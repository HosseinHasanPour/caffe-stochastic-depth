I0619 14:56:41.541462 17898 caffe.cpp:185] Using GPUs 0
I0619 14:56:41.578692 17898 caffe.cpp:190] GPU 0: GeForce GTX TITAN X
I0619 14:56:41.993626 17898 solver.cpp:48] Initializing solver from parameters: 
train_net: "examples/stochastic_depth/residual_train54.prototxt"
test_net: "examples/stochastic_depth/residual_test54.prototxt"
test_iter: 100
test_interval: 400
base_lr: 0.1
display: 400
max_iter: 200000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
solver_mode: GPU
device_id: 0
random_seed: 831486
stepvalue: 100000
stepvalue: 150000
type: "Nesterov"
I0619 14:56:41.993685 17898 solver.cpp:81] Creating training net from train_net file: examples/stochastic_depth/residual_train54.prototxt
I0619 14:56:42.009977 17898 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "/scratch/pas282/caffe/examples/cifar10/cifar10_train_leveldb_padding3"
    batch_size: 128
    backend: LEVELDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution21"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution22"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution22"
  top: "Convolution22"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Convolution22"
  top: "Convolution23"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution23"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution24"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution25"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution26"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution27"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution28"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution28"
  top: "Convolution28"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution29"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution30"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "Convolution30"
  top: "Convolution30"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Convolution30"
  top: "Convolution31"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise15"
  type: "Eltwise"
  bottom: "Eltwise14"
  bottom: "Convolution31"
  top: "Eltwise15"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "Eltwise15"
  top: "Eltwise15"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Eltwise15"
  top: "Convolution32"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm32"
  type: "BatchNorm"
  bottom: "Convolution32"
  top: "Convolution32"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale32"
  type: "Scale"
  bottom: "Convolution32"
  top: "Convolution32"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU32"
  type: "ReLU"
  bottom: "Convolution32"
  top: "Convolution32"
}
layer {
  name: "Convolution33"
  type: "Convolution"
  bottom: "Convolution32"
  top: "Convolution33"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm33"
  type: "BatchNorm"
  bottom: "Convolution33"
  top: "Convolution33"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale33"
  type: "Scale"
  bottom: "Convolution33"
  top: "Convolution33"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise16"
  type: "Eltwise"
  bottom: "Eltwise15"
  bottom: "Convolution33"
  top: "Eltwise16"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU33"
  type: "ReLU"
  bottom: "Eltwise16"
  top: "Eltwise16"
}
layer {
  name: "Convolution34"
  type: "Convolution"
  bottom: "Eltwise16"
  top: "Convolution34"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm34"
  type: "BatchNorm"
  bottom: "Convolution34"
  top: "Convolution34"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale34"
  type: "Scale"
  bottom: "Convolution34"
  top: "Convolution34"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU34"
  type: "ReLU"
  bottom: "Convolution34"
  top: "Convolution34"
}
layer {
  name: "Convolution35"
  type: "Convolution"
  bottom: "Convolution34"
  top: "Convolution35"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm35"
  type: "BatchNorm"
  bottom: "Convolution35"
  top: "Convolution35"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale35"
  type: "Scale"
  bottom: "Convolution35"
  top: "Convolution35"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise17"
  type: "Eltwise"
  bottom: "Eltwise16"
  bottom: "Convolution35"
  top: "Eltwise17"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU35"
  type: "ReLU"
  bottom: "Eltwise17"
  top: "Eltwise17"
}
layer {
  name: "Convolution36"
  type: "Convolution"
  bottom: "Eltwise17"
  top: "Convolution36"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
 
I0619 14:56:42.012615 17898 layer_factory.hpp:77] Creating layer Data1
I0619 14:56:42.012871 17898 net.cpp:91] Creating Layer Data1
I0619 14:56:42.012886 17898 net.cpp:399] Data1 -> Data1
I0619 14:56:42.012962 17898 net.cpp:399] Data1 -> Data2
I0619 14:56:42.052469 17902 db_leveldb.cpp:18] Opened leveldb /scratch/pas282/caffe/examples/cifar10/cifar10_train_leveldb_padding3
I0619 14:56:42.073369 17898 data_layer.cpp:41] output data size: 128,3,32,32
I0619 14:56:42.078850 17898 net.cpp:141] Setting up Data1
I0619 14:56:42.078892 17898 net.cpp:148] Top shape: 128 3 32 32 (393216)
I0619 14:56:42.078904 17898 net.cpp:148] Top shape: 128 (128)
I0619 14:56:42.078912 17898 net.cpp:156] Memory required for data: 1573376
I0619 14:56:42.078930 17898 layer_factory.hpp:77] Creating layer Convolution1
I0619 14:56:42.078972 17898 net.cpp:91] Creating Layer Convolution1
I0619 14:56:42.078986 17898 net.cpp:425] Convolution1 <- Data1
I0619 14:56:42.079017 17898 net.cpp:399] Convolution1 -> Convolution1
I0619 14:56:42.080518 17898 net.cpp:141] Setting up Convolution1
I0619 14:56:42.080546 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.080554 17898 net.cpp:156] Memory required for data: 9961984
I0619 14:56:42.080584 17898 layer_factory.hpp:77] Creating layer BatchNorm1
I0619 14:56:42.080608 17898 net.cpp:91] Creating Layer BatchNorm1
I0619 14:56:42.080617 17898 net.cpp:425] BatchNorm1 <- Convolution1
I0619 14:56:42.080636 17898 net.cpp:386] BatchNorm1 -> Convolution1 (in-place)
I0619 14:56:42.080988 17898 net.cpp:141] Setting up BatchNorm1
I0619 14:56:42.081004 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.081012 17898 net.cpp:156] Memory required for data: 18350592
I0619 14:56:42.081034 17898 layer_factory.hpp:77] Creating layer Scale1
I0619 14:56:42.081053 17898 net.cpp:91] Creating Layer Scale1
I0619 14:56:42.081060 17898 net.cpp:425] Scale1 <- Convolution1
I0619 14:56:42.081071 17898 net.cpp:386] Scale1 -> Convolution1 (in-place)
I0619 14:56:42.081138 17898 layer_factory.hpp:77] Creating layer Scale1
I0619 14:56:42.081357 17898 net.cpp:141] Setting up Scale1
I0619 14:56:42.081413 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.081426 17898 net.cpp:156] Memory required for data: 26739200
I0619 14:56:42.081446 17898 layer_factory.hpp:77] Creating layer ReLU1
I0619 14:56:42.081461 17898 net.cpp:91] Creating Layer ReLU1
I0619 14:56:42.081468 17898 net.cpp:425] ReLU1 <- Convolution1
I0619 14:56:42.081480 17898 net.cpp:386] ReLU1 -> Convolution1 (in-place)
I0619 14:56:42.081499 17898 net.cpp:141] Setting up ReLU1
I0619 14:56:42.081509 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.081516 17898 net.cpp:156] Memory required for data: 35127808
I0619 14:56:42.081523 17898 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0619 14:56:42.081542 17898 net.cpp:91] Creating Layer Convolution1_ReLU1_0_split
I0619 14:56:42.081550 17898 net.cpp:425] Convolution1_ReLU1_0_split <- Convolution1
I0619 14:56:42.081562 17898 net.cpp:399] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0619 14:56:42.081574 17898 net.cpp:399] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0619 14:56:42.081642 17898 net.cpp:141] Setting up Convolution1_ReLU1_0_split
I0619 14:56:42.081655 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.081667 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.081675 17898 net.cpp:156] Memory required for data: 51905024
I0619 14:56:42.081681 17898 layer_factory.hpp:77] Creating layer Convolution2
I0619 14:56:42.081697 17898 net.cpp:91] Creating Layer Convolution2
I0619 14:56:42.081706 17898 net.cpp:425] Convolution2 <- Convolution1_ReLU1_0_split_0
I0619 14:56:42.081722 17898 net.cpp:399] Convolution2 -> Convolution2
I0619 14:56:42.083344 17898 net.cpp:141] Setting up Convolution2
I0619 14:56:42.083371 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.083379 17898 net.cpp:156] Memory required for data: 60293632
I0619 14:56:42.083398 17898 layer_factory.hpp:77] Creating layer BatchNorm2
I0619 14:56:42.083420 17898 net.cpp:91] Creating Layer BatchNorm2
I0619 14:56:42.083428 17898 net.cpp:425] BatchNorm2 <- Convolution2
I0619 14:56:42.083442 17898 net.cpp:386] BatchNorm2 -> Convolution2 (in-place)
I0619 14:56:42.083755 17898 net.cpp:141] Setting up BatchNorm2
I0619 14:56:42.083768 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.083775 17898 net.cpp:156] Memory required for data: 68682240
I0619 14:56:42.083792 17898 layer_factory.hpp:77] Creating layer Scale2
I0619 14:56:42.083809 17898 net.cpp:91] Creating Layer Scale2
I0619 14:56:42.083817 17898 net.cpp:425] Scale2 <- Convolution2
I0619 14:56:42.083827 17898 net.cpp:386] Scale2 -> Convolution2 (in-place)
I0619 14:56:42.083880 17898 layer_factory.hpp:77] Creating layer Scale2
I0619 14:56:42.084069 17898 net.cpp:141] Setting up Scale2
I0619 14:56:42.084084 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.084090 17898 net.cpp:156] Memory required for data: 77070848
I0619 14:56:42.084102 17898 layer_factory.hpp:77] Creating layer ReLU2
I0619 14:56:42.084113 17898 net.cpp:91] Creating Layer ReLU2
I0619 14:56:42.084120 17898 net.cpp:425] ReLU2 <- Convolution2
I0619 14:56:42.084130 17898 net.cpp:386] ReLU2 -> Convolution2 (in-place)
I0619 14:56:42.084146 17898 net.cpp:141] Setting up ReLU2
I0619 14:56:42.084156 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.084161 17898 net.cpp:156] Memory required for data: 85459456
I0619 14:56:42.084167 17898 layer_factory.hpp:77] Creating layer Convolution3
I0619 14:56:42.084192 17898 net.cpp:91] Creating Layer Convolution3
I0619 14:56:42.084199 17898 net.cpp:425] Convolution3 <- Convolution2
I0619 14:56:42.084213 17898 net.cpp:399] Convolution3 -> Convolution3
I0619 14:56:42.084727 17898 net.cpp:141] Setting up Convolution3
I0619 14:56:42.084740 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.084748 17898 net.cpp:156] Memory required for data: 93848064
I0619 14:56:42.084759 17898 layer_factory.hpp:77] Creating layer BatchNorm3
I0619 14:56:42.084777 17898 net.cpp:91] Creating Layer BatchNorm3
I0619 14:56:42.084805 17898 net.cpp:425] BatchNorm3 <- Convolution3
I0619 14:56:42.084817 17898 net.cpp:386] BatchNorm3 -> Convolution3 (in-place)
I0619 14:56:42.085130 17898 net.cpp:141] Setting up BatchNorm3
I0619 14:56:42.085144 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.085150 17898 net.cpp:156] Memory required for data: 102236672
I0619 14:56:42.085171 17898 layer_factory.hpp:77] Creating layer Scale3
I0619 14:56:42.085186 17898 net.cpp:91] Creating Layer Scale3
I0619 14:56:42.085192 17898 net.cpp:425] Scale3 <- Convolution3
I0619 14:56:42.085202 17898 net.cpp:386] Scale3 -> Convolution3 (in-place)
I0619 14:56:42.085271 17898 layer_factory.hpp:77] Creating layer Scale3
I0619 14:56:42.085448 17898 net.cpp:141] Setting up Scale3
I0619 14:56:42.085459 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.085466 17898 net.cpp:156] Memory required for data: 110625280
I0619 14:56:42.085477 17898 layer_factory.hpp:77] Creating layer Eltwise1
I0619 14:56:42.085500 17898 net.cpp:91] Creating Layer Eltwise1
I0619 14:56:42.085506 17898 net.cpp:425] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0619 14:56:42.085515 17898 net.cpp:425] Eltwise1 <- Convolution3
I0619 14:56:42.085525 17898 net.cpp:399] Eltwise1 -> Eltwise1
I0619 14:56:42.085577 17898 net.cpp:141] Setting up Eltwise1
I0619 14:56:42.085587 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.085593 17898 net.cpp:156] Memory required for data: 119013888
I0619 14:56:42.085599 17898 layer_factory.hpp:77] Creating layer ReLU3
I0619 14:56:42.085613 17898 net.cpp:91] Creating Layer ReLU3
I0619 14:56:42.085618 17898 net.cpp:425] ReLU3 <- Eltwise1
I0619 14:56:42.085628 17898 net.cpp:386] ReLU3 -> Eltwise1 (in-place)
I0619 14:56:42.085638 17898 net.cpp:141] Setting up ReLU3
I0619 14:56:42.085647 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.085654 17898 net.cpp:156] Memory required for data: 127402496
I0619 14:56:42.085659 17898 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0619 14:56:42.085669 17898 net.cpp:91] Creating Layer Eltwise1_ReLU3_0_split
I0619 14:56:42.085677 17898 net.cpp:425] Eltwise1_ReLU3_0_split <- Eltwise1
I0619 14:56:42.085690 17898 net.cpp:399] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0619 14:56:42.085702 17898 net.cpp:399] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0619 14:56:42.085892 17898 net.cpp:141] Setting up Eltwise1_ReLU3_0_split
I0619 14:56:42.085908 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.085917 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.085923 17898 net.cpp:156] Memory required for data: 144179712
I0619 14:56:42.085930 17898 layer_factory.hpp:77] Creating layer Convolution4
I0619 14:56:42.085957 17898 net.cpp:91] Creating Layer Convolution4
I0619 14:56:42.085964 17898 net.cpp:425] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0619 14:56:42.085976 17898 net.cpp:399] Convolution4 -> Convolution4
I0619 14:56:42.086494 17898 net.cpp:141] Setting up Convolution4
I0619 14:56:42.086510 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.086518 17898 net.cpp:156] Memory required for data: 152568320
I0619 14:56:42.086529 17898 layer_factory.hpp:77] Creating layer BatchNorm4
I0619 14:56:42.086544 17898 net.cpp:91] Creating Layer BatchNorm4
I0619 14:56:42.086551 17898 net.cpp:425] BatchNorm4 <- Convolution4
I0619 14:56:42.086562 17898 net.cpp:386] BatchNorm4 -> Convolution4 (in-place)
I0619 14:56:42.086887 17898 net.cpp:141] Setting up BatchNorm4
I0619 14:56:42.086905 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.086911 17898 net.cpp:156] Memory required for data: 160956928
I0619 14:56:42.086926 17898 layer_factory.hpp:77] Creating layer Scale4
I0619 14:56:42.086941 17898 net.cpp:91] Creating Layer Scale4
I0619 14:56:42.086949 17898 net.cpp:425] Scale4 <- Convolution4
I0619 14:56:42.086959 17898 net.cpp:386] Scale4 -> Convolution4 (in-place)
I0619 14:56:42.087023 17898 layer_factory.hpp:77] Creating layer Scale4
I0619 14:56:42.087211 17898 net.cpp:141] Setting up Scale4
I0619 14:56:42.087244 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.087251 17898 net.cpp:156] Memory required for data: 169345536
I0619 14:56:42.087266 17898 layer_factory.hpp:77] Creating layer ReLU4
I0619 14:56:42.087277 17898 net.cpp:91] Creating Layer ReLU4
I0619 14:56:42.087283 17898 net.cpp:425] ReLU4 <- Convolution4
I0619 14:56:42.087296 17898 net.cpp:386] ReLU4 -> Convolution4 (in-place)
I0619 14:56:42.087308 17898 net.cpp:141] Setting up ReLU4
I0619 14:56:42.087318 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.087324 17898 net.cpp:156] Memory required for data: 177734144
I0619 14:56:42.087332 17898 layer_factory.hpp:77] Creating layer Convolution5
I0619 14:56:42.087352 17898 net.cpp:91] Creating Layer Convolution5
I0619 14:56:42.087364 17898 net.cpp:425] Convolution5 <- Convolution4
I0619 14:56:42.087375 17898 net.cpp:399] Convolution5 -> Convolution5
I0619 14:56:42.087889 17898 net.cpp:141] Setting up Convolution5
I0619 14:56:42.087905 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.087911 17898 net.cpp:156] Memory required for data: 186122752
I0619 14:56:42.087924 17898 layer_factory.hpp:77] Creating layer BatchNorm5
I0619 14:56:42.087940 17898 net.cpp:91] Creating Layer BatchNorm5
I0619 14:56:42.087949 17898 net.cpp:425] BatchNorm5 <- Convolution5
I0619 14:56:42.087962 17898 net.cpp:386] BatchNorm5 -> Convolution5 (in-place)
I0619 14:56:42.088284 17898 net.cpp:141] Setting up BatchNorm5
I0619 14:56:42.088297 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.088304 17898 net.cpp:156] Memory required for data: 194511360
I0619 14:56:42.088328 17898 layer_factory.hpp:77] Creating layer Scale5
I0619 14:56:42.088340 17898 net.cpp:91] Creating Layer Scale5
I0619 14:56:42.088346 17898 net.cpp:425] Scale5 <- Convolution5
I0619 14:56:42.088356 17898 net.cpp:386] Scale5 -> Convolution5 (in-place)
I0619 14:56:42.088423 17898 layer_factory.hpp:77] Creating layer Scale5
I0619 14:56:42.088625 17898 net.cpp:141] Setting up Scale5
I0619 14:56:42.088639 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.088644 17898 net.cpp:156] Memory required for data: 202899968
I0619 14:56:42.088656 17898 layer_factory.hpp:77] Creating layer Eltwise2
I0619 14:56:42.088670 17898 net.cpp:91] Creating Layer Eltwise2
I0619 14:56:42.088676 17898 net.cpp:425] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0619 14:56:42.088685 17898 net.cpp:425] Eltwise2 <- Convolution5
I0619 14:56:42.088697 17898 net.cpp:399] Eltwise2 -> Eltwise2
I0619 14:56:42.088817 17898 net.cpp:141] Setting up Eltwise2
I0619 14:56:42.088831 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.088838 17898 net.cpp:156] Memory required for data: 211288576
I0619 14:56:42.088850 17898 layer_factory.hpp:77] Creating layer ReLU5
I0619 14:56:42.088863 17898 net.cpp:91] Creating Layer ReLU5
I0619 14:56:42.088871 17898 net.cpp:425] ReLU5 <- Eltwise2
I0619 14:56:42.088881 17898 net.cpp:386] ReLU5 -> Eltwise2 (in-place)
I0619 14:56:42.088891 17898 net.cpp:141] Setting up ReLU5
I0619 14:56:42.088901 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.088907 17898 net.cpp:156] Memory required for data: 219677184
I0619 14:56:42.088914 17898 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0619 14:56:42.088923 17898 net.cpp:91] Creating Layer Eltwise2_ReLU5_0_split
I0619 14:56:42.088930 17898 net.cpp:425] Eltwise2_ReLU5_0_split <- Eltwise2
I0619 14:56:42.088939 17898 net.cpp:399] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0619 14:56:42.088951 17898 net.cpp:399] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0619 14:56:42.089010 17898 net.cpp:141] Setting up Eltwise2_ReLU5_0_split
I0619 14:56:42.089025 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.089035 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.089041 17898 net.cpp:156] Memory required for data: 236454400
I0619 14:56:42.089047 17898 layer_factory.hpp:77] Creating layer Convolution6
I0619 14:56:42.089066 17898 net.cpp:91] Creating Layer Convolution6
I0619 14:56:42.089092 17898 net.cpp:425] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0619 14:56:42.089107 17898 net.cpp:399] Convolution6 -> Convolution6
I0619 14:56:42.089326 17903 blocking_queue.cpp:50] Waiting for data
I0619 14:56:42.089629 17898 net.cpp:141] Setting up Convolution6
I0619 14:56:42.089644 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.089651 17898 net.cpp:156] Memory required for data: 244843008
I0619 14:56:42.089663 17898 layer_factory.hpp:77] Creating layer BatchNorm6
I0619 14:56:42.089674 17898 net.cpp:91] Creating Layer BatchNorm6
I0619 14:56:42.089681 17898 net.cpp:425] BatchNorm6 <- Convolution6
I0619 14:56:42.089694 17898 net.cpp:386] BatchNorm6 -> Convolution6 (in-place)
I0619 14:56:42.089999 17898 net.cpp:141] Setting up BatchNorm6
I0619 14:56:42.090011 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.090018 17898 net.cpp:156] Memory required for data: 253231616
I0619 14:56:42.090032 17898 layer_factory.hpp:77] Creating layer Scale6
I0619 14:56:42.090044 17898 net.cpp:91] Creating Layer Scale6
I0619 14:56:42.090050 17898 net.cpp:425] Scale6 <- Convolution6
I0619 14:56:42.090060 17898 net.cpp:386] Scale6 -> Convolution6 (in-place)
I0619 14:56:42.090121 17898 layer_factory.hpp:77] Creating layer Scale6
I0619 14:56:42.090297 17898 net.cpp:141] Setting up Scale6
I0619 14:56:42.090309 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.090315 17898 net.cpp:156] Memory required for data: 261620224
I0619 14:56:42.090327 17898 layer_factory.hpp:77] Creating layer ReLU6
I0619 14:56:42.090337 17898 net.cpp:91] Creating Layer ReLU6
I0619 14:56:42.090343 17898 net.cpp:425] ReLU6 <- Convolution6
I0619 14:56:42.090366 17898 net.cpp:386] ReLU6 -> Convolution6 (in-place)
I0619 14:56:42.090379 17898 net.cpp:141] Setting up ReLU6
I0619 14:56:42.090389 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.090394 17898 net.cpp:156] Memory required for data: 270008832
I0619 14:56:42.090401 17898 layer_factory.hpp:77] Creating layer Convolution7
I0619 14:56:42.090417 17898 net.cpp:91] Creating Layer Convolution7
I0619 14:56:42.090425 17898 net.cpp:425] Convolution7 <- Convolution6
I0619 14:56:42.090440 17898 net.cpp:399] Convolution7 -> Convolution7
I0619 14:56:42.090934 17898 net.cpp:141] Setting up Convolution7
I0619 14:56:42.090950 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.090955 17898 net.cpp:156] Memory required for data: 278397440
I0619 14:56:42.090967 17898 layer_factory.hpp:77] Creating layer BatchNorm7
I0619 14:56:42.090978 17898 net.cpp:91] Creating Layer BatchNorm7
I0619 14:56:42.090984 17898 net.cpp:425] BatchNorm7 <- Convolution7
I0619 14:56:42.091001 17898 net.cpp:386] BatchNorm7 -> Convolution7 (in-place)
I0619 14:56:42.091303 17898 net.cpp:141] Setting up BatchNorm7
I0619 14:56:42.091315 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.091322 17898 net.cpp:156] Memory required for data: 286786048
I0619 14:56:42.091336 17898 layer_factory.hpp:77] Creating layer Scale7
I0619 14:56:42.091354 17898 net.cpp:91] Creating Layer Scale7
I0619 14:56:42.091361 17898 net.cpp:425] Scale7 <- Convolution7
I0619 14:56:42.091372 17898 net.cpp:386] Scale7 -> Convolution7 (in-place)
I0619 14:56:42.091423 17898 layer_factory.hpp:77] Creating layer Scale7
I0619 14:56:42.091601 17898 net.cpp:141] Setting up Scale7
I0619 14:56:42.091614 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.091620 17898 net.cpp:156] Memory required for data: 295174656
I0619 14:56:42.091631 17898 layer_factory.hpp:77] Creating layer Eltwise3
I0619 14:56:42.091645 17898 net.cpp:91] Creating Layer Eltwise3
I0619 14:56:42.091652 17898 net.cpp:425] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0619 14:56:42.091660 17898 net.cpp:425] Eltwise3 <- Convolution7
I0619 14:56:42.091670 17898 net.cpp:399] Eltwise3 -> Eltwise3
I0619 14:56:42.091713 17898 net.cpp:141] Setting up Eltwise3
I0619 14:56:42.091724 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.091730 17898 net.cpp:156] Memory required for data: 303563264
I0619 14:56:42.091770 17898 layer_factory.hpp:77] Creating layer ReLU7
I0619 14:56:42.091781 17898 net.cpp:91] Creating Layer ReLU7
I0619 14:56:42.091789 17898 net.cpp:425] ReLU7 <- Eltwise3
I0619 14:56:42.091801 17898 net.cpp:386] ReLU7 -> Eltwise3 (in-place)
I0619 14:56:42.091819 17898 net.cpp:141] Setting up ReLU7
I0619 14:56:42.091828 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.091835 17898 net.cpp:156] Memory required for data: 311951872
I0619 14:56:42.091841 17898 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0619 14:56:42.091850 17898 net.cpp:91] Creating Layer Eltwise3_ReLU7_0_split
I0619 14:56:42.091856 17898 net.cpp:425] Eltwise3_ReLU7_0_split <- Eltwise3
I0619 14:56:42.091866 17898 net.cpp:399] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0619 14:56:42.091876 17898 net.cpp:399] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0619 14:56:42.091936 17898 net.cpp:141] Setting up Eltwise3_ReLU7_0_split
I0619 14:56:42.091948 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.091955 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.091963 17898 net.cpp:156] Memory required for data: 328729088
I0619 14:56:42.091969 17898 layer_factory.hpp:77] Creating layer Convolution8
I0619 14:56:42.091985 17898 net.cpp:91] Creating Layer Convolution8
I0619 14:56:42.091994 17898 net.cpp:425] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0619 14:56:42.092005 17898 net.cpp:399] Convolution8 -> Convolution8
I0619 14:56:42.092512 17898 net.cpp:141] Setting up Convolution8
I0619 14:56:42.092525 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.092531 17898 net.cpp:156] Memory required for data: 337117696
I0619 14:56:42.092543 17898 layer_factory.hpp:77] Creating layer BatchNorm8
I0619 14:56:42.092557 17898 net.cpp:91] Creating Layer BatchNorm8
I0619 14:56:42.092566 17898 net.cpp:425] BatchNorm8 <- Convolution8
I0619 14:56:42.092577 17898 net.cpp:386] BatchNorm8 -> Convolution8 (in-place)
I0619 14:56:42.092878 17898 net.cpp:141] Setting up BatchNorm8
I0619 14:56:42.092890 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.092896 17898 net.cpp:156] Memory required for data: 345506304
I0619 14:56:42.092911 17898 layer_factory.hpp:77] Creating layer Scale8
I0619 14:56:42.092921 17898 net.cpp:91] Creating Layer Scale8
I0619 14:56:42.092928 17898 net.cpp:425] Scale8 <- Convolution8
I0619 14:56:42.092941 17898 net.cpp:386] Scale8 -> Convolution8 (in-place)
I0619 14:56:42.092994 17898 layer_factory.hpp:77] Creating layer Scale8
I0619 14:56:42.093168 17898 net.cpp:141] Setting up Scale8
I0619 14:56:42.093179 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.093185 17898 net.cpp:156] Memory required for data: 353894912
I0619 14:56:42.093196 17898 layer_factory.hpp:77] Creating layer ReLU8
I0619 14:56:42.093210 17898 net.cpp:91] Creating Layer ReLU8
I0619 14:56:42.093217 17898 net.cpp:425] ReLU8 <- Convolution8
I0619 14:56:42.093226 17898 net.cpp:386] ReLU8 -> Convolution8 (in-place)
I0619 14:56:42.093237 17898 net.cpp:141] Setting up ReLU8
I0619 14:56:42.093245 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.093252 17898 net.cpp:156] Memory required for data: 362283520
I0619 14:56:42.093258 17898 layer_factory.hpp:77] Creating layer Convolution9
I0619 14:56:42.093276 17898 net.cpp:91] Creating Layer Convolution9
I0619 14:56:42.093282 17898 net.cpp:425] Convolution9 <- Convolution8
I0619 14:56:42.093292 17898 net.cpp:399] Convolution9 -> Convolution9
I0619 14:56:42.093801 17898 net.cpp:141] Setting up Convolution9
I0619 14:56:42.093813 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.093819 17898 net.cpp:156] Memory required for data: 370672128
I0619 14:56:42.093832 17898 layer_factory.hpp:77] Creating layer BatchNorm9
I0619 14:56:42.093844 17898 net.cpp:91] Creating Layer BatchNorm9
I0619 14:56:42.093852 17898 net.cpp:425] BatchNorm9 <- Convolution9
I0619 14:56:42.093861 17898 net.cpp:386] BatchNorm9 -> Convolution9 (in-place)
I0619 14:56:42.094169 17898 net.cpp:141] Setting up BatchNorm9
I0619 14:56:42.094198 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.094205 17898 net.cpp:156] Memory required for data: 379060736
I0619 14:56:42.094219 17898 layer_factory.hpp:77] Creating layer Scale9
I0619 14:56:42.094230 17898 net.cpp:91] Creating Layer Scale9
I0619 14:56:42.094238 17898 net.cpp:425] Scale9 <- Convolution9
I0619 14:56:42.094250 17898 net.cpp:386] Scale9 -> Convolution9 (in-place)
I0619 14:56:42.094306 17898 layer_factory.hpp:77] Creating layer Scale9
I0619 14:56:42.094511 17898 net.cpp:141] Setting up Scale9
I0619 14:56:42.094524 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.094532 17898 net.cpp:156] Memory required for data: 387449344
I0619 14:56:42.094543 17898 layer_factory.hpp:77] Creating layer Eltwise4
I0619 14:56:42.094557 17898 net.cpp:91] Creating Layer Eltwise4
I0619 14:56:42.094565 17898 net.cpp:425] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0619 14:56:42.094574 17898 net.cpp:425] Eltwise4 <- Convolution9
I0619 14:56:42.094584 17898 net.cpp:399] Eltwise4 -> Eltwise4
I0619 14:56:42.094624 17898 net.cpp:141] Setting up Eltwise4
I0619 14:56:42.094636 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.094643 17898 net.cpp:156] Memory required for data: 395837952
I0619 14:56:42.094650 17898 layer_factory.hpp:77] Creating layer ReLU9
I0619 14:56:42.094660 17898 net.cpp:91] Creating Layer ReLU9
I0619 14:56:42.094666 17898 net.cpp:425] ReLU9 <- Eltwise4
I0619 14:56:42.094677 17898 net.cpp:386] ReLU9 -> Eltwise4 (in-place)
I0619 14:56:42.094688 17898 net.cpp:141] Setting up ReLU9
I0619 14:56:42.094697 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.094703 17898 net.cpp:156] Memory required for data: 404226560
I0619 14:56:42.094710 17898 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0619 14:56:42.094719 17898 net.cpp:91] Creating Layer Eltwise4_ReLU9_0_split
I0619 14:56:42.094725 17898 net.cpp:425] Eltwise4_ReLU9_0_split <- Eltwise4
I0619 14:56:42.094734 17898 net.cpp:399] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0619 14:56:42.094745 17898 net.cpp:399] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0619 14:56:42.094801 17898 net.cpp:141] Setting up Eltwise4_ReLU9_0_split
I0619 14:56:42.094811 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.094820 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.094826 17898 net.cpp:156] Memory required for data: 421003776
I0619 14:56:42.094832 17898 layer_factory.hpp:77] Creating layer Convolution10
I0619 14:56:42.094858 17898 net.cpp:91] Creating Layer Convolution10
I0619 14:56:42.094866 17898 net.cpp:425] Convolution10 <- Eltwise4_ReLU9_0_split_0
I0619 14:56:42.094877 17898 net.cpp:399] Convolution10 -> Convolution10
I0619 14:56:42.095351 17898 net.cpp:141] Setting up Convolution10
I0619 14:56:42.095363 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.095369 17898 net.cpp:156] Memory required for data: 429392384
I0619 14:56:42.095398 17898 layer_factory.hpp:77] Creating layer BatchNorm10
I0619 14:56:42.095417 17898 net.cpp:91] Creating Layer BatchNorm10
I0619 14:56:42.095424 17898 net.cpp:425] BatchNorm10 <- Convolution10
I0619 14:56:42.095434 17898 net.cpp:386] BatchNorm10 -> Convolution10 (in-place)
I0619 14:56:42.095729 17898 net.cpp:141] Setting up BatchNorm10
I0619 14:56:42.095741 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.095747 17898 net.cpp:156] Memory required for data: 437780992
I0619 14:56:42.095762 17898 layer_factory.hpp:77] Creating layer Scale10
I0619 14:56:42.095772 17898 net.cpp:91] Creating Layer Scale10
I0619 14:56:42.095778 17898 net.cpp:425] Scale10 <- Convolution10
I0619 14:56:42.095789 17898 net.cpp:386] Scale10 -> Convolution10 (in-place)
I0619 14:56:42.095839 17898 layer_factory.hpp:77] Creating layer Scale10
I0619 14:56:42.096011 17898 net.cpp:141] Setting up Scale10
I0619 14:56:42.096022 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.096029 17898 net.cpp:156] Memory required for data: 446169600
I0619 14:56:42.096043 17898 layer_factory.hpp:77] Creating layer ReLU10
I0619 14:56:42.096068 17898 net.cpp:91] Creating Layer ReLU10
I0619 14:56:42.096079 17898 net.cpp:425] ReLU10 <- Convolution10
I0619 14:56:42.096088 17898 net.cpp:386] ReLU10 -> Convolution10 (in-place)
I0619 14:56:42.096098 17898 net.cpp:141] Setting up ReLU10
I0619 14:56:42.096107 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.096114 17898 net.cpp:156] Memory required for data: 454558208
I0619 14:56:42.096120 17898 layer_factory.hpp:77] Creating layer Convolution11
I0619 14:56:42.096138 17898 net.cpp:91] Creating Layer Convolution11
I0619 14:56:42.096144 17898 net.cpp:425] Convolution11 <- Convolution10
I0619 14:56:42.096154 17898 net.cpp:399] Convolution11 -> Convolution11
I0619 14:56:42.096653 17898 net.cpp:141] Setting up Convolution11
I0619 14:56:42.096667 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.096673 17898 net.cpp:156] Memory required for data: 462946816
I0619 14:56:42.096688 17898 layer_factory.hpp:77] Creating layer BatchNorm11
I0619 14:56:42.096704 17898 net.cpp:91] Creating Layer BatchNorm11
I0619 14:56:42.096710 17898 net.cpp:425] BatchNorm11 <- Convolution11
I0619 14:56:42.096722 17898 net.cpp:386] BatchNorm11 -> Convolution11 (in-place)
I0619 14:56:42.097012 17898 net.cpp:141] Setting up BatchNorm11
I0619 14:56:42.097023 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.097029 17898 net.cpp:156] Memory required for data: 471335424
I0619 14:56:42.097043 17898 layer_factory.hpp:77] Creating layer Scale11
I0619 14:56:42.097053 17898 net.cpp:91] Creating Layer Scale11
I0619 14:56:42.097059 17898 net.cpp:425] Scale11 <- Convolution11
I0619 14:56:42.097069 17898 net.cpp:386] Scale11 -> Convolution11 (in-place)
I0619 14:56:42.097121 17898 layer_factory.hpp:77] Creating layer Scale11
I0619 14:56:42.097282 17898 net.cpp:141] Setting up Scale11
I0619 14:56:42.097293 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.097300 17898 net.cpp:156] Memory required for data: 479724032
I0619 14:56:42.097309 17898 layer_factory.hpp:77] Creating layer Eltwise5
I0619 14:56:42.097319 17898 net.cpp:91] Creating Layer Eltwise5
I0619 14:56:42.097332 17898 net.cpp:425] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0619 14:56:42.097340 17898 net.cpp:425] Eltwise5 <- Convolution11
I0619 14:56:42.097349 17898 net.cpp:399] Eltwise5 -> Eltwise5
I0619 14:56:42.097383 17898 net.cpp:141] Setting up Eltwise5
I0619 14:56:42.097391 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.097398 17898 net.cpp:156] Memory required for data: 488112640
I0619 14:56:42.097404 17898 layer_factory.hpp:77] Creating layer ReLU11
I0619 14:56:42.097415 17898 net.cpp:91] Creating Layer ReLU11
I0619 14:56:42.097422 17898 net.cpp:425] ReLU11 <- Eltwise5
I0619 14:56:42.097430 17898 net.cpp:386] ReLU11 -> Eltwise5 (in-place)
I0619 14:56:42.097445 17898 net.cpp:141] Setting up ReLU11
I0619 14:56:42.097453 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.097460 17898 net.cpp:156] Memory required for data: 496501248
I0619 14:56:42.097465 17898 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0619 14:56:42.097475 17898 net.cpp:91] Creating Layer Eltwise5_ReLU11_0_split
I0619 14:56:42.097481 17898 net.cpp:425] Eltwise5_ReLU11_0_split <- Eltwise5
I0619 14:56:42.097488 17898 net.cpp:399] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0619 14:56:42.097499 17898 net.cpp:399] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0619 14:56:42.097550 17898 net.cpp:141] Setting up Eltwise5_ReLU11_0_split
I0619 14:56:42.097560 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.097568 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.097573 17898 net.cpp:156] Memory required for data: 513278464
I0619 14:56:42.097579 17898 layer_factory.hpp:77] Creating layer Convolution12
I0619 14:56:42.097595 17898 net.cpp:91] Creating Layer Convolution12
I0619 14:56:42.097602 17898 net.cpp:425] Convolution12 <- Eltwise5_ReLU11_0_split_0
I0619 14:56:42.097617 17898 net.cpp:399] Convolution12 -> Convolution12
I0619 14:56:42.098116 17898 net.cpp:141] Setting up Convolution12
I0619 14:56:42.098129 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.098135 17898 net.cpp:156] Memory required for data: 521667072
I0619 14:56:42.098146 17898 layer_factory.hpp:77] Creating layer BatchNorm12
I0619 14:56:42.098160 17898 net.cpp:91] Creating Layer BatchNorm12
I0619 14:56:42.098166 17898 net.cpp:425] BatchNorm12 <- Convolution12
I0619 14:56:42.098176 17898 net.cpp:386] BatchNorm12 -> Convolution12 (in-place)
I0619 14:56:42.098474 17898 net.cpp:141] Setting up BatchNorm12
I0619 14:56:42.098485 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.098491 17898 net.cpp:156] Memory required for data: 530055680
I0619 14:56:42.098505 17898 layer_factory.hpp:77] Creating layer Scale12
I0619 14:56:42.098515 17898 net.cpp:91] Creating Layer Scale12
I0619 14:56:42.098521 17898 net.cpp:425] Scale12 <- Convolution12
I0619 14:56:42.098533 17898 net.cpp:386] Scale12 -> Convolution12 (in-place)
I0619 14:56:42.098582 17898 layer_factory.hpp:77] Creating layer Scale12
I0619 14:56:42.098754 17898 net.cpp:141] Setting up Scale12
I0619 14:56:42.098767 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.098773 17898 net.cpp:156] Memory required for data: 538444288
I0619 14:56:42.098783 17898 layer_factory.hpp:77] Creating layer ReLU12
I0619 14:56:42.098795 17898 net.cpp:91] Creating Layer ReLU12
I0619 14:56:42.098801 17898 net.cpp:425] ReLU12 <- Convolution12
I0619 14:56:42.098810 17898 net.cpp:386] ReLU12 -> Convolution12 (in-place)
I0619 14:56:42.098820 17898 net.cpp:141] Setting up ReLU12
I0619 14:56:42.098829 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.098834 17898 net.cpp:156] Memory required for data: 546832896
I0619 14:56:42.098840 17898 layer_factory.hpp:77] Creating layer Convolution13
I0619 14:56:42.098856 17898 net.cpp:91] Creating Layer Convolution13
I0619 14:56:42.098863 17898 net.cpp:425] Convolution13 <- Convolution12
I0619 14:56:42.098873 17898 net.cpp:399] Convolution13 -> Convolution13
I0619 14:56:42.099385 17898 net.cpp:141] Setting up Convolution13
I0619 14:56:42.099400 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.099406 17898 net.cpp:156] Memory required for data: 555221504
I0619 14:56:42.099417 17898 layer_factory.hpp:77] Creating layer BatchNorm13
I0619 14:56:42.099428 17898 net.cpp:91] Creating Layer BatchNorm13
I0619 14:56:42.099434 17898 net.cpp:425] BatchNorm13 <- Convolution13
I0619 14:56:42.099450 17898 net.cpp:386] BatchNorm13 -> Convolution13 (in-place)
I0619 14:56:42.099745 17898 net.cpp:141] Setting up BatchNorm13
I0619 14:56:42.099756 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.099761 17898 net.cpp:156] Memory required for data: 563610112
I0619 14:56:42.099774 17898 layer_factory.hpp:77] Creating layer Scale13
I0619 14:56:42.099788 17898 net.cpp:91] Creating Layer Scale13
I0619 14:56:42.099794 17898 net.cpp:425] Scale13 <- Convolution13
I0619 14:56:42.099803 17898 net.cpp:386] Scale13 -> Convolution13 (in-place)
I0619 14:56:42.099854 17898 layer_factory.hpp:77] Creating layer Scale13
I0619 14:56:42.100033 17898 net.cpp:141] Setting up Scale13
I0619 14:56:42.100044 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.100049 17898 net.cpp:156] Memory required for data: 571998720
I0619 14:56:42.100059 17898 layer_factory.hpp:77] Creating layer Eltwise6
I0619 14:56:42.100069 17898 net.cpp:91] Creating Layer Eltwise6
I0619 14:56:42.100076 17898 net.cpp:425] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0619 14:56:42.100083 17898 net.cpp:425] Eltwise6 <- Convolution13
I0619 14:56:42.100095 17898 net.cpp:399] Eltwise6 -> Eltwise6
I0619 14:56:42.100136 17898 net.cpp:141] Setting up Eltwise6
I0619 14:56:42.100147 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.100152 17898 net.cpp:156] Memory required for data: 580387328
I0619 14:56:42.100158 17898 layer_factory.hpp:77] Creating layer ReLU13
I0619 14:56:42.100177 17898 net.cpp:91] Creating Layer ReLU13
I0619 14:56:42.100213 17898 net.cpp:425] ReLU13 <- Eltwise6
I0619 14:56:42.100222 17898 net.cpp:386] ReLU13 -> Eltwise6 (in-place)
I0619 14:56:42.100234 17898 net.cpp:141] Setting up ReLU13
I0619 14:56:42.100242 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.100249 17898 net.cpp:156] Memory required for data: 588775936
I0619 14:56:42.100255 17898 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0619 14:56:42.100267 17898 net.cpp:91] Creating Layer Eltwise6_ReLU13_0_split
I0619 14:56:42.100273 17898 net.cpp:425] Eltwise6_ReLU13_0_split <- Eltwise6
I0619 14:56:42.100283 17898 net.cpp:399] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0619 14:56:42.100294 17898 net.cpp:399] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0619 14:56:42.100352 17898 net.cpp:141] Setting up Eltwise6_ReLU13_0_split
I0619 14:56:42.100361 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.100369 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.100375 17898 net.cpp:156] Memory required for data: 605553152
I0619 14:56:42.100381 17898 layer_factory.hpp:77] Creating layer Convolution14
I0619 14:56:42.100394 17898 net.cpp:91] Creating Layer Convolution14
I0619 14:56:42.100401 17898 net.cpp:425] Convolution14 <- Eltwise6_ReLU13_0_split_0
I0619 14:56:42.100411 17898 net.cpp:399] Convolution14 -> Convolution14
I0619 14:56:42.100883 17898 net.cpp:141] Setting up Convolution14
I0619 14:56:42.100898 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.100903 17898 net.cpp:156] Memory required for data: 613941760
I0619 14:56:42.100914 17898 layer_factory.hpp:77] Creating layer BatchNorm14
I0619 14:56:42.100927 17898 net.cpp:91] Creating Layer BatchNorm14
I0619 14:56:42.100934 17898 net.cpp:425] BatchNorm14 <- Convolution14
I0619 14:56:42.100942 17898 net.cpp:386] BatchNorm14 -> Convolution14 (in-place)
I0619 14:56:42.101244 17898 net.cpp:141] Setting up BatchNorm14
I0619 14:56:42.101256 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.101263 17898 net.cpp:156] Memory required for data: 622330368
I0619 14:56:42.101275 17898 layer_factory.hpp:77] Creating layer Scale14
I0619 14:56:42.101285 17898 net.cpp:91] Creating Layer Scale14
I0619 14:56:42.101292 17898 net.cpp:425] Scale14 <- Convolution14
I0619 14:56:42.101301 17898 net.cpp:386] Scale14 -> Convolution14 (in-place)
I0619 14:56:42.101354 17898 layer_factory.hpp:77] Creating layer Scale14
I0619 14:56:42.101529 17898 net.cpp:141] Setting up Scale14
I0619 14:56:42.101541 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.101547 17898 net.cpp:156] Memory required for data: 630718976
I0619 14:56:42.101557 17898 layer_factory.hpp:77] Creating layer ReLU14
I0619 14:56:42.101567 17898 net.cpp:91] Creating Layer ReLU14
I0619 14:56:42.101572 17898 net.cpp:425] ReLU14 <- Convolution14
I0619 14:56:42.101583 17898 net.cpp:386] ReLU14 -> Convolution14 (in-place)
I0619 14:56:42.101593 17898 net.cpp:141] Setting up ReLU14
I0619 14:56:42.101603 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.101608 17898 net.cpp:156] Memory required for data: 639107584
I0619 14:56:42.101613 17898 layer_factory.hpp:77] Creating layer Convolution15
I0619 14:56:42.101630 17898 net.cpp:91] Creating Layer Convolution15
I0619 14:56:42.101636 17898 net.cpp:425] Convolution15 <- Convolution14
I0619 14:56:42.101646 17898 net.cpp:399] Convolution15 -> Convolution15
I0619 14:56:42.102121 17898 net.cpp:141] Setting up Convolution15
I0619 14:56:42.102133 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.102139 17898 net.cpp:156] Memory required for data: 647496192
I0619 14:56:42.102150 17898 layer_factory.hpp:77] Creating layer BatchNorm15
I0619 14:56:42.102169 17898 net.cpp:91] Creating Layer BatchNorm15
I0619 14:56:42.102176 17898 net.cpp:425] BatchNorm15 <- Convolution15
I0619 14:56:42.102185 17898 net.cpp:386] BatchNorm15 -> Convolution15 (in-place)
I0619 14:56:42.102478 17898 net.cpp:141] Setting up BatchNorm15
I0619 14:56:42.102494 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.102520 17898 net.cpp:156] Memory required for data: 655884800
I0619 14:56:42.102535 17898 layer_factory.hpp:77] Creating layer Scale15
I0619 14:56:42.102548 17898 net.cpp:91] Creating Layer Scale15
I0619 14:56:42.102555 17898 net.cpp:425] Scale15 <- Convolution15
I0619 14:56:42.102566 17898 net.cpp:386] Scale15 -> Convolution15 (in-place)
I0619 14:56:42.102622 17898 layer_factory.hpp:77] Creating layer Scale15
I0619 14:56:42.102797 17898 net.cpp:141] Setting up Scale15
I0619 14:56:42.102809 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.102814 17898 net.cpp:156] Memory required for data: 664273408
I0619 14:56:42.102825 17898 layer_factory.hpp:77] Creating layer Eltwise7
I0619 14:56:42.102834 17898 net.cpp:91] Creating Layer Eltwise7
I0619 14:56:42.102841 17898 net.cpp:425] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0619 14:56:42.102849 17898 net.cpp:425] Eltwise7 <- Convolution15
I0619 14:56:42.102861 17898 net.cpp:399] Eltwise7 -> Eltwise7
I0619 14:56:42.102902 17898 net.cpp:141] Setting up Eltwise7
I0619 14:56:42.102911 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.102917 17898 net.cpp:156] Memory required for data: 672662016
I0619 14:56:42.102923 17898 layer_factory.hpp:77] Creating layer ReLU15
I0619 14:56:42.102931 17898 net.cpp:91] Creating Layer ReLU15
I0619 14:56:42.102937 17898 net.cpp:425] ReLU15 <- Eltwise7
I0619 14:56:42.102946 17898 net.cpp:386] ReLU15 -> Eltwise7 (in-place)
I0619 14:56:42.102955 17898 net.cpp:141] Setting up ReLU15
I0619 14:56:42.102963 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.102969 17898 net.cpp:156] Memory required for data: 681050624
I0619 14:56:42.102975 17898 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0619 14:56:42.102988 17898 net.cpp:91] Creating Layer Eltwise7_ReLU15_0_split
I0619 14:56:42.102993 17898 net.cpp:425] Eltwise7_ReLU15_0_split <- Eltwise7
I0619 14:56:42.103001 17898 net.cpp:399] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0619 14:56:42.103013 17898 net.cpp:399] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0619 14:56:42.103068 17898 net.cpp:141] Setting up Eltwise7_ReLU15_0_split
I0619 14:56:42.103078 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.103086 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.103092 17898 net.cpp:156] Memory required for data: 697827840
I0619 14:56:42.103097 17898 layer_factory.hpp:77] Creating layer Convolution16
I0619 14:56:42.103111 17898 net.cpp:91] Creating Layer Convolution16
I0619 14:56:42.103117 17898 net.cpp:425] Convolution16 <- Eltwise7_ReLU15_0_split_0
I0619 14:56:42.103127 17898 net.cpp:399] Convolution16 -> Convolution16
I0619 14:56:42.103603 17898 net.cpp:141] Setting up Convolution16
I0619 14:56:42.103616 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.103621 17898 net.cpp:156] Memory required for data: 706216448
I0619 14:56:42.103632 17898 layer_factory.hpp:77] Creating layer BatchNorm16
I0619 14:56:42.103646 17898 net.cpp:91] Creating Layer BatchNorm16
I0619 14:56:42.103652 17898 net.cpp:425] BatchNorm16 <- Convolution16
I0619 14:56:42.103662 17898 net.cpp:386] BatchNorm16 -> Convolution16 (in-place)
I0619 14:56:42.103958 17898 net.cpp:141] Setting up BatchNorm16
I0619 14:56:42.103971 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.103976 17898 net.cpp:156] Memory required for data: 714605056
I0619 14:56:42.103988 17898 layer_factory.hpp:77] Creating layer Scale16
I0619 14:56:42.103998 17898 net.cpp:91] Creating Layer Scale16
I0619 14:56:42.104006 17898 net.cpp:425] Scale16 <- Convolution16
I0619 14:56:42.104013 17898 net.cpp:386] Scale16 -> Convolution16 (in-place)
I0619 14:56:42.104065 17898 layer_factory.hpp:77] Creating layer Scale16
I0619 14:56:42.104240 17898 net.cpp:141] Setting up Scale16
I0619 14:56:42.104251 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.104256 17898 net.cpp:156] Memory required for data: 722993664
I0619 14:56:42.104266 17898 layer_factory.hpp:77] Creating layer ReLU16
I0619 14:56:42.104287 17898 net.cpp:91] Creating Layer ReLU16
I0619 14:56:42.104308 17898 net.cpp:425] ReLU16 <- Convolution16
I0619 14:56:42.104318 17898 net.cpp:386] ReLU16 -> Convolution16 (in-place)
I0619 14:56:42.104328 17898 net.cpp:141] Setting up ReLU16
I0619 14:56:42.104341 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.104347 17898 net.cpp:156] Memory required for data: 731382272
I0619 14:56:42.104357 17898 layer_factory.hpp:77] Creating layer Convolution17
I0619 14:56:42.104372 17898 net.cpp:91] Creating Layer Convolution17
I0619 14:56:42.104379 17898 net.cpp:425] Convolution17 <- Convolution16
I0619 14:56:42.104389 17898 net.cpp:399] Convolution17 -> Convolution17
I0619 14:56:42.104873 17898 net.cpp:141] Setting up Convolution17
I0619 14:56:42.104887 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.104893 17898 net.cpp:156] Memory required for data: 739770880
I0619 14:56:42.104903 17898 layer_factory.hpp:77] Creating layer BatchNorm17
I0619 14:56:42.104913 17898 net.cpp:91] Creating Layer BatchNorm17
I0619 14:56:42.104923 17898 net.cpp:425] BatchNorm17 <- Convolution17
I0619 14:56:42.104935 17898 net.cpp:386] BatchNorm17 -> Convolution17 (in-place)
I0619 14:56:42.105227 17898 net.cpp:141] Setting up BatchNorm17
I0619 14:56:42.105238 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.105244 17898 net.cpp:156] Memory required for data: 748159488
I0619 14:56:42.105258 17898 layer_factory.hpp:77] Creating layer Scale17
I0619 14:56:42.105271 17898 net.cpp:91] Creating Layer Scale17
I0619 14:56:42.105278 17898 net.cpp:425] Scale17 <- Convolution17
I0619 14:56:42.105288 17898 net.cpp:386] Scale17 -> Convolution17 (in-place)
I0619 14:56:42.105339 17898 layer_factory.hpp:77] Creating layer Scale17
I0619 14:56:42.105514 17898 net.cpp:141] Setting up Scale17
I0619 14:56:42.105525 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.105530 17898 net.cpp:156] Memory required for data: 756548096
I0619 14:56:42.105540 17898 layer_factory.hpp:77] Creating layer Eltwise8
I0619 14:56:42.105550 17898 net.cpp:91] Creating Layer Eltwise8
I0619 14:56:42.105556 17898 net.cpp:425] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0619 14:56:42.105563 17898 net.cpp:425] Eltwise8 <- Convolution17
I0619 14:56:42.105576 17898 net.cpp:399] Eltwise8 -> Eltwise8
I0619 14:56:42.105612 17898 net.cpp:141] Setting up Eltwise8
I0619 14:56:42.105623 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.105628 17898 net.cpp:156] Memory required for data: 764936704
I0619 14:56:42.105633 17898 layer_factory.hpp:77] Creating layer ReLU17
I0619 14:56:42.105643 17898 net.cpp:91] Creating Layer ReLU17
I0619 14:56:42.105648 17898 net.cpp:425] ReLU17 <- Eltwise8
I0619 14:56:42.105656 17898 net.cpp:386] ReLU17 -> Eltwise8 (in-place)
I0619 14:56:42.105666 17898 net.cpp:141] Setting up ReLU17
I0619 14:56:42.105674 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.105680 17898 net.cpp:156] Memory required for data: 773325312
I0619 14:56:42.105686 17898 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0619 14:56:42.105695 17898 net.cpp:91] Creating Layer Eltwise8_ReLU17_0_split
I0619 14:56:42.105700 17898 net.cpp:425] Eltwise8_ReLU17_0_split <- Eltwise8
I0619 14:56:42.105715 17898 net.cpp:399] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0619 14:56:42.105726 17898 net.cpp:399] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0619 14:56:42.105782 17898 net.cpp:141] Setting up Eltwise8_ReLU17_0_split
I0619 14:56:42.105792 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.105799 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.105805 17898 net.cpp:156] Memory required for data: 790102528
I0619 14:56:42.105810 17898 layer_factory.hpp:77] Creating layer Convolution18
I0619 14:56:42.105823 17898 net.cpp:91] Creating Layer Convolution18
I0619 14:56:42.105830 17898 net.cpp:425] Convolution18 <- Eltwise8_ReLU17_0_split_0
I0619 14:56:42.105840 17898 net.cpp:399] Convolution18 -> Convolution18
I0619 14:56:42.106320 17898 net.cpp:141] Setting up Convolution18
I0619 14:56:42.106364 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.106375 17898 net.cpp:156] Memory required for data: 798491136
I0619 14:56:42.106387 17898 layer_factory.hpp:77] Creating layer BatchNorm18
I0619 14:56:42.106401 17898 net.cpp:91] Creating Layer BatchNorm18
I0619 14:56:42.106408 17898 net.cpp:425] BatchNorm18 <- Convolution18
I0619 14:56:42.106418 17898 net.cpp:386] BatchNorm18 -> Convolution18 (in-place)
I0619 14:56:42.106708 17898 net.cpp:141] Setting up BatchNorm18
I0619 14:56:42.106719 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.106724 17898 net.cpp:156] Memory required for data: 806879744
I0619 14:56:42.106736 17898 layer_factory.hpp:77] Creating layer Scale18
I0619 14:56:42.106748 17898 net.cpp:91] Creating Layer Scale18
I0619 14:56:42.106755 17898 net.cpp:425] Scale18 <- Convolution18
I0619 14:56:42.106763 17898 net.cpp:386] Scale18 -> Convolution18 (in-place)
I0619 14:56:42.106817 17898 layer_factory.hpp:77] Creating layer Scale18
I0619 14:56:42.106989 17898 net.cpp:141] Setting up Scale18
I0619 14:56:42.107000 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.107007 17898 net.cpp:156] Memory required for data: 815268352
I0619 14:56:42.107015 17898 layer_factory.hpp:77] Creating layer ReLU18
I0619 14:56:42.107024 17898 net.cpp:91] Creating Layer ReLU18
I0619 14:56:42.107030 17898 net.cpp:425] ReLU18 <- Convolution18
I0619 14:56:42.107040 17898 net.cpp:386] ReLU18 -> Convolution18 (in-place)
I0619 14:56:42.107050 17898 net.cpp:141] Setting up ReLU18
I0619 14:56:42.107059 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.107064 17898 net.cpp:156] Memory required for data: 823656960
I0619 14:56:42.107069 17898 layer_factory.hpp:77] Creating layer Convolution19
I0619 14:56:42.107084 17898 net.cpp:91] Creating Layer Convolution19
I0619 14:56:42.107090 17898 net.cpp:425] Convolution19 <- Convolution18
I0619 14:56:42.107100 17898 net.cpp:399] Convolution19 -> Convolution19
I0619 14:56:42.107553 17898 net.cpp:141] Setting up Convolution19
I0619 14:56:42.107565 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.107571 17898 net.cpp:156] Memory required for data: 832045568
I0619 14:56:42.107581 17898 layer_factory.hpp:77] Creating layer BatchNorm19
I0619 14:56:42.107592 17898 net.cpp:91] Creating Layer BatchNorm19
I0619 14:56:42.107599 17898 net.cpp:425] BatchNorm19 <- Convolution19
I0619 14:56:42.107607 17898 net.cpp:386] BatchNorm19 -> Convolution19 (in-place)
I0619 14:56:42.107883 17898 net.cpp:141] Setting up BatchNorm19
I0619 14:56:42.107894 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.107899 17898 net.cpp:156] Memory required for data: 840434176
I0619 14:56:42.107939 17898 layer_factory.hpp:77] Creating layer Scale19
I0619 14:56:42.107951 17898 net.cpp:91] Creating Layer Scale19
I0619 14:56:42.107957 17898 net.cpp:425] Scale19 <- Convolution19
I0619 14:56:42.107965 17898 net.cpp:386] Scale19 -> Convolution19 (in-place)
I0619 14:56:42.108016 17898 layer_factory.hpp:77] Creating layer Scale19
I0619 14:56:42.108172 17898 net.cpp:141] Setting up Scale19
I0619 14:56:42.108182 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.108188 17898 net.cpp:156] Memory required for data: 848822784
I0619 14:56:42.108198 17898 layer_factory.hpp:77] Creating layer Eltwise9
I0619 14:56:42.108207 17898 net.cpp:91] Creating Layer Eltwise9
I0619 14:56:42.108213 17898 net.cpp:425] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0619 14:56:42.108220 17898 net.cpp:425] Eltwise9 <- Convolution19
I0619 14:56:42.108229 17898 net.cpp:399] Eltwise9 -> Eltwise9
I0619 14:56:42.108264 17898 net.cpp:141] Setting up Eltwise9
I0619 14:56:42.108274 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.108279 17898 net.cpp:156] Memory required for data: 857211392
I0619 14:56:42.108284 17898 layer_factory.hpp:77] Creating layer ReLU19
I0619 14:56:42.108295 17898 net.cpp:91] Creating Layer ReLU19
I0619 14:56:42.108301 17898 net.cpp:425] ReLU19 <- Eltwise9
I0619 14:56:42.108314 17898 net.cpp:386] ReLU19 -> Eltwise9 (in-place)
I0619 14:56:42.108340 17898 net.cpp:141] Setting up ReLU19
I0619 14:56:42.108350 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.108355 17898 net.cpp:156] Memory required for data: 865600000
I0619 14:56:42.108361 17898 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0619 14:56:42.108369 17898 net.cpp:91] Creating Layer Eltwise9_ReLU19_0_split
I0619 14:56:42.108376 17898 net.cpp:425] Eltwise9_ReLU19_0_split <- Eltwise9
I0619 14:56:42.108383 17898 net.cpp:399] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0619 14:56:42.108397 17898 net.cpp:399] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0619 14:56:42.108453 17898 net.cpp:141] Setting up Eltwise9_ReLU19_0_split
I0619 14:56:42.108461 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.108469 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.108474 17898 net.cpp:156] Memory required for data: 882377216
I0619 14:56:42.108480 17898 layer_factory.hpp:77] Creating layer Convolution20
I0619 14:56:42.108496 17898 net.cpp:91] Creating Layer Convolution20
I0619 14:56:42.108502 17898 net.cpp:425] Convolution20 <- Eltwise9_ReLU19_0_split_0
I0619 14:56:42.108512 17898 net.cpp:399] Convolution20 -> Convolution20
I0619 14:56:42.108966 17898 net.cpp:141] Setting up Convolution20
I0619 14:56:42.108978 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.108984 17898 net.cpp:156] Memory required for data: 890765824
I0619 14:56:42.108994 17898 layer_factory.hpp:77] Creating layer BatchNorm20
I0619 14:56:42.109007 17898 net.cpp:91] Creating Layer BatchNorm20
I0619 14:56:42.109014 17898 net.cpp:425] BatchNorm20 <- Convolution20
I0619 14:56:42.109025 17898 net.cpp:386] BatchNorm20 -> Convolution20 (in-place)
I0619 14:56:42.109303 17898 net.cpp:141] Setting up BatchNorm20
I0619 14:56:42.109315 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.109320 17898 net.cpp:156] Memory required for data: 899154432
I0619 14:56:42.109333 17898 layer_factory.hpp:77] Creating layer Scale20
I0619 14:56:42.109344 17898 net.cpp:91] Creating Layer Scale20
I0619 14:56:42.109350 17898 net.cpp:425] Scale20 <- Convolution20
I0619 14:56:42.109359 17898 net.cpp:386] Scale20 -> Convolution20 (in-place)
I0619 14:56:42.109407 17898 layer_factory.hpp:77] Creating layer Scale20
I0619 14:56:42.109565 17898 net.cpp:141] Setting up Scale20
I0619 14:56:42.109575 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.109580 17898 net.cpp:156] Memory required for data: 907543040
I0619 14:56:42.109589 17898 layer_factory.hpp:77] Creating layer ReLU20
I0619 14:56:42.109598 17898 net.cpp:91] Creating Layer ReLU20
I0619 14:56:42.109604 17898 net.cpp:425] ReLU20 <- Convolution20
I0619 14:56:42.109612 17898 net.cpp:386] ReLU20 -> Convolution20 (in-place)
I0619 14:56:42.109623 17898 net.cpp:141] Setting up ReLU20
I0619 14:56:42.109632 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.109637 17898 net.cpp:156] Memory required for data: 915931648
I0619 14:56:42.109642 17898 layer_factory.hpp:77] Creating layer Convolution21
I0619 14:56:42.109658 17898 net.cpp:91] Creating Layer Convolution21
I0619 14:56:42.109663 17898 net.cpp:425] Convolution21 <- Convolution20
I0619 14:56:42.109675 17898 net.cpp:399] Convolution21 -> Convolution21
I0619 14:56:42.110126 17898 net.cpp:141] Setting up Convolution21
I0619 14:56:42.110138 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.110144 17898 net.cpp:156] Memory required for data: 924320256
I0619 14:56:42.110154 17898 layer_factory.hpp:77] Creating layer BatchNorm21
I0619 14:56:42.110168 17898 net.cpp:91] Creating Layer BatchNorm21
I0619 14:56:42.110175 17898 net.cpp:425] BatchNorm21 <- Convolution21
I0619 14:56:42.110185 17898 net.cpp:386] BatchNorm21 -> Convolution21 (in-place)
I0619 14:56:42.110476 17898 net.cpp:141] Setting up BatchNorm21
I0619 14:56:42.110487 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.110497 17898 net.cpp:156] Memory required for data: 932708864
I0619 14:56:42.110525 17898 layer_factory.hpp:77] Creating layer Scale21
I0619 14:56:42.110535 17898 net.cpp:91] Creating Layer Scale21
I0619 14:56:42.110541 17898 net.cpp:425] Scale21 <- Convolution21
I0619 14:56:42.110553 17898 net.cpp:386] Scale21 -> Convolution21 (in-place)
I0619 14:56:42.110602 17898 layer_factory.hpp:77] Creating layer Scale21
I0619 14:56:42.110761 17898 net.cpp:141] Setting up Scale21
I0619 14:56:42.110772 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.110777 17898 net.cpp:156] Memory required for data: 941097472
I0619 14:56:42.110787 17898 layer_factory.hpp:77] Creating layer Eltwise10
I0619 14:56:42.110798 17898 net.cpp:91] Creating Layer Eltwise10
I0619 14:56:42.110805 17898 net.cpp:425] Eltwise10 <- Eltwise9_ReLU19_0_split_1
I0619 14:56:42.110812 17898 net.cpp:425] Eltwise10 <- Convolution21
I0619 14:56:42.110821 17898 net.cpp:399] Eltwise10 -> Eltwise10
I0619 14:56:42.110860 17898 net.cpp:141] Setting up Eltwise10
I0619 14:56:42.110870 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.110875 17898 net.cpp:156] Memory required for data: 949486080
I0619 14:56:42.110880 17898 layer_factory.hpp:77] Creating layer ReLU21
I0619 14:56:42.110889 17898 net.cpp:91] Creating Layer ReLU21
I0619 14:56:42.110898 17898 net.cpp:425] ReLU21 <- Eltwise10
I0619 14:56:42.110909 17898 net.cpp:386] ReLU21 -> Eltwise10 (in-place)
I0619 14:56:42.110918 17898 net.cpp:141] Setting up ReLU21
I0619 14:56:42.110926 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.110931 17898 net.cpp:156] Memory required for data: 957874688
I0619 14:56:42.110937 17898 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0619 14:56:42.110945 17898 net.cpp:91] Creating Layer Eltwise10_ReLU21_0_split
I0619 14:56:42.110950 17898 net.cpp:425] Eltwise10_ReLU21_0_split <- Eltwise10
I0619 14:56:42.110958 17898 net.cpp:399] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0619 14:56:42.110968 17898 net.cpp:399] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0619 14:56:42.111018 17898 net.cpp:141] Setting up Eltwise10_ReLU21_0_split
I0619 14:56:42.111027 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.111034 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.111040 17898 net.cpp:156] Memory required for data: 974651904
I0619 14:56:42.111045 17898 layer_factory.hpp:77] Creating layer Convolution22
I0619 14:56:42.111062 17898 net.cpp:91] Creating Layer Convolution22
I0619 14:56:42.111068 17898 net.cpp:425] Convolution22 <- Eltwise10_ReLU21_0_split_0
I0619 14:56:42.111078 17898 net.cpp:399] Convolution22 -> Convolution22
I0619 14:56:42.111528 17898 net.cpp:141] Setting up Convolution22
I0619 14:56:42.111541 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.111546 17898 net.cpp:156] Memory required for data: 983040512
I0619 14:56:42.111555 17898 layer_factory.hpp:77] Creating layer BatchNorm22
I0619 14:56:42.111568 17898 net.cpp:91] Creating Layer BatchNorm22
I0619 14:56:42.111574 17898 net.cpp:425] BatchNorm22 <- Convolution22
I0619 14:56:42.111585 17898 net.cpp:386] BatchNorm22 -> Convolution22 (in-place)
I0619 14:56:42.111862 17898 net.cpp:141] Setting up BatchNorm22
I0619 14:56:42.111872 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.111878 17898 net.cpp:156] Memory required for data: 991429120
I0619 14:56:42.111891 17898 layer_factory.hpp:77] Creating layer Scale22
I0619 14:56:42.111902 17898 net.cpp:91] Creating Layer Scale22
I0619 14:56:42.111908 17898 net.cpp:425] Scale22 <- Convolution22
I0619 14:56:42.111917 17898 net.cpp:386] Scale22 -> Convolution22 (in-place)
I0619 14:56:42.111963 17898 layer_factory.hpp:77] Creating layer Scale22
I0619 14:56:42.112129 17898 net.cpp:141] Setting up Scale22
I0619 14:56:42.112143 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.112149 17898 net.cpp:156] Memory required for data: 999817728
I0619 14:56:42.112159 17898 layer_factory.hpp:77] Creating layer ReLU22
I0619 14:56:42.112171 17898 net.cpp:91] Creating Layer ReLU22
I0619 14:56:42.112190 17898 net.cpp:425] ReLU22 <- Convolution22
I0619 14:56:42.112200 17898 net.cpp:386] ReLU22 -> Convolution22 (in-place)
I0619 14:56:42.112210 17898 net.cpp:141] Setting up ReLU22
I0619 14:56:42.112217 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.112223 17898 net.cpp:156] Memory required for data: 1008206336
I0619 14:56:42.112228 17898 layer_factory.hpp:77] Creating layer Convolution23
I0619 14:56:42.112244 17898 net.cpp:91] Creating Layer Convolution23
I0619 14:56:42.112251 17898 net.cpp:425] Convolution23 <- Convolution22
I0619 14:56:42.112262 17898 net.cpp:399] Convolution23 -> Convolution23
I0619 14:56:42.112715 17898 net.cpp:141] Setting up Convolution23
I0619 14:56:42.112728 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.112735 17898 net.cpp:156] Memory required for data: 1016594944
I0619 14:56:42.112745 17898 layer_factory.hpp:77] Creating layer BatchNorm23
I0619 14:56:42.112756 17898 net.cpp:91] Creating Layer BatchNorm23
I0619 14:56:42.112763 17898 net.cpp:425] BatchNorm23 <- Convolution23
I0619 14:56:42.112773 17898 net.cpp:386] BatchNorm23 -> Convolution23 (in-place)
I0619 14:56:42.113042 17898 net.cpp:141] Setting up BatchNorm23
I0619 14:56:42.113052 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.113059 17898 net.cpp:156] Memory required for data: 1024983552
I0619 14:56:42.113070 17898 layer_factory.hpp:77] Creating layer Scale23
I0619 14:56:42.113080 17898 net.cpp:91] Creating Layer Scale23
I0619 14:56:42.113088 17898 net.cpp:425] Scale23 <- Convolution23
I0619 14:56:42.113098 17898 net.cpp:386] Scale23 -> Convolution23 (in-place)
I0619 14:56:42.113149 17898 layer_factory.hpp:77] Creating layer Scale23
I0619 14:56:42.113309 17898 net.cpp:141] Setting up Scale23
I0619 14:56:42.113322 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.113328 17898 net.cpp:156] Memory required for data: 1033372160
I0619 14:56:42.113338 17898 layer_factory.hpp:77] Creating layer Eltwise11
I0619 14:56:42.113348 17898 net.cpp:91] Creating Layer Eltwise11
I0619 14:56:42.113353 17898 net.cpp:425] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0619 14:56:42.113361 17898 net.cpp:425] Eltwise11 <- Convolution23
I0619 14:56:42.113369 17898 net.cpp:399] Eltwise11 -> Eltwise11
I0619 14:56:42.113410 17898 net.cpp:141] Setting up Eltwise11
I0619 14:56:42.113420 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.113425 17898 net.cpp:156] Memory required for data: 1041760768
I0619 14:56:42.113430 17898 layer_factory.hpp:77] Creating layer ReLU23
I0619 14:56:42.113440 17898 net.cpp:91] Creating Layer ReLU23
I0619 14:56:42.113448 17898 net.cpp:425] ReLU23 <- Eltwise11
I0619 14:56:42.113456 17898 net.cpp:386] ReLU23 -> Eltwise11 (in-place)
I0619 14:56:42.113464 17898 net.cpp:141] Setting up ReLU23
I0619 14:56:42.113472 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.113478 17898 net.cpp:156] Memory required for data: 1050149376
I0619 14:56:42.113483 17898 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0619 14:56:42.113492 17898 net.cpp:91] Creating Layer Eltwise11_ReLU23_0_split
I0619 14:56:42.113497 17898 net.cpp:425] Eltwise11_ReLU23_0_split <- Eltwise11
I0619 14:56:42.113504 17898 net.cpp:399] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0619 14:56:42.113517 17898 net.cpp:399] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0619 14:56:42.113565 17898 net.cpp:141] Setting up Eltwise11_ReLU23_0_split
I0619 14:56:42.113574 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.113581 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.113586 17898 net.cpp:156] Memory required for data: 1066926592
I0619 14:56:42.113592 17898 layer_factory.hpp:77] Creating layer Convolution24
I0619 14:56:42.113607 17898 net.cpp:91] Creating Layer Convolution24
I0619 14:56:42.113613 17898 net.cpp:425] Convolution24 <- Eltwise11_ReLU23_0_split_0
I0619 14:56:42.113623 17898 net.cpp:399] Convolution24 -> Convolution24
I0619 14:56:42.114079 17898 net.cpp:141] Setting up Convolution24
I0619 14:56:42.114107 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.114114 17898 net.cpp:156] Memory required for data: 1075315200
I0619 14:56:42.114123 17898 layer_factory.hpp:77] Creating layer BatchNorm24
I0619 14:56:42.114136 17898 net.cpp:91] Creating Layer BatchNorm24
I0619 14:56:42.114145 17898 net.cpp:425] BatchNorm24 <- Convolution24
I0619 14:56:42.114153 17898 net.cpp:386] BatchNorm24 -> Convolution24 (in-place)
I0619 14:56:42.114455 17898 net.cpp:141] Setting up BatchNorm24
I0619 14:56:42.114469 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.114475 17898 net.cpp:156] Memory required for data: 1083703808
I0619 14:56:42.114486 17898 layer_factory.hpp:77] Creating layer Scale24
I0619 14:56:42.114496 17898 net.cpp:91] Creating Layer Scale24
I0619 14:56:42.114503 17898 net.cpp:425] Scale24 <- Convolution24
I0619 14:56:42.114518 17898 net.cpp:386] Scale24 -> Convolution24 (in-place)
I0619 14:56:42.114568 17898 layer_factory.hpp:77] Creating layer Scale24
I0619 14:56:42.114728 17898 net.cpp:141] Setting up Scale24
I0619 14:56:42.114738 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.114744 17898 net.cpp:156] Memory required for data: 1092092416
I0619 14:56:42.114754 17898 layer_factory.hpp:77] Creating layer ReLU24
I0619 14:56:42.114766 17898 net.cpp:91] Creating Layer ReLU24
I0619 14:56:42.114774 17898 net.cpp:425] ReLU24 <- Convolution24
I0619 14:56:42.114783 17898 net.cpp:386] ReLU24 -> Convolution24 (in-place)
I0619 14:56:42.114792 17898 net.cpp:141] Setting up ReLU24
I0619 14:56:42.114800 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.114805 17898 net.cpp:156] Memory required for data: 1100481024
I0619 14:56:42.114811 17898 layer_factory.hpp:77] Creating layer Convolution25
I0619 14:56:42.114826 17898 net.cpp:91] Creating Layer Convolution25
I0619 14:56:42.114832 17898 net.cpp:425] Convolution25 <- Convolution24
I0619 14:56:42.114845 17898 net.cpp:399] Convolution25 -> Convolution25
I0619 14:56:42.115293 17898 net.cpp:141] Setting up Convolution25
I0619 14:56:42.115309 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.115314 17898 net.cpp:156] Memory required for data: 1108869632
I0619 14:56:42.115324 17898 layer_factory.hpp:77] Creating layer BatchNorm25
I0619 14:56:42.115336 17898 net.cpp:91] Creating Layer BatchNorm25
I0619 14:56:42.115342 17898 net.cpp:425] BatchNorm25 <- Convolution25
I0619 14:56:42.115351 17898 net.cpp:386] BatchNorm25 -> Convolution25 (in-place)
I0619 14:56:42.115633 17898 net.cpp:141] Setting up BatchNorm25
I0619 14:56:42.115643 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.115648 17898 net.cpp:156] Memory required for data: 1117258240
I0619 14:56:42.115660 17898 layer_factory.hpp:77] Creating layer Scale25
I0619 14:56:42.115670 17898 net.cpp:91] Creating Layer Scale25
I0619 14:56:42.115676 17898 net.cpp:425] Scale25 <- Convolution25
I0619 14:56:42.115687 17898 net.cpp:386] Scale25 -> Convolution25 (in-place)
I0619 14:56:42.115734 17898 layer_factory.hpp:77] Creating layer Scale25
I0619 14:56:42.115890 17898 net.cpp:141] Setting up Scale25
I0619 14:56:42.115900 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.115906 17898 net.cpp:156] Memory required for data: 1125646848
I0619 14:56:42.115916 17898 layer_factory.hpp:77] Creating layer Eltwise12
I0619 14:56:42.115927 17898 net.cpp:91] Creating Layer Eltwise12
I0619 14:56:42.115933 17898 net.cpp:425] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0619 14:56:42.115942 17898 net.cpp:425] Eltwise12 <- Convolution25
I0619 14:56:42.115949 17898 net.cpp:399] Eltwise12 -> Eltwise12
I0619 14:56:42.115983 17898 net.cpp:141] Setting up Eltwise12
I0619 14:56:42.115993 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.115998 17898 net.cpp:156] Memory required for data: 1134035456
I0619 14:56:42.116003 17898 layer_factory.hpp:77] Creating layer ReLU25
I0619 14:56:42.116011 17898 net.cpp:91] Creating Layer ReLU25
I0619 14:56:42.116017 17898 net.cpp:425] ReLU25 <- Eltwise12
I0619 14:56:42.116031 17898 net.cpp:386] ReLU25 -> Eltwise12 (in-place)
I0619 14:56:42.116057 17898 net.cpp:141] Setting up ReLU25
I0619 14:56:42.116066 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.116071 17898 net.cpp:156] Memory required for data: 1142424064
I0619 14:56:42.116077 17898 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I0619 14:56:42.116086 17898 net.cpp:91] Creating Layer Eltwise12_ReLU25_0_split
I0619 14:56:42.116091 17898 net.cpp:425] Eltwise12_ReLU25_0_split <- Eltwise12
I0619 14:56:42.116099 17898 net.cpp:399] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I0619 14:56:42.116109 17898 net.cpp:399] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I0619 14:56:42.116173 17898 net.cpp:141] Setting up Eltwise12_ReLU25_0_split
I0619 14:56:42.116183 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.116190 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.116196 17898 net.cpp:156] Memory required for data: 1159201280
I0619 14:56:42.116202 17898 layer_factory.hpp:77] Creating layer Convolution26
I0619 14:56:42.116214 17898 net.cpp:91] Creating Layer Convolution26
I0619 14:56:42.116221 17898 net.cpp:425] Convolution26 <- Eltwise12_ReLU25_0_split_0
I0619 14:56:42.116230 17898 net.cpp:399] Convolution26 -> Convolution26
I0619 14:56:42.116696 17898 net.cpp:141] Setting up Convolution26
I0619 14:56:42.116708 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.116714 17898 net.cpp:156] Memory required for data: 1167589888
I0619 14:56:42.116724 17898 layer_factory.hpp:77] Creating layer BatchNorm26
I0619 14:56:42.116736 17898 net.cpp:91] Creating Layer BatchNorm26
I0619 14:56:42.116744 17898 net.cpp:425] BatchNorm26 <- Convolution26
I0619 14:56:42.116751 17898 net.cpp:386] BatchNorm26 -> Convolution26 (in-place)
I0619 14:56:42.117032 17898 net.cpp:141] Setting up BatchNorm26
I0619 14:56:42.117041 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.117048 17898 net.cpp:156] Memory required for data: 1175978496
I0619 14:56:42.117059 17898 layer_factory.hpp:77] Creating layer Scale26
I0619 14:56:42.117087 17898 net.cpp:91] Creating Layer Scale26
I0619 14:56:42.117094 17898 net.cpp:425] Scale26 <- Convolution26
I0619 14:56:42.117103 17898 net.cpp:386] Scale26 -> Convolution26 (in-place)
I0619 14:56:42.117156 17898 layer_factory.hpp:77] Creating layer Scale26
I0619 14:56:42.117319 17898 net.cpp:141] Setting up Scale26
I0619 14:56:42.117329 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.117336 17898 net.cpp:156] Memory required for data: 1184367104
I0619 14:56:42.117346 17898 layer_factory.hpp:77] Creating layer ReLU26
I0619 14:56:42.117354 17898 net.cpp:91] Creating Layer ReLU26
I0619 14:56:42.117360 17898 net.cpp:425] ReLU26 <- Convolution26
I0619 14:56:42.117367 17898 net.cpp:386] ReLU26 -> Convolution26 (in-place)
I0619 14:56:42.117377 17898 net.cpp:141] Setting up ReLU26
I0619 14:56:42.117384 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.117390 17898 net.cpp:156] Memory required for data: 1192755712
I0619 14:56:42.117395 17898 layer_factory.hpp:77] Creating layer Convolution27
I0619 14:56:42.117410 17898 net.cpp:91] Creating Layer Convolution27
I0619 14:56:42.117418 17898 net.cpp:425] Convolution27 <- Convolution26
I0619 14:56:42.117426 17898 net.cpp:399] Convolution27 -> Convolution27
I0619 14:56:42.117882 17898 net.cpp:141] Setting up Convolution27
I0619 14:56:42.117894 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.117899 17898 net.cpp:156] Memory required for data: 1201144320
I0619 14:56:42.117909 17898 layer_factory.hpp:77] Creating layer BatchNorm27
I0619 14:56:42.117921 17898 net.cpp:91] Creating Layer BatchNorm27
I0619 14:56:42.117928 17898 net.cpp:425] BatchNorm27 <- Convolution27
I0619 14:56:42.117938 17898 net.cpp:386] BatchNorm27 -> Convolution27 (in-place)
I0619 14:56:42.118221 17898 net.cpp:141] Setting up BatchNorm27
I0619 14:56:42.118232 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.118242 17898 net.cpp:156] Memory required for data: 1209532928
I0619 14:56:42.118268 17898 layer_factory.hpp:77] Creating layer Scale27
I0619 14:56:42.118280 17898 net.cpp:91] Creating Layer Scale27
I0619 14:56:42.118288 17898 net.cpp:425] Scale27 <- Convolution27
I0619 14:56:42.118296 17898 net.cpp:386] Scale27 -> Convolution27 (in-place)
I0619 14:56:42.118348 17898 layer_factory.hpp:77] Creating layer Scale27
I0619 14:56:42.118531 17898 net.cpp:141] Setting up Scale27
I0619 14:56:42.118542 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.118547 17898 net.cpp:156] Memory required for data: 1217921536
I0619 14:56:42.118556 17898 layer_factory.hpp:77] Creating layer Eltwise13
I0619 14:56:42.118571 17898 net.cpp:91] Creating Layer Eltwise13
I0619 14:56:42.118577 17898 net.cpp:425] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I0619 14:56:42.118589 17898 net.cpp:425] Eltwise13 <- Convolution27
I0619 14:56:42.118597 17898 net.cpp:399] Eltwise13 -> Eltwise13
I0619 14:56:42.118634 17898 net.cpp:141] Setting up Eltwise13
I0619 14:56:42.118643 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.118649 17898 net.cpp:156] Memory required for data: 1226310144
I0619 14:56:42.118654 17898 layer_factory.hpp:77] Creating layer ReLU27
I0619 14:56:42.118665 17898 net.cpp:91] Creating Layer ReLU27
I0619 14:56:42.118671 17898 net.cpp:425] ReLU27 <- Eltwise13
I0619 14:56:42.118680 17898 net.cpp:386] ReLU27 -> Eltwise13 (in-place)
I0619 14:56:42.118687 17898 net.cpp:141] Setting up ReLU27
I0619 14:56:42.118695 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.118700 17898 net.cpp:156] Memory required for data: 1234698752
I0619 14:56:42.118705 17898 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I0619 14:56:42.118712 17898 net.cpp:91] Creating Layer Eltwise13_ReLU27_0_split
I0619 14:56:42.118717 17898 net.cpp:425] Eltwise13_ReLU27_0_split <- Eltwise13
I0619 14:56:42.118727 17898 net.cpp:399] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I0619 14:56:42.118737 17898 net.cpp:399] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I0619 14:56:42.118783 17898 net.cpp:141] Setting up Eltwise13_ReLU27_0_split
I0619 14:56:42.118793 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.118799 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.118804 17898 net.cpp:156] Memory required for data: 1251475968
I0619 14:56:42.118809 17898 layer_factory.hpp:77] Creating layer Convolution28
I0619 14:56:42.118824 17898 net.cpp:91] Creating Layer Convolution28
I0619 14:56:42.118830 17898 net.cpp:425] Convolution28 <- Eltwise13_ReLU27_0_split_0
I0619 14:56:42.118839 17898 net.cpp:399] Convolution28 -> Convolution28
I0619 14:56:42.119282 17898 net.cpp:141] Setting up Convolution28
I0619 14:56:42.119293 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.119298 17898 net.cpp:156] Memory required for data: 1259864576
I0619 14:56:42.119308 17898 layer_factory.hpp:77] Creating layer BatchNorm28
I0619 14:56:42.119318 17898 net.cpp:91] Creating Layer BatchNorm28
I0619 14:56:42.119323 17898 net.cpp:425] BatchNorm28 <- Convolution28
I0619 14:56:42.119333 17898 net.cpp:386] BatchNorm28 -> Convolution28 (in-place)
I0619 14:56:42.119595 17898 net.cpp:141] Setting up BatchNorm28
I0619 14:56:42.119604 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.119609 17898 net.cpp:156] Memory required for data: 1268253184
I0619 14:56:42.119621 17898 layer_factory.hpp:77] Creating layer Scale28
I0619 14:56:42.119633 17898 net.cpp:91] Creating Layer Scale28
I0619 14:56:42.119639 17898 net.cpp:425] Scale28 <- Convolution28
I0619 14:56:42.119647 17898 net.cpp:386] Scale28 -> Convolution28 (in-place)
I0619 14:56:42.119698 17898 layer_factory.hpp:77] Creating layer Scale28
I0619 14:56:42.119849 17898 net.cpp:141] Setting up Scale28
I0619 14:56:42.119859 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.119864 17898 net.cpp:156] Memory required for data: 1276641792
I0619 14:56:42.119874 17898 layer_factory.hpp:77] Creating layer ReLU28
I0619 14:56:42.119884 17898 net.cpp:91] Creating Layer ReLU28
I0619 14:56:42.119905 17898 net.cpp:425] ReLU28 <- Convolution28
I0619 14:56:42.119916 17898 net.cpp:386] ReLU28 -> Convolution28 (in-place)
I0619 14:56:42.119926 17898 net.cpp:141] Setting up ReLU28
I0619 14:56:42.119933 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.119938 17898 net.cpp:156] Memory required for data: 1285030400
I0619 14:56:42.119943 17898 layer_factory.hpp:77] Creating layer Convolution29
I0619 14:56:42.119957 17898 net.cpp:91] Creating Layer Convolution29
I0619 14:56:42.119963 17898 net.cpp:425] Convolution29 <- Convolution28
I0619 14:56:42.119972 17898 net.cpp:399] Convolution29 -> Convolution29
I0619 14:56:42.120409 17898 net.cpp:141] Setting up Convolution29
I0619 14:56:42.120419 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.120425 17898 net.cpp:156] Memory required for data: 1293419008
I0619 14:56:42.120434 17898 layer_factory.hpp:77] Creating layer BatchNorm29
I0619 14:56:42.120455 17898 net.cpp:91] Creating Layer BatchNorm29
I0619 14:56:42.120460 17898 net.cpp:425] BatchNorm29 <- Convolution29
I0619 14:56:42.120471 17898 net.cpp:386] BatchNorm29 -> Convolution29 (in-place)
I0619 14:56:42.120731 17898 net.cpp:141] Setting up BatchNorm29
I0619 14:56:42.120741 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.120746 17898 net.cpp:156] Memory required for data: 1301807616
I0619 14:56:42.120764 17898 layer_factory.hpp:77] Creating layer Scale29
I0619 14:56:42.120785 17898 net.cpp:91] Creating Layer Scale29
I0619 14:56:42.120791 17898 net.cpp:425] Scale29 <- Convolution29
I0619 14:56:42.120800 17898 net.cpp:386] Scale29 -> Convolution29 (in-place)
I0619 14:56:42.120846 17898 layer_factory.hpp:77] Creating layer Scale29
I0619 14:56:42.121001 17898 net.cpp:141] Setting up Scale29
I0619 14:56:42.121011 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.121016 17898 net.cpp:156] Memory required for data: 1310196224
I0619 14:56:42.121026 17898 layer_factory.hpp:77] Creating layer Eltwise14
I0619 14:56:42.121033 17898 net.cpp:91] Creating Layer Eltwise14
I0619 14:56:42.121040 17898 net.cpp:425] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I0619 14:56:42.121047 17898 net.cpp:425] Eltwise14 <- Convolution29
I0619 14:56:42.121057 17898 net.cpp:399] Eltwise14 -> Eltwise14
I0619 14:56:42.121088 17898 net.cpp:141] Setting up Eltwise14
I0619 14:56:42.121101 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.121106 17898 net.cpp:156] Memory required for data: 1318584832
I0619 14:56:42.121111 17898 layer_factory.hpp:77] Creating layer ReLU29
I0619 14:56:42.121119 17898 net.cpp:91] Creating Layer ReLU29
I0619 14:56:42.121125 17898 net.cpp:425] ReLU29 <- Eltwise14
I0619 14:56:42.121132 17898 net.cpp:386] ReLU29 -> Eltwise14 (in-place)
I0619 14:56:42.121141 17898 net.cpp:141] Setting up ReLU29
I0619 14:56:42.121148 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.121153 17898 net.cpp:156] Memory required for data: 1326973440
I0619 14:56:42.121158 17898 layer_factory.hpp:77] Creating layer Eltwise14_ReLU29_0_split
I0619 14:56:42.121166 17898 net.cpp:91] Creating Layer Eltwise14_ReLU29_0_split
I0619 14:56:42.121171 17898 net.cpp:425] Eltwise14_ReLU29_0_split <- Eltwise14
I0619 14:56:42.121188 17898 net.cpp:399] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_0
I0619 14:56:42.121198 17898 net.cpp:399] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_1
I0619 14:56:42.121244 17898 net.cpp:141] Setting up Eltwise14_ReLU29_0_split
I0619 14:56:42.121253 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.121259 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.121264 17898 net.cpp:156] Memory required for data: 1343750656
I0619 14:56:42.121269 17898 layer_factory.hpp:77] Creating layer Convolution30
I0619 14:56:42.121284 17898 net.cpp:91] Creating Layer Convolution30
I0619 14:56:42.121290 17898 net.cpp:425] Convolution30 <- Eltwise14_ReLU29_0_split_0
I0619 14:56:42.121299 17898 net.cpp:399] Convolution30 -> Convolution30
I0619 14:56:42.121737 17898 net.cpp:141] Setting up Convolution30
I0619 14:56:42.121763 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.121769 17898 net.cpp:156] Memory required for data: 1352139264
I0619 14:56:42.121779 17898 layer_factory.hpp:77] Creating layer BatchNorm30
I0619 14:56:42.121791 17898 net.cpp:91] Creating Layer BatchNorm30
I0619 14:56:42.121798 17898 net.cpp:425] BatchNorm30 <- Convolution30
I0619 14:56:42.121805 17898 net.cpp:386] BatchNorm30 -> Convolution30 (in-place)
I0619 14:56:42.122071 17898 net.cpp:141] Setting up BatchNorm30
I0619 14:56:42.122081 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.122087 17898 net.cpp:156] Memory required for data: 1360527872
I0619 14:56:42.122097 17898 layer_factory.hpp:77] Creating layer Scale30
I0619 14:56:42.122108 17898 net.cpp:91] Creating Layer Scale30
I0619 14:56:42.122114 17898 net.cpp:425] Scale30 <- Convolution30
I0619 14:56:42.122123 17898 net.cpp:386] Scale30 -> Convolution30 (in-place)
I0619 14:56:42.122174 17898 layer_factory.hpp:77] Creating layer Scale30
I0619 14:56:42.122334 17898 net.cpp:141] Setting up Scale30
I0619 14:56:42.122344 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.122349 17898 net.cpp:156] Memory required for data: 1368916480
I0619 14:56:42.122372 17898 layer_factory.hpp:77] Creating layer ReLU30
I0619 14:56:42.122381 17898 net.cpp:91] Creating Layer ReLU30
I0619 14:56:42.122386 17898 net.cpp:425] ReLU30 <- Convolution30
I0619 14:56:42.122400 17898 net.cpp:386] ReLU30 -> Convolution30 (in-place)
I0619 14:56:42.122411 17898 net.cpp:141] Setting up ReLU30
I0619 14:56:42.122417 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.122422 17898 net.cpp:156] Memory required for data: 1377305088
I0619 14:56:42.122427 17898 layer_factory.hpp:77] Creating layer Convolution31
I0619 14:56:42.122442 17898 net.cpp:91] Creating Layer Convolution31
I0619 14:56:42.122447 17898 net.cpp:425] Convolution31 <- Convolution30
I0619 14:56:42.122457 17898 net.cpp:399] Convolution31 -> Convolution31
I0619 14:56:42.122887 17898 net.cpp:141] Setting up Convolution31
I0619 14:56:42.122900 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.122905 17898 net.cpp:156] Memory required for data: 1385693696
I0619 14:56:42.122915 17898 layer_factory.hpp:77] Creating layer BatchNorm31
I0619 14:56:42.122925 17898 net.cpp:91] Creating Layer BatchNorm31
I0619 14:56:42.122931 17898 net.cpp:425] BatchNorm31 <- Convolution31
I0619 14:56:42.122948 17898 net.cpp:386] BatchNorm31 -> Convolution31 (in-place)
I0619 14:56:42.123211 17898 net.cpp:141] Setting up BatchNorm31
I0619 14:56:42.123221 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.123226 17898 net.cpp:156] Memory required for data: 1394082304
I0619 14:56:42.123239 17898 layer_factory.hpp:77] Creating layer Scale31
I0619 14:56:42.123250 17898 net.cpp:91] Creating Layer Scale31
I0619 14:56:42.123255 17898 net.cpp:425] Scale31 <- Convolution31
I0619 14:56:42.123268 17898 net.cpp:386] Scale31 -> Convolution31 (in-place)
I0619 14:56:42.123316 17898 layer_factory.hpp:77] Creating layer Scale31
I0619 14:56:42.123469 17898 net.cpp:141] Setting up Scale31
I0619 14:56:42.123479 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.123484 17898 net.cpp:156] Memory required for data: 1402470912
I0619 14:56:42.123493 17898 layer_factory.hpp:77] Creating layer Eltwise15
I0619 14:56:42.123502 17898 net.cpp:91] Creating Layer Eltwise15
I0619 14:56:42.123507 17898 net.cpp:425] Eltwise15 <- Eltwise14_ReLU29_0_split_1
I0619 14:56:42.123514 17898 net.cpp:425] Eltwise15 <- Convolution31
I0619 14:56:42.123525 17898 net.cpp:399] Eltwise15 -> Eltwise15
I0619 14:56:42.123556 17898 net.cpp:141] Setting up Eltwise15
I0619 14:56:42.123567 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.123572 17898 net.cpp:156] Memory required for data: 1410859520
I0619 14:56:42.123577 17898 layer_factory.hpp:77] Creating layer ReLU31
I0619 14:56:42.123585 17898 net.cpp:91] Creating Layer ReLU31
I0619 14:56:42.123595 17898 net.cpp:425] ReLU31 <- Eltwise15
I0619 14:56:42.123617 17898 net.cpp:386] ReLU31 -> Eltwise15 (in-place)
I0619 14:56:42.123626 17898 net.cpp:141] Setting up ReLU31
I0619 14:56:42.123634 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.123639 17898 net.cpp:156] Memory required for data: 1419248128
I0619 14:56:42.123644 17898 layer_factory.hpp:77] Creating layer Eltwise15_ReLU31_0_split
I0619 14:56:42.123652 17898 net.cpp:91] Creating Layer Eltwise15_ReLU31_0_split
I0619 14:56:42.123657 17898 net.cpp:425] Eltwise15_ReLU31_0_split <- Eltwise15
I0619 14:56:42.123667 17898 net.cpp:399] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_0
I0619 14:56:42.123677 17898 net.cpp:399] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_1
I0619 14:56:42.123725 17898 net.cpp:141] Setting up Eltwise15_ReLU31_0_split
I0619 14:56:42.123738 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.123744 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.123749 17898 net.cpp:156] Memory required for data: 1436025344
I0619 14:56:42.123754 17898 layer_factory.hpp:77] Creating layer Convolution32
I0619 14:56:42.123766 17898 net.cpp:91] Creating Layer Convolution32
I0619 14:56:42.123772 17898 net.cpp:425] Convolution32 <- Eltwise15_ReLU31_0_split_0
I0619 14:56:42.123781 17898 net.cpp:399] Convolution32 -> Convolution32
I0619 14:56:42.124209 17898 net.cpp:141] Setting up Convolution32
I0619 14:56:42.124220 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.124225 17898 net.cpp:156] Memory required for data: 1444413952
I0619 14:56:42.124235 17898 layer_factory.hpp:77] Creating layer BatchNorm32
I0619 14:56:42.124248 17898 net.cpp:91] Creating Layer BatchNorm32
I0619 14:56:42.124254 17898 net.cpp:425] BatchNorm32 <- Convolution32
I0619 14:56:42.124263 17898 net.cpp:386] BatchNorm32 -> Convolution32 (in-place)
I0619 14:56:42.124529 17898 net.cpp:141] Setting up BatchNorm32
I0619 14:56:42.124539 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.124544 17898 net.cpp:156] Memory required for data: 1452802560
I0619 14:56:42.124555 17898 layer_factory.hpp:77] Creating layer Scale32
I0619 14:56:42.124567 17898 net.cpp:91] Creating Layer Scale32
I0619 14:56:42.124573 17898 net.cpp:425] Scale32 <- Convolution32
I0619 14:56:42.124580 17898 net.cpp:386] Scale32 -> Convolution32 (in-place)
I0619 14:56:42.124627 17898 layer_factory.hpp:77] Creating layer Scale32
I0619 14:56:42.124781 17898 net.cpp:141] Setting up Scale32
I0619 14:56:42.124793 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.124796 17898 net.cpp:156] Memory required for data: 1461191168
I0619 14:56:42.124806 17898 layer_factory.hpp:77] Creating layer ReLU32
I0619 14:56:42.124814 17898 net.cpp:91] Creating Layer ReLU32
I0619 14:56:42.124819 17898 net.cpp:425] ReLU32 <- Convolution32
I0619 14:56:42.124830 17898 net.cpp:386] ReLU32 -> Convolution32 (in-place)
I0619 14:56:42.124840 17898 net.cpp:141] Setting up ReLU32
I0619 14:56:42.124847 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.124852 17898 net.cpp:156] Memory required for data: 1469579776
I0619 14:56:42.124857 17898 layer_factory.hpp:77] Creating layer Convolution33
I0619 14:56:42.124871 17898 net.cpp:91] Creating Layer Convolution33
I0619 14:56:42.124877 17898 net.cpp:425] Convolution33 <- Convolution32
I0619 14:56:42.124886 17898 net.cpp:399] Convolution33 -> Convolution33
I0619 14:56:42.125309 17898 net.cpp:141] Setting up Convolution33
I0619 14:56:42.125320 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.125325 17898 net.cpp:156] Memory required for data: 1477968384
I0619 14:56:42.125335 17898 layer_factory.hpp:77] Creating layer BatchNorm33
I0619 14:56:42.125344 17898 net.cpp:91] Creating Layer BatchNorm33
I0619 14:56:42.125352 17898 net.cpp:425] BatchNorm33 <- Convolution33
I0619 14:56:42.125360 17898 net.cpp:386] BatchNorm33 -> Convolution33 (in-place)
I0619 14:56:42.125617 17898 net.cpp:141] Setting up BatchNorm33
I0619 14:56:42.125625 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.125634 17898 net.cpp:156] Memory required for data: 1486356992
I0619 14:56:42.125660 17898 layer_factory.hpp:77] Creating layer Scale33
I0619 14:56:42.125674 17898 net.cpp:91] Creating Layer Scale33
I0619 14:56:42.125679 17898 net.cpp:425] Scale33 <- Convolution33
I0619 14:56:42.125687 17898 net.cpp:386] Scale33 -> Convolution33 (in-place)
I0619 14:56:42.125744 17898 layer_factory.hpp:77] Creating layer Scale33
I0619 14:56:42.125902 17898 net.cpp:141] Setting up Scale33
I0619 14:56:42.125912 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.125918 17898 net.cpp:156] Memory required for data: 1494745600
I0619 14:56:42.125927 17898 layer_factory.hpp:77] Creating layer Eltwise16
I0619 14:56:42.125936 17898 net.cpp:91] Creating Layer Eltwise16
I0619 14:56:42.125942 17898 net.cpp:425] Eltwise16 <- Eltwise15_ReLU31_0_split_1
I0619 14:56:42.125948 17898 net.cpp:425] Eltwise16 <- Convolution33
I0619 14:56:42.125959 17898 net.cpp:399] Eltwise16 -> Eltwise16
I0619 14:56:42.125993 17898 net.cpp:141] Setting up Eltwise16
I0619 14:56:42.126003 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.126008 17898 net.cpp:156] Memory required for data: 1503134208
I0619 14:56:42.126013 17898 layer_factory.hpp:77] Creating layer ReLU33
I0619 14:56:42.126027 17898 net.cpp:91] Creating Layer ReLU33
I0619 14:56:42.126032 17898 net.cpp:425] ReLU33 <- Eltwise16
I0619 14:56:42.126039 17898 net.cpp:386] ReLU33 -> Eltwise16 (in-place)
I0619 14:56:42.126049 17898 net.cpp:141] Setting up ReLU33
I0619 14:56:42.126055 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.126060 17898 net.cpp:156] Memory required for data: 1511522816
I0619 14:56:42.126065 17898 layer_factory.hpp:77] Creating layer Eltwise16_ReLU33_0_split
I0619 14:56:42.126073 17898 net.cpp:91] Creating Layer Eltwise16_ReLU33_0_split
I0619 14:56:42.126078 17898 net.cpp:425] Eltwise16_ReLU33_0_split <- Eltwise16
I0619 14:56:42.126088 17898 net.cpp:399] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_0
I0619 14:56:42.126098 17898 net.cpp:399] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_1
I0619 14:56:42.126145 17898 net.cpp:141] Setting up Eltwise16_ReLU33_0_split
I0619 14:56:42.126154 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.126162 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.126166 17898 net.cpp:156] Memory required for data: 1528300032
I0619 14:56:42.126171 17898 layer_factory.hpp:77] Creating layer Convolution34
I0619 14:56:42.126183 17898 net.cpp:91] Creating Layer Convolution34
I0619 14:56:42.126189 17898 net.cpp:425] Convolution34 <- Eltwise16_ReLU33_0_split_0
I0619 14:56:42.126199 17898 net.cpp:399] Convolution34 -> Convolution34
I0619 14:56:42.126641 17898 net.cpp:141] Setting up Convolution34
I0619 14:56:42.126660 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.126665 17898 net.cpp:156] Memory required for data: 1536688640
I0619 14:56:42.126675 17898 layer_factory.hpp:77] Creating layer BatchNorm34
I0619 14:56:42.126687 17898 net.cpp:91] Creating Layer BatchNorm34
I0619 14:56:42.126693 17898 net.cpp:425] BatchNorm34 <- Convolution34
I0619 14:56:42.126700 17898 net.cpp:386] BatchNorm34 -> Convolution34 (in-place)
I0619 14:56:42.126962 17898 net.cpp:141] Setting up BatchNorm34
I0619 14:56:42.126972 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.126977 17898 net.cpp:156] Memory required for data: 1545077248
I0619 14:56:42.126989 17898 layer_factory.hpp:77] Creating layer Scale34
I0619 14:56:42.127001 17898 net.cpp:91] Creating Layer Scale34
I0619 14:56:42.127007 17898 net.cpp:425] Scale34 <- Convolution34
I0619 14:56:42.127014 17898 net.cpp:386] Scale34 -> Convolution34 (in-place)
I0619 14:56:42.127061 17898 layer_factory.hpp:77] Creating layer Scale34
I0619 14:56:42.127225 17898 net.cpp:141] Setting up Scale34
I0619 14:56:42.127235 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.127240 17898 net.cpp:156] Memory required for data: 1553465856
I0619 14:56:42.127250 17898 layer_factory.hpp:77] Creating layer ReLU34
I0619 14:56:42.127262 17898 net.cpp:91] Creating Layer ReLU34
I0619 14:56:42.127281 17898 net.cpp:425] ReLU34 <- Convolution34
I0619 14:56:42.127293 17898 net.cpp:386] ReLU34 -> Convolution34 (in-place)
I0619 14:56:42.127302 17898 net.cpp:141] Setting up ReLU34
I0619 14:56:42.127310 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.127315 17898 net.cpp:156] Memory required for data: 1561854464
I0619 14:56:42.127322 17898 layer_factory.hpp:77] Creating layer Convolution35
I0619 14:56:42.127336 17898 net.cpp:91] Creating Layer Convolution35
I0619 14:56:42.127342 17898 net.cpp:425] Convolution35 <- Convolution34
I0619 14:56:42.127351 17898 net.cpp:399] Convolution35 -> Convolution35
I0619 14:56:42.127790 17898 net.cpp:141] Setting up Convolution35
I0619 14:56:42.127801 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.127807 17898 net.cpp:156] Memory required for data: 1570243072
I0619 14:56:42.127816 17898 layer_factory.hpp:77] Creating layer BatchNorm35
I0619 14:56:42.127828 17898 net.cpp:91] Creating Layer BatchNorm35
I0619 14:56:42.127833 17898 net.cpp:425] BatchNorm35 <- Convolution35
I0619 14:56:42.127841 17898 net.cpp:386] BatchNorm35 -> Convolution35 (in-place)
I0619 14:56:42.128114 17898 net.cpp:141] Setting up BatchNorm35
I0619 14:56:42.128126 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.128131 17898 net.cpp:156] Memory required for data: 1578631680
I0619 14:56:42.128142 17898 layer_factory.hpp:77] Creating layer Scale35
I0619 14:56:42.128154 17898 net.cpp:91] Creating Layer Scale35
I0619 14:56:42.128160 17898 net.cpp:425] Scale35 <- Convolution35
I0619 14:56:42.128168 17898 net.cpp:386] Scale35 -> Convolution35 (in-place)
I0619 14:56:42.128217 17898 layer_factory.hpp:77] Creating layer Scale35
I0619 14:56:42.128373 17898 net.cpp:141] Setting up Scale35
I0619 14:56:42.128383 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.128388 17898 net.cpp:156] Memory required for data: 1587020288
I0619 14:56:42.128397 17898 layer_factory.hpp:77] Creating layer Eltwise17
I0619 14:56:42.128406 17898 net.cpp:91] Creating Layer Eltwise17
I0619 14:56:42.128414 17898 net.cpp:425] Eltwise17 <- Eltwise16_ReLU33_0_split_1
I0619 14:56:42.128422 17898 net.cpp:425] Eltwise17 <- Convolution35
I0619 14:56:42.128432 17898 net.cpp:399] Eltwise17 -> Eltwise17
I0619 14:56:42.128465 17898 net.cpp:141] Setting up Eltwise17
I0619 14:56:42.128474 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.128479 17898 net.cpp:156] Memory required for data: 1595408896
I0619 14:56:42.128484 17898 layer_factory.hpp:77] Creating layer ReLU35
I0619 14:56:42.128492 17898 net.cpp:91] Creating Layer ReLU35
I0619 14:56:42.128499 17898 net.cpp:425] ReLU35 <- Eltwise17
I0619 14:56:42.128505 17898 net.cpp:386] ReLU35 -> Eltwise17 (in-place)
I0619 14:56:42.128514 17898 net.cpp:141] Setting up ReLU35
I0619 14:56:42.128521 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.128526 17898 net.cpp:156] Memory required for data: 1603797504
I0619 14:56:42.128531 17898 layer_factory.hpp:77] Creating layer Eltwise17_ReLU35_0_split
I0619 14:56:42.128541 17898 net.cpp:91] Creating Layer Eltwise17_ReLU35_0_split
I0619 14:56:42.128547 17898 net.cpp:425] Eltwise17_ReLU35_0_split <- Eltwise17
I0619 14:56:42.128554 17898 net.cpp:399] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_0
I0619 14:56:42.128563 17898 net.cpp:399] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_1
I0619 14:56:42.128613 17898 net.cpp:141] Setting up Eltwise17_ReLU35_0_split
I0619 14:56:42.128623 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.128629 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.128634 17898 net.cpp:156] Memory required for data: 1620574720
I0619 14:56:42.128639 17898 layer_factory.hpp:77] Creating layer Convolution36
I0619 14:56:42.128650 17898 net.cpp:91] Creating Layer Convolution36
I0619 14:56:42.128657 17898 net.cpp:425] Convolution36 <- Eltwise17_ReLU35_0_split_0
I0619 14:56:42.128666 17898 net.cpp:399] Convolution36 -> Convolution36
I0619 14:56:42.129118 17898 net.cpp:141] Setting up Convolution36
I0619 14:56:42.129130 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.129137 17898 net.cpp:156] Memory required for data: 1628963328
I0619 14:56:42.129147 17898 layer_factory.hpp:77] Creating layer BatchNorm36
I0619 14:56:42.129158 17898 net.cpp:91] Creating Layer BatchNorm36
I0619 14:56:42.129163 17898 net.cpp:425] BatchNorm36 <- Convolution36
I0619 14:56:42.129171 17898 net.cpp:386] BatchNorm36 -> Convolution36 (in-place)
I0619 14:56:42.129442 17898 net.cpp:141] Setting up BatchNorm36
I0619 14:56:42.129452 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.129457 17898 net.cpp:156] Memory required for data: 1637351936
I0619 14:56:42.129469 17898 layer_factory.hpp:77] Creating layer Scale36
I0619 14:56:42.129478 17898 net.cpp:91] Creating Layer Scale36
I0619 14:56:42.129484 17898 net.cpp:425] Scale36 <- Convolution36
I0619 14:56:42.129492 17898 net.cpp:386] Scale36 -> Convolution36 (in-place)
I0619 14:56:42.129540 17898 layer_factory.hpp:77] Creating layer Scale36
I0619 14:56:42.129696 17898 net.cpp:141] Setting up Scale36
I0619 14:56:42.129706 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.129711 17898 net.cpp:156] Memory required for data: 1645740544
I0619 14:56:42.129720 17898 layer_factory.hpp:77] Creating layer ReLU36
I0619 14:56:42.129729 17898 net.cpp:91] Creating Layer ReLU36
I0619 14:56:42.129734 17898 net.cpp:425] ReLU36 <- Convolution36
I0619 14:56:42.129745 17898 net.cpp:386] ReLU36 -> Convolution36 (in-place)
I0619 14:56:42.129753 17898 net.cpp:141] Setting up ReLU36
I0619 14:56:42.129760 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.129765 17898 net.cpp:156] Memory required for data: 1654129152
I0619 14:56:42.129771 17898 layer_factory.hpp:77] Creating layer Convolution37
I0619 14:56:42.129786 17898 net.cpp:91] Creating Layer Convolution37
I0619 14:56:42.129791 17898 net.cpp:425] Convolution37 <- Convolution36
I0619 14:56:42.129799 17898 net.cpp:399] Convolution37 -> Convolution37
I0619 14:56:42.130234 17898 net.cpp:141] Setting up Convolution37
I0619 14:56:42.130244 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.130249 17898 net.cpp:156] Memory required for data: 1662517760
I0619 14:56:42.130259 17898 layer_factory.hpp:77] Creating layer BatchNorm37
I0619 14:56:42.130270 17898 net.cpp:91] Creating Layer BatchNorm37
I0619 14:56:42.130275 17898 net.cpp:425] BatchNorm37 <- Convolution37
I0619 14:56:42.130283 17898 net.cpp:386] BatchNorm37 -> Convolution37 (in-place)
I0619 14:56:42.130573 17898 net.cpp:141] Setting up BatchNorm37
I0619 14:56:42.130584 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.130589 17898 net.cpp:156] Memory required for data: 1670906368
I0619 14:56:42.130645 17898 layer_factory.hpp:77] Creating layer Scale37
I0619 14:56:42.130657 17898 net.cpp:91] Creating Layer Scale37
I0619 14:56:42.130663 17898 net.cpp:425] Scale37 <- Convolution37
I0619 14:56:42.130671 17898 net.cpp:386] Scale37 -> Convolution37 (in-place)
I0619 14:56:42.130720 17898 layer_factory.hpp:77] Creating layer Scale37
I0619 14:56:42.130872 17898 net.cpp:141] Setting up Scale37
I0619 14:56:42.130883 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.130888 17898 net.cpp:156] Memory required for data: 1679294976
I0619 14:56:42.130897 17898 layer_factory.hpp:77] Creating layer Eltwise18
I0619 14:56:42.130913 17898 net.cpp:91] Creating Layer Eltwise18
I0619 14:56:42.130918 17898 net.cpp:425] Eltwise18 <- Eltwise17_ReLU35_0_split_1
I0619 14:56:42.130925 17898 net.cpp:425] Eltwise18 <- Convolution37
I0619 14:56:42.130934 17898 net.cpp:399] Eltwise18 -> Eltwise18
I0619 14:56:42.130966 17898 net.cpp:141] Setting up Eltwise18
I0619 14:56:42.130975 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.130980 17898 net.cpp:156] Memory required for data: 1687683584
I0619 14:56:42.130985 17898 layer_factory.hpp:77] Creating layer ReLU37
I0619 14:56:42.130992 17898 net.cpp:91] Creating Layer ReLU37
I0619 14:56:42.131002 17898 net.cpp:425] ReLU37 <- Eltwise18
I0619 14:56:42.131029 17898 net.cpp:386] ReLU37 -> Eltwise18 (in-place)
I0619 14:56:42.131039 17898 net.cpp:141] Setting up ReLU37
I0619 14:56:42.131047 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.131052 17898 net.cpp:156] Memory required for data: 1696072192
I0619 14:56:42.131057 17898 layer_factory.hpp:77] Creating layer Eltwise18_ReLU37_0_split
I0619 14:56:42.131064 17898 net.cpp:91] Creating Layer Eltwise18_ReLU37_0_split
I0619 14:56:42.131068 17898 net.cpp:425] Eltwise18_ReLU37_0_split <- Eltwise18
I0619 14:56:42.131077 17898 net.cpp:399] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_0
I0619 14:56:42.131085 17898 net.cpp:399] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_1
I0619 14:56:42.131134 17898 net.cpp:141] Setting up Eltwise18_ReLU37_0_split
I0619 14:56:42.131144 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.131150 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.131155 17898 net.cpp:156] Memory required for data: 1712849408
I0619 14:56:42.131160 17898 layer_factory.hpp:77] Creating layer Pooling1
I0619 14:56:42.131171 17898 net.cpp:91] Creating Layer Pooling1
I0619 14:56:42.131177 17898 net.cpp:425] Pooling1 <- Eltwise18_ReLU37_0_split_0
I0619 14:56:42.131187 17898 net.cpp:399] Pooling1 -> Pooling1
I0619 14:56:42.131237 17898 net.cpp:141] Setting up Pooling1
I0619 14:56:42.131245 17898 net.cpp:148] Top shape: 128 16 16 16 (524288)
I0619 14:56:42.131249 17898 net.cpp:156] Memory required for data: 1714946560
I0619 14:56:42.131254 17898 layer_factory.hpp:77] Creating layer Input1
I0619 14:56:42.131264 17898 net.cpp:91] Creating Layer Input1
I0619 14:56:42.131274 17898 net.cpp:399] Input1 -> Input1
I0619 14:56:42.131311 17898 net.cpp:141] Setting up Input1
I0619 14:56:42.131322 17898 net.cpp:148] Top shape: 128 16 16 16 (524288)
I0619 14:56:42.131327 17898 net.cpp:156] Memory required for data: 1717043712
I0619 14:56:42.131332 17898 layer_factory.hpp:77] Creating layer Concat1
I0619 14:56:42.131341 17898 net.cpp:91] Creating Layer Concat1
I0619 14:56:42.131346 17898 net.cpp:425] Concat1 <- Pooling1
I0619 14:56:42.131353 17898 net.cpp:425] Concat1 <- Input1
I0619 14:56:42.131361 17898 net.cpp:399] Concat1 -> Concat1
I0619 14:56:42.131397 17898 net.cpp:141] Setting up Concat1
I0619 14:56:42.131405 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.131410 17898 net.cpp:156] Memory required for data: 1721238016
I0619 14:56:42.131415 17898 layer_factory.hpp:77] Creating layer Convolution38
I0619 14:56:42.131429 17898 net.cpp:91] Creating Layer Convolution38
I0619 14:56:42.131435 17898 net.cpp:425] Convolution38 <- Eltwise18_ReLU37_0_split_1
I0619 14:56:42.131444 17898 net.cpp:399] Convolution38 -> Convolution38
I0619 14:56:42.132784 17898 net.cpp:141] Setting up Convolution38
I0619 14:56:42.132809 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.132815 17898 net.cpp:156] Memory required for data: 1725432320
I0619 14:56:42.132825 17898 layer_factory.hpp:77] Creating layer BatchNorm38
I0619 14:56:42.132838 17898 net.cpp:91] Creating Layer BatchNorm38
I0619 14:56:42.132844 17898 net.cpp:425] BatchNorm38 <- Convolution38
I0619 14:56:42.132855 17898 net.cpp:386] BatchNorm38 -> Convolution38 (in-place)
I0619 14:56:42.133111 17898 net.cpp:141] Setting up BatchNorm38
I0619 14:56:42.133128 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.133133 17898 net.cpp:156] Memory required for data: 1729626624
I0619 14:56:42.133144 17898 layer_factory.hpp:77] Creating layer Scale38
I0619 14:56:42.133153 17898 net.cpp:91] Creating Layer Scale38
I0619 14:56:42.133159 17898 net.cpp:425] Scale38 <- Convolution38
I0619 14:56:42.133172 17898 net.cpp:386] Scale38 -> Convolution38 (in-place)
I0619 14:56:42.133216 17898 layer_factory.hpp:77] Creating layer Scale38
I0619 14:56:42.133365 17898 net.cpp:141] Setting up Scale38
I0619 14:56:42.133378 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.133383 17898 net.cpp:156] Memory required for data: 1733820928
I0619 14:56:42.133395 17898 layer_factory.hpp:77] Creating layer ReLU38
I0619 14:56:42.133419 17898 net.cpp:91] Creating Layer ReLU38
I0619 14:56:42.133425 17898 net.cpp:425] ReLU38 <- Convolution38
I0619 14:56:42.133433 17898 net.cpp:386] ReLU38 -> Convolution38 (in-place)
I0619 14:56:42.133442 17898 net.cpp:141] Setting up ReLU38
I0619 14:56:42.133450 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.133455 17898 net.cpp:156] Memory required for data: 1738015232
I0619 14:56:42.133460 17898 layer_factory.hpp:77] Creating layer Convolution39
I0619 14:56:42.133474 17898 net.cpp:91] Creating Layer Convolution39
I0619 14:56:42.133481 17898 net.cpp:425] Convolution39 <- Convolution38
I0619 14:56:42.133491 17898 net.cpp:399] Convolution39 -> Convolution39
I0619 14:56:42.134238 17898 net.cpp:141] Setting up Convolution39
I0619 14:56:42.134250 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.134255 17898 net.cpp:156] Memory required for data: 1742209536
I0619 14:56:42.134264 17898 layer_factory.hpp:77] Creating layer BatchNorm39
I0619 14:56:42.134276 17898 net.cpp:91] Creating Layer BatchNorm39
I0619 14:56:42.134284 17898 net.cpp:425] BatchNorm39 <- Convolution39
I0619 14:56:42.134294 17898 net.cpp:386] BatchNorm39 -> Convolution39 (in-place)
I0619 14:56:42.134567 17898 net.cpp:141] Setting up BatchNorm39
I0619 14:56:42.134577 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.134582 17898 net.cpp:156] Memory required for data: 1746403840
I0619 14:56:42.134593 17898 layer_factory.hpp:77] Creating layer Scale39
I0619 14:56:42.134603 17898 net.cpp:91] Creating Layer Scale39
I0619 14:56:42.134608 17898 net.cpp:425] Scale39 <- Convolution39
I0619 14:56:42.134625 17898 net.cpp:386] Scale39 -> Convolution39 (in-place)
I0619 14:56:42.134670 17898 layer_factory.hpp:77] Creating layer Scale39
I0619 14:56:42.134831 17898 net.cpp:141] Setting up Scale39
I0619 14:56:42.134843 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.134848 17898 net.cpp:156] Memory required for data: 1750598144
I0619 14:56:42.134857 17898 layer_factory.hpp:77] Creating layer Eltwise19
I0619 14:56:42.134866 17898 net.cpp:91] Creating Layer Eltwise19
I0619 14:56:42.134871 17898 net.cpp:425] Eltwise19 <- Concat1
I0619 14:56:42.134878 17898 net.cpp:425] Eltwise19 <- Convolution39
I0619 14:56:42.134887 17898 net.cpp:399] Eltwise19 -> Eltwise19
I0619 14:56:42.134915 17898 net.cpp:141] Setting up Eltwise19
I0619 14:56:42.134924 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.134929 17898 net.cpp:156] Memory required for data: 1754792448
I0619 14:56:42.134934 17898 layer_factory.hpp:77] Creating layer ReLU39
I0619 14:56:42.134941 17898 net.cpp:91] Creating Layer ReLU39
I0619 14:56:42.134948 17898 net.cpp:425] ReLU39 <- Eltwise19
I0619 14:56:42.134956 17898 net.cpp:386] ReLU39 -> Eltwise19 (in-place)
I0619 14:56:42.134969 17898 net.cpp:141] Setting up ReLU39
I0619 14:56:42.134976 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.134980 17898 net.cpp:156] Memory required for data: 1758986752
I0619 14:56:42.134989 17898 layer_factory.hpp:77] Creating layer Eltwise19_ReLU39_0_split
I0619 14:56:42.134996 17898 net.cpp:91] Creating Layer Eltwise19_ReLU39_0_split
I0619 14:56:42.135001 17898 net.cpp:425] Eltwise19_ReLU39_0_split <- Eltwise19
I0619 14:56:42.135011 17898 net.cpp:399] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_0
I0619 14:56:42.135020 17898 net.cpp:399] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_1
I0619 14:56:42.135071 17898 net.cpp:141] Setting up Eltwise19_ReLU39_0_split
I0619 14:56:42.135081 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.135087 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.135092 17898 net.cpp:156] Memory required for data: 1767375360
I0619 14:56:42.135097 17898 layer_factory.hpp:77] Creating layer Convolution40
I0619 14:56:42.135109 17898 net.cpp:91] Creating Layer Convolution40
I0619 14:56:42.135115 17898 net.cpp:425] Convolution40 <- Eltwise19_ReLU39_0_split_0
I0619 14:56:42.135128 17898 net.cpp:399] Convolution40 -> Convolution40
I0619 14:56:42.135903 17898 net.cpp:141] Setting up Convolution40
I0619 14:56:42.135915 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.135921 17898 net.cpp:156] Memory required for data: 1771569664
I0619 14:56:42.135931 17898 layer_factory.hpp:77] Creating layer BatchNorm40
I0619 14:56:42.135941 17898 net.cpp:91] Creating Layer BatchNorm40
I0619 14:56:42.135947 17898 net.cpp:425] BatchNorm40 <- Convolution40
I0619 14:56:42.135957 17898 net.cpp:386] BatchNorm40 -> Convolution40 (in-place)
I0619 14:56:42.136209 17898 net.cpp:141] Setting up BatchNorm40
I0619 14:56:42.136219 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.136224 17898 net.cpp:156] Memory required for data: 1775763968
I0619 14:56:42.136235 17898 layer_factory.hpp:77] Creating layer Scale40
I0619 14:56:42.136245 17898 net.cpp:91] Creating Layer Scale40
I0619 14:56:42.136250 17898 net.cpp:425] Scale40 <- Convolution40
I0619 14:56:42.136260 17898 net.cpp:386] Scale40 -> Convolution40 (in-place)
I0619 14:56:42.136303 17898 layer_factory.hpp:77] Creating layer Scale40
I0619 14:56:42.136459 17898 net.cpp:141] Setting up Scale40
I0619 14:56:42.136471 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.136474 17898 net.cpp:156] Memory required for data: 1779958272
I0619 14:56:42.136483 17898 layer_factory.hpp:77] Creating layer ReLU40
I0619 14:56:42.136492 17898 net.cpp:91] Creating Layer ReLU40
I0619 14:56:42.136497 17898 net.cpp:425] ReLU40 <- Convolution40
I0619 14:56:42.136504 17898 net.cpp:386] ReLU40 -> Convolution40 (in-place)
I0619 14:56:42.136512 17898 net.cpp:141] Setting up ReLU40
I0619 14:56:42.136519 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.136524 17898 net.cpp:156] Memory required for data: 1784152576
I0619 14:56:42.136529 17898 layer_factory.hpp:77] Creating layer Convolution41
I0619 14:56:42.136543 17898 net.cpp:91] Creating Layer Convolution41
I0619 14:56:42.136548 17898 net.cpp:425] Convolution41 <- Convolution40
I0619 14:56:42.136559 17898 net.cpp:399] Convolution41 -> Convolution41
I0619 14:56:42.137307 17898 net.cpp:141] Setting up Convolution41
I0619 14:56:42.137318 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.137323 17898 net.cpp:156] Memory required for data: 1788346880
I0619 14:56:42.137332 17898 layer_factory.hpp:77] Creating layer BatchNorm41
I0619 14:56:42.137344 17898 net.cpp:91] Creating Layer BatchNorm41
I0619 14:56:42.137351 17898 net.cpp:425] BatchNorm41 <- Convolution41
I0619 14:56:42.137359 17898 net.cpp:386] BatchNorm41 -> Convolution41 (in-place)
I0619 14:56:42.137609 17898 net.cpp:141] Setting up BatchNorm41
I0619 14:56:42.137619 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.137624 17898 net.cpp:156] Memory required for data: 1792541184
I0619 14:56:42.137634 17898 layer_factory.hpp:77] Creating layer Scale41
I0619 14:56:42.137642 17898 net.cpp:91] Creating Layer Scale41
I0619 14:56:42.137648 17898 net.cpp:425] Scale41 <- Convolution41
I0619 14:56:42.137658 17898 net.cpp:386] Scale41 -> Convolution41 (in-place)
I0619 14:56:42.137699 17898 layer_factory.hpp:77] Creating layer Scale41
I0619 14:56:42.137851 17898 net.cpp:141] Setting up Scale41
I0619 14:56:42.137862 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.137867 17898 net.cpp:156] Memory required for data: 1796735488
I0619 14:56:42.137876 17898 layer_factory.hpp:77] Creating layer Eltwise20
I0619 14:56:42.137884 17898 net.cpp:91] Creating Layer Eltwise20
I0619 14:56:42.137890 17898 net.cpp:425] Eltwise20 <- Eltwise19_ReLU39_0_split_1
I0619 14:56:42.137897 17898 net.cpp:425] Eltwise20 <- Convolution41
I0619 14:56:42.137905 17898 net.cpp:399] Eltwise20 -> Eltwise20
I0619 14:56:42.137931 17898 net.cpp:141] Setting up Eltwise20
I0619 14:56:42.137940 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.137944 17898 net.cpp:156] Memory required for data: 1800929792
I0619 14:56:42.137949 17898 layer_factory.hpp:77] Creating layer ReLU41
I0619 14:56:42.137960 17898 net.cpp:91] Creating Layer ReLU41
I0619 14:56:42.137979 17898 net.cpp:425] ReLU41 <- Eltwise20
I0619 14:56:42.137989 17898 net.cpp:386] ReLU41 -> Eltwise20 (in-place)
I0619 14:56:42.137998 17898 net.cpp:141] Setting up ReLU41
I0619 14:56:42.138005 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.138010 17898 net.cpp:156] Memory required for data: 1805124096
I0619 14:56:42.138015 17898 layer_factory.hpp:77] Creating layer Eltwise20_ReLU41_0_split
I0619 14:56:42.138023 17898 net.cpp:91] Creating Layer Eltwise20_ReLU41_0_split
I0619 14:56:42.138028 17898 net.cpp:425] Eltwise20_ReLU41_0_split <- Eltwise20
I0619 14:56:42.138036 17898 net.cpp:399] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_0
I0619 14:56:42.138046 17898 net.cpp:399] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_1
I0619 14:56:42.138093 17898 net.cpp:141] Setting up Eltwise20_ReLU41_0_split
I0619 14:56:42.138103 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.138109 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.138114 17898 net.cpp:156] Memory required for data: 1813512704
I0619 14:56:42.138118 17898 layer_factory.hpp:77] Creating layer Convolution42
I0619 14:56:42.138133 17898 net.cpp:91] Creating Layer Convolution42
I0619 14:56:42.138139 17898 net.cpp:425] Convolution42 <- Eltwise20_ReLU41_0_split_0
I0619 14:56:42.138147 17898 net.cpp:399] Convolution42 -> Convolution42
I0619 14:56:42.138896 17898 net.cpp:141] Setting up Convolution42
I0619 14:56:42.138908 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.138913 17898 net.cpp:156] Memory required for data: 1817707008
I0619 14:56:42.138922 17898 layer_factory.hpp:77] Creating layer BatchNorm42
I0619 14:56:42.138934 17898 net.cpp:91] Creating Layer BatchNorm42
I0619 14:56:42.138941 17898 net.cpp:425] BatchNorm42 <- Convolution42
I0619 14:56:42.138952 17898 net.cpp:386] BatchNorm42 -> Convolution42 (in-place)
I0619 14:56:42.139197 17898 net.cpp:141] Setting up BatchNorm42
I0619 14:56:42.139207 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.139212 17898 net.cpp:156] Memory required for data: 1821901312
I0619 14:56:42.139222 17898 layer_factory.hpp:77] Creating layer Scale42
I0619 14:56:42.139231 17898 net.cpp:91] Creating Layer Scale42
I0619 14:56:42.139237 17898 net.cpp:425] Scale42 <- Convolution42
I0619 14:56:42.139246 17898 net.cpp:386] Scale42 -> Convolution42 (in-place)
I0619 14:56:42.139289 17898 layer_factory.hpp:77] Creating layer Scale42
I0619 14:56:42.139441 17898 net.cpp:141] Setting up Scale42
I0619 14:56:42.139451 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.139454 17898 net.cpp:156] Memory required for data: 1826095616
I0619 14:56:42.139463 17898 layer_factory.hpp:77] Creating layer ReLU42
I0619 14:56:42.139472 17898 net.cpp:91] Creating Layer ReLU42
I0619 14:56:42.139477 17898 net.cpp:425] ReLU42 <- Convolution42
I0619 14:56:42.139483 17898 net.cpp:386] ReLU42 -> Convolution42 (in-place)
I0619 14:56:42.139492 17898 net.cpp:141] Setting up ReLU42
I0619 14:56:42.139499 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.139503 17898 net.cpp:156] Memory required for data: 1830289920
I0619 14:56:42.139508 17898 layer_factory.hpp:77] Creating layer Convolution43
I0619 14:56:42.139523 17898 net.cpp:91] Creating Layer Convolution43
I0619 14:56:42.139528 17898 net.cpp:425] Convolution43 <- Convolution42
I0619 14:56:42.139539 17898 net.cpp:399] Convolution43 -> Convolution43
I0619 14:56:42.140274 17898 net.cpp:141] Setting up Convolution43
I0619 14:56:42.140285 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.140288 17898 net.cpp:156] Memory required for data: 1834484224
I0619 14:56:42.140297 17898 layer_factory.hpp:77] Creating layer BatchNorm43
I0619 14:56:42.140308 17898 net.cpp:91] Creating Layer BatchNorm43
I0619 14:56:42.140314 17898 net.cpp:425] BatchNorm43 <- Convolution43
I0619 14:56:42.140324 17898 net.cpp:386] BatchNorm43 -> Convolution43 (in-place)
I0619 14:56:42.140568 17898 net.cpp:141] Setting up BatchNorm43
I0619 14:56:42.140579 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.140600 17898 net.cpp:156] Memory required for data: 1838678528
I0619 14:56:42.140612 17898 layer_factory.hpp:77] Creating layer Scale43
I0619 14:56:42.140620 17898 net.cpp:91] Creating Layer Scale43
I0619 14:56:42.140626 17898 net.cpp:425] Scale43 <- Convolution43
I0619 14:56:42.140636 17898 net.cpp:386] Scale43 -> Convolution43 (in-place)
I0619 14:56:42.140681 17898 layer_factory.hpp:77] Creating layer Scale43
I0619 14:56:42.140839 17898 net.cpp:141] Setting up Scale43
I0619 14:56:42.140848 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.140853 17898 net.cpp:156] Memory required for data: 1842872832
I0619 14:56:42.140862 17898 layer_factory.hpp:77] Creating layer Eltwise21
I0619 14:56:42.140872 17898 net.cpp:91] Creating Layer Eltwise21
I0619 14:56:42.140877 17898 net.cpp:425] Eltwise21 <- Eltwise20_ReLU41_0_split_1
I0619 14:56:42.140883 17898 net.cpp:425] Eltwise21 <- Convolution43
I0619 14:56:42.140892 17898 net.cpp:399] Eltwise21 -> Eltwise21
I0619 14:56:42.140918 17898 net.cpp:141] Setting up Eltwise21
I0619 14:56:42.140925 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.140930 17898 net.cpp:156] Memory required for data: 1847067136
I0619 14:56:42.140935 17898 layer_factory.hpp:77] Creating layer ReLU43
I0619 14:56:42.140944 17898 net.cpp:91] Creating Layer ReLU43
I0619 14:56:42.140949 17898 net.cpp:425] ReLU43 <- Eltwise21
I0619 14:56:42.140959 17898 net.cpp:386] ReLU43 -> Eltwise21 (in-place)
I0619 14:56:42.140967 17898 net.cpp:141] Setting up ReLU43
I0619 14:56:42.140974 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.140980 17898 net.cpp:156] Memory required for data: 1851261440
I0619 14:56:42.140985 17898 layer_factory.hpp:77] Creating layer Eltwise21_ReLU43_0_split
I0619 14:56:42.140991 17898 net.cpp:91] Creating Layer Eltwise21_ReLU43_0_split
I0619 14:56:42.140996 17898 net.cpp:425] Eltwise21_ReLU43_0_split <- Eltwise21
I0619 14:56:42.141003 17898 net.cpp:399] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_0
I0619 14:56:42.141012 17898 net.cpp:399] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_1
I0619 14:56:42.141058 17898 net.cpp:141] Setting up Eltwise21_ReLU43_0_split
I0619 14:56:42.141067 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.141073 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.141078 17898 net.cpp:156] Memory required for data: 1859650048
I0619 14:56:42.141083 17898 layer_factory.hpp:77] Creating layer Convolution44
I0619 14:56:42.141096 17898 net.cpp:91] Creating Layer Convolution44
I0619 14:56:42.141103 17898 net.cpp:425] Convolution44 <- Eltwise21_ReLU43_0_split_0
I0619 14:56:42.141111 17898 net.cpp:399] Convolution44 -> Convolution44
I0619 14:56:42.141868 17898 net.cpp:141] Setting up Convolution44
I0619 14:56:42.141880 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.141885 17898 net.cpp:156] Memory required for data: 1863844352
I0619 14:56:42.141894 17898 layer_factory.hpp:77] Creating layer BatchNorm44
I0619 14:56:42.141906 17898 net.cpp:91] Creating Layer BatchNorm44
I0619 14:56:42.141911 17898 net.cpp:425] BatchNorm44 <- Convolution44
I0619 14:56:42.141921 17898 net.cpp:386] BatchNorm44 -> Convolution44 (in-place)
I0619 14:56:42.142168 17898 net.cpp:141] Setting up BatchNorm44
I0619 14:56:42.142177 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.142182 17898 net.cpp:156] Memory required for data: 1868038656
I0619 14:56:42.142194 17898 layer_factory.hpp:77] Creating layer Scale44
I0619 14:56:42.142204 17898 net.cpp:91] Creating Layer Scale44
I0619 14:56:42.142210 17898 net.cpp:425] Scale44 <- Convolution44
I0619 14:56:42.142217 17898 net.cpp:386] Scale44 -> Convolution44 (in-place)
I0619 14:56:42.142259 17898 layer_factory.hpp:77] Creating layer Scale44
I0619 14:56:42.142423 17898 net.cpp:141] Setting up Scale44
I0619 14:56:42.142434 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.142439 17898 net.cpp:156] Memory required for data: 1872232960
I0619 14:56:42.142467 17898 layer_factory.hpp:77] Creating layer ReLU44
I0619 14:56:42.142475 17898 net.cpp:91] Creating Layer ReLU44
I0619 14:56:42.142482 17898 net.cpp:425] ReLU44 <- Convolution44
I0619 14:56:42.142488 17898 net.cpp:386] ReLU44 -> Convolution44 (in-place)
I0619 14:56:42.142498 17898 net.cpp:141] Setting up ReLU44
I0619 14:56:42.142504 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.142509 17898 net.cpp:156] Memory required for data: 1876427264
I0619 14:56:42.142514 17898 layer_factory.hpp:77] Creating layer Convolution45
I0619 14:56:42.142529 17898 net.cpp:91] Creating Layer Convolution45
I0619 14:56:42.142536 17898 net.cpp:425] Convolution45 <- Convolution44
I0619 14:56:42.142544 17898 net.cpp:399] Convolution45 -> Convolution45
I0619 14:56:42.143270 17898 net.cpp:141] Setting up Convolution45
I0619 14:56:42.143281 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.143285 17898 net.cpp:156] Memory required for data: 1880621568
I0619 14:56:42.143295 17898 layer_factory.hpp:77] Creating layer BatchNorm45
I0619 14:56:42.143304 17898 net.cpp:91] Creating Layer BatchNorm45
I0619 14:56:42.143311 17898 net.cpp:425] BatchNorm45 <- Convolution45
I0619 14:56:42.143319 17898 net.cpp:386] BatchNorm45 -> Convolution45 (in-place)
I0619 14:56:42.143556 17898 net.cpp:141] Setting up BatchNorm45
I0619 14:56:42.143565 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.143570 17898 net.cpp:156] Memory required for data: 1884815872
I0619 14:56:42.143580 17898 layer_factory.hpp:77] Creating layer Scale45
I0619 14:56:42.143589 17898 net.cpp:91] Creating Layer Scale45
I0619 14:56:42.143594 17898 net.cpp:425] Scale45 <- Convolution45
I0619 14:56:42.143602 17898 net.cpp:386] Scale45 -> Convolution45 (in-place)
I0619 14:56:42.143642 17898 layer_factory.hpp:77] Creating layer Scale45
I0619 14:56:42.143787 17898 net.cpp:141] Setting up Scale45
I0619 14:56:42.143796 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.143800 17898 net.cpp:156] Memory required for data: 1889010176
I0619 14:56:42.143808 17898 layer_factory.hpp:77] Creating layer Eltwise22
I0619 14:56:42.143816 17898 net.cpp:91] Creating Layer Eltwise22
I0619 14:56:42.143822 17898 net.cpp:425] Eltwise22 <- Eltwise21_ReLU43_0_split_1
I0619 14:56:42.143828 17898 net.cpp:425] Eltwise22 <- Convolution45
I0619 14:56:42.143836 17898 net.cpp:399] Eltwise22 -> Eltwise22
I0619 14:56:42.143863 17898 net.cpp:141] Setting up Eltwise22
I0619 14:56:42.143872 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.143877 17898 net.cpp:156] Memory required for data: 1893204480
I0619 14:56:42.143882 17898 layer_factory.hpp:77] Creating layer ReLU45
I0619 14:56:42.143888 17898 net.cpp:91] Creating Layer ReLU45
I0619 14:56:42.143893 17898 net.cpp:425] ReLU45 <- Eltwise22
I0619 14:56:42.143903 17898 net.cpp:386] ReLU45 -> Eltwise22 (in-place)
I0619 14:56:42.143910 17898 net.cpp:141] Setting up ReLU45
I0619 14:56:42.143918 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.143921 17898 net.cpp:156] Memory required for data: 1897398784
I0619 14:56:42.143926 17898 layer_factory.hpp:77] Creating layer Eltwise22_ReLU45_0_split
I0619 14:56:42.143934 17898 net.cpp:91] Creating Layer Eltwise22_ReLU45_0_split
I0619 14:56:42.143939 17898 net.cpp:425] Eltwise22_ReLU45_0_split <- Eltwise22
I0619 14:56:42.143945 17898 net.cpp:399] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_0
I0619 14:56:42.143954 17898 net.cpp:399] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_1
I0619 14:56:42.143998 17898 net.cpp:141] Setting up Eltwise22_ReLU45_0_split
I0619 14:56:42.144006 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.144012 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.144016 17898 net.cpp:156] Memory required for data: 1905787392
I0619 14:56:42.144021 17898 layer_factory.hpp:77] Creating layer Convolution46
I0619 14:56:42.144042 17898 net.cpp:91] Creating Layer Convolution46
I0619 14:56:42.144047 17898 net.cpp:425] Convolution46 <- Eltwise22_ReLU45_0_split_0
I0619 14:56:42.144073 17898 net.cpp:399] Convolution46 -> Convolution46
I0619 14:56:42.144784 17898 net.cpp:141] Setting up Convolution46
I0619 14:56:42.144795 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.144800 17898 net.cpp:156] Memory required for data: 1909981696
I0619 14:56:42.144811 17898 layer_factory.hpp:77] Creating layer BatchNorm46
I0619 14:56:42.144821 17898 net.cpp:91] Creating Layer BatchNorm46
I0619 14:56:42.144827 17898 net.cpp:425] BatchNorm46 <- Convolution46
I0619 14:56:42.144836 17898 net.cpp:386] BatchNorm46 -> Convolution46 (in-place)
I0619 14:56:42.145068 17898 net.cpp:141] Setting up BatchNorm46
I0619 14:56:42.145077 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.145082 17898 net.cpp:156] Memory required for data: 1914176000
I0619 14:56:42.145092 17898 layer_factory.hpp:77] Creating layer Scale46
I0619 14:56:42.145102 17898 net.cpp:91] Creating Layer Scale46
I0619 14:56:42.145108 17898 net.cpp:425] Scale46 <- Convolution46
I0619 14:56:42.145115 17898 net.cpp:386] Scale46 -> Convolution46 (in-place)
I0619 14:56:42.145154 17898 layer_factory.hpp:77] Creating layer Scale46
I0619 14:56:42.145301 17898 net.cpp:141] Setting up Scale46
I0619 14:56:42.145310 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.145315 17898 net.cpp:156] Memory required for data: 1918370304
I0619 14:56:42.145323 17898 layer_factory.hpp:77] Creating layer ReLU46
I0619 14:56:42.145331 17898 net.cpp:91] Creating Layer ReLU46
I0619 14:56:42.145336 17898 net.cpp:425] ReLU46 <- Convolution46
I0619 14:56:42.145342 17898 net.cpp:386] ReLU46 -> Convolution46 (in-place)
I0619 14:56:42.145350 17898 net.cpp:141] Setting up ReLU46
I0619 14:56:42.145357 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.145361 17898 net.cpp:156] Memory required for data: 1922564608
I0619 14:56:42.145366 17898 layer_factory.hpp:77] Creating layer Convolution47
I0619 14:56:42.145383 17898 net.cpp:91] Creating Layer Convolution47
I0619 14:56:42.145388 17898 net.cpp:425] Convolution47 <- Convolution46
I0619 14:56:42.145396 17898 net.cpp:399] Convolution47 -> Convolution47
I0619 14:56:42.146097 17898 net.cpp:141] Setting up Convolution47
I0619 14:56:42.146107 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.146112 17898 net.cpp:156] Memory required for data: 1926758912
I0619 14:56:42.146121 17898 layer_factory.hpp:77] Creating layer BatchNorm47
I0619 14:56:42.146131 17898 net.cpp:91] Creating Layer BatchNorm47
I0619 14:56:42.146137 17898 net.cpp:425] BatchNorm47 <- Convolution47
I0619 14:56:42.146147 17898 net.cpp:386] BatchNorm47 -> Convolution47 (in-place)
I0619 14:56:42.146399 17898 net.cpp:141] Setting up BatchNorm47
I0619 14:56:42.146409 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.146414 17898 net.cpp:156] Memory required for data: 1930953216
I0619 14:56:42.146425 17898 layer_factory.hpp:77] Creating layer Scale47
I0619 14:56:42.146436 17898 net.cpp:91] Creating Layer Scale47
I0619 14:56:42.146442 17898 net.cpp:425] Scale47 <- Convolution47
I0619 14:56:42.146450 17898 net.cpp:386] Scale47 -> Convolution47 (in-place)
I0619 14:56:42.146497 17898 layer_factory.hpp:77] Creating layer Scale47
I0619 14:56:42.146637 17898 net.cpp:141] Setting up Scale47
I0619 14:56:42.146652 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.146656 17898 net.cpp:156] Memory required for data: 1935147520
I0619 14:56:42.146664 17898 layer_factory.hpp:77] Creating layer Eltwise23
I0619 14:56:42.146672 17898 net.cpp:91] Creating Layer Eltwise23
I0619 14:56:42.146678 17898 net.cpp:425] Eltwise23 <- Eltwise22_ReLU45_0_split_1
I0619 14:56:42.146684 17898 net.cpp:425] Eltwise23 <- Convolution47
I0619 14:56:42.146694 17898 net.cpp:399] Eltwise23 -> Eltwise23
I0619 14:56:42.146718 17898 net.cpp:141] Setting up Eltwise23
I0619 14:56:42.146724 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.146728 17898 net.cpp:156] Memory required for data: 1939341824
I0619 14:56:42.146733 17898 layer_factory.hpp:77] Creating layer ReLU47
I0619 14:56:42.146747 17898 net.cpp:91] Creating Layer ReLU47
I0619 14:56:42.146766 17898 net.cpp:425] ReLU47 <- Eltwise23
I0619 14:56:42.146773 17898 net.cpp:386] ReLU47 -> Eltwise23 (in-place)
I0619 14:56:42.146782 17898 net.cpp:141] Setting up ReLU47
I0619 14:56:42.146795 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.146800 17898 net.cpp:156] Memory required for data: 1943536128
I0619 14:56:42.146805 17898 layer_factory.hpp:77] Creating layer Eltwise23_ReLU47_0_split
I0619 14:56:42.146811 17898 net.cpp:91] Creating Layer Eltwise23_ReLU47_0_split
I0619 14:56:42.146816 17898 net.cpp:425] Eltwise23_ReLU47_0_split <- Eltwise23
I0619 14:56:42.146823 17898 net.cpp:399] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_0
I0619 14:56:42.146834 17898 net.cpp:399] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_1
I0619 14:56:42.146878 17898 net.cpp:141] Setting up Eltwise23_ReLU47_0_split
I0619 14:56:42.146886 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.146893 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.146898 17898 net.cpp:156] Memory required for data: 1951924736
I0619 14:56:42.146903 17898 layer_factory.hpp:77] Creating layer Convolution48
I0619 14:56:42.146915 17898 net.cpp:91] Creating Layer Convolution48
I0619 14:56:42.146920 17898 net.cpp:425] Convolution48 <- Eltwise23_ReLU47_0_split_0
I0619 14:56:42.146929 17898 net.cpp:399] Convolution48 -> Convolution48
I0619 14:56:42.147641 17898 net.cpp:141] Setting up Convolution48
I0619 14:56:42.147652 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.147658 17898 net.cpp:156] Memory required for data: 1956119040
I0619 14:56:42.147667 17898 layer_factory.hpp:77] Creating layer BatchNorm48
I0619 14:56:42.147675 17898 net.cpp:91] Creating Layer BatchNorm48
I0619 14:56:42.147683 17898 net.cpp:425] BatchNorm48 <- Convolution48
I0619 14:56:42.147691 17898 net.cpp:386] BatchNorm48 -> Convolution48 (in-place)
I0619 14:56:42.147932 17898 net.cpp:141] Setting up BatchNorm48
I0619 14:56:42.147940 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.147945 17898 net.cpp:156] Memory required for data: 1960313344
I0619 14:56:42.147955 17898 layer_factory.hpp:77] Creating layer Scale48
I0619 14:56:42.147966 17898 net.cpp:91] Creating Layer Scale48
I0619 14:56:42.147971 17898 net.cpp:425] Scale48 <- Convolution48
I0619 14:56:42.147979 17898 net.cpp:386] Scale48 -> Convolution48 (in-place)
I0619 14:56:42.148020 17898 layer_factory.hpp:77] Creating layer Scale48
I0619 14:56:42.148161 17898 net.cpp:141] Setting up Scale48
I0619 14:56:42.148170 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.148175 17898 net.cpp:156] Memory required for data: 1964507648
I0619 14:56:42.148183 17898 layer_factory.hpp:77] Creating layer ReLU48
I0619 14:56:42.148190 17898 net.cpp:91] Creating Layer ReLU48
I0619 14:56:42.148195 17898 net.cpp:425] ReLU48 <- Convolution48
I0619 14:56:42.148205 17898 net.cpp:386] ReLU48 -> Convolution48 (in-place)
I0619 14:56:42.148212 17898 net.cpp:141] Setting up ReLU48
I0619 14:56:42.148218 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.148223 17898 net.cpp:156] Memory required for data: 1968701952
I0619 14:56:42.148228 17898 layer_factory.hpp:77] Creating layer Convolution49
I0619 14:56:42.148241 17898 net.cpp:91] Creating Layer Convolution49
I0619 14:56:42.148246 17898 net.cpp:425] Convolution49 <- Convolution48
I0619 14:56:42.148253 17898 net.cpp:399] Convolution49 -> Convolution49
I0619 14:56:42.148963 17898 net.cpp:141] Setting up Convolution49
I0619 14:56:42.148982 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.148985 17898 net.cpp:156] Memory required for data: 1972896256
I0619 14:56:42.148994 17898 layer_factory.hpp:77] Creating layer BatchNorm49
I0619 14:56:42.149006 17898 net.cpp:91] Creating Layer BatchNorm49
I0619 14:56:42.149013 17898 net.cpp:425] BatchNorm49 <- Convolution49
I0619 14:56:42.149021 17898 net.cpp:386] BatchNorm49 -> Convolution49 (in-place)
I0619 14:56:42.149263 17898 net.cpp:141] Setting up BatchNorm49
I0619 14:56:42.149288 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.149293 17898 net.cpp:156] Memory required for data: 1977090560
I0619 14:56:42.149303 17898 layer_factory.hpp:77] Creating layer Scale49
I0619 14:56:42.149314 17898 net.cpp:91] Creating Layer Scale49
I0619 14:56:42.149320 17898 net.cpp:425] Scale49 <- Convolution49
I0619 14:56:42.149327 17898 net.cpp:386] Scale49 -> Convolution49 (in-place)
I0619 14:56:42.149370 17898 layer_factory.hpp:77] Creating layer Scale49
I0619 14:56:42.149518 17898 net.cpp:141] Setting up Scale49
I0619 14:56:42.149526 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.149530 17898 net.cpp:156] Memory required for data: 1981284864
I0619 14:56:42.149539 17898 layer_factory.hpp:77] Creating layer Eltwise24
I0619 14:56:42.149547 17898 net.cpp:91] Creating Layer Eltwise24
I0619 14:56:42.149554 17898 net.cpp:425] Eltwise24 <- Eltwise23_ReLU47_0_split_1
I0619 14:56:42.149559 17898 net.cpp:425] Eltwise24 <- Convolution49
I0619 14:56:42.149569 17898 net.cpp:399] Eltwise24 -> Eltwise24
I0619 14:56:42.149592 17898 net.cpp:141] Setting up Eltwise24
I0619 14:56:42.149600 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.149605 17898 net.cpp:156] Memory required for data: 1985479168
I0619 14:56:42.149608 17898 layer_factory.hpp:77] Creating layer ReLU49
I0619 14:56:42.149618 17898 net.cpp:91] Creating Layer ReLU49
I0619 14:56:42.149623 17898 net.cpp:425] ReLU49 <- Eltwise24
I0619 14:56:42.149631 17898 net.cpp:386] ReLU49 -> Eltwise24 (in-place)
I0619 14:56:42.149637 17898 net.cpp:141] Setting up ReLU49
I0619 14:56:42.149644 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.149648 17898 net.cpp:156] Memory required for data: 1989673472
I0619 14:56:42.149653 17898 layer_factory.hpp:77] Creating layer Eltwise24_ReLU49_0_split
I0619 14:56:42.149660 17898 net.cpp:91] Creating Layer Eltwise24_ReLU49_0_split
I0619 14:56:42.149664 17898 net.cpp:425] Eltwise24_ReLU49_0_split <- Eltwise24
I0619 14:56:42.149672 17898 net.cpp:399] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_0
I0619 14:56:42.149682 17898 net.cpp:399] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_1
I0619 14:56:42.149727 17898 net.cpp:141] Setting up Eltwise24_ReLU49_0_split
I0619 14:56:42.149735 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.149741 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.149745 17898 net.cpp:156] Memory required for data: 1998062080
I0619 14:56:42.149750 17898 layer_factory.hpp:77] Creating layer Convolution50
I0619 14:56:42.149763 17898 net.cpp:91] Creating Layer Convolution50
I0619 14:56:42.149770 17898 net.cpp:425] Convolution50 <- Eltwise24_ReLU49_0_split_0
I0619 14:56:42.149777 17898 net.cpp:399] Convolution50 -> Convolution50
I0619 14:56:42.151252 17898 net.cpp:141] Setting up Convolution50
I0619 14:56:42.151273 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.151279 17898 net.cpp:156] Memory required for data: 2002256384
I0619 14:56:42.151289 17898 layer_factory.hpp:77] Creating layer BatchNorm50
I0619 14:56:42.151298 17898 net.cpp:91] Creating Layer BatchNorm50
I0619 14:56:42.151305 17898 net.cpp:425] BatchNorm50 <- Convolution50
I0619 14:56:42.151314 17898 net.cpp:386] BatchNorm50 -> Convolution50 (in-place)
I0619 14:56:42.151556 17898 net.cpp:141] Setting up BatchNorm50
I0619 14:56:42.151566 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.151569 17898 net.cpp:156] Memory required for data: 2006450688
I0619 14:56:42.151581 17898 layer_factory.hpp:77] Creating layer Scale50
I0619 14:56:42.151592 17898 net.cpp:91] Creating Layer Scale50
I0619 14:56:42.151597 17898 net.cpp:425] Scale50 <- Convolution50
I0619 14:56:42.151604 17898 net.cpp:386] Scale50 -> Convolution50 (in-place)
I0619 14:56:42.151648 17898 layer_factory.hpp:77] Creating layer Scale50
I0619 14:56:42.151789 17898 net.cpp:141] Setting up Scale50
I0619 14:56:42.151798 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.151808 17898 net.cpp:156] Memory required for data: 2010644992
I0619 14:56:42.151830 17898 layer_factory.hpp:77] Creating layer ReLU50
I0619 14:56:42.151841 17898 net.cpp:91] Creating Layer ReLU50
I0619 14:56:42.151847 17898 net.cpp:425] ReLU50 <- Convolution50
I0619 14:56:42.151855 17898 net.cpp:386] ReLU50 -> Convolution50 (in-place)
I0619 14:56:42.151864 17898 net.cpp:141] Setting up ReLU50
I0619 14:56:42.151870 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.151875 17898 net.cpp:156] Memory required for data: 2014839296
I0619 14:56:42.151880 17898 layer_factory.hpp:77] Creating layer Convolution51
I0619 14:56:42.151893 17898 net.cpp:91] Creating Layer Convolution51
I0619 14:56:42.151898 17898 net.cpp:425] Convolution51 <- Convolution50
I0619 14:56:42.151907 17898 net.cpp:399] Convolution51 -> Convolution51
I0619 14:56:42.152606 17898 net.cpp:141] Setting up Convolution51
I0619 14:56:42.152621 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.152624 17898 net.cpp:156] Memory required for data: 2019033600
I0619 14:56:42.152633 17898 layer_factory.hpp:77] Creating layer BatchNorm51
I0619 14:56:42.152643 17898 net.cpp:91] Creating Layer BatchNorm51
I0619 14:56:42.152649 17898 net.cpp:425] BatchNorm51 <- Convolution51
I0619 14:56:42.152657 17898 net.cpp:386] BatchNorm51 -> Convolution51 (in-place)
I0619 14:56:42.152884 17898 net.cpp:141] Setting up BatchNorm51
I0619 14:56:42.152894 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.152897 17898 net.cpp:156] Memory required for data: 2023227904
I0619 14:56:42.152907 17898 layer_factory.hpp:77] Creating layer Scale51
I0619 14:56:42.152918 17898 net.cpp:91] Creating Layer Scale51
I0619 14:56:42.152923 17898 net.cpp:425] Scale51 <- Convolution51
I0619 14:56:42.152930 17898 net.cpp:386] Scale51 -> Convolution51 (in-place)
I0619 14:56:42.152973 17898 layer_factory.hpp:77] Creating layer Scale51
I0619 14:56:42.153123 17898 net.cpp:141] Setting up Scale51
I0619 14:56:42.153132 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.153136 17898 net.cpp:156] Memory required for data: 2027422208
I0619 14:56:42.153146 17898 layer_factory.hpp:77] Creating layer Eltwise25
I0619 14:56:42.153188 17898 net.cpp:91] Creating Layer Eltwise25
I0619 14:56:42.153195 17898 net.cpp:425] Eltwise25 <- Eltwise24_ReLU49_0_split_1
I0619 14:56:42.153203 17898 net.cpp:425] Eltwise25 <- Convolution51
I0619 14:56:42.153210 17898 net.cpp:399] Eltwise25 -> Eltwise25
I0619 14:56:42.153235 17898 net.cpp:141] Setting up Eltwise25
I0619 14:56:42.153244 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.153249 17898 net.cpp:156] Memory required for data: 2031616512
I0619 14:56:42.153254 17898 layer_factory.hpp:77] Creating layer ReLU51
I0619 14:56:42.153264 17898 net.cpp:91] Creating Layer ReLU51
I0619 14:56:42.153270 17898 net.cpp:425] ReLU51 <- Eltwise25
I0619 14:56:42.153276 17898 net.cpp:386] ReLU51 -> Eltwise25 (in-place)
I0619 14:56:42.153285 17898 net.cpp:141] Setting up ReLU51
I0619 14:56:42.153290 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.153295 17898 net.cpp:156] Memory required for data: 2035810816
I0619 14:56:42.153301 17898 layer_factory.hpp:77] Creating layer Eltwise25_ReLU51_0_split
I0619 14:56:42.153307 17898 net.cpp:91] Creating Layer Eltwise25_ReLU51_0_split
I0619 14:56:42.153312 17898 net.cpp:425] Eltwise25_ReLU51_0_split <- Eltwise25
I0619 14:56:42.153319 17898 net.cpp:399] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_0
I0619 14:56:42.153328 17898 net.cpp:399] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_1
I0619 14:56:42.153373 17898 net.cpp:141] Setting up Eltwise25_ReLU51_0_split
I0619 14:56:42.153381 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.153388 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.153391 17898 net.cpp:156] Memory required for data: 2044199424
I0619 14:56:42.153396 17898 layer_factory.hpp:77] Creating layer Convolution52
I0619 14:56:42.153409 17898 net.cpp:91] Creating Layer Convolution52
I0619 14:56:42.153419 17898 net.cpp:425] Convolution52 <- Eltwise25_ReLU51_0_split_0
I0619 14:56:42.153440 17898 net.cpp:399] Convolution52 -> Convolution52
I0619 14:56:42.154142 17898 net.cpp:141] Setting up Convolution52
I0619 14:56:42.154153 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.154157 17898 net.cpp:156] Memory required for data: 2048393728
I0619 14:56:42.154166 17898 layer_factory.hpp:77] Creating layer BatchNorm52
I0619 14:56:42.154181 17898 net.cpp:91] Creating Layer BatchNorm52
I0619 14:56:42.154188 17898 net.cpp:425] BatchNorm52 <- Convolution52
I0619 14:56:42.154197 17898 net.cpp:386] BatchNorm52 -> Convolution52 (in-place)
I0619 14:56:42.154440 17898 net.cpp:141] Setting up BatchNorm52
I0619 14:56:42.154451 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.154456 17898 net.cpp:156] Memory required for data: 2052588032
I0619 14:56:42.154466 17898 layer_factory.hpp:77] Creating layer Scale52
I0619 14:56:42.154475 17898 net.cpp:91] Creating Layer Scale52
I0619 14:56:42.154481 17898 net.cpp:425] Scale52 <- Convolution52
I0619 14:56:42.154490 17898 net.cpp:386] Scale52 -> Convolution52 (in-place)
I0619 14:56:42.154531 17898 layer_factory.hpp:77] Creating layer Scale52
I0619 14:56:42.154669 17898 net.cpp:141] Setting up Scale52
I0619 14:56:42.154680 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.154683 17898 net.cpp:156] Memory required for data: 2056782336
I0619 14:56:42.154692 17898 layer_factory.hpp:77] Creating layer ReLU52
I0619 14:56:42.154700 17898 net.cpp:91] Creating Layer ReLU52
I0619 14:56:42.154706 17898 net.cpp:425] ReLU52 <- Convolution52
I0619 14:56:42.154711 17898 net.cpp:386] ReLU52 -> Convolution52 (in-place)
I0619 14:56:42.154719 17898 net.cpp:141] Setting up ReLU52
I0619 14:56:42.154726 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.154731 17898 net.cpp:156] Memory required for data: 2060976640
I0619 14:56:42.154736 17898 layer_factory.hpp:77] Creating layer Convolution53
I0619 14:56:42.154757 17898 net.cpp:91] Creating Layer Convolution53
I0619 14:56:42.154762 17898 net.cpp:425] Convolution53 <- Convolution52
I0619 14:56:42.154772 17898 net.cpp:399] Convolution53 -> Convolution53
I0619 14:56:42.155452 17898 net.cpp:141] Setting up Convolution53
I0619 14:56:42.155462 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.155467 17898 net.cpp:156] Memory required for data: 2065170944
I0619 14:56:42.155474 17898 layer_factory.hpp:77] Creating layer BatchNorm53
I0619 14:56:42.155488 17898 net.cpp:91] Creating Layer BatchNorm53
I0619 14:56:42.155494 17898 net.cpp:425] BatchNorm53 <- Convolution53
I0619 14:56:42.155501 17898 net.cpp:386] BatchNorm53 -> Convolution53 (in-place)
I0619 14:56:42.155730 17898 net.cpp:141] Setting up BatchNorm53
I0619 14:56:42.155738 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.155742 17898 net.cpp:156] Memory required for data: 2069365248
I0619 14:56:42.155752 17898 layer_factory.hpp:77] Creating layer Scale53
I0619 14:56:42.155761 17898 net.cpp:91] Creating Layer Scale53
I0619 14:56:42.155766 17898 net.cpp:425] Scale53 <- Convolution53
I0619 14:56:42.155774 17898 net.cpp:386] Scale53 -> Convolution53 (in-place)
I0619 14:56:42.155812 17898 layer_factory.hpp:77] Creating layer Scale53
I0619 14:56:42.155946 17898 net.cpp:141] Setting up Scale53
I0619 14:56:42.155953 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.155957 17898 net.cpp:156] Memory required for data: 2073559552
I0619 14:56:42.155966 17898 layer_factory.hpp:77] Creating layer Eltwise26
I0619 14:56:42.155974 17898 net.cpp:91] Creating Layer Eltwise26
I0619 14:56:42.155980 17898 net.cpp:425] Eltwise26 <- Eltwise25_ReLU51_0_split_1
I0619 14:56:42.155987 17898 net.cpp:425] Eltwise26 <- Convolution53
I0619 14:56:42.155993 17898 net.cpp:399] Eltwise26 -> Eltwise26
I0619 14:56:42.156014 17898 net.cpp:141] Setting up Eltwise26
I0619 14:56:42.156021 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.156025 17898 net.cpp:156] Memory required for data: 2077753856
I0619 14:56:42.156033 17898 layer_factory.hpp:77] Creating layer ReLU53
I0619 14:56:42.156057 17898 net.cpp:91] Creating Layer ReLU53
I0619 14:56:42.156062 17898 net.cpp:425] ReLU53 <- Eltwise26
I0619 14:56:42.156071 17898 net.cpp:386] ReLU53 -> Eltwise26 (in-place)
I0619 14:56:42.156080 17898 net.cpp:141] Setting up ReLU53
I0619 14:56:42.156086 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.156090 17898 net.cpp:156] Memory required for data: 2081948160
I0619 14:56:42.156095 17898 layer_factory.hpp:77] Creating layer Eltwise26_ReLU53_0_split
I0619 14:56:42.156101 17898 net.cpp:91] Creating Layer Eltwise26_ReLU53_0_split
I0619 14:56:42.156105 17898 net.cpp:425] Eltwise26_ReLU53_0_split <- Eltwise26
I0619 14:56:42.156112 17898 net.cpp:399] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_0
I0619 14:56:42.156121 17898 net.cpp:399] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_1
I0619 14:56:42.156167 17898 net.cpp:141] Setting up Eltwise26_ReLU53_0_split
I0619 14:56:42.156175 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.156180 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.156185 17898 net.cpp:156] Memory required for data: 2090336768
I0619 14:56:42.156189 17898 layer_factory.hpp:77] Creating layer Convolution54
I0619 14:56:42.156203 17898 net.cpp:91] Creating Layer Convolution54
I0619 14:56:42.156208 17898 net.cpp:425] Convolution54 <- Eltwise26_ReLU53_0_split_0
I0619 14:56:42.156216 17898 net.cpp:399] Convolution54 -> Convolution54
I0619 14:56:42.156891 17898 net.cpp:141] Setting up Convolution54
I0619 14:56:42.156901 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.156905 17898 net.cpp:156] Memory required for data: 2094531072
I0619 14:56:42.156914 17898 layer_factory.hpp:77] Creating layer BatchNorm54
I0619 14:56:42.156924 17898 net.cpp:91] Creating Layer BatchNorm54
I0619 14:56:42.156934 17898 net.cpp:425] BatchNorm54 <- Convolution54
I0619 14:56:42.156942 17898 net.cpp:386] BatchNorm54 -> Convolution54 (in-place)
I0619 14:56:42.157163 17898 net.cpp:141] Setting up BatchNorm54
I0619 14:56:42.157172 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.157176 17898 net.cpp:156] Memory required for data: 2098725376
I0619 14:56:42.157186 17898 layer_factory.hpp:77] Creating layer Scale54
I0619 14:56:42.157194 17898 net.cpp:91] Creating Layer Scale54
I0619 14:56:42.157199 17898 net.cpp:425] Scale54 <- Convolution54
I0619 14:56:42.157208 17898 net.cpp:386] Scale54 -> Convolution54 (in-place)
I0619 14:56:42.157248 17898 layer_factory.hpp:77] Creating layer Scale54
I0619 14:56:42.157379 17898 net.cpp:141] Setting up Scale54
I0619 14:56:42.157390 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.157394 17898 net.cpp:156] Memory required for data: 2102919680
I0619 14:56:42.157407 17898 layer_factory.hpp:77] Creating layer ReLU54
I0619 14:56:42.157413 17898 net.cpp:91] Creating Layer ReLU54
I0619 14:56:42.157418 17898 net.cpp:425] ReLU54 <- Convolution54
I0619 14:56:42.157424 17898 net.cpp:386] ReLU54 -> Convolution54 (in-place)
I0619 14:56:42.157433 17898 net.cpp:141] Setting up ReLU54
I0619 14:56:42.157438 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.157443 17898 net.cpp:156] Memory required for data: 2107113984
I0619 14:56:42.157446 17898 layer_factory.hpp:77] Creating layer Convolution55
I0619 14:56:42.157459 17898 net.cpp:91] Creating Layer Convolution55
I0619 14:56:42.157464 17898 net.cpp:425] Convolution55 <- Convolution54
I0619 14:56:42.157474 17898 net.cpp:399] Convolution55 -> Convolution55
I0619 14:56:42.158136 17898 net.cpp:141] Setting up Convolution55
I0619 14:56:42.158146 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.158150 17898 net.cpp:156] Memory required for data: 2111308288
I0619 14:56:42.158159 17898 layer_factory.hpp:77] Creating layer BatchNorm55
I0619 14:56:42.158169 17898 net.cpp:91] Creating Layer BatchNorm55
I0619 14:56:42.158174 17898 net.cpp:425] BatchNorm55 <- Convolution55
I0619 14:56:42.158182 17898 net.cpp:386] BatchNorm55 -> Convolution55 (in-place)
I0619 14:56:42.158419 17898 net.cpp:141] Setting up BatchNorm55
I0619 14:56:42.158442 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.158447 17898 net.cpp:156] Memory required for data: 2115502592
I0619 14:56:42.158457 17898 layer_factory.hpp:77] Creating layer Scale55
I0619 14:56:42.158466 17898 net.cpp:91] Creating Layer Scale55
I0619 14:56:42.158471 17898 net.cpp:425] Scale55 <- Convolution55
I0619 14:56:42.158481 17898 net.cpp:386] Scale55 -> Convolution55 (in-place)
I0619 14:56:42.158522 17898 layer_factory.hpp:77] Creating layer Scale55
I0619 14:56:42.158654 17898 net.cpp:141] Setting up Scale55
I0619 14:56:42.158665 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.158669 17898 net.cpp:156] Memory required for data: 2119696896
I0619 14:56:42.158679 17898 layer_factory.hpp:77] Creating layer Eltwise27
I0619 14:56:42.158685 17898 net.cpp:91] Creating Layer Eltwise27
I0619 14:56:42.158691 17898 net.cpp:425] Eltwise27 <- Eltwise26_ReLU53_0_split_1
I0619 14:56:42.158697 17898 net.cpp:425] Eltwise27 <- Convolution55
I0619 14:56:42.158704 17898 net.cpp:399] Eltwise27 -> Eltwise27
I0619 14:56:42.158727 17898 net.cpp:141] Setting up Eltwise27
I0619 14:56:42.158735 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.158740 17898 net.cpp:156] Memory required for data: 2123891200
I0619 14:56:42.158746 17898 layer_factory.hpp:77] Creating layer ReLU55
I0619 14:56:42.158752 17898 net.cpp:91] Creating Layer ReLU55
I0619 14:56:42.158757 17898 net.cpp:425] ReLU55 <- Eltwise27
I0619 14:56:42.158766 17898 net.cpp:386] ReLU55 -> Eltwise27 (in-place)
I0619 14:56:42.158773 17898 net.cpp:141] Setting up ReLU55
I0619 14:56:42.158779 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.158783 17898 net.cpp:156] Memory required for data: 2128085504
I0619 14:56:42.158788 17898 layer_factory.hpp:77] Creating layer Eltwise27_ReLU55_0_split
I0619 14:56:42.158794 17898 net.cpp:91] Creating Layer Eltwise27_ReLU55_0_split
I0619 14:56:42.158799 17898 net.cpp:425] Eltwise27_ReLU55_0_split <- Eltwise27
I0619 14:56:42.158810 17898 net.cpp:399] Eltwise27_ReLU55_0_split -> Eltwise27_ReLU55_0_split_0
I0619 14:56:42.158819 17898 net.cpp:399] Eltwise27_ReLU55_0_split -> Eltwise27_ReLU55_0_split_1
I0619 14:56:42.158866 17898 net.cpp:141] Setting up Eltwise27_ReLU55_0_split
I0619 14:56:42.158874 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.158879 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.158884 17898 net.cpp:156] Memory required for data: 2136474112
I0619 14:56:42.158888 17898 layer_factory.hpp:77] Creating layer Convolution56
I0619 14:56:42.158901 17898 net.cpp:91] Creating Layer Convolution56
I0619 14:56:42.158907 17898 net.cpp:425] Convolution56 <- Eltwise27_ReLU55_0_split_0
I0619 14:56:42.158916 17898 net.cpp:399] Convolution56 -> Convolution56
I0619 14:56:42.159590 17898 net.cpp:141] Setting up Convolution56
I0619 14:56:42.159600 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.159605 17898 net.cpp:156] Memory required for data: 2140668416
I0619 14:56:42.159613 17898 layer_factory.hpp:77] Creating layer BatchNorm56
I0619 14:56:42.159623 17898 net.cpp:91] Creating Layer BatchNorm56
I0619 14:56:42.159628 17898 net.cpp:425] BatchNorm56 <- Convolution56
I0619 14:56:42.159637 17898 net.cpp:386] BatchNorm56 -> Convolution56 (in-place)
I0619 14:56:42.159857 17898 net.cpp:141] Setting up BatchNorm56
I0619 14:56:42.159867 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.159870 17898 net.cpp:156] Memory required for data: 2144862720
I0619 14:56:42.159880 17898 layer_factory.hpp:77] Creating layer Scale56
I0619 14:56:42.159888 17898 net.cpp:91] Creating Layer Scale56
I0619 14:56:42.159893 17898 net.cpp:425] Scale56 <- Convolution56
I0619 14:56:42.159903 17898 net.cpp:386] Scale56 -> Convolution56 (in-place)
I0619 14:56:42.159943 17898 layer_factory.hpp:77] Creating layer Scale56
I0619 14:56:42.160078 17898 net.cpp:141] Setting up Scale56
I0619 14:56:42.160085 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.160094 17898 net.cpp:156] Memory required for data: 2149057024
I0619 14:56:42.160115 17898 layer_factory.hpp:77] Creating layer ReLU56
I0619 14:56:42.160121 17898 net.cpp:91] Creating Layer ReLU56
I0619 14:56:42.160127 17898 net.cpp:425] ReLU56 <- Convolution56
I0619 14:56:42.160133 17898 net.cpp:386] ReLU56 -> Convolution56 (in-place)
I0619 14:56:42.160141 17898 net.cpp:141] Setting up ReLU56
I0619 14:56:42.160147 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.160152 17898 net.cpp:156] Memory required for data: 2153251328
I0619 14:56:42.160156 17898 layer_factory.hpp:77] Creating layer Convolution57
I0619 14:56:42.160169 17898 net.cpp:91] Creating Layer Convolution57
I0619 14:56:42.160174 17898 net.cpp:425] Convolution57 <- Convolution56
I0619 14:56:42.160184 17898 net.cpp:399] Convolution57 -> Convolution57
I0619 14:56:42.160851 17898 net.cpp:141] Setting up Convolution57
I0619 14:56:42.160861 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.160866 17898 net.cpp:156] Memory required for data: 2157445632
I0619 14:56:42.160873 17898 layer_factory.hpp:77] Creating layer BatchNorm57
I0619 14:56:42.160883 17898 net.cpp:91] Creating Layer BatchNorm57
I0619 14:56:42.160888 17898 net.cpp:425] BatchNorm57 <- Convolution57
I0619 14:56:42.160899 17898 net.cpp:386] BatchNorm57 -> Convolution57 (in-place)
I0619 14:56:42.161121 17898 net.cpp:141] Setting up BatchNorm57
I0619 14:56:42.161130 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.161135 17898 net.cpp:156] Memory required for data: 2161639936
I0619 14:56:42.161144 17898 layer_factory.hpp:77] Creating layer Scale57
I0619 14:56:42.161152 17898 net.cpp:91] Creating Layer Scale57
I0619 14:56:42.161157 17898 net.cpp:425] Scale57 <- Convolution57
I0619 14:56:42.161166 17898 net.cpp:386] Scale57 -> Convolution57 (in-place)
I0619 14:56:42.161211 17898 layer_factory.hpp:77] Creating layer Scale57
I0619 14:56:42.161344 17898 net.cpp:141] Setting up Scale57
I0619 14:56:42.161355 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.161358 17898 net.cpp:156] Memory required for data: 2165834240
I0619 14:56:42.161366 17898 layer_factory.hpp:77] Creating layer Eltwise28
I0619 14:56:42.161375 17898 net.cpp:91] Creating Layer Eltwise28
I0619 14:56:42.161380 17898 net.cpp:425] Eltwise28 <- Eltwise27_ReLU55_0_split_1
I0619 14:56:42.161386 17898 net.cpp:425] Eltwise28 <- Convolution57
I0619 14:56:42.161392 17898 net.cpp:399] Eltwise28 -> Eltwise28
I0619 14:56:42.161415 17898 net.cpp:141] Setting up Eltwise28
I0619 14:56:42.161423 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.161427 17898 net.cpp:156] Memory required for data: 2170028544
I0619 14:56:42.161432 17898 layer_factory.hpp:77] Creating layer ReLU57
I0619 14:56:42.161439 17898 net.cpp:91] Creating Layer ReLU57
I0619 14:56:42.161444 17898 net.cpp:425] ReLU57 <- Eltwise28
I0619 14:56:42.161453 17898 net.cpp:386] ReLU57 -> Eltwise28 (in-place)
I0619 14:56:42.161460 17898 net.cpp:141] Setting up ReLU57
I0619 14:56:42.161468 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.161471 17898 net.cpp:156] Memory required for data: 2174222848
I0619 14:56:42.161476 17898 layer_factory.hpp:77] Creating layer Eltwise28_ReLU57_0_split
I0619 14:56:42.161483 17898 net.cpp:91] Creating Layer Eltwise28_ReLU57_0_split
I0619 14:56:42.161487 17898 net.cpp:425] Eltwise28_ReLU57_0_split <- Eltwise28
I0619 14:56:42.161494 17898 net.cpp:399] Eltwise28_ReLU57_0_split -> Eltwise28_ReLU57_0_split_0
I0619 14:56:42.161501 17898 net.cpp:399] Eltwise28_ReLU57_0_split -> Eltwise28_ReLU57_0_split_1
I0619 14:56:42.161543 17898 net.cpp:141] Setting up Eltwise28_ReLU57_0_split
I0619 14:56:42.161550 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.161556 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.161561 17898 net.cpp:156] Memory required for data: 2182611456
I0619 14:56:42.161566 17898 layer_factory.hpp:77] Creating layer Convolution58
I0619 14:56:42.161577 17898 net.cpp:91] Creating Layer Convolution58
I0619 14:56:42.161586 17898 net.cpp:425] Convolution58 <- Eltwise28_ReLU57_0_split_0
I0619 14:56:42.161607 17898 net.cpp:399] Convolution58 -> Convolution58
I0619 14:56:42.162277 17898 net.cpp:141] Setting up Convolution58
I0619 14:56:42.162287 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.162292 17898 net.cpp:156] Memory required for data: 2186805760
I0619 14:56:42.162300 17898 layer_factory.hpp:77] Creating layer BatchNorm58
I0619 14:56:42.162312 17898 net.cpp:91] Creating Layer BatchNorm58
I0619 14:56:42.162317 17898 net.cpp:425] BatchNorm58 <- Convolution58
I0619 14:56:42.162325 17898 net.cpp:386] BatchNorm58 -> Convolution58 (in-place)
I0619 14:56:42.162554 17898 net.cpp:141] Setting up BatchNorm58
I0619 14:56:42.162564 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.162569 17898 net.cpp:156] Memory required for data: 2191000064
I0619 14:56:42.162578 17898 layer_factory.hpp:77] Creating layer Scale58
I0619 14:56:42.162586 17898 net.cpp:91] Creating Layer Scale58
I0619 14:56:42.162591 17898 net.cpp:425] Scale58 <- Convolution58
I0619 14:56:42.162600 17898 net.cpp:386] Scale58 -> Convolution58 (in-place)
I0619 14:56:42.162647 17898 layer_factory.hpp:77] Creating layer Scale58
I0619 14:56:42.162786 17898 net.cpp:141] Setting up Scale58
I0619 14:56:42.162794 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.162799 17898 net.cpp:156] Memory required for data: 2195194368
I0619 14:56:42.162807 17898 layer_factory.hpp:77] Creating layer ReLU58
I0619 14:56:42.162814 17898 net.cpp:91] Creating Layer ReLU58
I0619 14:56:42.162819 17898 net.cpp:425] ReLU58 <- Convolution58
I0619 14:56:42.162825 17898 net.cpp:386] ReLU58 -> Convolution58 (in-place)
I0619 14:56:42.162833 17898 net.cpp:141] Setting up ReLU58
I0619 14:56:42.162839 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.162843 17898 net.cpp:156] Memory required for data: 2199388672
I0619 14:56:42.162848 17898 layer_factory.hpp:77] Creating layer Convolution59
I0619 14:56:42.162860 17898 net.cpp:91] Creating Layer Convolution59
I0619 14:56:42.162865 17898 net.cpp:425] Convolution59 <- Convolution58
I0619 14:56:42.162874 17898 net.cpp:399] Convolution59 -> Convolution59
I0619 14:56:42.163542 17898 net.cpp:141] Setting up Convolution59
I0619 14:56:42.163552 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.163557 17898 net.cpp:156] Memory required for data: 2203582976
I0619 14:56:42.163564 17898 layer_factory.hpp:77] Creating layer BatchNorm59
I0619 14:56:42.163583 17898 net.cpp:91] Creating Layer BatchNorm59
I0619 14:56:42.163589 17898 net.cpp:425] BatchNorm59 <- Convolution59
I0619 14:56:42.163597 17898 net.cpp:386] BatchNorm59 -> Convolution59 (in-place)
I0619 14:56:42.163818 17898 net.cpp:141] Setting up BatchNorm59
I0619 14:56:42.163827 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.163831 17898 net.cpp:156] Memory required for data: 2207777280
I0619 14:56:42.163841 17898 layer_factory.hpp:77] Creating layer Scale59
I0619 14:56:42.163848 17898 net.cpp:91] Creating Layer Scale59
I0619 14:56:42.163853 17898 net.cpp:425] Scale59 <- Convolution59
I0619 14:56:42.163862 17898 net.cpp:386] Scale59 -> Convolution59 (in-place)
I0619 14:56:42.163900 17898 layer_factory.hpp:77] Creating layer Scale59
I0619 14:56:42.164038 17898 net.cpp:141] Setting up Scale59
I0619 14:56:42.164047 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.164052 17898 net.cpp:156] Memory required for data: 2211971584
I0619 14:56:42.164059 17898 layer_factory.hpp:77] Creating layer Eltwise29
I0619 14:56:42.164067 17898 net.cpp:91] Creating Layer Eltwise29
I0619 14:56:42.164072 17898 net.cpp:425] Eltwise29 <- Eltwise28_ReLU57_0_split_1
I0619 14:56:42.164077 17898 net.cpp:425] Eltwise29 <- Convolution59
I0619 14:56:42.164084 17898 net.cpp:399] Eltwise29 -> Eltwise29
I0619 14:56:42.164108 17898 net.cpp:141] Setting up Eltwise29
I0619 14:56:42.164115 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.164119 17898 net.cpp:156] Memory required for data: 2216165888
I0619 14:56:42.164127 17898 layer_factory.hpp:77] Creating layer ReLU59
I0619 14:56:42.164146 17898 net.cpp:91] Creating Layer ReLU59
I0619 14:56:42.164152 17898 net.cpp:425] ReLU59 <- Eltwise29
I0619 14:56:42.164161 17898 net.cpp:386] ReLU59 -> Eltwise29 (in-place)
I0619 14:56:42.164170 17898 net.cpp:141] Setting up ReLU59
I0619 14:56:42.164175 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.164180 17898 net.cpp:156] Memory required for data: 2220360192
I0619 14:56:42.164185 17898 layer_factory.hpp:77] Creating layer Eltwise29_ReLU59_0_split
I0619 14:56:42.164191 17898 net.cpp:91] Creating Layer Eltwise29_ReLU59_0_split
I0619 14:56:42.164196 17898 net.cpp:425] Eltwise29_ReLU59_0_split <- Eltwise29
I0619 14:56:42.164202 17898 net.cpp:399] Eltwise29_ReLU59_0_split -> Eltwise29_ReLU59_0_split_0
I0619 14:56:42.164211 17898 net.cpp:399] Eltwise29_ReLU59_0_split -> Eltwise29_ReLU59_0_split_1
I0619 14:56:42.164254 17898 net.cpp:141] Setting up Eltwise29_ReLU59_0_split
I0619 14:56:42.164261 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.164268 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.164273 17898 net.cpp:156] Memory required for data: 2228748800
I0619 14:56:42.164276 17898 layer_factory.hpp:77] Creating layer Convolution60
I0619 14:56:42.164288 17898 net.cpp:91] Creating Layer Convolution60
I0619 14:56:42.164294 17898 net.cpp:425] Convolution60 <- Eltwise29_ReLU59_0_split_0
I0619 14:56:42.164302 17898 net.cpp:399] Convolution60 -> Convolution60
I0619 14:56:42.164973 17898 net.cpp:141] Setting up Convolution60
I0619 14:56:42.164983 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.164988 17898 net.cpp:156] Memory required for data: 2232943104
I0619 14:56:42.164996 17898 layer_factory.hpp:77] Creating layer BatchNorm60
I0619 14:56:42.165006 17898 net.cpp:91] Creating Layer BatchNorm60
I0619 14:56:42.165012 17898 net.cpp:425] BatchNorm60 <- Convolution60
I0619 14:56:42.165021 17898 net.cpp:386] BatchNorm60 -> Convolution60 (in-place)
I0619 14:56:42.165248 17898 net.cpp:141] Setting up BatchNorm60
I0619 14:56:42.165257 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.165262 17898 net.cpp:156] Memory required for data: 2237137408
I0619 14:56:42.165271 17898 layer_factory.hpp:77] Creating layer Scale60
I0619 14:56:42.165282 17898 net.cpp:91] Creating Layer Scale60
I0619 14:56:42.165287 17898 net.cpp:425] Scale60 <- Convolution60
I0619 14:56:42.165293 17898 net.cpp:386] Scale60 -> Convolution60 (in-place)
I0619 14:56:42.165335 17898 layer_factory.hpp:77] Creating layer Scale60
I0619 14:56:42.165474 17898 net.cpp:141] Setting up Scale60
I0619 14:56:42.165483 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.165488 17898 net.cpp:156] Memory required for data: 2241331712
I0619 14:56:42.165495 17898 layer_factory.hpp:77] Creating layer ReLU60
I0619 14:56:42.165503 17898 net.cpp:91] Creating Layer ReLU60
I0619 14:56:42.165508 17898 net.cpp:425] ReLU60 <- Convolution60
I0619 14:56:42.165513 17898 net.cpp:386] ReLU60 -> Convolution60 (in-place)
I0619 14:56:42.165521 17898 net.cpp:141] Setting up ReLU60
I0619 14:56:42.165527 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.165531 17898 net.cpp:156] Memory required for data: 2245526016
I0619 14:56:42.165535 17898 layer_factory.hpp:77] Creating layer Convolution61
I0619 14:56:42.165549 17898 net.cpp:91] Creating Layer Convolution61
I0619 14:56:42.165555 17898 net.cpp:425] Convolution61 <- Convolution60
I0619 14:56:42.165562 17898 net.cpp:399] Convolution61 -> Convolution61
I0619 14:56:42.166224 17898 net.cpp:141] Setting up Convolution61
I0619 14:56:42.166234 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.166239 17898 net.cpp:156] Memory required for data: 2249720320
I0619 14:56:42.166247 17898 layer_factory.hpp:77] Creating layer BatchNorm61
I0619 14:56:42.166257 17898 net.cpp:91] Creating Layer BatchNorm61
I0619 14:56:42.166262 17898 net.cpp:425] BatchNorm61 <- Convolution61
I0619 14:56:42.166271 17898 net.cpp:386] BatchNorm61 -> Convolution61 (in-place)
I0619 14:56:42.166513 17898 net.cpp:141] Setting up BatchNorm61
I0619 14:56:42.166535 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.166540 17898 net.cpp:156] Memory required for data: 2253914624
I0619 14:56:42.166550 17898 layer_factory.hpp:77] Creating layer Scale61
I0619 14:56:42.166558 17898 net.cpp:91] Creating Layer Scale61
I0619 14:56:42.166564 17898 net.cpp:425] Scale61 <- Convolution61
I0619 14:56:42.166575 17898 net.cpp:386] Scale61 -> Convolution61 (in-place)
I0619 14:56:42.166617 17898 layer_factory.hpp:77] Creating layer Scale61
I0619 14:56:42.166762 17898 net.cpp:141] Setting up Scale61
I0619 14:56:42.166770 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.166775 17898 net.cpp:156] Memory required for data: 2258108928
I0619 14:56:42.166782 17898 layer_factory.hpp:77] Creating layer Eltwise30
I0619 14:56:42.166790 17898 net.cpp:91] Creating Layer Eltwise30
I0619 14:56:42.166795 17898 net.cpp:425] Eltwise30 <- Eltwise29_ReLU59_0_split_1
I0619 14:56:42.166800 17898 net.cpp:425] Eltwise30 <- Convolution61
I0619 14:56:42.166807 17898 net.cpp:399] Eltwise30 -> Eltwise30
I0619 14:56:42.166829 17898 net.cpp:141] Setting up Eltwise30
I0619 14:56:42.166836 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.166841 17898 net.cpp:156] Memory required for data: 2262303232
I0619 14:56:42.166844 17898 layer_factory.hpp:77] Creating layer ReLU61
I0619 14:56:42.166851 17898 net.cpp:91] Creating Layer ReLU61
I0619 14:56:42.166856 17898 net.cpp:425] ReLU61 <- Eltwise30
I0619 14:56:42.166863 17898 net.cpp:386] ReLU61 -> Eltwise30 (in-place)
I0619 14:56:42.166870 17898 net.cpp:141] Setting up ReLU61
I0619 14:56:42.166877 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.166882 17898 net.cpp:156] Memory required for data: 2266497536
I0619 14:56:42.166885 17898 layer_factory.hpp:77] Creating layer Eltwise30_ReLU61_0_split
I0619 14:56:42.166892 17898 net.cpp:91] Creating Layer Eltwise30_ReLU61_0_split
I0619 14:56:42.166895 17898 net.cpp:425] Eltwise30_ReLU61_0_split <- Eltwise30
I0619 14:56:42.166901 17898 net.cpp:399] Eltwise30_ReLU61_0_split -> Eltwise30_ReLU61_0_split_0
I0619 14:56:42.166909 17898 net.cpp:399] Eltwise30_ReLU61_0_split -> Eltwise30_ReLU61_0_split_1
I0619 14:56:42.166957 17898 net.cpp:141] Setting up Eltwise30_ReLU61_0_split
I0619 14:56:42.166965 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.166970 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.166973 17898 net.cpp:156] Memory required for data: 2274886144
I0619 14:56:42.166978 17898 layer_factory.hpp:77] Creating layer Convolution62
I0619 14:56:42.166990 17898 net.cpp:91] Creating Layer Convolution62
I0619 14:56:42.166995 17898 net.cpp:425] Convolution62 <- Eltwise30_ReLU61_0_split_0
I0619 14:56:42.167002 17898 net.cpp:399] Convolution62 -> Convolution62
I0619 14:56:42.167647 17898 net.cpp:141] Setting up Convolution62
I0619 14:56:42.167656 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.167661 17898 net.cpp:156] Memory required for data: 2279080448
I0619 14:56:42.167668 17898 layer_factory.hpp:77] Creating layer BatchNorm62
I0619 14:56:42.167680 17898 net.cpp:91] Creating Layer BatchNorm62
I0619 14:56:42.167685 17898 net.cpp:425] BatchNorm62 <- Convolution62
I0619 14:56:42.167695 17898 net.cpp:386] BatchNorm62 -> Convolution62 (in-place)
I0619 14:56:42.167912 17898 net.cpp:141] Setting up BatchNorm62
I0619 14:56:42.167919 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.167923 17898 net.cpp:156] Memory required for data: 2283274752
I0619 14:56:42.167932 17898 layer_factory.hpp:77] Creating layer Scale62
I0619 14:56:42.167943 17898 net.cpp:91] Creating Layer Scale62
I0619 14:56:42.167948 17898 net.cpp:425] Scale62 <- Convolution62
I0619 14:56:42.167953 17898 net.cpp:386] Scale62 -> Convolution62 (in-place)
I0619 14:56:42.167989 17898 layer_factory.hpp:77] Creating layer Scale62
I0619 14:56:42.168119 17898 net.cpp:141] Setting up Scale62
I0619 14:56:42.168128 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.168139 17898 net.cpp:156] Memory required for data: 2287469056
I0619 14:56:42.168159 17898 layer_factory.hpp:77] Creating layer ReLU62
I0619 14:56:42.168165 17898 net.cpp:91] Creating Layer ReLU62
I0619 14:56:42.168170 17898 net.cpp:425] ReLU62 <- Convolution62
I0619 14:56:42.168176 17898 net.cpp:386] ReLU62 -> Convolution62 (in-place)
I0619 14:56:42.168184 17898 net.cpp:141] Setting up ReLU62
I0619 14:56:42.168190 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.168195 17898 net.cpp:156] Memory required for data: 2291663360
I0619 14:56:42.168198 17898 layer_factory.hpp:77] Creating layer Convolution63
I0619 14:56:42.168212 17898 net.cpp:91] Creating Layer Convolution63
I0619 14:56:42.168217 17898 net.cpp:425] Convolution63 <- Convolution62
I0619 14:56:42.168226 17898 net.cpp:399] Convolution63 -> Convolution63
I0619 14:56:42.168861 17898 net.cpp:141] Setting up Convolution63
I0619 14:56:42.168871 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.168875 17898 net.cpp:156] Memory required for data: 2295857664
I0619 14:56:42.168882 17898 layer_factory.hpp:77] Creating layer BatchNorm63
I0619 14:56:42.168892 17898 net.cpp:91] Creating Layer BatchNorm63
I0619 14:56:42.168897 17898 net.cpp:425] BatchNorm63 <- Convolution63
I0619 14:56:42.168905 17898 net.cpp:386] BatchNorm63 -> Convolution63 (in-place)
I0619 14:56:42.169121 17898 net.cpp:141] Setting up BatchNorm63
I0619 14:56:42.169128 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.169132 17898 net.cpp:156] Memory required for data: 2300051968
I0619 14:56:42.169142 17898 layer_factory.hpp:77] Creating layer Scale63
I0619 14:56:42.169152 17898 net.cpp:91] Creating Layer Scale63
I0619 14:56:42.169157 17898 net.cpp:425] Scale63 <- Convolution63
I0619 14:56:42.169162 17898 net.cpp:386] Scale63 -> Convolution63 (in-place)
I0619 14:56:42.169198 17898 layer_factory.hpp:77] Creating layer Scale63
I0619 14:56:42.169327 17898 net.cpp:141] Setting up Scale63
I0619 14:56:42.169333 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.169337 17898 net.cpp:156] Memory required for data: 2304246272
I0619 14:56:42.169345 17898 layer_factory.hpp:77] Creating layer Eltwise31
I0619 14:56:42.169353 17898 net.cpp:91] Creating Layer Eltwise31
I0619 14:56:42.169358 17898 net.cpp:425] Eltwise31 <- Eltwise30_ReLU61_0_split_1
I0619 14:56:42.169363 17898 net.cpp:425] Eltwise31 <- Convolution63
I0619 14:56:42.169374 17898 net.cpp:399] Eltwise31 -> Eltwise31
I0619 14:56:42.169395 17898 net.cpp:141] Setting up Eltwise31
I0619 14:56:42.169401 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.169405 17898 net.cpp:156] Memory required for data: 2308440576
I0619 14:56:42.169409 17898 layer_factory.hpp:77] Creating layer ReLU63
I0619 14:56:42.169420 17898 net.cpp:91] Creating Layer ReLU63
I0619 14:56:42.169423 17898 net.cpp:425] ReLU63 <- Eltwise31
I0619 14:56:42.169430 17898 net.cpp:386] ReLU63 -> Eltwise31 (in-place)
I0619 14:56:42.169436 17898 net.cpp:141] Setting up ReLU63
I0619 14:56:42.169442 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.169447 17898 net.cpp:156] Memory required for data: 2312634880
I0619 14:56:42.169451 17898 layer_factory.hpp:77] Creating layer Eltwise31_ReLU63_0_split
I0619 14:56:42.169458 17898 net.cpp:91] Creating Layer Eltwise31_ReLU63_0_split
I0619 14:56:42.169462 17898 net.cpp:425] Eltwise31_ReLU63_0_split <- Eltwise31
I0619 14:56:42.169468 17898 net.cpp:399] Eltwise31_ReLU63_0_split -> Eltwise31_ReLU63_0_split_0
I0619 14:56:42.169478 17898 net.cpp:399] Eltwise31_ReLU63_0_split -> Eltwise31_ReLU63_0_split_1
I0619 14:56:42.169517 17898 net.cpp:141] Setting up Eltwise31_ReLU63_0_split
I0619 14:56:42.169523 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.169529 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.169533 17898 net.cpp:156] Memory required for data: 2321023488
I0619 14:56:42.169538 17898 layer_factory.hpp:77] Creating layer Convolution64
I0619 14:56:42.169549 17898 net.cpp:91] Creating Layer Convolution64
I0619 14:56:42.169558 17898 net.cpp:425] Convolution64 <- Eltwise31_ReLU63_0_split_0
I0619 14:56:42.169576 17898 net.cpp:399] Convolution64 -> Convolution64
I0619 14:56:42.170225 17898 net.cpp:141] Setting up Convolution64
I0619 14:56:42.170235 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.170239 17898 net.cpp:156] Memory required for data: 2325217792
I0619 14:56:42.170248 17898 layer_factory.hpp:77] Creating layer BatchNorm64
I0619 14:56:42.170255 17898 net.cpp:91] Creating Layer BatchNorm64
I0619 14:56:42.170263 17898 net.cpp:425] BatchNorm64 <- Convolution64
I0619 14:56:42.170269 17898 net.cpp:386] BatchNorm64 -> Convolution64 (in-place)
I0619 14:56:42.170486 17898 net.cpp:141] Setting up BatchNorm64
I0619 14:56:42.170496 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.170500 17898 net.cpp:156] Memory required for data: 2329412096
I0619 14:56:42.170509 17898 layer_factory.hpp:77] Creating layer Scale64
I0619 14:56:42.170526 17898 net.cpp:91] Creating Layer Scale64
I0619 14:56:42.170531 17898 net.cpp:425] Scale64 <- Convolution64
I0619 14:56:42.170537 17898 net.cpp:386] Scale64 -> Convolution64 (in-place)
I0619 14:56:42.170573 17898 layer_factory.hpp:77] Creating layer Scale64
I0619 14:56:42.170711 17898 net.cpp:141] Setting up Scale64
I0619 14:56:42.170719 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.170723 17898 net.cpp:156] Memory required for data: 2333606400
I0619 14:56:42.170732 17898 layer_factory.hpp:77] Creating layer ReLU64
I0619 14:56:42.170738 17898 net.cpp:91] Creating Layer ReLU64
I0619 14:56:42.170743 17898 net.cpp:425] ReLU64 <- Convolution64
I0619 14:56:42.170752 17898 net.cpp:386] ReLU64 -> Convolution64 (in-place)
I0619 14:56:42.170759 17898 net.cpp:141] Setting up ReLU64
I0619 14:56:42.170764 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.170769 17898 net.cpp:156] Memory required for data: 2337800704
I0619 14:56:42.170773 17898 layer_factory.hpp:77] Creating layer Convolution65
I0619 14:56:42.170785 17898 net.cpp:91] Creating Layer Convolution65
I0619 14:56:42.170789 17898 net.cpp:425] Convolution65 <- Convolution64
I0619 14:56:42.170797 17898 net.cpp:399] Convolution65 -> Convolution65
I0619 14:56:42.171429 17898 net.cpp:141] Setting up Convolution65
I0619 14:56:42.171439 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.171443 17898 net.cpp:156] Memory required for data: 2341995008
I0619 14:56:42.171452 17898 layer_factory.hpp:77] Creating layer BatchNorm65
I0619 14:56:42.171460 17898 net.cpp:91] Creating Layer BatchNorm65
I0619 14:56:42.171465 17898 net.cpp:425] BatchNorm65 <- Convolution65
I0619 14:56:42.171474 17898 net.cpp:386] BatchNorm65 -> Convolution65 (in-place)
I0619 14:56:42.171700 17898 net.cpp:141] Setting up BatchNorm65
I0619 14:56:42.171707 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.171712 17898 net.cpp:156] Memory required for data: 2346189312
I0619 14:56:42.171721 17898 layer_factory.hpp:77] Creating layer Scale65
I0619 14:56:42.171731 17898 net.cpp:91] Creating Layer Scale65
I0619 14:56:42.171736 17898 net.cpp:425] Scale65 <- Convolution65
I0619 14:56:42.171742 17898 net.cpp:386] Scale65 -> Convolution65 (in-place)
I0619 14:56:42.171779 17898 layer_factory.hpp:77] Creating layer Scale65
I0619 14:56:42.171911 17898 net.cpp:141] Setting up Scale65
I0619 14:56:42.171921 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.171924 17898 net.cpp:156] Memory required for data: 2350383616
I0619 14:56:42.171931 17898 layer_factory.hpp:77] Creating layer Eltwise32
I0619 14:56:42.171938 17898 net.cpp:91] Creating Layer Eltwise32
I0619 14:56:42.171943 17898 net.cpp:425] Eltwise32 <- Eltwise31_ReLU63_0_split_1
I0619 14:56:42.171949 17898 net.cpp:425] Eltwise32 <- Convolution65
I0619 14:56:42.171958 17898 net.cpp:399] Eltwise32 -> Eltwise32
I0619 14:56:42.171978 17898 net.cpp:141] Setting up Eltwise32
I0619 14:56:42.171984 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.171988 17898 net.cpp:156] Memory required for data: 2354577920
I0619 14:56:42.171996 17898 layer_factory.hpp:77] Creating layer ReLU65
I0619 14:56:42.172019 17898 net.cpp:91] Creating Layer ReLU65
I0619 14:56:42.172024 17898 net.cpp:425] ReLU65 <- Eltwise32
I0619 14:56:42.172029 17898 net.cpp:386] ReLU65 -> Eltwise32 (in-place)
I0619 14:56:42.172037 17898 net.cpp:141] Setting up ReLU65
I0619 14:56:42.172044 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.172047 17898 net.cpp:156] Memory required for data: 2358772224
I0619 14:56:42.172052 17898 layer_factory.hpp:77] Creating layer Eltwise32_ReLU65_0_split
I0619 14:56:42.172058 17898 net.cpp:91] Creating Layer Eltwise32_ReLU65_0_split
I0619 14:56:42.172062 17898 net.cpp:425] Eltwise32_ReLU65_0_split <- Eltwise32
I0619 14:56:42.172068 17898 net.cpp:399] Eltwise32_ReLU65_0_split -> Eltwise32_ReLU65_0_split_0
I0619 14:56:42.172080 17898 net.cpp:399] Eltwise32_ReLU65_0_split -> Eltwise32_ReLU65_0_split_1
I0619 14:56:42.172122 17898 net.cpp:141] Setting up Eltwise32_ReLU65_0_split
I0619 14:56:42.172128 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.172133 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.172137 17898 net.cpp:156] Memory required for data: 2367160832
I0619 14:56:42.172142 17898 layer_factory.hpp:77] Creating layer Convolution66
I0619 14:56:42.172154 17898 net.cpp:91] Creating Layer Convolution66
I0619 14:56:42.172159 17898 net.cpp:425] Convolution66 <- Eltwise32_ReLU65_0_split_0
I0619 14:56:42.172168 17898 net.cpp:399] Convolution66 -> Convolution66
I0619 14:56:42.173513 17898 net.cpp:141] Setting up Convolution66
I0619 14:56:42.173529 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.173534 17898 net.cpp:156] Memory required for data: 2371355136
I0619 14:56:42.173543 17898 layer_factory.hpp:77] Creating layer BatchNorm66
I0619 14:56:42.173552 17898 net.cpp:91] Creating Layer BatchNorm66
I0619 14:56:42.173557 17898 net.cpp:425] BatchNorm66 <- Convolution66
I0619 14:56:42.173568 17898 net.cpp:386] BatchNorm66 -> Convolution66 (in-place)
I0619 14:56:42.173792 17898 net.cpp:141] Setting up BatchNorm66
I0619 14:56:42.173801 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.173805 17898 net.cpp:156] Memory required for data: 2375549440
I0619 14:56:42.173815 17898 layer_factory.hpp:77] Creating layer Scale66
I0619 14:56:42.173822 17898 net.cpp:91] Creating Layer Scale66
I0619 14:56:42.173827 17898 net.cpp:425] Scale66 <- Convolution66
I0619 14:56:42.173835 17898 net.cpp:386] Scale66 -> Convolution66 (in-place)
I0619 14:56:42.173876 17898 layer_factory.hpp:77] Creating layer Scale66
I0619 14:56:42.174008 17898 net.cpp:141] Setting up Scale66
I0619 14:56:42.174016 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.174021 17898 net.cpp:156] Memory required for data: 2379743744
I0619 14:56:42.174028 17898 layer_factory.hpp:77] Creating layer ReLU66
I0619 14:56:42.174036 17898 net.cpp:91] Creating Layer ReLU66
I0619 14:56:42.174041 17898 net.cpp:425] ReLU66 <- Convolution66
I0619 14:56:42.174048 17898 net.cpp:386] ReLU66 -> Convolution66 (in-place)
I0619 14:56:42.174057 17898 net.cpp:141] Setting up ReLU66
I0619 14:56:42.174062 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.174067 17898 net.cpp:156] Memory required for data: 2383938048
I0619 14:56:42.174072 17898 layer_factory.hpp:77] Creating layer Convolution67
I0619 14:56:42.174082 17898 net.cpp:91] Creating Layer Convolution67
I0619 14:56:42.174085 17898 net.cpp:425] Convolution67 <- Convolution66
I0619 14:56:42.174095 17898 net.cpp:399] Convolution67 -> Convolution67
I0619 14:56:42.174768 17898 net.cpp:141] Setting up Convolution67
I0619 14:56:42.174779 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.174783 17898 net.cpp:156] Memory required for data: 2388132352
I0619 14:56:42.174792 17898 layer_factory.hpp:77] Creating layer BatchNorm67
I0619 14:56:42.174799 17898 net.cpp:91] Creating Layer BatchNorm67
I0619 14:56:42.174804 17898 net.cpp:425] BatchNorm67 <- Convolution67
I0619 14:56:42.174813 17898 net.cpp:386] BatchNorm67 -> Convolution67 (in-place)
I0619 14:56:42.175060 17898 net.cpp:141] Setting up BatchNorm67
I0619 14:56:42.175071 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.175074 17898 net.cpp:156] Memory required for data: 2392326656
I0619 14:56:42.175084 17898 layer_factory.hpp:77] Creating layer Scale67
I0619 14:56:42.175092 17898 net.cpp:91] Creating Layer Scale67
I0619 14:56:42.175097 17898 net.cpp:425] Scale67 <- Convolution67
I0619 14:56:42.175103 17898 net.cpp:386] Scale67 -> Convolution67 (in-place)
I0619 14:56:42.175144 17898 layer_factory.hpp:77] Creating layer Scale67
I0619 14:56:42.175279 17898 net.cpp:141] Setting up Scale67
I0619 14:56:42.175287 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.175292 17898 net.cpp:156] Memory required for data: 2396520960
I0619 14:56:42.175299 17898 layer_factory.hpp:77] Creating layer Eltwise33
I0619 14:56:42.175307 17898 net.cpp:91] Creating Layer Eltwise33
I0619 14:56:42.175312 17898 net.cpp:425] Eltwise33 <- Eltwise32_ReLU65_0_split_1
I0619 14:56:42.175318 17898 net.cpp:425] Eltwise33 <- Convolution67
I0619 14:56:42.175328 17898 net.cpp:399] Eltwise33 -> Eltwise33
I0619 14:56:42.175349 17898 net.cpp:141] Setting up Eltwise33
I0619 14:56:42.175364 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.175367 17898 net.cpp:156] Memory required for data: 2400715264
I0619 14:56:42.175371 17898 layer_factory.hpp:77] Creating layer ReLU67
I0619 14:56:42.175379 17898 net.cpp:91] Creating Layer ReLU67
I0619 14:56:42.175384 17898 net.cpp:425] ReLU67 <- Eltwise33
I0619 14:56:42.175391 17898 net.cpp:386] ReLU67 -> Eltwise33 (in-place)
I0619 14:56:42.175398 17898 net.cpp:141] Setting up ReLU67
I0619 14:56:42.175405 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.175410 17898 net.cpp:156] Memory required for data: 2404909568
I0619 14:56:42.175413 17898 layer_factory.hpp:77] Creating layer Eltwise33_ReLU67_0_split
I0619 14:56:42.175420 17898 net.cpp:91] Creating Layer Eltwise33_ReLU67_0_split
I0619 14:56:42.175425 17898 net.cpp:425] Eltwise33_ReLU67_0_split <- Eltwise33
I0619 14:56:42.175436 17898 net.cpp:399] Eltwise33_ReLU67_0_split -> Eltwise33_ReLU67_0_split_0
I0619 14:56:42.175444 17898 net.cpp:399] Eltwise33_ReLU67_0_split -> Eltwise33_ReLU67_0_split_1
I0619 14:56:42.175484 17898 net.cpp:141] Setting up Eltwise33_ReLU67_0_split
I0619 14:56:42.175492 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.175498 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.175501 17898 net.cpp:156] Memory required for data: 2413298176
I0619 14:56:42.175505 17898 layer_factory.hpp:77] Creating layer Convolution68
I0619 14:56:42.175515 17898 net.cpp:91] Creating Layer Convolution68
I0619 14:56:42.175520 17898 net.cpp:425] Convolution68 <- Eltwise33_ReLU67_0_split_0
I0619 14:56:42.175530 17898 net.cpp:399] Convolution68 -> Convolution68
I0619 14:56:42.176184 17898 net.cpp:141] Setting up Convolution68
I0619 14:56:42.176194 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.176198 17898 net.cpp:156] Memory required for data: 2417492480
I0619 14:56:42.176206 17898 layer_factory.hpp:77] Creating layer BatchNorm68
I0619 14:56:42.176214 17898 net.cpp:91] Creating Layer BatchNorm68
I0619 14:56:42.176218 17898 net.cpp:425] BatchNorm68 <- Convolution68
I0619 14:56:42.176228 17898 net.cpp:386] BatchNorm68 -> Convolution68 (in-place)
I0619 14:56:42.176448 17898 net.cpp:141] Setting up BatchNorm68
I0619 14:56:42.176460 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.176463 17898 net.cpp:156] Memory required for data: 2421686784
I0619 14:56:42.176472 17898 layer_factory.hpp:77] Creating layer Scale68
I0619 14:56:42.176479 17898 net.cpp:91] Creating Layer Scale68
I0619 14:56:42.176486 17898 net.cpp:425] Scale68 <- Convolution68
I0619 14:56:42.176491 17898 net.cpp:386] Scale68 -> Convolution68 (in-place)
I0619 14:56:42.176530 17898 layer_factory.hpp:77] Creating layer Scale68
I0619 14:56:42.176663 17898 net.cpp:141] Setting up Scale68
I0619 14:56:42.176672 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.176690 17898 net.cpp:156] Memory required for data: 2425881088
I0619 14:56:42.176699 17898 layer_factory.hpp:77] Creating layer ReLU68
I0619 14:56:42.176707 17898 net.cpp:91] Creating Layer ReLU68
I0619 14:56:42.176712 17898 net.cpp:425] ReLU68 <- Convolution68
I0619 14:56:42.176720 17898 net.cpp:386] ReLU68 -> Convolution68 (in-place)
I0619 14:56:42.176728 17898 net.cpp:141] Setting up ReLU68
I0619 14:56:42.176734 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.176738 17898 net.cpp:156] Memory required for data: 2430075392
I0619 14:56:42.176743 17898 layer_factory.hpp:77] Creating layer Convolution69
I0619 14:56:42.176755 17898 net.cpp:91] Creating Layer Convolution69
I0619 14:56:42.176760 17898 net.cpp:425] Convolution69 <- Convolution68
I0619 14:56:42.176767 17898 net.cpp:399] Convolution69 -> Convolution69
I0619 14:56:42.177412 17898 net.cpp:141] Setting up Convolution69
I0619 14:56:42.177422 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.177425 17898 net.cpp:156] Memory required for data: 2434269696
I0619 14:56:42.177433 17898 layer_factory.hpp:77] Creating layer BatchNorm69
I0619 14:56:42.177440 17898 net.cpp:91] Creating Layer BatchNorm69
I0619 14:56:42.177445 17898 net.cpp:425] BatchNorm69 <- Convolution69
I0619 14:56:42.177454 17898 net.cpp:386] BatchNorm69 -> Convolution69 (in-place)
I0619 14:56:42.177692 17898 net.cpp:141] Setting up BatchNorm69
I0619 14:56:42.177700 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.177705 17898 net.cpp:156] Memory required for data: 2438464000
I0619 14:56:42.177714 17898 layer_factory.hpp:77] Creating layer Scale69
I0619 14:56:42.177721 17898 net.cpp:91] Creating Layer Scale69
I0619 14:56:42.177726 17898 net.cpp:425] Scale69 <- Convolution69
I0619 14:56:42.177732 17898 net.cpp:386] Scale69 -> Convolution69 (in-place)
I0619 14:56:42.177772 17898 layer_factory.hpp:77] Creating layer Scale69
I0619 14:56:42.177911 17898 net.cpp:141] Setting up Scale69
I0619 14:56:42.177918 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.177922 17898 net.cpp:156] Memory required for data: 2442658304
I0619 14:56:42.177930 17898 layer_factory.hpp:77] Creating layer Eltwise34
I0619 14:56:42.177937 17898 net.cpp:91] Creating Layer Eltwise34
I0619 14:56:42.177942 17898 net.cpp:425] Eltwise34 <- Eltwise33_ReLU67_0_split_1
I0619 14:56:42.177947 17898 net.cpp:425] Eltwise34 <- Convolution69
I0619 14:56:42.177956 17898 net.cpp:399] Eltwise34 -> Eltwise34
I0619 14:56:42.177978 17898 net.cpp:141] Setting up Eltwise34
I0619 14:56:42.177985 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.177989 17898 net.cpp:156] Memory required for data: 2446852608
I0619 14:56:42.177994 17898 layer_factory.hpp:77] Creating layer ReLU69
I0619 14:56:42.178002 17898 net.cpp:91] Creating Layer ReLU69
I0619 14:56:42.178007 17898 net.cpp:425] ReLU69 <- Eltwise34
I0619 14:56:42.178014 17898 net.cpp:386] ReLU69 -> Eltwise34 (in-place)
I0619 14:56:42.178020 17898 net.cpp:141] Setting up ReLU69
I0619 14:56:42.178026 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.178030 17898 net.cpp:156] Memory required for data: 2451046912
I0619 14:56:42.178035 17898 layer_factory.hpp:77] Creating layer Eltwise34_ReLU69_0_split
I0619 14:56:42.178041 17898 net.cpp:91] Creating Layer Eltwise34_ReLU69_0_split
I0619 14:56:42.178045 17898 net.cpp:425] Eltwise34_ReLU69_0_split <- Eltwise34
I0619 14:56:42.178053 17898 net.cpp:399] Eltwise34_ReLU69_0_split -> Eltwise34_ReLU69_0_split_0
I0619 14:56:42.178062 17898 net.cpp:399] Eltwise34_ReLU69_0_split -> Eltwise34_ReLU69_0_split_1
I0619 14:56:42.178103 17898 net.cpp:141] Setting up Eltwise34_ReLU69_0_split
I0619 14:56:42.178110 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.178117 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.178120 17898 net.cpp:156] Memory required for data: 2459435520
I0619 14:56:42.178124 17898 layer_factory.hpp:77] Creating layer Convolution70
I0619 14:56:42.178138 17898 net.cpp:91] Creating Layer Convolution70
I0619 14:56:42.178154 17898 net.cpp:425] Convolution70 <- Eltwise34_ReLU69_0_split_0
I0619 14:56:42.178165 17898 net.cpp:399] Convolution70 -> Convolution70
I0619 14:56:42.178823 17898 net.cpp:141] Setting up Convolution70
I0619 14:56:42.178834 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.178838 17898 net.cpp:156] Memory required for data: 2463629824
I0619 14:56:42.178855 17898 layer_factory.hpp:77] Creating layer BatchNorm70
I0619 14:56:42.178863 17898 net.cpp:91] Creating Layer BatchNorm70
I0619 14:56:42.178867 17898 net.cpp:425] BatchNorm70 <- Convolution70
I0619 14:56:42.178876 17898 net.cpp:386] BatchNorm70 -> Convolution70 (in-place)
I0619 14:56:42.179090 17898 net.cpp:141] Setting up BatchNorm70
I0619 14:56:42.179097 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.179102 17898 net.cpp:156] Memory required for data: 2467824128
I0619 14:56:42.179111 17898 layer_factory.hpp:77] Creating layer Scale70
I0619 14:56:42.179118 17898 net.cpp:91] Creating Layer Scale70
I0619 14:56:42.179123 17898 net.cpp:425] Scale70 <- Convolution70
I0619 14:56:42.179129 17898 net.cpp:386] Scale70 -> Convolution70 (in-place)
I0619 14:56:42.179167 17898 layer_factory.hpp:77] Creating layer Scale70
I0619 14:56:42.179297 17898 net.cpp:141] Setting up Scale70
I0619 14:56:42.179306 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.179309 17898 net.cpp:156] Memory required for data: 2472018432
I0619 14:56:42.179316 17898 layer_factory.hpp:77] Creating layer ReLU70
I0619 14:56:42.179322 17898 net.cpp:91] Creating Layer ReLU70
I0619 14:56:42.179327 17898 net.cpp:425] ReLU70 <- Convolution70
I0619 14:56:42.179337 17898 net.cpp:386] ReLU70 -> Convolution70 (in-place)
I0619 14:56:42.179344 17898 net.cpp:141] Setting up ReLU70
I0619 14:56:42.179350 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.179354 17898 net.cpp:156] Memory required for data: 2476212736
I0619 14:56:42.179358 17898 layer_factory.hpp:77] Creating layer Convolution71
I0619 14:56:42.179370 17898 net.cpp:91] Creating Layer Convolution71
I0619 14:56:42.179375 17898 net.cpp:425] Convolution71 <- Convolution70
I0619 14:56:42.179383 17898 net.cpp:399] Convolution71 -> Convolution71
I0619 14:56:42.179996 17898 net.cpp:141] Setting up Convolution71
I0619 14:56:42.180006 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.180009 17898 net.cpp:156] Memory required for data: 2480407040
I0619 14:56:42.180016 17898 layer_factory.hpp:77] Creating layer BatchNorm71
I0619 14:56:42.180023 17898 net.cpp:91] Creating Layer BatchNorm71
I0619 14:56:42.180028 17898 net.cpp:425] BatchNorm71 <- Convolution71
I0619 14:56:42.180037 17898 net.cpp:386] BatchNorm71 -> Convolution71 (in-place)
I0619 14:56:42.180253 17898 net.cpp:141] Setting up BatchNorm71
I0619 14:56:42.180260 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.180264 17898 net.cpp:156] Memory required for data: 2484601344
I0619 14:56:42.180274 17898 layer_factory.hpp:77] Creating layer Scale71
I0619 14:56:42.180280 17898 net.cpp:91] Creating Layer Scale71
I0619 14:56:42.180285 17898 net.cpp:425] Scale71 <- Convolution71
I0619 14:56:42.180291 17898 net.cpp:386] Scale71 -> Convolution71 (in-place)
I0619 14:56:42.180330 17898 layer_factory.hpp:77] Creating layer Scale71
I0619 14:56:42.180464 17898 net.cpp:141] Setting up Scale71
I0619 14:56:42.180472 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.180476 17898 net.cpp:156] Memory required for data: 2488795648
I0619 14:56:42.180483 17898 layer_factory.hpp:77] Creating layer Eltwise35
I0619 14:56:42.180490 17898 net.cpp:91] Creating Layer Eltwise35
I0619 14:56:42.180498 17898 net.cpp:425] Eltwise35 <- Eltwise34_ReLU69_0_split_1
I0619 14:56:42.180505 17898 net.cpp:425] Eltwise35 <- Convolution71
I0619 14:56:42.180510 17898 net.cpp:399] Eltwise35 -> Eltwise35
I0619 14:56:42.180531 17898 net.cpp:141] Setting up Eltwise35
I0619 14:56:42.180537 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.180541 17898 net.cpp:156] Memory required for data: 2492989952
I0619 14:56:42.180560 17898 layer_factory.hpp:77] Creating layer ReLU71
I0619 14:56:42.180570 17898 net.cpp:91] Creating Layer ReLU71
I0619 14:56:42.180575 17898 net.cpp:425] ReLU71 <- Eltwise35
I0619 14:56:42.180582 17898 net.cpp:386] ReLU71 -> Eltwise35 (in-place)
I0619 14:56:42.180588 17898 net.cpp:141] Setting up ReLU71
I0619 14:56:42.180594 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.180598 17898 net.cpp:156] Memory required for data: 2497184256
I0619 14:56:42.180603 17898 layer_factory.hpp:77] Creating layer Eltwise35_ReLU71_0_split
I0619 14:56:42.180609 17898 net.cpp:91] Creating Layer Eltwise35_ReLU71_0_split
I0619 14:56:42.180613 17898 net.cpp:425] Eltwise35_ReLU71_0_split <- Eltwise35
I0619 14:56:42.180621 17898 net.cpp:399] Eltwise35_ReLU71_0_split -> Eltwise35_ReLU71_0_split_0
I0619 14:56:42.180629 17898 net.cpp:399] Eltwise35_ReLU71_0_split -> Eltwise35_ReLU71_0_split_1
I0619 14:56:42.180670 17898 net.cpp:141] Setting up Eltwise35_ReLU71_0_split
I0619 14:56:42.180677 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.180682 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.180686 17898 net.cpp:156] Memory required for data: 2505572864
I0619 14:56:42.180691 17898 layer_factory.hpp:77] Creating layer Convolution72
I0619 14:56:42.180702 17898 net.cpp:91] Creating Layer Convolution72
I0619 14:56:42.180707 17898 net.cpp:425] Convolution72 <- Eltwise35_ReLU71_0_split_0
I0619 14:56:42.180716 17898 net.cpp:399] Convolution72 -> Convolution72
I0619 14:56:42.181337 17898 net.cpp:141] Setting up Convolution72
I0619 14:56:42.181347 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.181351 17898 net.cpp:156] Memory required for data: 2509767168
I0619 14:56:42.181359 17898 layer_factory.hpp:77] Creating layer BatchNorm72
I0619 14:56:42.181368 17898 net.cpp:91] Creating Layer BatchNorm72
I0619 14:56:42.181373 17898 net.cpp:425] BatchNorm72 <- Convolution72
I0619 14:56:42.181380 17898 net.cpp:386] BatchNorm72 -> Convolution72 (in-place)
I0619 14:56:42.181589 17898 net.cpp:141] Setting up BatchNorm72
I0619 14:56:42.181597 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.181602 17898 net.cpp:156] Memory required for data: 2513961472
I0619 14:56:42.181610 17898 layer_factory.hpp:77] Creating layer Scale72
I0619 14:56:42.181617 17898 net.cpp:91] Creating Layer Scale72
I0619 14:56:42.181622 17898 net.cpp:425] Scale72 <- Convolution72
I0619 14:56:42.181628 17898 net.cpp:386] Scale72 -> Convolution72 (in-place)
I0619 14:56:42.181666 17898 layer_factory.hpp:77] Creating layer Scale72
I0619 14:56:42.181792 17898 net.cpp:141] Setting up Scale72
I0619 14:56:42.181799 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.181803 17898 net.cpp:156] Memory required for data: 2518155776
I0619 14:56:42.181810 17898 layer_factory.hpp:77] Creating layer ReLU72
I0619 14:56:42.181820 17898 net.cpp:91] Creating Layer ReLU72
I0619 14:56:42.181825 17898 net.cpp:425] ReLU72 <- Convolution72
I0619 14:56:42.181831 17898 net.cpp:386] ReLU72 -> Convolution72 (in-place)
I0619 14:56:42.181838 17898 net.cpp:141] Setting up ReLU72
I0619 14:56:42.181844 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.181849 17898 net.cpp:156] Memory required for data: 2522350080
I0619 14:56:42.181852 17898 layer_factory.hpp:77] Creating layer Convolution73
I0619 14:56:42.181864 17898 net.cpp:91] Creating Layer Convolution73
I0619 14:56:42.181869 17898 net.cpp:425] Convolution73 <- Convolution72
I0619 14:56:42.181875 17898 net.cpp:399] Convolution73 -> Convolution73
I0619 14:56:42.182497 17898 net.cpp:141] Setting up Convolution73
I0619 14:56:42.182507 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.182510 17898 net.cpp:156] Memory required for data: 2526544384
I0619 14:56:42.182518 17898 layer_factory.hpp:77] Creating layer BatchNorm73
I0619 14:56:42.182525 17898 net.cpp:91] Creating Layer BatchNorm73
I0619 14:56:42.182530 17898 net.cpp:425] BatchNorm73 <- Convolution73
I0619 14:56:42.182543 17898 net.cpp:386] BatchNorm73 -> Convolution73 (in-place)
I0619 14:56:42.182772 17898 net.cpp:141] Setting up BatchNorm73
I0619 14:56:42.182781 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.182785 17898 net.cpp:156] Memory required for data: 2530738688
I0619 14:56:42.182795 17898 layer_factory.hpp:77] Creating layer Scale73
I0619 14:56:42.182801 17898 net.cpp:91] Creating Layer Scale73
I0619 14:56:42.182806 17898 net.cpp:425] Scale73 <- Convolution73
I0619 14:56:42.182812 17898 net.cpp:386] Scale73 -> Convolution73 (in-place)
I0619 14:56:42.182850 17898 layer_factory.hpp:77] Creating layer Scale73
I0619 14:56:42.182978 17898 net.cpp:141] Setting up Scale73
I0619 14:56:42.182986 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.182991 17898 net.cpp:156] Memory required for data: 2534932992
I0619 14:56:42.182997 17898 layer_factory.hpp:77] Creating layer Eltwise36
I0619 14:56:42.183007 17898 net.cpp:91] Creating Layer Eltwise36
I0619 14:56:42.183012 17898 net.cpp:425] Eltwise36 <- Eltwise35_ReLU71_0_split_1
I0619 14:56:42.183017 17898 net.cpp:425] Eltwise36 <- Convolution73
I0619 14:56:42.183023 17898 net.cpp:399] Eltwise36 -> Eltwise36
I0619 14:56:42.183043 17898 net.cpp:141] Setting up Eltwise36
I0619 14:56:42.183050 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.183054 17898 net.cpp:156] Memory required for data: 2539127296
I0619 14:56:42.183058 17898 layer_factory.hpp:77] Creating layer ReLU73
I0619 14:56:42.183069 17898 net.cpp:91] Creating Layer ReLU73
I0619 14:56:42.183074 17898 net.cpp:425] ReLU73 <- Eltwise36
I0619 14:56:42.183080 17898 net.cpp:386] ReLU73 -> Eltwise36 (in-place)
I0619 14:56:42.183087 17898 net.cpp:141] Setting up ReLU73
I0619 14:56:42.183092 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.183096 17898 net.cpp:156] Memory required for data: 2543321600
I0619 14:56:42.183100 17898 layer_factory.hpp:77] Creating layer Eltwise36_ReLU73_0_split
I0619 14:56:42.183107 17898 net.cpp:91] Creating Layer Eltwise36_ReLU73_0_split
I0619 14:56:42.183111 17898 net.cpp:425] Eltwise36_ReLU73_0_split <- Eltwise36
I0619 14:56:42.183118 17898 net.cpp:399] Eltwise36_ReLU73_0_split -> Eltwise36_ReLU73_0_split_0
I0619 14:56:42.183126 17898 net.cpp:399] Eltwise36_ReLU73_0_split -> Eltwise36_ReLU73_0_split_1
I0619 14:56:42.183166 17898 net.cpp:141] Setting up Eltwise36_ReLU73_0_split
I0619 14:56:42.183173 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.183178 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.183182 17898 net.cpp:156] Memory required for data: 2551710208
I0619 14:56:42.183187 17898 layer_factory.hpp:77] Creating layer Pooling2
I0619 14:56:42.183193 17898 net.cpp:91] Creating Layer Pooling2
I0619 14:56:42.183198 17898 net.cpp:425] Pooling2 <- Eltwise36_ReLU73_0_split_0
I0619 14:56:42.183204 17898 net.cpp:399] Pooling2 -> Pooling2
I0619 14:56:42.183231 17898 net.cpp:141] Setting up Pooling2
I0619 14:56:42.183238 17898 net.cpp:148] Top shape: 128 32 8 8 (262144)
I0619 14:56:42.183241 17898 net.cpp:156] Memory required for data: 2552758784
I0619 14:56:42.183245 17898 layer_factory.hpp:77] Creating layer Input2
I0619 14:56:42.183254 17898 net.cpp:91] Creating Layer Input2
I0619 14:56:42.183259 17898 net.cpp:399] Input2 -> Input2
I0619 14:56:42.183286 17898 net.cpp:141] Setting up Input2
I0619 14:56:42.183293 17898 net.cpp:148] Top shape: 128 32 8 8 (262144)
I0619 14:56:42.183296 17898 net.cpp:156] Memory required for data: 2553807360
I0619 14:56:42.183300 17898 layer_factory.hpp:77] Creating layer Concat2
I0619 14:56:42.183307 17898 net.cpp:91] Creating Layer Concat2
I0619 14:56:42.183312 17898 net.cpp:425] Concat2 <- Pooling2
I0619 14:56:42.183321 17898 net.cpp:425] Concat2 <- Input2
I0619 14:56:42.183328 17898 net.cpp:399] Concat2 -> Concat2
I0619 14:56:42.183352 17898 net.cpp:141] Setting up Concat2
I0619 14:56:42.183359 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.183363 17898 net.cpp:156] Memory required for data: 2555904512
I0619 14:56:42.183367 17898 layer_factory.hpp:77] Creating layer Convolution74
I0619 14:56:42.183394 17898 net.cpp:91] Creating Layer Convolution74
I0619 14:56:42.183400 17898 net.cpp:425] Convolution74 <- Eltwise36_ReLU73_0_split_1
I0619 14:56:42.183408 17898 net.cpp:399] Convolution74 -> Convolution74
I0619 14:56:42.185063 17898 net.cpp:141] Setting up Convolution74
I0619 14:56:42.185078 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.185083 17898 net.cpp:156] Memory required for data: 2558001664
I0619 14:56:42.185159 17898 layer_factory.hpp:77] Creating layer BatchNorm74
I0619 14:56:42.185170 17898 net.cpp:91] Creating Layer BatchNorm74
I0619 14:56:42.185176 17898 net.cpp:425] BatchNorm74 <- Convolution74
I0619 14:56:42.185184 17898 net.cpp:386] BatchNorm74 -> Convolution74 (in-place)
I0619 14:56:42.185411 17898 net.cpp:141] Setting up BatchNorm74
I0619 14:56:42.185420 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.185425 17898 net.cpp:156] Memory required for data: 2560098816
I0619 14:56:42.185433 17898 layer_factory.hpp:77] Creating layer Scale74
I0619 14:56:42.185443 17898 net.cpp:91] Creating Layer Scale74
I0619 14:56:42.185448 17898 net.cpp:425] Scale74 <- Convolution74
I0619 14:56:42.185454 17898 net.cpp:386] Scale74 -> Convolution74 (in-place)
I0619 14:56:42.185493 17898 layer_factory.hpp:77] Creating layer Scale74
I0619 14:56:42.185633 17898 net.cpp:141] Setting up Scale74
I0619 14:56:42.185642 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.185645 17898 net.cpp:156] Memory required for data: 2562195968
I0619 14:56:42.185652 17898 layer_factory.hpp:77] Creating layer ReLU74
I0619 14:56:42.185659 17898 net.cpp:91] Creating Layer ReLU74
I0619 14:56:42.185664 17898 net.cpp:425] ReLU74 <- Convolution74
I0619 14:56:42.185672 17898 net.cpp:386] ReLU74 -> Convolution74 (in-place)
I0619 14:56:42.185679 17898 net.cpp:141] Setting up ReLU74
I0619 14:56:42.185685 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.185689 17898 net.cpp:156] Memory required for data: 2564293120
I0619 14:56:42.185693 17898 layer_factory.hpp:77] Creating layer Convolution75
I0619 14:56:42.185705 17898 net.cpp:91] Creating Layer Convolution75
I0619 14:56:42.185710 17898 net.cpp:425] Convolution75 <- Convolution74
I0619 14:56:42.185717 17898 net.cpp:399] Convolution75 -> Convolution75
I0619 14:56:42.187408 17898 net.cpp:141] Setting up Convolution75
I0619 14:56:42.187419 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.187423 17898 net.cpp:156] Memory required for data: 2566390272
I0619 14:56:42.187432 17898 layer_factory.hpp:77] Creating layer BatchNorm75
I0619 14:56:42.187440 17898 net.cpp:91] Creating Layer BatchNorm75
I0619 14:56:42.187445 17898 net.cpp:425] BatchNorm75 <- Convolution75
I0619 14:56:42.187453 17898 net.cpp:386] BatchNorm75 -> Convolution75 (in-place)
I0619 14:56:42.187676 17898 net.cpp:141] Setting up BatchNorm75
I0619 14:56:42.187685 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.187688 17898 net.cpp:156] Memory required for data: 2568487424
I0619 14:56:42.187697 17898 layer_factory.hpp:77] Creating layer Scale75
I0619 14:56:42.187705 17898 net.cpp:91] Creating Layer Scale75
I0619 14:56:42.187710 17898 net.cpp:425] Scale75 <- Convolution75
I0619 14:56:42.187716 17898 net.cpp:386] Scale75 -> Convolution75 (in-place)
I0619 14:56:42.187757 17898 layer_factory.hpp:77] Creating layer Scale75
I0619 14:56:42.187890 17898 net.cpp:141] Setting up Scale75
I0619 14:56:42.187897 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.187901 17898 net.cpp:156] Memory required for data: 2570584576
I0619 14:56:42.187909 17898 layer_factory.hpp:77] Creating layer Eltwise37
I0619 14:56:42.187916 17898 net.cpp:91] Creating Layer Eltwise37
I0619 14:56:42.187922 17898 net.cpp:425] Eltwise37 <- Concat2
I0619 14:56:42.187927 17898 net.cpp:425] Eltwise37 <- Convolution75
I0619 14:56:42.187935 17898 net.cpp:399] Eltwise37 -> Eltwise37
I0619 14:56:42.187957 17898 net.cpp:141] Setting up Eltwise37
I0619 14:56:42.187963 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.187970 17898 net.cpp:156] Memory required for data: 2572681728
I0619 14:56:42.187988 17898 layer_factory.hpp:77] Creating layer ReLU75
I0619 14:56:42.187994 17898 net.cpp:91] Creating Layer ReLU75
I0619 14:56:42.187999 17898 net.cpp:425] ReLU75 <- Eltwise37
I0619 14:56:42.188009 17898 net.cpp:386] ReLU75 -> Eltwise37 (in-place)
I0619 14:56:42.188015 17898 net.cpp:141] Setting up ReLU75
I0619 14:56:42.188021 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.188025 17898 net.cpp:156] Memory required for data: 2574778880
I0619 14:56:42.188030 17898 layer_factory.hpp:77] Creating layer Eltwise37_ReLU75_0_split
I0619 14:56:42.188035 17898 net.cpp:91] Creating Layer Eltwise37_ReLU75_0_split
I0619 14:56:42.188040 17898 net.cpp:425] Eltwise37_ReLU75_0_split <- Eltwise37
I0619 14:56:42.188045 17898 net.cpp:399] Eltwise37_ReLU75_0_split -> Eltwise37_ReLU75_0_split_0
I0619 14:56:42.188053 17898 net.cpp:399] Eltwise37_ReLU75_0_split -> Eltwise37_ReLU75_0_split_1
I0619 14:56:42.188096 17898 net.cpp:141] Setting up Eltwise37_ReLU75_0_split
I0619 14:56:42.188102 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.188108 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.188112 17898 net.cpp:156] Memory required for data: 2578973184
I0619 14:56:42.188117 17898 layer_factory.hpp:77] Creating layer Convolution76
I0619 14:56:42.188127 17898 net.cpp:91] Creating Layer Convolution76
I0619 14:56:42.188132 17898 net.cpp:425] Convolution76 <- Eltwise37_ReLU75_0_split_0
I0619 14:56:42.188140 17898 net.cpp:399] Convolution76 -> Convolution76
I0619 14:56:42.189823 17898 net.cpp:141] Setting up Convolution76
I0619 14:56:42.189833 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.189837 17898 net.cpp:156] Memory required for data: 2581070336
I0619 14:56:42.189844 17898 layer_factory.hpp:77] Creating layer BatchNorm76
I0619 14:56:42.189852 17898 net.cpp:91] Creating Layer BatchNorm76
I0619 14:56:42.189857 17898 net.cpp:425] BatchNorm76 <- Convolution76
I0619 14:56:42.189865 17898 net.cpp:386] BatchNorm76 -> Convolution76 (in-place)
I0619 14:56:42.190083 17898 net.cpp:141] Setting up BatchNorm76
I0619 14:56:42.190090 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.190094 17898 net.cpp:156] Memory required for data: 2583167488
I0619 14:56:42.190104 17898 layer_factory.hpp:77] Creating layer Scale76
I0619 14:56:42.190110 17898 net.cpp:91] Creating Layer Scale76
I0619 14:56:42.190115 17898 net.cpp:425] Scale76 <- Convolution76
I0619 14:56:42.190124 17898 net.cpp:386] Scale76 -> Convolution76 (in-place)
I0619 14:56:42.190160 17898 layer_factory.hpp:77] Creating layer Scale76
I0619 14:56:42.190302 17898 net.cpp:141] Setting up Scale76
I0619 14:56:42.190310 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.190315 17898 net.cpp:156] Memory required for data: 2585264640
I0619 14:56:42.190322 17898 layer_factory.hpp:77] Creating layer ReLU76
I0619 14:56:42.190330 17898 net.cpp:91] Creating Layer ReLU76
I0619 14:56:42.190333 17898 net.cpp:425] ReLU76 <- Convolution76
I0619 14:56:42.190340 17898 net.cpp:386] ReLU76 -> Convolution76 (in-place)
I0619 14:56:42.190346 17898 net.cpp:141] Setting up ReLU76
I0619 14:56:42.190359 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.190363 17898 net.cpp:156] Memory required for data: 2587361792
I0619 14:56:42.190368 17898 layer_factory.hpp:77] Creating layer Convolution77
I0619 14:56:42.190382 17898 net.cpp:91] Creating Layer Convolution77
I0619 14:56:42.190387 17898 net.cpp:425] Convolution77 <- Convolution76
I0619 14:56:42.190394 17898 net.cpp:399] Convolution77 -> Convolution77
I0619 14:56:42.192028 17898 net.cpp:141] Setting up Convolution77
I0619 14:56:42.192037 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.192041 17898 net.cpp:156] Memory required for data: 2589458944
I0619 14:56:42.192049 17898 layer_factory.hpp:77] Creating layer BatchNorm77
I0619 14:56:42.192057 17898 net.cpp:91] Creating Layer BatchNorm77
I0619 14:56:42.192062 17898 net.cpp:425] BatchNorm77 <- Convolution77
I0619 14:56:42.192075 17898 net.cpp:386] BatchNorm77 -> Convolution77 (in-place)
I0619 14:56:42.192294 17898 net.cpp:141] Setting up BatchNorm77
I0619 14:56:42.192303 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.192307 17898 net.cpp:156] Memory required for data: 2591556096
I0619 14:56:42.192315 17898 layer_factory.hpp:77] Creating layer Scale77
I0619 14:56:42.192324 17898 net.cpp:91] Creating Layer Scale77
I0619 14:56:42.192329 17898 net.cpp:425] Scale77 <- Convolution77
I0619 14:56:42.192335 17898 net.cpp:386] Scale77 -> Convolution77 (in-place)
I0619 14:56:42.192374 17898 layer_factory.hpp:77] Creating layer Scale77
I0619 14:56:42.192499 17898 net.cpp:141] Setting up Scale77
I0619 14:56:42.192507 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.192510 17898 net.cpp:156] Memory required for data: 2593653248
I0619 14:56:42.192517 17898 layer_factory.hpp:77] Creating layer Eltwise38
I0619 14:56:42.192525 17898 net.cpp:91] Creating Layer Eltwise38
I0619 14:56:42.192530 17898 net.cpp:425] Eltwise38 <- Eltwise37_ReLU75_0_split_1
I0619 14:56:42.192536 17898 net.cpp:425] Eltwise38 <- Convolution77
I0619 14:56:42.192544 17898 net.cpp:399] Eltwise38 -> Eltwise38
I0619 14:56:42.192564 17898 net.cpp:141] Setting up Eltwise38
I0619 14:56:42.192570 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.192574 17898 net.cpp:156] Memory required for data: 2595750400
I0619 14:56:42.192577 17898 layer_factory.hpp:77] Creating layer ReLU77
I0619 14:56:42.192584 17898 net.cpp:91] Creating Layer ReLU77
I0619 14:56:42.192587 17898 net.cpp:425] ReLU77 <- Eltwise38
I0619 14:56:42.192595 17898 net.cpp:386] ReLU77 -> Eltwise38 (in-place)
I0619 14:56:42.192602 17898 net.cpp:141] Setting up ReLU77
I0619 14:56:42.192607 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.192611 17898 net.cpp:156] Memory required for data: 2597847552
I0619 14:56:42.192615 17898 layer_factory.hpp:77] Creating layer Eltwise38_ReLU77_0_split
I0619 14:56:42.192621 17898 net.cpp:91] Creating Layer Eltwise38_ReLU77_0_split
I0619 14:56:42.192625 17898 net.cpp:425] Eltwise38_ReLU77_0_split <- Eltwise38
I0619 14:56:42.192631 17898 net.cpp:399] Eltwise38_ReLU77_0_split -> Eltwise38_ReLU77_0_split_0
I0619 14:56:42.192638 17898 net.cpp:399] Eltwise38_ReLU77_0_split -> Eltwise38_ReLU77_0_split_1
I0619 14:56:42.192677 17898 net.cpp:141] Setting up Eltwise38_ReLU77_0_split
I0619 14:56:42.192683 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.192688 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.192692 17898 net.cpp:156] Memory required for data: 2602041856
I0619 14:56:42.192697 17898 layer_factory.hpp:77] Creating layer Convolution78
I0619 14:56:42.192705 17898 net.cpp:91] Creating Layer Convolution78
I0619 14:56:42.192709 17898 net.cpp:425] Convolution78 <- Eltwise38_ReLU77_0_split_0
I0619 14:56:42.192718 17898 net.cpp:399] Convolution78 -> Convolution78
I0619 14:56:42.194326 17898 net.cpp:141] Setting up Convolution78
I0619 14:56:42.194336 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.194339 17898 net.cpp:156] Memory required for data: 2604139008
I0619 14:56:42.194347 17898 layer_factory.hpp:77] Creating layer BatchNorm78
I0619 14:56:42.194360 17898 net.cpp:91] Creating Layer BatchNorm78
I0619 14:56:42.194365 17898 net.cpp:425] BatchNorm78 <- Convolution78
I0619 14:56:42.194372 17898 net.cpp:386] BatchNorm78 -> Convolution78 (in-place)
I0619 14:56:42.194588 17898 net.cpp:141] Setting up BatchNorm78
I0619 14:56:42.194597 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.194600 17898 net.cpp:156] Memory required for data: 2606236160
I0619 14:56:42.194609 17898 layer_factory.hpp:77] Creating layer Scale78
I0619 14:56:42.194617 17898 net.cpp:91] Creating Layer Scale78
I0619 14:56:42.194622 17898 net.cpp:425] Scale78 <- Convolution78
I0619 14:56:42.194629 17898 net.cpp:386] Scale78 -> Convolution78 (in-place)
I0619 14:56:42.194666 17898 layer_factory.hpp:77] Creating layer Scale78
I0619 14:56:42.194794 17898 net.cpp:141] Setting up Scale78
I0619 14:56:42.194802 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.194820 17898 net.cpp:156] Memory required for data: 2608333312
I0619 14:56:42.194828 17898 layer_factory.hpp:77] Creating layer ReLU78
I0619 14:56:42.194834 17898 net.cpp:91] Creating Layer ReLU78
I0619 14:56:42.194839 17898 net.cpp:425] ReLU78 <- Convolution78
I0619 14:56:42.194845 17898 net.cpp:386] ReLU78 -> Convolution78 (in-place)
I0619 14:56:42.194851 17898 net.cpp:141] Setting up ReLU78
I0619 14:56:42.194857 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.194861 17898 net.cpp:156] Memory required for data: 2610430464
I0619 14:56:42.194865 17898 layer_factory.hpp:77] Creating layer Convolution79
I0619 14:56:42.194877 17898 net.cpp:91] Creating Layer Convolution79
I0619 14:56:42.194881 17898 net.cpp:425] Convolution79 <- Convolution78
I0619 14:56:42.194890 17898 net.cpp:399] Convolution79 -> Convolution79
I0619 14:56:42.196496 17898 net.cpp:141] Setting up Convolution79
I0619 14:56:42.196506 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.196509 17898 net.cpp:156] Memory required for data: 2612527616
I0619 14:56:42.196516 17898 layer_factory.hpp:77] Creating layer BatchNorm79
I0619 14:56:42.196524 17898 net.cpp:91] Creating Layer BatchNorm79
I0619 14:56:42.196529 17898 net.cpp:425] BatchNorm79 <- Convolution79
I0619 14:56:42.196538 17898 net.cpp:386] BatchNorm79 -> Convolution79 (in-place)
I0619 14:56:42.196748 17898 net.cpp:141] Setting up BatchNorm79
I0619 14:56:42.196755 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.196759 17898 net.cpp:156] Memory required for data: 2614624768
I0619 14:56:42.196768 17898 layer_factory.hpp:77] Creating layer Scale79
I0619 14:56:42.196776 17898 net.cpp:91] Creating Layer Scale79
I0619 14:56:42.196781 17898 net.cpp:425] Scale79 <- Convolution79
I0619 14:56:42.196786 17898 net.cpp:386] Scale79 -> Convolution79 (in-place)
I0619 14:56:42.196825 17898 layer_factory.hpp:77] Creating layer Scale79
I0619 14:56:42.196946 17898 net.cpp:141] Setting up Scale79
I0619 14:56:42.196954 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.196959 17898 net.cpp:156] Memory required for data: 2616721920
I0619 14:56:42.196965 17898 layer_factory.hpp:77] Creating layer Eltwise39
I0619 14:56:42.196975 17898 net.cpp:91] Creating Layer Eltwise39
I0619 14:56:42.196980 17898 net.cpp:425] Eltwise39 <- Eltwise38_ReLU77_0_split_1
I0619 14:56:42.196985 17898 net.cpp:425] Eltwise39 <- Convolution79
I0619 14:56:42.196991 17898 net.cpp:399] Eltwise39 -> Eltwise39
I0619 14:56:42.197013 17898 net.cpp:141] Setting up Eltwise39
I0619 14:56:42.197021 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.197023 17898 net.cpp:156] Memory required for data: 2618819072
I0619 14:56:42.197027 17898 layer_factory.hpp:77] Creating layer ReLU79
I0619 14:56:42.197033 17898 net.cpp:91] Creating Layer ReLU79
I0619 14:56:42.197038 17898 net.cpp:425] ReLU79 <- Eltwise39
I0619 14:56:42.197043 17898 net.cpp:386] ReLU79 -> Eltwise39 (in-place)
I0619 14:56:42.197049 17898 net.cpp:141] Setting up ReLU79
I0619 14:56:42.197055 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.197058 17898 net.cpp:156] Memory required for data: 2620916224
I0619 14:56:42.197062 17898 layer_factory.hpp:77] Creating layer Eltwise39_ReLU79_0_split
I0619 14:56:42.197070 17898 net.cpp:91] Creating Layer Eltwise39_ReLU79_0_split
I0619 14:56:42.197074 17898 net.cpp:425] Eltwise39_ReLU79_0_split <- Eltwise39
I0619 14:56:42.197080 17898 net.cpp:399] Eltwise39_ReLU79_0_split -> Eltwise39_ReLU79_0_split_0
I0619 14:56:42.197088 17898 net.cpp:399] Eltwise39_ReLU79_0_split -> Eltwise39_ReLU79_0_split_1
I0619 14:56:42.197134 17898 net.cpp:141] Setting up Eltwise39_ReLU79_0_split
I0619 14:56:42.197139 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.197144 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.197149 17898 net.cpp:156] Memory required for data: 2625110528
I0619 14:56:42.197152 17898 layer_factory.hpp:77] Creating layer Convolution80
I0619 14:56:42.197161 17898 net.cpp:91] Creating Layer Convolution80
I0619 14:56:42.197170 17898 net.cpp:425] Convolution80 <- Eltwise39_ReLU79_0_split_0
I0619 14:56:42.197187 17898 net.cpp:399] Convolution80 -> Convolution80
I0619 14:56:42.198810 17898 net.cpp:141] Setting up Convolution80
I0619 14:56:42.198823 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.198827 17898 net.cpp:156] Memory required for data: 2627207680
I0619 14:56:42.198834 17898 layer_factory.hpp:77] Creating layer BatchNorm80
I0619 14:56:42.198843 17898 net.cpp:91] Creating Layer BatchNorm80
I0619 14:56:42.198848 17898 net.cpp:425] BatchNorm80 <- Convolution80
I0619 14:56:42.198853 17898 net.cpp:386] BatchNorm80 -> Convolution80 (in-place)
I0619 14:56:42.199061 17898 net.cpp:141] Setting up BatchNorm80
I0619 14:56:42.199069 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.199074 17898 net.cpp:156] Memory required for data: 2629304832
I0619 14:56:42.199081 17898 layer_factory.hpp:77] Creating layer Scale80
I0619 14:56:42.199089 17898 net.cpp:91] Creating Layer Scale80
I0619 14:56:42.199093 17898 net.cpp:425] Scale80 <- Convolution80
I0619 14:56:42.199098 17898 net.cpp:386] Scale80 -> Convolution80 (in-place)
I0619 14:56:42.199138 17898 layer_factory.hpp:77] Creating layer Scale80
I0619 14:56:42.199265 17898 net.cpp:141] Setting up Scale80
I0619 14:56:42.199275 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.199278 17898 net.cpp:156] Memory required for data: 2631401984
I0619 14:56:42.199285 17898 layer_factory.hpp:77] Creating layer ReLU80
I0619 14:56:42.199291 17898 net.cpp:91] Creating Layer ReLU80
I0619 14:56:42.199295 17898 net.cpp:425] ReLU80 <- Convolution80
I0619 14:56:42.199301 17898 net.cpp:386] ReLU80 -> Convolution80 (in-place)
I0619 14:56:42.199307 17898 net.cpp:141] Setting up ReLU80
I0619 14:56:42.199313 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.199317 17898 net.cpp:156] Memory required for data: 2633499136
I0619 14:56:42.199321 17898 layer_factory.hpp:77] Creating layer Convolution81
I0619 14:56:42.199331 17898 net.cpp:91] Creating Layer Convolution81
I0619 14:56:42.199337 17898 net.cpp:425] Convolution81 <- Convolution80
I0619 14:56:42.199344 17898 net.cpp:399] Convolution81 -> Convolution81
I0619 14:56:42.201601 17898 net.cpp:141] Setting up Convolution81
I0619 14:56:42.201616 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.201619 17898 net.cpp:156] Memory required for data: 2635596288
I0619 14:56:42.201627 17898 layer_factory.hpp:77] Creating layer BatchNorm81
I0619 14:56:42.201637 17898 net.cpp:91] Creating Layer BatchNorm81
I0619 14:56:42.201642 17898 net.cpp:425] BatchNorm81 <- Convolution81
I0619 14:56:42.201649 17898 net.cpp:386] BatchNorm81 -> Convolution81 (in-place)
I0619 14:56:42.201860 17898 net.cpp:141] Setting up BatchNorm81
I0619 14:56:42.201869 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.201872 17898 net.cpp:156] Memory required for data: 2637693440
I0619 14:56:42.201881 17898 layer_factory.hpp:77] Creating layer Scale81
I0619 14:56:42.201889 17898 net.cpp:91] Creating Layer Scale81
I0619 14:56:42.201894 17898 net.cpp:425] Scale81 <- Convolution81
I0619 14:56:42.201900 17898 net.cpp:386] Scale81 -> Convolution81 (in-place)
I0619 14:56:42.201938 17898 layer_factory.hpp:77] Creating layer Scale81
I0619 14:56:42.202067 17898 net.cpp:141] Setting up Scale81
I0619 14:56:42.202076 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.202080 17898 net.cpp:156] Memory required for data: 2639790592
I0619 14:56:42.202087 17898 layer_factory.hpp:77] Creating layer Eltwise40
I0619 14:56:42.202095 17898 net.cpp:91] Creating Layer Eltwise40
I0619 14:56:42.202100 17898 net.cpp:425] Eltwise40 <- Eltwise39_ReLU79_0_split_1
I0619 14:56:42.202106 17898 net.cpp:425] Eltwise40 <- Convolution81
I0619 14:56:42.202112 17898 net.cpp:399] Eltwise40 -> Eltwise40
I0619 14:56:42.202133 17898 net.cpp:141] Setting up Eltwise40
I0619 14:56:42.202139 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.202143 17898 net.cpp:156] Memory required for data: 2641887744
I0619 14:56:42.202153 17898 layer_factory.hpp:77] Creating layer ReLU81
I0619 14:56:42.202174 17898 net.cpp:91] Creating Layer ReLU81
I0619 14:56:42.202180 17898 net.cpp:425] ReLU81 <- Eltwise40
I0619 14:56:42.202186 17898 net.cpp:386] ReLU81 -> Eltwise40 (in-place)
I0619 14:56:42.202193 17898 net.cpp:141] Setting up ReLU81
I0619 14:56:42.202199 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.202203 17898 net.cpp:156] Memory required for data: 2643984896
I0619 14:56:42.202208 17898 layer_factory.hpp:77] Creating layer Eltwise40_ReLU81_0_split
I0619 14:56:42.202214 17898 net.cpp:91] Creating Layer Eltwise40_ReLU81_0_split
I0619 14:56:42.202217 17898 net.cpp:425] Eltwise40_ReLU81_0_split <- Eltwise40
I0619 14:56:42.202224 17898 net.cpp:399] Eltwise40_ReLU81_0_split -> Eltwise40_ReLU81_0_split_0
I0619 14:56:42.202232 17898 net.cpp:399] Eltwise40_ReLU81_0_split -> Eltwise40_ReLU81_0_split_1
I0619 14:56:42.202277 17898 net.cpp:141] Setting up Eltwise40_ReLU81_0_split
I0619 14:56:42.202285 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.202289 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.202293 17898 net.cpp:156] Memory required for data: 2648179200
I0619 14:56:42.202297 17898 layer_factory.hpp:77] Creating layer Convolution82
I0619 14:56:42.202309 17898 net.cpp:91] Creating Layer Convolution82
I0619 14:56:42.202314 17898 net.cpp:425] Convolution82 <- Eltwise40_ReLU81_0_split_0
I0619 14:56:42.202322 17898 net.cpp:399] Convolution82 -> Convolution82
I0619 14:56:42.203943 17898 net.cpp:141] Setting up Convolution82
I0619 14:56:42.203954 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.203958 17898 net.cpp:156] Memory required for data: 2650276352
I0619 14:56:42.203965 17898 layer_factory.hpp:77] Creating layer BatchNorm82
I0619 14:56:42.203974 17898 net.cpp:91] Creating Layer BatchNorm82
I0619 14:56:42.203980 17898 net.cpp:425] BatchNorm82 <- Convolution82
I0619 14:56:42.203986 17898 net.cpp:386] BatchNorm82 -> Convolution82 (in-place)
I0619 14:56:42.204201 17898 net.cpp:141] Setting up BatchNorm82
I0619 14:56:42.204210 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.204212 17898 net.cpp:156] Memory required for data: 2652373504
I0619 14:56:42.204221 17898 layer_factory.hpp:77] Creating layer Scale82
I0619 14:56:42.204231 17898 net.cpp:91] Creating Layer Scale82
I0619 14:56:42.204236 17898 net.cpp:425] Scale82 <- Convolution82
I0619 14:56:42.204241 17898 net.cpp:386] Scale82 -> Convolution82 (in-place)
I0619 14:56:42.204277 17898 layer_factory.hpp:77] Creating layer Scale82
I0619 14:56:42.204404 17898 net.cpp:141] Setting up Scale82
I0619 14:56:42.204412 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.204416 17898 net.cpp:156] Memory required for data: 2654470656
I0619 14:56:42.204422 17898 layer_factory.hpp:77] Creating layer ReLU82
I0619 14:56:42.204429 17898 net.cpp:91] Creating Layer ReLU82
I0619 14:56:42.204433 17898 net.cpp:425] ReLU82 <- Convolution82
I0619 14:56:42.204442 17898 net.cpp:386] ReLU82 -> Convolution82 (in-place)
I0619 14:56:42.204448 17898 net.cpp:141] Setting up ReLU82
I0619 14:56:42.204454 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.204457 17898 net.cpp:156] Memory required for data: 2656567808
I0619 14:56:42.204462 17898 layer_factory.hpp:77] Creating layer Convolution83
I0619 14:56:42.204480 17898 net.cpp:91] Creating Layer Convolution83
I0619 14:56:42.204484 17898 net.cpp:425] Convolution83 <- Convolution82
I0619 14:56:42.204491 17898 net.cpp:399] Convolution83 -> Convolution83
I0619 14:56:42.206112 17898 net.cpp:141] Setting up Convolution83
I0619 14:56:42.206122 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.206126 17898 net.cpp:156] Memory required for data: 2658664960
I0619 14:56:42.206133 17898 layer_factory.hpp:77] Creating layer BatchNorm83
I0619 14:56:42.206142 17898 net.cpp:91] Creating Layer BatchNorm83
I0619 14:56:42.206147 17898 net.cpp:425] BatchNorm83 <- Convolution83
I0619 14:56:42.206154 17898 net.cpp:386] BatchNorm83 -> Convolution83 (in-place)
I0619 14:56:42.206385 17898 net.cpp:141] Setting up BatchNorm83
I0619 14:56:42.206409 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.206414 17898 net.cpp:156] Memory required for data: 2660762112
I0619 14:56:42.206423 17898 layer_factory.hpp:77] Creating layer Scale83
I0619 14:56:42.206431 17898 net.cpp:91] Creating Layer Scale83
I0619 14:56:42.206436 17898 net.cpp:425] Scale83 <- Convolution83
I0619 14:56:42.206442 17898 net.cpp:386] Scale83 -> Convolution83 (in-place)
I0619 14:56:42.206485 17898 layer_factory.hpp:77] Creating layer Scale83
I0619 14:56:42.206614 17898 net.cpp:141] Setting up Scale83
I0619 14:56:42.206622 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.206626 17898 net.cpp:156] Memory required for data: 2662859264
I0619 14:56:42.206634 17898 layer_factory.hpp:77] Creating layer Eltwise41
I0619 14:56:42.206640 17898 net.cpp:91] Creating Layer Eltwise41
I0619 14:56:42.206645 17898 net.cpp:425] Eltwise41 <- Eltwise40_ReLU81_0_split_1
I0619 14:56:42.206650 17898 net.cpp:425] Eltwise41 <- Convolution83
I0619 14:56:42.206660 17898 net.cpp:399] Eltwise41 -> Eltwise41
I0619 14:56:42.206678 17898 net.cpp:141] Setting up Eltwise41
I0619 14:56:42.206686 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.206689 17898 net.cpp:156] Memory required for data: 2664956416
I0619 14:56:42.206693 17898 layer_factory.hpp:77] Creating layer ReLU83
I0619 14:56:42.206703 17898 net.cpp:91] Creating Layer ReLU83
I0619 14:56:42.206707 17898 net.cpp:425] ReLU83 <- Eltwise41
I0619 14:56:42.206715 17898 net.cpp:386] ReLU83 -> Eltwise41 (in-place)
I0619 14:56:42.206723 17898 net.cpp:141] Setting up ReLU83
I0619 14:56:42.206729 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.206732 17898 net.cpp:156] Memory required for data: 2667053568
I0619 14:56:42.206737 17898 layer_factory.hpp:77] Creating layer Eltwise41_ReLU83_0_split
I0619 14:56:42.206743 17898 net.cpp:91] Creating Layer Eltwise41_ReLU83_0_split
I0619 14:56:42.206748 17898 net.cpp:425] Eltwise41_ReLU83_0_split <- Eltwise41
I0619 14:56:42.206753 17898 net.cpp:399] Eltwise41_ReLU83_0_split -> Eltwise41_ReLU83_0_split_0
I0619 14:56:42.206760 17898 net.cpp:399] Eltwise41_ReLU83_0_split -> Eltwise41_ReLU83_0_split_1
I0619 14:56:42.206799 17898 net.cpp:141] Setting up Eltwise41_ReLU83_0_split
I0619 14:56:42.206804 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.206809 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.206814 17898 net.cpp:156] Memory required for data: 2671247872
I0619 14:56:42.206817 17898 layer_factory.hpp:77] Creating layer Convolution84
I0619 14:56:42.206826 17898 net.cpp:91] Creating Layer Convolution84
I0619 14:56:42.206831 17898 net.cpp:425] Convolution84 <- Eltwise41_ReLU83_0_split_0
I0619 14:56:42.206840 17898 net.cpp:399] Convolution84 -> Convolution84
I0619 14:56:42.208446 17898 net.cpp:141] Setting up Convolution84
I0619 14:56:42.208454 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.208458 17898 net.cpp:156] Memory required for data: 2673345024
I0619 14:56:42.208465 17898 layer_factory.hpp:77] Creating layer BatchNorm84
I0619 14:56:42.208472 17898 net.cpp:91] Creating Layer BatchNorm84
I0619 14:56:42.208477 17898 net.cpp:425] BatchNorm84 <- Convolution84
I0619 14:56:42.208485 17898 net.cpp:386] BatchNorm84 -> Convolution84 (in-place)
I0619 14:56:42.208700 17898 net.cpp:141] Setting up BatchNorm84
I0619 14:56:42.208709 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.208711 17898 net.cpp:156] Memory required for data: 2675442176
I0619 14:56:42.208720 17898 layer_factory.hpp:77] Creating layer Scale84
I0619 14:56:42.208726 17898 net.cpp:91] Creating Layer Scale84
I0619 14:56:42.208731 17898 net.cpp:425] Scale84 <- Convolution84
I0619 14:56:42.208739 17898 net.cpp:386] Scale84 -> Convolution84 (in-place)
I0619 14:56:42.208775 17898 layer_factory.hpp:77] Creating layer Scale84
I0619 14:56:42.208899 17898 net.cpp:141] Setting up Scale84
I0619 14:56:42.208907 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.208910 17898 net.cpp:156] Memory required for data: 2677539328
I0619 14:56:42.208940 17898 layer_factory.hpp:77] Creating layer ReLU84
I0619 14:56:42.208946 17898 net.cpp:91] Creating Layer ReLU84
I0619 14:56:42.208951 17898 net.cpp:425] ReLU84 <- Convolution84
I0619 14:56:42.208956 17898 net.cpp:386] ReLU84 -> Convolution84 (in-place)
I0619 14:56:42.208963 17898 net.cpp:141] Setting up ReLU84
I0619 14:56:42.208969 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.208973 17898 net.cpp:156] Memory required for data: 2679636480
I0619 14:56:42.208977 17898 layer_factory.hpp:77] Creating layer Convolution85
I0619 14:56:42.208991 17898 net.cpp:91] Creating Layer Convolution85
I0619 14:56:42.208995 17898 net.cpp:425] Convolution85 <- Convolution84
I0619 14:56:42.209002 17898 net.cpp:399] Convolution85 -> Convolution85
I0619 14:56:42.210623 17898 net.cpp:141] Setting up Convolution85
I0619 14:56:42.210633 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.210636 17898 net.cpp:156] Memory required for data: 2681733632
I0619 14:56:42.210644 17898 layer_factory.hpp:77] Creating layer BatchNorm85
I0619 14:56:42.210654 17898 net.cpp:91] Creating Layer BatchNorm85
I0619 14:56:42.210657 17898 net.cpp:425] BatchNorm85 <- Convolution85
I0619 14:56:42.210665 17898 net.cpp:386] BatchNorm85 -> Convolution85 (in-place)
I0619 14:56:42.210875 17898 net.cpp:141] Setting up BatchNorm85
I0619 14:56:42.210882 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.210886 17898 net.cpp:156] Memory required for data: 2683830784
I0619 14:56:42.210894 17898 layer_factory.hpp:77] Creating layer Scale85
I0619 14:56:42.210902 17898 net.cpp:91] Creating Layer Scale85
I0619 14:56:42.210907 17898 net.cpp:425] Scale85 <- Convolution85
I0619 14:56:42.210913 17898 net.cpp:386] Scale85 -> Convolution85 (in-place)
I0619 14:56:42.210952 17898 layer_factory.hpp:77] Creating layer Scale85
I0619 14:56:42.211081 17898 net.cpp:141] Setting up Scale85
I0619 14:56:42.211088 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.211092 17898 net.cpp:156] Memory required for data: 2685927936
I0619 14:56:42.211099 17898 layer_factory.hpp:77] Creating layer Eltwise42
I0619 14:56:42.211112 17898 net.cpp:91] Creating Layer Eltwise42
I0619 14:56:42.211117 17898 net.cpp:425] Eltwise42 <- Eltwise41_ReLU83_0_split_1
I0619 14:56:42.211122 17898 net.cpp:425] Eltwise42 <- Convolution85
I0619 14:56:42.211129 17898 net.cpp:399] Eltwise42 -> Eltwise42
I0619 14:56:42.211149 17898 net.cpp:141] Setting up Eltwise42
I0619 14:56:42.211156 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.211159 17898 net.cpp:156] Memory required for data: 2688025088
I0619 14:56:42.211163 17898 layer_factory.hpp:77] Creating layer ReLU85
I0619 14:56:42.211169 17898 net.cpp:91] Creating Layer ReLU85
I0619 14:56:42.211174 17898 net.cpp:425] ReLU85 <- Eltwise42
I0619 14:56:42.211181 17898 net.cpp:386] ReLU85 -> Eltwise42 (in-place)
I0619 14:56:42.211189 17898 net.cpp:141] Setting up ReLU85
I0619 14:56:42.211194 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.211197 17898 net.cpp:156] Memory required for data: 2690122240
I0619 14:56:42.211201 17898 layer_factory.hpp:77] Creating layer Eltwise42_ReLU85_0_split
I0619 14:56:42.211207 17898 net.cpp:91] Creating Layer Eltwise42_ReLU85_0_split
I0619 14:56:42.211211 17898 net.cpp:425] Eltwise42_ReLU85_0_split <- Eltwise42
I0619 14:56:42.211217 17898 net.cpp:399] Eltwise42_ReLU85_0_split -> Eltwise42_ReLU85_0_split_0
I0619 14:56:42.211225 17898 net.cpp:399] Eltwise42_ReLU85_0_split -> Eltwise42_ReLU85_0_split_1
I0619 14:56:42.211262 17898 net.cpp:141] Setting up Eltwise42_ReLU85_0_split
I0619 14:56:42.211269 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.211274 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.211278 17898 net.cpp:156] Memory required for data: 2694316544
I0619 14:56:42.211282 17898 layer_factory.hpp:77] Creating layer Convolution86
I0619 14:56:42.211292 17898 net.cpp:91] Creating Layer Convolution86
I0619 14:56:42.211297 17898 net.cpp:425] Convolution86 <- Eltwise42_ReLU85_0_split_0
I0619 14:56:42.211309 17898 net.cpp:399] Convolution86 -> Convolution86
I0619 14:56:42.212932 17898 net.cpp:141] Setting up Convolution86
I0619 14:56:42.212942 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.212946 17898 net.cpp:156] Memory required for data: 2696413696
I0619 14:56:42.212954 17898 layer_factory.hpp:77] Creating layer BatchNorm86
I0619 14:56:42.212960 17898 net.cpp:91] Creating Layer BatchNorm86
I0619 14:56:42.212965 17898 net.cpp:425] BatchNorm86 <- Convolution86
I0619 14:56:42.212973 17898 net.cpp:386] BatchNorm86 -> Convolution86 (in-place)
I0619 14:56:42.213186 17898 net.cpp:141] Setting up BatchNorm86
I0619 14:56:42.213193 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.213197 17898 net.cpp:156] Memory required for data: 2698510848
I0619 14:56:42.213206 17898 layer_factory.hpp:77] Creating layer Scale86
I0619 14:56:42.213212 17898 net.cpp:91] Creating Layer Scale86
I0619 14:56:42.213217 17898 net.cpp:425] Scale86 <- Convolution86
I0619 14:56:42.213227 17898 net.cpp:386] Scale86 -> Convolution86 (in-place)
I0619 14:56:42.213263 17898 layer_factory.hpp:77] Creating layer Scale86
I0619 14:56:42.213392 17898 net.cpp:141] Setting up Scale86
I0619 14:56:42.213400 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.213404 17898 net.cpp:156] Memory required for data: 2700608000
I0619 14:56:42.213412 17898 layer_factory.hpp:77] Creating layer ReLU86
I0619 14:56:42.213418 17898 net.cpp:91] Creating Layer ReLU86
I0619 14:56:42.213421 17898 net.cpp:425] ReLU86 <- Convolution86
I0619 14:56:42.213428 17898 net.cpp:386] ReLU86 -> Convolution86 (in-place)
I0619 14:56:42.213434 17898 net.cpp:141] Setting up ReLU86
I0619 14:56:42.213439 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.213443 17898 net.cpp:156] Memory required for data: 2702705152
I0619 14:56:42.213448 17898 layer_factory.hpp:77] Creating layer Convolution87
I0619 14:56:42.213459 17898 net.cpp:91] Creating Layer Convolution87
I0619 14:56:42.213462 17898 net.cpp:425] Convolution87 <- Convolution86
I0619 14:56:42.213472 17898 net.cpp:399] Convolution87 -> Convolution87
I0619 14:56:42.215093 17898 net.cpp:141] Setting up Convolution87
I0619 14:56:42.215103 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.215107 17898 net.cpp:156] Memory required for data: 2704802304
I0619 14:56:42.215114 17898 layer_factory.hpp:77] Creating layer BatchNorm87
I0619 14:56:42.215123 17898 net.cpp:91] Creating Layer BatchNorm87
I0619 14:56:42.215128 17898 net.cpp:425] BatchNorm87 <- Convolution87
I0619 14:56:42.215140 17898 net.cpp:386] BatchNorm87 -> Convolution87 (in-place)
I0619 14:56:42.215347 17898 net.cpp:141] Setting up BatchNorm87
I0619 14:56:42.215354 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.215358 17898 net.cpp:156] Memory required for data: 2706899456
I0619 14:56:42.215368 17898 layer_factory.hpp:77] Creating layer Scale87
I0619 14:56:42.215376 17898 net.cpp:91] Creating Layer Scale87
I0619 14:56:42.215380 17898 net.cpp:425] Scale87 <- Convolution87
I0619 14:56:42.215386 17898 net.cpp:386] Scale87 -> Convolution87 (in-place)
I0619 14:56:42.215425 17898 layer_factory.hpp:77] Creating layer Scale87
I0619 14:56:42.215551 17898 net.cpp:141] Setting up Scale87
I0619 14:56:42.215559 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.215564 17898 net.cpp:156] Memory required for data: 2708996608
I0619 14:56:42.215569 17898 layer_factory.hpp:77] Creating layer Eltwise43
I0619 14:56:42.215579 17898 net.cpp:91] Creating Layer Eltwise43
I0619 14:56:42.215584 17898 net.cpp:425] Eltwise43 <- Eltwise42_ReLU85_0_split_1
I0619 14:56:42.215590 17898 net.cpp:425] Eltwise43 <- Convolution87
I0619 14:56:42.215595 17898 net.cpp:399] Eltwise43 -> Eltwise43
I0619 14:56:42.215616 17898 net.cpp:141] Setting up Eltwise43
I0619 14:56:42.215623 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.215626 17898 net.cpp:156] Memory required for data: 2711093760
I0619 14:56:42.215631 17898 layer_factory.hpp:77] Creating layer ReLU87
I0619 14:56:42.215641 17898 net.cpp:91] Creating Layer ReLU87
I0619 14:56:42.215656 17898 net.cpp:425] ReLU87 <- Eltwise43
I0619 14:56:42.215662 17898 net.cpp:386] ReLU87 -> Eltwise43 (in-place)
I0619 14:56:42.215668 17898 net.cpp:141] Setting up ReLU87
I0619 14:56:42.215674 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.215678 17898 net.cpp:156] Memory required for data: 2713190912
I0619 14:56:42.215682 17898 layer_factory.hpp:77] Creating layer Eltwise43_ReLU87_0_split
I0619 14:56:42.215692 17898 net.cpp:91] Creating Layer Eltwise43_ReLU87_0_split
I0619 14:56:42.215695 17898 net.cpp:425] Eltwise43_ReLU87_0_split <- Eltwise43
I0619 14:56:42.215700 17898 net.cpp:399] Eltwise43_ReLU87_0_split -> Eltwise43_ReLU87_0_split_0
I0619 14:56:42.215708 17898 net.cpp:399] Eltwise43_ReLU87_0_split -> Eltwise43_ReLU87_0_split_1
I0619 14:56:42.215749 17898 net.cpp:141] Setting up Eltwise43_ReLU87_0_split
I0619 14:56:42.215755 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.215760 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.215765 17898 net.cpp:156] Memory required for data: 2717385216
I0619 14:56:42.215770 17898 layer_factory.hpp:77] Creating layer Convolution88
I0619 14:56:42.215778 17898 net.cpp:91] Creating Layer Convolution88
I0619 14:56:42.215783 17898 net.cpp:425] Convolution88 <- Eltwise43_ReLU87_0_split_0
I0619 14:56:42.215790 17898 net.cpp:399] Convolution88 -> Convolution88
I0619 14:56:42.218058 17898 net.cpp:141] Setting up Convolution88
I0619 14:56:42.218073 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.218077 17898 net.cpp:156] Memory required for data: 2719482368
I0619 14:56:42.218086 17898 layer_factory.hpp:77] Creating layer BatchNorm88
I0619 14:56:42.218096 17898 net.cpp:91] Creating Layer BatchNorm88
I0619 14:56:42.218101 17898 net.cpp:425] BatchNorm88 <- Convolution88
I0619 14:56:42.218111 17898 net.cpp:386] BatchNorm88 -> Convolution88 (in-place)
I0619 14:56:42.218323 17898 net.cpp:141] Setting up BatchNorm88
I0619 14:56:42.218332 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.218335 17898 net.cpp:156] Memory required for data: 2721579520
I0619 14:56:42.218344 17898 layer_factory.hpp:77] Creating layer Scale88
I0619 14:56:42.218360 17898 net.cpp:91] Creating Layer Scale88
I0619 14:56:42.218366 17898 net.cpp:425] Scale88 <- Convolution88
I0619 14:56:42.218374 17898 net.cpp:386] Scale88 -> Convolution88 (in-place)
I0619 14:56:42.218415 17898 layer_factory.hpp:77] Creating layer Scale88
I0619 14:56:42.218544 17898 net.cpp:141] Setting up Scale88
I0619 14:56:42.218551 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.218555 17898 net.cpp:156] Memory required for data: 2723676672
I0619 14:56:42.218562 17898 layer_factory.hpp:77] Creating layer ReLU88
I0619 14:56:42.218575 17898 net.cpp:91] Creating Layer ReLU88
I0619 14:56:42.218580 17898 net.cpp:425] ReLU88 <- Convolution88
I0619 14:56:42.218586 17898 net.cpp:386] ReLU88 -> Convolution88 (in-place)
I0619 14:56:42.218593 17898 net.cpp:141] Setting up ReLU88
I0619 14:56:42.218600 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.218603 17898 net.cpp:156] Memory required for data: 2725773824
I0619 14:56:42.218607 17898 layer_factory.hpp:77] Creating layer Convolution89
I0619 14:56:42.218619 17898 net.cpp:91] Creating Layer Convolution89
I0619 14:56:42.218623 17898 net.cpp:425] Convolution89 <- Convolution88
I0619 14:56:42.218631 17898 net.cpp:399] Convolution89 -> Convolution89
I0619 14:56:42.220240 17898 net.cpp:141] Setting up Convolution89
I0619 14:56:42.220250 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.220253 17898 net.cpp:156] Memory required for data: 2727870976
I0619 14:56:42.220262 17898 layer_factory.hpp:77] Creating layer BatchNorm89
I0619 14:56:42.220270 17898 net.cpp:91] Creating Layer BatchNorm89
I0619 14:56:42.220275 17898 net.cpp:425] BatchNorm89 <- Convolution89
I0619 14:56:42.220281 17898 net.cpp:386] BatchNorm89 -> Convolution89 (in-place)
I0619 14:56:42.220497 17898 net.cpp:141] Setting up BatchNorm89
I0619 14:56:42.220509 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.220528 17898 net.cpp:156] Memory required for data: 2729968128
I0619 14:56:42.220538 17898 layer_factory.hpp:77] Creating layer Scale89
I0619 14:56:42.220546 17898 net.cpp:91] Creating Layer Scale89
I0619 14:56:42.220551 17898 net.cpp:425] Scale89 <- Convolution89
I0619 14:56:42.220556 17898 net.cpp:386] Scale89 -> Convolution89 (in-place)
I0619 14:56:42.220599 17898 layer_factory.hpp:77] Creating layer Scale89
I0619 14:56:42.220731 17898 net.cpp:141] Setting up Scale89
I0619 14:56:42.220739 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.220743 17898 net.cpp:156] Memory required for data: 2732065280
I0619 14:56:42.220751 17898 layer_factory.hpp:77] Creating layer Eltwise44
I0619 14:56:42.220758 17898 net.cpp:91] Creating Layer Eltwise44
I0619 14:56:42.220764 17898 net.cpp:425] Eltwise44 <- Eltwise43_ReLU87_0_split_1
I0619 14:56:42.220769 17898 net.cpp:425] Eltwise44 <- Convolution89
I0619 14:56:42.220775 17898 net.cpp:399] Eltwise44 -> Eltwise44
I0619 14:56:42.220795 17898 net.cpp:141] Setting up Eltwise44
I0619 14:56:42.220803 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.220805 17898 net.cpp:156] Memory required for data: 2734162432
I0619 14:56:42.220809 17898 layer_factory.hpp:77] Creating layer ReLU89
I0619 14:56:42.220818 17898 net.cpp:91] Creating Layer ReLU89
I0619 14:56:42.220823 17898 net.cpp:425] ReLU89 <- Eltwise44
I0619 14:56:42.220829 17898 net.cpp:386] ReLU89 -> Eltwise44 (in-place)
I0619 14:56:42.220834 17898 net.cpp:141] Setting up ReLU89
I0619 14:56:42.220840 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.220844 17898 net.cpp:156] Memory required for data: 2736259584
I0619 14:56:42.220849 17898 layer_factory.hpp:77] Creating layer Eltwise44_ReLU89_0_split
I0619 14:56:42.220854 17898 net.cpp:91] Creating Layer Eltwise44_ReLU89_0_split
I0619 14:56:42.220859 17898 net.cpp:425] Eltwise44_ReLU89_0_split <- Eltwise44
I0619 14:56:42.220865 17898 net.cpp:399] Eltwise44_ReLU89_0_split -> Eltwise44_ReLU89_0_split_0
I0619 14:56:42.220873 17898 net.cpp:399] Eltwise44_ReLU89_0_split -> Eltwise44_ReLU89_0_split_1
I0619 14:56:42.220911 17898 net.cpp:141] Setting up Eltwise44_ReLU89_0_split
I0619 14:56:42.220918 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.220923 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.220927 17898 net.cpp:156] Memory required for data: 2740453888
I0619 14:56:42.220930 17898 layer_factory.hpp:77] Creating layer Convolution90
I0619 14:56:42.220942 17898 net.cpp:91] Creating Layer Convolution90
I0619 14:56:42.220947 17898 net.cpp:425] Convolution90 <- Eltwise44_ReLU89_0_split_0
I0619 14:56:42.220954 17898 net.cpp:399] Convolution90 -> Convolution90
I0619 14:56:42.222573 17898 net.cpp:141] Setting up Convolution90
I0619 14:56:42.222582 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.222587 17898 net.cpp:156] Memory required for data: 2742551040
I0619 14:56:42.222594 17898 layer_factory.hpp:77] Creating layer BatchNorm90
I0619 14:56:42.222604 17898 net.cpp:91] Creating Layer BatchNorm90
I0619 14:56:42.222609 17898 net.cpp:425] BatchNorm90 <- Convolution90
I0619 14:56:42.222615 17898 net.cpp:386] BatchNorm90 -> Convolution90 (in-place)
I0619 14:56:42.222829 17898 net.cpp:141] Setting up BatchNorm90
I0619 14:56:42.222837 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.222841 17898 net.cpp:156] Memory required for data: 2744648192
I0619 14:56:42.222849 17898 layer_factory.hpp:77] Creating layer Scale90
I0619 14:56:42.222858 17898 net.cpp:91] Creating Layer Scale90
I0619 14:56:42.222863 17898 net.cpp:425] Scale90 <- Convolution90
I0619 14:56:42.222869 17898 net.cpp:386] Scale90 -> Convolution90 (in-place)
I0619 14:56:42.222905 17898 layer_factory.hpp:77] Creating layer Scale90
I0619 14:56:42.223034 17898 net.cpp:141] Setting up Scale90
I0619 14:56:42.223042 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.223047 17898 net.cpp:156] Memory required for data: 2746745344
I0619 14:56:42.223053 17898 layer_factory.hpp:77] Creating layer ReLU90
I0619 14:56:42.223078 17898 net.cpp:91] Creating Layer ReLU90
I0619 14:56:42.223086 17898 net.cpp:425] ReLU90 <- Convolution90
I0619 14:56:42.223094 17898 net.cpp:386] ReLU90 -> Convolution90 (in-place)
I0619 14:56:42.223103 17898 net.cpp:141] Setting up ReLU90
I0619 14:56:42.223109 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.223112 17898 net.cpp:156] Memory required for data: 2748842496
I0619 14:56:42.223116 17898 layer_factory.hpp:77] Creating layer Convolution91
I0619 14:56:42.223127 17898 net.cpp:91] Creating Layer Convolution91
I0619 14:56:42.223131 17898 net.cpp:425] Convolution91 <- Convolution90
I0619 14:56:42.223139 17898 net.cpp:399] Convolution91 -> Convolution91
I0619 14:56:42.224756 17898 net.cpp:141] Setting up Convolution91
I0619 14:56:42.224766 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.224771 17898 net.cpp:156] Memory required for data: 2750939648
I0619 14:56:42.224777 17898 layer_factory.hpp:77] Creating layer BatchNorm91
I0619 14:56:42.224786 17898 net.cpp:91] Creating Layer BatchNorm91
I0619 14:56:42.224791 17898 net.cpp:425] BatchNorm91 <- Convolution91
I0619 14:56:42.224797 17898 net.cpp:386] BatchNorm91 -> Convolution91 (in-place)
I0619 14:56:42.225013 17898 net.cpp:141] Setting up BatchNorm91
I0619 14:56:42.225020 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.225023 17898 net.cpp:156] Memory required for data: 2753036800
I0619 14:56:42.225033 17898 layer_factory.hpp:77] Creating layer Scale91
I0619 14:56:42.225039 17898 net.cpp:91] Creating Layer Scale91
I0619 14:56:42.225044 17898 net.cpp:425] Scale91 <- Convolution91
I0619 14:56:42.225049 17898 net.cpp:386] Scale91 -> Convolution91 (in-place)
I0619 14:56:42.225087 17898 layer_factory.hpp:77] Creating layer Scale91
I0619 14:56:42.225220 17898 net.cpp:141] Setting up Scale91
I0619 14:56:42.225229 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.225232 17898 net.cpp:156] Memory required for data: 2755133952
I0619 14:56:42.225239 17898 layer_factory.hpp:77] Creating layer Eltwise45
I0619 14:56:42.225245 17898 net.cpp:91] Creating Layer Eltwise45
I0619 14:56:42.225250 17898 net.cpp:425] Eltwise45 <- Eltwise44_ReLU89_0_split_1
I0619 14:56:42.225256 17898 net.cpp:425] Eltwise45 <- Convolution91
I0619 14:56:42.225265 17898 net.cpp:399] Eltwise45 -> Eltwise45
I0619 14:56:42.225287 17898 net.cpp:141] Setting up Eltwise45
I0619 14:56:42.225293 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.225297 17898 net.cpp:156] Memory required for data: 2757231104
I0619 14:56:42.225301 17898 layer_factory.hpp:77] Creating layer ReLU91
I0619 14:56:42.225306 17898 net.cpp:91] Creating Layer ReLU91
I0619 14:56:42.225311 17898 net.cpp:425] ReLU91 <- Eltwise45
I0619 14:56:42.225319 17898 net.cpp:386] ReLU91 -> Eltwise45 (in-place)
I0619 14:56:42.225327 17898 net.cpp:141] Setting up ReLU91
I0619 14:56:42.225332 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.225335 17898 net.cpp:156] Memory required for data: 2759328256
I0619 14:56:42.225339 17898 layer_factory.hpp:77] Creating layer Eltwise45_ReLU91_0_split
I0619 14:56:42.225345 17898 net.cpp:91] Creating Layer Eltwise45_ReLU91_0_split
I0619 14:56:42.225349 17898 net.cpp:425] Eltwise45_ReLU91_0_split <- Eltwise45
I0619 14:56:42.225354 17898 net.cpp:399] Eltwise45_ReLU91_0_split -> Eltwise45_ReLU91_0_split_0
I0619 14:56:42.225363 17898 net.cpp:399] Eltwise45_ReLU91_0_split -> Eltwise45_ReLU91_0_split_1
I0619 14:56:42.225401 17898 net.cpp:141] Setting up Eltwise45_ReLU91_0_split
I0619 14:56:42.225409 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.225414 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.225416 17898 net.cpp:156] Memory required for data: 2763522560
I0619 14:56:42.225420 17898 layer_factory.hpp:77] Creating layer Convolution92
I0619 14:56:42.225430 17898 net.cpp:91] Creating Layer Convolution92
I0619 14:56:42.225435 17898 net.cpp:425] Convolution92 <- Eltwise45_ReLU91_0_split_0
I0619 14:56:42.225443 17898 net.cpp:399] Convolution92 -> Convolution92
I0619 14:56:42.227082 17898 net.cpp:141] Setting up Convolution92
I0619 14:56:42.227108 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.227113 17898 net.cpp:156] Memory required for data: 2765619712
I0619 14:56:42.227120 17898 layer_factory.hpp:77] Creating layer BatchNorm92
I0619 14:56:42.227128 17898 net.cpp:91] Creating Layer BatchNorm92
I0619 14:56:42.227133 17898 net.cpp:425] BatchNorm92 <- Convolution92
I0619 14:56:42.227141 17898 net.cpp:386] BatchNorm92 -> Convolution92 (in-place)
I0619 14:56:42.227360 17898 net.cpp:141] Setting up BatchNorm92
I0619 14:56:42.227368 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.227371 17898 net.cpp:156] Memory required for data: 2767716864
I0619 14:56:42.227380 17898 layer_factory.hpp:77] Creating layer Scale92
I0619 14:56:42.227387 17898 net.cpp:91] Creating Layer Scale92
I0619 14:56:42.227392 17898 net.cpp:425] Scale92 <- Convolution92
I0619 14:56:42.227401 17898 net.cpp:386] Scale92 -> Convolution92 (in-place)
I0619 14:56:42.227437 17898 layer_factory.hpp:77] Creating layer Scale92
I0619 14:56:42.227577 17898 net.cpp:141] Setting up Scale92
I0619 14:56:42.227586 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.227589 17898 net.cpp:156] Memory required for data: 2769814016
I0619 14:56:42.227596 17898 layer_factory.hpp:77] Creating layer ReLU92
I0619 14:56:42.227602 17898 net.cpp:91] Creating Layer ReLU92
I0619 14:56:42.227607 17898 net.cpp:425] ReLU92 <- Convolution92
I0619 14:56:42.227613 17898 net.cpp:386] ReLU92 -> Convolution92 (in-place)
I0619 14:56:42.227620 17898 net.cpp:141] Setting up ReLU92
I0619 14:56:42.227625 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.227629 17898 net.cpp:156] Memory required for data: 2771911168
I0619 14:56:42.227633 17898 layer_factory.hpp:77] Creating layer Convolution93
I0619 14:56:42.227646 17898 net.cpp:91] Creating Layer Convolution93
I0619 14:56:42.227651 17898 net.cpp:425] Convolution93 <- Convolution92
I0619 14:56:42.227658 17898 net.cpp:399] Convolution93 -> Convolution93
I0619 14:56:42.229277 17898 net.cpp:141] Setting up Convolution93
I0619 14:56:42.229286 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.229290 17898 net.cpp:156] Memory required for data: 2774008320
I0619 14:56:42.229297 17898 layer_factory.hpp:77] Creating layer BatchNorm93
I0619 14:56:42.229307 17898 net.cpp:91] Creating Layer BatchNorm93
I0619 14:56:42.229311 17898 net.cpp:425] BatchNorm93 <- Convolution93
I0619 14:56:42.229320 17898 net.cpp:386] BatchNorm93 -> Convolution93 (in-place)
I0619 14:56:42.229534 17898 net.cpp:141] Setting up BatchNorm93
I0619 14:56:42.229542 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.229547 17898 net.cpp:156] Memory required for data: 2776105472
I0619 14:56:42.229554 17898 layer_factory.hpp:77] Creating layer Scale93
I0619 14:56:42.229563 17898 net.cpp:91] Creating Layer Scale93
I0619 14:56:42.229568 17898 net.cpp:425] Scale93 <- Convolution93
I0619 14:56:42.229574 17898 net.cpp:386] Scale93 -> Convolution93 (in-place)
I0619 14:56:42.229614 17898 layer_factory.hpp:77] Creating layer Scale93
I0619 14:56:42.229748 17898 net.cpp:141] Setting up Scale93
I0619 14:56:42.229755 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.229758 17898 net.cpp:156] Memory required for data: 2778202624
I0619 14:56:42.229765 17898 layer_factory.hpp:77] Creating layer Eltwise46
I0619 14:56:42.229774 17898 net.cpp:91] Creating Layer Eltwise46
I0619 14:56:42.229779 17898 net.cpp:425] Eltwise46 <- Eltwise45_ReLU91_0_split_1
I0619 14:56:42.229784 17898 net.cpp:425] Eltwise46 <- Convolution93
I0619 14:56:42.229792 17898 net.cpp:399] Eltwise46 -> Eltwise46
I0619 14:56:42.229812 17898 net.cpp:141] Setting up Eltwise46
I0619 14:56:42.229818 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.229822 17898 net.cpp:156] Memory required for data: 2780299776
I0619 14:56:42.229826 17898 layer_factory.hpp:77] Creating layer ReLU93
I0619 14:56:42.229832 17898 net.cpp:91] Creating Layer ReLU93
I0619 14:56:42.229840 17898 net.cpp:425] ReLU93 <- Eltwise46
I0619 14:56:42.229859 17898 net.cpp:386] ReLU93 -> Eltwise46 (in-place)
I0619 14:56:42.229867 17898 net.cpp:141] Setting up ReLU93
I0619 14:56:42.229872 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.229876 17898 net.cpp:156] Memory required for data: 2782396928
I0619 14:56:42.229881 17898 layer_factory.hpp:77] Creating layer Eltwise46_ReLU93_0_split
I0619 14:56:42.229887 17898 net.cpp:91] Creating Layer Eltwise46_ReLU93_0_split
I0619 14:56:42.229890 17898 net.cpp:425] Eltwise46_ReLU93_0_split <- Eltwise46
I0619 14:56:42.229897 17898 net.cpp:399] Eltwise46_ReLU93_0_split -> Eltwise46_ReLU93_0_split_0
I0619 14:56:42.229903 17898 net.cpp:399] Eltwise46_ReLU93_0_split -> Eltwise46_ReLU93_0_split_1
I0619 14:56:42.229945 17898 net.cpp:141] Setting up Eltwise46_ReLU93_0_split
I0619 14:56:42.229953 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.229957 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.229960 17898 net.cpp:156] Memory required for data: 2786591232
I0619 14:56:42.229964 17898 layer_factory.hpp:77] Creating layer Convolution94
I0619 14:56:42.229977 17898 net.cpp:91] Creating Layer Convolution94
I0619 14:56:42.229982 17898 net.cpp:425] Convolution94 <- Eltwise46_ReLU93_0_split_0
I0619 14:56:42.230000 17898 net.cpp:399] Convolution94 -> Convolution94
I0619 14:56:42.231634 17898 net.cpp:141] Setting up Convolution94
I0619 14:56:42.231644 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.231648 17898 net.cpp:156] Memory required for data: 2788688384
I0619 14:56:42.231655 17898 layer_factory.hpp:77] Creating layer BatchNorm94
I0619 14:56:42.231663 17898 net.cpp:91] Creating Layer BatchNorm94
I0619 14:56:42.231667 17898 net.cpp:425] BatchNorm94 <- Convolution94
I0619 14:56:42.231676 17898 net.cpp:386] BatchNorm94 -> Convolution94 (in-place)
I0619 14:56:42.231901 17898 net.cpp:141] Setting up BatchNorm94
I0619 14:56:42.231909 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.231914 17898 net.cpp:156] Memory required for data: 2790785536
I0619 14:56:42.231921 17898 layer_factory.hpp:77] Creating layer Scale94
I0619 14:56:42.231928 17898 net.cpp:91] Creating Layer Scale94
I0619 14:56:42.231933 17898 net.cpp:425] Scale94 <- Convolution94
I0619 14:56:42.231941 17898 net.cpp:386] Scale94 -> Convolution94 (in-place)
I0619 14:56:42.231979 17898 layer_factory.hpp:77] Creating layer Scale94
I0619 14:56:42.232785 17898 net.cpp:141] Setting up Scale94
I0619 14:56:42.232800 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.232805 17898 net.cpp:156] Memory required for data: 2792882688
I0619 14:56:42.232812 17898 layer_factory.hpp:77] Creating layer ReLU94
I0619 14:56:42.232820 17898 net.cpp:91] Creating Layer ReLU94
I0619 14:56:42.232825 17898 net.cpp:425] ReLU94 <- Convolution94
I0619 14:56:42.232833 17898 net.cpp:386] ReLU94 -> Convolution94 (in-place)
I0619 14:56:42.232842 17898 net.cpp:141] Setting up ReLU94
I0619 14:56:42.232848 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.232851 17898 net.cpp:156] Memory required for data: 2794979840
I0619 14:56:42.232856 17898 layer_factory.hpp:77] Creating layer Convolution95
I0619 14:56:42.232868 17898 net.cpp:91] Creating Layer Convolution95
I0619 14:56:42.232872 17898 net.cpp:425] Convolution95 <- Convolution94
I0619 14:56:42.232879 17898 net.cpp:399] Convolution95 -> Convolution95
I0619 14:56:42.235169 17898 net.cpp:141] Setting up Convolution95
I0619 14:56:42.235184 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.235188 17898 net.cpp:156] Memory required for data: 2797076992
I0619 14:56:42.235196 17898 layer_factory.hpp:77] Creating layer BatchNorm95
I0619 14:56:42.235204 17898 net.cpp:91] Creating Layer BatchNorm95
I0619 14:56:42.235209 17898 net.cpp:425] BatchNorm95 <- Convolution95
I0619 14:56:42.235219 17898 net.cpp:386] BatchNorm95 -> Convolution95 (in-place)
I0619 14:56:42.235438 17898 net.cpp:141] Setting up BatchNorm95
I0619 14:56:42.235447 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.235456 17898 net.cpp:156] Memory required for data: 2799174144
I0619 14:56:42.235491 17898 layer_factory.hpp:77] Creating layer Scale95
I0619 14:56:42.235498 17898 net.cpp:91] Creating Layer Scale95
I0619 14:56:42.235503 17898 net.cpp:425] Scale95 <- Convolution95
I0619 14:56:42.235512 17898 net.cpp:386] Scale95 -> Convolution95 (in-place)
I0619 14:56:42.235553 17898 layer_factory.hpp:77] Creating layer Scale95
I0619 14:56:42.235680 17898 net.cpp:141] Setting up Scale95
I0619 14:56:42.235688 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.235692 17898 net.cpp:156] Memory required for data: 2801271296
I0619 14:56:42.235699 17898 layer_factory.hpp:77] Creating layer Eltwise47
I0619 14:56:42.235707 17898 net.cpp:91] Creating Layer Eltwise47
I0619 14:56:42.235712 17898 net.cpp:425] Eltwise47 <- Eltwise46_ReLU93_0_split_1
I0619 14:56:42.235716 17898 net.cpp:425] Eltwise47 <- Convolution95
I0619 14:56:42.235724 17898 net.cpp:399] Eltwise47 -> Eltwise47
I0619 14:56:42.235745 17898 net.cpp:141] Setting up Eltwise47
I0619 14:56:42.235751 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.235755 17898 net.cpp:156] Memory required for data: 2803368448
I0619 14:56:42.235759 17898 layer_factory.hpp:77] Creating layer ReLU95
I0619 14:56:42.235769 17898 net.cpp:91] Creating Layer ReLU95
I0619 14:56:42.235774 17898 net.cpp:425] ReLU95 <- Eltwise47
I0619 14:56:42.235780 17898 net.cpp:386] ReLU95 -> Eltwise47 (in-place)
I0619 14:56:42.235786 17898 net.cpp:141] Setting up ReLU95
I0619 14:56:42.235791 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.235795 17898 net.cpp:156] Memory required for data: 2805465600
I0619 14:56:42.235800 17898 layer_factory.hpp:77] Creating layer Eltwise47_ReLU95_0_split
I0619 14:56:42.235805 17898 net.cpp:91] Creating Layer Eltwise47_ReLU95_0_split
I0619 14:56:42.235810 17898 net.cpp:425] Eltwise47_ReLU95_0_split <- Eltwise47
I0619 14:56:42.235817 17898 net.cpp:399] Eltwise47_ReLU95_0_split -> Eltwise47_ReLU95_0_split_0
I0619 14:56:42.235824 17898 net.cpp:399] Eltwise47_ReLU95_0_split -> Eltwise47_ReLU95_0_split_1
I0619 14:56:42.235862 17898 net.cpp:141] Setting up Eltwise47_ReLU95_0_split
I0619 14:56:42.235867 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.235872 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.235877 17898 net.cpp:156] Memory required for data: 2809659904
I0619 14:56:42.235880 17898 layer_factory.hpp:77] Creating layer Convolution96
I0619 14:56:42.235893 17898 net.cpp:91] Creating Layer Convolution96
I0619 14:56:42.235898 17898 net.cpp:425] Convolution96 <- Eltwise47_ReLU95_0_split_0
I0619 14:56:42.235904 17898 net.cpp:399] Convolution96 -> Convolution96
I0619 14:56:42.237525 17898 net.cpp:141] Setting up Convolution96
I0619 14:56:42.237535 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.237540 17898 net.cpp:156] Memory required for data: 2811757056
I0619 14:56:42.237546 17898 layer_factory.hpp:77] Creating layer BatchNorm96
I0619 14:56:42.237555 17898 net.cpp:91] Creating Layer BatchNorm96
I0619 14:56:42.237560 17898 net.cpp:425] BatchNorm96 <- Convolution96
I0619 14:56:42.237566 17898 net.cpp:386] BatchNorm96 -> Convolution96 (in-place)
I0619 14:56:42.237792 17898 net.cpp:141] Setting up BatchNorm96
I0619 14:56:42.237799 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.237803 17898 net.cpp:156] Memory required for data: 2813854208
I0619 14:56:42.237812 17898 layer_factory.hpp:77] Creating layer Scale96
I0619 14:56:42.237819 17898 net.cpp:91] Creating Layer Scale96
I0619 14:56:42.237823 17898 net.cpp:425] Scale96 <- Convolution96
I0619 14:56:42.237829 17898 net.cpp:386] Scale96 -> Convolution96 (in-place)
I0619 14:56:42.237867 17898 layer_factory.hpp:77] Creating layer Scale96
I0619 14:56:42.238006 17898 net.cpp:141] Setting up Scale96
I0619 14:56:42.238014 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.238018 17898 net.cpp:156] Memory required for data: 2815951360
I0619 14:56:42.238024 17898 layer_factory.hpp:77] Creating layer ReLU96
I0619 14:56:42.238031 17898 net.cpp:91] Creating Layer ReLU96
I0619 14:56:42.238039 17898 net.cpp:425] ReLU96 <- Convolution96
I0619 14:56:42.238060 17898 net.cpp:386] ReLU96 -> Convolution96 (in-place)
I0619 14:56:42.238068 17898 net.cpp:141] Setting up ReLU96
I0619 14:56:42.238075 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.238078 17898 net.cpp:156] Memory required for data: 2818048512
I0619 14:56:42.238082 17898 layer_factory.hpp:77] Creating layer Convolution97
I0619 14:56:42.238092 17898 net.cpp:91] Creating Layer Convolution97
I0619 14:56:42.238096 17898 net.cpp:425] Convolution97 <- Convolution96
I0619 14:56:42.238106 17898 net.cpp:399] Convolution97 -> Convolution97
I0619 14:56:42.239723 17898 net.cpp:141] Setting up Convolution97
I0619 14:56:42.239734 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.239737 17898 net.cpp:156] Memory required for data: 2820145664
I0619 14:56:42.239745 17898 layer_factory.hpp:77] Creating layer BatchNorm97
I0619 14:56:42.239751 17898 net.cpp:91] Creating Layer BatchNorm97
I0619 14:56:42.239756 17898 net.cpp:425] BatchNorm97 <- Convolution97
I0619 14:56:42.239764 17898 net.cpp:386] BatchNorm97 -> Convolution97 (in-place)
I0619 14:56:42.239975 17898 net.cpp:141] Setting up BatchNorm97
I0619 14:56:42.239984 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.239987 17898 net.cpp:156] Memory required for data: 2822242816
I0619 14:56:42.239996 17898 layer_factory.hpp:77] Creating layer Scale97
I0619 14:56:42.240003 17898 net.cpp:91] Creating Layer Scale97
I0619 14:56:42.240007 17898 net.cpp:425] Scale97 <- Convolution97
I0619 14:56:42.240015 17898 net.cpp:386] Scale97 -> Convolution97 (in-place)
I0619 14:56:42.240052 17898 layer_factory.hpp:77] Creating layer Scale97
I0619 14:56:42.240180 17898 net.cpp:141] Setting up Scale97
I0619 14:56:42.240187 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.240191 17898 net.cpp:156] Memory required for data: 2824339968
I0619 14:56:42.240198 17898 layer_factory.hpp:77] Creating layer Eltwise48
I0619 14:56:42.240206 17898 net.cpp:91] Creating Layer Eltwise48
I0619 14:56:42.240209 17898 net.cpp:425] Eltwise48 <- Eltwise47_ReLU95_0_split_1
I0619 14:56:42.240216 17898 net.cpp:425] Eltwise48 <- Convolution97
I0619 14:56:42.240221 17898 net.cpp:399] Eltwise48 -> Eltwise48
I0619 14:56:42.240243 17898 net.cpp:141] Setting up Eltwise48
I0619 14:56:42.240249 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.240253 17898 net.cpp:156] Memory required for data: 2826437120
I0619 14:56:42.240257 17898 layer_factory.hpp:77] Creating layer ReLU97
I0619 14:56:42.240263 17898 net.cpp:91] Creating Layer ReLU97
I0619 14:56:42.240267 17898 net.cpp:425] ReLU97 <- Eltwise48
I0619 14:56:42.240274 17898 net.cpp:386] ReLU97 -> Eltwise48 (in-place)
I0619 14:56:42.240281 17898 net.cpp:141] Setting up ReLU97
I0619 14:56:42.240288 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.240290 17898 net.cpp:156] Memory required for data: 2828534272
I0619 14:56:42.240294 17898 layer_factory.hpp:77] Creating layer Eltwise48_ReLU97_0_split
I0619 14:56:42.240300 17898 net.cpp:91] Creating Layer Eltwise48_ReLU97_0_split
I0619 14:56:42.240304 17898 net.cpp:425] Eltwise48_ReLU97_0_split <- Eltwise48
I0619 14:56:42.240310 17898 net.cpp:399] Eltwise48_ReLU97_0_split -> Eltwise48_ReLU97_0_split_0
I0619 14:56:42.240317 17898 net.cpp:399] Eltwise48_ReLU97_0_split -> Eltwise48_ReLU97_0_split_1
I0619 14:56:42.240357 17898 net.cpp:141] Setting up Eltwise48_ReLU97_0_split
I0619 14:56:42.240363 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.240370 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.240372 17898 net.cpp:156] Memory required for data: 2832728576
I0619 14:56:42.240376 17898 layer_factory.hpp:77] Creating layer Convolution98
I0619 14:56:42.240387 17898 net.cpp:91] Creating Layer Convolution98
I0619 14:56:42.240392 17898 net.cpp:425] Convolution98 <- Eltwise48_ReLU97_0_split_0
I0619 14:56:42.240399 17898 net.cpp:399] Convolution98 -> Convolution98
I0619 14:56:42.242017 17898 net.cpp:141] Setting up Convolution98
I0619 14:56:42.242029 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.242045 17898 net.cpp:156] Memory required for data: 2834825728
I0619 14:56:42.242053 17898 layer_factory.hpp:77] Creating layer BatchNorm98
I0619 14:56:42.242066 17898 net.cpp:91] Creating Layer BatchNorm98
I0619 14:56:42.242071 17898 net.cpp:425] BatchNorm98 <- Convolution98
I0619 14:56:42.242079 17898 net.cpp:386] BatchNorm98 -> Convolution98 (in-place)
I0619 14:56:42.242297 17898 net.cpp:141] Setting up BatchNorm98
I0619 14:56:42.242305 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.242310 17898 net.cpp:156] Memory required for data: 2836922880
I0619 14:56:42.242318 17898 layer_factory.hpp:77] Creating layer Scale98
I0619 14:56:42.242327 17898 net.cpp:91] Creating Layer Scale98
I0619 14:56:42.242332 17898 net.cpp:425] Scale98 <- Convolution98
I0619 14:56:42.242338 17898 net.cpp:386] Scale98 -> Convolution98 (in-place)
I0619 14:56:42.242384 17898 layer_factory.hpp:77] Creating layer Scale98
I0619 14:56:42.242513 17898 net.cpp:141] Setting up Scale98
I0619 14:56:42.242522 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.242525 17898 net.cpp:156] Memory required for data: 2839020032
I0619 14:56:42.242534 17898 layer_factory.hpp:77] Creating layer ReLU98
I0619 14:56:42.242542 17898 net.cpp:91] Creating Layer ReLU98
I0619 14:56:42.242547 17898 net.cpp:425] ReLU98 <- Convolution98
I0619 14:56:42.242553 17898 net.cpp:386] ReLU98 -> Convolution98 (in-place)
I0619 14:56:42.242563 17898 net.cpp:141] Setting up ReLU98
I0619 14:56:42.242568 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.242571 17898 net.cpp:156] Memory required for data: 2841117184
I0619 14:56:42.242576 17898 layer_factory.hpp:77] Creating layer Convolution99
I0619 14:56:42.242585 17898 net.cpp:91] Creating Layer Convolution99
I0619 14:56:42.242589 17898 net.cpp:425] Convolution99 <- Convolution98
I0619 14:56:42.242599 17898 net.cpp:399] Convolution99 -> Convolution99
I0619 14:56:42.244209 17898 net.cpp:141] Setting up Convolution99
I0619 14:56:42.244217 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.244221 17898 net.cpp:156] Memory required for data: 2843214336
I0619 14:56:42.244230 17898 layer_factory.hpp:77] Creating layer BatchNorm99
I0619 14:56:42.244236 17898 net.cpp:91] Creating Layer BatchNorm99
I0619 14:56:42.244240 17898 net.cpp:425] BatchNorm99 <- Convolution99
I0619 14:56:42.244246 17898 net.cpp:386] BatchNorm99 -> Convolution99 (in-place)
I0619 14:56:42.244459 17898 net.cpp:141] Setting up BatchNorm99
I0619 14:56:42.244467 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.244472 17898 net.cpp:156] Memory required for data: 2845311488
I0619 14:56:42.244480 17898 layer_factory.hpp:77] Creating layer Scale99
I0619 14:56:42.244488 17898 net.cpp:91] Creating Layer Scale99
I0619 14:56:42.244491 17898 net.cpp:425] Scale99 <- Convolution99
I0619 14:56:42.244498 17898 net.cpp:386] Scale99 -> Convolution99 (in-place)
I0619 14:56:42.244536 17898 layer_factory.hpp:77] Creating layer Scale99
I0619 14:56:42.244666 17898 net.cpp:141] Setting up Scale99
I0619 14:56:42.244676 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.244679 17898 net.cpp:156] Memory required for data: 2847408640
I0619 14:56:42.244686 17898 layer_factory.hpp:77] Creating layer Eltwise49
I0619 14:56:42.244693 17898 net.cpp:91] Creating Layer Eltwise49
I0619 14:56:42.244699 17898 net.cpp:425] Eltwise49 <- Eltwise48_ReLU97_0_split_1
I0619 14:56:42.244704 17898 net.cpp:425] Eltwise49 <- Convolution99
I0619 14:56:42.244709 17898 net.cpp:399] Eltwise49 -> Eltwise49
I0619 14:56:42.244731 17898 net.cpp:141] Setting up Eltwise49
I0619 14:56:42.244738 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.244741 17898 net.cpp:156] Memory required for data: 2849505792
I0619 14:56:42.244745 17898 layer_factory.hpp:77] Creating layer ReLU99
I0619 14:56:42.244751 17898 net.cpp:91] Creating Layer ReLU99
I0619 14:56:42.244755 17898 net.cpp:425] ReLU99 <- Eltwise49
I0619 14:56:42.244762 17898 net.cpp:386] ReLU99 -> Eltwise49 (in-place)
I0619 14:56:42.244784 17898 net.cpp:141] Setting up ReLU99
I0619 14:56:42.244791 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.244794 17898 net.cpp:156] Memory required for data: 2851602944
I0619 14:56:42.244798 17898 layer_factory.hpp:77] Creating layer Eltwise49_ReLU99_0_split
I0619 14:56:42.244804 17898 net.cpp:91] Creating Layer Eltwise49_ReLU99_0_split
I0619 14:56:42.244808 17898 net.cpp:425] Eltwise49_ReLU99_0_split <- Eltwise49
I0619 14:56:42.244814 17898 net.cpp:399] Eltwise49_ReLU99_0_split -> Eltwise49_ReLU99_0_split_0
I0619 14:56:42.244822 17898 net.cpp:399] Eltwise49_ReLU99_0_split -> Eltwise49_ReLU99_0_split_1
I0619 14:56:42.244863 17898 net.cpp:141] Setting up Eltwise49_ReLU99_0_split
I0619 14:56:42.244869 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.244874 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.244877 17898 net.cpp:156] Memory required for data: 2855797248
I0619 14:56:42.244881 17898 layer_factory.hpp:77] Creating layer Convolution100
I0619 14:56:42.244894 17898 net.cpp:91] Creating Layer Convolution100
I0619 14:56:42.244897 17898 net.cpp:425] Convolution100 <- Eltwise49_ReLU99_0_split_0
I0619 14:56:42.244905 17898 net.cpp:399] Convolution100 -> Convolution100
I0619 14:56:42.246552 17898 net.cpp:141] Setting up Convolution100
I0619 14:56:42.246565 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.246569 17898 net.cpp:156] Memory required for data: 2857894400
I0619 14:56:42.246577 17898 layer_factory.hpp:77] Creating layer BatchNorm100
I0619 14:56:42.246588 17898 net.cpp:91] Creating Layer BatchNorm100
I0619 14:56:42.246593 17898 net.cpp:425] BatchNorm100 <- Convolution100
I0619 14:56:42.246600 17898 net.cpp:386] BatchNorm100 -> Convolution100 (in-place)
I0619 14:56:42.246816 17898 net.cpp:141] Setting up BatchNorm100
I0619 14:56:42.246824 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.246829 17898 net.cpp:156] Memory required for data: 2859991552
I0619 14:56:42.246837 17898 layer_factory.hpp:77] Creating layer Scale100
I0619 14:56:42.246845 17898 net.cpp:91] Creating Layer Scale100
I0619 14:56:42.246848 17898 net.cpp:425] Scale100 <- Convolution100
I0619 14:56:42.246856 17898 net.cpp:386] Scale100 -> Convolution100 (in-place)
I0619 14:56:42.246892 17898 layer_factory.hpp:77] Creating layer Scale100
I0619 14:56:42.247030 17898 net.cpp:141] Setting up Scale100
I0619 14:56:42.247038 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.247041 17898 net.cpp:156] Memory required for data: 2862088704
I0619 14:56:42.247048 17898 layer_factory.hpp:77] Creating layer ReLU100
I0619 14:56:42.247056 17898 net.cpp:91] Creating Layer ReLU100
I0619 14:56:42.247059 17898 net.cpp:425] ReLU100 <- Convolution100
I0619 14:56:42.247067 17898 net.cpp:386] ReLU100 -> Convolution100 (in-place)
I0619 14:56:42.247074 17898 net.cpp:141] Setting up ReLU100
I0619 14:56:42.247081 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.247084 17898 net.cpp:156] Memory required for data: 2864185856
I0619 14:56:42.247088 17898 layer_factory.hpp:77] Creating layer Convolution101
I0619 14:56:42.247099 17898 net.cpp:91] Creating Layer Convolution101
I0619 14:56:42.247103 17898 net.cpp:425] Convolution101 <- Convolution100
I0619 14:56:42.247110 17898 net.cpp:399] Convolution101 -> Convolution101
I0619 14:56:42.248728 17898 net.cpp:141] Setting up Convolution101
I0619 14:56:42.248738 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.248741 17898 net.cpp:156] Memory required for data: 2866283008
I0619 14:56:42.248749 17898 layer_factory.hpp:77] Creating layer BatchNorm101
I0619 14:56:42.248757 17898 net.cpp:91] Creating Layer BatchNorm101
I0619 14:56:42.248761 17898 net.cpp:425] BatchNorm101 <- Convolution101
I0619 14:56:42.248769 17898 net.cpp:386] BatchNorm101 -> Convolution101 (in-place)
I0619 14:56:42.248983 17898 net.cpp:141] Setting up BatchNorm101
I0619 14:56:42.248991 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.248994 17898 net.cpp:156] Memory required for data: 2868380160
I0619 14:56:42.249006 17898 layer_factory.hpp:77] Creating layer Scale101
I0619 14:56:42.249028 17898 net.cpp:91] Creating Layer Scale101
I0619 14:56:42.249033 17898 net.cpp:425] Scale101 <- Convolution101
I0619 14:56:42.249039 17898 net.cpp:386] Scale101 -> Convolution101 (in-place)
I0619 14:56:42.249081 17898 layer_factory.hpp:77] Creating layer Scale101
I0619 14:56:42.249208 17898 net.cpp:141] Setting up Scale101
I0619 14:56:42.249217 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.249220 17898 net.cpp:156] Memory required for data: 2870477312
I0619 14:56:42.249228 17898 layer_factory.hpp:77] Creating layer Eltwise50
I0619 14:56:42.249238 17898 net.cpp:91] Creating Layer Eltwise50
I0619 14:56:42.249244 17898 net.cpp:425] Eltwise50 <- Eltwise49_ReLU99_0_split_1
I0619 14:56:42.249249 17898 net.cpp:425] Eltwise50 <- Convolution101
I0619 14:56:42.249258 17898 net.cpp:399] Eltwise50 -> Eltwise50
I0619 14:56:42.249277 17898 net.cpp:141] Setting up Eltwise50
I0619 14:56:42.249284 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.249287 17898 net.cpp:156] Memory required for data: 2872574464
I0619 14:56:42.249291 17898 layer_factory.hpp:77] Creating layer ReLU101
I0619 14:56:42.249297 17898 net.cpp:91] Creating Layer ReLU101
I0619 14:56:42.249301 17898 net.cpp:425] ReLU101 <- Eltwise50
I0619 14:56:42.249310 17898 net.cpp:386] ReLU101 -> Eltwise50 (in-place)
I0619 14:56:42.249316 17898 net.cpp:141] Setting up ReLU101
I0619 14:56:42.249321 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.249325 17898 net.cpp:156] Memory required for data: 2874671616
I0619 14:56:42.249330 17898 layer_factory.hpp:77] Creating layer Eltwise50_ReLU101_0_split
I0619 14:56:42.249336 17898 net.cpp:91] Creating Layer Eltwise50_ReLU101_0_split
I0619 14:56:42.249339 17898 net.cpp:425] Eltwise50_ReLU101_0_split <- Eltwise50
I0619 14:56:42.249344 17898 net.cpp:399] Eltwise50_ReLU101_0_split -> Eltwise50_ReLU101_0_split_0
I0619 14:56:42.249352 17898 net.cpp:399] Eltwise50_ReLU101_0_split -> Eltwise50_ReLU101_0_split_1
I0619 14:56:42.249395 17898 net.cpp:141] Setting up Eltwise50_ReLU101_0_split
I0619 14:56:42.249408 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.249413 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.249416 17898 net.cpp:156] Memory required for data: 2878865920
I0619 14:56:42.249420 17898 layer_factory.hpp:77] Creating layer Convolution102
I0619 14:56:42.249475 17898 net.cpp:91] Creating Layer Convolution102
I0619 14:56:42.249481 17898 net.cpp:425] Convolution102 <- Eltwise50_ReLU101_0_split_0
I0619 14:56:42.249490 17898 net.cpp:399] Convolution102 -> Convolution102
I0619 14:56:42.251773 17898 net.cpp:141] Setting up Convolution102
I0619 14:56:42.251790 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.251793 17898 net.cpp:156] Memory required for data: 2880963072
I0619 14:56:42.251802 17898 layer_factory.hpp:77] Creating layer BatchNorm102
I0619 14:56:42.251812 17898 net.cpp:91] Creating Layer BatchNorm102
I0619 14:56:42.251818 17898 net.cpp:425] BatchNorm102 <- Convolution102
I0619 14:56:42.251827 17898 net.cpp:386] BatchNorm102 -> Convolution102 (in-place)
I0619 14:56:42.252054 17898 net.cpp:141] Setting up BatchNorm102
I0619 14:56:42.252063 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.252066 17898 net.cpp:156] Memory required for data: 2883060224
I0619 14:56:42.252077 17898 layer_factory.hpp:77] Creating layer Scale102
I0619 14:56:42.252084 17898 net.cpp:91] Creating Layer Scale102
I0619 14:56:42.252089 17898 net.cpp:425] Scale102 <- Convolution102
I0619 14:56:42.252095 17898 net.cpp:386] Scale102 -> Convolution102 (in-place)
I0619 14:56:42.252135 17898 layer_factory.hpp:77] Creating layer Scale102
I0619 14:56:42.252264 17898 net.cpp:141] Setting up Scale102
I0619 14:56:42.252272 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.252276 17898 net.cpp:156] Memory required for data: 2885157376
I0619 14:56:42.252284 17898 layer_factory.hpp:77] Creating layer ReLU102
I0619 14:56:42.252295 17898 net.cpp:91] Creating Layer ReLU102
I0619 14:56:42.252313 17898 net.cpp:425] ReLU102 <- Convolution102
I0619 14:56:42.252321 17898 net.cpp:386] ReLU102 -> Convolution102 (in-place)
I0619 14:56:42.252329 17898 net.cpp:141] Setting up ReLU102
I0619 14:56:42.252336 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.252338 17898 net.cpp:156] Memory required for data: 2887254528
I0619 14:56:42.252343 17898 layer_factory.hpp:77] Creating layer Convolution103
I0619 14:56:42.252353 17898 net.cpp:91] Creating Layer Convolution103
I0619 14:56:42.252357 17898 net.cpp:425] Convolution103 <- Convolution102
I0619 14:56:42.252367 17898 net.cpp:399] Convolution103 -> Convolution103
I0619 14:56:42.253986 17898 net.cpp:141] Setting up Convolution103
I0619 14:56:42.253995 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.253999 17898 net.cpp:156] Memory required for data: 2889351680
I0619 14:56:42.254007 17898 layer_factory.hpp:77] Creating layer BatchNorm103
I0619 14:56:42.254014 17898 net.cpp:91] Creating Layer BatchNorm103
I0619 14:56:42.254019 17898 net.cpp:425] BatchNorm103 <- Convolution103
I0619 14:56:42.254026 17898 net.cpp:386] BatchNorm103 -> Convolution103 (in-place)
I0619 14:56:42.254248 17898 net.cpp:141] Setting up BatchNorm103
I0619 14:56:42.254256 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.254261 17898 net.cpp:156] Memory required for data: 2891448832
I0619 14:56:42.254269 17898 layer_factory.hpp:77] Creating layer Scale103
I0619 14:56:42.254276 17898 net.cpp:91] Creating Layer Scale103
I0619 14:56:42.254281 17898 net.cpp:425] Scale103 <- Convolution103
I0619 14:56:42.254287 17898 net.cpp:386] Scale103 -> Convolution103 (in-place)
I0619 14:56:42.254325 17898 layer_factory.hpp:77] Creating layer Scale103
I0619 14:56:42.254462 17898 net.cpp:141] Setting up Scale103
I0619 14:56:42.254473 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.254477 17898 net.cpp:156] Memory required for data: 2893545984
I0619 14:56:42.254484 17898 layer_factory.hpp:77] Creating layer Eltwise51
I0619 14:56:42.254492 17898 net.cpp:91] Creating Layer Eltwise51
I0619 14:56:42.254497 17898 net.cpp:425] Eltwise51 <- Eltwise50_ReLU101_0_split_1
I0619 14:56:42.254503 17898 net.cpp:425] Eltwise51 <- Convolution103
I0619 14:56:42.254508 17898 net.cpp:399] Eltwise51 -> Eltwise51
I0619 14:56:42.254531 17898 net.cpp:141] Setting up Eltwise51
I0619 14:56:42.254537 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.254541 17898 net.cpp:156] Memory required for data: 2895643136
I0619 14:56:42.254545 17898 layer_factory.hpp:77] Creating layer ReLU103
I0619 14:56:42.254551 17898 net.cpp:91] Creating Layer ReLU103
I0619 14:56:42.254555 17898 net.cpp:425] ReLU103 <- Eltwise51
I0619 14:56:42.254564 17898 net.cpp:386] ReLU103 -> Eltwise51 (in-place)
I0619 14:56:42.254570 17898 net.cpp:141] Setting up ReLU103
I0619 14:56:42.254575 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.254578 17898 net.cpp:156] Memory required for data: 2897740288
I0619 14:56:42.254582 17898 layer_factory.hpp:77] Creating layer Eltwise51_ReLU103_0_split
I0619 14:56:42.254588 17898 net.cpp:91] Creating Layer Eltwise51_ReLU103_0_split
I0619 14:56:42.254592 17898 net.cpp:425] Eltwise51_ReLU103_0_split <- Eltwise51
I0619 14:56:42.254597 17898 net.cpp:399] Eltwise51_ReLU103_0_split -> Eltwise51_ReLU103_0_split_0
I0619 14:56:42.254606 17898 net.cpp:399] Eltwise51_ReLU103_0_split -> Eltwise51_ReLU103_0_split_1
I0619 14:56:42.254643 17898 net.cpp:141] Setting up Eltwise51_ReLU103_0_split
I0619 14:56:42.254650 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.254655 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.254659 17898 net.cpp:156] Memory required for data: 2901934592
I0619 14:56:42.254663 17898 layer_factory.hpp:77] Creating layer Convolution104
I0619 14:56:42.254673 17898 net.cpp:91] Creating Layer Convolution104
I0619 14:56:42.254678 17898 net.cpp:425] Convolution104 <- Eltwise51_ReLU103_0_split_0
I0619 14:56:42.254686 17898 net.cpp:399] Convolution104 -> Convolution104
I0619 14:56:42.256312 17898 net.cpp:141] Setting up Convolution104
I0619 14:56:42.256336 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.256340 17898 net.cpp:156] Memory required for data: 2904031744
I0619 14:56:42.256352 17898 layer_factory.hpp:77] Creating layer BatchNorm104
I0619 14:56:42.256361 17898 net.cpp:91] Creating Layer BatchNorm104
I0619 14:56:42.256366 17898 net.cpp:425] BatchNorm104 <- Convolution104
I0619 14:56:42.256376 17898 net.cpp:386] BatchNorm104 -> Convolution104 (in-place)
I0619 14:56:42.256589 17898 net.cpp:141] Setting up BatchNorm104
I0619 14:56:42.256597 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.256602 17898 net.cpp:156] Memory required for data: 2906128896
I0619 14:56:42.256610 17898 layer_factory.hpp:77] Creating layer Scale104
I0619 14:56:42.256618 17898 net.cpp:91] Creating Layer Scale104
I0619 14:56:42.256623 17898 net.cpp:425] Scale104 <- Convolution104
I0619 14:56:42.256629 17898 net.cpp:386] Scale104 -> Convolution104 (in-place)
I0619 14:56:42.256669 17898 layer_factory.hpp:77] Creating layer Scale104
I0619 14:56:42.256798 17898 net.cpp:141] Setting up Scale104
I0619 14:56:42.256804 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.256808 17898 net.cpp:156] Memory required for data: 2908226048
I0619 14:56:42.256815 17898 layer_factory.hpp:77] Creating layer ReLU104
I0619 14:56:42.256825 17898 net.cpp:91] Creating Layer ReLU104
I0619 14:56:42.256830 17898 net.cpp:425] ReLU104 <- Convolution104
I0619 14:56:42.256835 17898 net.cpp:386] ReLU104 -> Convolution104 (in-place)
I0619 14:56:42.256842 17898 net.cpp:141] Setting up ReLU104
I0619 14:56:42.256849 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.256851 17898 net.cpp:156] Memory required for data: 2910323200
I0619 14:56:42.256855 17898 layer_factory.hpp:77] Creating layer Convolution105
I0619 14:56:42.256867 17898 net.cpp:91] Creating Layer Convolution105
I0619 14:56:42.256872 17898 net.cpp:425] Convolution105 <- Convolution104
I0619 14:56:42.256880 17898 net.cpp:399] Convolution105 -> Convolution105
I0619 14:56:42.258492 17898 net.cpp:141] Setting up Convolution105
I0619 14:56:42.258502 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.258507 17898 net.cpp:156] Memory required for data: 2912420352
I0619 14:56:42.258513 17898 layer_factory.hpp:77] Creating layer BatchNorm105
I0619 14:56:42.258520 17898 net.cpp:91] Creating Layer BatchNorm105
I0619 14:56:42.258525 17898 net.cpp:425] BatchNorm105 <- Convolution105
I0619 14:56:42.258536 17898 net.cpp:386] BatchNorm105 -> Convolution105 (in-place)
I0619 14:56:42.258747 17898 net.cpp:141] Setting up BatchNorm105
I0619 14:56:42.258755 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.258759 17898 net.cpp:156] Memory required for data: 2914517504
I0619 14:56:42.258767 17898 layer_factory.hpp:77] Creating layer Scale105
I0619 14:56:42.258774 17898 net.cpp:91] Creating Layer Scale105
I0619 14:56:42.258779 17898 net.cpp:425] Scale105 <- Convolution105
I0619 14:56:42.258785 17898 net.cpp:386] Scale105 -> Convolution105 (in-place)
I0619 14:56:42.258826 17898 layer_factory.hpp:77] Creating layer Scale105
I0619 14:56:42.258954 17898 net.cpp:141] Setting up Scale105
I0619 14:56:42.258961 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.258965 17898 net.cpp:156] Memory required for data: 2916614656
I0619 14:56:42.258971 17898 layer_factory.hpp:77] Creating layer Eltwise52
I0619 14:56:42.258980 17898 net.cpp:91] Creating Layer Eltwise52
I0619 14:56:42.258985 17898 net.cpp:425] Eltwise52 <- Eltwise51_ReLU103_0_split_1
I0619 14:56:42.258991 17898 net.cpp:425] Eltwise52 <- Convolution105
I0619 14:56:42.258997 17898 net.cpp:399] Eltwise52 -> Eltwise52
I0619 14:56:42.259016 17898 net.cpp:141] Setting up Eltwise52
I0619 14:56:42.259023 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.259027 17898 net.cpp:156] Memory required for data: 2918711808
I0619 14:56:42.259030 17898 layer_factory.hpp:77] Creating layer ReLU105
I0619 14:56:42.259042 17898 net.cpp:91] Creating Layer ReLU105
I0619 14:56:42.259049 17898 net.cpp:425] ReLU105 <- Eltwise52
I0619 14:56:42.259066 17898 net.cpp:386] ReLU105 -> Eltwise52 (in-place)
I0619 14:56:42.259074 17898 net.cpp:141] Setting up ReLU105
I0619 14:56:42.259080 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.259084 17898 net.cpp:156] Memory required for data: 2920808960
I0619 14:56:42.259088 17898 layer_factory.hpp:77] Creating layer Eltwise52_ReLU105_0_split
I0619 14:56:42.259096 17898 net.cpp:91] Creating Layer Eltwise52_ReLU105_0_split
I0619 14:56:42.259100 17898 net.cpp:425] Eltwise52_ReLU105_0_split <- Eltwise52
I0619 14:56:42.259106 17898 net.cpp:399] Eltwise52_ReLU105_0_split -> Eltwise52_ReLU105_0_split_0
I0619 14:56:42.259114 17898 net.cpp:399] Eltwise52_ReLU105_0_split -> Eltwise52_ReLU105_0_split_1
I0619 14:56:42.259155 17898 net.cpp:141] Setting up Eltwise52_ReLU105_0_split
I0619 14:56:42.259161 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.259166 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.259171 17898 net.cpp:156] Memory required for data: 2925003264
I0619 14:56:42.259174 17898 layer_factory.hpp:77] Creating layer Convolution106
I0619 14:56:42.259186 17898 net.cpp:91] Creating Layer Convolution106
I0619 14:56:42.259191 17898 net.cpp:425] Convolution106 <- Eltwise52_ReLU105_0_split_0
I0619 14:56:42.259198 17898 net.cpp:399] Convolution106 -> Convolution106
I0619 14:56:42.260815 17898 net.cpp:141] Setting up Convolution106
I0619 14:56:42.260824 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.260828 17898 net.cpp:156] Memory required for data: 2927100416
I0619 14:56:42.260835 17898 layer_factory.hpp:77] Creating layer BatchNorm106
I0619 14:56:42.260844 17898 net.cpp:91] Creating Layer BatchNorm106
I0619 14:56:42.260849 17898 net.cpp:425] BatchNorm106 <- Convolution106
I0619 14:56:42.260856 17898 net.cpp:386] BatchNorm106 -> Convolution106 (in-place)
I0619 14:56:42.261076 17898 net.cpp:141] Setting up BatchNorm106
I0619 14:56:42.261085 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.261088 17898 net.cpp:156] Memory required for data: 2929197568
I0619 14:56:42.261096 17898 layer_factory.hpp:77] Creating layer Scale106
I0619 14:56:42.261106 17898 net.cpp:91] Creating Layer Scale106
I0619 14:56:42.261111 17898 net.cpp:425] Scale106 <- Convolution106
I0619 14:56:42.261116 17898 net.cpp:386] Scale106 -> Convolution106 (in-place)
I0619 14:56:42.261157 17898 layer_factory.hpp:77] Creating layer Scale106
I0619 14:56:42.261286 17898 net.cpp:141] Setting up Scale106
I0619 14:56:42.261293 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.261297 17898 net.cpp:156] Memory required for data: 2931294720
I0619 14:56:42.261304 17898 layer_factory.hpp:77] Creating layer ReLU106
I0619 14:56:42.261310 17898 net.cpp:91] Creating Layer ReLU106
I0619 14:56:42.261314 17898 net.cpp:425] ReLU106 <- Convolution106
I0619 14:56:42.261322 17898 net.cpp:386] ReLU106 -> Convolution106 (in-place)
I0619 14:56:42.261329 17898 net.cpp:141] Setting up ReLU106
I0619 14:56:42.261335 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.261338 17898 net.cpp:156] Memory required for data: 2933391872
I0619 14:56:42.261343 17898 layer_factory.hpp:77] Creating layer Convolution107
I0619 14:56:42.261354 17898 net.cpp:91] Creating Layer Convolution107
I0619 14:56:42.261358 17898 net.cpp:425] Convolution107 <- Convolution106
I0619 14:56:42.261365 17898 net.cpp:399] Convolution107 -> Convolution107
I0619 14:56:42.262995 17898 net.cpp:141] Setting up Convolution107
I0619 14:56:42.263005 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.263008 17898 net.cpp:156] Memory required for data: 2935489024
I0619 14:56:42.263015 17898 layer_factory.hpp:77] Creating layer BatchNorm107
I0619 14:56:42.263027 17898 net.cpp:91] Creating Layer BatchNorm107
I0619 14:56:42.263032 17898 net.cpp:425] BatchNorm107 <- Convolution107
I0619 14:56:42.263038 17898 net.cpp:386] BatchNorm107 -> Convolution107 (in-place)
I0619 14:56:42.263250 17898 net.cpp:141] Setting up BatchNorm107
I0619 14:56:42.263262 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.263276 17898 net.cpp:156] Memory required for data: 2937586176
I0619 14:56:42.263285 17898 layer_factory.hpp:77] Creating layer Scale107
I0619 14:56:42.263293 17898 net.cpp:91] Creating Layer Scale107
I0619 14:56:42.263298 17898 net.cpp:425] Scale107 <- Convolution107
I0619 14:56:42.263303 17898 net.cpp:386] Scale107 -> Convolution107 (in-place)
I0619 14:56:42.263345 17898 layer_factory.hpp:77] Creating layer Scale107
I0619 14:56:42.263473 17898 net.cpp:141] Setting up Scale107
I0619 14:56:42.263480 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.263484 17898 net.cpp:156] Memory required for data: 2939683328
I0619 14:56:42.263491 17898 layer_factory.hpp:77] Creating layer Eltwise53
I0619 14:56:42.263499 17898 net.cpp:91] Creating Layer Eltwise53
I0619 14:56:42.263506 17898 net.cpp:425] Eltwise53 <- Eltwise52_ReLU105_0_split_1
I0619 14:56:42.263512 17898 net.cpp:425] Eltwise53 <- Convolution107
I0619 14:56:42.263519 17898 net.cpp:399] Eltwise53 -> Eltwise53
I0619 14:56:42.263538 17898 net.cpp:141] Setting up Eltwise53
I0619 14:56:42.263545 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.263548 17898 net.cpp:156] Memory required for data: 2941780480
I0619 14:56:42.263552 17898 layer_factory.hpp:77] Creating layer ReLU107
I0619 14:56:42.263561 17898 net.cpp:91] Creating Layer ReLU107
I0619 14:56:42.263566 17898 net.cpp:425] ReLU107 <- Eltwise53
I0619 14:56:42.263571 17898 net.cpp:386] ReLU107 -> Eltwise53 (in-place)
I0619 14:56:42.263578 17898 net.cpp:141] Setting up ReLU107
I0619 14:56:42.263583 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.263587 17898 net.cpp:156] Memory required for data: 2943877632
I0619 14:56:42.263592 17898 layer_factory.hpp:77] Creating layer Eltwise53_ReLU107_0_split
I0619 14:56:42.263597 17898 net.cpp:91] Creating Layer Eltwise53_ReLU107_0_split
I0619 14:56:42.263602 17898 net.cpp:425] Eltwise53_ReLU107_0_split <- Eltwise53
I0619 14:56:42.263609 17898 net.cpp:399] Eltwise53_ReLU107_0_split -> Eltwise53_ReLU107_0_split_0
I0619 14:56:42.263617 17898 net.cpp:399] Eltwise53_ReLU107_0_split -> Eltwise53_ReLU107_0_split_1
I0619 14:56:42.263669 17898 net.cpp:141] Setting up Eltwise53_ReLU107_0_split
I0619 14:56:42.263675 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.263680 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.263684 17898 net.cpp:156] Memory required for data: 2948071936
I0619 14:56:42.263689 17898 layer_factory.hpp:77] Creating layer Convolution108
I0619 14:56:42.263700 17898 net.cpp:91] Creating Layer Convolution108
I0619 14:56:42.263705 17898 net.cpp:425] Convolution108 <- Eltwise53_ReLU107_0_split_0
I0619 14:56:42.263711 17898 net.cpp:399] Convolution108 -> Convolution108
I0619 14:56:42.265329 17898 net.cpp:141] Setting up Convolution108
I0619 14:56:42.265339 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.265343 17898 net.cpp:156] Memory required for data: 2950169088
I0619 14:56:42.265350 17898 layer_factory.hpp:77] Creating layer BatchNorm108
I0619 14:56:42.265360 17898 net.cpp:91] Creating Layer BatchNorm108
I0619 14:56:42.265364 17898 net.cpp:425] BatchNorm108 <- Convolution108
I0619 14:56:42.265372 17898 net.cpp:386] BatchNorm108 -> Convolution108 (in-place)
I0619 14:56:42.265588 17898 net.cpp:141] Setting up BatchNorm108
I0619 14:56:42.265595 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.265599 17898 net.cpp:156] Memory required for data: 2952266240
I0619 14:56:42.265607 17898 layer_factory.hpp:77] Creating layer Scale108
I0619 14:56:42.265617 17898 net.cpp:91] Creating Layer Scale108
I0619 14:56:42.265622 17898 net.cpp:425] Scale108 <- Convolution108
I0619 14:56:42.265628 17898 net.cpp:386] Scale108 -> Convolution108 (in-place)
I0619 14:56:42.265664 17898 layer_factory.hpp:77] Creating layer Scale108
I0619 14:56:42.265797 17898 net.cpp:141] Setting up Scale108
I0619 14:56:42.265805 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.265808 17898 net.cpp:156] Memory required for data: 2954363392
I0619 14:56:42.265818 17898 layer_factory.hpp:77] Creating layer ReLU108
I0619 14:56:42.265841 17898 net.cpp:91] Creating Layer ReLU108
I0619 14:56:42.265846 17898 net.cpp:425] ReLU108 <- Convolution108
I0619 14:56:42.265856 17898 net.cpp:386] ReLU108 -> Convolution108 (in-place)
I0619 14:56:42.265863 17898 net.cpp:141] Setting up ReLU108
I0619 14:56:42.265869 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.265872 17898 net.cpp:156] Memory required for data: 2956460544
I0619 14:56:42.265877 17898 layer_factory.hpp:77] Creating layer Convolution109
I0619 14:56:42.265888 17898 net.cpp:91] Creating Layer Convolution109
I0619 14:56:42.265893 17898 net.cpp:425] Convolution109 <- Convolution108
I0619 14:56:42.265899 17898 net.cpp:399] Convolution109 -> Convolution109
I0619 14:56:42.268188 17898 net.cpp:141] Setting up Convolution109
I0619 14:56:42.268203 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.268208 17898 net.cpp:156] Memory required for data: 2958557696
I0619 14:56:42.268216 17898 layer_factory.hpp:77] Creating layer BatchNorm109
I0619 14:56:42.268224 17898 net.cpp:91] Creating Layer BatchNorm109
I0619 14:56:42.268229 17898 net.cpp:425] BatchNorm109 <- Convolution109
I0619 14:56:42.268239 17898 net.cpp:386] BatchNorm109 -> Convolution109 (in-place)
I0619 14:56:42.268463 17898 net.cpp:141] Setting up BatchNorm109
I0619 14:56:42.268472 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.268476 17898 net.cpp:156] Memory required for data: 2960654848
I0619 14:56:42.268484 17898 layer_factory.hpp:77] Creating layer Scale109
I0619 14:56:42.268492 17898 net.cpp:91] Creating Layer Scale109
I0619 14:56:42.268496 17898 net.cpp:425] Scale109 <- Convolution109
I0619 14:56:42.268504 17898 net.cpp:386] Scale109 -> Convolution109 (in-place)
I0619 14:56:42.268544 17898 layer_factory.hpp:77] Creating layer Scale109
I0619 14:56:42.268679 17898 net.cpp:141] Setting up Scale109
I0619 14:56:42.268687 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.268692 17898 net.cpp:156] Memory required for data: 2962752000
I0619 14:56:42.268698 17898 layer_factory.hpp:77] Creating layer Eltwise54
I0619 14:56:42.268705 17898 net.cpp:91] Creating Layer Eltwise54
I0619 14:56:42.268710 17898 net.cpp:425] Eltwise54 <- Eltwise53_ReLU107_0_split_1
I0619 14:56:42.268717 17898 net.cpp:425] Eltwise54 <- Convolution109
I0619 14:56:42.268723 17898 net.cpp:399] Eltwise54 -> Eltwise54
I0619 14:56:42.268745 17898 net.cpp:141] Setting up Eltwise54
I0619 14:56:42.268753 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.268755 17898 net.cpp:156] Memory required for data: 2964849152
I0619 14:56:42.268759 17898 layer_factory.hpp:77] Creating layer ReLU109
I0619 14:56:42.268765 17898 net.cpp:91] Creating Layer ReLU109
I0619 14:56:42.268770 17898 net.cpp:425] ReLU109 <- Eltwise54
I0619 14:56:42.268777 17898 net.cpp:386] ReLU109 -> Eltwise54 (in-place)
I0619 14:56:42.268784 17898 net.cpp:141] Setting up ReLU109
I0619 14:56:42.268790 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.268795 17898 net.cpp:156] Memory required for data: 2966946304
I0619 14:56:42.268797 17898 layer_factory.hpp:77] Creating layer Pooling4
I0619 14:56:42.268805 17898 net.cpp:91] Creating Layer Pooling4
I0619 14:56:42.268810 17898 net.cpp:425] Pooling4 <- Eltwise54
I0619 14:56:42.268817 17898 net.cpp:399] Pooling4 -> Pooling4
I0619 14:56:42.268844 17898 net.cpp:141] Setting up Pooling4
I0619 14:56:42.268851 17898 net.cpp:148] Top shape: 128 64 1 1 (8192)
I0619 14:56:42.268854 17898 net.cpp:156] Memory required for data: 2966979072
I0619 14:56:42.268858 17898 layer_factory.hpp:77] Creating layer InnerProduct1
I0619 14:56:42.268867 17898 net.cpp:91] Creating Layer InnerProduct1
I0619 14:56:42.268870 17898 net.cpp:425] InnerProduct1 <- Pooling4
I0619 14:56:42.268877 17898 net.cpp:399] InnerProduct1 -> InnerProduct1
I0619 14:56:42.269034 17898 net.cpp:141] Setting up InnerProduct1
I0619 14:56:42.269042 17898 net.cpp:148] Top shape: 128 10 (1280)
I0619 14:56:42.269047 17898 net.cpp:156] Memory required for data: 2966984192
I0619 14:56:42.269073 17898 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0619 14:56:42.269081 17898 net.cpp:91] Creating Layer SoftmaxWithLoss1
I0619 14:56:42.269086 17898 net.cpp:425] SoftmaxWithLoss1 <- InnerProduct1
I0619 14:56:42.269091 17898 net.cpp:425] SoftmaxWithLoss1 <- Data2
I0619 14:56:42.269104 17898 net.cpp:399] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0619 14:56:42.269130 17898 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0619 14:56:42.269237 17898 net.cpp:141] Setting up SoftmaxWithLoss1
I0619 14:56:42.269246 17898 net.cpp:148] Top shape: (1)
I0619 14:56:42.269249 17898 net.cpp:151]     with loss weight 1
I0619 14:56:42.269273 17898 net.cpp:156] Memory required for data: 2966984196
I0619 14:56:42.269276 17898 net.cpp:217] SoftmaxWithLoss1 needs backward computation.
I0619 14:56:42.269281 17898 net.cpp:217] InnerProduct1 needs backward computation.
I0619 14:56:42.269285 17898 net.cpp:217] Pooling4 needs backward computation.
I0619 14:56:42.269289 17898 net.cpp:217] ReLU109 needs backward computation.
I0619 14:56:42.269294 17898 net.cpp:217] Eltwise54 needs backward computation.
I0619 14:56:42.269299 17898 net.cpp:217] Scale109 needs backward computation.
I0619 14:56:42.269301 17898 net.cpp:217] BatchNorm109 needs backward computation.
I0619 14:56:42.269310 17898 net.cpp:217] Convolution109 needs backward computation.
I0619 14:56:42.269315 17898 net.cpp:217] ReLU108 needs backward computation.
I0619 14:56:42.269318 17898 net.cpp:217] Scale108 needs backward computation.
I0619 14:56:42.269322 17898 net.cpp:217] BatchNorm108 needs backward computation.
I0619 14:56:42.269325 17898 net.cpp:217] Convolution108 needs backward computation.
I0619 14:56:42.269330 17898 net.cpp:217] Eltwise53_ReLU107_0_split needs backward computation.
I0619 14:56:42.269333 17898 net.cpp:217] ReLU107 needs backward computation.
I0619 14:56:42.269337 17898 net.cpp:217] Eltwise53 needs backward computation.
I0619 14:56:42.269342 17898 net.cpp:217] Scale107 needs backward computation.
I0619 14:56:42.269346 17898 net.cpp:217] BatchNorm107 needs backward computation.
I0619 14:56:42.269350 17898 net.cpp:217] Convolution107 needs backward computation.
I0619 14:56:42.269353 17898 net.cpp:217] ReLU106 needs backward computation.
I0619 14:56:42.269357 17898 net.cpp:217] Scale106 needs backward computation.
I0619 14:56:42.269361 17898 net.cpp:217] BatchNorm106 needs backward computation.
I0619 14:56:42.269364 17898 net.cpp:217] Convolution106 needs backward computation.
I0619 14:56:42.269368 17898 net.cpp:217] Eltwise52_ReLU105_0_split needs backward computation.
I0619 14:56:42.269372 17898 net.cpp:217] ReLU105 needs backward computation.
I0619 14:56:42.269376 17898 net.cpp:217] Eltwise52 needs backward computation.
I0619 14:56:42.269381 17898 net.cpp:217] Scale105 needs backward computation.
I0619 14:56:42.269384 17898 net.cpp:217] BatchNorm105 needs backward computation.
I0619 14:56:42.269388 17898 net.cpp:217] Convolution105 needs backward computation.
I0619 14:56:42.269392 17898 net.cpp:217] ReLU104 needs backward computation.
I0619 14:56:42.269395 17898 net.cpp:217] Scale104 needs backward computation.
I0619 14:56:42.269399 17898 net.cpp:217] BatchNorm104 needs backward computation.
I0619 14:56:42.269402 17898 net.cpp:217] Convolution104 needs backward computation.
I0619 14:56:42.269407 17898 net.cpp:217] Eltwise51_ReLU103_0_split needs backward computation.
I0619 14:56:42.269412 17898 net.cpp:217] ReLU103 needs backward computation.
I0619 14:56:42.269414 17898 net.cpp:217] Eltwise51 needs backward computation.
I0619 14:56:42.269419 17898 net.cpp:217] Scale103 needs backward computation.
I0619 14:56:42.269423 17898 net.cpp:217] BatchNorm103 needs backward computation.
I0619 14:56:42.269426 17898 net.cpp:217] Convolution103 needs backward computation.
I0619 14:56:42.269430 17898 net.cpp:217] ReLU102 needs backward computation.
I0619 14:56:42.269434 17898 net.cpp:217] Scale102 needs backward computation.
I0619 14:56:42.269438 17898 net.cpp:217] BatchNorm102 needs backward computation.
I0619 14:56:42.269444 17898 net.cpp:217] Convolution102 needs backward computation.
I0619 14:56:42.269466 17898 net.cpp:217] Eltwise50_ReLU101_0_split needs backward computation.
I0619 14:56:42.269470 17898 net.cpp:217] ReLU101 needs backward computation.
I0619 14:56:42.269474 17898 net.cpp:217] Eltwise50 needs backward computation.
I0619 14:56:42.269479 17898 net.cpp:217] Scale101 needs backward computation.
I0619 14:56:42.269482 17898 net.cpp:217] BatchNorm101 needs backward computation.
I0619 14:56:42.269486 17898 net.cpp:217] Convolution101 needs backward computation.
I0619 14:56:42.269492 17898 net.cpp:217] ReLU100 needs backward computation.
I0619 14:56:42.269496 17898 net.cpp:217] Scale100 needs backward computation.
I0619 14:56:42.269500 17898 net.cpp:217] BatchNorm100 needs backward computation.
I0619 14:56:42.269503 17898 net.cpp:217] Convolution100 needs backward computation.
I0619 14:56:42.269508 17898 net.cpp:217] Eltwise49_ReLU99_0_split needs backward computation.
I0619 14:56:42.269512 17898 net.cpp:217] ReLU99 needs backward computation.
I0619 14:56:42.269516 17898 net.cpp:217] Eltwise49 needs backward computation.
I0619 14:56:42.269521 17898 net.cpp:217] Scale99 needs backward computation.
I0619 14:56:42.269526 17898 net.cpp:217] BatchNorm99 needs backward computation.
I0619 14:56:42.269529 17898 net.cpp:217] Convolution99 needs backward computation.
I0619 14:56:42.269533 17898 net.cpp:217] ReLU98 needs backward computation.
I0619 14:56:42.269537 17898 net.cpp:217] Scale98 needs backward computation.
I0619 14:56:42.269541 17898 net.cpp:217] BatchNorm98 needs backward computation.
I0619 14:56:42.269544 17898 net.cpp:217] Convolution98 needs backward computation.
I0619 14:56:42.269548 17898 net.cpp:217] Eltwise48_ReLU97_0_split needs backward computation.
I0619 14:56:42.269553 17898 net.cpp:217] ReLU97 needs backward computation.
I0619 14:56:42.269556 17898 net.cpp:217] Eltwise48 needs backward computation.
I0619 14:56:42.269562 17898 net.cpp:217] Scale97 needs backward computation.
I0619 14:56:42.269565 17898 net.cpp:217] BatchNorm97 needs backward computation.
I0619 14:56:42.269569 17898 net.cpp:217] Convolution97 needs backward computation.
I0619 14:56:42.269573 17898 net.cpp:217] ReLU96 needs backward computation.
I0619 14:56:42.269577 17898 net.cpp:217] Scale96 needs backward computation.
I0619 14:56:42.269580 17898 net.cpp:217] BatchNorm96 needs backward computation.
I0619 14:56:42.269584 17898 net.cpp:217] Convolution96 needs backward computation.
I0619 14:56:42.269588 17898 net.cpp:217] Eltwise47_ReLU95_0_split needs backward computation.
I0619 14:56:42.269593 17898 net.cpp:217] ReLU95 needs backward computation.
I0619 14:56:42.269596 17898 net.cpp:217] Eltwise47 needs backward computation.
I0619 14:56:42.269600 17898 net.cpp:217] Scale95 needs backward computation.
I0619 14:56:42.269604 17898 net.cpp:217] BatchNorm95 needs backward computation.
I0619 14:56:42.269608 17898 net.cpp:217] Convolution95 needs backward computation.
I0619 14:56:42.269611 17898 net.cpp:217] ReLU94 needs backward computation.
I0619 14:56:42.269615 17898 net.cpp:217] Scale94 needs backward computation.
I0619 14:56:42.269619 17898 net.cpp:217] BatchNorm94 needs backward computation.
I0619 14:56:42.269623 17898 net.cpp:217] Convolution94 needs backward computation.
I0619 14:56:42.269628 17898 net.cpp:217] Eltwise46_ReLU93_0_split needs backward computation.
I0619 14:56:42.269631 17898 net.cpp:217] ReLU93 needs backward computation.
I0619 14:56:42.269635 17898 net.cpp:217] Eltwise46 needs backward computation.
I0619 14:56:42.269639 17898 net.cpp:217] Scale93 needs backward computation.
I0619 14:56:42.269644 17898 net.cpp:217] BatchNorm93 needs backward computation.
I0619 14:56:42.269646 17898 net.cpp:217] Convolution93 needs backward computation.
I0619 14:56:42.269650 17898 net.cpp:217] ReLU92 needs backward computation.
I0619 14:56:42.269654 17898 net.cpp:217] Scale92 needs backward computation.
I0619 14:56:42.269659 17898 net.cpp:217] BatchNorm92 needs backward computation.
I0619 14:56:42.269661 17898 net.cpp:217] Convolution92 needs backward computation.
I0619 14:56:42.269668 17898 net.cpp:217] Eltwise45_ReLU91_0_split needs backward computation.
I0619 14:56:42.269680 17898 net.cpp:217] ReLU91 needs backward computation.
I0619 14:56:42.269683 17898 net.cpp:217] Eltwise45 needs backward computation.
I0619 14:56:42.269687 17898 net.cpp:217] Scale91 needs backward computation.
I0619 14:56:42.269691 17898 net.cpp:217] BatchNorm91 needs backward computation.
I0619 14:56:42.269695 17898 net.cpp:217] Convolution91 needs backward computation.
I0619 14:56:42.269698 17898 net.cpp:217] ReLU90 needs backward computation.
I0619 14:56:42.269702 17898 net.cpp:217] Scale90 needs backward computation.
I0619 14:56:42.269706 17898 net.cpp:217] BatchNorm90 needs backward computation.
I0619 14:56:42.269711 17898 net.cpp:217] Convolution90 needs backward computation.
I0619 14:56:42.269714 17898 net.cpp:217] Eltwise44_ReLU89_0_split needs backward computation.
I0619 14:56:42.269718 17898 net.cpp:217] ReLU89 needs backward computation.
I0619 14:56:42.269721 17898 net.cpp:217] Eltwise44 needs backward computation.
I0619 14:56:42.269726 17898 net.cpp:217] Scale89 needs backward computation.
I0619 14:56:42.269729 17898 net.cpp:217] BatchNorm89 needs backward computation.
I0619 14:56:42.269733 17898 net.cpp:217] Convolution89 needs backward computation.
I0619 14:56:42.269737 17898 net.cpp:217] ReLU88 needs backward computation.
I0619 14:56:42.269742 17898 net.cpp:217] Scale88 needs backward computation.
I0619 14:56:42.269744 17898 net.cpp:217] BatchNorm88 needs backward computation.
I0619 14:56:42.269748 17898 net.cpp:217] Convolution88 needs backward computation.
I0619 14:56:42.269752 17898 net.cpp:217] Eltwise43_ReLU87_0_split needs backward computation.
I0619 14:56:42.269757 17898 net.cpp:217] ReLU87 needs backward computation.
I0619 14:56:42.269760 17898 net.cpp:217] Eltwise43 needs backward computation.
I0619 14:56:42.269764 17898 net.cpp:217] Scale87 needs backward computation.
I0619 14:56:42.269768 17898 net.cpp:217] BatchNorm87 needs backward computation.
I0619 14:56:42.269772 17898 net.cpp:217] Convolution87 needs backward computation.
I0619 14:56:42.269775 17898 net.cpp:217] ReLU86 needs backward computation.
I0619 14:56:42.269779 17898 net.cpp:217] Scale86 needs backward computation.
I0619 14:56:42.269783 17898 net.cpp:217] BatchNorm86 needs backward computation.
I0619 14:56:42.269788 17898 net.cpp:217] Convolution86 needs backward computation.
I0619 14:56:42.269791 17898 net.cpp:217] Eltwise42_ReLU85_0_split needs backward computation.
I0619 14:56:42.269795 17898 net.cpp:217] ReLU85 needs backward computation.
I0619 14:56:42.269798 17898 net.cpp:217] Eltwise42 needs backward computation.
I0619 14:56:42.269804 17898 net.cpp:217] Scale85 needs backward computation.
I0619 14:56:42.269806 17898 net.cpp:217] BatchNorm85 needs backward computation.
I0619 14:56:42.269810 17898 net.cpp:217] Convolution85 needs backward computation.
I0619 14:56:42.269814 17898 net.cpp:217] ReLU84 needs backward computation.
I0619 14:56:42.269819 17898 net.cpp:217] Scale84 needs backward computation.
I0619 14:56:42.269821 17898 net.cpp:217] BatchNorm84 needs backward computation.
I0619 14:56:42.269825 17898 net.cpp:217] Convolution84 needs backward computation.
I0619 14:56:42.269829 17898 net.cpp:217] Eltwise41_ReLU83_0_split needs backward computation.
I0619 14:56:42.269834 17898 net.cpp:217] ReLU83 needs backward computation.
I0619 14:56:42.269837 17898 net.cpp:217] Eltwise41 needs backward computation.
I0619 14:56:42.269841 17898 net.cpp:217] Scale83 needs backward computation.
I0619 14:56:42.269845 17898 net.cpp:217] BatchNorm83 needs backward computation.
I0619 14:56:42.269848 17898 net.cpp:217] Convolution83 needs backward computation.
I0619 14:56:42.269852 17898 net.cpp:217] ReLU82 needs backward computation.
I0619 14:56:42.269856 17898 net.cpp:217] Scale82 needs backward computation.
I0619 14:56:42.269860 17898 net.cpp:217] BatchNorm82 needs backward computation.
I0619 14:56:42.269863 17898 net.cpp:217] Convolution82 needs backward computation.
I0619 14:56:42.269867 17898 net.cpp:217] Eltwise40_ReLU81_0_split needs backward computation.
I0619 14:56:42.269881 17898 net.cpp:217] ReLU81 needs backward computation.
I0619 14:56:42.269884 17898 net.cpp:217] Eltwise40 needs backward computation.
I0619 14:56:42.269889 17898 net.cpp:217] Scale81 needs backward computation.
I0619 14:56:42.269892 17898 net.cpp:217] BatchNorm81 needs backward computation.
I0619 14:56:42.269896 17898 net.cpp:217] Convolution81 needs backward computation.
I0619 14:56:42.269901 17898 net.cpp:217] ReLU80 needs backward computation.
I0619 14:56:42.269904 17898 net.cpp:217] Scale80 needs backward computation.
I0619 14:56:42.269907 17898 net.cpp:217] BatchNorm80 needs backward computation.
I0619 14:56:42.269912 17898 net.cpp:217] Convolution80 needs backward computation.
I0619 14:56:42.269915 17898 net.cpp:217] Eltwise39_ReLU79_0_split needs backward computation.
I0619 14:56:42.269919 17898 net.cpp:217] ReLU79 needs backward computation.
I0619 14:56:42.269923 17898 net.cpp:217] Eltwise39 needs backward computation.
I0619 14:56:42.269928 17898 net.cpp:217] Scale79 needs backward computation.
I0619 14:56:42.269932 17898 net.cpp:217] BatchNorm79 needs backward computation.
I0619 14:56:42.269935 17898 net.cpp:217] Convolution79 needs backward computation.
I0619 14:56:42.269939 17898 net.cpp:217] ReLU78 needs backward computation.
I0619 14:56:42.269943 17898 net.cpp:217] Scale78 needs backward computation.
I0619 14:56:42.269948 17898 net.cpp:217] BatchNorm78 needs backward computation.
I0619 14:56:42.269950 17898 net.cpp:217] Convolution78 needs backward computation.
I0619 14:56:42.269955 17898 net.cpp:217] Eltwise38_ReLU77_0_split needs backward computation.
I0619 14:56:42.269959 17898 net.cpp:217] ReLU77 needs backward computation.
I0619 14:56:42.269963 17898 net.cpp:217] Eltwise38 needs backward computation.
I0619 14:56:42.269968 17898 net.cpp:217] Scale77 needs backward computation.
I0619 14:56:42.269971 17898 net.cpp:217] BatchNorm77 needs backward computation.
I0619 14:56:42.269974 17898 net.cpp:217] Convolution77 needs backward computation.
I0619 14:56:42.269979 17898 net.cpp:217] ReLU76 needs backward computation.
I0619 14:56:42.269982 17898 net.cpp:217] Scale76 needs backward computation.
I0619 14:56:42.269986 17898 net.cpp:217] BatchNorm76 needs backward computation.
I0619 14:56:42.269989 17898 net.cpp:217] Convolution76 needs backward computation.
I0619 14:56:42.269994 17898 net.cpp:217] Eltwise37_ReLU75_0_split needs backward computation.
I0619 14:56:42.269997 17898 net.cpp:217] ReLU75 needs backward computation.
I0619 14:56:42.270001 17898 net.cpp:217] Eltwise37 needs backward computation.
I0619 14:56:42.270006 17898 net.cpp:217] Scale75 needs backward computation.
I0619 14:56:42.270009 17898 net.cpp:217] BatchNorm75 needs backward computation.
I0619 14:56:42.270014 17898 net.cpp:217] Convolution75 needs backward computation.
I0619 14:56:42.270017 17898 net.cpp:217] ReLU74 needs backward computation.
I0619 14:56:42.270021 17898 net.cpp:217] Scale74 needs backward computation.
I0619 14:56:42.270025 17898 net.cpp:217] BatchNorm74 needs backward computation.
I0619 14:56:42.270028 17898 net.cpp:217] Convolution74 needs backward computation.
I0619 14:56:42.270032 17898 net.cpp:217] Concat2 needs backward computation.
I0619 14:56:42.270037 17898 net.cpp:219] Input2 does not need backward computation.
I0619 14:56:42.270041 17898 net.cpp:217] Pooling2 needs backward computation.
I0619 14:56:42.270046 17898 net.cpp:217] Eltwise36_ReLU73_0_split needs backward computation.
I0619 14:56:42.270051 17898 net.cpp:217] ReLU73 needs backward computation.
I0619 14:56:42.270053 17898 net.cpp:217] Eltwise36 needs backward computation.
I0619 14:56:42.270058 17898 net.cpp:217] Scale73 needs backward computation.
I0619 14:56:42.270062 17898 net.cpp:217] BatchNorm73 needs backward computation.
I0619 14:56:42.270066 17898 net.cpp:217] Convolution73 needs backward computation.
I0619 14:56:42.270069 17898 net.cpp:217] ReLU72 needs backward computation.
I0619 14:56:42.270073 17898 net.cpp:217] Scale72 needs backward computation.
I0619 14:56:42.270079 17898 net.cpp:217] BatchNorm72 needs backward computation.
I0619 14:56:42.270089 17898 net.cpp:217] Convolution72 needs backward computation.
I0619 14:56:42.270094 17898 net.cpp:217] Eltwise35_ReLU71_0_split needs backward computation.
I0619 14:56:42.270098 17898 net.cpp:217] ReLU71 needs backward computation.
I0619 14:56:42.270102 17898 net.cpp:217] Eltwise35 needs backward computation.
I0619 14:56:42.270107 17898 net.cpp:217] Scale71 needs backward computation.
I0619 14:56:42.270109 17898 net.cpp:217] BatchNorm71 needs backward computation.
I0619 14:56:42.270113 17898 net.cpp:217] Convolution71 needs backward computation.
I0619 14:56:42.270117 17898 net.cpp:217] ReLU70 needs backward computation.
I0619 14:56:42.270122 17898 net.cpp:217] Scale70 needs backward computation.
I0619 14:56:42.270125 17898 net.cpp:217] BatchNorm70 needs backward computation.
I0619 14:56:42.270129 17898 net.cpp:217] Convolution70 needs backward computation.
I0619 14:56:42.270133 17898 net.cpp:217] Eltwise34_ReLU69_0_split needs backward computation.
I0619 14:56:42.270138 17898 net.cpp:217] ReLU69 needs backward computation.
I0619 14:56:42.270141 17898 net.cpp:217] Eltwise34 needs backward computation.
I0619 14:56:42.270145 17898 net.cpp:217] Scale69 needs backward computation.
I0619 14:56:42.270149 17898 net.cpp:217] BatchNorm69 needs backward computation.
I0619 14:56:42.270153 17898 net.cpp:217] Convolution69 needs backward computation.
I0619 14:56:42.270158 17898 net.cpp:217] ReLU68 needs backward computation.
I0619 14:56:42.270161 17898 net.cpp:217] Scale68 needs backward computation.
I0619 14:56:42.270164 17898 net.cpp:217] BatchNorm68 needs backward computation.
I0619 14:56:42.270169 17898 net.cpp:217] Convolution68 needs backward computation.
I0619 14:56:42.270172 17898 net.cpp:217] Eltwise33_ReLU67_0_split needs backward computation.
I0619 14:56:42.270179 17898 net.cpp:217] ReLU67 needs backward computation.
I0619 14:56:42.270184 17898 net.cpp:217] Eltwise33 needs backward computation.
I0619 14:56:42.270187 17898 net.cpp:217] Scale67 needs backward computation.
I0619 14:56:42.270191 17898 net.cpp:217] BatchNorm67 needs backward computation.
I0619 14:56:42.270195 17898 net.cpp:217] Convolution67 needs backward computation.
I0619 14:56:42.270198 17898 net.cpp:217] ReLU66 needs backward computation.
I0619 14:56:42.270208 17898 net.cpp:217] Scale66 needs backward computation.
I0619 14:56:42.270212 17898 net.cpp:217] BatchNorm66 needs backward computation.
I0619 14:56:42.270215 17898 net.cpp:217] Convolution66 needs backward computation.
I0619 14:56:42.270220 17898 net.cpp:217] Eltwise32_ReLU65_0_split needs backward computation.
I0619 14:56:42.270223 17898 net.cpp:217] ReLU65 needs backward computation.
I0619 14:56:42.270227 17898 net.cpp:217] Eltwise32 needs backward computation.
I0619 14:56:42.270236 17898 net.cpp:217] Scale65 needs backward computation.
I0619 14:56:42.270239 17898 net.cpp:217] BatchNorm65 needs backward computation.
I0619 14:56:42.270242 17898 net.cpp:217] Convolution65 needs backward computation.
I0619 14:56:42.270246 17898 net.cpp:217] ReLU64 needs backward computation.
I0619 14:56:42.270251 17898 net.cpp:217] Scale64 needs backward computation.
I0619 14:56:42.270254 17898 net.cpp:217] BatchNorm64 needs backward computation.
I0619 14:56:42.270258 17898 net.cpp:217] Convolution64 needs backward computation.
I0619 14:56:42.270262 17898 net.cpp:217] Eltwise31_ReLU63_0_split needs backward computation.
I0619 14:56:42.270267 17898 net.cpp:217] ReLU63 needs backward computation.
I0619 14:56:42.270270 17898 net.cpp:217] Eltwise31 needs backward computation.
I0619 14:56:42.270274 17898 net.cpp:217] Scale63 needs backward computation.
I0619 14:56:42.270278 17898 net.cpp:217] BatchNorm63 needs backward computation.
I0619 14:56:42.270282 17898 net.cpp:217] Convolution63 needs backward computation.
I0619 14:56:42.270287 17898 net.cpp:217] ReLU62 needs backward computation.
I0619 14:56:42.270290 17898 net.cpp:217] Scale62 needs backward computation.
I0619 14:56:42.270294 17898 net.cpp:217] BatchNorm62 needs backward computation.
I0619 14:56:42.270301 17898 net.cpp:217] Convolution62 needs backward computation.
I0619 14:56:42.270313 17898 net.cpp:217] Eltwise30_ReLU61_0_split needs backward computation.
I0619 14:56:42.270316 17898 net.cpp:217] ReLU61 needs backward computation.
I0619 14:56:42.270320 17898 net.cpp:217] Eltwise30 needs backward computation.
I0619 14:56:42.270325 17898 net.cpp:217] Scale61 needs backward computation.
I0619 14:56:42.270328 17898 net.cpp:217] BatchNorm61 needs backward computation.
I0619 14:56:42.270333 17898 net.cpp:217] Convolution61 needs backward computation.
I0619 14:56:42.270336 17898 net.cpp:217] ReLU60 needs backward computation.
I0619 14:56:42.270340 17898 net.cpp:217] Scale60 needs backward computation.
I0619 14:56:42.270344 17898 net.cpp:217] BatchNorm60 needs backward computation.
I0619 14:56:42.270349 17898 net.cpp:217] Convolution60 needs backward computation.
I0619 14:56:42.270357 17898 net.cpp:217] Eltwise29_ReLU59_0_split needs backward computation.
I0619 14:56:42.270362 17898 net.cpp:217] ReLU59 needs backward computation.
I0619 14:56:42.270366 17898 net.cpp:217] Eltwise29 needs backward computation.
I0619 14:56:42.270371 17898 net.cpp:217] Scale59 needs backward computation.
I0619 14:56:42.270375 17898 net.cpp:217] BatchNorm59 needs backward computation.
I0619 14:56:42.270380 17898 net.cpp:217] Convolution59 needs backward computation.
I0619 14:56:42.270383 17898 net.cpp:217] ReLU58 needs backward computation.
I0619 14:56:42.270387 17898 net.cpp:217] Scale58 needs backward computation.
I0619 14:56:42.270391 17898 net.cpp:217] BatchNorm58 needs backward computation.
I0619 14:56:42.270395 17898 net.cpp:217] Convolution58 needs backward computation.
I0619 14:56:42.270398 17898 net.cpp:217] Eltwise28_ReLU57_0_split needs backward computation.
I0619 14:56:42.270403 17898 net.cpp:217] ReLU57 needs backward computation.
I0619 14:56:42.270406 17898 net.cpp:217] Eltwise28 needs backward computation.
I0619 14:56:42.270411 17898 net.cpp:217] Scale57 needs backward computation.
I0619 14:56:42.270416 17898 net.cpp:217] BatchNorm57 needs backward computation.
I0619 14:56:42.270419 17898 net.cpp:217] Convolution57 needs backward computation.
I0619 14:56:42.270423 17898 net.cpp:217] ReLU56 needs backward computation.
I0619 14:56:42.270426 17898 net.cpp:217] Scale56 needs backward computation.
I0619 14:56:42.270431 17898 net.cpp:217] BatchNorm56 needs backward computation.
I0619 14:56:42.270434 17898 net.cpp:217] Convolution56 needs backward computation.
I0619 14:56:42.270438 17898 net.cpp:217] Eltwise27_ReLU55_0_split needs backward computation.
I0619 14:56:42.270442 17898 net.cpp:217] ReLU55 needs backward computation.
I0619 14:56:42.270447 17898 net.cpp:217] Eltwise27 needs backward computation.
I0619 14:56:42.270452 17898 net.cpp:217] Scale55 needs backward computation.
I0619 14:56:42.270454 17898 net.cpp:217] BatchNorm55 needs backward computation.
I0619 14:56:42.270458 17898 net.cpp:217] Convolution55 needs backward computation.
I0619 14:56:42.270462 17898 net.cpp:217] ReLU54 needs backward computation.
I0619 14:56:42.270467 17898 net.cpp:217] Scale54 needs backward computation.
I0619 14:56:42.270470 17898 net.cpp:217] BatchNorm54 needs backward computation.
I0619 14:56:42.270481 17898 net.cpp:217] Convolution54 needs backward computation.
I0619 14:56:42.270486 17898 net.cpp:217] Eltwise26_ReLU53_0_split needs backward computation.
I0619 14:56:42.270490 17898 net.cpp:217] ReLU53 needs backward computation.
I0619 14:56:42.270494 17898 net.cpp:217] Eltwise26 needs backward computation.
I0619 14:56:42.270499 17898 net.cpp:217] Scale53 needs backward computation.
I0619 14:56:42.270503 17898 net.cpp:217] BatchNorm53 needs backward computation.
I0619 14:56:42.270506 17898 net.cpp:217] Convolution53 needs backward computation.
I0619 14:56:42.270511 17898 net.cpp:217] ReLU52 needs backward computation.
I0619 14:56:42.270514 17898 net.cpp:217] Scale52 needs backward computation.
I0619 14:56:42.270519 17898 net.cpp:217] BatchNorm52 needs backward computation.
I0619 14:56:42.270522 17898 net.cpp:217] Convolution52 needs backward computation.
I0619 14:56:42.270534 17898 net.cpp:217] Eltwise25_ReLU51_0_split needs backward computation.
I0619 14:56:42.270546 17898 net.cpp:217] ReLU51 needs backward computation.
I0619 14:56:42.270556 17898 net.cpp:217] Eltwise25 needs backward computation.
I0619 14:56:42.270560 17898 net.cpp:217] Scale51 needs backward computation.
I0619 14:56:42.270565 17898 net.cpp:217] BatchNorm51 needs backward computation.
I0619 14:56:42.270567 17898 net.cpp:217] Convolution51 needs backward computation.
I0619 14:56:42.270572 17898 net.cpp:217] ReLU50 needs backward computation.
I0619 14:56:42.270576 17898 net.cpp:217] Scale50 needs backward computation.
I0619 14:56:42.270579 17898 net.cpp:217] BatchNorm50 needs backward computation.
I0619 14:56:42.270583 17898 net.cpp:217] Convolution50 needs backward computation.
I0619 14:56:42.270588 17898 net.cpp:217] Eltwise24_ReLU49_0_split needs backward computation.
I0619 14:56:42.270591 17898 net.cpp:217] ReLU49 needs backward computation.
I0619 14:56:42.270596 17898 net.cpp:217] Eltwise24 needs backward computation.
I0619 14:56:42.270601 17898 net.cpp:217] Scale49 needs backward computation.
I0619 14:56:42.270604 17898 net.cpp:217] BatchNorm49 needs backward computation.
I0619 14:56:42.270608 17898 net.cpp:217] Convolution49 needs backward computation.
I0619 14:56:42.270612 17898 net.cpp:217] ReLU48 needs backward computation.
I0619 14:56:42.270617 17898 net.cpp:217] Scale48 needs backward computation.
I0619 14:56:42.270620 17898 net.cpp:217] BatchNorm48 needs backward computation.
I0619 14:56:42.270624 17898 net.cpp:217] Convolution48 needs backward computation.
I0619 14:56:42.270628 17898 net.cpp:217] Eltwise23_ReLU47_0_split needs backward computation.
I0619 14:56:42.270632 17898 net.cpp:217] ReLU47 needs backward computation.
I0619 14:56:42.270637 17898 net.cpp:217] Eltwise23 needs backward computation.
I0619 14:56:42.270640 17898 net.cpp:217] Scale47 needs backward computation.
I0619 14:56:42.270644 17898 net.cpp:217] BatchNorm47 needs backward computation.
I0619 14:56:42.270648 17898 net.cpp:217] Convolution47 needs backward computation.
I0619 14:56:42.270653 17898 net.cpp:217] ReLU46 needs backward computation.
I0619 14:56:42.270656 17898 net.cpp:217] Scale46 needs backward computation.
I0619 14:56:42.270660 17898 net.cpp:217] BatchNorm46 needs backward computation.
I0619 14:56:42.270664 17898 net.cpp:217] Convolution46 needs backward computation.
I0619 14:56:42.270668 17898 net.cpp:217] Eltwise22_ReLU45_0_split needs backward computation.
I0619 14:56:42.270673 17898 net.cpp:217] ReLU45 needs backward computation.
I0619 14:56:42.270676 17898 net.cpp:217] Eltwise22 needs backward computation.
I0619 14:56:42.270681 17898 net.cpp:217] Scale45 needs backward computation.
I0619 14:56:42.270685 17898 net.cpp:217] BatchNorm45 needs backward computation.
I0619 14:56:42.270689 17898 net.cpp:217] Convolution45 needs backward computation.
I0619 14:56:42.270694 17898 net.cpp:217] ReLU44 needs backward computation.
I0619 14:56:42.270697 17898 net.cpp:217] Scale44 needs backward computation.
I0619 14:56:42.270701 17898 net.cpp:217] BatchNorm44 needs backward computation.
I0619 14:56:42.270705 17898 net.cpp:217] Convolution44 needs backward computation.
I0619 14:56:42.270709 17898 net.cpp:217] Eltwise21_ReLU43_0_split needs backward computation.
I0619 14:56:42.270714 17898 net.cpp:217] ReLU43 needs backward computation.
I0619 14:56:42.270717 17898 net.cpp:217] Eltwise21 needs backward computation.
I0619 14:56:42.270721 17898 net.cpp:217] Scale43 needs backward computation.
I0619 14:56:42.270725 17898 net.cpp:217] BatchNorm43 needs backward computation.
I0619 14:56:42.270730 17898 net.cpp:217] Convolution43 needs backward computation.
I0619 14:56:42.270733 17898 net.cpp:217] ReLU42 needs backward computation.
I0619 14:56:42.270737 17898 net.cpp:217] Scale42 needs backward computation.
I0619 14:56:42.270741 17898 net.cpp:217] BatchNorm42 needs backward computation.
I0619 14:56:42.270745 17898 net.cpp:217] Convolution42 needs backward computation.
I0619 14:56:42.270750 17898 net.cpp:217] Eltwise20_ReLU41_0_split needs backward computation.
I0619 14:56:42.270761 17898 net.cpp:217] ReLU41 needs backward computation.
I0619 14:56:42.270766 17898 net.cpp:217] Eltwise20 needs backward computation.
I0619 14:56:42.270771 17898 net.cpp:217] Scale41 needs backward computation.
I0619 14:56:42.270774 17898 net.cpp:217] BatchNorm41 needs backward computation.
I0619 14:56:42.270778 17898 net.cpp:217] Convolution41 needs backward computation.
I0619 14:56:42.270782 17898 net.cpp:217] ReLU40 needs backward computation.
I0619 14:56:42.270787 17898 net.cpp:217] Scale40 needs backward computation.
I0619 14:56:42.270790 17898 net.cpp:217] BatchNorm40 needs backward computation.
I0619 14:56:42.270793 17898 net.cpp:217] Convolution40 needs backward computation.
I0619 14:56:42.270798 17898 net.cpp:217] Eltwise19_ReLU39_0_split needs backward computation.
I0619 14:56:42.270802 17898 net.cpp:217] ReLU39 needs backward computation.
I0619 14:56:42.270807 17898 net.cpp:217] Eltwise19 needs backward computation.
I0619 14:56:42.270812 17898 net.cpp:217] Scale39 needs backward computation.
I0619 14:56:42.270815 17898 net.cpp:217] BatchNorm39 needs backward computation.
I0619 14:56:42.270818 17898 net.cpp:217] Convolution39 needs backward computation.
I0619 14:56:42.270823 17898 net.cpp:217] ReLU38 needs backward computation.
I0619 14:56:42.270828 17898 net.cpp:217] Scale38 needs backward computation.
I0619 14:56:42.270831 17898 net.cpp:217] BatchNorm38 needs backward computation.
I0619 14:56:42.270835 17898 net.cpp:217] Convolution38 needs backward computation.
I0619 14:56:42.270839 17898 net.cpp:217] Concat1 needs backward computation.
I0619 14:56:42.270844 17898 net.cpp:219] Input1 does not need backward computation.
I0619 14:56:42.270848 17898 net.cpp:217] Pooling1 needs backward computation.
I0619 14:56:42.270853 17898 net.cpp:217] Eltwise18_ReLU37_0_split needs backward computation.
I0619 14:56:42.270858 17898 net.cpp:217] ReLU37 needs backward computation.
I0619 14:56:42.270861 17898 net.cpp:217] Eltwise18 needs backward computation.
I0619 14:56:42.270866 17898 net.cpp:217] Scale37 needs backward computation.
I0619 14:56:42.270869 17898 net.cpp:217] BatchNorm37 needs backward computation.
I0619 14:56:42.270874 17898 net.cpp:217] Convolution37 needs backward computation.
I0619 14:56:42.270877 17898 net.cpp:217] ReLU36 needs backward computation.
I0619 14:56:42.270881 17898 net.cpp:217] Scale36 needs backward computation.
I0619 14:56:42.270885 17898 net.cpp:217] BatchNorm36 needs backward computation.
I0619 14:56:42.270889 17898 net.cpp:217] Convolution36 needs backward computation.
I0619 14:56:42.270894 17898 net.cpp:217] Eltwise17_ReLU35_0_split needs backward computation.
I0619 14:56:42.270897 17898 net.cpp:217] ReLU35 needs backward computation.
I0619 14:56:42.270902 17898 net.cpp:217] Eltwise17 needs backward computation.
I0619 14:56:42.270908 17898 net.cpp:217] Scale35 needs backward computation.
I0619 14:56:42.270913 17898 net.cpp:217] BatchNorm35 needs backward computation.
I0619 14:56:42.270917 17898 net.cpp:217] Convolution35 needs backward computation.
I0619 14:56:42.270921 17898 net.cpp:217] ReLU34 needs backward computation.
I0619 14:56:42.270925 17898 net.cpp:217] Scale34 needs backward computation.
I0619 14:56:42.270930 17898 net.cpp:217] BatchNorm34 needs backward computation.
I0619 14:56:42.270933 17898 net.cpp:217] Convolution34 needs backward computation.
I0619 14:56:42.270937 17898 net.cpp:217] Eltwise16_ReLU33_0_split needs backward computation.
I0619 14:56:42.270942 17898 net.cpp:217] ReLU33 needs backward computation.
I0619 14:56:42.270946 17898 net.cpp:217] Eltwise16 needs backward computation.
I0619 14:56:42.270951 17898 net.cpp:217] Scale33 needs backward computation.
I0619 14:56:42.270956 17898 net.cpp:217] BatchNorm33 needs backward computation.
I0619 14:56:42.270959 17898 net.cpp:217] Convolution33 needs backward computation.
I0619 14:56:42.270963 17898 net.cpp:217] ReLU32 needs backward computation.
I0619 14:56:42.270967 17898 net.cpp:217] Scale32 needs backward computation.
I0619 14:56:42.270973 17898 net.cpp:217] BatchNorm32 needs backward computation.
I0619 14:56:42.270984 17898 net.cpp:217] Convolution32 needs backward computation.
I0619 14:56:42.270988 17898 net.cpp:217] Eltwise15_ReLU31_0_split needs backward computation.
I0619 14:56:42.270993 17898 net.cpp:217] ReLU31 needs backward computation.
I0619 14:56:42.270998 17898 net.cpp:217] Eltwise15 needs backward computation.
I0619 14:56:42.271003 17898 net.cpp:217] Scale31 needs backward computation.
I0619 14:56:42.271005 17898 net.cpp:217] BatchNorm31 needs backward computation.
I0619 14:56:42.271009 17898 net.cpp:217] Convolution31 needs backward computation.
I0619 14:56:42.271014 17898 net.cpp:217] ReLU30 needs backward computation.
I0619 14:56:42.271018 17898 net.cpp:217] Scale30 needs backward computation.
I0619 14:56:42.271021 17898 net.cpp:217] BatchNorm30 needs backward computation.
I0619 14:56:42.271025 17898 net.cpp:217] Convolution30 needs backward computation.
I0619 14:56:42.271030 17898 net.cpp:217] Eltwise14_ReLU29_0_split needs backward computation.
I0619 14:56:42.271034 17898 net.cpp:217] ReLU29 needs backward computation.
I0619 14:56:42.271039 17898 net.cpp:217] Eltwise14 needs backward computation.
I0619 14:56:42.271044 17898 net.cpp:217] Scale29 needs backward computation.
I0619 14:56:42.271047 17898 net.cpp:217] BatchNorm29 needs backward computation.
I0619 14:56:42.271051 17898 net.cpp:217] Convolution29 needs backward computation.
I0619 14:56:42.271056 17898 net.cpp:217] ReLU28 needs backward computation.
I0619 14:56:42.271060 17898 net.cpp:217] Scale28 needs backward computation.
I0619 14:56:42.271064 17898 net.cpp:217] BatchNorm28 needs backward computation.
I0619 14:56:42.271069 17898 net.cpp:217] Convolution28 needs backward computation.
I0619 14:56:42.271072 17898 net.cpp:217] Eltwise13_ReLU27_0_split needs backward computation.
I0619 14:56:42.271076 17898 net.cpp:217] ReLU27 needs backward computation.
I0619 14:56:42.271080 17898 net.cpp:217] Eltwise13 needs backward computation.
I0619 14:56:42.271085 17898 net.cpp:217] Scale27 needs backward computation.
I0619 14:56:42.271090 17898 net.cpp:217] BatchNorm27 needs backward computation.
I0619 14:56:42.271093 17898 net.cpp:217] Convolution27 needs backward computation.
I0619 14:56:42.271097 17898 net.cpp:217] ReLU26 needs backward computation.
I0619 14:56:42.271101 17898 net.cpp:217] Scale26 needs backward computation.
I0619 14:56:42.271106 17898 net.cpp:217] BatchNorm26 needs backward computation.
I0619 14:56:42.271109 17898 net.cpp:217] Convolution26 needs backward computation.
I0619 14:56:42.271113 17898 net.cpp:217] Eltwise12_ReLU25_0_split needs backward computation.
I0619 14:56:42.271118 17898 net.cpp:217] ReLU25 needs backward computation.
I0619 14:56:42.271121 17898 net.cpp:217] Eltwise12 needs backward computation.
I0619 14:56:42.271126 17898 net.cpp:217] Scale25 needs backward computation.
I0619 14:56:42.271131 17898 net.cpp:217] BatchNorm25 needs backward computation.
I0619 14:56:42.271134 17898 net.cpp:217] Convolution25 needs backward computation.
I0619 14:56:42.271139 17898 net.cpp:217] ReLU24 needs backward computation.
I0619 14:56:42.271143 17898 net.cpp:217] Scale24 needs backward computation.
I0619 14:56:42.271147 17898 net.cpp:217] BatchNorm24 needs backward computation.
I0619 14:56:42.271152 17898 net.cpp:217] Convolution24 needs backward computation.
I0619 14:56:42.271155 17898 net.cpp:217] Eltwise11_ReLU23_0_split needs backward computation.
I0619 14:56:42.271159 17898 net.cpp:217] ReLU23 needs backward computation.
I0619 14:56:42.271163 17898 net.cpp:217] Eltwise11 needs backward computation.
I0619 14:56:42.271168 17898 net.cpp:217] Scale23 needs backward computation.
I0619 14:56:42.271173 17898 net.cpp:217] BatchNorm23 needs backward computation.
I0619 14:56:42.271176 17898 net.cpp:217] Convolution23 needs backward computation.
I0619 14:56:42.271180 17898 net.cpp:217] ReLU22 needs backward computation.
I0619 14:56:42.271184 17898 net.cpp:217] Scale22 needs backward computation.
I0619 14:56:42.271188 17898 net.cpp:217] BatchNorm22 needs backward computation.
I0619 14:56:42.271194 17898 net.cpp:217] Convolution22 needs backward computation.
I0619 14:56:42.271205 17898 net.cpp:217] Eltwise10_ReLU21_0_split needs backward computation.
I0619 14:56:42.271210 17898 net.cpp:217] ReLU21 needs backward computation.
I0619 14:56:42.271216 17898 net.cpp:217] Eltwise10 needs backward computation.
I0619 14:56:42.271221 17898 net.cpp:217] Scale21 needs backward computation.
I0619 14:56:42.271225 17898 net.cpp:217] BatchNorm21 needs backward computation.
I0619 14:56:42.271229 17898 net.cpp:217] Convolution21 needs backward computation.
I0619 14:56:42.271234 17898 net.cpp:217] ReLU20 needs backward computation.
I0619 14:56:42.271237 17898 net.cpp:217] Scale20 needs backward computation.
I0619 14:56:42.271241 17898 net.cpp:217] BatchNorm20 needs backward computation.
I0619 14:56:42.271245 17898 net.cpp:217] Convolution20 needs backward computation.
I0619 14:56:42.271250 17898 net.cpp:217] Eltwise9_ReLU19_0_split needs backward computation.
I0619 14:56:42.271255 17898 net.cpp:217] ReLU19 needs backward computation.
I0619 14:56:42.271260 17898 net.cpp:217] Eltwise9 needs backward computation.
I0619 14:56:42.271265 17898 net.cpp:217] Scale19 needs backward computation.
I0619 14:56:42.271268 17898 net.cpp:217] BatchNorm19 needs backward computation.
I0619 14:56:42.271272 17898 net.cpp:217] Convolution19 needs backward computation.
I0619 14:56:42.271276 17898 net.cpp:217] ReLU18 needs backward computation.
I0619 14:56:42.271281 17898 net.cpp:217] Scale18 needs backward computation.
I0619 14:56:42.271284 17898 net.cpp:217] BatchNorm18 needs backward computation.
I0619 14:56:42.271288 17898 net.cpp:217] Convolution18 needs backward computation.
I0619 14:56:42.271293 17898 net.cpp:217] Eltwise8_ReLU17_0_split needs backward computation.
I0619 14:56:42.271297 17898 net.cpp:217] ReLU17 needs backward computation.
I0619 14:56:42.271302 17898 net.cpp:217] Eltwise8 needs backward computation.
I0619 14:56:42.271308 17898 net.cpp:217] Scale17 needs backward computation.
I0619 14:56:42.271312 17898 net.cpp:217] BatchNorm17 needs backward computation.
I0619 14:56:42.271317 17898 net.cpp:217] Convolution17 needs backward computation.
I0619 14:56:42.271320 17898 net.cpp:217] ReLU16 needs backward computation.
I0619 14:56:42.271325 17898 net.cpp:217] Scale16 needs backward computation.
I0619 14:56:42.271329 17898 net.cpp:217] BatchNorm16 needs backward computation.
I0619 14:56:42.271333 17898 net.cpp:217] Convolution16 needs backward computation.
I0619 14:56:42.271337 17898 net.cpp:217] Eltwise7_ReLU15_0_split needs backward computation.
I0619 14:56:42.271342 17898 net.cpp:217] ReLU15 needs backward computation.
I0619 14:56:42.271347 17898 net.cpp:217] Eltwise7 needs backward computation.
I0619 14:56:42.271352 17898 net.cpp:217] Scale15 needs backward computation.
I0619 14:56:42.271355 17898 net.cpp:217] BatchNorm15 needs backward computation.
I0619 14:56:42.271359 17898 net.cpp:217] Convolution15 needs backward computation.
I0619 14:56:42.271363 17898 net.cpp:217] ReLU14 needs backward computation.
I0619 14:56:42.271368 17898 net.cpp:217] Scale14 needs backward computation.
I0619 14:56:42.271371 17898 net.cpp:217] BatchNorm14 needs backward computation.
I0619 14:56:42.271375 17898 net.cpp:217] Convolution14 needs backward computation.
I0619 14:56:42.271379 17898 net.cpp:217] Eltwise6_ReLU13_0_split needs backward computation.
I0619 14:56:42.271384 17898 net.cpp:217] ReLU13 needs backward computation.
I0619 14:56:42.271389 17898 net.cpp:217] Eltwise6 needs backward computation.
I0619 14:56:42.271394 17898 net.cpp:217] Scale13 needs backward computation.
I0619 14:56:42.271397 17898 net.cpp:217] BatchNorm13 needs backward computation.
I0619 14:56:42.271401 17898 net.cpp:217] Convolution13 needs backward computation.
I0619 14:56:42.271405 17898 net.cpp:217] ReLU12 needs backward computation.
I0619 14:56:42.271409 17898 net.cpp:217] Scale12 needs backward computation.
I0619 14:56:42.271414 17898 net.cpp:217] BatchNorm12 needs backward computation.
I0619 14:56:42.271417 17898 net.cpp:217] Convolution12 needs backward computation.
I0619 14:56:42.271423 17898 net.cpp:217] Eltwise5_ReLU11_0_split needs backward computation.
I0619 14:56:42.271436 17898 net.cpp:217] ReLU11 needs backward computation.
I0619 14:56:42.271440 17898 net.cpp:217] Eltwise5 needs backward computation.
I0619 14:56:42.271446 17898 net.cpp:217] Scale11 needs backward computation.
I0619 14:56:42.271450 17898 net.cpp:217] BatchNorm11 needs backward computation.
I0619 14:56:42.271455 17898 net.cpp:217] Convolution11 needs backward computation.
I0619 14:56:42.271458 17898 net.cpp:217] ReLU10 needs backward computation.
I0619 14:56:42.271462 17898 net.cpp:217] Scale10 needs backward computation.
I0619 14:56:42.271466 17898 net.cpp:217] BatchNorm10 needs backward computation.
I0619 14:56:42.271472 17898 net.cpp:217] Convolution10 needs backward computation.
I0619 14:56:42.271477 17898 net.cpp:217] Eltwise4_ReLU9_0_split needs backward computation.
I0619 14:56:42.271482 17898 net.cpp:217] ReLU9 needs backward computation.
I0619 14:56:42.271486 17898 net.cpp:217] Eltwise4 needs backward computation.
I0619 14:56:42.271492 17898 net.cpp:217] Scale9 needs backward computation.
I0619 14:56:42.271495 17898 net.cpp:217] BatchNorm9 needs backward computation.
I0619 14:56:42.271499 17898 net.cpp:217] Convolution9 needs backward computation.
I0619 14:56:42.271503 17898 net.cpp:217] ReLU8 needs backward computation.
I0619 14:56:42.271508 17898 net.cpp:217] Scale8 needs backward computation.
I0619 14:56:42.271512 17898 net.cpp:217] BatchNorm8 needs backward computation.
I0619 14:56:42.271517 17898 net.cpp:217] Convolution8 needs backward computation.
I0619 14:56:42.271520 17898 net.cpp:217] Eltwise3_ReLU7_0_split needs backward computation.
I0619 14:56:42.271527 17898 net.cpp:217] ReLU7 needs backward computation.
I0619 14:56:42.271530 17898 net.cpp:217] Eltwise3 needs backward computation.
I0619 14:56:42.271535 17898 net.cpp:217] Scale7 needs backward computation.
I0619 14:56:42.271539 17898 net.cpp:217] BatchNorm7 needs backward computation.
I0619 14:56:42.271543 17898 net.cpp:217] Convolution7 needs backward computation.
I0619 14:56:42.271548 17898 net.cpp:217] ReLU6 needs backward computation.
I0619 14:56:42.271551 17898 net.cpp:217] Scale6 needs backward computation.
I0619 14:56:42.271555 17898 net.cpp:217] BatchNorm6 needs backward computation.
I0619 14:56:42.271559 17898 net.cpp:217] Convolution6 needs backward computation.
I0619 14:56:42.271564 17898 net.cpp:217] Eltwise2_ReLU5_0_split needs backward computation.
I0619 14:56:42.271569 17898 net.cpp:217] ReLU5 needs backward computation.
I0619 14:56:42.271572 17898 net.cpp:217] Eltwise2 needs backward computation.
I0619 14:56:42.271577 17898 net.cpp:217] Scale5 needs backward computation.
I0619 14:56:42.271581 17898 net.cpp:217] BatchNorm5 needs backward computation.
I0619 14:56:42.271585 17898 net.cpp:217] Convolution5 needs backward computation.
I0619 14:56:42.271590 17898 net.cpp:217] ReLU4 needs backward computation.
I0619 14:56:42.271595 17898 net.cpp:217] Scale4 needs backward computation.
I0619 14:56:42.271598 17898 net.cpp:217] BatchNorm4 needs backward computation.
I0619 14:56:42.271602 17898 net.cpp:217] Convolution4 needs backward computation.
I0619 14:56:42.271606 17898 net.cpp:217] Eltwise1_ReLU3_0_split needs backward computation.
I0619 14:56:42.271611 17898 net.cpp:217] ReLU3 needs backward computation.
I0619 14:56:42.271615 17898 net.cpp:217] Eltwise1 needs backward computation.
I0619 14:56:42.271620 17898 net.cpp:217] Scale3 needs backward computation.
I0619 14:56:42.271625 17898 net.cpp:217] BatchNorm3 needs backward computation.
I0619 14:56:42.271628 17898 net.cpp:217] Convolution3 needs backward computation.
I0619 14:56:42.271633 17898 net.cpp:217] ReLU2 needs backward computation.
I0619 14:56:42.271637 17898 net.cpp:217] Scale2 needs backward computation.
I0619 14:56:42.271641 17898 net.cpp:217] BatchNorm2 needs backward computation.
I0619 14:56:42.271646 17898 net.cpp:217] Convolution2 needs backward computation.
I0619 14:56:42.271651 17898 net.cpp:217] Convolution1_ReLU1_0_split needs backward computation.
I0619 14:56:42.271657 17898 net.cpp:217] ReLU1 needs backward computation.
I0619 14:56:42.271668 17898 net.cpp:217] Scale1 needs backward computation.
I0619 14:56:42.271672 17898 net.cpp:217] BatchNorm1 needs backward computation.
I0619 14:56:42.271677 17898 net.cpp:217] Convolution1 needs backward computation.
I0619 14:56:42.271683 17898 net.cpp:219] Data1 does not need backward computation.
I0619 14:56:42.271687 17898 net.cpp:261] This network produces output SoftmaxWithLoss1
I0619 14:56:42.271996 17898 net.cpp:274] Network initialization done.
I0619 14:56:42.296294 17898 solver.cpp:181] Creating test net (#0) specified by test_net file: examples/stochastic_depth/residual_test54.prototxt
I0619 14:56:42.302206 17898 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "/scratch/pas282/caffe/examples/cifar10/cifar10_test_leveldb_padding3"
    batch_size: 128
    backend: LEVELDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution21"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution22"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution22"
  top: "Convolution22"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Convolution22"
  top: "Convolution23"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution23"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution24"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution25"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution26"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution27"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution28"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution28"
  top: "Convolution28"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution29"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution30"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "Convolution30"
  top: "Convolution30"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Convolution30"
  top: "Convolution31"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise15"
  type: "Eltwise"
  bottom: "Eltwise14"
  bottom: "Convolution31"
  top: "Eltwise15"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "Eltwise15"
  top: "Eltwise15"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Eltwise15"
  top: "Convolution32"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm32"
  type: "BatchNorm"
  bottom: "Convolution32"
  top: "Convolution32"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale32"
  type: "Scale"
  bottom: "Convolution32"
  top: "Convolution32"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU32"
  type: "ReLU"
  bottom: "Convolution32"
  top: "Convolution32"
}
layer {
  name: "Convolution33"
  type: "Convolution"
  bottom: "Convolution32"
  top: "Convolution33"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm33"
  type: "BatchNorm"
  bottom: "Convolution33"
  top: "Convolution33"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale33"
  type: "Scale"
  bottom: "Convolution33"
  top: "Convolution33"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise16"
  type: "Eltwise"
  bottom: "Eltwise15"
  bottom: "Convolution33"
  top: "Eltwise16"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU33"
  type: "ReLU"
  bottom: "Eltwise16"
  top: "Eltwise16"
}
layer {
  name: "Convolution34"
  type: "Convolution"
  bottom: "Eltwise16"
  top: "Convolution34"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm34"
  type: "BatchNorm"
  bottom: "Convolution34"
  top: "Convolution34"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale34"
  type: "Scale"
  bottom: "Convolution34"
  top: "Convolution34"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU34"
  type: "ReLU"
  bottom: "Convolution34"
  top: "Convolution34"
}
layer {
  name: "Convolution35"
  type: "Convolution"
  bottom: "Convolution34"
  top: "Convolution35"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm35"
  type: "BatchNorm"
  bottom: "Convolution35"
  top: "Convolution35"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale35"
  type: "Scale"
  bottom: "Convolution35"
  top: "Convolution35"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise17"
  type: "Eltwise"
  bottom: "Eltwise16"
  bottom: "Convolution35"
  top: "Eltwise17"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU35"
  type: "ReLU"
  bottom: "Eltwise17"
  top: "Eltwise17"
}
layer {
  name: "Convolution36"
  type: "Convolution"
  bottom: "Eltwise17"
  top: "Convolution36"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  n
I0619 14:56:42.306190 17898 layer_factory.hpp:77] Creating layer Data1
I0619 14:56:42.306442 17898 net.cpp:91] Creating Layer Data1
I0619 14:56:42.306463 17898 net.cpp:399] Data1 -> Data1
I0619 14:56:42.306481 17898 net.cpp:399] Data1 -> Data2
I0619 14:56:42.342314 17904 db_leveldb.cpp:18] Opened leveldb /scratch/pas282/caffe/examples/cifar10/cifar10_test_leveldb_padding3
I0619 14:56:42.343158 17898 data_layer.cpp:41] output data size: 128,3,32,32
I0619 14:56:42.348906 17898 net.cpp:141] Setting up Data1
I0619 14:56:42.348937 17898 net.cpp:148] Top shape: 128 3 32 32 (393216)
I0619 14:56:42.348951 17898 net.cpp:148] Top shape: 128 (128)
I0619 14:56:42.348959 17898 net.cpp:156] Memory required for data: 1573376
I0619 14:56:42.348969 17898 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0619 14:56:42.348986 17898 net.cpp:91] Creating Layer Data2_Data1_1_split
I0619 14:56:42.348995 17898 net.cpp:425] Data2_Data1_1_split <- Data2
I0619 14:56:42.349009 17898 net.cpp:399] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0619 14:56:42.349028 17898 net.cpp:399] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0619 14:56:42.349166 17898 net.cpp:141] Setting up Data2_Data1_1_split
I0619 14:56:42.349189 17898 net.cpp:148] Top shape: 128 (128)
I0619 14:56:42.349200 17898 net.cpp:148] Top shape: 128 (128)
I0619 14:56:42.349207 17898 net.cpp:156] Memory required for data: 1574400
I0619 14:56:42.349215 17898 layer_factory.hpp:77] Creating layer Convolution1
I0619 14:56:42.349236 17898 net.cpp:91] Creating Layer Convolution1
I0619 14:56:42.349244 17898 net.cpp:425] Convolution1 <- Data1
I0619 14:56:42.349261 17898 net.cpp:399] Convolution1 -> Convolution1
I0619 14:56:42.349864 17898 net.cpp:141] Setting up Convolution1
I0619 14:56:42.349882 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.349890 17898 net.cpp:156] Memory required for data: 9963008
I0619 14:56:42.349912 17898 layer_factory.hpp:77] Creating layer BatchNorm1
I0619 14:56:42.349933 17898 net.cpp:91] Creating Layer BatchNorm1
I0619 14:56:42.349942 17898 net.cpp:425] BatchNorm1 <- Convolution1
I0619 14:56:42.349961 17898 net.cpp:386] BatchNorm1 -> Convolution1 (in-place)
I0619 14:56:42.350430 17898 net.cpp:141] Setting up BatchNorm1
I0619 14:56:42.350448 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.350456 17898 net.cpp:156] Memory required for data: 18351616
I0619 14:56:42.350482 17898 layer_factory.hpp:77] Creating layer Scale1
I0619 14:56:42.350503 17898 net.cpp:91] Creating Layer Scale1
I0619 14:56:42.350512 17898 net.cpp:425] Scale1 <- Convolution1
I0619 14:56:42.350523 17898 net.cpp:386] Scale1 -> Convolution1 (in-place)
I0619 14:56:42.350594 17898 layer_factory.hpp:77] Creating layer Scale1
I0619 14:56:42.350987 17898 net.cpp:141] Setting up Scale1
I0619 14:56:42.351006 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.351014 17898 net.cpp:156] Memory required for data: 26740224
I0619 14:56:42.351028 17898 layer_factory.hpp:77] Creating layer ReLU1
I0619 14:56:42.351042 17898 net.cpp:91] Creating Layer ReLU1
I0619 14:56:42.351049 17898 net.cpp:425] ReLU1 <- Convolution1
I0619 14:56:42.351063 17898 net.cpp:386] ReLU1 -> Convolution1 (in-place)
I0619 14:56:42.351075 17898 net.cpp:141] Setting up ReLU1
I0619 14:56:42.351086 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.351094 17898 net.cpp:156] Memory required for data: 35128832
I0619 14:56:42.351100 17898 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0619 14:56:42.351111 17898 net.cpp:91] Creating Layer Convolution1_ReLU1_0_split
I0619 14:56:42.351119 17898 net.cpp:425] Convolution1_ReLU1_0_split <- Convolution1
I0619 14:56:42.351133 17898 net.cpp:399] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0619 14:56:42.351148 17898 net.cpp:399] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0619 14:56:42.351227 17898 net.cpp:141] Setting up Convolution1_ReLU1_0_split
I0619 14:56:42.351243 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.351253 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.351260 17898 net.cpp:156] Memory required for data: 51906048
I0619 14:56:42.351267 17898 layer_factory.hpp:77] Creating layer Convolution2
I0619 14:56:42.351284 17898 net.cpp:91] Creating Layer Convolution2
I0619 14:56:42.351292 17898 net.cpp:425] Convolution2 <- Convolution1_ReLU1_0_split_0
I0619 14:56:42.351305 17898 net.cpp:399] Convolution2 -> Convolution2
I0619 14:56:42.351981 17898 net.cpp:141] Setting up Convolution2
I0619 14:56:42.351999 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.352006 17898 net.cpp:156] Memory required for data: 60294656
I0619 14:56:42.352025 17898 layer_factory.hpp:77] Creating layer BatchNorm2
I0619 14:56:42.352046 17898 net.cpp:91] Creating Layer BatchNorm2
I0619 14:56:42.352056 17898 net.cpp:425] BatchNorm2 <- Convolution2
I0619 14:56:42.352067 17898 net.cpp:386] BatchNorm2 -> Convolution2 (in-place)
I0619 14:56:42.352517 17898 net.cpp:141] Setting up BatchNorm2
I0619 14:56:42.352535 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.352543 17898 net.cpp:156] Memory required for data: 68683264
I0619 14:56:42.352561 17898 layer_factory.hpp:77] Creating layer Scale2
I0619 14:56:42.352574 17898 net.cpp:91] Creating Layer Scale2
I0619 14:56:42.352582 17898 net.cpp:425] Scale2 <- Convolution2
I0619 14:56:42.352594 17898 net.cpp:386] Scale2 -> Convolution2 (in-place)
I0619 14:56:42.352675 17898 layer_factory.hpp:77] Creating layer Scale2
I0619 14:56:42.352919 17898 net.cpp:141] Setting up Scale2
I0619 14:56:42.352934 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.352947 17898 net.cpp:156] Memory required for data: 77071872
I0619 14:56:42.352962 17898 layer_factory.hpp:77] Creating layer ReLU2
I0619 14:56:42.352977 17898 net.cpp:91] Creating Layer ReLU2
I0619 14:56:42.352985 17898 net.cpp:425] ReLU2 <- Convolution2
I0619 14:56:42.352996 17898 net.cpp:386] ReLU2 -> Convolution2 (in-place)
I0619 14:56:42.353009 17898 net.cpp:141] Setting up ReLU2
I0619 14:56:42.353019 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.353032 17898 net.cpp:156] Memory required for data: 85460480
I0619 14:56:42.353061 17898 layer_factory.hpp:77] Creating layer Convolution3
I0619 14:56:42.353083 17898 net.cpp:91] Creating Layer Convolution3
I0619 14:56:42.353091 17898 net.cpp:425] Convolution3 <- Convolution2
I0619 14:56:42.353104 17898 net.cpp:399] Convolution3 -> Convolution3
I0619 14:56:42.353775 17898 net.cpp:141] Setting up Convolution3
I0619 14:56:42.353793 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.353801 17898 net.cpp:156] Memory required for data: 93849088
I0619 14:56:42.353814 17898 layer_factory.hpp:77] Creating layer BatchNorm3
I0619 14:56:42.353826 17898 net.cpp:91] Creating Layer BatchNorm3
I0619 14:56:42.353835 17898 net.cpp:425] BatchNorm3 <- Convolution3
I0619 14:56:42.353849 17898 net.cpp:386] BatchNorm3 -> Convolution3 (in-place)
I0619 14:56:42.354266 17898 net.cpp:141] Setting up BatchNorm3
I0619 14:56:42.354280 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.354288 17898 net.cpp:156] Memory required for data: 102237696
I0619 14:56:42.354315 17898 layer_factory.hpp:77] Creating layer Scale3
I0619 14:56:42.354327 17898 net.cpp:91] Creating Layer Scale3
I0619 14:56:42.354336 17898 net.cpp:425] Scale3 <- Convolution3
I0619 14:56:42.354346 17898 net.cpp:386] Scale3 -> Convolution3 (in-place)
I0619 14:56:42.354431 17898 layer_factory.hpp:77] Creating layer Scale3
I0619 14:56:42.354673 17898 net.cpp:141] Setting up Scale3
I0619 14:56:42.354688 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.354696 17898 net.cpp:156] Memory required for data: 110626304
I0619 14:56:42.354709 17898 layer_factory.hpp:77] Creating layer Eltwise1
I0619 14:56:42.354727 17898 net.cpp:91] Creating Layer Eltwise1
I0619 14:56:42.354737 17898 net.cpp:425] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0619 14:56:42.354746 17898 net.cpp:425] Eltwise1 <- Convolution3
I0619 14:56:42.354758 17898 net.cpp:399] Eltwise1 -> Eltwise1
I0619 14:56:42.354809 17898 net.cpp:141] Setting up Eltwise1
I0619 14:56:42.354820 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.354827 17898 net.cpp:156] Memory required for data: 119014912
I0619 14:56:42.354835 17898 layer_factory.hpp:77] Creating layer ReLU3
I0619 14:56:42.354846 17898 net.cpp:91] Creating Layer ReLU3
I0619 14:56:42.354854 17898 net.cpp:425] ReLU3 <- Eltwise1
I0619 14:56:42.354871 17898 net.cpp:386] ReLU3 -> Eltwise1 (in-place)
I0619 14:56:42.354883 17898 net.cpp:141] Setting up ReLU3
I0619 14:56:42.354894 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.354902 17898 net.cpp:156] Memory required for data: 127403520
I0619 14:56:42.354908 17898 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0619 14:56:42.354923 17898 net.cpp:91] Creating Layer Eltwise1_ReLU3_0_split
I0619 14:56:42.354930 17898 net.cpp:425] Eltwise1_ReLU3_0_split <- Eltwise1
I0619 14:56:42.354943 17898 net.cpp:399] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0619 14:56:42.354957 17898 net.cpp:399] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0619 14:56:42.355033 17898 net.cpp:141] Setting up Eltwise1_ReLU3_0_split
I0619 14:56:42.355046 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.355057 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.355064 17898 net.cpp:156] Memory required for data: 144180736
I0619 14:56:42.355072 17898 layer_factory.hpp:77] Creating layer Convolution4
I0619 14:56:42.355087 17898 net.cpp:91] Creating Layer Convolution4
I0619 14:56:42.355095 17898 net.cpp:425] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0619 14:56:42.355113 17898 net.cpp:399] Convolution4 -> Convolution4
I0619 14:56:42.355773 17898 net.cpp:141] Setting up Convolution4
I0619 14:56:42.355790 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.355798 17898 net.cpp:156] Memory required for data: 152569344
I0619 14:56:42.355811 17898 layer_factory.hpp:77] Creating layer BatchNorm4
I0619 14:56:42.355823 17898 net.cpp:91] Creating Layer BatchNorm4
I0619 14:56:42.355832 17898 net.cpp:425] BatchNorm4 <- Convolution4
I0619 14:56:42.355852 17898 net.cpp:386] BatchNorm4 -> Convolution4 (in-place)
I0619 14:56:42.356298 17898 net.cpp:141] Setting up BatchNorm4
I0619 14:56:42.356313 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.356320 17898 net.cpp:156] Memory required for data: 160957952
I0619 14:56:42.356338 17898 layer_factory.hpp:77] Creating layer Scale4
I0619 14:56:42.356351 17898 net.cpp:91] Creating Layer Scale4
I0619 14:56:42.356359 17898 net.cpp:425] Scale4 <- Convolution4
I0619 14:56:42.356371 17898 net.cpp:386] Scale4 -> Convolution4 (in-place)
I0619 14:56:42.356441 17898 layer_factory.hpp:77] Creating layer Scale4
I0619 14:56:42.356680 17898 net.cpp:141] Setting up Scale4
I0619 14:56:42.356695 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.356703 17898 net.cpp:156] Memory required for data: 169346560
I0619 14:56:42.356714 17898 layer_factory.hpp:77] Creating layer ReLU4
I0619 14:56:42.356741 17898 net.cpp:91] Creating Layer ReLU4
I0619 14:56:42.356750 17898 net.cpp:425] ReLU4 <- Convolution4
I0619 14:56:42.356765 17898 net.cpp:386] ReLU4 -> Convolution4 (in-place)
I0619 14:56:42.356778 17898 net.cpp:141] Setting up ReLU4
I0619 14:56:42.356789 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.356796 17898 net.cpp:156] Memory required for data: 177735168
I0619 14:56:42.356803 17898 layer_factory.hpp:77] Creating layer Convolution5
I0619 14:56:42.356819 17898 net.cpp:91] Creating Layer Convolution5
I0619 14:56:42.356827 17898 net.cpp:425] Convolution5 <- Convolution4
I0619 14:56:42.356843 17898 net.cpp:399] Convolution5 -> Convolution5
I0619 14:56:42.357503 17898 net.cpp:141] Setting up Convolution5
I0619 14:56:42.357520 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.357527 17898 net.cpp:156] Memory required for data: 186123776
I0619 14:56:42.357542 17898 layer_factory.hpp:77] Creating layer BatchNorm5
I0619 14:56:42.357554 17898 net.cpp:91] Creating Layer BatchNorm5
I0619 14:56:42.357563 17898 net.cpp:425] BatchNorm5 <- Convolution5
I0619 14:56:42.357578 17898 net.cpp:386] BatchNorm5 -> Convolution5 (in-place)
I0619 14:56:42.358006 17898 net.cpp:141] Setting up BatchNorm5
I0619 14:56:42.358019 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.358027 17898 net.cpp:156] Memory required for data: 194512384
I0619 14:56:42.358052 17898 layer_factory.hpp:77] Creating layer Scale5
I0619 14:56:42.358067 17898 net.cpp:91] Creating Layer Scale5
I0619 14:56:42.358075 17898 net.cpp:425] Scale5 <- Convolution5
I0619 14:56:42.358086 17898 net.cpp:386] Scale5 -> Convolution5 (in-place)
I0619 14:56:42.358155 17898 layer_factory.hpp:77] Creating layer Scale5
I0619 14:56:42.358407 17898 net.cpp:141] Setting up Scale5
I0619 14:56:42.358427 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.358433 17898 net.cpp:156] Memory required for data: 202900992
I0619 14:56:42.358448 17898 layer_factory.hpp:77] Creating layer Eltwise2
I0619 14:56:42.358459 17898 net.cpp:91] Creating Layer Eltwise2
I0619 14:56:42.358467 17898 net.cpp:425] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0619 14:56:42.358477 17898 net.cpp:425] Eltwise2 <- Convolution5
I0619 14:56:42.358489 17898 net.cpp:399] Eltwise2 -> Eltwise2
I0619 14:56:42.358549 17898 net.cpp:141] Setting up Eltwise2
I0619 14:56:42.358563 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.358571 17898 net.cpp:156] Memory required for data: 211289600
I0619 14:56:42.358578 17898 layer_factory.hpp:77] Creating layer ReLU5
I0619 14:56:42.358592 17898 net.cpp:91] Creating Layer ReLU5
I0619 14:56:42.358602 17898 net.cpp:425] ReLU5 <- Eltwise2
I0619 14:56:42.358611 17898 net.cpp:386] ReLU5 -> Eltwise2 (in-place)
I0619 14:56:42.358625 17898 net.cpp:141] Setting up ReLU5
I0619 14:56:42.358635 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.358642 17898 net.cpp:156] Memory required for data: 219678208
I0619 14:56:42.358651 17898 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0619 14:56:42.358661 17898 net.cpp:91] Creating Layer Eltwise2_ReLU5_0_split
I0619 14:56:42.358676 17898 net.cpp:425] Eltwise2_ReLU5_0_split <- Eltwise2
I0619 14:56:42.358716 17898 net.cpp:399] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0619 14:56:42.358732 17898 net.cpp:399] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0619 14:56:42.358803 17898 net.cpp:141] Setting up Eltwise2_ReLU5_0_split
I0619 14:56:42.358815 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.358825 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.358832 17898 net.cpp:156] Memory required for data: 236455424
I0619 14:56:42.358839 17898 layer_factory.hpp:77] Creating layer Convolution6
I0619 14:56:42.358858 17898 net.cpp:91] Creating Layer Convolution6
I0619 14:56:42.358866 17898 net.cpp:425] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0619 14:56:42.358880 17898 net.cpp:399] Convolution6 -> Convolution6
I0619 14:56:42.359498 17898 net.cpp:141] Setting up Convolution6
I0619 14:56:42.359513 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.359519 17898 net.cpp:156] Memory required for data: 244844032
I0619 14:56:42.359532 17898 layer_factory.hpp:77] Creating layer BatchNorm6
I0619 14:56:42.359544 17898 net.cpp:91] Creating Layer BatchNorm6
I0619 14:56:42.359552 17898 net.cpp:425] BatchNorm6 <- Convolution6
I0619 14:56:42.359566 17898 net.cpp:386] BatchNorm6 -> Convolution6 (in-place)
I0619 14:56:42.359952 17898 net.cpp:141] Setting up BatchNorm6
I0619 14:56:42.359966 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.359975 17898 net.cpp:156] Memory required for data: 253232640
I0619 14:56:42.359989 17898 layer_factory.hpp:77] Creating layer Scale6
I0619 14:56:42.360003 17898 net.cpp:91] Creating Layer Scale6
I0619 14:56:42.360011 17898 net.cpp:425] Scale6 <- Convolution6
I0619 14:56:42.360023 17898 net.cpp:386] Scale6 -> Convolution6 (in-place)
I0619 14:56:42.360090 17898 layer_factory.hpp:77] Creating layer Scale6
I0619 14:56:42.360321 17898 net.cpp:141] Setting up Scale6
I0619 14:56:42.360335 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.360342 17898 net.cpp:156] Memory required for data: 261621248
I0619 14:56:42.360354 17898 layer_factory.hpp:77] Creating layer ReLU6
I0619 14:56:42.360364 17898 net.cpp:91] Creating Layer ReLU6
I0619 14:56:42.360373 17898 net.cpp:425] ReLU6 <- Convolution6
I0619 14:56:42.360381 17898 net.cpp:386] ReLU6 -> Convolution6 (in-place)
I0619 14:56:42.360394 17898 net.cpp:141] Setting up ReLU6
I0619 14:56:42.360402 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.360409 17898 net.cpp:156] Memory required for data: 270009856
I0619 14:56:42.360416 17898 layer_factory.hpp:77] Creating layer Convolution7
I0619 14:56:42.360435 17898 net.cpp:91] Creating Layer Convolution7
I0619 14:56:42.360442 17898 net.cpp:425] Convolution7 <- Convolution6
I0619 14:56:42.360456 17898 net.cpp:399] Convolution7 -> Convolution7
I0619 14:56:42.361150 17898 net.cpp:141] Setting up Convolution7
I0619 14:56:42.361167 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.361176 17898 net.cpp:156] Memory required for data: 278398464
I0619 14:56:42.361187 17898 layer_factory.hpp:77] Creating layer BatchNorm7
I0619 14:56:42.361214 17898 net.cpp:91] Creating Layer BatchNorm7
I0619 14:56:42.361222 17898 net.cpp:425] BatchNorm7 <- Convolution7
I0619 14:56:42.361234 17898 net.cpp:386] BatchNorm7 -> Convolution7 (in-place)
I0619 14:56:42.361635 17898 net.cpp:141] Setting up BatchNorm7
I0619 14:56:42.361650 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.361656 17898 net.cpp:156] Memory required for data: 286787072
I0619 14:56:42.361672 17898 layer_factory.hpp:77] Creating layer Scale7
I0619 14:56:42.361687 17898 net.cpp:91] Creating Layer Scale7
I0619 14:56:42.361696 17898 net.cpp:425] Scale7 <- Convolution7
I0619 14:56:42.361706 17898 net.cpp:386] Scale7 -> Convolution7 (in-place)
I0619 14:56:42.361773 17898 layer_factory.hpp:77] Creating layer Scale7
I0619 14:56:42.362011 17898 net.cpp:141] Setting up Scale7
I0619 14:56:42.362026 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.362037 17898 net.cpp:156] Memory required for data: 295175680
I0619 14:56:42.362069 17898 layer_factory.hpp:77] Creating layer Eltwise3
I0619 14:56:42.362082 17898 net.cpp:91] Creating Layer Eltwise3
I0619 14:56:42.362089 17898 net.cpp:425] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0619 14:56:42.362099 17898 net.cpp:425] Eltwise3 <- Convolution7
I0619 14:56:42.362113 17898 net.cpp:399] Eltwise3 -> Eltwise3
I0619 14:56:42.362165 17898 net.cpp:141] Setting up Eltwise3
I0619 14:56:42.362177 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.362185 17898 net.cpp:156] Memory required for data: 303564288
I0619 14:56:42.362191 17898 layer_factory.hpp:77] Creating layer ReLU7
I0619 14:56:42.362202 17898 net.cpp:91] Creating Layer ReLU7
I0619 14:56:42.362210 17898 net.cpp:425] ReLU7 <- Eltwise3
I0619 14:56:42.362220 17898 net.cpp:386] ReLU7 -> Eltwise3 (in-place)
I0619 14:56:42.362232 17898 net.cpp:141] Setting up ReLU7
I0619 14:56:42.362242 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.362248 17898 net.cpp:156] Memory required for data: 311952896
I0619 14:56:42.362256 17898 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0619 14:56:42.362265 17898 net.cpp:91] Creating Layer Eltwise3_ReLU7_0_split
I0619 14:56:42.362272 17898 net.cpp:425] Eltwise3_ReLU7_0_split <- Eltwise3
I0619 14:56:42.362285 17898 net.cpp:399] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0619 14:56:42.362298 17898 net.cpp:399] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0619 14:56:42.362380 17898 net.cpp:141] Setting up Eltwise3_ReLU7_0_split
I0619 14:56:42.362393 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.362402 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.362409 17898 net.cpp:156] Memory required for data: 328730112
I0619 14:56:42.362416 17898 layer_factory.hpp:77] Creating layer Convolution8
I0619 14:56:42.362432 17898 net.cpp:91] Creating Layer Convolution8
I0619 14:56:42.362439 17898 net.cpp:425] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0619 14:56:42.362452 17898 net.cpp:399] Convolution8 -> Convolution8
I0619 14:56:42.363062 17898 net.cpp:141] Setting up Convolution8
I0619 14:56:42.363078 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.363085 17898 net.cpp:156] Memory required for data: 337118720
I0619 14:56:42.363097 17898 layer_factory.hpp:77] Creating layer BatchNorm8
I0619 14:56:42.363111 17898 net.cpp:91] Creating Layer BatchNorm8
I0619 14:56:42.363121 17898 net.cpp:425] BatchNorm8 <- Convolution8
I0619 14:56:42.363131 17898 net.cpp:386] BatchNorm8 -> Convolution8 (in-place)
I0619 14:56:42.363518 17898 net.cpp:141] Setting up BatchNorm8
I0619 14:56:42.363533 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.363539 17898 net.cpp:156] Memory required for data: 345507328
I0619 14:56:42.363555 17898 layer_factory.hpp:77] Creating layer Scale8
I0619 14:56:42.363570 17898 net.cpp:91] Creating Layer Scale8
I0619 14:56:42.363579 17898 net.cpp:425] Scale8 <- Convolution8
I0619 14:56:42.363590 17898 net.cpp:386] Scale8 -> Convolution8 (in-place)
I0619 14:56:42.363654 17898 layer_factory.hpp:77] Creating layer Scale8
I0619 14:56:42.363874 17898 net.cpp:141] Setting up Scale8
I0619 14:56:42.363888 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.363895 17898 net.cpp:156] Memory required for data: 353895936
I0619 14:56:42.363909 17898 layer_factory.hpp:77] Creating layer ReLU8
I0619 14:56:42.363919 17898 net.cpp:91] Creating Layer ReLU8
I0619 14:56:42.363926 17898 net.cpp:425] ReLU8 <- Convolution8
I0619 14:56:42.363940 17898 net.cpp:386] ReLU8 -> Convolution8 (in-place)
I0619 14:56:42.363950 17898 net.cpp:141] Setting up ReLU8
I0619 14:56:42.363960 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.363967 17898 net.cpp:156] Memory required for data: 362284544
I0619 14:56:42.363973 17898 layer_factory.hpp:77] Creating layer Convolution9
I0619 14:56:42.363991 17898 net.cpp:91] Creating Layer Convolution9
I0619 14:56:42.363998 17898 net.cpp:425] Convolution9 <- Convolution8
I0619 14:56:42.364014 17898 net.cpp:399] Convolution9 -> Convolution9
I0619 14:56:42.364682 17898 net.cpp:141] Setting up Convolution9
I0619 14:56:42.364701 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.364707 17898 net.cpp:156] Memory required for data: 370673152
I0619 14:56:42.364720 17898 layer_factory.hpp:77] Creating layer BatchNorm9
I0619 14:56:42.364734 17898 net.cpp:91] Creating Layer BatchNorm9
I0619 14:56:42.364742 17898 net.cpp:425] BatchNorm9 <- Convolution9
I0619 14:56:42.364753 17898 net.cpp:386] BatchNorm9 -> Convolution9 (in-place)
I0619 14:56:42.365149 17898 net.cpp:141] Setting up BatchNorm9
I0619 14:56:42.365162 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.365170 17898 net.cpp:156] Memory required for data: 379061760
I0619 14:56:42.365183 17898 layer_factory.hpp:77] Creating layer Scale9
I0619 14:56:42.365198 17898 net.cpp:91] Creating Layer Scale9
I0619 14:56:42.365207 17898 net.cpp:425] Scale9 <- Convolution9
I0619 14:56:42.365218 17898 net.cpp:386] Scale9 -> Convolution9 (in-place)
I0619 14:56:42.365285 17898 layer_factory.hpp:77] Creating layer Scale9
I0619 14:56:42.365510 17898 net.cpp:141] Setting up Scale9
I0619 14:56:42.365523 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.365530 17898 net.cpp:156] Memory required for data: 387450368
I0619 14:56:42.365542 17898 layer_factory.hpp:77] Creating layer Eltwise4
I0619 14:56:42.365553 17898 net.cpp:91] Creating Layer Eltwise4
I0619 14:56:42.365561 17898 net.cpp:425] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0619 14:56:42.365571 17898 net.cpp:425] Eltwise4 <- Convolution9
I0619 14:56:42.365584 17898 net.cpp:399] Eltwise4 -> Eltwise4
I0619 14:56:42.365631 17898 net.cpp:141] Setting up Eltwise4
I0619 14:56:42.365643 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.365649 17898 net.cpp:156] Memory required for data: 395838976
I0619 14:56:42.365656 17898 layer_factory.hpp:77] Creating layer ReLU9
I0619 14:56:42.365666 17898 net.cpp:91] Creating Layer ReLU9
I0619 14:56:42.365674 17898 net.cpp:425] ReLU9 <- Eltwise4
I0619 14:56:42.365684 17898 net.cpp:386] ReLU9 -> Eltwise4 (in-place)
I0619 14:56:42.365694 17898 net.cpp:141] Setting up ReLU9
I0619 14:56:42.365703 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.365710 17898 net.cpp:156] Memory required for data: 404227584
I0619 14:56:42.365717 17898 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0619 14:56:42.365730 17898 net.cpp:91] Creating Layer Eltwise4_ReLU9_0_split
I0619 14:56:42.365736 17898 net.cpp:425] Eltwise4_ReLU9_0_split <- Eltwise4
I0619 14:56:42.365746 17898 net.cpp:399] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0619 14:56:42.365761 17898 net.cpp:399] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0619 14:56:42.365830 17898 net.cpp:141] Setting up Eltwise4_ReLU9_0_split
I0619 14:56:42.365842 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.365851 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.365859 17898 net.cpp:156] Memory required for data: 421004800
I0619 14:56:42.365865 17898 layer_factory.hpp:77] Creating layer Convolution10
I0619 14:56:42.365880 17898 net.cpp:91] Creating Layer Convolution10
I0619 14:56:42.365887 17898 net.cpp:425] Convolution10 <- Eltwise4_ReLU9_0_split_0
I0619 14:56:42.365901 17898 net.cpp:399] Convolution10 -> Convolution10
I0619 14:56:42.366524 17898 net.cpp:141] Setting up Convolution10
I0619 14:56:42.366541 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.366549 17898 net.cpp:156] Memory required for data: 429393408
I0619 14:56:42.366580 17898 layer_factory.hpp:77] Creating layer BatchNorm10
I0619 14:56:42.366598 17898 net.cpp:91] Creating Layer BatchNorm10
I0619 14:56:42.366606 17898 net.cpp:425] BatchNorm10 <- Convolution10
I0619 14:56:42.366618 17898 net.cpp:386] BatchNorm10 -> Convolution10 (in-place)
I0619 14:56:42.367000 17898 net.cpp:141] Setting up BatchNorm10
I0619 14:56:42.367014 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.367025 17898 net.cpp:156] Memory required for data: 437782016
I0619 14:56:42.367060 17898 layer_factory.hpp:77] Creating layer Scale10
I0619 14:56:42.367082 17898 net.cpp:91] Creating Layer Scale10
I0619 14:56:42.367090 17898 net.cpp:425] Scale10 <- Convolution10
I0619 14:56:42.367102 17898 net.cpp:386] Scale10 -> Convolution10 (in-place)
I0619 14:56:42.367178 17898 layer_factory.hpp:77] Creating layer Scale10
I0619 14:56:42.367414 17898 net.cpp:141] Setting up Scale10
I0619 14:56:42.367429 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.367436 17898 net.cpp:156] Memory required for data: 446170624
I0619 14:56:42.367449 17898 layer_factory.hpp:77] Creating layer ReLU10
I0619 14:56:42.367460 17898 net.cpp:91] Creating Layer ReLU10
I0619 14:56:42.367467 17898 net.cpp:425] ReLU10 <- Convolution10
I0619 14:56:42.367477 17898 net.cpp:386] ReLU10 -> Convolution10 (in-place)
I0619 14:56:42.367491 17898 net.cpp:141] Setting up ReLU10
I0619 14:56:42.367501 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.367508 17898 net.cpp:156] Memory required for data: 454559232
I0619 14:56:42.367516 17898 layer_factory.hpp:77] Creating layer Convolution11
I0619 14:56:42.367544 17898 net.cpp:91] Creating Layer Convolution11
I0619 14:56:42.367552 17898 net.cpp:425] Convolution11 <- Convolution10
I0619 14:56:42.367568 17898 net.cpp:399] Convolution11 -> Convolution11
I0619 14:56:42.368186 17898 net.cpp:141] Setting up Convolution11
I0619 14:56:42.368201 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.368208 17898 net.cpp:156] Memory required for data: 462947840
I0619 14:56:42.368221 17898 layer_factory.hpp:77] Creating layer BatchNorm11
I0619 14:56:42.368234 17898 net.cpp:91] Creating Layer BatchNorm11
I0619 14:56:42.368242 17898 net.cpp:425] BatchNorm11 <- Convolution11
I0619 14:56:42.368255 17898 net.cpp:386] BatchNorm11 -> Convolution11 (in-place)
I0619 14:56:42.368626 17898 net.cpp:141] Setting up BatchNorm11
I0619 14:56:42.368640 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.368648 17898 net.cpp:156] Memory required for data: 471336448
I0619 14:56:42.368662 17898 layer_factory.hpp:77] Creating layer Scale11
I0619 14:56:42.368676 17898 net.cpp:91] Creating Layer Scale11
I0619 14:56:42.368685 17898 net.cpp:425] Scale11 <- Convolution11
I0619 14:56:42.368696 17898 net.cpp:386] Scale11 -> Convolution11 (in-place)
I0619 14:56:42.368757 17898 layer_factory.hpp:77] Creating layer Scale11
I0619 14:56:42.368978 17898 net.cpp:141] Setting up Scale11
I0619 14:56:42.368990 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.368998 17898 net.cpp:156] Memory required for data: 479725056
I0619 14:56:42.369009 17898 layer_factory.hpp:77] Creating layer Eltwise5
I0619 14:56:42.369021 17898 net.cpp:91] Creating Layer Eltwise5
I0619 14:56:42.369029 17898 net.cpp:425] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0619 14:56:42.369038 17898 net.cpp:425] Eltwise5 <- Convolution11
I0619 14:56:42.369050 17898 net.cpp:399] Eltwise5 -> Eltwise5
I0619 14:56:42.369096 17898 net.cpp:141] Setting up Eltwise5
I0619 14:56:42.369107 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.369114 17898 net.cpp:156] Memory required for data: 488113664
I0619 14:56:42.369120 17898 layer_factory.hpp:77] Creating layer ReLU11
I0619 14:56:42.369133 17898 net.cpp:91] Creating Layer ReLU11
I0619 14:56:42.369141 17898 net.cpp:425] ReLU11 <- Eltwise5
I0619 14:56:42.369150 17898 net.cpp:386] ReLU11 -> Eltwise5 (in-place)
I0619 14:56:42.369161 17898 net.cpp:141] Setting up ReLU11
I0619 14:56:42.369171 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.369177 17898 net.cpp:156] Memory required for data: 496502272
I0619 14:56:42.369184 17898 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0619 14:56:42.369194 17898 net.cpp:91] Creating Layer Eltwise5_ReLU11_0_split
I0619 14:56:42.369201 17898 net.cpp:425] Eltwise5_ReLU11_0_split <- Eltwise5
I0619 14:56:42.369213 17898 net.cpp:399] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0619 14:56:42.369231 17898 net.cpp:399] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0619 14:56:42.369319 17898 net.cpp:141] Setting up Eltwise5_ReLU11_0_split
I0619 14:56:42.369333 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.369341 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.369349 17898 net.cpp:156] Memory required for data: 513279488
I0619 14:56:42.369356 17898 layer_factory.hpp:77] Creating layer Convolution12
I0619 14:56:42.369375 17898 net.cpp:91] Creating Layer Convolution12
I0619 14:56:42.369385 17898 net.cpp:425] Convolution12 <- Eltwise5_ReLU11_0_split_0
I0619 14:56:42.369396 17898 net.cpp:399] Convolution12 -> Convolution12
I0619 14:56:42.370018 17898 net.cpp:141] Setting up Convolution12
I0619 14:56:42.370034 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.370041 17898 net.cpp:156] Memory required for data: 521668096
I0619 14:56:42.370054 17898 layer_factory.hpp:77] Creating layer BatchNorm12
I0619 14:56:42.370067 17898 net.cpp:91] Creating Layer BatchNorm12
I0619 14:56:42.370075 17898 net.cpp:425] BatchNorm12 <- Convolution12
I0619 14:56:42.370085 17898 net.cpp:386] BatchNorm12 -> Convolution12 (in-place)
I0619 14:56:42.370508 17898 net.cpp:141] Setting up BatchNorm12
I0619 14:56:42.370527 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.370533 17898 net.cpp:156] Memory required for data: 530056704
I0619 14:56:42.370549 17898 layer_factory.hpp:77] Creating layer Scale12
I0619 14:56:42.370560 17898 net.cpp:91] Creating Layer Scale12
I0619 14:56:42.370568 17898 net.cpp:425] Scale12 <- Convolution12
I0619 14:56:42.370579 17898 net.cpp:386] Scale12 -> Convolution12 (in-place)
I0619 14:56:42.370651 17898 layer_factory.hpp:77] Creating layer Scale12
I0619 14:56:42.370874 17898 net.cpp:141] Setting up Scale12
I0619 14:56:42.370887 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.370893 17898 net.cpp:156] Memory required for data: 538445312
I0619 14:56:42.370904 17898 layer_factory.hpp:77] Creating layer ReLU12
I0619 14:56:42.370914 17898 net.cpp:91] Creating Layer ReLU12
I0619 14:56:42.370921 17898 net.cpp:425] ReLU12 <- Convolution12
I0619 14:56:42.370934 17898 net.cpp:386] ReLU12 -> Convolution12 (in-place)
I0619 14:56:42.370945 17898 net.cpp:141] Setting up ReLU12
I0619 14:56:42.370954 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.370960 17898 net.cpp:156] Memory required for data: 546833920
I0619 14:56:42.370966 17898 layer_factory.hpp:77] Creating layer Convolution13
I0619 14:56:42.370983 17898 net.cpp:91] Creating Layer Convolution13
I0619 14:56:42.370990 17898 net.cpp:425] Convolution13 <- Convolution12
I0619 14:56:42.371001 17898 net.cpp:399] Convolution13 -> Convolution13
I0619 14:56:42.371558 17898 net.cpp:141] Setting up Convolution13
I0619 14:56:42.371572 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.371578 17898 net.cpp:156] Memory required for data: 555222528
I0619 14:56:42.371590 17898 layer_factory.hpp:77] Creating layer BatchNorm13
I0619 14:56:42.371603 17898 net.cpp:91] Creating Layer BatchNorm13
I0619 14:56:42.371610 17898 net.cpp:425] BatchNorm13 <- Convolution13
I0619 14:56:42.371620 17898 net.cpp:386] BatchNorm13 -> Convolution13 (in-place)
I0619 14:56:42.371973 17898 net.cpp:141] Setting up BatchNorm13
I0619 14:56:42.371986 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.371992 17898 net.cpp:156] Memory required for data: 563611136
I0619 14:56:42.372007 17898 layer_factory.hpp:77] Creating layer Scale13
I0619 14:56:42.372023 17898 net.cpp:91] Creating Layer Scale13
I0619 14:56:42.372032 17898 net.cpp:425] Scale13 <- Convolution13
I0619 14:56:42.372041 17898 net.cpp:386] Scale13 -> Convolution13 (in-place)
I0619 14:56:42.372102 17898 layer_factory.hpp:77] Creating layer Scale13
I0619 14:56:42.372306 17898 net.cpp:141] Setting up Scale13
I0619 14:56:42.372319 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.372325 17898 net.cpp:156] Memory required for data: 571999744
I0619 14:56:42.372337 17898 layer_factory.hpp:77] Creating layer Eltwise6
I0619 14:56:42.372365 17898 net.cpp:91] Creating Layer Eltwise6
I0619 14:56:42.372392 17898 net.cpp:425] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0619 14:56:42.372402 17898 net.cpp:425] Eltwise6 <- Convolution13
I0619 14:56:42.372412 17898 net.cpp:399] Eltwise6 -> Eltwise6
I0619 14:56:42.372457 17898 net.cpp:141] Setting up Eltwise6
I0619 14:56:42.372468 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.372474 17898 net.cpp:156] Memory required for data: 580388352
I0619 14:56:42.372481 17898 layer_factory.hpp:77] Creating layer ReLU13
I0619 14:56:42.372494 17898 net.cpp:91] Creating Layer ReLU13
I0619 14:56:42.372503 17898 net.cpp:425] ReLU13 <- Eltwise6
I0619 14:56:42.372511 17898 net.cpp:386] ReLU13 -> Eltwise6 (in-place)
I0619 14:56:42.372522 17898 net.cpp:141] Setting up ReLU13
I0619 14:56:42.372530 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.372537 17898 net.cpp:156] Memory required for data: 588776960
I0619 14:56:42.372544 17898 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0619 14:56:42.372553 17898 net.cpp:91] Creating Layer Eltwise6_ReLU13_0_split
I0619 14:56:42.372560 17898 net.cpp:425] Eltwise6_ReLU13_0_split <- Eltwise6
I0619 14:56:42.372570 17898 net.cpp:399] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0619 14:56:42.372581 17898 net.cpp:399] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0619 14:56:42.372645 17898 net.cpp:141] Setting up Eltwise6_ReLU13_0_split
I0619 14:56:42.372656 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.372666 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.372673 17898 net.cpp:156] Memory required for data: 605554176
I0619 14:56:42.372679 17898 layer_factory.hpp:77] Creating layer Convolution14
I0619 14:56:42.372699 17898 net.cpp:91] Creating Layer Convolution14
I0619 14:56:42.372705 17898 net.cpp:425] Convolution14 <- Eltwise6_ReLU13_0_split_0
I0619 14:56:42.372716 17898 net.cpp:399] Convolution14 -> Convolution14
I0619 14:56:42.373282 17898 net.cpp:141] Setting up Convolution14
I0619 14:56:42.373296 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.373303 17898 net.cpp:156] Memory required for data: 613942784
I0619 14:56:42.373316 17898 layer_factory.hpp:77] Creating layer BatchNorm14
I0619 14:56:42.373327 17898 net.cpp:91] Creating Layer BatchNorm14
I0619 14:56:42.373333 17898 net.cpp:425] BatchNorm14 <- Convolution14
I0619 14:56:42.373348 17898 net.cpp:386] BatchNorm14 -> Convolution14 (in-place)
I0619 14:56:42.373711 17898 net.cpp:141] Setting up BatchNorm14
I0619 14:56:42.373723 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.373730 17898 net.cpp:156] Memory required for data: 622331392
I0619 14:56:42.373744 17898 layer_factory.hpp:77] Creating layer Scale14
I0619 14:56:42.373754 17898 net.cpp:91] Creating Layer Scale14
I0619 14:56:42.373761 17898 net.cpp:425] Scale14 <- Convolution14
I0619 14:56:42.373775 17898 net.cpp:386] Scale14 -> Convolution14 (in-place)
I0619 14:56:42.373832 17898 layer_factory.hpp:77] Creating layer Scale14
I0619 14:56:42.374037 17898 net.cpp:141] Setting up Scale14
I0619 14:56:42.374050 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.374056 17898 net.cpp:156] Memory required for data: 630720000
I0619 14:56:42.374068 17898 layer_factory.hpp:77] Creating layer ReLU14
I0619 14:56:42.374076 17898 net.cpp:91] Creating Layer ReLU14
I0619 14:56:42.374083 17898 net.cpp:425] ReLU14 <- Convolution14
I0619 14:56:42.374094 17898 net.cpp:386] ReLU14 -> Convolution14 (in-place)
I0619 14:56:42.374106 17898 net.cpp:141] Setting up ReLU14
I0619 14:56:42.374114 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.374121 17898 net.cpp:156] Memory required for data: 639108608
I0619 14:56:42.374127 17898 layer_factory.hpp:77] Creating layer Convolution15
I0619 14:56:42.374146 17898 net.cpp:91] Creating Layer Convolution15
I0619 14:56:42.374155 17898 net.cpp:425] Convolution15 <- Convolution14
I0619 14:56:42.374164 17898 net.cpp:399] Convolution15 -> Convolution15
I0619 14:56:42.374816 17898 net.cpp:141] Setting up Convolution15
I0619 14:56:42.374853 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.374861 17898 net.cpp:156] Memory required for data: 647497216
I0619 14:56:42.374873 17898 layer_factory.hpp:77] Creating layer BatchNorm15
I0619 14:56:42.374884 17898 net.cpp:91] Creating Layer BatchNorm15
I0619 14:56:42.374892 17898 net.cpp:425] BatchNorm15 <- Convolution15
I0619 14:56:42.374907 17898 net.cpp:386] BatchNorm15 -> Convolution15 (in-place)
I0619 14:56:42.375354 17898 net.cpp:141] Setting up BatchNorm15
I0619 14:56:42.375370 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.375376 17898 net.cpp:156] Memory required for data: 655885824
I0619 14:56:42.375391 17898 layer_factory.hpp:77] Creating layer Scale15
I0619 14:56:42.375402 17898 net.cpp:91] Creating Layer Scale15
I0619 14:56:42.375411 17898 net.cpp:425] Scale15 <- Convolution15
I0619 14:56:42.375421 17898 net.cpp:386] Scale15 -> Convolution15 (in-place)
I0619 14:56:42.375483 17898 layer_factory.hpp:77] Creating layer Scale15
I0619 14:56:42.375689 17898 net.cpp:141] Setting up Scale15
I0619 14:56:42.375701 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.375707 17898 net.cpp:156] Memory required for data: 664274432
I0619 14:56:42.375720 17898 layer_factory.hpp:77] Creating layer Eltwise7
I0619 14:56:42.375733 17898 net.cpp:91] Creating Layer Eltwise7
I0619 14:56:42.375741 17898 net.cpp:425] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0619 14:56:42.375751 17898 net.cpp:425] Eltwise7 <- Convolution15
I0619 14:56:42.375763 17898 net.cpp:399] Eltwise7 -> Eltwise7
I0619 14:56:42.375804 17898 net.cpp:141] Setting up Eltwise7
I0619 14:56:42.375815 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.375823 17898 net.cpp:156] Memory required for data: 672663040
I0619 14:56:42.375829 17898 layer_factory.hpp:77] Creating layer ReLU15
I0619 14:56:42.375845 17898 net.cpp:91] Creating Layer ReLU15
I0619 14:56:42.375854 17898 net.cpp:425] ReLU15 <- Eltwise7
I0619 14:56:42.375864 17898 net.cpp:386] ReLU15 -> Eltwise7 (in-place)
I0619 14:56:42.375876 17898 net.cpp:141] Setting up ReLU15
I0619 14:56:42.375885 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.375891 17898 net.cpp:156] Memory required for data: 681051648
I0619 14:56:42.375898 17898 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0619 14:56:42.375907 17898 net.cpp:91] Creating Layer Eltwise7_ReLU15_0_split
I0619 14:56:42.375913 17898 net.cpp:425] Eltwise7_ReLU15_0_split <- Eltwise7
I0619 14:56:42.375926 17898 net.cpp:399] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0619 14:56:42.375936 17898 net.cpp:399] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0619 14:56:42.376001 17898 net.cpp:141] Setting up Eltwise7_ReLU15_0_split
I0619 14:56:42.376013 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.376021 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.376027 17898 net.cpp:156] Memory required for data: 697828864
I0619 14:56:42.376034 17898 layer_factory.hpp:77] Creating layer Convolution16
I0619 14:56:42.376049 17898 net.cpp:91] Creating Layer Convolution16
I0619 14:56:42.376055 17898 net.cpp:425] Convolution16 <- Eltwise7_ReLU15_0_split_0
I0619 14:56:42.376070 17898 net.cpp:399] Convolution16 -> Convolution16
I0619 14:56:42.376641 17898 net.cpp:141] Setting up Convolution16
I0619 14:56:42.376654 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.376660 17898 net.cpp:156] Memory required for data: 706217472
I0619 14:56:42.376672 17898 layer_factory.hpp:77] Creating layer BatchNorm16
I0619 14:56:42.376682 17898 net.cpp:91] Creating Layer BatchNorm16
I0619 14:56:42.376690 17898 net.cpp:425] BatchNorm16 <- Convolution16
I0619 14:56:42.376703 17898 net.cpp:386] BatchNorm16 -> Convolution16 (in-place)
I0619 14:56:42.377070 17898 net.cpp:141] Setting up BatchNorm16
I0619 14:56:42.377084 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.377089 17898 net.cpp:156] Memory required for data: 714606080
I0619 14:56:42.377107 17898 layer_factory.hpp:77] Creating layer Scale16
I0619 14:56:42.377137 17898 net.cpp:91] Creating Layer Scale16
I0619 14:56:42.377146 17898 net.cpp:425] Scale16 <- Convolution16
I0619 14:56:42.377156 17898 net.cpp:386] Scale16 -> Convolution16 (in-place)
I0619 14:56:42.377223 17898 layer_factory.hpp:77] Creating layer Scale16
I0619 14:56:42.377429 17898 net.cpp:141] Setting up Scale16
I0619 14:56:42.377442 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.377449 17898 net.cpp:156] Memory required for data: 722994688
I0619 14:56:42.377460 17898 layer_factory.hpp:77] Creating layer ReLU16
I0619 14:56:42.377470 17898 net.cpp:91] Creating Layer ReLU16
I0619 14:56:42.377476 17898 net.cpp:425] ReLU16 <- Convolution16
I0619 14:56:42.377488 17898 net.cpp:386] ReLU16 -> Convolution16 (in-place)
I0619 14:56:42.377501 17898 net.cpp:141] Setting up ReLU16
I0619 14:56:42.377509 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.377516 17898 net.cpp:156] Memory required for data: 731383296
I0619 14:56:42.377522 17898 layer_factory.hpp:77] Creating layer Convolution17
I0619 14:56:42.377537 17898 net.cpp:91] Creating Layer Convolution17
I0619 14:56:42.377544 17898 net.cpp:425] Convolution17 <- Convolution16
I0619 14:56:42.377558 17898 net.cpp:399] Convolution17 -> Convolution17
I0619 14:56:42.378134 17898 net.cpp:141] Setting up Convolution17
I0619 14:56:42.378149 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.378155 17898 net.cpp:156] Memory required for data: 739771904
I0619 14:56:42.378168 17898 layer_factory.hpp:77] Creating layer BatchNorm17
I0619 14:56:42.378180 17898 net.cpp:91] Creating Layer BatchNorm17
I0619 14:56:42.378188 17898 net.cpp:425] BatchNorm17 <- Convolution17
I0619 14:56:42.378201 17898 net.cpp:386] BatchNorm17 -> Convolution17 (in-place)
I0619 14:56:42.378582 17898 net.cpp:141] Setting up BatchNorm17
I0619 14:56:42.378597 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.378603 17898 net.cpp:156] Memory required for data: 748160512
I0619 14:56:42.378618 17898 layer_factory.hpp:77] Creating layer Scale17
I0619 14:56:42.378628 17898 net.cpp:91] Creating Layer Scale17
I0619 14:56:42.378636 17898 net.cpp:425] Scale17 <- Convolution17
I0619 14:56:42.378645 17898 net.cpp:386] Scale17 -> Convolution17 (in-place)
I0619 14:56:42.378710 17898 layer_factory.hpp:77] Creating layer Scale17
I0619 14:56:42.378919 17898 net.cpp:141] Setting up Scale17
I0619 14:56:42.378931 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.378937 17898 net.cpp:156] Memory required for data: 756549120
I0619 14:56:42.378948 17898 layer_factory.hpp:77] Creating layer Eltwise8
I0619 14:56:42.378962 17898 net.cpp:91] Creating Layer Eltwise8
I0619 14:56:42.378970 17898 net.cpp:425] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0619 14:56:42.378979 17898 net.cpp:425] Eltwise8 <- Convolution17
I0619 14:56:42.378991 17898 net.cpp:399] Eltwise8 -> Eltwise8
I0619 14:56:42.379032 17898 net.cpp:141] Setting up Eltwise8
I0619 14:56:42.379043 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.379050 17898 net.cpp:156] Memory required for data: 764937728
I0619 14:56:42.379055 17898 layer_factory.hpp:77] Creating layer ReLU17
I0619 14:56:42.379068 17898 net.cpp:91] Creating Layer ReLU17
I0619 14:56:42.379076 17898 net.cpp:425] ReLU17 <- Eltwise8
I0619 14:56:42.379086 17898 net.cpp:386] ReLU17 -> Eltwise8 (in-place)
I0619 14:56:42.379096 17898 net.cpp:141] Setting up ReLU17
I0619 14:56:42.379104 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.379112 17898 net.cpp:156] Memory required for data: 773326336
I0619 14:56:42.379119 17898 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0619 14:56:42.379128 17898 net.cpp:91] Creating Layer Eltwise8_ReLU17_0_split
I0619 14:56:42.379135 17898 net.cpp:425] Eltwise8_ReLU17_0_split <- Eltwise8
I0619 14:56:42.379147 17898 net.cpp:399] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0619 14:56:42.379158 17898 net.cpp:399] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0619 14:56:42.379225 17898 net.cpp:141] Setting up Eltwise8_ReLU17_0_split
I0619 14:56:42.379256 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.379264 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.379271 17898 net.cpp:156] Memory required for data: 790103552
I0619 14:56:42.379276 17898 layer_factory.hpp:77] Creating layer Convolution18
I0619 14:56:42.379294 17898 net.cpp:91] Creating Layer Convolution18
I0619 14:56:42.379302 17898 net.cpp:425] Convolution18 <- Eltwise8_ReLU17_0_split_0
I0619 14:56:42.379313 17898 net.cpp:399] Convolution18 -> Convolution18
I0619 14:56:42.379887 17898 net.cpp:141] Setting up Convolution18
I0619 14:56:42.379902 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.379909 17898 net.cpp:156] Memory required for data: 798492160
I0619 14:56:42.379920 17898 layer_factory.hpp:77] Creating layer BatchNorm18
I0619 14:56:42.379930 17898 net.cpp:91] Creating Layer BatchNorm18
I0619 14:56:42.379937 17898 net.cpp:425] BatchNorm18 <- Convolution18
I0619 14:56:42.379952 17898 net.cpp:386] BatchNorm18 -> Convolution18 (in-place)
I0619 14:56:42.380321 17898 net.cpp:141] Setting up BatchNorm18
I0619 14:56:42.380336 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.380343 17898 net.cpp:156] Memory required for data: 806880768
I0619 14:56:42.380357 17898 layer_factory.hpp:77] Creating layer Scale18
I0619 14:56:42.380368 17898 net.cpp:91] Creating Layer Scale18
I0619 14:56:42.380375 17898 net.cpp:425] Scale18 <- Convolution18
I0619 14:56:42.380385 17898 net.cpp:386] Scale18 -> Convolution18 (in-place)
I0619 14:56:42.380448 17898 layer_factory.hpp:77] Creating layer Scale18
I0619 14:56:42.380664 17898 net.cpp:141] Setting up Scale18
I0619 14:56:42.380677 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.380683 17898 net.cpp:156] Memory required for data: 815269376
I0619 14:56:42.380694 17898 layer_factory.hpp:77] Creating layer ReLU18
I0619 14:56:42.380704 17898 net.cpp:91] Creating Layer ReLU18
I0619 14:56:42.380712 17898 net.cpp:425] ReLU18 <- Convolution18
I0619 14:56:42.380723 17898 net.cpp:386] ReLU18 -> Convolution18 (in-place)
I0619 14:56:42.380735 17898 net.cpp:141] Setting up ReLU18
I0619 14:56:42.380743 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.380750 17898 net.cpp:156] Memory required for data: 823657984
I0619 14:56:42.380756 17898 layer_factory.hpp:77] Creating layer Convolution19
I0619 14:56:42.380770 17898 net.cpp:91] Creating Layer Convolution19
I0619 14:56:42.380776 17898 net.cpp:425] Convolution19 <- Convolution18
I0619 14:56:42.380790 17898 net.cpp:399] Convolution19 -> Convolution19
I0619 14:56:42.381366 17898 net.cpp:141] Setting up Convolution19
I0619 14:56:42.381381 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.381388 17898 net.cpp:156] Memory required for data: 832046592
I0619 14:56:42.381400 17898 layer_factory.hpp:77] Creating layer BatchNorm19
I0619 14:56:42.381412 17898 net.cpp:91] Creating Layer BatchNorm19
I0619 14:56:42.381419 17898 net.cpp:425] BatchNorm19 <- Convolution19
I0619 14:56:42.381429 17898 net.cpp:386] BatchNorm19 -> Convolution19 (in-place)
I0619 14:56:42.381811 17898 net.cpp:141] Setting up BatchNorm19
I0619 14:56:42.381825 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.381831 17898 net.cpp:156] Memory required for data: 840435200
I0619 14:56:42.381875 17898 layer_factory.hpp:77] Creating layer Scale19
I0619 14:56:42.381887 17898 net.cpp:91] Creating Layer Scale19
I0619 14:56:42.381894 17898 net.cpp:425] Scale19 <- Convolution19
I0619 14:56:42.381904 17898 net.cpp:386] Scale19 -> Convolution19 (in-place)
I0619 14:56:42.381970 17898 layer_factory.hpp:77] Creating layer Scale19
I0619 14:56:42.382179 17898 net.cpp:141] Setting up Scale19
I0619 14:56:42.382191 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.382197 17898 net.cpp:156] Memory required for data: 848823808
I0619 14:56:42.382208 17898 layer_factory.hpp:77] Creating layer Eltwise9
I0619 14:56:42.382218 17898 net.cpp:91] Creating Layer Eltwise9
I0619 14:56:42.382230 17898 net.cpp:425] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0619 14:56:42.382256 17898 net.cpp:425] Eltwise9 <- Convolution19
I0619 14:56:42.382272 17898 net.cpp:399] Eltwise9 -> Eltwise9
I0619 14:56:42.382318 17898 net.cpp:141] Setting up Eltwise9
I0619 14:56:42.382330 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.382336 17898 net.cpp:156] Memory required for data: 857212416
I0619 14:56:42.382342 17898 layer_factory.hpp:77] Creating layer ReLU19
I0619 14:56:42.382372 17898 net.cpp:91] Creating Layer ReLU19
I0619 14:56:42.382381 17898 net.cpp:425] ReLU19 <- Eltwise9
I0619 14:56:42.382390 17898 net.cpp:386] ReLU19 -> Eltwise9 (in-place)
I0619 14:56:42.382402 17898 net.cpp:141] Setting up ReLU19
I0619 14:56:42.382411 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.382417 17898 net.cpp:156] Memory required for data: 865601024
I0619 14:56:42.382424 17898 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0619 14:56:42.382436 17898 net.cpp:91] Creating Layer Eltwise9_ReLU19_0_split
I0619 14:56:42.382443 17898 net.cpp:425] Eltwise9_ReLU19_0_split <- Eltwise9
I0619 14:56:42.382452 17898 net.cpp:399] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0619 14:56:42.382464 17898 net.cpp:399] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0619 14:56:42.382532 17898 net.cpp:141] Setting up Eltwise9_ReLU19_0_split
I0619 14:56:42.382544 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.382551 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.382558 17898 net.cpp:156] Memory required for data: 882378240
I0619 14:56:42.382565 17898 layer_factory.hpp:77] Creating layer Convolution20
I0619 14:56:42.382580 17898 net.cpp:91] Creating Layer Convolution20
I0619 14:56:42.382586 17898 net.cpp:425] Convolution20 <- Eltwise9_ReLU19_0_split_0
I0619 14:56:42.382598 17898 net.cpp:399] Convolution20 -> Convolution20
I0619 14:56:42.383154 17898 net.cpp:141] Setting up Convolution20
I0619 14:56:42.383167 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.383174 17898 net.cpp:156] Memory required for data: 890766848
I0619 14:56:42.383185 17898 layer_factory.hpp:77] Creating layer BatchNorm20
I0619 14:56:42.383198 17898 net.cpp:91] Creating Layer BatchNorm20
I0619 14:56:42.383205 17898 net.cpp:425] BatchNorm20 <- Convolution20
I0619 14:56:42.383214 17898 net.cpp:386] BatchNorm20 -> Convolution20 (in-place)
I0619 14:56:42.383555 17898 net.cpp:141] Setting up BatchNorm20
I0619 14:56:42.383566 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.383572 17898 net.cpp:156] Memory required for data: 899155456
I0619 14:56:42.383585 17898 layer_factory.hpp:77] Creating layer Scale20
I0619 14:56:42.383595 17898 net.cpp:91] Creating Layer Scale20
I0619 14:56:42.383602 17898 net.cpp:425] Scale20 <- Convolution20
I0619 14:56:42.383611 17898 net.cpp:386] Scale20 -> Convolution20 (in-place)
I0619 14:56:42.383667 17898 layer_factory.hpp:77] Creating layer Scale20
I0619 14:56:42.383870 17898 net.cpp:141] Setting up Scale20
I0619 14:56:42.383883 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.383889 17898 net.cpp:156] Memory required for data: 907544064
I0619 14:56:42.383899 17898 layer_factory.hpp:77] Creating layer ReLU20
I0619 14:56:42.383908 17898 net.cpp:91] Creating Layer ReLU20
I0619 14:56:42.383915 17898 net.cpp:425] ReLU20 <- Convolution20
I0619 14:56:42.383929 17898 net.cpp:386] ReLU20 -> Convolution20 (in-place)
I0619 14:56:42.383940 17898 net.cpp:141] Setting up ReLU20
I0619 14:56:42.383949 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.383954 17898 net.cpp:156] Memory required for data: 915932672
I0619 14:56:42.383960 17898 layer_factory.hpp:77] Creating layer Convolution21
I0619 14:56:42.383975 17898 net.cpp:91] Creating Layer Convolution21
I0619 14:56:42.383981 17898 net.cpp:425] Convolution21 <- Convolution20
I0619 14:56:42.383992 17898 net.cpp:399] Convolution21 -> Convolution21
I0619 14:56:42.384523 17898 net.cpp:141] Setting up Convolution21
I0619 14:56:42.384539 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.384562 17898 net.cpp:156] Memory required for data: 924321280
I0619 14:56:42.384574 17898 layer_factory.hpp:77] Creating layer BatchNorm21
I0619 14:56:42.384588 17898 net.cpp:91] Creating Layer BatchNorm21
I0619 14:56:42.384595 17898 net.cpp:425] BatchNorm21 <- Convolution21
I0619 14:56:42.384604 17898 net.cpp:386] BatchNorm21 -> Convolution21 (in-place)
I0619 14:56:42.384948 17898 net.cpp:141] Setting up BatchNorm21
I0619 14:56:42.384959 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.384965 17898 net.cpp:156] Memory required for data: 932709888
I0619 14:56:42.384979 17898 layer_factory.hpp:77] Creating layer Scale21
I0619 14:56:42.384990 17898 net.cpp:91] Creating Layer Scale21
I0619 14:56:42.384997 17898 net.cpp:425] Scale21 <- Convolution21
I0619 14:56:42.385006 17898 net.cpp:386] Scale21 -> Convolution21 (in-place)
I0619 14:56:42.385063 17898 layer_factory.hpp:77] Creating layer Scale21
I0619 14:56:42.385260 17898 net.cpp:141] Setting up Scale21
I0619 14:56:42.385272 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.385278 17898 net.cpp:156] Memory required for data: 941098496
I0619 14:56:42.385289 17898 layer_factory.hpp:77] Creating layer Eltwise10
I0619 14:56:42.385299 17898 net.cpp:91] Creating Layer Eltwise10
I0619 14:56:42.385306 17898 net.cpp:425] Eltwise10 <- Eltwise9_ReLU19_0_split_1
I0619 14:56:42.385314 17898 net.cpp:425] Eltwise10 <- Convolution21
I0619 14:56:42.385326 17898 net.cpp:399] Eltwise10 -> Eltwise10
I0619 14:56:42.385368 17898 net.cpp:141] Setting up Eltwise10
I0619 14:56:42.385378 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.385383 17898 net.cpp:156] Memory required for data: 949487104
I0619 14:56:42.385390 17898 layer_factory.hpp:77] Creating layer ReLU21
I0619 14:56:42.385398 17898 net.cpp:91] Creating Layer ReLU21
I0619 14:56:42.385404 17898 net.cpp:425] ReLU21 <- Eltwise10
I0619 14:56:42.385413 17898 net.cpp:386] ReLU21 -> Eltwise10 (in-place)
I0619 14:56:42.385423 17898 net.cpp:141] Setting up ReLU21
I0619 14:56:42.385432 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.385437 17898 net.cpp:156] Memory required for data: 957875712
I0619 14:56:42.385442 17898 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0619 14:56:42.385455 17898 net.cpp:91] Creating Layer Eltwise10_ReLU21_0_split
I0619 14:56:42.385462 17898 net.cpp:425] Eltwise10_ReLU21_0_split <- Eltwise10
I0619 14:56:42.385470 17898 net.cpp:399] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0619 14:56:42.385481 17898 net.cpp:399] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0619 14:56:42.385542 17898 net.cpp:141] Setting up Eltwise10_ReLU21_0_split
I0619 14:56:42.385552 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.385561 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.385566 17898 net.cpp:156] Memory required for data: 974652928
I0619 14:56:42.385572 17898 layer_factory.hpp:77] Creating layer Convolution22
I0619 14:56:42.385586 17898 net.cpp:91] Creating Layer Convolution22
I0619 14:56:42.385592 17898 net.cpp:425] Convolution22 <- Eltwise10_ReLU21_0_split_0
I0619 14:56:42.385603 17898 net.cpp:399] Convolution22 -> Convolution22
I0619 14:56:42.386132 17898 net.cpp:141] Setting up Convolution22
I0619 14:56:42.386144 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.386150 17898 net.cpp:156] Memory required for data: 983041536
I0619 14:56:42.386162 17898 layer_factory.hpp:77] Creating layer BatchNorm22
I0619 14:56:42.386174 17898 net.cpp:91] Creating Layer BatchNorm22
I0619 14:56:42.386181 17898 net.cpp:425] BatchNorm22 <- Convolution22
I0619 14:56:42.386190 17898 net.cpp:386] BatchNorm22 -> Convolution22 (in-place)
I0619 14:56:42.386555 17898 net.cpp:141] Setting up BatchNorm22
I0619 14:56:42.386569 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.386576 17898 net.cpp:156] Memory required for data: 991430144
I0619 14:56:42.386590 17898 layer_factory.hpp:77] Creating layer Scale22
I0619 14:56:42.386606 17898 net.cpp:91] Creating Layer Scale22
I0619 14:56:42.386629 17898 net.cpp:425] Scale22 <- Convolution22
I0619 14:56:42.386639 17898 net.cpp:386] Scale22 -> Convolution22 (in-place)
I0619 14:56:42.386708 17898 layer_factory.hpp:77] Creating layer Scale22
I0619 14:56:42.386905 17898 net.cpp:141] Setting up Scale22
I0619 14:56:42.386917 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.386924 17898 net.cpp:156] Memory required for data: 999818752
I0619 14:56:42.386934 17898 layer_factory.hpp:77] Creating layer ReLU22
I0619 14:56:42.386943 17898 net.cpp:91] Creating Layer ReLU22
I0619 14:56:42.386950 17898 net.cpp:425] ReLU22 <- Convolution22
I0619 14:56:42.386961 17898 net.cpp:386] ReLU22 -> Convolution22 (in-place)
I0619 14:56:42.386972 17898 net.cpp:141] Setting up ReLU22
I0619 14:56:42.386981 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.386987 17898 net.cpp:156] Memory required for data: 1008207360
I0619 14:56:42.386993 17898 layer_factory.hpp:77] Creating layer Convolution23
I0619 14:56:42.387009 17898 net.cpp:91] Creating Layer Convolution23
I0619 14:56:42.387015 17898 net.cpp:425] Convolution23 <- Convolution22
I0619 14:56:42.387027 17898 net.cpp:399] Convolution23 -> Convolution23
I0619 14:56:42.387650 17898 net.cpp:141] Setting up Convolution23
I0619 14:56:42.387666 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.387672 17898 net.cpp:156] Memory required for data: 1016595968
I0619 14:56:42.387684 17898 layer_factory.hpp:77] Creating layer BatchNorm23
I0619 14:56:42.387696 17898 net.cpp:91] Creating Layer BatchNorm23
I0619 14:56:42.387702 17898 net.cpp:425] BatchNorm23 <- Convolution23
I0619 14:56:42.387714 17898 net.cpp:386] BatchNorm23 -> Convolution23 (in-place)
I0619 14:56:42.388047 17898 net.cpp:141] Setting up BatchNorm23
I0619 14:56:42.388059 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.388065 17898 net.cpp:156] Memory required for data: 1024984576
I0619 14:56:42.388078 17898 layer_factory.hpp:77] Creating layer Scale23
I0619 14:56:42.388092 17898 net.cpp:91] Creating Layer Scale23
I0619 14:56:42.388099 17898 net.cpp:425] Scale23 <- Convolution23
I0619 14:56:42.388108 17898 net.cpp:386] Scale23 -> Convolution23 (in-place)
I0619 14:56:42.388164 17898 layer_factory.hpp:77] Creating layer Scale23
I0619 14:56:42.388377 17898 net.cpp:141] Setting up Scale23
I0619 14:56:42.388391 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.388397 17898 net.cpp:156] Memory required for data: 1033373184
I0619 14:56:42.388407 17898 layer_factory.hpp:77] Creating layer Eltwise11
I0619 14:56:42.388417 17898 net.cpp:91] Creating Layer Eltwise11
I0619 14:56:42.388424 17898 net.cpp:425] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0619 14:56:42.388432 17898 net.cpp:425] Eltwise11 <- Convolution23
I0619 14:56:42.388444 17898 net.cpp:399] Eltwise11 -> Eltwise11
I0619 14:56:42.388487 17898 net.cpp:141] Setting up Eltwise11
I0619 14:56:42.388499 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.388504 17898 net.cpp:156] Memory required for data: 1041761792
I0619 14:56:42.388509 17898 layer_factory.hpp:77] Creating layer ReLU23
I0619 14:56:42.388519 17898 net.cpp:91] Creating Layer ReLU23
I0619 14:56:42.388525 17898 net.cpp:425] ReLU23 <- Eltwise11
I0619 14:56:42.388533 17898 net.cpp:386] ReLU23 -> Eltwise11 (in-place)
I0619 14:56:42.388543 17898 net.cpp:141] Setting up ReLU23
I0619 14:56:42.388551 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.388557 17898 net.cpp:156] Memory required for data: 1050150400
I0619 14:56:42.388563 17898 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0619 14:56:42.388572 17898 net.cpp:91] Creating Layer Eltwise11_ReLU23_0_split
I0619 14:56:42.388578 17898 net.cpp:425] Eltwise11_ReLU23_0_split <- Eltwise11
I0619 14:56:42.388591 17898 net.cpp:399] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0619 14:56:42.388602 17898 net.cpp:399] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0619 14:56:42.388681 17898 net.cpp:141] Setting up Eltwise11_ReLU23_0_split
I0619 14:56:42.388710 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.388720 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.388725 17898 net.cpp:156] Memory required for data: 1066927616
I0619 14:56:42.388731 17898 layer_factory.hpp:77] Creating layer Convolution24
I0619 14:56:42.388746 17898 net.cpp:91] Creating Layer Convolution24
I0619 14:56:42.388752 17898 net.cpp:425] Convolution24 <- Eltwise11_ReLU23_0_split_0
I0619 14:56:42.388763 17898 net.cpp:399] Convolution24 -> Convolution24
I0619 14:56:42.389313 17898 net.cpp:141] Setting up Convolution24
I0619 14:56:42.389328 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.389333 17898 net.cpp:156] Memory required for data: 1075316224
I0619 14:56:42.389344 17898 layer_factory.hpp:77] Creating layer BatchNorm24
I0619 14:56:42.389356 17898 net.cpp:91] Creating Layer BatchNorm24
I0619 14:56:42.389364 17898 net.cpp:425] BatchNorm24 <- Convolution24
I0619 14:56:42.389374 17898 net.cpp:386] BatchNorm24 -> Convolution24 (in-place)
I0619 14:56:42.389719 17898 net.cpp:141] Setting up BatchNorm24
I0619 14:56:42.389729 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.389735 17898 net.cpp:156] Memory required for data: 1083704832
I0619 14:56:42.389749 17898 layer_factory.hpp:77] Creating layer Scale24
I0619 14:56:42.389762 17898 net.cpp:91] Creating Layer Scale24
I0619 14:56:42.389770 17898 net.cpp:425] Scale24 <- Convolution24
I0619 14:56:42.389780 17898 net.cpp:386] Scale24 -> Convolution24 (in-place)
I0619 14:56:42.389838 17898 layer_factory.hpp:77] Creating layer Scale24
I0619 14:56:42.390033 17898 net.cpp:141] Setting up Scale24
I0619 14:56:42.390045 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.390053 17898 net.cpp:156] Memory required for data: 1092093440
I0619 14:56:42.390064 17898 layer_factory.hpp:77] Creating layer ReLU24
I0619 14:56:42.390074 17898 net.cpp:91] Creating Layer ReLU24
I0619 14:56:42.390080 17898 net.cpp:425] ReLU24 <- Convolution24
I0619 14:56:42.390091 17898 net.cpp:386] ReLU24 -> Convolution24 (in-place)
I0619 14:56:42.390102 17898 net.cpp:141] Setting up ReLU24
I0619 14:56:42.390110 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.390116 17898 net.cpp:156] Memory required for data: 1100482048
I0619 14:56:42.390122 17898 layer_factory.hpp:77] Creating layer Convolution25
I0619 14:56:42.390137 17898 net.cpp:91] Creating Layer Convolution25
I0619 14:56:42.390144 17898 net.cpp:425] Convolution25 <- Convolution24
I0619 14:56:42.390154 17898 net.cpp:399] Convolution25 -> Convolution25
I0619 14:56:42.390702 17898 net.cpp:141] Setting up Convolution25
I0619 14:56:42.390717 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.390722 17898 net.cpp:156] Memory required for data: 1108870656
I0619 14:56:42.390734 17898 layer_factory.hpp:77] Creating layer BatchNorm25
I0619 14:56:42.390748 17898 net.cpp:91] Creating Layer BatchNorm25
I0619 14:56:42.390754 17898 net.cpp:425] BatchNorm25 <- Convolution25
I0619 14:56:42.390763 17898 net.cpp:386] BatchNorm25 -> Convolution25 (in-place)
I0619 14:56:42.391100 17898 net.cpp:141] Setting up BatchNorm25
I0619 14:56:42.391111 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.391118 17898 net.cpp:156] Memory required for data: 1117259264
I0619 14:56:42.391130 17898 layer_factory.hpp:77] Creating layer Scale25
I0619 14:56:42.391144 17898 net.cpp:91] Creating Layer Scale25
I0619 14:56:42.391150 17898 net.cpp:425] Scale25 <- Convolution25
I0619 14:56:42.391160 17898 net.cpp:386] Scale25 -> Convolution25 (in-place)
I0619 14:56:42.391219 17898 layer_factory.hpp:77] Creating layer Scale25
I0619 14:56:42.391418 17898 net.cpp:141] Setting up Scale25
I0619 14:56:42.391430 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.391435 17898 net.cpp:156] Memory required for data: 1125647872
I0619 14:56:42.391446 17898 layer_factory.hpp:77] Creating layer Eltwise12
I0619 14:56:42.391456 17898 net.cpp:91] Creating Layer Eltwise12
I0619 14:56:42.391470 17898 net.cpp:425] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0619 14:56:42.391495 17898 net.cpp:425] Eltwise12 <- Convolution25
I0619 14:56:42.391510 17898 net.cpp:399] Eltwise12 -> Eltwise12
I0619 14:56:42.391561 17898 net.cpp:141] Setting up Eltwise12
I0619 14:56:42.391573 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.391579 17898 net.cpp:156] Memory required for data: 1134036480
I0619 14:56:42.391585 17898 layer_factory.hpp:77] Creating layer ReLU25
I0619 14:56:42.391611 17898 net.cpp:91] Creating Layer ReLU25
I0619 14:56:42.391618 17898 net.cpp:425] ReLU25 <- Eltwise12
I0619 14:56:42.391628 17898 net.cpp:386] ReLU25 -> Eltwise12 (in-place)
I0619 14:56:42.391639 17898 net.cpp:141] Setting up ReLU25
I0619 14:56:42.391647 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.391654 17898 net.cpp:156] Memory required for data: 1142425088
I0619 14:56:42.391659 17898 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I0619 14:56:42.391669 17898 net.cpp:91] Creating Layer Eltwise12_ReLU25_0_split
I0619 14:56:42.391674 17898 net.cpp:425] Eltwise12_ReLU25_0_split <- Eltwise12
I0619 14:56:42.391683 17898 net.cpp:399] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I0619 14:56:42.391695 17898 net.cpp:399] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I0619 14:56:42.391755 17898 net.cpp:141] Setting up Eltwise12_ReLU25_0_split
I0619 14:56:42.391765 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.391772 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.391778 17898 net.cpp:156] Memory required for data: 1159202304
I0619 14:56:42.391784 17898 layer_factory.hpp:77] Creating layer Convolution26
I0619 14:56:42.391800 17898 net.cpp:91] Creating Layer Convolution26
I0619 14:56:42.391808 17898 net.cpp:425] Convolution26 <- Eltwise12_ReLU25_0_split_0
I0619 14:56:42.391819 17898 net.cpp:399] Convolution26 -> Convolution26
I0619 14:56:42.392350 17898 net.cpp:141] Setting up Convolution26
I0619 14:56:42.392364 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.392370 17898 net.cpp:156] Memory required for data: 1167590912
I0619 14:56:42.392381 17898 layer_factory.hpp:77] Creating layer BatchNorm26
I0619 14:56:42.392416 17898 net.cpp:91] Creating Layer BatchNorm26
I0619 14:56:42.392423 17898 net.cpp:425] BatchNorm26 <- Convolution26
I0619 14:56:42.392432 17898 net.cpp:386] BatchNorm26 -> Convolution26 (in-place)
I0619 14:56:42.392771 17898 net.cpp:141] Setting up BatchNorm26
I0619 14:56:42.392783 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.392789 17898 net.cpp:156] Memory required for data: 1175979520
I0619 14:56:42.392803 17898 layer_factory.hpp:77] Creating layer Scale26
I0619 14:56:42.392813 17898 net.cpp:91] Creating Layer Scale26
I0619 14:56:42.392820 17898 net.cpp:425] Scale26 <- Convolution26
I0619 14:56:42.392829 17898 net.cpp:386] Scale26 -> Convolution26 (in-place)
I0619 14:56:42.392889 17898 layer_factory.hpp:77] Creating layer Scale26
I0619 14:56:42.393084 17898 net.cpp:141] Setting up Scale26
I0619 14:56:42.393095 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.393101 17898 net.cpp:156] Memory required for data: 1184368128
I0619 14:56:42.393112 17898 layer_factory.hpp:77] Creating layer ReLU26
I0619 14:56:42.393123 17898 net.cpp:91] Creating Layer ReLU26
I0619 14:56:42.393131 17898 net.cpp:425] ReLU26 <- Convolution26
I0619 14:56:42.393138 17898 net.cpp:386] ReLU26 -> Convolution26 (in-place)
I0619 14:56:42.393148 17898 net.cpp:141] Setting up ReLU26
I0619 14:56:42.393157 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.393162 17898 net.cpp:156] Memory required for data: 1192756736
I0619 14:56:42.393168 17898 layer_factory.hpp:77] Creating layer Convolution27
I0619 14:56:42.393185 17898 net.cpp:91] Creating Layer Convolution27
I0619 14:56:42.393193 17898 net.cpp:425] Convolution27 <- Convolution26
I0619 14:56:42.393203 17898 net.cpp:399] Convolution27 -> Convolution27
I0619 14:56:42.393734 17898 net.cpp:141] Setting up Convolution27
I0619 14:56:42.393753 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.393776 17898 net.cpp:156] Memory required for data: 1201145344
I0619 14:56:42.393788 17898 layer_factory.hpp:77] Creating layer BatchNorm27
I0619 14:56:42.393801 17898 net.cpp:91] Creating Layer BatchNorm27
I0619 14:56:42.393808 17898 net.cpp:425] BatchNorm27 <- Convolution27
I0619 14:56:42.393817 17898 net.cpp:386] BatchNorm27 -> Convolution27 (in-place)
I0619 14:56:42.394168 17898 net.cpp:141] Setting up BatchNorm27
I0619 14:56:42.394181 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.394187 17898 net.cpp:156] Memory required for data: 1209533952
I0619 14:56:42.394202 17898 layer_factory.hpp:77] Creating layer Scale27
I0619 14:56:42.394212 17898 net.cpp:91] Creating Layer Scale27
I0619 14:56:42.394219 17898 net.cpp:425] Scale27 <- Convolution27
I0619 14:56:42.394229 17898 net.cpp:386] Scale27 -> Convolution27 (in-place)
I0619 14:56:42.394289 17898 layer_factory.hpp:77] Creating layer Scale27
I0619 14:56:42.395272 17898 net.cpp:141] Setting up Scale27
I0619 14:56:42.395292 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.395298 17898 net.cpp:156] Memory required for data: 1217922560
I0619 14:56:42.395310 17898 layer_factory.hpp:77] Creating layer Eltwise13
I0619 14:56:42.395320 17898 net.cpp:91] Creating Layer Eltwise13
I0619 14:56:42.395328 17898 net.cpp:425] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I0619 14:56:42.395337 17898 net.cpp:425] Eltwise13 <- Convolution27
I0619 14:56:42.395349 17898 net.cpp:399] Eltwise13 -> Eltwise13
I0619 14:56:42.395391 17898 net.cpp:141] Setting up Eltwise13
I0619 14:56:42.395401 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.395406 17898 net.cpp:156] Memory required for data: 1226311168
I0619 14:56:42.395412 17898 layer_factory.hpp:77] Creating layer ReLU27
I0619 14:56:42.395424 17898 net.cpp:91] Creating Layer ReLU27
I0619 14:56:42.395431 17898 net.cpp:425] ReLU27 <- Eltwise13
I0619 14:56:42.395438 17898 net.cpp:386] ReLU27 -> Eltwise13 (in-place)
I0619 14:56:42.395448 17898 net.cpp:141] Setting up ReLU27
I0619 14:56:42.395457 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.395462 17898 net.cpp:156] Memory required for data: 1234699776
I0619 14:56:42.395467 17898 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I0619 14:56:42.395475 17898 net.cpp:91] Creating Layer Eltwise13_ReLU27_0_split
I0619 14:56:42.395481 17898 net.cpp:425] Eltwise13_ReLU27_0_split <- Eltwise13
I0619 14:56:42.395489 17898 net.cpp:399] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I0619 14:56:42.395500 17898 net.cpp:399] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I0619 14:56:42.395560 17898 net.cpp:141] Setting up Eltwise13_ReLU27_0_split
I0619 14:56:42.395570 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.395577 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.395582 17898 net.cpp:156] Memory required for data: 1251476992
I0619 14:56:42.395588 17898 layer_factory.hpp:77] Creating layer Convolution28
I0619 14:56:42.395603 17898 net.cpp:91] Creating Layer Convolution28
I0619 14:56:42.395611 17898 net.cpp:425] Convolution28 <- Eltwise13_ReLU27_0_split_0
I0619 14:56:42.395622 17898 net.cpp:399] Convolution28 -> Convolution28
I0619 14:56:42.396127 17898 net.cpp:141] Setting up Convolution28
I0619 14:56:42.396142 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.396147 17898 net.cpp:156] Memory required for data: 1259865600
I0619 14:56:42.396157 17898 layer_factory.hpp:77] Creating layer BatchNorm28
I0619 14:56:42.396167 17898 net.cpp:91] Creating Layer BatchNorm28
I0619 14:56:42.396173 17898 net.cpp:425] BatchNorm28 <- Convolution28
I0619 14:56:42.396185 17898 net.cpp:386] BatchNorm28 -> Convolution28 (in-place)
I0619 14:56:42.396505 17898 net.cpp:141] Setting up BatchNorm28
I0619 14:56:42.396515 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.396522 17898 net.cpp:156] Memory required for data: 1268254208
I0619 14:56:42.396534 17898 layer_factory.hpp:77] Creating layer Scale28
I0619 14:56:42.396564 17898 net.cpp:91] Creating Layer Scale28
I0619 14:56:42.396572 17898 net.cpp:425] Scale28 <- Convolution28
I0619 14:56:42.396584 17898 net.cpp:386] Scale28 -> Convolution28 (in-place)
I0619 14:56:42.396651 17898 layer_factory.hpp:77] Creating layer Scale28
I0619 14:56:42.396834 17898 net.cpp:141] Setting up Scale28
I0619 14:56:42.396847 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.396852 17898 net.cpp:156] Memory required for data: 1276642816
I0619 14:56:42.396862 17898 layer_factory.hpp:77] Creating layer ReLU28
I0619 14:56:42.396872 17898 net.cpp:91] Creating Layer ReLU28
I0619 14:56:42.396878 17898 net.cpp:425] ReLU28 <- Convolution28
I0619 14:56:42.396888 17898 net.cpp:386] ReLU28 -> Convolution28 (in-place)
I0619 14:56:42.396898 17898 net.cpp:141] Setting up ReLU28
I0619 14:56:42.396908 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.396913 17898 net.cpp:156] Memory required for data: 1285031424
I0619 14:56:42.396917 17898 layer_factory.hpp:77] Creating layer Convolution29
I0619 14:56:42.396934 17898 net.cpp:91] Creating Layer Convolution29
I0619 14:56:42.396940 17898 net.cpp:425] Convolution29 <- Convolution28
I0619 14:56:42.396952 17898 net.cpp:399] Convolution29 -> Convolution29
I0619 14:56:42.397475 17898 net.cpp:141] Setting up Convolution29
I0619 14:56:42.397490 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.397495 17898 net.cpp:156] Memory required for data: 1293420032
I0619 14:56:42.397505 17898 layer_factory.hpp:77] Creating layer BatchNorm29
I0619 14:56:42.397516 17898 net.cpp:91] Creating Layer BatchNorm29
I0619 14:56:42.397524 17898 net.cpp:425] BatchNorm29 <- Convolution29
I0619 14:56:42.397536 17898 net.cpp:386] BatchNorm29 -> Convolution29 (in-place)
I0619 14:56:42.397861 17898 net.cpp:141] Setting up BatchNorm29
I0619 14:56:42.397872 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.397877 17898 net.cpp:156] Memory required for data: 1301808640
I0619 14:56:42.397889 17898 layer_factory.hpp:77] Creating layer Scale29
I0619 14:56:42.397899 17898 net.cpp:91] Creating Layer Scale29
I0619 14:56:42.397907 17898 net.cpp:425] Scale29 <- Convolution29
I0619 14:56:42.397914 17898 net.cpp:386] Scale29 -> Convolution29 (in-place)
I0619 14:56:42.397967 17898 layer_factory.hpp:77] Creating layer Scale29
I0619 14:56:42.398149 17898 net.cpp:141] Setting up Scale29
I0619 14:56:42.398160 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.398166 17898 net.cpp:156] Memory required for data: 1310197248
I0619 14:56:42.398175 17898 layer_factory.hpp:77] Creating layer Eltwise14
I0619 14:56:42.398185 17898 net.cpp:91] Creating Layer Eltwise14
I0619 14:56:42.398191 17898 net.cpp:425] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I0619 14:56:42.398200 17898 net.cpp:425] Eltwise14 <- Convolution29
I0619 14:56:42.398211 17898 net.cpp:399] Eltwise14 -> Eltwise14
I0619 14:56:42.398247 17898 net.cpp:141] Setting up Eltwise14
I0619 14:56:42.398257 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.398262 17898 net.cpp:156] Memory required for data: 1318585856
I0619 14:56:42.398267 17898 layer_factory.hpp:77] Creating layer ReLU29
I0619 14:56:42.398278 17898 net.cpp:91] Creating Layer ReLU29
I0619 14:56:42.398285 17898 net.cpp:425] ReLU29 <- Eltwise14
I0619 14:56:42.398293 17898 net.cpp:386] ReLU29 -> Eltwise14 (in-place)
I0619 14:56:42.398303 17898 net.cpp:141] Setting up ReLU29
I0619 14:56:42.398311 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.398316 17898 net.cpp:156] Memory required for data: 1326974464
I0619 14:56:42.398322 17898 layer_factory.hpp:77] Creating layer Eltwise14_ReLU29_0_split
I0619 14:56:42.398332 17898 net.cpp:91] Creating Layer Eltwise14_ReLU29_0_split
I0619 14:56:42.398339 17898 net.cpp:425] Eltwise14_ReLU29_0_split <- Eltwise14
I0619 14:56:42.398346 17898 net.cpp:399] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_0
I0619 14:56:42.398368 17898 net.cpp:399] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_1
I0619 14:56:42.398432 17898 net.cpp:141] Setting up Eltwise14_ReLU29_0_split
I0619 14:56:42.398460 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.398468 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.398473 17898 net.cpp:156] Memory required for data: 1343751680
I0619 14:56:42.398479 17898 layer_factory.hpp:77] Creating layer Convolution30
I0619 14:56:42.398495 17898 net.cpp:91] Creating Layer Convolution30
I0619 14:56:42.398502 17898 net.cpp:425] Convolution30 <- Eltwise14_ReLU29_0_split_0
I0619 14:56:42.398514 17898 net.cpp:399] Convolution30 -> Convolution30
I0619 14:56:42.399015 17898 net.cpp:141] Setting up Convolution30
I0619 14:56:42.399029 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.399034 17898 net.cpp:156] Memory required for data: 1352140288
I0619 14:56:42.399045 17898 layer_factory.hpp:77] Creating layer BatchNorm30
I0619 14:56:42.399058 17898 net.cpp:91] Creating Layer BatchNorm30
I0619 14:56:42.399065 17898 net.cpp:425] BatchNorm30 <- Convolution30
I0619 14:56:42.399078 17898 net.cpp:386] BatchNorm30 -> Convolution30 (in-place)
I0619 14:56:42.399390 17898 net.cpp:141] Setting up BatchNorm30
I0619 14:56:42.399401 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.399406 17898 net.cpp:156] Memory required for data: 1360528896
I0619 14:56:42.399420 17898 layer_factory.hpp:77] Creating layer Scale30
I0619 14:56:42.399430 17898 net.cpp:91] Creating Layer Scale30
I0619 14:56:42.399435 17898 net.cpp:425] Scale30 <- Convolution30
I0619 14:56:42.399444 17898 net.cpp:386] Scale30 -> Convolution30 (in-place)
I0619 14:56:42.399500 17898 layer_factory.hpp:77] Creating layer Scale30
I0619 14:56:42.399682 17898 net.cpp:141] Setting up Scale30
I0619 14:56:42.399694 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.399699 17898 net.cpp:156] Memory required for data: 1368917504
I0619 14:56:42.399710 17898 layer_factory.hpp:77] Creating layer ReLU30
I0619 14:56:42.399718 17898 net.cpp:91] Creating Layer ReLU30
I0619 14:56:42.399725 17898 net.cpp:425] ReLU30 <- Convolution30
I0619 14:56:42.399739 17898 net.cpp:386] ReLU30 -> Convolution30 (in-place)
I0619 14:56:42.399749 17898 net.cpp:141] Setting up ReLU30
I0619 14:56:42.399756 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.399761 17898 net.cpp:156] Memory required for data: 1377306112
I0619 14:56:42.399766 17898 layer_factory.hpp:77] Creating layer Convolution31
I0619 14:56:42.399780 17898 net.cpp:91] Creating Layer Convolution31
I0619 14:56:42.399785 17898 net.cpp:425] Convolution31 <- Convolution30
I0619 14:56:42.399797 17898 net.cpp:399] Convolution31 -> Convolution31
I0619 14:56:42.400295 17898 net.cpp:141] Setting up Convolution31
I0619 14:56:42.400307 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.400312 17898 net.cpp:156] Memory required for data: 1385694720
I0619 14:56:42.400322 17898 layer_factory.hpp:77] Creating layer BatchNorm31
I0619 14:56:42.400332 17898 net.cpp:91] Creating Layer BatchNorm31
I0619 14:56:42.400338 17898 net.cpp:425] BatchNorm31 <- Convolution31
I0619 14:56:42.400349 17898 net.cpp:386] BatchNorm31 -> Convolution31 (in-place)
I0619 14:56:42.400660 17898 net.cpp:141] Setting up BatchNorm31
I0619 14:56:42.400671 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.400676 17898 net.cpp:156] Memory required for data: 1394083328
I0619 14:56:42.400688 17898 layer_factory.hpp:77] Creating layer Scale31
I0619 14:56:42.400698 17898 net.cpp:91] Creating Layer Scale31
I0619 14:56:42.400704 17898 net.cpp:425] Scale31 <- Convolution31
I0619 14:56:42.400712 17898 net.cpp:386] Scale31 -> Convolution31 (in-place)
I0619 14:56:42.400766 17898 layer_factory.hpp:77] Creating layer Scale31
I0619 14:56:42.400941 17898 net.cpp:141] Setting up Scale31
I0619 14:56:42.400952 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.400959 17898 net.cpp:156] Memory required for data: 1402471936
I0619 14:56:42.400969 17898 layer_factory.hpp:77] Creating layer Eltwise15
I0619 14:56:42.400977 17898 net.cpp:91] Creating Layer Eltwise15
I0619 14:56:42.401001 17898 net.cpp:425] Eltwise15 <- Eltwise14_ReLU29_0_split_1
I0619 14:56:42.401010 17898 net.cpp:425] Eltwise15 <- Convolution31
I0619 14:56:42.401023 17898 net.cpp:399] Eltwise15 -> Eltwise15
I0619 14:56:42.401062 17898 net.cpp:141] Setting up Eltwise15
I0619 14:56:42.401072 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.401077 17898 net.cpp:156] Memory required for data: 1410860544
I0619 14:56:42.401083 17898 layer_factory.hpp:77] Creating layer ReLU31
I0619 14:56:42.401094 17898 net.cpp:91] Creating Layer ReLU31
I0619 14:56:42.401101 17898 net.cpp:425] ReLU31 <- Eltwise15
I0619 14:56:42.401109 17898 net.cpp:386] ReLU31 -> Eltwise15 (in-place)
I0619 14:56:42.401118 17898 net.cpp:141] Setting up ReLU31
I0619 14:56:42.401125 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.401131 17898 net.cpp:156] Memory required for data: 1419249152
I0619 14:56:42.401137 17898 layer_factory.hpp:77] Creating layer Eltwise15_ReLU31_0_split
I0619 14:56:42.401145 17898 net.cpp:91] Creating Layer Eltwise15_ReLU31_0_split
I0619 14:56:42.401151 17898 net.cpp:425] Eltwise15_ReLU31_0_split <- Eltwise15
I0619 14:56:42.401165 17898 net.cpp:399] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_0
I0619 14:56:42.401176 17898 net.cpp:399] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_1
I0619 14:56:42.401234 17898 net.cpp:141] Setting up Eltwise15_ReLU31_0_split
I0619 14:56:42.401244 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.401252 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.401257 17898 net.cpp:156] Memory required for data: 1436026368
I0619 14:56:42.401263 17898 layer_factory.hpp:77] Creating layer Convolution32
I0619 14:56:42.401278 17898 net.cpp:91] Creating Layer Convolution32
I0619 14:56:42.401285 17898 net.cpp:425] Convolution32 <- Eltwise15_ReLU31_0_split_0
I0619 14:56:42.401295 17898 net.cpp:399] Convolution32 -> Convolution32
I0619 14:56:42.401788 17898 net.cpp:141] Setting up Convolution32
I0619 14:56:42.401800 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.401806 17898 net.cpp:156] Memory required for data: 1444414976
I0619 14:56:42.401816 17898 layer_factory.hpp:77] Creating layer BatchNorm32
I0619 14:56:42.401825 17898 net.cpp:91] Creating Layer BatchNorm32
I0619 14:56:42.401832 17898 net.cpp:425] BatchNorm32 <- Convolution32
I0619 14:56:42.401844 17898 net.cpp:386] BatchNorm32 -> Convolution32 (in-place)
I0619 14:56:42.402159 17898 net.cpp:141] Setting up BatchNorm32
I0619 14:56:42.402170 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.402176 17898 net.cpp:156] Memory required for data: 1452803584
I0619 14:56:42.402189 17898 layer_factory.hpp:77] Creating layer Scale32
I0619 14:56:42.402200 17898 net.cpp:91] Creating Layer Scale32
I0619 14:56:42.402207 17898 net.cpp:425] Scale32 <- Convolution32
I0619 14:56:42.402215 17898 net.cpp:386] Scale32 -> Convolution32 (in-place)
I0619 14:56:42.402271 17898 layer_factory.hpp:77] Creating layer Scale32
I0619 14:56:42.402456 17898 net.cpp:141] Setting up Scale32
I0619 14:56:42.402468 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.402473 17898 net.cpp:156] Memory required for data: 1461192192
I0619 14:56:42.402483 17898 layer_factory.hpp:77] Creating layer ReLU32
I0619 14:56:42.402493 17898 net.cpp:91] Creating Layer ReLU32
I0619 14:56:42.402498 17898 net.cpp:425] ReLU32 <- Convolution32
I0619 14:56:42.402509 17898 net.cpp:386] ReLU32 -> Convolution32 (in-place)
I0619 14:56:42.402518 17898 net.cpp:141] Setting up ReLU32
I0619 14:56:42.402526 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.402531 17898 net.cpp:156] Memory required for data: 1469580800
I0619 14:56:42.402537 17898 layer_factory.hpp:77] Creating layer Convolution33
I0619 14:56:42.402549 17898 net.cpp:91] Creating Layer Convolution33
I0619 14:56:42.402555 17898 net.cpp:425] Convolution33 <- Convolution32
I0619 14:56:42.402567 17898 net.cpp:399] Convolution33 -> Convolution33
I0619 14:56:42.403062 17898 net.cpp:141] Setting up Convolution33
I0619 14:56:42.403096 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.403102 17898 net.cpp:156] Memory required for data: 1477969408
I0619 14:56:42.403113 17898 layer_factory.hpp:77] Creating layer BatchNorm33
I0619 14:56:42.403122 17898 net.cpp:91] Creating Layer BatchNorm33
I0619 14:56:42.403129 17898 net.cpp:425] BatchNorm33 <- Convolution33
I0619 14:56:42.403137 17898 net.cpp:386] BatchNorm33 -> Convolution33 (in-place)
I0619 14:56:42.403447 17898 net.cpp:141] Setting up BatchNorm33
I0619 14:56:42.403458 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.403465 17898 net.cpp:156] Memory required for data: 1486358016
I0619 14:56:42.403476 17898 layer_factory.hpp:77] Creating layer Scale33
I0619 14:56:42.403486 17898 net.cpp:91] Creating Layer Scale33
I0619 14:56:42.403492 17898 net.cpp:425] Scale33 <- Convolution33
I0619 14:56:42.403501 17898 net.cpp:386] Scale33 -> Convolution33 (in-place)
I0619 14:56:42.403555 17898 layer_factory.hpp:77] Creating layer Scale33
I0619 14:56:42.403738 17898 net.cpp:141] Setting up Scale33
I0619 14:56:42.403749 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.403754 17898 net.cpp:156] Memory required for data: 1494746624
I0619 14:56:42.403764 17898 layer_factory.hpp:77] Creating layer Eltwise16
I0619 14:56:42.403775 17898 net.cpp:91] Creating Layer Eltwise16
I0619 14:56:42.403782 17898 net.cpp:425] Eltwise16 <- Eltwise15_ReLU31_0_split_1
I0619 14:56:42.403790 17898 net.cpp:425] Eltwise16 <- Convolution33
I0619 14:56:42.403800 17898 net.cpp:399] Eltwise16 -> Eltwise16
I0619 14:56:42.403837 17898 net.cpp:141] Setting up Eltwise16
I0619 14:56:42.403846 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.403851 17898 net.cpp:156] Memory required for data: 1503135232
I0619 14:56:42.403857 17898 layer_factory.hpp:77] Creating layer ReLU33
I0619 14:56:42.403866 17898 net.cpp:91] Creating Layer ReLU33
I0619 14:56:42.403872 17898 net.cpp:425] ReLU33 <- Eltwise16
I0619 14:56:42.403882 17898 net.cpp:386] ReLU33 -> Eltwise16 (in-place)
I0619 14:56:42.403892 17898 net.cpp:141] Setting up ReLU33
I0619 14:56:42.403900 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.403905 17898 net.cpp:156] Memory required for data: 1511523840
I0619 14:56:42.403911 17898 layer_factory.hpp:77] Creating layer Eltwise16_ReLU33_0_split
I0619 14:56:42.403919 17898 net.cpp:91] Creating Layer Eltwise16_ReLU33_0_split
I0619 14:56:42.403924 17898 net.cpp:425] Eltwise16_ReLU33_0_split <- Eltwise16
I0619 14:56:42.403934 17898 net.cpp:399] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_0
I0619 14:56:42.403945 17898 net.cpp:399] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_1
I0619 14:56:42.404000 17898 net.cpp:141] Setting up Eltwise16_ReLU33_0_split
I0619 14:56:42.404009 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.404016 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.404022 17898 net.cpp:156] Memory required for data: 1528301056
I0619 14:56:42.404028 17898 layer_factory.hpp:77] Creating layer Convolution34
I0619 14:56:42.404041 17898 net.cpp:91] Creating Layer Convolution34
I0619 14:56:42.404047 17898 net.cpp:425] Convolution34 <- Eltwise16_ReLU33_0_split_0
I0619 14:56:42.404059 17898 net.cpp:399] Convolution34 -> Convolution34
I0619 14:56:42.404551 17898 net.cpp:141] Setting up Convolution34
I0619 14:56:42.404563 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.404569 17898 net.cpp:156] Memory required for data: 1536689664
I0619 14:56:42.404579 17898 layer_factory.hpp:77] Creating layer BatchNorm34
I0619 14:56:42.404588 17898 net.cpp:91] Creating Layer BatchNorm34
I0619 14:56:42.404594 17898 net.cpp:425] BatchNorm34 <- Convolution34
I0619 14:56:42.404606 17898 net.cpp:386] BatchNorm34 -> Convolution34 (in-place)
I0619 14:56:42.404919 17898 net.cpp:141] Setting up BatchNorm34
I0619 14:56:42.404930 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.404937 17898 net.cpp:156] Memory required for data: 1545078272
I0619 14:56:42.404952 17898 layer_factory.hpp:77] Creating layer Scale34
I0619 14:56:42.404975 17898 net.cpp:91] Creating Layer Scale34
I0619 14:56:42.404983 17898 net.cpp:425] Scale34 <- Convolution34
I0619 14:56:42.404991 17898 net.cpp:386] Scale34 -> Convolution34 (in-place)
I0619 14:56:42.405052 17898 layer_factory.hpp:77] Creating layer Scale34
I0619 14:56:42.405235 17898 net.cpp:141] Setting up Scale34
I0619 14:56:42.405246 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.405251 17898 net.cpp:156] Memory required for data: 1553466880
I0619 14:56:42.405261 17898 layer_factory.hpp:77] Creating layer ReLU34
I0619 14:56:42.405270 17898 net.cpp:91] Creating Layer ReLU34
I0619 14:56:42.405277 17898 net.cpp:425] ReLU34 <- Convolution34
I0619 14:56:42.405287 17898 net.cpp:386] ReLU34 -> Convolution34 (in-place)
I0619 14:56:42.405297 17898 net.cpp:141] Setting up ReLU34
I0619 14:56:42.405303 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.405309 17898 net.cpp:156] Memory required for data: 1561855488
I0619 14:56:42.405315 17898 layer_factory.hpp:77] Creating layer Convolution35
I0619 14:56:42.405328 17898 net.cpp:91] Creating Layer Convolution35
I0619 14:56:42.405333 17898 net.cpp:425] Convolution35 <- Convolution34
I0619 14:56:42.405345 17898 net.cpp:399] Convolution35 -> Convolution35
I0619 14:56:42.405856 17898 net.cpp:141] Setting up Convolution35
I0619 14:56:42.405870 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.405875 17898 net.cpp:156] Memory required for data: 1570244096
I0619 14:56:42.405885 17898 layer_factory.hpp:77] Creating layer BatchNorm35
I0619 14:56:42.405895 17898 net.cpp:91] Creating Layer BatchNorm35
I0619 14:56:42.405901 17898 net.cpp:425] BatchNorm35 <- Convolution35
I0619 14:56:42.405912 17898 net.cpp:386] BatchNorm35 -> Convolution35 (in-place)
I0619 14:56:42.406966 17898 net.cpp:141] Setting up BatchNorm35
I0619 14:56:42.406985 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.406991 17898 net.cpp:156] Memory required for data: 1578632704
I0619 14:56:42.407006 17898 layer_factory.hpp:77] Creating layer Scale35
I0619 14:56:42.407016 17898 net.cpp:91] Creating Layer Scale35
I0619 14:56:42.407022 17898 net.cpp:425] Scale35 <- Convolution35
I0619 14:56:42.407034 17898 net.cpp:386] Scale35 -> Convolution35 (in-place)
I0619 14:56:42.407088 17898 layer_factory.hpp:77] Creating layer Scale35
I0619 14:56:42.407254 17898 net.cpp:141] Setting up Scale35
I0619 14:56:42.407265 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.407270 17898 net.cpp:156] Memory required for data: 1587021312
I0619 14:56:42.407280 17898 layer_factory.hpp:77] Creating layer Eltwise17
I0619 14:56:42.407291 17898 net.cpp:91] Creating Layer Eltwise17
I0619 14:56:42.407297 17898 net.cpp:425] Eltwise17 <- Eltwise16_ReLU33_0_split_1
I0619 14:56:42.407305 17898 net.cpp:425] Eltwise17 <- Convolution35
I0619 14:56:42.407313 17898 net.cpp:399] Eltwise17 -> Eltwise17
I0619 14:56:42.407356 17898 net.cpp:141] Setting up Eltwise17
I0619 14:56:42.407366 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.407371 17898 net.cpp:156] Memory required for data: 1595409920
I0619 14:56:42.407376 17898 layer_factory.hpp:77] Creating layer ReLU35
I0619 14:56:42.407384 17898 net.cpp:91] Creating Layer ReLU35
I0619 14:56:42.407390 17898 net.cpp:425] ReLU35 <- Eltwise17
I0619 14:56:42.407399 17898 net.cpp:386] ReLU35 -> Eltwise17 (in-place)
I0619 14:56:42.407409 17898 net.cpp:141] Setting up ReLU35
I0619 14:56:42.407416 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.407421 17898 net.cpp:156] Memory required for data: 1603798528
I0619 14:56:42.407428 17898 layer_factory.hpp:77] Creating layer Eltwise17_ReLU35_0_split
I0619 14:56:42.407434 17898 net.cpp:91] Creating Layer Eltwise17_ReLU35_0_split
I0619 14:56:42.407439 17898 net.cpp:425] Eltwise17_ReLU35_0_split <- Eltwise17
I0619 14:56:42.407447 17898 net.cpp:399] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_0
I0619 14:56:42.407457 17898 net.cpp:399] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_1
I0619 14:56:42.407516 17898 net.cpp:141] Setting up Eltwise17_ReLU35_0_split
I0619 14:56:42.407541 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.407549 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.407554 17898 net.cpp:156] Memory required for data: 1620575744
I0619 14:56:42.407560 17898 layer_factory.hpp:77] Creating layer Convolution36
I0619 14:56:42.407578 17898 net.cpp:91] Creating Layer Convolution36
I0619 14:56:42.407585 17898 net.cpp:425] Convolution36 <- Eltwise17_ReLU35_0_split_0
I0619 14:56:42.407595 17898 net.cpp:399] Convolution36 -> Convolution36
I0619 14:56:42.408074 17898 net.cpp:141] Setting up Convolution36
I0619 14:56:42.408085 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.408092 17898 net.cpp:156] Memory required for data: 1628964352
I0619 14:56:42.408102 17898 layer_factory.hpp:77] Creating layer BatchNorm36
I0619 14:56:42.408113 17898 net.cpp:91] Creating Layer BatchNorm36
I0619 14:56:42.408119 17898 net.cpp:425] BatchNorm36 <- Convolution36
I0619 14:56:42.408128 17898 net.cpp:386] BatchNorm36 -> Convolution36 (in-place)
I0619 14:56:42.408414 17898 net.cpp:141] Setting up BatchNorm36
I0619 14:56:42.408424 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.408429 17898 net.cpp:156] Memory required for data: 1637352960
I0619 14:56:42.408440 17898 layer_factory.hpp:77] Creating layer Scale36
I0619 14:56:42.408449 17898 net.cpp:91] Creating Layer Scale36
I0619 14:56:42.408457 17898 net.cpp:425] Scale36 <- Convolution36
I0619 14:56:42.408466 17898 net.cpp:386] Scale36 -> Convolution36 (in-place)
I0619 14:56:42.408515 17898 layer_factory.hpp:77] Creating layer Scale36
I0619 14:56:42.408679 17898 net.cpp:141] Setting up Scale36
I0619 14:56:42.408692 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.408697 17898 net.cpp:156] Memory required for data: 1645741568
I0619 14:56:42.408706 17898 layer_factory.hpp:77] Creating layer ReLU36
I0619 14:56:42.408715 17898 net.cpp:91] Creating Layer ReLU36
I0619 14:56:42.408720 17898 net.cpp:425] ReLU36 <- Convolution36
I0619 14:56:42.408728 17898 net.cpp:386] ReLU36 -> Convolution36 (in-place)
I0619 14:56:42.408736 17898 net.cpp:141] Setting up ReLU36
I0619 14:56:42.408745 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.408749 17898 net.cpp:156] Memory required for data: 1654130176
I0619 14:56:42.408754 17898 layer_factory.hpp:77] Creating layer Convolution37
I0619 14:56:42.408768 17898 net.cpp:91] Creating Layer Convolution37
I0619 14:56:42.408774 17898 net.cpp:425] Convolution37 <- Convolution36
I0619 14:56:42.408785 17898 net.cpp:399] Convolution37 -> Convolution37
I0619 14:56:42.409247 17898 net.cpp:141] Setting up Convolution37
I0619 14:56:42.409260 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.409265 17898 net.cpp:156] Memory required for data: 1662518784
I0619 14:56:42.409273 17898 layer_factory.hpp:77] Creating layer BatchNorm37
I0619 14:56:42.409284 17898 net.cpp:91] Creating Layer BatchNorm37
I0619 14:56:42.409291 17898 net.cpp:425] BatchNorm37 <- Convolution37
I0619 14:56:42.409299 17898 net.cpp:386] BatchNorm37 -> Convolution37 (in-place)
I0619 14:56:42.409595 17898 net.cpp:141] Setting up BatchNorm37
I0619 14:56:42.409605 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.409610 17898 net.cpp:156] Memory required for data: 1670907392
I0619 14:56:42.409658 17898 layer_factory.hpp:77] Creating layer Scale37
I0619 14:56:42.409669 17898 net.cpp:91] Creating Layer Scale37
I0619 14:56:42.409677 17898 net.cpp:425] Scale37 <- Convolution37
I0619 14:56:42.409684 17898 net.cpp:386] Scale37 -> Convolution37 (in-place)
I0619 14:56:42.409740 17898 layer_factory.hpp:77] Creating layer Scale37
I0619 14:56:42.409906 17898 net.cpp:141] Setting up Scale37
I0619 14:56:42.409916 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.409921 17898 net.cpp:156] Memory required for data: 1679296000
I0619 14:56:42.409931 17898 layer_factory.hpp:77] Creating layer Eltwise18
I0619 14:56:42.409946 17898 net.cpp:91] Creating Layer Eltwise18
I0619 14:56:42.409966 17898 net.cpp:425] Eltwise18 <- Eltwise17_ReLU35_0_split_1
I0619 14:56:42.409976 17898 net.cpp:425] Eltwise18 <- Convolution37
I0619 14:56:42.409984 17898 net.cpp:399] Eltwise18 -> Eltwise18
I0619 14:56:42.410023 17898 net.cpp:141] Setting up Eltwise18
I0619 14:56:42.410033 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.410038 17898 net.cpp:156] Memory required for data: 1687684608
I0619 14:56:42.410043 17898 layer_factory.hpp:77] Creating layer ReLU37
I0619 14:56:42.410051 17898 net.cpp:91] Creating Layer ReLU37
I0619 14:56:42.410058 17898 net.cpp:425] ReLU37 <- Eltwise18
I0619 14:56:42.410068 17898 net.cpp:386] ReLU37 -> Eltwise18 (in-place)
I0619 14:56:42.410078 17898 net.cpp:141] Setting up ReLU37
I0619 14:56:42.410084 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.410089 17898 net.cpp:156] Memory required for data: 1696073216
I0619 14:56:42.410095 17898 layer_factory.hpp:77] Creating layer Eltwise18_ReLU37_0_split
I0619 14:56:42.410109 17898 net.cpp:91] Creating Layer Eltwise18_ReLU37_0_split
I0619 14:56:42.410114 17898 net.cpp:425] Eltwise18_ReLU37_0_split <- Eltwise18
I0619 14:56:42.410121 17898 net.cpp:399] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_0
I0619 14:56:42.410132 17898 net.cpp:399] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_1
I0619 14:56:42.410184 17898 net.cpp:141] Setting up Eltwise18_ReLU37_0_split
I0619 14:56:42.410194 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.410200 17898 net.cpp:148] Top shape: 128 16 32 32 (2097152)
I0619 14:56:42.410205 17898 net.cpp:156] Memory required for data: 1712850432
I0619 14:56:42.410212 17898 layer_factory.hpp:77] Creating layer Pooling1
I0619 14:56:42.410220 17898 net.cpp:91] Creating Layer Pooling1
I0619 14:56:42.410225 17898 net.cpp:425] Pooling1 <- Eltwise18_ReLU37_0_split_0
I0619 14:56:42.410234 17898 net.cpp:399] Pooling1 -> Pooling1
I0619 14:56:42.410269 17898 net.cpp:141] Setting up Pooling1
I0619 14:56:42.410279 17898 net.cpp:148] Top shape: 128 16 16 16 (524288)
I0619 14:56:42.410284 17898 net.cpp:156] Memory required for data: 1714947584
I0619 14:56:42.410289 17898 layer_factory.hpp:77] Creating layer Input1
I0619 14:56:42.410297 17898 net.cpp:91] Creating Layer Input1
I0619 14:56:42.410305 17898 net.cpp:399] Input1 -> Input1
I0619 14:56:42.410338 17898 net.cpp:141] Setting up Input1
I0619 14:56:42.410347 17898 net.cpp:148] Top shape: 128 16 16 16 (524288)
I0619 14:56:42.410352 17898 net.cpp:156] Memory required for data: 1717044736
I0619 14:56:42.410367 17898 layer_factory.hpp:77] Creating layer Concat1
I0619 14:56:42.410380 17898 net.cpp:91] Creating Layer Concat1
I0619 14:56:42.410387 17898 net.cpp:425] Concat1 <- Pooling1
I0619 14:56:42.410394 17898 net.cpp:425] Concat1 <- Input1
I0619 14:56:42.410403 17898 net.cpp:399] Concat1 -> Concat1
I0619 14:56:42.410439 17898 net.cpp:141] Setting up Concat1
I0619 14:56:42.410449 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.410454 17898 net.cpp:156] Memory required for data: 1721239040
I0619 14:56:42.410459 17898 layer_factory.hpp:77] Creating layer Convolution38
I0619 14:56:42.410473 17898 net.cpp:91] Creating Layer Convolution38
I0619 14:56:42.410480 17898 net.cpp:425] Convolution38 <- Eltwise18_ReLU37_0_split_1
I0619 14:56:42.410492 17898 net.cpp:399] Convolution38 -> Convolution38
I0619 14:56:42.411087 17898 net.cpp:141] Setting up Convolution38
I0619 14:56:42.411098 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.411103 17898 net.cpp:156] Memory required for data: 1725433344
I0619 14:56:42.411114 17898 layer_factory.hpp:77] Creating layer BatchNorm38
I0619 14:56:42.411125 17898 net.cpp:91] Creating Layer BatchNorm38
I0619 14:56:42.411133 17898 net.cpp:425] BatchNorm38 <- Convolution38
I0619 14:56:42.411142 17898 net.cpp:386] BatchNorm38 -> Convolution38 (in-place)
I0619 14:56:42.411423 17898 net.cpp:141] Setting up BatchNorm38
I0619 14:56:42.411433 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.411442 17898 net.cpp:156] Memory required for data: 1729627648
I0619 14:56:42.411468 17898 layer_factory.hpp:77] Creating layer Scale38
I0619 14:56:42.411490 17898 net.cpp:91] Creating Layer Scale38
I0619 14:56:42.411497 17898 net.cpp:425] Scale38 <- Convolution38
I0619 14:56:42.411505 17898 net.cpp:386] Scale38 -> Convolution38 (in-place)
I0619 14:56:42.411556 17898 layer_factory.hpp:77] Creating layer Scale38
I0619 14:56:42.411727 17898 net.cpp:141] Setting up Scale38
I0619 14:56:42.411738 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.411743 17898 net.cpp:156] Memory required for data: 1733821952
I0619 14:56:42.411753 17898 layer_factory.hpp:77] Creating layer ReLU38
I0619 14:56:42.411761 17898 net.cpp:91] Creating Layer ReLU38
I0619 14:56:42.411768 17898 net.cpp:425] ReLU38 <- Convolution38
I0619 14:56:42.411775 17898 net.cpp:386] ReLU38 -> Convolution38 (in-place)
I0619 14:56:42.411784 17898 net.cpp:141] Setting up ReLU38
I0619 14:56:42.411792 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.411798 17898 net.cpp:156] Memory required for data: 1738016256
I0619 14:56:42.411803 17898 layer_factory.hpp:77] Creating layer Convolution39
I0619 14:56:42.411818 17898 net.cpp:91] Creating Layer Convolution39
I0619 14:56:42.411824 17898 net.cpp:425] Convolution39 <- Convolution38
I0619 14:56:42.411834 17898 net.cpp:399] Convolution39 -> Convolution39
I0619 14:56:42.412639 17898 net.cpp:141] Setting up Convolution39
I0619 14:56:42.412650 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.412657 17898 net.cpp:156] Memory required for data: 1742210560
I0619 14:56:42.412665 17898 layer_factory.hpp:77] Creating layer BatchNorm39
I0619 14:56:42.412677 17898 net.cpp:91] Creating Layer BatchNorm39
I0619 14:56:42.412683 17898 net.cpp:425] BatchNorm39 <- Convolution39
I0619 14:56:42.412693 17898 net.cpp:386] BatchNorm39 -> Convolution39 (in-place)
I0619 14:56:42.412966 17898 net.cpp:141] Setting up BatchNorm39
I0619 14:56:42.412976 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.412981 17898 net.cpp:156] Memory required for data: 1746404864
I0619 14:56:42.412992 17898 layer_factory.hpp:77] Creating layer Scale39
I0619 14:56:42.413002 17898 net.cpp:91] Creating Layer Scale39
I0619 14:56:42.413007 17898 net.cpp:425] Scale39 <- Convolution39
I0619 14:56:42.413017 17898 net.cpp:386] Scale39 -> Convolution39 (in-place)
I0619 14:56:42.413064 17898 layer_factory.hpp:77] Creating layer Scale39
I0619 14:56:42.413229 17898 net.cpp:141] Setting up Scale39
I0619 14:56:42.413239 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.413244 17898 net.cpp:156] Memory required for data: 1750599168
I0619 14:56:42.413254 17898 layer_factory.hpp:77] Creating layer Eltwise19
I0619 14:56:42.413261 17898 net.cpp:91] Creating Layer Eltwise19
I0619 14:56:42.413267 17898 net.cpp:425] Eltwise19 <- Concat1
I0619 14:56:42.413275 17898 net.cpp:425] Eltwise19 <- Convolution39
I0619 14:56:42.413283 17898 net.cpp:399] Eltwise19 -> Eltwise19
I0619 14:56:42.413311 17898 net.cpp:141] Setting up Eltwise19
I0619 14:56:42.413321 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.413326 17898 net.cpp:156] Memory required for data: 1754793472
I0619 14:56:42.413331 17898 layer_factory.hpp:77] Creating layer ReLU39
I0619 14:56:42.413337 17898 net.cpp:91] Creating Layer ReLU39
I0619 14:56:42.413346 17898 net.cpp:425] ReLU39 <- Eltwise19
I0619 14:56:42.413353 17898 net.cpp:386] ReLU39 -> Eltwise19 (in-place)
I0619 14:56:42.413362 17898 net.cpp:141] Setting up ReLU39
I0619 14:56:42.413369 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.413374 17898 net.cpp:156] Memory required for data: 1758987776
I0619 14:56:42.413379 17898 layer_factory.hpp:77] Creating layer Eltwise19_ReLU39_0_split
I0619 14:56:42.413388 17898 net.cpp:91] Creating Layer Eltwise19_ReLU39_0_split
I0619 14:56:42.413393 17898 net.cpp:425] Eltwise19_ReLU39_0_split <- Eltwise19
I0619 14:56:42.413399 17898 net.cpp:399] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_0
I0619 14:56:42.413419 17898 net.cpp:399] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_1
I0619 14:56:42.413486 17898 net.cpp:141] Setting up Eltwise19_ReLU39_0_split
I0619 14:56:42.413496 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.413502 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.413508 17898 net.cpp:156] Memory required for data: 1767376384
I0619 14:56:42.413513 17898 layer_factory.hpp:77] Creating layer Convolution40
I0619 14:56:42.413528 17898 net.cpp:91] Creating Layer Convolution40
I0619 14:56:42.413534 17898 net.cpp:425] Convolution40 <- Eltwise19_ReLU39_0_split_0
I0619 14:56:42.413544 17898 net.cpp:399] Convolution40 -> Convolution40
I0619 14:56:42.414366 17898 net.cpp:141] Setting up Convolution40
I0619 14:56:42.414379 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.414384 17898 net.cpp:156] Memory required for data: 1771570688
I0619 14:56:42.414394 17898 layer_factory.hpp:77] Creating layer BatchNorm40
I0619 14:56:42.414403 17898 net.cpp:91] Creating Layer BatchNorm40
I0619 14:56:42.414409 17898 net.cpp:425] BatchNorm40 <- Convolution40
I0619 14:56:42.414422 17898 net.cpp:386] BatchNorm40 -> Convolution40 (in-place)
I0619 14:56:42.414702 17898 net.cpp:141] Setting up BatchNorm40
I0619 14:56:42.414712 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.414717 17898 net.cpp:156] Memory required for data: 1775764992
I0619 14:56:42.414729 17898 layer_factory.hpp:77] Creating layer Scale40
I0619 14:56:42.414741 17898 net.cpp:91] Creating Layer Scale40
I0619 14:56:42.414747 17898 net.cpp:425] Scale40 <- Convolution40
I0619 14:56:42.414755 17898 net.cpp:386] Scale40 -> Convolution40 (in-place)
I0619 14:56:42.414803 17898 layer_factory.hpp:77] Creating layer Scale40
I0619 14:56:42.414968 17898 net.cpp:141] Setting up Scale40
I0619 14:56:42.414978 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.414983 17898 net.cpp:156] Memory required for data: 1779959296
I0619 14:56:42.414991 17898 layer_factory.hpp:77] Creating layer ReLU40
I0619 14:56:42.414999 17898 net.cpp:91] Creating Layer ReLU40
I0619 14:56:42.415005 17898 net.cpp:425] ReLU40 <- Convolution40
I0619 14:56:42.415025 17898 net.cpp:386] ReLU40 -> Convolution40 (in-place)
I0619 14:56:42.415035 17898 net.cpp:141] Setting up ReLU40
I0619 14:56:42.415043 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.415048 17898 net.cpp:156] Memory required for data: 1784153600
I0619 14:56:42.415053 17898 layer_factory.hpp:77] Creating layer Convolution41
I0619 14:56:42.415068 17898 net.cpp:91] Creating Layer Convolution41
I0619 14:56:42.415074 17898 net.cpp:425] Convolution41 <- Convolution40
I0619 14:56:42.415083 17898 net.cpp:399] Convolution41 -> Convolution41
I0619 14:56:42.415900 17898 net.cpp:141] Setting up Convolution41
I0619 14:56:42.415911 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.415917 17898 net.cpp:156] Memory required for data: 1788347904
I0619 14:56:42.415926 17898 layer_factory.hpp:77] Creating layer BatchNorm41
I0619 14:56:42.415937 17898 net.cpp:91] Creating Layer BatchNorm41
I0619 14:56:42.415944 17898 net.cpp:425] BatchNorm41 <- Convolution41
I0619 14:56:42.415954 17898 net.cpp:386] BatchNorm41 -> Convolution41 (in-place)
I0619 14:56:42.416236 17898 net.cpp:141] Setting up BatchNorm41
I0619 14:56:42.416246 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.416251 17898 net.cpp:156] Memory required for data: 1792542208
I0619 14:56:42.416261 17898 layer_factory.hpp:77] Creating layer Scale41
I0619 14:56:42.416273 17898 net.cpp:91] Creating Layer Scale41
I0619 14:56:42.416280 17898 net.cpp:425] Scale41 <- Convolution41
I0619 14:56:42.416287 17898 net.cpp:386] Scale41 -> Convolution41 (in-place)
I0619 14:56:42.416334 17898 layer_factory.hpp:77] Creating layer Scale41
I0619 14:56:42.416520 17898 net.cpp:141] Setting up Scale41
I0619 14:56:42.416532 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.416538 17898 net.cpp:156] Memory required for data: 1796736512
I0619 14:56:42.416548 17898 layer_factory.hpp:77] Creating layer Eltwise20
I0619 14:56:42.416574 17898 net.cpp:91] Creating Layer Eltwise20
I0619 14:56:42.416580 17898 net.cpp:425] Eltwise20 <- Eltwise19_ReLU39_0_split_1
I0619 14:56:42.416589 17898 net.cpp:425] Eltwise20 <- Convolution41
I0619 14:56:42.416600 17898 net.cpp:399] Eltwise20 -> Eltwise20
I0619 14:56:42.416630 17898 net.cpp:141] Setting up Eltwise20
I0619 14:56:42.416638 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.416643 17898 net.cpp:156] Memory required for data: 1800930816
I0619 14:56:42.416649 17898 layer_factory.hpp:77] Creating layer ReLU41
I0619 14:56:42.416659 17898 net.cpp:91] Creating Layer ReLU41
I0619 14:56:42.416666 17898 net.cpp:425] ReLU41 <- Eltwise20
I0619 14:56:42.416673 17898 net.cpp:386] ReLU41 -> Eltwise20 (in-place)
I0619 14:56:42.416682 17898 net.cpp:141] Setting up ReLU41
I0619 14:56:42.416689 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.416695 17898 net.cpp:156] Memory required for data: 1805125120
I0619 14:56:42.416700 17898 layer_factory.hpp:77] Creating layer Eltwise20_ReLU41_0_split
I0619 14:56:42.416707 17898 net.cpp:91] Creating Layer Eltwise20_ReLU41_0_split
I0619 14:56:42.416713 17898 net.cpp:425] Eltwise20_ReLU41_0_split <- Eltwise20
I0619 14:56:42.416720 17898 net.cpp:399] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_0
I0619 14:56:42.416733 17898 net.cpp:399] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_1
I0619 14:56:42.416782 17898 net.cpp:141] Setting up Eltwise20_ReLU41_0_split
I0619 14:56:42.416790 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.416798 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.416803 17898 net.cpp:156] Memory required for data: 1813513728
I0619 14:56:42.416808 17898 layer_factory.hpp:77] Creating layer Convolution42
I0619 14:56:42.416823 17898 net.cpp:91] Creating Layer Convolution42
I0619 14:56:42.416829 17898 net.cpp:425] Convolution42 <- Eltwise20_ReLU41_0_split_0
I0619 14:56:42.416839 17898 net.cpp:399] Convolution42 -> Convolution42
I0619 14:56:42.417665 17898 net.cpp:141] Setting up Convolution42
I0619 14:56:42.417677 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.417683 17898 net.cpp:156] Memory required for data: 1817708032
I0619 14:56:42.417692 17898 layer_factory.hpp:77] Creating layer BatchNorm42
I0619 14:56:42.417704 17898 net.cpp:91] Creating Layer BatchNorm42
I0619 14:56:42.417711 17898 net.cpp:425] BatchNorm42 <- Convolution42
I0619 14:56:42.417719 17898 net.cpp:386] BatchNorm42 -> Convolution42 (in-place)
I0619 14:56:42.417999 17898 net.cpp:141] Setting up BatchNorm42
I0619 14:56:42.418009 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.418015 17898 net.cpp:156] Memory required for data: 1821902336
I0619 14:56:42.418025 17898 layer_factory.hpp:77] Creating layer Scale42
I0619 14:56:42.418040 17898 net.cpp:91] Creating Layer Scale42
I0619 14:56:42.418047 17898 net.cpp:425] Scale42 <- Convolution42
I0619 14:56:42.418056 17898 net.cpp:386] Scale42 -> Convolution42 (in-place)
I0619 14:56:42.418107 17898 layer_factory.hpp:77] Creating layer Scale42
I0619 14:56:42.418274 17898 net.cpp:141] Setting up Scale42
I0619 14:56:42.418284 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.418289 17898 net.cpp:156] Memory required for data: 1826096640
I0619 14:56:42.418298 17898 layer_factory.hpp:77] Creating layer ReLU42
I0619 14:56:42.418306 17898 net.cpp:91] Creating Layer ReLU42
I0619 14:56:42.418313 17898 net.cpp:425] ReLU42 <- Convolution42
I0619 14:56:42.418323 17898 net.cpp:386] ReLU42 -> Convolution42 (in-place)
I0619 14:56:42.418331 17898 net.cpp:141] Setting up ReLU42
I0619 14:56:42.418339 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.418344 17898 net.cpp:156] Memory required for data: 1830290944
I0619 14:56:42.418349 17898 layer_factory.hpp:77] Creating layer Convolution43
I0619 14:56:42.418375 17898 net.cpp:91] Creating Layer Convolution43
I0619 14:56:42.418382 17898 net.cpp:425] Convolution43 <- Convolution42
I0619 14:56:42.418396 17898 net.cpp:399] Convolution43 -> Convolution43
I0619 14:56:42.419217 17898 net.cpp:141] Setting up Convolution43
I0619 14:56:42.419230 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.419235 17898 net.cpp:156] Memory required for data: 1834485248
I0619 14:56:42.419245 17898 layer_factory.hpp:77] Creating layer BatchNorm43
I0619 14:56:42.419255 17898 net.cpp:91] Creating Layer BatchNorm43
I0619 14:56:42.419261 17898 net.cpp:425] BatchNorm43 <- Convolution43
I0619 14:56:42.419271 17898 net.cpp:386] BatchNorm43 -> Convolution43 (in-place)
I0619 14:56:42.419533 17898 net.cpp:141] Setting up BatchNorm43
I0619 14:56:42.419543 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.419548 17898 net.cpp:156] Memory required for data: 1838679552
I0619 14:56:42.419559 17898 layer_factory.hpp:77] Creating layer Scale43
I0619 14:56:42.419569 17898 net.cpp:91] Creating Layer Scale43
I0619 14:56:42.419575 17898 net.cpp:425] Scale43 <- Convolution43
I0619 14:56:42.419584 17898 net.cpp:386] Scale43 -> Convolution43 (in-place)
I0619 14:56:42.419626 17898 layer_factory.hpp:77] Creating layer Scale43
I0619 14:56:42.419786 17898 net.cpp:141] Setting up Scale43
I0619 14:56:42.419796 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.419801 17898 net.cpp:156] Memory required for data: 1842873856
I0619 14:56:42.419809 17898 layer_factory.hpp:77] Creating layer Eltwise21
I0619 14:56:42.419817 17898 net.cpp:91] Creating Layer Eltwise21
I0619 14:56:42.419823 17898 net.cpp:425] Eltwise21 <- Eltwise20_ReLU41_0_split_1
I0619 14:56:42.419831 17898 net.cpp:425] Eltwise21 <- Convolution43
I0619 14:56:42.419843 17898 net.cpp:399] Eltwise21 -> Eltwise21
I0619 14:56:42.419869 17898 net.cpp:141] Setting up Eltwise21
I0619 14:56:42.419878 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.419883 17898 net.cpp:156] Memory required for data: 1847068160
I0619 14:56:42.419888 17898 layer_factory.hpp:77] Creating layer ReLU43
I0619 14:56:42.419896 17898 net.cpp:91] Creating Layer ReLU43
I0619 14:56:42.419903 17898 net.cpp:425] ReLU43 <- Eltwise21
I0619 14:56:42.419909 17898 net.cpp:386] ReLU43 -> Eltwise21 (in-place)
I0619 14:56:42.419917 17898 net.cpp:141] Setting up ReLU43
I0619 14:56:42.419924 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.419929 17898 net.cpp:156] Memory required for data: 1851262464
I0619 14:56:42.419934 17898 layer_factory.hpp:77] Creating layer Eltwise21_ReLU43_0_split
I0619 14:56:42.419941 17898 net.cpp:91] Creating Layer Eltwise21_ReLU43_0_split
I0619 14:56:42.419947 17898 net.cpp:425] Eltwise21_ReLU43_0_split <- Eltwise21
I0619 14:56:42.419957 17898 net.cpp:399] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_0
I0619 14:56:42.419967 17898 net.cpp:399] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_1
I0619 14:56:42.420013 17898 net.cpp:141] Setting up Eltwise21_ReLU43_0_split
I0619 14:56:42.420022 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.420027 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.420032 17898 net.cpp:156] Memory required for data: 1859651072
I0619 14:56:42.420037 17898 layer_factory.hpp:77] Creating layer Convolution44
I0619 14:56:42.420050 17898 net.cpp:91] Creating Layer Convolution44
I0619 14:56:42.420056 17898 net.cpp:425] Convolution44 <- Eltwise21_ReLU43_0_split_0
I0619 14:56:42.420066 17898 net.cpp:399] Convolution44 -> Convolution44
I0619 14:56:42.420840 17898 net.cpp:141] Setting up Convolution44
I0619 14:56:42.420850 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.420856 17898 net.cpp:156] Memory required for data: 1863845376
I0619 14:56:42.420871 17898 layer_factory.hpp:77] Creating layer BatchNorm44
I0619 14:56:42.420882 17898 net.cpp:91] Creating Layer BatchNorm44
I0619 14:56:42.420888 17898 net.cpp:425] BatchNorm44 <- Convolution44
I0619 14:56:42.420897 17898 net.cpp:386] BatchNorm44 -> Convolution44 (in-place)
I0619 14:56:42.421160 17898 net.cpp:141] Setting up BatchNorm44
I0619 14:56:42.421169 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.421178 17898 net.cpp:156] Memory required for data: 1868039680
I0619 14:56:42.421203 17898 layer_factory.hpp:77] Creating layer Scale44
I0619 14:56:42.421214 17898 net.cpp:91] Creating Layer Scale44
I0619 14:56:42.421221 17898 net.cpp:425] Scale44 <- Convolution44
I0619 14:56:42.421229 17898 net.cpp:386] Scale44 -> Convolution44 (in-place)
I0619 14:56:42.421277 17898 layer_factory.hpp:77] Creating layer Scale44
I0619 14:56:42.421437 17898 net.cpp:141] Setting up Scale44
I0619 14:56:42.421445 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.421450 17898 net.cpp:156] Memory required for data: 1872233984
I0619 14:56:42.421459 17898 layer_factory.hpp:77] Creating layer ReLU44
I0619 14:56:42.421468 17898 net.cpp:91] Creating Layer ReLU44
I0619 14:56:42.421473 17898 net.cpp:425] ReLU44 <- Convolution44
I0619 14:56:42.421481 17898 net.cpp:386] ReLU44 -> Convolution44 (in-place)
I0619 14:56:42.421490 17898 net.cpp:141] Setting up ReLU44
I0619 14:56:42.421497 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.421502 17898 net.cpp:156] Memory required for data: 1876428288
I0619 14:56:42.421507 17898 layer_factory.hpp:77] Creating layer Convolution45
I0619 14:56:42.421520 17898 net.cpp:91] Creating Layer Convolution45
I0619 14:56:42.421525 17898 net.cpp:425] Convolution45 <- Convolution44
I0619 14:56:42.421533 17898 net.cpp:399] Convolution45 -> Convolution45
I0619 14:56:42.422293 17898 net.cpp:141] Setting up Convolution45
I0619 14:56:42.422304 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.422309 17898 net.cpp:156] Memory required for data: 1880622592
I0619 14:56:42.422318 17898 layer_factory.hpp:77] Creating layer BatchNorm45
I0619 14:56:42.422327 17898 net.cpp:91] Creating Layer BatchNorm45
I0619 14:56:42.422334 17898 net.cpp:425] BatchNorm45 <- Convolution45
I0619 14:56:42.422343 17898 net.cpp:386] BatchNorm45 -> Convolution45 (in-place)
I0619 14:56:42.422624 17898 net.cpp:141] Setting up BatchNorm45
I0619 14:56:42.422636 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.422641 17898 net.cpp:156] Memory required for data: 1884816896
I0619 14:56:42.422652 17898 layer_factory.hpp:77] Creating layer Scale45
I0619 14:56:42.422662 17898 net.cpp:91] Creating Layer Scale45
I0619 14:56:42.422668 17898 net.cpp:425] Scale45 <- Convolution45
I0619 14:56:42.422677 17898 net.cpp:386] Scale45 -> Convolution45 (in-place)
I0619 14:56:42.422722 17898 layer_factory.hpp:77] Creating layer Scale45
I0619 14:56:42.422878 17898 net.cpp:141] Setting up Scale45
I0619 14:56:42.422888 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.422891 17898 net.cpp:156] Memory required for data: 1889011200
I0619 14:56:42.422900 17898 layer_factory.hpp:77] Creating layer Eltwise22
I0619 14:56:42.422909 17898 net.cpp:91] Creating Layer Eltwise22
I0619 14:56:42.422914 17898 net.cpp:425] Eltwise22 <- Eltwise21_ReLU43_0_split_1
I0619 14:56:42.422921 17898 net.cpp:425] Eltwise22 <- Convolution45
I0619 14:56:42.422932 17898 net.cpp:399] Eltwise22 -> Eltwise22
I0619 14:56:42.422956 17898 net.cpp:141] Setting up Eltwise22
I0619 14:56:42.422965 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.422968 17898 net.cpp:156] Memory required for data: 1893205504
I0619 14:56:42.422973 17898 layer_factory.hpp:77] Creating layer ReLU45
I0619 14:56:42.422983 17898 net.cpp:91] Creating Layer ReLU45
I0619 14:56:42.422988 17898 net.cpp:425] ReLU45 <- Eltwise22
I0619 14:56:42.422996 17898 net.cpp:386] ReLU45 -> Eltwise22 (in-place)
I0619 14:56:42.423004 17898 net.cpp:141] Setting up ReLU45
I0619 14:56:42.423012 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.423015 17898 net.cpp:156] Memory required for data: 1897399808
I0619 14:56:42.423020 17898 layer_factory.hpp:77] Creating layer Eltwise22_ReLU45_0_split
I0619 14:56:42.423027 17898 net.cpp:91] Creating Layer Eltwise22_ReLU45_0_split
I0619 14:56:42.423033 17898 net.cpp:425] Eltwise22_ReLU45_0_split <- Eltwise22
I0619 14:56:42.423043 17898 net.cpp:399] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_0
I0619 14:56:42.423055 17898 net.cpp:399] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_1
I0619 14:56:42.423118 17898 net.cpp:141] Setting up Eltwise22_ReLU45_0_split
I0619 14:56:42.423127 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.423133 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.423138 17898 net.cpp:156] Memory required for data: 1905788416
I0619 14:56:42.423143 17898 layer_factory.hpp:77] Creating layer Convolution46
I0619 14:56:42.423157 17898 net.cpp:91] Creating Layer Convolution46
I0619 14:56:42.423164 17898 net.cpp:425] Convolution46 <- Eltwise22_ReLU45_0_split_0
I0619 14:56:42.423173 17898 net.cpp:399] Convolution46 -> Convolution46
I0619 14:56:42.423943 17898 net.cpp:141] Setting up Convolution46
I0619 14:56:42.423955 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.423959 17898 net.cpp:156] Memory required for data: 1909982720
I0619 14:56:42.423969 17898 layer_factory.hpp:77] Creating layer BatchNorm46
I0619 14:56:42.423984 17898 net.cpp:91] Creating Layer BatchNorm46
I0619 14:56:42.423990 17898 net.cpp:425] BatchNorm46 <- Convolution46
I0619 14:56:42.423997 17898 net.cpp:386] BatchNorm46 -> Convolution46 (in-place)
I0619 14:56:42.424257 17898 net.cpp:141] Setting up BatchNorm46
I0619 14:56:42.424265 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.424270 17898 net.cpp:156] Memory required for data: 1914177024
I0619 14:56:42.424281 17898 layer_factory.hpp:77] Creating layer Scale46
I0619 14:56:42.424293 17898 net.cpp:91] Creating Layer Scale46
I0619 14:56:42.424299 17898 net.cpp:425] Scale46 <- Convolution46
I0619 14:56:42.424307 17898 net.cpp:386] Scale46 -> Convolution46 (in-place)
I0619 14:56:42.424353 17898 layer_factory.hpp:77] Creating layer Scale46
I0619 14:56:42.424515 17898 net.cpp:141] Setting up Scale46
I0619 14:56:42.424523 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.424528 17898 net.cpp:156] Memory required for data: 1918371328
I0619 14:56:42.424537 17898 layer_factory.hpp:77] Creating layer ReLU46
I0619 14:56:42.424545 17898 net.cpp:91] Creating Layer ReLU46
I0619 14:56:42.424551 17898 net.cpp:425] ReLU46 <- Convolution46
I0619 14:56:42.424559 17898 net.cpp:386] ReLU46 -> Convolution46 (in-place)
I0619 14:56:42.424568 17898 net.cpp:141] Setting up ReLU46
I0619 14:56:42.424574 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.424579 17898 net.cpp:156] Memory required for data: 1922565632
I0619 14:56:42.424584 17898 layer_factory.hpp:77] Creating layer Convolution47
I0619 14:56:42.424597 17898 net.cpp:91] Creating Layer Convolution47
I0619 14:56:42.424602 17898 net.cpp:425] Convolution47 <- Convolution46
I0619 14:56:42.424612 17898 net.cpp:399] Convolution47 -> Convolution47
I0619 14:56:42.425379 17898 net.cpp:141] Setting up Convolution47
I0619 14:56:42.425390 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.425396 17898 net.cpp:156] Memory required for data: 1926759936
I0619 14:56:42.425405 17898 layer_factory.hpp:77] Creating layer BatchNorm47
I0619 14:56:42.425415 17898 net.cpp:91] Creating Layer BatchNorm47
I0619 14:56:42.425421 17898 net.cpp:425] BatchNorm47 <- Convolution47
I0619 14:56:42.425429 17898 net.cpp:386] BatchNorm47 -> Convolution47 (in-place)
I0619 14:56:42.425691 17898 net.cpp:141] Setting up BatchNorm47
I0619 14:56:42.425701 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.425706 17898 net.cpp:156] Memory required for data: 1930954240
I0619 14:56:42.425716 17898 layer_factory.hpp:77] Creating layer Scale47
I0619 14:56:42.425727 17898 net.cpp:91] Creating Layer Scale47
I0619 14:56:42.425732 17898 net.cpp:425] Scale47 <- Convolution47
I0619 14:56:42.425740 17898 net.cpp:386] Scale47 -> Convolution47 (in-place)
I0619 14:56:42.425786 17898 layer_factory.hpp:77] Creating layer Scale47
I0619 14:56:42.425945 17898 net.cpp:141] Setting up Scale47
I0619 14:56:42.425953 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.425958 17898 net.cpp:156] Memory required for data: 1935148544
I0619 14:56:42.425971 17898 layer_factory.hpp:77] Creating layer Eltwise23
I0619 14:56:42.425994 17898 net.cpp:91] Creating Layer Eltwise23
I0619 14:56:42.426002 17898 net.cpp:425] Eltwise23 <- Eltwise22_ReLU45_0_split_1
I0619 14:56:42.426008 17898 net.cpp:425] Eltwise23 <- Convolution47
I0619 14:56:42.426018 17898 net.cpp:399] Eltwise23 -> Eltwise23
I0619 14:56:42.426045 17898 net.cpp:141] Setting up Eltwise23
I0619 14:56:42.426057 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.426062 17898 net.cpp:156] Memory required for data: 1939342848
I0619 14:56:42.426067 17898 layer_factory.hpp:77] Creating layer ReLU47
I0619 14:56:42.426074 17898 net.cpp:91] Creating Layer ReLU47
I0619 14:56:42.426080 17898 net.cpp:425] ReLU47 <- Eltwise23
I0619 14:56:42.426086 17898 net.cpp:386] ReLU47 -> Eltwise23 (in-place)
I0619 14:56:42.426095 17898 net.cpp:141] Setting up ReLU47
I0619 14:56:42.426101 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.426106 17898 net.cpp:156] Memory required for data: 1943537152
I0619 14:56:42.426111 17898 layer_factory.hpp:77] Creating layer Eltwise23_ReLU47_0_split
I0619 14:56:42.426118 17898 net.cpp:91] Creating Layer Eltwise23_ReLU47_0_split
I0619 14:56:42.426123 17898 net.cpp:425] Eltwise23_ReLU47_0_split <- Eltwise23
I0619 14:56:42.426132 17898 net.cpp:399] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_0
I0619 14:56:42.426142 17898 net.cpp:399] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_1
I0619 14:56:42.426188 17898 net.cpp:141] Setting up Eltwise23_ReLU47_0_split
I0619 14:56:42.426197 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.426203 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.426208 17898 net.cpp:156] Memory required for data: 1951925760
I0619 14:56:42.426213 17898 layer_factory.hpp:77] Creating layer Convolution48
I0619 14:56:42.426225 17898 net.cpp:91] Creating Layer Convolution48
I0619 14:56:42.426231 17898 net.cpp:425] Convolution48 <- Eltwise23_ReLU47_0_split_0
I0619 14:56:42.426240 17898 net.cpp:399] Convolution48 -> Convolution48
I0619 14:56:42.427023 17898 net.cpp:141] Setting up Convolution48
I0619 14:56:42.427037 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.427042 17898 net.cpp:156] Memory required for data: 1956120064
I0619 14:56:42.427050 17898 layer_factory.hpp:77] Creating layer BatchNorm48
I0619 14:56:42.427062 17898 net.cpp:91] Creating Layer BatchNorm48
I0619 14:56:42.427067 17898 net.cpp:425] BatchNorm48 <- Convolution48
I0619 14:56:42.427074 17898 net.cpp:386] BatchNorm48 -> Convolution48 (in-place)
I0619 14:56:42.427341 17898 net.cpp:141] Setting up BatchNorm48
I0619 14:56:42.427350 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.427356 17898 net.cpp:156] Memory required for data: 1960314368
I0619 14:56:42.427366 17898 layer_factory.hpp:77] Creating layer Scale48
I0619 14:56:42.427378 17898 net.cpp:91] Creating Layer Scale48
I0619 14:56:42.427384 17898 net.cpp:425] Scale48 <- Convolution48
I0619 14:56:42.427392 17898 net.cpp:386] Scale48 -> Convolution48 (in-place)
I0619 14:56:42.427438 17898 layer_factory.hpp:77] Creating layer Scale48
I0619 14:56:42.427598 17898 net.cpp:141] Setting up Scale48
I0619 14:56:42.427608 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.427613 17898 net.cpp:156] Memory required for data: 1964508672
I0619 14:56:42.427621 17898 layer_factory.hpp:77] Creating layer ReLU48
I0619 14:56:42.427629 17898 net.cpp:91] Creating Layer ReLU48
I0619 14:56:42.427635 17898 net.cpp:425] ReLU48 <- Convolution48
I0619 14:56:42.427644 17898 net.cpp:386] ReLU48 -> Convolution48 (in-place)
I0619 14:56:42.427654 17898 net.cpp:141] Setting up ReLU48
I0619 14:56:42.427660 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.427665 17898 net.cpp:156] Memory required for data: 1968702976
I0619 14:56:42.427670 17898 layer_factory.hpp:77] Creating layer Convolution49
I0619 14:56:42.427683 17898 net.cpp:91] Creating Layer Convolution49
I0619 14:56:42.427688 17898 net.cpp:425] Convolution49 <- Convolution48
I0619 14:56:42.427700 17898 net.cpp:399] Convolution49 -> Convolution49
I0619 14:56:42.428490 17898 net.cpp:141] Setting up Convolution49
I0619 14:56:42.428503 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.428508 17898 net.cpp:156] Memory required for data: 1972897280
I0619 14:56:42.428515 17898 layer_factory.hpp:77] Creating layer BatchNorm49
I0619 14:56:42.428527 17898 net.cpp:91] Creating Layer BatchNorm49
I0619 14:56:42.428534 17898 net.cpp:425] BatchNorm49 <- Convolution49
I0619 14:56:42.428541 17898 net.cpp:386] BatchNorm49 -> Convolution49 (in-place)
I0619 14:56:42.428808 17898 net.cpp:141] Setting up BatchNorm49
I0619 14:56:42.428817 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.428822 17898 net.cpp:156] Memory required for data: 1977091584
I0619 14:56:42.428833 17898 layer_factory.hpp:77] Creating layer Scale49
I0619 14:56:42.428843 17898 net.cpp:91] Creating Layer Scale49
I0619 14:56:42.428849 17898 net.cpp:425] Scale49 <- Convolution49
I0619 14:56:42.428858 17898 net.cpp:386] Scale49 -> Convolution49 (in-place)
I0619 14:56:42.428902 17898 layer_factory.hpp:77] Creating layer Scale49
I0619 14:56:42.429060 17898 net.cpp:141] Setting up Scale49
I0619 14:56:42.429069 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.429075 17898 net.cpp:156] Memory required for data: 1981285888
I0619 14:56:42.429082 17898 layer_factory.hpp:77] Creating layer Eltwise24
I0619 14:56:42.429090 17898 net.cpp:91] Creating Layer Eltwise24
I0619 14:56:42.429097 17898 net.cpp:425] Eltwise24 <- Eltwise23_ReLU47_0_split_1
I0619 14:56:42.429103 17898 net.cpp:425] Eltwise24 <- Convolution49
I0619 14:56:42.429114 17898 net.cpp:399] Eltwise24 -> Eltwise24
I0619 14:56:42.429138 17898 net.cpp:141] Setting up Eltwise24
I0619 14:56:42.429148 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.429153 17898 net.cpp:156] Memory required for data: 1985480192
I0619 14:56:42.429158 17898 layer_factory.hpp:77] Creating layer ReLU49
I0619 14:56:42.429165 17898 net.cpp:91] Creating Layer ReLU49
I0619 14:56:42.429172 17898 net.cpp:425] ReLU49 <- Eltwise24
I0619 14:56:42.429177 17898 net.cpp:386] ReLU49 -> Eltwise24 (in-place)
I0619 14:56:42.429186 17898 net.cpp:141] Setting up ReLU49
I0619 14:56:42.429193 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.429198 17898 net.cpp:156] Memory required for data: 1989674496
I0619 14:56:42.429203 17898 layer_factory.hpp:77] Creating layer Eltwise24_ReLU49_0_split
I0619 14:56:42.429209 17898 net.cpp:91] Creating Layer Eltwise24_ReLU49_0_split
I0619 14:56:42.429214 17898 net.cpp:425] Eltwise24_ReLU49_0_split <- Eltwise24
I0619 14:56:42.429224 17898 net.cpp:399] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_0
I0619 14:56:42.429247 17898 net.cpp:399] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_1
I0619 14:56:42.429296 17898 net.cpp:141] Setting up Eltwise24_ReLU49_0_split
I0619 14:56:42.429306 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.429312 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.429316 17898 net.cpp:156] Memory required for data: 1998063104
I0619 14:56:42.429322 17898 layer_factory.hpp:77] Creating layer Convolution50
I0619 14:56:42.429335 17898 net.cpp:91] Creating Layer Convolution50
I0619 14:56:42.429342 17898 net.cpp:425] Convolution50 <- Eltwise24_ReLU49_0_split_0
I0619 14:56:42.429352 17898 net.cpp:399] Convolution50 -> Convolution50
I0619 14:56:42.430120 17898 net.cpp:141] Setting up Convolution50
I0619 14:56:42.430131 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.430136 17898 net.cpp:156] Memory required for data: 2002257408
I0619 14:56:42.430145 17898 layer_factory.hpp:77] Creating layer BatchNorm50
I0619 14:56:42.430156 17898 net.cpp:91] Creating Layer BatchNorm50
I0619 14:56:42.430162 17898 net.cpp:425] BatchNorm50 <- Convolution50
I0619 14:56:42.430171 17898 net.cpp:386] BatchNorm50 -> Convolution50 (in-place)
I0619 14:56:42.430444 17898 net.cpp:141] Setting up BatchNorm50
I0619 14:56:42.430455 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.430464 17898 net.cpp:156] Memory required for data: 2006451712
I0619 14:56:42.430490 17898 layer_factory.hpp:77] Creating layer Scale50
I0619 14:56:42.430501 17898 net.cpp:91] Creating Layer Scale50
I0619 14:56:42.430508 17898 net.cpp:425] Scale50 <- Convolution50
I0619 14:56:42.430516 17898 net.cpp:386] Scale50 -> Convolution50 (in-place)
I0619 14:56:42.430575 17898 layer_factory.hpp:77] Creating layer Scale50
I0619 14:56:42.430727 17898 net.cpp:141] Setting up Scale50
I0619 14:56:42.430737 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.430742 17898 net.cpp:156] Memory required for data: 2010646016
I0619 14:56:42.430749 17898 layer_factory.hpp:77] Creating layer ReLU50
I0619 14:56:42.430757 17898 net.cpp:91] Creating Layer ReLU50
I0619 14:56:42.430763 17898 net.cpp:425] ReLU50 <- Convolution50
I0619 14:56:42.430771 17898 net.cpp:386] ReLU50 -> Convolution50 (in-place)
I0619 14:56:42.430780 17898 net.cpp:141] Setting up ReLU50
I0619 14:56:42.430786 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.430791 17898 net.cpp:156] Memory required for data: 2014840320
I0619 14:56:42.430795 17898 layer_factory.hpp:77] Creating layer Convolution51
I0619 14:56:42.430809 17898 net.cpp:91] Creating Layer Convolution51
I0619 14:56:42.430814 17898 net.cpp:425] Convolution51 <- Convolution50
I0619 14:56:42.430821 17898 net.cpp:399] Convolution51 -> Convolution51
I0619 14:56:42.431545 17898 net.cpp:141] Setting up Convolution51
I0619 14:56:42.431555 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.431560 17898 net.cpp:156] Memory required for data: 2019034624
I0619 14:56:42.431568 17898 layer_factory.hpp:77] Creating layer BatchNorm51
I0619 14:56:42.431576 17898 net.cpp:91] Creating Layer BatchNorm51
I0619 14:56:42.431583 17898 net.cpp:425] BatchNorm51 <- Convolution51
I0619 14:56:42.431591 17898 net.cpp:386] BatchNorm51 -> Convolution51 (in-place)
I0619 14:56:42.431840 17898 net.cpp:141] Setting up BatchNorm51
I0619 14:56:42.431849 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.431854 17898 net.cpp:156] Memory required for data: 2023228928
I0619 14:56:42.431864 17898 layer_factory.hpp:77] Creating layer Scale51
I0619 14:56:42.431896 17898 net.cpp:91] Creating Layer Scale51
I0619 14:56:42.431903 17898 net.cpp:425] Scale51 <- Convolution51
I0619 14:56:42.431911 17898 net.cpp:386] Scale51 -> Convolution51 (in-place)
I0619 14:56:42.431958 17898 layer_factory.hpp:77] Creating layer Scale51
I0619 14:56:42.432108 17898 net.cpp:141] Setting up Scale51
I0619 14:56:42.432117 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.432122 17898 net.cpp:156] Memory required for data: 2027423232
I0619 14:56:42.432132 17898 layer_factory.hpp:77] Creating layer Eltwise25
I0619 14:56:42.432138 17898 net.cpp:91] Creating Layer Eltwise25
I0619 14:56:42.432144 17898 net.cpp:425] Eltwise25 <- Eltwise24_ReLU49_0_split_1
I0619 14:56:42.432152 17898 net.cpp:425] Eltwise25 <- Convolution51
I0619 14:56:42.432158 17898 net.cpp:399] Eltwise25 -> Eltwise25
I0619 14:56:42.432181 17898 net.cpp:141] Setting up Eltwise25
I0619 14:56:42.432188 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.432193 17898 net.cpp:156] Memory required for data: 2031617536
I0619 14:56:42.432198 17898 layer_factory.hpp:77] Creating layer ReLU51
I0619 14:56:42.432207 17898 net.cpp:91] Creating Layer ReLU51
I0619 14:56:42.432212 17898 net.cpp:425] ReLU51 <- Eltwise25
I0619 14:56:42.432219 17898 net.cpp:386] ReLU51 -> Eltwise25 (in-place)
I0619 14:56:42.432226 17898 net.cpp:141] Setting up ReLU51
I0619 14:56:42.432234 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.432238 17898 net.cpp:156] Memory required for data: 2035811840
I0619 14:56:42.432242 17898 layer_factory.hpp:77] Creating layer Eltwise25_ReLU51_0_split
I0619 14:56:42.432250 17898 net.cpp:91] Creating Layer Eltwise25_ReLU51_0_split
I0619 14:56:42.432255 17898 net.cpp:425] Eltwise25_ReLU51_0_split <- Eltwise25
I0619 14:56:42.432263 17898 net.cpp:399] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_0
I0619 14:56:42.432288 17898 net.cpp:399] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_1
I0619 14:56:42.432338 17898 net.cpp:141] Setting up Eltwise25_ReLU51_0_split
I0619 14:56:42.432348 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.432354 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.432359 17898 net.cpp:156] Memory required for data: 2044200448
I0619 14:56:42.432364 17898 layer_factory.hpp:77] Creating layer Convolution52
I0619 14:56:42.432377 17898 net.cpp:91] Creating Layer Convolution52
I0619 14:56:42.432382 17898 net.cpp:425] Convolution52 <- Eltwise25_ReLU51_0_split_0
I0619 14:56:42.432391 17898 net.cpp:399] Convolution52 -> Convolution52
I0619 14:56:42.433130 17898 net.cpp:141] Setting up Convolution52
I0619 14:56:42.433141 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.433145 17898 net.cpp:156] Memory required for data: 2048394752
I0619 14:56:42.433154 17898 layer_factory.hpp:77] Creating layer BatchNorm52
I0619 14:56:42.433166 17898 net.cpp:91] Creating Layer BatchNorm52
I0619 14:56:42.433171 17898 net.cpp:425] BatchNorm52 <- Convolution52
I0619 14:56:42.433178 17898 net.cpp:386] BatchNorm52 -> Convolution52 (in-place)
I0619 14:56:42.433429 17898 net.cpp:141] Setting up BatchNorm52
I0619 14:56:42.433436 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.433441 17898 net.cpp:156] Memory required for data: 2052589056
I0619 14:56:42.433452 17898 layer_factory.hpp:77] Creating layer Scale52
I0619 14:56:42.433460 17898 net.cpp:91] Creating Layer Scale52
I0619 14:56:42.433465 17898 net.cpp:425] Scale52 <- Convolution52
I0619 14:56:42.433472 17898 net.cpp:386] Scale52 -> Convolution52 (in-place)
I0619 14:56:42.433516 17898 layer_factory.hpp:77] Creating layer Scale52
I0619 14:56:42.433665 17898 net.cpp:141] Setting up Scale52
I0619 14:56:42.433675 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.433678 17898 net.cpp:156] Memory required for data: 2056783360
I0619 14:56:42.433687 17898 layer_factory.hpp:77] Creating layer ReLU52
I0619 14:56:42.433697 17898 net.cpp:91] Creating Layer ReLU52
I0619 14:56:42.433703 17898 net.cpp:425] ReLU52 <- Convolution52
I0619 14:56:42.433709 17898 net.cpp:386] ReLU52 -> Convolution52 (in-place)
I0619 14:56:42.433717 17898 net.cpp:141] Setting up ReLU52
I0619 14:56:42.433724 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.433728 17898 net.cpp:156] Memory required for data: 2060977664
I0619 14:56:42.433733 17898 layer_factory.hpp:77] Creating layer Convolution53
I0619 14:56:42.433746 17898 net.cpp:91] Creating Layer Convolution53
I0619 14:56:42.433753 17898 net.cpp:425] Convolution53 <- Convolution52
I0619 14:56:42.433760 17898 net.cpp:399] Convolution53 -> Convolution53
I0619 14:56:42.434501 17898 net.cpp:141] Setting up Convolution53
I0619 14:56:42.434514 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.434519 17898 net.cpp:156] Memory required for data: 2065171968
I0619 14:56:42.434527 17898 layer_factory.hpp:77] Creating layer BatchNorm53
I0619 14:56:42.434535 17898 net.cpp:91] Creating Layer BatchNorm53
I0619 14:56:42.434541 17898 net.cpp:425] BatchNorm53 <- Convolution53
I0619 14:56:42.434551 17898 net.cpp:386] BatchNorm53 -> Convolution53 (in-place)
I0619 14:56:42.434801 17898 net.cpp:141] Setting up BatchNorm53
I0619 14:56:42.434811 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.434815 17898 net.cpp:156] Memory required for data: 2069366272
I0619 14:56:42.434825 17898 layer_factory.hpp:77] Creating layer Scale53
I0619 14:56:42.434834 17898 net.cpp:91] Creating Layer Scale53
I0619 14:56:42.434839 17898 net.cpp:425] Scale53 <- Convolution53
I0619 14:56:42.434846 17898 net.cpp:386] Scale53 -> Convolution53 (in-place)
I0619 14:56:42.434891 17898 layer_factory.hpp:77] Creating layer Scale53
I0619 14:56:42.435041 17898 net.cpp:141] Setting up Scale53
I0619 14:56:42.435050 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.435055 17898 net.cpp:156] Memory required for data: 2073560576
I0619 14:56:42.435066 17898 layer_factory.hpp:77] Creating layer Eltwise26
I0619 14:56:42.435089 17898 net.cpp:91] Creating Layer Eltwise26
I0619 14:56:42.435096 17898 net.cpp:425] Eltwise26 <- Eltwise25_ReLU51_0_split_1
I0619 14:56:42.435103 17898 net.cpp:425] Eltwise26 <- Convolution53
I0619 14:56:42.435111 17898 net.cpp:399] Eltwise26 -> Eltwise26
I0619 14:56:42.435137 17898 net.cpp:141] Setting up Eltwise26
I0619 14:56:42.435144 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.435149 17898 net.cpp:156] Memory required for data: 2077754880
I0619 14:56:42.435153 17898 layer_factory.hpp:77] Creating layer ReLU53
I0619 14:56:42.435166 17898 net.cpp:91] Creating Layer ReLU53
I0619 14:56:42.435173 17898 net.cpp:425] ReLU53 <- Eltwise26
I0619 14:56:42.435179 17898 net.cpp:386] ReLU53 -> Eltwise26 (in-place)
I0619 14:56:42.435187 17898 net.cpp:141] Setting up ReLU53
I0619 14:56:42.435194 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.435199 17898 net.cpp:156] Memory required for data: 2081949184
I0619 14:56:42.435204 17898 layer_factory.hpp:77] Creating layer Eltwise26_ReLU53_0_split
I0619 14:56:42.435210 17898 net.cpp:91] Creating Layer Eltwise26_ReLU53_0_split
I0619 14:56:42.435215 17898 net.cpp:425] Eltwise26_ReLU53_0_split <- Eltwise26
I0619 14:56:42.435228 17898 net.cpp:399] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_0
I0619 14:56:42.435237 17898 net.cpp:399] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_1
I0619 14:56:42.435284 17898 net.cpp:141] Setting up Eltwise26_ReLU53_0_split
I0619 14:56:42.435292 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.435299 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.435303 17898 net.cpp:156] Memory required for data: 2090337792
I0619 14:56:42.435308 17898 layer_factory.hpp:77] Creating layer Convolution54
I0619 14:56:42.435322 17898 net.cpp:91] Creating Layer Convolution54
I0619 14:56:42.435326 17898 net.cpp:425] Convolution54 <- Eltwise26_ReLU53_0_split_0
I0619 14:56:42.435335 17898 net.cpp:399] Convolution54 -> Convolution54
I0619 14:56:42.436069 17898 net.cpp:141] Setting up Convolution54
I0619 14:56:42.436079 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.436082 17898 net.cpp:156] Memory required for data: 2094532096
I0619 14:56:42.436091 17898 layer_factory.hpp:77] Creating layer BatchNorm54
I0619 14:56:42.436101 17898 net.cpp:91] Creating Layer BatchNorm54
I0619 14:56:42.436108 17898 net.cpp:425] BatchNorm54 <- Convolution54
I0619 14:56:42.436115 17898 net.cpp:386] BatchNorm54 -> Convolution54 (in-place)
I0619 14:56:42.436365 17898 net.cpp:141] Setting up BatchNorm54
I0619 14:56:42.436374 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.436379 17898 net.cpp:156] Memory required for data: 2098726400
I0619 14:56:42.436389 17898 layer_factory.hpp:77] Creating layer Scale54
I0619 14:56:42.436398 17898 net.cpp:91] Creating Layer Scale54
I0619 14:56:42.436403 17898 net.cpp:425] Scale54 <- Convolution54
I0619 14:56:42.436410 17898 net.cpp:386] Scale54 -> Convolution54 (in-place)
I0619 14:56:42.436455 17898 layer_factory.hpp:77] Creating layer Scale54
I0619 14:56:42.436601 17898 net.cpp:141] Setting up Scale54
I0619 14:56:42.436611 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.436615 17898 net.cpp:156] Memory required for data: 2102920704
I0619 14:56:42.436625 17898 layer_factory.hpp:77] Creating layer ReLU54
I0619 14:56:42.436633 17898 net.cpp:91] Creating Layer ReLU54
I0619 14:56:42.436640 17898 net.cpp:425] ReLU54 <- Convolution54
I0619 14:56:42.436645 17898 net.cpp:386] ReLU54 -> Convolution54 (in-place)
I0619 14:56:42.436653 17898 net.cpp:141] Setting up ReLU54
I0619 14:56:42.436661 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.436666 17898 net.cpp:156] Memory required for data: 2107115008
I0619 14:56:42.436669 17898 layer_factory.hpp:77] Creating layer Convolution55
I0619 14:56:42.436682 17898 net.cpp:91] Creating Layer Convolution55
I0619 14:56:42.436687 17898 net.cpp:425] Convolution55 <- Convolution54
I0619 14:56:42.436702 17898 net.cpp:399] Convolution55 -> Convolution55
I0619 14:56:42.437446 17898 net.cpp:141] Setting up Convolution55
I0619 14:56:42.437458 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.437463 17898 net.cpp:156] Memory required for data: 2111309312
I0619 14:56:42.437470 17898 layer_factory.hpp:77] Creating layer BatchNorm55
I0619 14:56:42.437479 17898 net.cpp:91] Creating Layer BatchNorm55
I0619 14:56:42.437484 17898 net.cpp:425] BatchNorm55 <- Convolution55
I0619 14:56:42.437494 17898 net.cpp:386] BatchNorm55 -> Convolution55 (in-place)
I0619 14:56:42.437747 17898 net.cpp:141] Setting up BatchNorm55
I0619 14:56:42.437755 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.437759 17898 net.cpp:156] Memory required for data: 2115503616
I0619 14:56:42.437770 17898 layer_factory.hpp:77] Creating layer Scale55
I0619 14:56:42.437778 17898 net.cpp:91] Creating Layer Scale55
I0619 14:56:42.437783 17898 net.cpp:425] Scale55 <- Convolution55
I0619 14:56:42.437790 17898 net.cpp:386] Scale55 -> Convolution55 (in-place)
I0619 14:56:42.437835 17898 layer_factory.hpp:77] Creating layer Scale55
I0619 14:56:42.437983 17898 net.cpp:141] Setting up Scale55
I0619 14:56:42.437993 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.437997 17898 net.cpp:156] Memory required for data: 2119697920
I0619 14:56:42.438005 17898 layer_factory.hpp:77] Creating layer Eltwise27
I0619 14:56:42.438014 17898 net.cpp:91] Creating Layer Eltwise27
I0619 14:56:42.438020 17898 net.cpp:425] Eltwise27 <- Eltwise26_ReLU53_0_split_1
I0619 14:56:42.438027 17898 net.cpp:425] Eltwise27 <- Convolution55
I0619 14:56:42.438035 17898 net.cpp:399] Eltwise27 -> Eltwise27
I0619 14:56:42.438057 17898 net.cpp:141] Setting up Eltwise27
I0619 14:56:42.438066 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.438069 17898 net.cpp:156] Memory required for data: 2123892224
I0619 14:56:42.438074 17898 layer_factory.hpp:77] Creating layer ReLU55
I0619 14:56:42.438083 17898 net.cpp:91] Creating Layer ReLU55
I0619 14:56:42.438089 17898 net.cpp:425] ReLU55 <- Eltwise27
I0619 14:56:42.438096 17898 net.cpp:386] ReLU55 -> Eltwise27 (in-place)
I0619 14:56:42.438103 17898 net.cpp:141] Setting up ReLU55
I0619 14:56:42.438110 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.438114 17898 net.cpp:156] Memory required for data: 2128086528
I0619 14:56:42.438119 17898 layer_factory.hpp:77] Creating layer Eltwise27_ReLU55_0_split
I0619 14:56:42.438127 17898 net.cpp:91] Creating Layer Eltwise27_ReLU55_0_split
I0619 14:56:42.438133 17898 net.cpp:425] Eltwise27_ReLU55_0_split <- Eltwise27
I0619 14:56:42.438139 17898 net.cpp:399] Eltwise27_ReLU55_0_split -> Eltwise27_ReLU55_0_split_0
I0619 14:56:42.438148 17898 net.cpp:399] Eltwise27_ReLU55_0_split -> Eltwise27_ReLU55_0_split_1
I0619 14:56:42.438195 17898 net.cpp:141] Setting up Eltwise27_ReLU55_0_split
I0619 14:56:42.438204 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.438210 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.438213 17898 net.cpp:156] Memory required for data: 2136475136
I0619 14:56:42.438218 17898 layer_factory.hpp:77] Creating layer Convolution56
I0619 14:56:42.438230 17898 net.cpp:91] Creating Layer Convolution56
I0619 14:56:42.438236 17898 net.cpp:425] Convolution56 <- Eltwise27_ReLU55_0_split_0
I0619 14:56:42.438244 17898 net.cpp:399] Convolution56 -> Convolution56
I0619 14:56:42.438982 17898 net.cpp:141] Setting up Convolution56
I0619 14:56:42.438993 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.438998 17898 net.cpp:156] Memory required for data: 2140669440
I0619 14:56:42.439007 17898 layer_factory.hpp:77] Creating layer BatchNorm56
I0619 14:56:42.439018 17898 net.cpp:91] Creating Layer BatchNorm56
I0619 14:56:42.439023 17898 net.cpp:425] BatchNorm56 <- Convolution56
I0619 14:56:42.439031 17898 net.cpp:386] BatchNorm56 -> Convolution56 (in-place)
I0619 14:56:42.439282 17898 net.cpp:141] Setting up BatchNorm56
I0619 14:56:42.439292 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.439314 17898 net.cpp:156] Memory required for data: 2144863744
I0619 14:56:42.439326 17898 layer_factory.hpp:77] Creating layer Scale56
I0619 14:56:42.439334 17898 net.cpp:91] Creating Layer Scale56
I0619 14:56:42.439340 17898 net.cpp:425] Scale56 <- Convolution56
I0619 14:56:42.439347 17898 net.cpp:386] Scale56 -> Convolution56 (in-place)
I0619 14:56:42.439394 17898 layer_factory.hpp:77] Creating layer Scale56
I0619 14:56:42.439543 17898 net.cpp:141] Setting up Scale56
I0619 14:56:42.439553 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.439556 17898 net.cpp:156] Memory required for data: 2149058048
I0619 14:56:42.439564 17898 layer_factory.hpp:77] Creating layer ReLU56
I0619 14:56:42.439574 17898 net.cpp:91] Creating Layer ReLU56
I0619 14:56:42.439579 17898 net.cpp:425] ReLU56 <- Convolution56
I0619 14:56:42.439586 17898 net.cpp:386] ReLU56 -> Convolution56 (in-place)
I0619 14:56:42.439594 17898 net.cpp:141] Setting up ReLU56
I0619 14:56:42.439600 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.439605 17898 net.cpp:156] Memory required for data: 2153252352
I0619 14:56:42.439610 17898 layer_factory.hpp:77] Creating layer Convolution57
I0619 14:56:42.439622 17898 net.cpp:91] Creating Layer Convolution57
I0619 14:56:42.439627 17898 net.cpp:425] Convolution57 <- Convolution56
I0619 14:56:42.439637 17898 net.cpp:399] Convolution57 -> Convolution57
I0619 14:56:42.440363 17898 net.cpp:141] Setting up Convolution57
I0619 14:56:42.440374 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.440379 17898 net.cpp:156] Memory required for data: 2157446656
I0619 14:56:42.440387 17898 layer_factory.hpp:77] Creating layer BatchNorm57
I0619 14:56:42.440399 17898 net.cpp:91] Creating Layer BatchNorm57
I0619 14:56:42.440404 17898 net.cpp:425] BatchNorm57 <- Convolution57
I0619 14:56:42.440412 17898 net.cpp:386] BatchNorm57 -> Convolution57 (in-place)
I0619 14:56:42.440662 17898 net.cpp:141] Setting up BatchNorm57
I0619 14:56:42.440671 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.440676 17898 net.cpp:156] Memory required for data: 2161640960
I0619 14:56:42.440686 17898 layer_factory.hpp:77] Creating layer Scale57
I0619 14:56:42.440695 17898 net.cpp:91] Creating Layer Scale57
I0619 14:56:42.440699 17898 net.cpp:425] Scale57 <- Convolution57
I0619 14:56:42.440706 17898 net.cpp:386] Scale57 -> Convolution57 (in-place)
I0619 14:56:42.440749 17898 layer_factory.hpp:77] Creating layer Scale57
I0619 14:56:42.440898 17898 net.cpp:141] Setting up Scale57
I0619 14:56:42.440907 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.440912 17898 net.cpp:156] Memory required for data: 2165835264
I0619 14:56:42.440920 17898 layer_factory.hpp:77] Creating layer Eltwise28
I0619 14:56:42.440929 17898 net.cpp:91] Creating Layer Eltwise28
I0619 14:56:42.440935 17898 net.cpp:425] Eltwise28 <- Eltwise27_ReLU55_0_split_1
I0619 14:56:42.440943 17898 net.cpp:425] Eltwise28 <- Convolution57
I0619 14:56:42.440950 17898 net.cpp:399] Eltwise28 -> Eltwise28
I0619 14:56:42.440973 17898 net.cpp:141] Setting up Eltwise28
I0619 14:56:42.440980 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.440984 17898 net.cpp:156] Memory required for data: 2170029568
I0619 14:56:42.440989 17898 layer_factory.hpp:77] Creating layer ReLU57
I0619 14:56:42.440999 17898 net.cpp:91] Creating Layer ReLU57
I0619 14:56:42.441004 17898 net.cpp:425] ReLU57 <- Eltwise28
I0619 14:56:42.441011 17898 net.cpp:386] ReLU57 -> Eltwise28 (in-place)
I0619 14:56:42.441018 17898 net.cpp:141] Setting up ReLU57
I0619 14:56:42.441025 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.441030 17898 net.cpp:156] Memory required for data: 2174223872
I0619 14:56:42.441035 17898 layer_factory.hpp:77] Creating layer Eltwise28_ReLU57_0_split
I0619 14:56:42.441042 17898 net.cpp:91] Creating Layer Eltwise28_ReLU57_0_split
I0619 14:56:42.441047 17898 net.cpp:425] Eltwise28_ReLU57_0_split <- Eltwise28
I0619 14:56:42.441054 17898 net.cpp:399] Eltwise28_ReLU57_0_split -> Eltwise28_ReLU57_0_split_0
I0619 14:56:42.441078 17898 net.cpp:399] Eltwise28_ReLU57_0_split -> Eltwise28_ReLU57_0_split_1
I0619 14:56:42.441128 17898 net.cpp:141] Setting up Eltwise28_ReLU57_0_split
I0619 14:56:42.441136 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.441143 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.441148 17898 net.cpp:156] Memory required for data: 2182612480
I0619 14:56:42.441153 17898 layer_factory.hpp:77] Creating layer Convolution58
I0619 14:56:42.441164 17898 net.cpp:91] Creating Layer Convolution58
I0619 14:56:42.441170 17898 net.cpp:425] Convolution58 <- Eltwise28_ReLU57_0_split_0
I0619 14:56:42.441179 17898 net.cpp:399] Convolution58 -> Convolution58
I0619 14:56:42.442627 17898 net.cpp:141] Setting up Convolution58
I0619 14:56:42.442646 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.442651 17898 net.cpp:156] Memory required for data: 2186806784
I0619 14:56:42.442661 17898 layer_factory.hpp:77] Creating layer BatchNorm58
I0619 14:56:42.442672 17898 net.cpp:91] Creating Layer BatchNorm58
I0619 14:56:42.442678 17898 net.cpp:425] BatchNorm58 <- Convolution58
I0619 14:56:42.442695 17898 net.cpp:386] BatchNorm58 -> Convolution58 (in-place)
I0619 14:56:42.442947 17898 net.cpp:141] Setting up BatchNorm58
I0619 14:56:42.442956 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.442960 17898 net.cpp:156] Memory required for data: 2191001088
I0619 14:56:42.442970 17898 layer_factory.hpp:77] Creating layer Scale58
I0619 14:56:42.442981 17898 net.cpp:91] Creating Layer Scale58
I0619 14:56:42.442986 17898 net.cpp:425] Scale58 <- Convolution58
I0619 14:56:42.442993 17898 net.cpp:386] Scale58 -> Convolution58 (in-place)
I0619 14:56:42.443038 17898 layer_factory.hpp:77] Creating layer Scale58
I0619 14:56:42.443192 17898 net.cpp:141] Setting up Scale58
I0619 14:56:42.443202 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.443207 17898 net.cpp:156] Memory required for data: 2195195392
I0619 14:56:42.443214 17898 layer_factory.hpp:77] Creating layer ReLU58
I0619 14:56:42.443224 17898 net.cpp:91] Creating Layer ReLU58
I0619 14:56:42.443229 17898 net.cpp:425] ReLU58 <- Convolution58
I0619 14:56:42.443236 17898 net.cpp:386] ReLU58 -> Convolution58 (in-place)
I0619 14:56:42.443244 17898 net.cpp:141] Setting up ReLU58
I0619 14:56:42.443250 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.443255 17898 net.cpp:156] Memory required for data: 2199389696
I0619 14:56:42.443259 17898 layer_factory.hpp:77] Creating layer Convolution59
I0619 14:56:42.443272 17898 net.cpp:91] Creating Layer Convolution59
I0619 14:56:42.443277 17898 net.cpp:425] Convolution59 <- Convolution58
I0619 14:56:42.443285 17898 net.cpp:399] Convolution59 -> Convolution59
I0619 14:56:42.443982 17898 net.cpp:141] Setting up Convolution59
I0619 14:56:42.443994 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.443999 17898 net.cpp:156] Memory required for data: 2203584000
I0619 14:56:42.444006 17898 layer_factory.hpp:77] Creating layer BatchNorm59
I0619 14:56:42.444016 17898 net.cpp:91] Creating Layer BatchNorm59
I0619 14:56:42.444021 17898 net.cpp:425] BatchNorm59 <- Convolution59
I0619 14:56:42.444028 17898 net.cpp:386] BatchNorm59 -> Convolution59 (in-place)
I0619 14:56:42.444273 17898 net.cpp:141] Setting up BatchNorm59
I0619 14:56:42.444283 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.444288 17898 net.cpp:156] Memory required for data: 2207778304
I0619 14:56:42.444298 17898 layer_factory.hpp:77] Creating layer Scale59
I0619 14:56:42.444308 17898 net.cpp:91] Creating Layer Scale59
I0619 14:56:42.444314 17898 net.cpp:425] Scale59 <- Convolution59
I0619 14:56:42.444320 17898 net.cpp:386] Scale59 -> Convolution59 (in-place)
I0619 14:56:42.444363 17898 layer_factory.hpp:77] Creating layer Scale59
I0619 14:56:42.444509 17898 net.cpp:141] Setting up Scale59
I0619 14:56:42.444519 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.444522 17898 net.cpp:156] Memory required for data: 2211972608
I0619 14:56:42.444550 17898 layer_factory.hpp:77] Creating layer Eltwise29
I0619 14:56:42.444561 17898 net.cpp:91] Creating Layer Eltwise29
I0619 14:56:42.444567 17898 net.cpp:425] Eltwise29 <- Eltwise28_ReLU57_0_split_1
I0619 14:56:42.444574 17898 net.cpp:425] Eltwise29 <- Convolution59
I0619 14:56:42.444581 17898 net.cpp:399] Eltwise29 -> Eltwise29
I0619 14:56:42.444609 17898 net.cpp:141] Setting up Eltwise29
I0619 14:56:42.444617 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.444622 17898 net.cpp:156] Memory required for data: 2216166912
I0619 14:56:42.444627 17898 layer_factory.hpp:77] Creating layer ReLU59
I0619 14:56:42.444633 17898 net.cpp:91] Creating Layer ReLU59
I0619 14:56:42.444638 17898 net.cpp:425] ReLU59 <- Eltwise29
I0619 14:56:42.444644 17898 net.cpp:386] ReLU59 -> Eltwise29 (in-place)
I0619 14:56:42.444653 17898 net.cpp:141] Setting up ReLU59
I0619 14:56:42.444658 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.444663 17898 net.cpp:156] Memory required for data: 2220361216
I0619 14:56:42.444667 17898 layer_factory.hpp:77] Creating layer Eltwise29_ReLU59_0_split
I0619 14:56:42.444674 17898 net.cpp:91] Creating Layer Eltwise29_ReLU59_0_split
I0619 14:56:42.444679 17898 net.cpp:425] Eltwise29_ReLU59_0_split <- Eltwise29
I0619 14:56:42.444686 17898 net.cpp:399] Eltwise29_ReLU59_0_split -> Eltwise29_ReLU59_0_split_0
I0619 14:56:42.444694 17898 net.cpp:399] Eltwise29_ReLU59_0_split -> Eltwise29_ReLU59_0_split_1
I0619 14:56:42.444743 17898 net.cpp:141] Setting up Eltwise29_ReLU59_0_split
I0619 14:56:42.444751 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.444756 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.444761 17898 net.cpp:156] Memory required for data: 2228749824
I0619 14:56:42.444766 17898 layer_factory.hpp:77] Creating layer Convolution60
I0619 14:56:42.444777 17898 net.cpp:91] Creating Layer Convolution60
I0619 14:56:42.444782 17898 net.cpp:425] Convolution60 <- Eltwise29_ReLU59_0_split_0
I0619 14:56:42.444789 17898 net.cpp:399] Convolution60 -> Convolution60
I0619 14:56:42.445482 17898 net.cpp:141] Setting up Convolution60
I0619 14:56:42.445492 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.445497 17898 net.cpp:156] Memory required for data: 2232944128
I0619 14:56:42.445505 17898 layer_factory.hpp:77] Creating layer BatchNorm60
I0619 14:56:42.445515 17898 net.cpp:91] Creating Layer BatchNorm60
I0619 14:56:42.445521 17898 net.cpp:425] BatchNorm60 <- Convolution60
I0619 14:56:42.445528 17898 net.cpp:386] BatchNorm60 -> Convolution60 (in-place)
I0619 14:56:42.445776 17898 net.cpp:141] Setting up BatchNorm60
I0619 14:56:42.445786 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.445791 17898 net.cpp:156] Memory required for data: 2237138432
I0619 14:56:42.445801 17898 layer_factory.hpp:77] Creating layer Scale60
I0619 14:56:42.445811 17898 net.cpp:91] Creating Layer Scale60
I0619 14:56:42.445816 17898 net.cpp:425] Scale60 <- Convolution60
I0619 14:56:42.445823 17898 net.cpp:386] Scale60 -> Convolution60 (in-place)
I0619 14:56:42.445868 17898 layer_factory.hpp:77] Creating layer Scale60
I0619 14:56:42.446012 17898 net.cpp:141] Setting up Scale60
I0619 14:56:42.446020 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.446025 17898 net.cpp:156] Memory required for data: 2241332736
I0619 14:56:42.446033 17898 layer_factory.hpp:77] Creating layer ReLU60
I0619 14:56:42.446043 17898 net.cpp:91] Creating Layer ReLU60
I0619 14:56:42.446048 17898 net.cpp:425] ReLU60 <- Convolution60
I0619 14:56:42.446054 17898 net.cpp:386] ReLU60 -> Convolution60 (in-place)
I0619 14:56:42.446061 17898 net.cpp:141] Setting up ReLU60
I0619 14:56:42.446069 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.446072 17898 net.cpp:156] Memory required for data: 2245527040
I0619 14:56:42.446076 17898 layer_factory.hpp:77] Creating layer Convolution61
I0619 14:56:42.446089 17898 net.cpp:91] Creating Layer Convolution61
I0619 14:56:42.446094 17898 net.cpp:425] Convolution61 <- Convolution60
I0619 14:56:42.446117 17898 net.cpp:399] Convolution61 -> Convolution61
I0619 14:56:42.446820 17898 net.cpp:141] Setting up Convolution61
I0619 14:56:42.446830 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.446835 17898 net.cpp:156] Memory required for data: 2249721344
I0619 14:56:42.446843 17898 layer_factory.hpp:77] Creating layer BatchNorm61
I0619 14:56:42.446853 17898 net.cpp:91] Creating Layer BatchNorm61
I0619 14:56:42.446859 17898 net.cpp:425] BatchNorm61 <- Convolution61
I0619 14:56:42.446866 17898 net.cpp:386] BatchNorm61 -> Convolution61 (in-place)
I0619 14:56:42.447115 17898 net.cpp:141] Setting up BatchNorm61
I0619 14:56:42.447124 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.447129 17898 net.cpp:156] Memory required for data: 2253915648
I0619 14:56:42.447137 17898 layer_factory.hpp:77] Creating layer Scale61
I0619 14:56:42.447147 17898 net.cpp:91] Creating Layer Scale61
I0619 14:56:42.447154 17898 net.cpp:425] Scale61 <- Convolution61
I0619 14:56:42.447160 17898 net.cpp:386] Scale61 -> Convolution61 (in-place)
I0619 14:56:42.447208 17898 layer_factory.hpp:77] Creating layer Scale61
I0619 14:56:42.447357 17898 net.cpp:141] Setting up Scale61
I0619 14:56:42.447365 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.447371 17898 net.cpp:156] Memory required for data: 2258109952
I0619 14:56:42.447377 17898 layer_factory.hpp:77] Creating layer Eltwise30
I0619 14:56:42.447387 17898 net.cpp:91] Creating Layer Eltwise30
I0619 14:56:42.447393 17898 net.cpp:425] Eltwise30 <- Eltwise29_ReLU59_0_split_1
I0619 14:56:42.447399 17898 net.cpp:425] Eltwise30 <- Convolution61
I0619 14:56:42.447407 17898 net.cpp:399] Eltwise30 -> Eltwise30
I0619 14:56:42.447432 17898 net.cpp:141] Setting up Eltwise30
I0619 14:56:42.447439 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.447443 17898 net.cpp:156] Memory required for data: 2262304256
I0619 14:56:42.447448 17898 layer_factory.hpp:77] Creating layer ReLU61
I0619 14:56:42.447454 17898 net.cpp:91] Creating Layer ReLU61
I0619 14:56:42.447459 17898 net.cpp:425] ReLU61 <- Eltwise30
I0619 14:56:42.447465 17898 net.cpp:386] ReLU61 -> Eltwise30 (in-place)
I0619 14:56:42.447474 17898 net.cpp:141] Setting up ReLU61
I0619 14:56:42.447479 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.447484 17898 net.cpp:156] Memory required for data: 2266498560
I0619 14:56:42.447487 17898 layer_factory.hpp:77] Creating layer Eltwise30_ReLU61_0_split
I0619 14:56:42.447496 17898 net.cpp:91] Creating Layer Eltwise30_ReLU61_0_split
I0619 14:56:42.447500 17898 net.cpp:425] Eltwise30_ReLU61_0_split <- Eltwise30
I0619 14:56:42.447507 17898 net.cpp:399] Eltwise30_ReLU61_0_split -> Eltwise30_ReLU61_0_split_0
I0619 14:56:42.447516 17898 net.cpp:399] Eltwise30_ReLU61_0_split -> Eltwise30_ReLU61_0_split_1
I0619 14:56:42.447561 17898 net.cpp:141] Setting up Eltwise30_ReLU61_0_split
I0619 14:56:42.447569 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.447576 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.447579 17898 net.cpp:156] Memory required for data: 2274887168
I0619 14:56:42.447584 17898 layer_factory.hpp:77] Creating layer Convolution62
I0619 14:56:42.447594 17898 net.cpp:91] Creating Layer Convolution62
I0619 14:56:42.447599 17898 net.cpp:425] Convolution62 <- Eltwise30_ReLU61_0_split_0
I0619 14:56:42.447607 17898 net.cpp:399] Convolution62 -> Convolution62
I0619 14:56:42.448299 17898 net.cpp:141] Setting up Convolution62
I0619 14:56:42.448309 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.448313 17898 net.cpp:156] Memory required for data: 2279081472
I0619 14:56:42.448323 17898 layer_factory.hpp:77] Creating layer BatchNorm62
I0619 14:56:42.448333 17898 net.cpp:91] Creating Layer BatchNorm62
I0619 14:56:42.448338 17898 net.cpp:425] BatchNorm62 <- Convolution62
I0619 14:56:42.448344 17898 net.cpp:386] BatchNorm62 -> Convolution62 (in-place)
I0619 14:56:42.448590 17898 net.cpp:141] Setting up BatchNorm62
I0619 14:56:42.448602 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.448621 17898 net.cpp:156] Memory required for data: 2283275776
I0619 14:56:42.448633 17898 layer_factory.hpp:77] Creating layer Scale62
I0619 14:56:42.448642 17898 net.cpp:91] Creating Layer Scale62
I0619 14:56:42.448647 17898 net.cpp:425] Scale62 <- Convolution62
I0619 14:56:42.448653 17898 net.cpp:386] Scale62 -> Convolution62 (in-place)
I0619 14:56:42.448700 17898 layer_factory.hpp:77] Creating layer Scale62
I0619 14:56:42.448851 17898 net.cpp:141] Setting up Scale62
I0619 14:56:42.448860 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.448864 17898 net.cpp:156] Memory required for data: 2287470080
I0619 14:56:42.448873 17898 layer_factory.hpp:77] Creating layer ReLU62
I0619 14:56:42.448881 17898 net.cpp:91] Creating Layer ReLU62
I0619 14:56:42.448887 17898 net.cpp:425] ReLU62 <- Convolution62
I0619 14:56:42.448894 17898 net.cpp:386] ReLU62 -> Convolution62 (in-place)
I0619 14:56:42.448901 17898 net.cpp:141] Setting up ReLU62
I0619 14:56:42.448907 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.448912 17898 net.cpp:156] Memory required for data: 2291664384
I0619 14:56:42.448916 17898 layer_factory.hpp:77] Creating layer Convolution63
I0619 14:56:42.448930 17898 net.cpp:91] Creating Layer Convolution63
I0619 14:56:42.448935 17898 net.cpp:425] Convolution63 <- Convolution62
I0619 14:56:42.448945 17898 net.cpp:399] Convolution63 -> Convolution63
I0619 14:56:42.449631 17898 net.cpp:141] Setting up Convolution63
I0619 14:56:42.449642 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.449646 17898 net.cpp:156] Memory required for data: 2295858688
I0619 14:56:42.449654 17898 layer_factory.hpp:77] Creating layer BatchNorm63
I0619 14:56:42.449662 17898 net.cpp:91] Creating Layer BatchNorm63
I0619 14:56:42.449667 17898 net.cpp:425] BatchNorm63 <- Convolution63
I0619 14:56:42.449674 17898 net.cpp:386] BatchNorm63 -> Convolution63 (in-place)
I0619 14:56:42.449923 17898 net.cpp:141] Setting up BatchNorm63
I0619 14:56:42.449931 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.449935 17898 net.cpp:156] Memory required for data: 2300052992
I0619 14:56:42.449945 17898 layer_factory.hpp:77] Creating layer Scale63
I0619 14:56:42.449954 17898 net.cpp:91] Creating Layer Scale63
I0619 14:56:42.449960 17898 net.cpp:425] Scale63 <- Convolution63
I0619 14:56:42.449967 17898 net.cpp:386] Scale63 -> Convolution63 (in-place)
I0619 14:56:42.450011 17898 layer_factory.hpp:77] Creating layer Scale63
I0619 14:56:42.450156 17898 net.cpp:141] Setting up Scale63
I0619 14:56:42.450165 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.450170 17898 net.cpp:156] Memory required for data: 2304247296
I0619 14:56:42.450177 17898 layer_factory.hpp:77] Creating layer Eltwise31
I0619 14:56:42.450191 17898 net.cpp:91] Creating Layer Eltwise31
I0619 14:56:42.450196 17898 net.cpp:425] Eltwise31 <- Eltwise30_ReLU61_0_split_1
I0619 14:56:42.450202 17898 net.cpp:425] Eltwise31 <- Convolution63
I0619 14:56:42.450209 17898 net.cpp:399] Eltwise31 -> Eltwise31
I0619 14:56:42.450234 17898 net.cpp:141] Setting up Eltwise31
I0619 14:56:42.450242 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.450247 17898 net.cpp:156] Memory required for data: 2308441600
I0619 14:56:42.450250 17898 layer_factory.hpp:77] Creating layer ReLU63
I0619 14:56:42.450258 17898 net.cpp:91] Creating Layer ReLU63
I0619 14:56:42.450263 17898 net.cpp:425] ReLU63 <- Eltwise31
I0619 14:56:42.450268 17898 net.cpp:386] ReLU63 -> Eltwise31 (in-place)
I0619 14:56:42.450275 17898 net.cpp:141] Setting up ReLU63
I0619 14:56:42.450281 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.450286 17898 net.cpp:156] Memory required for data: 2312635904
I0619 14:56:42.450290 17898 layer_factory.hpp:77] Creating layer Eltwise31_ReLU63_0_split
I0619 14:56:42.450302 17898 net.cpp:91] Creating Layer Eltwise31_ReLU63_0_split
I0619 14:56:42.450307 17898 net.cpp:425] Eltwise31_ReLU63_0_split <- Eltwise31
I0619 14:56:42.450317 17898 net.cpp:399] Eltwise31_ReLU63_0_split -> Eltwise31_ReLU63_0_split_0
I0619 14:56:42.450338 17898 net.cpp:399] Eltwise31_ReLU63_0_split -> Eltwise31_ReLU63_0_split_1
I0619 14:56:42.450395 17898 net.cpp:141] Setting up Eltwise31_ReLU63_0_split
I0619 14:56:42.450405 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.450412 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.450415 17898 net.cpp:156] Memory required for data: 2321024512
I0619 14:56:42.450420 17898 layer_factory.hpp:77] Creating layer Convolution64
I0619 14:56:42.450430 17898 net.cpp:91] Creating Layer Convolution64
I0619 14:56:42.450436 17898 net.cpp:425] Convolution64 <- Eltwise31_ReLU63_0_split_0
I0619 14:56:42.450444 17898 net.cpp:399] Convolution64 -> Convolution64
I0619 14:56:42.451146 17898 net.cpp:141] Setting up Convolution64
I0619 14:56:42.451159 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.451164 17898 net.cpp:156] Memory required for data: 2325218816
I0619 14:56:42.451172 17898 layer_factory.hpp:77] Creating layer BatchNorm64
I0619 14:56:42.451180 17898 net.cpp:91] Creating Layer BatchNorm64
I0619 14:56:42.451186 17898 net.cpp:425] BatchNorm64 <- Convolution64
I0619 14:56:42.451194 17898 net.cpp:386] BatchNorm64 -> Convolution64 (in-place)
I0619 14:56:42.451442 17898 net.cpp:141] Setting up BatchNorm64
I0619 14:56:42.451452 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.451455 17898 net.cpp:156] Memory required for data: 2329413120
I0619 14:56:42.451465 17898 layer_factory.hpp:77] Creating layer Scale64
I0619 14:56:42.451473 17898 net.cpp:91] Creating Layer Scale64
I0619 14:56:42.451478 17898 net.cpp:425] Scale64 <- Convolution64
I0619 14:56:42.451485 17898 net.cpp:386] Scale64 -> Convolution64 (in-place)
I0619 14:56:42.451529 17898 layer_factory.hpp:77] Creating layer Scale64
I0619 14:56:42.451676 17898 net.cpp:141] Setting up Scale64
I0619 14:56:42.451685 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.451690 17898 net.cpp:156] Memory required for data: 2333607424
I0619 14:56:42.451699 17898 layer_factory.hpp:77] Creating layer ReLU64
I0619 14:56:42.451707 17898 net.cpp:91] Creating Layer ReLU64
I0619 14:56:42.451712 17898 net.cpp:425] ReLU64 <- Convolution64
I0619 14:56:42.451719 17898 net.cpp:386] ReLU64 -> Convolution64 (in-place)
I0619 14:56:42.451727 17898 net.cpp:141] Setting up ReLU64
I0619 14:56:42.451733 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.451737 17898 net.cpp:156] Memory required for data: 2337801728
I0619 14:56:42.451742 17898 layer_factory.hpp:77] Creating layer Convolution65
I0619 14:56:42.451755 17898 net.cpp:91] Creating Layer Convolution65
I0619 14:56:42.451759 17898 net.cpp:425] Convolution65 <- Convolution64
I0619 14:56:42.451768 17898 net.cpp:399] Convolution65 -> Convolution65
I0619 14:56:42.452462 17898 net.cpp:141] Setting up Convolution65
I0619 14:56:42.452472 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.452477 17898 net.cpp:156] Memory required for data: 2341996032
I0619 14:56:42.452486 17898 layer_factory.hpp:77] Creating layer BatchNorm65
I0619 14:56:42.452493 17898 net.cpp:91] Creating Layer BatchNorm65
I0619 14:56:42.452498 17898 net.cpp:425] BatchNorm65 <- Convolution65
I0619 14:56:42.452505 17898 net.cpp:386] BatchNorm65 -> Convolution65 (in-place)
I0619 14:56:42.452752 17898 net.cpp:141] Setting up BatchNorm65
I0619 14:56:42.452761 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.452765 17898 net.cpp:156] Memory required for data: 2346190336
I0619 14:56:42.452777 17898 layer_factory.hpp:77] Creating layer Scale65
I0619 14:56:42.452785 17898 net.cpp:91] Creating Layer Scale65
I0619 14:56:42.452790 17898 net.cpp:425] Scale65 <- Convolution65
I0619 14:56:42.452797 17898 net.cpp:386] Scale65 -> Convolution65 (in-place)
I0619 14:56:42.452844 17898 layer_factory.hpp:77] Creating layer Scale65
I0619 14:56:42.452988 17898 net.cpp:141] Setting up Scale65
I0619 14:56:42.452996 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.453004 17898 net.cpp:156] Memory required for data: 2350384640
I0619 14:56:42.453025 17898 layer_factory.hpp:77] Creating layer Eltwise32
I0619 14:56:42.453035 17898 net.cpp:91] Creating Layer Eltwise32
I0619 14:56:42.453042 17898 net.cpp:425] Eltwise32 <- Eltwise31_ReLU63_0_split_1
I0619 14:56:42.453048 17898 net.cpp:425] Eltwise32 <- Convolution65
I0619 14:56:42.453055 17898 net.cpp:399] Eltwise32 -> Eltwise32
I0619 14:56:42.453081 17898 net.cpp:141] Setting up Eltwise32
I0619 14:56:42.453089 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.453094 17898 net.cpp:156] Memory required for data: 2354578944
I0619 14:56:42.453099 17898 layer_factory.hpp:77] Creating layer ReLU65
I0619 14:56:42.453104 17898 net.cpp:91] Creating Layer ReLU65
I0619 14:56:42.453109 17898 net.cpp:425] ReLU65 <- Eltwise32
I0619 14:56:42.453115 17898 net.cpp:386] ReLU65 -> Eltwise32 (in-place)
I0619 14:56:42.453124 17898 net.cpp:141] Setting up ReLU65
I0619 14:56:42.453130 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.453133 17898 net.cpp:156] Memory required for data: 2358773248
I0619 14:56:42.453138 17898 layer_factory.hpp:77] Creating layer Eltwise32_ReLU65_0_split
I0619 14:56:42.453147 17898 net.cpp:91] Creating Layer Eltwise32_ReLU65_0_split
I0619 14:56:42.453152 17898 net.cpp:425] Eltwise32_ReLU65_0_split <- Eltwise32
I0619 14:56:42.453158 17898 net.cpp:399] Eltwise32_ReLU65_0_split -> Eltwise32_ReLU65_0_split_0
I0619 14:56:42.453166 17898 net.cpp:399] Eltwise32_ReLU65_0_split -> Eltwise32_ReLU65_0_split_1
I0619 14:56:42.453212 17898 net.cpp:141] Setting up Eltwise32_ReLU65_0_split
I0619 14:56:42.453219 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.453225 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.453229 17898 net.cpp:156] Memory required for data: 2367161856
I0619 14:56:42.453234 17898 layer_factory.hpp:77] Creating layer Convolution66
I0619 14:56:42.453244 17898 net.cpp:91] Creating Layer Convolution66
I0619 14:56:42.453249 17898 net.cpp:425] Convolution66 <- Eltwise32_ReLU65_0_split_0
I0619 14:56:42.453261 17898 net.cpp:399] Convolution66 -> Convolution66
I0619 14:56:42.453953 17898 net.cpp:141] Setting up Convolution66
I0619 14:56:42.453963 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.453968 17898 net.cpp:156] Memory required for data: 2371356160
I0619 14:56:42.453975 17898 layer_factory.hpp:77] Creating layer BatchNorm66
I0619 14:56:42.453984 17898 net.cpp:91] Creating Layer BatchNorm66
I0619 14:56:42.453989 17898 net.cpp:425] BatchNorm66 <- Convolution66
I0619 14:56:42.453997 17898 net.cpp:386] BatchNorm66 -> Convolution66 (in-place)
I0619 14:56:42.454243 17898 net.cpp:141] Setting up BatchNorm66
I0619 14:56:42.454252 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.454257 17898 net.cpp:156] Memory required for data: 2375550464
I0619 14:56:42.454267 17898 layer_factory.hpp:77] Creating layer Scale66
I0619 14:56:42.454273 17898 net.cpp:91] Creating Layer Scale66
I0619 14:56:42.454279 17898 net.cpp:425] Scale66 <- Convolution66
I0619 14:56:42.454285 17898 net.cpp:386] Scale66 -> Convolution66 (in-place)
I0619 14:56:42.454329 17898 layer_factory.hpp:77] Creating layer Scale66
I0619 14:56:42.454491 17898 net.cpp:141] Setting up Scale66
I0619 14:56:42.454500 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.454505 17898 net.cpp:156] Memory required for data: 2379744768
I0619 14:56:42.454512 17898 layer_factory.hpp:77] Creating layer ReLU66
I0619 14:56:42.454522 17898 net.cpp:91] Creating Layer ReLU66
I0619 14:56:42.454527 17898 net.cpp:425] ReLU66 <- Convolution66
I0619 14:56:42.454533 17898 net.cpp:386] ReLU66 -> Convolution66 (in-place)
I0619 14:56:42.454540 17898 net.cpp:141] Setting up ReLU66
I0619 14:56:42.454546 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.454550 17898 net.cpp:156] Memory required for data: 2383939072
I0619 14:56:42.454555 17898 layer_factory.hpp:77] Creating layer Convolution67
I0619 14:56:42.454569 17898 net.cpp:91] Creating Layer Convolution67
I0619 14:56:42.454577 17898 net.cpp:425] Convolution67 <- Convolution66
I0619 14:56:42.454599 17898 net.cpp:399] Convolution67 -> Convolution67
I0619 14:56:42.455265 17898 net.cpp:141] Setting up Convolution67
I0619 14:56:42.455274 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.455279 17898 net.cpp:156] Memory required for data: 2388133376
I0619 14:56:42.455286 17898 layer_factory.hpp:77] Creating layer BatchNorm67
I0619 14:56:42.455294 17898 net.cpp:91] Creating Layer BatchNorm67
I0619 14:56:42.455299 17898 net.cpp:425] BatchNorm67 <- Convolution67
I0619 14:56:42.455305 17898 net.cpp:386] BatchNorm67 -> Convolution67 (in-place)
I0619 14:56:42.455541 17898 net.cpp:141] Setting up BatchNorm67
I0619 14:56:42.455549 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.455554 17898 net.cpp:156] Memory required for data: 2392327680
I0619 14:56:42.455564 17898 layer_factory.hpp:77] Creating layer Scale67
I0619 14:56:42.455570 17898 net.cpp:91] Creating Layer Scale67
I0619 14:56:42.455575 17898 net.cpp:425] Scale67 <- Convolution67
I0619 14:56:42.455581 17898 net.cpp:386] Scale67 -> Convolution67 (in-place)
I0619 14:56:42.455623 17898 layer_factory.hpp:77] Creating layer Scale67
I0619 14:56:42.455761 17898 net.cpp:141] Setting up Scale67
I0619 14:56:42.455770 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.455773 17898 net.cpp:156] Memory required for data: 2396521984
I0619 14:56:42.455781 17898 layer_factory.hpp:77] Creating layer Eltwise33
I0619 14:56:42.455790 17898 net.cpp:91] Creating Layer Eltwise33
I0619 14:56:42.455796 17898 net.cpp:425] Eltwise33 <- Eltwise32_ReLU65_0_split_1
I0619 14:56:42.455801 17898 net.cpp:425] Eltwise33 <- Convolution67
I0619 14:56:42.455808 17898 net.cpp:399] Eltwise33 -> Eltwise33
I0619 14:56:42.455832 17898 net.cpp:141] Setting up Eltwise33
I0619 14:56:42.455839 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.455843 17898 net.cpp:156] Memory required for data: 2400716288
I0619 14:56:42.455847 17898 layer_factory.hpp:77] Creating layer ReLU67
I0619 14:56:42.455853 17898 net.cpp:91] Creating Layer ReLU67
I0619 14:56:42.455858 17898 net.cpp:425] ReLU67 <- Eltwise33
I0619 14:56:42.455868 17898 net.cpp:386] ReLU67 -> Eltwise33 (in-place)
I0619 14:56:42.455875 17898 net.cpp:141] Setting up ReLU67
I0619 14:56:42.455881 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.455885 17898 net.cpp:156] Memory required for data: 2404910592
I0619 14:56:42.455889 17898 layer_factory.hpp:77] Creating layer Eltwise33_ReLU67_0_split
I0619 14:56:42.455895 17898 net.cpp:91] Creating Layer Eltwise33_ReLU67_0_split
I0619 14:56:42.455900 17898 net.cpp:425] Eltwise33_ReLU67_0_split <- Eltwise33
I0619 14:56:42.455906 17898 net.cpp:399] Eltwise33_ReLU67_0_split -> Eltwise33_ReLU67_0_split_0
I0619 14:56:42.455914 17898 net.cpp:399] Eltwise33_ReLU67_0_split -> Eltwise33_ReLU67_0_split_1
I0619 14:56:42.455956 17898 net.cpp:141] Setting up Eltwise33_ReLU67_0_split
I0619 14:56:42.455965 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.455970 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.455973 17898 net.cpp:156] Memory required for data: 2413299200
I0619 14:56:42.455977 17898 layer_factory.hpp:77] Creating layer Convolution68
I0619 14:56:42.455987 17898 net.cpp:91] Creating Layer Convolution68
I0619 14:56:42.455992 17898 net.cpp:425] Convolution68 <- Eltwise33_ReLU67_0_split_0
I0619 14:56:42.456001 17898 net.cpp:399] Convolution68 -> Convolution68
I0619 14:56:42.456662 17898 net.cpp:141] Setting up Convolution68
I0619 14:56:42.456672 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.456676 17898 net.cpp:156] Memory required for data: 2417493504
I0619 14:56:42.456684 17898 layer_factory.hpp:77] Creating layer BatchNorm68
I0619 14:56:42.456692 17898 net.cpp:91] Creating Layer BatchNorm68
I0619 14:56:42.456697 17898 net.cpp:425] BatchNorm68 <- Convolution68
I0619 14:56:42.456706 17898 net.cpp:386] BatchNorm68 -> Convolution68 (in-place)
I0619 14:56:42.456940 17898 net.cpp:141] Setting up BatchNorm68
I0619 14:56:42.456953 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.456969 17898 net.cpp:156] Memory required for data: 2421687808
I0619 14:56:42.456979 17898 layer_factory.hpp:77] Creating layer Scale68
I0619 14:56:42.456986 17898 net.cpp:91] Creating Layer Scale68
I0619 14:56:42.456991 17898 net.cpp:425] Scale68 <- Convolution68
I0619 14:56:42.456998 17898 net.cpp:386] Scale68 -> Convolution68 (in-place)
I0619 14:56:42.457042 17898 layer_factory.hpp:77] Creating layer Scale68
I0619 14:56:42.457185 17898 net.cpp:141] Setting up Scale68
I0619 14:56:42.457193 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.457197 17898 net.cpp:156] Memory required for data: 2425882112
I0619 14:56:42.457206 17898 layer_factory.hpp:77] Creating layer ReLU68
I0619 14:56:42.457213 17898 net.cpp:91] Creating Layer ReLU68
I0619 14:56:42.457219 17898 net.cpp:425] ReLU68 <- Convolution68
I0619 14:56:42.457227 17898 net.cpp:386] ReLU68 -> Convolution68 (in-place)
I0619 14:56:42.457234 17898 net.cpp:141] Setting up ReLU68
I0619 14:56:42.457240 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.457244 17898 net.cpp:156] Memory required for data: 2430076416
I0619 14:56:42.457249 17898 layer_factory.hpp:77] Creating layer Convolution69
I0619 14:56:42.457258 17898 net.cpp:91] Creating Layer Convolution69
I0619 14:56:42.457263 17898 net.cpp:425] Convolution69 <- Convolution68
I0619 14:56:42.457273 17898 net.cpp:399] Convolution69 -> Convolution69
I0619 14:56:42.457931 17898 net.cpp:141] Setting up Convolution69
I0619 14:56:42.457942 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.457945 17898 net.cpp:156] Memory required for data: 2434270720
I0619 14:56:42.457953 17898 layer_factory.hpp:77] Creating layer BatchNorm69
I0619 14:56:42.457960 17898 net.cpp:91] Creating Layer BatchNorm69
I0619 14:56:42.457965 17898 net.cpp:425] BatchNorm69 <- Convolution69
I0619 14:56:42.457975 17898 net.cpp:386] BatchNorm69 -> Convolution69 (in-place)
I0619 14:56:42.458209 17898 net.cpp:141] Setting up BatchNorm69
I0619 14:56:42.458216 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.458220 17898 net.cpp:156] Memory required for data: 2438465024
I0619 14:56:42.458230 17898 layer_factory.hpp:77] Creating layer Scale69
I0619 14:56:42.458237 17898 net.cpp:91] Creating Layer Scale69
I0619 14:56:42.458242 17898 net.cpp:425] Scale69 <- Convolution69
I0619 14:56:42.458248 17898 net.cpp:386] Scale69 -> Convolution69 (in-place)
I0619 14:56:42.458288 17898 layer_factory.hpp:77] Creating layer Scale69
I0619 14:56:42.458434 17898 net.cpp:141] Setting up Scale69
I0619 14:56:42.458444 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.458448 17898 net.cpp:156] Memory required for data: 2442659328
I0619 14:56:42.458456 17898 layer_factory.hpp:77] Creating layer Eltwise34
I0619 14:56:42.458467 17898 net.cpp:91] Creating Layer Eltwise34
I0619 14:56:42.458472 17898 net.cpp:425] Eltwise34 <- Eltwise33_ReLU67_0_split_1
I0619 14:56:42.458478 17898 net.cpp:425] Eltwise34 <- Convolution69
I0619 14:56:42.458487 17898 net.cpp:399] Eltwise34 -> Eltwise34
I0619 14:56:42.458508 17898 net.cpp:141] Setting up Eltwise34
I0619 14:56:42.458515 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.458519 17898 net.cpp:156] Memory required for data: 2446853632
I0619 14:56:42.458523 17898 layer_factory.hpp:77] Creating layer ReLU69
I0619 14:56:42.458530 17898 net.cpp:91] Creating Layer ReLU69
I0619 14:56:42.458534 17898 net.cpp:425] ReLU69 <- Eltwise34
I0619 14:56:42.458544 17898 net.cpp:386] ReLU69 -> Eltwise34 (in-place)
I0619 14:56:42.458550 17898 net.cpp:141] Setting up ReLU69
I0619 14:56:42.458556 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.458560 17898 net.cpp:156] Memory required for data: 2451047936
I0619 14:56:42.458564 17898 layer_factory.hpp:77] Creating layer Eltwise34_ReLU69_0_split
I0619 14:56:42.458570 17898 net.cpp:91] Creating Layer Eltwise34_ReLU69_0_split
I0619 14:56:42.458575 17898 net.cpp:425] Eltwise34_ReLU69_0_split <- Eltwise34
I0619 14:56:42.458585 17898 net.cpp:399] Eltwise34_ReLU69_0_split -> Eltwise34_ReLU69_0_split_0
I0619 14:56:42.458606 17898 net.cpp:399] Eltwise34_ReLU69_0_split -> Eltwise34_ReLU69_0_split_1
I0619 14:56:42.458652 17898 net.cpp:141] Setting up Eltwise34_ReLU69_0_split
I0619 14:56:42.458659 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.458665 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.458669 17898 net.cpp:156] Memory required for data: 2459436544
I0619 14:56:42.458673 17898 layer_factory.hpp:77] Creating layer Convolution70
I0619 14:56:42.458683 17898 net.cpp:91] Creating Layer Convolution70
I0619 14:56:42.458688 17898 net.cpp:425] Convolution70 <- Eltwise34_ReLU69_0_split_0
I0619 14:56:42.458698 17898 net.cpp:399] Convolution70 -> Convolution70
I0619 14:56:42.459354 17898 net.cpp:141] Setting up Convolution70
I0619 14:56:42.459364 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.459368 17898 net.cpp:156] Memory required for data: 2463630848
I0619 14:56:42.459377 17898 layer_factory.hpp:77] Creating layer BatchNorm70
I0619 14:56:42.459383 17898 net.cpp:91] Creating Layer BatchNorm70
I0619 14:56:42.459389 17898 net.cpp:425] BatchNorm70 <- Convolution70
I0619 14:56:42.459398 17898 net.cpp:386] BatchNorm70 -> Convolution70 (in-place)
I0619 14:56:42.459631 17898 net.cpp:141] Setting up BatchNorm70
I0619 14:56:42.459640 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.459643 17898 net.cpp:156] Memory required for data: 2467825152
I0619 14:56:42.459653 17898 layer_factory.hpp:77] Creating layer Scale70
I0619 14:56:42.459661 17898 net.cpp:91] Creating Layer Scale70
I0619 14:56:42.459666 17898 net.cpp:425] Scale70 <- Convolution70
I0619 14:56:42.459672 17898 net.cpp:386] Scale70 -> Convolution70 (in-place)
I0619 14:56:42.459713 17898 layer_factory.hpp:77] Creating layer Scale70
I0619 14:56:42.459851 17898 net.cpp:141] Setting up Scale70
I0619 14:56:42.459859 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.459864 17898 net.cpp:156] Memory required for data: 2472019456
I0619 14:56:42.459872 17898 layer_factory.hpp:77] Creating layer ReLU70
I0619 14:56:42.459878 17898 net.cpp:91] Creating Layer ReLU70
I0619 14:56:42.459883 17898 net.cpp:425] ReLU70 <- Convolution70
I0619 14:56:42.459892 17898 net.cpp:386] ReLU70 -> Convolution70 (in-place)
I0619 14:56:42.459899 17898 net.cpp:141] Setting up ReLU70
I0619 14:56:42.459905 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.459909 17898 net.cpp:156] Memory required for data: 2476213760
I0619 14:56:42.459913 17898 layer_factory.hpp:77] Creating layer Convolution71
I0619 14:56:42.459923 17898 net.cpp:91] Creating Layer Convolution71
I0619 14:56:42.459928 17898 net.cpp:425] Convolution71 <- Convolution70
I0619 14:56:42.459936 17898 net.cpp:399] Convolution71 -> Convolution71
I0619 14:56:42.460597 17898 net.cpp:141] Setting up Convolution71
I0619 14:56:42.460608 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.460613 17898 net.cpp:156] Memory required for data: 2480408064
I0619 14:56:42.460620 17898 layer_factory.hpp:77] Creating layer BatchNorm71
I0619 14:56:42.460628 17898 net.cpp:91] Creating Layer BatchNorm71
I0619 14:56:42.460633 17898 net.cpp:425] BatchNorm71 <- Convolution71
I0619 14:56:42.460641 17898 net.cpp:386] BatchNorm71 -> Convolution71 (in-place)
I0619 14:56:42.460872 17898 net.cpp:141] Setting up BatchNorm71
I0619 14:56:42.460880 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.460886 17898 net.cpp:156] Memory required for data: 2484602368
I0619 14:56:42.460893 17898 layer_factory.hpp:77] Creating layer Scale71
I0619 14:56:42.460901 17898 net.cpp:91] Creating Layer Scale71
I0619 14:56:42.460906 17898 net.cpp:425] Scale71 <- Convolution71
I0619 14:56:42.460912 17898 net.cpp:386] Scale71 -> Convolution71 (in-place)
I0619 14:56:42.460953 17898 layer_factory.hpp:77] Creating layer Scale71
I0619 14:56:42.461091 17898 net.cpp:141] Setting up Scale71
I0619 14:56:42.461099 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.461107 17898 net.cpp:156] Memory required for data: 2488796672
I0619 14:56:42.461125 17898 layer_factory.hpp:77] Creating layer Eltwise35
I0619 14:56:42.461135 17898 net.cpp:91] Creating Layer Eltwise35
I0619 14:56:42.461141 17898 net.cpp:425] Eltwise35 <- Eltwise34_ReLU69_0_split_1
I0619 14:56:42.461148 17898 net.cpp:425] Eltwise35 <- Convolution71
I0619 14:56:42.461155 17898 net.cpp:399] Eltwise35 -> Eltwise35
I0619 14:56:42.461179 17898 net.cpp:141] Setting up Eltwise35
I0619 14:56:42.461186 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.461190 17898 net.cpp:156] Memory required for data: 2492990976
I0619 14:56:42.461195 17898 layer_factory.hpp:77] Creating layer ReLU71
I0619 14:56:42.461201 17898 net.cpp:91] Creating Layer ReLU71
I0619 14:56:42.461206 17898 net.cpp:425] ReLU71 <- Eltwise35
I0619 14:56:42.461215 17898 net.cpp:386] ReLU71 -> Eltwise35 (in-place)
I0619 14:56:42.461222 17898 net.cpp:141] Setting up ReLU71
I0619 14:56:42.461227 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.461231 17898 net.cpp:156] Memory required for data: 2497185280
I0619 14:56:42.461236 17898 layer_factory.hpp:77] Creating layer Eltwise35_ReLU71_0_split
I0619 14:56:42.461242 17898 net.cpp:91] Creating Layer Eltwise35_ReLU71_0_split
I0619 14:56:42.461246 17898 net.cpp:425] Eltwise35_ReLU71_0_split <- Eltwise35
I0619 14:56:42.461254 17898 net.cpp:399] Eltwise35_ReLU71_0_split -> Eltwise35_ReLU71_0_split_0
I0619 14:56:42.461262 17898 net.cpp:399] Eltwise35_ReLU71_0_split -> Eltwise35_ReLU71_0_split_1
I0619 14:56:42.461305 17898 net.cpp:141] Setting up Eltwise35_ReLU71_0_split
I0619 14:56:42.461313 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.461318 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.461323 17898 net.cpp:156] Memory required for data: 2505573888
I0619 14:56:42.461328 17898 layer_factory.hpp:77] Creating layer Convolution72
I0619 14:56:42.461336 17898 net.cpp:91] Creating Layer Convolution72
I0619 14:56:42.461341 17898 net.cpp:425] Convolution72 <- Eltwise35_ReLU71_0_split_0
I0619 14:56:42.461357 17898 net.cpp:399] Convolution72 -> Convolution72
I0619 14:56:42.462020 17898 net.cpp:141] Setting up Convolution72
I0619 14:56:42.462030 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.462034 17898 net.cpp:156] Memory required for data: 2509768192
I0619 14:56:42.462043 17898 layer_factory.hpp:77] Creating layer BatchNorm72
I0619 14:56:42.462049 17898 net.cpp:91] Creating Layer BatchNorm72
I0619 14:56:42.462054 17898 net.cpp:425] BatchNorm72 <- Convolution72
I0619 14:56:42.462064 17898 net.cpp:386] BatchNorm72 -> Convolution72 (in-place)
I0619 14:56:42.462298 17898 net.cpp:141] Setting up BatchNorm72
I0619 14:56:42.462307 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.462311 17898 net.cpp:156] Memory required for data: 2513962496
I0619 14:56:42.462321 17898 layer_factory.hpp:77] Creating layer Scale72
I0619 14:56:42.462328 17898 net.cpp:91] Creating Layer Scale72
I0619 14:56:42.462333 17898 net.cpp:425] Scale72 <- Convolution72
I0619 14:56:42.462339 17898 net.cpp:386] Scale72 -> Convolution72 (in-place)
I0619 14:56:42.462388 17898 layer_factory.hpp:77] Creating layer Scale72
I0619 14:56:42.462528 17898 net.cpp:141] Setting up Scale72
I0619 14:56:42.462538 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.462541 17898 net.cpp:156] Memory required for data: 2518156800
I0619 14:56:42.462549 17898 layer_factory.hpp:77] Creating layer ReLU72
I0619 14:56:42.462556 17898 net.cpp:91] Creating Layer ReLU72
I0619 14:56:42.462561 17898 net.cpp:425] ReLU72 <- Convolution72
I0619 14:56:42.462569 17898 net.cpp:386] ReLU72 -> Convolution72 (in-place)
I0619 14:56:42.462576 17898 net.cpp:141] Setting up ReLU72
I0619 14:56:42.462582 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.462586 17898 net.cpp:156] Memory required for data: 2522351104
I0619 14:56:42.462590 17898 layer_factory.hpp:77] Creating layer Convolution73
I0619 14:56:42.462600 17898 net.cpp:91] Creating Layer Convolution73
I0619 14:56:42.462609 17898 net.cpp:425] Convolution73 <- Convolution72
I0619 14:56:42.462631 17898 net.cpp:399] Convolution73 -> Convolution73
I0619 14:56:42.463287 17898 net.cpp:141] Setting up Convolution73
I0619 14:56:42.463297 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.463301 17898 net.cpp:156] Memory required for data: 2526545408
I0619 14:56:42.463310 17898 layer_factory.hpp:77] Creating layer BatchNorm73
I0619 14:56:42.463317 17898 net.cpp:91] Creating Layer BatchNorm73
I0619 14:56:42.463322 17898 net.cpp:425] BatchNorm73 <- Convolution73
I0619 14:56:42.463331 17898 net.cpp:386] BatchNorm73 -> Convolution73 (in-place)
I0619 14:56:42.463568 17898 net.cpp:141] Setting up BatchNorm73
I0619 14:56:42.463577 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.463582 17898 net.cpp:156] Memory required for data: 2530739712
I0619 14:56:42.463590 17898 layer_factory.hpp:77] Creating layer Scale73
I0619 14:56:42.463598 17898 net.cpp:91] Creating Layer Scale73
I0619 14:56:42.463603 17898 net.cpp:425] Scale73 <- Convolution73
I0619 14:56:42.463608 17898 net.cpp:386] Scale73 -> Convolution73 (in-place)
I0619 14:56:42.463650 17898 layer_factory.hpp:77] Creating layer Scale73
I0619 14:56:42.463793 17898 net.cpp:141] Setting up Scale73
I0619 14:56:42.463802 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.463806 17898 net.cpp:156] Memory required for data: 2534934016
I0619 14:56:42.463814 17898 layer_factory.hpp:77] Creating layer Eltwise36
I0619 14:56:42.463821 17898 net.cpp:91] Creating Layer Eltwise36
I0619 14:56:42.463826 17898 net.cpp:425] Eltwise36 <- Eltwise35_ReLU71_0_split_1
I0619 14:56:42.463832 17898 net.cpp:425] Eltwise36 <- Convolution73
I0619 14:56:42.463840 17898 net.cpp:399] Eltwise36 -> Eltwise36
I0619 14:56:42.463862 17898 net.cpp:141] Setting up Eltwise36
I0619 14:56:42.463870 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.463873 17898 net.cpp:156] Memory required for data: 2539128320
I0619 14:56:42.463877 17898 layer_factory.hpp:77] Creating layer ReLU73
I0619 14:56:42.463884 17898 net.cpp:91] Creating Layer ReLU73
I0619 14:56:42.463888 17898 net.cpp:425] ReLU73 <- Eltwise36
I0619 14:56:42.463901 17898 net.cpp:386] ReLU73 -> Eltwise36 (in-place)
I0619 14:56:42.463908 17898 net.cpp:141] Setting up ReLU73
I0619 14:56:42.463914 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.463918 17898 net.cpp:156] Memory required for data: 2543322624
I0619 14:56:42.463922 17898 layer_factory.hpp:77] Creating layer Eltwise36_ReLU73_0_split
I0619 14:56:42.463928 17898 net.cpp:91] Creating Layer Eltwise36_ReLU73_0_split
I0619 14:56:42.463933 17898 net.cpp:425] Eltwise36_ReLU73_0_split <- Eltwise36
I0619 14:56:42.463942 17898 net.cpp:399] Eltwise36_ReLU73_0_split -> Eltwise36_ReLU73_0_split_0
I0619 14:56:42.463949 17898 net.cpp:399] Eltwise36_ReLU73_0_split -> Eltwise36_ReLU73_0_split_1
I0619 14:56:42.463994 17898 net.cpp:141] Setting up Eltwise36_ReLU73_0_split
I0619 14:56:42.464001 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.464006 17898 net.cpp:148] Top shape: 128 32 16 16 (1048576)
I0619 14:56:42.464010 17898 net.cpp:156] Memory required for data: 2551711232
I0619 14:56:42.464015 17898 layer_factory.hpp:77] Creating layer Pooling2
I0619 14:56:42.464022 17898 net.cpp:91] Creating Layer Pooling2
I0619 14:56:42.464027 17898 net.cpp:425] Pooling2 <- Eltwise36_ReLU73_0_split_0
I0619 14:56:42.464033 17898 net.cpp:399] Pooling2 -> Pooling2
I0619 14:56:42.464062 17898 net.cpp:141] Setting up Pooling2
I0619 14:56:42.464071 17898 net.cpp:148] Top shape: 128 32 8 8 (262144)
I0619 14:56:42.464074 17898 net.cpp:156] Memory required for data: 2552759808
I0619 14:56:42.464078 17898 layer_factory.hpp:77] Creating layer Input2
I0619 14:56:42.464087 17898 net.cpp:91] Creating Layer Input2
I0619 14:56:42.464092 17898 net.cpp:399] Input2 -> Input2
I0619 14:56:42.464121 17898 net.cpp:141] Setting up Input2
I0619 14:56:42.464129 17898 net.cpp:148] Top shape: 128 32 8 8 (262144)
I0619 14:56:42.464133 17898 net.cpp:156] Memory required for data: 2553808384
I0619 14:56:42.464153 17898 layer_factory.hpp:77] Creating layer Concat2
I0619 14:56:42.464160 17898 net.cpp:91] Creating Layer Concat2
I0619 14:56:42.464165 17898 net.cpp:425] Concat2 <- Pooling2
I0619 14:56:42.464171 17898 net.cpp:425] Concat2 <- Input2
I0619 14:56:42.464180 17898 net.cpp:399] Concat2 -> Concat2
I0619 14:56:42.464210 17898 net.cpp:141] Setting up Concat2
I0619 14:56:42.464217 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.464221 17898 net.cpp:156] Memory required for data: 2555905536
I0619 14:56:42.464226 17898 layer_factory.hpp:77] Creating layer Convolution74
I0619 14:56:42.464238 17898 net.cpp:91] Creating Layer Convolution74
I0619 14:56:42.464243 17898 net.cpp:425] Convolution74 <- Eltwise36_ReLU73_0_split_1
I0619 14:56:42.464253 17898 net.cpp:399] Convolution74 -> Convolution74
I0619 14:56:42.465302 17898 net.cpp:141] Setting up Convolution74
I0619 14:56:42.465312 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.465317 17898 net.cpp:156] Memory required for data: 2558002688
I0619 14:56:42.465378 17898 layer_factory.hpp:77] Creating layer BatchNorm74
I0619 14:56:42.465387 17898 net.cpp:91] Creating Layer BatchNorm74
I0619 14:56:42.465392 17898 net.cpp:425] BatchNorm74 <- Convolution74
I0619 14:56:42.465400 17898 net.cpp:386] BatchNorm74 -> Convolution74 (in-place)
I0619 14:56:42.465649 17898 net.cpp:141] Setting up BatchNorm74
I0619 14:56:42.465658 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.465662 17898 net.cpp:156] Memory required for data: 2560099840
I0619 14:56:42.465672 17898 layer_factory.hpp:77] Creating layer Scale74
I0619 14:56:42.465679 17898 net.cpp:91] Creating Layer Scale74
I0619 14:56:42.465687 17898 net.cpp:425] Scale74 <- Convolution74
I0619 14:56:42.465693 17898 net.cpp:386] Scale74 -> Convolution74 (in-place)
I0619 14:56:42.465736 17898 layer_factory.hpp:77] Creating layer Scale74
I0619 14:56:42.465881 17898 net.cpp:141] Setting up Scale74
I0619 14:56:42.465890 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.465894 17898 net.cpp:156] Memory required for data: 2562196992
I0619 14:56:42.465903 17898 layer_factory.hpp:77] Creating layer ReLU74
I0619 14:56:42.465909 17898 net.cpp:91] Creating Layer ReLU74
I0619 14:56:42.465914 17898 net.cpp:425] ReLU74 <- Convolution74
I0619 14:56:42.465921 17898 net.cpp:386] ReLU74 -> Convolution74 (in-place)
I0619 14:56:42.465929 17898 net.cpp:141] Setting up ReLU74
I0619 14:56:42.465935 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.465939 17898 net.cpp:156] Memory required for data: 2564294144
I0619 14:56:42.465944 17898 layer_factory.hpp:77] Creating layer Convolution75
I0619 14:56:42.465953 17898 net.cpp:91] Creating Layer Convolution75
I0619 14:56:42.465957 17898 net.cpp:425] Convolution75 <- Convolution74
I0619 14:56:42.465968 17898 net.cpp:399] Convolution75 -> Convolution75
I0619 14:56:42.467737 17898 net.cpp:141] Setting up Convolution75
I0619 14:56:42.467748 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.467752 17898 net.cpp:156] Memory required for data: 2566391296
I0619 14:56:42.467761 17898 layer_factory.hpp:77] Creating layer BatchNorm75
I0619 14:56:42.467768 17898 net.cpp:91] Creating Layer BatchNorm75
I0619 14:56:42.467773 17898 net.cpp:425] BatchNorm75 <- Convolution75
I0619 14:56:42.467782 17898 net.cpp:386] BatchNorm75 -> Convolution75 (in-place)
I0619 14:56:42.468019 17898 net.cpp:141] Setting up BatchNorm75
I0619 14:56:42.468026 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.468030 17898 net.cpp:156] Memory required for data: 2568488448
I0619 14:56:42.468039 17898 layer_factory.hpp:77] Creating layer Scale75
I0619 14:56:42.468046 17898 net.cpp:91] Creating Layer Scale75
I0619 14:56:42.468050 17898 net.cpp:425] Scale75 <- Convolution75
I0619 14:56:42.468056 17898 net.cpp:386] Scale75 -> Convolution75 (in-place)
I0619 14:56:42.468098 17898 layer_factory.hpp:77] Creating layer Scale75
I0619 14:56:42.468238 17898 net.cpp:141] Setting up Scale75
I0619 14:56:42.468250 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.468266 17898 net.cpp:156] Memory required for data: 2570585600
I0619 14:56:42.468274 17898 layer_factory.hpp:77] Creating layer Eltwise37
I0619 14:56:42.468281 17898 net.cpp:91] Creating Layer Eltwise37
I0619 14:56:42.468286 17898 net.cpp:425] Eltwise37 <- Concat2
I0619 14:56:42.468292 17898 net.cpp:425] Eltwise37 <- Convolution75
I0619 14:56:42.468298 17898 net.cpp:399] Eltwise37 -> Eltwise37
I0619 14:56:42.468324 17898 net.cpp:141] Setting up Eltwise37
I0619 14:56:42.468333 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.468336 17898 net.cpp:156] Memory required for data: 2572682752
I0619 14:56:42.468340 17898 layer_factory.hpp:77] Creating layer ReLU75
I0619 14:56:42.468346 17898 net.cpp:91] Creating Layer ReLU75
I0619 14:56:42.468351 17898 net.cpp:425] ReLU75 <- Eltwise37
I0619 14:56:42.468358 17898 net.cpp:386] ReLU75 -> Eltwise37 (in-place)
I0619 14:56:42.468365 17898 net.cpp:141] Setting up ReLU75
I0619 14:56:42.468371 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.468375 17898 net.cpp:156] Memory required for data: 2574779904
I0619 14:56:42.468379 17898 layer_factory.hpp:77] Creating layer Eltwise37_ReLU75_0_split
I0619 14:56:42.468385 17898 net.cpp:91] Creating Layer Eltwise37_ReLU75_0_split
I0619 14:56:42.468389 17898 net.cpp:425] Eltwise37_ReLU75_0_split <- Eltwise37
I0619 14:56:42.468395 17898 net.cpp:399] Eltwise37_ReLU75_0_split -> Eltwise37_ReLU75_0_split_0
I0619 14:56:42.468403 17898 net.cpp:399] Eltwise37_ReLU75_0_split -> Eltwise37_ReLU75_0_split_1
I0619 14:56:42.468446 17898 net.cpp:141] Setting up Eltwise37_ReLU75_0_split
I0619 14:56:42.468453 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.468458 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.468462 17898 net.cpp:156] Memory required for data: 2578974208
I0619 14:56:42.468466 17898 layer_factory.hpp:77] Creating layer Convolution76
I0619 14:56:42.468477 17898 net.cpp:91] Creating Layer Convolution76
I0619 14:56:42.468482 17898 net.cpp:425] Convolution76 <- Eltwise37_ReLU75_0_split_0
I0619 14:56:42.468490 17898 net.cpp:399] Convolution76 -> Convolution76
I0619 14:56:42.470209 17898 net.cpp:141] Setting up Convolution76
I0619 14:56:42.470219 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.470223 17898 net.cpp:156] Memory required for data: 2581071360
I0619 14:56:42.470230 17898 layer_factory.hpp:77] Creating layer BatchNorm76
I0619 14:56:42.470242 17898 net.cpp:91] Creating Layer BatchNorm76
I0619 14:56:42.470247 17898 net.cpp:425] BatchNorm76 <- Convolution76
I0619 14:56:42.470255 17898 net.cpp:386] BatchNorm76 -> Convolution76 (in-place)
I0619 14:56:42.470489 17898 net.cpp:141] Setting up BatchNorm76
I0619 14:56:42.470499 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.470502 17898 net.cpp:156] Memory required for data: 2583168512
I0619 14:56:42.470511 17898 layer_factory.hpp:77] Creating layer Scale76
I0619 14:56:42.470520 17898 net.cpp:91] Creating Layer Scale76
I0619 14:56:42.470526 17898 net.cpp:425] Scale76 <- Convolution76
I0619 14:56:42.470532 17898 net.cpp:386] Scale76 -> Convolution76 (in-place)
I0619 14:56:42.470573 17898 layer_factory.hpp:77] Creating layer Scale76
I0619 14:56:42.470717 17898 net.cpp:141] Setting up Scale76
I0619 14:56:42.470726 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.470731 17898 net.cpp:156] Memory required for data: 2585265664
I0619 14:56:42.470737 17898 layer_factory.hpp:77] Creating layer ReLU76
I0619 14:56:42.470746 17898 net.cpp:91] Creating Layer ReLU76
I0619 14:56:42.470752 17898 net.cpp:425] ReLU76 <- Convolution76
I0619 14:56:42.470757 17898 net.cpp:386] ReLU76 -> Convolution76 (in-place)
I0619 14:56:42.470765 17898 net.cpp:141] Setting up ReLU76
I0619 14:56:42.470770 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.470774 17898 net.cpp:156] Memory required for data: 2587362816
I0619 14:56:42.470778 17898 layer_factory.hpp:77] Creating layer Convolution77
I0619 14:56:42.470789 17898 net.cpp:91] Creating Layer Convolution77
I0619 14:56:42.470798 17898 net.cpp:425] Convolution77 <- Convolution76
I0619 14:56:42.470819 17898 net.cpp:399] Convolution77 -> Convolution77
I0619 14:56:42.472534 17898 net.cpp:141] Setting up Convolution77
I0619 14:56:42.472544 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.472548 17898 net.cpp:156] Memory required for data: 2589459968
I0619 14:56:42.472555 17898 layer_factory.hpp:77] Creating layer BatchNorm77
I0619 14:56:42.472563 17898 net.cpp:91] Creating Layer BatchNorm77
I0619 14:56:42.472568 17898 net.cpp:425] BatchNorm77 <- Convolution77
I0619 14:56:42.472573 17898 net.cpp:386] BatchNorm77 -> Convolution77 (in-place)
I0619 14:56:42.472803 17898 net.cpp:141] Setting up BatchNorm77
I0619 14:56:42.472812 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.472815 17898 net.cpp:156] Memory required for data: 2591557120
I0619 14:56:42.472825 17898 layer_factory.hpp:77] Creating layer Scale77
I0619 14:56:42.472832 17898 net.cpp:91] Creating Layer Scale77
I0619 14:56:42.472837 17898 net.cpp:425] Scale77 <- Convolution77
I0619 14:56:42.472843 17898 net.cpp:386] Scale77 -> Convolution77 (in-place)
I0619 14:56:42.472885 17898 layer_factory.hpp:77] Creating layer Scale77
I0619 14:56:42.473021 17898 net.cpp:141] Setting up Scale77
I0619 14:56:42.473028 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.473032 17898 net.cpp:156] Memory required for data: 2593654272
I0619 14:56:42.473039 17898 layer_factory.hpp:77] Creating layer Eltwise38
I0619 14:56:42.473047 17898 net.cpp:91] Creating Layer Eltwise38
I0619 14:56:42.473053 17898 net.cpp:425] Eltwise38 <- Eltwise37_ReLU75_0_split_1
I0619 14:56:42.473058 17898 net.cpp:425] Eltwise38 <- Convolution77
I0619 14:56:42.473065 17898 net.cpp:399] Eltwise38 -> Eltwise38
I0619 14:56:42.473086 17898 net.cpp:141] Setting up Eltwise38
I0619 14:56:42.473093 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.473096 17898 net.cpp:156] Memory required for data: 2595751424
I0619 14:56:42.473100 17898 layer_factory.hpp:77] Creating layer ReLU77
I0619 14:56:42.473109 17898 net.cpp:91] Creating Layer ReLU77
I0619 14:56:42.473114 17898 net.cpp:425] ReLU77 <- Eltwise38
I0619 14:56:42.473121 17898 net.cpp:386] ReLU77 -> Eltwise38 (in-place)
I0619 14:56:42.473129 17898 net.cpp:141] Setting up ReLU77
I0619 14:56:42.473134 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.473139 17898 net.cpp:156] Memory required for data: 2597848576
I0619 14:56:42.473142 17898 layer_factory.hpp:77] Creating layer Eltwise38_ReLU77_0_split
I0619 14:56:42.473148 17898 net.cpp:91] Creating Layer Eltwise38_ReLU77_0_split
I0619 14:56:42.473152 17898 net.cpp:425] Eltwise38_ReLU77_0_split <- Eltwise38
I0619 14:56:42.473158 17898 net.cpp:399] Eltwise38_ReLU77_0_split -> Eltwise38_ReLU77_0_split_0
I0619 14:56:42.473165 17898 net.cpp:399] Eltwise38_ReLU77_0_split -> Eltwise38_ReLU77_0_split_1
I0619 14:56:42.473208 17898 net.cpp:141] Setting up Eltwise38_ReLU77_0_split
I0619 14:56:42.473215 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.473220 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.473224 17898 net.cpp:156] Memory required for data: 2602042880
I0619 14:56:42.473228 17898 layer_factory.hpp:77] Creating layer Convolution78
I0619 14:56:42.473239 17898 net.cpp:91] Creating Layer Convolution78
I0619 14:56:42.473243 17898 net.cpp:425] Convolution78 <- Eltwise38_ReLU77_0_split_0
I0619 14:56:42.473251 17898 net.cpp:399] Convolution78 -> Convolution78
I0619 14:56:42.474972 17898 net.cpp:141] Setting up Convolution78
I0619 14:56:42.474982 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.474985 17898 net.cpp:156] Memory required for data: 2604140032
I0619 14:56:42.474993 17898 layer_factory.hpp:77] Creating layer BatchNorm78
I0619 14:56:42.475003 17898 net.cpp:91] Creating Layer BatchNorm78
I0619 14:56:42.475008 17898 net.cpp:425] BatchNorm78 <- Convolution78
I0619 14:56:42.475016 17898 net.cpp:386] BatchNorm78 -> Convolution78 (in-place)
I0619 14:56:42.475252 17898 net.cpp:141] Setting up BatchNorm78
I0619 14:56:42.475265 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.475281 17898 net.cpp:156] Memory required for data: 2606237184
I0619 14:56:42.475291 17898 layer_factory.hpp:77] Creating layer Scale78
I0619 14:56:42.475301 17898 net.cpp:91] Creating Layer Scale78
I0619 14:56:42.475306 17898 net.cpp:425] Scale78 <- Convolution78
I0619 14:56:42.475313 17898 net.cpp:386] Scale78 -> Convolution78 (in-place)
I0619 14:56:42.475359 17898 layer_factory.hpp:77] Creating layer Scale78
I0619 14:56:42.475502 17898 net.cpp:141] Setting up Scale78
I0619 14:56:42.475509 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.475513 17898 net.cpp:156] Memory required for data: 2608334336
I0619 14:56:42.475522 17898 layer_factory.hpp:77] Creating layer ReLU78
I0619 14:56:42.475529 17898 net.cpp:91] Creating Layer ReLU78
I0619 14:56:42.475534 17898 net.cpp:425] ReLU78 <- Convolution78
I0619 14:56:42.475540 17898 net.cpp:386] ReLU78 -> Convolution78 (in-place)
I0619 14:56:42.475548 17898 net.cpp:141] Setting up ReLU78
I0619 14:56:42.475553 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.475556 17898 net.cpp:156] Memory required for data: 2610431488
I0619 14:56:42.475561 17898 layer_factory.hpp:77] Creating layer Convolution79
I0619 14:56:42.475572 17898 net.cpp:91] Creating Layer Convolution79
I0619 14:56:42.475577 17898 net.cpp:425] Convolution79 <- Convolution78
I0619 14:56:42.475584 17898 net.cpp:399] Convolution79 -> Convolution79
I0619 14:56:42.477299 17898 net.cpp:141] Setting up Convolution79
I0619 14:56:42.477309 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.477313 17898 net.cpp:156] Memory required for data: 2612528640
I0619 14:56:42.477320 17898 layer_factory.hpp:77] Creating layer BatchNorm79
I0619 14:56:42.477329 17898 net.cpp:91] Creating Layer BatchNorm79
I0619 14:56:42.477334 17898 net.cpp:425] BatchNorm79 <- Convolution79
I0619 14:56:42.477341 17898 net.cpp:386] BatchNorm79 -> Convolution79 (in-place)
I0619 14:56:42.478195 17898 net.cpp:141] Setting up BatchNorm79
I0619 14:56:42.478210 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.478215 17898 net.cpp:156] Memory required for data: 2614625792
I0619 14:56:42.478225 17898 layer_factory.hpp:77] Creating layer Scale79
I0619 14:56:42.478235 17898 net.cpp:91] Creating Layer Scale79
I0619 14:56:42.478240 17898 net.cpp:425] Scale79 <- Convolution79
I0619 14:56:42.478248 17898 net.cpp:386] Scale79 -> Convolution79 (in-place)
I0619 14:56:42.478296 17898 layer_factory.hpp:77] Creating layer Scale79
I0619 14:56:42.478444 17898 net.cpp:141] Setting up Scale79
I0619 14:56:42.478454 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.478458 17898 net.cpp:156] Memory required for data: 2616722944
I0619 14:56:42.478466 17898 layer_factory.hpp:77] Creating layer Eltwise39
I0619 14:56:42.478473 17898 net.cpp:91] Creating Layer Eltwise39
I0619 14:56:42.478478 17898 net.cpp:425] Eltwise39 <- Eltwise38_ReLU77_0_split_1
I0619 14:56:42.478484 17898 net.cpp:425] Eltwise39 <- Convolution79
I0619 14:56:42.478492 17898 net.cpp:399] Eltwise39 -> Eltwise39
I0619 14:56:42.478518 17898 net.cpp:141] Setting up Eltwise39
I0619 14:56:42.478524 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.478528 17898 net.cpp:156] Memory required for data: 2618820096
I0619 14:56:42.478541 17898 layer_factory.hpp:77] Creating layer ReLU79
I0619 14:56:42.478548 17898 net.cpp:91] Creating Layer ReLU79
I0619 14:56:42.478552 17898 net.cpp:425] ReLU79 <- Eltwise39
I0619 14:56:42.478559 17898 net.cpp:386] ReLU79 -> Eltwise39 (in-place)
I0619 14:56:42.478566 17898 net.cpp:141] Setting up ReLU79
I0619 14:56:42.478572 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.478576 17898 net.cpp:156] Memory required for data: 2620917248
I0619 14:56:42.478580 17898 layer_factory.hpp:77] Creating layer Eltwise39_ReLU79_0_split
I0619 14:56:42.478586 17898 net.cpp:91] Creating Layer Eltwise39_ReLU79_0_split
I0619 14:56:42.478590 17898 net.cpp:425] Eltwise39_ReLU79_0_split <- Eltwise39
I0619 14:56:42.478600 17898 net.cpp:399] Eltwise39_ReLU79_0_split -> Eltwise39_ReLU79_0_split_0
I0619 14:56:42.478622 17898 net.cpp:399] Eltwise39_ReLU79_0_split -> Eltwise39_ReLU79_0_split_1
I0619 14:56:42.478664 17898 net.cpp:141] Setting up Eltwise39_ReLU79_0_split
I0619 14:56:42.478672 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.478677 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.478680 17898 net.cpp:156] Memory required for data: 2625111552
I0619 14:56:42.478684 17898 layer_factory.hpp:77] Creating layer Convolution80
I0619 14:56:42.478695 17898 net.cpp:91] Creating Layer Convolution80
I0619 14:56:42.478700 17898 net.cpp:425] Convolution80 <- Eltwise39_ReLU79_0_split_0
I0619 14:56:42.478708 17898 net.cpp:399] Convolution80 -> Convolution80
I0619 14:56:42.480931 17898 net.cpp:141] Setting up Convolution80
I0619 14:56:42.480947 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.480952 17898 net.cpp:156] Memory required for data: 2627208704
I0619 14:56:42.480959 17898 layer_factory.hpp:77] Creating layer BatchNorm80
I0619 14:56:42.480967 17898 net.cpp:91] Creating Layer BatchNorm80
I0619 14:56:42.480973 17898 net.cpp:425] BatchNorm80 <- Convolution80
I0619 14:56:42.480981 17898 net.cpp:386] BatchNorm80 -> Convolution80 (in-place)
I0619 14:56:42.481210 17898 net.cpp:141] Setting up BatchNorm80
I0619 14:56:42.481218 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.481222 17898 net.cpp:156] Memory required for data: 2629305856
I0619 14:56:42.481232 17898 layer_factory.hpp:77] Creating layer Scale80
I0619 14:56:42.481240 17898 net.cpp:91] Creating Layer Scale80
I0619 14:56:42.481245 17898 net.cpp:425] Scale80 <- Convolution80
I0619 14:56:42.481253 17898 net.cpp:386] Scale80 -> Convolution80 (in-place)
I0619 14:56:42.481293 17898 layer_factory.hpp:77] Creating layer Scale80
I0619 14:56:42.481431 17898 net.cpp:141] Setting up Scale80
I0619 14:56:42.481438 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.481442 17898 net.cpp:156] Memory required for data: 2631403008
I0619 14:56:42.481449 17898 layer_factory.hpp:77] Creating layer ReLU80
I0619 14:56:42.481456 17898 net.cpp:91] Creating Layer ReLU80
I0619 14:56:42.481461 17898 net.cpp:425] ReLU80 <- Convolution80
I0619 14:56:42.481467 17898 net.cpp:386] ReLU80 -> Convolution80 (in-place)
I0619 14:56:42.481473 17898 net.cpp:141] Setting up ReLU80
I0619 14:56:42.481478 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.481482 17898 net.cpp:156] Memory required for data: 2633500160
I0619 14:56:42.481487 17898 layer_factory.hpp:77] Creating layer Convolution81
I0619 14:56:42.481498 17898 net.cpp:91] Creating Layer Convolution81
I0619 14:56:42.481501 17898 net.cpp:425] Convolution81 <- Convolution80
I0619 14:56:42.481510 17898 net.cpp:399] Convolution81 -> Convolution81
I0619 14:56:42.483144 17898 net.cpp:141] Setting up Convolution81
I0619 14:56:42.483155 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.483158 17898 net.cpp:156] Memory required for data: 2635597312
I0619 14:56:42.483165 17898 layer_factory.hpp:77] Creating layer BatchNorm81
I0619 14:56:42.483175 17898 net.cpp:91] Creating Layer BatchNorm81
I0619 14:56:42.483180 17898 net.cpp:425] BatchNorm81 <- Convolution81
I0619 14:56:42.483187 17898 net.cpp:386] BatchNorm81 -> Convolution81 (in-place)
I0619 14:56:42.483410 17898 net.cpp:141] Setting up BatchNorm81
I0619 14:56:42.483418 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.483422 17898 net.cpp:156] Memory required for data: 2637694464
I0619 14:56:42.483430 17898 layer_factory.hpp:77] Creating layer Scale81
I0619 14:56:42.483440 17898 net.cpp:91] Creating Layer Scale81
I0619 14:56:42.483445 17898 net.cpp:425] Scale81 <- Convolution81
I0619 14:56:42.483451 17898 net.cpp:386] Scale81 -> Convolution81 (in-place)
I0619 14:56:42.483491 17898 layer_factory.hpp:77] Creating layer Scale81
I0619 14:56:42.483623 17898 net.cpp:141] Setting up Scale81
I0619 14:56:42.483631 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.483635 17898 net.cpp:156] Memory required for data: 2639791616
I0619 14:56:42.483659 17898 layer_factory.hpp:77] Creating layer Eltwise40
I0619 14:56:42.483671 17898 net.cpp:91] Creating Layer Eltwise40
I0619 14:56:42.483677 17898 net.cpp:425] Eltwise40 <- Eltwise39_ReLU79_0_split_1
I0619 14:56:42.483683 17898 net.cpp:425] Eltwise40 <- Convolution81
I0619 14:56:42.483690 17898 net.cpp:399] Eltwise40 -> Eltwise40
I0619 14:56:42.483716 17898 net.cpp:141] Setting up Eltwise40
I0619 14:56:42.483722 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.483726 17898 net.cpp:156] Memory required for data: 2641888768
I0619 14:56:42.483731 17898 layer_factory.hpp:77] Creating layer ReLU81
I0619 14:56:42.483736 17898 net.cpp:91] Creating Layer ReLU81
I0619 14:56:42.483741 17898 net.cpp:425] ReLU81 <- Eltwise40
I0619 14:56:42.483747 17898 net.cpp:386] ReLU81 -> Eltwise40 (in-place)
I0619 14:56:42.483753 17898 net.cpp:141] Setting up ReLU81
I0619 14:56:42.483758 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.483762 17898 net.cpp:156] Memory required for data: 2643985920
I0619 14:56:42.483767 17898 layer_factory.hpp:77] Creating layer Eltwise40_ReLU81_0_split
I0619 14:56:42.483774 17898 net.cpp:91] Creating Layer Eltwise40_ReLU81_0_split
I0619 14:56:42.483778 17898 net.cpp:425] Eltwise40_ReLU81_0_split <- Eltwise40
I0619 14:56:42.483784 17898 net.cpp:399] Eltwise40_ReLU81_0_split -> Eltwise40_ReLU81_0_split_0
I0619 14:56:42.483791 17898 net.cpp:399] Eltwise40_ReLU81_0_split -> Eltwise40_ReLU81_0_split_1
I0619 14:56:42.483832 17898 net.cpp:141] Setting up Eltwise40_ReLU81_0_split
I0619 14:56:42.483839 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.483844 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.483849 17898 net.cpp:156] Memory required for data: 2648180224
I0619 14:56:42.483852 17898 layer_factory.hpp:77] Creating layer Convolution82
I0619 14:56:42.483862 17898 net.cpp:91] Creating Layer Convolution82
I0619 14:56:42.483866 17898 net.cpp:425] Convolution82 <- Eltwise40_ReLU81_0_split_0
I0619 14:56:42.483875 17898 net.cpp:399] Convolution82 -> Convolution82
I0619 14:56:42.485502 17898 net.cpp:141] Setting up Convolution82
I0619 14:56:42.485513 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.485517 17898 net.cpp:156] Memory required for data: 2650277376
I0619 14:56:42.485524 17898 layer_factory.hpp:77] Creating layer BatchNorm82
I0619 14:56:42.485532 17898 net.cpp:91] Creating Layer BatchNorm82
I0619 14:56:42.485537 17898 net.cpp:425] BatchNorm82 <- Convolution82
I0619 14:56:42.485543 17898 net.cpp:386] BatchNorm82 -> Convolution82 (in-place)
I0619 14:56:42.485769 17898 net.cpp:141] Setting up BatchNorm82
I0619 14:56:42.485776 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.485780 17898 net.cpp:156] Memory required for data: 2652374528
I0619 14:56:42.485788 17898 layer_factory.hpp:77] Creating layer Scale82
I0619 14:56:42.485795 17898 net.cpp:91] Creating Layer Scale82
I0619 14:56:42.485800 17898 net.cpp:425] Scale82 <- Convolution82
I0619 14:56:42.485806 17898 net.cpp:386] Scale82 -> Convolution82 (in-place)
I0619 14:56:42.485848 17898 layer_factory.hpp:77] Creating layer Scale82
I0619 14:56:42.485985 17898 net.cpp:141] Setting up Scale82
I0619 14:56:42.485994 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.485998 17898 net.cpp:156] Memory required for data: 2654471680
I0619 14:56:42.486006 17898 layer_factory.hpp:77] Creating layer ReLU82
I0619 14:56:42.486011 17898 net.cpp:91] Creating Layer ReLU82
I0619 14:56:42.486016 17898 net.cpp:425] ReLU82 <- Convolution82
I0619 14:56:42.486021 17898 net.cpp:386] ReLU82 -> Convolution82 (in-place)
I0619 14:56:42.486028 17898 net.cpp:141] Setting up ReLU82
I0619 14:56:42.486034 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.486037 17898 net.cpp:156] Memory required for data: 2656568832
I0619 14:56:42.486042 17898 layer_factory.hpp:77] Creating layer Convolution83
I0619 14:56:42.486053 17898 net.cpp:91] Creating Layer Convolution83
I0619 14:56:42.486057 17898 net.cpp:425] Convolution83 <- Convolution82
I0619 14:56:42.486068 17898 net.cpp:399] Convolution83 -> Convolution83
I0619 14:56:42.487715 17898 net.cpp:141] Setting up Convolution83
I0619 14:56:42.487726 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.487730 17898 net.cpp:156] Memory required for data: 2658665984
I0619 14:56:42.487738 17898 layer_factory.hpp:77] Creating layer BatchNorm83
I0619 14:56:42.487747 17898 net.cpp:91] Creating Layer BatchNorm83
I0619 14:56:42.487752 17898 net.cpp:425] BatchNorm83 <- Convolution83
I0619 14:56:42.487759 17898 net.cpp:386] BatchNorm83 -> Convolution83 (in-place)
I0619 14:56:42.487988 17898 net.cpp:141] Setting up BatchNorm83
I0619 14:56:42.487996 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.488000 17898 net.cpp:156] Memory required for data: 2660763136
I0619 14:56:42.488009 17898 layer_factory.hpp:77] Creating layer Scale83
I0619 14:56:42.488018 17898 net.cpp:91] Creating Layer Scale83
I0619 14:56:42.488023 17898 net.cpp:425] Scale83 <- Convolution83
I0619 14:56:42.488029 17898 net.cpp:386] Scale83 -> Convolution83 (in-place)
I0619 14:56:42.488067 17898 layer_factory.hpp:77] Creating layer Scale83
I0619 14:56:42.488203 17898 net.cpp:141] Setting up Scale83
I0619 14:56:42.488210 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.488214 17898 net.cpp:156] Memory required for data: 2662860288
I0619 14:56:42.488221 17898 layer_factory.hpp:77] Creating layer Eltwise41
I0619 14:56:42.488227 17898 net.cpp:91] Creating Layer Eltwise41
I0619 14:56:42.488232 17898 net.cpp:425] Eltwise41 <- Eltwise40_ReLU81_0_split_1
I0619 14:56:42.488240 17898 net.cpp:425] Eltwise41 <- Convolution83
I0619 14:56:42.488246 17898 net.cpp:399] Eltwise41 -> Eltwise41
I0619 14:56:42.488266 17898 net.cpp:141] Setting up Eltwise41
I0619 14:56:42.488275 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.488278 17898 net.cpp:156] Memory required for data: 2664957440
I0619 14:56:42.488282 17898 layer_factory.hpp:77] Creating layer ReLU83
I0619 14:56:42.488288 17898 net.cpp:91] Creating Layer ReLU83
I0619 14:56:42.488292 17898 net.cpp:425] ReLU83 <- Eltwise41
I0619 14:56:42.488298 17898 net.cpp:386] ReLU83 -> Eltwise41 (in-place)
I0619 14:56:42.488304 17898 net.cpp:141] Setting up ReLU83
I0619 14:56:42.488309 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.488313 17898 net.cpp:156] Memory required for data: 2667054592
I0619 14:56:42.488317 17898 layer_factory.hpp:77] Creating layer Eltwise41_ReLU83_0_split
I0619 14:56:42.488323 17898 net.cpp:91] Creating Layer Eltwise41_ReLU83_0_split
I0619 14:56:42.488327 17898 net.cpp:425] Eltwise41_ReLU83_0_split <- Eltwise41
I0619 14:56:42.488335 17898 net.cpp:399] Eltwise41_ReLU83_0_split -> Eltwise41_ReLU83_0_split_0
I0619 14:56:42.488343 17898 net.cpp:399] Eltwise41_ReLU83_0_split -> Eltwise41_ReLU83_0_split_1
I0619 14:56:42.488380 17898 net.cpp:141] Setting up Eltwise41_ReLU83_0_split
I0619 14:56:42.488389 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.488394 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.488399 17898 net.cpp:156] Memory required for data: 2671248896
I0619 14:56:42.488402 17898 layer_factory.hpp:77] Creating layer Convolution84
I0619 14:56:42.488411 17898 net.cpp:91] Creating Layer Convolution84
I0619 14:56:42.488415 17898 net.cpp:425] Convolution84 <- Eltwise41_ReLU83_0_split_0
I0619 14:56:42.488422 17898 net.cpp:399] Convolution84 -> Convolution84
I0619 14:56:42.490047 17898 net.cpp:141] Setting up Convolution84
I0619 14:56:42.490057 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.490061 17898 net.cpp:156] Memory required for data: 2673346048
I0619 14:56:42.490068 17898 layer_factory.hpp:77] Creating layer BatchNorm84
I0619 14:56:42.490077 17898 net.cpp:91] Creating Layer BatchNorm84
I0619 14:56:42.490082 17898 net.cpp:425] BatchNorm84 <- Convolution84
I0619 14:56:42.490088 17898 net.cpp:386] BatchNorm84 -> Convolution84 (in-place)
I0619 14:56:42.490309 17898 net.cpp:141] Setting up BatchNorm84
I0619 14:56:42.490317 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.490324 17898 net.cpp:156] Memory required for data: 2675443200
I0619 14:56:42.490345 17898 layer_factory.hpp:77] Creating layer Scale84
I0619 14:56:42.490358 17898 net.cpp:91] Creating Layer Scale84
I0619 14:56:42.490365 17898 net.cpp:425] Scale84 <- Convolution84
I0619 14:56:42.490370 17898 net.cpp:386] Scale84 -> Convolution84 (in-place)
I0619 14:56:42.490417 17898 layer_factory.hpp:77] Creating layer Scale84
I0619 14:56:42.490550 17898 net.cpp:141] Setting up Scale84
I0619 14:56:42.490558 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.490562 17898 net.cpp:156] Memory required for data: 2677540352
I0619 14:56:42.490569 17898 layer_factory.hpp:77] Creating layer ReLU84
I0619 14:56:42.490578 17898 net.cpp:91] Creating Layer ReLU84
I0619 14:56:42.490583 17898 net.cpp:425] ReLU84 <- Convolution84
I0619 14:56:42.490589 17898 net.cpp:386] ReLU84 -> Convolution84 (in-place)
I0619 14:56:42.490597 17898 net.cpp:141] Setting up ReLU84
I0619 14:56:42.490602 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.490605 17898 net.cpp:156] Memory required for data: 2679637504
I0619 14:56:42.490609 17898 layer_factory.hpp:77] Creating layer Convolution85
I0619 14:56:42.490619 17898 net.cpp:91] Creating Layer Convolution85
I0619 14:56:42.490624 17898 net.cpp:425] Convolution85 <- Convolution84
I0619 14:56:42.490631 17898 net.cpp:399] Convolution85 -> Convolution85
I0619 14:56:42.492254 17898 net.cpp:141] Setting up Convolution85
I0619 14:56:42.492264 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.492267 17898 net.cpp:156] Memory required for data: 2681734656
I0619 14:56:42.492277 17898 layer_factory.hpp:77] Creating layer BatchNorm85
I0619 14:56:42.492285 17898 net.cpp:91] Creating Layer BatchNorm85
I0619 14:56:42.492288 17898 net.cpp:425] BatchNorm85 <- Convolution85
I0619 14:56:42.492296 17898 net.cpp:386] BatchNorm85 -> Convolution85 (in-place)
I0619 14:56:42.492521 17898 net.cpp:141] Setting up BatchNorm85
I0619 14:56:42.492528 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.492532 17898 net.cpp:156] Memory required for data: 2683831808
I0619 14:56:42.492542 17898 layer_factory.hpp:77] Creating layer Scale85
I0619 14:56:42.492548 17898 net.cpp:91] Creating Layer Scale85
I0619 14:56:42.492552 17898 net.cpp:425] Scale85 <- Convolution85
I0619 14:56:42.492560 17898 net.cpp:386] Scale85 -> Convolution85 (in-place)
I0619 14:56:42.492597 17898 layer_factory.hpp:77] Creating layer Scale85
I0619 14:56:42.492729 17898 net.cpp:141] Setting up Scale85
I0619 14:56:42.492738 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.492741 17898 net.cpp:156] Memory required for data: 2685928960
I0619 14:56:42.492748 17898 layer_factory.hpp:77] Creating layer Eltwise42
I0619 14:56:42.492754 17898 net.cpp:91] Creating Layer Eltwise42
I0619 14:56:42.492759 17898 net.cpp:425] Eltwise42 <- Eltwise41_ReLU83_0_split_1
I0619 14:56:42.492765 17898 net.cpp:425] Eltwise42 <- Convolution85
I0619 14:56:42.492774 17898 net.cpp:399] Eltwise42 -> Eltwise42
I0619 14:56:42.492794 17898 net.cpp:141] Setting up Eltwise42
I0619 14:56:42.492799 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.492804 17898 net.cpp:156] Memory required for data: 2688026112
I0619 14:56:42.492807 17898 layer_factory.hpp:77] Creating layer ReLU85
I0619 14:56:42.492815 17898 net.cpp:91] Creating Layer ReLU85
I0619 14:56:42.492820 17898 net.cpp:425] ReLU85 <- Eltwise42
I0619 14:56:42.492825 17898 net.cpp:386] ReLU85 -> Eltwise42 (in-place)
I0619 14:56:42.492831 17898 net.cpp:141] Setting up ReLU85
I0619 14:56:42.492836 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.492841 17898 net.cpp:156] Memory required for data: 2690123264
I0619 14:56:42.492844 17898 layer_factory.hpp:77] Creating layer Eltwise42_ReLU85_0_split
I0619 14:56:42.492851 17898 net.cpp:91] Creating Layer Eltwise42_ReLU85_0_split
I0619 14:56:42.492853 17898 net.cpp:425] Eltwise42_ReLU85_0_split <- Eltwise42
I0619 14:56:42.492861 17898 net.cpp:399] Eltwise42_ReLU85_0_split -> Eltwise42_ReLU85_0_split_0
I0619 14:56:42.492871 17898 net.cpp:399] Eltwise42_ReLU85_0_split -> Eltwise42_ReLU85_0_split_1
I0619 14:56:42.492926 17898 net.cpp:141] Setting up Eltwise42_ReLU85_0_split
I0619 14:56:42.492934 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.492939 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.492944 17898 net.cpp:156] Memory required for data: 2694317568
I0619 14:56:42.492947 17898 layer_factory.hpp:77] Creating layer Convolution86
I0619 14:56:42.492959 17898 net.cpp:91] Creating Layer Convolution86
I0619 14:56:42.492964 17898 net.cpp:425] Convolution86 <- Eltwise42_ReLU85_0_split_0
I0619 14:56:42.492971 17898 net.cpp:399] Convolution86 -> Convolution86
I0619 14:56:42.494609 17898 net.cpp:141] Setting up Convolution86
I0619 14:56:42.494619 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.494623 17898 net.cpp:156] Memory required for data: 2696414720
I0619 14:56:42.494632 17898 layer_factory.hpp:77] Creating layer BatchNorm86
I0619 14:56:42.494640 17898 net.cpp:91] Creating Layer BatchNorm86
I0619 14:56:42.494645 17898 net.cpp:425] BatchNorm86 <- Convolution86
I0619 14:56:42.494652 17898 net.cpp:386] BatchNorm86 -> Convolution86 (in-place)
I0619 14:56:42.494875 17898 net.cpp:141] Setting up BatchNorm86
I0619 14:56:42.494884 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.494887 17898 net.cpp:156] Memory required for data: 2698511872
I0619 14:56:42.494896 17898 layer_factory.hpp:77] Creating layer Scale86
I0619 14:56:42.494904 17898 net.cpp:91] Creating Layer Scale86
I0619 14:56:42.494907 17898 net.cpp:425] Scale86 <- Convolution86
I0619 14:56:42.494913 17898 net.cpp:386] Scale86 -> Convolution86 (in-place)
I0619 14:56:42.494953 17898 layer_factory.hpp:77] Creating layer Scale86
I0619 14:56:42.495091 17898 net.cpp:141] Setting up Scale86
I0619 14:56:42.495100 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.495102 17898 net.cpp:156] Memory required for data: 2700609024
I0619 14:56:42.495110 17898 layer_factory.hpp:77] Creating layer ReLU86
I0619 14:56:42.495116 17898 net.cpp:91] Creating Layer ReLU86
I0619 14:56:42.495121 17898 net.cpp:425] ReLU86 <- Convolution86
I0619 14:56:42.495128 17898 net.cpp:386] ReLU86 -> Convolution86 (in-place)
I0619 14:56:42.495136 17898 net.cpp:141] Setting up ReLU86
I0619 14:56:42.495141 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.495144 17898 net.cpp:156] Memory required for data: 2702706176
I0619 14:56:42.495148 17898 layer_factory.hpp:77] Creating layer Convolution87
I0619 14:56:42.495157 17898 net.cpp:91] Creating Layer Convolution87
I0619 14:56:42.495162 17898 net.cpp:425] Convolution87 <- Convolution86
I0619 14:56:42.495170 17898 net.cpp:399] Convolution87 -> Convolution87
I0619 14:56:42.497387 17898 net.cpp:141] Setting up Convolution87
I0619 14:56:42.497402 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.497407 17898 net.cpp:156] Memory required for data: 2704803328
I0619 14:56:42.497416 17898 layer_factory.hpp:77] Creating layer BatchNorm87
I0619 14:56:42.497427 17898 net.cpp:91] Creating Layer BatchNorm87
I0619 14:56:42.497433 17898 net.cpp:425] BatchNorm87 <- Convolution87
I0619 14:56:42.497442 17898 net.cpp:386] BatchNorm87 -> Convolution87 (in-place)
I0619 14:56:42.497669 17898 net.cpp:141] Setting up BatchNorm87
I0619 14:56:42.497678 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.497681 17898 net.cpp:156] Memory required for data: 2706900480
I0619 14:56:42.497689 17898 layer_factory.hpp:77] Creating layer Scale87
I0619 14:56:42.497699 17898 net.cpp:91] Creating Layer Scale87
I0619 14:56:42.497704 17898 net.cpp:425] Scale87 <- Convolution87
I0619 14:56:42.497709 17898 net.cpp:386] Scale87 -> Convolution87 (in-place)
I0619 14:56:42.497751 17898 layer_factory.hpp:77] Creating layer Scale87
I0619 14:56:42.497884 17898 net.cpp:141] Setting up Scale87
I0619 14:56:42.497892 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.497895 17898 net.cpp:156] Memory required for data: 2708997632
I0619 14:56:42.497902 17898 layer_factory.hpp:77] Creating layer Eltwise43
I0619 14:56:42.497927 17898 net.cpp:91] Creating Layer Eltwise43
I0619 14:56:42.497934 17898 net.cpp:425] Eltwise43 <- Eltwise42_ReLU85_0_split_1
I0619 14:56:42.497941 17898 net.cpp:425] Eltwise43 <- Convolution87
I0619 14:56:42.497948 17898 net.cpp:399] Eltwise43 -> Eltwise43
I0619 14:56:42.497972 17898 net.cpp:141] Setting up Eltwise43
I0619 14:56:42.497978 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.497982 17898 net.cpp:156] Memory required for data: 2711094784
I0619 14:56:42.497987 17898 layer_factory.hpp:77] Creating layer ReLU87
I0619 14:56:42.497992 17898 net.cpp:91] Creating Layer ReLU87
I0619 14:56:42.497997 17898 net.cpp:425] ReLU87 <- Eltwise43
I0619 14:56:42.498004 17898 net.cpp:386] ReLU87 -> Eltwise43 (in-place)
I0619 14:56:42.498011 17898 net.cpp:141] Setting up ReLU87
I0619 14:56:42.498018 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.498021 17898 net.cpp:156] Memory required for data: 2713191936
I0619 14:56:42.498025 17898 layer_factory.hpp:77] Creating layer Eltwise43_ReLU87_0_split
I0619 14:56:42.498030 17898 net.cpp:91] Creating Layer Eltwise43_ReLU87_0_split
I0619 14:56:42.498034 17898 net.cpp:425] Eltwise43_ReLU87_0_split <- Eltwise43
I0619 14:56:42.498040 17898 net.cpp:399] Eltwise43_ReLU87_0_split -> Eltwise43_ReLU87_0_split_0
I0619 14:56:42.498047 17898 net.cpp:399] Eltwise43_ReLU87_0_split -> Eltwise43_ReLU87_0_split_1
I0619 14:56:42.498093 17898 net.cpp:141] Setting up Eltwise43_ReLU87_0_split
I0619 14:56:42.498100 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.498106 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.498109 17898 net.cpp:156] Memory required for data: 2717386240
I0619 14:56:42.498113 17898 layer_factory.hpp:77] Creating layer Convolution88
I0619 14:56:42.498122 17898 net.cpp:91] Creating Layer Convolution88
I0619 14:56:42.498127 17898 net.cpp:425] Convolution88 <- Eltwise43_ReLU87_0_split_0
I0619 14:56:42.498137 17898 net.cpp:399] Convolution88 -> Convolution88
I0619 14:56:42.499769 17898 net.cpp:141] Setting up Convolution88
I0619 14:56:42.499779 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.499783 17898 net.cpp:156] Memory required for data: 2719483392
I0619 14:56:42.499791 17898 layer_factory.hpp:77] Creating layer BatchNorm88
I0619 14:56:42.499799 17898 net.cpp:91] Creating Layer BatchNorm88
I0619 14:56:42.499804 17898 net.cpp:425] BatchNorm88 <- Convolution88
I0619 14:56:42.499812 17898 net.cpp:386] BatchNorm88 -> Convolution88 (in-place)
I0619 14:56:42.500041 17898 net.cpp:141] Setting up BatchNorm88
I0619 14:56:42.500048 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.500052 17898 net.cpp:156] Memory required for data: 2721580544
I0619 14:56:42.500061 17898 layer_factory.hpp:77] Creating layer Scale88
I0619 14:56:42.500068 17898 net.cpp:91] Creating Layer Scale88
I0619 14:56:42.500073 17898 net.cpp:425] Scale88 <- Convolution88
I0619 14:56:42.500088 17898 net.cpp:386] Scale88 -> Convolution88 (in-place)
I0619 14:56:42.500129 17898 layer_factory.hpp:77] Creating layer Scale88
I0619 14:56:42.500265 17898 net.cpp:141] Setting up Scale88
I0619 14:56:42.500273 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.500277 17898 net.cpp:156] Memory required for data: 2723677696
I0619 14:56:42.500283 17898 layer_factory.hpp:77] Creating layer ReLU88
I0619 14:56:42.500290 17898 net.cpp:91] Creating Layer ReLU88
I0619 14:56:42.500294 17898 net.cpp:425] ReLU88 <- Convolution88
I0619 14:56:42.500300 17898 net.cpp:386] ReLU88 -> Convolution88 (in-place)
I0619 14:56:42.500308 17898 net.cpp:141] Setting up ReLU88
I0619 14:56:42.500313 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.500316 17898 net.cpp:156] Memory required for data: 2725774848
I0619 14:56:42.500320 17898 layer_factory.hpp:77] Creating layer Convolution89
I0619 14:56:42.500331 17898 net.cpp:91] Creating Layer Convolution89
I0619 14:56:42.500336 17898 net.cpp:425] Convolution89 <- Convolution88
I0619 14:56:42.500345 17898 net.cpp:399] Convolution89 -> Convolution89
I0619 14:56:42.501971 17898 net.cpp:141] Setting up Convolution89
I0619 14:56:42.501993 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.501998 17898 net.cpp:156] Memory required for data: 2727872000
I0619 14:56:42.502005 17898 layer_factory.hpp:77] Creating layer BatchNorm89
I0619 14:56:42.502015 17898 net.cpp:91] Creating Layer BatchNorm89
I0619 14:56:42.502020 17898 net.cpp:425] BatchNorm89 <- Convolution89
I0619 14:56:42.502028 17898 net.cpp:386] BatchNorm89 -> Convolution89 (in-place)
I0619 14:56:42.502251 17898 net.cpp:141] Setting up BatchNorm89
I0619 14:56:42.502259 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.502264 17898 net.cpp:156] Memory required for data: 2729969152
I0619 14:56:42.502271 17898 layer_factory.hpp:77] Creating layer Scale89
I0619 14:56:42.502280 17898 net.cpp:91] Creating Layer Scale89
I0619 14:56:42.502285 17898 net.cpp:425] Scale89 <- Convolution89
I0619 14:56:42.502291 17898 net.cpp:386] Scale89 -> Convolution89 (in-place)
I0619 14:56:42.502331 17898 layer_factory.hpp:77] Creating layer Scale89
I0619 14:56:42.502476 17898 net.cpp:141] Setting up Scale89
I0619 14:56:42.502485 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.502490 17898 net.cpp:156] Memory required for data: 2732066304
I0619 14:56:42.502496 17898 layer_factory.hpp:77] Creating layer Eltwise44
I0619 14:56:42.502506 17898 net.cpp:91] Creating Layer Eltwise44
I0619 14:56:42.502511 17898 net.cpp:425] Eltwise44 <- Eltwise43_ReLU87_0_split_1
I0619 14:56:42.502517 17898 net.cpp:425] Eltwise44 <- Convolution89
I0619 14:56:42.502523 17898 net.cpp:399] Eltwise44 -> Eltwise44
I0619 14:56:42.502547 17898 net.cpp:141] Setting up Eltwise44
I0619 14:56:42.502552 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.502557 17898 net.cpp:156] Memory required for data: 2734163456
I0619 14:56:42.502560 17898 layer_factory.hpp:77] Creating layer ReLU89
I0619 14:56:42.502567 17898 net.cpp:91] Creating Layer ReLU89
I0619 14:56:42.502570 17898 net.cpp:425] ReLU89 <- Eltwise44
I0619 14:56:42.502576 17898 net.cpp:386] ReLU89 -> Eltwise44 (in-place)
I0619 14:56:42.502583 17898 net.cpp:141] Setting up ReLU89
I0619 14:56:42.502588 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.502591 17898 net.cpp:156] Memory required for data: 2736260608
I0619 14:56:42.502595 17898 layer_factory.hpp:77] Creating layer Eltwise44_ReLU89_0_split
I0619 14:56:42.502604 17898 net.cpp:91] Creating Layer Eltwise44_ReLU89_0_split
I0619 14:56:42.502607 17898 net.cpp:425] Eltwise44_ReLU89_0_split <- Eltwise44
I0619 14:56:42.502614 17898 net.cpp:399] Eltwise44_ReLU89_0_split -> Eltwise44_ReLU89_0_split_0
I0619 14:56:42.502620 17898 net.cpp:399] Eltwise44_ReLU89_0_split -> Eltwise44_ReLU89_0_split_1
I0619 14:56:42.502660 17898 net.cpp:141] Setting up Eltwise44_ReLU89_0_split
I0619 14:56:42.502667 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.502672 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.502676 17898 net.cpp:156] Memory required for data: 2740454912
I0619 14:56:42.502681 17898 layer_factory.hpp:77] Creating layer Convolution90
I0619 14:56:42.502689 17898 net.cpp:91] Creating Layer Convolution90
I0619 14:56:42.502693 17898 net.cpp:425] Convolution90 <- Eltwise44_ReLU89_0_split_0
I0619 14:56:42.502701 17898 net.cpp:399] Convolution90 -> Convolution90
I0619 14:56:42.504328 17898 net.cpp:141] Setting up Convolution90
I0619 14:56:42.504338 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.504343 17898 net.cpp:156] Memory required for data: 2742552064
I0619 14:56:42.504350 17898 layer_factory.hpp:77] Creating layer BatchNorm90
I0619 14:56:42.504357 17898 net.cpp:91] Creating Layer BatchNorm90
I0619 14:56:42.504362 17898 net.cpp:425] BatchNorm90 <- Convolution90
I0619 14:56:42.504369 17898 net.cpp:386] BatchNorm90 -> Convolution90 (in-place)
I0619 14:56:42.504590 17898 net.cpp:141] Setting up BatchNorm90
I0619 14:56:42.504598 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.504601 17898 net.cpp:156] Memory required for data: 2744649216
I0619 14:56:42.504613 17898 layer_factory.hpp:77] Creating layer Scale90
I0619 14:56:42.504632 17898 net.cpp:91] Creating Layer Scale90
I0619 14:56:42.504637 17898 net.cpp:425] Scale90 <- Convolution90
I0619 14:56:42.504643 17898 net.cpp:386] Scale90 -> Convolution90 (in-place)
I0619 14:56:42.504689 17898 layer_factory.hpp:77] Creating layer Scale90
I0619 14:56:42.504823 17898 net.cpp:141] Setting up Scale90
I0619 14:56:42.504833 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.504837 17898 net.cpp:156] Memory required for data: 2746746368
I0619 14:56:42.504844 17898 layer_factory.hpp:77] Creating layer ReLU90
I0619 14:56:42.504850 17898 net.cpp:91] Creating Layer ReLU90
I0619 14:56:42.504855 17898 net.cpp:425] ReLU90 <- Convolution90
I0619 14:56:42.504860 17898 net.cpp:386] ReLU90 -> Convolution90 (in-place)
I0619 14:56:42.504873 17898 net.cpp:141] Setting up ReLU90
I0619 14:56:42.504878 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.504881 17898 net.cpp:156] Memory required for data: 2748843520
I0619 14:56:42.504885 17898 layer_factory.hpp:77] Creating layer Convolution91
I0619 14:56:42.504896 17898 net.cpp:91] Creating Layer Convolution91
I0619 14:56:42.504900 17898 net.cpp:425] Convolution91 <- Convolution90
I0619 14:56:42.504909 17898 net.cpp:399] Convolution91 -> Convolution91
I0619 14:56:42.506541 17898 net.cpp:141] Setting up Convolution91
I0619 14:56:42.506551 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.506554 17898 net.cpp:156] Memory required for data: 2750940672
I0619 14:56:42.506561 17898 layer_factory.hpp:77] Creating layer BatchNorm91
I0619 14:56:42.506572 17898 net.cpp:91] Creating Layer BatchNorm91
I0619 14:56:42.506578 17898 net.cpp:425] BatchNorm91 <- Convolution91
I0619 14:56:42.506584 17898 net.cpp:386] BatchNorm91 -> Convolution91 (in-place)
I0619 14:56:42.506810 17898 net.cpp:141] Setting up BatchNorm91
I0619 14:56:42.506819 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.506822 17898 net.cpp:156] Memory required for data: 2753037824
I0619 14:56:42.506831 17898 layer_factory.hpp:77] Creating layer Scale91
I0619 14:56:42.506840 17898 net.cpp:91] Creating Layer Scale91
I0619 14:56:42.506845 17898 net.cpp:425] Scale91 <- Convolution91
I0619 14:56:42.506850 17898 net.cpp:386] Scale91 -> Convolution91 (in-place)
I0619 14:56:42.506888 17898 layer_factory.hpp:77] Creating layer Scale91
I0619 14:56:42.507022 17898 net.cpp:141] Setting up Scale91
I0619 14:56:42.507030 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.507033 17898 net.cpp:156] Memory required for data: 2755134976
I0619 14:56:42.507040 17898 layer_factory.hpp:77] Creating layer Eltwise45
I0619 14:56:42.507046 17898 net.cpp:91] Creating Layer Eltwise45
I0619 14:56:42.507051 17898 net.cpp:425] Eltwise45 <- Eltwise44_ReLU89_0_split_1
I0619 14:56:42.507061 17898 net.cpp:425] Eltwise45 <- Convolution91
I0619 14:56:42.507068 17898 net.cpp:399] Eltwise45 -> Eltwise45
I0619 14:56:42.507089 17898 net.cpp:141] Setting up Eltwise45
I0619 14:56:42.507098 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.507102 17898 net.cpp:156] Memory required for data: 2757232128
I0619 14:56:42.507105 17898 layer_factory.hpp:77] Creating layer ReLU91
I0619 14:56:42.507112 17898 net.cpp:91] Creating Layer ReLU91
I0619 14:56:42.507117 17898 net.cpp:425] ReLU91 <- Eltwise45
I0619 14:56:42.507122 17898 net.cpp:386] ReLU91 -> Eltwise45 (in-place)
I0619 14:56:42.507128 17898 net.cpp:141] Setting up ReLU91
I0619 14:56:42.507133 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.507138 17898 net.cpp:156] Memory required for data: 2759329280
I0619 14:56:42.507141 17898 layer_factory.hpp:77] Creating layer Eltwise45_ReLU91_0_split
I0619 14:56:42.507148 17898 net.cpp:91] Creating Layer Eltwise45_ReLU91_0_split
I0619 14:56:42.507150 17898 net.cpp:425] Eltwise45_ReLU91_0_split <- Eltwise45
I0619 14:56:42.507158 17898 net.cpp:399] Eltwise45_ReLU91_0_split -> Eltwise45_ReLU91_0_split_0
I0619 14:56:42.507166 17898 net.cpp:399] Eltwise45_ReLU91_0_split -> Eltwise45_ReLU91_0_split_1
I0619 14:56:42.507208 17898 net.cpp:141] Setting up Eltwise45_ReLU91_0_split
I0619 14:56:42.507230 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.507236 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.507239 17898 net.cpp:156] Memory required for data: 2763523584
I0619 14:56:42.507243 17898 layer_factory.hpp:77] Creating layer Convolution92
I0619 14:56:42.507252 17898 net.cpp:91] Creating Layer Convolution92
I0619 14:56:42.507257 17898 net.cpp:425] Convolution92 <- Eltwise45_ReLU91_0_split_0
I0619 14:56:42.507264 17898 net.cpp:399] Convolution92 -> Convolution92
I0619 14:56:42.508896 17898 net.cpp:141] Setting up Convolution92
I0619 14:56:42.508906 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.508910 17898 net.cpp:156] Memory required for data: 2765620736
I0619 14:56:42.508918 17898 layer_factory.hpp:77] Creating layer BatchNorm92
I0619 14:56:42.508926 17898 net.cpp:91] Creating Layer BatchNorm92
I0619 14:56:42.508931 17898 net.cpp:425] BatchNorm92 <- Convolution92
I0619 14:56:42.508937 17898 net.cpp:386] BatchNorm92 -> Convolution92 (in-place)
I0619 14:56:42.509168 17898 net.cpp:141] Setting up BatchNorm92
I0619 14:56:42.509176 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.509181 17898 net.cpp:156] Memory required for data: 2767717888
I0619 14:56:42.509189 17898 layer_factory.hpp:77] Creating layer Scale92
I0619 14:56:42.509196 17898 net.cpp:91] Creating Layer Scale92
I0619 14:56:42.509202 17898 net.cpp:425] Scale92 <- Convolution92
I0619 14:56:42.509207 17898 net.cpp:386] Scale92 -> Convolution92 (in-place)
I0619 14:56:42.509249 17898 layer_factory.hpp:77] Creating layer Scale92
I0619 14:56:42.509382 17898 net.cpp:141] Setting up Scale92
I0619 14:56:42.509390 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.509393 17898 net.cpp:156] Memory required for data: 2769815040
I0619 14:56:42.509400 17898 layer_factory.hpp:77] Creating layer ReLU92
I0619 14:56:42.509408 17898 net.cpp:91] Creating Layer ReLU92
I0619 14:56:42.509413 17898 net.cpp:425] ReLU92 <- Convolution92
I0619 14:56:42.509418 17898 net.cpp:386] ReLU92 -> Convolution92 (in-place)
I0619 14:56:42.509425 17898 net.cpp:141] Setting up ReLU92
I0619 14:56:42.509431 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.509434 17898 net.cpp:156] Memory required for data: 2771912192
I0619 14:56:42.509438 17898 layer_factory.hpp:77] Creating layer Convolution93
I0619 14:56:42.509449 17898 net.cpp:91] Creating Layer Convolution93
I0619 14:56:42.509454 17898 net.cpp:425] Convolution93 <- Convolution92
I0619 14:56:42.509460 17898 net.cpp:399] Convolution93 -> Convolution93
I0619 14:56:42.511092 17898 net.cpp:141] Setting up Convolution93
I0619 14:56:42.511103 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.511107 17898 net.cpp:156] Memory required for data: 2774009344
I0619 14:56:42.511114 17898 layer_factory.hpp:77] Creating layer BatchNorm93
I0619 14:56:42.511121 17898 net.cpp:91] Creating Layer BatchNorm93
I0619 14:56:42.511126 17898 net.cpp:425] BatchNorm93 <- Convolution93
I0619 14:56:42.511134 17898 net.cpp:386] BatchNorm93 -> Convolution93 (in-place)
I0619 14:56:42.511371 17898 net.cpp:141] Setting up BatchNorm93
I0619 14:56:42.511379 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.511384 17898 net.cpp:156] Memory required for data: 2776106496
I0619 14:56:42.511391 17898 layer_factory.hpp:77] Creating layer Scale93
I0619 14:56:42.511399 17898 net.cpp:91] Creating Layer Scale93
I0619 14:56:42.511404 17898 net.cpp:425] Scale93 <- Convolution93
I0619 14:56:42.511411 17898 net.cpp:386] Scale93 -> Convolution93 (in-place)
I0619 14:56:42.511451 17898 layer_factory.hpp:77] Creating layer Scale93
I0619 14:56:42.511586 17898 net.cpp:141] Setting up Scale93
I0619 14:56:42.511595 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.511598 17898 net.cpp:156] Memory required for data: 2778203648
I0619 14:56:42.511605 17898 layer_factory.hpp:77] Creating layer Eltwise46
I0619 14:56:42.511612 17898 net.cpp:91] Creating Layer Eltwise46
I0619 14:56:42.511620 17898 net.cpp:425] Eltwise46 <- Eltwise45_ReLU91_0_split_1
I0619 14:56:42.511637 17898 net.cpp:425] Eltwise46 <- Convolution93
I0619 14:56:42.511646 17898 net.cpp:399] Eltwise46 -> Eltwise46
I0619 14:56:42.511669 17898 net.cpp:141] Setting up Eltwise46
I0619 14:56:42.511677 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.511679 17898 net.cpp:156] Memory required for data: 2780300800
I0619 14:56:42.511683 17898 layer_factory.hpp:77] Creating layer ReLU93
I0619 14:56:42.511694 17898 net.cpp:91] Creating Layer ReLU93
I0619 14:56:42.511699 17898 net.cpp:425] ReLU93 <- Eltwise46
I0619 14:56:42.511704 17898 net.cpp:386] ReLU93 -> Eltwise46 (in-place)
I0619 14:56:42.511711 17898 net.cpp:141] Setting up ReLU93
I0619 14:56:42.511716 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.511720 17898 net.cpp:156] Memory required for data: 2782397952
I0619 14:56:42.511724 17898 layer_factory.hpp:77] Creating layer Eltwise46_ReLU93_0_split
I0619 14:56:42.511730 17898 net.cpp:91] Creating Layer Eltwise46_ReLU93_0_split
I0619 14:56:42.511734 17898 net.cpp:425] Eltwise46_ReLU93_0_split <- Eltwise46
I0619 14:56:42.511742 17898 net.cpp:399] Eltwise46_ReLU93_0_split -> Eltwise46_ReLU93_0_split_0
I0619 14:56:42.511749 17898 net.cpp:399] Eltwise46_ReLU93_0_split -> Eltwise46_ReLU93_0_split_1
I0619 14:56:42.511788 17898 net.cpp:141] Setting up Eltwise46_ReLU93_0_split
I0619 14:56:42.511795 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.511800 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.511803 17898 net.cpp:156] Memory required for data: 2786592256
I0619 14:56:42.511807 17898 layer_factory.hpp:77] Creating layer Convolution94
I0619 14:56:42.511819 17898 net.cpp:91] Creating Layer Convolution94
I0619 14:56:42.511823 17898 net.cpp:425] Convolution94 <- Eltwise46_ReLU93_0_split_0
I0619 14:56:42.511831 17898 net.cpp:399] Convolution94 -> Convolution94
I0619 14:56:42.514066 17898 net.cpp:141] Setting up Convolution94
I0619 14:56:42.514081 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.514086 17898 net.cpp:156] Memory required for data: 2788689408
I0619 14:56:42.514094 17898 layer_factory.hpp:77] Creating layer BatchNorm94
I0619 14:56:42.514102 17898 net.cpp:91] Creating Layer BatchNorm94
I0619 14:56:42.514108 17898 net.cpp:425] BatchNorm94 <- Convolution94
I0619 14:56:42.514117 17898 net.cpp:386] BatchNorm94 -> Convolution94 (in-place)
I0619 14:56:42.514351 17898 net.cpp:141] Setting up BatchNorm94
I0619 14:56:42.514369 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.514374 17898 net.cpp:156] Memory required for data: 2790786560
I0619 14:56:42.514382 17898 layer_factory.hpp:77] Creating layer Scale94
I0619 14:56:42.514390 17898 net.cpp:91] Creating Layer Scale94
I0619 14:56:42.514394 17898 net.cpp:425] Scale94 <- Convolution94
I0619 14:56:42.514403 17898 net.cpp:386] Scale94 -> Convolution94 (in-place)
I0619 14:56:42.514446 17898 layer_factory.hpp:77] Creating layer Scale94
I0619 14:56:42.514583 17898 net.cpp:141] Setting up Scale94
I0619 14:56:42.514591 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.514595 17898 net.cpp:156] Memory required for data: 2792883712
I0619 14:56:42.514602 17898 layer_factory.hpp:77] Creating layer ReLU94
I0619 14:56:42.514608 17898 net.cpp:91] Creating Layer ReLU94
I0619 14:56:42.514613 17898 net.cpp:425] ReLU94 <- Convolution94
I0619 14:56:42.514622 17898 net.cpp:386] ReLU94 -> Convolution94 (in-place)
I0619 14:56:42.514631 17898 net.cpp:141] Setting up ReLU94
I0619 14:56:42.514636 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.514639 17898 net.cpp:156] Memory required for data: 2794980864
I0619 14:56:42.514643 17898 layer_factory.hpp:77] Creating layer Convolution95
I0619 14:56:42.514654 17898 net.cpp:91] Creating Layer Convolution95
I0619 14:56:42.514659 17898 net.cpp:425] Convolution95 <- Convolution94
I0619 14:56:42.514665 17898 net.cpp:399] Convolution95 -> Convolution95
I0619 14:56:42.516294 17898 net.cpp:141] Setting up Convolution95
I0619 14:56:42.516306 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.516324 17898 net.cpp:156] Memory required for data: 2797078016
I0619 14:56:42.516332 17898 layer_factory.hpp:77] Creating layer BatchNorm95
I0619 14:56:42.516342 17898 net.cpp:91] Creating Layer BatchNorm95
I0619 14:56:42.516347 17898 net.cpp:425] BatchNorm95 <- Convolution95
I0619 14:56:42.516355 17898 net.cpp:386] BatchNorm95 -> Convolution95 (in-place)
I0619 14:56:42.516585 17898 net.cpp:141] Setting up BatchNorm95
I0619 14:56:42.516593 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.516597 17898 net.cpp:156] Memory required for data: 2799175168
I0619 14:56:42.516607 17898 layer_factory.hpp:77] Creating layer Scale95
I0619 14:56:42.516615 17898 net.cpp:91] Creating Layer Scale95
I0619 14:56:42.516620 17898 net.cpp:425] Scale95 <- Convolution95
I0619 14:56:42.516626 17898 net.cpp:386] Scale95 -> Convolution95 (in-place)
I0619 14:56:42.516669 17898 layer_factory.hpp:77] Creating layer Scale95
I0619 14:56:42.516804 17898 net.cpp:141] Setting up Scale95
I0619 14:56:42.516813 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.516816 17898 net.cpp:156] Memory required for data: 2801272320
I0619 14:56:42.516824 17898 layer_factory.hpp:77] Creating layer Eltwise47
I0619 14:56:42.516832 17898 net.cpp:91] Creating Layer Eltwise47
I0619 14:56:42.516837 17898 net.cpp:425] Eltwise47 <- Eltwise46_ReLU93_0_split_1
I0619 14:56:42.516844 17898 net.cpp:425] Eltwise47 <- Convolution95
I0619 14:56:42.516851 17898 net.cpp:399] Eltwise47 -> Eltwise47
I0619 14:56:42.516873 17898 net.cpp:141] Setting up Eltwise47
I0619 14:56:42.516880 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.516883 17898 net.cpp:156] Memory required for data: 2803369472
I0619 14:56:42.516888 17898 layer_factory.hpp:77] Creating layer ReLU95
I0619 14:56:42.516894 17898 net.cpp:91] Creating Layer ReLU95
I0619 14:56:42.516899 17898 net.cpp:425] ReLU95 <- Eltwise47
I0619 14:56:42.516906 17898 net.cpp:386] ReLU95 -> Eltwise47 (in-place)
I0619 14:56:42.516913 17898 net.cpp:141] Setting up ReLU95
I0619 14:56:42.516919 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.516922 17898 net.cpp:156] Memory required for data: 2805466624
I0619 14:56:42.516927 17898 layer_factory.hpp:77] Creating layer Eltwise47_ReLU95_0_split
I0619 14:56:42.516932 17898 net.cpp:91] Creating Layer Eltwise47_ReLU95_0_split
I0619 14:56:42.516937 17898 net.cpp:425] Eltwise47_ReLU95_0_split <- Eltwise47
I0619 14:56:42.516942 17898 net.cpp:399] Eltwise47_ReLU95_0_split -> Eltwise47_ReLU95_0_split_0
I0619 14:56:42.516949 17898 net.cpp:399] Eltwise47_ReLU95_0_split -> Eltwise47_ReLU95_0_split_1
I0619 14:56:42.516991 17898 net.cpp:141] Setting up Eltwise47_ReLU95_0_split
I0619 14:56:42.516999 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.517004 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.517007 17898 net.cpp:156] Memory required for data: 2809660928
I0619 14:56:42.517011 17898 layer_factory.hpp:77] Creating layer Convolution96
I0619 14:56:42.517020 17898 net.cpp:91] Creating Layer Convolution96
I0619 14:56:42.517024 17898 net.cpp:425] Convolution96 <- Eltwise47_ReLU95_0_split_0
I0619 14:56:42.517035 17898 net.cpp:399] Convolution96 -> Convolution96
I0619 14:56:42.518672 17898 net.cpp:141] Setting up Convolution96
I0619 14:56:42.518683 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.518687 17898 net.cpp:156] Memory required for data: 2811758080
I0619 14:56:42.518694 17898 layer_factory.hpp:77] Creating layer BatchNorm96
I0619 14:56:42.518702 17898 net.cpp:91] Creating Layer BatchNorm96
I0619 14:56:42.518707 17898 net.cpp:425] BatchNorm96 <- Convolution96
I0619 14:56:42.518718 17898 net.cpp:386] BatchNorm96 -> Convolution96 (in-place)
I0619 14:56:42.518945 17898 net.cpp:141] Setting up BatchNorm96
I0619 14:56:42.518954 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.518957 17898 net.cpp:156] Memory required for data: 2813855232
I0619 14:56:42.518966 17898 layer_factory.hpp:77] Creating layer Scale96
I0619 14:56:42.518977 17898 net.cpp:91] Creating Layer Scale96
I0619 14:56:42.518993 17898 net.cpp:425] Scale96 <- Convolution96
I0619 14:56:42.519002 17898 net.cpp:386] Scale96 -> Convolution96 (in-place)
I0619 14:56:42.519044 17898 layer_factory.hpp:77] Creating layer Scale96
I0619 14:56:42.519181 17898 net.cpp:141] Setting up Scale96
I0619 14:56:42.519189 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.519193 17898 net.cpp:156] Memory required for data: 2815952384
I0619 14:56:42.519201 17898 layer_factory.hpp:77] Creating layer ReLU96
I0619 14:56:42.519207 17898 net.cpp:91] Creating Layer ReLU96
I0619 14:56:42.519212 17898 net.cpp:425] ReLU96 <- Convolution96
I0619 14:56:42.519217 17898 net.cpp:386] ReLU96 -> Convolution96 (in-place)
I0619 14:56:42.519223 17898 net.cpp:141] Setting up ReLU96
I0619 14:56:42.519229 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.519232 17898 net.cpp:156] Memory required for data: 2818049536
I0619 14:56:42.519237 17898 layer_factory.hpp:77] Creating layer Convolution97
I0619 14:56:42.519248 17898 net.cpp:91] Creating Layer Convolution97
I0619 14:56:42.519253 17898 net.cpp:425] Convolution97 <- Convolution96
I0619 14:56:42.519261 17898 net.cpp:399] Convolution97 -> Convolution97
I0619 14:56:42.520885 17898 net.cpp:141] Setting up Convolution97
I0619 14:56:42.520895 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.520898 17898 net.cpp:156] Memory required for data: 2820146688
I0619 14:56:42.520905 17898 layer_factory.hpp:77] Creating layer BatchNorm97
I0619 14:56:42.520915 17898 net.cpp:91] Creating Layer BatchNorm97
I0619 14:56:42.520920 17898 net.cpp:425] BatchNorm97 <- Convolution97
I0619 14:56:42.520927 17898 net.cpp:386] BatchNorm97 -> Convolution97 (in-place)
I0619 14:56:42.521154 17898 net.cpp:141] Setting up BatchNorm97
I0619 14:56:42.521162 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.521167 17898 net.cpp:156] Memory required for data: 2822243840
I0619 14:56:42.521174 17898 layer_factory.hpp:77] Creating layer Scale97
I0619 14:56:42.521183 17898 net.cpp:91] Creating Layer Scale97
I0619 14:56:42.521188 17898 net.cpp:425] Scale97 <- Convolution97
I0619 14:56:42.521194 17898 net.cpp:386] Scale97 -> Convolution97 (in-place)
I0619 14:56:42.521236 17898 layer_factory.hpp:77] Creating layer Scale97
I0619 14:56:42.521374 17898 net.cpp:141] Setting up Scale97
I0619 14:56:42.521381 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.521385 17898 net.cpp:156] Memory required for data: 2824340992
I0619 14:56:42.521392 17898 layer_factory.hpp:77] Creating layer Eltwise48
I0619 14:56:42.521400 17898 net.cpp:91] Creating Layer Eltwise48
I0619 14:56:42.521405 17898 net.cpp:425] Eltwise48 <- Eltwise47_ReLU95_0_split_1
I0619 14:56:42.521411 17898 net.cpp:425] Eltwise48 <- Convolution97
I0619 14:56:42.521417 17898 net.cpp:399] Eltwise48 -> Eltwise48
I0619 14:56:42.521440 17898 net.cpp:141] Setting up Eltwise48
I0619 14:56:42.521447 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.521450 17898 net.cpp:156] Memory required for data: 2826438144
I0619 14:56:42.521455 17898 layer_factory.hpp:77] Creating layer ReLU97
I0619 14:56:42.521461 17898 net.cpp:91] Creating Layer ReLU97
I0619 14:56:42.521466 17898 net.cpp:425] ReLU97 <- Eltwise48
I0619 14:56:42.521471 17898 net.cpp:386] ReLU97 -> Eltwise48 (in-place)
I0619 14:56:42.521477 17898 net.cpp:141] Setting up ReLU97
I0619 14:56:42.521482 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.521486 17898 net.cpp:156] Memory required for data: 2828535296
I0619 14:56:42.521491 17898 layer_factory.hpp:77] Creating layer Eltwise48_ReLU97_0_split
I0619 14:56:42.521498 17898 net.cpp:91] Creating Layer Eltwise48_ReLU97_0_split
I0619 14:56:42.521502 17898 net.cpp:425] Eltwise48_ReLU97_0_split <- Eltwise48
I0619 14:56:42.521507 17898 net.cpp:399] Eltwise48_ReLU97_0_split -> Eltwise48_ReLU97_0_split_0
I0619 14:56:42.521515 17898 net.cpp:399] Eltwise48_ReLU97_0_split -> Eltwise48_ReLU97_0_split_1
I0619 14:56:42.521556 17898 net.cpp:141] Setting up Eltwise48_ReLU97_0_split
I0619 14:56:42.521566 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.521582 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.521586 17898 net.cpp:156] Memory required for data: 2832729600
I0619 14:56:42.521590 17898 layer_factory.hpp:77] Creating layer Convolution98
I0619 14:56:42.521600 17898 net.cpp:91] Creating Layer Convolution98
I0619 14:56:42.521605 17898 net.cpp:425] Convolution98 <- Eltwise48_ReLU97_0_split_0
I0619 14:56:42.521612 17898 net.cpp:399] Convolution98 -> Convolution98
I0619 14:56:42.523253 17898 net.cpp:141] Setting up Convolution98
I0619 14:56:42.523267 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.523270 17898 net.cpp:156] Memory required for data: 2834826752
I0619 14:56:42.523277 17898 layer_factory.hpp:77] Creating layer BatchNorm98
I0619 14:56:42.523288 17898 net.cpp:91] Creating Layer BatchNorm98
I0619 14:56:42.523293 17898 net.cpp:425] BatchNorm98 <- Convolution98
I0619 14:56:42.523299 17898 net.cpp:386] BatchNorm98 -> Convolution98 (in-place)
I0619 14:56:42.523530 17898 net.cpp:141] Setting up BatchNorm98
I0619 14:56:42.523538 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.523541 17898 net.cpp:156] Memory required for data: 2836923904
I0619 14:56:42.523550 17898 layer_factory.hpp:77] Creating layer Scale98
I0619 14:56:42.523557 17898 net.cpp:91] Creating Layer Scale98
I0619 14:56:42.523562 17898 net.cpp:425] Scale98 <- Convolution98
I0619 14:56:42.523568 17898 net.cpp:386] Scale98 -> Convolution98 (in-place)
I0619 14:56:42.523612 17898 layer_factory.hpp:77] Creating layer Scale98
I0619 14:56:42.523746 17898 net.cpp:141] Setting up Scale98
I0619 14:56:42.523756 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.523761 17898 net.cpp:156] Memory required for data: 2839021056
I0619 14:56:42.523767 17898 layer_factory.hpp:77] Creating layer ReLU98
I0619 14:56:42.523773 17898 net.cpp:91] Creating Layer ReLU98
I0619 14:56:42.523778 17898 net.cpp:425] ReLU98 <- Convolution98
I0619 14:56:42.523783 17898 net.cpp:386] ReLU98 -> Convolution98 (in-place)
I0619 14:56:42.523790 17898 net.cpp:141] Setting up ReLU98
I0619 14:56:42.523795 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.523799 17898 net.cpp:156] Memory required for data: 2841118208
I0619 14:56:42.523803 17898 layer_factory.hpp:77] Creating layer Convolution99
I0619 14:56:42.523814 17898 net.cpp:91] Creating Layer Convolution99
I0619 14:56:42.523818 17898 net.cpp:425] Convolution99 <- Convolution98
I0619 14:56:42.523829 17898 net.cpp:399] Convolution99 -> Convolution99
I0619 14:56:42.525460 17898 net.cpp:141] Setting up Convolution99
I0619 14:56:42.525468 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.525472 17898 net.cpp:156] Memory required for data: 2843215360
I0619 14:56:42.525480 17898 layer_factory.hpp:77] Creating layer BatchNorm99
I0619 14:56:42.525488 17898 net.cpp:91] Creating Layer BatchNorm99
I0619 14:56:42.525493 17898 net.cpp:425] BatchNorm99 <- Convolution99
I0619 14:56:42.525499 17898 net.cpp:386] BatchNorm99 -> Convolution99 (in-place)
I0619 14:56:42.525730 17898 net.cpp:141] Setting up BatchNorm99
I0619 14:56:42.525738 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.525741 17898 net.cpp:156] Memory required for data: 2845312512
I0619 14:56:42.525750 17898 layer_factory.hpp:77] Creating layer Scale99
I0619 14:56:42.525758 17898 net.cpp:91] Creating Layer Scale99
I0619 14:56:42.525763 17898 net.cpp:425] Scale99 <- Convolution99
I0619 14:56:42.525769 17898 net.cpp:386] Scale99 -> Convolution99 (in-place)
I0619 14:56:42.525807 17898 layer_factory.hpp:77] Creating layer Scale99
I0619 14:56:42.525940 17898 net.cpp:141] Setting up Scale99
I0619 14:56:42.525949 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.525952 17898 net.cpp:156] Memory required for data: 2847409664
I0619 14:56:42.525959 17898 layer_factory.hpp:77] Creating layer Eltwise49
I0619 14:56:42.525965 17898 net.cpp:91] Creating Layer Eltwise49
I0619 14:56:42.525970 17898 net.cpp:425] Eltwise49 <- Eltwise48_ReLU97_0_split_1
I0619 14:56:42.525981 17898 net.cpp:425] Eltwise49 <- Convolution99
I0619 14:56:42.526000 17898 net.cpp:399] Eltwise49 -> Eltwise49
I0619 14:56:42.526023 17898 net.cpp:141] Setting up Eltwise49
I0619 14:56:42.526032 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.526036 17898 net.cpp:156] Memory required for data: 2849506816
I0619 14:56:42.526041 17898 layer_factory.hpp:77] Creating layer ReLU99
I0619 14:56:42.526046 17898 net.cpp:91] Creating Layer ReLU99
I0619 14:56:42.526051 17898 net.cpp:425] ReLU99 <- Eltwise49
I0619 14:56:42.526057 17898 net.cpp:386] ReLU99 -> Eltwise49 (in-place)
I0619 14:56:42.526062 17898 net.cpp:141] Setting up ReLU99
I0619 14:56:42.526068 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.526072 17898 net.cpp:156] Memory required for data: 2851603968
I0619 14:56:42.526075 17898 layer_factory.hpp:77] Creating layer Eltwise49_ReLU99_0_split
I0619 14:56:42.526082 17898 net.cpp:91] Creating Layer Eltwise49_ReLU99_0_split
I0619 14:56:42.526085 17898 net.cpp:425] Eltwise49_ReLU99_0_split <- Eltwise49
I0619 14:56:42.526093 17898 net.cpp:399] Eltwise49_ReLU99_0_split -> Eltwise49_ReLU99_0_split_0
I0619 14:56:42.526123 17898 net.cpp:399] Eltwise49_ReLU99_0_split -> Eltwise49_ReLU99_0_split_1
I0619 14:56:42.526168 17898 net.cpp:141] Setting up Eltwise49_ReLU99_0_split
I0619 14:56:42.526176 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.526181 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.526185 17898 net.cpp:156] Memory required for data: 2855798272
I0619 14:56:42.526190 17898 layer_factory.hpp:77] Creating layer Convolution100
I0619 14:56:42.526202 17898 net.cpp:91] Creating Layer Convolution100
I0619 14:56:42.526207 17898 net.cpp:425] Convolution100 <- Eltwise49_ReLU99_0_split_0
I0619 14:56:42.526216 17898 net.cpp:399] Convolution100 -> Convolution100
I0619 14:56:42.527866 17898 net.cpp:141] Setting up Convolution100
I0619 14:56:42.527878 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.527881 17898 net.cpp:156] Memory required for data: 2857895424
I0619 14:56:42.527889 17898 layer_factory.hpp:77] Creating layer BatchNorm100
I0619 14:56:42.527895 17898 net.cpp:91] Creating Layer BatchNorm100
I0619 14:56:42.527901 17898 net.cpp:425] BatchNorm100 <- Convolution100
I0619 14:56:42.527909 17898 net.cpp:386] BatchNorm100 -> Convolution100 (in-place)
I0619 14:56:42.528141 17898 net.cpp:141] Setting up BatchNorm100
I0619 14:56:42.528149 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.528153 17898 net.cpp:156] Memory required for data: 2859992576
I0619 14:56:42.528165 17898 layer_factory.hpp:77] Creating layer Scale100
I0619 14:56:42.528172 17898 net.cpp:91] Creating Layer Scale100
I0619 14:56:42.528177 17898 net.cpp:425] Scale100 <- Convolution100
I0619 14:56:42.528183 17898 net.cpp:386] Scale100 -> Convolution100 (in-place)
I0619 14:56:42.528224 17898 layer_factory.hpp:77] Creating layer Scale100
I0619 14:56:42.528360 17898 net.cpp:141] Setting up Scale100
I0619 14:56:42.528368 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.528373 17898 net.cpp:156] Memory required for data: 2862089728
I0619 14:56:42.528379 17898 layer_factory.hpp:77] Creating layer ReLU100
I0619 14:56:42.528388 17898 net.cpp:91] Creating Layer ReLU100
I0619 14:56:42.528393 17898 net.cpp:425] ReLU100 <- Convolution100
I0619 14:56:42.528399 17898 net.cpp:386] ReLU100 -> Convolution100 (in-place)
I0619 14:56:42.528406 17898 net.cpp:141] Setting up ReLU100
I0619 14:56:42.528411 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.528415 17898 net.cpp:156] Memory required for data: 2864186880
I0619 14:56:42.528419 17898 layer_factory.hpp:77] Creating layer Convolution101
I0619 14:56:42.528429 17898 net.cpp:91] Creating Layer Convolution101
I0619 14:56:42.528434 17898 net.cpp:425] Convolution101 <- Convolution100
I0619 14:56:42.528442 17898 net.cpp:399] Convolution101 -> Convolution101
I0619 14:56:42.530685 17898 net.cpp:141] Setting up Convolution101
I0619 14:56:42.530700 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.530722 17898 net.cpp:156] Memory required for data: 2866284032
I0619 14:56:42.530732 17898 layer_factory.hpp:77] Creating layer BatchNorm101
I0619 14:56:42.530742 17898 net.cpp:91] Creating Layer BatchNorm101
I0619 14:56:42.530747 17898 net.cpp:425] BatchNorm101 <- Convolution101
I0619 14:56:42.530756 17898 net.cpp:386] BatchNorm101 -> Convolution101 (in-place)
I0619 14:56:42.530992 17898 net.cpp:141] Setting up BatchNorm101
I0619 14:56:42.530999 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.531003 17898 net.cpp:156] Memory required for data: 2868381184
I0619 14:56:42.531013 17898 layer_factory.hpp:77] Creating layer Scale101
I0619 14:56:42.531021 17898 net.cpp:91] Creating Layer Scale101
I0619 14:56:42.531026 17898 net.cpp:425] Scale101 <- Convolution101
I0619 14:56:42.531031 17898 net.cpp:386] Scale101 -> Convolution101 (in-place)
I0619 14:56:42.531075 17898 layer_factory.hpp:77] Creating layer Scale101
I0619 14:56:42.531214 17898 net.cpp:141] Setting up Scale101
I0619 14:56:42.531224 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.531226 17898 net.cpp:156] Memory required for data: 2870478336
I0619 14:56:42.531234 17898 layer_factory.hpp:77] Creating layer Eltwise50
I0619 14:56:42.531242 17898 net.cpp:91] Creating Layer Eltwise50
I0619 14:56:42.531249 17898 net.cpp:425] Eltwise50 <- Eltwise49_ReLU99_0_split_1
I0619 14:56:42.531253 17898 net.cpp:425] Eltwise50 <- Convolution101
I0619 14:56:42.531260 17898 net.cpp:399] Eltwise50 -> Eltwise50
I0619 14:56:42.531283 17898 net.cpp:141] Setting up Eltwise50
I0619 14:56:42.531291 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.531294 17898 net.cpp:156] Memory required for data: 2872575488
I0619 14:56:42.531297 17898 layer_factory.hpp:77] Creating layer ReLU101
I0619 14:56:42.531304 17898 net.cpp:91] Creating Layer ReLU101
I0619 14:56:42.531308 17898 net.cpp:425] ReLU101 <- Eltwise50
I0619 14:56:42.531313 17898 net.cpp:386] ReLU101 -> Eltwise50 (in-place)
I0619 14:56:42.531321 17898 net.cpp:141] Setting up ReLU101
I0619 14:56:42.531325 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.531329 17898 net.cpp:156] Memory required for data: 2874672640
I0619 14:56:42.531333 17898 layer_factory.hpp:77] Creating layer Eltwise50_ReLU101_0_split
I0619 14:56:42.531383 17898 net.cpp:91] Creating Layer Eltwise50_ReLU101_0_split
I0619 14:56:42.531388 17898 net.cpp:425] Eltwise50_ReLU101_0_split <- Eltwise50
I0619 14:56:42.531395 17898 net.cpp:399] Eltwise50_ReLU101_0_split -> Eltwise50_ReLU101_0_split_0
I0619 14:56:42.531404 17898 net.cpp:399] Eltwise50_ReLU101_0_split -> Eltwise50_ReLU101_0_split_1
I0619 14:56:42.531450 17898 net.cpp:141] Setting up Eltwise50_ReLU101_0_split
I0619 14:56:42.531457 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.531462 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.531466 17898 net.cpp:156] Memory required for data: 2878866944
I0619 14:56:42.531471 17898 layer_factory.hpp:77] Creating layer Convolution102
I0619 14:56:42.531483 17898 net.cpp:91] Creating Layer Convolution102
I0619 14:56:42.531488 17898 net.cpp:425] Convolution102 <- Eltwise50_ReLU101_0_split_0
I0619 14:56:42.531498 17898 net.cpp:399] Convolution102 -> Convolution102
I0619 14:56:42.533133 17898 net.cpp:141] Setting up Convolution102
I0619 14:56:42.533143 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.533146 17898 net.cpp:156] Memory required for data: 2880964096
I0619 14:56:42.533154 17898 layer_factory.hpp:77] Creating layer BatchNorm102
I0619 14:56:42.533161 17898 net.cpp:91] Creating Layer BatchNorm102
I0619 14:56:42.533166 17898 net.cpp:425] BatchNorm102 <- Convolution102
I0619 14:56:42.533174 17898 net.cpp:386] BatchNorm102 -> Convolution102 (in-place)
I0619 14:56:42.533406 17898 net.cpp:141] Setting up BatchNorm102
I0619 14:56:42.533413 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.533417 17898 net.cpp:156] Memory required for data: 2883061248
I0619 14:56:42.533427 17898 layer_factory.hpp:77] Creating layer Scale102
I0619 14:56:42.533437 17898 net.cpp:91] Creating Layer Scale102
I0619 14:56:42.533453 17898 net.cpp:425] Scale102 <- Convolution102
I0619 14:56:42.533462 17898 net.cpp:386] Scale102 -> Convolution102 (in-place)
I0619 14:56:42.533506 17898 layer_factory.hpp:77] Creating layer Scale102
I0619 14:56:42.533644 17898 net.cpp:141] Setting up Scale102
I0619 14:56:42.533654 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.533658 17898 net.cpp:156] Memory required for data: 2885158400
I0619 14:56:42.533665 17898 layer_factory.hpp:77] Creating layer ReLU102
I0619 14:56:42.533673 17898 net.cpp:91] Creating Layer ReLU102
I0619 14:56:42.533677 17898 net.cpp:425] ReLU102 <- Convolution102
I0619 14:56:42.533682 17898 net.cpp:386] ReLU102 -> Convolution102 (in-place)
I0619 14:56:42.533689 17898 net.cpp:141] Setting up ReLU102
I0619 14:56:42.533695 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.533699 17898 net.cpp:156] Memory required for data: 2887255552
I0619 14:56:42.533702 17898 layer_factory.hpp:77] Creating layer Convolution103
I0619 14:56:42.533715 17898 net.cpp:91] Creating Layer Convolution103
I0619 14:56:42.533718 17898 net.cpp:425] Convolution103 <- Convolution102
I0619 14:56:42.533727 17898 net.cpp:399] Convolution103 -> Convolution103
I0619 14:56:42.535364 17898 net.cpp:141] Setting up Convolution103
I0619 14:56:42.535375 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.535379 17898 net.cpp:156] Memory required for data: 2889352704
I0619 14:56:42.535387 17898 layer_factory.hpp:77] Creating layer BatchNorm103
I0619 14:56:42.535397 17898 net.cpp:91] Creating Layer BatchNorm103
I0619 14:56:42.535401 17898 net.cpp:425] BatchNorm103 <- Convolution103
I0619 14:56:42.535408 17898 net.cpp:386] BatchNorm103 -> Convolution103 (in-place)
I0619 14:56:42.535636 17898 net.cpp:141] Setting up BatchNorm103
I0619 14:56:42.535645 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.535648 17898 net.cpp:156] Memory required for data: 2891449856
I0619 14:56:42.535656 17898 layer_factory.hpp:77] Creating layer Scale103
I0619 14:56:42.535665 17898 net.cpp:91] Creating Layer Scale103
I0619 14:56:42.535670 17898 net.cpp:425] Scale103 <- Convolution103
I0619 14:56:42.535676 17898 net.cpp:386] Scale103 -> Convolution103 (in-place)
I0619 14:56:42.535714 17898 layer_factory.hpp:77] Creating layer Scale103
I0619 14:56:42.535852 17898 net.cpp:141] Setting up Scale103
I0619 14:56:42.535861 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.535864 17898 net.cpp:156] Memory required for data: 2893547008
I0619 14:56:42.535871 17898 layer_factory.hpp:77] Creating layer Eltwise51
I0619 14:56:42.535881 17898 net.cpp:91] Creating Layer Eltwise51
I0619 14:56:42.535887 17898 net.cpp:425] Eltwise51 <- Eltwise50_ReLU101_0_split_1
I0619 14:56:42.535892 17898 net.cpp:425] Eltwise51 <- Convolution103
I0619 14:56:42.535898 17898 net.cpp:399] Eltwise51 -> Eltwise51
I0619 14:56:42.535922 17898 net.cpp:141] Setting up Eltwise51
I0619 14:56:42.535928 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.535933 17898 net.cpp:156] Memory required for data: 2895644160
I0619 14:56:42.535936 17898 layer_factory.hpp:77] Creating layer ReLU103
I0619 14:56:42.535943 17898 net.cpp:91] Creating Layer ReLU103
I0619 14:56:42.535948 17898 net.cpp:425] ReLU103 <- Eltwise51
I0619 14:56:42.535953 17898 net.cpp:386] ReLU103 -> Eltwise51 (in-place)
I0619 14:56:42.535959 17898 net.cpp:141] Setting up ReLU103
I0619 14:56:42.535964 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.535969 17898 net.cpp:156] Memory required for data: 2897741312
I0619 14:56:42.535972 17898 layer_factory.hpp:77] Creating layer Eltwise51_ReLU103_0_split
I0619 14:56:42.535979 17898 net.cpp:91] Creating Layer Eltwise51_ReLU103_0_split
I0619 14:56:42.535981 17898 net.cpp:425] Eltwise51_ReLU103_0_split <- Eltwise51
I0619 14:56:42.535989 17898 net.cpp:399] Eltwise51_ReLU103_0_split -> Eltwise51_ReLU103_0_split_0
I0619 14:56:42.535997 17898 net.cpp:399] Eltwise51_ReLU103_0_split -> Eltwise51_ReLU103_0_split_1
I0619 14:56:42.536042 17898 net.cpp:141] Setting up Eltwise51_ReLU103_0_split
I0619 14:56:42.536062 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.536067 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.536072 17898 net.cpp:156] Memory required for data: 2901935616
I0619 14:56:42.536075 17898 layer_factory.hpp:77] Creating layer Convolution104
I0619 14:56:42.536085 17898 net.cpp:91] Creating Layer Convolution104
I0619 14:56:42.536090 17898 net.cpp:425] Convolution104 <- Eltwise51_ReLU103_0_split_0
I0619 14:56:42.536098 17898 net.cpp:399] Convolution104 -> Convolution104
I0619 14:56:42.537731 17898 net.cpp:141] Setting up Convolution104
I0619 14:56:42.537740 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.537744 17898 net.cpp:156] Memory required for data: 2904032768
I0619 14:56:42.537751 17898 layer_factory.hpp:77] Creating layer BatchNorm104
I0619 14:56:42.537760 17898 net.cpp:91] Creating Layer BatchNorm104
I0619 14:56:42.537765 17898 net.cpp:425] BatchNorm104 <- Convolution104
I0619 14:56:42.537771 17898 net.cpp:386] BatchNorm104 -> Convolution104 (in-place)
I0619 14:56:42.538000 17898 net.cpp:141] Setting up BatchNorm104
I0619 14:56:42.538008 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.538012 17898 net.cpp:156] Memory required for data: 2906129920
I0619 14:56:42.538020 17898 layer_factory.hpp:77] Creating layer Scale104
I0619 14:56:42.538028 17898 net.cpp:91] Creating Layer Scale104
I0619 14:56:42.538033 17898 net.cpp:425] Scale104 <- Convolution104
I0619 14:56:42.538038 17898 net.cpp:386] Scale104 -> Convolution104 (in-place)
I0619 14:56:42.538080 17898 layer_factory.hpp:77] Creating layer Scale104
I0619 14:56:42.538216 17898 net.cpp:141] Setting up Scale104
I0619 14:56:42.538224 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.538228 17898 net.cpp:156] Memory required for data: 2908227072
I0619 14:56:42.538235 17898 layer_factory.hpp:77] Creating layer ReLU104
I0619 14:56:42.538244 17898 net.cpp:91] Creating Layer ReLU104
I0619 14:56:42.538247 17898 net.cpp:425] ReLU104 <- Convolution104
I0619 14:56:42.538254 17898 net.cpp:386] ReLU104 -> Convolution104 (in-place)
I0619 14:56:42.538260 17898 net.cpp:141] Setting up ReLU104
I0619 14:56:42.538265 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.538269 17898 net.cpp:156] Memory required for data: 2910324224
I0619 14:56:42.538274 17898 layer_factory.hpp:77] Creating layer Convolution105
I0619 14:56:42.538285 17898 net.cpp:91] Creating Layer Convolution105
I0619 14:56:42.538288 17898 net.cpp:425] Convolution105 <- Convolution104
I0619 14:56:42.538295 17898 net.cpp:399] Convolution105 -> Convolution105
I0619 14:56:42.539939 17898 net.cpp:141] Setting up Convolution105
I0619 14:56:42.539950 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.539954 17898 net.cpp:156] Memory required for data: 2912421376
I0619 14:56:42.539961 17898 layer_factory.hpp:77] Creating layer BatchNorm105
I0619 14:56:42.539970 17898 net.cpp:91] Creating Layer BatchNorm105
I0619 14:56:42.539975 17898 net.cpp:425] BatchNorm105 <- Convolution105
I0619 14:56:42.539981 17898 net.cpp:386] BatchNorm105 -> Convolution105 (in-place)
I0619 14:56:42.540208 17898 net.cpp:141] Setting up BatchNorm105
I0619 14:56:42.540216 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.540220 17898 net.cpp:156] Memory required for data: 2914518528
I0619 14:56:42.540230 17898 layer_factory.hpp:77] Creating layer Scale105
I0619 14:56:42.540236 17898 net.cpp:91] Creating Layer Scale105
I0619 14:56:42.540241 17898 net.cpp:425] Scale105 <- Convolution105
I0619 14:56:42.540248 17898 net.cpp:386] Scale105 -> Convolution105 (in-place)
I0619 14:56:42.540287 17898 layer_factory.hpp:77] Creating layer Scale105
I0619 14:56:42.540426 17898 net.cpp:141] Setting up Scale105
I0619 14:56:42.540434 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.540437 17898 net.cpp:156] Memory required for data: 2916615680
I0619 14:56:42.540444 17898 layer_factory.hpp:77] Creating layer Eltwise52
I0619 14:56:42.540454 17898 net.cpp:91] Creating Layer Eltwise52
I0619 14:56:42.540472 17898 net.cpp:425] Eltwise52 <- Eltwise51_ReLU103_0_split_1
I0619 14:56:42.540477 17898 net.cpp:425] Eltwise52 <- Convolution105
I0619 14:56:42.540487 17898 net.cpp:399] Eltwise52 -> Eltwise52
I0619 14:56:42.540509 17898 net.cpp:141] Setting up Eltwise52
I0619 14:56:42.540516 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.540520 17898 net.cpp:156] Memory required for data: 2918712832
I0619 14:56:42.540524 17898 layer_factory.hpp:77] Creating layer ReLU105
I0619 14:56:42.540532 17898 net.cpp:91] Creating Layer ReLU105
I0619 14:56:42.540536 17898 net.cpp:425] ReLU105 <- Eltwise52
I0619 14:56:42.540542 17898 net.cpp:386] ReLU105 -> Eltwise52 (in-place)
I0619 14:56:42.540549 17898 net.cpp:141] Setting up ReLU105
I0619 14:56:42.540555 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.540558 17898 net.cpp:156] Memory required for data: 2920809984
I0619 14:56:42.540561 17898 layer_factory.hpp:77] Creating layer Eltwise52_ReLU105_0_split
I0619 14:56:42.540567 17898 net.cpp:91] Creating Layer Eltwise52_ReLU105_0_split
I0619 14:56:42.540571 17898 net.cpp:425] Eltwise52_ReLU105_0_split <- Eltwise52
I0619 14:56:42.540580 17898 net.cpp:399] Eltwise52_ReLU105_0_split -> Eltwise52_ReLU105_0_split_0
I0619 14:56:42.540587 17898 net.cpp:399] Eltwise52_ReLU105_0_split -> Eltwise52_ReLU105_0_split_1
I0619 14:56:42.540627 17898 net.cpp:141] Setting up Eltwise52_ReLU105_0_split
I0619 14:56:42.540633 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.540638 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.540642 17898 net.cpp:156] Memory required for data: 2925004288
I0619 14:56:42.540647 17898 layer_factory.hpp:77] Creating layer Convolution106
I0619 14:56:42.540657 17898 net.cpp:91] Creating Layer Convolution106
I0619 14:56:42.540663 17898 net.cpp:425] Convolution106 <- Eltwise52_ReLU105_0_split_0
I0619 14:56:42.540669 17898 net.cpp:399] Convolution106 -> Convolution106
I0619 14:56:42.542310 17898 net.cpp:141] Setting up Convolution106
I0619 14:56:42.542320 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.542325 17898 net.cpp:156] Memory required for data: 2927101440
I0619 14:56:42.542331 17898 layer_factory.hpp:77] Creating layer BatchNorm106
I0619 14:56:42.542341 17898 net.cpp:91] Creating Layer BatchNorm106
I0619 14:56:42.542347 17898 net.cpp:425] BatchNorm106 <- Convolution106
I0619 14:56:42.542357 17898 net.cpp:386] BatchNorm106 -> Convolution106 (in-place)
I0619 14:56:42.542601 17898 net.cpp:141] Setting up BatchNorm106
I0619 14:56:42.542610 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.542614 17898 net.cpp:156] Memory required for data: 2929198592
I0619 14:56:42.542623 17898 layer_factory.hpp:77] Creating layer Scale106
I0619 14:56:42.542629 17898 net.cpp:91] Creating Layer Scale106
I0619 14:56:42.542634 17898 net.cpp:425] Scale106 <- Convolution106
I0619 14:56:42.542640 17898 net.cpp:386] Scale106 -> Convolution106 (in-place)
I0619 14:56:42.542686 17898 layer_factory.hpp:77] Creating layer Scale106
I0619 14:56:42.542835 17898 net.cpp:141] Setting up Scale106
I0619 14:56:42.542843 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.542847 17898 net.cpp:156] Memory required for data: 2931295744
I0619 14:56:42.542855 17898 layer_factory.hpp:77] Creating layer ReLU106
I0619 14:56:42.542860 17898 net.cpp:91] Creating Layer ReLU106
I0619 14:56:42.542865 17898 net.cpp:425] ReLU106 <- Convolution106
I0619 14:56:42.542873 17898 net.cpp:386] ReLU106 -> Convolution106 (in-place)
I0619 14:56:42.542881 17898 net.cpp:141] Setting up ReLU106
I0619 14:56:42.542886 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.542889 17898 net.cpp:156] Memory required for data: 2933392896
I0619 14:56:42.542893 17898 layer_factory.hpp:77] Creating layer Convolution107
I0619 14:56:42.542906 17898 net.cpp:91] Creating Layer Convolution107
I0619 14:56:42.542911 17898 net.cpp:425] Convolution107 <- Convolution106
I0619 14:56:42.542917 17898 net.cpp:399] Convolution107 -> Convolution107
I0619 14:56:42.544558 17898 net.cpp:141] Setting up Convolution107
I0619 14:56:42.544579 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.544584 17898 net.cpp:156] Memory required for data: 2935490048
I0619 14:56:42.544590 17898 layer_factory.hpp:77] Creating layer BatchNorm107
I0619 14:56:42.544597 17898 net.cpp:91] Creating Layer BatchNorm107
I0619 14:56:42.544602 17898 net.cpp:425] BatchNorm107 <- Convolution107
I0619 14:56:42.544611 17898 net.cpp:386] BatchNorm107 -> Convolution107 (in-place)
I0619 14:56:42.544845 17898 net.cpp:141] Setting up BatchNorm107
I0619 14:56:42.544853 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.544857 17898 net.cpp:156] Memory required for data: 2937587200
I0619 14:56:42.544865 17898 layer_factory.hpp:77] Creating layer Scale107
I0619 14:56:42.544872 17898 net.cpp:91] Creating Layer Scale107
I0619 14:56:42.544878 17898 net.cpp:425] Scale107 <- Convolution107
I0619 14:56:42.544885 17898 net.cpp:386] Scale107 -> Convolution107 (in-place)
I0619 14:56:42.544924 17898 layer_factory.hpp:77] Creating layer Scale107
I0619 14:56:42.545063 17898 net.cpp:141] Setting up Scale107
I0619 14:56:42.545071 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.545075 17898 net.cpp:156] Memory required for data: 2939684352
I0619 14:56:42.545083 17898 layer_factory.hpp:77] Creating layer Eltwise53
I0619 14:56:42.545089 17898 net.cpp:91] Creating Layer Eltwise53
I0619 14:56:42.545094 17898 net.cpp:425] Eltwise53 <- Eltwise52_ReLU105_0_split_1
I0619 14:56:42.545099 17898 net.cpp:425] Eltwise53 <- Convolution107
I0619 14:56:42.545109 17898 net.cpp:399] Eltwise53 -> Eltwise53
I0619 14:56:42.545130 17898 net.cpp:141] Setting up Eltwise53
I0619 14:56:42.545136 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.545140 17898 net.cpp:156] Memory required for data: 2941781504
I0619 14:56:42.545145 17898 layer_factory.hpp:77] Creating layer ReLU107
I0619 14:56:42.545152 17898 net.cpp:91] Creating Layer ReLU107
I0619 14:56:42.545156 17898 net.cpp:425] ReLU107 <- Eltwise53
I0619 14:56:42.545162 17898 net.cpp:386] ReLU107 -> Eltwise53 (in-place)
I0619 14:56:42.545168 17898 net.cpp:141] Setting up ReLU107
I0619 14:56:42.545174 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.545178 17898 net.cpp:156] Memory required for data: 2943878656
I0619 14:56:42.545181 17898 layer_factory.hpp:77] Creating layer Eltwise53_ReLU107_0_split
I0619 14:56:42.545188 17898 net.cpp:91] Creating Layer Eltwise53_ReLU107_0_split
I0619 14:56:42.545192 17898 net.cpp:425] Eltwise53_ReLU107_0_split <- Eltwise53
I0619 14:56:42.545197 17898 net.cpp:399] Eltwise53_ReLU107_0_split -> Eltwise53_ReLU107_0_split_0
I0619 14:56:42.545207 17898 net.cpp:399] Eltwise53_ReLU107_0_split -> Eltwise53_ReLU107_0_split_1
I0619 14:56:42.545253 17898 net.cpp:141] Setting up Eltwise53_ReLU107_0_split
I0619 14:56:42.545260 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.545265 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.545269 17898 net.cpp:156] Memory required for data: 2948072960
I0619 14:56:42.545274 17898 layer_factory.hpp:77] Creating layer Convolution108
I0619 14:56:42.545284 17898 net.cpp:91] Creating Layer Convolution108
I0619 14:56:42.545289 17898 net.cpp:425] Convolution108 <- Eltwise53_ReLU107_0_split_0
I0619 14:56:42.545296 17898 net.cpp:399] Convolution108 -> Convolution108
I0619 14:56:42.547541 17898 net.cpp:141] Setting up Convolution108
I0619 14:56:42.547556 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.547561 17898 net.cpp:156] Memory required for data: 2950170112
I0619 14:56:42.547569 17898 layer_factory.hpp:77] Creating layer BatchNorm108
I0619 14:56:42.547577 17898 net.cpp:91] Creating Layer BatchNorm108
I0619 14:56:42.547582 17898 net.cpp:425] BatchNorm108 <- Convolution108
I0619 14:56:42.547591 17898 net.cpp:386] BatchNorm108 -> Convolution108 (in-place)
I0619 14:56:42.547829 17898 net.cpp:141] Setting up BatchNorm108
I0619 14:56:42.547837 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.547845 17898 net.cpp:156] Memory required for data: 2952267264
I0619 14:56:42.547868 17898 layer_factory.hpp:77] Creating layer Scale108
I0619 14:56:42.547875 17898 net.cpp:91] Creating Layer Scale108
I0619 14:56:42.547880 17898 net.cpp:425] Scale108 <- Convolution108
I0619 14:56:42.547889 17898 net.cpp:386] Scale108 -> Convolution108 (in-place)
I0619 14:56:42.547932 17898 layer_factory.hpp:77] Creating layer Scale108
I0619 14:56:42.548074 17898 net.cpp:141] Setting up Scale108
I0619 14:56:42.548082 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.548086 17898 net.cpp:156] Memory required for data: 2954364416
I0619 14:56:42.548094 17898 layer_factory.hpp:77] Creating layer ReLU108
I0619 14:56:42.548100 17898 net.cpp:91] Creating Layer ReLU108
I0619 14:56:42.548105 17898 net.cpp:425] ReLU108 <- Convolution108
I0619 14:56:42.548110 17898 net.cpp:386] ReLU108 -> Convolution108 (in-place)
I0619 14:56:42.548117 17898 net.cpp:141] Setting up ReLU108
I0619 14:56:42.548123 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.548127 17898 net.cpp:156] Memory required for data: 2956461568
I0619 14:56:42.548131 17898 layer_factory.hpp:77] Creating layer Convolution109
I0619 14:56:42.548142 17898 net.cpp:91] Creating Layer Convolution109
I0619 14:56:42.548147 17898 net.cpp:425] Convolution109 <- Convolution108
I0619 14:56:42.548156 17898 net.cpp:399] Convolution109 -> Convolution109
I0619 14:56:42.549793 17898 net.cpp:141] Setting up Convolution109
I0619 14:56:42.549801 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.549805 17898 net.cpp:156] Memory required for data: 2958558720
I0619 14:56:42.549813 17898 layer_factory.hpp:77] Creating layer BatchNorm109
I0619 14:56:42.549823 17898 net.cpp:91] Creating Layer BatchNorm109
I0619 14:56:42.549828 17898 net.cpp:425] BatchNorm109 <- Convolution109
I0619 14:56:42.549835 17898 net.cpp:386] BatchNorm109 -> Convolution109 (in-place)
I0619 14:56:42.550068 17898 net.cpp:141] Setting up BatchNorm109
I0619 14:56:42.550076 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.550081 17898 net.cpp:156] Memory required for data: 2960655872
I0619 14:56:42.550088 17898 layer_factory.hpp:77] Creating layer Scale109
I0619 14:56:42.550097 17898 net.cpp:91] Creating Layer Scale109
I0619 14:56:42.550102 17898 net.cpp:425] Scale109 <- Convolution109
I0619 14:56:42.550108 17898 net.cpp:386] Scale109 -> Convolution109 (in-place)
I0619 14:56:42.550149 17898 layer_factory.hpp:77] Creating layer Scale109
I0619 14:56:42.550287 17898 net.cpp:141] Setting up Scale109
I0619 14:56:42.550293 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.550297 17898 net.cpp:156] Memory required for data: 2962753024
I0619 14:56:42.550304 17898 layer_factory.hpp:77] Creating layer Eltwise54
I0619 14:56:42.550315 17898 net.cpp:91] Creating Layer Eltwise54
I0619 14:56:42.550321 17898 net.cpp:425] Eltwise54 <- Eltwise53_ReLU107_0_split_1
I0619 14:56:42.550328 17898 net.cpp:425] Eltwise54 <- Convolution109
I0619 14:56:42.550333 17898 net.cpp:399] Eltwise54 -> Eltwise54
I0619 14:56:42.550365 17898 net.cpp:141] Setting up Eltwise54
I0619 14:56:42.550374 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.550377 17898 net.cpp:156] Memory required for data: 2964850176
I0619 14:56:42.550381 17898 layer_factory.hpp:77] Creating layer ReLU109
I0619 14:56:42.550387 17898 net.cpp:91] Creating Layer ReLU109
I0619 14:56:42.550392 17898 net.cpp:425] ReLU109 <- Eltwise54
I0619 14:56:42.550397 17898 net.cpp:386] ReLU109 -> Eltwise54 (in-place)
I0619 14:56:42.550405 17898 net.cpp:141] Setting up ReLU109
I0619 14:56:42.550410 17898 net.cpp:148] Top shape: 128 64 8 8 (524288)
I0619 14:56:42.550415 17898 net.cpp:156] Memory required for data: 2966947328
I0619 14:56:42.550417 17898 layer_factory.hpp:77] Creating layer Pooling4
I0619 14:56:42.550427 17898 net.cpp:91] Creating Layer Pooling4
I0619 14:56:42.550431 17898 net.cpp:425] Pooling4 <- Eltwise54
I0619 14:56:42.550437 17898 net.cpp:399] Pooling4 -> Pooling4
I0619 14:56:42.550467 17898 net.cpp:141] Setting up Pooling4
I0619 14:56:42.550477 17898 net.cpp:148] Top shape: 128 64 1 1 (8192)
I0619 14:56:42.550492 17898 net.cpp:156] Memory required for data: 2966980096
I0619 14:56:42.550495 17898 layer_factory.hpp:77] Creating layer InnerProduct1
I0619 14:56:42.550504 17898 net.cpp:91] Creating Layer InnerProduct1
I0619 14:56:42.550509 17898 net.cpp:425] InnerProduct1 <- Pooling4
I0619 14:56:42.550518 17898 net.cpp:399] InnerProduct1 -> InnerProduct1
I0619 14:56:42.550676 17898 net.cpp:141] Setting up InnerProduct1
I0619 14:56:42.550686 17898 net.cpp:148] Top shape: 128 10 (1280)
I0619 14:56:42.550690 17898 net.cpp:156] Memory required for data: 2966985216
I0619 14:56:42.550698 17898 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0619 14:56:42.550704 17898 net.cpp:91] Creating Layer InnerProduct1_InnerProduct1_0_split
I0619 14:56:42.550709 17898 net.cpp:425] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0619 14:56:42.550716 17898 net.cpp:399] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0619 14:56:42.550724 17898 net.cpp:399] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0619 14:56:42.550762 17898 net.cpp:141] Setting up InnerProduct1_InnerProduct1_0_split
I0619 14:56:42.550770 17898 net.cpp:148] Top shape: 128 10 (1280)
I0619 14:56:42.550775 17898 net.cpp:148] Top shape: 128 10 (1280)
I0619 14:56:42.550777 17898 net.cpp:156] Memory required for data: 2966995456
I0619 14:56:42.550781 17898 layer_factory.hpp:77] Creating layer Accuracy
I0619 14:56:42.550789 17898 net.cpp:91] Creating Layer Accuracy
I0619 14:56:42.550793 17898 net.cpp:425] Accuracy <- InnerProduct1_InnerProduct1_0_split_0
I0619 14:56:42.550798 17898 net.cpp:425] Accuracy <- Data2_Data1_1_split_0
I0619 14:56:42.550806 17898 net.cpp:399] Accuracy -> Accuracy
I0619 14:56:42.550820 17898 net.cpp:141] Setting up Accuracy
I0619 14:56:42.550825 17898 net.cpp:148] Top shape: (1)
I0619 14:56:42.550829 17898 net.cpp:156] Memory required for data: 2966995460
I0619 14:56:42.550833 17898 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0619 14:56:42.550840 17898 net.cpp:91] Creating Layer SoftmaxWithLoss1
I0619 14:56:42.550844 17898 net.cpp:425] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_1
I0619 14:56:42.550849 17898 net.cpp:425] SoftmaxWithLoss1 <- Data2_Data1_1_split_1
I0619 14:56:42.550858 17898 net.cpp:399] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0619 14:56:42.550868 17898 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0619 14:56:42.550974 17898 net.cpp:141] Setting up SoftmaxWithLoss1
I0619 14:56:42.550982 17898 net.cpp:148] Top shape: (1)
I0619 14:56:42.550987 17898 net.cpp:151]     with loss weight 1
I0619 14:56:42.550998 17898 net.cpp:156] Memory required for data: 2966995464
I0619 14:56:42.551002 17898 net.cpp:217] SoftmaxWithLoss1 needs backward computation.
I0619 14:56:42.551007 17898 net.cpp:219] Accuracy does not need backward computation.
I0619 14:56:42.551012 17898 net.cpp:217] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0619 14:56:42.551017 17898 net.cpp:217] InnerProduct1 needs backward computation.
I0619 14:56:42.551020 17898 net.cpp:217] Pooling4 needs backward computation.
I0619 14:56:42.551024 17898 net.cpp:217] ReLU109 needs backward computation.
I0619 14:56:42.551028 17898 net.cpp:217] Eltwise54 needs backward computation.
I0619 14:56:42.551033 17898 net.cpp:217] Scale109 needs backward computation.
I0619 14:56:42.551036 17898 net.cpp:217] BatchNorm109 needs backward computation.
I0619 14:56:42.551040 17898 net.cpp:217] Convolution109 needs backward computation.
I0619 14:56:42.551044 17898 net.cpp:217] ReLU108 needs backward computation.
I0619 14:56:42.551048 17898 net.cpp:217] Scale108 needs backward computation.
I0619 14:56:42.551051 17898 net.cpp:217] BatchNorm108 needs backward computation.
I0619 14:56:42.551055 17898 net.cpp:217] Convolution108 needs backward computation.
I0619 14:56:42.551059 17898 net.cpp:217] Eltwise53_ReLU107_0_split needs backward computation.
I0619 14:56:42.551064 17898 net.cpp:217] ReLU107 needs backward computation.
I0619 14:56:42.551071 17898 net.cpp:217] Eltwise53 needs backward computation.
I0619 14:56:42.551087 17898 net.cpp:217] Scale107 needs backward computation.
I0619 14:56:42.551091 17898 net.cpp:217] BatchNorm107 needs backward computation.
I0619 14:56:42.551095 17898 net.cpp:217] Convolution107 needs backward computation.
I0619 14:56:42.551101 17898 net.cpp:217] ReLU106 needs backward computation.
I0619 14:56:42.551105 17898 net.cpp:217] Scale106 needs backward computation.
I0619 14:56:42.551108 17898 net.cpp:217] BatchNorm106 needs backward computation.
I0619 14:56:42.551112 17898 net.cpp:217] Convolution106 needs backward computation.
I0619 14:56:42.551116 17898 net.cpp:217] Eltwise52_ReLU105_0_split needs backward computation.
I0619 14:56:42.551120 17898 net.cpp:217] ReLU105 needs backward computation.
I0619 14:56:42.551125 17898 net.cpp:217] Eltwise52 needs backward computation.
I0619 14:56:42.551129 17898 net.cpp:217] Scale105 needs backward computation.
I0619 14:56:42.551132 17898 net.cpp:217] BatchNorm105 needs backward computation.
I0619 14:56:42.551136 17898 net.cpp:217] Convolution105 needs backward computation.
I0619 14:56:42.551141 17898 net.cpp:217] ReLU104 needs backward computation.
I0619 14:56:42.551143 17898 net.cpp:217] Scale104 needs backward computation.
I0619 14:56:42.551147 17898 net.cpp:217] BatchNorm104 needs backward computation.
I0619 14:56:42.551151 17898 net.cpp:217] Convolution104 needs backward computation.
I0619 14:56:42.551156 17898 net.cpp:217] Eltwise51_ReLU103_0_split needs backward computation.
I0619 14:56:42.551159 17898 net.cpp:217] ReLU103 needs backward computation.
I0619 14:56:42.551163 17898 net.cpp:217] Eltwise51 needs backward computation.
I0619 14:56:42.551167 17898 net.cpp:217] Scale103 needs backward computation.
I0619 14:56:42.551172 17898 net.cpp:217] BatchNorm103 needs backward computation.
I0619 14:56:42.551175 17898 net.cpp:217] Convolution103 needs backward computation.
I0619 14:56:42.551178 17898 net.cpp:217] ReLU102 needs backward computation.
I0619 14:56:42.551182 17898 net.cpp:217] Scale102 needs backward computation.
I0619 14:56:42.551187 17898 net.cpp:217] BatchNorm102 needs backward computation.
I0619 14:56:42.551189 17898 net.cpp:217] Convolution102 needs backward computation.
I0619 14:56:42.551193 17898 net.cpp:217] Eltwise50_ReLU101_0_split needs backward computation.
I0619 14:56:42.551198 17898 net.cpp:217] ReLU101 needs backward computation.
I0619 14:56:42.551201 17898 net.cpp:217] Eltwise50 needs backward computation.
I0619 14:56:42.551206 17898 net.cpp:217] Scale101 needs backward computation.
I0619 14:56:42.551210 17898 net.cpp:217] BatchNorm101 needs backward computation.
I0619 14:56:42.551213 17898 net.cpp:217] Convolution101 needs backward computation.
I0619 14:56:42.551218 17898 net.cpp:217] ReLU100 needs backward computation.
I0619 14:56:42.551221 17898 net.cpp:217] Scale100 needs backward computation.
I0619 14:56:42.551224 17898 net.cpp:217] BatchNorm100 needs backward computation.
I0619 14:56:42.551229 17898 net.cpp:217] Convolution100 needs backward computation.
I0619 14:56:42.551232 17898 net.cpp:217] Eltwise49_ReLU99_0_split needs backward computation.
I0619 14:56:42.551236 17898 net.cpp:217] ReLU99 needs backward computation.
I0619 14:56:42.551240 17898 net.cpp:217] Eltwise49 needs backward computation.
I0619 14:56:42.551245 17898 net.cpp:217] Scale99 needs backward computation.
I0619 14:56:42.551249 17898 net.cpp:217] BatchNorm99 needs backward computation.
I0619 14:56:42.551254 17898 net.cpp:217] Convolution99 needs backward computation.
I0619 14:56:42.551257 17898 net.cpp:217] ReLU98 needs backward computation.
I0619 14:56:42.551261 17898 net.cpp:217] Scale98 needs backward computation.
I0619 14:56:42.551265 17898 net.cpp:217] BatchNorm98 needs backward computation.
I0619 14:56:42.551270 17898 net.cpp:217] Convolution98 needs backward computation.
I0619 14:56:42.551273 17898 net.cpp:217] Eltwise48_ReLU97_0_split needs backward computation.
I0619 14:56:42.551277 17898 net.cpp:217] ReLU97 needs backward computation.
I0619 14:56:42.551283 17898 net.cpp:217] Eltwise48 needs backward computation.
I0619 14:56:42.551295 17898 net.cpp:217] Scale97 needs backward computation.
I0619 14:56:42.551298 17898 net.cpp:217] BatchNorm97 needs backward computation.
I0619 14:56:42.551302 17898 net.cpp:217] Convolution97 needs backward computation.
I0619 14:56:42.551306 17898 net.cpp:217] ReLU96 needs backward computation.
I0619 14:56:42.551311 17898 net.cpp:217] Scale96 needs backward computation.
I0619 14:56:42.551313 17898 net.cpp:217] BatchNorm96 needs backward computation.
I0619 14:56:42.551317 17898 net.cpp:217] Convolution96 needs backward computation.
I0619 14:56:42.551321 17898 net.cpp:217] Eltwise47_ReLU95_0_split needs backward computation.
I0619 14:56:42.551326 17898 net.cpp:217] ReLU95 needs backward computation.
I0619 14:56:42.551329 17898 net.cpp:217] Eltwise47 needs backward computation.
I0619 14:56:42.551334 17898 net.cpp:217] Scale95 needs backward computation.
I0619 14:56:42.551337 17898 net.cpp:217] BatchNorm95 needs backward computation.
I0619 14:56:42.551342 17898 net.cpp:217] Convolution95 needs backward computation.
I0619 14:56:42.551345 17898 net.cpp:217] ReLU94 needs backward computation.
I0619 14:56:42.551349 17898 net.cpp:217] Scale94 needs backward computation.
I0619 14:56:42.551352 17898 net.cpp:217] BatchNorm94 needs backward computation.
I0619 14:56:42.551357 17898 net.cpp:217] Convolution94 needs backward computation.
I0619 14:56:42.551360 17898 net.cpp:217] Eltwise46_ReLU93_0_split needs backward computation.
I0619 14:56:42.551364 17898 net.cpp:217] ReLU93 needs backward computation.
I0619 14:56:42.551368 17898 net.cpp:217] Eltwise46 needs backward computation.
I0619 14:56:42.551373 17898 net.cpp:217] Scale93 needs backward computation.
I0619 14:56:42.551378 17898 net.cpp:217] BatchNorm93 needs backward computation.
I0619 14:56:42.551383 17898 net.cpp:217] Convolution93 needs backward computation.
I0619 14:56:42.551386 17898 net.cpp:217] ReLU92 needs backward computation.
I0619 14:56:42.551390 17898 net.cpp:217] Scale92 needs backward computation.
I0619 14:56:42.551393 17898 net.cpp:217] BatchNorm92 needs backward computation.
I0619 14:56:42.551398 17898 net.cpp:217] Convolution92 needs backward computation.
I0619 14:56:42.551401 17898 net.cpp:217] Eltwise45_ReLU91_0_split needs backward computation.
I0619 14:56:42.551405 17898 net.cpp:217] ReLU91 needs backward computation.
I0619 14:56:42.551409 17898 net.cpp:217] Eltwise45 needs backward computation.
I0619 14:56:42.551414 17898 net.cpp:217] Scale91 needs backward computation.
I0619 14:56:42.551417 17898 net.cpp:217] BatchNorm91 needs backward computation.
I0619 14:56:42.551421 17898 net.cpp:217] Convolution91 needs backward computation.
I0619 14:56:42.551425 17898 net.cpp:217] ReLU90 needs backward computation.
I0619 14:56:42.551429 17898 net.cpp:217] Scale90 needs backward computation.
I0619 14:56:42.551432 17898 net.cpp:217] BatchNorm90 needs backward computation.
I0619 14:56:42.551436 17898 net.cpp:217] Convolution90 needs backward computation.
I0619 14:56:42.551440 17898 net.cpp:217] Eltwise44_ReLU89_0_split needs backward computation.
I0619 14:56:42.551445 17898 net.cpp:217] ReLU89 needs backward computation.
I0619 14:56:42.551448 17898 net.cpp:217] Eltwise44 needs backward computation.
I0619 14:56:42.551452 17898 net.cpp:217] Scale89 needs backward computation.
I0619 14:56:42.551456 17898 net.cpp:217] BatchNorm89 needs backward computation.
I0619 14:56:42.551460 17898 net.cpp:217] Convolution89 needs backward computation.
I0619 14:56:42.551465 17898 net.cpp:217] ReLU88 needs backward computation.
I0619 14:56:42.551468 17898 net.cpp:217] Scale88 needs backward computation.
I0619 14:56:42.551471 17898 net.cpp:217] BatchNorm88 needs backward computation.
I0619 14:56:42.551476 17898 net.cpp:217] Convolution88 needs backward computation.
I0619 14:56:42.551479 17898 net.cpp:217] Eltwise43_ReLU87_0_split needs backward computation.
I0619 14:56:42.551483 17898 net.cpp:217] ReLU87 needs backward computation.
I0619 14:56:42.551487 17898 net.cpp:217] Eltwise43 needs backward computation.
I0619 14:56:42.551493 17898 net.cpp:217] Scale87 needs backward computation.
I0619 14:56:42.551503 17898 net.cpp:217] BatchNorm87 needs backward computation.
I0619 14:56:42.551507 17898 net.cpp:217] Convolution87 needs backward computation.
I0619 14:56:42.551512 17898 net.cpp:217] ReLU86 needs backward computation.
I0619 14:56:42.551515 17898 net.cpp:217] Scale86 needs backward computation.
I0619 14:56:42.551519 17898 net.cpp:217] BatchNorm86 needs backward computation.
I0619 14:56:42.551522 17898 net.cpp:217] Convolution86 needs backward computation.
I0619 14:56:42.551527 17898 net.cpp:217] Eltwise42_ReLU85_0_split needs backward computation.
I0619 14:56:42.551532 17898 net.cpp:217] ReLU85 needs backward computation.
I0619 14:56:42.551534 17898 net.cpp:217] Eltwise42 needs backward computation.
I0619 14:56:42.551539 17898 net.cpp:217] Scale85 needs backward computation.
I0619 14:56:42.551542 17898 net.cpp:217] BatchNorm85 needs backward computation.
I0619 14:56:42.551547 17898 net.cpp:217] Convolution85 needs backward computation.
I0619 14:56:42.551550 17898 net.cpp:217] ReLU84 needs backward computation.
I0619 14:56:42.551554 17898 net.cpp:217] Scale84 needs backward computation.
I0619 14:56:42.551558 17898 net.cpp:217] BatchNorm84 needs backward computation.
I0619 14:56:42.551561 17898 net.cpp:217] Convolution84 needs backward computation.
I0619 14:56:42.551565 17898 net.cpp:217] Eltwise41_ReLU83_0_split needs backward computation.
I0619 14:56:42.551569 17898 net.cpp:217] ReLU83 needs backward computation.
I0619 14:56:42.551573 17898 net.cpp:217] Eltwise41 needs backward computation.
I0619 14:56:42.551578 17898 net.cpp:217] Scale83 needs backward computation.
I0619 14:56:42.551581 17898 net.cpp:217] BatchNorm83 needs backward computation.
I0619 14:56:42.551585 17898 net.cpp:217] Convolution83 needs backward computation.
I0619 14:56:42.551589 17898 net.cpp:217] ReLU82 needs backward computation.
I0619 14:56:42.551592 17898 net.cpp:217] Scale82 needs backward computation.
I0619 14:56:42.551596 17898 net.cpp:217] BatchNorm82 needs backward computation.
I0619 14:56:42.551600 17898 net.cpp:217] Convolution82 needs backward computation.
I0619 14:56:42.551604 17898 net.cpp:217] Eltwise40_ReLU81_0_split needs backward computation.
I0619 14:56:42.551607 17898 net.cpp:217] ReLU81 needs backward computation.
I0619 14:56:42.551611 17898 net.cpp:217] Eltwise40 needs backward computation.
I0619 14:56:42.551616 17898 net.cpp:217] Scale81 needs backward computation.
I0619 14:56:42.551620 17898 net.cpp:217] BatchNorm81 needs backward computation.
I0619 14:56:42.551623 17898 net.cpp:217] Convolution81 needs backward computation.
I0619 14:56:42.551627 17898 net.cpp:217] ReLU80 needs backward computation.
I0619 14:56:42.551631 17898 net.cpp:217] Scale80 needs backward computation.
I0619 14:56:42.551635 17898 net.cpp:217] BatchNorm80 needs backward computation.
I0619 14:56:42.551638 17898 net.cpp:217] Convolution80 needs backward computation.
I0619 14:56:42.551642 17898 net.cpp:217] Eltwise39_ReLU79_0_split needs backward computation.
I0619 14:56:42.551646 17898 net.cpp:217] ReLU79 needs backward computation.
I0619 14:56:42.551651 17898 net.cpp:217] Eltwise39 needs backward computation.
I0619 14:56:42.551656 17898 net.cpp:217] Scale79 needs backward computation.
I0619 14:56:42.551659 17898 net.cpp:217] BatchNorm79 needs backward computation.
I0619 14:56:42.551663 17898 net.cpp:217] Convolution79 needs backward computation.
I0619 14:56:42.551667 17898 net.cpp:217] ReLU78 needs backward computation.
I0619 14:56:42.551671 17898 net.cpp:217] Scale78 needs backward computation.
I0619 14:56:42.551674 17898 net.cpp:217] BatchNorm78 needs backward computation.
I0619 14:56:42.551678 17898 net.cpp:217] Convolution78 needs backward computation.
I0619 14:56:42.551682 17898 net.cpp:217] Eltwise38_ReLU77_0_split needs backward computation.
I0619 14:56:42.551687 17898 net.cpp:217] ReLU77 needs backward computation.
I0619 14:56:42.551690 17898 net.cpp:217] Eltwise38 needs backward computation.
I0619 14:56:42.551694 17898 net.cpp:217] Scale77 needs backward computation.
I0619 14:56:42.551707 17898 net.cpp:217] BatchNorm77 needs backward computation.
I0619 14:56:42.551712 17898 net.cpp:217] Convolution77 needs backward computation.
I0619 14:56:42.551715 17898 net.cpp:217] ReLU76 needs backward computation.
I0619 14:56:42.551718 17898 net.cpp:217] Scale76 needs backward computation.
I0619 14:56:42.551723 17898 net.cpp:217] BatchNorm76 needs backward computation.
I0619 14:56:42.551726 17898 net.cpp:217] Convolution76 needs backward computation.
I0619 14:56:42.551730 17898 net.cpp:217] Eltwise37_ReLU75_0_split needs backward computation.
I0619 14:56:42.551734 17898 net.cpp:217] ReLU75 needs backward computation.
I0619 14:56:42.551738 17898 net.cpp:217] Eltwise37 needs backward computation.
I0619 14:56:42.551743 17898 net.cpp:217] Scale75 needs backward computation.
I0619 14:56:42.551746 17898 net.cpp:217] BatchNorm75 needs backward computation.
I0619 14:56:42.551750 17898 net.cpp:217] Convolution75 needs backward computation.
I0619 14:56:42.551754 17898 net.cpp:217] ReLU74 needs backward computation.
I0619 14:56:42.551758 17898 net.cpp:217] Scale74 needs backward computation.
I0619 14:56:42.551761 17898 net.cpp:217] BatchNorm74 needs backward computation.
I0619 14:56:42.551765 17898 net.cpp:217] Convolution74 needs backward computation.
I0619 14:56:42.551769 17898 net.cpp:217] Concat2 needs backward computation.
I0619 14:56:42.551774 17898 net.cpp:219] Input2 does not need backward computation.
I0619 14:56:42.551779 17898 net.cpp:217] Pooling2 needs backward computation.
I0619 14:56:42.551784 17898 net.cpp:217] Eltwise36_ReLU73_0_split needs backward computation.
I0619 14:56:42.551789 17898 net.cpp:217] ReLU73 needs backward computation.
I0619 14:56:42.551794 17898 net.cpp:217] Eltwise36 needs backward computation.
I0619 14:56:42.551797 17898 net.cpp:217] Scale73 needs backward computation.
I0619 14:56:42.551801 17898 net.cpp:217] BatchNorm73 needs backward computation.
I0619 14:56:42.551805 17898 net.cpp:217] Convolution73 needs backward computation.
I0619 14:56:42.551810 17898 net.cpp:217] ReLU72 needs backward computation.
I0619 14:56:42.551813 17898 net.cpp:217] Scale72 needs backward computation.
I0619 14:56:42.551816 17898 net.cpp:217] BatchNorm72 needs backward computation.
I0619 14:56:42.551820 17898 net.cpp:217] Convolution72 needs backward computation.
I0619 14:56:42.551825 17898 net.cpp:217] Eltwise35_ReLU71_0_split needs backward computation.
I0619 14:56:42.551828 17898 net.cpp:217] ReLU71 needs backward computation.
I0619 14:56:42.551832 17898 net.cpp:217] Eltwise35 needs backward computation.
I0619 14:56:42.551837 17898 net.cpp:217] Scale71 needs backward computation.
I0619 14:56:42.551841 17898 net.cpp:217] BatchNorm71 needs backward computation.
I0619 14:56:42.551844 17898 net.cpp:217] Convolution71 needs backward computation.
I0619 14:56:42.551848 17898 net.cpp:217] ReLU70 needs backward computation.
I0619 14:56:42.551852 17898 net.cpp:217] Scale70 needs backward computation.
I0619 14:56:42.551856 17898 net.cpp:217] BatchNorm70 needs backward computation.
I0619 14:56:42.551859 17898 net.cpp:217] Convolution70 needs backward computation.
I0619 14:56:42.551864 17898 net.cpp:217] Eltwise34_ReLU69_0_split needs backward computation.
I0619 14:56:42.551868 17898 net.cpp:217] ReLU69 needs backward computation.
I0619 14:56:42.551872 17898 net.cpp:217] Eltwise34 needs backward computation.
I0619 14:56:42.551877 17898 net.cpp:217] Scale69 needs backward computation.
I0619 14:56:42.551880 17898 net.cpp:217] BatchNorm69 needs backward computation.
I0619 14:56:42.551884 17898 net.cpp:217] Convolution69 needs backward computation.
I0619 14:56:42.551888 17898 net.cpp:217] ReLU68 needs backward computation.
I0619 14:56:42.551892 17898 net.cpp:217] Scale68 needs backward computation.
I0619 14:56:42.551895 17898 net.cpp:217] BatchNorm68 needs backward computation.
I0619 14:56:42.551899 17898 net.cpp:217] Convolution68 needs backward computation.
I0619 14:56:42.551903 17898 net.cpp:217] Eltwise33_ReLU67_0_split needs backward computation.
I0619 14:56:42.551909 17898 net.cpp:217] ReLU67 needs backward computation.
I0619 14:56:42.551919 17898 net.cpp:217] Eltwise33 needs backward computation.
I0619 14:56:42.551924 17898 net.cpp:217] Scale67 needs backward computation.
I0619 14:56:42.551928 17898 net.cpp:217] BatchNorm67 needs backward computation.
I0619 14:56:42.551931 17898 net.cpp:217] Convolution67 needs backward computation.
I0619 14:56:42.551936 17898 net.cpp:217] ReLU66 needs backward computation.
I0619 14:56:42.551939 17898 net.cpp:217] Scale66 needs backward computation.
I0619 14:56:42.551944 17898 net.cpp:217] BatchNorm66 needs backward computation.
I0619 14:56:42.551947 17898 net.cpp:217] Convolution66 needs backward computation.
I0619 14:56:42.551951 17898 net.cpp:217] Eltwise32_ReLU65_0_split needs backward computation.
I0619 14:56:42.551955 17898 net.cpp:217] ReLU65 needs backward computation.
I0619 14:56:42.551959 17898 net.cpp:217] Eltwise32 needs backward computation.
I0619 14:56:42.551964 17898 net.cpp:217] Scale65 needs backward computation.
I0619 14:56:42.551967 17898 net.cpp:217] BatchNorm65 needs backward computation.
I0619 14:56:42.551970 17898 net.cpp:217] Convolution65 needs backward computation.
I0619 14:56:42.551975 17898 net.cpp:217] ReLU64 needs backward computation.
I0619 14:56:42.551978 17898 net.cpp:217] Scale64 needs backward computation.
I0619 14:56:42.551982 17898 net.cpp:217] BatchNorm64 needs backward computation.
I0619 14:56:42.551986 17898 net.cpp:217] Convolution64 needs backward computation.
I0619 14:56:42.551990 17898 net.cpp:217] Eltwise31_ReLU63_0_split needs backward computation.
I0619 14:56:42.551995 17898 net.cpp:217] ReLU63 needs backward computation.
I0619 14:56:42.551997 17898 net.cpp:217] Eltwise31 needs backward computation.
I0619 14:56:42.552002 17898 net.cpp:217] Scale63 needs backward computation.
I0619 14:56:42.552006 17898 net.cpp:217] BatchNorm63 needs backward computation.
I0619 14:56:42.552009 17898 net.cpp:217] Convolution63 needs backward computation.
I0619 14:56:42.552013 17898 net.cpp:217] ReLU62 needs backward computation.
I0619 14:56:42.552017 17898 net.cpp:217] Scale62 needs backward computation.
I0619 14:56:42.552021 17898 net.cpp:217] BatchNorm62 needs backward computation.
I0619 14:56:42.552026 17898 net.cpp:217] Convolution62 needs backward computation.
I0619 14:56:42.552029 17898 net.cpp:217] Eltwise30_ReLU61_0_split needs backward computation.
I0619 14:56:42.552033 17898 net.cpp:217] ReLU61 needs backward computation.
I0619 14:56:42.552037 17898 net.cpp:217] Eltwise30 needs backward computation.
I0619 14:56:42.552042 17898 net.cpp:217] Scale61 needs backward computation.
I0619 14:56:42.552045 17898 net.cpp:217] BatchNorm61 needs backward computation.
I0619 14:56:42.552049 17898 net.cpp:217] Convolution61 needs backward computation.
I0619 14:56:42.552053 17898 net.cpp:217] ReLU60 needs backward computation.
I0619 14:56:42.552057 17898 net.cpp:217] Scale60 needs backward computation.
I0619 14:56:42.552060 17898 net.cpp:217] BatchNorm60 needs backward computation.
I0619 14:56:42.552064 17898 net.cpp:217] Convolution60 needs backward computation.
I0619 14:56:42.552068 17898 net.cpp:217] Eltwise29_ReLU59_0_split needs backward computation.
I0619 14:56:42.552073 17898 net.cpp:217] ReLU59 needs backward computation.
I0619 14:56:42.552076 17898 net.cpp:217] Eltwise29 needs backward computation.
I0619 14:56:42.552081 17898 net.cpp:217] Scale59 needs backward computation.
I0619 14:56:42.552084 17898 net.cpp:217] BatchNorm59 needs backward computation.
I0619 14:56:42.552088 17898 net.cpp:217] Convolution59 needs backward computation.
I0619 14:56:42.552093 17898 net.cpp:217] ReLU58 needs backward computation.
I0619 14:56:42.552096 17898 net.cpp:217] Scale58 needs backward computation.
I0619 14:56:42.552100 17898 net.cpp:217] BatchNorm58 needs backward computation.
I0619 14:56:42.552104 17898 net.cpp:217] Convolution58 needs backward computation.
I0619 14:56:42.552109 17898 net.cpp:217] Eltwise28_ReLU57_0_split needs backward computation.
I0619 14:56:42.552112 17898 net.cpp:217] ReLU57 needs backward computation.
I0619 14:56:42.552119 17898 net.cpp:217] Eltwise28 needs backward computation.
I0619 14:56:42.552130 17898 net.cpp:217] Scale57 needs backward computation.
I0619 14:56:42.552135 17898 net.cpp:217] BatchNorm57 needs backward computation.
I0619 14:56:42.552139 17898 net.cpp:217] Convolution57 needs backward computation.
I0619 14:56:42.552144 17898 net.cpp:217] ReLU56 needs backward computation.
I0619 14:56:42.552146 17898 net.cpp:217] Scale56 needs backward computation.
I0619 14:56:42.552150 17898 net.cpp:217] BatchNorm56 needs backward computation.
I0619 14:56:42.552155 17898 net.cpp:217] Convolution56 needs backward computation.
I0619 14:56:42.552158 17898 net.cpp:217] Eltwise27_ReLU55_0_split needs backward computation.
I0619 14:56:42.552162 17898 net.cpp:217] ReLU55 needs backward computation.
I0619 14:56:42.552166 17898 net.cpp:217] Eltwise27 needs backward computation.
I0619 14:56:42.552171 17898 net.cpp:217] Scale55 needs backward computation.
I0619 14:56:42.552175 17898 net.cpp:217] BatchNorm55 needs backward computation.
I0619 14:56:42.552178 17898 net.cpp:217] Convolution55 needs backward computation.
I0619 14:56:42.552182 17898 net.cpp:217] ReLU54 needs backward computation.
I0619 14:56:42.552186 17898 net.cpp:217] Scale54 needs backward computation.
I0619 14:56:42.552191 17898 net.cpp:217] BatchNorm54 needs backward computation.
I0619 14:56:42.552194 17898 net.cpp:217] Convolution54 needs backward computation.
I0619 14:56:42.552198 17898 net.cpp:217] Eltwise26_ReLU53_0_split needs backward computation.
I0619 14:56:42.552202 17898 net.cpp:217] ReLU53 needs backward computation.
I0619 14:56:42.552206 17898 net.cpp:217] Eltwise26 needs backward computation.
I0619 14:56:42.552211 17898 net.cpp:217] Scale53 needs backward computation.
I0619 14:56:42.552215 17898 net.cpp:217] BatchNorm53 needs backward computation.
I0619 14:56:42.552219 17898 net.cpp:217] Convolution53 needs backward computation.
I0619 14:56:42.552223 17898 net.cpp:217] ReLU52 needs backward computation.
I0619 14:56:42.552227 17898 net.cpp:217] Scale52 needs backward computation.
I0619 14:56:42.552232 17898 net.cpp:217] BatchNorm52 needs backward computation.
I0619 14:56:42.552234 17898 net.cpp:217] Convolution52 needs backward computation.
I0619 14:56:42.552238 17898 net.cpp:217] Eltwise25_ReLU51_0_split needs backward computation.
I0619 14:56:42.552242 17898 net.cpp:217] ReLU51 needs backward computation.
I0619 14:56:42.552247 17898 net.cpp:217] Eltwise25 needs backward computation.
I0619 14:56:42.552251 17898 net.cpp:217] Scale51 needs backward computation.
I0619 14:56:42.552255 17898 net.cpp:217] BatchNorm51 needs backward computation.
I0619 14:56:42.552258 17898 net.cpp:217] Convolution51 needs backward computation.
I0619 14:56:42.552263 17898 net.cpp:217] ReLU50 needs backward computation.
I0619 14:56:42.552266 17898 net.cpp:217] Scale50 needs backward computation.
I0619 14:56:42.552270 17898 net.cpp:217] BatchNorm50 needs backward computation.
I0619 14:56:42.552274 17898 net.cpp:217] Convolution50 needs backward computation.
I0619 14:56:42.552278 17898 net.cpp:217] Eltwise24_ReLU49_0_split needs backward computation.
I0619 14:56:42.552283 17898 net.cpp:217] ReLU49 needs backward computation.
I0619 14:56:42.552285 17898 net.cpp:217] Eltwise24 needs backward computation.
I0619 14:56:42.552290 17898 net.cpp:217] Scale49 needs backward computation.
I0619 14:56:42.552294 17898 net.cpp:217] BatchNorm49 needs backward computation.
I0619 14:56:42.552299 17898 net.cpp:217] Convolution49 needs backward computation.
I0619 14:56:42.552302 17898 net.cpp:217] ReLU48 needs backward computation.
I0619 14:56:42.552306 17898 net.cpp:217] Scale48 needs backward computation.
I0619 14:56:42.552310 17898 net.cpp:217] BatchNorm48 needs backward computation.
I0619 14:56:42.552314 17898 net.cpp:217] Convolution48 needs backward computation.
I0619 14:56:42.552317 17898 net.cpp:217] Eltwise23_ReLU47_0_split needs backward computation.
I0619 14:56:42.552322 17898 net.cpp:217] ReLU47 needs backward computation.
I0619 14:56:42.552325 17898 net.cpp:217] Eltwise23 needs backward computation.
I0619 14:56:42.552332 17898 net.cpp:217] Scale47 needs backward computation.
I0619 14:56:42.552342 17898 net.cpp:217] BatchNorm47 needs backward computation.
I0619 14:56:42.552346 17898 net.cpp:217] Convolution47 needs backward computation.
I0619 14:56:42.552351 17898 net.cpp:217] ReLU46 needs backward computation.
I0619 14:56:42.552356 17898 net.cpp:217] Scale46 needs backward computation.
I0619 14:56:42.552358 17898 net.cpp:217] BatchNorm46 needs backward computation.
I0619 14:56:42.552362 17898 net.cpp:217] Convolution46 needs backward computation.
I0619 14:56:42.552366 17898 net.cpp:217] Eltwise22_ReLU45_0_split needs backward computation.
I0619 14:56:42.552371 17898 net.cpp:217] ReLU45 needs backward computation.
I0619 14:56:42.552374 17898 net.cpp:217] Eltwise22 needs backward computation.
I0619 14:56:42.552379 17898 net.cpp:217] Scale45 needs backward computation.
I0619 14:56:42.552383 17898 net.cpp:217] BatchNorm45 needs backward computation.
I0619 14:56:42.552387 17898 net.cpp:217] Convolution45 needs backward computation.
I0619 14:56:42.552392 17898 net.cpp:217] ReLU44 needs backward computation.
I0619 14:56:42.552394 17898 net.cpp:217] Scale44 needs backward computation.
I0619 14:56:42.552398 17898 net.cpp:217] BatchNorm44 needs backward computation.
I0619 14:56:42.552402 17898 net.cpp:217] Convolution44 needs backward computation.
I0619 14:56:42.552407 17898 net.cpp:217] Eltwise21_ReLU43_0_split needs backward computation.
I0619 14:56:42.552410 17898 net.cpp:217] ReLU43 needs backward computation.
I0619 14:56:42.552414 17898 net.cpp:217] Eltwise21 needs backward computation.
I0619 14:56:42.552419 17898 net.cpp:217] Scale43 needs backward computation.
I0619 14:56:42.552423 17898 net.cpp:217] BatchNorm43 needs backward computation.
I0619 14:56:42.552426 17898 net.cpp:217] Convolution43 needs backward computation.
I0619 14:56:42.552430 17898 net.cpp:217] ReLU42 needs backward computation.
I0619 14:56:42.552434 17898 net.cpp:217] Scale42 needs backward computation.
I0619 14:56:42.552438 17898 net.cpp:217] BatchNorm42 needs backward computation.
I0619 14:56:42.552443 17898 net.cpp:217] Convolution42 needs backward computation.
I0619 14:56:42.552446 17898 net.cpp:217] Eltwise20_ReLU41_0_split needs backward computation.
I0619 14:56:42.552450 17898 net.cpp:217] ReLU41 needs backward computation.
I0619 14:56:42.552454 17898 net.cpp:217] Eltwise20 needs backward computation.
I0619 14:56:42.552459 17898 net.cpp:217] Scale41 needs backward computation.
I0619 14:56:42.552464 17898 net.cpp:217] BatchNorm41 needs backward computation.
I0619 14:56:42.552467 17898 net.cpp:217] Convolution41 needs backward computation.
I0619 14:56:42.552471 17898 net.cpp:217] ReLU40 needs backward computation.
I0619 14:56:42.552474 17898 net.cpp:217] Scale40 needs backward computation.
I0619 14:56:42.552479 17898 net.cpp:217] BatchNorm40 needs backward computation.
I0619 14:56:42.552482 17898 net.cpp:217] Convolution40 needs backward computation.
I0619 14:56:42.552486 17898 net.cpp:217] Eltwise19_ReLU39_0_split needs backward computation.
I0619 14:56:42.552494 17898 net.cpp:217] ReLU39 needs backward computation.
I0619 14:56:42.552497 17898 net.cpp:217] Eltwise19 needs backward computation.
I0619 14:56:42.552501 17898 net.cpp:217] Scale39 needs backward computation.
I0619 14:56:42.552505 17898 net.cpp:217] BatchNorm39 needs backward computation.
I0619 14:56:42.552510 17898 net.cpp:217] Convolution39 needs backward computation.
I0619 14:56:42.552515 17898 net.cpp:217] ReLU38 needs backward computation.
I0619 14:56:42.552518 17898 net.cpp:217] Scale38 needs backward computation.
I0619 14:56:42.552521 17898 net.cpp:217] BatchNorm38 needs backward computation.
I0619 14:56:42.552525 17898 net.cpp:217] Convolution38 needs backward computation.
I0619 14:56:42.552530 17898 net.cpp:217] Concat1 needs backward computation.
I0619 14:56:42.552536 17898 net.cpp:219] Input1 does not need backward computation.
I0619 14:56:42.552539 17898 net.cpp:217] Pooling1 needs backward computation.
I0619 14:56:42.552543 17898 net.cpp:217] Eltwise18_ReLU37_0_split needs backward computation.
I0619 14:56:42.552556 17898 net.cpp:217] ReLU37 needs backward computation.
I0619 14:56:42.552561 17898 net.cpp:217] Eltwise18 needs backward computation.
I0619 14:56:42.552566 17898 net.cpp:217] Scale37 needs backward computation.
I0619 14:56:42.552569 17898 net.cpp:217] BatchNorm37 needs backward computation.
I0619 14:56:42.552573 17898 net.cpp:217] Convolution37 needs backward computation.
I0619 14:56:42.552577 17898 net.cpp:217] ReLU36 needs backward computation.
I0619 14:56:42.552582 17898 net.cpp:217] Scale36 needs backward computation.
I0619 14:56:42.552585 17898 net.cpp:217] BatchNorm36 needs backward computation.
I0619 14:56:42.552588 17898 net.cpp:217] Convolution36 needs backward computation.
I0619 14:56:42.552592 17898 net.cpp:217] Eltwise17_ReLU35_0_split needs backward computation.
I0619 14:56:42.552597 17898 net.cpp:217] ReLU35 needs backward computation.
I0619 14:56:42.552602 17898 net.cpp:217] Eltwise17 needs backward computation.
I0619 14:56:42.552605 17898 net.cpp:217] Scale35 needs backward computation.
I0619 14:56:42.552609 17898 net.cpp:217] BatchNorm35 needs backward computation.
I0619 14:56:42.552613 17898 net.cpp:217] Convolution35 needs backward computation.
I0619 14:56:42.552618 17898 net.cpp:217] ReLU34 needs backward computation.
I0619 14:56:42.552621 17898 net.cpp:217] Scale34 needs backward computation.
I0619 14:56:42.552625 17898 net.cpp:217] BatchNorm34 needs backward computation.
I0619 14:56:42.552629 17898 net.cpp:217] Convolution34 needs backward computation.
I0619 14:56:42.552634 17898 net.cpp:217] Eltwise16_ReLU33_0_split needs backward computation.
I0619 14:56:42.552637 17898 net.cpp:217] ReLU33 needs backward computation.
I0619 14:56:42.552641 17898 net.cpp:217] Eltwise16 needs backward computation.
I0619 14:56:42.552646 17898 net.cpp:217] Scale33 needs backward computation.
I0619 14:56:42.552649 17898 net.cpp:217] BatchNorm33 needs backward computation.
I0619 14:56:42.552654 17898 net.cpp:217] Convolution33 needs backward computation.
I0619 14:56:42.552657 17898 net.cpp:217] ReLU32 needs backward computation.
I0619 14:56:42.552661 17898 net.cpp:217] Scale32 needs backward computation.
I0619 14:56:42.552665 17898 net.cpp:217] BatchNorm32 needs backward computation.
I0619 14:56:42.552669 17898 net.cpp:217] Convolution32 needs backward computation.
I0619 14:56:42.552673 17898 net.cpp:217] Eltwise15_ReLU31_0_split needs backward computation.
I0619 14:56:42.552677 17898 net.cpp:217] ReLU31 needs backward computation.
I0619 14:56:42.552680 17898 net.cpp:217] Eltwise15 needs backward computation.
I0619 14:56:42.552685 17898 net.cpp:217] Scale31 needs backward computation.
I0619 14:56:42.552690 17898 net.cpp:217] BatchNorm31 needs backward computation.
I0619 14:56:42.552693 17898 net.cpp:217] Convolution31 needs backward computation.
I0619 14:56:42.552697 17898 net.cpp:217] ReLU30 needs backward computation.
I0619 14:56:42.552701 17898 net.cpp:217] Scale30 needs backward computation.
I0619 14:56:42.552705 17898 net.cpp:217] BatchNorm30 needs backward computation.
I0619 14:56:42.552708 17898 net.cpp:217] Convolution30 needs backward computation.
I0619 14:56:42.552712 17898 net.cpp:217] Eltwise14_ReLU29_0_split needs backward computation.
I0619 14:56:42.552716 17898 net.cpp:217] ReLU29 needs backward computation.
I0619 14:56:42.552721 17898 net.cpp:217] Eltwise14 needs backward computation.
I0619 14:56:42.552726 17898 net.cpp:217] Scale29 needs backward computation.
I0619 14:56:42.552729 17898 net.cpp:217] BatchNorm29 needs backward computation.
I0619 14:56:42.552732 17898 net.cpp:217] Convolution29 needs backward computation.
I0619 14:56:42.552737 17898 net.cpp:217] ReLU28 needs backward computation.
I0619 14:56:42.552742 17898 net.cpp:217] Scale28 needs backward computation.
I0619 14:56:42.552744 17898 net.cpp:217] BatchNorm28 needs backward computation.
I0619 14:56:42.552748 17898 net.cpp:217] Convolution28 needs backward computation.
I0619 14:56:42.552752 17898 net.cpp:217] Eltwise13_ReLU27_0_split needs backward computation.
I0619 14:56:42.552757 17898 net.cpp:217] ReLU27 needs backward computation.
I0619 14:56:42.552768 17898 net.cpp:217] Eltwise13 needs backward computation.
I0619 14:56:42.552774 17898 net.cpp:217] Scale27 needs backward computation.
I0619 14:56:42.552778 17898 net.cpp:217] BatchNorm27 needs backward computation.
I0619 14:56:42.552781 17898 net.cpp:217] Convolution27 needs backward computation.
I0619 14:56:42.552786 17898 net.cpp:217] ReLU26 needs backward computation.
I0619 14:56:42.552790 17898 net.cpp:217] Scale26 needs backward computation.
I0619 14:56:42.552793 17898 net.cpp:217] BatchNorm26 needs backward computation.
I0619 14:56:42.552798 17898 net.cpp:217] Convolution26 needs backward computation.
I0619 14:56:42.552801 17898 net.cpp:217] Eltwise12_ReLU25_0_split needs backward computation.
I0619 14:56:42.552806 17898 net.cpp:217] ReLU25 needs backward computation.
I0619 14:56:42.552810 17898 net.cpp:217] Eltwise12 needs backward computation.
I0619 14:56:42.552814 17898 net.cpp:217] Scale25 needs backward computation.
I0619 14:56:42.552819 17898 net.cpp:217] BatchNorm25 needs backward computation.
I0619 14:56:42.552822 17898 net.cpp:217] Convolution25 needs backward computation.
I0619 14:56:42.552826 17898 net.cpp:217] ReLU24 needs backward computation.
I0619 14:56:42.552830 17898 net.cpp:217] Scale24 needs backward computation.
I0619 14:56:42.552834 17898 net.cpp:217] BatchNorm24 needs backward computation.
I0619 14:56:42.552837 17898 net.cpp:217] Convolution24 needs backward computation.
I0619 14:56:42.552841 17898 net.cpp:217] Eltwise11_ReLU23_0_split needs backward computation.
I0619 14:56:42.552846 17898 net.cpp:217] ReLU23 needs backward computation.
I0619 14:56:42.552850 17898 net.cpp:217] Eltwise11 needs backward computation.
I0619 14:56:42.552855 17898 net.cpp:217] Scale23 needs backward computation.
I0619 14:56:42.552858 17898 net.cpp:217] BatchNorm23 needs backward computation.
I0619 14:56:42.552862 17898 net.cpp:217] Convolution23 needs backward computation.
I0619 14:56:42.552866 17898 net.cpp:217] ReLU22 needs backward computation.
I0619 14:56:42.552870 17898 net.cpp:217] Scale22 needs backward computation.
I0619 14:56:42.552875 17898 net.cpp:217] BatchNorm22 needs backward computation.
I0619 14:56:42.552877 17898 net.cpp:217] Convolution22 needs backward computation.
I0619 14:56:42.552882 17898 net.cpp:217] Eltwise10_ReLU21_0_split needs backward computation.
I0619 14:56:42.552886 17898 net.cpp:217] ReLU21 needs backward computation.
I0619 14:56:42.552891 17898 net.cpp:217] Eltwise10 needs backward computation.
I0619 14:56:42.552896 17898 net.cpp:217] Scale21 needs backward computation.
I0619 14:56:42.552898 17898 net.cpp:217] BatchNorm21 needs backward computation.
I0619 14:56:42.552902 17898 net.cpp:217] Convolution21 needs backward computation.
I0619 14:56:42.552906 17898 net.cpp:217] ReLU20 needs backward computation.
I0619 14:56:42.552911 17898 net.cpp:217] Scale20 needs backward computation.
I0619 14:56:42.552914 17898 net.cpp:217] BatchNorm20 needs backward computation.
I0619 14:56:42.552918 17898 net.cpp:217] Convolution20 needs backward computation.
I0619 14:56:42.552922 17898 net.cpp:217] Eltwise9_ReLU19_0_split needs backward computation.
I0619 14:56:42.552927 17898 net.cpp:217] ReLU19 needs backward computation.
I0619 14:56:42.552932 17898 net.cpp:217] Eltwise9 needs backward computation.
I0619 14:56:42.552937 17898 net.cpp:217] Scale19 needs backward computation.
I0619 14:56:42.552940 17898 net.cpp:217] BatchNorm19 needs backward computation.
I0619 14:56:42.552944 17898 net.cpp:217] Convolution19 needs backward computation.
I0619 14:56:42.552948 17898 net.cpp:217] ReLU18 needs backward computation.
I0619 14:56:42.552953 17898 net.cpp:217] Scale18 needs backward computation.
I0619 14:56:42.552956 17898 net.cpp:217] BatchNorm18 needs backward computation.
I0619 14:56:42.552960 17898 net.cpp:217] Convolution18 needs backward computation.
I0619 14:56:42.552964 17898 net.cpp:217] Eltwise8_ReLU17_0_split needs backward computation.
I0619 14:56:42.552969 17898 net.cpp:217] ReLU17 needs backward computation.
I0619 14:56:42.552975 17898 net.cpp:217] Eltwise8 needs backward computation.
I0619 14:56:42.552986 17898 net.cpp:217] Scale17 needs backward computation.
I0619 14:56:42.552990 17898 net.cpp:217] BatchNorm17 needs backward computation.
I0619 14:56:42.552994 17898 net.cpp:217] Convolution17 needs backward computation.
I0619 14:56:42.552999 17898 net.cpp:217] ReLU16 needs backward computation.
I0619 14:56:42.553002 17898 net.cpp:217] Scale16 needs backward computation.
I0619 14:56:42.553006 17898 net.cpp:217] BatchNorm16 needs backward computation.
I0619 14:56:42.553010 17898 net.cpp:217] Convolution16 needs backward computation.
I0619 14:56:42.553014 17898 net.cpp:217] Eltwise7_ReLU15_0_split needs backward computation.
I0619 14:56:42.553020 17898 net.cpp:217] ReLU15 needs backward computation.
I0619 14:56:42.553023 17898 net.cpp:217] Eltwise7 needs backward computation.
I0619 14:56:42.553027 17898 net.cpp:217] Scale15 needs backward computation.
I0619 14:56:42.553031 17898 net.cpp:217] BatchNorm15 needs backward computation.
I0619 14:56:42.553035 17898 net.cpp:217] Convolution15 needs backward computation.
I0619 14:56:42.553040 17898 net.cpp:217] ReLU14 needs backward computation.
I0619 14:56:42.553043 17898 net.cpp:217] Scale14 needs backward computation.
I0619 14:56:42.553047 17898 net.cpp:217] BatchNorm14 needs backward computation.
I0619 14:56:42.553051 17898 net.cpp:217] Convolution14 needs backward computation.
I0619 14:56:42.553056 17898 net.cpp:217] Eltwise6_ReLU13_0_split needs backward computation.
I0619 14:56:42.553061 17898 net.cpp:217] ReLU13 needs backward computation.
I0619 14:56:42.553064 17898 net.cpp:217] Eltwise6 needs backward computation.
I0619 14:56:42.553068 17898 net.cpp:217] Scale13 needs backward computation.
I0619 14:56:42.553073 17898 net.cpp:217] BatchNorm13 needs backward computation.
I0619 14:56:42.553076 17898 net.cpp:217] Convolution13 needs backward computation.
I0619 14:56:42.553081 17898 net.cpp:217] ReLU12 needs backward computation.
I0619 14:56:42.553084 17898 net.cpp:217] Scale12 needs backward computation.
I0619 14:56:42.553088 17898 net.cpp:217] BatchNorm12 needs backward computation.
I0619 14:56:42.553092 17898 net.cpp:217] Convolution12 needs backward computation.
I0619 14:56:42.553097 17898 net.cpp:217] Eltwise5_ReLU11_0_split needs backward computation.
I0619 14:56:42.553102 17898 net.cpp:217] ReLU11 needs backward computation.
I0619 14:56:42.553105 17898 net.cpp:217] Eltwise5 needs backward computation.
I0619 14:56:42.553110 17898 net.cpp:217] Scale11 needs backward computation.
I0619 14:56:42.553114 17898 net.cpp:217] BatchNorm11 needs backward computation.
I0619 14:56:42.553117 17898 net.cpp:217] Convolution11 needs backward computation.
I0619 14:56:42.553122 17898 net.cpp:217] ReLU10 needs backward computation.
I0619 14:56:42.553127 17898 net.cpp:217] Scale10 needs backward computation.
I0619 14:56:42.553130 17898 net.cpp:217] BatchNorm10 needs backward computation.
I0619 14:56:42.553133 17898 net.cpp:217] Convolution10 needs backward computation.
I0619 14:56:42.553138 17898 net.cpp:217] Eltwise4_ReLU9_0_split needs backward computation.
I0619 14:56:42.553143 17898 net.cpp:217] ReLU9 needs backward computation.
I0619 14:56:42.553146 17898 net.cpp:217] Eltwise4 needs backward computation.
I0619 14:56:42.553153 17898 net.cpp:217] Scale9 needs backward computation.
I0619 14:56:42.553156 17898 net.cpp:217] BatchNorm9 needs backward computation.
I0619 14:56:42.553160 17898 net.cpp:217] Convolution9 needs backward computation.
I0619 14:56:42.553164 17898 net.cpp:217] ReLU8 needs backward computation.
I0619 14:56:42.553169 17898 net.cpp:217] Scale8 needs backward computation.
I0619 14:56:42.553172 17898 net.cpp:217] BatchNorm8 needs backward computation.
I0619 14:56:42.553176 17898 net.cpp:217] Convolution8 needs backward computation.
I0619 14:56:42.553180 17898 net.cpp:217] Eltwise3_ReLU7_0_split needs backward computation.
I0619 14:56:42.553184 17898 net.cpp:217] ReLU7 needs backward computation.
I0619 14:56:42.553189 17898 net.cpp:217] Eltwise3 needs backward computation.
I0619 14:56:42.553200 17898 net.cpp:217] Scale7 needs backward computation.
I0619 14:56:42.553211 17898 net.cpp:217] BatchNorm7 needs backward computation.
I0619 14:56:42.553215 17898 net.cpp:217] Convolution7 needs backward computation.
I0619 14:56:42.553220 17898 net.cpp:217] ReLU6 needs backward computation.
I0619 14:56:42.553223 17898 net.cpp:217] Scale6 needs backward computation.
I0619 14:56:42.553227 17898 net.cpp:217] BatchNorm6 needs backward computation.
I0619 14:56:42.553231 17898 net.cpp:217] Convolution6 needs backward computation.
I0619 14:56:42.553236 17898 net.cpp:217] Eltwise2_ReLU5_0_split needs backward computation.
I0619 14:56:42.553241 17898 net.cpp:217] ReLU5 needs backward computation.
I0619 14:56:42.553244 17898 net.cpp:217] Eltwise2 needs backward computation.
I0619 14:56:42.553249 17898 net.cpp:217] Scale5 needs backward computation.
I0619 14:56:42.553253 17898 net.cpp:217] BatchNorm5 needs backward computation.
I0619 14:56:42.553256 17898 net.cpp:217] Convolution5 needs backward computation.
I0619 14:56:42.553261 17898 net.cpp:217] ReLU4 needs backward computation.
I0619 14:56:42.553266 17898 net.cpp:217] Scale4 needs backward computation.
I0619 14:56:42.553269 17898 net.cpp:217] BatchNorm4 needs backward computation.
I0619 14:56:42.553272 17898 net.cpp:217] Convolution4 needs backward computation.
I0619 14:56:42.553277 17898 net.cpp:217] Eltwise1_ReLU3_0_split needs backward computation.
I0619 14:56:42.553282 17898 net.cpp:217] ReLU3 needs backward computation.
I0619 14:56:42.553285 17898 net.cpp:217] Eltwise1 needs backward computation.
I0619 14:56:42.553290 17898 net.cpp:217] Scale3 needs backward computation.
I0619 14:56:42.553294 17898 net.cpp:217] BatchNorm3 needs backward computation.
I0619 14:56:42.553298 17898 net.cpp:217] Convolution3 needs backward computation.
I0619 14:56:42.553303 17898 net.cpp:217] ReLU2 needs backward computation.
I0619 14:56:42.553308 17898 net.cpp:217] Scale2 needs backward computation.
I0619 14:56:42.553310 17898 net.cpp:217] BatchNorm2 needs backward computation.
I0619 14:56:42.553314 17898 net.cpp:217] Convolution2 needs backward computation.
I0619 14:56:42.553319 17898 net.cpp:217] Convolution1_ReLU1_0_split needs backward computation.
I0619 14:56:42.553324 17898 net.cpp:217] ReLU1 needs backward computation.
I0619 14:56:42.553328 17898 net.cpp:217] Scale1 needs backward computation.
I0619 14:56:42.553331 17898 net.cpp:217] BatchNorm1 needs backward computation.
I0619 14:56:42.553335 17898 net.cpp:217] Convolution1 needs backward computation.
I0619 14:56:42.553340 17898 net.cpp:219] Data2_Data1_1_split does not need backward computation.
I0619 14:56:42.553345 17898 net.cpp:219] Data1 does not need backward computation.
I0619 14:56:42.553349 17898 net.cpp:261] This network produces output Accuracy
I0619 14:56:42.553354 17898 net.cpp:261] This network produces output SoftmaxWithLoss1
I0619 14:56:42.553665 17898 net.cpp:274] Network initialization done.
I0619 14:56:42.555706 17898 solver.cpp:60] Solver scaffolding done.
I0619 14:56:42.594377 17898 caffe.cpp:219] Starting Optimization
I0619 14:56:42.594393 17898 solver.cpp:279] Solving 
I0619 14:56:42.594398 17898 solver.cpp:280] Learning Rate Policy: multistep
I0619 14:56:42.613216 17898 solver.cpp:337] Iteration 0, Testing net (#0)
I0619 14:57:45.600818 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.100078
I0619 14:57:45.601032 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0619 14:57:48.106932 17898 solver.cpp:228] Iteration 0, loss = 5.81584
I0619 14:57:48.106979 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 5.81584 (* 1 = 5.81584 loss)
I0619 14:57:48.107007 17898 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0619 15:14:32.648494 17898 solver.cpp:337] Iteration 400, Testing net (#0)
I0619 15:15:35.791857 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.12125
I0619 15:15:35.792055 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 2.39314 (* 1 = 2.39314 loss)
I0619 15:15:38.265228 17898 solver.cpp:228] Iteration 400, loss = 2.3259
I0619 15:15:38.265282 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 2.3259 (* 1 = 2.3259 loss)
I0619 15:15:38.265296 17898 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0619 15:32:21.301511 17898 solver.cpp:337] Iteration 800, Testing net (#0)
I0619 15:33:24.426384 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.171641
I0619 15:33:24.426568 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 5.54113 (* 1 = 5.54113 loss)
I0619 15:33:26.898419 17898 solver.cpp:228] Iteration 800, loss = 2.0138
I0619 15:33:26.898476 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 2.0138 (* 1 = 2.0138 loss)
I0619 15:33:26.898493 17898 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0619 15:50:10.045027 17898 solver.cpp:337] Iteration 1200, Testing net (#0)
I0619 15:51:13.351908 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.253984
I0619 15:51:13.352058 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 2.15253 (* 1 = 2.15253 loss)
I0619 15:51:15.835665 17898 solver.cpp:228] Iteration 1200, loss = 1.68771
I0619 15:51:15.835716 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.68771 (* 1 = 1.68771 loss)
I0619 15:51:15.835732 17898 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0619 16:07:58.635102 17898 solver.cpp:337] Iteration 1600, Testing net (#0)
I0619 16:09:01.803751 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.24875
I0619 16:09:01.803978 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 2.18593 (* 1 = 2.18593 loss)
I0619 16:09:04.272168 17898 solver.cpp:228] Iteration 1600, loss = 1.72762
I0619 16:09:04.272207 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.72762 (* 1 = 1.72762 loss)
I0619 16:09:04.272219 17898 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0619 16:25:47.528185 17898 solver.cpp:337] Iteration 2000, Testing net (#0)
I0619 16:26:50.688086 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.364453
I0619 16:26:50.688280 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.79226 (* 1 = 1.79226 loss)
I0619 16:26:53.181991 17898 solver.cpp:228] Iteration 2000, loss = 1.37779
I0619 16:26:53.182040 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.37779 (* 1 = 1.37779 loss)
I0619 16:26:53.182059 17898 sgd_solver.cpp:106] Iteration 2000, lr = 0.1
I0619 16:43:36.427348 17898 solver.cpp:337] Iteration 2400, Testing net (#0)
I0619 16:44:39.562465 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.346719
I0619 16:44:39.562675 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 2.12548 (* 1 = 2.12548 loss)
I0619 16:44:42.042654 17898 solver.cpp:228] Iteration 2400, loss = 1.07296
I0619 16:44:42.042711 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.07296 (* 1 = 1.07296 loss)
I0619 16:44:42.042735 17898 sgd_solver.cpp:106] Iteration 2400, lr = 0.1
I0619 17:01:25.429823 17898 solver.cpp:337] Iteration 2800, Testing net (#0)
I0619 17:02:28.606907 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.312031
I0619 17:02:28.607118 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 2.60754 (* 1 = 2.60754 loss)
I0619 17:02:31.085511 17898 solver.cpp:228] Iteration 2800, loss = 1.07121
I0619 17:02:31.085556 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.07121 (* 1 = 1.07121 loss)
I0619 17:02:31.085568 17898 sgd_solver.cpp:106] Iteration 2800, lr = 0.1
I0619 17:19:14.420624 17898 solver.cpp:337] Iteration 3200, Testing net (#0)
I0619 17:20:17.616871 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.30875
I0619 17:20:17.617084 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 2.59594 (* 1 = 2.59594 loss)
I0619 17:20:20.087666 17898 solver.cpp:228] Iteration 3200, loss = 1.08022
I0619 17:20:20.087707 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.08022 (* 1 = 1.08022 loss)
I0619 17:20:20.087719 17898 sgd_solver.cpp:106] Iteration 3200, lr = 0.1
I0619 17:37:03.035784 17898 solver.cpp:337] Iteration 3600, Testing net (#0)
I0619 17:38:06.211688 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.234219
I0619 17:38:06.211863 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 4.93703 (* 1 = 4.93703 loss)
I0619 17:38:08.681656 17898 solver.cpp:228] Iteration 3600, loss = 1.11677
I0619 17:38:08.681695 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 1.11677 (* 1 = 1.11677 loss)
I0619 17:38:08.681711 17898 sgd_solver.cpp:106] Iteration 3600, lr = 0.1
I0619 17:54:52.303163 17898 solver.cpp:337] Iteration 4000, Testing net (#0)
I0619 17:55:55.527587 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.329219
I0619 17:55:55.527797 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 2.48162 (* 1 = 2.48162 loss)
I0619 17:55:58.013787 17898 solver.cpp:228] Iteration 4000, loss = 0.758079
I0619 17:55:58.013842 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.758079 (* 1 = 0.758079 loss)
I0619 17:55:58.013885 17898 sgd_solver.cpp:106] Iteration 4000, lr = 0.1
I0619 18:12:41.965793 17898 solver.cpp:337] Iteration 4400, Testing net (#0)
I0619 18:13:45.198968 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.411953
I0619 18:13:45.199156 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.83557 (* 1 = 1.83557 loss)
I0619 18:13:47.672370 17898 solver.cpp:228] Iteration 4400, loss = 0.830945
I0619 18:13:47.672412 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.830945 (* 1 = 0.830945 loss)
I0619 18:13:47.672426 17898 sgd_solver.cpp:106] Iteration 4400, lr = 0.1
I0619 18:30:30.760066 17898 solver.cpp:337] Iteration 4800, Testing net (#0)
I0619 18:31:33.973544 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.271016
I0619 18:31:33.973752 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 3.34876 (* 1 = 3.34876 loss)
I0619 18:31:36.442301 17898 solver.cpp:228] Iteration 4800, loss = 0.675814
I0619 18:31:36.442356 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.675814 (* 1 = 0.675814 loss)
I0619 18:31:36.442384 17898 sgd_solver.cpp:106] Iteration 4800, lr = 0.1
I0619 18:48:19.702716 17898 solver.cpp:337] Iteration 5200, Testing net (#0)
I0619 18:49:22.796072 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.490859
I0619 18:49:22.796285 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.4337 (* 1 = 1.4337 loss)
I0619 18:49:25.267655 17898 solver.cpp:228] Iteration 5200, loss = 0.90306
I0619 18:49:25.267693 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.90306 (* 1 = 0.90306 loss)
I0619 18:49:25.267707 17898 sgd_solver.cpp:106] Iteration 5200, lr = 0.1
I0619 19:06:08.731698 17898 solver.cpp:337] Iteration 5600, Testing net (#0)
I0619 19:07:11.914338 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.497734
I0619 19:07:11.914542 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.59467 (* 1 = 1.59467 loss)
I0619 19:07:14.398751 17898 solver.cpp:228] Iteration 5600, loss = 0.627594
I0619 19:07:14.398798 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.627594 (* 1 = 0.627594 loss)
I0619 19:07:14.398816 17898 sgd_solver.cpp:106] Iteration 5600, lr = 0.1
I0619 19:23:57.466820 17898 solver.cpp:337] Iteration 6000, Testing net (#0)
I0619 19:25:00.681941 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.565469
I0619 19:25:00.682013 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.35486 (* 1 = 1.35486 loss)
I0619 19:25:03.147763 17898 solver.cpp:228] Iteration 6000, loss = 0.62568
I0619 19:25:03.147797 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.62568 (* 1 = 0.62568 loss)
I0619 19:25:03.147830 17898 sgd_solver.cpp:106] Iteration 6000, lr = 0.1
I0619 19:41:46.099953 17898 solver.cpp:337] Iteration 6400, Testing net (#0)
I0619 19:42:49.358120 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.578906
I0619 19:42:49.358306 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.31153 (* 1 = 1.31153 loss)
I0619 19:42:51.841998 17898 solver.cpp:228] Iteration 6400, loss = 0.63587
I0619 19:42:51.842039 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.63587 (* 1 = 0.63587 loss)
I0619 19:42:51.842052 17898 sgd_solver.cpp:106] Iteration 6400, lr = 0.1
I0619 19:59:35.263211 17898 solver.cpp:337] Iteration 6800, Testing net (#0)
I0619 20:00:38.457367 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.623906
I0619 20:00:38.457599 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.07029 (* 1 = 1.07029 loss)
I0619 20:00:40.924667 17898 solver.cpp:228] Iteration 6800, loss = 0.67217
I0619 20:00:40.924707 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.67217 (* 1 = 0.67217 loss)
I0619 20:00:40.924721 17898 sgd_solver.cpp:106] Iteration 6800, lr = 0.1
I0619 20:17:23.899740 17898 solver.cpp:337] Iteration 7200, Testing net (#0)
I0619 20:18:27.085402 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.579609
I0619 20:18:27.085605 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.399 (* 1 = 1.399 loss)
I0619 20:18:29.556725 17898 solver.cpp:228] Iteration 7200, loss = 0.399246
I0619 20:18:29.556780 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.399246 (* 1 = 0.399246 loss)
I0619 20:18:29.556800 17898 sgd_solver.cpp:106] Iteration 7200, lr = 0.1
I0619 20:35:12.789268 17898 solver.cpp:337] Iteration 7600, Testing net (#0)
I0619 20:36:15.949554 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.626094
I0619 20:36:15.949760 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.20281 (* 1 = 1.20281 loss)
I0619 20:36:18.425283 17898 solver.cpp:228] Iteration 7600, loss = 0.590865
I0619 20:36:18.425323 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.590865 (* 1 = 0.590865 loss)
I0619 20:36:18.425338 17898 sgd_solver.cpp:106] Iteration 7600, lr = 0.1
I0619 20:53:01.881531 17898 solver.cpp:337] Iteration 8000, Testing net (#0)
I0619 20:54:05.102257 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.637344
I0619 20:54:05.102490 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.1766 (* 1 = 1.1766 loss)
I0619 20:54:07.578622 17898 solver.cpp:228] Iteration 8000, loss = 0.348071
I0619 20:54:07.578662 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.348071 (* 1 = 0.348071 loss)
I0619 20:54:07.578680 17898 sgd_solver.cpp:106] Iteration 8000, lr = 0.1
I0619 21:10:50.883358 17898 solver.cpp:337] Iteration 8400, Testing net (#0)
I0619 21:11:54.192420 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.685625
I0619 21:11:54.192625 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.969366 (* 1 = 0.969366 loss)
I0619 21:11:56.674124 17898 solver.cpp:228] Iteration 8400, loss = 0.607697
I0619 21:11:56.674173 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.607697 (* 1 = 0.607697 loss)
I0619 21:11:56.674211 17898 sgd_solver.cpp:106] Iteration 8400, lr = 0.1
I0619 21:28:39.861659 17898 solver.cpp:337] Iteration 8800, Testing net (#0)
I0619 21:29:43.049029 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.511953
I0619 21:29:43.049221 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.6552 (* 1 = 1.6552 loss)
I0619 21:29:45.521579 17898 solver.cpp:228] Iteration 8800, loss = 0.498618
I0619 21:29:45.521626 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.498618 (* 1 = 0.498618 loss)
I0619 21:29:45.521638 17898 sgd_solver.cpp:106] Iteration 8800, lr = 0.1
I0619 21:46:30.055563 17898 solver.cpp:337] Iteration 9200, Testing net (#0)
I0619 21:47:33.508245 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.710078
I0619 21:47:33.508472 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.840994 (* 1 = 0.840994 loss)
I0619 21:47:35.978559 17898 solver.cpp:228] Iteration 9200, loss = 0.430364
I0619 21:47:35.978596 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.430364 (* 1 = 0.430364 loss)
I0619 21:47:35.978612 17898 sgd_solver.cpp:106] Iteration 9200, lr = 0.1
I0619 22:04:21.128015 17898 solver.cpp:337] Iteration 9600, Testing net (#0)
I0619 22:05:24.462592 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.735625
I0619 22:05:24.462796 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.795919 (* 1 = 0.795919 loss)
I0619 22:05:26.959679 17898 solver.cpp:228] Iteration 9600, loss = 0.378274
I0619 22:05:26.959723 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.378274 (* 1 = 0.378274 loss)
I0619 22:05:26.959738 17898 sgd_solver.cpp:106] Iteration 9600, lr = 0.1
I0619 22:22:12.152235 17898 solver.cpp:337] Iteration 10000, Testing net (#0)
I0619 22:23:15.515075 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.637031
I0619 22:23:15.515300 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.1364 (* 1 = 1.1364 loss)
I0619 22:23:17.991533 17898 solver.cpp:228] Iteration 10000, loss = 0.417208
I0619 22:23:17.991572 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.417208 (* 1 = 0.417208 loss)
I0619 22:23:17.991603 17898 sgd_solver.cpp:106] Iteration 10000, lr = 0.1
I0619 22:40:03.215538 17898 solver.cpp:337] Iteration 10400, Testing net (#0)
I0619 22:41:06.676736 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.661875
I0619 22:41:06.676897 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.07529 (* 1 = 1.07529 loss)
I0619 22:41:09.149514 17898 solver.cpp:228] Iteration 10400, loss = 0.246828
I0619 22:41:09.149550 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.246828 (* 1 = 0.246828 loss)
I0619 22:41:09.149564 17898 sgd_solver.cpp:106] Iteration 10400, lr = 0.1
I0619 22:57:54.337358 17898 solver.cpp:337] Iteration 10800, Testing net (#0)
I0619 22:58:57.684444 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.741484
I0619 22:58:57.684660 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.787983 (* 1 = 0.787983 loss)
I0619 22:59:00.159639 17898 solver.cpp:228] Iteration 10800, loss = 0.446919
I0619 22:59:00.159679 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.446919 (* 1 = 0.446919 loss)
I0619 22:59:00.159694 17898 sgd_solver.cpp:106] Iteration 10800, lr = 0.1
I0619 23:15:45.250308 17898 solver.cpp:337] Iteration 11200, Testing net (#0)
I0619 23:16:48.635220 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.719844
I0619 23:16:48.635432 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.874988 (* 1 = 0.874988 loss)
I0619 23:16:51.111189 17898 solver.cpp:228] Iteration 11200, loss = 0.480585
I0619 23:16:51.111225 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.480585 (* 1 = 0.480585 loss)
I0619 23:16:51.111241 17898 sgd_solver.cpp:106] Iteration 11200, lr = 0.1
I0619 23:33:35.966614 17898 solver.cpp:337] Iteration 11600, Testing net (#0)
I0619 23:34:39.272210 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.722188
I0619 23:34:39.272433 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.833767 (* 1 = 0.833767 loss)
I0619 23:34:41.743324 17898 solver.cpp:228] Iteration 11600, loss = 0.343823
I0619 23:34:41.743368 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.343823 (* 1 = 0.343823 loss)
I0619 23:34:41.743397 17898 sgd_solver.cpp:106] Iteration 11600, lr = 0.1
I0619 23:51:26.915567 17898 solver.cpp:337] Iteration 12000, Testing net (#0)
I0619 23:52:30.164023 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.723359
I0619 23:52:30.164211 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.866447 (* 1 = 0.866447 loss)
I0619 23:52:32.641705 17898 solver.cpp:228] Iteration 12000, loss = 0.454514
I0619 23:52:32.641747 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.454514 (* 1 = 0.454514 loss)
I0619 23:52:32.641763 17898 sgd_solver.cpp:106] Iteration 12000, lr = 0.1
I0620 00:09:18.060801 17898 solver.cpp:337] Iteration 12400, Testing net (#0)
I0620 00:10:21.376315 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.705781
I0620 00:10:21.376576 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.900111 (* 1 = 0.900111 loss)
I0620 00:10:23.849334 17898 solver.cpp:228] Iteration 12400, loss = 0.317732
I0620 00:10:23.849375 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.317732 (* 1 = 0.317732 loss)
I0620 00:10:23.849388 17898 sgd_solver.cpp:106] Iteration 12400, lr = 0.1
I0620 00:27:09.136997 17898 solver.cpp:337] Iteration 12800, Testing net (#0)
I0620 00:28:12.411219 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.662578
I0620 00:28:12.411474 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.04503 (* 1 = 1.04503 loss)
I0620 00:28:14.891170 17898 solver.cpp:228] Iteration 12800, loss = 0.395514
I0620 00:28:14.891222 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.395514 (* 1 = 0.395514 loss)
I0620 00:28:14.891238 17898 sgd_solver.cpp:106] Iteration 12800, lr = 0.1
I0620 00:44:59.854173 17898 solver.cpp:337] Iteration 13200, Testing net (#0)
I0620 00:46:03.206471 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.570781
I0620 00:46:03.206687 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.71838 (* 1 = 1.71838 loss)
I0620 00:46:05.681375 17898 solver.cpp:228] Iteration 13200, loss = 0.338937
I0620 00:46:05.681413 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.338937 (* 1 = 0.338937 loss)
I0620 00:46:05.681429 17898 sgd_solver.cpp:106] Iteration 13200, lr = 0.1
I0620 01:02:50.708329 17898 solver.cpp:337] Iteration 13600, Testing net (#0)
I0620 01:03:54.051304 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.609688
I0620 01:03:54.051533 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.63991 (* 1 = 1.63991 loss)
I0620 01:03:56.527251 17898 solver.cpp:228] Iteration 13600, loss = 0.379084
I0620 01:03:56.527292 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.379084 (* 1 = 0.379084 loss)
I0620 01:03:56.527307 17898 sgd_solver.cpp:106] Iteration 13600, lr = 0.1
I0620 01:20:41.530979 17898 solver.cpp:337] Iteration 14000, Testing net (#0)
I0620 01:21:44.969820 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.616719
I0620 01:21:44.970039 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.42895 (* 1 = 1.42895 loss)
I0620 01:21:47.445564 17898 solver.cpp:228] Iteration 14000, loss = 0.27653
I0620 01:21:47.445614 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.27653 (* 1 = 0.27653 loss)
I0620 01:21:47.445631 17898 sgd_solver.cpp:106] Iteration 14000, lr = 0.1
I0620 01:38:32.602267 17898 solver.cpp:337] Iteration 14400, Testing net (#0)
I0620 01:39:36.003736 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.794297
I0620 01:39:36.003916 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.628416 (* 1 = 0.628416 loss)
I0620 01:39:38.476366 17898 solver.cpp:228] Iteration 14400, loss = 0.336297
I0620 01:39:38.476402 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.336297 (* 1 = 0.336297 loss)
I0620 01:39:38.476416 17898 sgd_solver.cpp:106] Iteration 14400, lr = 0.1
I0620 01:56:23.587736 17898 solver.cpp:337] Iteration 14800, Testing net (#0)
I0620 01:57:26.978698 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.6825
I0620 01:57:26.978904 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.01353 (* 1 = 1.01353 loss)
I0620 01:57:29.454561 17898 solver.cpp:228] Iteration 14800, loss = 0.284987
I0620 01:57:29.454601 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.284987 (* 1 = 0.284987 loss)
I0620 01:57:29.454617 17898 sgd_solver.cpp:106] Iteration 14800, lr = 0.1
I0620 02:14:14.912784 17898 solver.cpp:337] Iteration 15200, Testing net (#0)
I0620 02:15:18.408989 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.739688
I0620 02:15:18.409162 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.870997 (* 1 = 0.870997 loss)
I0620 02:15:20.899718 17898 solver.cpp:228] Iteration 15200, loss = 0.375503
I0620 02:15:20.899754 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.375503 (* 1 = 0.375503 loss)
I0620 02:15:20.899767 17898 sgd_solver.cpp:106] Iteration 15200, lr = 0.1
I0620 02:32:06.161053 17898 solver.cpp:337] Iteration 15600, Testing net (#0)
I0620 02:33:09.459105 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.770547
I0620 02:33:09.459266 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.731502 (* 1 = 0.731502 loss)
I0620 02:33:11.935760 17898 solver.cpp:228] Iteration 15600, loss = 0.265666
I0620 02:33:11.935803 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.265666 (* 1 = 0.265666 loss)
I0620 02:33:11.935819 17898 sgd_solver.cpp:106] Iteration 15600, lr = 0.1
I0620 02:49:56.913620 17898 solver.cpp:337] Iteration 16000, Testing net (#0)
I0620 02:51:00.246757 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.531641
I0620 02:51:00.246953 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.92831 (* 1 = 1.92831 loss)
I0620 02:51:02.729560 17898 solver.cpp:228] Iteration 16000, loss = 0.359869
I0620 02:51:02.729626 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.359869 (* 1 = 0.359869 loss)
I0620 02:51:02.729642 17898 sgd_solver.cpp:106] Iteration 16000, lr = 0.1
I0620 03:07:48.007776 17898 solver.cpp:337] Iteration 16400, Testing net (#0)
I0620 03:08:51.384594 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.731094
I0620 03:08:51.384850 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.898777 (* 1 = 0.898777 loss)
I0620 03:08:53.860085 17898 solver.cpp:228] Iteration 16400, loss = 0.226791
I0620 03:08:53.860123 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.226791 (* 1 = 0.226791 loss)
I0620 03:08:53.860138 17898 sgd_solver.cpp:106] Iteration 16400, lr = 0.1
I0620 03:25:38.896994 17898 solver.cpp:337] Iteration 16800, Testing net (#0)
I0620 03:26:42.404110 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.731797
I0620 03:26:42.404307 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.786026 (* 1 = 0.786026 loss)
I0620 03:26:44.892704 17898 solver.cpp:228] Iteration 16800, loss = 0.251931
I0620 03:26:44.892747 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.251931 (* 1 = 0.251931 loss)
I0620 03:26:44.892774 17898 sgd_solver.cpp:106] Iteration 16800, lr = 0.1
I0620 03:43:30.104979 17898 solver.cpp:337] Iteration 17200, Testing net (#0)
I0620 03:44:33.520742 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.736719
I0620 03:44:33.520958 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.969299 (* 1 = 0.969299 loss)
I0620 03:44:35.991945 17898 solver.cpp:228] Iteration 17200, loss = 0.229443
I0620 03:44:35.991996 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.229443 (* 1 = 0.229443 loss)
I0620 03:44:35.992012 17898 sgd_solver.cpp:106] Iteration 17200, lr = 0.1
I0620 04:01:20.990108 17898 solver.cpp:337] Iteration 17600, Testing net (#0)
I0620 04:02:24.408196 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.710781
I0620 04:02:24.408325 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.17401 (* 1 = 1.17401 loss)
I0620 04:02:26.894753 17898 solver.cpp:228] Iteration 17600, loss = 0.243131
I0620 04:02:26.894812 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.243131 (* 1 = 0.243131 loss)
I0620 04:02:26.894827 17898 sgd_solver.cpp:106] Iteration 17600, lr = 0.1
I0620 04:19:11.801614 17898 solver.cpp:337] Iteration 18000, Testing net (#0)
I0620 04:20:15.160852 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.733516
I0620 04:20:15.161061 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.901668 (* 1 = 0.901668 loss)
I0620 04:20:17.653656 17898 solver.cpp:228] Iteration 18000, loss = 0.309993
I0620 04:20:17.653692 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.309992 (* 1 = 0.309992 loss)
I0620 04:20:17.653707 17898 sgd_solver.cpp:106] Iteration 18000, lr = 0.1
I0620 04:37:02.831378 17898 solver.cpp:337] Iteration 18400, Testing net (#0)
I0620 04:38:06.148376 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.759922
I0620 04:38:06.148521 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.762379 (* 1 = 0.762379 loss)
I0620 04:38:08.636536 17898 solver.cpp:228] Iteration 18400, loss = 0.237161
I0620 04:38:08.636569 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.237161 (* 1 = 0.237161 loss)
I0620 04:38:08.636584 17898 sgd_solver.cpp:106] Iteration 18400, lr = 0.1
I0620 04:54:53.481755 17898 solver.cpp:337] Iteration 18800, Testing net (#0)
I0620 04:55:56.857409 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.708516
I0620 04:55:56.857523 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.944064 (* 1 = 0.944064 loss)
I0620 04:55:59.340271 17898 solver.cpp:228] Iteration 18800, loss = 0.225259
I0620 04:55:59.340315 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.225259 (* 1 = 0.225259 loss)
I0620 04:55:59.340330 17898 sgd_solver.cpp:106] Iteration 18800, lr = 0.1
I0620 05:12:44.222403 17898 solver.cpp:337] Iteration 19200, Testing net (#0)
I0620 05:13:47.651250 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.735234
I0620 05:13:47.651437 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.983711 (* 1 = 0.983711 loss)
I0620 05:13:50.139765 17898 solver.cpp:228] Iteration 19200, loss = 0.235422
I0620 05:13:50.139819 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.235422 (* 1 = 0.235422 loss)
I0620 05:13:50.139834 17898 sgd_solver.cpp:106] Iteration 19200, lr = 0.1
I0620 05:30:35.200610 17898 solver.cpp:337] Iteration 19600, Testing net (#0)
I0620 05:31:38.539819 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.743672
I0620 05:31:38.540004 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.867321 (* 1 = 0.867321 loss)
I0620 05:31:41.017886 17898 solver.cpp:228] Iteration 19600, loss = 0.253772
I0620 05:31:41.017927 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.253772 (* 1 = 0.253772 loss)
I0620 05:31:41.017942 17898 sgd_solver.cpp:106] Iteration 19600, lr = 0.1
I0620 05:48:26.514938 17898 solver.cpp:337] Iteration 20000, Testing net (#0)
I0620 05:49:29.883662 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.755
I0620 05:49:29.883882 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.850308 (* 1 = 0.850308 loss)
I0620 05:49:32.373950 17898 solver.cpp:228] Iteration 20000, loss = 0.204376
I0620 05:49:32.373993 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.204375 (* 1 = 0.204375 loss)
I0620 05:49:32.374007 17898 sgd_solver.cpp:106] Iteration 20000, lr = 0.1
I0620 06:06:17.171248 17898 solver.cpp:337] Iteration 20400, Testing net (#0)
I0620 06:07:20.672763 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.699453
I0620 06:07:20.672905 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.16842 (* 1 = 1.16842 loss)
I0620 06:07:23.146982 17898 solver.cpp:228] Iteration 20400, loss = 0.255607
I0620 06:07:23.147017 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.255607 (* 1 = 0.255607 loss)
I0620 06:07:23.147032 17898 sgd_solver.cpp:106] Iteration 20400, lr = 0.1
I0620 06:24:08.216426 17898 solver.cpp:337] Iteration 20800, Testing net (#0)
I0620 06:25:11.586046 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.664141
I0620 06:25:11.586300 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.23672 (* 1 = 1.23672 loss)
I0620 06:25:14.057134 17898 solver.cpp:228] Iteration 20800, loss = 0.220852
I0620 06:25:14.057174 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220852 (* 1 = 0.220852 loss)
I0620 06:25:14.057190 17898 sgd_solver.cpp:106] Iteration 20800, lr = 0.1
I0620 06:41:58.784571 17898 solver.cpp:337] Iteration 21200, Testing net (#0)
I0620 06:43:02.199285 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.684453
I0620 06:43:02.199447 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.21639 (* 1 = 1.21639 loss)
I0620 06:43:04.673051 17898 solver.cpp:228] Iteration 21200, loss = 0.269134
I0620 06:43:04.673089 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.269134 (* 1 = 0.269134 loss)
I0620 06:43:04.673110 17898 sgd_solver.cpp:106] Iteration 21200, lr = 0.1
I0620 06:59:49.659731 17898 solver.cpp:337] Iteration 21600, Testing net (#0)
I0620 07:00:52.992681 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.762891
I0620 07:00:52.992889 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.787226 (* 1 = 0.787226 loss)
I0620 07:00:55.467908 17898 solver.cpp:228] Iteration 21600, loss = 0.186339
I0620 07:00:55.467949 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186339 (* 1 = 0.186339 loss)
I0620 07:00:55.467965 17898 sgd_solver.cpp:106] Iteration 21600, lr = 0.1
I0620 07:17:40.886548 17898 solver.cpp:337] Iteration 22000, Testing net (#0)
I0620 07:18:44.346608 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.766953
I0620 07:18:44.346822 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.784315 (* 1 = 0.784315 loss)
I0620 07:18:46.824935 17898 solver.cpp:228] Iteration 22000, loss = 0.327972
I0620 07:18:46.824980 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.327972 (* 1 = 0.327972 loss)
I0620 07:18:46.824995 17898 sgd_solver.cpp:106] Iteration 22000, lr = 0.1
I0620 07:35:32.030778 17898 solver.cpp:337] Iteration 22400, Testing net (#0)
I0620 07:36:35.575783 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.759844
I0620 07:36:35.575953 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.762769 (* 1 = 0.762769 loss)
I0620 07:36:38.052016 17898 solver.cpp:228] Iteration 22400, loss = 0.315465
I0620 07:36:38.052068 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.315465 (* 1 = 0.315465 loss)
I0620 07:36:38.052093 17898 sgd_solver.cpp:106] Iteration 22400, lr = 0.1
I0620 07:53:23.292735 17898 solver.cpp:337] Iteration 22800, Testing net (#0)
I0620 07:54:26.641336 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.755391
I0620 07:54:26.641513 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.792943 (* 1 = 0.792943 loss)
I0620 07:54:29.113881 17898 solver.cpp:228] Iteration 22800, loss = 0.248171
I0620 07:54:29.113924 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.248171 (* 1 = 0.248171 loss)
I0620 07:54:29.113939 17898 sgd_solver.cpp:106] Iteration 22800, lr = 0.1
I0620 08:11:14.228253 17898 solver.cpp:337] Iteration 23200, Testing net (#0)
I0620 08:12:17.677042 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.710156
I0620 08:12:17.677167 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.17824 (* 1 = 1.17824 loss)
I0620 08:12:20.171481 17898 solver.cpp:228] Iteration 23200, loss = 0.125666
I0620 08:12:20.171517 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.125666 (* 1 = 0.125666 loss)
I0620 08:12:20.171533 17898 sgd_solver.cpp:106] Iteration 23200, lr = 0.1
I0620 08:29:05.324365 17898 solver.cpp:337] Iteration 23600, Testing net (#0)
I0620 08:30:08.670150 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.705859
I0620 08:30:08.670377 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.06694 (* 1 = 1.06694 loss)
I0620 08:30:11.142391 17898 solver.cpp:228] Iteration 23600, loss = 0.171903
I0620 08:30:11.142427 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171903 (* 1 = 0.171903 loss)
I0620 08:30:11.142444 17898 sgd_solver.cpp:106] Iteration 23600, lr = 0.1
I0620 08:46:56.385512 17898 solver.cpp:337] Iteration 24000, Testing net (#0)
I0620 08:47:59.694424 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.770078
I0620 08:47:59.694596 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.773818 (* 1 = 0.773818 loss)
I0620 08:48:02.169464 17898 solver.cpp:228] Iteration 24000, loss = 0.189775
I0620 08:48:02.169504 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189775 (* 1 = 0.189775 loss)
I0620 08:48:02.169530 17898 sgd_solver.cpp:106] Iteration 24000, lr = 0.1
I0620 09:04:47.587465 17898 solver.cpp:337] Iteration 24400, Testing net (#0)
I0620 09:05:50.911140 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.624766
I0620 09:05:50.911378 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.51615 (* 1 = 1.51615 loss)
I0620 09:05:53.384356 17898 solver.cpp:228] Iteration 24400, loss = 0.156012
I0620 09:05:53.384400 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.156011 (* 1 = 0.156011 loss)
I0620 09:05:53.384415 17898 sgd_solver.cpp:106] Iteration 24400, lr = 0.1
I0620 09:22:38.414615 17898 solver.cpp:337] Iteration 24800, Testing net (#0)
I0620 09:23:41.773875 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.758516
I0620 09:23:41.774098 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.777246 (* 1 = 0.777246 loss)
I0620 09:23:44.249897 17898 solver.cpp:228] Iteration 24800, loss = 0.281325
I0620 09:23:44.249936 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.281325 (* 1 = 0.281325 loss)
I0620 09:23:44.249953 17898 sgd_solver.cpp:106] Iteration 24800, lr = 0.1
I0620 09:40:29.225015 17898 solver.cpp:337] Iteration 25200, Testing net (#0)
I0620 09:41:32.638172 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.717344
I0620 09:41:32.638348 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.990712 (* 1 = 0.990712 loss)
I0620 09:41:35.130858 17898 solver.cpp:228] Iteration 25200, loss = 0.313294
I0620 09:41:35.130897 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.313294 (* 1 = 0.313294 loss)
I0620 09:41:35.130913 17898 sgd_solver.cpp:106] Iteration 25200, lr = 0.1
I0620 09:58:20.347945 17898 solver.cpp:337] Iteration 25600, Testing net (#0)
I0620 09:59:23.707792 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.780859
I0620 09:59:23.708022 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.726419 (* 1 = 0.726419 loss)
I0620 09:59:26.189921 17898 solver.cpp:228] Iteration 25600, loss = 0.344237
I0620 09:59:26.189959 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.344236 (* 1 = 0.344236 loss)
I0620 09:59:26.189975 17898 sgd_solver.cpp:106] Iteration 25600, lr = 0.1
I0620 10:16:11.268548 17898 solver.cpp:337] Iteration 26000, Testing net (#0)
I0620 10:17:14.666548 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.700547
I0620 10:17:14.666713 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.12872 (* 1 = 1.12872 loss)
I0620 10:17:17.140328 17898 solver.cpp:228] Iteration 26000, loss = 0.126811
I0620 10:17:17.140367 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.12681 (* 1 = 0.12681 loss)
I0620 10:17:17.140382 17898 sgd_solver.cpp:106] Iteration 26000, lr = 0.1
I0620 10:34:02.287602 17898 solver.cpp:337] Iteration 26400, Testing net (#0)
I0620 10:35:05.754129 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.682891
I0620 10:35:05.754312 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.15436 (* 1 = 1.15436 loss)
I0620 10:35:08.219945 17898 solver.cpp:228] Iteration 26400, loss = 0.207613
I0620 10:35:08.219979 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207613 (* 1 = 0.207613 loss)
I0620 10:35:08.219993 17898 sgd_solver.cpp:106] Iteration 26400, lr = 0.1
I0620 10:51:53.676905 17898 solver.cpp:337] Iteration 26800, Testing net (#0)
I0620 10:52:56.959758 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.7575
I0620 10:52:56.959920 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.831698 (* 1 = 0.831698 loss)
I0620 10:52:59.445006 17898 solver.cpp:228] Iteration 26800, loss = 0.173707
I0620 10:52:59.445042 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173707 (* 1 = 0.173707 loss)
I0620 10:52:59.445058 17898 sgd_solver.cpp:106] Iteration 26800, lr = 0.1
I0620 11:09:44.770216 17898 solver.cpp:337] Iteration 27200, Testing net (#0)
I0620 11:10:48.167819 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.814375
I0620 11:10:48.168077 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.655203 (* 1 = 0.655203 loss)
I0620 11:10:50.654698 17898 solver.cpp:228] Iteration 27200, loss = 0.156227
I0620 11:10:50.654748 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.156227 (* 1 = 0.156227 loss)
I0620 11:10:50.654764 17898 sgd_solver.cpp:106] Iteration 27200, lr = 0.1
I0620 11:27:35.826901 17898 solver.cpp:337] Iteration 27600, Testing net (#0)
I0620 11:28:39.255825 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.732969
I0620 11:28:39.256017 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.901318 (* 1 = 0.901318 loss)
I0620 11:28:41.734377 17898 solver.cpp:228] Iteration 27600, loss = 0.297206
I0620 11:28:41.734422 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.297206 (* 1 = 0.297206 loss)
I0620 11:28:41.734436 17898 sgd_solver.cpp:106] Iteration 27600, lr = 0.1
I0620 11:45:26.787750 17898 solver.cpp:337] Iteration 28000, Testing net (#0)
I0620 11:46:30.176324 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.571172
I0620 11:46:30.176527 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.94306 (* 1 = 1.94306 loss)
I0620 11:46:32.653504 17898 solver.cpp:228] Iteration 28000, loss = 0.278552
I0620 11:46:32.653553 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.278552 (* 1 = 0.278552 loss)
I0620 11:46:32.653569 17898 sgd_solver.cpp:106] Iteration 28000, lr = 0.1
I0620 12:03:17.920054 17898 solver.cpp:337] Iteration 28400, Testing net (#0)
I0620 12:04:21.338636 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.805469
I0620 12:04:21.338846 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.642526 (* 1 = 0.642526 loss)
I0620 12:04:23.814782 17898 solver.cpp:228] Iteration 28400, loss = 0.174668
I0620 12:04:23.814854 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.174668 (* 1 = 0.174668 loss)
I0620 12:04:23.814877 17898 sgd_solver.cpp:106] Iteration 28400, lr = 0.1
I0620 12:21:09.021699 17898 solver.cpp:337] Iteration 28800, Testing net (#0)
I0620 12:22:12.381505 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.708125
I0620 12:22:12.381726 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.08032 (* 1 = 1.08032 loss)
I0620 12:22:14.857141 17898 solver.cpp:228] Iteration 28800, loss = 0.23753
I0620 12:22:14.857199 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.23753 (* 1 = 0.23753 loss)
I0620 12:22:14.857213 17898 sgd_solver.cpp:106] Iteration 28800, lr = 0.1
I0620 12:38:59.913732 17898 solver.cpp:337] Iteration 29200, Testing net (#0)
I0620 12:40:03.381050 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.684922
I0620 12:40:03.381283 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.29903 (* 1 = 1.29903 loss)
I0620 12:40:05.853569 17898 solver.cpp:228] Iteration 29200, loss = 0.173342
I0620 12:40:05.853626 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173342 (* 1 = 0.173342 loss)
I0620 12:40:05.853641 17898 sgd_solver.cpp:106] Iteration 29200, lr = 0.1
I0620 12:56:50.870795 17898 solver.cpp:337] Iteration 29600, Testing net (#0)
I0620 12:57:54.237576 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.791172
I0620 12:57:54.237814 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.758973 (* 1 = 0.758973 loss)
I0620 12:57:56.710683 17898 solver.cpp:228] Iteration 29600, loss = 0.206004
I0620 12:57:56.710737 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206004 (* 1 = 0.206004 loss)
I0620 12:57:56.710752 17898 sgd_solver.cpp:106] Iteration 29600, lr = 0.1
I0620 13:14:41.899860 17898 solver.cpp:337] Iteration 30000, Testing net (#0)
I0620 13:15:45.195757 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.698984
I0620 13:15:45.195909 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.13203 (* 1 = 1.13203 loss)
I0620 13:15:47.666797 17898 solver.cpp:228] Iteration 30000, loss = 0.186888
I0620 13:15:47.666852 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186888 (* 1 = 0.186888 loss)
I0620 13:15:47.666863 17898 sgd_solver.cpp:106] Iteration 30000, lr = 0.1
I0620 13:32:32.578168 17898 solver.cpp:337] Iteration 30400, Testing net (#0)
I0620 13:33:35.808042 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.754922
I0620 13:33:35.808269 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.871425 (* 1 = 0.871425 loss)
I0620 13:33:38.295043 17898 solver.cpp:228] Iteration 30400, loss = 0.252819
I0620 13:33:38.295106 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.252819 (* 1 = 0.252819 loss)
I0620 13:33:38.295123 17898 sgd_solver.cpp:106] Iteration 30400, lr = 0.1
I0620 13:50:23.393599 17898 solver.cpp:337] Iteration 30800, Testing net (#0)
I0620 13:51:26.840648 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.671328
I0620 13:51:26.840838 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.1982 (* 1 = 1.1982 loss)
I0620 13:51:29.331805 17898 solver.cpp:228] Iteration 30800, loss = 0.146463
I0620 13:51:29.331859 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.146463 (* 1 = 0.146463 loss)
I0620 13:51:29.331873 17898 sgd_solver.cpp:106] Iteration 30800, lr = 0.1
I0620 14:08:14.086743 17898 solver.cpp:337] Iteration 31200, Testing net (#0)
I0620 14:09:17.475209 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.787422
I0620 14:09:17.475440 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.717265 (* 1 = 0.717265 loss)
I0620 14:09:19.962213 17898 solver.cpp:228] Iteration 31200, loss = 0.195906
I0620 14:09:19.962272 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.195906 (* 1 = 0.195906 loss)
I0620 14:09:19.962285 17898 sgd_solver.cpp:106] Iteration 31200, lr = 0.1
I0620 14:26:05.336613 17898 solver.cpp:337] Iteration 31600, Testing net (#0)
I0620 14:27:08.704244 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.679922
I0620 14:27:08.704479 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.29154 (* 1 = 1.29154 loss)
I0620 14:27:11.185210 17898 solver.cpp:228] Iteration 31600, loss = 0.204044
I0620 14:27:11.185245 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.204044 (* 1 = 0.204044 loss)
I0620 14:27:11.185259 17898 sgd_solver.cpp:106] Iteration 31600, lr = 0.1
I0620 14:43:56.278973 17898 solver.cpp:337] Iteration 32000, Testing net (#0)
I0620 14:44:59.769299 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.585391
I0620 14:44:59.769596 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.7349 (* 1 = 1.7349 loss)
I0620 14:45:02.240334 17898 solver.cpp:228] Iteration 32000, loss = 0.216183
I0620 14:45:02.240383 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216183 (* 1 = 0.216183 loss)
I0620 14:45:02.240397 17898 sgd_solver.cpp:106] Iteration 32000, lr = 0.1
I0620 15:01:47.325634 17898 solver.cpp:337] Iteration 32400, Testing net (#0)
I0620 15:02:50.718565 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.765859
I0620 15:02:50.718801 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.876262 (* 1 = 0.876262 loss)
I0620 15:02:53.222709 17898 solver.cpp:228] Iteration 32400, loss = 0.153857
I0620 15:02:53.222774 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.153857 (* 1 = 0.153857 loss)
I0620 15:02:53.222790 17898 sgd_solver.cpp:106] Iteration 32400, lr = 0.1
I0620 15:19:38.427983 17898 solver.cpp:337] Iteration 32800, Testing net (#0)
I0620 15:20:41.835743 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.716016
I0620 15:20:41.835978 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.14438 (* 1 = 1.14438 loss)
I0620 15:20:44.304705 17898 solver.cpp:228] Iteration 32800, loss = 0.0838958
I0620 15:20:44.304769 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0838957 (* 1 = 0.0838957 loss)
I0620 15:20:44.304782 17898 sgd_solver.cpp:106] Iteration 32800, lr = 0.1
I0620 15:37:29.377971 17898 solver.cpp:337] Iteration 33200, Testing net (#0)
I0620 15:38:32.836920 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.77625
I0620 15:38:32.837152 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.764068 (* 1 = 0.764068 loss)
I0620 15:38:35.326782 17898 solver.cpp:228] Iteration 33200, loss = 0.17035
I0620 15:38:35.326831 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.170349 (* 1 = 0.170349 loss)
I0620 15:38:35.326845 17898 sgd_solver.cpp:106] Iteration 33200, lr = 0.1
I0620 15:55:20.516005 17898 solver.cpp:337] Iteration 33600, Testing net (#0)
I0620 15:56:23.983922 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.752187
I0620 15:56:23.984141 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.97111 (* 1 = 0.97111 loss)
I0620 15:56:26.461349 17898 solver.cpp:228] Iteration 33600, loss = 0.154666
I0620 15:56:26.461390 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.154666 (* 1 = 0.154666 loss)
I0620 15:56:26.461415 17898 sgd_solver.cpp:106] Iteration 33600, lr = 0.1
I0620 16:13:11.856139 17898 solver.cpp:337] Iteration 34000, Testing net (#0)
I0620 16:14:15.246788 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.811406
I0620 16:14:15.247011 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.687525 (* 1 = 0.687525 loss)
I0620 16:14:17.720872 17898 solver.cpp:228] Iteration 34000, loss = 0.149234
I0620 16:14:17.720935 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149234 (* 1 = 0.149234 loss)
I0620 16:14:17.720947 17898 sgd_solver.cpp:106] Iteration 34000, lr = 0.1
I0620 16:31:03.428808 17898 solver.cpp:337] Iteration 34400, Testing net (#0)
I0620 16:32:06.851872 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.793828
I0620 16:32:06.852063 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.799804 (* 1 = 0.799804 loss)
I0620 16:32:09.324231 17898 solver.cpp:228] Iteration 34400, loss = 0.126949
I0620 16:32:09.324264 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126949 (* 1 = 0.126949 loss)
I0620 16:32:09.324275 17898 sgd_solver.cpp:106] Iteration 34400, lr = 0.1
I0620 16:48:54.315270 17898 solver.cpp:337] Iteration 34800, Testing net (#0)
I0620 16:49:57.799356 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.773281
I0620 16:49:57.799554 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.807865 (* 1 = 0.807865 loss)
I0620 16:50:00.278475 17898 solver.cpp:228] Iteration 34800, loss = 0.200175
I0620 16:50:00.278525 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.200175 (* 1 = 0.200175 loss)
I0620 16:50:00.278539 17898 sgd_solver.cpp:106] Iteration 34800, lr = 0.1
I0620 17:06:45.440548 17898 solver.cpp:337] Iteration 35200, Testing net (#0)
I0620 17:07:48.897172 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.779531
I0620 17:07:48.897353 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.734984 (* 1 = 0.734984 loss)
I0620 17:07:51.371176 17898 solver.cpp:228] Iteration 35200, loss = 0.190211
I0620 17:07:51.371232 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190211 (* 1 = 0.190211 loss)
I0620 17:07:51.371245 17898 sgd_solver.cpp:106] Iteration 35200, lr = 0.1
I0620 17:24:36.390506 17898 solver.cpp:337] Iteration 35600, Testing net (#0)
I0620 17:25:39.715989 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.831172
I0620 17:25:39.716114 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.526034 (* 1 = 0.526034 loss)
I0620 17:25:42.188316 17898 solver.cpp:228] Iteration 35600, loss = 0.29575
I0620 17:25:42.188354 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.29575 (* 1 = 0.29575 loss)
I0620 17:25:42.188367 17898 sgd_solver.cpp:106] Iteration 35600, lr = 0.1
I0620 17:42:27.327649 17898 solver.cpp:337] Iteration 36000, Testing net (#0)
I0620 17:43:30.788808 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.829687
I0620 17:43:30.789001 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.557235 (* 1 = 0.557235 loss)
I0620 17:43:33.265233 17898 solver.cpp:228] Iteration 36000, loss = 0.163027
I0620 17:43:33.265283 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163027 (* 1 = 0.163027 loss)
I0620 17:43:33.265302 17898 sgd_solver.cpp:106] Iteration 36000, lr = 0.1
I0620 18:00:18.596671 17898 solver.cpp:337] Iteration 36400, Testing net (#0)
I0620 18:01:22.061321 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.803906
I0620 18:01:22.061486 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.657729 (* 1 = 0.657729 loss)
I0620 18:01:24.536674 17898 solver.cpp:228] Iteration 36400, loss = 0.169926
I0620 18:01:24.536718 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.169926 (* 1 = 0.169926 loss)
I0620 18:01:24.536731 17898 sgd_solver.cpp:106] Iteration 36400, lr = 0.1
I0620 18:18:09.948518 17898 solver.cpp:337] Iteration 36800, Testing net (#0)
I0620 18:19:13.348893 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.780937
I0620 18:19:13.349081 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.918144 (* 1 = 0.918144 loss)
I0620 18:19:15.830523 17898 solver.cpp:228] Iteration 36800, loss = 0.174657
I0620 18:19:15.830556 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.174657 (* 1 = 0.174657 loss)
I0620 18:19:15.830580 17898 sgd_solver.cpp:106] Iteration 36800, lr = 0.1
I0620 18:36:01.309751 17898 solver.cpp:337] Iteration 37200, Testing net (#0)
I0620 18:37:04.698581 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.749219
I0620 18:37:04.698781 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.07268 (* 1 = 1.07268 loss)
I0620 18:37:07.189540 17898 solver.cpp:228] Iteration 37200, loss = 0.218214
I0620 18:37:07.189584 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.218214 (* 1 = 0.218214 loss)
I0620 18:37:07.189599 17898 sgd_solver.cpp:106] Iteration 37200, lr = 0.1
I0620 18:53:52.424690 17898 solver.cpp:337] Iteration 37600, Testing net (#0)
I0620 18:54:55.682754 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.690703
I0620 18:54:55.682960 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.23581 (* 1 = 1.23581 loss)
I0620 18:54:58.157208 17898 solver.cpp:228] Iteration 37600, loss = 0.0841225
I0620 18:54:58.157253 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0841224 (* 1 = 0.0841224 loss)
I0620 18:54:58.157266 17898 sgd_solver.cpp:106] Iteration 37600, lr = 0.1
I0620 19:11:43.254521 17898 solver.cpp:337] Iteration 38000, Testing net (#0)
I0620 19:12:46.703989 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.776016
I0620 19:12:46.704200 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.783419 (* 1 = 0.783419 loss)
I0620 19:12:49.176996 17898 solver.cpp:228] Iteration 38000, loss = 0.234102
I0620 19:12:49.177083 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.234102 (* 1 = 0.234102 loss)
I0620 19:12:49.177095 17898 sgd_solver.cpp:106] Iteration 38000, lr = 0.1
I0620 19:29:34.491312 17898 solver.cpp:337] Iteration 38400, Testing net (#0)
I0620 19:30:37.931483 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.823359
I0620 19:30:37.931676 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.591263 (* 1 = 0.591263 loss)
I0620 19:30:40.407387 17898 solver.cpp:228] Iteration 38400, loss = 0.191694
I0620 19:30:40.407436 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.191694 (* 1 = 0.191694 loss)
I0620 19:30:40.407451 17898 sgd_solver.cpp:106] Iteration 38400, lr = 0.1
I0620 19:47:25.521014 17898 solver.cpp:337] Iteration 38800, Testing net (#0)
I0620 19:48:28.859237 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.794062
I0620 19:48:28.859417 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.722301 (* 1 = 0.722301 loss)
I0620 19:48:31.331138 17898 solver.cpp:228] Iteration 38800, loss = 0.241465
I0620 19:48:31.331187 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.241465 (* 1 = 0.241465 loss)
I0620 19:48:31.331203 17898 sgd_solver.cpp:106] Iteration 38800, lr = 0.1
I0620 20:05:16.468731 17898 solver.cpp:337] Iteration 39200, Testing net (#0)
I0620 20:06:19.933295 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.654297
I0620 20:06:19.933478 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.32937 (* 1 = 1.32937 loss)
I0620 20:06:22.413835 17898 solver.cpp:228] Iteration 39200, loss = 0.196519
I0620 20:06:22.413924 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.196519 (* 1 = 0.196519 loss)
I0620 20:06:22.413949 17898 sgd_solver.cpp:106] Iteration 39200, lr = 0.1
I0620 20:23:07.469697 17898 solver.cpp:337] Iteration 39600, Testing net (#0)
I0620 20:24:10.920503 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.638594
I0620 20:24:10.920723 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.84907 (* 1 = 1.84907 loss)
I0620 20:24:13.394595 17898 solver.cpp:228] Iteration 39600, loss = 0.106954
I0620 20:24:13.394654 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.106954 (* 1 = 0.106954 loss)
I0620 20:24:13.394668 17898 sgd_solver.cpp:106] Iteration 39600, lr = 0.1
I0620 20:40:58.461380 17898 solver.cpp:337] Iteration 40000, Testing net (#0)
I0620 20:42:01.736449 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.766016
I0620 20:42:01.736642 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.89617 (* 1 = 0.89617 loss)
I0620 20:42:04.212779 17898 solver.cpp:228] Iteration 40000, loss = 0.171975
I0620 20:42:04.212829 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171975 (* 1 = 0.171975 loss)
I0620 20:42:04.212853 17898 sgd_solver.cpp:106] Iteration 40000, lr = 0.1
I0620 20:58:49.393643 17898 solver.cpp:337] Iteration 40400, Testing net (#0)
I0620 20:59:52.705126 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.704844
I0620 20:59:52.705318 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.0093 (* 1 = 1.0093 loss)
I0620 20:59:55.180347 17898 solver.cpp:228] Iteration 40400, loss = 0.259515
I0620 20:59:55.180403 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.259515 (* 1 = 0.259515 loss)
I0620 20:59:55.180418 17898 sgd_solver.cpp:106] Iteration 40400, lr = 0.1
I0620 21:16:40.139852 17898 solver.cpp:337] Iteration 40800, Testing net (#0)
I0620 21:17:43.604344 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.834766
I0620 21:17:43.604538 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.546927 (* 1 = 0.546927 loss)
I0620 21:17:46.079633 17898 solver.cpp:228] Iteration 40800, loss = 0.199684
I0620 21:17:46.079680 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.199684 (* 1 = 0.199684 loss)
I0620 21:17:46.079694 17898 sgd_solver.cpp:106] Iteration 40800, lr = 0.1
I0620 21:34:31.534487 17898 solver.cpp:337] Iteration 41200, Testing net (#0)
I0620 21:35:34.965183 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.791172
I0620 21:35:34.965405 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.696281 (* 1 = 0.696281 loss)
I0620 21:35:37.434839 17898 solver.cpp:228] Iteration 41200, loss = 0.128566
I0620 21:35:37.434885 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.128566 (* 1 = 0.128566 loss)
I0620 21:35:37.434903 17898 sgd_solver.cpp:106] Iteration 41200, lr = 0.1
I0620 21:52:22.676324 17898 solver.cpp:337] Iteration 41600, Testing net (#0)
I0620 21:53:26.099447 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.804922
I0620 21:53:26.099650 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.614448 (* 1 = 0.614448 loss)
I0620 21:53:28.576341 17898 solver.cpp:228] Iteration 41600, loss = 0.161156
I0620 21:53:28.576391 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161155 (* 1 = 0.161155 loss)
I0620 21:53:28.576405 17898 sgd_solver.cpp:106] Iteration 41600, lr = 0.1
I0620 22:10:13.913384 17898 solver.cpp:337] Iteration 42000, Testing net (#0)
I0620 22:11:17.234336 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.708047
I0620 22:11:17.234554 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.23017 (* 1 = 1.23017 loss)
I0620 22:11:19.707381 17898 solver.cpp:228] Iteration 42000, loss = 0.0890435
I0620 22:11:19.707432 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0890434 (* 1 = 0.0890434 loss)
I0620 22:11:19.707447 17898 sgd_solver.cpp:106] Iteration 42000, lr = 0.1
I0620 22:28:04.747496 17898 solver.cpp:337] Iteration 42400, Testing net (#0)
I0620 22:29:08.047965 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.751641
I0620 22:29:08.048105 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.85171 (* 1 = 0.85171 loss)
I0620 22:29:10.541177 17898 solver.cpp:228] Iteration 42400, loss = 0.141147
I0620 22:29:10.541229 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.141147 (* 1 = 0.141147 loss)
I0620 22:29:10.541240 17898 sgd_solver.cpp:106] Iteration 42400, lr = 0.1
I0620 22:45:55.689743 17898 solver.cpp:337] Iteration 42800, Testing net (#0)
I0620 22:46:59.170298 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.717969
I0620 22:46:59.170483 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.09628 (* 1 = 1.09628 loss)
I0620 22:47:01.655855 17898 solver.cpp:228] Iteration 42800, loss = 0.211854
I0620 22:47:01.655900 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.211854 (* 1 = 0.211854 loss)
I0620 22:47:01.655913 17898 sgd_solver.cpp:106] Iteration 42800, lr = 0.1
I0620 23:03:46.973943 17898 solver.cpp:337] Iteration 43200, Testing net (#0)
I0620 23:04:50.465294 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.745156
I0620 23:04:50.465356 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.871552 (* 1 = 0.871552 loss)
I0620 23:04:52.941519 17898 solver.cpp:228] Iteration 43200, loss = 0.17346
I0620 23:04:52.941577 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173459 (* 1 = 0.173459 loss)
I0620 23:04:52.941602 17898 sgd_solver.cpp:106] Iteration 43200, lr = 0.1
I0620 23:21:38.306352 17898 solver.cpp:337] Iteration 43600, Testing net (#0)
I0620 23:22:41.662129 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.831563
I0620 23:22:41.662305 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.516351 (* 1 = 0.516351 loss)
I0620 23:22:44.134116 17898 solver.cpp:228] Iteration 43600, loss = 0.137002
I0620 23:22:44.134160 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.137002 (* 1 = 0.137002 loss)
I0620 23:22:44.134176 17898 sgd_solver.cpp:106] Iteration 43600, lr = 0.1
I0620 23:39:29.700199 17898 solver.cpp:337] Iteration 44000, Testing net (#0)
I0620 23:40:33.158020 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.784922
I0620 23:40:33.158200 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.710925 (* 1 = 0.710925 loss)
I0620 23:40:35.631424 17898 solver.cpp:228] Iteration 44000, loss = 0.181194
I0620 23:40:35.631464 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181194 (* 1 = 0.181194 loss)
I0620 23:40:35.631474 17898 sgd_solver.cpp:106] Iteration 44000, lr = 0.1
I0620 23:57:20.944846 17898 solver.cpp:337] Iteration 44400, Testing net (#0)
I0620 23:58:24.417345 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.793594
I0620 23:58:24.417533 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.759403 (* 1 = 0.759403 loss)
I0620 23:58:26.889534 17898 solver.cpp:228] Iteration 44400, loss = 0.216803
I0620 23:58:26.889587 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.216803 (* 1 = 0.216803 loss)
I0620 23:58:26.889601 17898 sgd_solver.cpp:106] Iteration 44400, lr = 0.1
I0621 00:15:11.955368 17898 solver.cpp:337] Iteration 44800, Testing net (#0)
I0621 00:16:15.379041 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.659141
I0621 00:16:15.379269 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.17863 (* 1 = 1.17863 loss)
I0621 00:16:17.855170 17898 solver.cpp:228] Iteration 44800, loss = 0.230271
I0621 00:16:17.855209 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.230271 (* 1 = 0.230271 loss)
I0621 00:16:17.855223 17898 sgd_solver.cpp:106] Iteration 44800, lr = 0.1
I0621 00:33:03.022091 17898 solver.cpp:337] Iteration 45200, Testing net (#0)
I0621 00:34:06.407658 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.695234
I0621 00:34:06.407917 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.04788 (* 1 = 1.04788 loss)
I0621 00:34:08.889565 17898 solver.cpp:228] Iteration 45200, loss = 0.119248
I0621 00:34:08.889636 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.119248 (* 1 = 0.119248 loss)
I0621 00:34:08.889657 17898 sgd_solver.cpp:106] Iteration 45200, lr = 0.1
I0621 00:50:54.208222 17898 solver.cpp:337] Iteration 45600, Testing net (#0)
I0621 00:51:57.597020 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.790234
I0621 00:51:57.597201 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.646624 (* 1 = 0.646624 loss)
I0621 00:52:00.072250 17898 solver.cpp:228] Iteration 45600, loss = 0.133381
I0621 00:52:00.072314 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.133381 (* 1 = 0.133381 loss)
I0621 00:52:00.072327 17898 sgd_solver.cpp:106] Iteration 45600, lr = 0.1
I0621 01:08:45.330941 17898 solver.cpp:337] Iteration 46000, Testing net (#0)
I0621 01:09:48.718426 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.652969
I0621 01:09:48.718644 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.49426 (* 1 = 1.49426 loss)
I0621 01:09:51.194229 17898 solver.cpp:228] Iteration 46000, loss = 0.151615
I0621 01:09:51.194270 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151615 (* 1 = 0.151615 loss)
I0621 01:09:51.194283 17898 sgd_solver.cpp:106] Iteration 46000, lr = 0.1
I0621 01:26:36.579016 17898 solver.cpp:337] Iteration 46400, Testing net (#0)
I0621 01:27:39.979787 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.761406
I0621 01:27:39.979985 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.796496 (* 1 = 0.796496 loss)
I0621 01:27:42.455588 17898 solver.cpp:228] Iteration 46400, loss = 0.121755
I0621 01:27:42.455643 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121755 (* 1 = 0.121755 loss)
I0621 01:27:42.455658 17898 sgd_solver.cpp:106] Iteration 46400, lr = 0.1
I0621 01:44:27.523048 17898 solver.cpp:337] Iteration 46800, Testing net (#0)
I0621 01:45:30.952208 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.800234
I0621 01:45:30.952417 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.723782 (* 1 = 0.723782 loss)
I0621 01:45:33.430635 17898 solver.cpp:228] Iteration 46800, loss = 0.192675
I0621 01:45:33.430691 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192675 (* 1 = 0.192675 loss)
I0621 01:45:33.430706 17898 sgd_solver.cpp:106] Iteration 46800, lr = 0.1
I0621 02:02:18.668191 17898 solver.cpp:337] Iteration 47200, Testing net (#0)
I0621 02:03:22.071050 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.81875
I0621 02:03:22.071267 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.596984 (* 1 = 0.596984 loss)
I0621 02:03:24.544755 17898 solver.cpp:228] Iteration 47200, loss = 0.207049
I0621 02:03:24.544817 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.207049 (* 1 = 0.207049 loss)
I0621 02:03:24.544831 17898 sgd_solver.cpp:106] Iteration 47200, lr = 0.1
I0621 02:20:09.919980 17898 solver.cpp:337] Iteration 47600, Testing net (#0)
I0621 02:21:13.277539 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.762422
I0621 02:21:13.277753 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.800999 (* 1 = 0.800999 loss)
I0621 02:21:15.752118 17898 solver.cpp:228] Iteration 47600, loss = 0.161799
I0621 02:21:15.752164 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161799 (* 1 = 0.161799 loss)
I0621 02:21:15.752184 17898 sgd_solver.cpp:106] Iteration 47600, lr = 0.1
I0621 02:38:00.405592 17898 solver.cpp:337] Iteration 48000, Testing net (#0)
I0621 02:39:03.805853 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.745156
I0621 02:39:03.805987 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.846782 (* 1 = 0.846782 loss)
I0621 02:39:06.284713 17898 solver.cpp:228] Iteration 48000, loss = 0.126449
I0621 02:39:06.284752 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126449 (* 1 = 0.126449 loss)
I0621 02:39:06.284765 17898 sgd_solver.cpp:106] Iteration 48000, lr = 0.1
I0621 02:55:51.495952 17898 solver.cpp:337] Iteration 48400, Testing net (#0)
I0621 02:56:54.887320 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.831953
I0621 02:56:54.887498 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.565758 (* 1 = 0.565758 loss)
I0621 02:56:57.378159 17898 solver.cpp:228] Iteration 48400, loss = 0.0735275
I0621 02:56:57.378203 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0735275 (* 1 = 0.0735275 loss)
I0621 02:56:57.378216 17898 sgd_solver.cpp:106] Iteration 48400, lr = 0.1
I0621 03:13:42.467347 17898 solver.cpp:337] Iteration 48800, Testing net (#0)
I0621 03:14:45.865316 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.773906
I0621 03:14:45.865563 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.911985 (* 1 = 0.911985 loss)
I0621 03:14:48.339901 17898 solver.cpp:228] Iteration 48800, loss = 0.176442
I0621 03:14:48.339954 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.176442 (* 1 = 0.176442 loss)
I0621 03:14:48.339967 17898 sgd_solver.cpp:106] Iteration 48800, lr = 0.1
I0621 03:31:33.591545 17898 solver.cpp:337] Iteration 49200, Testing net (#0)
I0621 03:32:37.078568 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.798906
I0621 03:32:37.078738 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.715785 (* 1 = 0.715785 loss)
I0621 03:32:39.572511 17898 solver.cpp:228] Iteration 49200, loss = 0.177104
I0621 03:32:39.572568 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177104 (* 1 = 0.177104 loss)
I0621 03:32:39.572582 17898 sgd_solver.cpp:106] Iteration 49200, lr = 0.1
I0621 03:49:24.961488 17898 solver.cpp:337] Iteration 49600, Testing net (#0)
I0621 03:50:28.309979 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.729219
I0621 03:50:28.310201 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.07992 (* 1 = 1.07992 loss)
I0621 03:50:30.778048 17898 solver.cpp:228] Iteration 49600, loss = 0.144208
I0621 03:50:30.778103 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.144208 (* 1 = 0.144208 loss)
I0621 03:50:30.778116 17898 sgd_solver.cpp:106] Iteration 49600, lr = 0.1
I0621 04:07:16.466462 17898 solver.cpp:337] Iteration 50000, Testing net (#0)
I0621 04:08:19.889853 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.7425
I0621 04:08:19.890065 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.31979 (* 1 = 1.31979 loss)
I0621 04:08:22.360846 17898 solver.cpp:228] Iteration 50000, loss = 0.146559
I0621 04:08:22.360893 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.146559 (* 1 = 0.146559 loss)
I0621 04:08:22.360904 17898 sgd_solver.cpp:106] Iteration 50000, lr = 0.1
I0621 04:25:07.785817 17898 solver.cpp:337] Iteration 50400, Testing net (#0)
I0621 04:26:11.155838 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.727578
I0621 04:26:11.156075 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.12574 (* 1 = 1.12574 loss)
I0621 04:26:13.628316 17898 solver.cpp:228] Iteration 50400, loss = 0.163366
I0621 04:26:13.628379 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163366 (* 1 = 0.163366 loss)
I0621 04:26:13.628392 17898 sgd_solver.cpp:106] Iteration 50400, lr = 0.1
I0621 04:42:58.673748 17898 solver.cpp:337] Iteration 50800, Testing net (#0)
I0621 04:44:02.127516 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.795313
I0621 04:44:02.127714 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.782946 (* 1 = 0.782946 loss)
I0621 04:44:04.608631 17898 solver.cpp:228] Iteration 50800, loss = 0.138048
I0621 04:44:04.608695 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138047 (* 1 = 0.138047 loss)
I0621 04:44:04.608714 17898 sgd_solver.cpp:106] Iteration 50800, lr = 0.1
I0621 05:00:49.901015 17898 solver.cpp:337] Iteration 51200, Testing net (#0)
I0621 05:01:53.290662 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.76875
I0621 05:01:53.290887 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.887101 (* 1 = 0.887101 loss)
I0621 05:01:55.772688 17898 solver.cpp:228] Iteration 51200, loss = 0.0983383
I0621 05:01:55.772761 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0983382 (* 1 = 0.0983382 loss)
I0621 05:01:55.772775 17898 sgd_solver.cpp:106] Iteration 51200, lr = 0.1
I0621 05:18:41.113245 17898 solver.cpp:337] Iteration 51600, Testing net (#0)
I0621 05:19:44.467118 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.786094
I0621 05:19:44.467377 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.69766 (* 1 = 0.69766 loss)
I0621 05:19:46.943162 17898 solver.cpp:228] Iteration 51600, loss = 0.108107
I0621 05:19:46.943222 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.108107 (* 1 = 0.108107 loss)
I0621 05:19:46.943236 17898 sgd_solver.cpp:106] Iteration 51600, lr = 0.1
I0621 05:36:32.424654 17898 solver.cpp:337] Iteration 52000, Testing net (#0)
I0621 05:37:35.881342 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.786094
I0621 05:37:35.881516 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.708611 (* 1 = 0.708611 loss)
I0621 05:37:38.345163 17898 solver.cpp:228] Iteration 52000, loss = 0.209199
I0621 05:37:38.345201 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.209199 (* 1 = 0.209199 loss)
I0621 05:37:38.345213 17898 sgd_solver.cpp:106] Iteration 52000, lr = 0.1
I0621 05:54:23.828407 17898 solver.cpp:337] Iteration 52400, Testing net (#0)
I0621 05:55:27.181592 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.679219
I0621 05:55:27.181792 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.44784 (* 1 = 1.44784 loss)
I0621 05:55:29.652523 17898 solver.cpp:228] Iteration 52400, loss = 0.0799701
I0621 05:55:29.652565 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.07997 (* 1 = 0.07997 loss)
I0621 05:55:29.652580 17898 sgd_solver.cpp:106] Iteration 52400, lr = 0.1
I0621 06:12:14.778267 17898 solver.cpp:337] Iteration 52800, Testing net (#0)
I0621 06:13:18.206323 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.742969
I0621 06:13:18.206424 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.972167 (* 1 = 0.972167 loss)
I0621 06:13:20.672384 17898 solver.cpp:228] Iteration 52800, loss = 0.0787999
I0621 06:13:20.672453 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0787998 (* 1 = 0.0787998 loss)
I0621 06:13:20.672472 17898 sgd_solver.cpp:106] Iteration 52800, lr = 0.1
I0621 06:30:05.564529 17898 solver.cpp:337] Iteration 53200, Testing net (#0)
I0621 06:31:09.058378 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.753906
I0621 06:31:09.058622 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.1257 (* 1 = 1.1257 loss)
I0621 06:31:11.527355 17898 solver.cpp:228] Iteration 53200, loss = 0.10346
I0621 06:31:11.527406 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.10346 (* 1 = 0.10346 loss)
I0621 06:31:11.527422 17898 sgd_solver.cpp:106] Iteration 53200, lr = 0.1
I0621 06:47:56.756338 17898 solver.cpp:337] Iteration 53600, Testing net (#0)
I0621 06:49:00.167117 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.748359
I0621 06:49:00.167343 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.998301 (* 1 = 0.998301 loss)
I0621 06:49:02.641711 17898 solver.cpp:228] Iteration 53600, loss = 0.136586
I0621 06:49:02.641754 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136586 (* 1 = 0.136586 loss)
I0621 06:49:02.641767 17898 sgd_solver.cpp:106] Iteration 53600, lr = 0.1
I0621 07:05:47.897685 17898 solver.cpp:337] Iteration 54000, Testing net (#0)
I0621 07:06:51.313349 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.749219
I0621 07:06:51.313544 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.958991 (* 1 = 0.958991 loss)
I0621 07:06:53.791182 17898 solver.cpp:228] Iteration 54000, loss = 0.148274
I0621 07:06:53.791254 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148274 (* 1 = 0.148274 loss)
I0621 07:06:53.791270 17898 sgd_solver.cpp:106] Iteration 54000, lr = 0.1
I0621 07:23:38.711364 17898 solver.cpp:337] Iteration 54400, Testing net (#0)
I0621 07:24:42.159122 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.782891
I0621 07:24:42.159348 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.760431 (* 1 = 0.760431 loss)
I0621 07:24:44.638881 17898 solver.cpp:228] Iteration 54400, loss = 0.132892
I0621 07:24:44.638921 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.132892 (* 1 = 0.132892 loss)
I0621 07:24:44.638931 17898 sgd_solver.cpp:106] Iteration 54400, lr = 0.1
I0621 07:41:29.847676 17898 solver.cpp:337] Iteration 54800, Testing net (#0)
I0621 07:42:33.241201 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.781172
I0621 07:42:33.241415 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.825916 (* 1 = 0.825916 loss)
I0621 07:42:35.717465 17898 solver.cpp:228] Iteration 54800, loss = 0.22561
I0621 07:42:35.717509 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.22561 (* 1 = 0.22561 loss)
I0621 07:42:35.717521 17898 sgd_solver.cpp:106] Iteration 54800, lr = 0.1
I0621 07:59:20.897516 17898 solver.cpp:337] Iteration 55200, Testing net (#0)
I0621 08:00:24.187855 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.801094
I0621 08:00:24.188061 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.650164 (* 1 = 0.650164 loss)
I0621 08:00:26.679249 17898 solver.cpp:228] Iteration 55200, loss = 0.151693
I0621 08:00:26.679291 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151693 (* 1 = 0.151693 loss)
I0621 08:00:26.679303 17898 sgd_solver.cpp:106] Iteration 55200, lr = 0.1
I0621 08:17:11.961560 17898 solver.cpp:337] Iteration 55600, Testing net (#0)
I0621 08:18:15.322706 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.756719
I0621 08:18:15.322862 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.958087 (* 1 = 0.958087 loss)
I0621 08:18:17.796212 17898 solver.cpp:228] Iteration 55600, loss = 0.114881
I0621 08:18:17.796257 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.114881 (* 1 = 0.114881 loss)
I0621 08:18:17.796278 17898 sgd_solver.cpp:106] Iteration 55600, lr = 0.1
I0621 08:35:02.894696 17898 solver.cpp:337] Iteration 56000, Testing net (#0)
I0621 08:36:06.185155 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.731719
I0621 08:36:06.185375 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.17876 (* 1 = 1.17876 loss)
I0621 08:36:08.660682 17898 solver.cpp:228] Iteration 56000, loss = 0.234495
I0621 08:36:08.660724 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.234495 (* 1 = 0.234495 loss)
I0621 08:36:08.660737 17898 sgd_solver.cpp:106] Iteration 56000, lr = 0.1
I0621 08:52:53.768429 17898 solver.cpp:337] Iteration 56400, Testing net (#0)
I0621 08:53:57.191015 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.61875
I0621 08:53:57.191234 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.991 (* 1 = 1.991 loss)
I0621 08:53:59.674047 17898 solver.cpp:228] Iteration 56400, loss = 0.10279
I0621 08:53:59.674103 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.10279 (* 1 = 0.10279 loss)
I0621 08:53:59.674116 17898 sgd_solver.cpp:106] Iteration 56400, lr = 0.1
I0621 09:10:44.663691 17898 solver.cpp:337] Iteration 56800, Testing net (#0)
I0621 09:11:48.071053 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.724922
I0621 09:11:48.071283 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.15221 (* 1 = 1.15221 loss)
I0621 09:11:50.548214 17898 solver.cpp:228] Iteration 56800, loss = 0.0936475
I0621 09:11:50.548274 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0936475 (* 1 = 0.0936475 loss)
I0621 09:11:50.548286 17898 sgd_solver.cpp:106] Iteration 56800, lr = 0.1
I0621 09:28:35.819130 17898 solver.cpp:337] Iteration 57200, Testing net (#0)
I0621 09:29:39.179268 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.720703
I0621 09:29:39.179481 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.877838 (* 1 = 0.877838 loss)
I0621 09:29:41.657583 17898 solver.cpp:228] Iteration 57200, loss = 0.189589
I0621 09:29:41.657637 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189588 (* 1 = 0.189588 loss)
I0621 09:29:41.657651 17898 sgd_solver.cpp:106] Iteration 57200, lr = 0.1
I0621 09:46:26.168486 17898 solver.cpp:337] Iteration 57600, Testing net (#0)
I0621 09:47:29.539580 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.789141
I0621 09:47:29.539757 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.819671 (* 1 = 0.819671 loss)
I0621 09:47:32.011018 17898 solver.cpp:228] Iteration 57600, loss = 0.201354
I0621 09:47:32.011083 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.201354 (* 1 = 0.201354 loss)
I0621 09:47:32.011096 17898 sgd_solver.cpp:106] Iteration 57600, lr = 0.1
I0621 10:04:17.093334 17898 solver.cpp:337] Iteration 58000, Testing net (#0)
I0621 10:05:20.516881 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.792656
I0621 10:05:20.517096 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.818273 (* 1 = 0.818273 loss)
I0621 10:05:22.995134 17898 solver.cpp:228] Iteration 58000, loss = 0.161298
I0621 10:05:22.995192 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161298 (* 1 = 0.161298 loss)
I0621 10:05:22.995204 17898 sgd_solver.cpp:106] Iteration 58000, lr = 0.1
I0621 10:22:07.979547 17898 solver.cpp:337] Iteration 58400, Testing net (#0)
I0621 10:23:11.406638 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.736953
I0621 10:23:11.406817 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.929031 (* 1 = 0.929031 loss)
I0621 10:23:13.875038 17898 solver.cpp:228] Iteration 58400, loss = 0.175843
I0621 10:23:13.875075 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.175843 (* 1 = 0.175843 loss)
I0621 10:23:13.875087 17898 sgd_solver.cpp:106] Iteration 58400, lr = 0.1
I0621 10:39:58.815053 17898 solver.cpp:337] Iteration 58800, Testing net (#0)
I0621 10:41:02.200525 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.694531
I0621 10:41:02.200665 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.37114 (* 1 = 1.37114 loss)
I0621 10:41:04.678158 17898 solver.cpp:228] Iteration 58800, loss = 0.168494
I0621 10:41:04.678195 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168494 (* 1 = 0.168494 loss)
I0621 10:41:04.678208 17898 sgd_solver.cpp:106] Iteration 58800, lr = 0.1
I0621 10:57:49.541631 17898 solver.cpp:337] Iteration 59200, Testing net (#0)
I0621 10:58:52.957172 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.738594
I0621 10:58:52.957381 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.00746 (* 1 = 1.00746 loss)
I0621 10:58:55.421452 17898 solver.cpp:228] Iteration 59200, loss = 0.140002
I0621 10:58:55.421499 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.140002 (* 1 = 0.140002 loss)
I0621 10:58:55.421509 17898 sgd_solver.cpp:106] Iteration 59200, lr = 0.1
I0621 11:15:40.408020 17898 solver.cpp:337] Iteration 59600, Testing net (#0)
I0621 11:16:43.926769 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.782734
I0621 11:16:43.926926 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.923618 (* 1 = 0.923618 loss)
I0621 11:16:46.405764 17898 solver.cpp:228] Iteration 59600, loss = 0.141695
I0621 11:16:46.405804 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.141695 (* 1 = 0.141695 loss)
I0621 11:16:46.405817 17898 sgd_solver.cpp:106] Iteration 59600, lr = 0.1
I0621 11:33:31.245266 17898 solver.cpp:337] Iteration 60000, Testing net (#0)
I0621 11:34:34.569250 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.816797
I0621 11:34:34.569476 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.675872 (* 1 = 0.675872 loss)
I0621 11:34:37.045563 17898 solver.cpp:228] Iteration 60000, loss = 0.138961
I0621 11:34:37.045608 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138961 (* 1 = 0.138961 loss)
I0621 11:34:37.045621 17898 sgd_solver.cpp:106] Iteration 60000, lr = 0.1
I0621 11:51:22.647471 17898 solver.cpp:337] Iteration 60400, Testing net (#0)
I0621 11:52:26.156047 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.831953
I0621 11:52:26.156258 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.556295 (* 1 = 0.556295 loss)
I0621 11:52:28.633965 17898 solver.cpp:228] Iteration 60400, loss = 0.16184
I0621 11:52:28.634021 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16184 (* 1 = 0.16184 loss)
I0621 11:52:28.634037 17898 sgd_solver.cpp:106] Iteration 60400, lr = 0.1
I0621 12:09:13.981153 17898 solver.cpp:337] Iteration 60800, Testing net (#0)
I0621 12:10:17.362581 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.789375
I0621 12:10:17.362766 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.647758 (* 1 = 0.647758 loss)
I0621 12:10:19.836621 17898 solver.cpp:228] Iteration 60800, loss = 0.167672
I0621 12:10:19.836654 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.167672 (* 1 = 0.167672 loss)
I0621 12:10:19.836668 17898 sgd_solver.cpp:106] Iteration 60800, lr = 0.1
I0621 12:27:04.378959 17898 solver.cpp:337] Iteration 61200, Testing net (#0)
I0621 12:28:07.609792 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.821563
I0621 12:28:07.610014 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.623308 (* 1 = 0.623308 loss)
I0621 12:28:10.125385 17898 solver.cpp:228] Iteration 61200, loss = 0.138705
I0621 12:28:10.125444 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.138705 (* 1 = 0.138705 loss)
I0621 12:28:10.125458 17898 sgd_solver.cpp:106] Iteration 61200, lr = 0.1
I0621 12:44:55.320513 17898 solver.cpp:337] Iteration 61600, Testing net (#0)
I0621 12:45:58.704593 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.662578
I0621 12:45:58.704761 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.25812 (* 1 = 1.25812 loss)
I0621 12:46:01.176676 17898 solver.cpp:228] Iteration 61600, loss = 0.102453
I0621 12:46:01.176770 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102453 (* 1 = 0.102453 loss)
I0621 12:46:01.176784 17898 sgd_solver.cpp:106] Iteration 61600, lr = 0.1
I0621 13:02:46.412855 17898 solver.cpp:337] Iteration 62000, Testing net (#0)
I0621 13:03:49.787639 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.777969
I0621 13:03:49.787808 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.849405 (* 1 = 0.849405 loss)
I0621 13:03:52.261320 17898 solver.cpp:228] Iteration 62000, loss = 0.187248
I0621 13:03:52.261384 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.187248 (* 1 = 0.187248 loss)
I0621 13:03:52.261399 17898 sgd_solver.cpp:106] Iteration 62000, lr = 0.1
I0621 13:20:37.001935 17898 solver.cpp:337] Iteration 62400, Testing net (#0)
I0621 13:21:40.407238 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.783594
I0621 13:21:40.407451 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.959314 (* 1 = 0.959314 loss)
I0621 13:21:42.899777 17898 solver.cpp:228] Iteration 62400, loss = 0.177648
I0621 13:21:42.899868 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177648 (* 1 = 0.177648 loss)
I0621 13:21:42.899883 17898 sgd_solver.cpp:106] Iteration 62400, lr = 0.1
I0621 13:38:27.645504 17898 solver.cpp:337] Iteration 62800, Testing net (#0)
I0621 13:39:31.057251 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.684687
I0621 13:39:31.057498 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.31238 (* 1 = 1.31238 loss)
I0621 13:39:33.530547 17898 solver.cpp:228] Iteration 62800, loss = 0.118637
I0621 13:39:33.530606 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118637 (* 1 = 0.118637 loss)
I0621 13:39:33.530619 17898 sgd_solver.cpp:106] Iteration 62800, lr = 0.1
I0621 13:56:18.598270 17898 solver.cpp:337] Iteration 63200, Testing net (#0)
I0621 13:57:22.096703 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.715391
I0621 13:57:22.096834 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.00813 (* 1 = 1.00813 loss)
I0621 13:57:24.578011 17898 solver.cpp:228] Iteration 63200, loss = 0.0966653
I0621 13:57:24.578045 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0966652 (* 1 = 0.0966652 loss)
I0621 13:57:24.578059 17898 sgd_solver.cpp:106] Iteration 63200, lr = 0.1
I0621 14:14:10.082161 17898 solver.cpp:337] Iteration 63600, Testing net (#0)
I0621 14:15:13.457453 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.78
I0621 14:15:13.457633 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.924257 (* 1 = 0.924257 loss)
I0621 14:15:15.925544 17898 solver.cpp:228] Iteration 63600, loss = 0.238563
I0621 14:15:15.925606 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.238562 (* 1 = 0.238562 loss)
I0621 14:15:15.925619 17898 sgd_solver.cpp:106] Iteration 63600, lr = 0.1
I0621 14:32:01.528311 17898 solver.cpp:337] Iteration 64000, Testing net (#0)
I0621 14:33:04.906930 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.782812
I0621 14:33:04.907119 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.813214 (* 1 = 0.813214 loss)
I0621 14:33:07.387042 17898 solver.cpp:228] Iteration 64000, loss = 0.191516
I0621 14:33:07.387102 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.191516 (* 1 = 0.191516 loss)
I0621 14:33:07.387116 17898 sgd_solver.cpp:106] Iteration 64000, lr = 0.1
I0621 14:49:52.471602 17898 solver.cpp:337] Iteration 64400, Testing net (#0)
I0621 14:50:55.824126 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.790781
I0621 14:50:55.824318 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.731481 (* 1 = 0.731481 loss)
I0621 14:50:58.294188 17898 solver.cpp:228] Iteration 64400, loss = 0.181733
I0621 14:50:58.294257 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.181733 (* 1 = 0.181733 loss)
I0621 14:50:58.294270 17898 sgd_solver.cpp:106] Iteration 64400, lr = 0.1
I0621 15:07:43.080624 17898 solver.cpp:337] Iteration 64800, Testing net (#0)
I0621 15:08:46.484388 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.790703
I0621 15:08:46.484591 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.725737 (* 1 = 0.725737 loss)
I0621 15:08:48.961750 17898 solver.cpp:228] Iteration 64800, loss = 0.0781333
I0621 15:08:48.961807 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0781332 (* 1 = 0.0781332 loss)
I0621 15:08:48.961818 17898 sgd_solver.cpp:106] Iteration 64800, lr = 0.1
I0621 15:25:33.882329 17898 solver.cpp:337] Iteration 65200, Testing net (#0)
I0621 15:26:37.281270 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.795469
I0621 15:26:37.281466 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.823066 (* 1 = 0.823066 loss)
I0621 15:26:39.756435 17898 solver.cpp:228] Iteration 65200, loss = 0.145174
I0621 15:26:39.756508 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.145174 (* 1 = 0.145174 loss)
I0621 15:26:39.756523 17898 sgd_solver.cpp:106] Iteration 65200, lr = 0.1
I0621 15:43:25.140061 17898 solver.cpp:337] Iteration 65600, Testing net (#0)
I0621 15:44:28.554927 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.842891
I0621 15:44:28.555132 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.532864 (* 1 = 0.532864 loss)
I0621 15:44:31.046742 17898 solver.cpp:228] Iteration 65600, loss = 0.0950872
I0621 15:44:31.046795 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0950871 (* 1 = 0.0950871 loss)
I0621 15:44:31.046818 17898 sgd_solver.cpp:106] Iteration 65600, lr = 0.1
I0621 16:01:16.249511 17898 solver.cpp:337] Iteration 66000, Testing net (#0)
I0621 16:02:19.748908 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.81875
I0621 16:02:19.749048 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.653597 (* 1 = 0.653597 loss)
I0621 16:02:22.229409 17898 solver.cpp:228] Iteration 66000, loss = 0.13464
I0621 16:02:22.229447 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.13464 (* 1 = 0.13464 loss)
I0621 16:02:22.229460 17898 sgd_solver.cpp:106] Iteration 66000, lr = 0.1
I0621 16:19:06.775501 17898 solver.cpp:337] Iteration 66400, Testing net (#0)
I0621 16:20:09.997753 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.663359
I0621 16:20:09.997997 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.59985 (* 1 = 1.59985 loss)
I0621 16:20:12.469666 17898 solver.cpp:228] Iteration 66400, loss = 0.0794437
I0621 16:20:12.469728 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0794436 (* 1 = 0.0794436 loss)
I0621 16:20:12.469745 17898 sgd_solver.cpp:106] Iteration 66400, lr = 0.1
I0621 16:36:56.425796 17898 solver.cpp:337] Iteration 66800, Testing net (#0)
I0621 16:37:59.710508 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.803672
I0621 16:37:59.710692 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.692901 (* 1 = 0.692901 loss)
I0621 16:38:02.182176 17898 solver.cpp:228] Iteration 66800, loss = 0.136858
I0621 16:38:02.182224 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136858 (* 1 = 0.136858 loss)
I0621 16:38:02.182235 17898 sgd_solver.cpp:106] Iteration 66800, lr = 0.1
I0621 16:54:46.562623 17898 solver.cpp:337] Iteration 67200, Testing net (#0)
I0621 16:55:49.850215 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.803437
I0621 16:55:49.850440 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.715909 (* 1 = 0.715909 loss)
I0621 16:55:52.323993 17898 solver.cpp:228] Iteration 67200, loss = 0.194463
I0621 16:55:52.324050 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.194463 (* 1 = 0.194463 loss)
I0621 16:55:52.324061 17898 sgd_solver.cpp:106] Iteration 67200, lr = 0.1
I0621 17:12:36.791271 17898 solver.cpp:337] Iteration 67600, Testing net (#0)
I0621 17:13:40.197769 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.854688
I0621 17:13:40.197921 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.506081 (* 1 = 0.506081 loss)
I0621 17:13:42.671082 17898 solver.cpp:228] Iteration 67600, loss = 0.134506
I0621 17:13:42.671149 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.134506 (* 1 = 0.134506 loss)
I0621 17:13:42.671169 17898 sgd_solver.cpp:106] Iteration 67600, lr = 0.1
I0621 17:30:28.035478 17898 solver.cpp:337] Iteration 68000, Testing net (#0)
I0621 17:31:31.518916 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.728125
I0621 17:31:31.519134 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.15929 (* 1 = 1.15929 loss)
I0621 17:31:33.992319 17898 solver.cpp:228] Iteration 68000, loss = 0.131399
I0621 17:31:33.992357 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131399 (* 1 = 0.131399 loss)
I0621 17:31:33.992367 17898 sgd_solver.cpp:106] Iteration 68000, lr = 0.1
I0621 17:48:19.223979 17898 solver.cpp:337] Iteration 68400, Testing net (#0)
I0621 17:49:22.664048 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.848359
I0621 17:49:22.664243 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.540211 (* 1 = 0.540211 loss)
I0621 17:49:25.147922 17898 solver.cpp:228] Iteration 68400, loss = 0.088297
I0621 17:49:25.147970 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0882968 (* 1 = 0.0882968 loss)
I0621 17:49:25.147982 17898 sgd_solver.cpp:106] Iteration 68400, lr = 0.1
I0621 18:06:10.424131 17898 solver.cpp:337] Iteration 68800, Testing net (#0)
I0621 18:07:13.906610 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.810625
I0621 18:07:13.906770 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.732262 (* 1 = 0.732262 loss)
I0621 18:07:16.377068 17898 solver.cpp:228] Iteration 68800, loss = 0.103662
I0621 18:07:16.377123 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103662 (* 1 = 0.103662 loss)
I0621 18:07:16.377136 17898 sgd_solver.cpp:106] Iteration 68800, lr = 0.1
I0621 18:24:01.695992 17898 solver.cpp:337] Iteration 69200, Testing net (#0)
I0621 18:25:05.044078 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.767031
I0621 18:25:05.044286 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.877545 (* 1 = 0.877545 loss)
I0621 18:25:07.521255 17898 solver.cpp:228] Iteration 69200, loss = 0.103172
I0621 18:25:07.521311 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103172 (* 1 = 0.103172 loss)
I0621 18:25:07.521327 17898 sgd_solver.cpp:106] Iteration 69200, lr = 0.1
I0621 18:41:52.691287 17898 solver.cpp:337] Iteration 69600, Testing net (#0)
I0621 18:42:56.098175 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.699453
I0621 18:42:56.098322 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.20266 (* 1 = 1.20266 loss)
I0621 18:42:58.576144 17898 solver.cpp:228] Iteration 69600, loss = 0.0601272
I0621 18:42:58.576203 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.060127 (* 1 = 0.060127 loss)
I0621 18:42:58.576216 17898 sgd_solver.cpp:106] Iteration 69600, lr = 0.1
I0621 18:59:43.391194 17898 solver.cpp:337] Iteration 70000, Testing net (#0)
I0621 19:00:46.630133 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.779297
I0621 19:00:46.630319 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.986675 (* 1 = 0.986675 loss)
I0621 19:00:49.103979 17898 solver.cpp:228] Iteration 70000, loss = 0.0678376
I0621 19:00:49.104050 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0678373 (* 1 = 0.0678373 loss)
I0621 19:00:49.104087 17898 sgd_solver.cpp:106] Iteration 70000, lr = 0.1
I0621 19:17:34.351995 17898 solver.cpp:337] Iteration 70400, Testing net (#0)
I0621 19:18:37.688637 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.766484
I0621 19:18:37.688854 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.993786 (* 1 = 0.993786 loss)
I0621 19:18:40.176265 17898 solver.cpp:228] Iteration 70400, loss = 0.151437
I0621 19:18:40.176319 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.151436 (* 1 = 0.151436 loss)
I0621 19:18:40.176332 17898 sgd_solver.cpp:106] Iteration 70400, lr = 0.1
I0621 19:35:25.325309 17898 solver.cpp:337] Iteration 70800, Testing net (#0)
I0621 19:36:28.748013 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.805156
I0621 19:36:28.748198 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.689959 (* 1 = 0.689959 loss)
I0621 19:36:31.222160 17898 solver.cpp:228] Iteration 70800, loss = 0.070914
I0621 19:36:31.222193 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0709138 (* 1 = 0.0709138 loss)
I0621 19:36:31.222205 17898 sgd_solver.cpp:106] Iteration 70800, lr = 0.1
I0621 19:53:16.183924 17898 solver.cpp:337] Iteration 71200, Testing net (#0)
I0621 19:54:19.612902 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.828828
I0621 19:54:19.613028 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.644435 (* 1 = 0.644435 loss)
I0621 19:54:22.089869 17898 solver.cpp:228] Iteration 71200, loss = 0.126326
I0621 19:54:22.089915 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.126326 (* 1 = 0.126326 loss)
I0621 19:54:22.089928 17898 sgd_solver.cpp:106] Iteration 71200, lr = 0.1
I0621 20:11:07.502802 17898 solver.cpp:337] Iteration 71600, Testing net (#0)
I0621 20:12:10.928462 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.797266
I0621 20:12:10.928599 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.787054 (* 1 = 0.787054 loss)
I0621 20:12:13.408996 17898 solver.cpp:228] Iteration 71600, loss = 0.116587
I0621 20:12:13.409036 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.116587 (* 1 = 0.116587 loss)
I0621 20:12:13.409049 17898 sgd_solver.cpp:106] Iteration 71600, lr = 0.1
I0621 20:28:58.757521 17898 solver.cpp:337] Iteration 72000, Testing net (#0)
I0621 20:30:02.131404 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.823125
I0621 20:30:02.131563 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.639231 (* 1 = 0.639231 loss)
I0621 20:30:04.607497 17898 solver.cpp:228] Iteration 72000, loss = 0.190281
I0621 20:30:04.607578 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190281 (* 1 = 0.190281 loss)
I0621 20:30:04.607590 17898 sgd_solver.cpp:106] Iteration 72000, lr = 0.1
I0621 20:46:49.647531 17898 solver.cpp:337] Iteration 72400, Testing net (#0)
I0621 20:47:53.077813 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.749844
I0621 20:47:53.078014 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.13025 (* 1 = 1.13025 loss)
I0621 20:47:55.546675 17898 solver.cpp:228] Iteration 72400, loss = 0.161473
I0621 20:47:55.546748 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.161473 (* 1 = 0.161473 loss)
I0621 20:47:55.546761 17898 sgd_solver.cpp:106] Iteration 72400, lr = 0.1
I0621 21:04:40.938803 17898 solver.cpp:337] Iteration 72800, Testing net (#0)
I0621 21:05:44.335958 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.816875
I0621 21:05:44.336174 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.811103 (* 1 = 0.811103 loss)
I0621 21:05:46.807687 17898 solver.cpp:228] Iteration 72800, loss = 0.160796
I0621 21:05:46.807739 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.160796 (* 1 = 0.160796 loss)
I0621 21:05:46.807754 17898 sgd_solver.cpp:106] Iteration 72800, lr = 0.1
I0621 21:22:32.260496 17898 solver.cpp:337] Iteration 73200, Testing net (#0)
I0621 21:23:35.603049 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.774688
I0621 21:23:35.603237 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.79647 (* 1 = 0.79647 loss)
I0621 21:23:38.082979 17898 solver.cpp:228] Iteration 73200, loss = 0.121088
I0621 21:23:38.083029 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121088 (* 1 = 0.121088 loss)
I0621 21:23:38.083041 17898 sgd_solver.cpp:106] Iteration 73200, lr = 0.1
I0621 21:40:23.388451 17898 solver.cpp:337] Iteration 73600, Testing net (#0)
I0621 21:41:26.660619 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.796172
I0621 21:41:26.660821 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.724111 (* 1 = 0.724111 loss)
I0621 21:41:29.157064 17898 solver.cpp:228] Iteration 73600, loss = 0.069066
I0621 21:41:29.157114 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0690657 (* 1 = 0.0690657 loss)
I0621 21:41:29.157125 17898 sgd_solver.cpp:106] Iteration 73600, lr = 0.1
I0621 21:58:13.886801 17898 solver.cpp:337] Iteration 74000, Testing net (#0)
I0621 21:59:17.242372 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.807422
I0621 21:59:17.242590 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.748054 (* 1 = 0.748054 loss)
I0621 21:59:19.717985 17898 solver.cpp:228] Iteration 74000, loss = 0.0700856
I0621 21:59:19.718039 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0700854 (* 1 = 0.0700854 loss)
I0621 21:59:19.718052 17898 sgd_solver.cpp:106] Iteration 74000, lr = 0.1
I0621 22:16:04.886937 17898 solver.cpp:337] Iteration 74400, Testing net (#0)
I0621 22:17:08.263926 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.804141
I0621 22:17:08.264152 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.742833 (* 1 = 0.742833 loss)
I0621 22:17:10.751672 17898 solver.cpp:228] Iteration 74400, loss = 0.0462339
I0621 22:17:10.751730 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0462336 (* 1 = 0.0462336 loss)
I0621 22:17:10.751741 17898 sgd_solver.cpp:106] Iteration 74400, lr = 0.1
I0621 22:33:56.020141 17898 solver.cpp:337] Iteration 74800, Testing net (#0)
I0621 22:34:59.486207 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.800313
I0621 22:34:59.486438 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.690543 (* 1 = 0.690543 loss)
I0621 22:35:01.976258 17898 solver.cpp:228] Iteration 74800, loss = 0.0820948
I0621 22:35:01.976332 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0820945 (* 1 = 0.0820945 loss)
I0621 22:35:01.976349 17898 sgd_solver.cpp:106] Iteration 74800, lr = 0.1
I0621 22:51:46.805274 17898 solver.cpp:337] Iteration 75200, Testing net (#0)
I0621 22:52:50.252825 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.744922
I0621 22:52:50.253041 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.995721 (* 1 = 0.995721 loss)
I0621 22:52:52.726361 17898 solver.cpp:228] Iteration 75200, loss = 0.149902
I0621 22:52:52.726404 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149902 (* 1 = 0.149902 loss)
I0621 22:52:52.726418 17898 sgd_solver.cpp:106] Iteration 75200, lr = 0.1
I0621 23:09:37.869169 17898 solver.cpp:337] Iteration 75600, Testing net (#0)
I0621 23:10:41.273843 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.825156
I0621 23:10:41.274057 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.604183 (* 1 = 0.604183 loss)
I0621 23:10:43.748390 17898 solver.cpp:228] Iteration 75600, loss = 0.112415
I0621 23:10:43.748459 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.112415 (* 1 = 0.112415 loss)
I0621 23:10:43.748472 17898 sgd_solver.cpp:106] Iteration 75600, lr = 0.1
I0621 23:27:29.110716 17898 solver.cpp:337] Iteration 76000, Testing net (#0)
I0621 23:28:32.653698 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.716641
I0621 23:28:32.653908 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.46722 (* 1 = 1.46722 loss)
I0621 23:28:35.129395 17898 solver.cpp:228] Iteration 76000, loss = 0.0657996
I0621 23:28:35.129463 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0657994 (* 1 = 0.0657994 loss)
I0621 23:28:35.129484 17898 sgd_solver.cpp:106] Iteration 76000, lr = 0.1
I0621 23:45:20.635977 17898 solver.cpp:337] Iteration 76400, Testing net (#0)
I0621 23:46:24.033679 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.803516
I0621 23:46:24.033906 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.864101 (* 1 = 0.864101 loss)
I0621 23:46:26.515774 17898 solver.cpp:228] Iteration 76400, loss = 0.0981074
I0621 23:46:26.515866 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0981072 (* 1 = 0.0981072 loss)
I0621 23:46:26.515880 17898 sgd_solver.cpp:106] Iteration 76400, lr = 0.1
I0622 00:03:12.053946 17898 solver.cpp:337] Iteration 76800, Testing net (#0)
I0622 00:04:15.474550 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.739922
I0622 00:04:15.474779 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.15935 (* 1 = 1.15935 loss)
I0622 00:04:17.954661 17898 solver.cpp:228] Iteration 76800, loss = 0.0825373
I0622 00:04:17.954720 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0825371 (* 1 = 0.0825371 loss)
I0622 00:04:17.954731 17898 sgd_solver.cpp:106] Iteration 76800, lr = 0.1
I0622 00:21:02.940984 17898 solver.cpp:337] Iteration 77200, Testing net (#0)
I0622 00:22:06.345437 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.816406
I0622 00:22:06.345614 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.688008 (* 1 = 0.688008 loss)
I0622 00:22:08.819891 17898 solver.cpp:228] Iteration 77200, loss = 0.149339
I0622 00:22:08.819955 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.149339 (* 1 = 0.149339 loss)
I0622 00:22:08.819969 17898 sgd_solver.cpp:106] Iteration 77200, lr = 0.1
I0622 00:38:54.139876 17898 solver.cpp:337] Iteration 77600, Testing net (#0)
I0622 00:39:57.525507 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.825859
I0622 00:39:57.525650 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.588163 (* 1 = 0.588163 loss)
I0622 00:40:00.016813 17898 solver.cpp:228] Iteration 77600, loss = 0.155138
I0622 00:40:00.016856 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.155137 (* 1 = 0.155137 loss)
I0622 00:40:00.016870 17898 sgd_solver.cpp:106] Iteration 77600, lr = 0.1
I0622 00:56:45.279382 17898 solver.cpp:337] Iteration 78000, Testing net (#0)
I0622 00:57:48.669096 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.665937
I0622 00:57:48.669327 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.71412 (* 1 = 1.71412 loss)
I0622 00:57:51.145068 17898 solver.cpp:228] Iteration 78000, loss = 0.105337
I0622 00:57:51.145128 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.105336 (* 1 = 0.105336 loss)
I0622 00:57:51.145141 17898 sgd_solver.cpp:106] Iteration 78000, lr = 0.1
I0622 01:14:36.411417 17898 solver.cpp:337] Iteration 78400, Testing net (#0)
I0622 01:15:39.840353 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.785469
I0622 01:15:39.840497 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.718871 (* 1 = 0.718871 loss)
I0622 01:15:42.314055 17898 solver.cpp:228] Iteration 78400, loss = 0.172992
I0622 01:15:42.314095 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172991 (* 1 = 0.172991 loss)
I0622 01:15:42.314107 17898 sgd_solver.cpp:106] Iteration 78400, lr = 0.1
I0622 01:32:26.713527 17898 solver.cpp:337] Iteration 78800, Testing net (#0)
I0622 01:33:30.007097 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.747109
I0622 01:33:30.007302 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.917264 (* 1 = 0.917264 loss)
I0622 01:33:32.480373 17898 solver.cpp:228] Iteration 78800, loss = 0.157905
I0622 01:33:32.480417 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.157905 (* 1 = 0.157905 loss)
I0622 01:33:32.480429 17898 sgd_solver.cpp:106] Iteration 78800, lr = 0.1
I0622 01:50:16.627717 17898 solver.cpp:337] Iteration 79200, Testing net (#0)
I0622 01:51:19.865264 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.800859
I0622 01:51:19.865460 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.721962 (* 1 = 0.721962 loss)
I0622 01:51:22.345826 17898 solver.cpp:228] Iteration 79200, loss = 0.115997
I0622 01:51:22.345875 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.115996 (* 1 = 0.115996 loss)
I0622 01:51:22.345887 17898 sgd_solver.cpp:106] Iteration 79200, lr = 0.1
I0622 02:08:06.907222 17898 solver.cpp:337] Iteration 79600, Testing net (#0)
I0622 02:09:10.171288 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.763906
I0622 02:09:10.182466 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.941576 (* 1 = 0.941576 loss)
I0622 02:09:12.655930 17898 solver.cpp:228] Iteration 79600, loss = 0.0931716
I0622 02:09:12.655972 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0931714 (* 1 = 0.0931714 loss)
I0622 02:09:12.655985 17898 sgd_solver.cpp:106] Iteration 79600, lr = 0.1
I0622 02:25:56.849094 17898 solver.cpp:337] Iteration 80000, Testing net (#0)
I0622 02:27:00.117317 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.815469
I0622 02:27:00.117462 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.694624 (* 1 = 0.694624 loss)
I0622 02:27:02.594601 17898 solver.cpp:228] Iteration 80000, loss = 0.0555192
I0622 02:27:02.594655 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0555191 (* 1 = 0.0555191 loss)
I0622 02:27:02.594667 17898 sgd_solver.cpp:106] Iteration 80000, lr = 0.1
I0622 02:43:47.662719 17898 solver.cpp:337] Iteration 80400, Testing net (#0)
I0622 02:44:51.066959 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.816641
I0622 02:44:51.067090 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.692014 (* 1 = 0.692014 loss)
I0622 02:44:53.542573 17898 solver.cpp:228] Iteration 80400, loss = 0.116143
I0622 02:44:53.542614 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.116143 (* 1 = 0.116143 loss)
I0622 02:44:53.542634 17898 sgd_solver.cpp:106] Iteration 80400, lr = 0.1
I0622 03:01:38.684937 17898 solver.cpp:337] Iteration 80800, Testing net (#0)
I0622 03:02:42.039253 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.751562
I0622 03:02:42.039458 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.850082 (* 1 = 0.850082 loss)
I0622 03:02:44.509485 17898 solver.cpp:228] Iteration 80800, loss = 0.107872
I0622 03:02:44.509537 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.107872 (* 1 = 0.107872 loss)
I0622 03:02:44.509551 17898 sgd_solver.cpp:106] Iteration 80800, lr = 0.1
I0622 03:19:29.426024 17898 solver.cpp:337] Iteration 81200, Testing net (#0)
I0622 03:20:32.746903 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.825938
I0622 03:20:32.747102 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.649743 (* 1 = 0.649743 loss)
I0622 03:20:35.217051 17898 solver.cpp:228] Iteration 81200, loss = 0.173286
I0622 03:20:35.217098 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173286 (* 1 = 0.173286 loss)
I0622 03:20:35.217123 17898 sgd_solver.cpp:106] Iteration 81200, lr = 0.1
I0622 03:37:20.078773 17898 solver.cpp:337] Iteration 81600, Testing net (#0)
I0622 03:38:23.450932 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.775781
I0622 03:38:23.451119 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.859018 (* 1 = 0.859018 loss)
I0622 03:38:25.921782 17898 solver.cpp:228] Iteration 81600, loss = 0.112889
I0622 03:38:25.921836 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.112889 (* 1 = 0.112889 loss)
I0622 03:38:25.921856 17898 sgd_solver.cpp:106] Iteration 81600, lr = 0.1
I0622 03:55:10.216357 17898 solver.cpp:337] Iteration 82000, Testing net (#0)
I0622 03:56:13.625182 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.749453
I0622 03:56:13.625373 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.1121 (* 1 = 1.1121 loss)
I0622 03:56:16.095660 17898 solver.cpp:228] Iteration 82000, loss = 0.142692
I0622 03:56:16.095705 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142692 (* 1 = 0.142692 loss)
I0622 03:56:16.095715 17898 sgd_solver.cpp:106] Iteration 82000, lr = 0.1
I0622 04:13:00.428166 17898 solver.cpp:337] Iteration 82400, Testing net (#0)
I0622 04:14:03.760782 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.810078
I0622 04:14:03.760933 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.686632 (* 1 = 0.686632 loss)
I0622 04:14:06.262871 17898 solver.cpp:228] Iteration 82400, loss = 0.180002
I0622 04:14:06.262943 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.180002 (* 1 = 0.180002 loss)
I0622 04:14:06.262954 17898 sgd_solver.cpp:106] Iteration 82400, lr = 0.1
I0622 04:30:51.763062 17898 solver.cpp:337] Iteration 82800, Testing net (#0)
I0622 04:31:55.205291 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.722031
I0622 04:31:55.205529 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.18343 (* 1 = 1.18343 loss)
I0622 04:31:57.681828 17898 solver.cpp:228] Iteration 82800, loss = 0.075016
I0622 04:31:57.681874 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.075016 (* 1 = 0.075016 loss)
I0622 04:31:57.681888 17898 sgd_solver.cpp:106] Iteration 82800, lr = 0.1
I0622 04:48:43.102720 17898 solver.cpp:337] Iteration 83200, Testing net (#0)
I0622 04:49:46.579753 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.848906
I0622 04:49:46.579939 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.551601 (* 1 = 0.551601 loss)
I0622 04:49:49.049384 17898 solver.cpp:228] Iteration 83200, loss = 0.130519
I0622 04:49:49.049451 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.130519 (* 1 = 0.130519 loss)
I0622 04:49:49.049466 17898 sgd_solver.cpp:106] Iteration 83200, lr = 0.1
I0622 05:06:34.261338 17898 solver.cpp:337] Iteration 83600, Testing net (#0)
I0622 05:07:37.571712 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.804297
I0622 05:07:37.571957 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.661704 (* 1 = 0.661704 loss)
I0622 05:07:40.053011 17898 solver.cpp:228] Iteration 83600, loss = 0.0753384
I0622 05:07:40.053056 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0753383 (* 1 = 0.0753383 loss)
I0622 05:07:40.053067 17898 sgd_solver.cpp:106] Iteration 83600, lr = 0.1
I0622 05:24:24.812422 17898 solver.cpp:337] Iteration 84000, Testing net (#0)
I0622 05:25:28.169821 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.709063
I0622 05:25:28.169998 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.34588 (* 1 = 1.34588 loss)
I0622 05:25:30.647204 17898 solver.cpp:228] Iteration 84000, loss = 0.146067
I0622 05:25:30.647267 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.146067 (* 1 = 0.146067 loss)
I0622 05:25:30.647280 17898 sgd_solver.cpp:106] Iteration 84000, lr = 0.1
I0622 05:42:15.835899 17898 solver.cpp:337] Iteration 84400, Testing net (#0)
I0622 05:43:19.295747 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.780391
I0622 05:43:19.295928 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.743185 (* 1 = 0.743185 loss)
I0622 05:43:21.777336 17898 solver.cpp:228] Iteration 84400, loss = 0.182099
I0622 05:43:21.777401 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.182099 (* 1 = 0.182099 loss)
I0622 05:43:21.777415 17898 sgd_solver.cpp:106] Iteration 84400, lr = 0.1
I0622 06:00:06.986502 17898 solver.cpp:337] Iteration 84800, Testing net (#0)
I0622 06:01:10.309545 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.832734
I0622 06:01:10.309677 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.634533 (* 1 = 0.634533 loss)
I0622 06:01:12.787333 17898 solver.cpp:228] Iteration 84800, loss = 0.13284
I0622 06:01:12.787395 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.13284 (* 1 = 0.13284 loss)
I0622 06:01:12.787406 17898 sgd_solver.cpp:106] Iteration 84800, lr = 0.1
I0622 06:17:58.277981 17898 solver.cpp:337] Iteration 85200, Testing net (#0)
I0622 06:19:01.496063 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.793281
I0622 06:19:01.496263 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.747131 (* 1 = 0.747131 loss)
I0622 06:19:03.972898 17898 solver.cpp:228] Iteration 85200, loss = 0.142276
I0622 06:19:03.972952 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.142276 (* 1 = 0.142276 loss)
I0622 06:19:03.972970 17898 sgd_solver.cpp:106] Iteration 85200, lr = 0.1
I0622 06:35:48.979957 17898 solver.cpp:337] Iteration 85600, Testing net (#0)
I0622 06:36:52.458070 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.813984
I0622 06:36:52.458305 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.665303 (* 1 = 0.665303 loss)
I0622 06:36:54.933704 17898 solver.cpp:228] Iteration 85600, loss = 0.136799
I0622 06:36:54.933745 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136799 (* 1 = 0.136799 loss)
I0622 06:36:54.933756 17898 sgd_solver.cpp:106] Iteration 85600, lr = 0.1
I0622 06:53:40.224671 17898 solver.cpp:337] Iteration 86000, Testing net (#0)
I0622 06:54:43.592140 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.757578
I0622 06:54:43.592384 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.07638 (* 1 = 1.07638 loss)
I0622 06:54:46.060843 17898 solver.cpp:228] Iteration 86000, loss = 0.127226
I0622 06:54:46.060904 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127226 (* 1 = 0.127226 loss)
I0622 06:54:46.060915 17898 sgd_solver.cpp:106] Iteration 86000, lr = 0.1
I0622 07:11:31.269305 17898 solver.cpp:337] Iteration 86400, Testing net (#0)
I0622 07:12:34.691659 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.793906
I0622 07:12:34.691861 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.829756 (* 1 = 0.829756 loss)
I0622 07:12:37.177083 17898 solver.cpp:228] Iteration 86400, loss = 0.10369
I0622 07:12:37.177134 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.10369 (* 1 = 0.10369 loss)
I0622 07:12:37.177147 17898 sgd_solver.cpp:106] Iteration 86400, lr = 0.1
I0622 07:29:22.498641 17898 solver.cpp:337] Iteration 86800, Testing net (#0)
I0622 07:30:25.882545 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.818359
I0622 07:30:25.882771 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.617576 (* 1 = 0.617576 loss)
I0622 07:30:28.361980 17898 solver.cpp:228] Iteration 86800, loss = 0.206295
I0622 07:30:28.362022 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.206295 (* 1 = 0.206295 loss)
I0622 07:30:28.362035 17898 sgd_solver.cpp:106] Iteration 86800, lr = 0.1
I0622 07:47:13.652087 17898 solver.cpp:337] Iteration 87200, Testing net (#0)
I0622 07:48:17.107182 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.828281
I0622 07:48:17.107375 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.586098 (* 1 = 0.586098 loss)
I0622 07:48:19.593416 17898 solver.cpp:228] Iteration 87200, loss = 0.0945476
I0622 07:48:19.593449 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0945476 (* 1 = 0.0945476 loss)
I0622 07:48:19.593463 17898 sgd_solver.cpp:106] Iteration 87200, lr = 0.1
I0622 08:05:04.830935 17898 solver.cpp:337] Iteration 87600, Testing net (#0)
I0622 08:06:08.109076 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.763828
I0622 08:06:08.109277 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.912173 (* 1 = 0.912173 loss)
I0622 08:06:10.593406 17898 solver.cpp:228] Iteration 87600, loss = 0.0770496
I0622 08:06:10.593493 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0770496 (* 1 = 0.0770496 loss)
I0622 08:06:10.593513 17898 sgd_solver.cpp:106] Iteration 87600, lr = 0.1
I0622 08:22:55.945943 17898 solver.cpp:337] Iteration 88000, Testing net (#0)
I0622 08:23:59.397085 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.752969
I0622 08:23:59.397318 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.953411 (* 1 = 0.953411 loss)
I0622 08:24:01.865510 17898 solver.cpp:228] Iteration 88000, loss = 0.092449
I0622 08:24:01.865572 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.092449 (* 1 = 0.092449 loss)
I0622 08:24:01.865586 17898 sgd_solver.cpp:106] Iteration 88000, lr = 0.1
I0622 08:40:46.995970 17898 solver.cpp:337] Iteration 88400, Testing net (#0)
I0622 08:41:50.461699 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.823281
I0622 08:41:50.461918 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.564613 (* 1 = 0.564613 loss)
I0622 08:41:52.934068 17898 solver.cpp:228] Iteration 88400, loss = 0.143452
I0622 08:41:52.934099 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143452 (* 1 = 0.143452 loss)
I0622 08:41:52.934113 17898 sgd_solver.cpp:106] Iteration 88400, lr = 0.1
I0622 08:58:38.066599 17898 solver.cpp:337] Iteration 88800, Testing net (#0)
I0622 08:59:41.441934 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.753672
I0622 08:59:41.442153 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.10296 (* 1 = 1.10296 loss)
I0622 08:59:43.909765 17898 solver.cpp:228] Iteration 88800, loss = 0.1483
I0622 08:59:43.909813 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.1483 (* 1 = 0.1483 loss)
I0622 08:59:43.909826 17898 sgd_solver.cpp:106] Iteration 88800, lr = 0.1
I0622 09:16:28.641777 17898 solver.cpp:337] Iteration 89200, Testing net (#0)
I0622 09:17:32.128446 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.686484
I0622 09:17:32.128654 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.17605 (* 1 = 1.17605 loss)
I0622 09:17:34.604010 17898 solver.cpp:228] Iteration 89200, loss = 0.271524
I0622 09:17:34.604074 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.271524 (* 1 = 0.271524 loss)
I0622 09:17:34.604085 17898 sgd_solver.cpp:106] Iteration 89200, lr = 0.1
I0622 09:34:19.368659 17898 solver.cpp:337] Iteration 89600, Testing net (#0)
I0622 09:35:22.850126 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.813984
I0622 09:35:22.850303 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.695971 (* 1 = 0.695971 loss)
I0622 09:35:25.333748 17898 solver.cpp:228] Iteration 89600, loss = 0.0545337
I0622 09:35:25.333797 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0545338 (* 1 = 0.0545338 loss)
I0622 09:35:25.333811 17898 sgd_solver.cpp:106] Iteration 89600, lr = 0.1
I0622 09:52:10.654654 17898 solver.cpp:337] Iteration 90000, Testing net (#0)
I0622 09:53:14.019860 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.823438
I0622 09:53:14.020001 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.761858 (* 1 = 0.761858 loss)
I0622 09:53:16.492754 17898 solver.cpp:228] Iteration 90000, loss = 0.0669582
I0622 09:53:16.492807 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0669582 (* 1 = 0.0669582 loss)
I0622 09:53:16.492822 17898 sgd_solver.cpp:106] Iteration 90000, lr = 0.1
I0622 10:10:01.545321 17898 solver.cpp:337] Iteration 90400, Testing net (#0)
I0622 10:11:04.921459 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.803672
I0622 10:11:04.921612 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.739489 (* 1 = 0.739489 loss)
I0622 10:11:07.401890 17898 solver.cpp:228] Iteration 90400, loss = 0.0946545
I0622 10:11:07.401965 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0946546 (* 1 = 0.0946546 loss)
I0622 10:11:07.401980 17898 sgd_solver.cpp:106] Iteration 90400, lr = 0.1
I0622 10:27:52.395380 17898 solver.cpp:337] Iteration 90800, Testing net (#0)
I0622 10:28:55.865959 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.807891
I0622 10:28:55.866181 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.774 (* 1 = 0.774 loss)
I0622 10:28:58.338021 17898 solver.cpp:228] Iteration 90800, loss = 0.129551
I0622 10:28:58.338073 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.129551 (* 1 = 0.129551 loss)
I0622 10:28:58.338084 17898 sgd_solver.cpp:106] Iteration 90800, lr = 0.1
I0622 10:45:43.771067 17898 solver.cpp:337] Iteration 91200, Testing net (#0)
I0622 10:46:47.278995 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.833594
I0622 10:46:47.279227 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.614245 (* 1 = 0.614245 loss)
I0622 10:46:49.751960 17898 solver.cpp:228] Iteration 91200, loss = 0.0853223
I0622 10:46:49.752007 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0853224 (* 1 = 0.0853224 loss)
I0622 10:46:49.752018 17898 sgd_solver.cpp:106] Iteration 91200, lr = 0.1
I0622 11:03:34.704906 17898 solver.cpp:337] Iteration 91600, Testing net (#0)
I0622 11:04:38.001452 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.802891
I0622 11:04:38.001677 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.693353 (* 1 = 0.693353 loss)
I0622 11:04:40.475240 17898 solver.cpp:228] Iteration 91600, loss = 0.104044
I0622 11:04:40.475298 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.104044 (* 1 = 0.104044 loss)
I0622 11:04:40.475312 17898 sgd_solver.cpp:106] Iteration 91600, lr = 0.1
I0622 11:21:25.766434 17898 solver.cpp:337] Iteration 92000, Testing net (#0)
I0622 11:22:29.217041 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.742422
I0622 11:22:29.217285 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.06219 (* 1 = 1.06219 loss)
I0622 11:22:31.691264 17898 solver.cpp:228] Iteration 92000, loss = 0.0526573
I0622 11:22:31.691329 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0526574 (* 1 = 0.0526574 loss)
I0622 11:22:31.691342 17898 sgd_solver.cpp:106] Iteration 92000, lr = 0.1
I0622 11:39:16.890724 17898 solver.cpp:337] Iteration 92400, Testing net (#0)
I0622 11:40:20.356338 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.789609
I0622 11:40:20.356470 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.870179 (* 1 = 0.870179 loss)
I0622 11:40:22.836449 17898 solver.cpp:228] Iteration 92400, loss = 0.121409
I0622 11:40:22.836489 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121409 (* 1 = 0.121409 loss)
I0622 11:40:22.836503 17898 sgd_solver.cpp:106] Iteration 92400, lr = 0.1
I0622 11:57:08.209611 17898 solver.cpp:337] Iteration 92800, Testing net (#0)
I0622 11:58:11.723917 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.798047
I0622 11:58:11.724148 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.75278 (* 1 = 0.75278 loss)
I0622 11:58:14.198104 17898 solver.cpp:228] Iteration 92800, loss = 0.0685266
I0622 11:58:14.198155 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0685267 (* 1 = 0.0685267 loss)
I0622 11:58:14.198168 17898 sgd_solver.cpp:106] Iteration 92800, lr = 0.1
I0622 12:14:59.630944 17898 solver.cpp:337] Iteration 93200, Testing net (#0)
I0622 12:16:02.981039 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.792109
I0622 12:16:02.981179 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.856369 (* 1 = 0.856369 loss)
I0622 12:16:05.458178 17898 solver.cpp:228] Iteration 93200, loss = 0.0986955
I0622 12:16:05.458225 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0986956 (* 1 = 0.0986956 loss)
I0622 12:16:05.458236 17898 sgd_solver.cpp:106] Iteration 93200, lr = 0.1
I0622 12:32:50.617213 17898 solver.cpp:337] Iteration 93600, Testing net (#0)
I0622 12:33:53.998946 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.782656
I0622 12:33:53.999110 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.894946 (* 1 = 0.894946 loss)
I0622 12:33:56.480075 17898 solver.cpp:228] Iteration 93600, loss = 0.200623
I0622 12:33:56.480135 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.200623 (* 1 = 0.200623 loss)
I0622 12:33:56.480150 17898 sgd_solver.cpp:106] Iteration 93600, lr = 0.1
I0622 12:50:42.005506 17898 solver.cpp:337] Iteration 94000, Testing net (#0)
I0622 12:51:45.434990 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.807734
I0622 12:51:45.435166 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.759212 (* 1 = 0.759212 loss)
I0622 12:51:47.911342 17898 solver.cpp:228] Iteration 94000, loss = 0.141147
I0622 12:51:47.911407 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.141148 (* 1 = 0.141148 loss)
I0622 12:51:47.911432 17898 sgd_solver.cpp:106] Iteration 94000, lr = 0.1
I0622 13:08:33.314327 17898 solver.cpp:337] Iteration 94400, Testing net (#0)
I0622 13:09:36.761488 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.801328
I0622 13:09:36.761682 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.758097 (* 1 = 0.758097 loss)
I0622 13:09:39.249804 17898 solver.cpp:228] Iteration 94400, loss = 0.177156
I0622 13:09:39.249843 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.177156 (* 1 = 0.177156 loss)
I0622 13:09:39.249866 17898 sgd_solver.cpp:106] Iteration 94400, lr = 0.1
I0622 13:26:24.993147 17898 solver.cpp:337] Iteration 94800, Testing net (#0)
I0622 13:27:28.382208 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.650312
I0622 13:27:28.382339 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.52612 (* 1 = 1.52612 loss)
I0622 13:27:30.857362 17898 solver.cpp:228] Iteration 94800, loss = 0.136706
I0622 13:27:30.857408 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.136706 (* 1 = 0.136706 loss)
I0622 13:27:30.857422 17898 sgd_solver.cpp:106] Iteration 94800, lr = 0.1
I0622 13:44:16.027413 17898 solver.cpp:337] Iteration 95200, Testing net (#0)
I0622 13:45:19.431735 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.772031
I0622 13:45:19.431962 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.96338 (* 1 = 0.96338 loss)
I0622 13:45:21.907727 17898 solver.cpp:228] Iteration 95200, loss = 0.139026
I0622 13:45:21.907886 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139026 (* 1 = 0.139026 loss)
I0622 13:45:21.907903 17898 sgd_solver.cpp:106] Iteration 95200, lr = 0.1
I0622 14:02:07.326895 17898 solver.cpp:337] Iteration 95600, Testing net (#0)
I0622 14:03:10.709924 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.737734
I0622 14:03:10.710111 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.01301 (* 1 = 1.01301 loss)
I0622 14:03:13.191545 17898 solver.cpp:228] Iteration 95600, loss = 0.153398
I0622 14:03:13.191608 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.153398 (* 1 = 0.153398 loss)
I0622 14:03:13.191622 17898 sgd_solver.cpp:106] Iteration 95600, lr = 0.1
I0622 14:19:58.653792 17898 solver.cpp:337] Iteration 96000, Testing net (#0)
I0622 14:21:02.045485 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.746875
I0622 14:21:02.045629 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.17348 (* 1 = 1.17348 loss)
I0622 14:21:04.537811 17898 solver.cpp:228] Iteration 96000, loss = 0.116633
I0622 14:21:04.537854 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.116633 (* 1 = 0.116633 loss)
I0622 14:21:04.537868 17898 sgd_solver.cpp:106] Iteration 96000, lr = 0.1
I0622 14:37:49.983554 17898 solver.cpp:337] Iteration 96400, Testing net (#0)
I0622 14:38:53.376554 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.837656
I0622 14:38:53.376765 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.596177 (* 1 = 0.596177 loss)
I0622 14:38:55.853746 17898 solver.cpp:228] Iteration 96400, loss = 0.0887786
I0622 14:38:55.853803 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0887788 (* 1 = 0.0887788 loss)
I0622 14:38:55.853817 17898 sgd_solver.cpp:106] Iteration 96400, lr = 0.1
I0622 14:55:39.978267 17898 solver.cpp:337] Iteration 96800, Testing net (#0)
I0622 14:56:43.506839 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.813984
I0622 14:56:43.507025 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.690733 (* 1 = 0.690733 loss)
I0622 14:56:46.006072 17898 solver.cpp:228] Iteration 96800, loss = 0.172617
I0622 14:56:46.006124 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.172617 (* 1 = 0.172617 loss)
I0622 14:56:46.006147 17898 sgd_solver.cpp:106] Iteration 96800, lr = 0.1
I0622 15:13:31.369762 17898 solver.cpp:337] Iteration 97200, Testing net (#0)
I0622 15:14:34.828515 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.742031
I0622 15:14:34.828722 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.04181 (* 1 = 1.04181 loss)
I0622 15:14:37.306737 17898 solver.cpp:228] Iteration 97200, loss = 0.111578
I0622 15:14:37.306782 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.111578 (* 1 = 0.111578 loss)
I0622 15:14:37.306792 17898 sgd_solver.cpp:106] Iteration 97200, lr = 0.1
I0622 15:31:21.418258 17898 solver.cpp:337] Iteration 97600, Testing net (#0)
I0622 15:32:24.943904 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.832266
I0622 15:32:24.944068 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.58857 (* 1 = 0.58857 loss)
I0622 15:32:27.419147 17898 solver.cpp:228] Iteration 97600, loss = 0.0966367
I0622 15:32:27.419203 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0966369 (* 1 = 0.0966369 loss)
I0622 15:32:27.419215 17898 sgd_solver.cpp:106] Iteration 97600, lr = 0.1
I0622 15:49:12.664345 17898 solver.cpp:337] Iteration 98000, Testing net (#0)
I0622 15:50:16.143937 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.843828
I0622 15:50:16.144124 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.537112 (* 1 = 0.537112 loss)
I0622 15:50:18.622601 17898 solver.cpp:228] Iteration 98000, loss = 0.13309
I0622 15:50:18.622665 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.13309 (* 1 = 0.13309 loss)
I0622 15:50:18.622679 17898 sgd_solver.cpp:106] Iteration 98000, lr = 0.1
I0622 16:07:03.713066 17898 solver.cpp:337] Iteration 98400, Testing net (#0)
I0622 16:08:07.191112 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.805547
I0622 16:08:07.191275 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.728449 (* 1 = 0.728449 loss)
I0622 16:08:09.663269 17898 solver.cpp:228] Iteration 98400, loss = 0.192203
I0622 16:08:09.663311 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.192203 (* 1 = 0.192203 loss)
I0622 16:08:09.663323 17898 sgd_solver.cpp:106] Iteration 98400, lr = 0.1
I0622 16:24:55.254053 17898 solver.cpp:337] Iteration 98800, Testing net (#0)
I0622 16:25:58.640941 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.817891
I0622 16:25:58.641151 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.64079 (* 1 = 0.64079 loss)
I0622 16:26:01.123507 17898 solver.cpp:228] Iteration 98800, loss = 0.128256
I0622 16:26:01.123567 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.128256 (* 1 = 0.128256 loss)
I0622 16:26:01.123579 17898 sgd_solver.cpp:106] Iteration 98800, lr = 0.1
I0622 16:42:46.507619 17898 solver.cpp:337] Iteration 99200, Testing net (#0)
I0622 16:43:49.965155 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.771328
I0622 16:43:49.965348 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.788055 (* 1 = 0.788055 loss)
I0622 16:43:52.436658 17898 solver.cpp:228] Iteration 99200, loss = 0.127338
I0622 16:43:52.436714 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127338 (* 1 = 0.127338 loss)
I0622 16:43:52.436738 17898 sgd_solver.cpp:106] Iteration 99200, lr = 0.1
I0622 17:00:37.907449 17898 solver.cpp:337] Iteration 99600, Testing net (#0)
I0622 17:01:41.420707 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.816484
I0622 17:01:41.420913 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.753045 (* 1 = 0.753045 loss)
I0622 17:01:43.892997 17898 solver.cpp:228] Iteration 99600, loss = 0.191295
I0622 17:01:43.893033 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.191295 (* 1 = 0.191295 loss)
I0622 17:01:43.893045 17898 sgd_solver.cpp:106] Iteration 99600, lr = 0.1
I0622 17:18:29.148007 17898 solver.cpp:337] Iteration 100000, Testing net (#0)
I0622 17:19:32.611623 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.725
I0622 17:19:32.611799 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 1.06451 (* 1 = 1.06451 loss)
I0622 17:19:35.093053 17898 solver.cpp:228] Iteration 100000, loss = 0.124934
I0622 17:19:35.093109 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.124935 (* 1 = 0.124935 loss)
I0622 17:19:35.093121 17898 sgd_solver.cpp:46] MultiStep Status: Iteration 100000, step = 1
I0622 17:19:35.093127 17898 sgd_solver.cpp:106] Iteration 100000, lr = 0.01
I0622 17:36:20.584566 17898 solver.cpp:337] Iteration 100400, Testing net (#0)
I0622 17:37:23.973443 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.898438
I0622 17:37:23.973654 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.367912 (* 1 = 0.367912 loss)
I0622 17:37:26.452854 17898 solver.cpp:228] Iteration 100400, loss = 0.0524775
I0622 17:37:26.452905 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0524778 (* 1 = 0.0524778 loss)
I0622 17:37:26.452916 17898 sgd_solver.cpp:106] Iteration 100400, lr = 0.01
I0622 17:54:11.041308 17898 solver.cpp:337] Iteration 100800, Testing net (#0)
I0622 17:55:14.431550 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.923437
I0622 17:55:14.431802 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.268633 (* 1 = 0.268633 loss)
I0622 17:55:16.910806 17898 solver.cpp:228] Iteration 100800, loss = 0.0170048
I0622 17:55:16.910856 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0170051 (* 1 = 0.0170051 loss)
I0622 17:55:16.910867 17898 sgd_solver.cpp:106] Iteration 100800, lr = 0.01
I0622 18:12:02.303107 17898 solver.cpp:337] Iteration 101200, Testing net (#0)
I0622 18:13:05.740823 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.923437
I0622 18:13:05.741001 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.281827 (* 1 = 0.281827 loss)
I0622 18:13:08.220978 17898 solver.cpp:228] Iteration 101200, loss = 0.0284736
I0622 18:13:08.221042 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0284739 (* 1 = 0.0284739 loss)
I0622 18:13:08.221056 17898 sgd_solver.cpp:106] Iteration 101200, lr = 0.01
I0622 18:29:53.806862 17898 solver.cpp:337] Iteration 101600, Testing net (#0)
I0622 18:30:57.259677 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.925703
I0622 18:30:57.259857 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.274036 (* 1 = 0.274036 loss)
I0622 18:30:59.733141 17898 solver.cpp:228] Iteration 101600, loss = 0.00585833
I0622 18:30:59.733199 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00585858 (* 1 = 0.00585858 loss)
I0622 18:30:59.733211 17898 sgd_solver.cpp:106] Iteration 101600, lr = 0.01
I0622 18:47:44.239666 17898 solver.cpp:337] Iteration 102000, Testing net (#0)
I0622 18:48:47.668387 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.92875
I0622 18:48:47.668606 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.269446 (* 1 = 0.269446 loss)
I0622 18:48:50.147655 17898 solver.cpp:228] Iteration 102000, loss = 0.0282179
I0622 18:48:50.147711 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0282181 (* 1 = 0.0282181 loss)
I0622 18:48:50.147724 17898 sgd_solver.cpp:106] Iteration 102000, lr = 0.01
I0622 19:05:35.523134 17898 solver.cpp:337] Iteration 102400, Testing net (#0)
I0622 19:06:38.981139 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.928672
I0622 19:06:38.981333 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.263688 (* 1 = 0.263688 loss)
I0622 19:06:41.450309 17898 solver.cpp:228] Iteration 102400, loss = 0.0220995
I0622 19:06:41.450377 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0220998 (* 1 = 0.0220998 loss)
I0622 19:06:41.450392 17898 sgd_solver.cpp:106] Iteration 102400, lr = 0.01
I0622 19:23:27.011713 17898 solver.cpp:337] Iteration 102800, Testing net (#0)
I0622 19:24:30.383632 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.929375
I0622 19:24:30.383800 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.278005 (* 1 = 0.278005 loss)
I0622 19:24:32.864020 17898 solver.cpp:228] Iteration 102800, loss = 0.016661
I0622 19:24:32.864078 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0166613 (* 1 = 0.0166613 loss)
I0622 19:24:32.864096 17898 sgd_solver.cpp:106] Iteration 102800, lr = 0.01
I0622 19:41:18.156267 17898 solver.cpp:337] Iteration 103200, Testing net (#0)
I0622 19:42:21.598767 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.929766
I0622 19:42:21.598908 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.27081 (* 1 = 0.27081 loss)
I0622 19:42:24.075747 17898 solver.cpp:228] Iteration 103200, loss = 0.00505556
I0622 19:42:24.075793 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00505578 (* 1 = 0.00505578 loss)
I0622 19:42:24.075805 17898 sgd_solver.cpp:106] Iteration 103200, lr = 0.01
I0622 19:59:08.909322 17898 solver.cpp:337] Iteration 103600, Testing net (#0)
I0622 20:00:12.223392 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.931172
I0622 20:00:12.223592 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.274168 (* 1 = 0.274168 loss)
I0622 20:00:14.713238 17898 solver.cpp:228] Iteration 103600, loss = 0.0291677
I0622 20:00:14.713289 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0291679 (* 1 = 0.0291679 loss)
I0622 20:00:14.713301 17898 sgd_solver.cpp:106] Iteration 103600, lr = 0.01
I0622 20:17:00.227776 17898 solver.cpp:337] Iteration 104000, Testing net (#0)
I0622 20:18:03.609786 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.933047
I0622 20:18:03.609918 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.273655 (* 1 = 0.273655 loss)
I0622 20:18:06.087249 17898 solver.cpp:228] Iteration 104000, loss = 0.004167
I0622 20:18:06.087311 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00416723 (* 1 = 0.00416723 loss)
I0622 20:18:06.087326 17898 sgd_solver.cpp:106] Iteration 104000, lr = 0.01
I0622 20:34:51.417457 17898 solver.cpp:337] Iteration 104400, Testing net (#0)
I0622 20:35:54.824954 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.929922
I0622 20:35:54.825160 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.289939 (* 1 = 0.289939 loss)
I0622 20:35:57.298498 17898 solver.cpp:228] Iteration 104400, loss = 0.0098271
I0622 20:35:57.298548 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00982732 (* 1 = 0.00982732 loss)
I0622 20:35:57.298560 17898 sgd_solver.cpp:106] Iteration 104400, lr = 0.01
I0622 20:52:41.741075 17898 solver.cpp:337] Iteration 104800, Testing net (#0)
I0622 20:53:45.184725 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.930703
I0622 20:53:45.184841 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.292806 (* 1 = 0.292806 loss)
I0622 20:53:47.662142 17898 solver.cpp:228] Iteration 104800, loss = 0.0289124
I0622 20:53:47.662171 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0289127 (* 1 = 0.0289127 loss)
I0622 20:53:47.662184 17898 sgd_solver.cpp:106] Iteration 104800, lr = 0.01
I0622 21:10:33.214968 17898 solver.cpp:337] Iteration 105200, Testing net (#0)
I0622 21:11:36.497509 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.932031
I0622 21:11:36.497723 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.279465 (* 1 = 0.279465 loss)
I0622 21:11:38.982547 17898 solver.cpp:228] Iteration 105200, loss = 0.00351372
I0622 21:11:38.982597 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00351394 (* 1 = 0.00351394 loss)
I0622 21:11:38.982609 17898 sgd_solver.cpp:106] Iteration 105200, lr = 0.01
I0622 21:28:24.453950 17898 solver.cpp:337] Iteration 105600, Testing net (#0)
I0622 21:29:27.782053 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.934453
I0622 21:29:27.782228 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.280708 (* 1 = 0.280708 loss)
I0622 21:29:30.251793 17898 solver.cpp:228] Iteration 105600, loss = 0.00565019
I0622 21:29:30.251845 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00565042 (* 1 = 0.00565042 loss)
I0622 21:29:30.251860 17898 sgd_solver.cpp:106] Iteration 105600, lr = 0.01
I0622 21:46:15.396858 17898 solver.cpp:337] Iteration 106000, Testing net (#0)
I0622 21:47:18.787149 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.934375
I0622 21:47:18.787349 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.278857 (* 1 = 0.278857 loss)
I0622 21:47:21.267086 17898 solver.cpp:228] Iteration 106000, loss = 0.00771896
I0622 21:47:21.267153 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00771919 (* 1 = 0.00771919 loss)
I0622 21:47:21.267166 17898 sgd_solver.cpp:106] Iteration 106000, lr = 0.01
I0622 22:04:06.608120 17898 solver.cpp:337] Iteration 106400, Testing net (#0)
I0622 22:05:10.044831 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.93375
I0622 22:05:10.045017 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.267961 (* 1 = 0.267961 loss)
I0622 22:05:12.522611 17898 solver.cpp:228] Iteration 106400, loss = 0.00177302
I0622 22:05:12.522661 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00177325 (* 1 = 0.00177325 loss)
I0622 22:05:12.522675 17898 sgd_solver.cpp:106] Iteration 106400, lr = 0.01
I0622 22:21:57.668069 17898 solver.cpp:337] Iteration 106800, Testing net (#0)
I0622 22:23:01.107697 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.933516
I0622 22:23:01.107878 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.274852 (* 1 = 0.274852 loss)
I0622 22:23:03.590025 17898 solver.cpp:228] Iteration 106800, loss = 0.0099823
I0622 22:23:03.590095 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00998253 (* 1 = 0.00998253 loss)
I0622 22:23:03.590107 17898 sgd_solver.cpp:106] Iteration 106800, lr = 0.01
I0622 22:39:48.816140 17898 solver.cpp:337] Iteration 107200, Testing net (#0)
I0622 22:40:52.117499 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.934844
I0622 22:40:52.117712 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.280683 (* 1 = 0.280683 loss)
I0622 22:40:54.587682 17898 solver.cpp:228] Iteration 107200, loss = 0.00395015
I0622 22:40:54.587733 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00395038 (* 1 = 0.00395038 loss)
I0622 22:40:54.587746 17898 sgd_solver.cpp:106] Iteration 107200, lr = 0.01
I0622 22:57:39.880853 17898 solver.cpp:337] Iteration 107600, Testing net (#0)
I0622 22:58:43.217543 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.933047
I0622 22:58:43.217674 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.277943 (* 1 = 0.277943 loss)
I0622 22:58:45.717489 17898 solver.cpp:228] Iteration 107600, loss = 0.00321672
I0622 22:58:45.717531 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00321696 (* 1 = 0.00321696 loss)
I0622 22:58:45.717546 17898 sgd_solver.cpp:106] Iteration 107600, lr = 0.01
I0622 23:15:31.042325 17898 solver.cpp:337] Iteration 108000, Testing net (#0)
I0622 23:16:34.491425 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.933281
I0622 23:16:34.491633 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.273642 (* 1 = 0.273642 loss)
I0622 23:16:36.970887 17898 solver.cpp:228] Iteration 108000, loss = 0.0058862
I0622 23:16:36.970944 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00588644 (* 1 = 0.00588644 loss)
I0622 23:16:36.970958 17898 sgd_solver.cpp:106] Iteration 108000, lr = 0.01
I0622 23:33:22.392953 17898 solver.cpp:337] Iteration 108400, Testing net (#0)
I0622 23:34:25.708186 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.93625
I0622 23:34:25.708402 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.282414 (* 1 = 0.282414 loss)
I0622 23:34:28.212446 17898 solver.cpp:228] Iteration 108400, loss = 0.00295533
I0622 23:34:28.212491 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00295556 (* 1 = 0.00295556 loss)
I0622 23:34:28.212503 17898 sgd_solver.cpp:106] Iteration 108400, lr = 0.01
I0622 23:51:13.488965 17898 solver.cpp:337] Iteration 108800, Testing net (#0)
I0622 23:52:17.012590 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.934297
I0622 23:52:17.012779 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.287597 (* 1 = 0.287597 loss)
I0622 23:52:19.486068 17898 solver.cpp:228] Iteration 108800, loss = 0.00378594
I0622 23:52:19.486119 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00378617 (* 1 = 0.00378617 loss)
I0622 23:52:19.486131 17898 sgd_solver.cpp:106] Iteration 108800, lr = 0.01
I0623 00:09:04.563571 17898 solver.cpp:337] Iteration 109200, Testing net (#0)
I0623 00:10:07.852447 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.933906
I0623 00:10:07.852645 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.278476 (* 1 = 0.278476 loss)
I0623 00:10:10.339093 17898 solver.cpp:228] Iteration 109200, loss = 0.0126211
I0623 00:10:10.339131 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0126213 (* 1 = 0.0126213 loss)
I0623 00:10:10.339143 17898 sgd_solver.cpp:106] Iteration 109200, lr = 0.01
I0623 00:26:55.415052 17898 solver.cpp:337] Iteration 109600, Testing net (#0)
I0623 00:27:58.760299 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.933047
I0623 00:27:58.760481 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.289252 (* 1 = 0.289252 loss)
I0623 00:28:01.240504 17898 solver.cpp:228] Iteration 109600, loss = 0.00899627
I0623 00:28:01.240592 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0089965 (* 1 = 0.0089965 loss)
I0623 00:28:01.240604 17898 sgd_solver.cpp:106] Iteration 109600, lr = 0.01
I0623 00:44:46.614954 17898 solver.cpp:337] Iteration 110000, Testing net (#0)
I0623 00:45:50.075995 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.934219
I0623 00:45:50.076205 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.293169 (* 1 = 0.293169 loss)
I0623 00:45:52.566812 17898 solver.cpp:228] Iteration 110000, loss = 0.00539564
I0623 00:45:52.566860 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00539588 (* 1 = 0.00539588 loss)
I0623 00:45:52.566877 17898 sgd_solver.cpp:106] Iteration 110000, lr = 0.01
I0623 01:02:38.061950 17898 solver.cpp:337] Iteration 110400, Testing net (#0)
I0623 01:03:41.409188 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.934844
I0623 01:03:41.409337 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.283075 (* 1 = 0.283075 loss)
I0623 01:03:43.886020 17898 solver.cpp:228] Iteration 110400, loss = 0.00901286
I0623 01:03:43.886054 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0090131 (* 1 = 0.0090131 loss)
I0623 01:03:43.886065 17898 sgd_solver.cpp:106] Iteration 110400, lr = 0.01
I0623 01:20:29.224269 17898 solver.cpp:337] Iteration 110800, Testing net (#0)
I0623 01:21:32.672724 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.933906
I0623 01:21:32.672937 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.276439 (* 1 = 0.276439 loss)
I0623 01:21:35.148392 17898 solver.cpp:228] Iteration 110800, loss = 0.00176501
I0623 01:21:35.148442 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00176524 (* 1 = 0.00176524 loss)
I0623 01:21:35.148453 17898 sgd_solver.cpp:106] Iteration 110800, lr = 0.01
I0623 01:38:20.475999 17898 solver.cpp:337] Iteration 111200, Testing net (#0)
I0623 01:39:23.884786 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.934609
I0623 01:39:23.884991 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.284903 (* 1 = 0.284903 loss)
I0623 01:39:26.359877 17898 solver.cpp:228] Iteration 111200, loss = 0.00304513
I0623 01:39:26.359922 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00304536 (* 1 = 0.00304536 loss)
I0623 01:39:26.359935 17898 sgd_solver.cpp:106] Iteration 111200, lr = 0.01
I0623 01:56:11.581501 17898 solver.cpp:337] Iteration 111600, Testing net (#0)
I0623 01:57:14.901157 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.933438
I0623 01:57:14.901342 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.293964 (* 1 = 0.293964 loss)
I0623 01:57:17.371203 17898 solver.cpp:228] Iteration 111600, loss = 0.00625691
I0623 01:57:17.371265 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00625714 (* 1 = 0.00625714 loss)
I0623 01:57:17.371278 17898 sgd_solver.cpp:106] Iteration 111600, lr = 0.01
I0623 02:14:02.323442 17898 solver.cpp:337] Iteration 112000, Testing net (#0)
I0623 02:15:05.726263 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936641
I0623 02:15:05.726461 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.280631 (* 1 = 0.280631 loss)
I0623 02:15:08.207537 17898 solver.cpp:228] Iteration 112000, loss = 0.00220396
I0623 02:15:08.207594 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00220419 (* 1 = 0.00220419 loss)
I0623 02:15:08.207607 17898 sgd_solver.cpp:106] Iteration 112000, lr = 0.01
I0623 02:31:53.229439 17898 solver.cpp:337] Iteration 112400, Testing net (#0)
I0623 02:32:56.641726 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936406
I0623 02:32:56.641921 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.29343 (* 1 = 0.29343 loss)
I0623 02:32:59.122505 17898 solver.cpp:228] Iteration 112400, loss = 0.00217901
I0623 02:32:59.122575 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00217923 (* 1 = 0.00217923 loss)
I0623 02:32:59.122594 17898 sgd_solver.cpp:106] Iteration 112400, lr = 0.01
I0623 02:49:43.117372 17898 solver.cpp:337] Iteration 112800, Testing net (#0)
I0623 02:50:46.390971 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.933984
I0623 02:50:46.391211 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.300437 (* 1 = 0.300437 loss)
I0623 02:50:48.871003 17898 solver.cpp:228] Iteration 112800, loss = 0.00185981
I0623 02:50:48.871049 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00186004 (* 1 = 0.00186004 loss)
I0623 02:50:48.871060 17898 sgd_solver.cpp:106] Iteration 112800, lr = 0.01
I0623 03:07:33.052309 17898 solver.cpp:337] Iteration 113200, Testing net (#0)
I0623 03:08:36.499444 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.934766
I0623 03:08:36.499622 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.298493 (* 1 = 0.298493 loss)
I0623 03:08:38.979190 17898 solver.cpp:228] Iteration 113200, loss = 0.000793361
I0623 03:08:38.979235 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000793589 (* 1 = 0.000793589 loss)
I0623 03:08:38.979282 17898 sgd_solver.cpp:106] Iteration 113200, lr = 0.01
I0623 03:25:24.122236 17898 solver.cpp:337] Iteration 113600, Testing net (#0)
I0623 03:26:27.486134 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.933359
I0623 03:26:27.486274 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.297386 (* 1 = 0.297386 loss)
I0623 03:26:29.955260 17898 solver.cpp:228] Iteration 113600, loss = 0.00655247
I0623 03:26:29.955296 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0065527 (* 1 = 0.0065527 loss)
I0623 03:26:29.955307 17898 sgd_solver.cpp:106] Iteration 113600, lr = 0.01
I0623 03:43:15.270455 17898 solver.cpp:337] Iteration 114000, Testing net (#0)
I0623 03:44:18.688208 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.933281
I0623 03:44:18.688380 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.296201 (* 1 = 0.296201 loss)
I0623 03:44:21.179857 17898 solver.cpp:228] Iteration 114000, loss = 0.0108045
I0623 03:44:21.179905 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0108047 (* 1 = 0.0108047 loss)
I0623 03:44:21.179918 17898 sgd_solver.cpp:106] Iteration 114000, lr = 0.01
I0623 04:01:06.107938 17898 solver.cpp:337] Iteration 114400, Testing net (#0)
I0623 04:02:09.498239 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.934766
I0623 04:02:09.498479 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.299004 (* 1 = 0.299004 loss)
I0623 04:02:11.979485 17898 solver.cpp:228] Iteration 114400, loss = 0.00140859
I0623 04:02:11.979547 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00140882 (* 1 = 0.00140882 loss)
I0623 04:02:11.979562 17898 sgd_solver.cpp:106] Iteration 114400, lr = 0.01
I0623 04:18:56.852938 17898 solver.cpp:337] Iteration 114800, Testing net (#0)
I0623 04:20:00.196632 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937344
I0623 04:20:00.196851 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.278159 (* 1 = 0.278159 loss)
I0623 04:20:02.679708 17898 solver.cpp:228] Iteration 114800, loss = 0.00667681
I0623 04:20:02.679759 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00667703 (* 1 = 0.00667703 loss)
I0623 04:20:02.679774 17898 sgd_solver.cpp:106] Iteration 114800, lr = 0.01
I0623 04:36:48.120551 17898 solver.cpp:337] Iteration 115200, Testing net (#0)
I0623 04:37:51.549870 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.933516
I0623 04:37:51.550086 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.290745 (* 1 = 0.290745 loss)
I0623 04:37:54.027359 17898 solver.cpp:228] Iteration 115200, loss = 0.00197616
I0623 04:37:54.027393 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00197638 (* 1 = 0.00197638 loss)
I0623 04:37:54.027406 17898 sgd_solver.cpp:106] Iteration 115200, lr = 0.01
I0623 04:54:39.281961 17898 solver.cpp:337] Iteration 115600, Testing net (#0)
I0623 04:55:42.747321 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.933516
I0623 04:55:42.747509 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.293233 (* 1 = 0.293233 loss)
I0623 04:55:45.220196 17898 solver.cpp:228] Iteration 115600, loss = 0.00273521
I0623 04:55:45.220264 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00273543 (* 1 = 0.00273543 loss)
I0623 04:55:45.220288 17898 sgd_solver.cpp:106] Iteration 115600, lr = 0.01
I0623 05:12:30.216934 17898 solver.cpp:337] Iteration 116000, Testing net (#0)
I0623 05:13:33.581315 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936094
I0623 05:13:33.581514 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.288519 (* 1 = 0.288519 loss)
I0623 05:13:36.050520 17898 solver.cpp:228] Iteration 116000, loss = 0.00161956
I0623 05:13:36.050575 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00161978 (* 1 = 0.00161978 loss)
I0623 05:13:36.050587 17898 sgd_solver.cpp:106] Iteration 116000, lr = 0.01
I0623 05:30:21.258651 17898 solver.cpp:337] Iteration 116400, Testing net (#0)
I0623 05:31:24.595845 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.94
I0623 05:31:24.596060 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.26647 (* 1 = 0.26647 loss)
I0623 05:31:27.075011 17898 solver.cpp:228] Iteration 116400, loss = 0.000952184
I0623 05:31:27.075049 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000952405 (* 1 = 0.000952405 loss)
I0623 05:31:27.075062 17898 sgd_solver.cpp:106] Iteration 116400, lr = 0.01
I0623 05:48:11.487576 17898 solver.cpp:337] Iteration 116800, Testing net (#0)
I0623 05:49:14.841004 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.935
I0623 05:49:14.841248 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.287876 (* 1 = 0.287876 loss)
I0623 05:49:17.312199 17898 solver.cpp:228] Iteration 116800, loss = 0.00113699
I0623 05:49:17.312264 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00113721 (* 1 = 0.00113721 loss)
I0623 05:49:17.312288 17898 sgd_solver.cpp:106] Iteration 116800, lr = 0.01
I0623 06:06:02.852833 17898 solver.cpp:337] Iteration 117200, Testing net (#0)
I0623 06:07:06.319739 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.934687
I0623 06:07:06.319865 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.298652 (* 1 = 0.298652 loss)
I0623 06:07:08.797085 17898 solver.cpp:228] Iteration 117200, loss = 0.00164324
I0623 06:07:08.797127 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00164346 (* 1 = 0.00164346 loss)
I0623 06:07:08.797139 17898 sgd_solver.cpp:106] Iteration 117200, lr = 0.01
I0623 06:23:54.113178 17898 solver.cpp:337] Iteration 117600, Testing net (#0)
I0623 06:24:57.687753 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937266
I0623 06:24:57.687980 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.288452 (* 1 = 0.288452 loss)
I0623 06:25:00.162911 17898 solver.cpp:228] Iteration 117600, loss = 0.0012365
I0623 06:25:00.162973 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00123672 (* 1 = 0.00123672 loss)
I0623 06:25:00.162989 17898 sgd_solver.cpp:106] Iteration 117600, lr = 0.01
I0623 06:41:45.558584 17898 solver.cpp:337] Iteration 118000, Testing net (#0)
I0623 06:42:48.956794 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938203
I0623 06:42:48.956943 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.284172 (* 1 = 0.284172 loss)
I0623 06:42:51.435340 17898 solver.cpp:228] Iteration 118000, loss = 0.000883434
I0623 06:42:51.435391 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000883657 (* 1 = 0.000883657 loss)
I0623 06:42:51.435405 17898 sgd_solver.cpp:106] Iteration 118000, lr = 0.01
I0623 06:59:36.813761 17898 solver.cpp:337] Iteration 118400, Testing net (#0)
I0623 07:00:40.179237 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.931719
I0623 07:00:40.179409 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.304218 (* 1 = 0.304218 loss)
I0623 07:00:42.661877 17898 solver.cpp:228] Iteration 118400, loss = 0.003806
I0623 07:00:42.661945 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00380623 (* 1 = 0.00380623 loss)
I0623 07:00:42.661962 17898 sgd_solver.cpp:106] Iteration 118400, lr = 0.01
I0623 07:17:28.006146 17898 solver.cpp:337] Iteration 118800, Testing net (#0)
I0623 07:18:31.344274 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.932813
I0623 07:18:31.344502 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.303294 (* 1 = 0.303294 loss)
I0623 07:18:33.826092 17898 solver.cpp:228] Iteration 118800, loss = 0.00250107
I0623 07:18:33.826138 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00250129 (* 1 = 0.00250129 loss)
I0623 07:18:33.826153 17898 sgd_solver.cpp:106] Iteration 118800, lr = 0.01
I0623 07:35:18.820835 17898 solver.cpp:337] Iteration 119200, Testing net (#0)
I0623 07:36:22.212661 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936797
I0623 07:36:22.212878 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.28078 (* 1 = 0.28078 loss)
I0623 07:36:24.686401 17898 solver.cpp:228] Iteration 119200, loss = 0.000910671
I0623 07:36:24.686475 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000910895 (* 1 = 0.000910895 loss)
I0623 07:36:24.686489 17898 sgd_solver.cpp:106] Iteration 119200, lr = 0.01
I0623 07:53:08.745200 17898 solver.cpp:337] Iteration 119600, Testing net (#0)
I0623 07:54:11.967070 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937344
I0623 07:54:11.967293 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.289324 (* 1 = 0.289324 loss)
I0623 07:54:14.473477 17898 solver.cpp:228] Iteration 119600, loss = 0.00205516
I0623 07:54:14.473534 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00205539 (* 1 = 0.00205539 loss)
I0623 07:54:14.473547 17898 sgd_solver.cpp:106] Iteration 119600, lr = 0.01
I0623 08:10:58.524173 17898 solver.cpp:337] Iteration 120000, Testing net (#0)
I0623 08:12:01.979440 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936016
I0623 08:12:01.979655 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.303274 (* 1 = 0.303274 loss)
I0623 08:12:04.466121 17898 solver.cpp:228] Iteration 120000, loss = 0.00400663
I0623 08:12:04.466168 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00400685 (* 1 = 0.00400685 loss)
I0623 08:12:04.466181 17898 sgd_solver.cpp:106] Iteration 120000, lr = 0.01
I0623 08:28:49.689285 17898 solver.cpp:337] Iteration 120400, Testing net (#0)
I0623 08:29:53.085005 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.93625
I0623 08:29:53.085247 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.294845 (* 1 = 0.294845 loss)
I0623 08:29:55.580126 17898 solver.cpp:228] Iteration 120400, loss = 0.0012365
I0623 08:29:55.580168 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00123672 (* 1 = 0.00123672 loss)
I0623 08:29:55.580179 17898 sgd_solver.cpp:106] Iteration 120400, lr = 0.01
I0623 08:46:40.726747 17898 solver.cpp:337] Iteration 120800, Testing net (#0)
I0623 08:47:44.131269 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936016
I0623 08:47:44.131510 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.280835 (* 1 = 0.280835 loss)
I0623 08:47:46.623180 17898 solver.cpp:228] Iteration 120800, loss = 0.000814189
I0623 08:47:46.623242 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000814411 (* 1 = 0.000814411 loss)
I0623 08:47:46.623256 17898 sgd_solver.cpp:106] Iteration 120800, lr = 0.01
I0623 09:04:31.869148 17898 solver.cpp:337] Iteration 121200, Testing net (#0)
I0623 09:05:35.325911 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.935313
I0623 09:05:35.326089 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.298824 (* 1 = 0.298824 loss)
I0623 09:05:37.820243 17898 solver.cpp:228] Iteration 121200, loss = 0.00245801
I0623 09:05:37.820298 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00245823 (* 1 = 0.00245823 loss)
I0623 09:05:37.820312 17898 sgd_solver.cpp:106] Iteration 121200, lr = 0.01
I0623 09:22:22.889945 17898 solver.cpp:337] Iteration 121600, Testing net (#0)
I0623 09:23:26.310858 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.934844
I0623 09:23:26.311079 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.306698 (* 1 = 0.306698 loss)
I0623 09:23:28.781266 17898 solver.cpp:228] Iteration 121600, loss = 0.00165246
I0623 09:23:28.781323 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00165268 (* 1 = 0.00165268 loss)
I0623 09:23:28.781335 17898 sgd_solver.cpp:106] Iteration 121600, lr = 0.01
I0623 09:40:13.657428 17898 solver.cpp:337] Iteration 122000, Testing net (#0)
I0623 09:41:17.017271 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938672
I0623 09:41:17.017405 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.273705 (* 1 = 0.273705 loss)
I0623 09:41:19.495214 17898 solver.cpp:228] Iteration 122000, loss = 0.00369018
I0623 09:41:19.495259 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0036904 (* 1 = 0.0036904 loss)
I0623 09:41:19.495270 17898 sgd_solver.cpp:106] Iteration 122000, lr = 0.01
I0623 09:58:04.323583 17898 solver.cpp:337] Iteration 122400, Testing net (#0)
I0623 09:59:07.551434 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.935547
I0623 09:59:07.551671 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.284144 (* 1 = 0.284144 loss)
I0623 09:59:10.025158 17898 solver.cpp:228] Iteration 122400, loss = 0.00180136
I0623 09:59:10.025202 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00180158 (* 1 = 0.00180158 loss)
I0623 09:59:10.025212 17898 sgd_solver.cpp:106] Iteration 122400, lr = 0.01
I0623 10:15:54.946600 17898 solver.cpp:337] Iteration 122800, Testing net (#0)
I0623 10:16:58.380879 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936797
I0623 10:16:58.381072 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.288104 (* 1 = 0.288104 loss)
I0623 10:17:00.864871 17898 solver.cpp:228] Iteration 122800, loss = 0.000941489
I0623 10:17:00.864912 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000941707 (* 1 = 0.000941707 loss)
I0623 10:17:00.864946 17898 sgd_solver.cpp:106] Iteration 122800, lr = 0.01
I0623 10:33:45.409327 17898 solver.cpp:337] Iteration 123200, Testing net (#0)
I0623 10:34:48.639930 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936797
I0623 10:34:48.640152 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.290113 (* 1 = 0.290113 loss)
I0623 10:34:51.118072 17898 solver.cpp:228] Iteration 123200, loss = 0.00195121
I0623 10:34:51.118130 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00195143 (* 1 = 0.00195143 loss)
I0623 10:34:51.118144 17898 sgd_solver.cpp:106] Iteration 123200, lr = 0.01
I0623 10:51:36.020854 17898 solver.cpp:337] Iteration 123600, Testing net (#0)
I0623 10:52:39.553531 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937656
I0623 10:52:39.553745 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.272389 (* 1 = 0.272389 loss)
I0623 10:52:42.026582 17898 solver.cpp:228] Iteration 123600, loss = 0.000927346
I0623 10:52:42.026634 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000927569 (* 1 = 0.000927569 loss)
I0623 10:52:42.026648 17898 sgd_solver.cpp:106] Iteration 123600, lr = 0.01
I0623 11:09:27.232993 17898 solver.cpp:337] Iteration 124000, Testing net (#0)
I0623 11:10:30.600280 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.935859
I0623 11:10:30.600502 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.288475 (* 1 = 0.288475 loss)
I0623 11:10:33.081655 17898 solver.cpp:228] Iteration 124000, loss = 0.00339141
I0623 11:10:33.081707 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00339163 (* 1 = 0.00339163 loss)
I0623 11:10:33.081719 17898 sgd_solver.cpp:106] Iteration 124000, lr = 0.01
I0623 11:27:18.176623 17898 solver.cpp:337] Iteration 124400, Testing net (#0)
I0623 11:28:21.694582 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.934141
I0623 11:28:21.694762 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.30201 (* 1 = 0.30201 loss)
I0623 11:28:24.171134 17898 solver.cpp:228] Iteration 124400, loss = 0.000692105
I0623 11:28:24.171174 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000692325 (* 1 = 0.000692325 loss)
I0623 11:28:24.171186 17898 sgd_solver.cpp:106] Iteration 124400, lr = 0.01
I0623 11:45:09.637131 17898 solver.cpp:337] Iteration 124800, Testing net (#0)
I0623 11:46:13.029489 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937109
I0623 11:46:13.029680 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.293227 (* 1 = 0.293227 loss)
I0623 11:46:15.514487 17898 solver.cpp:228] Iteration 124800, loss = 0.000938354
I0623 11:46:15.514525 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000938575 (* 1 = 0.000938575 loss)
I0623 11:46:15.514535 17898 sgd_solver.cpp:106] Iteration 124800, lr = 0.01
I0623 12:03:00.813266 17898 solver.cpp:337] Iteration 125200, Testing net (#0)
I0623 12:04:04.083483 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.93625
I0623 12:04:04.083715 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.292744 (* 1 = 0.292744 loss)
I0623 12:04:06.563925 17898 solver.cpp:228] Iteration 125200, loss = 0.00239739
I0623 12:04:06.563976 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00239761 (* 1 = 0.00239761 loss)
I0623 12:04:06.563987 17898 sgd_solver.cpp:106] Iteration 125200, lr = 0.01
I0623 12:20:52.123836 17898 solver.cpp:337] Iteration 125600, Testing net (#0)
I0623 12:21:55.447515 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.935703
I0623 12:21:55.447727 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.296238 (* 1 = 0.296238 loss)
I0623 12:21:57.926350 17898 solver.cpp:228] Iteration 125600, loss = 0.00458416
I0623 12:21:57.926412 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00458438 (* 1 = 0.00458438 loss)
I0623 12:21:57.926425 17898 sgd_solver.cpp:106] Iteration 125600, lr = 0.01
I0623 12:38:43.049033 17898 solver.cpp:337] Iteration 126000, Testing net (#0)
I0623 12:39:46.282140 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936953
I0623 12:39:46.282377 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.292654 (* 1 = 0.292654 loss)
I0623 12:39:48.749652 17898 solver.cpp:228] Iteration 126000, loss = 0.000963718
I0623 12:39:48.749696 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000963941 (* 1 = 0.000963941 loss)
I0623 12:39:48.749707 17898 sgd_solver.cpp:106] Iteration 126000, lr = 0.01
I0623 12:56:33.159391 17898 solver.cpp:337] Iteration 126400, Testing net (#0)
I0623 12:57:36.437933 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937109
I0623 12:57:36.438122 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.281439 (* 1 = 0.281439 loss)
I0623 12:57:38.916848 17898 solver.cpp:228] Iteration 126400, loss = 0.00315731
I0623 12:57:38.916913 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00315753 (* 1 = 0.00315753 loss)
I0623 12:57:38.916927 17898 sgd_solver.cpp:106] Iteration 126400, lr = 0.01
I0623 13:14:23.971602 17898 solver.cpp:337] Iteration 126800, Testing net (#0)
I0623 13:15:27.197856 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936094
I0623 13:15:27.202399 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.296584 (* 1 = 0.296584 loss)
I0623 13:15:29.671274 17898 solver.cpp:228] Iteration 126800, loss = 0.00183287
I0623 13:15:29.671319 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0018331 (* 1 = 0.0018331 loss)
I0623 13:15:29.671329 17898 sgd_solver.cpp:106] Iteration 126800, lr = 0.01
I0623 13:32:14.444190 17898 solver.cpp:337] Iteration 127200, Testing net (#0)
I0623 13:33:17.669651 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.935469
I0623 13:33:17.669842 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.298318 (* 1 = 0.298318 loss)
I0623 13:33:20.140281 17898 solver.cpp:228] Iteration 127200, loss = 0.000808731
I0623 13:33:20.140326 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000808955 (* 1 = 0.000808955 loss)
I0623 13:33:20.140343 17898 sgd_solver.cpp:106] Iteration 127200, lr = 0.01
I0623 13:50:04.583945 17898 solver.cpp:337] Iteration 127600, Testing net (#0)
I0623 13:51:08.124913 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.935547
I0623 13:51:08.125149 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.292818 (* 1 = 0.292818 loss)
I0623 13:51:10.604426 17898 solver.cpp:228] Iteration 127600, loss = 0.000644097
I0623 13:51:10.604511 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000644323 (* 1 = 0.000644323 loss)
I0623 13:51:10.604531 17898 sgd_solver.cpp:106] Iteration 127600, lr = 0.01
I0623 14:07:55.735574 17898 solver.cpp:337] Iteration 128000, Testing net (#0)
I0623 14:08:59.196730 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937344
I0623 14:08:59.196969 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.28355 (* 1 = 0.28355 loss)
I0623 14:09:01.672055 17898 solver.cpp:228] Iteration 128000, loss = 0.000598507
I0623 14:09:01.672138 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000598735 (* 1 = 0.000598735 loss)
I0623 14:09:01.672154 17898 sgd_solver.cpp:106] Iteration 128000, lr = 0.01
I0623 14:25:46.607939 17898 solver.cpp:337] Iteration 128400, Testing net (#0)
I0623 14:26:50.029373 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937891
I0623 14:26:50.029602 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.290476 (* 1 = 0.290476 loss)
I0623 14:26:52.512188 17898 solver.cpp:228] Iteration 128400, loss = 0.000668957
I0623 14:26:52.512248 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000669184 (* 1 = 0.000669184 loss)
I0623 14:26:52.512259 17898 sgd_solver.cpp:106] Iteration 128400, lr = 0.01
I0623 14:43:36.894392 17898 solver.cpp:337] Iteration 128800, Testing net (#0)
I0623 14:44:40.234396 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937109
I0623 14:44:40.234614 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.296401 (* 1 = 0.296401 loss)
I0623 14:44:42.710681 17898 solver.cpp:228] Iteration 128800, loss = 0.00139139
I0623 14:44:42.710742 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00139162 (* 1 = 0.00139162 loss)
I0623 14:44:42.710758 17898 sgd_solver.cpp:106] Iteration 128800, lr = 0.01
I0623 15:01:27.724086 17898 solver.cpp:337] Iteration 129200, Testing net (#0)
I0623 15:02:31.144798 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937969
I0623 15:02:31.144955 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.268893 (* 1 = 0.268893 loss)
I0623 15:02:33.621994 17898 solver.cpp:228] Iteration 129200, loss = 0.000770347
I0623 15:02:33.622052 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000770575 (* 1 = 0.000770575 loss)
I0623 15:02:33.622069 17898 sgd_solver.cpp:106] Iteration 129200, lr = 0.01
I0623 15:19:18.506966 17898 solver.cpp:337] Iteration 129600, Testing net (#0)
I0623 15:20:21.900832 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936016
I0623 15:20:21.901051 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.282899 (* 1 = 0.282899 loss)
I0623 15:20:24.374536 17898 solver.cpp:228] Iteration 129600, loss = 0.00205608
I0623 15:20:24.374596 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00205631 (* 1 = 0.00205631 loss)
I0623 15:20:24.374611 17898 sgd_solver.cpp:106] Iteration 129600, lr = 0.01
I0623 15:37:09.324599 17898 solver.cpp:337] Iteration 130000, Testing net (#0)
I0623 15:38:12.741125 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937031
I0623 15:38:12.743314 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.286674 (* 1 = 0.286674 loss)
I0623 15:38:15.226369 17898 solver.cpp:228] Iteration 130000, loss = 0.00215141
I0623 15:38:15.226426 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00215164 (* 1 = 0.00215164 loss)
I0623 15:38:15.226439 17898 sgd_solver.cpp:106] Iteration 130000, lr = 0.01
I0623 15:55:00.313195 17898 solver.cpp:337] Iteration 130400, Testing net (#0)
I0623 15:56:03.645259 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.935781
I0623 15:56:03.645506 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.280648 (* 1 = 0.280648 loss)
I0623 15:56:06.118230 17898 solver.cpp:228] Iteration 130400, loss = 0.00127902
I0623 15:56:06.118273 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00127924 (* 1 = 0.00127924 loss)
I0623 15:56:06.118286 17898 sgd_solver.cpp:106] Iteration 130400, lr = 0.01
I0623 16:12:51.364559 17898 solver.cpp:337] Iteration 130800, Testing net (#0)
I0623 16:13:54.714418 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936484
I0623 16:13:54.714563 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.278662 (* 1 = 0.278662 loss)
I0623 16:13:57.195518 17898 solver.cpp:228] Iteration 130800, loss = 0.0013074
I0623 16:13:57.195574 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00130762 (* 1 = 0.00130762 loss)
I0623 16:13:57.195586 17898 sgd_solver.cpp:106] Iteration 130800, lr = 0.01
I0623 16:30:42.133787 17898 solver.cpp:337] Iteration 131200, Testing net (#0)
I0623 16:31:45.439676 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.934062
I0623 16:31:45.439896 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.2976 (* 1 = 0.2976 loss)
I0623 16:31:47.926242 17898 solver.cpp:228] Iteration 131200, loss = 0.00113335
I0623 16:31:47.926331 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00113357 (* 1 = 0.00113357 loss)
I0623 16:31:47.926369 17898 sgd_solver.cpp:106] Iteration 131200, lr = 0.01
I0623 16:48:33.223872 17898 solver.cpp:337] Iteration 131600, Testing net (#0)
I0623 16:49:36.559429 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936328
I0623 16:49:36.559578 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.297962 (* 1 = 0.297962 loss)
I0623 16:49:39.030926 17898 solver.cpp:228] Iteration 131600, loss = 0.00173692
I0623 16:49:39.030957 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00173714 (* 1 = 0.00173714 loss)
I0623 16:49:39.030971 17898 sgd_solver.cpp:106] Iteration 131600, lr = 0.01
I0623 17:06:24.155050 17898 solver.cpp:337] Iteration 132000, Testing net (#0)
I0623 17:07:27.637967 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937344
I0623 17:07:27.638160 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.268145 (* 1 = 0.268145 loss)
I0623 17:07:30.114627 17898 solver.cpp:228] Iteration 132000, loss = 0.000677785
I0623 17:07:30.114681 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000678013 (* 1 = 0.000678013 loss)
I0623 17:07:30.114696 17898 sgd_solver.cpp:106] Iteration 132000, lr = 0.01
I0623 17:24:15.000923 17898 solver.cpp:337] Iteration 132400, Testing net (#0)
I0623 17:25:18.337131 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.935703
I0623 17:25:18.337353 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.281833 (* 1 = 0.281833 loss)
I0623 17:25:20.810592 17898 solver.cpp:228] Iteration 132400, loss = 0.000577217
I0623 17:25:20.810643 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000577447 (* 1 = 0.000577447 loss)
I0623 17:25:20.810657 17898 sgd_solver.cpp:106] Iteration 132400, lr = 0.01
I0623 17:42:05.830597 17898 solver.cpp:337] Iteration 132800, Testing net (#0)
I0623 17:43:09.195473 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.934531
I0623 17:43:09.195642 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.29405 (* 1 = 0.29405 loss)
I0623 17:43:11.693064 17898 solver.cpp:228] Iteration 132800, loss = 0.00101374
I0623 17:43:11.693109 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00101397 (* 1 = 0.00101397 loss)
I0623 17:43:11.693119 17898 sgd_solver.cpp:106] Iteration 132800, lr = 0.01
I0623 17:59:56.652330 17898 solver.cpp:337] Iteration 133200, Testing net (#0)
I0623 18:01:00.069237 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936562
I0623 18:01:00.069478 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.29315 (* 1 = 0.29315 loss)
I0623 18:01:02.549396 17898 solver.cpp:228] Iteration 133200, loss = 0.000756291
I0623 18:01:02.549451 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000756521 (* 1 = 0.000756521 loss)
I0623 18:01:02.549464 17898 sgd_solver.cpp:106] Iteration 133200, lr = 0.01
I0623 18:17:47.306607 17898 solver.cpp:337] Iteration 133600, Testing net (#0)
I0623 18:18:50.700486 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938516
I0623 18:18:50.700711 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.276257 (* 1 = 0.276257 loss)
I0623 18:18:53.177937 17898 solver.cpp:228] Iteration 133600, loss = 0.0017704
I0623 18:18:53.177992 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00177063 (* 1 = 0.00177063 loss)
I0623 18:18:53.178005 17898 sgd_solver.cpp:106] Iteration 133600, lr = 0.01
I0623 18:35:38.153833 17898 solver.cpp:337] Iteration 134000, Testing net (#0)
I0623 18:36:41.644806 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936719
I0623 18:36:41.644950 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.300026 (* 1 = 0.300026 loss)
I0623 18:36:44.123388 17898 solver.cpp:228] Iteration 134000, loss = 0.00150374
I0623 18:36:44.123447 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00150397 (* 1 = 0.00150397 loss)
I0623 18:36:44.123461 17898 sgd_solver.cpp:106] Iteration 134000, lr = 0.01
I0623 18:53:28.946969 17898 solver.cpp:337] Iteration 134400, Testing net (#0)
I0623 18:54:32.280565 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.934062
I0623 18:54:32.280800 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.298589 (* 1 = 0.298589 loss)
I0623 18:54:34.755182 17898 solver.cpp:228] Iteration 134400, loss = 0.00110574
I0623 18:54:34.755239 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00110597 (* 1 = 0.00110597 loss)
I0623 18:54:34.755252 17898 sgd_solver.cpp:106] Iteration 134400, lr = 0.01
I0623 19:11:19.626669 17898 solver.cpp:337] Iteration 134800, Testing net (#0)
I0623 19:12:23.060894 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936719
I0623 19:12:23.061115 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.282142 (* 1 = 0.282142 loss)
I0623 19:12:25.547492 17898 solver.cpp:228] Iteration 134800, loss = 0.00121396
I0623 19:12:25.547564 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00121419 (* 1 = 0.00121419 loss)
I0623 19:12:25.547585 17898 sgd_solver.cpp:106] Iteration 134800, lr = 0.01
I0623 19:29:10.609529 17898 solver.cpp:337] Iteration 135200, Testing net (#0)
I0623 19:30:14.002360 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.934844
I0623 19:30:14.002581 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.293736 (* 1 = 0.293736 loss)
I0623 19:30:16.470837 17898 solver.cpp:228] Iteration 135200, loss = 0.00161328
I0623 19:30:16.470901 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00161351 (* 1 = 0.00161351 loss)
I0623 19:30:16.470916 17898 sgd_solver.cpp:106] Iteration 135200, lr = 0.01
I0623 19:47:01.209758 17898 solver.cpp:337] Iteration 135600, Testing net (#0)
I0623 19:48:04.586526 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937266
I0623 19:48:04.586736 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.285464 (* 1 = 0.285464 loss)
I0623 19:48:07.058903 17898 solver.cpp:228] Iteration 135600, loss = 0.00262299
I0623 19:48:07.058974 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00262322 (* 1 = 0.00262322 loss)
I0623 19:48:07.058987 17898 sgd_solver.cpp:106] Iteration 135600, lr = 0.01
I0623 20:04:52.449772 17898 solver.cpp:337] Iteration 136000, Testing net (#0)
I0623 20:05:55.819447 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936484
I0623 20:05:55.819664 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.279652 (* 1 = 0.279652 loss)
I0623 20:05:58.300427 17898 solver.cpp:228] Iteration 136000, loss = 0.00156141
I0623 20:05:58.300484 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00156163 (* 1 = 0.00156163 loss)
I0623 20:05:58.300499 17898 sgd_solver.cpp:106] Iteration 136000, lr = 0.01
I0623 20:22:42.690510 17898 solver.cpp:337] Iteration 136400, Testing net (#0)
I0623 20:23:46.029530 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937813
I0623 20:23:46.029662 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.268169 (* 1 = 0.268169 loss)
I0623 20:23:48.503968 17898 solver.cpp:228] Iteration 136400, loss = 0.000446211
I0623 20:23:48.504056 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000446438 (* 1 = 0.000446438 loss)
I0623 20:23:48.504079 17898 sgd_solver.cpp:106] Iteration 136400, lr = 0.01
I0623 20:40:33.462491 17898 solver.cpp:337] Iteration 136800, Testing net (#0)
I0623 20:41:36.705970 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936094
I0623 20:41:36.706177 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.289165 (* 1 = 0.289165 loss)
I0623 20:41:39.177637 17898 solver.cpp:228] Iteration 136800, loss = 0.00304442
I0623 20:41:39.177682 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00304464 (* 1 = 0.00304464 loss)
I0623 20:41:39.177693 17898 sgd_solver.cpp:106] Iteration 136800, lr = 0.01
I0623 20:58:24.051137 17898 solver.cpp:337] Iteration 137200, Testing net (#0)
I0623 20:59:27.466637 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.934766
I0623 20:59:27.466876 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.297652 (* 1 = 0.297652 loss)
I0623 20:59:29.957430 17898 solver.cpp:228] Iteration 137200, loss = 0.00082201
I0623 20:59:29.957491 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000822238 (* 1 = 0.000822238 loss)
I0623 20:59:29.957505 17898 sgd_solver.cpp:106] Iteration 137200, lr = 0.01
I0623 21:16:14.938308 17898 solver.cpp:337] Iteration 137600, Testing net (#0)
I0623 21:17:18.408377 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.935
I0623 21:17:18.411759 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.292025 (* 1 = 0.292025 loss)
I0623 21:17:20.896108 17898 solver.cpp:228] Iteration 137600, loss = 0.0004928
I0623 21:17:20.896173 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000493029 (* 1 = 0.000493029 loss)
I0623 21:17:20.896184 17898 sgd_solver.cpp:106] Iteration 137600, lr = 0.01
I0623 21:34:06.066226 17898 solver.cpp:337] Iteration 138000, Testing net (#0)
I0623 21:35:09.443598 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.935313
I0623 21:35:09.443816 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.291631 (* 1 = 0.291631 loss)
I0623 21:35:11.924896 17898 solver.cpp:228] Iteration 138000, loss = 0.00145496
I0623 21:35:11.924962 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00145519 (* 1 = 0.00145519 loss)
I0623 21:35:11.924978 17898 sgd_solver.cpp:106] Iteration 138000, lr = 0.01
I0623 21:51:57.033143 17898 solver.cpp:337] Iteration 138400, Testing net (#0)
I0623 21:53:00.297891 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936406
I0623 21:53:00.298101 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.280736 (* 1 = 0.280736 loss)
I0623 21:53:02.769675 17898 solver.cpp:228] Iteration 138400, loss = 0.00103052
I0623 21:53:02.769716 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00103075 (* 1 = 0.00103075 loss)
I0623 21:53:02.769729 17898 sgd_solver.cpp:106] Iteration 138400, lr = 0.01
I0623 22:09:47.660913 17898 solver.cpp:337] Iteration 138800, Testing net (#0)
I0623 22:10:51.040788 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.934844
I0623 22:10:51.040971 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.292946 (* 1 = 0.292946 loss)
I0623 22:10:53.513542 17898 solver.cpp:228] Iteration 138800, loss = 0.000790894
I0623 22:10:53.513599 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000791124 (* 1 = 0.000791124 loss)
I0623 22:10:53.513614 17898 sgd_solver.cpp:106] Iteration 138800, lr = 0.01
I0623 22:27:38.209314 17898 solver.cpp:337] Iteration 139200, Testing net (#0)
I0623 22:28:41.566269 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937734
I0623 22:28:41.566471 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.277981 (* 1 = 0.277981 loss)
I0623 22:28:44.057109 17898 solver.cpp:228] Iteration 139200, loss = 0.00093701
I0623 22:28:44.057155 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000937239 (* 1 = 0.000937239 loss)
I0623 22:28:44.057166 17898 sgd_solver.cpp:106] Iteration 139200, lr = 0.01
I0623 22:45:28.956842 17898 solver.cpp:337] Iteration 139600, Testing net (#0)
I0623 22:46:32.262809 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936484
I0623 22:46:32.263010 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.2867 (* 1 = 0.2867 loss)
I0623 22:46:34.735499 17898 solver.cpp:228] Iteration 139600, loss = 0.00151715
I0623 22:46:34.735544 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00151738 (* 1 = 0.00151738 loss)
I0623 22:46:34.735558 17898 sgd_solver.cpp:106] Iteration 139600, lr = 0.01
I0623 23:03:26.642978 17898 solver.cpp:337] Iteration 140000, Testing net (#0)
I0623 23:04:30.505017 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937578
I0623 23:04:30.505157 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.290477 (* 1 = 0.290477 loss)
I0623 23:04:33.001205 17898 solver.cpp:228] Iteration 140000, loss = 0.000379494
I0623 23:04:33.001241 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000379724 (* 1 = 0.000379724 loss)
I0623 23:04:33.001253 17898 sgd_solver.cpp:106] Iteration 140000, lr = 0.01
I0623 23:21:20.183507 17898 solver.cpp:337] Iteration 140400, Testing net (#0)
I0623 23:22:23.676029 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936484
I0623 23:22:23.676172 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.28758 (* 1 = 0.28758 loss)
I0623 23:22:26.165657 17898 solver.cpp:228] Iteration 140400, loss = 0.00092085
I0623 23:22:26.165717 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000921081 (* 1 = 0.000921081 loss)
I0623 23:22:26.165731 17898 sgd_solver.cpp:106] Iteration 140400, lr = 0.01
I0623 23:39:10.323287 17898 solver.cpp:337] Iteration 140800, Testing net (#0)
I0623 23:40:13.665202 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.94
I0623 23:40:13.678457 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.274747 (* 1 = 0.274747 loss)
I0623 23:40:16.163990 17898 solver.cpp:228] Iteration 140800, loss = 0.00236911
I0623 23:40:16.164037 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00236934 (* 1 = 0.00236934 loss)
I0623 23:40:16.164049 17898 sgd_solver.cpp:106] Iteration 140800, lr = 0.01
I0623 23:57:00.542323 17898 solver.cpp:337] Iteration 141200, Testing net (#0)
I0623 23:58:03.947826 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.935938
I0623 23:58:03.948025 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.287836 (* 1 = 0.287836 loss)
I0623 23:58:06.428199 17898 solver.cpp:228] Iteration 141200, loss = 0.00179377
I0623 23:58:06.428251 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.001794 (* 1 = 0.001794 loss)
I0623 23:58:06.428264 17898 sgd_solver.cpp:106] Iteration 141200, lr = 0.01
I0624 00:14:51.312477 17898 solver.cpp:337] Iteration 141600, Testing net (#0)
I0624 00:15:54.575337 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936094
I0624 00:15:54.575561 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.291516 (* 1 = 0.291516 loss)
I0624 00:15:57.065605 17898 solver.cpp:228] Iteration 141600, loss = 0.000983909
I0624 00:15:57.065652 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000984141 (* 1 = 0.000984141 loss)
I0624 00:15:57.065670 17898 sgd_solver.cpp:106] Iteration 141600, lr = 0.01
I0624 00:32:41.774989 17898 solver.cpp:337] Iteration 142000, Testing net (#0)
I0624 00:33:45.101657 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938828
I0624 00:33:45.101893 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.269235 (* 1 = 0.269235 loss)
I0624 00:33:47.571643 17898 solver.cpp:228] Iteration 142000, loss = 0.00181515
I0624 00:33:47.571696 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00181538 (* 1 = 0.00181538 loss)
I0624 00:33:47.571707 17898 sgd_solver.cpp:106] Iteration 142000, lr = 0.01
I0624 00:50:32.570390 17898 solver.cpp:337] Iteration 142400, Testing net (#0)
I0624 00:51:36.065443 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939219
I0624 00:51:36.065634 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.285537 (* 1 = 0.285537 loss)
I0624 00:51:38.535280 17898 solver.cpp:228] Iteration 142400, loss = 0.00199403
I0624 00:51:38.535325 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00199426 (* 1 = 0.00199426 loss)
I0624 00:51:38.535337 17898 sgd_solver.cpp:106] Iteration 142400, lr = 0.01
I0624 01:08:23.508855 17898 solver.cpp:337] Iteration 142800, Testing net (#0)
I0624 01:09:26.772976 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938125
I0624 01:09:26.773180 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.283884 (* 1 = 0.283884 loss)
I0624 01:09:29.244169 17898 solver.cpp:228] Iteration 142800, loss = 0.00196708
I0624 01:09:29.244228 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00196731 (* 1 = 0.00196731 loss)
I0624 01:09:29.244246 17898 sgd_solver.cpp:106] Iteration 142800, lr = 0.01
I0624 01:26:14.388301 17898 solver.cpp:337] Iteration 143200, Testing net (#0)
I0624 01:27:17.756515 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936953
I0624 01:27:17.756706 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.297803 (* 1 = 0.297803 loss)
I0624 01:27:20.240489 17898 solver.cpp:228] Iteration 143200, loss = 0.00164002
I0624 01:27:20.240543 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00164026 (* 1 = 0.00164026 loss)
I0624 01:27:20.240559 17898 sgd_solver.cpp:106] Iteration 143200, lr = 0.01
I0624 01:44:05.251574 17898 solver.cpp:337] Iteration 143600, Testing net (#0)
I0624 01:45:08.665961 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938359
I0624 01:45:08.666139 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.272479 (* 1 = 0.272479 loss)
I0624 01:45:11.152811 17898 solver.cpp:228] Iteration 143600, loss = 0.00140299
I0624 01:45:11.152853 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00140322 (* 1 = 0.00140322 loss)
I0624 01:45:11.152864 17898 sgd_solver.cpp:106] Iteration 143600, lr = 0.01
I0624 02:01:55.366251 17898 solver.cpp:337] Iteration 144000, Testing net (#0)
I0624 02:02:58.787768 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937266
I0624 02:02:58.788003 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.291755 (* 1 = 0.291755 loss)
I0624 02:03:01.272847 17898 solver.cpp:228] Iteration 144000, loss = 0.000726688
I0624 02:03:01.272905 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000726921 (* 1 = 0.000726921 loss)
I0624 02:03:01.272918 17898 sgd_solver.cpp:106] Iteration 144000, lr = 0.01
I0624 02:19:46.382773 17898 solver.cpp:337] Iteration 144400, Testing net (#0)
I0624 02:20:49.729248 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.934766
I0624 02:20:49.729398 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.29332 (* 1 = 0.29332 loss)
I0624 02:20:52.202903 17898 solver.cpp:228] Iteration 144400, loss = 0.00130725
I0624 02:20:52.202961 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00130748 (* 1 = 0.00130748 loss)
I0624 02:20:52.202982 17898 sgd_solver.cpp:106] Iteration 144400, lr = 0.01
I0624 02:37:37.368331 17898 solver.cpp:337] Iteration 144800, Testing net (#0)
I0624 02:38:40.764282 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939453
I0624 02:38:40.764442 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.269957 (* 1 = 0.269957 loss)
I0624 02:38:43.243255 17898 solver.cpp:228] Iteration 144800, loss = 0.000889524
I0624 02:38:43.243350 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000889758 (* 1 = 0.000889758 loss)
I0624 02:38:43.243363 17898 sgd_solver.cpp:106] Iteration 144800, lr = 0.01
I0624 02:55:28.371230 17898 solver.cpp:337] Iteration 145200, Testing net (#0)
I0624 02:56:31.759965 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937422
I0624 02:56:31.760190 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.279959 (* 1 = 0.279959 loss)
I0624 02:56:34.249941 17898 solver.cpp:228] Iteration 145200, loss = 0.000658803
I0624 02:56:34.249985 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000659036 (* 1 = 0.000659036 loss)
I0624 02:56:34.250000 17898 sgd_solver.cpp:106] Iteration 145200, lr = 0.01
I0624 03:13:19.511579 17898 solver.cpp:337] Iteration 145600, Testing net (#0)
I0624 03:14:22.895979 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937344
I0624 03:14:22.896185 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.290013 (* 1 = 0.290013 loss)
I0624 03:14:25.369598 17898 solver.cpp:228] Iteration 145600, loss = 0.00115025
I0624 03:14:25.369642 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00115048 (* 1 = 0.00115048 loss)
I0624 03:14:25.369654 17898 sgd_solver.cpp:106] Iteration 145600, lr = 0.01
I0624 03:31:10.466346 17898 solver.cpp:337] Iteration 146000, Testing net (#0)
I0624 03:32:13.823240 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936172
I0624 03:32:13.823434 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.289205 (* 1 = 0.289205 loss)
I0624 03:32:16.311413 17898 solver.cpp:228] Iteration 146000, loss = 0.00124891
I0624 03:32:16.311458 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00124915 (* 1 = 0.00124915 loss)
I0624 03:32:16.311470 17898 sgd_solver.cpp:106] Iteration 146000, lr = 0.01
I0624 03:49:01.084852 17898 solver.cpp:337] Iteration 146400, Testing net (#0)
I0624 03:50:04.483804 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.93875
I0624 03:50:04.484006 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.278206 (* 1 = 0.278206 loss)
I0624 03:50:06.963500 17898 solver.cpp:228] Iteration 146400, loss = 0.00084736
I0624 03:50:06.963538 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000847595 (* 1 = 0.000847595 loss)
I0624 03:50:06.963551 17898 sgd_solver.cpp:106] Iteration 146400, lr = 0.01
I0624 04:06:51.922720 17898 solver.cpp:337] Iteration 146800, Testing net (#0)
I0624 04:07:55.345618 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938516
I0624 04:07:55.345811 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.288807 (* 1 = 0.288807 loss)
I0624 04:07:57.821444 17898 solver.cpp:228] Iteration 146800, loss = 0.000592273
I0624 04:07:57.821492 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000592509 (* 1 = 0.000592509 loss)
I0624 04:07:57.821506 17898 sgd_solver.cpp:106] Iteration 146800, lr = 0.01
I0624 04:24:42.463848 17898 solver.cpp:337] Iteration 147200, Testing net (#0)
I0624 04:25:45.671625 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.933672
I0624 04:25:45.671787 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.302152 (* 1 = 0.302152 loss)
I0624 04:25:48.145467 17898 solver.cpp:228] Iteration 147200, loss = 0.00145345
I0624 04:25:48.145512 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00145368 (* 1 = 0.00145368 loss)
I0624 04:25:48.145524 17898 sgd_solver.cpp:106] Iteration 147200, lr = 0.01
I0624 04:42:33.034509 17898 solver.cpp:337] Iteration 147600, Testing net (#0)
I0624 04:43:36.511883 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938828
I0624 04:43:36.512121 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.284732 (* 1 = 0.284732 loss)
I0624 04:43:38.999339 17898 solver.cpp:228] Iteration 147600, loss = 0.00042486
I0624 04:43:38.999405 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000425096 (* 1 = 0.000425096 loss)
I0624 04:43:38.999421 17898 sgd_solver.cpp:106] Iteration 147600, lr = 0.01
I0624 05:00:22.951207 17898 solver.cpp:337] Iteration 148000, Testing net (#0)
I0624 05:01:26.229023 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.93875
I0624 05:01:26.229214 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.279455 (* 1 = 0.279455 loss)
I0624 05:01:28.712826 17898 solver.cpp:228] Iteration 148000, loss = 0.00187431
I0624 05:01:28.712869 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00187455 (* 1 = 0.00187455 loss)
I0624 05:01:28.712880 17898 sgd_solver.cpp:106] Iteration 148000, lr = 0.01
I0624 05:18:12.928110 17898 solver.cpp:337] Iteration 148400, Testing net (#0)
I0624 05:19:16.142933 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938984
I0624 05:19:16.143154 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.282658 (* 1 = 0.282658 loss)
I0624 05:19:18.626036 17898 solver.cpp:228] Iteration 148400, loss = 0.00114429
I0624 05:19:18.626103 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00114453 (* 1 = 0.00114453 loss)
I0624 05:19:18.626119 17898 sgd_solver.cpp:106] Iteration 148400, lr = 0.01
I0624 05:36:02.921773 17898 solver.cpp:337] Iteration 148800, Testing net (#0)
I0624 05:37:06.279688 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936953
I0624 05:37:06.279892 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.288754 (* 1 = 0.288754 loss)
I0624 05:37:08.750808 17898 solver.cpp:228] Iteration 148800, loss = 0.0013046
I0624 05:37:08.750850 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00130484 (* 1 = 0.00130484 loss)
I0624 05:37:08.750864 17898 sgd_solver.cpp:106] Iteration 148800, lr = 0.01
I0624 05:53:53.716050 17898 solver.cpp:337] Iteration 149200, Testing net (#0)
I0624 05:54:57.123901 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938359
I0624 05:54:57.124078 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.275232 (* 1 = 0.275232 loss)
I0624 05:54:59.606138 17898 solver.cpp:228] Iteration 149200, loss = 0.000774169
I0624 05:54:59.606197 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000774406 (* 1 = 0.000774406 loss)
I0624 05:54:59.606210 17898 sgd_solver.cpp:106] Iteration 149200, lr = 0.01
I0624 06:11:44.717460 17898 solver.cpp:337] Iteration 149600, Testing net (#0)
I0624 06:12:48.133008 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937969
I0624 06:12:48.133186 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.282314 (* 1 = 0.282314 loss)
I0624 06:12:50.627998 17898 solver.cpp:228] Iteration 149600, loss = 0.0004277
I0624 06:12:50.628053 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000427936 (* 1 = 0.000427936 loss)
I0624 06:12:50.628068 17898 sgd_solver.cpp:106] Iteration 149600, lr = 0.01
I0624 06:29:42.534235 17898 solver.cpp:337] Iteration 150000, Testing net (#0)
I0624 06:30:45.877125 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936406
I0624 06:30:45.877351 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.296438 (* 1 = 0.296438 loss)
I0624 06:30:48.350935 17898 solver.cpp:228] Iteration 150000, loss = 0.000799005
I0624 06:30:48.350987 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000799241 (* 1 = 0.000799241 loss)
I0624 06:30:48.350997 17898 sgd_solver.cpp:46] MultiStep Status: Iteration 150000, step = 2
I0624 06:30:48.351003 17898 sgd_solver.cpp:106] Iteration 150000, lr = 0.001
I0624 06:47:33.306471 17898 solver.cpp:337] Iteration 150400, Testing net (#0)
I0624 06:48:36.649116 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938203
I0624 06:48:36.649336 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.280844 (* 1 = 0.280844 loss)
I0624 06:48:39.121081 17898 solver.cpp:228] Iteration 150400, loss = 0.00125062
I0624 06:48:39.121119 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00125085 (* 1 = 0.00125085 loss)
I0624 06:48:39.121132 17898 sgd_solver.cpp:106] Iteration 150400, lr = 0.001
I0624 07:05:26.039818 17898 solver.cpp:337] Iteration 150800, Testing net (#0)
I0624 07:06:29.980696 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937969
I0624 07:06:29.980818 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.273714 (* 1 = 0.273714 loss)
I0624 07:06:32.470209 17898 solver.cpp:228] Iteration 150800, loss = 0.000973309
I0624 07:06:32.470260 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000973544 (* 1 = 0.000973544 loss)
I0624 07:06:32.470273 17898 sgd_solver.cpp:106] Iteration 150800, lr = 0.001
I0624 07:23:20.710305 17898 solver.cpp:337] Iteration 151200, Testing net (#0)
I0624 07:24:24.054373 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939844
I0624 07:24:24.054589 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.273512 (* 1 = 0.273512 loss)
I0624 07:24:26.531399 17898 solver.cpp:228] Iteration 151200, loss = 0.00116531
I0624 07:24:26.531443 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00116554 (* 1 = 0.00116554 loss)
I0624 07:24:26.531455 17898 sgd_solver.cpp:106] Iteration 151200, lr = 0.001
I0624 07:41:15.459918 17898 solver.cpp:337] Iteration 151600, Testing net (#0)
I0624 07:42:18.799505 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936875
I0624 07:42:18.799644 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.285056 (* 1 = 0.285056 loss)
I0624 07:42:21.275135 17898 solver.cpp:228] Iteration 151600, loss = 0.00126922
I0624 07:42:21.275174 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00126946 (* 1 = 0.00126946 loss)
I0624 07:42:21.275187 17898 sgd_solver.cpp:106] Iteration 151600, lr = 0.001
I0624 07:59:13.162230 17898 solver.cpp:337] Iteration 152000, Testing net (#0)
I0624 08:00:16.569012 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940781
I0624 08:00:16.569159 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.263185 (* 1 = 0.263185 loss)
I0624 08:00:19.045851 17898 solver.cpp:228] Iteration 152000, loss = 0.000942896
I0624 08:00:19.045929 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000943132 (* 1 = 0.000943132 loss)
I0624 08:00:19.045953 17898 sgd_solver.cpp:106] Iteration 152000, lr = 0.001
I0624 08:17:04.129154 17898 solver.cpp:337] Iteration 152400, Testing net (#0)
I0624 08:18:07.651190 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939141
I0624 08:18:07.651410 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.268619 (* 1 = 0.268619 loss)
I0624 08:18:10.124052 17898 solver.cpp:228] Iteration 152400, loss = 0.000635176
I0624 08:18:10.124110 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000635413 (* 1 = 0.000635413 loss)
I0624 08:18:10.124122 17898 sgd_solver.cpp:106] Iteration 152400, lr = 0.001
I0624 08:34:55.682205 17898 solver.cpp:337] Iteration 152800, Testing net (#0)
I0624 08:35:59.087015 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938438
I0624 08:35:59.087224 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.278532 (* 1 = 0.278532 loss)
I0624 08:36:01.564060 17898 solver.cpp:228] Iteration 152800, loss = 0.00078916
I0624 08:36:01.564108 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000789397 (* 1 = 0.000789397 loss)
I0624 08:36:01.564131 17898 sgd_solver.cpp:106] Iteration 152800, lr = 0.001
I0624 08:52:46.844933 17898 solver.cpp:337] Iteration 153200, Testing net (#0)
I0624 08:53:50.079567 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.94
I0624 08:53:50.079792 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.27466 (* 1 = 0.27466 loss)
I0624 08:53:52.555517 17898 solver.cpp:228] Iteration 153200, loss = 0.00140506
I0624 08:53:52.555582 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0014053 (* 1 = 0.0014053 loss)
I0624 08:53:52.555593 17898 sgd_solver.cpp:106] Iteration 153200, lr = 0.001
I0624 09:10:37.424438 17898 solver.cpp:337] Iteration 153600, Testing net (#0)
I0624 09:11:40.848184 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940547
I0624 09:11:40.848414 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.261362 (* 1 = 0.261362 loss)
I0624 09:11:43.319690 17898 solver.cpp:228] Iteration 153600, loss = 0.00161764
I0624 09:11:43.319730 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00161788 (* 1 = 0.00161788 loss)
I0624 09:11:43.319742 17898 sgd_solver.cpp:106] Iteration 153600, lr = 0.001
I0624 09:28:28.467342 17898 solver.cpp:337] Iteration 154000, Testing net (#0)
I0624 09:29:31.945305 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939609
I0624 09:29:31.950723 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.267267 (* 1 = 0.267267 loss)
I0624 09:29:34.429297 17898 solver.cpp:228] Iteration 154000, loss = 0.000878829
I0624 09:29:34.429350 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000879065 (* 1 = 0.000879065 loss)
I0624 09:29:34.429364 17898 sgd_solver.cpp:106] Iteration 154000, lr = 0.001
I0624 09:46:19.383852 17898 solver.cpp:337] Iteration 154400, Testing net (#0)
I0624 09:47:22.697862 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938594
I0624 09:47:22.698047 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.273833 (* 1 = 0.273833 loss)
I0624 09:47:25.177606 17898 solver.cpp:228] Iteration 154400, loss = 0.0020659
I0624 09:47:25.177662 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00206613 (* 1 = 0.00206613 loss)
I0624 09:47:25.177673 17898 sgd_solver.cpp:106] Iteration 154400, lr = 0.001
I0624 10:04:10.072955 17898 solver.cpp:337] Iteration 154800, Testing net (#0)
I0624 10:05:13.484969 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940391
I0624 10:05:13.485185 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.260962 (* 1 = 0.260962 loss)
I0624 10:05:15.960605 17898 solver.cpp:228] Iteration 154800, loss = 0.00070993
I0624 10:05:15.960654 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000710166 (* 1 = 0.000710166 loss)
I0624 10:05:15.960666 17898 sgd_solver.cpp:106] Iteration 154800, lr = 0.001
I0624 10:22:01.011247 17898 solver.cpp:337] Iteration 155200, Testing net (#0)
I0624 10:23:04.229876 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940234
I0624 10:23:04.230073 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.267215 (* 1 = 0.267215 loss)
I0624 10:23:06.704493 17898 solver.cpp:228] Iteration 155200, loss = 0.00109541
I0624 10:23:06.704547 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00109565 (* 1 = 0.00109565 loss)
I0624 10:23:06.704561 17898 sgd_solver.cpp:106] Iteration 155200, lr = 0.001
I0624 10:39:51.556622 17898 solver.cpp:337] Iteration 155600, Testing net (#0)
I0624 10:40:54.910240 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939609
I0624 10:40:54.910481 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.272457 (* 1 = 0.272457 loss)
I0624 10:40:57.382673 17898 solver.cpp:228] Iteration 155600, loss = 0.000738691
I0624 10:40:57.382731 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000738926 (* 1 = 0.000738926 loss)
I0624 10:40:57.382745 17898 sgd_solver.cpp:106] Iteration 155600, lr = 0.001
I0624 10:57:42.458602 17898 solver.cpp:337] Iteration 156000, Testing net (#0)
I0624 10:58:45.707500 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939609
I0624 10:58:45.718428 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.278042 (* 1 = 0.278042 loss)
I0624 10:58:48.193608 17898 solver.cpp:228] Iteration 156000, loss = 0.000585041
I0624 10:58:48.193665 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000585278 (* 1 = 0.000585278 loss)
I0624 10:58:48.193681 17898 sgd_solver.cpp:106] Iteration 156000, lr = 0.001
I0624 11:15:33.434427 17898 solver.cpp:337] Iteration 156400, Testing net (#0)
I0624 11:16:36.833974 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940234
I0624 11:16:36.834152 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.261584 (* 1 = 0.261584 loss)
I0624 11:16:39.312270 17898 solver.cpp:228] Iteration 156400, loss = 0.000695341
I0624 11:16:39.312345 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000695579 (* 1 = 0.000695579 loss)
I0624 11:16:39.312357 17898 sgd_solver.cpp:106] Iteration 156400, lr = 0.001
I0624 11:33:24.234076 17898 solver.cpp:337] Iteration 156800, Testing net (#0)
I0624 11:34:27.608759 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938516
I0624 11:34:27.608893 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.280318 (* 1 = 0.280318 loss)
I0624 11:34:30.086052 17898 solver.cpp:228] Iteration 156800, loss = 0.000963548
I0624 11:34:30.086108 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000963785 (* 1 = 0.000963785 loss)
I0624 11:34:30.086120 17898 sgd_solver.cpp:106] Iteration 156800, lr = 0.001
I0624 11:51:14.498641 17898 solver.cpp:337] Iteration 157200, Testing net (#0)
I0624 11:52:17.856323 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939531
I0624 11:52:17.856554 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.275055 (* 1 = 0.275055 loss)
I0624 11:52:20.337635 17898 solver.cpp:228] Iteration 157200, loss = 0.000718387
I0624 11:52:20.337677 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000718623 (* 1 = 0.000718623 loss)
I0624 11:52:20.337692 17898 sgd_solver.cpp:106] Iteration 157200, lr = 0.001
I0624 12:09:05.515122 17898 solver.cpp:337] Iteration 157600, Testing net (#0)
I0624 12:10:08.934545 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939297
I0624 12:10:08.934788 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.271796 (* 1 = 0.271796 loss)
I0624 12:10:11.395490 17898 solver.cpp:228] Iteration 157600, loss = 0.00307771
I0624 12:10:11.395553 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00307794 (* 1 = 0.00307794 loss)
I0624 12:10:11.395570 17898 sgd_solver.cpp:106] Iteration 157600, lr = 0.001
I0624 12:26:56.549546 17898 solver.cpp:337] Iteration 158000, Testing net (#0)
I0624 12:27:59.939693 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.941016
I0624 12:27:59.939929 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.265956 (* 1 = 0.265956 loss)
I0624 12:28:02.412855 17898 solver.cpp:228] Iteration 158000, loss = 0.00180451
I0624 12:28:02.412943 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00180475 (* 1 = 0.00180475 loss)
I0624 12:28:02.412966 17898 sgd_solver.cpp:106] Iteration 158000, lr = 0.001
I0624 12:44:47.826714 17898 solver.cpp:337] Iteration 158400, Testing net (#0)
I0624 12:45:51.233860 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939766
I0624 12:45:51.234092 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.270039 (* 1 = 0.270039 loss)
I0624 12:45:53.708346 17898 solver.cpp:228] Iteration 158400, loss = 0.00138067
I0624 12:45:53.708410 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00138091 (* 1 = 0.00138091 loss)
I0624 12:45:53.708422 17898 sgd_solver.cpp:106] Iteration 158400, lr = 0.001
I0624 13:02:38.828455 17898 solver.cpp:337] Iteration 158800, Testing net (#0)
I0624 13:03:42.248915 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939375
I0624 13:03:42.249130 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.277062 (* 1 = 0.277062 loss)
I0624 13:03:44.719594 17898 solver.cpp:228] Iteration 158800, loss = 0.000826853
I0624 13:03:44.719642 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000827091 (* 1 = 0.000827091 loss)
I0624 13:03:44.719655 17898 sgd_solver.cpp:106] Iteration 158800, lr = 0.001
I0624 13:20:29.876919 17898 solver.cpp:337] Iteration 159200, Testing net (#0)
I0624 13:21:33.246762 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.942109
I0624 13:21:33.246919 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.253644 (* 1 = 0.253644 loss)
I0624 13:21:35.731995 17898 solver.cpp:228] Iteration 159200, loss = 0.000967299
I0624 13:21:35.732043 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000967537 (* 1 = 0.000967537 loss)
I0624 13:21:35.732055 17898 sgd_solver.cpp:106] Iteration 159200, lr = 0.001
I0624 13:38:20.750485 17898 solver.cpp:337] Iteration 159600, Testing net (#0)
I0624 13:39:24.136858 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938906
I0624 13:39:24.136994 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.277366 (* 1 = 0.277366 loss)
I0624 13:39:26.623023 17898 solver.cpp:228] Iteration 159600, loss = 0.000569431
I0624 13:39:26.623069 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000569668 (* 1 = 0.000569668 loss)
I0624 13:39:26.623081 17898 sgd_solver.cpp:106] Iteration 159600, lr = 0.001
I0624 13:56:11.105612 17898 solver.cpp:337] Iteration 160000, Testing net (#0)
I0624 13:57:14.331056 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939766
I0624 13:57:14.331272 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.282553 (* 1 = 0.282553 loss)
I0624 13:57:16.810853 17898 solver.cpp:228] Iteration 160000, loss = 0.00141786
I0624 13:57:16.810896 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0014181 (* 1 = 0.0014181 loss)
I0624 13:57:16.810907 17898 sgd_solver.cpp:106] Iteration 160000, lr = 0.001
I0624 14:14:00.307837 17898 solver.cpp:337] Iteration 160400, Testing net (#0)
I0624 14:15:03.523998 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938516
I0624 14:15:03.524195 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.275774 (* 1 = 0.275774 loss)
I0624 14:15:05.994737 17898 solver.cpp:228] Iteration 160400, loss = 0.00144378
I0624 14:15:05.994786 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00144401 (* 1 = 0.00144401 loss)
I0624 14:15:05.994797 17898 sgd_solver.cpp:106] Iteration 160400, lr = 0.001
I0624 14:31:50.789407 17898 solver.cpp:337] Iteration 160800, Testing net (#0)
I0624 14:32:54.177785 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940547
I0624 14:32:54.178020 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.266407 (* 1 = 0.266407 loss)
I0624 14:32:56.655416 17898 solver.cpp:228] Iteration 160800, loss = 0.000558753
I0624 14:32:56.655458 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000558989 (* 1 = 0.000558989 loss)
I0624 14:32:56.655470 17898 sgd_solver.cpp:106] Iteration 160800, lr = 0.001
I0624 14:49:45.630379 17898 solver.cpp:337] Iteration 161200, Testing net (#0)
I0624 14:50:49.542320 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938984
I0624 14:50:49.542531 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.274856 (* 1 = 0.274856 loss)
I0624 14:50:52.011881 17898 solver.cpp:228] Iteration 161200, loss = 0.00120213
I0624 14:50:52.011922 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00120236 (* 1 = 0.00120236 loss)
I0624 14:50:52.011934 17898 sgd_solver.cpp:106] Iteration 161200, lr = 0.001
I0624 15:07:41.119235 17898 solver.cpp:337] Iteration 161600, Testing net (#0)
I0624 15:08:44.712007 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938516
I0624 15:08:44.712235 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.278308 (* 1 = 0.278308 loss)
I0624 15:08:47.180032 17898 solver.cpp:228] Iteration 161600, loss = 0.000832038
I0624 15:08:47.180078 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000832274 (* 1 = 0.000832274 loss)
I0624 15:08:47.180090 17898 sgd_solver.cpp:106] Iteration 161600, lr = 0.001
I0624 15:25:36.894295 17898 solver.cpp:337] Iteration 162000, Testing net (#0)
I0624 15:26:40.804853 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.941641
I0624 15:26:40.805073 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.257355 (* 1 = 0.257355 loss)
I0624 15:26:43.269209 17898 solver.cpp:228] Iteration 162000, loss = 0.00114281
I0624 15:26:43.269248 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00114304 (* 1 = 0.00114304 loss)
I0624 15:26:43.269261 17898 sgd_solver.cpp:106] Iteration 162000, lr = 0.001
I0624 15:43:30.974223 17898 solver.cpp:337] Iteration 162400, Testing net (#0)
I0624 15:44:34.416050 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940781
I0624 15:44:34.416296 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.262648 (* 1 = 0.262648 loss)
I0624 15:44:36.879659 17898 solver.cpp:228] Iteration 162400, loss = 0.00216483
I0624 15:44:36.879703 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00216506 (* 1 = 0.00216506 loss)
I0624 15:44:36.879716 17898 sgd_solver.cpp:106] Iteration 162400, lr = 0.001
I0624 16:01:22.110345 17898 solver.cpp:337] Iteration 162800, Testing net (#0)
I0624 16:02:25.349467 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.941016
I0624 16:02:25.349668 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.27382 (* 1 = 0.27382 loss)
I0624 16:02:27.828903 17898 solver.cpp:228] Iteration 162800, loss = 0.000387232
I0624 16:02:27.828949 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000387468 (* 1 = 0.000387468 loss)
I0624 16:02:27.828961 17898 sgd_solver.cpp:106] Iteration 162800, lr = 0.001
I0624 16:19:09.546444 17898 solver.cpp:337] Iteration 163200, Testing net (#0)
I0624 16:20:12.672076 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938984
I0624 16:20:12.672292 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.272942 (* 1 = 0.272942 loss)
I0624 16:20:15.142768 17898 solver.cpp:228] Iteration 163200, loss = 0.00107892
I0624 16:20:15.142802 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00107916 (* 1 = 0.00107916 loss)
I0624 16:20:15.142812 17898 sgd_solver.cpp:106] Iteration 163200, lr = 0.001
I0624 16:36:55.958346 17898 solver.cpp:337] Iteration 163600, Testing net (#0)
I0624 16:37:59.029068 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.941406
I0624 16:37:59.029232 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.260219 (* 1 = 0.260219 loss)
I0624 16:38:01.493033 17898 solver.cpp:228] Iteration 163600, loss = 0.001603
I0624 16:38:01.493067 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00160323 (* 1 = 0.00160323 loss)
I0624 16:38:01.493077 17898 sgd_solver.cpp:106] Iteration 163600, lr = 0.001
I0624 16:54:48.456933 17898 solver.cpp:337] Iteration 164000, Testing net (#0)
I0624 16:55:51.720984 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940078
I0624 16:55:51.721204 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.272369 (* 1 = 0.272369 loss)
I0624 16:55:54.207834 17898 solver.cpp:228] Iteration 164000, loss = 0.000581082
I0624 16:55:54.207877 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000581318 (* 1 = 0.000581318 loss)
I0624 16:55:54.207890 17898 sgd_solver.cpp:106] Iteration 164000, lr = 0.001
I0624 17:12:40.422183 17898 solver.cpp:337] Iteration 164400, Testing net (#0)
I0624 17:13:43.670064 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939062
I0624 17:13:43.670229 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.27576 (* 1 = 0.27576 loss)
I0624 17:13:46.165834 17898 solver.cpp:228] Iteration 164400, loss = 0.000903318
I0624 17:13:46.165876 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000903554 (* 1 = 0.000903554 loss)
I0624 17:13:46.165886 17898 sgd_solver.cpp:106] Iteration 164400, lr = 0.001
I0624 17:30:31.979733 17898 solver.cpp:337] Iteration 164800, Testing net (#0)
I0624 17:31:35.286212 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.942109
I0624 17:31:35.286420 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.264088 (* 1 = 0.264088 loss)
I0624 17:31:37.766450 17898 solver.cpp:228] Iteration 164800, loss = 0.00102688
I0624 17:31:37.766490 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00102712 (* 1 = 0.00102712 loss)
I0624 17:31:37.766513 17898 sgd_solver.cpp:106] Iteration 164800, lr = 0.001
I0624 17:48:23.649102 17898 solver.cpp:337] Iteration 165200, Testing net (#0)
I0624 17:49:27.000337 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940391
I0624 17:49:27.000551 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.270794 (* 1 = 0.270794 loss)
I0624 17:49:29.487175 17898 solver.cpp:228] Iteration 165200, loss = 0.00136434
I0624 17:49:29.487217 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00136458 (* 1 = 0.00136458 loss)
I0624 17:49:29.487228 17898 sgd_solver.cpp:106] Iteration 165200, lr = 0.001
I0624 18:06:15.426692 17898 solver.cpp:337] Iteration 165600, Testing net (#0)
I0624 18:07:18.671571 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939531
I0624 18:07:18.671773 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.274954 (* 1 = 0.274954 loss)
I0624 18:07:21.150671 17898 solver.cpp:228] Iteration 165600, loss = 0.00111388
I0624 18:07:21.150699 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00111411 (* 1 = 0.00111411 loss)
I0624 18:07:21.150709 17898 sgd_solver.cpp:106] Iteration 165600, lr = 0.001
I0624 18:24:06.885224 17898 solver.cpp:337] Iteration 166000, Testing net (#0)
I0624 18:25:10.139518 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940625
I0624 18:25:10.139675 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.275084 (* 1 = 0.275084 loss)
I0624 18:25:12.618577 17898 solver.cpp:228] Iteration 166000, loss = 0.000829577
I0624 18:25:12.618616 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000829814 (* 1 = 0.000829814 loss)
I0624 18:25:12.618628 17898 sgd_solver.cpp:106] Iteration 166000, lr = 0.001
I0624 18:41:58.600651 17898 solver.cpp:337] Iteration 166400, Testing net (#0)
I0624 18:43:01.851889 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.941016
I0624 18:43:01.852107 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.261751 (* 1 = 0.261751 loss)
I0624 18:43:04.337257 17898 solver.cpp:228] Iteration 166400, loss = 0.00143461
I0624 18:43:04.337306 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00143485 (* 1 = 0.00143485 loss)
I0624 18:43:04.337317 17898 sgd_solver.cpp:106] Iteration 166400, lr = 0.001
I0624 18:59:50.657779 17898 solver.cpp:337] Iteration 166800, Testing net (#0)
I0624 19:00:53.920584 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939609
I0624 19:00:53.920788 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.273568 (* 1 = 0.273568 loss)
I0624 19:00:56.402655 17898 solver.cpp:228] Iteration 166800, loss = 0.000863641
I0624 19:00:56.402696 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000863878 (* 1 = 0.000863878 loss)
I0624 19:00:56.402709 17898 sgd_solver.cpp:106] Iteration 166800, lr = 0.001
I0624 19:17:42.370167 17898 solver.cpp:337] Iteration 167200, Testing net (#0)
I0624 19:18:45.628535 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938828
I0624 19:18:45.628674 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.279951 (* 1 = 0.279951 loss)
I0624 19:18:48.109825 17898 solver.cpp:228] Iteration 167200, loss = 0.00121721
I0624 19:18:48.109866 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00121744 (* 1 = 0.00121744 loss)
I0624 19:18:48.109877 17898 sgd_solver.cpp:106] Iteration 167200, lr = 0.001
I0624 19:35:34.014623 17898 solver.cpp:337] Iteration 167600, Testing net (#0)
I0624 19:36:37.214090 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.941094
I0624 19:36:37.214298 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.271977 (* 1 = 0.271977 loss)
I0624 19:36:39.701164 17898 solver.cpp:228] Iteration 167600, loss = 0.000502112
I0624 19:36:39.701210 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000502348 (* 1 = 0.000502348 loss)
I0624 19:36:39.701222 17898 sgd_solver.cpp:106] Iteration 167600, lr = 0.001
I0624 19:53:25.976502 17898 solver.cpp:337] Iteration 168000, Testing net (#0)
I0624 19:54:29.264520 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.942266
I0624 19:54:29.264729 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.264017 (* 1 = 0.264017 loss)
I0624 19:54:31.742808 17898 solver.cpp:228] Iteration 168000, loss = 0.00196321
I0624 19:54:31.742861 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00196344 (* 1 = 0.00196344 loss)
I0624 19:54:31.742874 17898 sgd_solver.cpp:106] Iteration 168000, lr = 0.001
I0624 20:11:17.655971 17898 solver.cpp:337] Iteration 168400, Testing net (#0)
I0624 20:12:20.884462 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940391
I0624 20:12:20.884660 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.267848 (* 1 = 0.267848 loss)
I0624 20:12:23.366308 17898 solver.cpp:228] Iteration 168400, loss = 0.000916497
I0624 20:12:23.366349 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000916733 (* 1 = 0.000916733 loss)
I0624 20:12:23.366366 17898 sgd_solver.cpp:106] Iteration 168400, lr = 0.001
I0624 20:29:08.898850 17898 solver.cpp:337] Iteration 168800, Testing net (#0)
I0624 20:30:12.150187 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939922
I0624 20:30:12.150427 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.277508 (* 1 = 0.277508 loss)
I0624 20:30:14.631091 17898 solver.cpp:228] Iteration 168800, loss = 0.00120475
I0624 20:30:14.631129 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00120499 (* 1 = 0.00120499 loss)
I0624 20:30:14.631141 17898 sgd_solver.cpp:106] Iteration 168800, lr = 0.001
I0624 20:47:00.431257 17898 solver.cpp:337] Iteration 169200, Testing net (#0)
I0624 20:48:03.687701 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939687
I0624 20:48:03.687896 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.257532 (* 1 = 0.257532 loss)
I0624 20:48:06.171897 17898 solver.cpp:228] Iteration 169200, loss = 0.00046369
I0624 20:48:06.171934 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000463926 (* 1 = 0.000463926 loss)
I0624 20:48:06.171944 17898 sgd_solver.cpp:106] Iteration 169200, lr = 0.001
I0624 21:04:52.022917 17898 solver.cpp:337] Iteration 169600, Testing net (#0)
I0624 21:05:55.300390 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.942422
I0624 21:05:55.300580 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.267139 (* 1 = 0.267139 loss)
I0624 21:05:57.792621 17898 solver.cpp:228] Iteration 169600, loss = 0.000490968
I0624 21:05:57.792665 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000491204 (* 1 = 0.000491204 loss)
I0624 21:05:57.792676 17898 sgd_solver.cpp:106] Iteration 169600, lr = 0.001
I0624 21:22:43.761487 17898 solver.cpp:337] Iteration 170000, Testing net (#0)
I0624 21:23:46.968403 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938984
I0624 21:23:46.968611 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.270776 (* 1 = 0.270776 loss)
I0624 21:23:49.463104 17898 solver.cpp:228] Iteration 170000, loss = 0.000410638
I0624 21:23:49.463143 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000410874 (* 1 = 0.000410874 loss)
I0624 21:23:49.463155 17898 sgd_solver.cpp:106] Iteration 170000, lr = 0.001
I0624 21:40:35.651588 17898 solver.cpp:337] Iteration 170400, Testing net (#0)
I0624 21:41:38.878990 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939609
I0624 21:41:38.879199 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.275826 (* 1 = 0.275826 loss)
I0624 21:41:41.360051 17898 solver.cpp:228] Iteration 170400, loss = 0.000584748
I0624 21:41:41.360091 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000584984 (* 1 = 0.000584984 loss)
I0624 21:41:41.360102 17898 sgd_solver.cpp:106] Iteration 170400, lr = 0.001
I0624 21:58:26.966686 17898 solver.cpp:337] Iteration 170800, Testing net (#0)
I0624 21:59:30.243381 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.941016
I0624 21:59:30.243609 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.260481 (* 1 = 0.260481 loss)
I0624 21:59:32.731492 17898 solver.cpp:228] Iteration 170800, loss = 0.00120175
I0624 21:59:32.731526 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00120198 (* 1 = 0.00120198 loss)
I0624 21:59:32.731537 17898 sgd_solver.cpp:106] Iteration 170800, lr = 0.001
I0624 22:16:18.757071 17898 solver.cpp:337] Iteration 171200, Testing net (#0)
I0624 22:17:22.044776 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939844
I0624 22:17:22.044967 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.276501 (* 1 = 0.276501 loss)
I0624 22:17:24.524770 17898 solver.cpp:228] Iteration 171200, loss = 0.000579656
I0624 22:17:24.524809 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000579892 (* 1 = 0.000579892 loss)
I0624 22:17:24.524821 17898 sgd_solver.cpp:106] Iteration 171200, lr = 0.001
I0624 22:34:09.775313 17898 solver.cpp:337] Iteration 171600, Testing net (#0)
I0624 22:35:12.999001 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940391
I0624 22:35:12.999210 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.274682 (* 1 = 0.274682 loss)
I0624 22:35:15.471020 17898 solver.cpp:228] Iteration 171600, loss = 0.000856678
I0624 22:35:15.471061 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000856914 (* 1 = 0.000856914 loss)
I0624 22:35:15.471073 17898 sgd_solver.cpp:106] Iteration 171600, lr = 0.001
I0624 22:52:01.373214 17898 solver.cpp:337] Iteration 172000, Testing net (#0)
I0624 22:53:04.637941 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.941562
I0624 22:53:04.638130 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.262402 (* 1 = 0.262402 loss)
I0624 22:53:07.117777 17898 solver.cpp:228] Iteration 172000, loss = 0.000856544
I0624 22:53:07.117815 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00085678 (* 1 = 0.00085678 loss)
I0624 22:53:07.117826 17898 sgd_solver.cpp:106] Iteration 172000, lr = 0.001
I0624 23:09:53.129053 17898 solver.cpp:337] Iteration 172400, Testing net (#0)
I0624 23:10:56.459115 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938672
I0624 23:10:56.459314 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.273662 (* 1 = 0.273662 loss)
I0624 23:10:58.939687 17898 solver.cpp:228] Iteration 172400, loss = 0.000526033
I0624 23:10:58.939728 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000526269 (* 1 = 0.000526269 loss)
I0624 23:10:58.939738 17898 sgd_solver.cpp:106] Iteration 172400, lr = 0.001
I0624 23:27:42.696239 17898 solver.cpp:337] Iteration 172800, Testing net (#0)
I0624 23:28:45.897783 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937891
I0624 23:28:45.897979 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.281025 (* 1 = 0.281025 loss)
I0624 23:28:48.380331 17898 solver.cpp:228] Iteration 172800, loss = 0.000773043
I0624 23:28:48.380380 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000773279 (* 1 = 0.000773279 loss)
I0624 23:28:48.380393 17898 sgd_solver.cpp:106] Iteration 172800, lr = 0.001
I0624 23:45:31.888499 17898 solver.cpp:337] Iteration 173200, Testing net (#0)
I0624 23:46:35.117878 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.941797
I0624 23:46:35.119550 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.268711 (* 1 = 0.268711 loss)
I0624 23:46:37.592964 17898 solver.cpp:228] Iteration 173200, loss = 0.00052277
I0624 23:46:37.593004 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000523006 (* 1 = 0.000523006 loss)
I0624 23:46:37.593019 17898 sgd_solver.cpp:106] Iteration 173200, lr = 0.001
I0625 00:03:20.884676 17898 solver.cpp:337] Iteration 173600, Testing net (#0)
I0625 00:04:24.094210 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940625
I0625 00:04:24.094530 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.263169 (* 1 = 0.263169 loss)
I0625 00:04:26.577941 17898 solver.cpp:228] Iteration 173600, loss = 0.000600683
I0625 00:04:26.577986 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000600918 (* 1 = 0.000600918 loss)
I0625 00:04:26.577996 17898 sgd_solver.cpp:106] Iteration 173600, lr = 0.001
I0625 00:21:10.732223 17898 solver.cpp:337] Iteration 174000, Testing net (#0)
I0625 00:22:13.966274 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940938
I0625 00:22:13.966533 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.275741 (* 1 = 0.275741 loss)
I0625 00:22:16.440728 17898 solver.cpp:228] Iteration 174000, loss = 0.000397515
I0625 00:22:16.440783 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000397751 (* 1 = 0.000397751 loss)
I0625 00:22:16.440798 17898 sgd_solver.cpp:106] Iteration 174000, lr = 0.001
I0625 00:39:00.049993 17898 solver.cpp:337] Iteration 174400, Testing net (#0)
I0625 00:40:03.219985 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938828
I0625 00:40:03.220191 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.28304 (* 1 = 0.28304 loss)
I0625 00:40:05.696559 17898 solver.cpp:228] Iteration 174400, loss = 0.000237834
I0625 00:40:05.696601 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00023807 (* 1 = 0.00023807 loss)
I0625 00:40:05.696612 17898 sgd_solver.cpp:106] Iteration 174400, lr = 0.001
I0625 00:56:49.464037 17898 solver.cpp:337] Iteration 174800, Testing net (#0)
I0625 00:57:52.685734 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.942109
I0625 00:57:52.685919 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.258908 (* 1 = 0.258908 loss)
I0625 00:57:55.162384 17898 solver.cpp:228] Iteration 174800, loss = 0.000629016
I0625 00:57:55.162431 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000629251 (* 1 = 0.000629251 loss)
I0625 00:57:55.162442 17898 sgd_solver.cpp:106] Iteration 174800, lr = 0.001
I0625 01:14:38.715152 17898 solver.cpp:337] Iteration 175200, Testing net (#0)
I0625 01:15:41.916112 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940313
I0625 01:15:41.916306 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.258529 (* 1 = 0.258529 loss)
I0625 01:15:44.392181 17898 solver.cpp:228] Iteration 175200, loss = 0.00144026
I0625 01:15:44.392226 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0014405 (* 1 = 0.0014405 loss)
I0625 01:15:44.392238 17898 sgd_solver.cpp:106] Iteration 175200, lr = 0.001
I0625 01:32:27.980453 17898 solver.cpp:337] Iteration 175600, Testing net (#0)
I0625 01:33:31.238472 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939219
I0625 01:33:31.238678 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.271915 (* 1 = 0.271915 loss)
I0625 01:33:33.708323 17898 solver.cpp:228] Iteration 175600, loss = 0.00069879
I0625 01:33:33.708372 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000699025 (* 1 = 0.000699025 loss)
I0625 01:33:33.708384 17898 sgd_solver.cpp:106] Iteration 175600, lr = 0.001
I0625 01:50:17.355412 17898 solver.cpp:337] Iteration 176000, Testing net (#0)
I0625 01:51:20.540004 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939062
I0625 01:51:20.546427 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.284156 (* 1 = 0.284156 loss)
I0625 01:51:23.010570 17898 solver.cpp:228] Iteration 176000, loss = 0.000537565
I0625 01:51:23.010615 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000537801 (* 1 = 0.000537801 loss)
I0625 01:51:23.010628 17898 sgd_solver.cpp:106] Iteration 176000, lr = 0.001
I0625 02:08:06.656612 17898 solver.cpp:337] Iteration 176400, Testing net (#0)
I0625 02:09:09.807577 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940703
I0625 02:09:09.807776 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.263293 (* 1 = 0.263293 loss)
I0625 02:09:12.279950 17898 solver.cpp:228] Iteration 176400, loss = 0.000895296
I0625 02:09:12.280001 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000895532 (* 1 = 0.000895532 loss)
I0625 02:09:12.280017 17898 sgd_solver.cpp:106] Iteration 176400, lr = 0.001
I0625 02:25:55.816076 17898 solver.cpp:337] Iteration 176800, Testing net (#0)
I0625 02:26:59.005928 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938438
I0625 02:26:59.006148 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.276152 (* 1 = 0.276152 loss)
I0625 02:27:01.477613 17898 solver.cpp:228] Iteration 176800, loss = 0.000893209
I0625 02:27:01.477668 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000893445 (* 1 = 0.000893445 loss)
I0625 02:27:01.477680 17898 sgd_solver.cpp:106] Iteration 176800, lr = 0.001
I0625 02:43:45.176728 17898 solver.cpp:337] Iteration 177200, Testing net (#0)
I0625 02:44:48.377337 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.936953
I0625 02:44:48.377523 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.275116 (* 1 = 0.275116 loss)
I0625 02:44:50.854465 17898 solver.cpp:228] Iteration 177200, loss = 0.00066132
I0625 02:44:50.854511 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000661555 (* 1 = 0.000661555 loss)
I0625 02:44:50.854523 17898 sgd_solver.cpp:106] Iteration 177200, lr = 0.001
I0625 03:01:34.460012 17898 solver.cpp:337] Iteration 177600, Testing net (#0)
I0625 03:02:37.654592 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939219
I0625 03:02:37.654808 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.274702 (* 1 = 0.274702 loss)
I0625 03:02:40.123564 17898 solver.cpp:228] Iteration 177600, loss = 0.000900696
I0625 03:02:40.123616 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000900931 (* 1 = 0.000900931 loss)
I0625 03:02:40.123628 17898 sgd_solver.cpp:106] Iteration 177600, lr = 0.001
I0625 03:19:23.448765 17898 solver.cpp:337] Iteration 178000, Testing net (#0)
I0625 03:20:26.628904 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.941172
I0625 03:20:26.629112 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.260509 (* 1 = 0.260509 loss)
I0625 03:20:29.105273 17898 solver.cpp:228] Iteration 178000, loss = 0.00118701
I0625 03:20:29.105319 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00118725 (* 1 = 0.00118725 loss)
I0625 03:20:29.105330 17898 sgd_solver.cpp:106] Iteration 178000, lr = 0.001
I0625 03:37:12.197113 17898 solver.cpp:337] Iteration 178400, Testing net (#0)
I0625 03:38:15.418879 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939062
I0625 03:38:15.419078 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.279639 (* 1 = 0.279639 loss)
I0625 03:38:17.893584 17898 solver.cpp:228] Iteration 178400, loss = 0.00086122
I0625 03:38:17.893642 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000861455 (* 1 = 0.000861455 loss)
I0625 03:38:17.893654 17898 sgd_solver.cpp:106] Iteration 178400, lr = 0.001
I0625 03:55:01.189790 17898 solver.cpp:337] Iteration 178800, Testing net (#0)
I0625 03:56:04.415137 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.93875
I0625 03:56:04.415307 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.278626 (* 1 = 0.278626 loss)
I0625 03:56:06.886266 17898 solver.cpp:228] Iteration 178800, loss = 0.000754868
I0625 03:56:06.886330 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000755103 (* 1 = 0.000755103 loss)
I0625 03:56:06.886343 17898 sgd_solver.cpp:106] Iteration 178800, lr = 0.001
I0625 04:12:51.121737 17898 solver.cpp:337] Iteration 179200, Testing net (#0)
I0625 04:13:54.504096 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.941953
I0625 04:13:54.504293 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.254314 (* 1 = 0.254314 loss)
I0625 04:13:56.977469 17898 solver.cpp:228] Iteration 179200, loss = 0.000315141
I0625 04:13:56.977519 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000315375 (* 1 = 0.000315375 loss)
I0625 04:13:56.977532 17898 sgd_solver.cpp:106] Iteration 179200, lr = 0.001
I0625 04:30:40.803881 17898 solver.cpp:337] Iteration 179600, Testing net (#0)
I0625 04:31:44.016424 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939062
I0625 04:31:44.016629 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.266791 (* 1 = 0.266791 loss)
I0625 04:31:46.482667 17898 solver.cpp:228] Iteration 179600, loss = 0.0004951
I0625 04:31:46.482717 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000495335 (* 1 = 0.000495335 loss)
I0625 04:31:46.482728 17898 sgd_solver.cpp:106] Iteration 179600, lr = 0.001
I0625 04:48:29.894801 17898 solver.cpp:337] Iteration 180000, Testing net (#0)
I0625 04:49:33.053200 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939453
I0625 04:49:33.053411 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.269472 (* 1 = 0.269472 loss)
I0625 04:49:35.528288 17898 solver.cpp:228] Iteration 180000, loss = 0.000447433
I0625 04:49:35.528331 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000447668 (* 1 = 0.000447668 loss)
I0625 04:49:35.528342 17898 sgd_solver.cpp:106] Iteration 180000, lr = 0.001
I0625 05:06:18.909448 17898 solver.cpp:337] Iteration 180400, Testing net (#0)
I0625 05:07:22.129111 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939687
I0625 05:07:22.129305 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.275449 (* 1 = 0.275449 loss)
I0625 05:07:24.609000 17898 solver.cpp:228] Iteration 180400, loss = 0.00100226
I0625 05:07:24.609046 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00100249 (* 1 = 0.00100249 loss)
I0625 05:07:24.609058 17898 sgd_solver.cpp:106] Iteration 180400, lr = 0.001
I0625 05:24:07.945575 17898 solver.cpp:337] Iteration 180800, Testing net (#0)
I0625 05:25:11.190101 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.942344
I0625 05:25:11.190307 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.260327 (* 1 = 0.260327 loss)
I0625 05:25:13.655830 17898 solver.cpp:228] Iteration 180800, loss = 0.000413683
I0625 05:25:13.655869 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000413918 (* 1 = 0.000413918 loss)
I0625 05:25:13.655880 17898 sgd_solver.cpp:106] Iteration 180800, lr = 0.001
I0625 05:41:57.163193 17898 solver.cpp:337] Iteration 181200, Testing net (#0)
I0625 05:43:00.406316 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940547
I0625 05:43:00.406782 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.276288 (* 1 = 0.276288 loss)
I0625 05:43:02.877825 17898 solver.cpp:228] Iteration 181200, loss = 0.000438362
I0625 05:43:02.877876 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000438597 (* 1 = 0.000438597 loss)
I0625 05:43:02.877890 17898 sgd_solver.cpp:106] Iteration 181200, lr = 0.001
I0625 05:59:47.105311 17898 solver.cpp:337] Iteration 181600, Testing net (#0)
I0625 06:00:50.524260 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938984
I0625 06:00:50.524471 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.275591 (* 1 = 0.275591 loss)
I0625 06:00:52.997144 17898 solver.cpp:228] Iteration 181600, loss = 0.00121295
I0625 06:00:52.997210 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00121319 (* 1 = 0.00121319 loss)
I0625 06:00:52.997233 17898 sgd_solver.cpp:106] Iteration 181600, lr = 0.001
I0625 06:17:37.349879 17898 solver.cpp:337] Iteration 182000, Testing net (#0)
I0625 06:18:40.580322 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940547
I0625 06:18:40.580543 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.264815 (* 1 = 0.264815 loss)
I0625 06:18:43.068068 17898 solver.cpp:228] Iteration 182000, loss = 0.000780426
I0625 06:18:43.068148 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000780663 (* 1 = 0.000780663 loss)
I0625 06:18:43.068164 17898 sgd_solver.cpp:106] Iteration 182000, lr = 0.001
I0625 06:35:27.010663 17898 solver.cpp:337] Iteration 182400, Testing net (#0)
I0625 06:36:30.236552 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.94
I0625 06:36:30.236745 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.271416 (* 1 = 0.271416 loss)
I0625 06:36:32.711558 17898 solver.cpp:228] Iteration 182400, loss = 0.00129393
I0625 06:36:32.711606 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00129417 (* 1 = 0.00129417 loss)
I0625 06:36:32.711617 17898 sgd_solver.cpp:106] Iteration 182400, lr = 0.001
I0625 06:53:15.969821 17898 solver.cpp:337] Iteration 182800, Testing net (#0)
I0625 06:54:19.227195 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938984
I0625 06:54:19.227421 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.278124 (* 1 = 0.278124 loss)
I0625 06:54:21.715600 17898 solver.cpp:228] Iteration 182800, loss = 0.000829879
I0625 06:54:21.715646 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000830117 (* 1 = 0.000830117 loss)
I0625 06:54:21.715657 17898 sgd_solver.cpp:106] Iteration 182800, lr = 0.001
I0625 07:11:05.275269 17898 solver.cpp:337] Iteration 183200, Testing net (#0)
I0625 07:12:08.493757 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939844
I0625 07:12:08.494071 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.275666 (* 1 = 0.275666 loss)
I0625 07:12:10.959508 17898 solver.cpp:228] Iteration 183200, loss = 0.000655168
I0625 07:12:10.959548 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000655406 (* 1 = 0.000655406 loss)
I0625 07:12:10.959560 17898 sgd_solver.cpp:106] Iteration 183200, lr = 0.001
I0625 07:28:54.872944 17898 solver.cpp:337] Iteration 183600, Testing net (#0)
I0625 07:29:58.107600 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.942031
I0625 07:29:58.107787 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.261567 (* 1 = 0.261567 loss)
I0625 07:30:00.580256 17898 solver.cpp:228] Iteration 183600, loss = 0.00119864
I0625 07:30:00.580303 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00119888 (* 1 = 0.00119888 loss)
I0625 07:30:00.580314 17898 sgd_solver.cpp:106] Iteration 183600, lr = 0.001
I0625 07:46:44.216020 17898 solver.cpp:337] Iteration 184000, Testing net (#0)
I0625 07:47:47.420631 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939219
I0625 07:47:47.420837 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.275211 (* 1 = 0.275211 loss)
I0625 07:47:49.902314 17898 solver.cpp:228] Iteration 184000, loss = 0.000582637
I0625 07:47:49.902364 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000582876 (* 1 = 0.000582876 loss)
I0625 07:47:49.902377 17898 sgd_solver.cpp:106] Iteration 184000, lr = 0.001
I0625 08:04:33.297018 17898 solver.cpp:337] Iteration 184400, Testing net (#0)
I0625 08:05:36.522930 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938594
I0625 08:05:36.523113 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.280975 (* 1 = 0.280975 loss)
I0625 08:05:38.995795 17898 solver.cpp:228] Iteration 184400, loss = 0.00166502
I0625 08:05:38.995846 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00166526 (* 1 = 0.00166526 loss)
I0625 08:05:38.995859 17898 sgd_solver.cpp:106] Iteration 184400, lr = 0.001
I0625 08:22:22.667065 17898 solver.cpp:337] Iteration 184800, Testing net (#0)
I0625 08:23:25.870205 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939844
I0625 08:23:25.870435 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.268695 (* 1 = 0.268695 loss)
I0625 08:23:28.350448 17898 solver.cpp:228] Iteration 184800, loss = 0.000418271
I0625 08:23:28.350484 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000418511 (* 1 = 0.000418511 loss)
I0625 08:23:28.350497 17898 sgd_solver.cpp:106] Iteration 184800, lr = 0.001
I0625 08:40:11.605340 17898 solver.cpp:337] Iteration 185200, Testing net (#0)
I0625 08:41:14.807775 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940078
I0625 08:41:14.807981 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.269863 (* 1 = 0.269863 loss)
I0625 08:41:17.280531 17898 solver.cpp:228] Iteration 185200, loss = 0.000669356
I0625 08:41:17.280572 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000669596 (* 1 = 0.000669596 loss)
I0625 08:41:17.280583 17898 sgd_solver.cpp:106] Iteration 185200, lr = 0.001
I0625 08:58:00.726542 17898 solver.cpp:337] Iteration 185600, Testing net (#0)
I0625 08:59:03.908535 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938359
I0625 08:59:03.910476 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.27906 (* 1 = 0.27906 loss)
I0625 08:59:06.387199 17898 solver.cpp:228] Iteration 185600, loss = 0.000869306
I0625 08:59:06.387243 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000869545 (* 1 = 0.000869545 loss)
I0625 08:59:06.387258 17898 sgd_solver.cpp:106] Iteration 185600, lr = 0.001
I0625 09:15:50.023171 17898 solver.cpp:337] Iteration 186000, Testing net (#0)
I0625 09:16:53.227073 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938672
I0625 09:16:53.227264 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.281152 (* 1 = 0.281152 loss)
I0625 09:16:55.697963 17898 solver.cpp:228] Iteration 186000, loss = 0.00112761
I0625 09:16:55.698009 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00112785 (* 1 = 0.00112785 loss)
I0625 09:16:55.698021 17898 sgd_solver.cpp:106] Iteration 186000, lr = 0.001
I0625 09:33:39.043633 17898 solver.cpp:337] Iteration 186400, Testing net (#0)
I0625 09:34:42.245712 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940703
I0625 09:34:42.245913 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.257917 (* 1 = 0.257917 loss)
I0625 09:34:44.729588 17898 solver.cpp:228] Iteration 186400, loss = 0.000824881
I0625 09:34:44.729629 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000825121 (* 1 = 0.000825121 loss)
I0625 09:34:44.729641 17898 sgd_solver.cpp:106] Iteration 186400, lr = 0.001
I0625 09:51:28.150920 17898 solver.cpp:337] Iteration 186800, Testing net (#0)
I0625 09:52:31.364029 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938516
I0625 09:52:31.364218 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.272252 (* 1 = 0.272252 loss)
I0625 09:52:33.834815 17898 solver.cpp:228] Iteration 186800, loss = 0.000956849
I0625 09:52:33.834861 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000957088 (* 1 = 0.000957088 loss)
I0625 09:52:33.834872 17898 sgd_solver.cpp:106] Iteration 186800, lr = 0.001
I0625 10:09:17.553628 17898 solver.cpp:337] Iteration 187200, Testing net (#0)
I0625 10:10:20.759979 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938438
I0625 10:10:20.760187 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.27169 (* 1 = 0.27169 loss)
I0625 10:10:23.233613 17898 solver.cpp:228] Iteration 187200, loss = 0.00145136
I0625 10:10:23.233654 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0014516 (* 1 = 0.0014516 loss)
I0625 10:10:23.233665 17898 sgd_solver.cpp:106] Iteration 187200, lr = 0.001
I0625 10:27:06.694267 17898 solver.cpp:337] Iteration 187600, Testing net (#0)
I0625 10:28:09.934880 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939531
I0625 10:28:09.935104 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.268783 (* 1 = 0.268783 loss)
I0625 10:28:12.412622 17898 solver.cpp:228] Iteration 187600, loss = 0.000837115
I0625 10:28:12.412668 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000837355 (* 1 = 0.000837355 loss)
I0625 10:28:12.412680 17898 sgd_solver.cpp:106] Iteration 187600, lr = 0.001
I0625 10:44:56.008746 17898 solver.cpp:337] Iteration 188000, Testing net (#0)
I0625 10:45:59.277778 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.942187
I0625 10:45:59.278000 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.25736 (* 1 = 0.25736 loss)
I0625 10:46:01.748189 17898 solver.cpp:228] Iteration 188000, loss = 0.00146475
I0625 10:46:01.748251 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00146499 (* 1 = 0.00146499 loss)
I0625 10:46:01.748265 17898 sgd_solver.cpp:106] Iteration 188000, lr = 0.001
I0625 11:02:46.192728 17898 solver.cpp:337] Iteration 188400, Testing net (#0)
I0625 11:03:49.397629 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938906
I0625 11:03:49.397840 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.275145 (* 1 = 0.275145 loss)
I0625 11:03:51.892523 17898 solver.cpp:228] Iteration 188400, loss = 0.0019778
I0625 11:03:51.892575 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00197804 (* 1 = 0.00197804 loss)
I0625 11:03:51.892590 17898 sgd_solver.cpp:106] Iteration 188400, lr = 0.001
I0625 11:20:35.318663 17898 solver.cpp:337] Iteration 188800, Testing net (#0)
I0625 11:21:38.510275 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940156
I0625 11:21:38.510452 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.27757 (* 1 = 0.27757 loss)
I0625 11:21:41.007588 17898 solver.cpp:228] Iteration 188800, loss = 0.00132254
I0625 11:21:41.007642 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00132278 (* 1 = 0.00132278 loss)
I0625 11:21:41.007658 17898 sgd_solver.cpp:106] Iteration 188800, lr = 0.001
I0625 11:38:24.423939 17898 solver.cpp:337] Iteration 189200, Testing net (#0)
I0625 11:39:27.637904 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940547
I0625 11:39:27.638123 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.263723 (* 1 = 0.263723 loss)
I0625 11:39:30.115445 17898 solver.cpp:228] Iteration 189200, loss = 0.000494889
I0625 11:39:30.115491 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000495128 (* 1 = 0.000495128 loss)
I0625 11:39:30.115502 17898 sgd_solver.cpp:106] Iteration 189200, lr = 0.001
I0625 11:56:13.549372 17898 solver.cpp:337] Iteration 189600, Testing net (#0)
I0625 11:57:16.730532 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939531
I0625 11:57:16.730753 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.273743 (* 1 = 0.273743 loss)
I0625 11:57:19.206728 17898 solver.cpp:228] Iteration 189600, loss = 0.000959855
I0625 11:57:19.206773 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000960095 (* 1 = 0.000960095 loss)
I0625 11:57:19.206786 17898 sgd_solver.cpp:106] Iteration 189600, lr = 0.001
I0625 12:14:02.512362 17898 solver.cpp:337] Iteration 190000, Testing net (#0)
I0625 12:15:05.731643 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940625
I0625 12:15:05.738387 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.276745 (* 1 = 0.276745 loss)
I0625 12:15:08.221356 17898 solver.cpp:228] Iteration 190000, loss = 0.00115926
I0625 12:15:08.221405 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0011595 (* 1 = 0.0011595 loss)
I0625 12:15:08.221415 17898 sgd_solver.cpp:106] Iteration 190000, lr = 0.001
I0625 12:31:51.609580 17898 solver.cpp:337] Iteration 190400, Testing net (#0)
I0625 12:32:54.807809 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.93875
I0625 12:32:54.808017 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.278018 (* 1 = 0.278018 loss)
I0625 12:32:57.297315 17898 solver.cpp:228] Iteration 190400, loss = 0.000780089
I0625 12:32:57.297361 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000780331 (* 1 = 0.000780331 loss)
I0625 12:32:57.297372 17898 sgd_solver.cpp:106] Iteration 190400, lr = 0.001
I0625 12:49:40.797621 17898 solver.cpp:337] Iteration 190800, Testing net (#0)
I0625 12:50:43.980348 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.941406
I0625 12:50:43.980551 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.259047 (* 1 = 0.259047 loss)
I0625 12:50:46.450651 17898 solver.cpp:228] Iteration 190800, loss = 0.00129823
I0625 12:50:46.450701 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00129847 (* 1 = 0.00129847 loss)
I0625 12:50:46.450712 17898 sgd_solver.cpp:106] Iteration 190800, lr = 0.001
I0625 13:07:29.784633 17898 solver.cpp:337] Iteration 191200, Testing net (#0)
I0625 13:08:32.994593 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937422
I0625 13:08:32.994804 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.278945 (* 1 = 0.278945 loss)
I0625 13:08:35.475252 17898 solver.cpp:228] Iteration 191200, loss = 0.000314551
I0625 13:08:35.475311 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000314794 (* 1 = 0.000314794 loss)
I0625 13:08:35.475322 17898 sgd_solver.cpp:106] Iteration 191200, lr = 0.001
I0625 13:25:18.787742 17898 solver.cpp:337] Iteration 191600, Testing net (#0)
I0625 13:26:22.011826 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939297
I0625 13:26:22.012015 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.276476 (* 1 = 0.276476 loss)
I0625 13:26:24.477982 17898 solver.cpp:228] Iteration 191600, loss = 0.00110755
I0625 13:26:24.478023 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00110779 (* 1 = 0.00110779 loss)
I0625 13:26:24.478034 17898 sgd_solver.cpp:106] Iteration 191600, lr = 0.001
I0625 13:43:07.869549 17898 solver.cpp:337] Iteration 192000, Testing net (#0)
I0625 13:44:11.081065 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.941797
I0625 13:44:11.081275 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.259719 (* 1 = 0.259719 loss)
I0625 13:44:13.556314 17898 solver.cpp:228] Iteration 192000, loss = 0.00064055
I0625 13:44:13.556362 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000640792 (* 1 = 0.000640792 loss)
I0625 13:44:13.556373 17898 sgd_solver.cpp:106] Iteration 192000, lr = 0.001
I0625 14:00:57.072494 17898 solver.cpp:337] Iteration 192400, Testing net (#0)
I0625 14:02:00.258000 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.93875
I0625 14:02:00.258205 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.268937 (* 1 = 0.268937 loss)
I0625 14:02:02.729457 17898 solver.cpp:228] Iteration 192400, loss = 0.00357242
I0625 14:02:02.729501 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00357266 (* 1 = 0.00357266 loss)
I0625 14:02:02.729513 17898 sgd_solver.cpp:106] Iteration 192400, lr = 0.001
I0625 14:18:46.319000 17898 solver.cpp:337] Iteration 192800, Testing net (#0)
I0625 14:19:49.527617 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937344
I0625 14:19:49.527815 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.276087 (* 1 = 0.276087 loss)
I0625 14:19:52.007458 17898 solver.cpp:228] Iteration 192800, loss = 0.000513214
I0625 14:19:52.007500 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000513457 (* 1 = 0.000513457 loss)
I0625 14:19:52.007511 17898 sgd_solver.cpp:106] Iteration 192800, lr = 0.001
I0625 14:36:35.575179 17898 solver.cpp:337] Iteration 193200, Testing net (#0)
I0625 14:37:38.785785 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940781
I0625 14:37:38.785980 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.268072 (* 1 = 0.268072 loss)
I0625 14:37:41.259913 17898 solver.cpp:228] Iteration 193200, loss = 0.000863187
I0625 14:37:41.259968 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000863429 (* 1 = 0.000863429 loss)
I0625 14:37:41.259984 17898 sgd_solver.cpp:106] Iteration 193200, lr = 0.001
I0625 14:54:24.719820 17898 solver.cpp:337] Iteration 193600, Testing net (#0)
I0625 14:55:27.992544 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.941328
I0625 14:55:27.992771 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.258151 (* 1 = 0.258151 loss)
I0625 14:55:30.465098 17898 solver.cpp:228] Iteration 193600, loss = 0.00220675
I0625 14:55:30.465144 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.002207 (* 1 = 0.002207 loss)
I0625 14:55:30.465154 17898 sgd_solver.cpp:106] Iteration 193600, lr = 0.001
I0625 15:12:13.953465 17898 solver.cpp:337] Iteration 194000, Testing net (#0)
I0625 15:13:17.219653 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939062
I0625 15:13:17.219854 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.280104 (* 1 = 0.280104 loss)
I0625 15:13:19.697372 17898 solver.cpp:228] Iteration 194000, loss = 0.000604783
I0625 15:13:19.697428 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000605025 (* 1 = 0.000605025 loss)
I0625 15:13:19.697443 17898 sgd_solver.cpp:106] Iteration 194000, lr = 0.001
I0625 15:30:03.125911 17898 solver.cpp:337] Iteration 194400, Testing net (#0)
I0625 15:31:06.380321 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937813
I0625 15:31:06.380482 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.278103 (* 1 = 0.278103 loss)
I0625 15:31:08.850939 17898 solver.cpp:228] Iteration 194400, loss = 0.000601619
I0625 15:31:08.850983 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000601862 (* 1 = 0.000601862 loss)
I0625 15:31:08.850994 17898 sgd_solver.cpp:106] Iteration 194400, lr = 0.001
I0625 15:47:52.547541 17898 solver.cpp:337] Iteration 194800, Testing net (#0)
I0625 15:48:55.749032 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939687
I0625 15:48:55.749256 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.269204 (* 1 = 0.269204 loss)
I0625 15:48:58.215610 17898 solver.cpp:228] Iteration 194800, loss = 0.00198176
I0625 15:48:58.215659 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.001982 (* 1 = 0.001982 loss)
I0625 15:48:58.215672 17898 sgd_solver.cpp:106] Iteration 194800, lr = 0.001
I0625 16:05:41.458719 17898 solver.cpp:337] Iteration 195200, Testing net (#0)
I0625 16:06:44.670066 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939844
I0625 16:06:44.682426 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.273393 (* 1 = 0.273393 loss)
I0625 16:06:47.156044 17898 solver.cpp:228] Iteration 195200, loss = 0.000621953
I0625 16:06:47.156085 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000622196 (* 1 = 0.000622196 loss)
I0625 16:06:47.156096 17898 sgd_solver.cpp:106] Iteration 195200, lr = 0.001
I0625 16:23:30.385704 17898 solver.cpp:337] Iteration 195600, Testing net (#0)
I0625 16:24:33.640264 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940469
I0625 16:24:33.640470 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.275149 (* 1 = 0.275149 loss)
I0625 16:24:36.115926 17898 solver.cpp:228] Iteration 195600, loss = 0.000585992
I0625 16:24:36.115977 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000586236 (* 1 = 0.000586236 loss)
I0625 16:24:36.115989 17898 sgd_solver.cpp:106] Iteration 195600, lr = 0.001
I0625 16:41:19.253563 17898 solver.cpp:337] Iteration 196000, Testing net (#0)
I0625 16:42:22.461117 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938125
I0625 16:42:22.461321 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.275525 (* 1 = 0.275525 loss)
I0625 16:42:24.932829 17898 solver.cpp:228] Iteration 196000, loss = 0.0013834
I0625 16:42:24.932870 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00138364 (* 1 = 0.00138364 loss)
I0625 16:42:24.932885 17898 sgd_solver.cpp:106] Iteration 196000, lr = 0.001
I0625 16:59:08.180531 17898 solver.cpp:337] Iteration 196400, Testing net (#0)
I0625 17:00:11.351539 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.943125
I0625 17:00:11.351727 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.260176 (* 1 = 0.260176 loss)
I0625 17:00:13.816016 17898 solver.cpp:228] Iteration 196400, loss = 0.000582907
I0625 17:00:13.816062 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000583151 (* 1 = 0.000583151 loss)
I0625 17:00:13.816073 17898 sgd_solver.cpp:106] Iteration 196400, lr = 0.001
I0625 17:16:57.276233 17898 solver.cpp:337] Iteration 196800, Testing net (#0)
I0625 17:18:00.479713 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.937422
I0625 17:18:00.479938 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.282015 (* 1 = 0.282015 loss)
I0625 17:18:02.962682 17898 solver.cpp:228] Iteration 196800, loss = 0.00063748
I0625 17:18:02.962739 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000637724 (* 1 = 0.000637724 loss)
I0625 17:18:02.962754 17898 sgd_solver.cpp:106] Iteration 196800, lr = 0.001
I0625 17:34:46.148181 17898 solver.cpp:337] Iteration 197200, Testing net (#0)
I0625 17:35:49.368371 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939609
I0625 17:35:49.368566 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.270232 (* 1 = 0.270232 loss)
I0625 17:35:51.842947 17898 solver.cpp:228] Iteration 197200, loss = 0.000977921
I0625 17:35:51.842995 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000978166 (* 1 = 0.000978166 loss)
I0625 17:35:51.843008 17898 sgd_solver.cpp:106] Iteration 197200, lr = 0.001
I0625 17:52:35.337069 17898 solver.cpp:337] Iteration 197600, Testing net (#0)
I0625 17:53:38.554044 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939844
I0625 17:53:38.554203 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.270338 (* 1 = 0.270338 loss)
I0625 17:53:41.028862 17898 solver.cpp:228] Iteration 197600, loss = 0.00112425
I0625 17:53:41.028909 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00112449 (* 1 = 0.00112449 loss)
I0625 17:53:41.028920 17898 sgd_solver.cpp:106] Iteration 197600, lr = 0.001
I0625 18:10:24.381597 17898 solver.cpp:337] Iteration 198000, Testing net (#0)
I0625 18:11:27.602680 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.941172
I0625 18:11:27.602885 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.261418 (* 1 = 0.261418 loss)
I0625 18:11:30.079181 17898 solver.cpp:228] Iteration 198000, loss = 0.000626655
I0625 18:11:30.079227 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0006269 (* 1 = 0.0006269 loss)
I0625 18:11:30.079241 17898 sgd_solver.cpp:106] Iteration 198000, lr = 0.001
I0625 18:28:14.241506 17898 solver.cpp:337] Iteration 198400, Testing net (#0)
I0625 18:29:17.729521 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939375
I0625 18:29:17.729749 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.270694 (* 1 = 0.270694 loss)
I0625 18:29:20.206385 17898 solver.cpp:228] Iteration 198400, loss = 0.00184253
I0625 18:29:20.206470 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00184278 (* 1 = 0.00184278 loss)
I0625 18:29:20.206491 17898 sgd_solver.cpp:106] Iteration 198400, lr = 0.001
I0625 18:46:03.946301 17898 solver.cpp:337] Iteration 198800, Testing net (#0)
I0625 18:47:07.165879 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.938281
I0625 18:47:07.166079 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.280398 (* 1 = 0.280398 loss)
I0625 18:47:09.642494 17898 solver.cpp:228] Iteration 198800, loss = 0.00211439
I0625 18:47:09.642542 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00211464 (* 1 = 0.00211464 loss)
I0625 18:47:09.642554 17898 sgd_solver.cpp:106] Iteration 198800, lr = 0.001
I0625 19:03:53.340977 17898 solver.cpp:337] Iteration 199200, Testing net (#0)
I0625 19:04:56.578409 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939766
I0625 19:04:56.578611 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.26097 (* 1 = 0.26097 loss)
I0625 19:04:59.051317 17898 solver.cpp:228] Iteration 199200, loss = 0.000878364
I0625 19:04:59.051365 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00087861 (* 1 = 0.00087861 loss)
I0625 19:04:59.051378 17898 sgd_solver.cpp:106] Iteration 199200, lr = 0.001
I0625 19:21:42.501138 17898 solver.cpp:337] Iteration 199600, Testing net (#0)
I0625 19:22:45.747400 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.939766
I0625 19:22:45.747598 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.271868 (* 1 = 0.271868 loss)
I0625 19:22:48.219828 17898 solver.cpp:228] Iteration 199600, loss = 0.000222788
I0625 19:22:48.219892 17898 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000223033 (* 1 = 0.000223033 loss)
I0625 19:22:48.219907 17898 sgd_solver.cpp:106] Iteration 199600, lr = 0.001
I0625 19:39:31.720671 17898 solver.cpp:454] Snapshotting to binary proto file _iter_200000.caffemodel
I0625 19:39:31.942463 17898 sgd_solver.cpp:273] Snapshotting solver state to binary proto file _iter_200000.solverstate
I0625 19:39:32.674675 17898 solver.cpp:317] Iteration 200000, loss = 0.000401521
I0625 19:39:32.674712 17898 solver.cpp:337] Iteration 200000, Testing net (#0)
I0625 19:40:35.913251 17898 solver.cpp:404]     Test net output #0: Accuracy = 0.940234
I0625 19:40:35.913429 17898 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.277112 (* 1 = 0.277112 loss)
I0625 19:40:35.913441 17898 solver.cpp:322] Optimization Done.
I0625 19:40:35.913445 17898 caffe.cpp:222] Optimization Done.
