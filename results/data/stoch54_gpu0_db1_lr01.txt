I0619 14:48:20.948288 17263 caffe.cpp:185] Using GPUs 0
I0619 14:48:20.987877 17263 caffe.cpp:190] GPU 0: GeForce GTX TITAN X
I0619 14:48:21.393035 17263 solver.cpp:283] Initializing solver from parameters: 
train_net: "examples/stochastic_depth/residual_train54.prototxt"
test_net: "examples/stochastic_depth/residual_test54.prototxt"
test_iter: 100
test_interval: 400
base_lr: 0.1
display: 400
max_iter: 200000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
solver_mode: GPU
device_id: 0
random_seed: 831486
stepvalue: 100000
stepvalue: 150000
type: "Nesterov"
I0619 14:48:21.393102 17263 solver.cpp:316] Creating training net from train_net file: examples/stochastic_depth/residual_train54.prototxt
I0619 14:48:21.408360 17263 net.cpp:417] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "/scratch/pas282/caffe/examples/cifar10/cifar10_train_leveldb_padding1"
    batch_size: 128
    backend: LEVELDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution21"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution22"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution22"
  top: "Convolution22"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Convolution22"
  top: "Convolution23"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution23"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution24"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution25"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution26"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution27"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution28"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution28"
  top: "Convolution28"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution29"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution30"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "Convolution30"
  top: "Convolution30"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Convolution30"
  top: "Convolution31"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise15"
  type: "Eltwise"
  bottom: "Eltwise14"
  bottom: "Convolution31"
  top: "Eltwise15"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "Eltwise15"
  top: "Eltwise15"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Eltwise15"
  top: "Convolution32"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm32"
  type: "BatchNorm"
  bottom: "Convolution32"
  top: "Convolution32"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale32"
  type: "Scale"
  bottom: "Convolution32"
  top: "Convolution32"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU32"
  type: "ReLU"
  bottom: "Convolution32"
  top: "Convolution32"
}
layer {
  name: "Convolution33"
  type: "Convolution"
  bottom: "Convolution32"
  top: "Convolution33"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm33"
  type: "BatchNorm"
  bottom: "Convolution33"
  top: "Convolution33"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale33"
  type: "Scale"
  bottom: "Convolution33"
  top: "Convolution33"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise16"
  type: "Eltwise"
  bottom: "Eltwise15"
  bottom: "Convolution33"
  top: "Eltwise16"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU33"
  type: "ReLU"
  bottom: "Eltwise16"
  top: "Eltwise16"
}
layer {
  name: "Convolution34"
  type: "Convolution"
  bottom: "Eltwise16"
  top: "Convolution34"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm34"
  type: "BatchNorm"
  bottom: "Convolution34"
  top: "Convolution34"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale34"
  type: "Scale"
  bottom: "Convolution34"
  top: "Convolution34"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU34"
  type: "ReLU"
  bottom: "Convolution34"
  top: "Convolution34"
}
layer {
  name: "Convolution35"
  type: "Convolution"
  bottom: "Convolution34"
  top: "Convolution35"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm35"
  type: "BatchNorm"
  bottom: "Convolution35"
  top: "Convolution35"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale35"
  type: "Scale"
  bottom: "Convolution35"
  top: "Convolution35"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise17"
  type: "Eltwise"
  bottom: "Eltwise16"
  bottom: "Convolution35"
  top: "Eltwise17"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU35"
  type: "ReLU"
  bottom: "Eltwise17"
  top: "Eltwise17"
}
layer {
  name: "Convolution36"
  type: "Convolution"
  bottom: "Eltwise17"
  top: "Convolution36"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
I0619 14:48:21.410995 17263 layer_factory.hpp:77] Creating layer Data1
I0619 14:48:21.411257 17263 net.cpp:459] Creating Layer Data1
I0619 14:48:21.411273 17263 net.cpp:860] Data1 -> Data1
I0619 14:48:21.411334 17263 net.cpp:860] Data1 -> Data2
I0619 14:48:21.453969 17267 db_leveldb.cpp:18] Opened leveldb /scratch/pas282/caffe/examples/cifar10/cifar10_train_leveldb_padding1
I0619 14:48:21.471935 17263 data_layer.cpp:41] output data size: 128,3,32,32
I0619 14:48:21.477186 17263 net.cpp:509] Setting up Data1
I0619 14:48:21.477226 17263 net.cpp:516] Top shape: 128 3 32 32 (393216)
I0619 14:48:21.477238 17263 net.cpp:516] Top shape: 128 (128)
I0619 14:48:21.477246 17263 net.cpp:524] Memory required for data: 1573376
I0619 14:48:21.477262 17263 layer_factory.hpp:77] Creating layer Convolution1
I0619 14:48:21.477296 17263 net.cpp:459] Creating Layer Convolution1
I0619 14:48:21.477309 17263 net.cpp:886] Convolution1 <- Data1
I0619 14:48:21.477334 17263 net.cpp:860] Convolution1 -> Convolution1
I0619 14:48:21.478888 17263 net.cpp:509] Setting up Convolution1
I0619 14:48:21.478916 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.478924 17263 net.cpp:524] Memory required for data: 9961984
I0619 14:48:21.478963 17263 layer_factory.hpp:77] Creating layer BatchNorm1
I0619 14:48:21.478997 17263 net.cpp:459] Creating Layer BatchNorm1
I0619 14:48:21.479007 17263 net.cpp:886] BatchNorm1 <- Convolution1
I0619 14:48:21.479018 17263 net.cpp:847] BatchNorm1 -> Convolution1 (in-place)
I0619 14:48:21.479514 17263 net.cpp:509] Setting up BatchNorm1
I0619 14:48:21.479533 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.479542 17263 net.cpp:524] Memory required for data: 18350592
I0619 14:48:21.479569 17263 layer_factory.hpp:77] Creating layer Scale1
I0619 14:48:21.479588 17263 net.cpp:459] Creating Layer Scale1
I0619 14:48:21.479594 17263 net.cpp:886] Scale1 <- Convolution1
I0619 14:48:21.479605 17263 net.cpp:847] Scale1 -> Convolution1 (in-place)
I0619 14:48:21.479766 17263 layer_factory.hpp:77] Creating layer Scale1
I0619 14:48:21.479995 17263 net.cpp:509] Setting up Scale1
I0619 14:48:21.480039 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.480048 17263 net.cpp:524] Memory required for data: 26739200
I0619 14:48:21.480065 17263 layer_factory.hpp:77] Creating layer ReLU1
I0619 14:48:21.480080 17263 net.cpp:459] Creating Layer ReLU1
I0619 14:48:21.480088 17263 net.cpp:886] ReLU1 <- Convolution1
I0619 14:48:21.480098 17263 net.cpp:847] ReLU1 -> Convolution1 (in-place)
I0619 14:48:21.480119 17263 net.cpp:509] Setting up ReLU1
I0619 14:48:21.480130 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.480137 17263 net.cpp:524] Memory required for data: 35127808
I0619 14:48:21.480144 17263 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0619 14:48:21.480167 17263 net.cpp:459] Creating Layer Convolution1_ReLU1_0_split
I0619 14:48:21.480175 17263 net.cpp:886] Convolution1_ReLU1_0_split <- Convolution1
I0619 14:48:21.480185 17263 net.cpp:860] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0619 14:48:21.480198 17263 net.cpp:860] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0619 14:48:21.480269 17263 net.cpp:509] Setting up Convolution1_ReLU1_0_split
I0619 14:48:21.480283 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.480293 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.480299 17263 net.cpp:524] Memory required for data: 51905024
I0619 14:48:21.480306 17263 layer_factory.hpp:77] Creating layer Convolution2
I0619 14:48:21.480322 17263 net.cpp:459] Creating Layer Convolution2
I0619 14:48:21.480330 17263 net.cpp:886] Convolution2 <- Convolution1_ReLU1_0_split_0
I0619 14:48:21.480343 17263 net.cpp:860] Convolution2 -> Convolution2
I0619 14:48:21.481787 17263 net.cpp:509] Setting up Convolution2
I0619 14:48:21.481820 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.481828 17263 net.cpp:524] Memory required for data: 60293632
I0619 14:48:21.481853 17263 layer_factory.hpp:77] Creating layer BatchNorm2
I0619 14:48:21.481868 17263 net.cpp:459] Creating Layer BatchNorm2
I0619 14:48:21.481876 17263 net.cpp:886] BatchNorm2 <- Convolution2
I0619 14:48:21.481891 17263 net.cpp:847] BatchNorm2 -> Convolution2 (in-place)
I0619 14:48:21.482285 17263 net.cpp:509] Setting up BatchNorm2
I0619 14:48:21.482300 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.482307 17263 net.cpp:524] Memory required for data: 68682240
I0619 14:48:21.482327 17263 layer_factory.hpp:77] Creating layer Scale2
I0619 14:48:21.482342 17263 net.cpp:459] Creating Layer Scale2
I0619 14:48:21.482349 17263 net.cpp:886] Scale2 <- Convolution2
I0619 14:48:21.482380 17263 net.cpp:847] Scale2 -> Convolution2 (in-place)
I0619 14:48:21.482447 17263 layer_factory.hpp:77] Creating layer Scale2
I0619 14:48:21.482810 17263 net.cpp:509] Setting up Scale2
I0619 14:48:21.482838 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.482844 17263 net.cpp:524] Memory required for data: 77070848
I0619 14:48:21.482863 17263 layer_factory.hpp:77] Creating layer ReLU2
I0619 14:48:21.482877 17263 net.cpp:459] Creating Layer ReLU2
I0619 14:48:21.482883 17263 net.cpp:886] ReLU2 <- Convolution2
I0619 14:48:21.482893 17263 net.cpp:847] ReLU2 -> Convolution2 (in-place)
I0619 14:48:21.482905 17263 net.cpp:509] Setting up ReLU2
I0619 14:48:21.482914 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.482920 17263 net.cpp:524] Memory required for data: 85459456
I0619 14:48:21.482928 17263 layer_factory.hpp:77] Creating layer Convolution3
I0619 14:48:21.482949 17263 net.cpp:459] Creating Layer Convolution3
I0619 14:48:21.482955 17263 net.cpp:886] Convolution3 <- Convolution2
I0619 14:48:21.482969 17263 net.cpp:860] Convolution3 -> Convolution3
I0619 14:48:21.483479 17263 net.cpp:509] Setting up Convolution3
I0619 14:48:21.483492 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.483500 17263 net.cpp:524] Memory required for data: 93848064
I0619 14:48:21.483515 17263 layer_factory.hpp:77] Creating layer BatchNorm3
I0619 14:48:21.483533 17263 net.cpp:459] Creating Layer BatchNorm3
I0619 14:48:21.483564 17263 net.cpp:886] BatchNorm3 <- Convolution3
I0619 14:48:21.483578 17263 net.cpp:847] BatchNorm3 -> Convolution3 (in-place)
I0619 14:48:21.483885 17263 net.cpp:509] Setting up BatchNorm3
I0619 14:48:21.483898 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.483906 17263 net.cpp:524] Memory required for data: 102236672
I0619 14:48:21.483935 17263 layer_factory.hpp:77] Creating layer Scale3
I0619 14:48:21.483947 17263 net.cpp:459] Creating Layer Scale3
I0619 14:48:21.483954 17263 net.cpp:886] Scale3 <- Convolution3
I0619 14:48:21.483964 17263 net.cpp:847] Scale3 -> Convolution3 (in-place)
I0619 14:48:21.484024 17263 layer_factory.hpp:77] Creating layer Scale3
I0619 14:48:21.484211 17263 net.cpp:509] Setting up Scale3
I0619 14:48:21.484225 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.484231 17263 net.cpp:524] Memory required for data: 110625280
I0619 14:48:21.484246 17263 layer_factory.hpp:77] Creating layer Eltwise1
I0619 14:48:21.484258 17268 blocking_queue.cpp:50] Waiting for data
I0619 14:48:21.484268 17263 net.cpp:459] Creating Layer Eltwise1
I0619 14:48:21.484300 17263 net.cpp:886] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0619 14:48:21.484313 17263 net.cpp:886] Eltwise1 <- Convolution3
I0619 14:48:21.484324 17263 net.cpp:860] Eltwise1 -> Eltwise1
I0619 14:48:21.484378 17263 net.cpp:509] Setting up Eltwise1
I0619 14:48:21.484390 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.484396 17263 net.cpp:524] Memory required for data: 119013888
I0619 14:48:21.484405 17263 layer_factory.hpp:77] Creating layer ReLU3
I0619 14:48:21.484414 17263 net.cpp:459] Creating Layer ReLU3
I0619 14:48:21.484422 17263 net.cpp:886] ReLU3 <- Eltwise1
I0619 14:48:21.484431 17263 net.cpp:847] ReLU3 -> Eltwise1 (in-place)
I0619 14:48:21.484441 17263 net.cpp:509] Setting up ReLU3
I0619 14:48:21.484450 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.484457 17263 net.cpp:524] Memory required for data: 127402496
I0619 14:48:21.484463 17263 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0619 14:48:21.484475 17263 net.cpp:459] Creating Layer Eltwise1_ReLU3_0_split
I0619 14:48:21.484483 17263 net.cpp:886] Eltwise1_ReLU3_0_split <- Eltwise1
I0619 14:48:21.484490 17263 net.cpp:860] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0619 14:48:21.484503 17263 net.cpp:860] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0619 14:48:21.484560 17263 net.cpp:509] Setting up Eltwise1_ReLU3_0_split
I0619 14:48:21.484572 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.484580 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.484586 17263 net.cpp:524] Memory required for data: 144179712
I0619 14:48:21.484593 17263 layer_factory.hpp:77] Creating layer Convolution4
I0619 14:48:21.484611 17263 net.cpp:459] Creating Layer Convolution4
I0619 14:48:21.484617 17263 net.cpp:886] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0619 14:48:21.484632 17263 net.cpp:860] Convolution4 -> Convolution4
I0619 14:48:21.485131 17263 net.cpp:509] Setting up Convolution4
I0619 14:48:21.485144 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.485152 17263 net.cpp:524] Memory required for data: 152568320
I0619 14:48:21.485167 17263 layer_factory.hpp:77] Creating layer BatchNorm4
I0619 14:48:21.485177 17263 net.cpp:459] Creating Layer BatchNorm4
I0619 14:48:21.485183 17263 net.cpp:886] BatchNorm4 <- Convolution4
I0619 14:48:21.485196 17263 net.cpp:847] BatchNorm4 -> Convolution4 (in-place)
I0619 14:48:21.485507 17263 net.cpp:509] Setting up BatchNorm4
I0619 14:48:21.485519 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.485525 17263 net.cpp:524] Memory required for data: 160956928
I0619 14:48:21.485543 17263 layer_factory.hpp:77] Creating layer Scale4
I0619 14:48:21.485554 17263 net.cpp:459] Creating Layer Scale4
I0619 14:48:21.485560 17263 net.cpp:886] Scale4 <- Convolution4
I0619 14:48:21.485570 17263 net.cpp:847] Scale4 -> Convolution4 (in-place)
I0619 14:48:21.485633 17263 layer_factory.hpp:77] Creating layer Scale4
I0619 14:48:21.485829 17263 net.cpp:509] Setting up Scale4
I0619 14:48:21.485843 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.485849 17263 net.cpp:524] Memory required for data: 169345536
I0619 14:48:21.485864 17263 layer_factory.hpp:77] Creating layer ReLU4
I0619 14:48:21.485877 17263 net.cpp:459] Creating Layer ReLU4
I0619 14:48:21.485883 17263 net.cpp:886] ReLU4 <- Convolution4
I0619 14:48:21.485893 17263 net.cpp:847] ReLU4 -> Convolution4 (in-place)
I0619 14:48:21.485904 17263 net.cpp:509] Setting up ReLU4
I0619 14:48:21.485913 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.485918 17263 net.cpp:524] Memory required for data: 177734144
I0619 14:48:21.485924 17263 layer_factory.hpp:77] Creating layer Convolution5
I0619 14:48:21.485945 17263 net.cpp:459] Creating Layer Convolution5
I0619 14:48:21.485952 17263 net.cpp:886] Convolution5 <- Convolution4
I0619 14:48:21.485963 17263 net.cpp:860] Convolution5 -> Convolution5
I0619 14:48:21.486484 17263 net.cpp:509] Setting up Convolution5
I0619 14:48:21.486498 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.486505 17263 net.cpp:524] Memory required for data: 186122752
I0619 14:48:21.486520 17263 layer_factory.hpp:77] Creating layer BatchNorm5
I0619 14:48:21.486531 17263 net.cpp:459] Creating Layer BatchNorm5
I0619 14:48:21.486537 17263 net.cpp:886] BatchNorm5 <- Convolution5
I0619 14:48:21.486560 17263 net.cpp:847] BatchNorm5 -> Convolution5 (in-place)
I0619 14:48:21.486867 17263 net.cpp:509] Setting up BatchNorm5
I0619 14:48:21.486879 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.486886 17263 net.cpp:524] Memory required for data: 194511360
I0619 14:48:21.486920 17263 layer_factory.hpp:77] Creating layer Scale5
I0619 14:48:21.486932 17263 net.cpp:459] Creating Layer Scale5
I0619 14:48:21.486939 17263 net.cpp:886] Scale5 <- Convolution5
I0619 14:48:21.486949 17263 net.cpp:847] Scale5 -> Convolution5 (in-place)
I0619 14:48:21.487010 17263 layer_factory.hpp:77] Creating layer Scale5
I0619 14:48:21.487185 17263 net.cpp:509] Setting up Scale5
I0619 14:48:21.487198 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.487205 17263 net.cpp:524] Memory required for data: 202899968
I0619 14:48:21.487218 17263 layer_factory.hpp:77] Creating layer Eltwise2
I0619 14:48:21.487233 17263 net.cpp:459] Creating Layer Eltwise2
I0619 14:48:21.487241 17263 net.cpp:886] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0619 14:48:21.487248 17263 net.cpp:886] Eltwise2 <- Convolution5
I0619 14:48:21.487258 17263 net.cpp:860] Eltwise2 -> Eltwise2
I0619 14:48:21.487298 17263 net.cpp:509] Setting up Eltwise2
I0619 14:48:21.487308 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.487314 17263 net.cpp:524] Memory required for data: 211288576
I0619 14:48:21.487321 17263 layer_factory.hpp:77] Creating layer ReLU5
I0619 14:48:21.487330 17263 net.cpp:459] Creating Layer ReLU5
I0619 14:48:21.487337 17263 net.cpp:886] ReLU5 <- Eltwise2
I0619 14:48:21.487351 17263 net.cpp:847] ReLU5 -> Eltwise2 (in-place)
I0619 14:48:21.487362 17263 net.cpp:509] Setting up ReLU5
I0619 14:48:21.487371 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.487376 17263 net.cpp:524] Memory required for data: 219677184
I0619 14:48:21.487383 17263 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0619 14:48:21.487392 17263 net.cpp:459] Creating Layer Eltwise2_ReLU5_0_split
I0619 14:48:21.487398 17263 net.cpp:886] Eltwise2_ReLU5_0_split <- Eltwise2
I0619 14:48:21.487407 17263 net.cpp:860] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0619 14:48:21.487417 17263 net.cpp:860] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0619 14:48:21.487473 17263 net.cpp:509] Setting up Eltwise2_ReLU5_0_split
I0619 14:48:21.487484 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.487493 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.487498 17263 net.cpp:524] Memory required for data: 236454400
I0619 14:48:21.487509 17263 layer_factory.hpp:77] Creating layer Convolution6
I0619 14:48:21.487541 17263 net.cpp:459] Creating Layer Convolution6
I0619 14:48:21.487550 17263 net.cpp:886] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0619 14:48:21.487565 17263 net.cpp:860] Convolution6 -> Convolution6
I0619 14:48:21.488104 17263 net.cpp:509] Setting up Convolution6
I0619 14:48:21.488121 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.488126 17263 net.cpp:524] Memory required for data: 244843008
I0619 14:48:21.488142 17263 layer_factory.hpp:77] Creating layer BatchNorm6
I0619 14:48:21.488152 17263 net.cpp:459] Creating Layer BatchNorm6
I0619 14:48:21.488159 17263 net.cpp:886] BatchNorm6 <- Convolution6
I0619 14:48:21.488168 17263 net.cpp:847] BatchNorm6 -> Convolution6 (in-place)
I0619 14:48:21.488520 17263 net.cpp:509] Setting up BatchNorm6
I0619 14:48:21.488535 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.488541 17263 net.cpp:524] Memory required for data: 253231616
I0619 14:48:21.488561 17263 layer_factory.hpp:77] Creating layer Scale6
I0619 14:48:21.488572 17263 net.cpp:459] Creating Layer Scale6
I0619 14:48:21.488579 17263 net.cpp:886] Scale6 <- Convolution6
I0619 14:48:21.488590 17263 net.cpp:847] Scale6 -> Convolution6 (in-place)
I0619 14:48:21.488737 17263 layer_factory.hpp:77] Creating layer Scale6
I0619 14:48:21.488934 17263 net.cpp:509] Setting up Scale6
I0619 14:48:21.488947 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.488955 17263 net.cpp:524] Memory required for data: 261620224
I0619 14:48:21.488970 17263 layer_factory.hpp:77] Creating layer ReLU6
I0619 14:48:21.488986 17263 net.cpp:459] Creating Layer ReLU6
I0619 14:48:21.488992 17263 net.cpp:886] ReLU6 <- Convolution6
I0619 14:48:21.489002 17263 net.cpp:847] ReLU6 -> Convolution6 (in-place)
I0619 14:48:21.489013 17263 net.cpp:509] Setting up ReLU6
I0619 14:48:21.489022 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.489028 17263 net.cpp:524] Memory required for data: 270008832
I0619 14:48:21.489034 17263 layer_factory.hpp:77] Creating layer Convolution7
I0619 14:48:21.489051 17263 net.cpp:459] Creating Layer Convolution7
I0619 14:48:21.489058 17263 net.cpp:886] Convolution7 <- Convolution6
I0619 14:48:21.489071 17263 net.cpp:860] Convolution7 -> Convolution7
I0619 14:48:21.489576 17263 net.cpp:509] Setting up Convolution7
I0619 14:48:21.489593 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.489599 17263 net.cpp:524] Memory required for data: 278397440
I0619 14:48:21.489614 17263 layer_factory.hpp:77] Creating layer BatchNorm7
I0619 14:48:21.489624 17263 net.cpp:459] Creating Layer BatchNorm7
I0619 14:48:21.489630 17263 net.cpp:886] BatchNorm7 <- Convolution7
I0619 14:48:21.489646 17263 net.cpp:847] BatchNorm7 -> Convolution7 (in-place)
I0619 14:48:21.489961 17263 net.cpp:509] Setting up BatchNorm7
I0619 14:48:21.489974 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.489981 17263 net.cpp:524] Memory required for data: 286786048
I0619 14:48:21.489998 17263 layer_factory.hpp:77] Creating layer Scale7
I0619 14:48:21.490012 17263 net.cpp:459] Creating Layer Scale7
I0619 14:48:21.490020 17263 net.cpp:886] Scale7 <- Convolution7
I0619 14:48:21.490032 17263 net.cpp:847] Scale7 -> Convolution7 (in-place)
I0619 14:48:21.490084 17263 layer_factory.hpp:77] Creating layer Scale7
I0619 14:48:21.490269 17263 net.cpp:509] Setting up Scale7
I0619 14:48:21.490281 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.490288 17263 net.cpp:524] Memory required for data: 295174656
I0619 14:48:21.490303 17263 layer_factory.hpp:77] Creating layer Eltwise3
I0619 14:48:21.490316 17263 net.cpp:459] Creating Layer Eltwise3
I0619 14:48:21.490324 17263 net.cpp:886] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0619 14:48:21.490331 17263 net.cpp:886] Eltwise3 <- Convolution7
I0619 14:48:21.490340 17263 net.cpp:860] Eltwise3 -> Eltwise3
I0619 14:48:21.490397 17263 net.cpp:509] Setting up Eltwise3
I0619 14:48:21.490409 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.490420 17263 net.cpp:524] Memory required for data: 303563264
I0619 14:48:21.490461 17263 layer_factory.hpp:77] Creating layer ReLU7
I0619 14:48:21.490473 17263 net.cpp:459] Creating Layer ReLU7
I0619 14:48:21.490480 17263 net.cpp:886] ReLU7 <- Eltwise3
I0619 14:48:21.490492 17263 net.cpp:847] ReLU7 -> Eltwise3 (in-place)
I0619 14:48:21.490504 17263 net.cpp:509] Setting up ReLU7
I0619 14:48:21.490514 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.490520 17263 net.cpp:524] Memory required for data: 311951872
I0619 14:48:21.490527 17263 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0619 14:48:21.490535 17263 net.cpp:459] Creating Layer Eltwise3_ReLU7_0_split
I0619 14:48:21.490542 17263 net.cpp:886] Eltwise3_ReLU7_0_split <- Eltwise3
I0619 14:48:21.490551 17263 net.cpp:860] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0619 14:48:21.490563 17263 net.cpp:860] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0619 14:48:21.490625 17263 net.cpp:509] Setting up Eltwise3_ReLU7_0_split
I0619 14:48:21.490636 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.490644 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.490650 17263 net.cpp:524] Memory required for data: 328729088
I0619 14:48:21.490656 17263 layer_factory.hpp:77] Creating layer Convolution8
I0619 14:48:21.490674 17263 net.cpp:459] Creating Layer Convolution8
I0619 14:48:21.490680 17263 net.cpp:886] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0619 14:48:21.490691 17263 net.cpp:860] Convolution8 -> Convolution8
I0619 14:48:21.491210 17263 net.cpp:509] Setting up Convolution8
I0619 14:48:21.491225 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.491232 17263 net.cpp:524] Memory required for data: 337117696
I0619 14:48:21.491246 17263 layer_factory.hpp:77] Creating layer BatchNorm8
I0619 14:48:21.491261 17263 net.cpp:459] Creating Layer BatchNorm8
I0619 14:48:21.491268 17263 net.cpp:886] BatchNorm8 <- Convolution8
I0619 14:48:21.491279 17263 net.cpp:847] BatchNorm8 -> Convolution8 (in-place)
I0619 14:48:21.491590 17263 net.cpp:509] Setting up BatchNorm8
I0619 14:48:21.491601 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.491608 17263 net.cpp:524] Memory required for data: 345506304
I0619 14:48:21.491626 17263 layer_factory.hpp:77] Creating layer Scale8
I0619 14:48:21.491638 17263 net.cpp:459] Creating Layer Scale8
I0619 14:48:21.491646 17263 net.cpp:886] Scale8 <- Convolution8
I0619 14:48:21.491654 17263 net.cpp:847] Scale8 -> Convolution8 (in-place)
I0619 14:48:21.491709 17263 layer_factory.hpp:77] Creating layer Scale8
I0619 14:48:21.491894 17263 net.cpp:509] Setting up Scale8
I0619 14:48:21.491906 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.491912 17263 net.cpp:524] Memory required for data: 353894912
I0619 14:48:21.491926 17263 layer_factory.hpp:77] Creating layer ReLU8
I0619 14:48:21.491936 17263 net.cpp:459] Creating Layer ReLU8
I0619 14:48:21.491943 17263 net.cpp:886] ReLU8 <- Convolution8
I0619 14:48:21.491955 17263 net.cpp:847] ReLU8 -> Convolution8 (in-place)
I0619 14:48:21.491966 17263 net.cpp:509] Setting up ReLU8
I0619 14:48:21.491974 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.491981 17263 net.cpp:524] Memory required for data: 362283520
I0619 14:48:21.491986 17263 layer_factory.hpp:77] Creating layer Convolution9
I0619 14:48:21.492003 17263 net.cpp:459] Creating Layer Convolution9
I0619 14:48:21.492010 17263 net.cpp:886] Convolution9 <- Convolution8
I0619 14:48:21.492020 17263 net.cpp:860] Convolution9 -> Convolution9
I0619 14:48:21.492532 17263 net.cpp:509] Setting up Convolution9
I0619 14:48:21.492545 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.492552 17263 net.cpp:524] Memory required for data: 370672128
I0619 14:48:21.492568 17263 layer_factory.hpp:77] Creating layer BatchNorm9
I0619 14:48:21.492581 17263 net.cpp:459] Creating Layer BatchNorm9
I0619 14:48:21.492588 17263 net.cpp:886] BatchNorm9 <- Convolution9
I0619 14:48:21.492597 17263 net.cpp:847] BatchNorm9 -> Convolution9 (in-place)
I0619 14:48:21.492930 17263 net.cpp:509] Setting up BatchNorm9
I0619 14:48:21.492944 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.492950 17263 net.cpp:524] Memory required for data: 379060736
I0619 14:48:21.492970 17263 layer_factory.hpp:77] Creating layer Scale9
I0619 14:48:21.492982 17263 net.cpp:459] Creating Layer Scale9
I0619 14:48:21.492990 17263 net.cpp:886] Scale9 <- Convolution9
I0619 14:48:21.492998 17263 net.cpp:847] Scale9 -> Convolution9 (in-place)
I0619 14:48:21.493057 17263 layer_factory.hpp:77] Creating layer Scale9
I0619 14:48:21.493238 17263 net.cpp:509] Setting up Scale9
I0619 14:48:21.493250 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.493257 17263 net.cpp:524] Memory required for data: 387449344
I0619 14:48:21.493271 17263 layer_factory.hpp:77] Creating layer Eltwise4
I0619 14:48:21.493284 17263 net.cpp:459] Creating Layer Eltwise4
I0619 14:48:21.493291 17263 net.cpp:886] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0619 14:48:21.493299 17263 net.cpp:886] Eltwise4 <- Convolution9
I0619 14:48:21.493309 17263 net.cpp:860] Eltwise4 -> Eltwise4
I0619 14:48:21.493350 17263 net.cpp:509] Setting up Eltwise4
I0619 14:48:21.493360 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.493367 17263 net.cpp:524] Memory required for data: 395837952
I0619 14:48:21.493376 17263 layer_factory.hpp:77] Creating layer ReLU9
I0619 14:48:21.493386 17263 net.cpp:459] Creating Layer ReLU9
I0619 14:48:21.493394 17263 net.cpp:886] ReLU9 <- Eltwise4
I0619 14:48:21.493409 17263 net.cpp:847] ReLU9 -> Eltwise4 (in-place)
I0619 14:48:21.493420 17263 net.cpp:509] Setting up ReLU9
I0619 14:48:21.493429 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.493435 17263 net.cpp:524] Memory required for data: 404226560
I0619 14:48:21.493441 17263 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0619 14:48:21.493453 17263 net.cpp:459] Creating Layer Eltwise4_ReLU9_0_split
I0619 14:48:21.493458 17263 net.cpp:886] Eltwise4_ReLU9_0_split <- Eltwise4
I0619 14:48:21.493468 17263 net.cpp:860] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0619 14:48:21.493479 17263 net.cpp:860] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0619 14:48:21.493535 17263 net.cpp:509] Setting up Eltwise4_ReLU9_0_split
I0619 14:48:21.493546 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.493553 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.493559 17263 net.cpp:524] Memory required for data: 421003776
I0619 14:48:21.493566 17263 layer_factory.hpp:77] Creating layer Convolution10
I0619 14:48:21.493579 17263 net.cpp:459] Creating Layer Convolution10
I0619 14:48:21.493587 17263 net.cpp:886] Convolution10 <- Eltwise4_ReLU9_0_split_0
I0619 14:48:21.493600 17263 net.cpp:860] Convolution10 -> Convolution10
I0619 14:48:21.494109 17263 net.cpp:509] Setting up Convolution10
I0619 14:48:21.494122 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.494129 17263 net.cpp:524] Memory required for data: 429392384
I0619 14:48:21.494158 17263 layer_factory.hpp:77] Creating layer BatchNorm10
I0619 14:48:21.494174 17263 net.cpp:459] Creating Layer BatchNorm10
I0619 14:48:21.494180 17263 net.cpp:886] BatchNorm10 <- Convolution10
I0619 14:48:21.494190 17263 net.cpp:847] BatchNorm10 -> Convolution10 (in-place)
I0619 14:48:21.494526 17263 net.cpp:509] Setting up BatchNorm10
I0619 14:48:21.494550 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.494556 17263 net.cpp:524] Memory required for data: 437780992
I0619 14:48:21.494573 17263 layer_factory.hpp:77] Creating layer Scale10
I0619 14:48:21.494583 17263 net.cpp:459] Creating Layer Scale10
I0619 14:48:21.494590 17263 net.cpp:886] Scale10 <- Convolution10
I0619 14:48:21.494601 17263 net.cpp:847] Scale10 -> Convolution10 (in-place)
I0619 14:48:21.494654 17263 layer_factory.hpp:77] Creating layer Scale10
I0619 14:48:21.494825 17263 net.cpp:509] Setting up Scale10
I0619 14:48:21.494837 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.494846 17263 net.cpp:524] Memory required for data: 446169600
I0619 14:48:21.494879 17263 layer_factory.hpp:77] Creating layer ReLU10
I0619 14:48:21.494891 17263 net.cpp:459] Creating Layer ReLU10
I0619 14:48:21.494899 17263 net.cpp:886] ReLU10 <- Convolution10
I0619 14:48:21.494907 17263 net.cpp:847] ReLU10 -> Convolution10 (in-place)
I0619 14:48:21.494917 17263 net.cpp:509] Setting up ReLU10
I0619 14:48:21.494926 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.494932 17263 net.cpp:524] Memory required for data: 454558208
I0619 14:48:21.494938 17263 layer_factory.hpp:77] Creating layer Convolution11
I0619 14:48:21.494956 17263 net.cpp:459] Creating Layer Convolution11
I0619 14:48:21.494962 17263 net.cpp:886] Convolution11 <- Convolution10
I0619 14:48:21.494972 17263 net.cpp:860] Convolution11 -> Convolution11
I0619 14:48:21.495463 17263 net.cpp:509] Setting up Convolution11
I0619 14:48:21.495478 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.495484 17263 net.cpp:524] Memory required for data: 462946816
I0619 14:48:21.495497 17263 layer_factory.hpp:77] Creating layer BatchNorm11
I0619 14:48:21.495512 17263 net.cpp:459] Creating Layer BatchNorm11
I0619 14:48:21.495519 17263 net.cpp:886] BatchNorm11 <- Convolution11
I0619 14:48:21.495528 17263 net.cpp:847] BatchNorm11 -> Convolution11 (in-place)
I0619 14:48:21.495825 17263 net.cpp:509] Setting up BatchNorm11
I0619 14:48:21.495836 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.495841 17263 net.cpp:524] Memory required for data: 471335424
I0619 14:48:21.495857 17263 layer_factory.hpp:77] Creating layer Scale11
I0619 14:48:21.495868 17263 net.cpp:459] Creating Layer Scale11
I0619 14:48:21.495874 17263 net.cpp:886] Scale11 <- Convolution11
I0619 14:48:21.495883 17263 net.cpp:847] Scale11 -> Convolution11 (in-place)
I0619 14:48:21.495939 17263 layer_factory.hpp:77] Creating layer Scale11
I0619 14:48:21.496109 17263 net.cpp:509] Setting up Scale11
I0619 14:48:21.496120 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.496127 17263 net.cpp:524] Memory required for data: 479724032
I0619 14:48:21.496145 17263 layer_factory.hpp:77] Creating layer Eltwise5
I0619 14:48:21.496155 17263 net.cpp:459] Creating Layer Eltwise5
I0619 14:48:21.496161 17263 net.cpp:886] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0619 14:48:21.496170 17263 net.cpp:886] Eltwise5 <- Convolution11
I0619 14:48:21.496181 17263 net.cpp:860] Eltwise5 -> Eltwise5
I0619 14:48:21.496217 17263 net.cpp:509] Setting up Eltwise5
I0619 14:48:21.496228 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.496234 17263 net.cpp:524] Memory required for data: 488112640
I0619 14:48:21.496240 17263 layer_factory.hpp:77] Creating layer ReLU11
I0619 14:48:21.496265 17263 net.cpp:459] Creating Layer ReLU11
I0619 14:48:21.496273 17263 net.cpp:886] ReLU11 <- Eltwise5
I0619 14:48:21.496282 17263 net.cpp:847] ReLU11 -> Eltwise5 (in-place)
I0619 14:48:21.496292 17263 net.cpp:509] Setting up ReLU11
I0619 14:48:21.496300 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.496306 17263 net.cpp:524] Memory required for data: 496501248
I0619 14:48:21.496312 17263 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0619 14:48:21.496320 17263 net.cpp:459] Creating Layer Eltwise5_ReLU11_0_split
I0619 14:48:21.496326 17263 net.cpp:886] Eltwise5_ReLU11_0_split <- Eltwise5
I0619 14:48:21.496337 17263 net.cpp:860] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0619 14:48:21.496348 17263 net.cpp:860] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0619 14:48:21.496402 17263 net.cpp:509] Setting up Eltwise5_ReLU11_0_split
I0619 14:48:21.496413 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.496420 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.496426 17263 net.cpp:524] Memory required for data: 513278464
I0619 14:48:21.496433 17263 layer_factory.hpp:77] Creating layer Convolution12
I0619 14:48:21.496448 17263 net.cpp:459] Creating Layer Convolution12
I0619 14:48:21.496459 17263 net.cpp:886] Convolution12 <- Eltwise5_ReLU11_0_split_0
I0619 14:48:21.496491 17263 net.cpp:860] Convolution12 -> Convolution12
I0619 14:48:21.496969 17263 net.cpp:509] Setting up Convolution12
I0619 14:48:21.496983 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.496989 17263 net.cpp:524] Memory required for data: 521667072
I0619 14:48:21.497002 17263 layer_factory.hpp:77] Creating layer BatchNorm12
I0619 14:48:21.497012 17263 net.cpp:459] Creating Layer BatchNorm12
I0619 14:48:21.497020 17263 net.cpp:886] BatchNorm12 <- Convolution12
I0619 14:48:21.497032 17263 net.cpp:847] BatchNorm12 -> Convolution12 (in-place)
I0619 14:48:21.497321 17263 net.cpp:509] Setting up BatchNorm12
I0619 14:48:21.497333 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.497339 17263 net.cpp:524] Memory required for data: 530055680
I0619 14:48:21.497357 17263 layer_factory.hpp:77] Creating layer Scale12
I0619 14:48:21.497367 17263 net.cpp:459] Creating Layer Scale12
I0619 14:48:21.497375 17263 net.cpp:886] Scale12 <- Convolution12
I0619 14:48:21.497386 17263 net.cpp:847] Scale12 -> Convolution12 (in-place)
I0619 14:48:21.497440 17263 layer_factory.hpp:77] Creating layer Scale12
I0619 14:48:21.497612 17263 net.cpp:509] Setting up Scale12
I0619 14:48:21.497624 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.497630 17263 net.cpp:524] Memory required for data: 538444288
I0619 14:48:21.497644 17263 layer_factory.hpp:77] Creating layer ReLU12
I0619 14:48:21.497658 17263 net.cpp:459] Creating Layer ReLU12
I0619 14:48:21.497664 17263 net.cpp:886] ReLU12 <- Convolution12
I0619 14:48:21.497673 17263 net.cpp:847] ReLU12 -> Convolution12 (in-place)
I0619 14:48:21.497684 17263 net.cpp:509] Setting up ReLU12
I0619 14:48:21.497692 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.497699 17263 net.cpp:524] Memory required for data: 546832896
I0619 14:48:21.497704 17263 layer_factory.hpp:77] Creating layer Convolution13
I0619 14:48:21.497720 17263 net.cpp:459] Creating Layer Convolution13
I0619 14:48:21.497726 17263 net.cpp:886] Convolution13 <- Convolution12
I0619 14:48:21.497736 17263 net.cpp:860] Convolution13 -> Convolution13
I0619 14:48:21.498220 17263 net.cpp:509] Setting up Convolution13
I0619 14:48:21.498234 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.498239 17263 net.cpp:524] Memory required for data: 555221504
I0619 14:48:21.498252 17263 layer_factory.hpp:77] Creating layer BatchNorm13
I0619 14:48:21.498265 17263 net.cpp:459] Creating Layer BatchNorm13
I0619 14:48:21.498272 17263 net.cpp:886] BatchNorm13 <- Convolution13
I0619 14:48:21.498281 17263 net.cpp:847] BatchNorm13 -> Convolution13 (in-place)
I0619 14:48:21.498591 17263 net.cpp:509] Setting up BatchNorm13
I0619 14:48:21.498605 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.498610 17263 net.cpp:524] Memory required for data: 563610112
I0619 14:48:21.498626 17263 layer_factory.hpp:77] Creating layer Scale13
I0619 14:48:21.498639 17263 net.cpp:459] Creating Layer Scale13
I0619 14:48:21.498646 17263 net.cpp:886] Scale13 <- Convolution13
I0619 14:48:21.498654 17263 net.cpp:847] Scale13 -> Convolution13 (in-place)
I0619 14:48:21.498703 17263 layer_factory.hpp:77] Creating layer Scale13
I0619 14:48:21.498880 17263 net.cpp:509] Setting up Scale13
I0619 14:48:21.498894 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.498900 17263 net.cpp:524] Memory required for data: 571998720
I0619 14:48:21.498914 17263 layer_factory.hpp:77] Creating layer Eltwise6
I0619 14:48:21.498924 17263 net.cpp:459] Creating Layer Eltwise6
I0619 14:48:21.498930 17263 net.cpp:886] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0619 14:48:21.498939 17263 net.cpp:886] Eltwise6 <- Convolution13
I0619 14:48:21.498946 17263 net.cpp:860] Eltwise6 -> Eltwise6
I0619 14:48:21.498991 17263 net.cpp:509] Setting up Eltwise6
I0619 14:48:21.499001 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.499007 17263 net.cpp:524] Memory required for data: 580387328
I0619 14:48:21.499013 17263 layer_factory.hpp:77] Creating layer ReLU13
I0619 14:48:21.499063 17263 net.cpp:459] Creating Layer ReLU13
I0619 14:48:21.499071 17263 net.cpp:886] ReLU13 <- Eltwise6
I0619 14:48:21.499083 17263 net.cpp:847] ReLU13 -> Eltwise6 (in-place)
I0619 14:48:21.499095 17263 net.cpp:509] Setting up ReLU13
I0619 14:48:21.499104 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.499110 17263 net.cpp:524] Memory required for data: 588775936
I0619 14:48:21.499116 17263 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0619 14:48:21.499125 17263 net.cpp:459] Creating Layer Eltwise6_ReLU13_0_split
I0619 14:48:21.499132 17263 net.cpp:886] Eltwise6_ReLU13_0_split <- Eltwise6
I0619 14:48:21.499141 17263 net.cpp:860] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0619 14:48:21.499152 17263 net.cpp:860] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0619 14:48:21.499208 17263 net.cpp:509] Setting up Eltwise6_ReLU13_0_split
I0619 14:48:21.499219 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.499228 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.499233 17263 net.cpp:524] Memory required for data: 605553152
I0619 14:48:21.499239 17263 layer_factory.hpp:77] Creating layer Convolution14
I0619 14:48:21.499255 17263 net.cpp:459] Creating Layer Convolution14
I0619 14:48:21.499261 17263 net.cpp:886] Convolution14 <- Eltwise6_ReLU13_0_split_0
I0619 14:48:21.499272 17263 net.cpp:860] Convolution14 -> Convolution14
I0619 14:48:21.499757 17263 net.cpp:509] Setting up Convolution14
I0619 14:48:21.499769 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.499774 17263 net.cpp:524] Memory required for data: 613941760
I0619 14:48:21.499788 17263 layer_factory.hpp:77] Creating layer BatchNorm14
I0619 14:48:21.499799 17263 net.cpp:459] Creating Layer BatchNorm14
I0619 14:48:21.499805 17263 net.cpp:886] BatchNorm14 <- Convolution14
I0619 14:48:21.499816 17263 net.cpp:847] BatchNorm14 -> Convolution14 (in-place)
I0619 14:48:21.500128 17263 net.cpp:509] Setting up BatchNorm14
I0619 14:48:21.500140 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.500146 17263 net.cpp:524] Memory required for data: 622330368
I0619 14:48:21.500164 17263 layer_factory.hpp:77] Creating layer Scale14
I0619 14:48:21.500174 17263 net.cpp:459] Creating Layer Scale14
I0619 14:48:21.500181 17263 net.cpp:886] Scale14 <- Convolution14
I0619 14:48:21.500193 17263 net.cpp:847] Scale14 -> Convolution14 (in-place)
I0619 14:48:21.500247 17263 layer_factory.hpp:77] Creating layer Scale14
I0619 14:48:21.500414 17263 net.cpp:509] Setting up Scale14
I0619 14:48:21.500425 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.500432 17263 net.cpp:524] Memory required for data: 630718976
I0619 14:48:21.500444 17263 layer_factory.hpp:77] Creating layer ReLU14
I0619 14:48:21.500458 17263 net.cpp:459] Creating Layer ReLU14
I0619 14:48:21.500463 17263 net.cpp:886] ReLU14 <- Convolution14
I0619 14:48:21.500471 17263 net.cpp:847] ReLU14 -> Convolution14 (in-place)
I0619 14:48:21.500483 17263 net.cpp:509] Setting up ReLU14
I0619 14:48:21.500491 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.500496 17263 net.cpp:524] Memory required for data: 639107584
I0619 14:48:21.500502 17263 layer_factory.hpp:77] Creating layer Convolution15
I0619 14:48:21.500519 17263 net.cpp:459] Creating Layer Convolution15
I0619 14:48:21.500526 17263 net.cpp:886] Convolution15 <- Convolution14
I0619 14:48:21.500540 17263 net.cpp:860] Convolution15 -> Convolution15
I0619 14:48:21.501039 17263 net.cpp:509] Setting up Convolution15
I0619 14:48:21.501051 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.501056 17263 net.cpp:524] Memory required for data: 647496192
I0619 14:48:21.501070 17263 layer_factory.hpp:77] Creating layer BatchNorm15
I0619 14:48:21.501080 17263 net.cpp:459] Creating Layer BatchNorm15
I0619 14:48:21.501087 17263 net.cpp:886] BatchNorm15 <- Convolution15
I0619 14:48:21.501098 17263 net.cpp:847] BatchNorm15 -> Convolution15 (in-place)
I0619 14:48:21.501401 17263 net.cpp:509] Setting up BatchNorm15
I0619 14:48:21.501430 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.501436 17263 net.cpp:524] Memory required for data: 655884800
I0619 14:48:21.501453 17263 layer_factory.hpp:77] Creating layer Scale15
I0619 14:48:21.501464 17263 net.cpp:459] Creating Layer Scale15
I0619 14:48:21.501471 17263 net.cpp:886] Scale15 <- Convolution15
I0619 14:48:21.501482 17263 net.cpp:847] Scale15 -> Convolution15 (in-place)
I0619 14:48:21.501534 17263 layer_factory.hpp:77] Creating layer Scale15
I0619 14:48:21.501708 17263 net.cpp:509] Setting up Scale15
I0619 14:48:21.501720 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.501726 17263 net.cpp:524] Memory required for data: 664273408
I0619 14:48:21.501739 17263 layer_factory.hpp:77] Creating layer Eltwise7
I0619 14:48:21.501751 17263 net.cpp:459] Creating Layer Eltwise7
I0619 14:48:21.501759 17263 net.cpp:886] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0619 14:48:21.501766 17263 net.cpp:886] Eltwise7 <- Convolution15
I0619 14:48:21.501775 17263 net.cpp:860] Eltwise7 -> Eltwise7
I0619 14:48:21.501812 17263 net.cpp:509] Setting up Eltwise7
I0619 14:48:21.501822 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.501827 17263 net.cpp:524] Memory required for data: 672662016
I0619 14:48:21.501834 17263 layer_factory.hpp:77] Creating layer ReLU15
I0619 14:48:21.501843 17263 net.cpp:459] Creating Layer ReLU15
I0619 14:48:21.501849 17263 net.cpp:886] ReLU15 <- Eltwise7
I0619 14:48:21.501860 17263 net.cpp:847] ReLU15 -> Eltwise7 (in-place)
I0619 14:48:21.501871 17263 net.cpp:509] Setting up ReLU15
I0619 14:48:21.501879 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.501885 17263 net.cpp:524] Memory required for data: 681050624
I0619 14:48:21.501891 17263 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0619 14:48:21.501900 17263 net.cpp:459] Creating Layer Eltwise7_ReLU15_0_split
I0619 14:48:21.501905 17263 net.cpp:886] Eltwise7_ReLU15_0_split <- Eltwise7
I0619 14:48:21.501915 17263 net.cpp:860] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0619 14:48:21.501926 17263 net.cpp:860] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0619 14:48:21.501979 17263 net.cpp:509] Setting up Eltwise7_ReLU15_0_split
I0619 14:48:21.501989 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.501996 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.502002 17263 net.cpp:524] Memory required for data: 697827840
I0619 14:48:21.502008 17263 layer_factory.hpp:77] Creating layer Convolution16
I0619 14:48:21.502023 17263 net.cpp:459] Creating Layer Convolution16
I0619 14:48:21.502030 17263 net.cpp:886] Convolution16 <- Eltwise7_ReLU15_0_split_0
I0619 14:48:21.502040 17263 net.cpp:860] Convolution16 -> Convolution16
I0619 14:48:21.502545 17263 net.cpp:509] Setting up Convolution16
I0619 14:48:21.502559 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.502565 17263 net.cpp:524] Memory required for data: 706216448
I0619 14:48:21.502579 17263 layer_factory.hpp:77] Creating layer BatchNorm16
I0619 14:48:21.502593 17263 net.cpp:459] Creating Layer BatchNorm16
I0619 14:48:21.502599 17263 net.cpp:886] BatchNorm16 <- Convolution16
I0619 14:48:21.502610 17263 net.cpp:847] BatchNorm16 -> Convolution16 (in-place)
I0619 14:48:21.502907 17263 net.cpp:509] Setting up BatchNorm16
I0619 14:48:21.502918 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.502923 17263 net.cpp:524] Memory required for data: 714605056
I0619 14:48:21.502940 17263 layer_factory.hpp:77] Creating layer Scale16
I0619 14:48:21.502953 17263 net.cpp:459] Creating Layer Scale16
I0619 14:48:21.502959 17263 net.cpp:886] Scale16 <- Convolution16
I0619 14:48:21.502969 17263 net.cpp:847] Scale16 -> Convolution16 (in-place)
I0619 14:48:21.503024 17263 layer_factory.hpp:77] Creating layer Scale16
I0619 14:48:21.503196 17263 net.cpp:509] Setting up Scale16
I0619 14:48:21.503207 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.503212 17263 net.cpp:524] Memory required for data: 722993664
I0619 14:48:21.503247 17263 layer_factory.hpp:77] Creating layer ReLU16
I0619 14:48:21.503258 17263 net.cpp:459] Creating Layer ReLU16
I0619 14:48:21.503265 17263 net.cpp:886] ReLU16 <- Convolution16
I0619 14:48:21.503276 17263 net.cpp:847] ReLU16 -> Convolution16 (in-place)
I0619 14:48:21.503288 17263 net.cpp:509] Setting up ReLU16
I0619 14:48:21.503296 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.503303 17263 net.cpp:524] Memory required for data: 731382272
I0619 14:48:21.503307 17263 layer_factory.hpp:77] Creating layer Convolution17
I0619 14:48:21.503336 17263 net.cpp:459] Creating Layer Convolution17
I0619 14:48:21.503345 17263 net.cpp:886] Convolution17 <- Convolution16
I0619 14:48:21.503355 17263 net.cpp:860] Convolution17 -> Convolution17
I0619 14:48:21.503849 17263 net.cpp:509] Setting up Convolution17
I0619 14:48:21.503861 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.503867 17263 net.cpp:524] Memory required for data: 739770880
I0619 14:48:21.503881 17263 layer_factory.hpp:77] Creating layer BatchNorm17
I0619 14:48:21.503906 17263 net.cpp:459] Creating Layer BatchNorm17
I0619 14:48:21.503912 17263 net.cpp:886] BatchNorm17 <- Convolution17
I0619 14:48:21.503921 17263 net.cpp:847] BatchNorm17 -> Convolution17 (in-place)
I0619 14:48:21.504221 17263 net.cpp:509] Setting up BatchNorm17
I0619 14:48:21.504233 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.504238 17263 net.cpp:524] Memory required for data: 748159488
I0619 14:48:21.504257 17263 layer_factory.hpp:77] Creating layer Scale17
I0619 14:48:21.504267 17263 net.cpp:459] Creating Layer Scale17
I0619 14:48:21.504273 17263 net.cpp:886] Scale17 <- Convolution17
I0619 14:48:21.504282 17263 net.cpp:847] Scale17 -> Convolution17 (in-place)
I0619 14:48:21.504338 17263 layer_factory.hpp:77] Creating layer Scale17
I0619 14:48:21.504511 17263 net.cpp:509] Setting up Scale17
I0619 14:48:21.504523 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.504528 17263 net.cpp:524] Memory required for data: 756548096
I0619 14:48:21.504540 17263 layer_factory.hpp:77] Creating layer Eltwise8
I0619 14:48:21.504556 17263 net.cpp:459] Creating Layer Eltwise8
I0619 14:48:21.504565 17263 net.cpp:886] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0619 14:48:21.504572 17263 net.cpp:886] Eltwise8 <- Convolution17
I0619 14:48:21.504582 17263 net.cpp:860] Eltwise8 -> Eltwise8
I0619 14:48:21.504623 17263 net.cpp:509] Setting up Eltwise8
I0619 14:48:21.504633 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.504638 17263 net.cpp:524] Memory required for data: 764936704
I0619 14:48:21.504644 17263 layer_factory.hpp:77] Creating layer ReLU17
I0619 14:48:21.504653 17263 net.cpp:459] Creating Layer ReLU17
I0619 14:48:21.504659 17263 net.cpp:886] ReLU17 <- Eltwise8
I0619 14:48:21.504670 17263 net.cpp:847] ReLU17 -> Eltwise8 (in-place)
I0619 14:48:21.504680 17263 net.cpp:509] Setting up ReLU17
I0619 14:48:21.504688 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.504694 17263 net.cpp:524] Memory required for data: 773325312
I0619 14:48:21.504700 17263 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0619 14:48:21.504709 17263 net.cpp:459] Creating Layer Eltwise8_ReLU17_0_split
I0619 14:48:21.504714 17263 net.cpp:886] Eltwise8_ReLU17_0_split <- Eltwise8
I0619 14:48:21.504722 17263 net.cpp:860] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0619 14:48:21.504732 17263 net.cpp:860] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0619 14:48:21.504787 17263 net.cpp:509] Setting up Eltwise8_ReLU17_0_split
I0619 14:48:21.504796 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.504804 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.504811 17263 net.cpp:524] Memory required for data: 790102528
I0619 14:48:21.504815 17263 layer_factory.hpp:77] Creating layer Convolution18
I0619 14:48:21.504828 17263 net.cpp:459] Creating Layer Convolution18
I0619 14:48:21.504834 17263 net.cpp:886] Convolution18 <- Eltwise8_ReLU17_0_split_0
I0619 14:48:21.504851 17263 net.cpp:860] Convolution18 -> Convolution18
I0619 14:48:21.505357 17263 net.cpp:509] Setting up Convolution18
I0619 14:48:21.505370 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.505376 17263 net.cpp:524] Memory required for data: 798491136
I0619 14:48:21.505390 17263 layer_factory.hpp:77] Creating layer BatchNorm18
I0619 14:48:21.505401 17263 net.cpp:459] Creating Layer BatchNorm18
I0619 14:48:21.505408 17263 net.cpp:886] BatchNorm18 <- Convolution18
I0619 14:48:21.505419 17263 net.cpp:847] BatchNorm18 -> Convolution18 (in-place)
I0619 14:48:21.505729 17263 net.cpp:509] Setting up BatchNorm18
I0619 14:48:21.505741 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.505748 17263 net.cpp:524] Memory required for data: 806879744
I0619 14:48:21.505764 17263 layer_factory.hpp:77] Creating layer Scale18
I0619 14:48:21.505774 17263 net.cpp:459] Creating Layer Scale18
I0619 14:48:21.505779 17263 net.cpp:886] Scale18 <- Convolution18
I0619 14:48:21.505787 17263 net.cpp:847] Scale18 -> Convolution18 (in-place)
I0619 14:48:21.505843 17263 layer_factory.hpp:77] Creating layer Scale18
I0619 14:48:21.506036 17263 net.cpp:509] Setting up Scale18
I0619 14:48:21.506048 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.506057 17263 net.cpp:524] Memory required for data: 815268352
I0619 14:48:21.506073 17263 layer_factory.hpp:77] Creating layer ReLU18
I0619 14:48:21.506083 17263 net.cpp:459] Creating Layer ReLU18
I0619 14:48:21.506090 17263 net.cpp:886] ReLU18 <- Convolution18
I0619 14:48:21.506101 17263 net.cpp:847] ReLU18 -> Convolution18 (in-place)
I0619 14:48:21.506113 17263 net.cpp:509] Setting up ReLU18
I0619 14:48:21.506120 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.506126 17263 net.cpp:524] Memory required for data: 823656960
I0619 14:48:21.506131 17263 layer_factory.hpp:77] Creating layer Convolution19
I0619 14:48:21.506145 17263 net.cpp:459] Creating Layer Convolution19
I0619 14:48:21.506151 17263 net.cpp:886] Convolution19 <- Convolution18
I0619 14:48:21.506163 17263 net.cpp:860] Convolution19 -> Convolution19
I0619 14:48:21.506670 17263 net.cpp:509] Setting up Convolution19
I0619 14:48:21.506685 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.506691 17263 net.cpp:524] Memory required for data: 832045568
I0619 14:48:21.506705 17263 layer_factory.hpp:77] Creating layer BatchNorm19
I0619 14:48:21.506716 17263 net.cpp:459] Creating Layer BatchNorm19
I0619 14:48:21.506722 17263 net.cpp:886] BatchNorm19 <- Convolution19
I0619 14:48:21.506733 17263 net.cpp:847] BatchNorm19 -> Convolution19 (in-place)
I0619 14:48:21.507040 17263 net.cpp:509] Setting up BatchNorm19
I0619 14:48:21.507050 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.507056 17263 net.cpp:524] Memory required for data: 840434176
I0619 14:48:21.507094 17263 layer_factory.hpp:77] Creating layer Scale19
I0619 14:48:21.507105 17263 net.cpp:459] Creating Layer Scale19
I0619 14:48:21.507112 17263 net.cpp:886] Scale19 <- Convolution19
I0619 14:48:21.507120 17263 net.cpp:847] Scale19 -> Convolution19 (in-place)
I0619 14:48:21.507177 17263 layer_factory.hpp:77] Creating layer Scale19
I0619 14:48:21.507344 17263 net.cpp:509] Setting up Scale19
I0619 14:48:21.507355 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.507361 17263 net.cpp:524] Memory required for data: 848822784
I0619 14:48:21.507375 17263 layer_factory.hpp:77] Creating layer Eltwise9
I0619 14:48:21.507387 17263 net.cpp:459] Creating Layer Eltwise9
I0619 14:48:21.507395 17263 net.cpp:886] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0619 14:48:21.507402 17263 net.cpp:886] Eltwise9 <- Convolution19
I0619 14:48:21.507411 17263 net.cpp:860] Eltwise9 -> Eltwise9
I0619 14:48:21.507443 17263 net.cpp:509] Setting up Eltwise9
I0619 14:48:21.507452 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.507457 17263 net.cpp:524] Memory required for data: 857211392
I0619 14:48:21.507463 17263 layer_factory.hpp:77] Creating layer ReLU19
I0619 14:48:21.507474 17263 net.cpp:459] Creating Layer ReLU19
I0619 14:48:21.507498 17263 net.cpp:886] ReLU19 <- Eltwise9
I0619 14:48:21.507509 17263 net.cpp:847] ReLU19 -> Eltwise9 (in-place)
I0619 14:48:21.507520 17263 net.cpp:509] Setting up ReLU19
I0619 14:48:21.507529 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.507534 17263 net.cpp:524] Memory required for data: 865600000
I0619 14:48:21.507539 17263 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0619 14:48:21.507546 17263 net.cpp:459] Creating Layer Eltwise9_ReLU19_0_split
I0619 14:48:21.507552 17263 net.cpp:886] Eltwise9_ReLU19_0_split <- Eltwise9
I0619 14:48:21.507560 17263 net.cpp:860] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0619 14:48:21.507572 17263 net.cpp:860] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0619 14:48:21.507627 17263 net.cpp:509] Setting up Eltwise9_ReLU19_0_split
I0619 14:48:21.507637 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.507645 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.507650 17263 net.cpp:524] Memory required for data: 882377216
I0619 14:48:21.507657 17263 layer_factory.hpp:77] Creating layer Convolution20
I0619 14:48:21.507668 17263 net.cpp:459] Creating Layer Convolution20
I0619 14:48:21.507674 17263 net.cpp:886] Convolution20 <- Eltwise9_ReLU19_0_split_0
I0619 14:48:21.507690 17263 net.cpp:860] Convolution20 -> Convolution20
I0619 14:48:21.508137 17263 net.cpp:509] Setting up Convolution20
I0619 14:48:21.508149 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.508155 17263 net.cpp:524] Memory required for data: 890765824
I0619 14:48:21.508169 17263 layer_factory.hpp:77] Creating layer BatchNorm20
I0619 14:48:21.508178 17263 net.cpp:459] Creating Layer BatchNorm20
I0619 14:48:21.508185 17263 net.cpp:886] BatchNorm20 <- Convolution20
I0619 14:48:21.508196 17263 net.cpp:847] BatchNorm20 -> Convolution20 (in-place)
I0619 14:48:21.508479 17263 net.cpp:509] Setting up BatchNorm20
I0619 14:48:21.508491 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.508496 17263 net.cpp:524] Memory required for data: 899154432
I0619 14:48:21.508510 17263 layer_factory.hpp:77] Creating layer Scale20
I0619 14:48:21.508520 17263 net.cpp:459] Creating Layer Scale20
I0619 14:48:21.508527 17263 net.cpp:886] Scale20 <- Convolution20
I0619 14:48:21.508534 17263 net.cpp:847] Scale20 -> Convolution20 (in-place)
I0619 14:48:21.508582 17263 layer_factory.hpp:77] Creating layer Scale20
I0619 14:48:21.508747 17263 net.cpp:509] Setting up Scale20
I0619 14:48:21.508759 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.508764 17263 net.cpp:524] Memory required for data: 907543040
I0619 14:48:21.508775 17263 layer_factory.hpp:77] Creating layer ReLU20
I0619 14:48:21.508785 17263 net.cpp:459] Creating Layer ReLU20
I0619 14:48:21.508790 17263 net.cpp:886] ReLU20 <- Convolution20
I0619 14:48:21.508801 17263 net.cpp:847] ReLU20 -> Convolution20 (in-place)
I0619 14:48:21.508810 17263 net.cpp:509] Setting up ReLU20
I0619 14:48:21.508818 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.508823 17263 net.cpp:524] Memory required for data: 915931648
I0619 14:48:21.508828 17263 layer_factory.hpp:77] Creating layer Convolution21
I0619 14:48:21.508844 17263 net.cpp:459] Creating Layer Convolution21
I0619 14:48:21.508851 17263 net.cpp:886] Convolution21 <- Convolution20
I0619 14:48:21.508860 17263 net.cpp:860] Convolution21 -> Convolution21
I0619 14:48:21.509322 17263 net.cpp:509] Setting up Convolution21
I0619 14:48:21.509335 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.509341 17263 net.cpp:524] Memory required for data: 924320256
I0619 14:48:21.509352 17263 layer_factory.hpp:77] Creating layer BatchNorm21
I0619 14:48:21.509362 17263 net.cpp:459] Creating Layer BatchNorm21
I0619 14:48:21.509368 17263 net.cpp:886] BatchNorm21 <- Convolution21
I0619 14:48:21.509382 17263 net.cpp:847] BatchNorm21 -> Convolution21 (in-place)
I0619 14:48:21.509663 17263 net.cpp:509] Setting up BatchNorm21
I0619 14:48:21.509677 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.509699 17263 net.cpp:524] Memory required for data: 932708864
I0619 14:48:21.509717 17263 layer_factory.hpp:77] Creating layer Scale21
I0619 14:48:21.509728 17263 net.cpp:459] Creating Layer Scale21
I0619 14:48:21.509734 17263 net.cpp:886] Scale21 <- Convolution21
I0619 14:48:21.509747 17263 net.cpp:847] Scale21 -> Convolution21 (in-place)
I0619 14:48:21.509796 17263 layer_factory.hpp:77] Creating layer Scale21
I0619 14:48:21.509955 17263 net.cpp:509] Setting up Scale21
I0619 14:48:21.509968 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.509973 17263 net.cpp:524] Memory required for data: 941097472
I0619 14:48:21.509985 17263 layer_factory.hpp:77] Creating layer Eltwise10
I0619 14:48:21.509999 17263 net.cpp:459] Creating Layer Eltwise10
I0619 14:48:21.510005 17263 net.cpp:886] Eltwise10 <- Eltwise9_ReLU19_0_split_1
I0619 14:48:21.510013 17263 net.cpp:886] Eltwise10 <- Convolution21
I0619 14:48:21.510023 17263 net.cpp:860] Eltwise10 -> Eltwise10
I0619 14:48:21.510058 17263 net.cpp:509] Setting up Eltwise10
I0619 14:48:21.510067 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.510073 17263 net.cpp:524] Memory required for data: 949486080
I0619 14:48:21.510078 17263 layer_factory.hpp:77] Creating layer ReLU21
I0619 14:48:21.510087 17263 net.cpp:459] Creating Layer ReLU21
I0619 14:48:21.510093 17263 net.cpp:886] ReLU21 <- Eltwise10
I0619 14:48:21.510103 17263 net.cpp:847] ReLU21 -> Eltwise10 (in-place)
I0619 14:48:21.510113 17263 net.cpp:509] Setting up ReLU21
I0619 14:48:21.510120 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.510126 17263 net.cpp:524] Memory required for data: 957874688
I0619 14:48:21.510131 17263 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0619 14:48:21.510139 17263 net.cpp:459] Creating Layer Eltwise10_ReLU21_0_split
I0619 14:48:21.510144 17263 net.cpp:886] Eltwise10_ReLU21_0_split <- Eltwise10
I0619 14:48:21.510152 17263 net.cpp:860] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0619 14:48:21.510162 17263 net.cpp:860] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0619 14:48:21.510213 17263 net.cpp:509] Setting up Eltwise10_ReLU21_0_split
I0619 14:48:21.510222 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.510231 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.510236 17263 net.cpp:524] Memory required for data: 974651904
I0619 14:48:21.510241 17263 layer_factory.hpp:77] Creating layer Convolution22
I0619 14:48:21.510257 17263 net.cpp:459] Creating Layer Convolution22
I0619 14:48:21.510263 17263 net.cpp:886] Convolution22 <- Eltwise10_ReLU21_0_split_0
I0619 14:48:21.510273 17263 net.cpp:860] Convolution22 -> Convolution22
I0619 14:48:21.510738 17263 net.cpp:509] Setting up Convolution22
I0619 14:48:21.510751 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.510756 17263 net.cpp:524] Memory required for data: 983040512
I0619 14:48:21.510771 17263 layer_factory.hpp:77] Creating layer BatchNorm22
I0619 14:48:21.510784 17263 net.cpp:459] Creating Layer BatchNorm22
I0619 14:48:21.510790 17263 net.cpp:886] BatchNorm22 <- Convolution22
I0619 14:48:21.510802 17263 net.cpp:847] BatchNorm22 -> Convolution22 (in-place)
I0619 14:48:21.511087 17263 net.cpp:509] Setting up BatchNorm22
I0619 14:48:21.511097 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.511102 17263 net.cpp:524] Memory required for data: 991429120
I0619 14:48:21.511117 17263 layer_factory.hpp:77] Creating layer Scale22
I0619 14:48:21.511129 17263 net.cpp:459] Creating Layer Scale22
I0619 14:48:21.511135 17263 net.cpp:886] Scale22 <- Convolution22
I0619 14:48:21.511144 17263 net.cpp:847] Scale22 -> Convolution22 (in-place)
I0619 14:48:21.511193 17263 layer_factory.hpp:77] Creating layer Scale22
I0619 14:48:21.511364 17263 net.cpp:509] Setting up Scale22
I0619 14:48:21.511375 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.511381 17263 net.cpp:524] Memory required for data: 999817728
I0619 14:48:21.511399 17263 layer_factory.hpp:77] Creating layer ReLU22
I0619 14:48:21.511423 17263 net.cpp:459] Creating Layer ReLU22
I0619 14:48:21.511430 17263 net.cpp:886] ReLU22 <- Convolution22
I0619 14:48:21.511441 17263 net.cpp:847] ReLU22 -> Convolution22 (in-place)
I0619 14:48:21.511451 17263 net.cpp:509] Setting up ReLU22
I0619 14:48:21.511459 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.511466 17263 net.cpp:524] Memory required for data: 1008206336
I0619 14:48:21.511471 17263 layer_factory.hpp:77] Creating layer Convolution23
I0619 14:48:21.511485 17263 net.cpp:459] Creating Layer Convolution23
I0619 14:48:21.511492 17263 net.cpp:886] Convolution23 <- Convolution22
I0619 14:48:21.511502 17263 net.cpp:860] Convolution23 -> Convolution23
I0619 14:48:21.511976 17263 net.cpp:509] Setting up Convolution23
I0619 14:48:21.511991 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.511997 17263 net.cpp:524] Memory required for data: 1016594944
I0619 14:48:21.512011 17263 layer_factory.hpp:77] Creating layer BatchNorm23
I0619 14:48:21.512023 17263 net.cpp:459] Creating Layer BatchNorm23
I0619 14:48:21.512030 17263 net.cpp:886] BatchNorm23 <- Convolution23
I0619 14:48:21.512042 17263 net.cpp:847] BatchNorm23 -> Convolution23 (in-place)
I0619 14:48:21.512329 17263 net.cpp:509] Setting up BatchNorm23
I0619 14:48:21.512341 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.512346 17263 net.cpp:524] Memory required for data: 1024983552
I0619 14:48:21.512362 17263 layer_factory.hpp:77] Creating layer Scale23
I0619 14:48:21.512373 17263 net.cpp:459] Creating Layer Scale23
I0619 14:48:21.512380 17263 net.cpp:886] Scale23 <- Convolution23
I0619 14:48:21.512388 17263 net.cpp:847] Scale23 -> Convolution23 (in-place)
I0619 14:48:21.512439 17263 layer_factory.hpp:77] Creating layer Scale23
I0619 14:48:21.512600 17263 net.cpp:509] Setting up Scale23
I0619 14:48:21.512610 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.512616 17263 net.cpp:524] Memory required for data: 1033372160
I0619 14:48:21.512629 17263 layer_factory.hpp:77] Creating layer Eltwise11
I0619 14:48:21.512637 17263 net.cpp:459] Creating Layer Eltwise11
I0619 14:48:21.512645 17263 net.cpp:886] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0619 14:48:21.512651 17263 net.cpp:886] Eltwise11 <- Convolution23
I0619 14:48:21.512665 17263 net.cpp:860] Eltwise11 -> Eltwise11
I0619 14:48:21.512699 17263 net.cpp:509] Setting up Eltwise11
I0619 14:48:21.512711 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.512717 17263 net.cpp:524] Memory required for data: 1041760768
I0619 14:48:21.512722 17263 layer_factory.hpp:77] Creating layer ReLU23
I0619 14:48:21.512730 17263 net.cpp:459] Creating Layer ReLU23
I0619 14:48:21.512735 17263 net.cpp:886] ReLU23 <- Eltwise11
I0619 14:48:21.512743 17263 net.cpp:847] ReLU23 -> Eltwise11 (in-place)
I0619 14:48:21.512753 17263 net.cpp:509] Setting up ReLU23
I0619 14:48:21.512759 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.512765 17263 net.cpp:524] Memory required for data: 1050149376
I0619 14:48:21.512770 17263 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0619 14:48:21.512778 17263 net.cpp:459] Creating Layer Eltwise11_ReLU23_0_split
I0619 14:48:21.512784 17263 net.cpp:886] Eltwise11_ReLU23_0_split <- Eltwise11
I0619 14:48:21.512794 17263 net.cpp:860] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0619 14:48:21.512804 17263 net.cpp:860] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0619 14:48:21.512852 17263 net.cpp:509] Setting up Eltwise11_ReLU23_0_split
I0619 14:48:21.512866 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.512873 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.512879 17263 net.cpp:524] Memory required for data: 1066926592
I0619 14:48:21.512884 17263 layer_factory.hpp:77] Creating layer Convolution24
I0619 14:48:21.512897 17263 net.cpp:459] Creating Layer Convolution24
I0619 14:48:21.512902 17263 net.cpp:886] Convolution24 <- Eltwise11_ReLU23_0_split_0
I0619 14:48:21.512933 17263 net.cpp:860] Convolution24 -> Convolution24
I0619 14:48:21.513387 17263 net.cpp:509] Setting up Convolution24
I0619 14:48:21.513401 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.513406 17263 net.cpp:524] Memory required for data: 1075315200
I0619 14:48:21.513419 17263 layer_factory.hpp:77] Creating layer BatchNorm24
I0619 14:48:21.513432 17263 net.cpp:459] Creating Layer BatchNorm24
I0619 14:48:21.513437 17263 net.cpp:886] BatchNorm24 <- Convolution24
I0619 14:48:21.513445 17263 net.cpp:847] BatchNorm24 -> Convolution24 (in-place)
I0619 14:48:21.513726 17263 net.cpp:509] Setting up BatchNorm24
I0619 14:48:21.513737 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.513742 17263 net.cpp:524] Memory required for data: 1083703808
I0619 14:48:21.513758 17263 layer_factory.hpp:77] Creating layer Scale24
I0619 14:48:21.513769 17263 net.cpp:459] Creating Layer Scale24
I0619 14:48:21.513775 17263 net.cpp:886] Scale24 <- Convolution24
I0619 14:48:21.513783 17263 net.cpp:847] Scale24 -> Convolution24 (in-place)
I0619 14:48:21.513833 17263 layer_factory.hpp:77] Creating layer Scale24
I0619 14:48:21.513999 17263 net.cpp:509] Setting up Scale24
I0619 14:48:21.514009 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.514015 17263 net.cpp:524] Memory required for data: 1092092416
I0619 14:48:21.514027 17263 layer_factory.hpp:77] Creating layer ReLU24
I0619 14:48:21.514039 17263 net.cpp:459] Creating Layer ReLU24
I0619 14:48:21.514045 17263 net.cpp:886] ReLU24 <- Convolution24
I0619 14:48:21.514052 17263 net.cpp:847] ReLU24 -> Convolution24 (in-place)
I0619 14:48:21.514061 17263 net.cpp:509] Setting up ReLU24
I0619 14:48:21.514070 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.514075 17263 net.cpp:524] Memory required for data: 1100481024
I0619 14:48:21.514081 17263 layer_factory.hpp:77] Creating layer Convolution25
I0619 14:48:21.514094 17263 net.cpp:459] Creating Layer Convolution25
I0619 14:48:21.514101 17263 net.cpp:886] Convolution25 <- Convolution24
I0619 14:48:21.514111 17263 net.cpp:860] Convolution25 -> Convolution25
I0619 14:48:21.514575 17263 net.cpp:509] Setting up Convolution25
I0619 14:48:21.514588 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.514593 17263 net.cpp:524] Memory required for data: 1108869632
I0619 14:48:21.514606 17263 layer_factory.hpp:77] Creating layer BatchNorm25
I0619 14:48:21.514616 17263 net.cpp:459] Creating Layer BatchNorm25
I0619 14:48:21.514622 17263 net.cpp:886] BatchNorm25 <- Convolution25
I0619 14:48:21.514631 17263 net.cpp:847] BatchNorm25 -> Convolution25 (in-place)
I0619 14:48:21.514915 17263 net.cpp:509] Setting up BatchNorm25
I0619 14:48:21.514925 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.514931 17263 net.cpp:524] Memory required for data: 1117258240
I0619 14:48:21.514946 17263 layer_factory.hpp:77] Creating layer Scale25
I0619 14:48:21.514955 17263 net.cpp:459] Creating Layer Scale25
I0619 14:48:21.514961 17263 net.cpp:886] Scale25 <- Convolution25
I0619 14:48:21.514969 17263 net.cpp:847] Scale25 -> Convolution25 (in-place)
I0619 14:48:21.515022 17263 layer_factory.hpp:77] Creating layer Scale25
I0619 14:48:21.515180 17263 net.cpp:509] Setting up Scale25
I0619 14:48:21.515192 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.515197 17263 net.cpp:524] Memory required for data: 1125646848
I0619 14:48:21.515211 17263 layer_factory.hpp:77] Creating layer Eltwise12
I0619 14:48:21.515220 17263 net.cpp:459] Creating Layer Eltwise12
I0619 14:48:21.515228 17263 net.cpp:886] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0619 14:48:21.515234 17263 net.cpp:886] Eltwise12 <- Convolution25
I0619 14:48:21.515245 17263 net.cpp:860] Eltwise12 -> Eltwise12
I0619 14:48:21.515278 17263 net.cpp:509] Setting up Eltwise12
I0619 14:48:21.515287 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.515292 17263 net.cpp:524] Memory required for data: 1134035456
I0619 14:48:21.515297 17263 layer_factory.hpp:77] Creating layer ReLU25
I0619 14:48:21.515313 17263 net.cpp:459] Creating Layer ReLU25
I0619 14:48:21.515336 17263 net.cpp:886] ReLU25 <- Eltwise12
I0619 14:48:21.515346 17263 net.cpp:847] ReLU25 -> Eltwise12 (in-place)
I0619 14:48:21.515355 17263 net.cpp:509] Setting up ReLU25
I0619 14:48:21.515364 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.515369 17263 net.cpp:524] Memory required for data: 1142424064
I0619 14:48:21.515375 17263 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I0619 14:48:21.515383 17263 net.cpp:459] Creating Layer Eltwise12_ReLU25_0_split
I0619 14:48:21.515388 17263 net.cpp:886] Eltwise12_ReLU25_0_split <- Eltwise12
I0619 14:48:21.515399 17263 net.cpp:860] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I0619 14:48:21.515410 17263 net.cpp:860] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I0619 14:48:21.515471 17263 net.cpp:509] Setting up Eltwise12_ReLU25_0_split
I0619 14:48:21.515481 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.515489 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.515496 17263 net.cpp:524] Memory required for data: 1159201280
I0619 14:48:21.515501 17263 layer_factory.hpp:77] Creating layer Convolution26
I0619 14:48:21.515516 17263 net.cpp:459] Creating Layer Convolution26
I0619 14:48:21.515522 17263 net.cpp:886] Convolution26 <- Eltwise12_ReLU25_0_split_0
I0619 14:48:21.515532 17263 net.cpp:860] Convolution26 -> Convolution26
I0619 14:48:21.515995 17263 net.cpp:509] Setting up Convolution26
I0619 14:48:21.516007 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.516013 17263 net.cpp:524] Memory required for data: 1167589888
I0619 14:48:21.516026 17263 layer_factory.hpp:77] Creating layer BatchNorm26
I0619 14:48:21.516041 17263 net.cpp:459] Creating Layer BatchNorm26
I0619 14:48:21.516047 17263 net.cpp:886] BatchNorm26 <- Convolution26
I0619 14:48:21.516055 17263 net.cpp:847] BatchNorm26 -> Convolution26 (in-place)
I0619 14:48:21.516340 17263 net.cpp:509] Setting up BatchNorm26
I0619 14:48:21.516350 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.516355 17263 net.cpp:524] Memory required for data: 1175978496
I0619 14:48:21.516371 17263 layer_factory.hpp:77] Creating layer Scale26
I0619 14:48:21.516398 17263 net.cpp:459] Creating Layer Scale26
I0619 14:48:21.516405 17263 net.cpp:886] Scale26 <- Convolution26
I0619 14:48:21.516414 17263 net.cpp:847] Scale26 -> Convolution26 (in-place)
I0619 14:48:21.516466 17263 layer_factory.hpp:77] Creating layer Scale26
I0619 14:48:21.516626 17263 net.cpp:509] Setting up Scale26
I0619 14:48:21.516638 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.516644 17263 net.cpp:524] Memory required for data: 1184367104
I0619 14:48:21.516659 17263 layer_factory.hpp:77] Creating layer ReLU26
I0619 14:48:21.516667 17263 net.cpp:459] Creating Layer ReLU26
I0619 14:48:21.516674 17263 net.cpp:886] ReLU26 <- Convolution26
I0619 14:48:21.516681 17263 net.cpp:847] ReLU26 -> Convolution26 (in-place)
I0619 14:48:21.516691 17263 net.cpp:509] Setting up ReLU26
I0619 14:48:21.516700 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.516705 17263 net.cpp:524] Memory required for data: 1192755712
I0619 14:48:21.516710 17263 layer_factory.hpp:77] Creating layer Convolution27
I0619 14:48:21.516724 17263 net.cpp:459] Creating Layer Convolution27
I0619 14:48:21.516731 17263 net.cpp:886] Convolution27 <- Convolution26
I0619 14:48:21.516739 17263 net.cpp:860] Convolution27 -> Convolution27
I0619 14:48:21.517194 17263 net.cpp:509] Setting up Convolution27
I0619 14:48:21.517206 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.517212 17263 net.cpp:524] Memory required for data: 1201144320
I0619 14:48:21.517225 17263 layer_factory.hpp:77] Creating layer BatchNorm27
I0619 14:48:21.517236 17263 net.cpp:459] Creating Layer BatchNorm27
I0619 14:48:21.517242 17263 net.cpp:886] BatchNorm27 <- Convolution27
I0619 14:48:21.517252 17263 net.cpp:847] BatchNorm27 -> Convolution27 (in-place)
I0619 14:48:21.517537 17263 net.cpp:509] Setting up BatchNorm27
I0619 14:48:21.517565 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.517570 17263 net.cpp:524] Memory required for data: 1209532928
I0619 14:48:21.517586 17263 layer_factory.hpp:77] Creating layer Scale27
I0619 14:48:21.517599 17263 net.cpp:459] Creating Layer Scale27
I0619 14:48:21.517606 17263 net.cpp:886] Scale27 <- Convolution27
I0619 14:48:21.517614 17263 net.cpp:847] Scale27 -> Convolution27 (in-place)
I0619 14:48:21.517664 17263 layer_factory.hpp:77] Creating layer Scale27
I0619 14:48:21.517834 17263 net.cpp:509] Setting up Scale27
I0619 14:48:21.517845 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.517851 17263 net.cpp:524] Memory required for data: 1217921536
I0619 14:48:21.517864 17263 layer_factory.hpp:77] Creating layer Eltwise13
I0619 14:48:21.517874 17263 net.cpp:459] Creating Layer Eltwise13
I0619 14:48:21.517880 17263 net.cpp:886] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I0619 14:48:21.517887 17263 net.cpp:886] Eltwise13 <- Convolution27
I0619 14:48:21.517899 17263 net.cpp:860] Eltwise13 -> Eltwise13
I0619 14:48:21.517932 17263 net.cpp:509] Setting up Eltwise13
I0619 14:48:21.517945 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.517951 17263 net.cpp:524] Memory required for data: 1226310144
I0619 14:48:21.517956 17263 layer_factory.hpp:77] Creating layer ReLU27
I0619 14:48:21.517963 17263 net.cpp:459] Creating Layer ReLU27
I0619 14:48:21.517969 17263 net.cpp:886] ReLU27 <- Eltwise13
I0619 14:48:21.517976 17263 net.cpp:847] ReLU27 -> Eltwise13 (in-place)
I0619 14:48:21.517985 17263 net.cpp:509] Setting up ReLU27
I0619 14:48:21.517993 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.517998 17263 net.cpp:524] Memory required for data: 1234698752
I0619 14:48:21.518003 17263 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I0619 14:48:21.518012 17263 net.cpp:459] Creating Layer Eltwise13_ReLU27_0_split
I0619 14:48:21.518018 17263 net.cpp:886] Eltwise13_ReLU27_0_split <- Eltwise13
I0619 14:48:21.518030 17263 net.cpp:860] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I0619 14:48:21.518041 17263 net.cpp:860] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I0619 14:48:21.518090 17263 net.cpp:509] Setting up Eltwise13_ReLU27_0_split
I0619 14:48:21.518100 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.518106 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.518111 17263 net.cpp:524] Memory required for data: 1251475968
I0619 14:48:21.518117 17263 layer_factory.hpp:77] Creating layer Convolution28
I0619 14:48:21.518132 17263 net.cpp:459] Creating Layer Convolution28
I0619 14:48:21.518138 17263 net.cpp:886] Convolution28 <- Eltwise13_ReLU27_0_split_0
I0619 14:48:21.518148 17263 net.cpp:860] Convolution28 -> Convolution28
I0619 14:48:21.518622 17263 net.cpp:509] Setting up Convolution28
I0619 14:48:21.518636 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.518641 17263 net.cpp:524] Memory required for data: 1259864576
I0619 14:48:21.518654 17263 layer_factory.hpp:77] Creating layer BatchNorm28
I0619 14:48:21.518666 17263 net.cpp:459] Creating Layer BatchNorm28
I0619 14:48:21.518673 17263 net.cpp:886] BatchNorm28 <- Convolution28
I0619 14:48:21.518682 17263 net.cpp:847] BatchNorm28 -> Convolution28 (in-place)
I0619 14:48:21.518962 17263 net.cpp:509] Setting up BatchNorm28
I0619 14:48:21.518972 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.518977 17263 net.cpp:524] Memory required for data: 1268253184
I0619 14:48:21.518995 17263 layer_factory.hpp:77] Creating layer Scale28
I0619 14:48:21.519003 17263 net.cpp:459] Creating Layer Scale28
I0619 14:48:21.519009 17263 net.cpp:886] Scale28 <- Convolution28
I0619 14:48:21.519016 17263 net.cpp:847] Scale28 -> Convolution28 (in-place)
I0619 14:48:21.519063 17263 layer_factory.hpp:77] Creating layer Scale28
I0619 14:48:21.519214 17263 net.cpp:509] Setting up Scale28
I0619 14:48:21.519224 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.519233 17263 net.cpp:524] Memory required for data: 1276641792
I0619 14:48:21.519263 17263 layer_factory.hpp:77] Creating layer ReLU28
I0619 14:48:21.519275 17263 net.cpp:459] Creating Layer ReLU28
I0619 14:48:21.519281 17263 net.cpp:886] ReLU28 <- Convolution28
I0619 14:48:21.519289 17263 net.cpp:847] ReLU28 -> Convolution28 (in-place)
I0619 14:48:21.519299 17263 net.cpp:509] Setting up ReLU28
I0619 14:48:21.519305 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.519310 17263 net.cpp:524] Memory required for data: 1285030400
I0619 14:48:21.519316 17263 layer_factory.hpp:77] Creating layer Convolution29
I0619 14:48:21.519330 17263 net.cpp:459] Creating Layer Convolution29
I0619 14:48:21.519336 17263 net.cpp:886] Convolution29 <- Convolution28
I0619 14:48:21.519345 17263 net.cpp:860] Convolution29 -> Convolution29
I0619 14:48:21.519783 17263 net.cpp:509] Setting up Convolution29
I0619 14:48:21.519795 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.519800 17263 net.cpp:524] Memory required for data: 1293419008
I0619 14:48:21.519812 17263 layer_factory.hpp:77] Creating layer BatchNorm29
I0619 14:48:21.519824 17263 net.cpp:459] Creating Layer BatchNorm29
I0619 14:48:21.519831 17263 net.cpp:886] BatchNorm29 <- Convolution29
I0619 14:48:21.519839 17263 net.cpp:847] BatchNorm29 -> Convolution29 (in-place)
I0619 14:48:21.520112 17263 net.cpp:509] Setting up BatchNorm29
I0619 14:48:21.520123 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.520128 17263 net.cpp:524] Memory required for data: 1301807616
I0619 14:48:21.520141 17263 layer_factory.hpp:77] Creating layer Scale29
I0619 14:48:21.520150 17263 net.cpp:459] Creating Layer Scale29
I0619 14:48:21.520156 17263 net.cpp:886] Scale29 <- Convolution29
I0619 14:48:21.520164 17263 net.cpp:847] Scale29 -> Convolution29 (in-place)
I0619 14:48:21.520212 17263 layer_factory.hpp:77] Creating layer Scale29
I0619 14:48:21.520370 17263 net.cpp:509] Setting up Scale29
I0619 14:48:21.520380 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.520385 17263 net.cpp:524] Memory required for data: 1310196224
I0619 14:48:21.520397 17263 layer_factory.hpp:77] Creating layer Eltwise14
I0619 14:48:21.520407 17263 net.cpp:459] Creating Layer Eltwise14
I0619 14:48:21.520413 17263 net.cpp:886] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I0619 14:48:21.520421 17263 net.cpp:886] Eltwise14 <- Convolution29
I0619 14:48:21.520431 17263 net.cpp:860] Eltwise14 -> Eltwise14
I0619 14:48:21.520460 17263 net.cpp:509] Setting up Eltwise14
I0619 14:48:21.520469 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.520474 17263 net.cpp:524] Memory required for data: 1318584832
I0619 14:48:21.520479 17263 layer_factory.hpp:77] Creating layer ReLU29
I0619 14:48:21.520489 17263 net.cpp:459] Creating Layer ReLU29
I0619 14:48:21.520494 17263 net.cpp:886] ReLU29 <- Eltwise14
I0619 14:48:21.520503 17263 net.cpp:847] ReLU29 -> Eltwise14 (in-place)
I0619 14:48:21.520510 17263 net.cpp:509] Setting up ReLU29
I0619 14:48:21.520517 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.520522 17263 net.cpp:524] Memory required for data: 1326973440
I0619 14:48:21.520527 17263 layer_factory.hpp:77] Creating layer Eltwise14_ReLU29_0_split
I0619 14:48:21.520535 17263 net.cpp:459] Creating Layer Eltwise14_ReLU29_0_split
I0619 14:48:21.520540 17263 net.cpp:886] Eltwise14_ReLU29_0_split <- Eltwise14
I0619 14:48:21.520547 17263 net.cpp:860] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_0
I0619 14:48:21.520557 17263 net.cpp:860] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_1
I0619 14:48:21.520606 17263 net.cpp:509] Setting up Eltwise14_ReLU29_0_split
I0619 14:48:21.520615 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.520622 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.520627 17263 net.cpp:524] Memory required for data: 1343750656
I0619 14:48:21.520632 17263 layer_factory.hpp:77] Creating layer Convolution30
I0619 14:48:21.520643 17263 net.cpp:459] Creating Layer Convolution30
I0619 14:48:21.520653 17263 net.cpp:886] Convolution30 <- Eltwise14_ReLU29_0_split_0
I0619 14:48:21.520681 17263 net.cpp:860] Convolution30 -> Convolution30
I0619 14:48:21.521118 17263 net.cpp:509] Setting up Convolution30
I0619 14:48:21.521131 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.521136 17263 net.cpp:524] Memory required for data: 1352139264
I0619 14:48:21.521148 17263 layer_factory.hpp:77] Creating layer BatchNorm30
I0619 14:48:21.521157 17263 net.cpp:459] Creating Layer BatchNorm30
I0619 14:48:21.521163 17263 net.cpp:886] BatchNorm30 <- Convolution30
I0619 14:48:21.521173 17263 net.cpp:847] BatchNorm30 -> Convolution30 (in-place)
I0619 14:48:21.521436 17263 net.cpp:509] Setting up BatchNorm30
I0619 14:48:21.521446 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.521451 17263 net.cpp:524] Memory required for data: 1360527872
I0619 14:48:21.521466 17263 layer_factory.hpp:77] Creating layer Scale30
I0619 14:48:21.521474 17263 net.cpp:459] Creating Layer Scale30
I0619 14:48:21.521481 17263 net.cpp:886] Scale30 <- Convolution30
I0619 14:48:21.521492 17263 net.cpp:847] Scale30 -> Convolution30 (in-place)
I0619 14:48:21.521538 17263 layer_factory.hpp:77] Creating layer Scale30
I0619 14:48:21.521692 17263 net.cpp:509] Setting up Scale30
I0619 14:48:21.521703 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.521708 17263 net.cpp:524] Memory required for data: 1368916480
I0619 14:48:21.521719 17263 layer_factory.hpp:77] Creating layer ReLU30
I0619 14:48:21.521729 17263 net.cpp:459] Creating Layer ReLU30
I0619 14:48:21.521735 17263 net.cpp:886] ReLU30 <- Convolution30
I0619 14:48:21.521744 17263 net.cpp:847] ReLU30 -> Convolution30 (in-place)
I0619 14:48:21.521751 17263 net.cpp:509] Setting up ReLU30
I0619 14:48:21.521759 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.521764 17263 net.cpp:524] Memory required for data: 1377305088
I0619 14:48:21.521769 17263 layer_factory.hpp:77] Creating layer Convolution31
I0619 14:48:21.521782 17263 net.cpp:459] Creating Layer Convolution31
I0619 14:48:21.521788 17263 net.cpp:886] Convolution31 <- Convolution30
I0619 14:48:21.521797 17263 net.cpp:860] Convolution31 -> Convolution31
I0619 14:48:21.522250 17263 net.cpp:509] Setting up Convolution31
I0619 14:48:21.522264 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.522269 17263 net.cpp:524] Memory required for data: 1385693696
I0619 14:48:21.522281 17263 layer_factory.hpp:77] Creating layer BatchNorm31
I0619 14:48:21.522294 17263 net.cpp:459] Creating Layer BatchNorm31
I0619 14:48:21.522300 17263 net.cpp:886] BatchNorm31 <- Convolution31
I0619 14:48:21.522306 17263 net.cpp:847] BatchNorm31 -> Convolution31 (in-place)
I0619 14:48:21.522585 17263 net.cpp:509] Setting up BatchNorm31
I0619 14:48:21.522596 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.522603 17263 net.cpp:524] Memory required for data: 1394082304
I0619 14:48:21.522616 17263 layer_factory.hpp:77] Creating layer Scale31
I0619 14:48:21.522625 17263 net.cpp:459] Creating Layer Scale31
I0619 14:48:21.522631 17263 net.cpp:886] Scale31 <- Convolution31
I0619 14:48:21.522641 17263 net.cpp:847] Scale31 -> Convolution31 (in-place)
I0619 14:48:21.522687 17263 layer_factory.hpp:77] Creating layer Scale31
I0619 14:48:21.522840 17263 net.cpp:509] Setting up Scale31
I0619 14:48:21.522850 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.522855 17263 net.cpp:524] Memory required for data: 1402470912
I0619 14:48:21.522869 17263 layer_factory.hpp:77] Creating layer Eltwise15
I0619 14:48:21.522878 17263 net.cpp:459] Creating Layer Eltwise15
I0619 14:48:21.522884 17263 net.cpp:886] Eltwise15 <- Eltwise14_ReLU29_0_split_1
I0619 14:48:21.522891 17263 net.cpp:886] Eltwise15 <- Convolution31
I0619 14:48:21.522899 17263 net.cpp:860] Eltwise15 -> Eltwise15
I0619 14:48:21.522934 17263 net.cpp:509] Setting up Eltwise15
I0619 14:48:21.522943 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.522948 17263 net.cpp:524] Memory required for data: 1410859520
I0619 14:48:21.522956 17263 layer_factory.hpp:77] Creating layer ReLU31
I0619 14:48:21.522982 17263 net.cpp:459] Creating Layer ReLU31
I0619 14:48:21.522989 17263 net.cpp:886] ReLU31 <- Eltwise15
I0619 14:48:21.522996 17263 net.cpp:847] ReLU31 -> Eltwise15 (in-place)
I0619 14:48:21.523005 17263 net.cpp:509] Setting up ReLU31
I0619 14:48:21.523013 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.523018 17263 net.cpp:524] Memory required for data: 1419248128
I0619 14:48:21.523025 17263 layer_factory.hpp:77] Creating layer Eltwise15_ReLU31_0_split
I0619 14:48:21.523031 17263 net.cpp:459] Creating Layer Eltwise15_ReLU31_0_split
I0619 14:48:21.523036 17263 net.cpp:886] Eltwise15_ReLU31_0_split <- Eltwise15
I0619 14:48:21.523044 17263 net.cpp:860] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_0
I0619 14:48:21.523056 17263 net.cpp:860] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_1
I0619 14:48:21.523105 17263 net.cpp:509] Setting up Eltwise15_ReLU31_0_split
I0619 14:48:21.523114 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.523121 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.523126 17263 net.cpp:524] Memory required for data: 1436025344
I0619 14:48:21.523131 17263 layer_factory.hpp:77] Creating layer Convolution32
I0619 14:48:21.523149 17263 net.cpp:459] Creating Layer Convolution32
I0619 14:48:21.523154 17263 net.cpp:886] Convolution32 <- Eltwise15_ReLU31_0_split_0
I0619 14:48:21.523164 17263 net.cpp:860] Convolution32 -> Convolution32
I0619 14:48:21.523597 17263 net.cpp:509] Setting up Convolution32
I0619 14:48:21.523608 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.523613 17263 net.cpp:524] Memory required for data: 1444413952
I0619 14:48:21.523625 17263 layer_factory.hpp:77] Creating layer BatchNorm32
I0619 14:48:21.523638 17263 net.cpp:459] Creating Layer BatchNorm32
I0619 14:48:21.523643 17263 net.cpp:886] BatchNorm32 <- Convolution32
I0619 14:48:21.523653 17263 net.cpp:847] BatchNorm32 -> Convolution32 (in-place)
I0619 14:48:21.523917 17263 net.cpp:509] Setting up BatchNorm32
I0619 14:48:21.523926 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.523931 17263 net.cpp:524] Memory required for data: 1452802560
I0619 14:48:21.523946 17263 layer_factory.hpp:77] Creating layer Scale32
I0619 14:48:21.523958 17263 net.cpp:459] Creating Layer Scale32
I0619 14:48:21.523964 17263 net.cpp:886] Scale32 <- Convolution32
I0619 14:48:21.523972 17263 net.cpp:847] Scale32 -> Convolution32 (in-place)
I0619 14:48:21.524019 17263 layer_factory.hpp:77] Creating layer Scale32
I0619 14:48:21.524173 17263 net.cpp:509] Setting up Scale32
I0619 14:48:21.524183 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.524188 17263 net.cpp:524] Memory required for data: 1461191168
I0619 14:48:21.524200 17263 layer_factory.hpp:77] Creating layer ReLU32
I0619 14:48:21.524209 17263 net.cpp:459] Creating Layer ReLU32
I0619 14:48:21.524214 17263 net.cpp:886] ReLU32 <- Convolution32
I0619 14:48:21.524224 17263 net.cpp:847] ReLU32 -> Convolution32 (in-place)
I0619 14:48:21.524233 17263 net.cpp:509] Setting up ReLU32
I0619 14:48:21.524240 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.524245 17263 net.cpp:524] Memory required for data: 1469579776
I0619 14:48:21.524250 17263 layer_factory.hpp:77] Creating layer Convolution33
I0619 14:48:21.524265 17263 net.cpp:459] Creating Layer Convolution33
I0619 14:48:21.524269 17263 net.cpp:886] Convolution33 <- Convolution32
I0619 14:48:21.524278 17263 net.cpp:860] Convolution33 -> Convolution33
I0619 14:48:21.524706 17263 net.cpp:509] Setting up Convolution33
I0619 14:48:21.524718 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.524722 17263 net.cpp:524] Memory required for data: 1477968384
I0619 14:48:21.524734 17263 layer_factory.hpp:77] Creating layer BatchNorm33
I0619 14:48:21.524745 17263 net.cpp:459] Creating Layer BatchNorm33
I0619 14:48:21.524751 17263 net.cpp:886] BatchNorm33 <- Convolution33
I0619 14:48:21.524758 17263 net.cpp:847] BatchNorm33 -> Convolution33 (in-place)
I0619 14:48:21.525046 17263 net.cpp:509] Setting up BatchNorm33
I0619 14:48:21.525058 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.525063 17263 net.cpp:524] Memory required for data: 1486356992
I0619 14:48:21.525080 17263 layer_factory.hpp:77] Creating layer Scale33
I0619 14:48:21.525089 17263 net.cpp:459] Creating Layer Scale33
I0619 14:48:21.525094 17263 net.cpp:886] Scale33 <- Convolution33
I0619 14:48:21.525102 17263 net.cpp:847] Scale33 -> Convolution33 (in-place)
I0619 14:48:21.525151 17263 layer_factory.hpp:77] Creating layer Scale33
I0619 14:48:21.525307 17263 net.cpp:509] Setting up Scale33
I0619 14:48:21.525317 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.525323 17263 net.cpp:524] Memory required for data: 1494745600
I0619 14:48:21.525334 17263 layer_factory.hpp:77] Creating layer Eltwise16
I0619 14:48:21.525346 17263 net.cpp:459] Creating Layer Eltwise16
I0619 14:48:21.525352 17263 net.cpp:886] Eltwise16 <- Eltwise15_ReLU31_0_split_1
I0619 14:48:21.525359 17263 net.cpp:886] Eltwise16 <- Convolution33
I0619 14:48:21.525367 17263 net.cpp:860] Eltwise16 -> Eltwise16
I0619 14:48:21.525400 17263 net.cpp:509] Setting up Eltwise16
I0619 14:48:21.525409 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.525414 17263 net.cpp:524] Memory required for data: 1503134208
I0619 14:48:21.525419 17263 layer_factory.hpp:77] Creating layer ReLU33
I0619 14:48:21.525427 17263 net.cpp:459] Creating Layer ReLU33
I0619 14:48:21.525432 17263 net.cpp:886] ReLU33 <- Eltwise16
I0619 14:48:21.525442 17263 net.cpp:847] ReLU33 -> Eltwise16 (in-place)
I0619 14:48:21.525451 17263 net.cpp:509] Setting up ReLU33
I0619 14:48:21.525459 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.525465 17263 net.cpp:524] Memory required for data: 1511522816
I0619 14:48:21.525470 17263 layer_factory.hpp:77] Creating layer Eltwise16_ReLU33_0_split
I0619 14:48:21.525476 17263 net.cpp:459] Creating Layer Eltwise16_ReLU33_0_split
I0619 14:48:21.525481 17263 net.cpp:886] Eltwise16_ReLU33_0_split <- Eltwise16
I0619 14:48:21.525488 17263 net.cpp:860] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_0
I0619 14:48:21.525498 17263 net.cpp:860] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_1
I0619 14:48:21.525547 17263 net.cpp:509] Setting up Eltwise16_ReLU33_0_split
I0619 14:48:21.525555 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.525563 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.525568 17263 net.cpp:524] Memory required for data: 1528300032
I0619 14:48:21.525573 17263 layer_factory.hpp:77] Creating layer Convolution34
I0619 14:48:21.525584 17263 net.cpp:459] Creating Layer Convolution34
I0619 14:48:21.525589 17263 net.cpp:886] Convolution34 <- Eltwise16_ReLU33_0_split_0
I0619 14:48:21.525601 17263 net.cpp:860] Convolution34 -> Convolution34
I0619 14:48:21.526027 17263 net.cpp:509] Setting up Convolution34
I0619 14:48:21.526039 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.526044 17263 net.cpp:524] Memory required for data: 1536688640
I0619 14:48:21.526057 17263 layer_factory.hpp:77] Creating layer BatchNorm34
I0619 14:48:21.526064 17263 net.cpp:459] Creating Layer BatchNorm34
I0619 14:48:21.526070 17263 net.cpp:886] BatchNorm34 <- Convolution34
I0619 14:48:21.526080 17263 net.cpp:847] BatchNorm34 -> Convolution34 (in-place)
I0619 14:48:21.526361 17263 net.cpp:509] Setting up BatchNorm34
I0619 14:48:21.526373 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.526378 17263 net.cpp:524] Memory required for data: 1545077248
I0619 14:48:21.526394 17263 layer_factory.hpp:77] Creating layer Scale34
I0619 14:48:21.526403 17263 net.cpp:459] Creating Layer Scale34
I0619 14:48:21.526409 17263 net.cpp:886] Scale34 <- Convolution34
I0619 14:48:21.526417 17263 net.cpp:847] Scale34 -> Convolution34 (in-place)
I0619 14:48:21.526466 17263 layer_factory.hpp:77] Creating layer Scale34
I0619 14:48:21.526625 17263 net.cpp:509] Setting up Scale34
I0619 14:48:21.526635 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.526659 17263 net.cpp:524] Memory required for data: 1553465856
I0619 14:48:21.526674 17263 layer_factory.hpp:77] Creating layer ReLU34
I0619 14:48:21.526682 17263 net.cpp:459] Creating Layer ReLU34
I0619 14:48:21.526689 17263 net.cpp:886] ReLU34 <- Convolution34
I0619 14:48:21.526700 17263 net.cpp:847] ReLU34 -> Convolution34 (in-place)
I0619 14:48:21.526710 17263 net.cpp:509] Setting up ReLU34
I0619 14:48:21.526716 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.526721 17263 net.cpp:524] Memory required for data: 1561854464
I0619 14:48:21.526726 17263 layer_factory.hpp:77] Creating layer Convolution35
I0619 14:48:21.526738 17263 net.cpp:459] Creating Layer Convolution35
I0619 14:48:21.526743 17263 net.cpp:886] Convolution35 <- Convolution34
I0619 14:48:21.526754 17263 net.cpp:860] Convolution35 -> Convolution35
I0619 14:48:21.527204 17263 net.cpp:509] Setting up Convolution35
I0619 14:48:21.527216 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.527221 17263 net.cpp:524] Memory required for data: 1570243072
I0619 14:48:21.527233 17263 layer_factory.hpp:77] Creating layer BatchNorm35
I0619 14:48:21.527242 17263 net.cpp:459] Creating Layer BatchNorm35
I0619 14:48:21.527247 17263 net.cpp:886] BatchNorm35 <- Convolution35
I0619 14:48:21.527257 17263 net.cpp:847] BatchNorm35 -> Convolution35 (in-place)
I0619 14:48:21.527520 17263 net.cpp:509] Setting up BatchNorm35
I0619 14:48:21.527530 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.527536 17263 net.cpp:524] Memory required for data: 1578631680
I0619 14:48:21.527550 17263 layer_factory.hpp:77] Creating layer Scale35
I0619 14:48:21.527559 17263 net.cpp:459] Creating Layer Scale35
I0619 14:48:21.527565 17263 net.cpp:886] Scale35 <- Convolution35
I0619 14:48:21.527575 17263 net.cpp:847] Scale35 -> Convolution35 (in-place)
I0619 14:48:21.527621 17263 layer_factory.hpp:77] Creating layer Scale35
I0619 14:48:21.527776 17263 net.cpp:509] Setting up Scale35
I0619 14:48:21.527786 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.527791 17263 net.cpp:524] Memory required for data: 1587020288
I0619 14:48:21.527803 17263 layer_factory.hpp:77] Creating layer Eltwise17
I0619 14:48:21.527814 17263 net.cpp:459] Creating Layer Eltwise17
I0619 14:48:21.527820 17263 net.cpp:886] Eltwise17 <- Eltwise16_ReLU33_0_split_1
I0619 14:48:21.527827 17263 net.cpp:886] Eltwise17 <- Convolution35
I0619 14:48:21.527835 17263 net.cpp:860] Eltwise17 -> Eltwise17
I0619 14:48:21.527869 17263 net.cpp:509] Setting up Eltwise17
I0619 14:48:21.527878 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.527884 17263 net.cpp:524] Memory required for data: 1595408896
I0619 14:48:21.527889 17263 layer_factory.hpp:77] Creating layer ReLU35
I0619 14:48:21.527895 17263 net.cpp:459] Creating Layer ReLU35
I0619 14:48:21.527901 17263 net.cpp:886] ReLU35 <- Eltwise17
I0619 14:48:21.527910 17263 net.cpp:847] ReLU35 -> Eltwise17 (in-place)
I0619 14:48:21.527920 17263 net.cpp:509] Setting up ReLU35
I0619 14:48:21.527927 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.527932 17263 net.cpp:524] Memory required for data: 1603797504
I0619 14:48:21.527937 17263 layer_factory.hpp:77] Creating layer Eltwise17_ReLU35_0_split
I0619 14:48:21.527945 17263 net.cpp:459] Creating Layer Eltwise17_ReLU35_0_split
I0619 14:48:21.527951 17263 net.cpp:886] Eltwise17_ReLU35_0_split <- Eltwise17
I0619 14:48:21.527957 17263 net.cpp:860] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_0
I0619 14:48:21.527966 17263 net.cpp:860] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_1
I0619 14:48:21.528023 17263 net.cpp:509] Setting up Eltwise17_ReLU35_0_split
I0619 14:48:21.528031 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.528038 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.528043 17263 net.cpp:524] Memory required for data: 1620574720
I0619 14:48:21.528051 17263 layer_factory.hpp:77] Creating layer Convolution36
I0619 14:48:21.528069 17263 net.cpp:459] Creating Layer Convolution36
I0619 14:48:21.528090 17263 net.cpp:886] Convolution36 <- Eltwise17_ReLU35_0_split_0
I0619 14:48:21.528100 17263 net.cpp:860] Convolution36 -> Convolution36
I0619 14:48:21.528544 17263 net.cpp:509] Setting up Convolution36
I0619 14:48:21.528556 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.528561 17263 net.cpp:524] Memory required for data: 1628963328
I0619 14:48:21.528574 17263 layer_factory.hpp:77] Creating layer BatchNorm36
I0619 14:48:21.528587 17263 net.cpp:459] Creating Layer BatchNorm36
I0619 14:48:21.528594 17263 net.cpp:886] BatchNorm36 <- Convolution36
I0619 14:48:21.528604 17263 net.cpp:847] BatchNorm36 -> Convolution36 (in-place)
I0619 14:48:21.528869 17263 net.cpp:509] Setting up BatchNorm36
I0619 14:48:21.528879 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.528884 17263 net.cpp:524] Memory required for data: 1637351936
I0619 14:48:21.528898 17263 layer_factory.hpp:77] Creating layer Scale36
I0619 14:48:21.528910 17263 net.cpp:459] Creating Layer Scale36
I0619 14:48:21.528916 17263 net.cpp:886] Scale36 <- Convolution36
I0619 14:48:21.528923 17263 net.cpp:847] Scale36 -> Convolution36 (in-place)
I0619 14:48:21.528972 17263 layer_factory.hpp:77] Creating layer Scale36
I0619 14:48:21.529132 17263 net.cpp:509] Setting up Scale36
I0619 14:48:21.529142 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.529147 17263 net.cpp:524] Memory required for data: 1645740544
I0619 14:48:21.529160 17263 layer_factory.hpp:77] Creating layer ReLU36
I0619 14:48:21.529167 17263 net.cpp:459] Creating Layer ReLU36
I0619 14:48:21.529172 17263 net.cpp:886] ReLU36 <- Convolution36
I0619 14:48:21.529182 17263 net.cpp:847] ReLU36 -> Convolution36 (in-place)
I0619 14:48:21.529191 17263 net.cpp:509] Setting up ReLU36
I0619 14:48:21.529198 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.529203 17263 net.cpp:524] Memory required for data: 1654129152
I0619 14:48:21.529208 17263 layer_factory.hpp:77] Creating layer Convolution37
I0619 14:48:21.529222 17263 net.cpp:459] Creating Layer Convolution37
I0619 14:48:21.529228 17263 net.cpp:886] Convolution37 <- Convolution36
I0619 14:48:21.529237 17263 net.cpp:860] Convolution37 -> Convolution37
I0619 14:48:21.529670 17263 net.cpp:509] Setting up Convolution37
I0619 14:48:21.529680 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.529685 17263 net.cpp:524] Memory required for data: 1662517760
I0619 14:48:21.529697 17263 layer_factory.hpp:77] Creating layer BatchNorm37
I0619 14:48:21.529708 17263 net.cpp:459] Creating Layer BatchNorm37
I0619 14:48:21.529714 17263 net.cpp:886] BatchNorm37 <- Convolution37
I0619 14:48:21.529724 17263 net.cpp:847] BatchNorm37 -> Convolution37 (in-place)
I0619 14:48:21.529999 17263 net.cpp:509] Setting up BatchNorm37
I0619 14:48:21.530009 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.530014 17263 net.cpp:524] Memory required for data: 1670906368
I0619 14:48:21.530064 17263 layer_factory.hpp:77] Creating layer Scale37
I0619 14:48:21.530076 17263 net.cpp:459] Creating Layer Scale37
I0619 14:48:21.530083 17263 net.cpp:886] Scale37 <- Convolution37
I0619 14:48:21.530092 17263 net.cpp:847] Scale37 -> Convolution37 (in-place)
I0619 14:48:21.530140 17263 layer_factory.hpp:77] Creating layer Scale37
I0619 14:48:21.530298 17263 net.cpp:509] Setting up Scale37
I0619 14:48:21.530309 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.530314 17263 net.cpp:524] Memory required for data: 1679294976
I0619 14:48:21.530326 17263 layer_factory.hpp:77] Creating layer Eltwise18
I0619 14:48:21.530338 17263 net.cpp:459] Creating Layer Eltwise18
I0619 14:48:21.530344 17263 net.cpp:886] Eltwise18 <- Eltwise17_ReLU35_0_split_1
I0619 14:48:21.530350 17263 net.cpp:886] Eltwise18 <- Convolution37
I0619 14:48:21.530369 17263 net.cpp:860] Eltwise18 -> Eltwise18
I0619 14:48:21.530406 17263 net.cpp:509] Setting up Eltwise18
I0619 14:48:21.530416 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.530424 17263 net.cpp:524] Memory required for data: 1687683584
I0619 14:48:21.530448 17263 layer_factory.hpp:77] Creating layer ReLU37
I0619 14:48:21.530458 17263 net.cpp:459] Creating Layer ReLU37
I0619 14:48:21.530464 17263 net.cpp:886] ReLU37 <- Eltwise18
I0619 14:48:21.530474 17263 net.cpp:847] ReLU37 -> Eltwise18 (in-place)
I0619 14:48:21.530484 17263 net.cpp:509] Setting up ReLU37
I0619 14:48:21.530493 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.530498 17263 net.cpp:524] Memory required for data: 1696072192
I0619 14:48:21.530503 17263 layer_factory.hpp:77] Creating layer Eltwise18_ReLU37_0_split
I0619 14:48:21.530509 17263 net.cpp:459] Creating Layer Eltwise18_ReLU37_0_split
I0619 14:48:21.530514 17263 net.cpp:886] Eltwise18_ReLU37_0_split <- Eltwise18
I0619 14:48:21.530522 17263 net.cpp:860] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_0
I0619 14:48:21.530531 17263 net.cpp:860] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_1
I0619 14:48:21.530587 17263 net.cpp:509] Setting up Eltwise18_ReLU37_0_split
I0619 14:48:21.530597 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.530604 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.530609 17263 net.cpp:524] Memory required for data: 1712849408
I0619 14:48:21.530614 17263 layer_factory.hpp:77] Creating layer Pooling1
I0619 14:48:21.530622 17263 net.cpp:459] Creating Layer Pooling1
I0619 14:48:21.530628 17263 net.cpp:886] Pooling1 <- Eltwise18_ReLU37_0_split_0
I0619 14:48:21.530639 17263 net.cpp:860] Pooling1 -> Pooling1
I0619 14:48:21.530695 17263 net.cpp:509] Setting up Pooling1
I0619 14:48:21.530704 17263 net.cpp:516] Top shape: 128 16 16 16 (524288)
I0619 14:48:21.530709 17263 net.cpp:524] Memory required for data: 1714946560
I0619 14:48:21.530714 17263 layer_factory.hpp:77] Creating layer Input1
I0619 14:48:21.530722 17263 net.cpp:459] Creating Layer Input1
I0619 14:48:21.530732 17263 net.cpp:860] Input1 -> Input1
I0619 14:48:21.530768 17263 net.cpp:509] Setting up Input1
I0619 14:48:21.530779 17263 net.cpp:516] Top shape: 128 16 16 16 (524288)
I0619 14:48:21.530784 17263 net.cpp:524] Memory required for data: 1717043712
I0619 14:48:21.530789 17263 layer_factory.hpp:77] Creating layer Concat1
I0619 14:48:21.530797 17263 net.cpp:459] Creating Layer Concat1
I0619 14:48:21.530803 17263 net.cpp:886] Concat1 <- Pooling1
I0619 14:48:21.530809 17263 net.cpp:886] Concat1 <- Input1
I0619 14:48:21.530817 17263 net.cpp:860] Concat1 -> Concat1
I0619 14:48:21.530851 17263 net.cpp:509] Setting up Concat1
I0619 14:48:21.530860 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.530865 17263 net.cpp:524] Memory required for data: 1721238016
I0619 14:48:21.530870 17263 layer_factory.hpp:77] Creating layer Convolution38
I0619 14:48:21.530884 17263 net.cpp:459] Creating Layer Convolution38
I0619 14:48:21.530890 17263 net.cpp:886] Convolution38 <- Eltwise18_ReLU37_0_split_1
I0619 14:48:21.530901 17263 net.cpp:860] Convolution38 -> Convolution38
I0619 14:48:21.532157 17263 net.cpp:509] Setting up Convolution38
I0619 14:48:21.532176 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.532182 17263 net.cpp:524] Memory required for data: 1725432320
I0619 14:48:21.532196 17263 layer_factory.hpp:77] Creating layer BatchNorm38
I0619 14:48:21.532209 17263 net.cpp:459] Creating Layer BatchNorm38
I0619 14:48:21.532215 17263 net.cpp:886] BatchNorm38 <- Convolution38
I0619 14:48:21.532225 17263 net.cpp:847] BatchNorm38 -> Convolution38 (in-place)
I0619 14:48:21.532482 17263 net.cpp:509] Setting up BatchNorm38
I0619 14:48:21.532491 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.532496 17263 net.cpp:524] Memory required for data: 1729626624
I0619 14:48:21.532511 17263 layer_factory.hpp:77] Creating layer Scale38
I0619 14:48:21.532522 17263 net.cpp:459] Creating Layer Scale38
I0619 14:48:21.532528 17263 net.cpp:886] Scale38 <- Convolution38
I0619 14:48:21.532536 17263 net.cpp:847] Scale38 -> Convolution38 (in-place)
I0619 14:48:21.532579 17263 layer_factory.hpp:77] Creating layer Scale38
I0619 14:48:21.532740 17263 net.cpp:509] Setting up Scale38
I0619 14:48:21.532766 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.532773 17263 net.cpp:524] Memory required for data: 1733820928
I0619 14:48:21.532785 17263 layer_factory.hpp:77] Creating layer ReLU38
I0619 14:48:21.532794 17263 net.cpp:459] Creating Layer ReLU38
I0619 14:48:21.532799 17263 net.cpp:886] ReLU38 <- Convolution38
I0619 14:48:21.532810 17263 net.cpp:847] ReLU38 -> Convolution38 (in-place)
I0619 14:48:21.532819 17263 net.cpp:509] Setting up ReLU38
I0619 14:48:21.532826 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.532831 17263 net.cpp:524] Memory required for data: 1738015232
I0619 14:48:21.532836 17263 layer_factory.hpp:77] Creating layer Convolution39
I0619 14:48:21.532850 17263 net.cpp:459] Creating Layer Convolution39
I0619 14:48:21.532855 17263 net.cpp:886] Convolution39 <- Convolution38
I0619 14:48:21.532863 17263 net.cpp:860] Convolution39 -> Convolution39
I0619 14:48:21.533613 17263 net.cpp:509] Setting up Convolution39
I0619 14:48:21.533627 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.533632 17263 net.cpp:524] Memory required for data: 1742209536
I0619 14:48:21.533643 17263 layer_factory.hpp:77] Creating layer BatchNorm39
I0619 14:48:21.533654 17263 net.cpp:459] Creating Layer BatchNorm39
I0619 14:48:21.533660 17263 net.cpp:886] BatchNorm39 <- Convolution39
I0619 14:48:21.533668 17263 net.cpp:847] BatchNorm39 -> Convolution39 (in-place)
I0619 14:48:21.533921 17263 net.cpp:509] Setting up BatchNorm39
I0619 14:48:21.533929 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.533934 17263 net.cpp:524] Memory required for data: 1746403840
I0619 14:48:21.533948 17263 layer_factory.hpp:77] Creating layer Scale39
I0619 14:48:21.533962 17263 net.cpp:459] Creating Layer Scale39
I0619 14:48:21.533967 17263 net.cpp:886] Scale39 <- Convolution39
I0619 14:48:21.533974 17263 net.cpp:847] Scale39 -> Convolution39 (in-place)
I0619 14:48:21.534019 17263 layer_factory.hpp:77] Creating layer Scale39
I0619 14:48:21.534171 17263 net.cpp:509] Setting up Scale39
I0619 14:48:21.534181 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.534186 17263 net.cpp:524] Memory required for data: 1750598144
I0619 14:48:21.534198 17263 layer_factory.hpp:77] Creating layer Eltwise19
I0619 14:48:21.534209 17263 net.cpp:459] Creating Layer Eltwise19
I0619 14:48:21.534215 17263 net.cpp:886] Eltwise19 <- Concat1
I0619 14:48:21.534224 17263 net.cpp:886] Eltwise19 <- Convolution39
I0619 14:48:21.534231 17263 net.cpp:860] Eltwise19 -> Eltwise19
I0619 14:48:21.534258 17263 net.cpp:509] Setting up Eltwise19
I0619 14:48:21.534266 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.534271 17263 net.cpp:524] Memory required for data: 1754792448
I0619 14:48:21.534276 17263 layer_factory.hpp:77] Creating layer ReLU39
I0619 14:48:21.534283 17263 net.cpp:459] Creating Layer ReLU39
I0619 14:48:21.534288 17263 net.cpp:886] ReLU39 <- Eltwise19
I0619 14:48:21.534296 17263 net.cpp:847] ReLU39 -> Eltwise19 (in-place)
I0619 14:48:21.534303 17263 net.cpp:509] Setting up ReLU39
I0619 14:48:21.534310 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.534314 17263 net.cpp:524] Memory required for data: 1758986752
I0619 14:48:21.534319 17263 layer_factory.hpp:77] Creating layer Eltwise19_ReLU39_0_split
I0619 14:48:21.534329 17263 net.cpp:459] Creating Layer Eltwise19_ReLU39_0_split
I0619 14:48:21.534334 17263 net.cpp:886] Eltwise19_ReLU39_0_split <- Eltwise19
I0619 14:48:21.534342 17263 net.cpp:860] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_0
I0619 14:48:21.534350 17263 net.cpp:860] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_1
I0619 14:48:21.534409 17263 net.cpp:509] Setting up Eltwise19_ReLU39_0_split
I0619 14:48:21.534418 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.534425 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.534430 17263 net.cpp:524] Memory required for data: 1767375360
I0619 14:48:21.534438 17263 layer_factory.hpp:77] Creating layer Convolution40
I0619 14:48:21.534466 17263 net.cpp:459] Creating Layer Convolution40
I0619 14:48:21.534471 17263 net.cpp:886] Convolution40 <- Eltwise19_ReLU39_0_split_0
I0619 14:48:21.534481 17263 net.cpp:860] Convolution40 -> Convolution40
I0619 14:48:21.535233 17263 net.cpp:509] Setting up Convolution40
I0619 14:48:21.535245 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.535250 17263 net.cpp:524] Memory required for data: 1771569664
I0619 14:48:21.535264 17263 layer_factory.hpp:77] Creating layer BatchNorm40
I0619 14:48:21.535274 17263 net.cpp:459] Creating Layer BatchNorm40
I0619 14:48:21.535279 17263 net.cpp:886] BatchNorm40 <- Convolution40
I0619 14:48:21.535290 17263 net.cpp:847] BatchNorm40 -> Convolution40 (in-place)
I0619 14:48:21.535543 17263 net.cpp:509] Setting up BatchNorm40
I0619 14:48:21.535553 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.535558 17263 net.cpp:524] Memory required for data: 1775763968
I0619 14:48:21.535572 17263 layer_factory.hpp:77] Creating layer Scale40
I0619 14:48:21.535579 17263 net.cpp:459] Creating Layer Scale40
I0619 14:48:21.535585 17263 net.cpp:886] Scale40 <- Convolution40
I0619 14:48:21.535593 17263 net.cpp:847] Scale40 -> Convolution40 (in-place)
I0619 14:48:21.535636 17263 layer_factory.hpp:77] Creating layer Scale40
I0619 14:48:21.535790 17263 net.cpp:509] Setting up Scale40
I0619 14:48:21.535801 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.535806 17263 net.cpp:524] Memory required for data: 1779958272
I0619 14:48:21.535817 17263 layer_factory.hpp:77] Creating layer ReLU40
I0619 14:48:21.535825 17263 net.cpp:459] Creating Layer ReLU40
I0619 14:48:21.535830 17263 net.cpp:886] ReLU40 <- Convolution40
I0619 14:48:21.535840 17263 net.cpp:847] ReLU40 -> Convolution40 (in-place)
I0619 14:48:21.535850 17263 net.cpp:509] Setting up ReLU40
I0619 14:48:21.535856 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.535861 17263 net.cpp:524] Memory required for data: 1784152576
I0619 14:48:21.535866 17263 layer_factory.hpp:77] Creating layer Convolution41
I0619 14:48:21.535876 17263 net.cpp:459] Creating Layer Convolution41
I0619 14:48:21.535881 17263 net.cpp:886] Convolution41 <- Convolution40
I0619 14:48:21.535892 17263 net.cpp:860] Convolution41 -> Convolution41
I0619 14:48:21.536633 17263 net.cpp:509] Setting up Convolution41
I0619 14:48:21.536644 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.536650 17263 net.cpp:524] Memory required for data: 1788346880
I0619 14:48:21.536661 17263 layer_factory.hpp:77] Creating layer BatchNorm41
I0619 14:48:21.536669 17263 net.cpp:459] Creating Layer BatchNorm41
I0619 14:48:21.536675 17263 net.cpp:886] BatchNorm41 <- Convolution41
I0619 14:48:21.536685 17263 net.cpp:847] BatchNorm41 -> Convolution41 (in-place)
I0619 14:48:21.536934 17263 net.cpp:509] Setting up BatchNorm41
I0619 14:48:21.536943 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.536948 17263 net.cpp:524] Memory required for data: 1792541184
I0619 14:48:21.536962 17263 layer_factory.hpp:77] Creating layer Scale41
I0619 14:48:21.536969 17263 net.cpp:459] Creating Layer Scale41
I0619 14:48:21.536974 17263 net.cpp:886] Scale41 <- Convolution41
I0619 14:48:21.536981 17263 net.cpp:847] Scale41 -> Convolution41 (in-place)
I0619 14:48:21.537026 17263 layer_factory.hpp:77] Creating layer Scale41
I0619 14:48:21.537173 17263 net.cpp:509] Setting up Scale41
I0619 14:48:21.537184 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.537189 17263 net.cpp:524] Memory required for data: 1796735488
I0619 14:48:21.537199 17263 layer_factory.hpp:77] Creating layer Eltwise20
I0619 14:48:21.537209 17263 net.cpp:459] Creating Layer Eltwise20
I0619 14:48:21.537215 17263 net.cpp:886] Eltwise20 <- Eltwise19_ReLU39_0_split_1
I0619 14:48:21.537222 17263 net.cpp:886] Eltwise20 <- Convolution41
I0619 14:48:21.537230 17263 net.cpp:860] Eltwise20 -> Eltwise20
I0619 14:48:21.537253 17263 net.cpp:509] Setting up Eltwise20
I0619 14:48:21.537266 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.537284 17263 net.cpp:524] Memory required for data: 1800929792
I0619 14:48:21.537291 17263 layer_factory.hpp:77] Creating layer ReLU41
I0619 14:48:21.537302 17263 net.cpp:459] Creating Layer ReLU41
I0619 14:48:21.537307 17263 net.cpp:886] ReLU41 <- Eltwise20
I0619 14:48:21.537314 17263 net.cpp:847] ReLU41 -> Eltwise20 (in-place)
I0619 14:48:21.537323 17263 net.cpp:509] Setting up ReLU41
I0619 14:48:21.537330 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.537335 17263 net.cpp:524] Memory required for data: 1805124096
I0619 14:48:21.537340 17263 layer_factory.hpp:77] Creating layer Eltwise20_ReLU41_0_split
I0619 14:48:21.537349 17263 net.cpp:459] Creating Layer Eltwise20_ReLU41_0_split
I0619 14:48:21.537354 17263 net.cpp:886] Eltwise20_ReLU41_0_split <- Eltwise20
I0619 14:48:21.537361 17263 net.cpp:860] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_0
I0619 14:48:21.537371 17263 net.cpp:860] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_1
I0619 14:48:21.537420 17263 net.cpp:509] Setting up Eltwise20_ReLU41_0_split
I0619 14:48:21.537430 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.537436 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.537441 17263 net.cpp:524] Memory required for data: 1813512704
I0619 14:48:21.537446 17263 layer_factory.hpp:77] Creating layer Convolution42
I0619 14:48:21.537458 17263 net.cpp:459] Creating Layer Convolution42
I0619 14:48:21.537464 17263 net.cpp:886] Convolution42 <- Eltwise20_ReLU41_0_split_0
I0619 14:48:21.537472 17263 net.cpp:860] Convolution42 -> Convolution42
I0619 14:48:21.538220 17263 net.cpp:509] Setting up Convolution42
I0619 14:48:21.538231 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.538236 17263 net.cpp:524] Memory required for data: 1817707008
I0619 14:48:21.538249 17263 layer_factory.hpp:77] Creating layer BatchNorm42
I0619 14:48:21.538262 17263 net.cpp:459] Creating Layer BatchNorm42
I0619 14:48:21.538267 17263 net.cpp:886] BatchNorm42 <- Convolution42
I0619 14:48:21.538278 17263 net.cpp:847] BatchNorm42 -> Convolution42 (in-place)
I0619 14:48:21.538537 17263 net.cpp:509] Setting up BatchNorm42
I0619 14:48:21.538547 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.538552 17263 net.cpp:524] Memory required for data: 1821901312
I0619 14:48:21.538568 17263 layer_factory.hpp:77] Creating layer Scale42
I0619 14:48:21.538575 17263 net.cpp:459] Creating Layer Scale42
I0619 14:48:21.538581 17263 net.cpp:886] Scale42 <- Convolution42
I0619 14:48:21.538591 17263 net.cpp:847] Scale42 -> Convolution42 (in-place)
I0619 14:48:21.538635 17263 layer_factory.hpp:77] Creating layer Scale42
I0619 14:48:21.538781 17263 net.cpp:509] Setting up Scale42
I0619 14:48:21.538791 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.538795 17263 net.cpp:524] Memory required for data: 1826095616
I0619 14:48:21.538807 17263 layer_factory.hpp:77] Creating layer ReLU42
I0619 14:48:21.538815 17263 net.cpp:459] Creating Layer ReLU42
I0619 14:48:21.538820 17263 net.cpp:886] ReLU42 <- Convolution42
I0619 14:48:21.538827 17263 net.cpp:847] ReLU42 -> Convolution42 (in-place)
I0619 14:48:21.538836 17263 net.cpp:509] Setting up ReLU42
I0619 14:48:21.538842 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.538847 17263 net.cpp:524] Memory required for data: 1830289920
I0619 14:48:21.538852 17263 layer_factory.hpp:77] Creating layer Convolution43
I0619 14:48:21.538866 17263 net.cpp:459] Creating Layer Convolution43
I0619 14:48:21.538872 17263 net.cpp:886] Convolution43 <- Convolution42
I0619 14:48:21.538882 17263 net.cpp:860] Convolution43 -> Convolution43
I0619 14:48:21.539616 17263 net.cpp:509] Setting up Convolution43
I0619 14:48:21.539626 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.539631 17263 net.cpp:524] Memory required for data: 1834484224
I0619 14:48:21.539644 17263 layer_factory.hpp:77] Creating layer BatchNorm43
I0619 14:48:21.539654 17263 net.cpp:459] Creating Layer BatchNorm43
I0619 14:48:21.539662 17263 net.cpp:886] BatchNorm43 <- Convolution43
I0619 14:48:21.539691 17263 net.cpp:847] BatchNorm43 -> Convolution43 (in-place)
I0619 14:48:21.539947 17263 net.cpp:509] Setting up BatchNorm43
I0619 14:48:21.539955 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.539960 17263 net.cpp:524] Memory required for data: 1838678528
I0619 14:48:21.539975 17263 layer_factory.hpp:77] Creating layer Scale43
I0619 14:48:21.539985 17263 net.cpp:459] Creating Layer Scale43
I0619 14:48:21.539991 17263 net.cpp:886] Scale43 <- Convolution43
I0619 14:48:21.540001 17263 net.cpp:847] Scale43 -> Convolution43 (in-place)
I0619 14:48:21.540045 17263 layer_factory.hpp:77] Creating layer Scale43
I0619 14:48:21.540197 17263 net.cpp:509] Setting up Scale43
I0619 14:48:21.540207 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.540212 17263 net.cpp:524] Memory required for data: 1842872832
I0619 14:48:21.540223 17263 layer_factory.hpp:77] Creating layer Eltwise21
I0619 14:48:21.540231 17263 net.cpp:459] Creating Layer Eltwise21
I0619 14:48:21.540237 17263 net.cpp:886] Eltwise21 <- Eltwise20_ReLU41_0_split_1
I0619 14:48:21.540244 17263 net.cpp:886] Eltwise21 <- Convolution43
I0619 14:48:21.540254 17263 net.cpp:860] Eltwise21 -> Eltwise21
I0619 14:48:21.540278 17263 net.cpp:509] Setting up Eltwise21
I0619 14:48:21.540287 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.540292 17263 net.cpp:524] Memory required for data: 1847067136
I0619 14:48:21.540295 17263 layer_factory.hpp:77] Creating layer ReLU43
I0619 14:48:21.540305 17263 net.cpp:459] Creating Layer ReLU43
I0619 14:48:21.540310 17263 net.cpp:886] ReLU43 <- Eltwise21
I0619 14:48:21.540318 17263 net.cpp:847] ReLU43 -> Eltwise21 (in-place)
I0619 14:48:21.540325 17263 net.cpp:509] Setting up ReLU43
I0619 14:48:21.540333 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.540336 17263 net.cpp:524] Memory required for data: 1851261440
I0619 14:48:21.540341 17263 layer_factory.hpp:77] Creating layer Eltwise21_ReLU43_0_split
I0619 14:48:21.540349 17263 net.cpp:459] Creating Layer Eltwise21_ReLU43_0_split
I0619 14:48:21.540354 17263 net.cpp:886] Eltwise21_ReLU43_0_split <- Eltwise21
I0619 14:48:21.540362 17263 net.cpp:860] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_0
I0619 14:48:21.540371 17263 net.cpp:860] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_1
I0619 14:48:21.540416 17263 net.cpp:509] Setting up Eltwise21_ReLU43_0_split
I0619 14:48:21.540424 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.540431 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.540436 17263 net.cpp:524] Memory required for data: 1859650048
I0619 14:48:21.540441 17263 layer_factory.hpp:77] Creating layer Convolution44
I0619 14:48:21.540454 17263 net.cpp:459] Creating Layer Convolution44
I0619 14:48:21.540459 17263 net.cpp:886] Convolution44 <- Eltwise21_ReLU43_0_split_0
I0619 14:48:21.540468 17263 net.cpp:860] Convolution44 -> Convolution44
I0619 14:48:21.541221 17263 net.cpp:509] Setting up Convolution44
I0619 14:48:21.541234 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.541239 17263 net.cpp:524] Memory required for data: 1863844352
I0619 14:48:21.541249 17263 layer_factory.hpp:77] Creating layer BatchNorm44
I0619 14:48:21.541260 17263 net.cpp:459] Creating Layer BatchNorm44
I0619 14:48:21.541266 17263 net.cpp:886] BatchNorm44 <- Convolution44
I0619 14:48:21.541273 17263 net.cpp:847] BatchNorm44 -> Convolution44 (in-place)
I0619 14:48:21.541527 17263 net.cpp:509] Setting up BatchNorm44
I0619 14:48:21.541537 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.541541 17263 net.cpp:524] Memory required for data: 1868038656
I0619 14:48:21.541558 17263 layer_factory.hpp:77] Creating layer Scale44
I0619 14:48:21.541565 17263 net.cpp:459] Creating Layer Scale44
I0619 14:48:21.541571 17263 net.cpp:886] Scale44 <- Convolution44
I0619 14:48:21.541579 17263 net.cpp:847] Scale44 -> Convolution44 (in-place)
I0619 14:48:21.541622 17263 layer_factory.hpp:77] Creating layer Scale44
I0619 14:48:21.541800 17263 net.cpp:509] Setting up Scale44
I0619 14:48:21.541812 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.541817 17263 net.cpp:524] Memory required for data: 1872232960
I0619 14:48:21.541829 17263 layer_factory.hpp:77] Creating layer ReLU44
I0619 14:48:21.541839 17263 net.cpp:459] Creating Layer ReLU44
I0619 14:48:21.541846 17263 net.cpp:886] ReLU44 <- Convolution44
I0619 14:48:21.541852 17263 net.cpp:847] ReLU44 -> Convolution44 (in-place)
I0619 14:48:21.541862 17263 net.cpp:509] Setting up ReLU44
I0619 14:48:21.541868 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.541873 17263 net.cpp:524] Memory required for data: 1876427264
I0619 14:48:21.541877 17263 layer_factory.hpp:77] Creating layer Convolution45
I0619 14:48:21.541894 17263 net.cpp:459] Creating Layer Convolution45
I0619 14:48:21.541899 17263 net.cpp:886] Convolution45 <- Convolution44
I0619 14:48:21.541910 17263 net.cpp:860] Convolution45 -> Convolution45
I0619 14:48:21.542670 17263 net.cpp:509] Setting up Convolution45
I0619 14:48:21.542686 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.542691 17263 net.cpp:524] Memory required for data: 1880621568
I0619 14:48:21.542711 17263 layer_factory.hpp:77] Creating layer BatchNorm45
I0619 14:48:21.542718 17263 net.cpp:459] Creating Layer BatchNorm45
I0619 14:48:21.542723 17263 net.cpp:886] BatchNorm45 <- Convolution45
I0619 14:48:21.542733 17263 net.cpp:847] BatchNorm45 -> Convolution45 (in-place)
I0619 14:48:21.542973 17263 net.cpp:509] Setting up BatchNorm45
I0619 14:48:21.542982 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.542987 17263 net.cpp:524] Memory required for data: 1884815872
I0619 14:48:21.543000 17263 layer_factory.hpp:77] Creating layer Scale45
I0619 14:48:21.543009 17263 net.cpp:459] Creating Layer Scale45
I0619 14:48:21.543014 17263 net.cpp:886] Scale45 <- Convolution45
I0619 14:48:21.543020 17263 net.cpp:847] Scale45 -> Convolution45 (in-place)
I0619 14:48:21.543062 17263 layer_factory.hpp:77] Creating layer Scale45
I0619 14:48:21.543202 17263 net.cpp:509] Setting up Scale45
I0619 14:48:21.543211 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.543216 17263 net.cpp:524] Memory required for data: 1889010176
I0619 14:48:21.543226 17263 layer_factory.hpp:77] Creating layer Eltwise22
I0619 14:48:21.543234 17263 net.cpp:459] Creating Layer Eltwise22
I0619 14:48:21.543241 17263 net.cpp:886] Eltwise22 <- Eltwise21_ReLU43_0_split_1
I0619 14:48:21.543246 17263 net.cpp:886] Eltwise22 <- Convolution45
I0619 14:48:21.543256 17263 net.cpp:860] Eltwise22 -> Eltwise22
I0619 14:48:21.543278 17263 net.cpp:509] Setting up Eltwise22
I0619 14:48:21.543287 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.543290 17263 net.cpp:524] Memory required for data: 1893204480
I0619 14:48:21.543295 17263 layer_factory.hpp:77] Creating layer ReLU45
I0619 14:48:21.543301 17263 net.cpp:459] Creating Layer ReLU45
I0619 14:48:21.543306 17263 net.cpp:886] ReLU45 <- Eltwise22
I0619 14:48:21.543318 17263 net.cpp:847] ReLU45 -> Eltwise22 (in-place)
I0619 14:48:21.543326 17263 net.cpp:509] Setting up ReLU45
I0619 14:48:21.543332 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.543337 17263 net.cpp:524] Memory required for data: 1897398784
I0619 14:48:21.543341 17263 layer_factory.hpp:77] Creating layer Eltwise22_ReLU45_0_split
I0619 14:48:21.543349 17263 net.cpp:459] Creating Layer Eltwise22_ReLU45_0_split
I0619 14:48:21.543352 17263 net.cpp:886] Eltwise22_ReLU45_0_split <- Eltwise22
I0619 14:48:21.543359 17263 net.cpp:860] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_0
I0619 14:48:21.543368 17263 net.cpp:860] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_1
I0619 14:48:21.543412 17263 net.cpp:509] Setting up Eltwise22_ReLU45_0_split
I0619 14:48:21.543421 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.543427 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.543431 17263 net.cpp:524] Memory required for data: 1905787392
I0619 14:48:21.543454 17263 layer_factory.hpp:77] Creating layer Convolution46
I0619 14:48:21.543467 17263 net.cpp:459] Creating Layer Convolution46
I0619 14:48:21.543472 17263 net.cpp:886] Convolution46 <- Eltwise22_ReLU45_0_split_0
I0619 14:48:21.543483 17263 net.cpp:860] Convolution46 -> Convolution46
I0619 14:48:21.544193 17263 net.cpp:509] Setting up Convolution46
I0619 14:48:21.544203 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.544208 17263 net.cpp:524] Memory required for data: 1909981696
I0619 14:48:21.544219 17263 layer_factory.hpp:77] Creating layer BatchNorm46
I0619 14:48:21.544229 17263 net.cpp:459] Creating Layer BatchNorm46
I0619 14:48:21.544234 17263 net.cpp:886] BatchNorm46 <- Convolution46
I0619 14:48:21.544241 17263 net.cpp:847] BatchNorm46 -> Convolution46 (in-place)
I0619 14:48:21.544481 17263 net.cpp:509] Setting up BatchNorm46
I0619 14:48:21.544491 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.544494 17263 net.cpp:524] Memory required for data: 1914176000
I0619 14:48:21.544508 17263 layer_factory.hpp:77] Creating layer Scale46
I0619 14:48:21.544515 17263 net.cpp:459] Creating Layer Scale46
I0619 14:48:21.544522 17263 net.cpp:886] Scale46 <- Convolution46
I0619 14:48:21.544531 17263 net.cpp:847] Scale46 -> Convolution46 (in-place)
I0619 14:48:21.544571 17263 layer_factory.hpp:77] Creating layer Scale46
I0619 14:48:21.544713 17263 net.cpp:509] Setting up Scale46
I0619 14:48:21.544721 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.544725 17263 net.cpp:524] Memory required for data: 1918370304
I0619 14:48:21.544739 17263 layer_factory.hpp:77] Creating layer ReLU46
I0619 14:48:21.544746 17263 net.cpp:459] Creating Layer ReLU46
I0619 14:48:21.544751 17263 net.cpp:886] ReLU46 <- Convolution46
I0619 14:48:21.544759 17263 net.cpp:847] ReLU46 -> Convolution46 (in-place)
I0619 14:48:21.544765 17263 net.cpp:509] Setting up ReLU46
I0619 14:48:21.544772 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.544776 17263 net.cpp:524] Memory required for data: 1922564608
I0619 14:48:21.544781 17263 layer_factory.hpp:77] Creating layer Convolution47
I0619 14:48:21.544795 17263 net.cpp:459] Creating Layer Convolution47
I0619 14:48:21.544800 17263 net.cpp:886] Convolution47 <- Convolution46
I0619 14:48:21.544808 17263 net.cpp:860] Convolution47 -> Convolution47
I0619 14:48:21.545513 17263 net.cpp:509] Setting up Convolution47
I0619 14:48:21.545523 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.545528 17263 net.cpp:524] Memory required for data: 1926758912
I0619 14:48:21.545538 17263 layer_factory.hpp:77] Creating layer BatchNorm47
I0619 14:48:21.545549 17263 net.cpp:459] Creating Layer BatchNorm47
I0619 14:48:21.545554 17263 net.cpp:886] BatchNorm47 <- Convolution47
I0619 14:48:21.545564 17263 net.cpp:847] BatchNorm47 -> Convolution47 (in-place)
I0619 14:48:21.545800 17263 net.cpp:509] Setting up BatchNorm47
I0619 14:48:21.545809 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.545814 17263 net.cpp:524] Memory required for data: 1930953216
I0619 14:48:21.545827 17263 layer_factory.hpp:77] Creating layer Scale47
I0619 14:48:21.545835 17263 net.cpp:459] Creating Layer Scale47
I0619 14:48:21.545840 17263 net.cpp:886] Scale47 <- Convolution47
I0619 14:48:21.545850 17263 net.cpp:847] Scale47 -> Convolution47 (in-place)
I0619 14:48:21.545889 17263 layer_factory.hpp:77] Creating layer Scale47
I0619 14:48:21.546032 17263 net.cpp:509] Setting up Scale47
I0619 14:48:21.546041 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.546046 17263 net.cpp:524] Memory required for data: 1935147520
I0619 14:48:21.546057 17263 layer_factory.hpp:77] Creating layer Eltwise23
I0619 14:48:21.546066 17263 net.cpp:459] Creating Layer Eltwise23
I0619 14:48:21.546072 17263 net.cpp:886] Eltwise23 <- Eltwise22_ReLU45_0_split_1
I0619 14:48:21.546077 17263 net.cpp:886] Eltwise23 <- Convolution47
I0619 14:48:21.546087 17263 net.cpp:860] Eltwise23 -> Eltwise23
I0619 14:48:21.546115 17263 net.cpp:509] Setting up Eltwise23
I0619 14:48:21.546138 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.546144 17263 net.cpp:524] Memory required for data: 1939341824
I0619 14:48:21.546147 17263 layer_factory.hpp:77] Creating layer ReLU47
I0619 14:48:21.546157 17263 net.cpp:459] Creating Layer ReLU47
I0619 14:48:21.546162 17263 net.cpp:886] ReLU47 <- Eltwise23
I0619 14:48:21.546169 17263 net.cpp:847] ReLU47 -> Eltwise23 (in-place)
I0619 14:48:21.546177 17263 net.cpp:509] Setting up ReLU47
I0619 14:48:21.546185 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.546190 17263 net.cpp:524] Memory required for data: 1943536128
I0619 14:48:21.546193 17263 layer_factory.hpp:77] Creating layer Eltwise23_ReLU47_0_split
I0619 14:48:21.546200 17263 net.cpp:459] Creating Layer Eltwise23_ReLU47_0_split
I0619 14:48:21.546205 17263 net.cpp:886] Eltwise23_ReLU47_0_split <- Eltwise23
I0619 14:48:21.546211 17263 net.cpp:860] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_0
I0619 14:48:21.546222 17263 net.cpp:860] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_1
I0619 14:48:21.546267 17263 net.cpp:509] Setting up Eltwise23_ReLU47_0_split
I0619 14:48:21.546275 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.546281 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.546286 17263 net.cpp:524] Memory required for data: 1951924736
I0619 14:48:21.546291 17263 layer_factory.hpp:77] Creating layer Convolution48
I0619 14:48:21.546304 17263 net.cpp:459] Creating Layer Convolution48
I0619 14:48:21.546309 17263 net.cpp:886] Convolution48 <- Eltwise23_ReLU47_0_split_0
I0619 14:48:21.546319 17263 net.cpp:860] Convolution48 -> Convolution48
I0619 14:48:21.547034 17263 net.cpp:509] Setting up Convolution48
I0619 14:48:21.547045 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.547050 17263 net.cpp:524] Memory required for data: 1956119040
I0619 14:48:21.547061 17263 layer_factory.hpp:77] Creating layer BatchNorm48
I0619 14:48:21.547072 17263 net.cpp:459] Creating Layer BatchNorm48
I0619 14:48:21.547077 17263 net.cpp:886] BatchNorm48 <- Convolution48
I0619 14:48:21.547086 17263 net.cpp:847] BatchNorm48 -> Convolution48 (in-place)
I0619 14:48:21.547328 17263 net.cpp:509] Setting up BatchNorm48
I0619 14:48:21.547338 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.547341 17263 net.cpp:524] Memory required for data: 1960313344
I0619 14:48:21.547354 17263 layer_factory.hpp:77] Creating layer Scale48
I0619 14:48:21.547365 17263 net.cpp:459] Creating Layer Scale48
I0619 14:48:21.547370 17263 net.cpp:886] Scale48 <- Convolution48
I0619 14:48:21.547377 17263 net.cpp:847] Scale48 -> Convolution48 (in-place)
I0619 14:48:21.547420 17263 layer_factory.hpp:77] Creating layer Scale48
I0619 14:48:21.547561 17263 net.cpp:509] Setting up Scale48
I0619 14:48:21.547570 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.547574 17263 net.cpp:524] Memory required for data: 1964507648
I0619 14:48:21.547585 17263 layer_factory.hpp:77] Creating layer ReLU48
I0619 14:48:21.547595 17263 net.cpp:459] Creating Layer ReLU48
I0619 14:48:21.547600 17263 net.cpp:886] ReLU48 <- Convolution48
I0619 14:48:21.547607 17263 net.cpp:847] ReLU48 -> Convolution48 (in-place)
I0619 14:48:21.547615 17263 net.cpp:509] Setting up ReLU48
I0619 14:48:21.547621 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.547626 17263 net.cpp:524] Memory required for data: 1968701952
I0619 14:48:21.547631 17263 layer_factory.hpp:77] Creating layer Convolution49
I0619 14:48:21.547642 17263 net.cpp:459] Creating Layer Convolution49
I0619 14:48:21.547647 17263 net.cpp:886] Convolution49 <- Convolution48
I0619 14:48:21.547655 17263 net.cpp:860] Convolution49 -> Convolution49
I0619 14:48:21.548360 17263 net.cpp:509] Setting up Convolution49
I0619 14:48:21.548370 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.548375 17263 net.cpp:524] Memory required for data: 1972896256
I0619 14:48:21.548387 17263 layer_factory.hpp:77] Creating layer BatchNorm49
I0619 14:48:21.548399 17263 net.cpp:459] Creating Layer BatchNorm49
I0619 14:48:21.548419 17263 net.cpp:886] BatchNorm49 <- Convolution49
I0619 14:48:21.548427 17263 net.cpp:847] BatchNorm49 -> Convolution49 (in-place)
I0619 14:48:21.548667 17263 net.cpp:509] Setting up BatchNorm49
I0619 14:48:21.548677 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.548681 17263 net.cpp:524] Memory required for data: 1977090560
I0619 14:48:21.548697 17263 layer_factory.hpp:77] Creating layer Scale49
I0619 14:48:21.548705 17263 net.cpp:459] Creating Layer Scale49
I0619 14:48:21.548710 17263 net.cpp:886] Scale49 <- Convolution49
I0619 14:48:21.548717 17263 net.cpp:847] Scale49 -> Convolution49 (in-place)
I0619 14:48:21.548760 17263 layer_factory.hpp:77] Creating layer Scale49
I0619 14:48:21.548905 17263 net.cpp:509] Setting up Scale49
I0619 14:48:21.548914 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.548918 17263 net.cpp:524] Memory required for data: 1981284864
I0619 14:48:21.548931 17263 layer_factory.hpp:77] Creating layer Eltwise24
I0619 14:48:21.548939 17263 net.cpp:459] Creating Layer Eltwise24
I0619 14:48:21.548945 17263 net.cpp:886] Eltwise24 <- Eltwise23_ReLU47_0_split_1
I0619 14:48:21.548951 17263 net.cpp:886] Eltwise24 <- Convolution49
I0619 14:48:21.548961 17263 net.cpp:860] Eltwise24 -> Eltwise24
I0619 14:48:21.548985 17263 net.cpp:509] Setting up Eltwise24
I0619 14:48:21.548992 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.548997 17263 net.cpp:524] Memory required for data: 1985479168
I0619 14:48:21.549001 17263 layer_factory.hpp:77] Creating layer ReLU49
I0619 14:48:21.549008 17263 net.cpp:459] Creating Layer ReLU49
I0619 14:48:21.549013 17263 net.cpp:886] ReLU49 <- Eltwise24
I0619 14:48:21.549021 17263 net.cpp:847] ReLU49 -> Eltwise24 (in-place)
I0619 14:48:21.549029 17263 net.cpp:509] Setting up ReLU49
I0619 14:48:21.549036 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.549041 17263 net.cpp:524] Memory required for data: 1989673472
I0619 14:48:21.549046 17263 layer_factory.hpp:77] Creating layer Eltwise24_ReLU49_0_split
I0619 14:48:21.549052 17263 net.cpp:459] Creating Layer Eltwise24_ReLU49_0_split
I0619 14:48:21.549057 17263 net.cpp:886] Eltwise24_ReLU49_0_split <- Eltwise24
I0619 14:48:21.549063 17263 net.cpp:860] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_0
I0619 14:48:21.549072 17263 net.cpp:860] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_1
I0619 14:48:21.549119 17263 net.cpp:509] Setting up Eltwise24_ReLU49_0_split
I0619 14:48:21.549127 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.549134 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.549139 17263 net.cpp:524] Memory required for data: 1998062080
I0619 14:48:21.549142 17263 layer_factory.hpp:77] Creating layer Convolution50
I0619 14:48:21.549154 17263 net.cpp:459] Creating Layer Convolution50
I0619 14:48:21.549159 17263 net.cpp:886] Convolution50 <- Eltwise24_ReLU49_0_split_0
I0619 14:48:21.549168 17263 net.cpp:860] Convolution50 -> Convolution50
I0619 14:48:21.550586 17263 net.cpp:509] Setting up Convolution50
I0619 14:48:21.550606 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.550611 17263 net.cpp:524] Memory required for data: 2002256384
I0619 14:48:21.550624 17263 layer_factory.hpp:77] Creating layer BatchNorm50
I0619 14:48:21.550637 17263 net.cpp:459] Creating Layer BatchNorm50
I0619 14:48:21.550643 17263 net.cpp:886] BatchNorm50 <- Convolution50
I0619 14:48:21.550652 17263 net.cpp:847] BatchNorm50 -> Convolution50 (in-place)
I0619 14:48:21.550889 17263 net.cpp:509] Setting up BatchNorm50
I0619 14:48:21.550897 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.550902 17263 net.cpp:524] Memory required for data: 2006450688
I0619 14:48:21.550916 17263 layer_factory.hpp:77] Creating layer Scale50
I0619 14:48:21.550925 17263 net.cpp:459] Creating Layer Scale50
I0619 14:48:21.550930 17263 net.cpp:886] Scale50 <- Convolution50
I0619 14:48:21.550938 17263 net.cpp:847] Scale50 -> Convolution50 (in-place)
I0619 14:48:21.550983 17263 layer_factory.hpp:77] Creating layer Scale50
I0619 14:48:21.551146 17263 net.cpp:509] Setting up Scale50
I0619 14:48:21.551159 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.551164 17263 net.cpp:524] Memory required for data: 2010644992
I0619 14:48:21.551175 17263 layer_factory.hpp:77] Creating layer ReLU50
I0619 14:48:21.551183 17263 net.cpp:459] Creating Layer ReLU50
I0619 14:48:21.551189 17263 net.cpp:886] ReLU50 <- Convolution50
I0619 14:48:21.551195 17263 net.cpp:847] ReLU50 -> Convolution50 (in-place)
I0619 14:48:21.551204 17263 net.cpp:509] Setting up ReLU50
I0619 14:48:21.551211 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.551215 17263 net.cpp:524] Memory required for data: 2014839296
I0619 14:48:21.551220 17263 layer_factory.hpp:77] Creating layer Convolution51
I0619 14:48:21.551234 17263 net.cpp:459] Creating Layer Convolution51
I0619 14:48:21.551239 17263 net.cpp:886] Convolution51 <- Convolution50
I0619 14:48:21.551249 17263 net.cpp:860] Convolution51 -> Convolution51
I0619 14:48:21.551945 17263 net.cpp:509] Setting up Convolution51
I0619 14:48:21.551956 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.551960 17263 net.cpp:524] Memory required for data: 2019033600
I0619 14:48:21.551971 17263 layer_factory.hpp:77] Creating layer BatchNorm51
I0619 14:48:21.551982 17263 net.cpp:459] Creating Layer BatchNorm51
I0619 14:48:21.551987 17263 net.cpp:886] BatchNorm51 <- Convolution51
I0619 14:48:21.551996 17263 net.cpp:847] BatchNorm51 -> Convolution51 (in-place)
I0619 14:48:21.552225 17263 net.cpp:509] Setting up BatchNorm51
I0619 14:48:21.552234 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.552239 17263 net.cpp:524] Memory required for data: 2023227904
I0619 14:48:21.552253 17263 layer_factory.hpp:77] Creating layer Scale51
I0619 14:48:21.552263 17263 net.cpp:459] Creating Layer Scale51
I0619 14:48:21.552268 17263 net.cpp:886] Scale51 <- Convolution51
I0619 14:48:21.552274 17263 net.cpp:847] Scale51 -> Convolution51 (in-place)
I0619 14:48:21.552315 17263 layer_factory.hpp:77] Creating layer Scale51
I0619 14:48:21.552459 17263 net.cpp:509] Setting up Scale51
I0619 14:48:21.552469 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.552472 17263 net.cpp:524] Memory required for data: 2027422208
I0619 14:48:21.552484 17263 layer_factory.hpp:77] Creating layer Eltwise25
I0619 14:48:21.552516 17263 net.cpp:459] Creating Layer Eltwise25
I0619 14:48:21.552523 17263 net.cpp:886] Eltwise25 <- Eltwise24_ReLU49_0_split_1
I0619 14:48:21.552531 17263 net.cpp:886] Eltwise25 <- Convolution51
I0619 14:48:21.552537 17263 net.cpp:860] Eltwise25 -> Eltwise25
I0619 14:48:21.552562 17263 net.cpp:509] Setting up Eltwise25
I0619 14:48:21.552570 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.552575 17263 net.cpp:524] Memory required for data: 2031616512
I0619 14:48:21.552582 17263 layer_factory.hpp:77] Creating layer ReLU51
I0619 14:48:21.552592 17263 net.cpp:459] Creating Layer ReLU51
I0619 14:48:21.552597 17263 net.cpp:886] ReLU51 <- Eltwise25
I0619 14:48:21.552603 17263 net.cpp:847] ReLU51 -> Eltwise25 (in-place)
I0619 14:48:21.552611 17263 net.cpp:509] Setting up ReLU51
I0619 14:48:21.552618 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.552623 17263 net.cpp:524] Memory required for data: 2035810816
I0619 14:48:21.552628 17263 layer_factory.hpp:77] Creating layer Eltwise25_ReLU51_0_split
I0619 14:48:21.552634 17263 net.cpp:459] Creating Layer Eltwise25_ReLU51_0_split
I0619 14:48:21.552639 17263 net.cpp:886] Eltwise25_ReLU51_0_split <- Eltwise25
I0619 14:48:21.552645 17263 net.cpp:860] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_0
I0619 14:48:21.552655 17263 net.cpp:860] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_1
I0619 14:48:21.552700 17263 net.cpp:509] Setting up Eltwise25_ReLU51_0_split
I0619 14:48:21.552711 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.552716 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.552724 17263 net.cpp:524] Memory required for data: 2044199424
I0619 14:48:21.552742 17263 layer_factory.hpp:77] Creating layer Convolution52
I0619 14:48:21.552755 17263 net.cpp:459] Creating Layer Convolution52
I0619 14:48:21.552760 17263 net.cpp:886] Convolution52 <- Eltwise25_ReLU51_0_split_0
I0619 14:48:21.552772 17263 net.cpp:860] Convolution52 -> Convolution52
I0619 14:48:21.553478 17263 net.cpp:509] Setting up Convolution52
I0619 14:48:21.553489 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.553494 17263 net.cpp:524] Memory required for data: 2048393728
I0619 14:48:21.553505 17263 layer_factory.hpp:77] Creating layer BatchNorm52
I0619 14:48:21.553520 17263 net.cpp:459] Creating Layer BatchNorm52
I0619 14:48:21.553526 17263 net.cpp:886] BatchNorm52 <- Convolution52
I0619 14:48:21.553534 17263 net.cpp:847] BatchNorm52 -> Convolution52 (in-place)
I0619 14:48:21.553771 17263 net.cpp:509] Setting up BatchNorm52
I0619 14:48:21.553779 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.553783 17263 net.cpp:524] Memory required for data: 2052588032
I0619 14:48:21.553797 17263 layer_factory.hpp:77] Creating layer Scale52
I0619 14:48:21.553805 17263 net.cpp:459] Creating Layer Scale52
I0619 14:48:21.553810 17263 net.cpp:886] Scale52 <- Convolution52
I0619 14:48:21.553819 17263 net.cpp:847] Scale52 -> Convolution52 (in-place)
I0619 14:48:21.553859 17263 layer_factory.hpp:77] Creating layer Scale52
I0619 14:48:21.553998 17263 net.cpp:509] Setting up Scale52
I0619 14:48:21.554008 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.554013 17263 net.cpp:524] Memory required for data: 2056782336
I0619 14:48:21.554025 17263 layer_factory.hpp:77] Creating layer ReLU52
I0619 14:48:21.554033 17263 net.cpp:459] Creating Layer ReLU52
I0619 14:48:21.554039 17263 net.cpp:886] ReLU52 <- Convolution52
I0619 14:48:21.554044 17263 net.cpp:847] ReLU52 -> Convolution52 (in-place)
I0619 14:48:21.554052 17263 net.cpp:509] Setting up ReLU52
I0619 14:48:21.554059 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.554064 17263 net.cpp:524] Memory required for data: 2060976640
I0619 14:48:21.554067 17263 layer_factory.hpp:77] Creating layer Convolution53
I0619 14:48:21.554086 17263 net.cpp:459] Creating Layer Convolution53
I0619 14:48:21.554091 17263 net.cpp:886] Convolution53 <- Convolution52
I0619 14:48:21.554102 17263 net.cpp:860] Convolution53 -> Convolution53
I0619 14:48:21.554814 17263 net.cpp:509] Setting up Convolution53
I0619 14:48:21.554826 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.554831 17263 net.cpp:524] Memory required for data: 2065170944
I0619 14:48:21.554841 17263 layer_factory.hpp:77] Creating layer BatchNorm53
I0619 14:48:21.554852 17263 net.cpp:459] Creating Layer BatchNorm53
I0619 14:48:21.554857 17263 net.cpp:886] BatchNorm53 <- Convolution53
I0619 14:48:21.554865 17263 net.cpp:847] BatchNorm53 -> Convolution53 (in-place)
I0619 14:48:21.555086 17263 net.cpp:509] Setting up BatchNorm53
I0619 14:48:21.555094 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.555099 17263 net.cpp:524] Memory required for data: 2069365248
I0619 14:48:21.555111 17263 layer_factory.hpp:77] Creating layer Scale53
I0619 14:48:21.555119 17263 net.cpp:459] Creating Layer Scale53
I0619 14:48:21.555124 17263 net.cpp:886] Scale53 <- Convolution53
I0619 14:48:21.555132 17263 net.cpp:847] Scale53 -> Convolution53 (in-place)
I0619 14:48:21.555169 17263 layer_factory.hpp:77] Creating layer Scale53
I0619 14:48:21.555305 17263 net.cpp:509] Setting up Scale53
I0619 14:48:21.555312 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.555317 17263 net.cpp:524] Memory required for data: 2073559552
I0619 14:48:21.555327 17263 layer_factory.hpp:77] Creating layer Eltwise26
I0619 14:48:21.555335 17263 net.cpp:459] Creating Layer Eltwise26
I0619 14:48:21.555341 17263 net.cpp:886] Eltwise26 <- Eltwise25_ReLU51_0_split_1
I0619 14:48:21.555346 17263 net.cpp:886] Eltwise26 <- Convolution53
I0619 14:48:21.555356 17263 net.cpp:860] Eltwise26 -> Eltwise26
I0619 14:48:21.555380 17263 net.cpp:509] Setting up Eltwise26
I0619 14:48:21.555402 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.555408 17263 net.cpp:524] Memory required for data: 2077753856
I0619 14:48:21.555413 17263 layer_factory.hpp:77] Creating layer ReLU53
I0619 14:48:21.555423 17263 net.cpp:459] Creating Layer ReLU53
I0619 14:48:21.555428 17263 net.cpp:886] ReLU53 <- Eltwise26
I0619 14:48:21.555433 17263 net.cpp:847] ReLU53 -> Eltwise26 (in-place)
I0619 14:48:21.555443 17263 net.cpp:509] Setting up ReLU53
I0619 14:48:21.555449 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.555452 17263 net.cpp:524] Memory required for data: 2081948160
I0619 14:48:21.555456 17263 layer_factory.hpp:77] Creating layer Eltwise26_ReLU53_0_split
I0619 14:48:21.555462 17263 net.cpp:459] Creating Layer Eltwise26_ReLU53_0_split
I0619 14:48:21.555467 17263 net.cpp:886] Eltwise26_ReLU53_0_split <- Eltwise26
I0619 14:48:21.555474 17263 net.cpp:860] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_0
I0619 14:48:21.555486 17263 net.cpp:860] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_1
I0619 14:48:21.555531 17263 net.cpp:509] Setting up Eltwise26_ReLU53_0_split
I0619 14:48:21.555537 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.555543 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.555547 17263 net.cpp:524] Memory required for data: 2090336768
I0619 14:48:21.555552 17263 layer_factory.hpp:77] Creating layer Convolution54
I0619 14:48:21.555564 17263 net.cpp:459] Creating Layer Convolution54
I0619 14:48:21.555570 17263 net.cpp:886] Convolution54 <- Eltwise26_ReLU53_0_split_0
I0619 14:48:21.555578 17263 net.cpp:860] Convolution54 -> Convolution54
I0619 14:48:21.556257 17263 net.cpp:509] Setting up Convolution54
I0619 14:48:21.556267 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.556272 17263 net.cpp:524] Memory required for data: 2094531072
I0619 14:48:21.556282 17263 layer_factory.hpp:77] Creating layer BatchNorm54
I0619 14:48:21.556293 17263 net.cpp:459] Creating Layer BatchNorm54
I0619 14:48:21.556298 17263 net.cpp:886] BatchNorm54 <- Convolution54
I0619 14:48:21.556304 17263 net.cpp:847] BatchNorm54 -> Convolution54 (in-place)
I0619 14:48:21.556524 17263 net.cpp:509] Setting up BatchNorm54
I0619 14:48:21.556532 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.556536 17263 net.cpp:524] Memory required for data: 2098725376
I0619 14:48:21.556550 17263 layer_factory.hpp:77] Creating layer Scale54
I0619 14:48:21.556558 17263 net.cpp:459] Creating Layer Scale54
I0619 14:48:21.556563 17263 net.cpp:886] Scale54 <- Convolution54
I0619 14:48:21.556571 17263 net.cpp:847] Scale54 -> Convolution54 (in-place)
I0619 14:48:21.556609 17263 layer_factory.hpp:77] Creating layer Scale54
I0619 14:48:21.556743 17263 net.cpp:509] Setting up Scale54
I0619 14:48:21.556751 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.556756 17263 net.cpp:524] Memory required for data: 2102919680
I0619 14:48:21.556766 17263 layer_factory.hpp:77] Creating layer ReLU54
I0619 14:48:21.556776 17263 net.cpp:459] Creating Layer ReLU54
I0619 14:48:21.556780 17263 net.cpp:886] ReLU54 <- Convolution54
I0619 14:48:21.556787 17263 net.cpp:847] ReLU54 -> Convolution54 (in-place)
I0619 14:48:21.556794 17263 net.cpp:509] Setting up ReLU54
I0619 14:48:21.556800 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.556804 17263 net.cpp:524] Memory required for data: 2107113984
I0619 14:48:21.556808 17263 layer_factory.hpp:77] Creating layer Convolution55
I0619 14:48:21.556821 17263 net.cpp:459] Creating Layer Convolution55
I0619 14:48:21.556825 17263 net.cpp:886] Convolution55 <- Convolution54
I0619 14:48:21.556833 17263 net.cpp:860] Convolution55 -> Convolution55
I0619 14:48:21.557494 17263 net.cpp:509] Setting up Convolution55
I0619 14:48:21.557503 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.557508 17263 net.cpp:524] Memory required for data: 2111308288
I0619 14:48:21.557521 17263 layer_factory.hpp:77] Creating layer BatchNorm55
I0619 14:48:21.557544 17263 net.cpp:459] Creating Layer BatchNorm55
I0619 14:48:21.557551 17263 net.cpp:886] BatchNorm55 <- Convolution55
I0619 14:48:21.557559 17263 net.cpp:847] BatchNorm55 -> Convolution55 (in-place)
I0619 14:48:21.557790 17263 net.cpp:509] Setting up BatchNorm55
I0619 14:48:21.557799 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.557803 17263 net.cpp:524] Memory required for data: 2115502592
I0619 14:48:21.557818 17263 layer_factory.hpp:77] Creating layer Scale55
I0619 14:48:21.557826 17263 net.cpp:459] Creating Layer Scale55
I0619 14:48:21.557832 17263 net.cpp:886] Scale55 <- Convolution55
I0619 14:48:21.557838 17263 net.cpp:847] Scale55 -> Convolution55 (in-place)
I0619 14:48:21.557879 17263 layer_factory.hpp:77] Creating layer Scale55
I0619 14:48:21.558012 17263 net.cpp:509] Setting up Scale55
I0619 14:48:21.558020 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.558024 17263 net.cpp:524] Memory required for data: 2119696896
I0619 14:48:21.558037 17263 layer_factory.hpp:77] Creating layer Eltwise27
I0619 14:48:21.558045 17263 net.cpp:459] Creating Layer Eltwise27
I0619 14:48:21.558050 17263 net.cpp:886] Eltwise27 <- Eltwise26_ReLU53_0_split_1
I0619 14:48:21.558056 17263 net.cpp:886] Eltwise27 <- Convolution55
I0619 14:48:21.558065 17263 net.cpp:860] Eltwise27 -> Eltwise27
I0619 14:48:21.558086 17263 net.cpp:509] Setting up Eltwise27
I0619 14:48:21.558094 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.558099 17263 net.cpp:524] Memory required for data: 2123891200
I0619 14:48:21.558104 17263 layer_factory.hpp:77] Creating layer ReLU55
I0619 14:48:21.558109 17263 net.cpp:459] Creating Layer ReLU55
I0619 14:48:21.558115 17263 net.cpp:886] ReLU55 <- Eltwise27
I0619 14:48:21.558125 17263 net.cpp:847] ReLU55 -> Eltwise27 (in-place)
I0619 14:48:21.558132 17263 net.cpp:509] Setting up ReLU55
I0619 14:48:21.558138 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.558142 17263 net.cpp:524] Memory required for data: 2128085504
I0619 14:48:21.558147 17263 layer_factory.hpp:77] Creating layer Eltwise27_ReLU55_0_split
I0619 14:48:21.558153 17263 net.cpp:459] Creating Layer Eltwise27_ReLU55_0_split
I0619 14:48:21.558157 17263 net.cpp:886] Eltwise27_ReLU55_0_split <- Eltwise27
I0619 14:48:21.558164 17263 net.cpp:860] Eltwise27_ReLU55_0_split -> Eltwise27_ReLU55_0_split_0
I0619 14:48:21.558172 17263 net.cpp:860] Eltwise27_ReLU55_0_split -> Eltwise27_ReLU55_0_split_1
I0619 14:48:21.558214 17263 net.cpp:509] Setting up Eltwise27_ReLU55_0_split
I0619 14:48:21.558223 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.558228 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.558233 17263 net.cpp:524] Memory required for data: 2136474112
I0619 14:48:21.558236 17263 layer_factory.hpp:77] Creating layer Convolution56
I0619 14:48:21.558246 17263 net.cpp:459] Creating Layer Convolution56
I0619 14:48:21.558251 17263 net.cpp:886] Convolution56 <- Eltwise27_ReLU55_0_split_0
I0619 14:48:21.558261 17263 net.cpp:860] Convolution56 -> Convolution56
I0619 14:48:21.558933 17263 net.cpp:509] Setting up Convolution56
I0619 14:48:21.558945 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.558950 17263 net.cpp:524] Memory required for data: 2140668416
I0619 14:48:21.558960 17263 layer_factory.hpp:77] Creating layer BatchNorm56
I0619 14:48:21.558969 17263 net.cpp:459] Creating Layer BatchNorm56
I0619 14:48:21.558974 17263 net.cpp:886] BatchNorm56 <- Convolution56
I0619 14:48:21.558984 17263 net.cpp:847] BatchNorm56 -> Convolution56 (in-place)
I0619 14:48:21.559207 17263 net.cpp:509] Setting up BatchNorm56
I0619 14:48:21.559216 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.559221 17263 net.cpp:524] Memory required for data: 2144862720
I0619 14:48:21.559232 17263 layer_factory.hpp:77] Creating layer Scale56
I0619 14:48:21.559240 17263 net.cpp:459] Creating Layer Scale56
I0619 14:48:21.559245 17263 net.cpp:886] Scale56 <- Convolution56
I0619 14:48:21.559257 17263 net.cpp:847] Scale56 -> Convolution56 (in-place)
I0619 14:48:21.559315 17263 layer_factory.hpp:77] Creating layer Scale56
I0619 14:48:21.559453 17263 net.cpp:509] Setting up Scale56
I0619 14:48:21.559461 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.559465 17263 net.cpp:524] Memory required for data: 2149057024
I0619 14:48:21.559476 17263 layer_factory.hpp:77] Creating layer ReLU56
I0619 14:48:21.559485 17263 net.cpp:459] Creating Layer ReLU56
I0619 14:48:21.559490 17263 net.cpp:886] ReLU56 <- Convolution56
I0619 14:48:21.559496 17263 net.cpp:847] ReLU56 -> Convolution56 (in-place)
I0619 14:48:21.559504 17263 net.cpp:509] Setting up ReLU56
I0619 14:48:21.559510 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.559514 17263 net.cpp:524] Memory required for data: 2153251328
I0619 14:48:21.559519 17263 layer_factory.hpp:77] Creating layer Convolution57
I0619 14:48:21.559531 17263 net.cpp:459] Creating Layer Convolution57
I0619 14:48:21.559536 17263 net.cpp:886] Convolution57 <- Convolution56
I0619 14:48:21.559543 17263 net.cpp:860] Convolution57 -> Convolution57
I0619 14:48:21.560214 17263 net.cpp:509] Setting up Convolution57
I0619 14:48:21.560223 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.560227 17263 net.cpp:524] Memory required for data: 2157445632
I0619 14:48:21.560237 17263 layer_factory.hpp:77] Creating layer BatchNorm57
I0619 14:48:21.560250 17263 net.cpp:459] Creating Layer BatchNorm57
I0619 14:48:21.560255 17263 net.cpp:886] BatchNorm57 <- Convolution57
I0619 14:48:21.560261 17263 net.cpp:847] BatchNorm57 -> Convolution57 (in-place)
I0619 14:48:21.560482 17263 net.cpp:509] Setting up BatchNorm57
I0619 14:48:21.560492 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.560495 17263 net.cpp:524] Memory required for data: 2161639936
I0619 14:48:21.560508 17263 layer_factory.hpp:77] Creating layer Scale57
I0619 14:48:21.560515 17263 net.cpp:459] Creating Layer Scale57
I0619 14:48:21.560519 17263 net.cpp:886] Scale57 <- Convolution57
I0619 14:48:21.560528 17263 net.cpp:847] Scale57 -> Convolution57 (in-place)
I0619 14:48:21.560566 17263 layer_factory.hpp:77] Creating layer Scale57
I0619 14:48:21.560698 17263 net.cpp:509] Setting up Scale57
I0619 14:48:21.560708 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.560713 17263 net.cpp:524] Memory required for data: 2165834240
I0619 14:48:21.560724 17263 layer_factory.hpp:77] Creating layer Eltwise28
I0619 14:48:21.560730 17263 net.cpp:459] Creating Layer Eltwise28
I0619 14:48:21.560735 17263 net.cpp:886] Eltwise28 <- Eltwise27_ReLU55_0_split_1
I0619 14:48:21.560741 17263 net.cpp:886] Eltwise28 <- Convolution57
I0619 14:48:21.560748 17263 net.cpp:860] Eltwise28 -> Eltwise28
I0619 14:48:21.560773 17263 net.cpp:509] Setting up Eltwise28
I0619 14:48:21.560781 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.560786 17263 net.cpp:524] Memory required for data: 2170028544
I0619 14:48:21.560789 17263 layer_factory.hpp:77] Creating layer ReLU57
I0619 14:48:21.560796 17263 net.cpp:459] Creating Layer ReLU57
I0619 14:48:21.560801 17263 net.cpp:886] ReLU57 <- Eltwise28
I0619 14:48:21.560808 17263 net.cpp:847] ReLU57 -> Eltwise28 (in-place)
I0619 14:48:21.560817 17263 net.cpp:509] Setting up ReLU57
I0619 14:48:21.560822 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.560827 17263 net.cpp:524] Memory required for data: 2174222848
I0619 14:48:21.560830 17263 layer_factory.hpp:77] Creating layer Eltwise28_ReLU57_0_split
I0619 14:48:21.560837 17263 net.cpp:459] Creating Layer Eltwise28_ReLU57_0_split
I0619 14:48:21.560842 17263 net.cpp:886] Eltwise28_ReLU57_0_split <- Eltwise28
I0619 14:48:21.560848 17263 net.cpp:860] Eltwise28_ReLU57_0_split -> Eltwise28_ReLU57_0_split_0
I0619 14:48:21.560856 17263 net.cpp:860] Eltwise28_ReLU57_0_split -> Eltwise28_ReLU57_0_split_1
I0619 14:48:21.560899 17263 net.cpp:509] Setting up Eltwise28_ReLU57_0_split
I0619 14:48:21.560906 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.560915 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.560932 17263 net.cpp:524] Memory required for data: 2182611456
I0619 14:48:21.560938 17263 layer_factory.hpp:77] Creating layer Convolution58
I0619 14:48:21.560951 17263 net.cpp:459] Creating Layer Convolution58
I0619 14:48:21.560956 17263 net.cpp:886] Convolution58 <- Eltwise28_ReLU57_0_split_0
I0619 14:48:21.560964 17263 net.cpp:860] Convolution58 -> Convolution58
I0619 14:48:21.561640 17263 net.cpp:509] Setting up Convolution58
I0619 14:48:21.561650 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.561655 17263 net.cpp:524] Memory required for data: 2186805760
I0619 14:48:21.561666 17263 layer_factory.hpp:77] Creating layer BatchNorm58
I0619 14:48:21.561676 17263 net.cpp:459] Creating Layer BatchNorm58
I0619 14:48:21.561681 17263 net.cpp:886] BatchNorm58 <- Convolution58
I0619 14:48:21.561689 17263 net.cpp:847] BatchNorm58 -> Convolution58 (in-place)
I0619 14:48:21.561913 17263 net.cpp:509] Setting up BatchNorm58
I0619 14:48:21.561923 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.561926 17263 net.cpp:524] Memory required for data: 2191000064
I0619 14:48:21.561939 17263 layer_factory.hpp:77] Creating layer Scale58
I0619 14:48:21.561949 17263 net.cpp:459] Creating Layer Scale58
I0619 14:48:21.561954 17263 net.cpp:886] Scale58 <- Convolution58
I0619 14:48:21.561959 17263 net.cpp:847] Scale58 -> Convolution58 (in-place)
I0619 14:48:21.562000 17263 layer_factory.hpp:77] Creating layer Scale58
I0619 14:48:21.562134 17263 net.cpp:509] Setting up Scale58
I0619 14:48:21.562144 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.562149 17263 net.cpp:524] Memory required for data: 2195194368
I0619 14:48:21.562158 17263 layer_factory.hpp:77] Creating layer ReLU58
I0619 14:48:21.562165 17263 net.cpp:459] Creating Layer ReLU58
I0619 14:48:21.562170 17263 net.cpp:886] ReLU58 <- Convolution58
I0619 14:48:21.562178 17263 net.cpp:847] ReLU58 -> Convolution58 (in-place)
I0619 14:48:21.562186 17263 net.cpp:509] Setting up ReLU58
I0619 14:48:21.562192 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.562197 17263 net.cpp:524] Memory required for data: 2199388672
I0619 14:48:21.562201 17263 layer_factory.hpp:77] Creating layer Convolution59
I0619 14:48:21.562213 17263 net.cpp:459] Creating Layer Convolution59
I0619 14:48:21.562217 17263 net.cpp:886] Convolution59 <- Convolution58
I0619 14:48:21.562225 17263 net.cpp:860] Convolution59 -> Convolution59
I0619 14:48:21.562906 17263 net.cpp:509] Setting up Convolution59
I0619 14:48:21.562917 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.562922 17263 net.cpp:524] Memory required for data: 2203582976
I0619 14:48:21.562932 17263 layer_factory.hpp:77] Creating layer BatchNorm59
I0619 14:48:21.562942 17263 net.cpp:459] Creating Layer BatchNorm59
I0619 14:48:21.562947 17263 net.cpp:886] BatchNorm59 <- Convolution59
I0619 14:48:21.562953 17263 net.cpp:847] BatchNorm59 -> Convolution59 (in-place)
I0619 14:48:21.563174 17263 net.cpp:509] Setting up BatchNorm59
I0619 14:48:21.563182 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.563187 17263 net.cpp:524] Memory required for data: 2207777280
I0619 14:48:21.563199 17263 layer_factory.hpp:77] Creating layer Scale59
I0619 14:48:21.563211 17263 net.cpp:459] Creating Layer Scale59
I0619 14:48:21.563216 17263 net.cpp:886] Scale59 <- Convolution59
I0619 14:48:21.563223 17263 net.cpp:847] Scale59 -> Convolution59 (in-place)
I0619 14:48:21.563268 17263 layer_factory.hpp:77] Creating layer Scale59
I0619 14:48:21.563401 17263 net.cpp:509] Setting up Scale59
I0619 14:48:21.563410 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.563415 17263 net.cpp:524] Memory required for data: 2211971584
I0619 14:48:21.563424 17263 layer_factory.hpp:77] Creating layer Eltwise29
I0619 14:48:21.563434 17263 net.cpp:459] Creating Layer Eltwise29
I0619 14:48:21.563439 17263 net.cpp:886] Eltwise29 <- Eltwise28_ReLU57_0_split_1
I0619 14:48:21.563446 17263 net.cpp:886] Eltwise29 <- Convolution59
I0619 14:48:21.563457 17263 net.cpp:860] Eltwise29 -> Eltwise29
I0619 14:48:21.563496 17263 net.cpp:509] Setting up Eltwise29
I0619 14:48:21.563505 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.563509 17263 net.cpp:524] Memory required for data: 2216165888
I0619 14:48:21.563514 17263 layer_factory.hpp:77] Creating layer ReLU59
I0619 14:48:21.563520 17263 net.cpp:459] Creating Layer ReLU59
I0619 14:48:21.563525 17263 net.cpp:886] ReLU59 <- Eltwise29
I0619 14:48:21.563531 17263 net.cpp:847] ReLU59 -> Eltwise29 (in-place)
I0619 14:48:21.563539 17263 net.cpp:509] Setting up ReLU59
I0619 14:48:21.563545 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.563549 17263 net.cpp:524] Memory required for data: 2220360192
I0619 14:48:21.563554 17263 layer_factory.hpp:77] Creating layer Eltwise29_ReLU59_0_split
I0619 14:48:21.563562 17263 net.cpp:459] Creating Layer Eltwise29_ReLU59_0_split
I0619 14:48:21.563567 17263 net.cpp:886] Eltwise29_ReLU59_0_split <- Eltwise29
I0619 14:48:21.563573 17263 net.cpp:860] Eltwise29_ReLU59_0_split -> Eltwise29_ReLU59_0_split_0
I0619 14:48:21.563581 17263 net.cpp:860] Eltwise29_ReLU59_0_split -> Eltwise29_ReLU59_0_split_1
I0619 14:48:21.563628 17263 net.cpp:509] Setting up Eltwise29_ReLU59_0_split
I0619 14:48:21.563635 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.563642 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.563645 17263 net.cpp:524] Memory required for data: 2228748800
I0619 14:48:21.563650 17263 layer_factory.hpp:77] Creating layer Convolution60
I0619 14:48:21.563660 17263 net.cpp:459] Creating Layer Convolution60
I0619 14:48:21.563665 17263 net.cpp:886] Convolution60 <- Eltwise29_ReLU59_0_split_0
I0619 14:48:21.563673 17263 net.cpp:860] Convolution60 -> Convolution60
I0619 14:48:21.564373 17263 net.cpp:509] Setting up Convolution60
I0619 14:48:21.564388 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.564393 17263 net.cpp:524] Memory required for data: 2232943104
I0619 14:48:21.564404 17263 layer_factory.hpp:77] Creating layer BatchNorm60
I0619 14:48:21.564412 17263 net.cpp:459] Creating Layer BatchNorm60
I0619 14:48:21.564417 17263 net.cpp:886] BatchNorm60 <- Convolution60
I0619 14:48:21.564429 17263 net.cpp:847] BatchNorm60 -> Convolution60 (in-place)
I0619 14:48:21.564656 17263 net.cpp:509] Setting up BatchNorm60
I0619 14:48:21.564666 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.564669 17263 net.cpp:524] Memory required for data: 2237137408
I0619 14:48:21.564682 17263 layer_factory.hpp:77] Creating layer Scale60
I0619 14:48:21.564690 17263 net.cpp:459] Creating Layer Scale60
I0619 14:48:21.564695 17263 net.cpp:886] Scale60 <- Convolution60
I0619 14:48:21.564702 17263 net.cpp:847] Scale60 -> Convolution60 (in-place)
I0619 14:48:21.564743 17263 layer_factory.hpp:77] Creating layer Scale60
I0619 14:48:21.564878 17263 net.cpp:509] Setting up Scale60
I0619 14:48:21.564888 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.564891 17263 net.cpp:524] Memory required for data: 2241331712
I0619 14:48:21.564903 17263 layer_factory.hpp:77] Creating layer ReLU60
I0619 14:48:21.564908 17263 net.cpp:459] Creating Layer ReLU60
I0619 14:48:21.564914 17263 net.cpp:886] ReLU60 <- Convolution60
I0619 14:48:21.564927 17263 net.cpp:847] ReLU60 -> Convolution60 (in-place)
I0619 14:48:21.564935 17263 net.cpp:509] Setting up ReLU60
I0619 14:48:21.564942 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.564946 17263 net.cpp:524] Memory required for data: 2245526016
I0619 14:48:21.564950 17263 layer_factory.hpp:77] Creating layer Convolution61
I0619 14:48:21.564963 17263 net.cpp:459] Creating Layer Convolution61
I0619 14:48:21.564968 17263 net.cpp:886] Convolution61 <- Convolution60
I0619 14:48:21.564975 17263 net.cpp:860] Convolution61 -> Convolution61
I0619 14:48:21.565640 17263 net.cpp:509] Setting up Convolution61
I0619 14:48:21.565651 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.565656 17263 net.cpp:524] Memory required for data: 2249720320
I0619 14:48:21.565683 17263 layer_factory.hpp:77] Creating layer BatchNorm61
I0619 14:48:21.565692 17263 net.cpp:459] Creating Layer BatchNorm61
I0619 14:48:21.565697 17263 net.cpp:886] BatchNorm61 <- Convolution61
I0619 14:48:21.565707 17263 net.cpp:847] BatchNorm61 -> Convolution61 (in-place)
I0619 14:48:21.565932 17263 net.cpp:509] Setting up BatchNorm61
I0619 14:48:21.565942 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.565946 17263 net.cpp:524] Memory required for data: 2253914624
I0619 14:48:21.565958 17263 layer_factory.hpp:77] Creating layer Scale61
I0619 14:48:21.565966 17263 net.cpp:459] Creating Layer Scale61
I0619 14:48:21.565971 17263 net.cpp:886] Scale61 <- Convolution61
I0619 14:48:21.565978 17263 net.cpp:847] Scale61 -> Convolution61 (in-place)
I0619 14:48:21.566018 17263 layer_factory.hpp:77] Creating layer Scale61
I0619 14:48:21.566153 17263 net.cpp:509] Setting up Scale61
I0619 14:48:21.566161 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.566165 17263 net.cpp:524] Memory required for data: 2258108928
I0619 14:48:21.566175 17263 layer_factory.hpp:77] Creating layer Eltwise30
I0619 14:48:21.566185 17263 net.cpp:459] Creating Layer Eltwise30
I0619 14:48:21.566190 17263 net.cpp:886] Eltwise30 <- Eltwise29_ReLU59_0_split_1
I0619 14:48:21.566196 17263 net.cpp:886] Eltwise30 <- Convolution61
I0619 14:48:21.566203 17263 net.cpp:860] Eltwise30 -> Eltwise30
I0619 14:48:21.566226 17263 net.cpp:509] Setting up Eltwise30
I0619 14:48:21.566232 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.566236 17263 net.cpp:524] Memory required for data: 2262303232
I0619 14:48:21.566241 17263 layer_factory.hpp:77] Creating layer ReLU61
I0619 14:48:21.566251 17263 net.cpp:459] Creating Layer ReLU61
I0619 14:48:21.566256 17263 net.cpp:886] ReLU61 <- Eltwise30
I0619 14:48:21.566263 17263 net.cpp:847] ReLU61 -> Eltwise30 (in-place)
I0619 14:48:21.566270 17263 net.cpp:509] Setting up ReLU61
I0619 14:48:21.566277 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.566282 17263 net.cpp:524] Memory required for data: 2266497536
I0619 14:48:21.566285 17263 layer_factory.hpp:77] Creating layer Eltwise30_ReLU61_0_split
I0619 14:48:21.566293 17263 net.cpp:459] Creating Layer Eltwise30_ReLU61_0_split
I0619 14:48:21.566296 17263 net.cpp:886] Eltwise30_ReLU61_0_split <- Eltwise30
I0619 14:48:21.566303 17263 net.cpp:860] Eltwise30_ReLU61_0_split -> Eltwise30_ReLU61_0_split_0
I0619 14:48:21.566310 17263 net.cpp:860] Eltwise30_ReLU61_0_split -> Eltwise30_ReLU61_0_split_1
I0619 14:48:21.566362 17263 net.cpp:509] Setting up Eltwise30_ReLU61_0_split
I0619 14:48:21.566372 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.566378 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.566382 17263 net.cpp:524] Memory required for data: 2274886144
I0619 14:48:21.566386 17263 layer_factory.hpp:77] Creating layer Convolution62
I0619 14:48:21.566400 17263 net.cpp:459] Creating Layer Convolution62
I0619 14:48:21.566404 17263 net.cpp:886] Convolution62 <- Eltwise30_ReLU61_0_split_0
I0619 14:48:21.566413 17263 net.cpp:860] Convolution62 -> Convolution62
I0619 14:48:21.567091 17263 net.cpp:509] Setting up Convolution62
I0619 14:48:21.567101 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.567106 17263 net.cpp:524] Memory required for data: 2279080448
I0619 14:48:21.567116 17263 layer_factory.hpp:77] Creating layer BatchNorm62
I0619 14:48:21.567126 17263 net.cpp:459] Creating Layer BatchNorm62
I0619 14:48:21.567131 17263 net.cpp:886] BatchNorm62 <- Convolution62
I0619 14:48:21.567142 17263 net.cpp:847] BatchNorm62 -> Convolution62 (in-place)
I0619 14:48:21.567354 17263 net.cpp:509] Setting up BatchNorm62
I0619 14:48:21.567363 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.567368 17263 net.cpp:524] Memory required for data: 2283274752
I0619 14:48:21.567379 17263 layer_factory.hpp:77] Creating layer Scale62
I0619 14:48:21.567389 17263 net.cpp:459] Creating Layer Scale62
I0619 14:48:21.567397 17263 net.cpp:886] Scale62 <- Convolution62
I0619 14:48:21.567417 17263 net.cpp:847] Scale62 -> Convolution62 (in-place)
I0619 14:48:21.567457 17263 layer_factory.hpp:77] Creating layer Scale62
I0619 14:48:21.567589 17263 net.cpp:509] Setting up Scale62
I0619 14:48:21.567597 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.567601 17263 net.cpp:524] Memory required for data: 2287469056
I0619 14:48:21.567611 17263 layer_factory.hpp:77] Creating layer ReLU62
I0619 14:48:21.567618 17263 net.cpp:459] Creating Layer ReLU62
I0619 14:48:21.567623 17263 net.cpp:886] ReLU62 <- Convolution62
I0619 14:48:21.567631 17263 net.cpp:847] ReLU62 -> Convolution62 (in-place)
I0619 14:48:21.567639 17263 net.cpp:509] Setting up ReLU62
I0619 14:48:21.567646 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.567649 17263 net.cpp:524] Memory required for data: 2291663360
I0619 14:48:21.567653 17263 layer_factory.hpp:77] Creating layer Convolution63
I0619 14:48:21.567665 17263 net.cpp:459] Creating Layer Convolution63
I0619 14:48:21.567670 17263 net.cpp:886] Convolution63 <- Convolution62
I0619 14:48:21.567677 17263 net.cpp:860] Convolution63 -> Convolution63
I0619 14:48:21.568313 17263 net.cpp:509] Setting up Convolution63
I0619 14:48:21.568323 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.568327 17263 net.cpp:524] Memory required for data: 2295857664
I0619 14:48:21.568337 17263 layer_factory.hpp:77] Creating layer BatchNorm63
I0619 14:48:21.568347 17263 net.cpp:459] Creating Layer BatchNorm63
I0619 14:48:21.568352 17263 net.cpp:886] BatchNorm63 <- Convolution63
I0619 14:48:21.568361 17263 net.cpp:847] BatchNorm63 -> Convolution63 (in-place)
I0619 14:48:21.568578 17263 net.cpp:509] Setting up BatchNorm63
I0619 14:48:21.568586 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.568590 17263 net.cpp:524] Memory required for data: 2300051968
I0619 14:48:21.568601 17263 layer_factory.hpp:77] Creating layer Scale63
I0619 14:48:21.568610 17263 net.cpp:459] Creating Layer Scale63
I0619 14:48:21.568615 17263 net.cpp:886] Scale63 <- Convolution63
I0619 14:48:21.568621 17263 net.cpp:847] Scale63 -> Convolution63 (in-place)
I0619 14:48:21.568660 17263 layer_factory.hpp:77] Creating layer Scale63
I0619 14:48:21.568790 17263 net.cpp:509] Setting up Scale63
I0619 14:48:21.568799 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.568802 17263 net.cpp:524] Memory required for data: 2304246272
I0619 14:48:21.568812 17263 layer_factory.hpp:77] Creating layer Eltwise31
I0619 14:48:21.568825 17263 net.cpp:459] Creating Layer Eltwise31
I0619 14:48:21.568830 17263 net.cpp:886] Eltwise31 <- Eltwise30_ReLU61_0_split_1
I0619 14:48:21.568835 17263 net.cpp:886] Eltwise31 <- Convolution63
I0619 14:48:21.568842 17263 net.cpp:860] Eltwise31 -> Eltwise31
I0619 14:48:21.568863 17263 net.cpp:509] Setting up Eltwise31
I0619 14:48:21.568872 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.568877 17263 net.cpp:524] Memory required for data: 2308440576
I0619 14:48:21.568881 17263 layer_factory.hpp:77] Creating layer ReLU63
I0619 14:48:21.568887 17263 net.cpp:459] Creating Layer ReLU63
I0619 14:48:21.568892 17263 net.cpp:886] ReLU63 <- Eltwise31
I0619 14:48:21.568898 17263 net.cpp:847] ReLU63 -> Eltwise31 (in-place)
I0619 14:48:21.568905 17263 net.cpp:509] Setting up ReLU63
I0619 14:48:21.568910 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.568914 17263 net.cpp:524] Memory required for data: 2312634880
I0619 14:48:21.568919 17263 layer_factory.hpp:77] Creating layer Eltwise31_ReLU63_0_split
I0619 14:48:21.568924 17263 net.cpp:459] Creating Layer Eltwise31_ReLU63_0_split
I0619 14:48:21.568928 17263 net.cpp:886] Eltwise31_ReLU63_0_split <- Eltwise31
I0619 14:48:21.568938 17263 net.cpp:860] Eltwise31_ReLU63_0_split -> Eltwise31_ReLU63_0_split_0
I0619 14:48:21.568945 17263 net.cpp:860] Eltwise31_ReLU63_0_split -> Eltwise31_ReLU63_0_split_1
I0619 14:48:21.568986 17263 net.cpp:509] Setting up Eltwise31_ReLU63_0_split
I0619 14:48:21.568994 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.569015 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.569020 17263 net.cpp:524] Memory required for data: 2321023488
I0619 14:48:21.569025 17263 layer_factory.hpp:77] Creating layer Convolution64
I0619 14:48:21.569034 17263 net.cpp:459] Creating Layer Convolution64
I0619 14:48:21.569039 17263 net.cpp:886] Convolution64 <- Eltwise31_ReLU63_0_split_0
I0619 14:48:21.569047 17263 net.cpp:860] Convolution64 -> Convolution64
I0619 14:48:21.569691 17263 net.cpp:509] Setting up Convolution64
I0619 14:48:21.569701 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.569706 17263 net.cpp:524] Memory required for data: 2325217792
I0619 14:48:21.569716 17263 layer_factory.hpp:77] Creating layer BatchNorm64
I0619 14:48:21.569726 17263 net.cpp:459] Creating Layer BatchNorm64
I0619 14:48:21.569731 17263 net.cpp:886] BatchNorm64 <- Convolution64
I0619 14:48:21.569737 17263 net.cpp:847] BatchNorm64 -> Convolution64 (in-place)
I0619 14:48:21.569954 17263 net.cpp:509] Setting up BatchNorm64
I0619 14:48:21.569962 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.569967 17263 net.cpp:524] Memory required for data: 2329412096
I0619 14:48:21.569979 17263 layer_factory.hpp:77] Creating layer Scale64
I0619 14:48:21.569986 17263 net.cpp:459] Creating Layer Scale64
I0619 14:48:21.569991 17263 net.cpp:886] Scale64 <- Convolution64
I0619 14:48:21.569998 17263 net.cpp:847] Scale64 -> Convolution64 (in-place)
I0619 14:48:21.570036 17263 layer_factory.hpp:77] Creating layer Scale64
I0619 14:48:21.570164 17263 net.cpp:509] Setting up Scale64
I0619 14:48:21.570173 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.570178 17263 net.cpp:524] Memory required for data: 2333606400
I0619 14:48:21.570189 17263 layer_factory.hpp:77] Creating layer ReLU64
I0619 14:48:21.570196 17263 net.cpp:459] Creating Layer ReLU64
I0619 14:48:21.570201 17263 net.cpp:886] ReLU64 <- Convolution64
I0619 14:48:21.570209 17263 net.cpp:847] ReLU64 -> Convolution64 (in-place)
I0619 14:48:21.570216 17263 net.cpp:509] Setting up ReLU64
I0619 14:48:21.570222 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.570226 17263 net.cpp:524] Memory required for data: 2337800704
I0619 14:48:21.570230 17263 layer_factory.hpp:77] Creating layer Convolution65
I0619 14:48:21.570240 17263 net.cpp:459] Creating Layer Convolution65
I0619 14:48:21.570245 17263 net.cpp:886] Convolution65 <- Convolution64
I0619 14:48:21.570256 17263 net.cpp:860] Convolution65 -> Convolution65
I0619 14:48:21.570899 17263 net.cpp:509] Setting up Convolution65
I0619 14:48:21.570910 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.570914 17263 net.cpp:524] Memory required for data: 2341995008
I0619 14:48:21.570925 17263 layer_factory.hpp:77] Creating layer BatchNorm65
I0619 14:48:21.570932 17263 net.cpp:459] Creating Layer BatchNorm65
I0619 14:48:21.570937 17263 net.cpp:886] BatchNorm65 <- Convolution65
I0619 14:48:21.570947 17263 net.cpp:847] BatchNorm65 -> Convolution65 (in-place)
I0619 14:48:21.571162 17263 net.cpp:509] Setting up BatchNorm65
I0619 14:48:21.571171 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.571176 17263 net.cpp:524] Memory required for data: 2346189312
I0619 14:48:21.571187 17263 layer_factory.hpp:77] Creating layer Scale65
I0619 14:48:21.571195 17263 net.cpp:459] Creating Layer Scale65
I0619 14:48:21.571200 17263 net.cpp:886] Scale65 <- Convolution65
I0619 14:48:21.571207 17263 net.cpp:847] Scale65 -> Convolution65 (in-place)
I0619 14:48:21.571244 17263 layer_factory.hpp:77] Creating layer Scale65
I0619 14:48:21.571370 17263 net.cpp:509] Setting up Scale65
I0619 14:48:21.571378 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.571382 17263 net.cpp:524] Memory required for data: 2350383616
I0619 14:48:21.571393 17263 layer_factory.hpp:77] Creating layer Eltwise32
I0619 14:48:21.571403 17263 net.cpp:459] Creating Layer Eltwise32
I0619 14:48:21.571408 17263 net.cpp:886] Eltwise32 <- Eltwise31_ReLU63_0_split_1
I0619 14:48:21.571418 17263 net.cpp:886] Eltwise32 <- Convolution65
I0619 14:48:21.571437 17263 net.cpp:860] Eltwise32 -> Eltwise32
I0619 14:48:21.571461 17263 net.cpp:509] Setting up Eltwise32
I0619 14:48:21.571468 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.571472 17263 net.cpp:524] Memory required for data: 2354577920
I0619 14:48:21.571477 17263 layer_factory.hpp:77] Creating layer ReLU65
I0619 14:48:21.571486 17263 net.cpp:459] Creating Layer ReLU65
I0619 14:48:21.571491 17263 net.cpp:886] ReLU65 <- Eltwise32
I0619 14:48:21.571497 17263 net.cpp:847] ReLU65 -> Eltwise32 (in-place)
I0619 14:48:21.571504 17263 net.cpp:509] Setting up ReLU65
I0619 14:48:21.571511 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.571514 17263 net.cpp:524] Memory required for data: 2358772224
I0619 14:48:21.571518 17263 layer_factory.hpp:77] Creating layer Eltwise32_ReLU65_0_split
I0619 14:48:21.571526 17263 net.cpp:459] Creating Layer Eltwise32_ReLU65_0_split
I0619 14:48:21.571529 17263 net.cpp:886] Eltwise32_ReLU65_0_split <- Eltwise32
I0619 14:48:21.571537 17263 net.cpp:860] Eltwise32_ReLU65_0_split -> Eltwise32_ReLU65_0_split_0
I0619 14:48:21.571545 17263 net.cpp:860] Eltwise32_ReLU65_0_split -> Eltwise32_ReLU65_0_split_1
I0619 14:48:21.571585 17263 net.cpp:509] Setting up Eltwise32_ReLU65_0_split
I0619 14:48:21.571593 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.571599 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.571604 17263 net.cpp:524] Memory required for data: 2367160832
I0619 14:48:21.571607 17263 layer_factory.hpp:77] Creating layer Convolution66
I0619 14:48:21.571619 17263 net.cpp:459] Creating Layer Convolution66
I0619 14:48:21.571624 17263 net.cpp:886] Convolution66 <- Eltwise32_ReLU65_0_split_0
I0619 14:48:21.571631 17263 net.cpp:860] Convolution66 -> Convolution66
I0619 14:48:21.572934 17263 net.cpp:509] Setting up Convolution66
I0619 14:48:21.572952 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.572957 17263 net.cpp:524] Memory required for data: 2371355136
I0619 14:48:21.572968 17263 layer_factory.hpp:77] Creating layer BatchNorm66
I0619 14:48:21.572979 17263 net.cpp:459] Creating Layer BatchNorm66
I0619 14:48:21.572984 17263 net.cpp:886] BatchNorm66 <- Convolution66
I0619 14:48:21.572993 17263 net.cpp:847] BatchNorm66 -> Convolution66 (in-place)
I0619 14:48:21.573217 17263 net.cpp:509] Setting up BatchNorm66
I0619 14:48:21.573226 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.573230 17263 net.cpp:524] Memory required for data: 2375549440
I0619 14:48:21.573246 17263 layer_factory.hpp:77] Creating layer Scale66
I0619 14:48:21.573253 17263 net.cpp:459] Creating Layer Scale66
I0619 14:48:21.573257 17263 net.cpp:886] Scale66 <- Convolution66
I0619 14:48:21.573264 17263 net.cpp:847] Scale66 -> Convolution66 (in-place)
I0619 14:48:21.573305 17263 layer_factory.hpp:77] Creating layer Scale66
I0619 14:48:21.573436 17263 net.cpp:509] Setting up Scale66
I0619 14:48:21.573446 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.573449 17263 net.cpp:524] Memory required for data: 2379743744
I0619 14:48:21.573459 17263 layer_factory.hpp:77] Creating layer ReLU66
I0619 14:48:21.573468 17263 net.cpp:459] Creating Layer ReLU66
I0619 14:48:21.573473 17263 net.cpp:886] ReLU66 <- Convolution66
I0619 14:48:21.573479 17263 net.cpp:847] ReLU66 -> Convolution66 (in-place)
I0619 14:48:21.573487 17263 net.cpp:509] Setting up ReLU66
I0619 14:48:21.573493 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.573498 17263 net.cpp:524] Memory required for data: 2383938048
I0619 14:48:21.573501 17263 layer_factory.hpp:77] Creating layer Convolution67
I0619 14:48:21.573513 17263 net.cpp:459] Creating Layer Convolution67
I0619 14:48:21.573518 17263 net.cpp:886] Convolution67 <- Convolution66
I0619 14:48:21.573528 17263 net.cpp:860] Convolution67 -> Convolution67
I0619 14:48:21.574170 17263 net.cpp:509] Setting up Convolution67
I0619 14:48:21.574182 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.574188 17263 net.cpp:524] Memory required for data: 2388132352
I0619 14:48:21.574213 17263 layer_factory.hpp:77] Creating layer BatchNorm67
I0619 14:48:21.574223 17263 net.cpp:459] Creating Layer BatchNorm67
I0619 14:48:21.574228 17263 net.cpp:886] BatchNorm67 <- Convolution67
I0619 14:48:21.574237 17263 net.cpp:847] BatchNorm67 -> Convolution67 (in-place)
I0619 14:48:21.574473 17263 net.cpp:509] Setting up BatchNorm67
I0619 14:48:21.574483 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.574487 17263 net.cpp:524] Memory required for data: 2392326656
I0619 14:48:21.574501 17263 layer_factory.hpp:77] Creating layer Scale67
I0619 14:48:21.574508 17263 net.cpp:459] Creating Layer Scale67
I0619 14:48:21.574512 17263 net.cpp:886] Scale67 <- Convolution67
I0619 14:48:21.574519 17263 net.cpp:847] Scale67 -> Convolution67 (in-place)
I0619 14:48:21.574559 17263 layer_factory.hpp:77] Creating layer Scale67
I0619 14:48:21.574694 17263 net.cpp:509] Setting up Scale67
I0619 14:48:21.574703 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.574707 17263 net.cpp:524] Memory required for data: 2396520960
I0619 14:48:21.574717 17263 layer_factory.hpp:77] Creating layer Eltwise33
I0619 14:48:21.574724 17263 net.cpp:459] Creating Layer Eltwise33
I0619 14:48:21.574730 17263 net.cpp:886] Eltwise33 <- Eltwise32_ReLU65_0_split_1
I0619 14:48:21.574736 17263 net.cpp:886] Eltwise33 <- Convolution67
I0619 14:48:21.574745 17263 net.cpp:860] Eltwise33 -> Eltwise33
I0619 14:48:21.574766 17263 net.cpp:509] Setting up Eltwise33
I0619 14:48:21.574774 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.574777 17263 net.cpp:524] Memory required for data: 2400715264
I0619 14:48:21.574781 17263 layer_factory.hpp:77] Creating layer ReLU67
I0619 14:48:21.574789 17263 net.cpp:459] Creating Layer ReLU67
I0619 14:48:21.574792 17263 net.cpp:886] ReLU67 <- Eltwise33
I0619 14:48:21.574800 17263 net.cpp:847] ReLU67 -> Eltwise33 (in-place)
I0619 14:48:21.574808 17263 net.cpp:509] Setting up ReLU67
I0619 14:48:21.574815 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.574818 17263 net.cpp:524] Memory required for data: 2404909568
I0619 14:48:21.574822 17263 layer_factory.hpp:77] Creating layer Eltwise33_ReLU67_0_split
I0619 14:48:21.574828 17263 net.cpp:459] Creating Layer Eltwise33_ReLU67_0_split
I0619 14:48:21.574832 17263 net.cpp:886] Eltwise33_ReLU67_0_split <- Eltwise33
I0619 14:48:21.574838 17263 net.cpp:860] Eltwise33_ReLU67_0_split -> Eltwise33_ReLU67_0_split_0
I0619 14:48:21.574847 17263 net.cpp:860] Eltwise33_ReLU67_0_split -> Eltwise33_ReLU67_0_split_1
I0619 14:48:21.574888 17263 net.cpp:509] Setting up Eltwise33_ReLU67_0_split
I0619 14:48:21.574895 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.574901 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.574905 17263 net.cpp:524] Memory required for data: 2413298176
I0619 14:48:21.574910 17263 layer_factory.hpp:77] Creating layer Convolution68
I0619 14:48:21.574919 17263 net.cpp:459] Creating Layer Convolution68
I0619 14:48:21.574924 17263 net.cpp:886] Convolution68 <- Eltwise33_ReLU67_0_split_0
I0619 14:48:21.574934 17263 net.cpp:860] Convolution68 -> Convolution68
I0619 14:48:21.575579 17263 net.cpp:509] Setting up Convolution68
I0619 14:48:21.575588 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.575592 17263 net.cpp:524] Memory required for data: 2417492480
I0619 14:48:21.575603 17263 layer_factory.hpp:77] Creating layer BatchNorm68
I0619 14:48:21.575613 17263 net.cpp:459] Creating Layer BatchNorm68
I0619 14:48:21.575618 17263 net.cpp:886] BatchNorm68 <- Convolution68
I0619 14:48:21.575623 17263 net.cpp:847] BatchNorm68 -> Convolution68 (in-place)
I0619 14:48:21.575842 17263 net.cpp:509] Setting up BatchNorm68
I0619 14:48:21.575850 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.575855 17263 net.cpp:524] Memory required for data: 2421686784
I0619 14:48:21.575866 17263 layer_factory.hpp:77] Creating layer Scale68
I0619 14:48:21.575877 17263 net.cpp:459] Creating Layer Scale68
I0619 14:48:21.575896 17263 net.cpp:886] Scale68 <- Convolution68
I0619 14:48:21.575906 17263 net.cpp:847] Scale68 -> Convolution68 (in-place)
I0619 14:48:21.575947 17263 layer_factory.hpp:77] Creating layer Scale68
I0619 14:48:21.576081 17263 net.cpp:509] Setting up Scale68
I0619 14:48:21.576091 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.576094 17263 net.cpp:524] Memory required for data: 2425881088
I0619 14:48:21.576110 17263 layer_factory.hpp:77] Creating layer ReLU68
I0619 14:48:21.576118 17263 net.cpp:459] Creating Layer ReLU68
I0619 14:48:21.576122 17263 net.cpp:886] ReLU68 <- Convolution68
I0619 14:48:21.576128 17263 net.cpp:847] ReLU68 -> Convolution68 (in-place)
I0619 14:48:21.576136 17263 net.cpp:509] Setting up ReLU68
I0619 14:48:21.576143 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.576146 17263 net.cpp:524] Memory required for data: 2430075392
I0619 14:48:21.576150 17263 layer_factory.hpp:77] Creating layer Convolution69
I0619 14:48:21.576162 17263 net.cpp:459] Creating Layer Convolution69
I0619 14:48:21.576167 17263 net.cpp:886] Convolution69 <- Convolution68
I0619 14:48:21.576176 17263 net.cpp:860] Convolution69 -> Convolution69
I0619 14:48:21.576817 17263 net.cpp:509] Setting up Convolution69
I0619 14:48:21.576828 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.576831 17263 net.cpp:524] Memory required for data: 2434269696
I0619 14:48:21.576841 17263 layer_factory.hpp:77] Creating layer BatchNorm69
I0619 14:48:21.576851 17263 net.cpp:459] Creating Layer BatchNorm69
I0619 14:48:21.576856 17263 net.cpp:886] BatchNorm69 <- Convolution69
I0619 14:48:21.576864 17263 net.cpp:847] BatchNorm69 -> Convolution69 (in-place)
I0619 14:48:21.577081 17263 net.cpp:509] Setting up BatchNorm69
I0619 14:48:21.577090 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.577093 17263 net.cpp:524] Memory required for data: 2438464000
I0619 14:48:21.577106 17263 layer_factory.hpp:77] Creating layer Scale69
I0619 14:48:21.577113 17263 net.cpp:459] Creating Layer Scale69
I0619 14:48:21.577118 17263 net.cpp:886] Scale69 <- Convolution69
I0619 14:48:21.577126 17263 net.cpp:847] Scale69 -> Convolution69 (in-place)
I0619 14:48:21.577162 17263 layer_factory.hpp:77] Creating layer Scale69
I0619 14:48:21.577292 17263 net.cpp:509] Setting up Scale69
I0619 14:48:21.577301 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.577306 17263 net.cpp:524] Memory required for data: 2442658304
I0619 14:48:21.577316 17263 layer_factory.hpp:77] Creating layer Eltwise34
I0619 14:48:21.577322 17263 net.cpp:459] Creating Layer Eltwise34
I0619 14:48:21.577327 17263 net.cpp:886] Eltwise34 <- Eltwise33_ReLU67_0_split_1
I0619 14:48:21.577333 17263 net.cpp:886] Eltwise34 <- Convolution69
I0619 14:48:21.577342 17263 net.cpp:860] Eltwise34 -> Eltwise34
I0619 14:48:21.577363 17263 net.cpp:509] Setting up Eltwise34
I0619 14:48:21.577370 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.577374 17263 net.cpp:524] Memory required for data: 2446852608
I0619 14:48:21.577378 17263 layer_factory.hpp:77] Creating layer ReLU69
I0619 14:48:21.577388 17263 net.cpp:459] Creating Layer ReLU69
I0619 14:48:21.577391 17263 net.cpp:886] ReLU69 <- Eltwise34
I0619 14:48:21.577397 17263 net.cpp:847] ReLU69 -> Eltwise34 (in-place)
I0619 14:48:21.577404 17263 net.cpp:509] Setting up ReLU69
I0619 14:48:21.577410 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.577414 17263 net.cpp:524] Memory required for data: 2451046912
I0619 14:48:21.577419 17263 layer_factory.hpp:77] Creating layer Eltwise34_ReLU69_0_split
I0619 14:48:21.577425 17263 net.cpp:459] Creating Layer Eltwise34_ReLU69_0_split
I0619 14:48:21.577428 17263 net.cpp:886] Eltwise34_ReLU69_0_split <- Eltwise34
I0619 14:48:21.577435 17263 net.cpp:860] Eltwise34_ReLU69_0_split -> Eltwise34_ReLU69_0_split_0
I0619 14:48:21.577445 17263 net.cpp:860] Eltwise34_ReLU69_0_split -> Eltwise34_ReLU69_0_split_1
I0619 14:48:21.577483 17263 net.cpp:509] Setting up Eltwise34_ReLU69_0_split
I0619 14:48:21.577496 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.577513 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.577518 17263 net.cpp:524] Memory required for data: 2459435520
I0619 14:48:21.577523 17263 layer_factory.hpp:77] Creating layer Convolution70
I0619 14:48:21.577535 17263 net.cpp:459] Creating Layer Convolution70
I0619 14:48:21.577540 17263 net.cpp:886] Convolution70 <- Eltwise34_ReLU69_0_split_0
I0619 14:48:21.577549 17263 net.cpp:860] Convolution70 -> Convolution70
I0619 14:48:21.578202 17263 net.cpp:509] Setting up Convolution70
I0619 14:48:21.578212 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.578215 17263 net.cpp:524] Memory required for data: 2463629824
I0619 14:48:21.578225 17263 layer_factory.hpp:77] Creating layer BatchNorm70
I0619 14:48:21.578235 17263 net.cpp:459] Creating Layer BatchNorm70
I0619 14:48:21.578240 17263 net.cpp:886] BatchNorm70 <- Convolution70
I0619 14:48:21.578246 17263 net.cpp:847] BatchNorm70 -> Convolution70 (in-place)
I0619 14:48:21.578476 17263 net.cpp:509] Setting up BatchNorm70
I0619 14:48:21.578485 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.578490 17263 net.cpp:524] Memory required for data: 2467824128
I0619 14:48:21.578503 17263 layer_factory.hpp:77] Creating layer Scale70
I0619 14:48:21.578512 17263 net.cpp:459] Creating Layer Scale70
I0619 14:48:21.578518 17263 net.cpp:886] Scale70 <- Convolution70
I0619 14:48:21.578533 17263 net.cpp:847] Scale70 -> Convolution70 (in-place)
I0619 14:48:21.578572 17263 layer_factory.hpp:77] Creating layer Scale70
I0619 14:48:21.578699 17263 net.cpp:509] Setting up Scale70
I0619 14:48:21.578707 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.578711 17263 net.cpp:524] Memory required for data: 2472018432
I0619 14:48:21.578722 17263 layer_factory.hpp:77] Creating layer ReLU70
I0619 14:48:21.578729 17263 net.cpp:459] Creating Layer ReLU70
I0619 14:48:21.578734 17263 net.cpp:886] ReLU70 <- Convolution70
I0619 14:48:21.578740 17263 net.cpp:847] ReLU70 -> Convolution70 (in-place)
I0619 14:48:21.578747 17263 net.cpp:509] Setting up ReLU70
I0619 14:48:21.578752 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.578757 17263 net.cpp:524] Memory required for data: 2476212736
I0619 14:48:21.578760 17263 layer_factory.hpp:77] Creating layer Convolution71
I0619 14:48:21.578773 17263 net.cpp:459] Creating Layer Convolution71
I0619 14:48:21.578778 17263 net.cpp:886] Convolution71 <- Convolution70
I0619 14:48:21.578784 17263 net.cpp:860] Convolution71 -> Convolution71
I0619 14:48:21.579404 17263 net.cpp:509] Setting up Convolution71
I0619 14:48:21.579414 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.579418 17263 net.cpp:524] Memory required for data: 2480407040
I0619 14:48:21.579428 17263 layer_factory.hpp:77] Creating layer BatchNorm71
I0619 14:48:21.579437 17263 net.cpp:459] Creating Layer BatchNorm71
I0619 14:48:21.579442 17263 net.cpp:886] BatchNorm71 <- Convolution71
I0619 14:48:21.579448 17263 net.cpp:847] BatchNorm71 -> Convolution71 (in-place)
I0619 14:48:21.579661 17263 net.cpp:509] Setting up BatchNorm71
I0619 14:48:21.579669 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.579674 17263 net.cpp:524] Memory required for data: 2484601344
I0619 14:48:21.579686 17263 layer_factory.hpp:77] Creating layer Scale71
I0619 14:48:21.579694 17263 net.cpp:459] Creating Layer Scale71
I0619 14:48:21.579699 17263 net.cpp:886] Scale71 <- Convolution71
I0619 14:48:21.579704 17263 net.cpp:847] Scale71 -> Convolution71 (in-place)
I0619 14:48:21.579743 17263 layer_factory.hpp:77] Creating layer Scale71
I0619 14:48:21.579870 17263 net.cpp:509] Setting up Scale71
I0619 14:48:21.579879 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.579882 17263 net.cpp:524] Memory required for data: 2488795648
I0619 14:48:21.579895 17263 layer_factory.hpp:77] Creating layer Eltwise35
I0619 14:48:21.579901 17263 net.cpp:459] Creating Layer Eltwise35
I0619 14:48:21.579910 17263 net.cpp:886] Eltwise35 <- Eltwise34_ReLU69_0_split_1
I0619 14:48:21.579928 17263 net.cpp:886] Eltwise35 <- Convolution71
I0619 14:48:21.579938 17263 net.cpp:860] Eltwise35 -> Eltwise35
I0619 14:48:21.579960 17263 net.cpp:509] Setting up Eltwise35
I0619 14:48:21.579968 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.579972 17263 net.cpp:524] Memory required for data: 2492989952
I0619 14:48:21.579977 17263 layer_factory.hpp:77] Creating layer ReLU71
I0619 14:48:21.579982 17263 net.cpp:459] Creating Layer ReLU71
I0619 14:48:21.579987 17263 net.cpp:886] ReLU71 <- Eltwise35
I0619 14:48:21.579994 17263 net.cpp:847] ReLU71 -> Eltwise35 (in-place)
I0619 14:48:21.580001 17263 net.cpp:509] Setting up ReLU71
I0619 14:48:21.580006 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.580010 17263 net.cpp:524] Memory required for data: 2497184256
I0619 14:48:21.580014 17263 layer_factory.hpp:77] Creating layer Eltwise35_ReLU71_0_split
I0619 14:48:21.580020 17263 net.cpp:459] Creating Layer Eltwise35_ReLU71_0_split
I0619 14:48:21.580024 17263 net.cpp:886] Eltwise35_ReLU71_0_split <- Eltwise35
I0619 14:48:21.580030 17263 net.cpp:860] Eltwise35_ReLU71_0_split -> Eltwise35_ReLU71_0_split_0
I0619 14:48:21.580037 17263 net.cpp:860] Eltwise35_ReLU71_0_split -> Eltwise35_ReLU71_0_split_1
I0619 14:48:21.580078 17263 net.cpp:509] Setting up Eltwise35_ReLU71_0_split
I0619 14:48:21.580085 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.580090 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.580095 17263 net.cpp:524] Memory required for data: 2505572864
I0619 14:48:21.580098 17263 layer_factory.hpp:77] Creating layer Convolution72
I0619 14:48:21.580108 17263 net.cpp:459] Creating Layer Convolution72
I0619 14:48:21.580112 17263 net.cpp:886] Convolution72 <- Eltwise35_ReLU71_0_split_0
I0619 14:48:21.580121 17263 net.cpp:860] Convolution72 -> Convolution72
I0619 14:48:21.580742 17263 net.cpp:509] Setting up Convolution72
I0619 14:48:21.580752 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.580756 17263 net.cpp:524] Memory required for data: 2509767168
I0619 14:48:21.580766 17263 layer_factory.hpp:77] Creating layer BatchNorm72
I0619 14:48:21.580775 17263 net.cpp:459] Creating Layer BatchNorm72
I0619 14:48:21.580778 17263 net.cpp:886] BatchNorm72 <- Convolution72
I0619 14:48:21.580786 17263 net.cpp:847] BatchNorm72 -> Convolution72 (in-place)
I0619 14:48:21.580999 17263 net.cpp:509] Setting up BatchNorm72
I0619 14:48:21.581007 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.581012 17263 net.cpp:524] Memory required for data: 2513961472
I0619 14:48:21.581023 17263 layer_factory.hpp:77] Creating layer Scale72
I0619 14:48:21.581030 17263 net.cpp:459] Creating Layer Scale72
I0619 14:48:21.581034 17263 net.cpp:886] Scale72 <- Convolution72
I0619 14:48:21.581040 17263 net.cpp:847] Scale72 -> Convolution72 (in-place)
I0619 14:48:21.581079 17263 layer_factory.hpp:77] Creating layer Scale72
I0619 14:48:21.581208 17263 net.cpp:509] Setting up Scale72
I0619 14:48:21.581217 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.581220 17263 net.cpp:524] Memory required for data: 2518155776
I0619 14:48:21.581230 17263 layer_factory.hpp:77] Creating layer ReLU72
I0619 14:48:21.581238 17263 net.cpp:459] Creating Layer ReLU72
I0619 14:48:21.581243 17263 net.cpp:886] ReLU72 <- Convolution72
I0619 14:48:21.581249 17263 net.cpp:847] ReLU72 -> Convolution72 (in-place)
I0619 14:48:21.581256 17263 net.cpp:509] Setting up ReLU72
I0619 14:48:21.581262 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.581266 17263 net.cpp:524] Memory required for data: 2522350080
I0619 14:48:21.581270 17263 layer_factory.hpp:77] Creating layer Convolution73
I0619 14:48:21.581281 17263 net.cpp:459] Creating Layer Convolution73
I0619 14:48:21.581285 17263 net.cpp:886] Convolution73 <- Convolution72
I0619 14:48:21.581292 17263 net.cpp:860] Convolution73 -> Convolution73
I0619 14:48:21.581907 17263 net.cpp:509] Setting up Convolution73
I0619 14:48:21.581919 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.581935 17263 net.cpp:524] Memory required for data: 2526544384
I0619 14:48:21.581946 17263 layer_factory.hpp:77] Creating layer BatchNorm73
I0619 14:48:21.581956 17263 net.cpp:459] Creating Layer BatchNorm73
I0619 14:48:21.581961 17263 net.cpp:886] BatchNorm73 <- Convolution73
I0619 14:48:21.581967 17263 net.cpp:847] BatchNorm73 -> Convolution73 (in-place)
I0619 14:48:21.582180 17263 net.cpp:509] Setting up BatchNorm73
I0619 14:48:21.582190 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.582193 17263 net.cpp:524] Memory required for data: 2530738688
I0619 14:48:21.582206 17263 layer_factory.hpp:77] Creating layer Scale73
I0619 14:48:21.582212 17263 net.cpp:459] Creating Layer Scale73
I0619 14:48:21.582216 17263 net.cpp:886] Scale73 <- Convolution73
I0619 14:48:21.582224 17263 net.cpp:847] Scale73 -> Convolution73 (in-place)
I0619 14:48:21.582260 17263 layer_factory.hpp:77] Creating layer Scale73
I0619 14:48:21.582391 17263 net.cpp:509] Setting up Scale73
I0619 14:48:21.582402 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.582406 17263 net.cpp:524] Memory required for data: 2534932992
I0619 14:48:21.582417 17263 layer_factory.hpp:77] Creating layer Eltwise36
I0619 14:48:21.582423 17263 net.cpp:459] Creating Layer Eltwise36
I0619 14:48:21.582428 17263 net.cpp:886] Eltwise36 <- Eltwise35_ReLU71_0_split_1
I0619 14:48:21.582434 17263 net.cpp:886] Eltwise36 <- Convolution73
I0619 14:48:21.582440 17263 net.cpp:860] Eltwise36 -> Eltwise36
I0619 14:48:21.582466 17263 net.cpp:509] Setting up Eltwise36
I0619 14:48:21.582473 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.582478 17263 net.cpp:524] Memory required for data: 2539127296
I0619 14:48:21.582481 17263 layer_factory.hpp:77] Creating layer ReLU73
I0619 14:48:21.582487 17263 net.cpp:459] Creating Layer ReLU73
I0619 14:48:21.582492 17263 net.cpp:886] ReLU73 <- Eltwise36
I0619 14:48:21.582499 17263 net.cpp:847] ReLU73 -> Eltwise36 (in-place)
I0619 14:48:21.582507 17263 net.cpp:509] Setting up ReLU73
I0619 14:48:21.582512 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.582516 17263 net.cpp:524] Memory required for data: 2543321600
I0619 14:48:21.582520 17263 layer_factory.hpp:77] Creating layer Eltwise36_ReLU73_0_split
I0619 14:48:21.582526 17263 net.cpp:459] Creating Layer Eltwise36_ReLU73_0_split
I0619 14:48:21.582530 17263 net.cpp:886] Eltwise36_ReLU73_0_split <- Eltwise36
I0619 14:48:21.582536 17263 net.cpp:860] Eltwise36_ReLU73_0_split -> Eltwise36_ReLU73_0_split_0
I0619 14:48:21.582543 17263 net.cpp:860] Eltwise36_ReLU73_0_split -> Eltwise36_ReLU73_0_split_1
I0619 14:48:21.582584 17263 net.cpp:509] Setting up Eltwise36_ReLU73_0_split
I0619 14:48:21.582592 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.582597 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.582600 17263 net.cpp:524] Memory required for data: 2551710208
I0619 14:48:21.582604 17263 layer_factory.hpp:77] Creating layer Pooling2
I0619 14:48:21.582612 17263 net.cpp:459] Creating Layer Pooling2
I0619 14:48:21.582617 17263 net.cpp:886] Pooling2 <- Eltwise36_ReLU73_0_split_0
I0619 14:48:21.582624 17263 net.cpp:860] Pooling2 -> Pooling2
I0619 14:48:21.582649 17263 net.cpp:509] Setting up Pooling2
I0619 14:48:21.582656 17263 net.cpp:516] Top shape: 128 32 8 8 (262144)
I0619 14:48:21.582660 17263 net.cpp:524] Memory required for data: 2552758784
I0619 14:48:21.582664 17263 layer_factory.hpp:77] Creating layer Input2
I0619 14:48:21.582671 17263 net.cpp:459] Creating Layer Input2
I0619 14:48:21.582680 17263 net.cpp:860] Input2 -> Input2
I0619 14:48:21.582706 17263 net.cpp:509] Setting up Input2
I0619 14:48:21.582715 17263 net.cpp:516] Top shape: 128 32 8 8 (262144)
I0619 14:48:21.582720 17263 net.cpp:524] Memory required for data: 2553807360
I0619 14:48:21.582723 17263 layer_factory.hpp:77] Creating layer Concat2
I0619 14:48:21.582731 17263 net.cpp:459] Creating Layer Concat2
I0619 14:48:21.582734 17263 net.cpp:886] Concat2 <- Pooling2
I0619 14:48:21.582743 17263 net.cpp:886] Concat2 <- Input2
I0619 14:48:21.582765 17263 net.cpp:860] Concat2 -> Concat2
I0619 14:48:21.582798 17263 net.cpp:509] Setting up Concat2
I0619 14:48:21.582804 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.582808 17263 net.cpp:524] Memory required for data: 2555904512
I0619 14:48:21.582813 17263 layer_factory.hpp:77] Creating layer Convolution74
I0619 14:48:21.582825 17263 net.cpp:459] Creating Layer Convolution74
I0619 14:48:21.582830 17263 net.cpp:886] Convolution74 <- Eltwise36_ReLU73_0_split_1
I0619 14:48:21.582839 17263 net.cpp:860] Convolution74 -> Convolution74
I0619 14:48:21.584451 17263 net.cpp:509] Setting up Convolution74
I0619 14:48:21.584467 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.584471 17263 net.cpp:524] Memory required for data: 2558001664
I0619 14:48:21.584537 17263 layer_factory.hpp:77] Creating layer BatchNorm74
I0619 14:48:21.584549 17263 net.cpp:459] Creating Layer BatchNorm74
I0619 14:48:21.584554 17263 net.cpp:886] BatchNorm74 <- Convolution74
I0619 14:48:21.584561 17263 net.cpp:847] BatchNorm74 -> Convolution74 (in-place)
I0619 14:48:21.584791 17263 net.cpp:509] Setting up BatchNorm74
I0619 14:48:21.584800 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.584805 17263 net.cpp:524] Memory required for data: 2560098816
I0619 14:48:21.584820 17263 layer_factory.hpp:77] Creating layer Scale74
I0619 14:48:21.584827 17263 net.cpp:459] Creating Layer Scale74
I0619 14:48:21.584831 17263 net.cpp:886] Scale74 <- Convolution74
I0619 14:48:21.584837 17263 net.cpp:847] Scale74 -> Convolution74 (in-place)
I0619 14:48:21.584880 17263 layer_factory.hpp:77] Creating layer Scale74
I0619 14:48:21.585017 17263 net.cpp:509] Setting up Scale74
I0619 14:48:21.585026 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.585031 17263 net.cpp:524] Memory required for data: 2562195968
I0619 14:48:21.585041 17263 layer_factory.hpp:77] Creating layer ReLU74
I0619 14:48:21.585047 17263 net.cpp:459] Creating Layer ReLU74
I0619 14:48:21.585052 17263 net.cpp:886] ReLU74 <- Convolution74
I0619 14:48:21.585060 17263 net.cpp:847] ReLU74 -> Convolution74 (in-place)
I0619 14:48:21.585067 17263 net.cpp:509] Setting up ReLU74
I0619 14:48:21.585073 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.585078 17263 net.cpp:524] Memory required for data: 2564293120
I0619 14:48:21.585081 17263 layer_factory.hpp:77] Creating layer Convolution75
I0619 14:48:21.585091 17263 net.cpp:459] Creating Layer Convolution75
I0619 14:48:21.585095 17263 net.cpp:886] Convolution75 <- Convolution74
I0619 14:48:21.585108 17263 net.cpp:860] Convolution75 -> Convolution75
I0619 14:48:21.586801 17263 net.cpp:509] Setting up Convolution75
I0619 14:48:21.586812 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.586817 17263 net.cpp:524] Memory required for data: 2566390272
I0619 14:48:21.586827 17263 layer_factory.hpp:77] Creating layer BatchNorm75
I0619 14:48:21.586833 17263 net.cpp:459] Creating Layer BatchNorm75
I0619 14:48:21.586838 17263 net.cpp:886] BatchNorm75 <- Convolution75
I0619 14:48:21.586848 17263 net.cpp:847] BatchNorm75 -> Convolution75 (in-place)
I0619 14:48:21.587069 17263 net.cpp:509] Setting up BatchNorm75
I0619 14:48:21.587077 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.587081 17263 net.cpp:524] Memory required for data: 2568487424
I0619 14:48:21.587093 17263 layer_factory.hpp:77] Creating layer Scale75
I0619 14:48:21.587101 17263 net.cpp:459] Creating Layer Scale75
I0619 14:48:21.587105 17263 net.cpp:886] Scale75 <- Convolution75
I0619 14:48:21.587113 17263 net.cpp:847] Scale75 -> Convolution75 (in-place)
I0619 14:48:21.587152 17263 layer_factory.hpp:77] Creating layer Scale75
I0619 14:48:21.587285 17263 net.cpp:509] Setting up Scale75
I0619 14:48:21.587294 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.587297 17263 net.cpp:524] Memory required for data: 2570584576
I0619 14:48:21.587307 17263 layer_factory.hpp:77] Creating layer Eltwise37
I0619 14:48:21.587318 17263 net.cpp:459] Creating Layer Eltwise37
I0619 14:48:21.587337 17263 net.cpp:886] Eltwise37 <- Concat2
I0619 14:48:21.587345 17263 net.cpp:886] Eltwise37 <- Convolution75
I0619 14:48:21.587353 17263 net.cpp:860] Eltwise37 -> Eltwise37
I0619 14:48:21.587376 17263 net.cpp:509] Setting up Eltwise37
I0619 14:48:21.587386 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.587390 17263 net.cpp:524] Memory required for data: 2572681728
I0619 14:48:21.587395 17263 layer_factory.hpp:77] Creating layer ReLU75
I0619 14:48:21.587401 17263 net.cpp:459] Creating Layer ReLU75
I0619 14:48:21.587405 17263 net.cpp:886] ReLU75 <- Eltwise37
I0619 14:48:21.587411 17263 net.cpp:847] ReLU75 -> Eltwise37 (in-place)
I0619 14:48:21.587419 17263 net.cpp:509] Setting up ReLU75
I0619 14:48:21.587424 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.587427 17263 net.cpp:524] Memory required for data: 2574778880
I0619 14:48:21.587431 17263 layer_factory.hpp:77] Creating layer Eltwise37_ReLU75_0_split
I0619 14:48:21.587437 17263 net.cpp:459] Creating Layer Eltwise37_ReLU75_0_split
I0619 14:48:21.587441 17263 net.cpp:886] Eltwise37_ReLU75_0_split <- Eltwise37
I0619 14:48:21.587450 17263 net.cpp:860] Eltwise37_ReLU75_0_split -> Eltwise37_ReLU75_0_split_0
I0619 14:48:21.587458 17263 net.cpp:860] Eltwise37_ReLU75_0_split -> Eltwise37_ReLU75_0_split_1
I0619 14:48:21.587496 17263 net.cpp:509] Setting up Eltwise37_ReLU75_0_split
I0619 14:48:21.587503 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.587509 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.587513 17263 net.cpp:524] Memory required for data: 2578973184
I0619 14:48:21.587517 17263 layer_factory.hpp:77] Creating layer Convolution76
I0619 14:48:21.587529 17263 net.cpp:459] Creating Layer Convolution76
I0619 14:48:21.587534 17263 net.cpp:886] Convolution76 <- Eltwise37_ReLU75_0_split_0
I0619 14:48:21.587541 17263 net.cpp:860] Convolution76 -> Convolution76
I0619 14:48:21.589233 17263 net.cpp:509] Setting up Convolution76
I0619 14:48:21.589243 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.589247 17263 net.cpp:524] Memory required for data: 2581070336
I0619 14:48:21.589257 17263 layer_factory.hpp:77] Creating layer BatchNorm76
I0619 14:48:21.589268 17263 net.cpp:459] Creating Layer BatchNorm76
I0619 14:48:21.589273 17263 net.cpp:886] BatchNorm76 <- Convolution76
I0619 14:48:21.589279 17263 net.cpp:847] BatchNorm76 -> Convolution76 (in-place)
I0619 14:48:21.589526 17263 net.cpp:509] Setting up BatchNorm76
I0619 14:48:21.589536 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.589540 17263 net.cpp:524] Memory required for data: 2583167488
I0619 14:48:21.589552 17263 layer_factory.hpp:77] Creating layer Scale76
I0619 14:48:21.589560 17263 net.cpp:459] Creating Layer Scale76
I0619 14:48:21.589565 17263 net.cpp:886] Scale76 <- Convolution76
I0619 14:48:21.589571 17263 net.cpp:847] Scale76 -> Convolution76 (in-place)
I0619 14:48:21.589615 17263 layer_factory.hpp:77] Creating layer Scale76
I0619 14:48:21.589748 17263 net.cpp:509] Setting up Scale76
I0619 14:48:21.589758 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.589762 17263 net.cpp:524] Memory required for data: 2585264640
I0619 14:48:21.589773 17263 layer_factory.hpp:77] Creating layer ReLU76
I0619 14:48:21.589779 17263 net.cpp:459] Creating Layer ReLU76
I0619 14:48:21.589788 17263 net.cpp:886] ReLU76 <- Convolution76
I0619 14:48:21.589794 17263 net.cpp:847] ReLU76 -> Convolution76 (in-place)
I0619 14:48:21.589802 17263 net.cpp:509] Setting up ReLU76
I0619 14:48:21.589807 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.589812 17263 net.cpp:524] Memory required for data: 2587361792
I0619 14:48:21.589815 17263 layer_factory.hpp:77] Creating layer Convolution77
I0619 14:48:21.589828 17263 net.cpp:459] Creating Layer Convolution77
I0619 14:48:21.589831 17263 net.cpp:886] Convolution77 <- Convolution76
I0619 14:48:21.589840 17263 net.cpp:860] Convolution77 -> Convolution77
I0619 14:48:21.591509 17263 net.cpp:509] Setting up Convolution77
I0619 14:48:21.591522 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.591539 17263 net.cpp:524] Memory required for data: 2589458944
I0619 14:48:21.591549 17263 layer_factory.hpp:77] Creating layer BatchNorm77
I0619 14:48:21.591559 17263 net.cpp:459] Creating Layer BatchNorm77
I0619 14:48:21.591564 17263 net.cpp:886] BatchNorm77 <- Convolution77
I0619 14:48:21.591572 17263 net.cpp:847] BatchNorm77 -> Convolution77 (in-place)
I0619 14:48:21.591789 17263 net.cpp:509] Setting up BatchNorm77
I0619 14:48:21.591796 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.591799 17263 net.cpp:524] Memory required for data: 2591556096
I0619 14:48:21.591811 17263 layer_factory.hpp:77] Creating layer Scale77
I0619 14:48:21.591820 17263 net.cpp:459] Creating Layer Scale77
I0619 14:48:21.591825 17263 net.cpp:886] Scale77 <- Convolution77
I0619 14:48:21.591830 17263 net.cpp:847] Scale77 -> Convolution77 (in-place)
I0619 14:48:21.591868 17263 layer_factory.hpp:77] Creating layer Scale77
I0619 14:48:21.591995 17263 net.cpp:509] Setting up Scale77
I0619 14:48:21.592001 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.592005 17263 net.cpp:524] Memory required for data: 2593653248
I0619 14:48:21.592016 17263 layer_factory.hpp:77] Creating layer Eltwise38
I0619 14:48:21.592023 17263 net.cpp:459] Creating Layer Eltwise38
I0619 14:48:21.592028 17263 net.cpp:886] Eltwise38 <- Eltwise37_ReLU75_0_split_1
I0619 14:48:21.592034 17263 net.cpp:886] Eltwise38 <- Convolution77
I0619 14:48:21.592042 17263 net.cpp:860] Eltwise38 -> Eltwise38
I0619 14:48:21.592062 17263 net.cpp:509] Setting up Eltwise38
I0619 14:48:21.592068 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.592072 17263 net.cpp:524] Memory required for data: 2595750400
I0619 14:48:21.592077 17263 layer_factory.hpp:77] Creating layer ReLU77
I0619 14:48:21.592082 17263 net.cpp:459] Creating Layer ReLU77
I0619 14:48:21.592087 17263 net.cpp:886] ReLU77 <- Eltwise38
I0619 14:48:21.592094 17263 net.cpp:847] ReLU77 -> Eltwise38 (in-place)
I0619 14:48:21.592102 17263 net.cpp:509] Setting up ReLU77
I0619 14:48:21.592106 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.592110 17263 net.cpp:524] Memory required for data: 2597847552
I0619 14:48:21.592114 17263 layer_factory.hpp:77] Creating layer Eltwise38_ReLU77_0_split
I0619 14:48:21.592119 17263 net.cpp:459] Creating Layer Eltwise38_ReLU77_0_split
I0619 14:48:21.592123 17263 net.cpp:886] Eltwise38_ReLU77_0_split <- Eltwise38
I0619 14:48:21.592129 17263 net.cpp:860] Eltwise38_ReLU77_0_split -> Eltwise38_ReLU77_0_split_0
I0619 14:48:21.592136 17263 net.cpp:860] Eltwise38_ReLU77_0_split -> Eltwise38_ReLU77_0_split_1
I0619 14:48:21.592175 17263 net.cpp:509] Setting up Eltwise38_ReLU77_0_split
I0619 14:48:21.592182 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.592187 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.592190 17263 net.cpp:524] Memory required for data: 2602041856
I0619 14:48:21.592195 17263 layer_factory.hpp:77] Creating layer Convolution78
I0619 14:48:21.592205 17263 net.cpp:459] Creating Layer Convolution78
I0619 14:48:21.592208 17263 net.cpp:886] Convolution78 <- Eltwise38_ReLU77_0_split_0
I0619 14:48:21.592217 17263 net.cpp:860] Convolution78 -> Convolution78
I0619 14:48:21.593834 17263 net.cpp:509] Setting up Convolution78
I0619 14:48:21.593843 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.593847 17263 net.cpp:524] Memory required for data: 2604139008
I0619 14:48:21.593858 17263 layer_factory.hpp:77] Creating layer BatchNorm78
I0619 14:48:21.593864 17263 net.cpp:459] Creating Layer BatchNorm78
I0619 14:48:21.593869 17263 net.cpp:886] BatchNorm78 <- Convolution78
I0619 14:48:21.593878 17263 net.cpp:847] BatchNorm78 -> Convolution78 (in-place)
I0619 14:48:21.594090 17263 net.cpp:509] Setting up BatchNorm78
I0619 14:48:21.594097 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.594101 17263 net.cpp:524] Memory required for data: 2606236160
I0619 14:48:21.594113 17263 layer_factory.hpp:77] Creating layer Scale78
I0619 14:48:21.594123 17263 net.cpp:459] Creating Layer Scale78
I0619 14:48:21.594141 17263 net.cpp:886] Scale78 <- Convolution78
I0619 14:48:21.594149 17263 net.cpp:847] Scale78 -> Convolution78 (in-place)
I0619 14:48:21.594188 17263 layer_factory.hpp:77] Creating layer Scale78
I0619 14:48:21.594317 17263 net.cpp:509] Setting up Scale78
I0619 14:48:21.594326 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.594329 17263 net.cpp:524] Memory required for data: 2608333312
I0619 14:48:21.594339 17263 layer_factory.hpp:77] Creating layer ReLU78
I0619 14:48:21.594346 17263 net.cpp:459] Creating Layer ReLU78
I0619 14:48:21.594350 17263 net.cpp:886] ReLU78 <- Convolution78
I0619 14:48:21.594363 17263 net.cpp:847] ReLU78 -> Convolution78 (in-place)
I0619 14:48:21.594372 17263 net.cpp:509] Setting up ReLU78
I0619 14:48:21.594377 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.594380 17263 net.cpp:524] Memory required for data: 2610430464
I0619 14:48:21.594384 17263 layer_factory.hpp:77] Creating layer Convolution79
I0619 14:48:21.594396 17263 net.cpp:459] Creating Layer Convolution79
I0619 14:48:21.594400 17263 net.cpp:886] Convolution79 <- Convolution78
I0619 14:48:21.594406 17263 net.cpp:860] Convolution79 -> Convolution79
I0619 14:48:21.596024 17263 net.cpp:509] Setting up Convolution79
I0619 14:48:21.596032 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.596036 17263 net.cpp:524] Memory required for data: 2612527616
I0619 14:48:21.596046 17263 layer_factory.hpp:77] Creating layer BatchNorm79
I0619 14:48:21.596057 17263 net.cpp:459] Creating Layer BatchNorm79
I0619 14:48:21.596061 17263 net.cpp:886] BatchNorm79 <- Convolution79
I0619 14:48:21.596067 17263 net.cpp:847] BatchNorm79 -> Convolution79 (in-place)
I0619 14:48:21.596281 17263 net.cpp:509] Setting up BatchNorm79
I0619 14:48:21.596287 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.596292 17263 net.cpp:524] Memory required for data: 2614624768
I0619 14:48:21.596302 17263 layer_factory.hpp:77] Creating layer Scale79
I0619 14:48:21.596309 17263 net.cpp:459] Creating Layer Scale79
I0619 14:48:21.596313 17263 net.cpp:886] Scale79 <- Convolution79
I0619 14:48:21.596319 17263 net.cpp:847] Scale79 -> Convolution79 (in-place)
I0619 14:48:21.596359 17263 layer_factory.hpp:77] Creating layer Scale79
I0619 14:48:21.596484 17263 net.cpp:509] Setting up Scale79
I0619 14:48:21.596493 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.596496 17263 net.cpp:524] Memory required for data: 2616721920
I0619 14:48:21.596505 17263 layer_factory.hpp:77] Creating layer Eltwise39
I0619 14:48:21.596514 17263 net.cpp:459] Creating Layer Eltwise39
I0619 14:48:21.596519 17263 net.cpp:886] Eltwise39 <- Eltwise38_ReLU77_0_split_1
I0619 14:48:21.596524 17263 net.cpp:886] Eltwise39 <- Convolution79
I0619 14:48:21.596530 17263 net.cpp:860] Eltwise39 -> Eltwise39
I0619 14:48:21.596550 17263 net.cpp:509] Setting up Eltwise39
I0619 14:48:21.596557 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.596560 17263 net.cpp:524] Memory required for data: 2618819072
I0619 14:48:21.596566 17263 layer_factory.hpp:77] Creating layer ReLU79
I0619 14:48:21.596575 17263 net.cpp:459] Creating Layer ReLU79
I0619 14:48:21.596580 17263 net.cpp:886] ReLU79 <- Eltwise39
I0619 14:48:21.596585 17263 net.cpp:847] ReLU79 -> Eltwise39 (in-place)
I0619 14:48:21.596591 17263 net.cpp:509] Setting up ReLU79
I0619 14:48:21.596596 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.596601 17263 net.cpp:524] Memory required for data: 2620916224
I0619 14:48:21.596604 17263 layer_factory.hpp:77] Creating layer Eltwise39_ReLU79_0_split
I0619 14:48:21.596611 17263 net.cpp:459] Creating Layer Eltwise39_ReLU79_0_split
I0619 14:48:21.596616 17263 net.cpp:886] Eltwise39_ReLU79_0_split <- Eltwise39
I0619 14:48:21.596621 17263 net.cpp:860] Eltwise39_ReLU79_0_split -> Eltwise39_ReLU79_0_split_0
I0619 14:48:21.596628 17263 net.cpp:860] Eltwise39_ReLU79_0_split -> Eltwise39_ReLU79_0_split_1
I0619 14:48:21.596668 17263 net.cpp:509] Setting up Eltwise39_ReLU79_0_split
I0619 14:48:21.596689 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.596694 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.596698 17263 net.cpp:524] Memory required for data: 2625110528
I0619 14:48:21.596703 17263 layer_factory.hpp:77] Creating layer Convolution80
I0619 14:48:21.596714 17263 net.cpp:459] Creating Layer Convolution80
I0619 14:48:21.596719 17263 net.cpp:886] Convolution80 <- Eltwise39_ReLU79_0_split_0
I0619 14:48:21.596726 17263 net.cpp:860] Convolution80 -> Convolution80
I0619 14:48:21.598351 17263 net.cpp:509] Setting up Convolution80
I0619 14:48:21.598366 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.598371 17263 net.cpp:524] Memory required for data: 2627207680
I0619 14:48:21.598381 17263 layer_factory.hpp:77] Creating layer BatchNorm80
I0619 14:48:21.598423 17263 net.cpp:459] Creating Layer BatchNorm80
I0619 14:48:21.598469 17263 net.cpp:886] BatchNorm80 <- Convolution80
I0619 14:48:21.598496 17263 net.cpp:847] BatchNorm80 -> Convolution80 (in-place)
I0619 14:48:21.598943 17263 net.cpp:509] Setting up BatchNorm80
I0619 14:48:21.598961 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.598969 17263 net.cpp:524] Memory required for data: 2629304832
I0619 14:48:21.598997 17263 layer_factory.hpp:77] Creating layer Scale80
I0619 14:48:21.599016 17263 net.cpp:459] Creating Layer Scale80
I0619 14:48:21.599025 17263 net.cpp:886] Scale80 <- Convolution80
I0619 14:48:21.599035 17263 net.cpp:847] Scale80 -> Convolution80 (in-place)
I0619 14:48:21.599112 17263 layer_factory.hpp:77] Creating layer Scale80
I0619 14:48:21.599339 17263 net.cpp:509] Setting up Scale80
I0619 14:48:21.599352 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.599359 17263 net.cpp:524] Memory required for data: 2631401984
I0619 14:48:21.599380 17263 layer_factory.hpp:77] Creating layer ReLU80
I0619 14:48:21.599392 17263 net.cpp:459] Creating Layer ReLU80
I0619 14:48:21.599401 17263 net.cpp:886] ReLU80 <- Convolution80
I0619 14:48:21.599411 17263 net.cpp:847] ReLU80 -> Convolution80 (in-place)
I0619 14:48:21.599427 17263 net.cpp:509] Setting up ReLU80
I0619 14:48:21.599437 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.599443 17263 net.cpp:524] Memory required for data: 2633499136
I0619 14:48:21.599450 17263 layer_factory.hpp:77] Creating layer Convolution81
I0619 14:48:21.599468 17263 net.cpp:459] Creating Layer Convolution81
I0619 14:48:21.599477 17263 net.cpp:886] Convolution81 <- Convolution80
I0619 14:48:21.599491 17263 net.cpp:860] Convolution81 -> Convolution81
I0619 14:48:21.603430 17263 net.cpp:509] Setting up Convolution81
I0619 14:48:21.603458 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.603466 17263 net.cpp:524] Memory required for data: 2635596288
I0619 14:48:21.603487 17263 layer_factory.hpp:77] Creating layer BatchNorm81
I0619 14:48:21.603507 17263 net.cpp:459] Creating Layer BatchNorm81
I0619 14:48:21.603518 17263 net.cpp:886] BatchNorm81 <- Convolution81
I0619 14:48:21.603533 17263 net.cpp:847] BatchNorm81 -> Convolution81 (in-place)
I0619 14:48:21.603943 17263 net.cpp:509] Setting up BatchNorm81
I0619 14:48:21.603960 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.603967 17263 net.cpp:524] Memory required for data: 2637693440
I0619 14:48:21.603996 17263 layer_factory.hpp:77] Creating layer Scale81
I0619 14:48:21.604012 17263 net.cpp:459] Creating Layer Scale81
I0619 14:48:21.604019 17263 net.cpp:886] Scale81 <- Convolution81
I0619 14:48:21.604032 17263 net.cpp:847] Scale81 -> Convolution81 (in-place)
I0619 14:48:21.604105 17263 layer_factory.hpp:77] Creating layer Scale81
I0619 14:48:21.604344 17263 net.cpp:509] Setting up Scale81
I0619 14:48:21.604358 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.604365 17263 net.cpp:524] Memory required for data: 2639790592
I0619 14:48:21.604387 17263 layer_factory.hpp:77] Creating layer Eltwise40
I0619 14:48:21.604401 17263 net.cpp:459] Creating Layer Eltwise40
I0619 14:48:21.604419 17263 net.cpp:886] Eltwise40 <- Eltwise39_ReLU79_0_split_1
I0619 14:48:21.604467 17263 net.cpp:886] Eltwise40 <- Convolution81
I0619 14:48:21.604486 17263 net.cpp:860] Eltwise40 -> Eltwise40
I0619 14:48:21.604528 17263 net.cpp:509] Setting up Eltwise40
I0619 14:48:21.604542 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.604549 17263 net.cpp:524] Memory required for data: 2641887744
I0619 14:48:21.604557 17263 layer_factory.hpp:77] Creating layer ReLU81
I0619 14:48:21.604568 17263 net.cpp:459] Creating Layer ReLU81
I0619 14:48:21.604576 17263 net.cpp:886] ReLU81 <- Eltwise40
I0619 14:48:21.604590 17263 net.cpp:847] ReLU81 -> Eltwise40 (in-place)
I0619 14:48:21.604604 17263 net.cpp:509] Setting up ReLU81
I0619 14:48:21.604614 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.604621 17263 net.cpp:524] Memory required for data: 2643984896
I0619 14:48:21.604629 17263 layer_factory.hpp:77] Creating layer Eltwise40_ReLU81_0_split
I0619 14:48:21.604640 17263 net.cpp:459] Creating Layer Eltwise40_ReLU81_0_split
I0619 14:48:21.604647 17263 net.cpp:886] Eltwise40_ReLU81_0_split <- Eltwise40
I0619 14:48:21.604657 17263 net.cpp:860] Eltwise40_ReLU81_0_split -> Eltwise40_ReLU81_0_split_0
I0619 14:48:21.604672 17263 net.cpp:860] Eltwise40_ReLU81_0_split -> Eltwise40_ReLU81_0_split_1
I0619 14:48:21.604749 17263 net.cpp:509] Setting up Eltwise40_ReLU81_0_split
I0619 14:48:21.604761 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.604771 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.604779 17263 net.cpp:524] Memory required for data: 2648179200
I0619 14:48:21.604786 17263 layer_factory.hpp:77] Creating layer Convolution82
I0619 14:48:21.604804 17263 net.cpp:459] Creating Layer Convolution82
I0619 14:48:21.604812 17263 net.cpp:886] Convolution82 <- Eltwise40_ReLU81_0_split_0
I0619 14:48:21.604830 17263 net.cpp:860] Convolution82 -> Convolution82
I0619 14:48:21.607931 17263 net.cpp:509] Setting up Convolution82
I0619 14:48:21.607949 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.607957 17263 net.cpp:524] Memory required for data: 2650276352
I0619 14:48:21.607975 17263 layer_factory.hpp:77] Creating layer BatchNorm82
I0619 14:48:21.607990 17263 net.cpp:459] Creating Layer BatchNorm82
I0619 14:48:21.607998 17263 net.cpp:886] BatchNorm82 <- Convolution82
I0619 14:48:21.608012 17263 net.cpp:847] BatchNorm82 -> Convolution82 (in-place)
I0619 14:48:21.608420 17263 net.cpp:509] Setting up BatchNorm82
I0619 14:48:21.608434 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.608441 17263 net.cpp:524] Memory required for data: 2652373504
I0619 14:48:21.608464 17263 layer_factory.hpp:77] Creating layer Scale82
I0619 14:48:21.608480 17263 net.cpp:459] Creating Layer Scale82
I0619 14:48:21.608489 17263 net.cpp:886] Scale82 <- Convolution82
I0619 14:48:21.608500 17263 net.cpp:847] Scale82 -> Convolution82 (in-place)
I0619 14:48:21.608568 17263 layer_factory.hpp:77] Creating layer Scale82
I0619 14:48:21.608805 17263 net.cpp:509] Setting up Scale82
I0619 14:48:21.608819 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.608826 17263 net.cpp:524] Memory required for data: 2654470656
I0619 14:48:21.608844 17263 layer_factory.hpp:77] Creating layer ReLU82
I0619 14:48:21.608856 17263 net.cpp:459] Creating Layer ReLU82
I0619 14:48:21.608865 17263 net.cpp:886] ReLU82 <- Convolution82
I0619 14:48:21.608878 17263 net.cpp:847] ReLU82 -> Convolution82 (in-place)
I0619 14:48:21.608892 17263 net.cpp:509] Setting up ReLU82
I0619 14:48:21.608902 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.608909 17263 net.cpp:524] Memory required for data: 2656567808
I0619 14:48:21.608916 17263 layer_factory.hpp:77] Creating layer Convolution83
I0619 14:48:21.608937 17263 net.cpp:459] Creating Layer Convolution83
I0619 14:48:21.608944 17263 net.cpp:886] Convolution83 <- Convolution82
I0619 14:48:21.608958 17263 net.cpp:860] Convolution83 -> Convolution83
I0619 14:48:21.612059 17263 net.cpp:509] Setting up Convolution83
I0619 14:48:21.612078 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.612118 17263 net.cpp:524] Memory required for data: 2658664960
I0619 14:48:21.612139 17263 layer_factory.hpp:77] Creating layer BatchNorm83
I0619 14:48:21.612157 17263 net.cpp:459] Creating Layer BatchNorm83
I0619 14:48:21.612167 17263 net.cpp:886] BatchNorm83 <- Convolution83
I0619 14:48:21.612179 17263 net.cpp:847] BatchNorm83 -> Convolution83 (in-place)
I0619 14:48:21.612589 17263 net.cpp:509] Setting up BatchNorm83
I0619 14:48:21.612603 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.612612 17263 net.cpp:524] Memory required for data: 2660762112
I0619 14:48:21.612632 17263 layer_factory.hpp:77] Creating layer Scale83
I0619 14:48:21.612645 17263 net.cpp:459] Creating Layer Scale83
I0619 14:48:21.612653 17263 net.cpp:886] Scale83 <- Convolution83
I0619 14:48:21.612664 17263 net.cpp:847] Scale83 -> Convolution83 (in-place)
I0619 14:48:21.612740 17263 layer_factory.hpp:77] Creating layer Scale83
I0619 14:48:21.612973 17263 net.cpp:509] Setting up Scale83
I0619 14:48:21.612987 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.612994 17263 net.cpp:524] Memory required for data: 2662859264
I0619 14:48:21.613011 17263 layer_factory.hpp:77] Creating layer Eltwise41
I0619 14:48:21.613028 17263 net.cpp:459] Creating Layer Eltwise41
I0619 14:48:21.613036 17263 net.cpp:886] Eltwise41 <- Eltwise40_ReLU81_0_split_1
I0619 14:48:21.613046 17263 net.cpp:886] Eltwise41 <- Convolution83
I0619 14:48:21.613059 17263 net.cpp:860] Eltwise41 -> Eltwise41
I0619 14:48:21.613095 17263 net.cpp:509] Setting up Eltwise41
I0619 14:48:21.613107 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.613114 17263 net.cpp:524] Memory required for data: 2664956416
I0619 14:48:21.613121 17263 layer_factory.hpp:77] Creating layer ReLU83
I0619 14:48:21.613137 17263 net.cpp:459] Creating Layer ReLU83
I0619 14:48:21.613144 17263 net.cpp:886] ReLU83 <- Eltwise41
I0619 14:48:21.613159 17263 net.cpp:847] ReLU83 -> Eltwise41 (in-place)
I0619 14:48:21.613173 17263 net.cpp:509] Setting up ReLU83
I0619 14:48:21.613183 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.613189 17263 net.cpp:524] Memory required for data: 2667053568
I0619 14:48:21.613196 17263 layer_factory.hpp:77] Creating layer Eltwise41_ReLU83_0_split
I0619 14:48:21.613209 17263 net.cpp:459] Creating Layer Eltwise41_ReLU83_0_split
I0619 14:48:21.613215 17263 net.cpp:886] Eltwise41_ReLU83_0_split <- Eltwise41
I0619 14:48:21.613226 17263 net.cpp:860] Eltwise41_ReLU83_0_split -> Eltwise41_ReLU83_0_split_0
I0619 14:48:21.613240 17263 net.cpp:860] Eltwise41_ReLU83_0_split -> Eltwise41_ReLU83_0_split_1
I0619 14:48:21.613312 17263 net.cpp:509] Setting up Eltwise41_ReLU83_0_split
I0619 14:48:21.613324 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.613334 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.613342 17263 net.cpp:524] Memory required for data: 2671247872
I0619 14:48:21.613349 17263 layer_factory.hpp:77] Creating layer Convolution84
I0619 14:48:21.613369 17263 net.cpp:459] Creating Layer Convolution84
I0619 14:48:21.613379 17263 net.cpp:886] Convolution84 <- Eltwise41_ReLU83_0_split_0
I0619 14:48:21.613392 17263 net.cpp:860] Convolution84 -> Convolution84
I0619 14:48:21.616380 17263 net.cpp:509] Setting up Convolution84
I0619 14:48:21.616397 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.616405 17263 net.cpp:524] Memory required for data: 2673345024
I0619 14:48:21.616421 17263 layer_factory.hpp:77] Creating layer BatchNorm84
I0619 14:48:21.616436 17263 net.cpp:459] Creating Layer BatchNorm84
I0619 14:48:21.616446 17263 net.cpp:886] BatchNorm84 <- Convolution84
I0619 14:48:21.616458 17263 net.cpp:847] BatchNorm84 -> Convolution84 (in-place)
I0619 14:48:21.616830 17263 net.cpp:509] Setting up BatchNorm84
I0619 14:48:21.616843 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.616850 17263 net.cpp:524] Memory required for data: 2675442176
I0619 14:48:21.616873 17263 layer_factory.hpp:77] Creating layer Scale84
I0619 14:48:21.616889 17263 net.cpp:459] Creating Layer Scale84
I0619 14:48:21.616930 17263 net.cpp:886] Scale84 <- Convolution84
I0619 14:48:21.616945 17263 net.cpp:847] Scale84 -> Convolution84 (in-place)
I0619 14:48:21.617022 17263 layer_factory.hpp:77] Creating layer Scale84
I0619 14:48:21.617250 17263 net.cpp:509] Setting up Scale84
I0619 14:48:21.617264 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.617270 17263 net.cpp:524] Memory required for data: 2677539328
I0619 14:48:21.617290 17263 layer_factory.hpp:77] Creating layer ReLU84
I0619 14:48:21.617302 17263 net.cpp:459] Creating Layer ReLU84
I0619 14:48:21.617311 17263 net.cpp:886] ReLU84 <- Convolution84
I0619 14:48:21.617322 17263 net.cpp:847] ReLU84 -> Convolution84 (in-place)
I0619 14:48:21.617334 17263 net.cpp:509] Setting up ReLU84
I0619 14:48:21.617344 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.617350 17263 net.cpp:524] Memory required for data: 2679636480
I0619 14:48:21.617357 17263 layer_factory.hpp:77] Creating layer Convolution85
I0619 14:48:21.617373 17263 net.cpp:459] Creating Layer Convolution85
I0619 14:48:21.617382 17263 net.cpp:886] Convolution85 <- Convolution84
I0619 14:48:21.617395 17263 net.cpp:860] Convolution85 -> Convolution85
I0619 14:48:21.620251 17263 net.cpp:509] Setting up Convolution85
I0619 14:48:21.620268 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.620275 17263 net.cpp:524] Memory required for data: 2681733632
I0619 14:48:21.620292 17263 layer_factory.hpp:77] Creating layer BatchNorm85
I0619 14:48:21.620306 17263 net.cpp:459] Creating Layer BatchNorm85
I0619 14:48:21.620313 17263 net.cpp:886] BatchNorm85 <- Convolution85
I0619 14:48:21.620326 17263 net.cpp:847] BatchNorm85 -> Convolution85 (in-place)
I0619 14:48:21.620697 17263 net.cpp:509] Setting up BatchNorm85
I0619 14:48:21.620709 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.620717 17263 net.cpp:524] Memory required for data: 2683830784
I0619 14:48:21.620736 17263 layer_factory.hpp:77] Creating layer Scale85
I0619 14:48:21.620748 17263 net.cpp:459] Creating Layer Scale85
I0619 14:48:21.620756 17263 net.cpp:886] Scale85 <- Convolution85
I0619 14:48:21.620769 17263 net.cpp:847] Scale85 -> Convolution85 (in-place)
I0619 14:48:21.620831 17263 layer_factory.hpp:77] Creating layer Scale85
I0619 14:48:21.621054 17263 net.cpp:509] Setting up Scale85
I0619 14:48:21.621068 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.621074 17263 net.cpp:524] Memory required for data: 2685927936
I0619 14:48:21.621090 17263 layer_factory.hpp:77] Creating layer Eltwise42
I0619 14:48:21.621103 17263 net.cpp:459] Creating Layer Eltwise42
I0619 14:48:21.621111 17263 net.cpp:886] Eltwise42 <- Eltwise41_ReLU83_0_split_1
I0619 14:48:21.621120 17263 net.cpp:886] Eltwise42 <- Convolution85
I0619 14:48:21.621134 17263 net.cpp:860] Eltwise42 -> Eltwise42
I0619 14:48:21.621168 17263 net.cpp:509] Setting up Eltwise42
I0619 14:48:21.621179 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.621186 17263 net.cpp:524] Memory required for data: 2688025088
I0619 14:48:21.621192 17263 layer_factory.hpp:77] Creating layer ReLU85
I0619 14:48:21.621206 17263 net.cpp:459] Creating Layer ReLU85
I0619 14:48:21.621213 17263 net.cpp:886] ReLU85 <- Eltwise42
I0619 14:48:21.621222 17263 net.cpp:847] ReLU85 -> Eltwise42 (in-place)
I0619 14:48:21.621233 17263 net.cpp:509] Setting up ReLU85
I0619 14:48:21.621243 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.621249 17263 net.cpp:524] Memory required for data: 2690122240
I0619 14:48:21.621256 17263 layer_factory.hpp:77] Creating layer Eltwise42_ReLU85_0_split
I0619 14:48:21.621266 17263 net.cpp:459] Creating Layer Eltwise42_ReLU85_0_split
I0619 14:48:21.621273 17263 net.cpp:886] Eltwise42_ReLU85_0_split <- Eltwise42
I0619 14:48:21.621286 17263 net.cpp:860] Eltwise42_ReLU85_0_split -> Eltwise42_ReLU85_0_split_0
I0619 14:48:21.621299 17263 net.cpp:860] Eltwise42_ReLU85_0_split -> Eltwise42_ReLU85_0_split_1
I0619 14:48:21.621362 17263 net.cpp:509] Setting up Eltwise42_ReLU85_0_split
I0619 14:48:21.621381 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.621410 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.621418 17263 net.cpp:524] Memory required for data: 2694316544
I0619 14:48:21.621425 17263 layer_factory.hpp:77] Creating layer Convolution86
I0619 14:48:21.621449 17263 net.cpp:459] Creating Layer Convolution86
I0619 14:48:21.621459 17263 net.cpp:886] Convolution86 <- Eltwise42_ReLU85_0_split_0
I0619 14:48:21.621471 17263 net.cpp:860] Convolution86 -> Convolution86
I0619 14:48:21.624341 17263 net.cpp:509] Setting up Convolution86
I0619 14:48:21.624357 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.624364 17263 net.cpp:524] Memory required for data: 2696413696
I0619 14:48:21.624382 17263 layer_factory.hpp:77] Creating layer BatchNorm86
I0619 14:48:21.624397 17263 net.cpp:459] Creating Layer BatchNorm86
I0619 14:48:21.624405 17263 net.cpp:886] BatchNorm86 <- Convolution86
I0619 14:48:21.624415 17263 net.cpp:847] BatchNorm86 -> Convolution86 (in-place)
I0619 14:48:21.624786 17263 net.cpp:509] Setting up BatchNorm86
I0619 14:48:21.624799 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.624806 17263 net.cpp:524] Memory required for data: 2698510848
I0619 14:48:21.624826 17263 layer_factory.hpp:77] Creating layer Scale86
I0619 14:48:21.624838 17263 net.cpp:459] Creating Layer Scale86
I0619 14:48:21.624846 17263 net.cpp:886] Scale86 <- Convolution86
I0619 14:48:21.624856 17263 net.cpp:847] Scale86 -> Convolution86 (in-place)
I0619 14:48:21.624924 17263 layer_factory.hpp:77] Creating layer Scale86
I0619 14:48:21.625140 17263 net.cpp:509] Setting up Scale86
I0619 14:48:21.625154 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.625159 17263 net.cpp:524] Memory required for data: 2700608000
I0619 14:48:21.625176 17263 layer_factory.hpp:77] Creating layer ReLU86
I0619 14:48:21.625190 17263 net.cpp:459] Creating Layer ReLU86
I0619 14:48:21.625198 17263 net.cpp:886] ReLU86 <- Convolution86
I0619 14:48:21.625208 17263 net.cpp:847] ReLU86 -> Convolution86 (in-place)
I0619 14:48:21.625219 17263 net.cpp:509] Setting up ReLU86
I0619 14:48:21.625229 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.625236 17263 net.cpp:524] Memory required for data: 2702705152
I0619 14:48:21.625243 17263 layer_factory.hpp:77] Creating layer Convolution87
I0619 14:48:21.625262 17263 net.cpp:459] Creating Layer Convolution87
I0619 14:48:21.625269 17263 net.cpp:886] Convolution87 <- Convolution86
I0619 14:48:21.625285 17263 net.cpp:860] Convolution87 -> Convolution87
I0619 14:48:21.628140 17263 net.cpp:509] Setting up Convolution87
I0619 14:48:21.628157 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.628165 17263 net.cpp:524] Memory required for data: 2704802304
I0619 14:48:21.628181 17263 layer_factory.hpp:77] Creating layer BatchNorm87
I0619 14:48:21.628196 17263 net.cpp:459] Creating Layer BatchNorm87
I0619 14:48:21.628206 17263 net.cpp:886] BatchNorm87 <- Convolution87
I0619 14:48:21.628216 17263 net.cpp:847] BatchNorm87 -> Convolution87 (in-place)
I0619 14:48:21.628587 17263 net.cpp:509] Setting up BatchNorm87
I0619 14:48:21.628599 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.628607 17263 net.cpp:524] Memory required for data: 2706899456
I0619 14:48:21.628626 17263 layer_factory.hpp:77] Creating layer Scale87
I0619 14:48:21.628641 17263 net.cpp:459] Creating Layer Scale87
I0619 14:48:21.628649 17263 net.cpp:886] Scale87 <- Convolution87
I0619 14:48:21.628659 17263 net.cpp:847] Scale87 -> Convolution87 (in-place)
I0619 14:48:21.628726 17263 layer_factory.hpp:77] Creating layer Scale87
I0619 14:48:21.628944 17263 net.cpp:509] Setting up Scale87
I0619 14:48:21.628957 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.628964 17263 net.cpp:524] Memory required for data: 2708996608
I0619 14:48:21.628980 17263 layer_factory.hpp:77] Creating layer Eltwise43
I0619 14:48:21.628995 17263 net.cpp:459] Creating Layer Eltwise43
I0619 14:48:21.629004 17263 net.cpp:886] Eltwise43 <- Eltwise42_ReLU85_0_split_1
I0619 14:48:21.629017 17263 net.cpp:886] Eltwise43 <- Convolution87
I0619 14:48:21.629048 17263 net.cpp:860] Eltwise43 -> Eltwise43
I0619 14:48:21.629091 17263 net.cpp:509] Setting up Eltwise43
I0619 14:48:21.629102 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.629108 17263 net.cpp:524] Memory required for data: 2711093760
I0619 14:48:21.629115 17263 layer_factory.hpp:77] Creating layer ReLU87
I0619 14:48:21.629127 17263 net.cpp:459] Creating Layer ReLU87
I0619 14:48:21.629133 17263 net.cpp:886] ReLU87 <- Eltwise43
I0619 14:48:21.629142 17263 net.cpp:847] ReLU87 -> Eltwise43 (in-place)
I0619 14:48:21.629153 17263 net.cpp:509] Setting up ReLU87
I0619 14:48:21.629163 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.629169 17263 net.cpp:524] Memory required for data: 2713190912
I0619 14:48:21.629176 17263 layer_factory.hpp:77] Creating layer Eltwise43_ReLU87_0_split
I0619 14:48:21.629199 17263 net.cpp:459] Creating Layer Eltwise43_ReLU87_0_split
I0619 14:48:21.629206 17263 net.cpp:886] Eltwise43_ReLU87_0_split <- Eltwise43
I0619 14:48:21.629216 17263 net.cpp:860] Eltwise43_ReLU87_0_split -> Eltwise43_ReLU87_0_split_0
I0619 14:48:21.629230 17263 net.cpp:860] Eltwise43_ReLU87_0_split -> Eltwise43_ReLU87_0_split_1
I0619 14:48:21.629297 17263 net.cpp:509] Setting up Eltwise43_ReLU87_0_split
I0619 14:48:21.629309 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.629318 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.629325 17263 net.cpp:524] Memory required for data: 2717385216
I0619 14:48:21.629333 17263 layer_factory.hpp:77] Creating layer Convolution88
I0619 14:48:21.629348 17263 net.cpp:459] Creating Layer Convolution88
I0619 14:48:21.629355 17263 net.cpp:886] Convolution88 <- Eltwise43_ReLU87_0_split_0
I0619 14:48:21.629371 17263 net.cpp:860] Convolution88 -> Convolution88
I0619 14:48:21.633165 17263 net.cpp:509] Setting up Convolution88
I0619 14:48:21.633191 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.633199 17263 net.cpp:524] Memory required for data: 2719482368
I0619 14:48:21.633219 17263 layer_factory.hpp:77] Creating layer BatchNorm88
I0619 14:48:21.633236 17263 net.cpp:459] Creating Layer BatchNorm88
I0619 14:48:21.633245 17263 net.cpp:886] BatchNorm88 <- Convolution88
I0619 14:48:21.633260 17263 net.cpp:847] BatchNorm88 -> Convolution88 (in-place)
I0619 14:48:21.633635 17263 net.cpp:509] Setting up BatchNorm88
I0619 14:48:21.633647 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.633654 17263 net.cpp:524] Memory required for data: 2721579520
I0619 14:48:21.633680 17263 layer_factory.hpp:77] Creating layer Scale88
I0619 14:48:21.633692 17263 net.cpp:459] Creating Layer Scale88
I0619 14:48:21.633700 17263 net.cpp:886] Scale88 <- Convolution88
I0619 14:48:21.633710 17263 net.cpp:847] Scale88 -> Convolution88 (in-place)
I0619 14:48:21.633779 17263 layer_factory.hpp:77] Creating layer Scale88
I0619 14:48:21.633998 17263 net.cpp:509] Setting up Scale88
I0619 14:48:21.634011 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.634018 17263 net.cpp:524] Memory required for data: 2723676672
I0619 14:48:21.634037 17263 layer_factory.hpp:77] Creating layer ReLU88
I0619 14:48:21.634048 17263 net.cpp:459] Creating Layer ReLU88
I0619 14:48:21.634057 17263 net.cpp:886] ReLU88 <- Convolution88
I0619 14:48:21.634069 17263 net.cpp:847] ReLU88 -> Convolution88 (in-place)
I0619 14:48:21.634081 17263 net.cpp:509] Setting up ReLU88
I0619 14:48:21.634091 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.634097 17263 net.cpp:524] Memory required for data: 2725773824
I0619 14:48:21.634104 17263 layer_factory.hpp:77] Creating layer Convolution89
I0619 14:48:21.634121 17263 net.cpp:459] Creating Layer Convolution89
I0619 14:48:21.634129 17263 net.cpp:886] Convolution89 <- Convolution88
I0619 14:48:21.634142 17263 net.cpp:860] Convolution89 -> Convolution89
I0619 14:48:21.637004 17263 net.cpp:509] Setting up Convolution89
I0619 14:48:21.637022 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.637034 17263 net.cpp:524] Memory required for data: 2727870976
I0619 14:48:21.637076 17263 layer_factory.hpp:77] Creating layer BatchNorm89
I0619 14:48:21.637089 17263 net.cpp:459] Creating Layer BatchNorm89
I0619 14:48:21.637099 17263 net.cpp:886] BatchNorm89 <- Convolution89
I0619 14:48:21.637112 17263 net.cpp:847] BatchNorm89 -> Convolution89 (in-place)
I0619 14:48:21.637482 17263 net.cpp:509] Setting up BatchNorm89
I0619 14:48:21.637495 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.637502 17263 net.cpp:524] Memory required for data: 2729968128
I0619 14:48:21.637522 17263 layer_factory.hpp:77] Creating layer Scale89
I0619 14:48:21.637534 17263 net.cpp:459] Creating Layer Scale89
I0619 14:48:21.637542 17263 net.cpp:886] Scale89 <- Convolution89
I0619 14:48:21.637554 17263 net.cpp:847] Scale89 -> Convolution89 (in-place)
I0619 14:48:21.637617 17263 layer_factory.hpp:77] Creating layer Scale89
I0619 14:48:21.637848 17263 net.cpp:509] Setting up Scale89
I0619 14:48:21.637862 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.637869 17263 net.cpp:524] Memory required for data: 2732065280
I0619 14:48:21.637886 17263 layer_factory.hpp:77] Creating layer Eltwise44
I0619 14:48:21.637898 17263 net.cpp:459] Creating Layer Eltwise44
I0619 14:48:21.637907 17263 net.cpp:886] Eltwise44 <- Eltwise43_ReLU87_0_split_1
I0619 14:48:21.637917 17263 net.cpp:886] Eltwise44 <- Convolution89
I0619 14:48:21.637930 17263 net.cpp:860] Eltwise44 -> Eltwise44
I0619 14:48:21.637966 17263 net.cpp:509] Setting up Eltwise44
I0619 14:48:21.637979 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.637984 17263 net.cpp:524] Memory required for data: 2734162432
I0619 14:48:21.637991 17263 layer_factory.hpp:77] Creating layer ReLU89
I0619 14:48:21.638006 17263 net.cpp:459] Creating Layer ReLU89
I0619 14:48:21.638015 17263 net.cpp:886] ReLU89 <- Eltwise44
I0619 14:48:21.638023 17263 net.cpp:847] ReLU89 -> Eltwise44 (in-place)
I0619 14:48:21.638036 17263 net.cpp:509] Setting up ReLU89
I0619 14:48:21.638044 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.638051 17263 net.cpp:524] Memory required for data: 2736259584
I0619 14:48:21.638058 17263 layer_factory.hpp:77] Creating layer Eltwise44_ReLU89_0_split
I0619 14:48:21.638068 17263 net.cpp:459] Creating Layer Eltwise44_ReLU89_0_split
I0619 14:48:21.638074 17263 net.cpp:886] Eltwise44_ReLU89_0_split <- Eltwise44
I0619 14:48:21.638087 17263 net.cpp:860] Eltwise44_ReLU89_0_split -> Eltwise44_ReLU89_0_split_0
I0619 14:48:21.638100 17263 net.cpp:860] Eltwise44_ReLU89_0_split -> Eltwise44_ReLU89_0_split_1
I0619 14:48:21.638164 17263 net.cpp:509] Setting up Eltwise44_ReLU89_0_split
I0619 14:48:21.638176 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.638185 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.638191 17263 net.cpp:524] Memory required for data: 2740453888
I0619 14:48:21.638198 17263 layer_factory.hpp:77] Creating layer Convolution90
I0619 14:48:21.638217 17263 net.cpp:459] Creating Layer Convolution90
I0619 14:48:21.638226 17263 net.cpp:886] Convolution90 <- Eltwise44_ReLU89_0_split_0
I0619 14:48:21.638237 17263 net.cpp:860] Convolution90 -> Convolution90
I0619 14:48:21.640930 17263 net.cpp:509] Setting up Convolution90
I0619 14:48:21.640946 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.640954 17263 net.cpp:524] Memory required for data: 2742551040
I0619 14:48:21.640969 17263 layer_factory.hpp:77] Creating layer BatchNorm90
I0619 14:48:21.640983 17263 net.cpp:459] Creating Layer BatchNorm90
I0619 14:48:21.640991 17263 net.cpp:886] BatchNorm90 <- Convolution90
I0619 14:48:21.641000 17263 net.cpp:847] BatchNorm90 -> Convolution90 (in-place)
I0619 14:48:21.641350 17263 net.cpp:509] Setting up BatchNorm90
I0619 14:48:21.641361 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.641367 17263 net.cpp:524] Memory required for data: 2744648192
I0619 14:48:21.641389 17263 layer_factory.hpp:77] Creating layer Scale90
I0619 14:48:21.641401 17263 net.cpp:459] Creating Layer Scale90
I0619 14:48:21.641412 17263 net.cpp:886] Scale90 <- Convolution90
I0619 14:48:21.641440 17263 net.cpp:847] Scale90 -> Convolution90 (in-place)
I0619 14:48:21.641512 17263 layer_factory.hpp:77] Creating layer Scale90
I0619 14:48:21.641721 17263 net.cpp:509] Setting up Scale90
I0619 14:48:21.641732 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.641738 17263 net.cpp:524] Memory required for data: 2746745344
I0619 14:48:21.641753 17263 layer_factory.hpp:77] Creating layer ReLU90
I0619 14:48:21.641767 17263 net.cpp:459] Creating Layer ReLU90
I0619 14:48:21.641774 17263 net.cpp:886] ReLU90 <- Convolution90
I0619 14:48:21.641783 17263 net.cpp:847] ReLU90 -> Convolution90 (in-place)
I0619 14:48:21.641794 17263 net.cpp:509] Setting up ReLU90
I0619 14:48:21.641803 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.641809 17263 net.cpp:524] Memory required for data: 2748842496
I0619 14:48:21.641815 17263 layer_factory.hpp:77] Creating layer Convolution91
I0619 14:48:21.641832 17263 net.cpp:459] Creating Layer Convolution91
I0619 14:48:21.641839 17263 net.cpp:886] Convolution91 <- Convolution90
I0619 14:48:21.641858 17263 net.cpp:860] Convolution91 -> Convolution91
I0619 14:48:21.644515 17263 net.cpp:509] Setting up Convolution91
I0619 14:48:21.644531 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.644537 17263 net.cpp:524] Memory required for data: 2750939648
I0619 14:48:21.644552 17263 layer_factory.hpp:77] Creating layer BatchNorm91
I0619 14:48:21.644567 17263 net.cpp:459] Creating Layer BatchNorm91
I0619 14:48:21.644574 17263 net.cpp:886] BatchNorm91 <- Convolution91
I0619 14:48:21.644584 17263 net.cpp:847] BatchNorm91 -> Convolution91 (in-place)
I0619 14:48:21.644937 17263 net.cpp:509] Setting up BatchNorm91
I0619 14:48:21.644948 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.644955 17263 net.cpp:524] Memory required for data: 2753036800
I0619 14:48:21.644973 17263 layer_factory.hpp:77] Creating layer Scale91
I0619 14:48:21.644987 17263 net.cpp:459] Creating Layer Scale91
I0619 14:48:21.644995 17263 net.cpp:886] Scale91 <- Convolution91
I0619 14:48:21.645004 17263 net.cpp:847] Scale91 -> Convolution91 (in-place)
I0619 14:48:21.645066 17263 layer_factory.hpp:77] Creating layer Scale91
I0619 14:48:21.645269 17263 net.cpp:509] Setting up Scale91
I0619 14:48:21.645282 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.645288 17263 net.cpp:524] Memory required for data: 2755133952
I0619 14:48:21.645303 17263 layer_factory.hpp:77] Creating layer Eltwise45
I0619 14:48:21.645316 17263 net.cpp:459] Creating Layer Eltwise45
I0619 14:48:21.645325 17263 net.cpp:886] Eltwise45 <- Eltwise44_ReLU89_0_split_1
I0619 14:48:21.645334 17263 net.cpp:886] Eltwise45 <- Convolution91
I0619 14:48:21.645344 17263 net.cpp:860] Eltwise45 -> Eltwise45
I0619 14:48:21.645377 17263 net.cpp:509] Setting up Eltwise45
I0619 14:48:21.645387 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.645393 17263 net.cpp:524] Memory required for data: 2757231104
I0619 14:48:21.645401 17263 layer_factory.hpp:77] Creating layer ReLU91
I0619 14:48:21.645409 17263 net.cpp:459] Creating Layer ReLU91
I0619 14:48:21.645416 17263 net.cpp:886] ReLU91 <- Eltwise45
I0619 14:48:21.645427 17263 net.cpp:847] ReLU91 -> Eltwise45 (in-place)
I0619 14:48:21.645438 17263 net.cpp:509] Setting up ReLU91
I0619 14:48:21.645447 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.645453 17263 net.cpp:524] Memory required for data: 2759328256
I0619 14:48:21.645459 17263 layer_factory.hpp:77] Creating layer Eltwise45_ReLU91_0_split
I0619 14:48:21.645468 17263 net.cpp:459] Creating Layer Eltwise45_ReLU91_0_split
I0619 14:48:21.645474 17263 net.cpp:886] Eltwise45_ReLU91_0_split <- Eltwise45
I0619 14:48:21.645484 17263 net.cpp:860] Eltwise45_ReLU91_0_split -> Eltwise45_ReLU91_0_split_0
I0619 14:48:21.645496 17263 net.cpp:860] Eltwise45_ReLU91_0_split -> Eltwise45_ReLU91_0_split_1
I0619 14:48:21.645557 17263 net.cpp:509] Setting up Eltwise45_ReLU91_0_split
I0619 14:48:21.645568 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.645601 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.645607 17263 net.cpp:524] Memory required for data: 2763522560
I0619 14:48:21.645614 17263 layer_factory.hpp:77] Creating layer Convolution92
I0619 14:48:21.645629 17263 net.cpp:459] Creating Layer Convolution92
I0619 14:48:21.645637 17263 net.cpp:886] Convolution92 <- Eltwise45_ReLU91_0_split_0
I0619 14:48:21.645653 17263 net.cpp:860] Convolution92 -> Convolution92
I0619 14:48:21.648324 17263 net.cpp:509] Setting up Convolution92
I0619 14:48:21.648340 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.648346 17263 net.cpp:524] Memory required for data: 2765619712
I0619 14:48:21.648362 17263 layer_factory.hpp:77] Creating layer BatchNorm92
I0619 14:48:21.648375 17263 net.cpp:459] Creating Layer BatchNorm92
I0619 14:48:21.648381 17263 net.cpp:886] BatchNorm92 <- Convolution92
I0619 14:48:21.648394 17263 net.cpp:847] BatchNorm92 -> Convolution92 (in-place)
I0619 14:48:21.648746 17263 net.cpp:509] Setting up BatchNorm92
I0619 14:48:21.648757 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.648764 17263 net.cpp:524] Memory required for data: 2767716864
I0619 14:48:21.648782 17263 layer_factory.hpp:77] Creating layer Scale92
I0619 14:48:21.648793 17263 net.cpp:459] Creating Layer Scale92
I0619 14:48:21.648800 17263 net.cpp:886] Scale92 <- Convolution92
I0619 14:48:21.648813 17263 net.cpp:847] Scale92 -> Convolution92 (in-place)
I0619 14:48:21.648871 17263 layer_factory.hpp:77] Creating layer Scale92
I0619 14:48:21.649075 17263 net.cpp:509] Setting up Scale92
I0619 14:48:21.649086 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.649092 17263 net.cpp:524] Memory required for data: 2769814016
I0619 14:48:21.649107 17263 layer_factory.hpp:77] Creating layer ReLU92
I0619 14:48:21.649117 17263 net.cpp:459] Creating Layer ReLU92
I0619 14:48:21.649125 17263 net.cpp:886] ReLU92 <- Convolution92
I0619 14:48:21.649137 17263 net.cpp:847] ReLU92 -> Convolution92 (in-place)
I0619 14:48:21.649148 17263 net.cpp:509] Setting up ReLU92
I0619 14:48:21.649158 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.649163 17263 net.cpp:524] Memory required for data: 2771911168
I0619 14:48:21.649169 17263 layer_factory.hpp:77] Creating layer Convolution93
I0619 14:48:21.649186 17263 net.cpp:459] Creating Layer Convolution93
I0619 14:48:21.649194 17263 net.cpp:886] Convolution93 <- Convolution92
I0619 14:48:21.649204 17263 net.cpp:860] Convolution93 -> Convolution93
I0619 14:48:21.651808 17263 net.cpp:509] Setting up Convolution93
I0619 14:48:21.651823 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.651829 17263 net.cpp:524] Memory required for data: 2774008320
I0619 14:48:21.651842 17263 layer_factory.hpp:77] Creating layer BatchNorm93
I0619 14:48:21.651859 17263 net.cpp:459] Creating Layer BatchNorm93
I0619 14:48:21.651866 17263 net.cpp:886] BatchNorm93 <- Convolution93
I0619 14:48:21.651875 17263 net.cpp:847] BatchNorm93 -> Convolution93 (in-place)
I0619 14:48:21.652202 17263 net.cpp:509] Setting up BatchNorm93
I0619 14:48:21.652215 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.652220 17263 net.cpp:524] Memory required for data: 2776105472
I0619 14:48:21.652237 17263 layer_factory.hpp:77] Creating layer Scale93
I0619 14:48:21.652248 17263 net.cpp:459] Creating Layer Scale93
I0619 14:48:21.652254 17263 net.cpp:886] Scale93 <- Convolution93
I0619 14:48:21.652263 17263 net.cpp:847] Scale93 -> Convolution93 (in-place)
I0619 14:48:21.652320 17263 layer_factory.hpp:77] Creating layer Scale93
I0619 14:48:21.652520 17263 net.cpp:509] Setting up Scale93
I0619 14:48:21.652532 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.652537 17263 net.cpp:524] Memory required for data: 2778202624
I0619 14:48:21.652551 17263 layer_factory.hpp:77] Creating layer Eltwise46
I0619 14:48:21.652565 17263 net.cpp:459] Creating Layer Eltwise46
I0619 14:48:21.652572 17263 net.cpp:886] Eltwise46 <- Eltwise45_ReLU91_0_split_1
I0619 14:48:21.652581 17263 net.cpp:886] Eltwise46 <- Convolution93
I0619 14:48:21.652612 17263 net.cpp:860] Eltwise46 -> Eltwise46
I0619 14:48:21.652647 17263 net.cpp:509] Setting up Eltwise46
I0619 14:48:21.652657 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.652662 17263 net.cpp:524] Memory required for data: 2780299776
I0619 14:48:21.652668 17263 layer_factory.hpp:77] Creating layer ReLU93
I0619 14:48:21.652680 17263 net.cpp:459] Creating Layer ReLU93
I0619 14:48:21.652686 17263 net.cpp:886] ReLU93 <- Eltwise46
I0619 14:48:21.652695 17263 net.cpp:847] ReLU93 -> Eltwise46 (in-place)
I0619 14:48:21.652705 17263 net.cpp:509] Setting up ReLU93
I0619 14:48:21.652714 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.652719 17263 net.cpp:524] Memory required for data: 2782396928
I0619 14:48:21.652725 17263 layer_factory.hpp:77] Creating layer Eltwise46_ReLU93_0_split
I0619 14:48:21.652734 17263 net.cpp:459] Creating Layer Eltwise46_ReLU93_0_split
I0619 14:48:21.652740 17263 net.cpp:886] Eltwise46_ReLU93_0_split <- Eltwise46
I0619 14:48:21.652748 17263 net.cpp:860] Eltwise46_ReLU93_0_split -> Eltwise46_ReLU93_0_split_0
I0619 14:48:21.652760 17263 net.cpp:860] Eltwise46_ReLU93_0_split -> Eltwise46_ReLU93_0_split_1
I0619 14:48:21.652819 17263 net.cpp:509] Setting up Eltwise46_ReLU93_0_split
I0619 14:48:21.652829 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.652837 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.652843 17263 net.cpp:524] Memory required for data: 2786591232
I0619 14:48:21.652849 17263 layer_factory.hpp:77] Creating layer Convolution94
I0619 14:48:21.652868 17263 net.cpp:459] Creating Layer Convolution94
I0619 14:48:21.652874 17263 net.cpp:886] Convolution94 <- Eltwise46_ReLU93_0_split_0
I0619 14:48:21.652885 17263 net.cpp:860] Convolution94 -> Convolution94
I0619 14:48:21.655385 17263 net.cpp:509] Setting up Convolution94
I0619 14:48:21.655400 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.655405 17263 net.cpp:524] Memory required for data: 2788688384
I0619 14:48:21.655421 17263 layer_factory.hpp:77] Creating layer BatchNorm94
I0619 14:48:21.655433 17263 net.cpp:459] Creating Layer BatchNorm94
I0619 14:48:21.655441 17263 net.cpp:886] BatchNorm94 <- Convolution94
I0619 14:48:21.655450 17263 net.cpp:847] BatchNorm94 -> Convolution94 (in-place)
I0619 14:48:21.655782 17263 net.cpp:509] Setting up BatchNorm94
I0619 14:48:21.655793 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.655799 17263 net.cpp:524] Memory required for data: 2790785536
I0619 14:48:21.655815 17263 layer_factory.hpp:77] Creating layer Scale94
I0619 14:48:21.655830 17263 net.cpp:459] Creating Layer Scale94
I0619 14:48:21.655838 17263 net.cpp:886] Scale94 <- Convolution94
I0619 14:48:21.655846 17263 net.cpp:847] Scale94 -> Convolution94 (in-place)
I0619 14:48:21.655906 17263 layer_factory.hpp:77] Creating layer Scale94
I0619 14:48:21.656949 17263 net.cpp:509] Setting up Scale94
I0619 14:48:21.656970 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.656976 17263 net.cpp:524] Memory required for data: 2792882688
I0619 14:48:21.656993 17263 layer_factory.hpp:77] Creating layer ReLU94
I0619 14:48:21.657008 17263 net.cpp:459] Creating Layer ReLU94
I0619 14:48:21.657016 17263 net.cpp:886] ReLU94 <- Convolution94
I0619 14:48:21.657027 17263 net.cpp:847] ReLU94 -> Convolution94 (in-place)
I0619 14:48:21.657038 17263 net.cpp:509] Setting up ReLU94
I0619 14:48:21.657047 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.657052 17263 net.cpp:524] Memory required for data: 2794979840
I0619 14:48:21.657058 17263 layer_factory.hpp:77] Creating layer Convolution95
I0619 14:48:21.657076 17263 net.cpp:459] Creating Layer Convolution95
I0619 14:48:21.657083 17263 net.cpp:886] Convolution95 <- Convolution94
I0619 14:48:21.657094 17263 net.cpp:860] Convolution95 -> Convolution95
I0619 14:48:21.660423 17263 net.cpp:509] Setting up Convolution95
I0619 14:48:21.660445 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.660452 17263 net.cpp:524] Memory required for data: 2797076992
I0619 14:48:21.660472 17263 layer_factory.hpp:77] Creating layer BatchNorm95
I0619 14:48:21.660508 17263 net.cpp:459] Creating Layer BatchNorm95
I0619 14:48:21.660517 17263 net.cpp:886] BatchNorm95 <- Convolution95
I0619 14:48:21.660527 17263 net.cpp:847] BatchNorm95 -> Convolution95 (in-place)
I0619 14:48:21.660863 17263 net.cpp:509] Setting up BatchNorm95
I0619 14:48:21.660876 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.660882 17263 net.cpp:524] Memory required for data: 2799174144
I0619 14:48:21.660900 17263 layer_factory.hpp:77] Creating layer Scale95
I0619 14:48:21.660912 17263 net.cpp:459] Creating Layer Scale95
I0619 14:48:21.660917 17263 net.cpp:886] Scale95 <- Convolution95
I0619 14:48:21.660926 17263 net.cpp:847] Scale95 -> Convolution95 (in-place)
I0619 14:48:21.660990 17263 layer_factory.hpp:77] Creating layer Scale95
I0619 14:48:21.661183 17263 net.cpp:509] Setting up Scale95
I0619 14:48:21.661195 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.661201 17263 net.cpp:524] Memory required for data: 2801271296
I0619 14:48:21.661216 17263 layer_factory.hpp:77] Creating layer Eltwise47
I0619 14:48:21.661229 17263 net.cpp:459] Creating Layer Eltwise47
I0619 14:48:21.661237 17263 net.cpp:886] Eltwise47 <- Eltwise46_ReLU93_0_split_1
I0619 14:48:21.661245 17263 net.cpp:886] Eltwise47 <- Convolution95
I0619 14:48:21.661255 17263 net.cpp:860] Eltwise47 -> Eltwise47
I0619 14:48:21.661284 17263 net.cpp:509] Setting up Eltwise47
I0619 14:48:21.661294 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.661300 17263 net.cpp:524] Memory required for data: 2803368448
I0619 14:48:21.661306 17263 layer_factory.hpp:77] Creating layer ReLU95
I0619 14:48:21.661319 17263 net.cpp:459] Creating Layer ReLU95
I0619 14:48:21.661325 17263 net.cpp:886] ReLU95 <- Eltwise47
I0619 14:48:21.661334 17263 net.cpp:847] ReLU95 -> Eltwise47 (in-place)
I0619 14:48:21.661344 17263 net.cpp:509] Setting up ReLU95
I0619 14:48:21.661351 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.661357 17263 net.cpp:524] Memory required for data: 2805465600
I0619 14:48:21.661363 17263 layer_factory.hpp:77] Creating layer Eltwise47_ReLU95_0_split
I0619 14:48:21.661372 17263 net.cpp:459] Creating Layer Eltwise47_ReLU95_0_split
I0619 14:48:21.661377 17263 net.cpp:886] Eltwise47_ReLU95_0_split <- Eltwise47
I0619 14:48:21.661386 17263 net.cpp:860] Eltwise47_ReLU95_0_split -> Eltwise47_ReLU95_0_split_0
I0619 14:48:21.661398 17263 net.cpp:860] Eltwise47_ReLU95_0_split -> Eltwise47_ReLU95_0_split_1
I0619 14:48:21.661455 17263 net.cpp:509] Setting up Eltwise47_ReLU95_0_split
I0619 14:48:21.661466 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.661474 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.661480 17263 net.cpp:524] Memory required for data: 2809659904
I0619 14:48:21.661486 17263 layer_factory.hpp:77] Creating layer Convolution96
I0619 14:48:21.661502 17263 net.cpp:459] Creating Layer Convolution96
I0619 14:48:21.661510 17263 net.cpp:886] Convolution96 <- Eltwise47_ReLU95_0_split_0
I0619 14:48:21.661521 17263 net.cpp:860] Convolution96 -> Convolution96
I0619 14:48:21.663957 17263 net.cpp:509] Setting up Convolution96
I0619 14:48:21.663972 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.663978 17263 net.cpp:524] Memory required for data: 2811757056
I0619 14:48:21.663992 17263 layer_factory.hpp:77] Creating layer BatchNorm96
I0619 14:48:21.664005 17263 net.cpp:459] Creating Layer BatchNorm96
I0619 14:48:21.664012 17263 net.cpp:886] BatchNorm96 <- Convolution96
I0619 14:48:21.664023 17263 net.cpp:847] BatchNorm96 -> Convolution96 (in-place)
I0619 14:48:21.664331 17263 net.cpp:509] Setting up BatchNorm96
I0619 14:48:21.664342 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.664348 17263 net.cpp:524] Memory required for data: 2813854208
I0619 14:48:21.664364 17263 layer_factory.hpp:77] Creating layer Scale96
I0619 14:48:21.664377 17263 net.cpp:459] Creating Layer Scale96
I0619 14:48:21.664384 17263 net.cpp:886] Scale96 <- Convolution96
I0619 14:48:21.664397 17263 net.cpp:847] Scale96 -> Convolution96 (in-place)
I0619 14:48:21.664475 17263 layer_factory.hpp:77] Creating layer Scale96
I0619 14:48:21.664660 17263 net.cpp:509] Setting up Scale96
I0619 14:48:21.664672 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.664677 17263 net.cpp:524] Memory required for data: 2815951360
I0619 14:48:21.664697 17263 layer_factory.hpp:77] Creating layer ReLU96
I0619 14:48:21.664707 17263 net.cpp:459] Creating Layer ReLU96
I0619 14:48:21.664715 17263 net.cpp:886] ReLU96 <- Convolution96
I0619 14:48:21.664722 17263 net.cpp:847] ReLU96 -> Convolution96 (in-place)
I0619 14:48:21.664732 17263 net.cpp:509] Setting up ReLU96
I0619 14:48:21.664739 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.664746 17263 net.cpp:524] Memory required for data: 2818048512
I0619 14:48:21.664750 17263 layer_factory.hpp:77] Creating layer Convolution97
I0619 14:48:21.664767 17263 net.cpp:459] Creating Layer Convolution97
I0619 14:48:21.664773 17263 net.cpp:886] Convolution97 <- Convolution96
I0619 14:48:21.664785 17263 net.cpp:860] Convolution97 -> Convolution97
I0619 14:48:21.667111 17263 net.cpp:509] Setting up Convolution97
I0619 14:48:21.667125 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.667131 17263 net.cpp:524] Memory required for data: 2820145664
I0619 14:48:21.667145 17263 layer_factory.hpp:77] Creating layer BatchNorm97
I0619 14:48:21.667155 17263 net.cpp:459] Creating Layer BatchNorm97
I0619 14:48:21.667162 17263 net.cpp:886] BatchNorm97 <- Convolution97
I0619 14:48:21.667173 17263 net.cpp:847] BatchNorm97 -> Convolution97 (in-place)
I0619 14:48:21.667480 17263 net.cpp:509] Setting up BatchNorm97
I0619 14:48:21.667491 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.667496 17263 net.cpp:524] Memory required for data: 2822242816
I0619 14:48:21.667513 17263 layer_factory.hpp:77] Creating layer Scale97
I0619 14:48:21.667523 17263 net.cpp:459] Creating Layer Scale97
I0619 14:48:21.667529 17263 net.cpp:886] Scale97 <- Convolution97
I0619 14:48:21.667539 17263 net.cpp:847] Scale97 -> Convolution97 (in-place)
I0619 14:48:21.667590 17263 layer_factory.hpp:77] Creating layer Scale97
I0619 14:48:21.667774 17263 net.cpp:509] Setting up Scale97
I0619 14:48:21.667785 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.667790 17263 net.cpp:524] Memory required for data: 2824339968
I0619 14:48:21.667804 17263 layer_factory.hpp:77] Creating layer Eltwise48
I0619 14:48:21.667814 17263 net.cpp:459] Creating Layer Eltwise48
I0619 14:48:21.667821 17263 net.cpp:886] Eltwise48 <- Eltwise47_ReLU95_0_split_1
I0619 14:48:21.667829 17263 net.cpp:886] Eltwise48 <- Convolution97
I0619 14:48:21.667840 17263 net.cpp:860] Eltwise48 -> Eltwise48
I0619 14:48:21.667867 17263 net.cpp:509] Setting up Eltwise48
I0619 14:48:21.667877 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.667882 17263 net.cpp:524] Memory required for data: 2826437120
I0619 14:48:21.667888 17263 layer_factory.hpp:77] Creating layer ReLU97
I0619 14:48:21.667901 17263 net.cpp:459] Creating Layer ReLU97
I0619 14:48:21.667907 17263 net.cpp:886] ReLU97 <- Eltwise48
I0619 14:48:21.667914 17263 net.cpp:847] ReLU97 -> Eltwise48 (in-place)
I0619 14:48:21.667924 17263 net.cpp:509] Setting up ReLU97
I0619 14:48:21.667932 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.667937 17263 net.cpp:524] Memory required for data: 2828534272
I0619 14:48:21.667943 17263 layer_factory.hpp:77] Creating layer Eltwise48_ReLU97_0_split
I0619 14:48:21.667951 17263 net.cpp:459] Creating Layer Eltwise48_ReLU97_0_split
I0619 14:48:21.667956 17263 net.cpp:886] Eltwise48_ReLU97_0_split <- Eltwise48
I0619 14:48:21.667964 17263 net.cpp:860] Eltwise48_ReLU97_0_split -> Eltwise48_ReLU97_0_split_0
I0619 14:48:21.667978 17263 net.cpp:860] Eltwise48_ReLU97_0_split -> Eltwise48_ReLU97_0_split_1
I0619 14:48:21.668030 17263 net.cpp:509] Setting up Eltwise48_ReLU97_0_split
I0619 14:48:21.668040 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.668051 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.668073 17263 net.cpp:524] Memory required for data: 2832728576
I0619 14:48:21.668081 17263 layer_factory.hpp:77] Creating layer Convolution98
I0619 14:48:21.668097 17263 net.cpp:459] Creating Layer Convolution98
I0619 14:48:21.668104 17263 net.cpp:886] Convolution98 <- Eltwise48_ReLU97_0_split_0
I0619 14:48:21.668114 17263 net.cpp:860] Convolution98 -> Convolution98
I0619 14:48:21.670459 17263 net.cpp:509] Setting up Convolution98
I0619 14:48:21.670472 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.670478 17263 net.cpp:524] Memory required for data: 2834825728
I0619 14:48:21.670492 17263 layer_factory.hpp:77] Creating layer BatchNorm98
I0619 14:48:21.670508 17263 net.cpp:459] Creating Layer BatchNorm98
I0619 14:48:21.670516 17263 net.cpp:886] BatchNorm98 <- Convolution98
I0619 14:48:21.670524 17263 net.cpp:847] BatchNorm98 -> Convolution98 (in-place)
I0619 14:48:21.670837 17263 net.cpp:509] Setting up BatchNorm98
I0619 14:48:21.670850 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.670855 17263 net.cpp:524] Memory required for data: 2836922880
I0619 14:48:21.670871 17263 layer_factory.hpp:77] Creating layer Scale98
I0619 14:48:21.670881 17263 net.cpp:459] Creating Layer Scale98
I0619 14:48:21.670887 17263 net.cpp:886] Scale98 <- Convolution98
I0619 14:48:21.670895 17263 net.cpp:847] Scale98 -> Convolution98 (in-place)
I0619 14:48:21.670950 17263 layer_factory.hpp:77] Creating layer Scale98
I0619 14:48:21.671133 17263 net.cpp:509] Setting up Scale98
I0619 14:48:21.671144 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.671149 17263 net.cpp:524] Memory required for data: 2839020032
I0619 14:48:21.671161 17263 layer_factory.hpp:77] Creating layer ReLU98
I0619 14:48:21.671174 17263 net.cpp:459] Creating Layer ReLU98
I0619 14:48:21.671180 17263 net.cpp:886] ReLU98 <- Convolution98
I0619 14:48:21.671187 17263 net.cpp:847] ReLU98 -> Convolution98 (in-place)
I0619 14:48:21.671197 17263 net.cpp:509] Setting up ReLU98
I0619 14:48:21.671205 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.671210 17263 net.cpp:524] Memory required for data: 2841117184
I0619 14:48:21.671216 17263 layer_factory.hpp:77] Creating layer Convolution99
I0619 14:48:21.671231 17263 net.cpp:459] Creating Layer Convolution99
I0619 14:48:21.671237 17263 net.cpp:886] Convolution99 <- Convolution98
I0619 14:48:21.671247 17263 net.cpp:860] Convolution99 -> Convolution99
I0619 14:48:21.673568 17263 net.cpp:509] Setting up Convolution99
I0619 14:48:21.673581 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.673588 17263 net.cpp:524] Memory required for data: 2843214336
I0619 14:48:21.673600 17263 layer_factory.hpp:77] Creating layer BatchNorm99
I0619 14:48:21.673614 17263 net.cpp:459] Creating Layer BatchNorm99
I0619 14:48:21.673620 17263 net.cpp:886] BatchNorm99 <- Convolution99
I0619 14:48:21.673629 17263 net.cpp:847] BatchNorm99 -> Convolution99 (in-place)
I0619 14:48:21.673938 17263 net.cpp:509] Setting up BatchNorm99
I0619 14:48:21.673949 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.673954 17263 net.cpp:524] Memory required for data: 2845311488
I0619 14:48:21.673969 17263 layer_factory.hpp:77] Creating layer Scale99
I0619 14:48:21.673982 17263 net.cpp:459] Creating Layer Scale99
I0619 14:48:21.673988 17263 net.cpp:886] Scale99 <- Convolution99
I0619 14:48:21.673996 17263 net.cpp:847] Scale99 -> Convolution99 (in-place)
I0619 14:48:21.674046 17263 layer_factory.hpp:77] Creating layer Scale99
I0619 14:48:21.674239 17263 net.cpp:509] Setting up Scale99
I0619 14:48:21.674250 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.674257 17263 net.cpp:524] Memory required for data: 2847408640
I0619 14:48:21.674269 17263 layer_factory.hpp:77] Creating layer Eltwise49
I0619 14:48:21.674283 17263 net.cpp:459] Creating Layer Eltwise49
I0619 14:48:21.674289 17263 net.cpp:886] Eltwise49 <- Eltwise48_ReLU97_0_split_1
I0619 14:48:21.674298 17263 net.cpp:886] Eltwise49 <- Convolution99
I0619 14:48:21.674310 17263 net.cpp:860] Eltwise49 -> Eltwise49
I0619 14:48:21.674371 17263 net.cpp:509] Setting up Eltwise49
I0619 14:48:21.674384 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.674389 17263 net.cpp:524] Memory required for data: 2849505792
I0619 14:48:21.674396 17263 layer_factory.hpp:77] Creating layer ReLU99
I0619 14:48:21.674404 17263 net.cpp:459] Creating Layer ReLU99
I0619 14:48:21.674410 17263 net.cpp:886] ReLU99 <- Eltwise49
I0619 14:48:21.674418 17263 net.cpp:847] ReLU99 -> Eltwise49 (in-place)
I0619 14:48:21.674427 17263 net.cpp:509] Setting up ReLU99
I0619 14:48:21.674435 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.674440 17263 net.cpp:524] Memory required for data: 2851602944
I0619 14:48:21.674446 17263 layer_factory.hpp:77] Creating layer Eltwise49_ReLU99_0_split
I0619 14:48:21.674458 17263 net.cpp:459] Creating Layer Eltwise49_ReLU99_0_split
I0619 14:48:21.674463 17263 net.cpp:886] Eltwise49_ReLU99_0_split <- Eltwise49
I0619 14:48:21.674471 17263 net.cpp:860] Eltwise49_ReLU99_0_split -> Eltwise49_ReLU99_0_split_0
I0619 14:48:21.674481 17263 net.cpp:860] Eltwise49_ReLU99_0_split -> Eltwise49_ReLU99_0_split_1
I0619 14:48:21.674540 17263 net.cpp:509] Setting up Eltwise49_ReLU99_0_split
I0619 14:48:21.674549 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.674556 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.674561 17263 net.cpp:524] Memory required for data: 2855797248
I0619 14:48:21.674567 17263 layer_factory.hpp:77] Creating layer Convolution100
I0619 14:48:21.674581 17263 net.cpp:459] Creating Layer Convolution100
I0619 14:48:21.674587 17263 net.cpp:886] Convolution100 <- Eltwise49_ReLU99_0_split_0
I0619 14:48:21.674597 17263 net.cpp:860] Convolution100 -> Convolution100
I0619 14:48:21.676846 17263 net.cpp:509] Setting up Convolution100
I0619 14:48:21.676864 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.676870 17263 net.cpp:524] Memory required for data: 2857894400
I0619 14:48:21.676884 17263 layer_factory.hpp:77] Creating layer BatchNorm100
I0619 14:48:21.676898 17263 net.cpp:459] Creating Layer BatchNorm100
I0619 14:48:21.676904 17263 net.cpp:886] BatchNorm100 <- Convolution100
I0619 14:48:21.676913 17263 net.cpp:847] BatchNorm100 -> Convolution100 (in-place)
I0619 14:48:21.677203 17263 net.cpp:509] Setting up BatchNorm100
I0619 14:48:21.677214 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.677219 17263 net.cpp:524] Memory required for data: 2859991552
I0619 14:48:21.677234 17263 layer_factory.hpp:77] Creating layer Scale100
I0619 14:48:21.677244 17263 net.cpp:459] Creating Layer Scale100
I0619 14:48:21.677250 17263 net.cpp:886] Scale100 <- Convolution100
I0619 14:48:21.677258 17263 net.cpp:847] Scale100 -> Convolution100 (in-place)
I0619 14:48:21.677310 17263 layer_factory.hpp:77] Creating layer Scale100
I0619 14:48:21.677481 17263 net.cpp:509] Setting up Scale100
I0619 14:48:21.677491 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.677496 17263 net.cpp:524] Memory required for data: 2862088704
I0619 14:48:21.677508 17263 layer_factory.hpp:77] Creating layer ReLU100
I0619 14:48:21.677520 17263 net.cpp:459] Creating Layer ReLU100
I0619 14:48:21.677525 17263 net.cpp:886] ReLU100 <- Convolution100
I0619 14:48:21.677533 17263 net.cpp:847] ReLU100 -> Convolution100 (in-place)
I0619 14:48:21.677541 17263 net.cpp:509] Setting up ReLU100
I0619 14:48:21.677548 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.677553 17263 net.cpp:524] Memory required for data: 2864185856
I0619 14:48:21.677558 17263 layer_factory.hpp:77] Creating layer Convolution101
I0619 14:48:21.677577 17263 net.cpp:459] Creating Layer Convolution101
I0619 14:48:21.677583 17263 net.cpp:886] Convolution101 <- Convolution100
I0619 14:48:21.677592 17263 net.cpp:860] Convolution101 -> Convolution101
I0619 14:48:21.679788 17263 net.cpp:509] Setting up Convolution101
I0619 14:48:21.679801 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.679806 17263 net.cpp:524] Memory required for data: 2866283008
I0619 14:48:21.679823 17263 layer_factory.hpp:77] Creating layer BatchNorm101
I0619 14:48:21.679853 17263 net.cpp:459] Creating Layer BatchNorm101
I0619 14:48:21.679860 17263 net.cpp:886] BatchNorm101 <- Convolution101
I0619 14:48:21.679869 17263 net.cpp:847] BatchNorm101 -> Convolution101 (in-place)
I0619 14:48:21.680166 17263 net.cpp:509] Setting up BatchNorm101
I0619 14:48:21.680177 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.680182 17263 net.cpp:524] Memory required for data: 2868380160
I0619 14:48:21.680198 17263 layer_factory.hpp:77] Creating layer Scale101
I0619 14:48:21.680210 17263 net.cpp:459] Creating Layer Scale101
I0619 14:48:21.680217 17263 net.cpp:886] Scale101 <- Convolution101
I0619 14:48:21.680223 17263 net.cpp:847] Scale101 -> Convolution101 (in-place)
I0619 14:48:21.680275 17263 layer_factory.hpp:77] Creating layer Scale101
I0619 14:48:21.680447 17263 net.cpp:509] Setting up Scale101
I0619 14:48:21.680457 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.680464 17263 net.cpp:524] Memory required for data: 2870477312
I0619 14:48:21.680475 17263 layer_factory.hpp:77] Creating layer Eltwise50
I0619 14:48:21.680487 17263 net.cpp:459] Creating Layer Eltwise50
I0619 14:48:21.680495 17263 net.cpp:886] Eltwise50 <- Eltwise49_ReLU99_0_split_1
I0619 14:48:21.680501 17263 net.cpp:886] Eltwise50 <- Convolution101
I0619 14:48:21.680510 17263 net.cpp:860] Eltwise50 -> Eltwise50
I0619 14:48:21.680537 17263 net.cpp:509] Setting up Eltwise50
I0619 14:48:21.680546 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.680552 17263 net.cpp:524] Memory required for data: 2872574464
I0619 14:48:21.680557 17263 layer_factory.hpp:77] Creating layer ReLU101
I0619 14:48:21.680564 17263 net.cpp:459] Creating Layer ReLU101
I0619 14:48:21.680570 17263 net.cpp:886] ReLU101 <- Eltwise50
I0619 14:48:21.680577 17263 net.cpp:847] ReLU101 -> Eltwise50 (in-place)
I0619 14:48:21.680585 17263 net.cpp:509] Setting up ReLU101
I0619 14:48:21.680593 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.680598 17263 net.cpp:524] Memory required for data: 2874671616
I0619 14:48:21.680603 17263 layer_factory.hpp:77] Creating layer Eltwise50_ReLU101_0_split
I0619 14:48:21.680613 17263 net.cpp:459] Creating Layer Eltwise50_ReLU101_0_split
I0619 14:48:21.680619 17263 net.cpp:886] Eltwise50_ReLU101_0_split <- Eltwise50
I0619 14:48:21.680626 17263 net.cpp:860] Eltwise50_ReLU101_0_split -> Eltwise50_ReLU101_0_split_0
I0619 14:48:21.680635 17263 net.cpp:860] Eltwise50_ReLU101_0_split -> Eltwise50_ReLU101_0_split_1
I0619 14:48:21.680688 17263 net.cpp:509] Setting up Eltwise50_ReLU101_0_split
I0619 14:48:21.680697 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.680704 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.680709 17263 net.cpp:524] Memory required for data: 2878865920
I0619 14:48:21.680714 17263 layer_factory.hpp:77] Creating layer Convolution102
I0619 14:48:21.680799 17263 net.cpp:459] Creating Layer Convolution102
I0619 14:48:21.680807 17263 net.cpp:886] Convolution102 <- Eltwise50_ReLU101_0_split_0
I0619 14:48:21.680817 17263 net.cpp:860] Convolution102 -> Convolution102
I0619 14:48:21.683878 17263 net.cpp:509] Setting up Convolution102
I0619 14:48:21.683899 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.683905 17263 net.cpp:524] Memory required for data: 2880963072
I0619 14:48:21.683920 17263 layer_factory.hpp:77] Creating layer BatchNorm102
I0619 14:48:21.683935 17263 net.cpp:459] Creating Layer BatchNorm102
I0619 14:48:21.683943 17263 net.cpp:886] BatchNorm102 <- Convolution102
I0619 14:48:21.683954 17263 net.cpp:847] BatchNorm102 -> Convolution102 (in-place)
I0619 14:48:21.684250 17263 net.cpp:509] Setting up BatchNorm102
I0619 14:48:21.684262 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.684267 17263 net.cpp:524] Memory required for data: 2883060224
I0619 14:48:21.684285 17263 layer_factory.hpp:77] Creating layer Scale102
I0619 14:48:21.684295 17263 net.cpp:459] Creating Layer Scale102
I0619 14:48:21.684305 17263 net.cpp:886] Scale102 <- Convolution102
I0619 14:48:21.684332 17263 net.cpp:847] Scale102 -> Convolution102 (in-place)
I0619 14:48:21.684391 17263 layer_factory.hpp:77] Creating layer Scale102
I0619 14:48:21.684563 17263 net.cpp:509] Setting up Scale102
I0619 14:48:21.684573 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.684579 17263 net.cpp:524] Memory required for data: 2885157376
I0619 14:48:21.684595 17263 layer_factory.hpp:77] Creating layer ReLU102
I0619 14:48:21.684604 17263 net.cpp:459] Creating Layer ReLU102
I0619 14:48:21.684610 17263 net.cpp:886] ReLU102 <- Convolution102
I0619 14:48:21.684620 17263 net.cpp:847] ReLU102 -> Convolution102 (in-place)
I0619 14:48:21.684629 17263 net.cpp:509] Setting up ReLU102
I0619 14:48:21.684638 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.684643 17263 net.cpp:524] Memory required for data: 2887254528
I0619 14:48:21.684648 17263 layer_factory.hpp:77] Creating layer Convolution103
I0619 14:48:21.684660 17263 net.cpp:459] Creating Layer Convolution103
I0619 14:48:21.684665 17263 net.cpp:886] Convolution103 <- Convolution102
I0619 14:48:21.684677 17263 net.cpp:860] Convolution103 -> Convolution103
I0619 14:48:21.686872 17263 net.cpp:509] Setting up Convolution103
I0619 14:48:21.686885 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.686892 17263 net.cpp:524] Memory required for data: 2889351680
I0619 14:48:21.686904 17263 layer_factory.hpp:77] Creating layer BatchNorm103
I0619 14:48:21.686914 17263 net.cpp:459] Creating Layer BatchNorm103
I0619 14:48:21.686920 17263 net.cpp:886] BatchNorm103 <- Convolution103
I0619 14:48:21.686931 17263 net.cpp:847] BatchNorm103 -> Convolution103 (in-place)
I0619 14:48:21.687203 17263 net.cpp:509] Setting up BatchNorm103
I0619 14:48:21.687212 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.687217 17263 net.cpp:524] Memory required for data: 2891448832
I0619 14:48:21.687232 17263 layer_factory.hpp:77] Creating layer Scale103
I0619 14:48:21.687240 17263 net.cpp:459] Creating Layer Scale103
I0619 14:48:21.687247 17263 net.cpp:886] Scale103 <- Convolution103
I0619 14:48:21.687255 17263 net.cpp:847] Scale103 -> Convolution103 (in-place)
I0619 14:48:21.687301 17263 layer_factory.hpp:77] Creating layer Scale103
I0619 14:48:21.687464 17263 net.cpp:509] Setting up Scale103
I0619 14:48:21.687474 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.687479 17263 net.cpp:524] Memory required for data: 2893545984
I0619 14:48:21.687490 17263 layer_factory.hpp:77] Creating layer Eltwise51
I0619 14:48:21.687500 17263 net.cpp:459] Creating Layer Eltwise51
I0619 14:48:21.687506 17263 net.cpp:886] Eltwise51 <- Eltwise50_ReLU101_0_split_1
I0619 14:48:21.687513 17263 net.cpp:886] Eltwise51 <- Convolution103
I0619 14:48:21.687523 17263 net.cpp:860] Eltwise51 -> Eltwise51
I0619 14:48:21.687548 17263 net.cpp:509] Setting up Eltwise51
I0619 14:48:21.687556 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.687561 17263 net.cpp:524] Memory required for data: 2895643136
I0619 14:48:21.687566 17263 layer_factory.hpp:77] Creating layer ReLU103
I0619 14:48:21.687577 17263 net.cpp:459] Creating Layer ReLU103
I0619 14:48:21.687582 17263 net.cpp:886] ReLU103 <- Eltwise51
I0619 14:48:21.687588 17263 net.cpp:847] ReLU103 -> Eltwise51 (in-place)
I0619 14:48:21.687597 17263 net.cpp:509] Setting up ReLU103
I0619 14:48:21.687604 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.687608 17263 net.cpp:524] Memory required for data: 2897740288
I0619 14:48:21.687613 17263 layer_factory.hpp:77] Creating layer Eltwise51_ReLU103_0_split
I0619 14:48:21.687621 17263 net.cpp:459] Creating Layer Eltwise51_ReLU103_0_split
I0619 14:48:21.687626 17263 net.cpp:886] Eltwise51_ReLU103_0_split <- Eltwise51
I0619 14:48:21.687635 17263 net.cpp:860] Eltwise51_ReLU103_0_split -> Eltwise51_ReLU103_0_split_0
I0619 14:48:21.687645 17263 net.cpp:860] Eltwise51_ReLU103_0_split -> Eltwise51_ReLU103_0_split_1
I0619 14:48:21.687692 17263 net.cpp:509] Setting up Eltwise51_ReLU103_0_split
I0619 14:48:21.687705 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.687726 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.687732 17263 net.cpp:524] Memory required for data: 2901934592
I0619 14:48:21.687737 17263 layer_factory.hpp:77] Creating layer Convolution104
I0619 14:48:21.687752 17263 net.cpp:459] Creating Layer Convolution104
I0619 14:48:21.687759 17263 net.cpp:886] Convolution104 <- Eltwise51_ReLU103_0_split_0
I0619 14:48:21.687768 17263 net.cpp:860] Convolution104 -> Convolution104
I0619 14:48:21.689839 17263 net.cpp:509] Setting up Convolution104
I0619 14:48:21.689851 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.689857 17263 net.cpp:524] Memory required for data: 2904031744
I0619 14:48:21.689869 17263 layer_factory.hpp:77] Creating layer BatchNorm104
I0619 14:48:21.689880 17263 net.cpp:459] Creating Layer BatchNorm104
I0619 14:48:21.689887 17263 net.cpp:886] BatchNorm104 <- Convolution104
I0619 14:48:21.689894 17263 net.cpp:847] BatchNorm104 -> Convolution104 (in-place)
I0619 14:48:21.690176 17263 net.cpp:509] Setting up BatchNorm104
I0619 14:48:21.690186 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.690191 17263 net.cpp:524] Memory required for data: 2906128896
I0619 14:48:21.690206 17263 layer_factory.hpp:77] Creating layer Scale104
I0619 14:48:21.690214 17263 net.cpp:459] Creating Layer Scale104
I0619 14:48:21.690219 17263 net.cpp:886] Scale104 <- Convolution104
I0619 14:48:21.690227 17263 net.cpp:847] Scale104 -> Convolution104 (in-place)
I0619 14:48:21.690279 17263 layer_factory.hpp:77] Creating layer Scale104
I0619 14:48:21.690445 17263 net.cpp:509] Setting up Scale104
I0619 14:48:21.690457 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.690461 17263 net.cpp:524] Memory required for data: 2908226048
I0619 14:48:21.690474 17263 layer_factory.hpp:77] Creating layer ReLU104
I0619 14:48:21.690485 17263 net.cpp:459] Creating Layer ReLU104
I0619 14:48:21.690491 17263 net.cpp:886] ReLU104 <- Convolution104
I0619 14:48:21.690498 17263 net.cpp:847] ReLU104 -> Convolution104 (in-place)
I0619 14:48:21.690507 17263 net.cpp:509] Setting up ReLU104
I0619 14:48:21.690515 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.690518 17263 net.cpp:524] Memory required for data: 2910323200
I0619 14:48:21.690523 17263 layer_factory.hpp:77] Creating layer Convolution105
I0619 14:48:21.690539 17263 net.cpp:459] Creating Layer Convolution105
I0619 14:48:21.690546 17263 net.cpp:886] Convolution105 <- Convolution104
I0619 14:48:21.690557 17263 net.cpp:860] Convolution105 -> Convolution105
I0619 14:48:21.692618 17263 net.cpp:509] Setting up Convolution105
I0619 14:48:21.692631 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.692636 17263 net.cpp:524] Memory required for data: 2912420352
I0619 14:48:21.692647 17263 layer_factory.hpp:77] Creating layer BatchNorm105
I0619 14:48:21.692659 17263 net.cpp:459] Creating Layer BatchNorm105
I0619 14:48:21.692665 17263 net.cpp:886] BatchNorm105 <- Convolution105
I0619 14:48:21.692672 17263 net.cpp:847] BatchNorm105 -> Convolution105 (in-place)
I0619 14:48:21.692940 17263 net.cpp:509] Setting up BatchNorm105
I0619 14:48:21.692950 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.692955 17263 net.cpp:524] Memory required for data: 2914517504
I0619 14:48:21.692970 17263 layer_factory.hpp:77] Creating layer Scale105
I0619 14:48:21.692983 17263 net.cpp:459] Creating Layer Scale105
I0619 14:48:21.692989 17263 net.cpp:886] Scale105 <- Convolution105
I0619 14:48:21.692996 17263 net.cpp:847] Scale105 -> Convolution105 (in-place)
I0619 14:48:21.693044 17263 layer_factory.hpp:77] Creating layer Scale105
I0619 14:48:21.693213 17263 net.cpp:509] Setting up Scale105
I0619 14:48:21.693224 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.693228 17263 net.cpp:524] Memory required for data: 2916614656
I0619 14:48:21.693240 17263 layer_factory.hpp:77] Creating layer Eltwise52
I0619 14:48:21.693254 17263 net.cpp:459] Creating Layer Eltwise52
I0619 14:48:21.693264 17263 net.cpp:886] Eltwise52 <- Eltwise51_ReLU103_0_split_1
I0619 14:48:21.693287 17263 net.cpp:886] Eltwise52 <- Convolution105
I0619 14:48:21.693296 17263 net.cpp:860] Eltwise52 -> Eltwise52
I0619 14:48:21.693327 17263 net.cpp:509] Setting up Eltwise52
I0619 14:48:21.693336 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.693341 17263 net.cpp:524] Memory required for data: 2918711808
I0619 14:48:21.693346 17263 layer_factory.hpp:77] Creating layer ReLU105
I0619 14:48:21.693354 17263 net.cpp:459] Creating Layer ReLU105
I0619 14:48:21.693359 17263 net.cpp:886] ReLU105 <- Eltwise52
I0619 14:48:21.693369 17263 net.cpp:847] ReLU105 -> Eltwise52 (in-place)
I0619 14:48:21.693378 17263 net.cpp:509] Setting up ReLU105
I0619 14:48:21.693384 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.693389 17263 net.cpp:524] Memory required for data: 2920808960
I0619 14:48:21.693394 17263 layer_factory.hpp:77] Creating layer Eltwise52_ReLU105_0_split
I0619 14:48:21.693403 17263 net.cpp:459] Creating Layer Eltwise52_ReLU105_0_split
I0619 14:48:21.693408 17263 net.cpp:886] Eltwise52_ReLU105_0_split <- Eltwise52
I0619 14:48:21.693414 17263 net.cpp:860] Eltwise52_ReLU105_0_split -> Eltwise52_ReLU105_0_split_0
I0619 14:48:21.693423 17263 net.cpp:860] Eltwise52_ReLU105_0_split -> Eltwise52_ReLU105_0_split_1
I0619 14:48:21.693473 17263 net.cpp:509] Setting up Eltwise52_ReLU105_0_split
I0619 14:48:21.693481 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.693488 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.693492 17263 net.cpp:524] Memory required for data: 2925003264
I0619 14:48:21.693498 17263 layer_factory.hpp:77] Creating layer Convolution106
I0619 14:48:21.693509 17263 net.cpp:459] Creating Layer Convolution106
I0619 14:48:21.693516 17263 net.cpp:886] Convolution106 <- Eltwise52_ReLU105_0_split_0
I0619 14:48:21.693528 17263 net.cpp:860] Convolution106 -> Convolution106
I0619 14:48:21.695597 17263 net.cpp:509] Setting up Convolution106
I0619 14:48:21.695611 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.695616 17263 net.cpp:524] Memory required for data: 2927100416
I0619 14:48:21.695628 17263 layer_factory.hpp:77] Creating layer BatchNorm106
I0619 14:48:21.695637 17263 net.cpp:459] Creating Layer BatchNorm106
I0619 14:48:21.695643 17263 net.cpp:886] BatchNorm106 <- Convolution106
I0619 14:48:21.695653 17263 net.cpp:847] BatchNorm106 -> Convolution106 (in-place)
I0619 14:48:21.695924 17263 net.cpp:509] Setting up BatchNorm106
I0619 14:48:21.695935 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.695940 17263 net.cpp:524] Memory required for data: 2929197568
I0619 14:48:21.695953 17263 layer_factory.hpp:77] Creating layer Scale106
I0619 14:48:21.695962 17263 net.cpp:459] Creating Layer Scale106
I0619 14:48:21.695967 17263 net.cpp:886] Scale106 <- Convolution106
I0619 14:48:21.695977 17263 net.cpp:847] Scale106 -> Convolution106 (in-place)
I0619 14:48:21.696024 17263 layer_factory.hpp:77] Creating layer Scale106
I0619 14:48:21.696187 17263 net.cpp:509] Setting up Scale106
I0619 14:48:21.696197 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.696202 17263 net.cpp:524] Memory required for data: 2931294720
I0619 14:48:21.696213 17263 layer_factory.hpp:77] Creating layer ReLU106
I0619 14:48:21.696221 17263 net.cpp:459] Creating Layer ReLU106
I0619 14:48:21.696228 17263 net.cpp:886] ReLU106 <- Convolution106
I0619 14:48:21.696236 17263 net.cpp:847] ReLU106 -> Convolution106 (in-place)
I0619 14:48:21.696245 17263 net.cpp:509] Setting up ReLU106
I0619 14:48:21.696252 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.696256 17263 net.cpp:524] Memory required for data: 2933391872
I0619 14:48:21.696262 17263 layer_factory.hpp:77] Creating layer Convolution107
I0619 14:48:21.696275 17263 net.cpp:459] Creating Layer Convolution107
I0619 14:48:21.696281 17263 net.cpp:886] Convolution107 <- Convolution106
I0619 14:48:21.696290 17263 net.cpp:860] Convolution107 -> Convolution107
I0619 14:48:21.698348 17263 net.cpp:509] Setting up Convolution107
I0619 14:48:21.698377 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.698397 17263 net.cpp:524] Memory required for data: 2935489024
I0619 14:48:21.698411 17263 layer_factory.hpp:77] Creating layer BatchNorm107
I0619 14:48:21.698426 17263 net.cpp:459] Creating Layer BatchNorm107
I0619 14:48:21.698432 17263 net.cpp:886] BatchNorm107 <- Convolution107
I0619 14:48:21.698441 17263 net.cpp:847] BatchNorm107 -> Convolution107 (in-place)
I0619 14:48:21.698734 17263 net.cpp:509] Setting up BatchNorm107
I0619 14:48:21.698743 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.698748 17263 net.cpp:524] Memory required for data: 2937586176
I0619 14:48:21.698762 17263 layer_factory.hpp:77] Creating layer Scale107
I0619 14:48:21.698771 17263 net.cpp:459] Creating Layer Scale107
I0619 14:48:21.698776 17263 net.cpp:886] Scale107 <- Convolution107
I0619 14:48:21.698783 17263 net.cpp:847] Scale107 -> Convolution107 (in-place)
I0619 14:48:21.698830 17263 layer_factory.hpp:77] Creating layer Scale107
I0619 14:48:21.698987 17263 net.cpp:509] Setting up Scale107
I0619 14:48:21.698994 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.698999 17263 net.cpp:524] Memory required for data: 2939683328
I0619 14:48:21.699010 17263 layer_factory.hpp:77] Creating layer Eltwise53
I0619 14:48:21.699021 17263 net.cpp:459] Creating Layer Eltwise53
I0619 14:48:21.699028 17263 net.cpp:886] Eltwise53 <- Eltwise52_ReLU105_0_split_1
I0619 14:48:21.699034 17263 net.cpp:886] Eltwise53 <- Convolution107
I0619 14:48:21.699041 17263 net.cpp:860] Eltwise53 -> Eltwise53
I0619 14:48:21.699064 17263 net.cpp:509] Setting up Eltwise53
I0619 14:48:21.699072 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.699077 17263 net.cpp:524] Memory required for data: 2941780480
I0619 14:48:21.699081 17263 layer_factory.hpp:77] Creating layer ReLU107
I0619 14:48:21.699093 17263 net.cpp:459] Creating Layer ReLU107
I0619 14:48:21.699098 17263 net.cpp:886] ReLU107 <- Eltwise53
I0619 14:48:21.699105 17263 net.cpp:847] ReLU107 -> Eltwise53 (in-place)
I0619 14:48:21.699113 17263 net.cpp:509] Setting up ReLU107
I0619 14:48:21.699120 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.699125 17263 net.cpp:524] Memory required for data: 2943877632
I0619 14:48:21.699129 17263 layer_factory.hpp:77] Creating layer Eltwise53_ReLU107_0_split
I0619 14:48:21.699136 17263 net.cpp:459] Creating Layer Eltwise53_ReLU107_0_split
I0619 14:48:21.699141 17263 net.cpp:886] Eltwise53_ReLU107_0_split <- Eltwise53
I0619 14:48:21.699147 17263 net.cpp:860] Eltwise53_ReLU107_0_split -> Eltwise53_ReLU107_0_split_0
I0619 14:48:21.699156 17263 net.cpp:860] Eltwise53_ReLU107_0_split -> Eltwise53_ReLU107_0_split_1
I0619 14:48:21.699203 17263 net.cpp:509] Setting up Eltwise53_ReLU107_0_split
I0619 14:48:21.699211 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.699218 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.699223 17263 net.cpp:524] Memory required for data: 2948071936
I0619 14:48:21.699228 17263 layer_factory.hpp:77] Creating layer Convolution108
I0619 14:48:21.699240 17263 net.cpp:459] Creating Layer Convolution108
I0619 14:48:21.699245 17263 net.cpp:886] Convolution108 <- Eltwise53_ReLU107_0_split_0
I0619 14:48:21.699254 17263 net.cpp:860] Convolution108 -> Convolution108
I0619 14:48:21.701217 17263 net.cpp:509] Setting up Convolution108
I0619 14:48:21.701228 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.701233 17263 net.cpp:524] Memory required for data: 2950169088
I0619 14:48:21.701244 17263 layer_factory.hpp:77] Creating layer BatchNorm108
I0619 14:48:21.701256 17263 net.cpp:459] Creating Layer BatchNorm108
I0619 14:48:21.701261 17263 net.cpp:886] BatchNorm108 <- Convolution108
I0619 14:48:21.701268 17263 net.cpp:847] BatchNorm108 -> Convolution108 (in-place)
I0619 14:48:21.701534 17263 net.cpp:509] Setting up BatchNorm108
I0619 14:48:21.701545 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.701548 17263 net.cpp:524] Memory required for data: 2952266240
I0619 14:48:21.701566 17263 layer_factory.hpp:77] Creating layer Scale108
I0619 14:48:21.701591 17263 net.cpp:459] Creating Layer Scale108
I0619 14:48:21.701598 17263 net.cpp:886] Scale108 <- Convolution108
I0619 14:48:21.701606 17263 net.cpp:847] Scale108 -> Convolution108 (in-place)
I0619 14:48:21.701654 17263 layer_factory.hpp:77] Creating layer Scale108
I0619 14:48:21.701810 17263 net.cpp:509] Setting up Scale108
I0619 14:48:21.701819 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.701824 17263 net.cpp:524] Memory required for data: 2954363392
I0619 14:48:21.701835 17263 layer_factory.hpp:77] Creating layer ReLU108
I0619 14:48:21.701846 17263 net.cpp:459] Creating Layer ReLU108
I0619 14:48:21.701853 17263 net.cpp:886] ReLU108 <- Convolution108
I0619 14:48:21.701859 17263 net.cpp:847] ReLU108 -> Convolution108 (in-place)
I0619 14:48:21.701867 17263 net.cpp:509] Setting up ReLU108
I0619 14:48:21.701874 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.701877 17263 net.cpp:524] Memory required for data: 2956460544
I0619 14:48:21.701882 17263 layer_factory.hpp:77] Creating layer Convolution109
I0619 14:48:21.701896 17263 net.cpp:459] Creating Layer Convolution109
I0619 14:48:21.701901 17263 net.cpp:886] Convolution109 <- Convolution108
I0619 14:48:21.701911 17263 net.cpp:860] Convolution109 -> Convolution109
I0619 14:48:21.704615 17263 net.cpp:509] Setting up Convolution109
I0619 14:48:21.704633 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.704639 17263 net.cpp:524] Memory required for data: 2958557696
I0619 14:48:21.704653 17263 layer_factory.hpp:77] Creating layer BatchNorm109
I0619 14:48:21.704664 17263 net.cpp:459] Creating Layer BatchNorm109
I0619 14:48:21.704671 17263 net.cpp:886] BatchNorm109 <- Convolution109
I0619 14:48:21.704681 17263 net.cpp:847] BatchNorm109 -> Convolution109 (in-place)
I0619 14:48:21.704951 17263 net.cpp:509] Setting up BatchNorm109
I0619 14:48:21.704960 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.704965 17263 net.cpp:524] Memory required for data: 2960654848
I0619 14:48:21.704980 17263 layer_factory.hpp:77] Creating layer Scale109
I0619 14:48:21.704993 17263 net.cpp:459] Creating Layer Scale109
I0619 14:48:21.704998 17263 net.cpp:886] Scale109 <- Convolution109
I0619 14:48:21.705005 17263 net.cpp:847] Scale109 -> Convolution109 (in-place)
I0619 14:48:21.705054 17263 layer_factory.hpp:77] Creating layer Scale109
I0619 14:48:21.705215 17263 net.cpp:509] Setting up Scale109
I0619 14:48:21.705224 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.705229 17263 net.cpp:524] Memory required for data: 2962752000
I0619 14:48:21.705243 17263 layer_factory.hpp:77] Creating layer Eltwise54
I0619 14:48:21.705252 17263 net.cpp:459] Creating Layer Eltwise54
I0619 14:48:21.705258 17263 net.cpp:886] Eltwise54 <- Eltwise53_ReLU107_0_split_1
I0619 14:48:21.705265 17263 net.cpp:886] Eltwise54 <- Convolution109
I0619 14:48:21.705276 17263 net.cpp:860] Eltwise54 -> Eltwise54
I0619 14:48:21.705299 17263 net.cpp:509] Setting up Eltwise54
I0619 14:48:21.705308 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.705312 17263 net.cpp:524] Memory required for data: 2964849152
I0619 14:48:21.705317 17263 layer_factory.hpp:77] Creating layer ReLU109
I0619 14:48:21.705323 17263 net.cpp:459] Creating Layer ReLU109
I0619 14:48:21.705328 17263 net.cpp:886] ReLU109 <- Eltwise54
I0619 14:48:21.705338 17263 net.cpp:847] ReLU109 -> Eltwise54 (in-place)
I0619 14:48:21.705346 17263 net.cpp:509] Setting up ReLU109
I0619 14:48:21.705353 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.705358 17263 net.cpp:524] Memory required for data: 2966946304
I0619 14:48:21.705363 17263 layer_factory.hpp:77] Creating layer Pooling4
I0619 14:48:21.705371 17263 net.cpp:459] Creating Layer Pooling4
I0619 14:48:21.705376 17263 net.cpp:886] Pooling4 <- Eltwise54
I0619 14:48:21.705384 17263 net.cpp:860] Pooling4 -> Pooling4
I0619 14:48:21.705415 17263 net.cpp:509] Setting up Pooling4
I0619 14:48:21.705422 17263 net.cpp:516] Top shape: 128 64 1 1 (8192)
I0619 14:48:21.705431 17263 net.cpp:524] Memory required for data: 2966979072
I0619 14:48:21.705452 17263 layer_factory.hpp:77] Creating layer InnerProduct1
I0619 14:48:21.705466 17263 net.cpp:459] Creating Layer InnerProduct1
I0619 14:48:21.705471 17263 net.cpp:886] InnerProduct1 <- Pooling4
I0619 14:48:21.705479 17263 net.cpp:860] InnerProduct1 -> InnerProduct1
I0619 14:48:21.705665 17263 net.cpp:509] Setting up InnerProduct1
I0619 14:48:21.705677 17263 net.cpp:516] Top shape: 128 10 (1280)
I0619 14:48:21.705682 17263 net.cpp:524] Memory required for data: 2966984192
I0619 14:48:21.705693 17263 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0619 14:48:21.705705 17263 net.cpp:459] Creating Layer SoftmaxWithLoss1
I0619 14:48:21.705711 17263 net.cpp:886] SoftmaxWithLoss1 <- InnerProduct1
I0619 14:48:21.705718 17263 net.cpp:886] SoftmaxWithLoss1 <- Data2
I0619 14:48:21.705729 17263 net.cpp:860] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0619 14:48:21.705744 17263 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0619 14:48:21.705867 17263 net.cpp:509] Setting up SoftmaxWithLoss1
I0619 14:48:21.705875 17263 net.cpp:516] Top shape: (1)
I0619 14:48:21.705880 17263 net.cpp:519]     with loss weight 1
I0619 14:48:21.705905 17263 net.cpp:524] Memory required for data: 2966984196
I0619 14:48:21.705910 17263 net.cpp:585] SoftmaxWithLoss1 needs backward computation.
I0619 14:48:21.705916 17263 net.cpp:585] InnerProduct1 needs backward computation.
I0619 14:48:21.705920 17263 net.cpp:585] Pooling4 needs backward computation.
I0619 14:48:21.705925 17263 net.cpp:585] ReLU109 needs backward computation.
I0619 14:48:21.705930 17263 net.cpp:585] Eltwise54 needs backward computation.
I0619 14:48:21.705935 17263 net.cpp:585] Scale109 needs backward computation.
I0619 14:48:21.705940 17263 net.cpp:585] BatchNorm109 needs backward computation.
I0619 14:48:21.705945 17263 net.cpp:585] Convolution109 needs backward computation.
I0619 14:48:21.705950 17263 net.cpp:585] ReLU108 needs backward computation.
I0619 14:48:21.705955 17263 net.cpp:585] Scale108 needs backward computation.
I0619 14:48:21.705958 17263 net.cpp:585] BatchNorm108 needs backward computation.
I0619 14:48:21.705963 17263 net.cpp:585] Convolution108 needs backward computation.
I0619 14:48:21.705968 17263 net.cpp:585] Eltwise53_ReLU107_0_split needs backward computation.
I0619 14:48:21.705973 17263 net.cpp:585] ReLU107 needs backward computation.
I0619 14:48:21.705977 17263 net.cpp:585] Eltwise53 needs backward computation.
I0619 14:48:21.705983 17263 net.cpp:585] Scale107 needs backward computation.
I0619 14:48:21.705987 17263 net.cpp:585] BatchNorm107 needs backward computation.
I0619 14:48:21.705991 17263 net.cpp:585] Convolution107 needs backward computation.
I0619 14:48:21.705996 17263 net.cpp:585] ReLU106 needs backward computation.
I0619 14:48:21.706001 17263 net.cpp:585] Scale106 needs backward computation.
I0619 14:48:21.706006 17263 net.cpp:585] BatchNorm106 needs backward computation.
I0619 14:48:21.706009 17263 net.cpp:585] Convolution106 needs backward computation.
I0619 14:48:21.706014 17263 net.cpp:585] Eltwise52_ReLU105_0_split needs backward computation.
I0619 14:48:21.706019 17263 net.cpp:585] ReLU105 needs backward computation.
I0619 14:48:21.706023 17263 net.cpp:585] Eltwise52 needs backward computation.
I0619 14:48:21.706029 17263 net.cpp:585] Scale105 needs backward computation.
I0619 14:48:21.706033 17263 net.cpp:585] BatchNorm105 needs backward computation.
I0619 14:48:21.706038 17263 net.cpp:585] Convolution105 needs backward computation.
I0619 14:48:21.706043 17263 net.cpp:585] ReLU104 needs backward computation.
I0619 14:48:21.706046 17263 net.cpp:585] Scale104 needs backward computation.
I0619 14:48:21.706051 17263 net.cpp:585] BatchNorm104 needs backward computation.
I0619 14:48:21.706055 17263 net.cpp:585] Convolution104 needs backward computation.
I0619 14:48:21.706060 17263 net.cpp:585] Eltwise51_ReLU103_0_split needs backward computation.
I0619 14:48:21.706065 17263 net.cpp:585] ReLU103 needs backward computation.
I0619 14:48:21.706073 17263 net.cpp:585] Eltwise51 needs backward computation.
I0619 14:48:21.706092 17263 net.cpp:585] Scale103 needs backward computation.
I0619 14:48:21.706099 17263 net.cpp:585] BatchNorm103 needs backward computation.
I0619 14:48:21.706102 17263 net.cpp:585] Convolution103 needs backward computation.
I0619 14:48:21.706107 17263 net.cpp:585] ReLU102 needs backward computation.
I0619 14:48:21.706111 17263 net.cpp:585] Scale102 needs backward computation.
I0619 14:48:21.706116 17263 net.cpp:585] BatchNorm102 needs backward computation.
I0619 14:48:21.706120 17263 net.cpp:585] Convolution102 needs backward computation.
I0619 14:48:21.706125 17263 net.cpp:585] Eltwise50_ReLU101_0_split needs backward computation.
I0619 14:48:21.706130 17263 net.cpp:585] ReLU101 needs backward computation.
I0619 14:48:21.706135 17263 net.cpp:585] Eltwise50 needs backward computation.
I0619 14:48:21.706140 17263 net.cpp:585] Scale101 needs backward computation.
I0619 14:48:21.706145 17263 net.cpp:585] BatchNorm101 needs backward computation.
I0619 14:48:21.706148 17263 net.cpp:585] Convolution101 needs backward computation.
I0619 14:48:21.706153 17263 net.cpp:585] ReLU100 needs backward computation.
I0619 14:48:21.706157 17263 net.cpp:585] Scale100 needs backward computation.
I0619 14:48:21.706161 17263 net.cpp:585] BatchNorm100 needs backward computation.
I0619 14:48:21.706166 17263 net.cpp:585] Convolution100 needs backward computation.
I0619 14:48:21.706171 17263 net.cpp:585] Eltwise49_ReLU99_0_split needs backward computation.
I0619 14:48:21.706176 17263 net.cpp:585] ReLU99 needs backward computation.
I0619 14:48:21.706181 17263 net.cpp:585] Eltwise49 needs backward computation.
I0619 14:48:21.706187 17263 net.cpp:585] Scale99 needs backward computation.
I0619 14:48:21.706192 17263 net.cpp:585] BatchNorm99 needs backward computation.
I0619 14:48:21.706195 17263 net.cpp:585] Convolution99 needs backward computation.
I0619 14:48:21.706200 17263 net.cpp:585] ReLU98 needs backward computation.
I0619 14:48:21.706205 17263 net.cpp:585] Scale98 needs backward computation.
I0619 14:48:21.706209 17263 net.cpp:585] BatchNorm98 needs backward computation.
I0619 14:48:21.706214 17263 net.cpp:585] Convolution98 needs backward computation.
I0619 14:48:21.706219 17263 net.cpp:585] Eltwise48_ReLU97_0_split needs backward computation.
I0619 14:48:21.706223 17263 net.cpp:585] ReLU97 needs backward computation.
I0619 14:48:21.706228 17263 net.cpp:585] Eltwise48 needs backward computation.
I0619 14:48:21.706234 17263 net.cpp:585] Scale97 needs backward computation.
I0619 14:48:21.706238 17263 net.cpp:585] BatchNorm97 needs backward computation.
I0619 14:48:21.706243 17263 net.cpp:585] Convolution97 needs backward computation.
I0619 14:48:21.706248 17263 net.cpp:585] ReLU96 needs backward computation.
I0619 14:48:21.706251 17263 net.cpp:585] Scale96 needs backward computation.
I0619 14:48:21.706256 17263 net.cpp:585] BatchNorm96 needs backward computation.
I0619 14:48:21.706260 17263 net.cpp:585] Convolution96 needs backward computation.
I0619 14:48:21.706265 17263 net.cpp:585] Eltwise47_ReLU95_0_split needs backward computation.
I0619 14:48:21.706270 17263 net.cpp:585] ReLU95 needs backward computation.
I0619 14:48:21.706274 17263 net.cpp:585] Eltwise47 needs backward computation.
I0619 14:48:21.706279 17263 net.cpp:585] Scale95 needs backward computation.
I0619 14:48:21.706284 17263 net.cpp:585] BatchNorm95 needs backward computation.
I0619 14:48:21.706288 17263 net.cpp:585] Convolution95 needs backward computation.
I0619 14:48:21.706293 17263 net.cpp:585] ReLU94 needs backward computation.
I0619 14:48:21.706297 17263 net.cpp:585] Scale94 needs backward computation.
I0619 14:48:21.706302 17263 net.cpp:585] BatchNorm94 needs backward computation.
I0619 14:48:21.706306 17263 net.cpp:585] Convolution94 needs backward computation.
I0619 14:48:21.706311 17263 net.cpp:585] Eltwise46_ReLU93_0_split needs backward computation.
I0619 14:48:21.706316 17263 net.cpp:585] ReLU93 needs backward computation.
I0619 14:48:21.706321 17263 net.cpp:585] Eltwise46 needs backward computation.
I0619 14:48:21.706329 17263 net.cpp:585] Scale93 needs backward computation.
I0619 14:48:21.706342 17263 net.cpp:585] BatchNorm93 needs backward computation.
I0619 14:48:21.706347 17263 net.cpp:585] Convolution93 needs backward computation.
I0619 14:48:21.706352 17263 net.cpp:585] ReLU92 needs backward computation.
I0619 14:48:21.706364 17263 net.cpp:585] Scale92 needs backward computation.
I0619 14:48:21.706368 17263 net.cpp:585] BatchNorm92 needs backward computation.
I0619 14:48:21.706373 17263 net.cpp:585] Convolution92 needs backward computation.
I0619 14:48:21.706378 17263 net.cpp:585] Eltwise45_ReLU91_0_split needs backward computation.
I0619 14:48:21.706383 17263 net.cpp:585] ReLU91 needs backward computation.
I0619 14:48:21.706387 17263 net.cpp:585] Eltwise45 needs backward computation.
I0619 14:48:21.706393 17263 net.cpp:585] Scale91 needs backward computation.
I0619 14:48:21.706398 17263 net.cpp:585] BatchNorm91 needs backward computation.
I0619 14:48:21.706401 17263 net.cpp:585] Convolution91 needs backward computation.
I0619 14:48:21.706406 17263 net.cpp:585] ReLU90 needs backward computation.
I0619 14:48:21.706410 17263 net.cpp:585] Scale90 needs backward computation.
I0619 14:48:21.706414 17263 net.cpp:585] BatchNorm90 needs backward computation.
I0619 14:48:21.706419 17263 net.cpp:585] Convolution90 needs backward computation.
I0619 14:48:21.706423 17263 net.cpp:585] Eltwise44_ReLU89_0_split needs backward computation.
I0619 14:48:21.706429 17263 net.cpp:585] ReLU89 needs backward computation.
I0619 14:48:21.706434 17263 net.cpp:585] Eltwise44 needs backward computation.
I0619 14:48:21.706439 17263 net.cpp:585] Scale89 needs backward computation.
I0619 14:48:21.706444 17263 net.cpp:585] BatchNorm89 needs backward computation.
I0619 14:48:21.706447 17263 net.cpp:585] Convolution89 needs backward computation.
I0619 14:48:21.706452 17263 net.cpp:585] ReLU88 needs backward computation.
I0619 14:48:21.706456 17263 net.cpp:585] Scale88 needs backward computation.
I0619 14:48:21.706461 17263 net.cpp:585] BatchNorm88 needs backward computation.
I0619 14:48:21.706465 17263 net.cpp:585] Convolution88 needs backward computation.
I0619 14:48:21.706470 17263 net.cpp:585] Eltwise43_ReLU87_0_split needs backward computation.
I0619 14:48:21.706475 17263 net.cpp:585] ReLU87 needs backward computation.
I0619 14:48:21.706480 17263 net.cpp:585] Eltwise43 needs backward computation.
I0619 14:48:21.706485 17263 net.cpp:585] Scale87 needs backward computation.
I0619 14:48:21.706488 17263 net.cpp:585] BatchNorm87 needs backward computation.
I0619 14:48:21.706493 17263 net.cpp:585] Convolution87 needs backward computation.
I0619 14:48:21.706498 17263 net.cpp:585] ReLU86 needs backward computation.
I0619 14:48:21.706502 17263 net.cpp:585] Scale86 needs backward computation.
I0619 14:48:21.706506 17263 net.cpp:585] BatchNorm86 needs backward computation.
I0619 14:48:21.706511 17263 net.cpp:585] Convolution86 needs backward computation.
I0619 14:48:21.706516 17263 net.cpp:585] Eltwise42_ReLU85_0_split needs backward computation.
I0619 14:48:21.706521 17263 net.cpp:585] ReLU85 needs backward computation.
I0619 14:48:21.706526 17263 net.cpp:585] Eltwise42 needs backward computation.
I0619 14:48:21.706531 17263 net.cpp:585] Scale85 needs backward computation.
I0619 14:48:21.706534 17263 net.cpp:585] BatchNorm85 needs backward computation.
I0619 14:48:21.706539 17263 net.cpp:585] Convolution85 needs backward computation.
I0619 14:48:21.706543 17263 net.cpp:585] ReLU84 needs backward computation.
I0619 14:48:21.706548 17263 net.cpp:585] Scale84 needs backward computation.
I0619 14:48:21.706552 17263 net.cpp:585] BatchNorm84 needs backward computation.
I0619 14:48:21.706557 17263 net.cpp:585] Convolution84 needs backward computation.
I0619 14:48:21.706562 17263 net.cpp:585] Eltwise41_ReLU83_0_split needs backward computation.
I0619 14:48:21.706569 17263 net.cpp:585] ReLU83 needs backward computation.
I0619 14:48:21.706574 17263 net.cpp:585] Eltwise41 needs backward computation.
I0619 14:48:21.706579 17263 net.cpp:585] Scale83 needs backward computation.
I0619 14:48:21.706595 17263 net.cpp:585] BatchNorm83 needs backward computation.
I0619 14:48:21.706600 17263 net.cpp:585] Convolution83 needs backward computation.
I0619 14:48:21.706605 17263 net.cpp:585] ReLU82 needs backward computation.
I0619 14:48:21.706610 17263 net.cpp:585] Scale82 needs backward computation.
I0619 14:48:21.706614 17263 net.cpp:585] BatchNorm82 needs backward computation.
I0619 14:48:21.706619 17263 net.cpp:585] Convolution82 needs backward computation.
I0619 14:48:21.706624 17263 net.cpp:585] Eltwise40_ReLU81_0_split needs backward computation.
I0619 14:48:21.706629 17263 net.cpp:585] ReLU81 needs backward computation.
I0619 14:48:21.706632 17263 net.cpp:585] Eltwise40 needs backward computation.
I0619 14:48:21.706639 17263 net.cpp:585] Scale81 needs backward computation.
I0619 14:48:21.706642 17263 net.cpp:585] BatchNorm81 needs backward computation.
I0619 14:48:21.706647 17263 net.cpp:585] Convolution81 needs backward computation.
I0619 14:48:21.706651 17263 net.cpp:585] ReLU80 needs backward computation.
I0619 14:48:21.706656 17263 net.cpp:585] Scale80 needs backward computation.
I0619 14:48:21.706660 17263 net.cpp:585] BatchNorm80 needs backward computation.
I0619 14:48:21.706665 17263 net.cpp:585] Convolution80 needs backward computation.
I0619 14:48:21.706670 17263 net.cpp:585] Eltwise39_ReLU79_0_split needs backward computation.
I0619 14:48:21.706676 17263 net.cpp:585] ReLU79 needs backward computation.
I0619 14:48:21.706681 17263 net.cpp:585] Eltwise39 needs backward computation.
I0619 14:48:21.706686 17263 net.cpp:585] Scale79 needs backward computation.
I0619 14:48:21.706691 17263 net.cpp:585] BatchNorm79 needs backward computation.
I0619 14:48:21.706696 17263 net.cpp:585] Convolution79 needs backward computation.
I0619 14:48:21.706701 17263 net.cpp:585] ReLU78 needs backward computation.
I0619 14:48:21.706704 17263 net.cpp:585] Scale78 needs backward computation.
I0619 14:48:21.706709 17263 net.cpp:585] BatchNorm78 needs backward computation.
I0619 14:48:21.706713 17263 net.cpp:585] Convolution78 needs backward computation.
I0619 14:48:21.706718 17263 net.cpp:585] Eltwise38_ReLU77_0_split needs backward computation.
I0619 14:48:21.706724 17263 net.cpp:585] ReLU77 needs backward computation.
I0619 14:48:21.706728 17263 net.cpp:585] Eltwise38 needs backward computation.
I0619 14:48:21.706734 17263 net.cpp:585] Scale77 needs backward computation.
I0619 14:48:21.706738 17263 net.cpp:585] BatchNorm77 needs backward computation.
I0619 14:48:21.706743 17263 net.cpp:585] Convolution77 needs backward computation.
I0619 14:48:21.706748 17263 net.cpp:585] ReLU76 needs backward computation.
I0619 14:48:21.706753 17263 net.cpp:585] Scale76 needs backward computation.
I0619 14:48:21.706758 17263 net.cpp:585] BatchNorm76 needs backward computation.
I0619 14:48:21.706763 17263 net.cpp:585] Convolution76 needs backward computation.
I0619 14:48:21.706768 17263 net.cpp:585] Eltwise37_ReLU75_0_split needs backward computation.
I0619 14:48:21.706773 17263 net.cpp:585] ReLU75 needs backward computation.
I0619 14:48:21.706776 17263 net.cpp:585] Eltwise37 needs backward computation.
I0619 14:48:21.706782 17263 net.cpp:585] Scale75 needs backward computation.
I0619 14:48:21.706786 17263 net.cpp:585] BatchNorm75 needs backward computation.
I0619 14:48:21.706791 17263 net.cpp:585] Convolution75 needs backward computation.
I0619 14:48:21.706796 17263 net.cpp:585] ReLU74 needs backward computation.
I0619 14:48:21.706800 17263 net.cpp:585] Scale74 needs backward computation.
I0619 14:48:21.706805 17263 net.cpp:585] BatchNorm74 needs backward computation.
I0619 14:48:21.706809 17263 net.cpp:585] Convolution74 needs backward computation.
I0619 14:48:21.706815 17263 net.cpp:585] Concat2 needs backward computation.
I0619 14:48:21.706820 17263 net.cpp:587] Input2 does not need backward computation.
I0619 14:48:21.706825 17263 net.cpp:585] Pooling2 needs backward computation.
I0619 14:48:21.706831 17263 net.cpp:585] Eltwise36_ReLU73_0_split needs backward computation.
I0619 14:48:21.706838 17263 net.cpp:585] ReLU73 needs backward computation.
I0619 14:48:21.706851 17263 net.cpp:585] Eltwise36 needs backward computation.
I0619 14:48:21.706857 17263 net.cpp:585] Scale73 needs backward computation.
I0619 14:48:21.706862 17263 net.cpp:585] BatchNorm73 needs backward computation.
I0619 14:48:21.706867 17263 net.cpp:585] Convolution73 needs backward computation.
I0619 14:48:21.706871 17263 net.cpp:585] ReLU72 needs backward computation.
I0619 14:48:21.706876 17263 net.cpp:585] Scale72 needs backward computation.
I0619 14:48:21.706881 17263 net.cpp:585] BatchNorm72 needs backward computation.
I0619 14:48:21.706885 17263 net.cpp:585] Convolution72 needs backward computation.
I0619 14:48:21.706890 17263 net.cpp:585] Eltwise35_ReLU71_0_split needs backward computation.
I0619 14:48:21.706895 17263 net.cpp:585] ReLU71 needs backward computation.
I0619 14:48:21.706900 17263 net.cpp:585] Eltwise35 needs backward computation.
I0619 14:48:21.706905 17263 net.cpp:585] Scale71 needs backward computation.
I0619 14:48:21.706910 17263 net.cpp:585] BatchNorm71 needs backward computation.
I0619 14:48:21.706915 17263 net.cpp:585] Convolution71 needs backward computation.
I0619 14:48:21.706920 17263 net.cpp:585] ReLU70 needs backward computation.
I0619 14:48:21.706924 17263 net.cpp:585] Scale70 needs backward computation.
I0619 14:48:21.706929 17263 net.cpp:585] BatchNorm70 needs backward computation.
I0619 14:48:21.706933 17263 net.cpp:585] Convolution70 needs backward computation.
I0619 14:48:21.706939 17263 net.cpp:585] Eltwise34_ReLU69_0_split needs backward computation.
I0619 14:48:21.706944 17263 net.cpp:585] ReLU69 needs backward computation.
I0619 14:48:21.706948 17263 net.cpp:585] Eltwise34 needs backward computation.
I0619 14:48:21.706954 17263 net.cpp:585] Scale69 needs backward computation.
I0619 14:48:21.706959 17263 net.cpp:585] BatchNorm69 needs backward computation.
I0619 14:48:21.706964 17263 net.cpp:585] Convolution69 needs backward computation.
I0619 14:48:21.706969 17263 net.cpp:585] ReLU68 needs backward computation.
I0619 14:48:21.706974 17263 net.cpp:585] Scale68 needs backward computation.
I0619 14:48:21.706979 17263 net.cpp:585] BatchNorm68 needs backward computation.
I0619 14:48:21.706982 17263 net.cpp:585] Convolution68 needs backward computation.
I0619 14:48:21.706987 17263 net.cpp:585] Eltwise33_ReLU67_0_split needs backward computation.
I0619 14:48:21.706992 17263 net.cpp:585] ReLU67 needs backward computation.
I0619 14:48:21.706997 17263 net.cpp:585] Eltwise33 needs backward computation.
I0619 14:48:21.707002 17263 net.cpp:585] Scale67 needs backward computation.
I0619 14:48:21.707007 17263 net.cpp:585] BatchNorm67 needs backward computation.
I0619 14:48:21.707011 17263 net.cpp:585] Convolution67 needs backward computation.
I0619 14:48:21.707016 17263 net.cpp:585] ReLU66 needs backward computation.
I0619 14:48:21.707021 17263 net.cpp:585] Scale66 needs backward computation.
I0619 14:48:21.707026 17263 net.cpp:585] BatchNorm66 needs backward computation.
I0619 14:48:21.707031 17263 net.cpp:585] Convolution66 needs backward computation.
I0619 14:48:21.707036 17263 net.cpp:585] Eltwise32_ReLU65_0_split needs backward computation.
I0619 14:48:21.707041 17263 net.cpp:585] ReLU65 needs backward computation.
I0619 14:48:21.707044 17263 net.cpp:585] Eltwise32 needs backward computation.
I0619 14:48:21.707051 17263 net.cpp:585] Scale65 needs backward computation.
I0619 14:48:21.707056 17263 net.cpp:585] BatchNorm65 needs backward computation.
I0619 14:48:21.707059 17263 net.cpp:585] Convolution65 needs backward computation.
I0619 14:48:21.707064 17263 net.cpp:585] ReLU64 needs backward computation.
I0619 14:48:21.707069 17263 net.cpp:585] Scale64 needs backward computation.
I0619 14:48:21.707073 17263 net.cpp:585] BatchNorm64 needs backward computation.
I0619 14:48:21.707078 17263 net.cpp:585] Convolution64 needs backward computation.
I0619 14:48:21.707083 17263 net.cpp:585] Eltwise31_ReLU63_0_split needs backward computation.
I0619 14:48:21.707088 17263 net.cpp:585] ReLU63 needs backward computation.
I0619 14:48:21.707095 17263 net.cpp:585] Eltwise31 needs backward computation.
I0619 14:48:21.707109 17263 net.cpp:585] Scale63 needs backward computation.
I0619 14:48:21.707114 17263 net.cpp:585] BatchNorm63 needs backward computation.
I0619 14:48:21.707119 17263 net.cpp:585] Convolution63 needs backward computation.
I0619 14:48:21.707124 17263 net.cpp:585] ReLU62 needs backward computation.
I0619 14:48:21.707129 17263 net.cpp:585] Scale62 needs backward computation.
I0619 14:48:21.707134 17263 net.cpp:585] BatchNorm62 needs backward computation.
I0619 14:48:21.707139 17263 net.cpp:585] Convolution62 needs backward computation.
I0619 14:48:21.707144 17263 net.cpp:585] Eltwise30_ReLU61_0_split needs backward computation.
I0619 14:48:21.707147 17263 net.cpp:585] ReLU61 needs backward computation.
I0619 14:48:21.707152 17263 net.cpp:585] Eltwise30 needs backward computation.
I0619 14:48:21.707159 17263 net.cpp:585] Scale61 needs backward computation.
I0619 14:48:21.707162 17263 net.cpp:585] BatchNorm61 needs backward computation.
I0619 14:48:21.707167 17263 net.cpp:585] Convolution61 needs backward computation.
I0619 14:48:21.707172 17263 net.cpp:585] ReLU60 needs backward computation.
I0619 14:48:21.707177 17263 net.cpp:585] Scale60 needs backward computation.
I0619 14:48:21.707181 17263 net.cpp:585] BatchNorm60 needs backward computation.
I0619 14:48:21.707186 17263 net.cpp:585] Convolution60 needs backward computation.
I0619 14:48:21.707191 17263 net.cpp:585] Eltwise29_ReLU59_0_split needs backward computation.
I0619 14:48:21.707196 17263 net.cpp:585] ReLU59 needs backward computation.
I0619 14:48:21.707201 17263 net.cpp:585] Eltwise29 needs backward computation.
I0619 14:48:21.707206 17263 net.cpp:585] Scale59 needs backward computation.
I0619 14:48:21.707211 17263 net.cpp:585] BatchNorm59 needs backward computation.
I0619 14:48:21.707216 17263 net.cpp:585] Convolution59 needs backward computation.
I0619 14:48:21.707221 17263 net.cpp:585] ReLU58 needs backward computation.
I0619 14:48:21.707226 17263 net.cpp:585] Scale58 needs backward computation.
I0619 14:48:21.707231 17263 net.cpp:585] BatchNorm58 needs backward computation.
I0619 14:48:21.707236 17263 net.cpp:585] Convolution58 needs backward computation.
I0619 14:48:21.707240 17263 net.cpp:585] Eltwise28_ReLU57_0_split needs backward computation.
I0619 14:48:21.707245 17263 net.cpp:585] ReLU57 needs backward computation.
I0619 14:48:21.707249 17263 net.cpp:585] Eltwise28 needs backward computation.
I0619 14:48:21.707255 17263 net.cpp:585] Scale57 needs backward computation.
I0619 14:48:21.707260 17263 net.cpp:585] BatchNorm57 needs backward computation.
I0619 14:48:21.707264 17263 net.cpp:585] Convolution57 needs backward computation.
I0619 14:48:21.707269 17263 net.cpp:585] ReLU56 needs backward computation.
I0619 14:48:21.707274 17263 net.cpp:585] Scale56 needs backward computation.
I0619 14:48:21.707278 17263 net.cpp:585] BatchNorm56 needs backward computation.
I0619 14:48:21.707283 17263 net.cpp:585] Convolution56 needs backward computation.
I0619 14:48:21.707288 17263 net.cpp:585] Eltwise27_ReLU55_0_split needs backward computation.
I0619 14:48:21.707293 17263 net.cpp:585] ReLU55 needs backward computation.
I0619 14:48:21.707298 17263 net.cpp:585] Eltwise27 needs backward computation.
I0619 14:48:21.707304 17263 net.cpp:585] Scale55 needs backward computation.
I0619 14:48:21.707309 17263 net.cpp:585] BatchNorm55 needs backward computation.
I0619 14:48:21.707314 17263 net.cpp:585] Convolution55 needs backward computation.
I0619 14:48:21.707319 17263 net.cpp:585] ReLU54 needs backward computation.
I0619 14:48:21.707322 17263 net.cpp:585] Scale54 needs backward computation.
I0619 14:48:21.707327 17263 net.cpp:585] BatchNorm54 needs backward computation.
I0619 14:48:21.707332 17263 net.cpp:585] Convolution54 needs backward computation.
I0619 14:48:21.707337 17263 net.cpp:585] Eltwise26_ReLU53_0_split needs backward computation.
I0619 14:48:21.707342 17263 net.cpp:585] ReLU53 needs backward computation.
I0619 14:48:21.707346 17263 net.cpp:585] Eltwise26 needs backward computation.
I0619 14:48:21.707356 17263 net.cpp:585] Scale53 needs backward computation.
I0619 14:48:21.707373 17263 net.cpp:585] BatchNorm53 needs backward computation.
I0619 14:48:21.707378 17263 net.cpp:585] Convolution53 needs backward computation.
I0619 14:48:21.707383 17263 net.cpp:585] ReLU52 needs backward computation.
I0619 14:48:21.707387 17263 net.cpp:585] Scale52 needs backward computation.
I0619 14:48:21.707392 17263 net.cpp:585] BatchNorm52 needs backward computation.
I0619 14:48:21.707396 17263 net.cpp:585] Convolution52 needs backward computation.
I0619 14:48:21.707401 17263 net.cpp:585] Eltwise25_ReLU51_0_split needs backward computation.
I0619 14:48:21.707406 17263 net.cpp:585] ReLU51 needs backward computation.
I0619 14:48:21.707412 17263 net.cpp:585] Eltwise25 needs backward computation.
I0619 14:48:21.707419 17263 net.cpp:585] Scale51 needs backward computation.
I0619 14:48:21.707424 17263 net.cpp:585] BatchNorm51 needs backward computation.
I0619 14:48:21.707429 17263 net.cpp:585] Convolution51 needs backward computation.
I0619 14:48:21.707434 17263 net.cpp:585] ReLU50 needs backward computation.
I0619 14:48:21.707439 17263 net.cpp:585] Scale50 needs backward computation.
I0619 14:48:21.707444 17263 net.cpp:585] BatchNorm50 needs backward computation.
I0619 14:48:21.707448 17263 net.cpp:585] Convolution50 needs backward computation.
I0619 14:48:21.707453 17263 net.cpp:585] Eltwise24_ReLU49_0_split needs backward computation.
I0619 14:48:21.707458 17263 net.cpp:585] ReLU49 needs backward computation.
I0619 14:48:21.707463 17263 net.cpp:585] Eltwise24 needs backward computation.
I0619 14:48:21.707468 17263 net.cpp:585] Scale49 needs backward computation.
I0619 14:48:21.707473 17263 net.cpp:585] BatchNorm49 needs backward computation.
I0619 14:48:21.707479 17263 net.cpp:585] Convolution49 needs backward computation.
I0619 14:48:21.707484 17263 net.cpp:585] ReLU48 needs backward computation.
I0619 14:48:21.707489 17263 net.cpp:585] Scale48 needs backward computation.
I0619 14:48:21.707492 17263 net.cpp:585] BatchNorm48 needs backward computation.
I0619 14:48:21.707497 17263 net.cpp:585] Convolution48 needs backward computation.
I0619 14:48:21.707502 17263 net.cpp:585] Eltwise23_ReLU47_0_split needs backward computation.
I0619 14:48:21.707507 17263 net.cpp:585] ReLU47 needs backward computation.
I0619 14:48:21.707512 17263 net.cpp:585] Eltwise23 needs backward computation.
I0619 14:48:21.707517 17263 net.cpp:585] Scale47 needs backward computation.
I0619 14:48:21.707522 17263 net.cpp:585] BatchNorm47 needs backward computation.
I0619 14:48:21.707526 17263 net.cpp:585] Convolution47 needs backward computation.
I0619 14:48:21.707531 17263 net.cpp:585] ReLU46 needs backward computation.
I0619 14:48:21.707536 17263 net.cpp:585] Scale46 needs backward computation.
I0619 14:48:21.707540 17263 net.cpp:585] BatchNorm46 needs backward computation.
I0619 14:48:21.707545 17263 net.cpp:585] Convolution46 needs backward computation.
I0619 14:48:21.707551 17263 net.cpp:585] Eltwise22_ReLU45_0_split needs backward computation.
I0619 14:48:21.707556 17263 net.cpp:585] ReLU45 needs backward computation.
I0619 14:48:21.707561 17263 net.cpp:585] Eltwise22 needs backward computation.
I0619 14:48:21.707566 17263 net.cpp:585] Scale45 needs backward computation.
I0619 14:48:21.707571 17263 net.cpp:585] BatchNorm45 needs backward computation.
I0619 14:48:21.707574 17263 net.cpp:585] Convolution45 needs backward computation.
I0619 14:48:21.707579 17263 net.cpp:585] ReLU44 needs backward computation.
I0619 14:48:21.707584 17263 net.cpp:585] Scale44 needs backward computation.
I0619 14:48:21.707589 17263 net.cpp:585] BatchNorm44 needs backward computation.
I0619 14:48:21.707593 17263 net.cpp:585] Convolution44 needs backward computation.
I0619 14:48:21.707598 17263 net.cpp:585] Eltwise21_ReLU43_0_split needs backward computation.
I0619 14:48:21.707603 17263 net.cpp:585] ReLU43 needs backward computation.
I0619 14:48:21.707608 17263 net.cpp:585] Eltwise21 needs backward computation.
I0619 14:48:21.707613 17263 net.cpp:585] Scale43 needs backward computation.
I0619 14:48:21.707628 17263 net.cpp:585] BatchNorm43 needs backward computation.
I0619 14:48:21.707634 17263 net.cpp:585] Convolution43 needs backward computation.
I0619 14:48:21.707639 17263 net.cpp:585] ReLU42 needs backward computation.
I0619 14:48:21.707644 17263 net.cpp:585] Scale42 needs backward computation.
I0619 14:48:21.707648 17263 net.cpp:585] BatchNorm42 needs backward computation.
I0619 14:48:21.707653 17263 net.cpp:585] Convolution42 needs backward computation.
I0619 14:48:21.707659 17263 net.cpp:585] Eltwise20_ReLU41_0_split needs backward computation.
I0619 14:48:21.707664 17263 net.cpp:585] ReLU41 needs backward computation.
I0619 14:48:21.707669 17263 net.cpp:585] Eltwise20 needs backward computation.
I0619 14:48:21.707674 17263 net.cpp:585] Scale41 needs backward computation.
I0619 14:48:21.707679 17263 net.cpp:585] BatchNorm41 needs backward computation.
I0619 14:48:21.707684 17263 net.cpp:585] Convolution41 needs backward computation.
I0619 14:48:21.707689 17263 net.cpp:585] ReLU40 needs backward computation.
I0619 14:48:21.707692 17263 net.cpp:585] Scale40 needs backward computation.
I0619 14:48:21.707697 17263 net.cpp:585] BatchNorm40 needs backward computation.
I0619 14:48:21.707701 17263 net.cpp:585] Convolution40 needs backward computation.
I0619 14:48:21.707707 17263 net.cpp:585] Eltwise19_ReLU39_0_split needs backward computation.
I0619 14:48:21.707712 17263 net.cpp:585] ReLU39 needs backward computation.
I0619 14:48:21.707717 17263 net.cpp:585] Eltwise19 needs backward computation.
I0619 14:48:21.707722 17263 net.cpp:585] Scale39 needs backward computation.
I0619 14:48:21.707727 17263 net.cpp:585] BatchNorm39 needs backward computation.
I0619 14:48:21.707732 17263 net.cpp:585] Convolution39 needs backward computation.
I0619 14:48:21.707737 17263 net.cpp:585] ReLU38 needs backward computation.
I0619 14:48:21.707742 17263 net.cpp:585] Scale38 needs backward computation.
I0619 14:48:21.707747 17263 net.cpp:585] BatchNorm38 needs backward computation.
I0619 14:48:21.707751 17263 net.cpp:585] Convolution38 needs backward computation.
I0619 14:48:21.707756 17263 net.cpp:585] Concat1 needs backward computation.
I0619 14:48:21.707765 17263 net.cpp:587] Input1 does not need backward computation.
I0619 14:48:21.707770 17263 net.cpp:585] Pooling1 needs backward computation.
I0619 14:48:21.707775 17263 net.cpp:585] Eltwise18_ReLU37_0_split needs backward computation.
I0619 14:48:21.707782 17263 net.cpp:585] ReLU37 needs backward computation.
I0619 14:48:21.707785 17263 net.cpp:585] Eltwise18 needs backward computation.
I0619 14:48:21.707792 17263 net.cpp:585] Scale37 needs backward computation.
I0619 14:48:21.707797 17263 net.cpp:585] BatchNorm37 needs backward computation.
I0619 14:48:21.707801 17263 net.cpp:585] Convolution37 needs backward computation.
I0619 14:48:21.707806 17263 net.cpp:585] ReLU36 needs backward computation.
I0619 14:48:21.707811 17263 net.cpp:585] Scale36 needs backward computation.
I0619 14:48:21.707815 17263 net.cpp:585] BatchNorm36 needs backward computation.
I0619 14:48:21.707820 17263 net.cpp:585] Convolution36 needs backward computation.
I0619 14:48:21.707825 17263 net.cpp:585] Eltwise17_ReLU35_0_split needs backward computation.
I0619 14:48:21.707830 17263 net.cpp:585] ReLU35 needs backward computation.
I0619 14:48:21.707835 17263 net.cpp:585] Eltwise17 needs backward computation.
I0619 14:48:21.707840 17263 net.cpp:585] Scale35 needs backward computation.
I0619 14:48:21.707845 17263 net.cpp:585] BatchNorm35 needs backward computation.
I0619 14:48:21.707849 17263 net.cpp:585] Convolution35 needs backward computation.
I0619 14:48:21.707855 17263 net.cpp:585] ReLU34 needs backward computation.
I0619 14:48:21.707859 17263 net.cpp:585] Scale34 needs backward computation.
I0619 14:48:21.707864 17263 net.cpp:585] BatchNorm34 needs backward computation.
I0619 14:48:21.707868 17263 net.cpp:585] Convolution34 needs backward computation.
I0619 14:48:21.707873 17263 net.cpp:585] Eltwise16_ReLU33_0_split needs backward computation.
I0619 14:48:21.707881 17263 net.cpp:585] ReLU33 needs backward computation.
I0619 14:48:21.707895 17263 net.cpp:585] Eltwise16 needs backward computation.
I0619 14:48:21.707901 17263 net.cpp:585] Scale33 needs backward computation.
I0619 14:48:21.707906 17263 net.cpp:585] BatchNorm33 needs backward computation.
I0619 14:48:21.707909 17263 net.cpp:585] Convolution33 needs backward computation.
I0619 14:48:21.707914 17263 net.cpp:585] ReLU32 needs backward computation.
I0619 14:48:21.707919 17263 net.cpp:585] Scale32 needs backward computation.
I0619 14:48:21.707924 17263 net.cpp:585] BatchNorm32 needs backward computation.
I0619 14:48:21.707928 17263 net.cpp:585] Convolution32 needs backward computation.
I0619 14:48:21.707933 17263 net.cpp:585] Eltwise15_ReLU31_0_split needs backward computation.
I0619 14:48:21.707938 17263 net.cpp:585] ReLU31 needs backward computation.
I0619 14:48:21.707943 17263 net.cpp:585] Eltwise15 needs backward computation.
I0619 14:48:21.707948 17263 net.cpp:585] Scale31 needs backward computation.
I0619 14:48:21.707953 17263 net.cpp:585] BatchNorm31 needs backward computation.
I0619 14:48:21.707957 17263 net.cpp:585] Convolution31 needs backward computation.
I0619 14:48:21.707962 17263 net.cpp:585] ReLU30 needs backward computation.
I0619 14:48:21.707967 17263 net.cpp:585] Scale30 needs backward computation.
I0619 14:48:21.707972 17263 net.cpp:585] BatchNorm30 needs backward computation.
I0619 14:48:21.707976 17263 net.cpp:585] Convolution30 needs backward computation.
I0619 14:48:21.707981 17263 net.cpp:585] Eltwise14_ReLU29_0_split needs backward computation.
I0619 14:48:21.707986 17263 net.cpp:585] ReLU29 needs backward computation.
I0619 14:48:21.707991 17263 net.cpp:585] Eltwise14 needs backward computation.
I0619 14:48:21.707996 17263 net.cpp:585] Scale29 needs backward computation.
I0619 14:48:21.708001 17263 net.cpp:585] BatchNorm29 needs backward computation.
I0619 14:48:21.708006 17263 net.cpp:585] Convolution29 needs backward computation.
I0619 14:48:21.708011 17263 net.cpp:585] ReLU28 needs backward computation.
I0619 14:48:21.708016 17263 net.cpp:585] Scale28 needs backward computation.
I0619 14:48:21.708021 17263 net.cpp:585] BatchNorm28 needs backward computation.
I0619 14:48:21.708025 17263 net.cpp:585] Convolution28 needs backward computation.
I0619 14:48:21.708030 17263 net.cpp:585] Eltwise13_ReLU27_0_split needs backward computation.
I0619 14:48:21.708036 17263 net.cpp:585] ReLU27 needs backward computation.
I0619 14:48:21.708040 17263 net.cpp:585] Eltwise13 needs backward computation.
I0619 14:48:21.708046 17263 net.cpp:585] Scale27 needs backward computation.
I0619 14:48:21.708050 17263 net.cpp:585] BatchNorm27 needs backward computation.
I0619 14:48:21.708055 17263 net.cpp:585] Convolution27 needs backward computation.
I0619 14:48:21.708060 17263 net.cpp:585] ReLU26 needs backward computation.
I0619 14:48:21.708065 17263 net.cpp:585] Scale26 needs backward computation.
I0619 14:48:21.708070 17263 net.cpp:585] BatchNorm26 needs backward computation.
I0619 14:48:21.708075 17263 net.cpp:585] Convolution26 needs backward computation.
I0619 14:48:21.708079 17263 net.cpp:585] Eltwise12_ReLU25_0_split needs backward computation.
I0619 14:48:21.708084 17263 net.cpp:585] ReLU25 needs backward computation.
I0619 14:48:21.708089 17263 net.cpp:585] Eltwise12 needs backward computation.
I0619 14:48:21.708094 17263 net.cpp:585] Scale25 needs backward computation.
I0619 14:48:21.708099 17263 net.cpp:585] BatchNorm25 needs backward computation.
I0619 14:48:21.708103 17263 net.cpp:585] Convolution25 needs backward computation.
I0619 14:48:21.708108 17263 net.cpp:585] ReLU24 needs backward computation.
I0619 14:48:21.708113 17263 net.cpp:585] Scale24 needs backward computation.
I0619 14:48:21.708117 17263 net.cpp:585] BatchNorm24 needs backward computation.
I0619 14:48:21.708122 17263 net.cpp:585] Convolution24 needs backward computation.
I0619 14:48:21.708127 17263 net.cpp:585] Eltwise11_ReLU23_0_split needs backward computation.
I0619 14:48:21.708132 17263 net.cpp:585] ReLU23 needs backward computation.
I0619 14:48:21.708139 17263 net.cpp:585] Eltwise11 needs backward computation.
I0619 14:48:21.708153 17263 net.cpp:585] Scale23 needs backward computation.
I0619 14:48:21.708158 17263 net.cpp:585] BatchNorm23 needs backward computation.
I0619 14:48:21.708163 17263 net.cpp:585] Convolution23 needs backward computation.
I0619 14:48:21.708168 17263 net.cpp:585] ReLU22 needs backward computation.
I0619 14:48:21.708173 17263 net.cpp:585] Scale22 needs backward computation.
I0619 14:48:21.708176 17263 net.cpp:585] BatchNorm22 needs backward computation.
I0619 14:48:21.708181 17263 net.cpp:585] Convolution22 needs backward computation.
I0619 14:48:21.708186 17263 net.cpp:585] Eltwise10_ReLU21_0_split needs backward computation.
I0619 14:48:21.708191 17263 net.cpp:585] ReLU21 needs backward computation.
I0619 14:48:21.708196 17263 net.cpp:585] Eltwise10 needs backward computation.
I0619 14:48:21.708202 17263 net.cpp:585] Scale21 needs backward computation.
I0619 14:48:21.708206 17263 net.cpp:585] BatchNorm21 needs backward computation.
I0619 14:48:21.708211 17263 net.cpp:585] Convolution21 needs backward computation.
I0619 14:48:21.708216 17263 net.cpp:585] ReLU20 needs backward computation.
I0619 14:48:21.708221 17263 net.cpp:585] Scale20 needs backward computation.
I0619 14:48:21.708225 17263 net.cpp:585] BatchNorm20 needs backward computation.
I0619 14:48:21.708230 17263 net.cpp:585] Convolution20 needs backward computation.
I0619 14:48:21.708235 17263 net.cpp:585] Eltwise9_ReLU19_0_split needs backward computation.
I0619 14:48:21.708240 17263 net.cpp:585] ReLU19 needs backward computation.
I0619 14:48:21.708245 17263 net.cpp:585] Eltwise9 needs backward computation.
I0619 14:48:21.708253 17263 net.cpp:585] Scale19 needs backward computation.
I0619 14:48:21.708258 17263 net.cpp:585] BatchNorm19 needs backward computation.
I0619 14:48:21.708263 17263 net.cpp:585] Convolution19 needs backward computation.
I0619 14:48:21.708269 17263 net.cpp:585] ReLU18 needs backward computation.
I0619 14:48:21.708274 17263 net.cpp:585] Scale18 needs backward computation.
I0619 14:48:21.708278 17263 net.cpp:585] BatchNorm18 needs backward computation.
I0619 14:48:21.708283 17263 net.cpp:585] Convolution18 needs backward computation.
I0619 14:48:21.708288 17263 net.cpp:585] Eltwise8_ReLU17_0_split needs backward computation.
I0619 14:48:21.708294 17263 net.cpp:585] ReLU17 needs backward computation.
I0619 14:48:21.708299 17263 net.cpp:585] Eltwise8 needs backward computation.
I0619 14:48:21.708304 17263 net.cpp:585] Scale17 needs backward computation.
I0619 14:48:21.708309 17263 net.cpp:585] BatchNorm17 needs backward computation.
I0619 14:48:21.708313 17263 net.cpp:585] Convolution17 needs backward computation.
I0619 14:48:21.708318 17263 net.cpp:585] ReLU16 needs backward computation.
I0619 14:48:21.708323 17263 net.cpp:585] Scale16 needs backward computation.
I0619 14:48:21.708328 17263 net.cpp:585] BatchNorm16 needs backward computation.
I0619 14:48:21.708333 17263 net.cpp:585] Convolution16 needs backward computation.
I0619 14:48:21.708338 17263 net.cpp:585] Eltwise7_ReLU15_0_split needs backward computation.
I0619 14:48:21.708343 17263 net.cpp:585] ReLU15 needs backward computation.
I0619 14:48:21.708348 17263 net.cpp:585] Eltwise7 needs backward computation.
I0619 14:48:21.708353 17263 net.cpp:585] Scale15 needs backward computation.
I0619 14:48:21.708359 17263 net.cpp:585] BatchNorm15 needs backward computation.
I0619 14:48:21.708364 17263 net.cpp:585] Convolution15 needs backward computation.
I0619 14:48:21.708369 17263 net.cpp:585] ReLU14 needs backward computation.
I0619 14:48:21.708374 17263 net.cpp:585] Scale14 needs backward computation.
I0619 14:48:21.708379 17263 net.cpp:585] BatchNorm14 needs backward computation.
I0619 14:48:21.708382 17263 net.cpp:585] Convolution14 needs backward computation.
I0619 14:48:21.708387 17263 net.cpp:585] Eltwise6_ReLU13_0_split needs backward computation.
I0619 14:48:21.708392 17263 net.cpp:585] ReLU13 needs backward computation.
I0619 14:48:21.708397 17263 net.cpp:585] Eltwise6 needs backward computation.
I0619 14:48:21.708406 17263 net.cpp:585] Scale13 needs backward computation.
I0619 14:48:21.708420 17263 net.cpp:585] BatchNorm13 needs backward computation.
I0619 14:48:21.708426 17263 net.cpp:585] Convolution13 needs backward computation.
I0619 14:48:21.708431 17263 net.cpp:585] ReLU12 needs backward computation.
I0619 14:48:21.708436 17263 net.cpp:585] Scale12 needs backward computation.
I0619 14:48:21.708441 17263 net.cpp:585] BatchNorm12 needs backward computation.
I0619 14:48:21.708444 17263 net.cpp:585] Convolution12 needs backward computation.
I0619 14:48:21.708451 17263 net.cpp:585] Eltwise5_ReLU11_0_split needs backward computation.
I0619 14:48:21.708456 17263 net.cpp:585] ReLU11 needs backward computation.
I0619 14:48:21.708459 17263 net.cpp:585] Eltwise5 needs backward computation.
I0619 14:48:21.708465 17263 net.cpp:585] Scale11 needs backward computation.
I0619 14:48:21.708470 17263 net.cpp:585] BatchNorm11 needs backward computation.
I0619 14:48:21.708475 17263 net.cpp:585] Convolution11 needs backward computation.
I0619 14:48:21.708480 17263 net.cpp:585] ReLU10 needs backward computation.
I0619 14:48:21.708485 17263 net.cpp:585] Scale10 needs backward computation.
I0619 14:48:21.708490 17263 net.cpp:585] BatchNorm10 needs backward computation.
I0619 14:48:21.708494 17263 net.cpp:585] Convolution10 needs backward computation.
I0619 14:48:21.708500 17263 net.cpp:585] Eltwise4_ReLU9_0_split needs backward computation.
I0619 14:48:21.708505 17263 net.cpp:585] ReLU9 needs backward computation.
I0619 14:48:21.708510 17263 net.cpp:585] Eltwise4 needs backward computation.
I0619 14:48:21.708516 17263 net.cpp:585] Scale9 needs backward computation.
I0619 14:48:21.708521 17263 net.cpp:585] BatchNorm9 needs backward computation.
I0619 14:48:21.708525 17263 net.cpp:585] Convolution9 needs backward computation.
I0619 14:48:21.708530 17263 net.cpp:585] ReLU8 needs backward computation.
I0619 14:48:21.708535 17263 net.cpp:585] Scale8 needs backward computation.
I0619 14:48:21.708540 17263 net.cpp:585] BatchNorm8 needs backward computation.
I0619 14:48:21.708544 17263 net.cpp:585] Convolution8 needs backward computation.
I0619 14:48:21.708550 17263 net.cpp:585] Eltwise3_ReLU7_0_split needs backward computation.
I0619 14:48:21.708555 17263 net.cpp:585] ReLU7 needs backward computation.
I0619 14:48:21.708560 17263 net.cpp:585] Eltwise3 needs backward computation.
I0619 14:48:21.708566 17263 net.cpp:585] Scale7 needs backward computation.
I0619 14:48:21.708570 17263 net.cpp:585] BatchNorm7 needs backward computation.
I0619 14:48:21.708575 17263 net.cpp:585] Convolution7 needs backward computation.
I0619 14:48:21.708580 17263 net.cpp:585] ReLU6 needs backward computation.
I0619 14:48:21.708585 17263 net.cpp:585] Scale6 needs backward computation.
I0619 14:48:21.708590 17263 net.cpp:585] BatchNorm6 needs backward computation.
I0619 14:48:21.708595 17263 net.cpp:585] Convolution6 needs backward computation.
I0619 14:48:21.708600 17263 net.cpp:585] Eltwise2_ReLU5_0_split needs backward computation.
I0619 14:48:21.708605 17263 net.cpp:585] ReLU5 needs backward computation.
I0619 14:48:21.708609 17263 net.cpp:585] Eltwise2 needs backward computation.
I0619 14:48:21.708614 17263 net.cpp:585] Scale5 needs backward computation.
I0619 14:48:21.708622 17263 net.cpp:585] BatchNorm5 needs backward computation.
I0619 14:48:21.708626 17263 net.cpp:585] Convolution5 needs backward computation.
I0619 14:48:21.708632 17263 net.cpp:585] ReLU4 needs backward computation.
I0619 14:48:21.708636 17263 net.cpp:585] Scale4 needs backward computation.
I0619 14:48:21.708642 17263 net.cpp:585] BatchNorm4 needs backward computation.
I0619 14:48:21.708645 17263 net.cpp:585] Convolution4 needs backward computation.
I0619 14:48:21.708652 17263 net.cpp:585] Eltwise1_ReLU3_0_split needs backward computation.
I0619 14:48:21.708657 17263 net.cpp:585] ReLU3 needs backward computation.
I0619 14:48:21.708662 17263 net.cpp:585] Eltwise1 needs backward computation.
I0619 14:48:21.708667 17263 net.cpp:585] Scale3 needs backward computation.
I0619 14:48:21.708676 17263 net.cpp:585] BatchNorm3 needs backward computation.
I0619 14:48:21.708689 17263 net.cpp:585] Convolution3 needs backward computation.
I0619 14:48:21.708695 17263 net.cpp:585] ReLU2 needs backward computation.
I0619 14:48:21.708700 17263 net.cpp:585] Scale2 needs backward computation.
I0619 14:48:21.708704 17263 net.cpp:585] BatchNorm2 needs backward computation.
I0619 14:48:21.708709 17263 net.cpp:585] Convolution2 needs backward computation.
I0619 14:48:21.708715 17263 net.cpp:585] Convolution1_ReLU1_0_split needs backward computation.
I0619 14:48:21.708720 17263 net.cpp:585] ReLU1 needs backward computation.
I0619 14:48:21.708725 17263 net.cpp:585] Scale1 needs backward computation.
I0619 14:48:21.708729 17263 net.cpp:585] BatchNorm1 needs backward computation.
I0619 14:48:21.708734 17263 net.cpp:585] Convolution1 needs backward computation.
I0619 14:48:21.708740 17263 net.cpp:587] Data1 does not need backward computation.
I0619 14:48:21.708745 17263 net.cpp:629] This network produces output SoftmaxWithLoss1
prob: 0.830189
prob: 0.660377
I0619 14:48:21.713394 17263 net.cpp:643] Network initialization done.
I0619 14:48:21.735208 17263 solver.cpp:416] Creating test net (#0) specified by test_net file: examples/stochastic_depth/residual_test54.prototxt
I0619 14:48:21.741089 17263 net.cpp:417] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "/scratch/pas282/caffe/examples/cifar10/cifar10_test_leveldb_padding1"
    batch_size: 128
    backend: LEVELDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution21"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution22"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution22"
  top: "Convolution22"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Convolution22"
  top: "Convolution23"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution23"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution24"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution25"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution26"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution27"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution28"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution28"
  top: "Convolution28"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution29"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution30"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "Convolution30"
  top: "Convolution30"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Convolution30"
  top: "Convolution31"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise15"
  type: "Eltwise"
  bottom: "Eltwise14"
  bottom: "Convolution31"
  top: "Eltwise15"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "Eltwise15"
  top: "Eltwise15"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Eltwise15"
  top: "Convolution32"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm32"
  type: "BatchNorm"
  bottom: "Convolution32"
  top: "Convolution32"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale32"
  type: "Scale"
  bottom: "Convolution32"
  top: "Convolution32"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU32"
  type: "ReLU"
  bottom: "Convolution32"
  top: "Convolution32"
}
layer {
  name: "Convolution33"
  type: "Convolution"
  bottom: "Convolution32"
  top: "Convolution33"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm33"
  type: "BatchNorm"
  bottom: "Convolution33"
  top: "Convolution33"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale33"
  type: "Scale"
  bottom: "Convolution33"
  top: "Convolution33"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise16"
  type: "Eltwise"
  bottom: "Eltwise15"
  bottom: "Convolution33"
  top: "Eltwise16"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU33"
  type: "ReLU"
  bottom: "Eltwise16"
  top: "Eltwise16"
}
layer {
  name: "Convolution34"
  type: "Convolution"
  bottom: "Eltwise16"
  top: "Convolution34"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm34"
  type: "BatchNorm"
  bottom: "Convolution34"
  top: "Convolution34"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale34"
  type: "Scale"
  bottom: "Convolution34"
  top: "Convolution34"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU34"
  type: "ReLU"
  bottom: "Convolution34"
  top: "Convolution34"
}
layer {
  name: "Convolution35"
  type: "Convolution"
  bottom: "Convolution34"
  top: "Convolution35"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm35"
  type: "BatchNorm"
  bottom: "Convolution35"
  top: "Convolution35"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale35"
  type: "Scale"
  bottom: "Convolution35"
  top: "Convolution35"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise17"
  type: "Eltwise"
  bottom: "Eltwise16"
  bottom: "Convolution35"
  top: "Eltwise17"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU35"
  type: "ReLU"
  bottom: "Eltwise17"
  top: "Eltwise17"
}
layer {
  name: "Convolution36"
  type: "Convolution"
  bottom: "Eltwise17"
  top: "Convolution36"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  
I0619 14:48:21.745168 17263 layer_factory.hpp:77] Creating layer Data1
I0619 14:48:21.745406 17263 net.cpp:459] Creating Layer Data1
I0619 14:48:21.745446 17263 net.cpp:860] Data1 -> Data1
I0619 14:48:21.745467 17263 net.cpp:860] Data1 -> Data2
I0619 14:48:21.784024 17269 db_leveldb.cpp:18] Opened leveldb /scratch/pas282/caffe/examples/cifar10/cifar10_test_leveldb_padding1
I0619 14:48:21.784878 17263 data_layer.cpp:41] output data size: 128,3,32,32
I0619 14:48:21.789903 17263 net.cpp:509] Setting up Data1
I0619 14:48:21.789928 17263 net.cpp:516] Top shape: 128 3 32 32 (393216)
I0619 14:48:21.789938 17263 net.cpp:516] Top shape: 128 (128)
I0619 14:48:21.789945 17263 net.cpp:524] Memory required for data: 1573376
I0619 14:48:21.789952 17263 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0619 14:48:21.789965 17263 net.cpp:459] Creating Layer Data2_Data1_1_split
I0619 14:48:21.789973 17263 net.cpp:886] Data2_Data1_1_split <- Data2
I0619 14:48:21.789984 17263 net.cpp:860] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0619 14:48:21.790000 17263 net.cpp:860] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0619 14:48:21.790129 17263 net.cpp:509] Setting up Data2_Data1_1_split
I0619 14:48:21.790145 17263 net.cpp:516] Top shape: 128 (128)
I0619 14:48:21.790153 17263 net.cpp:516] Top shape: 128 (128)
I0619 14:48:21.790158 17263 net.cpp:524] Memory required for data: 1574400
I0619 14:48:21.790165 17263 layer_factory.hpp:77] Creating layer Convolution1
I0619 14:48:21.790194 17263 net.cpp:459] Creating Layer Convolution1
I0619 14:48:21.790204 17263 net.cpp:886] Convolution1 <- Data1
I0619 14:48:21.790241 17263 net.cpp:860] Convolution1 -> Convolution1
I0619 14:48:21.790760 17263 net.cpp:509] Setting up Convolution1
I0619 14:48:21.790781 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.790788 17263 net.cpp:524] Memory required for data: 9963008
I0619 14:48:21.790809 17263 layer_factory.hpp:77] Creating layer BatchNorm1
I0619 14:48:21.790823 17263 net.cpp:459] Creating Layer BatchNorm1
I0619 14:48:21.790830 17263 net.cpp:886] BatchNorm1 <- Convolution1
I0619 14:48:21.790843 17263 net.cpp:847] BatchNorm1 -> Convolution1 (in-place)
I0619 14:48:21.791184 17263 net.cpp:509] Setting up BatchNorm1
I0619 14:48:21.791196 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.791203 17263 net.cpp:524] Memory required for data: 18351616
I0619 14:48:21.791224 17263 layer_factory.hpp:77] Creating layer Scale1
I0619 14:48:21.791236 17263 net.cpp:459] Creating Layer Scale1
I0619 14:48:21.791242 17263 net.cpp:886] Scale1 <- Convolution1
I0619 14:48:21.791251 17263 net.cpp:847] Scale1 -> Convolution1 (in-place)
I0619 14:48:21.791311 17263 layer_factory.hpp:77] Creating layer Scale1
I0619 14:48:21.791507 17263 net.cpp:509] Setting up Scale1
I0619 14:48:21.791518 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.791524 17263 net.cpp:524] Memory required for data: 26740224
I0619 14:48:21.791538 17263 layer_factory.hpp:77] Creating layer ReLU1
I0619 14:48:21.791550 17263 net.cpp:459] Creating Layer ReLU1
I0619 14:48:21.791556 17263 net.cpp:886] ReLU1 <- Convolution1
I0619 14:48:21.791565 17263 net.cpp:847] ReLU1 -> Convolution1 (in-place)
I0619 14:48:21.791575 17263 net.cpp:509] Setting up ReLU1
I0619 14:48:21.791589 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.791594 17263 net.cpp:524] Memory required for data: 35128832
I0619 14:48:21.791600 17263 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0619 14:48:21.791609 17263 net.cpp:459] Creating Layer Convolution1_ReLU1_0_split
I0619 14:48:21.791615 17263 net.cpp:886] Convolution1_ReLU1_0_split <- Convolution1
I0619 14:48:21.791623 17263 net.cpp:860] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0619 14:48:21.791642 17263 net.cpp:860] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0619 14:48:21.791714 17263 net.cpp:509] Setting up Convolution1_ReLU1_0_split
I0619 14:48:21.791726 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.791734 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.791740 17263 net.cpp:524] Memory required for data: 51906048
I0619 14:48:21.791746 17263 layer_factory.hpp:77] Creating layer Convolution2
I0619 14:48:21.791764 17263 net.cpp:459] Creating Layer Convolution2
I0619 14:48:21.791770 17263 net.cpp:886] Convolution2 <- Convolution1_ReLU1_0_split_0
I0619 14:48:21.791782 17263 net.cpp:860] Convolution2 -> Convolution2
I0619 14:48:21.792487 17263 net.cpp:509] Setting up Convolution2
I0619 14:48:21.792505 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.792513 17263 net.cpp:524] Memory required for data: 60294656
I0619 14:48:21.792536 17263 layer_factory.hpp:77] Creating layer BatchNorm2
I0619 14:48:21.792551 17263 net.cpp:459] Creating Layer BatchNorm2
I0619 14:48:21.792559 17263 net.cpp:886] BatchNorm2 <- Convolution2
I0619 14:48:21.792569 17263 net.cpp:847] BatchNorm2 -> Convolution2 (in-place)
I0619 14:48:21.792915 17263 net.cpp:509] Setting up BatchNorm2
I0619 14:48:21.792928 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.792934 17263 net.cpp:524] Memory required for data: 68683264
I0619 14:48:21.792954 17263 layer_factory.hpp:77] Creating layer Scale2
I0619 14:48:21.792965 17263 net.cpp:459] Creating Layer Scale2
I0619 14:48:21.792973 17263 net.cpp:886] Scale2 <- Convolution2
I0619 14:48:21.792981 17263 net.cpp:847] Scale2 -> Convolution2 (in-place)
I0619 14:48:21.793041 17263 layer_factory.hpp:77] Creating layer Scale2
I0619 14:48:21.793253 17263 net.cpp:509] Setting up Scale2
I0619 14:48:21.793267 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.793292 17263 net.cpp:524] Memory required for data: 77071872
I0619 14:48:21.793308 17263 layer_factory.hpp:77] Creating layer ReLU2
I0619 14:48:21.793320 17263 net.cpp:459] Creating Layer ReLU2
I0619 14:48:21.793328 17263 net.cpp:886] ReLU2 <- Convolution2
I0619 14:48:21.793336 17263 net.cpp:847] ReLU2 -> Convolution2 (in-place)
I0619 14:48:21.793347 17263 net.cpp:509] Setting up ReLU2
I0619 14:48:21.793355 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.793361 17263 net.cpp:524] Memory required for data: 85460480
I0619 14:48:21.793367 17263 layer_factory.hpp:77] Creating layer Convolution3
I0619 14:48:21.793385 17263 net.cpp:459] Creating Layer Convolution3
I0619 14:48:21.793390 17263 net.cpp:886] Convolution3 <- Convolution2
I0619 14:48:21.793402 17263 net.cpp:860] Convolution3 -> Convolution3
I0619 14:48:21.793951 17263 net.cpp:509] Setting up Convolution3
I0619 14:48:21.793967 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.793972 17263 net.cpp:524] Memory required for data: 93849088
I0619 14:48:21.793985 17263 layer_factory.hpp:77] Creating layer BatchNorm3
I0619 14:48:21.793998 17263 net.cpp:459] Creating Layer BatchNorm3
I0619 14:48:21.794005 17263 net.cpp:886] BatchNorm3 <- Convolution3
I0619 14:48:21.794014 17263 net.cpp:847] BatchNorm3 -> Convolution3 (in-place)
I0619 14:48:21.794374 17263 net.cpp:509] Setting up BatchNorm3
I0619 14:48:21.794389 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.794395 17263 net.cpp:524] Memory required for data: 102237696
I0619 14:48:21.794420 17263 layer_factory.hpp:77] Creating layer Scale3
I0619 14:48:21.794431 17263 net.cpp:459] Creating Layer Scale3
I0619 14:48:21.794437 17263 net.cpp:886] Scale3 <- Convolution3
I0619 14:48:21.794450 17263 net.cpp:847] Scale3 -> Convolution3 (in-place)
I0619 14:48:21.794534 17263 layer_factory.hpp:77] Creating layer Scale3
I0619 14:48:21.794741 17263 net.cpp:509] Setting up Scale3
I0619 14:48:21.794754 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.794759 17263 net.cpp:524] Memory required for data: 110626304
I0619 14:48:21.794776 17263 layer_factory.hpp:77] Creating layer Eltwise1
I0619 14:48:21.794786 17263 net.cpp:459] Creating Layer Eltwise1
I0619 14:48:21.794793 17263 net.cpp:886] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0619 14:48:21.794802 17263 net.cpp:886] Eltwise1 <- Convolution3
I0619 14:48:21.794814 17263 net.cpp:860] Eltwise1 -> Eltwise1
I0619 14:48:21.794854 17263 net.cpp:509] Setting up Eltwise1
I0619 14:48:21.794864 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.794870 17263 net.cpp:524] Memory required for data: 119014912
I0619 14:48:21.794877 17263 layer_factory.hpp:77] Creating layer ReLU3
I0619 14:48:21.794888 17263 net.cpp:459] Creating Layer ReLU3
I0619 14:48:21.794894 17263 net.cpp:886] ReLU3 <- Eltwise1
I0619 14:48:21.794904 17263 net.cpp:847] ReLU3 -> Eltwise1 (in-place)
I0619 14:48:21.794914 17263 net.cpp:509] Setting up ReLU3
I0619 14:48:21.794924 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.794929 17263 net.cpp:524] Memory required for data: 127403520
I0619 14:48:21.794935 17263 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0619 14:48:21.794950 17263 net.cpp:459] Creating Layer Eltwise1_ReLU3_0_split
I0619 14:48:21.794955 17263 net.cpp:886] Eltwise1_ReLU3_0_split <- Eltwise1
I0619 14:48:21.794965 17263 net.cpp:860] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0619 14:48:21.794975 17263 net.cpp:860] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0619 14:48:21.795054 17263 net.cpp:509] Setting up Eltwise1_ReLU3_0_split
I0619 14:48:21.795066 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.795073 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.795079 17263 net.cpp:524] Memory required for data: 144180736
I0619 14:48:21.795085 17263 layer_factory.hpp:77] Creating layer Convolution4
I0619 14:48:21.795105 17263 net.cpp:459] Creating Layer Convolution4
I0619 14:48:21.795114 17263 net.cpp:886] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0619 14:48:21.795143 17263 net.cpp:860] Convolution4 -> Convolution4
I0619 14:48:21.795687 17263 net.cpp:509] Setting up Convolution4
I0619 14:48:21.795701 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.795707 17263 net.cpp:524] Memory required for data: 152569344
I0619 14:48:21.795722 17263 layer_factory.hpp:77] Creating layer BatchNorm4
I0619 14:48:21.795735 17263 net.cpp:459] Creating Layer BatchNorm4
I0619 14:48:21.795742 17263 net.cpp:886] BatchNorm4 <- Convolution4
I0619 14:48:21.795750 17263 net.cpp:847] BatchNorm4 -> Convolution4 (in-place)
I0619 14:48:21.796098 17263 net.cpp:509] Setting up BatchNorm4
I0619 14:48:21.796110 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.796115 17263 net.cpp:524] Memory required for data: 160957952
I0619 14:48:21.796133 17263 layer_factory.hpp:77] Creating layer Scale4
I0619 14:48:21.796142 17263 net.cpp:459] Creating Layer Scale4
I0619 14:48:21.796149 17263 net.cpp:886] Scale4 <- Convolution4
I0619 14:48:21.796160 17263 net.cpp:847] Scale4 -> Convolution4 (in-place)
I0619 14:48:21.796216 17263 layer_factory.hpp:77] Creating layer Scale4
I0619 14:48:21.796414 17263 net.cpp:509] Setting up Scale4
I0619 14:48:21.796427 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.796432 17263 net.cpp:524] Memory required for data: 169346560
I0619 14:48:21.796448 17263 layer_factory.hpp:77] Creating layer ReLU4
I0619 14:48:21.796458 17263 net.cpp:459] Creating Layer ReLU4
I0619 14:48:21.796464 17263 net.cpp:886] ReLU4 <- Convolution4
I0619 14:48:21.796473 17263 net.cpp:847] ReLU4 -> Convolution4 (in-place)
I0619 14:48:21.796483 17263 net.cpp:509] Setting up ReLU4
I0619 14:48:21.796490 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.796496 17263 net.cpp:524] Memory required for data: 177735168
I0619 14:48:21.796501 17263 layer_factory.hpp:77] Creating layer Convolution5
I0619 14:48:21.796517 17263 net.cpp:459] Creating Layer Convolution5
I0619 14:48:21.796524 17263 net.cpp:886] Convolution5 <- Convolution4
I0619 14:48:21.796535 17263 net.cpp:860] Convolution5 -> Convolution5
I0619 14:48:21.797080 17263 net.cpp:509] Setting up Convolution5
I0619 14:48:21.797093 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.797101 17263 net.cpp:524] Memory required for data: 186123776
I0619 14:48:21.797113 17263 layer_factory.hpp:77] Creating layer BatchNorm5
I0619 14:48:21.797134 17263 net.cpp:459] Creating Layer BatchNorm5
I0619 14:48:21.797140 17263 net.cpp:886] BatchNorm5 <- Convolution5
I0619 14:48:21.797153 17263 net.cpp:847] BatchNorm5 -> Convolution5 (in-place)
I0619 14:48:21.797488 17263 net.cpp:509] Setting up BatchNorm5
I0619 14:48:21.797500 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.797507 17263 net.cpp:524] Memory required for data: 194512384
I0619 14:48:21.797533 17263 layer_factory.hpp:77] Creating layer Scale5
I0619 14:48:21.797544 17263 net.cpp:459] Creating Layer Scale5
I0619 14:48:21.797549 17263 net.cpp:886] Scale5 <- Convolution5
I0619 14:48:21.797559 17263 net.cpp:847] Scale5 -> Convolution5 (in-place)
I0619 14:48:21.797616 17263 layer_factory.hpp:77] Creating layer Scale5
I0619 14:48:21.797816 17263 net.cpp:509] Setting up Scale5
I0619 14:48:21.797828 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.797834 17263 net.cpp:524] Memory required for data: 202900992
I0619 14:48:21.797852 17263 layer_factory.hpp:77] Creating layer Eltwise2
I0619 14:48:21.797863 17263 net.cpp:459] Creating Layer Eltwise2
I0619 14:48:21.797869 17263 net.cpp:886] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0619 14:48:21.797878 17263 net.cpp:886] Eltwise2 <- Convolution5
I0619 14:48:21.797889 17263 net.cpp:860] Eltwise2 -> Eltwise2
I0619 14:48:21.797927 17263 net.cpp:509] Setting up Eltwise2
I0619 14:48:21.797937 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.797942 17263 net.cpp:524] Memory required for data: 211289600
I0619 14:48:21.797953 17263 layer_factory.hpp:77] Creating layer ReLU5
I0619 14:48:21.797965 17263 net.cpp:459] Creating Layer ReLU5
I0619 14:48:21.797988 17263 net.cpp:886] ReLU5 <- Eltwise2
I0619 14:48:21.797999 17263 net.cpp:847] ReLU5 -> Eltwise2 (in-place)
I0619 14:48:21.798012 17263 net.cpp:509] Setting up ReLU5
I0619 14:48:21.798019 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.798025 17263 net.cpp:524] Memory required for data: 219678208
I0619 14:48:21.798032 17263 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0619 14:48:21.798039 17263 net.cpp:459] Creating Layer Eltwise2_ReLU5_0_split
I0619 14:48:21.798045 17263 net.cpp:886] Eltwise2_ReLU5_0_split <- Eltwise2
I0619 14:48:21.798055 17263 net.cpp:860] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0619 14:48:21.798066 17263 net.cpp:860] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0619 14:48:21.798133 17263 net.cpp:509] Setting up Eltwise2_ReLU5_0_split
I0619 14:48:21.798144 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.798153 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.798159 17263 net.cpp:524] Memory required for data: 236455424
I0619 14:48:21.798164 17263 layer_factory.hpp:77] Creating layer Convolution6
I0619 14:48:21.798182 17263 net.cpp:459] Creating Layer Convolution6
I0619 14:48:21.798188 17263 net.cpp:886] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0619 14:48:21.798198 17263 net.cpp:860] Convolution6 -> Convolution6
I0619 14:48:21.798746 17263 net.cpp:509] Setting up Convolution6
I0619 14:48:21.798761 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.798768 17263 net.cpp:524] Memory required for data: 244844032
I0619 14:48:21.798784 17263 layer_factory.hpp:77] Creating layer BatchNorm6
I0619 14:48:21.798799 17263 net.cpp:459] Creating Layer BatchNorm6
I0619 14:48:21.798805 17263 net.cpp:886] BatchNorm6 <- Convolution6
I0619 14:48:21.798815 17263 net.cpp:847] BatchNorm6 -> Convolution6 (in-place)
I0619 14:48:21.799147 17263 net.cpp:509] Setting up BatchNorm6
I0619 14:48:21.799159 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.799165 17263 net.cpp:524] Memory required for data: 253232640
I0619 14:48:21.799180 17263 layer_factory.hpp:77] Creating layer Scale6
I0619 14:48:21.799191 17263 net.cpp:459] Creating Layer Scale6
I0619 14:48:21.799197 17263 net.cpp:886] Scale6 <- Convolution6
I0619 14:48:21.799208 17263 net.cpp:847] Scale6 -> Convolution6 (in-place)
I0619 14:48:21.799258 17263 layer_factory.hpp:77] Creating layer Scale6
I0619 14:48:21.799442 17263 net.cpp:509] Setting up Scale6
I0619 14:48:21.799453 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.799458 17263 net.cpp:524] Memory required for data: 261621248
I0619 14:48:21.799474 17263 layer_factory.hpp:77] Creating layer ReLU6
I0619 14:48:21.799485 17263 net.cpp:459] Creating Layer ReLU6
I0619 14:48:21.799491 17263 net.cpp:886] ReLU6 <- Convolution6
I0619 14:48:21.799499 17263 net.cpp:847] ReLU6 -> Convolution6 (in-place)
I0619 14:48:21.799510 17263 net.cpp:509] Setting up ReLU6
I0619 14:48:21.799517 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.799522 17263 net.cpp:524] Memory required for data: 270009856
I0619 14:48:21.799528 17263 layer_factory.hpp:77] Creating layer Convolution7
I0619 14:48:21.799543 17263 net.cpp:459] Creating Layer Convolution7
I0619 14:48:21.799549 17263 net.cpp:886] Convolution7 <- Convolution6
I0619 14:48:21.799561 17263 net.cpp:860] Convolution7 -> Convolution7
I0619 14:48:21.800067 17263 net.cpp:509] Setting up Convolution7
I0619 14:48:21.800079 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.800086 17263 net.cpp:524] Memory required for data: 278398464
I0619 14:48:21.800098 17263 layer_factory.hpp:77] Creating layer BatchNorm7
I0619 14:48:21.800119 17263 net.cpp:459] Creating Layer BatchNorm7
I0619 14:48:21.800127 17263 net.cpp:886] BatchNorm7 <- Convolution7
I0619 14:48:21.800138 17263 net.cpp:847] BatchNorm7 -> Convolution7 (in-place)
I0619 14:48:21.800456 17263 net.cpp:509] Setting up BatchNorm7
I0619 14:48:21.800470 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.800493 17263 net.cpp:524] Memory required for data: 286787072
I0619 14:48:21.800510 17263 layer_factory.hpp:77] Creating layer Scale7
I0619 14:48:21.800523 17263 net.cpp:459] Creating Layer Scale7
I0619 14:48:21.800530 17263 net.cpp:886] Scale7 <- Convolution7
I0619 14:48:21.800539 17263 net.cpp:847] Scale7 -> Convolution7 (in-place)
I0619 14:48:21.800595 17263 layer_factory.hpp:77] Creating layer Scale7
I0619 14:48:21.800792 17263 net.cpp:509] Setting up Scale7
I0619 14:48:21.800803 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.800809 17263 net.cpp:524] Memory required for data: 295175680
I0619 14:48:21.800823 17263 layer_factory.hpp:77] Creating layer Eltwise3
I0619 14:48:21.800834 17263 net.cpp:459] Creating Layer Eltwise3
I0619 14:48:21.800840 17263 net.cpp:886] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0619 14:48:21.800850 17263 net.cpp:886] Eltwise3 <- Convolution7
I0619 14:48:21.800860 17263 net.cpp:860] Eltwise3 -> Eltwise3
I0619 14:48:21.800899 17263 net.cpp:509] Setting up Eltwise3
I0619 14:48:21.800909 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.800914 17263 net.cpp:524] Memory required for data: 303564288
I0619 14:48:21.800920 17263 layer_factory.hpp:77] Creating layer ReLU7
I0619 14:48:21.800927 17263 net.cpp:459] Creating Layer ReLU7
I0619 14:48:21.800932 17263 net.cpp:886] ReLU7 <- Eltwise3
I0619 14:48:21.800940 17263 net.cpp:847] ReLU7 -> Eltwise3 (in-place)
I0619 14:48:21.800950 17263 net.cpp:509] Setting up ReLU7
I0619 14:48:21.800957 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.800962 17263 net.cpp:524] Memory required for data: 311952896
I0619 14:48:21.800968 17263 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0619 14:48:21.800978 17263 net.cpp:459] Creating Layer Eltwise3_ReLU7_0_split
I0619 14:48:21.800984 17263 net.cpp:886] Eltwise3_ReLU7_0_split <- Eltwise3
I0619 14:48:21.800992 17263 net.cpp:860] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0619 14:48:21.801002 17263 net.cpp:860] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0619 14:48:21.801060 17263 net.cpp:509] Setting up Eltwise3_ReLU7_0_split
I0619 14:48:21.801069 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.801077 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.801084 17263 net.cpp:524] Memory required for data: 328730112
I0619 14:48:21.801090 17263 layer_factory.hpp:77] Creating layer Convolution8
I0619 14:48:21.801101 17263 net.cpp:459] Creating Layer Convolution8
I0619 14:48:21.801107 17263 net.cpp:886] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0619 14:48:21.801117 17263 net.cpp:860] Convolution8 -> Convolution8
I0619 14:48:21.801617 17263 net.cpp:509] Setting up Convolution8
I0619 14:48:21.801630 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.801635 17263 net.cpp:524] Memory required for data: 337118720
I0619 14:48:21.801648 17263 layer_factory.hpp:77] Creating layer BatchNorm8
I0619 14:48:21.801661 17263 net.cpp:459] Creating Layer BatchNorm8
I0619 14:48:21.801667 17263 net.cpp:886] BatchNorm8 <- Convolution8
I0619 14:48:21.801676 17263 net.cpp:847] BatchNorm8 -> Convolution8 (in-place)
I0619 14:48:21.802048 17263 net.cpp:509] Setting up BatchNorm8
I0619 14:48:21.802062 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.802067 17263 net.cpp:524] Memory required for data: 345507328
I0619 14:48:21.802089 17263 layer_factory.hpp:77] Creating layer Scale8
I0619 14:48:21.802099 17263 net.cpp:459] Creating Layer Scale8
I0619 14:48:21.802106 17263 net.cpp:886] Scale8 <- Convolution8
I0619 14:48:21.802114 17263 net.cpp:847] Scale8 -> Convolution8 (in-place)
I0619 14:48:21.802173 17263 layer_factory.hpp:77] Creating layer Scale8
I0619 14:48:21.802547 17263 net.cpp:509] Setting up Scale8
I0619 14:48:21.802561 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.802567 17263 net.cpp:524] Memory required for data: 353895936
I0619 14:48:21.802582 17263 layer_factory.hpp:77] Creating layer ReLU8
I0619 14:48:21.802599 17263 net.cpp:459] Creating Layer ReLU8
I0619 14:48:21.802623 17263 net.cpp:886] ReLU8 <- Convolution8
I0619 14:48:21.802633 17263 net.cpp:847] ReLU8 -> Convolution8 (in-place)
I0619 14:48:21.802644 17263 net.cpp:509] Setting up ReLU8
I0619 14:48:21.802651 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.802657 17263 net.cpp:524] Memory required for data: 362284544
I0619 14:48:21.802662 17263 layer_factory.hpp:77] Creating layer Convolution9
I0619 14:48:21.802678 17263 net.cpp:459] Creating Layer Convolution9
I0619 14:48:21.802685 17263 net.cpp:886] Convolution9 <- Convolution8
I0619 14:48:21.802695 17263 net.cpp:860] Convolution9 -> Convolution9
I0619 14:48:21.803200 17263 net.cpp:509] Setting up Convolution9
I0619 14:48:21.803213 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.803220 17263 net.cpp:524] Memory required for data: 370673152
I0619 14:48:21.803232 17263 layer_factory.hpp:77] Creating layer BatchNorm9
I0619 14:48:21.803244 17263 net.cpp:459] Creating Layer BatchNorm9
I0619 14:48:21.803251 17263 net.cpp:886] BatchNorm9 <- Convolution9
I0619 14:48:21.803259 17263 net.cpp:847] BatchNorm9 -> Convolution9 (in-place)
I0619 14:48:21.803580 17263 net.cpp:509] Setting up BatchNorm9
I0619 14:48:21.803591 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.803598 17263 net.cpp:524] Memory required for data: 379061760
I0619 14:48:21.803613 17263 layer_factory.hpp:77] Creating layer Scale9
I0619 14:48:21.803623 17263 net.cpp:459] Creating Layer Scale9
I0619 14:48:21.803629 17263 net.cpp:886] Scale9 <- Convolution9
I0619 14:48:21.803637 17263 net.cpp:847] Scale9 -> Convolution9 (in-place)
I0619 14:48:21.803696 17263 layer_factory.hpp:77] Creating layer Scale9
I0619 14:48:21.803881 17263 net.cpp:509] Setting up Scale9
I0619 14:48:21.803892 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.803897 17263 net.cpp:524] Memory required for data: 387450368
I0619 14:48:21.803912 17263 layer_factory.hpp:77] Creating layer Eltwise4
I0619 14:48:21.803922 17263 net.cpp:459] Creating Layer Eltwise4
I0619 14:48:21.803930 17263 net.cpp:886] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0619 14:48:21.803936 17263 net.cpp:886] Eltwise4 <- Convolution9
I0619 14:48:21.803947 17263 net.cpp:860] Eltwise4 -> Eltwise4
I0619 14:48:21.803983 17263 net.cpp:509] Setting up Eltwise4
I0619 14:48:21.803992 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.803998 17263 net.cpp:524] Memory required for data: 395838976
I0619 14:48:21.804003 17263 layer_factory.hpp:77] Creating layer ReLU9
I0619 14:48:21.804021 17263 net.cpp:459] Creating Layer ReLU9
I0619 14:48:21.804028 17263 net.cpp:886] ReLU9 <- Eltwise4
I0619 14:48:21.804035 17263 net.cpp:847] ReLU9 -> Eltwise4 (in-place)
I0619 14:48:21.804044 17263 net.cpp:509] Setting up ReLU9
I0619 14:48:21.804054 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.804059 17263 net.cpp:524] Memory required for data: 404227584
I0619 14:48:21.804065 17263 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0619 14:48:21.804074 17263 net.cpp:459] Creating Layer Eltwise4_ReLU9_0_split
I0619 14:48:21.804078 17263 net.cpp:886] Eltwise4_ReLU9_0_split <- Eltwise4
I0619 14:48:21.804090 17263 net.cpp:860] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0619 14:48:21.804100 17263 net.cpp:860] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0619 14:48:21.804167 17263 net.cpp:509] Setting up Eltwise4_ReLU9_0_split
I0619 14:48:21.804178 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.804186 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.804191 17263 net.cpp:524] Memory required for data: 421004800
I0619 14:48:21.804198 17263 layer_factory.hpp:77] Creating layer Convolution10
I0619 14:48:21.804213 17263 net.cpp:459] Creating Layer Convolution10
I0619 14:48:21.804219 17263 net.cpp:886] Convolution10 <- Eltwise4_ReLU9_0_split_0
I0619 14:48:21.804229 17263 net.cpp:860] Convolution10 -> Convolution10
I0619 14:48:21.804745 17263 net.cpp:509] Setting up Convolution10
I0619 14:48:21.804762 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.804783 17263 net.cpp:524] Memory required for data: 429393408
I0619 14:48:21.804814 17263 layer_factory.hpp:77] Creating layer BatchNorm10
I0619 14:48:21.804826 17263 net.cpp:459] Creating Layer BatchNorm10
I0619 14:48:21.804832 17263 net.cpp:886] BatchNorm10 <- Convolution10
I0619 14:48:21.804844 17263 net.cpp:847] BatchNorm10 -> Convolution10 (in-place)
I0619 14:48:21.805166 17263 net.cpp:509] Setting up BatchNorm10
I0619 14:48:21.805178 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.805184 17263 net.cpp:524] Memory required for data: 437782016
I0619 14:48:21.805199 17263 layer_factory.hpp:77] Creating layer Scale10
I0619 14:48:21.805209 17263 net.cpp:459] Creating Layer Scale10
I0619 14:48:21.805215 17263 net.cpp:886] Scale10 <- Convolution10
I0619 14:48:21.805223 17263 net.cpp:847] Scale10 -> Convolution10 (in-place)
I0619 14:48:21.805277 17263 layer_factory.hpp:77] Creating layer Scale10
I0619 14:48:21.805469 17263 net.cpp:509] Setting up Scale10
I0619 14:48:21.805481 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.805487 17263 net.cpp:524] Memory required for data: 446170624
I0619 14:48:21.805500 17263 layer_factory.hpp:77] Creating layer ReLU10
I0619 14:48:21.805508 17263 net.cpp:459] Creating Layer ReLU10
I0619 14:48:21.805517 17263 net.cpp:886] ReLU10 <- Convolution10
I0619 14:48:21.805526 17263 net.cpp:847] ReLU10 -> Convolution10 (in-place)
I0619 14:48:21.805536 17263 net.cpp:509] Setting up ReLU10
I0619 14:48:21.805543 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.805548 17263 net.cpp:524] Memory required for data: 454559232
I0619 14:48:21.805554 17263 layer_factory.hpp:77] Creating layer Convolution11
I0619 14:48:21.805568 17263 net.cpp:459] Creating Layer Convolution11
I0619 14:48:21.805574 17263 net.cpp:886] Convolution11 <- Convolution10
I0619 14:48:21.805584 17263 net.cpp:860] Convolution11 -> Convolution11
I0619 14:48:21.806090 17263 net.cpp:509] Setting up Convolution11
I0619 14:48:21.806103 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.806108 17263 net.cpp:524] Memory required for data: 462947840
I0619 14:48:21.806121 17263 layer_factory.hpp:77] Creating layer BatchNorm11
I0619 14:48:21.806131 17263 net.cpp:459] Creating Layer BatchNorm11
I0619 14:48:21.806138 17263 net.cpp:886] BatchNorm11 <- Convolution11
I0619 14:48:21.806150 17263 net.cpp:847] BatchNorm11 -> Convolution11 (in-place)
I0619 14:48:21.806480 17263 net.cpp:509] Setting up BatchNorm11
I0619 14:48:21.806493 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.806499 17263 net.cpp:524] Memory required for data: 471336448
I0619 14:48:21.806514 17263 layer_factory.hpp:77] Creating layer Scale11
I0619 14:48:21.806524 17263 net.cpp:459] Creating Layer Scale11
I0619 14:48:21.806529 17263 net.cpp:886] Scale11 <- Convolution11
I0619 14:48:21.806540 17263 net.cpp:847] Scale11 -> Convolution11 (in-place)
I0619 14:48:21.806591 17263 layer_factory.hpp:77] Creating layer Scale11
I0619 14:48:21.806780 17263 net.cpp:509] Setting up Scale11
I0619 14:48:21.806792 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.806797 17263 net.cpp:524] Memory required for data: 479725056
I0619 14:48:21.806810 17263 layer_factory.hpp:77] Creating layer Eltwise5
I0619 14:48:21.806823 17263 net.cpp:459] Creating Layer Eltwise5
I0619 14:48:21.806829 17263 net.cpp:886] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0619 14:48:21.806836 17263 net.cpp:886] Eltwise5 <- Convolution11
I0619 14:48:21.806845 17263 net.cpp:860] Eltwise5 -> Eltwise5
I0619 14:48:21.806885 17263 net.cpp:509] Setting up Eltwise5
I0619 14:48:21.806895 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.806900 17263 net.cpp:524] Memory required for data: 488113664
I0619 14:48:21.806905 17263 layer_factory.hpp:77] Creating layer ReLU11
I0619 14:48:21.806912 17263 net.cpp:459] Creating Layer ReLU11
I0619 14:48:21.806918 17263 net.cpp:886] ReLU11 <- Eltwise5
I0619 14:48:21.806932 17263 net.cpp:847] ReLU11 -> Eltwise5 (in-place)
I0619 14:48:21.806962 17263 net.cpp:509] Setting up ReLU11
I0619 14:48:21.806972 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.806977 17263 net.cpp:524] Memory required for data: 496502272
I0619 14:48:21.806982 17263 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0619 14:48:21.806991 17263 net.cpp:459] Creating Layer Eltwise5_ReLU11_0_split
I0619 14:48:21.806996 17263 net.cpp:886] Eltwise5_ReLU11_0_split <- Eltwise5
I0619 14:48:21.807005 17263 net.cpp:860] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0619 14:48:21.807015 17263 net.cpp:860] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0619 14:48:21.807078 17263 net.cpp:509] Setting up Eltwise5_ReLU11_0_split
I0619 14:48:21.807088 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.807096 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.807101 17263 net.cpp:524] Memory required for data: 513279488
I0619 14:48:21.807106 17263 layer_factory.hpp:77] Creating layer Convolution12
I0619 14:48:21.807122 17263 net.cpp:459] Creating Layer Convolution12
I0619 14:48:21.807129 17263 net.cpp:886] Convolution12 <- Eltwise5_ReLU11_0_split_0
I0619 14:48:21.807140 17263 net.cpp:860] Convolution12 -> Convolution12
I0619 14:48:21.807648 17263 net.cpp:509] Setting up Convolution12
I0619 14:48:21.807662 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.807667 17263 net.cpp:524] Memory required for data: 521668096
I0619 14:48:21.807682 17263 layer_factory.hpp:77] Creating layer BatchNorm12
I0619 14:48:21.807695 17263 net.cpp:459] Creating Layer BatchNorm12
I0619 14:48:21.807703 17263 net.cpp:886] BatchNorm12 <- Convolution12
I0619 14:48:21.807713 17263 net.cpp:847] BatchNorm12 -> Convolution12 (in-place)
I0619 14:48:21.808029 17263 net.cpp:509] Setting up BatchNorm12
I0619 14:48:21.808040 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.808046 17263 net.cpp:524] Memory required for data: 530056704
I0619 14:48:21.808068 17263 layer_factory.hpp:77] Creating layer Scale12
I0619 14:48:21.808078 17263 net.cpp:459] Creating Layer Scale12
I0619 14:48:21.808084 17263 net.cpp:886] Scale12 <- Convolution12
I0619 14:48:21.808091 17263 net.cpp:847] Scale12 -> Convolution12 (in-place)
I0619 14:48:21.808145 17263 layer_factory.hpp:77] Creating layer Scale12
I0619 14:48:21.808326 17263 net.cpp:509] Setting up Scale12
I0619 14:48:21.808336 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.808341 17263 net.cpp:524] Memory required for data: 538445312
I0619 14:48:21.808354 17263 layer_factory.hpp:77] Creating layer ReLU12
I0619 14:48:21.808367 17263 net.cpp:459] Creating Layer ReLU12
I0619 14:48:21.808373 17263 net.cpp:886] ReLU12 <- Convolution12
I0619 14:48:21.808382 17263 net.cpp:847] ReLU12 -> Convolution12 (in-place)
I0619 14:48:21.808390 17263 net.cpp:509] Setting up ReLU12
I0619 14:48:21.808398 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.808403 17263 net.cpp:524] Memory required for data: 546833920
I0619 14:48:21.808408 17263 layer_factory.hpp:77] Creating layer Convolution13
I0619 14:48:21.808426 17263 net.cpp:459] Creating Layer Convolution13
I0619 14:48:21.808434 17263 net.cpp:886] Convolution13 <- Convolution12
I0619 14:48:21.808442 17263 net.cpp:860] Convolution13 -> Convolution13
I0619 14:48:21.808938 17263 net.cpp:509] Setting up Convolution13
I0619 14:48:21.808950 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.808956 17263 net.cpp:524] Memory required for data: 555222528
I0619 14:48:21.808969 17263 layer_factory.hpp:77] Creating layer BatchNorm13
I0619 14:48:21.808984 17263 net.cpp:459] Creating Layer BatchNorm13
I0619 14:48:21.808990 17263 net.cpp:886] BatchNorm13 <- Convolution13
I0619 14:48:21.808998 17263 net.cpp:847] BatchNorm13 -> Convolution13 (in-place)
I0619 14:48:21.809309 17263 net.cpp:509] Setting up BatchNorm13
I0619 14:48:21.809321 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.809327 17263 net.cpp:524] Memory required for data: 563611136
I0619 14:48:21.809350 17263 layer_factory.hpp:77] Creating layer Scale13
I0619 14:48:21.809376 17263 net.cpp:459] Creating Layer Scale13
I0619 14:48:21.809382 17263 net.cpp:886] Scale13 <- Convolution13
I0619 14:48:21.809391 17263 net.cpp:847] Scale13 -> Convolution13 (in-place)
I0619 14:48:21.809448 17263 layer_factory.hpp:77] Creating layer Scale13
I0619 14:48:21.809635 17263 net.cpp:509] Setting up Scale13
I0619 14:48:21.809648 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.809653 17263 net.cpp:524] Memory required for data: 571999744
I0619 14:48:21.809666 17263 layer_factory.hpp:77] Creating layer Eltwise6
I0619 14:48:21.809691 17263 net.cpp:459] Creating Layer Eltwise6
I0619 14:48:21.809698 17263 net.cpp:886] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0619 14:48:21.809706 17263 net.cpp:886] Eltwise6 <- Convolution13
I0619 14:48:21.809715 17263 net.cpp:860] Eltwise6 -> Eltwise6
I0619 14:48:21.809756 17263 net.cpp:509] Setting up Eltwise6
I0619 14:48:21.809767 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.809772 17263 net.cpp:524] Memory required for data: 580388352
I0619 14:48:21.809779 17263 layer_factory.hpp:77] Creating layer ReLU13
I0619 14:48:21.809787 17263 net.cpp:459] Creating Layer ReLU13
I0619 14:48:21.809792 17263 net.cpp:886] ReLU13 <- Eltwise6
I0619 14:48:21.809800 17263 net.cpp:847] ReLU13 -> Eltwise6 (in-place)
I0619 14:48:21.809809 17263 net.cpp:509] Setting up ReLU13
I0619 14:48:21.809816 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.809823 17263 net.cpp:524] Memory required for data: 588776960
I0619 14:48:21.809828 17263 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0619 14:48:21.809835 17263 net.cpp:459] Creating Layer Eltwise6_ReLU13_0_split
I0619 14:48:21.809840 17263 net.cpp:886] Eltwise6_ReLU13_0_split <- Eltwise6
I0619 14:48:21.809849 17263 net.cpp:860] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0619 14:48:21.809859 17263 net.cpp:860] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0619 14:48:21.809914 17263 net.cpp:509] Setting up Eltwise6_ReLU13_0_split
I0619 14:48:21.809924 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.809933 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.809938 17263 net.cpp:524] Memory required for data: 605554176
I0619 14:48:21.809945 17263 layer_factory.hpp:77] Creating layer Convolution14
I0619 14:48:21.809962 17263 net.cpp:459] Creating Layer Convolution14
I0619 14:48:21.809968 17263 net.cpp:886] Convolution14 <- Eltwise6_ReLU13_0_split_0
I0619 14:48:21.809978 17263 net.cpp:860] Convolution14 -> Convolution14
I0619 14:48:21.810487 17263 net.cpp:509] Setting up Convolution14
I0619 14:48:21.810499 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.810504 17263 net.cpp:524] Memory required for data: 613942784
I0619 14:48:21.810518 17263 layer_factory.hpp:77] Creating layer BatchNorm14
I0619 14:48:21.810529 17263 net.cpp:459] Creating Layer BatchNorm14
I0619 14:48:21.810536 17263 net.cpp:886] BatchNorm14 <- Convolution14
I0619 14:48:21.810547 17263 net.cpp:847] BatchNorm14 -> Convolution14 (in-place)
I0619 14:48:21.810849 17263 net.cpp:509] Setting up BatchNorm14
I0619 14:48:21.810859 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.810865 17263 net.cpp:524] Memory required for data: 622331392
I0619 14:48:21.810881 17263 layer_factory.hpp:77] Creating layer Scale14
I0619 14:48:21.810894 17263 net.cpp:459] Creating Layer Scale14
I0619 14:48:21.810899 17263 net.cpp:886] Scale14 <- Convolution14
I0619 14:48:21.810909 17263 net.cpp:847] Scale14 -> Convolution14 (in-place)
I0619 14:48:21.810957 17263 layer_factory.hpp:77] Creating layer Scale14
I0619 14:48:21.811125 17263 net.cpp:509] Setting up Scale14
I0619 14:48:21.811134 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.811141 17263 net.cpp:524] Memory required for data: 630720000
I0619 14:48:21.811152 17263 layer_factory.hpp:77] Creating layer ReLU14
I0619 14:48:21.811161 17263 net.cpp:459] Creating Layer ReLU14
I0619 14:48:21.811169 17263 net.cpp:886] ReLU14 <- Convolution14
I0619 14:48:21.811194 17263 net.cpp:847] ReLU14 -> Convolution14 (in-place)
I0619 14:48:21.811204 17263 net.cpp:509] Setting up ReLU14
I0619 14:48:21.811213 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.811218 17263 net.cpp:524] Memory required for data: 639108608
I0619 14:48:21.811223 17263 layer_factory.hpp:77] Creating layer Convolution15
I0619 14:48:21.811239 17263 net.cpp:459] Creating Layer Convolution15
I0619 14:48:21.811262 17263 net.cpp:886] Convolution15 <- Convolution14
I0619 14:48:21.811271 17263 net.cpp:860] Convolution15 -> Convolution15
I0619 14:48:21.811748 17263 net.cpp:509] Setting up Convolution15
I0619 14:48:21.811760 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.811766 17263 net.cpp:524] Memory required for data: 647497216
I0619 14:48:21.811779 17263 layer_factory.hpp:77] Creating layer BatchNorm15
I0619 14:48:21.811791 17263 net.cpp:459] Creating Layer BatchNorm15
I0619 14:48:21.811797 17263 net.cpp:886] BatchNorm15 <- Convolution15
I0619 14:48:21.811807 17263 net.cpp:847] BatchNorm15 -> Convolution15 (in-place)
I0619 14:48:21.812101 17263 net.cpp:509] Setting up BatchNorm15
I0619 14:48:21.812111 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.812117 17263 net.cpp:524] Memory required for data: 655885824
I0619 14:48:21.812134 17263 layer_factory.hpp:77] Creating layer Scale15
I0619 14:48:21.812147 17263 net.cpp:459] Creating Layer Scale15
I0619 14:48:21.812152 17263 net.cpp:886] Scale15 <- Convolution15
I0619 14:48:21.812160 17263 net.cpp:847] Scale15 -> Convolution15 (in-place)
I0619 14:48:21.812214 17263 layer_factory.hpp:77] Creating layer Scale15
I0619 14:48:21.812391 17263 net.cpp:509] Setting up Scale15
I0619 14:48:21.812402 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.812407 17263 net.cpp:524] Memory required for data: 664274432
I0619 14:48:21.812418 17263 layer_factory.hpp:77] Creating layer Eltwise7
I0619 14:48:21.812427 17263 net.cpp:459] Creating Layer Eltwise7
I0619 14:48:21.812433 17263 net.cpp:886] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0619 14:48:21.812443 17263 net.cpp:886] Eltwise7 <- Convolution15
I0619 14:48:21.812450 17263 net.cpp:860] Eltwise7 -> Eltwise7
I0619 14:48:21.812490 17263 net.cpp:509] Setting up Eltwise7
I0619 14:48:21.812500 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.812505 17263 net.cpp:524] Memory required for data: 672663040
I0619 14:48:21.812510 17263 layer_factory.hpp:77] Creating layer ReLU15
I0619 14:48:21.812518 17263 net.cpp:459] Creating Layer ReLU15
I0619 14:48:21.812523 17263 net.cpp:886] ReLU15 <- Eltwise7
I0619 14:48:21.812531 17263 net.cpp:847] ReLU15 -> Eltwise7 (in-place)
I0619 14:48:21.812539 17263 net.cpp:509] Setting up ReLU15
I0619 14:48:21.812546 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.812552 17263 net.cpp:524] Memory required for data: 681051648
I0619 14:48:21.812557 17263 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0619 14:48:21.812579 17263 net.cpp:459] Creating Layer Eltwise7_ReLU15_0_split
I0619 14:48:21.812587 17263 net.cpp:886] Eltwise7_ReLU15_0_split <- Eltwise7
I0619 14:48:21.812594 17263 net.cpp:860] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0619 14:48:21.812604 17263 net.cpp:860] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0619 14:48:21.812659 17263 net.cpp:509] Setting up Eltwise7_ReLU15_0_split
I0619 14:48:21.812669 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.812675 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.812680 17263 net.cpp:524] Memory required for data: 697828864
I0619 14:48:21.812685 17263 layer_factory.hpp:77] Creating layer Convolution16
I0619 14:48:21.812697 17263 net.cpp:459] Creating Layer Convolution16
I0619 14:48:21.812703 17263 net.cpp:886] Convolution16 <- Eltwise7_ReLU15_0_split_0
I0619 14:48:21.812712 17263 net.cpp:860] Convolution16 -> Convolution16
I0619 14:48:21.813187 17263 net.cpp:509] Setting up Convolution16
I0619 14:48:21.813204 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.813225 17263 net.cpp:524] Memory required for data: 706217472
I0619 14:48:21.813240 17263 layer_factory.hpp:77] Creating layer BatchNorm16
I0619 14:48:21.813252 17263 net.cpp:459] Creating Layer BatchNorm16
I0619 14:48:21.813259 17263 net.cpp:886] BatchNorm16 <- Convolution16
I0619 14:48:21.813267 17263 net.cpp:847] BatchNorm16 -> Convolution16 (in-place)
I0619 14:48:21.813568 17263 net.cpp:509] Setting up BatchNorm16
I0619 14:48:21.813578 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.813585 17263 net.cpp:524] Memory required for data: 714606080
I0619 14:48:21.813599 17263 layer_factory.hpp:77] Creating layer Scale16
I0619 14:48:21.813608 17263 net.cpp:459] Creating Layer Scale16
I0619 14:48:21.813614 17263 net.cpp:886] Scale16 <- Convolution16
I0619 14:48:21.813621 17263 net.cpp:847] Scale16 -> Convolution16 (in-place)
I0619 14:48:21.813678 17263 layer_factory.hpp:77] Creating layer Scale16
I0619 14:48:21.813863 17263 net.cpp:509] Setting up Scale16
I0619 14:48:21.813874 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.813879 17263 net.cpp:524] Memory required for data: 722994688
I0619 14:48:21.813894 17263 layer_factory.hpp:77] Creating layer ReLU16
I0619 14:48:21.813904 17263 net.cpp:459] Creating Layer ReLU16
I0619 14:48:21.813910 17263 net.cpp:886] ReLU16 <- Convolution16
I0619 14:48:21.813916 17263 net.cpp:847] ReLU16 -> Convolution16 (in-place)
I0619 14:48:21.813930 17263 net.cpp:509] Setting up ReLU16
I0619 14:48:21.813937 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.813943 17263 net.cpp:524] Memory required for data: 731383296
I0619 14:48:21.813948 17263 layer_factory.hpp:77] Creating layer Convolution17
I0619 14:48:21.813961 17263 net.cpp:459] Creating Layer Convolution17
I0619 14:48:21.813966 17263 net.cpp:886] Convolution17 <- Convolution16
I0619 14:48:21.813977 17263 net.cpp:860] Convolution17 -> Convolution17
I0619 14:48:21.814460 17263 net.cpp:509] Setting up Convolution17
I0619 14:48:21.814472 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.814479 17263 net.cpp:524] Memory required for data: 739771904
I0619 14:48:21.814492 17263 layer_factory.hpp:77] Creating layer BatchNorm17
I0619 14:48:21.814502 17263 net.cpp:459] Creating Layer BatchNorm17
I0619 14:48:21.814510 17263 net.cpp:886] BatchNorm17 <- Convolution17
I0619 14:48:21.814522 17263 net.cpp:847] BatchNorm17 -> Convolution17 (in-place)
I0619 14:48:21.814822 17263 net.cpp:509] Setting up BatchNorm17
I0619 14:48:21.814833 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.814838 17263 net.cpp:524] Memory required for data: 748160512
I0619 14:48:21.814856 17263 layer_factory.hpp:77] Creating layer Scale17
I0619 14:48:21.814864 17263 net.cpp:459] Creating Layer Scale17
I0619 14:48:21.814869 17263 net.cpp:886] Scale17 <- Convolution17
I0619 14:48:21.814877 17263 net.cpp:847] Scale17 -> Convolution17 (in-place)
I0619 14:48:21.814929 17263 layer_factory.hpp:77] Creating layer Scale17
I0619 14:48:21.815102 17263 net.cpp:509] Setting up Scale17
I0619 14:48:21.815112 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.815119 17263 net.cpp:524] Memory required for data: 756549120
I0619 14:48:21.815131 17263 layer_factory.hpp:77] Creating layer Eltwise8
I0619 14:48:21.815140 17263 net.cpp:459] Creating Layer Eltwise8
I0619 14:48:21.815147 17263 net.cpp:886] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0619 14:48:21.815156 17263 net.cpp:886] Eltwise8 <- Convolution17
I0619 14:48:21.815165 17263 net.cpp:860] Eltwise8 -> Eltwise8
I0619 14:48:21.815201 17263 net.cpp:509] Setting up Eltwise8
I0619 14:48:21.815209 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.815214 17263 net.cpp:524] Memory required for data: 764937728
I0619 14:48:21.815219 17263 layer_factory.hpp:77] Creating layer ReLU17
I0619 14:48:21.815230 17263 net.cpp:459] Creating Layer ReLU17
I0619 14:48:21.815235 17263 net.cpp:886] ReLU17 <- Eltwise8
I0619 14:48:21.815243 17263 net.cpp:847] ReLU17 -> Eltwise8 (in-place)
I0619 14:48:21.815256 17263 net.cpp:509] Setting up ReLU17
I0619 14:48:21.815279 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.815285 17263 net.cpp:524] Memory required for data: 773326336
I0619 14:48:21.815290 17263 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0619 14:48:21.815304 17263 net.cpp:459] Creating Layer Eltwise8_ReLU17_0_split
I0619 14:48:21.815310 17263 net.cpp:886] Eltwise8_ReLU17_0_split <- Eltwise8
I0619 14:48:21.815317 17263 net.cpp:860] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0619 14:48:21.815327 17263 net.cpp:860] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0619 14:48:21.815382 17263 net.cpp:509] Setting up Eltwise8_ReLU17_0_split
I0619 14:48:21.815392 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.815399 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.815404 17263 net.cpp:524] Memory required for data: 790103552
I0619 14:48:21.815410 17263 layer_factory.hpp:77] Creating layer Convolution18
I0619 14:48:21.815425 17263 net.cpp:459] Creating Layer Convolution18
I0619 14:48:21.815431 17263 net.cpp:886] Convolution18 <- Eltwise8_ReLU17_0_split_0
I0619 14:48:21.815441 17263 net.cpp:860] Convolution18 -> Convolution18
I0619 14:48:21.815938 17263 net.cpp:509] Setting up Convolution18
I0619 14:48:21.815951 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.815956 17263 net.cpp:524] Memory required for data: 798492160
I0619 14:48:21.815969 17263 layer_factory.hpp:77] Creating layer BatchNorm18
I0619 14:48:21.815979 17263 net.cpp:459] Creating Layer BatchNorm18
I0619 14:48:21.815984 17263 net.cpp:886] BatchNorm18 <- Convolution18
I0619 14:48:21.815994 17263 net.cpp:847] BatchNorm18 -> Convolution18 (in-place)
I0619 14:48:21.816334 17263 net.cpp:509] Setting up BatchNorm18
I0619 14:48:21.816346 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.816351 17263 net.cpp:524] Memory required for data: 806880768
I0619 14:48:21.816367 17263 layer_factory.hpp:77] Creating layer Scale18
I0619 14:48:21.816376 17263 net.cpp:459] Creating Layer Scale18
I0619 14:48:21.816382 17263 net.cpp:886] Scale18 <- Convolution18
I0619 14:48:21.816395 17263 net.cpp:847] Scale18 -> Convolution18 (in-place)
I0619 14:48:21.816541 17263 layer_factory.hpp:77] Creating layer Scale18
I0619 14:48:21.816720 17263 net.cpp:509] Setting up Scale18
I0619 14:48:21.816731 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.816736 17263 net.cpp:524] Memory required for data: 815269376
I0619 14:48:21.816750 17263 layer_factory.hpp:77] Creating layer ReLU18
I0619 14:48:21.816761 17263 net.cpp:459] Creating Layer ReLU18
I0619 14:48:21.816767 17263 net.cpp:886] ReLU18 <- Convolution18
I0619 14:48:21.816776 17263 net.cpp:847] ReLU18 -> Convolution18 (in-place)
I0619 14:48:21.816786 17263 net.cpp:509] Setting up ReLU18
I0619 14:48:21.816792 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.816797 17263 net.cpp:524] Memory required for data: 823657984
I0619 14:48:21.816802 17263 layer_factory.hpp:77] Creating layer Convolution19
I0619 14:48:21.816820 17263 net.cpp:459] Creating Layer Convolution19
I0619 14:48:21.816828 17263 net.cpp:886] Convolution19 <- Convolution18
I0619 14:48:21.816836 17263 net.cpp:860] Convolution19 -> Convolution19
I0619 14:48:21.817312 17263 net.cpp:509] Setting up Convolution19
I0619 14:48:21.817325 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.817332 17263 net.cpp:524] Memory required for data: 832046592
I0619 14:48:21.817344 17263 layer_factory.hpp:77] Creating layer BatchNorm19
I0619 14:48:21.817356 17263 net.cpp:459] Creating Layer BatchNorm19
I0619 14:48:21.817363 17263 net.cpp:886] BatchNorm19 <- Convolution19
I0619 14:48:21.817371 17263 net.cpp:847] BatchNorm19 -> Convolution19 (in-place)
I0619 14:48:21.817672 17263 net.cpp:509] Setting up BatchNorm19
I0619 14:48:21.817683 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.817688 17263 net.cpp:524] Memory required for data: 840435200
I0619 14:48:21.817729 17263 layer_factory.hpp:77] Creating layer Scale19
I0619 14:48:21.817759 17263 net.cpp:459] Creating Layer Scale19
I0619 14:48:21.817772 17263 net.cpp:886] Scale19 <- Convolution19
I0619 14:48:21.817781 17263 net.cpp:847] Scale19 -> Convolution19 (in-place)
I0619 14:48:21.817842 17263 layer_factory.hpp:77] Creating layer Scale19
I0619 14:48:21.818019 17263 net.cpp:509] Setting up Scale19
I0619 14:48:21.818032 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.818037 17263 net.cpp:524] Memory required for data: 848823808
I0619 14:48:21.818049 17263 layer_factory.hpp:77] Creating layer Eltwise9
I0619 14:48:21.818058 17263 net.cpp:459] Creating Layer Eltwise9
I0619 14:48:21.818064 17263 net.cpp:886] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0619 14:48:21.818073 17263 net.cpp:886] Eltwise9 <- Convolution19
I0619 14:48:21.818080 17263 net.cpp:860] Eltwise9 -> Eltwise9
I0619 14:48:21.818122 17263 net.cpp:509] Setting up Eltwise9
I0619 14:48:21.818130 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.818135 17263 net.cpp:524] Memory required for data: 857212416
I0619 14:48:21.818140 17263 layer_factory.hpp:77] Creating layer ReLU19
I0619 14:48:21.818151 17263 net.cpp:459] Creating Layer ReLU19
I0619 14:48:21.818157 17263 net.cpp:886] ReLU19 <- Eltwise9
I0619 14:48:21.818166 17263 net.cpp:847] ReLU19 -> Eltwise9 (in-place)
I0619 14:48:21.818176 17263 net.cpp:509] Setting up ReLU19
I0619 14:48:21.818182 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.818187 17263 net.cpp:524] Memory required for data: 865601024
I0619 14:48:21.818192 17263 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0619 14:48:21.818199 17263 net.cpp:459] Creating Layer Eltwise9_ReLU19_0_split
I0619 14:48:21.818205 17263 net.cpp:886] Eltwise9_ReLU19_0_split <- Eltwise9
I0619 14:48:21.818212 17263 net.cpp:860] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0619 14:48:21.818222 17263 net.cpp:860] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0619 14:48:21.818275 17263 net.cpp:509] Setting up Eltwise9_ReLU19_0_split
I0619 14:48:21.818284 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.818290 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.818296 17263 net.cpp:524] Memory required for data: 882378240
I0619 14:48:21.818301 17263 layer_factory.hpp:77] Creating layer Convolution20
I0619 14:48:21.818316 17263 net.cpp:459] Creating Layer Convolution20
I0619 14:48:21.818323 17263 net.cpp:886] Convolution20 <- Eltwise9_ReLU19_0_split_0
I0619 14:48:21.818334 17263 net.cpp:860] Convolution20 -> Convolution20
I0619 14:48:21.818826 17263 net.cpp:509] Setting up Convolution20
I0619 14:48:21.818840 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.818845 17263 net.cpp:524] Memory required for data: 890766848
I0619 14:48:21.818858 17263 layer_factory.hpp:77] Creating layer BatchNorm20
I0619 14:48:21.818869 17263 net.cpp:459] Creating Layer BatchNorm20
I0619 14:48:21.818876 17263 net.cpp:886] BatchNorm20 <- Convolution20
I0619 14:48:21.818886 17263 net.cpp:847] BatchNorm20 -> Convolution20 (in-place)
I0619 14:48:21.819185 17263 net.cpp:509] Setting up BatchNorm20
I0619 14:48:21.819195 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.819200 17263 net.cpp:524] Memory required for data: 899155456
I0619 14:48:21.819216 17263 layer_factory.hpp:77] Creating layer Scale20
I0619 14:48:21.819228 17263 net.cpp:459] Creating Layer Scale20
I0619 14:48:21.819234 17263 net.cpp:886] Scale20 <- Convolution20
I0619 14:48:21.819242 17263 net.cpp:847] Scale20 -> Convolution20 (in-place)
I0619 14:48:21.819290 17263 layer_factory.hpp:77] Creating layer Scale20
I0619 14:48:21.819464 17263 net.cpp:509] Setting up Scale20
I0619 14:48:21.819478 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.819483 17263 net.cpp:524] Memory required for data: 907544064
I0619 14:48:21.819494 17263 layer_factory.hpp:77] Creating layer ReLU20
I0619 14:48:21.819504 17263 net.cpp:459] Creating Layer ReLU20
I0619 14:48:21.819509 17263 net.cpp:886] ReLU20 <- Convolution20
I0619 14:48:21.819520 17263 net.cpp:847] ReLU20 -> Convolution20 (in-place)
I0619 14:48:21.819546 17263 net.cpp:509] Setting up ReLU20
I0619 14:48:21.819555 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.819561 17263 net.cpp:524] Memory required for data: 915932672
I0619 14:48:21.819566 17263 layer_factory.hpp:77] Creating layer Convolution21
I0619 14:48:21.819581 17263 net.cpp:459] Creating Layer Convolution21
I0619 14:48:21.819587 17263 net.cpp:886] Convolution21 <- Convolution20
I0619 14:48:21.819599 17263 net.cpp:860] Convolution21 -> Convolution21
I0619 14:48:21.820077 17263 net.cpp:509] Setting up Convolution21
I0619 14:48:21.820091 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.820096 17263 net.cpp:524] Memory required for data: 924321280
I0619 14:48:21.820107 17263 layer_factory.hpp:77] Creating layer BatchNorm21
I0619 14:48:21.820118 17263 net.cpp:459] Creating Layer BatchNorm21
I0619 14:48:21.820124 17263 net.cpp:886] BatchNorm21 <- Convolution21
I0619 14:48:21.820134 17263 net.cpp:847] BatchNorm21 -> Convolution21 (in-place)
I0619 14:48:21.820428 17263 net.cpp:509] Setting up BatchNorm21
I0619 14:48:21.820439 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.820444 17263 net.cpp:524] Memory required for data: 932709888
I0619 14:48:21.820458 17263 layer_factory.hpp:77] Creating layer Scale21
I0619 14:48:21.820471 17263 net.cpp:459] Creating Layer Scale21
I0619 14:48:21.820477 17263 net.cpp:886] Scale21 <- Convolution21
I0619 14:48:21.820485 17263 net.cpp:847] Scale21 -> Convolution21 (in-place)
I0619 14:48:21.820538 17263 layer_factory.hpp:77] Creating layer Scale21
I0619 14:48:21.820708 17263 net.cpp:509] Setting up Scale21
I0619 14:48:21.820719 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.820724 17263 net.cpp:524] Memory required for data: 941098496
I0619 14:48:21.820736 17263 layer_factory.hpp:77] Creating layer Eltwise10
I0619 14:48:21.820745 17263 net.cpp:459] Creating Layer Eltwise10
I0619 14:48:21.820751 17263 net.cpp:886] Eltwise10 <- Eltwise9_ReLU19_0_split_1
I0619 14:48:21.820760 17263 net.cpp:886] Eltwise10 <- Convolution21
I0619 14:48:21.820783 17263 net.cpp:860] Eltwise10 -> Eltwise10
I0619 14:48:21.820822 17263 net.cpp:509] Setting up Eltwise10
I0619 14:48:21.820832 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.820837 17263 net.cpp:524] Memory required for data: 949487104
I0619 14:48:21.820842 17263 layer_factory.hpp:77] Creating layer ReLU21
I0619 14:48:21.820849 17263 net.cpp:459] Creating Layer ReLU21
I0619 14:48:21.820855 17263 net.cpp:886] ReLU21 <- Eltwise10
I0619 14:48:21.820864 17263 net.cpp:847] ReLU21 -> Eltwise10 (in-place)
I0619 14:48:21.820873 17263 net.cpp:509] Setting up ReLU21
I0619 14:48:21.820880 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.820885 17263 net.cpp:524] Memory required for data: 957875712
I0619 14:48:21.820891 17263 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0619 14:48:21.820897 17263 net.cpp:459] Creating Layer Eltwise10_ReLU21_0_split
I0619 14:48:21.820904 17263 net.cpp:886] Eltwise10_ReLU21_0_split <- Eltwise10
I0619 14:48:21.820914 17263 net.cpp:860] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0619 14:48:21.820924 17263 net.cpp:860] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0619 14:48:21.820978 17263 net.cpp:509] Setting up Eltwise10_ReLU21_0_split
I0619 14:48:21.820987 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.820994 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.820999 17263 net.cpp:524] Memory required for data: 974652928
I0619 14:48:21.821004 17263 layer_factory.hpp:77] Creating layer Convolution22
I0619 14:48:21.821017 17263 net.cpp:459] Creating Layer Convolution22
I0619 14:48:21.821022 17263 net.cpp:886] Convolution22 <- Eltwise10_ReLU21_0_split_0
I0619 14:48:21.821032 17263 net.cpp:860] Convolution22 -> Convolution22
I0619 14:48:21.821506 17263 net.cpp:509] Setting up Convolution22
I0619 14:48:21.821521 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.821527 17263 net.cpp:524] Memory required for data: 983041536
I0619 14:48:21.821554 17263 layer_factory.hpp:77] Creating layer BatchNorm22
I0619 14:48:21.821568 17263 net.cpp:459] Creating Layer BatchNorm22
I0619 14:48:21.821574 17263 net.cpp:886] BatchNorm22 <- Convolution22
I0619 14:48:21.821583 17263 net.cpp:847] BatchNorm22 -> Convolution22 (in-place)
I0619 14:48:21.821888 17263 net.cpp:509] Setting up BatchNorm22
I0619 14:48:21.821899 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.821904 17263 net.cpp:524] Memory required for data: 991430144
I0619 14:48:21.821918 17263 layer_factory.hpp:77] Creating layer Scale22
I0619 14:48:21.821928 17263 net.cpp:459] Creating Layer Scale22
I0619 14:48:21.821933 17263 net.cpp:886] Scale22 <- Convolution22
I0619 14:48:21.821941 17263 net.cpp:847] Scale22 -> Convolution22 (in-place)
I0619 14:48:21.821990 17263 layer_factory.hpp:77] Creating layer Scale22
I0619 14:48:21.822167 17263 net.cpp:509] Setting up Scale22
I0619 14:48:21.822177 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.822182 17263 net.cpp:524] Memory required for data: 999818752
I0619 14:48:21.822194 17263 layer_factory.hpp:77] Creating layer ReLU22
I0619 14:48:21.822206 17263 net.cpp:459] Creating Layer ReLU22
I0619 14:48:21.822212 17263 net.cpp:886] ReLU22 <- Convolution22
I0619 14:48:21.822219 17263 net.cpp:847] ReLU22 -> Convolution22 (in-place)
I0619 14:48:21.822228 17263 net.cpp:509] Setting up ReLU22
I0619 14:48:21.822237 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.822242 17263 net.cpp:524] Memory required for data: 1008207360
I0619 14:48:21.822247 17263 layer_factory.hpp:77] Creating layer Convolution23
I0619 14:48:21.822260 17263 net.cpp:459] Creating Layer Convolution23
I0619 14:48:21.822265 17263 net.cpp:886] Convolution23 <- Convolution22
I0619 14:48:21.822276 17263 net.cpp:860] Convolution23 -> Convolution23
I0619 14:48:21.822759 17263 net.cpp:509] Setting up Convolution23
I0619 14:48:21.822772 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.822777 17263 net.cpp:524] Memory required for data: 1016595968
I0619 14:48:21.822788 17263 layer_factory.hpp:77] Creating layer BatchNorm23
I0619 14:48:21.822798 17263 net.cpp:459] Creating Layer BatchNorm23
I0619 14:48:21.822803 17263 net.cpp:886] BatchNorm23 <- Convolution23
I0619 14:48:21.822810 17263 net.cpp:847] BatchNorm23 -> Convolution23 (in-place)
I0619 14:48:21.823107 17263 net.cpp:509] Setting up BatchNorm23
I0619 14:48:21.823119 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.823124 17263 net.cpp:524] Memory required for data: 1024984576
I0619 14:48:21.823139 17263 layer_factory.hpp:77] Creating layer Scale23
I0619 14:48:21.823148 17263 net.cpp:459] Creating Layer Scale23
I0619 14:48:21.823153 17263 net.cpp:886] Scale23 <- Convolution23
I0619 14:48:21.823160 17263 net.cpp:847] Scale23 -> Convolution23 (in-place)
I0619 14:48:21.823212 17263 layer_factory.hpp:77] Creating layer Scale23
I0619 14:48:21.823380 17263 net.cpp:509] Setting up Scale23
I0619 14:48:21.823390 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.823395 17263 net.cpp:524] Memory required for data: 1033373184
I0619 14:48:21.823406 17263 layer_factory.hpp:77] Creating layer Eltwise11
I0619 14:48:21.823417 17263 net.cpp:459] Creating Layer Eltwise11
I0619 14:48:21.823423 17263 net.cpp:886] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0619 14:48:21.823431 17263 net.cpp:886] Eltwise11 <- Convolution23
I0619 14:48:21.823438 17263 net.cpp:860] Eltwise11 -> Eltwise11
I0619 14:48:21.823472 17263 net.cpp:509] Setting up Eltwise11
I0619 14:48:21.823482 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.823485 17263 net.cpp:524] Memory required for data: 1041761792
I0619 14:48:21.823490 17263 layer_factory.hpp:77] Creating layer ReLU23
I0619 14:48:21.823499 17263 net.cpp:459] Creating Layer ReLU23
I0619 14:48:21.823504 17263 net.cpp:886] ReLU23 <- Eltwise11
I0619 14:48:21.823514 17263 net.cpp:847] ReLU23 -> Eltwise11 (in-place)
I0619 14:48:21.823529 17263 net.cpp:509] Setting up ReLU23
I0619 14:48:21.823551 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.823559 17263 net.cpp:524] Memory required for data: 1050150400
I0619 14:48:21.823565 17263 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0619 14:48:21.823572 17263 net.cpp:459] Creating Layer Eltwise11_ReLU23_0_split
I0619 14:48:21.823577 17263 net.cpp:886] Eltwise11_ReLU23_0_split <- Eltwise11
I0619 14:48:21.823585 17263 net.cpp:860] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0619 14:48:21.823595 17263 net.cpp:860] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0619 14:48:21.823647 17263 net.cpp:509] Setting up Eltwise11_ReLU23_0_split
I0619 14:48:21.823657 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.823663 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.823668 17263 net.cpp:524] Memory required for data: 1066927616
I0619 14:48:21.823673 17263 layer_factory.hpp:77] Creating layer Convolution24
I0619 14:48:21.823683 17263 net.cpp:459] Creating Layer Convolution24
I0619 14:48:21.823689 17263 net.cpp:886] Convolution24 <- Eltwise11_ReLU23_0_split_0
I0619 14:48:21.823700 17263 net.cpp:860] Convolution24 -> Convolution24
I0619 14:48:21.824153 17263 net.cpp:509] Setting up Convolution24
I0619 14:48:21.824165 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.824172 17263 net.cpp:524] Memory required for data: 1075316224
I0619 14:48:21.824183 17263 layer_factory.hpp:77] Creating layer BatchNorm24
I0619 14:48:21.824192 17263 net.cpp:459] Creating Layer BatchNorm24
I0619 14:48:21.824198 17263 net.cpp:886] BatchNorm24 <- Convolution24
I0619 14:48:21.824208 17263 net.cpp:847] BatchNorm24 -> Convolution24 (in-place)
I0619 14:48:21.824489 17263 net.cpp:509] Setting up BatchNorm24
I0619 14:48:21.824499 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.824503 17263 net.cpp:524] Memory required for data: 1083704832
I0619 14:48:21.824517 17263 layer_factory.hpp:77] Creating layer Scale24
I0619 14:48:21.824527 17263 net.cpp:459] Creating Layer Scale24
I0619 14:48:21.824532 17263 net.cpp:886] Scale24 <- Convolution24
I0619 14:48:21.824538 17263 net.cpp:847] Scale24 -> Convolution24 (in-place)
I0619 14:48:21.824585 17263 layer_factory.hpp:77] Creating layer Scale24
I0619 14:48:21.824753 17263 net.cpp:509] Setting up Scale24
I0619 14:48:21.824764 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.824769 17263 net.cpp:524] Memory required for data: 1092093440
I0619 14:48:21.824779 17263 layer_factory.hpp:77] Creating layer ReLU24
I0619 14:48:21.824790 17263 net.cpp:459] Creating Layer ReLU24
I0619 14:48:21.824795 17263 net.cpp:886] ReLU24 <- Convolution24
I0619 14:48:21.824802 17263 net.cpp:847] ReLU24 -> Convolution24 (in-place)
I0619 14:48:21.824810 17263 net.cpp:509] Setting up ReLU24
I0619 14:48:21.824817 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.824822 17263 net.cpp:524] Memory required for data: 1100482048
I0619 14:48:21.824826 17263 layer_factory.hpp:77] Creating layer Convolution25
I0619 14:48:21.824839 17263 net.cpp:459] Creating Layer Convolution25
I0619 14:48:21.824846 17263 net.cpp:886] Convolution25 <- Convolution24
I0619 14:48:21.824853 17263 net.cpp:860] Convolution25 -> Convolution25
I0619 14:48:21.825311 17263 net.cpp:509] Setting up Convolution25
I0619 14:48:21.825322 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.825328 17263 net.cpp:524] Memory required for data: 1108870656
I0619 14:48:21.825340 17263 layer_factory.hpp:77] Creating layer BatchNorm25
I0619 14:48:21.825350 17263 net.cpp:459] Creating Layer BatchNorm25
I0619 14:48:21.825356 17263 net.cpp:886] BatchNorm25 <- Convolution25
I0619 14:48:21.825364 17263 net.cpp:847] BatchNorm25 -> Convolution25 (in-place)
I0619 14:48:21.825654 17263 net.cpp:509] Setting up BatchNorm25
I0619 14:48:21.825664 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.825670 17263 net.cpp:524] Memory required for data: 1117259264
I0619 14:48:21.825686 17263 layer_factory.hpp:77] Creating layer Scale25
I0619 14:48:21.825709 17263 net.cpp:459] Creating Layer Scale25
I0619 14:48:21.825716 17263 net.cpp:886] Scale25 <- Convolution25
I0619 14:48:21.825726 17263 net.cpp:847] Scale25 -> Convolution25 (in-place)
I0619 14:48:21.825775 17263 layer_factory.hpp:77] Creating layer Scale25
I0619 14:48:21.825939 17263 net.cpp:509] Setting up Scale25
I0619 14:48:21.825949 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.825954 17263 net.cpp:524] Memory required for data: 1125647872
I0619 14:48:21.825966 17263 layer_factory.hpp:77] Creating layer Eltwise12
I0619 14:48:21.825978 17263 net.cpp:459] Creating Layer Eltwise12
I0619 14:48:21.825984 17263 net.cpp:886] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0619 14:48:21.825989 17263 net.cpp:886] Eltwise12 <- Convolution25
I0619 14:48:21.825997 17263 net.cpp:860] Eltwise12 -> Eltwise12
I0619 14:48:21.826041 17263 net.cpp:509] Setting up Eltwise12
I0619 14:48:21.826051 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.826056 17263 net.cpp:524] Memory required for data: 1134036480
I0619 14:48:21.826061 17263 layer_factory.hpp:77] Creating layer ReLU25
I0619 14:48:21.826068 17263 net.cpp:459] Creating Layer ReLU25
I0619 14:48:21.826074 17263 net.cpp:886] ReLU25 <- Eltwise12
I0619 14:48:21.826084 17263 net.cpp:847] ReLU25 -> Eltwise12 (in-place)
I0619 14:48:21.826093 17263 net.cpp:509] Setting up ReLU25
I0619 14:48:21.826100 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.826105 17263 net.cpp:524] Memory required for data: 1142425088
I0619 14:48:21.826112 17263 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I0619 14:48:21.826118 17263 net.cpp:459] Creating Layer Eltwise12_ReLU25_0_split
I0619 14:48:21.826123 17263 net.cpp:886] Eltwise12_ReLU25_0_split <- Eltwise12
I0619 14:48:21.826131 17263 net.cpp:860] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I0619 14:48:21.826143 17263 net.cpp:860] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I0619 14:48:21.826195 17263 net.cpp:509] Setting up Eltwise12_ReLU25_0_split
I0619 14:48:21.826205 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.826210 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.826215 17263 net.cpp:524] Memory required for data: 1159202304
I0619 14:48:21.826220 17263 layer_factory.hpp:77] Creating layer Convolution26
I0619 14:48:21.826231 17263 net.cpp:459] Creating Layer Convolution26
I0619 14:48:21.826236 17263 net.cpp:886] Convolution26 <- Eltwise12_ReLU25_0_split_0
I0619 14:48:21.826248 17263 net.cpp:860] Convolution26 -> Convolution26
I0619 14:48:21.826714 17263 net.cpp:509] Setting up Convolution26
I0619 14:48:21.826725 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.826732 17263 net.cpp:524] Memory required for data: 1167590912
I0619 14:48:21.826745 17263 layer_factory.hpp:77] Creating layer BatchNorm26
I0619 14:48:21.826769 17263 net.cpp:459] Creating Layer BatchNorm26
I0619 14:48:21.826776 17263 net.cpp:886] BatchNorm26 <- Convolution26
I0619 14:48:21.826786 17263 net.cpp:847] BatchNorm26 -> Convolution26 (in-place)
I0619 14:48:21.827071 17263 net.cpp:509] Setting up BatchNorm26
I0619 14:48:21.827081 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.827087 17263 net.cpp:524] Memory required for data: 1175979520
I0619 14:48:21.827105 17263 layer_factory.hpp:77] Creating layer Scale26
I0619 14:48:21.827113 17263 net.cpp:459] Creating Layer Scale26
I0619 14:48:21.827118 17263 net.cpp:886] Scale26 <- Convolution26
I0619 14:48:21.827126 17263 net.cpp:847] Scale26 -> Convolution26 (in-place)
I0619 14:48:21.827175 17263 layer_factory.hpp:77] Creating layer Scale26
I0619 14:48:21.827356 17263 net.cpp:509] Setting up Scale26
I0619 14:48:21.827366 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.827371 17263 net.cpp:524] Memory required for data: 1184368128
I0619 14:48:21.827384 17263 layer_factory.hpp:77] Creating layer ReLU26
I0619 14:48:21.827397 17263 net.cpp:459] Creating Layer ReLU26
I0619 14:48:21.827407 17263 net.cpp:886] ReLU26 <- Convolution26
I0619 14:48:21.827430 17263 net.cpp:847] ReLU26 -> Convolution26 (in-place)
I0619 14:48:21.827440 17263 net.cpp:509] Setting up ReLU26
I0619 14:48:21.827448 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.827453 17263 net.cpp:524] Memory required for data: 1192756736
I0619 14:48:21.827457 17263 layer_factory.hpp:77] Creating layer Convolution27
I0619 14:48:21.827471 17263 net.cpp:459] Creating Layer Convolution27
I0619 14:48:21.827477 17263 net.cpp:886] Convolution27 <- Convolution26
I0619 14:48:21.827486 17263 net.cpp:860] Convolution27 -> Convolution27
I0619 14:48:21.827944 17263 net.cpp:509] Setting up Convolution27
I0619 14:48:21.827955 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.827960 17263 net.cpp:524] Memory required for data: 1201145344
I0619 14:48:21.827972 17263 layer_factory.hpp:77] Creating layer BatchNorm27
I0619 14:48:21.827985 17263 net.cpp:459] Creating Layer BatchNorm27
I0619 14:48:21.827991 17263 net.cpp:886] BatchNorm27 <- Convolution27
I0619 14:48:21.827998 17263 net.cpp:847] BatchNorm27 -> Convolution27 (in-place)
I0619 14:48:21.828285 17263 net.cpp:509] Setting up BatchNorm27
I0619 14:48:21.828295 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.828300 17263 net.cpp:524] Memory required for data: 1209533952
I0619 14:48:21.828315 17263 layer_factory.hpp:77] Creating layer Scale27
I0619 14:48:21.828323 17263 net.cpp:459] Creating Layer Scale27
I0619 14:48:21.828328 17263 net.cpp:886] Scale27 <- Convolution27
I0619 14:48:21.828336 17263 net.cpp:847] Scale27 -> Convolution27 (in-place)
I0619 14:48:21.828384 17263 layer_factory.hpp:77] Creating layer Scale27
I0619 14:48:21.829285 17263 net.cpp:509] Setting up Scale27
I0619 14:48:21.829305 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.829311 17263 net.cpp:524] Memory required for data: 1217922560
I0619 14:48:21.829325 17263 layer_factory.hpp:77] Creating layer Eltwise13
I0619 14:48:21.829337 17263 net.cpp:459] Creating Layer Eltwise13
I0619 14:48:21.829344 17263 net.cpp:886] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I0619 14:48:21.829352 17263 net.cpp:886] Eltwise13 <- Convolution27
I0619 14:48:21.829360 17263 net.cpp:860] Eltwise13 -> Eltwise13
I0619 14:48:21.829398 17263 net.cpp:509] Setting up Eltwise13
I0619 14:48:21.829407 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.829411 17263 net.cpp:524] Memory required for data: 1226311168
I0619 14:48:21.829416 17263 layer_factory.hpp:77] Creating layer ReLU27
I0619 14:48:21.829427 17263 net.cpp:459] Creating Layer ReLU27
I0619 14:48:21.829432 17263 net.cpp:886] ReLU27 <- Eltwise13
I0619 14:48:21.829442 17263 net.cpp:847] ReLU27 -> Eltwise13 (in-place)
I0619 14:48:21.829450 17263 net.cpp:509] Setting up ReLU27
I0619 14:48:21.829457 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.829463 17263 net.cpp:524] Memory required for data: 1234699776
I0619 14:48:21.829468 17263 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I0619 14:48:21.829474 17263 net.cpp:459] Creating Layer Eltwise13_ReLU27_0_split
I0619 14:48:21.829479 17263 net.cpp:886] Eltwise13_ReLU27_0_split <- Eltwise13
I0619 14:48:21.829486 17263 net.cpp:860] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I0619 14:48:21.829495 17263 net.cpp:860] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I0619 14:48:21.829550 17263 net.cpp:509] Setting up Eltwise13_ReLU27_0_split
I0619 14:48:21.829558 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.829566 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.829571 17263 net.cpp:524] Memory required for data: 1251476992
I0619 14:48:21.829576 17263 layer_factory.hpp:77] Creating layer Convolution28
I0619 14:48:21.829589 17263 net.cpp:459] Creating Layer Convolution28
I0619 14:48:21.829596 17263 net.cpp:886] Convolution28 <- Eltwise13_ReLU27_0_split_0
I0619 14:48:21.829604 17263 net.cpp:860] Convolution28 -> Convolution28
I0619 14:48:21.830056 17263 net.cpp:509] Setting up Convolution28
I0619 14:48:21.830072 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.830093 17263 net.cpp:524] Memory required for data: 1259865600
I0619 14:48:21.830108 17263 layer_factory.hpp:77] Creating layer BatchNorm28
I0619 14:48:21.830121 17263 net.cpp:459] Creating Layer BatchNorm28
I0619 14:48:21.830127 17263 net.cpp:886] BatchNorm28 <- Convolution28
I0619 14:48:21.830134 17263 net.cpp:847] BatchNorm28 -> Convolution28 (in-place)
I0619 14:48:21.830441 17263 net.cpp:509] Setting up BatchNorm28
I0619 14:48:21.830453 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.830458 17263 net.cpp:524] Memory required for data: 1268254208
I0619 14:48:21.830473 17263 layer_factory.hpp:77] Creating layer Scale28
I0619 14:48:21.830484 17263 net.cpp:459] Creating Layer Scale28
I0619 14:48:21.830490 17263 net.cpp:886] Scale28 <- Convolution28
I0619 14:48:21.830498 17263 net.cpp:847] Scale28 -> Convolution28 (in-place)
I0619 14:48:21.830545 17263 layer_factory.hpp:77] Creating layer Scale28
I0619 14:48:21.830713 17263 net.cpp:509] Setting up Scale28
I0619 14:48:21.830725 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.830730 17263 net.cpp:524] Memory required for data: 1276642816
I0619 14:48:21.830742 17263 layer_factory.hpp:77] Creating layer ReLU28
I0619 14:48:21.830750 17263 net.cpp:459] Creating Layer ReLU28
I0619 14:48:21.830756 17263 net.cpp:886] ReLU28 <- Convolution28
I0619 14:48:21.830763 17263 net.cpp:847] ReLU28 -> Convolution28 (in-place)
I0619 14:48:21.830771 17263 net.cpp:509] Setting up ReLU28
I0619 14:48:21.830778 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.830783 17263 net.cpp:524] Memory required for data: 1285031424
I0619 14:48:21.830787 17263 layer_factory.hpp:77] Creating layer Convolution29
I0619 14:48:21.830801 17263 net.cpp:459] Creating Layer Convolution29
I0619 14:48:21.830806 17263 net.cpp:886] Convolution29 <- Convolution28
I0619 14:48:21.830817 17263 net.cpp:860] Convolution29 -> Convolution29
I0619 14:48:21.831279 17263 net.cpp:509] Setting up Convolution29
I0619 14:48:21.831290 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.831295 17263 net.cpp:524] Memory required for data: 1293420032
I0619 14:48:21.831306 17263 layer_factory.hpp:77] Creating layer BatchNorm29
I0619 14:48:21.831317 17263 net.cpp:459] Creating Layer BatchNorm29
I0619 14:48:21.831323 17263 net.cpp:886] BatchNorm29 <- Convolution29
I0619 14:48:21.831333 17263 net.cpp:847] BatchNorm29 -> Convolution29 (in-place)
I0619 14:48:21.831622 17263 net.cpp:509] Setting up BatchNorm29
I0619 14:48:21.831632 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.831637 17263 net.cpp:524] Memory required for data: 1301808640
I0619 14:48:21.831651 17263 layer_factory.hpp:77] Creating layer Scale29
I0619 14:48:21.831662 17263 net.cpp:459] Creating Layer Scale29
I0619 14:48:21.831668 17263 net.cpp:886] Scale29 <- Convolution29
I0619 14:48:21.831676 17263 net.cpp:847] Scale29 -> Convolution29 (in-place)
I0619 14:48:21.831723 17263 layer_factory.hpp:77] Creating layer Scale29
I0619 14:48:21.831888 17263 net.cpp:509] Setting up Scale29
I0619 14:48:21.831898 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.831903 17263 net.cpp:524] Memory required for data: 1310197248
I0619 14:48:21.831914 17263 layer_factory.hpp:77] Creating layer Eltwise14
I0619 14:48:21.831923 17263 net.cpp:459] Creating Layer Eltwise14
I0619 14:48:21.831928 17263 net.cpp:886] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I0619 14:48:21.831935 17263 net.cpp:886] Eltwise14 <- Convolution29
I0619 14:48:21.831945 17263 net.cpp:860] Eltwise14 -> Eltwise14
I0619 14:48:21.831979 17263 net.cpp:509] Setting up Eltwise14
I0619 14:48:21.831989 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.831993 17263 net.cpp:524] Memory required for data: 1318585856
I0619 14:48:21.831998 17263 layer_factory.hpp:77] Creating layer ReLU29
I0619 14:48:21.832005 17263 net.cpp:459] Creating Layer ReLU29
I0619 14:48:21.832010 17263 net.cpp:886] ReLU29 <- Eltwise14
I0619 14:48:21.832021 17263 net.cpp:847] ReLU29 -> Eltwise14 (in-place)
I0619 14:48:21.832046 17263 net.cpp:509] Setting up ReLU29
I0619 14:48:21.832054 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.832059 17263 net.cpp:524] Memory required for data: 1326974464
I0619 14:48:21.832064 17263 layer_factory.hpp:77] Creating layer Eltwise14_ReLU29_0_split
I0619 14:48:21.832072 17263 net.cpp:459] Creating Layer Eltwise14_ReLU29_0_split
I0619 14:48:21.832077 17263 net.cpp:886] Eltwise14_ReLU29_0_split <- Eltwise14
I0619 14:48:21.832088 17263 net.cpp:860] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_0
I0619 14:48:21.832098 17263 net.cpp:860] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_1
I0619 14:48:21.832156 17263 net.cpp:509] Setting up Eltwise14_ReLU29_0_split
I0619 14:48:21.832165 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.832171 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.832176 17263 net.cpp:524] Memory required for data: 1343751680
I0619 14:48:21.832181 17263 layer_factory.hpp:77] Creating layer Convolution30
I0619 14:48:21.832192 17263 net.cpp:459] Creating Layer Convolution30
I0619 14:48:21.832198 17263 net.cpp:886] Convolution30 <- Eltwise14_ReLU29_0_split_0
I0619 14:48:21.832206 17263 net.cpp:860] Convolution30 -> Convolution30
I0619 14:48:21.832655 17263 net.cpp:509] Setting up Convolution30
I0619 14:48:21.832667 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.832672 17263 net.cpp:524] Memory required for data: 1352140288
I0619 14:48:21.832684 17263 layer_factory.hpp:77] Creating layer BatchNorm30
I0619 14:48:21.832695 17263 net.cpp:459] Creating Layer BatchNorm30
I0619 14:48:21.832701 17263 net.cpp:886] BatchNorm30 <- Convolution30
I0619 14:48:21.832710 17263 net.cpp:847] BatchNorm30 -> Convolution30 (in-place)
I0619 14:48:21.832995 17263 net.cpp:509] Setting up BatchNorm30
I0619 14:48:21.833005 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.833010 17263 net.cpp:524] Memory required for data: 1360528896
I0619 14:48:21.833024 17263 layer_factory.hpp:77] Creating layer Scale30
I0619 14:48:21.833032 17263 net.cpp:459] Creating Layer Scale30
I0619 14:48:21.833039 17263 net.cpp:886] Scale30 <- Convolution30
I0619 14:48:21.833045 17263 net.cpp:847] Scale30 -> Convolution30 (in-place)
I0619 14:48:21.833092 17263 layer_factory.hpp:77] Creating layer Scale30
I0619 14:48:21.833256 17263 net.cpp:509] Setting up Scale30
I0619 14:48:21.833266 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.833271 17263 net.cpp:524] Memory required for data: 1368917504
I0619 14:48:21.833282 17263 layer_factory.hpp:77] Creating layer ReLU30
I0619 14:48:21.833293 17263 net.cpp:459] Creating Layer ReLU30
I0619 14:48:21.833298 17263 net.cpp:886] ReLU30 <- Convolution30
I0619 14:48:21.833305 17263 net.cpp:847] ReLU30 -> Convolution30 (in-place)
I0619 14:48:21.833314 17263 net.cpp:509] Setting up ReLU30
I0619 14:48:21.833320 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.833325 17263 net.cpp:524] Memory required for data: 1377306112
I0619 14:48:21.833330 17263 layer_factory.hpp:77] Creating layer Convolution31
I0619 14:48:21.833343 17263 net.cpp:459] Creating Layer Convolution31
I0619 14:48:21.833348 17263 net.cpp:886] Convolution31 <- Convolution30
I0619 14:48:21.833359 17263 net.cpp:860] Convolution31 -> Convolution31
I0619 14:48:21.833812 17263 net.cpp:509] Setting up Convolution31
I0619 14:48:21.833823 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.833828 17263 net.cpp:524] Memory required for data: 1385694720
I0619 14:48:21.833839 17263 layer_factory.hpp:77] Creating layer BatchNorm31
I0619 14:48:21.833848 17263 net.cpp:459] Creating Layer BatchNorm31
I0619 14:48:21.833853 17263 net.cpp:886] BatchNorm31 <- Convolution31
I0619 14:48:21.833861 17263 net.cpp:847] BatchNorm31 -> Convolution31 (in-place)
I0619 14:48:21.834146 17263 net.cpp:509] Setting up BatchNorm31
I0619 14:48:21.834156 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.834164 17263 net.cpp:524] Memory required for data: 1394083328
I0619 14:48:21.834192 17263 layer_factory.hpp:77] Creating layer Scale31
I0619 14:48:21.834203 17263 net.cpp:459] Creating Layer Scale31
I0619 14:48:21.834208 17263 net.cpp:886] Scale31 <- Convolution31
I0619 14:48:21.834215 17263 net.cpp:847] Scale31 -> Convolution31 (in-place)
I0619 14:48:21.834271 17263 layer_factory.hpp:77] Creating layer Scale31
I0619 14:48:21.834450 17263 net.cpp:509] Setting up Scale31
I0619 14:48:21.834460 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.834465 17263 net.cpp:524] Memory required for data: 1402471936
I0619 14:48:21.834481 17263 layer_factory.hpp:77] Creating layer Eltwise15
I0619 14:48:21.834488 17263 net.cpp:459] Creating Layer Eltwise15
I0619 14:48:21.834496 17263 net.cpp:886] Eltwise15 <- Eltwise14_ReLU29_0_split_1
I0619 14:48:21.834502 17263 net.cpp:886] Eltwise15 <- Convolution31
I0619 14:48:21.834512 17263 net.cpp:860] Eltwise15 -> Eltwise15
I0619 14:48:21.834544 17263 net.cpp:509] Setting up Eltwise15
I0619 14:48:21.834553 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.834558 17263 net.cpp:524] Memory required for data: 1410860544
I0619 14:48:21.834563 17263 layer_factory.hpp:77] Creating layer ReLU31
I0619 14:48:21.834576 17263 net.cpp:459] Creating Layer ReLU31
I0619 14:48:21.834583 17263 net.cpp:886] ReLU31 <- Eltwise15
I0619 14:48:21.834591 17263 net.cpp:847] ReLU31 -> Eltwise15 (in-place)
I0619 14:48:21.834599 17263 net.cpp:509] Setting up ReLU31
I0619 14:48:21.834606 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.834611 17263 net.cpp:524] Memory required for data: 1419249152
I0619 14:48:21.834616 17263 layer_factory.hpp:77] Creating layer Eltwise15_ReLU31_0_split
I0619 14:48:21.834624 17263 net.cpp:459] Creating Layer Eltwise15_ReLU31_0_split
I0619 14:48:21.834631 17263 net.cpp:886] Eltwise15_ReLU31_0_split <- Eltwise15
I0619 14:48:21.834638 17263 net.cpp:860] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_0
I0619 14:48:21.834647 17263 net.cpp:860] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_1
I0619 14:48:21.834698 17263 net.cpp:509] Setting up Eltwise15_ReLU31_0_split
I0619 14:48:21.834707 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.834713 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.834718 17263 net.cpp:524] Memory required for data: 1436026368
I0619 14:48:21.834722 17263 layer_factory.hpp:77] Creating layer Convolution32
I0619 14:48:21.834736 17263 net.cpp:459] Creating Layer Convolution32
I0619 14:48:21.834743 17263 net.cpp:886] Convolution32 <- Eltwise15_ReLU31_0_split_0
I0619 14:48:21.834750 17263 net.cpp:860] Convolution32 -> Convolution32
I0619 14:48:21.835194 17263 net.cpp:509] Setting up Convolution32
I0619 14:48:21.835206 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.835211 17263 net.cpp:524] Memory required for data: 1444414976
I0619 14:48:21.835222 17263 layer_factory.hpp:77] Creating layer BatchNorm32
I0619 14:48:21.835230 17263 net.cpp:459] Creating Layer BatchNorm32
I0619 14:48:21.835235 17263 net.cpp:886] BatchNorm32 <- Convolution32
I0619 14:48:21.835244 17263 net.cpp:847] BatchNorm32 -> Convolution32 (in-place)
I0619 14:48:21.835515 17263 net.cpp:509] Setting up BatchNorm32
I0619 14:48:21.835525 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.835530 17263 net.cpp:524] Memory required for data: 1452803584
I0619 14:48:21.835542 17263 layer_factory.hpp:77] Creating layer Scale32
I0619 14:48:21.835551 17263 net.cpp:459] Creating Layer Scale32
I0619 14:48:21.835556 17263 net.cpp:886] Scale32 <- Convolution32
I0619 14:48:21.835564 17263 net.cpp:847] Scale32 -> Convolution32 (in-place)
I0619 14:48:21.835608 17263 layer_factory.hpp:77] Creating layer Scale32
I0619 14:48:21.835769 17263 net.cpp:509] Setting up Scale32
I0619 14:48:21.835779 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.835784 17263 net.cpp:524] Memory required for data: 1461192192
I0619 14:48:21.835795 17263 layer_factory.hpp:77] Creating layer ReLU32
I0619 14:48:21.835808 17263 net.cpp:459] Creating Layer ReLU32
I0619 14:48:21.835829 17263 net.cpp:886] ReLU32 <- Convolution32
I0619 14:48:21.835836 17263 net.cpp:847] ReLU32 -> Convolution32 (in-place)
I0619 14:48:21.835844 17263 net.cpp:509] Setting up ReLU32
I0619 14:48:21.835851 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.835856 17263 net.cpp:524] Memory required for data: 1469580800
I0619 14:48:21.835860 17263 layer_factory.hpp:77] Creating layer Convolution33
I0619 14:48:21.835873 17263 net.cpp:459] Creating Layer Convolution33
I0619 14:48:21.835878 17263 net.cpp:886] Convolution33 <- Convolution32
I0619 14:48:21.835886 17263 net.cpp:860] Convolution33 -> Convolution33
I0619 14:48:21.836334 17263 net.cpp:509] Setting up Convolution33
I0619 14:48:21.836347 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.836352 17263 net.cpp:524] Memory required for data: 1477969408
I0619 14:48:21.836364 17263 layer_factory.hpp:77] Creating layer BatchNorm33
I0619 14:48:21.836374 17263 net.cpp:459] Creating Layer BatchNorm33
I0619 14:48:21.836380 17263 net.cpp:886] BatchNorm33 <- Convolution33
I0619 14:48:21.836387 17263 net.cpp:847] BatchNorm33 -> Convolution33 (in-place)
I0619 14:48:21.836659 17263 net.cpp:509] Setting up BatchNorm33
I0619 14:48:21.836669 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.836673 17263 net.cpp:524] Memory required for data: 1486358016
I0619 14:48:21.836688 17263 layer_factory.hpp:77] Creating layer Scale33
I0619 14:48:21.836695 17263 net.cpp:459] Creating Layer Scale33
I0619 14:48:21.836700 17263 net.cpp:886] Scale33 <- Convolution33
I0619 14:48:21.836710 17263 net.cpp:847] Scale33 -> Convolution33 (in-place)
I0619 14:48:21.836756 17263 layer_factory.hpp:77] Creating layer Scale33
I0619 14:48:21.836915 17263 net.cpp:509] Setting up Scale33
I0619 14:48:21.836925 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.836930 17263 net.cpp:524] Memory required for data: 1494746624
I0619 14:48:21.836942 17263 layer_factory.hpp:77] Creating layer Eltwise16
I0619 14:48:21.836951 17263 net.cpp:459] Creating Layer Eltwise16
I0619 14:48:21.836956 17263 net.cpp:886] Eltwise16 <- Eltwise15_ReLU31_0_split_1
I0619 14:48:21.836962 17263 net.cpp:886] Eltwise16 <- Convolution33
I0619 14:48:21.836969 17263 net.cpp:860] Eltwise16 -> Eltwise16
I0619 14:48:21.837012 17263 net.cpp:509] Setting up Eltwise16
I0619 14:48:21.837021 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.837025 17263 net.cpp:524] Memory required for data: 1503135232
I0619 14:48:21.837030 17263 layer_factory.hpp:77] Creating layer ReLU33
I0619 14:48:21.837043 17263 net.cpp:459] Creating Layer ReLU33
I0619 14:48:21.837049 17263 net.cpp:886] ReLU33 <- Eltwise16
I0619 14:48:21.837055 17263 net.cpp:847] ReLU33 -> Eltwise16 (in-place)
I0619 14:48:21.837064 17263 net.cpp:509] Setting up ReLU33
I0619 14:48:21.837070 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.837075 17263 net.cpp:524] Memory required for data: 1511523840
I0619 14:48:21.837080 17263 layer_factory.hpp:77] Creating layer Eltwise16_ReLU33_0_split
I0619 14:48:21.837086 17263 net.cpp:459] Creating Layer Eltwise16_ReLU33_0_split
I0619 14:48:21.837091 17263 net.cpp:886] Eltwise16_ReLU33_0_split <- Eltwise16
I0619 14:48:21.837097 17263 net.cpp:860] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_0
I0619 14:48:21.837110 17263 net.cpp:860] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_1
I0619 14:48:21.837157 17263 net.cpp:509] Setting up Eltwise16_ReLU33_0_split
I0619 14:48:21.837164 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.837170 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.837174 17263 net.cpp:524] Memory required for data: 1528301056
I0619 14:48:21.837179 17263 layer_factory.hpp:77] Creating layer Convolution34
I0619 14:48:21.837191 17263 net.cpp:459] Creating Layer Convolution34
I0619 14:48:21.837198 17263 net.cpp:886] Convolution34 <- Eltwise16_ReLU33_0_split_0
I0619 14:48:21.837206 17263 net.cpp:860] Convolution34 -> Convolution34
I0619 14:48:21.837637 17263 net.cpp:509] Setting up Convolution34
I0619 14:48:21.837663 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.837669 17263 net.cpp:524] Memory required for data: 1536689664
I0619 14:48:21.837682 17263 layer_factory.hpp:77] Creating layer BatchNorm34
I0619 14:48:21.837692 17263 net.cpp:459] Creating Layer BatchNorm34
I0619 14:48:21.837698 17263 net.cpp:886] BatchNorm34 <- Convolution34
I0619 14:48:21.837707 17263 net.cpp:847] BatchNorm34 -> Convolution34 (in-place)
I0619 14:48:21.837976 17263 net.cpp:509] Setting up BatchNorm34
I0619 14:48:21.837986 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.837991 17263 net.cpp:524] Memory required for data: 1545078272
I0619 14:48:21.838006 17263 layer_factory.hpp:77] Creating layer Scale34
I0619 14:48:21.838016 17263 net.cpp:459] Creating Layer Scale34
I0619 14:48:21.838021 17263 net.cpp:886] Scale34 <- Convolution34
I0619 14:48:21.838027 17263 net.cpp:847] Scale34 -> Convolution34 (in-place)
I0619 14:48:21.838073 17263 layer_factory.hpp:77] Creating layer Scale34
I0619 14:48:21.838238 17263 net.cpp:509] Setting up Scale34
I0619 14:48:21.838246 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.838253 17263 net.cpp:524] Memory required for data: 1553466880
I0619 14:48:21.838263 17263 layer_factory.hpp:77] Creating layer ReLU34
I0619 14:48:21.838270 17263 net.cpp:459] Creating Layer ReLU34
I0619 14:48:21.838276 17263 net.cpp:886] ReLU34 <- Convolution34
I0619 14:48:21.838286 17263 net.cpp:847] ReLU34 -> Convolution34 (in-place)
I0619 14:48:21.838294 17263 net.cpp:509] Setting up ReLU34
I0619 14:48:21.838301 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.838305 17263 net.cpp:524] Memory required for data: 1561855488
I0619 14:48:21.838310 17263 layer_factory.hpp:77] Creating layer Convolution35
I0619 14:48:21.838321 17263 net.cpp:459] Creating Layer Convolution35
I0619 14:48:21.838326 17263 net.cpp:886] Convolution35 <- Convolution34
I0619 14:48:21.838335 17263 net.cpp:860] Convolution35 -> Convolution35
I0619 14:48:21.838790 17263 net.cpp:509] Setting up Convolution35
I0619 14:48:21.838805 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.838810 17263 net.cpp:524] Memory required for data: 1570244096
I0619 14:48:21.838821 17263 layer_factory.hpp:77] Creating layer BatchNorm35
I0619 14:48:21.838832 17263 net.cpp:459] Creating Layer BatchNorm35
I0619 14:48:21.838838 17263 net.cpp:886] BatchNorm35 <- Convolution35
I0619 14:48:21.838845 17263 net.cpp:847] BatchNorm35 -> Convolution35 (in-place)
I0619 14:48:21.839817 17263 net.cpp:509] Setting up BatchNorm35
I0619 14:48:21.839836 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.839843 17263 net.cpp:524] Memory required for data: 1578632704
I0619 14:48:21.839859 17263 layer_factory.hpp:77] Creating layer Scale35
I0619 14:48:21.839869 17263 net.cpp:459] Creating Layer Scale35
I0619 14:48:21.839874 17263 net.cpp:886] Scale35 <- Convolution35
I0619 14:48:21.839882 17263 net.cpp:847] Scale35 -> Convolution35 (in-place)
I0619 14:48:21.839936 17263 layer_factory.hpp:77] Creating layer Scale35
I0619 14:48:21.840095 17263 net.cpp:509] Setting up Scale35
I0619 14:48:21.840106 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.840109 17263 net.cpp:524] Memory required for data: 1587021312
I0619 14:48:21.840126 17263 layer_factory.hpp:77] Creating layer Eltwise17
I0619 14:48:21.840134 17263 net.cpp:459] Creating Layer Eltwise17
I0619 14:48:21.840140 17263 net.cpp:886] Eltwise17 <- Eltwise16_ReLU33_0_split_1
I0619 14:48:21.840149 17263 net.cpp:886] Eltwise17 <- Convolution35
I0619 14:48:21.840157 17263 net.cpp:860] Eltwise17 -> Eltwise17
I0619 14:48:21.840188 17263 net.cpp:509] Setting up Eltwise17
I0619 14:48:21.840196 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.840200 17263 net.cpp:524] Memory required for data: 1595409920
I0619 14:48:21.840205 17263 layer_factory.hpp:77] Creating layer ReLU35
I0619 14:48:21.840215 17263 net.cpp:459] Creating Layer ReLU35
I0619 14:48:21.840224 17263 net.cpp:886] ReLU35 <- Eltwise17
I0619 14:48:21.840246 17263 net.cpp:847] ReLU35 -> Eltwise17 (in-place)
I0619 14:48:21.840256 17263 net.cpp:509] Setting up ReLU35
I0619 14:48:21.840263 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.840267 17263 net.cpp:524] Memory required for data: 1603798528
I0619 14:48:21.840272 17263 layer_factory.hpp:77] Creating layer Eltwise17_ReLU35_0_split
I0619 14:48:21.840281 17263 net.cpp:459] Creating Layer Eltwise17_ReLU35_0_split
I0619 14:48:21.840286 17263 net.cpp:886] Eltwise17_ReLU35_0_split <- Eltwise17
I0619 14:48:21.840293 17263 net.cpp:860] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_0
I0619 14:48:21.840302 17263 net.cpp:860] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_1
I0619 14:48:21.840355 17263 net.cpp:509] Setting up Eltwise17_ReLU35_0_split
I0619 14:48:21.840363 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.840371 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.840375 17263 net.cpp:524] Memory required for data: 1620575744
I0619 14:48:21.840380 17263 layer_factory.hpp:77] Creating layer Convolution36
I0619 14:48:21.840394 17263 net.cpp:459] Creating Layer Convolution36
I0619 14:48:21.840399 17263 net.cpp:886] Convolution36 <- Eltwise17_ReLU35_0_split_0
I0619 14:48:21.840409 17263 net.cpp:860] Convolution36 -> Convolution36
I0619 14:48:21.840844 17263 net.cpp:509] Setting up Convolution36
I0619 14:48:21.840855 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.840862 17263 net.cpp:524] Memory required for data: 1628964352
I0619 14:48:21.840879 17263 layer_factory.hpp:77] Creating layer BatchNorm36
I0619 14:48:21.840894 17263 net.cpp:459] Creating Layer BatchNorm36
I0619 14:48:21.840900 17263 net.cpp:886] BatchNorm36 <- Convolution36
I0619 14:48:21.840908 17263 net.cpp:847] BatchNorm36 -> Convolution36 (in-place)
I0619 14:48:21.841174 17263 net.cpp:509] Setting up BatchNorm36
I0619 14:48:21.841183 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.841188 17263 net.cpp:524] Memory required for data: 1637352960
I0619 14:48:21.841203 17263 layer_factory.hpp:77] Creating layer Scale36
I0619 14:48:21.841212 17263 net.cpp:459] Creating Layer Scale36
I0619 14:48:21.841217 17263 net.cpp:886] Scale36 <- Convolution36
I0619 14:48:21.841226 17263 net.cpp:847] Scale36 -> Convolution36 (in-place)
I0619 14:48:21.841270 17263 layer_factory.hpp:77] Creating layer Scale36
I0619 14:48:21.841426 17263 net.cpp:509] Setting up Scale36
I0619 14:48:21.841436 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.841442 17263 net.cpp:524] Memory required for data: 1645741568
I0619 14:48:21.841454 17263 layer_factory.hpp:77] Creating layer ReLU36
I0619 14:48:21.841464 17263 net.cpp:459] Creating Layer ReLU36
I0619 14:48:21.841470 17263 net.cpp:886] ReLU36 <- Convolution36
I0619 14:48:21.841477 17263 net.cpp:847] ReLU36 -> Convolution36 (in-place)
I0619 14:48:21.841485 17263 net.cpp:509] Setting up ReLU36
I0619 14:48:21.841491 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.841496 17263 net.cpp:524] Memory required for data: 1654130176
I0619 14:48:21.841500 17263 layer_factory.hpp:77] Creating layer Convolution37
I0619 14:48:21.841513 17263 net.cpp:459] Creating Layer Convolution37
I0619 14:48:21.841518 17263 net.cpp:886] Convolution37 <- Convolution36
I0619 14:48:21.841526 17263 net.cpp:860] Convolution37 -> Convolution37
I0619 14:48:21.841954 17263 net.cpp:509] Setting up Convolution37
I0619 14:48:21.841965 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.841970 17263 net.cpp:524] Memory required for data: 1662518784
I0619 14:48:21.841981 17263 layer_factory.hpp:77] Creating layer BatchNorm37
I0619 14:48:21.841991 17263 net.cpp:459] Creating Layer BatchNorm37
I0619 14:48:21.841997 17263 net.cpp:886] BatchNorm37 <- Convolution37
I0619 14:48:21.842005 17263 net.cpp:847] BatchNorm37 -> Convolution37 (in-place)
I0619 14:48:21.842265 17263 net.cpp:509] Setting up BatchNorm37
I0619 14:48:21.842274 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.842283 17263 net.cpp:524] Memory required for data: 1670907392
I0619 14:48:21.842350 17263 layer_factory.hpp:77] Creating layer Scale37
I0619 14:48:21.842372 17263 net.cpp:459] Creating Layer Scale37
I0619 14:48:21.842378 17263 net.cpp:886] Scale37 <- Convolution37
I0619 14:48:21.842386 17263 net.cpp:847] Scale37 -> Convolution37 (in-place)
I0619 14:48:21.842437 17263 layer_factory.hpp:77] Creating layer Scale37
I0619 14:48:21.842588 17263 net.cpp:509] Setting up Scale37
I0619 14:48:21.842598 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.842603 17263 net.cpp:524] Memory required for data: 1679296000
I0619 14:48:21.842614 17263 layer_factory.hpp:77] Creating layer Eltwise18
I0619 14:48:21.842625 17263 net.cpp:459] Creating Layer Eltwise18
I0619 14:48:21.842631 17263 net.cpp:886] Eltwise18 <- Eltwise17_ReLU35_0_split_1
I0619 14:48:21.842638 17263 net.cpp:886] Eltwise18 <- Convolution37
I0619 14:48:21.842648 17263 net.cpp:860] Eltwise18 -> Eltwise18
I0619 14:48:21.842679 17263 net.cpp:509] Setting up Eltwise18
I0619 14:48:21.842687 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.842691 17263 net.cpp:524] Memory required for data: 1687684608
I0619 14:48:21.842696 17263 layer_factory.hpp:77] Creating layer ReLU37
I0619 14:48:21.842703 17263 net.cpp:459] Creating Layer ReLU37
I0619 14:48:21.842708 17263 net.cpp:886] ReLU37 <- Eltwise18
I0619 14:48:21.842716 17263 net.cpp:847] ReLU37 -> Eltwise18 (in-place)
I0619 14:48:21.842725 17263 net.cpp:509] Setting up ReLU37
I0619 14:48:21.842731 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.842736 17263 net.cpp:524] Memory required for data: 1696073216
I0619 14:48:21.842741 17263 layer_factory.hpp:77] Creating layer Eltwise18_ReLU37_0_split
I0619 14:48:21.842747 17263 net.cpp:459] Creating Layer Eltwise18_ReLU37_0_split
I0619 14:48:21.842751 17263 net.cpp:886] Eltwise18_ReLU37_0_split <- Eltwise18
I0619 14:48:21.842761 17263 net.cpp:860] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_0
I0619 14:48:21.842769 17263 net.cpp:860] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_1
I0619 14:48:21.842816 17263 net.cpp:509] Setting up Eltwise18_ReLU37_0_split
I0619 14:48:21.842824 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.842831 17263 net.cpp:516] Top shape: 128 16 32 32 (2097152)
I0619 14:48:21.842835 17263 net.cpp:524] Memory required for data: 1712850432
I0619 14:48:21.842840 17263 layer_factory.hpp:77] Creating layer Pooling1
I0619 14:48:21.842847 17263 net.cpp:459] Creating Layer Pooling1
I0619 14:48:21.842852 17263 net.cpp:886] Pooling1 <- Eltwise18_ReLU37_0_split_0
I0619 14:48:21.842859 17263 net.cpp:860] Pooling1 -> Pooling1
I0619 14:48:21.842891 17263 net.cpp:509] Setting up Pooling1
I0619 14:48:21.842900 17263 net.cpp:516] Top shape: 128 16 16 16 (524288)
I0619 14:48:21.842903 17263 net.cpp:524] Memory required for data: 1714947584
I0619 14:48:21.842908 17263 layer_factory.hpp:77] Creating layer Input1
I0619 14:48:21.842916 17263 net.cpp:459] Creating Layer Input1
I0619 14:48:21.842922 17263 net.cpp:860] Input1 -> Input1
I0619 14:48:21.842957 17263 net.cpp:509] Setting up Input1
I0619 14:48:21.842964 17263 net.cpp:516] Top shape: 128 16 16 16 (524288)
I0619 14:48:21.842968 17263 net.cpp:524] Memory required for data: 1717044736
I0619 14:48:21.842973 17263 layer_factory.hpp:77] Creating layer Concat1
I0619 14:48:21.842980 17263 net.cpp:459] Creating Layer Concat1
I0619 14:48:21.842986 17263 net.cpp:886] Concat1 <- Pooling1
I0619 14:48:21.842993 17263 net.cpp:886] Concat1 <- Input1
I0619 14:48:21.843001 17263 net.cpp:860] Concat1 -> Concat1
I0619 14:48:21.843031 17263 net.cpp:509] Setting up Concat1
I0619 14:48:21.843039 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.843044 17263 net.cpp:524] Memory required for data: 1721239040
I0619 14:48:21.843049 17263 layer_factory.hpp:77] Creating layer Convolution38
I0619 14:48:21.843063 17263 net.cpp:459] Creating Layer Convolution38
I0619 14:48:21.843070 17263 net.cpp:886] Convolution38 <- Eltwise18_ReLU37_0_split_1
I0619 14:48:21.843082 17263 net.cpp:860] Convolution38 -> Convolution38
I0619 14:48:21.843636 17263 net.cpp:509] Setting up Convolution38
I0619 14:48:21.843649 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.843654 17263 net.cpp:524] Memory required for data: 1725433344
I0619 14:48:21.843667 17263 layer_factory.hpp:77] Creating layer BatchNorm38
I0619 14:48:21.843678 17263 net.cpp:459] Creating Layer BatchNorm38
I0619 14:48:21.843684 17263 net.cpp:886] BatchNorm38 <- Convolution38
I0619 14:48:21.843691 17263 net.cpp:847] BatchNorm38 -> Convolution38 (in-place)
I0619 14:48:21.843950 17263 net.cpp:509] Setting up BatchNorm38
I0619 14:48:21.843960 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.843964 17263 net.cpp:524] Memory required for data: 1729627648
I0619 14:48:21.843981 17263 layer_factory.hpp:77] Creating layer Scale38
I0619 14:48:21.843988 17263 net.cpp:459] Creating Layer Scale38
I0619 14:48:21.843994 17263 net.cpp:886] Scale38 <- Convolution38
I0619 14:48:21.844002 17263 net.cpp:847] Scale38 -> Convolution38 (in-place)
I0619 14:48:21.844048 17263 layer_factory.hpp:77] Creating layer Scale38
I0619 14:48:21.844202 17263 net.cpp:509] Setting up Scale38
I0619 14:48:21.844211 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.844216 17263 net.cpp:524] Memory required for data: 1733821952
I0619 14:48:21.844228 17263 layer_factory.hpp:77] Creating layer ReLU38
I0619 14:48:21.844238 17263 net.cpp:459] Creating Layer ReLU38
I0619 14:48:21.844243 17263 net.cpp:886] ReLU38 <- Convolution38
I0619 14:48:21.844249 17263 net.cpp:847] ReLU38 -> Convolution38 (in-place)
I0619 14:48:21.844257 17263 net.cpp:509] Setting up ReLU38
I0619 14:48:21.844264 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.844269 17263 net.cpp:524] Memory required for data: 1738016256
I0619 14:48:21.844274 17263 layer_factory.hpp:77] Creating layer Convolution39
I0619 14:48:21.844285 17263 net.cpp:459] Creating Layer Convolution39
I0619 14:48:21.844291 17263 net.cpp:886] Convolution39 <- Convolution38
I0619 14:48:21.844300 17263 net.cpp:860] Convolution39 -> Convolution39
I0619 14:48:21.845029 17263 net.cpp:509] Setting up Convolution39
I0619 14:48:21.845041 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.845046 17263 net.cpp:524] Memory required for data: 1742210560
I0619 14:48:21.845055 17263 layer_factory.hpp:77] Creating layer BatchNorm39
I0619 14:48:21.845064 17263 net.cpp:459] Creating Layer BatchNorm39
I0619 14:48:21.845069 17263 net.cpp:886] BatchNorm39 <- Convolution39
I0619 14:48:21.845077 17263 net.cpp:847] BatchNorm39 -> Convolution39 (in-place)
I0619 14:48:21.845342 17263 net.cpp:509] Setting up BatchNorm39
I0619 14:48:21.845352 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.845357 17263 net.cpp:524] Memory required for data: 1746404864
I0619 14:48:21.845371 17263 layer_factory.hpp:77] Creating layer Scale39
I0619 14:48:21.845379 17263 net.cpp:459] Creating Layer Scale39
I0619 14:48:21.845384 17263 net.cpp:886] Scale39 <- Convolution39
I0619 14:48:21.845391 17263 net.cpp:847] Scale39 -> Convolution39 (in-place)
I0619 14:48:21.845438 17263 layer_factory.hpp:77] Creating layer Scale39
I0619 14:48:21.845592 17263 net.cpp:509] Setting up Scale39
I0619 14:48:21.845602 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.845607 17263 net.cpp:524] Memory required for data: 1750599168
I0619 14:48:21.845618 17263 layer_factory.hpp:77] Creating layer Eltwise19
I0619 14:48:21.845628 17263 net.cpp:459] Creating Layer Eltwise19
I0619 14:48:21.845633 17263 net.cpp:886] Eltwise19 <- Concat1
I0619 14:48:21.845639 17263 net.cpp:886] Eltwise19 <- Convolution39
I0619 14:48:21.845646 17263 net.cpp:860] Eltwise19 -> Eltwise19
I0619 14:48:21.845674 17263 net.cpp:509] Setting up Eltwise19
I0619 14:48:21.845681 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.845685 17263 net.cpp:524] Memory required for data: 1754793472
I0619 14:48:21.845690 17263 layer_factory.hpp:77] Creating layer ReLU39
I0619 14:48:21.845700 17263 net.cpp:459] Creating Layer ReLU39
I0619 14:48:21.845721 17263 net.cpp:886] ReLU39 <- Eltwise19
I0619 14:48:21.845733 17263 net.cpp:847] ReLU39 -> Eltwise19 (in-place)
I0619 14:48:21.845743 17263 net.cpp:509] Setting up ReLU39
I0619 14:48:21.845751 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.845754 17263 net.cpp:524] Memory required for data: 1758987776
I0619 14:48:21.845759 17263 layer_factory.hpp:77] Creating layer Eltwise19_ReLU39_0_split
I0619 14:48:21.845767 17263 net.cpp:459] Creating Layer Eltwise19_ReLU39_0_split
I0619 14:48:21.845772 17263 net.cpp:886] Eltwise19_ReLU39_0_split <- Eltwise19
I0619 14:48:21.845777 17263 net.cpp:860] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_0
I0619 14:48:21.845787 17263 net.cpp:860] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_1
I0619 14:48:21.845840 17263 net.cpp:509] Setting up Eltwise19_ReLU39_0_split
I0619 14:48:21.845849 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.845854 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.845860 17263 net.cpp:524] Memory required for data: 1767376384
I0619 14:48:21.845863 17263 layer_factory.hpp:77] Creating layer Convolution40
I0619 14:48:21.845875 17263 net.cpp:459] Creating Layer Convolution40
I0619 14:48:21.845880 17263 net.cpp:886] Convolution40 <- Eltwise19_ReLU39_0_split_0
I0619 14:48:21.845890 17263 net.cpp:860] Convolution40 -> Convolution40
I0619 14:48:21.846637 17263 net.cpp:509] Setting up Convolution40
I0619 14:48:21.846649 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.846654 17263 net.cpp:524] Memory required for data: 1771570688
I0619 14:48:21.846667 17263 layer_factory.hpp:77] Creating layer BatchNorm40
I0619 14:48:21.846675 17263 net.cpp:459] Creating Layer BatchNorm40
I0619 14:48:21.846681 17263 net.cpp:886] BatchNorm40 <- Convolution40
I0619 14:48:21.846690 17263 net.cpp:847] BatchNorm40 -> Convolution40 (in-place)
I0619 14:48:21.846953 17263 net.cpp:509] Setting up BatchNorm40
I0619 14:48:21.846962 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.846967 17263 net.cpp:524] Memory required for data: 1775764992
I0619 14:48:21.846981 17263 layer_factory.hpp:77] Creating layer Scale40
I0619 14:48:21.846988 17263 net.cpp:459] Creating Layer Scale40
I0619 14:48:21.846993 17263 net.cpp:886] Scale40 <- Convolution40
I0619 14:48:21.847000 17263 net.cpp:847] Scale40 -> Convolution40 (in-place)
I0619 14:48:21.847045 17263 layer_factory.hpp:77] Creating layer Scale40
I0619 14:48:21.847194 17263 net.cpp:509] Setting up Scale40
I0619 14:48:21.847203 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.847208 17263 net.cpp:524] Memory required for data: 1779959296
I0619 14:48:21.847219 17263 layer_factory.hpp:77] Creating layer ReLU40
I0619 14:48:21.847232 17263 net.cpp:459] Creating Layer ReLU40
I0619 14:48:21.847240 17263 net.cpp:886] ReLU40 <- Convolution40
I0619 14:48:21.847247 17263 net.cpp:847] ReLU40 -> Convolution40 (in-place)
I0619 14:48:21.847255 17263 net.cpp:509] Setting up ReLU40
I0619 14:48:21.847262 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.847266 17263 net.cpp:524] Memory required for data: 1784153600
I0619 14:48:21.847271 17263 layer_factory.hpp:77] Creating layer Convolution41
I0619 14:48:21.847285 17263 net.cpp:459] Creating Layer Convolution41
I0619 14:48:21.847290 17263 net.cpp:886] Convolution41 <- Convolution40
I0619 14:48:21.847297 17263 net.cpp:860] Convolution41 -> Convolution41
I0619 14:48:21.848031 17263 net.cpp:509] Setting up Convolution41
I0619 14:48:21.848040 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.848045 17263 net.cpp:524] Memory required for data: 1788347904
I0619 14:48:21.848057 17263 layer_factory.hpp:77] Creating layer BatchNorm41
I0619 14:48:21.848064 17263 net.cpp:459] Creating Layer BatchNorm41
I0619 14:48:21.848069 17263 net.cpp:886] BatchNorm41 <- Convolution41
I0619 14:48:21.848079 17263 net.cpp:847] BatchNorm41 -> Convolution41 (in-place)
I0619 14:48:21.848341 17263 net.cpp:509] Setting up BatchNorm41
I0619 14:48:21.848351 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.848371 17263 net.cpp:524] Memory required for data: 1792542208
I0619 14:48:21.848386 17263 layer_factory.hpp:77] Creating layer Scale41
I0619 14:48:21.848394 17263 net.cpp:459] Creating Layer Scale41
I0619 14:48:21.848399 17263 net.cpp:886] Scale41 <- Convolution41
I0619 14:48:21.848407 17263 net.cpp:847] Scale41 -> Convolution41 (in-place)
I0619 14:48:21.848454 17263 layer_factory.hpp:77] Creating layer Scale41
I0619 14:48:21.848606 17263 net.cpp:509] Setting up Scale41
I0619 14:48:21.848615 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.848620 17263 net.cpp:524] Memory required for data: 1796736512
I0619 14:48:21.848631 17263 layer_factory.hpp:77] Creating layer Eltwise20
I0619 14:48:21.848641 17263 net.cpp:459] Creating Layer Eltwise20
I0619 14:48:21.848646 17263 net.cpp:886] Eltwise20 <- Eltwise19_ReLU39_0_split_1
I0619 14:48:21.848654 17263 net.cpp:886] Eltwise20 <- Convolution41
I0619 14:48:21.848661 17263 net.cpp:860] Eltwise20 -> Eltwise20
I0619 14:48:21.848686 17263 net.cpp:509] Setting up Eltwise20
I0619 14:48:21.848695 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.848700 17263 net.cpp:524] Memory required for data: 1800930816
I0619 14:48:21.848704 17263 layer_factory.hpp:77] Creating layer ReLU41
I0619 14:48:21.848711 17263 net.cpp:459] Creating Layer ReLU41
I0619 14:48:21.848716 17263 net.cpp:886] ReLU41 <- Eltwise20
I0619 14:48:21.848724 17263 net.cpp:847] ReLU41 -> Eltwise20 (in-place)
I0619 14:48:21.848733 17263 net.cpp:509] Setting up ReLU41
I0619 14:48:21.848740 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.848744 17263 net.cpp:524] Memory required for data: 1805125120
I0619 14:48:21.848749 17263 layer_factory.hpp:77] Creating layer Eltwise20_ReLU41_0_split
I0619 14:48:21.848755 17263 net.cpp:459] Creating Layer Eltwise20_ReLU41_0_split
I0619 14:48:21.848760 17263 net.cpp:886] Eltwise20_ReLU41_0_split <- Eltwise20
I0619 14:48:21.848767 17263 net.cpp:860] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_0
I0619 14:48:21.848775 17263 net.cpp:860] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_1
I0619 14:48:21.848824 17263 net.cpp:509] Setting up Eltwise20_ReLU41_0_split
I0619 14:48:21.848831 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.848837 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.848842 17263 net.cpp:524] Memory required for data: 1813513728
I0619 14:48:21.848846 17263 layer_factory.hpp:77] Creating layer Convolution42
I0619 14:48:21.848860 17263 net.cpp:459] Creating Layer Convolution42
I0619 14:48:21.848865 17263 net.cpp:886] Convolution42 <- Eltwise20_ReLU41_0_split_0
I0619 14:48:21.848873 17263 net.cpp:860] Convolution42 -> Convolution42
I0619 14:48:21.849608 17263 net.cpp:509] Setting up Convolution42
I0619 14:48:21.849618 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.849623 17263 net.cpp:524] Memory required for data: 1817708032
I0619 14:48:21.849635 17263 layer_factory.hpp:77] Creating layer BatchNorm42
I0619 14:48:21.849645 17263 net.cpp:459] Creating Layer BatchNorm42
I0619 14:48:21.849652 17263 net.cpp:886] BatchNorm42 <- Convolution42
I0619 14:48:21.849661 17263 net.cpp:847] BatchNorm42 -> Convolution42 (in-place)
I0619 14:48:21.849911 17263 net.cpp:509] Setting up BatchNorm42
I0619 14:48:21.849920 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.849925 17263 net.cpp:524] Memory required for data: 1821902336
I0619 14:48:21.849938 17263 layer_factory.hpp:77] Creating layer Scale42
I0619 14:48:21.849949 17263 net.cpp:459] Creating Layer Scale42
I0619 14:48:21.849954 17263 net.cpp:886] Scale42 <- Convolution42
I0619 14:48:21.849961 17263 net.cpp:847] Scale42 -> Convolution42 (in-place)
I0619 14:48:21.850003 17263 layer_factory.hpp:77] Creating layer Scale42
I0619 14:48:21.850157 17263 net.cpp:509] Setting up Scale42
I0619 14:48:21.850165 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.850174 17263 net.cpp:524] Memory required for data: 1826096640
I0619 14:48:21.850206 17263 layer_factory.hpp:77] Creating layer ReLU42
I0619 14:48:21.850216 17263 net.cpp:459] Creating Layer ReLU42
I0619 14:48:21.850221 17263 net.cpp:886] ReLU42 <- Convolution42
I0619 14:48:21.850231 17263 net.cpp:847] ReLU42 -> Convolution42 (in-place)
I0619 14:48:21.850241 17263 net.cpp:509] Setting up ReLU42
I0619 14:48:21.850247 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.850252 17263 net.cpp:524] Memory required for data: 1830290944
I0619 14:48:21.850256 17263 layer_factory.hpp:77] Creating layer Convolution43
I0619 14:48:21.850270 17263 net.cpp:459] Creating Layer Convolution43
I0619 14:48:21.850275 17263 net.cpp:886] Convolution43 <- Convolution42
I0619 14:48:21.850282 17263 net.cpp:860] Convolution43 -> Convolution43
I0619 14:48:21.851027 17263 net.cpp:509] Setting up Convolution43
I0619 14:48:21.851039 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.851044 17263 net.cpp:524] Memory required for data: 1834485248
I0619 14:48:21.851058 17263 layer_factory.hpp:77] Creating layer BatchNorm43
I0619 14:48:21.851070 17263 net.cpp:459] Creating Layer BatchNorm43
I0619 14:48:21.851076 17263 net.cpp:886] BatchNorm43 <- Convolution43
I0619 14:48:21.851083 17263 net.cpp:847] BatchNorm43 -> Convolution43 (in-place)
I0619 14:48:21.851339 17263 net.cpp:509] Setting up BatchNorm43
I0619 14:48:21.851347 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.851352 17263 net.cpp:524] Memory required for data: 1838679552
I0619 14:48:21.851366 17263 layer_factory.hpp:77] Creating layer Scale43
I0619 14:48:21.851377 17263 net.cpp:459] Creating Layer Scale43
I0619 14:48:21.851382 17263 net.cpp:886] Scale43 <- Convolution43
I0619 14:48:21.851389 17263 net.cpp:847] Scale43 -> Convolution43 (in-place)
I0619 14:48:21.851434 17263 layer_factory.hpp:77] Creating layer Scale43
I0619 14:48:21.851588 17263 net.cpp:509] Setting up Scale43
I0619 14:48:21.851598 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.851603 17263 net.cpp:524] Memory required for data: 1842873856
I0619 14:48:21.851613 17263 layer_factory.hpp:77] Creating layer Eltwise21
I0619 14:48:21.851622 17263 net.cpp:459] Creating Layer Eltwise21
I0619 14:48:21.851629 17263 net.cpp:886] Eltwise21 <- Eltwise20_ReLU41_0_split_1
I0619 14:48:21.851635 17263 net.cpp:886] Eltwise21 <- Convolution43
I0619 14:48:21.851642 17263 net.cpp:860] Eltwise21 -> Eltwise21
I0619 14:48:21.851668 17263 net.cpp:509] Setting up Eltwise21
I0619 14:48:21.851676 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.851681 17263 net.cpp:524] Memory required for data: 1847068160
I0619 14:48:21.851686 17263 layer_factory.hpp:77] Creating layer ReLU43
I0619 14:48:21.851692 17263 net.cpp:459] Creating Layer ReLU43
I0619 14:48:21.851697 17263 net.cpp:886] ReLU43 <- Eltwise21
I0619 14:48:21.851703 17263 net.cpp:847] ReLU43 -> Eltwise21 (in-place)
I0619 14:48:21.851711 17263 net.cpp:509] Setting up ReLU43
I0619 14:48:21.851717 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.851722 17263 net.cpp:524] Memory required for data: 1851262464
I0619 14:48:21.851727 17263 layer_factory.hpp:77] Creating layer Eltwise21_ReLU43_0_split
I0619 14:48:21.851733 17263 net.cpp:459] Creating Layer Eltwise21_ReLU43_0_split
I0619 14:48:21.851737 17263 net.cpp:886] Eltwise21_ReLU43_0_split <- Eltwise21
I0619 14:48:21.851747 17263 net.cpp:860] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_0
I0619 14:48:21.851755 17263 net.cpp:860] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_1
I0619 14:48:21.851802 17263 net.cpp:509] Setting up Eltwise21_ReLU43_0_split
I0619 14:48:21.851810 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.851816 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.851821 17263 net.cpp:524] Memory required for data: 1859651072
I0619 14:48:21.851826 17263 layer_factory.hpp:77] Creating layer Convolution44
I0619 14:48:21.851836 17263 net.cpp:459] Creating Layer Convolution44
I0619 14:48:21.851845 17263 net.cpp:886] Convolution44 <- Eltwise21_ReLU43_0_split_0
I0619 14:48:21.851869 17263 net.cpp:860] Convolution44 -> Convolution44
I0619 14:48:21.852613 17263 net.cpp:509] Setting up Convolution44
I0619 14:48:21.852624 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.852629 17263 net.cpp:524] Memory required for data: 1863845376
I0619 14:48:21.852641 17263 layer_factory.hpp:77] Creating layer BatchNorm44
I0619 14:48:21.852653 17263 net.cpp:459] Creating Layer BatchNorm44
I0619 14:48:21.852658 17263 net.cpp:886] BatchNorm44 <- Convolution44
I0619 14:48:21.852665 17263 net.cpp:847] BatchNorm44 -> Convolution44 (in-place)
I0619 14:48:21.852922 17263 net.cpp:509] Setting up BatchNorm44
I0619 14:48:21.852931 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.852936 17263 net.cpp:524] Memory required for data: 1868039680
I0619 14:48:21.852949 17263 layer_factory.hpp:77] Creating layer Scale44
I0619 14:48:21.852957 17263 net.cpp:459] Creating Layer Scale44
I0619 14:48:21.852962 17263 net.cpp:886] Scale44 <- Convolution44
I0619 14:48:21.852969 17263 net.cpp:847] Scale44 -> Convolution44 (in-place)
I0619 14:48:21.853013 17263 layer_factory.hpp:77] Creating layer Scale44
I0619 14:48:21.853168 17263 net.cpp:509] Setting up Scale44
I0619 14:48:21.853178 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.853183 17263 net.cpp:524] Memory required for data: 1872233984
I0619 14:48:21.853195 17263 layer_factory.hpp:77] Creating layer ReLU44
I0619 14:48:21.853204 17263 net.cpp:459] Creating Layer ReLU44
I0619 14:48:21.853209 17263 net.cpp:886] ReLU44 <- Convolution44
I0619 14:48:21.853217 17263 net.cpp:847] ReLU44 -> Convolution44 (in-place)
I0619 14:48:21.853225 17263 net.cpp:509] Setting up ReLU44
I0619 14:48:21.853232 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.853236 17263 net.cpp:524] Memory required for data: 1876428288
I0619 14:48:21.853241 17263 layer_factory.hpp:77] Creating layer Convolution45
I0619 14:48:21.853251 17263 net.cpp:459] Creating Layer Convolution45
I0619 14:48:21.853256 17263 net.cpp:886] Convolution45 <- Convolution44
I0619 14:48:21.853266 17263 net.cpp:860] Convolution45 -> Convolution45
I0619 14:48:21.853996 17263 net.cpp:509] Setting up Convolution45
I0619 14:48:21.854007 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.854012 17263 net.cpp:524] Memory required for data: 1880622592
I0619 14:48:21.854022 17263 layer_factory.hpp:77] Creating layer BatchNorm45
I0619 14:48:21.854030 17263 net.cpp:459] Creating Layer BatchNorm45
I0619 14:48:21.854037 17263 net.cpp:886] BatchNorm45 <- Convolution45
I0619 14:48:21.854045 17263 net.cpp:847] BatchNorm45 -> Convolution45 (in-place)
I0619 14:48:21.854298 17263 net.cpp:509] Setting up BatchNorm45
I0619 14:48:21.854307 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.854312 17263 net.cpp:524] Memory required for data: 1884816896
I0619 14:48:21.854326 17263 layer_factory.hpp:77] Creating layer Scale45
I0619 14:48:21.854333 17263 net.cpp:459] Creating Layer Scale45
I0619 14:48:21.854338 17263 net.cpp:886] Scale45 <- Convolution45
I0619 14:48:21.854346 17263 net.cpp:847] Scale45 -> Convolution45 (in-place)
I0619 14:48:21.854406 17263 layer_factory.hpp:77] Creating layer Scale45
I0619 14:48:21.854560 17263 net.cpp:509] Setting up Scale45
I0619 14:48:21.854569 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.854574 17263 net.cpp:524] Memory required for data: 1889011200
I0619 14:48:21.854585 17263 layer_factory.hpp:77] Creating layer Eltwise22
I0619 14:48:21.854595 17263 net.cpp:459] Creating Layer Eltwise22
I0619 14:48:21.854601 17263 net.cpp:886] Eltwise22 <- Eltwise21_ReLU43_0_split_1
I0619 14:48:21.854607 17263 net.cpp:886] Eltwise22 <- Convolution45
I0619 14:48:21.854615 17263 net.cpp:860] Eltwise22 -> Eltwise22
I0619 14:48:21.854638 17263 net.cpp:509] Setting up Eltwise22
I0619 14:48:21.854646 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.854650 17263 net.cpp:524] Memory required for data: 1893205504
I0619 14:48:21.854660 17263 layer_factory.hpp:77] Creating layer ReLU45
I0619 14:48:21.854683 17263 net.cpp:459] Creating Layer ReLU45
I0619 14:48:21.854691 17263 net.cpp:886] ReLU45 <- Eltwise22
I0619 14:48:21.854696 17263 net.cpp:847] ReLU45 -> Eltwise22 (in-place)
I0619 14:48:21.854706 17263 net.cpp:509] Setting up ReLU45
I0619 14:48:21.854712 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.854717 17263 net.cpp:524] Memory required for data: 1897399808
I0619 14:48:21.854722 17263 layer_factory.hpp:77] Creating layer Eltwise22_ReLU45_0_split
I0619 14:48:21.854727 17263 net.cpp:459] Creating Layer Eltwise22_ReLU45_0_split
I0619 14:48:21.854737 17263 net.cpp:886] Eltwise22_ReLU45_0_split <- Eltwise22
I0619 14:48:21.854743 17263 net.cpp:860] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_0
I0619 14:48:21.854751 17263 net.cpp:860] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_1
I0619 14:48:21.854801 17263 net.cpp:509] Setting up Eltwise22_ReLU45_0_split
I0619 14:48:21.854809 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.854816 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.854821 17263 net.cpp:524] Memory required for data: 1905788416
I0619 14:48:21.854826 17263 layer_factory.hpp:77] Creating layer Convolution46
I0619 14:48:21.854838 17263 net.cpp:459] Creating Layer Convolution46
I0619 14:48:21.854845 17263 net.cpp:886] Convolution46 <- Eltwise22_ReLU45_0_split_0
I0619 14:48:21.854853 17263 net.cpp:860] Convolution46 -> Convolution46
I0619 14:48:21.855588 17263 net.cpp:509] Setting up Convolution46
I0619 14:48:21.855599 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.855603 17263 net.cpp:524] Memory required for data: 1909982720
I0619 14:48:21.855615 17263 layer_factory.hpp:77] Creating layer BatchNorm46
I0619 14:48:21.855625 17263 net.cpp:459] Creating Layer BatchNorm46
I0619 14:48:21.855631 17263 net.cpp:886] BatchNorm46 <- Convolution46
I0619 14:48:21.855638 17263 net.cpp:847] BatchNorm46 -> Convolution46 (in-place)
I0619 14:48:21.855901 17263 net.cpp:509] Setting up BatchNorm46
I0619 14:48:21.855909 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.855914 17263 net.cpp:524] Memory required for data: 1914177024
I0619 14:48:21.855928 17263 layer_factory.hpp:77] Creating layer Scale46
I0619 14:48:21.855936 17263 net.cpp:459] Creating Layer Scale46
I0619 14:48:21.855942 17263 net.cpp:886] Scale46 <- Convolution46
I0619 14:48:21.855950 17263 net.cpp:847] Scale46 -> Convolution46 (in-place)
I0619 14:48:21.855993 17263 layer_factory.hpp:77] Creating layer Scale46
I0619 14:48:21.856143 17263 net.cpp:509] Setting up Scale46
I0619 14:48:21.856154 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.856159 17263 net.cpp:524] Memory required for data: 1918371328
I0619 14:48:21.856170 17263 layer_factory.hpp:77] Creating layer ReLU46
I0619 14:48:21.856178 17263 net.cpp:459] Creating Layer ReLU46
I0619 14:48:21.856184 17263 net.cpp:886] ReLU46 <- Convolution46
I0619 14:48:21.856189 17263 net.cpp:847] ReLU46 -> Convolution46 (in-place)
I0619 14:48:21.856199 17263 net.cpp:509] Setting up ReLU46
I0619 14:48:21.856204 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.856209 17263 net.cpp:524] Memory required for data: 1922565632
I0619 14:48:21.856214 17263 layer_factory.hpp:77] Creating layer Convolution47
I0619 14:48:21.856228 17263 net.cpp:459] Creating Layer Convolution47
I0619 14:48:21.856233 17263 net.cpp:886] Convolution47 <- Convolution46
I0619 14:48:21.856243 17263 net.cpp:860] Convolution47 -> Convolution47
I0619 14:48:21.856976 17263 net.cpp:509] Setting up Convolution47
I0619 14:48:21.856986 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.856992 17263 net.cpp:524] Memory required for data: 1926759936
I0619 14:48:21.857002 17263 layer_factory.hpp:77] Creating layer BatchNorm47
I0619 14:48:21.857012 17263 net.cpp:459] Creating Layer BatchNorm47
I0619 14:48:21.857018 17263 net.cpp:886] BatchNorm47 <- Convolution47
I0619 14:48:21.857028 17263 net.cpp:847] BatchNorm47 -> Convolution47 (in-place)
I0619 14:48:21.857287 17263 net.cpp:509] Setting up BatchNorm47
I0619 14:48:21.857311 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.857316 17263 net.cpp:524] Memory required for data: 1930954240
I0619 14:48:21.857329 17263 layer_factory.hpp:77] Creating layer Scale47
I0619 14:48:21.857341 17263 net.cpp:459] Creating Layer Scale47
I0619 14:48:21.857347 17263 net.cpp:886] Scale47 <- Convolution47
I0619 14:48:21.857352 17263 net.cpp:847] Scale47 -> Convolution47 (in-place)
I0619 14:48:21.857398 17263 layer_factory.hpp:77] Creating layer Scale47
I0619 14:48:21.857550 17263 net.cpp:509] Setting up Scale47
I0619 14:48:21.857560 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.857564 17263 net.cpp:524] Memory required for data: 1935148544
I0619 14:48:21.857575 17263 layer_factory.hpp:77] Creating layer Eltwise23
I0619 14:48:21.857583 17263 net.cpp:459] Creating Layer Eltwise23
I0619 14:48:21.857589 17263 net.cpp:886] Eltwise23 <- Eltwise22_ReLU45_0_split_1
I0619 14:48:21.857595 17263 net.cpp:886] Eltwise23 <- Convolution47
I0619 14:48:21.857605 17263 net.cpp:860] Eltwise23 -> Eltwise23
I0619 14:48:21.857630 17263 net.cpp:509] Setting up Eltwise23
I0619 14:48:21.857637 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.857642 17263 net.cpp:524] Memory required for data: 1939342848
I0619 14:48:21.857646 17263 layer_factory.hpp:77] Creating layer ReLU47
I0619 14:48:21.857656 17263 net.cpp:459] Creating Layer ReLU47
I0619 14:48:21.857661 17263 net.cpp:886] ReLU47 <- Eltwise23
I0619 14:48:21.857666 17263 net.cpp:847] ReLU47 -> Eltwise23 (in-place)
I0619 14:48:21.857674 17263 net.cpp:509] Setting up ReLU47
I0619 14:48:21.857681 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.857686 17263 net.cpp:524] Memory required for data: 1943537152
I0619 14:48:21.857691 17263 layer_factory.hpp:77] Creating layer Eltwise23_ReLU47_0_split
I0619 14:48:21.857697 17263 net.cpp:459] Creating Layer Eltwise23_ReLU47_0_split
I0619 14:48:21.857702 17263 net.cpp:886] Eltwise23_ReLU47_0_split <- Eltwise23
I0619 14:48:21.857710 17263 net.cpp:860] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_0
I0619 14:48:21.857719 17263 net.cpp:860] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_1
I0619 14:48:21.857764 17263 net.cpp:509] Setting up Eltwise23_ReLU47_0_split
I0619 14:48:21.857771 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.857777 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.857782 17263 net.cpp:524] Memory required for data: 1951925760
I0619 14:48:21.857786 17263 layer_factory.hpp:77] Creating layer Convolution48
I0619 14:48:21.857800 17263 net.cpp:459] Creating Layer Convolution48
I0619 14:48:21.857805 17263 net.cpp:886] Convolution48 <- Eltwise23_ReLU47_0_split_0
I0619 14:48:21.857813 17263 net.cpp:860] Convolution48 -> Convolution48
I0619 14:48:21.858563 17263 net.cpp:509] Setting up Convolution48
I0619 14:48:21.858575 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.858580 17263 net.cpp:524] Memory required for data: 1956120064
I0619 14:48:21.858592 17263 layer_factory.hpp:77] Creating layer BatchNorm48
I0619 14:48:21.858603 17263 net.cpp:459] Creating Layer BatchNorm48
I0619 14:48:21.858609 17263 net.cpp:886] BatchNorm48 <- Convolution48
I0619 14:48:21.858616 17263 net.cpp:847] BatchNorm48 -> Convolution48 (in-place)
I0619 14:48:21.858875 17263 net.cpp:509] Setting up BatchNorm48
I0619 14:48:21.858882 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.858887 17263 net.cpp:524] Memory required for data: 1960314368
I0619 14:48:21.858902 17263 layer_factory.hpp:77] Creating layer Scale48
I0619 14:48:21.858911 17263 net.cpp:459] Creating Layer Scale48
I0619 14:48:21.858916 17263 net.cpp:886] Scale48 <- Convolution48
I0619 14:48:21.858922 17263 net.cpp:847] Scale48 -> Convolution48 (in-place)
I0619 14:48:21.858964 17263 layer_factory.hpp:77] Creating layer Scale48
I0619 14:48:21.859108 17263 net.cpp:509] Setting up Scale48
I0619 14:48:21.859117 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.859124 17263 net.cpp:524] Memory required for data: 1964508672
I0619 14:48:21.859149 17263 layer_factory.hpp:77] Creating layer ReLU48
I0619 14:48:21.859160 17263 net.cpp:459] Creating Layer ReLU48
I0619 14:48:21.859165 17263 net.cpp:886] ReLU48 <- Convolution48
I0619 14:48:21.859172 17263 net.cpp:847] ReLU48 -> Convolution48 (in-place)
I0619 14:48:21.859180 17263 net.cpp:509] Setting up ReLU48
I0619 14:48:21.859186 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.859190 17263 net.cpp:524] Memory required for data: 1968702976
I0619 14:48:21.859194 17263 layer_factory.hpp:77] Creating layer Convolution49
I0619 14:48:21.859206 17263 net.cpp:459] Creating Layer Convolution49
I0619 14:48:21.859211 17263 net.cpp:886] Convolution49 <- Convolution48
I0619 14:48:21.859222 17263 net.cpp:860] Convolution49 -> Convolution49
I0619 14:48:21.859917 17263 net.cpp:509] Setting up Convolution49
I0619 14:48:21.859928 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.859933 17263 net.cpp:524] Memory required for data: 1972897280
I0619 14:48:21.859943 17263 layer_factory.hpp:77] Creating layer BatchNorm49
I0619 14:48:21.859951 17263 net.cpp:459] Creating Layer BatchNorm49
I0619 14:48:21.859956 17263 net.cpp:886] BatchNorm49 <- Convolution49
I0619 14:48:21.859963 17263 net.cpp:847] BatchNorm49 -> Convolution49 (in-place)
I0619 14:48:21.860208 17263 net.cpp:509] Setting up BatchNorm49
I0619 14:48:21.860218 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.860221 17263 net.cpp:524] Memory required for data: 1977091584
I0619 14:48:21.860234 17263 layer_factory.hpp:77] Creating layer Scale49
I0619 14:48:21.860241 17263 net.cpp:459] Creating Layer Scale49
I0619 14:48:21.860246 17263 net.cpp:886] Scale49 <- Convolution49
I0619 14:48:21.860252 17263 net.cpp:847] Scale49 -> Convolution49 (in-place)
I0619 14:48:21.860296 17263 layer_factory.hpp:77] Creating layer Scale49
I0619 14:48:21.860447 17263 net.cpp:509] Setting up Scale49
I0619 14:48:21.860456 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.860460 17263 net.cpp:524] Memory required for data: 1981285888
I0619 14:48:21.860472 17263 layer_factory.hpp:77] Creating layer Eltwise24
I0619 14:48:21.860481 17263 net.cpp:459] Creating Layer Eltwise24
I0619 14:48:21.860486 17263 net.cpp:886] Eltwise24 <- Eltwise23_ReLU47_0_split_1
I0619 14:48:21.860492 17263 net.cpp:886] Eltwise24 <- Convolution49
I0619 14:48:21.860502 17263 net.cpp:860] Eltwise24 -> Eltwise24
I0619 14:48:21.860523 17263 net.cpp:509] Setting up Eltwise24
I0619 14:48:21.860532 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.860535 17263 net.cpp:524] Memory required for data: 1985480192
I0619 14:48:21.860539 17263 layer_factory.hpp:77] Creating layer ReLU49
I0619 14:48:21.860546 17263 net.cpp:459] Creating Layer ReLU49
I0619 14:48:21.860550 17263 net.cpp:886] ReLU49 <- Eltwise24
I0619 14:48:21.860561 17263 net.cpp:847] ReLU49 -> Eltwise24 (in-place)
I0619 14:48:21.860570 17263 net.cpp:509] Setting up ReLU49
I0619 14:48:21.860576 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.860580 17263 net.cpp:524] Memory required for data: 1989674496
I0619 14:48:21.860584 17263 layer_factory.hpp:77] Creating layer Eltwise24_ReLU49_0_split
I0619 14:48:21.860591 17263 net.cpp:459] Creating Layer Eltwise24_ReLU49_0_split
I0619 14:48:21.860595 17263 net.cpp:886] Eltwise24_ReLU49_0_split <- Eltwise24
I0619 14:48:21.860602 17263 net.cpp:860] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_0
I0619 14:48:21.860623 17263 net.cpp:860] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_1
I0619 14:48:21.860672 17263 net.cpp:509] Setting up Eltwise24_ReLU49_0_split
I0619 14:48:21.860682 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.860687 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.860692 17263 net.cpp:524] Memory required for data: 1998063104
I0619 14:48:21.860697 17263 layer_factory.hpp:77] Creating layer Convolution50
I0619 14:48:21.860709 17263 net.cpp:459] Creating Layer Convolution50
I0619 14:48:21.860715 17263 net.cpp:886] Convolution50 <- Eltwise24_ReLU49_0_split_0
I0619 14:48:21.860740 17263 net.cpp:860] Convolution50 -> Convolution50
I0619 14:48:21.861450 17263 net.cpp:509] Setting up Convolution50
I0619 14:48:21.861461 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.861466 17263 net.cpp:524] Memory required for data: 2002257408
I0619 14:48:21.861477 17263 layer_factory.hpp:77] Creating layer BatchNorm50
I0619 14:48:21.861485 17263 net.cpp:459] Creating Layer BatchNorm50
I0619 14:48:21.861490 17263 net.cpp:886] BatchNorm50 <- Convolution50
I0619 14:48:21.861500 17263 net.cpp:847] BatchNorm50 -> Convolution50 (in-place)
I0619 14:48:21.861747 17263 net.cpp:509] Setting up BatchNorm50
I0619 14:48:21.861755 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.861760 17263 net.cpp:524] Memory required for data: 2006451712
I0619 14:48:21.861773 17263 layer_factory.hpp:77] Creating layer Scale50
I0619 14:48:21.861780 17263 net.cpp:459] Creating Layer Scale50
I0619 14:48:21.861785 17263 net.cpp:886] Scale50 <- Convolution50
I0619 14:48:21.861793 17263 net.cpp:847] Scale50 -> Convolution50 (in-place)
I0619 14:48:21.861835 17263 layer_factory.hpp:77] Creating layer Scale50
I0619 14:48:21.861981 17263 net.cpp:509] Setting up Scale50
I0619 14:48:21.861990 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.861995 17263 net.cpp:524] Memory required for data: 2010646016
I0619 14:48:21.862005 17263 layer_factory.hpp:77] Creating layer ReLU50
I0619 14:48:21.862015 17263 net.cpp:459] Creating Layer ReLU50
I0619 14:48:21.862021 17263 net.cpp:886] ReLU50 <- Convolution50
I0619 14:48:21.862027 17263 net.cpp:847] ReLU50 -> Convolution50 (in-place)
I0619 14:48:21.862035 17263 net.cpp:509] Setting up ReLU50
I0619 14:48:21.862041 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.862046 17263 net.cpp:524] Memory required for data: 2014840320
I0619 14:48:21.862049 17263 layer_factory.hpp:77] Creating layer Convolution51
I0619 14:48:21.862061 17263 net.cpp:459] Creating Layer Convolution51
I0619 14:48:21.862073 17263 net.cpp:886] Convolution51 <- Convolution50
I0619 14:48:21.862082 17263 net.cpp:860] Convolution51 -> Convolution51
I0619 14:48:21.862792 17263 net.cpp:509] Setting up Convolution51
I0619 14:48:21.862803 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.862807 17263 net.cpp:524] Memory required for data: 2019034624
I0619 14:48:21.862818 17263 layer_factory.hpp:77] Creating layer BatchNorm51
I0619 14:48:21.862828 17263 net.cpp:459] Creating Layer BatchNorm51
I0619 14:48:21.862834 17263 net.cpp:886] BatchNorm51 <- Convolution51
I0619 14:48:21.862841 17263 net.cpp:847] BatchNorm51 -> Convolution51 (in-place)
I0619 14:48:21.863091 17263 net.cpp:509] Setting up BatchNorm51
I0619 14:48:21.863101 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.863106 17263 net.cpp:524] Memory required for data: 2023228928
I0619 14:48:21.863118 17263 layer_factory.hpp:77] Creating layer Scale51
I0619 14:48:21.863158 17263 net.cpp:459] Creating Layer Scale51
I0619 14:48:21.863165 17263 net.cpp:886] Scale51 <- Convolution51
I0619 14:48:21.863173 17263 net.cpp:847] Scale51 -> Convolution51 (in-place)
I0619 14:48:21.863221 17263 layer_factory.hpp:77] Creating layer Scale51
I0619 14:48:21.863369 17263 net.cpp:509] Setting up Scale51
I0619 14:48:21.863379 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.863384 17263 net.cpp:524] Memory required for data: 2027423232
I0619 14:48:21.863394 17263 layer_factory.hpp:77] Creating layer Eltwise25
I0619 14:48:21.863404 17263 net.cpp:459] Creating Layer Eltwise25
I0619 14:48:21.863409 17263 net.cpp:886] Eltwise25 <- Eltwise24_ReLU49_0_split_1
I0619 14:48:21.863416 17263 net.cpp:886] Eltwise25 <- Convolution51
I0619 14:48:21.863423 17263 net.cpp:860] Eltwise25 -> Eltwise25
I0619 14:48:21.863445 17263 net.cpp:509] Setting up Eltwise25
I0619 14:48:21.863452 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.863461 17263 net.cpp:524] Memory required for data: 2031617536
I0619 14:48:21.863466 17263 layer_factory.hpp:77] Creating layer ReLU51
I0619 14:48:21.863486 17263 net.cpp:459] Creating Layer ReLU51
I0619 14:48:21.863492 17263 net.cpp:886] ReLU51 <- Eltwise25
I0619 14:48:21.863500 17263 net.cpp:847] ReLU51 -> Eltwise25 (in-place)
I0619 14:48:21.863509 17263 net.cpp:509] Setting up ReLU51
I0619 14:48:21.863517 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.863520 17263 net.cpp:524] Memory required for data: 2035811840
I0619 14:48:21.863524 17263 layer_factory.hpp:77] Creating layer Eltwise25_ReLU51_0_split
I0619 14:48:21.863531 17263 net.cpp:459] Creating Layer Eltwise25_ReLU51_0_split
I0619 14:48:21.863535 17263 net.cpp:886] Eltwise25_ReLU51_0_split <- Eltwise25
I0619 14:48:21.863541 17263 net.cpp:860] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_0
I0619 14:48:21.863550 17263 net.cpp:860] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_1
I0619 14:48:21.863601 17263 net.cpp:509] Setting up Eltwise25_ReLU51_0_split
I0619 14:48:21.863610 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.863616 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.863620 17263 net.cpp:524] Memory required for data: 2044200448
I0619 14:48:21.863626 17263 layer_factory.hpp:77] Creating layer Convolution52
I0619 14:48:21.863636 17263 net.cpp:459] Creating Layer Convolution52
I0619 14:48:21.863641 17263 net.cpp:886] Convolution52 <- Eltwise25_ReLU51_0_split_0
I0619 14:48:21.863651 17263 net.cpp:860] Convolution52 -> Convolution52
I0619 14:48:21.864359 17263 net.cpp:509] Setting up Convolution52
I0619 14:48:21.864369 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.864374 17263 net.cpp:524] Memory required for data: 2048394752
I0619 14:48:21.864385 17263 layer_factory.hpp:77] Creating layer BatchNorm52
I0619 14:48:21.864393 17263 net.cpp:459] Creating Layer BatchNorm52
I0619 14:48:21.864398 17263 net.cpp:886] BatchNorm52 <- Convolution52
I0619 14:48:21.864408 17263 net.cpp:847] BatchNorm52 -> Convolution52 (in-place)
I0619 14:48:21.864653 17263 net.cpp:509] Setting up BatchNorm52
I0619 14:48:21.864661 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.864666 17263 net.cpp:524] Memory required for data: 2052589056
I0619 14:48:21.864680 17263 layer_factory.hpp:77] Creating layer Scale52
I0619 14:48:21.864686 17263 net.cpp:459] Creating Layer Scale52
I0619 14:48:21.864691 17263 net.cpp:886] Scale52 <- Convolution52
I0619 14:48:21.864698 17263 net.cpp:847] Scale52 -> Convolution52 (in-place)
I0619 14:48:21.864742 17263 layer_factory.hpp:77] Creating layer Scale52
I0619 14:48:21.864886 17263 net.cpp:509] Setting up Scale52
I0619 14:48:21.864895 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.864899 17263 net.cpp:524] Memory required for data: 2056783360
I0619 14:48:21.864909 17263 layer_factory.hpp:77] Creating layer ReLU52
I0619 14:48:21.864918 17263 net.cpp:459] Creating Layer ReLU52
I0619 14:48:21.864924 17263 net.cpp:886] ReLU52 <- Convolution52
I0619 14:48:21.864930 17263 net.cpp:847] ReLU52 -> Convolution52 (in-place)
I0619 14:48:21.864938 17263 net.cpp:509] Setting up ReLU52
I0619 14:48:21.864944 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.864948 17263 net.cpp:524] Memory required for data: 2060977664
I0619 14:48:21.864953 17263 layer_factory.hpp:77] Creating layer Convolution53
I0619 14:48:21.864964 17263 net.cpp:459] Creating Layer Convolution53
I0619 14:48:21.864969 17263 net.cpp:886] Convolution53 <- Convolution52
I0619 14:48:21.864976 17263 net.cpp:860] Convolution53 -> Convolution53
I0619 14:48:21.865679 17263 net.cpp:509] Setting up Convolution53
I0619 14:48:21.865689 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.865694 17263 net.cpp:524] Memory required for data: 2065171968
I0619 14:48:21.865705 17263 layer_factory.hpp:77] Creating layer BatchNorm53
I0619 14:48:21.865712 17263 net.cpp:459] Creating Layer BatchNorm53
I0619 14:48:21.865717 17263 net.cpp:886] BatchNorm53 <- Convolution53
I0619 14:48:21.865731 17263 net.cpp:847] BatchNorm53 -> Convolution53 (in-place)
I0619 14:48:21.865990 17263 net.cpp:509] Setting up BatchNorm53
I0619 14:48:21.866000 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.866005 17263 net.cpp:524] Memory required for data: 2069366272
I0619 14:48:21.866019 17263 layer_factory.hpp:77] Creating layer Scale53
I0619 14:48:21.866026 17263 net.cpp:459] Creating Layer Scale53
I0619 14:48:21.866031 17263 net.cpp:886] Scale53 <- Convolution53
I0619 14:48:21.866039 17263 net.cpp:847] Scale53 -> Convolution53 (in-place)
I0619 14:48:21.866083 17263 layer_factory.hpp:77] Creating layer Scale53
I0619 14:48:21.866228 17263 net.cpp:509] Setting up Scale53
I0619 14:48:21.866237 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.866241 17263 net.cpp:524] Memory required for data: 2073560576
I0619 14:48:21.866252 17263 layer_factory.hpp:77] Creating layer Eltwise26
I0619 14:48:21.866263 17263 net.cpp:459] Creating Layer Eltwise26
I0619 14:48:21.866268 17263 net.cpp:886] Eltwise26 <- Eltwise25_ReLU51_0_split_1
I0619 14:48:21.866274 17263 net.cpp:886] Eltwise26 <- Convolution53
I0619 14:48:21.866281 17263 net.cpp:860] Eltwise26 -> Eltwise26
I0619 14:48:21.866307 17263 net.cpp:509] Setting up Eltwise26
I0619 14:48:21.866315 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.866319 17263 net.cpp:524] Memory required for data: 2077754880
I0619 14:48:21.866323 17263 layer_factory.hpp:77] Creating layer ReLU53
I0619 14:48:21.866330 17263 net.cpp:459] Creating Layer ReLU53
I0619 14:48:21.866335 17263 net.cpp:886] ReLU53 <- Eltwise26
I0619 14:48:21.866343 17263 net.cpp:847] ReLU53 -> Eltwise26 (in-place)
I0619 14:48:21.866351 17263 net.cpp:509] Setting up ReLU53
I0619 14:48:21.866364 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.866369 17263 net.cpp:524] Memory required for data: 2081949184
I0619 14:48:21.866374 17263 layer_factory.hpp:77] Creating layer Eltwise26_ReLU53_0_split
I0619 14:48:21.866379 17263 net.cpp:459] Creating Layer Eltwise26_ReLU53_0_split
I0619 14:48:21.866384 17263 net.cpp:886] Eltwise26_ReLU53_0_split <- Eltwise26
I0619 14:48:21.866390 17263 net.cpp:860] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_0
I0619 14:48:21.866400 17263 net.cpp:860] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_1
I0619 14:48:21.866446 17263 net.cpp:509] Setting up Eltwise26_ReLU53_0_split
I0619 14:48:21.866454 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.866461 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.866464 17263 net.cpp:524] Memory required for data: 2090337792
I0619 14:48:21.866469 17263 layer_factory.hpp:77] Creating layer Convolution54
I0619 14:48:21.866482 17263 net.cpp:459] Creating Layer Convolution54
I0619 14:48:21.866487 17263 net.cpp:886] Convolution54 <- Eltwise26_ReLU53_0_split_0
I0619 14:48:21.866494 17263 net.cpp:860] Convolution54 -> Convolution54
I0619 14:48:21.867198 17263 net.cpp:509] Setting up Convolution54
I0619 14:48:21.867208 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.867213 17263 net.cpp:524] Memory required for data: 2094532096
I0619 14:48:21.867223 17263 layer_factory.hpp:77] Creating layer BatchNorm54
I0619 14:48:21.867233 17263 net.cpp:459] Creating Layer BatchNorm54
I0619 14:48:21.867239 17263 net.cpp:886] BatchNorm54 <- Convolution54
I0619 14:48:21.867247 17263 net.cpp:847] BatchNorm54 -> Convolution54 (in-place)
I0619 14:48:21.867491 17263 net.cpp:509] Setting up BatchNorm54
I0619 14:48:21.867499 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.867503 17263 net.cpp:524] Memory required for data: 2098726400
I0619 14:48:21.867516 17263 layer_factory.hpp:77] Creating layer Scale54
I0619 14:48:21.867525 17263 net.cpp:459] Creating Layer Scale54
I0619 14:48:21.867530 17263 net.cpp:886] Scale54 <- Convolution54
I0619 14:48:21.867537 17263 net.cpp:847] Scale54 -> Convolution54 (in-place)
I0619 14:48:21.867576 17263 layer_factory.hpp:77] Creating layer Scale54
I0619 14:48:21.867723 17263 net.cpp:509] Setting up Scale54
I0619 14:48:21.867735 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.867753 17263 net.cpp:524] Memory required for data: 2102920704
I0619 14:48:21.867764 17263 layer_factory.hpp:77] Creating layer ReLU54
I0619 14:48:21.867772 17263 net.cpp:459] Creating Layer ReLU54
I0619 14:48:21.867777 17263 net.cpp:886] ReLU54 <- Convolution54
I0619 14:48:21.867786 17263 net.cpp:847] ReLU54 -> Convolution54 (in-place)
I0619 14:48:21.867795 17263 net.cpp:509] Setting up ReLU54
I0619 14:48:21.867801 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.867805 17263 net.cpp:524] Memory required for data: 2107115008
I0619 14:48:21.867810 17263 layer_factory.hpp:77] Creating layer Convolution55
I0619 14:48:21.867825 17263 net.cpp:459] Creating Layer Convolution55
I0619 14:48:21.867830 17263 net.cpp:886] Convolution55 <- Convolution54
I0619 14:48:21.867836 17263 net.cpp:860] Convolution55 -> Convolution55
I0619 14:48:21.868537 17263 net.cpp:509] Setting up Convolution55
I0619 14:48:21.868548 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.868552 17263 net.cpp:524] Memory required for data: 2111309312
I0619 14:48:21.868566 17263 layer_factory.hpp:77] Creating layer BatchNorm55
I0619 14:48:21.868574 17263 net.cpp:459] Creating Layer BatchNorm55
I0619 14:48:21.868585 17263 net.cpp:886] BatchNorm55 <- Convolution55
I0619 14:48:21.868592 17263 net.cpp:847] BatchNorm55 -> Convolution55 (in-place)
I0619 14:48:21.868830 17263 net.cpp:509] Setting up BatchNorm55
I0619 14:48:21.868839 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.868844 17263 net.cpp:524] Memory required for data: 2115503616
I0619 14:48:21.868855 17263 layer_factory.hpp:77] Creating layer Scale55
I0619 14:48:21.868865 17263 net.cpp:459] Creating Layer Scale55
I0619 14:48:21.868870 17263 net.cpp:886] Scale55 <- Convolution55
I0619 14:48:21.868876 17263 net.cpp:847] Scale55 -> Convolution55 (in-place)
I0619 14:48:21.868924 17263 layer_factory.hpp:77] Creating layer Scale55
I0619 14:48:21.869068 17263 net.cpp:509] Setting up Scale55
I0619 14:48:21.869076 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.869081 17263 net.cpp:524] Memory required for data: 2119697920
I0619 14:48:21.869091 17263 layer_factory.hpp:77] Creating layer Eltwise27
I0619 14:48:21.869102 17263 net.cpp:459] Creating Layer Eltwise27
I0619 14:48:21.869107 17263 net.cpp:886] Eltwise27 <- Eltwise26_ReLU53_0_split_1
I0619 14:48:21.869113 17263 net.cpp:886] Eltwise27 <- Convolution55
I0619 14:48:21.869120 17263 net.cpp:860] Eltwise27 -> Eltwise27
I0619 14:48:21.869144 17263 net.cpp:509] Setting up Eltwise27
I0619 14:48:21.869153 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.869156 17263 net.cpp:524] Memory required for data: 2123892224
I0619 14:48:21.869161 17263 layer_factory.hpp:77] Creating layer ReLU55
I0619 14:48:21.869168 17263 net.cpp:459] Creating Layer ReLU55
I0619 14:48:21.869173 17263 net.cpp:886] ReLU55 <- Eltwise27
I0619 14:48:21.869179 17263 net.cpp:847] ReLU55 -> Eltwise27 (in-place)
I0619 14:48:21.869185 17263 net.cpp:509] Setting up ReLU55
I0619 14:48:21.869191 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.869195 17263 net.cpp:524] Memory required for data: 2128086528
I0619 14:48:21.869200 17263 layer_factory.hpp:77] Creating layer Eltwise27_ReLU55_0_split
I0619 14:48:21.869206 17263 net.cpp:459] Creating Layer Eltwise27_ReLU55_0_split
I0619 14:48:21.869210 17263 net.cpp:886] Eltwise27_ReLU55_0_split <- Eltwise27
I0619 14:48:21.869220 17263 net.cpp:860] Eltwise27_ReLU55_0_split -> Eltwise27_ReLU55_0_split_0
I0619 14:48:21.869227 17263 net.cpp:860] Eltwise27_ReLU55_0_split -> Eltwise27_ReLU55_0_split_1
I0619 14:48:21.869273 17263 net.cpp:509] Setting up Eltwise27_ReLU55_0_split
I0619 14:48:21.869282 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.869287 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.869292 17263 net.cpp:524] Memory required for data: 2136475136
I0619 14:48:21.869295 17263 layer_factory.hpp:77] Creating layer Convolution56
I0619 14:48:21.869308 17263 net.cpp:459] Creating Layer Convolution56
I0619 14:48:21.869326 17263 net.cpp:886] Convolution56 <- Eltwise27_ReLU55_0_split_0
I0619 14:48:21.869335 17263 net.cpp:860] Convolution56 -> Convolution56
I0619 14:48:21.870036 17263 net.cpp:509] Setting up Convolution56
I0619 14:48:21.870046 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.870051 17263 net.cpp:524] Memory required for data: 2140669440
I0619 14:48:21.870062 17263 layer_factory.hpp:77] Creating layer BatchNorm56
I0619 14:48:21.870072 17263 net.cpp:459] Creating Layer BatchNorm56
I0619 14:48:21.870077 17263 net.cpp:886] BatchNorm56 <- Convolution56
I0619 14:48:21.870086 17263 net.cpp:847] BatchNorm56 -> Convolution56 (in-place)
I0619 14:48:21.870334 17263 net.cpp:509] Setting up BatchNorm56
I0619 14:48:21.870344 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.870348 17263 net.cpp:524] Memory required for data: 2144863744
I0619 14:48:21.870369 17263 layer_factory.hpp:77] Creating layer Scale56
I0619 14:48:21.870378 17263 net.cpp:459] Creating Layer Scale56
I0619 14:48:21.870383 17263 net.cpp:886] Scale56 <- Convolution56
I0619 14:48:21.870390 17263 net.cpp:847] Scale56 -> Convolution56 (in-place)
I0619 14:48:21.870442 17263 layer_factory.hpp:77] Creating layer Scale56
I0619 14:48:21.870582 17263 net.cpp:509] Setting up Scale56
I0619 14:48:21.870591 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.870595 17263 net.cpp:524] Memory required for data: 2149058048
I0619 14:48:21.870605 17263 layer_factory.hpp:77] Creating layer ReLU56
I0619 14:48:21.870612 17263 net.cpp:459] Creating Layer ReLU56
I0619 14:48:21.870617 17263 net.cpp:886] ReLU56 <- Convolution56
I0619 14:48:21.870627 17263 net.cpp:847] ReLU56 -> Convolution56 (in-place)
I0619 14:48:21.870635 17263 net.cpp:509] Setting up ReLU56
I0619 14:48:21.870640 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.870645 17263 net.cpp:524] Memory required for data: 2153252352
I0619 14:48:21.870649 17263 layer_factory.hpp:77] Creating layer Convolution57
I0619 14:48:21.870658 17263 net.cpp:459] Creating Layer Convolution57
I0619 14:48:21.870662 17263 net.cpp:886] Convolution57 <- Convolution56
I0619 14:48:21.870671 17263 net.cpp:860] Convolution57 -> Convolution57
I0619 14:48:21.871335 17263 net.cpp:509] Setting up Convolution57
I0619 14:48:21.871346 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.871351 17263 net.cpp:524] Memory required for data: 2157446656
I0619 14:48:21.871361 17263 layer_factory.hpp:77] Creating layer BatchNorm57
I0619 14:48:21.871368 17263 net.cpp:459] Creating Layer BatchNorm57
I0619 14:48:21.871373 17263 net.cpp:886] BatchNorm57 <- Convolution57
I0619 14:48:21.871381 17263 net.cpp:847] BatchNorm57 -> Convolution57 (in-place)
I0619 14:48:21.871616 17263 net.cpp:509] Setting up BatchNorm57
I0619 14:48:21.871624 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.871629 17263 net.cpp:524] Memory required for data: 2161640960
I0619 14:48:21.871641 17263 layer_factory.hpp:77] Creating layer Scale57
I0619 14:48:21.871649 17263 net.cpp:459] Creating Layer Scale57
I0619 14:48:21.871654 17263 net.cpp:886] Scale57 <- Convolution57
I0619 14:48:21.871659 17263 net.cpp:847] Scale57 -> Convolution57 (in-place)
I0619 14:48:21.871706 17263 layer_factory.hpp:77] Creating layer Scale57
I0619 14:48:21.871845 17263 net.cpp:509] Setting up Scale57
I0619 14:48:21.871852 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.871856 17263 net.cpp:524] Memory required for data: 2165835264
I0619 14:48:21.871866 17263 layer_factory.hpp:77] Creating layer Eltwise28
I0619 14:48:21.871876 17263 net.cpp:459] Creating Layer Eltwise28
I0619 14:48:21.871881 17263 net.cpp:886] Eltwise28 <- Eltwise27_ReLU55_0_split_1
I0619 14:48:21.871887 17263 net.cpp:886] Eltwise28 <- Convolution57
I0619 14:48:21.871894 17263 net.cpp:860] Eltwise28 -> Eltwise28
I0619 14:48:21.871915 17263 net.cpp:509] Setting up Eltwise28
I0619 14:48:21.871922 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.871929 17263 net.cpp:524] Memory required for data: 2170029568
I0619 14:48:21.871948 17263 layer_factory.hpp:77] Creating layer ReLU57
I0619 14:48:21.871958 17263 net.cpp:459] Creating Layer ReLU57
I0619 14:48:21.871963 17263 net.cpp:886] ReLU57 <- Eltwise28
I0619 14:48:21.871968 17263 net.cpp:847] ReLU57 -> Eltwise28 (in-place)
I0619 14:48:21.871975 17263 net.cpp:509] Setting up ReLU57
I0619 14:48:21.871981 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.871986 17263 net.cpp:524] Memory required for data: 2174223872
I0619 14:48:21.871990 17263 layer_factory.hpp:77] Creating layer Eltwise28_ReLU57_0_split
I0619 14:48:21.871999 17263 net.cpp:459] Creating Layer Eltwise28_ReLU57_0_split
I0619 14:48:21.872002 17263 net.cpp:886] Eltwise28_ReLU57_0_split <- Eltwise28
I0619 14:48:21.872009 17263 net.cpp:860] Eltwise28_ReLU57_0_split -> Eltwise28_ReLU57_0_split_0
I0619 14:48:21.872016 17263 net.cpp:860] Eltwise28_ReLU57_0_split -> Eltwise28_ReLU57_0_split_1
I0619 14:48:21.872062 17263 net.cpp:509] Setting up Eltwise28_ReLU57_0_split
I0619 14:48:21.872071 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.872076 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.872079 17263 net.cpp:524] Memory required for data: 2182612480
I0619 14:48:21.872083 17263 layer_factory.hpp:77] Creating layer Convolution58
I0619 14:48:21.872095 17263 net.cpp:459] Creating Layer Convolution58
I0619 14:48:21.872100 17263 net.cpp:886] Convolution58 <- Eltwise28_ReLU57_0_split_0
I0619 14:48:21.872108 17263 net.cpp:860] Convolution58 -> Convolution58
I0619 14:48:21.873433 17263 net.cpp:509] Setting up Convolution58
I0619 14:48:21.873450 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.873456 17263 net.cpp:524] Memory required for data: 2186806784
I0619 14:48:21.873467 17263 layer_factory.hpp:77] Creating layer BatchNorm58
I0619 14:48:21.873477 17263 net.cpp:459] Creating Layer BatchNorm58
I0619 14:48:21.873484 17263 net.cpp:886] BatchNorm58 <- Convolution58
I0619 14:48:21.873492 17263 net.cpp:847] BatchNorm58 -> Convolution58 (in-place)
I0619 14:48:21.873733 17263 net.cpp:509] Setting up BatchNorm58
I0619 14:48:21.873741 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.873745 17263 net.cpp:524] Memory required for data: 2191001088
I0619 14:48:21.873760 17263 layer_factory.hpp:77] Creating layer Scale58
I0619 14:48:21.873769 17263 net.cpp:459] Creating Layer Scale58
I0619 14:48:21.873774 17263 net.cpp:886] Scale58 <- Convolution58
I0619 14:48:21.873780 17263 net.cpp:847] Scale58 -> Convolution58 (in-place)
I0619 14:48:21.873823 17263 layer_factory.hpp:77] Creating layer Scale58
I0619 14:48:21.873968 17263 net.cpp:509] Setting up Scale58
I0619 14:48:21.873977 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.873981 17263 net.cpp:524] Memory required for data: 2195195392
I0619 14:48:21.873993 17263 layer_factory.hpp:77] Creating layer ReLU58
I0619 14:48:21.874001 17263 net.cpp:459] Creating Layer ReLU58
I0619 14:48:21.874006 17263 net.cpp:886] ReLU58 <- Convolution58
I0619 14:48:21.874013 17263 net.cpp:847] ReLU58 -> Convolution58 (in-place)
I0619 14:48:21.874022 17263 net.cpp:509] Setting up ReLU58
I0619 14:48:21.874027 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.874032 17263 net.cpp:524] Memory required for data: 2199389696
I0619 14:48:21.874035 17263 layer_factory.hpp:77] Creating layer Convolution59
I0619 14:48:21.874045 17263 net.cpp:459] Creating Layer Convolution59
I0619 14:48:21.874049 17263 net.cpp:886] Convolution59 <- Convolution58
I0619 14:48:21.874059 17263 net.cpp:860] Convolution59 -> Convolution59
I0619 14:48:21.874732 17263 net.cpp:509] Setting up Convolution59
I0619 14:48:21.874742 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.874747 17263 net.cpp:524] Memory required for data: 2203584000
I0619 14:48:21.874758 17263 layer_factory.hpp:77] Creating layer BatchNorm59
I0619 14:48:21.874765 17263 net.cpp:459] Creating Layer BatchNorm59
I0619 14:48:21.874773 17263 net.cpp:886] BatchNorm59 <- Convolution59
I0619 14:48:21.874783 17263 net.cpp:847] BatchNorm59 -> Convolution59 (in-place)
I0619 14:48:21.875038 17263 net.cpp:509] Setting up BatchNorm59
I0619 14:48:21.875047 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.875051 17263 net.cpp:524] Memory required for data: 2207778304
I0619 14:48:21.875064 17263 layer_factory.hpp:77] Creating layer Scale59
I0619 14:48:21.875072 17263 net.cpp:459] Creating Layer Scale59
I0619 14:48:21.875077 17263 net.cpp:886] Scale59 <- Convolution59
I0619 14:48:21.875083 17263 net.cpp:847] Scale59 -> Convolution59 (in-place)
I0619 14:48:21.875125 17263 layer_factory.hpp:77] Creating layer Scale59
I0619 14:48:21.875265 17263 net.cpp:509] Setting up Scale59
I0619 14:48:21.875274 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.875278 17263 net.cpp:524] Memory required for data: 2211972608
I0619 14:48:21.875288 17263 layer_factory.hpp:77] Creating layer Eltwise29
I0619 14:48:21.875295 17263 net.cpp:459] Creating Layer Eltwise29
I0619 14:48:21.875304 17263 net.cpp:886] Eltwise29 <- Eltwise28_ReLU57_0_split_1
I0619 14:48:21.875310 17263 net.cpp:886] Eltwise29 <- Convolution59
I0619 14:48:21.875318 17263 net.cpp:860] Eltwise29 -> Eltwise29
I0619 14:48:21.875339 17263 net.cpp:509] Setting up Eltwise29
I0619 14:48:21.875346 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.875350 17263 net.cpp:524] Memory required for data: 2216166912
I0619 14:48:21.875355 17263 layer_factory.hpp:77] Creating layer ReLU59
I0619 14:48:21.875365 17263 net.cpp:459] Creating Layer ReLU59
I0619 14:48:21.875370 17263 net.cpp:886] ReLU59 <- Eltwise29
I0619 14:48:21.875376 17263 net.cpp:847] ReLU59 -> Eltwise29 (in-place)
I0619 14:48:21.875385 17263 net.cpp:509] Setting up ReLU59
I0619 14:48:21.875391 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.875394 17263 net.cpp:524] Memory required for data: 2220361216
I0619 14:48:21.875398 17263 layer_factory.hpp:77] Creating layer Eltwise29_ReLU59_0_split
I0619 14:48:21.875404 17263 net.cpp:459] Creating Layer Eltwise29_ReLU59_0_split
I0619 14:48:21.875408 17263 net.cpp:886] Eltwise29_ReLU59_0_split <- Eltwise29
I0619 14:48:21.875416 17263 net.cpp:860] Eltwise29_ReLU59_0_split -> Eltwise29_ReLU59_0_split_0
I0619 14:48:21.875424 17263 net.cpp:860] Eltwise29_ReLU59_0_split -> Eltwise29_ReLU59_0_split_1
I0619 14:48:21.875469 17263 net.cpp:509] Setting up Eltwise29_ReLU59_0_split
I0619 14:48:21.875478 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.875483 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.875486 17263 net.cpp:524] Memory required for data: 2228749824
I0619 14:48:21.875491 17263 layer_factory.hpp:77] Creating layer Convolution60
I0619 14:48:21.875505 17263 net.cpp:459] Creating Layer Convolution60
I0619 14:48:21.875510 17263 net.cpp:886] Convolution60 <- Eltwise29_ReLU59_0_split_0
I0619 14:48:21.875519 17263 net.cpp:860] Convolution60 -> Convolution60
I0619 14:48:21.876183 17263 net.cpp:509] Setting up Convolution60
I0619 14:48:21.876194 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.876197 17263 net.cpp:524] Memory required for data: 2232944128
I0619 14:48:21.876207 17263 layer_factory.hpp:77] Creating layer BatchNorm60
I0619 14:48:21.876217 17263 net.cpp:459] Creating Layer BatchNorm60
I0619 14:48:21.876222 17263 net.cpp:886] BatchNorm60 <- Convolution60
I0619 14:48:21.876229 17263 net.cpp:847] BatchNorm60 -> Convolution60 (in-place)
I0619 14:48:21.876466 17263 net.cpp:509] Setting up BatchNorm60
I0619 14:48:21.876473 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.876478 17263 net.cpp:524] Memory required for data: 2237138432
I0619 14:48:21.876490 17263 layer_factory.hpp:77] Creating layer Scale60
I0619 14:48:21.876497 17263 net.cpp:459] Creating Layer Scale60
I0619 14:48:21.876502 17263 net.cpp:886] Scale60 <- Convolution60
I0619 14:48:21.876512 17263 net.cpp:847] Scale60 -> Convolution60 (in-place)
I0619 14:48:21.876551 17263 layer_factory.hpp:77] Creating layer Scale60
I0619 14:48:21.876691 17263 net.cpp:509] Setting up Scale60
I0619 14:48:21.876716 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.876721 17263 net.cpp:524] Memory required for data: 2241332736
I0619 14:48:21.876732 17263 layer_factory.hpp:77] Creating layer ReLU60
I0619 14:48:21.876739 17263 net.cpp:459] Creating Layer ReLU60
I0619 14:48:21.876744 17263 net.cpp:886] ReLU60 <- Convolution60
I0619 14:48:21.876750 17263 net.cpp:847] ReLU60 -> Convolution60 (in-place)
I0619 14:48:21.876759 17263 net.cpp:509] Setting up ReLU60
I0619 14:48:21.876765 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.876768 17263 net.cpp:524] Memory required for data: 2245527040
I0619 14:48:21.876772 17263 layer_factory.hpp:77] Creating layer Convolution61
I0619 14:48:21.876785 17263 net.cpp:459] Creating Layer Convolution61
I0619 14:48:21.876790 17263 net.cpp:886] Convolution61 <- Convolution60
I0619 14:48:21.876798 17263 net.cpp:860] Convolution61 -> Convolution61
I0619 14:48:21.877465 17263 net.cpp:509] Setting up Convolution61
I0619 14:48:21.877475 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.877480 17263 net.cpp:524] Memory required for data: 2249721344
I0619 14:48:21.877490 17263 layer_factory.hpp:77] Creating layer BatchNorm61
I0619 14:48:21.877499 17263 net.cpp:459] Creating Layer BatchNorm61
I0619 14:48:21.877504 17263 net.cpp:886] BatchNorm61 <- Convolution61
I0619 14:48:21.877512 17263 net.cpp:847] BatchNorm61 -> Convolution61 (in-place)
I0619 14:48:21.877753 17263 net.cpp:509] Setting up BatchNorm61
I0619 14:48:21.877761 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.877765 17263 net.cpp:524] Memory required for data: 2253915648
I0619 14:48:21.877779 17263 layer_factory.hpp:77] Creating layer Scale61
I0619 14:48:21.877787 17263 net.cpp:459] Creating Layer Scale61
I0619 14:48:21.877792 17263 net.cpp:886] Scale61 <- Convolution61
I0619 14:48:21.877799 17263 net.cpp:847] Scale61 -> Convolution61 (in-place)
I0619 14:48:21.877838 17263 layer_factory.hpp:77] Creating layer Scale61
I0619 14:48:21.877979 17263 net.cpp:509] Setting up Scale61
I0619 14:48:21.877987 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.877991 17263 net.cpp:524] Memory required for data: 2258109952
I0619 14:48:21.878001 17263 layer_factory.hpp:77] Creating layer Eltwise30
I0619 14:48:21.878008 17263 net.cpp:459] Creating Layer Eltwise30
I0619 14:48:21.878013 17263 net.cpp:886] Eltwise30 <- Eltwise29_ReLU59_0_split_1
I0619 14:48:21.878020 17263 net.cpp:886] Eltwise30 <- Convolution61
I0619 14:48:21.878028 17263 net.cpp:860] Eltwise30 -> Eltwise30
I0619 14:48:21.878049 17263 net.cpp:509] Setting up Eltwise30
I0619 14:48:21.878057 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.878062 17263 net.cpp:524] Memory required for data: 2262304256
I0619 14:48:21.878065 17263 layer_factory.hpp:77] Creating layer ReLU61
I0619 14:48:21.878073 17263 net.cpp:459] Creating Layer ReLU61
I0619 14:48:21.878078 17263 net.cpp:886] ReLU61 <- Eltwise30
I0619 14:48:21.878084 17263 net.cpp:847] ReLU61 -> Eltwise30 (in-place)
I0619 14:48:21.878092 17263 net.cpp:509] Setting up ReLU61
I0619 14:48:21.878096 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.878101 17263 net.cpp:524] Memory required for data: 2266498560
I0619 14:48:21.878105 17263 layer_factory.hpp:77] Creating layer Eltwise30_ReLU61_0_split
I0619 14:48:21.878111 17263 net.cpp:459] Creating Layer Eltwise30_ReLU61_0_split
I0619 14:48:21.878115 17263 net.cpp:886] Eltwise30_ReLU61_0_split <- Eltwise30
I0619 14:48:21.878123 17263 net.cpp:860] Eltwise30_ReLU61_0_split -> Eltwise30_ReLU61_0_split_0
I0619 14:48:21.878131 17263 net.cpp:860] Eltwise30_ReLU61_0_split -> Eltwise30_ReLU61_0_split_1
I0619 14:48:21.878173 17263 net.cpp:509] Setting up Eltwise30_ReLU61_0_split
I0619 14:48:21.878180 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.878186 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.878190 17263 net.cpp:524] Memory required for data: 2274887168
I0619 14:48:21.878198 17263 layer_factory.hpp:77] Creating layer Convolution62
I0619 14:48:21.878223 17263 net.cpp:459] Creating Layer Convolution62
I0619 14:48:21.878229 17263 net.cpp:886] Convolution62 <- Eltwise30_ReLU61_0_split_0
I0619 14:48:21.878238 17263 net.cpp:860] Convolution62 -> Convolution62
I0619 14:48:21.878917 17263 net.cpp:509] Setting up Convolution62
I0619 14:48:21.878928 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.878933 17263 net.cpp:524] Memory required for data: 2279081472
I0619 14:48:21.878943 17263 layer_factory.hpp:77] Creating layer BatchNorm62
I0619 14:48:21.878953 17263 net.cpp:459] Creating Layer BatchNorm62
I0619 14:48:21.878959 17263 net.cpp:886] BatchNorm62 <- Convolution62
I0619 14:48:21.878965 17263 net.cpp:847] BatchNorm62 -> Convolution62 (in-place)
I0619 14:48:21.879199 17263 net.cpp:509] Setting up BatchNorm62
I0619 14:48:21.879207 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.879212 17263 net.cpp:524] Memory required for data: 2283275776
I0619 14:48:21.879227 17263 layer_factory.hpp:77] Creating layer Scale62
I0619 14:48:21.879235 17263 net.cpp:459] Creating Layer Scale62
I0619 14:48:21.879240 17263 net.cpp:886] Scale62 <- Convolution62
I0619 14:48:21.879245 17263 net.cpp:847] Scale62 -> Convolution62 (in-place)
I0619 14:48:21.879287 17263 layer_factory.hpp:77] Creating layer Scale62
I0619 14:48:21.879431 17263 net.cpp:509] Setting up Scale62
I0619 14:48:21.879439 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.879444 17263 net.cpp:524] Memory required for data: 2287470080
I0619 14:48:21.879454 17263 layer_factory.hpp:77] Creating layer ReLU62
I0619 14:48:21.879463 17263 net.cpp:459] Creating Layer ReLU62
I0619 14:48:21.879468 17263 net.cpp:886] ReLU62 <- Convolution62
I0619 14:48:21.879474 17263 net.cpp:847] ReLU62 -> Convolution62 (in-place)
I0619 14:48:21.879482 17263 net.cpp:509] Setting up ReLU62
I0619 14:48:21.879487 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.879492 17263 net.cpp:524] Memory required for data: 2291664384
I0619 14:48:21.879495 17263 layer_factory.hpp:77] Creating layer Convolution63
I0619 14:48:21.879508 17263 net.cpp:459] Creating Layer Convolution63
I0619 14:48:21.879513 17263 net.cpp:886] Convolution63 <- Convolution62
I0619 14:48:21.879519 17263 net.cpp:860] Convolution63 -> Convolution63
I0619 14:48:21.880179 17263 net.cpp:509] Setting up Convolution63
I0619 14:48:21.880189 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.880194 17263 net.cpp:524] Memory required for data: 2295858688
I0619 14:48:21.880203 17263 layer_factory.hpp:77] Creating layer BatchNorm63
I0619 14:48:21.880213 17263 net.cpp:459] Creating Layer BatchNorm63
I0619 14:48:21.880218 17263 net.cpp:886] BatchNorm63 <- Convolution63
I0619 14:48:21.880224 17263 net.cpp:847] BatchNorm63 -> Convolution63 (in-place)
I0619 14:48:21.880463 17263 net.cpp:509] Setting up BatchNorm63
I0619 14:48:21.880475 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.880478 17263 net.cpp:524] Memory required for data: 2300052992
I0619 14:48:21.880493 17263 layer_factory.hpp:77] Creating layer Scale63
I0619 14:48:21.880501 17263 net.cpp:459] Creating Layer Scale63
I0619 14:48:21.880506 17263 net.cpp:886] Scale63 <- Convolution63
I0619 14:48:21.880511 17263 net.cpp:847] Scale63 -> Convolution63 (in-place)
I0619 14:48:21.880555 17263 layer_factory.hpp:77] Creating layer Scale63
I0619 14:48:21.880697 17263 net.cpp:509] Setting up Scale63
I0619 14:48:21.880704 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.880708 17263 net.cpp:524] Memory required for data: 2304247296
I0619 14:48:21.880722 17263 layer_factory.hpp:77] Creating layer Eltwise31
I0619 14:48:21.880728 17263 net.cpp:459] Creating Layer Eltwise31
I0619 14:48:21.880733 17263 net.cpp:886] Eltwise31 <- Eltwise30_ReLU61_0_split_1
I0619 14:48:21.880739 17263 net.cpp:886] Eltwise31 <- Convolution63
I0619 14:48:21.880748 17263 net.cpp:860] Eltwise31 -> Eltwise31
I0619 14:48:21.880770 17263 net.cpp:509] Setting up Eltwise31
I0619 14:48:21.880780 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.880798 17263 net.cpp:524] Memory required for data: 2308441600
I0619 14:48:21.880803 17263 layer_factory.hpp:77] Creating layer ReLU63
I0619 14:48:21.880810 17263 net.cpp:459] Creating Layer ReLU63
I0619 14:48:21.880815 17263 net.cpp:886] ReLU63 <- Eltwise31
I0619 14:48:21.880823 17263 net.cpp:847] ReLU63 -> Eltwise31 (in-place)
I0619 14:48:21.880831 17263 net.cpp:509] Setting up ReLU63
I0619 14:48:21.880837 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.880841 17263 net.cpp:524] Memory required for data: 2312635904
I0619 14:48:21.880846 17263 layer_factory.hpp:77] Creating layer Eltwise31_ReLU63_0_split
I0619 14:48:21.880851 17263 net.cpp:459] Creating Layer Eltwise31_ReLU63_0_split
I0619 14:48:21.880856 17263 net.cpp:886] Eltwise31_ReLU63_0_split <- Eltwise31
I0619 14:48:21.880862 17263 net.cpp:860] Eltwise31_ReLU63_0_split -> Eltwise31_ReLU63_0_split_0
I0619 14:48:21.880870 17263 net.cpp:860] Eltwise31_ReLU63_0_split -> Eltwise31_ReLU63_0_split_1
I0619 14:48:21.880918 17263 net.cpp:509] Setting up Eltwise31_ReLU63_0_split
I0619 14:48:21.880925 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.880930 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.880935 17263 net.cpp:524] Memory required for data: 2321024512
I0619 14:48:21.880939 17263 layer_factory.hpp:77] Creating layer Convolution64
I0619 14:48:21.880949 17263 net.cpp:459] Creating Layer Convolution64
I0619 14:48:21.880954 17263 net.cpp:886] Convolution64 <- Eltwise31_ReLU63_0_split_0
I0619 14:48:21.880964 17263 net.cpp:860] Convolution64 -> Convolution64
I0619 14:48:21.881638 17263 net.cpp:509] Setting up Convolution64
I0619 14:48:21.881649 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.881652 17263 net.cpp:524] Memory required for data: 2325218816
I0619 14:48:21.881662 17263 layer_factory.hpp:77] Creating layer BatchNorm64
I0619 14:48:21.881670 17263 net.cpp:459] Creating Layer BatchNorm64
I0619 14:48:21.881675 17263 net.cpp:886] BatchNorm64 <- Convolution64
I0619 14:48:21.881683 17263 net.cpp:847] BatchNorm64 -> Convolution64 (in-place)
I0619 14:48:21.881922 17263 net.cpp:509] Setting up BatchNorm64
I0619 14:48:21.881930 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.881934 17263 net.cpp:524] Memory required for data: 2329413120
I0619 14:48:21.881947 17263 layer_factory.hpp:77] Creating layer Scale64
I0619 14:48:21.881953 17263 net.cpp:459] Creating Layer Scale64
I0619 14:48:21.881958 17263 net.cpp:886] Scale64 <- Convolution64
I0619 14:48:21.881964 17263 net.cpp:847] Scale64 -> Convolution64 (in-place)
I0619 14:48:21.882006 17263 layer_factory.hpp:77] Creating layer Scale64
I0619 14:48:21.882150 17263 net.cpp:509] Setting up Scale64
I0619 14:48:21.882159 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.882164 17263 net.cpp:524] Memory required for data: 2333607424
I0619 14:48:21.882174 17263 layer_factory.hpp:77] Creating layer ReLU64
I0619 14:48:21.882182 17263 net.cpp:459] Creating Layer ReLU64
I0619 14:48:21.882189 17263 net.cpp:886] ReLU64 <- Convolution64
I0619 14:48:21.882194 17263 net.cpp:847] ReLU64 -> Convolution64 (in-place)
I0619 14:48:21.882201 17263 net.cpp:509] Setting up ReLU64
I0619 14:48:21.882207 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.882211 17263 net.cpp:524] Memory required for data: 2337801728
I0619 14:48:21.882215 17263 layer_factory.hpp:77] Creating layer Convolution65
I0619 14:48:21.882226 17263 net.cpp:459] Creating Layer Convolution65
I0619 14:48:21.882231 17263 net.cpp:886] Convolution65 <- Convolution64
I0619 14:48:21.882241 17263 net.cpp:860] Convolution65 -> Convolution65
I0619 14:48:21.882907 17263 net.cpp:509] Setting up Convolution65
I0619 14:48:21.882917 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.882922 17263 net.cpp:524] Memory required for data: 2341996032
I0619 14:48:21.882931 17263 layer_factory.hpp:77] Creating layer BatchNorm65
I0619 14:48:21.882941 17263 net.cpp:459] Creating Layer BatchNorm65
I0619 14:48:21.882949 17263 net.cpp:886] BatchNorm65 <- Convolution65
I0619 14:48:21.882968 17263 net.cpp:847] BatchNorm65 -> Convolution65 (in-place)
I0619 14:48:21.883198 17263 net.cpp:509] Setting up BatchNorm65
I0619 14:48:21.883208 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.883211 17263 net.cpp:524] Memory required for data: 2346190336
I0619 14:48:21.883224 17263 layer_factory.hpp:77] Creating layer Scale65
I0619 14:48:21.883231 17263 net.cpp:459] Creating Layer Scale65
I0619 14:48:21.883235 17263 net.cpp:886] Scale65 <- Convolution65
I0619 14:48:21.883244 17263 net.cpp:847] Scale65 -> Convolution65 (in-place)
I0619 14:48:21.883281 17263 layer_factory.hpp:77] Creating layer Scale65
I0619 14:48:21.883411 17263 net.cpp:509] Setting up Scale65
I0619 14:48:21.883421 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.883426 17263 net.cpp:524] Memory required for data: 2350384640
I0619 14:48:21.883435 17263 layer_factory.hpp:77] Creating layer Eltwise32
I0619 14:48:21.883442 17263 net.cpp:459] Creating Layer Eltwise32
I0619 14:48:21.883447 17263 net.cpp:886] Eltwise32 <- Eltwise31_ReLU63_0_split_1
I0619 14:48:21.883453 17263 net.cpp:886] Eltwise32 <- Convolution65
I0619 14:48:21.883460 17263 net.cpp:860] Eltwise32 -> Eltwise32
I0619 14:48:21.883482 17263 net.cpp:509] Setting up Eltwise32
I0619 14:48:21.883489 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.883492 17263 net.cpp:524] Memory required for data: 2354578944
I0619 14:48:21.883496 17263 layer_factory.hpp:77] Creating layer ReLU65
I0619 14:48:21.883502 17263 net.cpp:459] Creating Layer ReLU65
I0619 14:48:21.883507 17263 net.cpp:886] ReLU65 <- Eltwise32
I0619 14:48:21.883514 17263 net.cpp:847] ReLU65 -> Eltwise32 (in-place)
I0619 14:48:21.883522 17263 net.cpp:509] Setting up ReLU65
I0619 14:48:21.883527 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.883532 17263 net.cpp:524] Memory required for data: 2358773248
I0619 14:48:21.883535 17263 layer_factory.hpp:77] Creating layer Eltwise32_ReLU65_0_split
I0619 14:48:21.883541 17263 net.cpp:459] Creating Layer Eltwise32_ReLU65_0_split
I0619 14:48:21.883545 17263 net.cpp:886] Eltwise32_ReLU65_0_split <- Eltwise32
I0619 14:48:21.883550 17263 net.cpp:860] Eltwise32_ReLU65_0_split -> Eltwise32_ReLU65_0_split_0
I0619 14:48:21.883558 17263 net.cpp:860] Eltwise32_ReLU65_0_split -> Eltwise32_ReLU65_0_split_1
I0619 14:48:21.883600 17263 net.cpp:509] Setting up Eltwise32_ReLU65_0_split
I0619 14:48:21.883607 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.883612 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.883616 17263 net.cpp:524] Memory required for data: 2367161856
I0619 14:48:21.883620 17263 layer_factory.hpp:77] Creating layer Convolution66
I0619 14:48:21.883631 17263 net.cpp:459] Creating Layer Convolution66
I0619 14:48:21.883636 17263 net.cpp:886] Convolution66 <- Eltwise32_ReLU65_0_split_0
I0619 14:48:21.883644 17263 net.cpp:860] Convolution66 -> Convolution66
I0619 14:48:21.884276 17263 net.cpp:509] Setting up Convolution66
I0619 14:48:21.884285 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.884289 17263 net.cpp:524] Memory required for data: 2371356160
I0619 14:48:21.884299 17263 layer_factory.hpp:77] Creating layer BatchNorm66
I0619 14:48:21.884308 17263 net.cpp:459] Creating Layer BatchNorm66
I0619 14:48:21.884315 17263 net.cpp:886] BatchNorm66 <- Convolution66
I0619 14:48:21.884321 17263 net.cpp:847] BatchNorm66 -> Convolution66 (in-place)
I0619 14:48:21.884543 17263 net.cpp:509] Setting up BatchNorm66
I0619 14:48:21.884552 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.884557 17263 net.cpp:524] Memory required for data: 2375550464
I0619 14:48:21.884567 17263 layer_factory.hpp:77] Creating layer Scale66
I0619 14:48:21.884577 17263 net.cpp:459] Creating Layer Scale66
I0619 14:48:21.884582 17263 net.cpp:886] Scale66 <- Convolution66
I0619 14:48:21.884588 17263 net.cpp:847] Scale66 -> Convolution66 (in-place)
I0619 14:48:21.884632 17263 layer_factory.hpp:77] Creating layer Scale66
I0619 14:48:21.884785 17263 net.cpp:509] Setting up Scale66
I0619 14:48:21.884795 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.884799 17263 net.cpp:524] Memory required for data: 2379744768
I0619 14:48:21.884809 17263 layer_factory.hpp:77] Creating layer ReLU66
I0619 14:48:21.884816 17263 net.cpp:459] Creating Layer ReLU66
I0619 14:48:21.884821 17263 net.cpp:886] ReLU66 <- Convolution66
I0619 14:48:21.884829 17263 net.cpp:847] ReLU66 -> Convolution66 (in-place)
I0619 14:48:21.884836 17263 net.cpp:509] Setting up ReLU66
I0619 14:48:21.884842 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.884846 17263 net.cpp:524] Memory required for data: 2383939072
I0619 14:48:21.884850 17263 layer_factory.hpp:77] Creating layer Convolution67
I0619 14:48:21.884861 17263 net.cpp:459] Creating Layer Convolution67
I0619 14:48:21.884866 17263 net.cpp:886] Convolution67 <- Convolution66
I0619 14:48:21.884873 17263 net.cpp:860] Convolution67 -> Convolution67
I0619 14:48:21.885504 17263 net.cpp:509] Setting up Convolution67
I0619 14:48:21.885512 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.885517 17263 net.cpp:524] Memory required for data: 2388133376
I0619 14:48:21.885526 17263 layer_factory.hpp:77] Creating layer BatchNorm67
I0619 14:48:21.885535 17263 net.cpp:459] Creating Layer BatchNorm67
I0619 14:48:21.885540 17263 net.cpp:886] BatchNorm67 <- Convolution67
I0619 14:48:21.885546 17263 net.cpp:847] BatchNorm67 -> Convolution67 (in-place)
I0619 14:48:21.885766 17263 net.cpp:509] Setting up BatchNorm67
I0619 14:48:21.885776 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.885779 17263 net.cpp:524] Memory required for data: 2392327680
I0619 14:48:21.885793 17263 layer_factory.hpp:77] Creating layer Scale67
I0619 14:48:21.885800 17263 net.cpp:459] Creating Layer Scale67
I0619 14:48:21.885804 17263 net.cpp:886] Scale67 <- Convolution67
I0619 14:48:21.885810 17263 net.cpp:847] Scale67 -> Convolution67 (in-place)
I0619 14:48:21.885850 17263 layer_factory.hpp:77] Creating layer Scale67
I0619 14:48:21.885982 17263 net.cpp:509] Setting up Scale67
I0619 14:48:21.885990 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.885993 17263 net.cpp:524] Memory required for data: 2396521984
I0619 14:48:21.886003 17263 layer_factory.hpp:77] Creating layer Eltwise33
I0619 14:48:21.886013 17263 net.cpp:459] Creating Layer Eltwise33
I0619 14:48:21.886018 17263 net.cpp:886] Eltwise33 <- Eltwise32_ReLU65_0_split_1
I0619 14:48:21.886023 17263 net.cpp:886] Eltwise33 <- Convolution67
I0619 14:48:21.886029 17263 net.cpp:860] Eltwise33 -> Eltwise33
I0619 14:48:21.886054 17263 net.cpp:509] Setting up Eltwise33
I0619 14:48:21.886060 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.886065 17263 net.cpp:524] Memory required for data: 2400716288
I0619 14:48:21.886068 17263 layer_factory.hpp:77] Creating layer ReLU67
I0619 14:48:21.886075 17263 net.cpp:459] Creating Layer ReLU67
I0619 14:48:21.886078 17263 net.cpp:886] ReLU67 <- Eltwise33
I0619 14:48:21.886086 17263 net.cpp:847] ReLU67 -> Eltwise33 (in-place)
I0619 14:48:21.886093 17263 net.cpp:509] Setting up ReLU67
I0619 14:48:21.886099 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.886102 17263 net.cpp:524] Memory required for data: 2404910592
I0619 14:48:21.886106 17263 layer_factory.hpp:77] Creating layer Eltwise33_ReLU67_0_split
I0619 14:48:21.886112 17263 net.cpp:459] Creating Layer Eltwise33_ReLU67_0_split
I0619 14:48:21.886116 17263 net.cpp:886] Eltwise33_ReLU67_0_split <- Eltwise33
I0619 14:48:21.886122 17263 net.cpp:860] Eltwise33_ReLU67_0_split -> Eltwise33_ReLU67_0_split_0
I0619 14:48:21.886131 17263 net.cpp:860] Eltwise33_ReLU67_0_split -> Eltwise33_ReLU67_0_split_1
I0619 14:48:21.886171 17263 net.cpp:509] Setting up Eltwise33_ReLU67_0_split
I0619 14:48:21.886178 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.886183 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.886190 17263 net.cpp:524] Memory required for data: 2413299200
I0619 14:48:21.886194 17263 layer_factory.hpp:77] Creating layer Convolution68
I0619 14:48:21.886216 17263 net.cpp:459] Creating Layer Convolution68
I0619 14:48:21.886222 17263 net.cpp:886] Convolution68 <- Eltwise33_ReLU67_0_split_0
I0619 14:48:21.886231 17263 net.cpp:860] Convolution68 -> Convolution68
I0619 14:48:21.886881 17263 net.cpp:509] Setting up Convolution68
I0619 14:48:21.886891 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.886896 17263 net.cpp:524] Memory required for data: 2417493504
I0619 14:48:21.886906 17263 layer_factory.hpp:77] Creating layer BatchNorm68
I0619 14:48:21.886914 17263 net.cpp:459] Creating Layer BatchNorm68
I0619 14:48:21.886919 17263 net.cpp:886] BatchNorm68 <- Convolution68
I0619 14:48:21.886927 17263 net.cpp:847] BatchNorm68 -> Convolution68 (in-place)
I0619 14:48:21.887150 17263 net.cpp:509] Setting up BatchNorm68
I0619 14:48:21.887157 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.887161 17263 net.cpp:524] Memory required for data: 2421687808
I0619 14:48:21.887173 17263 layer_factory.hpp:77] Creating layer Scale68
I0619 14:48:21.887181 17263 net.cpp:459] Creating Layer Scale68
I0619 14:48:21.887186 17263 net.cpp:886] Scale68 <- Convolution68
I0619 14:48:21.887190 17263 net.cpp:847] Scale68 -> Convolution68 (in-place)
I0619 14:48:21.887229 17263 layer_factory.hpp:77] Creating layer Scale68
I0619 14:48:21.887362 17263 net.cpp:509] Setting up Scale68
I0619 14:48:21.887369 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.887373 17263 net.cpp:524] Memory required for data: 2425882112
I0619 14:48:21.887383 17263 layer_factory.hpp:77] Creating layer ReLU68
I0619 14:48:21.887392 17263 net.cpp:459] Creating Layer ReLU68
I0619 14:48:21.887397 17263 net.cpp:886] ReLU68 <- Convolution68
I0619 14:48:21.887403 17263 net.cpp:847] ReLU68 -> Convolution68 (in-place)
I0619 14:48:21.887409 17263 net.cpp:509] Setting up ReLU68
I0619 14:48:21.887414 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.887418 17263 net.cpp:524] Memory required for data: 2430076416
I0619 14:48:21.887423 17263 layer_factory.hpp:77] Creating layer Convolution69
I0619 14:48:21.887434 17263 net.cpp:459] Creating Layer Convolution69
I0619 14:48:21.887437 17263 net.cpp:886] Convolution69 <- Convolution68
I0619 14:48:21.887444 17263 net.cpp:860] Convolution69 -> Convolution69
I0619 14:48:21.888077 17263 net.cpp:509] Setting up Convolution69
I0619 14:48:21.888085 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.888089 17263 net.cpp:524] Memory required for data: 2434270720
I0619 14:48:21.888099 17263 layer_factory.hpp:77] Creating layer BatchNorm69
I0619 14:48:21.888106 17263 net.cpp:459] Creating Layer BatchNorm69
I0619 14:48:21.888111 17263 net.cpp:886] BatchNorm69 <- Convolution69
I0619 14:48:21.888119 17263 net.cpp:847] BatchNorm69 -> Convolution69 (in-place)
I0619 14:48:21.888340 17263 net.cpp:509] Setting up BatchNorm69
I0619 14:48:21.888347 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.888351 17263 net.cpp:524] Memory required for data: 2438465024
I0619 14:48:21.888363 17263 layer_factory.hpp:77] Creating layer Scale69
I0619 14:48:21.888370 17263 net.cpp:459] Creating Layer Scale69
I0619 14:48:21.888375 17263 net.cpp:886] Scale69 <- Convolution69
I0619 14:48:21.888381 17263 net.cpp:847] Scale69 -> Convolution69 (in-place)
I0619 14:48:21.888423 17263 layer_factory.hpp:77] Creating layer Scale69
I0619 14:48:21.888561 17263 net.cpp:509] Setting up Scale69
I0619 14:48:21.888568 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.888572 17263 net.cpp:524] Memory required for data: 2442659328
I0619 14:48:21.888582 17263 layer_factory.hpp:77] Creating layer Eltwise34
I0619 14:48:21.888592 17263 net.cpp:459] Creating Layer Eltwise34
I0619 14:48:21.888597 17263 net.cpp:886] Eltwise34 <- Eltwise33_ReLU67_0_split_1
I0619 14:48:21.888602 17263 net.cpp:886] Eltwise34 <- Convolution69
I0619 14:48:21.888607 17263 net.cpp:860] Eltwise34 -> Eltwise34
I0619 14:48:21.888636 17263 net.cpp:509] Setting up Eltwise34
I0619 14:48:21.888644 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.888661 17263 net.cpp:524] Memory required for data: 2446853632
I0619 14:48:21.888666 17263 layer_factory.hpp:77] Creating layer ReLU69
I0619 14:48:21.888674 17263 net.cpp:459] Creating Layer ReLU69
I0619 14:48:21.888677 17263 net.cpp:886] ReLU69 <- Eltwise34
I0619 14:48:21.888685 17263 net.cpp:847] ReLU69 -> Eltwise34 (in-place)
I0619 14:48:21.888694 17263 net.cpp:509] Setting up ReLU69
I0619 14:48:21.888698 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.888702 17263 net.cpp:524] Memory required for data: 2451047936
I0619 14:48:21.888706 17263 layer_factory.hpp:77] Creating layer Eltwise34_ReLU69_0_split
I0619 14:48:21.888712 17263 net.cpp:459] Creating Layer Eltwise34_ReLU69_0_split
I0619 14:48:21.888716 17263 net.cpp:886] Eltwise34_ReLU69_0_split <- Eltwise34
I0619 14:48:21.888722 17263 net.cpp:860] Eltwise34_ReLU69_0_split -> Eltwise34_ReLU69_0_split_0
I0619 14:48:21.888731 17263 net.cpp:860] Eltwise34_ReLU69_0_split -> Eltwise34_ReLU69_0_split_1
I0619 14:48:21.888774 17263 net.cpp:509] Setting up Eltwise34_ReLU69_0_split
I0619 14:48:21.888782 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.888787 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.888790 17263 net.cpp:524] Memory required for data: 2459436544
I0619 14:48:21.888794 17263 layer_factory.hpp:77] Creating layer Convolution70
I0619 14:48:21.888805 17263 net.cpp:459] Creating Layer Convolution70
I0619 14:48:21.888810 17263 net.cpp:886] Convolution70 <- Eltwise34_ReLU69_0_split_0
I0619 14:48:21.888818 17263 net.cpp:860] Convolution70 -> Convolution70
I0619 14:48:21.889451 17263 net.cpp:509] Setting up Convolution70
I0619 14:48:21.889461 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.889464 17263 net.cpp:524] Memory required for data: 2463630848
I0619 14:48:21.889474 17263 layer_factory.hpp:77] Creating layer BatchNorm70
I0619 14:48:21.889483 17263 net.cpp:459] Creating Layer BatchNorm70
I0619 14:48:21.889488 17263 net.cpp:886] BatchNorm70 <- Convolution70
I0619 14:48:21.889497 17263 net.cpp:847] BatchNorm70 -> Convolution70 (in-place)
I0619 14:48:21.889719 17263 net.cpp:509] Setting up BatchNorm70
I0619 14:48:21.889726 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.889730 17263 net.cpp:524] Memory required for data: 2467825152
I0619 14:48:21.889742 17263 layer_factory.hpp:77] Creating layer Scale70
I0619 14:48:21.889751 17263 net.cpp:459] Creating Layer Scale70
I0619 14:48:21.889756 17263 net.cpp:886] Scale70 <- Convolution70
I0619 14:48:21.889762 17263 net.cpp:847] Scale70 -> Convolution70 (in-place)
I0619 14:48:21.889799 17263 layer_factory.hpp:77] Creating layer Scale70
I0619 14:48:21.889932 17263 net.cpp:509] Setting up Scale70
I0619 14:48:21.889940 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.889945 17263 net.cpp:524] Memory required for data: 2472019456
I0619 14:48:21.889955 17263 layer_factory.hpp:77] Creating layer ReLU70
I0619 14:48:21.889961 17263 net.cpp:459] Creating Layer ReLU70
I0619 14:48:21.889966 17263 net.cpp:886] ReLU70 <- Convolution70
I0619 14:48:21.889973 17263 net.cpp:847] ReLU70 -> Convolution70 (in-place)
I0619 14:48:21.889981 17263 net.cpp:509] Setting up ReLU70
I0619 14:48:21.889986 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.889991 17263 net.cpp:524] Memory required for data: 2476213760
I0619 14:48:21.889994 17263 layer_factory.hpp:77] Creating layer Convolution71
I0619 14:48:21.890005 17263 net.cpp:459] Creating Layer Convolution71
I0619 14:48:21.890009 17263 net.cpp:886] Convolution71 <- Convolution70
I0619 14:48:21.890017 17263 net.cpp:860] Convolution71 -> Convolution71
I0619 14:48:21.890657 17263 net.cpp:509] Setting up Convolution71
I0619 14:48:21.890667 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.890672 17263 net.cpp:524] Memory required for data: 2480408064
I0619 14:48:21.890683 17263 layer_factory.hpp:77] Creating layer BatchNorm71
I0619 14:48:21.890696 17263 net.cpp:459] Creating Layer BatchNorm71
I0619 14:48:21.890714 17263 net.cpp:886] BatchNorm71 <- Convolution71
I0619 14:48:21.890722 17263 net.cpp:847] BatchNorm71 -> Convolution71 (in-place)
I0619 14:48:21.890949 17263 net.cpp:509] Setting up BatchNorm71
I0619 14:48:21.890957 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.890961 17263 net.cpp:524] Memory required for data: 2484602368
I0619 14:48:21.890974 17263 layer_factory.hpp:77] Creating layer Scale71
I0619 14:48:21.890983 17263 net.cpp:459] Creating Layer Scale71
I0619 14:48:21.890988 17263 net.cpp:886] Scale71 <- Convolution71
I0619 14:48:21.890995 17263 net.cpp:847] Scale71 -> Convolution71 (in-place)
I0619 14:48:21.891036 17263 layer_factory.hpp:77] Creating layer Scale71
I0619 14:48:21.891170 17263 net.cpp:509] Setting up Scale71
I0619 14:48:21.891177 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.891181 17263 net.cpp:524] Memory required for data: 2488796672
I0619 14:48:21.891191 17263 layer_factory.hpp:77] Creating layer Eltwise35
I0619 14:48:21.891201 17263 net.cpp:459] Creating Layer Eltwise35
I0619 14:48:21.891206 17263 net.cpp:886] Eltwise35 <- Eltwise34_ReLU69_0_split_1
I0619 14:48:21.891211 17263 net.cpp:886] Eltwise35 <- Convolution71
I0619 14:48:21.891217 17263 net.cpp:860] Eltwise35 -> Eltwise35
I0619 14:48:21.891240 17263 net.cpp:509] Setting up Eltwise35
I0619 14:48:21.891247 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.891252 17263 net.cpp:524] Memory required for data: 2492990976
I0619 14:48:21.891255 17263 layer_factory.hpp:77] Creating layer ReLU71
I0619 14:48:21.891261 17263 net.cpp:459] Creating Layer ReLU71
I0619 14:48:21.891265 17263 net.cpp:886] ReLU71 <- Eltwise35
I0619 14:48:21.891270 17263 net.cpp:847] ReLU71 -> Eltwise35 (in-place)
I0619 14:48:21.891278 17263 net.cpp:509] Setting up ReLU71
I0619 14:48:21.891283 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.891286 17263 net.cpp:524] Memory required for data: 2497185280
I0619 14:48:21.891290 17263 layer_factory.hpp:77] Creating layer Eltwise35_ReLU71_0_split
I0619 14:48:21.891296 17263 net.cpp:459] Creating Layer Eltwise35_ReLU71_0_split
I0619 14:48:21.891300 17263 net.cpp:886] Eltwise35_ReLU71_0_split <- Eltwise35
I0619 14:48:21.891309 17263 net.cpp:860] Eltwise35_ReLU71_0_split -> Eltwise35_ReLU71_0_split_0
I0619 14:48:21.891316 17263 net.cpp:860] Eltwise35_ReLU71_0_split -> Eltwise35_ReLU71_0_split_1
I0619 14:48:21.891358 17263 net.cpp:509] Setting up Eltwise35_ReLU71_0_split
I0619 14:48:21.891366 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.891371 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.891376 17263 net.cpp:524] Memory required for data: 2505573888
I0619 14:48:21.891379 17263 layer_factory.hpp:77] Creating layer Convolution72
I0619 14:48:21.891388 17263 net.cpp:459] Creating Layer Convolution72
I0619 14:48:21.891392 17263 net.cpp:886] Convolution72 <- Eltwise35_ReLU71_0_split_0
I0619 14:48:21.891401 17263 net.cpp:860] Convolution72 -> Convolution72
I0619 14:48:21.892035 17263 net.cpp:509] Setting up Convolution72
I0619 14:48:21.892045 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.892048 17263 net.cpp:524] Memory required for data: 2509768192
I0619 14:48:21.892058 17263 layer_factory.hpp:77] Creating layer BatchNorm72
I0619 14:48:21.892069 17263 net.cpp:459] Creating Layer BatchNorm72
I0619 14:48:21.892074 17263 net.cpp:886] BatchNorm72 <- Convolution72
I0619 14:48:21.892081 17263 net.cpp:847] BatchNorm72 -> Convolution72 (in-place)
I0619 14:48:21.892309 17263 net.cpp:509] Setting up BatchNorm72
I0619 14:48:21.892318 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.892321 17263 net.cpp:524] Memory required for data: 2513962496
I0619 14:48:21.892333 17263 layer_factory.hpp:77] Creating layer Scale72
I0619 14:48:21.892340 17263 net.cpp:459] Creating Layer Scale72
I0619 14:48:21.892344 17263 net.cpp:886] Scale72 <- Convolution72
I0619 14:48:21.892350 17263 net.cpp:847] Scale72 -> Convolution72 (in-place)
I0619 14:48:21.892392 17263 layer_factory.hpp:77] Creating layer Scale72
I0619 14:48:21.892544 17263 net.cpp:509] Setting up Scale72
I0619 14:48:21.892554 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.892559 17263 net.cpp:524] Memory required for data: 2518156800
I0619 14:48:21.892568 17263 layer_factory.hpp:77] Creating layer ReLU72
I0619 14:48:21.892575 17263 net.cpp:459] Creating Layer ReLU72
I0619 14:48:21.892580 17263 net.cpp:886] ReLU72 <- Convolution72
I0619 14:48:21.892587 17263 net.cpp:847] ReLU72 -> Convolution72 (in-place)
I0619 14:48:21.892596 17263 net.cpp:509] Setting up ReLU72
I0619 14:48:21.892601 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.892604 17263 net.cpp:524] Memory required for data: 2522351104
I0619 14:48:21.892608 17263 layer_factory.hpp:77] Creating layer Convolution73
I0619 14:48:21.892617 17263 net.cpp:459] Creating Layer Convolution73
I0619 14:48:21.892622 17263 net.cpp:886] Convolution73 <- Convolution72
I0619 14:48:21.892630 17263 net.cpp:860] Convolution73 -> Convolution73
I0619 14:48:21.893261 17263 net.cpp:509] Setting up Convolution73
I0619 14:48:21.893270 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.893275 17263 net.cpp:524] Memory required for data: 2526545408
I0619 14:48:21.893285 17263 layer_factory.hpp:77] Creating layer BatchNorm73
I0619 14:48:21.893291 17263 net.cpp:459] Creating Layer BatchNorm73
I0619 14:48:21.893296 17263 net.cpp:886] BatchNorm73 <- Convolution73
I0619 14:48:21.893304 17263 net.cpp:847] BatchNorm73 -> Convolution73 (in-place)
I0619 14:48:21.893530 17263 net.cpp:509] Setting up BatchNorm73
I0619 14:48:21.893538 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.893543 17263 net.cpp:524] Memory required for data: 2530739712
I0619 14:48:21.893554 17263 layer_factory.hpp:77] Creating layer Scale73
I0619 14:48:21.893560 17263 net.cpp:459] Creating Layer Scale73
I0619 14:48:21.893565 17263 net.cpp:886] Scale73 <- Convolution73
I0619 14:48:21.893570 17263 net.cpp:847] Scale73 -> Convolution73 (in-place)
I0619 14:48:21.893611 17263 layer_factory.hpp:77] Creating layer Scale73
I0619 14:48:21.893748 17263 net.cpp:509] Setting up Scale73
I0619 14:48:21.893756 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.893760 17263 net.cpp:524] Memory required for data: 2534934016
I0619 14:48:21.893769 17263 layer_factory.hpp:77] Creating layer Eltwise36
I0619 14:48:21.893779 17263 net.cpp:459] Creating Layer Eltwise36
I0619 14:48:21.893784 17263 net.cpp:886] Eltwise36 <- Eltwise35_ReLU71_0_split_1
I0619 14:48:21.893790 17263 net.cpp:886] Eltwise36 <- Convolution73
I0619 14:48:21.893795 17263 net.cpp:860] Eltwise36 -> Eltwise36
I0619 14:48:21.893816 17263 net.cpp:509] Setting up Eltwise36
I0619 14:48:21.893823 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.893827 17263 net.cpp:524] Memory required for data: 2539128320
I0619 14:48:21.893831 17263 layer_factory.hpp:77] Creating layer ReLU73
I0619 14:48:21.893839 17263 net.cpp:459] Creating Layer ReLU73
I0619 14:48:21.893843 17263 net.cpp:886] ReLU73 <- Eltwise36
I0619 14:48:21.893849 17263 net.cpp:847] ReLU73 -> Eltwise36 (in-place)
I0619 14:48:21.893856 17263 net.cpp:509] Setting up ReLU73
I0619 14:48:21.893862 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.893865 17263 net.cpp:524] Memory required for data: 2543322624
I0619 14:48:21.893869 17263 layer_factory.hpp:77] Creating layer Eltwise36_ReLU73_0_split
I0619 14:48:21.893877 17263 net.cpp:459] Creating Layer Eltwise36_ReLU73_0_split
I0619 14:48:21.893882 17263 net.cpp:886] Eltwise36_ReLU73_0_split <- Eltwise36
I0619 14:48:21.893887 17263 net.cpp:860] Eltwise36_ReLU73_0_split -> Eltwise36_ReLU73_0_split_0
I0619 14:48:21.893894 17263 net.cpp:860] Eltwise36_ReLU73_0_split -> Eltwise36_ReLU73_0_split_1
I0619 14:48:21.893937 17263 net.cpp:509] Setting up Eltwise36_ReLU73_0_split
I0619 14:48:21.893944 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.893949 17263 net.cpp:516] Top shape: 128 32 16 16 (1048576)
I0619 14:48:21.893956 17263 net.cpp:524] Memory required for data: 2551711232
I0619 14:48:21.893972 17263 layer_factory.hpp:77] Creating layer Pooling2
I0619 14:48:21.893980 17263 net.cpp:459] Creating Layer Pooling2
I0619 14:48:21.893985 17263 net.cpp:886] Pooling2 <- Eltwise36_ReLU73_0_split_0
I0619 14:48:21.893995 17263 net.cpp:860] Pooling2 -> Pooling2
I0619 14:48:21.894023 17263 net.cpp:509] Setting up Pooling2
I0619 14:48:21.894031 17263 net.cpp:516] Top shape: 128 32 8 8 (262144)
I0619 14:48:21.894034 17263 net.cpp:524] Memory required for data: 2552759808
I0619 14:48:21.894038 17263 layer_factory.hpp:77] Creating layer Input2
I0619 14:48:21.894045 17263 net.cpp:459] Creating Layer Input2
I0619 14:48:21.894052 17263 net.cpp:860] Input2 -> Input2
I0619 14:48:21.894079 17263 net.cpp:509] Setting up Input2
I0619 14:48:21.894088 17263 net.cpp:516] Top shape: 128 32 8 8 (262144)
I0619 14:48:21.894091 17263 net.cpp:524] Memory required for data: 2553808384
I0619 14:48:21.894095 17263 layer_factory.hpp:77] Creating layer Concat2
I0619 14:48:21.894104 17263 net.cpp:459] Creating Layer Concat2
I0619 14:48:21.894109 17263 net.cpp:886] Concat2 <- Pooling2
I0619 14:48:21.894114 17263 net.cpp:886] Concat2 <- Input2
I0619 14:48:21.894120 17263 net.cpp:860] Concat2 -> Concat2
I0619 14:48:21.894145 17263 net.cpp:509] Setting up Concat2
I0619 14:48:21.894155 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.894158 17263 net.cpp:524] Memory required for data: 2555905536
I0619 14:48:21.894162 17263 layer_factory.hpp:77] Creating layer Convolution74
I0619 14:48:21.894175 17263 net.cpp:459] Creating Layer Convolution74
I0619 14:48:21.894178 17263 net.cpp:886] Convolution74 <- Eltwise36_ReLU73_0_split_1
I0619 14:48:21.894186 17263 net.cpp:860] Convolution74 -> Convolution74
I0619 14:48:21.895186 17263 net.cpp:509] Setting up Convolution74
I0619 14:48:21.895196 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.895200 17263 net.cpp:524] Memory required for data: 2558002688
I0619 14:48:21.895263 17263 layer_factory.hpp:77] Creating layer BatchNorm74
I0619 14:48:21.895273 17263 net.cpp:459] Creating Layer BatchNorm74
I0619 14:48:21.895278 17263 net.cpp:886] BatchNorm74 <- Convolution74
I0619 14:48:21.895284 17263 net.cpp:847] BatchNorm74 -> Convolution74 (in-place)
I0619 14:48:21.895515 17263 net.cpp:509] Setting up BatchNorm74
I0619 14:48:21.895524 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.895527 17263 net.cpp:524] Memory required for data: 2560099840
I0619 14:48:21.895540 17263 layer_factory.hpp:77] Creating layer Scale74
I0619 14:48:21.895547 17263 net.cpp:459] Creating Layer Scale74
I0619 14:48:21.895552 17263 net.cpp:886] Scale74 <- Convolution74
I0619 14:48:21.895557 17263 net.cpp:847] Scale74 -> Convolution74 (in-place)
I0619 14:48:21.895598 17263 layer_factory.hpp:77] Creating layer Scale74
I0619 14:48:21.895730 17263 net.cpp:509] Setting up Scale74
I0619 14:48:21.895740 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.895745 17263 net.cpp:524] Memory required for data: 2562196992
I0619 14:48:21.895755 17263 layer_factory.hpp:77] Creating layer ReLU74
I0619 14:48:21.895761 17263 net.cpp:459] Creating Layer ReLU74
I0619 14:48:21.895764 17263 net.cpp:886] ReLU74 <- Convolution74
I0619 14:48:21.895771 17263 net.cpp:847] ReLU74 -> Convolution74 (in-place)
I0619 14:48:21.895777 17263 net.cpp:509] Setting up ReLU74
I0619 14:48:21.895782 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.895786 17263 net.cpp:524] Memory required for data: 2564294144
I0619 14:48:21.895789 17263 layer_factory.hpp:77] Creating layer Convolution75
I0619 14:48:21.895802 17263 net.cpp:459] Creating Layer Convolution75
I0619 14:48:21.895805 17263 net.cpp:886] Convolution75 <- Convolution74
I0619 14:48:21.895813 17263 net.cpp:860] Convolution75 -> Convolution75
I0619 14:48:21.897464 17263 net.cpp:509] Setting up Convolution75
I0619 14:48:21.897475 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.897478 17263 net.cpp:524] Memory required for data: 2566391296
I0619 14:48:21.897490 17263 layer_factory.hpp:77] Creating layer BatchNorm75
I0619 14:48:21.897513 17263 net.cpp:459] Creating Layer BatchNorm75
I0619 14:48:21.897519 17263 net.cpp:886] BatchNorm75 <- Convolution75
I0619 14:48:21.897527 17263 net.cpp:847] BatchNorm75 -> Convolution75 (in-place)
I0619 14:48:21.897749 17263 net.cpp:509] Setting up BatchNorm75
I0619 14:48:21.897758 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.897761 17263 net.cpp:524] Memory required for data: 2568488448
I0619 14:48:21.897774 17263 layer_factory.hpp:77] Creating layer Scale75
I0619 14:48:21.897781 17263 net.cpp:459] Creating Layer Scale75
I0619 14:48:21.897786 17263 net.cpp:886] Scale75 <- Convolution75
I0619 14:48:21.897791 17263 net.cpp:847] Scale75 -> Convolution75 (in-place)
I0619 14:48:21.897830 17263 layer_factory.hpp:77] Creating layer Scale75
I0619 14:48:21.897963 17263 net.cpp:509] Setting up Scale75
I0619 14:48:21.897970 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.897974 17263 net.cpp:524] Memory required for data: 2570585600
I0619 14:48:21.897985 17263 layer_factory.hpp:77] Creating layer Eltwise37
I0619 14:48:21.897992 17263 net.cpp:459] Creating Layer Eltwise37
I0619 14:48:21.897996 17263 net.cpp:886] Eltwise37 <- Concat2
I0619 14:48:21.898002 17263 net.cpp:886] Eltwise37 <- Convolution75
I0619 14:48:21.898010 17263 net.cpp:860] Eltwise37 -> Eltwise37
I0619 14:48:21.898031 17263 net.cpp:509] Setting up Eltwise37
I0619 14:48:21.898037 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.898041 17263 net.cpp:524] Memory required for data: 2572682752
I0619 14:48:21.898046 17263 layer_factory.hpp:77] Creating layer ReLU75
I0619 14:48:21.898051 17263 net.cpp:459] Creating Layer ReLU75
I0619 14:48:21.898054 17263 net.cpp:886] ReLU75 <- Eltwise37
I0619 14:48:21.898067 17263 net.cpp:847] ReLU75 -> Eltwise37 (in-place)
I0619 14:48:21.898074 17263 net.cpp:509] Setting up ReLU75
I0619 14:48:21.898079 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.898083 17263 net.cpp:524] Memory required for data: 2574779904
I0619 14:48:21.898087 17263 layer_factory.hpp:77] Creating layer Eltwise37_ReLU75_0_split
I0619 14:48:21.898093 17263 net.cpp:459] Creating Layer Eltwise37_ReLU75_0_split
I0619 14:48:21.898097 17263 net.cpp:886] Eltwise37_ReLU75_0_split <- Eltwise37
I0619 14:48:21.898102 17263 net.cpp:860] Eltwise37_ReLU75_0_split -> Eltwise37_ReLU75_0_split_0
I0619 14:48:21.898110 17263 net.cpp:860] Eltwise37_ReLU75_0_split -> Eltwise37_ReLU75_0_split_1
I0619 14:48:21.898151 17263 net.cpp:509] Setting up Eltwise37_ReLU75_0_split
I0619 14:48:21.898159 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.898164 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.898167 17263 net.cpp:524] Memory required for data: 2578974208
I0619 14:48:21.898171 17263 layer_factory.hpp:77] Creating layer Convolution76
I0619 14:48:21.898180 17263 net.cpp:459] Creating Layer Convolution76
I0619 14:48:21.898185 17263 net.cpp:886] Convolution76 <- Eltwise37_ReLU75_0_split_0
I0619 14:48:21.898195 17263 net.cpp:860] Convolution76 -> Convolution76
I0619 14:48:21.899845 17263 net.cpp:509] Setting up Convolution76
I0619 14:48:21.899857 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.899860 17263 net.cpp:524] Memory required for data: 2581071360
I0619 14:48:21.899869 17263 layer_factory.hpp:77] Creating layer BatchNorm76
I0619 14:48:21.899876 17263 net.cpp:459] Creating Layer BatchNorm76
I0619 14:48:21.899881 17263 net.cpp:886] BatchNorm76 <- Convolution76
I0619 14:48:21.899889 17263 net.cpp:847] BatchNorm76 -> Convolution76 (in-place)
I0619 14:48:21.900107 17263 net.cpp:509] Setting up BatchNorm76
I0619 14:48:21.900115 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.900120 17263 net.cpp:524] Memory required for data: 2583168512
I0619 14:48:21.900130 17263 layer_factory.hpp:77] Creating layer Scale76
I0619 14:48:21.900141 17263 net.cpp:459] Creating Layer Scale76
I0619 14:48:21.900144 17263 net.cpp:886] Scale76 <- Convolution76
I0619 14:48:21.900153 17263 net.cpp:847] Scale76 -> Convolution76 (in-place)
I0619 14:48:21.900208 17263 layer_factory.hpp:77] Creating layer Scale76
I0619 14:48:21.900342 17263 net.cpp:509] Setting up Scale76
I0619 14:48:21.900351 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.900354 17263 net.cpp:524] Memory required for data: 2585265664
I0619 14:48:21.900364 17263 layer_factory.hpp:77] Creating layer ReLU76
I0619 14:48:21.900370 17263 net.cpp:459] Creating Layer ReLU76
I0619 14:48:21.900375 17263 net.cpp:886] ReLU76 <- Convolution76
I0619 14:48:21.900383 17263 net.cpp:847] ReLU76 -> Convolution76 (in-place)
I0619 14:48:21.900390 17263 net.cpp:509] Setting up ReLU76
I0619 14:48:21.900395 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.900399 17263 net.cpp:524] Memory required for data: 2587362816
I0619 14:48:21.900403 17263 layer_factory.hpp:77] Creating layer Convolution77
I0619 14:48:21.900415 17263 net.cpp:459] Creating Layer Convolution77
I0619 14:48:21.900419 17263 net.cpp:886] Convolution77 <- Convolution76
I0619 14:48:21.900426 17263 net.cpp:860] Convolution77 -> Convolution77
I0619 14:48:21.902068 17263 net.cpp:509] Setting up Convolution77
I0619 14:48:21.902078 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.902082 17263 net.cpp:524] Memory required for data: 2589459968
I0619 14:48:21.902091 17263 layer_factory.hpp:77] Creating layer BatchNorm77
I0619 14:48:21.902101 17263 net.cpp:459] Creating Layer BatchNorm77
I0619 14:48:21.902104 17263 net.cpp:886] BatchNorm77 <- Convolution77
I0619 14:48:21.902110 17263 net.cpp:847] BatchNorm77 -> Convolution77 (in-place)
I0619 14:48:21.902338 17263 net.cpp:509] Setting up BatchNorm77
I0619 14:48:21.902345 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.902349 17263 net.cpp:524] Memory required for data: 2591557120
I0619 14:48:21.902366 17263 layer_factory.hpp:77] Creating layer Scale77
I0619 14:48:21.902374 17263 net.cpp:459] Creating Layer Scale77
I0619 14:48:21.902379 17263 net.cpp:886] Scale77 <- Convolution77
I0619 14:48:21.902384 17263 net.cpp:847] Scale77 -> Convolution77 (in-place)
I0619 14:48:21.902427 17263 layer_factory.hpp:77] Creating layer Scale77
I0619 14:48:21.902559 17263 net.cpp:509] Setting up Scale77
I0619 14:48:21.902566 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.902570 17263 net.cpp:524] Memory required for data: 2593654272
I0619 14:48:21.902581 17263 layer_factory.hpp:77] Creating layer Eltwise38
I0619 14:48:21.902590 17263 net.cpp:459] Creating Layer Eltwise38
I0619 14:48:21.902595 17263 net.cpp:886] Eltwise38 <- Eltwise37_ReLU75_0_split_1
I0619 14:48:21.902601 17263 net.cpp:886] Eltwise38 <- Convolution77
I0619 14:48:21.902606 17263 net.cpp:860] Eltwise38 -> Eltwise38
I0619 14:48:21.902627 17263 net.cpp:509] Setting up Eltwise38
I0619 14:48:21.902633 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.902637 17263 net.cpp:524] Memory required for data: 2595751424
I0619 14:48:21.902642 17263 layer_factory.hpp:77] Creating layer ReLU77
I0619 14:48:21.902650 17263 net.cpp:459] Creating Layer ReLU77
I0619 14:48:21.902654 17263 net.cpp:886] ReLU77 <- Eltwise38
I0619 14:48:21.902662 17263 net.cpp:847] ReLU77 -> Eltwise38 (in-place)
I0619 14:48:21.902668 17263 net.cpp:509] Setting up ReLU77
I0619 14:48:21.902673 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.902678 17263 net.cpp:524] Memory required for data: 2597848576
I0619 14:48:21.902681 17263 layer_factory.hpp:77] Creating layer Eltwise38_ReLU77_0_split
I0619 14:48:21.902686 17263 net.cpp:459] Creating Layer Eltwise38_ReLU77_0_split
I0619 14:48:21.902690 17263 net.cpp:886] Eltwise38_ReLU77_0_split <- Eltwise38
I0619 14:48:21.902696 17263 net.cpp:860] Eltwise38_ReLU77_0_split -> Eltwise38_ReLU77_0_split_0
I0619 14:48:21.902704 17263 net.cpp:860] Eltwise38_ReLU77_0_split -> Eltwise38_ReLU77_0_split_1
I0619 14:48:21.902743 17263 net.cpp:509] Setting up Eltwise38_ReLU77_0_split
I0619 14:48:21.902750 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.902755 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.902761 17263 net.cpp:524] Memory required for data: 2602042880
I0619 14:48:21.902778 17263 layer_factory.hpp:77] Creating layer Convolution78
I0619 14:48:21.902789 17263 net.cpp:459] Creating Layer Convolution78
I0619 14:48:21.902796 17263 net.cpp:886] Convolution78 <- Eltwise38_ReLU77_0_split_0
I0619 14:48:21.902802 17263 net.cpp:860] Convolution78 -> Convolution78
I0619 14:48:21.904451 17263 net.cpp:509] Setting up Convolution78
I0619 14:48:21.904461 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.904465 17263 net.cpp:524] Memory required for data: 2604140032
I0619 14:48:21.904474 17263 layer_factory.hpp:77] Creating layer BatchNorm78
I0619 14:48:21.904484 17263 net.cpp:459] Creating Layer BatchNorm78
I0619 14:48:21.904489 17263 net.cpp:886] BatchNorm78 <- Convolution78
I0619 14:48:21.904496 17263 net.cpp:847] BatchNorm78 -> Convolution78 (in-place)
I0619 14:48:21.904717 17263 net.cpp:509] Setting up BatchNorm78
I0619 14:48:21.904726 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.904729 17263 net.cpp:524] Memory required for data: 2606237184
I0619 14:48:21.904744 17263 layer_factory.hpp:77] Creating layer Scale78
I0619 14:48:21.904752 17263 net.cpp:459] Creating Layer Scale78
I0619 14:48:21.904755 17263 net.cpp:886] Scale78 <- Convolution78
I0619 14:48:21.904762 17263 net.cpp:847] Scale78 -> Convolution78 (in-place)
I0619 14:48:21.904800 17263 layer_factory.hpp:77] Creating layer Scale78
I0619 14:48:21.904932 17263 net.cpp:509] Setting up Scale78
I0619 14:48:21.904939 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.904943 17263 net.cpp:524] Memory required for data: 2608334336
I0619 14:48:21.904954 17263 layer_factory.hpp:77] Creating layer ReLU78
I0619 14:48:21.904960 17263 net.cpp:459] Creating Layer ReLU78
I0619 14:48:21.904965 17263 net.cpp:886] ReLU78 <- Convolution78
I0619 14:48:21.904973 17263 net.cpp:847] ReLU78 -> Convolution78 (in-place)
I0619 14:48:21.904980 17263 net.cpp:509] Setting up ReLU78
I0619 14:48:21.904985 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.904989 17263 net.cpp:524] Memory required for data: 2610431488
I0619 14:48:21.904992 17263 layer_factory.hpp:77] Creating layer Convolution79
I0619 14:48:21.905001 17263 net.cpp:459] Creating Layer Convolution79
I0619 14:48:21.905005 17263 net.cpp:886] Convolution79 <- Convolution78
I0619 14:48:21.905014 17263 net.cpp:860] Convolution79 -> Convolution79
I0619 14:48:21.906672 17263 net.cpp:509] Setting up Convolution79
I0619 14:48:21.906682 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.906687 17263 net.cpp:524] Memory required for data: 2612528640
I0619 14:48:21.906695 17263 layer_factory.hpp:77] Creating layer BatchNorm79
I0619 14:48:21.906702 17263 net.cpp:459] Creating Layer BatchNorm79
I0619 14:48:21.906708 17263 net.cpp:886] BatchNorm79 <- Convolution79
I0619 14:48:21.906715 17263 net.cpp:847] BatchNorm79 -> Convolution79 (in-place)
I0619 14:48:21.907554 17263 net.cpp:509] Setting up BatchNorm79
I0619 14:48:21.907569 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.907574 17263 net.cpp:524] Memory required for data: 2614625792
I0619 14:48:21.907588 17263 layer_factory.hpp:77] Creating layer Scale79
I0619 14:48:21.907598 17263 net.cpp:459] Creating Layer Scale79
I0619 14:48:21.907603 17263 net.cpp:886] Scale79 <- Convolution79
I0619 14:48:21.907609 17263 net.cpp:847] Scale79 -> Convolution79 (in-place)
I0619 14:48:21.907655 17263 layer_factory.hpp:77] Creating layer Scale79
I0619 14:48:21.907790 17263 net.cpp:509] Setting up Scale79
I0619 14:48:21.907799 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.907802 17263 net.cpp:524] Memory required for data: 2616722944
I0619 14:48:21.907812 17263 layer_factory.hpp:77] Creating layer Eltwise39
I0619 14:48:21.907821 17263 net.cpp:459] Creating Layer Eltwise39
I0619 14:48:21.907826 17263 net.cpp:886] Eltwise39 <- Eltwise38_ReLU77_0_split_1
I0619 14:48:21.907832 17263 net.cpp:886] Eltwise39 <- Convolution79
I0619 14:48:21.907840 17263 net.cpp:860] Eltwise39 -> Eltwise39
I0619 14:48:21.907866 17263 net.cpp:509] Setting up Eltwise39
I0619 14:48:21.907887 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.907892 17263 net.cpp:524] Memory required for data: 2618820096
I0619 14:48:21.907896 17263 layer_factory.hpp:77] Creating layer ReLU79
I0619 14:48:21.907902 17263 net.cpp:459] Creating Layer ReLU79
I0619 14:48:21.907907 17263 net.cpp:886] ReLU79 <- Eltwise39
I0619 14:48:21.907915 17263 net.cpp:847] ReLU79 -> Eltwise39 (in-place)
I0619 14:48:21.907922 17263 net.cpp:509] Setting up ReLU79
I0619 14:48:21.907928 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.907932 17263 net.cpp:524] Memory required for data: 2620917248
I0619 14:48:21.907935 17263 layer_factory.hpp:77] Creating layer Eltwise39_ReLU79_0_split
I0619 14:48:21.907941 17263 net.cpp:459] Creating Layer Eltwise39_ReLU79_0_split
I0619 14:48:21.907945 17263 net.cpp:886] Eltwise39_ReLU79_0_split <- Eltwise39
I0619 14:48:21.907950 17263 net.cpp:860] Eltwise39_ReLU79_0_split -> Eltwise39_ReLU79_0_split_0
I0619 14:48:21.907958 17263 net.cpp:860] Eltwise39_ReLU79_0_split -> Eltwise39_ReLU79_0_split_1
I0619 14:48:21.908000 17263 net.cpp:509] Setting up Eltwise39_ReLU79_0_split
I0619 14:48:21.908007 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.908012 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.908016 17263 net.cpp:524] Memory required for data: 2625111552
I0619 14:48:21.908020 17263 layer_factory.hpp:77] Creating layer Convolution80
I0619 14:48:21.908030 17263 net.cpp:459] Creating Layer Convolution80
I0619 14:48:21.908035 17263 net.cpp:886] Convolution80 <- Eltwise39_ReLU79_0_split_0
I0619 14:48:21.908043 17263 net.cpp:860] Convolution80 -> Convolution80
I0619 14:48:21.910280 17263 net.cpp:509] Setting up Convolution80
I0619 14:48:21.910296 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.910300 17263 net.cpp:524] Memory required for data: 2627208704
I0619 14:48:21.910312 17263 layer_factory.hpp:77] Creating layer BatchNorm80
I0619 14:48:21.910322 17263 net.cpp:459] Creating Layer BatchNorm80
I0619 14:48:21.910327 17263 net.cpp:886] BatchNorm80 <- Convolution80
I0619 14:48:21.910336 17263 net.cpp:847] BatchNorm80 -> Convolution80 (in-place)
I0619 14:48:21.910572 17263 net.cpp:509] Setting up BatchNorm80
I0619 14:48:21.910580 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.910584 17263 net.cpp:524] Memory required for data: 2629305856
I0619 14:48:21.910601 17263 layer_factory.hpp:77] Creating layer Scale80
I0619 14:48:21.910609 17263 net.cpp:459] Creating Layer Scale80
I0619 14:48:21.910614 17263 net.cpp:886] Scale80 <- Convolution80
I0619 14:48:21.910619 17263 net.cpp:847] Scale80 -> Convolution80 (in-place)
I0619 14:48:21.910662 17263 layer_factory.hpp:77] Creating layer Scale80
I0619 14:48:21.910804 17263 net.cpp:509] Setting up Scale80
I0619 14:48:21.910811 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.910815 17263 net.cpp:524] Memory required for data: 2631403008
I0619 14:48:21.910825 17263 layer_factory.hpp:77] Creating layer ReLU80
I0619 14:48:21.910832 17263 net.cpp:459] Creating Layer ReLU80
I0619 14:48:21.910837 17263 net.cpp:886] ReLU80 <- Convolution80
I0619 14:48:21.910845 17263 net.cpp:847] ReLU80 -> Convolution80 (in-place)
I0619 14:48:21.910852 17263 net.cpp:509] Setting up ReLU80
I0619 14:48:21.910857 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.910861 17263 net.cpp:524] Memory required for data: 2633500160
I0619 14:48:21.910866 17263 layer_factory.hpp:77] Creating layer Convolution81
I0619 14:48:21.910874 17263 net.cpp:459] Creating Layer Convolution81
I0619 14:48:21.910878 17263 net.cpp:886] Convolution81 <- Convolution80
I0619 14:48:21.910887 17263 net.cpp:860] Convolution81 -> Convolution81
I0619 14:48:21.912524 17263 net.cpp:509] Setting up Convolution81
I0619 14:48:21.912534 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.912539 17263 net.cpp:524] Memory required for data: 2635597312
I0619 14:48:21.912549 17263 layer_factory.hpp:77] Creating layer BatchNorm81
I0619 14:48:21.912559 17263 net.cpp:459] Creating Layer BatchNorm81
I0619 14:48:21.912580 17263 net.cpp:886] BatchNorm81 <- Convolution81
I0619 14:48:21.912590 17263 net.cpp:847] BatchNorm81 -> Convolution81 (in-place)
I0619 14:48:21.912817 17263 net.cpp:509] Setting up BatchNorm81
I0619 14:48:21.912825 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.912829 17263 net.cpp:524] Memory required for data: 2637694464
I0619 14:48:21.912842 17263 layer_factory.hpp:77] Creating layer Scale81
I0619 14:48:21.912849 17263 net.cpp:459] Creating Layer Scale81
I0619 14:48:21.912853 17263 net.cpp:886] Scale81 <- Convolution81
I0619 14:48:21.912861 17263 net.cpp:847] Scale81 -> Convolution81 (in-place)
I0619 14:48:21.912900 17263 layer_factory.hpp:77] Creating layer Scale81
I0619 14:48:21.913035 17263 net.cpp:509] Setting up Scale81
I0619 14:48:21.913043 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.913048 17263 net.cpp:524] Memory required for data: 2639791616
I0619 14:48:21.913056 17263 layer_factory.hpp:77] Creating layer Eltwise40
I0619 14:48:21.913064 17263 net.cpp:459] Creating Layer Eltwise40
I0619 14:48:21.913069 17263 net.cpp:886] Eltwise40 <- Eltwise39_ReLU79_0_split_1
I0619 14:48:21.913074 17263 net.cpp:886] Eltwise40 <- Convolution81
I0619 14:48:21.913082 17263 net.cpp:860] Eltwise40 -> Eltwise40
I0619 14:48:21.913105 17263 net.cpp:509] Setting up Eltwise40
I0619 14:48:21.913115 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.913118 17263 net.cpp:524] Memory required for data: 2641888768
I0619 14:48:21.913122 17263 layer_factory.hpp:77] Creating layer ReLU81
I0619 14:48:21.913128 17263 net.cpp:459] Creating Layer ReLU81
I0619 14:48:21.913133 17263 net.cpp:886] ReLU81 <- Eltwise40
I0619 14:48:21.913139 17263 net.cpp:847] ReLU81 -> Eltwise40 (in-place)
I0619 14:48:21.913146 17263 net.cpp:509] Setting up ReLU81
I0619 14:48:21.913151 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.913156 17263 net.cpp:524] Memory required for data: 2643985920
I0619 14:48:21.913158 17263 layer_factory.hpp:77] Creating layer Eltwise40_ReLU81_0_split
I0619 14:48:21.913164 17263 net.cpp:459] Creating Layer Eltwise40_ReLU81_0_split
I0619 14:48:21.913168 17263 net.cpp:886] Eltwise40_ReLU81_0_split <- Eltwise40
I0619 14:48:21.913175 17263 net.cpp:860] Eltwise40_ReLU81_0_split -> Eltwise40_ReLU81_0_split_0
I0619 14:48:21.913183 17263 net.cpp:860] Eltwise40_ReLU81_0_split -> Eltwise40_ReLU81_0_split_1
I0619 14:48:21.913223 17263 net.cpp:509] Setting up Eltwise40_ReLU81_0_split
I0619 14:48:21.913229 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.913234 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.913239 17263 net.cpp:524] Memory required for data: 2648180224
I0619 14:48:21.913242 17263 layer_factory.hpp:77] Creating layer Convolution82
I0619 14:48:21.913254 17263 net.cpp:459] Creating Layer Convolution82
I0619 14:48:21.913257 17263 net.cpp:886] Convolution82 <- Eltwise40_ReLU81_0_split_0
I0619 14:48:21.913265 17263 net.cpp:860] Convolution82 -> Convolution82
I0619 14:48:21.914906 17263 net.cpp:509] Setting up Convolution82
I0619 14:48:21.914917 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.914921 17263 net.cpp:524] Memory required for data: 2650277376
I0619 14:48:21.914932 17263 layer_factory.hpp:77] Creating layer BatchNorm82
I0619 14:48:21.914942 17263 net.cpp:459] Creating Layer BatchNorm82
I0619 14:48:21.914947 17263 net.cpp:886] BatchNorm82 <- Convolution82
I0619 14:48:21.914952 17263 net.cpp:847] BatchNorm82 -> Convolution82 (in-place)
I0619 14:48:21.915182 17263 net.cpp:509] Setting up BatchNorm82
I0619 14:48:21.915190 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.915194 17263 net.cpp:524] Memory required for data: 2652374528
I0619 14:48:21.915206 17263 layer_factory.hpp:77] Creating layer Scale82
I0619 14:48:21.915213 17263 net.cpp:459] Creating Layer Scale82
I0619 14:48:21.915217 17263 net.cpp:886] Scale82 <- Convolution82
I0619 14:48:21.915223 17263 net.cpp:847] Scale82 -> Convolution82 (in-place)
I0619 14:48:21.915269 17263 layer_factory.hpp:77] Creating layer Scale82
I0619 14:48:21.915428 17263 net.cpp:509] Setting up Scale82
I0619 14:48:21.915437 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.915441 17263 net.cpp:524] Memory required for data: 2654471680
I0619 14:48:21.915453 17263 layer_factory.hpp:77] Creating layer ReLU82
I0619 14:48:21.915459 17263 net.cpp:459] Creating Layer ReLU82
I0619 14:48:21.915464 17263 net.cpp:886] ReLU82 <- Convolution82
I0619 14:48:21.915470 17263 net.cpp:847] ReLU82 -> Convolution82 (in-place)
I0619 14:48:21.915477 17263 net.cpp:509] Setting up ReLU82
I0619 14:48:21.915482 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.915485 17263 net.cpp:524] Memory required for data: 2656568832
I0619 14:48:21.915489 17263 layer_factory.hpp:77] Creating layer Convolution83
I0619 14:48:21.915501 17263 net.cpp:459] Creating Layer Convolution83
I0619 14:48:21.915505 17263 net.cpp:886] Convolution83 <- Convolution82
I0619 14:48:21.915514 17263 net.cpp:860] Convolution83 -> Convolution83
I0619 14:48:21.917145 17263 net.cpp:509] Setting up Convolution83
I0619 14:48:21.917155 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.917157 17263 net.cpp:524] Memory required for data: 2658665984
I0619 14:48:21.917167 17263 layer_factory.hpp:77] Creating layer BatchNorm83
I0619 14:48:21.917176 17263 net.cpp:459] Creating Layer BatchNorm83
I0619 14:48:21.917181 17263 net.cpp:886] BatchNorm83 <- Convolution83
I0619 14:48:21.917191 17263 net.cpp:847] BatchNorm83 -> Convolution83 (in-place)
I0619 14:48:21.917415 17263 net.cpp:509] Setting up BatchNorm83
I0619 14:48:21.917423 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.917426 17263 net.cpp:524] Memory required for data: 2660763136
I0619 14:48:21.917438 17263 layer_factory.hpp:77] Creating layer Scale83
I0619 14:48:21.917448 17263 net.cpp:459] Creating Layer Scale83
I0619 14:48:21.917451 17263 net.cpp:886] Scale83 <- Convolution83
I0619 14:48:21.917457 17263 net.cpp:847] Scale83 -> Convolution83 (in-place)
I0619 14:48:21.917497 17263 layer_factory.hpp:77] Creating layer Scale83
I0619 14:48:21.917632 17263 net.cpp:509] Setting up Scale83
I0619 14:48:21.917640 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.917644 17263 net.cpp:524] Memory required for data: 2662860288
I0619 14:48:21.917654 17263 layer_factory.hpp:77] Creating layer Eltwise41
I0619 14:48:21.917662 17263 net.cpp:459] Creating Layer Eltwise41
I0619 14:48:21.917667 17263 net.cpp:886] Eltwise41 <- Eltwise40_ReLU81_0_split_1
I0619 14:48:21.917673 17263 net.cpp:886] Eltwise41 <- Convolution83
I0619 14:48:21.917680 17263 net.cpp:860] Eltwise41 -> Eltwise41
I0619 14:48:21.917701 17263 net.cpp:509] Setting up Eltwise41
I0619 14:48:21.917708 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.917711 17263 net.cpp:524] Memory required for data: 2664957440
I0619 14:48:21.917716 17263 layer_factory.hpp:77] Creating layer ReLU83
I0619 14:48:21.917721 17263 net.cpp:459] Creating Layer ReLU83
I0619 14:48:21.917726 17263 net.cpp:886] ReLU83 <- Eltwise41
I0619 14:48:21.917732 17263 net.cpp:847] ReLU83 -> Eltwise41 (in-place)
I0619 14:48:21.917739 17263 net.cpp:509] Setting up ReLU83
I0619 14:48:21.917745 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.917748 17263 net.cpp:524] Memory required for data: 2667054592
I0619 14:48:21.917752 17263 layer_factory.hpp:77] Creating layer Eltwise41_ReLU83_0_split
I0619 14:48:21.917758 17263 net.cpp:459] Creating Layer Eltwise41_ReLU83_0_split
I0619 14:48:21.917762 17263 net.cpp:886] Eltwise41_ReLU83_0_split <- Eltwise41
I0619 14:48:21.917768 17263 net.cpp:860] Eltwise41_ReLU83_0_split -> Eltwise41_ReLU83_0_split_0
I0619 14:48:21.917775 17263 net.cpp:860] Eltwise41_ReLU83_0_split -> Eltwise41_ReLU83_0_split_1
I0619 14:48:21.917815 17263 net.cpp:509] Setting up Eltwise41_ReLU83_0_split
I0619 14:48:21.917822 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.917827 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.917834 17263 net.cpp:524] Memory required for data: 2671248896
I0619 14:48:21.917850 17263 layer_factory.hpp:77] Creating layer Convolution84
I0619 14:48:21.917860 17263 net.cpp:459] Creating Layer Convolution84
I0619 14:48:21.917865 17263 net.cpp:886] Convolution84 <- Eltwise41_ReLU83_0_split_0
I0619 14:48:21.917875 17263 net.cpp:860] Convolution84 -> Convolution84
I0619 14:48:21.919524 17263 net.cpp:509] Setting up Convolution84
I0619 14:48:21.919534 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.919538 17263 net.cpp:524] Memory required for data: 2673346048
I0619 14:48:21.919548 17263 layer_factory.hpp:77] Creating layer BatchNorm84
I0619 14:48:21.919556 17263 net.cpp:459] Creating Layer BatchNorm84
I0619 14:48:21.919560 17263 net.cpp:886] BatchNorm84 <- Convolution84
I0619 14:48:21.919569 17263 net.cpp:847] BatchNorm84 -> Convolution84 (in-place)
I0619 14:48:21.919798 17263 net.cpp:509] Setting up BatchNorm84
I0619 14:48:21.919806 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.919811 17263 net.cpp:524] Memory required for data: 2675443200
I0619 14:48:21.919821 17263 layer_factory.hpp:77] Creating layer Scale84
I0619 14:48:21.919828 17263 net.cpp:459] Creating Layer Scale84
I0619 14:48:21.919832 17263 net.cpp:886] Scale84 <- Convolution84
I0619 14:48:21.919841 17263 net.cpp:847] Scale84 -> Convolution84 (in-place)
I0619 14:48:21.919878 17263 layer_factory.hpp:77] Creating layer Scale84
I0619 14:48:21.920014 17263 net.cpp:509] Setting up Scale84
I0619 14:48:21.920022 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.920025 17263 net.cpp:524] Memory required for data: 2677540352
I0619 14:48:21.920035 17263 layer_factory.hpp:77] Creating layer ReLU84
I0619 14:48:21.920042 17263 net.cpp:459] Creating Layer ReLU84
I0619 14:48:21.920047 17263 net.cpp:886] ReLU84 <- Convolution84
I0619 14:48:21.920054 17263 net.cpp:847] ReLU84 -> Convolution84 (in-place)
I0619 14:48:21.920061 17263 net.cpp:509] Setting up ReLU84
I0619 14:48:21.920066 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.920070 17263 net.cpp:524] Memory required for data: 2679637504
I0619 14:48:21.920074 17263 layer_factory.hpp:77] Creating layer Convolution85
I0619 14:48:21.920085 17263 net.cpp:459] Creating Layer Convolution85
I0619 14:48:21.920089 17263 net.cpp:886] Convolution85 <- Convolution84
I0619 14:48:21.920096 17263 net.cpp:860] Convolution85 -> Convolution85
I0619 14:48:21.921725 17263 net.cpp:509] Setting up Convolution85
I0619 14:48:21.921736 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.921739 17263 net.cpp:524] Memory required for data: 2681734656
I0619 14:48:21.921748 17263 layer_factory.hpp:77] Creating layer BatchNorm85
I0619 14:48:21.921758 17263 net.cpp:459] Creating Layer BatchNorm85
I0619 14:48:21.921762 17263 net.cpp:886] BatchNorm85 <- Convolution85
I0619 14:48:21.921768 17263 net.cpp:847] BatchNorm85 -> Convolution85 (in-place)
I0619 14:48:21.921994 17263 net.cpp:509] Setting up BatchNorm85
I0619 14:48:21.922003 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.922006 17263 net.cpp:524] Memory required for data: 2683831808
I0619 14:48:21.922018 17263 layer_factory.hpp:77] Creating layer Scale85
I0619 14:48:21.922024 17263 net.cpp:459] Creating Layer Scale85
I0619 14:48:21.922029 17263 net.cpp:886] Scale85 <- Convolution85
I0619 14:48:21.922034 17263 net.cpp:847] Scale85 -> Convolution85 (in-place)
I0619 14:48:21.922072 17263 layer_factory.hpp:77] Creating layer Scale85
I0619 14:48:21.922207 17263 net.cpp:509] Setting up Scale85
I0619 14:48:21.922215 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.922219 17263 net.cpp:524] Memory required for data: 2685928960
I0619 14:48:21.922229 17263 layer_factory.hpp:77] Creating layer Eltwise42
I0619 14:48:21.922237 17263 net.cpp:459] Creating Layer Eltwise42
I0619 14:48:21.922243 17263 net.cpp:886] Eltwise42 <- Eltwise41_ReLU83_0_split_1
I0619 14:48:21.922248 17263 net.cpp:886] Eltwise42 <- Convolution85
I0619 14:48:21.922255 17263 net.cpp:860] Eltwise42 -> Eltwise42
I0619 14:48:21.922279 17263 net.cpp:509] Setting up Eltwise42
I0619 14:48:21.922286 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.922302 17263 net.cpp:524] Memory required for data: 2688026112
I0619 14:48:21.922307 17263 layer_factory.hpp:77] Creating layer ReLU85
I0619 14:48:21.922318 17263 net.cpp:459] Creating Layer ReLU85
I0619 14:48:21.922323 17263 net.cpp:886] ReLU85 <- Eltwise42
I0619 14:48:21.922329 17263 net.cpp:847] ReLU85 -> Eltwise42 (in-place)
I0619 14:48:21.922336 17263 net.cpp:509] Setting up ReLU85
I0619 14:48:21.922341 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.922345 17263 net.cpp:524] Memory required for data: 2690123264
I0619 14:48:21.922349 17263 layer_factory.hpp:77] Creating layer Eltwise42_ReLU85_0_split
I0619 14:48:21.922360 17263 net.cpp:459] Creating Layer Eltwise42_ReLU85_0_split
I0619 14:48:21.922365 17263 net.cpp:886] Eltwise42_ReLU85_0_split <- Eltwise42
I0619 14:48:21.922371 17263 net.cpp:860] Eltwise42_ReLU85_0_split -> Eltwise42_ReLU85_0_split_0
I0619 14:48:21.922379 17263 net.cpp:860] Eltwise42_ReLU85_0_split -> Eltwise42_ReLU85_0_split_1
I0619 14:48:21.922423 17263 net.cpp:509] Setting up Eltwise42_ReLU85_0_split
I0619 14:48:21.922430 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.922435 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.922440 17263 net.cpp:524] Memory required for data: 2694317568
I0619 14:48:21.922443 17263 layer_factory.hpp:77] Creating layer Convolution86
I0619 14:48:21.922454 17263 net.cpp:459] Creating Layer Convolution86
I0619 14:48:21.922459 17263 net.cpp:886] Convolution86 <- Eltwise42_ReLU85_0_split_0
I0619 14:48:21.922466 17263 net.cpp:860] Convolution86 -> Convolution86
I0619 14:48:21.924100 17263 net.cpp:509] Setting up Convolution86
I0619 14:48:21.924110 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.924114 17263 net.cpp:524] Memory required for data: 2696414720
I0619 14:48:21.924124 17263 layer_factory.hpp:77] Creating layer BatchNorm86
I0619 14:48:21.924134 17263 net.cpp:459] Creating Layer BatchNorm86
I0619 14:48:21.924139 17263 net.cpp:886] BatchNorm86 <- Convolution86
I0619 14:48:21.924146 17263 net.cpp:847] BatchNorm86 -> Convolution86 (in-place)
I0619 14:48:21.924368 17263 net.cpp:509] Setting up BatchNorm86
I0619 14:48:21.924376 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.924381 17263 net.cpp:524] Memory required for data: 2698511872
I0619 14:48:21.924392 17263 layer_factory.hpp:77] Creating layer Scale86
I0619 14:48:21.924401 17263 net.cpp:459] Creating Layer Scale86
I0619 14:48:21.924406 17263 net.cpp:886] Scale86 <- Convolution86
I0619 14:48:21.924412 17263 net.cpp:847] Scale86 -> Convolution86 (in-place)
I0619 14:48:21.924453 17263 layer_factory.hpp:77] Creating layer Scale86
I0619 14:48:21.924587 17263 net.cpp:509] Setting up Scale86
I0619 14:48:21.924594 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.924598 17263 net.cpp:524] Memory required for data: 2700609024
I0619 14:48:21.924607 17263 layer_factory.hpp:77] Creating layer ReLU86
I0619 14:48:21.924618 17263 net.cpp:459] Creating Layer ReLU86
I0619 14:48:21.924621 17263 net.cpp:886] ReLU86 <- Convolution86
I0619 14:48:21.924628 17263 net.cpp:847] ReLU86 -> Convolution86 (in-place)
I0619 14:48:21.924634 17263 net.cpp:509] Setting up ReLU86
I0619 14:48:21.924639 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.924643 17263 net.cpp:524] Memory required for data: 2702706176
I0619 14:48:21.924648 17263 layer_factory.hpp:77] Creating layer Convolution87
I0619 14:48:21.924659 17263 net.cpp:459] Creating Layer Convolution87
I0619 14:48:21.924664 17263 net.cpp:886] Convolution87 <- Convolution86
I0619 14:48:21.924671 17263 net.cpp:860] Convolution87 -> Convolution87
I0619 14:48:21.927165 17263 net.cpp:509] Setting up Convolution87
I0619 14:48:21.927203 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.927209 17263 net.cpp:524] Memory required for data: 2704803328
I0619 14:48:21.927228 17263 layer_factory.hpp:77] Creating layer BatchNorm87
I0619 14:48:21.927253 17263 net.cpp:459] Creating Layer BatchNorm87
I0619 14:48:21.927263 17263 net.cpp:886] BatchNorm87 <- Convolution87
I0619 14:48:21.927304 17263 net.cpp:847] BatchNorm87 -> Convolution87 (in-place)
I0619 14:48:21.927602 17263 net.cpp:509] Setting up BatchNorm87
I0619 14:48:21.927613 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.927618 17263 net.cpp:524] Memory required for data: 2706900480
I0619 14:48:21.927634 17263 layer_factory.hpp:77] Creating layer Scale87
I0619 14:48:21.927649 17263 net.cpp:459] Creating Layer Scale87
I0619 14:48:21.927654 17263 net.cpp:886] Scale87 <- Convolution87
I0619 14:48:21.927661 17263 net.cpp:847] Scale87 -> Convolution87 (in-place)
I0619 14:48:21.927717 17263 layer_factory.hpp:77] Creating layer Scale87
I0619 14:48:21.927886 17263 net.cpp:509] Setting up Scale87
I0619 14:48:21.927896 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.927901 17263 net.cpp:524] Memory required for data: 2708997632
I0619 14:48:21.927914 17263 layer_factory.hpp:77] Creating layer Eltwise43
I0619 14:48:21.927924 17263 net.cpp:459] Creating Layer Eltwise43
I0619 14:48:21.927932 17263 net.cpp:886] Eltwise43 <- Eltwise42_ReLU85_0_split_1
I0619 14:48:21.927939 17263 net.cpp:886] Eltwise43 <- Convolution87
I0619 14:48:21.927949 17263 net.cpp:860] Eltwise43 -> Eltwise43
I0619 14:48:21.927976 17263 net.cpp:509] Setting up Eltwise43
I0619 14:48:21.927984 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.927989 17263 net.cpp:524] Memory required for data: 2711094784
I0619 14:48:21.927994 17263 layer_factory.hpp:77] Creating layer ReLU87
I0619 14:48:21.928002 17263 net.cpp:459] Creating Layer ReLU87
I0619 14:48:21.928009 17263 net.cpp:886] ReLU87 <- Eltwise43
I0619 14:48:21.928017 17263 net.cpp:847] ReLU87 -> Eltwise43 (in-place)
I0619 14:48:21.928026 17263 net.cpp:509] Setting up ReLU87
I0619 14:48:21.928033 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.928037 17263 net.cpp:524] Memory required for data: 2713191936
I0619 14:48:21.928042 17263 layer_factory.hpp:77] Creating layer Eltwise43_ReLU87_0_split
I0619 14:48:21.928050 17263 net.cpp:459] Creating Layer Eltwise43_ReLU87_0_split
I0619 14:48:21.928055 17263 net.cpp:886] Eltwise43_ReLU87_0_split <- Eltwise43
I0619 14:48:21.928061 17263 net.cpp:860] Eltwise43_ReLU87_0_split -> Eltwise43_ReLU87_0_split_0
I0619 14:48:21.928071 17263 net.cpp:860] Eltwise43_ReLU87_0_split -> Eltwise43_ReLU87_0_split_1
I0619 14:48:21.928120 17263 net.cpp:509] Setting up Eltwise43_ReLU87_0_split
I0619 14:48:21.928129 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.928135 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.928139 17263 net.cpp:524] Memory required for data: 2717386240
I0619 14:48:21.928144 17263 layer_factory.hpp:77] Creating layer Convolution88
I0619 14:48:21.928158 17263 net.cpp:459] Creating Layer Convolution88
I0619 14:48:21.928164 17263 net.cpp:886] Convolution88 <- Eltwise43_ReLU87_0_split_0
I0619 14:48:21.928174 17263 net.cpp:860] Convolution88 -> Convolution88
I0619 14:48:21.930165 17263 net.cpp:509] Setting up Convolution88
I0619 14:48:21.930176 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.930181 17263 net.cpp:524] Memory required for data: 2719483392
I0619 14:48:21.930192 17263 layer_factory.hpp:77] Creating layer BatchNorm88
I0619 14:48:21.930202 17263 net.cpp:459] Creating Layer BatchNorm88
I0619 14:48:21.930207 17263 net.cpp:886] BatchNorm88 <- Convolution88
I0619 14:48:21.930218 17263 net.cpp:847] BatchNorm88 -> Convolution88 (in-place)
I0619 14:48:21.930505 17263 net.cpp:509] Setting up BatchNorm88
I0619 14:48:21.930516 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.930521 17263 net.cpp:524] Memory required for data: 2721580544
I0619 14:48:21.930536 17263 layer_factory.hpp:77] Creating layer Scale88
I0619 14:48:21.930544 17263 net.cpp:459] Creating Layer Scale88
I0619 14:48:21.930551 17263 net.cpp:886] Scale88 <- Convolution88
I0619 14:48:21.930559 17263 net.cpp:847] Scale88 -> Convolution88 (in-place)
I0619 14:48:21.930613 17263 layer_factory.hpp:77] Creating layer Scale88
I0619 14:48:21.930779 17263 net.cpp:509] Setting up Scale88
I0619 14:48:21.930806 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.930811 17263 net.cpp:524] Memory required for data: 2723677696
I0619 14:48:21.930824 17263 layer_factory.hpp:77] Creating layer ReLU88
I0619 14:48:21.930845 17263 net.cpp:459] Creating Layer ReLU88
I0619 14:48:21.930855 17263 net.cpp:886] ReLU88 <- Convolution88
I0619 14:48:21.930869 17263 net.cpp:847] ReLU88 -> Convolution88 (in-place)
I0619 14:48:21.930883 17263 net.cpp:509] Setting up ReLU88
I0619 14:48:21.930893 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.930901 17263 net.cpp:524] Memory required for data: 2725774848
I0619 14:48:21.930907 17263 layer_factory.hpp:77] Creating layer Convolution89
I0619 14:48:21.930928 17263 net.cpp:459] Creating Layer Convolution89
I0619 14:48:21.930937 17263 net.cpp:886] Convolution89 <- Convolution88
I0619 14:48:21.930949 17263 net.cpp:860] Convolution89 -> Convolution89
I0619 14:48:21.934072 17263 net.cpp:509] Setting up Convolution89
I0619 14:48:21.934089 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.934098 17263 net.cpp:524] Memory required for data: 2727872000
I0619 14:48:21.934115 17263 layer_factory.hpp:77] Creating layer BatchNorm89
I0619 14:48:21.934131 17263 net.cpp:459] Creating Layer BatchNorm89
I0619 14:48:21.934140 17263 net.cpp:886] BatchNorm89 <- Convolution89
I0619 14:48:21.934151 17263 net.cpp:847] BatchNorm89 -> Convolution89 (in-place)
I0619 14:48:21.934583 17263 net.cpp:509] Setting up BatchNorm89
I0619 14:48:21.934599 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.934607 17263 net.cpp:524] Memory required for data: 2729969152
I0619 14:48:21.934631 17263 layer_factory.hpp:77] Creating layer Scale89
I0619 14:48:21.934643 17263 net.cpp:459] Creating Layer Scale89
I0619 14:48:21.934653 17263 net.cpp:886] Scale89 <- Convolution89
I0619 14:48:21.934664 17263 net.cpp:847] Scale89 -> Convolution89 (in-place)
I0619 14:48:21.934741 17263 layer_factory.hpp:77] Creating layer Scale89
I0619 14:48:21.934986 17263 net.cpp:509] Setting up Scale89
I0619 14:48:21.935000 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.935008 17263 net.cpp:524] Memory required for data: 2732066304
I0619 14:48:21.935025 17263 layer_factory.hpp:77] Creating layer Eltwise44
I0619 14:48:21.935041 17263 net.cpp:459] Creating Layer Eltwise44
I0619 14:48:21.935051 17263 net.cpp:886] Eltwise44 <- Eltwise43_ReLU87_0_split_1
I0619 14:48:21.935061 17263 net.cpp:886] Eltwise44 <- Convolution89
I0619 14:48:21.935073 17263 net.cpp:860] Eltwise44 -> Eltwise44
I0619 14:48:21.935111 17263 net.cpp:509] Setting up Eltwise44
I0619 14:48:21.935123 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.935129 17263 net.cpp:524] Memory required for data: 2734163456
I0619 14:48:21.935137 17263 layer_factory.hpp:77] Creating layer ReLU89
I0619 14:48:21.935151 17263 net.cpp:459] Creating Layer ReLU89
I0619 14:48:21.935160 17263 net.cpp:886] ReLU89 <- Eltwise44
I0619 14:48:21.935170 17263 net.cpp:847] ReLU89 -> Eltwise44 (in-place)
I0619 14:48:21.935184 17263 net.cpp:509] Setting up ReLU89
I0619 14:48:21.935194 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.935200 17263 net.cpp:524] Memory required for data: 2736260608
I0619 14:48:21.935207 17263 layer_factory.hpp:77] Creating layer Eltwise44_ReLU89_0_split
I0619 14:48:21.935221 17263 net.cpp:459] Creating Layer Eltwise44_ReLU89_0_split
I0619 14:48:21.935230 17263 net.cpp:886] Eltwise44_ReLU89_0_split <- Eltwise44
I0619 14:48:21.935240 17263 net.cpp:860] Eltwise44_ReLU89_0_split -> Eltwise44_ReLU89_0_split_0
I0619 14:48:21.935253 17263 net.cpp:860] Eltwise44_ReLU89_0_split -> Eltwise44_ReLU89_0_split_1
I0619 14:48:21.935328 17263 net.cpp:509] Setting up Eltwise44_ReLU89_0_split
I0619 14:48:21.935341 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.935350 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.935358 17263 net.cpp:524] Memory required for data: 2740454912
I0619 14:48:21.935370 17263 layer_factory.hpp:77] Creating layer Convolution90
I0619 14:48:21.935420 17263 net.cpp:459] Creating Layer Convolution90
I0619 14:48:21.935431 17263 net.cpp:886] Convolution90 <- Eltwise44_ReLU89_0_split_0
I0619 14:48:21.935446 17263 net.cpp:860] Convolution90 -> Convolution90
I0619 14:48:21.938586 17263 net.cpp:509] Setting up Convolution90
I0619 14:48:21.938604 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.938612 17263 net.cpp:524] Memory required for data: 2742552064
I0619 14:48:21.938632 17263 layer_factory.hpp:77] Creating layer BatchNorm90
I0619 14:48:21.938648 17263 net.cpp:459] Creating Layer BatchNorm90
I0619 14:48:21.938657 17263 net.cpp:886] BatchNorm90 <- Convolution90
I0619 14:48:21.938673 17263 net.cpp:847] BatchNorm90 -> Convolution90 (in-place)
I0619 14:48:21.939090 17263 net.cpp:509] Setting up BatchNorm90
I0619 14:48:21.939105 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.939111 17263 net.cpp:524] Memory required for data: 2744649216
I0619 14:48:21.939132 17263 layer_factory.hpp:77] Creating layer Scale90
I0619 14:48:21.939148 17263 net.cpp:459] Creating Layer Scale90
I0619 14:48:21.939157 17263 net.cpp:886] Scale90 <- Convolution90
I0619 14:48:21.939167 17263 net.cpp:847] Scale90 -> Convolution90 (in-place)
I0619 14:48:21.939241 17263 layer_factory.hpp:77] Creating layer Scale90
I0619 14:48:21.939494 17263 net.cpp:509] Setting up Scale90
I0619 14:48:21.939815 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.939827 17263 net.cpp:524] Memory required for data: 2746746368
I0619 14:48:21.939853 17263 layer_factory.hpp:77] Creating layer ReLU90
I0619 14:48:21.939868 17263 net.cpp:459] Creating Layer ReLU90
I0619 14:48:21.939877 17263 net.cpp:886] ReLU90 <- Convolution90
I0619 14:48:21.939889 17263 net.cpp:847] ReLU90 -> Convolution90 (in-place)
I0619 14:48:21.939908 17263 net.cpp:509] Setting up ReLU90
I0619 14:48:21.939918 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.939925 17263 net.cpp:524] Memory required for data: 2748843520
I0619 14:48:21.939932 17263 layer_factory.hpp:77] Creating layer Convolution91
I0619 14:48:21.939950 17263 net.cpp:459] Creating Layer Convolution91
I0619 14:48:21.939959 17263 net.cpp:886] Convolution91 <- Convolution90
I0619 14:48:21.939975 17263 net.cpp:860] Convolution91 -> Convolution91
I0619 14:48:21.943087 17263 net.cpp:509] Setting up Convolution91
I0619 14:48:21.943104 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.943112 17263 net.cpp:524] Memory required for data: 2750940672
I0619 14:48:21.943128 17263 layer_factory.hpp:77] Creating layer BatchNorm91
I0619 14:48:21.943141 17263 net.cpp:459] Creating Layer BatchNorm91
I0619 14:48:21.943150 17263 net.cpp:886] BatchNorm91 <- Convolution91
I0619 14:48:21.943163 17263 net.cpp:847] BatchNorm91 -> Convolution91 (in-place)
I0619 14:48:21.943565 17263 net.cpp:509] Setting up BatchNorm91
I0619 14:48:21.943578 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.943585 17263 net.cpp:524] Memory required for data: 2753037824
I0619 14:48:21.943605 17263 layer_factory.hpp:77] Creating layer Scale91
I0619 14:48:21.943617 17263 net.cpp:459] Creating Layer Scale91
I0619 14:48:21.943625 17263 net.cpp:886] Scale91 <- Convolution91
I0619 14:48:21.943639 17263 net.cpp:847] Scale91 -> Convolution91 (in-place)
I0619 14:48:21.943704 17263 layer_factory.hpp:77] Creating layer Scale91
I0619 14:48:21.943935 17263 net.cpp:509] Setting up Scale91
I0619 14:48:21.943949 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.943955 17263 net.cpp:524] Memory required for data: 2755134976
I0619 14:48:21.943971 17263 layer_factory.hpp:77] Creating layer Eltwise45
I0619 14:48:21.943984 17263 net.cpp:459] Creating Layer Eltwise45
I0619 14:48:21.943992 17263 net.cpp:886] Eltwise45 <- Eltwise44_ReLU89_0_split_1
I0619 14:48:21.944002 17263 net.cpp:886] Eltwise45 <- Convolution91
I0619 14:48:21.944016 17263 net.cpp:860] Eltwise45 -> Eltwise45
I0619 14:48:21.944051 17263 net.cpp:509] Setting up Eltwise45
I0619 14:48:21.944068 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.944099 17263 net.cpp:524] Memory required for data: 2757232128
I0619 14:48:21.944108 17263 layer_factory.hpp:77] Creating layer ReLU91
I0619 14:48:21.944123 17263 net.cpp:459] Creating Layer ReLU91
I0619 14:48:21.944130 17263 net.cpp:886] ReLU91 <- Eltwise45
I0619 14:48:21.944139 17263 net.cpp:847] ReLU91 -> Eltwise45 (in-place)
I0619 14:48:21.944152 17263 net.cpp:509] Setting up ReLU91
I0619 14:48:21.944162 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.944169 17263 net.cpp:524] Memory required for data: 2759329280
I0619 14:48:21.944175 17263 layer_factory.hpp:77] Creating layer Eltwise45_ReLU91_0_split
I0619 14:48:21.944186 17263 net.cpp:459] Creating Layer Eltwise45_ReLU91_0_split
I0619 14:48:21.944193 17263 net.cpp:886] Eltwise45_ReLU91_0_split <- Eltwise45
I0619 14:48:21.944203 17263 net.cpp:860] Eltwise45_ReLU91_0_split -> Eltwise45_ReLU91_0_split_0
I0619 14:48:21.944219 17263 net.cpp:860] Eltwise45_ReLU91_0_split -> Eltwise45_ReLU91_0_split_1
I0619 14:48:21.944290 17263 net.cpp:509] Setting up Eltwise45_ReLU91_0_split
I0619 14:48:21.944303 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.944311 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.944317 17263 net.cpp:524] Memory required for data: 2763523584
I0619 14:48:21.944324 17263 layer_factory.hpp:77] Creating layer Convolution92
I0619 14:48:21.944346 17263 net.cpp:459] Creating Layer Convolution92
I0619 14:48:21.944355 17263 net.cpp:886] Convolution92 <- Eltwise45_ReLU91_0_split_0
I0619 14:48:21.944367 17263 net.cpp:860] Convolution92 -> Convolution92
I0619 14:48:21.947269 17263 net.cpp:509] Setting up Convolution92
I0619 14:48:21.947286 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.947293 17263 net.cpp:524] Memory required for data: 2765620736
I0619 14:48:21.947311 17263 layer_factory.hpp:77] Creating layer BatchNorm92
I0619 14:48:21.947327 17263 net.cpp:459] Creating Layer BatchNorm92
I0619 14:48:21.947335 17263 net.cpp:886] BatchNorm92 <- Convolution92
I0619 14:48:21.947346 17263 net.cpp:847] BatchNorm92 -> Convolution92 (in-place)
I0619 14:48:21.947738 17263 net.cpp:509] Setting up BatchNorm92
I0619 14:48:21.947752 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.947759 17263 net.cpp:524] Memory required for data: 2767717888
I0619 14:48:21.947780 17263 layer_factory.hpp:77] Creating layer Scale92
I0619 14:48:21.947793 17263 net.cpp:459] Creating Layer Scale92
I0619 14:48:21.947800 17263 net.cpp:886] Scale92 <- Convolution92
I0619 14:48:21.947810 17263 net.cpp:847] Scale92 -> Convolution92 (in-place)
I0619 14:48:21.947882 17263 layer_factory.hpp:77] Creating layer Scale92
I0619 14:48:21.948123 17263 net.cpp:509] Setting up Scale92
I0619 14:48:21.948137 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.948143 17263 net.cpp:524] Memory required for data: 2769815040
I0619 14:48:21.948160 17263 layer_factory.hpp:77] Creating layer ReLU92
I0619 14:48:21.948174 17263 net.cpp:459] Creating Layer ReLU92
I0619 14:48:21.948182 17263 net.cpp:886] ReLU92 <- Convolution92
I0619 14:48:21.948192 17263 net.cpp:847] ReLU92 -> Convolution92 (in-place)
I0619 14:48:21.948204 17263 net.cpp:509] Setting up ReLU92
I0619 14:48:21.948213 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.948220 17263 net.cpp:524] Memory required for data: 2771912192
I0619 14:48:21.948226 17263 layer_factory.hpp:77] Creating layer Convolution93
I0619 14:48:21.948246 17263 net.cpp:459] Creating Layer Convolution93
I0619 14:48:21.948253 17263 net.cpp:886] Convolution93 <- Convolution92
I0619 14:48:21.948264 17263 net.cpp:860] Convolution93 -> Convolution93
I0619 14:48:21.951151 17263 net.cpp:509] Setting up Convolution93
I0619 14:48:21.951169 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.951175 17263 net.cpp:524] Memory required for data: 2774009344
I0619 14:48:21.951192 17263 layer_factory.hpp:77] Creating layer BatchNorm93
I0619 14:48:21.951208 17263 net.cpp:459] Creating Layer BatchNorm93
I0619 14:48:21.951221 17263 net.cpp:886] BatchNorm93 <- Convolution93
I0619 14:48:21.951253 17263 net.cpp:847] BatchNorm93 -> Convolution93 (in-place)
I0619 14:48:21.951648 17263 net.cpp:509] Setting up BatchNorm93
I0619 14:48:21.951663 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.951669 17263 net.cpp:524] Memory required for data: 2776106496
I0619 14:48:21.951690 17263 layer_factory.hpp:77] Creating layer Scale93
I0619 14:48:21.951705 17263 net.cpp:459] Creating Layer Scale93
I0619 14:48:21.951714 17263 net.cpp:886] Scale93 <- Convolution93
I0619 14:48:21.951724 17263 net.cpp:847] Scale93 -> Convolution93 (in-place)
I0619 14:48:21.951789 17263 layer_factory.hpp:77] Creating layer Scale93
I0619 14:48:21.952023 17263 net.cpp:509] Setting up Scale93
I0619 14:48:21.952035 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.952041 17263 net.cpp:524] Memory required for data: 2778203648
I0619 14:48:21.952057 17263 layer_factory.hpp:77] Creating layer Eltwise46
I0619 14:48:21.952072 17263 net.cpp:459] Creating Layer Eltwise46
I0619 14:48:21.952081 17263 net.cpp:886] Eltwise46 <- Eltwise45_ReLU91_0_split_1
I0619 14:48:21.952091 17263 net.cpp:886] Eltwise46 <- Convolution93
I0619 14:48:21.952102 17263 net.cpp:860] Eltwise46 -> Eltwise46
I0619 14:48:21.952139 17263 net.cpp:509] Setting up Eltwise46
I0619 14:48:21.952152 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.952157 17263 net.cpp:524] Memory required for data: 2780300800
I0619 14:48:21.952164 17263 layer_factory.hpp:77] Creating layer ReLU93
I0619 14:48:21.952174 17263 net.cpp:459] Creating Layer ReLU93
I0619 14:48:21.952183 17263 net.cpp:886] ReLU93 <- Eltwise46
I0619 14:48:21.952191 17263 net.cpp:847] ReLU93 -> Eltwise46 (in-place)
I0619 14:48:21.952203 17263 net.cpp:509] Setting up ReLU93
I0619 14:48:21.952213 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.952219 17263 net.cpp:524] Memory required for data: 2782397952
I0619 14:48:21.952225 17263 layer_factory.hpp:77] Creating layer Eltwise46_ReLU93_0_split
I0619 14:48:21.952239 17263 net.cpp:459] Creating Layer Eltwise46_ReLU93_0_split
I0619 14:48:21.952245 17263 net.cpp:886] Eltwise46_ReLU93_0_split <- Eltwise46
I0619 14:48:21.952255 17263 net.cpp:860] Eltwise46_ReLU93_0_split -> Eltwise46_ReLU93_0_split_0
I0619 14:48:21.952268 17263 net.cpp:860] Eltwise46_ReLU93_0_split -> Eltwise46_ReLU93_0_split_1
I0619 14:48:21.952337 17263 net.cpp:509] Setting up Eltwise46_ReLU93_0_split
I0619 14:48:21.952348 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.952358 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.952363 17263 net.cpp:524] Memory required for data: 2786592256
I0619 14:48:21.952370 17263 layer_factory.hpp:77] Creating layer Convolution94
I0619 14:48:21.952388 17263 net.cpp:459] Creating Layer Convolution94
I0619 14:48:21.952394 17263 net.cpp:886] Convolution94 <- Eltwise46_ReLU93_0_split_0
I0619 14:48:21.952407 17263 net.cpp:860] Convolution94 -> Convolution94
I0619 14:48:21.956207 17263 net.cpp:509] Setting up Convolution94
I0619 14:48:21.956231 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.956238 17263 net.cpp:524] Memory required for data: 2788689408
I0619 14:48:21.956256 17263 layer_factory.hpp:77] Creating layer BatchNorm94
I0619 14:48:21.956274 17263 net.cpp:459] Creating Layer BatchNorm94
I0619 14:48:21.956282 17263 net.cpp:886] BatchNorm94 <- Convolution94
I0619 14:48:21.956295 17263 net.cpp:847] BatchNorm94 -> Convolution94 (in-place)
I0619 14:48:21.956662 17263 net.cpp:509] Setting up BatchNorm94
I0619 14:48:21.956675 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.956681 17263 net.cpp:524] Memory required for data: 2790786560
I0619 14:48:21.956706 17263 layer_factory.hpp:77] Creating layer Scale94
I0619 14:48:21.956717 17263 net.cpp:459] Creating Layer Scale94
I0619 14:48:21.956725 17263 net.cpp:886] Scale94 <- Convolution94
I0619 14:48:21.956735 17263 net.cpp:847] Scale94 -> Convolution94 (in-place)
I0619 14:48:21.956801 17263 layer_factory.hpp:77] Creating layer Scale94
I0619 14:48:21.957026 17263 net.cpp:509] Setting up Scale94
I0619 14:48:21.957062 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.957068 17263 net.cpp:524] Memory required for data: 2792883712
I0619 14:48:21.957088 17263 layer_factory.hpp:77] Creating layer ReLU94
I0619 14:48:21.957100 17263 net.cpp:459] Creating Layer ReLU94
I0619 14:48:21.957108 17263 net.cpp:886] ReLU94 <- Convolution94
I0619 14:48:21.957124 17263 net.cpp:847] ReLU94 -> Convolution94 (in-place)
I0619 14:48:21.957137 17263 net.cpp:509] Setting up ReLU94
I0619 14:48:21.957145 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.957152 17263 net.cpp:524] Memory required for data: 2794980864
I0619 14:48:21.957159 17263 layer_factory.hpp:77] Creating layer Convolution95
I0619 14:48:21.957173 17263 net.cpp:459] Creating Layer Convolution95
I0619 14:48:21.957180 17263 net.cpp:886] Convolution95 <- Convolution94
I0619 14:48:21.957195 17263 net.cpp:860] Convolution95 -> Convolution95
I0619 14:48:21.959872 17263 net.cpp:509] Setting up Convolution95
I0619 14:48:21.959888 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.959895 17263 net.cpp:524] Memory required for data: 2797078016
I0619 14:48:21.959911 17263 layer_factory.hpp:77] Creating layer BatchNorm95
I0619 14:48:21.959923 17263 net.cpp:459] Creating Layer BatchNorm95
I0619 14:48:21.959930 17263 net.cpp:886] BatchNorm95 <- Convolution95
I0619 14:48:21.959944 17263 net.cpp:847] BatchNorm95 -> Convolution95 (in-place)
I0619 14:48:21.960314 17263 net.cpp:509] Setting up BatchNorm95
I0619 14:48:21.960325 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.960332 17263 net.cpp:524] Memory required for data: 2799175168
I0619 14:48:21.960350 17263 layer_factory.hpp:77] Creating layer Scale95
I0619 14:48:21.960361 17263 net.cpp:459] Creating Layer Scale95
I0619 14:48:21.960368 17263 net.cpp:886] Scale95 <- Convolution95
I0619 14:48:21.960381 17263 net.cpp:847] Scale95 -> Convolution95 (in-place)
I0619 14:48:21.960443 17263 layer_factory.hpp:77] Creating layer Scale95
I0619 14:48:21.960662 17263 net.cpp:509] Setting up Scale95
I0619 14:48:21.960675 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.960680 17263 net.cpp:524] Memory required for data: 2801272320
I0619 14:48:21.960695 17263 layer_factory.hpp:77] Creating layer Eltwise47
I0619 14:48:21.960707 17263 net.cpp:459] Creating Layer Eltwise47
I0619 14:48:21.960716 17263 net.cpp:886] Eltwise47 <- Eltwise46_ReLU93_0_split_1
I0619 14:48:21.960726 17263 net.cpp:886] Eltwise47 <- Convolution95
I0619 14:48:21.960738 17263 net.cpp:860] Eltwise47 -> Eltwise47
I0619 14:48:21.960772 17263 net.cpp:509] Setting up Eltwise47
I0619 14:48:21.960783 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.960788 17263 net.cpp:524] Memory required for data: 2803369472
I0619 14:48:21.960795 17263 layer_factory.hpp:77] Creating layer ReLU95
I0619 14:48:21.960808 17263 net.cpp:459] Creating Layer ReLU95
I0619 14:48:21.960815 17263 net.cpp:886] ReLU95 <- Eltwise47
I0619 14:48:21.960824 17263 net.cpp:847] ReLU95 -> Eltwise47 (in-place)
I0619 14:48:21.960834 17263 net.cpp:509] Setting up ReLU95
I0619 14:48:21.960844 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.960850 17263 net.cpp:524] Memory required for data: 2805466624
I0619 14:48:21.960855 17263 layer_factory.hpp:77] Creating layer Eltwise47_ReLU95_0_split
I0619 14:48:21.960865 17263 net.cpp:459] Creating Layer Eltwise47_ReLU95_0_split
I0619 14:48:21.960871 17263 net.cpp:886] Eltwise47_ReLU95_0_split <- Eltwise47
I0619 14:48:21.960883 17263 net.cpp:860] Eltwise47_ReLU95_0_split -> Eltwise47_ReLU95_0_split_0
I0619 14:48:21.960896 17263 net.cpp:860] Eltwise47_ReLU95_0_split -> Eltwise47_ReLU95_0_split_1
I0619 14:48:21.960959 17263 net.cpp:509] Setting up Eltwise47_ReLU95_0_split
I0619 14:48:21.960970 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.960978 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.960984 17263 net.cpp:524] Memory required for data: 2809660928
I0619 14:48:21.960995 17263 layer_factory.hpp:77] Creating layer Convolution96
I0619 14:48:21.961014 17263 net.cpp:459] Creating Layer Convolution96
I0619 14:48:21.961041 17263 net.cpp:886] Convolution96 <- Eltwise47_ReLU95_0_split_0
I0619 14:48:21.961055 17263 net.cpp:860] Convolution96 -> Convolution96
I0619 14:48:21.967978 17263 net.cpp:509] Setting up Convolution96
I0619 14:48:21.968049 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.968056 17263 net.cpp:524] Memory required for data: 2811758080
I0619 14:48:21.968240 17263 layer_factory.hpp:77] Creating layer BatchNorm96
I0619 14:48:21.968314 17263 net.cpp:459] Creating Layer BatchNorm96
I0619 14:48:21.968433 17263 net.cpp:886] BatchNorm96 <- Convolution96
I0619 14:48:21.968456 17263 net.cpp:847] BatchNorm96 -> Convolution96 (in-place)
I0619 14:48:21.968822 17263 net.cpp:509] Setting up BatchNorm96
I0619 14:48:21.968837 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.968842 17263 net.cpp:524] Memory required for data: 2813855232
I0619 14:48:21.968878 17263 layer_factory.hpp:77] Creating layer Scale96
I0619 14:48:21.968897 17263 net.cpp:459] Creating Layer Scale96
I0619 14:48:21.968905 17263 net.cpp:886] Scale96 <- Convolution96
I0619 14:48:21.968914 17263 net.cpp:847] Scale96 -> Convolution96 (in-place)
I0619 14:48:21.968982 17263 layer_factory.hpp:77] Creating layer Scale96
I0619 14:48:21.969182 17263 net.cpp:509] Setting up Scale96
I0619 14:48:21.969194 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.969199 17263 net.cpp:524] Memory required for data: 2815952384
I0619 14:48:21.969216 17263 layer_factory.hpp:77] Creating layer ReLU96
I0619 14:48:21.969234 17263 net.cpp:459] Creating Layer ReLU96
I0619 14:48:21.969243 17263 net.cpp:886] ReLU96 <- Convolution96
I0619 14:48:21.969251 17263 net.cpp:847] ReLU96 -> Convolution96 (in-place)
I0619 14:48:21.969262 17263 net.cpp:509] Setting up ReLU96
I0619 14:48:21.969270 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.969275 17263 net.cpp:524] Memory required for data: 2818049536
I0619 14:48:21.969281 17263 layer_factory.hpp:77] Creating layer Convolution97
I0619 14:48:21.969323 17263 net.cpp:459] Creating Layer Convolution97
I0619 14:48:21.969331 17263 net.cpp:886] Convolution97 <- Convolution96
I0619 14:48:21.969343 17263 net.cpp:860] Convolution97 -> Convolution97
I0619 14:48:21.972103 17263 net.cpp:509] Setting up Convolution97
I0619 14:48:21.972121 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.972126 17263 net.cpp:524] Memory required for data: 2820146688
I0619 14:48:21.972141 17263 layer_factory.hpp:77] Creating layer BatchNorm97
I0619 14:48:21.972177 17263 net.cpp:459] Creating Layer BatchNorm97
I0619 14:48:21.972185 17263 net.cpp:886] BatchNorm97 <- Convolution97
I0619 14:48:21.972194 17263 net.cpp:847] BatchNorm97 -> Convolution97 (in-place)
I0619 14:48:21.972545 17263 net.cpp:509] Setting up BatchNorm97
I0619 14:48:21.972558 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.972564 17263 net.cpp:524] Memory required for data: 2822243840
I0619 14:48:21.972590 17263 layer_factory.hpp:77] Creating layer Scale97
I0619 14:48:21.972615 17263 net.cpp:459] Creating Layer Scale97
I0619 14:48:21.972622 17263 net.cpp:886] Scale97 <- Convolution97
I0619 14:48:21.972631 17263 net.cpp:847] Scale97 -> Convolution97 (in-place)
I0619 14:48:21.972694 17263 layer_factory.hpp:77] Creating layer Scale97
I0619 14:48:21.972903 17263 net.cpp:509] Setting up Scale97
I0619 14:48:21.972915 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.972921 17263 net.cpp:524] Memory required for data: 2824340992
I0619 14:48:21.972935 17263 layer_factory.hpp:77] Creating layer Eltwise48
I0619 14:48:21.972961 17263 net.cpp:459] Creating Layer Eltwise48
I0619 14:48:21.973032 17263 net.cpp:886] Eltwise48 <- Eltwise47_ReLU95_0_split_1
I0619 14:48:21.973042 17263 net.cpp:886] Eltwise48 <- Convolution97
I0619 14:48:21.973052 17263 net.cpp:860] Eltwise48 -> Eltwise48
I0619 14:48:21.973099 17263 net.cpp:509] Setting up Eltwise48
I0619 14:48:21.973110 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.973121 17263 net.cpp:524] Memory required for data: 2826438144
I0619 14:48:21.973146 17263 layer_factory.hpp:77] Creating layer ReLU97
I0619 14:48:21.973156 17263 net.cpp:459] Creating Layer ReLU97
I0619 14:48:21.973163 17263 net.cpp:886] ReLU97 <- Eltwise48
I0619 14:48:21.973172 17263 net.cpp:847] ReLU97 -> Eltwise48 (in-place)
I0619 14:48:21.973183 17263 net.cpp:509] Setting up ReLU97
I0619 14:48:21.973192 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.973197 17263 net.cpp:524] Memory required for data: 2828535296
I0619 14:48:21.973203 17263 layer_factory.hpp:77] Creating layer Eltwise48_ReLU97_0_split
I0619 14:48:21.973217 17263 net.cpp:459] Creating Layer Eltwise48_ReLU97_0_split
I0619 14:48:21.973222 17263 net.cpp:886] Eltwise48_ReLU97_0_split <- Eltwise48
I0619 14:48:21.973232 17263 net.cpp:860] Eltwise48_ReLU97_0_split -> Eltwise48_ReLU97_0_split_0
I0619 14:48:21.973243 17263 net.cpp:860] Eltwise48_ReLU97_0_split -> Eltwise48_ReLU97_0_split_1
I0619 14:48:21.973311 17263 net.cpp:509] Setting up Eltwise48_ReLU97_0_split
I0619 14:48:21.973323 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.973331 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.973337 17263 net.cpp:524] Memory required for data: 2832729600
I0619 14:48:21.973351 17263 layer_factory.hpp:77] Creating layer Convolution98
I0619 14:48:21.973376 17263 net.cpp:459] Creating Layer Convolution98
I0619 14:48:21.973382 17263 net.cpp:886] Convolution98 <- Eltwise48_ReLU97_0_split_0
I0619 14:48:21.973397 17263 net.cpp:860] Convolution98 -> Convolution98
I0619 14:48:21.975920 17263 net.cpp:509] Setting up Convolution98
I0619 14:48:21.975935 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.975942 17263 net.cpp:524] Memory required for data: 2834826752
I0619 14:48:21.975957 17263 layer_factory.hpp:77] Creating layer BatchNorm98
I0619 14:48:21.975980 17263 net.cpp:459] Creating Layer BatchNorm98
I0619 14:48:21.975989 17263 net.cpp:886] BatchNorm98 <- Convolution98
I0619 14:48:21.976001 17263 net.cpp:847] BatchNorm98 -> Convolution98 (in-place)
I0619 14:48:21.976353 17263 net.cpp:509] Setting up BatchNorm98
I0619 14:48:21.976366 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.976372 17263 net.cpp:524] Memory required for data: 2836923904
I0619 14:48:21.976389 17263 layer_factory.hpp:77] Creating layer Scale98
I0619 14:48:21.976408 17263 net.cpp:459] Creating Layer Scale98
I0619 14:48:21.976415 17263 net.cpp:886] Scale98 <- Convolution98
I0619 14:48:21.976426 17263 net.cpp:847] Scale98 -> Convolution98 (in-place)
I0619 14:48:21.976487 17263 layer_factory.hpp:77] Creating layer Scale98
I0619 14:48:21.976711 17263 net.cpp:509] Setting up Scale98
I0619 14:48:21.976723 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.976729 17263 net.cpp:524] Memory required for data: 2839021056
I0619 14:48:21.976747 17263 layer_factory.hpp:77] Creating layer ReLU98
I0619 14:48:21.976770 17263 net.cpp:459] Creating Layer ReLU98
I0619 14:48:21.976778 17263 net.cpp:886] ReLU98 <- Convolution98
I0619 14:48:21.976793 17263 net.cpp:847] ReLU98 -> Convolution98 (in-place)
I0619 14:48:21.976804 17263 net.cpp:509] Setting up ReLU98
I0619 14:48:21.976812 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.976819 17263 net.cpp:524] Memory required for data: 2841118208
I0619 14:48:21.976824 17263 layer_factory.hpp:77] Creating layer Convolution99
I0619 14:48:21.976856 17263 net.cpp:459] Creating Layer Convolution99
I0619 14:48:21.976863 17263 net.cpp:886] Convolution99 <- Convolution98
I0619 14:48:21.976874 17263 net.cpp:860] Convolution99 -> Convolution99
I0619 14:48:21.979367 17263 net.cpp:509] Setting up Convolution99
I0619 14:48:21.979382 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.979387 17263 net.cpp:524] Memory required for data: 2843215360
I0619 14:48:21.979401 17263 layer_factory.hpp:77] Creating layer BatchNorm99
I0619 14:48:21.979424 17263 net.cpp:459] Creating Layer BatchNorm99
I0619 14:48:21.979432 17263 net.cpp:886] BatchNorm99 <- Convolution99
I0619 14:48:21.979447 17263 net.cpp:847] BatchNorm99 -> Convolution99 (in-place)
I0619 14:48:21.979791 17263 net.cpp:509] Setting up BatchNorm99
I0619 14:48:21.979804 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.979809 17263 net.cpp:524] Memory required for data: 2845312512
I0619 14:48:21.979830 17263 layer_factory.hpp:77] Creating layer Scale99
I0619 14:48:21.979840 17263 net.cpp:459] Creating Layer Scale99
I0619 14:48:21.979846 17263 net.cpp:886] Scale99 <- Convolution99
I0619 14:48:21.979854 17263 net.cpp:847] Scale99 -> Convolution99 (in-place)
I0619 14:48:21.979910 17263 layer_factory.hpp:77] Creating layer Scale99
I0619 14:48:21.980105 17263 net.cpp:509] Setting up Scale99
I0619 14:48:21.980116 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.980121 17263 net.cpp:524] Memory required for data: 2847409664
I0619 14:48:21.980135 17263 layer_factory.hpp:77] Creating layer Eltwise49
I0619 14:48:21.980159 17263 net.cpp:459] Creating Layer Eltwise49
I0619 14:48:21.980167 17263 net.cpp:886] Eltwise49 <- Eltwise48_ReLU97_0_split_1
I0619 14:48:21.980175 17263 net.cpp:886] Eltwise49 <- Convolution99
I0619 14:48:21.980185 17263 net.cpp:860] Eltwise49 -> Eltwise49
I0619 14:48:21.980214 17263 net.cpp:509] Setting up Eltwise49
I0619 14:48:21.980224 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.980229 17263 net.cpp:524] Memory required for data: 2849506816
I0619 14:48:21.980235 17263 layer_factory.hpp:77] Creating layer ReLU99
I0619 14:48:21.980253 17263 net.cpp:459] Creating Layer ReLU99
I0619 14:48:21.980259 17263 net.cpp:886] ReLU99 <- Eltwise49
I0619 14:48:21.980268 17263 net.cpp:847] ReLU99 -> Eltwise49 (in-place)
I0619 14:48:21.980278 17263 net.cpp:509] Setting up ReLU99
I0619 14:48:21.980285 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.980290 17263 net.cpp:524] Memory required for data: 2851603968
I0619 14:48:21.980296 17263 layer_factory.hpp:77] Creating layer Eltwise49_ReLU99_0_split
I0619 14:48:21.980304 17263 net.cpp:459] Creating Layer Eltwise49_ReLU99_0_split
I0619 14:48:21.980309 17263 net.cpp:886] Eltwise49_ReLU99_0_split <- Eltwise49
I0619 14:48:21.980317 17263 net.cpp:860] Eltwise49_ReLU99_0_split -> Eltwise49_ReLU99_0_split_0
I0619 14:48:21.981722 17263 net.cpp:860] Eltwise49_ReLU99_0_split -> Eltwise49_ReLU99_0_split_1
I0619 14:48:21.981794 17263 net.cpp:509] Setting up Eltwise49_ReLU99_0_split
I0619 14:48:21.981809 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.981817 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.981822 17263 net.cpp:524] Memory required for data: 2855798272
I0619 14:48:21.981840 17263 layer_factory.hpp:77] Creating layer Convolution100
I0619 14:48:21.981873 17263 net.cpp:459] Creating Layer Convolution100
I0619 14:48:21.981879 17263 net.cpp:886] Convolution100 <- Eltwise49_ReLU99_0_split_0
I0619 14:48:21.981894 17263 net.cpp:860] Convolution100 -> Convolution100
I0619 14:48:21.984259 17263 net.cpp:509] Setting up Convolution100
I0619 14:48:21.984273 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.984279 17263 net.cpp:524] Memory required for data: 2857895424
I0619 14:48:21.984293 17263 layer_factory.hpp:77] Creating layer BatchNorm100
I0619 14:48:21.984316 17263 net.cpp:459] Creating Layer BatchNorm100
I0619 14:48:21.984323 17263 net.cpp:886] BatchNorm100 <- Convolution100
I0619 14:48:21.984339 17263 net.cpp:847] BatchNorm100 -> Convolution100 (in-place)
I0619 14:48:21.984671 17263 net.cpp:509] Setting up BatchNorm100
I0619 14:48:21.984683 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.984688 17263 net.cpp:524] Memory required for data: 2859992576
I0619 14:48:21.984705 17263 layer_factory.hpp:77] Creating layer Scale100
I0619 14:48:21.984726 17263 net.cpp:459] Creating Layer Scale100
I0619 14:48:21.984733 17263 net.cpp:886] Scale100 <- Convolution100
I0619 14:48:21.984748 17263 net.cpp:847] Scale100 -> Convolution100 (in-place)
I0619 14:48:21.984805 17263 layer_factory.hpp:77] Creating layer Scale100
I0619 14:48:21.985002 17263 net.cpp:509] Setting up Scale100
I0619 14:48:21.985014 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.985038 17263 net.cpp:524] Memory required for data: 2862089728
I0619 14:48:21.985052 17263 layer_factory.hpp:77] Creating layer ReLU100
I0619 14:48:21.985077 17263 net.cpp:459] Creating Layer ReLU100
I0619 14:48:21.985085 17263 net.cpp:886] ReLU100 <- Convolution100
I0619 14:48:21.985096 17263 net.cpp:847] ReLU100 -> Convolution100 (in-place)
I0619 14:48:21.985106 17263 net.cpp:509] Setting up ReLU100
I0619 14:48:21.985115 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.985121 17263 net.cpp:524] Memory required for data: 2864186880
I0619 14:48:21.985131 17263 layer_factory.hpp:77] Creating layer Convolution101
I0619 14:48:21.985170 17263 net.cpp:459] Creating Layer Convolution101
I0619 14:48:21.985177 17263 net.cpp:886] Convolution101 <- Convolution100
I0619 14:48:21.985188 17263 net.cpp:860] Convolution101 -> Convolution101
I0619 14:48:21.988740 17263 net.cpp:509] Setting up Convolution101
I0619 14:48:21.988762 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.988770 17263 net.cpp:524] Memory required for data: 2866284032
I0619 14:48:21.988785 17263 layer_factory.hpp:77] Creating layer BatchNorm101
I0619 14:48:21.988803 17263 net.cpp:459] Creating Layer BatchNorm101
I0619 14:48:21.988811 17263 net.cpp:886] BatchNorm101 <- Convolution101
I0619 14:48:21.988822 17263 net.cpp:847] BatchNorm101 -> Convolution101 (in-place)
I0619 14:48:21.989156 17263 net.cpp:509] Setting up BatchNorm101
I0619 14:48:21.989167 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.989173 17263 net.cpp:524] Memory required for data: 2868381184
I0619 14:48:21.989202 17263 layer_factory.hpp:77] Creating layer Scale101
I0619 14:48:21.989231 17263 net.cpp:459] Creating Layer Scale101
I0619 14:48:21.989238 17263 net.cpp:886] Scale101 <- Convolution101
I0619 14:48:21.989249 17263 net.cpp:847] Scale101 -> Convolution101 (in-place)
I0619 14:48:21.989310 17263 layer_factory.hpp:77] Creating layer Scale101
I0619 14:48:21.989507 17263 net.cpp:509] Setting up Scale101
I0619 14:48:21.989519 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.989524 17263 net.cpp:524] Memory required for data: 2870478336
I0619 14:48:21.989538 17263 layer_factory.hpp:77] Creating layer Eltwise50
I0619 14:48:21.989555 17263 net.cpp:459] Creating Layer Eltwise50
I0619 14:48:21.989563 17263 net.cpp:886] Eltwise50 <- Eltwise49_ReLU99_0_split_1
I0619 14:48:21.989572 17263 net.cpp:886] Eltwise50 <- Convolution101
I0619 14:48:21.989583 17263 net.cpp:860] Eltwise50 -> Eltwise50
I0619 14:48:21.989614 17263 net.cpp:509] Setting up Eltwise50
I0619 14:48:21.989626 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.989631 17263 net.cpp:524] Memory required for data: 2872575488
I0619 14:48:21.989644 17263 layer_factory.hpp:77] Creating layer ReLU101
I0619 14:48:21.989660 17263 net.cpp:459] Creating Layer ReLU101
I0619 14:48:21.989667 17263 net.cpp:886] ReLU101 <- Eltwise50
I0619 14:48:21.989675 17263 net.cpp:847] ReLU101 -> Eltwise50 (in-place)
I0619 14:48:21.989686 17263 net.cpp:509] Setting up ReLU101
I0619 14:48:21.989693 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.989698 17263 net.cpp:524] Memory required for data: 2874672640
I0619 14:48:21.989704 17263 layer_factory.hpp:77] Creating layer Eltwise50_ReLU101_0_split
I0619 14:48:21.991256 17263 net.cpp:459] Creating Layer Eltwise50_ReLU101_0_split
I0619 14:48:21.991268 17263 net.cpp:886] Eltwise50_ReLU101_0_split <- Eltwise50
I0619 14:48:21.991278 17263 net.cpp:860] Eltwise50_ReLU101_0_split -> Eltwise50_ReLU101_0_split_0
I0619 14:48:21.991291 17263 net.cpp:860] Eltwise50_ReLU101_0_split -> Eltwise50_ReLU101_0_split_1
I0619 14:48:21.991353 17263 net.cpp:509] Setting up Eltwise50_ReLU101_0_split
I0619 14:48:21.991363 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.991369 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.991374 17263 net.cpp:524] Memory required for data: 2878866944
I0619 14:48:21.991385 17263 layer_factory.hpp:77] Creating layer Convolution102
I0619 14:48:21.991436 17263 net.cpp:459] Creating Layer Convolution102
I0619 14:48:21.991446 17263 net.cpp:886] Convolution102 <- Eltwise50_ReLU101_0_split_0
I0619 14:48:21.991456 17263 net.cpp:860] Convolution102 -> Convolution102
I0619 14:48:21.993676 17263 net.cpp:509] Setting up Convolution102
I0619 14:48:21.993690 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.993695 17263 net.cpp:524] Memory required for data: 2880964096
I0619 14:48:21.993710 17263 layer_factory.hpp:77] Creating layer BatchNorm102
I0619 14:48:21.993732 17263 net.cpp:459] Creating Layer BatchNorm102
I0619 14:48:21.993739 17263 net.cpp:886] BatchNorm102 <- Convolution102
I0619 14:48:21.993747 17263 net.cpp:847] BatchNorm102 -> Convolution102 (in-place)
I0619 14:48:21.994055 17263 net.cpp:509] Setting up BatchNorm102
I0619 14:48:21.994066 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.994071 17263 net.cpp:524] Memory required for data: 2883061248
I0619 14:48:21.994087 17263 layer_factory.hpp:77] Creating layer Scale102
I0619 14:48:21.994108 17263 net.cpp:459] Creating Layer Scale102
I0619 14:48:21.994115 17263 net.cpp:886] Scale102 <- Convolution102
I0619 14:48:21.994123 17263 net.cpp:847] Scale102 -> Convolution102 (in-place)
I0619 14:48:21.994184 17263 layer_factory.hpp:77] Creating layer Scale102
I0619 14:48:21.994374 17263 net.cpp:509] Setting up Scale102
I0619 14:48:21.994387 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.994393 17263 net.cpp:524] Memory required for data: 2885158400
I0619 14:48:21.994406 17263 layer_factory.hpp:77] Creating layer ReLU102
I0619 14:48:21.994429 17263 net.cpp:459] Creating Layer ReLU102
I0619 14:48:21.994436 17263 net.cpp:886] ReLU102 <- Convolution102
I0619 14:48:21.994444 17263 net.cpp:847] ReLU102 -> Convolution102 (in-place)
I0619 14:48:21.994453 17263 net.cpp:509] Setting up ReLU102
I0619 14:48:21.994462 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.994467 17263 net.cpp:524] Memory required for data: 2887255552
I0619 14:48:21.994472 17263 layer_factory.hpp:77] Creating layer Convolution103
I0619 14:48:21.994494 17263 net.cpp:459] Creating Layer Convolution103
I0619 14:48:21.994500 17263 net.cpp:886] Convolution103 <- Convolution102
I0619 14:48:21.994511 17263 net.cpp:860] Convolution103 -> Convolution103
I0619 14:48:21.996718 17263 net.cpp:509] Setting up Convolution103
I0619 14:48:21.996731 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.996737 17263 net.cpp:524] Memory required for data: 2889352704
I0619 14:48:21.996757 17263 layer_factory.hpp:77] Creating layer BatchNorm103
I0619 14:48:21.996781 17263 net.cpp:459] Creating Layer BatchNorm103
I0619 14:48:21.996788 17263 net.cpp:886] BatchNorm103 <- Convolution103
I0619 14:48:21.996799 17263 net.cpp:847] BatchNorm103 -> Convolution103 (in-place)
I0619 14:48:21.997105 17263 net.cpp:509] Setting up BatchNorm103
I0619 14:48:21.997115 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.997122 17263 net.cpp:524] Memory required for data: 2891449856
I0619 14:48:21.997136 17263 layer_factory.hpp:77] Creating layer Scale103
I0619 14:48:21.997149 17263 net.cpp:459] Creating Layer Scale103
I0619 14:48:21.997156 17263 net.cpp:886] Scale103 <- Convolution103
I0619 14:48:21.997164 17263 net.cpp:847] Scale103 -> Convolution103 (in-place)
I0619 14:48:21.997218 17263 layer_factory.hpp:77] Creating layer Scale103
I0619 14:48:21.997400 17263 net.cpp:509] Setting up Scale103
I0619 14:48:21.997411 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.997416 17263 net.cpp:524] Memory required for data: 2893547008
I0619 14:48:21.997433 17263 layer_factory.hpp:77] Creating layer Eltwise51
I0619 14:48:21.997449 17263 net.cpp:459] Creating Layer Eltwise51
I0619 14:48:21.997457 17263 net.cpp:886] Eltwise51 <- Eltwise50_ReLU101_0_split_1
I0619 14:48:21.997464 17263 net.cpp:886] Eltwise51 <- Convolution103
I0619 14:48:21.997474 17263 net.cpp:860] Eltwise51 -> Eltwise51
I0619 14:48:21.997503 17263 net.cpp:509] Setting up Eltwise51
I0619 14:48:21.997517 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.997539 17263 net.cpp:524] Memory required for data: 2895644160
I0619 14:48:21.997545 17263 layer_factory.hpp:77] Creating layer ReLU103
I0619 14:48:21.997553 17263 net.cpp:459] Creating Layer ReLU103
I0619 14:48:21.997560 17263 net.cpp:886] ReLU103 <- Eltwise51
I0619 14:48:21.997570 17263 net.cpp:847] ReLU103 -> Eltwise51 (in-place)
I0619 14:48:21.997581 17263 net.cpp:509] Setting up ReLU103
I0619 14:48:21.997588 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.997593 17263 net.cpp:524] Memory required for data: 2897741312
I0619 14:48:21.997606 17263 layer_factory.hpp:77] Creating layer Eltwise51_ReLU103_0_split
I0619 14:48:21.997613 17263 net.cpp:459] Creating Layer Eltwise51_ReLU103_0_split
I0619 14:48:21.997618 17263 net.cpp:886] Eltwise51_ReLU103_0_split <- Eltwise51
I0619 14:48:21.997627 17263 net.cpp:860] Eltwise51_ReLU103_0_split -> Eltwise51_ReLU103_0_split_0
I0619 14:48:21.997637 17263 net.cpp:860] Eltwise51_ReLU103_0_split -> Eltwise51_ReLU103_0_split_1
I0619 14:48:21.997695 17263 net.cpp:509] Setting up Eltwise51_ReLU103_0_split
I0619 14:48:21.997705 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.997711 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.997717 17263 net.cpp:524] Memory required for data: 2901935616
I0619 14:48:21.997722 17263 layer_factory.hpp:77] Creating layer Convolution104
I0619 14:48:21.997735 17263 net.cpp:459] Creating Layer Convolution104
I0619 14:48:21.997741 17263 net.cpp:886] Convolution104 <- Eltwise51_ReLU103_0_split_0
I0619 14:48:21.997755 17263 net.cpp:860] Convolution104 -> Convolution104
I0619 14:48:21.999972 17263 net.cpp:509] Setting up Convolution104
I0619 14:48:21.999985 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:21.999991 17263 net.cpp:524] Memory required for data: 2904032768
I0619 14:48:22.000005 17263 layer_factory.hpp:77] Creating layer BatchNorm104
I0619 14:48:22.000015 17263 net.cpp:459] Creating Layer BatchNorm104
I0619 14:48:22.000022 17263 net.cpp:886] BatchNorm104 <- Convolution104
I0619 14:48:22.000032 17263 net.cpp:847] BatchNorm104 -> Convolution104 (in-place)
I0619 14:48:22.000347 17263 net.cpp:509] Setting up BatchNorm104
I0619 14:48:22.000358 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.000365 17263 net.cpp:524] Memory required for data: 2906129920
I0619 14:48:22.000380 17263 layer_factory.hpp:77] Creating layer Scale104
I0619 14:48:22.000401 17263 net.cpp:459] Creating Layer Scale104
I0619 14:48:22.000408 17263 net.cpp:886] Scale104 <- Convolution104
I0619 14:48:22.000416 17263 net.cpp:847] Scale104 -> Convolution104 (in-place)
I0619 14:48:22.000470 17263 layer_factory.hpp:77] Creating layer Scale104
I0619 14:48:22.000649 17263 net.cpp:509] Setting up Scale104
I0619 14:48:22.000659 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.000665 17263 net.cpp:524] Memory required for data: 2908227072
I0619 14:48:22.000685 17263 layer_factory.hpp:77] Creating layer ReLU104
I0619 14:48:22.000700 17263 net.cpp:459] Creating Layer ReLU104
I0619 14:48:22.000707 17263 net.cpp:886] ReLU104 <- Convolution104
I0619 14:48:22.000717 17263 net.cpp:847] ReLU104 -> Convolution104 (in-place)
I0619 14:48:22.000727 17263 net.cpp:509] Setting up ReLU104
I0619 14:48:22.000735 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.000740 17263 net.cpp:524] Memory required for data: 2910324224
I0619 14:48:22.000744 17263 layer_factory.hpp:77] Creating layer Convolution105
I0619 14:48:22.000773 17263 net.cpp:459] Creating Layer Convolution105
I0619 14:48:22.000779 17263 net.cpp:886] Convolution105 <- Convolution104
I0619 14:48:22.000789 17263 net.cpp:860] Convolution105 -> Convolution105
I0619 14:48:22.002984 17263 net.cpp:509] Setting up Convolution105
I0619 14:48:22.002996 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.003001 17263 net.cpp:524] Memory required for data: 2912421376
I0619 14:48:22.003013 17263 layer_factory.hpp:77] Creating layer BatchNorm105
I0619 14:48:22.003028 17263 net.cpp:459] Creating Layer BatchNorm105
I0619 14:48:22.003051 17263 net.cpp:886] BatchNorm105 <- Convolution105
I0619 14:48:22.003059 17263 net.cpp:847] BatchNorm105 -> Convolution105 (in-place)
I0619 14:48:22.003355 17263 net.cpp:509] Setting up BatchNorm105
I0619 14:48:22.003365 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.003371 17263 net.cpp:524] Memory required for data: 2914518528
I0619 14:48:22.003386 17263 layer_factory.hpp:77] Creating layer Scale105
I0619 14:48:22.003413 17263 net.cpp:459] Creating Layer Scale105
I0619 14:48:22.003420 17263 net.cpp:886] Scale105 <- Convolution105
I0619 14:48:22.003427 17263 net.cpp:847] Scale105 -> Convolution105 (in-place)
I0619 14:48:22.003484 17263 layer_factory.hpp:77] Creating layer Scale105
I0619 14:48:22.003659 17263 net.cpp:509] Setting up Scale105
I0619 14:48:22.003669 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.003674 17263 net.cpp:524] Memory required for data: 2916615680
I0619 14:48:22.003686 17263 layer_factory.hpp:77] Creating layer Eltwise52
I0619 14:48:22.003710 17263 net.cpp:459] Creating Layer Eltwise52
I0619 14:48:22.003716 17263 net.cpp:886] Eltwise52 <- Eltwise51_ReLU103_0_split_1
I0619 14:48:22.003729 17263 net.cpp:886] Eltwise52 <- Convolution105
I0619 14:48:22.003737 17263 net.cpp:860] Eltwise52 -> Eltwise52
I0619 14:48:22.003767 17263 net.cpp:509] Setting up Eltwise52
I0619 14:48:22.003775 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.003779 17263 net.cpp:524] Memory required for data: 2918712832
I0619 14:48:22.003785 17263 layer_factory.hpp:77] Creating layer ReLU105
I0619 14:48:22.003795 17263 net.cpp:459] Creating Layer ReLU105
I0619 14:48:22.003800 17263 net.cpp:886] ReLU105 <- Eltwise52
I0619 14:48:22.003808 17263 net.cpp:847] ReLU105 -> Eltwise52 (in-place)
I0619 14:48:22.003816 17263 net.cpp:509] Setting up ReLU105
I0619 14:48:22.003823 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.003828 17263 net.cpp:524] Memory required for data: 2920809984
I0619 14:48:22.003832 17263 layer_factory.hpp:77] Creating layer Eltwise52_ReLU105_0_split
I0619 14:48:22.003841 17263 net.cpp:459] Creating Layer Eltwise52_ReLU105_0_split
I0619 14:48:22.003846 17263 net.cpp:886] Eltwise52_ReLU105_0_split <- Eltwise52
I0619 14:48:22.003854 17263 net.cpp:860] Eltwise52_ReLU105_0_split -> Eltwise52_ReLU105_0_split_0
I0619 14:48:22.003864 17263 net.cpp:860] Eltwise52_ReLU105_0_split -> Eltwise52_ReLU105_0_split_1
I0619 14:48:22.003916 17263 net.cpp:509] Setting up Eltwise52_ReLU105_0_split
I0619 14:48:22.003926 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.003931 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.003937 17263 net.cpp:524] Memory required for data: 2925004288
I0619 14:48:22.003942 17263 layer_factory.hpp:77] Creating layer Convolution106
I0619 14:48:22.003974 17263 net.cpp:459] Creating Layer Convolution106
I0619 14:48:22.003981 17263 net.cpp:886] Convolution106 <- Eltwise52_ReLU105_0_split_0
I0619 14:48:22.003990 17263 net.cpp:860] Convolution106 -> Convolution106
I0619 14:48:22.006083 17263 net.cpp:509] Setting up Convolution106
I0619 14:48:22.006094 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.006099 17263 net.cpp:524] Memory required for data: 2927101440
I0619 14:48:22.006111 17263 layer_factory.hpp:77] Creating layer BatchNorm106
I0619 14:48:22.006129 17263 net.cpp:459] Creating Layer BatchNorm106
I0619 14:48:22.006136 17263 net.cpp:886] BatchNorm106 <- Convolution106
I0619 14:48:22.006146 17263 net.cpp:847] BatchNorm106 -> Convolution106 (in-place)
I0619 14:48:22.006444 17263 net.cpp:509] Setting up BatchNorm106
I0619 14:48:22.006455 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.006460 17263 net.cpp:524] Memory required for data: 2929198592
I0619 14:48:22.006475 17263 layer_factory.hpp:77] Creating layer Scale106
I0619 14:48:22.006502 17263 net.cpp:459] Creating Layer Scale106
I0619 14:48:22.006510 17263 net.cpp:886] Scale106 <- Convolution106
I0619 14:48:22.006520 17263 net.cpp:847] Scale106 -> Convolution106 (in-place)
I0619 14:48:22.006594 17263 layer_factory.hpp:77] Creating layer Scale106
I0619 14:48:22.006769 17263 net.cpp:509] Setting up Scale106
I0619 14:48:22.006779 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.006784 17263 net.cpp:524] Memory required for data: 2931295744
I0619 14:48:22.006803 17263 layer_factory.hpp:77] Creating layer ReLU106
I0619 14:48:22.006817 17263 net.cpp:459] Creating Layer ReLU106
I0619 14:48:22.006824 17263 net.cpp:886] ReLU106 <- Convolution106
I0619 14:48:22.006831 17263 net.cpp:847] ReLU106 -> Convolution106 (in-place)
I0619 14:48:22.006844 17263 net.cpp:509] Setting up ReLU106
I0619 14:48:22.006850 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.006855 17263 net.cpp:524] Memory required for data: 2933392896
I0619 14:48:22.006860 17263 layer_factory.hpp:77] Creating layer Convolution107
I0619 14:48:22.006891 17263 net.cpp:459] Creating Layer Convolution107
I0619 14:48:22.006896 17263 net.cpp:886] Convolution107 <- Convolution106
I0619 14:48:22.006907 17263 net.cpp:860] Convolution107 -> Convolution107
I0619 14:48:22.008994 17263 net.cpp:509] Setting up Convolution107
I0619 14:48:22.009006 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.009011 17263 net.cpp:524] Memory required for data: 2935490048
I0619 14:48:22.009023 17263 layer_factory.hpp:77] Creating layer BatchNorm107
I0619 14:48:22.009044 17263 net.cpp:459] Creating Layer BatchNorm107
I0619 14:48:22.009050 17263 net.cpp:886] BatchNorm107 <- Convolution107
I0619 14:48:22.009062 17263 net.cpp:847] BatchNorm107 -> Convolution107 (in-place)
I0619 14:48:22.009357 17263 net.cpp:509] Setting up BatchNorm107
I0619 14:48:22.009366 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.009371 17263 net.cpp:524] Memory required for data: 2937587200
I0619 14:48:22.009387 17263 layer_factory.hpp:77] Creating layer Scale107
I0619 14:48:22.009408 17263 net.cpp:459] Creating Layer Scale107
I0619 14:48:22.009415 17263 net.cpp:886] Scale107 <- Convolution107
I0619 14:48:22.009424 17263 net.cpp:847] Scale107 -> Convolution107 (in-place)
I0619 14:48:22.009476 17263 layer_factory.hpp:77] Creating layer Scale107
I0619 14:48:22.009649 17263 net.cpp:509] Setting up Scale107
I0619 14:48:22.009659 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.009663 17263 net.cpp:524] Memory required for data: 2939684352
I0619 14:48:22.009675 17263 layer_factory.hpp:77] Creating layer Eltwise53
I0619 14:48:22.009690 17263 net.cpp:459] Creating Layer Eltwise53
I0619 14:48:22.009697 17263 net.cpp:886] Eltwise53 <- Eltwise52_ReLU105_0_split_1
I0619 14:48:22.009704 17263 net.cpp:886] Eltwise53 <- Convolution107
I0619 14:48:22.009714 17263 net.cpp:860] Eltwise53 -> Eltwise53
I0619 14:48:22.009742 17263 net.cpp:509] Setting up Eltwise53
I0619 14:48:22.009750 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.009755 17263 net.cpp:524] Memory required for data: 2941781504
I0619 14:48:22.009769 17263 layer_factory.hpp:77] Creating layer ReLU107
I0619 14:48:22.009779 17263 net.cpp:459] Creating Layer ReLU107
I0619 14:48:22.009784 17263 net.cpp:886] ReLU107 <- Eltwise53
I0619 14:48:22.009793 17263 net.cpp:847] ReLU107 -> Eltwise53 (in-place)
I0619 14:48:22.009800 17263 net.cpp:509] Setting up ReLU107
I0619 14:48:22.009807 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.009812 17263 net.cpp:524] Memory required for data: 2943878656
I0619 14:48:22.009817 17263 layer_factory.hpp:77] Creating layer Eltwise53_ReLU107_0_split
I0619 14:48:22.009824 17263 net.cpp:459] Creating Layer Eltwise53_ReLU107_0_split
I0619 14:48:22.009829 17263 net.cpp:886] Eltwise53_ReLU107_0_split <- Eltwise53
I0619 14:48:22.009836 17263 net.cpp:860] Eltwise53_ReLU107_0_split -> Eltwise53_ReLU107_0_split_0
I0619 14:48:22.009848 17263 net.cpp:860] Eltwise53_ReLU107_0_split -> Eltwise53_ReLU107_0_split_1
I0619 14:48:22.009899 17263 net.cpp:509] Setting up Eltwise53_ReLU107_0_split
I0619 14:48:22.009907 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.009917 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.009938 17263 net.cpp:524] Memory required for data: 2948072960
I0619 14:48:22.009943 17263 layer_factory.hpp:77] Creating layer Convolution108
I0619 14:48:22.009974 17263 net.cpp:459] Creating Layer Convolution108
I0619 14:48:22.009981 17263 net.cpp:886] Convolution108 <- Eltwise53_ReLU107_0_split_0
I0619 14:48:22.009996 17263 net.cpp:860] Convolution108 -> Convolution108
I0619 14:48:22.012866 17263 net.cpp:509] Setting up Convolution108
I0619 14:48:22.012886 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.012892 17263 net.cpp:524] Memory required for data: 2950170112
I0619 14:48:22.012905 17263 layer_factory.hpp:77] Creating layer BatchNorm108
I0619 14:48:22.012929 17263 net.cpp:459] Creating Layer BatchNorm108
I0619 14:48:22.012938 17263 net.cpp:886] BatchNorm108 <- Convolution108
I0619 14:48:22.012948 17263 net.cpp:847] BatchNorm108 -> Convolution108 (in-place)
I0619 14:48:22.013248 17263 net.cpp:509] Setting up BatchNorm108
I0619 14:48:22.013259 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.013264 17263 net.cpp:524] Memory required for data: 2952267264
I0619 14:48:22.013285 17263 layer_factory.hpp:77] Creating layer Scale108
I0619 14:48:22.013303 17263 net.cpp:459] Creating Layer Scale108
I0619 14:48:22.013309 17263 net.cpp:886] Scale108 <- Convolution108
I0619 14:48:22.013317 17263 net.cpp:847] Scale108 -> Convolution108 (in-place)
I0619 14:48:22.013370 17263 layer_factory.hpp:77] Creating layer Scale108
I0619 14:48:22.013547 17263 net.cpp:509] Setting up Scale108
I0619 14:48:22.013558 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.013563 17263 net.cpp:524] Memory required for data: 2954364416
I0619 14:48:22.013576 17263 layer_factory.hpp:77] Creating layer ReLU108
I0619 14:48:22.013592 17263 net.cpp:459] Creating Layer ReLU108
I0619 14:48:22.013599 17263 net.cpp:886] ReLU108 <- Convolution108
I0619 14:48:22.013609 17263 net.cpp:847] ReLU108 -> Convolution108 (in-place)
I0619 14:48:22.013619 17263 net.cpp:509] Setting up ReLU108
I0619 14:48:22.013627 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.013631 17263 net.cpp:524] Memory required for data: 2956461568
I0619 14:48:22.013636 17263 layer_factory.hpp:77] Creating layer Convolution109
I0619 14:48:22.013649 17263 net.cpp:459] Creating Layer Convolution109
I0619 14:48:22.013655 17263 net.cpp:886] Convolution109 <- Convolution108
I0619 14:48:22.013664 17263 net.cpp:860] Convolution109 -> Convolution109
I0619 14:48:22.015735 17263 net.cpp:509] Setting up Convolution109
I0619 14:48:22.015749 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.015754 17263 net.cpp:524] Memory required for data: 2958558720
I0619 14:48:22.015766 17263 layer_factory.hpp:77] Creating layer BatchNorm109
I0619 14:48:22.015777 17263 net.cpp:459] Creating Layer BatchNorm109
I0619 14:48:22.015784 17263 net.cpp:886] BatchNorm109 <- Convolution109
I0619 14:48:22.015790 17263 net.cpp:847] BatchNorm109 -> Convolution109 (in-place)
I0619 14:48:22.016080 17263 net.cpp:509] Setting up BatchNorm109
I0619 14:48:22.016090 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.016095 17263 net.cpp:524] Memory required for data: 2960655872
I0619 14:48:22.016118 17263 layer_factory.hpp:77] Creating layer Scale109
I0619 14:48:22.016126 17263 net.cpp:459] Creating Layer Scale109
I0619 14:48:22.016131 17263 net.cpp:886] Scale109 <- Convolution109
I0619 14:48:22.016139 17263 net.cpp:847] Scale109 -> Convolution109 (in-place)
I0619 14:48:22.016192 17263 layer_factory.hpp:77] Creating layer Scale109
I0619 14:48:22.016355 17263 net.cpp:509] Setting up Scale109
I0619 14:48:22.016366 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.016369 17263 net.cpp:524] Memory required for data: 2962753024
I0619 14:48:22.016381 17263 layer_factory.hpp:77] Creating layer Eltwise54
I0619 14:48:22.016391 17263 net.cpp:459] Creating Layer Eltwise54
I0619 14:48:22.016397 17263 net.cpp:886] Eltwise54 <- Eltwise53_ReLU107_0_split_1
I0619 14:48:22.016408 17263 net.cpp:886] Eltwise54 <- Convolution109
I0619 14:48:22.016415 17263 net.cpp:860] Eltwise54 -> Eltwise54
I0619 14:48:22.016460 17263 net.cpp:509] Setting up Eltwise54
I0619 14:48:22.016470 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.016474 17263 net.cpp:524] Memory required for data: 2964850176
I0619 14:48:22.016479 17263 layer_factory.hpp:77] Creating layer ReLU109
I0619 14:48:22.016490 17263 net.cpp:459] Creating Layer ReLU109
I0619 14:48:22.016495 17263 net.cpp:886] ReLU109 <- Eltwise54
I0619 14:48:22.016510 17263 net.cpp:847] ReLU109 -> Eltwise54 (in-place)
I0619 14:48:22.016520 17263 net.cpp:509] Setting up ReLU109
I0619 14:48:22.016525 17263 net.cpp:516] Top shape: 128 64 8 8 (524288)
I0619 14:48:22.016530 17263 net.cpp:524] Memory required for data: 2966947328
I0619 14:48:22.016535 17263 layer_factory.hpp:77] Creating layer Pooling4
I0619 14:48:22.016543 17263 net.cpp:459] Creating Layer Pooling4
I0619 14:48:22.016548 17263 net.cpp:886] Pooling4 <- Eltwise54
I0619 14:48:22.016556 17263 net.cpp:860] Pooling4 -> Pooling4
I0619 14:48:22.016594 17263 net.cpp:509] Setting up Pooling4
I0619 14:48:22.016602 17263 net.cpp:516] Top shape: 128 64 1 1 (8192)
I0619 14:48:22.016607 17263 net.cpp:524] Memory required for data: 2966980096
I0619 14:48:22.016611 17263 layer_factory.hpp:77] Creating layer InnerProduct1
I0619 14:48:22.016633 17263 net.cpp:459] Creating Layer InnerProduct1
I0619 14:48:22.016638 17263 net.cpp:886] InnerProduct1 <- Pooling4
I0619 14:48:22.016646 17263 net.cpp:860] InnerProduct1 -> InnerProduct1
I0619 14:48:22.017246 17263 net.cpp:509] Setting up InnerProduct1
I0619 14:48:22.017257 17263 net.cpp:516] Top shape: 128 10 (1280)
I0619 14:48:22.017262 17263 net.cpp:524] Memory required for data: 2966985216
I0619 14:48:22.017276 17263 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0619 14:48:22.017283 17263 net.cpp:459] Creating Layer InnerProduct1_InnerProduct1_0_split
I0619 14:48:22.017289 17263 net.cpp:886] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0619 14:48:22.017297 17263 net.cpp:860] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0619 14:48:22.017309 17263 net.cpp:860] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0619 14:48:22.017355 17263 net.cpp:509] Setting up InnerProduct1_InnerProduct1_0_split
I0619 14:48:22.017364 17263 net.cpp:516] Top shape: 128 10 (1280)
I0619 14:48:22.017370 17263 net.cpp:516] Top shape: 128 10 (1280)
I0619 14:48:22.017374 17263 net.cpp:524] Memory required for data: 2966995456
I0619 14:48:22.017379 17263 layer_factory.hpp:77] Creating layer Accuracy
I0619 14:48:22.017387 17263 net.cpp:459] Creating Layer Accuracy
I0619 14:48:22.017393 17263 net.cpp:886] Accuracy <- InnerProduct1_InnerProduct1_0_split_0
I0619 14:48:22.017402 17263 net.cpp:886] Accuracy <- Data2_Data1_1_split_0
I0619 14:48:22.017410 17263 net.cpp:860] Accuracy -> Accuracy
I0619 14:48:22.017436 17263 net.cpp:509] Setting up Accuracy
I0619 14:48:22.017443 17263 net.cpp:516] Top shape: (1)
I0619 14:48:22.017447 17263 net.cpp:524] Memory required for data: 2966995460
I0619 14:48:22.017452 17263 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0619 14:48:22.017465 17263 net.cpp:459] Creating Layer SoftmaxWithLoss1
I0619 14:48:22.017472 17263 net.cpp:886] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_1
I0619 14:48:22.017478 17263 net.cpp:886] SoftmaxWithLoss1 <- Data2_Data1_1_split_1
I0619 14:48:22.017485 17263 net.cpp:860] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0619 14:48:22.017498 17263 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0619 14:48:22.017912 17263 net.cpp:509] Setting up SoftmaxWithLoss1
I0619 14:48:22.017923 17263 net.cpp:516] Top shape: (1)
I0619 14:48:22.017927 17263 net.cpp:519]     with loss weight 1
I0619 14:48:22.017940 17263 net.cpp:524] Memory required for data: 2966995464
I0619 14:48:22.017946 17263 net.cpp:585] SoftmaxWithLoss1 needs backward computation.
I0619 14:48:22.017951 17263 net.cpp:587] Accuracy does not need backward computation.
I0619 14:48:22.017961 17263 net.cpp:585] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0619 14:48:22.017981 17263 net.cpp:585] InnerProduct1 needs backward computation.
I0619 14:48:22.017987 17263 net.cpp:585] Pooling4 needs backward computation.
I0619 14:48:22.017992 17263 net.cpp:585] ReLU109 needs backward computation.
I0619 14:48:22.017998 17263 net.cpp:585] Eltwise54 needs backward computation.
I0619 14:48:22.018003 17263 net.cpp:585] Scale109 needs backward computation.
I0619 14:48:22.018008 17263 net.cpp:585] BatchNorm109 needs backward computation.
I0619 14:48:22.018013 17263 net.cpp:585] Convolution109 needs backward computation.
I0619 14:48:22.018018 17263 net.cpp:585] ReLU108 needs backward computation.
I0619 14:48:22.018023 17263 net.cpp:585] Scale108 needs backward computation.
I0619 14:48:22.018026 17263 net.cpp:585] BatchNorm108 needs backward computation.
I0619 14:48:22.018031 17263 net.cpp:585] Convolution108 needs backward computation.
I0619 14:48:22.018036 17263 net.cpp:585] Eltwise53_ReLU107_0_split needs backward computation.
I0619 14:48:22.018041 17263 net.cpp:585] ReLU107 needs backward computation.
I0619 14:48:22.018046 17263 net.cpp:585] Eltwise53 needs backward computation.
I0619 14:48:22.018051 17263 net.cpp:585] Scale107 needs backward computation.
I0619 14:48:22.018055 17263 net.cpp:585] BatchNorm107 needs backward computation.
I0619 14:48:22.018060 17263 net.cpp:585] Convolution107 needs backward computation.
I0619 14:48:22.018065 17263 net.cpp:585] ReLU106 needs backward computation.
I0619 14:48:22.018069 17263 net.cpp:585] Scale106 needs backward computation.
I0619 14:48:22.018074 17263 net.cpp:585] BatchNorm106 needs backward computation.
I0619 14:48:22.018077 17263 net.cpp:585] Convolution106 needs backward computation.
I0619 14:48:22.018084 17263 net.cpp:585] Eltwise52_ReLU105_0_split needs backward computation.
I0619 14:48:22.018088 17263 net.cpp:585] ReLU105 needs backward computation.
I0619 14:48:22.018092 17263 net.cpp:585] Eltwise52 needs backward computation.
I0619 14:48:22.018097 17263 net.cpp:585] Scale105 needs backward computation.
I0619 14:48:22.018102 17263 net.cpp:585] BatchNorm105 needs backward computation.
I0619 14:48:22.018106 17263 net.cpp:585] Convolution105 needs backward computation.
I0619 14:48:22.018111 17263 net.cpp:585] ReLU104 needs backward computation.
I0619 14:48:22.018115 17263 net.cpp:585] Scale104 needs backward computation.
I0619 14:48:22.018120 17263 net.cpp:585] BatchNorm104 needs backward computation.
I0619 14:48:22.018124 17263 net.cpp:585] Convolution104 needs backward computation.
I0619 14:48:22.018129 17263 net.cpp:585] Eltwise51_ReLU103_0_split needs backward computation.
I0619 14:48:22.018134 17263 net.cpp:585] ReLU103 needs backward computation.
I0619 14:48:22.018138 17263 net.cpp:585] Eltwise51 needs backward computation.
I0619 14:48:22.018143 17263 net.cpp:585] Scale103 needs backward computation.
I0619 14:48:22.018148 17263 net.cpp:585] BatchNorm103 needs backward computation.
I0619 14:48:22.018152 17263 net.cpp:585] Convolution103 needs backward computation.
I0619 14:48:22.018157 17263 net.cpp:585] ReLU102 needs backward computation.
I0619 14:48:22.018162 17263 net.cpp:585] Scale102 needs backward computation.
I0619 14:48:22.018165 17263 net.cpp:585] BatchNorm102 needs backward computation.
I0619 14:48:22.018170 17263 net.cpp:585] Convolution102 needs backward computation.
I0619 14:48:22.018175 17263 net.cpp:585] Eltwise50_ReLU101_0_split needs backward computation.
I0619 14:48:22.018180 17263 net.cpp:585] ReLU101 needs backward computation.
I0619 14:48:22.018184 17263 net.cpp:585] Eltwise50 needs backward computation.
I0619 14:48:22.018190 17263 net.cpp:585] Scale101 needs backward computation.
I0619 14:48:22.018194 17263 net.cpp:585] BatchNorm101 needs backward computation.
I0619 14:48:22.018198 17263 net.cpp:585] Convolution101 needs backward computation.
I0619 14:48:22.018203 17263 net.cpp:585] ReLU100 needs backward computation.
I0619 14:48:22.018208 17263 net.cpp:585] Scale100 needs backward computation.
I0619 14:48:22.018218 17263 net.cpp:585] BatchNorm100 needs backward computation.
I0619 14:48:22.018231 17263 net.cpp:585] Convolution100 needs backward computation.
I0619 14:48:22.018237 17263 net.cpp:585] Eltwise49_ReLU99_0_split needs backward computation.
I0619 14:48:22.018244 17263 net.cpp:585] ReLU99 needs backward computation.
I0619 14:48:22.018247 17263 net.cpp:585] Eltwise49 needs backward computation.
I0619 14:48:22.018254 17263 net.cpp:585] Scale99 needs backward computation.
I0619 14:48:22.018259 17263 net.cpp:585] BatchNorm99 needs backward computation.
I0619 14:48:22.018263 17263 net.cpp:585] Convolution99 needs backward computation.
I0619 14:48:22.018268 17263 net.cpp:585] ReLU98 needs backward computation.
I0619 14:48:22.018272 17263 net.cpp:585] Scale98 needs backward computation.
I0619 14:48:22.018277 17263 net.cpp:585] BatchNorm98 needs backward computation.
I0619 14:48:22.018281 17263 net.cpp:585] Convolution98 needs backward computation.
I0619 14:48:22.018286 17263 net.cpp:585] Eltwise48_ReLU97_0_split needs backward computation.
I0619 14:48:22.018291 17263 net.cpp:585] ReLU97 needs backward computation.
I0619 14:48:22.018296 17263 net.cpp:585] Eltwise48 needs backward computation.
I0619 14:48:22.018301 17263 net.cpp:585] Scale97 needs backward computation.
I0619 14:48:22.018306 17263 net.cpp:585] BatchNorm97 needs backward computation.
I0619 14:48:22.018311 17263 net.cpp:585] Convolution97 needs backward computation.
I0619 14:48:22.018316 17263 net.cpp:585] ReLU96 needs backward computation.
I0619 14:48:22.018321 17263 net.cpp:585] Scale96 needs backward computation.
I0619 14:48:22.018324 17263 net.cpp:585] BatchNorm96 needs backward computation.
I0619 14:48:22.018328 17263 net.cpp:585] Convolution96 needs backward computation.
I0619 14:48:22.018333 17263 net.cpp:585] Eltwise47_ReLU95_0_split needs backward computation.
I0619 14:48:22.018338 17263 net.cpp:585] ReLU95 needs backward computation.
I0619 14:48:22.018343 17263 net.cpp:585] Eltwise47 needs backward computation.
I0619 14:48:22.018348 17263 net.cpp:585] Scale95 needs backward computation.
I0619 14:48:22.018360 17263 net.cpp:585] BatchNorm95 needs backward computation.
I0619 14:48:22.018365 17263 net.cpp:585] Convolution95 needs backward computation.
I0619 14:48:22.018370 17263 net.cpp:585] ReLU94 needs backward computation.
I0619 14:48:22.018376 17263 net.cpp:585] Scale94 needs backward computation.
I0619 14:48:22.018380 17263 net.cpp:585] BatchNorm94 needs backward computation.
I0619 14:48:22.018385 17263 net.cpp:585] Convolution94 needs backward computation.
I0619 14:48:22.018390 17263 net.cpp:585] Eltwise46_ReLU93_0_split needs backward computation.
I0619 14:48:22.018395 17263 net.cpp:585] ReLU93 needs backward computation.
I0619 14:48:22.018399 17263 net.cpp:585] Eltwise46 needs backward computation.
I0619 14:48:22.018405 17263 net.cpp:585] Scale93 needs backward computation.
I0619 14:48:22.018409 17263 net.cpp:585] BatchNorm93 needs backward computation.
I0619 14:48:22.018414 17263 net.cpp:585] Convolution93 needs backward computation.
I0619 14:48:22.018419 17263 net.cpp:585] ReLU92 needs backward computation.
I0619 14:48:22.018424 17263 net.cpp:585] Scale92 needs backward computation.
I0619 14:48:22.018429 17263 net.cpp:585] BatchNorm92 needs backward computation.
I0619 14:48:22.018435 17263 net.cpp:585] Convolution92 needs backward computation.
I0619 14:48:22.018440 17263 net.cpp:585] Eltwise45_ReLU91_0_split needs backward computation.
I0619 14:48:22.018445 17263 net.cpp:585] ReLU91 needs backward computation.
I0619 14:48:22.018448 17263 net.cpp:585] Eltwise45 needs backward computation.
I0619 14:48:22.018455 17263 net.cpp:585] Scale91 needs backward computation.
I0619 14:48:22.018458 17263 net.cpp:585] BatchNorm91 needs backward computation.
I0619 14:48:22.018463 17263 net.cpp:585] Convolution91 needs backward computation.
I0619 14:48:22.018467 17263 net.cpp:585] ReLU90 needs backward computation.
I0619 14:48:22.018473 17263 net.cpp:585] Scale90 needs backward computation.
I0619 14:48:22.018478 17263 net.cpp:585] BatchNorm90 needs backward computation.
I0619 14:48:22.018486 17263 net.cpp:585] Convolution90 needs backward computation.
I0619 14:48:22.018501 17263 net.cpp:585] Eltwise44_ReLU89_0_split needs backward computation.
I0619 14:48:22.018506 17263 net.cpp:585] ReLU89 needs backward computation.
I0619 14:48:22.018510 17263 net.cpp:585] Eltwise44 needs backward computation.
I0619 14:48:22.018523 17263 net.cpp:585] Scale89 needs backward computation.
I0619 14:48:22.018534 17263 net.cpp:585] BatchNorm89 needs backward computation.
I0619 14:48:22.018539 17263 net.cpp:585] Convolution89 needs backward computation.
I0619 14:48:22.018544 17263 net.cpp:585] ReLU88 needs backward computation.
I0619 14:48:22.018549 17263 net.cpp:585] Scale88 needs backward computation.
I0619 14:48:22.018553 17263 net.cpp:585] BatchNorm88 needs backward computation.
I0619 14:48:22.018558 17263 net.cpp:585] Convolution88 needs backward computation.
I0619 14:48:22.018563 17263 net.cpp:585] Eltwise43_ReLU87_0_split needs backward computation.
I0619 14:48:22.018568 17263 net.cpp:585] ReLU87 needs backward computation.
I0619 14:48:22.018578 17263 net.cpp:585] Eltwise43 needs backward computation.
I0619 14:48:22.018587 17263 net.cpp:585] Scale87 needs backward computation.
I0619 14:48:22.018592 17263 net.cpp:585] BatchNorm87 needs backward computation.
I0619 14:48:22.018597 17263 net.cpp:585] Convolution87 needs backward computation.
I0619 14:48:22.018601 17263 net.cpp:585] ReLU86 needs backward computation.
I0619 14:48:22.018606 17263 net.cpp:585] Scale86 needs backward computation.
I0619 14:48:22.018611 17263 net.cpp:585] BatchNorm86 needs backward computation.
I0619 14:48:22.018615 17263 net.cpp:585] Convolution86 needs backward computation.
I0619 14:48:22.018620 17263 net.cpp:585] Eltwise42_ReLU85_0_split needs backward computation.
I0619 14:48:22.018625 17263 net.cpp:585] ReLU85 needs backward computation.
I0619 14:48:22.018630 17263 net.cpp:585] Eltwise42 needs backward computation.
I0619 14:48:22.018635 17263 net.cpp:585] Scale85 needs backward computation.
I0619 14:48:22.018643 17263 net.cpp:585] BatchNorm85 needs backward computation.
I0619 14:48:22.018648 17263 net.cpp:585] Convolution85 needs backward computation.
I0619 14:48:22.018653 17263 net.cpp:585] ReLU84 needs backward computation.
I0619 14:48:22.018657 17263 net.cpp:585] Scale84 needs backward computation.
I0619 14:48:22.018662 17263 net.cpp:585] BatchNorm84 needs backward computation.
I0619 14:48:22.018666 17263 net.cpp:585] Convolution84 needs backward computation.
I0619 14:48:22.018671 17263 net.cpp:585] Eltwise41_ReLU83_0_split needs backward computation.
I0619 14:48:22.018676 17263 net.cpp:585] ReLU83 needs backward computation.
I0619 14:48:22.018682 17263 net.cpp:585] Eltwise41 needs backward computation.
I0619 14:48:22.018687 17263 net.cpp:585] Scale83 needs backward computation.
I0619 14:48:22.018690 17263 net.cpp:585] BatchNorm83 needs backward computation.
I0619 14:48:22.018695 17263 net.cpp:585] Convolution83 needs backward computation.
I0619 14:48:22.018700 17263 net.cpp:585] ReLU82 needs backward computation.
I0619 14:48:22.018712 17263 net.cpp:585] Scale82 needs backward computation.
I0619 14:48:22.018720 17263 net.cpp:585] BatchNorm82 needs backward computation.
I0619 14:48:22.018729 17263 net.cpp:585] Convolution82 needs backward computation.
I0619 14:48:22.018734 17263 net.cpp:585] Eltwise40_ReLU81_0_split needs backward computation.
I0619 14:48:22.018739 17263 net.cpp:585] ReLU81 needs backward computation.
I0619 14:48:22.018743 17263 net.cpp:585] Eltwise40 needs backward computation.
I0619 14:48:22.018749 17263 net.cpp:585] Scale81 needs backward computation.
I0619 14:48:22.018754 17263 net.cpp:585] BatchNorm81 needs backward computation.
I0619 14:48:22.018759 17263 net.cpp:585] Convolution81 needs backward computation.
I0619 14:48:22.018762 17263 net.cpp:585] ReLU80 needs backward computation.
I0619 14:48:22.018771 17263 net.cpp:585] Scale80 needs backward computation.
I0619 14:48:22.018784 17263 net.cpp:585] BatchNorm80 needs backward computation.
I0619 14:48:22.018793 17263 net.cpp:585] Convolution80 needs backward computation.
I0619 14:48:22.018807 17263 net.cpp:585] Eltwise39_ReLU79_0_split needs backward computation.
I0619 14:48:22.018822 17263 net.cpp:585] ReLU79 needs backward computation.
I0619 14:48:22.018827 17263 net.cpp:585] Eltwise39 needs backward computation.
I0619 14:48:22.018833 17263 net.cpp:585] Scale79 needs backward computation.
I0619 14:48:22.018838 17263 net.cpp:585] BatchNorm79 needs backward computation.
I0619 14:48:22.018842 17263 net.cpp:585] Convolution79 needs backward computation.
I0619 14:48:22.018847 17263 net.cpp:585] ReLU78 needs backward computation.
I0619 14:48:22.018857 17263 net.cpp:585] Scale78 needs backward computation.
I0619 14:48:22.018865 17263 net.cpp:585] BatchNorm78 needs backward computation.
I0619 14:48:22.018870 17263 net.cpp:585] Convolution78 needs backward computation.
I0619 14:48:22.018875 17263 net.cpp:585] Eltwise38_ReLU77_0_split needs backward computation.
I0619 14:48:22.018880 17263 net.cpp:585] ReLU77 needs backward computation.
I0619 14:48:22.018884 17263 net.cpp:585] Eltwise38 needs backward computation.
I0619 14:48:22.018894 17263 net.cpp:585] Scale77 needs backward computation.
I0619 14:48:22.018899 17263 net.cpp:585] BatchNorm77 needs backward computation.
I0619 14:48:22.018903 17263 net.cpp:585] Convolution77 needs backward computation.
I0619 14:48:22.018908 17263 net.cpp:585] ReLU76 needs backward computation.
I0619 14:48:22.018913 17263 net.cpp:585] Scale76 needs backward computation.
I0619 14:48:22.018918 17263 net.cpp:585] BatchNorm76 needs backward computation.
I0619 14:48:22.018921 17263 net.cpp:585] Convolution76 needs backward computation.
I0619 14:48:22.018926 17263 net.cpp:585] Eltwise37_ReLU75_0_split needs backward computation.
I0619 14:48:22.018931 17263 net.cpp:585] ReLU75 needs backward computation.
I0619 14:48:22.018939 17263 net.cpp:585] Eltwise37 needs backward computation.
I0619 14:48:22.018949 17263 net.cpp:585] Scale75 needs backward computation.
I0619 14:48:22.018957 17263 net.cpp:585] BatchNorm75 needs backward computation.
I0619 14:48:22.018961 17263 net.cpp:585] Convolution75 needs backward computation.
I0619 14:48:22.018966 17263 net.cpp:585] ReLU74 needs backward computation.
I0619 14:48:22.018981 17263 net.cpp:585] Scale74 needs backward computation.
I0619 14:48:22.018985 17263 net.cpp:585] BatchNorm74 needs backward computation.
I0619 14:48:22.018990 17263 net.cpp:585] Convolution74 needs backward computation.
I0619 14:48:22.018996 17263 net.cpp:585] Concat2 needs backward computation.
I0619 14:48:22.019001 17263 net.cpp:587] Input2 does not need backward computation.
I0619 14:48:22.019006 17263 net.cpp:585] Pooling2 needs backward computation.
I0619 14:48:22.019011 17263 net.cpp:585] Eltwise36_ReLU73_0_split needs backward computation.
I0619 14:48:22.019016 17263 net.cpp:585] ReLU73 needs backward computation.
I0619 14:48:22.019021 17263 net.cpp:585] Eltwise36 needs backward computation.
I0619 14:48:22.019031 17263 net.cpp:585] Scale73 needs backward computation.
I0619 14:48:22.019035 17263 net.cpp:585] BatchNorm73 needs backward computation.
I0619 14:48:22.019040 17263 net.cpp:585] Convolution73 needs backward computation.
I0619 14:48:22.019044 17263 net.cpp:585] ReLU72 needs backward computation.
I0619 14:48:22.019053 17263 net.cpp:585] Scale72 needs backward computation.
I0619 14:48:22.019058 17263 net.cpp:585] BatchNorm72 needs backward computation.
I0619 14:48:22.019067 17263 net.cpp:585] Convolution72 needs backward computation.
I0619 14:48:22.019071 17263 net.cpp:585] Eltwise35_ReLU71_0_split needs backward computation.
I0619 14:48:22.019080 17263 net.cpp:585] ReLU71 needs backward computation.
I0619 14:48:22.019085 17263 net.cpp:585] Eltwise35 needs backward computation.
I0619 14:48:22.019091 17263 net.cpp:585] Scale71 needs backward computation.
I0619 14:48:22.019099 17263 net.cpp:585] BatchNorm71 needs backward computation.
I0619 14:48:22.019104 17263 net.cpp:585] Convolution71 needs backward computation.
I0619 14:48:22.019109 17263 net.cpp:585] ReLU70 needs backward computation.
I0619 14:48:22.019116 17263 net.cpp:585] Scale70 needs backward computation.
I0619 14:48:22.019125 17263 net.cpp:585] BatchNorm70 needs backward computation.
I0619 14:48:22.019142 17263 net.cpp:585] Convolution70 needs backward computation.
I0619 14:48:22.019147 17263 net.cpp:585] Eltwise34_ReLU69_0_split needs backward computation.
I0619 14:48:22.019152 17263 net.cpp:585] ReLU69 needs backward computation.
I0619 14:48:22.019157 17263 net.cpp:585] Eltwise34 needs backward computation.
I0619 14:48:22.019162 17263 net.cpp:585] Scale69 needs backward computation.
I0619 14:48:22.019167 17263 net.cpp:585] BatchNorm69 needs backward computation.
I0619 14:48:22.019171 17263 net.cpp:585] Convolution69 needs backward computation.
I0619 14:48:22.019176 17263 net.cpp:585] ReLU68 needs backward computation.
I0619 14:48:22.019186 17263 net.cpp:585] Scale68 needs backward computation.
I0619 14:48:22.019191 17263 net.cpp:585] BatchNorm68 needs backward computation.
I0619 14:48:22.019199 17263 net.cpp:585] Convolution68 needs backward computation.
I0619 14:48:22.019204 17263 net.cpp:585] Eltwise33_ReLU67_0_split needs backward computation.
I0619 14:48:22.019209 17263 net.cpp:585] ReLU67 needs backward computation.
I0619 14:48:22.019218 17263 net.cpp:585] Eltwise33 needs backward computation.
I0619 14:48:22.019227 17263 net.cpp:585] Scale67 needs backward computation.
I0619 14:48:22.019237 17263 net.cpp:585] BatchNorm67 needs backward computation.
I0619 14:48:22.019242 17263 net.cpp:585] Convolution67 needs backward computation.
I0619 14:48:22.019246 17263 net.cpp:585] ReLU66 needs backward computation.
I0619 14:48:22.019250 17263 net.cpp:585] Scale66 needs backward computation.
I0619 14:48:22.019259 17263 net.cpp:585] BatchNorm66 needs backward computation.
I0619 14:48:22.019264 17263 net.cpp:585] Convolution66 needs backward computation.
I0619 14:48:22.019269 17263 net.cpp:585] Eltwise32_ReLU65_0_split needs backward computation.
I0619 14:48:22.019274 17263 net.cpp:585] ReLU65 needs backward computation.
I0619 14:48:22.019279 17263 net.cpp:585] Eltwise32 needs backward computation.
I0619 14:48:22.019284 17263 net.cpp:585] Scale65 needs backward computation.
I0619 14:48:22.019289 17263 net.cpp:585] BatchNorm65 needs backward computation.
I0619 14:48:22.019292 17263 net.cpp:585] Convolution65 needs backward computation.
I0619 14:48:22.019297 17263 net.cpp:585] ReLU64 needs backward computation.
I0619 14:48:22.019309 17263 net.cpp:585] Scale64 needs backward computation.
I0619 14:48:22.019314 17263 net.cpp:585] BatchNorm64 needs backward computation.
I0619 14:48:22.019318 17263 net.cpp:585] Convolution64 needs backward computation.
I0619 14:48:22.019323 17263 net.cpp:585] Eltwise31_ReLU63_0_split needs backward computation.
I0619 14:48:22.019327 17263 net.cpp:585] ReLU63 needs backward computation.
I0619 14:48:22.019332 17263 net.cpp:585] Eltwise31 needs backward computation.
I0619 14:48:22.019341 17263 net.cpp:585] Scale63 needs backward computation.
I0619 14:48:22.019351 17263 net.cpp:585] BatchNorm63 needs backward computation.
I0619 14:48:22.019356 17263 net.cpp:585] Convolution63 needs backward computation.
I0619 14:48:22.019361 17263 net.cpp:585] ReLU62 needs backward computation.
I0619 14:48:22.019369 17263 net.cpp:585] Scale62 needs backward computation.
I0619 14:48:22.019378 17263 net.cpp:585] BatchNorm62 needs backward computation.
I0619 14:48:22.019382 17263 net.cpp:585] Convolution62 needs backward computation.
I0619 14:48:22.019388 17263 net.cpp:585] Eltwise30_ReLU61_0_split needs backward computation.
I0619 14:48:22.019392 17263 net.cpp:585] ReLU61 needs backward computation.
I0619 14:48:22.019397 17263 net.cpp:585] Eltwise30 needs backward computation.
I0619 14:48:22.019402 17263 net.cpp:585] Scale61 needs backward computation.
I0619 14:48:22.019412 17263 net.cpp:585] BatchNorm61 needs backward computation.
I0619 14:48:22.019417 17263 net.cpp:585] Convolution61 needs backward computation.
I0619 14:48:22.019421 17263 net.cpp:585] ReLU60 needs backward computation.
I0619 14:48:22.019425 17263 net.cpp:585] Scale60 needs backward computation.
I0619 14:48:22.019433 17263 net.cpp:585] BatchNorm60 needs backward computation.
I0619 14:48:22.019446 17263 net.cpp:585] Convolution60 needs backward computation.
I0619 14:48:22.019451 17263 net.cpp:585] Eltwise29_ReLU59_0_split needs backward computation.
I0619 14:48:22.019456 17263 net.cpp:585] ReLU59 needs backward computation.
I0619 14:48:22.019461 17263 net.cpp:585] Eltwise29 needs backward computation.
I0619 14:48:22.019477 17263 net.cpp:585] Scale59 needs backward computation.
I0619 14:48:22.019482 17263 net.cpp:585] BatchNorm59 needs backward computation.
I0619 14:48:22.019487 17263 net.cpp:585] Convolution59 needs backward computation.
I0619 14:48:22.019492 17263 net.cpp:585] ReLU58 needs backward computation.
I0619 14:48:22.019500 17263 net.cpp:585] Scale58 needs backward computation.
I0619 14:48:22.019510 17263 net.cpp:585] BatchNorm58 needs backward computation.
I0619 14:48:22.019515 17263 net.cpp:585] Convolution58 needs backward computation.
I0619 14:48:22.019520 17263 net.cpp:585] Eltwise28_ReLU57_0_split needs backward computation.
I0619 14:48:22.019525 17263 net.cpp:585] ReLU57 needs backward computation.
I0619 14:48:22.019529 17263 net.cpp:585] Eltwise28 needs backward computation.
I0619 14:48:22.019541 17263 net.cpp:585] Scale57 needs backward computation.
I0619 14:48:22.019546 17263 net.cpp:585] BatchNorm57 needs backward computation.
I0619 14:48:22.019551 17263 net.cpp:585] Convolution57 needs backward computation.
I0619 14:48:22.019559 17263 net.cpp:585] ReLU56 needs backward computation.
I0619 14:48:22.019568 17263 net.cpp:585] Scale56 needs backward computation.
I0619 14:48:22.019573 17263 net.cpp:585] BatchNorm56 needs backward computation.
I0619 14:48:22.019582 17263 net.cpp:585] Convolution56 needs backward computation.
I0619 14:48:22.019587 17263 net.cpp:585] Eltwise27_ReLU55_0_split needs backward computation.
I0619 14:48:22.019595 17263 net.cpp:585] ReLU55 needs backward computation.
I0619 14:48:22.019600 17263 net.cpp:585] Eltwise27 needs backward computation.
I0619 14:48:22.019605 17263 net.cpp:585] Scale55 needs backward computation.
I0619 14:48:22.019618 17263 net.cpp:585] BatchNorm55 needs backward computation.
I0619 14:48:22.019623 17263 net.cpp:585] Convolution55 needs backward computation.
I0619 14:48:22.019626 17263 net.cpp:585] ReLU54 needs backward computation.
I0619 14:48:22.019631 17263 net.cpp:585] Scale54 needs backward computation.
I0619 14:48:22.019640 17263 net.cpp:585] BatchNorm54 needs backward computation.
I0619 14:48:22.019644 17263 net.cpp:585] Convolution54 needs backward computation.
I0619 14:48:22.019649 17263 net.cpp:585] Eltwise26_ReLU53_0_split needs backward computation.
I0619 14:48:22.019659 17263 net.cpp:585] ReLU53 needs backward computation.
I0619 14:48:22.019664 17263 net.cpp:585] Eltwise26 needs backward computation.
I0619 14:48:22.019670 17263 net.cpp:585] Scale53 needs backward computation.
I0619 14:48:22.019673 17263 net.cpp:585] BatchNorm53 needs backward computation.
I0619 14:48:22.019677 17263 net.cpp:585] Convolution53 needs backward computation.
I0619 14:48:22.019682 17263 net.cpp:585] ReLU52 needs backward computation.
I0619 14:48:22.019691 17263 net.cpp:585] Scale52 needs backward computation.
I0619 14:48:22.019695 17263 net.cpp:585] BatchNorm52 needs backward computation.
I0619 14:48:22.019704 17263 net.cpp:585] Convolution52 needs backward computation.
I0619 14:48:22.019709 17263 net.cpp:585] Eltwise25_ReLU51_0_split needs backward computation.
I0619 14:48:22.019714 17263 net.cpp:585] ReLU51 needs backward computation.
I0619 14:48:22.019718 17263 net.cpp:585] Eltwise25 needs backward computation.
I0619 14:48:22.019723 17263 net.cpp:585] Scale51 needs backward computation.
I0619 14:48:22.019728 17263 net.cpp:585] BatchNorm51 needs backward computation.
I0619 14:48:22.019732 17263 net.cpp:585] Convolution51 needs backward computation.
I0619 14:48:22.019737 17263 net.cpp:585] ReLU50 needs backward computation.
I0619 14:48:22.019747 17263 net.cpp:585] Scale50 needs backward computation.
I0619 14:48:22.019752 17263 net.cpp:585] BatchNorm50 needs backward computation.
I0619 14:48:22.019758 17263 net.cpp:585] Convolution50 needs backward computation.
I0619 14:48:22.019773 17263 net.cpp:585] Eltwise24_ReLU49_0_split needs backward computation.
I0619 14:48:22.019778 17263 net.cpp:585] ReLU49 needs backward computation.
I0619 14:48:22.019783 17263 net.cpp:585] Eltwise24 needs backward computation.
I0619 14:48:22.019798 17263 net.cpp:585] Scale49 needs backward computation.
I0619 14:48:22.019809 17263 net.cpp:585] BatchNorm49 needs backward computation.
I0619 14:48:22.019814 17263 net.cpp:585] Convolution49 needs backward computation.
I0619 14:48:22.019819 17263 net.cpp:585] ReLU48 needs backward computation.
I0619 14:48:22.019827 17263 net.cpp:585] Scale48 needs backward computation.
I0619 14:48:22.019835 17263 net.cpp:585] BatchNorm48 needs backward computation.
I0619 14:48:22.019845 17263 net.cpp:585] Convolution48 needs backward computation.
I0619 14:48:22.019850 17263 net.cpp:585] Eltwise23_ReLU47_0_split needs backward computation.
I0619 14:48:22.019855 17263 net.cpp:585] ReLU47 needs backward computation.
I0619 14:48:22.019860 17263 net.cpp:585] Eltwise23 needs backward computation.
I0619 14:48:22.019865 17263 net.cpp:585] Scale47 needs backward computation.
I0619 14:48:22.019877 17263 net.cpp:585] BatchNorm47 needs backward computation.
I0619 14:48:22.019882 17263 net.cpp:585] Convolution47 needs backward computation.
I0619 14:48:22.019893 17263 net.cpp:585] ReLU46 needs backward computation.
I0619 14:48:22.019898 17263 net.cpp:585] Scale46 needs backward computation.
I0619 14:48:22.019903 17263 net.cpp:585] BatchNorm46 needs backward computation.
I0619 14:48:22.019907 17263 net.cpp:585] Convolution46 needs backward computation.
I0619 14:48:22.019912 17263 net.cpp:585] Eltwise22_ReLU45_0_split needs backward computation.
I0619 14:48:22.019917 17263 net.cpp:585] ReLU45 needs backward computation.
I0619 14:48:22.019922 17263 net.cpp:585] Eltwise22 needs backward computation.
I0619 14:48:22.019932 17263 net.cpp:585] Scale45 needs backward computation.
I0619 14:48:22.019937 17263 net.cpp:585] BatchNorm45 needs backward computation.
I0619 14:48:22.019942 17263 net.cpp:585] Convolution45 needs backward computation.
I0619 14:48:22.019947 17263 net.cpp:585] ReLU44 needs backward computation.
I0619 14:48:22.019954 17263 net.cpp:585] Scale44 needs backward computation.
I0619 14:48:22.019963 17263 net.cpp:585] BatchNorm44 needs backward computation.
I0619 14:48:22.019973 17263 net.cpp:585] Convolution44 needs backward computation.
I0619 14:48:22.019979 17263 net.cpp:585] Eltwise21_ReLU43_0_split needs backward computation.
I0619 14:48:22.019984 17263 net.cpp:585] ReLU43 needs backward computation.
I0619 14:48:22.019987 17263 net.cpp:585] Eltwise21 needs backward computation.
I0619 14:48:22.019994 17263 net.cpp:585] Scale43 needs backward computation.
I0619 14:48:22.020002 17263 net.cpp:585] BatchNorm43 needs backward computation.
I0619 14:48:22.020007 17263 net.cpp:585] Convolution43 needs backward computation.
I0619 14:48:22.020012 17263 net.cpp:585] ReLU42 needs backward computation.
I0619 14:48:22.020016 17263 net.cpp:585] Scale42 needs backward computation.
I0619 14:48:22.020025 17263 net.cpp:585] BatchNorm42 needs backward computation.
I0619 14:48:22.020030 17263 net.cpp:585] Convolution42 needs backward computation.
I0619 14:48:22.020035 17263 net.cpp:585] Eltwise20_ReLU41_0_split needs backward computation.
I0619 14:48:22.020040 17263 net.cpp:585] ReLU41 needs backward computation.
I0619 14:48:22.020045 17263 net.cpp:585] Eltwise20 needs backward computation.
I0619 14:48:22.020057 17263 net.cpp:585] Scale41 needs backward computation.
I0619 14:48:22.020062 17263 net.cpp:585] BatchNorm41 needs backward computation.
I0619 14:48:22.020066 17263 net.cpp:585] Convolution41 needs backward computation.
I0619 14:48:22.020071 17263 net.cpp:585] ReLU40 needs backward computation.
I0619 14:48:22.020084 17263 net.cpp:585] Scale40 needs backward computation.
I0619 14:48:22.020089 17263 net.cpp:585] BatchNorm40 needs backward computation.
I0619 14:48:22.020097 17263 net.cpp:585] Convolution40 needs backward computation.
I0619 14:48:22.020105 17263 net.cpp:585] Eltwise19_ReLU39_0_split needs backward computation.
I0619 14:48:22.020120 17263 net.cpp:585] ReLU39 needs backward computation.
I0619 14:48:22.020125 17263 net.cpp:585] Eltwise19 needs backward computation.
I0619 14:48:22.020135 17263 net.cpp:585] Scale39 needs backward computation.
I0619 14:48:22.020145 17263 net.cpp:585] BatchNorm39 needs backward computation.
I0619 14:48:22.020150 17263 net.cpp:585] Convolution39 needs backward computation.
I0619 14:48:22.020155 17263 net.cpp:585] ReLU38 needs backward computation.
I0619 14:48:22.020164 17263 net.cpp:585] Scale38 needs backward computation.
I0619 14:48:22.020175 17263 net.cpp:585] BatchNorm38 needs backward computation.
I0619 14:48:22.020180 17263 net.cpp:585] Convolution38 needs backward computation.
I0619 14:48:22.020185 17263 net.cpp:585] Concat1 needs backward computation.
I0619 14:48:22.020192 17263 net.cpp:587] Input1 does not need backward computation.
I0619 14:48:22.020196 17263 net.cpp:585] Pooling1 needs backward computation.
I0619 14:48:22.020206 17263 net.cpp:585] Eltwise18_ReLU37_0_split needs backward computation.
I0619 14:48:22.020212 17263 net.cpp:585] ReLU37 needs backward computation.
I0619 14:48:22.020216 17263 net.cpp:585] Eltwise18 needs backward computation.
I0619 14:48:22.020226 17263 net.cpp:585] Scale37 needs backward computation.
I0619 14:48:22.020231 17263 net.cpp:585] BatchNorm37 needs backward computation.
I0619 14:48:22.020236 17263 net.cpp:585] Convolution37 needs backward computation.
I0619 14:48:22.020241 17263 net.cpp:585] ReLU36 needs backward computation.
I0619 14:48:22.020246 17263 net.cpp:585] Scale36 needs backward computation.
I0619 14:48:22.020251 17263 net.cpp:585] BatchNorm36 needs backward computation.
I0619 14:48:22.020256 17263 net.cpp:585] Convolution36 needs backward computation.
I0619 14:48:22.020262 17263 net.cpp:585] Eltwise17_ReLU35_0_split needs backward computation.
I0619 14:48:22.020265 17263 net.cpp:585] ReLU35 needs backward computation.
I0619 14:48:22.020270 17263 net.cpp:585] Eltwise17 needs backward computation.
I0619 14:48:22.020277 17263 net.cpp:585] Scale35 needs backward computation.
I0619 14:48:22.020280 17263 net.cpp:585] BatchNorm35 needs backward computation.
I0619 14:48:22.020285 17263 net.cpp:585] Convolution35 needs backward computation.
I0619 14:48:22.020289 17263 net.cpp:585] ReLU34 needs backward computation.
I0619 14:48:22.020294 17263 net.cpp:585] Scale34 needs backward computation.
I0619 14:48:22.020303 17263 net.cpp:585] BatchNorm34 needs backward computation.
I0619 14:48:22.020308 17263 net.cpp:585] Convolution34 needs backward computation.
I0619 14:48:22.020313 17263 net.cpp:585] Eltwise16_ReLU33_0_split needs backward computation.
I0619 14:48:22.020318 17263 net.cpp:585] ReLU33 needs backward computation.
I0619 14:48:22.020323 17263 net.cpp:585] Eltwise16 needs backward computation.
I0619 14:48:22.020328 17263 net.cpp:585] Scale33 needs backward computation.
I0619 14:48:22.020333 17263 net.cpp:585] BatchNorm33 needs backward computation.
I0619 14:48:22.020336 17263 net.cpp:585] Convolution33 needs backward computation.
I0619 14:48:22.020341 17263 net.cpp:585] ReLU32 needs backward computation.
I0619 14:48:22.020346 17263 net.cpp:585] Scale32 needs backward computation.
I0619 14:48:22.020350 17263 net.cpp:585] BatchNorm32 needs backward computation.
I0619 14:48:22.020355 17263 net.cpp:585] Convolution32 needs backward computation.
I0619 14:48:22.020360 17263 net.cpp:585] Eltwise15_ReLU31_0_split needs backward computation.
I0619 14:48:22.020365 17263 net.cpp:585] ReLU31 needs backward computation.
I0619 14:48:22.020370 17263 net.cpp:585] Eltwise15 needs backward computation.
I0619 14:48:22.020380 17263 net.cpp:585] Scale31 needs backward computation.
I0619 14:48:22.020387 17263 net.cpp:585] BatchNorm31 needs backward computation.
I0619 14:48:22.020392 17263 net.cpp:585] Convolution31 needs backward computation.
I0619 14:48:22.020397 17263 net.cpp:585] ReLU30 needs backward computation.
I0619 14:48:22.020406 17263 net.cpp:585] Scale30 needs backward computation.
I0619 14:48:22.020421 17263 net.cpp:585] BatchNorm30 needs backward computation.
I0619 14:48:22.020438 17263 net.cpp:585] Convolution30 needs backward computation.
I0619 14:48:22.020444 17263 net.cpp:585] Eltwise14_ReLU29_0_split needs backward computation.
I0619 14:48:22.020449 17263 net.cpp:585] ReLU29 needs backward computation.
I0619 14:48:22.020454 17263 net.cpp:585] Eltwise14 needs backward computation.
I0619 14:48:22.020460 17263 net.cpp:585] Scale29 needs backward computation.
I0619 14:48:22.020464 17263 net.cpp:585] BatchNorm29 needs backward computation.
I0619 14:48:22.020469 17263 net.cpp:585] Convolution29 needs backward computation.
I0619 14:48:22.020474 17263 net.cpp:585] ReLU28 needs backward computation.
I0619 14:48:22.020479 17263 net.cpp:585] Scale28 needs backward computation.
I0619 14:48:22.020483 17263 net.cpp:585] BatchNorm28 needs backward computation.
I0619 14:48:22.020488 17263 net.cpp:585] Convolution28 needs backward computation.
I0619 14:48:22.020493 17263 net.cpp:585] Eltwise13_ReLU27_0_split needs backward computation.
I0619 14:48:22.020498 17263 net.cpp:585] ReLU27 needs backward computation.
I0619 14:48:22.020503 17263 net.cpp:585] Eltwise13 needs backward computation.
I0619 14:48:22.020512 17263 net.cpp:585] Scale27 needs backward computation.
I0619 14:48:22.020525 17263 net.cpp:585] BatchNorm27 needs backward computation.
I0619 14:48:22.020530 17263 net.cpp:585] Convolution27 needs backward computation.
I0619 14:48:22.020535 17263 net.cpp:585] ReLU26 needs backward computation.
I0619 14:48:22.020544 17263 net.cpp:585] Scale26 needs backward computation.
I0619 14:48:22.020548 17263 net.cpp:585] BatchNorm26 needs backward computation.
I0619 14:48:22.020562 17263 net.cpp:585] Convolution26 needs backward computation.
I0619 14:48:22.020568 17263 net.cpp:585] Eltwise12_ReLU25_0_split needs backward computation.
I0619 14:48:22.020573 17263 net.cpp:585] ReLU25 needs backward computation.
I0619 14:48:22.020577 17263 net.cpp:585] Eltwise12 needs backward computation.
I0619 14:48:22.020583 17263 net.cpp:585] Scale25 needs backward computation.
I0619 14:48:22.020587 17263 net.cpp:585] BatchNorm25 needs backward computation.
I0619 14:48:22.020592 17263 net.cpp:585] Convolution25 needs backward computation.
I0619 14:48:22.020597 17263 net.cpp:585] ReLU24 needs backward computation.
I0619 14:48:22.020601 17263 net.cpp:585] Scale24 needs backward computation.
I0619 14:48:22.020606 17263 net.cpp:585] BatchNorm24 needs backward computation.
I0619 14:48:22.020611 17263 net.cpp:585] Convolution24 needs backward computation.
I0619 14:48:22.020618 17263 net.cpp:585] Eltwise11_ReLU23_0_split needs backward computation.
I0619 14:48:22.020623 17263 net.cpp:585] ReLU23 needs backward computation.
I0619 14:48:22.020627 17263 net.cpp:585] Eltwise11 needs backward computation.
I0619 14:48:22.020633 17263 net.cpp:585] Scale23 needs backward computation.
I0619 14:48:22.020642 17263 net.cpp:585] BatchNorm23 needs backward computation.
I0619 14:48:22.020647 17263 net.cpp:585] Convolution23 needs backward computation.
I0619 14:48:22.020651 17263 net.cpp:585] ReLU22 needs backward computation.
I0619 14:48:22.020660 17263 net.cpp:585] Scale22 needs backward computation.
I0619 14:48:22.020670 17263 net.cpp:585] BatchNorm22 needs backward computation.
I0619 14:48:22.020679 17263 net.cpp:585] Convolution22 needs backward computation.
I0619 14:48:22.020684 17263 net.cpp:585] Eltwise10_ReLU21_0_split needs backward computation.
I0619 14:48:22.020689 17263 net.cpp:585] ReLU21 needs backward computation.
I0619 14:48:22.020694 17263 net.cpp:585] Eltwise10 needs backward computation.
I0619 14:48:22.020700 17263 net.cpp:585] Scale21 needs backward computation.
I0619 14:48:22.020709 17263 net.cpp:585] BatchNorm21 needs backward computation.
I0619 14:48:22.020714 17263 net.cpp:585] Convolution21 needs backward computation.
I0619 14:48:22.020719 17263 net.cpp:585] ReLU20 needs backward computation.
I0619 14:48:22.020723 17263 net.cpp:585] Scale20 needs backward computation.
I0619 14:48:22.020730 17263 net.cpp:585] BatchNorm20 needs backward computation.
I0619 14:48:22.020755 17263 net.cpp:585] Convolution20 needs backward computation.
I0619 14:48:22.020761 17263 net.cpp:585] Eltwise9_ReLU19_0_split needs backward computation.
I0619 14:48:22.020767 17263 net.cpp:585] ReLU19 needs backward computation.
I0619 14:48:22.020772 17263 net.cpp:585] Eltwise9 needs backward computation.
I0619 14:48:22.020778 17263 net.cpp:585] Scale19 needs backward computation.
I0619 14:48:22.020782 17263 net.cpp:585] BatchNorm19 needs backward computation.
I0619 14:48:22.020788 17263 net.cpp:585] Convolution19 needs backward computation.
I0619 14:48:22.020793 17263 net.cpp:585] ReLU18 needs backward computation.
I0619 14:48:22.020798 17263 net.cpp:585] Scale18 needs backward computation.
I0619 14:48:22.020803 17263 net.cpp:585] BatchNorm18 needs backward computation.
I0619 14:48:22.020807 17263 net.cpp:585] Convolution18 needs backward computation.
I0619 14:48:22.020812 17263 net.cpp:585] Eltwise8_ReLU17_0_split needs backward computation.
I0619 14:48:22.020818 17263 net.cpp:585] ReLU17 needs backward computation.
I0619 14:48:22.020823 17263 net.cpp:585] Eltwise8 needs backward computation.
I0619 14:48:22.020833 17263 net.cpp:585] Scale17 needs backward computation.
I0619 14:48:22.020838 17263 net.cpp:585] BatchNorm17 needs backward computation.
I0619 14:48:22.020843 17263 net.cpp:585] Convolution17 needs backward computation.
I0619 14:48:22.020848 17263 net.cpp:585] ReLU16 needs backward computation.
I0619 14:48:22.020856 17263 net.cpp:585] Scale16 needs backward computation.
I0619 14:48:22.020865 17263 net.cpp:585] BatchNorm16 needs backward computation.
I0619 14:48:22.020874 17263 net.cpp:585] Convolution16 needs backward computation.
I0619 14:48:22.020879 17263 net.cpp:585] Eltwise7_ReLU15_0_split needs backward computation.
I0619 14:48:22.020885 17263 net.cpp:585] ReLU15 needs backward computation.
I0619 14:48:22.020889 17263 net.cpp:585] Eltwise7 needs backward computation.
I0619 14:48:22.020900 17263 net.cpp:585] Scale15 needs backward computation.
I0619 14:48:22.020910 17263 net.cpp:585] BatchNorm15 needs backward computation.
I0619 14:48:22.020915 17263 net.cpp:585] Convolution15 needs backward computation.
I0619 14:48:22.020920 17263 net.cpp:585] ReLU14 needs backward computation.
I0619 14:48:22.020925 17263 net.cpp:585] Scale14 needs backward computation.
I0619 14:48:22.020934 17263 net.cpp:585] BatchNorm14 needs backward computation.
I0619 14:48:22.020938 17263 net.cpp:585] Convolution14 needs backward computation.
I0619 14:48:22.020944 17263 net.cpp:585] Eltwise6_ReLU13_0_split needs backward computation.
I0619 14:48:22.020949 17263 net.cpp:585] ReLU13 needs backward computation.
I0619 14:48:22.020953 17263 net.cpp:585] Eltwise6 needs backward computation.
I0619 14:48:22.020963 17263 net.cpp:585] Scale13 needs backward computation.
I0619 14:48:22.020972 17263 net.cpp:585] BatchNorm13 needs backward computation.
I0619 14:48:22.020977 17263 net.cpp:585] Convolution13 needs backward computation.
I0619 14:48:22.020982 17263 net.cpp:585] ReLU12 needs backward computation.
I0619 14:48:22.020992 17263 net.cpp:585] Scale12 needs backward computation.
I0619 14:48:22.020995 17263 net.cpp:585] BatchNorm12 needs backward computation.
I0619 14:48:22.021000 17263 net.cpp:585] Convolution12 needs backward computation.
I0619 14:48:22.021005 17263 net.cpp:585] Eltwise5_ReLU11_0_split needs backward computation.
I0619 14:48:22.021010 17263 net.cpp:585] ReLU11 needs backward computation.
I0619 14:48:22.021015 17263 net.cpp:585] Eltwise5 needs backward computation.
I0619 14:48:22.021021 17263 net.cpp:585] Scale11 needs backward computation.
I0619 14:48:22.021025 17263 net.cpp:585] BatchNorm11 needs backward computation.
I0619 14:48:22.021030 17263 net.cpp:585] Convolution11 needs backward computation.
I0619 14:48:22.021035 17263 net.cpp:585] ReLU10 needs backward computation.
I0619 14:48:22.021044 17263 net.cpp:585] Scale10 needs backward computation.
I0619 14:48:22.021059 17263 net.cpp:585] BatchNorm10 needs backward computation.
I0619 14:48:22.021067 17263 net.cpp:585] Convolution10 needs backward computation.
I0619 14:48:22.021081 17263 net.cpp:585] Eltwise4_ReLU9_0_split needs backward computation.
I0619 14:48:22.021087 17263 net.cpp:585] ReLU9 needs backward computation.
I0619 14:48:22.021092 17263 net.cpp:585] Eltwise4 needs backward computation.
I0619 14:48:22.021103 17263 net.cpp:585] Scale9 needs backward computation.
I0619 14:48:22.021113 17263 net.cpp:585] BatchNorm9 needs backward computation.
I0619 14:48:22.021118 17263 net.cpp:585] Convolution9 needs backward computation.
I0619 14:48:22.021123 17263 net.cpp:585] ReLU8 needs backward computation.
I0619 14:48:22.021132 17263 net.cpp:585] Scale8 needs backward computation.
I0619 14:48:22.021142 17263 net.cpp:585] BatchNorm8 needs backward computation.
I0619 14:48:22.021150 17263 net.cpp:585] Convolution8 needs backward computation.
I0619 14:48:22.021155 17263 net.cpp:585] Eltwise3_ReLU7_0_split needs backward computation.
I0619 14:48:22.021162 17263 net.cpp:585] ReLU7 needs backward computation.
I0619 14:48:22.021165 17263 net.cpp:585] Eltwise3 needs backward computation.
I0619 14:48:22.021181 17263 net.cpp:585] Scale7 needs backward computation.
I0619 14:48:22.021190 17263 net.cpp:585] BatchNorm7 needs backward computation.
I0619 14:48:22.021195 17263 net.cpp:585] Convolution7 needs backward computation.
I0619 14:48:22.021200 17263 net.cpp:585] ReLU6 needs backward computation.
I0619 14:48:22.021204 17263 net.cpp:585] Scale6 needs backward computation.
I0619 14:48:22.021209 17263 net.cpp:585] BatchNorm6 needs backward computation.
I0619 14:48:22.021214 17263 net.cpp:585] Convolution6 needs backward computation.
I0619 14:48:22.021219 17263 net.cpp:585] Eltwise2_ReLU5_0_split needs backward computation.
I0619 14:48:22.021224 17263 net.cpp:585] ReLU5 needs backward computation.
I0619 14:48:22.021229 17263 net.cpp:585] Eltwise2 needs backward computation.
I0619 14:48:22.021239 17263 net.cpp:585] Scale5 needs backward computation.
I0619 14:48:22.021244 17263 net.cpp:585] BatchNorm5 needs backward computation.
I0619 14:48:22.021248 17263 net.cpp:585] Convolution5 needs backward computation.
I0619 14:48:22.021252 17263 net.cpp:585] ReLU4 needs backward computation.
I0619 14:48:22.021257 17263 net.cpp:585] Scale4 needs backward computation.
I0619 14:48:22.021262 17263 net.cpp:585] BatchNorm4 needs backward computation.
I0619 14:48:22.021266 17263 net.cpp:585] Convolution4 needs backward computation.
I0619 14:48:22.021271 17263 net.cpp:585] Eltwise1_ReLU3_0_split needs backward computation.
I0619 14:48:22.021281 17263 net.cpp:585] ReLU3 needs backward computation.
I0619 14:48:22.021286 17263 net.cpp:585] Eltwise1 needs backward computation.
I0619 14:48:22.021296 17263 net.cpp:585] Scale3 needs backward computation.
I0619 14:48:22.021306 17263 net.cpp:585] BatchNorm3 needs backward computation.
I0619 14:48:22.021311 17263 net.cpp:585] Convolution3 needs backward computation.
I0619 14:48:22.021316 17263 net.cpp:585] ReLU2 needs backward computation.
I0619 14:48:22.021324 17263 net.cpp:585] Scale2 needs backward computation.
I0619 14:48:22.021335 17263 net.cpp:585] BatchNorm2 needs backward computation.
I0619 14:48:22.021344 17263 net.cpp:585] Convolution2 needs backward computation.
I0619 14:48:22.021350 17263 net.cpp:585] Convolution1_ReLU1_0_split needs backward computation.
I0619 14:48:22.021356 17263 net.cpp:585] ReLU1 needs backward computation.
I0619 14:48:22.021360 17263 net.cpp:585] Scale1 needs backward computation.
I0619 14:48:22.021369 17263 net.cpp:585] BatchNorm1 needs backward computation.
I0619 14:48:22.021374 17263 net.cpp:585] Convolution1 needs backward computation.
I0619 14:48:22.021380 17263 net.cpp:587] Data2_Data1_1_split does not need backward computation.
I0619 14:48:22.021386 17263 net.cpp:587] Data1 does not need backward computation.
I0619 14:48:22.021390 17263 net.cpp:629] This network produces output Accuracy
I0619 14:48:22.021397 17263 net.cpp:629] This network produces output SoftmaxWithLoss1
prob: 0.830189
prob: 0.660377
I0619 14:48:22.021818 17263 net.cpp:643] Network initialization done.
I0619 14:48:22.025764 17263 solver.cpp:295] Solver scaffolding done.
I0619 14:48:22.065246 17263 caffe.cpp:219] Starting Optimization
I0619 14:48:22.065263 17263 solver.cpp:112] Solving 
I0619 14:48:22.065268 17263 solver.cpp:113] Learning Rate Policy: multistep
I0619 14:48:22.080667 17263 solver.cpp:174] Iteration 0, Testing net (#0)
I0619 14:49:26.518940 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.100078
I0619 14:49:26.519182 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0619 14:49:28.555901 17263 solver.cpp:57] Iteration 0, loss = 4.35966
I0619 14:49:28.555956 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 4.35966 (* 1 = 4.35966 loss)
I0619 14:49:28.555972 17263 sgd_solver.cpp:43] Iteration 0, lr = 0.1
I0619 15:02:48.554659 17263 solver.cpp:174] Iteration 400, Testing net (#0)
I0619 15:03:53.852782 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.176484
I0619 15:03:53.853003 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 2.2494 (* 1 = 2.2494 loss)
I0619 15:03:55.735232 17263 solver.cpp:57] Iteration 400, loss = 2.11986
I0619 15:03:55.735276 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 2.11986 (* 1 = 2.11986 loss)
I0619 15:03:55.735287 17263 sgd_solver.cpp:43] Iteration 400, lr = 0.1
I0619 15:17:24.071749 17263 solver.cpp:174] Iteration 800, Testing net (#0)
I0619 15:18:29.351959 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.138203
I0619 15:18:29.352167 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 2.30193 (* 1 = 2.30193 loss)
I0619 15:18:31.340620 17263 solver.cpp:57] Iteration 800, loss = 1.82391
I0619 15:18:31.340661 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 1.82391 (* 1 = 1.82391 loss)
I0619 15:18:31.340672 17263 sgd_solver.cpp:43] Iteration 800, lr = 0.1
I0619 15:32:01.346916 17263 solver.cpp:174] Iteration 1200, Testing net (#0)
I0619 15:33:06.553807 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.271172
I0619 15:33:06.553936 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 1.97929 (* 1 = 1.97929 loss)
I0619 15:33:08.496485 17263 solver.cpp:57] Iteration 1200, loss = 1.527
I0619 15:33:08.496521 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 1.527 (* 1 = 1.527 loss)
I0619 15:33:08.496532 17263 sgd_solver.cpp:43] Iteration 1200, lr = 0.1
I0619 15:46:32.004935 17263 solver.cpp:174] Iteration 1600, Testing net (#0)
I0619 15:47:37.296123 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.281172
I0619 15:47:37.296257 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 2.06898 (* 1 = 2.06898 loss)
I0619 15:47:39.328888 17263 solver.cpp:57] Iteration 1600, loss = 1.54838
I0619 15:47:39.328939 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 1.54838 (* 1 = 1.54838 loss)
I0619 15:47:39.328950 17263 sgd_solver.cpp:43] Iteration 1600, lr = 0.1
I0619 16:01:05.057299 17263 solver.cpp:174] Iteration 2000, Testing net (#0)
I0619 16:02:10.317142 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.315703
I0619 16:02:10.317374 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 1.87856 (* 1 = 1.87856 loss)
I0619 16:02:12.615011 17263 solver.cpp:57] Iteration 2000, loss = 1.25418
I0619 16:02:12.615049 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 1.25418 (* 1 = 1.25418 loss)
I0619 16:02:12.615061 17263 sgd_solver.cpp:43] Iteration 2000, lr = 0.1
I0619 16:15:36.733238 17263 solver.cpp:174] Iteration 2400, Testing net (#0)
I0619 16:16:42.044358 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.425547
I0619 16:16:42.044497 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 1.71388 (* 1 = 1.71388 loss)
I0619 16:16:44.097256 17263 solver.cpp:57] Iteration 2400, loss = 0.989399
I0619 16:16:44.097306 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.989399 (* 1 = 0.989399 loss)
I0619 16:16:44.097318 17263 sgd_solver.cpp:43] Iteration 2400, lr = 0.1
I0619 16:30:09.791862 17263 solver.cpp:174] Iteration 2800, Testing net (#0)
I0619 16:31:15.137003 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.367109
I0619 16:31:15.137246 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 1.82 (* 1 = 1.82 loss)
I0619 16:31:16.986201 17263 solver.cpp:57] Iteration 2800, loss = 0.980368
I0619 16:31:16.986243 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.980368 (* 1 = 0.980368 loss)
I0619 16:31:16.986253 17263 sgd_solver.cpp:43] Iteration 2800, lr = 0.1
I0619 16:44:44.358084 17263 solver.cpp:174] Iteration 3200, Testing net (#0)
I0619 16:45:49.664899 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.411641
I0619 16:45:49.665052 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 1.78149 (* 1 = 1.78149 loss)
I0619 16:45:51.622500 17263 solver.cpp:57] Iteration 3200, loss = 0.875726
I0619 16:45:51.622542 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.875726 (* 1 = 0.875726 loss)
I0619 16:45:51.622553 17263 sgd_solver.cpp:43] Iteration 3200, lr = 0.1
I0619 16:59:21.903506 17263 solver.cpp:174] Iteration 3600, Testing net (#0)
I0619 17:00:27.209736 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.576719
I0619 17:00:27.209870 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 1.23764 (* 1 = 1.23764 loss)
I0619 17:00:29.079620 17263 solver.cpp:57] Iteration 3600, loss = 0.862566
I0619 17:00:29.079664 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.862566 (* 1 = 0.862566 loss)
I0619 17:00:29.079679 17263 sgd_solver.cpp:43] Iteration 3600, lr = 0.1
I0619 17:13:51.966387 17263 solver.cpp:174] Iteration 4000, Testing net (#0)
I0619 17:14:57.231389 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.259609
I0619 17:14:57.231529 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 3.04052 (* 1 = 3.04052 loss)
I0619 17:14:59.383949 17263 solver.cpp:57] Iteration 4000, loss = 0.648599
I0619 17:14:59.383987 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.648599 (* 1 = 0.648599 loss)
I0619 17:14:59.383997 17263 sgd_solver.cpp:43] Iteration 4000, lr = 0.1
I0619 17:28:26.348044 17263 solver.cpp:174] Iteration 4400, Testing net (#0)
I0619 17:29:31.648560 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.485234
I0619 17:29:31.648684 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 1.5977 (* 1 = 1.5977 loss)
I0619 17:29:33.520536 17263 solver.cpp:57] Iteration 4400, loss = 0.855674
I0619 17:29:33.520575 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.855674 (* 1 = 0.855674 loss)
I0619 17:29:33.520584 17263 sgd_solver.cpp:43] Iteration 4400, lr = 0.1
I0619 17:43:01.587440 17263 solver.cpp:174] Iteration 4800, Testing net (#0)
I0619 17:44:06.882927 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.359141
I0619 17:44:06.883076 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 2.05642 (* 1 = 2.05642 loss)
I0619 17:44:08.974000 17263 solver.cpp:57] Iteration 4800, loss = 0.818888
I0619 17:44:08.974035 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.818888 (* 1 = 0.818888 loss)
I0619 17:44:08.974045 17263 sgd_solver.cpp:43] Iteration 4800, lr = 0.1
I0619 17:57:38.062934 17263 solver.cpp:174] Iteration 5200, Testing net (#0)
I0619 17:58:43.378125 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.237031
I0619 17:58:43.378307 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 3.36045 (* 1 = 3.36045 loss)
I0619 17:58:45.360383 17263 solver.cpp:57] Iteration 5200, loss = 0.770353
I0619 17:58:45.360424 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.770353 (* 1 = 0.770353 loss)
I0619 17:58:45.360435 17263 sgd_solver.cpp:43] Iteration 5200, lr = 0.1
I0619 18:12:14.145884 17263 solver.cpp:174] Iteration 5600, Testing net (#0)
I0619 18:13:19.369025 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.319766
I0619 18:13:19.369159 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 2.4399 (* 1 = 2.4399 loss)
I0619 18:13:21.378829 17263 solver.cpp:57] Iteration 5600, loss = 0.62923
I0619 18:13:21.378870 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.62923 (* 1 = 0.62923 loss)
I0619 18:13:21.378880 17263 sgd_solver.cpp:43] Iteration 5600, lr = 0.1
I0619 18:26:45.310771 17263 solver.cpp:174] Iteration 6000, Testing net (#0)
I0619 18:27:50.650590 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.306953
I0619 18:27:50.650807 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 2.0634 (* 1 = 2.0634 loss)
I0619 18:27:52.440946 17263 solver.cpp:57] Iteration 6000, loss = 0.640817
I0619 18:27:52.440997 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.640817 (* 1 = 0.640817 loss)
I0619 18:27:52.441009 17263 sgd_solver.cpp:43] Iteration 6000, lr = 0.1
I0619 18:41:21.136351 17263 solver.cpp:174] Iteration 6400, Testing net (#0)
I0619 18:42:26.438086 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.340859
I0619 18:42:26.438235 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 2.20457 (* 1 = 2.20457 loss)
I0619 18:42:28.452611 17263 solver.cpp:57] Iteration 6400, loss = 0.554606
I0619 18:42:28.452651 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.554606 (* 1 = 0.554606 loss)
I0619 18:42:28.452661 17263 sgd_solver.cpp:43] Iteration 6400, lr = 0.1
I0619 18:55:52.610360 17263 solver.cpp:174] Iteration 6800, Testing net (#0)
I0619 18:56:57.928205 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.45375
I0619 18:56:57.928473 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 1.66472 (* 1 = 1.66472 loss)
I0619 18:56:59.881256 17263 solver.cpp:57] Iteration 6800, loss = 0.592966
I0619 18:56:59.881299 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.592966 (* 1 = 0.592966 loss)
I0619 18:56:59.881310 17263 sgd_solver.cpp:43] Iteration 6800, lr = 0.1
I0619 19:10:27.290112 17263 solver.cpp:174] Iteration 7200, Testing net (#0)
I0619 19:11:32.622581 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.63
I0619 19:11:32.622803 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 1.10421 (* 1 = 1.10421 loss)
I0619 19:11:34.705231 17263 solver.cpp:57] Iteration 7200, loss = 0.507975
I0619 19:11:34.705272 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.507975 (* 1 = 0.507975 loss)
I0619 19:11:34.705283 17263 sgd_solver.cpp:43] Iteration 7200, lr = 0.1
I0619 19:25:00.091245 17263 solver.cpp:174] Iteration 7600, Testing net (#0)
I0619 19:26:05.408658 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.615234
I0619 19:26:05.408772 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 1.1814 (* 1 = 1.1814 loss)
I0619 19:26:07.171260 17263 solver.cpp:57] Iteration 7600, loss = 0.74228
I0619 19:26:07.171298 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.74228 (* 1 = 0.74228 loss)
I0619 19:26:07.171309 17263 sgd_solver.cpp:43] Iteration 7600, lr = 0.1
I0619 19:39:33.351286 17263 solver.cpp:174] Iteration 8000, Testing net (#0)
I0619 19:40:38.654490 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.591094
I0619 19:40:38.654745 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 1.20387 (* 1 = 1.20387 loss)
I0619 19:40:40.535897 17263 solver.cpp:57] Iteration 8000, loss = 0.523633
I0619 19:40:40.535934 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.523633 (* 1 = 0.523633 loss)
I0619 19:40:40.535946 17263 sgd_solver.cpp:43] Iteration 8000, lr = 0.1
I0619 19:54:10.254082 17263 solver.cpp:174] Iteration 8400, Testing net (#0)
I0619 19:55:15.570062 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.589375
I0619 19:55:15.570288 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 1.24874 (* 1 = 1.24874 loss)
I0619 19:55:17.416185 17263 solver.cpp:57] Iteration 8400, loss = 0.734349
I0619 19:55:17.416229 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.734349 (* 1 = 0.734349 loss)
I0619 19:55:17.416240 17263 sgd_solver.cpp:43] Iteration 8400, lr = 0.1
I0619 20:08:44.660329 17263 solver.cpp:174] Iteration 8800, Testing net (#0)
I0619 20:09:49.955693 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.66375
I0619 20:09:49.955834 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 1.00255 (* 1 = 1.00255 loss)
I0619 20:09:51.901155 17263 solver.cpp:57] Iteration 8800, loss = 0.460703
I0619 20:09:51.901191 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.460703 (* 1 = 0.460703 loss)
I0619 20:09:51.901202 17263 sgd_solver.cpp:43] Iteration 8800, lr = 0.1
I0619 20:23:13.835980 17263 solver.cpp:174] Iteration 9200, Testing net (#0)
I0619 20:24:19.124694 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.715078
I0619 20:24:19.124897 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.860226 (* 1 = 0.860226 loss)
I0619 20:24:21.208572 17263 solver.cpp:57] Iteration 9200, loss = 0.333614
I0619 20:24:21.208613 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.333614 (* 1 = 0.333614 loss)
I0619 20:24:21.208624 17263 sgd_solver.cpp:43] Iteration 9200, lr = 0.1
I0619 20:37:49.873564 17263 solver.cpp:174] Iteration 9600, Testing net (#0)
I0619 20:38:55.195742 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.633516
I0619 20:38:55.195873 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 1.24025 (* 1 = 1.24025 loss)
I0619 20:38:57.421131 17263 solver.cpp:57] Iteration 9600, loss = 0.375289
I0619 20:38:57.421193 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.375289 (* 1 = 0.375289 loss)
I0619 20:38:57.421205 17263 sgd_solver.cpp:43] Iteration 9600, lr = 0.1
I0619 20:52:27.476073 17263 solver.cpp:174] Iteration 10000, Testing net (#0)
I0619 20:53:32.747746 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.708984
I0619 20:53:32.747901 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.868593 (* 1 = 0.868593 loss)
I0619 20:53:34.825147 17263 solver.cpp:57] Iteration 10000, loss = 0.39329
I0619 20:53:34.825186 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.39329 (* 1 = 0.39329 loss)
I0619 20:53:34.825196 17263 sgd_solver.cpp:43] Iteration 10000, lr = 0.1
I0619 21:07:00.737877 17263 solver.cpp:174] Iteration 10400, Testing net (#0)
I0619 21:08:06.082931 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.733516
I0619 21:08:06.083153 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.758912 (* 1 = 0.758912 loss)
I0619 21:08:07.988168 17263 solver.cpp:57] Iteration 10400, loss = 0.34099
I0619 21:08:07.988217 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.34099 (* 1 = 0.34099 loss)
I0619 21:08:07.988229 17263 sgd_solver.cpp:43] Iteration 10400, lr = 0.1
I0619 21:21:37.510313 17263 solver.cpp:174] Iteration 10800, Testing net (#0)
I0619 21:22:42.830956 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.685
I0619 21:22:42.831096 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.948634 (* 1 = 0.948634 loss)
I0619 21:22:44.881665 17263 solver.cpp:57] Iteration 10800, loss = 0.419187
I0619 21:22:44.881705 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.419187 (* 1 = 0.419187 loss)
I0619 21:22:44.881713 17263 sgd_solver.cpp:43] Iteration 10800, lr = 0.1
I0619 21:36:10.990442 17263 solver.cpp:174] Iteration 11200, Testing net (#0)
I0619 21:37:16.437692 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.709609
I0619 21:37:16.437871 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.851534 (* 1 = 0.851534 loss)
I0619 21:37:18.464884 17263 solver.cpp:57] Iteration 11200, loss = 0.426628
I0619 21:37:18.464937 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.426628 (* 1 = 0.426628 loss)
I0619 21:37:18.464946 17263 sgd_solver.cpp:43] Iteration 11200, lr = 0.1
I0619 21:50:43.108729 17263 solver.cpp:174] Iteration 11600, Testing net (#0)
I0619 21:51:48.330128 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.544141
I0619 21:51:48.330294 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 1.56424 (* 1 = 1.56424 loss)
I0619 21:51:50.244699 17263 solver.cpp:57] Iteration 11600, loss = 0.330404
I0619 21:51:50.244750 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.330404 (* 1 = 0.330404 loss)
I0619 21:51:50.244758 17263 sgd_solver.cpp:43] Iteration 11600, lr = 0.1
I0619 22:05:08.260329 17263 solver.cpp:174] Iteration 12000, Testing net (#0)
I0619 22:06:13.514029 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.740859
I0619 22:06:13.514230 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.798103 (* 1 = 0.798103 loss)
I0619 22:06:15.560550 17263 solver.cpp:57] Iteration 12000, loss = 0.370503
I0619 22:06:15.560592 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.370503 (* 1 = 0.370503 loss)
I0619 22:06:15.560600 17263 sgd_solver.cpp:43] Iteration 12000, lr = 0.1
I0619 22:19:43.957028 17263 solver.cpp:174] Iteration 12400, Testing net (#0)
I0619 22:20:49.213719 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.781406
I0619 22:20:49.213886 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.66131 (* 1 = 0.66131 loss)
I0619 22:20:51.052239 17263 solver.cpp:57] Iteration 12400, loss = 0.336558
I0619 22:20:51.052283 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.336558 (* 1 = 0.336558 loss)
I0619 22:20:51.052292 17263 sgd_solver.cpp:43] Iteration 12400, lr = 0.1
I0619 22:34:20.668211 17263 solver.cpp:174] Iteration 12800, Testing net (#0)
I0619 22:35:25.956979 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.646406
I0619 22:35:25.957181 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 1.24124 (* 1 = 1.24124 loss)
I0619 22:35:28.000308 17263 solver.cpp:57] Iteration 12800, loss = 0.41979
I0619 22:35:28.000350 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.41979 (* 1 = 0.41979 loss)
I0619 22:35:28.000358 17263 sgd_solver.cpp:43] Iteration 12800, lr = 0.1
I0619 22:48:54.556757 17263 solver.cpp:174] Iteration 13200, Testing net (#0)
I0619 22:49:59.811902 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.767891
I0619 22:49:59.812108 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.694997 (* 1 = 0.694997 loss)
I0619 22:50:01.653172 17263 solver.cpp:57] Iteration 13200, loss = 0.416234
I0619 22:50:01.653211 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.416234 (* 1 = 0.416234 loss)
I0619 22:50:01.653223 17263 sgd_solver.cpp:43] Iteration 13200, lr = 0.1
I0619 23:03:24.019002 17263 solver.cpp:174] Iteration 13600, Testing net (#0)
I0619 23:04:29.264654 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.705391
I0619 23:04:29.264852 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.88689 (* 1 = 0.88689 loss)
I0619 23:04:31.278976 17263 solver.cpp:57] Iteration 13600, loss = 0.418814
I0619 23:04:31.279044 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.418814 (* 1 = 0.418814 loss)
I0619 23:04:31.279068 17263 sgd_solver.cpp:43] Iteration 13600, lr = 0.1
I0619 23:17:55.459842 17263 solver.cpp:174] Iteration 14000, Testing net (#0)
I0619 23:19:00.712368 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.816875
I0619 23:19:00.712563 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.539791 (* 1 = 0.539791 loss)
I0619 23:19:02.718097 17263 solver.cpp:57] Iteration 14000, loss = 0.431924
I0619 23:19:02.718137 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.431924 (* 1 = 0.431924 loss)
I0619 23:19:02.718145 17263 sgd_solver.cpp:43] Iteration 14000, lr = 0.1
I0619 23:32:31.434078 17263 solver.cpp:174] Iteration 14400, Testing net (#0)
I0619 23:33:36.722352 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.803125
I0619 23:33:36.722537 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.594474 (* 1 = 0.594474 loss)
I0619 23:33:38.461701 17263 solver.cpp:57] Iteration 14400, loss = 0.486918
I0619 23:33:38.461753 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.486918 (* 1 = 0.486918 loss)
I0619 23:33:38.461765 17263 sgd_solver.cpp:43] Iteration 14400, lr = 0.1
I0619 23:47:08.103338 17263 solver.cpp:174] Iteration 14800, Testing net (#0)
I0619 23:48:13.386414 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.847734
I0619 23:48:13.386611 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.457256 (* 1 = 0.457256 loss)
I0619 23:48:15.387681 17263 solver.cpp:57] Iteration 14800, loss = 0.225373
I0619 23:48:15.387718 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.225373 (* 1 = 0.225373 loss)
I0619 23:48:15.387727 17263 sgd_solver.cpp:43] Iteration 14800, lr = 0.1
I0620 00:01:43.739770 17263 solver.cpp:174] Iteration 15200, Testing net (#0)
I0620 00:02:48.977701 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.830859
I0620 00:02:48.977893 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.498864 (* 1 = 0.498864 loss)
I0620 00:02:50.957036 17263 solver.cpp:57] Iteration 15200, loss = 0.360263
I0620 00:02:50.957075 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.360263 (* 1 = 0.360263 loss)
I0620 00:02:50.957084 17263 sgd_solver.cpp:43] Iteration 15200, lr = 0.1
I0620 00:16:19.808188 17263 solver.cpp:174] Iteration 15600, Testing net (#0)
I0620 00:17:25.078613 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.726172
I0620 00:17:25.090430 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.925494 (* 1 = 0.925494 loss)
I0620 00:17:27.312490 17263 solver.cpp:57] Iteration 15600, loss = 0.254266
I0620 00:17:27.312530 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.254265 (* 1 = 0.254265 loss)
I0620 00:17:27.312536 17263 sgd_solver.cpp:43] Iteration 15600, lr = 0.1
I0620 00:30:54.046495 17263 solver.cpp:174] Iteration 16000, Testing net (#0)
I0620 00:31:59.255208 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.821094
I0620 00:31:59.255352 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.535031 (* 1 = 0.535031 loss)
I0620 00:32:01.231570 17263 solver.cpp:57] Iteration 16000, loss = 0.258182
I0620 00:32:01.231604 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.258182 (* 1 = 0.258182 loss)
I0620 00:32:01.231612 17263 sgd_solver.cpp:43] Iteration 16000, lr = 0.1
I0620 00:45:27.206904 17263 solver.cpp:174] Iteration 16400, Testing net (#0)
I0620 00:46:32.403931 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.816641
I0620 00:46:32.404139 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.546276 (* 1 = 0.546276 loss)
I0620 00:46:34.379588 17263 solver.cpp:57] Iteration 16400, loss = 0.2065
I0620 00:46:34.379637 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.2065 (* 1 = 0.2065 loss)
I0620 00:46:34.379644 17263 sgd_solver.cpp:43] Iteration 16400, lr = 0.1
I0620 01:00:00.234710 17263 solver.cpp:174] Iteration 16800, Testing net (#0)
I0620 01:01:05.541647 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.82375
I0620 01:01:05.541821 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.532723 (* 1 = 0.532723 loss)
I0620 01:01:07.589453 17263 solver.cpp:57] Iteration 16800, loss = 0.22876
I0620 01:01:07.589509 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.22876 (* 1 = 0.22876 loss)
I0620 01:01:07.589519 17263 sgd_solver.cpp:43] Iteration 16800, lr = 0.1
I0620 01:14:35.274268 17263 solver.cpp:174] Iteration 17200, Testing net (#0)
I0620 01:15:40.591871 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.836719
I0620 01:15:40.592043 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.503758 (* 1 = 0.503758 loss)
I0620 01:15:42.562831 17263 solver.cpp:57] Iteration 17200, loss = 0.279249
I0620 01:15:42.562870 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.279249 (* 1 = 0.279249 loss)
I0620 01:15:42.562877 17263 sgd_solver.cpp:43] Iteration 17200, lr = 0.1
I0620 01:29:10.611075 17263 solver.cpp:174] Iteration 17600, Testing net (#0)
I0620 01:30:15.879101 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.825547
I0620 01:30:15.879340 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.533505 (* 1 = 0.533505 loss)
I0620 01:30:17.823622 17263 solver.cpp:57] Iteration 17600, loss = 0.274033
I0620 01:30:17.823664 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.274033 (* 1 = 0.274033 loss)
I0620 01:30:17.823673 17263 sgd_solver.cpp:43] Iteration 17600, lr = 0.1
I0620 01:43:42.294314 17263 solver.cpp:174] Iteration 18000, Testing net (#0)
I0620 01:44:47.535212 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.823125
I0620 01:44:47.535408 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.525139 (* 1 = 0.525139 loss)
I0620 01:44:49.306169 17263 solver.cpp:57] Iteration 18000, loss = 0.38499
I0620 01:44:49.306216 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.38499 (* 1 = 0.38499 loss)
I0620 01:44:49.306226 17263 sgd_solver.cpp:43] Iteration 18000, lr = 0.1
I0620 01:58:09.983743 17263 solver.cpp:174] Iteration 18400, Testing net (#0)
I0620 01:59:15.317098 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.822031
I0620 01:59:15.317306 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.571488 (* 1 = 0.571488 loss)
I0620 01:59:17.295156 17263 solver.cpp:57] Iteration 18400, loss = 0.278842
I0620 01:59:17.295200 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.278842 (* 1 = 0.278842 loss)
I0620 01:59:17.295210 17263 sgd_solver.cpp:43] Iteration 18400, lr = 0.1
I0620 02:12:42.389075 17263 solver.cpp:174] Iteration 18800, Testing net (#0)
I0620 02:13:47.659229 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.821172
I0620 02:13:47.659432 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.559758 (* 1 = 0.559758 loss)
I0620 02:13:49.543231 17263 solver.cpp:57] Iteration 18800, loss = 0.368354
I0620 02:13:49.543272 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.368353 (* 1 = 0.368353 loss)
I0620 02:13:49.543279 17263 sgd_solver.cpp:43] Iteration 18800, lr = 0.1
I0620 02:27:18.097457 17263 solver.cpp:174] Iteration 19200, Testing net (#0)
I0620 02:28:23.346246 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.829844
I0620 02:28:23.346457 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.526406 (* 1 = 0.526406 loss)
I0620 02:28:25.472268 17263 solver.cpp:57] Iteration 19200, loss = 0.311277
I0620 02:28:25.472306 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.311277 (* 1 = 0.311277 loss)
I0620 02:28:25.472312 17263 sgd_solver.cpp:43] Iteration 19200, lr = 0.1
I0620 02:41:51.704133 17263 solver.cpp:174] Iteration 19600, Testing net (#0)
I0620 02:42:56.968132 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.818438
I0620 02:42:56.968323 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.53802 (* 1 = 0.53802 loss)
I0620 02:42:59.135043 17263 solver.cpp:57] Iteration 19600, loss = 0.219026
I0620 02:42:59.135087 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.219026 (* 1 = 0.219026 loss)
I0620 02:42:59.135097 17263 sgd_solver.cpp:43] Iteration 19600, lr = 0.1
I0620 02:56:25.776373 17263 solver.cpp:174] Iteration 20000, Testing net (#0)
I0620 02:57:31.102588 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.823281
I0620 02:57:31.102767 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.521462 (* 1 = 0.521462 loss)
I0620 02:57:33.252753 17263 solver.cpp:57] Iteration 20000, loss = 0.182068
I0620 02:57:33.252801 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.182068 (* 1 = 0.182068 loss)
I0620 02:57:33.252810 17263 sgd_solver.cpp:43] Iteration 20000, lr = 0.1
I0620 03:10:58.853245 17263 solver.cpp:174] Iteration 20400, Testing net (#0)
I0620 03:12:04.099078 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.841953
I0620 03:12:04.099295 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.489022 (* 1 = 0.489022 loss)
I0620 03:12:06.042394 17263 solver.cpp:57] Iteration 20400, loss = 0.261799
I0620 03:12:06.042438 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.261799 (* 1 = 0.261799 loss)
I0620 03:12:06.042444 17263 sgd_solver.cpp:43] Iteration 20400, lr = 0.1
I0620 03:25:32.371492 17263 solver.cpp:174] Iteration 20800, Testing net (#0)
I0620 03:26:37.554877 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.780391
I0620 03:26:37.555102 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.683747 (* 1 = 0.683747 loss)
I0620 03:26:39.566565 17263 solver.cpp:57] Iteration 20800, loss = 0.256723
I0620 03:26:39.566612 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.256723 (* 1 = 0.256723 loss)
I0620 03:26:39.566620 17263 sgd_solver.cpp:43] Iteration 20800, lr = 0.1
I0620 03:40:05.499153 17263 solver.cpp:174] Iteration 21200, Testing net (#0)
I0620 03:41:10.810719 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.816797
I0620 03:41:10.810905 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.607793 (* 1 = 0.607793 loss)
I0620 03:41:12.747191 17263 solver.cpp:57] Iteration 21200, loss = 0.358082
I0620 03:41:12.747237 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.358082 (* 1 = 0.358082 loss)
I0620 03:41:12.747244 17263 sgd_solver.cpp:43] Iteration 21200, lr = 0.1
I0620 03:54:39.170301 17263 solver.cpp:174] Iteration 21600, Testing net (#0)
I0620 03:55:44.478791 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.754687
I0620 03:55:44.478971 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.811952 (* 1 = 0.811952 loss)
I0620 03:55:46.530401 17263 solver.cpp:57] Iteration 21600, loss = 0.23252
I0620 03:55:46.530442 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.23252 (* 1 = 0.23252 loss)
I0620 03:55:46.530450 17263 sgd_solver.cpp:43] Iteration 21600, lr = 0.1
I0620 04:09:13.699252 17263 solver.cpp:174] Iteration 22000, Testing net (#0)
I0620 04:10:18.951107 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.850703
I0620 04:10:18.951303 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.442828 (* 1 = 0.442828 loss)
I0620 04:10:20.755288 17263 solver.cpp:57] Iteration 22000, loss = 0.331498
I0620 04:10:20.755339 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.331498 (* 1 = 0.331498 loss)
I0620 04:10:20.755350 17263 sgd_solver.cpp:43] Iteration 22000, lr = 0.1
I0620 04:23:48.046769 17263 solver.cpp:174] Iteration 22400, Testing net (#0)
I0620 04:24:53.346156 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.808203
I0620 04:24:53.346375 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.625821 (* 1 = 0.625821 loss)
I0620 04:24:55.431859 17263 solver.cpp:57] Iteration 22400, loss = 0.233441
I0620 04:24:55.431902 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.233441 (* 1 = 0.233441 loss)
I0620 04:24:55.431910 17263 sgd_solver.cpp:43] Iteration 22400, lr = 0.1
I0620 04:38:22.042268 17263 solver.cpp:174] Iteration 22800, Testing net (#0)
I0620 04:39:27.288272 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.832344
I0620 04:39:27.288476 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.483853 (* 1 = 0.483853 loss)
I0620 04:39:29.025424 17263 solver.cpp:57] Iteration 22800, loss = 0.475355
I0620 04:39:29.025465 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.475355 (* 1 = 0.475355 loss)
I0620 04:39:29.025472 17263 sgd_solver.cpp:43] Iteration 22800, lr = 0.1
I0620 04:52:54.049015 17263 solver.cpp:174] Iteration 23200, Testing net (#0)
I0620 04:53:59.361361 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.836797
I0620 04:53:59.361536 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.51895 (* 1 = 0.51895 loss)
I0620 04:54:01.345718 17263 solver.cpp:57] Iteration 23200, loss = 0.201084
I0620 04:54:01.345763 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.201084 (* 1 = 0.201084 loss)
I0620 04:54:01.345772 17263 sgd_solver.cpp:43] Iteration 23200, lr = 0.1
I0620 05:07:22.214077 17263 solver.cpp:174] Iteration 23600, Testing net (#0)
I0620 05:08:27.469107 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.836797
I0620 05:08:27.469363 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.520045 (* 1 = 0.520045 loss)
I0620 05:08:29.439532 17263 solver.cpp:57] Iteration 23600, loss = 0.0905283
I0620 05:08:29.439569 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0905282 (* 1 = 0.0905282 loss)
I0620 05:08:29.439577 17263 sgd_solver.cpp:43] Iteration 23600, lr = 0.1
I0620 05:21:56.507421 17263 solver.cpp:174] Iteration 24000, Testing net (#0)
I0620 05:23:01.873049 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.791328
I0620 05:23:01.873252 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.730959 (* 1 = 0.730959 loss)
I0620 05:23:03.900732 17263 solver.cpp:57] Iteration 24000, loss = 0.167878
I0620 05:23:03.900774 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.167877 (* 1 = 0.167877 loss)
I0620 05:23:03.900784 17263 sgd_solver.cpp:43] Iteration 24000, lr = 0.1
I0620 05:36:27.046716 17263 solver.cpp:174] Iteration 24400, Testing net (#0)
I0620 05:37:32.344708 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.781563
I0620 05:37:32.344913 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.73684 (* 1 = 0.73684 loss)
I0620 05:37:34.318995 17263 solver.cpp:57] Iteration 24400, loss = 0.231432
I0620 05:37:34.319041 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.231432 (* 1 = 0.231432 loss)
I0620 05:37:34.319049 17263 sgd_solver.cpp:43] Iteration 24400, lr = 0.1
I0620 05:50:59.689690 17263 solver.cpp:174] Iteration 24800, Testing net (#0)
I0620 05:52:04.973443 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.851562
I0620 05:52:04.973624 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.454485 (* 1 = 0.454485 loss)
I0620 05:52:07.245012 17263 solver.cpp:57] Iteration 24800, loss = 0.194831
I0620 05:52:07.245059 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.194831 (* 1 = 0.194831 loss)
I0620 05:52:07.245070 17263 sgd_solver.cpp:43] Iteration 24800, lr = 0.1
I0620 06:05:30.695807 17263 solver.cpp:174] Iteration 25200, Testing net (#0)
I0620 06:06:35.938340 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.8575
I0620 06:06:35.938544 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.425118 (* 1 = 0.425118 loss)
I0620 06:06:37.953915 17263 solver.cpp:57] Iteration 25200, loss = 0.343465
I0620 06:06:37.953960 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.343465 (* 1 = 0.343465 loss)
I0620 06:06:37.953969 17263 sgd_solver.cpp:43] Iteration 25200, lr = 0.1
I0620 06:20:01.564698 17263 solver.cpp:174] Iteration 25600, Testing net (#0)
I0620 06:21:06.870236 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.869219
I0620 06:21:06.870431 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.378642 (* 1 = 0.378642 loss)
I0620 06:21:09.030185 17263 solver.cpp:57] Iteration 25600, loss = 0.32813
I0620 06:21:09.030228 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.32813 (* 1 = 0.32813 loss)
I0620 06:21:09.030237 17263 sgd_solver.cpp:43] Iteration 25600, lr = 0.1
I0620 06:34:32.318828 17263 solver.cpp:174] Iteration 26000, Testing net (#0)
I0620 06:35:37.597014 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.856953
I0620 06:35:37.597249 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.452265 (* 1 = 0.452265 loss)
I0620 06:35:39.577847 17263 solver.cpp:57] Iteration 26000, loss = 0.198475
I0620 06:35:39.577890 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.198475 (* 1 = 0.198475 loss)
I0620 06:35:39.577903 17263 sgd_solver.cpp:43] Iteration 26000, lr = 0.1
I0620 06:49:11.437257 17263 solver.cpp:174] Iteration 26400, Testing net (#0)
I0620 06:50:16.737073 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.852813
I0620 06:50:16.737277 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.466109 (* 1 = 0.466109 loss)
I0620 06:50:18.503590 17263 solver.cpp:57] Iteration 26400, loss = 0.295124
I0620 06:50:18.503628 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.295124 (* 1 = 0.295124 loss)
I0620 06:50:18.503640 17263 sgd_solver.cpp:43] Iteration 26400, lr = 0.1
I0620 07:03:42.400473 17263 solver.cpp:174] Iteration 26800, Testing net (#0)
I0620 07:04:47.681939 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.808438
I0620 07:04:47.682152 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.626487 (* 1 = 0.626487 loss)
I0620 07:04:49.881569 17263 solver.cpp:57] Iteration 26800, loss = 0.162907
I0620 07:04:49.881618 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.162907 (* 1 = 0.162907 loss)
I0620 07:04:49.881628 17263 sgd_solver.cpp:43] Iteration 26800, lr = 0.1
I0620 07:18:17.045631 17263 solver.cpp:174] Iteration 27200, Testing net (#0)
I0620 07:19:22.287510 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.855937
I0620 07:19:22.287711 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.470015 (* 1 = 0.470015 loss)
I0620 07:19:24.447165 17263 solver.cpp:57] Iteration 27200, loss = 0.300833
I0620 07:19:24.447203 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.300832 (* 1 = 0.300832 loss)
I0620 07:19:24.447212 17263 sgd_solver.cpp:43] Iteration 27200, lr = 0.1
I0620 07:32:51.223969 17263 solver.cpp:174] Iteration 27600, Testing net (#0)
I0620 07:33:56.530020 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.864922
I0620 07:33:56.530231 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.406851 (* 1 = 0.406851 loss)
I0620 07:33:58.692258 17263 solver.cpp:57] Iteration 27600, loss = 0.248078
I0620 07:33:58.692297 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.248077 (* 1 = 0.248077 loss)
I0620 07:33:58.692306 17263 sgd_solver.cpp:43] Iteration 27600, lr = 0.1
I0620 07:47:22.185667 17263 solver.cpp:174] Iteration 28000, Testing net (#0)
I0620 07:48:27.450872 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.798437
I0620 07:48:27.451082 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.678398 (* 1 = 0.678398 loss)
I0620 07:48:29.499248 17263 solver.cpp:57] Iteration 28000, loss = 0.252056
I0620 07:48:29.499295 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.252056 (* 1 = 0.252056 loss)
I0620 07:48:29.499302 17263 sgd_solver.cpp:43] Iteration 28000, lr = 0.1
I0620 08:01:54.581568 17263 solver.cpp:174] Iteration 28400, Testing net (#0)
I0620 08:02:59.860002 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.836797
I0620 08:02:59.860198 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.505751 (* 1 = 0.505751 loss)
I0620 08:03:01.640213 17263 solver.cpp:57] Iteration 28400, loss = 0.360986
I0620 08:03:01.640259 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.360986 (* 1 = 0.360986 loss)
I0620 08:03:01.640269 17263 sgd_solver.cpp:43] Iteration 28400, lr = 0.1
I0620 08:16:28.421521 17263 solver.cpp:174] Iteration 28800, Testing net (#0)
I0620 08:17:33.710963 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.777031
I0620 08:17:33.711118 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.687192 (* 1 = 0.687192 loss)
I0620 08:17:35.647948 17263 solver.cpp:57] Iteration 28800, loss = 0.322896
I0620 08:17:35.647992 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.322895 (* 1 = 0.322895 loss)
I0620 08:17:35.648001 17263 sgd_solver.cpp:43] Iteration 28800, lr = 0.1
I0620 08:30:57.908453 17263 solver.cpp:174] Iteration 29200, Testing net (#0)
I0620 08:32:03.193296 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.817656
I0620 08:32:03.193512 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.569208 (* 1 = 0.569208 loss)
I0620 08:32:05.137612 17263 solver.cpp:57] Iteration 29200, loss = 0.171029
I0620 08:32:05.137660 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.171029 (* 1 = 0.171029 loss)
I0620 08:32:05.137670 17263 sgd_solver.cpp:43] Iteration 29200, lr = 0.1
I0620 08:45:31.082258 17263 solver.cpp:174] Iteration 29600, Testing net (#0)
I0620 08:46:36.330663 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.846328
I0620 08:46:36.330885 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.480463 (* 1 = 0.480463 loss)
I0620 08:46:38.448853 17263 solver.cpp:57] Iteration 29600, loss = 0.236223
I0620 08:46:38.448889 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.236223 (* 1 = 0.236223 loss)
I0620 08:46:38.448896 17263 sgd_solver.cpp:43] Iteration 29600, lr = 0.1
I0620 09:00:01.824668 17263 solver.cpp:174] Iteration 30000, Testing net (#0)
I0620 09:01:07.141237 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.828281
I0620 09:01:07.141469 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.539739 (* 1 = 0.539739 loss)
I0620 09:01:09.091375 17263 solver.cpp:57] Iteration 30000, loss = 0.151649
I0620 09:01:09.091423 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.151649 (* 1 = 0.151649 loss)
I0620 09:01:09.091434 17263 sgd_solver.cpp:43] Iteration 30000, lr = 0.1
I0620 09:14:32.835621 17263 solver.cpp:174] Iteration 30400, Testing net (#0)
I0620 09:15:38.115877 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.825547
I0620 09:15:38.116077 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.586788 (* 1 = 0.586788 loss)
I0620 09:15:40.034060 17263 solver.cpp:57] Iteration 30400, loss = 0.15963
I0620 09:15:40.034108 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.15963 (* 1 = 0.15963 loss)
I0620 09:15:40.034117 17263 sgd_solver.cpp:43] Iteration 30400, lr = 0.1
I0620 09:29:09.025776 17263 solver.cpp:174] Iteration 30800, Testing net (#0)
I0620 09:30:14.323307 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.854922
I0620 09:30:14.323441 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.477768 (* 1 = 0.477768 loss)
I0620 09:30:16.218227 17263 solver.cpp:57] Iteration 30800, loss = 0.28845
I0620 09:30:16.218268 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.28845 (* 1 = 0.28845 loss)
I0620 09:30:16.218277 17263 sgd_solver.cpp:43] Iteration 30800, lr = 0.1
I0620 09:43:44.417039 17263 solver.cpp:174] Iteration 31200, Testing net (#0)
I0620 09:44:49.803148 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.818984
I0620 09:44:49.814420 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.543745 (* 1 = 0.543745 loss)
I0620 09:44:51.646713 17263 solver.cpp:57] Iteration 31200, loss = 0.432193
I0620 09:44:51.646754 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.432193 (* 1 = 0.432193 loss)
I0620 09:44:51.646761 17263 sgd_solver.cpp:43] Iteration 31200, lr = 0.1
I0620 09:58:20.158475 17263 solver.cpp:174] Iteration 31600, Testing net (#0)
I0620 09:59:25.346465 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.842578
I0620 09:59:25.346670 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.505979 (* 1 = 0.505979 loss)
I0620 09:59:27.040877 17263 solver.cpp:57] Iteration 31600, loss = 0.397528
I0620 09:59:27.040920 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.397528 (* 1 = 0.397528 loss)
I0620 09:59:27.040928 17263 sgd_solver.cpp:43] Iteration 31600, lr = 0.1
I0620 10:12:54.221904 17263 solver.cpp:174] Iteration 32000, Testing net (#0)
I0620 10:13:59.492399 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.826328
I0620 10:13:59.492593 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.588487 (* 1 = 0.588487 loss)
I0620 10:14:01.437229 17263 solver.cpp:57] Iteration 32000, loss = 0.212274
I0620 10:14:01.437273 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.212274 (* 1 = 0.212274 loss)
I0620 10:14:01.437283 17263 sgd_solver.cpp:43] Iteration 32000, lr = 0.1
I0620 10:27:28.139988 17263 solver.cpp:174] Iteration 32400, Testing net (#0)
I0620 10:28:33.390894 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.876562
I0620 10:28:33.391082 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.374899 (* 1 = 0.374899 loss)
I0620 10:28:35.370057 17263 solver.cpp:57] Iteration 32400, loss = 0.171303
I0620 10:28:35.370101 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.171303 (* 1 = 0.171303 loss)
I0620 10:28:35.370110 17263 sgd_solver.cpp:43] Iteration 32400, lr = 0.1
I0620 10:42:01.308787 17263 solver.cpp:174] Iteration 32800, Testing net (#0)
I0620 10:43:06.564188 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.842734
I0620 10:43:06.564379 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.488974 (* 1 = 0.488974 loss)
I0620 10:43:08.724653 17263 solver.cpp:57] Iteration 32800, loss = 0.123615
I0620 10:43:08.724699 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.123615 (* 1 = 0.123615 loss)
I0620 10:43:08.724707 17263 sgd_solver.cpp:43] Iteration 32800, lr = 0.1
I0620 10:56:35.001431 17263 solver.cpp:174] Iteration 33200, Testing net (#0)
I0620 10:57:40.206555 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.852031
I0620 10:57:40.206760 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.523137 (* 1 = 0.523137 loss)
I0620 10:57:42.015784 17263 solver.cpp:57] Iteration 33200, loss = 0.203131
I0620 10:57:42.015830 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.20313 (* 1 = 0.20313 loss)
I0620 10:57:42.015839 17263 sgd_solver.cpp:43] Iteration 33200, lr = 0.1
I0620 11:11:10.464131 17263 solver.cpp:174] Iteration 33600, Testing net (#0)
I0620 11:12:15.693142 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.796094
I0620 11:12:15.693341 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.690783 (* 1 = 0.690783 loss)
I0620 11:12:17.528511 17263 solver.cpp:57] Iteration 33600, loss = 0.210586
I0620 11:12:17.528556 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.210586 (* 1 = 0.210586 loss)
I0620 11:12:17.528568 17263 sgd_solver.cpp:43] Iteration 33600, lr = 0.1
I0620 11:25:43.803767 17263 solver.cpp:174] Iteration 34000, Testing net (#0)
I0620 11:26:49.093511 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.857578
I0620 11:26:49.093706 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.455019 (* 1 = 0.455019 loss)
I0620 11:26:50.950834 17263 solver.cpp:57] Iteration 34000, loss = 0.18646
I0620 11:26:50.950873 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.18646 (* 1 = 0.18646 loss)
I0620 11:26:50.950880 17263 sgd_solver.cpp:43] Iteration 34000, lr = 0.1
I0620 11:40:19.464016 17263 solver.cpp:174] Iteration 34400, Testing net (#0)
I0620 11:41:24.740927 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.811875
I0620 11:41:24.741087 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.671218 (* 1 = 0.671218 loss)
I0620 11:41:26.750073 17263 solver.cpp:57] Iteration 34400, loss = 0.138223
I0620 11:41:26.750119 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.138223 (* 1 = 0.138223 loss)
I0620 11:41:26.750128 17263 sgd_solver.cpp:43] Iteration 34400, lr = 0.1
I0620 11:54:50.457775 17263 solver.cpp:174] Iteration 34800, Testing net (#0)
I0620 11:55:55.702663 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.846484
I0620 11:55:55.702865 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.517771 (* 1 = 0.517771 loss)
I0620 11:55:57.750958 17263 solver.cpp:57] Iteration 34800, loss = 0.220367
I0620 11:55:57.750994 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.220367 (* 1 = 0.220367 loss)
I0620 11:55:57.751003 17263 sgd_solver.cpp:43] Iteration 34800, lr = 0.1
I0620 12:09:25.597827 17263 solver.cpp:174] Iteration 35200, Testing net (#0)
I0620 12:10:30.862751 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.821797
I0620 12:10:30.862902 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.71951 (* 1 = 0.71951 loss)
I0620 12:10:32.814787 17263 solver.cpp:57] Iteration 35200, loss = 0.223092
I0620 12:10:32.814836 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.223091 (* 1 = 0.223091 loss)
I0620 12:10:32.814847 17263 sgd_solver.cpp:43] Iteration 35200, lr = 0.1
I0620 12:23:59.079517 17263 solver.cpp:174] Iteration 35600, Testing net (#0)
I0620 12:25:04.390197 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.857891
I0620 12:25:04.390445 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.46693 (* 1 = 0.46693 loss)
I0620 12:25:06.514070 17263 solver.cpp:57] Iteration 35600, loss = 0.260591
I0620 12:25:06.514111 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.26059 (* 1 = 0.26059 loss)
I0620 12:25:06.514120 17263 sgd_solver.cpp:43] Iteration 35600, lr = 0.1
I0620 12:38:32.879065 17263 solver.cpp:174] Iteration 36000, Testing net (#0)
I0620 12:39:38.102309 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.875703
I0620 12:39:38.102531 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.383476 (* 1 = 0.383476 loss)
I0620 12:39:40.107484 17263 solver.cpp:57] Iteration 36000, loss = 0.258261
I0620 12:39:40.107540 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.258261 (* 1 = 0.258261 loss)
I0620 12:39:40.107549 17263 sgd_solver.cpp:43] Iteration 36000, lr = 0.1
I0620 12:53:04.871274 17263 solver.cpp:174] Iteration 36400, Testing net (#0)
I0620 12:54:10.143317 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.824531
I0620 12:54:10.143539 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.555207 (* 1 = 0.555207 loss)
I0620 12:54:12.095484 17263 solver.cpp:57] Iteration 36400, loss = 0.192509
I0620 12:54:12.095527 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.192509 (* 1 = 0.192509 loss)
I0620 12:54:12.095535 17263 sgd_solver.cpp:43] Iteration 36400, lr = 0.1
I0620 13:07:38.070577 17263 solver.cpp:174] Iteration 36800, Testing net (#0)
I0620 13:08:43.378615 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.863984
I0620 13:08:43.378813 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.433777 (* 1 = 0.433777 loss)
I0620 13:08:45.471771 17263 solver.cpp:57] Iteration 36800, loss = 0.237773
I0620 13:08:45.471824 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.237773 (* 1 = 0.237773 loss)
I0620 13:08:45.471833 17263 sgd_solver.cpp:43] Iteration 36800, lr = 0.1
I0620 13:22:09.412786 17263 solver.cpp:174] Iteration 37200, Testing net (#0)
I0620 13:23:14.666419 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.882266
I0620 13:23:14.666615 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.378277 (* 1 = 0.378277 loss)
I0620 13:23:16.680318 17263 solver.cpp:57] Iteration 37200, loss = 0.166384
I0620 13:23:16.680377 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.166383 (* 1 = 0.166383 loss)
I0620 13:23:16.680390 17263 sgd_solver.cpp:43] Iteration 37200, lr = 0.1
I0620 13:36:46.159497 17263 solver.cpp:174] Iteration 37600, Testing net (#0)
I0620 13:37:51.507860 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.865469
I0620 13:37:51.508044 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.42322 (* 1 = 0.42322 loss)
I0620 13:37:53.389016 17263 solver.cpp:57] Iteration 37600, loss = 0.132037
I0620 13:37:53.389062 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.132036 (* 1 = 0.132036 loss)
I0620 13:37:53.389070 17263 sgd_solver.cpp:43] Iteration 37600, lr = 0.1
I0620 13:51:18.075631 17263 solver.cpp:174] Iteration 38000, Testing net (#0)
I0620 13:52:23.313163 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.822344
I0620 13:52:23.313591 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.562302 (* 1 = 0.562302 loss)
I0620 13:52:25.327896 17263 solver.cpp:57] Iteration 38000, loss = 0.217657
I0620 13:52:25.327941 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.217656 (* 1 = 0.217656 loss)
I0620 13:52:25.327950 17263 sgd_solver.cpp:43] Iteration 38000, lr = 0.1
I0620 14:05:53.164868 17263 solver.cpp:174] Iteration 38400, Testing net (#0)
I0620 14:06:58.463044 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.865391
I0620 14:06:58.463260 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.444955 (* 1 = 0.444955 loss)
I0620 14:07:00.458331 17263 solver.cpp:57] Iteration 38400, loss = 0.316962
I0620 14:07:00.458382 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.316962 (* 1 = 0.316962 loss)
I0620 14:07:00.458392 17263 sgd_solver.cpp:43] Iteration 38400, lr = 0.1
I0620 14:20:30.647325 17263 solver.cpp:174] Iteration 38800, Testing net (#0)
I0620 14:21:35.906078 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.848281
I0620 14:21:35.906285 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.46903 (* 1 = 0.46903 loss)
I0620 14:21:37.745761 17263 solver.cpp:57] Iteration 38800, loss = 0.287795
I0620 14:21:37.745815 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.287794 (* 1 = 0.287794 loss)
I0620 14:21:37.745826 17263 sgd_solver.cpp:43] Iteration 38800, lr = 0.1
I0620 14:35:04.501184 17263 solver.cpp:174] Iteration 39200, Testing net (#0)
I0620 14:36:09.769670 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.864453
I0620 14:36:09.769886 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.44381 (* 1 = 0.44381 loss)
I0620 14:36:11.622035 17263 solver.cpp:57] Iteration 39200, loss = 0.215721
I0620 14:36:11.622074 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.21572 (* 1 = 0.21572 loss)
I0620 14:36:11.622082 17263 sgd_solver.cpp:43] Iteration 39200, lr = 0.1
I0620 14:49:37.143299 17263 solver.cpp:174] Iteration 39600, Testing net (#0)
I0620 14:50:42.469147 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.843984
I0620 14:50:42.469363 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.469087 (* 1 = 0.469087 loss)
I0620 14:50:44.507540 17263 solver.cpp:57] Iteration 39600, loss = 0.14725
I0620 14:50:44.507603 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.14725 (* 1 = 0.14725 loss)
I0620 14:50:44.507611 17263 sgd_solver.cpp:43] Iteration 39600, lr = 0.1
I0620 15:04:12.718258 17263 solver.cpp:174] Iteration 40000, Testing net (#0)
I0620 15:05:17.989971 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.820078
I0620 15:05:17.990165 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.611452 (* 1 = 0.611452 loss)
I0620 15:05:19.685322 17263 solver.cpp:57] Iteration 40000, loss = 0.381418
I0620 15:05:19.685367 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.381418 (* 1 = 0.381418 loss)
I0620 15:05:19.685374 17263 sgd_solver.cpp:43] Iteration 40000, lr = 0.1
I0620 15:18:44.847071 17263 solver.cpp:174] Iteration 40400, Testing net (#0)
I0620 15:19:50.095715 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.821406
I0620 15:19:50.095909 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.621252 (* 1 = 0.621252 loss)
I0620 15:19:52.034617 17263 solver.cpp:57] Iteration 40400, loss = 0.277159
I0620 15:19:52.034667 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.277158 (* 1 = 0.277158 loss)
I0620 15:19:52.034675 17263 sgd_solver.cpp:43] Iteration 40400, lr = 0.1
I0620 15:33:19.838840 17263 solver.cpp:174] Iteration 40800, Testing net (#0)
I0620 15:34:25.121018 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.848828
I0620 15:34:25.121220 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.504683 (* 1 = 0.504683 loss)
I0620 15:34:27.175807 17263 solver.cpp:57] Iteration 40800, loss = 0.232532
I0620 15:34:27.175845 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.232532 (* 1 = 0.232532 loss)
I0620 15:34:27.175853 17263 sgd_solver.cpp:43] Iteration 40800, lr = 0.1
I0620 15:47:51.747036 17263 solver.cpp:174] Iteration 41200, Testing net (#0)
I0620 15:48:57.057407 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.846016
I0620 15:48:57.057617 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.520073 (* 1 = 0.520073 loss)
I0620 15:48:59.026585 17263 solver.cpp:57] Iteration 41200, loss = 0.27221
I0620 15:48:59.026624 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.272209 (* 1 = 0.272209 loss)
I0620 15:48:59.026631 17263 sgd_solver.cpp:43] Iteration 41200, lr = 0.1
I0620 16:02:27.166746 17263 solver.cpp:174] Iteration 41600, Testing net (#0)
I0620 16:03:32.483114 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.877422
I0620 16:03:32.483302 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.374796 (* 1 = 0.374796 loss)
I0620 16:03:34.436384 17263 solver.cpp:57] Iteration 41600, loss = 0.234104
I0620 16:03:34.436429 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.234104 (* 1 = 0.234104 loss)
I0620 16:03:34.436436 17263 sgd_solver.cpp:43] Iteration 41600, lr = 0.1
I0620 16:16:57.783746 17263 solver.cpp:174] Iteration 42000, Testing net (#0)
I0620 16:18:03.102578 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.882109
I0620 16:18:03.102911 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.351715 (* 1 = 0.351715 loss)
I0620 16:18:05.188016 17263 solver.cpp:57] Iteration 42000, loss = 0.0844639
I0620 16:18:05.188057 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0844636 (* 1 = 0.0844636 loss)
I0620 16:18:05.188063 17263 sgd_solver.cpp:43] Iteration 42000, lr = 0.1
I0620 16:31:31.483454 17263 solver.cpp:174] Iteration 42400, Testing net (#0)
I0620 16:32:36.675173 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.878281
I0620 16:32:36.675364 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.381972 (* 1 = 0.381972 loss)
I0620 16:32:38.610327 17263 solver.cpp:57] Iteration 42400, loss = 0.197334
I0620 16:32:38.610368 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.197333 (* 1 = 0.197333 loss)
I0620 16:32:38.610376 17263 sgd_solver.cpp:43] Iteration 42400, lr = 0.1
I0620 16:46:06.447867 17263 solver.cpp:174] Iteration 42800, Testing net (#0)
I0620 16:47:11.722748 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.861406
I0620 16:47:11.722916 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.472345 (* 1 = 0.472345 loss)
I0620 16:47:13.601558 17263 solver.cpp:57] Iteration 42800, loss = 0.247866
I0620 16:47:13.601611 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.247866 (* 1 = 0.247866 loss)
I0620 16:47:13.601626 17263 sgd_solver.cpp:43] Iteration 42800, lr = 0.1
I0620 17:00:46.837939 17263 solver.cpp:174] Iteration 43200, Testing net (#0)
I0620 17:01:52.108463 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.880547
I0620 17:01:52.108666 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.390822 (* 1 = 0.390822 loss)
I0620 17:01:54.117913 17263 solver.cpp:57] Iteration 43200, loss = 0.0963364
I0620 17:01:54.117954 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0963362 (* 1 = 0.0963362 loss)
I0620 17:01:54.117962 17263 sgd_solver.cpp:43] Iteration 43200, lr = 0.1
I0620 17:15:21.657002 17263 solver.cpp:174] Iteration 43600, Testing net (#0)
I0620 17:16:27.028159 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.853437
I0620 17:16:27.028368 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.467135 (* 1 = 0.467135 loss)
I0620 17:16:28.835677 17263 solver.cpp:57] Iteration 43600, loss = 0.198151
I0620 17:16:28.835713 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.198151 (* 1 = 0.198151 loss)
I0620 17:16:28.835721 17263 sgd_solver.cpp:43] Iteration 43600, lr = 0.1
I0620 17:29:53.093235 17263 solver.cpp:174] Iteration 44000, Testing net (#0)
I0620 17:30:58.420625 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.830781
I0620 17:30:58.420835 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.593357 (* 1 = 0.593357 loss)
I0620 17:31:00.397187 17263 solver.cpp:57] Iteration 44000, loss = 0.200371
I0620 17:31:00.397228 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.200371 (* 1 = 0.200371 loss)
I0620 17:31:00.397235 17263 sgd_solver.cpp:43] Iteration 44000, lr = 0.1
I0620 17:44:27.588225 17263 solver.cpp:174] Iteration 44400, Testing net (#0)
I0620 17:45:32.872859 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.882187
I0620 17:45:32.873127 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.371356 (* 1 = 0.371356 loss)
I0620 17:45:34.917418 17263 solver.cpp:57] Iteration 44400, loss = 0.224557
I0620 17:45:34.917465 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.224557 (* 1 = 0.224557 loss)
I0620 17:45:34.917474 17263 sgd_solver.cpp:43] Iteration 44400, lr = 0.1
I0620 17:59:03.562974 17263 solver.cpp:174] Iteration 44800, Testing net (#0)
I0620 18:00:08.870077 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.84875
I0620 18:00:08.870285 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.459319 (* 1 = 0.459319 loss)
I0620 18:00:10.970217 17263 solver.cpp:57] Iteration 44800, loss = 0.238678
I0620 18:00:10.970265 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.238678 (* 1 = 0.238678 loss)
I0620 18:00:10.970274 17263 sgd_solver.cpp:43] Iteration 44800, lr = 0.1
I0620 18:13:35.847589 17263 solver.cpp:174] Iteration 45200, Testing net (#0)
I0620 18:14:41.191469 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.812266
I0620 18:14:41.191634 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.59962 (* 1 = 0.59962 loss)
I0620 18:14:43.206758 17263 solver.cpp:57] Iteration 45200, loss = 0.143203
I0620 18:14:43.206809 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.143203 (* 1 = 0.143203 loss)
I0620 18:14:43.206830 17263 sgd_solver.cpp:43] Iteration 45200, lr = 0.1
I0620 18:28:08.399358 17263 solver.cpp:174] Iteration 45600, Testing net (#0)
I0620 18:29:13.716087 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.842891
I0620 18:29:13.716312 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.50222 (* 1 = 0.50222 loss)
I0620 18:29:15.806787 17263 solver.cpp:57] Iteration 45600, loss = 0.174245
I0620 18:29:15.806830 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.174245 (* 1 = 0.174245 loss)
I0620 18:29:15.806839 17263 sgd_solver.cpp:43] Iteration 45600, lr = 0.1
I0620 18:42:42.507367 17263 solver.cpp:174] Iteration 46000, Testing net (#0)
I0620 18:43:47.822166 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.833438
I0620 18:43:47.822407 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.656224 (* 1 = 0.656224 loss)
I0620 18:43:50.027895 17263 solver.cpp:57] Iteration 46000, loss = 0.175461
I0620 18:43:50.027933 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.175461 (* 1 = 0.175461 loss)
I0620 18:43:50.027940 17263 sgd_solver.cpp:43] Iteration 46000, lr = 0.1
I0620 18:57:15.864634 17263 solver.cpp:174] Iteration 46400, Testing net (#0)
I0620 18:58:21.194057 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.845
I0620 18:58:21.194257 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.540548 (* 1 = 0.540548 loss)
I0620 18:58:23.146024 17263 solver.cpp:57] Iteration 46400, loss = 0.219253
I0620 18:58:23.146064 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.219253 (* 1 = 0.219253 loss)
I0620 18:58:23.146071 17263 sgd_solver.cpp:43] Iteration 46400, lr = 0.1
I0620 19:11:47.808264 17263 solver.cpp:174] Iteration 46800, Testing net (#0)
I0620 19:12:53.014040 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.872734
I0620 19:12:53.014246 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.429549 (* 1 = 0.429549 loss)
I0620 19:12:55.132486 17263 solver.cpp:57] Iteration 46800, loss = 0.218128
I0620 19:12:55.132529 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.218128 (* 1 = 0.218128 loss)
I0620 19:12:55.132539 17263 sgd_solver.cpp:43] Iteration 46800, lr = 0.1
I0620 19:26:19.569845 17263 solver.cpp:174] Iteration 47200, Testing net (#0)
I0620 19:27:24.844743 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.828672
I0620 19:27:24.844954 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.610913 (* 1 = 0.610913 loss)
I0620 19:27:26.933871 17263 solver.cpp:57] Iteration 47200, loss = 0.180406
I0620 19:27:26.933917 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.180406 (* 1 = 0.180406 loss)
I0620 19:27:26.933933 17263 sgd_solver.cpp:43] Iteration 47200, lr = 0.1
I0620 19:40:53.887423 17263 solver.cpp:174] Iteration 47600, Testing net (#0)
I0620 19:41:59.184429 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.887656
I0620 19:41:59.184640 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.327005 (* 1 = 0.327005 loss)
I0620 19:42:01.203925 17263 solver.cpp:57] Iteration 47600, loss = 0.165508
I0620 19:42:01.203965 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.165508 (* 1 = 0.165508 loss)
I0620 19:42:01.203974 17263 sgd_solver.cpp:43] Iteration 47600, lr = 0.1
I0620 19:55:27.595012 17263 solver.cpp:174] Iteration 48000, Testing net (#0)
I0620 19:56:32.905527 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.893984
I0620 19:56:32.918424 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.332574 (* 1 = 0.332574 loss)
I0620 19:56:35.011468 17263 solver.cpp:57] Iteration 48000, loss = 0.123797
I0620 19:56:35.011505 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.123797 (* 1 = 0.123797 loss)
I0620 19:56:35.011513 17263 sgd_solver.cpp:43] Iteration 48000, lr = 0.1
I0620 20:10:04.436452 17263 solver.cpp:174] Iteration 48400, Testing net (#0)
I0620 20:11:09.703202 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.850859
I0620 20:11:09.703415 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.506222 (* 1 = 0.506222 loss)
I0620 20:11:11.822211 17263 solver.cpp:57] Iteration 48400, loss = 0.11128
I0620 20:11:11.822252 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.11128 (* 1 = 0.11128 loss)
I0620 20:11:11.822258 17263 sgd_solver.cpp:43] Iteration 48400, lr = 0.1
I0620 20:24:37.397392 17263 solver.cpp:174] Iteration 48800, Testing net (#0)
I0620 20:25:42.701563 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.833828
I0620 20:25:42.701788 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.59787 (* 1 = 0.59787 loss)
I0620 20:25:44.679183 17263 solver.cpp:57] Iteration 48800, loss = 0.212706
I0620 20:25:44.679226 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.212706 (* 1 = 0.212706 loss)
I0620 20:25:44.679235 17263 sgd_solver.cpp:43] Iteration 48800, lr = 0.1
I0620 20:39:08.905493 17263 solver.cpp:174] Iteration 49200, Testing net (#0)
I0620 20:40:14.214427 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.878828
I0620 20:40:14.214721 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.407502 (* 1 = 0.407502 loss)
I0620 20:40:15.909936 17263 solver.cpp:57] Iteration 49200, loss = 0.286917
I0620 20:40:15.909984 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.286917 (* 1 = 0.286917 loss)
I0620 20:40:15.909993 17263 sgd_solver.cpp:43] Iteration 49200, lr = 0.1
I0620 20:53:41.231040 17263 solver.cpp:174] Iteration 49600, Testing net (#0)
I0620 20:54:46.501704 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.811719
I0620 20:54:46.501840 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.583232 (* 1 = 0.583232 loss)
I0620 20:54:48.341833 17263 solver.cpp:57] Iteration 49600, loss = 0.121356
I0620 20:54:48.341881 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.121356 (* 1 = 0.121356 loss)
I0620 20:54:48.341892 17263 sgd_solver.cpp:43] Iteration 49600, lr = 0.1
I0620 21:08:14.898207 17263 solver.cpp:174] Iteration 50000, Testing net (#0)
I0620 21:09:20.185947 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.888281
I0620 21:09:20.186137 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.342147 (* 1 = 0.342147 loss)
I0620 21:09:21.957351 17263 solver.cpp:57] Iteration 50000, loss = 0.171618
I0620 21:09:21.957404 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.171617 (* 1 = 0.171617 loss)
I0620 21:09:21.957414 17263 sgd_solver.cpp:43] Iteration 50000, lr = 0.1
I0620 21:22:51.506860 17263 solver.cpp:174] Iteration 50400, Testing net (#0)
I0620 21:23:56.774969 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.848437
I0620 21:23:56.775189 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.509149 (* 1 = 0.509149 loss)
I0620 21:23:58.614554 17263 solver.cpp:57] Iteration 50400, loss = 0.249944
I0620 21:23:58.614599 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.249944 (* 1 = 0.249944 loss)
I0620 21:23:58.614611 17263 sgd_solver.cpp:43] Iteration 50400, lr = 0.1
I0620 21:37:25.707264 17263 solver.cpp:174] Iteration 50800, Testing net (#0)
I0620 21:38:30.967011 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.866484
I0620 21:38:30.967228 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.414719 (* 1 = 0.414719 loss)
I0620 21:38:33.007349 17263 solver.cpp:57] Iteration 50800, loss = 0.125303
I0620 21:38:33.007395 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.125303 (* 1 = 0.125303 loss)
I0620 21:38:33.007405 17263 sgd_solver.cpp:43] Iteration 50800, lr = 0.1
I0620 21:52:01.159198 17263 solver.cpp:174] Iteration 51200, Testing net (#0)
I0620 21:53:06.378703 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.870625
I0620 21:53:06.378900 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.425173 (* 1 = 0.425173 loss)
I0620 21:53:08.468565 17263 solver.cpp:57] Iteration 51200, loss = 0.155335
I0620 21:53:08.468624 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.155335 (* 1 = 0.155335 loss)
I0620 21:53:08.468636 17263 sgd_solver.cpp:43] Iteration 51200, lr = 0.1
I0620 22:06:31.153815 17263 solver.cpp:174] Iteration 51600, Testing net (#0)
I0620 22:07:36.501364 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.871875
I0620 22:07:36.501600 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.432778 (* 1 = 0.432778 loss)
I0620 22:07:38.382014 17263 solver.cpp:57] Iteration 51600, loss = 0.104145
I0620 22:07:38.382052 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.104144 (* 1 = 0.104144 loss)
I0620 22:07:38.382061 17263 sgd_solver.cpp:43] Iteration 51600, lr = 0.1
I0620 22:21:03.870728 17263 solver.cpp:174] Iteration 52000, Testing net (#0)
I0620 22:22:09.181681 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.865625
I0620 22:22:09.181872 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.430352 (* 1 = 0.430352 loss)
I0620 22:22:11.342573 17263 solver.cpp:57] Iteration 52000, loss = 0.147965
I0620 22:22:11.342643 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.147965 (* 1 = 0.147965 loss)
I0620 22:22:11.342660 17263 sgd_solver.cpp:43] Iteration 52000, lr = 0.1
I0620 22:35:39.891705 17263 solver.cpp:174] Iteration 52400, Testing net (#0)
I0620 22:36:45.184816 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.865781
I0620 22:36:45.185000 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.441234 (* 1 = 0.441234 loss)
I0620 22:36:47.346904 17263 solver.cpp:57] Iteration 52400, loss = 0.156765
I0620 22:36:47.346943 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.156765 (* 1 = 0.156765 loss)
I0620 22:36:47.346951 17263 sgd_solver.cpp:43] Iteration 52400, lr = 0.1
I0620 22:50:16.043748 17263 solver.cpp:174] Iteration 52800, Testing net (#0)
I0620 22:51:21.331955 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.845234
I0620 22:51:21.332159 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.528387 (* 1 = 0.528387 loss)
I0620 22:51:23.150347 17263 solver.cpp:57] Iteration 52800, loss = 0.293049
I0620 22:51:23.150419 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.293049 (* 1 = 0.293049 loss)
I0620 22:51:23.150436 17263 sgd_solver.cpp:43] Iteration 52800, lr = 0.1
I0620 23:04:49.503845 17263 solver.cpp:174] Iteration 53200, Testing net (#0)
I0620 23:05:54.825597 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.829844
I0620 23:05:54.825806 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.595775 (* 1 = 0.595775 loss)
I0620 23:05:56.866667 17263 solver.cpp:57] Iteration 53200, loss = 0.13856
I0620 23:05:56.866706 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.13856 (* 1 = 0.13856 loss)
I0620 23:05:56.866722 17263 sgd_solver.cpp:43] Iteration 53200, lr = 0.1
I0620 23:19:22.471150 17263 solver.cpp:174] Iteration 53600, Testing net (#0)
I0620 23:20:27.717021 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.862656
I0620 23:20:27.717247 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.440325 (* 1 = 0.440325 loss)
I0620 23:20:29.762506 17263 solver.cpp:57] Iteration 53600, loss = 0.147736
I0620 23:20:29.762552 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.147736 (* 1 = 0.147736 loss)
I0620 23:20:29.762559 17263 sgd_solver.cpp:43] Iteration 53600, lr = 0.1
I0620 23:33:59.897336 17263 solver.cpp:174] Iteration 54000, Testing net (#0)
I0620 23:35:05.200273 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.812734
I0620 23:35:05.200510 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.641956 (* 1 = 0.641956 loss)
I0620 23:35:07.111117 17263 solver.cpp:57] Iteration 54000, loss = 0.241539
I0620 23:35:07.111166 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.241539 (* 1 = 0.241539 loss)
I0620 23:35:07.111174 17263 sgd_solver.cpp:43] Iteration 54000, lr = 0.1
I0620 23:48:33.411804 17263 solver.cpp:174] Iteration 54400, Testing net (#0)
I0620 23:49:38.693903 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.834766
I0620 23:49:38.694147 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.581888 (* 1 = 0.581888 loss)
I0620 23:49:40.742183 17263 solver.cpp:57] Iteration 54400, loss = 0.287807
I0620 23:49:40.742226 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.287807 (* 1 = 0.287807 loss)
I0620 23:49:40.742235 17263 sgd_solver.cpp:43] Iteration 54400, lr = 0.1
I0621 00:03:05.767894 17263 solver.cpp:174] Iteration 54800, Testing net (#0)
I0621 00:04:11.015837 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.872422
I0621 00:04:11.016039 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.416646 (* 1 = 0.416646 loss)
I0621 00:04:13.206003 17263 solver.cpp:57] Iteration 54800, loss = 0.144141
I0621 00:04:13.206045 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.144141 (* 1 = 0.144141 loss)
I0621 00:04:13.206053 17263 sgd_solver.cpp:43] Iteration 54800, lr = 0.1
I0621 00:17:37.359494 17263 solver.cpp:174] Iteration 55200, Testing net (#0)
I0621 00:18:42.646579 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.882187
I0621 00:18:42.646792 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.371969 (* 1 = 0.371969 loss)
I0621 00:18:44.732095 17263 solver.cpp:57] Iteration 55200, loss = 0.256578
I0621 00:18:44.732136 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.256578 (* 1 = 0.256578 loss)
I0621 00:18:44.732143 17263 sgd_solver.cpp:43] Iteration 55200, lr = 0.1
I0621 00:32:10.138974 17263 solver.cpp:174] Iteration 55600, Testing net (#0)
I0621 00:33:15.374671 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.810078
I0621 00:33:15.374902 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.638937 (* 1 = 0.638937 loss)
I0621 00:33:17.377249 17263 solver.cpp:57] Iteration 55600, loss = 0.242276
I0621 00:33:17.377295 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.242276 (* 1 = 0.242276 loss)
I0621 00:33:17.377305 17263 sgd_solver.cpp:43] Iteration 55600, lr = 0.1
I0621 00:46:48.241955 17263 solver.cpp:174] Iteration 56000, Testing net (#0)
I0621 00:47:53.521880 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.858828
I0621 00:47:53.522081 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.430781 (* 1 = 0.430781 loss)
I0621 00:47:55.516357 17263 solver.cpp:57] Iteration 56000, loss = 0.143247
I0621 00:47:55.516399 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.143247 (* 1 = 0.143247 loss)
I0621 00:47:55.516407 17263 sgd_solver.cpp:43] Iteration 56000, lr = 0.1
I0621 01:01:18.584260 17263 solver.cpp:174] Iteration 56400, Testing net (#0)
I0621 01:02:23.886505 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.847422
I0621 01:02:23.886844 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.501565 (* 1 = 0.501565 loss)
I0621 01:02:25.975764 17263 solver.cpp:57] Iteration 56400, loss = 0.121243
I0621 01:02:25.975821 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.121243 (* 1 = 0.121243 loss)
I0621 01:02:25.975832 17263 sgd_solver.cpp:43] Iteration 56400, lr = 0.1
I0621 01:15:50.300895 17263 solver.cpp:174] Iteration 56800, Testing net (#0)
I0621 01:16:55.657655 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.835859
I0621 01:16:55.657867 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.57216 (* 1 = 0.57216 loss)
I0621 01:16:57.747669 17263 solver.cpp:57] Iteration 56800, loss = 0.187397
I0621 01:16:57.747707 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.187397 (* 1 = 0.187397 loss)
I0621 01:16:57.747714 17263 sgd_solver.cpp:43] Iteration 56800, lr = 0.1
I0621 01:30:19.894978 17263 solver.cpp:174] Iteration 57200, Testing net (#0)
I0621 01:31:25.193526 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.863047
I0621 01:31:25.193729 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.45746 (* 1 = 0.45746 loss)
I0621 01:31:27.210222 17263 solver.cpp:57] Iteration 57200, loss = 0.174765
I0621 01:31:27.210261 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.174765 (* 1 = 0.174765 loss)
I0621 01:31:27.210269 17263 sgd_solver.cpp:43] Iteration 57200, lr = 0.1
I0621 01:44:52.408030 17263 solver.cpp:174] Iteration 57600, Testing net (#0)
I0621 01:45:57.634780 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.887891
I0621 01:45:57.634932 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.343887 (* 1 = 0.343887 loss)
I0621 01:45:59.579180 17263 solver.cpp:57] Iteration 57600, loss = 0.1636
I0621 01:45:59.579224 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.1636 (* 1 = 0.1636 loss)
I0621 01:45:59.579233 17263 sgd_solver.cpp:43] Iteration 57600, lr = 0.1
I0621 01:59:27.027528 17263 solver.cpp:174] Iteration 58000, Testing net (#0)
I0621 02:00:32.322391 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.869844
I0621 02:00:32.322608 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.401692 (* 1 = 0.401692 loss)
I0621 02:00:34.157896 17263 solver.cpp:57] Iteration 58000, loss = 0.188032
I0621 02:00:34.157940 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.188032 (* 1 = 0.188032 loss)
I0621 02:00:34.157950 17263 sgd_solver.cpp:43] Iteration 58000, lr = 0.1
I0621 02:13:57.857224 17263 solver.cpp:174] Iteration 58400, Testing net (#0)
I0621 02:15:03.144718 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.853906
I0621 02:15:03.158469 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.462598 (* 1 = 0.462598 loss)
I0621 02:15:05.308902 17263 solver.cpp:57] Iteration 58400, loss = 0.307075
I0621 02:15:05.308940 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.307075 (* 1 = 0.307075 loss)
I0621 02:15:05.308948 17263 sgd_solver.cpp:43] Iteration 58400, lr = 0.1
I0621 02:28:32.311187 17263 solver.cpp:174] Iteration 58800, Testing net (#0)
I0621 02:29:37.617712 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.890312
I0621 02:29:37.617918 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.342971 (* 1 = 0.342971 loss)
I0621 02:29:39.744773 17263 solver.cpp:57] Iteration 58800, loss = 0.0645276
I0621 02:29:39.744822 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0645274 (* 1 = 0.0645274 loss)
I0621 02:29:39.744835 17263 sgd_solver.cpp:43] Iteration 58800, lr = 0.1
I0621 02:43:06.474515 17263 solver.cpp:174] Iteration 59200, Testing net (#0)
I0621 02:44:11.794401 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.847109
I0621 02:44:11.794606 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.524293 (* 1 = 0.524293 loss)
I0621 02:44:13.672528 17263 solver.cpp:57] Iteration 59200, loss = 0.166908
I0621 02:44:13.672588 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.166907 (* 1 = 0.166907 loss)
I0621 02:44:13.672597 17263 sgd_solver.cpp:43] Iteration 59200, lr = 0.1
I0621 02:57:39.145498 17263 solver.cpp:174] Iteration 59600, Testing net (#0)
I0621 02:58:44.458215 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.878594
I0621 02:58:44.458438 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.385641 (* 1 = 0.385641 loss)
I0621 02:58:46.512151 17263 solver.cpp:57] Iteration 59600, loss = 0.158013
I0621 02:58:46.512192 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.158013 (* 1 = 0.158013 loss)
I0621 02:58:46.512199 17263 sgd_solver.cpp:43] Iteration 59600, lr = 0.1
I0621 03:12:13.488133 17263 solver.cpp:174] Iteration 60000, Testing net (#0)
I0621 03:13:18.733515 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.888281
I0621 03:13:18.746418 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.352499 (* 1 = 0.352499 loss)
I0621 03:13:20.605518 17263 solver.cpp:57] Iteration 60000, loss = 0.208277
I0621 03:13:20.605557 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.208277 (* 1 = 0.208277 loss)
I0621 03:13:20.605567 17263 sgd_solver.cpp:43] Iteration 60000, lr = 0.1
I0621 03:26:45.704880 17263 solver.cpp:174] Iteration 60400, Testing net (#0)
I0621 03:27:50.976073 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.889609
I0621 03:27:50.976302 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.347642 (* 1 = 0.347642 loss)
I0621 03:27:52.958835 17263 solver.cpp:57] Iteration 60400, loss = 0.0938584
I0621 03:27:52.958881 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0938581 (* 1 = 0.0938581 loss)
I0621 03:27:52.958890 17263 sgd_solver.cpp:43] Iteration 60400, lr = 0.1
I0621 03:41:18.193578 17263 solver.cpp:174] Iteration 60800, Testing net (#0)
I0621 03:42:23.442565 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.854062
I0621 03:42:23.442735 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.447913 (* 1 = 0.447913 loss)
I0621 03:42:25.281566 17263 solver.cpp:57] Iteration 60800, loss = 0.35746
I0621 03:42:25.281615 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.35746 (* 1 = 0.35746 loss)
I0621 03:42:25.281625 17263 sgd_solver.cpp:43] Iteration 60800, lr = 0.1
I0621 03:55:50.207294 17263 solver.cpp:174] Iteration 61200, Testing net (#0)
I0621 03:56:55.583266 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.868047
I0621 03:56:55.583493 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.412276 (* 1 = 0.412276 loss)
I0621 03:56:57.466953 17263 solver.cpp:57] Iteration 61200, loss = 0.212823
I0621 03:56:57.466994 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.212823 (* 1 = 0.212823 loss)
I0621 03:56:57.467000 17263 sgd_solver.cpp:43] Iteration 61200, lr = 0.1
I0621 04:10:24.163235 17263 solver.cpp:174] Iteration 61600, Testing net (#0)
I0621 04:11:29.427466 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.718594
I0621 04:11:29.427690 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 1.0265 (* 1 = 1.0265 loss)
I0621 04:11:31.338892 17263 solver.cpp:57] Iteration 61600, loss = 0.127771
I0621 04:11:31.338949 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.127771 (* 1 = 0.127771 loss)
I0621 04:11:31.338963 17263 sgd_solver.cpp:43] Iteration 61600, lr = 0.1
I0621 04:24:57.290822 17263 solver.cpp:174] Iteration 62000, Testing net (#0)
I0621 04:26:02.528077 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.828125
I0621 04:26:02.528256 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.606957 (* 1 = 0.606957 loss)
I0621 04:26:04.564182 17263 solver.cpp:57] Iteration 62000, loss = 0.15901
I0621 04:26:04.564231 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.159009 (* 1 = 0.159009 loss)
I0621 04:26:04.564241 17263 sgd_solver.cpp:43] Iteration 62000, lr = 0.1
I0621 04:39:33.467460 17263 solver.cpp:174] Iteration 62400, Testing net (#0)
I0621 04:40:38.755664 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.814766
I0621 04:40:38.755872 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.644236 (* 1 = 0.644236 loss)
I0621 04:40:40.765714 17263 solver.cpp:57] Iteration 62400, loss = 0.145543
I0621 04:40:40.765756 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.145542 (* 1 = 0.145542 loss)
I0621 04:40:40.765763 17263 sgd_solver.cpp:43] Iteration 62400, lr = 0.1
I0621 04:54:09.105469 17263 solver.cpp:174] Iteration 62800, Testing net (#0)
I0621 04:55:14.376123 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.865781
I0621 04:55:14.376318 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.432488 (* 1 = 0.432488 loss)
I0621 04:55:16.316536 17263 solver.cpp:57] Iteration 62800, loss = 0.253131
I0621 04:55:16.316578 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.25313 (* 1 = 0.25313 loss)
I0621 04:55:16.316586 17263 sgd_solver.cpp:43] Iteration 62800, lr = 0.1
I0621 05:08:43.822590 17263 solver.cpp:174] Iteration 63200, Testing net (#0)
I0621 05:09:49.124977 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.843984
I0621 05:09:49.125205 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.573708 (* 1 = 0.573708 loss)
I0621 05:09:51.281868 17263 solver.cpp:57] Iteration 63200, loss = 0.134326
I0621 05:09:51.281908 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.134326 (* 1 = 0.134326 loss)
I0621 05:09:51.281915 17263 sgd_solver.cpp:43] Iteration 63200, lr = 0.1
I0621 05:23:18.498584 17263 solver.cpp:174] Iteration 63600, Testing net (#0)
I0621 05:24:23.778084 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.819297
I0621 05:24:23.778286 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.627987 (* 1 = 0.627987 loss)
I0621 05:24:25.833544 17263 solver.cpp:57] Iteration 63600, loss = 0.245526
I0621 05:24:25.833588 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.245526 (* 1 = 0.245526 loss)
I0621 05:24:25.833597 17263 sgd_solver.cpp:43] Iteration 63600, lr = 0.1
I0621 05:37:55.340219 17263 solver.cpp:174] Iteration 64000, Testing net (#0)
I0621 05:39:00.654111 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.876484
I0621 05:39:00.654275 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.385043 (* 1 = 0.385043 loss)
I0621 05:39:02.483098 17263 solver.cpp:57] Iteration 64000, loss = 0.184975
I0621 05:39:02.483139 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.184975 (* 1 = 0.184975 loss)
I0621 05:39:02.483147 17263 sgd_solver.cpp:43] Iteration 64000, lr = 0.1
I0621 05:52:24.934229 17263 solver.cpp:174] Iteration 64400, Testing net (#0)
I0621 05:53:30.193059 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.858437
I0621 05:53:30.193270 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.466495 (* 1 = 0.466495 loss)
I0621 05:53:32.001607 17263 solver.cpp:57] Iteration 64400, loss = 0.183103
I0621 05:53:32.001659 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.183103 (* 1 = 0.183103 loss)
I0621 05:53:32.001669 17263 sgd_solver.cpp:43] Iteration 64400, lr = 0.1
I0621 06:06:55.148993 17263 solver.cpp:174] Iteration 64800, Testing net (#0)
I0621 06:08:00.463495 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.8775
I0621 06:08:00.463690 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.385281 (* 1 = 0.385281 loss)
I0621 06:08:02.581043 17263 solver.cpp:57] Iteration 64800, loss = 0.108942
I0621 06:08:02.581079 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.108942 (* 1 = 0.108942 loss)
I0621 06:08:02.581084 17263 sgd_solver.cpp:43] Iteration 64800, lr = 0.1
I0621 06:21:26.625764 17263 solver.cpp:174] Iteration 65200, Testing net (#0)
I0621 06:22:31.933432 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.826953
I0621 06:22:31.933634 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.631267 (* 1 = 0.631267 loss)
I0621 06:22:33.945765 17263 solver.cpp:57] Iteration 65200, loss = 0.285078
I0621 06:22:33.945808 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.285078 (* 1 = 0.285078 loss)
I0621 06:22:33.945816 17263 sgd_solver.cpp:43] Iteration 65200, lr = 0.1
I0621 06:36:02.484792 17263 solver.cpp:174] Iteration 65600, Testing net (#0)
I0621 06:37:07.830860 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.845312
I0621 06:37:07.831074 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.527642 (* 1 = 0.527642 loss)
I0621 06:37:09.806069 17263 solver.cpp:57] Iteration 65600, loss = 0.181485
I0621 06:37:09.806112 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.181484 (* 1 = 0.181484 loss)
I0621 06:37:09.806119 17263 sgd_solver.cpp:43] Iteration 65600, lr = 0.1
I0621 06:50:36.477821 17263 solver.cpp:174] Iteration 66000, Testing net (#0)
I0621 06:51:41.793539 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.813906
I0621 06:51:41.793730 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.628845 (* 1 = 0.628845 loss)
I0621 06:51:43.874721 17263 solver.cpp:57] Iteration 66000, loss = 0.193951
I0621 06:51:43.874766 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.19395 (* 1 = 0.19395 loss)
I0621 06:51:43.874776 17263 sgd_solver.cpp:43] Iteration 66000, lr = 0.1
I0621 07:05:13.470841 17263 solver.cpp:174] Iteration 66400, Testing net (#0)
I0621 07:06:18.726126 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.887031
I0621 07:06:18.726330 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.357417 (* 1 = 0.357417 loss)
I0621 07:06:20.869321 17263 solver.cpp:57] Iteration 66400, loss = 0.113713
I0621 07:06:20.869374 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.113713 (* 1 = 0.113713 loss)
I0621 07:06:20.869384 17263 sgd_solver.cpp:43] Iteration 66400, lr = 0.1
I0621 07:19:47.191648 17263 solver.cpp:174] Iteration 66800, Testing net (#0)
I0621 07:20:52.474288 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.834531
I0621 07:20:52.474524 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.569856 (* 1 = 0.569856 loss)
I0621 07:20:54.312561 17263 solver.cpp:57] Iteration 66800, loss = 0.140312
I0621 07:20:54.312599 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.140312 (* 1 = 0.140312 loss)
I0621 07:20:54.312607 17263 sgd_solver.cpp:43] Iteration 66800, lr = 0.1
I0621 07:34:20.195513 17263 solver.cpp:174] Iteration 67200, Testing net (#0)
I0621 07:35:25.507169 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.874609
I0621 07:35:25.507369 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.407842 (* 1 = 0.407842 loss)
I0621 07:35:27.590034 17263 solver.cpp:57] Iteration 67200, loss = 0.148446
I0621 07:35:27.590083 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.148446 (* 1 = 0.148446 loss)
I0621 07:35:27.590092 17263 sgd_solver.cpp:43] Iteration 67200, lr = 0.1
I0621 07:48:50.654377 17263 solver.cpp:174] Iteration 67600, Testing net (#0)
I0621 07:49:55.996742 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.812813
I0621 07:49:55.996978 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.609436 (* 1 = 0.609436 loss)
I0621 07:49:58.095880 17263 solver.cpp:57] Iteration 67600, loss = 0.138005
I0621 07:49:58.095921 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.138005 (* 1 = 0.138005 loss)
I0621 07:49:58.095929 17263 sgd_solver.cpp:43] Iteration 67600, lr = 0.1
I0621 08:03:24.768571 17263 solver.cpp:174] Iteration 68000, Testing net (#0)
I0621 08:04:30.081701 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.846016
I0621 08:04:30.081904 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.55037 (* 1 = 0.55037 loss)
I0621 08:04:31.850579 17263 solver.cpp:57] Iteration 68000, loss = 0.220434
I0621 08:04:31.850620 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.220434 (* 1 = 0.220434 loss)
I0621 08:04:31.850628 17263 sgd_solver.cpp:43] Iteration 68000, lr = 0.1
I0621 08:18:01.967388 17263 solver.cpp:174] Iteration 68400, Testing net (#0)
I0621 08:19:07.248152 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.854688
I0621 08:19:07.248365 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.553382 (* 1 = 0.553382 loss)
I0621 08:19:09.194120 17263 solver.cpp:57] Iteration 68400, loss = 0.106479
I0621 08:19:09.194164 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.106479 (* 1 = 0.106479 loss)
I0621 08:19:09.194175 17263 sgd_solver.cpp:43] Iteration 68400, lr = 0.1
I0621 08:32:36.006718 17263 solver.cpp:174] Iteration 68800, Testing net (#0)
I0621 08:33:41.397713 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.888281
I0621 08:33:41.397909 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.367021 (* 1 = 0.367021 loss)
I0621 08:33:43.273062 17263 solver.cpp:57] Iteration 68800, loss = 0.164404
I0621 08:33:43.273111 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.164404 (* 1 = 0.164404 loss)
I0621 08:33:43.273121 17263 sgd_solver.cpp:43] Iteration 68800, lr = 0.1
I0621 08:47:11.053246 17263 solver.cpp:174] Iteration 69200, Testing net (#0)
I0621 08:48:16.343022 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.814375
I0621 08:48:16.343231 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.678518 (* 1 = 0.678518 loss)
I0621 08:48:18.174311 17263 solver.cpp:57] Iteration 69200, loss = 0.198464
I0621 08:48:18.174361 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.198464 (* 1 = 0.198464 loss)
I0621 08:48:18.174371 17263 sgd_solver.cpp:43] Iteration 69200, lr = 0.1
I0621 09:01:41.703016 17263 solver.cpp:174] Iteration 69600, Testing net (#0)
I0621 09:02:46.966301 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.864844
I0621 09:02:46.966536 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.43701 (* 1 = 0.43701 loss)
I0621 09:02:48.987215 17263 solver.cpp:57] Iteration 69600, loss = 0.120603
I0621 09:02:48.987264 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.120603 (* 1 = 0.120603 loss)
I0621 09:02:48.987277 17263 sgd_solver.cpp:43] Iteration 69600, lr = 0.1
I0621 09:16:14.197271 17263 solver.cpp:174] Iteration 70000, Testing net (#0)
I0621 09:17:19.515892 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.851797
I0621 09:17:19.516093 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.486793 (* 1 = 0.486793 loss)
I0621 09:17:21.667031 17263 solver.cpp:57] Iteration 70000, loss = 0.251886
I0621 09:17:21.667073 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.251886 (* 1 = 0.251886 loss)
I0621 09:17:21.667081 17263 sgd_solver.cpp:43] Iteration 70000, lr = 0.1
I0621 09:30:50.980309 17263 solver.cpp:174] Iteration 70400, Testing net (#0)
I0621 09:31:56.231523 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.805
I0621 09:31:56.231751 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.715013 (* 1 = 0.715013 loss)
I0621 09:31:58.312428 17263 solver.cpp:57] Iteration 70400, loss = 0.236017
I0621 09:31:58.312472 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.236017 (* 1 = 0.236017 loss)
I0621 09:31:58.312481 17263 sgd_solver.cpp:43] Iteration 70400, lr = 0.1
I0621 09:45:25.068843 17263 solver.cpp:174] Iteration 70800, Testing net (#0)
I0621 09:46:30.357589 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.892422
I0621 09:46:30.357792 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.32356 (* 1 = 0.32356 loss)
I0621 09:46:32.481058 17263 solver.cpp:57] Iteration 70800, loss = 0.118977
I0621 09:46:32.481109 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.118977 (* 1 = 0.118977 loss)
I0621 09:46:32.481119 17263 sgd_solver.cpp:43] Iteration 70800, lr = 0.1
I0621 09:59:54.822396 17263 solver.cpp:174] Iteration 71200, Testing net (#0)
I0621 10:01:00.186775 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.869453
I0621 10:01:00.187024 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.451717 (* 1 = 0.451717 loss)
I0621 10:01:02.129773 17263 solver.cpp:57] Iteration 71200, loss = 0.212453
I0621 10:01:02.129812 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.212453 (* 1 = 0.212453 loss)
I0621 10:01:02.129820 17263 sgd_solver.cpp:43] Iteration 71200, lr = 0.1
I0621 10:14:26.580682 17263 solver.cpp:174] Iteration 71600, Testing net (#0)
I0621 10:15:31.884321 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.863828
I0621 10:15:31.884512 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.429934 (* 1 = 0.429934 loss)
I0621 10:15:34.077648 17263 solver.cpp:57] Iteration 71600, loss = 0.144306
I0621 10:15:34.077693 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.144306 (* 1 = 0.144306 loss)
I0621 10:15:34.077700 17263 sgd_solver.cpp:43] Iteration 71600, lr = 0.1
I0621 10:28:56.360913 17263 solver.cpp:174] Iteration 72000, Testing net (#0)
I0621 10:30:01.622568 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.87
I0621 10:30:01.622778 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.393421 (* 1 = 0.393421 loss)
I0621 10:30:03.570328 17263 solver.cpp:57] Iteration 72000, loss = 0.204747
I0621 10:30:03.570368 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.204747 (* 1 = 0.204747 loss)
I0621 10:30:03.570379 17263 sgd_solver.cpp:43] Iteration 72000, lr = 0.1
I0621 10:43:32.175379 17263 solver.cpp:174] Iteration 72400, Testing net (#0)
I0621 10:44:37.446498 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.885391
I0621 10:44:37.446715 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.337621 (* 1 = 0.337621 loss)
I0621 10:44:39.383294 17263 solver.cpp:57] Iteration 72400, loss = 0.28233
I0621 10:44:39.383337 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.28233 (* 1 = 0.28233 loss)
I0621 10:44:39.383343 17263 sgd_solver.cpp:43] Iteration 72400, lr = 0.1
I0621 10:58:04.243943 17263 solver.cpp:174] Iteration 72800, Testing net (#0)
I0621 10:59:09.417753 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.788672
I0621 10:59:09.417948 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.850867 (* 1 = 0.850867 loss)
I0621 10:59:11.397524 17263 solver.cpp:57] Iteration 72800, loss = 0.310061
I0621 10:59:11.397563 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.310061 (* 1 = 0.310061 loss)
I0621 10:59:11.397572 17263 sgd_solver.cpp:43] Iteration 72800, lr = 0.1
I0621 11:12:36.141305 17263 solver.cpp:174] Iteration 73200, Testing net (#0)
I0621 11:13:41.445760 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.884687
I0621 11:13:41.445986 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.370294 (* 1 = 0.370294 loss)
I0621 11:13:43.349340 17263 solver.cpp:57] Iteration 73200, loss = 0.134289
I0621 11:13:43.349387 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.134289 (* 1 = 0.134289 loss)
I0621 11:13:43.349396 17263 sgd_solver.cpp:43] Iteration 73200, lr = 0.1
I0621 11:27:11.232447 17263 solver.cpp:174] Iteration 73600, Testing net (#0)
I0621 11:28:16.570073 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.871328
I0621 11:28:16.570263 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.406571 (* 1 = 0.406571 loss)
I0621 11:28:18.520128 17263 solver.cpp:57] Iteration 73600, loss = 0.114429
I0621 11:28:18.520177 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.114429 (* 1 = 0.114429 loss)
I0621 11:28:18.520187 17263 sgd_solver.cpp:43] Iteration 73600, lr = 0.1
I0621 11:41:43.828104 17263 solver.cpp:174] Iteration 74000, Testing net (#0)
I0621 11:42:49.138700 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.887891
I0621 11:42:49.138873 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.340277 (* 1 = 0.340277 loss)
I0621 11:42:51.222944 17263 solver.cpp:57] Iteration 74000, loss = 0.142443
I0621 11:42:51.222986 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.142443 (* 1 = 0.142443 loss)
I0621 11:42:51.223004 17263 sgd_solver.cpp:43] Iteration 74000, lr = 0.1
I0621 11:56:16.421082 17263 solver.cpp:174] Iteration 74400, Testing net (#0)
I0621 11:57:21.700175 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.891563
I0621 11:57:21.700371 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.34934 (* 1 = 0.34934 loss)
I0621 11:57:24.006916 17263 solver.cpp:57] Iteration 74400, loss = 0.11695
I0621 11:57:24.006969 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.11695 (* 1 = 0.11695 loss)
I0621 11:57:24.006980 17263 sgd_solver.cpp:43] Iteration 74400, lr = 0.1
I0621 12:10:53.560458 17263 solver.cpp:174] Iteration 74800, Testing net (#0)
I0621 12:11:58.878782 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.894609
I0621 12:11:58.878996 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.337108 (* 1 = 0.337108 loss)
I0621 12:12:00.825968 17263 solver.cpp:57] Iteration 74800, loss = 0.201337
I0621 12:12:00.826006 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.201337 (* 1 = 0.201337 loss)
I0621 12:12:00.826014 17263 sgd_solver.cpp:43] Iteration 74800, lr = 0.1
I0621 12:25:29.225334 17263 solver.cpp:174] Iteration 75200, Testing net (#0)
I0621 12:26:34.507845 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.853359
I0621 12:26:34.508018 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.507121 (* 1 = 0.507121 loss)
I0621 12:26:36.523002 17263 solver.cpp:57] Iteration 75200, loss = 0.209922
I0621 12:26:36.523044 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.209922 (* 1 = 0.209922 loss)
I0621 12:26:36.523054 17263 sgd_solver.cpp:43] Iteration 75200, lr = 0.1
I0621 12:40:06.116801 17263 solver.cpp:174] Iteration 75600, Testing net (#0)
I0621 12:41:11.426304 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.867031
I0621 12:41:11.426517 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.43548 (* 1 = 0.43548 loss)
I0621 12:41:13.408954 17263 solver.cpp:57] Iteration 75600, loss = 0.173776
I0621 12:41:13.408995 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.173776 (* 1 = 0.173776 loss)
I0621 12:41:13.409003 17263 sgd_solver.cpp:43] Iteration 75600, lr = 0.1
I0621 12:54:38.777493 17263 solver.cpp:174] Iteration 76000, Testing net (#0)
I0621 12:55:44.011569 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.838516
I0621 12:55:44.011780 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.508716 (* 1 = 0.508716 loss)
I0621 12:55:46.130606 17263 solver.cpp:57] Iteration 76000, loss = 0.0716656
I0621 12:55:46.130645 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0716655 (* 1 = 0.0716655 loss)
I0621 12:55:46.130652 17263 sgd_solver.cpp:43] Iteration 76000, lr = 0.1
I0621 13:09:11.188519 17263 solver.cpp:174] Iteration 76400, Testing net (#0)
I0621 13:10:16.446741 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.852734
I0621 13:10:16.446975 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.559811 (* 1 = 0.559811 loss)
I0621 13:10:18.279644 17263 solver.cpp:57] Iteration 76400, loss = 0.189316
I0621 13:10:18.279692 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.189316 (* 1 = 0.189316 loss)
I0621 13:10:18.279700 17263 sgd_solver.cpp:43] Iteration 76400, lr = 0.1
I0621 13:23:41.906994 17263 solver.cpp:174] Iteration 76800, Testing net (#0)
I0621 13:24:47.203757 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.872656
I0621 13:24:47.203826 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.424165 (* 1 = 0.424165 loss)
I0621 13:24:49.192375 17263 solver.cpp:57] Iteration 76800, loss = 0.155
I0621 13:24:49.192416 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.155 (* 1 = 0.155 loss)
I0621 13:24:49.192425 17263 sgd_solver.cpp:43] Iteration 76800, lr = 0.1
I0621 13:38:20.112617 17263 solver.cpp:174] Iteration 77200, Testing net (#0)
I0621 13:39:25.327973 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.835938
I0621 13:39:25.328182 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.53421 (* 1 = 0.53421 loss)
I0621 13:39:27.362627 17263 solver.cpp:57] Iteration 77200, loss = 0.203917
I0621 13:39:27.362664 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.203917 (* 1 = 0.203917 loss)
I0621 13:39:27.362673 17263 sgd_solver.cpp:43] Iteration 77200, lr = 0.1
I0621 13:52:50.977705 17263 solver.cpp:174] Iteration 77600, Testing net (#0)
I0621 13:53:56.265528 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.858203
I0621 13:53:56.265732 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.509103 (* 1 = 0.509103 loss)
I0621 13:53:58.323495 17263 solver.cpp:57] Iteration 77600, loss = 0.142577
I0621 13:53:58.323549 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.142577 (* 1 = 0.142577 loss)
I0621 13:53:58.323557 17263 sgd_solver.cpp:43] Iteration 77600, lr = 0.1
I0621 14:07:26.046304 17263 solver.cpp:174] Iteration 78000, Testing net (#0)
I0621 14:08:31.342443 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.798281
I0621 14:08:31.342633 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.664851 (* 1 = 0.664851 loss)
I0621 14:08:33.123631 17263 solver.cpp:57] Iteration 78000, loss = 0.120787
I0621 14:08:33.123669 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.120787 (* 1 = 0.120787 loss)
I0621 14:08:33.123678 17263 sgd_solver.cpp:43] Iteration 78000, lr = 0.1
I0621 14:21:59.224081 17263 solver.cpp:174] Iteration 78400, Testing net (#0)
I0621 14:23:04.517151 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.818125
I0621 14:23:04.526397 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.616784 (* 1 = 0.616784 loss)
I0621 14:23:06.789590 17263 solver.cpp:57] Iteration 78400, loss = 0.150752
I0621 14:23:06.789633 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.150752 (* 1 = 0.150752 loss)
I0621 14:23:06.789643 17263 sgd_solver.cpp:43] Iteration 78400, lr = 0.1
I0621 14:36:34.768645 17263 solver.cpp:174] Iteration 78800, Testing net (#0)
I0621 14:37:40.027604 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.858359
I0621 14:37:40.027809 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.473532 (* 1 = 0.473532 loss)
I0621 14:37:41.527050 17263 solver.cpp:57] Iteration 78800, loss = 0.569495
I0621 14:37:41.527092 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.569495 (* 1 = 0.569495 loss)
I0621 14:37:41.527101 17263 sgd_solver.cpp:43] Iteration 78800, lr = 0.1
I0621 14:51:11.201223 17263 solver.cpp:174] Iteration 79200, Testing net (#0)
I0621 14:52:16.507243 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.853828
I0621 14:52:16.507439 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.511388 (* 1 = 0.511388 loss)
I0621 14:52:18.632156 17263 solver.cpp:57] Iteration 79200, loss = 0.0914568
I0621 14:52:18.632195 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0914568 (* 1 = 0.0914568 loss)
I0621 14:52:18.632202 17263 sgd_solver.cpp:43] Iteration 79200, lr = 0.1
I0621 15:05:44.087532 17263 solver.cpp:174] Iteration 79600, Testing net (#0)
I0621 15:06:49.419018 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.880156
I0621 15:06:49.419229 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.39858 (* 1 = 0.39858 loss)
I0621 15:06:51.362360 17263 solver.cpp:57] Iteration 79600, loss = 0.208718
I0621 15:06:51.362401 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.208719 (* 1 = 0.208719 loss)
I0621 15:06:51.362408 17263 sgd_solver.cpp:43] Iteration 79600, lr = 0.1
I0621 15:20:19.596276 17263 solver.cpp:174] Iteration 80000, Testing net (#0)
I0621 15:21:24.927809 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.862969
I0621 15:21:24.938417 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.43658 (* 1 = 0.43658 loss)
I0621 15:21:26.876767 17263 solver.cpp:57] Iteration 80000, loss = 0.105721
I0621 15:21:26.876802 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.105721 (* 1 = 0.105721 loss)
I0621 15:21:26.876814 17263 sgd_solver.cpp:43] Iteration 80000, lr = 0.1
I0621 15:34:54.193686 17263 solver.cpp:174] Iteration 80400, Testing net (#0)
I0621 15:35:59.498324 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.864453
I0621 15:35:59.498551 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.539177 (* 1 = 0.539177 loss)
I0621 15:36:01.553938 17263 solver.cpp:57] Iteration 80400, loss = 0.0609549
I0621 15:36:01.553980 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0609549 (* 1 = 0.0609549 loss)
I0621 15:36:01.553987 17263 sgd_solver.cpp:43] Iteration 80400, lr = 0.1
I0621 15:49:29.189312 17263 solver.cpp:174] Iteration 80800, Testing net (#0)
I0621 15:50:34.499428 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.838906
I0621 15:50:34.499634 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.592742 (* 1 = 0.592742 loss)
I0621 15:50:36.402994 17263 solver.cpp:57] Iteration 80800, loss = 0.235289
I0621 15:50:36.403033 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.235289 (* 1 = 0.235289 loss)
I0621 15:50:36.403041 17263 sgd_solver.cpp:43] Iteration 80800, lr = 0.1
I0621 16:04:01.338047 17263 solver.cpp:174] Iteration 81200, Testing net (#0)
I0621 16:05:06.645300 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.831094
I0621 16:05:06.645503 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.534459 (* 1 = 0.534459 loss)
I0621 16:05:08.490866 17263 solver.cpp:57] Iteration 81200, loss = 0.152979
I0621 16:05:08.490912 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.152979 (* 1 = 0.152979 loss)
I0621 16:05:08.490923 17263 sgd_solver.cpp:43] Iteration 81200, lr = 0.1
I0621 16:18:38.247014 17263 solver.cpp:174] Iteration 81600, Testing net (#0)
I0621 16:19:43.434155 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.830547
I0621 16:19:43.435798 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.594701 (* 1 = 0.594701 loss)
I0621 16:19:45.513288 17263 solver.cpp:57] Iteration 81600, loss = 0.136911
I0621 16:19:45.513339 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.136911 (* 1 = 0.136911 loss)
I0621 16:19:45.513350 17263 sgd_solver.cpp:43] Iteration 81600, lr = 0.1
I0621 16:33:13.865388 17263 solver.cpp:174] Iteration 82000, Testing net (#0)
I0621 16:34:19.193006 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.873359
I0621 16:34:19.193228 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.374726 (* 1 = 0.374726 loss)
I0621 16:34:20.997431 17263 solver.cpp:57] Iteration 82000, loss = 0.216074
I0621 16:34:20.997473 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.216074 (* 1 = 0.216074 loss)
I0621 16:34:20.997485 17263 sgd_solver.cpp:43] Iteration 82000, lr = 0.1
I0621 16:47:47.927433 17263 solver.cpp:174] Iteration 82400, Testing net (#0)
I0621 16:48:53.272938 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.874062
I0621 16:48:53.273146 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.409168 (* 1 = 0.409168 loss)
I0621 16:48:55.183773 17263 solver.cpp:57] Iteration 82400, loss = 0.141189
I0621 16:48:55.183830 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.141189 (* 1 = 0.141189 loss)
I0621 16:48:55.183842 17263 sgd_solver.cpp:43] Iteration 82400, lr = 0.1
I0621 17:02:20.437672 17263 solver.cpp:174] Iteration 82800, Testing net (#0)
I0621 17:03:25.804694 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.855547
I0621 17:03:25.804894 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.515242 (* 1 = 0.515242 loss)
I0621 17:03:27.395004 17263 solver.cpp:57] Iteration 82800, loss = 0.229501
I0621 17:03:27.395043 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.229501 (* 1 = 0.229501 loss)
I0621 17:03:27.395071 17263 sgd_solver.cpp:43] Iteration 82800, lr = 0.1
I0621 17:16:52.802026 17263 solver.cpp:174] Iteration 83200, Testing net (#0)
I0621 17:17:58.060226 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.876562
I0621 17:17:58.060421 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.404198 (* 1 = 0.404198 loss)
I0621 17:17:59.760573 17263 solver.cpp:57] Iteration 83200, loss = 0.210526
I0621 17:17:59.760614 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.210527 (* 1 = 0.210527 loss)
I0621 17:17:59.760623 17263 sgd_solver.cpp:43] Iteration 83200, lr = 0.1
I0621 17:31:26.545820 17263 solver.cpp:174] Iteration 83600, Testing net (#0)
I0621 17:32:31.809213 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.864062
I0621 17:32:31.809451 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.464911 (* 1 = 0.464911 loss)
I0621 17:32:33.617370 17263 solver.cpp:57] Iteration 83600, loss = 0.176415
I0621 17:32:33.617411 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.176415 (* 1 = 0.176415 loss)
I0621 17:32:33.617420 17263 sgd_solver.cpp:43] Iteration 83600, lr = 0.1
I0621 17:46:02.826258 17263 solver.cpp:174] Iteration 84000, Testing net (#0)
I0621 17:47:08.137994 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.885078
I0621 17:47:08.138223 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.378906 (* 1 = 0.378906 loss)
I0621 17:47:10.160444 17263 solver.cpp:57] Iteration 84000, loss = 0.0968183
I0621 17:47:10.160482 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0968185 (* 1 = 0.0968185 loss)
I0621 17:47:10.160491 17263 sgd_solver.cpp:43] Iteration 84000, lr = 0.1
I0621 18:00:35.661983 17263 solver.cpp:174] Iteration 84400, Testing net (#0)
I0621 18:01:40.950214 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.851406
I0621 18:01:40.962427 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.498578 (* 1 = 0.498578 loss)
I0621 18:01:42.983199 17263 solver.cpp:57] Iteration 84400, loss = 0.161031
I0621 18:01:42.983237 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.161031 (* 1 = 0.161031 loss)
I0621 18:01:42.983247 17263 sgd_solver.cpp:43] Iteration 84400, lr = 0.1
I0621 18:15:10.807001 17263 solver.cpp:174] Iteration 84800, Testing net (#0)
I0621 18:16:16.087728 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.882422
I0621 18:16:16.087936 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.383381 (* 1 = 0.383381 loss)
I0621 18:16:18.120034 17263 solver.cpp:57] Iteration 84800, loss = 0.126141
I0621 18:16:18.120085 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.126141 (* 1 = 0.126141 loss)
I0621 18:16:18.120095 17263 sgd_solver.cpp:43] Iteration 84800, lr = 0.1
I0621 18:29:47.964916 17263 solver.cpp:174] Iteration 85200, Testing net (#0)
I0621 18:30:53.224863 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.817969
I0621 18:30:53.225057 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.746759 (* 1 = 0.746759 loss)
I0621 18:30:54.964273 17263 solver.cpp:57] Iteration 85200, loss = 0.212261
I0621 18:30:54.964315 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.212261 (* 1 = 0.212261 loss)
I0621 18:30:54.964323 17263 sgd_solver.cpp:43] Iteration 85200, lr = 0.1
I0621 18:44:17.874712 17263 solver.cpp:174] Iteration 85600, Testing net (#0)
I0621 18:45:23.197146 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.840078
I0621 18:45:23.197340 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.571876 (* 1 = 0.571876 loss)
I0621 18:45:25.424471 17263 solver.cpp:57] Iteration 85600, loss = 0.170922
I0621 18:45:25.424516 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.170923 (* 1 = 0.170923 loss)
I0621 18:45:25.424525 17263 sgd_solver.cpp:43] Iteration 85600, lr = 0.1
I0621 18:58:51.967171 17263 solver.cpp:174] Iteration 86000, Testing net (#0)
I0621 18:59:57.264133 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.832109
I0621 18:59:57.264348 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.546111 (* 1 = 0.546111 loss)
I0621 18:59:59.242393 17263 solver.cpp:57] Iteration 86000, loss = 0.107807
I0621 18:59:59.242454 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.107808 (* 1 = 0.107808 loss)
I0621 18:59:59.242463 17263 sgd_solver.cpp:43] Iteration 86000, lr = 0.1
I0621 19:13:27.943379 17263 solver.cpp:174] Iteration 86400, Testing net (#0)
I0621 19:14:33.283195 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.87375
I0621 19:14:33.283427 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.37809 (* 1 = 0.37809 loss)
I0621 19:14:35.194557 17263 solver.cpp:57] Iteration 86400, loss = 0.170423
I0621 19:14:35.194597 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.170423 (* 1 = 0.170423 loss)
I0621 19:14:35.194605 17263 sgd_solver.cpp:43] Iteration 86400, lr = 0.1
I0621 19:28:04.024405 17263 solver.cpp:174] Iteration 86800, Testing net (#0)
I0621 19:29:09.289724 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.845391
I0621 19:29:09.289949 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.511992 (* 1 = 0.511992 loss)
I0621 19:29:11.339125 17263 solver.cpp:57] Iteration 86800, loss = 0.14863
I0621 19:29:11.339179 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.14863 (* 1 = 0.14863 loss)
I0621 19:29:11.339189 17263 sgd_solver.cpp:43] Iteration 86800, lr = 0.1
I0621 19:42:37.154579 17263 solver.cpp:174] Iteration 87200, Testing net (#0)
I0621 19:43:42.419009 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.880781
I0621 19:43:42.419236 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.365819 (* 1 = 0.365819 loss)
I0621 19:43:44.500918 17263 solver.cpp:57] Iteration 87200, loss = 0.107511
I0621 19:43:44.500960 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.107511 (* 1 = 0.107511 loss)
I0621 19:43:44.500969 17263 sgd_solver.cpp:43] Iteration 87200, lr = 0.1
I0621 19:57:10.200392 17263 solver.cpp:174] Iteration 87600, Testing net (#0)
I0621 19:58:15.523828 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.815859
I0621 19:58:15.524022 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.601988 (* 1 = 0.601988 loss)
I0621 19:58:17.570845 17263 solver.cpp:57] Iteration 87600, loss = 0.117429
I0621 19:58:17.570894 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.11743 (* 1 = 0.11743 loss)
I0621 19:58:17.570904 17263 sgd_solver.cpp:43] Iteration 87600, lr = 0.1
I0621 20:11:39.538245 17263 solver.cpp:174] Iteration 88000, Testing net (#0)
I0621 20:12:44.797427 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.896797
I0621 20:12:44.797612 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.323454 (* 1 = 0.323454 loss)
I0621 20:12:46.701057 17263 solver.cpp:57] Iteration 88000, loss = 0.253268
I0621 20:12:46.701102 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.253268 (* 1 = 0.253268 loss)
I0621 20:12:46.701109 17263 sgd_solver.cpp:43] Iteration 88000, lr = 0.1
I0621 20:26:15.812352 17263 solver.cpp:174] Iteration 88400, Testing net (#0)
I0621 20:27:21.094919 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.77625
I0621 20:27:21.098505 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.771798 (* 1 = 0.771798 loss)
I0621 20:27:23.129118 17263 solver.cpp:57] Iteration 88400, loss = 0.152347
I0621 20:27:23.129156 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.152347 (* 1 = 0.152347 loss)
I0621 20:27:23.129165 17263 sgd_solver.cpp:43] Iteration 88400, lr = 0.1
I0621 20:40:46.817770 17263 solver.cpp:174] Iteration 88800, Testing net (#0)
I0621 20:41:52.126087 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.875234
I0621 20:41:52.126286 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.41124 (* 1 = 0.41124 loss)
I0621 20:41:54.109798 17263 solver.cpp:57] Iteration 88800, loss = 0.176673
I0621 20:41:54.109856 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.176674 (* 1 = 0.176674 loss)
I0621 20:41:54.109871 17263 sgd_solver.cpp:43] Iteration 88800, lr = 0.1
I0621 20:55:19.410737 17263 solver.cpp:174] Iteration 89200, Testing net (#0)
I0621 20:56:24.684445 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.847188
I0621 20:56:24.684619 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.488489 (* 1 = 0.488489 loss)
I0621 20:56:26.728812 17263 solver.cpp:57] Iteration 89200, loss = 0.14251
I0621 20:56:26.728847 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.14251 (* 1 = 0.14251 loss)
I0621 20:56:26.728857 17263 sgd_solver.cpp:43] Iteration 89200, lr = 0.1
I0621 21:09:55.536381 17263 solver.cpp:174] Iteration 89600, Testing net (#0)
I0621 21:11:00.826345 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.845391
I0621 21:11:00.826567 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.534346 (* 1 = 0.534346 loss)
I0621 21:11:02.762914 17263 solver.cpp:57] Iteration 89600, loss = 0.19807
I0621 21:11:02.762956 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.19807 (* 1 = 0.19807 loss)
I0621 21:11:02.762964 17263 sgd_solver.cpp:43] Iteration 89600, lr = 0.1
I0621 21:24:29.380944 17263 solver.cpp:174] Iteration 90000, Testing net (#0)
I0621 21:25:34.683863 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.843672
I0621 21:25:34.684070 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.591291 (* 1 = 0.591291 loss)
I0621 21:25:36.558272 17263 solver.cpp:57] Iteration 90000, loss = 0.289544
I0621 21:25:36.558326 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.289544 (* 1 = 0.289544 loss)
I0621 21:25:36.558337 17263 sgd_solver.cpp:43] Iteration 90000, lr = 0.1
I0621 21:39:05.108419 17263 solver.cpp:174] Iteration 90400, Testing net (#0)
I0621 21:40:10.436326 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.817656
I0621 21:40:10.436522 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.609644 (* 1 = 0.609644 loss)
I0621 21:40:12.517477 17263 solver.cpp:57] Iteration 90400, loss = 0.159379
I0621 21:40:12.517519 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.159379 (* 1 = 0.159379 loss)
I0621 21:40:12.517527 17263 sgd_solver.cpp:43] Iteration 90400, lr = 0.1
I0621 21:53:37.915560 17263 solver.cpp:174] Iteration 90800, Testing net (#0)
I0621 21:54:43.197326 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.854844
I0621 21:54:43.197520 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.493189 (* 1 = 0.493189 loss)
I0621 21:54:45.243652 17263 solver.cpp:57] Iteration 90800, loss = 0.193315
I0621 21:54:45.243695 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.193315 (* 1 = 0.193315 loss)
I0621 21:54:45.243705 17263 sgd_solver.cpp:43] Iteration 90800, lr = 0.1
I0621 22:08:10.014379 17263 solver.cpp:174] Iteration 91200, Testing net (#0)
I0621 22:09:15.313796 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.783828
I0621 22:09:15.318410 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.793417 (* 1 = 0.793417 loss)
I0621 22:09:17.442865 17263 solver.cpp:57] Iteration 91200, loss = 0.11404
I0621 22:09:17.442906 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.11404 (* 1 = 0.11404 loss)
I0621 22:09:17.442915 17263 sgd_solver.cpp:43] Iteration 91200, lr = 0.1
I0621 22:22:44.081034 17263 solver.cpp:174] Iteration 91600, Testing net (#0)
I0621 22:23:49.363700 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.842969
I0621 22:23:49.363911 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.554443 (* 1 = 0.554443 loss)
I0621 22:23:51.378721 17263 solver.cpp:57] Iteration 91600, loss = 0.171638
I0621 22:23:51.378772 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.171639 (* 1 = 0.171639 loss)
I0621 22:23:51.378782 17263 sgd_solver.cpp:43] Iteration 91600, lr = 0.1
I0621 22:37:19.590191 17263 solver.cpp:174] Iteration 92000, Testing net (#0)
I0621 22:38:24.892271 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.744766
I0621 22:38:24.892503 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 1.0376 (* 1 = 1.0376 loss)
I0621 22:38:26.901068 17263 solver.cpp:57] Iteration 92000, loss = 0.14555
I0621 22:38:26.901140 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.14555 (* 1 = 0.14555 loss)
I0621 22:38:26.901154 17263 sgd_solver.cpp:43] Iteration 92000, lr = 0.1
I0621 22:51:49.385311 17263 solver.cpp:174] Iteration 92400, Testing net (#0)
I0621 22:52:54.644443 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.885703
I0621 22:52:54.644665 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.390753 (* 1 = 0.390753 loss)
I0621 22:52:56.332013 17263 solver.cpp:57] Iteration 92400, loss = 0.674807
I0621 22:52:56.332056 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.674807 (* 1 = 0.674807 loss)
I0621 22:52:56.332063 17263 sgd_solver.cpp:43] Iteration 92400, lr = 0.1
I0621 23:06:17.565280 17263 solver.cpp:174] Iteration 92800, Testing net (#0)
I0621 23:07:22.933506 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.877813
I0621 23:07:22.933718 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.407778 (* 1 = 0.407778 loss)
I0621 23:07:25.155567 17263 solver.cpp:57] Iteration 92800, loss = 0.0898135
I0621 23:07:25.155618 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0898137 (* 1 = 0.0898137 loss)
I0621 23:07:25.155628 17263 sgd_solver.cpp:43] Iteration 92800, lr = 0.1
I0621 23:20:53.806232 17263 solver.cpp:174] Iteration 93200, Testing net (#0)
I0621 23:21:59.130967 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.888984
I0621 23:21:59.131160 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.358507 (* 1 = 0.358507 loss)
I0621 23:22:00.862763 17263 solver.cpp:57] Iteration 93200, loss = 0.282261
I0621 23:22:00.862804 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.282262 (* 1 = 0.282262 loss)
I0621 23:22:00.862812 17263 sgd_solver.cpp:43] Iteration 93200, lr = 0.1
I0621 23:35:29.919139 17263 solver.cpp:174] Iteration 93600, Testing net (#0)
I0621 23:36:35.274312 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.873984
I0621 23:36:35.274505 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.415137 (* 1 = 0.415137 loss)
I0621 23:36:37.218104 17263 solver.cpp:57] Iteration 93600, loss = 0.217151
I0621 23:36:37.218155 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.217151 (* 1 = 0.217151 loss)
I0621 23:36:37.218164 17263 sgd_solver.cpp:43] Iteration 93600, lr = 0.1
I0621 23:50:03.054865 17263 solver.cpp:174] Iteration 94000, Testing net (#0)
I0621 23:51:08.368999 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.828281
I0621 23:51:08.369217 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.580216 (* 1 = 0.580216 loss)
I0621 23:51:10.454171 17263 solver.cpp:57] Iteration 94000, loss = 0.18979
I0621 23:51:10.454216 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.18979 (* 1 = 0.18979 loss)
I0621 23:51:10.454226 17263 sgd_solver.cpp:43] Iteration 94000, lr = 0.1
I0622 00:04:35.451011 17263 solver.cpp:174] Iteration 94400, Testing net (#0)
I0622 00:05:40.748137 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.886094
I0622 00:05:40.748360 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.394972 (* 1 = 0.394972 loss)
I0622 00:05:42.866948 17263 solver.cpp:57] Iteration 94400, loss = 0.171476
I0622 00:05:42.866989 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.171476 (* 1 = 0.171476 loss)
I0622 00:05:42.866997 17263 sgd_solver.cpp:43] Iteration 94400, lr = 0.1
I0622 00:19:13.006537 17263 solver.cpp:174] Iteration 94800, Testing net (#0)
I0622 00:20:18.313359 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.865937
I0622 00:20:18.313565 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.436465 (* 1 = 0.436465 loss)
I0622 00:20:20.436033 17263 solver.cpp:57] Iteration 94800, loss = 0.147141
I0622 00:20:20.436077 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.147141 (* 1 = 0.147141 loss)
I0622 00:20:20.436085 17263 sgd_solver.cpp:43] Iteration 94800, lr = 0.1
I0622 00:33:46.085149 17263 solver.cpp:174] Iteration 95200, Testing net (#0)
I0622 00:34:51.439137 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.888984
I0622 00:34:51.439348 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.356425 (* 1 = 0.356425 loss)
I0622 00:34:53.357151 17263 solver.cpp:57] Iteration 95200, loss = 0.132919
I0622 00:34:53.357192 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.132919 (* 1 = 0.132919 loss)
I0622 00:34:53.357200 17263 sgd_solver.cpp:43] Iteration 95200, lr = 0.1
I0622 00:48:17.443464 17263 solver.cpp:174] Iteration 95600, Testing net (#0)
I0622 00:49:22.825323 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.873828
I0622 00:49:22.825533 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.443386 (* 1 = 0.443386 loss)
I0622 00:49:24.771469 17263 solver.cpp:57] Iteration 95600, loss = 0.345181
I0622 00:49:24.771517 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.345182 (* 1 = 0.345182 loss)
I0622 00:49:24.771525 17263 sgd_solver.cpp:43] Iteration 95600, lr = 0.1
I0622 01:02:49.038295 17263 solver.cpp:174] Iteration 96000, Testing net (#0)
I0622 01:03:54.343360 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.880938
I0622 01:03:54.343590 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.394607 (* 1 = 0.394607 loss)
I0622 01:03:56.363240 17263 solver.cpp:57] Iteration 96000, loss = 0.241538
I0622 01:03:56.363283 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.241539 (* 1 = 0.241539 loss)
I0622 01:03:56.363294 17263 sgd_solver.cpp:43] Iteration 96000, lr = 0.1
I0622 01:17:28.602951 17263 solver.cpp:174] Iteration 96400, Testing net (#0)
I0622 01:18:33.945636 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.863906
I0622 01:18:33.950446 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.454347 (* 1 = 0.454347 loss)
I0622 01:18:36.074815 17263 solver.cpp:57] Iteration 96400, loss = 0.175764
I0622 01:18:36.074864 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.175764 (* 1 = 0.175764 loss)
I0622 01:18:36.074877 17263 sgd_solver.cpp:43] Iteration 96400, lr = 0.1
I0622 01:32:00.570830 17263 solver.cpp:174] Iteration 96800, Testing net (#0)
I0622 01:33:05.818234 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.861016
I0622 01:33:05.818383 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.469041 (* 1 = 0.469041 loss)
I0622 01:33:07.792660 17263 solver.cpp:57] Iteration 96800, loss = 0.0508445
I0622 01:33:07.792711 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0508448 (* 1 = 0.0508448 loss)
I0622 01:33:07.792719 17263 sgd_solver.cpp:43] Iteration 96800, lr = 0.1
I0622 01:46:37.066741 17263 solver.cpp:174] Iteration 97200, Testing net (#0)
I0622 01:47:42.418005 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.863906
I0622 01:47:42.418216 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.46778 (* 1 = 0.46778 loss)
I0622 01:47:44.328197 17263 solver.cpp:57] Iteration 97200, loss = 0.334237
I0622 01:47:44.328238 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.334238 (* 1 = 0.334238 loss)
I0622 01:47:44.328248 17263 sgd_solver.cpp:43] Iteration 97200, lr = 0.1
I0622 02:01:10.255384 17263 solver.cpp:174] Iteration 97600, Testing net (#0)
I0622 02:02:15.610954 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.831172
I0622 02:02:15.611598 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.705508 (* 1 = 0.705508 loss)
I0622 02:02:17.397586 17263 solver.cpp:57] Iteration 97600, loss = 0.178631
I0622 02:02:17.397637 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.178631 (* 1 = 0.178631 loss)
I0622 02:02:17.397647 17263 sgd_solver.cpp:43] Iteration 97600, lr = 0.1
I0622 02:15:40.335999 17263 solver.cpp:174] Iteration 98000, Testing net (#0)
I0622 02:16:45.605938 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.857109
I0622 02:16:45.606174 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.452565 (* 1 = 0.452565 loss)
I0622 02:16:47.372791 17263 solver.cpp:57] Iteration 98000, loss = 0.274777
I0622 02:16:47.372843 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.274777 (* 1 = 0.274777 loss)
I0622 02:16:47.372851 17263 sgd_solver.cpp:43] Iteration 98000, lr = 0.1
I0622 02:30:11.719300 17263 solver.cpp:174] Iteration 98400, Testing net (#0)
I0622 02:31:16.982338 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.892422
I0622 02:31:16.982547 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.353105 (* 1 = 0.353105 loss)
I0622 02:31:18.885006 17263 solver.cpp:57] Iteration 98400, loss = 0.369913
I0622 02:31:18.885056 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.369913 (* 1 = 0.369913 loss)
I0622 02:31:18.885064 17263 sgd_solver.cpp:43] Iteration 98400, lr = 0.1
I0622 02:44:44.535501 17263 solver.cpp:174] Iteration 98800, Testing net (#0)
I0622 02:45:49.850479 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.872734
I0622 02:45:49.858392 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.399728 (* 1 = 0.399728 loss)
I0622 02:45:51.650609 17263 solver.cpp:57] Iteration 98800, loss = 0.294829
I0622 02:45:51.650648 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.294829 (* 1 = 0.294829 loss)
I0622 02:45:51.650658 17263 sgd_solver.cpp:43] Iteration 98800, lr = 0.1
I0622 02:59:19.849900 17263 solver.cpp:174] Iteration 99200, Testing net (#0)
I0622 03:00:25.094013 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.809453
I0622 03:00:25.094229 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.644881 (* 1 = 0.644881 loss)
I0622 03:00:27.140450 17263 solver.cpp:57] Iteration 99200, loss = 0.138974
I0622 03:00:27.140491 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.138975 (* 1 = 0.138975 loss)
I0622 03:00:27.140499 17263 sgd_solver.cpp:43] Iteration 99200, lr = 0.1
I0622 03:13:52.678813 17263 solver.cpp:174] Iteration 99600, Testing net (#0)
I0622 03:14:58.014189 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.895547
I0622 03:14:58.014436 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.334952 (* 1 = 0.334952 loss)
I0622 03:14:59.898906 17263 solver.cpp:57] Iteration 99600, loss = 0.155583
I0622 03:14:59.898949 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.155584 (* 1 = 0.155584 loss)
I0622 03:14:59.898959 17263 sgd_solver.cpp:43] Iteration 99600, lr = 0.1
I0622 03:28:27.074658 17263 solver.cpp:174] Iteration 100000, Testing net (#0)
I0622 03:29:32.412784 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.843359
I0622 03:29:32.426434 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.557707 (* 1 = 0.557707 loss)
I0622 03:29:34.339365 17263 solver.cpp:57] Iteration 100000, loss = 0.144498
I0622 03:29:34.339414 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.144498 (* 1 = 0.144498 loss)
I0622 03:29:34.339426 17263 sgd_solver.cpp:109] MultiStep Status: Iteration 100000, step = 1
I0622 03:29:34.339429 17263 sgd_solver.cpp:43] Iteration 100000, lr = 0.01
I0622 03:42:59.704993 17263 solver.cpp:174] Iteration 100400, Testing net (#0)
I0622 03:44:05.074890 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.929297
I0622 03:44:05.075110 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.225741 (* 1 = 0.225741 loss)
I0622 03:44:07.017051 17263 solver.cpp:57] Iteration 100400, loss = 0.0781892
I0622 03:44:07.017097 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0781895 (* 1 = 0.0781895 loss)
I0622 03:44:07.017107 17263 sgd_solver.cpp:43] Iteration 100400, lr = 0.01
I0622 03:57:36.483732 17263 solver.cpp:174] Iteration 100800, Testing net (#0)
I0622 03:58:41.814549 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.933281
I0622 03:58:41.814769 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.210121 (* 1 = 0.210121 loss)
I0622 03:58:43.619856 17263 solver.cpp:57] Iteration 100800, loss = 0.101118
I0622 03:58:43.619941 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.101118 (* 1 = 0.101118 loss)
I0622 03:58:43.619961 17263 sgd_solver.cpp:43] Iteration 100800, lr = 0.01
I0622 04:12:11.813019 17263 solver.cpp:174] Iteration 101200, Testing net (#0)
I0622 04:13:17.110895 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.931953
I0622 04:13:17.111116 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.224726 (* 1 = 0.224726 loss)
I0622 04:13:19.094260 17263 solver.cpp:57] Iteration 101200, loss = 0.0658972
I0622 04:13:19.094310 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0658975 (* 1 = 0.0658975 loss)
I0622 04:13:19.094319 17263 sgd_solver.cpp:43] Iteration 101200, lr = 0.01
I0622 04:26:41.491355 17263 solver.cpp:174] Iteration 101600, Testing net (#0)
I0622 04:27:46.765818 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.937344
I0622 04:27:46.766010 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.213486 (* 1 = 0.213486 loss)
I0622 04:27:48.866377 17263 solver.cpp:57] Iteration 101600, loss = 0.0266746
I0622 04:27:48.866432 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0266749 (* 1 = 0.0266749 loss)
I0622 04:27:48.866441 17263 sgd_solver.cpp:43] Iteration 101600, lr = 0.01
I0622 04:41:15.379083 17263 solver.cpp:174] Iteration 102000, Testing net (#0)
I0622 04:42:20.690300 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.934375
I0622 04:42:20.690501 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.218484 (* 1 = 0.218484 loss)
I0622 04:42:22.809159 17263 solver.cpp:57] Iteration 102000, loss = 0.0755469
I0622 04:42:22.809206 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0755472 (* 1 = 0.0755472 loss)
I0622 04:42:22.809213 17263 sgd_solver.cpp:43] Iteration 102000, lr = 0.01
I0622 04:55:47.688611 17263 solver.cpp:174] Iteration 102400, Testing net (#0)
I0622 04:56:53.042912 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.93125
I0622 04:56:53.043134 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.24662 (* 1 = 0.24662 loss)
I0622 04:56:54.854235 17263 solver.cpp:57] Iteration 102400, loss = 0.0649679
I0622 04:56:54.854279 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0649681 (* 1 = 0.0649681 loss)
I0622 04:56:54.854286 17263 sgd_solver.cpp:43] Iteration 102400, lr = 0.01
I0622 05:10:23.075637 17263 solver.cpp:174] Iteration 102800, Testing net (#0)
I0622 05:11:28.407740 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.934844
I0622 05:11:28.407951 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.229349 (* 1 = 0.229349 loss)
I0622 05:11:30.557832 17263 solver.cpp:57] Iteration 102800, loss = 0.0410278
I0622 05:11:30.557888 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0410279 (* 1 = 0.0410279 loss)
I0622 05:11:30.557895 17263 sgd_solver.cpp:43] Iteration 102800, lr = 0.01
I0622 05:24:53.233239 17263 solver.cpp:174] Iteration 103200, Testing net (#0)
I0622 05:25:58.460844 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.935703
I0622 05:25:58.461004 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.232238 (* 1 = 0.232238 loss)
I0622 05:26:00.229455 17263 solver.cpp:57] Iteration 103200, loss = 0.0474074
I0622 05:26:00.229498 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0474076 (* 1 = 0.0474076 loss)
I0622 05:26:00.229508 17263 sgd_solver.cpp:43] Iteration 103200, lr = 0.01
I0622 05:39:24.804388 17263 solver.cpp:174] Iteration 103600, Testing net (#0)
I0622 05:40:30.095460 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.934297
I0622 05:40:30.095649 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.235391 (* 1 = 0.235391 loss)
I0622 05:40:32.234406 17263 solver.cpp:57] Iteration 103600, loss = 0.0280726
I0622 05:40:32.234452 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0280728 (* 1 = 0.0280728 loss)
I0622 05:40:32.234460 17263 sgd_solver.cpp:43] Iteration 103600, lr = 0.01
I0622 05:54:01.654106 17263 solver.cpp:174] Iteration 104000, Testing net (#0)
I0622 05:55:06.955255 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.936328
I0622 05:55:06.955447 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.225957 (* 1 = 0.225957 loss)
I0622 05:55:08.764096 17263 solver.cpp:57] Iteration 104000, loss = 0.0547138
I0622 05:55:08.764148 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.054714 (* 1 = 0.054714 loss)
I0622 05:55:08.764160 17263 sgd_solver.cpp:43] Iteration 104000, lr = 0.01
I0622 06:08:31.189898 17263 solver.cpp:174] Iteration 104400, Testing net (#0)
I0622 06:09:36.493995 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.937969
I0622 06:09:36.494240 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.230801 (* 1 = 0.230801 loss)
I0622 06:09:38.477901 17263 solver.cpp:57] Iteration 104400, loss = 0.0551521
I0622 06:09:38.477942 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0551523 (* 1 = 0.0551523 loss)
I0622 06:09:38.477952 17263 sgd_solver.cpp:43] Iteration 104400, lr = 0.01
I0622 06:23:02.562291 17263 solver.cpp:174] Iteration 104800, Testing net (#0)
I0622 06:24:07.864912 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.934766
I0622 06:24:07.865061 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.23131 (* 1 = 0.23131 loss)
I0622 06:24:09.943351 17263 solver.cpp:57] Iteration 104800, loss = 0.0387458
I0622 06:24:09.943399 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.038746 (* 1 = 0.038746 loss)
I0622 06:24:09.943423 17263 sgd_solver.cpp:43] Iteration 104800, lr = 0.01
I0622 06:37:32.691963 17263 solver.cpp:174] Iteration 105200, Testing net (#0)
I0622 06:38:37.979847 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.938047
I0622 06:38:37.980082 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.220393 (* 1 = 0.220393 loss)
I0622 06:38:40.031600 17263 solver.cpp:57] Iteration 105200, loss = 0.0317348
I0622 06:38:40.031642 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.031735 (* 1 = 0.031735 loss)
I0622 06:38:40.031651 17263 sgd_solver.cpp:43] Iteration 105200, lr = 0.01
I0622 06:52:05.022071 17263 solver.cpp:174] Iteration 105600, Testing net (#0)
I0622 06:53:10.314033 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.935625
I0622 06:53:10.326436 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.238014 (* 1 = 0.238014 loss)
I0622 06:53:12.445034 17263 solver.cpp:57] Iteration 105600, loss = 0.0200009
I0622 06:53:12.445071 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0200011 (* 1 = 0.0200011 loss)
I0622 06:53:12.445130 17263 sgd_solver.cpp:43] Iteration 105600, lr = 0.01
I0622 07:06:35.572927 17263 solver.cpp:174] Iteration 106000, Testing net (#0)
I0622 07:07:40.885462 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.936641
I0622 07:07:40.885684 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.237905 (* 1 = 0.237905 loss)
I0622 07:07:43.012424 17263 solver.cpp:57] Iteration 106000, loss = 0.0126578
I0622 07:07:43.012472 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.012658 (* 1 = 0.012658 loss)
I0622 07:07:43.012481 17263 sgd_solver.cpp:43] Iteration 106000, lr = 0.01
I0622 07:21:09.833003 17263 solver.cpp:174] Iteration 106400, Testing net (#0)
I0622 07:22:15.101825 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.941562
I0622 07:22:15.102061 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.22159 (* 1 = 0.22159 loss)
I0622 07:22:16.950127 17263 solver.cpp:57] Iteration 106400, loss = 0.0625567
I0622 07:22:16.950167 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0625568 (* 1 = 0.0625568 loss)
I0622 07:22:16.950179 17263 sgd_solver.cpp:43] Iteration 106400, lr = 0.01
I0622 07:35:39.948717 17263 solver.cpp:174] Iteration 106800, Testing net (#0)
I0622 07:36:45.211412 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.940078
I0622 07:36:45.211671 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.230268 (* 1 = 0.230268 loss)
I0622 07:36:47.366008 17263 solver.cpp:57] Iteration 106800, loss = 0.0282899
I0622 07:36:47.366056 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0282901 (* 1 = 0.0282901 loss)
I0622 07:36:47.366065 17263 sgd_solver.cpp:43] Iteration 106800, lr = 0.01
I0622 07:50:12.082298 17263 solver.cpp:174] Iteration 107200, Testing net (#0)
I0622 07:51:17.329727 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.936797
I0622 07:51:17.329908 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.247825 (* 1 = 0.247825 loss)
I0622 07:51:19.094539 17263 solver.cpp:57] Iteration 107200, loss = 0.0390882
I0622 07:51:19.094580 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0390883 (* 1 = 0.0390883 loss)
I0622 07:51:19.094588 17263 sgd_solver.cpp:43] Iteration 107200, lr = 0.01
I0622 08:04:45.574224 17263 solver.cpp:174] Iteration 107600, Testing net (#0)
I0622 08:05:50.766856 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.936406
I0622 08:05:50.767037 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.247974 (* 1 = 0.247974 loss)
I0622 08:05:52.704658 17263 solver.cpp:57] Iteration 107600, loss = 0.0117695
I0622 08:05:52.704713 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0117696 (* 1 = 0.0117696 loss)
I0622 08:05:52.704725 17263 sgd_solver.cpp:43] Iteration 107600, lr = 0.01
I0622 08:19:16.250210 17263 solver.cpp:174] Iteration 108000, Testing net (#0)
I0622 08:20:21.524430 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.943281
I0622 08:20:21.524636 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.227165 (* 1 = 0.227165 loss)
I0622 08:20:23.478080 17263 solver.cpp:57] Iteration 108000, loss = 0.0646033
I0622 08:20:23.478117 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0646034 (* 1 = 0.0646034 loss)
I0622 08:20:23.478124 17263 sgd_solver.cpp:43] Iteration 108000, lr = 0.01
I0622 08:33:49.307809 17263 solver.cpp:174] Iteration 108400, Testing net (#0)
I0622 08:34:54.568711 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.940547
I0622 08:34:54.568919 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.232898 (* 1 = 0.232898 loss)
I0622 08:34:56.510392 17263 solver.cpp:57] Iteration 108400, loss = 0.109343
I0622 08:34:56.510433 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.109343 (* 1 = 0.109343 loss)
I0622 08:34:56.510440 17263 sgd_solver.cpp:43] Iteration 108400, lr = 0.01
I0622 08:48:23.529610 17263 solver.cpp:174] Iteration 108800, Testing net (#0)
I0622 08:49:28.834512 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.941562
I0622 08:49:28.834713 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.228162 (* 1 = 0.228162 loss)
I0622 08:49:30.678756 17263 solver.cpp:57] Iteration 108800, loss = 0.0255135
I0622 08:49:30.678795 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0255137 (* 1 = 0.0255137 loss)
I0622 08:49:30.678804 17263 sgd_solver.cpp:43] Iteration 108800, lr = 0.01
I0622 09:02:55.819519 17263 solver.cpp:174] Iteration 109200, Testing net (#0)
I0622 09:04:01.091063 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.939141
I0622 09:04:01.091279 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.226712 (* 1 = 0.226712 loss)
I0622 09:04:03.215773 17263 solver.cpp:57] Iteration 109200, loss = 0.00467391
I0622 09:04:03.215816 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00467412 (* 1 = 0.00467412 loss)
I0622 09:04:03.215823 17263 sgd_solver.cpp:43] Iteration 109200, lr = 0.01
I0622 09:17:26.577519 17263 solver.cpp:174] Iteration 109600, Testing net (#0)
I0622 09:18:31.914228 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.93875
I0622 09:18:31.914443 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.241095 (* 1 = 0.241095 loss)
I0622 09:18:33.724973 17263 solver.cpp:57] Iteration 109600, loss = 0.0241229
I0622 09:18:33.725011 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0241231 (* 1 = 0.0241231 loss)
I0622 09:18:33.725028 17263 sgd_solver.cpp:43] Iteration 109600, lr = 0.01
I0622 09:32:02.438711 17263 solver.cpp:174] Iteration 110000, Testing net (#0)
I0622 09:33:07.659273 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.940625
I0622 09:33:07.659492 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.237857 (* 1 = 0.237857 loss)
I0622 09:33:09.664815 17263 solver.cpp:57] Iteration 110000, loss = 0.0465388
I0622 09:33:09.664858 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.046539 (* 1 = 0.046539 loss)
I0622 09:33:09.664867 17263 sgd_solver.cpp:43] Iteration 110000, lr = 0.01
I0622 09:46:29.354573 17263 solver.cpp:174] Iteration 110400, Testing net (#0)
I0622 09:47:34.629719 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.940313
I0622 09:47:34.629849 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.234501 (* 1 = 0.234501 loss)
I0622 09:47:36.368209 17263 solver.cpp:57] Iteration 110400, loss = 0.0927767
I0622 09:47:36.368252 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0927769 (* 1 = 0.0927769 loss)
I0622 09:47:36.368259 17263 sgd_solver.cpp:43] Iteration 110400, lr = 0.01
I0622 10:01:04.029889 17263 solver.cpp:174] Iteration 110800, Testing net (#0)
I0622 10:02:09.351577 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.941328
I0622 10:02:09.351788 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.228002 (* 1 = 0.228002 loss)
I0622 10:02:11.323072 17263 solver.cpp:57] Iteration 110800, loss = 0.00722079
I0622 10:02:11.323112 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00722102 (* 1 = 0.00722102 loss)
I0622 10:02:11.323119 17263 sgd_solver.cpp:43] Iteration 110800, lr = 0.01
I0622 10:15:38.498642 17263 solver.cpp:174] Iteration 111200, Testing net (#0)
I0622 10:16:43.785302 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.936406
I0622 10:16:43.785513 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.250908 (* 1 = 0.250908 loss)
I0622 10:16:45.903483 17263 solver.cpp:57] Iteration 111200, loss = 0.0111747
I0622 10:16:45.903525 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0111749 (* 1 = 0.0111749 loss)
I0622 10:16:45.903532 17263 sgd_solver.cpp:43] Iteration 111200, lr = 0.01
I0622 10:30:11.959136 17263 solver.cpp:174] Iteration 111600, Testing net (#0)
I0622 10:31:17.240037 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.938281
I0622 10:31:17.240207 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.249236 (* 1 = 0.249236 loss)
I0622 10:31:19.185784 17263 solver.cpp:57] Iteration 111600, loss = 0.0148491
I0622 10:31:19.185827 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0148493 (* 1 = 0.0148493 loss)
I0622 10:31:19.185837 17263 sgd_solver.cpp:43] Iteration 111600, lr = 0.01
I0622 10:44:44.231997 17263 solver.cpp:174] Iteration 112000, Testing net (#0)
I0622 10:45:49.555686 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.940391
I0622 10:45:49.556048 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.235137 (* 1 = 0.235137 loss)
I0622 10:45:51.599156 17263 solver.cpp:57] Iteration 112000, loss = 0.0268451
I0622 10:45:51.599215 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0268453 (* 1 = 0.0268453 loss)
I0622 10:45:51.599225 17263 sgd_solver.cpp:43] Iteration 112000, lr = 0.01
I0622 10:59:16.279155 17263 solver.cpp:174] Iteration 112400, Testing net (#0)
I0622 11:00:21.499716 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.9425
I0622 11:00:21.499907 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.231462 (* 1 = 0.231462 loss)
I0622 11:00:23.336091 17263 solver.cpp:57] Iteration 112400, loss = 0.015851
I0622 11:00:23.336135 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0158512 (* 1 = 0.0158512 loss)
I0622 11:00:23.336144 17263 sgd_solver.cpp:43] Iteration 112400, lr = 0.01
I0622 11:13:48.229641 17263 solver.cpp:174] Iteration 112800, Testing net (#0)
I0622 11:14:53.520480 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.938906
I0622 11:14:53.520684 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.255163 (* 1 = 0.255163 loss)
I0622 11:14:55.576167 17263 solver.cpp:57] Iteration 112800, loss = 0.0110695
I0622 11:14:55.576215 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0110696 (* 1 = 0.0110696 loss)
I0622 11:14:55.576225 17263 sgd_solver.cpp:43] Iteration 112800, lr = 0.01
I0622 11:28:20.024092 17263 solver.cpp:174] Iteration 113200, Testing net (#0)
I0622 11:29:25.310611 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.940469
I0622 11:29:25.310804 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.252081 (* 1 = 0.252081 loss)
I0622 11:29:27.230876 17263 solver.cpp:57] Iteration 113200, loss = 0.0166014
I0622 11:29:27.230916 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0166015 (* 1 = 0.0166015 loss)
I0622 11:29:27.230924 17263 sgd_solver.cpp:43] Iteration 113200, lr = 0.01
I0622 11:42:52.107363 17263 solver.cpp:174] Iteration 113600, Testing net (#0)
I0622 11:43:57.476549 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.940313
I0622 11:43:57.476766 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.251189 (* 1 = 0.251189 loss)
I0622 11:43:59.452914 17263 solver.cpp:57] Iteration 113600, loss = 0.0316937
I0622 11:43:59.452957 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0316939 (* 1 = 0.0316939 loss)
I0622 11:43:59.452968 17263 sgd_solver.cpp:43] Iteration 113600, lr = 0.01
I0622 11:57:21.298913 17263 solver.cpp:174] Iteration 114000, Testing net (#0)
I0622 11:58:26.558331 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.939141
I0622 11:58:26.558549 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.250595 (* 1 = 0.250595 loss)
I0622 11:58:28.612138 17263 solver.cpp:57] Iteration 114000, loss = 0.036235
I0622 11:58:28.612181 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0362351 (* 1 = 0.0362351 loss)
I0622 11:58:28.612190 17263 sgd_solver.cpp:43] Iteration 114000, lr = 0.01
I0622 12:11:55.008476 17263 solver.cpp:174] Iteration 114400, Testing net (#0)
I0622 12:13:00.232794 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.939687
I0622 12:13:00.233027 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.262286 (* 1 = 0.262286 loss)
I0622 12:13:02.362854 17263 solver.cpp:57] Iteration 114400, loss = 0.0155683
I0622 12:13:02.362897 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0155684 (* 1 = 0.0155684 loss)
I0622 12:13:02.362906 17263 sgd_solver.cpp:43] Iteration 114400, lr = 0.01
I0622 12:26:26.521332 17263 solver.cpp:174] Iteration 114800, Testing net (#0)
I0622 12:27:31.799134 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.937031
I0622 12:27:31.799309 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.264466 (* 1 = 0.264466 loss)
I0622 12:27:33.991888 17263 solver.cpp:57] Iteration 114800, loss = 0.00363213
I0622 12:27:33.991928 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00363223 (* 1 = 0.00363223 loss)
I0622 12:27:33.991937 17263 sgd_solver.cpp:43] Iteration 114800, lr = 0.01
I0622 12:40:58.315038 17263 solver.cpp:174] Iteration 115200, Testing net (#0)
I0622 12:42:03.610239 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.936406
I0622 12:42:03.610466 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.270443 (* 1 = 0.270443 loss)
I0622 12:42:05.513221 17263 solver.cpp:57] Iteration 115200, loss = 0.0320278
I0622 12:42:05.513264 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0320279 (* 1 = 0.0320279 loss)
I0622 12:42:05.513273 17263 sgd_solver.cpp:43] Iteration 115200, lr = 0.01
I0622 12:55:32.865962 17263 solver.cpp:174] Iteration 115600, Testing net (#0)
I0622 12:56:38.176190 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.937422
I0622 12:56:38.176436 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.259331 (* 1 = 0.259331 loss)
I0622 12:56:40.063787 17263 solver.cpp:57] Iteration 115600, loss = 0.0210996
I0622 12:56:40.063833 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0210998 (* 1 = 0.0210998 loss)
I0622 12:56:40.063841 17263 sgd_solver.cpp:43] Iteration 115600, lr = 0.01
I0622 13:10:03.662487 17263 solver.cpp:174] Iteration 116000, Testing net (#0)
I0622 13:11:08.998699 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.938438
I0622 13:11:08.998886 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.261142 (* 1 = 0.261142 loss)
I0622 13:11:11.124486 17263 solver.cpp:57] Iteration 116000, loss = 0.0138371
I0622 13:11:11.124547 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0138373 (* 1 = 0.0138373 loss)
I0622 13:11:11.124562 17263 sgd_solver.cpp:43] Iteration 116000, lr = 0.01
I0622 13:24:38.483878 17263 solver.cpp:174] Iteration 116400, Testing net (#0)
I0622 13:25:43.755826 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.942344
I0622 13:25:43.756023 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.238138 (* 1 = 0.238138 loss)
I0622 13:25:45.520608 17263 solver.cpp:57] Iteration 116400, loss = 0.0171699
I0622 13:25:45.520651 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0171701 (* 1 = 0.0171701 loss)
I0622 13:25:45.520660 17263 sgd_solver.cpp:43] Iteration 116400, lr = 0.01
I0622 13:39:06.838944 17263 solver.cpp:174] Iteration 116800, Testing net (#0)
I0622 13:40:12.140431 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.941094
I0622 13:40:12.140624 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.245541 (* 1 = 0.245541 loss)
I0622 13:40:14.019944 17263 solver.cpp:57] Iteration 116800, loss = 0.0115914
I0622 13:40:14.019980 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0115916 (* 1 = 0.0115916 loss)
I0622 13:40:14.019989 17263 sgd_solver.cpp:43] Iteration 116800, lr = 0.01
I0622 13:53:38.059842 17263 solver.cpp:174] Iteration 117200, Testing net (#0)
I0622 13:54:43.373008 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.938047
I0622 13:54:43.373234 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.273773 (* 1 = 0.273773 loss)
I0622 13:54:45.276218 17263 solver.cpp:57] Iteration 117200, loss = 0.0268428
I0622 13:54:45.276258 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0268429 (* 1 = 0.0268429 loss)
I0622 13:54:45.276265 17263 sgd_solver.cpp:43] Iteration 117200, lr = 0.01
I0622 14:08:12.898497 17263 solver.cpp:174] Iteration 117600, Testing net (#0)
I0622 14:09:18.150192 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.939062
I0622 14:09:18.150423 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.256268 (* 1 = 0.256268 loss)
I0622 14:09:20.019925 17263 solver.cpp:57] Iteration 117600, loss = 0.0373719
I0622 14:09:20.019969 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0373721 (* 1 = 0.0373721 loss)
I0622 14:09:20.019979 17263 sgd_solver.cpp:43] Iteration 117600, lr = 0.01
I0622 14:22:45.420828 17263 solver.cpp:174] Iteration 118000, Testing net (#0)
I0622 14:23:50.718827 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.941875
I0622 14:23:50.719038 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.236081 (* 1 = 0.236081 loss)
I0622 14:23:52.945263 17263 solver.cpp:57] Iteration 118000, loss = 0.00238484
I0622 14:23:52.945309 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00238496 (* 1 = 0.00238496 loss)
I0622 14:23:52.945318 17263 sgd_solver.cpp:43] Iteration 118000, lr = 0.01
I0622 14:37:19.399184 17263 solver.cpp:174] Iteration 118400, Testing net (#0)
I0622 14:38:24.612687 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.939375
I0622 14:38:24.612900 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.253485 (* 1 = 0.253485 loss)
I0622 14:38:26.761795 17263 solver.cpp:57] Iteration 118400, loss = 0.0142938
I0622 14:38:26.761843 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0142939 (* 1 = 0.0142939 loss)
I0622 14:38:26.761859 17263 sgd_solver.cpp:43] Iteration 118400, lr = 0.01
I0622 14:51:52.163264 17263 solver.cpp:174] Iteration 118800, Testing net (#0)
I0622 14:52:57.548187 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.940391
I0622 14:52:57.548257 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.258014 (* 1 = 0.258014 loss)
I0622 14:52:59.598786 17263 solver.cpp:57] Iteration 118800, loss = 0.00889549
I0622 14:52:59.598835 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00889563 (* 1 = 0.00889563 loss)
I0622 14:52:59.598845 17263 sgd_solver.cpp:43] Iteration 118800, lr = 0.01
I0622 15:06:24.532922 17263 solver.cpp:174] Iteration 119200, Testing net (#0)
I0622 15:07:29.792946 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.938516
I0622 15:07:29.793139 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.259635 (* 1 = 0.259635 loss)
I0622 15:07:31.656594 17263 solver.cpp:57] Iteration 119200, loss = 0.0296975
I0622 15:07:31.656631 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0296976 (* 1 = 0.0296976 loss)
I0622 15:07:31.656640 17263 sgd_solver.cpp:43] Iteration 119200, lr = 0.01
I0622 15:21:00.766259 17263 solver.cpp:174] Iteration 119600, Testing net (#0)
I0622 15:22:06.065117 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.940625
I0622 15:22:06.065322 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.264632 (* 1 = 0.264632 loss)
I0622 15:22:08.085156 17263 solver.cpp:57] Iteration 119600, loss = 0.0126879
I0622 15:22:08.085196 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0126881 (* 1 = 0.0126881 loss)
I0622 15:22:08.085204 17263 sgd_solver.cpp:43] Iteration 119600, lr = 0.01
I0622 15:35:37.525339 17263 solver.cpp:174] Iteration 120000, Testing net (#0)
I0622 15:36:42.785590 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.939922
I0622 15:36:42.785783 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.262221 (* 1 = 0.262221 loss)
I0622 15:36:44.660672 17263 solver.cpp:57] Iteration 120000, loss = 0.0232305
I0622 15:36:44.660734 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0232307 (* 1 = 0.0232307 loss)
I0622 15:36:44.660748 17263 sgd_solver.cpp:43] Iteration 120000, lr = 0.01
I0622 15:50:09.843503 17263 solver.cpp:174] Iteration 120400, Testing net (#0)
I0622 15:51:15.140996 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.937266
I0622 15:51:15.141202 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.269261 (* 1 = 0.269261 loss)
I0622 15:51:17.336442 17263 solver.cpp:57] Iteration 120400, loss = 0.00508106
I0622 15:51:17.336484 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00508122 (* 1 = 0.00508122 loss)
I0622 15:51:17.336493 17263 sgd_solver.cpp:43] Iteration 120400, lr = 0.01
I0622 16:04:45.588887 17263 solver.cpp:174] Iteration 120800, Testing net (#0)
I0622 16:05:50.870198 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.940938
I0622 16:05:50.870412 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.241653 (* 1 = 0.241653 loss)
I0622 16:05:52.847661 17263 solver.cpp:57] Iteration 120800, loss = 0.00553734
I0622 16:05:52.847707 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00553752 (* 1 = 0.00553752 loss)
I0622 16:05:52.847717 17263 sgd_solver.cpp:43] Iteration 120800, lr = 0.01
I0622 16:19:18.633222 17263 solver.cpp:174] Iteration 121200, Testing net (#0)
I0622 16:20:23.937928 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.938594
I0622 16:20:23.938421 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.246518 (* 1 = 0.246518 loss)
I0622 16:20:25.984753 17263 solver.cpp:57] Iteration 121200, loss = 0.017138
I0622 16:20:25.984791 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0171382 (* 1 = 0.0171382 loss)
I0622 16:20:25.984797 17263 sgd_solver.cpp:43] Iteration 121200, lr = 0.01
I0622 16:33:51.315901 17263 solver.cpp:174] Iteration 121600, Testing net (#0)
I0622 16:34:56.603200 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.938047
I0622 16:34:56.603397 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.25341 (* 1 = 0.25341 loss)
I0622 16:34:58.726861 17263 solver.cpp:57] Iteration 121600, loss = 0.0113326
I0622 16:34:58.726904 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0113328 (* 1 = 0.0113328 loss)
I0622 16:34:58.726912 17263 sgd_solver.cpp:43] Iteration 121600, lr = 0.01
I0622 16:48:24.258895 17263 solver.cpp:174] Iteration 122000, Testing net (#0)
I0622 16:49:29.561094 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.940703
I0622 16:49:29.561305 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.243929 (* 1 = 0.243929 loss)
I0622 16:49:31.573973 17263 solver.cpp:57] Iteration 122000, loss = 0.0126613
I0622 16:49:31.574012 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0126616 (* 1 = 0.0126616 loss)
I0622 16:49:31.574020 17263 sgd_solver.cpp:43] Iteration 122000, lr = 0.01
I0622 17:02:59.055892 17263 solver.cpp:174] Iteration 122400, Testing net (#0)
I0622 17:04:04.356547 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.936875
I0622 17:04:04.356709 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.267659 (* 1 = 0.267659 loss)
I0622 17:04:06.480644 17263 solver.cpp:57] Iteration 122400, loss = 0.00778425
I0622 17:04:06.480684 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00778447 (* 1 = 0.00778447 loss)
I0622 17:04:06.480692 17263 sgd_solver.cpp:43] Iteration 122400, lr = 0.01
I0622 17:17:29.897091 17263 solver.cpp:174] Iteration 122800, Testing net (#0)
I0622 17:18:35.163516 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.938984
I0622 17:18:35.163650 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.25311 (* 1 = 0.25311 loss)
I0622 17:18:37.131485 17263 solver.cpp:57] Iteration 122800, loss = 0.0502917
I0622 17:18:37.131536 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0502919 (* 1 = 0.0502919 loss)
I0622 17:18:37.131546 17263 sgd_solver.cpp:43] Iteration 122800, lr = 0.01
I0622 17:32:02.777457 17263 solver.cpp:174] Iteration 123200, Testing net (#0)
I0622 17:33:08.076216 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.940469
I0622 17:33:08.076413 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.246466 (* 1 = 0.246466 loss)
I0622 17:33:10.126189 17263 solver.cpp:57] Iteration 123200, loss = 0.00247659
I0622 17:33:10.126245 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00247679 (* 1 = 0.00247679 loss)
I0622 17:33:10.126256 17263 sgd_solver.cpp:43] Iteration 123200, lr = 0.01
I0622 17:46:37.786870 17263 solver.cpp:174] Iteration 123600, Testing net (#0)
I0622 17:47:43.115401 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.942813
I0622 17:47:43.116080 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.237428 (* 1 = 0.237428 loss)
I0622 17:47:44.831923 17263 solver.cpp:57] Iteration 123600, loss = 0.0445885
I0622 17:47:44.831965 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0445887 (* 1 = 0.0445887 loss)
I0622 17:47:44.831975 17263 sgd_solver.cpp:43] Iteration 123600, lr = 0.01
I0622 18:01:11.018106 17263 solver.cpp:174] Iteration 124000, Testing net (#0)
I0622 18:02:16.287273 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.942422
I0622 18:02:16.287531 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.252575 (* 1 = 0.252575 loss)
I0622 18:02:18.234756 17263 solver.cpp:57] Iteration 124000, loss = 0.0446551
I0622 18:02:18.234793 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0446554 (* 1 = 0.0446554 loss)
I0622 18:02:18.234802 17263 sgd_solver.cpp:43] Iteration 124000, lr = 0.01
I0622 18:15:45.423235 17263 solver.cpp:174] Iteration 124400, Testing net (#0)
I0622 18:16:50.696384 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.938594
I0622 18:16:50.696610 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.278567 (* 1 = 0.278567 loss)
I0622 18:16:52.716483 17263 solver.cpp:57] Iteration 124400, loss = 0.00482388
I0622 18:16:52.716528 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00482411 (* 1 = 0.00482411 loss)
I0622 18:16:52.716536 17263 sgd_solver.cpp:43] Iteration 124400, lr = 0.01
I0622 18:30:18.216831 17263 solver.cpp:174] Iteration 124800, Testing net (#0)
I0622 18:31:23.497330 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.938125
I0622 18:31:23.498368 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.269527 (* 1 = 0.269527 loss)
I0622 18:31:25.541606 17263 solver.cpp:57] Iteration 124800, loss = 0.0507459
I0622 18:31:25.541651 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0507461 (* 1 = 0.0507461 loss)
I0622 18:31:25.541661 17263 sgd_solver.cpp:43] Iteration 124800, lr = 0.01
I0622 18:44:51.742460 17263 solver.cpp:174] Iteration 125200, Testing net (#0)
I0622 18:45:57.109989 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.939375
I0622 18:45:57.110146 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.274838 (* 1 = 0.274838 loss)
I0622 18:45:59.270295 17263 solver.cpp:57] Iteration 125200, loss = 0.00735664
I0622 18:45:59.270339 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00735685 (* 1 = 0.00735685 loss)
I0622 18:45:59.270346 17263 sgd_solver.cpp:43] Iteration 125200, lr = 0.01
I0622 18:59:25.208323 17263 solver.cpp:174] Iteration 125600, Testing net (#0)
I0622 19:00:30.485505 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.938047
I0622 19:00:30.485755 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.258886 (* 1 = 0.258886 loss)
I0622 19:00:32.572782 17263 solver.cpp:57] Iteration 125600, loss = 0.031685
I0622 19:00:32.572827 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0316852 (* 1 = 0.0316852 loss)
I0622 19:00:32.572835 17263 sgd_solver.cpp:43] Iteration 125600, lr = 0.01
I0622 19:13:57.360806 17263 solver.cpp:174] Iteration 126000, Testing net (#0)
I0622 19:15:02.656857 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.939766
I0622 19:15:02.657054 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.256516 (* 1 = 0.256516 loss)
I0622 19:15:04.462648 17263 solver.cpp:57] Iteration 126000, loss = 0.0139986
I0622 19:15:04.462692 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0139988 (* 1 = 0.0139988 loss)
I0622 19:15:04.462700 17263 sgd_solver.cpp:43] Iteration 126000, lr = 0.01
I0622 19:28:31.095784 17263 solver.cpp:174] Iteration 126400, Testing net (#0)
I0622 19:29:36.343510 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.941406
I0622 19:29:36.343744 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.264749 (* 1 = 0.264749 loss)
I0622 19:29:38.290449 17263 solver.cpp:57] Iteration 126400, loss = 0.0112138
I0622 19:29:38.290490 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0112141 (* 1 = 0.0112141 loss)
I0622 19:29:38.290498 17263 sgd_solver.cpp:43] Iteration 126400, lr = 0.01
I0622 19:43:05.529456 17263 solver.cpp:174] Iteration 126800, Testing net (#0)
I0622 19:44:10.803253 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.940234
I0622 19:44:10.803424 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.272845 (* 1 = 0.272845 loss)
I0622 19:44:12.766800 17263 solver.cpp:57] Iteration 126800, loss = 0.0244966
I0622 19:44:12.766842 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0244969 (* 1 = 0.0244969 loss)
I0622 19:44:12.766850 17263 sgd_solver.cpp:43] Iteration 126800, lr = 0.01
I0622 19:57:39.004099 17263 solver.cpp:174] Iteration 127200, Testing net (#0)
I0622 19:58:44.315449 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.944766
I0622 19:58:44.315608 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.252862 (* 1 = 0.252862 loss)
I0622 19:58:46.363067 17263 solver.cpp:57] Iteration 127200, loss = 0.021019
I0622 19:58:46.363122 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0210192 (* 1 = 0.0210192 loss)
I0622 19:58:46.363140 17263 sgd_solver.cpp:43] Iteration 127200, lr = 0.01
I0622 20:12:07.889914 17263 solver.cpp:174] Iteration 127600, Testing net (#0)
I0622 20:13:13.236711 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.944062
I0622 20:13:13.236917 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.245175 (* 1 = 0.245175 loss)
I0622 20:13:15.095064 17263 solver.cpp:57] Iteration 127600, loss = 0.0313708
I0622 20:13:15.095108 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0313711 (* 1 = 0.0313711 loss)
I0622 20:13:15.095118 17263 sgd_solver.cpp:43] Iteration 127600, lr = 0.01
I0622 20:26:45.165514 17263 solver.cpp:174] Iteration 128000, Testing net (#0)
I0622 20:27:50.463140 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.940469
I0622 20:27:50.463358 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.262979 (* 1 = 0.262979 loss)
I0622 20:27:52.440459 17263 solver.cpp:57] Iteration 128000, loss = 0.0173498
I0622 20:27:52.440510 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0173501 (* 1 = 0.0173501 loss)
I0622 20:27:52.440517 17263 sgd_solver.cpp:43] Iteration 128000, lr = 0.01
I0622 20:41:17.835849 17263 solver.cpp:174] Iteration 128400, Testing net (#0)
I0622 20:42:23.167392 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.941172
I0622 20:42:23.167590 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.267215 (* 1 = 0.267215 loss)
I0622 20:42:25.367034 17263 solver.cpp:57] Iteration 128400, loss = 0.00165239
I0622 20:42:25.367076 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00165271 (* 1 = 0.00165271 loss)
I0622 20:42:25.367084 17263 sgd_solver.cpp:43] Iteration 128400, lr = 0.01
I0622 20:55:49.946106 17263 solver.cpp:174] Iteration 128800, Testing net (#0)
I0622 20:56:55.271965 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.939297
I0622 20:56:55.272191 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.268979 (* 1 = 0.268979 loss)
I0622 20:56:57.176754 17263 solver.cpp:57] Iteration 128800, loss = 0.056191
I0622 20:56:57.176798 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0561914 (* 1 = 0.0561914 loss)
I0622 20:56:57.176807 17263 sgd_solver.cpp:43] Iteration 128800, lr = 0.01
I0622 21:10:19.608708 17263 solver.cpp:174] Iteration 129200, Testing net (#0)
I0622 21:11:24.855753 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.942578
I0622 21:11:24.862393 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.252495 (* 1 = 0.252495 loss)
I0622 21:11:26.962721 17263 solver.cpp:57] Iteration 129200, loss = 0.0128345
I0622 21:11:26.962772 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0128348 (* 1 = 0.0128348 loss)
I0622 21:11:26.962780 17263 sgd_solver.cpp:43] Iteration 129200, lr = 0.01
I0622 21:24:56.489449 17263 solver.cpp:174] Iteration 129600, Testing net (#0)
I0622 21:26:01.771008 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.942344
I0622 21:26:01.771229 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.259529 (* 1 = 0.259529 loss)
I0622 21:26:03.826864 17263 solver.cpp:57] Iteration 129600, loss = 0.00346055
I0622 21:26:03.826905 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0034608 (* 1 = 0.0034608 loss)
I0622 21:26:03.826911 17263 sgd_solver.cpp:43] Iteration 129600, lr = 0.01
I0622 21:39:31.209969 17263 solver.cpp:174] Iteration 130000, Testing net (#0)
I0622 21:40:36.466413 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.935703
I0622 21:40:36.466624 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.300293 (* 1 = 0.300293 loss)
I0622 21:40:38.442510 17263 solver.cpp:57] Iteration 130000, loss = 0.00564682
I0622 21:40:38.442559 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00564709 (* 1 = 0.00564709 loss)
I0622 21:40:38.442570 17263 sgd_solver.cpp:43] Iteration 130000, lr = 0.01
I0622 21:54:03.141692 17263 solver.cpp:174] Iteration 130400, Testing net (#0)
I0622 21:55:08.484668 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.940156
I0622 21:55:08.484872 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.273566 (* 1 = 0.273566 loss)
I0622 21:55:10.598351 17263 solver.cpp:57] Iteration 130400, loss = 0.0040329
I0622 21:55:10.598408 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00403316 (* 1 = 0.00403316 loss)
I0622 21:55:10.598417 17263 sgd_solver.cpp:43] Iteration 130400, lr = 0.01
I0622 22:08:39.084897 17263 solver.cpp:174] Iteration 130800, Testing net (#0)
I0622 22:09:44.382766 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.939453
I0622 22:09:44.382959 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.270185 (* 1 = 0.270185 loss)
I0622 22:09:46.514101 17263 solver.cpp:57] Iteration 130800, loss = 0.00265413
I0622 22:09:46.514147 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0026544 (* 1 = 0.0026544 loss)
I0622 22:09:46.514158 17263 sgd_solver.cpp:43] Iteration 130800, lr = 0.01
I0622 22:23:11.006479 17263 solver.cpp:174] Iteration 131200, Testing net (#0)
I0622 22:24:16.328176 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.935234
I0622 22:24:16.328408 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.307812 (* 1 = 0.307812 loss)
I0622 22:24:18.233952 17263 solver.cpp:57] Iteration 131200, loss = 0.00767452
I0622 22:24:18.233999 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00767474 (* 1 = 0.00767474 loss)
I0622 22:24:18.234009 17263 sgd_solver.cpp:43] Iteration 131200, lr = 0.01
I0622 22:37:43.386373 17263 solver.cpp:174] Iteration 131600, Testing net (#0)
I0622 22:38:48.727686 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.940938
I0622 22:38:48.727880 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.26962 (* 1 = 0.26962 loss)
I0622 22:38:50.884286 17263 solver.cpp:57] Iteration 131600, loss = 0.0301214
I0622 22:38:50.884328 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0301216 (* 1 = 0.0301216 loss)
I0622 22:38:50.884337 17263 sgd_solver.cpp:43] Iteration 131600, lr = 0.01
I0622 22:52:15.596870 17263 solver.cpp:174] Iteration 132000, Testing net (#0)
I0622 22:53:20.908391 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.937969
I0622 22:53:20.908586 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.291279 (* 1 = 0.291279 loss)
I0622 22:53:23.032392 17263 solver.cpp:57] Iteration 132000, loss = 0.00112477
I0622 22:53:23.032440 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00112504 (* 1 = 0.00112504 loss)
I0622 22:53:23.032450 17263 sgd_solver.cpp:43] Iteration 132000, lr = 0.01
I0622 23:06:48.949462 17263 solver.cpp:174] Iteration 132400, Testing net (#0)
I0622 23:07:54.216367 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.938828
I0622 23:07:54.216564 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.280759 (* 1 = 0.280759 loss)
I0622 23:07:56.240049 17263 solver.cpp:57] Iteration 132400, loss = 0.00143404
I0622 23:07:56.240094 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00143428 (* 1 = 0.00143428 loss)
I0622 23:07:56.240103 17263 sgd_solver.cpp:43] Iteration 132400, lr = 0.01
I0622 23:21:24.217329 17263 solver.cpp:174] Iteration 132800, Testing net (#0)
I0622 23:22:29.545130 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.940078
I0622 23:22:29.545274 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.275197 (* 1 = 0.275197 loss)
I0622 23:22:31.517338 17263 solver.cpp:57] Iteration 132800, loss = 0.0117606
I0622 23:22:31.517380 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0117608 (* 1 = 0.0117608 loss)
I0622 23:22:31.517387 17263 sgd_solver.cpp:43] Iteration 132800, lr = 0.01
I0622 23:36:00.384973 17263 solver.cpp:174] Iteration 133200, Testing net (#0)
I0622 23:37:05.674166 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.941094
I0622 23:37:05.674453 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.274743 (* 1 = 0.274743 loss)
I0622 23:37:07.877106 17263 solver.cpp:57] Iteration 133200, loss = 0.000386707
I0622 23:37:07.877151 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000386917 (* 1 = 0.000386917 loss)
I0622 23:37:07.877161 17263 sgd_solver.cpp:43] Iteration 133200, lr = 0.01
I0622 23:50:37.832388 17263 solver.cpp:174] Iteration 133600, Testing net (#0)
I0622 23:51:43.139868 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.942344
I0622 23:51:43.140070 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.266467 (* 1 = 0.266467 loss)
I0622 23:51:45.227279 17263 solver.cpp:57] Iteration 133600, loss = 0.0273538
I0622 23:51:45.227331 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.027354 (* 1 = 0.027354 loss)
I0622 23:51:45.227342 17263 sgd_solver.cpp:43] Iteration 133600, lr = 0.01
I0623 00:05:08.896891 17263 solver.cpp:174] Iteration 134000, Testing net (#0)
I0623 00:06:14.183367 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.939844
I0623 00:06:14.183584 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.262319 (* 1 = 0.262319 loss)
I0623 00:06:16.099405 17263 solver.cpp:57] Iteration 134000, loss = 0.00589931
I0623 00:06:16.099454 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00589954 (* 1 = 0.00589954 loss)
I0623 00:06:16.099464 17263 sgd_solver.cpp:43] Iteration 134000, lr = 0.01
I0623 00:19:45.320583 17263 solver.cpp:174] Iteration 134400, Testing net (#0)
I0623 00:20:50.631153 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.941094
I0623 00:20:50.631338 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.277966 (* 1 = 0.277966 loss)
I0623 00:20:52.645773 17263 solver.cpp:57] Iteration 134400, loss = 0.00662241
I0623 00:20:52.645810 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00662267 (* 1 = 0.00662267 loss)
I0623 00:20:52.645817 17263 sgd_solver.cpp:43] Iteration 134400, lr = 0.01
I0623 00:34:18.736495 17263 solver.cpp:174] Iteration 134800, Testing net (#0)
I0623 00:35:23.995223 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.939062
I0623 00:35:23.995416 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.285797 (* 1 = 0.285797 loss)
I0623 00:35:25.874675 17263 solver.cpp:57] Iteration 134800, loss = 0.0320081
I0623 00:35:25.874711 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0320084 (* 1 = 0.0320084 loss)
I0623 00:35:25.874717 17263 sgd_solver.cpp:43] Iteration 134800, lr = 0.01
I0623 00:48:52.743365 17263 solver.cpp:174] Iteration 135200, Testing net (#0)
I0623 00:49:58.003481 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.942578
I0623 00:49:58.003695 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.268776 (* 1 = 0.268776 loss)
I0623 00:49:59.909333 17263 solver.cpp:57] Iteration 135200, loss = 0.00343117
I0623 00:49:59.909384 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00343144 (* 1 = 0.00343144 loss)
I0623 00:49:59.909395 17263 sgd_solver.cpp:43] Iteration 135200, lr = 0.01
I0623 01:03:25.557091 17263 solver.cpp:174] Iteration 135600, Testing net (#0)
I0623 01:04:30.848531 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.939609
I0623 01:04:30.848717 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.283412 (* 1 = 0.283412 loss)
I0623 01:04:32.760932 17263 solver.cpp:57] Iteration 135600, loss = 0.0438327
I0623 01:04:32.760977 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.043833 (* 1 = 0.043833 loss)
I0623 01:04:32.760984 17263 sgd_solver.cpp:43] Iteration 135600, lr = 0.01
I0623 01:18:00.188534 17263 solver.cpp:174] Iteration 136000, Testing net (#0)
I0623 01:19:05.579011 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.938672
I0623 01:19:05.579216 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.277038 (* 1 = 0.277038 loss)
I0623 01:19:07.739997 17263 solver.cpp:57] Iteration 136000, loss = 0.0132351
I0623 01:19:07.740036 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0132354 (* 1 = 0.0132354 loss)
I0623 01:19:07.740044 17263 sgd_solver.cpp:43] Iteration 136000, lr = 0.01
I0623 01:32:29.471334 17263 solver.cpp:174] Iteration 136400, Testing net (#0)
I0623 01:33:34.745131 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.941562
I0623 01:33:34.745378 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.276493 (* 1 = 0.276493 loss)
I0623 01:33:36.797746 17263 solver.cpp:57] Iteration 136400, loss = 0.00232152
I0623 01:33:36.797798 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0023218 (* 1 = 0.0023218 loss)
I0623 01:33:36.797809 17263 sgd_solver.cpp:43] Iteration 136400, lr = 0.01
I0623 01:47:05.368094 17263 solver.cpp:174] Iteration 136800, Testing net (#0)
I0623 01:48:10.678647 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.941641
I0623 01:48:10.686429 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.258711 (* 1 = 0.258711 loss)
I0623 01:48:12.665769 17263 solver.cpp:57] Iteration 136800, loss = 0.0134427
I0623 01:48:12.665807 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.013443 (* 1 = 0.013443 loss)
I0623 01:48:12.665815 17263 sgd_solver.cpp:43] Iteration 136800, lr = 0.01
I0623 02:01:38.699753 17263 solver.cpp:174] Iteration 137200, Testing net (#0)
I0623 02:02:44.041213 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.938984
I0623 02:02:44.041434 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.267392 (* 1 = 0.267392 loss)
I0623 02:02:45.962077 17263 solver.cpp:57] Iteration 137200, loss = 0.00345757
I0623 02:02:45.962123 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00345787 (* 1 = 0.00345787 loss)
I0623 02:02:45.962133 17263 sgd_solver.cpp:43] Iteration 137200, lr = 0.01
I0623 02:16:13.849231 17263 solver.cpp:174] Iteration 137600, Testing net (#0)
I0623 02:17:19.114455 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.941562
I0623 02:17:19.118425 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.284167 (* 1 = 0.284167 loss)
I0623 02:17:21.305449 17263 solver.cpp:57] Iteration 137600, loss = 0.00318744
I0623 02:17:21.305480 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00318774 (* 1 = 0.00318774 loss)
I0623 02:17:21.305487 17263 sgd_solver.cpp:43] Iteration 137600, lr = 0.01
I0623 02:30:49.327637 17263 solver.cpp:174] Iteration 138000, Testing net (#0)
I0623 02:31:54.584738 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.933125
I0623 02:31:54.584815 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.312061 (* 1 = 0.312061 loss)
I0623 02:31:56.451288 17263 solver.cpp:57] Iteration 138000, loss = 0.0400324
I0623 02:31:56.451346 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0400326 (* 1 = 0.0400326 loss)
I0623 02:31:56.451354 17263 sgd_solver.cpp:43] Iteration 138000, lr = 0.01
I0623 02:45:25.787261 17263 solver.cpp:174] Iteration 138400, Testing net (#0)
I0623 02:46:31.122931 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.934609
I0623 02:46:31.123224 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.2935 (* 1 = 0.2935 loss)
I0623 02:46:33.222617 17263 solver.cpp:57] Iteration 138400, loss = 0.00138693
I0623 02:46:33.222656 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00138722 (* 1 = 0.00138722 loss)
I0623 02:46:33.222662 17263 sgd_solver.cpp:43] Iteration 138400, lr = 0.01
I0623 03:00:02.024085 17263 solver.cpp:174] Iteration 138800, Testing net (#0)
I0623 03:01:07.341176 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.936641
I0623 03:01:07.341372 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.298466 (* 1 = 0.298466 loss)
I0623 03:01:09.281976 17263 solver.cpp:57] Iteration 138800, loss = 0.00866896
I0623 03:01:09.282013 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00866923 (* 1 = 0.00866923 loss)
I0623 03:01:09.282019 17263 sgd_solver.cpp:43] Iteration 138800, lr = 0.01
I0623 03:14:37.803139 17263 solver.cpp:174] Iteration 139200, Testing net (#0)
I0623 03:15:43.064579 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.938281
I0623 03:15:43.064751 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.285847 (* 1 = 0.285847 loss)
I0623 03:15:45.223484 17263 solver.cpp:57] Iteration 139200, loss = 0.00194102
I0623 03:15:45.223529 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00194126 (* 1 = 0.00194126 loss)
I0623 03:15:45.223546 17263 sgd_solver.cpp:43] Iteration 139200, lr = 0.01
I0623 03:29:09.480324 17263 solver.cpp:174] Iteration 139600, Testing net (#0)
I0623 03:30:14.774209 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.938125
I0623 03:30:14.774435 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.276812 (* 1 = 0.276812 loss)
I0623 03:30:16.785413 17263 solver.cpp:57] Iteration 139600, loss = 0.0214847
I0623 03:30:16.785459 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0214849 (* 1 = 0.0214849 loss)
I0623 03:30:16.785467 17263 sgd_solver.cpp:43] Iteration 139600, lr = 0.01
I0623 03:43:39.906388 17263 solver.cpp:174] Iteration 140000, Testing net (#0)
I0623 03:44:45.129772 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.939375
I0623 03:44:45.129964 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.293645 (* 1 = 0.293645 loss)
I0623 03:44:47.172575 17263 solver.cpp:57] Iteration 140000, loss = 0.00279165
I0623 03:44:47.172619 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00279188 (* 1 = 0.00279188 loss)
I0623 03:44:47.172628 17263 sgd_solver.cpp:43] Iteration 140000, lr = 0.01
I0623 03:58:14.256978 17263 solver.cpp:174] Iteration 140400, Testing net (#0)
I0623 03:59:19.599166 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.939609
I0623 03:59:19.599309 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.283006 (* 1 = 0.283006 loss)
I0623 03:59:21.595531 17263 solver.cpp:57] Iteration 140400, loss = 0.0201549
I0623 03:59:21.595569 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0201551 (* 1 = 0.0201551 loss)
I0623 03:59:21.595578 17263 sgd_solver.cpp:43] Iteration 140400, lr = 0.01
I0623 04:12:48.493155 17263 solver.cpp:174] Iteration 140800, Testing net (#0)
I0623 04:13:53.879673 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.938281
I0623 04:13:53.879863 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.302729 (* 1 = 0.302729 loss)
I0623 04:13:55.713397 17263 solver.cpp:57] Iteration 140800, loss = 0.0475943
I0623 04:13:55.713438 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0475945 (* 1 = 0.0475945 loss)
I0623 04:13:55.713445 17263 sgd_solver.cpp:43] Iteration 140800, lr = 0.01
I0623 04:27:23.245405 17263 solver.cpp:174] Iteration 141200, Testing net (#0)
I0623 04:28:28.527832 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.934531
I0623 04:28:28.528023 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.316163 (* 1 = 0.316163 loss)
I0623 04:28:30.409431 17263 solver.cpp:57] Iteration 141200, loss = 0.00350163
I0623 04:28:30.409471 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00350186 (* 1 = 0.00350186 loss)
I0623 04:28:30.409479 17263 sgd_solver.cpp:43] Iteration 141200, lr = 0.01
I0623 04:41:57.276690 17263 solver.cpp:174] Iteration 141600, Testing net (#0)
I0623 04:43:02.624862 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.939219
I0623 04:43:02.625073 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.276913 (* 1 = 0.276913 loss)
I0623 04:43:04.676553 17263 solver.cpp:57] Iteration 141600, loss = 0.00581034
I0623 04:43:04.676595 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00581055 (* 1 = 0.00581055 loss)
I0623 04:43:04.676604 17263 sgd_solver.cpp:43] Iteration 141600, lr = 0.01
I0623 04:56:29.301398 17263 solver.cpp:174] Iteration 142000, Testing net (#0)
I0623 04:57:34.612313 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.940469
I0623 04:57:34.612532 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.277861 (* 1 = 0.277861 loss)
I0623 04:57:36.584121 17263 solver.cpp:57] Iteration 142000, loss = 0.0640628
I0623 04:57:36.584168 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.064063 (* 1 = 0.064063 loss)
I0623 04:57:36.584174 17263 sgd_solver.cpp:43] Iteration 142000, lr = 0.01
I0623 05:11:01.889559 17263 solver.cpp:174] Iteration 142400, Testing net (#0)
I0623 05:12:07.193013 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.93875
I0623 05:12:07.193222 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.291599 (* 1 = 0.291599 loss)
I0623 05:12:09.126318 17263 solver.cpp:57] Iteration 142400, loss = 0.0397944
I0623 05:12:09.126368 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0397946 (* 1 = 0.0397946 loss)
I0623 05:12:09.126376 17263 sgd_solver.cpp:43] Iteration 142400, lr = 0.01
I0623 05:25:38.419589 17263 solver.cpp:174] Iteration 142800, Testing net (#0)
I0623 05:26:43.680441 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.940313
I0623 05:26:43.680658 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.270585 (* 1 = 0.270585 loss)
I0623 05:26:45.622892 17263 solver.cpp:57] Iteration 142800, loss = 0.0122463
I0623 05:26:45.622933 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0122465 (* 1 = 0.0122465 loss)
I0623 05:26:45.622941 17263 sgd_solver.cpp:43] Iteration 142800, lr = 0.01
I0623 05:40:11.846228 17263 solver.cpp:174] Iteration 143200, Testing net (#0)
I0623 05:41:17.192963 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.935469
I0623 05:41:17.193295 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.29216 (* 1 = 0.29216 loss)
I0623 05:41:19.279448 17263 solver.cpp:57] Iteration 143200, loss = 0.0008246
I0623 05:41:19.279491 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00082479 (* 1 = 0.00082479 loss)
I0623 05:41:19.279500 17263 sgd_solver.cpp:43] Iteration 143200, lr = 0.01
I0623 05:54:43.773011 17263 solver.cpp:174] Iteration 143600, Testing net (#0)
I0623 05:55:49.081715 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.93875
I0623 05:55:49.081888 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.273407 (* 1 = 0.273407 loss)
I0623 05:55:50.992368 17263 solver.cpp:57] Iteration 143600, loss = 0.0219843
I0623 05:55:50.992410 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0219845 (* 1 = 0.0219845 loss)
I0623 05:55:50.992419 17263 sgd_solver.cpp:43] Iteration 143600, lr = 0.01
I0623 06:09:16.088764 17263 solver.cpp:174] Iteration 144000, Testing net (#0)
I0623 06:10:21.394016 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.941016
I0623 06:10:21.394227 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.26943 (* 1 = 0.26943 loss)
I0623 06:10:23.371441 17263 solver.cpp:57] Iteration 144000, loss = 0.021463
I0623 06:10:23.371487 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0214631 (* 1 = 0.0214631 loss)
I0623 06:10:23.371497 17263 sgd_solver.cpp:43] Iteration 144000, lr = 0.01
I0623 06:23:48.644565 17263 solver.cpp:174] Iteration 144400, Testing net (#0)
I0623 06:24:53.860710 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.935547
I0623 06:24:53.860924 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.299862 (* 1 = 0.299862 loss)
I0623 06:24:55.858036 17263 solver.cpp:57] Iteration 144400, loss = 0.0122044
I0623 06:24:55.858083 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0122046 (* 1 = 0.0122046 loss)
I0623 06:24:55.858091 17263 sgd_solver.cpp:43] Iteration 144400, lr = 0.01
I0623 06:38:23.648711 17263 solver.cpp:174] Iteration 144800, Testing net (#0)
I0623 06:39:28.995363 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.937813
I0623 06:39:28.995568 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.289979 (* 1 = 0.289979 loss)
I0623 06:39:31.116842 17263 solver.cpp:57] Iteration 144800, loss = 0.00757049
I0623 06:39:31.116894 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00757069 (* 1 = 0.00757069 loss)
I0623 06:39:31.116904 17263 sgd_solver.cpp:43] Iteration 144800, lr = 0.01
I0623 06:52:58.643666 17263 solver.cpp:174] Iteration 145200, Testing net (#0)
I0623 06:54:03.944057 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.9425
I0623 06:54:03.944274 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.262901 (* 1 = 0.262901 loss)
I0623 06:54:05.781812 17263 solver.cpp:57] Iteration 145200, loss = 0.00962205
I0623 06:54:05.781855 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00962223 (* 1 = 0.00962223 loss)
I0623 06:54:05.781864 17263 sgd_solver.cpp:43] Iteration 145200, lr = 0.01
I0623 07:07:34.581075 17263 solver.cpp:174] Iteration 145600, Testing net (#0)
I0623 07:08:39.891366 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.937969
I0623 07:08:39.891602 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.279563 (* 1 = 0.279563 loss)
I0623 07:08:41.933858 17263 solver.cpp:57] Iteration 145600, loss = 0.0318938
I0623 07:08:41.933902 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0318939 (* 1 = 0.0318939 loss)
I0623 07:08:41.933912 17263 sgd_solver.cpp:43] Iteration 145600, lr = 0.01
I0623 07:22:08.212949 17263 solver.cpp:174] Iteration 146000, Testing net (#0)
I0623 07:23:13.517578 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.942344
I0623 07:23:13.517776 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.270007 (* 1 = 0.270007 loss)
I0623 07:23:15.598095 17263 solver.cpp:57] Iteration 146000, loss = 0.00628032
I0623 07:23:15.598140 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00628045 (* 1 = 0.00628045 loss)
I0623 07:23:15.598147 17263 sgd_solver.cpp:43] Iteration 146000, lr = 0.01
I0623 07:36:41.004526 17263 solver.cpp:174] Iteration 146400, Testing net (#0)
I0623 07:37:46.344949 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.936484
I0623 07:37:46.345101 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.30493 (* 1 = 0.30493 loss)
I0623 07:37:48.246000 17263 solver.cpp:57] Iteration 146400, loss = 0.0215416
I0623 07:37:48.246040 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0215417 (* 1 = 0.0215417 loss)
I0623 07:37:48.246048 17263 sgd_solver.cpp:43] Iteration 146400, lr = 0.01
I0623 07:51:17.550052 17263 solver.cpp:174] Iteration 146800, Testing net (#0)
I0623 07:52:22.878193 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.935938
I0623 07:52:22.878381 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.300383 (* 1 = 0.300383 loss)
I0623 07:52:24.880326 17263 solver.cpp:57] Iteration 146800, loss = 0.0404323
I0623 07:52:24.880367 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0404325 (* 1 = 0.0404325 loss)
I0623 07:52:24.880378 17263 sgd_solver.cpp:43] Iteration 146800, lr = 0.01
I0623 08:05:51.735307 17263 solver.cpp:174] Iteration 147200, Testing net (#0)
I0623 08:06:57.107455 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.938984
I0623 08:06:57.107631 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.294375 (* 1 = 0.294375 loss)
I0623 08:06:59.089445 17263 solver.cpp:57] Iteration 147200, loss = 0.0241162
I0623 08:06:59.089509 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0241164 (* 1 = 0.0241164 loss)
I0623 08:06:59.089517 17263 sgd_solver.cpp:43] Iteration 147200, lr = 0.01
I0623 08:20:24.996531 17263 solver.cpp:174] Iteration 147600, Testing net (#0)
I0623 08:21:30.303506 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.937266
I0623 08:21:30.303714 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.301133 (* 1 = 0.301133 loss)
I0623 08:21:32.245007 17263 solver.cpp:57] Iteration 147600, loss = 0.00380305
I0623 08:21:32.245048 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00380317 (* 1 = 0.00380317 loss)
I0623 08:21:32.245055 17263 sgd_solver.cpp:43] Iteration 147600, lr = 0.01
I0623 08:35:00.631608 17263 solver.cpp:174] Iteration 148000, Testing net (#0)
I0623 08:36:05.924068 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.936484
I0623 08:36:05.930405 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.316734 (* 1 = 0.316734 loss)
I0623 08:36:07.804919 17263 solver.cpp:57] Iteration 148000, loss = 0.0591905
I0623 08:36:07.804952 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0591906 (* 1 = 0.0591906 loss)
I0623 08:36:07.804961 17263 sgd_solver.cpp:43] Iteration 148000, lr = 0.01
I0623 08:49:31.058557 17263 solver.cpp:174] Iteration 148400, Testing net (#0)
I0623 08:50:36.344530 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.937422
I0623 08:50:36.344736 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.267678 (* 1 = 0.267678 loss)
I0623 08:50:38.384045 17263 solver.cpp:57] Iteration 148400, loss = 0.02581
I0623 08:50:38.384088 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0258101 (* 1 = 0.0258101 loss)
I0623 08:50:38.384095 17263 sgd_solver.cpp:43] Iteration 148400, lr = 0.01
I0623 09:04:07.846662 17263 solver.cpp:174] Iteration 148800, Testing net (#0)
I0623 09:05:13.104898 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.941406
I0623 09:05:13.105099 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.282907 (* 1 = 0.282907 loss)
I0623 09:05:14.891494 17263 solver.cpp:57] Iteration 148800, loss = 0.0367066
I0623 09:05:14.891548 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0367067 (* 1 = 0.0367067 loss)
I0623 09:05:14.891559 17263 sgd_solver.cpp:43] Iteration 148800, lr = 0.01
I0623 09:18:40.717142 17263 solver.cpp:174] Iteration 149200, Testing net (#0)
I0623 09:19:45.983615 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.939375
I0623 09:19:45.983820 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.280481 (* 1 = 0.280481 loss)
I0623 09:19:48.072834 17263 solver.cpp:57] Iteration 149200, loss = 0.00530525
I0623 09:19:48.072875 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00530537 (* 1 = 0.00530537 loss)
I0623 09:19:48.072891 17263 sgd_solver.cpp:43] Iteration 149200, lr = 0.01
I0623 09:33:16.712045 17263 solver.cpp:174] Iteration 149600, Testing net (#0)
I0623 09:34:22.018492 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.937891
I0623 09:34:22.018718 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.301443 (* 1 = 0.301443 loss)
I0623 09:34:24.082257 17263 solver.cpp:57] Iteration 149600, loss = 0.000940003
I0623 09:34:24.082310 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000940118 (* 1 = 0.000940118 loss)
I0623 09:34:24.082324 17263 sgd_solver.cpp:43] Iteration 149600, lr = 0.01
I0623 09:47:46.952498 17263 solver.cpp:174] Iteration 150000, Testing net (#0)
I0623 09:48:52.279330 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.936328
I0623 09:48:52.279502 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.301076 (* 1 = 0.301076 loss)
I0623 09:48:53.970695 17263 solver.cpp:57] Iteration 150000, loss = 0.0285945
I0623 09:48:53.970744 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0285946 (* 1 = 0.0285946 loss)
I0623 09:48:53.970752 17263 sgd_solver.cpp:109] MultiStep Status: Iteration 150000, step = 2
I0623 09:48:53.970755 17263 sgd_solver.cpp:43] Iteration 150000, lr = 0.001
I0623 10:02:22.280582 17263 solver.cpp:174] Iteration 150400, Testing net (#0)
I0623 10:03:27.619861 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.943125
I0623 10:03:27.620079 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.262901 (* 1 = 0.262901 loss)
I0623 10:03:29.154302 17263 solver.cpp:57] Iteration 150400, loss = 0.0246179
I0623 10:03:29.154350 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.024618 (* 1 = 0.024618 loss)
I0623 10:03:29.154364 17263 sgd_solver.cpp:43] Iteration 150400, lr = 0.001
I0623 10:16:53.286419 17263 solver.cpp:174] Iteration 150800, Testing net (#0)
I0623 10:17:58.632974 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.945391
I0623 10:17:58.633177 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.253336 (* 1 = 0.253336 loss)
I0623 10:18:00.729135 17263 solver.cpp:57] Iteration 150800, loss = 0.00741229
I0623 10:18:00.729184 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00741239 (* 1 = 0.00741239 loss)
I0623 10:18:00.729197 17263 sgd_solver.cpp:43] Iteration 150800, lr = 0.001
I0623 10:31:28.985363 17263 solver.cpp:174] Iteration 151200, Testing net (#0)
I0623 10:32:34.301250 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946016
I0623 10:32:34.301429 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.252755 (* 1 = 0.252755 loss)
I0623 10:32:36.171831 17263 solver.cpp:57] Iteration 151200, loss = 0.0407095
I0623 10:32:36.171871 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0407096 (* 1 = 0.0407096 loss)
I0623 10:32:36.171880 17263 sgd_solver.cpp:43] Iteration 151200, lr = 0.001
I0623 10:45:58.766974 17263 solver.cpp:174] Iteration 151600, Testing net (#0)
I0623 10:47:04.055833 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.945781
I0623 10:47:04.056064 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.251867 (* 1 = 0.251867 loss)
I0623 10:47:06.112979 17263 solver.cpp:57] Iteration 151600, loss = 0.000477266
I0623 10:47:06.113016 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000477407 (* 1 = 0.000477407 loss)
I0623 10:47:06.113024 17263 sgd_solver.cpp:43] Iteration 151600, lr = 0.001
I0623 11:00:30.654276 17263 solver.cpp:174] Iteration 152000, Testing net (#0)
I0623 11:01:36.037001 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947891
I0623 11:01:36.037214 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.246894 (* 1 = 0.246894 loss)
I0623 11:01:38.076925 17263 solver.cpp:57] Iteration 152000, loss = 0.00232309
I0623 11:01:38.076966 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00232324 (* 1 = 0.00232324 loss)
I0623 11:01:38.076972 17263 sgd_solver.cpp:43] Iteration 152000, lr = 0.001
I0623 11:15:00.465188 17263 solver.cpp:174] Iteration 152400, Testing net (#0)
I0623 11:16:05.783387 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946641
I0623 11:16:05.783612 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.25161 (* 1 = 0.25161 loss)
I0623 11:16:07.760608 17263 solver.cpp:57] Iteration 152400, loss = 0.00134052
I0623 11:16:07.760654 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00134065 (* 1 = 0.00134065 loss)
I0623 11:16:07.760663 17263 sgd_solver.cpp:43] Iteration 152400, lr = 0.001
I0623 11:29:31.922945 17263 solver.cpp:174] Iteration 152800, Testing net (#0)
I0623 11:30:37.181416 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.945703
I0623 11:30:37.181633 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.255247 (* 1 = 0.255247 loss)
I0623 11:30:39.047673 17263 solver.cpp:57] Iteration 152800, loss = 0.00840348
I0623 11:30:39.047730 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00840361 (* 1 = 0.00840361 loss)
I0623 11:30:39.047740 17263 sgd_solver.cpp:43] Iteration 152800, lr = 0.001
I0623 11:44:04.266566 17263 solver.cpp:174] Iteration 153200, Testing net (#0)
I0623 11:45:09.596303 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947187
I0623 11:45:09.596494 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.251749 (* 1 = 0.251749 loss)
I0623 11:45:11.627666 17263 solver.cpp:57] Iteration 153200, loss = 0.00225316
I0623 11:45:11.627718 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00225329 (* 1 = 0.00225329 loss)
I0623 11:45:11.627729 17263 sgd_solver.cpp:43] Iteration 153200, lr = 0.001
I0623 11:58:42.510033 17263 solver.cpp:174] Iteration 153600, Testing net (#0)
I0623 11:59:47.784153 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946797
I0623 11:59:47.784409 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.252316 (* 1 = 0.252316 loss)
I0623 11:59:49.875551 17263 solver.cpp:57] Iteration 153600, loss = 0.00287453
I0623 11:59:49.875596 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00287468 (* 1 = 0.00287468 loss)
I0623 11:59:49.875603 17263 sgd_solver.cpp:43] Iteration 153600, lr = 0.001
I0623 12:13:11.743650 17263 solver.cpp:174] Iteration 154000, Testing net (#0)
I0623 12:14:17.061210 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.944922
I0623 12:14:17.061429 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.25931 (* 1 = 0.25931 loss)
I0623 12:14:18.939836 17263 solver.cpp:57] Iteration 154000, loss = 0.0106337
I0623 12:14:18.939874 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0106338 (* 1 = 0.0106338 loss)
I0623 12:14:18.939882 17263 sgd_solver.cpp:43] Iteration 154000, lr = 0.001
I0623 12:27:44.592911 17263 solver.cpp:174] Iteration 154400, Testing net (#0)
I0623 12:28:49.875134 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.948047
I0623 12:28:49.885294 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.249919 (* 1 = 0.249919 loss)
I0623 12:28:51.895177 17263 solver.cpp:57] Iteration 154400, loss = 0.0332496
I0623 12:28:51.895226 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0332497 (* 1 = 0.0332497 loss)
I0623 12:28:51.895234 17263 sgd_solver.cpp:43] Iteration 154400, lr = 0.001
I0623 12:42:19.897186 17263 solver.cpp:174] Iteration 154800, Testing net (#0)
I0623 12:43:25.185946 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946563
I0623 12:43:25.198431 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.250414 (* 1 = 0.250414 loss)
I0623 12:43:27.178122 17263 solver.cpp:57] Iteration 154800, loss = 0.00275251
I0623 12:43:27.178154 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00275263 (* 1 = 0.00275263 loss)
I0623 12:43:27.178163 17263 sgd_solver.cpp:43] Iteration 154800, lr = 0.001
I0623 12:56:52.591837 17263 solver.cpp:174] Iteration 155200, Testing net (#0)
I0623 12:57:57.960620 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947187
I0623 12:57:57.960825 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.246535 (* 1 = 0.246535 loss)
I0623 12:57:59.978993 17263 solver.cpp:57] Iteration 155200, loss = 0.00458161
I0623 12:57:59.979038 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00458172 (* 1 = 0.00458172 loss)
I0623 12:57:59.979048 17263 sgd_solver.cpp:43] Iteration 155200, lr = 0.001
I0623 13:11:28.023710 17263 solver.cpp:174] Iteration 155600, Testing net (#0)
I0623 13:12:33.339999 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946328
I0623 13:12:33.340206 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.247786 (* 1 = 0.247786 loss)
I0623 13:12:35.468348 17263 solver.cpp:57] Iteration 155600, loss = 0.00185671
I0623 13:12:35.468394 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00185683 (* 1 = 0.00185683 loss)
I0623 13:12:35.468403 17263 sgd_solver.cpp:43] Iteration 155600, lr = 0.001
I0623 13:26:03.087970 17263 solver.cpp:174] Iteration 156000, Testing net (#0)
I0623 13:27:08.355870 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947266
I0623 13:27:08.356091 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.250348 (* 1 = 0.250348 loss)
I0623 13:27:10.477329 17263 solver.cpp:57] Iteration 156000, loss = 0.000444395
I0623 13:27:10.477380 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000444499 (* 1 = 0.000444499 loss)
I0623 13:27:10.477391 17263 sgd_solver.cpp:43] Iteration 156000, lr = 0.001
I0623 13:40:35.483552 17263 solver.cpp:174] Iteration 156400, Testing net (#0)
I0623 13:41:40.797433 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.9475
I0623 13:41:40.797652 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.247867 (* 1 = 0.247867 loss)
I0623 13:41:42.662588 17263 solver.cpp:57] Iteration 156400, loss = 0.00421173
I0623 13:41:42.662626 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00421185 (* 1 = 0.00421185 loss)
I0623 13:41:42.662642 17263 sgd_solver.cpp:43] Iteration 156400, lr = 0.001
I0623 13:55:07.447967 17263 solver.cpp:174] Iteration 156800, Testing net (#0)
I0623 13:56:12.784534 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947109
I0623 13:56:12.784761 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.252483 (* 1 = 0.252483 loss)
I0623 13:56:14.760177 17263 solver.cpp:57] Iteration 156800, loss = 0.00498453
I0623 13:56:14.760216 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00498461 (* 1 = 0.00498461 loss)
I0623 13:56:14.760223 17263 sgd_solver.cpp:43] Iteration 156800, lr = 0.001
I0623 14:09:38.137223 17263 solver.cpp:174] Iteration 157200, Testing net (#0)
I0623 14:10:43.484776 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947031
I0623 14:10:43.484968 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.259145 (* 1 = 0.259145 loss)
I0623 14:10:45.504734 17263 solver.cpp:57] Iteration 157200, loss = 0.00080749
I0623 14:10:45.504772 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000807568 (* 1 = 0.000807568 loss)
I0623 14:10:45.504779 17263 sgd_solver.cpp:43] Iteration 157200, lr = 0.001
I0623 14:24:12.121438 17263 solver.cpp:174] Iteration 157600, Testing net (#0)
I0623 14:25:17.418138 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946484
I0623 14:25:17.418293 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.249176 (* 1 = 0.249176 loss)
I0623 14:25:19.327323 17263 solver.cpp:57] Iteration 157600, loss = 0.00544341
I0623 14:25:19.327364 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00544347 (* 1 = 0.00544347 loss)
I0623 14:25:19.327373 17263 sgd_solver.cpp:43] Iteration 157600, lr = 0.001
I0623 14:38:44.318624 17263 solver.cpp:174] Iteration 158000, Testing net (#0)
I0623 14:39:49.635646 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947734
I0623 14:39:49.635808 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.244929 (* 1 = 0.244929 loss)
I0623 14:39:51.652740 17263 solver.cpp:57] Iteration 158000, loss = 0.0031495
I0623 14:39:51.652793 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00314958 (* 1 = 0.00314958 loss)
I0623 14:39:51.652802 17263 sgd_solver.cpp:43] Iteration 158000, lr = 0.001
I0623 14:53:18.201033 17263 solver.cpp:174] Iteration 158400, Testing net (#0)
I0623 14:54:23.518049 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947187
I0623 14:54:23.518246 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.25166 (* 1 = 0.25166 loss)
I0623 14:54:25.422746 17263 solver.cpp:57] Iteration 158400, loss = 0.00526456
I0623 14:54:25.422786 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00526464 (* 1 = 0.00526464 loss)
I0623 14:54:25.422794 17263 sgd_solver.cpp:43] Iteration 158400, lr = 0.001
I0623 15:07:53.083711 17263 solver.cpp:174] Iteration 158800, Testing net (#0)
I0623 15:08:58.333667 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.945547
I0623 15:08:58.333878 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.265512 (* 1 = 0.265512 loss)
I0623 15:09:00.209872 17263 solver.cpp:57] Iteration 158800, loss = 0.00149797
I0623 15:09:00.209909 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00149803 (* 1 = 0.00149803 loss)
I0623 15:09:00.209915 17263 sgd_solver.cpp:43] Iteration 158800, lr = 0.001
I0623 15:22:22.565237 17263 solver.cpp:174] Iteration 159200, Testing net (#0)
I0623 15:23:27.854275 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947969
I0623 15:23:27.854488 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.248905 (* 1 = 0.248905 loss)
I0623 15:23:29.910727 17263 solver.cpp:57] Iteration 159200, loss = 0.00289053
I0623 15:23:29.910773 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00289061 (* 1 = 0.00289061 loss)
I0623 15:23:29.910784 17263 sgd_solver.cpp:43] Iteration 159200, lr = 0.001
I0623 15:36:57.389446 17263 solver.cpp:174] Iteration 159600, Testing net (#0)
I0623 15:38:02.631650 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946484
I0623 15:38:02.631882 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.255839 (* 1 = 0.255839 loss)
I0623 15:38:04.550108 17263 solver.cpp:57] Iteration 159600, loss = 0.00124711
I0623 15:38:04.550154 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0012472 (* 1 = 0.0012472 loss)
I0623 15:38:04.550163 17263 sgd_solver.cpp:43] Iteration 159600, lr = 0.001
I0623 15:51:31.284234 17263 solver.cpp:174] Iteration 160000, Testing net (#0)
I0623 15:52:36.596480 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946719
I0623 15:52:36.596835 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.256704 (* 1 = 0.256704 loss)
I0623 15:52:38.752643 17263 solver.cpp:57] Iteration 160000, loss = 0.000509993
I0623 15:52:38.752686 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00051009 (* 1 = 0.00051009 loss)
I0623 15:52:38.752693 17263 sgd_solver.cpp:43] Iteration 160000, lr = 0.001
I0623 16:06:06.728838 17263 solver.cpp:174] Iteration 160400, Testing net (#0)
I0623 16:07:12.019359 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946484
I0623 16:07:12.019567 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.25714 (* 1 = 0.25714 loss)
I0623 16:07:14.078729 17263 solver.cpp:57] Iteration 160400, loss = 0.0107447
I0623 16:07:14.078773 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0107448 (* 1 = 0.0107448 loss)
I0623 16:07:14.078781 17263 sgd_solver.cpp:43] Iteration 160400, lr = 0.001
I0623 16:20:40.613052 17263 solver.cpp:174] Iteration 160800, Testing net (#0)
I0623 16:21:45.912874 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.948438
I0623 16:21:45.913103 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.256854 (* 1 = 0.256854 loss)
I0623 16:21:48.143355 17263 solver.cpp:57] Iteration 160800, loss = 1.41012e-05
I0623 16:21:48.143399 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 1.42426e-05 (* 1 = 1.42426e-05 loss)
I0623 16:21:48.143407 17263 sgd_solver.cpp:43] Iteration 160800, lr = 0.001
I0623 16:35:16.991297 17263 solver.cpp:174] Iteration 161200, Testing net (#0)
I0623 16:36:22.413111 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.94625
I0623 16:36:22.413306 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.255178 (* 1 = 0.255178 loss)
I0623 16:36:24.432525 17263 solver.cpp:57] Iteration 161200, loss = 0.0192244
I0623 16:36:24.432569 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0192245 (* 1 = 0.0192245 loss)
I0623 16:36:24.432576 17263 sgd_solver.cpp:43] Iteration 161200, lr = 0.001
I0623 16:49:50.849963 17263 solver.cpp:174] Iteration 161600, Testing net (#0)
I0623 16:50:56.141950 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947891
I0623 16:50:56.142155 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.25562 (* 1 = 0.25562 loss)
I0623 16:50:58.261230 17263 solver.cpp:57] Iteration 161600, loss = 0.000814868
I0623 16:50:58.261272 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000814998 (* 1 = 0.000814998 loss)
I0623 16:50:58.261281 17263 sgd_solver.cpp:43] Iteration 161600, lr = 0.001
I0623 17:04:24.130059 17263 solver.cpp:174] Iteration 162000, Testing net (#0)
I0623 17:05:29.455334 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.948359
I0623 17:05:29.455530 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.252049 (* 1 = 0.252049 loss)
I0623 17:05:31.469820 17263 solver.cpp:57] Iteration 162000, loss = 0.0023719
I0623 17:05:31.469861 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00237204 (* 1 = 0.00237204 loss)
I0623 17:05:31.469867 17263 sgd_solver.cpp:43] Iteration 162000, lr = 0.001
I0623 17:18:56.701285 17263 solver.cpp:174] Iteration 162400, Testing net (#0)
I0623 17:20:02.045219 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946719
I0623 17:20:02.045457 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.258354 (* 1 = 0.258354 loss)
I0623 17:20:04.138974 17263 solver.cpp:57] Iteration 162400, loss = 0.000618617
I0623 17:20:04.139014 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000618753 (* 1 = 0.000618753 loss)
I0623 17:20:04.139021 17263 sgd_solver.cpp:43] Iteration 162400, lr = 0.001
I0623 17:33:29.718968 17263 solver.cpp:174] Iteration 162800, Testing net (#0)
I0623 17:34:34.976759 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946953
I0623 17:34:34.976963 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.257556 (* 1 = 0.257556 loss)
I0623 17:34:36.993379 17263 solver.cpp:57] Iteration 162800, loss = 0.0174311
I0623 17:34:36.993418 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0174313 (* 1 = 0.0174313 loss)
I0623 17:34:36.993427 17263 sgd_solver.cpp:43] Iteration 162800, lr = 0.001
I0623 17:48:01.955792 17263 solver.cpp:174] Iteration 163200, Testing net (#0)
I0623 17:49:07.287293 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.948828
I0623 17:49:07.287495 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.253208 (* 1 = 0.253208 loss)
I0623 17:49:09.303486 17263 solver.cpp:57] Iteration 163200, loss = 0.000566476
I0623 17:49:09.303527 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000566628 (* 1 = 0.000566628 loss)
I0623 17:49:09.303536 17263 sgd_solver.cpp:43] Iteration 163200, lr = 0.001
I0623 18:02:33.252624 17263 solver.cpp:174] Iteration 163600, Testing net (#0)
I0623 18:03:38.567276 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.948438
I0623 18:03:38.567471 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.252342 (* 1 = 0.252342 loss)
I0623 18:03:40.484118 17263 solver.cpp:57] Iteration 163600, loss = 0.00122212
I0623 18:03:40.484164 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00122227 (* 1 = 0.00122227 loss)
I0623 18:03:40.484172 17263 sgd_solver.cpp:43] Iteration 163600, lr = 0.001
I0623 18:17:03.258530 17263 solver.cpp:174] Iteration 164000, Testing net (#0)
I0623 18:18:08.545717 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.948125
I0623 18:18:08.545930 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.258027 (* 1 = 0.258027 loss)
I0623 18:18:10.633496 17263 solver.cpp:57] Iteration 164000, loss = 0.00478849
I0623 18:18:10.633564 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00478869 (* 1 = 0.00478869 loss)
I0623 18:18:10.633584 17263 sgd_solver.cpp:43] Iteration 164000, lr = 0.001
I0623 18:31:36.766753 17263 solver.cpp:174] Iteration 164400, Testing net (#0)
I0623 18:32:42.040346 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947031
I0623 18:32:42.040519 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.259974 (* 1 = 0.259974 loss)
I0623 18:32:44.019506 17263 solver.cpp:57] Iteration 164400, loss = 0.0020655
I0623 18:32:44.019541 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00206568 (* 1 = 0.00206568 loss)
I0623 18:32:44.019547 17263 sgd_solver.cpp:43] Iteration 164400, lr = 0.001
I0623 18:46:16.716598 17263 solver.cpp:174] Iteration 164800, Testing net (#0)
I0623 18:47:21.993906 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947734
I0623 18:47:21.994099 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.260963 (* 1 = 0.260963 loss)
I0623 18:47:23.834385 17263 solver.cpp:57] Iteration 164800, loss = 0.00295755
I0623 18:47:23.834429 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00295777 (* 1 = 0.00295777 loss)
I0623 18:47:23.834436 17263 sgd_solver.cpp:43] Iteration 164800, lr = 0.001
I0623 19:00:52.092685 17263 solver.cpp:174] Iteration 165200, Testing net (#0)
I0623 19:01:57.340876 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.949141
I0623 19:01:57.341068 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.262177 (* 1 = 0.262177 loss)
I0623 19:01:59.387888 17263 solver.cpp:57] Iteration 165200, loss = 0.00256597
I0623 19:01:59.387939 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00256619 (* 1 = 0.00256619 loss)
I0623 19:01:59.387950 17263 sgd_solver.cpp:43] Iteration 165200, lr = 0.001
I0623 19:15:25.611615 17263 solver.cpp:174] Iteration 165600, Testing net (#0)
I0623 19:16:30.947790 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946016
I0623 19:16:30.948001 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.262993 (* 1 = 0.262993 loss)
I0623 19:16:32.953131 17263 solver.cpp:57] Iteration 165600, loss = 0.0117589
I0623 19:16:32.953172 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0117591 (* 1 = 0.0117591 loss)
I0623 19:16:32.953181 17263 sgd_solver.cpp:43] Iteration 165600, lr = 0.001
I0623 19:29:57.969486 17263 solver.cpp:174] Iteration 166000, Testing net (#0)
I0623 19:31:03.248435 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947109
I0623 19:31:03.248664 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.264933 (* 1 = 0.264933 loss)
I0623 19:31:05.286865 17263 solver.cpp:57] Iteration 166000, loss = 0.00368669
I0623 19:31:05.286906 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0036869 (* 1 = 0.0036869 loss)
I0623 19:31:05.286912 17263 sgd_solver.cpp:43] Iteration 166000, lr = 0.001
I0623 19:44:31.838244 17263 solver.cpp:174] Iteration 166400, Testing net (#0)
I0623 19:45:37.171241 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.949844
I0623 19:45:37.171700 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.252925 (* 1 = 0.252925 loss)
I0623 19:45:39.226280 17263 solver.cpp:57] Iteration 166400, loss = 0.0143765
I0623 19:45:39.226320 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0143767 (* 1 = 0.0143767 loss)
I0623 19:45:39.226327 17263 sgd_solver.cpp:43] Iteration 166400, lr = 0.001
I0623 19:59:08.173552 17263 solver.cpp:174] Iteration 166800, Testing net (#0)
I0623 20:00:13.527333 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.944844
I0623 20:00:13.527485 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.264908 (* 1 = 0.264908 loss)
I0623 20:00:15.469466 17263 solver.cpp:57] Iteration 166800, loss = 0.00347345
I0623 20:00:15.469511 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00347365 (* 1 = 0.00347365 loss)
I0623 20:00:15.469518 17263 sgd_solver.cpp:43] Iteration 166800, lr = 0.001
I0623 20:13:40.796458 17263 solver.cpp:174] Iteration 167200, Testing net (#0)
I0623 20:14:46.113137 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947422
I0623 20:14:46.113329 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.257146 (* 1 = 0.257146 loss)
I0623 20:14:48.032209 17263 solver.cpp:57] Iteration 167200, loss = 0.00239182
I0623 20:14:48.032251 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00239202 (* 1 = 0.00239202 loss)
I0623 20:14:48.032260 17263 sgd_solver.cpp:43] Iteration 167200, lr = 0.001
I0623 20:28:13.020545 17263 solver.cpp:174] Iteration 167600, Testing net (#0)
I0623 20:29:18.290803 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946406
I0623 20:29:18.291020 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.265103 (* 1 = 0.265103 loss)
I0623 20:29:20.315137 17263 solver.cpp:57] Iteration 167600, loss = 0.0098654
I0623 20:29:20.315181 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00986558 (* 1 = 0.00986558 loss)
I0623 20:29:20.315191 17263 sgd_solver.cpp:43] Iteration 167600, lr = 0.001
I0623 20:42:48.638612 17263 solver.cpp:174] Iteration 168000, Testing net (#0)
I0623 20:43:53.915897 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947187
I0623 20:43:53.916107 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.268994 (* 1 = 0.268994 loss)
I0623 20:43:55.902612 17263 solver.cpp:57] Iteration 168000, loss = 0.00384021
I0623 20:43:55.902660 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00384038 (* 1 = 0.00384038 loss)
I0623 20:43:55.902672 17263 sgd_solver.cpp:43] Iteration 168000, lr = 0.001
I0623 20:57:21.859357 17263 solver.cpp:174] Iteration 168400, Testing net (#0)
I0623 20:58:27.111778 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946719
I0623 20:58:27.122418 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.261799 (* 1 = 0.261799 loss)
I0623 20:58:28.962013 17263 solver.cpp:57] Iteration 168400, loss = 0.00990403
I0623 20:58:28.962056 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00990417 (* 1 = 0.00990417 loss)
I0623 20:58:28.962066 17263 sgd_solver.cpp:43] Iteration 168400, lr = 0.001
I0623 21:11:55.587743 17263 solver.cpp:174] Iteration 168800, Testing net (#0)
I0623 21:13:00.912679 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946328
I0623 21:13:00.912894 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.262819 (* 1 = 0.262819 loss)
I0623 21:13:03.076047 17263 solver.cpp:57] Iteration 168800, loss = 0.00115449
I0623 21:13:03.076088 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00115464 (* 1 = 0.00115464 loss)
I0623 21:13:03.076097 17263 sgd_solver.cpp:43] Iteration 168800, lr = 0.001
I0623 21:26:27.169471 17263 solver.cpp:174] Iteration 169200, Testing net (#0)
I0623 21:27:32.494155 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947969
I0623 21:27:32.494323 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.260109 (* 1 = 0.260109 loss)
I0623 21:27:34.471226 17263 solver.cpp:57] Iteration 169200, loss = 0.00389211
I0623 21:27:34.471272 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00389227 (* 1 = 0.00389227 loss)
I0623 21:27:34.471282 17263 sgd_solver.cpp:43] Iteration 169200, lr = 0.001
I0623 21:40:59.170464 17263 solver.cpp:174] Iteration 169600, Testing net (#0)
I0623 21:42:04.506973 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947031
I0623 21:42:04.507218 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.26605 (* 1 = 0.26605 loss)
I0623 21:42:06.564339 17263 solver.cpp:57] Iteration 169600, loss = 0.00135185
I0623 21:42:06.564393 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00135202 (* 1 = 0.00135202 loss)
I0623 21:42:06.564400 17263 sgd_solver.cpp:43] Iteration 169600, lr = 0.001
I0623 21:55:33.332293 17263 solver.cpp:174] Iteration 170000, Testing net (#0)
I0623 21:56:38.624840 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947031
I0623 21:56:38.625031 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.263212 (* 1 = 0.263212 loss)
I0623 21:56:40.845712 17263 solver.cpp:57] Iteration 170000, loss = 0.00155701
I0623 21:56:40.845752 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00155718 (* 1 = 0.00155718 loss)
I0623 21:56:40.845759 17263 sgd_solver.cpp:43] Iteration 170000, lr = 0.001
I0623 22:10:08.989776 17263 solver.cpp:174] Iteration 170400, Testing net (#0)
I0623 22:11:14.194186 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947344
I0623 22:11:14.206423 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.260037 (* 1 = 0.260037 loss)
I0623 22:11:16.161032 17263 solver.cpp:57] Iteration 170400, loss = 0.00454355
I0623 22:11:16.161069 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00454372 (* 1 = 0.00454372 loss)
I0623 22:11:16.161077 17263 sgd_solver.cpp:43] Iteration 170400, lr = 0.001
I0623 22:24:41.785614 17263 solver.cpp:174] Iteration 170800, Testing net (#0)
I0623 22:25:47.074684 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.948281
I0623 22:25:47.074892 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.251193 (* 1 = 0.251193 loss)
I0623 22:25:49.194285 17263 solver.cpp:57] Iteration 170800, loss = 0.000238737
I0623 22:25:49.194322 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000238923 (* 1 = 0.000238923 loss)
I0623 22:25:49.194330 17263 sgd_solver.cpp:43] Iteration 170800, lr = 0.001
I0623 22:39:13.009348 17263 solver.cpp:174] Iteration 171200, Testing net (#0)
I0623 22:40:18.261028 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946641
I0623 22:40:18.261250 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.26321 (* 1 = 0.26321 loss)
I0623 22:40:20.123332 17263 solver.cpp:57] Iteration 171200, loss = 0.104346
I0623 22:40:20.123375 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.104346 (* 1 = 0.104346 loss)
I0623 22:40:20.123383 17263 sgd_solver.cpp:43] Iteration 171200, lr = 0.001
I0623 22:53:45.864447 17263 solver.cpp:174] Iteration 171600, Testing net (#0)
I0623 22:54:51.130980 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947187
I0623 22:54:51.131180 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.258766 (* 1 = 0.258766 loss)
I0623 22:54:53.195772 17263 solver.cpp:57] Iteration 171600, loss = 0.00521505
I0623 22:54:53.195816 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00521528 (* 1 = 0.00521528 loss)
I0623 22:54:53.195824 17263 sgd_solver.cpp:43] Iteration 171600, lr = 0.001
I0623 23:08:22.067466 17263 solver.cpp:174] Iteration 172000, Testing net (#0)
I0623 23:09:27.366081 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.948438
I0623 23:09:27.366274 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.254565 (* 1 = 0.254565 loss)
I0623 23:09:29.412762 17263 solver.cpp:57] Iteration 172000, loss = 0.000997435
I0623 23:09:29.412802 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000997681 (* 1 = 0.000997681 loss)
I0623 23:09:29.412811 17263 sgd_solver.cpp:43] Iteration 172000, lr = 0.001
I0623 23:22:59.419140 17263 solver.cpp:174] Iteration 172400, Testing net (#0)
I0623 23:24:04.688065 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947187
I0623 23:24:04.694399 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.261766 (* 1 = 0.261766 loss)
I0623 23:24:06.677546 17263 solver.cpp:57] Iteration 172400, loss = 0.00978282
I0623 23:24:06.677583 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00978306 (* 1 = 0.00978306 loss)
I0623 23:24:06.677592 17263 sgd_solver.cpp:43] Iteration 172400, lr = 0.001
I0623 23:37:35.343771 17263 solver.cpp:174] Iteration 172800, Testing net (#0)
I0623 23:38:40.657402 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.945859
I0623 23:38:40.657620 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.262444 (* 1 = 0.262444 loss)
I0623 23:38:42.594624 17263 solver.cpp:57] Iteration 172800, loss = 0.0248241
I0623 23:38:42.594666 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0248243 (* 1 = 0.0248243 loss)
I0623 23:38:42.594672 17263 sgd_solver.cpp:43] Iteration 172800, lr = 0.001
I0623 23:52:11.663764 17263 solver.cpp:174] Iteration 173200, Testing net (#0)
I0623 23:53:16.933874 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946953
I0623 23:53:16.934085 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.258241 (* 1 = 0.258241 loss)
I0623 23:53:19.098991 17263 solver.cpp:57] Iteration 173200, loss = 0.00609788
I0623 23:53:19.099043 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00609808 (* 1 = 0.00609808 loss)
I0623 23:53:19.099056 17263 sgd_solver.cpp:43] Iteration 173200, lr = 0.001
I0624 00:06:42.808192 17263 solver.cpp:174] Iteration 173600, Testing net (#0)
I0624 00:07:48.129148 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.949609
I0624 00:07:48.134402 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.248921 (* 1 = 0.248921 loss)
I0624 00:07:49.977499 17263 solver.cpp:57] Iteration 173600, loss = 0.000381244
I0624 00:07:49.977541 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000381461 (* 1 = 0.000381461 loss)
I0624 00:07:49.977548 17263 sgd_solver.cpp:43] Iteration 173600, lr = 0.001
I0624 00:21:17.303642 17263 solver.cpp:174] Iteration 174000, Testing net (#0)
I0624 00:22:22.602764 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946328
I0624 00:22:22.602965 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.251884 (* 1 = 0.251884 loss)
I0624 00:22:24.521736 17263 solver.cpp:57] Iteration 174000, loss = 0.0176039
I0624 00:22:24.521775 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0176041 (* 1 = 0.0176041 loss)
I0624 00:22:24.521782 17263 sgd_solver.cpp:43] Iteration 174000, lr = 0.001
I0624 00:35:50.773993 17263 solver.cpp:174] Iteration 174400, Testing net (#0)
I0624 00:36:56.110174 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946406
I0624 00:36:56.110404 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.265597 (* 1 = 0.265597 loss)
I0624 00:36:57.974117 17263 solver.cpp:57] Iteration 174400, loss = 0.0136535
I0624 00:36:57.974181 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0136538 (* 1 = 0.0136538 loss)
I0624 00:36:57.974197 17263 sgd_solver.cpp:43] Iteration 174400, lr = 0.001
I0624 00:50:24.843466 17263 solver.cpp:174] Iteration 174800, Testing net (#0)
I0624 00:51:30.080202 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.948672
I0624 00:51:30.080411 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.252872 (* 1 = 0.252872 loss)
I0624 00:51:32.053364 17263 solver.cpp:57] Iteration 174800, loss = 0.00577406
I0624 00:51:32.053421 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00577427 (* 1 = 0.00577427 loss)
I0624 00:51:32.053432 17263 sgd_solver.cpp:43] Iteration 174800, lr = 0.001
I0624 01:04:56.696389 17263 solver.cpp:174] Iteration 175200, Testing net (#0)
I0624 01:06:01.987651 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.948359
I0624 01:06:01.987855 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.262932 (* 1 = 0.262932 loss)
I0624 01:06:03.834753 17263 solver.cpp:57] Iteration 175200, loss = 0.0120244
I0624 01:06:03.834791 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0120246 (* 1 = 0.0120246 loss)
I0624 01:06:03.834800 17263 sgd_solver.cpp:43] Iteration 175200, lr = 0.001
I0624 01:19:29.755514 17263 solver.cpp:174] Iteration 175600, Testing net (#0)
I0624 01:20:35.070374 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946563
I0624 01:20:35.070932 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.262813 (* 1 = 0.262813 loss)
I0624 01:20:36.856669 17263 solver.cpp:57] Iteration 175600, loss = 0.00918095
I0624 01:20:36.856746 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00918118 (* 1 = 0.00918118 loss)
I0624 01:20:36.856765 17263 sgd_solver.cpp:43] Iteration 175600, lr = 0.001
I0624 01:34:01.578436 17263 solver.cpp:174] Iteration 176000, Testing net (#0)
I0624 01:35:06.880960 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947656
I0624 01:35:06.881134 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.258807 (* 1 = 0.258807 loss)
I0624 01:35:08.624337 17263 solver.cpp:57] Iteration 176000, loss = 0.0130993
I0624 01:35:08.624375 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0130995 (* 1 = 0.0130995 loss)
I0624 01:35:08.624382 17263 sgd_solver.cpp:43] Iteration 176000, lr = 0.001
I0624 01:48:35.363111 17263 solver.cpp:174] Iteration 176400, Testing net (#0)
I0624 01:49:40.673740 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.951016
I0624 01:49:40.673943 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.259651 (* 1 = 0.259651 loss)
I0624 01:49:42.663509 17263 solver.cpp:57] Iteration 176400, loss = 0.000232402
I0624 01:49:42.663548 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000232662 (* 1 = 0.000232662 loss)
I0624 01:49:42.663555 17263 sgd_solver.cpp:43] Iteration 176400, lr = 0.001
I0624 02:03:07.253028 17263 solver.cpp:174] Iteration 176800, Testing net (#0)
I0624 02:04:12.553576 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947812
I0624 02:04:12.553783 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.259994 (* 1 = 0.259994 loss)
I0624 02:04:14.611475 17263 solver.cpp:57] Iteration 176800, loss = 0.00173157
I0624 02:04:14.611546 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00173184 (* 1 = 0.00173184 loss)
I0624 02:04:14.611569 17263 sgd_solver.cpp:43] Iteration 176800, lr = 0.001
I0624 02:17:37.538116 17263 solver.cpp:174] Iteration 177200, Testing net (#0)
I0624 02:18:42.819241 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946875
I0624 02:18:42.819440 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.263957 (* 1 = 0.263957 loss)
I0624 02:18:44.646776 17263 solver.cpp:57] Iteration 177200, loss = 0.00388525
I0624 02:18:44.646824 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00388554 (* 1 = 0.00388554 loss)
I0624 02:18:44.646834 17263 sgd_solver.cpp:43] Iteration 177200, lr = 0.001
I0624 02:32:12.724258 17263 solver.cpp:174] Iteration 177600, Testing net (#0)
I0624 02:33:17.991755 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946328
I0624 02:33:17.991950 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.269187 (* 1 = 0.269187 loss)
I0624 02:33:20.155830 17263 solver.cpp:57] Iteration 177600, loss = 0.000340078
I0624 02:33:20.155874 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000340332 (* 1 = 0.000340332 loss)
I0624 02:33:20.155881 17263 sgd_solver.cpp:43] Iteration 177600, lr = 0.001
I0624 02:46:49.829489 17263 solver.cpp:174] Iteration 178000, Testing net (#0)
I0624 02:47:55.157804 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947734
I0624 02:47:55.170429 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.257776 (* 1 = 0.257776 loss)
I0624 02:47:57.258987 17263 solver.cpp:57] Iteration 178000, loss = 0.0012128
I0624 02:47:57.259024 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00121305 (* 1 = 0.00121305 loss)
I0624 02:47:57.259032 17263 sgd_solver.cpp:43] Iteration 178000, lr = 0.001
I0624 03:01:25.509845 17263 solver.cpp:174] Iteration 178400, Testing net (#0)
I0624 03:02:30.806502 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946406
I0624 03:02:30.806704 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.250877 (* 1 = 0.250877 loss)
I0624 03:02:32.785173 17263 solver.cpp:57] Iteration 178400, loss = 0.0192837
I0624 03:02:32.785230 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0192839 (* 1 = 0.0192839 loss)
I0624 03:02:32.785241 17263 sgd_solver.cpp:43] Iteration 178400, lr = 0.001
I0624 03:15:57.671658 17263 solver.cpp:174] Iteration 178800, Testing net (#0)
I0624 03:17:02.939409 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947812
I0624 03:17:02.939631 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.260006 (* 1 = 0.260006 loss)
I0624 03:17:05.061017 17263 solver.cpp:57] Iteration 178800, loss = 0.0189968
I0624 03:17:05.061058 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.018997 (* 1 = 0.018997 loss)
I0624 03:17:05.061065 17263 sgd_solver.cpp:43] Iteration 178800, lr = 0.001
I0624 03:30:29.473685 17263 solver.cpp:174] Iteration 179200, Testing net (#0)
I0624 03:31:34.730161 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.948203
I0624 03:31:34.730367 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.247613 (* 1 = 0.247613 loss)
I0624 03:31:36.879407 17263 solver.cpp:57] Iteration 179200, loss = 0.000702355
I0624 03:31:36.879461 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000702612 (* 1 = 0.000702612 loss)
I0624 03:31:36.879470 17263 sgd_solver.cpp:43] Iteration 179200, lr = 0.001
I0624 03:45:07.706501 17263 solver.cpp:174] Iteration 179600, Testing net (#0)
I0624 03:46:12.996487 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.9475
I0624 03:46:12.996685 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.255772 (* 1 = 0.255772 loss)
I0624 03:46:15.047521 17263 solver.cpp:57] Iteration 179600, loss = 0.00109406
I0624 03:46:15.047585 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0010943 (* 1 = 0.0010943 loss)
I0624 03:46:15.047600 17263 sgd_solver.cpp:43] Iteration 179600, lr = 0.001
I0624 03:59:44.198633 17263 solver.cpp:174] Iteration 180000, Testing net (#0)
I0624 04:00:49.522405 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947344
I0624 04:00:49.522603 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.254572 (* 1 = 0.254572 loss)
I0624 04:00:51.566587 17263 solver.cpp:57] Iteration 180000, loss = 0.0105859
I0624 04:00:51.566628 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0105861 (* 1 = 0.0105861 loss)
I0624 04:00:51.566638 17263 sgd_solver.cpp:43] Iteration 180000, lr = 0.001
I0624 04:14:18.002985 17263 solver.cpp:174] Iteration 180400, Testing net (#0)
I0624 04:15:23.318722 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.945938
I0624 04:15:23.318930 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.258951 (* 1 = 0.258951 loss)
I0624 04:15:25.117094 17263 solver.cpp:57] Iteration 180400, loss = 0.0177086
I0624 04:15:25.117137 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0177088 (* 1 = 0.0177088 loss)
I0624 04:15:25.117144 17263 sgd_solver.cpp:43] Iteration 180400, lr = 0.001
I0624 04:28:49.388512 17263 solver.cpp:174] Iteration 180800, Testing net (#0)
I0624 04:29:54.671670 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.949219
I0624 04:29:54.675524 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.250145 (* 1 = 0.250145 loss)
I0624 04:29:56.641623 17263 solver.cpp:57] Iteration 180800, loss = 0.0182905
I0624 04:29:56.641664 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0182908 (* 1 = 0.0182908 loss)
I0624 04:29:56.641671 17263 sgd_solver.cpp:43] Iteration 180800, lr = 0.001
I0624 04:43:24.277758 17263 solver.cpp:174] Iteration 181200, Testing net (#0)
I0624 04:44:29.555697 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.945156
I0624 04:44:29.562397 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.266063 (* 1 = 0.266063 loss)
I0624 04:44:31.753542 17263 solver.cpp:57] Iteration 181200, loss = 0.00030558
I0624 04:44:31.753608 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000305773 (* 1 = 0.000305773 loss)
I0624 04:44:31.753624 17263 sgd_solver.cpp:43] Iteration 181200, lr = 0.001
I0624 04:57:58.004501 17263 solver.cpp:174] Iteration 181600, Testing net (#0)
I0624 04:59:03.307924 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947344
I0624 04:59:03.308148 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.265274 (* 1 = 0.265274 loss)
I0624 04:59:05.469332 17263 solver.cpp:57] Iteration 181600, loss = 0.000660044
I0624 04:59:05.469388 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000660237 (* 1 = 0.000660237 loss)
I0624 04:59:05.469399 17263 sgd_solver.cpp:43] Iteration 181600, lr = 0.001
I0624 05:12:28.410815 17263 solver.cpp:174] Iteration 182000, Testing net (#0)
I0624 05:13:33.757549 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947109
I0624 05:13:33.757707 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.257741 (* 1 = 0.257741 loss)
I0624 05:13:35.761920 17263 solver.cpp:57] Iteration 182000, loss = 0.0162121
I0624 05:13:35.761960 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0162123 (* 1 = 0.0162123 loss)
I0624 05:13:35.761966 17263 sgd_solver.cpp:43] Iteration 182000, lr = 0.001
I0624 05:27:01.952618 17263 solver.cpp:174] Iteration 182400, Testing net (#0)
I0624 05:28:07.315498 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947266
I0624 05:28:07.326424 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.258091 (* 1 = 0.258091 loss)
I0624 05:28:09.192234 17263 solver.cpp:57] Iteration 182400, loss = 0.0136647
I0624 05:28:09.192271 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0136649 (* 1 = 0.0136649 loss)
I0624 05:28:09.192279 17263 sgd_solver.cpp:43] Iteration 182400, lr = 0.001
I0624 05:41:34.023627 17263 solver.cpp:174] Iteration 182800, Testing net (#0)
I0624 05:42:39.283221 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.945859
I0624 05:42:39.283486 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.264047 (* 1 = 0.264047 loss)
I0624 05:42:41.160259 17263 solver.cpp:57] Iteration 182800, loss = 0.00210119
I0624 05:42:41.160306 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00210135 (* 1 = 0.00210135 loss)
I0624 05:42:41.160315 17263 sgd_solver.cpp:43] Iteration 182800, lr = 0.001
I0624 05:56:06.954886 17263 solver.cpp:174] Iteration 183200, Testing net (#0)
I0624 05:57:12.187357 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.945938
I0624 05:57:12.187568 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.261699 (* 1 = 0.261699 loss)
I0624 05:57:14.234380 17263 solver.cpp:57] Iteration 183200, loss = 0.0128735
I0624 05:57:14.234426 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0128737 (* 1 = 0.0128737 loss)
I0624 05:57:14.234436 17263 sgd_solver.cpp:43] Iteration 183200, lr = 0.001
I0624 06:10:37.401870 17263 solver.cpp:174] Iteration 183600, Testing net (#0)
I0624 06:11:42.697785 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946719
I0624 06:11:42.697975 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.265202 (* 1 = 0.265202 loss)
I0624 06:11:44.609583 17263 solver.cpp:57] Iteration 183600, loss = 0.00105479
I0624 06:11:44.609623 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00105497 (* 1 = 0.00105497 loss)
I0624 06:11:44.609630 17263 sgd_solver.cpp:43] Iteration 183600, lr = 0.001
I0624 06:25:06.738289 17263 solver.cpp:174] Iteration 184000, Testing net (#0)
I0624 06:26:11.950598 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946953
I0624 06:26:11.950809 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.257236 (* 1 = 0.257236 loss)
I0624 06:26:13.997040 17263 solver.cpp:57] Iteration 184000, loss = 0.000345258
I0624 06:26:13.997089 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000345454 (* 1 = 0.000345454 loss)
I0624 06:26:13.997100 17263 sgd_solver.cpp:43] Iteration 184000, lr = 0.001
I0624 06:39:44.457830 17263 solver.cpp:174] Iteration 184400, Testing net (#0)
I0624 06:40:49.741762 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947578
I0624 06:40:49.741972 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.259936 (* 1 = 0.259936 loss)
I0624 06:40:51.858000 17263 solver.cpp:57] Iteration 184400, loss = 0.00165567
I0624 06:40:51.858045 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00165588 (* 1 = 0.00165588 loss)
I0624 06:40:51.858057 17263 sgd_solver.cpp:43] Iteration 184400, lr = 0.001
I0624 06:54:22.414270 17263 solver.cpp:174] Iteration 184800, Testing net (#0)
I0624 06:55:27.664762 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947656
I0624 06:55:27.678422 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.259351 (* 1 = 0.259351 loss)
I0624 06:55:29.459086 17263 solver.cpp:57] Iteration 184800, loss = 0.00315811
I0624 06:55:29.459117 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00315834 (* 1 = 0.00315834 loss)
I0624 06:55:29.459125 17263 sgd_solver.cpp:43] Iteration 184800, lr = 0.001
I0624 07:08:56.796913 17263 solver.cpp:174] Iteration 185200, Testing net (#0)
I0624 07:10:02.108994 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947578
I0624 07:10:02.109156 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.261859 (* 1 = 0.261859 loss)
I0624 07:10:04.157564 17263 solver.cpp:57] Iteration 185200, loss = 0.00186212
I0624 07:10:04.157605 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00186235 (* 1 = 0.00186235 loss)
I0624 07:10:04.157613 17263 sgd_solver.cpp:43] Iteration 185200, lr = 0.001
I0624 07:23:29.175536 17263 solver.cpp:174] Iteration 185600, Testing net (#0)
I0624 07:24:34.388906 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947656
I0624 07:24:34.402456 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.256784 (* 1 = 0.256784 loss)
I0624 07:24:36.532111 17263 solver.cpp:57] Iteration 185600, loss = 0.000252269
I0624 07:24:36.532152 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000252485 (* 1 = 0.000252485 loss)
I0624 07:24:36.532166 17263 sgd_solver.cpp:43] Iteration 185600, lr = 0.001
I0624 07:38:00.163548 17263 solver.cpp:174] Iteration 186000, Testing net (#0)
I0624 07:39:05.449618 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.948594
I0624 07:39:05.462417 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.262023 (* 1 = 0.262023 loss)
I0624 07:39:07.265709 17263 solver.cpp:57] Iteration 186000, loss = 0.00318095
I0624 07:39:07.265760 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00318117 (* 1 = 0.00318117 loss)
I0624 07:39:07.265770 17263 sgd_solver.cpp:43] Iteration 186000, lr = 0.001
I0624 07:52:32.348853 17263 solver.cpp:174] Iteration 186400, Testing net (#0)
I0624 07:53:37.652668 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.948984
I0624 07:53:37.666440 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.260244 (* 1 = 0.260244 loss)
I0624 07:53:39.643141 17263 solver.cpp:57] Iteration 186400, loss = 0.000838622
I0624 07:53:39.643187 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000838841 (* 1 = 0.000838841 loss)
I0624 07:53:39.643196 17263 sgd_solver.cpp:43] Iteration 186400, lr = 0.001
I0624 08:07:09.463430 17263 solver.cpp:174] Iteration 186800, Testing net (#0)
I0624 08:08:14.761773 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946563
I0624 08:08:14.761981 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.26837 (* 1 = 0.26837 loss)
I0624 08:08:16.422345 17263 solver.cpp:57] Iteration 186800, loss = 0.0901293
I0624 08:08:16.422396 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0901296 (* 1 = 0.0901296 loss)
I0624 08:08:16.422405 17263 sgd_solver.cpp:43] Iteration 186800, lr = 0.001
I0624 08:21:43.551445 17263 solver.cpp:174] Iteration 187200, Testing net (#0)
I0624 08:22:48.816718 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947812
I0624 08:22:48.817080 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.263258 (* 1 = 0.263258 loss)
I0624 08:22:50.860361 17263 solver.cpp:57] Iteration 187200, loss = 0.00697238
I0624 08:22:50.860404 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00697262 (* 1 = 0.00697262 loss)
I0624 08:22:50.860410 17263 sgd_solver.cpp:43] Iteration 187200, lr = 0.001
I0624 08:36:17.103386 17263 solver.cpp:174] Iteration 187600, Testing net (#0)
I0624 08:37:22.407161 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.949297
I0624 08:37:22.407373 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.258472 (* 1 = 0.258472 loss)
I0624 08:37:24.317782 17263 solver.cpp:57] Iteration 187600, loss = 0.0423913
I0624 08:37:24.317824 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0423916 (* 1 = 0.0423916 loss)
I0624 08:37:24.317832 17263 sgd_solver.cpp:43] Iteration 187600, lr = 0.001
I0624 08:50:55.010038 17263 solver.cpp:174] Iteration 188000, Testing net (#0)
I0624 08:52:00.249191 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947578
I0624 08:52:00.262451 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.26881 (* 1 = 0.26881 loss)
I0624 08:52:02.355850 17263 solver.cpp:57] Iteration 188000, loss = 0.00145759
I0624 08:52:02.355901 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00145785 (* 1 = 0.00145785 loss)
I0624 08:52:02.355907 17263 sgd_solver.cpp:43] Iteration 188000, lr = 0.001
I0624 09:05:25.770345 17263 solver.cpp:174] Iteration 188400, Testing net (#0)
I0624 09:06:31.085041 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947656
I0624 09:06:31.085247 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.256441 (* 1 = 0.256441 loss)
I0624 09:06:33.207846 17263 solver.cpp:57] Iteration 188400, loss = 0.00227913
I0624 09:06:33.207901 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00227939 (* 1 = 0.00227939 loss)
I0624 09:06:33.207909 17263 sgd_solver.cpp:43] Iteration 188400, lr = 0.001
I0624 09:19:58.281901 17263 solver.cpp:174] Iteration 188800, Testing net (#0)
I0624 09:21:03.569471 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947109
I0624 09:21:03.569670 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.268074 (* 1 = 0.268074 loss)
I0624 09:21:05.547113 17263 solver.cpp:57] Iteration 188800, loss = 0.00616908
I0624 09:21:05.547160 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00616934 (* 1 = 0.00616934 loss)
I0624 09:21:05.547169 17263 sgd_solver.cpp:43] Iteration 188800, lr = 0.001
I0624 09:34:30.224732 17263 solver.cpp:174] Iteration 189200, Testing net (#0)
I0624 09:35:35.509902 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.948047
I0624 09:35:35.510118 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.262182 (* 1 = 0.262182 loss)
I0624 09:35:37.373309 17263 solver.cpp:57] Iteration 189200, loss = 0.0184368
I0624 09:35:37.373359 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.018437 (* 1 = 0.018437 loss)
I0624 09:35:37.373370 17263 sgd_solver.cpp:43] Iteration 189200, lr = 0.001
I0624 09:49:03.894817 17263 solver.cpp:174] Iteration 189600, Testing net (#0)
I0624 09:50:09.178299 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.945469
I0624 09:50:09.186425 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.27338 (* 1 = 0.27338 loss)
I0624 09:50:11.342735 17263 solver.cpp:57] Iteration 189600, loss = 0.000541274
I0624 09:50:11.342767 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000541548 (* 1 = 0.000541548 loss)
I0624 09:50:11.342775 17263 sgd_solver.cpp:43] Iteration 189600, lr = 0.001
I0624 10:03:39.327407 17263 solver.cpp:174] Iteration 190000, Testing net (#0)
I0624 10:04:44.567836 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.945859
I0624 10:04:44.567988 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.271861 (* 1 = 0.271861 loss)
I0624 10:04:46.455101 17263 solver.cpp:57] Iteration 190000, loss = 0.0128486
I0624 10:04:46.455155 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0128489 (* 1 = 0.0128489 loss)
I0624 10:04:46.455168 17263 sgd_solver.cpp:43] Iteration 190000, lr = 0.001
I0624 10:18:14.664669 17263 solver.cpp:174] Iteration 190400, Testing net (#0)
I0624 10:19:20.009306 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947109
I0624 10:19:20.009461 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.261635 (* 1 = 0.261635 loss)
I0624 10:19:21.735307 17263 solver.cpp:57] Iteration 190400, loss = 0.0343962
I0624 10:19:21.735348 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0343965 (* 1 = 0.0343965 loss)
I0624 10:19:21.735357 17263 sgd_solver.cpp:43] Iteration 190400, lr = 0.001
I0624 10:32:49.380092 17263 solver.cpp:174] Iteration 190800, Testing net (#0)
I0624 10:33:54.672826 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.948281
I0624 10:33:54.673043 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.262897 (* 1 = 0.262897 loss)
I0624 10:33:56.768692 17263 solver.cpp:57] Iteration 190800, loss = 0.00231149
I0624 10:33:56.768736 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00231178 (* 1 = 0.00231178 loss)
I0624 10:33:56.768746 17263 sgd_solver.cpp:43] Iteration 190800, lr = 0.001
I0624 10:47:23.102602 17263 solver.cpp:174] Iteration 191200, Testing net (#0)
I0624 10:48:28.411723 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.944844
I0624 10:48:28.411922 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.271436 (* 1 = 0.271436 loss)
I0624 10:48:30.426533 17263 solver.cpp:57] Iteration 191200, loss = 0.000808403
I0624 10:48:30.426573 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000808697 (* 1 = 0.000808697 loss)
I0624 10:48:30.426578 17263 sgd_solver.cpp:43] Iteration 191200, lr = 0.001
I0624 11:01:57.210292 17263 solver.cpp:174] Iteration 191600, Testing net (#0)
I0624 11:03:02.572772 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946094
I0624 11:03:02.572962 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.266203 (* 1 = 0.266203 loss)
I0624 11:03:04.274826 17263 solver.cpp:57] Iteration 191600, loss = 0.0505019
I0624 11:03:04.274868 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0505022 (* 1 = 0.0505022 loss)
I0624 11:03:04.274878 17263 sgd_solver.cpp:43] Iteration 191600, lr = 0.001
I0624 11:16:29.762827 17263 solver.cpp:174] Iteration 192000, Testing net (#0)
I0624 11:17:35.054155 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.948594
I0624 11:17:35.058424 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.254775 (* 1 = 0.254775 loss)
I0624 11:17:36.859086 17263 solver.cpp:57] Iteration 192000, loss = 0.00560619
I0624 11:17:36.859118 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0056065 (* 1 = 0.0056065 loss)
I0624 11:17:36.859125 17263 sgd_solver.cpp:43] Iteration 192000, lr = 0.001
I0624 11:31:04.205843 17263 solver.cpp:174] Iteration 192400, Testing net (#0)
I0624 11:32:09.502022 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.945781
I0624 11:32:09.503613 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.275931 (* 1 = 0.275931 loss)
I0624 11:32:11.696045 17263 solver.cpp:57] Iteration 192400, loss = 0.00392566
I0624 11:32:11.696087 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00392596 (* 1 = 0.00392596 loss)
I0624 11:32:11.696094 17263 sgd_solver.cpp:43] Iteration 192400, lr = 0.001
I0624 11:45:36.196477 17263 solver.cpp:174] Iteration 192800, Testing net (#0)
I0624 11:46:41.580785 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947031
I0624 11:46:41.581004 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.258553 (* 1 = 0.258553 loss)
I0624 11:46:43.602934 17263 solver.cpp:57] Iteration 192800, loss = 0.00201505
I0624 11:46:43.602980 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00201537 (* 1 = 0.00201537 loss)
I0624 11:46:43.602989 17263 sgd_solver.cpp:43] Iteration 192800, lr = 0.001
I0624 12:00:05.841612 17263 solver.cpp:174] Iteration 193200, Testing net (#0)
I0624 12:01:11.118345 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.948594
I0624 12:01:11.118568 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.250326 (* 1 = 0.250326 loss)
I0624 12:01:13.270279 17263 solver.cpp:57] Iteration 193200, loss = 0.000315353
I0624 12:01:13.270325 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000315662 (* 1 = 0.000315662 loss)
I0624 12:01:13.270334 17263 sgd_solver.cpp:43] Iteration 193200, lr = 0.001
I0624 12:14:42.316896 17263 solver.cpp:174] Iteration 193600, Testing net (#0)
I0624 12:15:47.601701 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.948438
I0624 12:15:47.601912 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.266258 (* 1 = 0.266258 loss)
I0624 12:15:49.305917 17263 solver.cpp:57] Iteration 193600, loss = 0.0560244
I0624 12:15:49.305960 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0560246 (* 1 = 0.0560246 loss)
I0624 12:15:49.305968 17263 sgd_solver.cpp:43] Iteration 193600, lr = 0.001
I0624 12:29:15.195322 17263 solver.cpp:174] Iteration 194000, Testing net (#0)
I0624 12:30:20.447866 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947656
I0624 12:30:20.448107 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.25977 (* 1 = 0.25977 loss)
I0624 12:30:22.569428 17263 solver.cpp:57] Iteration 194000, loss = 0.000290587
I0624 12:30:22.569473 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000290869 (* 1 = 0.000290869 loss)
I0624 12:30:22.569481 17263 sgd_solver.cpp:43] Iteration 194000, lr = 0.001
I0624 12:43:48.150671 17263 solver.cpp:174] Iteration 194400, Testing net (#0)
I0624 12:44:53.423239 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.948984
I0624 12:44:53.423468 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.259866 (* 1 = 0.259866 loss)
I0624 12:44:55.371783 17263 solver.cpp:57] Iteration 194400, loss = 0.000922358
I0624 12:44:55.371846 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000922614 (* 1 = 0.000922614 loss)
I0624 12:44:55.371860 17263 sgd_solver.cpp:43] Iteration 194400, lr = 0.001
I0624 12:58:22.088883 17263 solver.cpp:174] Iteration 194800, Testing net (#0)
I0624 12:59:27.371635 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.948594
I0624 12:59:27.371840 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.250716 (* 1 = 0.250716 loss)
I0624 12:59:29.391683 17263 solver.cpp:57] Iteration 194800, loss = 0.0642821
I0624 12:59:29.391721 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0642824 (* 1 = 0.0642824 loss)
I0624 12:59:29.391729 17263 sgd_solver.cpp:43] Iteration 194800, lr = 0.001
I0624 13:12:57.395496 17263 solver.cpp:174] Iteration 195200, Testing net (#0)
I0624 13:14:02.658105 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947812
I0624 13:14:02.658316 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.263941 (* 1 = 0.263941 loss)
I0624 13:14:04.895267 17263 solver.cpp:57] Iteration 195200, loss = 0.000757967
I0624 13:14:04.895311 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000758202 (* 1 = 0.000758202 loss)
I0624 13:14:04.895321 17263 sgd_solver.cpp:43] Iteration 195200, lr = 0.001
I0624 13:27:29.773586 17263 solver.cpp:174] Iteration 195600, Testing net (#0)
I0624 13:28:35.028389 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947031
I0624 13:28:35.028599 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.263361 (* 1 = 0.263361 loss)
I0624 13:28:37.073915 17263 solver.cpp:57] Iteration 195600, loss = 0.00645777
I0624 13:28:37.073954 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00645799 (* 1 = 0.00645799 loss)
I0624 13:28:37.073961 17263 sgd_solver.cpp:43] Iteration 195600, lr = 0.001
I0624 13:42:00.612551 17263 solver.cpp:174] Iteration 196000, Testing net (#0)
I0624 13:43:05.899431 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947734
I0624 13:43:05.899565 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.265105 (* 1 = 0.265105 loss)
I0624 13:43:07.990412 17263 solver.cpp:57] Iteration 196000, loss = 0.00176049
I0624 13:43:07.990455 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00176072 (* 1 = 0.00176072 loss)
I0624 13:43:07.990464 17263 sgd_solver.cpp:43] Iteration 196000, lr = 0.001
I0624 13:56:38.119909 17263 solver.cpp:174] Iteration 196400, Testing net (#0)
I0624 13:57:43.517995 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.948672
I0624 13:57:43.518206 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.266133 (* 1 = 0.266133 loss)
I0624 13:57:45.662001 17263 solver.cpp:57] Iteration 196400, loss = 0.000711846
I0624 13:57:45.662046 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.000712071 (* 1 = 0.000712071 loss)
I0624 13:57:45.662057 17263 sgd_solver.cpp:43] Iteration 196400, lr = 0.001
I0624 14:11:14.916185 17263 solver.cpp:174] Iteration 196800, Testing net (#0)
I0624 14:12:20.281014 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947344
I0624 14:12:20.290436 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.26636 (* 1 = 0.26636 loss)
I0624 14:12:22.273010 17263 solver.cpp:57] Iteration 196800, loss = 0.00114903
I0624 14:12:22.273049 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00114924 (* 1 = 0.00114924 loss)
I0624 14:12:22.273058 17263 sgd_solver.cpp:43] Iteration 196800, lr = 0.001
I0624 14:25:46.825816 17263 solver.cpp:174] Iteration 197200, Testing net (#0)
I0624 14:26:52.126979 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947187
I0624 14:26:52.127184 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.269125 (* 1 = 0.269125 loss)
I0624 14:26:54.065033 17263 solver.cpp:57] Iteration 197200, loss = 0.0220992
I0624 14:26:54.065084 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0220994 (* 1 = 0.0220994 loss)
I0624 14:26:54.065101 17263 sgd_solver.cpp:43] Iteration 197200, lr = 0.001
I0624 14:40:20.516822 17263 solver.cpp:174] Iteration 197600, Testing net (#0)
I0624 14:41:26.087855 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946094
I0624 14:41:26.088030 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.266021 (* 1 = 0.266021 loss)
I0624 14:41:28.078968 17263 solver.cpp:57] Iteration 197600, loss = 0.00464101
I0624 14:41:28.079007 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00464122 (* 1 = 0.00464122 loss)
I0624 14:41:28.079015 17263 sgd_solver.cpp:43] Iteration 197600, lr = 0.001
I0624 14:54:57.008999 17263 solver.cpp:174] Iteration 198000, Testing net (#0)
I0624 14:56:02.431485 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947344
I0624 14:56:02.431682 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.268985 (* 1 = 0.268985 loss)
I0624 14:56:04.240710 17263 solver.cpp:57] Iteration 198000, loss = 0.0131416
I0624 14:56:04.240747 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0131418 (* 1 = 0.0131418 loss)
I0624 14:56:04.240756 17263 sgd_solver.cpp:43] Iteration 198000, lr = 0.001
I0624 15:09:39.441359 17263 solver.cpp:174] Iteration 198400, Testing net (#0)
I0624 15:10:45.143573 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.947578
I0624 15:10:45.143757 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.262896 (* 1 = 0.262896 loss)
I0624 15:10:47.220445 17263 solver.cpp:57] Iteration 198400, loss = 0.00163745
I0624 15:10:47.220485 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00163766 (* 1 = 0.00163766 loss)
I0624 15:10:47.220494 17263 sgd_solver.cpp:43] Iteration 198400, lr = 0.001
I0624 15:24:16.890713 17263 solver.cpp:174] Iteration 198800, Testing net (#0)
I0624 15:25:22.620133 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.949297
I0624 15:25:22.620332 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.261106 (* 1 = 0.261106 loss)
I0624 15:25:24.740962 17263 solver.cpp:57] Iteration 198800, loss = 0.0103666
I0624 15:25:24.740998 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.0103668 (* 1 = 0.0103668 loss)
I0624 15:25:24.741005 17263 sgd_solver.cpp:43] Iteration 198800, lr = 0.001
I0624 15:38:57.559417 17263 solver.cpp:174] Iteration 199200, Testing net (#0)
I0624 15:40:03.258263 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.948984
I0624 15:40:03.258527 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.260389 (* 1 = 0.260389 loss)
I0624 15:40:05.282552 17263 solver.cpp:57] Iteration 199200, loss = 0.00366542
I0624 15:40:05.282585 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 0.00366566 (* 1 = 0.00366566 loss)
I0624 15:40:05.282593 17263 sgd_solver.cpp:43] Iteration 199200, lr = 0.001
I0624 15:53:32.997849 17263 solver.cpp:174] Iteration 199600, Testing net (#0)
I0624 15:54:38.290184 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.946563
I0624 15:54:38.290413 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.272212 (* 1 = 0.272212 loss)
I0624 15:54:40.459164 17263 solver.cpp:57] Iteration 199600, loss = 6.80378e-05
I0624 15:54:40.459205 17263 solver.cpp:73]     Train net output #0: SoftmaxWithLoss1 = 6.82686e-05 (* 1 = 6.82686e-05 loss)
I0624 15:54:40.459214 17263 sgd_solver.cpp:43] Iteration 199600, lr = 0.001
I0624 16:08:00.701371 17263 solver.cpp:475] Snapshotting to binary proto file _iter_200000.caffemodel
I0624 16:08:00.923054 17263 sgd_solver.cpp:294] Snapshotting solver state to binary proto file _iter_200000.solverstate
I0624 16:08:01.677901 17263 solver.cpp:150] Iteration 200000, loss = 2.34621
I0624 16:08:01.677939 17263 solver.cpp:174] Iteration 200000, Testing net (#0)
I0624 16:09:06.950323 17263 solver.cpp:241]     Test net output #0: Accuracy = 0.945078
I0624 16:09:06.950544 17263 solver.cpp:241]     Test net output #1: SoftmaxWithLoss1 = 0.271578 (* 1 = 0.271578 loss)
I0624 16:09:06.950570 17263 solver.cpp:155] Optimization Done.
I0624 16:09:06.950580 17263 caffe.cpp:222] Optimization Done.
