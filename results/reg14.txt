I0525 23:43:48.380209 15117 caffe.cpp:185] Using GPUs 0
I0525 23:43:48.412592 15117 caffe.cpp:190] GPU 0: GeForce GTX TITAN X
I0525 23:43:48.785120 15117 solver.cpp:53] Initializing solver from parameters: 
train_net: "examples/stochastic_depth/residual_train.prototxt"
test_net: "examples/stochastic_depth/residual_test.prototxt"
test_iter: 100
test_interval: 100
base_lr: 0.02
display: 10
max_iter: 64000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
solver_mode: GPU
device_id: 0
random_seed: 831486
stepvalue: 32000
stepvalue: 48000
type: "Nesterov"
I0525 23:43:48.785209 15117 solver.cpp:86] Creating training net from train_net file: examples/stochastic_depth/residual_train.prototxt
I0525 23:43:48.790164 15117 net.cpp:148] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "/scratch/pas282/caffe/examples/cifar10/cifar10_train_leveldb_padding1"
    batch_size: 128
    backend: LEVELDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise4"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Input1"
  type: "Input"
  top: "Input1"
  input_param {
    shape {
      dim: 128
      dim: 16
      dim: 16
      dim: 16
    }
  }
}
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "Pooling1"
  bottom: "Input1"
  top: "Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Concat1"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Pooling2"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling2"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Input2"
  type: "Input"
  top: "Input2"
  input_param {
    shape {
      dim: 128
      dim: 32
      dim: 8
      dim: 8
    }
  }
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "Pooling2"
  bottom: "Input2"
  top: "Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Concat2"
  bottom: "Convolution21"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution22"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution22"
  top: "Convolution22"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Convolution22"
  top: "Convolution23"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution23"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution24"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution25"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution26"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution27"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution28"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution28"
  top: "Convolution28"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution29"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Pooling3"
  type: "Pooling"
  bottom: "Eltwise14"
  top: "Pooling3"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling3"
  top: "InnerProduct1"
  inner_product_param {
    num_output: 10
    bias_term: true
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
I0525 23:43:48.791024 15117 layer_factory.hpp:77] Creating layer Data1
I0525 23:43:48.792445 15117 net.cpp:190] Creating Layer Data1
I0525 23:43:48.792501 15117 net.cpp:579] Data1 -> Data1
I0525 23:43:48.792572 15117 net.cpp:579] Data1 -> Data2
I0525 23:43:48.834004 15121 db_leveldb.cpp:18] Opened leveldb /scratch/pas282/caffe/examples/cifar10/cifar10_train_leveldb_padding1
I0525 23:43:48.852670 15117 data_layer.cpp:41] output data size: 128,3,32,32
I0525 23:43:48.858400 15117 net.cpp:240] Setting up Data1
I0525 23:43:48.858461 15117 net.cpp:247] Top shape: 128 3 32 32 (393216)
I0525 23:43:48.858469 15117 net.cpp:247] Top shape: 128 (128)
I0525 23:43:48.858474 15117 net.cpp:255] Memory required for data: 1573376
I0525 23:43:48.858490 15117 layer_factory.hpp:77] Creating layer Convolution1
I0525 23:43:48.858527 15117 net.cpp:190] Creating Layer Convolution1
I0525 23:43:48.858538 15117 net.cpp:605] Convolution1 <- Data1
I0525 23:43:48.858561 15117 net.cpp:579] Convolution1 -> Convolution1
I0525 23:43:48.859711 15117 net.cpp:240] Setting up Convolution1
I0525 23:43:48.859750 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.859755 15117 net.cpp:255] Memory required for data: 9961984
I0525 23:43:48.859783 15117 layer_factory.hpp:77] Creating layer BatchNorm1
I0525 23:43:48.859808 15117 net.cpp:190] Creating Layer BatchNorm1
I0525 23:43:48.859819 15117 net.cpp:605] BatchNorm1 <- Convolution1
I0525 23:43:48.859828 15117 net.cpp:566] BatchNorm1 -> Convolution1 (in-place)
I0525 23:43:48.860182 15117 net.cpp:240] Setting up BatchNorm1
I0525 23:43:48.860195 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.860199 15117 net.cpp:255] Memory required for data: 18350592
I0525 23:43:48.860219 15117 layer_factory.hpp:77] Creating layer Scale1
I0525 23:43:48.860229 15117 net.cpp:190] Creating Layer Scale1
I0525 23:43:48.860234 15117 net.cpp:605] Scale1 <- Convolution1
I0525 23:43:48.860239 15117 net.cpp:566] Scale1 -> Convolution1 (in-place)
I0525 23:43:48.860290 15117 layer_factory.hpp:77] Creating layer Scale1
I0525 23:43:48.860438 15117 net.cpp:240] Setting up Scale1
I0525 23:43:48.860447 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.860451 15117 net.cpp:255] Memory required for data: 26739200
I0525 23:43:48.860460 15117 layer_factory.hpp:77] Creating layer ReLU1
I0525 23:43:48.860476 15117 net.cpp:190] Creating Layer ReLU1
I0525 23:43:48.860479 15117 net.cpp:605] ReLU1 <- Convolution1
I0525 23:43:48.860486 15117 net.cpp:566] ReLU1 -> Convolution1 (in-place)
I0525 23:43:48.860502 15117 net.cpp:240] Setting up ReLU1
I0525 23:43:48.860507 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.860510 15117 net.cpp:255] Memory required for data: 35127808
I0525 23:43:48.860513 15117 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0525 23:43:48.860528 15117 net.cpp:190] Creating Layer Convolution1_ReLU1_0_split
I0525 23:43:48.860532 15117 net.cpp:605] Convolution1_ReLU1_0_split <- Convolution1
I0525 23:43:48.860538 15117 net.cpp:579] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0525 23:43:48.860545 15117 net.cpp:579] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0525 23:43:48.860581 15117 net.cpp:240] Setting up Convolution1_ReLU1_0_split
I0525 23:43:48.860589 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.860594 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.860599 15117 net.cpp:255] Memory required for data: 51905024
I0525 23:43:48.860602 15117 layer_factory.hpp:77] Creating layer Convolution2
I0525 23:43:48.860615 15117 net.cpp:190] Creating Layer Convolution2
I0525 23:43:48.860618 15117 net.cpp:605] Convolution2 <- Convolution1_ReLU1_0_split_0
I0525 23:43:48.860627 15117 net.cpp:579] Convolution2 -> Convolution2
I0525 23:43:48.862936 15117 net.cpp:240] Setting up Convolution2
I0525 23:43:48.862978 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.862984 15117 net.cpp:255] Memory required for data: 60293632
I0525 23:43:48.863008 15117 layer_factory.hpp:77] Creating layer BatchNorm2
I0525 23:43:48.863026 15117 net.cpp:190] Creating Layer BatchNorm2
I0525 23:43:48.863034 15117 net.cpp:605] BatchNorm2 <- Convolution2
I0525 23:43:48.863042 15117 net.cpp:566] BatchNorm2 -> Convolution2 (in-place)
I0525 23:43:48.863260 15117 net.cpp:240] Setting up BatchNorm2
I0525 23:43:48.863271 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.863276 15117 net.cpp:255] Memory required for data: 68682240
I0525 23:43:48.863291 15117 layer_factory.hpp:77] Creating layer Scale2
I0525 23:43:48.863302 15117 net.cpp:190] Creating Layer Scale2
I0525 23:43:48.863307 15117 net.cpp:605] Scale2 <- Convolution2
I0525 23:43:48.863313 15117 net.cpp:566] Scale2 -> Convolution2 (in-place)
I0525 23:43:48.863353 15117 layer_factory.hpp:77] Creating layer Scale2
I0525 23:43:48.863487 15117 net.cpp:240] Setting up Scale2
I0525 23:43:48.863497 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.863500 15117 net.cpp:255] Memory required for data: 77070848
I0525 23:43:48.863508 15117 layer_factory.hpp:77] Creating layer ReLU2
I0525 23:43:48.863519 15117 net.cpp:190] Creating Layer ReLU2
I0525 23:43:48.863524 15117 net.cpp:605] ReLU2 <- Convolution2
I0525 23:43:48.863529 15117 net.cpp:566] ReLU2 -> Convolution2 (in-place)
I0525 23:43:48.863538 15117 net.cpp:240] Setting up ReLU2
I0525 23:43:48.863543 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.863546 15117 net.cpp:255] Memory required for data: 85459456
I0525 23:43:48.863550 15117 layer_factory.hpp:77] Creating layer Convolution3
I0525 23:43:48.863569 15117 net.cpp:190] Creating Layer Convolution3
I0525 23:43:48.863572 15117 net.cpp:605] Convolution3 <- Convolution2
I0525 23:43:48.863579 15117 net.cpp:579] Convolution3 -> Convolution3
I0525 23:43:48.863865 15117 net.cpp:240] Setting up Convolution3
I0525 23:43:48.863873 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.863878 15117 net.cpp:255] Memory required for data: 93848064
I0525 23:43:48.863893 15117 layer_factory.hpp:77] Creating layer BatchNorm3
I0525 23:43:48.863934 15117 net.cpp:190] Creating Layer BatchNorm3
I0525 23:43:48.863939 15117 net.cpp:605] BatchNorm3 <- Convolution3
I0525 23:43:48.863945 15117 net.cpp:566] BatchNorm3 -> Convolution3 (in-place)
I0525 23:43:48.864116 15117 net.cpp:240] Setting up BatchNorm3
I0525 23:43:48.864125 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.864128 15117 net.cpp:255] Memory required for data: 102236672
I0525 23:43:48.864148 15117 layer_factory.hpp:77] Creating layer Scale3
I0525 23:43:48.864156 15117 net.cpp:190] Creating Layer Scale3
I0525 23:43:48.864161 15117 net.cpp:605] Scale3 <- Convolution3
I0525 23:43:48.864166 15117 net.cpp:566] Scale3 -> Convolution3 (in-place)
I0525 23:43:48.864202 15117 layer_factory.hpp:77] Creating layer Scale3
I0525 23:43:48.864320 15117 net.cpp:240] Setting up Scale3
I0525 23:43:48.864328 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.864332 15117 net.cpp:255] Memory required for data: 110625280
I0525 23:43:48.864343 15117 layer_factory.hpp:77] Creating layer Eltwise1
I0525 23:43:48.864352 15117 net.cpp:190] Creating Layer Eltwise1
I0525 23:43:48.864356 15117 net.cpp:605] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0525 23:43:48.864362 15117 net.cpp:605] Eltwise1 <- Convolution3
I0525 23:43:48.864370 15117 net.cpp:579] Eltwise1 -> Eltwise1
I0525 23:43:48.864403 15117 net.cpp:240] Setting up Eltwise1
I0525 23:43:48.864409 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.864413 15117 net.cpp:255] Memory required for data: 119013888
I0525 23:43:48.864418 15117 layer_factory.hpp:77] Creating layer ReLU3
I0525 23:43:48.864426 15117 net.cpp:190] Creating Layer ReLU3
I0525 23:43:48.864430 15117 net.cpp:605] ReLU3 <- Eltwise1
I0525 23:43:48.864435 15117 net.cpp:566] ReLU3 -> Eltwise1 (in-place)
I0525 23:43:48.864442 15117 net.cpp:240] Setting up ReLU3
I0525 23:43:48.864446 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.864450 15117 net.cpp:255] Memory required for data: 127402496
I0525 23:43:48.864454 15117 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0525 23:43:48.864460 15117 net.cpp:190] Creating Layer Eltwise1_ReLU3_0_split
I0525 23:43:48.864464 15117 net.cpp:605] Eltwise1_ReLU3_0_split <- Eltwise1
I0525 23:43:48.864470 15117 net.cpp:579] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0525 23:43:48.864476 15117 net.cpp:579] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0525 23:43:48.864516 15117 net.cpp:240] Setting up Eltwise1_ReLU3_0_split
I0525 23:43:48.864524 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.864529 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.864532 15117 net.cpp:255] Memory required for data: 144179712
I0525 23:43:48.864537 15117 layer_factory.hpp:77] Creating layer Convolution4
I0525 23:43:48.864550 15117 net.cpp:190] Creating Layer Convolution4
I0525 23:43:48.864555 15117 net.cpp:605] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0525 23:43:48.864562 15117 net.cpp:579] Convolution4 -> Convolution4
I0525 23:43:48.864804 15122 blocking_queue.cpp:50] Waiting for data
I0525 23:43:48.864967 15117 net.cpp:240] Setting up Convolution4
I0525 23:43:48.864977 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.864981 15117 net.cpp:255] Memory required for data: 152568320
I0525 23:43:48.864990 15117 layer_factory.hpp:77] Creating layer BatchNorm4
I0525 23:43:48.865002 15117 net.cpp:190] Creating Layer BatchNorm4
I0525 23:43:48.865007 15117 net.cpp:605] BatchNorm4 <- Convolution4
I0525 23:43:48.865013 15117 net.cpp:566] BatchNorm4 -> Convolution4 (in-place)
I0525 23:43:48.865203 15117 net.cpp:240] Setting up BatchNorm4
I0525 23:43:48.865211 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.865216 15117 net.cpp:255] Memory required for data: 160956928
I0525 23:43:48.865226 15117 layer_factory.hpp:77] Creating layer Scale4
I0525 23:43:48.865236 15117 net.cpp:190] Creating Layer Scale4
I0525 23:43:48.865242 15117 net.cpp:605] Scale4 <- Convolution4
I0525 23:43:48.865252 15117 net.cpp:566] Scale4 -> Convolution4 (in-place)
I0525 23:43:48.865314 15117 layer_factory.hpp:77] Creating layer Scale4
I0525 23:43:48.865414 15117 net.cpp:240] Setting up Scale4
I0525 23:43:48.865424 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.865428 15117 net.cpp:255] Memory required for data: 169345536
I0525 23:43:48.865437 15117 layer_factory.hpp:77] Creating layer ReLU4
I0525 23:43:48.865444 15117 net.cpp:190] Creating Layer ReLU4
I0525 23:43:48.865448 15117 net.cpp:605] ReLU4 <- Convolution4
I0525 23:43:48.865453 15117 net.cpp:566] ReLU4 -> Convolution4 (in-place)
I0525 23:43:48.865460 15117 net.cpp:240] Setting up ReLU4
I0525 23:43:48.865465 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.865469 15117 net.cpp:255] Memory required for data: 177734144
I0525 23:43:48.865473 15117 layer_factory.hpp:77] Creating layer Convolution5
I0525 23:43:48.865485 15117 net.cpp:190] Creating Layer Convolution5
I0525 23:43:48.865489 15117 net.cpp:605] Convolution5 <- Convolution4
I0525 23:43:48.865497 15117 net.cpp:579] Convolution5 -> Convolution5
I0525 23:43:48.865779 15117 net.cpp:240] Setting up Convolution5
I0525 23:43:48.865787 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.865792 15117 net.cpp:255] Memory required for data: 186122752
I0525 23:43:48.865799 15117 layer_factory.hpp:77] Creating layer BatchNorm5
I0525 23:43:48.865810 15117 net.cpp:190] Creating Layer BatchNorm5
I0525 23:43:48.865814 15117 net.cpp:605] BatchNorm5 <- Convolution5
I0525 23:43:48.865821 15117 net.cpp:566] BatchNorm5 -> Convolution5 (in-place)
I0525 23:43:48.865993 15117 net.cpp:240] Setting up BatchNorm5
I0525 23:43:48.865999 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.866003 15117 net.cpp:255] Memory required for data: 194511360
I0525 23:43:48.866025 15117 layer_factory.hpp:77] Creating layer Scale5
I0525 23:43:48.866034 15117 net.cpp:190] Creating Layer Scale5
I0525 23:43:48.866037 15117 net.cpp:605] Scale5 <- Convolution5
I0525 23:43:48.866044 15117 net.cpp:566] Scale5 -> Convolution5 (in-place)
I0525 23:43:48.866078 15117 layer_factory.hpp:77] Creating layer Scale5
I0525 23:43:48.866183 15117 net.cpp:240] Setting up Scale5
I0525 23:43:48.866190 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.866194 15117 net.cpp:255] Memory required for data: 202899968
I0525 23:43:48.866204 15117 layer_factory.hpp:77] Creating layer Eltwise2
I0525 23:43:48.866214 15117 net.cpp:190] Creating Layer Eltwise2
I0525 23:43:48.866219 15117 net.cpp:605] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0525 23:43:48.866224 15117 net.cpp:605] Eltwise2 <- Convolution5
I0525 23:43:48.866230 15117 net.cpp:579] Eltwise2 -> Eltwise2
I0525 23:43:48.866253 15117 net.cpp:240] Setting up Eltwise2
I0525 23:43:48.866260 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.866263 15117 net.cpp:255] Memory required for data: 211288576
I0525 23:43:48.866266 15117 layer_factory.hpp:77] Creating layer ReLU5
I0525 23:43:48.866276 15117 net.cpp:190] Creating Layer ReLU5
I0525 23:43:48.866279 15117 net.cpp:605] ReLU5 <- Eltwise2
I0525 23:43:48.866286 15117 net.cpp:566] ReLU5 -> Eltwise2 (in-place)
I0525 23:43:48.866291 15117 net.cpp:240] Setting up ReLU5
I0525 23:43:48.866297 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.866300 15117 net.cpp:255] Memory required for data: 219677184
I0525 23:43:48.866304 15117 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0525 23:43:48.866310 15117 net.cpp:190] Creating Layer Eltwise2_ReLU5_0_split
I0525 23:43:48.866314 15117 net.cpp:605] Eltwise2_ReLU5_0_split <- Eltwise2
I0525 23:43:48.866319 15117 net.cpp:579] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0525 23:43:48.866327 15117 net.cpp:579] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0525 23:43:48.866370 15117 net.cpp:240] Setting up Eltwise2_ReLU5_0_split
I0525 23:43:48.866377 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.866382 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.866392 15117 net.cpp:255] Memory required for data: 236454400
I0525 23:43:48.866420 15117 layer_factory.hpp:77] Creating layer Convolution6
I0525 23:43:48.866432 15117 net.cpp:190] Creating Layer Convolution6
I0525 23:43:48.866437 15117 net.cpp:605] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0525 23:43:48.866444 15117 net.cpp:579] Convolution6 -> Convolution6
I0525 23:43:48.866739 15117 net.cpp:240] Setting up Convolution6
I0525 23:43:48.866749 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.866751 15117 net.cpp:255] Memory required for data: 244843008
I0525 23:43:48.866760 15117 layer_factory.hpp:77] Creating layer BatchNorm6
I0525 23:43:48.870380 15117 net.cpp:190] Creating Layer BatchNorm6
I0525 23:43:48.870419 15117 net.cpp:605] BatchNorm6 <- Convolution6
I0525 23:43:48.870435 15117 net.cpp:566] BatchNorm6 -> Convolution6 (in-place)
I0525 23:43:48.870708 15117 net.cpp:240] Setting up BatchNorm6
I0525 23:43:48.870719 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.870723 15117 net.cpp:255] Memory required for data: 253231616
I0525 23:43:48.870740 15117 layer_factory.hpp:77] Creating layer Scale6
I0525 23:43:48.870750 15117 net.cpp:190] Creating Layer Scale6
I0525 23:43:48.870754 15117 net.cpp:605] Scale6 <- Convolution6
I0525 23:43:48.870764 15117 net.cpp:566] Scale6 -> Convolution6 (in-place)
I0525 23:43:48.870800 15117 layer_factory.hpp:77] Creating layer Scale6
I0525 23:43:48.870908 15117 net.cpp:240] Setting up Scale6
I0525 23:43:48.870915 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.870919 15117 net.cpp:255] Memory required for data: 261620224
I0525 23:43:48.870929 15117 layer_factory.hpp:77] Creating layer ReLU6
I0525 23:43:48.870937 15117 net.cpp:190] Creating Layer ReLU6
I0525 23:43:48.870941 15117 net.cpp:605] ReLU6 <- Convolution6
I0525 23:43:48.870947 15117 net.cpp:566] ReLU6 -> Convolution6 (in-place)
I0525 23:43:48.870954 15117 net.cpp:240] Setting up ReLU6
I0525 23:43:48.870959 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.870964 15117 net.cpp:255] Memory required for data: 270008832
I0525 23:43:48.870967 15117 layer_factory.hpp:77] Creating layer Convolution7
I0525 23:43:48.870982 15117 net.cpp:190] Creating Layer Convolution7
I0525 23:43:48.870986 15117 net.cpp:605] Convolution7 <- Convolution6
I0525 23:43:48.870995 15117 net.cpp:579] Convolution7 -> Convolution7
I0525 23:43:48.871304 15117 net.cpp:240] Setting up Convolution7
I0525 23:43:48.871315 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.871318 15117 net.cpp:255] Memory required for data: 278397440
I0525 23:43:48.871327 15117 layer_factory.hpp:77] Creating layer BatchNorm7
I0525 23:43:48.871337 15117 net.cpp:190] Creating Layer BatchNorm7
I0525 23:43:48.871341 15117 net.cpp:605] BatchNorm7 <- Convolution7
I0525 23:43:48.871350 15117 net.cpp:566] BatchNorm7 -> Convolution7 (in-place)
I0525 23:43:48.871518 15117 net.cpp:240] Setting up BatchNorm7
I0525 23:43:48.871526 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.871529 15117 net.cpp:255] Memory required for data: 286786048
I0525 23:43:48.871539 15117 layer_factory.hpp:77] Creating layer Scale7
I0525 23:43:48.871554 15117 net.cpp:190] Creating Layer Scale7
I0525 23:43:48.871559 15117 net.cpp:605] Scale7 <- Convolution7
I0525 23:43:48.871564 15117 net.cpp:566] Scale7 -> Convolution7 (in-place)
I0525 23:43:48.871598 15117 layer_factory.hpp:77] Creating layer Scale7
I0525 23:43:48.871701 15117 net.cpp:240] Setting up Scale7
I0525 23:43:48.871707 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.871711 15117 net.cpp:255] Memory required for data: 295174656
I0525 23:43:48.871719 15117 layer_factory.hpp:77] Creating layer Eltwise3
I0525 23:43:48.871758 15117 net.cpp:190] Creating Layer Eltwise3
I0525 23:43:48.871767 15117 net.cpp:605] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0525 23:43:48.871772 15117 net.cpp:605] Eltwise3 <- Convolution7
I0525 23:43:48.871778 15117 net.cpp:579] Eltwise3 -> Eltwise3
I0525 23:43:48.871812 15117 net.cpp:240] Setting up Eltwise3
I0525 23:43:48.871825 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.871856 15117 net.cpp:255] Memory required for data: 303563264
I0525 23:43:48.871861 15117 layer_factory.hpp:77] Creating layer ReLU7
I0525 23:43:48.871868 15117 net.cpp:190] Creating Layer ReLU7
I0525 23:43:48.871872 15117 net.cpp:605] ReLU7 <- Eltwise3
I0525 23:43:48.871881 15117 net.cpp:566] ReLU7 -> Eltwise3 (in-place)
I0525 23:43:48.871887 15117 net.cpp:240] Setting up ReLU7
I0525 23:43:48.871892 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.871896 15117 net.cpp:255] Memory required for data: 311951872
I0525 23:43:48.871899 15117 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0525 23:43:48.871906 15117 net.cpp:190] Creating Layer Eltwise3_ReLU7_0_split
I0525 23:43:48.871909 15117 net.cpp:605] Eltwise3_ReLU7_0_split <- Eltwise3
I0525 23:43:48.871914 15117 net.cpp:579] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0525 23:43:48.871920 15117 net.cpp:579] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0525 23:43:48.871954 15117 net.cpp:240] Setting up Eltwise3_ReLU7_0_split
I0525 23:43:48.871960 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.871965 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.871968 15117 net.cpp:255] Memory required for data: 328729088
I0525 23:43:48.871973 15117 layer_factory.hpp:77] Creating layer Convolution8
I0525 23:43:48.871984 15117 net.cpp:190] Creating Layer Convolution8
I0525 23:43:48.871987 15117 net.cpp:605] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0525 23:43:48.871996 15117 net.cpp:579] Convolution8 -> Convolution8
I0525 23:43:48.872287 15117 net.cpp:240] Setting up Convolution8
I0525 23:43:48.872298 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.872303 15117 net.cpp:255] Memory required for data: 337117696
I0525 23:43:48.872311 15117 layer_factory.hpp:77] Creating layer BatchNorm8
I0525 23:43:48.872318 15117 net.cpp:190] Creating Layer BatchNorm8
I0525 23:43:48.872323 15117 net.cpp:605] BatchNorm8 <- Convolution8
I0525 23:43:48.872328 15117 net.cpp:566] BatchNorm8 -> Convolution8 (in-place)
I0525 23:43:48.872505 15117 net.cpp:240] Setting up BatchNorm8
I0525 23:43:48.872512 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.872516 15117 net.cpp:255] Memory required for data: 345506304
I0525 23:43:48.872526 15117 layer_factory.hpp:77] Creating layer Scale8
I0525 23:43:48.872534 15117 net.cpp:190] Creating Layer Scale8
I0525 23:43:48.872537 15117 net.cpp:605] Scale8 <- Convolution8
I0525 23:43:48.872544 15117 net.cpp:566] Scale8 -> Convolution8 (in-place)
I0525 23:43:48.872577 15117 layer_factory.hpp:77] Creating layer Scale8
I0525 23:43:48.872681 15117 net.cpp:240] Setting up Scale8
I0525 23:43:48.872689 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.872692 15117 net.cpp:255] Memory required for data: 353894912
I0525 23:43:48.872702 15117 layer_factory.hpp:77] Creating layer ReLU8
I0525 23:43:48.872710 15117 net.cpp:190] Creating Layer ReLU8
I0525 23:43:48.872714 15117 net.cpp:605] ReLU8 <- Convolution8
I0525 23:43:48.872721 15117 net.cpp:566] ReLU8 -> Convolution8 (in-place)
I0525 23:43:48.872730 15117 net.cpp:240] Setting up ReLU8
I0525 23:43:48.872735 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.872738 15117 net.cpp:255] Memory required for data: 362283520
I0525 23:43:48.872742 15117 layer_factory.hpp:77] Creating layer Convolution9
I0525 23:43:48.872751 15117 net.cpp:190] Creating Layer Convolution9
I0525 23:43:48.872756 15117 net.cpp:605] Convolution9 <- Convolution8
I0525 23:43:48.872763 15117 net.cpp:579] Convolution9 -> Convolution9
I0525 23:43:48.873045 15117 net.cpp:240] Setting up Convolution9
I0525 23:43:48.873054 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.873059 15117 net.cpp:255] Memory required for data: 370672128
I0525 23:43:48.873066 15117 layer_factory.hpp:77] Creating layer BatchNorm9
I0525 23:43:48.873075 15117 net.cpp:190] Creating Layer BatchNorm9
I0525 23:43:48.873083 15117 net.cpp:605] BatchNorm9 <- Convolution9
I0525 23:43:48.873127 15117 net.cpp:566] BatchNorm9 -> Convolution9 (in-place)
I0525 23:43:48.873311 15117 net.cpp:240] Setting up BatchNorm9
I0525 23:43:48.873320 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.873323 15117 net.cpp:255] Memory required for data: 379060736
I0525 23:43:48.873335 15117 layer_factory.hpp:77] Creating layer Scale9
I0525 23:43:48.873342 15117 net.cpp:190] Creating Layer Scale9
I0525 23:43:48.873347 15117 net.cpp:605] Scale9 <- Convolution9
I0525 23:43:48.873352 15117 net.cpp:566] Scale9 -> Convolution9 (in-place)
I0525 23:43:48.873401 15117 layer_factory.hpp:77] Creating layer Scale9
I0525 23:43:48.873508 15117 net.cpp:240] Setting up Scale9
I0525 23:43:48.873517 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.873519 15117 net.cpp:255] Memory required for data: 387449344
I0525 23:43:48.873528 15117 layer_factory.hpp:77] Creating layer Eltwise4
I0525 23:43:48.873536 15117 net.cpp:190] Creating Layer Eltwise4
I0525 23:43:48.873541 15117 net.cpp:605] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0525 23:43:48.873548 15117 net.cpp:605] Eltwise4 <- Convolution9
I0525 23:43:48.873554 15117 net.cpp:579] Eltwise4 -> Eltwise4
I0525 23:43:48.873576 15117 net.cpp:240] Setting up Eltwise4
I0525 23:43:48.873582 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.873586 15117 net.cpp:255] Memory required for data: 395837952
I0525 23:43:48.873590 15117 layer_factory.hpp:77] Creating layer ReLU9
I0525 23:43:48.873600 15117 net.cpp:190] Creating Layer ReLU9
I0525 23:43:48.873603 15117 net.cpp:605] ReLU9 <- Eltwise4
I0525 23:43:48.873608 15117 net.cpp:566] ReLU9 -> Eltwise4 (in-place)
I0525 23:43:48.873615 15117 net.cpp:240] Setting up ReLU9
I0525 23:43:48.873620 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.873623 15117 net.cpp:255] Memory required for data: 404226560
I0525 23:43:48.873627 15117 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0525 23:43:48.873636 15117 net.cpp:190] Creating Layer Eltwise4_ReLU9_0_split
I0525 23:43:48.873638 15117 net.cpp:605] Eltwise4_ReLU9_0_split <- Eltwise4
I0525 23:43:48.873643 15117 net.cpp:579] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0525 23:43:48.873649 15117 net.cpp:579] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0525 23:43:48.873683 15117 net.cpp:240] Setting up Eltwise4_ReLU9_0_split
I0525 23:43:48.873689 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.873694 15117 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:43:48.873697 15117 net.cpp:255] Memory required for data: 421003776
I0525 23:43:48.873702 15117 layer_factory.hpp:77] Creating layer Pooling1
I0525 23:43:48.873709 15117 net.cpp:190] Creating Layer Pooling1
I0525 23:43:48.873713 15117 net.cpp:605] Pooling1 <- Eltwise4_ReLU9_0_split_0
I0525 23:43:48.873720 15117 net.cpp:579] Pooling1 -> Pooling1
I0525 23:43:48.873765 15117 net.cpp:240] Setting up Pooling1
I0525 23:43:48.873772 15117 net.cpp:247] Top shape: 128 16 16 16 (524288)
I0525 23:43:48.873776 15117 net.cpp:255] Memory required for data: 423100928
I0525 23:43:48.873780 15117 layer_factory.hpp:77] Creating layer Input1
I0525 23:43:48.873790 15117 net.cpp:190] Creating Layer Input1
I0525 23:43:48.873795 15117 net.cpp:579] Input1 -> Input1
I0525 23:43:48.873827 15117 net.cpp:240] Setting up Input1
I0525 23:43:48.873833 15117 net.cpp:247] Top shape: 128 16 16 16 (524288)
I0525 23:43:48.873837 15117 net.cpp:255] Memory required for data: 425198080
I0525 23:43:48.873842 15117 layer_factory.hpp:77] Creating layer Concat1
I0525 23:43:48.873852 15117 net.cpp:190] Creating Layer Concat1
I0525 23:43:48.873855 15117 net.cpp:605] Concat1 <- Pooling1
I0525 23:43:48.873860 15117 net.cpp:605] Concat1 <- Input1
I0525 23:43:48.873867 15117 net.cpp:579] Concat1 -> Concat1
I0525 23:43:48.873894 15117 net.cpp:240] Setting up Concat1
I0525 23:43:48.873900 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.873904 15117 net.cpp:255] Memory required for data: 429392384
I0525 23:43:48.873913 15117 layer_factory.hpp:77] Creating layer Convolution10
I0525 23:43:48.873944 15117 net.cpp:190] Creating Layer Convolution10
I0525 23:43:48.873949 15117 net.cpp:605] Convolution10 <- Eltwise4_ReLU9_0_split_1
I0525 23:43:48.873955 15117 net.cpp:579] Convolution10 -> Convolution10
I0525 23:43:48.875489 15117 net.cpp:240] Setting up Convolution10
I0525 23:43:48.875531 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.875536 15117 net.cpp:255] Memory required for data: 433586688
I0525 23:43:48.875572 15117 layer_factory.hpp:77] Creating layer BatchNorm10
I0525 23:43:48.875588 15117 net.cpp:190] Creating Layer BatchNorm10
I0525 23:43:48.875594 15117 net.cpp:605] BatchNorm10 <- Convolution10
I0525 23:43:48.875602 15117 net.cpp:566] BatchNorm10 -> Convolution10 (in-place)
I0525 23:43:48.875783 15117 net.cpp:240] Setting up BatchNorm10
I0525 23:43:48.875790 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.875794 15117 net.cpp:255] Memory required for data: 437780992
I0525 23:43:48.875805 15117 layer_factory.hpp:77] Creating layer Scale10
I0525 23:43:48.875814 15117 net.cpp:190] Creating Layer Scale10
I0525 23:43:48.875818 15117 net.cpp:605] Scale10 <- Convolution10
I0525 23:43:48.875826 15117 net.cpp:566] Scale10 -> Convolution10 (in-place)
I0525 23:43:48.875859 15117 layer_factory.hpp:77] Creating layer Scale10
I0525 23:43:48.875962 15117 net.cpp:240] Setting up Scale10
I0525 23:43:48.875972 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.875975 15117 net.cpp:255] Memory required for data: 441975296
I0525 23:43:48.875984 15117 layer_factory.hpp:77] Creating layer ReLU10
I0525 23:43:48.875993 15117 net.cpp:190] Creating Layer ReLU10
I0525 23:43:48.875998 15117 net.cpp:605] ReLU10 <- Convolution10
I0525 23:43:48.876003 15117 net.cpp:566] ReLU10 -> Convolution10 (in-place)
I0525 23:43:48.876010 15117 net.cpp:240] Setting up ReLU10
I0525 23:43:48.876015 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.876019 15117 net.cpp:255] Memory required for data: 446169600
I0525 23:43:48.876024 15117 layer_factory.hpp:77] Creating layer Convolution11
I0525 23:43:48.876037 15117 net.cpp:190] Creating Layer Convolution11
I0525 23:43:48.876041 15117 net.cpp:605] Convolution11 <- Convolution10
I0525 23:43:48.876049 15117 net.cpp:579] Convolution11 -> Convolution11
I0525 23:43:48.876597 15117 net.cpp:240] Setting up Convolution11
I0525 23:43:48.876611 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.876616 15117 net.cpp:255] Memory required for data: 450363904
I0525 23:43:48.876626 15117 layer_factory.hpp:77] Creating layer BatchNorm11
I0525 23:43:48.876637 15117 net.cpp:190] Creating Layer BatchNorm11
I0525 23:43:48.876642 15117 net.cpp:605] BatchNorm11 <- Convolution11
I0525 23:43:48.876653 15117 net.cpp:566] BatchNorm11 -> Convolution11 (in-place)
I0525 23:43:48.876823 15117 net.cpp:240] Setting up BatchNorm11
I0525 23:43:48.876832 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.876835 15117 net.cpp:255] Memory required for data: 454558208
I0525 23:43:48.876845 15117 layer_factory.hpp:77] Creating layer Scale11
I0525 23:43:48.876857 15117 net.cpp:190] Creating Layer Scale11
I0525 23:43:48.876862 15117 net.cpp:605] Scale11 <- Convolution11
I0525 23:43:48.876866 15117 net.cpp:566] Scale11 -> Convolution11 (in-place)
I0525 23:43:48.876899 15117 layer_factory.hpp:77] Creating layer Scale11
I0525 23:43:48.877007 15117 net.cpp:240] Setting up Scale11
I0525 23:43:48.877014 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.877018 15117 net.cpp:255] Memory required for data: 458752512
I0525 23:43:48.877027 15117 layer_factory.hpp:77] Creating layer Eltwise5
I0525 23:43:48.877038 15117 net.cpp:190] Creating Layer Eltwise5
I0525 23:43:48.877041 15117 net.cpp:605] Eltwise5 <- Concat1
I0525 23:43:48.877048 15117 net.cpp:605] Eltwise5 <- Convolution11
I0525 23:43:48.877056 15117 net.cpp:579] Eltwise5 -> Eltwise5
I0525 23:43:48.877076 15117 net.cpp:240] Setting up Eltwise5
I0525 23:43:48.877082 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.877094 15117 net.cpp:255] Memory required for data: 462946816
I0525 23:43:48.877128 15117 layer_factory.hpp:77] Creating layer ReLU11
I0525 23:43:48.877141 15117 net.cpp:190] Creating Layer ReLU11
I0525 23:43:48.877146 15117 net.cpp:605] ReLU11 <- Eltwise5
I0525 23:43:48.877151 15117 net.cpp:566] ReLU11 -> Eltwise5 (in-place)
I0525 23:43:48.877158 15117 net.cpp:240] Setting up ReLU11
I0525 23:43:48.877163 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.877167 15117 net.cpp:255] Memory required for data: 467141120
I0525 23:43:48.877171 15117 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0525 23:43:48.877177 15117 net.cpp:190] Creating Layer Eltwise5_ReLU11_0_split
I0525 23:43:48.877182 15117 net.cpp:605] Eltwise5_ReLU11_0_split <- Eltwise5
I0525 23:43:48.877187 15117 net.cpp:579] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0525 23:43:48.877195 15117 net.cpp:579] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0525 23:43:48.877235 15117 net.cpp:240] Setting up Eltwise5_ReLU11_0_split
I0525 23:43:48.877243 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.877249 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.877251 15117 net.cpp:255] Memory required for data: 475529728
I0525 23:43:48.877255 15117 layer_factory.hpp:77] Creating layer Convolution12
I0525 23:43:48.877269 15117 net.cpp:190] Creating Layer Convolution12
I0525 23:43:48.877274 15117 net.cpp:605] Convolution12 <- Eltwise5_ReLU11_0_split_0
I0525 23:43:48.877279 15117 net.cpp:579] Convolution12 -> Convolution12
I0525 23:43:48.877827 15117 net.cpp:240] Setting up Convolution12
I0525 23:43:48.877840 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.877845 15117 net.cpp:255] Memory required for data: 479724032
I0525 23:43:48.877854 15117 layer_factory.hpp:77] Creating layer BatchNorm12
I0525 23:43:48.877866 15117 net.cpp:190] Creating Layer BatchNorm12
I0525 23:43:48.877871 15117 net.cpp:605] BatchNorm12 <- Convolution12
I0525 23:43:48.877876 15117 net.cpp:566] BatchNorm12 -> Convolution12 (in-place)
I0525 23:43:48.878052 15117 net.cpp:240] Setting up BatchNorm12
I0525 23:43:48.878062 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.878065 15117 net.cpp:255] Memory required for data: 483918336
I0525 23:43:48.878077 15117 layer_factory.hpp:77] Creating layer Scale12
I0525 23:43:48.878087 15117 net.cpp:190] Creating Layer Scale12
I0525 23:43:48.878090 15117 net.cpp:605] Scale12 <- Convolution12
I0525 23:43:48.878095 15117 net.cpp:566] Scale12 -> Convolution12 (in-place)
I0525 23:43:48.878130 15117 layer_factory.hpp:77] Creating layer Scale12
I0525 23:43:48.882396 15117 net.cpp:240] Setting up Scale12
I0525 23:43:48.882441 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.882446 15117 net.cpp:255] Memory required for data: 488112640
I0525 23:43:48.882464 15117 layer_factory.hpp:77] Creating layer ReLU12
I0525 23:43:48.882480 15117 net.cpp:190] Creating Layer ReLU12
I0525 23:43:48.882488 15117 net.cpp:605] ReLU12 <- Convolution12
I0525 23:43:48.882496 15117 net.cpp:566] ReLU12 -> Convolution12 (in-place)
I0525 23:43:48.882509 15117 net.cpp:240] Setting up ReLU12
I0525 23:43:48.882514 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.882519 15117 net.cpp:255] Memory required for data: 492306944
I0525 23:43:48.882522 15117 layer_factory.hpp:77] Creating layer Convolution13
I0525 23:43:48.882539 15117 net.cpp:190] Creating Layer Convolution13
I0525 23:43:48.882542 15117 net.cpp:605] Convolution13 <- Convolution12
I0525 23:43:48.882551 15117 net.cpp:579] Convolution13 -> Convolution13
I0525 23:43:48.883168 15117 net.cpp:240] Setting up Convolution13
I0525 23:43:48.883183 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.883188 15117 net.cpp:255] Memory required for data: 496501248
I0525 23:43:48.883198 15117 layer_factory.hpp:77] Creating layer BatchNorm13
I0525 23:43:48.883220 15117 net.cpp:190] Creating Layer BatchNorm13
I0525 23:43:48.883226 15117 net.cpp:605] BatchNorm13 <- Convolution13
I0525 23:43:48.883275 15117 net.cpp:566] BatchNorm13 -> Convolution13 (in-place)
I0525 23:43:48.883460 15117 net.cpp:240] Setting up BatchNorm13
I0525 23:43:48.883469 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.883473 15117 net.cpp:255] Memory required for data: 500695552
I0525 23:43:48.883486 15117 layer_factory.hpp:77] Creating layer Scale13
I0525 23:43:48.883494 15117 net.cpp:190] Creating Layer Scale13
I0525 23:43:48.883498 15117 net.cpp:605] Scale13 <- Convolution13
I0525 23:43:48.883507 15117 net.cpp:566] Scale13 -> Convolution13 (in-place)
I0525 23:43:48.883538 15117 layer_factory.hpp:77] Creating layer Scale13
I0525 23:43:48.883646 15117 net.cpp:240] Setting up Scale13
I0525 23:43:48.883656 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.883659 15117 net.cpp:255] Memory required for data: 504889856
I0525 23:43:48.883667 15117 layer_factory.hpp:77] Creating layer Eltwise6
I0525 23:43:48.883677 15117 net.cpp:190] Creating Layer Eltwise6
I0525 23:43:48.883682 15117 net.cpp:605] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0525 23:43:48.883687 15117 net.cpp:605] Eltwise6 <- Convolution13
I0525 23:43:48.883692 15117 net.cpp:579] Eltwise6 -> Eltwise6
I0525 23:43:48.883715 15117 net.cpp:240] Setting up Eltwise6
I0525 23:43:48.883721 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.883725 15117 net.cpp:255] Memory required for data: 509084160
I0525 23:43:48.883729 15117 layer_factory.hpp:77] Creating layer ReLU13
I0525 23:43:48.883735 15117 net.cpp:190] Creating Layer ReLU13
I0525 23:43:48.883739 15117 net.cpp:605] ReLU13 <- Eltwise6
I0525 23:43:48.883746 15117 net.cpp:566] ReLU13 -> Eltwise6 (in-place)
I0525 23:43:48.883752 15117 net.cpp:240] Setting up ReLU13
I0525 23:43:48.883757 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.883761 15117 net.cpp:255] Memory required for data: 513278464
I0525 23:43:48.883765 15117 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0525 23:43:48.883771 15117 net.cpp:190] Creating Layer Eltwise6_ReLU13_0_split
I0525 23:43:48.883775 15117 net.cpp:605] Eltwise6_ReLU13_0_split <- Eltwise6
I0525 23:43:48.883780 15117 net.cpp:579] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0525 23:43:48.883786 15117 net.cpp:579] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0525 23:43:48.883819 15117 net.cpp:240] Setting up Eltwise6_ReLU13_0_split
I0525 23:43:48.883826 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.883831 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.883834 15117 net.cpp:255] Memory required for data: 521667072
I0525 23:43:48.883837 15117 layer_factory.hpp:77] Creating layer Convolution14
I0525 23:43:48.883851 15117 net.cpp:190] Creating Layer Convolution14
I0525 23:43:48.883854 15117 net.cpp:605] Convolution14 <- Eltwise6_ReLU13_0_split_0
I0525 23:43:48.883862 15117 net.cpp:579] Convolution14 -> Convolution14
I0525 23:43:48.884404 15117 net.cpp:240] Setting up Convolution14
I0525 23:43:48.884418 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.884423 15117 net.cpp:255] Memory required for data: 525861376
I0525 23:43:48.884433 15117 layer_factory.hpp:77] Creating layer BatchNorm14
I0525 23:43:48.884443 15117 net.cpp:190] Creating Layer BatchNorm14
I0525 23:43:48.884452 15117 net.cpp:605] BatchNorm14 <- Convolution14
I0525 23:43:48.884459 15117 net.cpp:566] BatchNorm14 -> Convolution14 (in-place)
I0525 23:43:48.884655 15117 net.cpp:240] Setting up BatchNorm14
I0525 23:43:48.884665 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.884668 15117 net.cpp:255] Memory required for data: 530055680
I0525 23:43:48.884680 15117 layer_factory.hpp:77] Creating layer Scale14
I0525 23:43:48.884690 15117 net.cpp:190] Creating Layer Scale14
I0525 23:43:48.884694 15117 net.cpp:605] Scale14 <- Convolution14
I0525 23:43:48.884701 15117 net.cpp:566] Scale14 -> Convolution14 (in-place)
I0525 23:43:48.884739 15117 layer_factory.hpp:77] Creating layer Scale14
I0525 23:43:48.884863 15117 net.cpp:240] Setting up Scale14
I0525 23:43:48.884881 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.884920 15117 net.cpp:255] Memory required for data: 534249984
I0525 23:43:48.884932 15117 layer_factory.hpp:77] Creating layer ReLU14
I0525 23:43:48.884939 15117 net.cpp:190] Creating Layer ReLU14
I0525 23:43:48.884943 15117 net.cpp:605] ReLU14 <- Convolution14
I0525 23:43:48.884951 15117 net.cpp:566] ReLU14 -> Convolution14 (in-place)
I0525 23:43:48.884958 15117 net.cpp:240] Setting up ReLU14
I0525 23:43:48.884964 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.884968 15117 net.cpp:255] Memory required for data: 538444288
I0525 23:43:48.884971 15117 layer_factory.hpp:77] Creating layer Convolution15
I0525 23:43:48.884984 15117 net.cpp:190] Creating Layer Convolution15
I0525 23:43:48.884987 15117 net.cpp:605] Convolution15 <- Convolution14
I0525 23:43:48.884994 15117 net.cpp:579] Convolution15 -> Convolution15
I0525 23:43:48.885540 15117 net.cpp:240] Setting up Convolution15
I0525 23:43:48.885555 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.885558 15117 net.cpp:255] Memory required for data: 542638592
I0525 23:43:48.885567 15117 layer_factory.hpp:77] Creating layer BatchNorm15
I0525 23:43:48.885577 15117 net.cpp:190] Creating Layer BatchNorm15
I0525 23:43:48.885582 15117 net.cpp:605] BatchNorm15 <- Convolution15
I0525 23:43:48.885588 15117 net.cpp:566] BatchNorm15 -> Convolution15 (in-place)
I0525 23:43:48.885762 15117 net.cpp:240] Setting up BatchNorm15
I0525 23:43:48.885771 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.885774 15117 net.cpp:255] Memory required for data: 546832896
I0525 23:43:48.885787 15117 layer_factory.hpp:77] Creating layer Scale15
I0525 23:43:48.885795 15117 net.cpp:190] Creating Layer Scale15
I0525 23:43:48.885799 15117 net.cpp:605] Scale15 <- Convolution15
I0525 23:43:48.885805 15117 net.cpp:566] Scale15 -> Convolution15 (in-place)
I0525 23:43:48.885841 15117 layer_factory.hpp:77] Creating layer Scale15
I0525 23:43:48.885951 15117 net.cpp:240] Setting up Scale15
I0525 23:43:48.885958 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.885962 15117 net.cpp:255] Memory required for data: 551027200
I0525 23:43:48.885970 15117 layer_factory.hpp:77] Creating layer Eltwise7
I0525 23:43:48.885982 15117 net.cpp:190] Creating Layer Eltwise7
I0525 23:43:48.885988 15117 net.cpp:605] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0525 23:43:48.885993 15117 net.cpp:605] Eltwise7 <- Convolution15
I0525 23:43:48.885998 15117 net.cpp:579] Eltwise7 -> Eltwise7
I0525 23:43:48.886021 15117 net.cpp:240] Setting up Eltwise7
I0525 23:43:48.886028 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.886031 15117 net.cpp:255] Memory required for data: 555221504
I0525 23:43:48.886035 15117 layer_factory.hpp:77] Creating layer ReLU15
I0525 23:43:48.886041 15117 net.cpp:190] Creating Layer ReLU15
I0525 23:43:48.886045 15117 net.cpp:605] ReLU15 <- Eltwise7
I0525 23:43:48.886050 15117 net.cpp:566] ReLU15 -> Eltwise7 (in-place)
I0525 23:43:48.886057 15117 net.cpp:240] Setting up ReLU15
I0525 23:43:48.886062 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.886066 15117 net.cpp:255] Memory required for data: 559415808
I0525 23:43:48.886070 15117 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0525 23:43:48.886075 15117 net.cpp:190] Creating Layer Eltwise7_ReLU15_0_split
I0525 23:43:48.886080 15117 net.cpp:605] Eltwise7_ReLU15_0_split <- Eltwise7
I0525 23:43:48.886086 15117 net.cpp:579] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0525 23:43:48.886093 15117 net.cpp:579] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0525 23:43:48.886129 15117 net.cpp:240] Setting up Eltwise7_ReLU15_0_split
I0525 23:43:48.886137 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.886142 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.886144 15117 net.cpp:255] Memory required for data: 567804416
I0525 23:43:48.886148 15117 layer_factory.hpp:77] Creating layer Convolution16
I0525 23:43:48.886164 15117 net.cpp:190] Creating Layer Convolution16
I0525 23:43:48.886193 15117 net.cpp:605] Convolution16 <- Eltwise7_ReLU15_0_split_0
I0525 23:43:48.886200 15117 net.cpp:579] Convolution16 -> Convolution16
I0525 23:43:48.886760 15117 net.cpp:240] Setting up Convolution16
I0525 23:43:48.886775 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.886780 15117 net.cpp:255] Memory required for data: 571998720
I0525 23:43:48.886790 15117 layer_factory.hpp:77] Creating layer BatchNorm16
I0525 23:43:48.886801 15117 net.cpp:190] Creating Layer BatchNorm16
I0525 23:43:48.886806 15117 net.cpp:605] BatchNorm16 <- Convolution16
I0525 23:43:48.886811 15117 net.cpp:566] BatchNorm16 -> Convolution16 (in-place)
I0525 23:43:48.886989 15117 net.cpp:240] Setting up BatchNorm16
I0525 23:43:48.886996 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.887001 15117 net.cpp:255] Memory required for data: 576193024
I0525 23:43:48.887012 15117 layer_factory.hpp:77] Creating layer Scale16
I0525 23:43:48.887019 15117 net.cpp:190] Creating Layer Scale16
I0525 23:43:48.887023 15117 net.cpp:605] Scale16 <- Convolution16
I0525 23:43:48.887029 15117 net.cpp:566] Scale16 -> Convolution16 (in-place)
I0525 23:43:48.887063 15117 layer_factory.hpp:77] Creating layer Scale16
I0525 23:43:48.887171 15117 net.cpp:240] Setting up Scale16
I0525 23:43:48.887179 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.887182 15117 net.cpp:255] Memory required for data: 580387328
I0525 23:43:48.887193 15117 layer_factory.hpp:77] Creating layer ReLU16
I0525 23:43:48.887202 15117 net.cpp:190] Creating Layer ReLU16
I0525 23:43:48.887207 15117 net.cpp:605] ReLU16 <- Convolution16
I0525 23:43:48.887213 15117 net.cpp:566] ReLU16 -> Convolution16 (in-place)
I0525 23:43:48.887220 15117 net.cpp:240] Setting up ReLU16
I0525 23:43:48.887225 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.887229 15117 net.cpp:255] Memory required for data: 584581632
I0525 23:43:48.887233 15117 layer_factory.hpp:77] Creating layer Convolution17
I0525 23:43:48.887243 15117 net.cpp:190] Creating Layer Convolution17
I0525 23:43:48.887248 15117 net.cpp:605] Convolution17 <- Convolution16
I0525 23:43:48.887256 15117 net.cpp:579] Convolution17 -> Convolution17
I0525 23:43:48.887794 15117 net.cpp:240] Setting up Convolution17
I0525 23:43:48.887806 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.887810 15117 net.cpp:255] Memory required for data: 588775936
I0525 23:43:48.887820 15117 layer_factory.hpp:77] Creating layer BatchNorm17
I0525 23:43:48.887828 15117 net.cpp:190] Creating Layer BatchNorm17
I0525 23:43:48.887833 15117 net.cpp:605] BatchNorm17 <- Convolution17
I0525 23:43:48.887841 15117 net.cpp:566] BatchNorm17 -> Convolution17 (in-place)
I0525 23:43:48.888023 15117 net.cpp:240] Setting up BatchNorm17
I0525 23:43:48.888032 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.888036 15117 net.cpp:255] Memory required for data: 592970240
I0525 23:43:48.888047 15117 layer_factory.hpp:77] Creating layer Scale17
I0525 23:43:48.888056 15117 net.cpp:190] Creating Layer Scale17
I0525 23:43:48.888061 15117 net.cpp:605] Scale17 <- Convolution17
I0525 23:43:48.888065 15117 net.cpp:566] Scale17 -> Convolution17 (in-place)
I0525 23:43:48.888100 15117 layer_factory.hpp:77] Creating layer Scale17
I0525 23:43:48.888206 15117 net.cpp:240] Setting up Scale17
I0525 23:43:48.888213 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.888217 15117 net.cpp:255] Memory required for data: 597164544
I0525 23:43:48.888226 15117 layer_factory.hpp:77] Creating layer Eltwise8
I0525 23:43:48.888237 15117 net.cpp:190] Creating Layer Eltwise8
I0525 23:43:48.888243 15117 net.cpp:605] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0525 23:43:48.888248 15117 net.cpp:605] Eltwise8 <- Convolution17
I0525 23:43:48.888254 15117 net.cpp:579] Eltwise8 -> Eltwise8
I0525 23:43:48.888275 15117 net.cpp:240] Setting up Eltwise8
I0525 23:43:48.888281 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.888293 15117 net.cpp:255] Memory required for data: 601358848
I0525 23:43:48.888329 15117 layer_factory.hpp:77] Creating layer ReLU17
I0525 23:43:48.888348 15117 net.cpp:190] Creating Layer ReLU17
I0525 23:43:48.888353 15117 net.cpp:605] ReLU17 <- Eltwise8
I0525 23:43:48.888360 15117 net.cpp:566] ReLU17 -> Eltwise8 (in-place)
I0525 23:43:48.888365 15117 net.cpp:240] Setting up ReLU17
I0525 23:43:48.888371 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.888375 15117 net.cpp:255] Memory required for data: 605553152
I0525 23:43:48.888378 15117 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0525 23:43:48.888387 15117 net.cpp:190] Creating Layer Eltwise8_ReLU17_0_split
I0525 23:43:48.888391 15117 net.cpp:605] Eltwise8_ReLU17_0_split <- Eltwise8
I0525 23:43:48.888396 15117 net.cpp:579] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0525 23:43:48.888403 15117 net.cpp:579] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0525 23:43:48.888442 15117 net.cpp:240] Setting up Eltwise8_ReLU17_0_split
I0525 23:43:48.888448 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.888453 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.888458 15117 net.cpp:255] Memory required for data: 613941760
I0525 23:43:48.888461 15117 layer_factory.hpp:77] Creating layer Convolution18
I0525 23:43:48.888475 15117 net.cpp:190] Creating Layer Convolution18
I0525 23:43:48.888479 15117 net.cpp:605] Convolution18 <- Eltwise8_ReLU17_0_split_0
I0525 23:43:48.888486 15117 net.cpp:579] Convolution18 -> Convolution18
I0525 23:43:48.889039 15117 net.cpp:240] Setting up Convolution18
I0525 23:43:48.889053 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.889057 15117 net.cpp:255] Memory required for data: 618136064
I0525 23:43:48.889067 15117 layer_factory.hpp:77] Creating layer BatchNorm18
I0525 23:43:48.889088 15117 net.cpp:190] Creating Layer BatchNorm18
I0525 23:43:48.889094 15117 net.cpp:605] BatchNorm18 <- Convolution18
I0525 23:43:48.889101 15117 net.cpp:566] BatchNorm18 -> Convolution18 (in-place)
I0525 23:43:48.889278 15117 net.cpp:240] Setting up BatchNorm18
I0525 23:43:48.889286 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.889289 15117 net.cpp:255] Memory required for data: 622330368
I0525 23:43:48.889300 15117 layer_factory.hpp:77] Creating layer Scale18
I0525 23:43:48.889308 15117 net.cpp:190] Creating Layer Scale18
I0525 23:43:48.889312 15117 net.cpp:605] Scale18 <- Convolution18
I0525 23:43:48.889320 15117 net.cpp:566] Scale18 -> Convolution18 (in-place)
I0525 23:43:48.889354 15117 layer_factory.hpp:77] Creating layer Scale18
I0525 23:43:48.889467 15117 net.cpp:240] Setting up Scale18
I0525 23:43:48.889475 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.889479 15117 net.cpp:255] Memory required for data: 626524672
I0525 23:43:48.889488 15117 layer_factory.hpp:77] Creating layer ReLU18
I0525 23:43:48.889495 15117 net.cpp:190] Creating Layer ReLU18
I0525 23:43:48.889499 15117 net.cpp:605] ReLU18 <- Convolution18
I0525 23:43:48.889505 15117 net.cpp:566] ReLU18 -> Convolution18 (in-place)
I0525 23:43:48.889511 15117 net.cpp:240] Setting up ReLU18
I0525 23:43:48.889518 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.889520 15117 net.cpp:255] Memory required for data: 630718976
I0525 23:43:48.889524 15117 layer_factory.hpp:77] Creating layer Convolution19
I0525 23:43:48.889536 15117 net.cpp:190] Creating Layer Convolution19
I0525 23:43:48.889541 15117 net.cpp:605] Convolution19 <- Convolution18
I0525 23:43:48.889549 15117 net.cpp:579] Convolution19 -> Convolution19
I0525 23:43:48.890089 15117 net.cpp:240] Setting up Convolution19
I0525 23:43:48.890100 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.890105 15117 net.cpp:255] Memory required for data: 634913280
I0525 23:43:48.890115 15117 layer_factory.hpp:77] Creating layer BatchNorm19
I0525 23:43:48.890125 15117 net.cpp:190] Creating Layer BatchNorm19
I0525 23:43:48.890130 15117 net.cpp:605] BatchNorm19 <- Convolution19
I0525 23:43:48.890144 15117 net.cpp:566] BatchNorm19 -> Convolution19 (in-place)
I0525 23:43:48.890363 15117 net.cpp:240] Setting up BatchNorm19
I0525 23:43:48.890373 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.890377 15117 net.cpp:255] Memory required for data: 639107584
I0525 23:43:48.890418 15117 layer_factory.hpp:77] Creating layer Scale19
I0525 23:43:48.890429 15117 net.cpp:190] Creating Layer Scale19
I0525 23:43:48.890434 15117 net.cpp:605] Scale19 <- Convolution19
I0525 23:43:48.890439 15117 net.cpp:566] Scale19 -> Convolution19 (in-place)
I0525 23:43:48.890478 15117 layer_factory.hpp:77] Creating layer Scale19
I0525 23:43:48.890589 15117 net.cpp:240] Setting up Scale19
I0525 23:43:48.890597 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.890600 15117 net.cpp:255] Memory required for data: 643301888
I0525 23:43:48.890609 15117 layer_factory.hpp:77] Creating layer Eltwise9
I0525 23:43:48.890619 15117 net.cpp:190] Creating Layer Eltwise9
I0525 23:43:48.890624 15117 net.cpp:605] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0525 23:43:48.890628 15117 net.cpp:605] Eltwise9 <- Convolution19
I0525 23:43:48.890635 15117 net.cpp:579] Eltwise9 -> Eltwise9
I0525 23:43:48.890653 15117 net.cpp:240] Setting up Eltwise9
I0525 23:43:48.890661 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.890663 15117 net.cpp:255] Memory required for data: 647496192
I0525 23:43:48.890667 15117 layer_factory.hpp:77] Creating layer ReLU19
I0525 23:43:48.890677 15117 net.cpp:190] Creating Layer ReLU19
I0525 23:43:48.890681 15117 net.cpp:605] ReLU19 <- Eltwise9
I0525 23:43:48.890686 15117 net.cpp:566] ReLU19 -> Eltwise9 (in-place)
I0525 23:43:48.890694 15117 net.cpp:240] Setting up ReLU19
I0525 23:43:48.890699 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.890703 15117 net.cpp:255] Memory required for data: 651690496
I0525 23:43:48.890707 15117 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0525 23:43:48.890713 15117 net.cpp:190] Creating Layer Eltwise9_ReLU19_0_split
I0525 23:43:48.890717 15117 net.cpp:605] Eltwise9_ReLU19_0_split <- Eltwise9
I0525 23:43:48.890722 15117 net.cpp:579] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0525 23:43:48.890728 15117 net.cpp:579] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0525 23:43:48.890763 15117 net.cpp:240] Setting up Eltwise9_ReLU19_0_split
I0525 23:43:48.890769 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.890774 15117 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:43:48.890777 15117 net.cpp:255] Memory required for data: 660079104
I0525 23:43:48.890781 15117 layer_factory.hpp:77] Creating layer Pooling2
I0525 23:43:48.890789 15117 net.cpp:190] Creating Layer Pooling2
I0525 23:43:48.890794 15117 net.cpp:605] Pooling2 <- Eltwise9_ReLU19_0_split_0
I0525 23:43:48.890805 15117 net.cpp:579] Pooling2 -> Pooling2
I0525 23:43:48.890828 15117 net.cpp:240] Setting up Pooling2
I0525 23:43:48.890835 15117 net.cpp:247] Top shape: 128 32 8 8 (262144)
I0525 23:43:48.890838 15117 net.cpp:255] Memory required for data: 661127680
I0525 23:43:48.890842 15117 layer_factory.hpp:77] Creating layer Input2
I0525 23:43:48.890852 15117 net.cpp:190] Creating Layer Input2
I0525 23:43:48.890857 15117 net.cpp:579] Input2 -> Input2
I0525 23:43:48.890882 15117 net.cpp:240] Setting up Input2
I0525 23:43:48.890888 15117 net.cpp:247] Top shape: 128 32 8 8 (262144)
I0525 23:43:48.890892 15117 net.cpp:255] Memory required for data: 662176256
I0525 23:43:48.890897 15117 layer_factory.hpp:77] Creating layer Concat2
I0525 23:43:48.890908 15117 net.cpp:190] Creating Layer Concat2
I0525 23:43:48.890911 15117 net.cpp:605] Concat2 <- Pooling2
I0525 23:43:48.890916 15117 net.cpp:605] Concat2 <- Input2
I0525 23:43:48.890923 15117 net.cpp:579] Concat2 -> Concat2
I0525 23:43:48.890949 15117 net.cpp:240] Setting up Concat2
I0525 23:43:48.890955 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.890959 15117 net.cpp:255] Memory required for data: 664273408
I0525 23:43:48.890964 15117 layer_factory.hpp:77] Creating layer Convolution20
I0525 23:43:48.891001 15117 net.cpp:190] Creating Layer Convolution20
I0525 23:43:48.891006 15117 net.cpp:605] Convolution20 <- Eltwise9_ReLU19_0_split_1
I0525 23:43:48.891013 15117 net.cpp:579] Convolution20 -> Convolution20
I0525 23:43:48.892761 15117 net.cpp:240] Setting up Convolution20
I0525 23:43:48.892807 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.892810 15117 net.cpp:255] Memory required for data: 666370560
I0525 23:43:48.892827 15117 layer_factory.hpp:77] Creating layer BatchNorm20
I0525 23:43:48.892843 15117 net.cpp:190] Creating Layer BatchNorm20
I0525 23:43:48.892850 15117 net.cpp:605] BatchNorm20 <- Convolution20
I0525 23:43:48.892859 15117 net.cpp:566] BatchNorm20 -> Convolution20 (in-place)
I0525 23:43:48.893054 15117 net.cpp:240] Setting up BatchNorm20
I0525 23:43:48.893061 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.893065 15117 net.cpp:255] Memory required for data: 668467712
I0525 23:43:48.893076 15117 layer_factory.hpp:77] Creating layer Scale20
I0525 23:43:48.893090 15117 net.cpp:190] Creating Layer Scale20
I0525 23:43:48.893095 15117 net.cpp:605] Scale20 <- Convolution20
I0525 23:43:48.893100 15117 net.cpp:566] Scale20 -> Convolution20 (in-place)
I0525 23:43:48.893138 15117 layer_factory.hpp:77] Creating layer Scale20
I0525 23:43:48.893255 15117 net.cpp:240] Setting up Scale20
I0525 23:43:48.893262 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.893266 15117 net.cpp:255] Memory required for data: 670564864
I0525 23:43:48.893275 15117 layer_factory.hpp:77] Creating layer ReLU20
I0525 23:43:48.893293 15117 net.cpp:190] Creating Layer ReLU20
I0525 23:43:48.893298 15117 net.cpp:605] ReLU20 <- Convolution20
I0525 23:43:48.893304 15117 net.cpp:566] ReLU20 -> Convolution20 (in-place)
I0525 23:43:48.893311 15117 net.cpp:240] Setting up ReLU20
I0525 23:43:48.893316 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.893321 15117 net.cpp:255] Memory required for data: 672662016
I0525 23:43:48.893324 15117 layer_factory.hpp:77] Creating layer Convolution21
I0525 23:43:48.893338 15117 net.cpp:190] Creating Layer Convolution21
I0525 23:43:48.893342 15117 net.cpp:605] Convolution21 <- Convolution20
I0525 23:43:48.893349 15117 net.cpp:579] Convolution21 -> Convolution21
I0525 23:43:48.894901 15117 net.cpp:240] Setting up Convolution21
I0525 23:43:48.894932 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.894937 15117 net.cpp:255] Memory required for data: 674759168
I0525 23:43:48.894953 15117 layer_factory.hpp:77] Creating layer BatchNorm21
I0525 23:43:48.894966 15117 net.cpp:190] Creating Layer BatchNorm21
I0525 23:43:48.894973 15117 net.cpp:605] BatchNorm21 <- Convolution21
I0525 23:43:48.894980 15117 net.cpp:566] BatchNorm21 -> Convolution21 (in-place)
I0525 23:43:48.895170 15117 net.cpp:240] Setting up BatchNorm21
I0525 23:43:48.895179 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.895182 15117 net.cpp:255] Memory required for data: 676856320
I0525 23:43:48.895193 15117 layer_factory.hpp:77] Creating layer Scale21
I0525 23:43:48.895202 15117 net.cpp:190] Creating Layer Scale21
I0525 23:43:48.895206 15117 net.cpp:605] Scale21 <- Convolution21
I0525 23:43:48.895211 15117 net.cpp:566] Scale21 -> Convolution21 (in-place)
I0525 23:43:48.895251 15117 layer_factory.hpp:77] Creating layer Scale21
I0525 23:43:48.895365 15117 net.cpp:240] Setting up Scale21
I0525 23:43:48.895373 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.895377 15117 net.cpp:255] Memory required for data: 678953472
I0525 23:43:48.895388 15117 layer_factory.hpp:77] Creating layer Eltwise10
I0525 23:43:48.895397 15117 net.cpp:190] Creating Layer Eltwise10
I0525 23:43:48.895403 15117 net.cpp:605] Eltwise10 <- Concat2
I0525 23:43:48.895408 15117 net.cpp:605] Eltwise10 <- Convolution21
I0525 23:43:48.895416 15117 net.cpp:579] Eltwise10 -> Eltwise10
I0525 23:43:48.895438 15117 net.cpp:240] Setting up Eltwise10
I0525 23:43:48.895445 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.895455 15117 net.cpp:255] Memory required for data: 681050624
I0525 23:43:48.895490 15117 layer_factory.hpp:77] Creating layer ReLU21
I0525 23:43:48.895498 15117 net.cpp:190] Creating Layer ReLU21
I0525 23:43:48.895503 15117 net.cpp:605] ReLU21 <- Eltwise10
I0525 23:43:48.895509 15117 net.cpp:566] ReLU21 -> Eltwise10 (in-place)
I0525 23:43:48.895516 15117 net.cpp:240] Setting up ReLU21
I0525 23:43:48.895522 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.895526 15117 net.cpp:255] Memory required for data: 683147776
I0525 23:43:48.895529 15117 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0525 23:43:48.895536 15117 net.cpp:190] Creating Layer Eltwise10_ReLU21_0_split
I0525 23:43:48.895539 15117 net.cpp:605] Eltwise10_ReLU21_0_split <- Eltwise10
I0525 23:43:48.895545 15117 net.cpp:579] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0525 23:43:48.895551 15117 net.cpp:579] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0525 23:43:48.895589 15117 net.cpp:240] Setting up Eltwise10_ReLU21_0_split
I0525 23:43:48.895596 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.895601 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.895604 15117 net.cpp:255] Memory required for data: 687342080
I0525 23:43:48.895608 15117 layer_factory.hpp:77] Creating layer Convolution22
I0525 23:43:48.895622 15117 net.cpp:190] Creating Layer Convolution22
I0525 23:43:48.895625 15117 net.cpp:605] Convolution22 <- Eltwise10_ReLU21_0_split_0
I0525 23:43:48.895632 15117 net.cpp:579] Convolution22 -> Convolution22
I0525 23:43:48.897198 15117 net.cpp:240] Setting up Convolution22
I0525 23:43:48.897230 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.897234 15117 net.cpp:255] Memory required for data: 689439232
I0525 23:43:48.897248 15117 layer_factory.hpp:77] Creating layer BatchNorm22
I0525 23:43:48.897264 15117 net.cpp:190] Creating Layer BatchNorm22
I0525 23:43:48.897271 15117 net.cpp:605] BatchNorm22 <- Convolution22
I0525 23:43:48.897281 15117 net.cpp:566] BatchNorm22 -> Convolution22 (in-place)
I0525 23:43:48.897480 15117 net.cpp:240] Setting up BatchNorm22
I0525 23:43:48.897487 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.897491 15117 net.cpp:255] Memory required for data: 691536384
I0525 23:43:48.897505 15117 layer_factory.hpp:77] Creating layer Scale22
I0525 23:43:48.897513 15117 net.cpp:190] Creating Layer Scale22
I0525 23:43:48.897518 15117 net.cpp:605] Scale22 <- Convolution22
I0525 23:43:48.897523 15117 net.cpp:566] Scale22 -> Convolution22 (in-place)
I0525 23:43:48.897563 15117 layer_factory.hpp:77] Creating layer Scale22
I0525 23:43:48.897677 15117 net.cpp:240] Setting up Scale22
I0525 23:43:48.897685 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.897688 15117 net.cpp:255] Memory required for data: 693633536
I0525 23:43:48.897697 15117 layer_factory.hpp:77] Creating layer ReLU22
I0525 23:43:48.897706 15117 net.cpp:190] Creating Layer ReLU22
I0525 23:43:48.897709 15117 net.cpp:605] ReLU22 <- Convolution22
I0525 23:43:48.897716 15117 net.cpp:566] ReLU22 -> Convolution22 (in-place)
I0525 23:43:48.897723 15117 net.cpp:240] Setting up ReLU22
I0525 23:43:48.897728 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.897732 15117 net.cpp:255] Memory required for data: 695730688
I0525 23:43:48.897737 15117 layer_factory.hpp:77] Creating layer Convolution23
I0525 23:43:48.897748 15117 net.cpp:190] Creating Layer Convolution23
I0525 23:43:48.897753 15117 net.cpp:605] Convolution23 <- Convolution22
I0525 23:43:48.897760 15117 net.cpp:579] Convolution23 -> Convolution23
I0525 23:43:48.899304 15117 net.cpp:240] Setting up Convolution23
I0525 23:43:48.899338 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.899341 15117 net.cpp:255] Memory required for data: 697827840
I0525 23:43:48.899356 15117 layer_factory.hpp:77] Creating layer BatchNorm23
I0525 23:43:48.899370 15117 net.cpp:190] Creating Layer BatchNorm23
I0525 23:43:48.899377 15117 net.cpp:605] BatchNorm23 <- Convolution23
I0525 23:43:48.899394 15117 net.cpp:566] BatchNorm23 -> Convolution23 (in-place)
I0525 23:43:48.899618 15117 net.cpp:240] Setting up BatchNorm23
I0525 23:43:48.899627 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.899631 15117 net.cpp:255] Memory required for data: 699924992
I0525 23:43:48.899642 15117 layer_factory.hpp:77] Creating layer Scale23
I0525 23:43:48.899652 15117 net.cpp:190] Creating Layer Scale23
I0525 23:43:48.899657 15117 net.cpp:605] Scale23 <- Convolution23
I0525 23:43:48.899663 15117 net.cpp:566] Scale23 -> Convolution23 (in-place)
I0525 23:43:48.899700 15117 layer_factory.hpp:77] Creating layer Scale23
I0525 23:43:48.899816 15117 net.cpp:240] Setting up Scale23
I0525 23:43:48.899823 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.899827 15117 net.cpp:255] Memory required for data: 702022144
I0525 23:43:48.899835 15117 layer_factory.hpp:77] Creating layer Eltwise11
I0525 23:43:48.899844 15117 net.cpp:190] Creating Layer Eltwise11
I0525 23:43:48.899849 15117 net.cpp:605] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0525 23:43:48.899854 15117 net.cpp:605] Eltwise11 <- Convolution23
I0525 23:43:48.899863 15117 net.cpp:579] Eltwise11 -> Eltwise11
I0525 23:43:48.899883 15117 net.cpp:240] Setting up Eltwise11
I0525 23:43:48.899890 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.899894 15117 net.cpp:255] Memory required for data: 704119296
I0525 23:43:48.899899 15117 layer_factory.hpp:77] Creating layer ReLU23
I0525 23:43:48.899905 15117 net.cpp:190] Creating Layer ReLU23
I0525 23:43:48.899909 15117 net.cpp:605] ReLU23 <- Eltwise11
I0525 23:43:48.899914 15117 net.cpp:566] ReLU23 -> Eltwise11 (in-place)
I0525 23:43:48.899920 15117 net.cpp:240] Setting up ReLU23
I0525 23:43:48.899925 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.899930 15117 net.cpp:255] Memory required for data: 706216448
I0525 23:43:48.899933 15117 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0525 23:43:48.899940 15117 net.cpp:190] Creating Layer Eltwise11_ReLU23_0_split
I0525 23:43:48.899943 15117 net.cpp:605] Eltwise11_ReLU23_0_split <- Eltwise11
I0525 23:43:48.899950 15117 net.cpp:579] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0525 23:43:48.899968 15117 net.cpp:579] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0525 23:43:48.900002 15117 net.cpp:240] Setting up Eltwise11_ReLU23_0_split
I0525 23:43:48.900010 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.900015 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.900018 15117 net.cpp:255] Memory required for data: 710410752
I0525 23:43:48.900022 15117 layer_factory.hpp:77] Creating layer Convolution24
I0525 23:43:48.900034 15117 net.cpp:190] Creating Layer Convolution24
I0525 23:43:48.900038 15117 net.cpp:605] Convolution24 <- Eltwise11_ReLU23_0_split_0
I0525 23:43:48.900048 15117 net.cpp:579] Convolution24 -> Convolution24
I0525 23:43:48.901628 15117 net.cpp:240] Setting up Convolution24
I0525 23:43:48.901660 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.901664 15117 net.cpp:255] Memory required for data: 712507904
I0525 23:43:48.901680 15117 layer_factory.hpp:77] Creating layer BatchNorm24
I0525 23:43:48.901700 15117 net.cpp:190] Creating Layer BatchNorm24
I0525 23:43:48.901707 15117 net.cpp:605] BatchNorm24 <- Convolution24
I0525 23:43:48.901716 15117 net.cpp:566] BatchNorm24 -> Convolution24 (in-place)
I0525 23:43:48.901906 15117 net.cpp:240] Setting up BatchNorm24
I0525 23:43:48.901912 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.901916 15117 net.cpp:255] Memory required for data: 714605056
I0525 23:43:48.901927 15117 layer_factory.hpp:77] Creating layer Scale24
I0525 23:43:48.901938 15117 net.cpp:190] Creating Layer Scale24
I0525 23:43:48.901942 15117 net.cpp:605] Scale24 <- Convolution24
I0525 23:43:48.901948 15117 net.cpp:566] Scale24 -> Convolution24 (in-place)
I0525 23:43:48.901984 15117 layer_factory.hpp:77] Creating layer Scale24
I0525 23:43:48.902101 15117 net.cpp:240] Setting up Scale24
I0525 23:43:48.902109 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.902158 15117 net.cpp:255] Memory required for data: 716702208
I0525 23:43:48.902166 15117 layer_factory.hpp:77] Creating layer ReLU24
I0525 23:43:48.902176 15117 net.cpp:190] Creating Layer ReLU24
I0525 23:43:48.902181 15117 net.cpp:605] ReLU24 <- Convolution24
I0525 23:43:48.902187 15117 net.cpp:566] ReLU24 -> Convolution24 (in-place)
I0525 23:43:48.902194 15117 net.cpp:240] Setting up ReLU24
I0525 23:43:48.902199 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.902202 15117 net.cpp:255] Memory required for data: 718799360
I0525 23:43:48.902206 15117 layer_factory.hpp:77] Creating layer Convolution25
I0525 23:43:48.902220 15117 net.cpp:190] Creating Layer Convolution25
I0525 23:43:48.902225 15117 net.cpp:605] Convolution25 <- Convolution24
I0525 23:43:48.902230 15117 net.cpp:579] Convolution25 -> Convolution25
I0525 23:43:48.903796 15117 net.cpp:240] Setting up Convolution25
I0525 23:43:48.903830 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.903833 15117 net.cpp:255] Memory required for data: 720896512
I0525 23:43:48.903848 15117 layer_factory.hpp:77] Creating layer BatchNorm25
I0525 23:43:48.903863 15117 net.cpp:190] Creating Layer BatchNorm25
I0525 23:43:48.903870 15117 net.cpp:605] BatchNorm25 <- Convolution25
I0525 23:43:48.903878 15117 net.cpp:566] BatchNorm25 -> Convolution25 (in-place)
I0525 23:43:48.904073 15117 net.cpp:240] Setting up BatchNorm25
I0525 23:43:48.904081 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.904085 15117 net.cpp:255] Memory required for data: 722993664
I0525 23:43:48.904096 15117 layer_factory.hpp:77] Creating layer Scale25
I0525 23:43:48.904129 15117 net.cpp:190] Creating Layer Scale25
I0525 23:43:48.904134 15117 net.cpp:605] Scale25 <- Convolution25
I0525 23:43:48.904140 15117 net.cpp:566] Scale25 -> Convolution25 (in-place)
I0525 23:43:48.904181 15117 layer_factory.hpp:77] Creating layer Scale25
I0525 23:43:48.904306 15117 net.cpp:240] Setting up Scale25
I0525 23:43:48.904314 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.904319 15117 net.cpp:255] Memory required for data: 725090816
I0525 23:43:48.904327 15117 layer_factory.hpp:77] Creating layer Eltwise12
I0525 23:43:48.904336 15117 net.cpp:190] Creating Layer Eltwise12
I0525 23:43:48.904345 15117 net.cpp:605] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0525 23:43:48.904350 15117 net.cpp:605] Eltwise12 <- Convolution25
I0525 23:43:48.904357 15117 net.cpp:579] Eltwise12 -> Eltwise12
I0525 23:43:48.904376 15117 net.cpp:240] Setting up Eltwise12
I0525 23:43:48.904383 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.904386 15117 net.cpp:255] Memory required for data: 727187968
I0525 23:43:48.904391 15117 layer_factory.hpp:77] Creating layer ReLU25
I0525 23:43:48.904400 15117 net.cpp:190] Creating Layer ReLU25
I0525 23:43:48.904405 15117 net.cpp:605] ReLU25 <- Eltwise12
I0525 23:43:48.904410 15117 net.cpp:566] ReLU25 -> Eltwise12 (in-place)
I0525 23:43:48.904417 15117 net.cpp:240] Setting up ReLU25
I0525 23:43:48.904422 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.904425 15117 net.cpp:255] Memory required for data: 729285120
I0525 23:43:48.904429 15117 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I0525 23:43:48.904435 15117 net.cpp:190] Creating Layer Eltwise12_ReLU25_0_split
I0525 23:43:48.904439 15117 net.cpp:605] Eltwise12_ReLU25_0_split <- Eltwise12
I0525 23:43:48.904444 15117 net.cpp:579] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I0525 23:43:48.904451 15117 net.cpp:579] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I0525 23:43:48.904486 15117 net.cpp:240] Setting up Eltwise12_ReLU25_0_split
I0525 23:43:48.904492 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.904497 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.904501 15117 net.cpp:255] Memory required for data: 733479424
I0525 23:43:48.904505 15117 layer_factory.hpp:77] Creating layer Convolution26
I0525 23:43:48.904520 15117 net.cpp:190] Creating Layer Convolution26
I0525 23:43:48.904531 15117 net.cpp:605] Convolution26 <- Eltwise12_ReLU25_0_split_0
I0525 23:43:48.904570 15117 net.cpp:579] Convolution26 -> Convolution26
I0525 23:43:48.906136 15117 net.cpp:240] Setting up Convolution26
I0525 23:43:48.906168 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.906172 15117 net.cpp:255] Memory required for data: 735576576
I0525 23:43:48.906186 15117 layer_factory.hpp:77] Creating layer BatchNorm26
I0525 23:43:48.906201 15117 net.cpp:190] Creating Layer BatchNorm26
I0525 23:43:48.906208 15117 net.cpp:605] BatchNorm26 <- Convolution26
I0525 23:43:48.906218 15117 net.cpp:566] BatchNorm26 -> Convolution26 (in-place)
I0525 23:43:48.910521 15117 net.cpp:240] Setting up BatchNorm26
I0525 23:43:48.910558 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.910563 15117 net.cpp:255] Memory required for data: 737673728
I0525 23:43:48.910585 15117 layer_factory.hpp:77] Creating layer Scale26
I0525 23:43:48.910606 15117 net.cpp:190] Creating Layer Scale26
I0525 23:43:48.910614 15117 net.cpp:605] Scale26 <- Convolution26
I0525 23:43:48.910624 15117 net.cpp:566] Scale26 -> Convolution26 (in-place)
I0525 23:43:48.910671 15117 layer_factory.hpp:77] Creating layer Scale26
I0525 23:43:48.910786 15117 net.cpp:240] Setting up Scale26
I0525 23:43:48.910794 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.910797 15117 net.cpp:255] Memory required for data: 739770880
I0525 23:43:48.910807 15117 layer_factory.hpp:77] Creating layer ReLU26
I0525 23:43:48.910816 15117 net.cpp:190] Creating Layer ReLU26
I0525 23:43:48.910821 15117 net.cpp:605] ReLU26 <- Convolution26
I0525 23:43:48.910827 15117 net.cpp:566] ReLU26 -> Convolution26 (in-place)
I0525 23:43:48.910835 15117 net.cpp:240] Setting up ReLU26
I0525 23:43:48.910840 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.910843 15117 net.cpp:255] Memory required for data: 741868032
I0525 23:43:48.910847 15117 layer_factory.hpp:77] Creating layer Convolution27
I0525 23:43:48.910861 15117 net.cpp:190] Creating Layer Convolution27
I0525 23:43:48.910866 15117 net.cpp:605] Convolution27 <- Convolution26
I0525 23:43:48.910871 15117 net.cpp:579] Convolution27 -> Convolution27
I0525 23:43:48.913249 15117 net.cpp:240] Setting up Convolution27
I0525 23:43:48.913296 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.913301 15117 net.cpp:255] Memory required for data: 743965184
I0525 23:43:48.913319 15117 layer_factory.hpp:77] Creating layer BatchNorm27
I0525 23:43:48.913342 15117 net.cpp:190] Creating Layer BatchNorm27
I0525 23:43:48.913350 15117 net.cpp:605] BatchNorm27 <- Convolution27
I0525 23:43:48.913359 15117 net.cpp:566] BatchNorm27 -> Convolution27 (in-place)
I0525 23:43:48.913554 15117 net.cpp:240] Setting up BatchNorm27
I0525 23:43:48.913563 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.913566 15117 net.cpp:255] Memory required for data: 746062336
I0525 23:43:48.913578 15117 layer_factory.hpp:77] Creating layer Scale27
I0525 23:43:48.913588 15117 net.cpp:190] Creating Layer Scale27
I0525 23:43:48.913592 15117 net.cpp:605] Scale27 <- Convolution27
I0525 23:43:48.913597 15117 net.cpp:566] Scale27 -> Convolution27 (in-place)
I0525 23:43:48.913636 15117 layer_factory.hpp:77] Creating layer Scale27
I0525 23:43:48.913750 15117 net.cpp:240] Setting up Scale27
I0525 23:43:48.913758 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.913763 15117 net.cpp:255] Memory required for data: 748159488
I0525 23:43:48.913771 15117 layer_factory.hpp:77] Creating layer Eltwise13
I0525 23:43:48.913782 15117 net.cpp:190] Creating Layer Eltwise13
I0525 23:43:48.913789 15117 net.cpp:605] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I0525 23:43:48.913794 15117 net.cpp:605] Eltwise13 <- Convolution27
I0525 23:43:48.913800 15117 net.cpp:579] Eltwise13 -> Eltwise13
I0525 23:43:48.913822 15117 net.cpp:240] Setting up Eltwise13
I0525 23:43:48.913828 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.913832 15117 net.cpp:255] Memory required for data: 750256640
I0525 23:43:48.913842 15117 layer_factory.hpp:77] Creating layer ReLU27
I0525 23:43:48.913880 15117 net.cpp:190] Creating Layer ReLU27
I0525 23:43:48.913884 15117 net.cpp:605] ReLU27 <- Eltwise13
I0525 23:43:48.913892 15117 net.cpp:566] ReLU27 -> Eltwise13 (in-place)
I0525 23:43:48.913900 15117 net.cpp:240] Setting up ReLU27
I0525 23:43:48.913905 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.913909 15117 net.cpp:255] Memory required for data: 752353792
I0525 23:43:48.913913 15117 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I0525 23:43:48.913919 15117 net.cpp:190] Creating Layer Eltwise13_ReLU27_0_split
I0525 23:43:48.913923 15117 net.cpp:605] Eltwise13_ReLU27_0_split <- Eltwise13
I0525 23:43:48.913928 15117 net.cpp:579] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I0525 23:43:48.913934 15117 net.cpp:579] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I0525 23:43:48.913972 15117 net.cpp:240] Setting up Eltwise13_ReLU27_0_split
I0525 23:43:48.913980 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.913985 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.913987 15117 net.cpp:255] Memory required for data: 756548096
I0525 23:43:48.913991 15117 layer_factory.hpp:77] Creating layer Convolution28
I0525 23:43:48.914003 15117 net.cpp:190] Creating Layer Convolution28
I0525 23:43:48.914007 15117 net.cpp:605] Convolution28 <- Eltwise13_ReLU27_0_split_0
I0525 23:43:48.914017 15117 net.cpp:579] Convolution28 -> Convolution28
I0525 23:43:48.915585 15117 net.cpp:240] Setting up Convolution28
I0525 23:43:48.915621 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.915626 15117 net.cpp:255] Memory required for data: 758645248
I0525 23:43:48.915642 15117 layer_factory.hpp:77] Creating layer BatchNorm28
I0525 23:43:48.915657 15117 net.cpp:190] Creating Layer BatchNorm28
I0525 23:43:48.915663 15117 net.cpp:605] BatchNorm28 <- Convolution28
I0525 23:43:48.915674 15117 net.cpp:566] BatchNorm28 -> Convolution28 (in-place)
I0525 23:43:48.915873 15117 net.cpp:240] Setting up BatchNorm28
I0525 23:43:48.915880 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.915884 15117 net.cpp:255] Memory required for data: 760742400
I0525 23:43:48.915895 15117 layer_factory.hpp:77] Creating layer Scale28
I0525 23:43:48.915904 15117 net.cpp:190] Creating Layer Scale28
I0525 23:43:48.915909 15117 net.cpp:605] Scale28 <- Convolution28
I0525 23:43:48.915915 15117 net.cpp:566] Scale28 -> Convolution28 (in-place)
I0525 23:43:48.915953 15117 layer_factory.hpp:77] Creating layer Scale28
I0525 23:43:48.916081 15117 net.cpp:240] Setting up Scale28
I0525 23:43:48.916090 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.916093 15117 net.cpp:255] Memory required for data: 762839552
I0525 23:43:48.916102 15117 layer_factory.hpp:77] Creating layer ReLU28
I0525 23:43:48.916110 15117 net.cpp:190] Creating Layer ReLU28
I0525 23:43:48.916115 15117 net.cpp:605] ReLU28 <- Convolution28
I0525 23:43:48.916122 15117 net.cpp:566] ReLU28 -> Convolution28 (in-place)
I0525 23:43:48.916129 15117 net.cpp:240] Setting up ReLU28
I0525 23:43:48.916134 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.916138 15117 net.cpp:255] Memory required for data: 764936704
I0525 23:43:48.916142 15117 layer_factory.hpp:77] Creating layer Convolution29
I0525 23:43:48.916157 15117 net.cpp:190] Creating Layer Convolution29
I0525 23:43:48.916160 15117 net.cpp:605] Convolution29 <- Convolution28
I0525 23:43:48.916167 15117 net.cpp:579] Convolution29 -> Convolution29
I0525 23:43:48.917733 15117 net.cpp:240] Setting up Convolution29
I0525 23:43:48.917768 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.917773 15117 net.cpp:255] Memory required for data: 767033856
I0525 23:43:48.917788 15117 layer_factory.hpp:77] Creating layer BatchNorm29
I0525 23:43:48.917803 15117 net.cpp:190] Creating Layer BatchNorm29
I0525 23:43:48.917810 15117 net.cpp:605] BatchNorm29 <- Convolution29
I0525 23:43:48.917819 15117 net.cpp:566] BatchNorm29 -> Convolution29 (in-place)
I0525 23:43:48.918061 15117 net.cpp:240] Setting up BatchNorm29
I0525 23:43:48.918102 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.918107 15117 net.cpp:255] Memory required for data: 769131008
I0525 23:43:48.918119 15117 layer_factory.hpp:77] Creating layer Scale29
I0525 23:43:48.918129 15117 net.cpp:190] Creating Layer Scale29
I0525 23:43:48.918133 15117 net.cpp:605] Scale29 <- Convolution29
I0525 23:43:48.918139 15117 net.cpp:566] Scale29 -> Convolution29 (in-place)
I0525 23:43:48.918185 15117 layer_factory.hpp:77] Creating layer Scale29
I0525 23:43:48.918305 15117 net.cpp:240] Setting up Scale29
I0525 23:43:48.918313 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.918318 15117 net.cpp:255] Memory required for data: 771228160
I0525 23:43:48.918325 15117 layer_factory.hpp:77] Creating layer Eltwise14
I0525 23:43:48.918336 15117 net.cpp:190] Creating Layer Eltwise14
I0525 23:43:48.918342 15117 net.cpp:605] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I0525 23:43:48.918349 15117 net.cpp:605] Eltwise14 <- Convolution29
I0525 23:43:48.918360 15117 net.cpp:579] Eltwise14 -> Eltwise14
I0525 23:43:48.918381 15117 net.cpp:240] Setting up Eltwise14
I0525 23:43:48.918387 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.918391 15117 net.cpp:255] Memory required for data: 773325312
I0525 23:43:48.918395 15117 layer_factory.hpp:77] Creating layer ReLU29
I0525 23:43:48.918406 15117 net.cpp:190] Creating Layer ReLU29
I0525 23:43:48.918411 15117 net.cpp:605] ReLU29 <- Eltwise14
I0525 23:43:48.918416 15117 net.cpp:566] ReLU29 -> Eltwise14 (in-place)
I0525 23:43:48.918424 15117 net.cpp:240] Setting up ReLU29
I0525 23:43:48.918429 15117 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:43:48.918433 15117 net.cpp:255] Memory required for data: 775422464
I0525 23:43:48.918437 15117 layer_factory.hpp:77] Creating layer Pooling3
I0525 23:43:48.918445 15117 net.cpp:190] Creating Layer Pooling3
I0525 23:43:48.918449 15117 net.cpp:605] Pooling3 <- Eltwise14
I0525 23:43:48.918455 15117 net.cpp:579] Pooling3 -> Pooling3
I0525 23:43:48.918493 15117 net.cpp:240] Setting up Pooling3
I0525 23:43:48.918500 15117 net.cpp:247] Top shape: 128 64 1 1 (8192)
I0525 23:43:48.918504 15117 net.cpp:255] Memory required for data: 775455232
I0525 23:43:48.918509 15117 layer_factory.hpp:77] Creating layer InnerProduct1
I0525 23:43:48.918516 15117 net.cpp:190] Creating Layer InnerProduct1
I0525 23:43:48.918520 15117 net.cpp:605] InnerProduct1 <- Pooling3
I0525 23:43:48.918527 15117 net.cpp:579] InnerProduct1 -> InnerProduct1
I0525 23:43:48.918680 15117 net.cpp:240] Setting up InnerProduct1
I0525 23:43:48.918690 15117 net.cpp:247] Top shape: 128 10 (1280)
I0525 23:43:48.918694 15117 net.cpp:255] Memory required for data: 775460352
I0525 23:43:48.918704 15117 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0525 23:43:48.918723 15117 net.cpp:190] Creating Layer SoftmaxWithLoss1
I0525 23:43:48.918727 15117 net.cpp:605] SoftmaxWithLoss1 <- InnerProduct1
I0525 23:43:48.918733 15117 net.cpp:605] SoftmaxWithLoss1 <- Data2
I0525 23:43:48.918742 15117 net.cpp:579] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0525 23:43:48.918754 15117 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0525 23:43:48.918853 15117 net.cpp:240] Setting up SoftmaxWithLoss1
I0525 23:43:48.918860 15117 net.cpp:247] Top shape: (1)
I0525 23:43:48.918864 15117 net.cpp:250]     with loss weight 1
I0525 23:43:48.918891 15117 net.cpp:255] Memory required for data: 775460356
I0525 23:43:48.918896 15117 net.cpp:316] SoftmaxWithLoss1 needs backward computation.
I0525 23:43:48.918901 15117 net.cpp:316] InnerProduct1 needs backward computation.
I0525 23:43:48.918905 15117 net.cpp:316] Pooling3 needs backward computation.
I0525 23:43:48.918910 15117 net.cpp:316] ReLU29 needs backward computation.
I0525 23:43:48.918912 15117 net.cpp:316] Eltwise14 needs backward computation.
I0525 23:43:48.918917 15117 net.cpp:316] Scale29 needs backward computation.
I0525 23:43:48.918920 15117 net.cpp:316] BatchNorm29 needs backward computation.
I0525 23:43:48.918925 15117 net.cpp:316] Convolution29 needs backward computation.
I0525 23:43:48.918956 15117 net.cpp:316] ReLU28 needs backward computation.
I0525 23:43:48.918959 15117 net.cpp:316] Scale28 needs backward computation.
I0525 23:43:48.918963 15117 net.cpp:316] BatchNorm28 needs backward computation.
I0525 23:43:48.918967 15117 net.cpp:316] Convolution28 needs backward computation.
I0525 23:43:48.918972 15117 net.cpp:316] Eltwise13_ReLU27_0_split needs backward computation.
I0525 23:43:48.918975 15117 net.cpp:316] ReLU27 needs backward computation.
I0525 23:43:48.918979 15117 net.cpp:316] Eltwise13 needs backward computation.
I0525 23:43:48.918983 15117 net.cpp:316] Scale27 needs backward computation.
I0525 23:43:48.918987 15117 net.cpp:316] BatchNorm27 needs backward computation.
I0525 23:43:48.918992 15117 net.cpp:316] Convolution27 needs backward computation.
I0525 23:43:48.918995 15117 net.cpp:316] ReLU26 needs backward computation.
I0525 23:43:48.918999 15117 net.cpp:316] Scale26 needs backward computation.
I0525 23:43:48.919003 15117 net.cpp:316] BatchNorm26 needs backward computation.
I0525 23:43:48.919006 15117 net.cpp:316] Convolution26 needs backward computation.
I0525 23:43:48.919010 15117 net.cpp:316] Eltwise12_ReLU25_0_split needs backward computation.
I0525 23:43:48.919014 15117 net.cpp:316] ReLU25 needs backward computation.
I0525 23:43:48.919018 15117 net.cpp:316] Eltwise12 needs backward computation.
I0525 23:43:48.919023 15117 net.cpp:316] Scale25 needs backward computation.
I0525 23:43:48.919028 15117 net.cpp:316] BatchNorm25 needs backward computation.
I0525 23:43:48.919030 15117 net.cpp:316] Convolution25 needs backward computation.
I0525 23:43:48.919035 15117 net.cpp:316] ReLU24 needs backward computation.
I0525 23:43:48.919039 15117 net.cpp:316] Scale24 needs backward computation.
I0525 23:43:48.919042 15117 net.cpp:316] BatchNorm24 needs backward computation.
I0525 23:43:48.919046 15117 net.cpp:316] Convolution24 needs backward computation.
I0525 23:43:48.919050 15117 net.cpp:316] Eltwise11_ReLU23_0_split needs backward computation.
I0525 23:43:48.919054 15117 net.cpp:316] ReLU23 needs backward computation.
I0525 23:43:48.919059 15117 net.cpp:316] Eltwise11 needs backward computation.
I0525 23:43:48.919064 15117 net.cpp:316] Scale23 needs backward computation.
I0525 23:43:48.919066 15117 net.cpp:316] BatchNorm23 needs backward computation.
I0525 23:43:48.919070 15117 net.cpp:316] Convolution23 needs backward computation.
I0525 23:43:48.919075 15117 net.cpp:316] ReLU22 needs backward computation.
I0525 23:43:48.919078 15117 net.cpp:316] Scale22 needs backward computation.
I0525 23:43:48.919082 15117 net.cpp:316] BatchNorm22 needs backward computation.
I0525 23:43:48.919085 15117 net.cpp:316] Convolution22 needs backward computation.
I0525 23:43:48.919090 15117 net.cpp:316] Eltwise10_ReLU21_0_split needs backward computation.
I0525 23:43:48.919095 15117 net.cpp:316] ReLU21 needs backward computation.
I0525 23:43:48.919098 15117 net.cpp:316] Eltwise10 needs backward computation.
I0525 23:43:48.919103 15117 net.cpp:316] Scale21 needs backward computation.
I0525 23:43:48.919107 15117 net.cpp:316] BatchNorm21 needs backward computation.
I0525 23:43:48.919111 15117 net.cpp:316] Convolution21 needs backward computation.
I0525 23:43:48.919116 15117 net.cpp:316] ReLU20 needs backward computation.
I0525 23:43:48.919119 15117 net.cpp:316] Scale20 needs backward computation.
I0525 23:43:48.919123 15117 net.cpp:316] BatchNorm20 needs backward computation.
I0525 23:43:48.919126 15117 net.cpp:316] Convolution20 needs backward computation.
I0525 23:43:48.919131 15117 net.cpp:316] Concat2 needs backward computation.
I0525 23:43:48.919137 15117 net.cpp:318] Input2 does not need backward computation.
I0525 23:43:48.919140 15117 net.cpp:316] Pooling2 needs backward computation.
I0525 23:43:48.919145 15117 net.cpp:316] Eltwise9_ReLU19_0_split needs backward computation.
I0525 23:43:48.919150 15117 net.cpp:316] ReLU19 needs backward computation.
I0525 23:43:48.919153 15117 net.cpp:316] Eltwise9 needs backward computation.
I0525 23:43:48.919162 15117 net.cpp:316] Scale19 needs backward computation.
I0525 23:43:48.919173 15117 net.cpp:316] BatchNorm19 needs backward computation.
I0525 23:43:48.919176 15117 net.cpp:316] Convolution19 needs backward computation.
I0525 23:43:48.919181 15117 net.cpp:316] ReLU18 needs backward computation.
I0525 23:43:48.919185 15117 net.cpp:316] Scale18 needs backward computation.
I0525 23:43:48.919188 15117 net.cpp:316] BatchNorm18 needs backward computation.
I0525 23:43:48.919193 15117 net.cpp:316] Convolution18 needs backward computation.
I0525 23:43:48.919198 15117 net.cpp:316] Eltwise8_ReLU17_0_split needs backward computation.
I0525 23:43:48.919201 15117 net.cpp:316] ReLU17 needs backward computation.
I0525 23:43:48.919205 15117 net.cpp:316] Eltwise8 needs backward computation.
I0525 23:43:48.919210 15117 net.cpp:316] Scale17 needs backward computation.
I0525 23:43:48.919214 15117 net.cpp:316] BatchNorm17 needs backward computation.
I0525 23:43:48.919219 15117 net.cpp:316] Convolution17 needs backward computation.
I0525 23:43:48.919222 15117 net.cpp:316] ReLU16 needs backward computation.
I0525 23:43:48.919226 15117 net.cpp:316] Scale16 needs backward computation.
I0525 23:43:48.919230 15117 net.cpp:316] BatchNorm16 needs backward computation.
I0525 23:43:48.919234 15117 net.cpp:316] Convolution16 needs backward computation.
I0525 23:43:48.919239 15117 net.cpp:316] Eltwise7_ReLU15_0_split needs backward computation.
I0525 23:43:48.919244 15117 net.cpp:316] ReLU15 needs backward computation.
I0525 23:43:48.919246 15117 net.cpp:316] Eltwise7 needs backward computation.
I0525 23:43:48.919251 15117 net.cpp:316] Scale15 needs backward computation.
I0525 23:43:48.919255 15117 net.cpp:316] BatchNorm15 needs backward computation.
I0525 23:43:48.919260 15117 net.cpp:316] Convolution15 needs backward computation.
I0525 23:43:48.919263 15117 net.cpp:316] ReLU14 needs backward computation.
I0525 23:43:48.919267 15117 net.cpp:316] Scale14 needs backward computation.
I0525 23:43:48.919271 15117 net.cpp:316] BatchNorm14 needs backward computation.
I0525 23:43:48.919275 15117 net.cpp:316] Convolution14 needs backward computation.
I0525 23:43:48.919280 15117 net.cpp:316] Eltwise6_ReLU13_0_split needs backward computation.
I0525 23:43:48.919283 15117 net.cpp:316] ReLU13 needs backward computation.
I0525 23:43:48.919287 15117 net.cpp:316] Eltwise6 needs backward computation.
I0525 23:43:48.919294 15117 net.cpp:316] Scale13 needs backward computation.
I0525 23:43:48.919299 15117 net.cpp:316] BatchNorm13 needs backward computation.
I0525 23:43:48.919302 15117 net.cpp:316] Convolution13 needs backward computation.
I0525 23:43:48.919306 15117 net.cpp:316] ReLU12 needs backward computation.
I0525 23:43:48.919312 15117 net.cpp:316] Scale12 needs backward computation.
I0525 23:43:48.919315 15117 net.cpp:316] BatchNorm12 needs backward computation.
I0525 23:43:48.919318 15117 net.cpp:316] Convolution12 needs backward computation.
I0525 23:43:48.919322 15117 net.cpp:316] Eltwise5_ReLU11_0_split needs backward computation.
I0525 23:43:48.919327 15117 net.cpp:316] ReLU11 needs backward computation.
I0525 23:43:48.919332 15117 net.cpp:316] Eltwise5 needs backward computation.
I0525 23:43:48.919335 15117 net.cpp:316] Scale11 needs backward computation.
I0525 23:43:48.919340 15117 net.cpp:316] BatchNorm11 needs backward computation.
I0525 23:43:48.919343 15117 net.cpp:316] Convolution11 needs backward computation.
I0525 23:43:48.919348 15117 net.cpp:316] ReLU10 needs backward computation.
I0525 23:43:48.919351 15117 net.cpp:316] Scale10 needs backward computation.
I0525 23:43:48.919355 15117 net.cpp:316] BatchNorm10 needs backward computation.
I0525 23:43:48.919359 15117 net.cpp:316] Convolution10 needs backward computation.
I0525 23:43:48.919364 15117 net.cpp:316] Concat1 needs backward computation.
I0525 23:43:48.919369 15117 net.cpp:318] Input1 does not need backward computation.
I0525 23:43:48.919373 15117 net.cpp:316] Pooling1 needs backward computation.
I0525 23:43:48.919378 15117 net.cpp:316] Eltwise4_ReLU9_0_split needs backward computation.
I0525 23:43:48.919385 15117 net.cpp:316] ReLU9 needs backward computation.
I0525 23:43:48.919399 15117 net.cpp:316] Eltwise4 needs backward computation.
I0525 23:43:48.919404 15117 net.cpp:316] Scale9 needs backward computation.
I0525 23:43:48.919409 15117 net.cpp:316] BatchNorm9 needs backward computation.
I0525 23:43:48.919412 15117 net.cpp:316] Convolution9 needs backward computation.
I0525 23:43:48.919417 15117 net.cpp:316] ReLU8 needs backward computation.
I0525 23:43:48.919421 15117 net.cpp:316] Scale8 needs backward computation.
I0525 23:43:48.919425 15117 net.cpp:316] BatchNorm8 needs backward computation.
I0525 23:43:48.919430 15117 net.cpp:316] Convolution8 needs backward computation.
I0525 23:43:48.919433 15117 net.cpp:316] Eltwise3_ReLU7_0_split needs backward computation.
I0525 23:43:48.919438 15117 net.cpp:316] ReLU7 needs backward computation.
I0525 23:43:48.919442 15117 net.cpp:316] Eltwise3 needs backward computation.
I0525 23:43:48.919447 15117 net.cpp:316] Scale7 needs backward computation.
I0525 23:43:48.919451 15117 net.cpp:316] BatchNorm7 needs backward computation.
I0525 23:43:48.919456 15117 net.cpp:316] Convolution7 needs backward computation.
I0525 23:43:48.919459 15117 net.cpp:316] ReLU6 needs backward computation.
I0525 23:43:48.919463 15117 net.cpp:316] Scale6 needs backward computation.
I0525 23:43:48.919467 15117 net.cpp:316] BatchNorm6 needs backward computation.
I0525 23:43:48.919471 15117 net.cpp:316] Convolution6 needs backward computation.
I0525 23:43:48.919476 15117 net.cpp:316] Eltwise2_ReLU5_0_split needs backward computation.
I0525 23:43:48.919479 15117 net.cpp:316] ReLU5 needs backward computation.
I0525 23:43:48.919484 15117 net.cpp:316] Eltwise2 needs backward computation.
I0525 23:43:48.919489 15117 net.cpp:316] Scale5 needs backward computation.
I0525 23:43:48.919493 15117 net.cpp:316] BatchNorm5 needs backward computation.
I0525 23:43:48.919497 15117 net.cpp:316] Convolution5 needs backward computation.
I0525 23:43:48.919503 15117 net.cpp:316] ReLU4 needs backward computation.
I0525 23:43:48.919507 15117 net.cpp:316] Scale4 needs backward computation.
I0525 23:43:48.919510 15117 net.cpp:316] BatchNorm4 needs backward computation.
I0525 23:43:48.919514 15117 net.cpp:316] Convolution4 needs backward computation.
I0525 23:43:48.919519 15117 net.cpp:316] Eltwise1_ReLU3_0_split needs backward computation.
I0525 23:43:48.919523 15117 net.cpp:316] ReLU3 needs backward computation.
I0525 23:43:48.919528 15117 net.cpp:316] Eltwise1 needs backward computation.
I0525 23:43:48.919533 15117 net.cpp:316] Scale3 needs backward computation.
I0525 23:43:48.919536 15117 net.cpp:316] BatchNorm3 needs backward computation.
I0525 23:43:48.919540 15117 net.cpp:316] Convolution3 needs backward computation.
I0525 23:43:48.919544 15117 net.cpp:316] ReLU2 needs backward computation.
I0525 23:43:48.919548 15117 net.cpp:316] Scale2 needs backward computation.
I0525 23:43:48.919553 15117 net.cpp:316] BatchNorm2 needs backward computation.
I0525 23:43:48.919556 15117 net.cpp:316] Convolution2 needs backward computation.
I0525 23:43:48.919561 15117 net.cpp:316] Convolution1_ReLU1_0_split needs backward computation.
I0525 23:43:48.919566 15117 net.cpp:316] ReLU1 needs backward computation.
I0525 23:43:48.919570 15117 net.cpp:316] Scale1 needs backward computation.
I0525 23:43:48.919574 15117 net.cpp:316] BatchNorm1 needs backward computation.
I0525 23:43:48.919579 15117 net.cpp:316] Convolution1 needs backward computation.
I0525 23:43:48.919584 15117 net.cpp:318] Data1 does not need backward computation.
I0525 23:43:48.919587 15117 net.cpp:360] This network produces output SoftmaxWithLoss1
I0525 23:43:48.919705 15117 net.cpp:374] Network initialization done.
I0525 23:43:48.924062 15117 solver.cpp:186] Creating test net (#0) specified by test_net file: examples/stochastic_depth/residual_test.prototxt
I0525 23:43:48.925216 15117 net.cpp:148] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "/scratch/pas282/caffe/examples/cifar10/cifar10_test_leveldb_padding1"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise4"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Input1"
  type: "Input"
  top: "Input1"
  input_param {
    shape {
      dim: 100
      dim: 16
      dim: 16
      dim: 16
    }
  }
}
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "Pooling1"
  bottom: "Input1"
  top: "Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Concat1"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Pooling2"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling2"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Input2"
  type: "Input"
  top: "Input2"
  input_param {
    shape {
      dim: 100
      dim: 32
      dim: 8
      dim: 8
    }
  }
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "Pooling2"
  bottom: "Input2"
  top: "Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Concat2"
  bottom: "Convolution21"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution22"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution22"
  top: "Convolution22"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Convolution22"
  top: "Convolution23"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution23"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution24"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution25"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution26"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution27"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution28"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution28"
  top: "Convolution28"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution29"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Pooling3"
  type: "Pooling"
  bottom: "Eltwise14"
  top: "Pooling3"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling3"
  top: "InnerProduct1"
  inner_product_param {
    num_output: 10
    bias_term: true
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Accuracy"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "Accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
I0525 23:43:48.925961 15117 layer_factory.hpp:77] Creating layer Data1
I0525 23:43:48.926146 15117 net.cpp:190] Creating Layer Data1
I0525 23:43:48.926175 15117 net.cpp:579] Data1 -> Data1
I0525 23:43:48.926194 15117 net.cpp:579] Data1 -> Data2
I0525 23:43:48.962142 15123 db_leveldb.cpp:18] Opened leveldb /scratch/pas282/caffe/examples/cifar10/cifar10_test_leveldb_padding1
I0525 23:43:48.962724 15117 data_layer.cpp:41] output data size: 100,3,32,32
I0525 23:43:48.974416 15117 net.cpp:240] Setting up Data1
I0525 23:43:48.974477 15117 net.cpp:247] Top shape: 100 3 32 32 (307200)
I0525 23:43:48.974485 15117 net.cpp:247] Top shape: 100 (100)
I0525 23:43:48.974489 15117 net.cpp:255] Memory required for data: 1229200
I0525 23:43:48.974498 15117 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0525 23:43:48.975296 15117 net.cpp:190] Creating Layer Data2_Data1_1_split
I0525 23:43:48.975322 15117 net.cpp:605] Data2_Data1_1_split <- Data2
I0525 23:43:48.975335 15117 net.cpp:579] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0525 23:43:48.975352 15117 net.cpp:579] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0525 23:43:48.975515 15117 net.cpp:240] Setting up Data2_Data1_1_split
I0525 23:43:48.975533 15117 net.cpp:247] Top shape: 100 (100)
I0525 23:43:48.975538 15117 net.cpp:247] Top shape: 100 (100)
I0525 23:43:48.975541 15117 net.cpp:255] Memory required for data: 1230000
I0525 23:43:48.975548 15117 layer_factory.hpp:77] Creating layer Convolution1
I0525 23:43:48.975571 15117 net.cpp:190] Creating Layer Convolution1
I0525 23:43:48.975576 15117 net.cpp:605] Convolution1 <- Data1
I0525 23:43:48.975589 15117 net.cpp:579] Convolution1 -> Convolution1
I0525 23:43:48.975898 15117 net.cpp:240] Setting up Convolution1
I0525 23:43:48.975909 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.975914 15117 net.cpp:255] Memory required for data: 7783600
I0525 23:43:48.975929 15117 layer_factory.hpp:77] Creating layer BatchNorm1
I0525 23:43:48.975939 15117 net.cpp:190] Creating Layer BatchNorm1
I0525 23:43:48.975944 15117 net.cpp:605] BatchNorm1 <- Convolution1
I0525 23:43:48.975951 15117 net.cpp:566] BatchNorm1 -> Convolution1 (in-place)
I0525 23:43:48.976146 15117 net.cpp:240] Setting up BatchNorm1
I0525 23:43:48.976155 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.976158 15117 net.cpp:255] Memory required for data: 14337200
I0525 23:43:48.976172 15117 layer_factory.hpp:77] Creating layer Scale1
I0525 23:43:48.976183 15117 net.cpp:190] Creating Layer Scale1
I0525 23:43:48.976187 15117 net.cpp:605] Scale1 <- Convolution1
I0525 23:43:48.976197 15117 net.cpp:566] Scale1 -> Convolution1 (in-place)
I0525 23:43:48.976240 15117 layer_factory.hpp:77] Creating layer Scale1
I0525 23:43:48.976364 15117 net.cpp:240] Setting up Scale1
I0525 23:43:48.976404 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.976408 15117 net.cpp:255] Memory required for data: 20890800
I0525 23:43:48.976418 15117 layer_factory.hpp:77] Creating layer ReLU1
I0525 23:43:48.976428 15117 net.cpp:190] Creating Layer ReLU1
I0525 23:43:48.976433 15117 net.cpp:605] ReLU1 <- Convolution1
I0525 23:43:48.976438 15117 net.cpp:566] ReLU1 -> Convolution1 (in-place)
I0525 23:43:48.976445 15117 net.cpp:240] Setting up ReLU1
I0525 23:43:48.976451 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.976454 15117 net.cpp:255] Memory required for data: 27444400
I0525 23:43:48.976459 15117 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0525 23:43:48.976464 15117 net.cpp:190] Creating Layer Convolution1_ReLU1_0_split
I0525 23:43:48.976469 15117 net.cpp:605] Convolution1_ReLU1_0_split <- Convolution1
I0525 23:43:48.976475 15117 net.cpp:579] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0525 23:43:48.976483 15117 net.cpp:579] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0525 23:43:48.976521 15117 net.cpp:240] Setting up Convolution1_ReLU1_0_split
I0525 23:43:48.976526 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.976531 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.976536 15117 net.cpp:255] Memory required for data: 40551600
I0525 23:43:48.976539 15117 layer_factory.hpp:77] Creating layer Convolution2
I0525 23:43:48.976552 15117 net.cpp:190] Creating Layer Convolution2
I0525 23:43:48.976555 15117 net.cpp:605] Convolution2 <- Convolution1_ReLU1_0_split_0
I0525 23:43:48.976562 15117 net.cpp:579] Convolution2 -> Convolution2
I0525 23:43:48.976879 15117 net.cpp:240] Setting up Convolution2
I0525 23:43:48.976888 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.976892 15117 net.cpp:255] Memory required for data: 47105200
I0525 23:43:48.976907 15117 layer_factory.hpp:77] Creating layer BatchNorm2
I0525 23:43:48.976917 15117 net.cpp:190] Creating Layer BatchNorm2
I0525 23:43:48.976922 15117 net.cpp:605] BatchNorm2 <- Convolution2
I0525 23:43:48.976928 15117 net.cpp:566] BatchNorm2 -> Convolution2 (in-place)
I0525 23:43:48.977141 15117 net.cpp:240] Setting up BatchNorm2
I0525 23:43:48.977152 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.977156 15117 net.cpp:255] Memory required for data: 53658800
I0525 23:43:48.977170 15117 layer_factory.hpp:77] Creating layer Scale2
I0525 23:43:48.977179 15117 net.cpp:190] Creating Layer Scale2
I0525 23:43:48.977183 15117 net.cpp:605] Scale2 <- Convolution2
I0525 23:43:48.977188 15117 net.cpp:566] Scale2 -> Convolution2 (in-place)
I0525 23:43:48.977242 15117 layer_factory.hpp:77] Creating layer Scale2
I0525 23:43:48.977355 15117 net.cpp:240] Setting up Scale2
I0525 23:43:48.977361 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.977365 15117 net.cpp:255] Memory required for data: 60212400
I0525 23:43:48.977378 15117 layer_factory.hpp:77] Creating layer ReLU2
I0525 23:43:48.977387 15117 net.cpp:190] Creating Layer ReLU2
I0525 23:43:48.977391 15117 net.cpp:605] ReLU2 <- Convolution2
I0525 23:43:48.977401 15117 net.cpp:566] ReLU2 -> Convolution2 (in-place)
I0525 23:43:48.977408 15117 net.cpp:240] Setting up ReLU2
I0525 23:43:48.977413 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.977417 15117 net.cpp:255] Memory required for data: 66766000
I0525 23:43:48.977421 15117 layer_factory.hpp:77] Creating layer Convolution3
I0525 23:43:48.977432 15117 net.cpp:190] Creating Layer Convolution3
I0525 23:43:48.977435 15117 net.cpp:605] Convolution3 <- Convolution2
I0525 23:43:48.977443 15117 net.cpp:579] Convolution3 -> Convolution3
I0525 23:43:48.977951 15117 net.cpp:240] Setting up Convolution3
I0525 23:43:48.977967 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.977970 15117 net.cpp:255] Memory required for data: 73319600
I0525 23:43:48.977980 15117 layer_factory.hpp:77] Creating layer BatchNorm3
I0525 23:43:48.977995 15117 net.cpp:190] Creating Layer BatchNorm3
I0525 23:43:48.978027 15117 net.cpp:605] BatchNorm3 <- Convolution3
I0525 23:43:48.978037 15117 net.cpp:566] BatchNorm3 -> Convolution3 (in-place)
I0525 23:43:48.978241 15117 net.cpp:240] Setting up BatchNorm3
I0525 23:43:48.978250 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.978253 15117 net.cpp:255] Memory required for data: 79873200
I0525 23:43:48.978269 15117 layer_factory.hpp:77] Creating layer Scale3
I0525 23:43:48.978281 15117 net.cpp:190] Creating Layer Scale3
I0525 23:43:48.978286 15117 net.cpp:605] Scale3 <- Convolution3
I0525 23:43:48.978292 15117 net.cpp:566] Scale3 -> Convolution3 (in-place)
I0525 23:43:48.978335 15117 layer_factory.hpp:77] Creating layer Scale3
I0525 23:43:48.978457 15117 net.cpp:240] Setting up Scale3
I0525 23:43:48.978466 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.978469 15117 net.cpp:255] Memory required for data: 86426800
I0525 23:43:48.978478 15117 layer_factory.hpp:77] Creating layer Eltwise1
I0525 23:43:48.978487 15117 net.cpp:190] Creating Layer Eltwise1
I0525 23:43:48.978492 15117 net.cpp:605] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0525 23:43:48.978497 15117 net.cpp:605] Eltwise1 <- Convolution3
I0525 23:43:48.978503 15117 net.cpp:579] Eltwise1 -> Eltwise1
I0525 23:43:48.978530 15117 net.cpp:240] Setting up Eltwise1
I0525 23:43:48.978536 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.978540 15117 net.cpp:255] Memory required for data: 92980400
I0525 23:43:48.978543 15117 layer_factory.hpp:77] Creating layer ReLU3
I0525 23:43:48.978552 15117 net.cpp:190] Creating Layer ReLU3
I0525 23:43:48.978556 15117 net.cpp:605] ReLU3 <- Eltwise1
I0525 23:43:48.978562 15117 net.cpp:566] ReLU3 -> Eltwise1 (in-place)
I0525 23:43:48.978569 15117 net.cpp:240] Setting up ReLU3
I0525 23:43:48.978574 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.978576 15117 net.cpp:255] Memory required for data: 99534000
I0525 23:43:48.978580 15117 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0525 23:43:48.978590 15117 net.cpp:190] Creating Layer Eltwise1_ReLU3_0_split
I0525 23:43:48.978593 15117 net.cpp:605] Eltwise1_ReLU3_0_split <- Eltwise1
I0525 23:43:48.978601 15117 net.cpp:579] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0525 23:43:48.978608 15117 net.cpp:579] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0525 23:43:48.978641 15117 net.cpp:240] Setting up Eltwise1_ReLU3_0_split
I0525 23:43:48.978647 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.978653 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.978657 15117 net.cpp:255] Memory required for data: 112641200
I0525 23:43:48.978660 15117 layer_factory.hpp:77] Creating layer Convolution4
I0525 23:43:48.978674 15117 net.cpp:190] Creating Layer Convolution4
I0525 23:43:48.978678 15117 net.cpp:605] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0525 23:43:48.978684 15117 net.cpp:579] Convolution4 -> Convolution4
I0525 23:43:48.979182 15117 net.cpp:240] Setting up Convolution4
I0525 23:43:48.979195 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.979199 15117 net.cpp:255] Memory required for data: 119194800
I0525 23:43:48.979212 15117 layer_factory.hpp:77] Creating layer BatchNorm4
I0525 23:43:48.979223 15117 net.cpp:190] Creating Layer BatchNorm4
I0525 23:43:48.979228 15117 net.cpp:605] BatchNorm4 <- Convolution4
I0525 23:43:48.979234 15117 net.cpp:566] BatchNorm4 -> Convolution4 (in-place)
I0525 23:43:48.979439 15117 net.cpp:240] Setting up BatchNorm4
I0525 23:43:48.979447 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.979451 15117 net.cpp:255] Memory required for data: 125748400
I0525 23:43:48.979465 15117 layer_factory.hpp:77] Creating layer Scale4
I0525 23:43:48.979473 15117 net.cpp:190] Creating Layer Scale4
I0525 23:43:48.979477 15117 net.cpp:605] Scale4 <- Convolution4
I0525 23:43:48.979485 15117 net.cpp:566] Scale4 -> Convolution4 (in-place)
I0525 23:43:48.979529 15117 layer_factory.hpp:77] Creating layer Scale4
I0525 23:43:48.979650 15117 net.cpp:240] Setting up Scale4
I0525 23:43:48.979686 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.979691 15117 net.cpp:255] Memory required for data: 132302000
I0525 23:43:48.979701 15117 layer_factory.hpp:77] Creating layer ReLU4
I0525 23:43:48.979709 15117 net.cpp:190] Creating Layer ReLU4
I0525 23:43:48.979713 15117 net.cpp:605] ReLU4 <- Convolution4
I0525 23:43:48.979719 15117 net.cpp:566] ReLU4 -> Convolution4 (in-place)
I0525 23:43:48.979727 15117 net.cpp:240] Setting up ReLU4
I0525 23:43:48.979732 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.979737 15117 net.cpp:255] Memory required for data: 138855600
I0525 23:43:48.979740 15117 layer_factory.hpp:77] Creating layer Convolution5
I0525 23:43:48.979750 15117 net.cpp:190] Creating Layer Convolution5
I0525 23:43:48.979754 15117 net.cpp:605] Convolution5 <- Convolution4
I0525 23:43:48.979763 15117 net.cpp:579] Convolution5 -> Convolution5
I0525 23:43:48.980093 15117 net.cpp:240] Setting up Convolution5
I0525 23:43:48.980103 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.980106 15117 net.cpp:255] Memory required for data: 145409200
I0525 23:43:48.980114 15117 layer_factory.hpp:77] Creating layer BatchNorm5
I0525 23:43:48.980123 15117 net.cpp:190] Creating Layer BatchNorm5
I0525 23:43:48.980128 15117 net.cpp:605] BatchNorm5 <- Convolution5
I0525 23:43:48.980135 15117 net.cpp:566] BatchNorm5 -> Convolution5 (in-place)
I0525 23:43:48.980326 15117 net.cpp:240] Setting up BatchNorm5
I0525 23:43:48.980334 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.980339 15117 net.cpp:255] Memory required for data: 151962800
I0525 23:43:48.980356 15117 layer_factory.hpp:77] Creating layer Scale5
I0525 23:43:48.980366 15117 net.cpp:190] Creating Layer Scale5
I0525 23:43:48.980371 15117 net.cpp:605] Scale5 <- Convolution5
I0525 23:43:48.980377 15117 net.cpp:566] Scale5 -> Convolution5 (in-place)
I0525 23:43:48.980427 15117 layer_factory.hpp:77] Creating layer Scale5
I0525 23:43:48.982410 15117 net.cpp:240] Setting up Scale5
I0525 23:43:48.982457 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.982461 15117 net.cpp:255] Memory required for data: 158516400
I0525 23:43:48.982481 15117 layer_factory.hpp:77] Creating layer Eltwise2
I0525 23:43:48.982498 15117 net.cpp:190] Creating Layer Eltwise2
I0525 23:43:48.982506 15117 net.cpp:605] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0525 23:43:48.982516 15117 net.cpp:605] Eltwise2 <- Convolution5
I0525 23:43:48.982523 15117 net.cpp:579] Eltwise2 -> Eltwise2
I0525 23:43:48.982612 15117 net.cpp:240] Setting up Eltwise2
I0525 23:43:48.982620 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.982623 15117 net.cpp:255] Memory required for data: 165070000
I0525 23:43:48.982627 15117 layer_factory.hpp:77] Creating layer ReLU5
I0525 23:43:48.982635 15117 net.cpp:190] Creating Layer ReLU5
I0525 23:43:48.982640 15117 net.cpp:605] ReLU5 <- Eltwise2
I0525 23:43:48.982645 15117 net.cpp:566] ReLU5 -> Eltwise2 (in-place)
I0525 23:43:48.982651 15117 net.cpp:240] Setting up ReLU5
I0525 23:43:48.982656 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.982661 15117 net.cpp:255] Memory required for data: 171623600
I0525 23:43:48.982664 15117 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0525 23:43:48.982673 15117 net.cpp:190] Creating Layer Eltwise2_ReLU5_0_split
I0525 23:43:48.982681 15117 net.cpp:605] Eltwise2_ReLU5_0_split <- Eltwise2
I0525 23:43:48.982686 15117 net.cpp:579] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0525 23:43:48.982693 15117 net.cpp:579] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0525 23:43:48.982744 15117 net.cpp:240] Setting up Eltwise2_ReLU5_0_split
I0525 23:43:48.982750 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.982758 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.982760 15117 net.cpp:255] Memory required for data: 184730800
I0525 23:43:48.982764 15117 layer_factory.hpp:77] Creating layer Convolution6
I0525 23:43:48.982784 15117 net.cpp:190] Creating Layer Convolution6
I0525 23:43:48.982817 15117 net.cpp:605] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0525 23:43:48.982827 15117 net.cpp:579] Convolution6 -> Convolution6
I0525 23:43:48.983178 15117 net.cpp:240] Setting up Convolution6
I0525 23:43:48.983188 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.983191 15117 net.cpp:255] Memory required for data: 191284400
I0525 23:43:48.983201 15117 layer_factory.hpp:77] Creating layer BatchNorm6
I0525 23:43:48.983209 15117 net.cpp:190] Creating Layer BatchNorm6
I0525 23:43:48.983214 15117 net.cpp:605] BatchNorm6 <- Convolution6
I0525 23:43:48.983222 15117 net.cpp:566] BatchNorm6 -> Convolution6 (in-place)
I0525 23:43:48.983418 15117 net.cpp:240] Setting up BatchNorm6
I0525 23:43:48.983425 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.983429 15117 net.cpp:255] Memory required for data: 197838000
I0525 23:43:48.983440 15117 layer_factory.hpp:77] Creating layer Scale6
I0525 23:43:48.983448 15117 net.cpp:190] Creating Layer Scale6
I0525 23:43:48.983453 15117 net.cpp:605] Scale6 <- Convolution6
I0525 23:43:48.983458 15117 net.cpp:566] Scale6 -> Convolution6 (in-place)
I0525 23:43:48.983502 15117 layer_factory.hpp:77] Creating layer Scale6
I0525 23:43:48.983615 15117 net.cpp:240] Setting up Scale6
I0525 23:43:48.983623 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.983626 15117 net.cpp:255] Memory required for data: 204391600
I0525 23:43:48.983635 15117 layer_factory.hpp:77] Creating layer ReLU6
I0525 23:43:48.983644 15117 net.cpp:190] Creating Layer ReLU6
I0525 23:43:48.983649 15117 net.cpp:605] ReLU6 <- Convolution6
I0525 23:43:48.983654 15117 net.cpp:566] ReLU6 -> Convolution6 (in-place)
I0525 23:43:48.983660 15117 net.cpp:240] Setting up ReLU6
I0525 23:43:48.983666 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.983669 15117 net.cpp:255] Memory required for data: 210945200
I0525 23:43:48.983674 15117 layer_factory.hpp:77] Creating layer Convolution7
I0525 23:43:48.983686 15117 net.cpp:190] Creating Layer Convolution7
I0525 23:43:48.983690 15117 net.cpp:605] Convolution7 <- Convolution6
I0525 23:43:48.983696 15117 net.cpp:579] Convolution7 -> Convolution7
I0525 23:43:48.984012 15117 net.cpp:240] Setting up Convolution7
I0525 23:43:48.984024 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.984027 15117 net.cpp:255] Memory required for data: 217498800
I0525 23:43:48.984036 15117 layer_factory.hpp:77] Creating layer BatchNorm7
I0525 23:43:48.984052 15117 net.cpp:190] Creating Layer BatchNorm7
I0525 23:43:48.984057 15117 net.cpp:605] BatchNorm7 <- Convolution7
I0525 23:43:48.984064 15117 net.cpp:566] BatchNorm7 -> Convolution7 (in-place)
I0525 23:43:48.984266 15117 net.cpp:240] Setting up BatchNorm7
I0525 23:43:48.984273 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.984277 15117 net.cpp:255] Memory required for data: 224052400
I0525 23:43:48.984288 15117 layer_factory.hpp:77] Creating layer Scale7
I0525 23:43:48.984298 15117 net.cpp:190] Creating Layer Scale7
I0525 23:43:48.984303 15117 net.cpp:605] Scale7 <- Convolution7
I0525 23:43:48.984309 15117 net.cpp:566] Scale7 -> Convolution7 (in-place)
I0525 23:43:48.984354 15117 layer_factory.hpp:77] Creating layer Scale7
I0525 23:43:48.984473 15117 net.cpp:240] Setting up Scale7
I0525 23:43:48.984482 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.984485 15117 net.cpp:255] Memory required for data: 230606000
I0525 23:43:48.984494 15117 layer_factory.hpp:77] Creating layer Eltwise3
I0525 23:43:48.984503 15117 net.cpp:190] Creating Layer Eltwise3
I0525 23:43:48.984508 15117 net.cpp:605] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0525 23:43:48.984516 15117 net.cpp:605] Eltwise3 <- Convolution7
I0525 23:43:48.984522 15117 net.cpp:579] Eltwise3 -> Eltwise3
I0525 23:43:48.984550 15117 net.cpp:240] Setting up Eltwise3
I0525 23:43:48.984556 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.984561 15117 net.cpp:255] Memory required for data: 237159600
I0525 23:43:48.984571 15117 layer_factory.hpp:77] Creating layer ReLU7
I0525 23:43:48.984606 15117 net.cpp:190] Creating Layer ReLU7
I0525 23:43:48.984611 15117 net.cpp:605] ReLU7 <- Eltwise3
I0525 23:43:48.984616 15117 net.cpp:566] ReLU7 -> Eltwise3 (in-place)
I0525 23:43:48.984623 15117 net.cpp:240] Setting up ReLU7
I0525 23:43:48.984628 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.984632 15117 net.cpp:255] Memory required for data: 243713200
I0525 23:43:48.984635 15117 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0525 23:43:48.984645 15117 net.cpp:190] Creating Layer Eltwise3_ReLU7_0_split
I0525 23:43:48.984648 15117 net.cpp:605] Eltwise3_ReLU7_0_split <- Eltwise3
I0525 23:43:48.984654 15117 net.cpp:579] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0525 23:43:48.984660 15117 net.cpp:579] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0525 23:43:48.984697 15117 net.cpp:240] Setting up Eltwise3_ReLU7_0_split
I0525 23:43:48.984704 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.984709 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.984712 15117 net.cpp:255] Memory required for data: 256820400
I0525 23:43:48.984715 15117 layer_factory.hpp:77] Creating layer Convolution8
I0525 23:43:48.984726 15117 net.cpp:190] Creating Layer Convolution8
I0525 23:43:48.984731 15117 net.cpp:605] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0525 23:43:48.984737 15117 net.cpp:579] Convolution8 -> Convolution8
I0525 23:43:48.985054 15117 net.cpp:240] Setting up Convolution8
I0525 23:43:48.985064 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.985066 15117 net.cpp:255] Memory required for data: 263374000
I0525 23:43:48.985075 15117 layer_factory.hpp:77] Creating layer BatchNorm8
I0525 23:43:48.985087 15117 net.cpp:190] Creating Layer BatchNorm8
I0525 23:43:48.985091 15117 net.cpp:605] BatchNorm8 <- Convolution8
I0525 23:43:48.985097 15117 net.cpp:566] BatchNorm8 -> Convolution8 (in-place)
I0525 23:43:48.985294 15117 net.cpp:240] Setting up BatchNorm8
I0525 23:43:48.985302 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.985306 15117 net.cpp:255] Memory required for data: 269927600
I0525 23:43:48.985316 15117 layer_factory.hpp:77] Creating layer Scale8
I0525 23:43:48.985323 15117 net.cpp:190] Creating Layer Scale8
I0525 23:43:48.985328 15117 net.cpp:605] Scale8 <- Convolution8
I0525 23:43:48.985333 15117 net.cpp:566] Scale8 -> Convolution8 (in-place)
I0525 23:43:48.985378 15117 layer_factory.hpp:77] Creating layer Scale8
I0525 23:43:48.985496 15117 net.cpp:240] Setting up Scale8
I0525 23:43:48.985503 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.985507 15117 net.cpp:255] Memory required for data: 276481200
I0525 23:43:48.990393 15117 layer_factory.hpp:77] Creating layer ReLU8
I0525 23:43:48.990437 15117 net.cpp:190] Creating Layer ReLU8
I0525 23:43:48.990447 15117 net.cpp:605] ReLU8 <- Convolution8
I0525 23:43:48.990459 15117 net.cpp:566] ReLU8 -> Convolution8 (in-place)
I0525 23:43:48.990473 15117 net.cpp:240] Setting up ReLU8
I0525 23:43:48.990481 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.990486 15117 net.cpp:255] Memory required for data: 283034800
I0525 23:43:48.990491 15117 layer_factory.hpp:77] Creating layer Convolution9
I0525 23:43:48.990505 15117 net.cpp:190] Creating Layer Convolution9
I0525 23:43:48.990509 15117 net.cpp:605] Convolution9 <- Convolution8
I0525 23:43:48.990520 15117 net.cpp:579] Convolution9 -> Convolution9
I0525 23:43:48.991118 15117 net.cpp:240] Setting up Convolution9
I0525 23:43:48.991135 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.991139 15117 net.cpp:255] Memory required for data: 289588400
I0525 23:43:48.991152 15117 layer_factory.hpp:77] Creating layer BatchNorm9
I0525 23:43:48.991163 15117 net.cpp:190] Creating Layer BatchNorm9
I0525 23:43:48.991168 15117 net.cpp:605] BatchNorm9 <- Convolution9
I0525 23:43:48.991175 15117 net.cpp:566] BatchNorm9 -> Convolution9 (in-place)
I0525 23:43:48.991384 15117 net.cpp:240] Setting up BatchNorm9
I0525 23:43:48.991397 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.991436 15117 net.cpp:255] Memory required for data: 296142000
I0525 23:43:48.991447 15117 layer_factory.hpp:77] Creating layer Scale9
I0525 23:43:48.991456 15117 net.cpp:190] Creating Layer Scale9
I0525 23:43:48.991461 15117 net.cpp:605] Scale9 <- Convolution9
I0525 23:43:48.991466 15117 net.cpp:566] Scale9 -> Convolution9 (in-place)
I0525 23:43:48.991520 15117 layer_factory.hpp:77] Creating layer Scale9
I0525 23:43:48.991636 15117 net.cpp:240] Setting up Scale9
I0525 23:43:48.991644 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.991648 15117 net.cpp:255] Memory required for data: 302695600
I0525 23:43:48.991657 15117 layer_factory.hpp:77] Creating layer Eltwise4
I0525 23:43:48.991667 15117 net.cpp:190] Creating Layer Eltwise4
I0525 23:43:48.991673 15117 net.cpp:605] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0525 23:43:48.991679 15117 net.cpp:605] Eltwise4 <- Convolution9
I0525 23:43:48.991684 15117 net.cpp:579] Eltwise4 -> Eltwise4
I0525 23:43:48.991713 15117 net.cpp:240] Setting up Eltwise4
I0525 23:43:48.991719 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.991722 15117 net.cpp:255] Memory required for data: 309249200
I0525 23:43:48.991726 15117 layer_factory.hpp:77] Creating layer ReLU9
I0525 23:43:48.991732 15117 net.cpp:190] Creating Layer ReLU9
I0525 23:43:48.991736 15117 net.cpp:605] ReLU9 <- Eltwise4
I0525 23:43:48.991744 15117 net.cpp:566] ReLU9 -> Eltwise4 (in-place)
I0525 23:43:48.991750 15117 net.cpp:240] Setting up ReLU9
I0525 23:43:48.991755 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.991758 15117 net.cpp:255] Memory required for data: 315802800
I0525 23:43:48.991762 15117 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0525 23:43:48.991768 15117 net.cpp:190] Creating Layer Eltwise4_ReLU9_0_split
I0525 23:43:48.991772 15117 net.cpp:605] Eltwise4_ReLU9_0_split <- Eltwise4
I0525 23:43:48.991776 15117 net.cpp:579] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0525 23:43:48.991782 15117 net.cpp:579] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0525 23:43:48.991818 15117 net.cpp:240] Setting up Eltwise4_ReLU9_0_split
I0525 23:43:48.991824 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.991829 15117 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:43:48.991832 15117 net.cpp:255] Memory required for data: 328910000
I0525 23:43:48.991837 15117 layer_factory.hpp:77] Creating layer Pooling1
I0525 23:43:48.991845 15117 net.cpp:190] Creating Layer Pooling1
I0525 23:43:48.991850 15117 net.cpp:605] Pooling1 <- Eltwise4_ReLU9_0_split_0
I0525 23:43:48.991855 15117 net.cpp:579] Pooling1 -> Pooling1
I0525 23:43:48.991879 15117 net.cpp:240] Setting up Pooling1
I0525 23:43:48.991885 15117 net.cpp:247] Top shape: 100 16 16 16 (409600)
I0525 23:43:48.991888 15117 net.cpp:255] Memory required for data: 330548400
I0525 23:43:48.991892 15117 layer_factory.hpp:77] Creating layer Input1
I0525 23:43:48.991901 15117 net.cpp:190] Creating Layer Input1
I0525 23:43:48.991909 15117 net.cpp:579] Input1 -> Input1
I0525 23:43:48.991935 15117 net.cpp:240] Setting up Input1
I0525 23:43:48.991951 15117 net.cpp:247] Top shape: 100 16 16 16 (409600)
I0525 23:43:48.991955 15117 net.cpp:255] Memory required for data: 332186800
I0525 23:43:48.991960 15117 layer_factory.hpp:77] Creating layer Concat1
I0525 23:43:48.991967 15117 net.cpp:190] Creating Layer Concat1
I0525 23:43:48.991971 15117 net.cpp:605] Concat1 <- Pooling1
I0525 23:43:48.991976 15117 net.cpp:605] Concat1 <- Input1
I0525 23:43:48.991982 15117 net.cpp:579] Concat1 -> Concat1
I0525 23:43:48.992009 15117 net.cpp:240] Setting up Concat1
I0525 23:43:48.992017 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.992020 15117 net.cpp:255] Memory required for data: 335463600
I0525 23:43:48.992023 15117 layer_factory.hpp:77] Creating layer Convolution10
I0525 23:43:48.992036 15117 net.cpp:190] Creating Layer Convolution10
I0525 23:43:48.992040 15117 net.cpp:605] Convolution10 <- Eltwise4_ReLU9_0_split_1
I0525 23:43:48.992065 15117 net.cpp:579] Convolution10 -> Convolution10
I0525 23:43:48.992487 15117 net.cpp:240] Setting up Convolution10
I0525 23:43:48.992498 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.992502 15117 net.cpp:255] Memory required for data: 338740400
I0525 23:43:48.992532 15117 layer_factory.hpp:77] Creating layer BatchNorm10
I0525 23:43:48.992542 15117 net.cpp:190] Creating Layer BatchNorm10
I0525 23:43:48.992547 15117 net.cpp:605] BatchNorm10 <- Convolution10
I0525 23:43:48.992563 15117 net.cpp:566] BatchNorm10 -> Convolution10 (in-place)
I0525 23:43:48.992760 15117 net.cpp:240] Setting up BatchNorm10
I0525 23:43:48.992769 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.992772 15117 net.cpp:255] Memory required for data: 342017200
I0525 23:43:48.992782 15117 layer_factory.hpp:77] Creating layer Scale10
I0525 23:43:48.992790 15117 net.cpp:190] Creating Layer Scale10
I0525 23:43:48.992795 15117 net.cpp:605] Scale10 <- Convolution10
I0525 23:43:48.992800 15117 net.cpp:566] Scale10 -> Convolution10 (in-place)
I0525 23:43:48.992846 15117 layer_factory.hpp:77] Creating layer Scale10
I0525 23:43:48.992962 15117 net.cpp:240] Setting up Scale10
I0525 23:43:48.992970 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.992974 15117 net.cpp:255] Memory required for data: 345294000
I0525 23:43:48.992982 15117 layer_factory.hpp:77] Creating layer ReLU10
I0525 23:43:48.992992 15117 net.cpp:190] Creating Layer ReLU10
I0525 23:43:48.992997 15117 net.cpp:605] ReLU10 <- Convolution10
I0525 23:43:48.993002 15117 net.cpp:566] ReLU10 -> Convolution10 (in-place)
I0525 23:43:48.993010 15117 net.cpp:240] Setting up ReLU10
I0525 23:43:48.993015 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.993018 15117 net.cpp:255] Memory required for data: 348570800
I0525 23:43:48.993021 15117 layer_factory.hpp:77] Creating layer Convolution11
I0525 23:43:48.993037 15117 net.cpp:190] Creating Layer Convolution11
I0525 23:43:48.993042 15117 net.cpp:605] Convolution11 <- Convolution10
I0525 23:43:48.993051 15117 net.cpp:579] Convolution11 -> Convolution11
I0525 23:43:48.993618 15117 net.cpp:240] Setting up Convolution11
I0525 23:43:48.993633 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.993636 15117 net.cpp:255] Memory required for data: 351847600
I0525 23:43:48.993646 15117 layer_factory.hpp:77] Creating layer BatchNorm11
I0525 23:43:48.993657 15117 net.cpp:190] Creating Layer BatchNorm11
I0525 23:43:48.993662 15117 net.cpp:605] BatchNorm11 <- Convolution11
I0525 23:43:48.993669 15117 net.cpp:566] BatchNorm11 -> Convolution11 (in-place)
I0525 23:43:48.993855 15117 net.cpp:240] Setting up BatchNorm11
I0525 23:43:48.993863 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.993866 15117 net.cpp:255] Memory required for data: 355124400
I0525 23:43:48.993877 15117 layer_factory.hpp:77] Creating layer Scale11
I0525 23:43:48.993885 15117 net.cpp:190] Creating Layer Scale11
I0525 23:43:48.993890 15117 net.cpp:605] Scale11 <- Convolution11
I0525 23:43:48.993897 15117 net.cpp:566] Scale11 -> Convolution11 (in-place)
I0525 23:43:48.993938 15117 layer_factory.hpp:77] Creating layer Scale11
I0525 23:43:48.994052 15117 net.cpp:240] Setting up Scale11
I0525 23:43:48.994060 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.994065 15117 net.cpp:255] Memory required for data: 358401200
I0525 23:43:48.994072 15117 layer_factory.hpp:77] Creating layer Eltwise5
I0525 23:43:48.994081 15117 net.cpp:190] Creating Layer Eltwise5
I0525 23:43:48.994086 15117 net.cpp:605] Eltwise5 <- Concat1
I0525 23:43:48.994091 15117 net.cpp:605] Eltwise5 <- Convolution11
I0525 23:43:48.994101 15117 net.cpp:579] Eltwise5 -> Eltwise5
I0525 23:43:48.994129 15117 net.cpp:240] Setting up Eltwise5
I0525 23:43:48.994138 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.994143 15117 net.cpp:255] Memory required for data: 361678000
I0525 23:43:48.994146 15117 layer_factory.hpp:77] Creating layer ReLU11
I0525 23:43:48.994158 15117 net.cpp:190] Creating Layer ReLU11
I0525 23:43:48.994194 15117 net.cpp:605] ReLU11 <- Eltwise5
I0525 23:43:48.994199 15117 net.cpp:566] ReLU11 -> Eltwise5 (in-place)
I0525 23:43:48.994206 15117 net.cpp:240] Setting up ReLU11
I0525 23:43:48.994212 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.994216 15117 net.cpp:255] Memory required for data: 364954800
I0525 23:43:48.994220 15117 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0525 23:43:48.994226 15117 net.cpp:190] Creating Layer Eltwise5_ReLU11_0_split
I0525 23:43:48.994230 15117 net.cpp:605] Eltwise5_ReLU11_0_split <- Eltwise5
I0525 23:43:48.994238 15117 net.cpp:579] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0525 23:43:48.994246 15117 net.cpp:579] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0525 23:43:48.994282 15117 net.cpp:240] Setting up Eltwise5_ReLU11_0_split
I0525 23:43:48.994287 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.994292 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.994295 15117 net.cpp:255] Memory required for data: 371508400
I0525 23:43:48.994299 15117 layer_factory.hpp:77] Creating layer Convolution12
I0525 23:43:48.994313 15117 net.cpp:190] Creating Layer Convolution12
I0525 23:43:48.994318 15117 net.cpp:605] Convolution12 <- Eltwise5_ReLU11_0_split_0
I0525 23:43:48.994323 15117 net.cpp:579] Convolution12 -> Convolution12
I0525 23:43:48.994913 15117 net.cpp:240] Setting up Convolution12
I0525 23:43:48.994928 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.994932 15117 net.cpp:255] Memory required for data: 374785200
I0525 23:43:48.994943 15117 layer_factory.hpp:77] Creating layer BatchNorm12
I0525 23:43:48.994953 15117 net.cpp:190] Creating Layer BatchNorm12
I0525 23:43:48.994958 15117 net.cpp:605] BatchNorm12 <- Convolution12
I0525 23:43:48.994963 15117 net.cpp:566] BatchNorm12 -> Convolution12 (in-place)
I0525 23:43:48.995157 15117 net.cpp:240] Setting up BatchNorm12
I0525 23:43:48.995164 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.995169 15117 net.cpp:255] Memory required for data: 378062000
I0525 23:43:48.995182 15117 layer_factory.hpp:77] Creating layer Scale12
I0525 23:43:48.995189 15117 net.cpp:190] Creating Layer Scale12
I0525 23:43:48.995193 15117 net.cpp:605] Scale12 <- Convolution12
I0525 23:43:48.995199 15117 net.cpp:566] Scale12 -> Convolution12 (in-place)
I0525 23:43:48.995244 15117 layer_factory.hpp:77] Creating layer Scale12
I0525 23:43:48.995363 15117 net.cpp:240] Setting up Scale12
I0525 23:43:48.995370 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.995374 15117 net.cpp:255] Memory required for data: 381338800
I0525 23:43:48.995384 15117 layer_factory.hpp:77] Creating layer ReLU12
I0525 23:43:48.995393 15117 net.cpp:190] Creating Layer ReLU12
I0525 23:43:48.995396 15117 net.cpp:605] ReLU12 <- Convolution12
I0525 23:43:48.995404 15117 net.cpp:566] ReLU12 -> Convolution12 (in-place)
I0525 23:43:48.995411 15117 net.cpp:240] Setting up ReLU12
I0525 23:43:48.995416 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.995420 15117 net.cpp:255] Memory required for data: 384615600
I0525 23:43:48.995424 15117 layer_factory.hpp:77] Creating layer Convolution13
I0525 23:43:48.995446 15117 net.cpp:190] Creating Layer Convolution13
I0525 23:43:48.995451 15117 net.cpp:605] Convolution13 <- Convolution12
I0525 23:43:48.995457 15117 net.cpp:579] Convolution13 -> Convolution13
I0525 23:43:48.996019 15117 net.cpp:240] Setting up Convolution13
I0525 23:43:48.996032 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.996037 15117 net.cpp:255] Memory required for data: 387892400
I0525 23:43:48.996047 15117 layer_factory.hpp:77] Creating layer BatchNorm13
I0525 23:43:48.996057 15117 net.cpp:190] Creating Layer BatchNorm13
I0525 23:43:48.996062 15117 net.cpp:605] BatchNorm13 <- Convolution13
I0525 23:43:48.996069 15117 net.cpp:566] BatchNorm13 -> Convolution13 (in-place)
I0525 23:43:48.998392 15117 net.cpp:240] Setting up BatchNorm13
I0525 23:43:48.998440 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.998482 15117 net.cpp:255] Memory required for data: 391169200
I0525 23:43:48.998508 15117 layer_factory.hpp:77] Creating layer Scale13
I0525 23:43:48.998527 15117 net.cpp:190] Creating Layer Scale13
I0525 23:43:48.998533 15117 net.cpp:605] Scale13 <- Convolution13
I0525 23:43:48.998541 15117 net.cpp:566] Scale13 -> Convolution13 (in-place)
I0525 23:43:48.998656 15117 layer_factory.hpp:77] Creating layer Scale13
I0525 23:43:48.998795 15117 net.cpp:240] Setting up Scale13
I0525 23:43:48.998802 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.998810 15117 net.cpp:255] Memory required for data: 394446000
I0525 23:43:48.998817 15117 layer_factory.hpp:77] Creating layer Eltwise6
I0525 23:43:48.998826 15117 net.cpp:190] Creating Layer Eltwise6
I0525 23:43:48.998832 15117 net.cpp:605] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0525 23:43:48.998849 15117 net.cpp:605] Eltwise6 <- Convolution13
I0525 23:43:48.998857 15117 net.cpp:579] Eltwise6 -> Eltwise6
I0525 23:43:48.998880 15117 net.cpp:240] Setting up Eltwise6
I0525 23:43:48.998889 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.998893 15117 net.cpp:255] Memory required for data: 397722800
I0525 23:43:48.998896 15117 layer_factory.hpp:77] Creating layer ReLU13
I0525 23:43:48.998904 15117 net.cpp:190] Creating Layer ReLU13
I0525 23:43:48.998908 15117 net.cpp:605] ReLU13 <- Eltwise6
I0525 23:43:48.998914 15117 net.cpp:566] ReLU13 -> Eltwise6 (in-place)
I0525 23:43:48.998919 15117 net.cpp:240] Setting up ReLU13
I0525 23:43:48.998924 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.998929 15117 net.cpp:255] Memory required for data: 400999600
I0525 23:43:48.998931 15117 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0525 23:43:48.998939 15117 net.cpp:190] Creating Layer Eltwise6_ReLU13_0_split
I0525 23:43:48.998942 15117 net.cpp:605] Eltwise6_ReLU13_0_split <- Eltwise6
I0525 23:43:48.998950 15117 net.cpp:579] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0525 23:43:48.998956 15117 net.cpp:579] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0525 23:43:48.998991 15117 net.cpp:240] Setting up Eltwise6_ReLU13_0_split
I0525 23:43:48.998998 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.999003 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.999007 15117 net.cpp:255] Memory required for data: 407553200
I0525 23:43:48.999011 15117 layer_factory.hpp:77] Creating layer Convolution14
I0525 23:43:48.999022 15117 net.cpp:190] Creating Layer Convolution14
I0525 23:43:48.999025 15117 net.cpp:605] Convolution14 <- Eltwise6_ReLU13_0_split_0
I0525 23:43:48.999032 15117 net.cpp:579] Convolution14 -> Convolution14
I0525 23:43:48.999665 15117 net.cpp:240] Setting up Convolution14
I0525 23:43:48.999682 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.999686 15117 net.cpp:255] Memory required for data: 410830000
I0525 23:43:48.999696 15117 layer_factory.hpp:77] Creating layer BatchNorm14
I0525 23:43:48.999708 15117 net.cpp:190] Creating Layer BatchNorm14
I0525 23:43:48.999714 15117 net.cpp:605] BatchNorm14 <- Convolution14
I0525 23:43:48.999721 15117 net.cpp:566] BatchNorm14 -> Convolution14 (in-place)
I0525 23:43:48.999917 15117 net.cpp:240] Setting up BatchNorm14
I0525 23:43:48.999923 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:48.999927 15117 net.cpp:255] Memory required for data: 414106800
I0525 23:43:48.999938 15117 layer_factory.hpp:77] Creating layer Scale14
I0525 23:43:48.999946 15117 net.cpp:190] Creating Layer Scale14
I0525 23:43:48.999951 15117 net.cpp:605] Scale14 <- Convolution14
I0525 23:43:48.999958 15117 net.cpp:566] Scale14 -> Convolution14 (in-place)
I0525 23:43:49.000005 15117 layer_factory.hpp:77] Creating layer Scale14
I0525 23:43:49.000125 15117 net.cpp:240] Setting up Scale14
I0525 23:43:49.000134 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.000138 15117 net.cpp:255] Memory required for data: 417383600
I0525 23:43:49.000155 15117 layer_factory.hpp:77] Creating layer ReLU14
I0525 23:43:49.000193 15117 net.cpp:190] Creating Layer ReLU14
I0525 23:43:49.000198 15117 net.cpp:605] ReLU14 <- Convolution14
I0525 23:43:49.000205 15117 net.cpp:566] ReLU14 -> Convolution14 (in-place)
I0525 23:43:49.000212 15117 net.cpp:240] Setting up ReLU14
I0525 23:43:49.000218 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.000221 15117 net.cpp:255] Memory required for data: 420660400
I0525 23:43:49.000226 15117 layer_factory.hpp:77] Creating layer Convolution15
I0525 23:43:49.000237 15117 net.cpp:190] Creating Layer Convolution15
I0525 23:43:49.000242 15117 net.cpp:605] Convolution15 <- Convolution14
I0525 23:43:49.000249 15117 net.cpp:579] Convolution15 -> Convolution15
I0525 23:43:49.000814 15117 net.cpp:240] Setting up Convolution15
I0525 23:43:49.000829 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.000833 15117 net.cpp:255] Memory required for data: 423937200
I0525 23:43:49.000843 15117 layer_factory.hpp:77] Creating layer BatchNorm15
I0525 23:43:49.000851 15117 net.cpp:190] Creating Layer BatchNorm15
I0525 23:43:49.000856 15117 net.cpp:605] BatchNorm15 <- Convolution15
I0525 23:43:49.000864 15117 net.cpp:566] BatchNorm15 -> Convolution15 (in-place)
I0525 23:43:49.001075 15117 net.cpp:240] Setting up BatchNorm15
I0525 23:43:49.001085 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.001088 15117 net.cpp:255] Memory required for data: 427214000
I0525 23:43:49.001099 15117 layer_factory.hpp:77] Creating layer Scale15
I0525 23:43:49.001107 15117 net.cpp:190] Creating Layer Scale15
I0525 23:43:49.001112 15117 net.cpp:605] Scale15 <- Convolution15
I0525 23:43:49.001117 15117 net.cpp:566] Scale15 -> Convolution15 (in-place)
I0525 23:43:49.001165 15117 layer_factory.hpp:77] Creating layer Scale15
I0525 23:43:49.001278 15117 net.cpp:240] Setting up Scale15
I0525 23:43:49.001286 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.001289 15117 net.cpp:255] Memory required for data: 430490800
I0525 23:43:49.001298 15117 layer_factory.hpp:77] Creating layer Eltwise7
I0525 23:43:49.001309 15117 net.cpp:190] Creating Layer Eltwise7
I0525 23:43:49.001315 15117 net.cpp:605] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0525 23:43:49.001322 15117 net.cpp:605] Eltwise7 <- Convolution15
I0525 23:43:49.001327 15117 net.cpp:579] Eltwise7 -> Eltwise7
I0525 23:43:49.001348 15117 net.cpp:240] Setting up Eltwise7
I0525 23:43:49.001355 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.001358 15117 net.cpp:255] Memory required for data: 433767600
I0525 23:43:49.001363 15117 layer_factory.hpp:77] Creating layer ReLU15
I0525 23:43:49.001373 15117 net.cpp:190] Creating Layer ReLU15
I0525 23:43:49.001376 15117 net.cpp:605] ReLU15 <- Eltwise7
I0525 23:43:49.001382 15117 net.cpp:566] ReLU15 -> Eltwise7 (in-place)
I0525 23:43:49.001389 15117 net.cpp:240] Setting up ReLU15
I0525 23:43:49.001394 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.001399 15117 net.cpp:255] Memory required for data: 437044400
I0525 23:43:49.001401 15117 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0525 23:43:49.001408 15117 net.cpp:190] Creating Layer Eltwise7_ReLU15_0_split
I0525 23:43:49.001412 15117 net.cpp:605] Eltwise7_ReLU15_0_split <- Eltwise7
I0525 23:43:49.001417 15117 net.cpp:579] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0525 23:43:49.001425 15117 net.cpp:579] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0525 23:43:49.001461 15117 net.cpp:240] Setting up Eltwise7_ReLU15_0_split
I0525 23:43:49.001467 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.001472 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.001477 15117 net.cpp:255] Memory required for data: 443598000
I0525 23:43:49.001480 15117 layer_factory.hpp:77] Creating layer Convolution16
I0525 23:43:49.001494 15117 net.cpp:190] Creating Layer Convolution16
I0525 23:43:49.001499 15117 net.cpp:605] Convolution16 <- Eltwise7_ReLU15_0_split_0
I0525 23:43:49.001507 15117 net.cpp:579] Convolution16 -> Convolution16
I0525 23:43:49.002120 15117 net.cpp:240] Setting up Convolution16
I0525 23:43:49.002136 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.002140 15117 net.cpp:255] Memory required for data: 446874800
I0525 23:43:49.002151 15117 layer_factory.hpp:77] Creating layer BatchNorm16
I0525 23:43:49.002388 15117 net.cpp:190] Creating Layer BatchNorm16
I0525 23:43:49.002400 15117 net.cpp:605] BatchNorm16 <- Convolution16
I0525 23:43:49.002413 15117 net.cpp:566] BatchNorm16 -> Convolution16 (in-place)
I0525 23:43:49.002629 15117 net.cpp:240] Setting up BatchNorm16
I0525 23:43:49.002638 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.002642 15117 net.cpp:255] Memory required for data: 450151600
I0525 23:43:49.002655 15117 layer_factory.hpp:77] Creating layer Scale16
I0525 23:43:49.002665 15117 net.cpp:190] Creating Layer Scale16
I0525 23:43:49.002670 15117 net.cpp:605] Scale16 <- Convolution16
I0525 23:43:49.002674 15117 net.cpp:566] Scale16 -> Convolution16 (in-place)
I0525 23:43:49.002720 15117 layer_factory.hpp:77] Creating layer Scale16
I0525 23:43:49.002836 15117 net.cpp:240] Setting up Scale16
I0525 23:43:49.002845 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.002848 15117 net.cpp:255] Memory required for data: 453428400
I0525 23:43:49.002856 15117 layer_factory.hpp:77] Creating layer ReLU16
I0525 23:43:49.002864 15117 net.cpp:190] Creating Layer ReLU16
I0525 23:43:49.002868 15117 net.cpp:605] ReLU16 <- Convolution16
I0525 23:43:49.002876 15117 net.cpp:566] ReLU16 -> Convolution16 (in-place)
I0525 23:43:49.002883 15117 net.cpp:240] Setting up ReLU16
I0525 23:43:49.002889 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.002892 15117 net.cpp:255] Memory required for data: 456705200
I0525 23:43:49.002897 15117 layer_factory.hpp:77] Creating layer Convolution17
I0525 23:43:49.002912 15117 net.cpp:190] Creating Layer Convolution17
I0525 23:43:49.002918 15117 net.cpp:605] Convolution17 <- Convolution16
I0525 23:43:49.002923 15117 net.cpp:579] Convolution17 -> Convolution17
I0525 23:43:49.003530 15117 net.cpp:240] Setting up Convolution17
I0525 23:43:49.003550 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.003553 15117 net.cpp:255] Memory required for data: 459982000
I0525 23:43:49.003564 15117 layer_factory.hpp:77] Creating layer BatchNorm17
I0525 23:43:49.003576 15117 net.cpp:190] Creating Layer BatchNorm17
I0525 23:43:49.003582 15117 net.cpp:605] BatchNorm17 <- Convolution17
I0525 23:43:49.003587 15117 net.cpp:566] BatchNorm17 -> Convolution17 (in-place)
I0525 23:43:49.003787 15117 net.cpp:240] Setting up BatchNorm17
I0525 23:43:49.003795 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.003799 15117 net.cpp:255] Memory required for data: 463258800
I0525 23:43:49.003813 15117 layer_factory.hpp:77] Creating layer Scale17
I0525 23:43:49.003820 15117 net.cpp:190] Creating Layer Scale17
I0525 23:43:49.003824 15117 net.cpp:605] Scale17 <- Convolution17
I0525 23:43:49.003830 15117 net.cpp:566] Scale17 -> Convolution17 (in-place)
I0525 23:43:49.004336 15117 layer_factory.hpp:77] Creating layer Scale17
I0525 23:43:49.004503 15117 net.cpp:240] Setting up Scale17
I0525 23:43:49.004515 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.004519 15117 net.cpp:255] Memory required for data: 466535600
I0525 23:43:49.004534 15117 layer_factory.hpp:77] Creating layer Eltwise8
I0525 23:43:49.004544 15117 net.cpp:190] Creating Layer Eltwise8
I0525 23:43:49.004551 15117 net.cpp:605] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0525 23:43:49.004557 15117 net.cpp:605] Eltwise8 <- Convolution17
I0525 23:43:49.004566 15117 net.cpp:579] Eltwise8 -> Eltwise8
I0525 23:43:49.004590 15117 net.cpp:240] Setting up Eltwise8
I0525 23:43:49.004595 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.004600 15117 net.cpp:255] Memory required for data: 469812400
I0525 23:43:49.004602 15117 layer_factory.hpp:77] Creating layer ReLU17
I0525 23:43:49.004611 15117 net.cpp:190] Creating Layer ReLU17
I0525 23:43:49.004621 15117 net.cpp:605] ReLU17 <- Eltwise8
I0525 23:43:49.004662 15117 net.cpp:566] ReLU17 -> Eltwise8 (in-place)
I0525 23:43:49.004669 15117 net.cpp:240] Setting up ReLU17
I0525 23:43:49.004674 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.004678 15117 net.cpp:255] Memory required for data: 473089200
I0525 23:43:49.004683 15117 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0525 23:43:49.004688 15117 net.cpp:190] Creating Layer Eltwise8_ReLU17_0_split
I0525 23:43:49.004693 15117 net.cpp:605] Eltwise8_ReLU17_0_split <- Eltwise8
I0525 23:43:49.004698 15117 net.cpp:579] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0525 23:43:49.004704 15117 net.cpp:579] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0525 23:43:49.004745 15117 net.cpp:240] Setting up Eltwise8_ReLU17_0_split
I0525 23:43:49.004752 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.004757 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.004760 15117 net.cpp:255] Memory required for data: 479642800
I0525 23:43:49.004765 15117 layer_factory.hpp:77] Creating layer Convolution18
I0525 23:43:49.004776 15117 net.cpp:190] Creating Layer Convolution18
I0525 23:43:49.004781 15117 net.cpp:605] Convolution18 <- Eltwise8_ReLU17_0_split_0
I0525 23:43:49.004789 15117 net.cpp:579] Convolution18 -> Convolution18
I0525 23:43:49.006227 15117 net.cpp:240] Setting up Convolution18
I0525 23:43:49.006269 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.006273 15117 net.cpp:255] Memory required for data: 482919600
I0525 23:43:49.006289 15117 layer_factory.hpp:77] Creating layer BatchNorm18
I0525 23:43:49.006306 15117 net.cpp:190] Creating Layer BatchNorm18
I0525 23:43:49.006314 15117 net.cpp:605] BatchNorm18 <- Convolution18
I0525 23:43:49.006325 15117 net.cpp:566] BatchNorm18 -> Convolution18 (in-place)
I0525 23:43:49.006525 15117 net.cpp:240] Setting up BatchNorm18
I0525 23:43:49.006534 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.006538 15117 net.cpp:255] Memory required for data: 486196400
I0525 23:43:49.006548 15117 layer_factory.hpp:77] Creating layer Scale18
I0525 23:43:49.006557 15117 net.cpp:190] Creating Layer Scale18
I0525 23:43:49.006562 15117 net.cpp:605] Scale18 <- Convolution18
I0525 23:43:49.006572 15117 net.cpp:566] Scale18 -> Convolution18 (in-place)
I0525 23:43:49.006615 15117 layer_factory.hpp:77] Creating layer Scale18
I0525 23:43:49.006736 15117 net.cpp:240] Setting up Scale18
I0525 23:43:49.006743 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.006747 15117 net.cpp:255] Memory required for data: 489473200
I0525 23:43:49.006757 15117 layer_factory.hpp:77] Creating layer ReLU18
I0525 23:43:49.006763 15117 net.cpp:190] Creating Layer ReLU18
I0525 23:43:49.006768 15117 net.cpp:605] ReLU18 <- Convolution18
I0525 23:43:49.006777 15117 net.cpp:566] ReLU18 -> Convolution18 (in-place)
I0525 23:43:49.006783 15117 net.cpp:240] Setting up ReLU18
I0525 23:43:49.006789 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.006793 15117 net.cpp:255] Memory required for data: 492750000
I0525 23:43:49.006796 15117 layer_factory.hpp:77] Creating layer Convolution19
I0525 23:43:49.006810 15117 net.cpp:190] Creating Layer Convolution19
I0525 23:43:49.006815 15117 net.cpp:605] Convolution19 <- Convolution18
I0525 23:43:49.006821 15117 net.cpp:579] Convolution19 -> Convolution19
I0525 23:43:49.007381 15117 net.cpp:240] Setting up Convolution19
I0525 23:43:49.007397 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.007401 15117 net.cpp:255] Memory required for data: 496026800
I0525 23:43:49.007411 15117 layer_factory.hpp:77] Creating layer BatchNorm19
I0525 23:43:49.007424 15117 net.cpp:190] Creating Layer BatchNorm19
I0525 23:43:49.007429 15117 net.cpp:605] BatchNorm19 <- Convolution19
I0525 23:43:49.007434 15117 net.cpp:566] BatchNorm19 -> Convolution19 (in-place)
I0525 23:43:49.007613 15117 net.cpp:240] Setting up BatchNorm19
I0525 23:43:49.007622 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.007632 15117 net.cpp:255] Memory required for data: 499303600
I0525 23:43:49.007704 15117 layer_factory.hpp:77] Creating layer Scale19
I0525 23:43:49.007714 15117 net.cpp:190] Creating Layer Scale19
I0525 23:43:49.007717 15117 net.cpp:605] Scale19 <- Convolution19
I0525 23:43:49.007725 15117 net.cpp:566] Scale19 -> Convolution19 (in-place)
I0525 23:43:49.007773 15117 layer_factory.hpp:77] Creating layer Scale19
I0525 23:43:49.007889 15117 net.cpp:240] Setting up Scale19
I0525 23:43:49.007896 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.007899 15117 net.cpp:255] Memory required for data: 502580400
I0525 23:43:49.007907 15117 layer_factory.hpp:77] Creating layer Eltwise9
I0525 23:43:49.007916 15117 net.cpp:190] Creating Layer Eltwise9
I0525 23:43:49.007922 15117 net.cpp:605] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0525 23:43:49.007930 15117 net.cpp:605] Eltwise9 <- Convolution19
I0525 23:43:49.007936 15117 net.cpp:579] Eltwise9 -> Eltwise9
I0525 23:43:49.007956 15117 net.cpp:240] Setting up Eltwise9
I0525 23:43:49.007966 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.007968 15117 net.cpp:255] Memory required for data: 505857200
I0525 23:43:49.007972 15117 layer_factory.hpp:77] Creating layer ReLU19
I0525 23:43:49.007979 15117 net.cpp:190] Creating Layer ReLU19
I0525 23:43:49.007983 15117 net.cpp:605] ReLU19 <- Eltwise9
I0525 23:43:49.007988 15117 net.cpp:566] ReLU19 -> Eltwise9 (in-place)
I0525 23:43:49.007995 15117 net.cpp:240] Setting up ReLU19
I0525 23:43:49.008000 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.008004 15117 net.cpp:255] Memory required for data: 509134000
I0525 23:43:49.008008 15117 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0525 23:43:49.008013 15117 net.cpp:190] Creating Layer Eltwise9_ReLU19_0_split
I0525 23:43:49.008018 15117 net.cpp:605] Eltwise9_ReLU19_0_split <- Eltwise9
I0525 23:43:49.008028 15117 net.cpp:579] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0525 23:43:49.008035 15117 net.cpp:579] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0525 23:43:49.008070 15117 net.cpp:240] Setting up Eltwise9_ReLU19_0_split
I0525 23:43:49.008076 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.008081 15117 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:43:49.008085 15117 net.cpp:255] Memory required for data: 515687600
I0525 23:43:49.008090 15117 layer_factory.hpp:77] Creating layer Pooling2
I0525 23:43:49.008100 15117 net.cpp:190] Creating Layer Pooling2
I0525 23:43:49.008103 15117 net.cpp:605] Pooling2 <- Eltwise9_ReLU19_0_split_0
I0525 23:43:49.008108 15117 net.cpp:579] Pooling2 -> Pooling2
I0525 23:43:49.008132 15117 net.cpp:240] Setting up Pooling2
I0525 23:43:49.008138 15117 net.cpp:247] Top shape: 100 32 8 8 (204800)
I0525 23:43:49.008141 15117 net.cpp:255] Memory required for data: 516506800
I0525 23:43:49.008146 15117 layer_factory.hpp:77] Creating layer Input2
I0525 23:43:49.008154 15117 net.cpp:190] Creating Layer Input2
I0525 23:43:49.008162 15117 net.cpp:579] Input2 -> Input2
I0525 23:43:49.008186 15117 net.cpp:240] Setting up Input2
I0525 23:43:49.008193 15117 net.cpp:247] Top shape: 100 32 8 8 (204800)
I0525 23:43:49.008196 15117 net.cpp:255] Memory required for data: 517326000
I0525 23:43:49.008200 15117 layer_factory.hpp:77] Creating layer Concat2
I0525 23:43:49.008208 15117 net.cpp:190] Creating Layer Concat2
I0525 23:43:49.008213 15117 net.cpp:605] Concat2 <- Pooling2
I0525 23:43:49.008218 15117 net.cpp:605] Concat2 <- Input2
I0525 23:43:49.008225 15117 net.cpp:579] Concat2 -> Concat2
I0525 23:43:49.008249 15117 net.cpp:240] Setting up Concat2
I0525 23:43:49.008257 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.008261 15117 net.cpp:255] Memory required for data: 518964400
I0525 23:43:49.008265 15117 layer_factory.hpp:77] Creating layer Convolution20
I0525 23:43:49.008276 15117 net.cpp:190] Creating Layer Convolution20
I0525 23:43:49.008281 15117 net.cpp:605] Convolution20 <- Eltwise9_ReLU19_0_split_1
I0525 23:43:49.008291 15117 net.cpp:579] Convolution20 -> Convolution20
I0525 23:43:49.009238 15117 net.cpp:240] Setting up Convolution20
I0525 23:43:49.009268 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.009271 15117 net.cpp:255] Memory required for data: 520602800
I0525 23:43:49.009285 15117 layer_factory.hpp:77] Creating layer BatchNorm20
I0525 23:43:49.009300 15117 net.cpp:190] Creating Layer BatchNorm20
I0525 23:43:49.009307 15117 net.cpp:605] BatchNorm20 <- Convolution20
I0525 23:43:49.009315 15117 net.cpp:566] BatchNorm20 -> Convolution20 (in-place)
I0525 23:43:49.009517 15117 net.cpp:240] Setting up BatchNorm20
I0525 23:43:49.009524 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.009529 15117 net.cpp:255] Memory required for data: 522241200
I0525 23:43:49.009541 15117 layer_factory.hpp:77] Creating layer Scale20
I0525 23:43:49.009552 15117 net.cpp:190] Creating Layer Scale20
I0525 23:43:49.009557 15117 net.cpp:605] Scale20 <- Convolution20
I0525 23:43:49.009562 15117 net.cpp:566] Scale20 -> Convolution20 (in-place)
I0525 23:43:49.009613 15117 layer_factory.hpp:77] Creating layer Scale20
I0525 23:43:49.009732 15117 net.cpp:240] Setting up Scale20
I0525 23:43:49.009739 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.009742 15117 net.cpp:255] Memory required for data: 523879600
I0525 23:43:49.009752 15117 layer_factory.hpp:77] Creating layer ReLU20
I0525 23:43:49.009762 15117 net.cpp:190] Creating Layer ReLU20
I0525 23:43:49.009766 15117 net.cpp:605] ReLU20 <- Convolution20
I0525 23:43:49.009771 15117 net.cpp:566] ReLU20 -> Convolution20 (in-place)
I0525 23:43:49.009778 15117 net.cpp:240] Setting up ReLU20
I0525 23:43:49.009785 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.009789 15117 net.cpp:255] Memory required for data: 525518000
I0525 23:43:49.009793 15117 layer_factory.hpp:77] Creating layer Convolution21
I0525 23:43:49.009805 15117 net.cpp:190] Creating Layer Convolution21
I0525 23:43:49.009810 15117 net.cpp:605] Convolution21 <- Convolution20
I0525 23:43:49.009819 15117 net.cpp:579] Convolution21 -> Convolution21
I0525 23:43:49.012624 15117 net.cpp:240] Setting up Convolution21
I0525 23:43:49.012665 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.012670 15117 net.cpp:255] Memory required for data: 527156400
I0525 23:43:49.012688 15117 layer_factory.hpp:77] Creating layer BatchNorm21
I0525 23:43:49.012703 15117 net.cpp:190] Creating Layer BatchNorm21
I0525 23:43:49.012712 15117 net.cpp:605] BatchNorm21 <- Convolution21
I0525 23:43:49.012723 15117 net.cpp:566] BatchNorm21 -> Convolution21 (in-place)
I0525 23:43:49.012936 15117 net.cpp:240] Setting up BatchNorm21
I0525 23:43:49.012944 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.012948 15117 net.cpp:255] Memory required for data: 528794800
I0525 23:43:49.012959 15117 layer_factory.hpp:77] Creating layer Scale21
I0525 23:43:49.012969 15117 net.cpp:190] Creating Layer Scale21
I0525 23:43:49.012972 15117 net.cpp:605] Scale21 <- Convolution21
I0525 23:43:49.012980 15117 net.cpp:566] Scale21 -> Convolution21 (in-place)
I0525 23:43:49.013028 15117 layer_factory.hpp:77] Creating layer Scale21
I0525 23:43:49.013151 15117 net.cpp:240] Setting up Scale21
I0525 23:43:49.013159 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.013164 15117 net.cpp:255] Memory required for data: 530433200
I0525 23:43:49.013172 15117 layer_factory.hpp:77] Creating layer Eltwise10
I0525 23:43:49.013183 15117 net.cpp:190] Creating Layer Eltwise10
I0525 23:43:49.013188 15117 net.cpp:605] Eltwise10 <- Concat2
I0525 23:43:49.013193 15117 net.cpp:605] Eltwise10 <- Convolution21
I0525 23:43:49.013200 15117 net.cpp:579] Eltwise10 -> Eltwise10
I0525 23:43:49.013228 15117 net.cpp:240] Setting up Eltwise10
I0525 23:43:49.013234 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.013237 15117 net.cpp:255] Memory required for data: 532071600
I0525 23:43:49.013242 15117 layer_factory.hpp:77] Creating layer ReLU21
I0525 23:43:49.013248 15117 net.cpp:190] Creating Layer ReLU21
I0525 23:43:49.013252 15117 net.cpp:605] ReLU21 <- Eltwise10
I0525 23:43:49.013295 15117 net.cpp:566] ReLU21 -> Eltwise10 (in-place)
I0525 23:43:49.013303 15117 net.cpp:240] Setting up ReLU21
I0525 23:43:49.013309 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.013312 15117 net.cpp:255] Memory required for data: 533710000
I0525 23:43:49.013317 15117 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0525 23:43:49.013324 15117 net.cpp:190] Creating Layer Eltwise10_ReLU21_0_split
I0525 23:43:49.013327 15117 net.cpp:605] Eltwise10_ReLU21_0_split <- Eltwise10
I0525 23:43:49.013332 15117 net.cpp:579] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0525 23:43:49.013339 15117 net.cpp:579] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0525 23:43:49.013376 15117 net.cpp:240] Setting up Eltwise10_ReLU21_0_split
I0525 23:43:49.013382 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.013387 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.013391 15117 net.cpp:255] Memory required for data: 536986800
I0525 23:43:49.013394 15117 layer_factory.hpp:77] Creating layer Convolution22
I0525 23:43:49.013406 15117 net.cpp:190] Creating Layer Convolution22
I0525 23:43:49.013411 15117 net.cpp:605] Convolution22 <- Eltwise10_ReLU21_0_split_0
I0525 23:43:49.013419 15117 net.cpp:579] Convolution22 -> Convolution22
I0525 23:43:49.015121 15117 net.cpp:240] Setting up Convolution22
I0525 23:43:49.015162 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.015167 15117 net.cpp:255] Memory required for data: 538625200
I0525 23:43:49.015184 15117 layer_factory.hpp:77] Creating layer BatchNorm22
I0525 23:43:49.015199 15117 net.cpp:190] Creating Layer BatchNorm22
I0525 23:43:49.015208 15117 net.cpp:605] BatchNorm22 <- Convolution22
I0525 23:43:49.015219 15117 net.cpp:566] BatchNorm22 -> Convolution22 (in-place)
I0525 23:43:49.015429 15117 net.cpp:240] Setting up BatchNorm22
I0525 23:43:49.015435 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.015439 15117 net.cpp:255] Memory required for data: 540263600
I0525 23:43:49.015450 15117 layer_factory.hpp:77] Creating layer Scale22
I0525 23:43:49.015460 15117 net.cpp:190] Creating Layer Scale22
I0525 23:43:49.015463 15117 net.cpp:605] Scale22 <- Convolution22
I0525 23:43:49.015471 15117 net.cpp:566] Scale22 -> Convolution22 (in-place)
I0525 23:43:49.015518 15117 layer_factory.hpp:77] Creating layer Scale22
I0525 23:43:49.015638 15117 net.cpp:240] Setting up Scale22
I0525 23:43:49.015645 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.015650 15117 net.cpp:255] Memory required for data: 541902000
I0525 23:43:49.015658 15117 layer_factory.hpp:77] Creating layer ReLU22
I0525 23:43:49.015666 15117 net.cpp:190] Creating Layer ReLU22
I0525 23:43:49.015671 15117 net.cpp:605] ReLU22 <- Convolution22
I0525 23:43:49.015678 15117 net.cpp:566] ReLU22 -> Convolution22 (in-place)
I0525 23:43:49.015715 15117 net.cpp:240] Setting up ReLU22
I0525 23:43:49.015722 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.015727 15117 net.cpp:255] Memory required for data: 543540400
I0525 23:43:49.015730 15117 layer_factory.hpp:77] Creating layer Convolution23
I0525 23:43:49.015745 15117 net.cpp:190] Creating Layer Convolution23
I0525 23:43:49.015749 15117 net.cpp:605] Convolution23 <- Convolution22
I0525 23:43:49.015756 15117 net.cpp:579] Convolution23 -> Convolution23
I0525 23:43:49.017426 15117 net.cpp:240] Setting up Convolution23
I0525 23:43:49.017462 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.017467 15117 net.cpp:255] Memory required for data: 545178800
I0525 23:43:49.017482 15117 layer_factory.hpp:77] Creating layer BatchNorm23
I0525 23:43:49.017508 15117 net.cpp:190] Creating Layer BatchNorm23
I0525 23:43:49.017516 15117 net.cpp:605] BatchNorm23 <- Convolution23
I0525 23:43:49.017524 15117 net.cpp:566] BatchNorm23 -> Convolution23 (in-place)
I0525 23:43:49.017722 15117 net.cpp:240] Setting up BatchNorm23
I0525 23:43:49.017729 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.017734 15117 net.cpp:255] Memory required for data: 546817200
I0525 23:43:49.017783 15117 layer_factory.hpp:77] Creating layer Scale23
I0525 23:43:49.017796 15117 net.cpp:190] Creating Layer Scale23
I0525 23:43:49.017801 15117 net.cpp:605] Scale23 <- Convolution23
I0525 23:43:49.017807 15117 net.cpp:566] Scale23 -> Convolution23 (in-place)
I0525 23:43:49.017887 15117 layer_factory.hpp:77] Creating layer Scale23
I0525 23:43:49.018015 15117 net.cpp:240] Setting up Scale23
I0525 23:43:49.018023 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.018028 15117 net.cpp:255] Memory required for data: 548455600
I0525 23:43:49.018038 15117 layer_factory.hpp:77] Creating layer Eltwise11
I0525 23:43:49.018049 15117 net.cpp:190] Creating Layer Eltwise11
I0525 23:43:49.018054 15117 net.cpp:605] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0525 23:43:49.018059 15117 net.cpp:605] Eltwise11 <- Convolution23
I0525 23:43:49.018067 15117 net.cpp:579] Eltwise11 -> Eltwise11
I0525 23:43:49.018093 15117 net.cpp:240] Setting up Eltwise11
I0525 23:43:49.018100 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.018103 15117 net.cpp:255] Memory required for data: 550094000
I0525 23:43:49.018107 15117 layer_factory.hpp:77] Creating layer ReLU23
I0525 23:43:49.018116 15117 net.cpp:190] Creating Layer ReLU23
I0525 23:43:49.018121 15117 net.cpp:605] ReLU23 <- Eltwise11
I0525 23:43:49.018156 15117 net.cpp:566] ReLU23 -> Eltwise11 (in-place)
I0525 23:43:49.018163 15117 net.cpp:240] Setting up ReLU23
I0525 23:43:49.018169 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.018172 15117 net.cpp:255] Memory required for data: 551732400
I0525 23:43:49.018177 15117 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0525 23:43:49.018183 15117 net.cpp:190] Creating Layer Eltwise11_ReLU23_0_split
I0525 23:43:49.018187 15117 net.cpp:605] Eltwise11_ReLU23_0_split <- Eltwise11
I0525 23:43:49.018193 15117 net.cpp:579] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0525 23:43:49.018198 15117 net.cpp:579] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0525 23:43:49.018235 15117 net.cpp:240] Setting up Eltwise11_ReLU23_0_split
I0525 23:43:49.018241 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.018246 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.018250 15117 net.cpp:255] Memory required for data: 555009200
I0525 23:43:49.018254 15117 layer_factory.hpp:77] Creating layer Convolution24
I0525 23:43:49.018267 15117 net.cpp:190] Creating Layer Convolution24
I0525 23:43:49.018271 15117 net.cpp:605] Convolution24 <- Eltwise11_ReLU23_0_split_0
I0525 23:43:49.018278 15117 net.cpp:579] Convolution24 -> Convolution24
I0525 23:43:49.020773 15117 net.cpp:240] Setting up Convolution24
I0525 23:43:49.020823 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.020828 15117 net.cpp:255] Memory required for data: 556647600
I0525 23:43:49.020845 15117 layer_factory.hpp:77] Creating layer BatchNorm24
I0525 23:43:49.020862 15117 net.cpp:190] Creating Layer BatchNorm24
I0525 23:43:49.020870 15117 net.cpp:605] BatchNorm24 <- Convolution24
I0525 23:43:49.020879 15117 net.cpp:566] BatchNorm24 -> Convolution24 (in-place)
I0525 23:43:49.021124 15117 net.cpp:240] Setting up BatchNorm24
I0525 23:43:49.021134 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.021138 15117 net.cpp:255] Memory required for data: 558286000
I0525 23:43:49.021150 15117 layer_factory.hpp:77] Creating layer Scale24
I0525 23:43:49.021160 15117 net.cpp:190] Creating Layer Scale24
I0525 23:43:49.021164 15117 net.cpp:605] Scale24 <- Convolution24
I0525 23:43:49.021170 15117 net.cpp:566] Scale24 -> Convolution24 (in-place)
I0525 23:43:49.021229 15117 layer_factory.hpp:77] Creating layer Scale24
I0525 23:43:49.021363 15117 net.cpp:240] Setting up Scale24
I0525 23:43:49.021370 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.021374 15117 net.cpp:255] Memory required for data: 559924400
I0525 23:43:49.021384 15117 layer_factory.hpp:77] Creating layer ReLU24
I0525 23:43:49.021392 15117 net.cpp:190] Creating Layer ReLU24
I0525 23:43:49.021402 15117 net.cpp:605] ReLU24 <- Convolution24
I0525 23:43:49.021440 15117 net.cpp:566] ReLU24 -> Convolution24 (in-place)
I0525 23:43:49.021448 15117 net.cpp:240] Setting up ReLU24
I0525 23:43:49.021453 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.021457 15117 net.cpp:255] Memory required for data: 561562800
I0525 23:43:49.021461 15117 layer_factory.hpp:77] Creating layer Convolution25
I0525 23:43:49.021476 15117 net.cpp:190] Creating Layer Convolution25
I0525 23:43:49.021481 15117 net.cpp:605] Convolution25 <- Convolution24
I0525 23:43:49.021488 15117 net.cpp:579] Convolution25 -> Convolution25
I0525 23:43:49.023178 15117 net.cpp:240] Setting up Convolution25
I0525 23:43:49.023217 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.023222 15117 net.cpp:255] Memory required for data: 563201200
I0525 23:43:49.023241 15117 layer_factory.hpp:77] Creating layer BatchNorm25
I0525 23:43:49.023282 15117 net.cpp:190] Creating Layer BatchNorm25
I0525 23:43:49.023291 15117 net.cpp:605] BatchNorm25 <- Convolution25
I0525 23:43:49.023300 15117 net.cpp:566] BatchNorm25 -> Convolution25 (in-place)
I0525 23:43:49.023502 15117 net.cpp:240] Setting up BatchNorm25
I0525 23:43:49.023510 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.023514 15117 net.cpp:255] Memory required for data: 564839600
I0525 23:43:49.023526 15117 layer_factory.hpp:77] Creating layer Scale25
I0525 23:43:49.023537 15117 net.cpp:190] Creating Layer Scale25
I0525 23:43:49.023541 15117 net.cpp:605] Scale25 <- Convolution25
I0525 23:43:49.023547 15117 net.cpp:566] Scale25 -> Convolution25 (in-place)
I0525 23:43:49.023597 15117 layer_factory.hpp:77] Creating layer Scale25
I0525 23:43:49.023718 15117 net.cpp:240] Setting up Scale25
I0525 23:43:49.023726 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.023730 15117 net.cpp:255] Memory required for data: 566478000
I0525 23:43:49.023738 15117 layer_factory.hpp:77] Creating layer Eltwise12
I0525 23:43:49.023748 15117 net.cpp:190] Creating Layer Eltwise12
I0525 23:43:49.023754 15117 net.cpp:605] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0525 23:43:49.023761 15117 net.cpp:605] Eltwise12 <- Convolution25
I0525 23:43:49.023768 15117 net.cpp:579] Eltwise12 -> Eltwise12
I0525 23:43:49.023793 15117 net.cpp:240] Setting up Eltwise12
I0525 23:43:49.023799 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.023803 15117 net.cpp:255] Memory required for data: 568116400
I0525 23:43:49.023808 15117 layer_factory.hpp:77] Creating layer ReLU25
I0525 23:43:49.023818 15117 net.cpp:190] Creating Layer ReLU25
I0525 23:43:49.023821 15117 net.cpp:605] ReLU25 <- Eltwise12
I0525 23:43:49.023826 15117 net.cpp:566] ReLU25 -> Eltwise12 (in-place)
I0525 23:43:49.023833 15117 net.cpp:240] Setting up ReLU25
I0525 23:43:49.023838 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.023843 15117 net.cpp:255] Memory required for data: 569754800
I0525 23:43:49.023846 15117 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I0525 23:43:49.023854 15117 net.cpp:190] Creating Layer Eltwise12_ReLU25_0_split
I0525 23:43:49.023857 15117 net.cpp:605] Eltwise12_ReLU25_0_split <- Eltwise12
I0525 23:43:49.023862 15117 net.cpp:579] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I0525 23:43:49.023869 15117 net.cpp:579] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I0525 23:43:49.023908 15117 net.cpp:240] Setting up Eltwise12_ReLU25_0_split
I0525 23:43:49.023916 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.023921 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.023923 15117 net.cpp:255] Memory required for data: 573031600
I0525 23:43:49.023927 15117 layer_factory.hpp:77] Creating layer Convolution26
I0525 23:43:49.023942 15117 net.cpp:190] Creating Layer Convolution26
I0525 23:43:49.023947 15117 net.cpp:605] Convolution26 <- Eltwise12_ReLU25_0_split_0
I0525 23:43:49.023954 15117 net.cpp:579] Convolution26 -> Convolution26
I0525 23:43:49.026698 15117 net.cpp:240] Setting up Convolution26
I0525 23:43:49.026744 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.026779 15117 net.cpp:255] Memory required for data: 574670000
I0525 23:43:49.026795 15117 layer_factory.hpp:77] Creating layer BatchNorm26
I0525 23:43:49.026823 15117 net.cpp:190] Creating Layer BatchNorm26
I0525 23:43:49.026830 15117 net.cpp:605] BatchNorm26 <- Convolution26
I0525 23:43:49.026841 15117 net.cpp:566] BatchNorm26 -> Convolution26 (in-place)
I0525 23:43:49.027043 15117 net.cpp:240] Setting up BatchNorm26
I0525 23:43:49.027051 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.027055 15117 net.cpp:255] Memory required for data: 576308400
I0525 23:43:49.027065 15117 layer_factory.hpp:77] Creating layer Scale26
I0525 23:43:49.027076 15117 net.cpp:190] Creating Layer Scale26
I0525 23:43:49.027081 15117 net.cpp:605] Scale26 <- Convolution26
I0525 23:43:49.027086 15117 net.cpp:566] Scale26 -> Convolution26 (in-place)
I0525 23:43:49.027137 15117 layer_factory.hpp:77] Creating layer Scale26
I0525 23:43:49.027254 15117 net.cpp:240] Setting up Scale26
I0525 23:43:49.027261 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.027266 15117 net.cpp:255] Memory required for data: 577946800
I0525 23:43:49.027274 15117 layer_factory.hpp:77] Creating layer ReLU26
I0525 23:43:49.027281 15117 net.cpp:190] Creating Layer ReLU26
I0525 23:43:49.027287 15117 net.cpp:605] ReLU26 <- Convolution26
I0525 23:43:49.027294 15117 net.cpp:566] ReLU26 -> Convolution26 (in-place)
I0525 23:43:49.027302 15117 net.cpp:240] Setting up ReLU26
I0525 23:43:49.027307 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.027310 15117 net.cpp:255] Memory required for data: 579585200
I0525 23:43:49.027314 15117 layer_factory.hpp:77] Creating layer Convolution27
I0525 23:43:49.027325 15117 net.cpp:190] Creating Layer Convolution27
I0525 23:43:49.027330 15117 net.cpp:605] Convolution27 <- Convolution26
I0525 23:43:49.027338 15117 net.cpp:579] Convolution27 -> Convolution27
I0525 23:43:49.029021 15117 net.cpp:240] Setting up Convolution27
I0525 23:43:49.029057 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.029062 15117 net.cpp:255] Memory required for data: 581223600
I0525 23:43:49.029078 15117 layer_factory.hpp:77] Creating layer BatchNorm27
I0525 23:43:49.029093 15117 net.cpp:190] Creating Layer BatchNorm27
I0525 23:43:49.029101 15117 net.cpp:605] BatchNorm27 <- Convolution27
I0525 23:43:49.029110 15117 net.cpp:566] BatchNorm27 -> Convolution27 (in-place)
I0525 23:43:49.029316 15117 net.cpp:240] Setting up BatchNorm27
I0525 23:43:49.029325 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.029328 15117 net.cpp:255] Memory required for data: 582862000
I0525 23:43:49.029340 15117 layer_factory.hpp:77] Creating layer Scale27
I0525 23:43:49.029351 15117 net.cpp:190] Creating Layer Scale27
I0525 23:43:49.029356 15117 net.cpp:605] Scale27 <- Convolution27
I0525 23:43:49.029361 15117 net.cpp:566] Scale27 -> Convolution27 (in-place)
I0525 23:43:49.029413 15117 layer_factory.hpp:77] Creating layer Scale27
I0525 23:43:49.029532 15117 net.cpp:240] Setting up Scale27
I0525 23:43:49.029539 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.029543 15117 net.cpp:255] Memory required for data: 584500400
I0525 23:43:49.029597 15117 layer_factory.hpp:77] Creating layer Eltwise13
I0525 23:43:49.029609 15117 net.cpp:190] Creating Layer Eltwise13
I0525 23:43:49.029616 15117 net.cpp:605] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I0525 23:43:49.029623 15117 net.cpp:605] Eltwise13 <- Convolution27
I0525 23:43:49.029631 15117 net.cpp:579] Eltwise13 -> Eltwise13
I0525 23:43:49.029667 15117 net.cpp:240] Setting up Eltwise13
I0525 23:43:49.029673 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.029677 15117 net.cpp:255] Memory required for data: 586138800
I0525 23:43:49.029681 15117 layer_factory.hpp:77] Creating layer ReLU27
I0525 23:43:49.029692 15117 net.cpp:190] Creating Layer ReLU27
I0525 23:43:49.029697 15117 net.cpp:605] ReLU27 <- Eltwise13
I0525 23:43:49.029702 15117 net.cpp:566] ReLU27 -> Eltwise13 (in-place)
I0525 23:43:49.029716 15117 net.cpp:240] Setting up ReLU27
I0525 23:43:49.029750 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.029754 15117 net.cpp:255] Memory required for data: 587777200
I0525 23:43:49.029758 15117 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I0525 23:43:49.029765 15117 net.cpp:190] Creating Layer Eltwise13_ReLU27_0_split
I0525 23:43:49.029769 15117 net.cpp:605] Eltwise13_ReLU27_0_split <- Eltwise13
I0525 23:43:49.029774 15117 net.cpp:579] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I0525 23:43:49.029781 15117 net.cpp:579] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I0525 23:43:49.029820 15117 net.cpp:240] Setting up Eltwise13_ReLU27_0_split
I0525 23:43:49.029827 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.029831 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.029835 15117 net.cpp:255] Memory required for data: 591054000
I0525 23:43:49.029839 15117 layer_factory.hpp:77] Creating layer Convolution28
I0525 23:43:49.029850 15117 net.cpp:190] Creating Layer Convolution28
I0525 23:43:49.029855 15117 net.cpp:605] Convolution28 <- Eltwise13_ReLU27_0_split_0
I0525 23:43:49.029865 15117 net.cpp:579] Convolution28 -> Convolution28
I0525 23:43:49.031507 15117 net.cpp:240] Setting up Convolution28
I0525 23:43:49.031543 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.031548 15117 net.cpp:255] Memory required for data: 592692400
I0525 23:43:49.031563 15117 layer_factory.hpp:77] Creating layer BatchNorm28
I0525 23:43:49.031580 15117 net.cpp:190] Creating Layer BatchNorm28
I0525 23:43:49.031589 15117 net.cpp:605] BatchNorm28 <- Convolution28
I0525 23:43:49.031596 15117 net.cpp:566] BatchNorm28 -> Convolution28 (in-place)
I0525 23:43:49.031831 15117 net.cpp:240] Setting up BatchNorm28
I0525 23:43:49.031841 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.031844 15117 net.cpp:255] Memory required for data: 594330800
I0525 23:43:49.031857 15117 layer_factory.hpp:77] Creating layer Scale28
I0525 23:43:49.031872 15117 net.cpp:190] Creating Layer Scale28
I0525 23:43:49.031877 15117 net.cpp:605] Scale28 <- Convolution28
I0525 23:43:49.031883 15117 net.cpp:566] Scale28 -> Convolution28 (in-place)
I0525 23:43:49.031934 15117 layer_factory.hpp:77] Creating layer Scale28
I0525 23:43:49.032052 15117 net.cpp:240] Setting up Scale28
I0525 23:43:49.032061 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.032064 15117 net.cpp:255] Memory required for data: 595969200
I0525 23:43:49.032075 15117 layer_factory.hpp:77] Creating layer ReLU28
I0525 23:43:49.032083 15117 net.cpp:190] Creating Layer ReLU28
I0525 23:43:49.032088 15117 net.cpp:605] ReLU28 <- Convolution28
I0525 23:43:49.032093 15117 net.cpp:566] ReLU28 -> Convolution28 (in-place)
I0525 23:43:49.032099 15117 net.cpp:240] Setting up ReLU28
I0525 23:43:49.032104 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.032109 15117 net.cpp:255] Memory required for data: 597607600
I0525 23:43:49.032112 15117 layer_factory.hpp:77] Creating layer Convolution29
I0525 23:43:49.032126 15117 net.cpp:190] Creating Layer Convolution29
I0525 23:43:49.032131 15117 net.cpp:605] Convolution29 <- Convolution28
I0525 23:43:49.032140 15117 net.cpp:579] Convolution29 -> Convolution29
I0525 23:43:49.033769 15117 net.cpp:240] Setting up Convolution29
I0525 23:43:49.033804 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.033809 15117 net.cpp:255] Memory required for data: 599246000
I0525 23:43:49.033825 15117 layer_factory.hpp:77] Creating layer BatchNorm29
I0525 23:43:49.033864 15117 net.cpp:190] Creating Layer BatchNorm29
I0525 23:43:49.033871 15117 net.cpp:605] BatchNorm29 <- Convolution29
I0525 23:43:49.033884 15117 net.cpp:566] BatchNorm29 -> Convolution29 (in-place)
I0525 23:43:49.034101 15117 net.cpp:240] Setting up BatchNorm29
I0525 23:43:49.034111 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.034114 15117 net.cpp:255] Memory required for data: 600884400
I0525 23:43:49.034132 15117 layer_factory.hpp:77] Creating layer Scale29
I0525 23:43:49.034173 15117 net.cpp:190] Creating Layer Scale29
I0525 23:43:49.034178 15117 net.cpp:605] Scale29 <- Convolution29
I0525 23:43:49.034186 15117 net.cpp:566] Scale29 -> Convolution29 (in-place)
I0525 23:43:49.034237 15117 layer_factory.hpp:77] Creating layer Scale29
I0525 23:43:49.034364 15117 net.cpp:240] Setting up Scale29
I0525 23:43:49.034373 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.034376 15117 net.cpp:255] Memory required for data: 602522800
I0525 23:43:49.034385 15117 layer_factory.hpp:77] Creating layer Eltwise14
I0525 23:43:49.034396 15117 net.cpp:190] Creating Layer Eltwise14
I0525 23:43:49.034402 15117 net.cpp:605] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I0525 23:43:49.034409 15117 net.cpp:605] Eltwise14 <- Convolution29
I0525 23:43:49.034415 15117 net.cpp:579] Eltwise14 -> Eltwise14
I0525 23:43:49.034442 15117 net.cpp:240] Setting up Eltwise14
I0525 23:43:49.034449 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.034452 15117 net.cpp:255] Memory required for data: 604161200
I0525 23:43:49.034456 15117 layer_factory.hpp:77] Creating layer ReLU29
I0525 23:43:49.034463 15117 net.cpp:190] Creating Layer ReLU29
I0525 23:43:49.034468 15117 net.cpp:605] ReLU29 <- Eltwise14
I0525 23:43:49.034481 15117 net.cpp:566] ReLU29 -> Eltwise14 (in-place)
I0525 23:43:49.034487 15117 net.cpp:240] Setting up ReLU29
I0525 23:43:49.034492 15117 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:43:49.034497 15117 net.cpp:255] Memory required for data: 605799600
I0525 23:43:49.034499 15117 layer_factory.hpp:77] Creating layer Pooling3
I0525 23:43:49.034508 15117 net.cpp:190] Creating Layer Pooling3
I0525 23:43:49.034512 15117 net.cpp:605] Pooling3 <- Eltwise14
I0525 23:43:49.034518 15117 net.cpp:579] Pooling3 -> Pooling3
I0525 23:43:49.034543 15117 net.cpp:240] Setting up Pooling3
I0525 23:43:49.034550 15117 net.cpp:247] Top shape: 100 64 1 1 (6400)
I0525 23:43:49.034554 15117 net.cpp:255] Memory required for data: 605825200
I0525 23:43:49.034557 15117 layer_factory.hpp:77] Creating layer InnerProduct1
I0525 23:43:49.034569 15117 net.cpp:190] Creating Layer InnerProduct1
I0525 23:43:49.034574 15117 net.cpp:605] InnerProduct1 <- Pooling3
I0525 23:43:49.034579 15117 net.cpp:579] InnerProduct1 -> InnerProduct1
I0525 23:43:49.034742 15117 net.cpp:240] Setting up InnerProduct1
I0525 23:43:49.034751 15117 net.cpp:247] Top shape: 100 10 (1000)
I0525 23:43:49.034755 15117 net.cpp:255] Memory required for data: 605829200
I0525 23:43:49.034765 15117 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0525 23:43:49.034773 15117 net.cpp:190] Creating Layer InnerProduct1_InnerProduct1_0_split
I0525 23:43:49.034777 15117 net.cpp:605] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0525 23:43:49.034783 15117 net.cpp:579] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0525 23:43:49.034790 15117 net.cpp:579] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0525 23:43:49.034827 15117 net.cpp:240] Setting up InnerProduct1_InnerProduct1_0_split
I0525 23:43:49.034834 15117 net.cpp:247] Top shape: 100 10 (1000)
I0525 23:43:49.034838 15117 net.cpp:247] Top shape: 100 10 (1000)
I0525 23:43:49.034842 15117 net.cpp:255] Memory required for data: 605837200
I0525 23:43:49.034847 15117 layer_factory.hpp:77] Creating layer Accuracy
I0525 23:43:49.034854 15117 net.cpp:190] Creating Layer Accuracy
I0525 23:43:49.034858 15117 net.cpp:605] Accuracy <- InnerProduct1_InnerProduct1_0_split_0
I0525 23:43:49.034863 15117 net.cpp:605] Accuracy <- Data2_Data1_1_split_0
I0525 23:43:49.034873 15117 net.cpp:579] Accuracy -> Accuracy
I0525 23:43:49.034890 15117 net.cpp:240] Setting up Accuracy
I0525 23:43:49.034919 15117 net.cpp:247] Top shape: (1)
I0525 23:43:49.034924 15117 net.cpp:255] Memory required for data: 605837204
I0525 23:43:49.034929 15117 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0525 23:43:49.034935 15117 net.cpp:190] Creating Layer SoftmaxWithLoss1
I0525 23:43:49.034945 15117 net.cpp:605] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_1
I0525 23:43:49.034967 15117 net.cpp:605] SoftmaxWithLoss1 <- Data2_Data1_1_split_1
I0525 23:43:49.034975 15117 net.cpp:579] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0525 23:43:49.034984 15117 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0525 23:43:49.035084 15117 net.cpp:240] Setting up SoftmaxWithLoss1
I0525 23:43:49.035092 15117 net.cpp:247] Top shape: (1)
I0525 23:43:49.035096 15117 net.cpp:250]     with loss weight 1
I0525 23:43:49.035110 15117 net.cpp:255] Memory required for data: 605837208
I0525 23:43:49.035115 15117 net.cpp:316] SoftmaxWithLoss1 needs backward computation.
I0525 23:43:49.035120 15117 net.cpp:318] Accuracy does not need backward computation.
I0525 23:43:49.035123 15117 net.cpp:316] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0525 23:43:49.035127 15117 net.cpp:316] InnerProduct1 needs backward computation.
I0525 23:43:49.035131 15117 net.cpp:316] Pooling3 needs backward computation.
I0525 23:43:49.035135 15117 net.cpp:316] ReLU29 needs backward computation.
I0525 23:43:49.035138 15117 net.cpp:316] Eltwise14 needs backward computation.
I0525 23:43:49.035143 15117 net.cpp:316] Scale29 needs backward computation.
I0525 23:43:49.035146 15117 net.cpp:316] BatchNorm29 needs backward computation.
I0525 23:43:49.035151 15117 net.cpp:316] Convolution29 needs backward computation.
I0525 23:43:49.035154 15117 net.cpp:316] ReLU28 needs backward computation.
I0525 23:43:49.035158 15117 net.cpp:316] Scale28 needs backward computation.
I0525 23:43:49.035162 15117 net.cpp:316] BatchNorm28 needs backward computation.
I0525 23:43:49.035166 15117 net.cpp:316] Convolution28 needs backward computation.
I0525 23:43:49.035171 15117 net.cpp:316] Eltwise13_ReLU27_0_split needs backward computation.
I0525 23:43:49.035174 15117 net.cpp:316] ReLU27 needs backward computation.
I0525 23:43:49.035178 15117 net.cpp:316] Eltwise13 needs backward computation.
I0525 23:43:49.035183 15117 net.cpp:316] Scale27 needs backward computation.
I0525 23:43:49.035187 15117 net.cpp:316] BatchNorm27 needs backward computation.
I0525 23:43:49.035190 15117 net.cpp:316] Convolution27 needs backward computation.
I0525 23:43:49.035194 15117 net.cpp:316] ReLU26 needs backward computation.
I0525 23:43:49.035198 15117 net.cpp:316] Scale26 needs backward computation.
I0525 23:43:49.035202 15117 net.cpp:316] BatchNorm26 needs backward computation.
I0525 23:43:49.035207 15117 net.cpp:316] Convolution26 needs backward computation.
I0525 23:43:49.035212 15117 net.cpp:316] Eltwise12_ReLU25_0_split needs backward computation.
I0525 23:43:49.035215 15117 net.cpp:316] ReLU25 needs backward computation.
I0525 23:43:49.035219 15117 net.cpp:316] Eltwise12 needs backward computation.
I0525 23:43:49.035224 15117 net.cpp:316] Scale25 needs backward computation.
I0525 23:43:49.035228 15117 net.cpp:316] BatchNorm25 needs backward computation.
I0525 23:43:49.035231 15117 net.cpp:316] Convolution25 needs backward computation.
I0525 23:43:49.035235 15117 net.cpp:316] ReLU24 needs backward computation.
I0525 23:43:49.035239 15117 net.cpp:316] Scale24 needs backward computation.
I0525 23:43:49.035243 15117 net.cpp:316] BatchNorm24 needs backward computation.
I0525 23:43:49.035248 15117 net.cpp:316] Convolution24 needs backward computation.
I0525 23:43:49.035251 15117 net.cpp:316] Eltwise11_ReLU23_0_split needs backward computation.
I0525 23:43:49.035255 15117 net.cpp:316] ReLU23 needs backward computation.
I0525 23:43:49.035259 15117 net.cpp:316] Eltwise11 needs backward computation.
I0525 23:43:49.035264 15117 net.cpp:316] Scale23 needs backward computation.
I0525 23:43:49.035269 15117 net.cpp:316] BatchNorm23 needs backward computation.
I0525 23:43:49.035272 15117 net.cpp:316] Convolution23 needs backward computation.
I0525 23:43:49.035276 15117 net.cpp:316] ReLU22 needs backward computation.
I0525 23:43:49.035280 15117 net.cpp:316] Scale22 needs backward computation.
I0525 23:43:49.035284 15117 net.cpp:316] BatchNorm22 needs backward computation.
I0525 23:43:49.035291 15117 net.cpp:316] Convolution22 needs backward computation.
I0525 23:43:49.035305 15117 net.cpp:316] Eltwise10_ReLU21_0_split needs backward computation.
I0525 23:43:49.035312 15117 net.cpp:316] ReLU21 needs backward computation.
I0525 23:43:49.035316 15117 net.cpp:316] Eltwise10 needs backward computation.
I0525 23:43:49.035320 15117 net.cpp:316] Scale21 needs backward computation.
I0525 23:43:49.035326 15117 net.cpp:316] BatchNorm21 needs backward computation.
I0525 23:43:49.035329 15117 net.cpp:316] Convolution21 needs backward computation.
I0525 23:43:49.035333 15117 net.cpp:316] ReLU20 needs backward computation.
I0525 23:43:49.035337 15117 net.cpp:316] Scale20 needs backward computation.
I0525 23:43:49.035341 15117 net.cpp:316] BatchNorm20 needs backward computation.
I0525 23:43:49.035344 15117 net.cpp:316] Convolution20 needs backward computation.
I0525 23:43:49.035349 15117 net.cpp:316] Concat2 needs backward computation.
I0525 23:43:49.035354 15117 net.cpp:318] Input2 does not need backward computation.
I0525 23:43:49.035358 15117 net.cpp:316] Pooling2 needs backward computation.
I0525 23:43:49.035362 15117 net.cpp:316] Eltwise9_ReLU19_0_split needs backward computation.
I0525 23:43:49.035368 15117 net.cpp:316] ReLU19 needs backward computation.
I0525 23:43:49.035372 15117 net.cpp:316] Eltwise9 needs backward computation.
I0525 23:43:49.035377 15117 net.cpp:316] Scale19 needs backward computation.
I0525 23:43:49.035382 15117 net.cpp:316] BatchNorm19 needs backward computation.
I0525 23:43:49.035384 15117 net.cpp:316] Convolution19 needs backward computation.
I0525 23:43:49.035389 15117 net.cpp:316] ReLU18 needs backward computation.
I0525 23:43:49.035393 15117 net.cpp:316] Scale18 needs backward computation.
I0525 23:43:49.035397 15117 net.cpp:316] BatchNorm18 needs backward computation.
I0525 23:43:49.035400 15117 net.cpp:316] Convolution18 needs backward computation.
I0525 23:43:49.035404 15117 net.cpp:316] Eltwise8_ReLU17_0_split needs backward computation.
I0525 23:43:49.035409 15117 net.cpp:316] ReLU17 needs backward computation.
I0525 23:43:49.035413 15117 net.cpp:316] Eltwise8 needs backward computation.
I0525 23:43:49.035418 15117 net.cpp:316] Scale17 needs backward computation.
I0525 23:43:49.035423 15117 net.cpp:316] BatchNorm17 needs backward computation.
I0525 23:43:49.035426 15117 net.cpp:316] Convolution17 needs backward computation.
I0525 23:43:49.035430 15117 net.cpp:316] ReLU16 needs backward computation.
I0525 23:43:49.035434 15117 net.cpp:316] Scale16 needs backward computation.
I0525 23:43:49.035437 15117 net.cpp:316] BatchNorm16 needs backward computation.
I0525 23:43:49.035441 15117 net.cpp:316] Convolution16 needs backward computation.
I0525 23:43:49.035445 15117 net.cpp:316] Eltwise7_ReLU15_0_split needs backward computation.
I0525 23:43:49.035449 15117 net.cpp:316] ReLU15 needs backward computation.
I0525 23:43:49.035454 15117 net.cpp:316] Eltwise7 needs backward computation.
I0525 23:43:49.035459 15117 net.cpp:316] Scale15 needs backward computation.
I0525 23:43:49.035462 15117 net.cpp:316] BatchNorm15 needs backward computation.
I0525 23:43:49.035466 15117 net.cpp:316] Convolution15 needs backward computation.
I0525 23:43:49.035470 15117 net.cpp:316] ReLU14 needs backward computation.
I0525 23:43:49.035475 15117 net.cpp:316] Scale14 needs backward computation.
I0525 23:43:49.035478 15117 net.cpp:316] BatchNorm14 needs backward computation.
I0525 23:43:49.035482 15117 net.cpp:316] Convolution14 needs backward computation.
I0525 23:43:49.035486 15117 net.cpp:316] Eltwise6_ReLU13_0_split needs backward computation.
I0525 23:43:49.035491 15117 net.cpp:316] ReLU13 needs backward computation.
I0525 23:43:49.035495 15117 net.cpp:316] Eltwise6 needs backward computation.
I0525 23:43:49.035501 15117 net.cpp:316] Scale13 needs backward computation.
I0525 23:43:49.035504 15117 net.cpp:316] BatchNorm13 needs backward computation.
I0525 23:43:49.035507 15117 net.cpp:316] Convolution13 needs backward computation.
I0525 23:43:49.035511 15117 net.cpp:316] ReLU12 needs backward computation.
I0525 23:43:49.035521 15117 net.cpp:316] Scale12 needs backward computation.
I0525 23:43:49.035531 15117 net.cpp:316] BatchNorm12 needs backward computation.
I0525 23:43:49.035536 15117 net.cpp:316] Convolution12 needs backward computation.
I0525 23:43:49.035539 15117 net.cpp:316] Eltwise5_ReLU11_0_split needs backward computation.
I0525 23:43:49.035544 15117 net.cpp:316] ReLU11 needs backward computation.
I0525 23:43:49.035548 15117 net.cpp:316] Eltwise5 needs backward computation.
I0525 23:43:49.035552 15117 net.cpp:316] Scale11 needs backward computation.
I0525 23:43:49.035557 15117 net.cpp:316] BatchNorm11 needs backward computation.
I0525 23:43:49.035560 15117 net.cpp:316] Convolution11 needs backward computation.
I0525 23:43:49.035564 15117 net.cpp:316] ReLU10 needs backward computation.
I0525 23:43:49.035569 15117 net.cpp:316] Scale10 needs backward computation.
I0525 23:43:49.035573 15117 net.cpp:316] BatchNorm10 needs backward computation.
I0525 23:43:49.035578 15117 net.cpp:316] Convolution10 needs backward computation.
I0525 23:43:49.035581 15117 net.cpp:316] Concat1 needs backward computation.
I0525 23:43:49.035586 15117 net.cpp:318] Input1 does not need backward computation.
I0525 23:43:49.035590 15117 net.cpp:316] Pooling1 needs backward computation.
I0525 23:43:49.035595 15117 net.cpp:316] Eltwise4_ReLU9_0_split needs backward computation.
I0525 23:43:49.035599 15117 net.cpp:316] ReLU9 needs backward computation.
I0525 23:43:49.035604 15117 net.cpp:316] Eltwise4 needs backward computation.
I0525 23:43:49.035609 15117 net.cpp:316] Scale9 needs backward computation.
I0525 23:43:49.035614 15117 net.cpp:316] BatchNorm9 needs backward computation.
I0525 23:43:49.035617 15117 net.cpp:316] Convolution9 needs backward computation.
I0525 23:43:49.035621 15117 net.cpp:316] ReLU8 needs backward computation.
I0525 23:43:49.035625 15117 net.cpp:316] Scale8 needs backward computation.
I0525 23:43:49.035629 15117 net.cpp:316] BatchNorm8 needs backward computation.
I0525 23:43:49.035634 15117 net.cpp:316] Convolution8 needs backward computation.
I0525 23:43:49.035637 15117 net.cpp:316] Eltwise3_ReLU7_0_split needs backward computation.
I0525 23:43:49.035642 15117 net.cpp:316] ReLU7 needs backward computation.
I0525 23:43:49.035645 15117 net.cpp:316] Eltwise3 needs backward computation.
I0525 23:43:49.035650 15117 net.cpp:316] Scale7 needs backward computation.
I0525 23:43:49.035655 15117 net.cpp:316] BatchNorm7 needs backward computation.
I0525 23:43:49.035658 15117 net.cpp:316] Convolution7 needs backward computation.
I0525 23:43:49.035663 15117 net.cpp:316] ReLU6 needs backward computation.
I0525 23:43:49.035667 15117 net.cpp:316] Scale6 needs backward computation.
I0525 23:43:49.035671 15117 net.cpp:316] BatchNorm6 needs backward computation.
I0525 23:43:49.035675 15117 net.cpp:316] Convolution6 needs backward computation.
I0525 23:43:49.035679 15117 net.cpp:316] Eltwise2_ReLU5_0_split needs backward computation.
I0525 23:43:49.035683 15117 net.cpp:316] ReLU5 needs backward computation.
I0525 23:43:49.035687 15117 net.cpp:316] Eltwise2 needs backward computation.
I0525 23:43:49.035694 15117 net.cpp:316] Scale5 needs backward computation.
I0525 23:43:49.035699 15117 net.cpp:316] BatchNorm5 needs backward computation.
I0525 23:43:49.035702 15117 net.cpp:316] Convolution5 needs backward computation.
I0525 23:43:49.035707 15117 net.cpp:316] ReLU4 needs backward computation.
I0525 23:43:49.035712 15117 net.cpp:316] Scale4 needs backward computation.
I0525 23:43:49.035717 15117 net.cpp:316] BatchNorm4 needs backward computation.
I0525 23:43:49.035719 15117 net.cpp:316] Convolution4 needs backward computation.
I0525 23:43:49.035724 15117 net.cpp:316] Eltwise1_ReLU3_0_split needs backward computation.
I0525 23:43:49.035728 15117 net.cpp:316] ReLU3 needs backward computation.
I0525 23:43:49.035733 15117 net.cpp:316] Eltwise1 needs backward computation.
I0525 23:43:49.035738 15117 net.cpp:316] Scale3 needs backward computation.
I0525 23:43:49.035742 15117 net.cpp:316] BatchNorm3 needs backward computation.
I0525 23:43:49.035749 15117 net.cpp:316] Convolution3 needs backward computation.
I0525 23:43:49.035760 15117 net.cpp:316] ReLU2 needs backward computation.
I0525 23:43:49.035764 15117 net.cpp:316] Scale2 needs backward computation.
I0525 23:43:49.035768 15117 net.cpp:316] BatchNorm2 needs backward computation.
I0525 23:43:49.035773 15117 net.cpp:316] Convolution2 needs backward computation.
I0525 23:43:49.035778 15117 net.cpp:316] Convolution1_ReLU1_0_split needs backward computation.
I0525 23:43:49.035781 15117 net.cpp:316] ReLU1 needs backward computation.
I0525 23:43:49.035786 15117 net.cpp:316] Scale1 needs backward computation.
I0525 23:43:49.035789 15117 net.cpp:316] BatchNorm1 needs backward computation.
I0525 23:43:49.035794 15117 net.cpp:316] Convolution1 needs backward computation.
I0525 23:43:49.035799 15117 net.cpp:318] Data2_Data1_1_split does not need backward computation.
I0525 23:43:49.035804 15117 net.cpp:318] Data1 does not need backward computation.
I0525 23:43:49.035807 15117 net.cpp:360] This network produces output Accuracy
I0525 23:43:49.035814 15117 net.cpp:360] This network produces output SoftmaxWithLoss1
I0525 23:43:49.035913 15117 net.cpp:374] Network initialization done.
I0525 23:43:49.036610 15117 solver.cpp:65] Solver scaffolding done.
I0525 23:43:49.045611 15117 caffe.cpp:219] Starting Optimization
I0525 23:43:49.045649 15117 solver.cpp:284] Solving 
I0525 23:43:49.045653 15117 solver.cpp:285] Learning Rate Policy: multistep
I0525 23:43:49.050446 15117 solver.cpp:342] Iteration 0, Testing net (#0)
I0525 23:44:01.976714 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.1
I0525 23:44:01.976788 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0525 23:44:02.619225 15117 solver.cpp:233] Iteration 0, loss = 4.66365
I0525 23:44:02.619316 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 4.66365 (* 1 = 4.66365 loss)
I0525 23:44:02.619348 15117 sgd_solver.cpp:294] Iteration 0, lr = 0.02
I0525 23:44:08.976325 15117 solver.cpp:233] Iteration 10, loss = 1.95634
I0525 23:44:08.976416 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.95634 (* 1 = 1.95634 loss)
I0525 23:44:08.976430 15117 sgd_solver.cpp:294] Iteration 10, lr = 0.02
I0525 23:44:15.354817 15117 solver.cpp:233] Iteration 20, loss = 1.91666
I0525 23:44:15.354936 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.91666 (* 1 = 1.91666 loss)
I0525 23:44:15.354949 15117 sgd_solver.cpp:294] Iteration 20, lr = 0.02
I0525 23:44:21.719494 15117 solver.cpp:233] Iteration 30, loss = 1.93753
I0525 23:44:21.719800 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.93753 (* 1 = 1.93753 loss)
I0525 23:44:21.719815 15117 sgd_solver.cpp:294] Iteration 30, lr = 0.02
I0525 23:44:28.096145 15117 solver.cpp:233] Iteration 40, loss = 1.7534
I0525 23:44:28.096233 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.7534 (* 1 = 1.7534 loss)
I0525 23:44:28.096246 15117 sgd_solver.cpp:294] Iteration 40, lr = 0.02
I0525 23:44:34.470054 15117 solver.cpp:233] Iteration 50, loss = 1.66733
I0525 23:44:34.470149 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.66733 (* 1 = 1.66733 loss)
I0525 23:44:34.470160 15117 sgd_solver.cpp:294] Iteration 50, lr = 0.02
I0525 23:44:40.839728 15117 solver.cpp:233] Iteration 60, loss = 1.77023
I0525 23:44:40.839840 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.77023 (* 1 = 1.77023 loss)
I0525 23:44:40.839859 15117 sgd_solver.cpp:294] Iteration 60, lr = 0.02
I0525 23:44:47.191341 15117 solver.cpp:233] Iteration 70, loss = 1.82215
I0525 23:44:47.191416 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.82215 (* 1 = 1.82215 loss)
I0525 23:44:47.191428 15117 sgd_solver.cpp:294] Iteration 70, lr = 0.02
I0525 23:44:53.538175 15117 solver.cpp:233] Iteration 80, loss = 1.55187
I0525 23:44:53.538378 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.55187 (* 1 = 1.55187 loss)
I0525 23:44:53.538393 15117 sgd_solver.cpp:294] Iteration 80, lr = 0.02
I0525 23:44:59.883283 15117 solver.cpp:233] Iteration 90, loss = 1.46603
I0525 23:44:59.883363 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.46603 (* 1 = 1.46603 loss)
I0525 23:44:59.883374 15117 sgd_solver.cpp:294] Iteration 90, lr = 0.02
I0525 23:45:05.617487 15117 solver.cpp:342] Iteration 100, Testing net (#0)
I0525 23:45:18.525923 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.1825
I0525 23:45:18.526026 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 3.26936 (* 1 = 3.26936 loss)
I0525 23:45:19.130368 15117 solver.cpp:233] Iteration 100, loss = 1.59126
I0525 23:45:19.130457 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.59126 (* 1 = 1.59126 loss)
I0525 23:45:19.130475 15117 sgd_solver.cpp:294] Iteration 100, lr = 0.02
I0525 23:45:25.498111 15117 solver.cpp:233] Iteration 110, loss = 1.61664
I0525 23:45:25.498451 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.61664 (* 1 = 1.61664 loss)
I0525 23:45:25.498468 15117 sgd_solver.cpp:294] Iteration 110, lr = 0.02
I0525 23:45:31.850904 15117 solver.cpp:233] Iteration 120, loss = 1.67115
I0525 23:45:31.850996 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.67115 (* 1 = 1.67115 loss)
I0525 23:45:31.851009 15117 sgd_solver.cpp:294] Iteration 120, lr = 0.02
I0525 23:45:38.220219 15117 solver.cpp:233] Iteration 130, loss = 1.45722
I0525 23:45:38.220302 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.45722 (* 1 = 1.45722 loss)
I0525 23:45:38.220315 15117 sgd_solver.cpp:294] Iteration 130, lr = 0.02
I0525 23:45:44.565021 15117 solver.cpp:233] Iteration 140, loss = 1.56951
I0525 23:45:44.565111 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.56951 (* 1 = 1.56951 loss)
I0525 23:45:44.565125 15117 sgd_solver.cpp:294] Iteration 140, lr = 0.02
I0525 23:45:50.906080 15117 solver.cpp:233] Iteration 150, loss = 1.4361
I0525 23:45:50.906167 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.4361 (* 1 = 1.4361 loss)
I0525 23:45:50.906179 15117 sgd_solver.cpp:294] Iteration 150, lr = 0.02
I0525 23:45:57.245589 15117 solver.cpp:233] Iteration 160, loss = 1.5271
I0525 23:45:57.245828 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.5271 (* 1 = 1.5271 loss)
I0525 23:45:57.245852 15117 sgd_solver.cpp:294] Iteration 160, lr = 0.02
I0525 23:46:03.629593 15117 solver.cpp:233] Iteration 170, loss = 1.48721
I0525 23:46:03.629670 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.48721 (* 1 = 1.48721 loss)
I0525 23:46:03.629683 15117 sgd_solver.cpp:294] Iteration 170, lr = 0.02
I0525 23:46:09.972590 15117 solver.cpp:233] Iteration 180, loss = 1.16908
I0525 23:46:09.972667 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.16908 (* 1 = 1.16908 loss)
I0525 23:46:09.972681 15117 sgd_solver.cpp:294] Iteration 180, lr = 0.02
I0525 23:46:16.316368 15117 solver.cpp:233] Iteration 190, loss = 1.33082
I0525 23:46:16.316439 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.33082 (* 1 = 1.33082 loss)
I0525 23:46:16.316452 15117 sgd_solver.cpp:294] Iteration 190, lr = 0.02
I0525 23:46:22.053571 15117 solver.cpp:342] Iteration 200, Testing net (#0)
I0525 23:46:34.938719 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.2445
I0525 23:46:34.938875 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 2.93905 (* 1 = 2.93905 loss)
I0525 23:46:35.539433 15117 solver.cpp:233] Iteration 200, loss = 1.35585
I0525 23:46:35.539505 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.35585 (* 1 = 1.35585 loss)
I0525 23:46:35.539516 15117 sgd_solver.cpp:294] Iteration 200, lr = 0.02
I0525 23:46:41.870890 15117 solver.cpp:233] Iteration 210, loss = 1.41084
I0525 23:46:41.870975 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.41084 (* 1 = 1.41084 loss)
I0525 23:46:41.870988 15117 sgd_solver.cpp:294] Iteration 210, lr = 0.02
I0525 23:46:48.204376 15117 solver.cpp:233] Iteration 220, loss = 1.27475
I0525 23:46:48.204450 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.27475 (* 1 = 1.27475 loss)
I0525 23:46:48.204470 15117 sgd_solver.cpp:294] Iteration 220, lr = 0.02
I0525 23:46:54.534703 15117 solver.cpp:233] Iteration 230, loss = 1.37175
I0525 23:46:54.534772 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.37175 (* 1 = 1.37175 loss)
I0525 23:46:54.534785 15117 sgd_solver.cpp:294] Iteration 230, lr = 0.02
I0525 23:47:00.894879 15117 solver.cpp:233] Iteration 240, loss = 1.47994
I0525 23:47:00.894948 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.47994 (* 1 = 1.47994 loss)
I0525 23:47:00.894958 15117 sgd_solver.cpp:294] Iteration 240, lr = 0.02
I0525 23:47:07.279331 15117 solver.cpp:233] Iteration 250, loss = 1.30048
I0525 23:47:07.279556 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.30048 (* 1 = 1.30048 loss)
I0525 23:47:07.279569 15117 sgd_solver.cpp:294] Iteration 250, lr = 0.02
I0525 23:47:13.666595 15117 solver.cpp:233] Iteration 260, loss = 1.35683
I0525 23:47:13.666668 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.35683 (* 1 = 1.35683 loss)
I0525 23:47:13.666679 15117 sgd_solver.cpp:294] Iteration 260, lr = 0.02
I0525 23:47:20.055073 15117 solver.cpp:233] Iteration 270, loss = 1.1951
I0525 23:47:20.055136 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.1951 (* 1 = 1.1951 loss)
I0525 23:47:20.055146 15117 sgd_solver.cpp:294] Iteration 270, lr = 0.02
I0525 23:47:26.444053 15117 solver.cpp:233] Iteration 280, loss = 1.19505
I0525 23:47:26.444123 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.19505 (* 1 = 1.19505 loss)
I0525 23:47:26.444133 15117 sgd_solver.cpp:294] Iteration 280, lr = 0.02
I0525 23:47:32.825402 15117 solver.cpp:233] Iteration 290, loss = 1.28633
I0525 23:47:32.825466 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.28633 (* 1 = 1.28633 loss)
I0525 23:47:32.825477 15117 sgd_solver.cpp:294] Iteration 290, lr = 0.02
I0525 23:47:38.601972 15117 solver.cpp:342] Iteration 300, Testing net (#0)
I0525 23:47:51.830775 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.3623
I0525 23:47:51.830842 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.99853 (* 1 = 1.99853 loss)
I0525 23:47:52.438961 15117 solver.cpp:233] Iteration 300, loss = 1.20355
I0525 23:47:52.439031 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.20355 (* 1 = 1.20355 loss)
I0525 23:47:52.439041 15117 sgd_solver.cpp:294] Iteration 300, lr = 0.02
I0525 23:47:58.828876 15117 solver.cpp:233] Iteration 310, loss = 1.29
I0525 23:47:58.828950 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.29 (* 1 = 1.29 loss)
I0525 23:47:58.828961 15117 sgd_solver.cpp:294] Iteration 310, lr = 0.02
I0525 23:48:05.217629 15117 solver.cpp:233] Iteration 320, loss = 1.39858
I0525 23:48:05.217701 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.39858 (* 1 = 1.39858 loss)
I0525 23:48:05.217711 15117 sgd_solver.cpp:294] Iteration 320, lr = 0.02
I0525 23:48:11.606542 15117 solver.cpp:233] Iteration 330, loss = 1.15371
I0525 23:48:11.606708 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.15371 (* 1 = 1.15371 loss)
I0525 23:48:11.606719 15117 sgd_solver.cpp:294] Iteration 330, lr = 0.02
I0525 23:48:17.999825 15117 solver.cpp:233] Iteration 340, loss = 1.20944
I0525 23:48:17.999897 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.20944 (* 1 = 1.20944 loss)
I0525 23:48:17.999907 15117 sgd_solver.cpp:294] Iteration 340, lr = 0.02
I0525 23:48:24.383705 15117 solver.cpp:233] Iteration 350, loss = 1.16229
I0525 23:48:24.383774 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.16229 (* 1 = 1.16229 loss)
I0525 23:48:24.383785 15117 sgd_solver.cpp:294] Iteration 350, lr = 0.02
I0525 23:48:30.764503 15117 solver.cpp:233] Iteration 360, loss = 1.10687
I0525 23:48:30.764569 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.10687 (* 1 = 1.10687 loss)
I0525 23:48:30.764578 15117 sgd_solver.cpp:294] Iteration 360, lr = 0.02
I0525 23:48:37.145323 15117 solver.cpp:233] Iteration 370, loss = 0.994569
I0525 23:48:37.145395 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.994569 (* 1 = 0.994569 loss)
I0525 23:48:37.145406 15117 sgd_solver.cpp:294] Iteration 370, lr = 0.02
I0525 23:48:43.529109 15117 solver.cpp:233] Iteration 380, loss = 1.13761
I0525 23:48:43.529337 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.13761 (* 1 = 1.13761 loss)
I0525 23:48:43.529351 15117 sgd_solver.cpp:294] Iteration 380, lr = 0.02
I0525 23:48:49.914404 15117 solver.cpp:233] Iteration 390, loss = 1.24183
I0525 23:48:49.914469 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.24183 (* 1 = 1.24183 loss)
I0525 23:48:49.914480 15117 sgd_solver.cpp:294] Iteration 390, lr = 0.02
I0525 23:48:55.692201 15117 solver.cpp:342] Iteration 400, Testing net (#0)
I0525 23:49:08.749879 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.4175
I0525 23:49:08.749953 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.95906 (* 1 = 1.95906 loss)
I0525 23:49:09.357578 15117 solver.cpp:233] Iteration 400, loss = 1.11975
I0525 23:49:09.357645 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.11975 (* 1 = 1.11975 loss)
I0525 23:49:09.357657 15117 sgd_solver.cpp:294] Iteration 400, lr = 0.02
I0525 23:49:15.756091 15117 solver.cpp:233] Iteration 410, loss = 0.965269
I0525 23:49:15.756289 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.965269 (* 1 = 0.965269 loss)
I0525 23:49:15.756300 15117 sgd_solver.cpp:294] Iteration 410, lr = 0.02
I0525 23:49:22.142637 15117 solver.cpp:233] Iteration 420, loss = 1.02371
I0525 23:49:22.142705 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.02371 (* 1 = 1.02371 loss)
I0525 23:49:22.142716 15117 sgd_solver.cpp:294] Iteration 420, lr = 0.02
I0525 23:49:28.527256 15117 solver.cpp:233] Iteration 430, loss = 1.34847
I0525 23:49:28.527339 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.34847 (* 1 = 1.34847 loss)
I0525 23:49:28.527353 15117 sgd_solver.cpp:294] Iteration 430, lr = 0.02
I0525 23:49:34.912608 15117 solver.cpp:233] Iteration 440, loss = 1.06216
I0525 23:49:34.912672 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.06216 (* 1 = 1.06216 loss)
I0525 23:49:34.912683 15117 sgd_solver.cpp:294] Iteration 440, lr = 0.02
I0525 23:49:41.294710 15117 solver.cpp:233] Iteration 450, loss = 1.15602
I0525 23:49:41.294780 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.15602 (* 1 = 1.15602 loss)
I0525 23:49:41.294790 15117 sgd_solver.cpp:294] Iteration 450, lr = 0.02
I0525 23:49:47.677934 15117 solver.cpp:233] Iteration 460, loss = 1.177
I0525 23:49:47.678089 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.177 (* 1 = 1.177 loss)
I0525 23:49:47.678102 15117 sgd_solver.cpp:294] Iteration 460, lr = 0.02
I0525 23:49:54.062515 15117 solver.cpp:233] Iteration 470, loss = 1.19608
I0525 23:49:54.062582 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.19608 (* 1 = 1.19608 loss)
I0525 23:49:54.062593 15117 sgd_solver.cpp:294] Iteration 470, lr = 0.02
I0525 23:50:00.446313 15117 solver.cpp:233] Iteration 480, loss = 1.04088
I0525 23:50:00.446393 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.04088 (* 1 = 1.04088 loss)
I0525 23:50:00.446403 15117 sgd_solver.cpp:294] Iteration 480, lr = 0.02
I0525 23:50:06.830646 15117 solver.cpp:233] Iteration 490, loss = 1.0076
I0525 23:50:06.830711 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.0076 (* 1 = 1.0076 loss)
I0525 23:50:06.830721 15117 sgd_solver.cpp:294] Iteration 490, lr = 0.02
I0525 23:50:12.613224 15117 solver.cpp:342] Iteration 500, Testing net (#0)
I0525 23:50:25.683236 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.3462
I0525 23:50:25.683403 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 2.76213 (* 1 = 2.76213 loss)
I0525 23:50:26.290199 15117 solver.cpp:233] Iteration 500, loss = 1.13096
I0525 23:50:26.290271 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.13096 (* 1 = 1.13096 loss)
I0525 23:50:26.290298 15117 sgd_solver.cpp:294] Iteration 500, lr = 0.02
I0525 23:50:32.682131 15117 solver.cpp:233] Iteration 510, loss = 1.0155
I0525 23:50:32.682205 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.0155 (* 1 = 1.0155 loss)
I0525 23:50:32.682216 15117 sgd_solver.cpp:294] Iteration 510, lr = 0.02
I0525 23:50:39.070631 15117 solver.cpp:233] Iteration 520, loss = 1.16609
I0525 23:50:39.070698 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.16609 (* 1 = 1.16609 loss)
I0525 23:50:39.070708 15117 sgd_solver.cpp:294] Iteration 520, lr = 0.02
I0525 23:50:45.447701 15117 solver.cpp:233] Iteration 530, loss = 0.77966
I0525 23:50:45.447769 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.77966 (* 1 = 0.77966 loss)
I0525 23:50:45.447779 15117 sgd_solver.cpp:294] Iteration 530, lr = 0.02
I0525 23:50:51.827059 15117 solver.cpp:233] Iteration 540, loss = 1.11516
I0525 23:50:51.827129 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.11516 (* 1 = 1.11516 loss)
I0525 23:50:51.827139 15117 sgd_solver.cpp:294] Iteration 540, lr = 0.02
I0525 23:50:58.206881 15117 solver.cpp:233] Iteration 550, loss = 1.13653
I0525 23:50:58.207126 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.13653 (* 1 = 1.13653 loss)
I0525 23:50:58.207142 15117 sgd_solver.cpp:294] Iteration 550, lr = 0.02
I0525 23:51:04.591708 15117 solver.cpp:233] Iteration 560, loss = 1.00345
I0525 23:51:04.591780 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.00345 (* 1 = 1.00345 loss)
I0525 23:51:04.591791 15117 sgd_solver.cpp:294] Iteration 560, lr = 0.02
I0525 23:51:10.971807 15117 solver.cpp:233] Iteration 570, loss = 1.0665
I0525 23:51:10.971874 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.0665 (* 1 = 1.0665 loss)
I0525 23:51:10.971884 15117 sgd_solver.cpp:294] Iteration 570, lr = 0.02
I0525 23:51:17.354993 15117 solver.cpp:233] Iteration 580, loss = 0.986959
I0525 23:51:17.355062 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.986959 (* 1 = 0.986959 loss)
I0525 23:51:17.355072 15117 sgd_solver.cpp:294] Iteration 580, lr = 0.02
I0525 23:51:23.737393 15117 solver.cpp:233] Iteration 590, loss = 0.924638
I0525 23:51:23.737459 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.924638 (* 1 = 0.924638 loss)
I0525 23:51:23.737470 15117 sgd_solver.cpp:294] Iteration 590, lr = 0.02
I0525 23:51:29.516860 15117 solver.cpp:342] Iteration 600, Testing net (#0)
I0525 23:51:42.535141 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.394
I0525 23:51:42.535207 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 2.53727 (* 1 = 2.53727 loss)
I0525 23:51:43.140221 15117 solver.cpp:233] Iteration 600, loss = 1.10594
I0525 23:51:43.140296 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.10594 (* 1 = 1.10594 loss)
I0525 23:51:43.140310 15117 sgd_solver.cpp:294] Iteration 600, lr = 0.02
I0525 23:51:49.536888 15117 solver.cpp:233] Iteration 610, loss = 1.06475
I0525 23:51:49.536958 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.06475 (* 1 = 1.06475 loss)
I0525 23:51:49.536968 15117 sgd_solver.cpp:294] Iteration 610, lr = 0.02
I0525 23:51:55.931205 15117 solver.cpp:233] Iteration 620, loss = 1.00992
I0525 23:51:55.931275 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.00992 (* 1 = 1.00992 loss)
I0525 23:51:55.931285 15117 sgd_solver.cpp:294] Iteration 620, lr = 0.02
I0525 23:52:02.333039 15117 solver.cpp:233] Iteration 630, loss = 1.01201
I0525 23:52:02.333207 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.01201 (* 1 = 1.01201 loss)
I0525 23:52:02.333220 15117 sgd_solver.cpp:294] Iteration 630, lr = 0.02
I0525 23:52:08.735000 15117 solver.cpp:233] Iteration 640, loss = 1.00475
I0525 23:52:08.735071 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.00475 (* 1 = 1.00475 loss)
I0525 23:52:08.735081 15117 sgd_solver.cpp:294] Iteration 640, lr = 0.02
I0525 23:52:15.139631 15117 solver.cpp:233] Iteration 650, loss = 0.907802
I0525 23:52:15.139706 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.907802 (* 1 = 0.907802 loss)
I0525 23:52:15.139719 15117 sgd_solver.cpp:294] Iteration 650, lr = 0.02
I0525 23:52:21.539540 15117 solver.cpp:233] Iteration 660, loss = 0.842873
I0525 23:52:21.539608 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.842873 (* 1 = 0.842873 loss)
I0525 23:52:21.539618 15117 sgd_solver.cpp:294] Iteration 660, lr = 0.02
I0525 23:52:27.944051 15117 solver.cpp:233] Iteration 670, loss = 1.06525
I0525 23:52:27.944121 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.06525 (* 1 = 1.06525 loss)
I0525 23:52:27.944131 15117 sgd_solver.cpp:294] Iteration 670, lr = 0.02
I0525 23:52:34.347193 15117 solver.cpp:233] Iteration 680, loss = 1.0881
I0525 23:52:34.347404 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.0881 (* 1 = 1.0881 loss)
I0525 23:52:34.347415 15117 sgd_solver.cpp:294] Iteration 680, lr = 0.02
I0525 23:52:40.746140 15117 solver.cpp:233] Iteration 690, loss = 0.943067
I0525 23:52:40.746213 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.943067 (* 1 = 0.943067 loss)
I0525 23:52:40.746224 15117 sgd_solver.cpp:294] Iteration 690, lr = 0.02
I0525 23:52:46.545821 15117 solver.cpp:342] Iteration 700, Testing net (#0)
I0525 23:52:59.616348 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.4396
I0525 23:52:59.616425 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.98457 (* 1 = 1.98457 loss)
I0525 23:53:00.222219 15117 solver.cpp:233] Iteration 700, loss = 0.959273
I0525 23:53:00.222287 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.959273 (* 1 = 0.959273 loss)
I0525 23:53:00.222301 15117 sgd_solver.cpp:294] Iteration 700, lr = 0.02
I0525 23:53:06.606851 15117 solver.cpp:233] Iteration 710, loss = 1.04343
I0525 23:53:06.607022 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.04343 (* 1 = 1.04343 loss)
I0525 23:53:06.607033 15117 sgd_solver.cpp:294] Iteration 710, lr = 0.02
I0525 23:53:12.990044 15117 solver.cpp:233] Iteration 720, loss = 0.86413
I0525 23:53:12.990115 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.86413 (* 1 = 0.86413 loss)
I0525 23:53:12.990126 15117 sgd_solver.cpp:294] Iteration 720, lr = 0.02
I0525 23:53:19.377799 15117 solver.cpp:233] Iteration 730, loss = 1.08653
I0525 23:53:19.377869 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.08653 (* 1 = 1.08653 loss)
I0525 23:53:19.377881 15117 sgd_solver.cpp:294] Iteration 730, lr = 0.02
I0525 23:53:25.767405 15117 solver.cpp:233] Iteration 740, loss = 1.07547
I0525 23:53:25.767477 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.07547 (* 1 = 1.07547 loss)
I0525 23:53:25.767488 15117 sgd_solver.cpp:294] Iteration 740, lr = 0.02
I0525 23:53:32.152289 15117 solver.cpp:233] Iteration 750, loss = 0.8769
I0525 23:53:32.152361 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.8769 (* 1 = 0.8769 loss)
I0525 23:53:32.152371 15117 sgd_solver.cpp:294] Iteration 750, lr = 0.02
I0525 23:53:38.538885 15117 solver.cpp:233] Iteration 760, loss = 0.904569
I0525 23:53:38.539041 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.904569 (* 1 = 0.904569 loss)
I0525 23:53:38.539052 15117 sgd_solver.cpp:294] Iteration 760, lr = 0.02
I0525 23:53:44.923789 15117 solver.cpp:233] Iteration 770, loss = 0.896936
I0525 23:53:44.923861 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.896936 (* 1 = 0.896936 loss)
I0525 23:53:44.923871 15117 sgd_solver.cpp:294] Iteration 770, lr = 0.02
I0525 23:53:51.307304 15117 solver.cpp:233] Iteration 780, loss = 0.81043
I0525 23:53:51.307370 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.81043 (* 1 = 0.81043 loss)
I0525 23:53:51.307381 15117 sgd_solver.cpp:294] Iteration 780, lr = 0.02
I0525 23:53:57.687521 15117 solver.cpp:233] Iteration 790, loss = 0.791639
I0525 23:53:57.687607 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.791639 (* 1 = 0.791639 loss)
I0525 23:53:57.687618 15117 sgd_solver.cpp:294] Iteration 790, lr = 0.02
I0525 23:54:03.506521 15117 solver.cpp:342] Iteration 800, Testing net (#0)
I0525 23:54:16.614537 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.4817
I0525 23:54:16.614761 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 2.00236 (* 1 = 2.00236 loss)
I0525 23:54:17.220672 15117 solver.cpp:233] Iteration 800, loss = 0.821692
I0525 23:54:17.220742 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.821692 (* 1 = 0.821692 loss)
I0525 23:54:17.220755 15117 sgd_solver.cpp:294] Iteration 800, lr = 0.02
I0525 23:54:23.606889 15117 solver.cpp:233] Iteration 810, loss = 0.776941
I0525 23:54:23.606956 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.776941 (* 1 = 0.776941 loss)
I0525 23:54:23.606966 15117 sgd_solver.cpp:294] Iteration 810, lr = 0.02
I0525 23:54:29.990916 15117 solver.cpp:233] Iteration 820, loss = 1.09018
I0525 23:54:29.990988 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.09018 (* 1 = 1.09018 loss)
I0525 23:54:29.990999 15117 sgd_solver.cpp:294] Iteration 820, lr = 0.02
I0525 23:54:36.370625 15117 solver.cpp:233] Iteration 830, loss = 0.763451
I0525 23:54:36.370690 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.763451 (* 1 = 0.763451 loss)
I0525 23:54:36.370702 15117 sgd_solver.cpp:294] Iteration 830, lr = 0.02
I0525 23:54:42.753466 15117 solver.cpp:233] Iteration 840, loss = 0.931961
I0525 23:54:42.753535 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.931961 (* 1 = 0.931961 loss)
I0525 23:54:42.753546 15117 sgd_solver.cpp:294] Iteration 840, lr = 0.02
I0525 23:54:49.138857 15117 solver.cpp:233] Iteration 850, loss = 0.785372
I0525 23:54:49.139020 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.785372 (* 1 = 0.785372 loss)
I0525 23:54:49.139032 15117 sgd_solver.cpp:294] Iteration 850, lr = 0.02
I0525 23:54:55.522696 15117 solver.cpp:233] Iteration 860, loss = 0.876087
I0525 23:54:55.522763 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.876087 (* 1 = 0.876087 loss)
I0525 23:54:55.522774 15117 sgd_solver.cpp:294] Iteration 860, lr = 0.02
I0525 23:55:01.907476 15117 solver.cpp:233] Iteration 870, loss = 0.85526
I0525 23:55:01.907546 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.85526 (* 1 = 0.85526 loss)
I0525 23:55:01.907557 15117 sgd_solver.cpp:294] Iteration 870, lr = 0.02
I0525 23:55:08.303817 15117 solver.cpp:233] Iteration 880, loss = 0.864699
I0525 23:55:08.303882 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.864699 (* 1 = 0.864699 loss)
I0525 23:55:08.303894 15117 sgd_solver.cpp:294] Iteration 880, lr = 0.02
I0525 23:55:14.703347 15117 solver.cpp:233] Iteration 890, loss = 0.90714
I0525 23:55:14.703418 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.90714 (* 1 = 0.90714 loss)
I0525 23:55:14.703428 15117 sgd_solver.cpp:294] Iteration 890, lr = 0.02
I0525 23:55:20.492692 15117 solver.cpp:342] Iteration 900, Testing net (#0)
I0525 23:55:33.600402 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.3384
I0525 23:55:33.600466 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 2.93407 (* 1 = 2.93407 loss)
I0525 23:55:34.207027 15117 solver.cpp:233] Iteration 900, loss = 0.803901
I0525 23:55:34.207099 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.803901 (* 1 = 0.803901 loss)
I0525 23:55:34.207113 15117 sgd_solver.cpp:294] Iteration 900, lr = 0.02
I0525 23:55:40.622552 15117 solver.cpp:233] Iteration 910, loss = 1.09348
I0525 23:55:40.622617 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.09348 (* 1 = 1.09348 loss)
I0525 23:55:40.622627 15117 sgd_solver.cpp:294] Iteration 910, lr = 0.02
I0525 23:55:47.014837 15117 solver.cpp:233] Iteration 920, loss = 0.949194
I0525 23:55:47.014906 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.949194 (* 1 = 0.949194 loss)
I0525 23:55:47.014928 15117 sgd_solver.cpp:294] Iteration 920, lr = 0.02
I0525 23:55:53.397308 15117 solver.cpp:233] Iteration 930, loss = 1.04036
I0525 23:55:53.397546 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.04036 (* 1 = 1.04036 loss)
I0525 23:55:53.397560 15117 sgd_solver.cpp:294] Iteration 930, lr = 0.02
I0525 23:55:59.781476 15117 solver.cpp:233] Iteration 940, loss = 0.929333
I0525 23:55:59.781554 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.929333 (* 1 = 0.929333 loss)
I0525 23:55:59.781566 15117 sgd_solver.cpp:294] Iteration 940, lr = 0.02
I0525 23:56:06.166299 15117 solver.cpp:233] Iteration 950, loss = 0.827945
I0525 23:56:06.166375 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.827945 (* 1 = 0.827945 loss)
I0525 23:56:06.166388 15117 sgd_solver.cpp:294] Iteration 950, lr = 0.02
I0525 23:56:12.553066 15117 solver.cpp:233] Iteration 960, loss = 0.941532
I0525 23:56:12.553130 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.941532 (* 1 = 0.941532 loss)
I0525 23:56:12.553141 15117 sgd_solver.cpp:294] Iteration 960, lr = 0.02
I0525 23:56:18.938504 15117 solver.cpp:233] Iteration 970, loss = 0.897586
I0525 23:56:18.938575 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.897586 (* 1 = 0.897586 loss)
I0525 23:56:18.938585 15117 sgd_solver.cpp:294] Iteration 970, lr = 0.02
I0525 23:56:25.322324 15117 solver.cpp:233] Iteration 980, loss = 0.933672
I0525 23:56:25.322480 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.933672 (* 1 = 0.933672 loss)
I0525 23:56:25.322494 15117 sgd_solver.cpp:294] Iteration 980, lr = 0.02
I0525 23:56:31.708717 15117 solver.cpp:233] Iteration 990, loss = 0.907958
I0525 23:56:31.708787 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.907958 (* 1 = 0.907958 loss)
I0525 23:56:31.708799 15117 sgd_solver.cpp:294] Iteration 990, lr = 0.02
I0525 23:56:37.486872 15117 solver.cpp:342] Iteration 1000, Testing net (#0)
I0525 23:56:50.524246 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.5045
I0525 23:56:50.524313 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 2.0108 (* 1 = 2.0108 loss)
I0525 23:56:51.130668 15117 solver.cpp:233] Iteration 1000, loss = 0.907136
I0525 23:56:51.130736 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.907136 (* 1 = 0.907136 loss)
I0525 23:56:51.130749 15117 sgd_solver.cpp:294] Iteration 1000, lr = 0.02
I0525 23:56:57.519688 15117 solver.cpp:233] Iteration 1010, loss = 0.683876
I0525 23:56:57.519876 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.683876 (* 1 = 0.683876 loss)
I0525 23:56:57.519899 15117 sgd_solver.cpp:294] Iteration 1010, lr = 0.02
I0525 23:57:03.917814 15117 solver.cpp:233] Iteration 1020, loss = 0.82221
I0525 23:57:03.917891 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.82221 (* 1 = 0.82221 loss)
I0525 23:57:03.917902 15117 sgd_solver.cpp:294] Iteration 1020, lr = 0.02
I0525 23:57:10.313695 15117 solver.cpp:233] Iteration 1030, loss = 0.964454
I0525 23:57:10.313784 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.964454 (* 1 = 0.964454 loss)
I0525 23:57:10.313798 15117 sgd_solver.cpp:294] Iteration 1030, lr = 0.02
I0525 23:57:16.717579 15117 solver.cpp:233] Iteration 1040, loss = 0.798778
I0525 23:57:16.717679 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.798778 (* 1 = 0.798778 loss)
I0525 23:57:16.717691 15117 sgd_solver.cpp:294] Iteration 1040, lr = 0.02
I0525 23:57:23.122836 15117 solver.cpp:233] Iteration 1050, loss = 0.90868
I0525 23:57:23.122911 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.90868 (* 1 = 0.90868 loss)
I0525 23:57:23.122922 15117 sgd_solver.cpp:294] Iteration 1050, lr = 0.02
I0525 23:57:29.525375 15117 solver.cpp:233] Iteration 1060, loss = 0.832552
I0525 23:57:29.525617 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.832552 (* 1 = 0.832552 loss)
I0525 23:57:29.525631 15117 sgd_solver.cpp:294] Iteration 1060, lr = 0.02
I0525 23:57:35.930068 15117 solver.cpp:233] Iteration 1070, loss = 0.914688
I0525 23:57:35.930140 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.914688 (* 1 = 0.914688 loss)
I0525 23:57:35.930150 15117 sgd_solver.cpp:294] Iteration 1070, lr = 0.02
I0525 23:57:42.328709 15117 solver.cpp:233] Iteration 1080, loss = 0.781565
I0525 23:57:42.328783 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.781565 (* 1 = 0.781565 loss)
I0525 23:57:42.328794 15117 sgd_solver.cpp:294] Iteration 1080, lr = 0.02
I0525 23:57:48.722151 15117 solver.cpp:233] Iteration 1090, loss = 0.856196
I0525 23:57:48.722235 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.856196 (* 1 = 0.856196 loss)
I0525 23:57:48.722249 15117 sgd_solver.cpp:294] Iteration 1090, lr = 0.02
I0525 23:57:54.510256 15117 solver.cpp:342] Iteration 1100, Testing net (#0)
I0525 23:58:07.545644 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.4
I0525 23:58:07.545861 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 2.37505 (* 1 = 2.37505 loss)
I0525 23:58:08.153421 15117 solver.cpp:233] Iteration 1100, loss = 0.816312
I0525 23:58:08.153511 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.816312 (* 1 = 0.816312 loss)
I0525 23:58:08.153527 15117 sgd_solver.cpp:294] Iteration 1100, lr = 0.02
I0525 23:58:14.575759 15117 solver.cpp:233] Iteration 1110, loss = 0.759606
I0525 23:58:14.575836 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.759606 (* 1 = 0.759606 loss)
I0525 23:58:14.575847 15117 sgd_solver.cpp:294] Iteration 1110, lr = 0.02
I0525 23:58:20.984259 15117 solver.cpp:233] Iteration 1120, loss = 0.767388
I0525 23:58:20.984339 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.767388 (* 1 = 0.767388 loss)
I0525 23:58:20.984351 15117 sgd_solver.cpp:294] Iteration 1120, lr = 0.02
I0525 23:58:27.377728 15117 solver.cpp:233] Iteration 1130, loss = 0.878868
I0525 23:58:27.377821 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.878868 (* 1 = 0.878868 loss)
I0525 23:58:27.377833 15117 sgd_solver.cpp:294] Iteration 1130, lr = 0.02
I0525 23:58:33.768141 15117 solver.cpp:233] Iteration 1140, loss = 0.655082
I0525 23:58:33.768223 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.655082 (* 1 = 0.655082 loss)
I0525 23:58:33.768234 15117 sgd_solver.cpp:294] Iteration 1140, lr = 0.02
I0525 23:58:40.163283 15117 solver.cpp:233] Iteration 1150, loss = 0.693261
I0525 23:58:40.163475 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.693261 (* 1 = 0.693261 loss)
I0525 23:58:40.163489 15117 sgd_solver.cpp:294] Iteration 1150, lr = 0.02
I0525 23:58:46.558668 15117 solver.cpp:233] Iteration 1160, loss = 0.735376
I0525 23:58:46.558766 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.735376 (* 1 = 0.735376 loss)
I0525 23:58:46.558780 15117 sgd_solver.cpp:294] Iteration 1160, lr = 0.02
I0525 23:58:52.953475 15117 solver.cpp:233] Iteration 1170, loss = 0.748531
I0525 23:58:52.953554 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.748531 (* 1 = 0.748531 loss)
I0525 23:58:52.953567 15117 sgd_solver.cpp:294] Iteration 1170, lr = 0.02
I0525 23:58:59.348597 15117 solver.cpp:233] Iteration 1180, loss = 0.824317
I0525 23:58:59.348690 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.824317 (* 1 = 0.824317 loss)
I0525 23:58:59.348704 15117 sgd_solver.cpp:294] Iteration 1180, lr = 0.02
I0525 23:59:05.742672 15117 solver.cpp:233] Iteration 1190, loss = 0.663799
I0525 23:59:05.742760 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.663799 (* 1 = 0.663799 loss)
I0525 23:59:05.742774 15117 sgd_solver.cpp:294] Iteration 1190, lr = 0.02
I0525 23:59:11.532713 15117 solver.cpp:342] Iteration 1200, Testing net (#0)
I0525 23:59:24.557618 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.4657
I0525 23:59:24.557708 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 2.21186 (* 1 = 2.21186 loss)
I0525 23:59:25.165065 15117 solver.cpp:233] Iteration 1200, loss = 0.696151
I0525 23:59:25.165158 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.696151 (* 1 = 0.696151 loss)
I0525 23:59:25.165174 15117 sgd_solver.cpp:294] Iteration 1200, lr = 0.02
I0525 23:59:31.557354 15117 solver.cpp:233] Iteration 1210, loss = 0.926643
I0525 23:59:31.557445 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.926643 (* 1 = 0.926643 loss)
I0525 23:59:31.557458 15117 sgd_solver.cpp:294] Iteration 1210, lr = 0.02
I0525 23:59:37.952929 15117 solver.cpp:233] Iteration 1220, loss = 0.721473
I0525 23:59:37.953004 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.721473 (* 1 = 0.721473 loss)
I0525 23:59:37.953016 15117 sgd_solver.cpp:294] Iteration 1220, lr = 0.02
I0525 23:59:44.341204 15117 solver.cpp:233] Iteration 1230, loss = 0.77851
I0525 23:59:44.341449 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.77851 (* 1 = 0.77851 loss)
I0525 23:59:44.341461 15117 sgd_solver.cpp:294] Iteration 1230, lr = 0.02
I0525 23:59:50.736651 15117 solver.cpp:233] Iteration 1240, loss = 0.896029
I0525 23:59:50.736732 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.896029 (* 1 = 0.896029 loss)
I0525 23:59:50.736743 15117 sgd_solver.cpp:294] Iteration 1240, lr = 0.02
I0525 23:59:57.129153 15117 solver.cpp:233] Iteration 1250, loss = 0.690711
I0525 23:59:57.129230 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.690711 (* 1 = 0.690711 loss)
I0525 23:59:57.129242 15117 sgd_solver.cpp:294] Iteration 1250, lr = 0.02
I0526 00:00:03.527815 15117 solver.cpp:233] Iteration 1260, loss = 0.813134
I0526 00:00:03.527902 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.813134 (* 1 = 0.813134 loss)
I0526 00:00:03.527915 15117 sgd_solver.cpp:294] Iteration 1260, lr = 0.02
I0526 00:00:09.922853 15117 solver.cpp:233] Iteration 1270, loss = 0.738943
I0526 00:00:09.922946 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.738943 (* 1 = 0.738943 loss)
I0526 00:00:09.922960 15117 sgd_solver.cpp:294] Iteration 1270, lr = 0.02
I0526 00:00:16.317793 15117 solver.cpp:233] Iteration 1280, loss = 0.796183
I0526 00:00:16.317998 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.796183 (* 1 = 0.796183 loss)
I0526 00:00:16.318011 15117 sgd_solver.cpp:294] Iteration 1280, lr = 0.02
I0526 00:00:22.712293 15117 solver.cpp:233] Iteration 1290, loss = 0.817495
I0526 00:00:22.712373 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.817495 (* 1 = 0.817495 loss)
I0526 00:00:22.712384 15117 sgd_solver.cpp:294] Iteration 1290, lr = 0.02
I0526 00:00:28.498765 15117 solver.cpp:342] Iteration 1300, Testing net (#0)
I0526 00:00:41.565825 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.3074
I0526 00:00:41.565892 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 3.12062 (* 1 = 3.12062 loss)
I0526 00:00:42.173002 15117 solver.cpp:233] Iteration 1300, loss = 0.914978
I0526 00:00:42.173094 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.914978 (* 1 = 0.914978 loss)
I0526 00:00:42.173106 15117 sgd_solver.cpp:294] Iteration 1300, lr = 0.02
I0526 00:00:48.571657 15117 solver.cpp:233] Iteration 1310, loss = 0.854795
I0526 00:00:48.571822 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.854795 (* 1 = 0.854795 loss)
I0526 00:00:48.571836 15117 sgd_solver.cpp:294] Iteration 1310, lr = 0.02
I0526 00:00:54.968065 15117 solver.cpp:233] Iteration 1320, loss = 0.815903
I0526 00:00:54.968147 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.815903 (* 1 = 0.815903 loss)
I0526 00:00:54.968160 15117 sgd_solver.cpp:294] Iteration 1320, lr = 0.02
I0526 00:01:01.363677 15117 solver.cpp:233] Iteration 1330, loss = 0.731764
I0526 00:01:01.363750 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.731764 (* 1 = 0.731764 loss)
I0526 00:01:01.363762 15117 sgd_solver.cpp:294] Iteration 1330, lr = 0.02
I0526 00:01:07.765765 15117 solver.cpp:233] Iteration 1340, loss = 0.826863
I0526 00:01:07.765888 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.826863 (* 1 = 0.826863 loss)
I0526 00:01:07.765902 15117 sgd_solver.cpp:294] Iteration 1340, lr = 0.02
I0526 00:01:14.166544 15117 solver.cpp:233] Iteration 1350, loss = 0.825674
I0526 00:01:14.166618 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.825674 (* 1 = 0.825674 loss)
I0526 00:01:14.166630 15117 sgd_solver.cpp:294] Iteration 1350, lr = 0.02
I0526 00:01:20.563855 15117 solver.cpp:233] Iteration 1360, loss = 0.590381
I0526 00:01:20.564092 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.590381 (* 1 = 0.590381 loss)
I0526 00:01:20.564106 15117 sgd_solver.cpp:294] Iteration 1360, lr = 0.02
I0526 00:01:26.957020 15117 solver.cpp:233] Iteration 1370, loss = 0.721901
I0526 00:01:26.957125 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.721901 (* 1 = 0.721901 loss)
I0526 00:01:26.957137 15117 sgd_solver.cpp:294] Iteration 1370, lr = 0.02
I0526 00:01:33.353540 15117 solver.cpp:233] Iteration 1380, loss = 0.737023
I0526 00:01:33.353616 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.737023 (* 1 = 0.737023 loss)
I0526 00:01:33.353628 15117 sgd_solver.cpp:294] Iteration 1380, lr = 0.02
I0526 00:01:39.747918 15117 solver.cpp:233] Iteration 1390, loss = 0.580052
I0526 00:01:39.747995 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.580052 (* 1 = 0.580052 loss)
I0526 00:01:39.748006 15117 sgd_solver.cpp:294] Iteration 1390, lr = 0.02
I0526 00:01:45.532788 15117 solver.cpp:342] Iteration 1400, Testing net (#0)
I0526 00:01:58.565935 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.404
I0526 00:01:58.566114 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 2.96064 (* 1 = 2.96064 loss)
I0526 00:01:59.172070 15117 solver.cpp:233] Iteration 1400, loss = 0.703263
I0526 00:01:59.172140 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.703263 (* 1 = 0.703263 loss)
I0526 00:01:59.172154 15117 sgd_solver.cpp:294] Iteration 1400, lr = 0.02
I0526 00:02:05.565963 15117 solver.cpp:233] Iteration 1410, loss = 0.682924
I0526 00:02:05.566040 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.682924 (* 1 = 0.682924 loss)
I0526 00:02:05.566051 15117 sgd_solver.cpp:294] Iteration 1410, lr = 0.02
I0526 00:02:11.955282 15117 solver.cpp:233] Iteration 1420, loss = 0.651947
I0526 00:02:11.955358 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.651947 (* 1 = 0.651947 loss)
I0526 00:02:11.955371 15117 sgd_solver.cpp:294] Iteration 1420, lr = 0.02
I0526 00:02:18.338671 15117 solver.cpp:233] Iteration 1430, loss = 0.740703
I0526 00:02:18.338742 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.740703 (* 1 = 0.740703 loss)
I0526 00:02:18.338754 15117 sgd_solver.cpp:294] Iteration 1430, lr = 0.02
I0526 00:02:24.723582 15117 solver.cpp:233] Iteration 1440, loss = 0.831618
I0526 00:02:24.723666 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.831618 (* 1 = 0.831618 loss)
I0526 00:02:24.723677 15117 sgd_solver.cpp:294] Iteration 1440, lr = 0.02
I0526 00:02:31.110312 15117 solver.cpp:233] Iteration 1450, loss = 0.803372
I0526 00:02:31.110477 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.803372 (* 1 = 0.803372 loss)
I0526 00:02:31.110489 15117 sgd_solver.cpp:294] Iteration 1450, lr = 0.02
I0526 00:02:37.496439 15117 solver.cpp:233] Iteration 1460, loss = 0.758453
I0526 00:02:37.496520 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.758453 (* 1 = 0.758453 loss)
I0526 00:02:37.496532 15117 sgd_solver.cpp:294] Iteration 1460, lr = 0.02
I0526 00:02:43.892922 15117 solver.cpp:233] Iteration 1470, loss = 0.728747
I0526 00:02:43.892995 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.728747 (* 1 = 0.728747 loss)
I0526 00:02:43.893007 15117 sgd_solver.cpp:294] Iteration 1470, lr = 0.02
I0526 00:02:50.284149 15117 solver.cpp:233] Iteration 1480, loss = 0.515368
I0526 00:02:50.284226 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.515368 (* 1 = 0.515368 loss)
I0526 00:02:50.284255 15117 sgd_solver.cpp:294] Iteration 1480, lr = 0.02
I0526 00:02:56.675848 15117 solver.cpp:233] Iteration 1490, loss = 0.760498
I0526 00:02:56.675932 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.760498 (* 1 = 0.760498 loss)
I0526 00:02:56.675945 15117 sgd_solver.cpp:294] Iteration 1490, lr = 0.02
I0526 00:03:02.464087 15117 solver.cpp:342] Iteration 1500, Testing net (#0)
I0526 00:03:15.508911 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.3663
I0526 00:03:15.508988 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 2.52843 (* 1 = 2.52843 loss)
I0526 00:03:16.115790 15117 solver.cpp:233] Iteration 1500, loss = 0.733276
I0526 00:03:16.115867 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.733276 (* 1 = 0.733276 loss)
I0526 00:03:16.115880 15117 sgd_solver.cpp:294] Iteration 1500, lr = 0.02
I0526 00:03:22.512468 15117 solver.cpp:233] Iteration 1510, loss = 0.71736
I0526 00:03:22.512549 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.71736 (* 1 = 0.71736 loss)
I0526 00:03:22.512562 15117 sgd_solver.cpp:294] Iteration 1510, lr = 0.02
I0526 00:03:28.909495 15117 solver.cpp:233] Iteration 1520, loss = 0.629251
I0526 00:03:28.909564 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.629251 (* 1 = 0.629251 loss)
I0526 00:03:28.909575 15117 sgd_solver.cpp:294] Iteration 1520, lr = 0.02
I0526 00:03:35.305045 15117 solver.cpp:233] Iteration 1530, loss = 0.576479
I0526 00:03:35.305294 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.576479 (* 1 = 0.576479 loss)
I0526 00:03:35.305307 15117 sgd_solver.cpp:294] Iteration 1530, lr = 0.02
I0526 00:03:41.698562 15117 solver.cpp:233] Iteration 1540, loss = 0.535909
I0526 00:03:41.698649 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.535909 (* 1 = 0.535909 loss)
I0526 00:03:41.698662 15117 sgd_solver.cpp:294] Iteration 1540, lr = 0.02
I0526 00:03:48.099416 15117 solver.cpp:233] Iteration 1550, loss = 0.578121
I0526 00:03:48.099506 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.578121 (* 1 = 0.578121 loss)
I0526 00:03:48.099520 15117 sgd_solver.cpp:294] Iteration 1550, lr = 0.02
I0526 00:03:54.507061 15117 solver.cpp:233] Iteration 1560, loss = 0.693641
I0526 00:03:54.507154 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.693641 (* 1 = 0.693641 loss)
I0526 00:03:54.507167 15117 sgd_solver.cpp:294] Iteration 1560, lr = 0.02
I0526 00:04:00.904657 15117 solver.cpp:233] Iteration 1570, loss = 0.561963
I0526 00:04:00.904743 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.561963 (* 1 = 0.561963 loss)
I0526 00:04:00.904757 15117 sgd_solver.cpp:294] Iteration 1570, lr = 0.02
I0526 00:04:07.302783 15117 solver.cpp:233] Iteration 1580, loss = 0.559751
I0526 00:04:07.302994 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.559751 (* 1 = 0.559751 loss)
I0526 00:04:07.303009 15117 sgd_solver.cpp:294] Iteration 1580, lr = 0.02
I0526 00:04:13.697371 15117 solver.cpp:233] Iteration 1590, loss = 0.725488
I0526 00:04:13.697463 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.725488 (* 1 = 0.725488 loss)
I0526 00:04:13.697477 15117 sgd_solver.cpp:294] Iteration 1590, lr = 0.02
I0526 00:04:19.489756 15117 solver.cpp:342] Iteration 1600, Testing net (#0)
I0526 00:04:32.605324 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.5655
I0526 00:04:32.605432 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.44539 (* 1 = 1.44539 loss)
I0526 00:04:33.211534 15117 solver.cpp:233] Iteration 1600, loss = 0.686986
I0526 00:04:33.211626 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.686986 (* 1 = 0.686986 loss)
I0526 00:04:33.211640 15117 sgd_solver.cpp:294] Iteration 1600, lr = 0.02
I0526 00:04:39.599230 15117 solver.cpp:233] Iteration 1610, loss = 0.679832
I0526 00:04:39.599571 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.679832 (* 1 = 0.679832 loss)
I0526 00:04:39.599593 15117 sgd_solver.cpp:294] Iteration 1610, lr = 0.02
I0526 00:04:45.991822 15117 solver.cpp:233] Iteration 1620, loss = 0.808874
I0526 00:04:45.991919 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.808874 (* 1 = 0.808874 loss)
I0526 00:04:45.991932 15117 sgd_solver.cpp:294] Iteration 1620, lr = 0.02
I0526 00:04:52.385592 15117 solver.cpp:233] Iteration 1630, loss = 0.682935
I0526 00:04:52.385675 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.682935 (* 1 = 0.682935 loss)
I0526 00:04:52.385689 15117 sgd_solver.cpp:294] Iteration 1630, lr = 0.02
I0526 00:04:58.780303 15117 solver.cpp:233] Iteration 1640, loss = 0.653262
I0526 00:04:58.780403 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.653262 (* 1 = 0.653262 loss)
I0526 00:04:58.780417 15117 sgd_solver.cpp:294] Iteration 1640, lr = 0.02
I0526 00:05:05.170408 15117 solver.cpp:233] Iteration 1650, loss = 0.553149
I0526 00:05:05.170497 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.553149 (* 1 = 0.553149 loss)
I0526 00:05:05.170511 15117 sgd_solver.cpp:294] Iteration 1650, lr = 0.02
I0526 00:05:11.563123 15117 solver.cpp:233] Iteration 1660, loss = 0.754186
I0526 00:05:11.563346 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.754186 (* 1 = 0.754186 loss)
I0526 00:05:11.563360 15117 sgd_solver.cpp:294] Iteration 1660, lr = 0.02
I0526 00:05:17.955441 15117 solver.cpp:233] Iteration 1670, loss = 0.69311
I0526 00:05:17.955533 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.69311 (* 1 = 0.69311 loss)
I0526 00:05:17.955546 15117 sgd_solver.cpp:294] Iteration 1670, lr = 0.02
I0526 00:05:24.346747 15117 solver.cpp:233] Iteration 1680, loss = 0.665276
I0526 00:05:24.346834 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.665276 (* 1 = 0.665276 loss)
I0526 00:05:24.346848 15117 sgd_solver.cpp:294] Iteration 1680, lr = 0.02
I0526 00:05:30.739773 15117 solver.cpp:233] Iteration 1690, loss = 0.833203
I0526 00:05:30.739852 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.833203 (* 1 = 0.833203 loss)
I0526 00:05:30.739864 15117 sgd_solver.cpp:294] Iteration 1690, lr = 0.02
I0526 00:05:36.522706 15117 solver.cpp:342] Iteration 1700, Testing net (#0)
I0526 00:05:49.575388 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.5732
I0526 00:05:49.575548 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.32107 (* 1 = 1.32107 loss)
I0526 00:05:50.182472 15117 solver.cpp:233] Iteration 1700, loss = 0.655049
I0526 00:05:50.182554 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.655049 (* 1 = 0.655049 loss)
I0526 00:05:50.182569 15117 sgd_solver.cpp:294] Iteration 1700, lr = 0.02
I0526 00:05:56.580219 15117 solver.cpp:233] Iteration 1710, loss = 0.733335
I0526 00:05:56.580317 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.733335 (* 1 = 0.733335 loss)
I0526 00:05:56.580330 15117 sgd_solver.cpp:294] Iteration 1710, lr = 0.02
I0526 00:06:02.979027 15117 solver.cpp:233] Iteration 1720, loss = 0.801109
I0526 00:06:02.979111 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.801109 (* 1 = 0.801109 loss)
I0526 00:06:02.979126 15117 sgd_solver.cpp:294] Iteration 1720, lr = 0.02
I0526 00:06:09.368763 15117 solver.cpp:233] Iteration 1730, loss = 0.87198
I0526 00:06:09.368840 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.87198 (* 1 = 0.87198 loss)
I0526 00:06:09.368852 15117 sgd_solver.cpp:294] Iteration 1730, lr = 0.02
I0526 00:06:15.765693 15117 solver.cpp:233] Iteration 1740, loss = 0.655716
I0526 00:06:15.765771 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.655716 (* 1 = 0.655716 loss)
I0526 00:06:15.765784 15117 sgd_solver.cpp:294] Iteration 1740, lr = 0.02
I0526 00:06:22.158370 15117 solver.cpp:233] Iteration 1750, loss = 0.513554
I0526 00:06:22.158648 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.513554 (* 1 = 0.513554 loss)
I0526 00:06:22.158666 15117 sgd_solver.cpp:294] Iteration 1750, lr = 0.02
I0526 00:06:28.549350 15117 solver.cpp:233] Iteration 1760, loss = 0.598492
I0526 00:06:28.549444 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.598492 (* 1 = 0.598492 loss)
I0526 00:06:28.549458 15117 sgd_solver.cpp:294] Iteration 1760, lr = 0.02
I0526 00:06:34.945297 15117 solver.cpp:233] Iteration 1770, loss = 0.667764
I0526 00:06:34.945394 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.667764 (* 1 = 0.667764 loss)
I0526 00:06:34.945407 15117 sgd_solver.cpp:294] Iteration 1770, lr = 0.02
I0526 00:06:41.336814 15117 solver.cpp:233] Iteration 1780, loss = 0.616675
I0526 00:06:41.336906 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.616675 (* 1 = 0.616675 loss)
I0526 00:06:41.336917 15117 sgd_solver.cpp:294] Iteration 1780, lr = 0.02
I0526 00:06:47.734519 15117 solver.cpp:233] Iteration 1790, loss = 0.656395
I0526 00:06:47.734603 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.656395 (* 1 = 0.656395 loss)
I0526 00:06:47.734616 15117 sgd_solver.cpp:294] Iteration 1790, lr = 0.02
I0526 00:06:53.526036 15117 solver.cpp:342] Iteration 1800, Testing net (#0)
I0526 00:07:06.625632 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.595
I0526 00:07:06.625704 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.42871 (* 1 = 1.42871 loss)
I0526 00:07:07.231842 15117 solver.cpp:233] Iteration 1800, loss = 0.655608
I0526 00:07:07.231930 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.655608 (* 1 = 0.655608 loss)
I0526 00:07:07.231945 15117 sgd_solver.cpp:294] Iteration 1800, lr = 0.02
I0526 00:07:13.631731 15117 solver.cpp:233] Iteration 1810, loss = 0.56069
I0526 00:07:13.631810 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.56069 (* 1 = 0.56069 loss)
I0526 00:07:13.631822 15117 sgd_solver.cpp:294] Iteration 1810, lr = 0.02
I0526 00:07:20.031150 15117 solver.cpp:233] Iteration 1820, loss = 0.843971
I0526 00:07:20.031234 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.843971 (* 1 = 0.843971 loss)
I0526 00:07:20.031247 15117 sgd_solver.cpp:294] Iteration 1820, lr = 0.02
I0526 00:07:26.434970 15117 solver.cpp:233] Iteration 1830, loss = 0.624554
I0526 00:07:26.435174 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.624554 (* 1 = 0.624554 loss)
I0526 00:07:26.435189 15117 sgd_solver.cpp:294] Iteration 1830, lr = 0.02
I0526 00:07:32.837806 15117 solver.cpp:233] Iteration 1840, loss = 0.761017
I0526 00:07:32.837898 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.761017 (* 1 = 0.761017 loss)
I0526 00:07:32.837911 15117 sgd_solver.cpp:294] Iteration 1840, lr = 0.02
I0526 00:07:39.229542 15117 solver.cpp:233] Iteration 1850, loss = 0.677427
I0526 00:07:39.229630 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.677427 (* 1 = 0.677427 loss)
I0526 00:07:39.229643 15117 sgd_solver.cpp:294] Iteration 1850, lr = 0.02
I0526 00:07:45.620239 15117 solver.cpp:233] Iteration 1860, loss = 0.678123
I0526 00:07:45.620332 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.678123 (* 1 = 0.678123 loss)
I0526 00:07:45.620343 15117 sgd_solver.cpp:294] Iteration 1860, lr = 0.02
I0526 00:07:52.019230 15117 solver.cpp:233] Iteration 1870, loss = 0.623545
I0526 00:07:52.019325 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.623545 (* 1 = 0.623545 loss)
I0526 00:07:52.019337 15117 sgd_solver.cpp:294] Iteration 1870, lr = 0.02
I0526 00:07:58.420789 15117 solver.cpp:233] Iteration 1880, loss = 0.590715
I0526 00:07:58.420994 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.590715 (* 1 = 0.590715 loss)
I0526 00:07:58.421008 15117 sgd_solver.cpp:294] Iteration 1880, lr = 0.02
I0526 00:08:04.817184 15117 solver.cpp:233] Iteration 1890, loss = 0.632923
I0526 00:08:04.817270 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.632923 (* 1 = 0.632923 loss)
I0526 00:08:04.817281 15117 sgd_solver.cpp:294] Iteration 1890, lr = 0.02
I0526 00:08:10.607235 15117 solver.cpp:342] Iteration 1900, Testing net (#0)
I0526 00:08:23.674515 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.6341
I0526 00:08:23.674588 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.1765 (* 1 = 1.1765 loss)
I0526 00:08:24.282186 15117 solver.cpp:233] Iteration 1900, loss = 0.702856
I0526 00:08:24.282266 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.702856 (* 1 = 0.702856 loss)
I0526 00:08:24.282280 15117 sgd_solver.cpp:294] Iteration 1900, lr = 0.02
I0526 00:08:30.684667 15117 solver.cpp:233] Iteration 1910, loss = 0.516764
I0526 00:08:30.684950 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.516764 (* 1 = 0.516764 loss)
I0526 00:08:30.684963 15117 sgd_solver.cpp:294] Iteration 1910, lr = 0.02
I0526 00:08:37.084166 15117 solver.cpp:233] Iteration 1920, loss = 0.500285
I0526 00:08:37.084252 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.500285 (* 1 = 0.500285 loss)
I0526 00:08:37.084264 15117 sgd_solver.cpp:294] Iteration 1920, lr = 0.02
I0526 00:08:43.474436 15117 solver.cpp:233] Iteration 1930, loss = 0.590611
I0526 00:08:43.474510 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.590611 (* 1 = 0.590611 loss)
I0526 00:08:43.474524 15117 sgd_solver.cpp:294] Iteration 1930, lr = 0.02
I0526 00:08:49.915390 15117 solver.cpp:233] Iteration 1940, loss = 0.546487
I0526 00:08:49.915475 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.546487 (* 1 = 0.546487 loss)
I0526 00:08:49.915488 15117 sgd_solver.cpp:294] Iteration 1940, lr = 0.02
I0526 00:08:56.313846 15117 solver.cpp:233] Iteration 1950, loss = 0.665842
I0526 00:08:56.313922 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.665842 (* 1 = 0.665842 loss)
I0526 00:08:56.313935 15117 sgd_solver.cpp:294] Iteration 1950, lr = 0.02
I0526 00:09:02.709681 15117 solver.cpp:233] Iteration 1960, loss = 0.529175
I0526 00:09:02.709867 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.529175 (* 1 = 0.529175 loss)
I0526 00:09:02.709880 15117 sgd_solver.cpp:294] Iteration 1960, lr = 0.02
I0526 00:09:09.099982 15117 solver.cpp:233] Iteration 1970, loss = 0.602598
I0526 00:09:09.100064 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.602598 (* 1 = 0.602598 loss)
I0526 00:09:09.100076 15117 sgd_solver.cpp:294] Iteration 1970, lr = 0.02
I0526 00:09:15.490140 15117 solver.cpp:233] Iteration 1980, loss = 0.646278
I0526 00:09:15.490226 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.646278 (* 1 = 0.646278 loss)
I0526 00:09:15.490238 15117 sgd_solver.cpp:294] Iteration 1980, lr = 0.02
I0526 00:09:21.885088 15117 solver.cpp:233] Iteration 1990, loss = 0.519239
I0526 00:09:21.885165 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.519239 (* 1 = 0.519239 loss)
I0526 00:09:21.885177 15117 sgd_solver.cpp:294] Iteration 1990, lr = 0.02
I0526 00:09:27.672952 15117 solver.cpp:342] Iteration 2000, Testing net (#0)
I0526 00:09:40.708400 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.6747
I0526 00:09:40.708585 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.925443 (* 1 = 0.925443 loss)
I0526 00:09:41.316305 15117 solver.cpp:233] Iteration 2000, loss = 0.680061
I0526 00:09:41.316385 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.680061 (* 1 = 0.680061 loss)
I0526 00:09:41.316401 15117 sgd_solver.cpp:294] Iteration 2000, lr = 0.02
I0526 00:09:47.709105 15117 solver.cpp:233] Iteration 2010, loss = 0.622188
I0526 00:09:47.709185 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.622188 (* 1 = 0.622188 loss)
I0526 00:09:47.709197 15117 sgd_solver.cpp:294] Iteration 2010, lr = 0.02
I0526 00:09:54.102738 15117 solver.cpp:233] Iteration 2020, loss = 0.593423
I0526 00:09:54.102818 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.593423 (* 1 = 0.593423 loss)
I0526 00:09:54.102830 15117 sgd_solver.cpp:294] Iteration 2020, lr = 0.02
I0526 00:10:00.495316 15117 solver.cpp:233] Iteration 2030, loss = 0.550012
I0526 00:10:00.495409 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.550012 (* 1 = 0.550012 loss)
I0526 00:10:00.495421 15117 sgd_solver.cpp:294] Iteration 2030, lr = 0.02
I0526 00:10:06.893628 15117 solver.cpp:233] Iteration 2040, loss = 0.814029
I0526 00:10:06.893709 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.814029 (* 1 = 0.814029 loss)
I0526 00:10:06.893720 15117 sgd_solver.cpp:294] Iteration 2040, lr = 0.02
I0526 00:10:13.296877 15117 solver.cpp:233] Iteration 2050, loss = 0.655092
I0526 00:10:13.297240 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.655092 (* 1 = 0.655092 loss)
I0526 00:10:13.297255 15117 sgd_solver.cpp:294] Iteration 2050, lr = 0.02
I0526 00:10:19.694360 15117 solver.cpp:233] Iteration 2060, loss = 0.835422
I0526 00:10:19.694443 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.835422 (* 1 = 0.835422 loss)
I0526 00:10:19.694458 15117 sgd_solver.cpp:294] Iteration 2060, lr = 0.02
I0526 00:10:26.093138 15117 solver.cpp:233] Iteration 2070, loss = 0.528431
I0526 00:10:26.093219 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.528431 (* 1 = 0.528431 loss)
I0526 00:10:26.093230 15117 sgd_solver.cpp:294] Iteration 2070, lr = 0.02
I0526 00:10:32.488078 15117 solver.cpp:233] Iteration 2080, loss = 0.647327
I0526 00:10:32.488154 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.647327 (* 1 = 0.647327 loss)
I0526 00:10:32.488167 15117 sgd_solver.cpp:294] Iteration 2080, lr = 0.02
I0526 00:10:38.882297 15117 solver.cpp:233] Iteration 2090, loss = 0.659309
I0526 00:10:38.882386 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.659309 (* 1 = 0.659309 loss)
I0526 00:10:38.882400 15117 sgd_solver.cpp:294] Iteration 2090, lr = 0.02
I0526 00:10:44.672521 15117 solver.cpp:342] Iteration 2100, Testing net (#0)
I0526 00:10:57.718066 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.6433
I0526 00:10:57.718138 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.14043 (* 1 = 1.14043 loss)
I0526 00:10:58.324437 15117 solver.cpp:233] Iteration 2100, loss = 0.533887
I0526 00:10:58.324532 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.533887 (* 1 = 0.533887 loss)
I0526 00:10:58.324547 15117 sgd_solver.cpp:294] Iteration 2100, lr = 0.02
I0526 00:11:04.711765 15117 solver.cpp:233] Iteration 2110, loss = 0.590827
I0526 00:11:04.711848 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.590827 (* 1 = 0.590827 loss)
I0526 00:11:04.711861 15117 sgd_solver.cpp:294] Iteration 2110, lr = 0.02
I0526 00:11:11.104321 15117 solver.cpp:233] Iteration 2120, loss = 0.656183
I0526 00:11:11.104395 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.656183 (* 1 = 0.656183 loss)
I0526 00:11:11.104408 15117 sgd_solver.cpp:294] Iteration 2120, lr = 0.02
I0526 00:11:17.501034 15117 solver.cpp:233] Iteration 2130, loss = 0.686377
I0526 00:11:17.501214 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.686377 (* 1 = 0.686377 loss)
I0526 00:11:17.501227 15117 sgd_solver.cpp:294] Iteration 2130, lr = 0.02
I0526 00:11:23.895026 15117 solver.cpp:233] Iteration 2140, loss = 0.621696
I0526 00:11:23.895109 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.621696 (* 1 = 0.621696 loss)
I0526 00:11:23.895123 15117 sgd_solver.cpp:294] Iteration 2140, lr = 0.02
I0526 00:11:30.294106 15117 solver.cpp:233] Iteration 2150, loss = 0.766686
I0526 00:11:30.294203 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.766686 (* 1 = 0.766686 loss)
I0526 00:11:30.294214 15117 sgd_solver.cpp:294] Iteration 2150, lr = 0.02
I0526 00:11:36.696482 15117 solver.cpp:233] Iteration 2160, loss = 0.601154
I0526 00:11:36.696581 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.601154 (* 1 = 0.601154 loss)
I0526 00:11:36.696593 15117 sgd_solver.cpp:294] Iteration 2160, lr = 0.02
I0526 00:11:43.096848 15117 solver.cpp:233] Iteration 2170, loss = 0.495399
I0526 00:11:43.096966 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.495399 (* 1 = 0.495399 loss)
I0526 00:11:43.096981 15117 sgd_solver.cpp:294] Iteration 2170, lr = 0.02
I0526 00:11:49.499222 15117 solver.cpp:233] Iteration 2180, loss = 0.680686
I0526 00:11:49.499505 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.680686 (* 1 = 0.680686 loss)
I0526 00:11:49.499518 15117 sgd_solver.cpp:294] Iteration 2180, lr = 0.02
I0526 00:11:55.895841 15117 solver.cpp:233] Iteration 2190, loss = 0.534927
I0526 00:11:55.895937 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.534927 (* 1 = 0.534927 loss)
I0526 00:11:55.895951 15117 sgd_solver.cpp:294] Iteration 2190, lr = 0.02
I0526 00:12:01.686295 15117 solver.cpp:342] Iteration 2200, Testing net (#0)
I0526 00:12:14.774175 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.6043
I0526 00:12:14.774269 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.38274 (* 1 = 1.38274 loss)
I0526 00:12:15.381011 15117 solver.cpp:233] Iteration 2200, loss = 0.573373
I0526 00:12:15.381098 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.573373 (* 1 = 0.573373 loss)
I0526 00:12:15.381114 15117 sgd_solver.cpp:294] Iteration 2200, lr = 0.02
I0526 00:12:21.781730 15117 solver.cpp:233] Iteration 2210, loss = 0.654444
I0526 00:12:21.781960 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.654444 (* 1 = 0.654444 loss)
I0526 00:12:21.781973 15117 sgd_solver.cpp:294] Iteration 2210, lr = 0.02
I0526 00:12:28.175487 15117 solver.cpp:233] Iteration 2220, loss = 0.630885
I0526 00:12:28.175647 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.630885 (* 1 = 0.630885 loss)
I0526 00:12:28.175663 15117 sgd_solver.cpp:294] Iteration 2220, lr = 0.02
I0526 00:12:34.567344 15117 solver.cpp:233] Iteration 2230, loss = 0.598799
I0526 00:12:34.567446 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.598799 (* 1 = 0.598799 loss)
I0526 00:12:34.567459 15117 sgd_solver.cpp:294] Iteration 2230, lr = 0.02
I0526 00:12:40.964814 15117 solver.cpp:233] Iteration 2240, loss = 0.699627
I0526 00:12:40.964913 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.699627 (* 1 = 0.699627 loss)
I0526 00:12:40.964927 15117 sgd_solver.cpp:294] Iteration 2240, lr = 0.02
I0526 00:12:47.352882 15117 solver.cpp:233] Iteration 2250, loss = 0.776445
I0526 00:12:47.352994 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.776445 (* 1 = 0.776445 loss)
I0526 00:12:47.353009 15117 sgd_solver.cpp:294] Iteration 2250, lr = 0.02
I0526 00:12:53.749300 15117 solver.cpp:233] Iteration 2260, loss = 0.571367
I0526 00:12:53.749528 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.571367 (* 1 = 0.571367 loss)
I0526 00:12:53.749541 15117 sgd_solver.cpp:294] Iteration 2260, lr = 0.02
I0526 00:13:00.156347 15117 solver.cpp:233] Iteration 2270, loss = 0.640849
I0526 00:13:00.156442 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.640849 (* 1 = 0.640849 loss)
I0526 00:13:00.156458 15117 sgd_solver.cpp:294] Iteration 2270, lr = 0.02
I0526 00:13:06.574342 15117 solver.cpp:233] Iteration 2280, loss = 0.595439
I0526 00:13:06.574432 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.595439 (* 1 = 0.595439 loss)
I0526 00:13:06.574446 15117 sgd_solver.cpp:294] Iteration 2280, lr = 0.02
I0526 00:13:12.995872 15117 solver.cpp:233] Iteration 2290, loss = 0.6194
I0526 00:13:12.995971 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.6194 (* 1 = 0.6194 loss)
I0526 00:13:12.995986 15117 sgd_solver.cpp:294] Iteration 2290, lr = 0.02
I0526 00:13:18.804738 15117 solver.cpp:342] Iteration 2300, Testing net (#0)
I0526 00:13:31.833987 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.6166
I0526 00:13:31.834202 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.08995 (* 1 = 1.08995 loss)
I0526 00:13:32.441613 15117 solver.cpp:233] Iteration 2300, loss = 0.630165
I0526 00:13:32.441709 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.630165 (* 1 = 0.630165 loss)
I0526 00:13:32.441745 15117 sgd_solver.cpp:294] Iteration 2300, lr = 0.02
I0526 00:13:38.850546 15117 solver.cpp:233] Iteration 2310, loss = 0.496684
I0526 00:13:38.850635 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.496684 (* 1 = 0.496684 loss)
I0526 00:13:38.850646 15117 sgd_solver.cpp:294] Iteration 2310, lr = 0.02
I0526 00:13:45.259991 15117 solver.cpp:233] Iteration 2320, loss = 0.612498
I0526 00:13:45.260087 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.612498 (* 1 = 0.612498 loss)
I0526 00:13:45.260099 15117 sgd_solver.cpp:294] Iteration 2320, lr = 0.02
I0526 00:13:51.679177 15117 solver.cpp:233] Iteration 2330, loss = 0.657671
I0526 00:13:51.679277 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.657671 (* 1 = 0.657671 loss)
I0526 00:13:51.679292 15117 sgd_solver.cpp:294] Iteration 2330, lr = 0.02
I0526 00:13:58.093153 15117 solver.cpp:233] Iteration 2340, loss = 0.580865
I0526 00:13:58.093253 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.580865 (* 1 = 0.580865 loss)
I0526 00:13:58.093268 15117 sgd_solver.cpp:294] Iteration 2340, lr = 0.02
I0526 00:14:04.499779 15117 solver.cpp:233] Iteration 2350, loss = 0.599495
I0526 00:14:04.500118 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.599495 (* 1 = 0.599495 loss)
I0526 00:14:04.500133 15117 sgd_solver.cpp:294] Iteration 2350, lr = 0.02
I0526 00:14:10.911108 15117 solver.cpp:233] Iteration 2360, loss = 0.560234
I0526 00:14:10.911204 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.560234 (* 1 = 0.560234 loss)
I0526 00:14:10.911219 15117 sgd_solver.cpp:294] Iteration 2360, lr = 0.02
I0526 00:14:17.318441 15117 solver.cpp:233] Iteration 2370, loss = 0.69986
I0526 00:14:17.318532 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.69986 (* 1 = 0.69986 loss)
I0526 00:14:17.318544 15117 sgd_solver.cpp:294] Iteration 2370, lr = 0.02
I0526 00:14:23.730265 15117 solver.cpp:233] Iteration 2380, loss = 0.453367
I0526 00:14:23.730340 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.453367 (* 1 = 0.453367 loss)
I0526 00:14:23.730360 15117 sgd_solver.cpp:294] Iteration 2380, lr = 0.02
I0526 00:14:30.134902 15117 solver.cpp:233] Iteration 2390, loss = 0.577859
I0526 00:14:30.134981 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.577859 (* 1 = 0.577859 loss)
I0526 00:14:30.134994 15117 sgd_solver.cpp:294] Iteration 2390, lr = 0.02
I0526 00:14:35.929329 15117 solver.cpp:342] Iteration 2400, Testing net (#0)
I0526 00:14:49.057749 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.5317
I0526 00:14:49.057833 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.43524 (* 1 = 1.43524 loss)
I0526 00:14:49.663393 15117 solver.cpp:233] Iteration 2400, loss = 0.537738
I0526 00:14:49.663468 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.537738 (* 1 = 0.537738 loss)
I0526 00:14:49.663483 15117 sgd_solver.cpp:294] Iteration 2400, lr = 0.02
I0526 00:14:56.060073 15117 solver.cpp:233] Iteration 2410, loss = 0.603754
I0526 00:14:56.060158 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.603754 (* 1 = 0.603754 loss)
I0526 00:14:56.060171 15117 sgd_solver.cpp:294] Iteration 2410, lr = 0.02
I0526 00:15:02.470777 15117 solver.cpp:233] Iteration 2420, loss = 0.587101
I0526 00:15:02.470863 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.587101 (* 1 = 0.587101 loss)
I0526 00:15:02.470876 15117 sgd_solver.cpp:294] Iteration 2420, lr = 0.02
I0526 00:15:08.872442 15117 solver.cpp:233] Iteration 2430, loss = 0.578366
I0526 00:15:08.872654 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.578366 (* 1 = 0.578366 loss)
I0526 00:15:08.872668 15117 sgd_solver.cpp:294] Iteration 2430, lr = 0.02
I0526 00:15:15.281752 15117 solver.cpp:233] Iteration 2440, loss = 0.521968
I0526 00:15:15.281846 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.521968 (* 1 = 0.521968 loss)
I0526 00:15:15.281874 15117 sgd_solver.cpp:294] Iteration 2440, lr = 0.02
I0526 00:15:21.693137 15117 solver.cpp:233] Iteration 2450, loss = 0.667341
I0526 00:15:21.693219 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.667341 (* 1 = 0.667341 loss)
I0526 00:15:21.693233 15117 sgd_solver.cpp:294] Iteration 2450, lr = 0.02
I0526 00:15:28.101282 15117 solver.cpp:233] Iteration 2460, loss = 0.585478
I0526 00:15:28.101388 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.585478 (* 1 = 0.585478 loss)
I0526 00:15:28.101405 15117 sgd_solver.cpp:294] Iteration 2460, lr = 0.02
I0526 00:15:34.502923 15117 solver.cpp:233] Iteration 2470, loss = 0.4965
I0526 00:15:34.503005 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.4965 (* 1 = 0.4965 loss)
I0526 00:15:34.503017 15117 sgd_solver.cpp:294] Iteration 2470, lr = 0.02
I0526 00:15:40.912364 15117 solver.cpp:233] Iteration 2480, loss = 0.71175
I0526 00:15:40.912683 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.71175 (* 1 = 0.71175 loss)
I0526 00:15:40.912700 15117 sgd_solver.cpp:294] Iteration 2480, lr = 0.02
I0526 00:15:47.319864 15117 solver.cpp:233] Iteration 2490, loss = 0.514744
I0526 00:15:47.319949 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.514744 (* 1 = 0.514744 loss)
I0526 00:15:47.319962 15117 sgd_solver.cpp:294] Iteration 2490, lr = 0.02
I0526 00:15:53.114367 15117 solver.cpp:342] Iteration 2500, Testing net (#0)
I0526 00:16:06.143134 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.6492
I0526 00:16:06.143231 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.16154 (* 1 = 1.16154 loss)
I0526 00:16:06.752735 15117 solver.cpp:233] Iteration 2500, loss = 0.509603
I0526 00:16:06.752837 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.509603 (* 1 = 0.509603 loss)
I0526 00:16:06.752852 15117 sgd_solver.cpp:294] Iteration 2500, lr = 0.02
I0526 00:16:13.169986 15117 solver.cpp:233] Iteration 2510, loss = 0.691294
I0526 00:16:13.170222 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.691294 (* 1 = 0.691294 loss)
I0526 00:16:13.170236 15117 sgd_solver.cpp:294] Iteration 2510, lr = 0.02
I0526 00:16:19.583205 15117 solver.cpp:233] Iteration 2520, loss = 0.677572
I0526 00:16:19.583289 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.677572 (* 1 = 0.677572 loss)
I0526 00:16:19.583300 15117 sgd_solver.cpp:294] Iteration 2520, lr = 0.02
I0526 00:16:25.995647 15117 solver.cpp:233] Iteration 2530, loss = 0.530149
I0526 00:16:25.995733 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.530149 (* 1 = 0.530149 loss)
I0526 00:16:25.995744 15117 sgd_solver.cpp:294] Iteration 2530, lr = 0.02
I0526 00:16:32.404829 15117 solver.cpp:233] Iteration 2540, loss = 0.579978
I0526 00:16:32.404918 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.579978 (* 1 = 0.579978 loss)
I0526 00:16:32.404930 15117 sgd_solver.cpp:294] Iteration 2540, lr = 0.02
I0526 00:16:38.812888 15117 solver.cpp:233] Iteration 2550, loss = 0.574992
I0526 00:16:38.812983 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.574992 (* 1 = 0.574992 loss)
I0526 00:16:38.812996 15117 sgd_solver.cpp:294] Iteration 2550, lr = 0.02
I0526 00:16:45.221515 15117 solver.cpp:233] Iteration 2560, loss = 0.583515
I0526 00:16:45.221720 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.583515 (* 1 = 0.583515 loss)
I0526 00:16:45.221735 15117 sgd_solver.cpp:294] Iteration 2560, lr = 0.02
I0526 00:16:51.632040 15117 solver.cpp:233] Iteration 2570, loss = 0.487678
I0526 00:16:51.632112 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.487678 (* 1 = 0.487678 loss)
I0526 00:16:51.632122 15117 sgd_solver.cpp:294] Iteration 2570, lr = 0.02
I0526 00:16:58.036984 15117 solver.cpp:233] Iteration 2580, loss = 0.480124
I0526 00:16:58.037091 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.480124 (* 1 = 0.480124 loss)
I0526 00:16:58.037107 15117 sgd_solver.cpp:294] Iteration 2580, lr = 0.02
I0526 00:17:04.440335 15117 solver.cpp:233] Iteration 2590, loss = 0.546394
I0526 00:17:04.440419 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.546394 (* 1 = 0.546394 loss)
I0526 00:17:04.440431 15117 sgd_solver.cpp:294] Iteration 2590, lr = 0.02
I0526 00:17:10.233038 15117 solver.cpp:342] Iteration 2600, Testing net (#0)
I0526 00:17:23.229588 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.491
I0526 00:17:23.229897 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.66516 (* 1 = 1.66516 loss)
I0526 00:17:23.838342 15117 solver.cpp:233] Iteration 2600, loss = 0.642473
I0526 00:17:23.838433 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.642473 (* 1 = 0.642473 loss)
I0526 00:17:23.838449 15117 sgd_solver.cpp:294] Iteration 2600, lr = 0.02
I0526 00:17:30.255717 15117 solver.cpp:233] Iteration 2610, loss = 0.467708
I0526 00:17:30.255800 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.467708 (* 1 = 0.467708 loss)
I0526 00:17:30.255811 15117 sgd_solver.cpp:294] Iteration 2610, lr = 0.02
I0526 00:17:36.661696 15117 solver.cpp:233] Iteration 2620, loss = 0.552006
I0526 00:17:36.661777 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.552006 (* 1 = 0.552006 loss)
I0526 00:17:36.661788 15117 sgd_solver.cpp:294] Iteration 2620, lr = 0.02
I0526 00:17:43.073724 15117 solver.cpp:233] Iteration 2630, loss = 0.602275
I0526 00:17:43.073843 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.602275 (* 1 = 0.602275 loss)
I0526 00:17:43.073859 15117 sgd_solver.cpp:294] Iteration 2630, lr = 0.02
I0526 00:17:49.482460 15117 solver.cpp:233] Iteration 2640, loss = 0.601057
I0526 00:17:49.482553 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.601057 (* 1 = 0.601057 loss)
I0526 00:17:49.482568 15117 sgd_solver.cpp:294] Iteration 2640, lr = 0.02
I0526 00:17:55.890277 15117 solver.cpp:233] Iteration 2650, loss = 0.406773
I0526 00:17:55.890480 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.406773 (* 1 = 0.406773 loss)
I0526 00:17:55.890492 15117 sgd_solver.cpp:294] Iteration 2650, lr = 0.02
I0526 00:18:02.287179 15117 solver.cpp:233] Iteration 2660, loss = 0.593018
I0526 00:18:02.287269 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.593018 (* 1 = 0.593018 loss)
I0526 00:18:02.287281 15117 sgd_solver.cpp:294] Iteration 2660, lr = 0.02
I0526 00:18:08.681246 15117 solver.cpp:233] Iteration 2670, loss = 0.522429
I0526 00:18:08.681314 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.522429 (* 1 = 0.522429 loss)
I0526 00:18:08.681327 15117 sgd_solver.cpp:294] Iteration 2670, lr = 0.02
I0526 00:18:15.077424 15117 solver.cpp:233] Iteration 2680, loss = 0.462433
I0526 00:18:15.077520 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.462433 (* 1 = 0.462433 loss)
I0526 00:18:15.077533 15117 sgd_solver.cpp:294] Iteration 2680, lr = 0.02
I0526 00:18:21.475222 15117 solver.cpp:233] Iteration 2690, loss = 0.632843
I0526 00:18:21.475317 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.632843 (* 1 = 0.632843 loss)
I0526 00:18:21.475328 15117 sgd_solver.cpp:294] Iteration 2690, lr = 0.02
I0526 00:18:27.266659 15117 solver.cpp:342] Iteration 2700, Testing net (#0)
I0526 00:18:40.273077 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.5866
I0526 00:18:40.273161 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.46946 (* 1 = 1.46946 loss)
I0526 00:18:40.878965 15117 solver.cpp:233] Iteration 2700, loss = 0.50558
I0526 00:18:40.879060 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.50558 (* 1 = 0.50558 loss)
I0526 00:18:40.879076 15117 sgd_solver.cpp:294] Iteration 2700, lr = 0.02
I0526 00:18:47.278450 15117 solver.cpp:233] Iteration 2710, loss = 0.448576
I0526 00:18:47.278535 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.448576 (* 1 = 0.448576 loss)
I0526 00:18:47.278548 15117 sgd_solver.cpp:294] Iteration 2710, lr = 0.02
I0526 00:18:53.686851 15117 solver.cpp:233] Iteration 2720, loss = 0.401334
I0526 00:18:53.686933 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.401334 (* 1 = 0.401334 loss)
I0526 00:18:53.686944 15117 sgd_solver.cpp:294] Iteration 2720, lr = 0.02
I0526 00:19:00.089622 15117 solver.cpp:233] Iteration 2730, loss = 0.6319
I0526 00:19:00.089880 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.6319 (* 1 = 0.6319 loss)
I0526 00:19:00.089895 15117 sgd_solver.cpp:294] Iteration 2730, lr = 0.02
I0526 00:19:06.488647 15117 solver.cpp:233] Iteration 2740, loss = 0.513099
I0526 00:19:06.488741 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.513099 (* 1 = 0.513099 loss)
I0526 00:19:06.488754 15117 sgd_solver.cpp:294] Iteration 2740, lr = 0.02
I0526 00:19:12.899065 15117 solver.cpp:233] Iteration 2750, loss = 0.486546
I0526 00:19:12.899164 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.486546 (* 1 = 0.486546 loss)
I0526 00:19:12.899180 15117 sgd_solver.cpp:294] Iteration 2750, lr = 0.02
I0526 00:19:19.305280 15117 solver.cpp:233] Iteration 2760, loss = 0.68012
I0526 00:19:19.305353 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.68012 (* 1 = 0.68012 loss)
I0526 00:19:19.305364 15117 sgd_solver.cpp:294] Iteration 2760, lr = 0.02
I0526 00:19:25.710316 15117 solver.cpp:233] Iteration 2770, loss = 0.533935
I0526 00:19:25.710409 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.533935 (* 1 = 0.533935 loss)
I0526 00:19:25.710424 15117 sgd_solver.cpp:294] Iteration 2770, lr = 0.02
I0526 00:19:32.116364 15117 solver.cpp:233] Iteration 2780, loss = 0.463781
I0526 00:19:32.116564 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.463781 (* 1 = 0.463781 loss)
I0526 00:19:32.116578 15117 sgd_solver.cpp:294] Iteration 2780, lr = 0.02
I0526 00:19:38.517758 15117 solver.cpp:233] Iteration 2790, loss = 0.570061
I0526 00:19:38.517853 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.570061 (* 1 = 0.570061 loss)
I0526 00:19:38.517866 15117 sgd_solver.cpp:294] Iteration 2790, lr = 0.02
I0526 00:19:44.312001 15117 solver.cpp:342] Iteration 2800, Testing net (#0)
I0526 00:19:57.316915 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.6794
I0526 00:19:57.316985 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.971512 (* 1 = 0.971512 loss)
I0526 00:19:57.924389 15117 solver.cpp:233] Iteration 2800, loss = 0.461293
I0526 00:19:57.924480 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.461293 (* 1 = 0.461293 loss)
I0526 00:19:57.924495 15117 sgd_solver.cpp:294] Iteration 2800, lr = 0.02
I0526 00:20:04.326277 15117 solver.cpp:233] Iteration 2810, loss = 0.467346
I0526 00:20:04.326457 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.467346 (* 1 = 0.467346 loss)
I0526 00:20:04.326470 15117 sgd_solver.cpp:294] Iteration 2810, lr = 0.02
I0526 00:20:10.734616 15117 solver.cpp:233] Iteration 2820, loss = 0.550005
I0526 00:20:10.734709 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.550005 (* 1 = 0.550005 loss)
I0526 00:20:10.734722 15117 sgd_solver.cpp:294] Iteration 2820, lr = 0.02
I0526 00:20:17.134780 15117 solver.cpp:233] Iteration 2830, loss = 0.631088
I0526 00:20:17.134860 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.631088 (* 1 = 0.631088 loss)
I0526 00:20:17.134873 15117 sgd_solver.cpp:294] Iteration 2830, lr = 0.02
I0526 00:20:23.534551 15117 solver.cpp:233] Iteration 2840, loss = 0.491573
I0526 00:20:23.534641 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.491573 (* 1 = 0.491573 loss)
I0526 00:20:23.534654 15117 sgd_solver.cpp:294] Iteration 2840, lr = 0.02
I0526 00:20:29.930065 15117 solver.cpp:233] Iteration 2850, loss = 0.505758
I0526 00:20:29.930141 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.505758 (* 1 = 0.505758 loss)
I0526 00:20:29.930155 15117 sgd_solver.cpp:294] Iteration 2850, lr = 0.02
I0526 00:20:36.329008 15117 solver.cpp:233] Iteration 2860, loss = 0.410708
I0526 00:20:36.329237 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.410708 (* 1 = 0.410708 loss)
I0526 00:20:36.329251 15117 sgd_solver.cpp:294] Iteration 2860, lr = 0.02
I0526 00:20:42.738917 15117 solver.cpp:233] Iteration 2870, loss = 0.649151
I0526 00:20:42.739001 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.649151 (* 1 = 0.649151 loss)
I0526 00:20:42.739013 15117 sgd_solver.cpp:294] Iteration 2870, lr = 0.02
I0526 00:20:49.142824 15117 solver.cpp:233] Iteration 2880, loss = 0.407734
I0526 00:20:49.142901 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.407734 (* 1 = 0.407734 loss)
I0526 00:20:49.142912 15117 sgd_solver.cpp:294] Iteration 2880, lr = 0.02
I0526 00:20:55.540474 15117 solver.cpp:233] Iteration 2890, loss = 0.503044
I0526 00:20:55.540565 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.503044 (* 1 = 0.503044 loss)
I0526 00:20:55.540577 15117 sgd_solver.cpp:294] Iteration 2890, lr = 0.02
I0526 00:21:01.338088 15117 solver.cpp:342] Iteration 2900, Testing net (#0)
I0526 00:21:14.353585 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.67
I0526 00:21:14.353821 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.987995 (* 1 = 0.987995 loss)
I0526 00:21:14.961472 15117 solver.cpp:233] Iteration 2900, loss = 0.606873
I0526 00:21:14.961555 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.606873 (* 1 = 0.606873 loss)
I0526 00:21:14.961568 15117 sgd_solver.cpp:294] Iteration 2900, lr = 0.02
I0526 00:21:21.366662 15117 solver.cpp:233] Iteration 2910, loss = 0.552439
I0526 00:21:21.366766 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.552439 (* 1 = 0.552439 loss)
I0526 00:21:21.366781 15117 sgd_solver.cpp:294] Iteration 2910, lr = 0.02
I0526 00:21:27.771504 15117 solver.cpp:233] Iteration 2920, loss = 0.628252
I0526 00:21:27.771594 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.628252 (* 1 = 0.628252 loss)
I0526 00:21:27.771608 15117 sgd_solver.cpp:294] Iteration 2920, lr = 0.02
I0526 00:21:34.171511 15117 solver.cpp:233] Iteration 2930, loss = 0.450947
I0526 00:21:34.171584 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.450947 (* 1 = 0.450947 loss)
I0526 00:21:34.171596 15117 sgd_solver.cpp:294] Iteration 2930, lr = 0.02
I0526 00:21:40.571058 15117 solver.cpp:233] Iteration 2940, loss = 0.493838
I0526 00:21:40.571128 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.493838 (* 1 = 0.493838 loss)
I0526 00:21:40.571141 15117 sgd_solver.cpp:294] Iteration 2940, lr = 0.02
I0526 00:21:46.969681 15117 solver.cpp:233] Iteration 2950, loss = 0.447416
I0526 00:21:46.969857 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.447416 (* 1 = 0.447416 loss)
I0526 00:21:46.969871 15117 sgd_solver.cpp:294] Iteration 2950, lr = 0.02
I0526 00:21:53.373342 15117 solver.cpp:233] Iteration 2960, loss = 0.40507
I0526 00:21:53.373414 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.40507 (* 1 = 0.40507 loss)
I0526 00:21:53.373425 15117 sgd_solver.cpp:294] Iteration 2960, lr = 0.02
I0526 00:21:59.772181 15117 solver.cpp:233] Iteration 2970, loss = 0.439316
I0526 00:21:59.772253 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.439316 (* 1 = 0.439316 loss)
I0526 00:21:59.772264 15117 sgd_solver.cpp:294] Iteration 2970, lr = 0.02
I0526 00:22:06.173215 15117 solver.cpp:233] Iteration 2980, loss = 0.549959
I0526 00:22:06.173286 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.549959 (* 1 = 0.549959 loss)
I0526 00:22:06.173298 15117 sgd_solver.cpp:294] Iteration 2980, lr = 0.02
I0526 00:22:12.572123 15117 solver.cpp:233] Iteration 2990, loss = 0.554404
I0526 00:22:12.572196 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.554404 (* 1 = 0.554404 loss)
I0526 00:22:12.572207 15117 sgd_solver.cpp:294] Iteration 2990, lr = 0.02
I0526 00:22:18.363783 15117 solver.cpp:342] Iteration 3000, Testing net (#0)
I0526 00:22:31.338551 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.6067
I0526 00:22:31.338626 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.3405 (* 1 = 1.3405 loss)
I0526 00:22:31.946195 15117 solver.cpp:233] Iteration 3000, loss = 0.535221
I0526 00:22:31.946264 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.535221 (* 1 = 0.535221 loss)
I0526 00:22:31.946279 15117 sgd_solver.cpp:294] Iteration 3000, lr = 0.02
I0526 00:22:38.335381 15117 solver.cpp:233] Iteration 3010, loss = 0.509562
I0526 00:22:38.335450 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.509562 (* 1 = 0.509562 loss)
I0526 00:22:38.335461 15117 sgd_solver.cpp:294] Iteration 3010, lr = 0.02
I0526 00:22:44.755187 15117 solver.cpp:233] Iteration 3020, loss = 0.46761
I0526 00:22:44.755259 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.46761 (* 1 = 0.46761 loss)
I0526 00:22:44.755270 15117 sgd_solver.cpp:294] Iteration 3020, lr = 0.02
I0526 00:22:51.148855 15117 solver.cpp:233] Iteration 3030, loss = 0.716233
I0526 00:22:51.149085 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.716233 (* 1 = 0.716233 loss)
I0526 00:22:51.149097 15117 sgd_solver.cpp:294] Iteration 3030, lr = 0.02
I0526 00:22:57.541007 15117 solver.cpp:233] Iteration 3040, loss = 0.530613
I0526 00:22:57.541124 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.530613 (* 1 = 0.530613 loss)
I0526 00:22:57.541138 15117 sgd_solver.cpp:294] Iteration 3040, lr = 0.02
I0526 00:23:03.948451 15117 solver.cpp:233] Iteration 3050, loss = 0.593346
I0526 00:23:03.948513 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.593346 (* 1 = 0.593346 loss)
I0526 00:23:03.948523 15117 sgd_solver.cpp:294] Iteration 3050, lr = 0.02
I0526 00:23:10.343128 15117 solver.cpp:233] Iteration 3060, loss = 0.536773
I0526 00:23:10.343194 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.536773 (* 1 = 0.536773 loss)
I0526 00:23:10.343205 15117 sgd_solver.cpp:294] Iteration 3060, lr = 0.02
I0526 00:23:16.739828 15117 solver.cpp:233] Iteration 3070, loss = 0.659326
I0526 00:23:16.739899 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.659326 (* 1 = 0.659326 loss)
I0526 00:23:16.739910 15117 sgd_solver.cpp:294] Iteration 3070, lr = 0.02
I0526 00:23:23.134440 15117 solver.cpp:233] Iteration 3080, loss = 0.564354
I0526 00:23:23.134567 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.564354 (* 1 = 0.564354 loss)
I0526 00:23:23.134578 15117 sgd_solver.cpp:294] Iteration 3080, lr = 0.02
I0526 00:23:29.526645 15117 solver.cpp:233] Iteration 3090, loss = 0.418164
I0526 00:23:29.526720 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.418164 (* 1 = 0.418164 loss)
I0526 00:23:29.526731 15117 sgd_solver.cpp:294] Iteration 3090, lr = 0.02
I0526 00:23:35.300756 15117 solver.cpp:342] Iteration 3100, Testing net (#0)
I0526 00:23:48.315474 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.6877
I0526 00:23:48.315537 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.03339 (* 1 = 1.03339 loss)
I0526 00:23:48.921092 15117 solver.cpp:233] Iteration 3100, loss = 0.399813
I0526 00:23:48.921160 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.399813 (* 1 = 0.399813 loss)
I0526 00:23:48.921174 15117 sgd_solver.cpp:294] Iteration 3100, lr = 0.02
I0526 00:23:55.300613 15117 solver.cpp:233] Iteration 3110, loss = 0.355621
I0526 00:23:55.300796 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.355621 (* 1 = 0.355621 loss)
I0526 00:23:55.300807 15117 sgd_solver.cpp:294] Iteration 3110, lr = 0.02
I0526 00:24:01.685505 15117 solver.cpp:233] Iteration 3120, loss = 0.581875
I0526 00:24:01.685577 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.581875 (* 1 = 0.581875 loss)
I0526 00:24:01.685588 15117 sgd_solver.cpp:294] Iteration 3120, lr = 0.02
I0526 00:24:08.068104 15117 solver.cpp:233] Iteration 3130, loss = 0.626401
I0526 00:24:08.068176 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.626401 (* 1 = 0.626401 loss)
I0526 00:24:08.068198 15117 sgd_solver.cpp:294] Iteration 3130, lr = 0.02
I0526 00:24:14.449692 15117 solver.cpp:233] Iteration 3140, loss = 0.550329
I0526 00:24:14.449762 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.550329 (* 1 = 0.550329 loss)
I0526 00:24:14.449774 15117 sgd_solver.cpp:294] Iteration 3140, lr = 0.02
I0526 00:24:20.827971 15117 solver.cpp:233] Iteration 3150, loss = 0.467052
I0526 00:24:20.828042 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.467052 (* 1 = 0.467052 loss)
I0526 00:24:20.828052 15117 sgd_solver.cpp:294] Iteration 3150, lr = 0.02
I0526 00:24:27.210101 15117 solver.cpp:233] Iteration 3160, loss = 0.537173
I0526 00:24:27.210317 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.537173 (* 1 = 0.537173 loss)
I0526 00:24:27.210328 15117 sgd_solver.cpp:294] Iteration 3160, lr = 0.02
I0526 00:24:33.591900 15117 solver.cpp:233] Iteration 3170, loss = 0.416402
I0526 00:24:33.591969 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.416402 (* 1 = 0.416402 loss)
I0526 00:24:33.591980 15117 sgd_solver.cpp:294] Iteration 3170, lr = 0.02
I0526 00:24:39.977054 15117 solver.cpp:233] Iteration 3180, loss = 0.62002
I0526 00:24:39.977130 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.62002 (* 1 = 0.62002 loss)
I0526 00:24:39.977141 15117 sgd_solver.cpp:294] Iteration 3180, lr = 0.02
I0526 00:24:46.357519 15117 solver.cpp:233] Iteration 3190, loss = 0.363487
I0526 00:24:46.357591 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.363487 (* 1 = 0.363487 loss)
I0526 00:24:46.357602 15117 sgd_solver.cpp:294] Iteration 3190, lr = 0.02
I0526 00:24:52.135928 15117 solver.cpp:342] Iteration 3200, Testing net (#0)
I0526 00:25:05.132164 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7006
I0526 00:25:05.132316 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.895362 (* 1 = 0.895362 loss)
I0526 00:25:05.738101 15117 solver.cpp:233] Iteration 3200, loss = 0.469785
I0526 00:25:05.738168 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.469785 (* 1 = 0.469785 loss)
I0526 00:25:05.738180 15117 sgd_solver.cpp:294] Iteration 3200, lr = 0.02
I0526 00:25:12.119706 15117 solver.cpp:233] Iteration 3210, loss = 0.520023
I0526 00:25:12.119778 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.520023 (* 1 = 0.520023 loss)
I0526 00:25:12.119789 15117 sgd_solver.cpp:294] Iteration 3210, lr = 0.02
I0526 00:25:18.500398 15117 solver.cpp:233] Iteration 3220, loss = 0.477014
I0526 00:25:18.500468 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.477014 (* 1 = 0.477014 loss)
I0526 00:25:18.500479 15117 sgd_solver.cpp:294] Iteration 3220, lr = 0.02
I0526 00:25:24.882351 15117 solver.cpp:233] Iteration 3230, loss = 0.418485
I0526 00:25:24.882423 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.418485 (* 1 = 0.418485 loss)
I0526 00:25:24.882434 15117 sgd_solver.cpp:294] Iteration 3230, lr = 0.02
I0526 00:25:31.263172 15117 solver.cpp:233] Iteration 3240, loss = 0.555454
I0526 00:25:31.263242 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.555454 (* 1 = 0.555454 loss)
I0526 00:25:31.263252 15117 sgd_solver.cpp:294] Iteration 3240, lr = 0.02
I0526 00:25:37.649047 15117 solver.cpp:233] Iteration 3250, loss = 0.426408
I0526 00:25:37.649194 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.426408 (* 1 = 0.426408 loss)
I0526 00:25:37.649205 15117 sgd_solver.cpp:294] Iteration 3250, lr = 0.02
I0526 00:25:44.032469 15117 solver.cpp:233] Iteration 3260, loss = 0.60497
I0526 00:25:44.032537 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.60497 (* 1 = 0.60497 loss)
I0526 00:25:44.032548 15117 sgd_solver.cpp:294] Iteration 3260, lr = 0.02
I0526 00:25:50.417582 15117 solver.cpp:233] Iteration 3270, loss = 0.587313
I0526 00:25:50.417650 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.587313 (* 1 = 0.587313 loss)
I0526 00:25:50.417661 15117 sgd_solver.cpp:294] Iteration 3270, lr = 0.02
I0526 00:25:56.795629 15117 solver.cpp:233] Iteration 3280, loss = 0.414824
I0526 00:25:56.795697 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.414824 (* 1 = 0.414824 loss)
I0526 00:25:56.795707 15117 sgd_solver.cpp:294] Iteration 3280, lr = 0.02
I0526 00:26:03.178237 15117 solver.cpp:233] Iteration 3290, loss = 0.42973
I0526 00:26:03.178309 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.42973 (* 1 = 0.42973 loss)
I0526 00:26:03.178320 15117 sgd_solver.cpp:294] Iteration 3290, lr = 0.02
I0526 00:26:08.951799 15117 solver.cpp:342] Iteration 3300, Testing net (#0)
I0526 00:26:21.994024 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.6706
I0526 00:26:21.994091 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.971042 (* 1 = 0.971042 loss)
I0526 00:26:22.598914 15117 solver.cpp:233] Iteration 3300, loss = 0.587321
I0526 00:26:22.598984 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.587321 (* 1 = 0.587321 loss)
I0526 00:26:22.598996 15117 sgd_solver.cpp:294] Iteration 3300, lr = 0.02
I0526 00:26:28.986946 15117 solver.cpp:233] Iteration 3310, loss = 0.489804
I0526 00:26:28.987018 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.489804 (* 1 = 0.489804 loss)
I0526 00:26:28.987030 15117 sgd_solver.cpp:294] Iteration 3310, lr = 0.02
I0526 00:26:35.372467 15117 solver.cpp:233] Iteration 3320, loss = 0.301803
I0526 00:26:35.372534 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.301803 (* 1 = 0.301803 loss)
I0526 00:26:35.372546 15117 sgd_solver.cpp:294] Iteration 3320, lr = 0.02
I0526 00:26:41.760066 15117 solver.cpp:233] Iteration 3330, loss = 0.491868
I0526 00:26:41.760228 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.491868 (* 1 = 0.491868 loss)
I0526 00:26:41.760241 15117 sgd_solver.cpp:294] Iteration 3330, lr = 0.02
I0526 00:26:48.144531 15117 solver.cpp:233] Iteration 3340, loss = 0.49167
I0526 00:26:48.144601 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.49167 (* 1 = 0.49167 loss)
I0526 00:26:48.144613 15117 sgd_solver.cpp:294] Iteration 3340, lr = 0.02
I0526 00:26:54.528486 15117 solver.cpp:233] Iteration 3350, loss = 0.363396
I0526 00:26:54.528553 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.363396 (* 1 = 0.363396 loss)
I0526 00:26:54.528563 15117 sgd_solver.cpp:294] Iteration 3350, lr = 0.02
I0526 00:27:00.908782 15117 solver.cpp:233] Iteration 3360, loss = 0.568228
I0526 00:27:00.908850 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.568228 (* 1 = 0.568228 loss)
I0526 00:27:00.908861 15117 sgd_solver.cpp:294] Iteration 3360, lr = 0.02
I0526 00:27:07.293368 15117 solver.cpp:233] Iteration 3370, loss = 0.573653
I0526 00:27:07.293442 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.573653 (* 1 = 0.573653 loss)
I0526 00:27:07.293454 15117 sgd_solver.cpp:294] Iteration 3370, lr = 0.02
I0526 00:27:13.677356 15117 solver.cpp:233] Iteration 3380, loss = 0.384334
I0526 00:27:13.677510 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.384334 (* 1 = 0.384334 loss)
I0526 00:27:13.677521 15117 sgd_solver.cpp:294] Iteration 3380, lr = 0.02
I0526 00:27:20.060077 15117 solver.cpp:233] Iteration 3390, loss = 0.706883
I0526 00:27:20.060147 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.706883 (* 1 = 0.706883 loss)
I0526 00:27:20.060156 15117 sgd_solver.cpp:294] Iteration 3390, lr = 0.02
I0526 00:27:25.836827 15117 solver.cpp:342] Iteration 3400, Testing net (#0)
I0526 00:27:38.894435 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.6698
I0526 00:27:38.894497 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.03959 (* 1 = 1.03959 loss)
I0526 00:27:39.500494 15117 solver.cpp:233] Iteration 3400, loss = 0.507345
I0526 00:27:39.500566 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.507345 (* 1 = 0.507345 loss)
I0526 00:27:39.500577 15117 sgd_solver.cpp:294] Iteration 3400, lr = 0.02
I0526 00:27:45.885283 15117 solver.cpp:233] Iteration 3410, loss = 0.492863
I0526 00:27:45.885479 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.492863 (* 1 = 0.492863 loss)
I0526 00:27:45.885491 15117 sgd_solver.cpp:294] Iteration 3410, lr = 0.02
I0526 00:27:52.269150 15117 solver.cpp:233] Iteration 3420, loss = 0.582953
I0526 00:27:52.269215 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.582953 (* 1 = 0.582953 loss)
I0526 00:27:52.269227 15117 sgd_solver.cpp:294] Iteration 3420, lr = 0.02
I0526 00:27:58.654317 15117 solver.cpp:233] Iteration 3430, loss = 0.554035
I0526 00:27:58.654386 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.554035 (* 1 = 0.554035 loss)
I0526 00:27:58.654397 15117 sgd_solver.cpp:294] Iteration 3430, lr = 0.02
I0526 00:28:05.034209 15117 solver.cpp:233] Iteration 3440, loss = 0.546536
I0526 00:28:05.034272 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.546536 (* 1 = 0.546536 loss)
I0526 00:28:05.034284 15117 sgd_solver.cpp:294] Iteration 3440, lr = 0.02
I0526 00:28:11.419091 15117 solver.cpp:233] Iteration 3450, loss = 0.372187
I0526 00:28:11.419157 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.372187 (* 1 = 0.372187 loss)
I0526 00:28:11.419168 15117 sgd_solver.cpp:294] Iteration 3450, lr = 0.02
I0526 00:28:17.799773 15117 solver.cpp:233] Iteration 3460, loss = 0.676105
I0526 00:28:17.799919 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.676105 (* 1 = 0.676105 loss)
I0526 00:28:17.799932 15117 sgd_solver.cpp:294] Iteration 3460, lr = 0.02
I0526 00:28:24.182202 15117 solver.cpp:233] Iteration 3470, loss = 0.516039
I0526 00:28:24.182271 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.516039 (* 1 = 0.516039 loss)
I0526 00:28:24.182282 15117 sgd_solver.cpp:294] Iteration 3470, lr = 0.02
I0526 00:28:30.566345 15117 solver.cpp:233] Iteration 3480, loss = 0.516146
I0526 00:28:30.566421 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.516146 (* 1 = 0.516146 loss)
I0526 00:28:30.566432 15117 sgd_solver.cpp:294] Iteration 3480, lr = 0.02
I0526 00:28:36.950201 15117 solver.cpp:233] Iteration 3490, loss = 0.299718
I0526 00:28:36.950268 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.299718 (* 1 = 0.299718 loss)
I0526 00:28:36.950279 15117 sgd_solver.cpp:294] Iteration 3490, lr = 0.02
I0526 00:28:42.728601 15117 solver.cpp:342] Iteration 3500, Testing net (#0)
I0526 00:28:55.730468 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7775
I0526 00:28:55.730612 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.640146 (* 1 = 0.640146 loss)
I0526 00:28:56.335238 15117 solver.cpp:233] Iteration 3500, loss = 0.504288
I0526 00:28:56.335304 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.504288 (* 1 = 0.504288 loss)
I0526 00:28:56.335314 15117 sgd_solver.cpp:294] Iteration 3500, lr = 0.02
I0526 00:29:02.716842 15117 solver.cpp:233] Iteration 3510, loss = 0.591116
I0526 00:29:02.716914 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.591116 (* 1 = 0.591116 loss)
I0526 00:29:02.716927 15117 sgd_solver.cpp:294] Iteration 3510, lr = 0.02
I0526 00:29:09.096091 15117 solver.cpp:233] Iteration 3520, loss = 0.497367
I0526 00:29:09.096158 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.497367 (* 1 = 0.497367 loss)
I0526 00:29:09.096168 15117 sgd_solver.cpp:294] Iteration 3520, lr = 0.02
I0526 00:29:15.475463 15117 solver.cpp:233] Iteration 3530, loss = 0.436128
I0526 00:29:15.475534 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.436128 (* 1 = 0.436128 loss)
I0526 00:29:15.475545 15117 sgd_solver.cpp:294] Iteration 3530, lr = 0.02
I0526 00:29:21.854714 15117 solver.cpp:233] Iteration 3540, loss = 0.435631
I0526 00:29:21.854778 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.435631 (* 1 = 0.435631 loss)
I0526 00:29:21.854789 15117 sgd_solver.cpp:294] Iteration 3540, lr = 0.02
I0526 00:29:28.228937 15117 solver.cpp:233] Iteration 3550, loss = 0.529321
I0526 00:29:28.229172 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.529321 (* 1 = 0.529321 loss)
I0526 00:29:28.229185 15117 sgd_solver.cpp:294] Iteration 3550, lr = 0.02
I0526 00:29:34.612210 15117 solver.cpp:233] Iteration 3560, loss = 0.47517
I0526 00:29:34.612279 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.47517 (* 1 = 0.47517 loss)
I0526 00:29:34.612289 15117 sgd_solver.cpp:294] Iteration 3560, lr = 0.02
I0526 00:29:40.992813 15117 solver.cpp:233] Iteration 3570, loss = 0.506252
I0526 00:29:40.992879 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.506252 (* 1 = 0.506252 loss)
I0526 00:29:40.992892 15117 sgd_solver.cpp:294] Iteration 3570, lr = 0.02
I0526 00:29:47.370797 15117 solver.cpp:233] Iteration 3580, loss = 0.43124
I0526 00:29:47.370862 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.43124 (* 1 = 0.43124 loss)
I0526 00:29:47.370872 15117 sgd_solver.cpp:294] Iteration 3580, lr = 0.02
I0526 00:29:53.752410 15117 solver.cpp:233] Iteration 3590, loss = 0.412062
I0526 00:29:53.752475 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.412062 (* 1 = 0.412062 loss)
I0526 00:29:53.752485 15117 sgd_solver.cpp:294] Iteration 3590, lr = 0.02
I0526 00:29:59.541091 15117 solver.cpp:342] Iteration 3600, Testing net (#0)
I0526 00:30:12.543709 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7614
I0526 00:30:12.543776 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.698946 (* 1 = 0.698946 loss)
I0526 00:30:13.150589 15117 solver.cpp:233] Iteration 3600, loss = 0.492599
I0526 00:30:13.150656 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.492599 (* 1 = 0.492599 loss)
I0526 00:30:13.150671 15117 sgd_solver.cpp:294] Iteration 3600, lr = 0.02
I0526 00:30:19.544692 15117 solver.cpp:233] Iteration 3610, loss = 0.406987
I0526 00:30:19.544762 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.406987 (* 1 = 0.406987 loss)
I0526 00:30:19.544773 15117 sgd_solver.cpp:294] Iteration 3610, lr = 0.02
I0526 00:30:25.924100 15117 solver.cpp:233] Iteration 3620, loss = 0.579075
I0526 00:30:25.924168 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.579075 (* 1 = 0.579075 loss)
I0526 00:30:25.924180 15117 sgd_solver.cpp:294] Iteration 3620, lr = 0.02
I0526 00:30:32.301811 15117 solver.cpp:233] Iteration 3630, loss = 0.346862
I0526 00:30:32.301962 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.346862 (* 1 = 0.346862 loss)
I0526 00:30:32.301975 15117 sgd_solver.cpp:294] Iteration 3630, lr = 0.02
I0526 00:30:38.679857 15117 solver.cpp:233] Iteration 3640, loss = 0.531826
I0526 00:30:38.679921 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.531826 (* 1 = 0.531826 loss)
I0526 00:30:38.679934 15117 sgd_solver.cpp:294] Iteration 3640, lr = 0.02
I0526 00:30:45.058815 15117 solver.cpp:233] Iteration 3650, loss = 0.519535
I0526 00:30:45.058887 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.519535 (* 1 = 0.519535 loss)
I0526 00:30:45.058897 15117 sgd_solver.cpp:294] Iteration 3650, lr = 0.02
I0526 00:30:51.432927 15117 solver.cpp:233] Iteration 3660, loss = 0.521974
I0526 00:30:51.432992 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.521974 (* 1 = 0.521974 loss)
I0526 00:30:51.433002 15117 sgd_solver.cpp:294] Iteration 3660, lr = 0.02
I0526 00:30:57.814725 15117 solver.cpp:233] Iteration 3670, loss = 0.447169
I0526 00:30:57.814802 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.447169 (* 1 = 0.447169 loss)
I0526 00:30:57.814815 15117 sgd_solver.cpp:294] Iteration 3670, lr = 0.02
I0526 00:31:04.195613 15117 solver.cpp:233] Iteration 3680, loss = 0.438571
I0526 00:31:04.195747 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.438571 (* 1 = 0.438571 loss)
I0526 00:31:04.195760 15117 sgd_solver.cpp:294] Iteration 3680, lr = 0.02
I0526 00:31:10.571972 15117 solver.cpp:233] Iteration 3690, loss = 0.506335
I0526 00:31:10.572041 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.506335 (* 1 = 0.506335 loss)
I0526 00:31:10.572062 15117 sgd_solver.cpp:294] Iteration 3690, lr = 0.02
I0526 00:31:16.343597 15117 solver.cpp:342] Iteration 3700, Testing net (#0)
I0526 00:31:29.331356 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7222
I0526 00:31:29.331425 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.768185 (* 1 = 0.768185 loss)
I0526 00:31:29.937057 15117 solver.cpp:233] Iteration 3700, loss = 0.44144
I0526 00:31:29.937120 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.44144 (* 1 = 0.44144 loss)
I0526 00:31:29.937134 15117 sgd_solver.cpp:294] Iteration 3700, lr = 0.02
I0526 00:31:36.315873 15117 solver.cpp:233] Iteration 3710, loss = 0.338012
I0526 00:31:36.316073 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.338012 (* 1 = 0.338012 loss)
I0526 00:31:36.316085 15117 sgd_solver.cpp:294] Iteration 3710, lr = 0.02
I0526 00:31:42.694061 15117 solver.cpp:233] Iteration 3720, loss = 0.397479
I0526 00:31:42.694149 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.397479 (* 1 = 0.397479 loss)
I0526 00:31:42.694162 15117 sgd_solver.cpp:294] Iteration 3720, lr = 0.02
I0526 00:31:49.073724 15117 solver.cpp:233] Iteration 3730, loss = 0.380055
I0526 00:31:49.073797 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.380055 (* 1 = 0.380055 loss)
I0526 00:31:49.073807 15117 sgd_solver.cpp:294] Iteration 3730, lr = 0.02
I0526 00:31:55.451083 15117 solver.cpp:233] Iteration 3740, loss = 0.454848
I0526 00:31:55.451150 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.454848 (* 1 = 0.454848 loss)
I0526 00:31:55.451161 15117 sgd_solver.cpp:294] Iteration 3740, lr = 0.02
I0526 00:32:01.831244 15117 solver.cpp:233] Iteration 3750, loss = 0.405723
I0526 00:32:01.831313 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.405723 (* 1 = 0.405723 loss)
I0526 00:32:01.831323 15117 sgd_solver.cpp:294] Iteration 3750, lr = 0.02
I0526 00:32:08.212211 15117 solver.cpp:233] Iteration 3760, loss = 0.432446
I0526 00:32:08.212364 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.432446 (* 1 = 0.432446 loss)
I0526 00:32:08.212376 15117 sgd_solver.cpp:294] Iteration 3760, lr = 0.02
I0526 00:32:14.587890 15117 solver.cpp:233] Iteration 3770, loss = 0.477929
I0526 00:32:14.587961 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.477929 (* 1 = 0.477929 loss)
I0526 00:32:14.587972 15117 sgd_solver.cpp:294] Iteration 3770, lr = 0.02
I0526 00:32:20.965769 15117 solver.cpp:233] Iteration 3780, loss = 0.632178
I0526 00:32:20.965834 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.632178 (* 1 = 0.632178 loss)
I0526 00:32:20.965845 15117 sgd_solver.cpp:294] Iteration 3780, lr = 0.02
I0526 00:32:27.343255 15117 solver.cpp:233] Iteration 3790, loss = 0.447173
I0526 00:32:27.343319 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.447173 (* 1 = 0.447173 loss)
I0526 00:32:27.343330 15117 sgd_solver.cpp:294] Iteration 3790, lr = 0.02
I0526 00:32:33.144173 15117 solver.cpp:342] Iteration 3800, Testing net (#0)
I0526 00:32:46.329033 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.719
I0526 00:32:46.329198 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.884768 (* 1 = 0.884768 loss)
I0526 00:32:46.935180 15117 solver.cpp:233] Iteration 3800, loss = 0.58775
I0526 00:32:46.935248 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.58775 (* 1 = 0.58775 loss)
I0526 00:32:46.935261 15117 sgd_solver.cpp:294] Iteration 3800, lr = 0.02
I0526 00:32:53.315686 15117 solver.cpp:233] Iteration 3810, loss = 0.452393
I0526 00:32:53.315754 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.452393 (* 1 = 0.452393 loss)
I0526 00:32:53.315767 15117 sgd_solver.cpp:294] Iteration 3810, lr = 0.02
I0526 00:32:59.697595 15117 solver.cpp:233] Iteration 3820, loss = 0.438029
I0526 00:32:59.697686 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.438029 (* 1 = 0.438029 loss)
I0526 00:32:59.697716 15117 sgd_solver.cpp:294] Iteration 3820, lr = 0.02
I0526 00:33:06.078649 15117 solver.cpp:233] Iteration 3830, loss = 0.293765
I0526 00:33:06.078737 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.293765 (* 1 = 0.293765 loss)
I0526 00:33:06.078748 15117 sgd_solver.cpp:294] Iteration 3830, lr = 0.02
I0526 00:33:12.483605 15117 solver.cpp:233] Iteration 3840, loss = 0.582839
I0526 00:33:12.483717 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.582839 (* 1 = 0.582839 loss)
I0526 00:33:12.483731 15117 sgd_solver.cpp:294] Iteration 3840, lr = 0.02
I0526 00:33:18.897234 15117 solver.cpp:233] Iteration 3850, loss = 0.44306
I0526 00:33:18.897500 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.44306 (* 1 = 0.44306 loss)
I0526 00:33:18.897512 15117 sgd_solver.cpp:294] Iteration 3850, lr = 0.02
I0526 00:33:25.292732 15117 solver.cpp:233] Iteration 3860, loss = 0.490301
I0526 00:33:25.292831 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.490301 (* 1 = 0.490301 loss)
I0526 00:33:25.292843 15117 sgd_solver.cpp:294] Iteration 3860, lr = 0.02
I0526 00:33:31.749517 15117 solver.cpp:233] Iteration 3870, loss = 0.397072
I0526 00:33:31.749617 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.397072 (* 1 = 0.397072 loss)
I0526 00:33:31.749636 15117 sgd_solver.cpp:294] Iteration 3870, lr = 0.02
I0526 00:33:38.142835 15117 solver.cpp:233] Iteration 3880, loss = 0.381693
I0526 00:33:38.142925 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.381693 (* 1 = 0.381693 loss)
I0526 00:33:38.142936 15117 sgd_solver.cpp:294] Iteration 3880, lr = 0.02
I0526 00:33:44.553051 15117 solver.cpp:233] Iteration 3890, loss = 0.483362
I0526 00:33:44.553124 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.483362 (* 1 = 0.483362 loss)
I0526 00:33:44.553135 15117 sgd_solver.cpp:294] Iteration 3890, lr = 0.02
I0526 00:33:50.361328 15117 solver.cpp:342] Iteration 3900, Testing net (#0)
I0526 00:34:03.626912 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7227
I0526 00:34:03.626981 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.895865 (* 1 = 0.895865 loss)
I0526 00:34:04.241622 15117 solver.cpp:233] Iteration 3900, loss = 0.403128
I0526 00:34:04.241691 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.403128 (* 1 = 0.403128 loss)
I0526 00:34:04.241711 15117 sgd_solver.cpp:294] Iteration 3900, lr = 0.02
I0526 00:34:10.700151 15117 solver.cpp:233] Iteration 3910, loss = 0.362991
I0526 00:34:10.700234 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.362991 (* 1 = 0.362991 loss)
I0526 00:34:10.700245 15117 sgd_solver.cpp:294] Iteration 3910, lr = 0.02
I0526 00:34:17.101929 15117 solver.cpp:233] Iteration 3920, loss = 0.484072
I0526 00:34:17.102022 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.484072 (* 1 = 0.484072 loss)
I0526 00:34:17.102035 15117 sgd_solver.cpp:294] Iteration 3920, lr = 0.02
I0526 00:34:23.490746 15117 solver.cpp:233] Iteration 3930, loss = 0.496344
I0526 00:34:23.490908 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.496344 (* 1 = 0.496344 loss)
I0526 00:34:23.490921 15117 sgd_solver.cpp:294] Iteration 3930, lr = 0.02
I0526 00:34:29.883653 15117 solver.cpp:233] Iteration 3940, loss = 0.355876
I0526 00:34:29.883718 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.355876 (* 1 = 0.355876 loss)
I0526 00:34:29.883729 15117 sgd_solver.cpp:294] Iteration 3940, lr = 0.02
I0526 00:34:36.276254 15117 solver.cpp:233] Iteration 3950, loss = 0.452094
I0526 00:34:36.276330 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.452094 (* 1 = 0.452094 loss)
I0526 00:34:36.276342 15117 sgd_solver.cpp:294] Iteration 3950, lr = 0.02
I0526 00:34:42.676019 15117 solver.cpp:233] Iteration 3960, loss = 0.401416
I0526 00:34:42.676110 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.401416 (* 1 = 0.401416 loss)
I0526 00:34:42.676123 15117 sgd_solver.cpp:294] Iteration 3960, lr = 0.02
I0526 00:34:49.097254 15117 solver.cpp:233] Iteration 3970, loss = 0.43204
I0526 00:34:49.097327 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.43204 (* 1 = 0.43204 loss)
I0526 00:34:49.097339 15117 sgd_solver.cpp:294] Iteration 3970, lr = 0.02
I0526 00:34:55.556754 15117 solver.cpp:233] Iteration 3980, loss = 0.388145
I0526 00:34:55.557003 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.388145 (* 1 = 0.388145 loss)
I0526 00:34:55.557015 15117 sgd_solver.cpp:294] Iteration 3980, lr = 0.02
I0526 00:35:01.971381 15117 solver.cpp:233] Iteration 3990, loss = 0.414459
I0526 00:35:01.971472 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.414459 (* 1 = 0.414459 loss)
I0526 00:35:01.971483 15117 sgd_solver.cpp:294] Iteration 3990, lr = 0.02
I0526 00:35:07.753163 15117 solver.cpp:342] Iteration 4000, Testing net (#0)
I0526 00:35:20.895012 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7569
I0526 00:35:20.895084 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.72196 (* 1 = 0.72196 loss)
I0526 00:35:21.500928 15117 solver.cpp:233] Iteration 4000, loss = 0.451462
I0526 00:35:21.501032 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.451462 (* 1 = 0.451462 loss)
I0526 00:35:21.501054 15117 sgd_solver.cpp:294] Iteration 4000, lr = 0.02
I0526 00:35:27.881081 15117 solver.cpp:233] Iteration 4010, loss = 0.442589
I0526 00:35:27.881340 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.442589 (* 1 = 0.442589 loss)
I0526 00:35:27.881357 15117 sgd_solver.cpp:294] Iteration 4010, lr = 0.02
I0526 00:35:34.256606 15117 solver.cpp:233] Iteration 4020, loss = 0.371035
I0526 00:35:34.256677 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.371035 (* 1 = 0.371035 loss)
I0526 00:35:34.256687 15117 sgd_solver.cpp:294] Iteration 4020, lr = 0.02
I0526 00:35:40.637589 15117 solver.cpp:233] Iteration 4030, loss = 0.548946
I0526 00:35:40.637658 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.548946 (* 1 = 0.548946 loss)
I0526 00:35:40.637670 15117 sgd_solver.cpp:294] Iteration 4030, lr = 0.02
I0526 00:35:47.022933 15117 solver.cpp:233] Iteration 4040, loss = 0.369172
I0526 00:35:47.023001 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.369172 (* 1 = 0.369172 loss)
I0526 00:35:47.023012 15117 sgd_solver.cpp:294] Iteration 4040, lr = 0.02
I0526 00:35:53.434242 15117 solver.cpp:233] Iteration 4050, loss = 0.461922
I0526 00:35:53.434310 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.461922 (* 1 = 0.461922 loss)
I0526 00:35:53.434321 15117 sgd_solver.cpp:294] Iteration 4050, lr = 0.02
I0526 00:35:59.837393 15117 solver.cpp:233] Iteration 4060, loss = 0.450966
I0526 00:35:59.837566 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.450966 (* 1 = 0.450966 loss)
I0526 00:35:59.837579 15117 sgd_solver.cpp:294] Iteration 4060, lr = 0.02
I0526 00:36:06.268975 15117 solver.cpp:233] Iteration 4070, loss = 0.55128
I0526 00:36:06.269039 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.55128 (* 1 = 0.55128 loss)
I0526 00:36:06.269050 15117 sgd_solver.cpp:294] Iteration 4070, lr = 0.02
I0526 00:36:12.668551 15117 solver.cpp:233] Iteration 4080, loss = 0.386552
I0526 00:36:12.668633 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.386552 (* 1 = 0.386552 loss)
I0526 00:36:12.668647 15117 sgd_solver.cpp:294] Iteration 4080, lr = 0.02
I0526 00:36:19.042333 15117 solver.cpp:233] Iteration 4090, loss = 0.613261
I0526 00:36:19.042398 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.613261 (* 1 = 0.613261 loss)
I0526 00:36:19.042408 15117 sgd_solver.cpp:294] Iteration 4090, lr = 0.02
I0526 00:36:24.806421 15117 solver.cpp:342] Iteration 4100, Testing net (#0)
I0526 00:36:37.848067 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7132
I0526 00:36:37.848304 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.815045 (* 1 = 0.815045 loss)
I0526 00:36:38.452522 15117 solver.cpp:233] Iteration 4100, loss = 0.510283
I0526 00:36:38.452589 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.510283 (* 1 = 0.510283 loss)
I0526 00:36:38.452601 15117 sgd_solver.cpp:294] Iteration 4100, lr = 0.02
I0526 00:36:44.825459 15117 solver.cpp:233] Iteration 4110, loss = 0.35665
I0526 00:36:44.825526 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.35665 (* 1 = 0.35665 loss)
I0526 00:36:44.825537 15117 sgd_solver.cpp:294] Iteration 4110, lr = 0.02
I0526 00:36:51.196027 15117 solver.cpp:233] Iteration 4120, loss = 0.336712
I0526 00:36:51.196092 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.336712 (* 1 = 0.336712 loss)
I0526 00:36:51.196102 15117 sgd_solver.cpp:294] Iteration 4120, lr = 0.02
I0526 00:36:57.562100 15117 solver.cpp:233] Iteration 4130, loss = 0.416243
I0526 00:36:57.562170 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.416243 (* 1 = 0.416243 loss)
I0526 00:36:57.562185 15117 sgd_solver.cpp:294] Iteration 4130, lr = 0.02
I0526 00:37:03.926116 15117 solver.cpp:233] Iteration 4140, loss = 0.35954
I0526 00:37:03.926178 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.35954 (* 1 = 0.35954 loss)
I0526 00:37:03.926189 15117 sgd_solver.cpp:294] Iteration 4140, lr = 0.02
I0526 00:37:10.297350 15117 solver.cpp:233] Iteration 4150, loss = 0.324597
I0526 00:37:10.297511 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.324597 (* 1 = 0.324597 loss)
I0526 00:37:10.297523 15117 sgd_solver.cpp:294] Iteration 4150, lr = 0.02
I0526 00:37:16.662729 15117 solver.cpp:233] Iteration 4160, loss = 0.527365
I0526 00:37:16.662796 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.527365 (* 1 = 0.527365 loss)
I0526 00:37:16.662808 15117 sgd_solver.cpp:294] Iteration 4160, lr = 0.02
I0526 00:37:23.029191 15117 solver.cpp:233] Iteration 4170, loss = 0.455537
I0526 00:37:23.029258 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.455537 (* 1 = 0.455537 loss)
I0526 00:37:23.029269 15117 sgd_solver.cpp:294] Iteration 4170, lr = 0.02
I0526 00:37:29.394898 15117 solver.cpp:233] Iteration 4180, loss = 0.431847
I0526 00:37:29.394959 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.431847 (* 1 = 0.431847 loss)
I0526 00:37:29.394970 15117 sgd_solver.cpp:294] Iteration 4180, lr = 0.02
I0526 00:37:35.762439 15117 solver.cpp:233] Iteration 4190, loss = 0.301687
I0526 00:37:35.762501 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.301687 (* 1 = 0.301687 loss)
I0526 00:37:35.762512 15117 sgd_solver.cpp:294] Iteration 4190, lr = 0.02
I0526 00:37:41.528733 15117 solver.cpp:342] Iteration 4200, Testing net (#0)
I0526 00:37:54.518412 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.62
I0526 00:37:54.518481 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.34944 (* 1 = 1.34944 loss)
I0526 00:37:55.123232 15117 solver.cpp:233] Iteration 4200, loss = 0.435029
I0526 00:37:55.123299 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.435029 (* 1 = 0.435029 loss)
I0526 00:37:55.123312 15117 sgd_solver.cpp:294] Iteration 4200, lr = 0.02
I0526 00:38:01.488453 15117 solver.cpp:233] Iteration 4210, loss = 0.384756
I0526 00:38:01.488520 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.384756 (* 1 = 0.384756 loss)
I0526 00:38:01.488531 15117 sgd_solver.cpp:294] Iteration 4210, lr = 0.02
I0526 00:38:07.864100 15117 solver.cpp:233] Iteration 4220, loss = 0.34855
I0526 00:38:07.864169 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.34855 (* 1 = 0.34855 loss)
I0526 00:38:07.864181 15117 sgd_solver.cpp:294] Iteration 4220, lr = 0.02
I0526 00:38:14.230970 15117 solver.cpp:233] Iteration 4230, loss = 0.494234
I0526 00:38:14.231112 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.494234 (* 1 = 0.494234 loss)
I0526 00:38:14.231123 15117 sgd_solver.cpp:294] Iteration 4230, lr = 0.02
I0526 00:38:20.597148 15117 solver.cpp:233] Iteration 4240, loss = 0.546962
I0526 00:38:20.597225 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.546962 (* 1 = 0.546962 loss)
I0526 00:38:20.597235 15117 sgd_solver.cpp:294] Iteration 4240, lr = 0.02
I0526 00:38:26.966811 15117 solver.cpp:233] Iteration 4250, loss = 0.423794
I0526 00:38:26.966873 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.423794 (* 1 = 0.423794 loss)
I0526 00:38:26.966883 15117 sgd_solver.cpp:294] Iteration 4250, lr = 0.02
I0526 00:38:33.335760 15117 solver.cpp:233] Iteration 4260, loss = 0.301254
I0526 00:38:33.335829 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.301254 (* 1 = 0.301254 loss)
I0526 00:38:33.335840 15117 sgd_solver.cpp:294] Iteration 4260, lr = 0.02
I0526 00:38:39.702556 15117 solver.cpp:233] Iteration 4270, loss = 0.485657
I0526 00:38:39.702621 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.485657 (* 1 = 0.485657 loss)
I0526 00:38:39.702631 15117 sgd_solver.cpp:294] Iteration 4270, lr = 0.02
I0526 00:38:46.070014 15117 solver.cpp:233] Iteration 4280, loss = 0.588565
I0526 00:38:46.070211 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.588565 (* 1 = 0.588565 loss)
I0526 00:38:46.070224 15117 sgd_solver.cpp:294] Iteration 4280, lr = 0.02
I0526 00:38:52.446593 15117 solver.cpp:233] Iteration 4290, loss = 0.462998
I0526 00:38:52.446657 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.462998 (* 1 = 0.462998 loss)
I0526 00:38:52.446667 15117 sgd_solver.cpp:294] Iteration 4290, lr = 0.02
I0526 00:38:58.231050 15117 solver.cpp:342] Iteration 4300, Testing net (#0)
I0526 00:39:11.224917 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7463
I0526 00:39:11.224979 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.737637 (* 1 = 0.737637 loss)
I0526 00:39:11.836802 15117 solver.cpp:233] Iteration 4300, loss = 0.33578
I0526 00:39:11.836865 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.33578 (* 1 = 0.33578 loss)
I0526 00:39:11.836875 15117 sgd_solver.cpp:294] Iteration 4300, lr = 0.02
I0526 00:39:18.276209 15117 solver.cpp:233] Iteration 4310, loss = 0.50009
I0526 00:39:18.276370 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.50009 (* 1 = 0.50009 loss)
I0526 00:39:18.276381 15117 sgd_solver.cpp:294] Iteration 4310, lr = 0.02
I0526 00:39:24.710716 15117 solver.cpp:233] Iteration 4320, loss = 0.469461
I0526 00:39:24.710786 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.469461 (* 1 = 0.469461 loss)
I0526 00:39:24.710798 15117 sgd_solver.cpp:294] Iteration 4320, lr = 0.02
I0526 00:39:31.087921 15117 solver.cpp:233] Iteration 4330, loss = 0.403087
I0526 00:39:31.087990 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.403087 (* 1 = 0.403087 loss)
I0526 00:39:31.087999 15117 sgd_solver.cpp:294] Iteration 4330, lr = 0.02
I0526 00:39:37.456156 15117 solver.cpp:233] Iteration 4340, loss = 0.35374
I0526 00:39:37.456223 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.35374 (* 1 = 0.35374 loss)
I0526 00:39:37.456234 15117 sgd_solver.cpp:294] Iteration 4340, lr = 0.02
I0526 00:39:43.824336 15117 solver.cpp:233] Iteration 4350, loss = 0.437525
I0526 00:39:43.824400 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.437525 (* 1 = 0.437525 loss)
I0526 00:39:43.824412 15117 sgd_solver.cpp:294] Iteration 4350, lr = 0.02
I0526 00:39:50.190675 15117 solver.cpp:233] Iteration 4360, loss = 0.335149
I0526 00:39:50.190826 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.335149 (* 1 = 0.335149 loss)
I0526 00:39:50.190839 15117 sgd_solver.cpp:294] Iteration 4360, lr = 0.02
I0526 00:39:56.559629 15117 solver.cpp:233] Iteration 4370, loss = 0.456039
I0526 00:39:56.559692 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.456039 (* 1 = 0.456039 loss)
I0526 00:39:56.559703 15117 sgd_solver.cpp:294] Iteration 4370, lr = 0.02
I0526 00:40:02.933104 15117 solver.cpp:233] Iteration 4380, loss = 0.43133
I0526 00:40:02.933171 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.43133 (* 1 = 0.43133 loss)
I0526 00:40:02.933197 15117 sgd_solver.cpp:294] Iteration 4380, lr = 0.02
I0526 00:40:09.299433 15117 solver.cpp:233] Iteration 4390, loss = 0.298566
I0526 00:40:09.299499 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.298566 (* 1 = 0.298566 loss)
I0526 00:40:09.299510 15117 sgd_solver.cpp:294] Iteration 4390, lr = 0.02
I0526 00:40:15.065421 15117 solver.cpp:342] Iteration 4400, Testing net (#0)
I0526 00:40:28.062216 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7194
I0526 00:40:28.062424 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.846377 (* 1 = 0.846377 loss)
I0526 00:40:28.666337 15117 solver.cpp:233] Iteration 4400, loss = 0.422119
I0526 00:40:28.666406 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.422119 (* 1 = 0.422119 loss)
I0526 00:40:28.666419 15117 sgd_solver.cpp:294] Iteration 4400, lr = 0.02
I0526 00:40:35.035394 15117 solver.cpp:233] Iteration 4410, loss = 0.38699
I0526 00:40:35.035457 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.38699 (* 1 = 0.38699 loss)
I0526 00:40:35.035468 15117 sgd_solver.cpp:294] Iteration 4410, lr = 0.02
I0526 00:40:41.401264 15117 solver.cpp:233] Iteration 4420, loss = 0.396037
I0526 00:40:41.401327 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.396037 (* 1 = 0.396037 loss)
I0526 00:40:41.401337 15117 sgd_solver.cpp:294] Iteration 4420, lr = 0.02
I0526 00:40:47.770603 15117 solver.cpp:233] Iteration 4430, loss = 0.364997
I0526 00:40:47.770668 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.364997 (* 1 = 0.364997 loss)
I0526 00:40:47.770678 15117 sgd_solver.cpp:294] Iteration 4430, lr = 0.02
I0526 00:40:54.139005 15117 solver.cpp:233] Iteration 4440, loss = 0.510429
I0526 00:40:54.139070 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.510429 (* 1 = 0.510429 loss)
I0526 00:40:54.139081 15117 sgd_solver.cpp:294] Iteration 4440, lr = 0.02
I0526 00:41:00.507771 15117 solver.cpp:233] Iteration 4450, loss = 0.415645
I0526 00:41:00.507923 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.415645 (* 1 = 0.415645 loss)
I0526 00:41:00.507936 15117 sgd_solver.cpp:294] Iteration 4450, lr = 0.02
I0526 00:41:06.874743 15117 solver.cpp:233] Iteration 4460, loss = 0.387671
I0526 00:41:06.874806 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.387671 (* 1 = 0.387671 loss)
I0526 00:41:06.874816 15117 sgd_solver.cpp:294] Iteration 4460, lr = 0.02
I0526 00:41:13.243453 15117 solver.cpp:233] Iteration 4470, loss = 0.316857
I0526 00:41:13.243521 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.316857 (* 1 = 0.316857 loss)
I0526 00:41:13.243532 15117 sgd_solver.cpp:294] Iteration 4470, lr = 0.02
I0526 00:41:19.611929 15117 solver.cpp:233] Iteration 4480, loss = 0.452995
I0526 00:41:19.611994 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.452995 (* 1 = 0.452995 loss)
I0526 00:41:19.612004 15117 sgd_solver.cpp:294] Iteration 4480, lr = 0.02
I0526 00:41:25.981217 15117 solver.cpp:233] Iteration 4490, loss = 0.379927
I0526 00:41:25.981283 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.379927 (* 1 = 0.379927 loss)
I0526 00:41:25.981294 15117 sgd_solver.cpp:294] Iteration 4490, lr = 0.02
I0526 00:41:31.748509 15117 solver.cpp:342] Iteration 4500, Testing net (#0)
I0526 00:41:44.816262 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.6912
I0526 00:41:44.816331 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.943272 (* 1 = 0.943272 loss)
I0526 00:41:45.419821 15117 solver.cpp:233] Iteration 4500, loss = 0.357603
I0526 00:41:45.419884 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.357603 (* 1 = 0.357603 loss)
I0526 00:41:45.419896 15117 sgd_solver.cpp:294] Iteration 4500, lr = 0.02
I0526 00:41:51.786394 15117 solver.cpp:233] Iteration 4510, loss = 0.287895
I0526 00:41:51.786461 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.287895 (* 1 = 0.287895 loss)
I0526 00:41:51.786484 15117 sgd_solver.cpp:294] Iteration 4510, lr = 0.02
I0526 00:41:58.152717 15117 solver.cpp:233] Iteration 4520, loss = 0.408467
I0526 00:41:58.152786 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.408467 (* 1 = 0.408467 loss)
I0526 00:41:58.152797 15117 sgd_solver.cpp:294] Iteration 4520, lr = 0.02
I0526 00:42:04.520917 15117 solver.cpp:233] Iteration 4530, loss = 0.372024
I0526 00:42:04.521137 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.372024 (* 1 = 0.372024 loss)
I0526 00:42:04.521150 15117 sgd_solver.cpp:294] Iteration 4530, lr = 0.02
I0526 00:42:10.890627 15117 solver.cpp:233] Iteration 4540, loss = 0.393392
I0526 00:42:10.890691 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.393392 (* 1 = 0.393392 loss)
I0526 00:42:10.890702 15117 sgd_solver.cpp:294] Iteration 4540, lr = 0.02
I0526 00:42:17.255951 15117 solver.cpp:233] Iteration 4550, loss = 0.410075
I0526 00:42:17.256021 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.410075 (* 1 = 0.410075 loss)
I0526 00:42:17.256031 15117 sgd_solver.cpp:294] Iteration 4550, lr = 0.02
I0526 00:42:23.625991 15117 solver.cpp:233] Iteration 4560, loss = 0.352445
I0526 00:42:23.626056 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.352445 (* 1 = 0.352445 loss)
I0526 00:42:23.626067 15117 sgd_solver.cpp:294] Iteration 4560, lr = 0.02
I0526 00:42:29.994992 15117 solver.cpp:233] Iteration 4570, loss = 0.445105
I0526 00:42:29.995059 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.445105 (* 1 = 0.445105 loss)
I0526 00:42:29.995070 15117 sgd_solver.cpp:294] Iteration 4570, lr = 0.02
I0526 00:42:36.359912 15117 solver.cpp:233] Iteration 4580, loss = 0.362997
I0526 00:42:36.360080 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.362997 (* 1 = 0.362997 loss)
I0526 00:42:36.360091 15117 sgd_solver.cpp:294] Iteration 4580, lr = 0.02
I0526 00:42:42.730661 15117 solver.cpp:233] Iteration 4590, loss = 0.350494
I0526 00:42:42.730738 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.350494 (* 1 = 0.350494 loss)
I0526 00:42:42.730752 15117 sgd_solver.cpp:294] Iteration 4590, lr = 0.02
I0526 00:42:48.495054 15117 solver.cpp:342] Iteration 4600, Testing net (#0)
I0526 00:43:01.531190 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7638
I0526 00:43:01.531255 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.688758 (* 1 = 0.688758 loss)
I0526 00:43:02.136739 15117 solver.cpp:233] Iteration 4600, loss = 0.386581
I0526 00:43:02.136806 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.386581 (* 1 = 0.386581 loss)
I0526 00:43:02.136818 15117 sgd_solver.cpp:294] Iteration 4600, lr = 0.02
I0526 00:43:08.525784 15117 solver.cpp:233] Iteration 4610, loss = 0.467041
I0526 00:43:08.525931 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.467041 (* 1 = 0.467041 loss)
I0526 00:43:08.525943 15117 sgd_solver.cpp:294] Iteration 4610, lr = 0.02
I0526 00:43:14.916396 15117 solver.cpp:233] Iteration 4620, loss = 0.375473
I0526 00:43:14.916470 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.375473 (* 1 = 0.375473 loss)
I0526 00:43:14.916481 15117 sgd_solver.cpp:294] Iteration 4620, lr = 0.02
I0526 00:43:21.303622 15117 solver.cpp:233] Iteration 4630, loss = 0.297584
I0526 00:43:21.303684 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.297584 (* 1 = 0.297584 loss)
I0526 00:43:21.303695 15117 sgd_solver.cpp:294] Iteration 4630, lr = 0.02
I0526 00:43:27.676162 15117 solver.cpp:233] Iteration 4640, loss = 0.321113
I0526 00:43:27.676237 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.321113 (* 1 = 0.321113 loss)
I0526 00:43:27.676250 15117 sgd_solver.cpp:294] Iteration 4640, lr = 0.02
I0526 00:43:34.047353 15117 solver.cpp:233] Iteration 4650, loss = 0.516203
I0526 00:43:34.047415 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.516203 (* 1 = 0.516203 loss)
I0526 00:43:34.047433 15117 sgd_solver.cpp:294] Iteration 4650, lr = 0.02
I0526 00:43:40.418722 15117 solver.cpp:233] Iteration 4660, loss = 0.536232
I0526 00:43:40.418932 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.536232 (* 1 = 0.536232 loss)
I0526 00:43:40.418944 15117 sgd_solver.cpp:294] Iteration 4660, lr = 0.02
I0526 00:43:46.791034 15117 solver.cpp:233] Iteration 4670, loss = 0.381893
I0526 00:43:46.791101 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.381893 (* 1 = 0.381893 loss)
I0526 00:43:46.791112 15117 sgd_solver.cpp:294] Iteration 4670, lr = 0.02
I0526 00:43:53.164376 15117 solver.cpp:233] Iteration 4680, loss = 0.356362
I0526 00:43:53.164444 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.356362 (* 1 = 0.356362 loss)
I0526 00:43:53.164454 15117 sgd_solver.cpp:294] Iteration 4680, lr = 0.02
I0526 00:43:59.536383 15117 solver.cpp:233] Iteration 4690, loss = 0.343815
I0526 00:43:59.536449 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.343815 (* 1 = 0.343815 loss)
I0526 00:43:59.536460 15117 sgd_solver.cpp:294] Iteration 4690, lr = 0.02
I0526 00:44:05.303637 15117 solver.cpp:342] Iteration 4700, Testing net (#0)
I0526 00:44:18.338610 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7492
I0526 00:44:18.338773 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.754772 (* 1 = 0.754772 loss)
I0526 00:44:18.944392 15117 solver.cpp:233] Iteration 4700, loss = 0.440185
I0526 00:44:18.944463 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.440185 (* 1 = 0.440185 loss)
I0526 00:44:18.944474 15117 sgd_solver.cpp:294] Iteration 4700, lr = 0.02
I0526 00:44:25.315171 15117 solver.cpp:233] Iteration 4710, loss = 0.434866
I0526 00:44:25.315234 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.434866 (* 1 = 0.434866 loss)
I0526 00:44:25.315243 15117 sgd_solver.cpp:294] Iteration 4710, lr = 0.02
I0526 00:44:31.686962 15117 solver.cpp:233] Iteration 4720, loss = 0.439321
I0526 00:44:31.687031 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.439321 (* 1 = 0.439321 loss)
I0526 00:44:31.687041 15117 sgd_solver.cpp:294] Iteration 4720, lr = 0.02
I0526 00:44:38.055527 15117 solver.cpp:233] Iteration 4730, loss = 0.359218
I0526 00:44:38.055591 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.359218 (* 1 = 0.359218 loss)
I0526 00:44:38.055603 15117 sgd_solver.cpp:294] Iteration 4730, lr = 0.02
I0526 00:44:44.453146 15117 solver.cpp:233] Iteration 4740, loss = 0.340437
I0526 00:44:44.453222 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.340437 (* 1 = 0.340437 loss)
I0526 00:44:44.453233 15117 sgd_solver.cpp:294] Iteration 4740, lr = 0.02
I0526 00:44:50.821981 15117 solver.cpp:233] Iteration 4750, loss = 0.471511
I0526 00:44:50.822135 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.471511 (* 1 = 0.471511 loss)
I0526 00:44:50.822147 15117 sgd_solver.cpp:294] Iteration 4750, lr = 0.02
I0526 00:44:57.190413 15117 solver.cpp:233] Iteration 4760, loss = 0.473024
I0526 00:44:57.190480 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.473024 (* 1 = 0.473024 loss)
I0526 00:44:57.190491 15117 sgd_solver.cpp:294] Iteration 4760, lr = 0.02
I0526 00:45:03.557498 15117 solver.cpp:233] Iteration 4770, loss = 0.427754
I0526 00:45:03.557569 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.427754 (* 1 = 0.427754 loss)
I0526 00:45:03.557580 15117 sgd_solver.cpp:294] Iteration 4770, lr = 0.02
I0526 00:45:09.925528 15117 solver.cpp:233] Iteration 4780, loss = 0.250394
I0526 00:45:09.925592 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.250394 (* 1 = 0.250394 loss)
I0526 00:45:09.925603 15117 sgd_solver.cpp:294] Iteration 4780, lr = 0.02
I0526 00:45:16.293707 15117 solver.cpp:233] Iteration 4790, loss = 0.283962
I0526 00:45:16.293776 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.283962 (* 1 = 0.283962 loss)
I0526 00:45:16.293787 15117 sgd_solver.cpp:294] Iteration 4790, lr = 0.02
I0526 00:45:22.053454 15117 solver.cpp:342] Iteration 4800, Testing net (#0)
I0526 00:45:35.089059 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.6539
I0526 00:45:35.089128 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.06426 (* 1 = 1.06426 loss)
I0526 00:45:35.693572 15117 solver.cpp:233] Iteration 4800, loss = 0.413226
I0526 00:45:35.693639 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.413226 (* 1 = 0.413226 loss)
I0526 00:45:35.693651 15117 sgd_solver.cpp:294] Iteration 4800, lr = 0.02
I0526 00:45:42.063231 15117 solver.cpp:233] Iteration 4810, loss = 0.534375
I0526 00:45:42.063297 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.534375 (* 1 = 0.534375 loss)
I0526 00:45:42.063308 15117 sgd_solver.cpp:294] Iteration 4810, lr = 0.02
I0526 00:45:48.433735 15117 solver.cpp:233] Iteration 4820, loss = 0.389699
I0526 00:45:48.433799 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.389699 (* 1 = 0.389699 loss)
I0526 00:45:48.433810 15117 sgd_solver.cpp:294] Iteration 4820, lr = 0.02
I0526 00:45:54.803127 15117 solver.cpp:233] Iteration 4830, loss = 0.502319
I0526 00:45:54.803277 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.502319 (* 1 = 0.502319 loss)
I0526 00:45:54.803289 15117 sgd_solver.cpp:294] Iteration 4830, lr = 0.02
I0526 00:46:01.171367 15117 solver.cpp:233] Iteration 4840, loss = 0.397034
I0526 00:46:01.171432 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.397034 (* 1 = 0.397034 loss)
I0526 00:46:01.171443 15117 sgd_solver.cpp:294] Iteration 4840, lr = 0.02
I0526 00:46:07.538617 15117 solver.cpp:233] Iteration 4850, loss = 0.26225
I0526 00:46:07.538682 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.26225 (* 1 = 0.26225 loss)
I0526 00:46:07.538694 15117 sgd_solver.cpp:294] Iteration 4850, lr = 0.02
I0526 00:46:13.906966 15117 solver.cpp:233] Iteration 4860, loss = 0.394693
I0526 00:46:13.907030 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.394693 (* 1 = 0.394693 loss)
I0526 00:46:13.907042 15117 sgd_solver.cpp:294] Iteration 4860, lr = 0.02
I0526 00:46:20.276309 15117 solver.cpp:233] Iteration 4870, loss = 0.427552
I0526 00:46:20.276374 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.427552 (* 1 = 0.427552 loss)
I0526 00:46:20.276386 15117 sgd_solver.cpp:294] Iteration 4870, lr = 0.02
I0526 00:46:26.642199 15117 solver.cpp:233] Iteration 4880, loss = 0.39941
I0526 00:46:26.642328 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.39941 (* 1 = 0.39941 loss)
I0526 00:46:26.642338 15117 sgd_solver.cpp:294] Iteration 4880, lr = 0.02
I0526 00:46:33.015568 15117 solver.cpp:233] Iteration 4890, loss = 0.350242
I0526 00:46:33.015633 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.350242 (* 1 = 0.350242 loss)
I0526 00:46:33.015643 15117 sgd_solver.cpp:294] Iteration 4890, lr = 0.02
I0526 00:46:38.781954 15117 solver.cpp:342] Iteration 4900, Testing net (#0)
I0526 00:46:51.836355 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.6298
I0526 00:46:51.836424 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.30434 (* 1 = 1.30434 loss)
I0526 00:46:52.438866 15117 solver.cpp:233] Iteration 4900, loss = 0.434494
I0526 00:46:52.438932 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.434494 (* 1 = 0.434494 loss)
I0526 00:46:52.438944 15117 sgd_solver.cpp:294] Iteration 4900, lr = 0.02
I0526 00:46:58.829475 15117 solver.cpp:233] Iteration 4910, loss = 0.372276
I0526 00:46:58.829625 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.372276 (* 1 = 0.372276 loss)
I0526 00:46:58.829639 15117 sgd_solver.cpp:294] Iteration 4910, lr = 0.02
I0526 00:47:05.256839 15117 solver.cpp:233] Iteration 4920, loss = 0.427816
I0526 00:47:05.256906 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.427816 (* 1 = 0.427816 loss)
I0526 00:47:05.256918 15117 sgd_solver.cpp:294] Iteration 4920, lr = 0.02
I0526 00:47:11.699789 15117 solver.cpp:233] Iteration 4930, loss = 0.372578
I0526 00:47:11.699864 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.372578 (* 1 = 0.372578 loss)
I0526 00:47:11.699875 15117 sgd_solver.cpp:294] Iteration 4930, lr = 0.02
I0526 00:47:18.091266 15117 solver.cpp:233] Iteration 4940, loss = 0.286304
I0526 00:47:18.091336 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.286304 (* 1 = 0.286304 loss)
I0526 00:47:18.091347 15117 sgd_solver.cpp:294] Iteration 4940, lr = 0.02
I0526 00:47:24.467258 15117 solver.cpp:233] Iteration 4950, loss = 0.42595
I0526 00:47:24.467319 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.42595 (* 1 = 0.42595 loss)
I0526 00:47:24.467330 15117 sgd_solver.cpp:294] Iteration 4950, lr = 0.02
I0526 00:47:30.845417 15117 solver.cpp:233] Iteration 4960, loss = 0.49159
I0526 00:47:30.845641 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.49159 (* 1 = 0.49159 loss)
I0526 00:47:30.845654 15117 sgd_solver.cpp:294] Iteration 4960, lr = 0.02
I0526 00:47:37.217638 15117 solver.cpp:233] Iteration 4970, loss = 0.330814
I0526 00:47:37.217706 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.330814 (* 1 = 0.330814 loss)
I0526 00:47:37.217716 15117 sgd_solver.cpp:294] Iteration 4970, lr = 0.02
I0526 00:47:43.592753 15117 solver.cpp:233] Iteration 4980, loss = 0.451313
I0526 00:47:43.592820 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.451313 (* 1 = 0.451313 loss)
I0526 00:47:43.592831 15117 sgd_solver.cpp:294] Iteration 4980, lr = 0.02
I0526 00:47:49.965237 15117 solver.cpp:233] Iteration 4990, loss = 0.259249
I0526 00:47:49.965303 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.259249 (* 1 = 0.259249 loss)
I0526 00:47:49.965313 15117 sgd_solver.cpp:294] Iteration 4990, lr = 0.02
I0526 00:47:55.737738 15117 solver.cpp:342] Iteration 5000, Testing net (#0)
I0526 00:48:08.736521 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7629
I0526 00:48:08.736670 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.679543 (* 1 = 0.679543 loss)
I0526 00:48:09.340355 15117 solver.cpp:233] Iteration 5000, loss = 0.387439
I0526 00:48:09.340423 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.387439 (* 1 = 0.387439 loss)
I0526 00:48:09.340436 15117 sgd_solver.cpp:294] Iteration 5000, lr = 0.02
I0526 00:48:15.721292 15117 solver.cpp:233] Iteration 5010, loss = 0.355362
I0526 00:48:15.721360 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.355362 (* 1 = 0.355362 loss)
I0526 00:48:15.721371 15117 sgd_solver.cpp:294] Iteration 5010, lr = 0.02
I0526 00:48:22.099711 15117 solver.cpp:233] Iteration 5020, loss = 0.235901
I0526 00:48:22.099776 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.235901 (* 1 = 0.235901 loss)
I0526 00:48:22.099786 15117 sgd_solver.cpp:294] Iteration 5020, lr = 0.02
I0526 00:48:28.473922 15117 solver.cpp:233] Iteration 5030, loss = 0.400144
I0526 00:48:28.473989 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.400144 (* 1 = 0.400144 loss)
I0526 00:48:28.474000 15117 sgd_solver.cpp:294] Iteration 5030, lr = 0.02
I0526 00:48:34.849576 15117 solver.cpp:233] Iteration 5040, loss = 0.353244
I0526 00:48:34.849640 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.353244 (* 1 = 0.353244 loss)
I0526 00:48:34.849650 15117 sgd_solver.cpp:294] Iteration 5040, lr = 0.02
I0526 00:48:41.220944 15117 solver.cpp:233] Iteration 5050, loss = 0.485164
I0526 00:48:41.221102 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.485164 (* 1 = 0.485164 loss)
I0526 00:48:41.221114 15117 sgd_solver.cpp:294] Iteration 5050, lr = 0.02
I0526 00:48:47.603869 15117 solver.cpp:233] Iteration 5060, loss = 0.501663
I0526 00:48:47.603943 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.501663 (* 1 = 0.501663 loss)
I0526 00:48:47.603953 15117 sgd_solver.cpp:294] Iteration 5060, lr = 0.02
I0526 00:48:53.999598 15117 solver.cpp:233] Iteration 5070, loss = 0.300704
I0526 00:48:53.999676 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.300704 (* 1 = 0.300704 loss)
I0526 00:48:53.999687 15117 sgd_solver.cpp:294] Iteration 5070, lr = 0.02
I0526 00:49:00.392683 15117 solver.cpp:233] Iteration 5080, loss = 0.390679
I0526 00:49:00.392755 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.390679 (* 1 = 0.390679 loss)
I0526 00:49:00.392765 15117 sgd_solver.cpp:294] Iteration 5080, lr = 0.02
I0526 00:49:06.780773 15117 solver.cpp:233] Iteration 5090, loss = 0.453934
I0526 00:49:06.780843 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.453934 (* 1 = 0.453934 loss)
I0526 00:49:06.780854 15117 sgd_solver.cpp:294] Iteration 5090, lr = 0.02
I0526 00:49:12.566547 15117 solver.cpp:342] Iteration 5100, Testing net (#0)
I0526 00:49:25.608727 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7793
I0526 00:49:25.608791 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.639295 (* 1 = 0.639295 loss)
I0526 00:49:26.212602 15117 solver.cpp:233] Iteration 5100, loss = 0.241097
I0526 00:49:26.212663 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.241097 (* 1 = 0.241097 loss)
I0526 00:49:26.212674 15117 sgd_solver.cpp:294] Iteration 5100, lr = 0.02
I0526 00:49:32.577247 15117 solver.cpp:233] Iteration 5110, loss = 0.441692
I0526 00:49:32.577316 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.441692 (* 1 = 0.441692 loss)
I0526 00:49:32.577327 15117 sgd_solver.cpp:294] Iteration 5110, lr = 0.02
I0526 00:49:38.946113 15117 solver.cpp:233] Iteration 5120, loss = 0.407842
I0526 00:49:38.946178 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.407842 (* 1 = 0.407842 loss)
I0526 00:49:38.946188 15117 sgd_solver.cpp:294] Iteration 5120, lr = 0.02
I0526 00:49:45.317008 15117 solver.cpp:233] Iteration 5130, loss = 0.466626
I0526 00:49:45.317178 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.466626 (* 1 = 0.466626 loss)
I0526 00:49:45.317189 15117 sgd_solver.cpp:294] Iteration 5130, lr = 0.02
I0526 00:49:51.691190 15117 solver.cpp:233] Iteration 5140, loss = 0.426317
I0526 00:49:51.691254 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.426317 (* 1 = 0.426317 loss)
I0526 00:49:51.691265 15117 sgd_solver.cpp:294] Iteration 5140, lr = 0.02
I0526 00:49:58.071066 15117 solver.cpp:233] Iteration 5150, loss = 0.447085
I0526 00:49:58.071135 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.447085 (* 1 = 0.447085 loss)
I0526 00:49:58.071146 15117 sgd_solver.cpp:294] Iteration 5150, lr = 0.02
I0526 00:50:04.447052 15117 solver.cpp:233] Iteration 5160, loss = 0.644451
I0526 00:50:04.447115 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.644451 (* 1 = 0.644451 loss)
I0526 00:50:04.447125 15117 sgd_solver.cpp:294] Iteration 5160, lr = 0.02
I0526 00:50:10.878757 15117 solver.cpp:233] Iteration 5170, loss = 0.430865
I0526 00:50:10.878826 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.430865 (* 1 = 0.430865 loss)
I0526 00:50:10.878839 15117 sgd_solver.cpp:294] Iteration 5170, lr = 0.02
I0526 00:50:17.299484 15117 solver.cpp:233] Iteration 5180, loss = 0.366207
I0526 00:50:17.299654 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.366207 (* 1 = 0.366207 loss)
I0526 00:50:17.299666 15117 sgd_solver.cpp:294] Iteration 5180, lr = 0.02
I0526 00:50:23.671469 15117 solver.cpp:233] Iteration 5190, loss = 0.393224
I0526 00:50:23.671535 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.393224 (* 1 = 0.393224 loss)
I0526 00:50:23.671545 15117 sgd_solver.cpp:294] Iteration 5190, lr = 0.02
I0526 00:50:29.443668 15117 solver.cpp:342] Iteration 5200, Testing net (#0)
I0526 00:50:42.443565 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7059
I0526 00:50:42.443632 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.912847 (* 1 = 0.912847 loss)
I0526 00:50:43.048434 15117 solver.cpp:233] Iteration 5200, loss = 0.445621
I0526 00:50:43.048496 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.445621 (* 1 = 0.445621 loss)
I0526 00:50:43.048516 15117 sgd_solver.cpp:294] Iteration 5200, lr = 0.02
I0526 00:50:49.476927 15117 solver.cpp:233] Iteration 5210, loss = 0.428018
I0526 00:50:49.477159 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.428018 (* 1 = 0.428018 loss)
I0526 00:50:49.477172 15117 sgd_solver.cpp:294] Iteration 5210, lr = 0.02
I0526 00:50:55.922309 15117 solver.cpp:233] Iteration 5220, loss = 0.486451
I0526 00:50:55.922379 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.486451 (* 1 = 0.486451 loss)
I0526 00:50:55.922391 15117 sgd_solver.cpp:294] Iteration 5220, lr = 0.02
I0526 00:51:02.359064 15117 solver.cpp:233] Iteration 5230, loss = 0.370989
I0526 00:51:02.359130 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.370989 (* 1 = 0.370989 loss)
I0526 00:51:02.359141 15117 sgd_solver.cpp:294] Iteration 5230, lr = 0.02
I0526 00:51:08.725350 15117 solver.cpp:233] Iteration 5240, loss = 0.402809
I0526 00:51:08.725419 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.402809 (* 1 = 0.402809 loss)
I0526 00:51:08.725430 15117 sgd_solver.cpp:294] Iteration 5240, lr = 0.02
I0526 00:51:15.092890 15117 solver.cpp:233] Iteration 5250, loss = 0.355144
I0526 00:51:15.092963 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.355144 (* 1 = 0.355144 loss)
I0526 00:51:15.092974 15117 sgd_solver.cpp:294] Iteration 5250, lr = 0.02
I0526 00:51:21.463502 15117 solver.cpp:233] Iteration 5260, loss = 0.327607
I0526 00:51:21.463672 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.327607 (* 1 = 0.327607 loss)
I0526 00:51:21.463685 15117 sgd_solver.cpp:294] Iteration 5260, lr = 0.02
I0526 00:51:27.836784 15117 solver.cpp:233] Iteration 5270, loss = 0.452621
I0526 00:51:27.836856 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.452621 (* 1 = 0.452621 loss)
I0526 00:51:27.836869 15117 sgd_solver.cpp:294] Iteration 5270, lr = 0.02
I0526 00:51:34.215540 15117 solver.cpp:233] Iteration 5280, loss = 0.344803
I0526 00:51:34.215610 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.344803 (* 1 = 0.344803 loss)
I0526 00:51:34.215620 15117 sgd_solver.cpp:294] Iteration 5280, lr = 0.02
I0526 00:51:40.603237 15117 solver.cpp:233] Iteration 5290, loss = 0.409202
I0526 00:51:40.603301 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.409202 (* 1 = 0.409202 loss)
I0526 00:51:40.603312 15117 sgd_solver.cpp:294] Iteration 5290, lr = 0.02
I0526 00:51:46.385431 15117 solver.cpp:342] Iteration 5300, Testing net (#0)
I0526 00:51:59.380342 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.65
I0526 00:51:59.380496 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.13506 (* 1 = 1.13506 loss)
I0526 00:51:59.988041 15117 solver.cpp:233] Iteration 5300, loss = 0.427144
I0526 00:51:59.988107 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.427144 (* 1 = 0.427144 loss)
I0526 00:51:59.988121 15117 sgd_solver.cpp:294] Iteration 5300, lr = 0.02
I0526 00:52:06.372979 15117 solver.cpp:233] Iteration 5310, loss = 0.315696
I0526 00:52:06.373041 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.315696 (* 1 = 0.315696 loss)
I0526 00:52:06.373051 15117 sgd_solver.cpp:294] Iteration 5310, lr = 0.02
I0526 00:52:12.752638 15117 solver.cpp:233] Iteration 5320, loss = 0.450122
I0526 00:52:12.752714 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.450122 (* 1 = 0.450122 loss)
I0526 00:52:12.752727 15117 sgd_solver.cpp:294] Iteration 5320, lr = 0.02
I0526 00:52:19.136068 15117 solver.cpp:233] Iteration 5330, loss = 0.419477
I0526 00:52:19.136131 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.419477 (* 1 = 0.419477 loss)
I0526 00:52:19.136142 15117 sgd_solver.cpp:294] Iteration 5330, lr = 0.02
I0526 00:52:25.518077 15117 solver.cpp:233] Iteration 5340, loss = 0.48281
I0526 00:52:25.518142 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.48281 (* 1 = 0.48281 loss)
I0526 00:52:25.518167 15117 sgd_solver.cpp:294] Iteration 5340, lr = 0.02
I0526 00:52:31.900679 15117 solver.cpp:233] Iteration 5350, loss = 0.441842
I0526 00:52:31.900892 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.441842 (* 1 = 0.441842 loss)
I0526 00:52:31.900904 15117 sgd_solver.cpp:294] Iteration 5350, lr = 0.02
I0526 00:52:38.282471 15117 solver.cpp:233] Iteration 5360, loss = 0.315218
I0526 00:52:38.282534 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.315218 (* 1 = 0.315218 loss)
I0526 00:52:38.282544 15117 sgd_solver.cpp:294] Iteration 5360, lr = 0.02
I0526 00:52:44.660838 15117 solver.cpp:233] Iteration 5370, loss = 0.274238
I0526 00:52:44.660907 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.274238 (* 1 = 0.274238 loss)
I0526 00:52:44.660918 15117 sgd_solver.cpp:294] Iteration 5370, lr = 0.02
I0526 00:52:51.041581 15117 solver.cpp:233] Iteration 5380, loss = 0.345035
I0526 00:52:51.041648 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.345035 (* 1 = 0.345035 loss)
I0526 00:52:51.041658 15117 sgd_solver.cpp:294] Iteration 5380, lr = 0.02
I0526 00:52:57.423666 15117 solver.cpp:233] Iteration 5390, loss = 0.369923
I0526 00:52:57.423745 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.369923 (* 1 = 0.369923 loss)
I0526 00:52:57.423759 15117 sgd_solver.cpp:294] Iteration 5390, lr = 0.02
I0526 00:53:03.214709 15117 solver.cpp:342] Iteration 5400, Testing net (#0)
I0526 00:53:16.396644 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8087
I0526 00:53:16.396714 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.558877 (* 1 = 0.558877 loss)
I0526 00:53:17.000192 15117 solver.cpp:233] Iteration 5400, loss = 0.30645
I0526 00:53:17.000257 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.30645 (* 1 = 0.30645 loss)
I0526 00:53:17.000269 15117 sgd_solver.cpp:294] Iteration 5400, lr = 0.02
I0526 00:53:23.369863 15117 solver.cpp:233] Iteration 5410, loss = 0.403804
I0526 00:53:23.369930 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.403804 (* 1 = 0.403804 loss)
I0526 00:53:23.369941 15117 sgd_solver.cpp:294] Iteration 5410, lr = 0.02
I0526 00:53:29.751950 15117 solver.cpp:233] Iteration 5420, loss = 0.364167
I0526 00:53:29.752017 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.364167 (* 1 = 0.364167 loss)
I0526 00:53:29.752028 15117 sgd_solver.cpp:294] Iteration 5420, lr = 0.02
I0526 00:53:36.134964 15117 solver.cpp:233] Iteration 5430, loss = 0.413909
I0526 00:53:36.135114 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.413909 (* 1 = 0.413909 loss)
I0526 00:53:36.135125 15117 sgd_solver.cpp:294] Iteration 5430, lr = 0.02
I0526 00:53:42.514369 15117 solver.cpp:233] Iteration 5440, loss = 0.566242
I0526 00:53:42.514446 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.566242 (* 1 = 0.566242 loss)
I0526 00:53:42.514459 15117 sgd_solver.cpp:294] Iteration 5440, lr = 0.02
I0526 00:53:48.899767 15117 solver.cpp:233] Iteration 5450, loss = 0.322327
I0526 00:53:48.899832 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.322327 (* 1 = 0.322327 loss)
I0526 00:53:48.899842 15117 sgd_solver.cpp:294] Iteration 5450, lr = 0.02
I0526 00:53:55.282582 15117 solver.cpp:233] Iteration 5460, loss = 0.23798
I0526 00:53:55.282645 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.23798 (* 1 = 0.23798 loss)
I0526 00:53:55.282655 15117 sgd_solver.cpp:294] Iteration 5460, lr = 0.02
I0526 00:54:01.670256 15117 solver.cpp:233] Iteration 5470, loss = 0.243176
I0526 00:54:01.670336 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.243176 (* 1 = 0.243176 loss)
I0526 00:54:01.670346 15117 sgd_solver.cpp:294] Iteration 5470, lr = 0.02
I0526 00:54:08.056839 15117 solver.cpp:233] Iteration 5480, loss = 0.401767
I0526 00:54:08.057047 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.401767 (* 1 = 0.401767 loss)
I0526 00:54:08.057060 15117 sgd_solver.cpp:294] Iteration 5480, lr = 0.02
I0526 00:54:14.461097 15117 solver.cpp:233] Iteration 5490, loss = 0.324902
I0526 00:54:14.461171 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.324902 (* 1 = 0.324902 loss)
I0526 00:54:14.461182 15117 sgd_solver.cpp:294] Iteration 5490, lr = 0.02
I0526 00:54:20.267165 15117 solver.cpp:342] Iteration 5500, Testing net (#0)
I0526 00:54:33.366868 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7749
I0526 00:54:33.366935 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.668395 (* 1 = 0.668395 loss)
I0526 00:54:33.972604 15117 solver.cpp:233] Iteration 5500, loss = 0.350204
I0526 00:54:33.972672 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.350204 (* 1 = 0.350204 loss)
I0526 00:54:33.972686 15117 sgd_solver.cpp:294] Iteration 5500, lr = 0.02
I0526 00:54:40.354943 15117 solver.cpp:233] Iteration 5510, loss = 0.315501
I0526 00:54:40.355093 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.315501 (* 1 = 0.315501 loss)
I0526 00:54:40.355104 15117 sgd_solver.cpp:294] Iteration 5510, lr = 0.02
I0526 00:54:46.738937 15117 solver.cpp:233] Iteration 5520, loss = 0.304634
I0526 00:54:46.739006 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.304634 (* 1 = 0.304634 loss)
I0526 00:54:46.739017 15117 sgd_solver.cpp:294] Iteration 5520, lr = 0.02
I0526 00:54:53.120872 15117 solver.cpp:233] Iteration 5530, loss = 0.461028
I0526 00:54:53.120936 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.461028 (* 1 = 0.461028 loss)
I0526 00:54:53.120946 15117 sgd_solver.cpp:294] Iteration 5530, lr = 0.02
I0526 00:54:59.500838 15117 solver.cpp:233] Iteration 5540, loss = 0.44268
I0526 00:54:59.500908 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.44268 (* 1 = 0.44268 loss)
I0526 00:54:59.500921 15117 sgd_solver.cpp:294] Iteration 5540, lr = 0.02
I0526 00:55:05.881319 15117 solver.cpp:233] Iteration 5550, loss = 0.443104
I0526 00:55:05.881388 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.443104 (* 1 = 0.443104 loss)
I0526 00:55:05.881399 15117 sgd_solver.cpp:294] Iteration 5550, lr = 0.02
I0526 00:55:12.276527 15117 solver.cpp:233] Iteration 5560, loss = 0.567963
I0526 00:55:12.276679 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.567963 (* 1 = 0.567963 loss)
I0526 00:55:12.276691 15117 sgd_solver.cpp:294] Iteration 5560, lr = 0.02
I0526 00:55:18.660305 15117 solver.cpp:233] Iteration 5570, loss = 0.399985
I0526 00:55:18.660374 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.399985 (* 1 = 0.399985 loss)
I0526 00:55:18.660385 15117 sgd_solver.cpp:294] Iteration 5570, lr = 0.02
I0526 00:55:25.041800 15117 solver.cpp:233] Iteration 5580, loss = 0.384489
I0526 00:55:25.041870 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.384489 (* 1 = 0.384489 loss)
I0526 00:55:25.041882 15117 sgd_solver.cpp:294] Iteration 5580, lr = 0.02
I0526 00:55:31.426743 15117 solver.cpp:233] Iteration 5590, loss = 0.358154
I0526 00:55:31.426810 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.358154 (* 1 = 0.358154 loss)
I0526 00:55:31.426821 15117 sgd_solver.cpp:294] Iteration 5590, lr = 0.02
I0526 00:55:37.209740 15117 solver.cpp:342] Iteration 5600, Testing net (#0)
I0526 00:55:50.332190 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7905
I0526 00:55:50.332351 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.598273 (* 1 = 0.598273 loss)
I0526 00:55:50.937839 15117 solver.cpp:233] Iteration 5600, loss = 0.285476
I0526 00:55:50.937911 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.285476 (* 1 = 0.285476 loss)
I0526 00:55:50.937924 15117 sgd_solver.cpp:294] Iteration 5600, lr = 0.02
I0526 00:55:57.325042 15117 solver.cpp:233] Iteration 5610, loss = 0.41788
I0526 00:55:57.325109 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.41788 (* 1 = 0.41788 loss)
I0526 00:55:57.325119 15117 sgd_solver.cpp:294] Iteration 5610, lr = 0.02
I0526 00:56:03.712643 15117 solver.cpp:233] Iteration 5620, loss = 0.274017
I0526 00:56:03.712713 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.274017 (* 1 = 0.274017 loss)
I0526 00:56:03.712724 15117 sgd_solver.cpp:294] Iteration 5620, lr = 0.02
I0526 00:56:10.089838 15117 solver.cpp:233] Iteration 5630, loss = 0.299351
I0526 00:56:10.089906 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.299351 (* 1 = 0.299351 loss)
I0526 00:56:10.089916 15117 sgd_solver.cpp:294] Iteration 5630, lr = 0.02
I0526 00:56:16.472267 15117 solver.cpp:233] Iteration 5640, loss = 0.41544
I0526 00:56:16.472340 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.41544 (* 1 = 0.41544 loss)
I0526 00:56:16.472352 15117 sgd_solver.cpp:294] Iteration 5640, lr = 0.02
I0526 00:56:22.855227 15117 solver.cpp:233] Iteration 5650, loss = 0.312277
I0526 00:56:22.855448 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.312277 (* 1 = 0.312277 loss)
I0526 00:56:22.855459 15117 sgd_solver.cpp:294] Iteration 5650, lr = 0.02
I0526 00:56:29.238843 15117 solver.cpp:233] Iteration 5660, loss = 0.31629
I0526 00:56:29.238912 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.31629 (* 1 = 0.31629 loss)
I0526 00:56:29.238924 15117 sgd_solver.cpp:294] Iteration 5660, lr = 0.02
I0526 00:56:35.622843 15117 solver.cpp:233] Iteration 5670, loss = 0.312689
I0526 00:56:35.622907 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.312689 (* 1 = 0.312689 loss)
I0526 00:56:35.622918 15117 sgd_solver.cpp:294] Iteration 5670, lr = 0.02
I0526 00:56:42.005483 15117 solver.cpp:233] Iteration 5680, loss = 0.463624
I0526 00:56:42.005553 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.463624 (* 1 = 0.463624 loss)
I0526 00:56:42.005564 15117 sgd_solver.cpp:294] Iteration 5680, lr = 0.02
I0526 00:56:48.390285 15117 solver.cpp:233] Iteration 5690, loss = 0.402362
I0526 00:56:48.390359 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.402362 (* 1 = 0.402362 loss)
I0526 00:56:48.390370 15117 sgd_solver.cpp:294] Iteration 5690, lr = 0.02
I0526 00:56:54.175948 15117 solver.cpp:342] Iteration 5700, Testing net (#0)
I0526 00:57:07.272310 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7537
I0526 00:57:07.272380 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.720339 (* 1 = 0.720339 loss)
I0526 00:57:07.877689 15117 solver.cpp:233] Iteration 5700, loss = 0.341059
I0526 00:57:07.877786 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.341059 (* 1 = 0.341059 loss)
I0526 00:57:07.877804 15117 sgd_solver.cpp:294] Iteration 5700, lr = 0.02
I0526 00:57:14.264987 15117 solver.cpp:233] Iteration 5710, loss = 0.465352
I0526 00:57:14.265064 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.465352 (* 1 = 0.465352 loss)
I0526 00:57:14.265074 15117 sgd_solver.cpp:294] Iteration 5710, lr = 0.02
I0526 00:57:20.653776 15117 solver.cpp:233] Iteration 5720, loss = 0.411092
I0526 00:57:20.653842 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.411092 (* 1 = 0.411092 loss)
I0526 00:57:20.653853 15117 sgd_solver.cpp:294] Iteration 5720, lr = 0.02
I0526 00:57:27.046293 15117 solver.cpp:233] Iteration 5730, loss = 0.402381
I0526 00:57:27.046443 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.402381 (* 1 = 0.402381 loss)
I0526 00:57:27.046455 15117 sgd_solver.cpp:294] Iteration 5730, lr = 0.02
I0526 00:57:33.448462 15117 solver.cpp:233] Iteration 5740, loss = 0.332508
I0526 00:57:33.448530 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.332508 (* 1 = 0.332508 loss)
I0526 00:57:33.448540 15117 sgd_solver.cpp:294] Iteration 5740, lr = 0.02
I0526 00:57:39.838304 15117 solver.cpp:233] Iteration 5750, loss = 0.355937
I0526 00:57:39.838376 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.355937 (* 1 = 0.355937 loss)
I0526 00:57:39.838385 15117 sgd_solver.cpp:294] Iteration 5750, lr = 0.02
I0526 00:57:46.230476 15117 solver.cpp:233] Iteration 5760, loss = 0.443123
I0526 00:57:46.230561 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.443123 (* 1 = 0.443123 loss)
I0526 00:57:46.230572 15117 sgd_solver.cpp:294] Iteration 5760, lr = 0.02
I0526 00:57:52.620345 15117 solver.cpp:233] Iteration 5770, loss = 0.343771
I0526 00:57:52.620410 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.343771 (* 1 = 0.343771 loss)
I0526 00:57:52.620420 15117 sgd_solver.cpp:294] Iteration 5770, lr = 0.02
I0526 00:57:59.010396 15117 solver.cpp:233] Iteration 5780, loss = 0.369726
I0526 00:57:59.010592 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.369726 (* 1 = 0.369726 loss)
I0526 00:57:59.010604 15117 sgd_solver.cpp:294] Iteration 5780, lr = 0.02
I0526 00:58:05.397096 15117 solver.cpp:233] Iteration 5790, loss = 0.280926
I0526 00:58:05.397164 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.280926 (* 1 = 0.280926 loss)
I0526 00:58:05.397174 15117 sgd_solver.cpp:294] Iteration 5790, lr = 0.02
I0526 00:58:11.181478 15117 solver.cpp:342] Iteration 5800, Testing net (#0)
I0526 00:58:24.236529 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7713
I0526 00:58:24.236598 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.676945 (* 1 = 0.676945 loss)
I0526 00:58:24.841513 15117 solver.cpp:233] Iteration 5800, loss = 0.455667
I0526 00:58:24.841579 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.455667 (* 1 = 0.455667 loss)
I0526 00:58:24.841593 15117 sgd_solver.cpp:294] Iteration 5800, lr = 0.02
I0526 00:58:31.285007 15117 solver.cpp:233] Iteration 5810, loss = 0.438188
I0526 00:58:31.285190 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.438188 (* 1 = 0.438188 loss)
I0526 00:58:31.285202 15117 sgd_solver.cpp:294] Iteration 5810, lr = 0.02
I0526 00:58:37.683615 15117 solver.cpp:233] Iteration 5820, loss = 0.365268
I0526 00:58:37.683683 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.365268 (* 1 = 0.365268 loss)
I0526 00:58:37.683694 15117 sgd_solver.cpp:294] Iteration 5820, lr = 0.02
I0526 00:58:44.067366 15117 solver.cpp:233] Iteration 5830, loss = 0.498084
I0526 00:58:44.067436 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.498084 (* 1 = 0.498084 loss)
I0526 00:58:44.067447 15117 sgd_solver.cpp:294] Iteration 5830, lr = 0.02
I0526 00:58:50.452494 15117 solver.cpp:233] Iteration 5840, loss = 0.21264
I0526 00:58:50.452561 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.21264 (* 1 = 0.21264 loss)
I0526 00:58:50.452571 15117 sgd_solver.cpp:294] Iteration 5840, lr = 0.02
I0526 00:58:56.839839 15117 solver.cpp:233] Iteration 5850, loss = 0.304783
I0526 00:58:56.839910 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.304783 (* 1 = 0.304783 loss)
I0526 00:58:56.839921 15117 sgd_solver.cpp:294] Iteration 5850, lr = 0.02
I0526 00:59:03.232154 15117 solver.cpp:233] Iteration 5860, loss = 0.256793
I0526 00:59:03.232318 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.256793 (* 1 = 0.256793 loss)
I0526 00:59:03.232331 15117 sgd_solver.cpp:294] Iteration 5860, lr = 0.02
I0526 00:59:09.619063 15117 solver.cpp:233] Iteration 5870, loss = 0.35389
I0526 00:59:09.619127 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.35389 (* 1 = 0.35389 loss)
I0526 00:59:09.619138 15117 sgd_solver.cpp:294] Iteration 5870, lr = 0.02
I0526 00:59:16.008272 15117 solver.cpp:233] Iteration 5880, loss = 0.25188
I0526 00:59:16.008342 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.25188 (* 1 = 0.25188 loss)
I0526 00:59:16.008353 15117 sgd_solver.cpp:294] Iteration 5880, lr = 0.02
I0526 00:59:22.399104 15117 solver.cpp:233] Iteration 5890, loss = 0.291214
I0526 00:59:22.399171 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.291214 (* 1 = 0.291214 loss)
I0526 00:59:22.399183 15117 sgd_solver.cpp:294] Iteration 5890, lr = 0.02
I0526 00:59:28.188298 15117 solver.cpp:342] Iteration 5900, Testing net (#0)
I0526 00:59:41.215199 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.6912
I0526 00:59:41.215399 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.919402 (* 1 = 0.919402 loss)
I0526 00:59:41.827873 15117 solver.cpp:233] Iteration 5900, loss = 0.333812
I0526 00:59:41.827934 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.333812 (* 1 = 0.333812 loss)
I0526 00:59:41.827944 15117 sgd_solver.cpp:294] Iteration 5900, lr = 0.02
I0526 00:59:48.271152 15117 solver.cpp:233] Iteration 5910, loss = 0.31322
I0526 00:59:48.271221 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.31322 (* 1 = 0.31322 loss)
I0526 00:59:48.271232 15117 sgd_solver.cpp:294] Iteration 5910, lr = 0.02
I0526 00:59:54.711153 15117 solver.cpp:233] Iteration 5920, loss = 0.424008
I0526 00:59:54.711220 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.424008 (* 1 = 0.424008 loss)
I0526 00:59:54.711230 15117 sgd_solver.cpp:294] Iteration 5920, lr = 0.02
I0526 01:00:01.103157 15117 solver.cpp:233] Iteration 5930, loss = 0.333211
I0526 01:00:01.103229 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.333211 (* 1 = 0.333211 loss)
I0526 01:00:01.103240 15117 sgd_solver.cpp:294] Iteration 5930, lr = 0.02
I0526 01:00:07.495726 15117 solver.cpp:233] Iteration 5940, loss = 0.289532
I0526 01:00:07.495798 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.289532 (* 1 = 0.289532 loss)
I0526 01:00:07.495810 15117 sgd_solver.cpp:294] Iteration 5940, lr = 0.02
I0526 01:00:13.898118 15117 solver.cpp:233] Iteration 5950, loss = 0.366073
I0526 01:00:13.898294 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.366073 (* 1 = 0.366073 loss)
I0526 01:00:13.898308 15117 sgd_solver.cpp:294] Iteration 5950, lr = 0.02
I0526 01:00:20.350738 15117 solver.cpp:233] Iteration 5960, loss = 0.28802
I0526 01:00:20.350800 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.28802 (* 1 = 0.28802 loss)
I0526 01:00:20.350812 15117 sgd_solver.cpp:294] Iteration 5960, lr = 0.02
I0526 01:00:26.837466 15117 solver.cpp:233] Iteration 5970, loss = 0.418989
I0526 01:00:26.837533 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.418989 (* 1 = 0.418989 loss)
I0526 01:00:26.837545 15117 sgd_solver.cpp:294] Iteration 5970, lr = 0.02
I0526 01:00:33.228199 15117 solver.cpp:233] Iteration 5980, loss = 0.282067
I0526 01:00:33.228274 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.282067 (* 1 = 0.282067 loss)
I0526 01:00:33.228286 15117 sgd_solver.cpp:294] Iteration 5980, lr = 0.02
I0526 01:00:39.605633 15117 solver.cpp:233] Iteration 5990, loss = 0.308961
I0526 01:00:39.605703 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.308961 (* 1 = 0.308961 loss)
I0526 01:00:39.605715 15117 sgd_solver.cpp:294] Iteration 5990, lr = 0.02
I0526 01:00:45.377976 15117 solver.cpp:342] Iteration 6000, Testing net (#0)
I0526 01:00:58.415490 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7572
I0526 01:00:58.415565 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.74248 (* 1 = 0.74248 loss)
I0526 01:00:59.021473 15117 solver.cpp:233] Iteration 6000, loss = 0.33016
I0526 01:00:59.021543 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.33016 (* 1 = 0.33016 loss)
I0526 01:00:59.021555 15117 sgd_solver.cpp:294] Iteration 6000, lr = 0.02
I0526 01:01:05.420056 15117 solver.cpp:233] Iteration 6010, loss = 0.33618
I0526 01:01:05.420120 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.33618 (* 1 = 0.33618 loss)
I0526 01:01:05.420130 15117 sgd_solver.cpp:294] Iteration 6010, lr = 0.02
I0526 01:01:11.857842 15117 solver.cpp:233] Iteration 6020, loss = 0.27252
I0526 01:01:11.857908 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.27252 (* 1 = 0.27252 loss)
I0526 01:01:11.857918 15117 sgd_solver.cpp:294] Iteration 6020, lr = 0.02
I0526 01:01:18.301487 15117 solver.cpp:233] Iteration 6030, loss = 0.322769
I0526 01:01:18.301705 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.322769 (* 1 = 0.322769 loss)
I0526 01:01:18.301723 15117 sgd_solver.cpp:294] Iteration 6030, lr = 0.02
I0526 01:01:24.672828 15117 solver.cpp:233] Iteration 6040, loss = 0.315981
I0526 01:01:24.672893 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.315981 (* 1 = 0.315981 loss)
I0526 01:01:24.672902 15117 sgd_solver.cpp:294] Iteration 6040, lr = 0.02
I0526 01:01:31.042189 15117 solver.cpp:233] Iteration 6050, loss = 0.322068
I0526 01:01:31.042256 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.322068 (* 1 = 0.322068 loss)
I0526 01:01:31.042268 15117 sgd_solver.cpp:294] Iteration 6050, lr = 0.02
I0526 01:01:37.416615 15117 solver.cpp:233] Iteration 6060, loss = 0.404113
I0526 01:01:37.416682 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.404113 (* 1 = 0.404113 loss)
I0526 01:01:37.416692 15117 sgd_solver.cpp:294] Iteration 6060, lr = 0.02
I0526 01:01:43.853320 15117 solver.cpp:233] Iteration 6070, loss = 0.48592
I0526 01:01:43.853387 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.48592 (* 1 = 0.48592 loss)
I0526 01:01:43.853399 15117 sgd_solver.cpp:294] Iteration 6070, lr = 0.02
I0526 01:01:50.220752 15117 solver.cpp:233] Iteration 6080, loss = 0.418632
I0526 01:01:50.220918 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.418632 (* 1 = 0.418632 loss)
I0526 01:01:50.220930 15117 sgd_solver.cpp:294] Iteration 6080, lr = 0.02
I0526 01:01:56.591192 15117 solver.cpp:233] Iteration 6090, loss = 0.393899
I0526 01:01:56.591251 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.393899 (* 1 = 0.393899 loss)
I0526 01:01:56.591262 15117 sgd_solver.cpp:294] Iteration 6090, lr = 0.02
I0526 01:02:02.359194 15117 solver.cpp:342] Iteration 6100, Testing net (#0)
I0526 01:02:15.410655 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7143
I0526 01:02:15.410725 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.881441 (* 1 = 0.881441 loss)
I0526 01:02:16.023535 15117 solver.cpp:233] Iteration 6100, loss = 0.48404
I0526 01:02:16.023605 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.48404 (* 1 = 0.48404 loss)
I0526 01:02:16.023618 15117 sgd_solver.cpp:294] Iteration 6100, lr = 0.02
I0526 01:02:22.402791 15117 solver.cpp:233] Iteration 6110, loss = 0.300672
I0526 01:02:22.402948 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.300672 (* 1 = 0.300672 loss)
I0526 01:02:22.402961 15117 sgd_solver.cpp:294] Iteration 6110, lr = 0.02
I0526 01:02:28.775923 15117 solver.cpp:233] Iteration 6120, loss = 0.370675
I0526 01:02:28.775985 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.370675 (* 1 = 0.370675 loss)
I0526 01:02:28.775996 15117 sgd_solver.cpp:294] Iteration 6120, lr = 0.02
I0526 01:02:35.141716 15117 solver.cpp:233] Iteration 6130, loss = 0.359722
I0526 01:02:35.141788 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.359722 (* 1 = 0.359722 loss)
I0526 01:02:35.141798 15117 sgd_solver.cpp:294] Iteration 6130, lr = 0.02
I0526 01:02:41.509532 15117 solver.cpp:233] Iteration 6140, loss = 0.373436
I0526 01:02:41.509593 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.373436 (* 1 = 0.373436 loss)
I0526 01:02:41.509604 15117 sgd_solver.cpp:294] Iteration 6140, lr = 0.02
I0526 01:02:47.882879 15117 solver.cpp:233] Iteration 6150, loss = 0.30074
I0526 01:02:47.882947 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.30074 (* 1 = 0.30074 loss)
I0526 01:02:47.882958 15117 sgd_solver.cpp:294] Iteration 6150, lr = 0.02
I0526 01:02:54.254405 15117 solver.cpp:233] Iteration 6160, loss = 0.236091
I0526 01:02:54.254559 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.236091 (* 1 = 0.236091 loss)
I0526 01:02:54.254570 15117 sgd_solver.cpp:294] Iteration 6160, lr = 0.02
I0526 01:03:00.635234 15117 solver.cpp:233] Iteration 6170, loss = 0.487376
I0526 01:03:00.635304 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.487376 (* 1 = 0.487376 loss)
I0526 01:03:00.635316 15117 sgd_solver.cpp:294] Iteration 6170, lr = 0.02
I0526 01:03:07.018236 15117 solver.cpp:233] Iteration 6180, loss = 0.344272
I0526 01:03:07.018314 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.344272 (* 1 = 0.344272 loss)
I0526 01:03:07.018326 15117 sgd_solver.cpp:294] Iteration 6180, lr = 0.02
I0526 01:03:13.457525 15117 solver.cpp:233] Iteration 6190, loss = 0.358099
I0526 01:03:13.457594 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.358099 (* 1 = 0.358099 loss)
I0526 01:03:13.457607 15117 sgd_solver.cpp:294] Iteration 6190, lr = 0.02
I0526 01:03:19.274557 15117 solver.cpp:342] Iteration 6200, Testing net (#0)
I0526 01:03:32.438997 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.6964
I0526 01:03:32.439203 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.945078 (* 1 = 0.945078 loss)
I0526 01:03:33.044021 15117 solver.cpp:233] Iteration 6200, loss = 0.305592
I0526 01:03:33.044090 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.305592 (* 1 = 0.305592 loss)
I0526 01:03:33.044101 15117 sgd_solver.cpp:294] Iteration 6200, lr = 0.02
I0526 01:03:39.419589 15117 solver.cpp:233] Iteration 6210, loss = 0.326663
I0526 01:03:39.419654 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.326663 (* 1 = 0.326663 loss)
I0526 01:03:39.419666 15117 sgd_solver.cpp:294] Iteration 6210, lr = 0.02
I0526 01:03:45.801857 15117 solver.cpp:233] Iteration 6220, loss = 0.358722
I0526 01:03:45.801928 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.358722 (* 1 = 0.358722 loss)
I0526 01:03:45.801939 15117 sgd_solver.cpp:294] Iteration 6220, lr = 0.02
I0526 01:03:52.192440 15117 solver.cpp:233] Iteration 6230, loss = 0.23874
I0526 01:03:52.192507 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.23874 (* 1 = 0.23874 loss)
I0526 01:03:52.192517 15117 sgd_solver.cpp:294] Iteration 6230, lr = 0.02
I0526 01:03:58.587312 15117 solver.cpp:233] Iteration 6240, loss = 0.335522
I0526 01:03:58.587388 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.335522 (* 1 = 0.335522 loss)
I0526 01:03:58.587401 15117 sgd_solver.cpp:294] Iteration 6240, lr = 0.02
I0526 01:04:04.976578 15117 solver.cpp:233] Iteration 6250, loss = 0.249286
I0526 01:04:04.976734 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.249286 (* 1 = 0.249286 loss)
I0526 01:04:04.976745 15117 sgd_solver.cpp:294] Iteration 6250, lr = 0.02
I0526 01:04:11.370961 15117 solver.cpp:233] Iteration 6260, loss = 0.341923
I0526 01:04:11.371036 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.341923 (* 1 = 0.341923 loss)
I0526 01:04:11.371047 15117 sgd_solver.cpp:294] Iteration 6260, lr = 0.02
I0526 01:04:17.764775 15117 solver.cpp:233] Iteration 6270, loss = 0.285027
I0526 01:04:17.764844 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.285027 (* 1 = 0.285027 loss)
I0526 01:04:17.764855 15117 sgd_solver.cpp:294] Iteration 6270, lr = 0.02
I0526 01:04:24.145136 15117 solver.cpp:233] Iteration 6280, loss = 0.30103
I0526 01:04:24.145203 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.30103 (* 1 = 0.30103 loss)
I0526 01:04:24.145213 15117 sgd_solver.cpp:294] Iteration 6280, lr = 0.02
I0526 01:04:30.514116 15117 solver.cpp:233] Iteration 6290, loss = 0.411545
I0526 01:04:30.514183 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.411545 (* 1 = 0.411545 loss)
I0526 01:04:30.514194 15117 sgd_solver.cpp:294] Iteration 6290, lr = 0.02
I0526 01:04:36.281975 15117 solver.cpp:342] Iteration 6300, Testing net (#0)
I0526 01:04:49.280289 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8182
I0526 01:04:49.280359 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.533333 (* 1 = 0.533333 loss)
I0526 01:04:49.890710 15117 solver.cpp:233] Iteration 6300, loss = 0.370889
I0526 01:04:49.890779 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.370889 (* 1 = 0.370889 loss)
I0526 01:04:49.890791 15117 sgd_solver.cpp:294] Iteration 6300, lr = 0.02
I0526 01:04:56.262334 15117 solver.cpp:233] Iteration 6310, loss = 0.340209
I0526 01:04:56.262403 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.340209 (* 1 = 0.340209 loss)
I0526 01:04:56.262413 15117 sgd_solver.cpp:294] Iteration 6310, lr = 0.02
I0526 01:05:02.633908 15117 solver.cpp:233] Iteration 6320, loss = 0.310939
I0526 01:05:02.633976 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.310939 (* 1 = 0.310939 loss)
I0526 01:05:02.633986 15117 sgd_solver.cpp:294] Iteration 6320, lr = 0.02
I0526 01:05:09.014221 15117 solver.cpp:233] Iteration 6330, loss = 0.271958
I0526 01:05:09.014433 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.271958 (* 1 = 0.271958 loss)
I0526 01:05:09.014446 15117 sgd_solver.cpp:294] Iteration 6330, lr = 0.02
I0526 01:05:15.388401 15117 solver.cpp:233] Iteration 6340, loss = 0.282591
I0526 01:05:15.388469 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.282591 (* 1 = 0.282591 loss)
I0526 01:05:15.388480 15117 sgd_solver.cpp:294] Iteration 6340, lr = 0.02
I0526 01:05:21.761587 15117 solver.cpp:233] Iteration 6350, loss = 0.233205
I0526 01:05:21.761654 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.233205 (* 1 = 0.233205 loss)
I0526 01:05:21.761667 15117 sgd_solver.cpp:294] Iteration 6350, lr = 0.02
I0526 01:05:28.131554 15117 solver.cpp:233] Iteration 6360, loss = 0.394431
I0526 01:05:28.131628 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.394431 (* 1 = 0.394431 loss)
I0526 01:05:28.131639 15117 sgd_solver.cpp:294] Iteration 6360, lr = 0.02
I0526 01:05:34.570530 15117 solver.cpp:233] Iteration 6370, loss = 0.219408
I0526 01:05:34.570591 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.219408 (* 1 = 0.219408 loss)
I0526 01:05:34.570601 15117 sgd_solver.cpp:294] Iteration 6370, lr = 0.02
I0526 01:05:41.009470 15117 solver.cpp:233] Iteration 6380, loss = 0.303441
I0526 01:05:41.009629 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.303441 (* 1 = 0.303441 loss)
I0526 01:05:41.009639 15117 sgd_solver.cpp:294] Iteration 6380, lr = 0.02
I0526 01:05:47.456163 15117 solver.cpp:233] Iteration 6390, loss = 0.363981
I0526 01:05:47.456231 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.363981 (* 1 = 0.363981 loss)
I0526 01:05:47.456243 15117 sgd_solver.cpp:294] Iteration 6390, lr = 0.02
I0526 01:05:53.284821 15117 solver.cpp:342] Iteration 6400, Testing net (#0)
I0526 01:06:06.435799 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7502
I0526 01:06:06.435868 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.768467 (* 1 = 0.768467 loss)
I0526 01:06:07.049335 15117 solver.cpp:233] Iteration 6400, loss = 0.271478
I0526 01:06:07.049402 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.271478 (* 1 = 0.271478 loss)
I0526 01:06:07.049414 15117 sgd_solver.cpp:294] Iteration 6400, lr = 0.02
I0526 01:06:13.459817 15117 solver.cpp:233] Iteration 6410, loss = 0.395134
I0526 01:06:13.459993 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.395134 (* 1 = 0.395134 loss)
I0526 01:06:13.460005 15117 sgd_solver.cpp:294] Iteration 6410, lr = 0.02
I0526 01:06:19.832578 15117 solver.cpp:233] Iteration 6420, loss = 0.215724
I0526 01:06:19.832645 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.215724 (* 1 = 0.215724 loss)
I0526 01:06:19.832655 15117 sgd_solver.cpp:294] Iteration 6420, lr = 0.02
I0526 01:06:26.200042 15117 solver.cpp:233] Iteration 6430, loss = 0.440944
I0526 01:06:26.200105 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.440944 (* 1 = 0.440944 loss)
I0526 01:06:26.200116 15117 sgd_solver.cpp:294] Iteration 6430, lr = 0.02
I0526 01:06:32.572190 15117 solver.cpp:233] Iteration 6440, loss = 0.400358
I0526 01:06:32.572255 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.400358 (* 1 = 0.400358 loss)
I0526 01:06:32.572266 15117 sgd_solver.cpp:294] Iteration 6440, lr = 0.02
I0526 01:06:38.942272 15117 solver.cpp:233] Iteration 6450, loss = 0.417953
I0526 01:06:38.942349 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.417953 (* 1 = 0.417953 loss)
I0526 01:06:38.942430 15117 sgd_solver.cpp:294] Iteration 6450, lr = 0.02
I0526 01:06:45.311331 15117 solver.cpp:233] Iteration 6460, loss = 0.381244
I0526 01:06:45.311529 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.381244 (* 1 = 0.381244 loss)
I0526 01:06:45.311542 15117 sgd_solver.cpp:294] Iteration 6460, lr = 0.02
I0526 01:06:51.684437 15117 solver.cpp:233] Iteration 6470, loss = 0.233405
I0526 01:06:51.684500 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.233405 (* 1 = 0.233405 loss)
I0526 01:06:51.684510 15117 sgd_solver.cpp:294] Iteration 6470, lr = 0.02
I0526 01:06:58.056399 15117 solver.cpp:233] Iteration 6480, loss = 0.243758
I0526 01:06:58.056475 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.243758 (* 1 = 0.243758 loss)
I0526 01:06:58.056488 15117 sgd_solver.cpp:294] Iteration 6480, lr = 0.02
I0526 01:07:04.426563 15117 solver.cpp:233] Iteration 6490, loss = 0.449816
I0526 01:07:04.426630 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.449816 (* 1 = 0.449816 loss)
I0526 01:07:04.426641 15117 sgd_solver.cpp:294] Iteration 6490, lr = 0.02
I0526 01:07:10.197279 15117 solver.cpp:342] Iteration 6500, Testing net (#0)
I0526 01:07:23.231959 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.6987
I0526 01:07:23.232126 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.918226 (* 1 = 0.918226 loss)
I0526 01:07:23.836518 15117 solver.cpp:233] Iteration 6500, loss = 0.412653
I0526 01:07:23.836580 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.412653 (* 1 = 0.412653 loss)
I0526 01:07:23.836591 15117 sgd_solver.cpp:294] Iteration 6500, lr = 0.02
I0526 01:07:30.249028 15117 solver.cpp:233] Iteration 6510, loss = 0.347428
I0526 01:07:30.249097 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.347428 (* 1 = 0.347428 loss)
I0526 01:07:30.249109 15117 sgd_solver.cpp:294] Iteration 6510, lr = 0.02
I0526 01:07:36.648332 15117 solver.cpp:233] Iteration 6520, loss = 0.367197
I0526 01:07:36.648399 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.367197 (* 1 = 0.367197 loss)
I0526 01:07:36.648411 15117 sgd_solver.cpp:294] Iteration 6520, lr = 0.02
I0526 01:07:43.026370 15117 solver.cpp:233] Iteration 6530, loss = 0.267548
I0526 01:07:43.026442 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.267548 (* 1 = 0.267548 loss)
I0526 01:07:43.026454 15117 sgd_solver.cpp:294] Iteration 6530, lr = 0.02
I0526 01:07:49.416383 15117 solver.cpp:233] Iteration 6540, loss = 0.25395
I0526 01:07:49.416451 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.25395 (* 1 = 0.25395 loss)
I0526 01:07:49.416461 15117 sgd_solver.cpp:294] Iteration 6540, lr = 0.02
I0526 01:07:55.806668 15117 solver.cpp:233] Iteration 6550, loss = 0.314855
I0526 01:07:55.806823 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.314855 (* 1 = 0.314855 loss)
I0526 01:07:55.806835 15117 sgd_solver.cpp:294] Iteration 6550, lr = 0.02
I0526 01:08:02.187661 15117 solver.cpp:233] Iteration 6560, loss = 0.453739
I0526 01:08:02.187738 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.453739 (* 1 = 0.453739 loss)
I0526 01:08:02.187750 15117 sgd_solver.cpp:294] Iteration 6560, lr = 0.02
I0526 01:08:08.577589 15117 solver.cpp:233] Iteration 6570, loss = 0.348687
I0526 01:08:08.577659 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.348687 (* 1 = 0.348687 loss)
I0526 01:08:08.577672 15117 sgd_solver.cpp:294] Iteration 6570, lr = 0.02
I0526 01:08:14.972949 15117 solver.cpp:233] Iteration 6580, loss = 0.157859
I0526 01:08:14.973019 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.157859 (* 1 = 0.157859 loss)
I0526 01:08:14.973031 15117 sgd_solver.cpp:294] Iteration 6580, lr = 0.02
I0526 01:08:21.363682 15117 solver.cpp:233] Iteration 6590, loss = 0.225632
I0526 01:08:21.363751 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.225632 (* 1 = 0.225632 loss)
I0526 01:08:21.363772 15117 sgd_solver.cpp:294] Iteration 6590, lr = 0.02
I0526 01:08:27.142334 15117 solver.cpp:342] Iteration 6600, Testing net (#0)
I0526 01:08:40.200600 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8088
I0526 01:08:40.200667 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.569813 (* 1 = 0.569813 loss)
I0526 01:08:40.807257 15117 solver.cpp:233] Iteration 6600, loss = 0.372593
I0526 01:08:40.807324 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.372593 (* 1 = 0.372593 loss)
I0526 01:08:40.807337 15117 sgd_solver.cpp:294] Iteration 6600, lr = 0.02
I0526 01:08:47.207280 15117 solver.cpp:233] Iteration 6610, loss = 0.240782
I0526 01:08:47.207352 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.240782 (* 1 = 0.240782 loss)
I0526 01:08:47.207363 15117 sgd_solver.cpp:294] Iteration 6610, lr = 0.02
I0526 01:08:53.596211 15117 solver.cpp:233] Iteration 6620, loss = 0.298822
I0526 01:08:53.596281 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.298822 (* 1 = 0.298822 loss)
I0526 01:08:53.596290 15117 sgd_solver.cpp:294] Iteration 6620, lr = 0.02
I0526 01:08:59.985976 15117 solver.cpp:233] Iteration 6630, loss = 0.281131
I0526 01:08:59.986156 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.281131 (* 1 = 0.281131 loss)
I0526 01:08:59.986168 15117 sgd_solver.cpp:294] Iteration 6630, lr = 0.02
I0526 01:09:06.363684 15117 solver.cpp:233] Iteration 6640, loss = 0.30994
I0526 01:09:06.363749 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.30994 (* 1 = 0.30994 loss)
I0526 01:09:06.363759 15117 sgd_solver.cpp:294] Iteration 6640, lr = 0.02
I0526 01:09:12.752143 15117 solver.cpp:233] Iteration 6650, loss = 0.392658
I0526 01:09:12.752226 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.392658 (* 1 = 0.392658 loss)
I0526 01:09:12.752239 15117 sgd_solver.cpp:294] Iteration 6650, lr = 0.02
I0526 01:09:19.148773 15117 solver.cpp:233] Iteration 6660, loss = 0.22437
I0526 01:09:19.148839 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.22437 (* 1 = 0.22437 loss)
I0526 01:09:19.148851 15117 sgd_solver.cpp:294] Iteration 6660, lr = 0.02
I0526 01:09:25.564019 15117 solver.cpp:233] Iteration 6670, loss = 0.339195
I0526 01:09:25.564090 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.339195 (* 1 = 0.339195 loss)
I0526 01:09:25.564100 15117 sgd_solver.cpp:294] Iteration 6670, lr = 0.02
I0526 01:09:32.032341 15117 solver.cpp:233] Iteration 6680, loss = 0.441018
I0526 01:09:32.032506 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.441018 (* 1 = 0.441018 loss)
I0526 01:09:32.032518 15117 sgd_solver.cpp:294] Iteration 6680, lr = 0.02
I0526 01:09:38.456071 15117 solver.cpp:233] Iteration 6690, loss = 0.237558
I0526 01:09:38.456138 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.237558 (* 1 = 0.237558 loss)
I0526 01:09:38.456149 15117 sgd_solver.cpp:294] Iteration 6690, lr = 0.02
I0526 01:09:44.248610 15117 solver.cpp:342] Iteration 6700, Testing net (#0)
I0526 01:09:57.329135 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.768
I0526 01:09:57.329202 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.704366 (* 1 = 0.704366 loss)
I0526 01:09:57.938031 15117 solver.cpp:233] Iteration 6700, loss = 0.288004
I0526 01:09:57.938107 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.288004 (* 1 = 0.288004 loss)
I0526 01:09:57.938119 15117 sgd_solver.cpp:294] Iteration 6700, lr = 0.02
I0526 01:10:04.328712 15117 solver.cpp:233] Iteration 6710, loss = 0.300237
I0526 01:10:04.328855 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.300237 (* 1 = 0.300237 loss)
I0526 01:10:04.328866 15117 sgd_solver.cpp:294] Iteration 6710, lr = 0.02
I0526 01:10:10.718046 15117 solver.cpp:233] Iteration 6720, loss = 0.355565
I0526 01:10:10.718117 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.355565 (* 1 = 0.355565 loss)
I0526 01:10:10.718138 15117 sgd_solver.cpp:294] Iteration 6720, lr = 0.02
I0526 01:10:17.121506 15117 solver.cpp:233] Iteration 6730, loss = 0.296926
I0526 01:10:17.121582 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.296926 (* 1 = 0.296926 loss)
I0526 01:10:17.121593 15117 sgd_solver.cpp:294] Iteration 6730, lr = 0.02
I0526 01:10:23.613852 15117 solver.cpp:233] Iteration 6740, loss = 0.210778
I0526 01:10:23.613925 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.210778 (* 1 = 0.210778 loss)
I0526 01:10:23.613937 15117 sgd_solver.cpp:294] Iteration 6740, lr = 0.02
I0526 01:10:30.033056 15117 solver.cpp:233] Iteration 6750, loss = 0.326744
I0526 01:10:30.033128 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.326744 (* 1 = 0.326744 loss)
I0526 01:10:30.033138 15117 sgd_solver.cpp:294] Iteration 6750, lr = 0.02
I0526 01:10:36.440248 15117 solver.cpp:233] Iteration 6760, loss = 0.341083
I0526 01:10:36.440469 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.341083 (* 1 = 0.341083 loss)
I0526 01:10:36.440482 15117 sgd_solver.cpp:294] Iteration 6760, lr = 0.02
I0526 01:10:42.839946 15117 solver.cpp:233] Iteration 6770, loss = 0.393128
I0526 01:10:42.840029 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.393128 (* 1 = 0.393128 loss)
I0526 01:10:42.840042 15117 sgd_solver.cpp:294] Iteration 6770, lr = 0.02
I0526 01:10:49.238411 15117 solver.cpp:233] Iteration 6780, loss = 0.240774
I0526 01:10:49.238476 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.240774 (* 1 = 0.240774 loss)
I0526 01:10:49.238486 15117 sgd_solver.cpp:294] Iteration 6780, lr = 0.02
I0526 01:10:55.648871 15117 solver.cpp:233] Iteration 6790, loss = 0.313848
I0526 01:10:55.648939 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.313848 (* 1 = 0.313848 loss)
I0526 01:10:55.648950 15117 sgd_solver.cpp:294] Iteration 6790, lr = 0.02
I0526 01:11:01.452095 15117 solver.cpp:342] Iteration 6800, Testing net (#0)
I0526 01:11:14.606750 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7746
I0526 01:11:14.606920 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.716816 (* 1 = 0.716816 loss)
I0526 01:11:15.211007 15117 solver.cpp:233] Iteration 6800, loss = 0.434585
I0526 01:11:15.211071 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.434585 (* 1 = 0.434585 loss)
I0526 01:11:15.211086 15117 sgd_solver.cpp:294] Iteration 6800, lr = 0.02
I0526 01:11:21.585847 15117 solver.cpp:233] Iteration 6810, loss = 0.37778
I0526 01:11:21.585916 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.37778 (* 1 = 0.37778 loss)
I0526 01:11:21.585925 15117 sgd_solver.cpp:294] Iteration 6810, lr = 0.02
I0526 01:11:27.966524 15117 solver.cpp:233] Iteration 6820, loss = 0.283018
I0526 01:11:27.966603 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.283018 (* 1 = 0.283018 loss)
I0526 01:11:27.966616 15117 sgd_solver.cpp:294] Iteration 6820, lr = 0.02
I0526 01:11:34.362637 15117 solver.cpp:233] Iteration 6830, loss = 0.420551
I0526 01:11:34.362692 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.420551 (* 1 = 0.420551 loss)
I0526 01:11:34.362702 15117 sgd_solver.cpp:294] Iteration 6830, lr = 0.02
I0526 01:11:40.760815 15117 solver.cpp:233] Iteration 6840, loss = 0.338672
I0526 01:11:40.760885 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.338672 (* 1 = 0.338672 loss)
I0526 01:11:40.760896 15117 sgd_solver.cpp:294] Iteration 6840, lr = 0.02
I0526 01:11:47.163900 15117 solver.cpp:233] Iteration 6850, loss = 0.487661
I0526 01:11:47.164055 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.487661 (* 1 = 0.487661 loss)
I0526 01:11:47.164067 15117 sgd_solver.cpp:294] Iteration 6850, lr = 0.02
I0526 01:11:53.565515 15117 solver.cpp:233] Iteration 6860, loss = 0.262415
I0526 01:11:53.565592 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.262415 (* 1 = 0.262415 loss)
I0526 01:11:53.565614 15117 sgd_solver.cpp:294] Iteration 6860, lr = 0.02
I0526 01:11:59.946573 15117 solver.cpp:233] Iteration 6870, loss = 0.280652
I0526 01:11:59.946641 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.280652 (* 1 = 0.280652 loss)
I0526 01:11:59.946653 15117 sgd_solver.cpp:294] Iteration 6870, lr = 0.02
I0526 01:12:06.324921 15117 solver.cpp:233] Iteration 6880, loss = 0.42156
I0526 01:12:06.324991 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.42156 (* 1 = 0.42156 loss)
I0526 01:12:06.325001 15117 sgd_solver.cpp:294] Iteration 6880, lr = 0.02
I0526 01:12:12.715364 15117 solver.cpp:233] Iteration 6890, loss = 0.393547
I0526 01:12:12.715441 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.393547 (* 1 = 0.393547 loss)
I0526 01:12:12.715456 15117 sgd_solver.cpp:294] Iteration 6890, lr = 0.02
I0526 01:12:18.501991 15117 solver.cpp:342] Iteration 6900, Testing net (#0)
I0526 01:12:31.632621 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7342
I0526 01:12:31.632694 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.887532 (* 1 = 0.887532 loss)
I0526 01:12:32.236510 15117 solver.cpp:233] Iteration 6900, loss = 0.442196
I0526 01:12:32.236577 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.442196 (* 1 = 0.442196 loss)
I0526 01:12:32.236590 15117 sgd_solver.cpp:294] Iteration 6900, lr = 0.02
I0526 01:12:38.611160 15117 solver.cpp:233] Iteration 6910, loss = 0.321917
I0526 01:12:38.611224 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.321917 (* 1 = 0.321917 loss)
I0526 01:12:38.611234 15117 sgd_solver.cpp:294] Iteration 6910, lr = 0.02
I0526 01:12:44.992043 15117 solver.cpp:233] Iteration 6920, loss = 0.307644
I0526 01:12:44.992113 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.307644 (* 1 = 0.307644 loss)
I0526 01:12:44.992125 15117 sgd_solver.cpp:294] Iteration 6920, lr = 0.02
I0526 01:12:51.379837 15117 solver.cpp:233] Iteration 6930, loss = 0.325416
I0526 01:12:51.380005 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.325416 (* 1 = 0.325416 loss)
I0526 01:12:51.380017 15117 sgd_solver.cpp:294] Iteration 6930, lr = 0.02
I0526 01:12:57.760100 15117 solver.cpp:233] Iteration 6940, loss = 0.28239
I0526 01:12:57.760176 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.28239 (* 1 = 0.28239 loss)
I0526 01:12:57.760188 15117 sgd_solver.cpp:294] Iteration 6940, lr = 0.02
I0526 01:13:04.136796 15117 solver.cpp:233] Iteration 6950, loss = 0.296166
I0526 01:13:04.136864 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.296166 (* 1 = 0.296166 loss)
I0526 01:13:04.136875 15117 sgd_solver.cpp:294] Iteration 6950, lr = 0.02
I0526 01:13:10.515074 15117 solver.cpp:233] Iteration 6960, loss = 0.394704
I0526 01:13:10.515141 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.394704 (* 1 = 0.394704 loss)
I0526 01:13:10.515151 15117 sgd_solver.cpp:294] Iteration 6960, lr = 0.02
I0526 01:13:16.901193 15117 solver.cpp:233] Iteration 6970, loss = 0.190194
I0526 01:13:16.901262 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.190194 (* 1 = 0.190194 loss)
I0526 01:13:16.901273 15117 sgd_solver.cpp:294] Iteration 6970, lr = 0.02
I0526 01:13:23.279470 15117 solver.cpp:233] Iteration 6980, loss = 0.322266
I0526 01:13:23.279623 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.322266 (* 1 = 0.322266 loss)
I0526 01:13:23.279635 15117 sgd_solver.cpp:294] Iteration 6980, lr = 0.02
I0526 01:13:29.658561 15117 solver.cpp:233] Iteration 6990, loss = 0.46243
I0526 01:13:29.658632 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.46243 (* 1 = 0.46243 loss)
I0526 01:13:29.658643 15117 sgd_solver.cpp:294] Iteration 6990, lr = 0.02
I0526 01:13:35.436008 15117 solver.cpp:342] Iteration 7000, Testing net (#0)
I0526 01:13:48.504685 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7708
I0526 01:13:48.504760 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.760204 (* 1 = 0.760204 loss)
I0526 01:13:49.112262 15117 solver.cpp:233] Iteration 7000, loss = 0.3177
I0526 01:13:49.112330 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.3177 (* 1 = 0.3177 loss)
I0526 01:13:49.112344 15117 sgd_solver.cpp:294] Iteration 7000, lr = 0.02
I0526 01:13:55.528357 15117 solver.cpp:233] Iteration 7010, loss = 0.263403
I0526 01:13:55.530446 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.263403 (* 1 = 0.263403 loss)
I0526 01:13:55.530468 15117 sgd_solver.cpp:294] Iteration 7010, lr = 0.02
I0526 01:14:01.929321 15117 solver.cpp:233] Iteration 7020, loss = 0.263355
I0526 01:14:01.929399 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.263355 (* 1 = 0.263355 loss)
I0526 01:14:01.929409 15117 sgd_solver.cpp:294] Iteration 7020, lr = 0.02
I0526 01:14:08.317235 15117 solver.cpp:233] Iteration 7030, loss = 0.210639
I0526 01:14:08.317296 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.210639 (* 1 = 0.210639 loss)
I0526 01:14:08.317306 15117 sgd_solver.cpp:294] Iteration 7030, lr = 0.02
I0526 01:14:14.710048 15117 solver.cpp:233] Iteration 7040, loss = 0.311046
I0526 01:14:14.710119 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.311046 (* 1 = 0.311046 loss)
I0526 01:14:14.710131 15117 sgd_solver.cpp:294] Iteration 7040, lr = 0.02
I0526 01:14:21.129117 15117 solver.cpp:233] Iteration 7050, loss = 0.194206
I0526 01:14:21.129185 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.194206 (* 1 = 0.194206 loss)
I0526 01:14:21.129196 15117 sgd_solver.cpp:294] Iteration 7050, lr = 0.02
I0526 01:14:27.573158 15117 solver.cpp:233] Iteration 7060, loss = 0.235698
I0526 01:14:27.573318 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.235698 (* 1 = 0.235698 loss)
I0526 01:14:27.573331 15117 sgd_solver.cpp:294] Iteration 7060, lr = 0.02
I0526 01:14:34.023797 15117 solver.cpp:233] Iteration 7070, loss = 0.510821
I0526 01:14:34.023861 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.510821 (* 1 = 0.510821 loss)
I0526 01:14:34.023872 15117 sgd_solver.cpp:294] Iteration 7070, lr = 0.02
I0526 01:14:40.462079 15117 solver.cpp:233] Iteration 7080, loss = 0.357281
I0526 01:14:40.462143 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.357281 (* 1 = 0.357281 loss)
I0526 01:14:40.462155 15117 sgd_solver.cpp:294] Iteration 7080, lr = 0.02
I0526 01:14:46.846457 15117 solver.cpp:233] Iteration 7090, loss = 0.448635
I0526 01:14:46.846526 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.448635 (* 1 = 0.448635 loss)
I0526 01:14:46.846539 15117 sgd_solver.cpp:294] Iteration 7090, lr = 0.02
I0526 01:14:52.662894 15117 solver.cpp:342] Iteration 7100, Testing net (#0)
I0526 01:15:05.684684 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7753
I0526 01:15:05.684906 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.688068 (* 1 = 0.688068 loss)
I0526 01:15:06.298444 15117 solver.cpp:233] Iteration 7100, loss = 0.2515
I0526 01:15:06.298508 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.2515 (* 1 = 0.2515 loss)
I0526 01:15:06.298521 15117 sgd_solver.cpp:294] Iteration 7100, lr = 0.02
I0526 01:15:12.712316 15117 solver.cpp:233] Iteration 7110, loss = 0.361983
I0526 01:15:12.712389 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.361983 (* 1 = 0.361983 loss)
I0526 01:15:12.712402 15117 sgd_solver.cpp:294] Iteration 7110, lr = 0.02
I0526 01:15:19.087749 15117 solver.cpp:233] Iteration 7120, loss = 0.278608
I0526 01:15:19.087817 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.278608 (* 1 = 0.278608 loss)
I0526 01:15:19.087828 15117 sgd_solver.cpp:294] Iteration 7120, lr = 0.02
I0526 01:15:25.463501 15117 solver.cpp:233] Iteration 7130, loss = 0.282735
I0526 01:15:25.463604 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.282735 (* 1 = 0.282735 loss)
I0526 01:15:25.463618 15117 sgd_solver.cpp:294] Iteration 7130, lr = 0.02
I0526 01:15:31.843201 15117 solver.cpp:233] Iteration 7140, loss = 0.372363
I0526 01:15:31.843329 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.372363 (* 1 = 0.372363 loss)
I0526 01:15:31.843344 15117 sgd_solver.cpp:294] Iteration 7140, lr = 0.02
I0526 01:15:38.248286 15117 solver.cpp:233] Iteration 7150, loss = 0.376549
I0526 01:15:38.248522 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.376549 (* 1 = 0.376549 loss)
I0526 01:15:38.248536 15117 sgd_solver.cpp:294] Iteration 7150, lr = 0.02
I0526 01:15:44.618016 15117 solver.cpp:233] Iteration 7160, loss = 0.470606
I0526 01:15:44.618080 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.470606 (* 1 = 0.470606 loss)
I0526 01:15:44.618090 15117 sgd_solver.cpp:294] Iteration 7160, lr = 0.02
I0526 01:15:50.986199 15117 solver.cpp:233] Iteration 7170, loss = 0.224825
I0526 01:15:50.986263 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.224825 (* 1 = 0.224825 loss)
I0526 01:15:50.986274 15117 sgd_solver.cpp:294] Iteration 7170, lr = 0.02
I0526 01:15:57.353040 15117 solver.cpp:233] Iteration 7180, loss = 0.388988
I0526 01:15:57.353103 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.388988 (* 1 = 0.388988 loss)
I0526 01:15:57.353114 15117 sgd_solver.cpp:294] Iteration 7180, lr = 0.02
I0526 01:16:03.722817 15117 solver.cpp:233] Iteration 7190, loss = 0.342099
I0526 01:16:03.722882 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.342099 (* 1 = 0.342099 loss)
I0526 01:16:03.722893 15117 sgd_solver.cpp:294] Iteration 7190, lr = 0.02
I0526 01:16:09.485210 15117 solver.cpp:342] Iteration 7200, Testing net (#0)
I0526 01:16:22.662195 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7238
I0526 01:16:22.662266 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.923635 (* 1 = 0.923635 loss)
I0526 01:16:23.267169 15117 solver.cpp:233] Iteration 7200, loss = 0.296834
I0526 01:16:23.267232 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.296834 (* 1 = 0.296834 loss)
I0526 01:16:23.267246 15117 sgd_solver.cpp:294] Iteration 7200, lr = 0.02
I0526 01:16:29.635594 15117 solver.cpp:233] Iteration 7210, loss = 0.326025
I0526 01:16:29.635658 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.326025 (* 1 = 0.326025 loss)
I0526 01:16:29.635669 15117 sgd_solver.cpp:294] Iteration 7210, lr = 0.02
I0526 01:16:36.022625 15117 solver.cpp:233] Iteration 7220, loss = 0.29876
I0526 01:16:36.022691 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.29876 (* 1 = 0.29876 loss)
I0526 01:16:36.022701 15117 sgd_solver.cpp:294] Iteration 7220, lr = 0.02
I0526 01:16:42.387233 15117 solver.cpp:233] Iteration 7230, loss = 0.421776
I0526 01:16:42.387369 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.421776 (* 1 = 0.421776 loss)
I0526 01:16:42.387380 15117 sgd_solver.cpp:294] Iteration 7230, lr = 0.02
I0526 01:16:48.748680 15117 solver.cpp:233] Iteration 7240, loss = 0.343936
I0526 01:16:48.748746 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.343936 (* 1 = 0.343936 loss)
I0526 01:16:48.748757 15117 sgd_solver.cpp:294] Iteration 7240, lr = 0.02
I0526 01:16:55.110087 15117 solver.cpp:233] Iteration 7250, loss = 0.210486
I0526 01:16:55.110154 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.210486 (* 1 = 0.210486 loss)
I0526 01:16:55.110164 15117 sgd_solver.cpp:294] Iteration 7250, lr = 0.02
I0526 01:17:01.477654 15117 solver.cpp:233] Iteration 7260, loss = 0.321823
I0526 01:17:01.477720 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.321823 (* 1 = 0.321823 loss)
I0526 01:17:01.477730 15117 sgd_solver.cpp:294] Iteration 7260, lr = 0.02
I0526 01:17:07.840353 15117 solver.cpp:233] Iteration 7270, loss = 0.316649
I0526 01:17:07.840416 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.316649 (* 1 = 0.316649 loss)
I0526 01:17:07.840426 15117 sgd_solver.cpp:294] Iteration 7270, lr = 0.02
I0526 01:17:14.207267 15117 solver.cpp:233] Iteration 7280, loss = 0.317251
I0526 01:17:14.207473 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.317251 (* 1 = 0.317251 loss)
I0526 01:17:14.207486 15117 sgd_solver.cpp:294] Iteration 7280, lr = 0.02
I0526 01:17:20.571254 15117 solver.cpp:233] Iteration 7290, loss = 0.355732
I0526 01:17:20.571316 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.355732 (* 1 = 0.355732 loss)
I0526 01:17:20.571327 15117 sgd_solver.cpp:294] Iteration 7290, lr = 0.02
I0526 01:17:26.336426 15117 solver.cpp:342] Iteration 7300, Testing net (#0)
I0526 01:17:39.415599 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.659
I0526 01:17:39.415669 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.31038 (* 1 = 1.31038 loss)
I0526 01:17:40.028671 15117 solver.cpp:233] Iteration 7300, loss = 0.327584
I0526 01:17:40.028754 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.327584 (* 1 = 0.327584 loss)
I0526 01:17:40.028767 15117 sgd_solver.cpp:294] Iteration 7300, lr = 0.02
I0526 01:17:46.488443 15117 solver.cpp:233] Iteration 7310, loss = 0.325603
I0526 01:17:46.490435 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.325603 (* 1 = 0.325603 loss)
I0526 01:17:46.490456 15117 sgd_solver.cpp:294] Iteration 7310, lr = 0.02
I0526 01:17:52.905952 15117 solver.cpp:233] Iteration 7320, loss = 0.29367
I0526 01:17:52.906013 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.29367 (* 1 = 0.29367 loss)
I0526 01:17:52.906024 15117 sgd_solver.cpp:294] Iteration 7320, lr = 0.02
I0526 01:17:59.289636 15117 solver.cpp:233] Iteration 7330, loss = 0.284624
I0526 01:17:59.289706 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.284624 (* 1 = 0.284624 loss)
I0526 01:17:59.289717 15117 sgd_solver.cpp:294] Iteration 7330, lr = 0.02
I0526 01:18:05.675160 15117 solver.cpp:233] Iteration 7340, loss = 0.352448
I0526 01:18:05.675232 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.352448 (* 1 = 0.352448 loss)
I0526 01:18:05.675242 15117 sgd_solver.cpp:294] Iteration 7340, lr = 0.02
I0526 01:18:12.062644 15117 solver.cpp:233] Iteration 7350, loss = 0.36858
I0526 01:18:12.062714 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.36858 (* 1 = 0.36858 loss)
I0526 01:18:12.062726 15117 sgd_solver.cpp:294] Iteration 7350, lr = 0.02
I0526 01:18:18.439541 15117 solver.cpp:233] Iteration 7360, loss = 0.215323
I0526 01:18:18.439692 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.215323 (* 1 = 0.215323 loss)
I0526 01:18:18.439702 15117 sgd_solver.cpp:294] Iteration 7360, lr = 0.02
I0526 01:18:24.841897 15117 solver.cpp:233] Iteration 7370, loss = 0.276723
I0526 01:18:24.841963 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.276723 (* 1 = 0.276723 loss)
I0526 01:18:24.841974 15117 sgd_solver.cpp:294] Iteration 7370, lr = 0.02
I0526 01:18:31.289928 15117 solver.cpp:233] Iteration 7380, loss = 0.437049
I0526 01:18:31.289994 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.437049 (* 1 = 0.437049 loss)
I0526 01:18:31.290004 15117 sgd_solver.cpp:294] Iteration 7380, lr = 0.02
I0526 01:18:37.717288 15117 solver.cpp:233] Iteration 7390, loss = 0.26599
I0526 01:18:37.717357 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.26599 (* 1 = 0.26599 loss)
I0526 01:18:37.717370 15117 sgd_solver.cpp:294] Iteration 7390, lr = 0.02
I0526 01:18:43.489001 15117 solver.cpp:342] Iteration 7400, Testing net (#0)
I0526 01:18:56.559111 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7977
I0526 01:18:56.559257 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.603502 (* 1 = 0.603502 loss)
I0526 01:18:57.163714 15117 solver.cpp:233] Iteration 7400, loss = 0.26954
I0526 01:18:57.163779 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.26954 (* 1 = 0.26954 loss)
I0526 01:18:57.163790 15117 sgd_solver.cpp:294] Iteration 7400, lr = 0.02
I0526 01:19:03.532814 15117 solver.cpp:233] Iteration 7410, loss = 0.2514
I0526 01:19:03.532879 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.2514 (* 1 = 0.2514 loss)
I0526 01:19:03.532899 15117 sgd_solver.cpp:294] Iteration 7410, lr = 0.02
I0526 01:19:09.906069 15117 solver.cpp:233] Iteration 7420, loss = 0.316848
I0526 01:19:09.906134 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.316848 (* 1 = 0.316848 loss)
I0526 01:19:09.906146 15117 sgd_solver.cpp:294] Iteration 7420, lr = 0.02
I0526 01:19:16.281720 15117 solver.cpp:233] Iteration 7430, loss = 0.29809
I0526 01:19:16.281791 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.29809 (* 1 = 0.29809 loss)
I0526 01:19:16.281802 15117 sgd_solver.cpp:294] Iteration 7430, lr = 0.02
I0526 01:19:22.657099 15117 solver.cpp:233] Iteration 7440, loss = 0.268572
I0526 01:19:22.657167 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.268572 (* 1 = 0.268572 loss)
I0526 01:19:22.657177 15117 sgd_solver.cpp:294] Iteration 7440, lr = 0.02
I0526 01:19:29.041028 15117 solver.cpp:233] Iteration 7450, loss = 0.289333
I0526 01:19:29.041308 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.289333 (* 1 = 0.289333 loss)
I0526 01:19:29.041329 15117 sgd_solver.cpp:294] Iteration 7450, lr = 0.02
I0526 01:19:35.428035 15117 solver.cpp:233] Iteration 7460, loss = 0.487554
I0526 01:19:35.428105 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.487554 (* 1 = 0.487554 loss)
I0526 01:19:35.428117 15117 sgd_solver.cpp:294] Iteration 7460, lr = 0.02
I0526 01:19:41.811569 15117 solver.cpp:233] Iteration 7470, loss = 0.269874
I0526 01:19:41.811638 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.269874 (* 1 = 0.269874 loss)
I0526 01:19:41.811650 15117 sgd_solver.cpp:294] Iteration 7470, lr = 0.02
I0526 01:19:48.198097 15117 solver.cpp:233] Iteration 7480, loss = 0.250004
I0526 01:19:48.198173 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.250004 (* 1 = 0.250004 loss)
I0526 01:19:48.198184 15117 sgd_solver.cpp:294] Iteration 7480, lr = 0.02
I0526 01:19:54.583787 15117 solver.cpp:233] Iteration 7490, loss = 0.365125
I0526 01:19:54.583858 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.365125 (* 1 = 0.365125 loss)
I0526 01:19:54.583868 15117 sgd_solver.cpp:294] Iteration 7490, lr = 0.02
I0526 01:20:00.364652 15117 solver.cpp:342] Iteration 7500, Testing net (#0)
I0526 01:20:13.418671 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7027
I0526 01:20:13.418745 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.955634 (* 1 = 0.955634 loss)
I0526 01:20:14.024384 15117 solver.cpp:233] Iteration 7500, loss = 0.229067
I0526 01:20:14.024451 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.229067 (* 1 = 0.229067 loss)
I0526 01:20:14.024464 15117 sgd_solver.cpp:294] Iteration 7500, lr = 0.02
I0526 01:20:20.407654 15117 solver.cpp:233] Iteration 7510, loss = 0.306297
I0526 01:20:20.407723 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.306297 (* 1 = 0.306297 loss)
I0526 01:20:20.407734 15117 sgd_solver.cpp:294] Iteration 7510, lr = 0.02
I0526 01:20:26.792225 15117 solver.cpp:233] Iteration 7520, loss = 0.248749
I0526 01:20:26.792294 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.248749 (* 1 = 0.248749 loss)
I0526 01:20:26.792305 15117 sgd_solver.cpp:294] Iteration 7520, lr = 0.02
I0526 01:20:33.169483 15117 solver.cpp:233] Iteration 7530, loss = 0.397133
I0526 01:20:33.169637 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.397133 (* 1 = 0.397133 loss)
I0526 01:20:33.169649 15117 sgd_solver.cpp:294] Iteration 7530, lr = 0.02
I0526 01:20:39.551913 15117 solver.cpp:233] Iteration 7540, loss = 0.246564
I0526 01:20:39.551982 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.246564 (* 1 = 0.246564 loss)
I0526 01:20:39.551995 15117 sgd_solver.cpp:294] Iteration 7540, lr = 0.02
I0526 01:20:45.936108 15117 solver.cpp:233] Iteration 7550, loss = 0.378043
I0526 01:20:45.936179 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.378043 (* 1 = 0.378043 loss)
I0526 01:20:45.936200 15117 sgd_solver.cpp:294] Iteration 7550, lr = 0.02
I0526 01:20:52.322875 15117 solver.cpp:233] Iteration 7560, loss = 0.340502
I0526 01:20:52.322942 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.340502 (* 1 = 0.340502 loss)
I0526 01:20:52.322953 15117 sgd_solver.cpp:294] Iteration 7560, lr = 0.02
I0526 01:20:58.708528 15117 solver.cpp:233] Iteration 7570, loss = 0.354108
I0526 01:20:58.708595 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.354108 (* 1 = 0.354108 loss)
I0526 01:20:58.708606 15117 sgd_solver.cpp:294] Iteration 7570, lr = 0.02
I0526 01:21:05.097975 15117 solver.cpp:233] Iteration 7580, loss = 0.319849
I0526 01:21:05.098219 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.319849 (* 1 = 0.319849 loss)
I0526 01:21:05.098232 15117 sgd_solver.cpp:294] Iteration 7580, lr = 0.02
I0526 01:21:11.485851 15117 solver.cpp:233] Iteration 7590, loss = 0.370617
I0526 01:21:11.485919 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.370617 (* 1 = 0.370617 loss)
I0526 01:21:11.485930 15117 sgd_solver.cpp:294] Iteration 7590, lr = 0.02
I0526 01:21:17.269306 15117 solver.cpp:342] Iteration 7600, Testing net (#0)
I0526 01:21:30.533639 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7774
I0526 01:21:30.533721 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.714858 (* 1 = 0.714858 loss)
I0526 01:21:31.141111 15117 solver.cpp:233] Iteration 7600, loss = 0.366858
I0526 01:21:31.141187 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.366858 (* 1 = 0.366858 loss)
I0526 01:21:31.141202 15117 sgd_solver.cpp:294] Iteration 7600, lr = 0.02
I0526 01:21:37.539988 15117 solver.cpp:233] Iteration 7610, loss = 0.27362
I0526 01:21:37.540148 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.27362 (* 1 = 0.27362 loss)
I0526 01:21:37.540159 15117 sgd_solver.cpp:294] Iteration 7610, lr = 0.02
I0526 01:21:43.927155 15117 solver.cpp:233] Iteration 7620, loss = 0.394745
I0526 01:21:43.927218 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.394745 (* 1 = 0.394745 loss)
I0526 01:21:43.927228 15117 sgd_solver.cpp:294] Iteration 7620, lr = 0.02
I0526 01:21:50.308272 15117 solver.cpp:233] Iteration 7630, loss = 0.30447
I0526 01:21:50.308341 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.30447 (* 1 = 0.30447 loss)
I0526 01:21:50.308352 15117 sgd_solver.cpp:294] Iteration 7630, lr = 0.02
I0526 01:21:56.741086 15117 solver.cpp:233] Iteration 7640, loss = 0.285842
I0526 01:21:56.741158 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.285842 (* 1 = 0.285842 loss)
I0526 01:21:56.741169 15117 sgd_solver.cpp:294] Iteration 7640, lr = 0.02
I0526 01:22:03.135995 15117 solver.cpp:233] Iteration 7650, loss = 0.255622
I0526 01:22:03.136062 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.255622 (* 1 = 0.255622 loss)
I0526 01:22:03.136073 15117 sgd_solver.cpp:294] Iteration 7650, lr = 0.02
I0526 01:22:09.521739 15117 solver.cpp:233] Iteration 7660, loss = 0.264729
I0526 01:22:09.521896 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.264729 (* 1 = 0.264729 loss)
I0526 01:22:09.521908 15117 sgd_solver.cpp:294] Iteration 7660, lr = 0.02
I0526 01:22:15.909405 15117 solver.cpp:233] Iteration 7670, loss = 0.301383
I0526 01:22:15.909478 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.301383 (* 1 = 0.301383 loss)
I0526 01:22:15.909489 15117 sgd_solver.cpp:294] Iteration 7670, lr = 0.02
I0526 01:22:22.306542 15117 solver.cpp:233] Iteration 7680, loss = 0.332318
I0526 01:22:22.306613 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.332318 (* 1 = 0.332318 loss)
I0526 01:22:22.306623 15117 sgd_solver.cpp:294] Iteration 7680, lr = 0.02
I0526 01:22:28.701961 15117 solver.cpp:233] Iteration 7690, loss = 0.321854
I0526 01:22:28.702026 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.321854 (* 1 = 0.321854 loss)
I0526 01:22:28.702038 15117 sgd_solver.cpp:294] Iteration 7690, lr = 0.02
I0526 01:22:34.507596 15117 solver.cpp:342] Iteration 7700, Testing net (#0)
I0526 01:22:47.851387 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7833
I0526 01:22:47.851635 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.658985 (* 1 = 0.658985 loss)
I0526 01:22:48.465405 15117 solver.cpp:233] Iteration 7700, loss = 0.262833
I0526 01:22:48.465487 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.262833 (* 1 = 0.262833 loss)
I0526 01:22:48.465499 15117 sgd_solver.cpp:294] Iteration 7700, lr = 0.02
I0526 01:22:54.932957 15117 solver.cpp:233] Iteration 7710, loss = 0.385794
I0526 01:22:54.933023 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.385794 (* 1 = 0.385794 loss)
I0526 01:22:54.933035 15117 sgd_solver.cpp:294] Iteration 7710, lr = 0.02
I0526 01:23:01.375600 15117 solver.cpp:233] Iteration 7720, loss = 0.363975
I0526 01:23:01.375668 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.363975 (* 1 = 0.363975 loss)
I0526 01:23:01.375679 15117 sgd_solver.cpp:294] Iteration 7720, lr = 0.02
I0526 01:23:07.761312 15117 solver.cpp:233] Iteration 7730, loss = 0.196842
I0526 01:23:07.761384 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.196842 (* 1 = 0.196842 loss)
I0526 01:23:07.761394 15117 sgd_solver.cpp:294] Iteration 7730, lr = 0.02
I0526 01:23:14.152127 15117 solver.cpp:233] Iteration 7740, loss = 0.265489
I0526 01:23:14.152189 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.265489 (* 1 = 0.265489 loss)
I0526 01:23:14.152199 15117 sgd_solver.cpp:294] Iteration 7740, lr = 0.02
I0526 01:23:20.538971 15117 solver.cpp:233] Iteration 7750, loss = 0.328383
I0526 01:23:20.539137 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.328383 (* 1 = 0.328383 loss)
I0526 01:23:20.539149 15117 sgd_solver.cpp:294] Iteration 7750, lr = 0.02
I0526 01:23:26.927707 15117 solver.cpp:233] Iteration 7760, loss = 0.422058
I0526 01:23:26.927763 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.422058 (* 1 = 0.422058 loss)
I0526 01:23:26.927774 15117 sgd_solver.cpp:294] Iteration 7760, lr = 0.02
I0526 01:23:33.315325 15117 solver.cpp:233] Iteration 7770, loss = 0.224891
I0526 01:23:33.315387 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.224891 (* 1 = 0.224891 loss)
I0526 01:23:33.315397 15117 sgd_solver.cpp:294] Iteration 7770, lr = 0.02
I0526 01:23:39.709947 15117 solver.cpp:233] Iteration 7780, loss = 0.302887
I0526 01:23:39.710013 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.302887 (* 1 = 0.302887 loss)
I0526 01:23:39.710023 15117 sgd_solver.cpp:294] Iteration 7780, lr = 0.02
I0526 01:23:46.211228 15117 solver.cpp:233] Iteration 7790, loss = 0.203672
I0526 01:23:46.211297 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.203672 (* 1 = 0.203672 loss)
I0526 01:23:46.211308 15117 sgd_solver.cpp:294] Iteration 7790, lr = 0.02
I0526 01:23:51.994114 15117 solver.cpp:342] Iteration 7800, Testing net (#0)
I0526 01:24:05.044620 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7491
I0526 01:24:05.044687 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.787328 (* 1 = 0.787328 loss)
I0526 01:24:05.658474 15117 solver.cpp:233] Iteration 7800, loss = 0.186915
I0526 01:24:05.658540 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.186915 (* 1 = 0.186915 loss)
I0526 01:24:05.658551 15117 sgd_solver.cpp:294] Iteration 7800, lr = 0.02
I0526 01:24:12.099834 15117 solver.cpp:233] Iteration 7810, loss = 0.358997
I0526 01:24:12.099905 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.358997 (* 1 = 0.358997 loss)
I0526 01:24:12.099915 15117 sgd_solver.cpp:294] Iteration 7810, lr = 0.02
I0526 01:24:18.482311 15117 solver.cpp:233] Iteration 7820, loss = 0.202302
I0526 01:24:18.482396 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.202302 (* 1 = 0.202302 loss)
I0526 01:24:18.482409 15117 sgd_solver.cpp:294] Iteration 7820, lr = 0.02
I0526 01:24:24.859725 15117 solver.cpp:233] Iteration 7830, loss = 0.251532
I0526 01:24:24.859941 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.251532 (* 1 = 0.251532 loss)
I0526 01:24:24.859953 15117 sgd_solver.cpp:294] Iteration 7830, lr = 0.02
I0526 01:24:31.237128 15117 solver.cpp:233] Iteration 7840, loss = 0.318441
I0526 01:24:31.237198 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.318441 (* 1 = 0.318441 loss)
I0526 01:24:31.237210 15117 sgd_solver.cpp:294] Iteration 7840, lr = 0.02
I0526 01:24:37.614874 15117 solver.cpp:233] Iteration 7850, loss = 0.234767
I0526 01:24:37.614944 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.234767 (* 1 = 0.234767 loss)
I0526 01:24:37.614958 15117 sgd_solver.cpp:294] Iteration 7850, lr = 0.02
I0526 01:24:43.993592 15117 solver.cpp:233] Iteration 7860, loss = 0.289697
I0526 01:24:43.993664 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.289697 (* 1 = 0.289697 loss)
I0526 01:24:43.993674 15117 sgd_solver.cpp:294] Iteration 7860, lr = 0.02
I0526 01:24:50.377598 15117 solver.cpp:233] Iteration 7870, loss = 0.278085
I0526 01:24:50.377666 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.278085 (* 1 = 0.278085 loss)
I0526 01:24:50.377677 15117 sgd_solver.cpp:294] Iteration 7870, lr = 0.02
I0526 01:24:56.762419 15117 solver.cpp:233] Iteration 7880, loss = 0.328596
I0526 01:24:56.762562 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.328596 (* 1 = 0.328596 loss)
I0526 01:24:56.762573 15117 sgd_solver.cpp:294] Iteration 7880, lr = 0.02
I0526 01:25:03.142396 15117 solver.cpp:233] Iteration 7890, loss = 0.234397
I0526 01:25:03.142467 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.234397 (* 1 = 0.234397 loss)
I0526 01:25:03.142477 15117 sgd_solver.cpp:294] Iteration 7890, lr = 0.02
I0526 01:25:08.919387 15117 solver.cpp:342] Iteration 7900, Testing net (#0)
I0526 01:25:21.992923 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.638
I0526 01:25:21.993000 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.36779 (* 1 = 1.36779 loss)
I0526 01:25:22.598250 15117 solver.cpp:233] Iteration 7900, loss = 0.341934
I0526 01:25:22.598317 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.341934 (* 1 = 0.341934 loss)
I0526 01:25:22.598330 15117 sgd_solver.cpp:294] Iteration 7900, lr = 0.02
I0526 01:25:28.987136 15117 solver.cpp:233] Iteration 7910, loss = 0.308908
I0526 01:25:28.987285 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.308908 (* 1 = 0.308908 loss)
I0526 01:25:28.987298 15117 sgd_solver.cpp:294] Iteration 7910, lr = 0.02
I0526 01:25:35.375962 15117 solver.cpp:233] Iteration 7920, loss = 0.347019
I0526 01:25:35.376034 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.347019 (* 1 = 0.347019 loss)
I0526 01:25:35.376044 15117 sgd_solver.cpp:294] Iteration 7920, lr = 0.02
I0526 01:25:41.750824 15117 solver.cpp:233] Iteration 7930, loss = 0.273584
I0526 01:25:41.750891 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.273584 (* 1 = 0.273584 loss)
I0526 01:25:41.750902 15117 sgd_solver.cpp:294] Iteration 7930, lr = 0.02
I0526 01:25:48.132007 15117 solver.cpp:233] Iteration 7940, loss = 0.403821
I0526 01:25:48.132069 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.403821 (* 1 = 0.403821 loss)
I0526 01:25:48.132081 15117 sgd_solver.cpp:294] Iteration 7940, lr = 0.02
I0526 01:25:54.511478 15117 solver.cpp:233] Iteration 7950, loss = 0.268982
I0526 01:25:54.511548 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.268982 (* 1 = 0.268982 loss)
I0526 01:25:54.511559 15117 sgd_solver.cpp:294] Iteration 7950, lr = 0.02
I0526 01:26:00.947346 15117 solver.cpp:233] Iteration 7960, loss = 0.259782
I0526 01:26:00.947492 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.259782 (* 1 = 0.259782 loss)
I0526 01:26:00.947504 15117 sgd_solver.cpp:294] Iteration 7960, lr = 0.02
I0526 01:26:07.395190 15117 solver.cpp:233] Iteration 7970, loss = 0.271386
I0526 01:26:07.395259 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.271386 (* 1 = 0.271386 loss)
I0526 01:26:07.395270 15117 sgd_solver.cpp:294] Iteration 7970, lr = 0.02
I0526 01:26:13.810794 15117 solver.cpp:233] Iteration 7980, loss = 0.449044
I0526 01:26:13.810864 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.449044 (* 1 = 0.449044 loss)
I0526 01:26:13.810874 15117 sgd_solver.cpp:294] Iteration 7980, lr = 0.02
I0526 01:26:20.186446 15117 solver.cpp:233] Iteration 7990, loss = 0.33159
I0526 01:26:20.186517 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.33159 (* 1 = 0.33159 loss)
I0526 01:26:20.186528 15117 sgd_solver.cpp:294] Iteration 7990, lr = 0.02
I0526 01:26:25.955809 15117 solver.cpp:342] Iteration 8000, Testing net (#0)
I0526 01:26:39.070716 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7676
I0526 01:26:39.070929 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.666735 (* 1 = 0.666735 loss)
I0526 01:26:39.675559 15117 solver.cpp:233] Iteration 8000, loss = 0.255282
I0526 01:26:39.675624 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.255282 (* 1 = 0.255282 loss)
I0526 01:26:39.675637 15117 sgd_solver.cpp:294] Iteration 8000, lr = 0.02
I0526 01:26:46.057023 15117 solver.cpp:233] Iteration 8010, loss = 0.223546
I0526 01:26:46.057090 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.223546 (* 1 = 0.223546 loss)
I0526 01:26:46.057101 15117 sgd_solver.cpp:294] Iteration 8010, lr = 0.02
I0526 01:26:52.439137 15117 solver.cpp:233] Iteration 8020, loss = 0.383028
I0526 01:26:52.439205 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.383028 (* 1 = 0.383028 loss)
I0526 01:26:52.439216 15117 sgd_solver.cpp:294] Iteration 8020, lr = 0.02
I0526 01:26:58.845015 15117 solver.cpp:233] Iteration 8030, loss = 0.36639
I0526 01:26:58.845093 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.36639 (* 1 = 0.36639 loss)
I0526 01:26:58.845103 15117 sgd_solver.cpp:294] Iteration 8030, lr = 0.02
I0526 01:27:05.302999 15117 solver.cpp:233] Iteration 8040, loss = 0.273002
I0526 01:27:05.303071 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.273002 (* 1 = 0.273002 loss)
I0526 01:27:05.303081 15117 sgd_solver.cpp:294] Iteration 8040, lr = 0.02
I0526 01:27:11.741897 15117 solver.cpp:233] Iteration 8050, loss = 0.289715
I0526 01:27:11.742055 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.289715 (* 1 = 0.289715 loss)
I0526 01:27:11.742068 15117 sgd_solver.cpp:294] Iteration 8050, lr = 0.02
I0526 01:27:18.131820 15117 solver.cpp:233] Iteration 8060, loss = 0.251632
I0526 01:27:18.131888 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.251632 (* 1 = 0.251632 loss)
I0526 01:27:18.131899 15117 sgd_solver.cpp:294] Iteration 8060, lr = 0.02
I0526 01:27:24.521870 15117 solver.cpp:233] Iteration 8070, loss = 0.383668
I0526 01:27:24.521937 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.383668 (* 1 = 0.383668 loss)
I0526 01:27:24.521949 15117 sgd_solver.cpp:294] Iteration 8070, lr = 0.02
I0526 01:27:30.896083 15117 solver.cpp:233] Iteration 8080, loss = 0.229879
I0526 01:27:30.896143 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.229879 (* 1 = 0.229879 loss)
I0526 01:27:30.896154 15117 sgd_solver.cpp:294] Iteration 8080, lr = 0.02
I0526 01:27:37.276125 15117 solver.cpp:233] Iteration 8090, loss = 0.268687
I0526 01:27:37.276192 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.268687 (* 1 = 0.268687 loss)
I0526 01:27:37.276203 15117 sgd_solver.cpp:294] Iteration 8090, lr = 0.02
I0526 01:27:43.050060 15117 solver.cpp:342] Iteration 8100, Testing net (#0)
I0526 01:27:56.131783 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8188
I0526 01:27:56.131852 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.552239 (* 1 = 0.552239 loss)
I0526 01:27:56.737231 15117 solver.cpp:233] Iteration 8100, loss = 0.364826
I0526 01:27:56.737296 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.364826 (* 1 = 0.364826 loss)
I0526 01:27:56.737318 15117 sgd_solver.cpp:294] Iteration 8100, lr = 0.02
I0526 01:28:03.104686 15117 solver.cpp:233] Iteration 8110, loss = 0.277792
I0526 01:28:03.104754 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.277792 (* 1 = 0.277792 loss)
I0526 01:28:03.104766 15117 sgd_solver.cpp:294] Iteration 8110, lr = 0.02
I0526 01:28:09.477866 15117 solver.cpp:233] Iteration 8120, loss = 0.344553
I0526 01:28:09.477934 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.344553 (* 1 = 0.344553 loss)
I0526 01:28:09.477946 15117 sgd_solver.cpp:294] Iteration 8120, lr = 0.02
I0526 01:28:15.858376 15117 solver.cpp:233] Iteration 8130, loss = 0.171358
I0526 01:28:15.858578 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.171358 (* 1 = 0.171358 loss)
I0526 01:28:15.858590 15117 sgd_solver.cpp:294] Iteration 8130, lr = 0.02
I0526 01:28:22.240277 15117 solver.cpp:233] Iteration 8140, loss = 0.27964
I0526 01:28:22.240345 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.27964 (* 1 = 0.27964 loss)
I0526 01:28:22.240356 15117 sgd_solver.cpp:294] Iteration 8140, lr = 0.02
I0526 01:28:28.621132 15117 solver.cpp:233] Iteration 8150, loss = 0.338807
I0526 01:28:28.621193 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.338807 (* 1 = 0.338807 loss)
I0526 01:28:28.621204 15117 sgd_solver.cpp:294] Iteration 8150, lr = 0.02
I0526 01:28:34.998507 15117 solver.cpp:233] Iteration 8160, loss = 0.318037
I0526 01:28:34.998575 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.318037 (* 1 = 0.318037 loss)
I0526 01:28:34.998586 15117 sgd_solver.cpp:294] Iteration 8160, lr = 0.02
I0526 01:28:41.427098 15117 solver.cpp:233] Iteration 8170, loss = 0.229476
I0526 01:28:41.427161 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.229476 (* 1 = 0.229476 loss)
I0526 01:28:41.427172 15117 sgd_solver.cpp:294] Iteration 8170, lr = 0.02
I0526 01:28:47.868356 15117 solver.cpp:233] Iteration 8180, loss = 0.247709
I0526 01:28:47.868525 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.247709 (* 1 = 0.247709 loss)
I0526 01:28:47.868535 15117 sgd_solver.cpp:294] Iteration 8180, lr = 0.02
I0526 01:28:54.280462 15117 solver.cpp:233] Iteration 8190, loss = 0.30331
I0526 01:28:54.280529 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.30331 (* 1 = 0.30331 loss)
I0526 01:28:54.280540 15117 sgd_solver.cpp:294] Iteration 8190, lr = 0.02
I0526 01:29:00.046339 15117 solver.cpp:342] Iteration 8200, Testing net (#0)
I0526 01:29:13.192646 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7779
I0526 01:29:13.192718 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.694699 (* 1 = 0.694699 loss)
I0526 01:29:13.797468 15117 solver.cpp:233] Iteration 8200, loss = 0.291615
I0526 01:29:13.797535 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.291615 (* 1 = 0.291615 loss)
I0526 01:29:13.797547 15117 sgd_solver.cpp:294] Iteration 8200, lr = 0.02
I0526 01:29:20.174841 15117 solver.cpp:233] Iteration 8210, loss = 0.199415
I0526 01:29:20.174990 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.199415 (* 1 = 0.199415 loss)
I0526 01:29:20.175001 15117 sgd_solver.cpp:294] Iteration 8210, lr = 0.02
I0526 01:29:26.623363 15117 solver.cpp:233] Iteration 8220, loss = 0.356996
I0526 01:29:26.623427 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.356996 (* 1 = 0.356996 loss)
I0526 01:29:26.623437 15117 sgd_solver.cpp:294] Iteration 8220, lr = 0.02
I0526 01:29:33.063735 15117 solver.cpp:233] Iteration 8230, loss = 0.338362
I0526 01:29:33.063797 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.338362 (* 1 = 0.338362 loss)
I0526 01:29:33.063809 15117 sgd_solver.cpp:294] Iteration 8230, lr = 0.02
I0526 01:29:39.448671 15117 solver.cpp:233] Iteration 8240, loss = 0.188751
I0526 01:29:39.448755 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.188751 (* 1 = 0.188751 loss)
I0526 01:29:39.448781 15117 sgd_solver.cpp:294] Iteration 8240, lr = 0.02
I0526 01:29:45.871490 15117 solver.cpp:233] Iteration 8250, loss = 0.364036
I0526 01:29:45.871573 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.364036 (* 1 = 0.364036 loss)
I0526 01:29:45.871587 15117 sgd_solver.cpp:294] Iteration 8250, lr = 0.02
I0526 01:29:52.250913 15117 solver.cpp:233] Iteration 8260, loss = 0.257552
I0526 01:29:52.251155 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.257552 (* 1 = 0.257552 loss)
I0526 01:29:52.251170 15117 sgd_solver.cpp:294] Iteration 8260, lr = 0.02
I0526 01:29:58.635854 15117 solver.cpp:233] Iteration 8270, loss = 0.269657
I0526 01:29:58.635927 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.269657 (* 1 = 0.269657 loss)
I0526 01:29:58.635938 15117 sgd_solver.cpp:294] Iteration 8270, lr = 0.02
I0526 01:30:05.015321 15117 solver.cpp:233] Iteration 8280, loss = 0.313155
I0526 01:30:05.015393 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.313155 (* 1 = 0.313155 loss)
I0526 01:30:05.015404 15117 sgd_solver.cpp:294] Iteration 8280, lr = 0.02
I0526 01:30:11.394184 15117 solver.cpp:233] Iteration 8290, loss = 0.377394
I0526 01:30:11.394253 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.377394 (* 1 = 0.377394 loss)
I0526 01:30:11.394264 15117 sgd_solver.cpp:294] Iteration 8290, lr = 0.02
I0526 01:30:17.167071 15117 solver.cpp:342] Iteration 8300, Testing net (#0)
I0526 01:30:30.220401 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.637
I0526 01:30:30.220582 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.2916 (* 1 = 1.2916 loss)
I0526 01:30:30.824283 15117 solver.cpp:233] Iteration 8300, loss = 0.245481
I0526 01:30:30.824353 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.245481 (* 1 = 0.245481 loss)
I0526 01:30:30.824367 15117 sgd_solver.cpp:294] Iteration 8300, lr = 0.02
I0526 01:30:37.202404 15117 solver.cpp:233] Iteration 8310, loss = 0.348875
I0526 01:30:37.202477 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.348875 (* 1 = 0.348875 loss)
I0526 01:30:37.202488 15117 sgd_solver.cpp:294] Iteration 8310, lr = 0.02
I0526 01:30:43.577977 15117 solver.cpp:233] Iteration 8320, loss = 0.333043
I0526 01:30:43.578042 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.333043 (* 1 = 0.333043 loss)
I0526 01:30:43.578054 15117 sgd_solver.cpp:294] Iteration 8320, lr = 0.02
I0526 01:30:49.951234 15117 solver.cpp:233] Iteration 8330, loss = 0.281195
I0526 01:30:49.951305 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.281195 (* 1 = 0.281195 loss)
I0526 01:30:49.951318 15117 sgd_solver.cpp:294] Iteration 8330, lr = 0.02
I0526 01:30:56.324502 15117 solver.cpp:233] Iteration 8340, loss = 0.215835
I0526 01:30:56.324574 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.215835 (* 1 = 0.215835 loss)
I0526 01:30:56.324586 15117 sgd_solver.cpp:294] Iteration 8340, lr = 0.02
I0526 01:31:02.697615 15117 solver.cpp:233] Iteration 8350, loss = 0.208351
I0526 01:31:02.697780 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.208351 (* 1 = 0.208351 loss)
I0526 01:31:02.697791 15117 sgd_solver.cpp:294] Iteration 8350, lr = 0.02
I0526 01:31:09.071338 15117 solver.cpp:233] Iteration 8360, loss = 0.287015
I0526 01:31:09.071409 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.287015 (* 1 = 0.287015 loss)
I0526 01:31:09.071421 15117 sgd_solver.cpp:294] Iteration 8360, lr = 0.02
I0526 01:31:15.446825 15117 solver.cpp:233] Iteration 8370, loss = 0.344881
I0526 01:31:15.446904 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.344881 (* 1 = 0.344881 loss)
I0526 01:31:15.446916 15117 sgd_solver.cpp:294] Iteration 8370, lr = 0.02
I0526 01:31:21.817569 15117 solver.cpp:233] Iteration 8380, loss = 0.271511
I0526 01:31:21.817641 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.271511 (* 1 = 0.271511 loss)
I0526 01:31:21.817653 15117 sgd_solver.cpp:294] Iteration 8380, lr = 0.02
I0526 01:31:28.186394 15117 solver.cpp:233] Iteration 8390, loss = 0.232729
I0526 01:31:28.186465 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.232729 (* 1 = 0.232729 loss)
I0526 01:31:28.186476 15117 sgd_solver.cpp:294] Iteration 8390, lr = 0.02
I0526 01:31:33.967262 15117 solver.cpp:342] Iteration 8400, Testing net (#0)
I0526 01:31:46.989367 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7858
I0526 01:31:46.989442 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.648607 (* 1 = 0.648607 loss)
I0526 01:31:47.594442 15117 solver.cpp:233] Iteration 8400, loss = 0.441262
I0526 01:31:47.594513 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.441262 (* 1 = 0.441262 loss)
I0526 01:31:47.594527 15117 sgd_solver.cpp:294] Iteration 8400, lr = 0.02
I0526 01:31:53.971117 15117 solver.cpp:233] Iteration 8410, loss = 0.274608
I0526 01:31:53.971184 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.274608 (* 1 = 0.274608 loss)
I0526 01:31:53.971196 15117 sgd_solver.cpp:294] Iteration 8410, lr = 0.02
I0526 01:32:00.350543 15117 solver.cpp:233] Iteration 8420, loss = 0.232541
I0526 01:32:00.350612 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.232541 (* 1 = 0.232541 loss)
I0526 01:32:00.350625 15117 sgd_solver.cpp:294] Iteration 8420, lr = 0.02
I0526 01:32:06.725123 15117 solver.cpp:233] Iteration 8430, loss = 0.265493
I0526 01:32:06.725280 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.265493 (* 1 = 0.265493 loss)
I0526 01:32:06.725291 15117 sgd_solver.cpp:294] Iteration 8430, lr = 0.02
I0526 01:32:13.096788 15117 solver.cpp:233] Iteration 8440, loss = 0.234937
I0526 01:32:13.096855 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.234937 (* 1 = 0.234937 loss)
I0526 01:32:13.096868 15117 sgd_solver.cpp:294] Iteration 8440, lr = 0.02
I0526 01:32:19.469900 15117 solver.cpp:233] Iteration 8450, loss = 0.357966
I0526 01:32:19.469969 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.357966 (* 1 = 0.357966 loss)
I0526 01:32:19.469980 15117 sgd_solver.cpp:294] Iteration 8450, lr = 0.02
I0526 01:32:25.844988 15117 solver.cpp:233] Iteration 8460, loss = 0.398844
I0526 01:32:25.845060 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.398844 (* 1 = 0.398844 loss)
I0526 01:32:25.845072 15117 sgd_solver.cpp:294] Iteration 8460, lr = 0.02
I0526 01:32:32.226250 15117 solver.cpp:233] Iteration 8470, loss = 0.350315
I0526 01:32:32.226325 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.350315 (* 1 = 0.350315 loss)
I0526 01:32:32.226336 15117 sgd_solver.cpp:294] Iteration 8470, lr = 0.02
I0526 01:32:38.675153 15117 solver.cpp:233] Iteration 8480, loss = 0.248129
I0526 01:32:38.675305 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.248129 (* 1 = 0.248129 loss)
I0526 01:32:38.675318 15117 sgd_solver.cpp:294] Iteration 8480, lr = 0.02
I0526 01:32:45.101954 15117 solver.cpp:233] Iteration 8490, loss = 0.377245
I0526 01:32:45.102030 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.377245 (* 1 = 0.377245 loss)
I0526 01:32:45.102043 15117 sgd_solver.cpp:294] Iteration 8490, lr = 0.02
I0526 01:32:50.889853 15117 solver.cpp:342] Iteration 8500, Testing net (#0)
I0526 01:33:03.925429 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7566
I0526 01:33:03.925504 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.738972 (* 1 = 0.738972 loss)
I0526 01:33:04.530593 15117 solver.cpp:233] Iteration 8500, loss = 0.256949
I0526 01:33:04.530663 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.256949 (* 1 = 0.256949 loss)
I0526 01:33:04.530678 15117 sgd_solver.cpp:294] Iteration 8500, lr = 0.02
I0526 01:33:10.904235 15117 solver.cpp:233] Iteration 8510, loss = 0.33187
I0526 01:33:10.904388 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.33187 (* 1 = 0.33187 loss)
I0526 01:33:10.904402 15117 sgd_solver.cpp:294] Iteration 8510, lr = 0.02
I0526 01:33:17.282371 15117 solver.cpp:233] Iteration 8520, loss = 0.393642
I0526 01:33:17.282445 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.393642 (* 1 = 0.393642 loss)
I0526 01:33:17.282459 15117 sgd_solver.cpp:294] Iteration 8520, lr = 0.02
I0526 01:33:23.660544 15117 solver.cpp:233] Iteration 8530, loss = 0.225508
I0526 01:33:23.660622 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.225508 (* 1 = 0.225508 loss)
I0526 01:33:23.660634 15117 sgd_solver.cpp:294] Iteration 8530, lr = 0.02
I0526 01:33:30.041201 15117 solver.cpp:233] Iteration 8540, loss = 0.315503
I0526 01:33:30.041278 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.315503 (* 1 = 0.315503 loss)
I0526 01:33:30.041290 15117 sgd_solver.cpp:294] Iteration 8540, lr = 0.02
I0526 01:33:36.416805 15117 solver.cpp:233] Iteration 8550, loss = 0.318836
I0526 01:33:36.416878 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.318836 (* 1 = 0.318836 loss)
I0526 01:33:36.416890 15117 sgd_solver.cpp:294] Iteration 8550, lr = 0.02
I0526 01:33:42.792948 15117 solver.cpp:233] Iteration 8560, loss = 0.263736
I0526 01:33:42.793176 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.263736 (* 1 = 0.263736 loss)
I0526 01:33:42.793190 15117 sgd_solver.cpp:294] Iteration 8560, lr = 0.02
I0526 01:33:49.171051 15117 solver.cpp:233] Iteration 8570, loss = 0.279961
I0526 01:33:49.171125 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.279961 (* 1 = 0.279961 loss)
I0526 01:33:49.171138 15117 sgd_solver.cpp:294] Iteration 8570, lr = 0.02
I0526 01:33:55.548749 15117 solver.cpp:233] Iteration 8580, loss = 0.256889
I0526 01:33:55.548821 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.256889 (* 1 = 0.256889 loss)
I0526 01:33:55.548835 15117 sgd_solver.cpp:294] Iteration 8580, lr = 0.02
I0526 01:34:01.935894 15117 solver.cpp:233] Iteration 8590, loss = 0.172215
I0526 01:34:01.935973 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.172215 (* 1 = 0.172215 loss)
I0526 01:34:01.935986 15117 sgd_solver.cpp:294] Iteration 8590, lr = 0.02
I0526 01:34:07.713387 15117 solver.cpp:342] Iteration 8600, Testing net (#0)
I0526 01:34:20.771291 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7484
I0526 01:34:20.771459 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.878315 (* 1 = 0.878315 loss)
I0526 01:34:21.378212 15117 solver.cpp:233] Iteration 8600, loss = 0.341045
I0526 01:34:21.378284 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.341045 (* 1 = 0.341045 loss)
I0526 01:34:21.378299 15117 sgd_solver.cpp:294] Iteration 8600, lr = 0.02
I0526 01:34:27.754216 15117 solver.cpp:233] Iteration 8610, loss = 0.343362
I0526 01:34:27.754290 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.343362 (* 1 = 0.343362 loss)
I0526 01:34:27.754302 15117 sgd_solver.cpp:294] Iteration 8610, lr = 0.02
I0526 01:34:34.179936 15117 solver.cpp:233] Iteration 8620, loss = 0.371058
I0526 01:34:34.180008 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.371058 (* 1 = 0.371058 loss)
I0526 01:34:34.180019 15117 sgd_solver.cpp:294] Iteration 8620, lr = 0.02
I0526 01:34:40.564625 15117 solver.cpp:233] Iteration 8630, loss = 0.200666
I0526 01:34:40.564693 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.200666 (* 1 = 0.200666 loss)
I0526 01:34:40.564704 15117 sgd_solver.cpp:294] Iteration 8630, lr = 0.02
I0526 01:34:46.944880 15117 solver.cpp:233] Iteration 8640, loss = 0.273202
I0526 01:34:46.944941 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.273202 (* 1 = 0.273202 loss)
I0526 01:34:46.944953 15117 sgd_solver.cpp:294] Iteration 8640, lr = 0.02
I0526 01:34:53.326740 15117 solver.cpp:233] Iteration 8650, loss = 0.182095
I0526 01:34:53.326889 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.182095 (* 1 = 0.182095 loss)
I0526 01:34:53.326901 15117 sgd_solver.cpp:294] Iteration 8650, lr = 0.02
I0526 01:34:59.703404 15117 solver.cpp:233] Iteration 8660, loss = 0.226524
I0526 01:34:59.703491 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.226524 (* 1 = 0.226524 loss)
I0526 01:34:59.703506 15117 sgd_solver.cpp:294] Iteration 8660, lr = 0.02
I0526 01:35:06.073238 15117 solver.cpp:233] Iteration 8670, loss = 0.266379
I0526 01:35:06.073305 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.266379 (* 1 = 0.266379 loss)
I0526 01:35:06.073317 15117 sgd_solver.cpp:294] Iteration 8670, lr = 0.02
I0526 01:35:12.463686 15117 solver.cpp:233] Iteration 8680, loss = 0.263098
I0526 01:35:12.463762 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.263098 (* 1 = 0.263098 loss)
I0526 01:35:12.463774 15117 sgd_solver.cpp:294] Iteration 8680, lr = 0.02
I0526 01:35:18.858361 15117 solver.cpp:233] Iteration 8690, loss = 0.274551
I0526 01:35:18.858431 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.274551 (* 1 = 0.274551 loss)
I0526 01:35:18.858443 15117 sgd_solver.cpp:294] Iteration 8690, lr = 0.02
I0526 01:35:24.643771 15117 solver.cpp:342] Iteration 8700, Testing net (#0)
I0526 01:35:37.657640 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7545
I0526 01:35:37.657718 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.793951 (* 1 = 0.793951 loss)
I0526 01:35:38.261914 15117 solver.cpp:233] Iteration 8700, loss = 0.282811
I0526 01:35:38.261986 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.282811 (* 1 = 0.282811 loss)
I0526 01:35:38.261998 15117 sgd_solver.cpp:294] Iteration 8700, lr = 0.02
I0526 01:35:44.636656 15117 solver.cpp:233] Iteration 8710, loss = 0.265171
I0526 01:35:44.636734 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.265171 (* 1 = 0.265171 loss)
I0526 01:35:44.636746 15117 sgd_solver.cpp:294] Iteration 8710, lr = 0.02
I0526 01:35:51.012920 15117 solver.cpp:233] Iteration 8720, loss = 0.213695
I0526 01:35:51.012989 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.213695 (* 1 = 0.213695 loss)
I0526 01:35:51.013000 15117 sgd_solver.cpp:294] Iteration 8720, lr = 0.02
I0526 01:35:57.380606 15117 solver.cpp:233] Iteration 8730, loss = 0.258673
I0526 01:35:57.380767 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.258673 (* 1 = 0.258673 loss)
I0526 01:35:57.380779 15117 sgd_solver.cpp:294] Iteration 8730, lr = 0.02
I0526 01:36:03.757930 15117 solver.cpp:233] Iteration 8740, loss = 0.225988
I0526 01:36:03.757993 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.225988 (* 1 = 0.225988 loss)
I0526 01:36:03.758004 15117 sgd_solver.cpp:294] Iteration 8740, lr = 0.02
I0526 01:36:10.137426 15117 solver.cpp:233] Iteration 8750, loss = 0.232121
I0526 01:36:10.137501 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.232121 (* 1 = 0.232121 loss)
I0526 01:36:10.137512 15117 sgd_solver.cpp:294] Iteration 8750, lr = 0.02
I0526 01:36:16.512014 15117 solver.cpp:233] Iteration 8760, loss = 0.332493
I0526 01:36:16.512087 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.332493 (* 1 = 0.332493 loss)
I0526 01:36:16.512097 15117 sgd_solver.cpp:294] Iteration 8760, lr = 0.02
I0526 01:36:22.884220 15117 solver.cpp:233] Iteration 8770, loss = 0.275003
I0526 01:36:22.884285 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.275003 (* 1 = 0.275003 loss)
I0526 01:36:22.884295 15117 sgd_solver.cpp:294] Iteration 8770, lr = 0.02
I0526 01:36:29.257114 15117 solver.cpp:233] Iteration 8780, loss = 0.318797
I0526 01:36:29.257267 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.318797 (* 1 = 0.318797 loss)
I0526 01:36:29.257282 15117 sgd_solver.cpp:294] Iteration 8780, lr = 0.02
I0526 01:36:35.629750 15117 solver.cpp:233] Iteration 8790, loss = 0.345272
I0526 01:36:35.629817 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.345272 (* 1 = 0.345272 loss)
I0526 01:36:35.629828 15117 sgd_solver.cpp:294] Iteration 8790, lr = 0.02
I0526 01:36:41.401665 15117 solver.cpp:342] Iteration 8800, Testing net (#0)
I0526 01:36:54.439843 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7909
I0526 01:36:54.439929 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.67558 (* 1 = 0.67558 loss)
I0526 01:36:55.044606 15117 solver.cpp:233] Iteration 8800, loss = 0.268488
I0526 01:36:55.044679 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.268488 (* 1 = 0.268488 loss)
I0526 01:36:55.044692 15117 sgd_solver.cpp:294] Iteration 8800, lr = 0.02
I0526 01:37:01.420910 15117 solver.cpp:233] Iteration 8810, loss = 0.193609
I0526 01:37:01.421140 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.193609 (* 1 = 0.193609 loss)
I0526 01:37:01.421154 15117 sgd_solver.cpp:294] Iteration 8810, lr = 0.02
I0526 01:37:07.798434 15117 solver.cpp:233] Iteration 8820, loss = 0.229852
I0526 01:37:07.798506 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.229852 (* 1 = 0.229852 loss)
I0526 01:37:07.798516 15117 sgd_solver.cpp:294] Iteration 8820, lr = 0.02
I0526 01:37:14.174077 15117 solver.cpp:233] Iteration 8830, loss = 0.273037
I0526 01:37:14.174161 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.273037 (* 1 = 0.273037 loss)
I0526 01:37:14.174175 15117 sgd_solver.cpp:294] Iteration 8830, lr = 0.02
I0526 01:37:20.557970 15117 solver.cpp:233] Iteration 8840, loss = 0.238353
I0526 01:37:20.558048 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.238353 (* 1 = 0.238353 loss)
I0526 01:37:20.558059 15117 sgd_solver.cpp:294] Iteration 8840, lr = 0.02
I0526 01:37:26.938132 15117 solver.cpp:233] Iteration 8850, loss = 0.330341
I0526 01:37:26.938204 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.330341 (* 1 = 0.330341 loss)
I0526 01:37:26.938215 15117 sgd_solver.cpp:294] Iteration 8850, lr = 0.02
I0526 01:37:33.318207 15117 solver.cpp:233] Iteration 8860, loss = 0.213438
I0526 01:37:33.318367 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.213438 (* 1 = 0.213438 loss)
I0526 01:37:33.318377 15117 sgd_solver.cpp:294] Iteration 8860, lr = 0.02
I0526 01:37:39.701104 15117 solver.cpp:233] Iteration 8870, loss = 0.304603
I0526 01:37:39.701179 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.304603 (* 1 = 0.304603 loss)
I0526 01:37:39.701189 15117 sgd_solver.cpp:294] Iteration 8870, lr = 0.02
I0526 01:37:46.084547 15117 solver.cpp:233] Iteration 8880, loss = 0.357904
I0526 01:37:46.084615 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.357904 (* 1 = 0.357904 loss)
I0526 01:37:46.084627 15117 sgd_solver.cpp:294] Iteration 8880, lr = 0.02
I0526 01:37:52.469776 15117 solver.cpp:233] Iteration 8890, loss = 0.197179
I0526 01:37:52.469847 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.197179 (* 1 = 0.197179 loss)
I0526 01:37:52.469858 15117 sgd_solver.cpp:294] Iteration 8890, lr = 0.02
I0526 01:37:58.264758 15117 solver.cpp:342] Iteration 8900, Testing net (#0)
I0526 01:38:11.352381 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.768
I0526 01:38:11.352556 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.719085 (* 1 = 0.719085 loss)
I0526 01:38:11.959130 15117 solver.cpp:233] Iteration 8900, loss = 0.256872
I0526 01:38:11.959193 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.256872 (* 1 = 0.256872 loss)
I0526 01:38:11.959206 15117 sgd_solver.cpp:294] Iteration 8900, lr = 0.02
I0526 01:38:18.353092 15117 solver.cpp:233] Iteration 8910, loss = 0.322564
I0526 01:38:18.353166 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.322564 (* 1 = 0.322564 loss)
I0526 01:38:18.353178 15117 sgd_solver.cpp:294] Iteration 8910, lr = 0.02
I0526 01:38:24.745398 15117 solver.cpp:233] Iteration 8920, loss = 0.301347
I0526 01:38:24.745458 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.301347 (* 1 = 0.301347 loss)
I0526 01:38:24.745471 15117 sgd_solver.cpp:294] Iteration 8920, lr = 0.02
I0526 01:38:31.133843 15117 solver.cpp:233] Iteration 8930, loss = 0.326789
I0526 01:38:31.133916 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.326789 (* 1 = 0.326789 loss)
I0526 01:38:31.133939 15117 sgd_solver.cpp:294] Iteration 8930, lr = 0.02
I0526 01:38:37.525051 15117 solver.cpp:233] Iteration 8940, loss = 0.261413
I0526 01:38:37.525120 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.261413 (* 1 = 0.261413 loss)
I0526 01:38:37.525131 15117 sgd_solver.cpp:294] Iteration 8940, lr = 0.02
I0526 01:38:43.918321 15117 solver.cpp:233] Iteration 8950, loss = 0.289808
I0526 01:38:43.918540 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.289808 (* 1 = 0.289808 loss)
I0526 01:38:43.918555 15117 sgd_solver.cpp:294] Iteration 8950, lr = 0.02
I0526 01:38:50.305976 15117 solver.cpp:233] Iteration 8960, loss = 0.188445
I0526 01:38:50.306053 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.188445 (* 1 = 0.188445 loss)
I0526 01:38:50.306066 15117 sgd_solver.cpp:294] Iteration 8960, lr = 0.02
I0526 01:38:56.694084 15117 solver.cpp:233] Iteration 8970, loss = 0.231717
I0526 01:38:56.694154 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.231717 (* 1 = 0.231717 loss)
I0526 01:38:56.694164 15117 sgd_solver.cpp:294] Iteration 8970, lr = 0.02
I0526 01:39:03.083425 15117 solver.cpp:233] Iteration 8980, loss = 0.295954
I0526 01:39:03.083492 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.295954 (* 1 = 0.295954 loss)
I0526 01:39:03.083504 15117 sgd_solver.cpp:294] Iteration 8980, lr = 0.02
I0526 01:39:09.487704 15117 solver.cpp:233] Iteration 8990, loss = 0.221031
I0526 01:39:09.487772 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.221031 (* 1 = 0.221031 loss)
I0526 01:39:09.487783 15117 sgd_solver.cpp:294] Iteration 8990, lr = 0.02
I0526 01:39:15.268442 15117 solver.cpp:342] Iteration 9000, Testing net (#0)
I0526 01:39:28.310235 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8116
I0526 01:39:28.310304 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.599239 (* 1 = 0.599239 loss)
I0526 01:39:28.916087 15117 solver.cpp:233] Iteration 9000, loss = 0.252161
I0526 01:39:28.916157 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.252161 (* 1 = 0.252161 loss)
I0526 01:39:28.916167 15117 sgd_solver.cpp:294] Iteration 9000, lr = 0.02
I0526 01:39:35.304611 15117 solver.cpp:233] Iteration 9010, loss = 0.294093
I0526 01:39:35.304680 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.294093 (* 1 = 0.294093 loss)
I0526 01:39:35.304692 15117 sgd_solver.cpp:294] Iteration 9010, lr = 0.02
I0526 01:39:41.706815 15117 solver.cpp:233] Iteration 9020, loss = 0.282171
I0526 01:39:41.706881 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.282171 (* 1 = 0.282171 loss)
I0526 01:39:41.706890 15117 sgd_solver.cpp:294] Iteration 9020, lr = 0.02
I0526 01:39:48.113852 15117 solver.cpp:233] Iteration 9030, loss = 0.18399
I0526 01:39:48.114006 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.18399 (* 1 = 0.18399 loss)
I0526 01:39:48.114017 15117 sgd_solver.cpp:294] Iteration 9030, lr = 0.02
I0526 01:39:54.520349 15117 solver.cpp:233] Iteration 9040, loss = 0.369233
I0526 01:39:54.520416 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.369233 (* 1 = 0.369233 loss)
I0526 01:39:54.520426 15117 sgd_solver.cpp:294] Iteration 9040, lr = 0.02
I0526 01:40:00.925604 15117 solver.cpp:233] Iteration 9050, loss = 0.335797
I0526 01:40:00.925678 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.335797 (* 1 = 0.335797 loss)
I0526 01:40:00.925689 15117 sgd_solver.cpp:294] Iteration 9050, lr = 0.02
I0526 01:40:07.328773 15117 solver.cpp:233] Iteration 9060, loss = 0.161212
I0526 01:40:07.328840 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.161212 (* 1 = 0.161212 loss)
I0526 01:40:07.328851 15117 sgd_solver.cpp:294] Iteration 9060, lr = 0.02
I0526 01:40:13.727761 15117 solver.cpp:233] Iteration 9070, loss = 0.272734
I0526 01:40:13.727828 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.272734 (* 1 = 0.272734 loss)
I0526 01:40:13.727849 15117 sgd_solver.cpp:294] Iteration 9070, lr = 0.02
I0526 01:40:20.128945 15117 solver.cpp:233] Iteration 9080, loss = 0.196432
I0526 01:40:20.129170 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.196432 (* 1 = 0.196432 loss)
I0526 01:40:20.129184 15117 sgd_solver.cpp:294] Iteration 9080, lr = 0.02
I0526 01:40:26.536780 15117 solver.cpp:233] Iteration 9090, loss = 0.233405
I0526 01:40:26.536850 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.233405 (* 1 = 0.233405 loss)
I0526 01:40:26.536861 15117 sgd_solver.cpp:294] Iteration 9090, lr = 0.02
I0526 01:40:32.343008 15117 solver.cpp:342] Iteration 9100, Testing net (#0)
I0526 01:40:45.444403 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.6222
I0526 01:40:45.444478 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.64426 (* 1 = 1.64426 loss)
I0526 01:40:46.054072 15117 solver.cpp:233] Iteration 9100, loss = 0.214184
I0526 01:40:46.054146 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.214184 (* 1 = 0.214184 loss)
I0526 01:40:46.054158 15117 sgd_solver.cpp:294] Iteration 9100, lr = 0.02
I0526 01:40:52.492280 15117 solver.cpp:233] Iteration 9110, loss = 0.22556
I0526 01:40:52.492475 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.22556 (* 1 = 0.22556 loss)
I0526 01:40:52.492491 15117 sgd_solver.cpp:294] Iteration 9110, lr = 0.02
I0526 01:40:58.918761 15117 solver.cpp:233] Iteration 9120, loss = 0.255951
I0526 01:40:58.918829 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.255951 (* 1 = 0.255951 loss)
I0526 01:40:58.918839 15117 sgd_solver.cpp:294] Iteration 9120, lr = 0.02
I0526 01:41:05.333297 15117 solver.cpp:233] Iteration 9130, loss = 0.266424
I0526 01:41:05.333369 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.266424 (* 1 = 0.266424 loss)
I0526 01:41:05.333380 15117 sgd_solver.cpp:294] Iteration 9130, lr = 0.02
I0526 01:41:11.742334 15117 solver.cpp:233] Iteration 9140, loss = 0.316655
I0526 01:41:11.742406 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.316655 (* 1 = 0.316655 loss)
I0526 01:41:11.742419 15117 sgd_solver.cpp:294] Iteration 9140, lr = 0.02
I0526 01:41:18.156085 15117 solver.cpp:233] Iteration 9150, loss = 0.277393
I0526 01:41:18.156162 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.277393 (* 1 = 0.277393 loss)
I0526 01:41:18.156173 15117 sgd_solver.cpp:294] Iteration 9150, lr = 0.02
I0526 01:41:24.565080 15117 solver.cpp:233] Iteration 9160, loss = 0.243389
I0526 01:41:24.565213 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.243389 (* 1 = 0.243389 loss)
I0526 01:41:24.565225 15117 sgd_solver.cpp:294] Iteration 9160, lr = 0.02
I0526 01:41:30.977227 15117 solver.cpp:233] Iteration 9170, loss = 0.403388
I0526 01:41:30.977296 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.403388 (* 1 = 0.403388 loss)
I0526 01:41:30.977308 15117 sgd_solver.cpp:294] Iteration 9170, lr = 0.02
I0526 01:41:37.387557 15117 solver.cpp:233] Iteration 9180, loss = 0.188917
I0526 01:41:37.387625 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.188917 (* 1 = 0.188917 loss)
I0526 01:41:37.387636 15117 sgd_solver.cpp:294] Iteration 9180, lr = 0.02
I0526 01:41:43.795063 15117 solver.cpp:233] Iteration 9190, loss = 0.29385
I0526 01:41:43.795128 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.29385 (* 1 = 0.29385 loss)
I0526 01:41:43.795140 15117 sgd_solver.cpp:294] Iteration 9190, lr = 0.02
I0526 01:41:49.598289 15117 solver.cpp:342] Iteration 9200, Testing net (#0)
I0526 01:42:02.790530 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7516
I0526 01:42:02.790695 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.836458 (* 1 = 0.836458 loss)
I0526 01:42:03.400324 15117 solver.cpp:233] Iteration 9200, loss = 0.310042
I0526 01:42:03.400388 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.310042 (* 1 = 0.310042 loss)
I0526 01:42:03.400400 15117 sgd_solver.cpp:294] Iteration 9200, lr = 0.02
I0526 01:42:09.813405 15117 solver.cpp:233] Iteration 9210, loss = 0.199014
I0526 01:42:09.813470 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.199014 (* 1 = 0.199014 loss)
I0526 01:42:09.813482 15117 sgd_solver.cpp:294] Iteration 9210, lr = 0.02
I0526 01:42:16.224447 15117 solver.cpp:233] Iteration 9220, loss = 0.265992
I0526 01:42:16.224519 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.265992 (* 1 = 0.265992 loss)
I0526 01:42:16.224530 15117 sgd_solver.cpp:294] Iteration 9220, lr = 0.02
I0526 01:42:22.636775 15117 solver.cpp:233] Iteration 9230, loss = 0.312261
I0526 01:42:22.636842 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.312261 (* 1 = 0.312261 loss)
I0526 01:42:22.636853 15117 sgd_solver.cpp:294] Iteration 9230, lr = 0.02
I0526 01:42:29.048182 15117 solver.cpp:233] Iteration 9240, loss = 0.30718
I0526 01:42:29.048250 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.30718 (* 1 = 0.30718 loss)
I0526 01:42:29.048261 15117 sgd_solver.cpp:294] Iteration 9240, lr = 0.02
I0526 01:42:35.456856 15117 solver.cpp:233] Iteration 9250, loss = 0.234256
I0526 01:42:35.457087 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.234256 (* 1 = 0.234256 loss)
I0526 01:42:35.457099 15117 sgd_solver.cpp:294] Iteration 9250, lr = 0.02
I0526 01:42:41.855685 15117 solver.cpp:233] Iteration 9260, loss = 0.207353
I0526 01:42:41.855761 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.207353 (* 1 = 0.207353 loss)
I0526 01:42:41.855772 15117 sgd_solver.cpp:294] Iteration 9260, lr = 0.02
I0526 01:42:48.245415 15117 solver.cpp:233] Iteration 9270, loss = 0.212685
I0526 01:42:48.245488 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.212685 (* 1 = 0.212685 loss)
I0526 01:42:48.245501 15117 sgd_solver.cpp:294] Iteration 9270, lr = 0.02
I0526 01:42:54.640231 15117 solver.cpp:233] Iteration 9280, loss = 0.342186
I0526 01:42:54.640305 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.342186 (* 1 = 0.342186 loss)
I0526 01:42:54.640317 15117 sgd_solver.cpp:294] Iteration 9280, lr = 0.02
I0526 01:43:01.035598 15117 solver.cpp:233] Iteration 9290, loss = 0.227332
I0526 01:43:01.035671 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.227332 (* 1 = 0.227332 loss)
I0526 01:43:01.035682 15117 sgd_solver.cpp:294] Iteration 9290, lr = 0.02
I0526 01:43:06.820540 15117 solver.cpp:342] Iteration 9300, Testing net (#0)
I0526 01:43:19.940054 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7583
I0526 01:43:19.940124 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.847998 (* 1 = 0.847998 loss)
I0526 01:43:20.547099 15117 solver.cpp:233] Iteration 9300, loss = 0.324933
I0526 01:43:20.547166 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.324933 (* 1 = 0.324933 loss)
I0526 01:43:20.547179 15117 sgd_solver.cpp:294] Iteration 9300, lr = 0.02
I0526 01:43:26.944602 15117 solver.cpp:233] Iteration 9310, loss = 0.252508
I0526 01:43:26.944669 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.252508 (* 1 = 0.252508 loss)
I0526 01:43:26.944679 15117 sgd_solver.cpp:294] Iteration 9310, lr = 0.02
I0526 01:43:33.342120 15117 solver.cpp:233] Iteration 9320, loss = 0.372143
I0526 01:43:33.342191 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.372143 (* 1 = 0.372143 loss)
I0526 01:43:33.342202 15117 sgd_solver.cpp:294] Iteration 9320, lr = 0.02
I0526 01:43:39.745419 15117 solver.cpp:233] Iteration 9330, loss = 0.238718
I0526 01:43:39.745565 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.238718 (* 1 = 0.238718 loss)
I0526 01:43:39.745579 15117 sgd_solver.cpp:294] Iteration 9330, lr = 0.02
I0526 01:43:46.147090 15117 solver.cpp:233] Iteration 9340, loss = 0.24407
I0526 01:43:46.147163 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.24407 (* 1 = 0.24407 loss)
I0526 01:43:46.147174 15117 sgd_solver.cpp:294] Iteration 9340, lr = 0.02
I0526 01:43:52.547209 15117 solver.cpp:233] Iteration 9350, loss = 0.246949
I0526 01:43:52.547293 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.246949 (* 1 = 0.246949 loss)
I0526 01:43:52.547305 15117 sgd_solver.cpp:294] Iteration 9350, lr = 0.02
I0526 01:43:58.950534 15117 solver.cpp:233] Iteration 9360, loss = 0.1842
I0526 01:43:58.950604 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.1842 (* 1 = 0.1842 loss)
I0526 01:43:58.950615 15117 sgd_solver.cpp:294] Iteration 9360, lr = 0.02
I0526 01:44:05.358167 15117 solver.cpp:233] Iteration 9370, loss = 0.343174
I0526 01:44:05.358235 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.343174 (* 1 = 0.343174 loss)
I0526 01:44:05.358247 15117 sgd_solver.cpp:294] Iteration 9370, lr = 0.02
I0526 01:44:11.757699 15117 solver.cpp:233] Iteration 9380, loss = 0.28034
I0526 01:44:11.757935 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.28034 (* 1 = 0.28034 loss)
I0526 01:44:11.757948 15117 sgd_solver.cpp:294] Iteration 9380, lr = 0.02
I0526 01:44:18.153342 15117 solver.cpp:233] Iteration 9390, loss = 0.268557
I0526 01:44:18.153414 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.268557 (* 1 = 0.268557 loss)
I0526 01:44:18.153425 15117 sgd_solver.cpp:294] Iteration 9390, lr = 0.02
I0526 01:44:23.951637 15117 solver.cpp:342] Iteration 9400, Testing net (#0)
I0526 01:44:37.048912 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.802
I0526 01:44:37.048985 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.645658 (* 1 = 0.645658 loss)
I0526 01:44:37.655879 15117 solver.cpp:233] Iteration 9400, loss = 0.224758
I0526 01:44:37.655947 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.224758 (* 1 = 0.224758 loss)
I0526 01:44:37.655959 15117 sgd_solver.cpp:294] Iteration 9400, lr = 0.02
I0526 01:44:44.056088 15117 solver.cpp:233] Iteration 9410, loss = 0.278015
I0526 01:44:44.056246 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.278015 (* 1 = 0.278015 loss)
I0526 01:44:44.056257 15117 sgd_solver.cpp:294] Iteration 9410, lr = 0.02
I0526 01:44:50.461993 15117 solver.cpp:233] Iteration 9420, loss = 0.248215
I0526 01:44:50.462064 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.248215 (* 1 = 0.248215 loss)
I0526 01:44:50.462075 15117 sgd_solver.cpp:294] Iteration 9420, lr = 0.02
I0526 01:44:56.868438 15117 solver.cpp:233] Iteration 9430, loss = 0.354833
I0526 01:44:56.868508 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.354833 (* 1 = 0.354833 loss)
I0526 01:44:56.868520 15117 sgd_solver.cpp:294] Iteration 9430, lr = 0.02
I0526 01:45:03.291126 15117 solver.cpp:233] Iteration 9440, loss = 0.163452
I0526 01:45:03.291200 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.163452 (* 1 = 0.163452 loss)
I0526 01:45:03.291213 15117 sgd_solver.cpp:294] Iteration 9440, lr = 0.02
I0526 01:45:09.696885 15117 solver.cpp:233] Iteration 9450, loss = 0.166635
I0526 01:45:09.696952 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.166635 (* 1 = 0.166635 loss)
I0526 01:45:09.696964 15117 sgd_solver.cpp:294] Iteration 9450, lr = 0.02
I0526 01:45:16.100924 15117 solver.cpp:233] Iteration 9460, loss = 0.315457
I0526 01:45:16.101070 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.315457 (* 1 = 0.315457 loss)
I0526 01:45:16.101083 15117 sgd_solver.cpp:294] Iteration 9460, lr = 0.02
I0526 01:45:22.503816 15117 solver.cpp:233] Iteration 9470, loss = 0.270599
I0526 01:45:22.503883 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.270599 (* 1 = 0.270599 loss)
I0526 01:45:22.503895 15117 sgd_solver.cpp:294] Iteration 9470, lr = 0.02
I0526 01:45:28.907699 15117 solver.cpp:233] Iteration 9480, loss = 0.281342
I0526 01:45:28.907768 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.281342 (* 1 = 0.281342 loss)
I0526 01:45:28.907780 15117 sgd_solver.cpp:294] Iteration 9480, lr = 0.02
I0526 01:45:35.309418 15117 solver.cpp:233] Iteration 9490, loss = 0.266878
I0526 01:45:35.309505 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.266878 (* 1 = 0.266878 loss)
I0526 01:45:35.309517 15117 sgd_solver.cpp:294] Iteration 9490, lr = 0.02
I0526 01:45:41.106076 15117 solver.cpp:342] Iteration 9500, Testing net (#0)
I0526 01:45:54.219060 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7219
I0526 01:45:54.219276 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.04362 (* 1 = 1.04362 loss)
I0526 01:45:54.827759 15117 solver.cpp:233] Iteration 9500, loss = 0.225339
I0526 01:45:54.827829 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.225339 (* 1 = 0.225339 loss)
I0526 01:45:54.827843 15117 sgd_solver.cpp:294] Iteration 9500, lr = 0.02
I0526 01:46:01.232866 15117 solver.cpp:233] Iteration 9510, loss = 0.384337
I0526 01:46:01.232935 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.384337 (* 1 = 0.384337 loss)
I0526 01:46:01.232946 15117 sgd_solver.cpp:294] Iteration 9510, lr = 0.02
I0526 01:46:07.636143 15117 solver.cpp:233] Iteration 9520, loss = 0.292503
I0526 01:46:07.636212 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.292503 (* 1 = 0.292503 loss)
I0526 01:46:07.636224 15117 sgd_solver.cpp:294] Iteration 9520, lr = 0.02
I0526 01:46:14.041904 15117 solver.cpp:233] Iteration 9530, loss = 0.202644
I0526 01:46:14.041971 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.202644 (* 1 = 0.202644 loss)
I0526 01:46:14.041982 15117 sgd_solver.cpp:294] Iteration 9530, lr = 0.02
I0526 01:46:20.437896 15117 solver.cpp:233] Iteration 9540, loss = 0.31294
I0526 01:46:20.437963 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.31294 (* 1 = 0.31294 loss)
I0526 01:46:20.437975 15117 sgd_solver.cpp:294] Iteration 9540, lr = 0.02
I0526 01:46:26.838448 15117 solver.cpp:233] Iteration 9550, loss = 0.321198
I0526 01:46:26.838660 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.321198 (* 1 = 0.321198 loss)
I0526 01:46:26.838672 15117 sgd_solver.cpp:294] Iteration 9550, lr = 0.02
I0526 01:46:33.236770 15117 solver.cpp:233] Iteration 9560, loss = 0.205245
I0526 01:46:33.236845 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.205245 (* 1 = 0.205245 loss)
I0526 01:46:33.236856 15117 sgd_solver.cpp:294] Iteration 9560, lr = 0.02
I0526 01:46:39.634326 15117 solver.cpp:233] Iteration 9570, loss = 0.164887
I0526 01:46:39.634403 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.164887 (* 1 = 0.164887 loss)
I0526 01:46:39.634415 15117 sgd_solver.cpp:294] Iteration 9570, lr = 0.02
I0526 01:46:46.034976 15117 solver.cpp:233] Iteration 9580, loss = 0.234847
I0526 01:46:46.035048 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.234847 (* 1 = 0.234847 loss)
I0526 01:46:46.035059 15117 sgd_solver.cpp:294] Iteration 9580, lr = 0.02
I0526 01:46:52.434303 15117 solver.cpp:233] Iteration 9590, loss = 0.256603
I0526 01:46:52.434377 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.256603 (* 1 = 0.256603 loss)
I0526 01:46:52.434388 15117 sgd_solver.cpp:294] Iteration 9590, lr = 0.02
I0526 01:46:58.222827 15117 solver.cpp:342] Iteration 9600, Testing net (#0)
I0526 01:47:11.288672 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8056
I0526 01:47:11.288745 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.63423 (* 1 = 0.63423 loss)
I0526 01:47:11.893908 15117 solver.cpp:233] Iteration 9600, loss = 0.183979
I0526 01:47:11.893975 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.183979 (* 1 = 0.183979 loss)
I0526 01:47:11.893988 15117 sgd_solver.cpp:294] Iteration 9600, lr = 0.02
I0526 01:47:18.275252 15117 solver.cpp:233] Iteration 9610, loss = 0.342198
I0526 01:47:18.275321 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.342198 (* 1 = 0.342198 loss)
I0526 01:47:18.275331 15117 sgd_solver.cpp:294] Iteration 9610, lr = 0.02
I0526 01:47:24.661020 15117 solver.cpp:233] Iteration 9620, loss = 0.305479
I0526 01:47:24.661092 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.305479 (* 1 = 0.305479 loss)
I0526 01:47:24.661114 15117 sgd_solver.cpp:294] Iteration 9620, lr = 0.02
I0526 01:47:31.047482 15117 solver.cpp:233] Iteration 9630, loss = 0.244968
I0526 01:47:31.047690 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.244968 (* 1 = 0.244968 loss)
I0526 01:47:31.047703 15117 sgd_solver.cpp:294] Iteration 9630, lr = 0.02
I0526 01:47:37.431273 15117 solver.cpp:233] Iteration 9640, loss = 0.360575
I0526 01:47:37.431341 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.360575 (* 1 = 0.360575 loss)
I0526 01:47:37.431352 15117 sgd_solver.cpp:294] Iteration 9640, lr = 0.02
I0526 01:47:43.810508 15117 solver.cpp:233] Iteration 9650, loss = 0.183369
I0526 01:47:43.810576 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.183369 (* 1 = 0.183369 loss)
I0526 01:47:43.810587 15117 sgd_solver.cpp:294] Iteration 9650, lr = 0.02
I0526 01:47:50.188580 15117 solver.cpp:233] Iteration 9660, loss = 0.258068
I0526 01:47:50.188657 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.258068 (* 1 = 0.258068 loss)
I0526 01:47:50.188668 15117 sgd_solver.cpp:294] Iteration 9660, lr = 0.02
I0526 01:47:56.568264 15117 solver.cpp:233] Iteration 9670, loss = 0.253393
I0526 01:47:56.568333 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.253393 (* 1 = 0.253393 loss)
I0526 01:47:56.568343 15117 sgd_solver.cpp:294] Iteration 9670, lr = 0.02
I0526 01:48:02.952530 15117 solver.cpp:233] Iteration 9680, loss = 0.252859
I0526 01:48:02.952682 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.252859 (* 1 = 0.252859 loss)
I0526 01:48:02.952694 15117 sgd_solver.cpp:294] Iteration 9680, lr = 0.02
I0526 01:48:09.338485 15117 solver.cpp:233] Iteration 9690, loss = 0.298062
I0526 01:48:09.338552 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.298062 (* 1 = 0.298062 loss)
I0526 01:48:09.338563 15117 sgd_solver.cpp:294] Iteration 9690, lr = 0.02
I0526 01:48:15.117754 15117 solver.cpp:342] Iteration 9700, Testing net (#0)
I0526 01:48:28.150307 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7588
I0526 01:48:28.150383 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.823696 (* 1 = 0.823696 loss)
I0526 01:48:28.755328 15117 solver.cpp:233] Iteration 9700, loss = 0.182667
I0526 01:48:28.755394 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.182667 (* 1 = 0.182667 loss)
I0526 01:48:28.755405 15117 sgd_solver.cpp:294] Iteration 9700, lr = 0.02
I0526 01:48:35.133519 15117 solver.cpp:233] Iteration 9710, loss = 0.342082
I0526 01:48:35.133663 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.342082 (* 1 = 0.342082 loss)
I0526 01:48:35.133676 15117 sgd_solver.cpp:294] Iteration 9710, lr = 0.02
I0526 01:48:41.510892 15117 solver.cpp:233] Iteration 9720, loss = 0.221301
I0526 01:48:41.510962 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.221301 (* 1 = 0.221301 loss)
I0526 01:48:41.510973 15117 sgd_solver.cpp:294] Iteration 9720, lr = 0.02
I0526 01:48:47.887701 15117 solver.cpp:233] Iteration 9730, loss = 0.286993
I0526 01:48:47.887770 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.286993 (* 1 = 0.286993 loss)
I0526 01:48:47.887781 15117 sgd_solver.cpp:294] Iteration 9730, lr = 0.02
I0526 01:48:54.260551 15117 solver.cpp:233] Iteration 9740, loss = 0.187546
I0526 01:48:54.260617 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.187546 (* 1 = 0.187546 loss)
I0526 01:48:54.260628 15117 sgd_solver.cpp:294] Iteration 9740, lr = 0.02
I0526 01:49:00.634336 15117 solver.cpp:233] Iteration 9750, loss = 0.216671
I0526 01:49:00.634409 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.216671 (* 1 = 0.216671 loss)
I0526 01:49:00.634420 15117 sgd_solver.cpp:294] Iteration 9750, lr = 0.02
I0526 01:49:07.007627 15117 solver.cpp:233] Iteration 9760, loss = 0.265382
I0526 01:49:07.007830 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.265382 (* 1 = 0.265382 loss)
I0526 01:49:07.007846 15117 sgd_solver.cpp:294] Iteration 9760, lr = 0.02
I0526 01:49:13.377971 15117 solver.cpp:233] Iteration 9770, loss = 0.290041
I0526 01:49:13.378039 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.290041 (* 1 = 0.290041 loss)
I0526 01:49:13.378051 15117 sgd_solver.cpp:294] Iteration 9770, lr = 0.02
I0526 01:49:19.753087 15117 solver.cpp:233] Iteration 9780, loss = 0.236817
I0526 01:49:19.753156 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.236817 (* 1 = 0.236817 loss)
I0526 01:49:19.753167 15117 sgd_solver.cpp:294] Iteration 9780, lr = 0.02
I0526 01:49:26.127151 15117 solver.cpp:233] Iteration 9790, loss = 0.267678
I0526 01:49:26.127218 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.267678 (* 1 = 0.267678 loss)
I0526 01:49:26.127228 15117 sgd_solver.cpp:294] Iteration 9790, lr = 0.02
I0526 01:49:31.900109 15117 solver.cpp:342] Iteration 9800, Testing net (#0)
I0526 01:49:44.885141 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7246
I0526 01:49:44.885291 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.950656 (* 1 = 0.950656 loss)
I0526 01:49:45.490252 15117 solver.cpp:233] Iteration 9800, loss = 0.282431
I0526 01:49:45.490321 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.282431 (* 1 = 0.282431 loss)
I0526 01:49:45.490334 15117 sgd_solver.cpp:294] Iteration 9800, lr = 0.02
I0526 01:49:51.867328 15117 solver.cpp:233] Iteration 9810, loss = 0.20675
I0526 01:49:51.867399 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.20675 (* 1 = 0.20675 loss)
I0526 01:49:51.867410 15117 sgd_solver.cpp:294] Iteration 9810, lr = 0.02
I0526 01:49:58.242676 15117 solver.cpp:233] Iteration 9820, loss = 0.222864
I0526 01:49:58.242745 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.222864 (* 1 = 0.222864 loss)
I0526 01:49:58.242756 15117 sgd_solver.cpp:294] Iteration 9820, lr = 0.02
I0526 01:50:04.619005 15117 solver.cpp:233] Iteration 9830, loss = 0.283218
I0526 01:50:04.619077 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.283218 (* 1 = 0.283218 loss)
I0526 01:50:04.619089 15117 sgd_solver.cpp:294] Iteration 9830, lr = 0.02
I0526 01:50:10.994858 15117 solver.cpp:233] Iteration 9840, loss = 0.272008
I0526 01:50:10.994928 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.272008 (* 1 = 0.272008 loss)
I0526 01:50:10.994940 15117 sgd_solver.cpp:294] Iteration 9840, lr = 0.02
I0526 01:50:17.371021 15117 solver.cpp:233] Iteration 9850, loss = 0.181095
I0526 01:50:17.371184 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.181095 (* 1 = 0.181095 loss)
I0526 01:50:17.371197 15117 sgd_solver.cpp:294] Iteration 9850, lr = 0.02
I0526 01:50:23.742239 15117 solver.cpp:233] Iteration 9860, loss = 0.215096
I0526 01:50:23.742310 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.215096 (* 1 = 0.215096 loss)
I0526 01:50:23.742321 15117 sgd_solver.cpp:294] Iteration 9860, lr = 0.02
I0526 01:50:30.118111 15117 solver.cpp:233] Iteration 9870, loss = 0.30085
I0526 01:50:30.118181 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.30085 (* 1 = 0.30085 loss)
I0526 01:50:30.118192 15117 sgd_solver.cpp:294] Iteration 9870, lr = 0.02
I0526 01:50:36.491668 15117 solver.cpp:233] Iteration 9880, loss = 0.199488
I0526 01:50:36.491734 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.199488 (* 1 = 0.199488 loss)
I0526 01:50:36.491746 15117 sgd_solver.cpp:294] Iteration 9880, lr = 0.02
I0526 01:50:42.869096 15117 solver.cpp:233] Iteration 9890, loss = 0.235375
I0526 01:50:42.869168 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.235375 (* 1 = 0.235375 loss)
I0526 01:50:42.869179 15117 sgd_solver.cpp:294] Iteration 9890, lr = 0.02
I0526 01:50:48.639322 15117 solver.cpp:342] Iteration 9900, Testing net (#0)
I0526 01:51:01.630013 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7974
I0526 01:51:01.630089 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.678185 (* 1 = 0.678185 loss)
I0526 01:51:02.235218 15117 solver.cpp:233] Iteration 9900, loss = 0.426848
I0526 01:51:02.235291 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.426848 (* 1 = 0.426848 loss)
I0526 01:51:02.235304 15117 sgd_solver.cpp:294] Iteration 9900, lr = 0.02
I0526 01:51:08.611800 15117 solver.cpp:233] Iteration 9910, loss = 0.301427
I0526 01:51:08.611870 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.301427 (* 1 = 0.301427 loss)
I0526 01:51:08.611879 15117 sgd_solver.cpp:294] Iteration 9910, lr = 0.02
I0526 01:51:14.990281 15117 solver.cpp:233] Iteration 9920, loss = 0.191484
I0526 01:51:14.990365 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.191484 (* 1 = 0.191484 loss)
I0526 01:51:14.990377 15117 sgd_solver.cpp:294] Iteration 9920, lr = 0.02
I0526 01:51:21.365293 15117 solver.cpp:233] Iteration 9930, loss = 0.319402
I0526 01:51:21.365473 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.319402 (* 1 = 0.319402 loss)
I0526 01:51:21.365485 15117 sgd_solver.cpp:294] Iteration 9930, lr = 0.02
I0526 01:51:27.742609 15117 solver.cpp:233] Iteration 9940, loss = 0.296484
I0526 01:51:27.742683 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.296484 (* 1 = 0.296484 loss)
I0526 01:51:27.742696 15117 sgd_solver.cpp:294] Iteration 9940, lr = 0.02
I0526 01:51:34.118990 15117 solver.cpp:233] Iteration 9950, loss = 0.168604
I0526 01:51:34.119063 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.168604 (* 1 = 0.168604 loss)
I0526 01:51:34.119074 15117 sgd_solver.cpp:294] Iteration 9950, lr = 0.02
I0526 01:51:40.495493 15117 solver.cpp:233] Iteration 9960, loss = 0.235596
I0526 01:51:40.495571 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.235596 (* 1 = 0.235596 loss)
I0526 01:51:40.495584 15117 sgd_solver.cpp:294] Iteration 9960, lr = 0.02
I0526 01:51:46.868876 15117 solver.cpp:233] Iteration 9970, loss = 0.222965
I0526 01:51:46.868947 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.222965 (* 1 = 0.222965 loss)
I0526 01:51:46.868957 15117 sgd_solver.cpp:294] Iteration 9970, lr = 0.02
I0526 01:51:53.238687 15117 solver.cpp:233] Iteration 9980, loss = 0.27119
I0526 01:51:53.238845 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.27119 (* 1 = 0.27119 loss)
I0526 01:51:53.238858 15117 sgd_solver.cpp:294] Iteration 9980, lr = 0.02
I0526 01:51:59.616452 15117 solver.cpp:233] Iteration 9990, loss = 0.269581
I0526 01:51:59.616533 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.269581 (* 1 = 0.269581 loss)
I0526 01:51:59.616547 15117 sgd_solver.cpp:294] Iteration 9990, lr = 0.02
I0526 01:52:05.388422 15117 solver.cpp:342] Iteration 10000, Testing net (#0)
I0526 01:52:18.430464 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7551
I0526 01:52:18.430538 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.914225 (* 1 = 0.914225 loss)
I0526 01:52:19.035400 15117 solver.cpp:233] Iteration 10000, loss = 0.261239
I0526 01:52:19.035470 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.261239 (* 1 = 0.261239 loss)
I0526 01:52:19.035485 15117 sgd_solver.cpp:294] Iteration 10000, lr = 0.02
I0526 01:52:25.412667 15117 solver.cpp:233] Iteration 10010, loss = 0.12012
I0526 01:52:25.412817 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.12012 (* 1 = 0.12012 loss)
I0526 01:52:25.412829 15117 sgd_solver.cpp:294] Iteration 10010, lr = 0.02
I0526 01:52:31.786182 15117 solver.cpp:233] Iteration 10020, loss = 0.248946
I0526 01:52:31.786253 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.248946 (* 1 = 0.248946 loss)
I0526 01:52:31.786264 15117 sgd_solver.cpp:294] Iteration 10020, lr = 0.02
I0526 01:52:38.160696 15117 solver.cpp:233] Iteration 10030, loss = 0.408794
I0526 01:52:38.160763 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.408794 (* 1 = 0.408794 loss)
I0526 01:52:38.160773 15117 sgd_solver.cpp:294] Iteration 10030, lr = 0.02
I0526 01:52:44.530760 15117 solver.cpp:233] Iteration 10040, loss = 0.253227
I0526 01:52:44.530845 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.253227 (* 1 = 0.253227 loss)
I0526 01:52:44.530859 15117 sgd_solver.cpp:294] Iteration 10040, lr = 0.02
I0526 01:52:50.906118 15117 solver.cpp:233] Iteration 10050, loss = 0.344865
I0526 01:52:50.906185 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.344865 (* 1 = 0.344865 loss)
I0526 01:52:50.906195 15117 sgd_solver.cpp:294] Iteration 10050, lr = 0.02
I0526 01:52:57.280391 15117 solver.cpp:233] Iteration 10060, loss = 0.176506
I0526 01:52:57.280593 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.176506 (* 1 = 0.176506 loss)
I0526 01:52:57.280606 15117 sgd_solver.cpp:294] Iteration 10060, lr = 0.02
I0526 01:53:03.656847 15117 solver.cpp:233] Iteration 10070, loss = 0.219915
I0526 01:53:03.656919 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.219914 (* 1 = 0.219914 loss)
I0526 01:53:03.656929 15117 sgd_solver.cpp:294] Iteration 10070, lr = 0.02
I0526 01:53:10.029835 15117 solver.cpp:233] Iteration 10080, loss = 0.175754
I0526 01:53:10.029904 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.175754 (* 1 = 0.175754 loss)
I0526 01:53:10.029917 15117 sgd_solver.cpp:294] Iteration 10080, lr = 0.02
I0526 01:53:16.404043 15117 solver.cpp:233] Iteration 10090, loss = 0.231381
I0526 01:53:16.404114 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.231381 (* 1 = 0.231381 loss)
I0526 01:53:16.404125 15117 sgd_solver.cpp:294] Iteration 10090, lr = 0.02
I0526 01:53:22.174922 15117 solver.cpp:342] Iteration 10100, Testing net (#0)
I0526 01:53:35.176854 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8075
I0526 01:53:35.177016 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.61104 (* 1 = 0.61104 loss)
I0526 01:53:35.781018 15117 solver.cpp:233] Iteration 10100, loss = 0.305723
I0526 01:53:35.781093 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.305723 (* 1 = 0.305723 loss)
I0526 01:53:35.781107 15117 sgd_solver.cpp:294] Iteration 10100, lr = 0.02
I0526 01:53:42.150818 15117 solver.cpp:233] Iteration 10110, loss = 0.228918
I0526 01:53:42.150887 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.228918 (* 1 = 0.228918 loss)
I0526 01:53:42.150898 15117 sgd_solver.cpp:294] Iteration 10110, lr = 0.02
I0526 01:53:48.524142 15117 solver.cpp:233] Iteration 10120, loss = 0.197036
I0526 01:53:48.524214 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.197036 (* 1 = 0.197036 loss)
I0526 01:53:48.524225 15117 sgd_solver.cpp:294] Iteration 10120, lr = 0.02
I0526 01:53:54.893818 15117 solver.cpp:233] Iteration 10130, loss = 0.224013
I0526 01:53:54.893885 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.224013 (* 1 = 0.224013 loss)
I0526 01:53:54.893896 15117 sgd_solver.cpp:294] Iteration 10130, lr = 0.02
I0526 01:54:01.272392 15117 solver.cpp:233] Iteration 10140, loss = 0.188725
I0526 01:54:01.272465 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.188725 (* 1 = 0.188725 loss)
I0526 01:54:01.272477 15117 sgd_solver.cpp:294] Iteration 10140, lr = 0.02
I0526 01:54:07.652283 15117 solver.cpp:233] Iteration 10150, loss = 0.285638
I0526 01:54:07.652462 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.285638 (* 1 = 0.285638 loss)
I0526 01:54:07.652477 15117 sgd_solver.cpp:294] Iteration 10150, lr = 0.02
I0526 01:54:14.034740 15117 solver.cpp:233] Iteration 10160, loss = 0.217045
I0526 01:54:14.034806 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.217045 (* 1 = 0.217045 loss)
I0526 01:54:14.034818 15117 sgd_solver.cpp:294] Iteration 10160, lr = 0.02
I0526 01:54:20.415844 15117 solver.cpp:233] Iteration 10170, loss = 0.27926
I0526 01:54:20.415918 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.27926 (* 1 = 0.27926 loss)
I0526 01:54:20.415930 15117 sgd_solver.cpp:294] Iteration 10170, lr = 0.02
I0526 01:54:26.787838 15117 solver.cpp:233] Iteration 10180, loss = 0.222495
I0526 01:54:26.787911 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.222495 (* 1 = 0.222495 loss)
I0526 01:54:26.787924 15117 sgd_solver.cpp:294] Iteration 10180, lr = 0.02
I0526 01:54:33.159179 15117 solver.cpp:233] Iteration 10190, loss = 0.201105
I0526 01:54:33.159246 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.201105 (* 1 = 0.201105 loss)
I0526 01:54:33.159256 15117 sgd_solver.cpp:294] Iteration 10190, lr = 0.02
I0526 01:54:38.965273 15117 solver.cpp:342] Iteration 10200, Testing net (#0)
I0526 01:54:52.333209 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7806
I0526 01:54:52.333295 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.700275 (* 1 = 0.700275 loss)
I0526 01:54:52.937575 15117 solver.cpp:233] Iteration 10200, loss = 0.221275
I0526 01:54:52.937671 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.221275 (* 1 = 0.221275 loss)
I0526 01:54:52.937701 15117 sgd_solver.cpp:294] Iteration 10200, lr = 0.02
I0526 01:54:59.371803 15117 solver.cpp:233] Iteration 10210, loss = 0.211379
I0526 01:54:59.371887 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.211379 (* 1 = 0.211379 loss)
I0526 01:54:59.371901 15117 sgd_solver.cpp:294] Iteration 10210, lr = 0.02
I0526 01:55:05.802644 15117 solver.cpp:233] Iteration 10220, loss = 0.267755
I0526 01:55:05.802713 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.267755 (* 1 = 0.267755 loss)
I0526 01:55:05.802724 15117 sgd_solver.cpp:294] Iteration 10220, lr = 0.02
I0526 01:55:12.185425 15117 solver.cpp:233] Iteration 10230, loss = 0.271771
I0526 01:55:12.185585 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.271771 (* 1 = 0.271771 loss)
I0526 01:55:12.185597 15117 sgd_solver.cpp:294] Iteration 10230, lr = 0.02
I0526 01:55:18.571107 15117 solver.cpp:233] Iteration 10240, loss = 0.280847
I0526 01:55:18.571176 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.280847 (* 1 = 0.280847 loss)
I0526 01:55:18.571187 15117 sgd_solver.cpp:294] Iteration 10240, lr = 0.02
I0526 01:55:24.955631 15117 solver.cpp:233] Iteration 10250, loss = 0.209814
I0526 01:55:24.955696 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.209814 (* 1 = 0.209814 loss)
I0526 01:55:24.955708 15117 sgd_solver.cpp:294] Iteration 10250, lr = 0.02
I0526 01:55:31.345367 15117 solver.cpp:233] Iteration 10260, loss = 0.253502
I0526 01:55:31.345445 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.253502 (* 1 = 0.253502 loss)
I0526 01:55:31.345456 15117 sgd_solver.cpp:294] Iteration 10260, lr = 0.02
I0526 01:55:37.735524 15117 solver.cpp:233] Iteration 10270, loss = 0.186081
I0526 01:55:37.735591 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.186081 (* 1 = 0.186081 loss)
I0526 01:55:37.735604 15117 sgd_solver.cpp:294] Iteration 10270, lr = 0.02
I0526 01:55:44.119462 15117 solver.cpp:233] Iteration 10280, loss = 0.298897
I0526 01:55:44.119616 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.298897 (* 1 = 0.298897 loss)
I0526 01:55:44.119628 15117 sgd_solver.cpp:294] Iteration 10280, lr = 0.02
I0526 01:55:50.494729 15117 solver.cpp:233] Iteration 10290, loss = 0.193345
I0526 01:55:50.494801 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.193345 (* 1 = 0.193345 loss)
I0526 01:55:50.494812 15117 sgd_solver.cpp:294] Iteration 10290, lr = 0.02
I0526 01:55:56.259419 15117 solver.cpp:342] Iteration 10300, Testing net (#0)
I0526 01:56:09.601073 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7967
I0526 01:56:09.601146 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.637685 (* 1 = 0.637685 loss)
I0526 01:56:10.204118 15117 solver.cpp:233] Iteration 10300, loss = 0.389378
I0526 01:56:10.204182 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.389378 (* 1 = 0.389378 loss)
I0526 01:56:10.204195 15117 sgd_solver.cpp:294] Iteration 10300, lr = 0.02
I0526 01:56:16.611578 15117 solver.cpp:233] Iteration 10310, loss = 0.199164
I0526 01:56:16.611810 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.199164 (* 1 = 0.199164 loss)
I0526 01:56:16.611824 15117 sgd_solver.cpp:294] Iteration 10310, lr = 0.02
I0526 01:56:23.048784 15117 solver.cpp:233] Iteration 10320, loss = 0.278517
I0526 01:56:23.048851 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.278517 (* 1 = 0.278517 loss)
I0526 01:56:23.048862 15117 sgd_solver.cpp:294] Iteration 10320, lr = 0.02
I0526 01:56:29.470674 15117 solver.cpp:233] Iteration 10330, loss = 0.197656
I0526 01:56:29.470755 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.197656 (* 1 = 0.197656 loss)
I0526 01:56:29.470768 15117 sgd_solver.cpp:294] Iteration 10330, lr = 0.02
I0526 01:56:35.935508 15117 solver.cpp:233] Iteration 10340, loss = 0.398904
I0526 01:56:35.935575 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.398904 (* 1 = 0.398904 loss)
I0526 01:56:35.935587 15117 sgd_solver.cpp:294] Iteration 10340, lr = 0.02
I0526 01:56:42.354473 15117 solver.cpp:233] Iteration 10350, loss = 0.226212
I0526 01:56:42.354545 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.226212 (* 1 = 0.226212 loss)
I0526 01:56:42.354557 15117 sgd_solver.cpp:294] Iteration 10350, lr = 0.02
I0526 01:56:48.756844 15117 solver.cpp:233] Iteration 10360, loss = 0.206728
I0526 01:56:48.756994 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.206728 (* 1 = 0.206728 loss)
I0526 01:56:48.757007 15117 sgd_solver.cpp:294] Iteration 10360, lr = 0.02
I0526 01:56:55.158885 15117 solver.cpp:233] Iteration 10370, loss = 0.147631
I0526 01:56:55.158953 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.147631 (* 1 = 0.147631 loss)
I0526 01:56:55.158964 15117 sgd_solver.cpp:294] Iteration 10370, lr = 0.02
I0526 01:57:01.579109 15117 solver.cpp:233] Iteration 10380, loss = 0.213605
I0526 01:57:01.579180 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.213605 (* 1 = 0.213605 loss)
I0526 01:57:01.579191 15117 sgd_solver.cpp:294] Iteration 10380, lr = 0.02
I0526 01:57:07.978600 15117 solver.cpp:233] Iteration 10390, loss = 0.154628
I0526 01:57:07.978669 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.154628 (* 1 = 0.154628 loss)
I0526 01:57:07.978680 15117 sgd_solver.cpp:294] Iteration 10390, lr = 0.02
I0526 01:57:13.788517 15117 solver.cpp:342] Iteration 10400, Testing net (#0)
I0526 01:57:27.086869 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7017
I0526 01:57:27.087026 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.23312 (* 1 = 1.23312 loss)
I0526 01:57:27.694078 15117 solver.cpp:233] Iteration 10400, loss = 0.148931
I0526 01:57:27.694145 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.148931 (* 1 = 0.148931 loss)
I0526 01:57:27.694157 15117 sgd_solver.cpp:294] Iteration 10400, lr = 0.02
I0526 01:57:34.081437 15117 solver.cpp:233] Iteration 10410, loss = 0.325544
I0526 01:57:34.081511 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.325544 (* 1 = 0.325544 loss)
I0526 01:57:34.081522 15117 sgd_solver.cpp:294] Iteration 10410, lr = 0.02
I0526 01:57:40.475996 15117 solver.cpp:233] Iteration 10420, loss = 0.211522
I0526 01:57:40.476069 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.211522 (* 1 = 0.211522 loss)
I0526 01:57:40.476081 15117 sgd_solver.cpp:294] Iteration 10420, lr = 0.02
I0526 01:57:46.915182 15117 solver.cpp:233] Iteration 10430, loss = 0.245297
I0526 01:57:46.915254 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.245297 (* 1 = 0.245297 loss)
I0526 01:57:46.915266 15117 sgd_solver.cpp:294] Iteration 10430, lr = 0.02
I0526 01:57:53.327594 15117 solver.cpp:233] Iteration 10440, loss = 0.214459
I0526 01:57:53.327697 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.214459 (* 1 = 0.214459 loss)
I0526 01:57:53.327713 15117 sgd_solver.cpp:294] Iteration 10440, lr = 0.02
I0526 01:57:59.739156 15117 solver.cpp:233] Iteration 10450, loss = 0.275969
I0526 01:57:59.739388 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.275969 (* 1 = 0.275969 loss)
I0526 01:57:59.739401 15117 sgd_solver.cpp:294] Iteration 10450, lr = 0.02
I0526 01:58:06.170588 15117 solver.cpp:233] Iteration 10460, loss = 0.238434
I0526 01:58:06.170655 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.238434 (* 1 = 0.238434 loss)
I0526 01:58:06.170667 15117 sgd_solver.cpp:294] Iteration 10460, lr = 0.02
I0526 01:58:12.610257 15117 solver.cpp:233] Iteration 10470, loss = 0.235184
I0526 01:58:12.610326 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.235184 (* 1 = 0.235184 loss)
I0526 01:58:12.610337 15117 sgd_solver.cpp:294] Iteration 10470, lr = 0.02
I0526 01:58:19.011075 15117 solver.cpp:233] Iteration 10480, loss = 0.19294
I0526 01:58:19.011150 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.19294 (* 1 = 0.19294 loss)
I0526 01:58:19.011162 15117 sgd_solver.cpp:294] Iteration 10480, lr = 0.02
I0526 01:58:25.388989 15117 solver.cpp:233] Iteration 10490, loss = 0.24096
I0526 01:58:25.389055 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.24096 (* 1 = 0.24096 loss)
I0526 01:58:25.389065 15117 sgd_solver.cpp:294] Iteration 10490, lr = 0.02
I0526 01:58:31.196893 15117 solver.cpp:342] Iteration 10500, Testing net (#0)
I0526 01:58:44.639880 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7896
I0526 01:58:44.639958 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.687806 (* 1 = 0.687806 loss)
I0526 01:58:45.251243 15117 solver.cpp:233] Iteration 10500, loss = 0.277437
I0526 01:58:45.251323 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.277437 (* 1 = 0.277437 loss)
I0526 01:58:45.251338 15117 sgd_solver.cpp:294] Iteration 10500, lr = 0.02
I0526 01:58:51.654012 15117 solver.cpp:233] Iteration 10510, loss = 0.138607
I0526 01:58:51.654080 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.138607 (* 1 = 0.138607 loss)
I0526 01:58:51.654091 15117 sgd_solver.cpp:294] Iteration 10510, lr = 0.02
I0526 01:58:58.074399 15117 solver.cpp:233] Iteration 10520, loss = 0.240705
I0526 01:58:58.074467 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.240705 (* 1 = 0.240705 loss)
I0526 01:58:58.074478 15117 sgd_solver.cpp:294] Iteration 10520, lr = 0.02
I0526 01:59:04.460458 15117 solver.cpp:233] Iteration 10530, loss = 0.233236
I0526 01:59:04.460628 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.233236 (* 1 = 0.233236 loss)
I0526 01:59:04.460640 15117 sgd_solver.cpp:294] Iteration 10530, lr = 0.02
I0526 01:59:10.883443 15117 solver.cpp:233] Iteration 10540, loss = 0.291353
I0526 01:59:10.883513 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.291353 (* 1 = 0.291353 loss)
I0526 01:59:10.883524 15117 sgd_solver.cpp:294] Iteration 10540, lr = 0.02
I0526 01:59:17.321851 15117 solver.cpp:233] Iteration 10550, loss = 0.228467
I0526 01:59:17.321934 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.228467 (* 1 = 0.228467 loss)
I0526 01:59:17.321946 15117 sgd_solver.cpp:294] Iteration 10550, lr = 0.02
I0526 01:59:23.750265 15117 solver.cpp:233] Iteration 10560, loss = 0.272159
I0526 01:59:23.750337 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.272159 (* 1 = 0.272159 loss)
I0526 01:59:23.750349 15117 sgd_solver.cpp:294] Iteration 10560, lr = 0.02
I0526 01:59:30.161842 15117 solver.cpp:233] Iteration 10570, loss = 0.226979
I0526 01:59:30.161929 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.226979 (* 1 = 0.226979 loss)
I0526 01:59:30.161943 15117 sgd_solver.cpp:294] Iteration 10570, lr = 0.02
I0526 01:59:36.585155 15117 solver.cpp:233] Iteration 10580, loss = 0.142423
I0526 01:59:36.585310 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.142423 (* 1 = 0.142423 loss)
I0526 01:59:36.585322 15117 sgd_solver.cpp:294] Iteration 10580, lr = 0.02
I0526 01:59:43.006767 15117 solver.cpp:233] Iteration 10590, loss = 0.241872
I0526 01:59:43.006844 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.241872 (* 1 = 0.241872 loss)
I0526 01:59:43.006856 15117 sgd_solver.cpp:294] Iteration 10590, lr = 0.02
I0526 01:59:48.811960 15117 solver.cpp:342] Iteration 10600, Testing net (#0)
I0526 02:00:02.117844 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8144
I0526 02:00:02.117943 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.568541 (* 1 = 0.568541 loss)
I0526 02:00:02.728780 15117 solver.cpp:233] Iteration 10600, loss = 0.195586
I0526 02:00:02.728857 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.195586 (* 1 = 0.195586 loss)
I0526 02:00:02.728873 15117 sgd_solver.cpp:294] Iteration 10600, lr = 0.02
I0526 02:00:09.152685 15117 solver.cpp:233] Iteration 10610, loss = 0.265635
I0526 02:00:09.152906 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.265635 (* 1 = 0.265635 loss)
I0526 02:00:09.152920 15117 sgd_solver.cpp:294] Iteration 10610, lr = 0.02
I0526 02:00:15.628445 15117 solver.cpp:233] Iteration 10620, loss = 0.265587
I0526 02:00:15.628521 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.265587 (* 1 = 0.265587 loss)
I0526 02:00:15.628533 15117 sgd_solver.cpp:294] Iteration 10620, lr = 0.02
I0526 02:00:22.013641 15117 solver.cpp:233] Iteration 10630, loss = 0.213676
I0526 02:00:22.013715 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.213676 (* 1 = 0.213676 loss)
I0526 02:00:22.013728 15117 sgd_solver.cpp:294] Iteration 10630, lr = 0.02
I0526 02:00:28.398316 15117 solver.cpp:233] Iteration 10640, loss = 0.267536
I0526 02:00:28.398418 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.267536 (* 1 = 0.267536 loss)
I0526 02:00:28.398432 15117 sgd_solver.cpp:294] Iteration 10640, lr = 0.02
I0526 02:00:34.781234 15117 solver.cpp:233] Iteration 10650, loss = 0.243785
I0526 02:00:34.781314 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.243785 (* 1 = 0.243785 loss)
I0526 02:00:34.781327 15117 sgd_solver.cpp:294] Iteration 10650, lr = 0.02
I0526 02:00:41.218791 15117 solver.cpp:233] Iteration 10660, loss = 0.22671
I0526 02:00:41.218957 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.22671 (* 1 = 0.22671 loss)
I0526 02:00:41.218971 15117 sgd_solver.cpp:294] Iteration 10660, lr = 0.02
I0526 02:00:47.642051 15117 solver.cpp:233] Iteration 10670, loss = 0.199261
I0526 02:00:47.642125 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.199261 (* 1 = 0.199261 loss)
I0526 02:00:47.642138 15117 sgd_solver.cpp:294] Iteration 10670, lr = 0.02
I0526 02:00:54.064368 15117 solver.cpp:233] Iteration 10680, loss = 0.265734
I0526 02:00:54.064436 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.265734 (* 1 = 0.265734 loss)
I0526 02:00:54.064447 15117 sgd_solver.cpp:294] Iteration 10680, lr = 0.02
I0526 02:01:00.496230 15117 solver.cpp:233] Iteration 10690, loss = 0.225532
I0526 02:01:00.496309 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.225532 (* 1 = 0.225532 loss)
I0526 02:01:00.496323 15117 sgd_solver.cpp:294] Iteration 10690, lr = 0.02
I0526 02:01:06.300390 15117 solver.cpp:342] Iteration 10700, Testing net (#0)
I0526 02:01:19.655931 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7102
I0526 02:01:19.656074 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.12764 (* 1 = 1.12764 loss)
I0526 02:01:20.262454 15117 solver.cpp:233] Iteration 10700, loss = 0.134534
I0526 02:01:20.262519 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.134534 (* 1 = 0.134534 loss)
I0526 02:01:20.262533 15117 sgd_solver.cpp:294] Iteration 10700, lr = 0.02
I0526 02:01:26.645972 15117 solver.cpp:233] Iteration 10710, loss = 0.226079
I0526 02:01:26.646036 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.226079 (* 1 = 0.226079 loss)
I0526 02:01:26.646047 15117 sgd_solver.cpp:294] Iteration 10710, lr = 0.02
I0526 02:01:33.023078 15117 solver.cpp:233] Iteration 10720, loss = 0.151444
I0526 02:01:33.023160 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.151444 (* 1 = 0.151444 loss)
I0526 02:01:33.023171 15117 sgd_solver.cpp:294] Iteration 10720, lr = 0.02
I0526 02:01:39.432304 15117 solver.cpp:233] Iteration 10730, loss = 0.297874
I0526 02:01:39.432373 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.297874 (* 1 = 0.297874 loss)
I0526 02:01:39.432384 15117 sgd_solver.cpp:294] Iteration 10730, lr = 0.02
I0526 02:01:45.849601 15117 solver.cpp:233] Iteration 10740, loss = 0.209684
I0526 02:01:45.849671 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.209684 (* 1 = 0.209684 loss)
I0526 02:01:45.849683 15117 sgd_solver.cpp:294] Iteration 10740, lr = 0.02
I0526 02:01:52.246938 15117 solver.cpp:233] Iteration 10750, loss = 0.207957
I0526 02:01:52.247148 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.207957 (* 1 = 0.207957 loss)
I0526 02:01:52.247160 15117 sgd_solver.cpp:294] Iteration 10750, lr = 0.02
I0526 02:01:58.693279 15117 solver.cpp:233] Iteration 10760, loss = 0.185307
I0526 02:01:58.693353 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.185307 (* 1 = 0.185307 loss)
I0526 02:01:58.693364 15117 sgd_solver.cpp:294] Iteration 10760, lr = 0.02
I0526 02:02:05.087472 15117 solver.cpp:233] Iteration 10770, loss = 0.237874
I0526 02:02:05.087546 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.237874 (* 1 = 0.237874 loss)
I0526 02:02:05.087558 15117 sgd_solver.cpp:294] Iteration 10770, lr = 0.02
I0526 02:02:11.512573 15117 solver.cpp:233] Iteration 10780, loss = 0.219513
I0526 02:02:11.512641 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.219513 (* 1 = 0.219513 loss)
I0526 02:02:11.512655 15117 sgd_solver.cpp:294] Iteration 10780, lr = 0.02
I0526 02:02:17.915191 15117 solver.cpp:233] Iteration 10790, loss = 0.219266
I0526 02:02:17.915262 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.219266 (* 1 = 0.219266 loss)
I0526 02:02:17.915273 15117 sgd_solver.cpp:294] Iteration 10790, lr = 0.02
I0526 02:02:23.689703 15117 solver.cpp:342] Iteration 10800, Testing net (#0)
I0526 02:02:37.015014 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7035
I0526 02:02:37.015087 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.13378 (* 1 = 1.13378 loss)
I0526 02:02:37.619551 15117 solver.cpp:233] Iteration 10800, loss = 0.215718
I0526 02:02:37.619621 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.215718 (* 1 = 0.215718 loss)
I0526 02:02:37.619633 15117 sgd_solver.cpp:294] Iteration 10800, lr = 0.02
I0526 02:02:43.991466 15117 solver.cpp:233] Iteration 10810, loss = 0.175831
I0526 02:02:43.991534 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.175831 (* 1 = 0.175831 loss)
I0526 02:02:43.991545 15117 sgd_solver.cpp:294] Iteration 10810, lr = 0.02
I0526 02:02:50.377158 15117 solver.cpp:233] Iteration 10820, loss = 0.338575
I0526 02:02:50.377228 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.338575 (* 1 = 0.338575 loss)
I0526 02:02:50.377239 15117 sgd_solver.cpp:294] Iteration 10820, lr = 0.02
I0526 02:02:56.784903 15117 solver.cpp:233] Iteration 10830, loss = 0.263913
I0526 02:02:56.785056 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.263913 (* 1 = 0.263913 loss)
I0526 02:02:56.785069 15117 sgd_solver.cpp:294] Iteration 10830, lr = 0.02
I0526 02:03:03.188504 15117 solver.cpp:233] Iteration 10840, loss = 0.233899
I0526 02:03:03.188572 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.233899 (* 1 = 0.233899 loss)
I0526 02:03:03.188585 15117 sgd_solver.cpp:294] Iteration 10840, lr = 0.02
I0526 02:03:09.588335 15117 solver.cpp:233] Iteration 10850, loss = 0.199202
I0526 02:03:09.588407 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.199202 (* 1 = 0.199202 loss)
I0526 02:03:09.588418 15117 sgd_solver.cpp:294] Iteration 10850, lr = 0.02
I0526 02:03:16.046170 15117 solver.cpp:233] Iteration 10860, loss = 0.222602
I0526 02:03:16.046241 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.222602 (* 1 = 0.222602 loss)
I0526 02:03:16.046262 15117 sgd_solver.cpp:294] Iteration 10860, lr = 0.02
I0526 02:03:22.458000 15117 solver.cpp:233] Iteration 10870, loss = 0.25573
I0526 02:03:22.458067 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.25573 (* 1 = 0.25573 loss)
I0526 02:03:22.458079 15117 sgd_solver.cpp:294] Iteration 10870, lr = 0.02
I0526 02:03:28.858762 15117 solver.cpp:233] Iteration 10880, loss = 0.18743
I0526 02:03:28.858968 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.18743 (* 1 = 0.18743 loss)
I0526 02:03:28.858983 15117 sgd_solver.cpp:294] Iteration 10880, lr = 0.02
I0526 02:03:35.275461 15117 solver.cpp:233] Iteration 10890, loss = 0.250084
I0526 02:03:35.275537 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.250084 (* 1 = 0.250084 loss)
I0526 02:03:35.275548 15117 sgd_solver.cpp:294] Iteration 10890, lr = 0.02
I0526 02:03:41.120600 15117 solver.cpp:342] Iteration 10900, Testing net (#0)
I0526 02:03:54.411097 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8135
I0526 02:03:54.411195 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.60055 (* 1 = 0.60055 loss)
I0526 02:03:55.022267 15117 solver.cpp:233] Iteration 10900, loss = 0.271783
I0526 02:03:55.022336 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.271783 (* 1 = 0.271783 loss)
I0526 02:03:55.022349 15117 sgd_solver.cpp:294] Iteration 10900, lr = 0.02
I0526 02:04:01.427340 15117 solver.cpp:233] Iteration 10910, loss = 0.269067
I0526 02:04:01.427492 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.269067 (* 1 = 0.269067 loss)
I0526 02:04:01.427505 15117 sgd_solver.cpp:294] Iteration 10910, lr = 0.02
I0526 02:04:07.868119 15117 solver.cpp:233] Iteration 10920, loss = 0.230237
I0526 02:04:07.868190 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.230237 (* 1 = 0.230237 loss)
I0526 02:04:07.868201 15117 sgd_solver.cpp:294] Iteration 10920, lr = 0.02
I0526 02:04:14.314980 15117 solver.cpp:233] Iteration 10930, loss = 0.203315
I0526 02:04:14.315048 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.203315 (* 1 = 0.203315 loss)
I0526 02:04:14.315059 15117 sgd_solver.cpp:294] Iteration 10930, lr = 0.02
I0526 02:04:20.729277 15117 solver.cpp:233] Iteration 10940, loss = 0.191203
I0526 02:04:20.729352 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.191203 (* 1 = 0.191203 loss)
I0526 02:04:20.729364 15117 sgd_solver.cpp:294] Iteration 10940, lr = 0.02
I0526 02:04:27.143798 15117 solver.cpp:233] Iteration 10950, loss = 0.179232
I0526 02:04:27.143874 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.179232 (* 1 = 0.179232 loss)
I0526 02:04:27.143888 15117 sgd_solver.cpp:294] Iteration 10950, lr = 0.02
I0526 02:04:33.574112 15117 solver.cpp:233] Iteration 10960, loss = 0.196433
I0526 02:04:33.574266 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.196433 (* 1 = 0.196433 loss)
I0526 02:04:33.574280 15117 sgd_solver.cpp:294] Iteration 10960, lr = 0.02
I0526 02:04:39.994511 15117 solver.cpp:233] Iteration 10970, loss = 0.241025
I0526 02:04:39.994578 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.241025 (* 1 = 0.241025 loss)
I0526 02:04:39.994590 15117 sgd_solver.cpp:294] Iteration 10970, lr = 0.02
I0526 02:04:46.422777 15117 solver.cpp:233] Iteration 10980, loss = 0.227863
I0526 02:04:46.422847 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.227863 (* 1 = 0.227863 loss)
I0526 02:04:46.422858 15117 sgd_solver.cpp:294] Iteration 10980, lr = 0.02
I0526 02:04:52.820363 15117 solver.cpp:233] Iteration 10990, loss = 0.267958
I0526 02:04:52.820430 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.267958 (* 1 = 0.267958 loss)
I0526 02:04:52.820441 15117 sgd_solver.cpp:294] Iteration 10990, lr = 0.02
I0526 02:04:58.622012 15117 solver.cpp:342] Iteration 11000, Testing net (#0)
I0526 02:05:11.800391 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.771
I0526 02:05:11.800629 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.724963 (* 1 = 0.724963 loss)
I0526 02:05:12.413435 15117 solver.cpp:233] Iteration 11000, loss = 0.182513
I0526 02:05:12.413511 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.182513 (* 1 = 0.182513 loss)
I0526 02:05:12.413524 15117 sgd_solver.cpp:294] Iteration 11000, lr = 0.02
I0526 02:05:18.808487 15117 solver.cpp:233] Iteration 11010, loss = 0.278525
I0526 02:05:18.808579 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.278525 (* 1 = 0.278525 loss)
I0526 02:05:18.808595 15117 sgd_solver.cpp:294] Iteration 11010, lr = 0.02
I0526 02:05:25.200474 15117 solver.cpp:233] Iteration 11020, loss = 0.267237
I0526 02:05:25.200558 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.267237 (* 1 = 0.267237 loss)
I0526 02:05:25.200572 15117 sgd_solver.cpp:294] Iteration 11020, lr = 0.02
I0526 02:05:31.606343 15117 solver.cpp:233] Iteration 11030, loss = 0.128263
I0526 02:05:31.606420 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.128263 (* 1 = 0.128263 loss)
I0526 02:05:31.606431 15117 sgd_solver.cpp:294] Iteration 11030, lr = 0.02
I0526 02:05:38.025192 15117 solver.cpp:233] Iteration 11040, loss = 0.206561
I0526 02:05:38.025261 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.206561 (* 1 = 0.206561 loss)
I0526 02:05:38.025274 15117 sgd_solver.cpp:294] Iteration 11040, lr = 0.02
I0526 02:05:44.426012 15117 solver.cpp:233] Iteration 11050, loss = 0.185293
I0526 02:05:44.426247 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.185293 (* 1 = 0.185293 loss)
I0526 02:05:44.426278 15117 sgd_solver.cpp:294] Iteration 11050, lr = 0.02
I0526 02:05:50.820399 15117 solver.cpp:233] Iteration 11060, loss = 0.271423
I0526 02:05:50.820472 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.271423 (* 1 = 0.271423 loss)
I0526 02:05:50.820484 15117 sgd_solver.cpp:294] Iteration 11060, lr = 0.02
I0526 02:05:57.218083 15117 solver.cpp:233] Iteration 11070, loss = 0.184138
I0526 02:05:57.218152 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.184138 (* 1 = 0.184138 loss)
I0526 02:05:57.218163 15117 sgd_solver.cpp:294] Iteration 11070, lr = 0.02
I0526 02:06:03.615468 15117 solver.cpp:233] Iteration 11080, loss = 0.472797
I0526 02:06:03.615537 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.472797 (* 1 = 0.472797 loss)
I0526 02:06:03.615550 15117 sgd_solver.cpp:294] Iteration 11080, lr = 0.02
I0526 02:06:10.002429 15117 solver.cpp:233] Iteration 11090, loss = 0.201995
I0526 02:06:10.002511 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.201995 (* 1 = 0.201995 loss)
I0526 02:06:10.002526 15117 sgd_solver.cpp:294] Iteration 11090, lr = 0.02
I0526 02:06:15.796880 15117 solver.cpp:342] Iteration 11100, Testing net (#0)
I0526 02:06:28.893234 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7323
I0526 02:06:28.893308 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.989346 (* 1 = 0.989346 loss)
I0526 02:06:29.502476 15117 solver.cpp:233] Iteration 11100, loss = 0.120447
I0526 02:06:29.502563 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.120447 (* 1 = 0.120447 loss)
I0526 02:06:29.502579 15117 sgd_solver.cpp:294] Iteration 11100, lr = 0.02
I0526 02:06:35.917657 15117 solver.cpp:233] Iteration 11110, loss = 0.273499
I0526 02:06:35.917740 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.273499 (* 1 = 0.273499 loss)
I0526 02:06:35.917755 15117 sgd_solver.cpp:294] Iteration 11110, lr = 0.02
I0526 02:06:42.349483 15117 solver.cpp:233] Iteration 11120, loss = 0.220693
I0526 02:06:42.349563 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.220693 (* 1 = 0.220693 loss)
I0526 02:06:42.349578 15117 sgd_solver.cpp:294] Iteration 11120, lr = 0.02
I0526 02:06:48.751540 15117 solver.cpp:233] Iteration 11130, loss = 0.2655
I0526 02:06:48.751854 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.2655 (* 1 = 0.2655 loss)
I0526 02:06:48.751894 15117 sgd_solver.cpp:294] Iteration 11130, lr = 0.02
I0526 02:06:55.152734 15117 solver.cpp:233] Iteration 11140, loss = 0.173752
I0526 02:06:55.152842 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.173752 (* 1 = 0.173752 loss)
I0526 02:06:55.152856 15117 sgd_solver.cpp:294] Iteration 11140, lr = 0.02
I0526 02:07:01.580585 15117 solver.cpp:233] Iteration 11150, loss = 0.232328
I0526 02:07:01.580670 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.232328 (* 1 = 0.232328 loss)
I0526 02:07:01.580684 15117 sgd_solver.cpp:294] Iteration 11150, lr = 0.02
I0526 02:07:07.990205 15117 solver.cpp:233] Iteration 11160, loss = 0.244139
I0526 02:07:07.990324 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.244139 (* 1 = 0.244139 loss)
I0526 02:07:07.990340 15117 sgd_solver.cpp:294] Iteration 11160, lr = 0.02
I0526 02:07:14.419560 15117 solver.cpp:233] Iteration 11170, loss = 0.220512
I0526 02:07:14.419631 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.220512 (* 1 = 0.220512 loss)
I0526 02:07:14.419644 15117 sgd_solver.cpp:294] Iteration 11170, lr = 0.02
I0526 02:07:20.825983 15117 solver.cpp:233] Iteration 11180, loss = 0.171237
I0526 02:07:20.826234 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.171237 (* 1 = 0.171237 loss)
I0526 02:07:20.826263 15117 sgd_solver.cpp:294] Iteration 11180, lr = 0.02
I0526 02:07:27.218227 15117 solver.cpp:233] Iteration 11190, loss = 0.158075
I0526 02:07:27.218364 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.158075 (* 1 = 0.158075 loss)
I0526 02:07:27.218389 15117 sgd_solver.cpp:294] Iteration 11190, lr = 0.02
I0526 02:07:33.004530 15117 solver.cpp:342] Iteration 11200, Testing net (#0)
I0526 02:07:46.128494 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8227
I0526 02:07:46.128566 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.582319 (* 1 = 0.582319 loss)
I0526 02:07:46.731748 15117 solver.cpp:233] Iteration 11200, loss = 0.289506
I0526 02:07:46.731839 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.289506 (* 1 = 0.289506 loss)
I0526 02:07:46.731853 15117 sgd_solver.cpp:294] Iteration 11200, lr = 0.02
I0526 02:07:53.165321 15117 solver.cpp:233] Iteration 11210, loss = 0.24574
I0526 02:07:53.165565 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.24574 (* 1 = 0.24574 loss)
I0526 02:07:53.165593 15117 sgd_solver.cpp:294] Iteration 11210, lr = 0.02
I0526 02:07:59.581532 15117 solver.cpp:233] Iteration 11220, loss = 0.21366
I0526 02:07:59.581606 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.21366 (* 1 = 0.21366 loss)
I0526 02:07:59.581619 15117 sgd_solver.cpp:294] Iteration 11220, lr = 0.02
I0526 02:08:05.993470 15117 solver.cpp:233] Iteration 11230, loss = 0.224779
I0526 02:08:05.993542 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.224779 (* 1 = 0.224779 loss)
I0526 02:08:05.993554 15117 sgd_solver.cpp:294] Iteration 11230, lr = 0.02
I0526 02:08:12.408504 15117 solver.cpp:233] Iteration 11240, loss = 0.185664
I0526 02:08:12.408574 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.185664 (* 1 = 0.185664 loss)
I0526 02:08:12.408586 15117 sgd_solver.cpp:294] Iteration 11240, lr = 0.02
I0526 02:08:18.806216 15117 solver.cpp:233] Iteration 11250, loss = 0.249978
I0526 02:08:18.806288 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.249978 (* 1 = 0.249978 loss)
I0526 02:08:18.806298 15117 sgd_solver.cpp:294] Iteration 11250, lr = 0.02
I0526 02:08:25.180307 15117 solver.cpp:233] Iteration 11260, loss = 0.182935
I0526 02:08:25.180583 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.182935 (* 1 = 0.182935 loss)
I0526 02:08:25.180616 15117 sgd_solver.cpp:294] Iteration 11260, lr = 0.02
I0526 02:08:31.579234 15117 solver.cpp:233] Iteration 11270, loss = 0.151934
I0526 02:08:31.579303 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.151934 (* 1 = 0.151934 loss)
I0526 02:08:31.579324 15117 sgd_solver.cpp:294] Iteration 11270, lr = 0.02
I0526 02:08:37.972208 15117 solver.cpp:233] Iteration 11280, loss = 0.18553
I0526 02:08:37.972280 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.18553 (* 1 = 0.18553 loss)
I0526 02:08:37.972293 15117 sgd_solver.cpp:294] Iteration 11280, lr = 0.02
I0526 02:08:44.379788 15117 solver.cpp:233] Iteration 11290, loss = 0.20209
I0526 02:08:44.379868 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.20209 (* 1 = 0.20209 loss)
I0526 02:08:44.379883 15117 sgd_solver.cpp:294] Iteration 11290, lr = 0.02
I0526 02:08:50.170593 15117 solver.cpp:342] Iteration 11300, Testing net (#0)
I0526 02:09:03.323688 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7987
I0526 02:09:03.323912 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.683021 (* 1 = 0.683021 loss)
I0526 02:09:03.931785 15117 solver.cpp:233] Iteration 11300, loss = 0.319754
I0526 02:09:03.931855 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.319754 (* 1 = 0.319754 loss)
I0526 02:09:03.931870 15117 sgd_solver.cpp:294] Iteration 11300, lr = 0.02
I0526 02:09:10.334728 15117 solver.cpp:233] Iteration 11310, loss = 0.224499
I0526 02:09:10.334825 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.224499 (* 1 = 0.224499 loss)
I0526 02:09:10.334841 15117 sgd_solver.cpp:294] Iteration 11310, lr = 0.02
I0526 02:09:16.736702 15117 solver.cpp:233] Iteration 11320, loss = 0.15922
I0526 02:09:16.736775 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.15922 (* 1 = 0.15922 loss)
I0526 02:09:16.736788 15117 sgd_solver.cpp:294] Iteration 11320, lr = 0.02
I0526 02:09:23.131783 15117 solver.cpp:233] Iteration 11330, loss = 0.180805
I0526 02:09:23.131855 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.180805 (* 1 = 0.180805 loss)
I0526 02:09:23.131866 15117 sgd_solver.cpp:294] Iteration 11330, lr = 0.02
I0526 02:09:29.528906 15117 solver.cpp:233] Iteration 11340, loss = 0.19558
I0526 02:09:29.528980 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.19558 (* 1 = 0.19558 loss)
I0526 02:09:29.528993 15117 sgd_solver.cpp:294] Iteration 11340, lr = 0.02
I0526 02:09:35.928017 15117 solver.cpp:233] Iteration 11350, loss = 0.0968156
I0526 02:09:35.928236 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0968156 (* 1 = 0.0968156 loss)
I0526 02:09:35.928264 15117 sgd_solver.cpp:294] Iteration 11350, lr = 0.02
I0526 02:09:42.327302 15117 solver.cpp:233] Iteration 11360, loss = 0.216345
I0526 02:09:42.327380 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.216345 (* 1 = 0.216345 loss)
I0526 02:09:42.327394 15117 sgd_solver.cpp:294] Iteration 11360, lr = 0.02
I0526 02:09:48.740699 15117 solver.cpp:233] Iteration 11370, loss = 0.182019
I0526 02:09:48.740767 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.182019 (* 1 = 0.182019 loss)
I0526 02:09:48.740778 15117 sgd_solver.cpp:294] Iteration 11370, lr = 0.02
I0526 02:09:55.159363 15117 solver.cpp:233] Iteration 11380, loss = 0.278263
I0526 02:09:55.159452 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.278263 (* 1 = 0.278263 loss)
I0526 02:09:55.159468 15117 sgd_solver.cpp:294] Iteration 11380, lr = 0.02
I0526 02:10:01.570709 15117 solver.cpp:233] Iteration 11390, loss = 0.252622
I0526 02:10:01.570785 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.252622 (* 1 = 0.252622 loss)
I0526 02:10:01.570801 15117 sgd_solver.cpp:294] Iteration 11390, lr = 0.02
I0526 02:10:07.366417 15117 solver.cpp:342] Iteration 11400, Testing net (#0)
I0526 02:10:20.563746 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7143
I0526 02:10:20.563818 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.07077 (* 1 = 1.07077 loss)
I0526 02:10:21.172565 15117 solver.cpp:233] Iteration 11400, loss = 0.251361
I0526 02:10:21.172636 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.251361 (* 1 = 0.251361 loss)
I0526 02:10:21.172660 15117 sgd_solver.cpp:294] Iteration 11400, lr = 0.02
I0526 02:10:27.588490 15117 solver.cpp:233] Iteration 11410, loss = 0.393713
I0526 02:10:27.588562 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.393713 (* 1 = 0.393713 loss)
I0526 02:10:27.588574 15117 sgd_solver.cpp:294] Iteration 11410, lr = 0.02
I0526 02:10:33.979624 15117 solver.cpp:233] Iteration 11420, loss = 0.247001
I0526 02:10:33.979693 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.247001 (* 1 = 0.247001 loss)
I0526 02:10:33.979704 15117 sgd_solver.cpp:294] Iteration 11420, lr = 0.02
I0526 02:10:40.389817 15117 solver.cpp:233] Iteration 11430, loss = 0.251848
I0526 02:10:40.390000 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.251848 (* 1 = 0.251848 loss)
I0526 02:10:40.390015 15117 sgd_solver.cpp:294] Iteration 11430, lr = 0.02
I0526 02:10:46.783025 15117 solver.cpp:233] Iteration 11440, loss = 0.211001
I0526 02:10:46.783097 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.211001 (* 1 = 0.211001 loss)
I0526 02:10:46.783108 15117 sgd_solver.cpp:294] Iteration 11440, lr = 0.02
I0526 02:10:53.179819 15117 solver.cpp:233] Iteration 11450, loss = 0.322413
I0526 02:10:53.179888 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.322413 (* 1 = 0.322413 loss)
I0526 02:10:53.179899 15117 sgd_solver.cpp:294] Iteration 11450, lr = 0.02
I0526 02:10:59.584583 15117 solver.cpp:233] Iteration 11460, loss = 0.272217
I0526 02:10:59.584663 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.272217 (* 1 = 0.272217 loss)
I0526 02:10:59.584676 15117 sgd_solver.cpp:294] Iteration 11460, lr = 0.02
I0526 02:11:05.997653 15117 solver.cpp:233] Iteration 11470, loss = 0.233529
I0526 02:11:05.997723 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.233529 (* 1 = 0.233529 loss)
I0526 02:11:05.997735 15117 sgd_solver.cpp:294] Iteration 11470, lr = 0.02
I0526 02:11:12.405797 15117 solver.cpp:233] Iteration 11480, loss = 0.220087
I0526 02:11:12.406043 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.220087 (* 1 = 0.220087 loss)
I0526 02:11:12.406071 15117 sgd_solver.cpp:294] Iteration 11480, lr = 0.02
I0526 02:11:18.778774 15117 solver.cpp:233] Iteration 11490, loss = 0.192389
I0526 02:11:18.778843 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.192389 (* 1 = 0.192389 loss)
I0526 02:11:18.778854 15117 sgd_solver.cpp:294] Iteration 11490, lr = 0.02
I0526 02:11:24.582963 15117 solver.cpp:342] Iteration 11500, Testing net (#0)
I0526 02:11:37.810942 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8217
I0526 02:11:37.811008 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.546144 (* 1 = 0.546144 loss)
I0526 02:11:38.420107 15117 solver.cpp:233] Iteration 11500, loss = 0.18405
I0526 02:11:38.420176 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.18405 (* 1 = 0.18405 loss)
I0526 02:11:38.420188 15117 sgd_solver.cpp:294] Iteration 11500, lr = 0.02
I0526 02:11:44.796753 15117 solver.cpp:233] Iteration 11510, loss = 0.174676
I0526 02:11:44.796996 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.174676 (* 1 = 0.174676 loss)
I0526 02:11:44.797026 15117 sgd_solver.cpp:294] Iteration 11510, lr = 0.02
I0526 02:11:51.219420 15117 solver.cpp:233] Iteration 11520, loss = 0.146542
I0526 02:11:51.219487 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.146542 (* 1 = 0.146542 loss)
I0526 02:11:51.219498 15117 sgd_solver.cpp:294] Iteration 11520, lr = 0.02
I0526 02:11:57.614001 15117 solver.cpp:233] Iteration 11530, loss = 0.166409
I0526 02:11:57.614069 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.166409 (* 1 = 0.166409 loss)
I0526 02:11:57.614080 15117 sgd_solver.cpp:294] Iteration 11530, lr = 0.02
I0526 02:12:04.023618 15117 solver.cpp:233] Iteration 11540, loss = 0.333702
I0526 02:12:04.023687 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.333702 (* 1 = 0.333702 loss)
I0526 02:12:04.023699 15117 sgd_solver.cpp:294] Iteration 11540, lr = 0.02
I0526 02:12:10.409862 15117 solver.cpp:233] Iteration 11550, loss = 0.273365
I0526 02:12:10.409941 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.273365 (* 1 = 0.273365 loss)
I0526 02:12:10.409953 15117 sgd_solver.cpp:294] Iteration 11550, lr = 0.02
I0526 02:12:16.804589 15117 solver.cpp:233] Iteration 11560, loss = 0.20173
I0526 02:12:16.804898 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.20173 (* 1 = 0.20173 loss)
I0526 02:12:16.804926 15117 sgd_solver.cpp:294] Iteration 11560, lr = 0.02
I0526 02:12:23.196030 15117 solver.cpp:233] Iteration 11570, loss = 0.252414
I0526 02:12:23.196102 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.252414 (* 1 = 0.252414 loss)
I0526 02:12:23.196115 15117 sgd_solver.cpp:294] Iteration 11570, lr = 0.02
I0526 02:12:29.586168 15117 solver.cpp:233] Iteration 11580, loss = 0.261356
I0526 02:12:29.586237 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.261356 (* 1 = 0.261356 loss)
I0526 02:12:29.586248 15117 sgd_solver.cpp:294] Iteration 11580, lr = 0.02
I0526 02:12:35.988488 15117 solver.cpp:233] Iteration 11590, loss = 0.249258
I0526 02:12:35.988561 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.249258 (* 1 = 0.249258 loss)
I0526 02:12:35.988574 15117 sgd_solver.cpp:294] Iteration 11590, lr = 0.02
I0526 02:12:41.789563 15117 solver.cpp:342] Iteration 11600, Testing net (#0)
I0526 02:12:54.936570 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8328
I0526 02:12:54.936736 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.550958 (* 1 = 0.550958 loss)
I0526 02:12:55.541206 15117 solver.cpp:233] Iteration 11600, loss = 0.197122
I0526 02:12:55.541280 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.197122 (* 1 = 0.197122 loss)
I0526 02:12:55.541293 15117 sgd_solver.cpp:294] Iteration 11600, lr = 0.02
I0526 02:13:01.933027 15117 solver.cpp:233] Iteration 11610, loss = 0.191133
I0526 02:13:01.933096 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.191133 (* 1 = 0.191133 loss)
I0526 02:13:01.933109 15117 sgd_solver.cpp:294] Iteration 11610, lr = 0.02
I0526 02:13:08.335001 15117 solver.cpp:233] Iteration 11620, loss = 0.203429
I0526 02:13:08.335070 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.203429 (* 1 = 0.203429 loss)
I0526 02:13:08.335083 15117 sgd_solver.cpp:294] Iteration 11620, lr = 0.02
I0526 02:13:14.718782 15117 solver.cpp:233] Iteration 11630, loss = 0.192304
I0526 02:13:14.718858 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.192304 (* 1 = 0.192304 loss)
I0526 02:13:14.718870 15117 sgd_solver.cpp:294] Iteration 11630, lr = 0.02
I0526 02:13:21.111475 15117 solver.cpp:233] Iteration 11640, loss = 0.235344
I0526 02:13:21.111543 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.235344 (* 1 = 0.235344 loss)
I0526 02:13:21.111557 15117 sgd_solver.cpp:294] Iteration 11640, lr = 0.02
I0526 02:13:27.517881 15117 solver.cpp:233] Iteration 11650, loss = 0.165727
I0526 02:13:27.518115 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.165727 (* 1 = 0.165727 loss)
I0526 02:13:27.518136 15117 sgd_solver.cpp:294] Iteration 11650, lr = 0.02
I0526 02:13:33.917873 15117 solver.cpp:233] Iteration 11660, loss = 0.269503
I0526 02:13:33.917943 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.269503 (* 1 = 0.269503 loss)
I0526 02:13:33.917954 15117 sgd_solver.cpp:294] Iteration 11660, lr = 0.02
I0526 02:13:40.309604 15117 solver.cpp:233] Iteration 11670, loss = 0.18667
I0526 02:13:40.309677 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.18667 (* 1 = 0.18667 loss)
I0526 02:13:40.309690 15117 sgd_solver.cpp:294] Iteration 11670, lr = 0.02
I0526 02:13:46.707303 15117 solver.cpp:233] Iteration 11680, loss = 0.176973
I0526 02:13:46.707370 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.176973 (* 1 = 0.176973 loss)
I0526 02:13:46.707381 15117 sgd_solver.cpp:294] Iteration 11680, lr = 0.02
I0526 02:13:53.097842 15117 solver.cpp:233] Iteration 11690, loss = 0.330849
I0526 02:13:53.097914 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.330849 (* 1 = 0.330849 loss)
I0526 02:13:53.097925 15117 sgd_solver.cpp:294] Iteration 11690, lr = 0.02
I0526 02:13:58.881532 15117 solver.cpp:342] Iteration 11700, Testing net (#0)
I0526 02:14:12.033793 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8006
I0526 02:14:12.033867 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.709543 (* 1 = 0.709543 loss)
I0526 02:14:12.637625 15117 solver.cpp:233] Iteration 11700, loss = 0.265963
I0526 02:14:12.637753 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.265963 (* 1 = 0.265963 loss)
I0526 02:14:12.637783 15117 sgd_solver.cpp:294] Iteration 11700, lr = 0.02
I0526 02:14:19.028180 15117 solver.cpp:233] Iteration 11710, loss = 0.129715
I0526 02:14:19.028254 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.129715 (* 1 = 0.129715 loss)
I0526 02:14:19.028267 15117 sgd_solver.cpp:294] Iteration 11710, lr = 0.02
I0526 02:14:25.427783 15117 solver.cpp:233] Iteration 11720, loss = 0.189412
I0526 02:14:25.427875 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.189412 (* 1 = 0.189412 loss)
I0526 02:14:25.427887 15117 sgd_solver.cpp:294] Iteration 11720, lr = 0.02
I0526 02:14:31.811740 15117 solver.cpp:233] Iteration 11730, loss = 0.256757
I0526 02:14:31.812693 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.256757 (* 1 = 0.256757 loss)
I0526 02:14:31.812713 15117 sgd_solver.cpp:294] Iteration 11730, lr = 0.02
I0526 02:14:38.246484 15117 solver.cpp:233] Iteration 11740, loss = 0.146533
I0526 02:14:38.246554 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.146533 (* 1 = 0.146533 loss)
I0526 02:14:38.246567 15117 sgd_solver.cpp:294] Iteration 11740, lr = 0.02
I0526 02:14:44.628134 15117 solver.cpp:233] Iteration 11750, loss = 0.180719
I0526 02:14:44.628206 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.180719 (* 1 = 0.180719 loss)
I0526 02:14:44.628218 15117 sgd_solver.cpp:294] Iteration 11750, lr = 0.02
I0526 02:14:51.012954 15117 solver.cpp:233] Iteration 11760, loss = 0.168339
I0526 02:14:51.013026 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.168339 (* 1 = 0.168339 loss)
I0526 02:14:51.013039 15117 sgd_solver.cpp:294] Iteration 11760, lr = 0.02
I0526 02:14:57.393496 15117 solver.cpp:233] Iteration 11770, loss = 0.152931
I0526 02:14:57.393565 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.152931 (* 1 = 0.152931 loss)
I0526 02:14:57.393578 15117 sgd_solver.cpp:294] Iteration 11770, lr = 0.02
I0526 02:15:03.758134 15117 solver.cpp:233] Iteration 11780, loss = 0.256531
I0526 02:15:03.758266 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.256531 (* 1 = 0.256531 loss)
I0526 02:15:03.758280 15117 sgd_solver.cpp:294] Iteration 11780, lr = 0.02
I0526 02:15:10.125402 15117 solver.cpp:233] Iteration 11790, loss = 0.251704
I0526 02:15:10.125466 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.251704 (* 1 = 0.251704 loss)
I0526 02:15:10.125478 15117 sgd_solver.cpp:294] Iteration 11790, lr = 0.02
I0526 02:15:15.889415 15117 solver.cpp:342] Iteration 11800, Testing net (#0)
I0526 02:15:28.885048 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7746
I0526 02:15:28.885113 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.77872 (* 1 = 0.77872 loss)
I0526 02:15:29.487673 15117 solver.cpp:233] Iteration 11800, loss = 0.241075
I0526 02:15:29.487733 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.241075 (* 1 = 0.241075 loss)
I0526 02:15:29.487746 15117 sgd_solver.cpp:294] Iteration 11800, lr = 0.02
I0526 02:15:35.838405 15117 solver.cpp:233] Iteration 11810, loss = 0.301137
I0526 02:15:35.838532 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.301137 (* 1 = 0.301137 loss)
I0526 02:15:35.838544 15117 sgd_solver.cpp:294] Iteration 11810, lr = 0.02
I0526 02:15:42.193681 15117 solver.cpp:233] Iteration 11820, loss = 0.191502
I0526 02:15:42.193745 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.191502 (* 1 = 0.191502 loss)
I0526 02:15:42.193755 15117 sgd_solver.cpp:294] Iteration 11820, lr = 0.02
I0526 02:15:48.563067 15117 solver.cpp:233] Iteration 11830, loss = 0.1619
I0526 02:15:48.563143 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.1619 (* 1 = 0.1619 loss)
I0526 02:15:48.563158 15117 sgd_solver.cpp:294] Iteration 11830, lr = 0.02
I0526 02:15:54.928596 15117 solver.cpp:233] Iteration 11840, loss = 0.133193
I0526 02:15:54.928691 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.133193 (* 1 = 0.133193 loss)
I0526 02:15:54.928716 15117 sgd_solver.cpp:294] Iteration 11840, lr = 0.02
I0526 02:16:01.285109 15117 solver.cpp:233] Iteration 11850, loss = 0.208941
I0526 02:16:01.285183 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.208941 (* 1 = 0.208941 loss)
I0526 02:16:01.285197 15117 sgd_solver.cpp:294] Iteration 11850, lr = 0.02
I0526 02:16:07.656350 15117 solver.cpp:233] Iteration 11860, loss = 0.289127
I0526 02:16:07.656661 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.289127 (* 1 = 0.289127 loss)
I0526 02:16:07.656688 15117 sgd_solver.cpp:294] Iteration 11860, lr = 0.02
I0526 02:16:14.033700 15117 solver.cpp:233] Iteration 11870, loss = 0.130443
I0526 02:16:14.033792 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.130443 (* 1 = 0.130443 loss)
I0526 02:16:14.033805 15117 sgd_solver.cpp:294] Iteration 11870, lr = 0.02
I0526 02:16:20.415802 15117 solver.cpp:233] Iteration 11880, loss = 0.232332
I0526 02:16:20.415887 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.232332 (* 1 = 0.232332 loss)
I0526 02:16:20.415904 15117 sgd_solver.cpp:294] Iteration 11880, lr = 0.02
I0526 02:16:26.777182 15117 solver.cpp:233] Iteration 11890, loss = 0.293131
I0526 02:16:26.777258 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.293131 (* 1 = 0.293131 loss)
I0526 02:16:26.777271 15117 sgd_solver.cpp:294] Iteration 11890, lr = 0.02
I0526 02:16:32.542496 15117 solver.cpp:342] Iteration 11900, Testing net (#0)
I0526 02:16:45.554253 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8263
I0526 02:16:45.554410 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.552925 (* 1 = 0.552925 loss)
I0526 02:16:46.156595 15117 solver.cpp:233] Iteration 11900, loss = 0.175572
I0526 02:16:46.156656 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.175572 (* 1 = 0.175572 loss)
I0526 02:16:46.156668 15117 sgd_solver.cpp:294] Iteration 11900, lr = 0.02
I0526 02:16:52.521121 15117 solver.cpp:233] Iteration 11910, loss = 0.260794
I0526 02:16:52.521201 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.260794 (* 1 = 0.260794 loss)
I0526 02:16:52.521214 15117 sgd_solver.cpp:294] Iteration 11910, lr = 0.02
I0526 02:16:58.891858 15117 solver.cpp:233] Iteration 11920, loss = 0.166766
I0526 02:16:58.892006 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.166766 (* 1 = 0.166766 loss)
I0526 02:16:58.892046 15117 sgd_solver.cpp:294] Iteration 11920, lr = 0.02
I0526 02:17:05.276250 15117 solver.cpp:233] Iteration 11930, loss = 0.272494
I0526 02:17:05.276350 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.272494 (* 1 = 0.272494 loss)
I0526 02:17:05.276378 15117 sgd_solver.cpp:294] Iteration 11930, lr = 0.02
I0526 02:17:11.643606 15117 solver.cpp:233] Iteration 11940, loss = 0.234768
I0526 02:17:11.643679 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.234768 (* 1 = 0.234768 loss)
I0526 02:17:11.643692 15117 sgd_solver.cpp:294] Iteration 11940, lr = 0.02
I0526 02:17:18.012143 15117 solver.cpp:233] Iteration 11950, loss = 0.224088
I0526 02:17:18.012298 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.224088 (* 1 = 0.224088 loss)
I0526 02:17:18.012311 15117 sgd_solver.cpp:294] Iteration 11950, lr = 0.02
I0526 02:17:24.389430 15117 solver.cpp:233] Iteration 11960, loss = 0.288319
I0526 02:17:24.389525 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.288319 (* 1 = 0.288319 loss)
I0526 02:17:24.389542 15117 sgd_solver.cpp:294] Iteration 11960, lr = 0.02
I0526 02:17:30.770743 15117 solver.cpp:233] Iteration 11970, loss = 0.321667
I0526 02:17:30.770829 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.321667 (* 1 = 0.321667 loss)
I0526 02:17:30.770862 15117 sgd_solver.cpp:294] Iteration 11970, lr = 0.02
I0526 02:17:37.147064 15117 solver.cpp:233] Iteration 11980, loss = 0.246915
I0526 02:17:37.147130 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.246915 (* 1 = 0.246915 loss)
I0526 02:17:37.147142 15117 sgd_solver.cpp:294] Iteration 11980, lr = 0.02
I0526 02:17:43.527129 15117 solver.cpp:233] Iteration 11990, loss = 0.185421
I0526 02:17:43.527220 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.185421 (* 1 = 0.185421 loss)
I0526 02:17:43.527235 15117 sgd_solver.cpp:294] Iteration 11990, lr = 0.02
I0526 02:17:49.307633 15117 solver.cpp:342] Iteration 12000, Testing net (#0)
I0526 02:18:02.370600 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7464
I0526 02:18:02.370707 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.03356 (* 1 = 1.03356 loss)
I0526 02:18:02.978783 15117 solver.cpp:233] Iteration 12000, loss = 0.269658
I0526 02:18:02.978844 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.269658 (* 1 = 0.269658 loss)
I0526 02:18:02.978857 15117 sgd_solver.cpp:294] Iteration 12000, lr = 0.02
I0526 02:18:09.387728 15117 solver.cpp:233] Iteration 12010, loss = 0.253111
I0526 02:18:09.387800 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.253111 (* 1 = 0.253111 loss)
I0526 02:18:09.387814 15117 sgd_solver.cpp:294] Iteration 12010, lr = 0.02
I0526 02:18:15.765511 15117 solver.cpp:233] Iteration 12020, loss = 0.236702
I0526 02:18:15.765583 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.236702 (* 1 = 0.236702 loss)
I0526 02:18:15.765595 15117 sgd_solver.cpp:294] Iteration 12020, lr = 0.02
I0526 02:18:22.168362 15117 solver.cpp:233] Iteration 12030, loss = 0.176747
I0526 02:18:22.168614 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.176747 (* 1 = 0.176747 loss)
I0526 02:18:22.168642 15117 sgd_solver.cpp:294] Iteration 12030, lr = 0.02
I0526 02:18:28.526681 15117 solver.cpp:233] Iteration 12040, loss = 0.117678
I0526 02:18:28.526748 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.117678 (* 1 = 0.117678 loss)
I0526 02:18:28.526760 15117 sgd_solver.cpp:294] Iteration 12040, lr = 0.02
I0526 02:18:34.908181 15117 solver.cpp:233] Iteration 12050, loss = 0.241914
I0526 02:18:34.908267 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.241914 (* 1 = 0.241914 loss)
I0526 02:18:34.908282 15117 sgd_solver.cpp:294] Iteration 12050, lr = 0.02
I0526 02:18:41.275068 15117 solver.cpp:233] Iteration 12060, loss = 0.222666
I0526 02:18:41.275151 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.222666 (* 1 = 0.222666 loss)
I0526 02:18:41.275166 15117 sgd_solver.cpp:294] Iteration 12060, lr = 0.02
I0526 02:18:47.663713 15117 solver.cpp:233] Iteration 12070, loss = 0.254194
I0526 02:18:47.663799 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.254194 (* 1 = 0.254194 loss)
I0526 02:18:47.663810 15117 sgd_solver.cpp:294] Iteration 12070, lr = 0.02
I0526 02:18:54.052829 15117 solver.cpp:233] Iteration 12080, loss = 0.314988
I0526 02:18:54.053015 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.314988 (* 1 = 0.314988 loss)
I0526 02:18:54.053031 15117 sgd_solver.cpp:294] Iteration 12080, lr = 0.02
I0526 02:19:00.440747 15117 solver.cpp:233] Iteration 12090, loss = 0.150849
I0526 02:19:00.440815 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.150849 (* 1 = 0.150849 loss)
I0526 02:19:00.440827 15117 sgd_solver.cpp:294] Iteration 12090, lr = 0.02
I0526 02:19:06.207567 15117 solver.cpp:342] Iteration 12100, Testing net (#0)
I0526 02:19:19.275739 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7321
I0526 02:19:19.275810 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.06478 (* 1 = 1.06478 loss)
I0526 02:19:19.877609 15117 solver.cpp:233] Iteration 12100, loss = 0.183466
I0526 02:19:19.877672 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.183466 (* 1 = 0.183466 loss)
I0526 02:19:19.877686 15117 sgd_solver.cpp:294] Iteration 12100, lr = 0.02
I0526 02:19:26.260476 15117 solver.cpp:233] Iteration 12110, loss = 0.235734
I0526 02:19:26.260691 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.235734 (* 1 = 0.235734 loss)
I0526 02:19:26.260706 15117 sgd_solver.cpp:294] Iteration 12110, lr = 0.02
I0526 02:19:32.639525 15117 solver.cpp:233] Iteration 12120, loss = 0.167479
I0526 02:19:32.639596 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.167479 (* 1 = 0.167479 loss)
I0526 02:19:32.639610 15117 sgd_solver.cpp:294] Iteration 12120, lr = 0.02
I0526 02:19:39.009485 15117 solver.cpp:233] Iteration 12130, loss = 0.137568
I0526 02:19:39.009552 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.137568 (* 1 = 0.137568 loss)
I0526 02:19:39.009564 15117 sgd_solver.cpp:294] Iteration 12130, lr = 0.02
I0526 02:19:45.380303 15117 solver.cpp:233] Iteration 12140, loss = 0.154935
I0526 02:19:45.380374 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.154935 (* 1 = 0.154935 loss)
I0526 02:19:45.380386 15117 sgd_solver.cpp:294] Iteration 12140, lr = 0.02
I0526 02:19:51.738876 15117 solver.cpp:233] Iteration 12150, loss = 0.203961
I0526 02:19:51.738940 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.203961 (* 1 = 0.203961 loss)
I0526 02:19:51.738951 15117 sgd_solver.cpp:294] Iteration 12150, lr = 0.02
I0526 02:19:58.109503 15117 solver.cpp:233] Iteration 12160, loss = 0.227393
I0526 02:19:58.109725 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.227393 (* 1 = 0.227393 loss)
I0526 02:19:58.109755 15117 sgd_solver.cpp:294] Iteration 12160, lr = 0.02
I0526 02:20:04.488178 15117 solver.cpp:233] Iteration 12170, loss = 0.18415
I0526 02:20:04.488247 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.18415 (* 1 = 0.18415 loss)
I0526 02:20:04.488260 15117 sgd_solver.cpp:294] Iteration 12170, lr = 0.02
I0526 02:20:10.859508 15117 solver.cpp:233] Iteration 12180, loss = 0.282613
I0526 02:20:10.859576 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.282613 (* 1 = 0.282613 loss)
I0526 02:20:10.859588 15117 sgd_solver.cpp:294] Iteration 12180, lr = 0.02
I0526 02:20:17.237905 15117 solver.cpp:233] Iteration 12190, loss = 0.1945
I0526 02:20:17.238018 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.1945 (* 1 = 0.1945 loss)
I0526 02:20:17.238034 15117 sgd_solver.cpp:294] Iteration 12190, lr = 0.02
I0526 02:20:22.993209 15117 solver.cpp:342] Iteration 12200, Testing net (#0)
I0526 02:20:36.012219 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.77
I0526 02:20:36.012361 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.849811 (* 1 = 0.849811 loss)
I0526 02:20:36.615624 15117 solver.cpp:233] Iteration 12200, loss = 0.225559
I0526 02:20:36.615696 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.225559 (* 1 = 0.225559 loss)
I0526 02:20:36.615711 15117 sgd_solver.cpp:294] Iteration 12200, lr = 0.02
I0526 02:20:42.985956 15117 solver.cpp:233] Iteration 12210, loss = 0.113806
I0526 02:20:42.986033 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.113806 (* 1 = 0.113806 loss)
I0526 02:20:42.986047 15117 sgd_solver.cpp:294] Iteration 12210, lr = 0.02
I0526 02:20:49.373869 15117 solver.cpp:233] Iteration 12220, loss = 0.245022
I0526 02:20:49.373965 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.245022 (* 1 = 0.245022 loss)
I0526 02:20:49.373975 15117 sgd_solver.cpp:294] Iteration 12220, lr = 0.02
I0526 02:20:55.763679 15117 solver.cpp:233] Iteration 12230, loss = 0.12561
I0526 02:20:55.763759 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.12561 (* 1 = 0.12561 loss)
I0526 02:20:55.763772 15117 sgd_solver.cpp:294] Iteration 12230, lr = 0.02
I0526 02:21:02.140300 15117 solver.cpp:233] Iteration 12240, loss = 0.19893
I0526 02:21:02.140379 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.19893 (* 1 = 0.19893 loss)
I0526 02:21:02.140394 15117 sgd_solver.cpp:294] Iteration 12240, lr = 0.02
I0526 02:21:08.515352 15117 solver.cpp:233] Iteration 12250, loss = 0.232539
I0526 02:21:08.515704 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.232539 (* 1 = 0.232539 loss)
I0526 02:21:08.515736 15117 sgd_solver.cpp:294] Iteration 12250, lr = 0.02
I0526 02:21:14.893236 15117 solver.cpp:233] Iteration 12260, loss = 0.1394
I0526 02:21:14.893381 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.1394 (* 1 = 0.1394 loss)
I0526 02:21:14.893399 15117 sgd_solver.cpp:294] Iteration 12260, lr = 0.02
I0526 02:21:21.282899 15117 solver.cpp:233] Iteration 12270, loss = 0.135662
I0526 02:21:21.282971 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.135662 (* 1 = 0.135662 loss)
I0526 02:21:21.282984 15117 sgd_solver.cpp:294] Iteration 12270, lr = 0.02
I0526 02:21:27.682401 15117 solver.cpp:233] Iteration 12280, loss = 0.208619
I0526 02:21:27.682473 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.208619 (* 1 = 0.208619 loss)
I0526 02:21:27.682484 15117 sgd_solver.cpp:294] Iteration 12280, lr = 0.02
I0526 02:21:34.086761 15117 solver.cpp:233] Iteration 12290, loss = 0.191712
I0526 02:21:34.086830 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.191712 (* 1 = 0.191712 loss)
I0526 02:21:34.086843 15117 sgd_solver.cpp:294] Iteration 12290, lr = 0.02
I0526 02:21:39.871897 15117 solver.cpp:342] Iteration 12300, Testing net (#0)
I0526 02:21:52.955041 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7627
I0526 02:21:52.955116 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.909383 (* 1 = 0.909383 loss)
I0526 02:21:53.563740 15117 solver.cpp:233] Iteration 12300, loss = 0.287859
I0526 02:21:53.563809 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.287859 (* 1 = 0.287859 loss)
I0526 02:21:53.563823 15117 sgd_solver.cpp:294] Iteration 12300, lr = 0.02
I0526 02:21:59.922432 15117 solver.cpp:233] Iteration 12310, loss = 0.15833
I0526 02:21:59.922499 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.15833 (* 1 = 0.15833 loss)
I0526 02:21:59.922511 15117 sgd_solver.cpp:294] Iteration 12310, lr = 0.02
I0526 02:22:06.309026 15117 solver.cpp:233] Iteration 12320, loss = 0.304725
I0526 02:22:06.309092 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.304725 (* 1 = 0.304725 loss)
I0526 02:22:06.309103 15117 sgd_solver.cpp:294] Iteration 12320, lr = 0.02
I0526 02:22:12.679208 15117 solver.cpp:233] Iteration 12330, loss = 0.201186
I0526 02:22:12.679431 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.201186 (* 1 = 0.201186 loss)
I0526 02:22:12.679461 15117 sgd_solver.cpp:294] Iteration 12330, lr = 0.02
I0526 02:22:19.062330 15117 solver.cpp:233] Iteration 12340, loss = 0.219724
I0526 02:22:19.062427 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.219724 (* 1 = 0.219724 loss)
I0526 02:22:19.062443 15117 sgd_solver.cpp:294] Iteration 12340, lr = 0.02
I0526 02:22:25.459290 15117 solver.cpp:233] Iteration 12350, loss = 0.335944
I0526 02:22:25.459363 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.335944 (* 1 = 0.335944 loss)
I0526 02:22:25.459375 15117 sgd_solver.cpp:294] Iteration 12350, lr = 0.02
I0526 02:22:31.829537 15117 solver.cpp:233] Iteration 12360, loss = 0.16351
I0526 02:22:31.829609 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.16351 (* 1 = 0.16351 loss)
I0526 02:22:31.829622 15117 sgd_solver.cpp:294] Iteration 12360, lr = 0.02
I0526 02:22:38.209435 15117 solver.cpp:233] Iteration 12370, loss = 0.162643
I0526 02:22:38.209507 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.162643 (* 1 = 0.162643 loss)
I0526 02:22:38.209529 15117 sgd_solver.cpp:294] Iteration 12370, lr = 0.02
I0526 02:22:44.596488 15117 solver.cpp:233] Iteration 12380, loss = 0.229839
I0526 02:22:44.596788 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.229839 (* 1 = 0.229839 loss)
I0526 02:22:44.596814 15117 sgd_solver.cpp:294] Iteration 12380, lr = 0.02
I0526 02:22:50.984879 15117 solver.cpp:233] Iteration 12390, loss = 0.217182
I0526 02:22:50.984951 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.217182 (* 1 = 0.217182 loss)
I0526 02:22:50.984962 15117 sgd_solver.cpp:294] Iteration 12390, lr = 0.02
I0526 02:22:56.784854 15117 solver.cpp:342] Iteration 12400, Testing net (#0)
I0526 02:23:09.930502 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7745
I0526 02:23:09.930570 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.968569 (* 1 = 0.968569 loss)
I0526 02:23:10.532374 15117 solver.cpp:233] Iteration 12400, loss = 0.171304
I0526 02:23:10.532450 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.171304 (* 1 = 0.171304 loss)
I0526 02:23:10.532464 15117 sgd_solver.cpp:294] Iteration 12400, lr = 0.02
I0526 02:23:16.907760 15117 solver.cpp:233] Iteration 12410, loss = 0.163411
I0526 02:23:16.907990 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.163411 (* 1 = 0.163411 loss)
I0526 02:23:16.908015 15117 sgd_solver.cpp:294] Iteration 12410, lr = 0.02
I0526 02:23:23.294548 15117 solver.cpp:233] Iteration 12420, loss = 0.222273
I0526 02:23:23.294620 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.222273 (* 1 = 0.222273 loss)
I0526 02:23:23.294632 15117 sgd_solver.cpp:294] Iteration 12420, lr = 0.02
I0526 02:23:29.681359 15117 solver.cpp:233] Iteration 12430, loss = 0.211941
I0526 02:23:29.681424 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.211941 (* 1 = 0.211941 loss)
I0526 02:23:29.681435 15117 sgd_solver.cpp:294] Iteration 12430, lr = 0.02
I0526 02:23:36.062280 15117 solver.cpp:233] Iteration 12440, loss = 0.205092
I0526 02:23:36.062348 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.205091 (* 1 = 0.205091 loss)
I0526 02:23:36.062369 15117 sgd_solver.cpp:294] Iteration 12440, lr = 0.02
I0526 02:23:42.443238 15117 solver.cpp:233] Iteration 12450, loss = 0.231649
I0526 02:23:42.443306 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.231649 (* 1 = 0.231649 loss)
I0526 02:23:42.443318 15117 sgd_solver.cpp:294] Iteration 12450, lr = 0.02
I0526 02:23:48.816117 15117 solver.cpp:233] Iteration 12460, loss = 0.189585
I0526 02:23:48.816364 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.189585 (* 1 = 0.189585 loss)
I0526 02:23:48.816393 15117 sgd_solver.cpp:294] Iteration 12460, lr = 0.02
I0526 02:23:55.200551 15117 solver.cpp:233] Iteration 12470, loss = 0.205341
I0526 02:23:55.200614 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.205341 (* 1 = 0.205341 loss)
I0526 02:23:55.200625 15117 sgd_solver.cpp:294] Iteration 12470, lr = 0.02
I0526 02:24:01.585010 15117 solver.cpp:233] Iteration 12480, loss = 0.268128
I0526 02:24:01.585104 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.268128 (* 1 = 0.268128 loss)
I0526 02:24:01.585124 15117 sgd_solver.cpp:294] Iteration 12480, lr = 0.02
I0526 02:24:07.949185 15117 solver.cpp:233] Iteration 12490, loss = 0.192317
I0526 02:24:07.949251 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.192317 (* 1 = 0.192317 loss)
I0526 02:24:07.949264 15117 sgd_solver.cpp:294] Iteration 12490, lr = 0.02
I0526 02:24:13.717767 15117 solver.cpp:342] Iteration 12500, Testing net (#0)
I0526 02:24:26.769642 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7493
I0526 02:24:26.769884 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.905458 (* 1 = 0.905458 loss)
I0526 02:24:27.372571 15117 solver.cpp:233] Iteration 12500, loss = 0.179005
I0526 02:24:27.372644 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.179005 (* 1 = 0.179005 loss)
I0526 02:24:27.372669 15117 sgd_solver.cpp:294] Iteration 12500, lr = 0.02
I0526 02:24:33.754715 15117 solver.cpp:233] Iteration 12510, loss = 0.248165
I0526 02:24:33.754801 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.248165 (* 1 = 0.248165 loss)
I0526 02:24:33.754829 15117 sgd_solver.cpp:294] Iteration 12510, lr = 0.02
I0526 02:24:40.114073 15117 solver.cpp:233] Iteration 12520, loss = 0.203382
I0526 02:24:40.114212 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.203382 (* 1 = 0.203382 loss)
I0526 02:24:40.114226 15117 sgd_solver.cpp:294] Iteration 12520, lr = 0.02
I0526 02:24:46.480940 15117 solver.cpp:233] Iteration 12530, loss = 0.169798
I0526 02:24:46.481011 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.169798 (* 1 = 0.169798 loss)
I0526 02:24:46.481024 15117 sgd_solver.cpp:294] Iteration 12530, lr = 0.02
I0526 02:24:52.856345 15117 solver.cpp:233] Iteration 12540, loss = 0.20337
I0526 02:24:52.856418 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.20337 (* 1 = 0.20337 loss)
I0526 02:24:52.856431 15117 sgd_solver.cpp:294] Iteration 12540, lr = 0.02
I0526 02:24:59.219669 15117 solver.cpp:233] Iteration 12550, loss = 0.203242
I0526 02:24:59.219889 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.203242 (* 1 = 0.203242 loss)
I0526 02:24:59.219907 15117 sgd_solver.cpp:294] Iteration 12550, lr = 0.02
I0526 02:25:05.591863 15117 solver.cpp:233] Iteration 12560, loss = 0.119529
I0526 02:25:05.591936 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.119529 (* 1 = 0.119529 loss)
I0526 02:25:05.591949 15117 sgd_solver.cpp:294] Iteration 12560, lr = 0.02
I0526 02:25:11.970158 15117 solver.cpp:233] Iteration 12570, loss = 0.207732
I0526 02:25:11.970227 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.207732 (* 1 = 0.207732 loss)
I0526 02:25:11.970238 15117 sgd_solver.cpp:294] Iteration 12570, lr = 0.02
I0526 02:25:18.360338 15117 solver.cpp:233] Iteration 12580, loss = 0.200018
I0526 02:25:18.360409 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.200018 (* 1 = 0.200018 loss)
I0526 02:25:18.360421 15117 sgd_solver.cpp:294] Iteration 12580, lr = 0.02
I0526 02:25:24.738126 15117 solver.cpp:233] Iteration 12590, loss = 0.132555
I0526 02:25:24.738193 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.132555 (* 1 = 0.132555 loss)
I0526 02:25:24.738204 15117 sgd_solver.cpp:294] Iteration 12590, lr = 0.02
I0526 02:25:30.503487 15117 solver.cpp:342] Iteration 12600, Testing net (#0)
I0526 02:25:43.574029 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7866
I0526 02:25:43.574092 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.740364 (* 1 = 0.740364 loss)
I0526 02:25:44.176807 15117 solver.cpp:233] Iteration 12600, loss = 0.145872
I0526 02:25:44.176884 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.145872 (* 1 = 0.145872 loss)
I0526 02:25:44.176898 15117 sgd_solver.cpp:294] Iteration 12600, lr = 0.02
I0526 02:25:50.549226 15117 solver.cpp:233] Iteration 12610, loss = 0.207557
I0526 02:25:50.549299 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.207557 (* 1 = 0.207557 loss)
I0526 02:25:50.549312 15117 sgd_solver.cpp:294] Iteration 12610, lr = 0.02
I0526 02:25:56.914831 15117 solver.cpp:233] Iteration 12620, loss = 0.229887
I0526 02:25:56.914901 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.229887 (* 1 = 0.229887 loss)
I0526 02:25:56.914913 15117 sgd_solver.cpp:294] Iteration 12620, lr = 0.02
I0526 02:26:03.294047 15117 solver.cpp:233] Iteration 12630, loss = 0.192571
I0526 02:26:03.298504 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.192571 (* 1 = 0.192571 loss)
I0526 02:26:03.298527 15117 sgd_solver.cpp:294] Iteration 12630, lr = 0.02
I0526 02:26:09.679514 15117 solver.cpp:233] Iteration 12640, loss = 0.231897
I0526 02:26:09.679582 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.231897 (* 1 = 0.231897 loss)
I0526 02:26:09.679602 15117 sgd_solver.cpp:294] Iteration 12640, lr = 0.02
I0526 02:26:16.066227 15117 solver.cpp:233] Iteration 12650, loss = 0.186111
I0526 02:26:16.066325 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.186111 (* 1 = 0.186111 loss)
I0526 02:26:16.066345 15117 sgd_solver.cpp:294] Iteration 12650, lr = 0.02
I0526 02:26:22.441696 15117 solver.cpp:233] Iteration 12660, loss = 0.346667
I0526 02:26:22.441771 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.346667 (* 1 = 0.346667 loss)
I0526 02:26:22.441783 15117 sgd_solver.cpp:294] Iteration 12660, lr = 0.02
I0526 02:26:28.824580 15117 solver.cpp:233] Iteration 12670, loss = 0.186711
I0526 02:26:28.824650 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.186711 (* 1 = 0.186711 loss)
I0526 02:26:28.824662 15117 sgd_solver.cpp:294] Iteration 12670, lr = 0.02
I0526 02:26:35.215386 15117 solver.cpp:233] Iteration 12680, loss = 0.237571
I0526 02:26:35.215605 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.237571 (* 1 = 0.237571 loss)
I0526 02:26:35.215620 15117 sgd_solver.cpp:294] Iteration 12680, lr = 0.02
I0526 02:26:41.608434 15117 solver.cpp:233] Iteration 12690, loss = 0.316073
I0526 02:26:41.608501 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.316073 (* 1 = 0.316073 loss)
I0526 02:26:41.608513 15117 sgd_solver.cpp:294] Iteration 12690, lr = 0.02
I0526 02:26:47.389634 15117 solver.cpp:342] Iteration 12700, Testing net (#0)
I0526 02:27:00.430371 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8054
I0526 02:27:00.430439 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.653228 (* 1 = 0.653228 loss)
I0526 02:27:01.031999 15117 solver.cpp:233] Iteration 12700, loss = 0.32229
I0526 02:27:01.032086 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.32229 (* 1 = 0.32229 loss)
I0526 02:27:01.032106 15117 sgd_solver.cpp:294] Iteration 12700, lr = 0.02
I0526 02:27:07.430696 15117 solver.cpp:233] Iteration 12710, loss = 0.214308
I0526 02:27:07.430837 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.214308 (* 1 = 0.214308 loss)
I0526 02:27:07.430850 15117 sgd_solver.cpp:294] Iteration 12710, lr = 0.02
I0526 02:27:13.818016 15117 solver.cpp:233] Iteration 12720, loss = 0.157784
I0526 02:27:13.818084 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.157784 (* 1 = 0.157784 loss)
I0526 02:27:13.818096 15117 sgd_solver.cpp:294] Iteration 12720, lr = 0.02
I0526 02:27:20.194286 15117 solver.cpp:233] Iteration 12730, loss = 0.161302
I0526 02:27:20.194365 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.161301 (* 1 = 0.161301 loss)
I0526 02:27:20.194377 15117 sgd_solver.cpp:294] Iteration 12730, lr = 0.02
I0526 02:27:26.589911 15117 solver.cpp:233] Iteration 12740, loss = 0.267656
I0526 02:27:26.589977 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.267656 (* 1 = 0.267656 loss)
I0526 02:27:26.589989 15117 sgd_solver.cpp:294] Iteration 12740, lr = 0.02
I0526 02:27:32.983099 15117 solver.cpp:233] Iteration 12750, loss = 0.278751
I0526 02:27:32.983166 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.27875 (* 1 = 0.27875 loss)
I0526 02:27:32.983177 15117 sgd_solver.cpp:294] Iteration 12750, lr = 0.02
I0526 02:27:39.368850 15117 solver.cpp:233] Iteration 12760, loss = 0.288309
I0526 02:27:39.368979 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.288309 (* 1 = 0.288309 loss)
I0526 02:27:39.368991 15117 sgd_solver.cpp:294] Iteration 12760, lr = 0.02
I0526 02:27:45.746459 15117 solver.cpp:233] Iteration 12770, loss = 0.224184
I0526 02:27:45.746531 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.224184 (* 1 = 0.224184 loss)
I0526 02:27:45.746544 15117 sgd_solver.cpp:294] Iteration 12770, lr = 0.02
I0526 02:27:52.128836 15117 solver.cpp:233] Iteration 12780, loss = 0.188769
I0526 02:27:52.128912 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.188769 (* 1 = 0.188769 loss)
I0526 02:27:52.128937 15117 sgd_solver.cpp:294] Iteration 12780, lr = 0.02
I0526 02:27:58.516405 15117 solver.cpp:233] Iteration 12790, loss = 0.285699
I0526 02:27:58.516480 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.285699 (* 1 = 0.285699 loss)
I0526 02:27:58.516494 15117 sgd_solver.cpp:294] Iteration 12790, lr = 0.02
I0526 02:28:04.321308 15117 solver.cpp:342] Iteration 12800, Testing net (#0)
I0526 02:28:17.457543 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7768
I0526 02:28:17.457715 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.79709 (* 1 = 0.79709 loss)
I0526 02:28:18.059236 15117 solver.cpp:233] Iteration 12800, loss = 0.219945
I0526 02:28:18.059309 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.219945 (* 1 = 0.219945 loss)
I0526 02:28:18.059324 15117 sgd_solver.cpp:294] Iteration 12800, lr = 0.02
I0526 02:28:24.419179 15117 solver.cpp:233] Iteration 12810, loss = 0.313897
I0526 02:28:24.419240 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.313897 (* 1 = 0.313897 loss)
I0526 02:28:24.419251 15117 sgd_solver.cpp:294] Iteration 12810, lr = 0.02
I0526 02:28:30.792207 15117 solver.cpp:233] Iteration 12820, loss = 0.224636
I0526 02:28:30.792279 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.224636 (* 1 = 0.224636 loss)
I0526 02:28:30.792292 15117 sgd_solver.cpp:294] Iteration 12820, lr = 0.02
I0526 02:28:37.167743 15117 solver.cpp:233] Iteration 12830, loss = 0.0875893
I0526 02:28:37.167815 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0875893 (* 1 = 0.0875893 loss)
I0526 02:28:37.167827 15117 sgd_solver.cpp:294] Iteration 12830, lr = 0.02
I0526 02:28:43.543608 15117 solver.cpp:233] Iteration 12840, loss = 0.0901104
I0526 02:28:43.543684 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0901103 (* 1 = 0.0901103 loss)
I0526 02:28:43.543697 15117 sgd_solver.cpp:294] Iteration 12840, lr = 0.02
I0526 02:28:49.904955 15117 solver.cpp:233] Iteration 12850, loss = 0.303946
I0526 02:28:49.905174 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.303946 (* 1 = 0.303946 loss)
I0526 02:28:49.905200 15117 sgd_solver.cpp:294] Iteration 12850, lr = 0.02
I0526 02:28:56.280148 15117 solver.cpp:233] Iteration 12860, loss = 0.205511
I0526 02:28:56.280220 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.205511 (* 1 = 0.205511 loss)
I0526 02:28:56.280232 15117 sgd_solver.cpp:294] Iteration 12860, lr = 0.02
I0526 02:29:02.665765 15117 solver.cpp:233] Iteration 12870, loss = 0.233049
I0526 02:29:02.665839 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.233049 (* 1 = 0.233049 loss)
I0526 02:29:02.665851 15117 sgd_solver.cpp:294] Iteration 12870, lr = 0.02
I0526 02:29:09.027582 15117 solver.cpp:233] Iteration 12880, loss = 0.147362
I0526 02:29:09.027650 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.147362 (* 1 = 0.147362 loss)
I0526 02:29:09.027662 15117 sgd_solver.cpp:294] Iteration 12880, lr = 0.02
I0526 02:29:15.405650 15117 solver.cpp:233] Iteration 12890, loss = 0.163038
I0526 02:29:15.405724 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.163038 (* 1 = 0.163038 loss)
I0526 02:29:15.405735 15117 sgd_solver.cpp:294] Iteration 12890, lr = 0.02
I0526 02:29:21.183476 15117 solver.cpp:342] Iteration 12900, Testing net (#0)
I0526 02:29:34.218385 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7891
I0526 02:29:34.218456 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.71927 (* 1 = 0.71927 loss)
I0526 02:29:34.823822 15117 solver.cpp:233] Iteration 12900, loss = 0.244524
I0526 02:29:34.823891 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.244524 (* 1 = 0.244524 loss)
I0526 02:29:34.823906 15117 sgd_solver.cpp:294] Iteration 12900, lr = 0.02
I0526 02:29:41.187559 15117 solver.cpp:233] Iteration 12910, loss = 0.0988035
I0526 02:29:41.187621 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0988035 (* 1 = 0.0988035 loss)
I0526 02:29:41.187641 15117 sgd_solver.cpp:294] Iteration 12910, lr = 0.02
I0526 02:29:47.554545 15117 solver.cpp:233] Iteration 12920, loss = 0.175051
I0526 02:29:47.554615 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.175051 (* 1 = 0.175051 loss)
I0526 02:29:47.554627 15117 sgd_solver.cpp:294] Iteration 12920, lr = 0.02
I0526 02:29:53.923862 15117 solver.cpp:233] Iteration 12930, loss = 0.334157
I0526 02:29:53.924139 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.334157 (* 1 = 0.334157 loss)
I0526 02:29:53.924165 15117 sgd_solver.cpp:294] Iteration 12930, lr = 0.02
I0526 02:30:00.291824 15117 solver.cpp:233] Iteration 12940, loss = 0.171644
I0526 02:30:00.291900 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.171644 (* 1 = 0.171644 loss)
I0526 02:30:00.291915 15117 sgd_solver.cpp:294] Iteration 12940, lr = 0.02
I0526 02:30:06.666988 15117 solver.cpp:233] Iteration 12950, loss = 0.143737
I0526 02:30:06.667062 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.143737 (* 1 = 0.143737 loss)
I0526 02:30:06.667073 15117 sgd_solver.cpp:294] Iteration 12950, lr = 0.02
I0526 02:30:13.030616 15117 solver.cpp:233] Iteration 12960, loss = 0.285435
I0526 02:30:13.030679 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.285435 (* 1 = 0.285435 loss)
I0526 02:30:13.030692 15117 sgd_solver.cpp:294] Iteration 12960, lr = 0.02
I0526 02:30:19.395061 15117 solver.cpp:233] Iteration 12970, loss = 0.267205
I0526 02:30:19.395133 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.267205 (* 1 = 0.267205 loss)
I0526 02:30:19.395144 15117 sgd_solver.cpp:294] Iteration 12970, lr = 0.02
I0526 02:30:25.764268 15117 solver.cpp:233] Iteration 12980, loss = 0.221865
I0526 02:30:25.764505 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.221865 (* 1 = 0.221865 loss)
I0526 02:30:25.764533 15117 sgd_solver.cpp:294] Iteration 12980, lr = 0.02
I0526 02:30:32.137580 15117 solver.cpp:233] Iteration 12990, loss = 0.132691
I0526 02:30:32.137656 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.132691 (* 1 = 0.132691 loss)
I0526 02:30:32.137670 15117 sgd_solver.cpp:294] Iteration 12990, lr = 0.02
I0526 02:30:37.923779 15117 solver.cpp:342] Iteration 13000, Testing net (#0)
I0526 02:30:50.995026 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7897
I0526 02:30:50.995095 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.743963 (* 1 = 0.743963 loss)
I0526 02:30:51.597487 15117 solver.cpp:233] Iteration 13000, loss = 0.223262
I0526 02:30:51.597571 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.223262 (* 1 = 0.223262 loss)
I0526 02:30:51.597590 15117 sgd_solver.cpp:294] Iteration 13000, lr = 0.02
I0526 02:30:57.981657 15117 solver.cpp:233] Iteration 13010, loss = 0.287187
I0526 02:30:57.981910 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.287187 (* 1 = 0.287187 loss)
I0526 02:30:57.981937 15117 sgd_solver.cpp:294] Iteration 13010, lr = 0.02
I0526 02:31:04.370637 15117 solver.cpp:233] Iteration 13020, loss = 0.265015
I0526 02:31:04.370708 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.265015 (* 1 = 0.265015 loss)
I0526 02:31:04.370720 15117 sgd_solver.cpp:294] Iteration 13020, lr = 0.02
I0526 02:31:10.752815 15117 solver.cpp:233] Iteration 13030, loss = 0.141806
I0526 02:31:10.752899 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.141806 (* 1 = 0.141806 loss)
I0526 02:31:10.752915 15117 sgd_solver.cpp:294] Iteration 13030, lr = 0.02
I0526 02:31:17.113565 15117 solver.cpp:233] Iteration 13040, loss = 0.204051
I0526 02:31:17.113629 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.204051 (* 1 = 0.204051 loss)
I0526 02:31:17.113642 15117 sgd_solver.cpp:294] Iteration 13040, lr = 0.02
I0526 02:31:23.485975 15117 solver.cpp:233] Iteration 13050, loss = 0.27422
I0526 02:31:23.486047 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.27422 (* 1 = 0.27422 loss)
I0526 02:31:23.486069 15117 sgd_solver.cpp:294] Iteration 13050, lr = 0.02
I0526 02:31:29.854001 15117 solver.cpp:233] Iteration 13060, loss = 0.261648
I0526 02:31:29.854217 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.261648 (* 1 = 0.261648 loss)
I0526 02:31:29.854231 15117 sgd_solver.cpp:294] Iteration 13060, lr = 0.02
I0526 02:31:36.233073 15117 solver.cpp:233] Iteration 13070, loss = 0.184068
I0526 02:31:36.233141 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.184068 (* 1 = 0.184068 loss)
I0526 02:31:36.233152 15117 sgd_solver.cpp:294] Iteration 13070, lr = 0.02
I0526 02:31:42.602520 15117 solver.cpp:233] Iteration 13080, loss = 0.223048
I0526 02:31:42.602589 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.223048 (* 1 = 0.223048 loss)
I0526 02:31:42.602601 15117 sgd_solver.cpp:294] Iteration 13080, lr = 0.02
I0526 02:31:48.976116 15117 solver.cpp:233] Iteration 13090, loss = 0.194204
I0526 02:31:48.976186 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.194204 (* 1 = 0.194204 loss)
I0526 02:31:48.976197 15117 sgd_solver.cpp:294] Iteration 13090, lr = 0.02
I0526 02:31:54.743558 15117 solver.cpp:342] Iteration 13100, Testing net (#0)
I0526 02:32:07.771608 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7862
I0526 02:32:07.771766 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.74655 (* 1 = 0.74655 loss)
I0526 02:32:08.380239 15117 solver.cpp:233] Iteration 13100, loss = 0.279418
I0526 02:32:08.380312 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.279418 (* 1 = 0.279418 loss)
I0526 02:32:08.380326 15117 sgd_solver.cpp:294] Iteration 13100, lr = 0.02
I0526 02:32:14.753072 15117 solver.cpp:233] Iteration 13110, loss = 0.133619
I0526 02:32:14.753149 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.133619 (* 1 = 0.133619 loss)
I0526 02:32:14.753162 15117 sgd_solver.cpp:294] Iteration 13110, lr = 0.02
I0526 02:32:21.120187 15117 solver.cpp:233] Iteration 13120, loss = 0.156015
I0526 02:32:21.120259 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.156015 (* 1 = 0.156015 loss)
I0526 02:32:21.120270 15117 sgd_solver.cpp:294] Iteration 13120, lr = 0.02
I0526 02:32:27.501170 15117 solver.cpp:233] Iteration 13130, loss = 0.226578
I0526 02:32:27.501241 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.226578 (* 1 = 0.226578 loss)
I0526 02:32:27.501255 15117 sgd_solver.cpp:294] Iteration 13130, lr = 0.02
I0526 02:32:33.892895 15117 solver.cpp:233] Iteration 13140, loss = 0.215978
I0526 02:32:33.892966 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.215978 (* 1 = 0.215978 loss)
I0526 02:32:33.892978 15117 sgd_solver.cpp:294] Iteration 13140, lr = 0.02
I0526 02:32:40.275985 15117 solver.cpp:233] Iteration 13150, loss = 0.291399
I0526 02:32:40.276206 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.291399 (* 1 = 0.291399 loss)
I0526 02:32:40.276234 15117 sgd_solver.cpp:294] Iteration 13150, lr = 0.02
I0526 02:32:46.647655 15117 solver.cpp:233] Iteration 13160, loss = 0.195013
I0526 02:32:46.647732 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.195012 (* 1 = 0.195012 loss)
I0526 02:32:46.647744 15117 sgd_solver.cpp:294] Iteration 13160, lr = 0.02
I0526 02:32:53.021101 15117 solver.cpp:233] Iteration 13170, loss = 0.265506
I0526 02:32:53.021173 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.265506 (* 1 = 0.265506 loss)
I0526 02:32:53.021186 15117 sgd_solver.cpp:294] Iteration 13170, lr = 0.02
I0526 02:32:59.394855 15117 solver.cpp:233] Iteration 13180, loss = 0.254931
I0526 02:32:59.394927 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.254931 (* 1 = 0.254931 loss)
I0526 02:32:59.394938 15117 sgd_solver.cpp:294] Iteration 13180, lr = 0.02
I0526 02:33:05.765795 15117 solver.cpp:233] Iteration 13190, loss = 0.137151
I0526 02:33:05.765874 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.137151 (* 1 = 0.137151 loss)
I0526 02:33:05.765911 15117 sgd_solver.cpp:294] Iteration 13190, lr = 0.02
I0526 02:33:11.552878 15117 solver.cpp:342] Iteration 13200, Testing net (#0)
I0526 02:33:24.663071 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7398
I0526 02:33:24.663166 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.06052 (* 1 = 1.06052 loss)
I0526 02:33:25.272266 15117 solver.cpp:233] Iteration 13200, loss = 0.208463
I0526 02:33:25.272356 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.208463 (* 1 = 0.208463 loss)
I0526 02:33:25.272377 15117 sgd_solver.cpp:294] Iteration 13200, lr = 0.02
I0526 02:33:31.650482 15117 solver.cpp:233] Iteration 13210, loss = 0.378814
I0526 02:33:31.650588 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.378814 (* 1 = 0.378814 loss)
I0526 02:33:31.650609 15117 sgd_solver.cpp:294] Iteration 13210, lr = 0.02
I0526 02:33:38.023706 15117 solver.cpp:233] Iteration 13220, loss = 0.132952
I0526 02:33:38.023792 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.132952 (* 1 = 0.132952 loss)
I0526 02:33:38.023818 15117 sgd_solver.cpp:294] Iteration 13220, lr = 0.02
I0526 02:33:44.405843 15117 solver.cpp:233] Iteration 13230, loss = 0.17232
I0526 02:33:44.405999 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.17232 (* 1 = 0.17232 loss)
I0526 02:33:44.406011 15117 sgd_solver.cpp:294] Iteration 13230, lr = 0.02
I0526 02:33:50.782229 15117 solver.cpp:233] Iteration 13240, loss = 0.227952
I0526 02:33:50.782318 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.227952 (* 1 = 0.227952 loss)
I0526 02:33:50.782335 15117 sgd_solver.cpp:294] Iteration 13240, lr = 0.02
I0526 02:33:57.156925 15117 solver.cpp:233] Iteration 13250, loss = 0.261974
I0526 02:33:57.157003 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.261974 (* 1 = 0.261974 loss)
I0526 02:33:57.157016 15117 sgd_solver.cpp:294] Iteration 13250, lr = 0.02
I0526 02:34:03.532974 15117 solver.cpp:233] Iteration 13260, loss = 0.164539
I0526 02:34:03.533056 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.164539 (* 1 = 0.164539 loss)
I0526 02:34:03.533071 15117 sgd_solver.cpp:294] Iteration 13260, lr = 0.02
I0526 02:34:09.900513 15117 solver.cpp:233] Iteration 13270, loss = 0.163243
I0526 02:34:09.900607 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.163243 (* 1 = 0.163243 loss)
I0526 02:34:09.900627 15117 sgd_solver.cpp:294] Iteration 13270, lr = 0.02
I0526 02:34:16.273262 15117 solver.cpp:233] Iteration 13280, loss = 0.109581
I0526 02:34:16.273422 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.109581 (* 1 = 0.109581 loss)
I0526 02:34:16.273435 15117 sgd_solver.cpp:294] Iteration 13280, lr = 0.02
I0526 02:34:22.642119 15117 solver.cpp:233] Iteration 13290, loss = 0.185137
I0526 02:34:22.642215 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.185137 (* 1 = 0.185137 loss)
I0526 02:34:22.642233 15117 sgd_solver.cpp:294] Iteration 13290, lr = 0.02
I0526 02:34:28.424630 15117 solver.cpp:342] Iteration 13300, Testing net (#0)
I0526 02:34:41.509763 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7556
I0526 02:34:41.509831 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.887332 (* 1 = 0.887332 loss)
I0526 02:34:42.111493 15117 solver.cpp:233] Iteration 13300, loss = 0.0942667
I0526 02:34:42.111588 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0942667 (* 1 = 0.0942667 loss)
I0526 02:34:42.111604 15117 sgd_solver.cpp:294] Iteration 13300, lr = 0.02
I0526 02:34:48.492349 15117 solver.cpp:233] Iteration 13310, loss = 0.155399
I0526 02:34:48.492599 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.155399 (* 1 = 0.155399 loss)
I0526 02:34:48.492626 15117 sgd_solver.cpp:294] Iteration 13310, lr = 0.02
I0526 02:34:54.865248 15117 solver.cpp:233] Iteration 13320, loss = 0.376005
I0526 02:34:54.865334 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.376005 (* 1 = 0.376005 loss)
I0526 02:34:54.865345 15117 sgd_solver.cpp:294] Iteration 13320, lr = 0.02
I0526 02:35:01.256700 15117 solver.cpp:233] Iteration 13330, loss = 0.228033
I0526 02:35:01.256772 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.228033 (* 1 = 0.228033 loss)
I0526 02:35:01.256784 15117 sgd_solver.cpp:294] Iteration 13330, lr = 0.02
I0526 02:35:07.651310 15117 solver.cpp:233] Iteration 13340, loss = 0.17894
I0526 02:35:07.651386 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.17894 (* 1 = 0.17894 loss)
I0526 02:35:07.651397 15117 sgd_solver.cpp:294] Iteration 13340, lr = 0.02
I0526 02:35:14.021402 15117 solver.cpp:233] Iteration 13350, loss = 0.190313
I0526 02:35:14.021472 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.190313 (* 1 = 0.190313 loss)
I0526 02:35:14.021483 15117 sgd_solver.cpp:294] Iteration 13350, lr = 0.02
I0526 02:35:20.410747 15117 solver.cpp:233] Iteration 13360, loss = 0.158781
I0526 02:35:20.410961 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.158781 (* 1 = 0.158781 loss)
I0526 02:35:20.410976 15117 sgd_solver.cpp:294] Iteration 13360, lr = 0.02
I0526 02:35:26.796116 15117 solver.cpp:233] Iteration 13370, loss = 0.14534
I0526 02:35:26.796185 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.14534 (* 1 = 0.14534 loss)
I0526 02:35:26.796196 15117 sgd_solver.cpp:294] Iteration 13370, lr = 0.02
I0526 02:35:33.182843 15117 solver.cpp:233] Iteration 13380, loss = 0.260678
I0526 02:35:33.182911 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.260678 (* 1 = 0.260678 loss)
I0526 02:35:33.182922 15117 sgd_solver.cpp:294] Iteration 13380, lr = 0.02
I0526 02:35:39.560377 15117 solver.cpp:233] Iteration 13390, loss = 0.232126
I0526 02:35:39.560451 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.232126 (* 1 = 0.232126 loss)
I0526 02:35:39.560462 15117 sgd_solver.cpp:294] Iteration 13390, lr = 0.02
I0526 02:35:45.343405 15117 solver.cpp:342] Iteration 13400, Testing net (#0)
I0526 02:35:58.375776 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8173
I0526 02:35:58.375926 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.580268 (* 1 = 0.580268 loss)
I0526 02:35:58.980193 15117 solver.cpp:233] Iteration 13400, loss = 0.209218
I0526 02:35:58.980260 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.209218 (* 1 = 0.209218 loss)
I0526 02:35:58.980275 15117 sgd_solver.cpp:294] Iteration 13400, lr = 0.02
I0526 02:36:05.359768 15117 solver.cpp:233] Iteration 13410, loss = 0.251845
I0526 02:36:05.359838 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.251845 (* 1 = 0.251845 loss)
I0526 02:36:05.359851 15117 sgd_solver.cpp:294] Iteration 13410, lr = 0.02
I0526 02:36:11.730326 15117 solver.cpp:233] Iteration 13420, loss = 0.180434
I0526 02:36:11.730404 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.180434 (* 1 = 0.180434 loss)
I0526 02:36:11.730417 15117 sgd_solver.cpp:294] Iteration 13420, lr = 0.02
I0526 02:36:18.105912 15117 solver.cpp:233] Iteration 13430, loss = 0.210751
I0526 02:36:18.105978 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.210751 (* 1 = 0.210751 loss)
I0526 02:36:18.105989 15117 sgd_solver.cpp:294] Iteration 13430, lr = 0.02
I0526 02:36:24.484235 15117 solver.cpp:233] Iteration 13440, loss = 0.199584
I0526 02:36:24.484308 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.199584 (* 1 = 0.199584 loss)
I0526 02:36:24.484320 15117 sgd_solver.cpp:294] Iteration 13440, lr = 0.02
I0526 02:36:30.849432 15117 solver.cpp:233] Iteration 13450, loss = 0.301794
I0526 02:36:30.850497 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.301794 (* 1 = 0.301794 loss)
I0526 02:36:30.850524 15117 sgd_solver.cpp:294] Iteration 13450, lr = 0.02
I0526 02:36:37.236309 15117 solver.cpp:233] Iteration 13460, loss = 0.228
I0526 02:36:37.236378 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.228 (* 1 = 0.228 loss)
I0526 02:36:37.236390 15117 sgd_solver.cpp:294] Iteration 13460, lr = 0.02
I0526 02:36:43.599858 15117 solver.cpp:233] Iteration 13470, loss = 0.232849
I0526 02:36:43.599932 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.232849 (* 1 = 0.232849 loss)
I0526 02:36:43.599944 15117 sgd_solver.cpp:294] Iteration 13470, lr = 0.02
I0526 02:36:49.966789 15117 solver.cpp:233] Iteration 13480, loss = 0.313374
I0526 02:36:49.966853 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.313374 (* 1 = 0.313374 loss)
I0526 02:36:49.966866 15117 sgd_solver.cpp:294] Iteration 13480, lr = 0.02
I0526 02:36:56.324549 15117 solver.cpp:233] Iteration 13490, loss = 0.20914
I0526 02:36:56.324620 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.20914 (* 1 = 0.20914 loss)
I0526 02:36:56.324632 15117 sgd_solver.cpp:294] Iteration 13490, lr = 0.02
I0526 02:37:02.093416 15117 solver.cpp:342] Iteration 13500, Testing net (#0)
I0526 02:37:15.099993 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7413
I0526 02:37:15.100060 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.999705 (* 1 = 0.999705 loss)
I0526 02:37:15.705765 15117 solver.cpp:233] Iteration 13500, loss = 0.100608
I0526 02:37:15.705832 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.100608 (* 1 = 0.100608 loss)
I0526 02:37:15.705844 15117 sgd_solver.cpp:294] Iteration 13500, lr = 0.02
I0526 02:37:22.086571 15117 solver.cpp:233] Iteration 13510, loss = 0.181157
I0526 02:37:22.086640 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.181157 (* 1 = 0.181157 loss)
I0526 02:37:22.086652 15117 sgd_solver.cpp:294] Iteration 13510, lr = 0.02
I0526 02:37:28.474860 15117 solver.cpp:233] Iteration 13520, loss = 0.167766
I0526 02:37:28.474932 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.167766 (* 1 = 0.167766 loss)
I0526 02:37:28.474946 15117 sgd_solver.cpp:294] Iteration 13520, lr = 0.02
I0526 02:37:34.848414 15117 solver.cpp:233] Iteration 13530, loss = 0.186557
I0526 02:37:34.848584 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.186557 (* 1 = 0.186557 loss)
I0526 02:37:34.848598 15117 sgd_solver.cpp:294] Iteration 13530, lr = 0.02
I0526 02:37:41.221271 15117 solver.cpp:233] Iteration 13540, loss = 0.209056
I0526 02:37:41.221343 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.209056 (* 1 = 0.209056 loss)
I0526 02:37:41.221355 15117 sgd_solver.cpp:294] Iteration 13540, lr = 0.02
I0526 02:37:47.585793 15117 solver.cpp:233] Iteration 13550, loss = 0.17925
I0526 02:37:47.585865 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.17925 (* 1 = 0.17925 loss)
I0526 02:37:47.585877 15117 sgd_solver.cpp:294] Iteration 13550, lr = 0.02
I0526 02:37:53.949265 15117 solver.cpp:233] Iteration 13560, loss = 0.131853
I0526 02:37:53.949337 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.131853 (* 1 = 0.131853 loss)
I0526 02:37:53.949352 15117 sgd_solver.cpp:294] Iteration 13560, lr = 0.02
I0526 02:38:00.308249 15117 solver.cpp:233] Iteration 13570, loss = 0.171079
I0526 02:38:00.308320 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.171079 (* 1 = 0.171079 loss)
I0526 02:38:00.308331 15117 sgd_solver.cpp:294] Iteration 13570, lr = 0.02
I0526 02:38:06.675357 15117 solver.cpp:233] Iteration 13580, loss = 0.190814
I0526 02:38:06.675585 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.190814 (* 1 = 0.190814 loss)
I0526 02:38:06.675613 15117 sgd_solver.cpp:294] Iteration 13580, lr = 0.02
I0526 02:38:13.032843 15117 solver.cpp:233] Iteration 13590, loss = 0.3371
I0526 02:38:13.032914 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.3371 (* 1 = 0.3371 loss)
I0526 02:38:13.032927 15117 sgd_solver.cpp:294] Iteration 13590, lr = 0.02
I0526 02:38:18.817369 15117 solver.cpp:342] Iteration 13600, Testing net (#0)
I0526 02:38:31.854610 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7913
I0526 02:38:31.854677 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.781519 (* 1 = 0.781519 loss)
I0526 02:38:32.455736 15117 solver.cpp:233] Iteration 13600, loss = 0.226991
I0526 02:38:32.455796 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.226991 (* 1 = 0.226991 loss)
I0526 02:38:32.455807 15117 sgd_solver.cpp:294] Iteration 13600, lr = 0.02
I0526 02:38:38.825184 15117 solver.cpp:233] Iteration 13610, loss = 0.13877
I0526 02:38:38.825479 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.13877 (* 1 = 0.13877 loss)
I0526 02:38:38.825507 15117 sgd_solver.cpp:294] Iteration 13610, lr = 0.02
I0526 02:38:45.203692 15117 solver.cpp:233] Iteration 13620, loss = 0.203717
I0526 02:38:45.203768 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.203717 (* 1 = 0.203717 loss)
I0526 02:38:45.203780 15117 sgd_solver.cpp:294] Iteration 13620, lr = 0.02
I0526 02:38:51.582350 15117 solver.cpp:233] Iteration 13630, loss = 0.241911
I0526 02:38:51.582453 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.241911 (* 1 = 0.241911 loss)
I0526 02:38:51.582469 15117 sgd_solver.cpp:294] Iteration 13630, lr = 0.02
I0526 02:38:58.000846 15117 solver.cpp:233] Iteration 13640, loss = 0.239308
I0526 02:38:58.000922 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.239308 (* 1 = 0.239308 loss)
I0526 02:38:58.000936 15117 sgd_solver.cpp:294] Iteration 13640, lr = 0.02
I0526 02:39:04.367413 15117 solver.cpp:233] Iteration 13650, loss = 0.132214
I0526 02:39:04.367514 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.132214 (* 1 = 0.132214 loss)
I0526 02:39:04.367535 15117 sgd_solver.cpp:294] Iteration 13650, lr = 0.02
I0526 02:39:10.737542 15117 solver.cpp:233] Iteration 13660, loss = 0.146386
I0526 02:39:10.737757 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.146385 (* 1 = 0.146385 loss)
I0526 02:39:10.737785 15117 sgd_solver.cpp:294] Iteration 13660, lr = 0.02
I0526 02:39:17.101097 15117 solver.cpp:233] Iteration 13670, loss = 0.21781
I0526 02:39:17.101162 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.21781 (* 1 = 0.21781 loss)
I0526 02:39:17.101173 15117 sgd_solver.cpp:294] Iteration 13670, lr = 0.02
I0526 02:39:23.458773 15117 solver.cpp:233] Iteration 13680, loss = 0.146046
I0526 02:39:23.458880 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.146046 (* 1 = 0.146046 loss)
I0526 02:39:23.458906 15117 sgd_solver.cpp:294] Iteration 13680, lr = 0.02
I0526 02:39:29.830209 15117 solver.cpp:233] Iteration 13690, loss = 0.10691
I0526 02:39:29.830297 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.10691 (* 1 = 0.10691 loss)
I0526 02:39:29.830313 15117 sgd_solver.cpp:294] Iteration 13690, lr = 0.02
I0526 02:39:35.608304 15117 solver.cpp:342] Iteration 13700, Testing net (#0)
I0526 02:39:48.693754 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7954
I0526 02:39:48.693964 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.725951 (* 1 = 0.725951 loss)
I0526 02:39:49.299285 15117 solver.cpp:233] Iteration 13700, loss = 0.150088
I0526 02:39:49.299363 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.150088 (* 1 = 0.150088 loss)
I0526 02:39:49.299377 15117 sgd_solver.cpp:294] Iteration 13700, lr = 0.02
I0526 02:39:55.684237 15117 solver.cpp:233] Iteration 13710, loss = 0.27524
I0526 02:39:55.684309 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.27524 (* 1 = 0.27524 loss)
I0526 02:39:55.684320 15117 sgd_solver.cpp:294] Iteration 13710, lr = 0.02
I0526 02:40:02.073631 15117 solver.cpp:233] Iteration 13720, loss = 0.209697
I0526 02:40:02.073706 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.209697 (* 1 = 0.209697 loss)
I0526 02:40:02.073719 15117 sgd_solver.cpp:294] Iteration 13720, lr = 0.02
I0526 02:40:08.453270 15117 solver.cpp:233] Iteration 13730, loss = 0.1607
I0526 02:40:08.453373 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.1607 (* 1 = 0.1607 loss)
I0526 02:40:08.453408 15117 sgd_solver.cpp:294] Iteration 13730, lr = 0.02
I0526 02:40:14.832710 15117 solver.cpp:233] Iteration 13740, loss = 0.245096
I0526 02:40:14.832818 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.245096 (* 1 = 0.245096 loss)
I0526 02:40:14.832836 15117 sgd_solver.cpp:294] Iteration 13740, lr = 0.02
I0526 02:40:21.215065 15117 solver.cpp:233] Iteration 13750, loss = 0.139519
I0526 02:40:21.215375 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.139519 (* 1 = 0.139519 loss)
I0526 02:40:21.215409 15117 sgd_solver.cpp:294] Iteration 13750, lr = 0.02
I0526 02:40:27.586156 15117 solver.cpp:233] Iteration 13760, loss = 0.305884
I0526 02:40:27.586241 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.305884 (* 1 = 0.305884 loss)
I0526 02:40:27.586256 15117 sgd_solver.cpp:294] Iteration 13760, lr = 0.02
I0526 02:40:33.975059 15117 solver.cpp:233] Iteration 13770, loss = 0.169869
I0526 02:40:33.975142 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.169869 (* 1 = 0.169869 loss)
I0526 02:40:33.975158 15117 sgd_solver.cpp:294] Iteration 13770, lr = 0.02
I0526 02:40:40.348188 15117 solver.cpp:233] Iteration 13780, loss = 0.121636
I0526 02:40:40.348260 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.121636 (* 1 = 0.121636 loss)
I0526 02:40:40.348273 15117 sgd_solver.cpp:294] Iteration 13780, lr = 0.02
I0526 02:40:46.733362 15117 solver.cpp:233] Iteration 13790, loss = 0.15195
I0526 02:40:46.733435 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.15195 (* 1 = 0.15195 loss)
I0526 02:40:46.733448 15117 sgd_solver.cpp:294] Iteration 13790, lr = 0.02
I0526 02:40:52.506237 15117 solver.cpp:342] Iteration 13800, Testing net (#0)
I0526 02:41:05.575131 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7469
I0526 02:41:05.575203 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.869781 (* 1 = 0.869781 loss)
I0526 02:41:06.178166 15117 solver.cpp:233] Iteration 13800, loss = 0.179525
I0526 02:41:06.178280 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.179525 (* 1 = 0.179525 loss)
I0526 02:41:06.178297 15117 sgd_solver.cpp:294] Iteration 13800, lr = 0.02
I0526 02:41:12.571465 15117 solver.cpp:233] Iteration 13810, loss = 0.221306
I0526 02:41:12.571554 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.221306 (* 1 = 0.221306 loss)
I0526 02:41:12.571569 15117 sgd_solver.cpp:294] Iteration 13810, lr = 0.02
I0526 02:41:18.966037 15117 solver.cpp:233] Iteration 13820, loss = 0.182706
I0526 02:41:18.966107 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.182706 (* 1 = 0.182706 loss)
I0526 02:41:18.966120 15117 sgd_solver.cpp:294] Iteration 13820, lr = 0.02
I0526 02:41:25.358801 15117 solver.cpp:233] Iteration 13830, loss = 0.253897
I0526 02:41:25.359004 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.253897 (* 1 = 0.253897 loss)
I0526 02:41:25.359030 15117 sgd_solver.cpp:294] Iteration 13830, lr = 0.02
I0526 02:41:31.754914 15117 solver.cpp:233] Iteration 13840, loss = 0.235888
I0526 02:41:31.754987 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.235888 (* 1 = 0.235888 loss)
I0526 02:41:31.754999 15117 sgd_solver.cpp:294] Iteration 13840, lr = 0.02
I0526 02:41:38.135248 15117 solver.cpp:233] Iteration 13850, loss = 0.237443
I0526 02:41:38.135315 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.237443 (* 1 = 0.237443 loss)
I0526 02:41:38.135326 15117 sgd_solver.cpp:294] Iteration 13850, lr = 0.02
I0526 02:41:44.540242 15117 solver.cpp:233] Iteration 13860, loss = 0.231876
I0526 02:41:44.540309 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.231876 (* 1 = 0.231876 loss)
I0526 02:41:44.540321 15117 sgd_solver.cpp:294] Iteration 13860, lr = 0.02
I0526 02:41:50.956939 15117 solver.cpp:233] Iteration 13870, loss = 0.281594
I0526 02:41:50.957015 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.281594 (* 1 = 0.281594 loss)
I0526 02:41:50.957027 15117 sgd_solver.cpp:294] Iteration 13870, lr = 0.02
I0526 02:41:57.366013 15117 solver.cpp:233] Iteration 13880, loss = 0.195557
I0526 02:41:57.366325 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.195557 (* 1 = 0.195557 loss)
I0526 02:41:57.366369 15117 sgd_solver.cpp:294] Iteration 13880, lr = 0.02
I0526 02:42:03.771136 15117 solver.cpp:233] Iteration 13890, loss = 0.140497
I0526 02:42:03.771214 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.140497 (* 1 = 0.140497 loss)
I0526 02:42:03.771229 15117 sgd_solver.cpp:294] Iteration 13890, lr = 0.02
I0526 02:42:09.564705 15117 solver.cpp:342] Iteration 13900, Testing net (#0)
I0526 02:42:22.687376 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7862
I0526 02:42:22.687441 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.735488 (* 1 = 0.735488 loss)
I0526 02:42:23.297093 15117 solver.cpp:233] Iteration 13900, loss = 0.19186
I0526 02:42:23.297163 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.19186 (* 1 = 0.19186 loss)
I0526 02:42:23.297175 15117 sgd_solver.cpp:294] Iteration 13900, lr = 0.02
I0526 02:42:29.690704 15117 solver.cpp:233] Iteration 13910, loss = 0.160972
I0526 02:42:29.690925 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.160972 (* 1 = 0.160972 loss)
I0526 02:42:29.690945 15117 sgd_solver.cpp:294] Iteration 13910, lr = 0.02
I0526 02:42:36.115926 15117 solver.cpp:233] Iteration 13920, loss = 0.172468
I0526 02:42:36.115998 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.172468 (* 1 = 0.172468 loss)
I0526 02:42:36.116010 15117 sgd_solver.cpp:294] Iteration 13920, lr = 0.02
I0526 02:42:42.530565 15117 solver.cpp:233] Iteration 13930, loss = 0.254587
I0526 02:42:42.530661 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.254587 (* 1 = 0.254587 loss)
I0526 02:42:42.530676 15117 sgd_solver.cpp:294] Iteration 13930, lr = 0.02
I0526 02:42:48.960578 15117 solver.cpp:233] Iteration 13940, loss = 0.17266
I0526 02:42:48.960654 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.17266 (* 1 = 0.17266 loss)
I0526 02:42:48.960666 15117 sgd_solver.cpp:294] Iteration 13940, lr = 0.02
I0526 02:42:55.354120 15117 solver.cpp:233] Iteration 13950, loss = 0.238983
I0526 02:42:55.354190 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.238983 (* 1 = 0.238983 loss)
I0526 02:42:55.354202 15117 sgd_solver.cpp:294] Iteration 13950, lr = 0.02
I0526 02:43:01.776288 15117 solver.cpp:233] Iteration 13960, loss = 0.320176
I0526 02:43:01.776437 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.320176 (* 1 = 0.320176 loss)
I0526 02:43:01.776450 15117 sgd_solver.cpp:294] Iteration 13960, lr = 0.02
I0526 02:43:08.178758 15117 solver.cpp:233] Iteration 13970, loss = 0.218988
I0526 02:43:08.178835 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.218988 (* 1 = 0.218988 loss)
I0526 02:43:08.178850 15117 sgd_solver.cpp:294] Iteration 13970, lr = 0.02
I0526 02:43:14.595299 15117 solver.cpp:233] Iteration 13980, loss = 0.16894
I0526 02:43:14.595374 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.16894 (* 1 = 0.16894 loss)
I0526 02:43:14.595387 15117 sgd_solver.cpp:294] Iteration 13980, lr = 0.02
I0526 02:43:21.003638 15117 solver.cpp:233] Iteration 13990, loss = 0.201125
I0526 02:43:21.003703 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.201125 (* 1 = 0.201125 loss)
I0526 02:43:21.003715 15117 sgd_solver.cpp:294] Iteration 13990, lr = 0.02
I0526 02:43:26.794230 15117 solver.cpp:342] Iteration 14000, Testing net (#0)
I0526 02:43:39.897855 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7833
I0526 02:43:39.898016 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.840102 (* 1 = 0.840102 loss)
I0526 02:43:40.505465 15117 solver.cpp:233] Iteration 14000, loss = 0.275386
I0526 02:43:40.505532 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.275386 (* 1 = 0.275386 loss)
I0526 02:43:40.505545 15117 sgd_solver.cpp:294] Iteration 14000, lr = 0.02
I0526 02:43:46.900657 15117 solver.cpp:233] Iteration 14010, loss = 0.216277
I0526 02:43:46.900737 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.216277 (* 1 = 0.216277 loss)
I0526 02:43:46.900749 15117 sgd_solver.cpp:294] Iteration 14010, lr = 0.02
I0526 02:43:53.290767 15117 solver.cpp:233] Iteration 14020, loss = 0.104077
I0526 02:43:53.290843 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.104077 (* 1 = 0.104077 loss)
I0526 02:43:53.290854 15117 sgd_solver.cpp:294] Iteration 14020, lr = 0.02
I0526 02:43:59.713135 15117 solver.cpp:233] Iteration 14030, loss = 0.189192
I0526 02:43:59.713199 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.189192 (* 1 = 0.189192 loss)
I0526 02:43:59.713212 15117 sgd_solver.cpp:294] Iteration 14030, lr = 0.02
I0526 02:44:06.110860 15117 solver.cpp:233] Iteration 14040, loss = 0.125925
I0526 02:44:06.110929 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.125925 (* 1 = 0.125925 loss)
I0526 02:44:06.110941 15117 sgd_solver.cpp:294] Iteration 14040, lr = 0.02
I0526 02:44:12.509577 15117 solver.cpp:233] Iteration 14050, loss = 0.161669
I0526 02:44:12.509793 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.161669 (* 1 = 0.161669 loss)
I0526 02:44:12.509809 15117 sgd_solver.cpp:294] Iteration 14050, lr = 0.02
I0526 02:44:18.868655 15117 solver.cpp:233] Iteration 14060, loss = 0.196173
I0526 02:44:18.868726 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.196173 (* 1 = 0.196173 loss)
I0526 02:44:18.868738 15117 sgd_solver.cpp:294] Iteration 14060, lr = 0.02
I0526 02:44:25.197222 15117 solver.cpp:233] Iteration 14070, loss = 0.201478
I0526 02:44:25.197298 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.201478 (* 1 = 0.201478 loss)
I0526 02:44:25.197310 15117 sgd_solver.cpp:294] Iteration 14070, lr = 0.02
I0526 02:44:31.553122 15117 solver.cpp:233] Iteration 14080, loss = 0.173248
I0526 02:44:31.553196 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.173248 (* 1 = 0.173248 loss)
I0526 02:44:31.553210 15117 sgd_solver.cpp:294] Iteration 14080, lr = 0.02
I0526 02:44:37.915133 15117 solver.cpp:233] Iteration 14090, loss = 0.183198
I0526 02:44:37.915210 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.183198 (* 1 = 0.183198 loss)
I0526 02:44:37.915223 15117 sgd_solver.cpp:294] Iteration 14090, lr = 0.02
I0526 02:44:43.649034 15117 solver.cpp:342] Iteration 14100, Testing net (#0)
I0526 02:44:56.651603 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8285
I0526 02:44:56.651686 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.561588 (* 1 = 0.561588 loss)
I0526 02:44:57.249748 15117 solver.cpp:233] Iteration 14100, loss = 0.171256
I0526 02:44:57.249827 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.171256 (* 1 = 0.171256 loss)
I0526 02:44:57.249842 15117 sgd_solver.cpp:294] Iteration 14100, lr = 0.02
I0526 02:45:03.590266 15117 solver.cpp:233] Iteration 14110, loss = 0.127355
I0526 02:45:03.590333 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.127355 (* 1 = 0.127355 loss)
I0526 02:45:03.590347 15117 sgd_solver.cpp:294] Iteration 14110, lr = 0.02
I0526 02:45:09.931836 15117 solver.cpp:233] Iteration 14120, loss = 0.220974
I0526 02:45:09.931902 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.220974 (* 1 = 0.220974 loss)
I0526 02:45:09.931913 15117 sgd_solver.cpp:294] Iteration 14120, lr = 0.02
I0526 02:45:16.280580 15117 solver.cpp:233] Iteration 14130, loss = 0.152945
I0526 02:45:16.294530 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.152945 (* 1 = 0.152945 loss)
I0526 02:45:16.294559 15117 sgd_solver.cpp:294] Iteration 14130, lr = 0.02
I0526 02:45:22.616755 15117 solver.cpp:233] Iteration 14140, loss = 0.161225
I0526 02:45:22.616881 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.161225 (* 1 = 0.161225 loss)
I0526 02:45:22.616904 15117 sgd_solver.cpp:294] Iteration 14140, lr = 0.02
I0526 02:45:28.965997 15117 solver.cpp:233] Iteration 14150, loss = 0.134853
I0526 02:45:28.966078 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.134853 (* 1 = 0.134853 loss)
I0526 02:45:28.966097 15117 sgd_solver.cpp:294] Iteration 14150, lr = 0.02
I0526 02:45:35.330823 15117 solver.cpp:233] Iteration 14160, loss = 0.168627
I0526 02:45:35.330914 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.168627 (* 1 = 0.168627 loss)
I0526 02:45:35.330929 15117 sgd_solver.cpp:294] Iteration 14160, lr = 0.02
I0526 02:45:41.662494 15117 solver.cpp:233] Iteration 14170, loss = 0.228066
I0526 02:45:41.662565 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.228066 (* 1 = 0.228066 loss)
I0526 02:45:41.662576 15117 sgd_solver.cpp:294] Iteration 14170, lr = 0.02
I0526 02:45:47.989703 15117 solver.cpp:233] Iteration 14180, loss = 0.19567
I0526 02:45:47.990010 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.19567 (* 1 = 0.19567 loss)
I0526 02:45:47.990039 15117 sgd_solver.cpp:294] Iteration 14180, lr = 0.02
I0526 02:45:54.335479 15117 solver.cpp:233] Iteration 14190, loss = 0.261804
I0526 02:45:54.335546 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.261804 (* 1 = 0.261804 loss)
I0526 02:45:54.335557 15117 sgd_solver.cpp:294] Iteration 14190, lr = 0.02
I0526 02:46:00.076342 15117 solver.cpp:342] Iteration 14200, Testing net (#0)
I0526 02:46:13.073971 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8394
I0526 02:46:13.074048 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.550797 (* 1 = 0.550797 loss)
I0526 02:46:13.675540 15117 solver.cpp:233] Iteration 14200, loss = 0.186981
I0526 02:46:13.675611 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.186981 (* 1 = 0.186981 loss)
I0526 02:46:13.675626 15117 sgd_solver.cpp:294] Iteration 14200, lr = 0.02
I0526 02:46:20.040473 15117 solver.cpp:233] Iteration 14210, loss = 0.227797
I0526 02:46:20.040638 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.227797 (* 1 = 0.227797 loss)
I0526 02:46:20.040652 15117 sgd_solver.cpp:294] Iteration 14210, lr = 0.02
I0526 02:46:26.395771 15117 solver.cpp:233] Iteration 14220, loss = 0.145944
I0526 02:46:26.395846 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.145944 (* 1 = 0.145944 loss)
I0526 02:46:26.395859 15117 sgd_solver.cpp:294] Iteration 14220, lr = 0.02
I0526 02:46:32.766227 15117 solver.cpp:233] Iteration 14230, loss = 0.231065
I0526 02:46:32.766300 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.231065 (* 1 = 0.231065 loss)
I0526 02:46:32.766314 15117 sgd_solver.cpp:294] Iteration 14230, lr = 0.02
I0526 02:46:39.099501 15117 solver.cpp:233] Iteration 14240, loss = 0.187875
I0526 02:46:39.099570 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.187875 (* 1 = 0.187875 loss)
I0526 02:46:39.099581 15117 sgd_solver.cpp:294] Iteration 14240, lr = 0.02
I0526 02:46:45.444432 15117 solver.cpp:233] Iteration 14250, loss = 0.168724
I0526 02:46:45.444505 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.168724 (* 1 = 0.168724 loss)
I0526 02:46:45.444517 15117 sgd_solver.cpp:294] Iteration 14250, lr = 0.02
I0526 02:46:51.782769 15117 solver.cpp:233] Iteration 14260, loss = 0.189248
I0526 02:46:51.783007 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.189248 (* 1 = 0.189248 loss)
I0526 02:46:51.783032 15117 sgd_solver.cpp:294] Iteration 14260, lr = 0.02
I0526 02:46:58.123865 15117 solver.cpp:233] Iteration 14270, loss = 0.316196
I0526 02:46:58.123937 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.316196 (* 1 = 0.316196 loss)
I0526 02:46:58.123950 15117 sgd_solver.cpp:294] Iteration 14270, lr = 0.02
I0526 02:47:04.480075 15117 solver.cpp:233] Iteration 14280, loss = 0.258292
I0526 02:47:04.480149 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.258292 (* 1 = 0.258292 loss)
I0526 02:47:04.480161 15117 sgd_solver.cpp:294] Iteration 14280, lr = 0.02
I0526 02:47:10.825152 15117 solver.cpp:233] Iteration 14290, loss = 0.0929108
I0526 02:47:10.825224 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0929108 (* 1 = 0.0929108 loss)
I0526 02:47:10.825248 15117 sgd_solver.cpp:294] Iteration 14290, lr = 0.02
I0526 02:47:16.576800 15117 solver.cpp:342] Iteration 14300, Testing net (#0)
I0526 02:47:29.581773 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7925
I0526 02:47:29.581980 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.720834 (* 1 = 0.720834 loss)
I0526 02:47:30.183665 15117 solver.cpp:233] Iteration 14300, loss = 0.290273
I0526 02:47:30.183737 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.290273 (* 1 = 0.290273 loss)
I0526 02:47:30.183751 15117 sgd_solver.cpp:294] Iteration 14300, lr = 0.02
I0526 02:47:36.526971 15117 solver.cpp:233] Iteration 14310, loss = 0.165387
I0526 02:47:36.527040 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.165387 (* 1 = 0.165387 loss)
I0526 02:47:36.527050 15117 sgd_solver.cpp:294] Iteration 14310, lr = 0.02
I0526 02:47:42.869396 15117 solver.cpp:233] Iteration 14320, loss = 0.209052
I0526 02:47:42.869470 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.209052 (* 1 = 0.209052 loss)
I0526 02:47:42.869482 15117 sgd_solver.cpp:294] Iteration 14320, lr = 0.02
I0526 02:47:49.228796 15117 solver.cpp:233] Iteration 14330, loss = 0.200895
I0526 02:47:49.228871 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.200895 (* 1 = 0.200895 loss)
I0526 02:47:49.228885 15117 sgd_solver.cpp:294] Iteration 14330, lr = 0.02
I0526 02:47:55.606616 15117 solver.cpp:233] Iteration 14340, loss = 0.179936
I0526 02:47:55.606690 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.179936 (* 1 = 0.179936 loss)
I0526 02:47:55.606703 15117 sgd_solver.cpp:294] Iteration 14340, lr = 0.02
I0526 02:48:01.955307 15117 solver.cpp:233] Iteration 14350, loss = 0.28256
I0526 02:48:01.955468 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.28256 (* 1 = 0.28256 loss)
I0526 02:48:01.955482 15117 sgd_solver.cpp:294] Iteration 14350, lr = 0.02
I0526 02:48:08.306128 15117 solver.cpp:233] Iteration 14360, loss = 0.303627
I0526 02:48:08.306213 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.303627 (* 1 = 0.303627 loss)
I0526 02:48:08.306231 15117 sgd_solver.cpp:294] Iteration 14360, lr = 0.02
I0526 02:48:14.650295 15117 solver.cpp:233] Iteration 14370, loss = 0.249017
I0526 02:48:14.650384 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.249017 (* 1 = 0.249017 loss)
I0526 02:48:14.650398 15117 sgd_solver.cpp:294] Iteration 14370, lr = 0.02
I0526 02:48:21.000365 15117 solver.cpp:233] Iteration 14380, loss = 0.135673
I0526 02:48:21.000430 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.135673 (* 1 = 0.135673 loss)
I0526 02:48:21.000442 15117 sgd_solver.cpp:294] Iteration 14380, lr = 0.02
I0526 02:48:27.349529 15117 solver.cpp:233] Iteration 14390, loss = 0.194431
I0526 02:48:27.349624 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.194431 (* 1 = 0.194431 loss)
I0526 02:48:27.349639 15117 sgd_solver.cpp:294] Iteration 14390, lr = 0.02
I0526 02:48:33.071244 15117 solver.cpp:342] Iteration 14400, Testing net (#0)
I0526 02:48:46.032902 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8336
I0526 02:48:46.032966 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.557636 (* 1 = 0.557636 loss)
I0526 02:48:46.631121 15117 solver.cpp:233] Iteration 14400, loss = 0.252648
I0526 02:48:46.631191 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.252648 (* 1 = 0.252648 loss)
I0526 02:48:46.631206 15117 sgd_solver.cpp:294] Iteration 14400, lr = 0.02
I0526 02:48:52.969650 15117 solver.cpp:233] Iteration 14410, loss = 0.21792
I0526 02:48:52.969719 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.21792 (* 1 = 0.21792 loss)
I0526 02:48:52.969732 15117 sgd_solver.cpp:294] Iteration 14410, lr = 0.02
I0526 02:48:59.315001 15117 solver.cpp:233] Iteration 14420, loss = 0.209155
I0526 02:48:59.315075 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.209155 (* 1 = 0.209155 loss)
I0526 02:48:59.315096 15117 sgd_solver.cpp:294] Iteration 14420, lr = 0.02
I0526 02:49:05.661602 15117 solver.cpp:233] Iteration 14430, loss = 0.156311
I0526 02:49:05.661763 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.156311 (* 1 = 0.156311 loss)
I0526 02:49:05.661777 15117 sgd_solver.cpp:294] Iteration 14430, lr = 0.02
I0526 02:49:12.000983 15117 solver.cpp:233] Iteration 14440, loss = 0.142819
I0526 02:49:12.001055 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.142819 (* 1 = 0.142819 loss)
I0526 02:49:12.001067 15117 sgd_solver.cpp:294] Iteration 14440, lr = 0.02
I0526 02:49:18.345423 15117 solver.cpp:233] Iteration 14450, loss = 0.18716
I0526 02:49:18.345487 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.18716 (* 1 = 0.18716 loss)
I0526 02:49:18.345500 15117 sgd_solver.cpp:294] Iteration 14450, lr = 0.02
I0526 02:49:24.676800 15117 solver.cpp:233] Iteration 14460, loss = 0.117889
I0526 02:49:24.676874 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.117889 (* 1 = 0.117889 loss)
I0526 02:49:24.676887 15117 sgd_solver.cpp:294] Iteration 14460, lr = 0.02
I0526 02:49:31.013427 15117 solver.cpp:233] Iteration 14470, loss = 0.240822
I0526 02:49:31.013499 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.240822 (* 1 = 0.240822 loss)
I0526 02:49:31.013510 15117 sgd_solver.cpp:294] Iteration 14470, lr = 0.02
I0526 02:49:37.343585 15117 solver.cpp:233] Iteration 14480, loss = 0.188134
I0526 02:49:37.343824 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.188134 (* 1 = 0.188134 loss)
I0526 02:49:37.343852 15117 sgd_solver.cpp:294] Iteration 14480, lr = 0.02
I0526 02:49:43.693516 15117 solver.cpp:233] Iteration 14490, loss = 0.129118
I0526 02:49:43.693595 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.129118 (* 1 = 0.129118 loss)
I0526 02:49:43.693608 15117 sgd_solver.cpp:294] Iteration 14490, lr = 0.02
I0526 02:49:49.423880 15117 solver.cpp:342] Iteration 14500, Testing net (#0)
I0526 02:50:02.401716 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7603
I0526 02:50:02.401787 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.890061 (* 1 = 0.890061 loss)
I0526 02:50:03.003119 15117 solver.cpp:233] Iteration 14500, loss = 0.112009
I0526 02:50:03.003187 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.112009 (* 1 = 0.112009 loss)
I0526 02:50:03.003201 15117 sgd_solver.cpp:294] Iteration 14500, lr = 0.02
I0526 02:50:09.348500 15117 solver.cpp:233] Iteration 14510, loss = 0.143449
I0526 02:50:09.348738 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.143449 (* 1 = 0.143449 loss)
I0526 02:50:09.348767 15117 sgd_solver.cpp:294] Iteration 14510, lr = 0.02
I0526 02:50:15.698956 15117 solver.cpp:233] Iteration 14520, loss = 0.19729
I0526 02:50:15.699025 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.19729 (* 1 = 0.19729 loss)
I0526 02:50:15.699036 15117 sgd_solver.cpp:294] Iteration 14520, lr = 0.02
I0526 02:50:22.048349 15117 solver.cpp:233] Iteration 14530, loss = 0.233734
I0526 02:50:22.048418 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.233734 (* 1 = 0.233734 loss)
I0526 02:50:22.048429 15117 sgd_solver.cpp:294] Iteration 14530, lr = 0.02
I0526 02:50:28.389602 15117 solver.cpp:233] Iteration 14540, loss = 0.242119
I0526 02:50:28.389670 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.242119 (* 1 = 0.242119 loss)
I0526 02:50:28.389683 15117 sgd_solver.cpp:294] Iteration 14540, lr = 0.02
I0526 02:50:34.749550 15117 solver.cpp:233] Iteration 14550, loss = 0.15351
I0526 02:50:34.749627 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.15351 (* 1 = 0.15351 loss)
I0526 02:50:34.749641 15117 sgd_solver.cpp:294] Iteration 14550, lr = 0.02
I0526 02:50:41.118566 15117 solver.cpp:233] Iteration 14560, loss = 0.231913
I0526 02:50:41.118744 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.231913 (* 1 = 0.231913 loss)
I0526 02:50:41.118764 15117 sgd_solver.cpp:294] Iteration 14560, lr = 0.02
I0526 02:50:47.491021 15117 solver.cpp:233] Iteration 14570, loss = 0.215023
I0526 02:50:47.491097 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.215023 (* 1 = 0.215023 loss)
I0526 02:50:47.491111 15117 sgd_solver.cpp:294] Iteration 14570, lr = 0.02
I0526 02:50:53.831957 15117 solver.cpp:233] Iteration 14580, loss = 0.203382
I0526 02:50:53.832036 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.203382 (* 1 = 0.203382 loss)
I0526 02:50:53.832047 15117 sgd_solver.cpp:294] Iteration 14580, lr = 0.02
I0526 02:51:00.186429 15117 solver.cpp:233] Iteration 14590, loss = 0.172031
I0526 02:51:00.186501 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.172031 (* 1 = 0.172031 loss)
I0526 02:51:00.186512 15117 sgd_solver.cpp:294] Iteration 14590, lr = 0.02
I0526 02:51:05.925760 15117 solver.cpp:342] Iteration 14600, Testing net (#0)
I0526 02:51:18.909546 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7628
I0526 02:51:18.909728 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.83195 (* 1 = 0.83195 loss)
I0526 02:51:19.515413 15117 solver.cpp:233] Iteration 14600, loss = 0.127295
I0526 02:51:19.515485 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.127295 (* 1 = 0.127295 loss)
I0526 02:51:19.515498 15117 sgd_solver.cpp:294] Iteration 14600, lr = 0.02
I0526 02:51:25.861368 15117 solver.cpp:233] Iteration 14610, loss = 0.179275
I0526 02:51:25.861443 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.179275 (* 1 = 0.179275 loss)
I0526 02:51:25.861455 15117 sgd_solver.cpp:294] Iteration 14610, lr = 0.02
I0526 02:51:32.229084 15117 solver.cpp:233] Iteration 14620, loss = 0.180453
I0526 02:51:32.229163 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.180453 (* 1 = 0.180453 loss)
I0526 02:51:32.229176 15117 sgd_solver.cpp:294] Iteration 14620, lr = 0.02
I0526 02:51:38.591284 15117 solver.cpp:233] Iteration 14630, loss = 0.256626
I0526 02:51:38.591353 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.256626 (* 1 = 0.256626 loss)
I0526 02:51:38.591364 15117 sgd_solver.cpp:294] Iteration 14630, lr = 0.02
I0526 02:51:44.958206 15117 solver.cpp:233] Iteration 14640, loss = 0.174096
I0526 02:51:44.958284 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.174096 (* 1 = 0.174096 loss)
I0526 02:51:44.958297 15117 sgd_solver.cpp:294] Iteration 14640, lr = 0.02
I0526 02:51:51.310309 15117 solver.cpp:233] Iteration 14650, loss = 0.190775
I0526 02:51:51.310596 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.190775 (* 1 = 0.190775 loss)
I0526 02:51:51.310626 15117 sgd_solver.cpp:294] Iteration 14650, lr = 0.02
I0526 02:51:57.652505 15117 solver.cpp:233] Iteration 14660, loss = 0.133493
I0526 02:51:57.652580 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.133493 (* 1 = 0.133493 loss)
I0526 02:51:57.652595 15117 sgd_solver.cpp:294] Iteration 14660, lr = 0.02
I0526 02:52:04.004156 15117 solver.cpp:233] Iteration 14670, loss = 0.163808
I0526 02:52:04.004232 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.163808 (* 1 = 0.163808 loss)
I0526 02:52:04.004245 15117 sgd_solver.cpp:294] Iteration 14670, lr = 0.02
I0526 02:52:10.345043 15117 solver.cpp:233] Iteration 14680, loss = 0.149573
I0526 02:52:10.345111 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.149573 (* 1 = 0.149573 loss)
I0526 02:52:10.345124 15117 sgd_solver.cpp:294] Iteration 14680, lr = 0.02
I0526 02:52:16.703382 15117 solver.cpp:233] Iteration 14690, loss = 0.118992
I0526 02:52:16.703459 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.118992 (* 1 = 0.118992 loss)
I0526 02:52:16.703472 15117 sgd_solver.cpp:294] Iteration 14690, lr = 0.02
I0526 02:52:22.453399 15117 solver.cpp:342] Iteration 14700, Testing net (#0)
I0526 02:52:35.453409 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.844
I0526 02:52:35.453490 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.510338 (* 1 = 0.510338 loss)
I0526 02:52:36.057546 15117 solver.cpp:233] Iteration 14700, loss = 0.211878
I0526 02:52:36.057617 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.211878 (* 1 = 0.211878 loss)
I0526 02:52:36.057633 15117 sgd_solver.cpp:294] Iteration 14700, lr = 0.02
I0526 02:52:42.413734 15117 solver.cpp:233] Iteration 14710, loss = 0.188463
I0526 02:52:42.413827 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.188463 (* 1 = 0.188463 loss)
I0526 02:52:42.413842 15117 sgd_solver.cpp:294] Iteration 14710, lr = 0.02
I0526 02:52:48.747068 15117 solver.cpp:233] Iteration 14720, loss = 0.224261
I0526 02:52:48.747138 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.224261 (* 1 = 0.224261 loss)
I0526 02:52:48.747148 15117 sgd_solver.cpp:294] Iteration 14720, lr = 0.02
I0526 02:52:55.096374 15117 solver.cpp:233] Iteration 14730, loss = 0.190052
I0526 02:52:55.096503 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.190052 (* 1 = 0.190052 loss)
I0526 02:52:55.096515 15117 sgd_solver.cpp:294] Iteration 14730, lr = 0.02
I0526 02:53:01.434105 15117 solver.cpp:233] Iteration 14740, loss = 0.283816
I0526 02:53:01.434181 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.283816 (* 1 = 0.283816 loss)
I0526 02:53:01.434193 15117 sgd_solver.cpp:294] Iteration 14740, lr = 0.02
I0526 02:53:07.808652 15117 solver.cpp:233] Iteration 14750, loss = 0.232007
I0526 02:53:07.808724 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.232007 (* 1 = 0.232007 loss)
I0526 02:53:07.808735 15117 sgd_solver.cpp:294] Iteration 14750, lr = 0.02
I0526 02:53:14.162088 15117 solver.cpp:233] Iteration 14760, loss = 0.206451
I0526 02:53:14.162170 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.206451 (* 1 = 0.206451 loss)
I0526 02:53:14.162184 15117 sgd_solver.cpp:294] Iteration 14760, lr = 0.02
I0526 02:53:20.511093 15117 solver.cpp:233] Iteration 14770, loss = 0.300023
I0526 02:53:20.511157 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.300023 (* 1 = 0.300023 loss)
I0526 02:53:20.511168 15117 sgd_solver.cpp:294] Iteration 14770, lr = 0.02
I0526 02:53:26.873944 15117 solver.cpp:233] Iteration 14780, loss = 0.169042
I0526 02:53:26.874199 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.169042 (* 1 = 0.169042 loss)
I0526 02:53:26.874228 15117 sgd_solver.cpp:294] Iteration 14780, lr = 0.02
I0526 02:53:33.238106 15117 solver.cpp:233] Iteration 14790, loss = 0.233388
I0526 02:53:33.238183 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.233388 (* 1 = 0.233388 loss)
I0526 02:53:33.238196 15117 sgd_solver.cpp:294] Iteration 14790, lr = 0.02
I0526 02:53:38.991433 15117 solver.cpp:342] Iteration 14800, Testing net (#0)
I0526 02:53:52.016463 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7947
I0526 02:53:52.016536 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.809018 (* 1 = 0.809018 loss)
I0526 02:53:52.622262 15117 solver.cpp:233] Iteration 14800, loss = 0.191368
I0526 02:53:52.622329 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.191368 (* 1 = 0.191368 loss)
I0526 02:53:52.622344 15117 sgd_solver.cpp:294] Iteration 14800, lr = 0.02
I0526 02:53:58.959591 15117 solver.cpp:233] Iteration 14810, loss = 0.15952
I0526 02:53:58.959790 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.15952 (* 1 = 0.15952 loss)
I0526 02:53:58.959811 15117 sgd_solver.cpp:294] Iteration 14810, lr = 0.02
I0526 02:54:05.319856 15117 solver.cpp:233] Iteration 14820, loss = 0.260221
I0526 02:54:05.319924 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.260221 (* 1 = 0.260221 loss)
I0526 02:54:05.319936 15117 sgd_solver.cpp:294] Iteration 14820, lr = 0.02
I0526 02:54:11.667279 15117 solver.cpp:233] Iteration 14830, loss = 0.235887
I0526 02:54:11.667341 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.235887 (* 1 = 0.235887 loss)
I0526 02:54:11.667361 15117 sgd_solver.cpp:294] Iteration 14830, lr = 0.02
I0526 02:54:18.026166 15117 solver.cpp:233] Iteration 14840, loss = 0.192546
I0526 02:54:18.026238 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.192546 (* 1 = 0.192546 loss)
I0526 02:54:18.026249 15117 sgd_solver.cpp:294] Iteration 14840, lr = 0.02
I0526 02:54:24.399364 15117 solver.cpp:233] Iteration 14850, loss = 0.17492
I0526 02:54:24.399436 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.17492 (* 1 = 0.17492 loss)
I0526 02:54:24.399449 15117 sgd_solver.cpp:294] Iteration 14850, lr = 0.02
I0526 02:54:30.741828 15117 solver.cpp:233] Iteration 14860, loss = 0.252776
I0526 02:54:30.742084 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.252776 (* 1 = 0.252776 loss)
I0526 02:54:30.742100 15117 sgd_solver.cpp:294] Iteration 14860, lr = 0.02
I0526 02:54:37.094635 15117 solver.cpp:233] Iteration 14870, loss = 0.265029
I0526 02:54:37.094714 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.265029 (* 1 = 0.265029 loss)
I0526 02:54:37.094728 15117 sgd_solver.cpp:294] Iteration 14870, lr = 0.02
I0526 02:54:43.418467 15117 solver.cpp:233] Iteration 14880, loss = 0.124811
I0526 02:54:43.418540 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.124811 (* 1 = 0.124811 loss)
I0526 02:54:43.418550 15117 sgd_solver.cpp:294] Iteration 14880, lr = 0.02
I0526 02:54:49.765945 15117 solver.cpp:233] Iteration 14890, loss = 0.160173
I0526 02:54:49.766021 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.160173 (* 1 = 0.160173 loss)
I0526 02:54:49.766033 15117 sgd_solver.cpp:294] Iteration 14890, lr = 0.02
I0526 02:54:55.524236 15117 solver.cpp:342] Iteration 14900, Testing net (#0)
I0526 02:55:08.514889 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7478
I0526 02:55:08.515125 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.993206 (* 1 = 0.993206 loss)
I0526 02:55:09.116978 15117 solver.cpp:233] Iteration 14900, loss = 0.121876
I0526 02:55:09.117059 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.121876 (* 1 = 0.121876 loss)
I0526 02:55:09.117079 15117 sgd_solver.cpp:294] Iteration 14900, lr = 0.02
I0526 02:55:15.468049 15117 solver.cpp:233] Iteration 14910, loss = 0.165592
I0526 02:55:15.468118 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.165592 (* 1 = 0.165592 loss)
I0526 02:55:15.468130 15117 sgd_solver.cpp:294] Iteration 14910, lr = 0.02
I0526 02:55:21.837360 15117 solver.cpp:233] Iteration 14920, loss = 0.27951
I0526 02:55:21.837430 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.279511 (* 1 = 0.279511 loss)
I0526 02:55:21.837441 15117 sgd_solver.cpp:294] Iteration 14920, lr = 0.02
I0526 02:55:28.183629 15117 solver.cpp:233] Iteration 14930, loss = 0.213495
I0526 02:55:28.183706 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.213495 (* 1 = 0.213495 loss)
I0526 02:55:28.183719 15117 sgd_solver.cpp:294] Iteration 14930, lr = 0.02
I0526 02:55:34.517364 15117 solver.cpp:233] Iteration 14940, loss = 0.186503
I0526 02:55:34.517436 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.186503 (* 1 = 0.186503 loss)
I0526 02:55:34.517447 15117 sgd_solver.cpp:294] Iteration 14940, lr = 0.02
I0526 02:55:40.865118 15117 solver.cpp:233] Iteration 14950, loss = 0.185172
I0526 02:55:40.865341 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.185172 (* 1 = 0.185172 loss)
I0526 02:55:40.865371 15117 sgd_solver.cpp:294] Iteration 14950, lr = 0.02
I0526 02:55:47.201241 15117 solver.cpp:233] Iteration 14960, loss = 0.145525
I0526 02:55:47.201318 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.145525 (* 1 = 0.145525 loss)
I0526 02:55:47.201330 15117 sgd_solver.cpp:294] Iteration 14960, lr = 0.02
I0526 02:55:53.547920 15117 solver.cpp:233] Iteration 14970, loss = 0.130233
I0526 02:55:53.547989 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.130233 (* 1 = 0.130233 loss)
I0526 02:55:53.548002 15117 sgd_solver.cpp:294] Iteration 14970, lr = 0.02
I0526 02:55:59.904371 15117 solver.cpp:233] Iteration 14980, loss = 0.198782
I0526 02:55:59.904436 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.198783 (* 1 = 0.198783 loss)
I0526 02:55:59.904448 15117 sgd_solver.cpp:294] Iteration 14980, lr = 0.02
I0526 02:56:06.210183 15117 solver.cpp:233] Iteration 14990, loss = 0.101864
I0526 02:56:06.210270 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.101864 (* 1 = 0.101864 loss)
I0526 02:56:06.210288 15117 sgd_solver.cpp:294] Iteration 14990, lr = 0.02
I0526 02:56:11.947484 15117 solver.cpp:342] Iteration 15000, Testing net (#0)
I0526 02:56:24.922271 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7625
I0526 02:56:24.922350 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.885776 (* 1 = 0.885776 loss)
I0526 02:56:25.522555 15117 solver.cpp:233] Iteration 15000, loss = 0.213394
I0526 02:56:25.522619 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.213394 (* 1 = 0.213394 loss)
I0526 02:56:25.522634 15117 sgd_solver.cpp:294] Iteration 15000, lr = 0.02
I0526 02:56:31.866264 15117 solver.cpp:233] Iteration 15010, loss = 0.22756
I0526 02:56:31.866335 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.22756 (* 1 = 0.22756 loss)
I0526 02:56:31.866348 15117 sgd_solver.cpp:294] Iteration 15010, lr = 0.02
I0526 02:56:38.219722 15117 solver.cpp:233] Iteration 15020, loss = 0.132167
I0526 02:56:38.219792 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.132167 (* 1 = 0.132167 loss)
I0526 02:56:38.219805 15117 sgd_solver.cpp:294] Iteration 15020, lr = 0.02
I0526 02:56:44.584717 15117 solver.cpp:233] Iteration 15030, loss = 0.176496
I0526 02:56:44.584965 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.176496 (* 1 = 0.176496 loss)
I0526 02:56:44.584995 15117 sgd_solver.cpp:294] Iteration 15030, lr = 0.02
I0526 02:56:50.926391 15117 solver.cpp:233] Iteration 15040, loss = 0.208982
I0526 02:56:50.926461 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.208982 (* 1 = 0.208982 loss)
I0526 02:56:50.926473 15117 sgd_solver.cpp:294] Iteration 15040, lr = 0.02
I0526 02:56:57.276368 15117 solver.cpp:233] Iteration 15050, loss = 0.19535
I0526 02:56:57.276485 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.19535 (* 1 = 0.19535 loss)
I0526 02:56:57.276511 15117 sgd_solver.cpp:294] Iteration 15050, lr = 0.02
I0526 02:57:03.616598 15117 solver.cpp:233] Iteration 15060, loss = 0.164947
I0526 02:57:03.616672 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.164947 (* 1 = 0.164947 loss)
I0526 02:57:03.616684 15117 sgd_solver.cpp:294] Iteration 15060, lr = 0.02
I0526 02:57:09.956624 15117 solver.cpp:233] Iteration 15070, loss = 0.132833
I0526 02:57:09.956692 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.132833 (* 1 = 0.132833 loss)
I0526 02:57:09.956706 15117 sgd_solver.cpp:294] Iteration 15070, lr = 0.02
I0526 02:57:16.297143 15117 solver.cpp:233] Iteration 15080, loss = 0.157053
I0526 02:57:16.297296 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.157053 (* 1 = 0.157053 loss)
I0526 02:57:16.297308 15117 sgd_solver.cpp:294] Iteration 15080, lr = 0.02
I0526 02:57:22.633533 15117 solver.cpp:233] Iteration 15090, loss = 0.172528
I0526 02:57:22.633606 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.172528 (* 1 = 0.172528 loss)
I0526 02:57:22.633620 15117 sgd_solver.cpp:294] Iteration 15090, lr = 0.02
I0526 02:57:28.376525 15117 solver.cpp:342] Iteration 15100, Testing net (#0)
I0526 02:57:41.344408 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.6963
I0526 02:57:41.344483 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.28394 (* 1 = 1.28394 loss)
I0526 02:57:41.949342 15117 solver.cpp:233] Iteration 15100, loss = 0.226179
I0526 02:57:41.949419 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.226179 (* 1 = 0.226179 loss)
I0526 02:57:41.949434 15117 sgd_solver.cpp:294] Iteration 15100, lr = 0.02
I0526 02:57:48.287883 15117 solver.cpp:233] Iteration 15110, loss = 0.174327
I0526 02:57:48.288213 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.174327 (* 1 = 0.174327 loss)
I0526 02:57:48.288262 15117 sgd_solver.cpp:294] Iteration 15110, lr = 0.02
I0526 02:57:54.613939 15117 solver.cpp:233] Iteration 15120, loss = 0.195156
I0526 02:57:54.614006 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.195156 (* 1 = 0.195156 loss)
I0526 02:57:54.614018 15117 sgd_solver.cpp:294] Iteration 15120, lr = 0.02
I0526 02:58:00.954185 15117 solver.cpp:233] Iteration 15130, loss = 0.237835
I0526 02:58:00.954254 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.237835 (* 1 = 0.237835 loss)
I0526 02:58:00.954267 15117 sgd_solver.cpp:294] Iteration 15130, lr = 0.02
I0526 02:58:07.284071 15117 solver.cpp:233] Iteration 15140, loss = 0.0848579
I0526 02:58:07.284147 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.084858 (* 1 = 0.084858 loss)
I0526 02:58:07.284159 15117 sgd_solver.cpp:294] Iteration 15140, lr = 0.02
I0526 02:58:13.623026 15117 solver.cpp:233] Iteration 15150, loss = 0.167246
I0526 02:58:13.623105 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.167246 (* 1 = 0.167246 loss)
I0526 02:58:13.623116 15117 sgd_solver.cpp:294] Iteration 15150, lr = 0.02
I0526 02:58:19.954339 15117 solver.cpp:233] Iteration 15160, loss = 0.195593
I0526 02:58:19.954635 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.195593 (* 1 = 0.195593 loss)
I0526 02:58:19.954670 15117 sgd_solver.cpp:294] Iteration 15160, lr = 0.02
I0526 02:58:26.289850 15117 solver.cpp:233] Iteration 15170, loss = 0.18758
I0526 02:58:26.289927 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.18758 (* 1 = 0.18758 loss)
I0526 02:58:26.289939 15117 sgd_solver.cpp:294] Iteration 15170, lr = 0.02
I0526 02:58:32.623220 15117 solver.cpp:233] Iteration 15180, loss = 0.209354
I0526 02:58:32.623302 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.209354 (* 1 = 0.209354 loss)
I0526 02:58:32.623317 15117 sgd_solver.cpp:294] Iteration 15180, lr = 0.02
I0526 02:58:38.987970 15117 solver.cpp:233] Iteration 15190, loss = 0.14374
I0526 02:58:38.988061 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.14374 (* 1 = 0.14374 loss)
I0526 02:58:38.988077 15117 sgd_solver.cpp:294] Iteration 15190, lr = 0.02
I0526 02:58:44.725847 15117 solver.cpp:342] Iteration 15200, Testing net (#0)
I0526 02:58:57.748430 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8043
I0526 02:58:57.748663 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.734554 (* 1 = 0.734554 loss)
I0526 02:58:58.347239 15117 solver.cpp:233] Iteration 15200, loss = 0.191019
I0526 02:58:58.347326 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.191019 (* 1 = 0.191019 loss)
I0526 02:58:58.347345 15117 sgd_solver.cpp:294] Iteration 15200, lr = 0.02
I0526 02:59:04.711657 15117 solver.cpp:233] Iteration 15210, loss = 0.22366
I0526 02:59:04.711733 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.22366 (* 1 = 0.22366 loss)
I0526 02:59:04.711746 15117 sgd_solver.cpp:294] Iteration 15210, lr = 0.02
I0526 02:59:11.061511 15117 solver.cpp:233] Iteration 15220, loss = 0.10996
I0526 02:59:11.061601 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.10996 (* 1 = 0.10996 loss)
I0526 02:59:11.061617 15117 sgd_solver.cpp:294] Iteration 15220, lr = 0.02
I0526 02:59:17.446892 15117 solver.cpp:233] Iteration 15230, loss = 0.210216
I0526 02:59:17.447013 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.210216 (* 1 = 0.210216 loss)
I0526 02:59:17.447029 15117 sgd_solver.cpp:294] Iteration 15230, lr = 0.02
I0526 02:59:23.809820 15117 solver.cpp:233] Iteration 15240, loss = 0.230437
I0526 02:59:23.809893 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.230438 (* 1 = 0.230438 loss)
I0526 02:59:23.809906 15117 sgd_solver.cpp:294] Iteration 15240, lr = 0.02
I0526 02:59:30.187711 15117 solver.cpp:233] Iteration 15250, loss = 0.144312
I0526 02:59:30.187970 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.144312 (* 1 = 0.144312 loss)
I0526 02:59:30.187994 15117 sgd_solver.cpp:294] Iteration 15250, lr = 0.02
I0526 02:59:36.542307 15117 solver.cpp:233] Iteration 15260, loss = 0.193953
I0526 02:59:36.542390 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.193953 (* 1 = 0.193953 loss)
I0526 02:59:36.542402 15117 sgd_solver.cpp:294] Iteration 15260, lr = 0.02
I0526 02:59:42.883343 15117 solver.cpp:233] Iteration 15270, loss = 0.16923
I0526 02:59:42.883421 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.16923 (* 1 = 0.16923 loss)
I0526 02:59:42.883435 15117 sgd_solver.cpp:294] Iteration 15270, lr = 0.02
I0526 02:59:49.269886 15117 solver.cpp:233] Iteration 15280, loss = 0.154222
I0526 02:59:49.269958 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.154222 (* 1 = 0.154222 loss)
I0526 02:59:49.269971 15117 sgd_solver.cpp:294] Iteration 15280, lr = 0.02
I0526 02:59:55.626058 15117 solver.cpp:233] Iteration 15290, loss = 0.263906
I0526 02:59:55.626132 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.263907 (* 1 = 0.263907 loss)
I0526 02:59:55.626143 15117 sgd_solver.cpp:294] Iteration 15290, lr = 0.02
I0526 03:00:01.387950 15117 solver.cpp:342] Iteration 15300, Testing net (#0)
I0526 03:00:14.422073 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7728
I0526 03:00:14.422149 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.808945 (* 1 = 0.808945 loss)
I0526 03:00:15.031577 15117 solver.cpp:233] Iteration 15300, loss = 0.278698
I0526 03:00:15.031651 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.278698 (* 1 = 0.278698 loss)
I0526 03:00:15.031664 15117 sgd_solver.cpp:294] Iteration 15300, lr = 0.02
I0526 03:00:21.391489 15117 solver.cpp:233] Iteration 15310, loss = 0.117531
I0526 03:00:21.391561 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.117531 (* 1 = 0.117531 loss)
I0526 03:00:21.391572 15117 sgd_solver.cpp:294] Iteration 15310, lr = 0.02
I0526 03:00:27.725600 15117 solver.cpp:233] Iteration 15320, loss = 0.152133
I0526 03:00:27.725673 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.152133 (* 1 = 0.152133 loss)
I0526 03:00:27.725687 15117 sgd_solver.cpp:294] Iteration 15320, lr = 0.02
I0526 03:00:34.073424 15117 solver.cpp:233] Iteration 15330, loss = 0.171635
I0526 03:00:34.073664 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.171635 (* 1 = 0.171635 loss)
I0526 03:00:34.073693 15117 sgd_solver.cpp:294] Iteration 15330, lr = 0.02
I0526 03:00:40.399247 15117 solver.cpp:233] Iteration 15340, loss = 0.285798
I0526 03:00:40.399312 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.285798 (* 1 = 0.285798 loss)
I0526 03:00:40.399323 15117 sgd_solver.cpp:294] Iteration 15340, lr = 0.02
I0526 03:00:46.739213 15117 solver.cpp:233] Iteration 15350, loss = 0.125412
I0526 03:00:46.739289 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.125412 (* 1 = 0.125412 loss)
I0526 03:00:46.739302 15117 sgd_solver.cpp:294] Iteration 15350, lr = 0.02
I0526 03:00:53.093163 15117 solver.cpp:233] Iteration 15360, loss = 0.209341
I0526 03:00:53.093232 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.209341 (* 1 = 0.209341 loss)
I0526 03:00:53.093245 15117 sgd_solver.cpp:294] Iteration 15360, lr = 0.02
I0526 03:00:59.444720 15117 solver.cpp:233] Iteration 15370, loss = 0.151163
I0526 03:00:59.444789 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.151163 (* 1 = 0.151163 loss)
I0526 03:00:59.444802 15117 sgd_solver.cpp:294] Iteration 15370, lr = 0.02
I0526 03:01:05.797858 15117 solver.cpp:233] Iteration 15380, loss = 0.196676
I0526 03:01:05.798008 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.196676 (* 1 = 0.196676 loss)
I0526 03:01:05.798022 15117 sgd_solver.cpp:294] Iteration 15380, lr = 0.02
I0526 03:01:12.143623 15117 solver.cpp:233] Iteration 15390, loss = 0.173367
I0526 03:01:12.143704 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.173367 (* 1 = 0.173367 loss)
I0526 03:01:12.143717 15117 sgd_solver.cpp:294] Iteration 15390, lr = 0.02
I0526 03:01:17.884982 15117 solver.cpp:342] Iteration 15400, Testing net (#0)
I0526 03:01:30.846720 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8113
I0526 03:01:30.846807 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.664901 (* 1 = 0.664901 loss)
I0526 03:01:31.448112 15117 solver.cpp:233] Iteration 15400, loss = 0.174119
I0526 03:01:31.448180 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.174119 (* 1 = 0.174119 loss)
I0526 03:01:31.448194 15117 sgd_solver.cpp:294] Iteration 15400, lr = 0.02
I0526 03:01:37.798446 15117 solver.cpp:233] Iteration 15410, loss = 0.162313
I0526 03:01:37.798741 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.162313 (* 1 = 0.162313 loss)
I0526 03:01:37.798770 15117 sgd_solver.cpp:294] Iteration 15410, lr = 0.02
I0526 03:01:44.144140 15117 solver.cpp:233] Iteration 15420, loss = 0.168223
I0526 03:01:44.144208 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.168223 (* 1 = 0.168223 loss)
I0526 03:01:44.144220 15117 sgd_solver.cpp:294] Iteration 15420, lr = 0.02
I0526 03:01:50.499384 15117 solver.cpp:233] Iteration 15430, loss = 0.118952
I0526 03:01:50.499454 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.118952 (* 1 = 0.118952 loss)
I0526 03:01:50.499466 15117 sgd_solver.cpp:294] Iteration 15430, lr = 0.02
I0526 03:01:56.828588 15117 solver.cpp:233] Iteration 15440, loss = 0.0993726
I0526 03:01:56.828650 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0993727 (* 1 = 0.0993727 loss)
I0526 03:01:56.828661 15117 sgd_solver.cpp:294] Iteration 15440, lr = 0.02
I0526 03:02:03.148931 15117 solver.cpp:233] Iteration 15450, loss = 0.138259
I0526 03:02:03.148985 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.138259 (* 1 = 0.138259 loss)
I0526 03:02:03.148994 15117 sgd_solver.cpp:294] Iteration 15450, lr = 0.02
I0526 03:02:09.470527 15117 solver.cpp:233] Iteration 15460, loss = 0.119767
I0526 03:02:09.470791 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.119767 (* 1 = 0.119767 loss)
I0526 03:02:09.470820 15117 sgd_solver.cpp:294] Iteration 15460, lr = 0.02
I0526 03:02:15.808913 15117 solver.cpp:233] Iteration 15470, loss = 0.186988
I0526 03:02:15.808985 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.186988 (* 1 = 0.186988 loss)
I0526 03:02:15.808997 15117 sgd_solver.cpp:294] Iteration 15470, lr = 0.02
I0526 03:02:22.137626 15117 solver.cpp:233] Iteration 15480, loss = 0.0919228
I0526 03:02:22.137714 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0919229 (* 1 = 0.0919229 loss)
I0526 03:02:22.137727 15117 sgd_solver.cpp:294] Iteration 15480, lr = 0.02
I0526 03:02:28.478387 15117 solver.cpp:233] Iteration 15490, loss = 0.162448
I0526 03:02:28.478454 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.162448 (* 1 = 0.162448 loss)
I0526 03:02:28.478466 15117 sgd_solver.cpp:294] Iteration 15490, lr = 0.02
I0526 03:02:34.219861 15117 solver.cpp:342] Iteration 15500, Testing net (#0)
I0526 03:02:47.081269 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.6717
I0526 03:02:47.081396 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.51695 (* 1 = 1.51695 loss)
I0526 03:02:47.681440 15117 solver.cpp:233] Iteration 15500, loss = 0.163409
I0526 03:02:47.681493 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.163409 (* 1 = 0.163409 loss)
I0526 03:02:47.681502 15117 sgd_solver.cpp:294] Iteration 15500, lr = 0.02
I0526 03:02:53.997366 15117 solver.cpp:233] Iteration 15510, loss = 0.138445
I0526 03:02:53.997424 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.138445 (* 1 = 0.138445 loss)
I0526 03:02:53.997434 15117 sgd_solver.cpp:294] Iteration 15510, lr = 0.02
I0526 03:03:00.310739 15117 solver.cpp:233] Iteration 15520, loss = 0.129654
I0526 03:03:00.310799 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.129654 (* 1 = 0.129654 loss)
I0526 03:03:00.310809 15117 sgd_solver.cpp:294] Iteration 15520, lr = 0.02
I0526 03:03:06.628031 15117 solver.cpp:233] Iteration 15530, loss = 0.23149
I0526 03:03:06.628084 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.23149 (* 1 = 0.23149 loss)
I0526 03:03:06.628093 15117 sgd_solver.cpp:294] Iteration 15530, lr = 0.02
I0526 03:03:12.940081 15117 solver.cpp:233] Iteration 15540, loss = 0.160173
I0526 03:03:12.940140 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.160173 (* 1 = 0.160173 loss)
I0526 03:03:12.940157 15117 sgd_solver.cpp:294] Iteration 15540, lr = 0.02
I0526 03:03:19.254861 15117 solver.cpp:233] Iteration 15550, loss = 0.287129
I0526 03:03:19.255048 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.287129 (* 1 = 0.287129 loss)
I0526 03:03:19.255059 15117 sgd_solver.cpp:294] Iteration 15550, lr = 0.02
I0526 03:03:25.571559 15117 solver.cpp:233] Iteration 15560, loss = 0.173262
I0526 03:03:25.571610 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.173262 (* 1 = 0.173262 loss)
I0526 03:03:25.571619 15117 sgd_solver.cpp:294] Iteration 15560, lr = 0.02
I0526 03:03:31.891938 15117 solver.cpp:233] Iteration 15570, loss = 0.230214
I0526 03:03:31.891998 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.230214 (* 1 = 0.230214 loss)
I0526 03:03:31.892007 15117 sgd_solver.cpp:294] Iteration 15570, lr = 0.02
I0526 03:03:38.211122 15117 solver.cpp:233] Iteration 15580, loss = 0.188551
I0526 03:03:38.211179 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.188552 (* 1 = 0.188552 loss)
I0526 03:03:38.211187 15117 sgd_solver.cpp:294] Iteration 15580, lr = 0.02
I0526 03:03:44.527894 15117 solver.cpp:233] Iteration 15590, loss = 0.113719
I0526 03:03:44.527952 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.113719 (* 1 = 0.113719 loss)
I0526 03:03:44.527962 15117 sgd_solver.cpp:294] Iteration 15590, lr = 0.02
I0526 03:03:50.247267 15117 solver.cpp:342] Iteration 15600, Testing net (#0)
I0526 03:04:03.091972 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8143
I0526 03:04:03.092030 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.645271 (* 1 = 0.645271 loss)
I0526 03:04:03.691674 15117 solver.cpp:233] Iteration 15600, loss = 0.139291
I0526 03:04:03.691735 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.139291 (* 1 = 0.139291 loss)
I0526 03:04:03.691742 15117 sgd_solver.cpp:294] Iteration 15600, lr = 0.02
I0526 03:04:10.009552 15117 solver.cpp:233] Iteration 15610, loss = 0.164874
I0526 03:04:10.009611 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.164874 (* 1 = 0.164874 loss)
I0526 03:04:10.009621 15117 sgd_solver.cpp:294] Iteration 15610, lr = 0.02
I0526 03:04:16.329911 15117 solver.cpp:233] Iteration 15620, loss = 0.188738
I0526 03:04:16.329970 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.188738 (* 1 = 0.188738 loss)
I0526 03:04:16.329980 15117 sgd_solver.cpp:294] Iteration 15620, lr = 0.02
I0526 03:04:22.656270 15117 solver.cpp:233] Iteration 15630, loss = 0.271196
I0526 03:04:22.656409 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.271196 (* 1 = 0.271196 loss)
I0526 03:04:22.656419 15117 sgd_solver.cpp:294] Iteration 15630, lr = 0.02
I0526 03:04:28.970832 15117 solver.cpp:233] Iteration 15640, loss = 0.240725
I0526 03:04:28.970885 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.240725 (* 1 = 0.240725 loss)
I0526 03:04:28.970895 15117 sgd_solver.cpp:294] Iteration 15640, lr = 0.02
I0526 03:04:35.293380 15117 solver.cpp:233] Iteration 15650, loss = 0.0984289
I0526 03:04:35.293439 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.098429 (* 1 = 0.098429 loss)
I0526 03:04:35.293448 15117 sgd_solver.cpp:294] Iteration 15650, lr = 0.02
I0526 03:04:41.616489 15117 solver.cpp:233] Iteration 15660, loss = 0.301885
I0526 03:04:41.616555 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.301885 (* 1 = 0.301885 loss)
I0526 03:04:41.616565 15117 sgd_solver.cpp:294] Iteration 15660, lr = 0.02
I0526 03:04:47.935564 15117 solver.cpp:233] Iteration 15670, loss = 0.145806
I0526 03:04:47.935617 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.145806 (* 1 = 0.145806 loss)
I0526 03:04:47.935626 15117 sgd_solver.cpp:294] Iteration 15670, lr = 0.02
I0526 03:04:54.255481 15117 solver.cpp:233] Iteration 15680, loss = 0.20328
I0526 03:04:54.255662 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.20328 (* 1 = 0.20328 loss)
I0526 03:04:54.255673 15117 sgd_solver.cpp:294] Iteration 15680, lr = 0.02
I0526 03:05:00.574187 15117 solver.cpp:233] Iteration 15690, loss = 0.121662
I0526 03:05:00.574252 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.121662 (* 1 = 0.121662 loss)
I0526 03:05:00.574261 15117 sgd_solver.cpp:294] Iteration 15690, lr = 0.02
I0526 03:05:06.294248 15117 solver.cpp:342] Iteration 15700, Testing net (#0)
I0526 03:05:19.134902 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8457
I0526 03:05:19.134956 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.514518 (* 1 = 0.514518 loss)
I0526 03:05:19.734688 15117 solver.cpp:233] Iteration 15700, loss = 0.147395
I0526 03:05:19.734746 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.147396 (* 1 = 0.147396 loss)
I0526 03:05:19.734755 15117 sgd_solver.cpp:294] Iteration 15700, lr = 0.02
I0526 03:05:26.051468 15117 solver.cpp:233] Iteration 15710, loss = 0.25036
I0526 03:05:26.051566 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.25036 (* 1 = 0.25036 loss)
I0526 03:05:26.051576 15117 sgd_solver.cpp:294] Iteration 15710, lr = 0.02
I0526 03:05:32.362928 15117 solver.cpp:233] Iteration 15720, loss = 0.153123
I0526 03:05:32.362980 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.153123 (* 1 = 0.153123 loss)
I0526 03:05:32.362989 15117 sgd_solver.cpp:294] Iteration 15720, lr = 0.02
I0526 03:05:38.680434 15117 solver.cpp:233] Iteration 15730, loss = 0.159062
I0526 03:05:38.680496 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.159062 (* 1 = 0.159062 loss)
I0526 03:05:38.680505 15117 sgd_solver.cpp:294] Iteration 15730, lr = 0.02
I0526 03:05:44.996156 15117 solver.cpp:233] Iteration 15740, loss = 0.150348
I0526 03:05:44.996206 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.150348 (* 1 = 0.150348 loss)
I0526 03:05:44.996215 15117 sgd_solver.cpp:294] Iteration 15740, lr = 0.02
I0526 03:05:51.310184 15117 solver.cpp:233] Iteration 15750, loss = 0.225671
I0526 03:05:51.310233 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.225671 (* 1 = 0.225671 loss)
I0526 03:05:51.310242 15117 sgd_solver.cpp:294] Iteration 15750, lr = 0.02
I0526 03:05:57.631996 15117 solver.cpp:233] Iteration 15760, loss = 0.273062
I0526 03:05:57.632112 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.273062 (* 1 = 0.273062 loss)
I0526 03:05:57.632122 15117 sgd_solver.cpp:294] Iteration 15760, lr = 0.02
I0526 03:06:03.953305 15117 solver.cpp:233] Iteration 15770, loss = 0.153074
I0526 03:06:03.953357 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.153074 (* 1 = 0.153074 loss)
I0526 03:06:03.953366 15117 sgd_solver.cpp:294] Iteration 15770, lr = 0.02
I0526 03:06:10.272248 15117 solver.cpp:233] Iteration 15780, loss = 0.128887
I0526 03:06:10.272305 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.128887 (* 1 = 0.128887 loss)
I0526 03:06:10.272315 15117 sgd_solver.cpp:294] Iteration 15780, lr = 0.02
I0526 03:06:16.591284 15117 solver.cpp:233] Iteration 15790, loss = 0.159425
I0526 03:06:16.591336 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.159425 (* 1 = 0.159425 loss)
I0526 03:06:16.591346 15117 sgd_solver.cpp:294] Iteration 15790, lr = 0.02
I0526 03:06:22.313408 15117 solver.cpp:342] Iteration 15800, Testing net (#0)
I0526 03:06:35.156497 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8092
I0526 03:06:35.156671 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.696526 (* 1 = 0.696526 loss)
I0526 03:06:35.756831 15117 solver.cpp:233] Iteration 15800, loss = 0.215459
I0526 03:06:35.756883 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.21546 (* 1 = 0.21546 loss)
I0526 03:06:35.756892 15117 sgd_solver.cpp:294] Iteration 15800, lr = 0.02
I0526 03:06:42.076481 15117 solver.cpp:233] Iteration 15810, loss = 0.137829
I0526 03:06:42.076536 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.137829 (* 1 = 0.137829 loss)
I0526 03:06:42.076546 15117 sgd_solver.cpp:294] Iteration 15810, lr = 0.02
I0526 03:06:48.397564 15117 solver.cpp:233] Iteration 15820, loss = 0.0594205
I0526 03:06:48.397619 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0594206 (* 1 = 0.0594206 loss)
I0526 03:06:48.397627 15117 sgd_solver.cpp:294] Iteration 15820, lr = 0.02
I0526 03:06:54.716485 15117 solver.cpp:233] Iteration 15830, loss = 0.165041
I0526 03:06:54.716541 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.165041 (* 1 = 0.165041 loss)
I0526 03:06:54.716549 15117 sgd_solver.cpp:294] Iteration 15830, lr = 0.02
I0526 03:07:01.036101 15117 solver.cpp:233] Iteration 15840, loss = 0.187854
I0526 03:07:01.036154 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.187854 (* 1 = 0.187854 loss)
I0526 03:07:01.036162 15117 sgd_solver.cpp:294] Iteration 15840, lr = 0.02
I0526 03:07:07.355900 15117 solver.cpp:233] Iteration 15850, loss = 0.116885
I0526 03:07:07.356024 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.116885 (* 1 = 0.116885 loss)
I0526 03:07:07.356034 15117 sgd_solver.cpp:294] Iteration 15850, lr = 0.02
I0526 03:07:13.675899 15117 solver.cpp:233] Iteration 15860, loss = 0.1886
I0526 03:07:13.675956 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.188601 (* 1 = 0.188601 loss)
I0526 03:07:13.675966 15117 sgd_solver.cpp:294] Iteration 15860, lr = 0.02
I0526 03:07:19.989404 15117 solver.cpp:233] Iteration 15870, loss = 0.219782
I0526 03:07:19.989457 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.219782 (* 1 = 0.219782 loss)
I0526 03:07:19.989466 15117 sgd_solver.cpp:294] Iteration 15870, lr = 0.02
I0526 03:07:26.309896 15117 solver.cpp:233] Iteration 15880, loss = 0.148028
I0526 03:07:26.309962 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.148028 (* 1 = 0.148028 loss)
I0526 03:07:26.309972 15117 sgd_solver.cpp:294] Iteration 15880, lr = 0.02
I0526 03:07:32.629191 15117 solver.cpp:233] Iteration 15890, loss = 0.17782
I0526 03:07:32.629245 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.177821 (* 1 = 0.177821 loss)
I0526 03:07:32.629253 15117 sgd_solver.cpp:294] Iteration 15890, lr = 0.02
I0526 03:07:38.350962 15117 solver.cpp:342] Iteration 15900, Testing net (#0)
I0526 03:07:51.190752 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8276
I0526 03:07:51.190801 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.649134 (* 1 = 0.649134 loss)
I0526 03:07:51.789950 15117 solver.cpp:233] Iteration 15900, loss = 0.149359
I0526 03:07:51.790000 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.149359 (* 1 = 0.149359 loss)
I0526 03:07:51.790009 15117 sgd_solver.cpp:294] Iteration 15900, lr = 0.02
I0526 03:07:58.107507 15117 solver.cpp:233] Iteration 15910, loss = 0.166488
I0526 03:07:58.107563 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.166488 (* 1 = 0.166488 loss)
I0526 03:07:58.107571 15117 sgd_solver.cpp:294] Iteration 15910, lr = 0.02
I0526 03:08:04.424228 15117 solver.cpp:233] Iteration 15920, loss = 0.14518
I0526 03:08:04.424290 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.14518 (* 1 = 0.14518 loss)
I0526 03:08:04.424299 15117 sgd_solver.cpp:294] Iteration 15920, lr = 0.02
I0526 03:08:10.744797 15117 solver.cpp:233] Iteration 15930, loss = 0.18925
I0526 03:08:10.744961 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.18925 (* 1 = 0.18925 loss)
I0526 03:08:10.744971 15117 sgd_solver.cpp:294] Iteration 15930, lr = 0.02
I0526 03:08:17.064436 15117 solver.cpp:233] Iteration 15940, loss = 0.230286
I0526 03:08:17.064489 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.230286 (* 1 = 0.230286 loss)
I0526 03:08:17.064499 15117 sgd_solver.cpp:294] Iteration 15940, lr = 0.02
I0526 03:08:23.382477 15117 solver.cpp:233] Iteration 15950, loss = 0.169501
I0526 03:08:23.382530 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.169501 (* 1 = 0.169501 loss)
I0526 03:08:23.382540 15117 sgd_solver.cpp:294] Iteration 15950, lr = 0.02
I0526 03:08:29.703495 15117 solver.cpp:233] Iteration 15960, loss = 0.213209
I0526 03:08:29.703549 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.213209 (* 1 = 0.213209 loss)
I0526 03:08:29.703558 15117 sgd_solver.cpp:294] Iteration 15960, lr = 0.02
I0526 03:08:36.024547 15117 solver.cpp:233] Iteration 15970, loss = 0.189817
I0526 03:08:36.024597 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.189818 (* 1 = 0.189818 loss)
I0526 03:08:36.024605 15117 sgd_solver.cpp:294] Iteration 15970, lr = 0.02
I0526 03:08:42.344192 15117 solver.cpp:233] Iteration 15980, loss = 0.1184
I0526 03:08:42.344336 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.1184 (* 1 = 0.1184 loss)
I0526 03:08:42.344347 15117 sgd_solver.cpp:294] Iteration 15980, lr = 0.02
I0526 03:08:48.665768 15117 solver.cpp:233] Iteration 15990, loss = 0.125785
I0526 03:08:48.665817 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.125785 (* 1 = 0.125785 loss)
I0526 03:08:48.665827 15117 sgd_solver.cpp:294] Iteration 15990, lr = 0.02
I0526 03:08:54.385460 15117 solver.cpp:342] Iteration 16000, Testing net (#0)
I0526 03:09:07.225607 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7992
I0526 03:09:07.225658 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.790407 (* 1 = 0.790407 loss)
I0526 03:09:07.825034 15117 solver.cpp:233] Iteration 16000, loss = 0.18068
I0526 03:09:07.825093 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.18068 (* 1 = 0.18068 loss)
I0526 03:09:07.825103 15117 sgd_solver.cpp:294] Iteration 16000, lr = 0.02
I0526 03:09:14.147086 15117 solver.cpp:233] Iteration 16010, loss = 0.163661
I0526 03:09:14.147214 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.163661 (* 1 = 0.163661 loss)
I0526 03:09:14.147224 15117 sgd_solver.cpp:294] Iteration 16010, lr = 0.02
I0526 03:09:20.466816 15117 solver.cpp:233] Iteration 16020, loss = 0.250953
I0526 03:09:20.466877 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.250953 (* 1 = 0.250953 loss)
I0526 03:09:20.466886 15117 sgd_solver.cpp:294] Iteration 16020, lr = 0.02
I0526 03:09:26.781980 15117 solver.cpp:233] Iteration 16030, loss = 0.206101
I0526 03:09:26.782039 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.206101 (* 1 = 0.206101 loss)
I0526 03:09:26.782049 15117 sgd_solver.cpp:294] Iteration 16030, lr = 0.02
I0526 03:09:33.105415 15117 solver.cpp:233] Iteration 16040, loss = 0.120371
I0526 03:09:33.105468 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.120371 (* 1 = 0.120371 loss)
I0526 03:09:33.105476 15117 sgd_solver.cpp:294] Iteration 16040, lr = 0.02
I0526 03:09:39.427912 15117 solver.cpp:233] Iteration 16050, loss = 0.216852
I0526 03:09:39.427965 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.216852 (* 1 = 0.216852 loss)
I0526 03:09:39.427974 15117 sgd_solver.cpp:294] Iteration 16050, lr = 0.02
I0526 03:09:45.745223 15117 solver.cpp:233] Iteration 16060, loss = 0.206166
I0526 03:09:45.745318 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.206166 (* 1 = 0.206166 loss)
I0526 03:09:45.745328 15117 sgd_solver.cpp:294] Iteration 16060, lr = 0.02
I0526 03:09:52.068775 15117 solver.cpp:233] Iteration 16070, loss = 0.200074
I0526 03:09:52.068828 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.200074 (* 1 = 0.200074 loss)
I0526 03:09:52.068845 15117 sgd_solver.cpp:294] Iteration 16070, lr = 0.02
I0526 03:09:58.391592 15117 solver.cpp:233] Iteration 16080, loss = 0.231431
I0526 03:09:58.391641 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.231431 (* 1 = 0.231431 loss)
I0526 03:09:58.391650 15117 sgd_solver.cpp:294] Iteration 16080, lr = 0.02
I0526 03:10:04.711252 15117 solver.cpp:233] Iteration 16090, loss = 0.191708
I0526 03:10:04.711305 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.191708 (* 1 = 0.191708 loss)
I0526 03:10:04.711313 15117 sgd_solver.cpp:294] Iteration 16090, lr = 0.02
I0526 03:10:10.429399 15117 solver.cpp:342] Iteration 16100, Testing net (#0)
I0526 03:10:23.276422 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8433
I0526 03:10:23.276599 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.52062 (* 1 = 0.52062 loss)
I0526 03:10:23.875607 15117 solver.cpp:233] Iteration 16100, loss = 0.105675
I0526 03:10:23.875679 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.105675 (* 1 = 0.105675 loss)
I0526 03:10:23.875689 15117 sgd_solver.cpp:294] Iteration 16100, lr = 0.02
I0526 03:10:30.186774 15117 solver.cpp:233] Iteration 16110, loss = 0.17551
I0526 03:10:30.186827 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.17551 (* 1 = 0.17551 loss)
I0526 03:10:30.186836 15117 sgd_solver.cpp:294] Iteration 16110, lr = 0.02
I0526 03:10:36.506135 15117 solver.cpp:233] Iteration 16120, loss = 0.161161
I0526 03:10:36.506194 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.161161 (* 1 = 0.161161 loss)
I0526 03:10:36.506203 15117 sgd_solver.cpp:294] Iteration 16120, lr = 0.02
I0526 03:10:42.825449 15117 solver.cpp:233] Iteration 16130, loss = 0.238854
I0526 03:10:42.825503 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.238854 (* 1 = 0.238854 loss)
I0526 03:10:42.825511 15117 sgd_solver.cpp:294] Iteration 16130, lr = 0.02
I0526 03:10:49.146287 15117 solver.cpp:233] Iteration 16140, loss = 0.179564
I0526 03:10:49.146340 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.179564 (* 1 = 0.179564 loss)
I0526 03:10:49.146349 15117 sgd_solver.cpp:294] Iteration 16140, lr = 0.02
I0526 03:10:55.466781 15117 solver.cpp:233] Iteration 16150, loss = 0.261478
I0526 03:10:55.466892 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.261478 (* 1 = 0.261478 loss)
I0526 03:10:55.466902 15117 sgd_solver.cpp:294] Iteration 16150, lr = 0.02
I0526 03:11:01.786612 15117 solver.cpp:233] Iteration 16160, loss = 0.240615
I0526 03:11:01.786669 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.240615 (* 1 = 0.240615 loss)
I0526 03:11:01.786689 15117 sgd_solver.cpp:294] Iteration 16160, lr = 0.02
I0526 03:11:08.105576 15117 solver.cpp:233] Iteration 16170, loss = 0.126517
I0526 03:11:08.105630 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.126517 (* 1 = 0.126517 loss)
I0526 03:11:08.105640 15117 sgd_solver.cpp:294] Iteration 16170, lr = 0.02
I0526 03:11:14.423966 15117 solver.cpp:233] Iteration 16180, loss = 0.182567
I0526 03:11:14.424018 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.182567 (* 1 = 0.182567 loss)
I0526 03:11:14.424026 15117 sgd_solver.cpp:294] Iteration 16180, lr = 0.02
I0526 03:11:20.743880 15117 solver.cpp:233] Iteration 16190, loss = 0.15411
I0526 03:11:20.743947 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.15411 (* 1 = 0.15411 loss)
I0526 03:11:20.743957 15117 sgd_solver.cpp:294] Iteration 16190, lr = 0.02
I0526 03:11:26.467792 15117 solver.cpp:342] Iteration 16200, Testing net (#0)
I0526 03:11:39.312114 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7782
I0526 03:11:39.312166 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.792667 (* 1 = 0.792667 loss)
I0526 03:11:39.912238 15117 solver.cpp:233] Iteration 16200, loss = 0.164945
I0526 03:11:39.912292 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.164946 (* 1 = 0.164946 loss)
I0526 03:11:39.912308 15117 sgd_solver.cpp:294] Iteration 16200, lr = 0.02
I0526 03:11:46.233978 15117 solver.cpp:233] Iteration 16210, loss = 0.246144
I0526 03:11:46.234033 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.246144 (* 1 = 0.246144 loss)
I0526 03:11:46.234042 15117 sgd_solver.cpp:294] Iteration 16210, lr = 0.02
I0526 03:11:52.554839 15117 solver.cpp:233] Iteration 16220, loss = 0.1765
I0526 03:11:52.554889 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.1765 (* 1 = 0.1765 loss)
I0526 03:11:52.554898 15117 sgd_solver.cpp:294] Iteration 16220, lr = 0.02
I0526 03:11:58.878374 15117 solver.cpp:233] Iteration 16230, loss = 0.146427
I0526 03:11:58.878550 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.146427 (* 1 = 0.146427 loss)
I0526 03:11:58.878561 15117 sgd_solver.cpp:294] Iteration 16230, lr = 0.02
I0526 03:12:05.198242 15117 solver.cpp:233] Iteration 16240, loss = 0.201357
I0526 03:12:05.198294 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.201357 (* 1 = 0.201357 loss)
I0526 03:12:05.198304 15117 sgd_solver.cpp:294] Iteration 16240, lr = 0.02
I0526 03:12:11.523958 15117 solver.cpp:233] Iteration 16250, loss = 0.192691
I0526 03:12:11.524009 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.192691 (* 1 = 0.192691 loss)
I0526 03:12:11.524018 15117 sgd_solver.cpp:294] Iteration 16250, lr = 0.02
I0526 03:12:17.843861 15117 solver.cpp:233] Iteration 16260, loss = 0.0963755
I0526 03:12:17.843919 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0963756 (* 1 = 0.0963756 loss)
I0526 03:12:17.843929 15117 sgd_solver.cpp:294] Iteration 16260, lr = 0.02
I0526 03:12:24.167742 15117 solver.cpp:233] Iteration 16270, loss = 0.165269
I0526 03:12:24.167791 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.165269 (* 1 = 0.165269 loss)
I0526 03:12:24.167800 15117 sgd_solver.cpp:294] Iteration 16270, lr = 0.02
I0526 03:12:30.483278 15117 solver.cpp:233] Iteration 16280, loss = 0.211483
I0526 03:12:30.483400 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.211483 (* 1 = 0.211483 loss)
I0526 03:12:30.483410 15117 sgd_solver.cpp:294] Iteration 16280, lr = 0.02
I0526 03:12:36.798877 15117 solver.cpp:233] Iteration 16290, loss = 0.206696
I0526 03:12:36.798938 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.206696 (* 1 = 0.206696 loss)
I0526 03:12:36.798948 15117 sgd_solver.cpp:294] Iteration 16290, lr = 0.02
I0526 03:12:42.518291 15117 solver.cpp:342] Iteration 16300, Testing net (#0)
I0526 03:12:55.359175 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7915
I0526 03:12:55.359221 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.870677 (* 1 = 0.870677 loss)
I0526 03:12:55.958247 15117 solver.cpp:233] Iteration 16300, loss = 0.27537
I0526 03:12:55.958297 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.27537 (* 1 = 0.27537 loss)
I0526 03:12:55.958307 15117 sgd_solver.cpp:294] Iteration 16300, lr = 0.02
I0526 03:13:02.278970 15117 solver.cpp:233] Iteration 16310, loss = 0.111534
I0526 03:13:02.279101 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.111534 (* 1 = 0.111534 loss)
I0526 03:13:02.279111 15117 sgd_solver.cpp:294] Iteration 16310, lr = 0.02
I0526 03:13:08.596489 15117 solver.cpp:233] Iteration 16320, loss = 0.174597
I0526 03:13:08.596546 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.174598 (* 1 = 0.174598 loss)
I0526 03:13:08.596556 15117 sgd_solver.cpp:294] Iteration 16320, lr = 0.02
I0526 03:13:14.918256 15117 solver.cpp:233] Iteration 16330, loss = 0.137845
I0526 03:13:14.918318 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.137845 (* 1 = 0.137845 loss)
I0526 03:13:14.918329 15117 sgd_solver.cpp:294] Iteration 16330, lr = 0.02
I0526 03:13:21.238086 15117 solver.cpp:233] Iteration 16340, loss = 0.165667
I0526 03:13:21.238142 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.165667 (* 1 = 0.165667 loss)
I0526 03:13:21.238157 15117 sgd_solver.cpp:294] Iteration 16340, lr = 0.02
I0526 03:13:27.557478 15117 solver.cpp:233] Iteration 16350, loss = 0.154199
I0526 03:13:27.557529 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.154199 (* 1 = 0.154199 loss)
I0526 03:13:27.557538 15117 sgd_solver.cpp:294] Iteration 16350, lr = 0.02
I0526 03:13:33.873508 15117 solver.cpp:233] Iteration 16360, loss = 0.159812
I0526 03:13:33.873656 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.159812 (* 1 = 0.159812 loss)
I0526 03:13:33.873667 15117 sgd_solver.cpp:294] Iteration 16360, lr = 0.02
I0526 03:13:40.190224 15117 solver.cpp:233] Iteration 16370, loss = 0.163266
I0526 03:13:40.190276 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.163266 (* 1 = 0.163266 loss)
I0526 03:13:40.190285 15117 sgd_solver.cpp:294] Iteration 16370, lr = 0.02
I0526 03:13:46.512042 15117 solver.cpp:233] Iteration 16380, loss = 0.131287
I0526 03:13:46.512094 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.131287 (* 1 = 0.131287 loss)
I0526 03:13:46.512104 15117 sgd_solver.cpp:294] Iteration 16380, lr = 0.02
I0526 03:13:52.836319 15117 solver.cpp:233] Iteration 16390, loss = 0.145505
I0526 03:13:52.836369 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.145505 (* 1 = 0.145505 loss)
I0526 03:13:52.836377 15117 sgd_solver.cpp:294] Iteration 16390, lr = 0.02
I0526 03:13:58.554731 15117 solver.cpp:342] Iteration 16400, Testing net (#0)
I0526 03:14:11.392978 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7822
I0526 03:14:11.393127 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.855628 (* 1 = 0.855628 loss)
I0526 03:14:11.992619 15117 solver.cpp:233] Iteration 16400, loss = 0.128741
I0526 03:14:11.992671 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.128741 (* 1 = 0.128741 loss)
I0526 03:14:11.992681 15117 sgd_solver.cpp:294] Iteration 16400, lr = 0.02
I0526 03:14:18.308629 15117 solver.cpp:233] Iteration 16410, loss = 0.11994
I0526 03:14:18.308681 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.11994 (* 1 = 0.11994 loss)
I0526 03:14:18.308689 15117 sgd_solver.cpp:294] Iteration 16410, lr = 0.02
I0526 03:14:24.627050 15117 solver.cpp:233] Iteration 16420, loss = 0.195676
I0526 03:14:24.627100 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.195676 (* 1 = 0.195676 loss)
I0526 03:14:24.627110 15117 sgd_solver.cpp:294] Iteration 16420, lr = 0.02
I0526 03:14:30.943428 15117 solver.cpp:233] Iteration 16430, loss = 0.17429
I0526 03:14:30.943483 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.17429 (* 1 = 0.17429 loss)
I0526 03:14:30.943491 15117 sgd_solver.cpp:294] Iteration 16430, lr = 0.02
I0526 03:14:37.264122 15117 solver.cpp:233] Iteration 16440, loss = 0.11555
I0526 03:14:37.264171 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.11555 (* 1 = 0.11555 loss)
I0526 03:14:37.264179 15117 sgd_solver.cpp:294] Iteration 16440, lr = 0.02
I0526 03:14:43.576912 15117 solver.cpp:233] Iteration 16450, loss = 0.167098
I0526 03:14:43.577047 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.167098 (* 1 = 0.167098 loss)
I0526 03:14:43.577059 15117 sgd_solver.cpp:294] Iteration 16450, lr = 0.02
I0526 03:14:49.894008 15117 solver.cpp:233] Iteration 16460, loss = 0.171589
I0526 03:14:49.894059 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.171589 (* 1 = 0.171589 loss)
I0526 03:14:49.894068 15117 sgd_solver.cpp:294] Iteration 16460, lr = 0.02
I0526 03:14:56.210669 15117 solver.cpp:233] Iteration 16470, loss = 0.137412
I0526 03:14:56.210731 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.137412 (* 1 = 0.137412 loss)
I0526 03:14:56.210739 15117 sgd_solver.cpp:294] Iteration 16470, lr = 0.02
I0526 03:15:02.527487 15117 solver.cpp:233] Iteration 16480, loss = 0.144885
I0526 03:15:02.527535 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.144885 (* 1 = 0.144885 loss)
I0526 03:15:02.527550 15117 sgd_solver.cpp:294] Iteration 16480, lr = 0.02
I0526 03:15:08.841914 15117 solver.cpp:233] Iteration 16490, loss = 0.121172
I0526 03:15:08.841967 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.121172 (* 1 = 0.121172 loss)
I0526 03:15:08.841975 15117 sgd_solver.cpp:294] Iteration 16490, lr = 0.02
I0526 03:15:14.561085 15117 solver.cpp:342] Iteration 16500, Testing net (#0)
I0526 03:15:27.397781 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7974
I0526 03:15:27.397835 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.734514 (* 1 = 0.734514 loss)
I0526 03:15:27.998082 15117 solver.cpp:233] Iteration 16500, loss = 0.142232
I0526 03:15:27.998134 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.142232 (* 1 = 0.142232 loss)
I0526 03:15:27.998142 15117 sgd_solver.cpp:294] Iteration 16500, lr = 0.02
I0526 03:15:34.318359 15117 solver.cpp:233] Iteration 16510, loss = 0.207423
I0526 03:15:34.318410 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.207423 (* 1 = 0.207423 loss)
I0526 03:15:34.318419 15117 sgd_solver.cpp:294] Iteration 16510, lr = 0.02
I0526 03:15:40.635026 15117 solver.cpp:233] Iteration 16520, loss = 0.169704
I0526 03:15:40.635078 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.169704 (* 1 = 0.169704 loss)
I0526 03:15:40.635087 15117 sgd_solver.cpp:294] Iteration 16520, lr = 0.02
I0526 03:15:46.955082 15117 solver.cpp:233] Iteration 16530, loss = 0.199924
I0526 03:15:46.955162 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.199924 (* 1 = 0.199924 loss)
I0526 03:15:46.955181 15117 sgd_solver.cpp:294] Iteration 16530, lr = 0.02
I0526 03:15:53.274549 15117 solver.cpp:233] Iteration 16540, loss = 0.154082
I0526 03:15:53.274601 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.154082 (* 1 = 0.154082 loss)
I0526 03:15:53.274610 15117 sgd_solver.cpp:294] Iteration 16540, lr = 0.02
I0526 03:15:59.597229 15117 solver.cpp:233] Iteration 16550, loss = 0.278616
I0526 03:15:59.597283 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.278616 (* 1 = 0.278616 loss)
I0526 03:15:59.597292 15117 sgd_solver.cpp:294] Iteration 16550, lr = 0.02
I0526 03:16:05.919257 15117 solver.cpp:233] Iteration 16560, loss = 0.174346
I0526 03:16:05.919312 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.174346 (* 1 = 0.174346 loss)
I0526 03:16:05.919320 15117 sgd_solver.cpp:294] Iteration 16560, lr = 0.02
I0526 03:16:12.239928 15117 solver.cpp:233] Iteration 16570, loss = 0.207652
I0526 03:16:12.239980 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.207652 (* 1 = 0.207652 loss)
I0526 03:16:12.239989 15117 sgd_solver.cpp:294] Iteration 16570, lr = 0.02
I0526 03:16:18.563247 15117 solver.cpp:233] Iteration 16580, loss = 0.125215
I0526 03:16:18.563335 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.125215 (* 1 = 0.125215 loss)
I0526 03:16:18.563345 15117 sgd_solver.cpp:294] Iteration 16580, lr = 0.02
I0526 03:16:24.882028 15117 solver.cpp:233] Iteration 16590, loss = 0.167291
I0526 03:16:24.882076 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.167291 (* 1 = 0.167291 loss)
I0526 03:16:24.882084 15117 sgd_solver.cpp:294] Iteration 16590, lr = 0.02
I0526 03:16:30.605432 15117 solver.cpp:342] Iteration 16600, Testing net (#0)
I0526 03:16:43.460203 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8074
I0526 03:16:43.460263 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.741614 (* 1 = 0.741614 loss)
I0526 03:16:44.059389 15117 solver.cpp:233] Iteration 16600, loss = 0.130133
I0526 03:16:44.059437 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.130133 (* 1 = 0.130133 loss)
I0526 03:16:44.059443 15117 sgd_solver.cpp:294] Iteration 16600, lr = 0.02
I0526 03:16:50.377899 15117 solver.cpp:233] Iteration 16610, loss = 0.133243
I0526 03:16:50.378053 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.133243 (* 1 = 0.133243 loss)
I0526 03:16:50.378068 15117 sgd_solver.cpp:294] Iteration 16610, lr = 0.02
I0526 03:16:56.698967 15117 solver.cpp:233] Iteration 16620, loss = 0.189443
I0526 03:16:56.699029 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.189443 (* 1 = 0.189443 loss)
I0526 03:16:56.699039 15117 sgd_solver.cpp:294] Iteration 16620, lr = 0.02
I0526 03:17:03.013084 15117 solver.cpp:233] Iteration 16630, loss = 0.185102
I0526 03:17:03.013139 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.185102 (* 1 = 0.185102 loss)
I0526 03:17:03.013147 15117 sgd_solver.cpp:294] Iteration 16630, lr = 0.02
I0526 03:17:09.333678 15117 solver.cpp:233] Iteration 16640, loss = 0.139708
I0526 03:17:09.333739 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.139708 (* 1 = 0.139708 loss)
I0526 03:17:09.333748 15117 sgd_solver.cpp:294] Iteration 16640, lr = 0.02
I0526 03:17:15.654469 15117 solver.cpp:233] Iteration 16650, loss = 0.0944673
I0526 03:17:15.654536 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0944673 (* 1 = 0.0944673 loss)
I0526 03:17:15.654544 15117 sgd_solver.cpp:294] Iteration 16650, lr = 0.02
I0526 03:17:21.978742 15117 solver.cpp:233] Iteration 16660, loss = 0.178095
I0526 03:17:21.978878 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.178095 (* 1 = 0.178095 loss)
I0526 03:17:21.978888 15117 sgd_solver.cpp:294] Iteration 16660, lr = 0.02
I0526 03:17:28.292798 15117 solver.cpp:233] Iteration 16670, loss = 0.189582
I0526 03:17:28.292855 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.189582 (* 1 = 0.189582 loss)
I0526 03:17:28.292865 15117 sgd_solver.cpp:294] Iteration 16670, lr = 0.02
I0526 03:17:34.612784 15117 solver.cpp:233] Iteration 16680, loss = 0.186881
I0526 03:17:34.612833 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.186881 (* 1 = 0.186881 loss)
I0526 03:17:34.612843 15117 sgd_solver.cpp:294] Iteration 16680, lr = 0.02
I0526 03:17:40.930912 15117 solver.cpp:233] Iteration 16690, loss = 0.0965428
I0526 03:17:40.930963 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0965428 (* 1 = 0.0965428 loss)
I0526 03:17:40.930971 15117 sgd_solver.cpp:294] Iteration 16690, lr = 0.02
I0526 03:17:46.646863 15117 solver.cpp:342] Iteration 16700, Testing net (#0)
I0526 03:17:59.488579 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7844
I0526 03:17:59.488705 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.824021 (* 1 = 0.824021 loss)
I0526 03:18:00.088336 15117 solver.cpp:233] Iteration 16700, loss = 0.146048
I0526 03:18:00.088390 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.146048 (* 1 = 0.146048 loss)
I0526 03:18:00.088400 15117 sgd_solver.cpp:294] Iteration 16700, lr = 0.02
I0526 03:18:06.401101 15117 solver.cpp:233] Iteration 16710, loss = 0.193826
I0526 03:18:06.401154 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.193826 (* 1 = 0.193826 loss)
I0526 03:18:06.401162 15117 sgd_solver.cpp:294] Iteration 16710, lr = 0.02
I0526 03:18:12.721153 15117 solver.cpp:233] Iteration 16720, loss = 0.10622
I0526 03:18:12.721210 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.10622 (* 1 = 0.10622 loss)
I0526 03:18:12.721220 15117 sgd_solver.cpp:294] Iteration 16720, lr = 0.02
I0526 03:18:19.040213 15117 solver.cpp:233] Iteration 16730, loss = 0.0727897
I0526 03:18:19.040277 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0727897 (* 1 = 0.0727897 loss)
I0526 03:18:19.040285 15117 sgd_solver.cpp:294] Iteration 16730, lr = 0.02
I0526 03:18:25.361325 15117 solver.cpp:233] Iteration 16740, loss = 0.136658
I0526 03:18:25.361380 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.136658 (* 1 = 0.136658 loss)
I0526 03:18:25.361390 15117 sgd_solver.cpp:294] Iteration 16740, lr = 0.02
I0526 03:18:31.681743 15117 solver.cpp:233] Iteration 16750, loss = 0.121269
I0526 03:18:31.681927 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.121269 (* 1 = 0.121269 loss)
I0526 03:18:31.681939 15117 sgd_solver.cpp:294] Iteration 16750, lr = 0.02
I0526 03:18:38.002281 15117 solver.cpp:233] Iteration 16760, loss = 0.154861
I0526 03:18:38.002336 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.154862 (* 1 = 0.154862 loss)
I0526 03:18:38.002346 15117 sgd_solver.cpp:294] Iteration 16760, lr = 0.02
I0526 03:18:44.320143 15117 solver.cpp:233] Iteration 16770, loss = 0.1241
I0526 03:18:44.320201 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.1241 (* 1 = 0.1241 loss)
I0526 03:18:44.320211 15117 sgd_solver.cpp:294] Iteration 16770, lr = 0.02
I0526 03:18:50.635530 15117 solver.cpp:233] Iteration 16780, loss = 0.241762
I0526 03:18:50.635586 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.241762 (* 1 = 0.241762 loss)
I0526 03:18:50.635596 15117 sgd_solver.cpp:294] Iteration 16780, lr = 0.02
I0526 03:18:56.951541 15117 solver.cpp:233] Iteration 16790, loss = 0.285837
I0526 03:18:56.951596 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.285837 (* 1 = 0.285837 loss)
I0526 03:18:56.951606 15117 sgd_solver.cpp:294] Iteration 16790, lr = 0.02
I0526 03:19:02.665436 15117 solver.cpp:342] Iteration 16800, Testing net (#0)
I0526 03:19:15.505245 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8099
I0526 03:19:15.505306 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.707483 (* 1 = 0.707483 loss)
I0526 03:19:16.105625 15117 solver.cpp:233] Iteration 16800, loss = 0.110015
I0526 03:19:16.105677 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.110015 (* 1 = 0.110015 loss)
I0526 03:19:16.105686 15117 sgd_solver.cpp:294] Iteration 16800, lr = 0.02
I0526 03:19:22.421772 15117 solver.cpp:233] Iteration 16810, loss = 0.118733
I0526 03:19:22.421826 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.118733 (* 1 = 0.118733 loss)
I0526 03:19:22.421835 15117 sgd_solver.cpp:294] Iteration 16810, lr = 0.02
I0526 03:19:28.739667 15117 solver.cpp:233] Iteration 16820, loss = 0.150035
I0526 03:19:28.739723 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.150035 (* 1 = 0.150035 loss)
I0526 03:19:28.739732 15117 sgd_solver.cpp:294] Iteration 16820, lr = 0.02
I0526 03:19:35.056622 15117 solver.cpp:233] Iteration 16830, loss = 0.103743
I0526 03:19:35.056759 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.103743 (* 1 = 0.103743 loss)
I0526 03:19:35.056769 15117 sgd_solver.cpp:294] Iteration 16830, lr = 0.02
I0526 03:19:41.372104 15117 solver.cpp:233] Iteration 16840, loss = 0.146885
I0526 03:19:41.372164 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.146885 (* 1 = 0.146885 loss)
I0526 03:19:41.372174 15117 sgd_solver.cpp:294] Iteration 16840, lr = 0.02
I0526 03:19:47.690148 15117 solver.cpp:233] Iteration 16850, loss = 0.146972
I0526 03:19:47.690201 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.146972 (* 1 = 0.146972 loss)
I0526 03:19:47.690210 15117 sgd_solver.cpp:294] Iteration 16850, lr = 0.02
I0526 03:19:54.003101 15117 solver.cpp:233] Iteration 16860, loss = 0.122666
I0526 03:19:54.003168 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.122666 (* 1 = 0.122666 loss)
I0526 03:19:54.003180 15117 sgd_solver.cpp:294] Iteration 16860, lr = 0.02
I0526 03:20:00.339954 15117 solver.cpp:233] Iteration 16870, loss = 0.103441
I0526 03:20:00.340025 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.103441 (* 1 = 0.103441 loss)
I0526 03:20:00.340036 15117 sgd_solver.cpp:294] Iteration 16870, lr = 0.02
I0526 03:20:06.666770 15117 solver.cpp:233] Iteration 16880, loss = 0.161768
I0526 03:20:06.666901 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.161768 (* 1 = 0.161768 loss)
I0526 03:20:06.666913 15117 sgd_solver.cpp:294] Iteration 16880, lr = 0.02
I0526 03:20:12.993095 15117 solver.cpp:233] Iteration 16890, loss = 0.109678
I0526 03:20:12.993147 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.109678 (* 1 = 0.109678 loss)
I0526 03:20:12.993157 15117 sgd_solver.cpp:294] Iteration 16890, lr = 0.02
I0526 03:20:18.729972 15117 solver.cpp:342] Iteration 16900, Testing net (#0)
I0526 03:20:31.604655 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.765
I0526 03:20:31.604712 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.939897 (* 1 = 0.939897 loss)
I0526 03:20:32.207708 15117 solver.cpp:233] Iteration 16900, loss = 0.186468
I0526 03:20:32.207777 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.186468 (* 1 = 0.186468 loss)
I0526 03:20:32.207785 15117 sgd_solver.cpp:294] Iteration 16900, lr = 0.02
I0526 03:20:38.553356 15117 solver.cpp:233] Iteration 16910, loss = 0.224643
I0526 03:20:38.553510 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.224643 (* 1 = 0.224643 loss)
I0526 03:20:38.553521 15117 sgd_solver.cpp:294] Iteration 16910, lr = 0.02
I0526 03:20:44.899008 15117 solver.cpp:233] Iteration 16920, loss = 0.137844
I0526 03:20:44.899068 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.137844 (* 1 = 0.137844 loss)
I0526 03:20:44.899077 15117 sgd_solver.cpp:294] Iteration 16920, lr = 0.02
I0526 03:20:51.245620 15117 solver.cpp:233] Iteration 16930, loss = 0.135568
I0526 03:20:51.245682 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.135568 (* 1 = 0.135568 loss)
I0526 03:20:51.245692 15117 sgd_solver.cpp:294] Iteration 16930, lr = 0.02
I0526 03:20:57.590769 15117 solver.cpp:233] Iteration 16940, loss = 0.144607
I0526 03:20:57.590819 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.144607 (* 1 = 0.144607 loss)
I0526 03:20:57.590827 15117 sgd_solver.cpp:294] Iteration 16940, lr = 0.02
I0526 03:21:03.933996 15117 solver.cpp:233] Iteration 16950, loss = 0.107011
I0526 03:21:03.934067 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.107011 (* 1 = 0.107011 loss)
I0526 03:21:03.934074 15117 sgd_solver.cpp:294] Iteration 16950, lr = 0.02
I0526 03:21:10.281134 15117 solver.cpp:233] Iteration 16960, loss = 0.119866
I0526 03:21:10.281261 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.119866 (* 1 = 0.119866 loss)
I0526 03:21:10.281271 15117 sgd_solver.cpp:294] Iteration 16960, lr = 0.02
I0526 03:21:16.625375 15117 solver.cpp:233] Iteration 16970, loss = 0.120437
I0526 03:21:16.625427 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.120437 (* 1 = 0.120437 loss)
I0526 03:21:16.625434 15117 sgd_solver.cpp:294] Iteration 16970, lr = 0.02
I0526 03:21:22.967211 15117 solver.cpp:233] Iteration 16980, loss = 0.143167
I0526 03:21:22.967269 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.143167 (* 1 = 0.143167 loss)
I0526 03:21:22.967278 15117 sgd_solver.cpp:294] Iteration 16980, lr = 0.02
I0526 03:21:29.307857 15117 solver.cpp:233] Iteration 16990, loss = 0.108806
I0526 03:21:29.307909 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.108806 (* 1 = 0.108806 loss)
I0526 03:21:29.307916 15117 sgd_solver.cpp:294] Iteration 16990, lr = 0.02
I0526 03:21:35.047524 15117 solver.cpp:342] Iteration 17000, Testing net (#0)
I0526 03:21:47.917366 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8011
I0526 03:21:47.917484 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.790538 (* 1 = 0.790538 loss)
I0526 03:21:48.519558 15117 solver.cpp:233] Iteration 17000, loss = 0.154162
I0526 03:21:48.519605 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.154162 (* 1 = 0.154162 loss)
I0526 03:21:48.519613 15117 sgd_solver.cpp:294] Iteration 17000, lr = 0.02
I0526 03:21:54.861701 15117 solver.cpp:233] Iteration 17010, loss = 0.127684
I0526 03:21:54.861750 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.127684 (* 1 = 0.127684 loss)
I0526 03:21:54.861759 15117 sgd_solver.cpp:294] Iteration 17010, lr = 0.02
I0526 03:22:01.205984 15117 solver.cpp:233] Iteration 17020, loss = 0.116466
I0526 03:22:01.206043 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.116466 (* 1 = 0.116466 loss)
I0526 03:22:01.206050 15117 sgd_solver.cpp:294] Iteration 17020, lr = 0.02
I0526 03:22:07.551856 15117 solver.cpp:233] Iteration 17030, loss = 0.200714
I0526 03:22:07.551918 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.200714 (* 1 = 0.200714 loss)
I0526 03:22:07.551928 15117 sgd_solver.cpp:294] Iteration 17030, lr = 0.02
I0526 03:22:13.895395 15117 solver.cpp:233] Iteration 17040, loss = 0.103386
I0526 03:22:13.895444 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.103386 (* 1 = 0.103386 loss)
I0526 03:22:13.895452 15117 sgd_solver.cpp:294] Iteration 17040, lr = 0.02
I0526 03:22:20.239670 15117 solver.cpp:233] Iteration 17050, loss = 0.13273
I0526 03:22:20.239835 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.13273 (* 1 = 0.13273 loss)
I0526 03:22:20.239845 15117 sgd_solver.cpp:294] Iteration 17050, lr = 0.02
I0526 03:22:26.578688 15117 solver.cpp:233] Iteration 17060, loss = 0.115873
I0526 03:22:26.578737 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.115873 (* 1 = 0.115873 loss)
I0526 03:22:26.578747 15117 sgd_solver.cpp:294] Iteration 17060, lr = 0.02
I0526 03:22:32.921288 15117 solver.cpp:233] Iteration 17070, loss = 0.152866
I0526 03:22:32.921340 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.152866 (* 1 = 0.152866 loss)
I0526 03:22:32.921350 15117 sgd_solver.cpp:294] Iteration 17070, lr = 0.02
I0526 03:22:39.267520 15117 solver.cpp:233] Iteration 17080, loss = 0.1199
I0526 03:22:39.267568 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.1199 (* 1 = 0.1199 loss)
I0526 03:22:39.267577 15117 sgd_solver.cpp:294] Iteration 17080, lr = 0.02
I0526 03:22:45.612279 15117 solver.cpp:233] Iteration 17090, loss = 0.167731
I0526 03:22:45.612326 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.167731 (* 1 = 0.167731 loss)
I0526 03:22:45.612334 15117 sgd_solver.cpp:294] Iteration 17090, lr = 0.02
I0526 03:22:51.351868 15117 solver.cpp:342] Iteration 17100, Testing net (#0)
I0526 03:23:04.207602 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7716
I0526 03:23:04.207651 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.893165 (* 1 = 0.893165 loss)
I0526 03:23:04.808897 15117 solver.cpp:233] Iteration 17100, loss = 0.0929412
I0526 03:23:04.808946 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0929413 (* 1 = 0.0929413 loss)
I0526 03:23:04.808955 15117 sgd_solver.cpp:294] Iteration 17100, lr = 0.02
I0526 03:23:11.149664 15117 solver.cpp:233] Iteration 17110, loss = 0.150648
I0526 03:23:11.149716 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.150648 (* 1 = 0.150648 loss)
I0526 03:23:11.149725 15117 sgd_solver.cpp:294] Iteration 17110, lr = 0.02
I0526 03:23:17.490823 15117 solver.cpp:233] Iteration 17120, loss = 0.150744
I0526 03:23:17.490876 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.150744 (* 1 = 0.150744 loss)
I0526 03:23:17.490885 15117 sgd_solver.cpp:294] Iteration 17120, lr = 0.02
I0526 03:23:23.831905 15117 solver.cpp:233] Iteration 17130, loss = 0.0814203
I0526 03:23:23.832011 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0814203 (* 1 = 0.0814203 loss)
I0526 03:23:23.832020 15117 sgd_solver.cpp:294] Iteration 17130, lr = 0.02
I0526 03:23:30.172788 15117 solver.cpp:233] Iteration 17140, loss = 0.0977688
I0526 03:23:30.172842 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0977688 (* 1 = 0.0977688 loss)
I0526 03:23:30.172850 15117 sgd_solver.cpp:294] Iteration 17140, lr = 0.02
I0526 03:23:36.512275 15117 solver.cpp:233] Iteration 17150, loss = 0.257056
I0526 03:23:36.512322 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.257057 (* 1 = 0.257057 loss)
I0526 03:23:36.512331 15117 sgd_solver.cpp:294] Iteration 17150, lr = 0.02
I0526 03:23:42.854171 15117 solver.cpp:233] Iteration 17160, loss = 0.178539
I0526 03:23:42.854220 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.178539 (* 1 = 0.178539 loss)
I0526 03:23:42.854229 15117 sgd_solver.cpp:294] Iteration 17160, lr = 0.02
I0526 03:23:49.194711 15117 solver.cpp:233] Iteration 17170, loss = 0.152989
I0526 03:23:49.194763 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.152989 (* 1 = 0.152989 loss)
I0526 03:23:49.194772 15117 sgd_solver.cpp:294] Iteration 17170, lr = 0.02
I0526 03:23:55.536558 15117 solver.cpp:233] Iteration 17180, loss = 0.119153
I0526 03:23:55.536726 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.119153 (* 1 = 0.119153 loss)
I0526 03:23:55.536736 15117 sgd_solver.cpp:294] Iteration 17180, lr = 0.02
I0526 03:24:01.877187 15117 solver.cpp:233] Iteration 17190, loss = 0.102085
I0526 03:24:01.877235 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.102085 (* 1 = 0.102085 loss)
I0526 03:24:01.877244 15117 sgd_solver.cpp:294] Iteration 17190, lr = 0.02
I0526 03:24:07.613929 15117 solver.cpp:342] Iteration 17200, Testing net (#0)
I0526 03:24:20.467605 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8184
I0526 03:24:20.467651 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.622521 (* 1 = 0.622521 loss)
I0526 03:24:21.068632 15117 solver.cpp:233] Iteration 17200, loss = 0.140024
I0526 03:24:21.068677 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.140024 (* 1 = 0.140024 loss)
I0526 03:24:21.068686 15117 sgd_solver.cpp:294] Iteration 17200, lr = 0.02
I0526 03:24:27.402319 15117 solver.cpp:233] Iteration 17210, loss = 0.132265
I0526 03:24:27.402402 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.132265 (* 1 = 0.132265 loss)
I0526 03:24:27.402411 15117 sgd_solver.cpp:294] Iteration 17210, lr = 0.02
I0526 03:24:33.738127 15117 solver.cpp:233] Iteration 17220, loss = 0.17995
I0526 03:24:33.738175 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.17995 (* 1 = 0.17995 loss)
I0526 03:24:33.738183 15117 sgd_solver.cpp:294] Iteration 17220, lr = 0.02
I0526 03:24:40.068555 15117 solver.cpp:233] Iteration 17230, loss = 0.105355
I0526 03:24:40.068604 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.105355 (* 1 = 0.105355 loss)
I0526 03:24:40.068624 15117 sgd_solver.cpp:294] Iteration 17230, lr = 0.02
I0526 03:24:46.402324 15117 solver.cpp:233] Iteration 17240, loss = 0.129772
I0526 03:24:46.402375 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.129772 (* 1 = 0.129772 loss)
I0526 03:24:46.402384 15117 sgd_solver.cpp:294] Iteration 17240, lr = 0.02
I0526 03:24:52.735893 15117 solver.cpp:233] Iteration 17250, loss = 0.165351
I0526 03:24:52.735942 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.165351 (* 1 = 0.165351 loss)
I0526 03:24:52.735951 15117 sgd_solver.cpp:294] Iteration 17250, lr = 0.02
I0526 03:24:59.071110 15117 solver.cpp:233] Iteration 17260, loss = 0.0975134
I0526 03:24:59.071238 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0975134 (* 1 = 0.0975134 loss)
I0526 03:24:59.071247 15117 sgd_solver.cpp:294] Iteration 17260, lr = 0.02
I0526 03:25:05.411239 15117 solver.cpp:233] Iteration 17270, loss = 0.140969
I0526 03:25:05.411288 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.140969 (* 1 = 0.140969 loss)
I0526 03:25:05.411298 15117 sgd_solver.cpp:294] Iteration 17270, lr = 0.02
I0526 03:25:11.743649 15117 solver.cpp:233] Iteration 17280, loss = 0.0643643
I0526 03:25:11.743703 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0643643 (* 1 = 0.0643643 loss)
I0526 03:25:11.743712 15117 sgd_solver.cpp:294] Iteration 17280, lr = 0.02
I0526 03:25:18.082065 15117 solver.cpp:233] Iteration 17290, loss = 0.0937064
I0526 03:25:18.082115 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0937064 (* 1 = 0.0937064 loss)
I0526 03:25:18.082123 15117 sgd_solver.cpp:294] Iteration 17290, lr = 0.02
I0526 03:25:23.819499 15117 solver.cpp:342] Iteration 17300, Testing net (#0)
I0526 03:25:36.672577 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8058
I0526 03:25:36.672727 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.706234 (* 1 = 0.706234 loss)
I0526 03:25:37.275231 15117 solver.cpp:233] Iteration 17300, loss = 0.100224
I0526 03:25:37.275282 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.100224 (* 1 = 0.100224 loss)
I0526 03:25:37.275290 15117 sgd_solver.cpp:294] Iteration 17300, lr = 0.02
I0526 03:25:43.612422 15117 solver.cpp:233] Iteration 17310, loss = 0.217322
I0526 03:25:43.612469 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.217322 (* 1 = 0.217322 loss)
I0526 03:25:43.612478 15117 sgd_solver.cpp:294] Iteration 17310, lr = 0.02
I0526 03:25:49.949836 15117 solver.cpp:233] Iteration 17320, loss = 0.172231
I0526 03:25:49.949911 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.172231 (* 1 = 0.172231 loss)
I0526 03:25:49.949920 15117 sgd_solver.cpp:294] Iteration 17320, lr = 0.02
I0526 03:25:56.284747 15117 solver.cpp:233] Iteration 17330, loss = 0.232098
I0526 03:25:56.284796 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.232098 (* 1 = 0.232098 loss)
I0526 03:25:56.284804 15117 sgd_solver.cpp:294] Iteration 17330, lr = 0.02
I0526 03:26:02.619565 15117 solver.cpp:233] Iteration 17340, loss = 0.133597
I0526 03:26:02.619619 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.133597 (* 1 = 0.133597 loss)
I0526 03:26:02.619628 15117 sgd_solver.cpp:294] Iteration 17340, lr = 0.02
I0526 03:26:08.951347 15117 solver.cpp:233] Iteration 17350, loss = 0.132704
I0526 03:26:08.951442 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.132704 (* 1 = 0.132704 loss)
I0526 03:26:08.951452 15117 sgd_solver.cpp:294] Iteration 17350, lr = 0.02
I0526 03:26:15.287354 15117 solver.cpp:233] Iteration 17360, loss = 0.179229
I0526 03:26:15.287396 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.179229 (* 1 = 0.179229 loss)
I0526 03:26:15.287405 15117 sgd_solver.cpp:294] Iteration 17360, lr = 0.02
I0526 03:26:21.624734 15117 solver.cpp:233] Iteration 17370, loss = 0.139721
I0526 03:26:21.624790 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.139721 (* 1 = 0.139721 loss)
I0526 03:26:21.624799 15117 sgd_solver.cpp:294] Iteration 17370, lr = 0.02
I0526 03:26:27.960314 15117 solver.cpp:233] Iteration 17380, loss = 0.090374
I0526 03:26:27.960362 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0903741 (* 1 = 0.0903741 loss)
I0526 03:26:27.960371 15117 sgd_solver.cpp:294] Iteration 17380, lr = 0.02
I0526 03:26:34.299458 15117 solver.cpp:233] Iteration 17390, loss = 0.170021
I0526 03:26:34.299505 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.170021 (* 1 = 0.170021 loss)
I0526 03:26:34.299515 15117 sgd_solver.cpp:294] Iteration 17390, lr = 0.02
I0526 03:26:40.032512 15117 solver.cpp:342] Iteration 17400, Testing net (#0)
I0526 03:26:52.884747 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8203
I0526 03:26:52.884794 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.631235 (* 1 = 0.631235 loss)
I0526 03:26:53.485184 15117 solver.cpp:233] Iteration 17400, loss = 0.192641
I0526 03:26:53.485230 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.192641 (* 1 = 0.192641 loss)
I0526 03:26:53.485239 15117 sgd_solver.cpp:294] Iteration 17400, lr = 0.02
I0526 03:26:59.815578 15117 solver.cpp:233] Iteration 17410, loss = 0.231163
I0526 03:26:59.815628 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.231163 (* 1 = 0.231163 loss)
I0526 03:26:59.815646 15117 sgd_solver.cpp:294] Iteration 17410, lr = 0.02
I0526 03:27:06.152019 15117 solver.cpp:233] Iteration 17420, loss = 0.162132
I0526 03:27:06.152062 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.162132 (* 1 = 0.162132 loss)
I0526 03:27:06.152070 15117 sgd_solver.cpp:294] Iteration 17420, lr = 0.02
I0526 03:27:12.486870 15117 solver.cpp:233] Iteration 17430, loss = 0.181228
I0526 03:27:12.486946 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.181228 (* 1 = 0.181228 loss)
I0526 03:27:12.486954 15117 sgd_solver.cpp:294] Iteration 17430, lr = 0.02
I0526 03:27:18.817819 15117 solver.cpp:233] Iteration 17440, loss = 0.194368
I0526 03:27:18.817873 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.194368 (* 1 = 0.194368 loss)
I0526 03:27:18.817881 15117 sgd_solver.cpp:294] Iteration 17440, lr = 0.02
I0526 03:27:25.152387 15117 solver.cpp:233] Iteration 17450, loss = 0.145393
I0526 03:27:25.152439 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.145393 (* 1 = 0.145393 loss)
I0526 03:27:25.152447 15117 sgd_solver.cpp:294] Iteration 17450, lr = 0.02
I0526 03:27:31.491117 15117 solver.cpp:233] Iteration 17460, loss = 0.151217
I0526 03:27:31.491164 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.151217 (* 1 = 0.151217 loss)
I0526 03:27:31.491173 15117 sgd_solver.cpp:294] Iteration 17460, lr = 0.02
I0526 03:27:37.831439 15117 solver.cpp:233] Iteration 17470, loss = 0.16054
I0526 03:27:37.831498 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.16054 (* 1 = 0.16054 loss)
I0526 03:27:37.831506 15117 sgd_solver.cpp:294] Iteration 17470, lr = 0.02
I0526 03:27:44.166752 15117 solver.cpp:233] Iteration 17480, loss = 0.163689
I0526 03:27:44.166921 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.163689 (* 1 = 0.163689 loss)
I0526 03:27:44.166932 15117 sgd_solver.cpp:294] Iteration 17480, lr = 0.02
I0526 03:27:50.503592 15117 solver.cpp:233] Iteration 17490, loss = 0.122188
I0526 03:27:50.503643 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.122188 (* 1 = 0.122188 loss)
I0526 03:27:50.503651 15117 sgd_solver.cpp:294] Iteration 17490, lr = 0.02
I0526 03:27:56.239917 15117 solver.cpp:342] Iteration 17500, Testing net (#0)
I0526 03:28:09.099488 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8144
I0526 03:28:09.099540 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.719136 (* 1 = 0.719136 loss)
I0526 03:28:09.700681 15117 solver.cpp:233] Iteration 17500, loss = 0.155444
I0526 03:28:09.700729 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.155444 (* 1 = 0.155444 loss)
I0526 03:28:09.700738 15117 sgd_solver.cpp:294] Iteration 17500, lr = 0.02
I0526 03:28:16.035377 15117 solver.cpp:233] Iteration 17510, loss = 0.123043
I0526 03:28:16.035449 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.123043 (* 1 = 0.123043 loss)
I0526 03:28:16.035457 15117 sgd_solver.cpp:294] Iteration 17510, lr = 0.02
I0526 03:28:22.373982 15117 solver.cpp:233] Iteration 17520, loss = 0.124709
I0526 03:28:22.374032 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.124709 (* 1 = 0.124709 loss)
I0526 03:28:22.374042 15117 sgd_solver.cpp:294] Iteration 17520, lr = 0.02
I0526 03:28:28.713047 15117 solver.cpp:233] Iteration 17530, loss = 0.112567
I0526 03:28:28.713099 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.112568 (* 1 = 0.112568 loss)
I0526 03:28:28.713107 15117 sgd_solver.cpp:294] Iteration 17530, lr = 0.02
I0526 03:28:35.054316 15117 solver.cpp:233] Iteration 17540, loss = 0.109136
I0526 03:28:35.054379 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.109136 (* 1 = 0.109136 loss)
I0526 03:28:35.054388 15117 sgd_solver.cpp:294] Iteration 17540, lr = 0.02
I0526 03:28:41.392293 15117 solver.cpp:233] Iteration 17550, loss = 0.19212
I0526 03:28:41.392355 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.19212 (* 1 = 0.19212 loss)
I0526 03:28:41.392364 15117 sgd_solver.cpp:294] Iteration 17550, lr = 0.02
I0526 03:28:47.733974 15117 solver.cpp:233] Iteration 17560, loss = 0.142325
I0526 03:28:47.734050 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.142325 (* 1 = 0.142325 loss)
I0526 03:28:47.734058 15117 sgd_solver.cpp:294] Iteration 17560, lr = 0.02
I0526 03:28:54.068310 15117 solver.cpp:233] Iteration 17570, loss = 0.0757386
I0526 03:28:54.068356 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0757386 (* 1 = 0.0757386 loss)
I0526 03:28:54.068364 15117 sgd_solver.cpp:294] Iteration 17570, lr = 0.02
I0526 03:29:00.404561 15117 solver.cpp:233] Iteration 17580, loss = 0.164196
I0526 03:29:00.404614 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.164196 (* 1 = 0.164196 loss)
I0526 03:29:00.404623 15117 sgd_solver.cpp:294] Iteration 17580, lr = 0.02
I0526 03:29:06.740749 15117 solver.cpp:233] Iteration 17590, loss = 0.169937
I0526 03:29:06.740800 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.169937 (* 1 = 0.169937 loss)
I0526 03:29:06.740809 15117 sgd_solver.cpp:294] Iteration 17590, lr = 0.02
I0526 03:29:12.475203 15117 solver.cpp:342] Iteration 17600, Testing net (#0)
I0526 03:29:25.329848 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8168
I0526 03:29:25.329967 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.655641 (* 1 = 0.655641 loss)
I0526 03:29:25.932175 15117 solver.cpp:233] Iteration 17600, loss = 0.0926767
I0526 03:29:25.932224 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0926767 (* 1 = 0.0926767 loss)
I0526 03:29:25.932232 15117 sgd_solver.cpp:294] Iteration 17600, lr = 0.02
I0526 03:29:32.261131 15117 solver.cpp:233] Iteration 17610, loss = 0.20967
I0526 03:29:32.261194 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.20967 (* 1 = 0.20967 loss)
I0526 03:29:32.261203 15117 sgd_solver.cpp:294] Iteration 17610, lr = 0.02
I0526 03:29:38.595799 15117 solver.cpp:233] Iteration 17620, loss = 0.187479
I0526 03:29:38.595845 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.187479 (* 1 = 0.187479 loss)
I0526 03:29:38.595854 15117 sgd_solver.cpp:294] Iteration 17620, lr = 0.02
I0526 03:29:44.927533 15117 solver.cpp:233] Iteration 17630, loss = 0.253018
I0526 03:29:44.927577 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.253018 (* 1 = 0.253018 loss)
I0526 03:29:44.927585 15117 sgd_solver.cpp:294] Iteration 17630, lr = 0.02
I0526 03:29:51.261641 15117 solver.cpp:233] Iteration 17640, loss = 0.210915
I0526 03:29:51.261693 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.210915 (* 1 = 0.210915 loss)
I0526 03:29:51.261701 15117 sgd_solver.cpp:294] Iteration 17640, lr = 0.02
I0526 03:29:57.602828 15117 solver.cpp:233] Iteration 17650, loss = 0.11341
I0526 03:29:57.602910 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.11341 (* 1 = 0.11341 loss)
I0526 03:29:57.602919 15117 sgd_solver.cpp:294] Iteration 17650, lr = 0.02
I0526 03:30:03.942236 15117 solver.cpp:233] Iteration 17660, loss = 0.229603
I0526 03:30:03.942286 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.229603 (* 1 = 0.229603 loss)
I0526 03:30:03.942294 15117 sgd_solver.cpp:294] Iteration 17660, lr = 0.02
I0526 03:30:10.281589 15117 solver.cpp:233] Iteration 17670, loss = 0.126403
I0526 03:30:10.281637 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.126403 (* 1 = 0.126403 loss)
I0526 03:30:10.281646 15117 sgd_solver.cpp:294] Iteration 17670, lr = 0.02
I0526 03:30:16.620548 15117 solver.cpp:233] Iteration 17680, loss = 0.120069
I0526 03:30:16.620620 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.120069 (* 1 = 0.120069 loss)
I0526 03:30:16.620628 15117 sgd_solver.cpp:294] Iteration 17680, lr = 0.02
I0526 03:30:22.958715 15117 solver.cpp:233] Iteration 17690, loss = 0.106578
I0526 03:30:22.958765 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.106578 (* 1 = 0.106578 loss)
I0526 03:30:22.958775 15117 sgd_solver.cpp:294] Iteration 17690, lr = 0.02
I0526 03:30:28.693671 15117 solver.cpp:342] Iteration 17700, Testing net (#0)
I0526 03:30:41.544800 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8
I0526 03:30:41.544848 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.701453 (* 1 = 0.701453 loss)
I0526 03:30:42.146670 15117 solver.cpp:233] Iteration 17700, loss = 0.236023
I0526 03:30:42.146715 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.236023 (* 1 = 0.236023 loss)
I0526 03:30:42.146723 15117 sgd_solver.cpp:294] Iteration 17700, lr = 0.02
I0526 03:30:48.482851 15117 solver.cpp:233] Iteration 17710, loss = 0.215616
I0526 03:30:48.482909 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.215616 (* 1 = 0.215616 loss)
I0526 03:30:48.482918 15117 sgd_solver.cpp:294] Iteration 17710, lr = 0.02
I0526 03:30:54.814056 15117 solver.cpp:233] Iteration 17720, loss = 0.244131
I0526 03:30:54.814110 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.244131 (* 1 = 0.244131 loss)
I0526 03:30:54.814118 15117 sgd_solver.cpp:294] Iteration 17720, lr = 0.02
I0526 03:31:01.147629 15117 solver.cpp:233] Iteration 17730, loss = 0.207473
I0526 03:31:01.147801 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.207473 (* 1 = 0.207473 loss)
I0526 03:31:01.147812 15117 sgd_solver.cpp:294] Iteration 17730, lr = 0.02
I0526 03:31:07.484838 15117 solver.cpp:233] Iteration 17740, loss = 0.0838925
I0526 03:31:07.484911 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0838925 (* 1 = 0.0838925 loss)
I0526 03:31:07.484920 15117 sgd_solver.cpp:294] Iteration 17740, lr = 0.02
I0526 03:31:13.826057 15117 solver.cpp:233] Iteration 17750, loss = 0.116309
I0526 03:31:13.826109 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.116309 (* 1 = 0.116309 loss)
I0526 03:31:13.826117 15117 sgd_solver.cpp:294] Iteration 17750, lr = 0.02
I0526 03:31:20.162416 15117 solver.cpp:233] Iteration 17760, loss = 0.123912
I0526 03:31:20.162482 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.123912 (* 1 = 0.123912 loss)
I0526 03:31:20.162492 15117 sgd_solver.cpp:294] Iteration 17760, lr = 0.02
I0526 03:31:26.501363 15117 solver.cpp:233] Iteration 17770, loss = 0.151575
I0526 03:31:26.501413 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.151576 (* 1 = 0.151576 loss)
I0526 03:31:26.501422 15117 sgd_solver.cpp:294] Iteration 17770, lr = 0.02
I0526 03:31:32.836324 15117 solver.cpp:233] Iteration 17780, loss = 0.129376
I0526 03:31:32.836455 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.129376 (* 1 = 0.129376 loss)
I0526 03:31:32.836465 15117 sgd_solver.cpp:294] Iteration 17780, lr = 0.02
I0526 03:31:39.176403 15117 solver.cpp:233] Iteration 17790, loss = 0.149997
I0526 03:31:39.176450 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.149997 (* 1 = 0.149997 loss)
I0526 03:31:39.176457 15117 sgd_solver.cpp:294] Iteration 17790, lr = 0.02
I0526 03:31:44.909446 15117 solver.cpp:342] Iteration 17800, Testing net (#0)
I0526 03:31:57.745473 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8003
I0526 03:31:57.745525 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.759161 (* 1 = 0.759161 loss)
I0526 03:31:58.347508 15117 solver.cpp:233] Iteration 17800, loss = 0.219854
I0526 03:31:58.347553 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.219854 (* 1 = 0.219854 loss)
I0526 03:31:58.347563 15117 sgd_solver.cpp:294] Iteration 17800, lr = 0.02
I0526 03:32:04.685252 15117 solver.cpp:233] Iteration 17810, loss = 0.145804
I0526 03:32:04.685324 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.145804 (* 1 = 0.145804 loss)
I0526 03:32:04.685333 15117 sgd_solver.cpp:294] Iteration 17810, lr = 0.02
I0526 03:32:11.024067 15117 solver.cpp:233] Iteration 17820, loss = 0.125025
I0526 03:32:11.024118 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.125025 (* 1 = 0.125025 loss)
I0526 03:32:11.024127 15117 sgd_solver.cpp:294] Iteration 17820, lr = 0.02
I0526 03:32:17.358029 15117 solver.cpp:233] Iteration 17830, loss = 0.193327
I0526 03:32:17.358078 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.193327 (* 1 = 0.193327 loss)
I0526 03:32:17.358088 15117 sgd_solver.cpp:294] Iteration 17830, lr = 0.02
I0526 03:32:23.693572 15117 solver.cpp:233] Iteration 17840, loss = 0.165227
I0526 03:32:23.693620 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.165227 (* 1 = 0.165227 loss)
I0526 03:32:23.693629 15117 sgd_solver.cpp:294] Iteration 17840, lr = 0.02
I0526 03:32:30.031101 15117 solver.cpp:233] Iteration 17850, loss = 0.143797
I0526 03:32:30.031168 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.143797 (* 1 = 0.143797 loss)
I0526 03:32:30.031177 15117 sgd_solver.cpp:294] Iteration 17850, lr = 0.02
I0526 03:32:36.365810 15117 solver.cpp:233] Iteration 17860, loss = 0.0978551
I0526 03:32:36.365964 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0978552 (* 1 = 0.0978552 loss)
I0526 03:32:36.365975 15117 sgd_solver.cpp:294] Iteration 17860, lr = 0.02
I0526 03:32:42.699982 15117 solver.cpp:233] Iteration 17870, loss = 0.110703
I0526 03:32:42.700032 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.110703 (* 1 = 0.110703 loss)
I0526 03:32:42.700040 15117 sgd_solver.cpp:294] Iteration 17870, lr = 0.02
I0526 03:32:49.035817 15117 solver.cpp:233] Iteration 17880, loss = 0.125478
I0526 03:32:49.035879 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.125478 (* 1 = 0.125478 loss)
I0526 03:32:49.035888 15117 sgd_solver.cpp:294] Iteration 17880, lr = 0.02
I0526 03:32:55.376824 15117 solver.cpp:233] Iteration 17890, loss = 0.149425
I0526 03:32:55.376878 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.149425 (* 1 = 0.149425 loss)
I0526 03:32:55.376888 15117 sgd_solver.cpp:294] Iteration 17890, lr = 0.02
I0526 03:33:01.112515 15117 solver.cpp:342] Iteration 17900, Testing net (#0)
I0526 03:33:13.956879 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7866
I0526 03:33:13.956954 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.766752 (* 1 = 0.766752 loss)
I0526 03:33:14.556810 15117 solver.cpp:233] Iteration 17900, loss = 0.103426
I0526 03:33:14.556860 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.103426 (* 1 = 0.103426 loss)
I0526 03:33:14.556869 15117 sgd_solver.cpp:294] Iteration 17900, lr = 0.02
I0526 03:33:20.888543 15117 solver.cpp:233] Iteration 17910, loss = 0.216862
I0526 03:33:20.888592 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.216862 (* 1 = 0.216862 loss)
I0526 03:33:20.888599 15117 sgd_solver.cpp:294] Iteration 17910, lr = 0.02
I0526 03:33:27.226879 15117 solver.cpp:233] Iteration 17920, loss = 0.213383
I0526 03:33:27.226928 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.213383 (* 1 = 0.213383 loss)
I0526 03:33:27.226936 15117 sgd_solver.cpp:294] Iteration 17920, lr = 0.02
I0526 03:33:33.566531 15117 solver.cpp:233] Iteration 17930, loss = 0.189404
I0526 03:33:33.566582 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.189404 (* 1 = 0.189404 loss)
I0526 03:33:33.566601 15117 sgd_solver.cpp:294] Iteration 17930, lr = 0.02
I0526 03:33:39.903734 15117 solver.cpp:233] Iteration 17940, loss = 0.137021
I0526 03:33:39.903780 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.137021 (* 1 = 0.137021 loss)
I0526 03:33:39.903789 15117 sgd_solver.cpp:294] Iteration 17940, lr = 0.02
I0526 03:33:46.241209 15117 solver.cpp:233] Iteration 17950, loss = 0.14393
I0526 03:33:46.241291 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.14393 (* 1 = 0.14393 loss)
I0526 03:33:46.241300 15117 sgd_solver.cpp:294] Iteration 17950, lr = 0.02
I0526 03:33:52.577179 15117 solver.cpp:233] Iteration 17960, loss = 0.0719082
I0526 03:33:52.577232 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0719083 (* 1 = 0.0719083 loss)
I0526 03:33:52.577242 15117 sgd_solver.cpp:294] Iteration 17960, lr = 0.02
I0526 03:33:58.915877 15117 solver.cpp:233] Iteration 17970, loss = 0.0766517
I0526 03:33:58.915927 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0766517 (* 1 = 0.0766517 loss)
I0526 03:33:58.915935 15117 sgd_solver.cpp:294] Iteration 17970, lr = 0.02
I0526 03:34:05.247588 15117 solver.cpp:233] Iteration 17980, loss = 0.125756
I0526 03:34:05.247635 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.125756 (* 1 = 0.125756 loss)
I0526 03:34:05.247644 15117 sgd_solver.cpp:294] Iteration 17980, lr = 0.02
I0526 03:34:11.579141 15117 solver.cpp:233] Iteration 17990, loss = 0.08133
I0526 03:34:11.579200 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.08133 (* 1 = 0.08133 loss)
I0526 03:34:11.579208 15117 sgd_solver.cpp:294] Iteration 17990, lr = 0.02
I0526 03:34:17.306926 15117 solver.cpp:342] Iteration 18000, Testing net (#0)
I0526 03:34:30.150629 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7633
I0526 03:34:30.150681 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.05508 (* 1 = 1.05508 loss)
I0526 03:34:30.751786 15117 solver.cpp:233] Iteration 18000, loss = 0.148065
I0526 03:34:30.751834 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.148065 (* 1 = 0.148065 loss)
I0526 03:34:30.751842 15117 sgd_solver.cpp:294] Iteration 18000, lr = 0.02
I0526 03:34:37.084226 15117 solver.cpp:233] Iteration 18010, loss = 0.100754
I0526 03:34:37.084276 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.100754 (* 1 = 0.100754 loss)
I0526 03:34:37.084286 15117 sgd_solver.cpp:294] Iteration 18010, lr = 0.02
I0526 03:34:43.421156 15117 solver.cpp:233] Iteration 18020, loss = 0.111075
I0526 03:34:43.421208 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.111075 (* 1 = 0.111075 loss)
I0526 03:34:43.421216 15117 sgd_solver.cpp:294] Iteration 18020, lr = 0.02
I0526 03:34:49.751996 15117 solver.cpp:233] Iteration 18030, loss = 0.222445
I0526 03:34:49.752071 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.222445 (* 1 = 0.222445 loss)
I0526 03:34:49.752080 15117 sgd_solver.cpp:294] Iteration 18030, lr = 0.02
I0526 03:34:56.087968 15117 solver.cpp:233] Iteration 18040, loss = 0.100266
I0526 03:34:56.088019 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.100266 (* 1 = 0.100266 loss)
I0526 03:34:56.088028 15117 sgd_solver.cpp:294] Iteration 18040, lr = 0.02
I0526 03:35:02.424751 15117 solver.cpp:233] Iteration 18050, loss = 0.220882
I0526 03:35:02.424804 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.220882 (* 1 = 0.220882 loss)
I0526 03:35:02.424813 15117 sgd_solver.cpp:294] Iteration 18050, lr = 0.02
I0526 03:35:08.761426 15117 solver.cpp:233] Iteration 18060, loss = 0.225121
I0526 03:35:08.761476 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.225121 (* 1 = 0.225121 loss)
I0526 03:35:08.761484 15117 sgd_solver.cpp:294] Iteration 18060, lr = 0.02
I0526 03:35:15.096348 15117 solver.cpp:233] Iteration 18070, loss = 0.235399
I0526 03:35:15.096396 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.235399 (* 1 = 0.235399 loss)
I0526 03:35:15.096405 15117 sgd_solver.cpp:294] Iteration 18070, lr = 0.02
I0526 03:35:21.428361 15117 solver.cpp:233] Iteration 18080, loss = 0.110479
I0526 03:35:21.428434 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.110479 (* 1 = 0.110479 loss)
I0526 03:35:21.428444 15117 sgd_solver.cpp:294] Iteration 18080, lr = 0.02
I0526 03:35:27.758699 15117 solver.cpp:233] Iteration 18090, loss = 0.15119
I0526 03:35:27.758749 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.15119 (* 1 = 0.15119 loss)
I0526 03:35:27.758757 15117 sgd_solver.cpp:294] Iteration 18090, lr = 0.02
I0526 03:35:33.490979 15117 solver.cpp:342] Iteration 18100, Testing net (#0)
I0526 03:35:46.347977 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7416
I0526 03:35:46.348052 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.04713 (* 1 = 1.04713 loss)
I0526 03:35:46.948258 15117 solver.cpp:233] Iteration 18100, loss = 0.160801
I0526 03:35:46.948307 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.160801 (* 1 = 0.160801 loss)
I0526 03:35:46.948317 15117 sgd_solver.cpp:294] Iteration 18100, lr = 0.02
I0526 03:35:53.281515 15117 solver.cpp:233] Iteration 18110, loss = 0.174293
I0526 03:35:53.281646 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.174293 (* 1 = 0.174293 loss)
I0526 03:35:53.281656 15117 sgd_solver.cpp:294] Iteration 18110, lr = 0.02
I0526 03:35:59.615973 15117 solver.cpp:233] Iteration 18120, loss = 0.143748
I0526 03:35:59.616034 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.143748 (* 1 = 0.143748 loss)
I0526 03:35:59.616050 15117 sgd_solver.cpp:294] Iteration 18120, lr = 0.02
I0526 03:36:05.949934 15117 solver.cpp:233] Iteration 18130, loss = 0.166446
I0526 03:36:05.950007 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.166446 (* 1 = 0.166446 loss)
I0526 03:36:05.950021 15117 sgd_solver.cpp:294] Iteration 18130, lr = 0.02
I0526 03:36:12.280496 15117 solver.cpp:233] Iteration 18140, loss = 0.187893
I0526 03:36:12.280547 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.187893 (* 1 = 0.187893 loss)
I0526 03:36:12.280556 15117 sgd_solver.cpp:294] Iteration 18140, lr = 0.02
I0526 03:36:18.612795 15117 solver.cpp:233] Iteration 18150, loss = 0.107628
I0526 03:36:18.612854 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.107628 (* 1 = 0.107628 loss)
I0526 03:36:18.612862 15117 sgd_solver.cpp:294] Iteration 18150, lr = 0.02
I0526 03:36:24.944844 15117 solver.cpp:233] Iteration 18160, loss = 0.194646
I0526 03:36:24.944998 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.194646 (* 1 = 0.194646 loss)
I0526 03:36:24.945008 15117 sgd_solver.cpp:294] Iteration 18160, lr = 0.02
I0526 03:36:31.275529 15117 solver.cpp:233] Iteration 18170, loss = 0.124998
I0526 03:36:31.275591 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.124998 (* 1 = 0.124998 loss)
I0526 03:36:31.275599 15117 sgd_solver.cpp:294] Iteration 18170, lr = 0.02
I0526 03:36:37.610942 15117 solver.cpp:233] Iteration 18180, loss = 0.130269
I0526 03:36:37.610992 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.130269 (* 1 = 0.130269 loss)
I0526 03:36:37.611001 15117 sgd_solver.cpp:294] Iteration 18180, lr = 0.02
I0526 03:36:43.939656 15117 solver.cpp:233] Iteration 18190, loss = 0.178616
I0526 03:36:43.939704 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.178616 (* 1 = 0.178616 loss)
I0526 03:36:43.939713 15117 sgd_solver.cpp:294] Iteration 18190, lr = 0.02
I0526 03:36:49.669656 15117 solver.cpp:342] Iteration 18200, Testing net (#0)
I0526 03:37:02.510231 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7827
I0526 03:37:02.510396 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.909772 (* 1 = 0.909772 loss)
I0526 03:37:03.110126 15117 solver.cpp:233] Iteration 18200, loss = 0.160346
I0526 03:37:03.110177 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.160346 (* 1 = 0.160346 loss)
I0526 03:37:03.110188 15117 sgd_solver.cpp:294] Iteration 18200, lr = 0.02
I0526 03:37:09.446774 15117 solver.cpp:233] Iteration 18210, loss = 0.143157
I0526 03:37:09.446830 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.143157 (* 1 = 0.143157 loss)
I0526 03:37:09.446840 15117 sgd_solver.cpp:294] Iteration 18210, lr = 0.02
I0526 03:37:15.783159 15117 solver.cpp:233] Iteration 18220, loss = 0.269866
I0526 03:37:15.783206 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.269866 (* 1 = 0.269866 loss)
I0526 03:37:15.783215 15117 sgd_solver.cpp:294] Iteration 18220, lr = 0.02
I0526 03:37:22.110522 15117 solver.cpp:233] Iteration 18230, loss = 0.138888
I0526 03:37:22.110570 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.138888 (* 1 = 0.138888 loss)
I0526 03:37:22.110579 15117 sgd_solver.cpp:294] Iteration 18230, lr = 0.02
I0526 03:37:28.444623 15117 solver.cpp:233] Iteration 18240, loss = 0.169435
I0526 03:37:28.444672 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.169435 (* 1 = 0.169435 loss)
I0526 03:37:28.444681 15117 sgd_solver.cpp:294] Iteration 18240, lr = 0.02
I0526 03:37:34.779480 15117 solver.cpp:233] Iteration 18250, loss = 0.215895
I0526 03:37:34.779629 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.215895 (* 1 = 0.215895 loss)
I0526 03:37:34.779639 15117 sgd_solver.cpp:294] Iteration 18250, lr = 0.02
I0526 03:37:41.118417 15117 solver.cpp:233] Iteration 18260, loss = 0.197522
I0526 03:37:41.118464 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.197522 (* 1 = 0.197522 loss)
I0526 03:37:41.118477 15117 sgd_solver.cpp:294] Iteration 18260, lr = 0.02
I0526 03:37:47.455423 15117 solver.cpp:233] Iteration 18270, loss = 0.204003
I0526 03:37:47.455478 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.204003 (* 1 = 0.204003 loss)
I0526 03:37:47.455487 15117 sgd_solver.cpp:294] Iteration 18270, lr = 0.02
I0526 03:37:53.794344 15117 solver.cpp:233] Iteration 18280, loss = 0.113524
I0526 03:37:53.794409 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.113524 (* 1 = 0.113524 loss)
I0526 03:37:53.794417 15117 sgd_solver.cpp:294] Iteration 18280, lr = 0.02
I0526 03:38:00.133222 15117 solver.cpp:233] Iteration 18290, loss = 0.0898518
I0526 03:38:00.133270 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0898518 (* 1 = 0.0898518 loss)
I0526 03:38:00.133278 15117 sgd_solver.cpp:294] Iteration 18290, lr = 0.02
I0526 03:38:05.868755 15117 solver.cpp:342] Iteration 18300, Testing net (#0)
I0526 03:38:18.719918 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.815
I0526 03:38:18.719969 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.701796 (* 1 = 0.701796 loss)
I0526 03:38:19.321346 15117 solver.cpp:233] Iteration 18300, loss = 0.153017
I0526 03:38:19.321393 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.153017 (* 1 = 0.153017 loss)
I0526 03:38:19.321403 15117 sgd_solver.cpp:294] Iteration 18300, lr = 0.02
I0526 03:38:25.654661 15117 solver.cpp:233] Iteration 18310, loss = 0.162315
I0526 03:38:25.654711 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.162315 (* 1 = 0.162315 loss)
I0526 03:38:25.654718 15117 sgd_solver.cpp:294] Iteration 18310, lr = 0.02
I0526 03:38:31.988736 15117 solver.cpp:233] Iteration 18320, loss = 0.155911
I0526 03:38:31.988783 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.155911 (* 1 = 0.155911 loss)
I0526 03:38:31.988790 15117 sgd_solver.cpp:294] Iteration 18320, lr = 0.02
I0526 03:38:38.325356 15117 solver.cpp:233] Iteration 18330, loss = 0.228602
I0526 03:38:38.325480 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.228602 (* 1 = 0.228602 loss)
I0526 03:38:38.325490 15117 sgd_solver.cpp:294] Iteration 18330, lr = 0.02
I0526 03:38:44.665055 15117 solver.cpp:233] Iteration 18340, loss = 0.0529901
I0526 03:38:44.665103 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0529902 (* 1 = 0.0529902 loss)
I0526 03:38:44.665112 15117 sgd_solver.cpp:294] Iteration 18340, lr = 0.02
I0526 03:38:51.000957 15117 solver.cpp:233] Iteration 18350, loss = 0.0685298
I0526 03:38:51.001006 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0685299 (* 1 = 0.0685299 loss)
I0526 03:38:51.001014 15117 sgd_solver.cpp:294] Iteration 18350, lr = 0.02
I0526 03:38:57.333107 15117 solver.cpp:233] Iteration 18360, loss = 0.147641
I0526 03:38:57.333159 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.147641 (* 1 = 0.147641 loss)
I0526 03:38:57.333168 15117 sgd_solver.cpp:294] Iteration 18360, lr = 0.02
I0526 03:39:03.668961 15117 solver.cpp:233] Iteration 18370, loss = 0.0703697
I0526 03:39:03.669037 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0703698 (* 1 = 0.0703698 loss)
I0526 03:39:03.669045 15117 sgd_solver.cpp:294] Iteration 18370, lr = 0.02
I0526 03:39:10.005010 15117 solver.cpp:233] Iteration 18380, loss = 0.133816
I0526 03:39:10.005077 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.133816 (* 1 = 0.133816 loss)
I0526 03:39:10.005085 15117 sgd_solver.cpp:294] Iteration 18380, lr = 0.02
I0526 03:39:16.337538 15117 solver.cpp:233] Iteration 18390, loss = 0.173878
I0526 03:39:16.337584 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.173878 (* 1 = 0.173878 loss)
I0526 03:39:16.337592 15117 sgd_solver.cpp:294] Iteration 18390, lr = 0.02
I0526 03:39:22.066685 15117 solver.cpp:342] Iteration 18400, Testing net (#0)
I0526 03:39:34.909365 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8275
I0526 03:39:34.909421 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.663877 (* 1 = 0.663877 loss)
I0526 03:39:35.510438 15117 solver.cpp:233] Iteration 18400, loss = 0.12118
I0526 03:39:35.510484 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.12118 (* 1 = 0.12118 loss)
I0526 03:39:35.510493 15117 sgd_solver.cpp:294] Iteration 18400, lr = 0.02
I0526 03:39:41.845707 15117 solver.cpp:233] Iteration 18410, loss = 0.139336
I0526 03:39:41.845856 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.139336 (* 1 = 0.139336 loss)
I0526 03:39:41.845867 15117 sgd_solver.cpp:294] Iteration 18410, lr = 0.02
I0526 03:39:48.181814 15117 solver.cpp:233] Iteration 18420, loss = 0.113069
I0526 03:39:48.181862 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.113069 (* 1 = 0.113069 loss)
I0526 03:39:48.181869 15117 sgd_solver.cpp:294] Iteration 18420, lr = 0.02
I0526 03:39:54.512403 15117 solver.cpp:233] Iteration 18430, loss = 0.190576
I0526 03:39:54.512465 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.190576 (* 1 = 0.190576 loss)
I0526 03:39:54.512471 15117 sgd_solver.cpp:294] Iteration 18430, lr = 0.02
I0526 03:40:00.851516 15117 solver.cpp:233] Iteration 18440, loss = 0.098589
I0526 03:40:00.851563 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0985891 (* 1 = 0.0985891 loss)
I0526 03:40:00.851572 15117 sgd_solver.cpp:294] Iteration 18440, lr = 0.02
I0526 03:40:07.192271 15117 solver.cpp:233] Iteration 18450, loss = 0.149092
I0526 03:40:07.192337 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.149092 (* 1 = 0.149092 loss)
I0526 03:40:07.192345 15117 sgd_solver.cpp:294] Iteration 18450, lr = 0.02
I0526 03:40:13.524622 15117 solver.cpp:233] Iteration 18460, loss = 0.0861175
I0526 03:40:13.524742 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0861176 (* 1 = 0.0861176 loss)
I0526 03:40:13.524762 15117 sgd_solver.cpp:294] Iteration 18460, lr = 0.02
I0526 03:40:19.858630 15117 solver.cpp:233] Iteration 18470, loss = 0.172356
I0526 03:40:19.858701 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.172356 (* 1 = 0.172356 loss)
I0526 03:40:19.858711 15117 sgd_solver.cpp:294] Iteration 18470, lr = 0.02
I0526 03:40:26.193701 15117 solver.cpp:233] Iteration 18480, loss = 0.141966
I0526 03:40:26.193747 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.141966 (* 1 = 0.141966 loss)
I0526 03:40:26.193755 15117 sgd_solver.cpp:294] Iteration 18480, lr = 0.02
I0526 03:40:32.547993 15117 solver.cpp:233] Iteration 18490, loss = 0.134408
I0526 03:40:32.548039 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.134408 (* 1 = 0.134408 loss)
I0526 03:40:32.548048 15117 sgd_solver.cpp:294] Iteration 18490, lr = 0.02
I0526 03:40:38.293387 15117 solver.cpp:342] Iteration 18500, Testing net (#0)
I0526 03:40:51.143280 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.821
I0526 03:40:51.143409 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.671064 (* 1 = 0.671064 loss)
I0526 03:40:51.745499 15117 solver.cpp:233] Iteration 18500, loss = 0.178374
I0526 03:40:51.745544 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.178374 (* 1 = 0.178374 loss)
I0526 03:40:51.745553 15117 sgd_solver.cpp:294] Iteration 18500, lr = 0.02
I0526 03:40:58.086567 15117 solver.cpp:233] Iteration 18510, loss = 0.100272
I0526 03:40:58.086619 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.100272 (* 1 = 0.100272 loss)
I0526 03:40:58.086628 15117 sgd_solver.cpp:294] Iteration 18510, lr = 0.02
I0526 03:41:04.427724 15117 solver.cpp:233] Iteration 18520, loss = 0.0650144
I0526 03:41:04.427789 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0650144 (* 1 = 0.0650144 loss)
I0526 03:41:04.427809 15117 sgd_solver.cpp:294] Iteration 18520, lr = 0.02
I0526 03:41:10.766855 15117 solver.cpp:233] Iteration 18530, loss = 0.12137
I0526 03:41:10.766896 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.12137 (* 1 = 0.12137 loss)
I0526 03:41:10.766911 15117 sgd_solver.cpp:294] Iteration 18530, lr = 0.02
I0526 03:41:17.109050 15117 solver.cpp:233] Iteration 18540, loss = 0.122154
I0526 03:41:17.109098 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.122154 (* 1 = 0.122154 loss)
I0526 03:41:17.109107 15117 sgd_solver.cpp:294] Iteration 18540, lr = 0.02
I0526 03:41:23.445327 15117 solver.cpp:233] Iteration 18550, loss = 0.212969
I0526 03:41:23.445582 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.212969 (* 1 = 0.212969 loss)
I0526 03:41:23.445616 15117 sgd_solver.cpp:294] Iteration 18550, lr = 0.02
I0526 03:41:29.785130 15117 solver.cpp:233] Iteration 18560, loss = 0.193943
I0526 03:41:29.785183 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.193943 (* 1 = 0.193943 loss)
I0526 03:41:29.785192 15117 sgd_solver.cpp:294] Iteration 18560, lr = 0.02
I0526 03:41:36.127096 15117 solver.cpp:233] Iteration 18570, loss = 0.156522
I0526 03:41:36.127140 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.156522 (* 1 = 0.156522 loss)
I0526 03:41:36.127146 15117 sgd_solver.cpp:294] Iteration 18570, lr = 0.02
I0526 03:41:42.468956 15117 solver.cpp:233] Iteration 18580, loss = 0.208317
I0526 03:41:42.468999 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.208317 (* 1 = 0.208317 loss)
I0526 03:41:42.469007 15117 sgd_solver.cpp:294] Iteration 18580, lr = 0.02
I0526 03:41:48.808318 15117 solver.cpp:233] Iteration 18590, loss = 0.140515
I0526 03:41:48.808367 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.140515 (* 1 = 0.140515 loss)
I0526 03:41:48.808373 15117 sgd_solver.cpp:294] Iteration 18590, lr = 0.02
I0526 03:41:54.548704 15117 solver.cpp:342] Iteration 18600, Testing net (#0)
I0526 03:42:07.399909 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7843
I0526 03:42:07.399953 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.800445 (* 1 = 0.800445 loss)
I0526 03:42:08.001458 15117 solver.cpp:233] Iteration 18600, loss = 0.154122
I0526 03:42:08.001495 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.154122 (* 1 = 0.154122 loss)
I0526 03:42:08.001502 15117 sgd_solver.cpp:294] Iteration 18600, lr = 0.02
I0526 03:42:14.346369 15117 solver.cpp:233] Iteration 18610, loss = 0.0913337
I0526 03:42:14.346412 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0913337 (* 1 = 0.0913337 loss)
I0526 03:42:14.346421 15117 sgd_solver.cpp:294] Iteration 18610, lr = 0.02
I0526 03:42:20.687055 15117 solver.cpp:233] Iteration 18620, loss = 0.112367
I0526 03:42:20.687098 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.112367 (* 1 = 0.112367 loss)
I0526 03:42:20.687104 15117 sgd_solver.cpp:294] Iteration 18620, lr = 0.02
I0526 03:42:27.029377 15117 solver.cpp:233] Iteration 18630, loss = 0.245471
I0526 03:42:27.029502 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.245471 (* 1 = 0.245471 loss)
I0526 03:42:27.029512 15117 sgd_solver.cpp:294] Iteration 18630, lr = 0.02
I0526 03:42:33.371206 15117 solver.cpp:233] Iteration 18640, loss = 0.144341
I0526 03:42:33.371248 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.144341 (* 1 = 0.144341 loss)
I0526 03:42:33.371254 15117 sgd_solver.cpp:294] Iteration 18640, lr = 0.02
I0526 03:42:39.713147 15117 solver.cpp:233] Iteration 18650, loss = 0.134805
I0526 03:42:39.713191 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.134805 (* 1 = 0.134805 loss)
I0526 03:42:39.713198 15117 sgd_solver.cpp:294] Iteration 18650, lr = 0.02
I0526 03:42:46.051537 15117 solver.cpp:233] Iteration 18660, loss = 0.183096
I0526 03:42:46.051591 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.183096 (* 1 = 0.183096 loss)
I0526 03:42:46.051601 15117 sgd_solver.cpp:294] Iteration 18660, lr = 0.02
I0526 03:42:52.391010 15117 solver.cpp:233] Iteration 18670, loss = 0.240469
I0526 03:42:52.391054 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.240469 (* 1 = 0.240469 loss)
I0526 03:42:52.391068 15117 sgd_solver.cpp:294] Iteration 18670, lr = 0.02
I0526 03:42:58.730902 15117 solver.cpp:233] Iteration 18680, loss = 0.11807
I0526 03:42:58.731088 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.11807 (* 1 = 0.11807 loss)
I0526 03:42:58.731098 15117 sgd_solver.cpp:294] Iteration 18680, lr = 0.02
I0526 03:43:05.070889 15117 solver.cpp:233] Iteration 18690, loss = 0.185717
I0526 03:43:05.070932 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.185717 (* 1 = 0.185717 loss)
I0526 03:43:05.070940 15117 sgd_solver.cpp:294] Iteration 18690, lr = 0.02
I0526 03:43:10.810978 15117 solver.cpp:342] Iteration 18700, Testing net (#0)
I0526 03:43:23.667906 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8305
I0526 03:43:23.667959 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.706493 (* 1 = 0.706493 loss)
I0526 03:43:24.270936 15117 solver.cpp:233] Iteration 18700, loss = 0.183021
I0526 03:43:24.270994 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.183021 (* 1 = 0.183021 loss)
I0526 03:43:24.271003 15117 sgd_solver.cpp:294] Iteration 18700, lr = 0.02
I0526 03:43:30.611901 15117 solver.cpp:233] Iteration 18710, loss = 0.149656
I0526 03:43:30.612017 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.149656 (* 1 = 0.149656 loss)
I0526 03:43:30.612026 15117 sgd_solver.cpp:294] Iteration 18710, lr = 0.02
I0526 03:43:36.954744 15117 solver.cpp:233] Iteration 18720, loss = 0.179963
I0526 03:43:36.954792 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.179963 (* 1 = 0.179963 loss)
I0526 03:43:36.954799 15117 sgd_solver.cpp:294] Iteration 18720, lr = 0.02
I0526 03:43:43.292054 15117 solver.cpp:233] Iteration 18730, loss = 0.128386
I0526 03:43:43.292100 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.128386 (* 1 = 0.128386 loss)
I0526 03:43:43.292109 15117 sgd_solver.cpp:294] Iteration 18730, lr = 0.02
I0526 03:43:49.628631 15117 solver.cpp:233] Iteration 18740, loss = 0.125541
I0526 03:43:49.628687 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.125541 (* 1 = 0.125541 loss)
I0526 03:43:49.628696 15117 sgd_solver.cpp:294] Iteration 18740, lr = 0.02
I0526 03:43:55.969457 15117 solver.cpp:233] Iteration 18750, loss = 0.0576411
I0526 03:43:55.969508 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0576412 (* 1 = 0.0576412 loss)
I0526 03:43:55.969517 15117 sgd_solver.cpp:294] Iteration 18750, lr = 0.02
I0526 03:44:02.303083 15117 solver.cpp:233] Iteration 18760, loss = 0.206056
I0526 03:44:02.303220 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.206056 (* 1 = 0.206056 loss)
I0526 03:44:02.303231 15117 sgd_solver.cpp:294] Iteration 18760, lr = 0.02
I0526 03:44:08.640429 15117 solver.cpp:233] Iteration 18770, loss = 0.130149
I0526 03:44:08.640480 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.130149 (* 1 = 0.130149 loss)
I0526 03:44:08.640487 15117 sgd_solver.cpp:294] Iteration 18770, lr = 0.02
I0526 03:44:14.971863 15117 solver.cpp:233] Iteration 18780, loss = 0.108222
I0526 03:44:14.971928 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.108222 (* 1 = 0.108222 loss)
I0526 03:44:14.971938 15117 sgd_solver.cpp:294] Iteration 18780, lr = 0.02
I0526 03:44:21.309455 15117 solver.cpp:233] Iteration 18790, loss = 0.133544
I0526 03:44:21.309512 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.133544 (* 1 = 0.133544 loss)
I0526 03:44:21.309521 15117 sgd_solver.cpp:294] Iteration 18790, lr = 0.02
I0526 03:44:27.045755 15117 solver.cpp:342] Iteration 18800, Testing net (#0)
I0526 03:44:39.897280 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7882
I0526 03:44:39.897459 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.872914 (* 1 = 0.872914 loss)
I0526 03:44:40.498242 15117 solver.cpp:233] Iteration 18800, loss = 0.111966
I0526 03:44:40.498286 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.111966 (* 1 = 0.111966 loss)
I0526 03:44:40.498301 15117 sgd_solver.cpp:294] Iteration 18800, lr = 0.02
I0526 03:44:46.836354 15117 solver.cpp:233] Iteration 18810, loss = 0.121682
I0526 03:44:46.836408 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.121682 (* 1 = 0.121682 loss)
I0526 03:44:46.836417 15117 sgd_solver.cpp:294] Iteration 18810, lr = 0.02
I0526 03:44:53.167469 15117 solver.cpp:233] Iteration 18820, loss = 0.160266
I0526 03:44:53.167518 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.160266 (* 1 = 0.160266 loss)
I0526 03:44:53.167526 15117 sgd_solver.cpp:294] Iteration 18820, lr = 0.02
I0526 03:44:59.509749 15117 solver.cpp:233] Iteration 18830, loss = 0.112371
I0526 03:44:59.509805 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.112372 (* 1 = 0.112372 loss)
I0526 03:44:59.509814 15117 sgd_solver.cpp:294] Iteration 18830, lr = 0.02
I0526 03:45:05.848716 15117 solver.cpp:233] Iteration 18840, loss = 0.15524
I0526 03:45:05.848762 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.15524 (* 1 = 0.15524 loss)
I0526 03:45:05.848770 15117 sgd_solver.cpp:294] Iteration 18840, lr = 0.02
I0526 03:45:12.191575 15117 solver.cpp:233] Iteration 18850, loss = 0.107024
I0526 03:45:12.191831 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.107024 (* 1 = 0.107024 loss)
I0526 03:45:12.191867 15117 sgd_solver.cpp:294] Iteration 18850, lr = 0.02
I0526 03:45:18.529940 15117 solver.cpp:233] Iteration 18860, loss = 0.0967537
I0526 03:45:18.530009 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0967538 (* 1 = 0.0967538 loss)
I0526 03:45:18.530017 15117 sgd_solver.cpp:294] Iteration 18860, lr = 0.02
I0526 03:45:24.869094 15117 solver.cpp:233] Iteration 18870, loss = 0.169117
I0526 03:45:24.869139 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.169117 (* 1 = 0.169117 loss)
I0526 03:45:24.869148 15117 sgd_solver.cpp:294] Iteration 18870, lr = 0.02
I0526 03:45:31.209744 15117 solver.cpp:233] Iteration 18880, loss = 0.15294
I0526 03:45:31.209787 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.15294 (* 1 = 0.15294 loss)
I0526 03:45:31.209794 15117 sgd_solver.cpp:294] Iteration 18880, lr = 0.02
I0526 03:45:37.552815 15117 solver.cpp:233] Iteration 18890, loss = 0.126219
I0526 03:45:37.552856 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.126219 (* 1 = 0.126219 loss)
I0526 03:45:37.552863 15117 sgd_solver.cpp:294] Iteration 18890, lr = 0.02
I0526 03:45:43.292132 15117 solver.cpp:342] Iteration 18900, Testing net (#0)
I0526 03:45:56.147186 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8376
I0526 03:45:56.147225 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.562486 (* 1 = 0.562486 loss)
I0526 03:45:56.750764 15117 solver.cpp:233] Iteration 18900, loss = 0.125371
I0526 03:45:56.750815 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.125371 (* 1 = 0.125371 loss)
I0526 03:45:56.750824 15117 sgd_solver.cpp:294] Iteration 18900, lr = 0.02
I0526 03:46:03.092633 15117 solver.cpp:233] Iteration 18910, loss = 0.226824
I0526 03:46:03.092679 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.226824 (* 1 = 0.226824 loss)
I0526 03:46:03.092686 15117 sgd_solver.cpp:294] Iteration 18910, lr = 0.02
I0526 03:46:09.434074 15117 solver.cpp:233] Iteration 18920, loss = 0.0860975
I0526 03:46:09.434119 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0860975 (* 1 = 0.0860975 loss)
I0526 03:46:09.434126 15117 sgd_solver.cpp:294] Iteration 18920, lr = 0.02
I0526 03:46:15.775104 15117 solver.cpp:233] Iteration 18930, loss = 0.0960393
I0526 03:46:15.775291 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0960393 (* 1 = 0.0960393 loss)
I0526 03:46:15.775321 15117 sgd_solver.cpp:294] Iteration 18930, lr = 0.02
I0526 03:46:22.110307 15117 solver.cpp:233] Iteration 18940, loss = 0.206106
I0526 03:46:22.110366 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.206106 (* 1 = 0.206106 loss)
I0526 03:46:22.110383 15117 sgd_solver.cpp:294] Iteration 18940, lr = 0.02
I0526 03:46:28.453009 15117 solver.cpp:233] Iteration 18950, loss = 0.247271
I0526 03:46:28.453059 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.247271 (* 1 = 0.247271 loss)
I0526 03:46:28.453068 15117 sgd_solver.cpp:294] Iteration 18950, lr = 0.02
I0526 03:46:34.792306 15117 solver.cpp:233] Iteration 18960, loss = 0.11353
I0526 03:46:34.792348 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.11353 (* 1 = 0.11353 loss)
I0526 03:46:34.792356 15117 sgd_solver.cpp:294] Iteration 18960, lr = 0.02
I0526 03:46:41.127167 15117 solver.cpp:233] Iteration 18970, loss = 0.0919913
I0526 03:46:41.127218 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0919913 (* 1 = 0.0919913 loss)
I0526 03:46:41.127228 15117 sgd_solver.cpp:294] Iteration 18970, lr = 0.02
I0526 03:46:47.472265 15117 solver.cpp:233] Iteration 18980, loss = 0.0912624
I0526 03:46:47.472422 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0912625 (* 1 = 0.0912625 loss)
I0526 03:46:47.472432 15117 sgd_solver.cpp:294] Iteration 18980, lr = 0.02
I0526 03:46:53.811650 15117 solver.cpp:233] Iteration 18990, loss = 0.159376
I0526 03:46:53.811712 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.159376 (* 1 = 0.159376 loss)
I0526 03:46:53.811731 15117 sgd_solver.cpp:294] Iteration 18990, lr = 0.02
I0526 03:46:59.552228 15117 solver.cpp:342] Iteration 19000, Testing net (#0)
I0526 03:47:12.405216 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.78
I0526 03:47:12.405262 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.86257 (* 1 = 0.86257 loss)
I0526 03:47:13.007298 15117 solver.cpp:233] Iteration 19000, loss = 0.17261
I0526 03:47:13.007349 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.17261 (* 1 = 0.17261 loss)
I0526 03:47:13.007359 15117 sgd_solver.cpp:294] Iteration 19000, lr = 0.02
I0526 03:47:19.347174 15117 solver.cpp:233] Iteration 19010, loss = 0.209343
I0526 03:47:19.347311 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.209343 (* 1 = 0.209343 loss)
I0526 03:47:19.347318 15117 sgd_solver.cpp:294] Iteration 19010, lr = 0.02
I0526 03:47:25.688562 15117 solver.cpp:233] Iteration 19020, loss = 0.237074
I0526 03:47:25.688611 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.237074 (* 1 = 0.237074 loss)
I0526 03:47:25.688617 15117 sgd_solver.cpp:294] Iteration 19020, lr = 0.02
I0526 03:47:32.033365 15117 solver.cpp:233] Iteration 19030, loss = 0.108254
I0526 03:47:32.033416 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.108254 (* 1 = 0.108254 loss)
I0526 03:47:32.033422 15117 sgd_solver.cpp:294] Iteration 19030, lr = 0.02
I0526 03:47:38.375250 15117 solver.cpp:233] Iteration 19040, loss = 0.107232
I0526 03:47:38.375290 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.107232 (* 1 = 0.107232 loss)
I0526 03:47:38.375298 15117 sgd_solver.cpp:294] Iteration 19040, lr = 0.02
I0526 03:47:44.713325 15117 solver.cpp:233] Iteration 19050, loss = 0.197099
I0526 03:47:44.713378 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.197099 (* 1 = 0.197099 loss)
I0526 03:47:44.713385 15117 sgd_solver.cpp:294] Iteration 19050, lr = 0.02
I0526 03:47:51.054915 15117 solver.cpp:233] Iteration 19060, loss = 0.202766
I0526 03:47:51.055133 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.202766 (* 1 = 0.202766 loss)
I0526 03:47:51.055161 15117 sgd_solver.cpp:294] Iteration 19060, lr = 0.02
I0526 03:47:57.391713 15117 solver.cpp:233] Iteration 19070, loss = 0.178563
I0526 03:47:57.391767 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.178563 (* 1 = 0.178563 loss)
I0526 03:47:57.391777 15117 sgd_solver.cpp:294] Iteration 19070, lr = 0.02
I0526 03:48:03.728641 15117 solver.cpp:233] Iteration 19080, loss = 0.068862
I0526 03:48:03.728677 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.068862 (* 1 = 0.068862 loss)
I0526 03:48:03.728711 15117 sgd_solver.cpp:294] Iteration 19080, lr = 0.02
I0526 03:48:10.070641 15117 solver.cpp:233] Iteration 19090, loss = 0.0510885
I0526 03:48:10.070685 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0510886 (* 1 = 0.0510886 loss)
I0526 03:48:10.070693 15117 sgd_solver.cpp:294] Iteration 19090, lr = 0.02
I0526 03:48:15.812062 15117 solver.cpp:342] Iteration 19100, Testing net (#0)
I0526 03:48:28.667533 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7985
I0526 03:48:28.667812 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.838926 (* 1 = 0.838926 loss)
I0526 03:48:29.266022 15117 solver.cpp:233] Iteration 19100, loss = 0.196537
I0526 03:48:29.266064 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.196537 (* 1 = 0.196537 loss)
I0526 03:48:29.266073 15117 sgd_solver.cpp:294] Iteration 19100, lr = 0.02
I0526 03:48:35.603227 15117 solver.cpp:233] Iteration 19110, loss = 0.117796
I0526 03:48:35.603267 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.117796 (* 1 = 0.117796 loss)
I0526 03:48:35.603274 15117 sgd_solver.cpp:294] Iteration 19110, lr = 0.02
I0526 03:48:41.945161 15117 solver.cpp:233] Iteration 19120, loss = 0.109692
I0526 03:48:41.945207 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.109692 (* 1 = 0.109692 loss)
I0526 03:48:41.945215 15117 sgd_solver.cpp:294] Iteration 19120, lr = 0.02
I0526 03:48:48.284745 15117 solver.cpp:233] Iteration 19130, loss = 0.118096
I0526 03:48:48.284782 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.118096 (* 1 = 0.118096 loss)
I0526 03:48:48.284790 15117 sgd_solver.cpp:294] Iteration 19130, lr = 0.02
I0526 03:48:54.610800 15117 solver.cpp:233] Iteration 19140, loss = 0.188513
I0526 03:48:54.610839 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.188513 (* 1 = 0.188513 loss)
I0526 03:48:54.610847 15117 sgd_solver.cpp:294] Iteration 19140, lr = 0.02
I0526 03:49:00.928333 15117 solver.cpp:233] Iteration 19150, loss = 0.209378
I0526 03:49:00.928549 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.209378 (* 1 = 0.209378 loss)
I0526 03:49:00.928587 15117 sgd_solver.cpp:294] Iteration 19150, lr = 0.02
I0526 03:49:07.244731 15117 solver.cpp:233] Iteration 19160, loss = 0.0835348
I0526 03:49:07.244776 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0835349 (* 1 = 0.0835349 loss)
I0526 03:49:07.244782 15117 sgd_solver.cpp:294] Iteration 19160, lr = 0.02
I0526 03:49:13.559448 15117 solver.cpp:233] Iteration 19170, loss = 0.138558
I0526 03:49:13.559489 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.138558 (* 1 = 0.138558 loss)
I0526 03:49:13.559496 15117 sgd_solver.cpp:294] Iteration 19170, lr = 0.02
I0526 03:49:19.876762 15117 solver.cpp:233] Iteration 19180, loss = 0.210375
I0526 03:49:19.876804 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.210375 (* 1 = 0.210375 loss)
I0526 03:49:19.876811 15117 sgd_solver.cpp:294] Iteration 19180, lr = 0.02
I0526 03:49:26.194036 15117 solver.cpp:233] Iteration 19190, loss = 0.138904
I0526 03:49:26.194077 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.138904 (* 1 = 0.138904 loss)
I0526 03:49:26.194083 15117 sgd_solver.cpp:294] Iteration 19190, lr = 0.02
I0526 03:49:31.910290 15117 solver.cpp:342] Iteration 19200, Testing net (#0)
I0526 03:49:44.726791 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8423
I0526 03:49:44.726840 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.554521 (* 1 = 0.554521 loss)
I0526 03:49:45.325207 15117 solver.cpp:233] Iteration 19200, loss = 0.144914
I0526 03:49:45.325240 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.144914 (* 1 = 0.144914 loss)
I0526 03:49:45.325248 15117 sgd_solver.cpp:294] Iteration 19200, lr = 0.02
I0526 03:49:51.642590 15117 solver.cpp:233] Iteration 19210, loss = 0.169653
I0526 03:49:51.642626 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.169653 (* 1 = 0.169653 loss)
I0526 03:49:51.642632 15117 sgd_solver.cpp:294] Iteration 19210, lr = 0.02
I0526 03:49:57.958454 15117 solver.cpp:233] Iteration 19220, loss = 0.136533
I0526 03:49:57.958493 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.136533 (* 1 = 0.136533 loss)
I0526 03:49:57.958499 15117 sgd_solver.cpp:294] Iteration 19220, lr = 0.02
I0526 03:50:04.277392 15117 solver.cpp:233] Iteration 19230, loss = 0.129184
I0526 03:50:04.277545 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.129184 (* 1 = 0.129184 loss)
I0526 03:50:04.277554 15117 sgd_solver.cpp:294] Iteration 19230, lr = 0.02
I0526 03:50:10.569391 15117 solver.cpp:233] Iteration 19240, loss = 0.0498341
I0526 03:50:10.569428 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0498341 (* 1 = 0.0498341 loss)
I0526 03:50:10.569435 15117 sgd_solver.cpp:294] Iteration 19240, lr = 0.02
I0526 03:50:16.858953 15117 solver.cpp:233] Iteration 19250, loss = 0.134659
I0526 03:50:16.858992 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.134659 (* 1 = 0.134659 loss)
I0526 03:50:16.858999 15117 sgd_solver.cpp:294] Iteration 19250, lr = 0.02
I0526 03:50:23.150382 15117 solver.cpp:233] Iteration 19260, loss = 0.15654
I0526 03:50:23.150420 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.15654 (* 1 = 0.15654 loss)
I0526 03:50:23.150426 15117 sgd_solver.cpp:294] Iteration 19260, lr = 0.02
I0526 03:50:29.452617 15117 solver.cpp:233] Iteration 19270, loss = 0.200016
I0526 03:50:29.452659 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.200016 (* 1 = 0.200016 loss)
I0526 03:50:29.452666 15117 sgd_solver.cpp:294] Iteration 19270, lr = 0.02
I0526 03:50:35.766870 15117 solver.cpp:233] Iteration 19280, loss = 0.0984975
I0526 03:50:35.767076 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0984976 (* 1 = 0.0984976 loss)
I0526 03:50:35.767107 15117 sgd_solver.cpp:294] Iteration 19280, lr = 0.02
I0526 03:50:42.088441 15117 solver.cpp:233] Iteration 19290, loss = 0.177318
I0526 03:50:42.088485 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.177318 (* 1 = 0.177318 loss)
I0526 03:50:42.088491 15117 sgd_solver.cpp:294] Iteration 19290, lr = 0.02
I0526 03:50:47.828047 15117 solver.cpp:342] Iteration 19300, Testing net (#0)
I0526 03:51:00.669625 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8273
I0526 03:51:00.669668 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.645569 (* 1 = 0.645569 loss)
I0526 03:51:01.271776 15117 solver.cpp:233] Iteration 19300, loss = 0.247471
I0526 03:51:01.271812 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.247471 (* 1 = 0.247471 loss)
I0526 03:51:01.271819 15117 sgd_solver.cpp:294] Iteration 19300, lr = 0.02
I0526 03:51:07.610395 15117 solver.cpp:233] Iteration 19310, loss = 0.217331
I0526 03:51:07.610623 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.217331 (* 1 = 0.217331 loss)
I0526 03:51:07.610651 15117 sgd_solver.cpp:294] Iteration 19310, lr = 0.02
I0526 03:51:13.945873 15117 solver.cpp:233] Iteration 19320, loss = 0.252269
I0526 03:51:13.945919 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.252269 (* 1 = 0.252269 loss)
I0526 03:51:13.945929 15117 sgd_solver.cpp:294] Iteration 19320, lr = 0.02
I0526 03:51:20.280437 15117 solver.cpp:233] Iteration 19330, loss = 0.224478
I0526 03:51:20.280480 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.224478 (* 1 = 0.224478 loss)
I0526 03:51:20.280488 15117 sgd_solver.cpp:294] Iteration 19330, lr = 0.02
I0526 03:51:26.611723 15117 solver.cpp:233] Iteration 19340, loss = 0.144504
I0526 03:51:26.611765 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.144504 (* 1 = 0.144504 loss)
I0526 03:51:26.611773 15117 sgd_solver.cpp:294] Iteration 19340, lr = 0.02
I0526 03:51:32.945556 15117 solver.cpp:233] Iteration 19350, loss = 0.199735
I0526 03:51:32.945597 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.199735 (* 1 = 0.199735 loss)
I0526 03:51:32.945605 15117 sgd_solver.cpp:294] Iteration 19350, lr = 0.02
I0526 03:51:39.285748 15117 solver.cpp:233] Iteration 19360, loss = 0.141496
I0526 03:51:39.286037 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.141496 (* 1 = 0.141496 loss)
I0526 03:51:39.286067 15117 sgd_solver.cpp:294] Iteration 19360, lr = 0.02
I0526 03:51:45.626261 15117 solver.cpp:233] Iteration 19370, loss = 0.109468
I0526 03:51:45.626312 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.109468 (* 1 = 0.109468 loss)
I0526 03:51:45.626320 15117 sgd_solver.cpp:294] Iteration 19370, lr = 0.02
I0526 03:51:51.967346 15117 solver.cpp:233] Iteration 19380, loss = 0.219024
I0526 03:51:51.967387 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.219024 (* 1 = 0.219024 loss)
I0526 03:51:51.967394 15117 sgd_solver.cpp:294] Iteration 19380, lr = 0.02
I0526 03:51:58.306525 15117 solver.cpp:233] Iteration 19390, loss = 0.139054
I0526 03:51:58.306567 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.139054 (* 1 = 0.139054 loss)
I0526 03:51:58.306573 15117 sgd_solver.cpp:294] Iteration 19390, lr = 0.02
I0526 03:52:04.042567 15117 solver.cpp:342] Iteration 19400, Testing net (#0)
I0526 03:52:16.885045 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7777
I0526 03:52:16.885272 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.862458 (* 1 = 0.862458 loss)
I0526 03:52:17.486996 15117 solver.cpp:233] Iteration 19400, loss = 0.166998
I0526 03:52:17.487030 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.166998 (* 1 = 0.166998 loss)
I0526 03:52:17.487036 15117 sgd_solver.cpp:294] Iteration 19400, lr = 0.02
I0526 03:52:23.824142 15117 solver.cpp:233] Iteration 19410, loss = 0.108285
I0526 03:52:23.824180 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.108285 (* 1 = 0.108285 loss)
I0526 03:52:23.824187 15117 sgd_solver.cpp:294] Iteration 19410, lr = 0.02
I0526 03:52:30.162878 15117 solver.cpp:233] Iteration 19420, loss = 0.219078
I0526 03:52:30.162919 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.219078 (* 1 = 0.219078 loss)
I0526 03:52:30.162925 15117 sgd_solver.cpp:294] Iteration 19420, lr = 0.02
I0526 03:52:36.498899 15117 solver.cpp:233] Iteration 19430, loss = 0.19528
I0526 03:52:36.498947 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.19528 (* 1 = 0.19528 loss)
I0526 03:52:36.498955 15117 sgd_solver.cpp:294] Iteration 19430, lr = 0.02
I0526 03:52:42.833998 15117 solver.cpp:233] Iteration 19440, loss = 0.107064
I0526 03:52:42.834038 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.107064 (* 1 = 0.107064 loss)
I0526 03:52:42.834045 15117 sgd_solver.cpp:294] Iteration 19440, lr = 0.02
I0526 03:52:49.170114 15117 solver.cpp:233] Iteration 19450, loss = 0.116896
I0526 03:52:49.170344 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.116896 (* 1 = 0.116896 loss)
I0526 03:52:49.170408 15117 sgd_solver.cpp:294] Iteration 19450, lr = 0.02
I0526 03:52:55.505980 15117 solver.cpp:233] Iteration 19460, loss = 0.294795
I0526 03:52:55.506016 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.294795 (* 1 = 0.294795 loss)
I0526 03:52:55.506022 15117 sgd_solver.cpp:294] Iteration 19460, lr = 0.02
I0526 03:53:01.841424 15117 solver.cpp:233] Iteration 19470, loss = 0.0584442
I0526 03:53:01.841466 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0584442 (* 1 = 0.0584442 loss)
I0526 03:53:01.841472 15117 sgd_solver.cpp:294] Iteration 19470, lr = 0.02
I0526 03:53:08.180440 15117 solver.cpp:233] Iteration 19480, loss = 0.107144
I0526 03:53:08.180481 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.107144 (* 1 = 0.107144 loss)
I0526 03:53:08.180487 15117 sgd_solver.cpp:294] Iteration 19480, lr = 0.02
I0526 03:53:14.519212 15117 solver.cpp:233] Iteration 19490, loss = 0.169683
I0526 03:53:14.519253 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.169683 (* 1 = 0.169683 loss)
I0526 03:53:14.519261 15117 sgd_solver.cpp:294] Iteration 19490, lr = 0.02
I0526 03:53:20.256731 15117 solver.cpp:342] Iteration 19500, Testing net (#0)
I0526 03:53:33.102766 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8454
I0526 03:53:33.102809 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.551159 (* 1 = 0.551159 loss)
I0526 03:53:33.704346 15117 solver.cpp:233] Iteration 19500, loss = 0.0999543
I0526 03:53:33.704392 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0999543 (* 1 = 0.0999543 loss)
I0526 03:53:33.704401 15117 sgd_solver.cpp:294] Iteration 19500, lr = 0.02
I0526 03:53:40.039326 15117 solver.cpp:233] Iteration 19510, loss = 0.065954
I0526 03:53:40.039366 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.065954 (* 1 = 0.065954 loss)
I0526 03:53:40.039372 15117 sgd_solver.cpp:294] Iteration 19510, lr = 0.02
I0526 03:53:46.371558 15117 solver.cpp:233] Iteration 19520, loss = 0.127398
I0526 03:53:46.371599 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.127398 (* 1 = 0.127398 loss)
I0526 03:53:46.371606 15117 sgd_solver.cpp:294] Iteration 19520, lr = 0.02
I0526 03:53:52.707372 15117 solver.cpp:233] Iteration 19530, loss = 0.0834444
I0526 03:53:52.707602 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0834444 (* 1 = 0.0834444 loss)
I0526 03:53:52.707631 15117 sgd_solver.cpp:294] Iteration 19530, lr = 0.02
I0526 03:53:59.047472 15117 solver.cpp:233] Iteration 19540, loss = 0.126981
I0526 03:53:59.047516 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.126981 (* 1 = 0.126981 loss)
I0526 03:53:59.047523 15117 sgd_solver.cpp:294] Iteration 19540, lr = 0.02
I0526 03:54:05.385607 15117 solver.cpp:233] Iteration 19550, loss = 0.0839221
I0526 03:54:05.385645 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0839221 (* 1 = 0.0839221 loss)
I0526 03:54:05.385653 15117 sgd_solver.cpp:294] Iteration 19550, lr = 0.02
I0526 03:54:11.721159 15117 solver.cpp:233] Iteration 19560, loss = 0.152834
I0526 03:54:11.721199 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.152834 (* 1 = 0.152834 loss)
I0526 03:54:11.721206 15117 sgd_solver.cpp:294] Iteration 19560, lr = 0.02
I0526 03:54:18.063896 15117 solver.cpp:233] Iteration 19570, loss = 0.224667
I0526 03:54:18.063930 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.224667 (* 1 = 0.224667 loss)
I0526 03:54:18.063937 15117 sgd_solver.cpp:294] Iteration 19570, lr = 0.02
I0526 03:54:24.406024 15117 solver.cpp:233] Iteration 19580, loss = 0.128209
I0526 03:54:24.406249 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.128209 (* 1 = 0.128209 loss)
I0526 03:54:24.406286 15117 sgd_solver.cpp:294] Iteration 19580, lr = 0.02
I0526 03:54:30.742487 15117 solver.cpp:233] Iteration 19590, loss = 0.181601
I0526 03:54:30.742532 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.181601 (* 1 = 0.181601 loss)
I0526 03:54:30.742539 15117 sgd_solver.cpp:294] Iteration 19590, lr = 0.02
I0526 03:54:36.479967 15117 solver.cpp:342] Iteration 19600, Testing net (#0)
I0526 03:54:49.328800 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8291
I0526 03:54:49.328858 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.609247 (* 1 = 0.609247 loss)
I0526 03:54:49.930744 15117 solver.cpp:233] Iteration 19600, loss = 0.108916
I0526 03:54:49.930779 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.108916 (* 1 = 0.108916 loss)
I0526 03:54:49.930788 15117 sgd_solver.cpp:294] Iteration 19600, lr = 0.02
I0526 03:54:56.269740 15117 solver.cpp:233] Iteration 19610, loss = 0.209154
I0526 03:54:56.269964 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.209154 (* 1 = 0.209154 loss)
I0526 03:54:56.270000 15117 sgd_solver.cpp:294] Iteration 19610, lr = 0.02
I0526 03:55:02.609238 15117 solver.cpp:233] Iteration 19620, loss = 0.0670025
I0526 03:55:02.609277 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0670025 (* 1 = 0.0670025 loss)
I0526 03:55:02.609285 15117 sgd_solver.cpp:294] Iteration 19620, lr = 0.02
I0526 03:55:08.948885 15117 solver.cpp:233] Iteration 19630, loss = 0.173747
I0526 03:55:08.948925 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.173747 (* 1 = 0.173747 loss)
I0526 03:55:08.948933 15117 sgd_solver.cpp:294] Iteration 19630, lr = 0.02
I0526 03:55:15.289938 15117 solver.cpp:233] Iteration 19640, loss = 0.134398
I0526 03:55:15.289981 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.134398 (* 1 = 0.134398 loss)
I0526 03:55:15.289988 15117 sgd_solver.cpp:294] Iteration 19640, lr = 0.02
I0526 03:55:21.631970 15117 solver.cpp:233] Iteration 19650, loss = 0.182652
I0526 03:55:21.632010 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.182652 (* 1 = 0.182652 loss)
I0526 03:55:21.632019 15117 sgd_solver.cpp:294] Iteration 19650, lr = 0.02
I0526 03:55:27.969991 15117 solver.cpp:233] Iteration 19660, loss = 0.173784
I0526 03:55:27.970279 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.173784 (* 1 = 0.173784 loss)
I0526 03:55:27.970309 15117 sgd_solver.cpp:294] Iteration 19660, lr = 0.02
I0526 03:55:34.309545 15117 solver.cpp:233] Iteration 19670, loss = 0.0968475
I0526 03:55:34.309587 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0968475 (* 1 = 0.0968475 loss)
I0526 03:55:34.309593 15117 sgd_solver.cpp:294] Iteration 19670, lr = 0.02
I0526 03:55:40.650204 15117 solver.cpp:233] Iteration 19680, loss = 0.166507
I0526 03:55:40.650244 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.166507 (* 1 = 0.166507 loss)
I0526 03:55:40.650250 15117 sgd_solver.cpp:294] Iteration 19680, lr = 0.02
I0526 03:55:46.993410 15117 solver.cpp:233] Iteration 19690, loss = 0.14319
I0526 03:55:46.993448 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.14319 (* 1 = 0.14319 loss)
I0526 03:55:46.993455 15117 sgd_solver.cpp:294] Iteration 19690, lr = 0.02
I0526 03:55:52.733518 15117 solver.cpp:342] Iteration 19700, Testing net (#0)
I0526 03:56:05.574856 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.835
I0526 03:56:05.575085 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.553836 (* 1 = 0.553836 loss)
I0526 03:56:06.174337 15117 solver.cpp:233] Iteration 19700, loss = 0.152178
I0526 03:56:06.174383 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.152178 (* 1 = 0.152178 loss)
I0526 03:56:06.174392 15117 sgd_solver.cpp:294] Iteration 19700, lr = 0.02
I0526 03:56:12.515125 15117 solver.cpp:233] Iteration 19710, loss = 0.145692
I0526 03:56:12.515166 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.145692 (* 1 = 0.145692 loss)
I0526 03:56:12.515172 15117 sgd_solver.cpp:294] Iteration 19710, lr = 0.02
I0526 03:56:18.851647 15117 solver.cpp:233] Iteration 19720, loss = 0.146101
I0526 03:56:18.851703 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.146101 (* 1 = 0.146101 loss)
I0526 03:56:18.851711 15117 sgd_solver.cpp:294] Iteration 19720, lr = 0.02
I0526 03:56:25.194413 15117 solver.cpp:233] Iteration 19730, loss = 0.187533
I0526 03:56:25.194456 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.187533 (* 1 = 0.187533 loss)
I0526 03:56:25.194463 15117 sgd_solver.cpp:294] Iteration 19730, lr = 0.02
I0526 03:56:31.536563 15117 solver.cpp:233] Iteration 19740, loss = 0.159295
I0526 03:56:31.536614 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.159295 (* 1 = 0.159295 loss)
I0526 03:56:31.536623 15117 sgd_solver.cpp:294] Iteration 19740, lr = 0.02
I0526 03:56:37.876849 15117 solver.cpp:233] Iteration 19750, loss = 0.0958057
I0526 03:56:37.877076 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0958057 (* 1 = 0.0958057 loss)
I0526 03:56:37.877105 15117 sgd_solver.cpp:294] Iteration 19750, lr = 0.02
I0526 03:56:44.220526 15117 solver.cpp:233] Iteration 19760, loss = 0.13352
I0526 03:56:44.220577 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.13352 (* 1 = 0.13352 loss)
I0526 03:56:44.220585 15117 sgd_solver.cpp:294] Iteration 19760, lr = 0.02
I0526 03:56:50.559458 15117 solver.cpp:233] Iteration 19770, loss = 0.100786
I0526 03:56:50.559504 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.100786 (* 1 = 0.100786 loss)
I0526 03:56:50.559510 15117 sgd_solver.cpp:294] Iteration 19770, lr = 0.02
I0526 03:56:56.899469 15117 solver.cpp:233] Iteration 19780, loss = 0.104297
I0526 03:56:56.899518 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.104297 (* 1 = 0.104297 loss)
I0526 03:56:56.899524 15117 sgd_solver.cpp:294] Iteration 19780, lr = 0.02
I0526 03:57:03.236501 15117 solver.cpp:233] Iteration 19790, loss = 0.127767
I0526 03:57:03.236541 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.127767 (* 1 = 0.127767 loss)
I0526 03:57:03.236547 15117 sgd_solver.cpp:294] Iteration 19790, lr = 0.02
I0526 03:57:08.971329 15117 solver.cpp:342] Iteration 19800, Testing net (#0)
I0526 03:57:21.825492 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.6954
I0526 03:57:21.825562 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.52567 (* 1 = 1.52567 loss)
I0526 03:57:22.427755 15117 solver.cpp:233] Iteration 19800, loss = 0.103695
I0526 03:57:22.427780 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.103695 (* 1 = 0.103695 loss)
I0526 03:57:22.427788 15117 sgd_solver.cpp:294] Iteration 19800, lr = 0.02
I0526 03:57:28.766917 15117 solver.cpp:233] Iteration 19810, loss = 0.121345
I0526 03:57:28.766953 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.121345 (* 1 = 0.121345 loss)
I0526 03:57:28.766960 15117 sgd_solver.cpp:294] Iteration 19810, lr = 0.02
I0526 03:57:35.106070 15117 solver.cpp:233] Iteration 19820, loss = 0.0809898
I0526 03:57:35.106113 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0809899 (* 1 = 0.0809899 loss)
I0526 03:57:35.106122 15117 sgd_solver.cpp:294] Iteration 19820, lr = 0.02
I0526 03:57:41.446970 15117 solver.cpp:233] Iteration 19830, loss = 0.147987
I0526 03:57:41.447177 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.147987 (* 1 = 0.147987 loss)
I0526 03:57:41.447207 15117 sgd_solver.cpp:294] Iteration 19830, lr = 0.02
I0526 03:57:47.788512 15117 solver.cpp:233] Iteration 19840, loss = 0.177839
I0526 03:57:47.788553 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.177839 (* 1 = 0.177839 loss)
I0526 03:57:47.788561 15117 sgd_solver.cpp:294] Iteration 19840, lr = 0.02
I0526 03:57:54.128099 15117 solver.cpp:233] Iteration 19850, loss = 0.195094
I0526 03:57:54.128144 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.195095 (* 1 = 0.195095 loss)
I0526 03:57:54.128151 15117 sgd_solver.cpp:294] Iteration 19850, lr = 0.02
I0526 03:58:00.468053 15117 solver.cpp:233] Iteration 19860, loss = 0.109745
I0526 03:58:00.468104 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.109745 (* 1 = 0.109745 loss)
I0526 03:58:00.468111 15117 sgd_solver.cpp:294] Iteration 19860, lr = 0.02
I0526 03:58:06.809797 15117 solver.cpp:233] Iteration 19870, loss = 0.122338
I0526 03:58:06.809839 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.122338 (* 1 = 0.122338 loss)
I0526 03:58:06.809845 15117 sgd_solver.cpp:294] Iteration 19870, lr = 0.02
I0526 03:58:13.149431 15117 solver.cpp:233] Iteration 19880, loss = 0.122645
I0526 03:58:13.149652 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.122645 (* 1 = 0.122645 loss)
I0526 03:58:13.149678 15117 sgd_solver.cpp:294] Iteration 19880, lr = 0.02
I0526 03:58:19.489127 15117 solver.cpp:233] Iteration 19890, loss = 0.176823
I0526 03:58:19.489169 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.176823 (* 1 = 0.176823 loss)
I0526 03:58:19.489178 15117 sgd_solver.cpp:294] Iteration 19890, lr = 0.02
I0526 03:58:25.225975 15117 solver.cpp:342] Iteration 19900, Testing net (#0)
I0526 03:58:38.073798 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8436
I0526 03:58:38.073845 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.566856 (* 1 = 0.566856 loss)
I0526 03:58:38.676352 15117 solver.cpp:233] Iteration 19900, loss = 0.117786
I0526 03:58:38.676389 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.117786 (* 1 = 0.117786 loss)
I0526 03:58:38.676396 15117 sgd_solver.cpp:294] Iteration 19900, lr = 0.02
I0526 03:58:44.997148 15117 solver.cpp:233] Iteration 19910, loss = 0.162308
I0526 03:58:44.997391 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.162308 (* 1 = 0.162308 loss)
I0526 03:58:44.997421 15117 sgd_solver.cpp:294] Iteration 19910, lr = 0.02
I0526 03:58:51.310415 15117 solver.cpp:233] Iteration 19920, loss = 0.114412
I0526 03:58:51.310456 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.114412 (* 1 = 0.114412 loss)
I0526 03:58:51.310463 15117 sgd_solver.cpp:294] Iteration 19920, lr = 0.02
I0526 03:58:57.628015 15117 solver.cpp:233] Iteration 19930, loss = 0.102916
I0526 03:58:57.628051 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.102916 (* 1 = 0.102916 loss)
I0526 03:58:57.628058 15117 sgd_solver.cpp:294] Iteration 19930, lr = 0.02
I0526 03:59:03.942641 15117 solver.cpp:233] Iteration 19940, loss = 0.126397
I0526 03:59:03.942680 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.126397 (* 1 = 0.126397 loss)
I0526 03:59:03.942687 15117 sgd_solver.cpp:294] Iteration 19940, lr = 0.02
I0526 03:59:10.255792 15117 solver.cpp:233] Iteration 19950, loss = 0.173482
I0526 03:59:10.255836 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.173482 (* 1 = 0.173482 loss)
I0526 03:59:10.255844 15117 sgd_solver.cpp:294] Iteration 19950, lr = 0.02
I0526 03:59:16.569360 15117 solver.cpp:233] Iteration 19960, loss = 0.143481
I0526 03:59:16.569567 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.143481 (* 1 = 0.143481 loss)
I0526 03:59:16.569597 15117 sgd_solver.cpp:294] Iteration 19960, lr = 0.02
I0526 03:59:22.885025 15117 solver.cpp:233] Iteration 19970, loss = 0.0664177
I0526 03:59:22.885068 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0664177 (* 1 = 0.0664177 loss)
I0526 03:59:22.885076 15117 sgd_solver.cpp:294] Iteration 19970, lr = 0.02
I0526 03:59:29.200577 15117 solver.cpp:233] Iteration 19980, loss = 0.115299
I0526 03:59:29.200616 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.115299 (* 1 = 0.115299 loss)
I0526 03:59:29.200623 15117 sgd_solver.cpp:294] Iteration 19980, lr = 0.02
I0526 03:59:35.519744 15117 solver.cpp:233] Iteration 19990, loss = 0.233305
I0526 03:59:35.519789 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.233305 (* 1 = 0.233305 loss)
I0526 03:59:35.519796 15117 sgd_solver.cpp:294] Iteration 19990, lr = 0.02
I0526 03:59:41.233616 15117 solver.cpp:342] Iteration 20000, Testing net (#0)
I0526 03:59:54.058809 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8316
I0526 03:59:54.059020 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.638419 (* 1 = 0.638419 loss)
I0526 03:59:54.659150 15117 solver.cpp:233] Iteration 20000, loss = 0.164062
I0526 03:59:54.659183 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.164062 (* 1 = 0.164062 loss)
I0526 03:59:54.659193 15117 sgd_solver.cpp:294] Iteration 20000, lr = 0.02
I0526 04:00:00.994876 15117 solver.cpp:233] Iteration 20010, loss = 0.152457
I0526 04:00:00.994920 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.152457 (* 1 = 0.152457 loss)
I0526 04:00:00.994926 15117 sgd_solver.cpp:294] Iteration 20010, lr = 0.02
I0526 04:00:07.337131 15117 solver.cpp:233] Iteration 20020, loss = 0.14
I0526 04:00:07.337177 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.14 (* 1 = 0.14 loss)
I0526 04:00:07.337183 15117 sgd_solver.cpp:294] Iteration 20020, lr = 0.02
I0526 04:00:13.663060 15117 solver.cpp:233] Iteration 20030, loss = 0.0985298
I0526 04:00:13.663086 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0985298 (* 1 = 0.0985298 loss)
I0526 04:00:13.663094 15117 sgd_solver.cpp:294] Iteration 20030, lr = 0.02
I0526 04:00:19.980123 15117 solver.cpp:233] Iteration 20040, loss = 0.199326
I0526 04:00:19.980166 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.199326 (* 1 = 0.199326 loss)
I0526 04:00:19.980175 15117 sgd_solver.cpp:294] Iteration 20040, lr = 0.02
I0526 04:00:26.297780 15117 solver.cpp:233] Iteration 20050, loss = 0.221322
I0526 04:00:26.298040 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.221322 (* 1 = 0.221322 loss)
I0526 04:00:26.298069 15117 sgd_solver.cpp:294] Iteration 20050, lr = 0.02
I0526 04:00:32.612823 15117 solver.cpp:233] Iteration 20060, loss = 0.129502
I0526 04:00:32.612877 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.129502 (* 1 = 0.129502 loss)
I0526 04:00:32.612884 15117 sgd_solver.cpp:294] Iteration 20060, lr = 0.02
I0526 04:00:38.928144 15117 solver.cpp:233] Iteration 20070, loss = 0.16408
I0526 04:00:38.928186 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.16408 (* 1 = 0.16408 loss)
I0526 04:00:38.928194 15117 sgd_solver.cpp:294] Iteration 20070, lr = 0.02
I0526 04:00:45.241535 15117 solver.cpp:233] Iteration 20080, loss = 0.159513
I0526 04:00:45.241577 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.159513 (* 1 = 0.159513 loss)
I0526 04:00:45.241585 15117 sgd_solver.cpp:294] Iteration 20080, lr = 0.02
I0526 04:00:51.556125 15117 solver.cpp:233] Iteration 20090, loss = 0.210446
I0526 04:00:51.556181 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.210446 (* 1 = 0.210446 loss)
I0526 04:00:51.556188 15117 sgd_solver.cpp:294] Iteration 20090, lr = 0.02
I0526 04:00:57.281177 15117 solver.cpp:342] Iteration 20100, Testing net (#0)
I0526 04:01:10.129851 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8169
I0526 04:01:10.129909 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.731669 (* 1 = 0.731669 loss)
I0526 04:01:10.732033 15117 solver.cpp:233] Iteration 20100, loss = 0.148283
I0526 04:01:10.732069 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.148283 (* 1 = 0.148283 loss)
I0526 04:01:10.732076 15117 sgd_solver.cpp:294] Iteration 20100, lr = 0.02
I0526 04:01:17.067318 15117 solver.cpp:233] Iteration 20110, loss = 0.0821465
I0526 04:01:17.067351 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0821465 (* 1 = 0.0821465 loss)
I0526 04:01:17.067358 15117 sgd_solver.cpp:294] Iteration 20110, lr = 0.02
I0526 04:01:23.405130 15117 solver.cpp:233] Iteration 20120, loss = 0.203657
I0526 04:01:23.405171 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.203657 (* 1 = 0.203657 loss)
I0526 04:01:23.405179 15117 sgd_solver.cpp:294] Iteration 20120, lr = 0.02
I0526 04:01:29.743443 15117 solver.cpp:233] Iteration 20130, loss = 0.164505
I0526 04:01:29.743667 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.164505 (* 1 = 0.164505 loss)
I0526 04:01:29.743696 15117 sgd_solver.cpp:294] Iteration 20130, lr = 0.02
I0526 04:01:36.078446 15117 solver.cpp:233] Iteration 20140, loss = 0.106709
I0526 04:01:36.078502 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.106709 (* 1 = 0.106709 loss)
I0526 04:01:36.078510 15117 sgd_solver.cpp:294] Iteration 20140, lr = 0.02
I0526 04:01:42.418648 15117 solver.cpp:233] Iteration 20150, loss = 0.130184
I0526 04:01:42.418699 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.130184 (* 1 = 0.130184 loss)
I0526 04:01:42.418705 15117 sgd_solver.cpp:294] Iteration 20150, lr = 0.02
I0526 04:01:48.758285 15117 solver.cpp:233] Iteration 20160, loss = 0.109336
I0526 04:01:48.758327 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.109336 (* 1 = 0.109336 loss)
I0526 04:01:48.758344 15117 sgd_solver.cpp:294] Iteration 20160, lr = 0.02
I0526 04:01:55.098927 15117 solver.cpp:233] Iteration 20170, loss = 0.172265
I0526 04:01:55.098970 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.172265 (* 1 = 0.172265 loss)
I0526 04:01:55.098978 15117 sgd_solver.cpp:294] Iteration 20170, lr = 0.02
I0526 04:02:01.437868 15117 solver.cpp:233] Iteration 20180, loss = 0.242828
I0526 04:02:01.437975 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.242828 (* 1 = 0.242828 loss)
I0526 04:02:01.437984 15117 sgd_solver.cpp:294] Iteration 20180, lr = 0.02
I0526 04:02:07.775115 15117 solver.cpp:233] Iteration 20190, loss = 0.194151
I0526 04:02:07.775156 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.194151 (* 1 = 0.194151 loss)
I0526 04:02:07.775163 15117 sgd_solver.cpp:294] Iteration 20190, lr = 0.02
I0526 04:02:13.510329 15117 solver.cpp:342] Iteration 20200, Testing net (#0)
I0526 04:02:26.361078 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7616
I0526 04:02:26.361120 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.19397 (* 1 = 1.19397 loss)
I0526 04:02:26.963310 15117 solver.cpp:233] Iteration 20200, loss = 0.108731
I0526 04:02:26.963346 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.108731 (* 1 = 0.108731 loss)
I0526 04:02:26.963353 15117 sgd_solver.cpp:294] Iteration 20200, lr = 0.02
I0526 04:02:33.303428 15117 solver.cpp:233] Iteration 20210, loss = 0.177092
I0526 04:02:33.303668 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.177092 (* 1 = 0.177092 loss)
I0526 04:02:33.303697 15117 sgd_solver.cpp:294] Iteration 20210, lr = 0.02
I0526 04:02:39.646167 15117 solver.cpp:233] Iteration 20220, loss = 0.239809
I0526 04:02:39.646211 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.239809 (* 1 = 0.239809 loss)
I0526 04:02:39.646219 15117 sgd_solver.cpp:294] Iteration 20220, lr = 0.02
I0526 04:02:45.985272 15117 solver.cpp:233] Iteration 20230, loss = 0.091336
I0526 04:02:45.985323 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0913361 (* 1 = 0.0913361 loss)
I0526 04:02:45.985332 15117 sgd_solver.cpp:294] Iteration 20230, lr = 0.02
I0526 04:02:52.323189 15117 solver.cpp:233] Iteration 20240, loss = 0.113802
I0526 04:02:52.323231 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.113802 (* 1 = 0.113802 loss)
I0526 04:02:52.323240 15117 sgd_solver.cpp:294] Iteration 20240, lr = 0.02
I0526 04:02:58.661839 15117 solver.cpp:233] Iteration 20250, loss = 0.102086
I0526 04:02:58.661878 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.102086 (* 1 = 0.102086 loss)
I0526 04:02:58.661886 15117 sgd_solver.cpp:294] Iteration 20250, lr = 0.02
I0526 04:03:04.995728 15117 solver.cpp:233] Iteration 20260, loss = 0.109836
I0526 04:03:04.995947 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.109836 (* 1 = 0.109836 loss)
I0526 04:03:04.995977 15117 sgd_solver.cpp:294] Iteration 20260, lr = 0.02
I0526 04:03:11.329316 15117 solver.cpp:233] Iteration 20270, loss = 0.104624
I0526 04:03:11.329375 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.104624 (* 1 = 0.104624 loss)
I0526 04:03:11.329382 15117 sgd_solver.cpp:294] Iteration 20270, lr = 0.02
I0526 04:03:17.667853 15117 solver.cpp:233] Iteration 20280, loss = 0.130574
I0526 04:03:17.667896 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.130575 (* 1 = 0.130575 loss)
I0526 04:03:17.667904 15117 sgd_solver.cpp:294] Iteration 20280, lr = 0.02
I0526 04:03:24.005059 15117 solver.cpp:233] Iteration 20290, loss = 0.105236
I0526 04:03:24.005102 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.105236 (* 1 = 0.105236 loss)
I0526 04:03:24.005110 15117 sgd_solver.cpp:294] Iteration 20290, lr = 0.02
I0526 04:03:29.740753 15117 solver.cpp:342] Iteration 20300, Testing net (#0)
I0526 04:03:42.586432 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8261
I0526 04:03:42.586668 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.633864 (* 1 = 0.633864 loss)
I0526 04:03:43.186967 15117 solver.cpp:233] Iteration 20300, loss = 0.0952973
I0526 04:03:43.187018 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0952973 (* 1 = 0.0952973 loss)
I0526 04:03:43.187027 15117 sgd_solver.cpp:294] Iteration 20300, lr = 0.02
I0526 04:03:49.523742 15117 solver.cpp:233] Iteration 20310, loss = 0.157481
I0526 04:03:49.523787 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.157481 (* 1 = 0.157481 loss)
I0526 04:03:49.523795 15117 sgd_solver.cpp:294] Iteration 20310, lr = 0.02
I0526 04:03:55.863641 15117 solver.cpp:233] Iteration 20320, loss = 0.125326
I0526 04:03:55.863695 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.125326 (* 1 = 0.125326 loss)
I0526 04:03:55.863703 15117 sgd_solver.cpp:294] Iteration 20320, lr = 0.02
I0526 04:04:02.202836 15117 solver.cpp:233] Iteration 20330, loss = 0.10539
I0526 04:04:02.202888 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.10539 (* 1 = 0.10539 loss)
I0526 04:04:02.202894 15117 sgd_solver.cpp:294] Iteration 20330, lr = 0.02
I0526 04:04:08.540603 15117 solver.cpp:233] Iteration 20340, loss = 0.133612
I0526 04:04:08.540643 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.133612 (* 1 = 0.133612 loss)
I0526 04:04:08.540650 15117 sgd_solver.cpp:294] Iteration 20340, lr = 0.02
I0526 04:04:14.875015 15117 solver.cpp:233] Iteration 20350, loss = 0.0930931
I0526 04:04:14.875277 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0930932 (* 1 = 0.0930932 loss)
I0526 04:04:14.875305 15117 sgd_solver.cpp:294] Iteration 20350, lr = 0.02
I0526 04:04:21.213762 15117 solver.cpp:233] Iteration 20360, loss = 0.124704
I0526 04:04:21.213810 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.124705 (* 1 = 0.124705 loss)
I0526 04:04:21.213819 15117 sgd_solver.cpp:294] Iteration 20360, lr = 0.02
I0526 04:04:27.550436 15117 solver.cpp:233] Iteration 20370, loss = 0.162611
I0526 04:04:27.550477 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.162611 (* 1 = 0.162611 loss)
I0526 04:04:27.550483 15117 sgd_solver.cpp:294] Iteration 20370, lr = 0.02
I0526 04:04:33.889564 15117 solver.cpp:233] Iteration 20380, loss = 0.13549
I0526 04:04:33.889608 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.13549 (* 1 = 0.13549 loss)
I0526 04:04:33.889616 15117 sgd_solver.cpp:294] Iteration 20380, lr = 0.02
I0526 04:04:40.224875 15117 solver.cpp:233] Iteration 20390, loss = 0.12958
I0526 04:04:40.224912 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.12958 (* 1 = 0.12958 loss)
I0526 04:04:40.224920 15117 sgd_solver.cpp:294] Iteration 20390, lr = 0.02
I0526 04:04:45.964854 15117 solver.cpp:342] Iteration 20400, Testing net (#0)
I0526 04:04:58.823616 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7709
I0526 04:04:58.823657 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.874768 (* 1 = 0.874768 loss)
I0526 04:04:59.426142 15117 solver.cpp:233] Iteration 20400, loss = 0.087822
I0526 04:04:59.426177 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.087822 (* 1 = 0.087822 loss)
I0526 04:04:59.426183 15117 sgd_solver.cpp:294] Iteration 20400, lr = 0.02
I0526 04:05:05.765127 15117 solver.cpp:233] Iteration 20410, loss = 0.0922347
I0526 04:05:05.765168 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0922347 (* 1 = 0.0922347 loss)
I0526 04:05:05.765174 15117 sgd_solver.cpp:294] Iteration 20410, lr = 0.02
I0526 04:05:12.102936 15117 solver.cpp:233] Iteration 20420, loss = 0.179
I0526 04:05:12.102974 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.179 (* 1 = 0.179 loss)
I0526 04:05:12.102980 15117 sgd_solver.cpp:294] Iteration 20420, lr = 0.02
I0526 04:05:18.439622 15117 solver.cpp:233] Iteration 20430, loss = 0.110347
I0526 04:05:18.439846 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.110347 (* 1 = 0.110347 loss)
I0526 04:05:18.439882 15117 sgd_solver.cpp:294] Iteration 20430, lr = 0.02
I0526 04:05:24.773800 15117 solver.cpp:233] Iteration 20440, loss = 0.152312
I0526 04:05:24.773850 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.152312 (* 1 = 0.152312 loss)
I0526 04:05:24.773859 15117 sgd_solver.cpp:294] Iteration 20440, lr = 0.02
I0526 04:05:31.111418 15117 solver.cpp:233] Iteration 20450, loss = 0.193373
I0526 04:05:31.111466 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.193373 (* 1 = 0.193373 loss)
I0526 04:05:31.111475 15117 sgd_solver.cpp:294] Iteration 20450, lr = 0.02
I0526 04:05:37.444207 15117 solver.cpp:233] Iteration 20460, loss = 0.144984
I0526 04:05:37.444247 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.144984 (* 1 = 0.144984 loss)
I0526 04:05:37.444254 15117 sgd_solver.cpp:294] Iteration 20460, lr = 0.02
I0526 04:05:43.783926 15117 solver.cpp:233] Iteration 20470, loss = 0.132125
I0526 04:05:43.783970 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.132125 (* 1 = 0.132125 loss)
I0526 04:05:43.783977 15117 sgd_solver.cpp:294] Iteration 20470, lr = 0.02
I0526 04:05:50.116591 15117 solver.cpp:233] Iteration 20480, loss = 0.212403
I0526 04:05:50.116873 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.212403 (* 1 = 0.212403 loss)
I0526 04:05:50.116902 15117 sgd_solver.cpp:294] Iteration 20480, lr = 0.02
I0526 04:05:56.454742 15117 solver.cpp:233] Iteration 20490, loss = 0.173872
I0526 04:05:56.454783 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.173873 (* 1 = 0.173873 loss)
I0526 04:05:56.454790 15117 sgd_solver.cpp:294] Iteration 20490, lr = 0.02
I0526 04:06:02.195488 15117 solver.cpp:342] Iteration 20500, Testing net (#0)
I0526 04:06:15.051100 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.811
I0526 04:06:15.051144 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.782523 (* 1 = 0.782523 loss)
I0526 04:06:15.653688 15117 solver.cpp:233] Iteration 20500, loss = 0.0959762
I0526 04:06:15.653735 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0959762 (* 1 = 0.0959762 loss)
I0526 04:06:15.653744 15117 sgd_solver.cpp:294] Iteration 20500, lr = 0.02
I0526 04:06:21.993170 15117 solver.cpp:233] Iteration 20510, loss = 0.127711
I0526 04:06:21.993391 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.127711 (* 1 = 0.127711 loss)
I0526 04:06:21.993419 15117 sgd_solver.cpp:294] Iteration 20510, lr = 0.02
I0526 04:06:28.332475 15117 solver.cpp:233] Iteration 20520, loss = 0.149188
I0526 04:06:28.332520 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.149188 (* 1 = 0.149188 loss)
I0526 04:06:28.332526 15117 sgd_solver.cpp:294] Iteration 20520, lr = 0.02
I0526 04:06:34.670764 15117 solver.cpp:233] Iteration 20530, loss = 0.177314
I0526 04:06:34.670805 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.177314 (* 1 = 0.177314 loss)
I0526 04:06:34.670814 15117 sgd_solver.cpp:294] Iteration 20530, lr = 0.02
I0526 04:06:41.011682 15117 solver.cpp:233] Iteration 20540, loss = 0.0534056
I0526 04:06:41.011719 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0534056 (* 1 = 0.0534056 loss)
I0526 04:06:41.011726 15117 sgd_solver.cpp:294] Iteration 20540, lr = 0.02
I0526 04:06:47.346575 15117 solver.cpp:233] Iteration 20550, loss = 0.0942683
I0526 04:06:47.346622 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0942684 (* 1 = 0.0942684 loss)
I0526 04:06:47.346629 15117 sgd_solver.cpp:294] Iteration 20550, lr = 0.02
I0526 04:06:53.686347 15117 solver.cpp:233] Iteration 20560, loss = 0.0601192
I0526 04:06:53.686583 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0601192 (* 1 = 0.0601192 loss)
I0526 04:06:53.686611 15117 sgd_solver.cpp:294] Iteration 20560, lr = 0.02
I0526 04:07:00.027923 15117 solver.cpp:233] Iteration 20570, loss = 0.202144
I0526 04:07:00.027969 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.202144 (* 1 = 0.202144 loss)
I0526 04:07:00.027976 15117 sgd_solver.cpp:294] Iteration 20570, lr = 0.02
I0526 04:07:06.367746 15117 solver.cpp:233] Iteration 20580, loss = 0.0983243
I0526 04:07:06.367789 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0983244 (* 1 = 0.0983244 loss)
I0526 04:07:06.367796 15117 sgd_solver.cpp:294] Iteration 20580, lr = 0.02
I0526 04:07:12.704197 15117 solver.cpp:233] Iteration 20590, loss = 0.172152
I0526 04:07:12.704259 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.172152 (* 1 = 0.172152 loss)
I0526 04:07:12.704272 15117 sgd_solver.cpp:294] Iteration 20590, lr = 0.02
I0526 04:07:18.440429 15117 solver.cpp:342] Iteration 20600, Testing net (#0)
I0526 04:07:31.294005 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8044
I0526 04:07:31.294297 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.783898 (* 1 = 0.783898 loss)
I0526 04:07:31.893831 15117 solver.cpp:233] Iteration 20600, loss = 0.149843
I0526 04:07:31.893872 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.149843 (* 1 = 0.149843 loss)
I0526 04:07:31.893882 15117 sgd_solver.cpp:294] Iteration 20600, lr = 0.02
I0526 04:07:38.230952 15117 solver.cpp:233] Iteration 20610, loss = 0.16495
I0526 04:07:38.230979 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.16495 (* 1 = 0.16495 loss)
I0526 04:07:38.230986 15117 sgd_solver.cpp:294] Iteration 20610, lr = 0.02
I0526 04:07:44.569700 15117 solver.cpp:233] Iteration 20620, loss = 0.158139
I0526 04:07:44.569738 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.158139 (* 1 = 0.158139 loss)
I0526 04:07:44.569746 15117 sgd_solver.cpp:294] Iteration 20620, lr = 0.02
I0526 04:07:50.905565 15117 solver.cpp:233] Iteration 20630, loss = 0.0574814
I0526 04:07:50.905602 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0574814 (* 1 = 0.0574814 loss)
I0526 04:07:50.905609 15117 sgd_solver.cpp:294] Iteration 20630, lr = 0.02
I0526 04:07:57.241597 15117 solver.cpp:233] Iteration 20640, loss = 0.122305
I0526 04:07:57.241636 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.122305 (* 1 = 0.122305 loss)
I0526 04:07:57.241643 15117 sgd_solver.cpp:294] Iteration 20640, lr = 0.02
I0526 04:08:03.570843 15117 solver.cpp:233] Iteration 20650, loss = 0.0963493
I0526 04:08:03.571079 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0963494 (* 1 = 0.0963494 loss)
I0526 04:08:03.571110 15117 sgd_solver.cpp:294] Iteration 20650, lr = 0.02
I0526 04:08:09.904753 15117 solver.cpp:233] Iteration 20660, loss = 0.101837
I0526 04:08:09.904795 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.101837 (* 1 = 0.101837 loss)
I0526 04:08:09.904814 15117 sgd_solver.cpp:294] Iteration 20660, lr = 0.02
I0526 04:08:16.240391 15117 solver.cpp:233] Iteration 20670, loss = 0.120139
I0526 04:08:16.240432 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.120139 (* 1 = 0.120139 loss)
I0526 04:08:16.240440 15117 sgd_solver.cpp:294] Iteration 20670, lr = 0.02
I0526 04:08:22.574059 15117 solver.cpp:233] Iteration 20680, loss = 0.189996
I0526 04:08:22.574095 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.189996 (* 1 = 0.189996 loss)
I0526 04:08:22.574102 15117 sgd_solver.cpp:294] Iteration 20680, lr = 0.02
I0526 04:08:28.907068 15117 solver.cpp:233] Iteration 20690, loss = 0.146734
I0526 04:08:28.907114 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.146734 (* 1 = 0.146734 loss)
I0526 04:08:28.907122 15117 sgd_solver.cpp:294] Iteration 20690, lr = 0.02
I0526 04:08:34.642359 15117 solver.cpp:342] Iteration 20700, Testing net (#0)
I0526 04:08:47.480795 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8025
I0526 04:08:47.480841 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.826667 (* 1 = 0.826667 loss)
I0526 04:08:48.082828 15117 solver.cpp:233] Iteration 20700, loss = 0.106288
I0526 04:08:48.082883 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.106288 (* 1 = 0.106288 loss)
I0526 04:08:48.082891 15117 sgd_solver.cpp:294] Iteration 20700, lr = 0.02
I0526 04:08:54.419564 15117 solver.cpp:233] Iteration 20710, loss = 0.135774
I0526 04:08:54.419601 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.135774 (* 1 = 0.135774 loss)
I0526 04:08:54.419607 15117 sgd_solver.cpp:294] Iteration 20710, lr = 0.02
I0526 04:09:00.755507 15117 solver.cpp:233] Iteration 20720, loss = 0.157119
I0526 04:09:00.755548 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.157119 (* 1 = 0.157119 loss)
I0526 04:09:00.755561 15117 sgd_solver.cpp:294] Iteration 20720, lr = 0.02
I0526 04:09:07.091960 15117 solver.cpp:233] Iteration 20730, loss = 0.106799
I0526 04:09:07.092205 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.106799 (* 1 = 0.106799 loss)
I0526 04:09:07.092238 15117 sgd_solver.cpp:294] Iteration 20730, lr = 0.02
I0526 04:09:13.428817 15117 solver.cpp:233] Iteration 20740, loss = 0.111773
I0526 04:09:13.428860 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.111773 (* 1 = 0.111773 loss)
I0526 04:09:13.428867 15117 sgd_solver.cpp:294] Iteration 20740, lr = 0.02
I0526 04:09:19.767365 15117 solver.cpp:233] Iteration 20750, loss = 0.156214
I0526 04:09:19.767403 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.156214 (* 1 = 0.156214 loss)
I0526 04:09:19.767410 15117 sgd_solver.cpp:294] Iteration 20750, lr = 0.02
I0526 04:09:26.103505 15117 solver.cpp:233] Iteration 20760, loss = 0.0527447
I0526 04:09:26.103544 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0527447 (* 1 = 0.0527447 loss)
I0526 04:09:26.103551 15117 sgd_solver.cpp:294] Iteration 20760, lr = 0.02
I0526 04:09:32.438539 15117 solver.cpp:233] Iteration 20770, loss = 0.16717
I0526 04:09:32.438581 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.16717 (* 1 = 0.16717 loss)
I0526 04:09:32.438588 15117 sgd_solver.cpp:294] Iteration 20770, lr = 0.02
I0526 04:09:38.771303 15117 solver.cpp:233] Iteration 20780, loss = 0.179719
I0526 04:09:38.771543 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.179719 (* 1 = 0.179719 loss)
I0526 04:09:38.771571 15117 sgd_solver.cpp:294] Iteration 20780, lr = 0.02
I0526 04:09:45.100059 15117 solver.cpp:233] Iteration 20790, loss = 0.134059
I0526 04:09:45.100097 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.134059 (* 1 = 0.134059 loss)
I0526 04:09:45.100105 15117 sgd_solver.cpp:294] Iteration 20790, lr = 0.02
I0526 04:09:50.834744 15117 solver.cpp:342] Iteration 20800, Testing net (#0)
I0526 04:10:03.672291 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8078
I0526 04:10:03.672343 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.722452 (* 1 = 0.722452 loss)
I0526 04:10:04.274634 15117 solver.cpp:233] Iteration 20800, loss = 0.095915
I0526 04:10:04.274657 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.095915 (* 1 = 0.095915 loss)
I0526 04:10:04.274663 15117 sgd_solver.cpp:294] Iteration 20800, lr = 0.02
I0526 04:10:10.609318 15117 solver.cpp:233] Iteration 20810, loss = 0.199616
I0526 04:10:10.609552 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.199616 (* 1 = 0.199616 loss)
I0526 04:10:10.609580 15117 sgd_solver.cpp:294] Iteration 20810, lr = 0.02
I0526 04:10:16.943547 15117 solver.cpp:233] Iteration 20820, loss = 0.131924
I0526 04:10:16.943590 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.131924 (* 1 = 0.131924 loss)
I0526 04:10:16.943598 15117 sgd_solver.cpp:294] Iteration 20820, lr = 0.02
I0526 04:10:23.272732 15117 solver.cpp:233] Iteration 20830, loss = 0.0862316
I0526 04:10:23.272774 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0862317 (* 1 = 0.0862317 loss)
I0526 04:10:23.272781 15117 sgd_solver.cpp:294] Iteration 20830, lr = 0.02
I0526 04:10:29.602187 15117 solver.cpp:233] Iteration 20840, loss = 0.0978145
I0526 04:10:29.602231 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0978146 (* 1 = 0.0978146 loss)
I0526 04:10:29.602239 15117 sgd_solver.cpp:294] Iteration 20840, lr = 0.02
I0526 04:10:35.935854 15117 solver.cpp:233] Iteration 20850, loss = 0.110627
I0526 04:10:35.935897 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.110627 (* 1 = 0.110627 loss)
I0526 04:10:35.935905 15117 sgd_solver.cpp:294] Iteration 20850, lr = 0.02
I0526 04:10:42.268811 15117 solver.cpp:233] Iteration 20860, loss = 0.105269
I0526 04:10:42.269069 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.105269 (* 1 = 0.105269 loss)
I0526 04:10:42.269116 15117 sgd_solver.cpp:294] Iteration 20860, lr = 0.02
I0526 04:10:48.603591 15117 solver.cpp:233] Iteration 20870, loss = 0.0727768
I0526 04:10:48.603632 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0727768 (* 1 = 0.0727768 loss)
I0526 04:10:48.603641 15117 sgd_solver.cpp:294] Iteration 20870, lr = 0.02
I0526 04:10:54.934885 15117 solver.cpp:233] Iteration 20880, loss = 0.194303
I0526 04:10:54.934933 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.194303 (* 1 = 0.194303 loss)
I0526 04:10:54.934940 15117 sgd_solver.cpp:294] Iteration 20880, lr = 0.02
I0526 04:11:01.268702 15117 solver.cpp:233] Iteration 20890, loss = 0.0592671
I0526 04:11:01.268745 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0592672 (* 1 = 0.0592672 loss)
I0526 04:11:01.268753 15117 sgd_solver.cpp:294] Iteration 20890, lr = 0.02
I0526 04:11:07.000284 15117 solver.cpp:342] Iteration 20900, Testing net (#0)
I0526 04:11:19.833183 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.831
I0526 04:11:19.833320 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.669529 (* 1 = 0.669529 loss)
I0526 04:11:20.435446 15117 solver.cpp:233] Iteration 20900, loss = 0.21677
I0526 04:11:20.435477 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.21677 (* 1 = 0.21677 loss)
I0526 04:11:20.435484 15117 sgd_solver.cpp:294] Iteration 20900, lr = 0.02
I0526 04:11:26.772574 15117 solver.cpp:233] Iteration 20910, loss = 0.110303
I0526 04:11:26.772613 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.110303 (* 1 = 0.110303 loss)
I0526 04:11:26.772629 15117 sgd_solver.cpp:294] Iteration 20910, lr = 0.02
I0526 04:11:33.103785 15117 solver.cpp:233] Iteration 20920, loss = 0.128577
I0526 04:11:33.103824 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.128577 (* 1 = 0.128577 loss)
I0526 04:11:33.103832 15117 sgd_solver.cpp:294] Iteration 20920, lr = 0.02
I0526 04:11:39.437676 15117 solver.cpp:233] Iteration 20930, loss = 0.0903855
I0526 04:11:39.437716 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0903856 (* 1 = 0.0903856 loss)
I0526 04:11:39.437722 15117 sgd_solver.cpp:294] Iteration 20930, lr = 0.02
I0526 04:11:45.773327 15117 solver.cpp:233] Iteration 20940, loss = 0.173292
I0526 04:11:45.773368 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.173292 (* 1 = 0.173292 loss)
I0526 04:11:45.773375 15117 sgd_solver.cpp:294] Iteration 20940, lr = 0.02
I0526 04:11:52.112491 15117 solver.cpp:233] Iteration 20950, loss = 0.104426
I0526 04:11:52.112563 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.104426 (* 1 = 0.104426 loss)
I0526 04:11:52.112571 15117 sgd_solver.cpp:294] Iteration 20950, lr = 0.02
I0526 04:11:58.452200 15117 solver.cpp:233] Iteration 20960, loss = 0.131923
I0526 04:11:58.452247 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.131923 (* 1 = 0.131923 loss)
I0526 04:11:58.452255 15117 sgd_solver.cpp:294] Iteration 20960, lr = 0.02
I0526 04:12:04.786984 15117 solver.cpp:233] Iteration 20970, loss = 0.102775
I0526 04:12:04.787025 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.102775 (* 1 = 0.102775 loss)
I0526 04:12:04.787032 15117 sgd_solver.cpp:294] Iteration 20970, lr = 0.02
I0526 04:12:11.125392 15117 solver.cpp:233] Iteration 20980, loss = 0.123985
I0526 04:12:11.125434 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.123985 (* 1 = 0.123985 loss)
I0526 04:12:11.125442 15117 sgd_solver.cpp:294] Iteration 20980, lr = 0.02
I0526 04:12:17.460958 15117 solver.cpp:233] Iteration 20990, loss = 0.193979
I0526 04:12:17.461019 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.193979 (* 1 = 0.193979 loss)
I0526 04:12:17.461029 15117 sgd_solver.cpp:294] Iteration 20990, lr = 0.02
I0526 04:12:23.197168 15117 solver.cpp:342] Iteration 21000, Testing net (#0)
I0526 04:12:36.033217 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8025
I0526 04:12:36.033263 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.816257 (* 1 = 0.816257 loss)
I0526 04:12:36.635715 15117 solver.cpp:233] Iteration 21000, loss = 0.171161
I0526 04:12:36.635751 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.171161 (* 1 = 0.171161 loss)
I0526 04:12:36.635758 15117 sgd_solver.cpp:294] Iteration 21000, lr = 0.02
I0526 04:12:42.969296 15117 solver.cpp:233] Iteration 21010, loss = 0.153852
I0526 04:12:42.969347 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.153852 (* 1 = 0.153852 loss)
I0526 04:12:42.969353 15117 sgd_solver.cpp:294] Iteration 21010, lr = 0.02
I0526 04:12:49.302913 15117 solver.cpp:233] Iteration 21020, loss = 0.209058
I0526 04:12:49.302968 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.209058 (* 1 = 0.209058 loss)
I0526 04:12:49.302975 15117 sgd_solver.cpp:294] Iteration 21020, lr = 0.02
I0526 04:12:55.635105 15117 solver.cpp:233] Iteration 21030, loss = 0.163265
I0526 04:12:55.635342 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.163265 (* 1 = 0.163265 loss)
I0526 04:12:55.635370 15117 sgd_solver.cpp:294] Iteration 21030, lr = 0.02
I0526 04:13:01.968787 15117 solver.cpp:233] Iteration 21040, loss = 0.143718
I0526 04:13:01.968834 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.143718 (* 1 = 0.143718 loss)
I0526 04:13:01.968842 15117 sgd_solver.cpp:294] Iteration 21040, lr = 0.02
I0526 04:13:08.304611 15117 solver.cpp:233] Iteration 21050, loss = 0.0802409
I0526 04:13:08.304653 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.080241 (* 1 = 0.080241 loss)
I0526 04:13:08.304661 15117 sgd_solver.cpp:294] Iteration 21050, lr = 0.02
I0526 04:13:14.643065 15117 solver.cpp:233] Iteration 21060, loss = 0.14452
I0526 04:13:14.643131 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.14452 (* 1 = 0.14452 loss)
I0526 04:13:14.643139 15117 sgd_solver.cpp:294] Iteration 21060, lr = 0.02
I0526 04:13:20.980831 15117 solver.cpp:233] Iteration 21070, loss = 0.162991
I0526 04:13:20.980866 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.162991 (* 1 = 0.162991 loss)
I0526 04:13:20.980875 15117 sgd_solver.cpp:294] Iteration 21070, lr = 0.02
I0526 04:13:27.315745 15117 solver.cpp:233] Iteration 21080, loss = 0.101075
I0526 04:13:27.315959 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.101075 (* 1 = 0.101075 loss)
I0526 04:13:27.315985 15117 sgd_solver.cpp:294] Iteration 21080, lr = 0.02
I0526 04:13:33.650219 15117 solver.cpp:233] Iteration 21090, loss = 0.206337
I0526 04:13:33.650264 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.206337 (* 1 = 0.206337 loss)
I0526 04:13:33.650271 15117 sgd_solver.cpp:294] Iteration 21090, lr = 0.02
I0526 04:13:39.381042 15117 solver.cpp:342] Iteration 21100, Testing net (#0)
I0526 04:13:52.225653 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8296
I0526 04:13:52.225703 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.663195 (* 1 = 0.663195 loss)
I0526 04:13:52.826807 15117 solver.cpp:233] Iteration 21100, loss = 0.0833066
I0526 04:13:52.826830 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0833066 (* 1 = 0.0833066 loss)
I0526 04:13:52.826838 15117 sgd_solver.cpp:294] Iteration 21100, lr = 0.02
I0526 04:13:59.163363 15117 solver.cpp:233] Iteration 21110, loss = 0.202838
I0526 04:13:59.163590 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.202838 (* 1 = 0.202838 loss)
I0526 04:13:59.163619 15117 sgd_solver.cpp:294] Iteration 21110, lr = 0.02
I0526 04:14:05.500519 15117 solver.cpp:233] Iteration 21120, loss = 0.182133
I0526 04:14:05.500558 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.182133 (* 1 = 0.182133 loss)
I0526 04:14:05.500566 15117 sgd_solver.cpp:294] Iteration 21120, lr = 0.02
I0526 04:14:11.839025 15117 solver.cpp:233] Iteration 21130, loss = 0.109516
I0526 04:14:11.839064 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.109516 (* 1 = 0.109516 loss)
I0526 04:14:11.839077 15117 sgd_solver.cpp:294] Iteration 21130, lr = 0.02
I0526 04:14:18.173398 15117 solver.cpp:233] Iteration 21140, loss = 0.0827907
I0526 04:14:18.173435 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0827908 (* 1 = 0.0827908 loss)
I0526 04:14:18.173442 15117 sgd_solver.cpp:294] Iteration 21140, lr = 0.02
I0526 04:14:24.506853 15117 solver.cpp:233] Iteration 21150, loss = 0.0800162
I0526 04:14:24.506892 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0800163 (* 1 = 0.0800163 loss)
I0526 04:14:24.506899 15117 sgd_solver.cpp:294] Iteration 21150, lr = 0.02
I0526 04:14:30.845649 15117 solver.cpp:233] Iteration 21160, loss = 0.131801
I0526 04:14:30.845927 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.131801 (* 1 = 0.131801 loss)
I0526 04:14:30.845957 15117 sgd_solver.cpp:294] Iteration 21160, lr = 0.02
I0526 04:14:37.180445 15117 solver.cpp:233] Iteration 21170, loss = 0.246584
I0526 04:14:37.180483 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.246584 (* 1 = 0.246584 loss)
I0526 04:14:37.180490 15117 sgd_solver.cpp:294] Iteration 21170, lr = 0.02
I0526 04:14:43.519043 15117 solver.cpp:233] Iteration 21180, loss = 0.112697
I0526 04:14:43.519088 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.112697 (* 1 = 0.112697 loss)
I0526 04:14:43.519095 15117 sgd_solver.cpp:294] Iteration 21180, lr = 0.02
I0526 04:14:49.854315 15117 solver.cpp:233] Iteration 21190, loss = 0.126113
I0526 04:14:49.854380 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.126113 (* 1 = 0.126113 loss)
I0526 04:14:49.854398 15117 sgd_solver.cpp:294] Iteration 21190, lr = 0.02
I0526 04:14:55.589119 15117 solver.cpp:342] Iteration 21200, Testing net (#0)
I0526 04:15:08.424554 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7689
I0526 04:15:08.424775 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.946225 (* 1 = 0.946225 loss)
I0526 04:15:09.024229 15117 solver.cpp:233] Iteration 21200, loss = 0.144125
I0526 04:15:09.024274 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.144125 (* 1 = 0.144125 loss)
I0526 04:15:09.024291 15117 sgd_solver.cpp:294] Iteration 21200, lr = 0.02
I0526 04:15:15.349303 15117 solver.cpp:233] Iteration 21210, loss = 0.207494
I0526 04:15:15.349346 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.207494 (* 1 = 0.207494 loss)
I0526 04:15:15.349354 15117 sgd_solver.cpp:294] Iteration 21210, lr = 0.02
I0526 04:15:21.681845 15117 solver.cpp:233] Iteration 21220, loss = 0.109375
I0526 04:15:21.681886 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.109375 (* 1 = 0.109375 loss)
I0526 04:15:21.681893 15117 sgd_solver.cpp:294] Iteration 21220, lr = 0.02
I0526 04:15:28.014701 15117 solver.cpp:233] Iteration 21230, loss = 0.106165
I0526 04:15:28.014742 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.106165 (* 1 = 0.106165 loss)
I0526 04:15:28.014750 15117 sgd_solver.cpp:294] Iteration 21230, lr = 0.02
I0526 04:15:34.350747 15117 solver.cpp:233] Iteration 21240, loss = 0.155101
I0526 04:15:34.350792 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.155101 (* 1 = 0.155101 loss)
I0526 04:15:34.350800 15117 sgd_solver.cpp:294] Iteration 21240, lr = 0.02
I0526 04:15:40.681689 15117 solver.cpp:233] Iteration 21250, loss = 0.0971994
I0526 04:15:40.681841 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0971995 (* 1 = 0.0971995 loss)
I0526 04:15:40.681851 15117 sgd_solver.cpp:294] Iteration 21250, lr = 0.02
I0526 04:15:47.018071 15117 solver.cpp:233] Iteration 21260, loss = 0.0952823
I0526 04:15:47.018110 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0952824 (* 1 = 0.0952824 loss)
I0526 04:15:47.018117 15117 sgd_solver.cpp:294] Iteration 21260, lr = 0.02
I0526 04:15:53.352939 15117 solver.cpp:233] Iteration 21270, loss = 0.112506
I0526 04:15:53.352978 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.112506 (* 1 = 0.112506 loss)
I0526 04:15:53.352993 15117 sgd_solver.cpp:294] Iteration 21270, lr = 0.02
I0526 04:15:59.688928 15117 solver.cpp:233] Iteration 21280, loss = 0.113471
I0526 04:15:59.688968 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.113471 (* 1 = 0.113471 loss)
I0526 04:15:59.688977 15117 sgd_solver.cpp:294] Iteration 21280, lr = 0.02
I0526 04:16:06.025121 15117 solver.cpp:233] Iteration 21290, loss = 0.163661
I0526 04:16:06.025161 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.163661 (* 1 = 0.163661 loss)
I0526 04:16:06.025166 15117 sgd_solver.cpp:294] Iteration 21290, lr = 0.02
I0526 04:16:11.761870 15117 solver.cpp:342] Iteration 21300, Testing net (#0)
I0526 04:16:24.609252 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8306
I0526 04:16:24.609300 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.642257 (* 1 = 0.642257 loss)
I0526 04:16:25.211338 15117 solver.cpp:233] Iteration 21300, loss = 0.125896
I0526 04:16:25.211359 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.125896 (* 1 = 0.125896 loss)
I0526 04:16:25.211366 15117 sgd_solver.cpp:294] Iteration 21300, lr = 0.02
I0526 04:16:31.549504 15117 solver.cpp:233] Iteration 21310, loss = 0.116354
I0526 04:16:31.549546 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.116354 (* 1 = 0.116354 loss)
I0526 04:16:31.549554 15117 sgd_solver.cpp:294] Iteration 21310, lr = 0.02
I0526 04:16:37.886286 15117 solver.cpp:233] Iteration 21320, loss = 0.130662
I0526 04:16:37.886324 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.130662 (* 1 = 0.130662 loss)
I0526 04:16:37.886332 15117 sgd_solver.cpp:294] Iteration 21320, lr = 0.02
I0526 04:16:44.224941 15117 solver.cpp:233] Iteration 21330, loss = 0.139914
I0526 04:16:44.225155 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.139914 (* 1 = 0.139914 loss)
I0526 04:16:44.225184 15117 sgd_solver.cpp:294] Iteration 21330, lr = 0.02
I0526 04:16:50.563155 15117 solver.cpp:233] Iteration 21340, loss = 0.103721
I0526 04:16:50.563205 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.103721 (* 1 = 0.103721 loss)
I0526 04:16:50.563213 15117 sgd_solver.cpp:294] Iteration 21340, lr = 0.02
I0526 04:16:56.901648 15117 solver.cpp:233] Iteration 21350, loss = 0.12819
I0526 04:16:56.901690 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.12819 (* 1 = 0.12819 loss)
I0526 04:16:56.901696 15117 sgd_solver.cpp:294] Iteration 21350, lr = 0.02
I0526 04:17:03.240589 15117 solver.cpp:233] Iteration 21360, loss = 0.183528
I0526 04:17:03.240631 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.183528 (* 1 = 0.183528 loss)
I0526 04:17:03.240638 15117 sgd_solver.cpp:294] Iteration 21360, lr = 0.02
I0526 04:17:09.579881 15117 solver.cpp:233] Iteration 21370, loss = 0.106758
I0526 04:17:09.579919 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.106758 (* 1 = 0.106758 loss)
I0526 04:17:09.579926 15117 sgd_solver.cpp:294] Iteration 21370, lr = 0.02
I0526 04:17:15.917018 15117 solver.cpp:233] Iteration 21380, loss = 0.155311
I0526 04:17:15.917261 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.155311 (* 1 = 0.155311 loss)
I0526 04:17:15.917290 15117 sgd_solver.cpp:294] Iteration 21380, lr = 0.02
I0526 04:17:22.255826 15117 solver.cpp:233] Iteration 21390, loss = 0.106578
I0526 04:17:22.255878 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.106578 (* 1 = 0.106578 loss)
I0526 04:17:22.255887 15117 sgd_solver.cpp:294] Iteration 21390, lr = 0.02
I0526 04:17:27.971318 15117 solver.cpp:342] Iteration 21400, Testing net (#0)
I0526 04:17:40.803467 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8191
I0526 04:17:40.803514 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.730825 (* 1 = 0.730825 loss)
I0526 04:17:41.404721 15117 solver.cpp:233] Iteration 21400, loss = 0.0895176
I0526 04:17:41.404758 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0895176 (* 1 = 0.0895176 loss)
I0526 04:17:41.404781 15117 sgd_solver.cpp:294] Iteration 21400, lr = 0.02
I0526 04:17:47.740691 15117 solver.cpp:233] Iteration 21410, loss = 0.126939
I0526 04:17:47.740874 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.126939 (* 1 = 0.126939 loss)
I0526 04:17:47.740882 15117 sgd_solver.cpp:294] Iteration 21410, lr = 0.02
I0526 04:17:54.077482 15117 solver.cpp:233] Iteration 21420, loss = 0.171029
I0526 04:17:54.077536 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.171029 (* 1 = 0.171029 loss)
I0526 04:17:54.077543 15117 sgd_solver.cpp:294] Iteration 21420, lr = 0.02
I0526 04:18:00.412462 15117 solver.cpp:233] Iteration 21430, loss = 0.111663
I0526 04:18:00.412503 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.111663 (* 1 = 0.111663 loss)
I0526 04:18:00.412510 15117 sgd_solver.cpp:294] Iteration 21430, lr = 0.02
I0526 04:18:06.745386 15117 solver.cpp:233] Iteration 21440, loss = 0.185829
I0526 04:18:06.745434 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.185829 (* 1 = 0.185829 loss)
I0526 04:18:06.745440 15117 sgd_solver.cpp:294] Iteration 21440, lr = 0.02
I0526 04:18:13.077914 15117 solver.cpp:233] Iteration 21450, loss = 0.266761
I0526 04:18:13.077976 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.266761 (* 1 = 0.266761 loss)
I0526 04:18:13.077983 15117 sgd_solver.cpp:294] Iteration 21450, lr = 0.02
I0526 04:18:19.415277 15117 solver.cpp:233] Iteration 21460, loss = 0.115443
I0526 04:18:19.415518 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.115443 (* 1 = 0.115443 loss)
I0526 04:18:19.415547 15117 sgd_solver.cpp:294] Iteration 21460, lr = 0.02
I0526 04:18:25.752382 15117 solver.cpp:233] Iteration 21470, loss = 0.109915
I0526 04:18:25.752423 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.109915 (* 1 = 0.109915 loss)
I0526 04:18:25.752429 15117 sgd_solver.cpp:294] Iteration 21470, lr = 0.02
I0526 04:18:32.088817 15117 solver.cpp:233] Iteration 21480, loss = 0.150619
I0526 04:18:32.088860 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.150619 (* 1 = 0.150619 loss)
I0526 04:18:32.088866 15117 sgd_solver.cpp:294] Iteration 21480, lr = 0.02
I0526 04:18:38.422750 15117 solver.cpp:233] Iteration 21490, loss = 0.0868773
I0526 04:18:38.422790 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0868774 (* 1 = 0.0868774 loss)
I0526 04:18:38.422796 15117 sgd_solver.cpp:294] Iteration 21490, lr = 0.02
I0526 04:18:44.156483 15117 solver.cpp:342] Iteration 21500, Testing net (#0)
I0526 04:18:56.994444 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8189
I0526 04:18:56.994679 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.717435 (* 1 = 0.717435 loss)
I0526 04:18:57.594535 15117 solver.cpp:233] Iteration 21500, loss = 0.158622
I0526 04:18:57.594568 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.158622 (* 1 = 0.158622 loss)
I0526 04:18:57.594578 15117 sgd_solver.cpp:294] Iteration 21500, lr = 0.02
I0526 04:19:03.929756 15117 solver.cpp:233] Iteration 21510, loss = 0.178408
I0526 04:19:03.929800 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.178408 (* 1 = 0.178408 loss)
I0526 04:19:03.929817 15117 sgd_solver.cpp:294] Iteration 21510, lr = 0.02
I0526 04:19:10.266778 15117 solver.cpp:233] Iteration 21520, loss = 0.0975959
I0526 04:19:10.266819 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0975959 (* 1 = 0.0975959 loss)
I0526 04:19:10.266826 15117 sgd_solver.cpp:294] Iteration 21520, lr = 0.02
I0526 04:19:16.604625 15117 solver.cpp:233] Iteration 21530, loss = 0.177659
I0526 04:19:16.604667 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.177659 (* 1 = 0.177659 loss)
I0526 04:19:16.604674 15117 sgd_solver.cpp:294] Iteration 21530, lr = 0.02
I0526 04:19:22.938208 15117 solver.cpp:233] Iteration 21540, loss = 0.0953139
I0526 04:19:22.938256 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.095314 (* 1 = 0.095314 loss)
I0526 04:19:22.938269 15117 sgd_solver.cpp:294] Iteration 21540, lr = 0.02
I0526 04:19:29.275414 15117 solver.cpp:233] Iteration 21550, loss = 0.145062
I0526 04:19:29.275660 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.145062 (* 1 = 0.145062 loss)
I0526 04:19:29.275686 15117 sgd_solver.cpp:294] Iteration 21550, lr = 0.02
I0526 04:19:35.601599 15117 solver.cpp:233] Iteration 21560, loss = 0.0580614
I0526 04:19:35.601641 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0580615 (* 1 = 0.0580615 loss)
I0526 04:19:35.601649 15117 sgd_solver.cpp:294] Iteration 21560, lr = 0.02
I0526 04:19:41.934180 15117 solver.cpp:233] Iteration 21570, loss = 0.146095
I0526 04:19:41.934206 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.146095 (* 1 = 0.146095 loss)
I0526 04:19:41.934211 15117 sgd_solver.cpp:294] Iteration 21570, lr = 0.02
I0526 04:19:48.266165 15117 solver.cpp:233] Iteration 21580, loss = 0.0881528
I0526 04:19:48.266204 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0881529 (* 1 = 0.0881529 loss)
I0526 04:19:48.266211 15117 sgd_solver.cpp:294] Iteration 21580, lr = 0.02
I0526 04:19:54.602023 15117 solver.cpp:233] Iteration 21590, loss = 0.16547
I0526 04:19:54.602062 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.16547 (* 1 = 0.16547 loss)
I0526 04:19:54.602069 15117 sgd_solver.cpp:294] Iteration 21590, lr = 0.02
I0526 04:20:00.337224 15117 solver.cpp:342] Iteration 21600, Testing net (#0)
I0526 04:20:13.172757 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8002
I0526 04:20:13.172801 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.770035 (* 1 = 0.770035 loss)
I0526 04:20:13.774363 15117 solver.cpp:233] Iteration 21600, loss = 0.147169
I0526 04:20:13.774405 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.147169 (* 1 = 0.147169 loss)
I0526 04:20:13.774413 15117 sgd_solver.cpp:294] Iteration 21600, lr = 0.02
I0526 04:20:20.108330 15117 solver.cpp:233] Iteration 21610, loss = 0.0596205
I0526 04:20:20.108372 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0596205 (* 1 = 0.0596205 loss)
I0526 04:20:20.108379 15117 sgd_solver.cpp:294] Iteration 21610, lr = 0.02
I0526 04:20:26.441665 15117 solver.cpp:233] Iteration 21620, loss = 0.113877
I0526 04:20:26.441704 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.113877 (* 1 = 0.113877 loss)
I0526 04:20:26.441712 15117 sgd_solver.cpp:294] Iteration 21620, lr = 0.02
I0526 04:20:32.778461 15117 solver.cpp:233] Iteration 21630, loss = 0.106463
I0526 04:20:32.778687 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.106463 (* 1 = 0.106463 loss)
I0526 04:20:32.778714 15117 sgd_solver.cpp:294] Iteration 21630, lr = 0.02
I0526 04:20:39.114027 15117 solver.cpp:233] Iteration 21640, loss = 0.134723
I0526 04:20:39.114070 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.134723 (* 1 = 0.134723 loss)
I0526 04:20:39.114078 15117 sgd_solver.cpp:294] Iteration 21640, lr = 0.02
I0526 04:20:45.451829 15117 solver.cpp:233] Iteration 21650, loss = 0.157102
I0526 04:20:45.451874 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.157102 (* 1 = 0.157102 loss)
I0526 04:20:45.451881 15117 sgd_solver.cpp:294] Iteration 21650, lr = 0.02
I0526 04:20:51.784943 15117 solver.cpp:233] Iteration 21660, loss = 0.106262
I0526 04:20:51.784988 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.106262 (* 1 = 0.106262 loss)
I0526 04:20:51.784996 15117 sgd_solver.cpp:294] Iteration 21660, lr = 0.02
I0526 04:20:58.118883 15117 solver.cpp:233] Iteration 21670, loss = 0.161991
I0526 04:20:58.118935 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.161991 (* 1 = 0.161991 loss)
I0526 04:20:58.118942 15117 sgd_solver.cpp:294] Iteration 21670, lr = 0.02
I0526 04:21:04.451746 15117 solver.cpp:233] Iteration 21680, loss = 0.0648253
I0526 04:21:04.451922 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0648254 (* 1 = 0.0648254 loss)
I0526 04:21:04.451936 15117 sgd_solver.cpp:294] Iteration 21680, lr = 0.02
I0526 04:21:10.787938 15117 solver.cpp:233] Iteration 21690, loss = 0.120639
I0526 04:21:10.787976 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.120639 (* 1 = 0.120639 loss)
I0526 04:21:10.787982 15117 sgd_solver.cpp:294] Iteration 21690, lr = 0.02
I0526 04:21:16.519613 15117 solver.cpp:342] Iteration 21700, Testing net (#0)
I0526 04:21:29.355654 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8024
I0526 04:21:29.355708 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.806734 (* 1 = 0.806734 loss)
I0526 04:21:29.956553 15117 solver.cpp:233] Iteration 21700, loss = 0.161194
I0526 04:21:29.956590 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.161194 (* 1 = 0.161194 loss)
I0526 04:21:29.956598 15117 sgd_solver.cpp:294] Iteration 21700, lr = 0.02
I0526 04:21:36.292057 15117 solver.cpp:233] Iteration 21710, loss = 0.156696
I0526 04:21:36.292306 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.156696 (* 1 = 0.156696 loss)
I0526 04:21:36.292335 15117 sgd_solver.cpp:294] Iteration 21710, lr = 0.02
I0526 04:21:42.629191 15117 solver.cpp:233] Iteration 21720, loss = 0.179111
I0526 04:21:42.629235 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.179111 (* 1 = 0.179111 loss)
I0526 04:21:42.629241 15117 sgd_solver.cpp:294] Iteration 21720, lr = 0.02
I0526 04:21:48.961874 15117 solver.cpp:233] Iteration 21730, loss = 0.114947
I0526 04:21:48.961916 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.114947 (* 1 = 0.114947 loss)
I0526 04:21:48.961922 15117 sgd_solver.cpp:294] Iteration 21730, lr = 0.02
I0526 04:21:55.295624 15117 solver.cpp:233] Iteration 21740, loss = 0.191566
I0526 04:21:55.295650 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.191566 (* 1 = 0.191566 loss)
I0526 04:21:55.295656 15117 sgd_solver.cpp:294] Iteration 21740, lr = 0.02
I0526 04:22:01.631101 15117 solver.cpp:233] Iteration 21750, loss = 0.129083
I0526 04:22:01.631145 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.129083 (* 1 = 0.129083 loss)
I0526 04:22:01.631152 15117 sgd_solver.cpp:294] Iteration 21750, lr = 0.02
I0526 04:22:07.965186 15117 solver.cpp:233] Iteration 21760, loss = 0.0931498
I0526 04:22:07.965406 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0931499 (* 1 = 0.0931499 loss)
I0526 04:22:07.965443 15117 sgd_solver.cpp:294] Iteration 21760, lr = 0.02
I0526 04:22:14.299212 15117 solver.cpp:233] Iteration 21770, loss = 0.0905619
I0526 04:22:14.299257 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.090562 (* 1 = 0.090562 loss)
I0526 04:22:14.299264 15117 sgd_solver.cpp:294] Iteration 21770, lr = 0.02
I0526 04:22:20.631597 15117 solver.cpp:233] Iteration 21780, loss = 0.116992
I0526 04:22:20.631639 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.116992 (* 1 = 0.116992 loss)
I0526 04:22:20.631646 15117 sgd_solver.cpp:294] Iteration 21780, lr = 0.02
I0526 04:22:26.962757 15117 solver.cpp:233] Iteration 21790, loss = 0.142599
I0526 04:22:26.962806 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.142599 (* 1 = 0.142599 loss)
I0526 04:22:26.962815 15117 sgd_solver.cpp:294] Iteration 21790, lr = 0.02
I0526 04:22:32.697607 15117 solver.cpp:342] Iteration 21800, Testing net (#0)
I0526 04:22:45.538122 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7927
I0526 04:22:45.538395 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.859073 (* 1 = 0.859073 loss)
I0526 04:22:46.138203 15117 solver.cpp:233] Iteration 21800, loss = 0.169165
I0526 04:22:46.138247 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.169165 (* 1 = 0.169165 loss)
I0526 04:22:46.138257 15117 sgd_solver.cpp:294] Iteration 21800, lr = 0.02
I0526 04:22:52.471793 15117 solver.cpp:233] Iteration 21810, loss = 0.219342
I0526 04:22:52.471832 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.219342 (* 1 = 0.219342 loss)
I0526 04:22:52.471845 15117 sgd_solver.cpp:294] Iteration 21810, lr = 0.02
I0526 04:22:58.810611 15117 solver.cpp:233] Iteration 21820, loss = 0.127787
I0526 04:22:58.810648 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.127787 (* 1 = 0.127787 loss)
I0526 04:22:58.810657 15117 sgd_solver.cpp:294] Iteration 21820, lr = 0.02
I0526 04:23:05.146385 15117 solver.cpp:233] Iteration 21830, loss = 0.119716
I0526 04:23:05.146425 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.119716 (* 1 = 0.119716 loss)
I0526 04:23:05.146431 15117 sgd_solver.cpp:294] Iteration 21830, lr = 0.02
I0526 04:23:11.485195 15117 solver.cpp:233] Iteration 21840, loss = 0.0833607
I0526 04:23:11.485226 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0833608 (* 1 = 0.0833608 loss)
I0526 04:23:11.485232 15117 sgd_solver.cpp:294] Iteration 21840, lr = 0.02
I0526 04:23:17.822325 15117 solver.cpp:233] Iteration 21850, loss = 0.125576
I0526 04:23:17.822492 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.125577 (* 1 = 0.125577 loss)
I0526 04:23:17.822501 15117 sgd_solver.cpp:294] Iteration 21850, lr = 0.02
I0526 04:23:24.162137 15117 solver.cpp:233] Iteration 21860, loss = 0.073015
I0526 04:23:24.162176 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0730151 (* 1 = 0.0730151 loss)
I0526 04:23:24.162184 15117 sgd_solver.cpp:294] Iteration 21860, lr = 0.02
I0526 04:23:30.498397 15117 solver.cpp:233] Iteration 21870, loss = 0.239908
I0526 04:23:30.498440 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.239908 (* 1 = 0.239908 loss)
I0526 04:23:30.498446 15117 sgd_solver.cpp:294] Iteration 21870, lr = 0.02
I0526 04:23:36.832309 15117 solver.cpp:233] Iteration 21880, loss = 0.181137
I0526 04:23:36.832356 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.181137 (* 1 = 0.181137 loss)
I0526 04:23:36.832363 15117 sgd_solver.cpp:294] Iteration 21880, lr = 0.02
I0526 04:23:43.167192 15117 solver.cpp:233] Iteration 21890, loss = 0.138256
I0526 04:23:43.167229 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.138256 (* 1 = 0.138256 loss)
I0526 04:23:43.167237 15117 sgd_solver.cpp:294] Iteration 21890, lr = 0.02
I0526 04:23:48.906730 15117 solver.cpp:342] Iteration 21900, Testing net (#0)
I0526 04:24:01.738729 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8333
I0526 04:24:01.738775 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.588703 (* 1 = 0.588703 loss)
I0526 04:24:02.341255 15117 solver.cpp:233] Iteration 21900, loss = 0.118005
I0526 04:24:02.341276 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.118005 (* 1 = 0.118005 loss)
I0526 04:24:02.341284 15117 sgd_solver.cpp:294] Iteration 21900, lr = 0.02
I0526 04:24:08.680150 15117 solver.cpp:233] Iteration 21910, loss = 0.183087
I0526 04:24:08.680194 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.183087 (* 1 = 0.183087 loss)
I0526 04:24:08.680202 15117 sgd_solver.cpp:294] Iteration 21910, lr = 0.02
I0526 04:24:15.014412 15117 solver.cpp:233] Iteration 21920, loss = 0.0933162
I0526 04:24:15.014454 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0933163 (* 1 = 0.0933163 loss)
I0526 04:24:15.014461 15117 sgd_solver.cpp:294] Iteration 21920, lr = 0.02
I0526 04:24:21.350292 15117 solver.cpp:233] Iteration 21930, loss = 0.105229
I0526 04:24:21.350510 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.105229 (* 1 = 0.105229 loss)
I0526 04:24:21.350536 15117 sgd_solver.cpp:294] Iteration 21930, lr = 0.02
I0526 04:24:27.690500 15117 solver.cpp:233] Iteration 21940, loss = 0.0337522
I0526 04:24:27.690538 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0337523 (* 1 = 0.0337523 loss)
I0526 04:24:27.690546 15117 sgd_solver.cpp:294] Iteration 21940, lr = 0.02
I0526 04:24:34.028059 15117 solver.cpp:233] Iteration 21950, loss = 0.134509
I0526 04:24:34.028096 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.134509 (* 1 = 0.134509 loss)
I0526 04:24:34.028110 15117 sgd_solver.cpp:294] Iteration 21950, lr = 0.02
I0526 04:24:40.366354 15117 solver.cpp:233] Iteration 21960, loss = 0.128783
I0526 04:24:40.366408 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.128783 (* 1 = 0.128783 loss)
I0526 04:24:40.366416 15117 sgd_solver.cpp:294] Iteration 21960, lr = 0.02
I0526 04:24:46.702276 15117 solver.cpp:233] Iteration 21970, loss = 0.0794618
I0526 04:24:46.702314 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0794619 (* 1 = 0.0794619 loss)
I0526 04:24:46.702322 15117 sgd_solver.cpp:294] Iteration 21970, lr = 0.02
I0526 04:24:53.041406 15117 solver.cpp:233] Iteration 21980, loss = 0.143652
I0526 04:24:53.041550 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.143652 (* 1 = 0.143652 loss)
I0526 04:24:53.041559 15117 sgd_solver.cpp:294] Iteration 21980, lr = 0.02
I0526 04:24:59.375430 15117 solver.cpp:233] Iteration 21990, loss = 0.156019
I0526 04:24:59.375470 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.156019 (* 1 = 0.156019 loss)
I0526 04:24:59.375478 15117 sgd_solver.cpp:294] Iteration 21990, lr = 0.02
I0526 04:25:05.110648 15117 solver.cpp:342] Iteration 22000, Testing net (#0)
I0526 04:25:17.956111 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8158
I0526 04:25:17.956156 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.688832 (* 1 = 0.688832 loss)
I0526 04:25:18.557670 15117 solver.cpp:233] Iteration 22000, loss = 0.243574
I0526 04:25:18.557708 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.243574 (* 1 = 0.243574 loss)
I0526 04:25:18.557715 15117 sgd_solver.cpp:294] Iteration 22000, lr = 0.02
I0526 04:25:24.894951 15117 solver.cpp:233] Iteration 22010, loss = 0.294626
I0526 04:25:24.895186 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.294626 (* 1 = 0.294626 loss)
I0526 04:25:24.895216 15117 sgd_solver.cpp:294] Iteration 22010, lr = 0.02
I0526 04:25:31.231070 15117 solver.cpp:233] Iteration 22020, loss = 0.0923996
I0526 04:25:31.231109 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0923997 (* 1 = 0.0923997 loss)
I0526 04:25:31.231117 15117 sgd_solver.cpp:294] Iteration 22020, lr = 0.02
I0526 04:25:37.565851 15117 solver.cpp:233] Iteration 22030, loss = 0.111649
I0526 04:25:37.565893 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.111649 (* 1 = 0.111649 loss)
I0526 04:25:37.565901 15117 sgd_solver.cpp:294] Iteration 22030, lr = 0.02
I0526 04:25:43.904160 15117 solver.cpp:233] Iteration 22040, loss = 0.138909
I0526 04:25:43.904222 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.138909 (* 1 = 0.138909 loss)
I0526 04:25:43.904228 15117 sgd_solver.cpp:294] Iteration 22040, lr = 0.02
I0526 04:25:50.240527 15117 solver.cpp:233] Iteration 22050, loss = 0.128428
I0526 04:25:50.240567 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.128428 (* 1 = 0.128428 loss)
I0526 04:25:50.240586 15117 sgd_solver.cpp:294] Iteration 22050, lr = 0.02
I0526 04:25:56.578269 15117 solver.cpp:233] Iteration 22060, loss = 0.0910404
I0526 04:25:56.578500 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0910406 (* 1 = 0.0910406 loss)
I0526 04:25:56.578524 15117 sgd_solver.cpp:294] Iteration 22060, lr = 0.02
I0526 04:26:02.907647 15117 solver.cpp:233] Iteration 22070, loss = 0.0898719
I0526 04:26:02.907691 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.089872 (* 1 = 0.089872 loss)
I0526 04:26:02.907699 15117 sgd_solver.cpp:294] Iteration 22070, lr = 0.02
I0526 04:26:09.247117 15117 solver.cpp:233] Iteration 22080, loss = 0.0666846
I0526 04:26:09.247171 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0666847 (* 1 = 0.0666847 loss)
I0526 04:26:09.247179 15117 sgd_solver.cpp:294] Iteration 22080, lr = 0.02
I0526 04:26:15.584450 15117 solver.cpp:233] Iteration 22090, loss = 0.125247
I0526 04:26:15.584488 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.125247 (* 1 = 0.125247 loss)
I0526 04:26:15.584501 15117 sgd_solver.cpp:294] Iteration 22090, lr = 0.02
I0526 04:26:21.321697 15117 solver.cpp:342] Iteration 22100, Testing net (#0)
I0526 04:26:34.160475 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7945
I0526 04:26:34.160749 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.777925 (* 1 = 0.777925 loss)
I0526 04:26:34.760632 15117 solver.cpp:233] Iteration 22100, loss = 0.0801152
I0526 04:26:34.760699 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0801153 (* 1 = 0.0801153 loss)
I0526 04:26:34.760710 15117 sgd_solver.cpp:294] Iteration 22100, lr = 0.02
I0526 04:26:41.090867 15117 solver.cpp:233] Iteration 22110, loss = 0.175215
I0526 04:26:41.090910 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.175215 (* 1 = 0.175215 loss)
I0526 04:26:41.090919 15117 sgd_solver.cpp:294] Iteration 22110, lr = 0.02
I0526 04:26:47.429486 15117 solver.cpp:233] Iteration 22120, loss = 0.165582
I0526 04:26:47.429522 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.165583 (* 1 = 0.165583 loss)
I0526 04:26:47.429528 15117 sgd_solver.cpp:294] Iteration 22120, lr = 0.02
I0526 04:26:53.766190 15117 solver.cpp:233] Iteration 22130, loss = 0.140027
I0526 04:26:53.766221 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.140027 (* 1 = 0.140027 loss)
I0526 04:26:53.766227 15117 sgd_solver.cpp:294] Iteration 22130, lr = 0.02
I0526 04:27:00.106134 15117 solver.cpp:233] Iteration 22140, loss = 0.183403
I0526 04:27:00.106175 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.183403 (* 1 = 0.183403 loss)
I0526 04:27:00.106181 15117 sgd_solver.cpp:294] Iteration 22140, lr = 0.02
I0526 04:27:06.441478 15117 solver.cpp:233] Iteration 22150, loss = 0.110572
I0526 04:27:06.441716 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.110572 (* 1 = 0.110572 loss)
I0526 04:27:06.441745 15117 sgd_solver.cpp:294] Iteration 22150, lr = 0.02
I0526 04:27:12.776067 15117 solver.cpp:233] Iteration 22160, loss = 0.148824
I0526 04:27:12.776120 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.148824 (* 1 = 0.148824 loss)
I0526 04:27:12.776129 15117 sgd_solver.cpp:294] Iteration 22160, lr = 0.02
I0526 04:27:19.108458 15117 solver.cpp:233] Iteration 22170, loss = 0.150625
I0526 04:27:19.108506 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.150625 (* 1 = 0.150625 loss)
I0526 04:27:19.108515 15117 sgd_solver.cpp:294] Iteration 22170, lr = 0.02
I0526 04:27:25.443356 15117 solver.cpp:233] Iteration 22180, loss = 0.131608
I0526 04:27:25.443399 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.131608 (* 1 = 0.131608 loss)
I0526 04:27:25.443408 15117 sgd_solver.cpp:294] Iteration 22180, lr = 0.02
I0526 04:27:31.782567 15117 solver.cpp:233] Iteration 22190, loss = 0.117386
I0526 04:27:31.782608 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.117386 (* 1 = 0.117386 loss)
I0526 04:27:31.782614 15117 sgd_solver.cpp:294] Iteration 22190, lr = 0.02
I0526 04:27:37.516762 15117 solver.cpp:342] Iteration 22200, Testing net (#0)
I0526 04:27:50.356858 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.823
I0526 04:27:50.356901 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.68121 (* 1 = 0.68121 loss)
I0526 04:27:50.958431 15117 solver.cpp:233] Iteration 22200, loss = 0.0852166
I0526 04:27:50.958467 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0852167 (* 1 = 0.0852167 loss)
I0526 04:27:50.958475 15117 sgd_solver.cpp:294] Iteration 22200, lr = 0.02
I0526 04:27:57.295114 15117 solver.cpp:233] Iteration 22210, loss = 0.136924
I0526 04:27:57.295153 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.136924 (* 1 = 0.136924 loss)
I0526 04:27:57.295161 15117 sgd_solver.cpp:294] Iteration 22210, lr = 0.02
I0526 04:28:03.634482 15117 solver.cpp:233] Iteration 22220, loss = 0.0976505
I0526 04:28:03.634521 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0976506 (* 1 = 0.0976506 loss)
I0526 04:28:03.634534 15117 sgd_solver.cpp:294] Iteration 22220, lr = 0.02
I0526 04:28:09.970062 15117 solver.cpp:233] Iteration 22230, loss = 0.136793
I0526 04:28:09.970327 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.136794 (* 1 = 0.136794 loss)
I0526 04:28:09.970386 15117 sgd_solver.cpp:294] Iteration 22230, lr = 0.02
I0526 04:28:16.302268 15117 solver.cpp:233] Iteration 22240, loss = 0.0575197
I0526 04:28:16.302323 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0575199 (* 1 = 0.0575199 loss)
I0526 04:28:16.302330 15117 sgd_solver.cpp:294] Iteration 22240, lr = 0.02
I0526 04:28:22.642005 15117 solver.cpp:233] Iteration 22250, loss = 0.0720248
I0526 04:28:22.642051 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0720249 (* 1 = 0.0720249 loss)
I0526 04:28:22.642060 15117 sgd_solver.cpp:294] Iteration 22250, lr = 0.02
I0526 04:28:28.976372 15117 solver.cpp:233] Iteration 22260, loss = 0.13341
I0526 04:28:28.976410 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.13341 (* 1 = 0.13341 loss)
I0526 04:28:28.976418 15117 sgd_solver.cpp:294] Iteration 22260, lr = 0.02
I0526 04:28:35.312608 15117 solver.cpp:233] Iteration 22270, loss = 0.0955305
I0526 04:28:35.312649 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0955307 (* 1 = 0.0955307 loss)
I0526 04:28:35.312655 15117 sgd_solver.cpp:294] Iteration 22270, lr = 0.02
I0526 04:28:41.643349 15117 solver.cpp:233] Iteration 22280, loss = 0.144153
I0526 04:28:41.643586 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.144153 (* 1 = 0.144153 loss)
I0526 04:28:41.643615 15117 sgd_solver.cpp:294] Iteration 22280, lr = 0.02
I0526 04:28:47.973186 15117 solver.cpp:233] Iteration 22290, loss = 0.108803
I0526 04:28:47.973225 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.108803 (* 1 = 0.108803 loss)
I0526 04:28:47.973233 15117 sgd_solver.cpp:294] Iteration 22290, lr = 0.02
I0526 04:28:53.708693 15117 solver.cpp:342] Iteration 22300, Testing net (#0)
I0526 04:29:06.542824 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8325
I0526 04:29:06.542863 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.642798 (* 1 = 0.642798 loss)
I0526 04:29:07.144876 15117 solver.cpp:233] Iteration 22300, loss = 0.154516
I0526 04:29:07.144906 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.154516 (* 1 = 0.154516 loss)
I0526 04:29:07.144912 15117 sgd_solver.cpp:294] Iteration 22300, lr = 0.02
I0526 04:29:13.477972 15117 solver.cpp:233] Iteration 22310, loss = 0.155616
I0526 04:29:13.478188 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.155616 (* 1 = 0.155616 loss)
I0526 04:29:13.478217 15117 sgd_solver.cpp:294] Iteration 22310, lr = 0.02
I0526 04:29:19.811326 15117 solver.cpp:233] Iteration 22320, loss = 0.131152
I0526 04:29:19.811365 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.131152 (* 1 = 0.131152 loss)
I0526 04:29:19.811372 15117 sgd_solver.cpp:294] Iteration 22320, lr = 0.02
I0526 04:29:26.145627 15117 solver.cpp:233] Iteration 22330, loss = 0.0926023
I0526 04:29:26.145691 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0926024 (* 1 = 0.0926024 loss)
I0526 04:29:26.145699 15117 sgd_solver.cpp:294] Iteration 22330, lr = 0.02
I0526 04:29:32.478564 15117 solver.cpp:233] Iteration 22340, loss = 0.183467
I0526 04:29:32.478606 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.183467 (* 1 = 0.183467 loss)
I0526 04:29:32.478613 15117 sgd_solver.cpp:294] Iteration 22340, lr = 0.02
I0526 04:29:38.810240 15117 solver.cpp:233] Iteration 22350, loss = 0.138067
I0526 04:29:38.810286 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.138067 (* 1 = 0.138067 loss)
I0526 04:29:38.810293 15117 sgd_solver.cpp:294] Iteration 22350, lr = 0.02
I0526 04:29:45.144542 15117 solver.cpp:233] Iteration 22360, loss = 0.137733
I0526 04:29:45.144829 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.137734 (* 1 = 0.137734 loss)
I0526 04:29:45.144857 15117 sgd_solver.cpp:294] Iteration 22360, lr = 0.02
I0526 04:29:51.472831 15117 solver.cpp:233] Iteration 22370, loss = 0.140289
I0526 04:29:51.472870 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.140289 (* 1 = 0.140289 loss)
I0526 04:29:51.472878 15117 sgd_solver.cpp:294] Iteration 22370, lr = 0.02
I0526 04:29:57.809948 15117 solver.cpp:233] Iteration 22380, loss = 0.103442
I0526 04:29:57.809988 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.103443 (* 1 = 0.103443 loss)
I0526 04:29:57.809996 15117 sgd_solver.cpp:294] Iteration 22380, lr = 0.02
I0526 04:30:04.143471 15117 solver.cpp:233] Iteration 22390, loss = 0.148922
I0526 04:30:04.143512 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.148922 (* 1 = 0.148922 loss)
I0526 04:30:04.143518 15117 sgd_solver.cpp:294] Iteration 22390, lr = 0.02
I0526 04:30:09.870041 15117 solver.cpp:342] Iteration 22400, Testing net (#0)
I0526 04:30:22.678869 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8475
I0526 04:30:22.679095 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.516906 (* 1 = 0.516906 loss)
I0526 04:30:23.278101 15117 solver.cpp:233] Iteration 22400, loss = 0.148109
I0526 04:30:23.278142 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.148109 (* 1 = 0.148109 loss)
I0526 04:30:23.278151 15117 sgd_solver.cpp:294] Iteration 22400, lr = 0.02
I0526 04:30:29.590847 15117 solver.cpp:233] Iteration 22410, loss = 0.166462
I0526 04:30:29.590888 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.166462 (* 1 = 0.166462 loss)
I0526 04:30:29.590895 15117 sgd_solver.cpp:294] Iteration 22410, lr = 0.02
I0526 04:30:35.904853 15117 solver.cpp:233] Iteration 22420, loss = 0.104335
I0526 04:30:35.904902 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.104335 (* 1 = 0.104335 loss)
I0526 04:30:35.904909 15117 sgd_solver.cpp:294] Iteration 22420, lr = 0.02
I0526 04:30:42.226423 15117 solver.cpp:233] Iteration 22430, loss = 0.155982
I0526 04:30:42.226464 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.155982 (* 1 = 0.155982 loss)
I0526 04:30:42.226471 15117 sgd_solver.cpp:294] Iteration 22430, lr = 0.02
I0526 04:30:48.562549 15117 solver.cpp:233] Iteration 22440, loss = 0.0905436
I0526 04:30:48.562589 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0905437 (* 1 = 0.0905437 loss)
I0526 04:30:48.562597 15117 sgd_solver.cpp:294] Iteration 22440, lr = 0.02
I0526 04:30:54.895974 15117 solver.cpp:233] Iteration 22450, loss = 0.0699184
I0526 04:30:54.896199 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0699186 (* 1 = 0.0699186 loss)
I0526 04:30:54.896227 15117 sgd_solver.cpp:294] Iteration 22450, lr = 0.02
I0526 04:31:01.225605 15117 solver.cpp:233] Iteration 22460, loss = 0.154138
I0526 04:31:01.225658 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.154138 (* 1 = 0.154138 loss)
I0526 04:31:01.225666 15117 sgd_solver.cpp:294] Iteration 22460, lr = 0.02
I0526 04:31:07.559814 15117 solver.cpp:233] Iteration 22470, loss = 0.115346
I0526 04:31:07.559855 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.115346 (* 1 = 0.115346 loss)
I0526 04:31:07.559862 15117 sgd_solver.cpp:294] Iteration 22470, lr = 0.02
I0526 04:31:13.897537 15117 solver.cpp:233] Iteration 22480, loss = 0.107276
I0526 04:31:13.897579 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.107276 (* 1 = 0.107276 loss)
I0526 04:31:13.897586 15117 sgd_solver.cpp:294] Iteration 22480, lr = 0.02
I0526 04:31:20.234452 15117 solver.cpp:233] Iteration 22490, loss = 0.116327
I0526 04:31:20.234494 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.116327 (* 1 = 0.116327 loss)
I0526 04:31:20.234501 15117 sgd_solver.cpp:294] Iteration 22490, lr = 0.02
I0526 04:31:25.963963 15117 solver.cpp:342] Iteration 22500, Testing net (#0)
I0526 04:31:38.808926 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7566
I0526 04:31:38.808974 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.0955 (* 1 = 1.0955 loss)
I0526 04:31:39.410621 15117 solver.cpp:233] Iteration 22500, loss = 0.110619
I0526 04:31:39.410660 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.11062 (* 1 = 0.11062 loss)
I0526 04:31:39.410667 15117 sgd_solver.cpp:294] Iteration 22500, lr = 0.02
I0526 04:31:45.746047 15117 solver.cpp:233] Iteration 22510, loss = 0.136569
I0526 04:31:45.746085 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.136569 (* 1 = 0.136569 loss)
I0526 04:31:45.746093 15117 sgd_solver.cpp:294] Iteration 22510, lr = 0.02
I0526 04:31:52.079900 15117 solver.cpp:233] Iteration 22520, loss = 0.149165
I0526 04:31:52.079946 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.149165 (* 1 = 0.149165 loss)
I0526 04:31:52.079953 15117 sgd_solver.cpp:294] Iteration 22520, lr = 0.02
I0526 04:31:58.412631 15117 solver.cpp:233] Iteration 22530, loss = 0.15504
I0526 04:31:58.412861 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.15504 (* 1 = 0.15504 loss)
I0526 04:31:58.412889 15117 sgd_solver.cpp:294] Iteration 22530, lr = 0.02
I0526 04:32:04.746590 15117 solver.cpp:233] Iteration 22540, loss = 0.119038
I0526 04:32:04.746630 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.119038 (* 1 = 0.119038 loss)
I0526 04:32:04.746636 15117 sgd_solver.cpp:294] Iteration 22540, lr = 0.02
I0526 04:32:11.080898 15117 solver.cpp:233] Iteration 22550, loss = 0.152513
I0526 04:32:11.080940 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.152513 (* 1 = 0.152513 loss)
I0526 04:32:11.080946 15117 sgd_solver.cpp:294] Iteration 22550, lr = 0.02
I0526 04:32:17.415349 15117 solver.cpp:233] Iteration 22560, loss = 0.126185
I0526 04:32:17.415400 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.126185 (* 1 = 0.126185 loss)
I0526 04:32:17.415407 15117 sgd_solver.cpp:294] Iteration 22560, lr = 0.02
I0526 04:32:23.750380 15117 solver.cpp:233] Iteration 22570, loss = 0.124192
I0526 04:32:23.750419 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.124192 (* 1 = 0.124192 loss)
I0526 04:32:23.750427 15117 sgd_solver.cpp:294] Iteration 22570, lr = 0.02
I0526 04:32:30.085320 15117 solver.cpp:233] Iteration 22580, loss = 0.0862983
I0526 04:32:30.085541 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0862984 (* 1 = 0.0862984 loss)
I0526 04:32:30.085566 15117 sgd_solver.cpp:294] Iteration 22580, lr = 0.02
I0526 04:32:36.419536 15117 solver.cpp:233] Iteration 22590, loss = 0.171332
I0526 04:32:36.419579 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.171332 (* 1 = 0.171332 loss)
I0526 04:32:36.419586 15117 sgd_solver.cpp:294] Iteration 22590, lr = 0.02
I0526 04:32:42.154492 15117 solver.cpp:342] Iteration 22600, Testing net (#0)
I0526 04:32:54.997408 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8256
I0526 04:32:54.997452 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.703323 (* 1 = 0.703323 loss)
I0526 04:32:55.598707 15117 solver.cpp:233] Iteration 22600, loss = 0.221526
I0526 04:32:55.598743 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.221526 (* 1 = 0.221526 loss)
I0526 04:32:55.598752 15117 sgd_solver.cpp:294] Iteration 22600, lr = 0.02
I0526 04:33:01.932307 15117 solver.cpp:233] Iteration 22610, loss = 0.10211
I0526 04:33:01.932520 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.10211 (* 1 = 0.10211 loss)
I0526 04:33:01.932546 15117 sgd_solver.cpp:294] Iteration 22610, lr = 0.02
I0526 04:33:08.267977 15117 solver.cpp:233] Iteration 22620, loss = 0.0639824
I0526 04:33:08.268031 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0639825 (* 1 = 0.0639825 loss)
I0526 04:33:08.268038 15117 sgd_solver.cpp:294] Iteration 22620, lr = 0.02
I0526 04:33:14.600715 15117 solver.cpp:233] Iteration 22630, loss = 0.074639
I0526 04:33:14.600754 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0746391 (* 1 = 0.0746391 loss)
I0526 04:33:14.600761 15117 sgd_solver.cpp:294] Iteration 22630, lr = 0.02
I0526 04:33:20.935696 15117 solver.cpp:233] Iteration 22640, loss = 0.0700893
I0526 04:33:20.935734 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0700894 (* 1 = 0.0700894 loss)
I0526 04:33:20.935742 15117 sgd_solver.cpp:294] Iteration 22640, lr = 0.02
I0526 04:33:27.270485 15117 solver.cpp:233] Iteration 22650, loss = 0.0946177
I0526 04:33:27.270527 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0946178 (* 1 = 0.0946178 loss)
I0526 04:33:27.270534 15117 sgd_solver.cpp:294] Iteration 22650, lr = 0.02
I0526 04:33:33.609377 15117 solver.cpp:233] Iteration 22660, loss = 0.0641725
I0526 04:33:33.609637 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0641726 (* 1 = 0.0641726 loss)
I0526 04:33:33.609663 15117 sgd_solver.cpp:294] Iteration 22660, lr = 0.02
I0526 04:33:39.944423 15117 solver.cpp:233] Iteration 22670, loss = 0.144722
I0526 04:33:39.944478 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.144722 (* 1 = 0.144722 loss)
I0526 04:33:39.944485 15117 sgd_solver.cpp:294] Iteration 22670, lr = 0.02
I0526 04:33:46.281664 15117 solver.cpp:233] Iteration 22680, loss = 0.0714772
I0526 04:33:46.281704 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0714773 (* 1 = 0.0714773 loss)
I0526 04:33:46.281710 15117 sgd_solver.cpp:294] Iteration 22680, lr = 0.02
I0526 04:33:52.617688 15117 solver.cpp:233] Iteration 22690, loss = 0.0765787
I0526 04:33:52.617730 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0765788 (* 1 = 0.0765788 loss)
I0526 04:33:52.617738 15117 sgd_solver.cpp:294] Iteration 22690, lr = 0.02
I0526 04:33:58.351641 15117 solver.cpp:342] Iteration 22700, Testing net (#0)
I0526 04:34:11.197636 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8363
I0526 04:34:11.197887 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.621161 (* 1 = 0.621161 loss)
I0526 04:34:11.799023 15117 solver.cpp:233] Iteration 22700, loss = 0.0918961
I0526 04:34:11.799067 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0918963 (* 1 = 0.0918963 loss)
I0526 04:34:11.799077 15117 sgd_solver.cpp:294] Iteration 22700, lr = 0.02
I0526 04:34:18.132233 15117 solver.cpp:233] Iteration 22710, loss = 0.125248
I0526 04:34:18.132272 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.125248 (* 1 = 0.125248 loss)
I0526 04:34:18.132279 15117 sgd_solver.cpp:294] Iteration 22710, lr = 0.02
I0526 04:34:24.467743 15117 solver.cpp:233] Iteration 22720, loss = 0.120839
I0526 04:34:24.467785 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.120839 (* 1 = 0.120839 loss)
I0526 04:34:24.467792 15117 sgd_solver.cpp:294] Iteration 22720, lr = 0.02
I0526 04:34:30.799917 15117 solver.cpp:233] Iteration 22730, loss = 0.0834676
I0526 04:34:30.799957 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0834677 (* 1 = 0.0834677 loss)
I0526 04:34:30.799964 15117 sgd_solver.cpp:294] Iteration 22730, lr = 0.02
I0526 04:34:37.132437 15117 solver.cpp:233] Iteration 22740, loss = 0.0757461
I0526 04:34:37.132483 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0757462 (* 1 = 0.0757462 loss)
I0526 04:34:37.132490 15117 sgd_solver.cpp:294] Iteration 22740, lr = 0.02
I0526 04:34:43.467139 15117 solver.cpp:233] Iteration 22750, loss = 0.0843863
I0526 04:34:43.467381 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0843864 (* 1 = 0.0843864 loss)
I0526 04:34:43.467411 15117 sgd_solver.cpp:294] Iteration 22750, lr = 0.02
I0526 04:34:49.801326 15117 solver.cpp:233] Iteration 22760, loss = 0.0540989
I0526 04:34:49.801380 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.054099 (* 1 = 0.054099 loss)
I0526 04:34:49.801388 15117 sgd_solver.cpp:294] Iteration 22760, lr = 0.02
I0526 04:34:56.138834 15117 solver.cpp:233] Iteration 22770, loss = 0.0908724
I0526 04:34:56.138880 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0908725 (* 1 = 0.0908725 loss)
I0526 04:34:56.138886 15117 sgd_solver.cpp:294] Iteration 22770, lr = 0.02
I0526 04:35:02.476238 15117 solver.cpp:233] Iteration 22780, loss = 0.140543
I0526 04:35:02.476277 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.140543 (* 1 = 0.140543 loss)
I0526 04:35:02.476285 15117 sgd_solver.cpp:294] Iteration 22780, lr = 0.02
I0526 04:35:08.817190 15117 solver.cpp:233] Iteration 22790, loss = 0.141359
I0526 04:35:08.817231 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.141359 (* 1 = 0.141359 loss)
I0526 04:35:08.817239 15117 sgd_solver.cpp:294] Iteration 22790, lr = 0.02
I0526 04:35:14.552477 15117 solver.cpp:342] Iteration 22800, Testing net (#0)
I0526 04:35:27.396668 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.837
I0526 04:35:27.396711 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.573191 (* 1 = 0.573191 loss)
I0526 04:35:27.999199 15117 solver.cpp:233] Iteration 22800, loss = 0.136867
I0526 04:35:27.999233 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.136867 (* 1 = 0.136867 loss)
I0526 04:35:27.999239 15117 sgd_solver.cpp:294] Iteration 22800, lr = 0.02
I0526 04:35:34.339406 15117 solver.cpp:233] Iteration 22810, loss = 0.132806
I0526 04:35:34.339444 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.132806 (* 1 = 0.132806 loss)
I0526 04:35:34.339452 15117 sgd_solver.cpp:294] Iteration 22810, lr = 0.02
I0526 04:35:40.675442 15117 solver.cpp:233] Iteration 22820, loss = 0.120289
I0526 04:35:40.675487 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.120289 (* 1 = 0.120289 loss)
I0526 04:35:40.675493 15117 sgd_solver.cpp:294] Iteration 22820, lr = 0.02
I0526 04:35:47.014447 15117 solver.cpp:233] Iteration 22830, loss = 0.0980229
I0526 04:35:47.014643 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.098023 (* 1 = 0.098023 loss)
I0526 04:35:47.014672 15117 sgd_solver.cpp:294] Iteration 22830, lr = 0.02
I0526 04:35:53.351471 15117 solver.cpp:233] Iteration 22840, loss = 0.211701
I0526 04:35:53.351523 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.211701 (* 1 = 0.211701 loss)
I0526 04:35:53.351531 15117 sgd_solver.cpp:294] Iteration 22840, lr = 0.02
I0526 04:35:59.689800 15117 solver.cpp:233] Iteration 22850, loss = 0.145881
I0526 04:35:59.689843 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.145881 (* 1 = 0.145881 loss)
I0526 04:35:59.689851 15117 sgd_solver.cpp:294] Iteration 22850, lr = 0.02
I0526 04:36:06.028594 15117 solver.cpp:233] Iteration 22860, loss = 0.105267
I0526 04:36:06.028633 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.105267 (* 1 = 0.105267 loss)
I0526 04:36:06.028640 15117 sgd_solver.cpp:294] Iteration 22860, lr = 0.02
I0526 04:36:12.358922 15117 solver.cpp:233] Iteration 22870, loss = 0.133639
I0526 04:36:12.358959 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.133639 (* 1 = 0.133639 loss)
I0526 04:36:12.358965 15117 sgd_solver.cpp:294] Iteration 22870, lr = 0.02
I0526 04:36:18.693886 15117 solver.cpp:233] Iteration 22880, loss = 0.184889
I0526 04:36:18.694103 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.184889 (* 1 = 0.184889 loss)
I0526 04:36:18.694130 15117 sgd_solver.cpp:294] Iteration 22880, lr = 0.02
I0526 04:36:25.028229 15117 solver.cpp:233] Iteration 22890, loss = 0.0612282
I0526 04:36:25.028273 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0612283 (* 1 = 0.0612283 loss)
I0526 04:36:25.028281 15117 sgd_solver.cpp:294] Iteration 22890, lr = 0.02
I0526 04:36:30.764300 15117 solver.cpp:342] Iteration 22900, Testing net (#0)
I0526 04:36:43.600530 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8468
I0526 04:36:43.600571 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.51945 (* 1 = 0.51945 loss)
I0526 04:36:44.201931 15117 solver.cpp:233] Iteration 22900, loss = 0.0691118
I0526 04:36:44.201970 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.069112 (* 1 = 0.069112 loss)
I0526 04:36:44.201979 15117 sgd_solver.cpp:294] Iteration 22900, lr = 0.02
I0526 04:36:50.535336 15117 solver.cpp:233] Iteration 22910, loss = 0.164605
I0526 04:36:50.535610 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.164605 (* 1 = 0.164605 loss)
I0526 04:36:50.535640 15117 sgd_solver.cpp:294] Iteration 22910, lr = 0.02
I0526 04:36:56.871320 15117 solver.cpp:233] Iteration 22920, loss = 0.158248
I0526 04:36:56.871362 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.158248 (* 1 = 0.158248 loss)
I0526 04:36:56.871369 15117 sgd_solver.cpp:294] Iteration 22920, lr = 0.02
I0526 04:37:03.205343 15117 solver.cpp:233] Iteration 22930, loss = 0.237306
I0526 04:37:03.205387 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.237307 (* 1 = 0.237307 loss)
I0526 04:37:03.205395 15117 sgd_solver.cpp:294] Iteration 22930, lr = 0.02
I0526 04:37:09.543320 15117 solver.cpp:233] Iteration 22940, loss = 0.147624
I0526 04:37:09.543373 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.147624 (* 1 = 0.147624 loss)
I0526 04:37:09.543380 15117 sgd_solver.cpp:294] Iteration 22940, lr = 0.02
I0526 04:37:15.881422 15117 solver.cpp:233] Iteration 22950, loss = 0.155902
I0526 04:37:15.881464 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.155902 (* 1 = 0.155902 loss)
I0526 04:37:15.881470 15117 sgd_solver.cpp:294] Iteration 22950, lr = 0.02
I0526 04:37:22.217525 15117 solver.cpp:233] Iteration 22960, loss = 0.128302
I0526 04:37:22.217756 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.128303 (* 1 = 0.128303 loss)
I0526 04:37:22.217794 15117 sgd_solver.cpp:294] Iteration 22960, lr = 0.02
I0526 04:37:28.549926 15117 solver.cpp:233] Iteration 22970, loss = 0.0633913
I0526 04:37:28.549968 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0633915 (* 1 = 0.0633915 loss)
I0526 04:37:28.549974 15117 sgd_solver.cpp:294] Iteration 22970, lr = 0.02
I0526 04:37:34.884692 15117 solver.cpp:233] Iteration 22980, loss = 0.107334
I0526 04:37:34.884735 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.107334 (* 1 = 0.107334 loss)
I0526 04:37:34.884742 15117 sgd_solver.cpp:294] Iteration 22980, lr = 0.02
I0526 04:37:41.220494 15117 solver.cpp:233] Iteration 22990, loss = 0.134001
I0526 04:37:41.220533 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.134001 (* 1 = 0.134001 loss)
I0526 04:37:41.220541 15117 sgd_solver.cpp:294] Iteration 22990, lr = 0.02
I0526 04:37:46.955173 15117 solver.cpp:342] Iteration 23000, Testing net (#0)
I0526 04:37:59.797761 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8384
I0526 04:37:59.797981 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.632475 (* 1 = 0.632475 loss)
I0526 04:38:00.396843 15117 solver.cpp:233] Iteration 23000, loss = 0.0770904
I0526 04:38:00.396915 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0770905 (* 1 = 0.0770905 loss)
I0526 04:38:00.396927 15117 sgd_solver.cpp:294] Iteration 23000, lr = 0.02
I0526 04:38:06.729553 15117 solver.cpp:233] Iteration 23010, loss = 0.0646049
I0526 04:38:06.729596 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0646051 (* 1 = 0.0646051 loss)
I0526 04:38:06.729604 15117 sgd_solver.cpp:294] Iteration 23010, lr = 0.02
I0526 04:38:13.063927 15117 solver.cpp:233] Iteration 23020, loss = 0.152576
I0526 04:38:13.063969 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.152576 (* 1 = 0.152576 loss)
I0526 04:38:13.063977 15117 sgd_solver.cpp:294] Iteration 23020, lr = 0.02
I0526 04:38:19.402585 15117 solver.cpp:233] Iteration 23030, loss = 0.0819973
I0526 04:38:19.402629 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0819974 (* 1 = 0.0819974 loss)
I0526 04:38:19.402637 15117 sgd_solver.cpp:294] Iteration 23030, lr = 0.02
I0526 04:38:25.735165 15117 solver.cpp:233] Iteration 23040, loss = 0.128938
I0526 04:38:25.735206 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.128938 (* 1 = 0.128938 loss)
I0526 04:38:25.735214 15117 sgd_solver.cpp:294] Iteration 23040, lr = 0.02
I0526 04:38:32.069015 15117 solver.cpp:233] Iteration 23050, loss = 0.0659474
I0526 04:38:32.069125 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0659476 (* 1 = 0.0659476 loss)
I0526 04:38:32.069144 15117 sgd_solver.cpp:294] Iteration 23050, lr = 0.02
I0526 04:38:38.402318 15117 solver.cpp:233] Iteration 23060, loss = 0.139014
I0526 04:38:38.402359 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.139014 (* 1 = 0.139014 loss)
I0526 04:38:38.402379 15117 sgd_solver.cpp:294] Iteration 23060, lr = 0.02
I0526 04:38:44.740645 15117 solver.cpp:233] Iteration 23070, loss = 0.123798
I0526 04:38:44.740689 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.123798 (* 1 = 0.123798 loss)
I0526 04:38:44.740697 15117 sgd_solver.cpp:294] Iteration 23070, lr = 0.02
I0526 04:38:51.075611 15117 solver.cpp:233] Iteration 23080, loss = 0.113169
I0526 04:38:51.075659 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.113169 (* 1 = 0.113169 loss)
I0526 04:38:51.075665 15117 sgd_solver.cpp:294] Iteration 23080, lr = 0.02
I0526 04:38:57.413729 15117 solver.cpp:233] Iteration 23090, loss = 0.148562
I0526 04:38:57.413771 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.148563 (* 1 = 0.148563 loss)
I0526 04:38:57.413779 15117 sgd_solver.cpp:294] Iteration 23090, lr = 0.02
I0526 04:39:03.148612 15117 solver.cpp:342] Iteration 23100, Testing net (#0)
I0526 04:39:15.978492 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8122
I0526 04:39:15.978544 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.796558 (* 1 = 0.796558 loss)
I0526 04:39:16.579145 15117 solver.cpp:233] Iteration 23100, loss = 0.187585
I0526 04:39:16.579183 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.187585 (* 1 = 0.187585 loss)
I0526 04:39:16.579190 15117 sgd_solver.cpp:294] Iteration 23100, lr = 0.02
I0526 04:39:22.914999 15117 solver.cpp:233] Iteration 23110, loss = 0.132922
I0526 04:39:22.915040 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.132922 (* 1 = 0.132922 loss)
I0526 04:39:22.915048 15117 sgd_solver.cpp:294] Iteration 23110, lr = 0.02
I0526 04:39:29.253490 15117 solver.cpp:233] Iteration 23120, loss = 0.122717
I0526 04:39:29.253531 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.122717 (* 1 = 0.122717 loss)
I0526 04:39:29.253540 15117 sgd_solver.cpp:294] Iteration 23120, lr = 0.02
I0526 04:39:35.587141 15117 solver.cpp:233] Iteration 23130, loss = 0.141977
I0526 04:39:35.587364 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.141977 (* 1 = 0.141977 loss)
I0526 04:39:35.587393 15117 sgd_solver.cpp:294] Iteration 23130, lr = 0.02
I0526 04:39:41.917111 15117 solver.cpp:233] Iteration 23140, loss = 0.153285
I0526 04:39:41.917152 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.153285 (* 1 = 0.153285 loss)
I0526 04:39:41.917160 15117 sgd_solver.cpp:294] Iteration 23140, lr = 0.02
I0526 04:39:48.250068 15117 solver.cpp:233] Iteration 23150, loss = 0.0840534
I0526 04:39:48.250108 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0840535 (* 1 = 0.0840535 loss)
I0526 04:39:48.250113 15117 sgd_solver.cpp:294] Iteration 23150, lr = 0.02
I0526 04:39:54.584472 15117 solver.cpp:233] Iteration 23160, loss = 0.130526
I0526 04:39:54.584514 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.130527 (* 1 = 0.130527 loss)
I0526 04:39:54.584522 15117 sgd_solver.cpp:294] Iteration 23160, lr = 0.02
I0526 04:40:00.919894 15117 solver.cpp:233] Iteration 23170, loss = 0.0960266
I0526 04:40:00.919937 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0960267 (* 1 = 0.0960267 loss)
I0526 04:40:00.919944 15117 sgd_solver.cpp:294] Iteration 23170, lr = 0.02
I0526 04:40:07.254289 15117 solver.cpp:233] Iteration 23180, loss = 0.102325
I0526 04:40:07.254529 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.102326 (* 1 = 0.102326 loss)
I0526 04:40:07.254559 15117 sgd_solver.cpp:294] Iteration 23180, lr = 0.02
I0526 04:40:13.592566 15117 solver.cpp:233] Iteration 23190, loss = 0.0965694
I0526 04:40:13.592618 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0965696 (* 1 = 0.0965696 loss)
I0526 04:40:13.592628 15117 sgd_solver.cpp:294] Iteration 23190, lr = 0.02
I0526 04:40:19.326669 15117 solver.cpp:342] Iteration 23200, Testing net (#0)
I0526 04:40:32.160073 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7923
I0526 04:40:32.160115 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.78784 (* 1 = 0.78784 loss)
I0526 04:40:32.761661 15117 solver.cpp:233] Iteration 23200, loss = 0.0752891
I0526 04:40:32.761685 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0752893 (* 1 = 0.0752893 loss)
I0526 04:40:32.761693 15117 sgd_solver.cpp:294] Iteration 23200, lr = 0.02
I0526 04:40:39.095863 15117 solver.cpp:233] Iteration 23210, loss = 0.0810896
I0526 04:40:39.096140 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0810897 (* 1 = 0.0810897 loss)
I0526 04:40:39.096168 15117 sgd_solver.cpp:294] Iteration 23210, lr = 0.02
I0526 04:40:45.427883 15117 solver.cpp:233] Iteration 23220, loss = 0.0522948
I0526 04:40:45.427938 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0522949 (* 1 = 0.0522949 loss)
I0526 04:40:45.427945 15117 sgd_solver.cpp:294] Iteration 23220, lr = 0.02
I0526 04:40:51.766762 15117 solver.cpp:233] Iteration 23230, loss = 0.149253
I0526 04:40:51.766811 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.149253 (* 1 = 0.149253 loss)
I0526 04:40:51.766818 15117 sgd_solver.cpp:294] Iteration 23230, lr = 0.02
I0526 04:40:58.100832 15117 solver.cpp:233] Iteration 23240, loss = 0.103974
I0526 04:40:58.100877 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.103974 (* 1 = 0.103974 loss)
I0526 04:40:58.100884 15117 sgd_solver.cpp:294] Iteration 23240, lr = 0.02
I0526 04:41:04.437489 15117 solver.cpp:233] Iteration 23250, loss = 0.0771745
I0526 04:41:04.437533 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0771746 (* 1 = 0.0771746 loss)
I0526 04:41:04.437541 15117 sgd_solver.cpp:294] Iteration 23250, lr = 0.02
I0526 04:41:10.771574 15117 solver.cpp:233] Iteration 23260, loss = 0.111813
I0526 04:41:10.771694 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.111813 (* 1 = 0.111813 loss)
I0526 04:41:10.771704 15117 sgd_solver.cpp:294] Iteration 23260, lr = 0.02
I0526 04:41:17.107858 15117 solver.cpp:233] Iteration 23270, loss = 0.133736
I0526 04:41:17.107897 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.133736 (* 1 = 0.133736 loss)
I0526 04:41:17.107905 15117 sgd_solver.cpp:294] Iteration 23270, lr = 0.02
I0526 04:41:23.447118 15117 solver.cpp:233] Iteration 23280, loss = 0.163759
I0526 04:41:23.447156 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.163759 (* 1 = 0.163759 loss)
I0526 04:41:23.447163 15117 sgd_solver.cpp:294] Iteration 23280, lr = 0.02
I0526 04:41:29.784474 15117 solver.cpp:233] Iteration 23290, loss = 0.177026
I0526 04:41:29.784520 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.177026 (* 1 = 0.177026 loss)
I0526 04:41:29.784528 15117 sgd_solver.cpp:294] Iteration 23290, lr = 0.02
I0526 04:41:35.517035 15117 solver.cpp:342] Iteration 23300, Testing net (#0)
I0526 04:41:48.356837 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.822
I0526 04:41:48.357070 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.684772 (* 1 = 0.684772 loss)
I0526 04:41:48.956540 15117 solver.cpp:233] Iteration 23300, loss = 0.103291
I0526 04:41:48.956589 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.103291 (* 1 = 0.103291 loss)
I0526 04:41:48.956598 15117 sgd_solver.cpp:294] Iteration 23300, lr = 0.02
I0526 04:41:55.288264 15117 solver.cpp:233] Iteration 23310, loss = 0.102935
I0526 04:41:55.288303 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.102935 (* 1 = 0.102935 loss)
I0526 04:41:55.288311 15117 sgd_solver.cpp:294] Iteration 23310, lr = 0.02
I0526 04:42:01.619550 15117 solver.cpp:233] Iteration 23320, loss = 0.19153
I0526 04:42:01.619592 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.191531 (* 1 = 0.191531 loss)
I0526 04:42:01.619601 15117 sgd_solver.cpp:294] Iteration 23320, lr = 0.02
I0526 04:42:07.952797 15117 solver.cpp:233] Iteration 23330, loss = 0.16206
I0526 04:42:07.952836 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.16206 (* 1 = 0.16206 loss)
I0526 04:42:07.952841 15117 sgd_solver.cpp:294] Iteration 23330, lr = 0.02
I0526 04:42:14.291117 15117 solver.cpp:233] Iteration 23340, loss = 0.0532682
I0526 04:42:14.291160 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0532684 (* 1 = 0.0532684 loss)
I0526 04:42:14.291168 15117 sgd_solver.cpp:294] Iteration 23340, lr = 0.02
I0526 04:42:20.628366 15117 solver.cpp:233] Iteration 23350, loss = 0.129698
I0526 04:42:20.628638 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.129698 (* 1 = 0.129698 loss)
I0526 04:42:20.628666 15117 sgd_solver.cpp:294] Iteration 23350, lr = 0.02
I0526 04:42:26.963904 15117 solver.cpp:233] Iteration 23360, loss = 0.0720732
I0526 04:42:26.963948 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0720733 (* 1 = 0.0720733 loss)
I0526 04:42:26.963954 15117 sgd_solver.cpp:294] Iteration 23360, lr = 0.02
I0526 04:42:33.301178 15117 solver.cpp:233] Iteration 23370, loss = 0.152749
I0526 04:42:33.301221 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.152749 (* 1 = 0.152749 loss)
I0526 04:42:33.301228 15117 sgd_solver.cpp:294] Iteration 23370, lr = 0.02
I0526 04:42:39.640905 15117 solver.cpp:233] Iteration 23380, loss = 0.0821728
I0526 04:42:39.640950 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0821729 (* 1 = 0.0821729 loss)
I0526 04:42:39.640957 15117 sgd_solver.cpp:294] Iteration 23380, lr = 0.02
I0526 04:42:45.980007 15117 solver.cpp:233] Iteration 23390, loss = 0.165694
I0526 04:42:45.980051 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.165694 (* 1 = 0.165694 loss)
I0526 04:42:45.980059 15117 sgd_solver.cpp:294] Iteration 23390, lr = 0.02
I0526 04:42:51.713495 15117 solver.cpp:342] Iteration 23400, Testing net (#0)
I0526 04:43:04.560099 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8327
I0526 04:43:04.560137 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.662275 (* 1 = 0.662275 loss)
I0526 04:43:05.161887 15117 solver.cpp:233] Iteration 23400, loss = 0.205282
I0526 04:43:05.161926 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.205282 (* 1 = 0.205282 loss)
I0526 04:43:05.161932 15117 sgd_solver.cpp:294] Iteration 23400, lr = 0.02
I0526 04:43:11.496742 15117 solver.cpp:233] Iteration 23410, loss = 0.170924
I0526 04:43:11.496781 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.170924 (* 1 = 0.170924 loss)
I0526 04:43:11.496788 15117 sgd_solver.cpp:294] Iteration 23410, lr = 0.02
I0526 04:43:17.836576 15117 solver.cpp:233] Iteration 23420, loss = 0.14144
I0526 04:43:17.836616 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.14144 (* 1 = 0.14144 loss)
I0526 04:43:17.836622 15117 sgd_solver.cpp:294] Iteration 23420, lr = 0.02
I0526 04:43:24.175487 15117 solver.cpp:233] Iteration 23430, loss = 0.0887297
I0526 04:43:24.175714 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0887298 (* 1 = 0.0887298 loss)
I0526 04:43:24.175740 15117 sgd_solver.cpp:294] Iteration 23430, lr = 0.02
I0526 04:43:30.516660 15117 solver.cpp:233] Iteration 23440, loss = 0.09093
I0526 04:43:30.516688 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0909301 (* 1 = 0.0909301 loss)
I0526 04:43:30.516695 15117 sgd_solver.cpp:294] Iteration 23440, lr = 0.02
I0526 04:43:36.854770 15117 solver.cpp:233] Iteration 23450, loss = 0.0465759
I0526 04:43:36.854828 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0465761 (* 1 = 0.0465761 loss)
I0526 04:43:36.854836 15117 sgd_solver.cpp:294] Iteration 23450, lr = 0.02
I0526 04:43:43.191911 15117 solver.cpp:233] Iteration 23460, loss = 0.0860797
I0526 04:43:43.191956 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0860798 (* 1 = 0.0860798 loss)
I0526 04:43:43.191964 15117 sgd_solver.cpp:294] Iteration 23460, lr = 0.02
I0526 04:43:49.527775 15117 solver.cpp:233] Iteration 23470, loss = 0.197004
I0526 04:43:49.527813 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.197004 (* 1 = 0.197004 loss)
I0526 04:43:49.527820 15117 sgd_solver.cpp:294] Iteration 23470, lr = 0.02
I0526 04:43:55.865471 15117 solver.cpp:233] Iteration 23480, loss = 0.126119
I0526 04:43:55.865746 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.126119 (* 1 = 0.126119 loss)
I0526 04:43:55.865773 15117 sgd_solver.cpp:294] Iteration 23480, lr = 0.02
I0526 04:44:02.195765 15117 solver.cpp:233] Iteration 23490, loss = 0.173378
I0526 04:44:02.195812 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.173378 (* 1 = 0.173378 loss)
I0526 04:44:02.195821 15117 sgd_solver.cpp:294] Iteration 23490, lr = 0.02
I0526 04:44:07.928990 15117 solver.cpp:342] Iteration 23500, Testing net (#0)
I0526 04:44:20.767393 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.805
I0526 04:44:20.767437 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.800453 (* 1 = 0.800453 loss)
I0526 04:44:21.369719 15117 solver.cpp:233] Iteration 23500, loss = 0.0875042
I0526 04:44:21.369752 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0875043 (* 1 = 0.0875043 loss)
I0526 04:44:21.369760 15117 sgd_solver.cpp:294] Iteration 23500, lr = 0.02
I0526 04:44:27.704046 15117 solver.cpp:233] Iteration 23510, loss = 0.111382
I0526 04:44:27.704267 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.111382 (* 1 = 0.111382 loss)
I0526 04:44:27.704295 15117 sgd_solver.cpp:294] Iteration 23510, lr = 0.02
I0526 04:44:34.036499 15117 solver.cpp:233] Iteration 23520, loss = 0.140597
I0526 04:44:34.036541 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.140597 (* 1 = 0.140597 loss)
I0526 04:44:34.036548 15117 sgd_solver.cpp:294] Iteration 23520, lr = 0.02
I0526 04:44:40.374555 15117 solver.cpp:233] Iteration 23530, loss = 0.0490051
I0526 04:44:40.374594 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0490052 (* 1 = 0.0490052 loss)
I0526 04:44:40.374601 15117 sgd_solver.cpp:294] Iteration 23530, lr = 0.02
I0526 04:44:46.713116 15117 solver.cpp:233] Iteration 23540, loss = 0.0785148
I0526 04:44:46.713150 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0785149 (* 1 = 0.0785149 loss)
I0526 04:44:46.713157 15117 sgd_solver.cpp:294] Iteration 23540, lr = 0.02
I0526 04:44:53.049043 15117 solver.cpp:233] Iteration 23550, loss = 0.124856
I0526 04:44:53.049083 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.124856 (* 1 = 0.124856 loss)
I0526 04:44:53.049090 15117 sgd_solver.cpp:294] Iteration 23550, lr = 0.02
I0526 04:44:59.385207 15117 solver.cpp:233] Iteration 23560, loss = 0.0807508
I0526 04:44:59.385442 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0807509 (* 1 = 0.0807509 loss)
I0526 04:44:59.385470 15117 sgd_solver.cpp:294] Iteration 23560, lr = 0.02
I0526 04:45:05.725071 15117 solver.cpp:233] Iteration 23570, loss = 0.110816
I0526 04:45:05.725114 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.110816 (* 1 = 0.110816 loss)
I0526 04:45:05.725121 15117 sgd_solver.cpp:294] Iteration 23570, lr = 0.02
I0526 04:45:12.058796 15117 solver.cpp:233] Iteration 23580, loss = 0.169184
I0526 04:45:12.058836 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.169184 (* 1 = 0.169184 loss)
I0526 04:45:12.058843 15117 sgd_solver.cpp:294] Iteration 23580, lr = 0.02
I0526 04:45:18.398947 15117 solver.cpp:233] Iteration 23590, loss = 0.103159
I0526 04:45:18.398990 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.103159 (* 1 = 0.103159 loss)
I0526 04:45:18.398998 15117 sgd_solver.cpp:294] Iteration 23590, lr = 0.02
I0526 04:45:24.133329 15117 solver.cpp:342] Iteration 23600, Testing net (#0)
I0526 04:45:36.981675 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7636
I0526 04:45:36.981937 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.06465 (* 1 = 1.06465 loss)
I0526 04:45:37.579629 15117 solver.cpp:233] Iteration 23600, loss = 0.0529668
I0526 04:45:37.579670 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0529669 (* 1 = 0.0529669 loss)
I0526 04:45:37.579679 15117 sgd_solver.cpp:294] Iteration 23600, lr = 0.02
I0526 04:45:43.912199 15117 solver.cpp:233] Iteration 23610, loss = 0.114766
I0526 04:45:43.912231 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.114766 (* 1 = 0.114766 loss)
I0526 04:45:43.912238 15117 sgd_solver.cpp:294] Iteration 23610, lr = 0.02
I0526 04:45:50.245224 15117 solver.cpp:233] Iteration 23620, loss = 0.134172
I0526 04:45:50.245262 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.134172 (* 1 = 0.134172 loss)
I0526 04:45:50.245270 15117 sgd_solver.cpp:294] Iteration 23620, lr = 0.02
I0526 04:45:56.584908 15117 solver.cpp:233] Iteration 23630, loss = 0.128376
I0526 04:45:56.584949 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.128377 (* 1 = 0.128377 loss)
I0526 04:45:56.584955 15117 sgd_solver.cpp:294] Iteration 23630, lr = 0.02
I0526 04:46:02.922358 15117 solver.cpp:233] Iteration 23640, loss = 0.106191
I0526 04:46:02.922415 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.106191 (* 1 = 0.106191 loss)
I0526 04:46:02.922421 15117 sgd_solver.cpp:294] Iteration 23640, lr = 0.02
I0526 04:46:09.261570 15117 solver.cpp:233] Iteration 23650, loss = 0.11608
I0526 04:46:09.261804 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.116081 (* 1 = 0.116081 loss)
I0526 04:46:09.261831 15117 sgd_solver.cpp:294] Iteration 23650, lr = 0.02
I0526 04:46:15.596807 15117 solver.cpp:233] Iteration 23660, loss = 0.0895693
I0526 04:46:15.596863 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0895694 (* 1 = 0.0895694 loss)
I0526 04:46:15.596870 15117 sgd_solver.cpp:294] Iteration 23660, lr = 0.02
I0526 04:46:21.930857 15117 solver.cpp:233] Iteration 23670, loss = 0.100069
I0526 04:46:21.930896 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.100069 (* 1 = 0.100069 loss)
I0526 04:46:21.930903 15117 sgd_solver.cpp:294] Iteration 23670, lr = 0.02
I0526 04:46:28.267576 15117 solver.cpp:233] Iteration 23680, loss = 0.0742555
I0526 04:46:28.267617 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0742556 (* 1 = 0.0742556 loss)
I0526 04:46:28.267626 15117 sgd_solver.cpp:294] Iteration 23680, lr = 0.02
I0526 04:46:34.599032 15117 solver.cpp:233] Iteration 23690, loss = 0.0840772
I0526 04:46:34.599076 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0840772 (* 1 = 0.0840772 loss)
I0526 04:46:34.599083 15117 sgd_solver.cpp:294] Iteration 23690, lr = 0.02
I0526 04:46:40.332509 15117 solver.cpp:342] Iteration 23700, Testing net (#0)
I0526 04:46:53.176055 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7512
I0526 04:46:53.176101 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.11074 (* 1 = 1.11074 loss)
I0526 04:46:53.777745 15117 solver.cpp:233] Iteration 23700, loss = 0.106877
I0526 04:46:53.777766 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.106877 (* 1 = 0.106877 loss)
I0526 04:46:53.777773 15117 sgd_solver.cpp:294] Iteration 23700, lr = 0.02
I0526 04:47:00.116283 15117 solver.cpp:233] Iteration 23710, loss = 0.150755
I0526 04:47:00.116328 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.150755 (* 1 = 0.150755 loss)
I0526 04:47:00.116335 15117 sgd_solver.cpp:294] Iteration 23710, lr = 0.02
I0526 04:47:06.454291 15117 solver.cpp:233] Iteration 23720, loss = 0.086981
I0526 04:47:06.454329 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0869811 (* 1 = 0.0869811 loss)
I0526 04:47:06.454335 15117 sgd_solver.cpp:294] Iteration 23720, lr = 0.02
I0526 04:47:12.790475 15117 solver.cpp:233] Iteration 23730, loss = 0.0627811
I0526 04:47:12.790755 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0627812 (* 1 = 0.0627812 loss)
I0526 04:47:12.790784 15117 sgd_solver.cpp:294] Iteration 23730, lr = 0.02
I0526 04:47:19.125370 15117 solver.cpp:233] Iteration 23740, loss = 0.0974656
I0526 04:47:19.125411 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0974657 (* 1 = 0.0974657 loss)
I0526 04:47:19.125418 15117 sgd_solver.cpp:294] Iteration 23740, lr = 0.02
I0526 04:47:25.463439 15117 solver.cpp:233] Iteration 23750, loss = 0.0637505
I0526 04:47:25.463477 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0637506 (* 1 = 0.0637506 loss)
I0526 04:47:25.463485 15117 sgd_solver.cpp:294] Iteration 23750, lr = 0.02
I0526 04:47:31.799027 15117 solver.cpp:233] Iteration 23760, loss = 0.161761
I0526 04:47:31.799069 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.161762 (* 1 = 0.161762 loss)
I0526 04:47:31.799077 15117 sgd_solver.cpp:294] Iteration 23760, lr = 0.02
I0526 04:47:38.132572 15117 solver.cpp:233] Iteration 23770, loss = 0.0977133
I0526 04:47:38.132614 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0977134 (* 1 = 0.0977134 loss)
I0526 04:47:38.132622 15117 sgd_solver.cpp:294] Iteration 23770, lr = 0.02
I0526 04:47:44.471401 15117 solver.cpp:233] Iteration 23780, loss = 0.16595
I0526 04:47:44.471626 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.16595 (* 1 = 0.16595 loss)
I0526 04:47:44.471654 15117 sgd_solver.cpp:294] Iteration 23780, lr = 0.02
I0526 04:47:50.801156 15117 solver.cpp:233] Iteration 23790, loss = 0.208803
I0526 04:47:50.801200 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.208803 (* 1 = 0.208803 loss)
I0526 04:47:50.801208 15117 sgd_solver.cpp:294] Iteration 23790, lr = 0.02
I0526 04:47:56.535267 15117 solver.cpp:342] Iteration 23800, Testing net (#0)
I0526 04:48:09.374220 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8097
I0526 04:48:09.374267 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.808685 (* 1 = 0.808685 loss)
I0526 04:48:09.975332 15117 solver.cpp:233] Iteration 23800, loss = 0.299199
I0526 04:48:09.975370 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.299199 (* 1 = 0.299199 loss)
I0526 04:48:09.975376 15117 sgd_solver.cpp:294] Iteration 23800, lr = 0.02
I0526 04:48:16.311250 15117 solver.cpp:233] Iteration 23810, loss = 0.118299
I0526 04:48:16.311473 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.118299 (* 1 = 0.118299 loss)
I0526 04:48:16.311501 15117 sgd_solver.cpp:294] Iteration 23810, lr = 0.02
I0526 04:48:22.643647 15117 solver.cpp:233] Iteration 23820, loss = 0.058976
I0526 04:48:22.643688 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0589761 (* 1 = 0.0589761 loss)
I0526 04:48:22.643695 15117 sgd_solver.cpp:294] Iteration 23820, lr = 0.02
I0526 04:48:28.981793 15117 solver.cpp:233] Iteration 23830, loss = 0.0991004
I0526 04:48:28.981837 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0991004 (* 1 = 0.0991004 loss)
I0526 04:48:28.981844 15117 sgd_solver.cpp:294] Iteration 23830, lr = 0.02
I0526 04:48:35.320000 15117 solver.cpp:233] Iteration 23840, loss = 0.144049
I0526 04:48:35.320036 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.144049 (* 1 = 0.144049 loss)
I0526 04:48:35.320053 15117 sgd_solver.cpp:294] Iteration 23840, lr = 0.02
I0526 04:48:41.657553 15117 solver.cpp:233] Iteration 23850, loss = 0.112944
I0526 04:48:41.657595 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.112944 (* 1 = 0.112944 loss)
I0526 04:48:41.657603 15117 sgd_solver.cpp:294] Iteration 23850, lr = 0.02
I0526 04:48:47.995105 15117 solver.cpp:233] Iteration 23860, loss = 0.214952
I0526 04:48:47.995327 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.214952 (* 1 = 0.214952 loss)
I0526 04:48:47.995355 15117 sgd_solver.cpp:294] Iteration 23860, lr = 0.02
I0526 04:48:54.331406 15117 solver.cpp:233] Iteration 23870, loss = 0.130226
I0526 04:48:54.331468 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.130226 (* 1 = 0.130226 loss)
I0526 04:48:54.331477 15117 sgd_solver.cpp:294] Iteration 23870, lr = 0.02
I0526 04:49:00.668805 15117 solver.cpp:233] Iteration 23880, loss = 0.1468
I0526 04:49:00.668849 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.1468 (* 1 = 0.1468 loss)
I0526 04:49:00.668869 15117 sgd_solver.cpp:294] Iteration 23880, lr = 0.02
I0526 04:49:07.009668 15117 solver.cpp:233] Iteration 23890, loss = 0.209943
I0526 04:49:07.009707 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.209943 (* 1 = 0.209943 loss)
I0526 04:49:07.009714 15117 sgd_solver.cpp:294] Iteration 23890, lr = 0.02
I0526 04:49:12.740082 15117 solver.cpp:342] Iteration 23900, Testing net (#0)
I0526 04:49:25.583075 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.834
I0526 04:49:25.583338 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.635752 (* 1 = 0.635752 loss)
I0526 04:49:26.186542 15117 solver.cpp:233] Iteration 23900, loss = 0.194799
I0526 04:49:26.186573 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.194799 (* 1 = 0.194799 loss)
I0526 04:49:26.186579 15117 sgd_solver.cpp:294] Iteration 23900, lr = 0.02
I0526 04:49:32.518517 15117 solver.cpp:233] Iteration 23910, loss = 0.214615
I0526 04:49:32.518559 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.214615 (* 1 = 0.214615 loss)
I0526 04:49:32.518566 15117 sgd_solver.cpp:294] Iteration 23910, lr = 0.02
I0526 04:49:38.854899 15117 solver.cpp:233] Iteration 23920, loss = 0.111145
I0526 04:49:38.854938 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.111145 (* 1 = 0.111145 loss)
I0526 04:49:38.854945 15117 sgd_solver.cpp:294] Iteration 23920, lr = 0.02
I0526 04:49:45.191458 15117 solver.cpp:233] Iteration 23930, loss = 0.103088
I0526 04:49:45.191510 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.103088 (* 1 = 0.103088 loss)
I0526 04:49:45.191517 15117 sgd_solver.cpp:294] Iteration 23930, lr = 0.02
I0526 04:49:51.526576 15117 solver.cpp:233] Iteration 23940, loss = 0.126854
I0526 04:49:51.526605 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.126854 (* 1 = 0.126854 loss)
I0526 04:49:51.526613 15117 sgd_solver.cpp:294] Iteration 23940, lr = 0.02
I0526 04:49:57.864214 15117 solver.cpp:233] Iteration 23950, loss = 0.126741
I0526 04:49:57.864441 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.126741 (* 1 = 0.126741 loss)
I0526 04:49:57.864475 15117 sgd_solver.cpp:294] Iteration 23950, lr = 0.02
I0526 04:50:04.199259 15117 solver.cpp:233] Iteration 23960, loss = 0.100842
I0526 04:50:04.199303 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.100842 (* 1 = 0.100842 loss)
I0526 04:50:04.199311 15117 sgd_solver.cpp:294] Iteration 23960, lr = 0.02
I0526 04:50:10.534389 15117 solver.cpp:233] Iteration 23970, loss = 0.190983
I0526 04:50:10.534426 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.190983 (* 1 = 0.190983 loss)
I0526 04:50:10.534433 15117 sgd_solver.cpp:294] Iteration 23970, lr = 0.02
I0526 04:50:16.862880 15117 solver.cpp:233] Iteration 23980, loss = 0.19116
I0526 04:50:16.862922 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.191161 (* 1 = 0.191161 loss)
I0526 04:50:16.862929 15117 sgd_solver.cpp:294] Iteration 23980, lr = 0.02
I0526 04:50:23.198878 15117 solver.cpp:233] Iteration 23990, loss = 0.0668533
I0526 04:50:23.198918 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0668534 (* 1 = 0.0668534 loss)
I0526 04:50:23.198925 15117 sgd_solver.cpp:294] Iteration 23990, lr = 0.02
I0526 04:50:28.935997 15117 solver.cpp:342] Iteration 24000, Testing net (#0)
I0526 04:50:41.782089 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8151
I0526 04:50:41.782133 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.78471 (* 1 = 0.78471 loss)
I0526 04:50:42.384198 15117 solver.cpp:233] Iteration 24000, loss = 0.0661515
I0526 04:50:42.384235 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0661516 (* 1 = 0.0661516 loss)
I0526 04:50:42.384243 15117 sgd_solver.cpp:294] Iteration 24000, lr = 0.02
I0526 04:50:48.718498 15117 solver.cpp:233] Iteration 24010, loss = 0.0859555
I0526 04:50:48.718540 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0859556 (* 1 = 0.0859556 loss)
I0526 04:50:48.718549 15117 sgd_solver.cpp:294] Iteration 24010, lr = 0.02
I0526 04:50:55.054919 15117 solver.cpp:233] Iteration 24020, loss = 0.0965367
I0526 04:50:55.054970 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0965368 (* 1 = 0.0965368 loss)
I0526 04:50:55.054976 15117 sgd_solver.cpp:294] Iteration 24020, lr = 0.02
I0526 04:51:01.393344 15117 solver.cpp:233] Iteration 24030, loss = 0.100796
I0526 04:51:01.393514 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.100796 (* 1 = 0.100796 loss)
I0526 04:51:01.393524 15117 sgd_solver.cpp:294] Iteration 24030, lr = 0.02
I0526 04:51:07.727712 15117 solver.cpp:233] Iteration 24040, loss = 0.0805893
I0526 04:51:07.727751 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0805894 (* 1 = 0.0805894 loss)
I0526 04:51:07.727757 15117 sgd_solver.cpp:294] Iteration 24040, lr = 0.02
I0526 04:51:14.061158 15117 solver.cpp:233] Iteration 24050, loss = 0.123055
I0526 04:51:14.061205 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.123055 (* 1 = 0.123055 loss)
I0526 04:51:14.061213 15117 sgd_solver.cpp:294] Iteration 24050, lr = 0.02
I0526 04:51:20.397809 15117 solver.cpp:233] Iteration 24060, loss = 0.108928
I0526 04:51:20.397853 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.108928 (* 1 = 0.108928 loss)
I0526 04:51:20.397861 15117 sgd_solver.cpp:294] Iteration 24060, lr = 0.02
I0526 04:51:26.728996 15117 solver.cpp:233] Iteration 24070, loss = 0.0852343
I0526 04:51:26.729033 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0852345 (* 1 = 0.0852345 loss)
I0526 04:51:26.729041 15117 sgd_solver.cpp:294] Iteration 24070, lr = 0.02
I0526 04:51:33.064718 15117 solver.cpp:233] Iteration 24080, loss = 0.173624
I0526 04:51:33.064939 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.173625 (* 1 = 0.173625 loss)
I0526 04:51:33.064967 15117 sgd_solver.cpp:294] Iteration 24080, lr = 0.02
I0526 04:51:39.398530 15117 solver.cpp:233] Iteration 24090, loss = 0.155941
I0526 04:51:39.398593 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.155942 (* 1 = 0.155942 loss)
I0526 04:51:39.398602 15117 sgd_solver.cpp:294] Iteration 24090, lr = 0.02
I0526 04:51:45.131485 15117 solver.cpp:342] Iteration 24100, Testing net (#0)
I0526 04:51:57.975144 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8192
I0526 04:51:57.975184 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.744133 (* 1 = 0.744133 loss)
I0526 04:51:58.577575 15117 solver.cpp:233] Iteration 24100, loss = 0.136897
I0526 04:51:58.577627 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.136897 (* 1 = 0.136897 loss)
I0526 04:51:58.577635 15117 sgd_solver.cpp:294] Iteration 24100, lr = 0.02
I0526 04:52:04.911159 15117 solver.cpp:233] Iteration 24110, loss = 0.0872588
I0526 04:52:04.911384 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0872589 (* 1 = 0.0872589 loss)
I0526 04:52:04.911412 15117 sgd_solver.cpp:294] Iteration 24110, lr = 0.02
I0526 04:52:11.242624 15117 solver.cpp:233] Iteration 24120, loss = 0.163856
I0526 04:52:11.242667 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.163856 (* 1 = 0.163856 loss)
I0526 04:52:11.242676 15117 sgd_solver.cpp:294] Iteration 24120, lr = 0.02
I0526 04:52:17.580621 15117 solver.cpp:233] Iteration 24130, loss = 0.0756725
I0526 04:52:17.580663 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0756726 (* 1 = 0.0756726 loss)
I0526 04:52:17.580672 15117 sgd_solver.cpp:294] Iteration 24130, lr = 0.02
I0526 04:52:23.917810 15117 solver.cpp:233] Iteration 24140, loss = 0.16692
I0526 04:52:23.917866 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.166921 (* 1 = 0.166921 loss)
I0526 04:52:23.917875 15117 sgd_solver.cpp:294] Iteration 24140, lr = 0.02
I0526 04:52:30.250783 15117 solver.cpp:233] Iteration 24150, loss = 0.1117
I0526 04:52:30.250823 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.1117 (* 1 = 0.1117 loss)
I0526 04:52:30.250831 15117 sgd_solver.cpp:294] Iteration 24150, lr = 0.02
I0526 04:52:36.586789 15117 solver.cpp:233] Iteration 24160, loss = 0.182587
I0526 04:52:36.587051 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.182587 (* 1 = 0.182587 loss)
I0526 04:52:36.587085 15117 sgd_solver.cpp:294] Iteration 24160, lr = 0.02
I0526 04:52:42.923033 15117 solver.cpp:233] Iteration 24170, loss = 0.0860705
I0526 04:52:42.923074 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0860707 (* 1 = 0.0860707 loss)
I0526 04:52:42.923080 15117 sgd_solver.cpp:294] Iteration 24170, lr = 0.02
I0526 04:52:49.261431 15117 solver.cpp:233] Iteration 24180, loss = 0.0634881
I0526 04:52:49.261483 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0634882 (* 1 = 0.0634882 loss)
I0526 04:52:49.261490 15117 sgd_solver.cpp:294] Iteration 24180, lr = 0.02
I0526 04:52:55.597795 15117 solver.cpp:233] Iteration 24190, loss = 0.190042
I0526 04:52:55.597841 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.190042 (* 1 = 0.190042 loss)
I0526 04:52:55.597846 15117 sgd_solver.cpp:294] Iteration 24190, lr = 0.02
I0526 04:53:01.331851 15117 solver.cpp:342] Iteration 24200, Testing net (#0)
I0526 04:53:14.172338 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8368
I0526 04:53:14.172565 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.598073 (* 1 = 0.598073 loss)
I0526 04:53:14.773289 15117 solver.cpp:233] Iteration 24200, loss = 0.0999817
I0526 04:53:14.773339 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0999819 (* 1 = 0.0999819 loss)
I0526 04:53:14.773346 15117 sgd_solver.cpp:294] Iteration 24200, lr = 0.02
I0526 04:53:21.104209 15117 solver.cpp:233] Iteration 24210, loss = 0.030151
I0526 04:53:21.104245 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0301511 (* 1 = 0.0301511 loss)
I0526 04:53:21.104252 15117 sgd_solver.cpp:294] Iteration 24210, lr = 0.02
I0526 04:53:27.437271 15117 solver.cpp:233] Iteration 24220, loss = 0.149586
I0526 04:53:27.437312 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.149586 (* 1 = 0.149586 loss)
I0526 04:53:27.437319 15117 sgd_solver.cpp:294] Iteration 24220, lr = 0.02
I0526 04:53:33.776907 15117 solver.cpp:233] Iteration 24230, loss = 0.081286
I0526 04:53:33.776958 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0812862 (* 1 = 0.0812862 loss)
I0526 04:53:33.776965 15117 sgd_solver.cpp:294] Iteration 24230, lr = 0.02
I0526 04:53:40.116674 15117 solver.cpp:233] Iteration 24240, loss = 0.114309
I0526 04:53:40.116719 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.114309 (* 1 = 0.114309 loss)
I0526 04:53:40.116726 15117 sgd_solver.cpp:294] Iteration 24240, lr = 0.02
I0526 04:53:46.451776 15117 solver.cpp:233] Iteration 24250, loss = 0.0646917
I0526 04:53:46.452010 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0646918 (* 1 = 0.0646918 loss)
I0526 04:53:46.452039 15117 sgd_solver.cpp:294] Iteration 24250, lr = 0.02
I0526 04:53:52.786649 15117 solver.cpp:233] Iteration 24260, loss = 0.135697
I0526 04:53:52.786694 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.135697 (* 1 = 0.135697 loss)
I0526 04:53:52.786701 15117 sgd_solver.cpp:294] Iteration 24260, lr = 0.02
I0526 04:53:59.118597 15117 solver.cpp:233] Iteration 24270, loss = 0.0589264
I0526 04:53:59.118638 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0589265 (* 1 = 0.0589265 loss)
I0526 04:53:59.118646 15117 sgd_solver.cpp:294] Iteration 24270, lr = 0.02
I0526 04:54:05.455739 15117 solver.cpp:233] Iteration 24280, loss = 0.208737
I0526 04:54:05.455787 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.208737 (* 1 = 0.208737 loss)
I0526 04:54:05.455796 15117 sgd_solver.cpp:294] Iteration 24280, lr = 0.02
I0526 04:54:11.793565 15117 solver.cpp:233] Iteration 24290, loss = 0.194471
I0526 04:54:11.793612 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.194472 (* 1 = 0.194472 loss)
I0526 04:54:11.793620 15117 sgd_solver.cpp:294] Iteration 24290, lr = 0.02
I0526 04:54:17.529614 15117 solver.cpp:342] Iteration 24300, Testing net (#0)
I0526 04:54:30.364873 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7661
I0526 04:54:30.364929 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.03792 (* 1 = 1.03792 loss)
I0526 04:54:30.967001 15117 solver.cpp:233] Iteration 24300, loss = 0.134819
I0526 04:54:30.967036 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.134819 (* 1 = 0.134819 loss)
I0526 04:54:30.967043 15117 sgd_solver.cpp:294] Iteration 24300, lr = 0.02
I0526 04:54:37.305189 15117 solver.cpp:233] Iteration 24310, loss = 0.189392
I0526 04:54:37.305240 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.189392 (* 1 = 0.189392 loss)
I0526 04:54:37.305248 15117 sgd_solver.cpp:294] Iteration 24310, lr = 0.02
I0526 04:54:43.641790 15117 solver.cpp:233] Iteration 24320, loss = 0.134251
I0526 04:54:43.641834 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.134251 (* 1 = 0.134251 loss)
I0526 04:54:43.641841 15117 sgd_solver.cpp:294] Iteration 24320, lr = 0.02
I0526 04:54:49.978626 15117 solver.cpp:233] Iteration 24330, loss = 0.115225
I0526 04:54:49.978860 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.115225 (* 1 = 0.115225 loss)
I0526 04:54:49.978888 15117 sgd_solver.cpp:294] Iteration 24330, lr = 0.02
I0526 04:54:56.309085 15117 solver.cpp:233] Iteration 24340, loss = 0.134547
I0526 04:54:56.309126 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.134547 (* 1 = 0.134547 loss)
I0526 04:54:56.309134 15117 sgd_solver.cpp:294] Iteration 24340, lr = 0.02
I0526 04:55:02.645452 15117 solver.cpp:233] Iteration 24350, loss = 0.112737
I0526 04:55:02.645506 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.112737 (* 1 = 0.112737 loss)
I0526 04:55:02.645514 15117 sgd_solver.cpp:294] Iteration 24350, lr = 0.02
I0526 04:55:08.982424 15117 solver.cpp:233] Iteration 24360, loss = 0.0657603
I0526 04:55:08.982471 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0657605 (* 1 = 0.0657605 loss)
I0526 04:55:08.982480 15117 sgd_solver.cpp:294] Iteration 24360, lr = 0.02
I0526 04:55:15.320098 15117 solver.cpp:233] Iteration 24370, loss = 0.0939693
I0526 04:55:15.320142 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0939694 (* 1 = 0.0939694 loss)
I0526 04:55:15.320149 15117 sgd_solver.cpp:294] Iteration 24370, lr = 0.02
I0526 04:55:21.654902 15117 solver.cpp:233] Iteration 24380, loss = 0.191955
I0526 04:55:21.655115 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.191955 (* 1 = 0.191955 loss)
I0526 04:55:21.655151 15117 sgd_solver.cpp:294] Iteration 24380, lr = 0.02
I0526 04:55:27.990304 15117 solver.cpp:233] Iteration 24390, loss = 0.112631
I0526 04:55:27.990345 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.112631 (* 1 = 0.112631 loss)
I0526 04:55:27.990351 15117 sgd_solver.cpp:294] Iteration 24390, lr = 0.02
I0526 04:55:33.722903 15117 solver.cpp:342] Iteration 24400, Testing net (#0)
I0526 04:55:46.565084 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8067
I0526 04:55:46.565129 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.79822 (* 1 = 0.79822 loss)
I0526 04:55:47.166152 15117 solver.cpp:233] Iteration 24400, loss = 0.120675
I0526 04:55:47.166185 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.120675 (* 1 = 0.120675 loss)
I0526 04:55:47.166193 15117 sgd_solver.cpp:294] Iteration 24400, lr = 0.02
I0526 04:55:53.500169 15117 solver.cpp:233] Iteration 24410, loss = 0.184464
I0526 04:55:53.500466 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.184465 (* 1 = 0.184465 loss)
I0526 04:55:53.500500 15117 sgd_solver.cpp:294] Iteration 24410, lr = 0.02
I0526 04:55:59.837854 15117 solver.cpp:233] Iteration 24420, loss = 0.0757912
I0526 04:55:59.837904 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0757914 (* 1 = 0.0757914 loss)
I0526 04:55:59.837911 15117 sgd_solver.cpp:294] Iteration 24420, lr = 0.02
I0526 04:56:06.173092 15117 solver.cpp:233] Iteration 24430, loss = 0.135652
I0526 04:56:06.173144 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.135652 (* 1 = 0.135652 loss)
I0526 04:56:06.173152 15117 sgd_solver.cpp:294] Iteration 24430, lr = 0.02
I0526 04:56:12.512799 15117 solver.cpp:233] Iteration 24440, loss = 0.111463
I0526 04:56:12.512840 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.111463 (* 1 = 0.111463 loss)
I0526 04:56:12.512846 15117 sgd_solver.cpp:294] Iteration 24440, lr = 0.02
I0526 04:56:18.850074 15117 solver.cpp:233] Iteration 24450, loss = 0.120113
I0526 04:56:18.850119 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.120114 (* 1 = 0.120114 loss)
I0526 04:56:18.850126 15117 sgd_solver.cpp:294] Iteration 24450, lr = 0.02
I0526 04:56:25.181946 15117 solver.cpp:233] Iteration 24460, loss = 0.100241
I0526 04:56:25.182164 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.100241 (* 1 = 0.100241 loss)
I0526 04:56:25.182193 15117 sgd_solver.cpp:294] Iteration 24460, lr = 0.02
I0526 04:56:31.520253 15117 solver.cpp:233] Iteration 24470, loss = 0.155554
I0526 04:56:31.520308 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.155554 (* 1 = 0.155554 loss)
I0526 04:56:31.520314 15117 sgd_solver.cpp:294] Iteration 24470, lr = 0.02
I0526 04:56:37.854002 15117 solver.cpp:233] Iteration 24480, loss = 0.147359
I0526 04:56:37.854043 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.147359 (* 1 = 0.147359 loss)
I0526 04:56:37.854049 15117 sgd_solver.cpp:294] Iteration 24480, lr = 0.02
I0526 04:56:44.194442 15117 solver.cpp:233] Iteration 24490, loss = 0.134611
I0526 04:56:44.194478 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.134611 (* 1 = 0.134611 loss)
I0526 04:56:44.194484 15117 sgd_solver.cpp:294] Iteration 24490, lr = 0.02
I0526 04:56:49.931783 15117 solver.cpp:342] Iteration 24500, Testing net (#0)
I0526 04:57:02.775214 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8397
I0526 04:57:02.775435 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.729587 (* 1 = 0.729587 loss)
I0526 04:57:03.374496 15117 solver.cpp:233] Iteration 24500, loss = 0.0914118
I0526 04:57:03.374534 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0914119 (* 1 = 0.0914119 loss)
I0526 04:57:03.374543 15117 sgd_solver.cpp:294] Iteration 24500, lr = 0.02
I0526 04:57:09.712250 15117 solver.cpp:233] Iteration 24510, loss = 0.134027
I0526 04:57:09.712312 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.134027 (* 1 = 0.134027 loss)
I0526 04:57:09.712319 15117 sgd_solver.cpp:294] Iteration 24510, lr = 0.02
I0526 04:57:16.048002 15117 solver.cpp:233] Iteration 24520, loss = 0.129331
I0526 04:57:16.048039 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.129331 (* 1 = 0.129331 loss)
I0526 04:57:16.048046 15117 sgd_solver.cpp:294] Iteration 24520, lr = 0.02
I0526 04:57:22.387053 15117 solver.cpp:233] Iteration 24530, loss = 0.0993767
I0526 04:57:22.387095 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0993768 (* 1 = 0.0993768 loss)
I0526 04:57:22.387102 15117 sgd_solver.cpp:294] Iteration 24530, lr = 0.02
I0526 04:57:28.722462 15117 solver.cpp:233] Iteration 24540, loss = 0.0468233
I0526 04:57:28.722499 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0468235 (* 1 = 0.0468235 loss)
I0526 04:57:28.722506 15117 sgd_solver.cpp:294] Iteration 24540, lr = 0.02
I0526 04:57:35.060858 15117 solver.cpp:233] Iteration 24550, loss = 0.0941913
I0526 04:57:35.061138 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0941915 (* 1 = 0.0941915 loss)
I0526 04:57:35.061177 15117 sgd_solver.cpp:294] Iteration 24550, lr = 0.02
I0526 04:57:41.399142 15117 solver.cpp:233] Iteration 24560, loss = 0.148488
I0526 04:57:41.399183 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.148488 (* 1 = 0.148488 loss)
I0526 04:57:41.399202 15117 sgd_solver.cpp:294] Iteration 24560, lr = 0.02
I0526 04:57:47.733551 15117 solver.cpp:233] Iteration 24570, loss = 0.199295
I0526 04:57:47.733593 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.199295 (* 1 = 0.199295 loss)
I0526 04:57:47.733600 15117 sgd_solver.cpp:294] Iteration 24570, lr = 0.02
I0526 04:57:54.073364 15117 solver.cpp:233] Iteration 24580, loss = 0.140695
I0526 04:57:54.073405 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.140696 (* 1 = 0.140696 loss)
I0526 04:57:54.073411 15117 sgd_solver.cpp:294] Iteration 24580, lr = 0.02
I0526 04:58:00.411154 15117 solver.cpp:233] Iteration 24590, loss = 0.0633097
I0526 04:58:00.411186 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0633099 (* 1 = 0.0633099 loss)
I0526 04:58:00.411206 15117 sgd_solver.cpp:294] Iteration 24590, lr = 0.02
I0526 04:58:06.147083 15117 solver.cpp:342] Iteration 24600, Testing net (#0)
I0526 04:58:18.985626 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8339
I0526 04:58:18.985671 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.728964 (* 1 = 0.728964 loss)
I0526 04:58:19.586969 15117 solver.cpp:233] Iteration 24600, loss = 0.167903
I0526 04:58:19.587007 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.167903 (* 1 = 0.167903 loss)
I0526 04:58:19.587015 15117 sgd_solver.cpp:294] Iteration 24600, lr = 0.02
I0526 04:58:25.921816 15117 solver.cpp:233] Iteration 24610, loss = 0.0670549
I0526 04:58:25.921854 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0670551 (* 1 = 0.0670551 loss)
I0526 04:58:25.921861 15117 sgd_solver.cpp:294] Iteration 24610, lr = 0.02
I0526 04:58:32.257232 15117 solver.cpp:233] Iteration 24620, loss = 0.11179
I0526 04:58:32.257272 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.11179 (* 1 = 0.11179 loss)
I0526 04:58:32.257292 15117 sgd_solver.cpp:294] Iteration 24620, lr = 0.02
I0526 04:58:38.593336 15117 solver.cpp:233] Iteration 24630, loss = 0.081331
I0526 04:58:38.593566 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0813312 (* 1 = 0.0813312 loss)
I0526 04:58:38.593595 15117 sgd_solver.cpp:294] Iteration 24630, lr = 0.02
I0526 04:58:44.921236 15117 solver.cpp:233] Iteration 24640, loss = 0.0852137
I0526 04:58:44.921284 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0852139 (* 1 = 0.0852139 loss)
I0526 04:58:44.921293 15117 sgd_solver.cpp:294] Iteration 24640, lr = 0.02
I0526 04:58:51.257237 15117 solver.cpp:233] Iteration 24650, loss = 0.115378
I0526 04:58:51.257277 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.115378 (* 1 = 0.115378 loss)
I0526 04:58:51.257283 15117 sgd_solver.cpp:294] Iteration 24650, lr = 0.02
I0526 04:58:57.594003 15117 solver.cpp:233] Iteration 24660, loss = 0.0866489
I0526 04:58:57.594046 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0866491 (* 1 = 0.0866491 loss)
I0526 04:58:57.594053 15117 sgd_solver.cpp:294] Iteration 24660, lr = 0.02
I0526 04:59:03.933820 15117 solver.cpp:233] Iteration 24670, loss = 0.1176
I0526 04:59:03.933876 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.1176 (* 1 = 0.1176 loss)
I0526 04:59:03.933881 15117 sgd_solver.cpp:294] Iteration 24670, lr = 0.02
I0526 04:59:10.271420 15117 solver.cpp:233] Iteration 24680, loss = 0.116748
I0526 04:59:10.271638 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.116749 (* 1 = 0.116749 loss)
I0526 04:59:10.271673 15117 sgd_solver.cpp:294] Iteration 24680, lr = 0.02
I0526 04:59:16.606184 15117 solver.cpp:233] Iteration 24690, loss = 0.111894
I0526 04:59:16.606231 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.111894 (* 1 = 0.111894 loss)
I0526 04:59:16.606240 15117 sgd_solver.cpp:294] Iteration 24690, lr = 0.02
I0526 04:59:22.341064 15117 solver.cpp:342] Iteration 24700, Testing net (#0)
I0526 04:59:35.182757 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8298
I0526 04:59:35.182801 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.724177 (* 1 = 0.724177 loss)
I0526 04:59:35.785092 15117 solver.cpp:233] Iteration 24700, loss = 0.0666238
I0526 04:59:35.785136 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.066624 (* 1 = 0.066624 loss)
I0526 04:59:35.785143 15117 sgd_solver.cpp:294] Iteration 24700, lr = 0.02
I0526 04:59:42.121934 15117 solver.cpp:233] Iteration 24710, loss = 0.0674453
I0526 04:59:42.122212 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0674455 (* 1 = 0.0674455 loss)
I0526 04:59:42.122241 15117 sgd_solver.cpp:294] Iteration 24710, lr = 0.02
I0526 04:59:48.457808 15117 solver.cpp:233] Iteration 24720, loss = 0.163671
I0526 04:59:48.457849 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.163671 (* 1 = 0.163671 loss)
I0526 04:59:48.457856 15117 sgd_solver.cpp:294] Iteration 24720, lr = 0.02
I0526 04:59:54.793732 15117 solver.cpp:233] Iteration 24730, loss = 0.112367
I0526 04:59:54.793773 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.112367 (* 1 = 0.112367 loss)
I0526 04:59:54.793781 15117 sgd_solver.cpp:294] Iteration 24730, lr = 0.02
I0526 05:00:01.133462 15117 solver.cpp:233] Iteration 24740, loss = 0.159234
I0526 05:00:01.133502 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.159234 (* 1 = 0.159234 loss)
I0526 05:00:01.133509 15117 sgd_solver.cpp:294] Iteration 24740, lr = 0.02
I0526 05:00:07.466747 15117 solver.cpp:233] Iteration 24750, loss = 0.0946261
I0526 05:00:07.466805 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0946263 (* 1 = 0.0946263 loss)
I0526 05:00:07.466814 15117 sgd_solver.cpp:294] Iteration 24750, lr = 0.02
I0526 05:00:13.804141 15117 solver.cpp:233] Iteration 24760, loss = 0.0909717
I0526 05:00:13.804364 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0909719 (* 1 = 0.0909719 loss)
I0526 05:00:13.804394 15117 sgd_solver.cpp:294] Iteration 24760, lr = 0.02
I0526 05:00:20.145205 15117 solver.cpp:233] Iteration 24770, loss = 0.0821448
I0526 05:00:20.145244 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.082145 (* 1 = 0.082145 loss)
I0526 05:00:20.145251 15117 sgd_solver.cpp:294] Iteration 24770, lr = 0.02
I0526 05:00:26.478997 15117 solver.cpp:233] Iteration 24780, loss = 0.0739768
I0526 05:00:26.479038 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0739769 (* 1 = 0.0739769 loss)
I0526 05:00:26.479045 15117 sgd_solver.cpp:294] Iteration 24780, lr = 0.02
I0526 05:00:32.810168 15117 solver.cpp:233] Iteration 24790, loss = 0.11453
I0526 05:00:32.810209 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.11453 (* 1 = 0.11453 loss)
I0526 05:00:32.810216 15117 sgd_solver.cpp:294] Iteration 24790, lr = 0.02
I0526 05:00:38.540838 15117 solver.cpp:342] Iteration 24800, Testing net (#0)
I0526 05:00:51.383934 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8239
I0526 05:00:51.384162 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.727946 (* 1 = 0.727946 loss)
I0526 05:00:51.981202 15117 solver.cpp:233] Iteration 24800, loss = 0.188928
I0526 05:00:51.981256 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.188928 (* 1 = 0.188928 loss)
I0526 05:00:51.981266 15117 sgd_solver.cpp:294] Iteration 24800, lr = 0.02
I0526 05:00:58.309486 15117 solver.cpp:233] Iteration 24810, loss = 0.122967
I0526 05:00:58.309527 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.122967 (* 1 = 0.122967 loss)
I0526 05:00:58.309535 15117 sgd_solver.cpp:294] Iteration 24810, lr = 0.02
I0526 05:01:04.645973 15117 solver.cpp:233] Iteration 24820, loss = 0.173871
I0526 05:01:04.646015 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.173872 (* 1 = 0.173872 loss)
I0526 05:01:04.646023 15117 sgd_solver.cpp:294] Iteration 24820, lr = 0.02
I0526 05:01:10.980360 15117 solver.cpp:233] Iteration 24830, loss = 0.220531
I0526 05:01:10.980414 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.220531 (* 1 = 0.220531 loss)
I0526 05:01:10.980422 15117 sgd_solver.cpp:294] Iteration 24830, lr = 0.02
I0526 05:01:17.315748 15117 solver.cpp:233] Iteration 24840, loss = 0.138054
I0526 05:01:17.315786 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.138054 (* 1 = 0.138054 loss)
I0526 05:01:17.315793 15117 sgd_solver.cpp:294] Iteration 24840, lr = 0.02
I0526 05:01:23.653424 15117 solver.cpp:233] Iteration 24850, loss = 0.142197
I0526 05:01:23.653692 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.142197 (* 1 = 0.142197 loss)
I0526 05:01:23.653719 15117 sgd_solver.cpp:294] Iteration 24850, lr = 0.02
I0526 05:01:29.991683 15117 solver.cpp:233] Iteration 24860, loss = 0.0609573
I0526 05:01:29.991730 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0609574 (* 1 = 0.0609574 loss)
I0526 05:01:29.991737 15117 sgd_solver.cpp:294] Iteration 24860, lr = 0.02
I0526 05:01:36.330135 15117 solver.cpp:233] Iteration 24870, loss = 0.144984
I0526 05:01:36.330174 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.144984 (* 1 = 0.144984 loss)
I0526 05:01:36.330180 15117 sgd_solver.cpp:294] Iteration 24870, lr = 0.02
I0526 05:01:42.666924 15117 solver.cpp:233] Iteration 24880, loss = 0.0952154
I0526 05:01:42.666966 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0952156 (* 1 = 0.0952156 loss)
I0526 05:01:42.666972 15117 sgd_solver.cpp:294] Iteration 24880, lr = 0.02
I0526 05:01:49.002050 15117 solver.cpp:233] Iteration 24890, loss = 0.12957
I0526 05:01:49.002089 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.129571 (* 1 = 0.129571 loss)
I0526 05:01:49.002097 15117 sgd_solver.cpp:294] Iteration 24890, lr = 0.02
I0526 05:01:54.736399 15117 solver.cpp:342] Iteration 24900, Testing net (#0)
I0526 05:02:07.577869 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8024
I0526 05:02:07.577908 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.962201 (* 1 = 0.962201 loss)
I0526 05:02:08.179111 15117 solver.cpp:233] Iteration 24900, loss = 0.062264
I0526 05:02:08.179154 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0622641 (* 1 = 0.0622641 loss)
I0526 05:02:08.179162 15117 sgd_solver.cpp:294] Iteration 24900, lr = 0.02
I0526 05:02:14.517362 15117 solver.cpp:233] Iteration 24910, loss = 0.161792
I0526 05:02:14.517390 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.161792 (* 1 = 0.161792 loss)
I0526 05:02:14.517398 15117 sgd_solver.cpp:294] Iteration 24910, lr = 0.02
I0526 05:02:20.853576 15117 solver.cpp:233] Iteration 24920, loss = 0.179258
I0526 05:02:20.853616 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.179258 (* 1 = 0.179258 loss)
I0526 05:02:20.853623 15117 sgd_solver.cpp:294] Iteration 24920, lr = 0.02
I0526 05:02:27.187641 15117 solver.cpp:233] Iteration 24930, loss = 0.116654
I0526 05:02:27.187896 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.116654 (* 1 = 0.116654 loss)
I0526 05:02:27.187923 15117 sgd_solver.cpp:294] Iteration 24930, lr = 0.02
I0526 05:02:33.524231 15117 solver.cpp:233] Iteration 24940, loss = 0.1022
I0526 05:02:33.524271 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.1022 (* 1 = 0.1022 loss)
I0526 05:02:33.524278 15117 sgd_solver.cpp:294] Iteration 24940, lr = 0.02
I0526 05:02:39.858907 15117 solver.cpp:233] Iteration 24950, loss = 0.0566084
I0526 05:02:39.858947 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0566085 (* 1 = 0.0566085 loss)
I0526 05:02:39.858953 15117 sgd_solver.cpp:294] Iteration 24950, lr = 0.02
I0526 05:02:46.194900 15117 solver.cpp:233] Iteration 24960, loss = 0.113021
I0526 05:02:46.194942 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.113021 (* 1 = 0.113021 loss)
I0526 05:02:46.194950 15117 sgd_solver.cpp:294] Iteration 24960, lr = 0.02
I0526 05:02:52.534709 15117 solver.cpp:233] Iteration 24970, loss = 0.145744
I0526 05:02:52.534759 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.145744 (* 1 = 0.145744 loss)
I0526 05:02:52.534765 15117 sgd_solver.cpp:294] Iteration 24970, lr = 0.02
I0526 05:02:58.872305 15117 solver.cpp:233] Iteration 24980, loss = 0.101119
I0526 05:02:58.872560 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.101119 (* 1 = 0.101119 loss)
I0526 05:02:58.872593 15117 sgd_solver.cpp:294] Iteration 24980, lr = 0.02
I0526 05:03:05.208325 15117 solver.cpp:233] Iteration 24990, loss = 0.123336
I0526 05:03:05.208367 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.123337 (* 1 = 0.123337 loss)
I0526 05:03:05.208375 15117 sgd_solver.cpp:294] Iteration 24990, lr = 0.02
I0526 05:03:10.945726 15117 solver.cpp:342] Iteration 25000, Testing net (#0)
I0526 05:03:23.787781 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7961
I0526 05:03:23.787827 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.07772 (* 1 = 1.07772 loss)
I0526 05:03:24.389367 15117 solver.cpp:233] Iteration 25000, loss = 0.0825657
I0526 05:03:24.389403 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0825659 (* 1 = 0.0825659 loss)
I0526 05:03:24.389410 15117 sgd_solver.cpp:294] Iteration 25000, lr = 0.02
I0526 05:03:30.723757 15117 solver.cpp:233] Iteration 25010, loss = 0.200185
I0526 05:03:30.723978 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.200185 (* 1 = 0.200185 loss)
I0526 05:03:30.724009 15117 sgd_solver.cpp:294] Iteration 25010, lr = 0.02
I0526 05:03:37.053601 15117 solver.cpp:233] Iteration 25020, loss = 0.0335412
I0526 05:03:37.053645 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0335413 (* 1 = 0.0335413 loss)
I0526 05:03:37.053654 15117 sgd_solver.cpp:294] Iteration 25020, lr = 0.02
I0526 05:03:43.389539 15117 solver.cpp:233] Iteration 25030, loss = 0.0596123
I0526 05:03:43.389578 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0596124 (* 1 = 0.0596124 loss)
I0526 05:03:43.389586 15117 sgd_solver.cpp:294] Iteration 25030, lr = 0.02
I0526 05:03:49.719666 15117 solver.cpp:233] Iteration 25040, loss = 0.0829519
I0526 05:03:49.719702 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.082952 (* 1 = 0.082952 loss)
I0526 05:03:49.719709 15117 sgd_solver.cpp:294] Iteration 25040, lr = 0.02
I0526 05:03:56.056534 15117 solver.cpp:233] Iteration 25050, loss = 0.124633
I0526 05:03:56.056574 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.124633 (* 1 = 0.124633 loss)
I0526 05:03:56.056581 15117 sgd_solver.cpp:294] Iteration 25050, lr = 0.02
I0526 05:04:02.394152 15117 solver.cpp:233] Iteration 25060, loss = 0.0566684
I0526 05:04:02.394398 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0566685 (* 1 = 0.0566685 loss)
I0526 05:04:02.394424 15117 sgd_solver.cpp:294] Iteration 25060, lr = 0.02
I0526 05:04:08.729084 15117 solver.cpp:233] Iteration 25070, loss = 0.0918107
I0526 05:04:08.729135 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0918108 (* 1 = 0.0918108 loss)
I0526 05:04:08.729142 15117 sgd_solver.cpp:294] Iteration 25070, lr = 0.02
I0526 05:04:15.065165 15117 solver.cpp:233] Iteration 25080, loss = 0.0965093
I0526 05:04:15.065207 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0965094 (* 1 = 0.0965094 loss)
I0526 05:04:15.065213 15117 sgd_solver.cpp:294] Iteration 25080, lr = 0.02
I0526 05:04:21.404119 15117 solver.cpp:233] Iteration 25090, loss = 0.124065
I0526 05:04:21.404160 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.124065 (* 1 = 0.124065 loss)
I0526 05:04:21.404166 15117 sgd_solver.cpp:294] Iteration 25090, lr = 0.02
I0526 05:04:27.137809 15117 solver.cpp:342] Iteration 25100, Testing net (#0)
I0526 05:04:39.983512 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8581
I0526 05:04:39.983783 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.585796 (* 1 = 0.585796 loss)
I0526 05:04:40.582006 15117 solver.cpp:233] Iteration 25100, loss = 0.0674577
I0526 05:04:40.582047 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0674578 (* 1 = 0.0674578 loss)
I0526 05:04:40.582056 15117 sgd_solver.cpp:294] Iteration 25100, lr = 0.02
I0526 05:04:46.919842 15117 solver.cpp:233] Iteration 25110, loss = 0.158745
I0526 05:04:46.919885 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.158745 (* 1 = 0.158745 loss)
I0526 05:04:46.919893 15117 sgd_solver.cpp:294] Iteration 25110, lr = 0.02
I0526 05:04:53.255321 15117 solver.cpp:233] Iteration 25120, loss = 0.103096
I0526 05:04:53.255365 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.103096 (* 1 = 0.103096 loss)
I0526 05:04:53.255373 15117 sgd_solver.cpp:294] Iteration 25120, lr = 0.02
I0526 05:04:59.587834 15117 solver.cpp:233] Iteration 25130, loss = 0.133197
I0526 05:04:59.587877 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.133197 (* 1 = 0.133197 loss)
I0526 05:04:59.587883 15117 sgd_solver.cpp:294] Iteration 25130, lr = 0.02
I0526 05:05:05.921507 15117 solver.cpp:233] Iteration 25140, loss = 0.0613669
I0526 05:05:05.921548 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.061367 (* 1 = 0.061367 loss)
I0526 05:05:05.921555 15117 sgd_solver.cpp:294] Iteration 25140, lr = 0.02
I0526 05:05:12.248121 15117 solver.cpp:233] Iteration 25150, loss = 0.0884233
I0526 05:05:12.248234 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0884234 (* 1 = 0.0884234 loss)
I0526 05:05:12.248241 15117 sgd_solver.cpp:294] Iteration 25150, lr = 0.02
I0526 05:05:18.562826 15117 solver.cpp:233] Iteration 25160, loss = 0.12234
I0526 05:05:18.562863 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.12234 (* 1 = 0.12234 loss)
I0526 05:05:18.562870 15117 sgd_solver.cpp:294] Iteration 25160, lr = 0.02
I0526 05:05:24.875507 15117 solver.cpp:233] Iteration 25170, loss = 0.0801929
I0526 05:05:24.875546 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0801931 (* 1 = 0.0801931 loss)
I0526 05:05:24.875553 15117 sgd_solver.cpp:294] Iteration 25170, lr = 0.02
I0526 05:05:31.176607 15117 solver.cpp:233] Iteration 25180, loss = 0.131942
I0526 05:05:31.176645 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.131942 (* 1 = 0.131942 loss)
I0526 05:05:31.176651 15117 sgd_solver.cpp:294] Iteration 25180, lr = 0.02
I0526 05:05:37.470087 15117 solver.cpp:233] Iteration 25190, loss = 0.130407
I0526 05:05:37.470124 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.130407 (* 1 = 0.130407 loss)
I0526 05:05:37.470131 15117 sgd_solver.cpp:294] Iteration 25190, lr = 0.02
I0526 05:05:43.180393 15117 solver.cpp:342] Iteration 25200, Testing net (#0)
I0526 05:05:56.006379 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7725
I0526 05:05:56.006428 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.12457 (* 1 = 1.12457 loss)
I0526 05:05:56.608482 15117 solver.cpp:233] Iteration 25200, loss = 0.106778
I0526 05:05:56.608517 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.106778 (* 1 = 0.106778 loss)
I0526 05:05:56.608525 15117 sgd_solver.cpp:294] Iteration 25200, lr = 0.02
I0526 05:06:02.942698 15117 solver.cpp:233] Iteration 25210, loss = 0.0731061
I0526 05:06:02.942739 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0731062 (* 1 = 0.0731062 loss)
I0526 05:06:02.942746 15117 sgd_solver.cpp:294] Iteration 25210, lr = 0.02
I0526 05:06:09.275575 15117 solver.cpp:233] Iteration 25220, loss = 0.0447858
I0526 05:06:09.275615 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0447859 (* 1 = 0.0447859 loss)
I0526 05:06:09.275622 15117 sgd_solver.cpp:294] Iteration 25220, lr = 0.02
I0526 05:06:15.612684 15117 solver.cpp:233] Iteration 25230, loss = 0.126363
I0526 05:06:15.612944 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.126364 (* 1 = 0.126364 loss)
I0526 05:06:15.612970 15117 sgd_solver.cpp:294] Iteration 25230, lr = 0.02
I0526 05:06:21.946218 15117 solver.cpp:233] Iteration 25240, loss = 0.102145
I0526 05:06:21.946260 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.102146 (* 1 = 0.102146 loss)
I0526 05:06:21.946269 15117 sgd_solver.cpp:294] Iteration 25240, lr = 0.02
I0526 05:06:28.282243 15117 solver.cpp:233] Iteration 25250, loss = 0.0643804
I0526 05:06:28.282285 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0643805 (* 1 = 0.0643805 loss)
I0526 05:06:28.282292 15117 sgd_solver.cpp:294] Iteration 25250, lr = 0.02
I0526 05:06:34.618738 15117 solver.cpp:233] Iteration 25260, loss = 0.121123
I0526 05:06:34.618778 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.121123 (* 1 = 0.121123 loss)
I0526 05:06:34.618796 15117 sgd_solver.cpp:294] Iteration 25260, lr = 0.02
I0526 05:06:40.952409 15117 solver.cpp:233] Iteration 25270, loss = 0.134317
I0526 05:06:40.952455 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.134317 (* 1 = 0.134317 loss)
I0526 05:06:40.952461 15117 sgd_solver.cpp:294] Iteration 25270, lr = 0.02
I0526 05:06:47.289590 15117 solver.cpp:233] Iteration 25280, loss = 0.0710727
I0526 05:06:47.289829 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0710728 (* 1 = 0.0710728 loss)
I0526 05:06:47.289857 15117 sgd_solver.cpp:294] Iteration 25280, lr = 0.02
I0526 05:06:53.628180 15117 solver.cpp:233] Iteration 25290, loss = 0.1032
I0526 05:06:53.628226 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.1032 (* 1 = 0.1032 loss)
I0526 05:06:53.628232 15117 sgd_solver.cpp:294] Iteration 25290, lr = 0.02
I0526 05:06:59.358610 15117 solver.cpp:342] Iteration 25300, Testing net (#0)
I0526 05:07:12.197989 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7975
I0526 05:07:12.198035 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.807095 (* 1 = 0.807095 loss)
I0526 05:07:12.798770 15117 solver.cpp:233] Iteration 25300, loss = 0.160045
I0526 05:07:12.798809 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.160046 (* 1 = 0.160046 loss)
I0526 05:07:12.798816 15117 sgd_solver.cpp:294] Iteration 25300, lr = 0.02
I0526 05:07:19.134351 15117 solver.cpp:233] Iteration 25310, loss = 0.188104
I0526 05:07:19.134564 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.188104 (* 1 = 0.188104 loss)
I0526 05:07:19.134593 15117 sgd_solver.cpp:294] Iteration 25310, lr = 0.02
I0526 05:07:25.468384 15117 solver.cpp:233] Iteration 25320, loss = 0.0941723
I0526 05:07:25.468431 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0941724 (* 1 = 0.0941724 loss)
I0526 05:07:25.468439 15117 sgd_solver.cpp:294] Iteration 25320, lr = 0.02
I0526 05:07:31.806140 15117 solver.cpp:233] Iteration 25330, loss = 0.106203
I0526 05:07:31.806182 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.106203 (* 1 = 0.106203 loss)
I0526 05:07:31.806190 15117 sgd_solver.cpp:294] Iteration 25330, lr = 0.02
I0526 05:07:38.144810 15117 solver.cpp:233] Iteration 25340, loss = 0.0632975
I0526 05:07:38.144870 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0632977 (* 1 = 0.0632977 loss)
I0526 05:07:38.144876 15117 sgd_solver.cpp:294] Iteration 25340, lr = 0.02
I0526 05:07:44.482547 15117 solver.cpp:233] Iteration 25350, loss = 0.108382
I0526 05:07:44.482592 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.108382 (* 1 = 0.108382 loss)
I0526 05:07:44.482599 15117 sgd_solver.cpp:294] Iteration 25350, lr = 0.02
I0526 05:07:50.816907 15117 solver.cpp:233] Iteration 25360, loss = 0.0855214
I0526 05:07:50.817133 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0855215 (* 1 = 0.0855215 loss)
I0526 05:07:50.817167 15117 sgd_solver.cpp:294] Iteration 25360, lr = 0.02
I0526 05:07:57.150213 15117 solver.cpp:233] Iteration 25370, loss = 0.0894956
I0526 05:07:57.150264 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0894957 (* 1 = 0.0894957 loss)
I0526 05:07:57.150272 15117 sgd_solver.cpp:294] Iteration 25370, lr = 0.02
I0526 05:08:03.485530 15117 solver.cpp:233] Iteration 25380, loss = 0.104594
I0526 05:08:03.485569 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.104594 (* 1 = 0.104594 loss)
I0526 05:08:03.485577 15117 sgd_solver.cpp:294] Iteration 25380, lr = 0.02
I0526 05:08:09.819308 15117 solver.cpp:233] Iteration 25390, loss = 0.108678
I0526 05:08:09.819358 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.108679 (* 1 = 0.108679 loss)
I0526 05:08:09.819365 15117 sgd_solver.cpp:294] Iteration 25390, lr = 0.02
I0526 05:08:15.552562 15117 solver.cpp:342] Iteration 25400, Testing net (#0)
I0526 05:08:28.392876 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8152
I0526 05:08:28.393142 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.81522 (* 1 = 0.81522 loss)
I0526 05:08:28.993471 15117 solver.cpp:233] Iteration 25400, loss = 0.114072
I0526 05:08:28.993517 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.114073 (* 1 = 0.114073 loss)
I0526 05:08:28.993526 15117 sgd_solver.cpp:294] Iteration 25400, lr = 0.02
I0526 05:08:35.328074 15117 solver.cpp:233] Iteration 25410, loss = 0.0311898
I0526 05:08:35.328114 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0311899 (* 1 = 0.0311899 loss)
I0526 05:08:35.328120 15117 sgd_solver.cpp:294] Iteration 25410, lr = 0.02
I0526 05:08:41.662281 15117 solver.cpp:233] Iteration 25420, loss = 0.099767
I0526 05:08:41.662322 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0997672 (* 1 = 0.0997672 loss)
I0526 05:08:41.662328 15117 sgd_solver.cpp:294] Iteration 25420, lr = 0.02
I0526 05:08:47.997406 15117 solver.cpp:233] Iteration 25430, loss = 0.18877
I0526 05:08:47.997449 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.18877 (* 1 = 0.18877 loss)
I0526 05:08:47.997457 15117 sgd_solver.cpp:294] Iteration 25430, lr = 0.02
I0526 05:08:54.329859 15117 solver.cpp:233] Iteration 25440, loss = 0.124294
I0526 05:08:54.329900 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.124294 (* 1 = 0.124294 loss)
I0526 05:08:54.329908 15117 sgd_solver.cpp:294] Iteration 25440, lr = 0.02
I0526 05:09:00.665354 15117 solver.cpp:233] Iteration 25450, loss = 0.0802063
I0526 05:09:00.665565 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0802065 (* 1 = 0.0802065 loss)
I0526 05:09:00.665585 15117 sgd_solver.cpp:294] Iteration 25450, lr = 0.02
I0526 05:09:07.001504 15117 solver.cpp:233] Iteration 25460, loss = 0.152544
I0526 05:09:07.001544 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.152544 (* 1 = 0.152544 loss)
I0526 05:09:07.001551 15117 sgd_solver.cpp:294] Iteration 25460, lr = 0.02
I0526 05:09:13.339593 15117 solver.cpp:233] Iteration 25470, loss = 0.154153
I0526 05:09:13.339637 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.154153 (* 1 = 0.154153 loss)
I0526 05:09:13.339644 15117 sgd_solver.cpp:294] Iteration 25470, lr = 0.02
I0526 05:09:19.676805 15117 solver.cpp:233] Iteration 25480, loss = 0.0694067
I0526 05:09:19.676858 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0694068 (* 1 = 0.0694068 loss)
I0526 05:09:19.676865 15117 sgd_solver.cpp:294] Iteration 25480, lr = 0.02
I0526 05:09:26.014089 15117 solver.cpp:233] Iteration 25490, loss = 0.0589788
I0526 05:09:26.014133 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0589789 (* 1 = 0.0589789 loss)
I0526 05:09:26.014140 15117 sgd_solver.cpp:294] Iteration 25490, lr = 0.02
I0526 05:09:31.747383 15117 solver.cpp:342] Iteration 25500, Testing net (#0)
I0526 05:09:44.593744 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8375
I0526 05:09:44.593791 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.694169 (* 1 = 0.694169 loss)
I0526 05:09:45.194488 15117 solver.cpp:233] Iteration 25500, loss = 0.0980867
I0526 05:09:45.194532 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0980868 (* 1 = 0.0980868 loss)
I0526 05:09:45.194540 15117 sgd_solver.cpp:294] Iteration 25500, lr = 0.02
I0526 05:09:51.532955 15117 solver.cpp:233] Iteration 25510, loss = 0.188098
I0526 05:09:51.532995 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.188098 (* 1 = 0.188098 loss)
I0526 05:09:51.533004 15117 sgd_solver.cpp:294] Iteration 25510, lr = 0.02
I0526 05:09:57.870192 15117 solver.cpp:233] Iteration 25520, loss = 0.103076
I0526 05:09:57.870242 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.103076 (* 1 = 0.103076 loss)
I0526 05:09:57.870249 15117 sgd_solver.cpp:294] Iteration 25520, lr = 0.02
I0526 05:10:04.209185 15117 solver.cpp:233] Iteration 25530, loss = 0.0676994
I0526 05:10:04.209447 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0676995 (* 1 = 0.0676995 loss)
I0526 05:10:04.209476 15117 sgd_solver.cpp:294] Iteration 25530, lr = 0.02
I0526 05:10:10.548393 15117 solver.cpp:233] Iteration 25540, loss = 0.0934858
I0526 05:10:10.548436 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0934859 (* 1 = 0.0934859 loss)
I0526 05:10:10.548444 15117 sgd_solver.cpp:294] Iteration 25540, lr = 0.02
I0526 05:10:16.882860 15117 solver.cpp:233] Iteration 25550, loss = 0.148741
I0526 05:10:16.882900 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.148741 (* 1 = 0.148741 loss)
I0526 05:10:16.882907 15117 sgd_solver.cpp:294] Iteration 25550, lr = 0.02
I0526 05:10:23.220955 15117 solver.cpp:233] Iteration 25560, loss = 0.0973059
I0526 05:10:23.221004 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.097306 (* 1 = 0.097306 loss)
I0526 05:10:23.221012 15117 sgd_solver.cpp:294] Iteration 25560, lr = 0.02
I0526 05:10:29.555434 15117 solver.cpp:233] Iteration 25570, loss = 0.140205
I0526 05:10:29.555497 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.140205 (* 1 = 0.140205 loss)
I0526 05:10:29.555505 15117 sgd_solver.cpp:294] Iteration 25570, lr = 0.02
I0526 05:10:35.891083 15117 solver.cpp:233] Iteration 25580, loss = 0.193685
I0526 05:10:35.891307 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.193685 (* 1 = 0.193685 loss)
I0526 05:10:35.891335 15117 sgd_solver.cpp:294] Iteration 25580, lr = 0.02
I0526 05:10:42.224566 15117 solver.cpp:233] Iteration 25590, loss = 0.15145
I0526 05:10:42.224608 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.15145 (* 1 = 0.15145 loss)
I0526 05:10:42.224616 15117 sgd_solver.cpp:294] Iteration 25590, lr = 0.02
I0526 05:10:47.957459 15117 solver.cpp:342] Iteration 25600, Testing net (#0)
I0526 05:11:00.793936 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8278
I0526 05:11:00.793979 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.780633 (* 1 = 0.780633 loss)
I0526 05:11:01.394320 15117 solver.cpp:233] Iteration 25600, loss = 0.18727
I0526 05:11:01.394343 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.187271 (* 1 = 0.187271 loss)
I0526 05:11:01.394351 15117 sgd_solver.cpp:294] Iteration 25600, lr = 0.02
I0526 05:11:07.732717 15117 solver.cpp:233] Iteration 25610, loss = 0.0719044
I0526 05:11:07.732940 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0719046 (* 1 = 0.0719046 loss)
I0526 05:11:07.732967 15117 sgd_solver.cpp:294] Iteration 25610, lr = 0.02
I0526 05:11:14.069941 15117 solver.cpp:233] Iteration 25620, loss = 0.108376
I0526 05:11:14.069984 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.108376 (* 1 = 0.108376 loss)
I0526 05:11:14.069991 15117 sgd_solver.cpp:294] Iteration 25620, lr = 0.02
I0526 05:11:20.407763 15117 solver.cpp:233] Iteration 25630, loss = 0.27135
I0526 05:11:20.407804 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.271351 (* 1 = 0.271351 loss)
I0526 05:11:20.407811 15117 sgd_solver.cpp:294] Iteration 25630, lr = 0.02
I0526 05:11:26.745736 15117 solver.cpp:233] Iteration 25640, loss = 0.168756
I0526 05:11:26.745782 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.168756 (* 1 = 0.168756 loss)
I0526 05:11:26.745790 15117 sgd_solver.cpp:294] Iteration 25640, lr = 0.02
I0526 05:11:33.084203 15117 solver.cpp:233] Iteration 25650, loss = 0.166401
I0526 05:11:33.084241 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.166401 (* 1 = 0.166401 loss)
I0526 05:11:33.084249 15117 sgd_solver.cpp:294] Iteration 25650, lr = 0.02
I0526 05:11:39.426735 15117 solver.cpp:233] Iteration 25660, loss = 0.070089
I0526 05:11:39.427005 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0700891 (* 1 = 0.0700891 loss)
I0526 05:11:39.427034 15117 sgd_solver.cpp:294] Iteration 25660, lr = 0.02
I0526 05:11:45.765621 15117 solver.cpp:233] Iteration 25670, loss = 0.0504413
I0526 05:11:45.765661 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0504414 (* 1 = 0.0504414 loss)
I0526 05:11:45.765666 15117 sgd_solver.cpp:294] Iteration 25670, lr = 0.02
I0526 05:11:52.102275 15117 solver.cpp:233] Iteration 25680, loss = 0.107386
I0526 05:11:52.102315 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.107386 (* 1 = 0.107386 loss)
I0526 05:11:52.102322 15117 sgd_solver.cpp:294] Iteration 25680, lr = 0.02
I0526 05:11:58.441085 15117 solver.cpp:233] Iteration 25690, loss = 0.155449
I0526 05:11:58.441125 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.155449 (* 1 = 0.155449 loss)
I0526 05:11:58.441131 15117 sgd_solver.cpp:294] Iteration 25690, lr = 0.02
I0526 05:12:04.179807 15117 solver.cpp:342] Iteration 25700, Testing net (#0)
I0526 05:12:17.020364 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7903
I0526 05:12:17.020591 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.891642 (* 1 = 0.891642 loss)
I0526 05:12:17.622161 15117 solver.cpp:233] Iteration 25700, loss = 0.0895827
I0526 05:12:17.622207 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0895828 (* 1 = 0.0895828 loss)
I0526 05:12:17.622215 15117 sgd_solver.cpp:294] Iteration 25700, lr = 0.02
I0526 05:12:23.959710 15117 solver.cpp:233] Iteration 25710, loss = 0.168243
I0526 05:12:23.959749 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.168243 (* 1 = 0.168243 loss)
I0526 05:12:23.959756 15117 sgd_solver.cpp:294] Iteration 25710, lr = 0.02
I0526 05:12:30.300703 15117 solver.cpp:233] Iteration 25720, loss = 0.0826847
I0526 05:12:30.300740 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0826848 (* 1 = 0.0826848 loss)
I0526 05:12:30.300746 15117 sgd_solver.cpp:294] Iteration 25720, lr = 0.02
I0526 05:12:36.636510 15117 solver.cpp:233] Iteration 25730, loss = 0.0619709
I0526 05:12:36.636551 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.061971 (* 1 = 0.061971 loss)
I0526 05:12:36.636559 15117 sgd_solver.cpp:294] Iteration 25730, lr = 0.02
I0526 05:12:42.976888 15117 solver.cpp:233] Iteration 25740, loss = 0.136981
I0526 05:12:42.976928 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.136981 (* 1 = 0.136981 loss)
I0526 05:12:42.976935 15117 sgd_solver.cpp:294] Iteration 25740, lr = 0.02
I0526 05:12:49.316077 15117 solver.cpp:233] Iteration 25750, loss = 0.113302
I0526 05:12:49.316293 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.113302 (* 1 = 0.113302 loss)
I0526 05:12:49.316318 15117 sgd_solver.cpp:294] Iteration 25750, lr = 0.02
I0526 05:12:55.647480 15117 solver.cpp:233] Iteration 25760, loss = 0.0977044
I0526 05:12:55.647526 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0977045 (* 1 = 0.0977045 loss)
I0526 05:12:55.647534 15117 sgd_solver.cpp:294] Iteration 25760, lr = 0.02
I0526 05:13:01.984174 15117 solver.cpp:233] Iteration 25770, loss = 0.0620985
I0526 05:13:01.984215 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0620986 (* 1 = 0.0620986 loss)
I0526 05:13:01.984221 15117 sgd_solver.cpp:294] Iteration 25770, lr = 0.02
I0526 05:13:08.323333 15117 solver.cpp:233] Iteration 25780, loss = 0.0500416
I0526 05:13:08.323386 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0500418 (* 1 = 0.0500418 loss)
I0526 05:13:08.323395 15117 sgd_solver.cpp:294] Iteration 25780, lr = 0.02
I0526 05:13:14.657521 15117 solver.cpp:233] Iteration 25790, loss = 0.0964033
I0526 05:13:14.657568 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0964035 (* 1 = 0.0964035 loss)
I0526 05:13:14.657577 15117 sgd_solver.cpp:294] Iteration 25790, lr = 0.02
I0526 05:13:20.388475 15117 solver.cpp:342] Iteration 25800, Testing net (#0)
I0526 05:13:33.237174 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7669
I0526 05:13:33.237215 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.04067 (* 1 = 1.04067 loss)
I0526 05:13:33.838896 15117 solver.cpp:233] Iteration 25800, loss = 0.0770452
I0526 05:13:33.838932 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0770453 (* 1 = 0.0770453 loss)
I0526 05:13:33.838938 15117 sgd_solver.cpp:294] Iteration 25800, lr = 0.02
I0526 05:13:40.178208 15117 solver.cpp:233] Iteration 25810, loss = 0.116375
I0526 05:13:40.178261 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.116375 (* 1 = 0.116375 loss)
I0526 05:13:40.178267 15117 sgd_solver.cpp:294] Iteration 25810, lr = 0.02
I0526 05:13:46.515413 15117 solver.cpp:233] Iteration 25820, loss = 0.146598
I0526 05:13:46.515463 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.146599 (* 1 = 0.146599 loss)
I0526 05:13:46.515470 15117 sgd_solver.cpp:294] Iteration 25820, lr = 0.02
I0526 05:13:52.850123 15117 solver.cpp:233] Iteration 25830, loss = 0.0879831
I0526 05:13:52.850380 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0879832 (* 1 = 0.0879832 loss)
I0526 05:13:52.850412 15117 sgd_solver.cpp:294] Iteration 25830, lr = 0.02
I0526 05:13:59.182848 15117 solver.cpp:233] Iteration 25840, loss = 0.0898087
I0526 05:13:59.182889 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0898088 (* 1 = 0.0898088 loss)
I0526 05:13:59.182898 15117 sgd_solver.cpp:294] Iteration 25840, lr = 0.02
I0526 05:14:05.520735 15117 solver.cpp:233] Iteration 25850, loss = 0.112289
I0526 05:14:05.520776 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.112289 (* 1 = 0.112289 loss)
I0526 05:14:05.520783 15117 sgd_solver.cpp:294] Iteration 25850, lr = 0.02
I0526 05:14:11.860960 15117 solver.cpp:233] Iteration 25860, loss = 0.1119
I0526 05:14:11.861001 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.1119 (* 1 = 0.1119 loss)
I0526 05:14:11.861009 15117 sgd_solver.cpp:294] Iteration 25860, lr = 0.02
I0526 05:14:18.199630 15117 solver.cpp:233] Iteration 25870, loss = 0.0811394
I0526 05:14:18.199671 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0811395 (* 1 = 0.0811395 loss)
I0526 05:14:18.199689 15117 sgd_solver.cpp:294] Iteration 25870, lr = 0.02
I0526 05:14:24.536499 15117 solver.cpp:233] Iteration 25880, loss = 0.0935559
I0526 05:14:24.536717 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.093556 (* 1 = 0.093556 loss)
I0526 05:14:24.536747 15117 sgd_solver.cpp:294] Iteration 25880, lr = 0.02
I0526 05:14:30.871409 15117 solver.cpp:233] Iteration 25890, loss = 0.0885973
I0526 05:14:30.871450 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0885975 (* 1 = 0.0885975 loss)
I0526 05:14:30.871456 15117 sgd_solver.cpp:294] Iteration 25890, lr = 0.02
I0526 05:14:36.606570 15117 solver.cpp:342] Iteration 25900, Testing net (#0)
I0526 05:14:49.442703 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7617
I0526 05:14:49.442759 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.29417 (* 1 = 1.29417 loss)
I0526 05:14:50.044216 15117 solver.cpp:233] Iteration 25900, loss = 0.253363
I0526 05:14:50.044252 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.253363 (* 1 = 0.253363 loss)
I0526 05:14:50.044260 15117 sgd_solver.cpp:294] Iteration 25900, lr = 0.02
I0526 05:14:56.380481 15117 solver.cpp:233] Iteration 25910, loss = 0.135553
I0526 05:14:56.380756 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.135553 (* 1 = 0.135553 loss)
I0526 05:14:56.380794 15117 sgd_solver.cpp:294] Iteration 25910, lr = 0.02
I0526 05:15:02.718181 15117 solver.cpp:233] Iteration 25920, loss = 0.12511
I0526 05:15:02.718221 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.12511 (* 1 = 0.12511 loss)
I0526 05:15:02.718228 15117 sgd_solver.cpp:294] Iteration 25920, lr = 0.02
I0526 05:15:09.052745 15117 solver.cpp:233] Iteration 25930, loss = 0.102775
I0526 05:15:09.052772 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.102775 (* 1 = 0.102775 loss)
I0526 05:15:09.052780 15117 sgd_solver.cpp:294] Iteration 25930, lr = 0.02
I0526 05:15:15.392114 15117 solver.cpp:233] Iteration 25940, loss = 0.0874444
I0526 05:15:15.392153 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0874446 (* 1 = 0.0874446 loss)
I0526 05:15:15.392159 15117 sgd_solver.cpp:294] Iteration 25940, lr = 0.02
I0526 05:15:21.725534 15117 solver.cpp:233] Iteration 25950, loss = 0.130214
I0526 05:15:21.725581 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.130214 (* 1 = 0.130214 loss)
I0526 05:15:21.725589 15117 sgd_solver.cpp:294] Iteration 25950, lr = 0.02
I0526 05:15:28.055836 15117 solver.cpp:233] Iteration 25960, loss = 0.165535
I0526 05:15:28.056061 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.165535 (* 1 = 0.165535 loss)
I0526 05:15:28.056095 15117 sgd_solver.cpp:294] Iteration 25960, lr = 0.02
I0526 05:15:34.390163 15117 solver.cpp:233] Iteration 25970, loss = 0.204412
I0526 05:15:34.390208 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.204412 (* 1 = 0.204412 loss)
I0526 05:15:34.390214 15117 sgd_solver.cpp:294] Iteration 25970, lr = 0.02
I0526 05:15:40.726064 15117 solver.cpp:233] Iteration 25980, loss = 0.110051
I0526 05:15:40.726104 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.110051 (* 1 = 0.110051 loss)
I0526 05:15:40.726111 15117 sgd_solver.cpp:294] Iteration 25980, lr = 0.02
I0526 05:15:47.060531 15117 solver.cpp:233] Iteration 25990, loss = 0.122877
I0526 05:15:47.060573 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.122877 (* 1 = 0.122877 loss)
I0526 05:15:47.060581 15117 sgd_solver.cpp:294] Iteration 25990, lr = 0.02
I0526 05:15:52.790505 15117 solver.cpp:342] Iteration 26000, Testing net (#0)
I0526 05:16:05.626430 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7977
I0526 05:16:05.626668 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.886697 (* 1 = 0.886697 loss)
I0526 05:16:06.229032 15117 solver.cpp:233] Iteration 26000, loss = 0.0504343
I0526 05:16:06.229059 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0504344 (* 1 = 0.0504344 loss)
I0526 05:16:06.229066 15117 sgd_solver.cpp:294] Iteration 26000, lr = 0.02
I0526 05:16:12.562610 15117 solver.cpp:233] Iteration 26010, loss = 0.0739656
I0526 05:16:12.562638 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0739657 (* 1 = 0.0739657 loss)
I0526 05:16:12.562645 15117 sgd_solver.cpp:294] Iteration 26010, lr = 0.02
I0526 05:16:18.897368 15117 solver.cpp:233] Iteration 26020, loss = 0.131506
I0526 05:16:18.897410 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.131506 (* 1 = 0.131506 loss)
I0526 05:16:18.897416 15117 sgd_solver.cpp:294] Iteration 26020, lr = 0.02
I0526 05:16:25.235288 15117 solver.cpp:233] Iteration 26030, loss = 0.0713208
I0526 05:16:25.235330 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.071321 (* 1 = 0.071321 loss)
I0526 05:16:25.235337 15117 sgd_solver.cpp:294] Iteration 26030, lr = 0.02
I0526 05:16:31.567610 15117 solver.cpp:233] Iteration 26040, loss = 0.101131
I0526 05:16:31.567672 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.101131 (* 1 = 0.101131 loss)
I0526 05:16:31.567682 15117 sgd_solver.cpp:294] Iteration 26040, lr = 0.02
I0526 05:16:37.902521 15117 solver.cpp:233] Iteration 26050, loss = 0.132997
I0526 05:16:37.902784 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.132997 (* 1 = 0.132997 loss)
I0526 05:16:37.902825 15117 sgd_solver.cpp:294] Iteration 26050, lr = 0.02
I0526 05:16:44.237042 15117 solver.cpp:233] Iteration 26060, loss = 0.0759404
I0526 05:16:44.237082 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0759405 (* 1 = 0.0759405 loss)
I0526 05:16:44.237089 15117 sgd_solver.cpp:294] Iteration 26060, lr = 0.02
I0526 05:16:50.574615 15117 solver.cpp:233] Iteration 26070, loss = 0.0644099
I0526 05:16:50.574653 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.06441 (* 1 = 0.06441 loss)
I0526 05:16:50.574671 15117 sgd_solver.cpp:294] Iteration 26070, lr = 0.02
I0526 05:16:56.910048 15117 solver.cpp:233] Iteration 26080, loss = 0.074739
I0526 05:16:56.910089 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0747391 (* 1 = 0.0747391 loss)
I0526 05:16:56.910096 15117 sgd_solver.cpp:294] Iteration 26080, lr = 0.02
I0526 05:17:03.240500 15117 solver.cpp:233] Iteration 26090, loss = 0.113653
I0526 05:17:03.240542 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.113653 (* 1 = 0.113653 loss)
I0526 05:17:03.240550 15117 sgd_solver.cpp:294] Iteration 26090, lr = 0.02
I0526 05:17:08.975435 15117 solver.cpp:342] Iteration 26100, Testing net (#0)
I0526 05:17:21.806618 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7927
I0526 05:17:21.806668 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.965927 (* 1 = 0.965927 loss)
I0526 05:17:22.407739 15117 solver.cpp:233] Iteration 26100, loss = 0.120287
I0526 05:17:22.407760 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.120287 (* 1 = 0.120287 loss)
I0526 05:17:22.407768 15117 sgd_solver.cpp:294] Iteration 26100, lr = 0.02
I0526 05:17:28.745110 15117 solver.cpp:233] Iteration 26110, loss = 0.0609184
I0526 05:17:28.745146 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0609185 (* 1 = 0.0609185 loss)
I0526 05:17:28.745152 15117 sgd_solver.cpp:294] Iteration 26110, lr = 0.02
I0526 05:17:35.080341 15117 solver.cpp:233] Iteration 26120, loss = 0.0671862
I0526 05:17:35.080385 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0671863 (* 1 = 0.0671863 loss)
I0526 05:17:35.080394 15117 sgd_solver.cpp:294] Iteration 26120, lr = 0.02
I0526 05:17:41.415215 15117 solver.cpp:233] Iteration 26130, loss = 0.0812961
I0526 05:17:41.415429 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0812962 (* 1 = 0.0812962 loss)
I0526 05:17:41.415455 15117 sgd_solver.cpp:294] Iteration 26130, lr = 0.02
I0526 05:17:47.743286 15117 solver.cpp:233] Iteration 26140, loss = 0.082263
I0526 05:17:47.743331 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0822631 (* 1 = 0.0822631 loss)
I0526 05:17:47.743340 15117 sgd_solver.cpp:294] Iteration 26140, lr = 0.02
I0526 05:17:54.077004 15117 solver.cpp:233] Iteration 26150, loss = 0.073609
I0526 05:17:54.077046 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0736091 (* 1 = 0.0736091 loss)
I0526 05:17:54.077054 15117 sgd_solver.cpp:294] Iteration 26150, lr = 0.02
I0526 05:18:00.410274 15117 solver.cpp:233] Iteration 26160, loss = 0.0501411
I0526 05:18:00.410315 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0501412 (* 1 = 0.0501412 loss)
I0526 05:18:00.410322 15117 sgd_solver.cpp:294] Iteration 26160, lr = 0.02
I0526 05:18:06.743044 15117 solver.cpp:233] Iteration 26170, loss = 0.0933565
I0526 05:18:06.743089 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0933566 (* 1 = 0.0933566 loss)
I0526 05:18:06.743096 15117 sgd_solver.cpp:294] Iteration 26170, lr = 0.02
I0526 05:18:13.076552 15117 solver.cpp:233] Iteration 26180, loss = 0.135595
I0526 05:18:13.076681 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.135595 (* 1 = 0.135595 loss)
I0526 05:18:13.076689 15117 sgd_solver.cpp:294] Iteration 26180, lr = 0.02
I0526 05:18:19.405915 15117 solver.cpp:233] Iteration 26190, loss = 0.0948854
I0526 05:18:19.405957 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0948855 (* 1 = 0.0948855 loss)
I0526 05:18:19.405971 15117 sgd_solver.cpp:294] Iteration 26190, lr = 0.02
I0526 05:18:25.117707 15117 solver.cpp:342] Iteration 26200, Testing net (#0)
I0526 05:18:37.946022 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8368
I0526 05:18:37.946065 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.683807 (* 1 = 0.683807 loss)
I0526 05:18:38.547171 15117 solver.cpp:233] Iteration 26200, loss = 0.067896
I0526 05:18:38.547199 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0678961 (* 1 = 0.0678961 loss)
I0526 05:18:38.547217 15117 sgd_solver.cpp:294] Iteration 26200, lr = 0.02
I0526 05:18:44.882460 15117 solver.cpp:233] Iteration 26210, loss = 0.0929868
I0526 05:18:44.882604 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.092987 (* 1 = 0.092987 loss)
I0526 05:18:44.882613 15117 sgd_solver.cpp:294] Iteration 26210, lr = 0.02
I0526 05:18:51.216923 15117 solver.cpp:233] Iteration 26220, loss = 0.0892069
I0526 05:18:51.216961 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.089207 (* 1 = 0.089207 loss)
I0526 05:18:51.216969 15117 sgd_solver.cpp:294] Iteration 26220, lr = 0.02
I0526 05:18:57.553402 15117 solver.cpp:233] Iteration 26230, loss = 0.101855
I0526 05:18:57.553445 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.101855 (* 1 = 0.101855 loss)
I0526 05:18:57.553452 15117 sgd_solver.cpp:294] Iteration 26230, lr = 0.02
I0526 05:19:03.890493 15117 solver.cpp:233] Iteration 26240, loss = 0.131864
I0526 05:19:03.890535 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.131864 (* 1 = 0.131864 loss)
I0526 05:19:03.890553 15117 sgd_solver.cpp:294] Iteration 26240, lr = 0.02
I0526 05:19:10.228034 15117 solver.cpp:233] Iteration 26250, loss = 0.104473
I0526 05:19:10.228065 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.104473 (* 1 = 0.104473 loss)
I0526 05:19:10.228072 15117 sgd_solver.cpp:294] Iteration 26250, lr = 0.02
I0526 05:19:16.563575 15117 solver.cpp:233] Iteration 26260, loss = 0.1063
I0526 05:19:16.563639 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.1063 (* 1 = 0.1063 loss)
I0526 05:19:16.563647 15117 sgd_solver.cpp:294] Iteration 26260, lr = 0.02
I0526 05:19:22.898386 15117 solver.cpp:233] Iteration 26270, loss = 0.104508
I0526 05:19:22.898423 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.104509 (* 1 = 0.104509 loss)
I0526 05:19:22.898432 15117 sgd_solver.cpp:294] Iteration 26270, lr = 0.02
I0526 05:19:29.232641 15117 solver.cpp:233] Iteration 26280, loss = 0.114668
I0526 05:19:29.232681 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.114668 (* 1 = 0.114668 loss)
I0526 05:19:29.232688 15117 sgd_solver.cpp:294] Iteration 26280, lr = 0.02
I0526 05:19:35.566762 15117 solver.cpp:233] Iteration 26290, loss = 0.121119
I0526 05:19:35.566803 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.121119 (* 1 = 0.121119 loss)
I0526 05:19:35.566810 15117 sgd_solver.cpp:294] Iteration 26290, lr = 0.02
I0526 05:19:41.299187 15117 solver.cpp:342] Iteration 26300, Testing net (#0)
I0526 05:19:54.143317 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8399
I0526 05:19:54.143447 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.652322 (* 1 = 0.652322 loss)
I0526 05:19:54.744392 15117 solver.cpp:233] Iteration 26300, loss = 0.100593
I0526 05:19:54.744415 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.100593 (* 1 = 0.100593 loss)
I0526 05:19:54.744422 15117 sgd_solver.cpp:294] Iteration 26300, lr = 0.02
I0526 05:20:01.078755 15117 solver.cpp:233] Iteration 26310, loss = 0.120654
I0526 05:20:01.078795 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.120654 (* 1 = 0.120654 loss)
I0526 05:20:01.078802 15117 sgd_solver.cpp:294] Iteration 26310, lr = 0.02
I0526 05:20:07.412586 15117 solver.cpp:233] Iteration 26320, loss = 0.10779
I0526 05:20:07.412637 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.10779 (* 1 = 0.10779 loss)
I0526 05:20:07.412650 15117 sgd_solver.cpp:294] Iteration 26320, lr = 0.02
I0526 05:20:13.746449 15117 solver.cpp:233] Iteration 26330, loss = 0.148742
I0526 05:20:13.746489 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.148742 (* 1 = 0.148742 loss)
I0526 05:20:13.746496 15117 sgd_solver.cpp:294] Iteration 26330, lr = 0.02
I0526 05:20:20.081912 15117 solver.cpp:233] Iteration 26340, loss = 0.130932
I0526 05:20:20.081954 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.130933 (* 1 = 0.130933 loss)
I0526 05:20:20.081960 15117 sgd_solver.cpp:294] Iteration 26340, lr = 0.02
I0526 05:20:26.416302 15117 solver.cpp:233] Iteration 26350, loss = 0.157889
I0526 05:20:26.416582 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.157889 (* 1 = 0.157889 loss)
I0526 05:20:26.416611 15117 sgd_solver.cpp:294] Iteration 26350, lr = 0.02
I0526 05:20:32.742808 15117 solver.cpp:233] Iteration 26360, loss = 0.132943
I0526 05:20:32.742853 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.132943 (* 1 = 0.132943 loss)
I0526 05:20:32.742861 15117 sgd_solver.cpp:294] Iteration 26360, lr = 0.02
I0526 05:20:39.079026 15117 solver.cpp:233] Iteration 26370, loss = 0.117566
I0526 05:20:39.079066 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.117567 (* 1 = 0.117567 loss)
I0526 05:20:39.079074 15117 sgd_solver.cpp:294] Iteration 26370, lr = 0.02
I0526 05:20:45.410791 15117 solver.cpp:233] Iteration 26380, loss = 0.130488
I0526 05:20:45.410836 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.130488 (* 1 = 0.130488 loss)
I0526 05:20:45.410843 15117 sgd_solver.cpp:294] Iteration 26380, lr = 0.02
I0526 05:20:51.746718 15117 solver.cpp:233] Iteration 26390, loss = 0.099542
I0526 05:20:51.746759 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0995421 (* 1 = 0.0995421 loss)
I0526 05:20:51.746778 15117 sgd_solver.cpp:294] Iteration 26390, lr = 0.02
I0526 05:20:57.479194 15117 solver.cpp:342] Iteration 26400, Testing net (#0)
I0526 05:21:10.322952 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8423
I0526 05:21:10.323006 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.614445 (* 1 = 0.614445 loss)
I0526 05:21:10.924389 15117 solver.cpp:233] Iteration 26400, loss = 0.156847
I0526 05:21:10.924425 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.156847 (* 1 = 0.156847 loss)
I0526 05:21:10.924432 15117 sgd_solver.cpp:294] Iteration 26400, lr = 0.02
I0526 05:21:17.262687 15117 solver.cpp:233] Iteration 26410, loss = 0.0850822
I0526 05:21:17.262735 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0850823 (* 1 = 0.0850823 loss)
I0526 05:21:17.262742 15117 sgd_solver.cpp:294] Iteration 26410, lr = 0.02
I0526 05:21:23.601079 15117 solver.cpp:233] Iteration 26420, loss = 0.0911265
I0526 05:21:23.601119 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0911266 (* 1 = 0.0911266 loss)
I0526 05:21:23.601125 15117 sgd_solver.cpp:294] Iteration 26420, lr = 0.02
I0526 05:21:29.940031 15117 solver.cpp:233] Iteration 26430, loss = 0.116143
I0526 05:21:29.940261 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.116143 (* 1 = 0.116143 loss)
I0526 05:21:29.940290 15117 sgd_solver.cpp:294] Iteration 26430, lr = 0.02
I0526 05:21:36.271760 15117 solver.cpp:233] Iteration 26440, loss = 0.085647
I0526 05:21:36.271812 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0856471 (* 1 = 0.0856471 loss)
I0526 05:21:36.271831 15117 sgd_solver.cpp:294] Iteration 26440, lr = 0.02
I0526 05:21:42.607503 15117 solver.cpp:233] Iteration 26450, loss = 0.0861287
I0526 05:21:42.607537 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0861288 (* 1 = 0.0861288 loss)
I0526 05:21:42.607545 15117 sgd_solver.cpp:294] Iteration 26450, lr = 0.02
I0526 05:21:48.946264 15117 solver.cpp:233] Iteration 26460, loss = 0.211513
I0526 05:21:48.946302 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.211513 (* 1 = 0.211513 loss)
I0526 05:21:48.946316 15117 sgd_solver.cpp:294] Iteration 26460, lr = 0.02
I0526 05:21:55.281561 15117 solver.cpp:233] Iteration 26470, loss = 0.116675
I0526 05:21:55.281613 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.116675 (* 1 = 0.116675 loss)
I0526 05:21:55.281620 15117 sgd_solver.cpp:294] Iteration 26470, lr = 0.02
I0526 05:22:01.617276 15117 solver.cpp:233] Iteration 26480, loss = 0.038946
I0526 05:22:01.617530 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0389461 (* 1 = 0.0389461 loss)
I0526 05:22:01.617559 15117 sgd_solver.cpp:294] Iteration 26480, lr = 0.02
I0526 05:22:07.951252 15117 solver.cpp:233] Iteration 26490, loss = 0.0731704
I0526 05:22:07.951292 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0731706 (* 1 = 0.0731706 loss)
I0526 05:22:07.951298 15117 sgd_solver.cpp:294] Iteration 26490, lr = 0.02
I0526 05:22:13.690369 15117 solver.cpp:342] Iteration 26500, Testing net (#0)
I0526 05:22:26.533560 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8405
I0526 05:22:26.533604 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.607506 (* 1 = 0.607506 loss)
I0526 05:22:27.135745 15117 solver.cpp:233] Iteration 26500, loss = 0.240215
I0526 05:22:27.135766 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.240215 (* 1 = 0.240215 loss)
I0526 05:22:27.135773 15117 sgd_solver.cpp:294] Iteration 26500, lr = 0.02
I0526 05:22:33.472342 15117 solver.cpp:233] Iteration 26510, loss = 0.0978078
I0526 05:22:33.472563 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0978079 (* 1 = 0.0978079 loss)
I0526 05:22:33.472595 15117 sgd_solver.cpp:294] Iteration 26510, lr = 0.02
I0526 05:22:39.808292 15117 solver.cpp:233] Iteration 26520, loss = 0.0594303
I0526 05:22:39.808341 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0594304 (* 1 = 0.0594304 loss)
I0526 05:22:39.808351 15117 sgd_solver.cpp:294] Iteration 26520, lr = 0.02
I0526 05:22:46.143249 15117 solver.cpp:233] Iteration 26530, loss = 0.0668862
I0526 05:22:46.143297 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0668863 (* 1 = 0.0668863 loss)
I0526 05:22:46.143304 15117 sgd_solver.cpp:294] Iteration 26530, lr = 0.02
I0526 05:22:52.480609 15117 solver.cpp:233] Iteration 26540, loss = 0.0407435
I0526 05:22:52.480646 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0407436 (* 1 = 0.0407436 loss)
I0526 05:22:52.480654 15117 sgd_solver.cpp:294] Iteration 26540, lr = 0.02
I0526 05:22:58.815054 15117 solver.cpp:233] Iteration 26550, loss = 0.137465
I0526 05:22:58.815086 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.137465 (* 1 = 0.137465 loss)
I0526 05:22:58.815094 15117 sgd_solver.cpp:294] Iteration 26550, lr = 0.02
I0526 05:23:05.149736 15117 solver.cpp:233] Iteration 26560, loss = 0.101607
I0526 05:23:05.149968 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.101608 (* 1 = 0.101608 loss)
I0526 05:23:05.149999 15117 sgd_solver.cpp:294] Iteration 26560, lr = 0.02
I0526 05:23:11.485997 15117 solver.cpp:233] Iteration 26570, loss = 0.110181
I0526 05:23:11.486043 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.110181 (* 1 = 0.110181 loss)
I0526 05:23:11.486062 15117 sgd_solver.cpp:294] Iteration 26570, lr = 0.02
I0526 05:23:17.824451 15117 solver.cpp:233] Iteration 26580, loss = 0.0632959
I0526 05:23:17.824491 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.063296 (* 1 = 0.063296 loss)
I0526 05:23:17.824497 15117 sgd_solver.cpp:294] Iteration 26580, lr = 0.02
I0526 05:23:24.158198 15117 solver.cpp:233] Iteration 26590, loss = 0.0884987
I0526 05:23:24.158259 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0884988 (* 1 = 0.0884988 loss)
I0526 05:23:24.158267 15117 sgd_solver.cpp:294] Iteration 26590, lr = 0.02
I0526 05:23:29.894515 15117 solver.cpp:342] Iteration 26600, Testing net (#0)
I0526 05:23:42.735203 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.832
I0526 05:23:42.735496 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.646487 (* 1 = 0.646487 loss)
I0526 05:23:43.335016 15117 solver.cpp:233] Iteration 26600, loss = 0.128182
I0526 05:23:43.335054 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.128182 (* 1 = 0.128182 loss)
I0526 05:23:43.335064 15117 sgd_solver.cpp:294] Iteration 26600, lr = 0.02
I0526 05:23:49.671344 15117 solver.cpp:233] Iteration 26610, loss = 0.0531949
I0526 05:23:49.671385 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.053195 (* 1 = 0.053195 loss)
I0526 05:23:49.671391 15117 sgd_solver.cpp:294] Iteration 26610, lr = 0.02
I0526 05:23:56.003443 15117 solver.cpp:233] Iteration 26620, loss = 0.0964493
I0526 05:23:56.003482 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0964494 (* 1 = 0.0964494 loss)
I0526 05:23:56.003489 15117 sgd_solver.cpp:294] Iteration 26620, lr = 0.02
I0526 05:24:02.342356 15117 solver.cpp:233] Iteration 26630, loss = 0.0527446
I0526 05:24:02.342393 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0527447 (* 1 = 0.0527447 loss)
I0526 05:24:02.342401 15117 sgd_solver.cpp:294] Iteration 26630, lr = 0.02
I0526 05:24:08.682776 15117 solver.cpp:233] Iteration 26640, loss = 0.0772053
I0526 05:24:08.682816 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0772054 (* 1 = 0.0772054 loss)
I0526 05:24:08.682823 15117 sgd_solver.cpp:294] Iteration 26640, lr = 0.02
I0526 05:24:15.021159 15117 solver.cpp:233] Iteration 26650, loss = 0.0868942
I0526 05:24:15.021386 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0868943 (* 1 = 0.0868943 loss)
I0526 05:24:15.021415 15117 sgd_solver.cpp:294] Iteration 26650, lr = 0.02
I0526 05:24:21.359004 15117 solver.cpp:233] Iteration 26660, loss = 0.104969
I0526 05:24:21.359048 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.104969 (* 1 = 0.104969 loss)
I0526 05:24:21.359056 15117 sgd_solver.cpp:294] Iteration 26660, lr = 0.02
I0526 05:24:27.698578 15117 solver.cpp:233] Iteration 26670, loss = 0.112442
I0526 05:24:27.698618 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.112442 (* 1 = 0.112442 loss)
I0526 05:24:27.698626 15117 sgd_solver.cpp:294] Iteration 26670, lr = 0.02
I0526 05:24:34.037911 15117 solver.cpp:233] Iteration 26680, loss = 0.0849304
I0526 05:24:34.037950 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0849306 (* 1 = 0.0849306 loss)
I0526 05:24:34.037957 15117 sgd_solver.cpp:294] Iteration 26680, lr = 0.02
I0526 05:24:40.368970 15117 solver.cpp:233] Iteration 26690, loss = 0.111176
I0526 05:24:40.369014 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.111176 (* 1 = 0.111176 loss)
I0526 05:24:40.369021 15117 sgd_solver.cpp:294] Iteration 26690, lr = 0.02
I0526 05:24:46.101871 15117 solver.cpp:342] Iteration 26700, Testing net (#0)
I0526 05:24:58.938923 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8424
I0526 05:24:58.938971 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.61704 (* 1 = 0.61704 loss)
I0526 05:24:59.539386 15117 solver.cpp:233] Iteration 26700, loss = 0.10237
I0526 05:24:59.539418 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.10237 (* 1 = 0.10237 loss)
I0526 05:24:59.539425 15117 sgd_solver.cpp:294] Iteration 26700, lr = 0.02
I0526 05:25:05.874480 15117 solver.cpp:233] Iteration 26710, loss = 0.125959
I0526 05:25:05.874521 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.125959 (* 1 = 0.125959 loss)
I0526 05:25:05.874527 15117 sgd_solver.cpp:294] Iteration 26710, lr = 0.02
I0526 05:25:12.210167 15117 solver.cpp:233] Iteration 26720, loss = 0.0810903
I0526 05:25:12.210211 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0810904 (* 1 = 0.0810904 loss)
I0526 05:25:12.210218 15117 sgd_solver.cpp:294] Iteration 26720, lr = 0.02
I0526 05:25:18.541501 15117 solver.cpp:233] Iteration 26730, loss = 0.127757
I0526 05:25:18.541760 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.127757 (* 1 = 0.127757 loss)
I0526 05:25:18.541800 15117 sgd_solver.cpp:294] Iteration 26730, lr = 0.02
I0526 05:25:24.875501 15117 solver.cpp:233] Iteration 26740, loss = 0.15982
I0526 05:25:24.875545 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.15982 (* 1 = 0.15982 loss)
I0526 05:25:24.875555 15117 sgd_solver.cpp:294] Iteration 26740, lr = 0.02
I0526 05:25:31.215317 15117 solver.cpp:233] Iteration 26750, loss = 0.0846666
I0526 05:25:31.215355 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0846668 (* 1 = 0.0846668 loss)
I0526 05:25:31.215363 15117 sgd_solver.cpp:294] Iteration 26750, lr = 0.02
I0526 05:25:37.549386 15117 solver.cpp:233] Iteration 26760, loss = 0.119845
I0526 05:25:37.549422 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.119845 (* 1 = 0.119845 loss)
I0526 05:25:37.549429 15117 sgd_solver.cpp:294] Iteration 26760, lr = 0.02
I0526 05:25:43.884124 15117 solver.cpp:233] Iteration 26770, loss = 0.0387255
I0526 05:25:43.884167 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0387256 (* 1 = 0.0387256 loss)
I0526 05:25:43.884184 15117 sgd_solver.cpp:294] Iteration 26770, lr = 0.02
I0526 05:25:50.217434 15117 solver.cpp:233] Iteration 26780, loss = 0.200369
I0526 05:25:50.217667 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.200369 (* 1 = 0.200369 loss)
I0526 05:25:50.217695 15117 sgd_solver.cpp:294] Iteration 26780, lr = 0.02
I0526 05:25:56.550071 15117 solver.cpp:233] Iteration 26790, loss = 0.125778
I0526 05:25:56.550112 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.125778 (* 1 = 0.125778 loss)
I0526 05:25:56.550119 15117 sgd_solver.cpp:294] Iteration 26790, lr = 0.02
I0526 05:26:02.281404 15117 solver.cpp:342] Iteration 26800, Testing net (#0)
I0526 05:26:15.119248 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8496
I0526 05:26:15.119295 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.568887 (* 1 = 0.568887 loss)
I0526 05:26:15.721106 15117 solver.cpp:233] Iteration 26800, loss = 0.0723728
I0526 05:26:15.721144 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0723729 (* 1 = 0.0723729 loss)
I0526 05:26:15.721153 15117 sgd_solver.cpp:294] Iteration 26800, lr = 0.02
I0526 05:26:22.053971 15117 solver.cpp:233] Iteration 26810, loss = 0.076969
I0526 05:26:22.054193 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0769691 (* 1 = 0.0769691 loss)
I0526 05:26:22.054222 15117 sgd_solver.cpp:294] Iteration 26810, lr = 0.02
I0526 05:26:28.389386 15117 solver.cpp:233] Iteration 26820, loss = 0.142096
I0526 05:26:28.389427 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.142096 (* 1 = 0.142096 loss)
I0526 05:26:28.389436 15117 sgd_solver.cpp:294] Iteration 26820, lr = 0.02
I0526 05:26:34.720825 15117 solver.cpp:233] Iteration 26830, loss = 0.085775
I0526 05:26:34.720870 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0857751 (* 1 = 0.0857751 loss)
I0526 05:26:34.720880 15117 sgd_solver.cpp:294] Iteration 26830, lr = 0.02
I0526 05:26:41.056576 15117 solver.cpp:233] Iteration 26840, loss = 0.0480737
I0526 05:26:41.056617 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0480738 (* 1 = 0.0480738 loss)
I0526 05:26:41.056624 15117 sgd_solver.cpp:294] Iteration 26840, lr = 0.02
I0526 05:26:47.389626 15117 solver.cpp:233] Iteration 26850, loss = 0.121622
I0526 05:26:47.389667 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.121622 (* 1 = 0.121622 loss)
I0526 05:26:47.389674 15117 sgd_solver.cpp:294] Iteration 26850, lr = 0.02
I0526 05:26:53.723110 15117 solver.cpp:233] Iteration 26860, loss = 0.101709
I0526 05:26:53.723351 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.101709 (* 1 = 0.101709 loss)
I0526 05:26:53.723379 15117 sgd_solver.cpp:294] Iteration 26860, lr = 0.02
I0526 05:27:00.059097 15117 solver.cpp:233] Iteration 26870, loss = 0.123958
I0526 05:27:00.059140 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.123958 (* 1 = 0.123958 loss)
I0526 05:27:00.059152 15117 sgd_solver.cpp:294] Iteration 26870, lr = 0.02
I0526 05:27:06.391515 15117 solver.cpp:233] Iteration 26880, loss = 0.0783844
I0526 05:27:06.391540 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0783845 (* 1 = 0.0783845 loss)
I0526 05:27:06.391546 15117 sgd_solver.cpp:294] Iteration 26880, lr = 0.02
I0526 05:27:12.728152 15117 solver.cpp:233] Iteration 26890, loss = 0.0473084
I0526 05:27:12.728191 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0473085 (* 1 = 0.0473085 loss)
I0526 05:27:12.728199 15117 sgd_solver.cpp:294] Iteration 26890, lr = 0.02
I0526 05:27:18.465209 15117 solver.cpp:342] Iteration 26900, Testing net (#0)
I0526 05:27:31.301873 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8493
I0526 05:27:31.302163 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.561859 (* 1 = 0.561859 loss)
I0526 05:27:31.904623 15117 solver.cpp:233] Iteration 26900, loss = 0.122474
I0526 05:27:31.904659 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.122474 (* 1 = 0.122474 loss)
I0526 05:27:31.904665 15117 sgd_solver.cpp:294] Iteration 26900, lr = 0.02
I0526 05:27:38.239599 15117 solver.cpp:233] Iteration 26910, loss = 0.100539
I0526 05:27:38.239637 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.100539 (* 1 = 0.100539 loss)
I0526 05:27:38.239644 15117 sgd_solver.cpp:294] Iteration 26910, lr = 0.02
I0526 05:27:44.575003 15117 solver.cpp:233] Iteration 26920, loss = 0.169882
I0526 05:27:44.575047 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.169882 (* 1 = 0.169882 loss)
I0526 05:27:44.575053 15117 sgd_solver.cpp:294] Iteration 26920, lr = 0.02
I0526 05:27:50.908866 15117 solver.cpp:233] Iteration 26930, loss = 0.15627
I0526 05:27:50.908905 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.15627 (* 1 = 0.15627 loss)
I0526 05:27:50.908911 15117 sgd_solver.cpp:294] Iteration 26930, lr = 0.02
I0526 05:27:57.246140 15117 solver.cpp:233] Iteration 26940, loss = 0.133797
I0526 05:27:57.246177 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.133797 (* 1 = 0.133797 loss)
I0526 05:27:57.246184 15117 sgd_solver.cpp:294] Iteration 26940, lr = 0.02
I0526 05:28:03.584014 15117 solver.cpp:233] Iteration 26950, loss = 0.0912773
I0526 05:28:03.584239 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0912775 (* 1 = 0.0912775 loss)
I0526 05:28:03.584269 15117 sgd_solver.cpp:294] Iteration 26950, lr = 0.02
I0526 05:28:09.921141 15117 solver.cpp:233] Iteration 26960, loss = 0.0608424
I0526 05:28:09.921188 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0608425 (* 1 = 0.0608425 loss)
I0526 05:28:09.921196 15117 sgd_solver.cpp:294] Iteration 26960, lr = 0.02
I0526 05:28:16.254366 15117 solver.cpp:233] Iteration 26970, loss = 0.127935
I0526 05:28:16.254428 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.127935 (* 1 = 0.127935 loss)
I0526 05:28:16.254436 15117 sgd_solver.cpp:294] Iteration 26970, lr = 0.02
I0526 05:28:22.587532 15117 solver.cpp:233] Iteration 26980, loss = 0.0593133
I0526 05:28:22.587574 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0593135 (* 1 = 0.0593135 loss)
I0526 05:28:22.587579 15117 sgd_solver.cpp:294] Iteration 26980, lr = 0.02
I0526 05:28:28.922775 15117 solver.cpp:233] Iteration 26990, loss = 0.0840753
I0526 05:28:28.922818 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0840754 (* 1 = 0.0840754 loss)
I0526 05:28:28.922827 15117 sgd_solver.cpp:294] Iteration 26990, lr = 0.02
I0526 05:28:34.652861 15117 solver.cpp:342] Iteration 27000, Testing net (#0)
I0526 05:28:47.492892 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8064
I0526 05:28:47.492946 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.779795 (* 1 = 0.779795 loss)
I0526 05:28:48.094434 15117 solver.cpp:233] Iteration 27000, loss = 0.132538
I0526 05:28:48.094470 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.132538 (* 1 = 0.132538 loss)
I0526 05:28:48.094483 15117 sgd_solver.cpp:294] Iteration 27000, lr = 0.02
I0526 05:28:54.429150 15117 solver.cpp:233] Iteration 27010, loss = 0.134975
I0526 05:28:54.429188 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.134976 (* 1 = 0.134976 loss)
I0526 05:28:54.429195 15117 sgd_solver.cpp:294] Iteration 27010, lr = 0.02
I0526 05:29:00.763072 15117 solver.cpp:233] Iteration 27020, loss = 0.0639303
I0526 05:29:00.763113 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0639304 (* 1 = 0.0639304 loss)
I0526 05:29:00.763120 15117 sgd_solver.cpp:294] Iteration 27020, lr = 0.02
I0526 05:29:07.096365 15117 solver.cpp:233] Iteration 27030, loss = 0.110595
I0526 05:29:07.096649 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.110595 (* 1 = 0.110595 loss)
I0526 05:29:07.096678 15117 sgd_solver.cpp:294] Iteration 27030, lr = 0.02
I0526 05:29:13.435987 15117 solver.cpp:233] Iteration 27040, loss = 0.110009
I0526 05:29:13.436030 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.110009 (* 1 = 0.110009 loss)
I0526 05:29:13.436038 15117 sgd_solver.cpp:294] Iteration 27040, lr = 0.02
I0526 05:29:19.775249 15117 solver.cpp:233] Iteration 27050, loss = 0.124441
I0526 05:29:19.775290 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.124441 (* 1 = 0.124441 loss)
I0526 05:29:19.775296 15117 sgd_solver.cpp:294] Iteration 27050, lr = 0.02
I0526 05:29:26.110812 15117 solver.cpp:233] Iteration 27060, loss = 0.19433
I0526 05:29:26.110857 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.19433 (* 1 = 0.19433 loss)
I0526 05:29:26.110864 15117 sgd_solver.cpp:294] Iteration 27060, lr = 0.02
I0526 05:29:32.444486 15117 solver.cpp:233] Iteration 27070, loss = 0.122113
I0526 05:29:32.444521 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.122113 (* 1 = 0.122113 loss)
I0526 05:29:32.444528 15117 sgd_solver.cpp:294] Iteration 27070, lr = 0.02
I0526 05:29:38.777822 15117 solver.cpp:233] Iteration 27080, loss = 0.0411415
I0526 05:29:38.778015 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0411416 (* 1 = 0.0411416 loss)
I0526 05:29:38.778045 15117 sgd_solver.cpp:294] Iteration 27080, lr = 0.02
I0526 05:29:45.111131 15117 solver.cpp:233] Iteration 27090, loss = 0.0996546
I0526 05:29:45.111174 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0996548 (* 1 = 0.0996548 loss)
I0526 05:29:45.111183 15117 sgd_solver.cpp:294] Iteration 27090, lr = 0.02
I0526 05:29:50.844871 15117 solver.cpp:342] Iteration 27100, Testing net (#0)
I0526 05:30:03.681068 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.849
I0526 05:30:03.681113 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.558356 (* 1 = 0.558356 loss)
I0526 05:30:04.281581 15117 solver.cpp:233] Iteration 27100, loss = 0.0293932
I0526 05:30:04.281616 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0293933 (* 1 = 0.0293933 loss)
I0526 05:30:04.281623 15117 sgd_solver.cpp:294] Iteration 27100, lr = 0.02
I0526 05:30:10.617199 15117 solver.cpp:233] Iteration 27110, loss = 0.0751298
I0526 05:30:10.617436 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.07513 (* 1 = 0.07513 loss)
I0526 05:30:10.617465 15117 sgd_solver.cpp:294] Iteration 27110, lr = 0.02
I0526 05:30:16.952383 15117 solver.cpp:233] Iteration 27120, loss = 0.0647255
I0526 05:30:16.952425 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0647256 (* 1 = 0.0647256 loss)
I0526 05:30:16.952442 15117 sgd_solver.cpp:294] Iteration 27120, lr = 0.02
I0526 05:30:23.289237 15117 solver.cpp:233] Iteration 27130, loss = 0.245987
I0526 05:30:23.289279 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.245987 (* 1 = 0.245987 loss)
I0526 05:30:23.289286 15117 sgd_solver.cpp:294] Iteration 27130, lr = 0.02
I0526 05:30:29.624173 15117 solver.cpp:233] Iteration 27140, loss = 0.0928123
I0526 05:30:29.624218 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0928124 (* 1 = 0.0928124 loss)
I0526 05:30:29.624231 15117 sgd_solver.cpp:294] Iteration 27140, lr = 0.02
I0526 05:30:35.959671 15117 solver.cpp:233] Iteration 27150, loss = 0.19007
I0526 05:30:35.959709 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.19007 (* 1 = 0.19007 loss)
I0526 05:30:35.959717 15117 sgd_solver.cpp:294] Iteration 27150, lr = 0.02
I0526 05:30:42.295135 15117 solver.cpp:233] Iteration 27160, loss = 0.125937
I0526 05:30:42.295418 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.125937 (* 1 = 0.125937 loss)
I0526 05:30:42.295444 15117 sgd_solver.cpp:294] Iteration 27160, lr = 0.02
I0526 05:30:48.628080 15117 solver.cpp:233] Iteration 27170, loss = 0.135013
I0526 05:30:48.628118 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.135013 (* 1 = 0.135013 loss)
I0526 05:30:48.628125 15117 sgd_solver.cpp:294] Iteration 27170, lr = 0.02
I0526 05:30:54.965529 15117 solver.cpp:233] Iteration 27180, loss = 0.121179
I0526 05:30:54.965575 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.12118 (* 1 = 0.12118 loss)
I0526 05:30:54.965584 15117 sgd_solver.cpp:294] Iteration 27180, lr = 0.02
I0526 05:31:01.302425 15117 solver.cpp:233] Iteration 27190, loss = 0.0506465
I0526 05:31:01.302464 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0506466 (* 1 = 0.0506466 loss)
I0526 05:31:01.302470 15117 sgd_solver.cpp:294] Iteration 27190, lr = 0.02
I0526 05:31:07.036396 15117 solver.cpp:342] Iteration 27200, Testing net (#0)
I0526 05:31:19.883874 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8039
I0526 05:31:19.884116 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.785351 (* 1 = 0.785351 loss)
I0526 05:31:20.485895 15117 solver.cpp:233] Iteration 27200, loss = 0.134353
I0526 05:31:20.485934 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.134353 (* 1 = 0.134353 loss)
I0526 05:31:20.485940 15117 sgd_solver.cpp:294] Iteration 27200, lr = 0.02
I0526 05:31:26.823123 15117 solver.cpp:233] Iteration 27210, loss = 0.0985595
I0526 05:31:26.823166 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0985596 (* 1 = 0.0985596 loss)
I0526 05:31:26.823173 15117 sgd_solver.cpp:294] Iteration 27210, lr = 0.02
I0526 05:31:33.155905 15117 solver.cpp:233] Iteration 27220, loss = 0.054628
I0526 05:31:33.155959 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0546281 (* 1 = 0.0546281 loss)
I0526 05:31:33.155968 15117 sgd_solver.cpp:294] Iteration 27220, lr = 0.02
I0526 05:31:39.486081 15117 solver.cpp:233] Iteration 27230, loss = 0.0816159
I0526 05:31:39.486130 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0816161 (* 1 = 0.0816161 loss)
I0526 05:31:39.486140 15117 sgd_solver.cpp:294] Iteration 27230, lr = 0.02
I0526 05:31:45.814376 15117 solver.cpp:233] Iteration 27240, loss = 0.0884891
I0526 05:31:45.814430 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0884892 (* 1 = 0.0884892 loss)
I0526 05:31:45.814440 15117 sgd_solver.cpp:294] Iteration 27240, lr = 0.02
I0526 05:31:52.142230 15117 solver.cpp:233] Iteration 27250, loss = 0.13512
I0526 05:31:52.142493 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.13512 (* 1 = 0.13512 loss)
I0526 05:31:52.142523 15117 sgd_solver.cpp:294] Iteration 27250, lr = 0.02
I0526 05:31:58.481274 15117 solver.cpp:233] Iteration 27260, loss = 0.102887
I0526 05:31:58.481320 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.102887 (* 1 = 0.102887 loss)
I0526 05:31:58.481328 15117 sgd_solver.cpp:294] Iteration 27260, lr = 0.02
I0526 05:32:04.820719 15117 solver.cpp:233] Iteration 27270, loss = 0.13938
I0526 05:32:04.820761 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.13938 (* 1 = 0.13938 loss)
I0526 05:32:04.820770 15117 sgd_solver.cpp:294] Iteration 27270, lr = 0.02
I0526 05:32:11.153017 15117 solver.cpp:233] Iteration 27280, loss = 0.135106
I0526 05:32:11.153067 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.135106 (* 1 = 0.135106 loss)
I0526 05:32:11.153079 15117 sgd_solver.cpp:294] Iteration 27280, lr = 0.02
I0526 05:32:17.490512 15117 solver.cpp:233] Iteration 27290, loss = 0.0935028
I0526 05:32:17.490553 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0935029 (* 1 = 0.0935029 loss)
I0526 05:32:17.490561 15117 sgd_solver.cpp:294] Iteration 27290, lr = 0.02
I0526 05:32:23.223510 15117 solver.cpp:342] Iteration 27300, Testing net (#0)
I0526 05:32:36.063506 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8413
I0526 05:32:36.063550 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.6259 (* 1 = 0.6259 loss)
I0526 05:32:36.665108 15117 solver.cpp:233] Iteration 27300, loss = 0.144071
I0526 05:32:36.665145 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.144071 (* 1 = 0.144071 loss)
I0526 05:32:36.665153 15117 sgd_solver.cpp:294] Iteration 27300, lr = 0.02
I0526 05:32:42.999361 15117 solver.cpp:233] Iteration 27310, loss = 0.044435
I0526 05:32:42.999402 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0444352 (* 1 = 0.0444352 loss)
I0526 05:32:42.999408 15117 sgd_solver.cpp:294] Iteration 27310, lr = 0.02
I0526 05:32:49.332345 15117 solver.cpp:233] Iteration 27320, loss = 0.166204
I0526 05:32:49.332387 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.166204 (* 1 = 0.166204 loss)
I0526 05:32:49.332394 15117 sgd_solver.cpp:294] Iteration 27320, lr = 0.02
I0526 05:32:55.669345 15117 solver.cpp:233] Iteration 27330, loss = 0.0881663
I0526 05:32:55.669561 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0881664 (* 1 = 0.0881664 loss)
I0526 05:32:55.669589 15117 sgd_solver.cpp:294] Iteration 27330, lr = 0.02
I0526 05:33:02.003639 15117 solver.cpp:233] Iteration 27340, loss = 0.144679
I0526 05:33:02.003679 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.144679 (* 1 = 0.144679 loss)
I0526 05:33:02.003685 15117 sgd_solver.cpp:294] Iteration 27340, lr = 0.02
I0526 05:33:08.344930 15117 solver.cpp:233] Iteration 27350, loss = 0.160606
I0526 05:33:08.344974 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.160606 (* 1 = 0.160606 loss)
I0526 05:33:08.344981 15117 sgd_solver.cpp:294] Iteration 27350, lr = 0.02
I0526 05:33:14.674100 15117 solver.cpp:233] Iteration 27360, loss = 0.0850485
I0526 05:33:14.674139 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0850487 (* 1 = 0.0850487 loss)
I0526 05:33:14.674146 15117 sgd_solver.cpp:294] Iteration 27360, lr = 0.02
I0526 05:33:21.009739 15117 solver.cpp:233] Iteration 27370, loss = 0.134338
I0526 05:33:21.009802 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.134338 (* 1 = 0.134338 loss)
I0526 05:33:21.009809 15117 sgd_solver.cpp:294] Iteration 27370, lr = 0.02
I0526 05:33:27.349472 15117 solver.cpp:233] Iteration 27380, loss = 0.0444914
I0526 05:33:27.349689 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0444916 (* 1 = 0.0444916 loss)
I0526 05:33:27.349719 15117 sgd_solver.cpp:294] Iteration 27380, lr = 0.02
I0526 05:33:33.687389 15117 solver.cpp:233] Iteration 27390, loss = 0.0464467
I0526 05:33:33.687433 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0464468 (* 1 = 0.0464468 loss)
I0526 05:33:33.687440 15117 sgd_solver.cpp:294] Iteration 27390, lr = 0.02
I0526 05:33:39.426705 15117 solver.cpp:342] Iteration 27400, Testing net (#0)
I0526 05:33:52.271316 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8224
I0526 05:33:52.271363 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.705052 (* 1 = 0.705052 loss)
I0526 05:33:52.871721 15117 solver.cpp:233] Iteration 27400, loss = 0.089194
I0526 05:33:52.871773 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0891941 (* 1 = 0.0891941 loss)
I0526 05:33:52.871781 15117 sgd_solver.cpp:294] Iteration 27400, lr = 0.02
I0526 05:33:59.208108 15117 solver.cpp:233] Iteration 27410, loss = 0.124486
I0526 05:33:59.208369 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.124486 (* 1 = 0.124486 loss)
I0526 05:33:59.208410 15117 sgd_solver.cpp:294] Iteration 27410, lr = 0.02
I0526 05:34:05.545500 15117 solver.cpp:233] Iteration 27420, loss = 0.199195
I0526 05:34:05.545542 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.199195 (* 1 = 0.199195 loss)
I0526 05:34:05.545548 15117 sgd_solver.cpp:294] Iteration 27420, lr = 0.02
I0526 05:34:11.885707 15117 solver.cpp:233] Iteration 27430, loss = 0.118734
I0526 05:34:11.885746 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.118734 (* 1 = 0.118734 loss)
I0526 05:34:11.885754 15117 sgd_solver.cpp:294] Iteration 27430, lr = 0.02
I0526 05:34:18.220906 15117 solver.cpp:233] Iteration 27440, loss = 0.0834207
I0526 05:34:18.220950 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0834208 (* 1 = 0.0834208 loss)
I0526 05:34:18.220957 15117 sgd_solver.cpp:294] Iteration 27440, lr = 0.02
I0526 05:34:24.557324 15117 solver.cpp:233] Iteration 27450, loss = 0.120137
I0526 05:34:24.557364 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.120138 (* 1 = 0.120138 loss)
I0526 05:34:24.557371 15117 sgd_solver.cpp:294] Iteration 27450, lr = 0.02
I0526 05:34:30.895387 15117 solver.cpp:233] Iteration 27460, loss = 0.128602
I0526 05:34:30.895602 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.128602 (* 1 = 0.128602 loss)
I0526 05:34:30.895637 15117 sgd_solver.cpp:294] Iteration 27460, lr = 0.02
I0526 05:34:37.227490 15117 solver.cpp:233] Iteration 27470, loss = 0.0821625
I0526 05:34:37.227535 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0821626 (* 1 = 0.0821626 loss)
I0526 05:34:37.227541 15117 sgd_solver.cpp:294] Iteration 27470, lr = 0.02
I0526 05:34:43.561455 15117 solver.cpp:233] Iteration 27480, loss = 0.148643
I0526 05:34:43.561496 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.148643 (* 1 = 0.148643 loss)
I0526 05:34:43.561503 15117 sgd_solver.cpp:294] Iteration 27480, lr = 0.02
I0526 05:34:49.897066 15117 solver.cpp:233] Iteration 27490, loss = 0.129794
I0526 05:34:49.897111 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.129794 (* 1 = 0.129794 loss)
I0526 05:34:49.897119 15117 sgd_solver.cpp:294] Iteration 27490, lr = 0.02
I0526 05:34:55.629490 15117 solver.cpp:342] Iteration 27500, Testing net (#0)
I0526 05:35:08.468241 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8198
I0526 05:35:08.468466 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.711406 (* 1 = 0.711406 loss)
I0526 05:35:09.067914 15117 solver.cpp:233] Iteration 27500, loss = 0.151833
I0526 05:35:09.067956 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.151833 (* 1 = 0.151833 loss)
I0526 05:35:09.067965 15117 sgd_solver.cpp:294] Iteration 27500, lr = 0.02
I0526 05:35:15.405366 15117 solver.cpp:233] Iteration 27510, loss = 0.109277
I0526 05:35:15.405407 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.109277 (* 1 = 0.109277 loss)
I0526 05:35:15.405414 15117 sgd_solver.cpp:294] Iteration 27510, lr = 0.02
I0526 05:35:21.742032 15117 solver.cpp:233] Iteration 27520, loss = 0.116668
I0526 05:35:21.742071 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.116668 (* 1 = 0.116668 loss)
I0526 05:35:21.742079 15117 sgd_solver.cpp:294] Iteration 27520, lr = 0.02
I0526 05:35:28.078981 15117 solver.cpp:233] Iteration 27530, loss = 0.102006
I0526 05:35:28.079022 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.102006 (* 1 = 0.102006 loss)
I0526 05:35:28.079030 15117 sgd_solver.cpp:294] Iteration 27530, lr = 0.02
I0526 05:35:34.413835 15117 solver.cpp:233] Iteration 27540, loss = 0.0983597
I0526 05:35:34.413892 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0983598 (* 1 = 0.0983598 loss)
I0526 05:35:34.413900 15117 sgd_solver.cpp:294] Iteration 27540, lr = 0.02
I0526 05:35:40.752326 15117 solver.cpp:233] Iteration 27550, loss = 0.11365
I0526 05:35:40.752605 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.113651 (* 1 = 0.113651 loss)
I0526 05:35:40.752645 15117 sgd_solver.cpp:294] Iteration 27550, lr = 0.02
I0526 05:35:47.086324 15117 solver.cpp:233] Iteration 27560, loss = 0.0935328
I0526 05:35:47.086369 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0935329 (* 1 = 0.0935329 loss)
I0526 05:35:47.086376 15117 sgd_solver.cpp:294] Iteration 27560, lr = 0.02
I0526 05:35:53.426448 15117 solver.cpp:233] Iteration 27570, loss = 0.0935795
I0526 05:35:53.426488 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0935796 (* 1 = 0.0935796 loss)
I0526 05:35:53.426496 15117 sgd_solver.cpp:294] Iteration 27570, lr = 0.02
I0526 05:35:59.763449 15117 solver.cpp:233] Iteration 27580, loss = 0.0805034
I0526 05:35:59.763494 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0805035 (* 1 = 0.0805035 loss)
I0526 05:35:59.763500 15117 sgd_solver.cpp:294] Iteration 27580, lr = 0.02
I0526 05:36:06.101816 15117 solver.cpp:233] Iteration 27590, loss = 0.0959478
I0526 05:36:06.101858 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.095948 (* 1 = 0.095948 loss)
I0526 05:36:06.101866 15117 sgd_solver.cpp:294] Iteration 27590, lr = 0.02
I0526 05:36:11.842016 15117 solver.cpp:342] Iteration 27600, Testing net (#0)
I0526 05:36:24.679668 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.809
I0526 05:36:24.679716 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.791965 (* 1 = 0.791965 loss)
I0526 05:36:25.280025 15117 solver.cpp:233] Iteration 27600, loss = 0.127762
I0526 05:36:25.280086 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.127762 (* 1 = 0.127762 loss)
I0526 05:36:25.280097 15117 sgd_solver.cpp:294] Iteration 27600, lr = 0.02
I0526 05:36:31.612756 15117 solver.cpp:233] Iteration 27610, loss = 0.112622
I0526 05:36:31.612797 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.112622 (* 1 = 0.112622 loss)
I0526 05:36:31.612802 15117 sgd_solver.cpp:294] Iteration 27610, lr = 0.02
I0526 05:36:37.951387 15117 solver.cpp:233] Iteration 27620, loss = 0.0576843
I0526 05:36:37.951429 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0576844 (* 1 = 0.0576844 loss)
I0526 05:36:37.951437 15117 sgd_solver.cpp:294] Iteration 27620, lr = 0.02
I0526 05:36:44.290928 15117 solver.cpp:233] Iteration 27630, loss = 0.0854598
I0526 05:36:44.291064 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.08546 (* 1 = 0.08546 loss)
I0526 05:36:44.291071 15117 sgd_solver.cpp:294] Iteration 27630, lr = 0.02
I0526 05:36:50.632030 15117 solver.cpp:233] Iteration 27640, loss = 0.0822948
I0526 05:36:50.632068 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0822949 (* 1 = 0.0822949 loss)
I0526 05:36:50.632076 15117 sgd_solver.cpp:294] Iteration 27640, lr = 0.02
I0526 05:36:56.967782 15117 solver.cpp:233] Iteration 27650, loss = 0.155656
I0526 05:36:56.967821 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.155656 (* 1 = 0.155656 loss)
I0526 05:36:56.967829 15117 sgd_solver.cpp:294] Iteration 27650, lr = 0.02
I0526 05:37:03.305054 15117 solver.cpp:233] Iteration 27660, loss = 0.0651748
I0526 05:37:03.305102 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.065175 (* 1 = 0.065175 loss)
I0526 05:37:03.305110 15117 sgd_solver.cpp:294] Iteration 27660, lr = 0.02
I0526 05:37:09.644660 15117 solver.cpp:233] Iteration 27670, loss = 0.120185
I0526 05:37:09.644701 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.120185 (* 1 = 0.120185 loss)
I0526 05:37:09.644708 15117 sgd_solver.cpp:294] Iteration 27670, lr = 0.02
I0526 05:37:15.980726 15117 solver.cpp:233] Iteration 27680, loss = 0.0652926
I0526 05:37:15.980958 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0652927 (* 1 = 0.0652927 loss)
I0526 05:37:15.980988 15117 sgd_solver.cpp:294] Iteration 27680, lr = 0.02
I0526 05:37:22.313374 15117 solver.cpp:233] Iteration 27690, loss = 0.0980932
I0526 05:37:22.313419 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0980934 (* 1 = 0.0980934 loss)
I0526 05:37:22.313432 15117 sgd_solver.cpp:294] Iteration 27690, lr = 0.02
I0526 05:37:28.045969 15117 solver.cpp:342] Iteration 27700, Testing net (#0)
I0526 05:37:40.883694 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8428
I0526 05:37:40.883739 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.652482 (* 1 = 0.652482 loss)
I0526 05:37:41.484864 15117 solver.cpp:233] Iteration 27700, loss = 0.176596
I0526 05:37:41.484906 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.176596 (* 1 = 0.176596 loss)
I0526 05:37:41.484915 15117 sgd_solver.cpp:294] Iteration 27700, lr = 0.02
I0526 05:37:47.823331 15117 solver.cpp:233] Iteration 27710, loss = 0.103874
I0526 05:37:47.823482 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.103874 (* 1 = 0.103874 loss)
I0526 05:37:47.823492 15117 sgd_solver.cpp:294] Iteration 27710, lr = 0.02
I0526 05:37:54.155536 15117 solver.cpp:233] Iteration 27720, loss = 0.0556229
I0526 05:37:54.155596 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.055623 (* 1 = 0.055623 loss)
I0526 05:37:54.155616 15117 sgd_solver.cpp:294] Iteration 27720, lr = 0.02
I0526 05:38:00.491231 15117 solver.cpp:233] Iteration 27730, loss = 0.126441
I0526 05:38:00.491272 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.126441 (* 1 = 0.126441 loss)
I0526 05:38:00.491279 15117 sgd_solver.cpp:294] Iteration 27730, lr = 0.02
I0526 05:38:06.824414 15117 solver.cpp:233] Iteration 27740, loss = 0.0904675
I0526 05:38:06.824453 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0904677 (* 1 = 0.0904677 loss)
I0526 05:38:06.824460 15117 sgd_solver.cpp:294] Iteration 27740, lr = 0.02
I0526 05:38:13.160717 15117 solver.cpp:233] Iteration 27750, loss = 0.0567109
I0526 05:38:13.160748 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.056711 (* 1 = 0.056711 loss)
I0526 05:38:13.160755 15117 sgd_solver.cpp:294] Iteration 27750, lr = 0.02
I0526 05:38:19.495012 15117 solver.cpp:233] Iteration 27760, loss = 0.0776227
I0526 05:38:19.495231 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0776228 (* 1 = 0.0776228 loss)
I0526 05:38:19.495257 15117 sgd_solver.cpp:294] Iteration 27760, lr = 0.02
I0526 05:38:25.832411 15117 solver.cpp:233] Iteration 27770, loss = 0.125443
I0526 05:38:25.832449 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.125443 (* 1 = 0.125443 loss)
I0526 05:38:25.832456 15117 sgd_solver.cpp:294] Iteration 27770, lr = 0.02
I0526 05:38:32.168581 15117 solver.cpp:233] Iteration 27780, loss = 0.063533
I0526 05:38:32.168622 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0635331 (* 1 = 0.0635331 loss)
I0526 05:38:32.168629 15117 sgd_solver.cpp:294] Iteration 27780, lr = 0.02
I0526 05:38:38.499187 15117 solver.cpp:233] Iteration 27790, loss = 0.135589
I0526 05:38:38.499228 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.135589 (* 1 = 0.135589 loss)
I0526 05:38:38.499235 15117 sgd_solver.cpp:294] Iteration 27790, lr = 0.02
I0526 05:38:44.232599 15117 solver.cpp:342] Iteration 27800, Testing net (#0)
I0526 05:38:57.074769 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8283
I0526 05:38:57.075012 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.693838 (* 1 = 0.693838 loss)
I0526 05:38:57.674739 15117 solver.cpp:233] Iteration 27800, loss = 0.0617848
I0526 05:38:57.674782 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0617849 (* 1 = 0.0617849 loss)
I0526 05:38:57.674789 15117 sgd_solver.cpp:294] Iteration 27800, lr = 0.02
I0526 05:39:04.009343 15117 solver.cpp:233] Iteration 27810, loss = 0.152309
I0526 05:39:04.009384 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.152309 (* 1 = 0.152309 loss)
I0526 05:39:04.009390 15117 sgd_solver.cpp:294] Iteration 27810, lr = 0.02
I0526 05:39:10.344849 15117 solver.cpp:233] Iteration 27820, loss = 0.069796
I0526 05:39:10.344889 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0697961 (* 1 = 0.0697961 loss)
I0526 05:39:10.344902 15117 sgd_solver.cpp:294] Iteration 27820, lr = 0.02
I0526 05:39:16.682658 15117 solver.cpp:233] Iteration 27830, loss = 0.0663589
I0526 05:39:16.682698 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0663591 (* 1 = 0.0663591 loss)
I0526 05:39:16.682704 15117 sgd_solver.cpp:294] Iteration 27830, lr = 0.02
I0526 05:39:23.012080 15117 solver.cpp:233] Iteration 27840, loss = 0.101671
I0526 05:39:23.012121 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.101671 (* 1 = 0.101671 loss)
I0526 05:39:23.012128 15117 sgd_solver.cpp:294] Iteration 27840, lr = 0.02
I0526 05:39:29.348633 15117 solver.cpp:233] Iteration 27850, loss = 0.0771473
I0526 05:39:29.348906 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0771475 (* 1 = 0.0771475 loss)
I0526 05:39:29.348937 15117 sgd_solver.cpp:294] Iteration 27850, lr = 0.02
I0526 05:39:35.684350 15117 solver.cpp:233] Iteration 27860, loss = 0.0564324
I0526 05:39:35.684394 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0564325 (* 1 = 0.0564325 loss)
I0526 05:39:35.684401 15117 sgd_solver.cpp:294] Iteration 27860, lr = 0.02
I0526 05:39:42.015743 15117 solver.cpp:233] Iteration 27870, loss = 0.121665
I0526 05:39:42.015785 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.121665 (* 1 = 0.121665 loss)
I0526 05:39:42.015794 15117 sgd_solver.cpp:294] Iteration 27870, lr = 0.02
I0526 05:39:48.350654 15117 solver.cpp:233] Iteration 27880, loss = 0.0821345
I0526 05:39:48.350709 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0821346 (* 1 = 0.0821346 loss)
I0526 05:39:48.350718 15117 sgd_solver.cpp:294] Iteration 27880, lr = 0.02
I0526 05:39:54.685345 15117 solver.cpp:233] Iteration 27890, loss = 0.04727
I0526 05:39:54.685389 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0472701 (* 1 = 0.0472701 loss)
I0526 05:39:54.685395 15117 sgd_solver.cpp:294] Iteration 27890, lr = 0.02
I0526 05:40:00.419193 15117 solver.cpp:342] Iteration 27900, Testing net (#0)
I0526 05:40:13.265182 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.784
I0526 05:40:13.265228 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.989823 (* 1 = 0.989823 loss)
I0526 05:40:13.865941 15117 solver.cpp:233] Iteration 27900, loss = 0.115162
I0526 05:40:13.865973 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.115162 (* 1 = 0.115162 loss)
I0526 05:40:13.865980 15117 sgd_solver.cpp:294] Iteration 27900, lr = 0.02
I0526 05:40:20.201352 15117 solver.cpp:233] Iteration 27910, loss = 0.104096
I0526 05:40:20.201391 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.104096 (* 1 = 0.104096 loss)
I0526 05:40:20.201398 15117 sgd_solver.cpp:294] Iteration 27910, lr = 0.02
I0526 05:40:26.540122 15117 solver.cpp:233] Iteration 27920, loss = 0.212598
I0526 05:40:26.540148 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.212598 (* 1 = 0.212598 loss)
I0526 05:40:26.540154 15117 sgd_solver.cpp:294] Iteration 27920, lr = 0.02
I0526 05:40:32.877106 15117 solver.cpp:233] Iteration 27930, loss = 0.0983934
I0526 05:40:32.877341 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0983936 (* 1 = 0.0983936 loss)
I0526 05:40:32.877369 15117 sgd_solver.cpp:294] Iteration 27930, lr = 0.02
I0526 05:40:39.214685 15117 solver.cpp:233] Iteration 27940, loss = 0.0683557
I0526 05:40:39.214727 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0683559 (* 1 = 0.0683559 loss)
I0526 05:40:39.214735 15117 sgd_solver.cpp:294] Iteration 27940, lr = 0.02
I0526 05:40:45.550087 15117 solver.cpp:233] Iteration 27950, loss = 0.123906
I0526 05:40:45.550132 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.123906 (* 1 = 0.123906 loss)
I0526 05:40:45.550139 15117 sgd_solver.cpp:294] Iteration 27950, lr = 0.02
I0526 05:40:51.888449 15117 solver.cpp:233] Iteration 27960, loss = 0.0289312
I0526 05:40:51.888495 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0289314 (* 1 = 0.0289314 loss)
I0526 05:40:51.888507 15117 sgd_solver.cpp:294] Iteration 27960, lr = 0.02
I0526 05:40:58.225543 15117 solver.cpp:233] Iteration 27970, loss = 0.0657999
I0526 05:40:58.225584 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0658 (* 1 = 0.0658 loss)
I0526 05:40:58.225590 15117 sgd_solver.cpp:294] Iteration 27970, lr = 0.02
I0526 05:41:04.560744 15117 solver.cpp:233] Iteration 27980, loss = 0.0951195
I0526 05:41:04.560994 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0951196 (* 1 = 0.0951196 loss)
I0526 05:41:04.561023 15117 sgd_solver.cpp:294] Iteration 27980, lr = 0.02
I0526 05:41:10.892523 15117 solver.cpp:233] Iteration 27990, loss = 0.123168
I0526 05:41:10.892563 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.123169 (* 1 = 0.123169 loss)
I0526 05:41:10.892570 15117 sgd_solver.cpp:294] Iteration 27990, lr = 0.02
I0526 05:41:16.626682 15117 solver.cpp:342] Iteration 28000, Testing net (#0)
I0526 05:41:29.468394 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.809
I0526 05:41:29.468441 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.818571 (* 1 = 0.818571 loss)
I0526 05:41:30.069576 15117 solver.cpp:233] Iteration 28000, loss = 0.0746979
I0526 05:41:30.069599 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.074698 (* 1 = 0.074698 loss)
I0526 05:41:30.069607 15117 sgd_solver.cpp:294] Iteration 28000, lr = 0.02
I0526 05:41:36.405953 15117 solver.cpp:233] Iteration 28010, loss = 0.0689439
I0526 05:41:36.406193 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.068944 (* 1 = 0.068944 loss)
I0526 05:41:36.406221 15117 sgd_solver.cpp:294] Iteration 28010, lr = 0.02
I0526 05:41:42.741399 15117 solver.cpp:233] Iteration 28020, loss = 0.0800304
I0526 05:41:42.741444 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0800305 (* 1 = 0.0800305 loss)
I0526 05:41:42.741451 15117 sgd_solver.cpp:294] Iteration 28020, lr = 0.02
I0526 05:41:49.078970 15117 solver.cpp:233] Iteration 28030, loss = 0.092711
I0526 05:41:49.079010 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0927111 (* 1 = 0.0927111 loss)
I0526 05:41:49.079018 15117 sgd_solver.cpp:294] Iteration 28030, lr = 0.02
I0526 05:41:55.413522 15117 solver.cpp:233] Iteration 28040, loss = 0.10439
I0526 05:41:55.413583 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.10439 (* 1 = 0.10439 loss)
I0526 05:41:55.413591 15117 sgd_solver.cpp:294] Iteration 28040, lr = 0.02
I0526 05:42:01.748461 15117 solver.cpp:233] Iteration 28050, loss = 0.10272
I0526 05:42:01.748513 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.10272 (* 1 = 0.10272 loss)
I0526 05:42:01.748533 15117 sgd_solver.cpp:294] Iteration 28050, lr = 0.02
I0526 05:42:08.086571 15117 solver.cpp:233] Iteration 28060, loss = 0.0753644
I0526 05:42:08.086796 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0753645 (* 1 = 0.0753645 loss)
I0526 05:42:08.086827 15117 sgd_solver.cpp:294] Iteration 28060, lr = 0.02
I0526 05:42:14.419338 15117 solver.cpp:233] Iteration 28070, loss = 0.135284
I0526 05:42:14.419381 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.135284 (* 1 = 0.135284 loss)
I0526 05:42:14.419389 15117 sgd_solver.cpp:294] Iteration 28070, lr = 0.02
I0526 05:42:20.756256 15117 solver.cpp:233] Iteration 28080, loss = 0.11312
I0526 05:42:20.756314 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.11312 (* 1 = 0.11312 loss)
I0526 05:42:20.756322 15117 sgd_solver.cpp:294] Iteration 28080, lr = 0.02
I0526 05:42:27.093627 15117 solver.cpp:233] Iteration 28090, loss = 0.0313128
I0526 05:42:27.093668 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.031313 (* 1 = 0.031313 loss)
I0526 05:42:27.093675 15117 sgd_solver.cpp:294] Iteration 28090, lr = 0.02
I0526 05:42:32.831338 15117 solver.cpp:342] Iteration 28100, Testing net (#0)
I0526 05:42:45.678413 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8154
I0526 05:42:45.678694 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.821408 (* 1 = 0.821408 loss)
I0526 05:42:46.280753 15117 solver.cpp:233] Iteration 28100, loss = 0.0940364
I0526 05:42:46.280802 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0940365 (* 1 = 0.0940365 loss)
I0526 05:42:46.280809 15117 sgd_solver.cpp:294] Iteration 28100, lr = 0.02
I0526 05:42:52.617432 15117 solver.cpp:233] Iteration 28110, loss = 0.0549907
I0526 05:42:52.617470 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0549908 (* 1 = 0.0549908 loss)
I0526 05:42:52.617478 15117 sgd_solver.cpp:294] Iteration 28110, lr = 0.02
I0526 05:42:58.955813 15117 solver.cpp:233] Iteration 28120, loss = 0.0690998
I0526 05:42:58.955854 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0691 (* 1 = 0.0691 loss)
I0526 05:42:58.955862 15117 sgd_solver.cpp:294] Iteration 28120, lr = 0.02
I0526 05:43:05.296871 15117 solver.cpp:233] Iteration 28130, loss = 0.129226
I0526 05:43:05.296910 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.129226 (* 1 = 0.129226 loss)
I0526 05:43:05.296916 15117 sgd_solver.cpp:294] Iteration 28130, lr = 0.02
I0526 05:43:11.633194 15117 solver.cpp:233] Iteration 28140, loss = 0.127229
I0526 05:43:11.633234 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.127229 (* 1 = 0.127229 loss)
I0526 05:43:11.633241 15117 sgd_solver.cpp:294] Iteration 28140, lr = 0.02
I0526 05:43:17.971596 15117 solver.cpp:233] Iteration 28150, loss = 0.101131
I0526 05:43:17.971834 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.101131 (* 1 = 0.101131 loss)
I0526 05:43:17.971863 15117 sgd_solver.cpp:294] Iteration 28150, lr = 0.02
I0526 05:43:24.303616 15117 solver.cpp:233] Iteration 28160, loss = 0.0769615
I0526 05:43:24.303658 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0769617 (* 1 = 0.0769617 loss)
I0526 05:43:24.303665 15117 sgd_solver.cpp:294] Iteration 28160, lr = 0.02
I0526 05:43:30.638778 15117 solver.cpp:233] Iteration 28170, loss = 0.117938
I0526 05:43:30.638821 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.117939 (* 1 = 0.117939 loss)
I0526 05:43:30.638829 15117 sgd_solver.cpp:294] Iteration 28170, lr = 0.02
I0526 05:43:36.977571 15117 solver.cpp:233] Iteration 28180, loss = 0.174079
I0526 05:43:36.977607 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.174079 (* 1 = 0.174079 loss)
I0526 05:43:36.977615 15117 sgd_solver.cpp:294] Iteration 28180, lr = 0.02
I0526 05:43:43.319878 15117 solver.cpp:233] Iteration 28190, loss = 0.138905
I0526 05:43:43.319918 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.138906 (* 1 = 0.138906 loss)
I0526 05:43:43.319926 15117 sgd_solver.cpp:294] Iteration 28190, lr = 0.02
I0526 05:43:49.056300 15117 solver.cpp:342] Iteration 28200, Testing net (#0)
I0526 05:44:01.909605 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7954
I0526 05:44:01.909653 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.948166 (* 1 = 0.948166 loss)
I0526 05:44:02.511970 15117 solver.cpp:233] Iteration 28200, loss = 0.107593
I0526 05:44:02.511991 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.107593 (* 1 = 0.107593 loss)
I0526 05:44:02.511998 15117 sgd_solver.cpp:294] Iteration 28200, lr = 0.02
I0526 05:44:08.849025 15117 solver.cpp:233] Iteration 28210, loss = 0.0919135
I0526 05:44:08.849064 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0919136 (* 1 = 0.0919136 loss)
I0526 05:44:08.849071 15117 sgd_solver.cpp:294] Iteration 28210, lr = 0.02
I0526 05:44:15.181210 15117 solver.cpp:233] Iteration 28220, loss = 0.117301
I0526 05:44:15.181255 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.117301 (* 1 = 0.117301 loss)
I0526 05:44:15.181264 15117 sgd_solver.cpp:294] Iteration 28220, lr = 0.02
I0526 05:44:21.509590 15117 solver.cpp:233] Iteration 28230, loss = 0.0682775
I0526 05:44:21.509846 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0682776 (* 1 = 0.0682776 loss)
I0526 05:44:21.509886 15117 sgd_solver.cpp:294] Iteration 28230, lr = 0.02
I0526 05:44:27.842207 15117 solver.cpp:233] Iteration 28240, loss = 0.120454
I0526 05:44:27.842252 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.120454 (* 1 = 0.120454 loss)
I0526 05:44:27.842259 15117 sgd_solver.cpp:294] Iteration 28240, lr = 0.02
I0526 05:44:34.174605 15117 solver.cpp:233] Iteration 28250, loss = 0.0990742
I0526 05:44:34.174645 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0990743 (* 1 = 0.0990743 loss)
I0526 05:44:34.174654 15117 sgd_solver.cpp:294] Iteration 28250, lr = 0.02
I0526 05:44:40.505756 15117 solver.cpp:233] Iteration 28260, loss = 0.136427
I0526 05:44:40.505791 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.136427 (* 1 = 0.136427 loss)
I0526 05:44:40.505798 15117 sgd_solver.cpp:294] Iteration 28260, lr = 0.02
I0526 05:44:46.839359 15117 solver.cpp:233] Iteration 28270, loss = 0.089114
I0526 05:44:46.839401 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0891142 (* 1 = 0.0891142 loss)
I0526 05:44:46.839407 15117 sgd_solver.cpp:294] Iteration 28270, lr = 0.02
I0526 05:44:53.177114 15117 solver.cpp:233] Iteration 28280, loss = 0.0610898
I0526 05:44:53.177343 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0610899 (* 1 = 0.0610899 loss)
I0526 05:44:53.177371 15117 sgd_solver.cpp:294] Iteration 28280, lr = 0.02
I0526 05:44:59.515947 15117 solver.cpp:233] Iteration 28290, loss = 0.0547768
I0526 05:44:59.515990 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0547769 (* 1 = 0.0547769 loss)
I0526 05:44:59.515998 15117 sgd_solver.cpp:294] Iteration 28290, lr = 0.02
I0526 05:45:05.252116 15117 solver.cpp:342] Iteration 28300, Testing net (#0)
I0526 05:45:18.100280 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8401
I0526 05:45:18.100325 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.607054 (* 1 = 0.607054 loss)
I0526 05:45:18.701939 15117 solver.cpp:233] Iteration 28300, loss = 0.098458
I0526 05:45:18.701975 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0984581 (* 1 = 0.0984581 loss)
I0526 05:45:18.701983 15117 sgd_solver.cpp:294] Iteration 28300, lr = 0.02
I0526 05:45:25.038025 15117 solver.cpp:233] Iteration 28310, loss = 0.0558554
I0526 05:45:25.038251 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0558555 (* 1 = 0.0558555 loss)
I0526 05:45:25.038278 15117 sgd_solver.cpp:294] Iteration 28310, lr = 0.02
I0526 05:45:31.379741 15117 solver.cpp:233] Iteration 28320, loss = 0.0408557
I0526 05:45:31.379782 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0408559 (* 1 = 0.0408559 loss)
I0526 05:45:31.379789 15117 sgd_solver.cpp:294] Iteration 28320, lr = 0.02
I0526 05:45:37.716313 15117 solver.cpp:233] Iteration 28330, loss = 0.0814594
I0526 05:45:37.716356 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0814596 (* 1 = 0.0814596 loss)
I0526 05:45:37.716363 15117 sgd_solver.cpp:294] Iteration 28330, lr = 0.02
I0526 05:45:44.057147 15117 solver.cpp:233] Iteration 28340, loss = 0.0975827
I0526 05:45:44.057186 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0975828 (* 1 = 0.0975828 loss)
I0526 05:45:44.057193 15117 sgd_solver.cpp:294] Iteration 28340, lr = 0.02
I0526 05:45:50.392705 15117 solver.cpp:233] Iteration 28350, loss = 0.0754297
I0526 05:45:50.392747 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0754298 (* 1 = 0.0754298 loss)
I0526 05:45:50.392755 15117 sgd_solver.cpp:294] Iteration 28350, lr = 0.02
I0526 05:45:56.727978 15117 solver.cpp:233] Iteration 28360, loss = 0.185154
I0526 05:45:56.728188 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.185154 (* 1 = 0.185154 loss)
I0526 05:45:56.728215 15117 sgd_solver.cpp:294] Iteration 28360, lr = 0.02
I0526 05:46:03.061470 15117 solver.cpp:233] Iteration 28370, loss = 0.163162
I0526 05:46:03.061508 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.163162 (* 1 = 0.163162 loss)
I0526 05:46:03.061522 15117 sgd_solver.cpp:294] Iteration 28370, lr = 0.02
I0526 05:46:09.397162 15117 solver.cpp:233] Iteration 28380, loss = 0.0713584
I0526 05:46:09.397200 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0713585 (* 1 = 0.0713585 loss)
I0526 05:46:09.397207 15117 sgd_solver.cpp:294] Iteration 28380, lr = 0.02
I0526 05:46:15.738737 15117 solver.cpp:233] Iteration 28390, loss = 0.185481
I0526 05:46:15.738790 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.185482 (* 1 = 0.185482 loss)
I0526 05:46:15.738800 15117 sgd_solver.cpp:294] Iteration 28390, lr = 0.02
I0526 05:46:21.473723 15117 solver.cpp:342] Iteration 28400, Testing net (#0)
I0526 05:46:34.313598 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7876
I0526 05:46:34.313860 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.03097 (* 1 = 1.03097 loss)
I0526 05:46:34.912830 15117 solver.cpp:233] Iteration 28400, loss = 0.141009
I0526 05:46:34.912863 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.141009 (* 1 = 0.141009 loss)
I0526 05:46:34.912873 15117 sgd_solver.cpp:294] Iteration 28400, lr = 0.02
I0526 05:46:41.247040 15117 solver.cpp:233] Iteration 28410, loss = 0.0653416
I0526 05:46:41.247081 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0653417 (* 1 = 0.0653417 loss)
I0526 05:46:41.247087 15117 sgd_solver.cpp:294] Iteration 28410, lr = 0.02
I0526 05:46:47.581146 15117 solver.cpp:233] Iteration 28420, loss = 0.131577
I0526 05:46:47.581188 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.131577 (* 1 = 0.131577 loss)
I0526 05:46:47.581195 15117 sgd_solver.cpp:294] Iteration 28420, lr = 0.02
I0526 05:46:53.912849 15117 solver.cpp:233] Iteration 28430, loss = 0.093294
I0526 05:46:53.912889 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0932941 (* 1 = 0.0932941 loss)
I0526 05:46:53.912895 15117 sgd_solver.cpp:294] Iteration 28430, lr = 0.02
I0526 05:47:00.248040 15117 solver.cpp:233] Iteration 28440, loss = 0.0867142
I0526 05:47:00.248080 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0867143 (* 1 = 0.0867143 loss)
I0526 05:47:00.248088 15117 sgd_solver.cpp:294] Iteration 28440, lr = 0.02
I0526 05:47:06.581225 15117 solver.cpp:233] Iteration 28450, loss = 0.105555
I0526 05:47:06.581482 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.105555 (* 1 = 0.105555 loss)
I0526 05:47:06.581511 15117 sgd_solver.cpp:294] Iteration 28450, lr = 0.02
I0526 05:47:12.910601 15117 solver.cpp:233] Iteration 28460, loss = 0.166791
I0526 05:47:12.910653 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.166791 (* 1 = 0.166791 loss)
I0526 05:47:12.910661 15117 sgd_solver.cpp:294] Iteration 28460, lr = 0.02
I0526 05:47:19.241194 15117 solver.cpp:233] Iteration 28470, loss = 0.152988
I0526 05:47:19.241232 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.152988 (* 1 = 0.152988 loss)
I0526 05:47:19.241240 15117 sgd_solver.cpp:294] Iteration 28470, lr = 0.02
I0526 05:47:25.581282 15117 solver.cpp:233] Iteration 28480, loss = 0.110404
I0526 05:47:25.581336 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.110404 (* 1 = 0.110404 loss)
I0526 05:47:25.581342 15117 sgd_solver.cpp:294] Iteration 28480, lr = 0.02
I0526 05:47:31.916155 15117 solver.cpp:233] Iteration 28490, loss = 0.0877662
I0526 05:47:31.916195 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0877663 (* 1 = 0.0877663 loss)
I0526 05:47:31.916203 15117 sgd_solver.cpp:294] Iteration 28490, lr = 0.02
I0526 05:47:37.648751 15117 solver.cpp:342] Iteration 28500, Testing net (#0)
I0526 05:47:50.487653 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.832
I0526 05:47:50.487700 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.755872 (* 1 = 0.755872 loss)
I0526 05:47:51.088507 15117 solver.cpp:233] Iteration 28500, loss = 0.0823218
I0526 05:47:51.088546 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0823219 (* 1 = 0.0823219 loss)
I0526 05:47:51.088559 15117 sgd_solver.cpp:294] Iteration 28500, lr = 0.02
I0526 05:47:57.421674 15117 solver.cpp:233] Iteration 28510, loss = 0.11604
I0526 05:47:57.421713 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.11604 (* 1 = 0.11604 loss)
I0526 05:47:57.421720 15117 sgd_solver.cpp:294] Iteration 28510, lr = 0.02
I0526 05:48:03.758666 15117 solver.cpp:233] Iteration 28520, loss = 0.183039
I0526 05:48:03.758716 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.18304 (* 1 = 0.18304 loss)
I0526 05:48:03.758723 15117 sgd_solver.cpp:294] Iteration 28520, lr = 0.02
I0526 05:48:10.094715 15117 solver.cpp:233] Iteration 28530, loss = 0.124276
I0526 05:48:10.094983 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.124276 (* 1 = 0.124276 loss)
I0526 05:48:10.095010 15117 sgd_solver.cpp:294] Iteration 28530, lr = 0.02
I0526 05:48:16.426506 15117 solver.cpp:233] Iteration 28540, loss = 0.0569519
I0526 05:48:16.426553 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.056952 (* 1 = 0.056952 loss)
I0526 05:48:16.426560 15117 sgd_solver.cpp:294] Iteration 28540, lr = 0.02
I0526 05:48:22.761977 15117 solver.cpp:233] Iteration 28550, loss = 0.150853
I0526 05:48:22.762017 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.150853 (* 1 = 0.150853 loss)
I0526 05:48:22.762025 15117 sgd_solver.cpp:294] Iteration 28550, lr = 0.02
I0526 05:48:29.098693 15117 solver.cpp:233] Iteration 28560, loss = 0.133935
I0526 05:48:29.098737 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.133935 (* 1 = 0.133935 loss)
I0526 05:48:29.098744 15117 sgd_solver.cpp:294] Iteration 28560, lr = 0.02
I0526 05:48:35.432602 15117 solver.cpp:233] Iteration 28570, loss = 0.118769
I0526 05:48:35.432643 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.118769 (* 1 = 0.118769 loss)
I0526 05:48:35.432649 15117 sgd_solver.cpp:294] Iteration 28570, lr = 0.02
I0526 05:48:41.771242 15117 solver.cpp:233] Iteration 28580, loss = 0.13908
I0526 05:48:41.771466 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.13908 (* 1 = 0.13908 loss)
I0526 05:48:41.771499 15117 sgd_solver.cpp:294] Iteration 28580, lr = 0.02
I0526 05:48:48.103828 15117 solver.cpp:233] Iteration 28590, loss = 0.101037
I0526 05:48:48.103873 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.101037 (* 1 = 0.101037 loss)
I0526 05:48:48.103879 15117 sgd_solver.cpp:294] Iteration 28590, lr = 0.02
I0526 05:48:53.838150 15117 solver.cpp:342] Iteration 28600, Testing net (#0)
I0526 05:49:06.669889 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.789
I0526 05:49:06.669931 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.965526 (* 1 = 0.965526 loss)
I0526 05:49:07.271312 15117 solver.cpp:233] Iteration 28600, loss = 0.174912
I0526 05:49:07.271358 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.174912 (* 1 = 0.174912 loss)
I0526 05:49:07.271365 15117 sgd_solver.cpp:294] Iteration 28600, lr = 0.02
I0526 05:49:13.609429 15117 solver.cpp:233] Iteration 28610, loss = 0.0834239
I0526 05:49:13.609668 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0834241 (* 1 = 0.0834241 loss)
I0526 05:49:13.609696 15117 sgd_solver.cpp:294] Iteration 28610, lr = 0.02
I0526 05:49:19.943367 15117 solver.cpp:233] Iteration 28620, loss = 0.183199
I0526 05:49:19.943410 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.183199 (* 1 = 0.183199 loss)
I0526 05:49:19.943418 15117 sgd_solver.cpp:294] Iteration 28620, lr = 0.02
I0526 05:49:26.277768 15117 solver.cpp:233] Iteration 28630, loss = 0.0723741
I0526 05:49:26.277811 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0723742 (* 1 = 0.0723742 loss)
I0526 05:49:26.277817 15117 sgd_solver.cpp:294] Iteration 28630, lr = 0.02
I0526 05:49:32.614331 15117 solver.cpp:233] Iteration 28640, loss = 0.0940405
I0526 05:49:32.614378 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0940406 (* 1 = 0.0940406 loss)
I0526 05:49:32.614392 15117 sgd_solver.cpp:294] Iteration 28640, lr = 0.02
I0526 05:49:38.951230 15117 solver.cpp:233] Iteration 28650, loss = 0.111134
I0526 05:49:38.951268 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.111134 (* 1 = 0.111134 loss)
I0526 05:49:38.951274 15117 sgd_solver.cpp:294] Iteration 28650, lr = 0.02
I0526 05:49:45.288779 15117 solver.cpp:233] Iteration 28660, loss = 0.123844
I0526 05:49:45.289037 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.123844 (* 1 = 0.123844 loss)
I0526 05:49:45.289067 15117 sgd_solver.cpp:294] Iteration 28660, lr = 0.02
I0526 05:49:51.621484 15117 solver.cpp:233] Iteration 28670, loss = 0.114259
I0526 05:49:51.621534 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.114259 (* 1 = 0.114259 loss)
I0526 05:49:51.621542 15117 sgd_solver.cpp:294] Iteration 28670, lr = 0.02
I0526 05:49:57.955957 15117 solver.cpp:233] Iteration 28680, loss = 0.0724035
I0526 05:49:57.956006 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0724036 (* 1 = 0.0724036 loss)
I0526 05:49:57.956013 15117 sgd_solver.cpp:294] Iteration 28680, lr = 0.02
I0526 05:50:04.291100 15117 solver.cpp:233] Iteration 28690, loss = 0.135002
I0526 05:50:04.291139 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.135002 (* 1 = 0.135002 loss)
I0526 05:50:04.291146 15117 sgd_solver.cpp:294] Iteration 28690, lr = 0.02
I0526 05:50:10.020081 15117 solver.cpp:342] Iteration 28700, Testing net (#0)
I0526 05:50:22.852741 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8547
I0526 05:50:22.852985 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.582209 (* 1 = 0.582209 loss)
I0526 05:50:23.454023 15117 solver.cpp:233] Iteration 28700, loss = 0.0489295
I0526 05:50:23.454061 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0489296 (* 1 = 0.0489296 loss)
I0526 05:50:23.454067 15117 sgd_solver.cpp:294] Iteration 28700, lr = 0.02
I0526 05:50:29.789860 15117 solver.cpp:233] Iteration 28710, loss = 0.0914791
I0526 05:50:29.789902 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0914792 (* 1 = 0.0914792 loss)
I0526 05:50:29.789909 15117 sgd_solver.cpp:294] Iteration 28710, lr = 0.02
I0526 05:50:36.122548 15117 solver.cpp:233] Iteration 28720, loss = 0.0843157
I0526 05:50:36.122586 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0843158 (* 1 = 0.0843158 loss)
I0526 05:50:36.122593 15117 sgd_solver.cpp:294] Iteration 28720, lr = 0.02
I0526 05:50:42.456106 15117 solver.cpp:233] Iteration 28730, loss = 0.120525
I0526 05:50:42.456166 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.120525 (* 1 = 0.120525 loss)
I0526 05:50:42.456173 15117 sgd_solver.cpp:294] Iteration 28730, lr = 0.02
I0526 05:50:48.793954 15117 solver.cpp:233] Iteration 28740, loss = 0.0996771
I0526 05:50:48.793995 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0996773 (* 1 = 0.0996773 loss)
I0526 05:50:48.794001 15117 sgd_solver.cpp:294] Iteration 28740, lr = 0.02
I0526 05:50:55.125524 15117 solver.cpp:233] Iteration 28750, loss = 0.0967479
I0526 05:50:55.125744 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0967481 (* 1 = 0.0967481 loss)
I0526 05:50:55.125779 15117 sgd_solver.cpp:294] Iteration 28750, lr = 0.02
I0526 05:51:01.460211 15117 solver.cpp:233] Iteration 28760, loss = 0.156892
I0526 05:51:01.460256 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.156892 (* 1 = 0.156892 loss)
I0526 05:51:01.460264 15117 sgd_solver.cpp:294] Iteration 28760, lr = 0.02
I0526 05:51:07.795744 15117 solver.cpp:233] Iteration 28770, loss = 0.15687
I0526 05:51:07.795785 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.15687 (* 1 = 0.15687 loss)
I0526 05:51:07.795794 15117 sgd_solver.cpp:294] Iteration 28770, lr = 0.02
I0526 05:51:14.128656 15117 solver.cpp:233] Iteration 28780, loss = 0.153206
I0526 05:51:14.128711 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.153206 (* 1 = 0.153206 loss)
I0526 05:51:14.128723 15117 sgd_solver.cpp:294] Iteration 28780, lr = 0.02
I0526 05:51:20.464501 15117 solver.cpp:233] Iteration 28790, loss = 0.0514545
I0526 05:51:20.464542 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0514547 (* 1 = 0.0514547 loss)
I0526 05:51:20.464548 15117 sgd_solver.cpp:294] Iteration 28790, lr = 0.02
I0526 05:51:26.198133 15117 solver.cpp:342] Iteration 28800, Testing net (#0)
I0526 05:51:39.022050 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8336
I0526 05:51:39.022097 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.716175 (* 1 = 0.716175 loss)
I0526 05:51:39.622571 15117 solver.cpp:233] Iteration 28800, loss = 0.173165
I0526 05:51:39.622623 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.173165 (* 1 = 0.173165 loss)
I0526 05:51:39.622632 15117 sgd_solver.cpp:294] Iteration 28800, lr = 0.02
I0526 05:51:45.958226 15117 solver.cpp:233] Iteration 28810, loss = 0.124284
I0526 05:51:45.958267 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.124284 (* 1 = 0.124284 loss)
I0526 05:51:45.958274 15117 sgd_solver.cpp:294] Iteration 28810, lr = 0.02
I0526 05:51:52.295958 15117 solver.cpp:233] Iteration 28820, loss = 0.0728501
I0526 05:51:52.295999 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0728502 (* 1 = 0.0728502 loss)
I0526 05:51:52.296005 15117 sgd_solver.cpp:294] Iteration 28820, lr = 0.02
I0526 05:51:58.634307 15117 solver.cpp:233] Iteration 28830, loss = 0.0947995
I0526 05:51:58.634549 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0947996 (* 1 = 0.0947996 loss)
I0526 05:51:58.634585 15117 sgd_solver.cpp:294] Iteration 28830, lr = 0.02
I0526 05:52:04.968618 15117 solver.cpp:233] Iteration 28840, loss = 0.11677
I0526 05:52:04.968659 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.11677 (* 1 = 0.11677 loss)
I0526 05:52:04.968665 15117 sgd_solver.cpp:294] Iteration 28840, lr = 0.02
I0526 05:52:11.304514 15117 solver.cpp:233] Iteration 28850, loss = 0.0854605
I0526 05:52:11.304556 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0854606 (* 1 = 0.0854606 loss)
I0526 05:52:11.304564 15117 sgd_solver.cpp:294] Iteration 28850, lr = 0.02
I0526 05:52:17.641984 15117 solver.cpp:233] Iteration 28860, loss = 0.0906423
I0526 05:52:17.642035 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0906424 (* 1 = 0.0906424 loss)
I0526 05:52:17.642041 15117 sgd_solver.cpp:294] Iteration 28860, lr = 0.02
I0526 05:52:23.976558 15117 solver.cpp:233] Iteration 28870, loss = 0.0573225
I0526 05:52:23.976598 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0573227 (* 1 = 0.0573227 loss)
I0526 05:52:23.976604 15117 sgd_solver.cpp:294] Iteration 28870, lr = 0.02
I0526 05:52:30.312958 15117 solver.cpp:233] Iteration 28880, loss = 0.0690515
I0526 05:52:30.313190 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0690517 (* 1 = 0.0690517 loss)
I0526 05:52:30.313220 15117 sgd_solver.cpp:294] Iteration 28880, lr = 0.02
I0526 05:52:36.643975 15117 solver.cpp:233] Iteration 28890, loss = 0.141299
I0526 05:52:36.644016 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.141299 (* 1 = 0.141299 loss)
I0526 05:52:36.644022 15117 sgd_solver.cpp:294] Iteration 28890, lr = 0.02
I0526 05:52:42.379828 15117 solver.cpp:342] Iteration 28900, Testing net (#0)
I0526 05:52:55.226306 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7891
I0526 05:52:55.226349 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.00977 (* 1 = 1.00977 loss)
I0526 05:52:55.827728 15117 solver.cpp:233] Iteration 28900, loss = 0.0433182
I0526 05:52:55.827775 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0433183 (* 1 = 0.0433183 loss)
I0526 05:52:55.827793 15117 sgd_solver.cpp:294] Iteration 28900, lr = 0.02
I0526 05:53:02.162603 15117 solver.cpp:233] Iteration 28910, loss = 0.0836812
I0526 05:53:02.162864 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0836813 (* 1 = 0.0836813 loss)
I0526 05:53:02.162904 15117 sgd_solver.cpp:294] Iteration 28910, lr = 0.02
I0526 05:53:08.499927 15117 solver.cpp:233] Iteration 28920, loss = 0.118013
I0526 05:53:08.499966 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.118013 (* 1 = 0.118013 loss)
I0526 05:53:08.499974 15117 sgd_solver.cpp:294] Iteration 28920, lr = 0.02
I0526 05:53:14.838089 15117 solver.cpp:233] Iteration 28930, loss = 0.117115
I0526 05:53:14.838129 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.117115 (* 1 = 0.117115 loss)
I0526 05:53:14.838136 15117 sgd_solver.cpp:294] Iteration 28930, lr = 0.02
I0526 05:53:21.173491 15117 solver.cpp:233] Iteration 28940, loss = 0.0822623
I0526 05:53:21.173532 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0822624 (* 1 = 0.0822624 loss)
I0526 05:53:21.173538 15117 sgd_solver.cpp:294] Iteration 28940, lr = 0.02
I0526 05:53:27.508345 15117 solver.cpp:233] Iteration 28950, loss = 0.0464103
I0526 05:53:27.508395 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0464105 (* 1 = 0.0464105 loss)
I0526 05:53:27.508402 15117 sgd_solver.cpp:294] Iteration 28950, lr = 0.02
I0526 05:53:33.836585 15117 solver.cpp:233] Iteration 28960, loss = 0.0693154
I0526 05:53:33.836836 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0693155 (* 1 = 0.0693155 loss)
I0526 05:53:33.836865 15117 sgd_solver.cpp:294] Iteration 28960, lr = 0.02
I0526 05:53:40.171977 15117 solver.cpp:233] Iteration 28970, loss = 0.0949153
I0526 05:53:40.172026 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0949155 (* 1 = 0.0949155 loss)
I0526 05:53:40.172034 15117 sgd_solver.cpp:294] Iteration 28970, lr = 0.02
I0526 05:53:46.512003 15117 solver.cpp:233] Iteration 28980, loss = 0.0741277
I0526 05:53:46.512049 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0741278 (* 1 = 0.0741278 loss)
I0526 05:53:46.512058 15117 sgd_solver.cpp:294] Iteration 28980, lr = 0.02
I0526 05:53:52.845157 15117 solver.cpp:233] Iteration 28990, loss = 0.0913884
I0526 05:53:52.845199 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0913886 (* 1 = 0.0913886 loss)
I0526 05:53:52.845207 15117 sgd_solver.cpp:294] Iteration 28990, lr = 0.02
I0526 05:53:58.579941 15117 solver.cpp:342] Iteration 29000, Testing net (#0)
I0526 05:54:11.419328 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8227
I0526 05:54:11.419538 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.832452 (* 1 = 0.832452 loss)
I0526 05:54:12.021759 15117 solver.cpp:233] Iteration 29000, loss = 0.0707257
I0526 05:54:12.021805 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0707259 (* 1 = 0.0707259 loss)
I0526 05:54:12.021813 15117 sgd_solver.cpp:294] Iteration 29000, lr = 0.02
I0526 05:54:18.354879 15117 solver.cpp:233] Iteration 29010, loss = 0.0821597
I0526 05:54:18.354920 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0821598 (* 1 = 0.0821598 loss)
I0526 05:54:18.354928 15117 sgd_solver.cpp:294] Iteration 29010, lr = 0.02
I0526 05:54:24.691344 15117 solver.cpp:233] Iteration 29020, loss = 0.0780759
I0526 05:54:24.691385 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0780761 (* 1 = 0.0780761 loss)
I0526 05:54:24.691391 15117 sgd_solver.cpp:294] Iteration 29020, lr = 0.02
I0526 05:54:31.028153 15117 solver.cpp:233] Iteration 29030, loss = 0.0765279
I0526 05:54:31.028197 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0765281 (* 1 = 0.0765281 loss)
I0526 05:54:31.028203 15117 sgd_solver.cpp:294] Iteration 29030, lr = 0.02
I0526 05:54:37.366021 15117 solver.cpp:233] Iteration 29040, loss = 0.0493619
I0526 05:54:37.366060 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.049362 (* 1 = 0.049362 loss)
I0526 05:54:37.366067 15117 sgd_solver.cpp:294] Iteration 29040, lr = 0.02
I0526 05:54:43.702803 15117 solver.cpp:233] Iteration 29050, loss = 0.117437
I0526 05:54:43.703071 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.117437 (* 1 = 0.117437 loss)
I0526 05:54:43.703109 15117 sgd_solver.cpp:294] Iteration 29050, lr = 0.02
I0526 05:54:50.035764 15117 solver.cpp:233] Iteration 29060, loss = 0.0689753
I0526 05:54:50.035804 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0689755 (* 1 = 0.0689755 loss)
I0526 05:54:50.035811 15117 sgd_solver.cpp:294] Iteration 29060, lr = 0.02
I0526 05:54:56.373275 15117 solver.cpp:233] Iteration 29070, loss = 0.129034
I0526 05:54:56.373312 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.129034 (* 1 = 0.129034 loss)
I0526 05:54:56.373320 15117 sgd_solver.cpp:294] Iteration 29070, lr = 0.02
I0526 05:55:02.706219 15117 solver.cpp:233] Iteration 29080, loss = 0.101585
I0526 05:55:02.706264 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.101585 (* 1 = 0.101585 loss)
I0526 05:55:02.706271 15117 sgd_solver.cpp:294] Iteration 29080, lr = 0.02
I0526 05:55:09.045507 15117 solver.cpp:233] Iteration 29090, loss = 0.084476
I0526 05:55:09.045543 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0844761 (* 1 = 0.0844761 loss)
I0526 05:55:09.045550 15117 sgd_solver.cpp:294] Iteration 29090, lr = 0.02
I0526 05:55:14.780966 15117 solver.cpp:342] Iteration 29100, Testing net (#0)
I0526 05:55:27.625334 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8463
I0526 05:55:27.625376 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.621009 (* 1 = 0.621009 loss)
I0526 05:55:28.227408 15117 solver.cpp:233] Iteration 29100, loss = 0.11979
I0526 05:55:28.227458 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.11979 (* 1 = 0.11979 loss)
I0526 05:55:28.227465 15117 sgd_solver.cpp:294] Iteration 29100, lr = 0.02
I0526 05:55:34.565105 15117 solver.cpp:233] Iteration 29110, loss = 0.0483613
I0526 05:55:34.565147 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0483615 (* 1 = 0.0483615 loss)
I0526 05:55:34.565155 15117 sgd_solver.cpp:294] Iteration 29110, lr = 0.02
I0526 05:55:40.903981 15117 solver.cpp:233] Iteration 29120, loss = 0.106668
I0526 05:55:40.904032 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.106668 (* 1 = 0.106668 loss)
I0526 05:55:40.904041 15117 sgd_solver.cpp:294] Iteration 29120, lr = 0.02
I0526 05:55:47.243732 15117 solver.cpp:233] Iteration 29130, loss = 0.121892
I0526 05:55:47.243968 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.121893 (* 1 = 0.121893 loss)
I0526 05:55:47.243996 15117 sgd_solver.cpp:294] Iteration 29130, lr = 0.02
I0526 05:55:53.575592 15117 solver.cpp:233] Iteration 29140, loss = 0.0563964
I0526 05:55:53.575635 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0563966 (* 1 = 0.0563966 loss)
I0526 05:55:53.575654 15117 sgd_solver.cpp:294] Iteration 29140, lr = 0.02
I0526 05:55:59.912474 15117 solver.cpp:233] Iteration 29150, loss = 0.0638852
I0526 05:55:59.912513 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0638854 (* 1 = 0.0638854 loss)
I0526 05:55:59.912520 15117 sgd_solver.cpp:294] Iteration 29150, lr = 0.02
I0526 05:56:06.250893 15117 solver.cpp:233] Iteration 29160, loss = 0.0865594
I0526 05:56:06.250941 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0865595 (* 1 = 0.0865595 loss)
I0526 05:56:06.250948 15117 sgd_solver.cpp:294] Iteration 29160, lr = 0.02
I0526 05:56:12.585403 15117 solver.cpp:233] Iteration 29170, loss = 0.0988583
I0526 05:56:12.585443 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0988584 (* 1 = 0.0988584 loss)
I0526 05:56:12.585450 15117 sgd_solver.cpp:294] Iteration 29170, lr = 0.02
I0526 05:56:18.921054 15117 solver.cpp:233] Iteration 29180, loss = 0.102259
I0526 05:56:18.921274 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.102259 (* 1 = 0.102259 loss)
I0526 05:56:18.921303 15117 sgd_solver.cpp:294] Iteration 29180, lr = 0.02
I0526 05:56:25.251526 15117 solver.cpp:233] Iteration 29190, loss = 0.0468409
I0526 05:56:25.251570 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.046841 (* 1 = 0.046841 loss)
I0526 05:56:25.251583 15117 sgd_solver.cpp:294] Iteration 29190, lr = 0.02
I0526 05:56:30.986032 15117 solver.cpp:342] Iteration 29200, Testing net (#0)
I0526 05:56:43.829152 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7804
I0526 05:56:43.829196 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.04077 (* 1 = 1.04077 loss)
I0526 05:56:44.430040 15117 solver.cpp:233] Iteration 29200, loss = 0.0824214
I0526 05:56:44.430075 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0824215 (* 1 = 0.0824215 loss)
I0526 05:56:44.430083 15117 sgd_solver.cpp:294] Iteration 29200, lr = 0.02
I0526 05:56:50.768318 15117 solver.cpp:233] Iteration 29210, loss = 0.134991
I0526 05:56:50.768587 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.134991 (* 1 = 0.134991 loss)
I0526 05:56:50.768613 15117 sgd_solver.cpp:294] Iteration 29210, lr = 0.02
I0526 05:56:57.107089 15117 solver.cpp:233] Iteration 29220, loss = 0.0442354
I0526 05:56:57.107130 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0442355 (* 1 = 0.0442355 loss)
I0526 05:56:57.107136 15117 sgd_solver.cpp:294] Iteration 29220, lr = 0.02
I0526 05:57:03.443585 15117 solver.cpp:233] Iteration 29230, loss = 0.113192
I0526 05:57:03.443624 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.113192 (* 1 = 0.113192 loss)
I0526 05:57:03.443630 15117 sgd_solver.cpp:294] Iteration 29230, lr = 0.02
I0526 05:57:09.780187 15117 solver.cpp:233] Iteration 29240, loss = 0.0551157
I0526 05:57:09.780230 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0551159 (* 1 = 0.0551159 loss)
I0526 05:57:09.780236 15117 sgd_solver.cpp:294] Iteration 29240, lr = 0.02
I0526 05:57:16.120865 15117 solver.cpp:233] Iteration 29250, loss = 0.0946062
I0526 05:57:16.120918 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0946063 (* 1 = 0.0946063 loss)
I0526 05:57:16.120924 15117 sgd_solver.cpp:294] Iteration 29250, lr = 0.02
I0526 05:57:22.457145 15117 solver.cpp:233] Iteration 29260, loss = 0.0900602
I0526 05:57:22.457391 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0900604 (* 1 = 0.0900604 loss)
I0526 05:57:22.457420 15117 sgd_solver.cpp:294] Iteration 29260, lr = 0.02
I0526 05:57:28.789527 15117 solver.cpp:233] Iteration 29270, loss = 0.118016
I0526 05:57:28.789566 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.118016 (* 1 = 0.118016 loss)
I0526 05:57:28.789572 15117 sgd_solver.cpp:294] Iteration 29270, lr = 0.02
I0526 05:57:35.126727 15117 solver.cpp:233] Iteration 29280, loss = 0.145468
I0526 05:57:35.126765 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.145468 (* 1 = 0.145468 loss)
I0526 05:57:35.126771 15117 sgd_solver.cpp:294] Iteration 29280, lr = 0.02
I0526 05:57:41.463201 15117 solver.cpp:233] Iteration 29290, loss = 0.131348
I0526 05:57:41.463243 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.131348 (* 1 = 0.131348 loss)
I0526 05:57:41.463250 15117 sgd_solver.cpp:294] Iteration 29290, lr = 0.02
I0526 05:57:47.198767 15117 solver.cpp:342] Iteration 29300, Testing net (#0)
I0526 05:58:00.047534 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7977
I0526 05:58:00.047780 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.919155 (* 1 = 0.919155 loss)
I0526 05:58:00.649693 15117 solver.cpp:233] Iteration 29300, loss = 0.180055
I0526 05:58:00.649720 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.180055 (* 1 = 0.180055 loss)
I0526 05:58:00.649727 15117 sgd_solver.cpp:294] Iteration 29300, lr = 0.02
I0526 05:58:06.984158 15117 solver.cpp:233] Iteration 29310, loss = 0.120112
I0526 05:58:06.984199 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.120113 (* 1 = 0.120113 loss)
I0526 05:58:06.984205 15117 sgd_solver.cpp:294] Iteration 29310, lr = 0.02
I0526 05:58:13.319751 15117 solver.cpp:233] Iteration 29320, loss = 0.0911992
I0526 05:58:13.319792 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0911993 (* 1 = 0.0911993 loss)
I0526 05:58:13.319807 15117 sgd_solver.cpp:294] Iteration 29320, lr = 0.02
I0526 05:58:19.655562 15117 solver.cpp:233] Iteration 29330, loss = 0.0794695
I0526 05:58:19.655601 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0794696 (* 1 = 0.0794696 loss)
I0526 05:58:19.655609 15117 sgd_solver.cpp:294] Iteration 29330, lr = 0.02
I0526 05:58:25.990048 15117 solver.cpp:233] Iteration 29340, loss = 0.195736
I0526 05:58:25.990090 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.195736 (* 1 = 0.195736 loss)
I0526 05:58:25.990097 15117 sgd_solver.cpp:294] Iteration 29340, lr = 0.02
I0526 05:58:32.328361 15117 solver.cpp:233] Iteration 29350, loss = 0.108374
I0526 05:58:32.328619 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.108374 (* 1 = 0.108374 loss)
I0526 05:58:32.328647 15117 sgd_solver.cpp:294] Iteration 29350, lr = 0.02
I0526 05:58:38.660920 15117 solver.cpp:233] Iteration 29360, loss = 0.0993632
I0526 05:58:38.660972 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0993633 (* 1 = 0.0993633 loss)
I0526 05:58:38.660991 15117 sgd_solver.cpp:294] Iteration 29360, lr = 0.02
I0526 05:58:44.995105 15117 solver.cpp:233] Iteration 29370, loss = 0.088752
I0526 05:58:44.995160 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0887522 (* 1 = 0.0887522 loss)
I0526 05:58:44.995167 15117 sgd_solver.cpp:294] Iteration 29370, lr = 0.02
I0526 05:58:51.330862 15117 solver.cpp:233] Iteration 29380, loss = 0.107754
I0526 05:58:51.330904 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.107754 (* 1 = 0.107754 loss)
I0526 05:58:51.330911 15117 sgd_solver.cpp:294] Iteration 29380, lr = 0.02
I0526 05:58:57.666784 15117 solver.cpp:233] Iteration 29390, loss = 0.0920258
I0526 05:58:57.666823 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.092026 (* 1 = 0.092026 loss)
I0526 05:58:57.666831 15117 sgd_solver.cpp:294] Iteration 29390, lr = 0.02
I0526 05:59:03.397966 15117 solver.cpp:342] Iteration 29400, Testing net (#0)
I0526 05:59:16.236477 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7706
I0526 05:59:16.236532 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.14588 (* 1 = 1.14588 loss)
I0526 05:59:16.836931 15117 solver.cpp:233] Iteration 29400, loss = 0.0744843
I0526 05:59:16.836966 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0744845 (* 1 = 0.0744845 loss)
I0526 05:59:16.836973 15117 sgd_solver.cpp:294] Iteration 29400, lr = 0.02
I0526 05:59:23.168680 15117 solver.cpp:233] Iteration 29410, loss = 0.076527
I0526 05:59:23.168728 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0765272 (* 1 = 0.0765272 loss)
I0526 05:59:23.168736 15117 sgd_solver.cpp:294] Iteration 29410, lr = 0.02
I0526 05:59:29.502754 15117 solver.cpp:233] Iteration 29420, loss = 0.108077
I0526 05:59:29.502799 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.108077 (* 1 = 0.108077 loss)
I0526 05:59:29.502806 15117 sgd_solver.cpp:294] Iteration 29420, lr = 0.02
I0526 05:59:35.841267 15117 solver.cpp:233] Iteration 29430, loss = 0.122634
I0526 05:59:35.841509 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.122634 (* 1 = 0.122634 loss)
I0526 05:59:35.841538 15117 sgd_solver.cpp:294] Iteration 29430, lr = 0.02
I0526 05:59:42.175032 15117 solver.cpp:233] Iteration 29440, loss = 0.0767177
I0526 05:59:42.175061 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0767178 (* 1 = 0.0767178 loss)
I0526 05:59:42.175068 15117 sgd_solver.cpp:294] Iteration 29440, lr = 0.02
I0526 05:59:48.506971 15117 solver.cpp:233] Iteration 29450, loss = 0.119943
I0526 05:59:48.507014 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.119943 (* 1 = 0.119943 loss)
I0526 05:59:48.507020 15117 sgd_solver.cpp:294] Iteration 29450, lr = 0.02
I0526 05:59:54.846169 15117 solver.cpp:233] Iteration 29460, loss = 0.0547463
I0526 05:59:54.846210 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0547464 (* 1 = 0.0547464 loss)
I0526 05:59:54.846221 15117 sgd_solver.cpp:294] Iteration 29460, lr = 0.02
I0526 06:00:01.182279 15117 solver.cpp:233] Iteration 29470, loss = 0.0762944
I0526 06:00:01.182322 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0762945 (* 1 = 0.0762945 loss)
I0526 06:00:01.182329 15117 sgd_solver.cpp:294] Iteration 29470, lr = 0.02
I0526 06:00:07.516186 15117 solver.cpp:233] Iteration 29480, loss = 0.0750804
I0526 06:00:07.516448 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0750806 (* 1 = 0.0750806 loss)
I0526 06:00:07.516476 15117 sgd_solver.cpp:294] Iteration 29480, lr = 0.02
I0526 06:00:13.854075 15117 solver.cpp:233] Iteration 29490, loss = 0.0838692
I0526 06:00:13.854115 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0838694 (* 1 = 0.0838694 loss)
I0526 06:00:13.854122 15117 sgd_solver.cpp:294] Iteration 29490, lr = 0.02
I0526 06:00:19.588106 15117 solver.cpp:342] Iteration 29500, Testing net (#0)
I0526 06:00:32.429086 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8275
I0526 06:00:32.429131 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.714863 (* 1 = 0.714863 loss)
I0526 06:00:33.030374 15117 solver.cpp:233] Iteration 29500, loss = 0.0470118
I0526 06:00:33.030407 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0470119 (* 1 = 0.0470119 loss)
I0526 06:00:33.030414 15117 sgd_solver.cpp:294] Iteration 29500, lr = 0.02
I0526 06:00:39.369055 15117 solver.cpp:233] Iteration 29510, loss = 0.0493923
I0526 06:00:39.369276 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0493925 (* 1 = 0.0493925 loss)
I0526 06:00:39.369310 15117 sgd_solver.cpp:294] Iteration 29510, lr = 0.02
I0526 06:00:45.702800 15117 solver.cpp:233] Iteration 29520, loss = 0.0544715
I0526 06:00:45.702844 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0544716 (* 1 = 0.0544716 loss)
I0526 06:00:45.702852 15117 sgd_solver.cpp:294] Iteration 29520, lr = 0.02
I0526 06:00:52.038362 15117 solver.cpp:233] Iteration 29530, loss = 0.05988
I0526 06:00:52.038413 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0598802 (* 1 = 0.0598802 loss)
I0526 06:00:52.038419 15117 sgd_solver.cpp:294] Iteration 29530, lr = 0.02
I0526 06:00:58.373834 15117 solver.cpp:233] Iteration 29540, loss = 0.0595814
I0526 06:00:58.373872 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0595815 (* 1 = 0.0595815 loss)
I0526 06:00:58.373880 15117 sgd_solver.cpp:294] Iteration 29540, lr = 0.02
I0526 06:01:04.708508 15117 solver.cpp:233] Iteration 29550, loss = 0.0677327
I0526 06:01:04.708551 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0677329 (* 1 = 0.0677329 loss)
I0526 06:01:04.708559 15117 sgd_solver.cpp:294] Iteration 29550, lr = 0.02
I0526 06:01:11.045142 15117 solver.cpp:233] Iteration 29560, loss = 0.0663113
I0526 06:01:11.045357 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0663114 (* 1 = 0.0663114 loss)
I0526 06:01:11.045387 15117 sgd_solver.cpp:294] Iteration 29560, lr = 0.02
I0526 06:01:17.377374 15117 solver.cpp:233] Iteration 29570, loss = 0.0818487
I0526 06:01:17.377418 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0818488 (* 1 = 0.0818488 loss)
I0526 06:01:17.377425 15117 sgd_solver.cpp:294] Iteration 29570, lr = 0.02
I0526 06:01:23.713521 15117 solver.cpp:233] Iteration 29580, loss = 0.0517264
I0526 06:01:23.713562 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0517266 (* 1 = 0.0517266 loss)
I0526 06:01:23.713568 15117 sgd_solver.cpp:294] Iteration 29580, lr = 0.02
I0526 06:01:30.047698 15117 solver.cpp:233] Iteration 29590, loss = 0.11417
I0526 06:01:30.047744 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.11417 (* 1 = 0.11417 loss)
I0526 06:01:30.047751 15117 sgd_solver.cpp:294] Iteration 29590, lr = 0.02
I0526 06:01:35.780125 15117 solver.cpp:342] Iteration 29600, Testing net (#0)
I0526 06:01:48.617226 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8081
I0526 06:01:48.617501 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.841441 (* 1 = 0.841441 loss)
I0526 06:01:49.217447 15117 solver.cpp:233] Iteration 29600, loss = 0.109492
I0526 06:01:49.217489 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.109492 (* 1 = 0.109492 loss)
I0526 06:01:49.217506 15117 sgd_solver.cpp:294] Iteration 29600, lr = 0.02
I0526 06:01:55.548846 15117 solver.cpp:233] Iteration 29610, loss = 0.0538089
I0526 06:01:55.548883 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0538091 (* 1 = 0.0538091 loss)
I0526 06:01:55.548892 15117 sgd_solver.cpp:294] Iteration 29610, lr = 0.02
I0526 06:02:01.888052 15117 solver.cpp:233] Iteration 29620, loss = 0.0478334
I0526 06:02:01.888094 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0478335 (* 1 = 0.0478335 loss)
I0526 06:02:01.888103 15117 sgd_solver.cpp:294] Iteration 29620, lr = 0.02
I0526 06:02:08.220764 15117 solver.cpp:233] Iteration 29630, loss = 0.0823307
I0526 06:02:08.220805 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0823309 (* 1 = 0.0823309 loss)
I0526 06:02:08.220813 15117 sgd_solver.cpp:294] Iteration 29630, lr = 0.02
I0526 06:02:14.556798 15117 solver.cpp:233] Iteration 29640, loss = 0.125275
I0526 06:02:14.556841 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.125275 (* 1 = 0.125275 loss)
I0526 06:02:14.556848 15117 sgd_solver.cpp:294] Iteration 29640, lr = 0.02
I0526 06:02:20.891365 15117 solver.cpp:233] Iteration 29650, loss = 0.0719729
I0526 06:02:20.891592 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0719731 (* 1 = 0.0719731 loss)
I0526 06:02:20.891629 15117 sgd_solver.cpp:294] Iteration 29650, lr = 0.02
I0526 06:02:27.230705 15117 solver.cpp:233] Iteration 29660, loss = 0.0752836
I0526 06:02:27.230748 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0752838 (* 1 = 0.0752838 loss)
I0526 06:02:27.230756 15117 sgd_solver.cpp:294] Iteration 29660, lr = 0.02
I0526 06:02:33.567026 15117 solver.cpp:233] Iteration 29670, loss = 0.0748641
I0526 06:02:33.567080 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0748643 (* 1 = 0.0748643 loss)
I0526 06:02:33.567087 15117 sgd_solver.cpp:294] Iteration 29670, lr = 0.02
I0526 06:02:39.902254 15117 solver.cpp:233] Iteration 29680, loss = 0.133159
I0526 06:02:39.902292 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.133159 (* 1 = 0.133159 loss)
I0526 06:02:39.902300 15117 sgd_solver.cpp:294] Iteration 29680, lr = 0.02
I0526 06:02:46.240906 15117 solver.cpp:233] Iteration 29690, loss = 0.0743832
I0526 06:02:46.240944 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0743834 (* 1 = 0.0743834 loss)
I0526 06:02:46.240952 15117 sgd_solver.cpp:294] Iteration 29690, lr = 0.02
I0526 06:02:51.976095 15117 solver.cpp:342] Iteration 29700, Testing net (#0)
I0526 06:03:04.824937 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.793
I0526 06:03:04.824985 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.0796 (* 1 = 1.0796 loss)
I0526 06:03:05.423885 15117 solver.cpp:233] Iteration 29700, loss = 0.0653748
I0526 06:03:05.423931 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0653749 (* 1 = 0.0653749 loss)
I0526 06:03:05.423938 15117 sgd_solver.cpp:294] Iteration 29700, lr = 0.02
I0526 06:03:11.760954 15117 solver.cpp:233] Iteration 29710, loss = 0.0653794
I0526 06:03:11.760998 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0653795 (* 1 = 0.0653795 loss)
I0526 06:03:11.761006 15117 sgd_solver.cpp:294] Iteration 29710, lr = 0.02
I0526 06:03:18.096216 15117 solver.cpp:233] Iteration 29720, loss = 0.0827999
I0526 06:03:18.096259 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0828001 (* 1 = 0.0828001 loss)
I0526 06:03:18.096266 15117 sgd_solver.cpp:294] Iteration 29720, lr = 0.02
I0526 06:03:24.431591 15117 solver.cpp:233] Iteration 29730, loss = 0.0533967
I0526 06:03:24.431864 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0533969 (* 1 = 0.0533969 loss)
I0526 06:03:24.431905 15117 sgd_solver.cpp:294] Iteration 29730, lr = 0.02
I0526 06:03:30.759505 15117 solver.cpp:233] Iteration 29740, loss = 0.111691
I0526 06:03:30.759544 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.111691 (* 1 = 0.111691 loss)
I0526 06:03:30.759552 15117 sgd_solver.cpp:294] Iteration 29740, lr = 0.02
I0526 06:03:37.088587 15117 solver.cpp:233] Iteration 29750, loss = 0.101058
I0526 06:03:37.088625 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.101058 (* 1 = 0.101058 loss)
I0526 06:03:37.088634 15117 sgd_solver.cpp:294] Iteration 29750, lr = 0.02
I0526 06:03:43.424054 15117 solver.cpp:233] Iteration 29760, loss = 0.149167
I0526 06:03:43.424098 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.149167 (* 1 = 0.149167 loss)
I0526 06:03:43.424105 15117 sgd_solver.cpp:294] Iteration 29760, lr = 0.02
I0526 06:03:49.760334 15117 solver.cpp:233] Iteration 29770, loss = 0.101128
I0526 06:03:49.760375 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.101128 (* 1 = 0.101128 loss)
I0526 06:03:49.760381 15117 sgd_solver.cpp:294] Iteration 29770, lr = 0.02
I0526 06:03:56.096215 15117 solver.cpp:233] Iteration 29780, loss = 0.0599204
I0526 06:03:56.096443 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0599205 (* 1 = 0.0599205 loss)
I0526 06:03:56.096473 15117 sgd_solver.cpp:294] Iteration 29780, lr = 0.02
I0526 06:04:02.426583 15117 solver.cpp:233] Iteration 29790, loss = 0.108919
I0526 06:04:02.426625 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.108919 (* 1 = 0.108919 loss)
I0526 06:04:02.426632 15117 sgd_solver.cpp:294] Iteration 29790, lr = 0.02
I0526 06:04:08.163175 15117 solver.cpp:342] Iteration 29800, Testing net (#0)
I0526 06:04:21.006098 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7902
I0526 06:04:21.006141 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.982494 (* 1 = 0.982494 loss)
I0526 06:04:21.607501 15117 solver.cpp:233] Iteration 29800, loss = 0.0851784
I0526 06:04:21.607535 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0851786 (* 1 = 0.0851786 loss)
I0526 06:04:21.607543 15117 sgd_solver.cpp:294] Iteration 29800, lr = 0.02
I0526 06:04:27.945045 15117 solver.cpp:233] Iteration 29810, loss = 0.084213
I0526 06:04:27.945108 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0842131 (* 1 = 0.0842131 loss)
I0526 06:04:27.945117 15117 sgd_solver.cpp:294] Iteration 29810, lr = 0.02
I0526 06:04:34.280047 15117 solver.cpp:233] Iteration 29820, loss = 0.125935
I0526 06:04:34.280086 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.125935 (* 1 = 0.125935 loss)
I0526 06:04:34.280093 15117 sgd_solver.cpp:294] Iteration 29820, lr = 0.02
I0526 06:04:40.617740 15117 solver.cpp:233] Iteration 29830, loss = 0.127448
I0526 06:04:40.617780 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.127448 (* 1 = 0.127448 loss)
I0526 06:04:40.617787 15117 sgd_solver.cpp:294] Iteration 29830, lr = 0.02
I0526 06:04:46.957424 15117 solver.cpp:233] Iteration 29840, loss = 0.0977339
I0526 06:04:46.957474 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0977341 (* 1 = 0.0977341 loss)
I0526 06:04:46.957494 15117 sgd_solver.cpp:294] Iteration 29840, lr = 0.02
I0526 06:04:53.292822 15117 solver.cpp:233] Iteration 29850, loss = 0.0780029
I0526 06:04:53.292866 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.078003 (* 1 = 0.078003 loss)
I0526 06:04:53.292873 15117 sgd_solver.cpp:294] Iteration 29850, lr = 0.02
I0526 06:04:59.626956 15117 solver.cpp:233] Iteration 29860, loss = 0.0748115
I0526 06:04:59.627081 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0748117 (* 1 = 0.0748117 loss)
I0526 06:04:59.627090 15117 sgd_solver.cpp:294] Iteration 29860, lr = 0.02
I0526 06:05:05.963434 15117 solver.cpp:233] Iteration 29870, loss = 0.0818612
I0526 06:05:05.963485 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0818613 (* 1 = 0.0818613 loss)
I0526 06:05:05.963497 15117 sgd_solver.cpp:294] Iteration 29870, lr = 0.02
I0526 06:05:12.300483 15117 solver.cpp:233] Iteration 29880, loss = 0.0753717
I0526 06:05:12.300528 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0753719 (* 1 = 0.0753719 loss)
I0526 06:05:12.300535 15117 sgd_solver.cpp:294] Iteration 29880, lr = 0.02
I0526 06:05:18.630834 15117 solver.cpp:233] Iteration 29890, loss = 0.0952004
I0526 06:05:18.630874 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0952005 (* 1 = 0.0952005 loss)
I0526 06:05:18.630882 15117 sgd_solver.cpp:294] Iteration 29890, lr = 0.02
I0526 06:05:24.367863 15117 solver.cpp:342] Iteration 29900, Testing net (#0)
I0526 06:05:37.208655 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8506
I0526 06:05:37.208919 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.665899 (* 1 = 0.665899 loss)
I0526 06:05:37.809783 15117 solver.cpp:233] Iteration 29900, loss = 0.0972259
I0526 06:05:37.809856 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0972261 (* 1 = 0.0972261 loss)
I0526 06:05:37.809869 15117 sgd_solver.cpp:294] Iteration 29900, lr = 0.02
I0526 06:05:44.143467 15117 solver.cpp:233] Iteration 29910, loss = 0.171183
I0526 06:05:44.143519 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.171183 (* 1 = 0.171183 loss)
I0526 06:05:44.143527 15117 sgd_solver.cpp:294] Iteration 29910, lr = 0.02
I0526 06:05:50.477893 15117 solver.cpp:233] Iteration 29920, loss = 0.0730046
I0526 06:05:50.477957 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0730047 (* 1 = 0.0730047 loss)
I0526 06:05:50.477963 15117 sgd_solver.cpp:294] Iteration 29920, lr = 0.02
I0526 06:05:56.813263 15117 solver.cpp:233] Iteration 29930, loss = 0.0638778
I0526 06:05:56.813308 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.063878 (* 1 = 0.063878 loss)
I0526 06:05:56.813314 15117 sgd_solver.cpp:294] Iteration 29930, lr = 0.02
I0526 06:06:03.148005 15117 solver.cpp:233] Iteration 29940, loss = 0.0561541
I0526 06:06:03.148042 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0561542 (* 1 = 0.0561542 loss)
I0526 06:06:03.148051 15117 sgd_solver.cpp:294] Iteration 29940, lr = 0.02
I0526 06:06:09.481122 15117 solver.cpp:233] Iteration 29950, loss = 0.131017
I0526 06:06:09.481349 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.131017 (* 1 = 0.131017 loss)
I0526 06:06:09.481379 15117 sgd_solver.cpp:294] Iteration 29950, lr = 0.02
I0526 06:06:15.811502 15117 solver.cpp:233] Iteration 29960, loss = 0.120434
I0526 06:06:15.811543 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.120434 (* 1 = 0.120434 loss)
I0526 06:06:15.811552 15117 sgd_solver.cpp:294] Iteration 29960, lr = 0.02
I0526 06:06:22.145871 15117 solver.cpp:233] Iteration 29970, loss = 0.0693196
I0526 06:06:22.145910 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0693197 (* 1 = 0.0693197 loss)
I0526 06:06:22.145917 15117 sgd_solver.cpp:294] Iteration 29970, lr = 0.02
I0526 06:06:28.482868 15117 solver.cpp:233] Iteration 29980, loss = 0.106381
I0526 06:06:28.482923 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.106381 (* 1 = 0.106381 loss)
I0526 06:06:28.482929 15117 sgd_solver.cpp:294] Iteration 29980, lr = 0.02
I0526 06:06:34.821774 15117 solver.cpp:233] Iteration 29990, loss = 0.0862442
I0526 06:06:34.821827 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0862444 (* 1 = 0.0862444 loss)
I0526 06:06:34.821844 15117 sgd_solver.cpp:294] Iteration 29990, lr = 0.02
I0526 06:06:40.557137 15117 solver.cpp:342] Iteration 30000, Testing net (#0)
I0526 06:06:53.396342 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8337
I0526 06:06:53.396389 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.689649 (* 1 = 0.689649 loss)
I0526 06:06:53.998251 15117 solver.cpp:233] Iteration 30000, loss = 0.0397031
I0526 06:06:53.998287 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0397032 (* 1 = 0.0397032 loss)
I0526 06:06:53.998299 15117 sgd_solver.cpp:294] Iteration 30000, lr = 0.02
I0526 06:07:00.337749 15117 solver.cpp:233] Iteration 30010, loss = 0.062325
I0526 06:07:00.337800 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0623251 (* 1 = 0.0623251 loss)
I0526 06:07:00.337806 15117 sgd_solver.cpp:294] Iteration 30010, lr = 0.02
I0526 06:07:06.677970 15117 solver.cpp:233] Iteration 30020, loss = 0.0738543
I0526 06:07:06.678010 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0738545 (* 1 = 0.0738545 loss)
I0526 06:07:06.678019 15117 sgd_solver.cpp:294] Iteration 30020, lr = 0.02
I0526 06:07:13.014605 15117 solver.cpp:233] Iteration 30030, loss = 0.0960189
I0526 06:07:13.014878 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0960191 (* 1 = 0.0960191 loss)
I0526 06:07:13.014906 15117 sgd_solver.cpp:294] Iteration 30030, lr = 0.02
I0526 06:07:19.347506 15117 solver.cpp:233] Iteration 30040, loss = 0.0690049
I0526 06:07:19.347568 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0690051 (* 1 = 0.0690051 loss)
I0526 06:07:19.347575 15117 sgd_solver.cpp:294] Iteration 30040, lr = 0.02
I0526 06:07:25.683708 15117 solver.cpp:233] Iteration 30050, loss = 0.0647366
I0526 06:07:25.683761 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0647368 (* 1 = 0.0647368 loss)
I0526 06:07:25.683768 15117 sgd_solver.cpp:294] Iteration 30050, lr = 0.02
I0526 06:07:32.026912 15117 solver.cpp:233] Iteration 30060, loss = 0.0774538
I0526 06:07:32.026952 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0774539 (* 1 = 0.0774539 loss)
I0526 06:07:32.026959 15117 sgd_solver.cpp:294] Iteration 30060, lr = 0.02
I0526 06:07:38.361178 15117 solver.cpp:233] Iteration 30070, loss = 0.069004
I0526 06:07:38.361219 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0690042 (* 1 = 0.0690042 loss)
I0526 06:07:38.361225 15117 sgd_solver.cpp:294] Iteration 30070, lr = 0.02
I0526 06:07:44.696074 15117 solver.cpp:233] Iteration 30080, loss = 0.0932814
I0526 06:07:44.696300 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0932816 (* 1 = 0.0932816 loss)
I0526 06:07:44.696327 15117 sgd_solver.cpp:294] Iteration 30080, lr = 0.02
I0526 06:07:51.029882 15117 solver.cpp:233] Iteration 30090, loss = 0.0961626
I0526 06:07:51.029943 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0961628 (* 1 = 0.0961628 loss)
I0526 06:07:51.029950 15117 sgd_solver.cpp:294] Iteration 30090, lr = 0.02
I0526 06:07:56.763998 15117 solver.cpp:342] Iteration 30100, Testing net (#0)
I0526 06:08:09.605239 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8553
I0526 06:08:09.605288 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.592138 (* 1 = 0.592138 loss)
I0526 06:08:10.207504 15117 solver.cpp:233] Iteration 30100, loss = 0.0418129
I0526 06:08:10.207540 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0418131 (* 1 = 0.0418131 loss)
I0526 06:08:10.207547 15117 sgd_solver.cpp:294] Iteration 30100, lr = 0.02
I0526 06:08:16.546205 15117 solver.cpp:233] Iteration 30110, loss = 0.0585095
I0526 06:08:16.546452 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0585096 (* 1 = 0.0585096 loss)
I0526 06:08:16.546481 15117 sgd_solver.cpp:294] Iteration 30110, lr = 0.02
I0526 06:08:22.880331 15117 solver.cpp:233] Iteration 30120, loss = 0.127294
I0526 06:08:22.880373 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.127294 (* 1 = 0.127294 loss)
I0526 06:08:22.880379 15117 sgd_solver.cpp:294] Iteration 30120, lr = 0.02
I0526 06:08:29.212960 15117 solver.cpp:233] Iteration 30130, loss = 0.14865
I0526 06:08:29.213001 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.14865 (* 1 = 0.14865 loss)
I0526 06:08:29.213009 15117 sgd_solver.cpp:294] Iteration 30130, lr = 0.02
I0526 06:08:35.549968 15117 solver.cpp:233] Iteration 30140, loss = 0.0857833
I0526 06:08:35.550026 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0857834 (* 1 = 0.0857834 loss)
I0526 06:08:35.550034 15117 sgd_solver.cpp:294] Iteration 30140, lr = 0.02
I0526 06:08:41.884518 15117 solver.cpp:233] Iteration 30150, loss = 0.0685405
I0526 06:08:41.884560 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0685406 (* 1 = 0.0685406 loss)
I0526 06:08:41.884568 15117 sgd_solver.cpp:294] Iteration 30150, lr = 0.02
I0526 06:08:48.215785 15117 solver.cpp:233] Iteration 30160, loss = 0.0851097
I0526 06:08:48.216068 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0851098 (* 1 = 0.0851098 loss)
I0526 06:08:48.216097 15117 sgd_solver.cpp:294] Iteration 30160, lr = 0.02
I0526 06:08:54.549073 15117 solver.cpp:233] Iteration 30170, loss = 0.0722848
I0526 06:08:54.549113 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.072285 (* 1 = 0.072285 loss)
I0526 06:08:54.549119 15117 sgd_solver.cpp:294] Iteration 30170, lr = 0.02
I0526 06:09:00.882736 15117 solver.cpp:233] Iteration 30180, loss = 0.116052
I0526 06:09:00.882776 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.116052 (* 1 = 0.116052 loss)
I0526 06:09:00.882783 15117 sgd_solver.cpp:294] Iteration 30180, lr = 0.02
I0526 06:09:07.222580 15117 solver.cpp:233] Iteration 30190, loss = 0.175986
I0526 06:09:07.222620 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.175986 (* 1 = 0.175986 loss)
I0526 06:09:07.222626 15117 sgd_solver.cpp:294] Iteration 30190, lr = 0.02
I0526 06:09:12.956300 15117 solver.cpp:342] Iteration 30200, Testing net (#0)
I0526 06:09:25.796696 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7976
I0526 06:09:25.796921 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.973735 (* 1 = 0.973735 loss)
I0526 06:09:26.397843 15117 solver.cpp:233] Iteration 30200, loss = 0.0814976
I0526 06:09:26.397894 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0814978 (* 1 = 0.0814978 loss)
I0526 06:09:26.397903 15117 sgd_solver.cpp:294] Iteration 30200, lr = 0.02
I0526 06:09:32.729394 15117 solver.cpp:233] Iteration 30210, loss = 0.0874941
I0526 06:09:32.729430 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0874942 (* 1 = 0.0874942 loss)
I0526 06:09:32.729437 15117 sgd_solver.cpp:294] Iteration 30210, lr = 0.02
I0526 06:09:39.065167 15117 solver.cpp:233] Iteration 30220, loss = 0.128138
I0526 06:09:39.065207 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.128138 (* 1 = 0.128138 loss)
I0526 06:09:39.065213 15117 sgd_solver.cpp:294] Iteration 30220, lr = 0.02
I0526 06:09:45.398787 15117 solver.cpp:233] Iteration 30230, loss = 0.144588
I0526 06:09:45.398834 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.144588 (* 1 = 0.144588 loss)
I0526 06:09:45.398843 15117 sgd_solver.cpp:294] Iteration 30230, lr = 0.02
I0526 06:09:51.733568 15117 solver.cpp:233] Iteration 30240, loss = 0.0604893
I0526 06:09:51.733606 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0604895 (* 1 = 0.0604895 loss)
I0526 06:09:51.733613 15117 sgd_solver.cpp:294] Iteration 30240, lr = 0.02
I0526 06:09:58.069059 15117 solver.cpp:233] Iteration 30250, loss = 0.114114
I0526 06:09:58.069279 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.114115 (* 1 = 0.114115 loss)
I0526 06:09:58.069308 15117 sgd_solver.cpp:294] Iteration 30250, lr = 0.02
I0526 06:10:04.404834 15117 solver.cpp:233] Iteration 30260, loss = 0.0879767
I0526 06:10:04.404887 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0879769 (* 1 = 0.0879769 loss)
I0526 06:10:04.404894 15117 sgd_solver.cpp:294] Iteration 30260, lr = 0.02
I0526 06:10:10.742939 15117 solver.cpp:233] Iteration 30270, loss = 0.119888
I0526 06:10:10.742977 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.119888 (* 1 = 0.119888 loss)
I0526 06:10:10.742985 15117 sgd_solver.cpp:294] Iteration 30270, lr = 0.02
I0526 06:10:17.078049 15117 solver.cpp:233] Iteration 30280, loss = 0.0374378
I0526 06:10:17.078099 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0374379 (* 1 = 0.0374379 loss)
I0526 06:10:17.078104 15117 sgd_solver.cpp:294] Iteration 30280, lr = 0.02
I0526 06:10:23.411151 15117 solver.cpp:233] Iteration 30290, loss = 0.061723
I0526 06:10:23.411190 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0617232 (* 1 = 0.0617232 loss)
I0526 06:10:23.411196 15117 sgd_solver.cpp:294] Iteration 30290, lr = 0.02
I0526 06:10:29.144191 15117 solver.cpp:342] Iteration 30300, Testing net (#0)
I0526 06:10:41.990340 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.786
I0526 06:10:41.990417 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.01672 (* 1 = 1.01672 loss)
I0526 06:10:42.592268 15117 solver.cpp:233] Iteration 30300, loss = 0.0488241
I0526 06:10:42.592305 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0488242 (* 1 = 0.0488242 loss)
I0526 06:10:42.592313 15117 sgd_solver.cpp:294] Iteration 30300, lr = 0.02
I0526 06:10:48.928391 15117 solver.cpp:233] Iteration 30310, loss = 0.108854
I0526 06:10:48.928433 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.108854 (* 1 = 0.108854 loss)
I0526 06:10:48.928442 15117 sgd_solver.cpp:294] Iteration 30310, lr = 0.02
I0526 06:10:55.256165 15117 solver.cpp:233] Iteration 30320, loss = 0.16169
I0526 06:10:55.256202 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.16169 (* 1 = 0.16169 loss)
I0526 06:10:55.256209 15117 sgd_solver.cpp:294] Iteration 30320, lr = 0.02
I0526 06:11:01.590735 15117 solver.cpp:233] Iteration 30330, loss = 0.0748915
I0526 06:11:01.590956 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0748916 (* 1 = 0.0748916 loss)
I0526 06:11:01.590993 15117 sgd_solver.cpp:294] Iteration 30330, lr = 0.02
I0526 06:11:07.917541 15117 solver.cpp:233] Iteration 30340, loss = 0.0733157
I0526 06:11:07.917582 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0733159 (* 1 = 0.0733159 loss)
I0526 06:11:07.917590 15117 sgd_solver.cpp:294] Iteration 30340, lr = 0.02
I0526 06:11:14.251255 15117 solver.cpp:233] Iteration 30350, loss = 0.0645688
I0526 06:11:14.251296 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.064569 (* 1 = 0.064569 loss)
I0526 06:11:14.251313 15117 sgd_solver.cpp:294] Iteration 30350, lr = 0.02
I0526 06:11:20.588975 15117 solver.cpp:233] Iteration 30360, loss = 0.0859633
I0526 06:11:20.589016 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0859634 (* 1 = 0.0859634 loss)
I0526 06:11:20.589025 15117 sgd_solver.cpp:294] Iteration 30360, lr = 0.02
I0526 06:11:26.928005 15117 solver.cpp:233] Iteration 30370, loss = 0.107898
I0526 06:11:26.928045 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.107898 (* 1 = 0.107898 loss)
I0526 06:11:26.928052 15117 sgd_solver.cpp:294] Iteration 30370, lr = 0.02
I0526 06:11:33.264590 15117 solver.cpp:233] Iteration 30380, loss = 0.105965
I0526 06:11:33.264714 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.105965 (* 1 = 0.105965 loss)
I0526 06:11:33.264722 15117 sgd_solver.cpp:294] Iteration 30380, lr = 0.02
I0526 06:11:39.601472 15117 solver.cpp:233] Iteration 30390, loss = 0.0928741
I0526 06:11:39.601513 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0928743 (* 1 = 0.0928743 loss)
I0526 06:11:39.601521 15117 sgd_solver.cpp:294] Iteration 30390, lr = 0.02
I0526 06:11:45.333411 15117 solver.cpp:342] Iteration 30400, Testing net (#0)
I0526 06:11:58.175590 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8061
I0526 06:11:58.175634 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.802347 (* 1 = 0.802347 loss)
I0526 06:11:58.777389 15117 solver.cpp:233] Iteration 30400, loss = 0.0915543
I0526 06:11:58.777422 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0915544 (* 1 = 0.0915544 loss)
I0526 06:11:58.777431 15117 sgd_solver.cpp:294] Iteration 30400, lr = 0.02
I0526 06:12:05.113883 15117 solver.cpp:233] Iteration 30410, loss = 0.144347
I0526 06:12:05.114161 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.144347 (* 1 = 0.144347 loss)
I0526 06:12:05.114189 15117 sgd_solver.cpp:294] Iteration 30410, lr = 0.02
I0526 06:12:11.449455 15117 solver.cpp:233] Iteration 30420, loss = 0.137758
I0526 06:12:11.449502 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.137758 (* 1 = 0.137758 loss)
I0526 06:12:11.449512 15117 sgd_solver.cpp:294] Iteration 30420, lr = 0.02
I0526 06:12:17.786442 15117 solver.cpp:233] Iteration 30430, loss = 0.12647
I0526 06:12:17.786478 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.12647 (* 1 = 0.12647 loss)
I0526 06:12:17.786485 15117 sgd_solver.cpp:294] Iteration 30430, lr = 0.02
I0526 06:12:24.123823 15117 solver.cpp:233] Iteration 30440, loss = 0.078873
I0526 06:12:24.123860 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0788731 (* 1 = 0.0788731 loss)
I0526 06:12:24.123867 15117 sgd_solver.cpp:294] Iteration 30440, lr = 0.02
I0526 06:12:30.460791 15117 solver.cpp:233] Iteration 30450, loss = 0.103609
I0526 06:12:30.460830 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.103609 (* 1 = 0.103609 loss)
I0526 06:12:30.460836 15117 sgd_solver.cpp:294] Iteration 30450, lr = 0.02
I0526 06:12:36.799430 15117 solver.cpp:233] Iteration 30460, loss = 0.0690646
I0526 06:12:36.799577 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0690648 (* 1 = 0.0690648 loss)
I0526 06:12:36.799587 15117 sgd_solver.cpp:294] Iteration 30460, lr = 0.02
I0526 06:12:43.136723 15117 solver.cpp:233] Iteration 30470, loss = 0.0591972
I0526 06:12:43.136765 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0591973 (* 1 = 0.0591973 loss)
I0526 06:12:43.136772 15117 sgd_solver.cpp:294] Iteration 30470, lr = 0.02
I0526 06:12:49.476655 15117 solver.cpp:233] Iteration 30480, loss = 0.136384
I0526 06:12:49.476696 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.136384 (* 1 = 0.136384 loss)
I0526 06:12:49.476703 15117 sgd_solver.cpp:294] Iteration 30480, lr = 0.02
I0526 06:12:55.817749 15117 solver.cpp:233] Iteration 30490, loss = 0.0569891
I0526 06:12:55.817790 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0569892 (* 1 = 0.0569892 loss)
I0526 06:12:55.817796 15117 sgd_solver.cpp:294] Iteration 30490, lr = 0.02
I0526 06:13:01.557525 15117 solver.cpp:342] Iteration 30500, Testing net (#0)
I0526 06:13:14.396517 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8004
I0526 06:13:14.396720 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.793744 (* 1 = 0.793744 loss)
I0526 06:13:14.997251 15117 solver.cpp:233] Iteration 30500, loss = 0.0616128
I0526 06:13:14.997300 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0616129 (* 1 = 0.0616129 loss)
I0526 06:13:14.997309 15117 sgd_solver.cpp:294] Iteration 30500, lr = 0.02
I0526 06:13:21.332953 15117 solver.cpp:233] Iteration 30510, loss = 0.0583672
I0526 06:13:21.333006 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0583674 (* 1 = 0.0583674 loss)
I0526 06:13:21.333014 15117 sgd_solver.cpp:294] Iteration 30510, lr = 0.02
I0526 06:13:27.669015 15117 solver.cpp:233] Iteration 30520, loss = 0.0447438
I0526 06:13:27.669060 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0447439 (* 1 = 0.0447439 loss)
I0526 06:13:27.669067 15117 sgd_solver.cpp:294] Iteration 30520, lr = 0.02
I0526 06:13:34.004837 15117 solver.cpp:233] Iteration 30530, loss = 0.193923
I0526 06:13:34.004865 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.193923 (* 1 = 0.193923 loss)
I0526 06:13:34.004873 15117 sgd_solver.cpp:294] Iteration 30530, lr = 0.02
I0526 06:13:40.343731 15117 solver.cpp:233] Iteration 30540, loss = 0.0791315
I0526 06:13:40.343773 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0791316 (* 1 = 0.0791316 loss)
I0526 06:13:40.343780 15117 sgd_solver.cpp:294] Iteration 30540, lr = 0.02
I0526 06:13:46.683104 15117 solver.cpp:233] Iteration 30550, loss = 0.145674
I0526 06:13:46.683368 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.145674 (* 1 = 0.145674 loss)
I0526 06:13:46.683398 15117 sgd_solver.cpp:294] Iteration 30550, lr = 0.02
I0526 06:13:53.023396 15117 solver.cpp:233] Iteration 30560, loss = 0.136197
I0526 06:13:53.023437 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.136197 (* 1 = 0.136197 loss)
I0526 06:13:53.023443 15117 sgd_solver.cpp:294] Iteration 30560, lr = 0.02
I0526 06:13:59.361248 15117 solver.cpp:233] Iteration 30570, loss = 0.0724211
I0526 06:13:59.361289 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0724213 (* 1 = 0.0724213 loss)
I0526 06:13:59.361295 15117 sgd_solver.cpp:294] Iteration 30570, lr = 0.02
I0526 06:14:05.696840 15117 solver.cpp:233] Iteration 30580, loss = 0.0860533
I0526 06:14:05.696874 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0860535 (* 1 = 0.0860535 loss)
I0526 06:14:05.696882 15117 sgd_solver.cpp:294] Iteration 30580, lr = 0.02
I0526 06:14:12.036815 15117 solver.cpp:233] Iteration 30590, loss = 0.0789462
I0526 06:14:12.036859 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0789464 (* 1 = 0.0789464 loss)
I0526 06:14:12.036865 15117 sgd_solver.cpp:294] Iteration 30590, lr = 0.02
I0526 06:14:17.777079 15117 solver.cpp:342] Iteration 30600, Testing net (#0)
I0526 06:14:30.628414 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8292
I0526 06:14:30.628461 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.663015 (* 1 = 0.663015 loss)
I0526 06:14:31.230926 15117 solver.cpp:233] Iteration 30600, loss = 0.0488041
I0526 06:14:31.230952 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0488043 (* 1 = 0.0488043 loss)
I0526 06:14:31.230959 15117 sgd_solver.cpp:294] Iteration 30600, lr = 0.02
I0526 06:14:37.569984 15117 solver.cpp:233] Iteration 30610, loss = 0.0787708
I0526 06:14:37.570034 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.078771 (* 1 = 0.078771 loss)
I0526 06:14:37.570041 15117 sgd_solver.cpp:294] Iteration 30610, lr = 0.02
I0526 06:14:43.904542 15117 solver.cpp:233] Iteration 30620, loss = 0.0805243
I0526 06:14:43.904582 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0805244 (* 1 = 0.0805244 loss)
I0526 06:14:43.904590 15117 sgd_solver.cpp:294] Iteration 30620, lr = 0.02
I0526 06:14:50.239615 15117 solver.cpp:233] Iteration 30630, loss = 0.137259
I0526 06:14:50.239842 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.13726 (* 1 = 0.13726 loss)
I0526 06:14:50.239871 15117 sgd_solver.cpp:294] Iteration 30630, lr = 0.02
I0526 06:14:56.572672 15117 solver.cpp:233] Iteration 30640, loss = 0.0574052
I0526 06:14:56.572715 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0574054 (* 1 = 0.0574054 loss)
I0526 06:14:56.572721 15117 sgd_solver.cpp:294] Iteration 30640, lr = 0.02
I0526 06:15:02.908649 15117 solver.cpp:233] Iteration 30650, loss = 0.0444117
I0526 06:15:02.908713 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0444119 (* 1 = 0.0444119 loss)
I0526 06:15:02.908720 15117 sgd_solver.cpp:294] Iteration 30650, lr = 0.02
I0526 06:15:09.243510 15117 solver.cpp:233] Iteration 30660, loss = 0.18284
I0526 06:15:09.243551 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.18284 (* 1 = 0.18284 loss)
I0526 06:15:09.243557 15117 sgd_solver.cpp:294] Iteration 30660, lr = 0.02
I0526 06:15:15.573055 15117 solver.cpp:233] Iteration 30670, loss = 0.0432221
I0526 06:15:15.573117 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0432222 (* 1 = 0.0432222 loss)
I0526 06:15:15.573125 15117 sgd_solver.cpp:294] Iteration 30670, lr = 0.02
I0526 06:15:21.906643 15117 solver.cpp:233] Iteration 30680, loss = 0.149414
I0526 06:15:21.906879 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.149414 (* 1 = 0.149414 loss)
I0526 06:15:21.906908 15117 sgd_solver.cpp:294] Iteration 30680, lr = 0.02
I0526 06:15:28.241045 15117 solver.cpp:233] Iteration 30690, loss = 0.117244
I0526 06:15:28.241091 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.117244 (* 1 = 0.117244 loss)
I0526 06:15:28.241099 15117 sgd_solver.cpp:294] Iteration 30690, lr = 0.02
I0526 06:15:33.977450 15117 solver.cpp:342] Iteration 30700, Testing net (#0)
I0526 06:15:46.814257 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8269
I0526 06:15:46.814303 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.705433 (* 1 = 0.705433 loss)
I0526 06:15:47.415169 15117 solver.cpp:233] Iteration 30700, loss = 0.0630251
I0526 06:15:47.415205 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0630253 (* 1 = 0.0630253 loss)
I0526 06:15:47.415212 15117 sgd_solver.cpp:294] Iteration 30700, lr = 0.02
I0526 06:15:53.744690 15117 solver.cpp:233] Iteration 30710, loss = 0.0842419
I0526 06:15:53.744956 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0842421 (* 1 = 0.0842421 loss)
I0526 06:15:53.744985 15117 sgd_solver.cpp:294] Iteration 30710, lr = 0.02
I0526 06:16:00.077486 15117 solver.cpp:233] Iteration 30720, loss = 0.139611
I0526 06:16:00.077527 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.139611 (* 1 = 0.139611 loss)
I0526 06:16:00.077534 15117 sgd_solver.cpp:294] Iteration 30720, lr = 0.02
I0526 06:16:06.417305 15117 solver.cpp:233] Iteration 30730, loss = 0.0871718
I0526 06:16:06.417348 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0871719 (* 1 = 0.0871719 loss)
I0526 06:16:06.417356 15117 sgd_solver.cpp:294] Iteration 30730, lr = 0.02
I0526 06:16:12.757200 15117 solver.cpp:233] Iteration 30740, loss = 0.160871
I0526 06:16:12.757243 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.160871 (* 1 = 0.160871 loss)
I0526 06:16:12.757251 15117 sgd_solver.cpp:294] Iteration 30740, lr = 0.02
I0526 06:16:19.089514 15117 solver.cpp:233] Iteration 30750, loss = 0.0855063
I0526 06:16:19.089555 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0855065 (* 1 = 0.0855065 loss)
I0526 06:16:19.089562 15117 sgd_solver.cpp:294] Iteration 30750, lr = 0.02
I0526 06:16:25.420583 15117 solver.cpp:233] Iteration 30760, loss = 0.12362
I0526 06:16:25.420817 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.12362 (* 1 = 0.12362 loss)
I0526 06:16:25.420846 15117 sgd_solver.cpp:294] Iteration 30760, lr = 0.02
I0526 06:16:31.754375 15117 solver.cpp:233] Iteration 30770, loss = 0.0918017
I0526 06:16:31.754416 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0918019 (* 1 = 0.0918019 loss)
I0526 06:16:31.754425 15117 sgd_solver.cpp:294] Iteration 30770, lr = 0.02
I0526 06:16:38.089761 15117 solver.cpp:233] Iteration 30780, loss = 0.116449
I0526 06:16:38.089805 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.11645 (* 1 = 0.11645 loss)
I0526 06:16:38.089813 15117 sgd_solver.cpp:294] Iteration 30780, lr = 0.02
I0526 06:16:44.428478 15117 solver.cpp:233] Iteration 30790, loss = 0.0942624
I0526 06:16:44.428527 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0942626 (* 1 = 0.0942626 loss)
I0526 06:16:44.428534 15117 sgd_solver.cpp:294] Iteration 30790, lr = 0.02
I0526 06:16:50.162704 15117 solver.cpp:342] Iteration 30800, Testing net (#0)
I0526 06:17:03.003226 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8203
I0526 06:17:03.003453 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.754117 (* 1 = 0.754117 loss)
I0526 06:17:03.603086 15117 solver.cpp:233] Iteration 30800, loss = 0.114746
I0526 06:17:03.603128 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.114746 (* 1 = 0.114746 loss)
I0526 06:17:03.603137 15117 sgd_solver.cpp:294] Iteration 30800, lr = 0.02
I0526 06:17:09.933583 15117 solver.cpp:233] Iteration 30810, loss = 0.095043
I0526 06:17:09.933627 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0950431 (* 1 = 0.0950431 loss)
I0526 06:17:09.933634 15117 sgd_solver.cpp:294] Iteration 30810, lr = 0.02
I0526 06:17:16.269629 15117 solver.cpp:233] Iteration 30820, loss = 0.130053
I0526 06:17:16.269675 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.130053 (* 1 = 0.130053 loss)
I0526 06:17:16.269683 15117 sgd_solver.cpp:294] Iteration 30820, lr = 0.02
I0526 06:17:22.607448 15117 solver.cpp:233] Iteration 30830, loss = 0.115963
I0526 06:17:22.607487 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.115964 (* 1 = 0.115964 loss)
I0526 06:17:22.607494 15117 sgd_solver.cpp:294] Iteration 30830, lr = 0.02
I0526 06:17:28.945638 15117 solver.cpp:233] Iteration 30840, loss = 0.061838
I0526 06:17:28.945677 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0618382 (* 1 = 0.0618382 loss)
I0526 06:17:28.945684 15117 sgd_solver.cpp:294] Iteration 30840, lr = 0.02
I0526 06:17:35.283747 15117 solver.cpp:233] Iteration 30850, loss = 0.0784741
I0526 06:17:35.284013 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0784743 (* 1 = 0.0784743 loss)
I0526 06:17:35.284042 15117 sgd_solver.cpp:294] Iteration 30850, lr = 0.02
I0526 06:17:41.621196 15117 solver.cpp:233] Iteration 30860, loss = 0.129437
I0526 06:17:41.621248 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.129438 (* 1 = 0.129438 loss)
I0526 06:17:41.621255 15117 sgd_solver.cpp:294] Iteration 30860, lr = 0.02
I0526 06:17:47.955587 15117 solver.cpp:233] Iteration 30870, loss = 0.0421921
I0526 06:17:47.955627 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0421923 (* 1 = 0.0421923 loss)
I0526 06:17:47.955634 15117 sgd_solver.cpp:294] Iteration 30870, lr = 0.02
I0526 06:17:54.292870 15117 solver.cpp:233] Iteration 30880, loss = 0.0719093
I0526 06:17:54.292918 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0719094 (* 1 = 0.0719094 loss)
I0526 06:17:54.292927 15117 sgd_solver.cpp:294] Iteration 30880, lr = 0.02
I0526 06:18:00.624279 15117 solver.cpp:233] Iteration 30890, loss = 0.0581782
I0526 06:18:00.624321 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0581784 (* 1 = 0.0581784 loss)
I0526 06:18:00.624328 15117 sgd_solver.cpp:294] Iteration 30890, lr = 0.02
I0526 06:18:06.356214 15117 solver.cpp:342] Iteration 30900, Testing net (#0)
I0526 06:18:19.182782 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8029
I0526 06:18:19.182834 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.838993 (* 1 = 0.838993 loss)
I0526 06:18:19.783818 15117 solver.cpp:233] Iteration 30900, loss = 0.0981593
I0526 06:18:19.783854 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0981595 (* 1 = 0.0981595 loss)
I0526 06:18:19.783861 15117 sgd_solver.cpp:294] Iteration 30900, lr = 0.02
I0526 06:18:26.117483 15117 solver.cpp:233] Iteration 30910, loss = 0.0843552
I0526 06:18:26.117522 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0843553 (* 1 = 0.0843553 loss)
I0526 06:18:26.117530 15117 sgd_solver.cpp:294] Iteration 30910, lr = 0.02
I0526 06:18:32.450978 15117 solver.cpp:233] Iteration 30920, loss = 0.114553
I0526 06:18:32.451020 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.114553 (* 1 = 0.114553 loss)
I0526 06:18:32.451025 15117 sgd_solver.cpp:294] Iteration 30920, lr = 0.02
I0526 06:18:38.784736 15117 solver.cpp:233] Iteration 30930, loss = 0.0531235
I0526 06:18:38.784967 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0531236 (* 1 = 0.0531236 loss)
I0526 06:18:38.784994 15117 sgd_solver.cpp:294] Iteration 30930, lr = 0.02
I0526 06:18:45.115417 15117 solver.cpp:233] Iteration 30940, loss = 0.0305664
I0526 06:18:45.115463 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0305666 (* 1 = 0.0305666 loss)
I0526 06:18:45.115470 15117 sgd_solver.cpp:294] Iteration 30940, lr = 0.02
I0526 06:18:51.450340 15117 solver.cpp:233] Iteration 30950, loss = 0.0567304
I0526 06:18:51.450393 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0567306 (* 1 = 0.0567306 loss)
I0526 06:18:51.450402 15117 sgd_solver.cpp:294] Iteration 30950, lr = 0.02
I0526 06:18:57.783124 15117 solver.cpp:233] Iteration 30960, loss = 0.0868044
I0526 06:18:57.783165 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0868046 (* 1 = 0.0868046 loss)
I0526 06:18:57.783172 15117 sgd_solver.cpp:294] Iteration 30960, lr = 0.02
I0526 06:19:04.115780 15117 solver.cpp:233] Iteration 30970, loss = 0.0939143
I0526 06:19:04.115831 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0939145 (* 1 = 0.0939145 loss)
I0526 06:19:04.115839 15117 sgd_solver.cpp:294] Iteration 30970, lr = 0.02
I0526 06:19:10.447963 15117 solver.cpp:233] Iteration 30980, loss = 0.102822
I0526 06:19:10.448225 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.102822 (* 1 = 0.102822 loss)
I0526 06:19:10.448253 15117 sgd_solver.cpp:294] Iteration 30980, lr = 0.02
I0526 06:19:16.777073 15117 solver.cpp:233] Iteration 30990, loss = 0.0656916
I0526 06:19:16.777113 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0656918 (* 1 = 0.0656918 loss)
I0526 06:19:16.777122 15117 sgd_solver.cpp:294] Iteration 30990, lr = 0.02
I0526 06:19:22.508384 15117 solver.cpp:342] Iteration 31000, Testing net (#0)
I0526 06:19:35.343492 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.841
I0526 06:19:35.343547 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.718884 (* 1 = 0.718884 loss)
I0526 06:19:35.945387 15117 solver.cpp:233] Iteration 31000, loss = 0.0525216
I0526 06:19:35.945432 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0525217 (* 1 = 0.0525217 loss)
I0526 06:19:35.945439 15117 sgd_solver.cpp:294] Iteration 31000, lr = 0.02
I0526 06:19:42.278194 15117 solver.cpp:233] Iteration 31010, loss = 0.0930759
I0526 06:19:42.278440 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0930761 (* 1 = 0.0930761 loss)
I0526 06:19:42.278470 15117 sgd_solver.cpp:294] Iteration 31010, lr = 0.02
I0526 06:19:48.612658 15117 solver.cpp:233] Iteration 31020, loss = 0.0425644
I0526 06:19:48.612705 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0425646 (* 1 = 0.0425646 loss)
I0526 06:19:48.612712 15117 sgd_solver.cpp:294] Iteration 31020, lr = 0.02
I0526 06:19:54.950129 15117 solver.cpp:233] Iteration 31030, loss = 0.114714
I0526 06:19:54.950165 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.114714 (* 1 = 0.114714 loss)
I0526 06:19:54.950171 15117 sgd_solver.cpp:294] Iteration 31030, lr = 0.02
I0526 06:20:01.286065 15117 solver.cpp:233] Iteration 31040, loss = 0.115132
I0526 06:20:01.286105 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.115133 (* 1 = 0.115133 loss)
I0526 06:20:01.286113 15117 sgd_solver.cpp:294] Iteration 31040, lr = 0.02
I0526 06:20:07.620901 15117 solver.cpp:233] Iteration 31050, loss = 0.113143
I0526 06:20:07.620939 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.113144 (* 1 = 0.113144 loss)
I0526 06:20:07.620947 15117 sgd_solver.cpp:294] Iteration 31050, lr = 0.02
I0526 06:20:13.960270 15117 solver.cpp:233] Iteration 31060, loss = 0.132185
I0526 06:20:13.960482 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.132185 (* 1 = 0.132185 loss)
I0526 06:20:13.960510 15117 sgd_solver.cpp:294] Iteration 31060, lr = 0.02
I0526 06:20:20.294126 15117 solver.cpp:233] Iteration 31070, loss = 0.0897991
I0526 06:20:20.294169 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0897993 (* 1 = 0.0897993 loss)
I0526 06:20:20.294176 15117 sgd_solver.cpp:294] Iteration 31070, lr = 0.02
I0526 06:20:26.626359 15117 solver.cpp:233] Iteration 31080, loss = 0.123264
I0526 06:20:26.626401 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.123264 (* 1 = 0.123264 loss)
I0526 06:20:26.626408 15117 sgd_solver.cpp:294] Iteration 31080, lr = 0.02
I0526 06:20:32.959626 15117 solver.cpp:233] Iteration 31090, loss = 0.107523
I0526 06:20:32.959667 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.107523 (* 1 = 0.107523 loss)
I0526 06:20:32.959674 15117 sgd_solver.cpp:294] Iteration 31090, lr = 0.02
I0526 06:20:38.693871 15117 solver.cpp:342] Iteration 31100, Testing net (#0)
I0526 06:20:51.533388 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8082
I0526 06:20:51.533666 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.826529 (* 1 = 0.826529 loss)
I0526 06:20:52.132161 15117 solver.cpp:233] Iteration 31100, loss = 0.126087
I0526 06:20:52.132207 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.126087 (* 1 = 0.126087 loss)
I0526 06:20:52.132216 15117 sgd_solver.cpp:294] Iteration 31100, lr = 0.02
I0526 06:20:58.470054 15117 solver.cpp:233] Iteration 31110, loss = 0.102748
I0526 06:20:58.470116 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.102748 (* 1 = 0.102748 loss)
I0526 06:20:58.470124 15117 sgd_solver.cpp:294] Iteration 31110, lr = 0.02
I0526 06:21:04.809016 15117 solver.cpp:233] Iteration 31120, loss = 0.106435
I0526 06:21:04.809058 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.106435 (* 1 = 0.106435 loss)
I0526 06:21:04.809065 15117 sgd_solver.cpp:294] Iteration 31120, lr = 0.02
I0526 06:21:11.143805 15117 solver.cpp:233] Iteration 31130, loss = 0.0749337
I0526 06:21:11.143856 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0749339 (* 1 = 0.0749339 loss)
I0526 06:21:11.143862 15117 sgd_solver.cpp:294] Iteration 31130, lr = 0.02
I0526 06:21:17.480252 15117 solver.cpp:233] Iteration 31140, loss = 0.122179
I0526 06:21:17.480298 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.122179 (* 1 = 0.122179 loss)
I0526 06:21:17.480304 15117 sgd_solver.cpp:294] Iteration 31140, lr = 0.02
I0526 06:21:23.816256 15117 solver.cpp:233] Iteration 31150, loss = 0.0517765
I0526 06:21:23.816483 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0517767 (* 1 = 0.0517767 loss)
I0526 06:21:23.816510 15117 sgd_solver.cpp:294] Iteration 31150, lr = 0.02
I0526 06:21:30.155371 15117 solver.cpp:233] Iteration 31160, loss = 0.165814
I0526 06:21:30.155416 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.165815 (* 1 = 0.165815 loss)
I0526 06:21:30.155422 15117 sgd_solver.cpp:294] Iteration 31160, lr = 0.02
I0526 06:21:36.493401 15117 solver.cpp:233] Iteration 31170, loss = 0.121703
I0526 06:21:36.493441 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.121703 (* 1 = 0.121703 loss)
I0526 06:21:36.493448 15117 sgd_solver.cpp:294] Iteration 31170, lr = 0.02
I0526 06:21:42.832176 15117 solver.cpp:233] Iteration 31180, loss = 0.0851742
I0526 06:21:42.832218 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0851744 (* 1 = 0.0851744 loss)
I0526 06:21:42.832226 15117 sgd_solver.cpp:294] Iteration 31180, lr = 0.02
I0526 06:21:49.167814 15117 solver.cpp:233] Iteration 31190, loss = 0.111878
I0526 06:21:49.167855 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.111878 (* 1 = 0.111878 loss)
I0526 06:21:49.167861 15117 sgd_solver.cpp:294] Iteration 31190, lr = 0.02
I0526 06:21:54.901093 15117 solver.cpp:342] Iteration 31200, Testing net (#0)
I0526 06:22:07.739979 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8237
I0526 06:22:07.740022 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.818357 (* 1 = 0.818357 loss)
I0526 06:22:08.341200 15117 solver.cpp:233] Iteration 31200, loss = 0.0919432
I0526 06:22:08.341236 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0919434 (* 1 = 0.0919434 loss)
I0526 06:22:08.341243 15117 sgd_solver.cpp:294] Iteration 31200, lr = 0.02
I0526 06:22:14.679249 15117 solver.cpp:233] Iteration 31210, loss = 0.075051
I0526 06:22:14.679291 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0750512 (* 1 = 0.0750512 loss)
I0526 06:22:14.679298 15117 sgd_solver.cpp:294] Iteration 31210, lr = 0.02
I0526 06:22:21.011108 15117 solver.cpp:233] Iteration 31220, loss = 0.0639809
I0526 06:22:21.011139 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.063981 (* 1 = 0.063981 loss)
I0526 06:22:21.011147 15117 sgd_solver.cpp:294] Iteration 31220, lr = 0.02
I0526 06:22:27.346079 15117 solver.cpp:233] Iteration 31230, loss = 0.0313143
I0526 06:22:27.346380 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0313145 (* 1 = 0.0313145 loss)
I0526 06:22:27.346410 15117 sgd_solver.cpp:294] Iteration 31230, lr = 0.02
I0526 06:22:33.682415 15117 solver.cpp:233] Iteration 31240, loss = 0.084949
I0526 06:22:33.682457 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0849492 (* 1 = 0.0849492 loss)
I0526 06:22:33.682466 15117 sgd_solver.cpp:294] Iteration 31240, lr = 0.02
I0526 06:22:40.019728 15117 solver.cpp:233] Iteration 31250, loss = 0.114794
I0526 06:22:40.019770 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.114794 (* 1 = 0.114794 loss)
I0526 06:22:40.019778 15117 sgd_solver.cpp:294] Iteration 31250, lr = 0.02
I0526 06:22:46.352331 15117 solver.cpp:233] Iteration 31260, loss = 0.090437
I0526 06:22:46.352382 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0904371 (* 1 = 0.0904371 loss)
I0526 06:22:46.352390 15117 sgd_solver.cpp:294] Iteration 31260, lr = 0.02
I0526 06:22:52.691148 15117 solver.cpp:233] Iteration 31270, loss = 0.10309
I0526 06:22:52.691190 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.10309 (* 1 = 0.10309 loss)
I0526 06:22:52.691198 15117 sgd_solver.cpp:294] Iteration 31270, lr = 0.02
I0526 06:22:59.026468 15117 solver.cpp:233] Iteration 31280, loss = 0.0839291
I0526 06:22:59.026705 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0839293 (* 1 = 0.0839293 loss)
I0526 06:22:59.026733 15117 sgd_solver.cpp:294] Iteration 31280, lr = 0.02
I0526 06:23:05.361598 15117 solver.cpp:233] Iteration 31290, loss = 0.07515
I0526 06:23:05.361634 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0751502 (* 1 = 0.0751502 loss)
I0526 06:23:05.361640 15117 sgd_solver.cpp:294] Iteration 31290, lr = 0.02
I0526 06:23:11.089484 15117 solver.cpp:342] Iteration 31300, Testing net (#0)
I0526 06:23:23.938552 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8243
I0526 06:23:23.938596 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.761285 (* 1 = 0.761285 loss)
I0526 06:23:24.539402 15117 solver.cpp:233] Iteration 31300, loss = 0.130909
I0526 06:23:24.539441 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.130909 (* 1 = 0.130909 loss)
I0526 06:23:24.539449 15117 sgd_solver.cpp:294] Iteration 31300, lr = 0.02
I0526 06:23:30.877923 15117 solver.cpp:233] Iteration 31310, loss = 0.0713635
I0526 06:23:30.878060 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0713637 (* 1 = 0.0713637 loss)
I0526 06:23:30.878070 15117 sgd_solver.cpp:294] Iteration 31310, lr = 0.02
I0526 06:23:37.219285 15117 solver.cpp:233] Iteration 31320, loss = 0.158067
I0526 06:23:37.219323 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.158067 (* 1 = 0.158067 loss)
I0526 06:23:37.219331 15117 sgd_solver.cpp:294] Iteration 31320, lr = 0.02
I0526 06:23:43.557265 15117 solver.cpp:233] Iteration 31330, loss = 0.124715
I0526 06:23:43.557306 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.124715 (* 1 = 0.124715 loss)
I0526 06:23:43.557312 15117 sgd_solver.cpp:294] Iteration 31330, lr = 0.02
I0526 06:23:49.891973 15117 solver.cpp:233] Iteration 31340, loss = 0.0661457
I0526 06:23:49.892001 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0661459 (* 1 = 0.0661459 loss)
I0526 06:23:49.892009 15117 sgd_solver.cpp:294] Iteration 31340, lr = 0.02
I0526 06:23:56.211253 15117 solver.cpp:233] Iteration 31350, loss = 0.0675901
I0526 06:23:56.211294 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0675903 (* 1 = 0.0675903 loss)
I0526 06:23:56.211302 15117 sgd_solver.cpp:294] Iteration 31350, lr = 0.02
I0526 06:24:02.524586 15117 solver.cpp:233] Iteration 31360, loss = 0.201396
I0526 06:24:02.524792 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.201396 (* 1 = 0.201396 loss)
I0526 06:24:02.524821 15117 sgd_solver.cpp:294] Iteration 31360, lr = 0.02
I0526 06:24:08.840879 15117 solver.cpp:233] Iteration 31370, loss = 0.0722003
I0526 06:24:08.840936 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0722005 (* 1 = 0.0722005 loss)
I0526 06:24:08.840945 15117 sgd_solver.cpp:294] Iteration 31370, lr = 0.02
I0526 06:24:15.154121 15117 solver.cpp:233] Iteration 31380, loss = 0.0618695
I0526 06:24:15.154161 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0618697 (* 1 = 0.0618697 loss)
I0526 06:24:15.154168 15117 sgd_solver.cpp:294] Iteration 31380, lr = 0.02
I0526 06:24:21.466987 15117 solver.cpp:233] Iteration 31390, loss = 0.148902
I0526 06:24:21.467023 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.148902 (* 1 = 0.148902 loss)
I0526 06:24:21.467031 15117 sgd_solver.cpp:294] Iteration 31390, lr = 0.02
I0526 06:24:27.183938 15117 solver.cpp:342] Iteration 31400, Testing net (#0)
I0526 06:24:40.007405 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8202
I0526 06:24:40.007678 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.664122 (* 1 = 0.664122 loss)
I0526 06:24:40.610045 15117 solver.cpp:233] Iteration 31400, loss = 0.054146
I0526 06:24:40.610085 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0541462 (* 1 = 0.0541462 loss)
I0526 06:24:40.610092 15117 sgd_solver.cpp:294] Iteration 31400, lr = 0.02
I0526 06:24:46.948496 15117 solver.cpp:233] Iteration 31410, loss = 0.0790867
I0526 06:24:46.948539 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0790869 (* 1 = 0.0790869 loss)
I0526 06:24:46.948545 15117 sgd_solver.cpp:294] Iteration 31410, lr = 0.02
I0526 06:24:53.284631 15117 solver.cpp:233] Iteration 31420, loss = 0.0699972
I0526 06:24:53.284670 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0699974 (* 1 = 0.0699974 loss)
I0526 06:24:53.284677 15117 sgd_solver.cpp:294] Iteration 31420, lr = 0.02
I0526 06:24:59.619216 15117 solver.cpp:233] Iteration 31430, loss = 0.0750194
I0526 06:24:59.619259 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0750196 (* 1 = 0.0750196 loss)
I0526 06:24:59.619266 15117 sgd_solver.cpp:294] Iteration 31430, lr = 0.02
I0526 06:25:05.955947 15117 solver.cpp:233] Iteration 31440, loss = 0.0817354
I0526 06:25:05.955993 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0817356 (* 1 = 0.0817356 loss)
I0526 06:25:05.956001 15117 sgd_solver.cpp:294] Iteration 31440, lr = 0.02
I0526 06:25:12.293648 15117 solver.cpp:233] Iteration 31450, loss = 0.122245
I0526 06:25:12.293861 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.122245 (* 1 = 0.122245 loss)
I0526 06:25:12.293897 15117 sgd_solver.cpp:294] Iteration 31450, lr = 0.02
I0526 06:25:18.622237 15117 solver.cpp:233] Iteration 31460, loss = 0.0604564
I0526 06:25:18.622282 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0604566 (* 1 = 0.0604566 loss)
I0526 06:25:18.622288 15117 sgd_solver.cpp:294] Iteration 31460, lr = 0.02
I0526 06:25:24.930662 15117 solver.cpp:233] Iteration 31470, loss = 0.0628136
I0526 06:25:24.930703 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0628138 (* 1 = 0.0628138 loss)
I0526 06:25:24.930721 15117 sgd_solver.cpp:294] Iteration 31470, lr = 0.02
I0526 06:25:31.244925 15117 solver.cpp:233] Iteration 31480, loss = 0.149468
I0526 06:25:31.244967 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.149468 (* 1 = 0.149468 loss)
I0526 06:25:31.244974 15117 sgd_solver.cpp:294] Iteration 31480, lr = 0.02
I0526 06:25:37.553930 15117 solver.cpp:233] Iteration 31490, loss = 0.108394
I0526 06:25:37.553972 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.108395 (* 1 = 0.108395 loss)
I0526 06:25:37.553979 15117 sgd_solver.cpp:294] Iteration 31490, lr = 0.02
I0526 06:25:43.268548 15117 solver.cpp:342] Iteration 31500, Testing net (#0)
I0526 06:25:56.088896 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.815901
I0526 06:25:56.088938 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.773346 (* 1 = 0.773346 loss)
I0526 06:25:56.688658 15117 solver.cpp:233] Iteration 31500, loss = 0.128022
I0526 06:25:56.688686 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.128022 (* 1 = 0.128022 loss)
I0526 06:25:56.688694 15117 sgd_solver.cpp:294] Iteration 31500, lr = 0.02
I0526 06:26:02.997109 15117 solver.cpp:233] Iteration 31510, loss = 0.149513
I0526 06:26:02.997149 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.149514 (* 1 = 0.149514 loss)
I0526 06:26:02.997158 15117 sgd_solver.cpp:294] Iteration 31510, lr = 0.02
I0526 06:26:09.311318 15117 solver.cpp:233] Iteration 31520, loss = 0.086928
I0526 06:26:09.311357 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0869281 (* 1 = 0.0869281 loss)
I0526 06:26:09.311365 15117 sgd_solver.cpp:294] Iteration 31520, lr = 0.02
I0526 06:26:15.624116 15117 solver.cpp:233] Iteration 31530, loss = 0.107076
I0526 06:26:15.624338 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.107076 (* 1 = 0.107076 loss)
I0526 06:26:15.624367 15117 sgd_solver.cpp:294] Iteration 31530, lr = 0.02
I0526 06:26:21.953886 15117 solver.cpp:233] Iteration 31540, loss = 0.0746545
I0526 06:26:21.953922 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0746547 (* 1 = 0.0746547 loss)
I0526 06:26:21.953930 15117 sgd_solver.cpp:294] Iteration 31540, lr = 0.02
I0526 06:26:28.295197 15117 solver.cpp:233] Iteration 31550, loss = 0.10132
I0526 06:26:28.295251 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.10132 (* 1 = 0.10132 loss)
I0526 06:26:28.295258 15117 sgd_solver.cpp:294] Iteration 31550, lr = 0.02
I0526 06:26:34.628507 15117 solver.cpp:233] Iteration 31560, loss = 0.162309
I0526 06:26:34.628569 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.162309 (* 1 = 0.162309 loss)
I0526 06:26:34.628576 15117 sgd_solver.cpp:294] Iteration 31560, lr = 0.02
I0526 06:26:40.963834 15117 solver.cpp:233] Iteration 31570, loss = 0.163709
I0526 06:26:40.963884 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.16371 (* 1 = 0.16371 loss)
I0526 06:26:40.963902 15117 sgd_solver.cpp:294] Iteration 31570, lr = 0.02
I0526 06:26:47.299733 15117 solver.cpp:233] Iteration 31580, loss = 0.0526212
I0526 06:26:47.299971 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0526214 (* 1 = 0.0526214 loss)
I0526 06:26:47.300000 15117 sgd_solver.cpp:294] Iteration 31580, lr = 0.02
I0526 06:26:53.632860 15117 solver.cpp:233] Iteration 31590, loss = 0.0454272
I0526 06:26:53.632912 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0454273 (* 1 = 0.0454273 loss)
I0526 06:26:53.632920 15117 sgd_solver.cpp:294] Iteration 31590, lr = 0.02
I0526 06:26:59.361863 15117 solver.cpp:342] Iteration 31600, Testing net (#0)
I0526 06:27:12.196938 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8193
I0526 06:27:12.196984 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.799692 (* 1 = 0.799692 loss)
I0526 06:27:12.799104 15117 solver.cpp:233] Iteration 31600, loss = 0.0527394
I0526 06:27:12.799149 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0527396 (* 1 = 0.0527396 loss)
I0526 06:27:12.799157 15117 sgd_solver.cpp:294] Iteration 31600, lr = 0.02
I0526 06:27:19.138797 15117 solver.cpp:233] Iteration 31610, loss = 0.0492189
I0526 06:27:19.139011 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.049219 (* 1 = 0.049219 loss)
I0526 06:27:19.139039 15117 sgd_solver.cpp:294] Iteration 31610, lr = 0.02
I0526 06:27:25.473933 15117 solver.cpp:233] Iteration 31620, loss = 0.0882767
I0526 06:27:25.473973 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0882769 (* 1 = 0.0882769 loss)
I0526 06:27:25.473980 15117 sgd_solver.cpp:294] Iteration 31620, lr = 0.02
I0526 06:27:31.812099 15117 solver.cpp:233] Iteration 31630, loss = 0.0896954
I0526 06:27:31.812134 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0896956 (* 1 = 0.0896956 loss)
I0526 06:27:31.812140 15117 sgd_solver.cpp:294] Iteration 31630, lr = 0.02
I0526 06:27:38.150179 15117 solver.cpp:233] Iteration 31640, loss = 0.107984
I0526 06:27:38.150226 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.107984 (* 1 = 0.107984 loss)
I0526 06:27:38.150234 15117 sgd_solver.cpp:294] Iteration 31640, lr = 0.02
I0526 06:27:44.486029 15117 solver.cpp:233] Iteration 31650, loss = 0.092209
I0526 06:27:44.486088 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0922092 (* 1 = 0.0922092 loss)
I0526 06:27:44.486095 15117 sgd_solver.cpp:294] Iteration 31650, lr = 0.02
I0526 06:27:50.819026 15117 solver.cpp:233] Iteration 31660, loss = 0.0788853
I0526 06:27:50.819285 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0788855 (* 1 = 0.0788855 loss)
I0526 06:27:50.819314 15117 sgd_solver.cpp:294] Iteration 31660, lr = 0.02
I0526 06:27:57.154659 15117 solver.cpp:233] Iteration 31670, loss = 0.0734493
I0526 06:27:57.154698 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0734495 (* 1 = 0.0734495 loss)
I0526 06:27:57.154707 15117 sgd_solver.cpp:294] Iteration 31670, lr = 0.02
I0526 06:28:03.485167 15117 solver.cpp:233] Iteration 31680, loss = 0.149822
I0526 06:28:03.485205 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.149822 (* 1 = 0.149822 loss)
I0526 06:28:03.485213 15117 sgd_solver.cpp:294] Iteration 31680, lr = 0.02
I0526 06:28:09.823920 15117 solver.cpp:233] Iteration 31690, loss = 0.0961839
I0526 06:28:09.823971 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0961841 (* 1 = 0.0961841 loss)
I0526 06:28:09.823977 15117 sgd_solver.cpp:294] Iteration 31690, lr = 0.02
I0526 06:28:15.559015 15117 solver.cpp:342] Iteration 31700, Testing net (#0)
I0526 06:28:28.396662 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8264
I0526 06:28:28.396901 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.703512 (* 1 = 0.703512 loss)
I0526 06:28:28.997267 15117 solver.cpp:233] Iteration 31700, loss = 0.0416985
I0526 06:28:28.997300 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0416986 (* 1 = 0.0416986 loss)
I0526 06:28:28.997309 15117 sgd_solver.cpp:294] Iteration 31700, lr = 0.02
I0526 06:28:35.329717 15117 solver.cpp:233] Iteration 31710, loss = 0.0780384
I0526 06:28:35.329756 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0780386 (* 1 = 0.0780386 loss)
I0526 06:28:35.329762 15117 sgd_solver.cpp:294] Iteration 31710, lr = 0.02
I0526 06:28:41.664628 15117 solver.cpp:233] Iteration 31720, loss = 0.190816
I0526 06:28:41.664670 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.190816 (* 1 = 0.190816 loss)
I0526 06:28:41.664679 15117 sgd_solver.cpp:294] Iteration 31720, lr = 0.02
I0526 06:28:47.997944 15117 solver.cpp:233] Iteration 31730, loss = 0.141905
I0526 06:28:47.997987 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.141905 (* 1 = 0.141905 loss)
I0526 06:28:47.997993 15117 sgd_solver.cpp:294] Iteration 31730, lr = 0.02
I0526 06:28:54.333602 15117 solver.cpp:233] Iteration 31740, loss = 0.057074
I0526 06:28:54.333658 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0570741 (* 1 = 0.0570741 loss)
I0526 06:28:54.333667 15117 sgd_solver.cpp:294] Iteration 31740, lr = 0.02
I0526 06:29:00.672847 15117 solver.cpp:233] Iteration 31750, loss = 0.0894143
I0526 06:29:00.673051 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0894144 (* 1 = 0.0894144 loss)
I0526 06:29:00.673077 15117 sgd_solver.cpp:294] Iteration 31750, lr = 0.02
I0526 06:29:07.007339 15117 solver.cpp:233] Iteration 31760, loss = 0.140994
I0526 06:29:07.007380 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.140994 (* 1 = 0.140994 loss)
I0526 06:29:07.007388 15117 sgd_solver.cpp:294] Iteration 31760, lr = 0.02
I0526 06:29:13.343899 15117 solver.cpp:233] Iteration 31770, loss = 0.132632
I0526 06:29:13.343937 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.132632 (* 1 = 0.132632 loss)
I0526 06:29:13.343943 15117 sgd_solver.cpp:294] Iteration 31770, lr = 0.02
I0526 06:29:19.678261 15117 solver.cpp:233] Iteration 31780, loss = 0.0616459
I0526 06:29:19.678323 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.061646 (* 1 = 0.061646 loss)
I0526 06:29:19.678331 15117 sgd_solver.cpp:294] Iteration 31780, lr = 0.02
I0526 06:29:26.014348 15117 solver.cpp:233] Iteration 31790, loss = 0.102497
I0526 06:29:26.014405 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.102497 (* 1 = 0.102497 loss)
I0526 06:29:26.014411 15117 sgd_solver.cpp:294] Iteration 31790, lr = 0.02
I0526 06:29:31.753172 15117 solver.cpp:342] Iteration 31800, Testing net (#0)
I0526 06:29:44.593890 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.7744
I0526 06:29:44.593933 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.0495 (* 1 = 1.0495 loss)
I0526 06:29:45.194790 15117 solver.cpp:233] Iteration 31800, loss = 0.0951782
I0526 06:29:45.194830 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0951784 (* 1 = 0.0951784 loss)
I0526 06:29:45.194839 15117 sgd_solver.cpp:294] Iteration 31800, lr = 0.02
I0526 06:29:51.533725 15117 solver.cpp:233] Iteration 31810, loss = 0.0593333
I0526 06:29:51.533762 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0593335 (* 1 = 0.0593335 loss)
I0526 06:29:51.533771 15117 sgd_solver.cpp:294] Iteration 31810, lr = 0.02
I0526 06:29:57.871795 15117 solver.cpp:233] Iteration 31820, loss = 0.207604
I0526 06:29:57.871840 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.207604 (* 1 = 0.207604 loss)
I0526 06:29:57.871846 15117 sgd_solver.cpp:294] Iteration 31820, lr = 0.02
I0526 06:30:04.200717 15117 solver.cpp:233] Iteration 31830, loss = 0.0915632
I0526 06:30:04.200949 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0915634 (* 1 = 0.0915634 loss)
I0526 06:30:04.200978 15117 sgd_solver.cpp:294] Iteration 31830, lr = 0.02
I0526 06:30:10.528827 15117 solver.cpp:233] Iteration 31840, loss = 0.1089
I0526 06:30:10.528869 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.1089 (* 1 = 0.1089 loss)
I0526 06:30:10.528877 15117 sgd_solver.cpp:294] Iteration 31840, lr = 0.02
I0526 06:30:16.866266 15117 solver.cpp:233] Iteration 31850, loss = 0.109472
I0526 06:30:16.866309 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.109472 (* 1 = 0.109472 loss)
I0526 06:30:16.866317 15117 sgd_solver.cpp:294] Iteration 31850, lr = 0.02
I0526 06:30:23.204670 15117 solver.cpp:233] Iteration 31860, loss = 0.0706175
I0526 06:30:23.204712 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0706177 (* 1 = 0.0706177 loss)
I0526 06:30:23.204720 15117 sgd_solver.cpp:294] Iteration 31860, lr = 0.02
I0526 06:30:29.533846 15117 solver.cpp:233] Iteration 31870, loss = 0.081196
I0526 06:30:29.533890 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0811962 (* 1 = 0.0811962 loss)
I0526 06:30:29.533898 15117 sgd_solver.cpp:294] Iteration 31870, lr = 0.02
I0526 06:30:35.866291 15117 solver.cpp:233] Iteration 31880, loss = 0.173945
I0526 06:30:35.866515 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.173945 (* 1 = 0.173945 loss)
I0526 06:30:35.866542 15117 sgd_solver.cpp:294] Iteration 31880, lr = 0.02
I0526 06:30:42.197207 15117 solver.cpp:233] Iteration 31890, loss = 0.0652748
I0526 06:30:42.197245 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.065275 (* 1 = 0.065275 loss)
I0526 06:30:42.197253 15117 sgd_solver.cpp:294] Iteration 31890, lr = 0.02
I0526 06:30:47.933823 15117 solver.cpp:342] Iteration 31900, Testing net (#0)
I0526 06:31:00.767449 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8175
I0526 06:31:00.767490 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.763289 (* 1 = 0.763289 loss)
I0526 06:31:01.367321 15117 solver.cpp:233] Iteration 31900, loss = 0.0830437
I0526 06:31:01.367357 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0830439 (* 1 = 0.0830439 loss)
I0526 06:31:01.367364 15117 sgd_solver.cpp:294] Iteration 31900, lr = 0.02
I0526 06:31:07.704223 15117 solver.cpp:233] Iteration 31910, loss = 0.0728086
I0526 06:31:07.704505 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0728088 (* 1 = 0.0728088 loss)
I0526 06:31:07.704538 15117 sgd_solver.cpp:294] Iteration 31910, lr = 0.02
I0526 06:31:14.038460 15117 solver.cpp:233] Iteration 31920, loss = 0.0585263
I0526 06:31:14.038508 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0585265 (* 1 = 0.0585265 loss)
I0526 06:31:14.038516 15117 sgd_solver.cpp:294] Iteration 31920, lr = 0.02
I0526 06:31:20.374289 15117 solver.cpp:233] Iteration 31930, loss = 0.0942196
I0526 06:31:20.374330 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0942198 (* 1 = 0.0942198 loss)
I0526 06:31:20.374337 15117 sgd_solver.cpp:294] Iteration 31930, lr = 0.02
I0526 06:31:26.711669 15117 solver.cpp:233] Iteration 31940, loss = 0.0962074
I0526 06:31:26.711707 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0962076 (* 1 = 0.0962076 loss)
I0526 06:31:26.711714 15117 sgd_solver.cpp:294] Iteration 31940, lr = 0.02
I0526 06:31:33.045472 15117 solver.cpp:233] Iteration 31950, loss = 0.15495
I0526 06:31:33.045512 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.15495 (* 1 = 0.15495 loss)
I0526 06:31:33.045519 15117 sgd_solver.cpp:294] Iteration 31950, lr = 0.02
I0526 06:31:39.379595 15117 solver.cpp:233] Iteration 31960, loss = 0.1449
I0526 06:31:39.379814 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.1449 (* 1 = 0.1449 loss)
I0526 06:31:39.379843 15117 sgd_solver.cpp:294] Iteration 31960, lr = 0.02
I0526 06:31:45.712950 15117 solver.cpp:233] Iteration 31970, loss = 0.0511851
I0526 06:31:45.712992 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0511854 (* 1 = 0.0511854 loss)
I0526 06:31:45.713011 15117 sgd_solver.cpp:294] Iteration 31970, lr = 0.02
I0526 06:31:52.048637 15117 solver.cpp:233] Iteration 31980, loss = 0.0457872
I0526 06:31:52.048676 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0457874 (* 1 = 0.0457874 loss)
I0526 06:31:52.048682 15117 sgd_solver.cpp:294] Iteration 31980, lr = 0.02
I0526 06:31:58.383271 15117 solver.cpp:233] Iteration 31990, loss = 0.110193
I0526 06:31:58.383311 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.110193 (* 1 = 0.110193 loss)
I0526 06:31:58.383318 15117 sgd_solver.cpp:294] Iteration 31990, lr = 0.02
I0526 06:32:04.115597 15117 solver.cpp:342] Iteration 32000, Testing net (#0)
I0526 06:32:16.954102 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8208
I0526 06:32:16.954322 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.854793 (* 1 = 0.854793 loss)
I0526 06:32:17.555058 15117 solver.cpp:233] Iteration 32000, loss = 0.122361
I0526 06:32:17.555104 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.122361 (* 1 = 0.122361 loss)
I0526 06:32:17.555111 15117 sgd_solver.cpp:234] MultiStep Status: Iteration 32000, step = 1
I0526 06:32:17.555116 15117 sgd_solver.cpp:294] Iteration 32000, lr = 0.002
I0526 06:32:23.886410 15117 solver.cpp:233] Iteration 32010, loss = 0.0447803
I0526 06:32:23.886450 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0447805 (* 1 = 0.0447805 loss)
I0526 06:32:23.886456 15117 sgd_solver.cpp:294] Iteration 32010, lr = 0.002
I0526 06:32:30.219216 15117 solver.cpp:233] Iteration 32020, loss = 0.0960791
I0526 06:32:30.219256 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0960793 (* 1 = 0.0960793 loss)
I0526 06:32:30.219264 15117 sgd_solver.cpp:294] Iteration 32020, lr = 0.002
I0526 06:32:36.555212 15117 solver.cpp:233] Iteration 32030, loss = 0.106398
I0526 06:32:36.555253 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.106398 (* 1 = 0.106398 loss)
I0526 06:32:36.555259 15117 sgd_solver.cpp:294] Iteration 32030, lr = 0.002
I0526 06:32:42.885655 15117 solver.cpp:233] Iteration 32040, loss = 0.106215
I0526 06:32:42.885704 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.106215 (* 1 = 0.106215 loss)
I0526 06:32:42.885712 15117 sgd_solver.cpp:294] Iteration 32040, lr = 0.002
I0526 06:32:49.222453 15117 solver.cpp:233] Iteration 32050, loss = 0.0614558
I0526 06:32:49.222718 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.061456 (* 1 = 0.061456 loss)
I0526 06:32:49.222746 15117 sgd_solver.cpp:294] Iteration 32050, lr = 0.002
I0526 06:32:55.548737 15117 solver.cpp:233] Iteration 32060, loss = 0.0470111
I0526 06:32:55.548765 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0470112 (* 1 = 0.0470112 loss)
I0526 06:32:55.548784 15117 sgd_solver.cpp:294] Iteration 32060, lr = 0.002
I0526 06:33:01.885874 15117 solver.cpp:233] Iteration 32070, loss = 0.159392
I0526 06:33:01.885917 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.159393 (* 1 = 0.159393 loss)
I0526 06:33:01.885924 15117 sgd_solver.cpp:294] Iteration 32070, lr = 0.002
I0526 06:33:08.222908 15117 solver.cpp:233] Iteration 32080, loss = 0.0812218
I0526 06:33:08.222952 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0812219 (* 1 = 0.0812219 loss)
I0526 06:33:08.222961 15117 sgd_solver.cpp:294] Iteration 32080, lr = 0.002
I0526 06:33:14.558571 15117 solver.cpp:233] Iteration 32090, loss = 0.0922698
I0526 06:33:14.558612 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.09227 (* 1 = 0.09227 loss)
I0526 06:33:14.558620 15117 sgd_solver.cpp:294] Iteration 32090, lr = 0.002
I0526 06:33:20.294622 15117 solver.cpp:342] Iteration 32100, Testing net (#0)
I0526 06:33:33.129380 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8556
I0526 06:33:33.129423 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.640031 (* 1 = 0.640031 loss)
I0526 06:33:33.732529 15117 solver.cpp:233] Iteration 32100, loss = 0.0417496
I0526 06:33:33.732563 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0417498 (* 1 = 0.0417498 loss)
I0526 06:33:33.732569 15117 sgd_solver.cpp:294] Iteration 32100, lr = 0.002
I0526 06:33:40.070592 15117 solver.cpp:233] Iteration 32110, loss = 0.177648
I0526 06:33:40.070633 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.177648 (* 1 = 0.177648 loss)
I0526 06:33:40.070639 15117 sgd_solver.cpp:294] Iteration 32110, lr = 0.002
I0526 06:33:46.408115 15117 solver.cpp:233] Iteration 32120, loss = 0.0782025
I0526 06:33:46.408157 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0782027 (* 1 = 0.0782027 loss)
I0526 06:33:46.408164 15117 sgd_solver.cpp:294] Iteration 32120, lr = 0.002
I0526 06:33:52.747074 15117 solver.cpp:233] Iteration 32130, loss = 0.0549076
I0526 06:33:52.747300 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0549078 (* 1 = 0.0549078 loss)
I0526 06:33:52.747329 15117 sgd_solver.cpp:294] Iteration 32130, lr = 0.002
I0526 06:33:59.084061 15117 solver.cpp:233] Iteration 32140, loss = 0.0708593
I0526 06:33:59.084105 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0708595 (* 1 = 0.0708595 loss)
I0526 06:33:59.084113 15117 sgd_solver.cpp:294] Iteration 32140, lr = 0.002
I0526 06:34:05.406893 15117 solver.cpp:233] Iteration 32150, loss = 0.0620613
I0526 06:34:05.406942 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0620614 (* 1 = 0.0620614 loss)
I0526 06:34:05.406949 15117 sgd_solver.cpp:294] Iteration 32150, lr = 0.002
I0526 06:34:11.718724 15117 solver.cpp:233] Iteration 32160, loss = 0.0768776
I0526 06:34:11.718761 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0768778 (* 1 = 0.0768778 loss)
I0526 06:34:11.718768 15117 sgd_solver.cpp:294] Iteration 32160, lr = 0.002
I0526 06:34:18.032806 15117 solver.cpp:233] Iteration 32170, loss = 0.0537661
I0526 06:34:18.032847 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0537662 (* 1 = 0.0537662 loss)
I0526 06:34:18.032855 15117 sgd_solver.cpp:294] Iteration 32170, lr = 0.002
I0526 06:34:24.340359 15117 solver.cpp:233] Iteration 32180, loss = 0.0781624
I0526 06:34:24.340620 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0781626 (* 1 = 0.0781626 loss)
I0526 06:34:24.340661 15117 sgd_solver.cpp:294] Iteration 32180, lr = 0.002
I0526 06:34:30.655340 15117 solver.cpp:233] Iteration 32190, loss = 0.0422528
I0526 06:34:30.655386 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.042253 (* 1 = 0.042253 loss)
I0526 06:34:30.655395 15117 sgd_solver.cpp:294] Iteration 32190, lr = 0.002
I0526 06:34:36.366297 15117 solver.cpp:342] Iteration 32200, Testing net (#0)
I0526 06:34:49.175173 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8672
I0526 06:34:49.175218 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.564276 (* 1 = 0.564276 loss)
I0526 06:34:49.775009 15117 solver.cpp:233] Iteration 32200, loss = 0.0927246
I0526 06:34:49.775044 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0927248 (* 1 = 0.0927248 loss)
I0526 06:34:49.775051 15117 sgd_solver.cpp:294] Iteration 32200, lr = 0.002
I0526 06:34:56.103018 15117 solver.cpp:233] Iteration 32210, loss = 0.0651977
I0526 06:34:56.103250 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0651979 (* 1 = 0.0651979 loss)
I0526 06:34:56.103279 15117 sgd_solver.cpp:294] Iteration 32210, lr = 0.002
I0526 06:35:02.435679 15117 solver.cpp:233] Iteration 32220, loss = 0.0746113
I0526 06:35:02.435719 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0746115 (* 1 = 0.0746115 loss)
I0526 06:35:02.435726 15117 sgd_solver.cpp:294] Iteration 32220, lr = 0.002
I0526 06:35:08.771390 15117 solver.cpp:233] Iteration 32230, loss = 0.0885262
I0526 06:35:08.771432 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0885264 (* 1 = 0.0885264 loss)
I0526 06:35:08.771440 15117 sgd_solver.cpp:294] Iteration 32230, lr = 0.002
I0526 06:35:15.103685 15117 solver.cpp:233] Iteration 32240, loss = 0.0282584
I0526 06:35:15.103726 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0282586 (* 1 = 0.0282586 loss)
I0526 06:35:15.103734 15117 sgd_solver.cpp:294] Iteration 32240, lr = 0.002
I0526 06:35:21.437943 15117 solver.cpp:233] Iteration 32250, loss = 0.0461517
I0526 06:35:21.437986 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0461519 (* 1 = 0.0461519 loss)
I0526 06:35:21.437994 15117 sgd_solver.cpp:294] Iteration 32250, lr = 0.002
I0526 06:35:27.769888 15117 solver.cpp:233] Iteration 32260, loss = 0.0246534
I0526 06:35:27.770107 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0246536 (* 1 = 0.0246536 loss)
I0526 06:35:27.770134 15117 sgd_solver.cpp:294] Iteration 32260, lr = 0.002
I0526 06:35:34.108301 15117 solver.cpp:233] Iteration 32270, loss = 0.0702785
I0526 06:35:34.108345 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0702787 (* 1 = 0.0702787 loss)
I0526 06:35:34.108351 15117 sgd_solver.cpp:294] Iteration 32270, lr = 0.002
I0526 06:35:40.447805 15117 solver.cpp:233] Iteration 32280, loss = 0.0596215
I0526 06:35:40.447836 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0596217 (* 1 = 0.0596217 loss)
I0526 06:35:40.447844 15117 sgd_solver.cpp:294] Iteration 32280, lr = 0.002
I0526 06:35:46.784545 15117 solver.cpp:233] Iteration 32290, loss = 0.0688831
I0526 06:35:46.784584 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0688833 (* 1 = 0.0688833 loss)
I0526 06:35:46.784591 15117 sgd_solver.cpp:294] Iteration 32290, lr = 0.002
I0526 06:35:52.518640 15117 solver.cpp:342] Iteration 32300, Testing net (#0)
I0526 06:36:05.357975 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8769
I0526 06:36:05.358202 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.515135 (* 1 = 0.515135 loss)
I0526 06:36:05.960142 15117 solver.cpp:233] Iteration 32300, loss = 0.0198202
I0526 06:36:05.960186 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0198203 (* 1 = 0.0198203 loss)
I0526 06:36:05.960194 15117 sgd_solver.cpp:294] Iteration 32300, lr = 0.002
I0526 06:36:12.296257 15117 solver.cpp:233] Iteration 32310, loss = 0.0192226
I0526 06:36:12.296298 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0192228 (* 1 = 0.0192228 loss)
I0526 06:36:12.296311 15117 sgd_solver.cpp:294] Iteration 32310, lr = 0.002
I0526 06:36:18.629231 15117 solver.cpp:233] Iteration 32320, loss = 0.087355
I0526 06:36:18.629281 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0873552 (* 1 = 0.0873552 loss)
I0526 06:36:18.629288 15117 sgd_solver.cpp:294] Iteration 32320, lr = 0.002
I0526 06:36:24.967506 15117 solver.cpp:233] Iteration 32330, loss = 0.0249451
I0526 06:36:24.967548 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0249453 (* 1 = 0.0249453 loss)
I0526 06:36:24.967556 15117 sgd_solver.cpp:294] Iteration 32330, lr = 0.002
I0526 06:36:31.305670 15117 solver.cpp:233] Iteration 32340, loss = 0.0389862
I0526 06:36:31.305712 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0389863 (* 1 = 0.0389863 loss)
I0526 06:36:31.305719 15117 sgd_solver.cpp:294] Iteration 32340, lr = 0.002
I0526 06:36:37.644114 15117 solver.cpp:233] Iteration 32350, loss = 0.0353284
I0526 06:36:37.644371 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0353286 (* 1 = 0.0353286 loss)
I0526 06:36:37.644412 15117 sgd_solver.cpp:294] Iteration 32350, lr = 0.002
I0526 06:36:43.976213 15117 solver.cpp:233] Iteration 32360, loss = 0.0370136
I0526 06:36:43.976254 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0370138 (* 1 = 0.0370138 loss)
I0526 06:36:43.976263 15117 sgd_solver.cpp:294] Iteration 32360, lr = 0.002
I0526 06:36:50.315901 15117 solver.cpp:233] Iteration 32370, loss = 0.0248139
I0526 06:36:50.315951 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0248141 (* 1 = 0.0248141 loss)
I0526 06:36:50.315958 15117 sgd_solver.cpp:294] Iteration 32370, lr = 0.002
I0526 06:36:56.654613 15117 solver.cpp:233] Iteration 32380, loss = 0.0338701
I0526 06:36:56.654651 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0338703 (* 1 = 0.0338703 loss)
I0526 06:36:56.654659 15117 sgd_solver.cpp:294] Iteration 32380, lr = 0.002
I0526 06:37:02.992426 15117 solver.cpp:233] Iteration 32390, loss = 0.0293294
I0526 06:37:02.992465 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0293295 (* 1 = 0.0293295 loss)
I0526 06:37:02.992471 15117 sgd_solver.cpp:294] Iteration 32390, lr = 0.002
I0526 06:37:08.732110 15117 solver.cpp:342] Iteration 32400, Testing net (#0)
I0526 06:37:21.567720 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8833
I0526 06:37:21.567766 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.459241 (* 1 = 0.459241 loss)
I0526 06:37:22.168476 15117 solver.cpp:233] Iteration 32400, loss = 0.032478
I0526 06:37:22.168510 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0324782 (* 1 = 0.0324782 loss)
I0526 06:37:22.168519 15117 sgd_solver.cpp:294] Iteration 32400, lr = 0.002
I0526 06:37:28.503484 15117 solver.cpp:233] Iteration 32410, loss = 0.078709
I0526 06:37:28.503535 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0787092 (* 1 = 0.0787092 loss)
I0526 06:37:28.503542 15117 sgd_solver.cpp:294] Iteration 32410, lr = 0.002
I0526 06:37:34.839298 15117 solver.cpp:233] Iteration 32420, loss = 0.0780222
I0526 06:37:34.839339 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0780224 (* 1 = 0.0780224 loss)
I0526 06:37:34.839346 15117 sgd_solver.cpp:294] Iteration 32420, lr = 0.002
I0526 06:37:41.175482 15117 solver.cpp:233] Iteration 32430, loss = 0.118366
I0526 06:37:41.175694 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.118366 (* 1 = 0.118366 loss)
I0526 06:37:41.175720 15117 sgd_solver.cpp:294] Iteration 32430, lr = 0.002
I0526 06:37:47.510300 15117 solver.cpp:233] Iteration 32440, loss = 0.0396245
I0526 06:37:47.510344 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0396247 (* 1 = 0.0396247 loss)
I0526 06:37:47.510357 15117 sgd_solver.cpp:294] Iteration 32440, lr = 0.002
I0526 06:37:53.848184 15117 solver.cpp:233] Iteration 32450, loss = 0.0442871
I0526 06:37:53.848224 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0442873 (* 1 = 0.0442873 loss)
I0526 06:37:53.848237 15117 sgd_solver.cpp:294] Iteration 32450, lr = 0.002
I0526 06:38:00.186897 15117 solver.cpp:233] Iteration 32460, loss = 0.0306799
I0526 06:38:00.186940 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.03068 (* 1 = 0.03068 loss)
I0526 06:38:00.186949 15117 sgd_solver.cpp:294] Iteration 32460, lr = 0.002
I0526 06:38:06.522583 15117 solver.cpp:233] Iteration 32470, loss = 0.0474053
I0526 06:38:06.522624 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0474054 (* 1 = 0.0474054 loss)
I0526 06:38:06.522629 15117 sgd_solver.cpp:294] Iteration 32470, lr = 0.002
I0526 06:38:12.858414 15117 solver.cpp:233] Iteration 32480, loss = 0.0449752
I0526 06:38:12.858695 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0449754 (* 1 = 0.0449754 loss)
I0526 06:38:12.858724 15117 sgd_solver.cpp:294] Iteration 32480, lr = 0.002
I0526 06:38:19.196249 15117 solver.cpp:233] Iteration 32490, loss = 0.0388942
I0526 06:38:19.196293 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0388944 (* 1 = 0.0388944 loss)
I0526 06:38:19.196300 15117 sgd_solver.cpp:294] Iteration 32490, lr = 0.002
I0526 06:38:24.928170 15117 solver.cpp:342] Iteration 32500, Testing net (#0)
I0526 06:38:37.769032 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8914
I0526 06:38:37.769078 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.410311 (* 1 = 0.410311 loss)
I0526 06:38:38.370978 15117 solver.cpp:233] Iteration 32500, loss = 0.0302622
I0526 06:38:38.371012 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0302624 (* 1 = 0.0302624 loss)
I0526 06:38:38.371019 15117 sgd_solver.cpp:294] Iteration 32500, lr = 0.002
I0526 06:38:44.708791 15117 solver.cpp:233] Iteration 32510, loss = 0.0635195
I0526 06:38:44.709033 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0635197 (* 1 = 0.0635197 loss)
I0526 06:38:44.709060 15117 sgd_solver.cpp:294] Iteration 32510, lr = 0.002
I0526 06:38:51.045745 15117 solver.cpp:233] Iteration 32520, loss = 0.0998721
I0526 06:38:51.045783 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0998723 (* 1 = 0.0998723 loss)
I0526 06:38:51.045789 15117 sgd_solver.cpp:294] Iteration 32520, lr = 0.002
I0526 06:38:57.385440 15117 solver.cpp:233] Iteration 32530, loss = 0.0173035
I0526 06:38:57.385480 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0173037 (* 1 = 0.0173037 loss)
I0526 06:38:57.385486 15117 sgd_solver.cpp:294] Iteration 32530, lr = 0.002
I0526 06:39:03.721688 15117 solver.cpp:233] Iteration 32540, loss = 0.0677245
I0526 06:39:03.721731 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0677247 (* 1 = 0.0677247 loss)
I0526 06:39:03.721738 15117 sgd_solver.cpp:294] Iteration 32540, lr = 0.002
I0526 06:39:10.061082 15117 solver.cpp:233] Iteration 32550, loss = 0.0454307
I0526 06:39:10.061122 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0454309 (* 1 = 0.0454309 loss)
I0526 06:39:10.061128 15117 sgd_solver.cpp:294] Iteration 32550, lr = 0.002
I0526 06:39:16.398149 15117 solver.cpp:233] Iteration 32560, loss = 0.0441875
I0526 06:39:16.398406 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0441877 (* 1 = 0.0441877 loss)
I0526 06:39:16.398434 15117 sgd_solver.cpp:294] Iteration 32560, lr = 0.002
I0526 06:39:22.727305 15117 solver.cpp:233] Iteration 32570, loss = 0.0461315
I0526 06:39:22.727351 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0461317 (* 1 = 0.0461317 loss)
I0526 06:39:22.727360 15117 sgd_solver.cpp:294] Iteration 32570, lr = 0.002
I0526 06:39:29.061950 15117 solver.cpp:233] Iteration 32580, loss = 0.0572509
I0526 06:39:29.061995 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0572511 (* 1 = 0.0572511 loss)
I0526 06:39:29.062002 15117 sgd_solver.cpp:294] Iteration 32580, lr = 0.002
I0526 06:39:35.399190 15117 solver.cpp:233] Iteration 32590, loss = 0.0320883
I0526 06:39:35.399220 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0320885 (* 1 = 0.0320885 loss)
I0526 06:39:35.399232 15117 sgd_solver.cpp:294] Iteration 32590, lr = 0.002
I0526 06:39:41.132529 15117 solver.cpp:342] Iteration 32600, Testing net (#0)
I0526 06:39:53.972010 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8874
I0526 06:39:53.972291 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.420427 (* 1 = 0.420427 loss)
I0526 06:39:54.571554 15117 solver.cpp:233] Iteration 32600, loss = 0.0396604
I0526 06:39:54.571597 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0396606 (* 1 = 0.0396606 loss)
I0526 06:39:54.571606 15117 sgd_solver.cpp:294] Iteration 32600, lr = 0.002
I0526 06:40:00.904903 15117 solver.cpp:233] Iteration 32610, loss = 0.0476732
I0526 06:40:00.904947 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0476734 (* 1 = 0.0476734 loss)
I0526 06:40:00.904953 15117 sgd_solver.cpp:294] Iteration 32610, lr = 0.002
I0526 06:40:07.238131 15117 solver.cpp:233] Iteration 32620, loss = 0.0601206
I0526 06:40:07.238173 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0601208 (* 1 = 0.0601208 loss)
I0526 06:40:07.238179 15117 sgd_solver.cpp:294] Iteration 32620, lr = 0.002
I0526 06:40:13.577767 15117 solver.cpp:233] Iteration 32630, loss = 0.0493935
I0526 06:40:13.577807 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0493936 (* 1 = 0.0493936 loss)
I0526 06:40:13.577816 15117 sgd_solver.cpp:294] Iteration 32630, lr = 0.002
I0526 06:40:19.914234 15117 solver.cpp:233] Iteration 32640, loss = 0.0638573
I0526 06:40:19.914275 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0638575 (* 1 = 0.0638575 loss)
I0526 06:40:19.914283 15117 sgd_solver.cpp:294] Iteration 32640, lr = 0.002
I0526 06:40:26.248819 15117 solver.cpp:233] Iteration 32650, loss = 0.0396626
I0526 06:40:26.249053 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0396628 (* 1 = 0.0396628 loss)
I0526 06:40:26.249081 15117 sgd_solver.cpp:294] Iteration 32650, lr = 0.002
I0526 06:40:32.584455 15117 solver.cpp:233] Iteration 32660, loss = 0.0178562
I0526 06:40:32.584496 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0178564 (* 1 = 0.0178564 loss)
I0526 06:40:32.584503 15117 sgd_solver.cpp:294] Iteration 32660, lr = 0.002
I0526 06:40:38.922696 15117 solver.cpp:233] Iteration 32670, loss = 0.0378091
I0526 06:40:38.922737 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0378093 (* 1 = 0.0378093 loss)
I0526 06:40:38.922745 15117 sgd_solver.cpp:294] Iteration 32670, lr = 0.002
I0526 06:40:45.258185 15117 solver.cpp:233] Iteration 32680, loss = 0.0520356
I0526 06:40:45.258229 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0520358 (* 1 = 0.0520358 loss)
I0526 06:40:45.258235 15117 sgd_solver.cpp:294] Iteration 32680, lr = 0.002
I0526 06:40:51.593556 15117 solver.cpp:233] Iteration 32690, loss = 0.0453292
I0526 06:40:51.593585 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0453293 (* 1 = 0.0453293 loss)
I0526 06:40:51.593591 15117 sgd_solver.cpp:294] Iteration 32690, lr = 0.002
I0526 06:40:57.329602 15117 solver.cpp:342] Iteration 32700, Testing net (#0)
I0526 06:41:10.175658 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8916
I0526 06:41:10.175706 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.432778 (* 1 = 0.432778 loss)
I0526 06:41:10.776958 15117 solver.cpp:233] Iteration 32700, loss = 0.03697
I0526 06:41:10.776990 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0369701 (* 1 = 0.0369701 loss)
I0526 06:41:10.776998 15117 sgd_solver.cpp:294] Iteration 32700, lr = 0.002
I0526 06:41:17.113232 15117 solver.cpp:233] Iteration 32710, loss = 0.0230141
I0526 06:41:17.113273 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0230142 (* 1 = 0.0230142 loss)
I0526 06:41:17.113291 15117 sgd_solver.cpp:294] Iteration 32710, lr = 0.002
I0526 06:41:23.444900 15117 solver.cpp:233] Iteration 32720, loss = 0.0322215
I0526 06:41:23.444944 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0322216 (* 1 = 0.0322216 loss)
I0526 06:41:23.444952 15117 sgd_solver.cpp:294] Iteration 32720, lr = 0.002
I0526 06:41:29.778650 15117 solver.cpp:233] Iteration 32730, loss = 0.0245111
I0526 06:41:29.778905 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0245113 (* 1 = 0.0245113 loss)
I0526 06:41:29.778930 15117 sgd_solver.cpp:294] Iteration 32730, lr = 0.002
I0526 06:41:36.115238 15117 solver.cpp:233] Iteration 32740, loss = 0.01559
I0526 06:41:36.115280 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0155901 (* 1 = 0.0155901 loss)
I0526 06:41:36.115288 15117 sgd_solver.cpp:294] Iteration 32740, lr = 0.002
I0526 06:41:42.447916 15117 solver.cpp:233] Iteration 32750, loss = 0.0142732
I0526 06:41:42.447957 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0142734 (* 1 = 0.0142734 loss)
I0526 06:41:42.447963 15117 sgd_solver.cpp:294] Iteration 32750, lr = 0.002
I0526 06:41:48.784080 15117 solver.cpp:233] Iteration 32760, loss = 0.0560001
I0526 06:41:48.784137 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0560002 (* 1 = 0.0560002 loss)
I0526 06:41:48.784147 15117 sgd_solver.cpp:294] Iteration 32760, lr = 0.002
I0526 06:41:55.118573 15117 solver.cpp:233] Iteration 32770, loss = 0.0183258
I0526 06:41:55.118621 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.018326 (* 1 = 0.018326 loss)
I0526 06:41:55.118628 15117 sgd_solver.cpp:294] Iteration 32770, lr = 0.002
I0526 06:42:01.449813 15117 solver.cpp:233] Iteration 32780, loss = 0.0571838
I0526 06:42:01.450042 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0571839 (* 1 = 0.0571839 loss)
I0526 06:42:01.450070 15117 sgd_solver.cpp:294] Iteration 32780, lr = 0.002
I0526 06:42:07.783970 15117 solver.cpp:233] Iteration 32790, loss = 0.0227708
I0526 06:42:07.784010 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0227709 (* 1 = 0.0227709 loss)
I0526 06:42:07.784018 15117 sgd_solver.cpp:294] Iteration 32790, lr = 0.002
I0526 06:42:13.517539 15117 solver.cpp:342] Iteration 32800, Testing net (#0)
I0526 06:42:26.352865 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8958
I0526 06:42:26.352908 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.409472 (* 1 = 0.409472 loss)
I0526 06:42:26.954558 15117 solver.cpp:233] Iteration 32800, loss = 0.024731
I0526 06:42:26.954594 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0247312 (* 1 = 0.0247312 loss)
I0526 06:42:26.954602 15117 sgd_solver.cpp:294] Iteration 32800, lr = 0.002
I0526 06:42:33.289659 15117 solver.cpp:233] Iteration 32810, loss = 0.0802029
I0526 06:42:33.289878 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0802031 (* 1 = 0.0802031 loss)
I0526 06:42:33.289904 15117 sgd_solver.cpp:294] Iteration 32810, lr = 0.002
I0526 06:42:39.623138 15117 solver.cpp:233] Iteration 32820, loss = 0.0281588
I0526 06:42:39.623181 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.028159 (* 1 = 0.028159 loss)
I0526 06:42:39.623188 15117 sgd_solver.cpp:294] Iteration 32820, lr = 0.002
I0526 06:42:45.958658 15117 solver.cpp:233] Iteration 32830, loss = 0.0272586
I0526 06:42:45.958699 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0272588 (* 1 = 0.0272588 loss)
I0526 06:42:45.958708 15117 sgd_solver.cpp:294] Iteration 32830, lr = 0.002
I0526 06:42:52.294237 15117 solver.cpp:233] Iteration 32840, loss = 0.0635345
I0526 06:42:52.294275 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0635346 (* 1 = 0.0635346 loss)
I0526 06:42:52.294282 15117 sgd_solver.cpp:294] Iteration 32840, lr = 0.002
I0526 06:42:58.627252 15117 solver.cpp:233] Iteration 32850, loss = 0.036511
I0526 06:42:58.627300 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0365112 (* 1 = 0.0365112 loss)
I0526 06:42:58.627308 15117 sgd_solver.cpp:294] Iteration 32850, lr = 0.002
I0526 06:43:04.962414 15117 solver.cpp:233] Iteration 32860, loss = 0.0602019
I0526 06:43:04.962682 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0602021 (* 1 = 0.0602021 loss)
I0526 06:43:04.962712 15117 sgd_solver.cpp:294] Iteration 32860, lr = 0.002
I0526 06:43:11.292544 15117 solver.cpp:233] Iteration 32870, loss = 0.0350276
I0526 06:43:11.292596 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0350277 (* 1 = 0.0350277 loss)
I0526 06:43:11.292603 15117 sgd_solver.cpp:294] Iteration 32870, lr = 0.002
I0526 06:43:17.630048 15117 solver.cpp:233] Iteration 32880, loss = 0.0305519
I0526 06:43:17.630087 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.030552 (* 1 = 0.030552 loss)
I0526 06:43:17.630095 15117 sgd_solver.cpp:294] Iteration 32880, lr = 0.002
I0526 06:43:23.965934 15117 solver.cpp:233] Iteration 32890, loss = 0.0430212
I0526 06:43:23.965975 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0430213 (* 1 = 0.0430213 loss)
I0526 06:43:23.965982 15117 sgd_solver.cpp:294] Iteration 32890, lr = 0.002
I0526 06:43:29.700487 15117 solver.cpp:342] Iteration 32900, Testing net (#0)
I0526 06:43:42.543994 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8942
I0526 06:43:42.544209 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.408048 (* 1 = 0.408048 loss)
I0526 06:43:43.143421 15117 solver.cpp:233] Iteration 32900, loss = 0.0209155
I0526 06:43:43.143455 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0209156 (* 1 = 0.0209156 loss)
I0526 06:43:43.143463 15117 sgd_solver.cpp:294] Iteration 32900, lr = 0.002
I0526 06:43:49.482425 15117 solver.cpp:233] Iteration 32910, loss = 0.0379212
I0526 06:43:49.482458 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0379214 (* 1 = 0.0379214 loss)
I0526 06:43:49.482466 15117 sgd_solver.cpp:294] Iteration 32910, lr = 0.002
I0526 06:43:55.819012 15117 solver.cpp:233] Iteration 32920, loss = 0.0538463
I0526 06:43:55.819052 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0538465 (* 1 = 0.0538465 loss)
I0526 06:43:55.819061 15117 sgd_solver.cpp:294] Iteration 32920, lr = 0.002
I0526 06:44:02.150594 15117 solver.cpp:233] Iteration 32930, loss = 0.0320983
I0526 06:44:02.150651 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0320985 (* 1 = 0.0320985 loss)
I0526 06:44:02.150660 15117 sgd_solver.cpp:294] Iteration 32930, lr = 0.002
I0526 06:44:08.487854 15117 solver.cpp:233] Iteration 32940, loss = 0.0435771
I0526 06:44:08.487895 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0435773 (* 1 = 0.0435773 loss)
I0526 06:44:08.487901 15117 sgd_solver.cpp:294] Iteration 32940, lr = 0.002
I0526 06:44:14.826889 15117 solver.cpp:233] Iteration 32950, loss = 0.0456639
I0526 06:44:14.827103 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.045664 (* 1 = 0.045664 loss)
I0526 06:44:14.827132 15117 sgd_solver.cpp:294] Iteration 32950, lr = 0.002
I0526 06:44:21.159641 15117 solver.cpp:233] Iteration 32960, loss = 0.032411
I0526 06:44:21.159685 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0324112 (* 1 = 0.0324112 loss)
I0526 06:44:21.159693 15117 sgd_solver.cpp:294] Iteration 32960, lr = 0.002
I0526 06:44:27.496192 15117 solver.cpp:233] Iteration 32970, loss = 0.0381751
I0526 06:44:27.496233 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0381753 (* 1 = 0.0381753 loss)
I0526 06:44:27.496240 15117 sgd_solver.cpp:294] Iteration 32970, lr = 0.002
I0526 06:44:33.829998 15117 solver.cpp:233] Iteration 32980, loss = 0.0594241
I0526 06:44:33.830039 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0594242 (* 1 = 0.0594242 loss)
I0526 06:44:33.830046 15117 sgd_solver.cpp:294] Iteration 32980, lr = 0.002
I0526 06:44:40.165566 15117 solver.cpp:233] Iteration 32990, loss = 0.0577142
I0526 06:44:40.165606 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0577144 (* 1 = 0.0577144 loss)
I0526 06:44:40.165612 15117 sgd_solver.cpp:294] Iteration 32990, lr = 0.002
I0526 06:44:45.893072 15117 solver.cpp:342] Iteration 33000, Testing net (#0)
I0526 06:44:58.734488 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9011
I0526 06:44:58.734536 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.398572 (* 1 = 0.398572 loss)
I0526 06:44:59.335718 15117 solver.cpp:233] Iteration 33000, loss = 0.0183063
I0526 06:44:59.335778 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0183064 (* 1 = 0.0183064 loss)
I0526 06:44:59.335786 15117 sgd_solver.cpp:294] Iteration 33000, lr = 0.002
I0526 06:45:05.670204 15117 solver.cpp:233] Iteration 33010, loss = 0.0344209
I0526 06:45:05.670248 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0344211 (* 1 = 0.0344211 loss)
I0526 06:45:05.670256 15117 sgd_solver.cpp:294] Iteration 33010, lr = 0.002
I0526 06:45:12.003099 15117 solver.cpp:233] Iteration 33020, loss = 0.0353454
I0526 06:45:12.003151 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0353456 (* 1 = 0.0353456 loss)
I0526 06:45:12.003160 15117 sgd_solver.cpp:294] Iteration 33020, lr = 0.002
I0526 06:45:18.328932 15117 solver.cpp:233] Iteration 33030, loss = 0.04792
I0526 06:45:18.329190 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0479202 (* 1 = 0.0479202 loss)
I0526 06:45:18.329218 15117 sgd_solver.cpp:294] Iteration 33030, lr = 0.002
I0526 06:45:24.663825 15117 solver.cpp:233] Iteration 33040, loss = 0.0104387
I0526 06:45:24.663868 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0104388 (* 1 = 0.0104388 loss)
I0526 06:45:24.663877 15117 sgd_solver.cpp:294] Iteration 33040, lr = 0.002
I0526 06:45:31.002398 15117 solver.cpp:233] Iteration 33050, loss = 0.0266306
I0526 06:45:31.002442 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0266307 (* 1 = 0.0266307 loss)
I0526 06:45:31.002449 15117 sgd_solver.cpp:294] Iteration 33050, lr = 0.002
I0526 06:45:37.337014 15117 solver.cpp:233] Iteration 33060, loss = 0.0145999
I0526 06:45:37.337054 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0146001 (* 1 = 0.0146001 loss)
I0526 06:45:37.337061 15117 sgd_solver.cpp:294] Iteration 33060, lr = 0.002
I0526 06:45:43.675483 15117 solver.cpp:233] Iteration 33070, loss = 0.0525188
I0526 06:45:43.675523 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0525189 (* 1 = 0.0525189 loss)
I0526 06:45:43.675529 15117 sgd_solver.cpp:294] Iteration 33070, lr = 0.002
I0526 06:45:50.014313 15117 solver.cpp:233] Iteration 33080, loss = 0.0559738
I0526 06:45:50.014535 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.055974 (* 1 = 0.055974 loss)
I0526 06:45:50.014562 15117 sgd_solver.cpp:294] Iteration 33080, lr = 0.002
I0526 06:45:56.346632 15117 solver.cpp:233] Iteration 33090, loss = 0.0225248
I0526 06:45:56.346698 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0225249 (* 1 = 0.0225249 loss)
I0526 06:45:56.346715 15117 sgd_solver.cpp:294] Iteration 33090, lr = 0.002
I0526 06:46:02.081884 15117 solver.cpp:342] Iteration 33100, Testing net (#0)
I0526 06:46:14.928756 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8969
I0526 06:46:14.928814 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.399023 (* 1 = 0.399023 loss)
I0526 06:46:15.530911 15117 solver.cpp:233] Iteration 33100, loss = 0.015036
I0526 06:46:15.530949 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0150362 (* 1 = 0.0150362 loss)
I0526 06:46:15.530957 15117 sgd_solver.cpp:294] Iteration 33100, lr = 0.002
I0526 06:46:21.868924 15117 solver.cpp:233] Iteration 33110, loss = 0.0492448
I0526 06:46:21.869158 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.049245 (* 1 = 0.049245 loss)
I0526 06:46:21.869187 15117 sgd_solver.cpp:294] Iteration 33110, lr = 0.002
I0526 06:46:28.205312 15117 solver.cpp:233] Iteration 33120, loss = 0.0245562
I0526 06:46:28.205355 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0245564 (* 1 = 0.0245564 loss)
I0526 06:46:28.205363 15117 sgd_solver.cpp:294] Iteration 33120, lr = 0.002
I0526 06:46:34.542440 15117 solver.cpp:233] Iteration 33130, loss = 0.0303401
I0526 06:46:34.542480 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0303402 (* 1 = 0.0303402 loss)
I0526 06:46:34.542487 15117 sgd_solver.cpp:294] Iteration 33130, lr = 0.002
I0526 06:46:40.877701 15117 solver.cpp:233] Iteration 33140, loss = 0.0646965
I0526 06:46:40.877742 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0646966 (* 1 = 0.0646966 loss)
I0526 06:46:40.877748 15117 sgd_solver.cpp:294] Iteration 33140, lr = 0.002
I0526 06:46:47.213665 15117 solver.cpp:233] Iteration 33150, loss = 0.0345613
I0526 06:46:47.213707 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0345615 (* 1 = 0.0345615 loss)
I0526 06:46:47.213714 15117 sgd_solver.cpp:294] Iteration 33150, lr = 0.002
I0526 06:46:53.548148 15117 solver.cpp:233] Iteration 33160, loss = 0.0303182
I0526 06:46:53.548452 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0303183 (* 1 = 0.0303183 loss)
I0526 06:46:53.548482 15117 sgd_solver.cpp:294] Iteration 33160, lr = 0.002
I0526 06:46:59.884485 15117 solver.cpp:233] Iteration 33170, loss = 0.0313366
I0526 06:46:59.884527 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0313368 (* 1 = 0.0313368 loss)
I0526 06:46:59.884536 15117 sgd_solver.cpp:294] Iteration 33170, lr = 0.002
I0526 06:47:06.217607 15117 solver.cpp:233] Iteration 33180, loss = 0.0421463
I0526 06:47:06.217663 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0421464 (* 1 = 0.0421464 loss)
I0526 06:47:06.217669 15117 sgd_solver.cpp:294] Iteration 33180, lr = 0.002
I0526 06:47:12.549790 15117 solver.cpp:233] Iteration 33190, loss = 0.0187921
I0526 06:47:12.549829 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0187922 (* 1 = 0.0187922 loss)
I0526 06:47:12.549836 15117 sgd_solver.cpp:294] Iteration 33190, lr = 0.002
I0526 06:47:18.280326 15117 solver.cpp:342] Iteration 33200, Testing net (#0)
I0526 06:47:31.117282 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8995
I0526 06:47:31.117506 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.397668 (* 1 = 0.397668 loss)
I0526 06:47:31.717874 15117 solver.cpp:233] Iteration 33200, loss = 0.0444472
I0526 06:47:31.717916 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0444474 (* 1 = 0.0444474 loss)
I0526 06:47:31.717923 15117 sgd_solver.cpp:294] Iteration 33200, lr = 0.002
I0526 06:47:38.054463 15117 solver.cpp:233] Iteration 33210, loss = 0.048521
I0526 06:47:38.054508 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0485212 (* 1 = 0.0485212 loss)
I0526 06:47:38.054515 15117 sgd_solver.cpp:294] Iteration 33210, lr = 0.002
I0526 06:47:44.390430 15117 solver.cpp:233] Iteration 33220, loss = 0.0644127
I0526 06:47:44.390472 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0644129 (* 1 = 0.0644129 loss)
I0526 06:47:44.390478 15117 sgd_solver.cpp:294] Iteration 33220, lr = 0.002
I0526 06:47:50.727915 15117 solver.cpp:233] Iteration 33230, loss = 0.0579493
I0526 06:47:50.727968 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0579495 (* 1 = 0.0579495 loss)
I0526 06:47:50.727975 15117 sgd_solver.cpp:294] Iteration 33230, lr = 0.002
I0526 06:47:57.064769 15117 solver.cpp:233] Iteration 33240, loss = 0.026204
I0526 06:47:57.064808 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0262042 (* 1 = 0.0262042 loss)
I0526 06:47:57.064815 15117 sgd_solver.cpp:294] Iteration 33240, lr = 0.002
I0526 06:48:03.398926 15117 solver.cpp:233] Iteration 33250, loss = 0.0438726
I0526 06:48:03.399145 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0438728 (* 1 = 0.0438728 loss)
I0526 06:48:03.399174 15117 sgd_solver.cpp:294] Iteration 33250, lr = 0.002
I0526 06:48:09.727593 15117 solver.cpp:233] Iteration 33260, loss = 0.0514164
I0526 06:48:09.727656 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0514165 (* 1 = 0.0514165 loss)
I0526 06:48:09.727669 15117 sgd_solver.cpp:294] Iteration 33260, lr = 0.002
I0526 06:48:16.057888 15117 solver.cpp:233] Iteration 33270, loss = 0.0272913
I0526 06:48:16.057934 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0272915 (* 1 = 0.0272915 loss)
I0526 06:48:16.057943 15117 sgd_solver.cpp:294] Iteration 33270, lr = 0.002
I0526 06:48:22.394192 15117 solver.cpp:233] Iteration 33280, loss = 0.0225662
I0526 06:48:22.394234 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0225663 (* 1 = 0.0225663 loss)
I0526 06:48:22.394242 15117 sgd_solver.cpp:294] Iteration 33280, lr = 0.002
I0526 06:48:28.730638 15117 solver.cpp:233] Iteration 33290, loss = 0.025134
I0526 06:48:28.730679 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0251342 (* 1 = 0.0251342 loss)
I0526 06:48:28.730685 15117 sgd_solver.cpp:294] Iteration 33290, lr = 0.002
I0526 06:48:34.466919 15117 solver.cpp:342] Iteration 33300, Testing net (#0)
I0526 06:48:47.303691 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8947
I0526 06:48:47.303738 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.404142 (* 1 = 0.404142 loss)
I0526 06:48:47.904819 15117 solver.cpp:233] Iteration 33300, loss = 0.0141093
I0526 06:48:47.904855 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0141095 (* 1 = 0.0141095 loss)
I0526 06:48:47.904863 15117 sgd_solver.cpp:294] Iteration 33300, lr = 0.002
I0526 06:48:54.240514 15117 solver.cpp:233] Iteration 33310, loss = 0.0268837
I0526 06:48:54.240563 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0268839 (* 1 = 0.0268839 loss)
I0526 06:48:54.240571 15117 sgd_solver.cpp:294] Iteration 33310, lr = 0.002
I0526 06:49:00.574353 15117 solver.cpp:233] Iteration 33320, loss = 0.0550754
I0526 06:49:00.574393 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0550755 (* 1 = 0.0550755 loss)
I0526 06:49:00.574400 15117 sgd_solver.cpp:294] Iteration 33320, lr = 0.002
I0526 06:49:06.911909 15117 solver.cpp:233] Iteration 33330, loss = 0.0475887
I0526 06:49:06.912142 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0475888 (* 1 = 0.0475888 loss)
I0526 06:49:06.912170 15117 sgd_solver.cpp:294] Iteration 33330, lr = 0.002
I0526 06:49:13.247948 15117 solver.cpp:233] Iteration 33340, loss = 0.0367403
I0526 06:49:13.247992 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0367405 (* 1 = 0.0367405 loss)
I0526 06:49:13.248000 15117 sgd_solver.cpp:294] Iteration 33340, lr = 0.002
I0526 06:49:19.575575 15117 solver.cpp:233] Iteration 33350, loss = 0.0343006
I0526 06:49:19.575615 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0343007 (* 1 = 0.0343007 loss)
I0526 06:49:19.575623 15117 sgd_solver.cpp:294] Iteration 33350, lr = 0.002
I0526 06:49:25.909555 15117 solver.cpp:233] Iteration 33360, loss = 0.0341701
I0526 06:49:25.909600 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0341702 (* 1 = 0.0341702 loss)
I0526 06:49:25.909608 15117 sgd_solver.cpp:294] Iteration 33360, lr = 0.002
I0526 06:49:32.249794 15117 solver.cpp:233] Iteration 33370, loss = 0.0322097
I0526 06:49:32.249835 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0322099 (* 1 = 0.0322099 loss)
I0526 06:49:32.249843 15117 sgd_solver.cpp:294] Iteration 33370, lr = 0.002
I0526 06:49:38.581900 15117 solver.cpp:233] Iteration 33380, loss = 0.0158457
I0526 06:49:38.582154 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0158459 (* 1 = 0.0158459 loss)
I0526 06:49:38.582186 15117 sgd_solver.cpp:294] Iteration 33380, lr = 0.002
I0526 06:49:44.919509 15117 solver.cpp:233] Iteration 33390, loss = 0.00987871
I0526 06:49:44.919551 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00987887 (* 1 = 0.00987887 loss)
I0526 06:49:44.919559 15117 sgd_solver.cpp:294] Iteration 33390, lr = 0.002
I0526 06:49:50.652426 15117 solver.cpp:342] Iteration 33400, Testing net (#0)
I0526 06:50:03.494159 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8987
I0526 06:50:03.494215 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.399888 (* 1 = 0.399888 loss)
I0526 06:50:04.096544 15117 solver.cpp:233] Iteration 33400, loss = 0.0496056
I0526 06:50:04.096570 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0496057 (* 1 = 0.0496057 loss)
I0526 06:50:04.096576 15117 sgd_solver.cpp:294] Iteration 33400, lr = 0.002
I0526 06:50:10.432505 15117 solver.cpp:233] Iteration 33410, loss = 0.0209202
I0526 06:50:10.432790 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0209203 (* 1 = 0.0209203 loss)
I0526 06:50:10.432818 15117 sgd_solver.cpp:294] Iteration 33410, lr = 0.002
I0526 06:50:16.770586 15117 solver.cpp:233] Iteration 33420, loss = 0.0372022
I0526 06:50:16.770623 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0372024 (* 1 = 0.0372024 loss)
I0526 06:50:16.770629 15117 sgd_solver.cpp:294] Iteration 33420, lr = 0.002
I0526 06:50:23.105200 15117 solver.cpp:233] Iteration 33430, loss = 0.0561255
I0526 06:50:23.105262 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0561256 (* 1 = 0.0561256 loss)
I0526 06:50:23.105270 15117 sgd_solver.cpp:294] Iteration 33430, lr = 0.002
I0526 06:50:29.440629 15117 solver.cpp:233] Iteration 33440, loss = 0.0301402
I0526 06:50:29.440670 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0301404 (* 1 = 0.0301404 loss)
I0526 06:50:29.440676 15117 sgd_solver.cpp:294] Iteration 33440, lr = 0.002
I0526 06:50:35.776439 15117 solver.cpp:233] Iteration 33450, loss = 0.0357179
I0526 06:50:35.776485 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0357181 (* 1 = 0.0357181 loss)
I0526 06:50:35.776494 15117 sgd_solver.cpp:294] Iteration 33450, lr = 0.002
I0526 06:50:42.109092 15117 solver.cpp:233] Iteration 33460, loss = 0.0379273
I0526 06:50:42.109328 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0379274 (* 1 = 0.0379274 loss)
I0526 06:50:42.109359 15117 sgd_solver.cpp:294] Iteration 33460, lr = 0.002
I0526 06:50:48.446926 15117 solver.cpp:233] Iteration 33470, loss = 0.037408
I0526 06:50:48.446965 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0374082 (* 1 = 0.0374082 loss)
I0526 06:50:48.446974 15117 sgd_solver.cpp:294] Iteration 33470, lr = 0.002
I0526 06:50:54.781942 15117 solver.cpp:233] Iteration 33480, loss = 0.0490774
I0526 06:50:54.781970 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0490776 (* 1 = 0.0490776 loss)
I0526 06:50:54.781977 15117 sgd_solver.cpp:294] Iteration 33480, lr = 0.002
I0526 06:51:01.119025 15117 solver.cpp:233] Iteration 33490, loss = 0.041341
I0526 06:51:01.119067 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0413411 (* 1 = 0.0413411 loss)
I0526 06:51:01.119074 15117 sgd_solver.cpp:294] Iteration 33490, lr = 0.002
I0526 06:51:06.851158 15117 solver.cpp:342] Iteration 33500, Testing net (#0)
I0526 06:51:19.702651 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9001
I0526 06:51:19.702873 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.399801 (* 1 = 0.399801 loss)
I0526 06:51:20.303460 15117 solver.cpp:233] Iteration 33500, loss = 0.0600495
I0526 06:51:20.303536 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0600497 (* 1 = 0.0600497 loss)
I0526 06:51:20.303547 15117 sgd_solver.cpp:294] Iteration 33500, lr = 0.002
I0526 06:51:26.634670 15117 solver.cpp:233] Iteration 33510, loss = 0.0400802
I0526 06:51:26.634719 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0400804 (* 1 = 0.0400804 loss)
I0526 06:51:26.634727 15117 sgd_solver.cpp:294] Iteration 33510, lr = 0.002
I0526 06:51:32.970396 15117 solver.cpp:233] Iteration 33520, loss = 0.0288204
I0526 06:51:32.970437 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0288206 (* 1 = 0.0288206 loss)
I0526 06:51:32.970444 15117 sgd_solver.cpp:294] Iteration 33520, lr = 0.002
I0526 06:51:39.304647 15117 solver.cpp:233] Iteration 33530, loss = 0.0294024
I0526 06:51:39.304685 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0294026 (* 1 = 0.0294026 loss)
I0526 06:51:39.304698 15117 sgd_solver.cpp:294] Iteration 33530, lr = 0.002
I0526 06:51:45.634189 15117 solver.cpp:233] Iteration 33540, loss = 0.0270496
I0526 06:51:45.634227 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0270498 (* 1 = 0.0270498 loss)
I0526 06:51:45.634235 15117 sgd_solver.cpp:294] Iteration 33540, lr = 0.002
I0526 06:51:51.965883 15117 solver.cpp:233] Iteration 33550, loss = 0.0272257
I0526 06:51:51.966150 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0272259 (* 1 = 0.0272259 loss)
I0526 06:51:51.966187 15117 sgd_solver.cpp:294] Iteration 33550, lr = 0.002
I0526 06:51:58.299343 15117 solver.cpp:233] Iteration 33560, loss = 0.03127
I0526 06:51:58.299386 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0312701 (* 1 = 0.0312701 loss)
I0526 06:51:58.299393 15117 sgd_solver.cpp:294] Iteration 33560, lr = 0.002
I0526 06:52:04.632645 15117 solver.cpp:233] Iteration 33570, loss = 0.0463654
I0526 06:52:04.632690 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0463656 (* 1 = 0.0463656 loss)
I0526 06:52:04.632699 15117 sgd_solver.cpp:294] Iteration 33570, lr = 0.002
I0526 06:52:10.966192 15117 solver.cpp:233] Iteration 33580, loss = 0.0404812
I0526 06:52:10.966229 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0404813 (* 1 = 0.0404813 loss)
I0526 06:52:10.966236 15117 sgd_solver.cpp:294] Iteration 33580, lr = 0.002
I0526 06:52:17.302604 15117 solver.cpp:233] Iteration 33590, loss = 0.0404623
I0526 06:52:17.302650 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0404625 (* 1 = 0.0404625 loss)
I0526 06:52:17.302657 15117 sgd_solver.cpp:294] Iteration 33590, lr = 0.002
I0526 06:52:23.036919 15117 solver.cpp:342] Iteration 33600, Testing net (#0)
I0526 06:52:35.884426 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9008
I0526 06:52:35.884474 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.405778 (* 1 = 0.405778 loss)
I0526 06:52:36.485918 15117 solver.cpp:233] Iteration 33600, loss = 0.0336705
I0526 06:52:36.485956 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0336706 (* 1 = 0.0336706 loss)
I0526 06:52:36.485963 15117 sgd_solver.cpp:294] Iteration 33600, lr = 0.002
I0526 06:52:42.822389 15117 solver.cpp:233] Iteration 33610, loss = 0.063567
I0526 06:52:42.822437 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0635671 (* 1 = 0.0635671 loss)
I0526 06:52:42.822444 15117 sgd_solver.cpp:294] Iteration 33610, lr = 0.002
I0526 06:52:49.154207 15117 solver.cpp:233] Iteration 33620, loss = 0.0339192
I0526 06:52:49.154250 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0339194 (* 1 = 0.0339194 loss)
I0526 06:52:49.154258 15117 sgd_solver.cpp:294] Iteration 33620, lr = 0.002
I0526 06:52:55.489814 15117 solver.cpp:233] Iteration 33630, loss = 0.0205844
I0526 06:52:55.490031 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0205846 (* 1 = 0.0205846 loss)
I0526 06:52:55.490059 15117 sgd_solver.cpp:294] Iteration 33630, lr = 0.002
I0526 06:53:01.824522 15117 solver.cpp:233] Iteration 33640, loss = 0.0240282
I0526 06:53:01.824564 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0240283 (* 1 = 0.0240283 loss)
I0526 06:53:01.824571 15117 sgd_solver.cpp:294] Iteration 33640, lr = 0.002
I0526 06:53:08.160238 15117 solver.cpp:233] Iteration 33650, loss = 0.0248307
I0526 06:53:08.160281 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0248308 (* 1 = 0.0248308 loss)
I0526 06:53:08.160289 15117 sgd_solver.cpp:294] Iteration 33650, lr = 0.002
I0526 06:53:14.498088 15117 solver.cpp:233] Iteration 33660, loss = 0.0500202
I0526 06:53:14.498128 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0500204 (* 1 = 0.0500204 loss)
I0526 06:53:14.498136 15117 sgd_solver.cpp:294] Iteration 33660, lr = 0.002
I0526 06:53:20.834189 15117 solver.cpp:233] Iteration 33670, loss = 0.0707396
I0526 06:53:20.834254 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0707397 (* 1 = 0.0707397 loss)
I0526 06:53:20.834264 15117 sgd_solver.cpp:294] Iteration 33670, lr = 0.002
I0526 06:53:27.167227 15117 solver.cpp:233] Iteration 33680, loss = 0.0309833
I0526 06:53:27.167503 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0309834 (* 1 = 0.0309834 loss)
I0526 06:53:27.167529 15117 sgd_solver.cpp:294] Iteration 33680, lr = 0.002
I0526 06:53:33.502507 15117 solver.cpp:233] Iteration 33690, loss = 0.0157052
I0526 06:53:33.502554 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0157054 (* 1 = 0.0157054 loss)
I0526 06:53:33.502562 15117 sgd_solver.cpp:294] Iteration 33690, lr = 0.002
I0526 06:53:39.232612 15117 solver.cpp:342] Iteration 33700, Testing net (#0)
I0526 06:53:52.068822 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8987
I0526 06:53:52.068853 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.414042 (* 1 = 0.414042 loss)
I0526 06:53:52.670393 15117 solver.cpp:233] Iteration 33700, loss = 0.043461
I0526 06:53:52.670426 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0434611 (* 1 = 0.0434611 loss)
I0526 06:53:52.670433 15117 sgd_solver.cpp:294] Iteration 33700, lr = 0.002
I0526 06:53:59.002482 15117 solver.cpp:233] Iteration 33710, loss = 0.0176464
I0526 06:53:59.002714 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0176465 (* 1 = 0.0176465 loss)
I0526 06:53:59.002740 15117 sgd_solver.cpp:294] Iteration 33710, lr = 0.002
I0526 06:54:05.337179 15117 solver.cpp:233] Iteration 33720, loss = 0.0179022
I0526 06:54:05.337229 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0179024 (* 1 = 0.0179024 loss)
I0526 06:54:05.337237 15117 sgd_solver.cpp:294] Iteration 33720, lr = 0.002
I0526 06:54:11.674391 15117 solver.cpp:233] Iteration 33730, loss = 0.0453124
I0526 06:54:11.674435 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0453126 (* 1 = 0.0453126 loss)
I0526 06:54:11.674443 15117 sgd_solver.cpp:294] Iteration 33730, lr = 0.002
I0526 06:54:18.005832 15117 solver.cpp:233] Iteration 33740, loss = 0.0257234
I0526 06:54:18.005873 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0257236 (* 1 = 0.0257236 loss)
I0526 06:54:18.005882 15117 sgd_solver.cpp:294] Iteration 33740, lr = 0.002
I0526 06:54:24.340153 15117 solver.cpp:233] Iteration 33750, loss = 0.0254349
I0526 06:54:24.340193 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.025435 (* 1 = 0.025435 loss)
I0526 06:54:24.340200 15117 sgd_solver.cpp:294] Iteration 33750, lr = 0.002
I0526 06:54:30.677474 15117 solver.cpp:233] Iteration 33760, loss = 0.0244699
I0526 06:54:30.677691 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0244701 (* 1 = 0.0244701 loss)
I0526 06:54:30.677721 15117 sgd_solver.cpp:294] Iteration 33760, lr = 0.002
I0526 06:54:37.011860 15117 solver.cpp:233] Iteration 33770, loss = 0.036374
I0526 06:54:37.011901 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0363741 (* 1 = 0.0363741 loss)
I0526 06:54:37.011909 15117 sgd_solver.cpp:294] Iteration 33770, lr = 0.002
I0526 06:54:43.348290 15117 solver.cpp:233] Iteration 33780, loss = 0.0355625
I0526 06:54:43.348335 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0355627 (* 1 = 0.0355627 loss)
I0526 06:54:43.348342 15117 sgd_solver.cpp:294] Iteration 33780, lr = 0.002
I0526 06:54:49.685999 15117 solver.cpp:233] Iteration 33790, loss = 0.0441533
I0526 06:54:49.686041 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0441534 (* 1 = 0.0441534 loss)
I0526 06:54:49.686048 15117 sgd_solver.cpp:294] Iteration 33790, lr = 0.002
I0526 06:54:55.419812 15117 solver.cpp:342] Iteration 33800, Testing net (#0)
I0526 06:55:08.260532 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.901
I0526 06:55:08.260738 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.394105 (* 1 = 0.394105 loss)
I0526 06:55:08.862522 15117 solver.cpp:233] Iteration 33800, loss = 0.0185332
I0526 06:55:08.862573 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0185333 (* 1 = 0.0185333 loss)
I0526 06:55:08.862583 15117 sgd_solver.cpp:294] Iteration 33800, lr = 0.002
I0526 06:55:15.197065 15117 solver.cpp:233] Iteration 33810, loss = 0.0244145
I0526 06:55:15.197105 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0244147 (* 1 = 0.0244147 loss)
I0526 06:55:15.197113 15117 sgd_solver.cpp:294] Iteration 33810, lr = 0.002
I0526 06:55:21.534657 15117 solver.cpp:233] Iteration 33820, loss = 0.00933573
I0526 06:55:21.534698 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00933589 (* 1 = 0.00933589 loss)
I0526 06:55:21.534705 15117 sgd_solver.cpp:294] Iteration 33820, lr = 0.002
I0526 06:55:27.872406 15117 solver.cpp:233] Iteration 33830, loss = 0.0135393
I0526 06:55:27.872460 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0135395 (* 1 = 0.0135395 loss)
I0526 06:55:27.872467 15117 sgd_solver.cpp:294] Iteration 33830, lr = 0.002
I0526 06:55:34.210856 15117 solver.cpp:233] Iteration 33840, loss = 0.0293813
I0526 06:55:34.210894 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0293815 (* 1 = 0.0293815 loss)
I0526 06:55:34.210901 15117 sgd_solver.cpp:294] Iteration 33840, lr = 0.002
I0526 06:55:40.547938 15117 solver.cpp:233] Iteration 33850, loss = 0.0180804
I0526 06:55:40.548219 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0180806 (* 1 = 0.0180806 loss)
I0526 06:55:40.548249 15117 sgd_solver.cpp:294] Iteration 33850, lr = 0.002
I0526 06:55:46.886296 15117 solver.cpp:233] Iteration 33860, loss = 0.0455311
I0526 06:55:46.886339 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0455313 (* 1 = 0.0455313 loss)
I0526 06:55:46.886348 15117 sgd_solver.cpp:294] Iteration 33860, lr = 0.002
I0526 06:55:53.220149 15117 solver.cpp:233] Iteration 33870, loss = 0.0326828
I0526 06:55:53.220186 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.032683 (* 1 = 0.032683 loss)
I0526 06:55:53.220193 15117 sgd_solver.cpp:294] Iteration 33870, lr = 0.002
I0526 06:55:59.557384 15117 solver.cpp:233] Iteration 33880, loss = 0.033329
I0526 06:55:59.557425 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0333291 (* 1 = 0.0333291 loss)
I0526 06:55:59.557431 15117 sgd_solver.cpp:294] Iteration 33880, lr = 0.002
I0526 06:56:05.894901 15117 solver.cpp:233] Iteration 33890, loss = 0.0592102
I0526 06:56:05.894939 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0592104 (* 1 = 0.0592104 loss)
I0526 06:56:05.894947 15117 sgd_solver.cpp:294] Iteration 33890, lr = 0.002
I0526 06:56:11.631989 15117 solver.cpp:342] Iteration 33900, Testing net (#0)
I0526 06:56:24.476595 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9044
I0526 06:56:24.476639 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.383727 (* 1 = 0.383727 loss)
I0526 06:56:25.078184 15117 solver.cpp:233] Iteration 33900, loss = 0.0105449
I0526 06:56:25.078217 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0105451 (* 1 = 0.0105451 loss)
I0526 06:56:25.078225 15117 sgd_solver.cpp:294] Iteration 33900, lr = 0.002
I0526 06:56:31.417021 15117 solver.cpp:233] Iteration 33910, loss = 0.0198367
I0526 06:56:31.417063 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0198368 (* 1 = 0.0198368 loss)
I0526 06:56:31.417070 15117 sgd_solver.cpp:294] Iteration 33910, lr = 0.002
I0526 06:56:37.749438 15117 solver.cpp:233] Iteration 33920, loss = 0.034007
I0526 06:56:37.749500 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0340071 (* 1 = 0.0340071 loss)
I0526 06:56:37.749507 15117 sgd_solver.cpp:294] Iteration 33920, lr = 0.002
I0526 06:56:44.085800 15117 solver.cpp:233] Iteration 33930, loss = 0.0579463
I0526 06:56:44.085928 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0579465 (* 1 = 0.0579465 loss)
I0526 06:56:44.085937 15117 sgd_solver.cpp:294] Iteration 33930, lr = 0.002
I0526 06:56:50.422397 15117 solver.cpp:233] Iteration 33940, loss = 0.0222437
I0526 06:56:50.422435 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0222439 (* 1 = 0.0222439 loss)
I0526 06:56:50.422441 15117 sgd_solver.cpp:294] Iteration 33940, lr = 0.002
I0526 06:56:56.759184 15117 solver.cpp:233] Iteration 33950, loss = 0.0303626
I0526 06:56:56.759227 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0303628 (* 1 = 0.0303628 loss)
I0526 06:56:56.759234 15117 sgd_solver.cpp:294] Iteration 33950, lr = 0.002
I0526 06:57:03.097754 15117 solver.cpp:233] Iteration 33960, loss = 0.0701452
I0526 06:57:03.097793 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0701454 (* 1 = 0.0701454 loss)
I0526 06:57:03.097800 15117 sgd_solver.cpp:294] Iteration 33960, lr = 0.002
I0526 06:57:09.432235 15117 solver.cpp:233] Iteration 33970, loss = 0.0288578
I0526 06:57:09.432265 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0288579 (* 1 = 0.0288579 loss)
I0526 06:57:09.432271 15117 sgd_solver.cpp:294] Iteration 33970, lr = 0.002
I0526 06:57:15.770560 15117 solver.cpp:233] Iteration 33980, loss = 0.0366478
I0526 06:57:15.770719 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.036648 (* 1 = 0.036648 loss)
I0526 06:57:15.770726 15117 sgd_solver.cpp:294] Iteration 33980, lr = 0.002
I0526 06:57:22.104357 15117 solver.cpp:233] Iteration 33990, loss = 0.0265944
I0526 06:57:22.104408 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0265945 (* 1 = 0.0265945 loss)
I0526 06:57:22.104415 15117 sgd_solver.cpp:294] Iteration 33990, lr = 0.002
I0526 06:57:27.840957 15117 solver.cpp:342] Iteration 34000, Testing net (#0)
I0526 06:57:40.686790 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9017
I0526 06:57:40.686833 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.398648 (* 1 = 0.398648 loss)
I0526 06:57:41.288664 15117 solver.cpp:233] Iteration 34000, loss = 0.0296699
I0526 06:57:41.288712 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.02967 (* 1 = 0.02967 loss)
I0526 06:57:41.288718 15117 sgd_solver.cpp:294] Iteration 34000, lr = 0.002
I0526 06:57:47.626071 15117 solver.cpp:233] Iteration 34010, loss = 0.0406704
I0526 06:57:47.626301 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0406705 (* 1 = 0.0406705 loss)
I0526 06:57:47.626327 15117 sgd_solver.cpp:294] Iteration 34010, lr = 0.002
I0526 06:57:53.962116 15117 solver.cpp:233] Iteration 34020, loss = 0.0422192
I0526 06:57:53.962142 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0422193 (* 1 = 0.0422193 loss)
I0526 06:57:53.962149 15117 sgd_solver.cpp:294] Iteration 34020, lr = 0.002
I0526 06:58:00.302542 15117 solver.cpp:233] Iteration 34030, loss = 0.0170112
I0526 06:58:00.302584 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0170113 (* 1 = 0.0170113 loss)
I0526 06:58:00.302592 15117 sgd_solver.cpp:294] Iteration 34030, lr = 0.002
I0526 06:58:06.641850 15117 solver.cpp:233] Iteration 34040, loss = 0.0333563
I0526 06:58:06.641891 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0333564 (* 1 = 0.0333564 loss)
I0526 06:58:06.641898 15117 sgd_solver.cpp:294] Iteration 34040, lr = 0.002
I0526 06:58:12.977941 15117 solver.cpp:233] Iteration 34050, loss = 0.0277586
I0526 06:58:12.977987 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0277588 (* 1 = 0.0277588 loss)
I0526 06:58:12.977994 15117 sgd_solver.cpp:294] Iteration 34050, lr = 0.002
I0526 06:58:19.314620 15117 solver.cpp:233] Iteration 34060, loss = 0.0466493
I0526 06:58:19.314853 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0466495 (* 1 = 0.0466495 loss)
I0526 06:58:19.314882 15117 sgd_solver.cpp:294] Iteration 34060, lr = 0.002
I0526 06:58:25.650708 15117 solver.cpp:233] Iteration 34070, loss = 0.0407363
I0526 06:58:25.650750 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0407364 (* 1 = 0.0407364 loss)
I0526 06:58:25.650758 15117 sgd_solver.cpp:294] Iteration 34070, lr = 0.002
I0526 06:58:31.989434 15117 solver.cpp:233] Iteration 34080, loss = 0.0404564
I0526 06:58:31.989472 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0404565 (* 1 = 0.0404565 loss)
I0526 06:58:31.989480 15117 sgd_solver.cpp:294] Iteration 34080, lr = 0.002
I0526 06:58:38.323698 15117 solver.cpp:233] Iteration 34090, loss = 0.0201478
I0526 06:58:38.323736 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0201479 (* 1 = 0.0201479 loss)
I0526 06:58:38.323743 15117 sgd_solver.cpp:294] Iteration 34090, lr = 0.002
I0526 06:58:44.056592 15117 solver.cpp:342] Iteration 34100, Testing net (#0)
I0526 06:58:56.892945 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8993
I0526 06:58:56.893234 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.407415 (* 1 = 0.407415 loss)
I0526 06:58:57.492805 15117 solver.cpp:233] Iteration 34100, loss = 0.0303118
I0526 06:58:57.492847 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.030312 (* 1 = 0.030312 loss)
I0526 06:58:57.492857 15117 sgd_solver.cpp:294] Iteration 34100, lr = 0.002
I0526 06:59:03.828443 15117 solver.cpp:233] Iteration 34110, loss = 0.0491659
I0526 06:59:03.828482 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.049166 (* 1 = 0.049166 loss)
I0526 06:59:03.828490 15117 sgd_solver.cpp:294] Iteration 34110, lr = 0.002
I0526 06:59:10.166512 15117 solver.cpp:233] Iteration 34120, loss = 0.0180528
I0526 06:59:10.166550 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.018053 (* 1 = 0.018053 loss)
I0526 06:59:10.166558 15117 sgd_solver.cpp:294] Iteration 34120, lr = 0.002
I0526 06:59:16.507441 15117 solver.cpp:233] Iteration 34130, loss = 0.0231278
I0526 06:59:16.507483 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.023128 (* 1 = 0.023128 loss)
I0526 06:59:16.507501 15117 sgd_solver.cpp:294] Iteration 34130, lr = 0.002
I0526 06:59:22.842594 15117 solver.cpp:233] Iteration 34140, loss = 0.0219885
I0526 06:59:22.842634 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0219887 (* 1 = 0.0219887 loss)
I0526 06:59:22.842641 15117 sgd_solver.cpp:294] Iteration 34140, lr = 0.002
I0526 06:59:29.177644 15117 solver.cpp:233] Iteration 34150, loss = 0.0483753
I0526 06:59:29.177880 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0483755 (* 1 = 0.0483755 loss)
I0526 06:59:29.177908 15117 sgd_solver.cpp:294] Iteration 34150, lr = 0.002
I0526 06:59:35.508651 15117 solver.cpp:233] Iteration 34160, loss = 0.0503289
I0526 06:59:35.508700 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0503291 (* 1 = 0.0503291 loss)
I0526 06:59:35.508708 15117 sgd_solver.cpp:294] Iteration 34160, lr = 0.002
I0526 06:59:41.845407 15117 solver.cpp:233] Iteration 34170, loss = 0.0118891
I0526 06:59:41.845449 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0118892 (* 1 = 0.0118892 loss)
I0526 06:59:41.845456 15117 sgd_solver.cpp:294] Iteration 34170, lr = 0.002
I0526 06:59:48.183225 15117 solver.cpp:233] Iteration 34180, loss = 0.0203191
I0526 06:59:48.183267 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0203192 (* 1 = 0.0203192 loss)
I0526 06:59:48.183274 15117 sgd_solver.cpp:294] Iteration 34180, lr = 0.002
I0526 06:59:54.520773 15117 solver.cpp:233] Iteration 34190, loss = 0.025333
I0526 06:59:54.520828 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0253332 (* 1 = 0.0253332 loss)
I0526 06:59:54.520833 15117 sgd_solver.cpp:294] Iteration 34190, lr = 0.002
I0526 07:00:00.257469 15117 solver.cpp:342] Iteration 34200, Testing net (#0)
I0526 07:00:13.112664 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8986
I0526 07:00:13.112714 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.388606 (* 1 = 0.388606 loss)
I0526 07:00:13.713369 15117 solver.cpp:233] Iteration 34200, loss = 0.0057655
I0526 07:00:13.713403 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00576567 (* 1 = 0.00576567 loss)
I0526 07:00:13.713421 15117 sgd_solver.cpp:294] Iteration 34200, lr = 0.002
I0526 07:00:20.049665 15117 solver.cpp:233] Iteration 34210, loss = 0.0244387
I0526 07:00:20.049705 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0244388 (* 1 = 0.0244388 loss)
I0526 07:00:20.049711 15117 sgd_solver.cpp:294] Iteration 34210, lr = 0.002
I0526 07:00:26.384344 15117 solver.cpp:233] Iteration 34220, loss = 0.0165886
I0526 07:00:26.384388 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0165888 (* 1 = 0.0165888 loss)
I0526 07:00:26.384395 15117 sgd_solver.cpp:294] Iteration 34220, lr = 0.002
I0526 07:00:32.720336 15117 solver.cpp:233] Iteration 34230, loss = 0.015197
I0526 07:00:32.720602 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0151971 (* 1 = 0.0151971 loss)
I0526 07:00:32.720631 15117 sgd_solver.cpp:294] Iteration 34230, lr = 0.002
I0526 07:00:39.050686 15117 solver.cpp:233] Iteration 34240, loss = 0.0254287
I0526 07:00:39.050729 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0254289 (* 1 = 0.0254289 loss)
I0526 07:00:39.050735 15117 sgd_solver.cpp:294] Iteration 34240, lr = 0.002
I0526 07:00:45.390847 15117 solver.cpp:233] Iteration 34250, loss = 0.048229
I0526 07:00:45.390893 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0482292 (* 1 = 0.0482292 loss)
I0526 07:00:45.390900 15117 sgd_solver.cpp:294] Iteration 34250, lr = 0.002
I0526 07:00:51.725462 15117 solver.cpp:233] Iteration 34260, loss = 0.0355114
I0526 07:00:51.725503 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0355116 (* 1 = 0.0355116 loss)
I0526 07:00:51.725509 15117 sgd_solver.cpp:294] Iteration 34260, lr = 0.002
I0526 07:00:58.057790 15117 solver.cpp:233] Iteration 34270, loss = 0.0114972
I0526 07:00:58.057832 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0114974 (* 1 = 0.0114974 loss)
I0526 07:00:58.057838 15117 sgd_solver.cpp:294] Iteration 34270, lr = 0.002
I0526 07:01:04.395663 15117 solver.cpp:233] Iteration 34280, loss = 0.0561865
I0526 07:01:04.395887 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0561867 (* 1 = 0.0561867 loss)
I0526 07:01:04.395915 15117 sgd_solver.cpp:294] Iteration 34280, lr = 0.002
I0526 07:01:10.733394 15117 solver.cpp:233] Iteration 34290, loss = 0.0679298
I0526 07:01:10.733440 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0679299 (* 1 = 0.0679299 loss)
I0526 07:01:10.733448 15117 sgd_solver.cpp:294] Iteration 34290, lr = 0.002
I0526 07:01:16.469524 15117 solver.cpp:342] Iteration 34300, Testing net (#0)
I0526 07:01:29.306114 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9044
I0526 07:01:29.306159 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.385128 (* 1 = 0.385128 loss)
I0526 07:01:29.908190 15117 solver.cpp:233] Iteration 34300, loss = 0.0429245
I0526 07:01:29.908224 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0429247 (* 1 = 0.0429247 loss)
I0526 07:01:29.908232 15117 sgd_solver.cpp:294] Iteration 34300, lr = 0.002
I0526 07:01:36.242539 15117 solver.cpp:233] Iteration 34310, loss = 0.0289048
I0526 07:01:36.242771 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0289049 (* 1 = 0.0289049 loss)
I0526 07:01:36.242801 15117 sgd_solver.cpp:294] Iteration 34310, lr = 0.002
I0526 07:01:42.576287 15117 solver.cpp:233] Iteration 34320, loss = 0.0260114
I0526 07:01:42.576333 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0260116 (* 1 = 0.0260116 loss)
I0526 07:01:42.576339 15117 sgd_solver.cpp:294] Iteration 34320, lr = 0.002
I0526 07:01:48.910761 15117 solver.cpp:233] Iteration 34330, loss = 0.0143198
I0526 07:01:48.910804 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.01432 (* 1 = 0.01432 loss)
I0526 07:01:48.910809 15117 sgd_solver.cpp:294] Iteration 34330, lr = 0.002
I0526 07:01:55.247953 15117 solver.cpp:233] Iteration 34340, loss = 0.0314228
I0526 07:01:55.247992 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.031423 (* 1 = 0.031423 loss)
I0526 07:01:55.248004 15117 sgd_solver.cpp:294] Iteration 34340, lr = 0.002
I0526 07:02:01.585551 15117 solver.cpp:233] Iteration 34350, loss = 0.0503276
I0526 07:02:01.585590 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0503277 (* 1 = 0.0503277 loss)
I0526 07:02:01.585597 15117 sgd_solver.cpp:294] Iteration 34350, lr = 0.002
I0526 07:02:07.922601 15117 solver.cpp:233] Iteration 34360, loss = 0.0462407
I0526 07:02:07.922778 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0462409 (* 1 = 0.0462409 loss)
I0526 07:02:07.922788 15117 sgd_solver.cpp:294] Iteration 34360, lr = 0.002
I0526 07:02:14.260149 15117 solver.cpp:233] Iteration 34370, loss = 0.0163179
I0526 07:02:14.260191 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.016318 (* 1 = 0.016318 loss)
I0526 07:02:14.260200 15117 sgd_solver.cpp:294] Iteration 34370, lr = 0.002
I0526 07:02:20.596050 15117 solver.cpp:233] Iteration 34380, loss = 0.0406764
I0526 07:02:20.596091 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0406766 (* 1 = 0.0406766 loss)
I0526 07:02:20.596098 15117 sgd_solver.cpp:294] Iteration 34380, lr = 0.002
I0526 07:02:26.931242 15117 solver.cpp:233] Iteration 34390, loss = 0.022186
I0526 07:02:26.931283 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0221862 (* 1 = 0.0221862 loss)
I0526 07:02:26.931289 15117 sgd_solver.cpp:294] Iteration 34390, lr = 0.002
I0526 07:02:32.665019 15117 solver.cpp:342] Iteration 34400, Testing net (#0)
I0526 07:02:45.502943 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9055
I0526 07:02:45.503167 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.372275 (* 1 = 0.372275 loss)
I0526 07:02:46.102756 15117 solver.cpp:233] Iteration 34400, loss = 0.0194993
I0526 07:02:46.102804 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0194995 (* 1 = 0.0194995 loss)
I0526 07:02:46.102813 15117 sgd_solver.cpp:294] Iteration 34400, lr = 0.002
I0526 07:02:52.438154 15117 solver.cpp:233] Iteration 34410, loss = 0.0498349
I0526 07:02:52.438190 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0498351 (* 1 = 0.0498351 loss)
I0526 07:02:52.438197 15117 sgd_solver.cpp:294] Iteration 34410, lr = 0.002
I0526 07:02:58.774996 15117 solver.cpp:233] Iteration 34420, loss = 0.0230245
I0526 07:02:58.775059 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0230247 (* 1 = 0.0230247 loss)
I0526 07:02:58.775068 15117 sgd_solver.cpp:294] Iteration 34420, lr = 0.002
I0526 07:03:05.107084 15117 solver.cpp:233] Iteration 34430, loss = 0.0403319
I0526 07:03:05.107125 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0403321 (* 1 = 0.0403321 loss)
I0526 07:03:05.107132 15117 sgd_solver.cpp:294] Iteration 34430, lr = 0.002
I0526 07:03:11.445199 15117 solver.cpp:233] Iteration 34440, loss = 0.0325476
I0526 07:03:11.445242 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0325478 (* 1 = 0.0325478 loss)
I0526 07:03:11.445250 15117 sgd_solver.cpp:294] Iteration 34440, lr = 0.002
I0526 07:03:17.779638 15117 solver.cpp:233] Iteration 34450, loss = 0.0311384
I0526 07:03:17.779867 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0311385 (* 1 = 0.0311385 loss)
I0526 07:03:17.779893 15117 sgd_solver.cpp:294] Iteration 34450, lr = 0.002
I0526 07:03:24.115937 15117 solver.cpp:233] Iteration 34460, loss = 0.0532814
I0526 07:03:24.115993 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0532815 (* 1 = 0.0532815 loss)
I0526 07:03:24.115999 15117 sgd_solver.cpp:294] Iteration 34460, lr = 0.002
I0526 07:03:30.451983 15117 solver.cpp:233] Iteration 34470, loss = 0.0252368
I0526 07:03:30.452019 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0252369 (* 1 = 0.0252369 loss)
I0526 07:03:30.452026 15117 sgd_solver.cpp:294] Iteration 34470, lr = 0.002
I0526 07:03:36.786924 15117 solver.cpp:233] Iteration 34480, loss = 0.0180379
I0526 07:03:36.786964 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.018038 (* 1 = 0.018038 loss)
I0526 07:03:36.786978 15117 sgd_solver.cpp:294] Iteration 34480, lr = 0.002
I0526 07:03:43.116430 15117 solver.cpp:233] Iteration 34490, loss = 0.0362087
I0526 07:03:43.116492 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0362088 (* 1 = 0.0362088 loss)
I0526 07:03:43.116500 15117 sgd_solver.cpp:294] Iteration 34490, lr = 0.002
I0526 07:03:48.851624 15117 solver.cpp:342] Iteration 34500, Testing net (#0)
I0526 07:04:01.680804 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8988
I0526 07:04:01.680847 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.399766 (* 1 = 0.399766 loss)
I0526 07:04:02.283227 15117 solver.cpp:233] Iteration 34500, loss = 0.0560991
I0526 07:04:02.283275 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0560993 (* 1 = 0.0560993 loss)
I0526 07:04:02.283282 15117 sgd_solver.cpp:294] Iteration 34500, lr = 0.002
I0526 07:04:08.618706 15117 solver.cpp:233] Iteration 34510, loss = 0.0238441
I0526 07:04:08.618749 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0238442 (* 1 = 0.0238442 loss)
I0526 07:04:08.618757 15117 sgd_solver.cpp:294] Iteration 34510, lr = 0.002
I0526 07:04:14.955191 15117 solver.cpp:233] Iteration 34520, loss = 0.0516056
I0526 07:04:14.955248 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0516057 (* 1 = 0.0516057 loss)
I0526 07:04:14.955255 15117 sgd_solver.cpp:294] Iteration 34520, lr = 0.002
I0526 07:04:21.292842 15117 solver.cpp:233] Iteration 34530, loss = 0.0149342
I0526 07:04:21.293088 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0149344 (* 1 = 0.0149344 loss)
I0526 07:04:21.293123 15117 sgd_solver.cpp:294] Iteration 34530, lr = 0.002
I0526 07:04:27.621498 15117 solver.cpp:233] Iteration 34540, loss = 0.0217662
I0526 07:04:27.621543 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0217664 (* 1 = 0.0217664 loss)
I0526 07:04:27.621551 15117 sgd_solver.cpp:294] Iteration 34540, lr = 0.002
I0526 07:04:33.959172 15117 solver.cpp:233] Iteration 34550, loss = 0.086359
I0526 07:04:33.959209 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0863591 (* 1 = 0.0863591 loss)
I0526 07:04:33.959216 15117 sgd_solver.cpp:294] Iteration 34550, lr = 0.002
I0526 07:04:40.299962 15117 solver.cpp:233] Iteration 34560, loss = 0.0231374
I0526 07:04:40.300009 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0231376 (* 1 = 0.0231376 loss)
I0526 07:04:40.300017 15117 sgd_solver.cpp:294] Iteration 34560, lr = 0.002
I0526 07:04:46.641649 15117 solver.cpp:233] Iteration 34570, loss = 0.0145332
I0526 07:04:46.641695 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0145334 (* 1 = 0.0145334 loss)
I0526 07:04:46.641701 15117 sgd_solver.cpp:294] Iteration 34570, lr = 0.002
I0526 07:04:52.979912 15117 solver.cpp:233] Iteration 34580, loss = 0.0151378
I0526 07:04:52.980028 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0151379 (* 1 = 0.0151379 loss)
I0526 07:04:52.980036 15117 sgd_solver.cpp:294] Iteration 34580, lr = 0.002
I0526 07:04:59.316684 15117 solver.cpp:233] Iteration 34590, loss = 0.0399343
I0526 07:04:59.316725 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0399344 (* 1 = 0.0399344 loss)
I0526 07:04:59.316731 15117 sgd_solver.cpp:294] Iteration 34590, lr = 0.002
I0526 07:05:05.053042 15117 solver.cpp:342] Iteration 34600, Testing net (#0)
I0526 07:05:17.888993 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9032
I0526 07:05:17.889047 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.390531 (* 1 = 0.390531 loss)
I0526 07:05:18.489532 15117 solver.cpp:233] Iteration 34600, loss = 0.0169189
I0526 07:05:18.489565 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0169191 (* 1 = 0.0169191 loss)
I0526 07:05:18.489573 15117 sgd_solver.cpp:294] Iteration 34600, lr = 0.002
I0526 07:05:24.830869 15117 solver.cpp:233] Iteration 34610, loss = 0.0534205
I0526 07:05:24.831120 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0534207 (* 1 = 0.0534207 loss)
I0526 07:05:24.831161 15117 sgd_solver.cpp:294] Iteration 34610, lr = 0.002
I0526 07:05:31.159900 15117 solver.cpp:233] Iteration 34620, loss = 0.0195094
I0526 07:05:31.159941 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0195096 (* 1 = 0.0195096 loss)
I0526 07:05:31.159948 15117 sgd_solver.cpp:294] Iteration 34620, lr = 0.002
I0526 07:05:37.493245 15117 solver.cpp:233] Iteration 34630, loss = 0.0295705
I0526 07:05:37.493283 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0295707 (* 1 = 0.0295707 loss)
I0526 07:05:37.493291 15117 sgd_solver.cpp:294] Iteration 34630, lr = 0.002
I0526 07:05:43.831636 15117 solver.cpp:233] Iteration 34640, loss = 0.0182058
I0526 07:05:43.831667 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.018206 (* 1 = 0.018206 loss)
I0526 07:05:43.831676 15117 sgd_solver.cpp:294] Iteration 34640, lr = 0.002
I0526 07:05:50.168349 15117 solver.cpp:233] Iteration 34650, loss = 0.0448286
I0526 07:05:50.168392 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0448288 (* 1 = 0.0448288 loss)
I0526 07:05:50.168401 15117 sgd_solver.cpp:294] Iteration 34650, lr = 0.002
I0526 07:05:56.508384 15117 solver.cpp:233] Iteration 34660, loss = 0.0345389
I0526 07:05:56.508608 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0345391 (* 1 = 0.0345391 loss)
I0526 07:05:56.508637 15117 sgd_solver.cpp:294] Iteration 34660, lr = 0.002
I0526 07:06:02.844080 15117 solver.cpp:233] Iteration 34670, loss = 0.0100084
I0526 07:06:02.844122 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0100085 (* 1 = 0.0100085 loss)
I0526 07:06:02.844128 15117 sgd_solver.cpp:294] Iteration 34670, lr = 0.002
I0526 07:06:09.182315 15117 solver.cpp:233] Iteration 34680, loss = 0.00972344
I0526 07:06:09.182373 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00972361 (* 1 = 0.00972361 loss)
I0526 07:06:09.182391 15117 sgd_solver.cpp:294] Iteration 34680, lr = 0.002
I0526 07:06:15.517634 15117 solver.cpp:233] Iteration 34690, loss = 0.0312373
I0526 07:06:15.517675 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0312374 (* 1 = 0.0312374 loss)
I0526 07:06:15.517684 15117 sgd_solver.cpp:294] Iteration 34690, lr = 0.002
I0526 07:06:21.253734 15117 solver.cpp:342] Iteration 34700, Testing net (#0)
I0526 07:06:34.090745 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.904
I0526 07:06:34.090965 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.390942 (* 1 = 0.390942 loss)
I0526 07:06:34.689875 15117 solver.cpp:233] Iteration 34700, loss = 0.0283043
I0526 07:06:34.689908 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0283044 (* 1 = 0.0283044 loss)
I0526 07:06:34.689918 15117 sgd_solver.cpp:294] Iteration 34700, lr = 0.002
I0526 07:06:41.021312 15117 solver.cpp:233] Iteration 34710, loss = 0.0144333
I0526 07:06:41.021370 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0144335 (* 1 = 0.0144335 loss)
I0526 07:06:41.021378 15117 sgd_solver.cpp:294] Iteration 34710, lr = 0.002
I0526 07:06:47.358275 15117 solver.cpp:233] Iteration 34720, loss = 0.0220059
I0526 07:06:47.358314 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.022006 (* 1 = 0.022006 loss)
I0526 07:06:47.358319 15117 sgd_solver.cpp:294] Iteration 34720, lr = 0.002
I0526 07:06:53.693313 15117 solver.cpp:233] Iteration 34730, loss = 0.0287014
I0526 07:06:53.693358 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0287016 (* 1 = 0.0287016 loss)
I0526 07:06:53.693366 15117 sgd_solver.cpp:294] Iteration 34730, lr = 0.002
I0526 07:07:00.033440 15117 solver.cpp:233] Iteration 34740, loss = 0.0194957
I0526 07:07:00.033483 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0194959 (* 1 = 0.0194959 loss)
I0526 07:07:00.033489 15117 sgd_solver.cpp:294] Iteration 34740, lr = 0.002
I0526 07:07:06.370098 15117 solver.cpp:233] Iteration 34750, loss = 0.0130256
I0526 07:07:06.370395 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0130257 (* 1 = 0.0130257 loss)
I0526 07:07:06.370425 15117 sgd_solver.cpp:294] Iteration 34750, lr = 0.002
I0526 07:07:12.703820 15117 solver.cpp:233] Iteration 34760, loss = 0.0122019
I0526 07:07:12.703862 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.012202 (* 1 = 0.012202 loss)
I0526 07:07:12.703871 15117 sgd_solver.cpp:294] Iteration 34760, lr = 0.002
I0526 07:07:19.040796 15117 solver.cpp:233] Iteration 34770, loss = 0.0340405
I0526 07:07:19.040838 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0340407 (* 1 = 0.0340407 loss)
I0526 07:07:19.040845 15117 sgd_solver.cpp:294] Iteration 34770, lr = 0.002
I0526 07:07:25.376811 15117 solver.cpp:233] Iteration 34780, loss = 0.0409514
I0526 07:07:25.376852 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0409516 (* 1 = 0.0409516 loss)
I0526 07:07:25.376859 15117 sgd_solver.cpp:294] Iteration 34780, lr = 0.002
I0526 07:07:31.714087 15117 solver.cpp:233] Iteration 34790, loss = 0.0184802
I0526 07:07:31.714129 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0184804 (* 1 = 0.0184804 loss)
I0526 07:07:31.714135 15117 sgd_solver.cpp:294] Iteration 34790, lr = 0.002
I0526 07:07:37.447800 15117 solver.cpp:342] Iteration 34800, Testing net (#0)
I0526 07:07:50.300134 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9014
I0526 07:07:50.300184 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.400096 (* 1 = 0.400096 loss)
I0526 07:07:50.900979 15117 solver.cpp:233] Iteration 34800, loss = 0.0138244
I0526 07:07:50.901003 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0138245 (* 1 = 0.0138245 loss)
I0526 07:07:50.901010 15117 sgd_solver.cpp:294] Iteration 34800, lr = 0.002
I0526 07:07:57.240854 15117 solver.cpp:233] Iteration 34810, loss = 0.0256961
I0526 07:07:57.240892 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0256963 (* 1 = 0.0256963 loss)
I0526 07:07:57.240900 15117 sgd_solver.cpp:294] Iteration 34810, lr = 0.002
I0526 07:08:03.579226 15117 solver.cpp:233] Iteration 34820, loss = 0.0451045
I0526 07:08:03.579268 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0451047 (* 1 = 0.0451047 loss)
I0526 07:08:03.579277 15117 sgd_solver.cpp:294] Iteration 34820, lr = 0.002
I0526 07:08:09.915086 15117 solver.cpp:233] Iteration 34830, loss = 0.0200033
I0526 07:08:09.915310 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0200034 (* 1 = 0.0200034 loss)
I0526 07:08:09.915339 15117 sgd_solver.cpp:294] Iteration 34830, lr = 0.002
I0526 07:08:16.250645 15117 solver.cpp:233] Iteration 34840, loss = 0.0255434
I0526 07:08:16.250696 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0255435 (* 1 = 0.0255435 loss)
I0526 07:08:16.250704 15117 sgd_solver.cpp:294] Iteration 34840, lr = 0.002
I0526 07:08:22.588762 15117 solver.cpp:233] Iteration 34850, loss = 0.01123
I0526 07:08:22.588804 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0112302 (* 1 = 0.0112302 loss)
I0526 07:08:22.588810 15117 sgd_solver.cpp:294] Iteration 34850, lr = 0.002
I0526 07:08:28.924401 15117 solver.cpp:233] Iteration 34860, loss = 0.0191625
I0526 07:08:28.924443 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0191627 (* 1 = 0.0191627 loss)
I0526 07:08:28.924450 15117 sgd_solver.cpp:294] Iteration 34860, lr = 0.002
I0526 07:08:35.257809 15117 solver.cpp:233] Iteration 34870, loss = 0.0178867
I0526 07:08:35.257863 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0178869 (* 1 = 0.0178869 loss)
I0526 07:08:35.257870 15117 sgd_solver.cpp:294] Iteration 34870, lr = 0.002
I0526 07:08:41.596477 15117 solver.cpp:233] Iteration 34880, loss = 0.0274473
I0526 07:08:41.596693 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0274475 (* 1 = 0.0274475 loss)
I0526 07:08:41.596727 15117 sgd_solver.cpp:294] Iteration 34880, lr = 0.002
I0526 07:08:47.928686 15117 solver.cpp:233] Iteration 34890, loss = 0.0340234
I0526 07:08:47.928732 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0340235 (* 1 = 0.0340235 loss)
I0526 07:08:47.928741 15117 sgd_solver.cpp:294] Iteration 34890, lr = 0.002
I0526 07:08:53.663030 15117 solver.cpp:342] Iteration 34900, Testing net (#0)
I0526 07:09:06.506711 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8976
I0526 07:09:06.506762 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.421089 (* 1 = 0.421089 loss)
I0526 07:09:07.104830 15117 solver.cpp:233] Iteration 34900, loss = 0.0452797
I0526 07:09:07.104854 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0452799 (* 1 = 0.0452799 loss)
I0526 07:09:07.104861 15117 sgd_solver.cpp:294] Iteration 34900, lr = 0.002
I0526 07:09:13.441799 15117 solver.cpp:233] Iteration 34910, loss = 0.0237001
I0526 07:09:13.441977 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0237002 (* 1 = 0.0237002 loss)
I0526 07:09:13.441985 15117 sgd_solver.cpp:294] Iteration 34910, lr = 0.002
I0526 07:09:19.778375 15117 solver.cpp:233] Iteration 34920, loss = 0.0190943
I0526 07:09:19.778427 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0190945 (* 1 = 0.0190945 loss)
I0526 07:09:19.778434 15117 sgd_solver.cpp:294] Iteration 34920, lr = 0.002
I0526 07:09:26.115058 15117 solver.cpp:233] Iteration 34930, loss = 0.0431996
I0526 07:09:26.115099 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0431998 (* 1 = 0.0431998 loss)
I0526 07:09:26.115105 15117 sgd_solver.cpp:294] Iteration 34930, lr = 0.002
I0526 07:09:32.452157 15117 solver.cpp:233] Iteration 34940, loss = 0.0254526
I0526 07:09:32.452198 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0254528 (* 1 = 0.0254528 loss)
I0526 07:09:32.452205 15117 sgd_solver.cpp:294] Iteration 34940, lr = 0.002
I0526 07:09:38.784440 15117 solver.cpp:233] Iteration 34950, loss = 0.022459
I0526 07:09:38.784482 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0224591 (* 1 = 0.0224591 loss)
I0526 07:09:38.784489 15117 sgd_solver.cpp:294] Iteration 34950, lr = 0.002
I0526 07:09:45.122721 15117 solver.cpp:233] Iteration 34960, loss = 0.0370667
I0526 07:09:45.122979 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0370669 (* 1 = 0.0370669 loss)
I0526 07:09:45.123008 15117 sgd_solver.cpp:294] Iteration 34960, lr = 0.002
I0526 07:09:51.457311 15117 solver.cpp:233] Iteration 34970, loss = 0.0206662
I0526 07:09:51.457362 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0206664 (* 1 = 0.0206664 loss)
I0526 07:09:51.457381 15117 sgd_solver.cpp:294] Iteration 34970, lr = 0.002
I0526 07:09:57.793421 15117 solver.cpp:233] Iteration 34980, loss = 0.0349176
I0526 07:09:57.793460 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0349178 (* 1 = 0.0349178 loss)
I0526 07:09:57.793467 15117 sgd_solver.cpp:294] Iteration 34980, lr = 0.002
I0526 07:10:04.124245 15117 solver.cpp:233] Iteration 34990, loss = 0.0291836
I0526 07:10:04.124294 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0291838 (* 1 = 0.0291838 loss)
I0526 07:10:04.124302 15117 sgd_solver.cpp:294] Iteration 34990, lr = 0.002
I0526 07:10:09.861263 15117 solver.cpp:342] Iteration 35000, Testing net (#0)
I0526 07:10:22.704957 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8992
I0526 07:10:22.705179 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.400748 (* 1 = 0.400748 loss)
I0526 07:10:23.305065 15117 solver.cpp:233] Iteration 35000, loss = 0.0451416
I0526 07:10:23.305101 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0451417 (* 1 = 0.0451417 loss)
I0526 07:10:23.305110 15117 sgd_solver.cpp:294] Iteration 35000, lr = 0.002
I0526 07:10:29.638598 15117 solver.cpp:233] Iteration 35010, loss = 0.0387069
I0526 07:10:29.638646 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.038707 (* 1 = 0.038707 loss)
I0526 07:10:29.638654 15117 sgd_solver.cpp:294] Iteration 35010, lr = 0.002
I0526 07:10:35.978478 15117 solver.cpp:233] Iteration 35020, loss = 0.0127605
I0526 07:10:35.978523 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0127607 (* 1 = 0.0127607 loss)
I0526 07:10:35.978531 15117 sgd_solver.cpp:294] Iteration 35020, lr = 0.002
I0526 07:10:42.314683 15117 solver.cpp:233] Iteration 35030, loss = 0.0159942
I0526 07:10:42.314720 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0159943 (* 1 = 0.0159943 loss)
I0526 07:10:42.314728 15117 sgd_solver.cpp:294] Iteration 35030, lr = 0.002
I0526 07:10:48.649435 15117 solver.cpp:233] Iteration 35040, loss = 0.0306176
I0526 07:10:48.649480 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0306178 (* 1 = 0.0306178 loss)
I0526 07:10:48.649487 15117 sgd_solver.cpp:294] Iteration 35040, lr = 0.002
I0526 07:10:54.982939 15117 solver.cpp:233] Iteration 35050, loss = 0.0182604
I0526 07:10:54.983202 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0182605 (* 1 = 0.0182605 loss)
I0526 07:10:54.983232 15117 sgd_solver.cpp:294] Iteration 35050, lr = 0.002
I0526 07:11:01.318456 15117 solver.cpp:233] Iteration 35060, loss = 0.0130963
I0526 07:11:01.318500 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0130965 (* 1 = 0.0130965 loss)
I0526 07:11:01.318507 15117 sgd_solver.cpp:294] Iteration 35060, lr = 0.002
I0526 07:11:07.656497 15117 solver.cpp:233] Iteration 35070, loss = 0.0183571
I0526 07:11:07.656540 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0183573 (* 1 = 0.0183573 loss)
I0526 07:11:07.656548 15117 sgd_solver.cpp:294] Iteration 35070, lr = 0.002
I0526 07:11:13.994699 15117 solver.cpp:233] Iteration 35080, loss = 0.0188664
I0526 07:11:13.994741 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0188666 (* 1 = 0.0188666 loss)
I0526 07:11:13.994750 15117 sgd_solver.cpp:294] Iteration 35080, lr = 0.002
I0526 07:11:20.329805 15117 solver.cpp:233] Iteration 35090, loss = 0.0369312
I0526 07:11:20.329860 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0369314 (* 1 = 0.0369314 loss)
I0526 07:11:20.329867 15117 sgd_solver.cpp:294] Iteration 35090, lr = 0.002
I0526 07:11:26.068773 15117 solver.cpp:342] Iteration 35100, Testing net (#0)
I0526 07:11:38.911649 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8973
I0526 07:11:38.911701 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.426001 (* 1 = 0.426001 loss)
I0526 07:11:39.513095 15117 solver.cpp:233] Iteration 35100, loss = 0.0315867
I0526 07:11:39.513149 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0315869 (* 1 = 0.0315869 loss)
I0526 07:11:39.513159 15117 sgd_solver.cpp:294] Iteration 35100, lr = 0.002
I0526 07:11:45.848479 15117 solver.cpp:233] Iteration 35110, loss = 0.0166594
I0526 07:11:45.848505 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0166595 (* 1 = 0.0166595 loss)
I0526 07:11:45.848511 15117 sgd_solver.cpp:294] Iteration 35110, lr = 0.002
I0526 07:11:52.183806 15117 solver.cpp:233] Iteration 35120, loss = 0.0471399
I0526 07:11:52.183851 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.04714 (* 1 = 0.04714 loss)
I0526 07:11:52.183857 15117 sgd_solver.cpp:294] Iteration 35120, lr = 0.002
I0526 07:11:58.522686 15117 solver.cpp:233] Iteration 35130, loss = 0.0349879
I0526 07:11:58.522899 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0349881 (* 1 = 0.0349881 loss)
I0526 07:11:58.522927 15117 sgd_solver.cpp:294] Iteration 35130, lr = 0.002
I0526 07:12:04.857041 15117 solver.cpp:233] Iteration 35140, loss = 0.0114537
I0526 07:12:04.857080 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0114539 (* 1 = 0.0114539 loss)
I0526 07:12:04.857087 15117 sgd_solver.cpp:294] Iteration 35140, lr = 0.002
I0526 07:12:11.190978 15117 solver.cpp:233] Iteration 35150, loss = 0.00873028
I0526 07:12:11.191015 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00873044 (* 1 = 0.00873044 loss)
I0526 07:12:11.191022 15117 sgd_solver.cpp:294] Iteration 35150, lr = 0.002
I0526 07:12:17.525733 15117 solver.cpp:233] Iteration 35160, loss = 0.0295476
I0526 07:12:17.525770 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0295478 (* 1 = 0.0295478 loss)
I0526 07:12:17.525777 15117 sgd_solver.cpp:294] Iteration 35160, lr = 0.002
I0526 07:12:23.865644 15117 solver.cpp:233] Iteration 35170, loss = 0.0133531
I0526 07:12:23.865694 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0133532 (* 1 = 0.0133532 loss)
I0526 07:12:23.865701 15117 sgd_solver.cpp:294] Iteration 35170, lr = 0.002
I0526 07:12:30.205380 15117 solver.cpp:233] Iteration 35180, loss = 0.0574966
I0526 07:12:30.205667 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0574967 (* 1 = 0.0574967 loss)
I0526 07:12:30.205696 15117 sgd_solver.cpp:294] Iteration 35180, lr = 0.002
I0526 07:12:36.514312 15117 solver.cpp:233] Iteration 35190, loss = 0.00884306
I0526 07:12:36.514356 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00884322 (* 1 = 0.00884322 loss)
I0526 07:12:36.514375 15117 sgd_solver.cpp:294] Iteration 35190, lr = 0.002
I0526 07:12:42.229209 15117 solver.cpp:342] Iteration 35200, Testing net (#0)
I0526 07:12:55.040019 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8994
I0526 07:12:55.040056 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.41423 (* 1 = 0.41423 loss)
I0526 07:12:55.641499 15117 solver.cpp:233] Iteration 35200, loss = 0.0487269
I0526 07:12:55.641532 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0487271 (* 1 = 0.0487271 loss)
I0526 07:12:55.641551 15117 sgd_solver.cpp:294] Iteration 35200, lr = 0.002
I0526 07:13:01.977090 15117 solver.cpp:233] Iteration 35210, loss = 0.0214971
I0526 07:13:01.977326 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0214972 (* 1 = 0.0214972 loss)
I0526 07:13:01.977354 15117 sgd_solver.cpp:294] Iteration 35210, lr = 0.002
I0526 07:13:08.309120 15117 solver.cpp:233] Iteration 35220, loss = 0.0798755
I0526 07:13:08.309159 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0798757 (* 1 = 0.0798757 loss)
I0526 07:13:08.309165 15117 sgd_solver.cpp:294] Iteration 35220, lr = 0.002
I0526 07:13:14.641849 15117 solver.cpp:233] Iteration 35230, loss = 0.0254522
I0526 07:13:14.641890 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0254524 (* 1 = 0.0254524 loss)
I0526 07:13:14.641896 15117 sgd_solver.cpp:294] Iteration 35230, lr = 0.002
I0526 07:13:20.975545 15117 solver.cpp:233] Iteration 35240, loss = 0.0168238
I0526 07:13:20.975585 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0168239 (* 1 = 0.0168239 loss)
I0526 07:13:20.975592 15117 sgd_solver.cpp:294] Iteration 35240, lr = 0.002
I0526 07:13:27.310768 15117 solver.cpp:233] Iteration 35250, loss = 0.0150585
I0526 07:13:27.310813 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0150587 (* 1 = 0.0150587 loss)
I0526 07:13:27.310820 15117 sgd_solver.cpp:294] Iteration 35250, lr = 0.002
I0526 07:13:33.644165 15117 solver.cpp:233] Iteration 35260, loss = 0.0330094
I0526 07:13:33.644414 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0330095 (* 1 = 0.0330095 loss)
I0526 07:13:33.644444 15117 sgd_solver.cpp:294] Iteration 35260, lr = 0.002
I0526 07:13:39.974485 15117 solver.cpp:233] Iteration 35270, loss = 0.0255346
I0526 07:13:39.974539 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0255348 (* 1 = 0.0255348 loss)
I0526 07:13:39.974557 15117 sgd_solver.cpp:294] Iteration 35270, lr = 0.002
I0526 07:13:46.307224 15117 solver.cpp:233] Iteration 35280, loss = 0.0101284
I0526 07:13:46.307267 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0101286 (* 1 = 0.0101286 loss)
I0526 07:13:46.307274 15117 sgd_solver.cpp:294] Iteration 35280, lr = 0.002
I0526 07:13:52.635350 15117 solver.cpp:233] Iteration 35290, loss = 0.0126639
I0526 07:13:52.635391 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0126641 (* 1 = 0.0126641 loss)
I0526 07:13:52.635398 15117 sgd_solver.cpp:294] Iteration 35290, lr = 0.002
I0526 07:13:58.363946 15117 solver.cpp:342] Iteration 35300, Testing net (#0)
I0526 07:14:11.203816 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9014
I0526 07:14:11.203980 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.407348 (* 1 = 0.407348 loss)
I0526 07:14:11.805183 15117 solver.cpp:233] Iteration 35300, loss = 0.0566525
I0526 07:14:11.805224 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0566526 (* 1 = 0.0566526 loss)
I0526 07:14:11.805232 15117 sgd_solver.cpp:294] Iteration 35300, lr = 0.002
I0526 07:14:18.143606 15117 solver.cpp:233] Iteration 35310, loss = 0.0482308
I0526 07:14:18.143657 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0482309 (* 1 = 0.0482309 loss)
I0526 07:14:18.143664 15117 sgd_solver.cpp:294] Iteration 35310, lr = 0.002
I0526 07:14:24.482317 15117 solver.cpp:233] Iteration 35320, loss = 0.026065
I0526 07:14:24.482357 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0260652 (* 1 = 0.0260652 loss)
I0526 07:14:24.482363 15117 sgd_solver.cpp:294] Iteration 35320, lr = 0.002
I0526 07:14:30.815240 15117 solver.cpp:233] Iteration 35330, loss = 0.0107246
I0526 07:14:30.815285 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0107247 (* 1 = 0.0107247 loss)
I0526 07:14:30.815294 15117 sgd_solver.cpp:294] Iteration 35330, lr = 0.002
I0526 07:14:37.151315 15117 solver.cpp:233] Iteration 35340, loss = 0.0242478
I0526 07:14:37.151355 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.024248 (* 1 = 0.024248 loss)
I0526 07:14:37.151362 15117 sgd_solver.cpp:294] Iteration 35340, lr = 0.002
I0526 07:14:43.484598 15117 solver.cpp:233] Iteration 35350, loss = 0.0145445
I0526 07:14:43.484832 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0145447 (* 1 = 0.0145447 loss)
I0526 07:14:43.484860 15117 sgd_solver.cpp:294] Iteration 35350, lr = 0.002
I0526 07:14:49.818579 15117 solver.cpp:233] Iteration 35360, loss = 0.0329859
I0526 07:14:49.818626 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.032986 (* 1 = 0.032986 loss)
I0526 07:14:49.818634 15117 sgd_solver.cpp:294] Iteration 35360, lr = 0.002
I0526 07:14:56.151283 15117 solver.cpp:233] Iteration 35370, loss = 0.014367
I0526 07:14:56.151319 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0143672 (* 1 = 0.0143672 loss)
I0526 07:14:56.151325 15117 sgd_solver.cpp:294] Iteration 35370, lr = 0.002
I0526 07:15:02.488370 15117 solver.cpp:233] Iteration 35380, loss = 0.0550701
I0526 07:15:02.488423 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0550702 (* 1 = 0.0550702 loss)
I0526 07:15:02.488430 15117 sgd_solver.cpp:294] Iteration 35380, lr = 0.002
I0526 07:15:08.822365 15117 solver.cpp:233] Iteration 35390, loss = 0.0384413
I0526 07:15:08.822402 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0384415 (* 1 = 0.0384415 loss)
I0526 07:15:08.822408 15117 sgd_solver.cpp:294] Iteration 35390, lr = 0.002
I0526 07:15:14.557932 15117 solver.cpp:342] Iteration 35400, Testing net (#0)
I0526 07:15:27.398389 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9015
I0526 07:15:27.398437 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.405531 (* 1 = 0.405531 loss)
I0526 07:15:28.000694 15117 solver.cpp:233] Iteration 35400, loss = 0.0201554
I0526 07:15:28.000715 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0201556 (* 1 = 0.0201556 loss)
I0526 07:15:28.000721 15117 sgd_solver.cpp:294] Iteration 35400, lr = 0.002
I0526 07:15:34.335436 15117 solver.cpp:233] Iteration 35410, loss = 0.034978
I0526 07:15:34.335476 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0349781 (* 1 = 0.0349781 loss)
I0526 07:15:34.335484 15117 sgd_solver.cpp:294] Iteration 35410, lr = 0.002
I0526 07:15:40.673815 15117 solver.cpp:233] Iteration 35420, loss = 0.0112378
I0526 07:15:40.673856 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.011238 (* 1 = 0.011238 loss)
I0526 07:15:40.673868 15117 sgd_solver.cpp:294] Iteration 35420, lr = 0.002
I0526 07:15:47.011210 15117 solver.cpp:233] Iteration 35430, loss = 0.0443785
I0526 07:15:47.011471 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0443787 (* 1 = 0.0443787 loss)
I0526 07:15:47.011502 15117 sgd_solver.cpp:294] Iteration 35430, lr = 0.002
I0526 07:15:53.346853 15117 solver.cpp:233] Iteration 35440, loss = 0.0141856
I0526 07:15:53.346890 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0141858 (* 1 = 0.0141858 loss)
I0526 07:15:53.346899 15117 sgd_solver.cpp:294] Iteration 35440, lr = 0.002
I0526 07:15:59.683254 15117 solver.cpp:233] Iteration 35450, loss = 0.0245274
I0526 07:15:59.683295 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0245275 (* 1 = 0.0245275 loss)
I0526 07:15:59.683301 15117 sgd_solver.cpp:294] Iteration 35450, lr = 0.002
I0526 07:16:06.017451 15117 solver.cpp:233] Iteration 35460, loss = 0.0542678
I0526 07:16:06.017505 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0542679 (* 1 = 0.0542679 loss)
I0526 07:16:06.017513 15117 sgd_solver.cpp:294] Iteration 35460, lr = 0.002
I0526 07:16:12.350395 15117 solver.cpp:233] Iteration 35470, loss = 0.0196821
I0526 07:16:12.350457 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0196823 (* 1 = 0.0196823 loss)
I0526 07:16:12.350467 15117 sgd_solver.cpp:294] Iteration 35470, lr = 0.002
I0526 07:16:18.685360 15117 solver.cpp:233] Iteration 35480, loss = 0.0127709
I0526 07:16:18.685586 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.012771 (* 1 = 0.012771 loss)
I0526 07:16:18.685611 15117 sgd_solver.cpp:294] Iteration 35480, lr = 0.002
I0526 07:16:25.015048 15117 solver.cpp:233] Iteration 35490, loss = 0.0216175
I0526 07:16:25.015076 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0216176 (* 1 = 0.0216176 loss)
I0526 07:16:25.015084 15117 sgd_solver.cpp:294] Iteration 35490, lr = 0.002
I0526 07:16:30.749639 15117 solver.cpp:342] Iteration 35500, Testing net (#0)
I0526 07:16:43.591001 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9025
I0526 07:16:43.591045 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.406508 (* 1 = 0.406508 loss)
I0526 07:16:44.192399 15117 solver.cpp:233] Iteration 35500, loss = 0.0159561
I0526 07:16:44.192440 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0159563 (* 1 = 0.0159563 loss)
I0526 07:16:44.192447 15117 sgd_solver.cpp:294] Iteration 35500, lr = 0.002
I0526 07:16:50.542722 15117 solver.cpp:233] Iteration 35510, loss = 0.0170389
I0526 07:16:50.542950 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0170391 (* 1 = 0.0170391 loss)
I0526 07:16:50.542979 15117 sgd_solver.cpp:294] Iteration 35510, lr = 0.002
I0526 07:16:56.889407 15117 solver.cpp:233] Iteration 35520, loss = 0.0125071
I0526 07:16:56.889456 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0125073 (* 1 = 0.0125073 loss)
I0526 07:16:56.889462 15117 sgd_solver.cpp:294] Iteration 35520, lr = 0.002
I0526 07:17:03.240859 15117 solver.cpp:233] Iteration 35530, loss = 0.0218922
I0526 07:17:03.240897 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0218923 (* 1 = 0.0218923 loss)
I0526 07:17:03.240916 15117 sgd_solver.cpp:294] Iteration 35530, lr = 0.002
I0526 07:17:09.581626 15117 solver.cpp:233] Iteration 35540, loss = 0.0398216
I0526 07:17:09.581668 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0398218 (* 1 = 0.0398218 loss)
I0526 07:17:09.581675 15117 sgd_solver.cpp:294] Iteration 35540, lr = 0.002
I0526 07:17:15.921627 15117 solver.cpp:233] Iteration 35550, loss = 0.0109475
I0526 07:17:15.921671 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0109476 (* 1 = 0.0109476 loss)
I0526 07:17:15.921679 15117 sgd_solver.cpp:294] Iteration 35550, lr = 0.002
I0526 07:17:22.262835 15117 solver.cpp:233] Iteration 35560, loss = 0.020339
I0526 07:17:22.263095 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0203391 (* 1 = 0.0203391 loss)
I0526 07:17:22.263134 15117 sgd_solver.cpp:294] Iteration 35560, lr = 0.002
I0526 07:17:28.601485 15117 solver.cpp:233] Iteration 35570, loss = 0.0169002
I0526 07:17:28.601526 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0169003 (* 1 = 0.0169003 loss)
I0526 07:17:28.601534 15117 sgd_solver.cpp:294] Iteration 35570, lr = 0.002
I0526 07:17:34.935845 15117 solver.cpp:233] Iteration 35580, loss = 0.0149154
I0526 07:17:34.935883 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0149156 (* 1 = 0.0149156 loss)
I0526 07:17:34.935891 15117 sgd_solver.cpp:294] Iteration 35580, lr = 0.002
I0526 07:17:41.276160 15117 solver.cpp:233] Iteration 35590, loss = 0.00811663
I0526 07:17:41.276199 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00811679 (* 1 = 0.00811679 loss)
I0526 07:17:41.276207 15117 sgd_solver.cpp:294] Iteration 35590, lr = 0.002
I0526 07:17:47.017205 15117 solver.cpp:342] Iteration 35600, Testing net (#0)
I0526 07:17:59.873531 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9001
I0526 07:17:59.873765 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.409878 (* 1 = 0.409878 loss)
I0526 07:18:00.477505 15117 solver.cpp:233] Iteration 35600, loss = 0.0513074
I0526 07:18:00.477550 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0513075 (* 1 = 0.0513075 loss)
I0526 07:18:00.477556 15117 sgd_solver.cpp:294] Iteration 35600, lr = 0.002
I0526 07:18:06.818213 15117 solver.cpp:233] Iteration 35610, loss = 0.0232506
I0526 07:18:06.818256 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0232507 (* 1 = 0.0232507 loss)
I0526 07:18:06.818264 15117 sgd_solver.cpp:294] Iteration 35610, lr = 0.002
I0526 07:18:13.162464 15117 solver.cpp:233] Iteration 35620, loss = 0.0291989
I0526 07:18:13.162513 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.029199 (* 1 = 0.029199 loss)
I0526 07:18:13.162519 15117 sgd_solver.cpp:294] Iteration 35620, lr = 0.002
I0526 07:18:19.506458 15117 solver.cpp:233] Iteration 35630, loss = 0.0354558
I0526 07:18:19.506510 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.035456 (* 1 = 0.035456 loss)
I0526 07:18:19.506518 15117 sgd_solver.cpp:294] Iteration 35630, lr = 0.002
I0526 07:18:25.848521 15117 solver.cpp:233] Iteration 35640, loss = 0.0246449
I0526 07:18:25.848567 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0246451 (* 1 = 0.0246451 loss)
I0526 07:18:25.848575 15117 sgd_solver.cpp:294] Iteration 35640, lr = 0.002
I0526 07:18:32.190230 15117 solver.cpp:233] Iteration 35650, loss = 0.0149491
I0526 07:18:32.190464 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0149493 (* 1 = 0.0149493 loss)
I0526 07:18:32.190491 15117 sgd_solver.cpp:294] Iteration 35650, lr = 0.002
I0526 07:18:38.526240 15117 solver.cpp:233] Iteration 35660, loss = 0.0250895
I0526 07:18:38.526286 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0250897 (* 1 = 0.0250897 loss)
I0526 07:18:38.526293 15117 sgd_solver.cpp:294] Iteration 35660, lr = 0.002
I0526 07:18:44.867041 15117 solver.cpp:233] Iteration 35670, loss = 0.0275695
I0526 07:18:44.867082 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0275697 (* 1 = 0.0275697 loss)
I0526 07:18:44.867089 15117 sgd_solver.cpp:294] Iteration 35670, lr = 0.002
I0526 07:18:51.212550 15117 solver.cpp:233] Iteration 35680, loss = 0.0257321
I0526 07:18:51.212604 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0257323 (* 1 = 0.0257323 loss)
I0526 07:18:51.212611 15117 sgd_solver.cpp:294] Iteration 35680, lr = 0.002
I0526 07:18:57.553195 15117 solver.cpp:233] Iteration 35690, loss = 0.0134852
I0526 07:18:57.553247 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0134854 (* 1 = 0.0134854 loss)
I0526 07:18:57.553254 15117 sgd_solver.cpp:294] Iteration 35690, lr = 0.002
I0526 07:19:03.293378 15117 solver.cpp:342] Iteration 35700, Testing net (#0)
I0526 07:19:16.144987 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9021
I0526 07:19:16.145038 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.404457 (* 1 = 0.404457 loss)
I0526 07:19:16.745908 15117 solver.cpp:233] Iteration 35700, loss = 0.0218903
I0526 07:19:16.745949 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0218905 (* 1 = 0.0218905 loss)
I0526 07:19:16.745957 15117 sgd_solver.cpp:294] Iteration 35700, lr = 0.002
I0526 07:19:23.091092 15117 solver.cpp:233] Iteration 35710, loss = 0.00747041
I0526 07:19:23.091135 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00747059 (* 1 = 0.00747059 loss)
I0526 07:19:23.091142 15117 sgd_solver.cpp:294] Iteration 35710, lr = 0.002
I0526 07:19:29.434053 15117 solver.cpp:233] Iteration 35720, loss = 0.0156267
I0526 07:19:29.434095 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0156269 (* 1 = 0.0156269 loss)
I0526 07:19:29.434103 15117 sgd_solver.cpp:294] Iteration 35720, lr = 0.002
I0526 07:19:35.775102 15117 solver.cpp:233] Iteration 35730, loss = 0.0145436
I0526 07:19:35.775339 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0145437 (* 1 = 0.0145437 loss)
I0526 07:19:35.775372 15117 sgd_solver.cpp:294] Iteration 35730, lr = 0.002
I0526 07:19:42.108815 15117 solver.cpp:233] Iteration 35740, loss = 0.025346
I0526 07:19:42.108858 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0253462 (* 1 = 0.0253462 loss)
I0526 07:19:42.108865 15117 sgd_solver.cpp:294] Iteration 35740, lr = 0.002
I0526 07:19:48.443096 15117 solver.cpp:233] Iteration 35750, loss = 0.0310124
I0526 07:19:48.443125 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0310126 (* 1 = 0.0310126 loss)
I0526 07:19:48.443132 15117 sgd_solver.cpp:294] Iteration 35750, lr = 0.002
I0526 07:19:54.787989 15117 solver.cpp:233] Iteration 35760, loss = 0.040589
I0526 07:19:54.788038 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0405892 (* 1 = 0.0405892 loss)
I0526 07:19:54.788045 15117 sgd_solver.cpp:294] Iteration 35760, lr = 0.002
I0526 07:20:01.134246 15117 solver.cpp:233] Iteration 35770, loss = 0.0179113
I0526 07:20:01.134285 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0179115 (* 1 = 0.0179115 loss)
I0526 07:20:01.134292 15117 sgd_solver.cpp:294] Iteration 35770, lr = 0.002
I0526 07:20:07.479898 15117 solver.cpp:233] Iteration 35780, loss = 0.0168905
I0526 07:20:07.480141 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0168906 (* 1 = 0.0168906 loss)
I0526 07:20:07.480178 15117 sgd_solver.cpp:294] Iteration 35780, lr = 0.002
I0526 07:20:13.824427 15117 solver.cpp:233] Iteration 35790, loss = 0.0204545
I0526 07:20:13.824470 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0204547 (* 1 = 0.0204547 loss)
I0526 07:20:13.824478 15117 sgd_solver.cpp:294] Iteration 35790, lr = 0.002
I0526 07:20:19.564594 15117 solver.cpp:342] Iteration 35800, Testing net (#0)
I0526 07:20:32.412106 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9034
I0526 07:20:32.412155 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.392655 (* 1 = 0.392655 loss)
I0526 07:20:33.014130 15117 solver.cpp:233] Iteration 35800, loss = 0.0170054
I0526 07:20:33.014170 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0170056 (* 1 = 0.0170056 loss)
I0526 07:20:33.014189 15117 sgd_solver.cpp:294] Iteration 35800, lr = 0.002
I0526 07:20:39.356712 15117 solver.cpp:233] Iteration 35810, loss = 0.0141068
I0526 07:20:39.356956 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.014107 (* 1 = 0.014107 loss)
I0526 07:20:39.356984 15117 sgd_solver.cpp:294] Iteration 35810, lr = 0.002
I0526 07:20:45.683707 15117 solver.cpp:233] Iteration 35820, loss = 0.0399632
I0526 07:20:45.683753 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0399634 (* 1 = 0.0399634 loss)
I0526 07:20:45.683761 15117 sgd_solver.cpp:294] Iteration 35820, lr = 0.002
I0526 07:20:52.021852 15117 solver.cpp:233] Iteration 35830, loss = 0.00860204
I0526 07:20:52.021908 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00860221 (* 1 = 0.00860221 loss)
I0526 07:20:52.021915 15117 sgd_solver.cpp:294] Iteration 35830, lr = 0.002
I0526 07:20:58.367012 15117 solver.cpp:233] Iteration 35840, loss = 0.0398714
I0526 07:20:58.367054 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0398716 (* 1 = 0.0398716 loss)
I0526 07:20:58.367061 15117 sgd_solver.cpp:294] Iteration 35840, lr = 0.002
I0526 07:21:04.715637 15117 solver.cpp:233] Iteration 35850, loss = 0.0235067
I0526 07:21:04.715677 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0235068 (* 1 = 0.0235068 loss)
I0526 07:21:04.715684 15117 sgd_solver.cpp:294] Iteration 35850, lr = 0.002
I0526 07:21:11.055955 15117 solver.cpp:233] Iteration 35860, loss = 0.0308263
I0526 07:21:11.056219 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0308265 (* 1 = 0.0308265 loss)
I0526 07:21:11.056248 15117 sgd_solver.cpp:294] Iteration 35860, lr = 0.002
I0526 07:21:17.376842 15117 solver.cpp:233] Iteration 35870, loss = 0.0325253
I0526 07:21:17.376884 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0325254 (* 1 = 0.0325254 loss)
I0526 07:21:17.376891 15117 sgd_solver.cpp:294] Iteration 35870, lr = 0.002
I0526 07:21:23.696713 15117 solver.cpp:233] Iteration 35880, loss = 0.0112029
I0526 07:21:23.696756 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.011203 (* 1 = 0.011203 loss)
I0526 07:21:23.696764 15117 sgd_solver.cpp:294] Iteration 35880, lr = 0.002
I0526 07:21:30.017035 15117 solver.cpp:233] Iteration 35890, loss = 0.0153142
I0526 07:21:30.017077 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0153144 (* 1 = 0.0153144 loss)
I0526 07:21:30.017084 15117 sgd_solver.cpp:294] Iteration 35890, lr = 0.002
I0526 07:21:35.737553 15117 solver.cpp:342] Iteration 35900, Testing net (#0)
I0526 07:21:48.560598 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9013
I0526 07:21:48.560813 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.416711 (* 1 = 0.416711 loss)
I0526 07:21:49.160840 15117 solver.cpp:233] Iteration 35900, loss = 0.0156193
I0526 07:21:49.160900 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0156195 (* 1 = 0.0156195 loss)
I0526 07:21:49.160912 15117 sgd_solver.cpp:294] Iteration 35900, lr = 0.002
I0526 07:21:55.445179 15117 solver.cpp:233] Iteration 35910, loss = 0.0216837
I0526 07:21:55.445225 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0216839 (* 1 = 0.0216839 loss)
I0526 07:21:55.445235 15117 sgd_solver.cpp:294] Iteration 35910, lr = 0.002
I0526 07:22:01.734644 15117 solver.cpp:233] Iteration 35920, loss = 0.0170191
I0526 07:22:01.734696 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0170193 (* 1 = 0.0170193 loss)
I0526 07:22:01.734704 15117 sgd_solver.cpp:294] Iteration 35920, lr = 0.002
I0526 07:22:08.019804 15117 solver.cpp:233] Iteration 35930, loss = 0.0336658
I0526 07:22:08.019845 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.033666 (* 1 = 0.033666 loss)
I0526 07:22:08.019852 15117 sgd_solver.cpp:294] Iteration 35930, lr = 0.002
I0526 07:22:14.309172 15117 solver.cpp:233] Iteration 35940, loss = 0.0323699
I0526 07:22:14.309212 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0323701 (* 1 = 0.0323701 loss)
I0526 07:22:14.309219 15117 sgd_solver.cpp:294] Iteration 35940, lr = 0.002
I0526 07:22:20.597179 15117 solver.cpp:233] Iteration 35950, loss = 0.0116615
I0526 07:22:20.597401 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0116617 (* 1 = 0.0116617 loss)
I0526 07:22:20.597427 15117 sgd_solver.cpp:294] Iteration 35950, lr = 0.002
I0526 07:22:26.889659 15117 solver.cpp:233] Iteration 35960, loss = 0.0282601
I0526 07:22:26.889704 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0282603 (* 1 = 0.0282603 loss)
I0526 07:22:26.889711 15117 sgd_solver.cpp:294] Iteration 35960, lr = 0.002
I0526 07:22:33.179289 15117 solver.cpp:233] Iteration 35970, loss = 0.0290537
I0526 07:22:33.179337 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0290539 (* 1 = 0.0290539 loss)
I0526 07:22:33.179343 15117 sgd_solver.cpp:294] Iteration 35970, lr = 0.002
I0526 07:22:39.471037 15117 solver.cpp:233] Iteration 35980, loss = 0.012598
I0526 07:22:39.471081 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0125982 (* 1 = 0.0125982 loss)
I0526 07:22:39.471088 15117 sgd_solver.cpp:294] Iteration 35980, lr = 0.002
I0526 07:22:45.760081 15117 solver.cpp:233] Iteration 35990, loss = 0.0541889
I0526 07:22:45.760121 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0541891 (* 1 = 0.0541891 loss)
I0526 07:22:45.760128 15117 sgd_solver.cpp:294] Iteration 35990, lr = 0.002
I0526 07:22:51.454671 15117 solver.cpp:342] Iteration 36000, Testing net (#0)
I0526 07:23:04.245465 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.901
I0526 07:23:04.245509 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.422747 (* 1 = 0.422747 loss)
I0526 07:23:04.842258 15117 solver.cpp:233] Iteration 36000, loss = 0.0464227
I0526 07:23:04.842298 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0464229 (* 1 = 0.0464229 loss)
I0526 07:23:04.842304 15117 sgd_solver.cpp:294] Iteration 36000, lr = 0.002
I0526 07:23:11.134799 15117 solver.cpp:233] Iteration 36010, loss = 0.0208491
I0526 07:23:11.134829 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0208492 (* 1 = 0.0208492 loss)
I0526 07:23:11.134836 15117 sgd_solver.cpp:294] Iteration 36010, lr = 0.002
I0526 07:23:17.426390 15117 solver.cpp:233] Iteration 36020, loss = 0.0133413
I0526 07:23:17.426435 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0133415 (* 1 = 0.0133415 loss)
I0526 07:23:17.426443 15117 sgd_solver.cpp:294] Iteration 36020, lr = 0.002
I0526 07:23:23.718117 15117 solver.cpp:233] Iteration 36030, loss = 0.0194016
I0526 07:23:23.718341 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0194018 (* 1 = 0.0194018 loss)
I0526 07:23:23.718399 15117 sgd_solver.cpp:294] Iteration 36030, lr = 0.002
I0526 07:23:30.013650 15117 solver.cpp:233] Iteration 36040, loss = 0.0140619
I0526 07:23:30.013695 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0140621 (* 1 = 0.0140621 loss)
I0526 07:23:30.013702 15117 sgd_solver.cpp:294] Iteration 36040, lr = 0.002
I0526 07:23:36.300165 15117 solver.cpp:233] Iteration 36050, loss = 0.0104605
I0526 07:23:36.300210 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0104606 (* 1 = 0.0104606 loss)
I0526 07:23:36.300217 15117 sgd_solver.cpp:294] Iteration 36050, lr = 0.002
I0526 07:23:42.593024 15117 solver.cpp:233] Iteration 36060, loss = 0.0136694
I0526 07:23:42.593056 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0136696 (* 1 = 0.0136696 loss)
I0526 07:23:42.593063 15117 sgd_solver.cpp:294] Iteration 36060, lr = 0.002
I0526 07:23:48.882639 15117 solver.cpp:233] Iteration 36070, loss = 0.0236049
I0526 07:23:48.882693 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0236051 (* 1 = 0.0236051 loss)
I0526 07:23:48.882699 15117 sgd_solver.cpp:294] Iteration 36070, lr = 0.002
I0526 07:23:55.169155 15117 solver.cpp:233] Iteration 36080, loss = 0.0224666
I0526 07:23:55.169381 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0224668 (* 1 = 0.0224668 loss)
I0526 07:23:55.169410 15117 sgd_solver.cpp:294] Iteration 36080, lr = 0.002
I0526 07:24:01.460391 15117 solver.cpp:233] Iteration 36090, loss = 0.0191008
I0526 07:24:01.460438 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.019101 (* 1 = 0.019101 loss)
I0526 07:24:01.460448 15117 sgd_solver.cpp:294] Iteration 36090, lr = 0.002
I0526 07:24:07.150171 15117 solver.cpp:342] Iteration 36100, Testing net (#0)
I0526 07:24:19.938006 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9036
I0526 07:24:19.938042 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.403817 (* 1 = 0.403817 loss)
I0526 07:24:20.535931 15117 solver.cpp:233] Iteration 36100, loss = 0.01564
I0526 07:24:20.535969 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0156402 (* 1 = 0.0156402 loss)
I0526 07:24:20.535975 15117 sgd_solver.cpp:294] Iteration 36100, lr = 0.002
I0526 07:24:26.823113 15117 solver.cpp:233] Iteration 36110, loss = 0.0127065
I0526 07:24:26.823387 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0127067 (* 1 = 0.0127067 loss)
I0526 07:24:26.823415 15117 sgd_solver.cpp:294] Iteration 36110, lr = 0.002
I0526 07:24:33.113612 15117 solver.cpp:233] Iteration 36120, loss = 0.0184805
I0526 07:24:33.113652 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0184807 (* 1 = 0.0184807 loss)
I0526 07:24:33.113659 15117 sgd_solver.cpp:294] Iteration 36120, lr = 0.002
I0526 07:24:39.401463 15117 solver.cpp:233] Iteration 36130, loss = 0.0326954
I0526 07:24:39.401502 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0326956 (* 1 = 0.0326956 loss)
I0526 07:24:39.401510 15117 sgd_solver.cpp:294] Iteration 36130, lr = 0.002
I0526 07:24:45.690652 15117 solver.cpp:233] Iteration 36140, loss = 0.00771187
I0526 07:24:45.690708 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00771204 (* 1 = 0.00771204 loss)
I0526 07:24:45.690716 15117 sgd_solver.cpp:294] Iteration 36140, lr = 0.002
I0526 07:24:51.979795 15117 solver.cpp:233] Iteration 36150, loss = 0.0219971
I0526 07:24:51.979838 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0219972 (* 1 = 0.0219972 loss)
I0526 07:24:51.979845 15117 sgd_solver.cpp:294] Iteration 36150, lr = 0.002
I0526 07:24:58.266942 15117 solver.cpp:233] Iteration 36160, loss = 0.0407831
I0526 07:24:58.267175 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0407832 (* 1 = 0.0407832 loss)
I0526 07:24:58.267205 15117 sgd_solver.cpp:294] Iteration 36160, lr = 0.002
I0526 07:25:04.554446 15117 solver.cpp:233] Iteration 36170, loss = 0.0250184
I0526 07:25:04.554489 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0250185 (* 1 = 0.0250185 loss)
I0526 07:25:04.554497 15117 sgd_solver.cpp:294] Iteration 36170, lr = 0.002
I0526 07:25:10.843966 15117 solver.cpp:233] Iteration 36180, loss = 0.0267718
I0526 07:25:10.844009 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.026772 (* 1 = 0.026772 loss)
I0526 07:25:10.844017 15117 sgd_solver.cpp:294] Iteration 36180, lr = 0.002
I0526 07:25:17.133029 15117 solver.cpp:233] Iteration 36190, loss = 0.0230842
I0526 07:25:17.133070 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0230844 (* 1 = 0.0230844 loss)
I0526 07:25:17.133077 15117 sgd_solver.cpp:294] Iteration 36190, lr = 0.002
I0526 07:25:22.828186 15117 solver.cpp:342] Iteration 36200, Testing net (#0)
I0526 07:25:35.609832 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9032
I0526 07:25:35.610059 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.400125 (* 1 = 0.400125 loss)
I0526 07:25:36.207660 15117 solver.cpp:233] Iteration 36200, loss = 0.0336425
I0526 07:25:36.207707 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0336427 (* 1 = 0.0336427 loss)
I0526 07:25:36.207715 15117 sgd_solver.cpp:294] Iteration 36200, lr = 0.002
I0526 07:25:42.499948 15117 solver.cpp:233] Iteration 36210, loss = 0.0163562
I0526 07:25:42.499990 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0163564 (* 1 = 0.0163564 loss)
I0526 07:25:42.499997 15117 sgd_solver.cpp:294] Iteration 36210, lr = 0.002
I0526 07:25:48.789482 15117 solver.cpp:233] Iteration 36220, loss = 0.0145337
I0526 07:25:48.789526 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0145339 (* 1 = 0.0145339 loss)
I0526 07:25:48.789533 15117 sgd_solver.cpp:294] Iteration 36220, lr = 0.002
I0526 07:25:55.079473 15117 solver.cpp:233] Iteration 36230, loss = 0.0291742
I0526 07:25:55.079514 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0291744 (* 1 = 0.0291744 loss)
I0526 07:25:55.079520 15117 sgd_solver.cpp:294] Iteration 36230, lr = 0.002
I0526 07:26:01.364392 15117 solver.cpp:233] Iteration 36240, loss = 0.0171372
I0526 07:26:01.364436 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0171373 (* 1 = 0.0171373 loss)
I0526 07:26:01.364444 15117 sgd_solver.cpp:294] Iteration 36240, lr = 0.002
I0526 07:26:07.652310 15117 solver.cpp:233] Iteration 36250, loss = 0.0186704
I0526 07:26:07.652530 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0186706 (* 1 = 0.0186706 loss)
I0526 07:26:07.652559 15117 sgd_solver.cpp:294] Iteration 36250, lr = 0.002
I0526 07:26:13.938100 15117 solver.cpp:233] Iteration 36260, loss = 0.00931532
I0526 07:26:13.938151 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00931548 (* 1 = 0.00931548 loss)
I0526 07:26:13.938159 15117 sgd_solver.cpp:294] Iteration 36260, lr = 0.002
I0526 07:26:20.222144 15117 solver.cpp:233] Iteration 36270, loss = 0.00715722
I0526 07:26:20.222188 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00715737 (* 1 = 0.00715737 loss)
I0526 07:26:20.222196 15117 sgd_solver.cpp:294] Iteration 36270, lr = 0.002
I0526 07:26:26.510995 15117 solver.cpp:233] Iteration 36280, loss = 0.0403609
I0526 07:26:26.511035 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.040361 (* 1 = 0.040361 loss)
I0526 07:26:26.511044 15117 sgd_solver.cpp:294] Iteration 36280, lr = 0.002
I0526 07:26:32.798737 15117 solver.cpp:233] Iteration 36290, loss = 0.0346594
I0526 07:26:32.798775 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0346595 (* 1 = 0.0346595 loss)
I0526 07:26:32.798782 15117 sgd_solver.cpp:294] Iteration 36290, lr = 0.002
I0526 07:26:38.491019 15117 solver.cpp:342] Iteration 36300, Testing net (#0)
I0526 07:26:51.282335 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9032
I0526 07:26:51.282395 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.418023 (* 1 = 0.418023 loss)
I0526 07:26:51.879225 15117 solver.cpp:233] Iteration 36300, loss = 0.0356891
I0526 07:26:51.879261 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0356893 (* 1 = 0.0356893 loss)
I0526 07:26:51.879267 15117 sgd_solver.cpp:294] Iteration 36300, lr = 0.002
I0526 07:26:58.166565 15117 solver.cpp:233] Iteration 36310, loss = 0.0338404
I0526 07:26:58.166606 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0338405 (* 1 = 0.0338405 loss)
I0526 07:26:58.166615 15117 sgd_solver.cpp:294] Iteration 36310, lr = 0.002
I0526 07:27:04.453830 15117 solver.cpp:233] Iteration 36320, loss = 0.0390336
I0526 07:27:04.453872 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0390338 (* 1 = 0.0390338 loss)
I0526 07:27:04.453881 15117 sgd_solver.cpp:294] Iteration 36320, lr = 0.002
I0526 07:27:10.741211 15117 solver.cpp:233] Iteration 36330, loss = 0.016474
I0526 07:27:10.741441 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0164742 (* 1 = 0.0164742 loss)
I0526 07:27:10.741471 15117 sgd_solver.cpp:294] Iteration 36330, lr = 0.002
I0526 07:27:17.022493 15117 solver.cpp:233] Iteration 36340, loss = 0.0304507
I0526 07:27:17.022538 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0304509 (* 1 = 0.0304509 loss)
I0526 07:27:17.022546 15117 sgd_solver.cpp:294] Iteration 36340, lr = 0.002
I0526 07:27:23.310678 15117 solver.cpp:233] Iteration 36350, loss = 0.0303818
I0526 07:27:23.310736 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.030382 (* 1 = 0.030382 loss)
I0526 07:27:23.310744 15117 sgd_solver.cpp:294] Iteration 36350, lr = 0.002
I0526 07:27:29.598803 15117 solver.cpp:233] Iteration 36360, loss = 0.0301617
I0526 07:27:29.598846 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0301619 (* 1 = 0.0301619 loss)
I0526 07:27:29.598855 15117 sgd_solver.cpp:294] Iteration 36360, lr = 0.002
I0526 07:27:35.885565 15117 solver.cpp:233] Iteration 36370, loss = 0.0298822
I0526 07:27:35.885607 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0298823 (* 1 = 0.0298823 loss)
I0526 07:27:35.885620 15117 sgd_solver.cpp:294] Iteration 36370, lr = 0.002
I0526 07:27:42.171612 15117 solver.cpp:233] Iteration 36380, loss = 0.0281151
I0526 07:27:42.171870 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0281153 (* 1 = 0.0281153 loss)
I0526 07:27:42.171896 15117 sgd_solver.cpp:294] Iteration 36380, lr = 0.002
I0526 07:27:48.462193 15117 solver.cpp:233] Iteration 36390, loss = 0.0332537
I0526 07:27:48.462232 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0332539 (* 1 = 0.0332539 loss)
I0526 07:27:48.462239 15117 sgd_solver.cpp:294] Iteration 36390, lr = 0.002
I0526 07:27:54.155105 15117 solver.cpp:342] Iteration 36400, Testing net (#0)
I0526 07:28:06.941869 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9018
I0526 07:28:06.941915 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.407452 (* 1 = 0.407452 loss)
I0526 07:28:07.538962 15117 solver.cpp:233] Iteration 36400, loss = 0.0203927
I0526 07:28:07.539003 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0203929 (* 1 = 0.0203929 loss)
I0526 07:28:07.539011 15117 sgd_solver.cpp:294] Iteration 36400, lr = 0.002
I0526 07:28:13.827343 15117 solver.cpp:233] Iteration 36410, loss = 0.0418181
I0526 07:28:13.827566 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0418182 (* 1 = 0.0418182 loss)
I0526 07:28:13.827596 15117 sgd_solver.cpp:294] Iteration 36410, lr = 0.002
I0526 07:28:20.112426 15117 solver.cpp:233] Iteration 36420, loss = 0.0192104
I0526 07:28:20.112469 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0192106 (* 1 = 0.0192106 loss)
I0526 07:28:20.112476 15117 sgd_solver.cpp:294] Iteration 36420, lr = 0.002
I0526 07:28:26.400368 15117 solver.cpp:233] Iteration 36430, loss = 0.0257721
I0526 07:28:26.400410 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0257723 (* 1 = 0.0257723 loss)
I0526 07:28:26.400418 15117 sgd_solver.cpp:294] Iteration 36430, lr = 0.002
I0526 07:28:32.688120 15117 solver.cpp:233] Iteration 36440, loss = 0.0219515
I0526 07:28:32.688172 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0219517 (* 1 = 0.0219517 loss)
I0526 07:28:32.688179 15117 sgd_solver.cpp:294] Iteration 36440, lr = 0.002
I0526 07:28:38.979867 15117 solver.cpp:233] Iteration 36450, loss = 0.0121408
I0526 07:28:38.979907 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.012141 (* 1 = 0.012141 loss)
I0526 07:28:38.979914 15117 sgd_solver.cpp:294] Iteration 36450, lr = 0.002
I0526 07:28:45.274220 15117 solver.cpp:233] Iteration 36460, loss = 0.0250157
I0526 07:28:45.274461 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0250159 (* 1 = 0.0250159 loss)
I0526 07:28:45.274489 15117 sgd_solver.cpp:294] Iteration 36460, lr = 0.002
I0526 07:28:51.565762 15117 solver.cpp:233] Iteration 36470, loss = 0.0182238
I0526 07:28:51.565805 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0182239 (* 1 = 0.0182239 loss)
I0526 07:28:51.565812 15117 sgd_solver.cpp:294] Iteration 36470, lr = 0.002
I0526 07:28:57.852599 15117 solver.cpp:233] Iteration 36480, loss = 0.0121834
I0526 07:28:57.852638 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0121836 (* 1 = 0.0121836 loss)
I0526 07:28:57.852644 15117 sgd_solver.cpp:294] Iteration 36480, lr = 0.002
I0526 07:29:04.143381 15117 solver.cpp:233] Iteration 36490, loss = 0.00800302
I0526 07:29:04.143420 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00800318 (* 1 = 0.00800318 loss)
I0526 07:29:04.143429 15117 sgd_solver.cpp:294] Iteration 36490, lr = 0.002
I0526 07:29:09.836700 15117 solver.cpp:342] Iteration 36500, Testing net (#0)
I0526 07:29:22.613809 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9016
I0526 07:29:22.614040 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.414643 (* 1 = 0.414643 loss)
I0526 07:29:23.210539 15117 solver.cpp:233] Iteration 36500, loss = 0.0215503
I0526 07:29:23.210592 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0215505 (* 1 = 0.0215505 loss)
I0526 07:29:23.210604 15117 sgd_solver.cpp:294] Iteration 36500, lr = 0.002
I0526 07:29:29.500855 15117 solver.cpp:233] Iteration 36510, loss = 0.0421758
I0526 07:29:29.500895 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0421759 (* 1 = 0.0421759 loss)
I0526 07:29:29.500902 15117 sgd_solver.cpp:294] Iteration 36510, lr = 0.002
I0526 07:29:35.788691 15117 solver.cpp:233] Iteration 36520, loss = 0.025147
I0526 07:29:35.788735 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0251472 (* 1 = 0.0251472 loss)
I0526 07:29:35.788741 15117 sgd_solver.cpp:294] Iteration 36520, lr = 0.002
I0526 07:29:42.078102 15117 solver.cpp:233] Iteration 36530, loss = 0.0109925
I0526 07:29:42.078130 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0109927 (* 1 = 0.0109927 loss)
I0526 07:29:42.078136 15117 sgd_solver.cpp:294] Iteration 36530, lr = 0.002
I0526 07:29:48.366644 15117 solver.cpp:233] Iteration 36540, loss = 0.0180161
I0526 07:29:48.366683 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0180163 (* 1 = 0.0180163 loss)
I0526 07:29:48.366689 15117 sgd_solver.cpp:294] Iteration 36540, lr = 0.002
I0526 07:29:54.656651 15117 solver.cpp:233] Iteration 36550, loss = 0.0197788
I0526 07:29:54.656918 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.019779 (* 1 = 0.019779 loss)
I0526 07:29:54.656946 15117 sgd_solver.cpp:294] Iteration 36550, lr = 0.002
I0526 07:30:00.952064 15117 solver.cpp:233] Iteration 36560, loss = 0.0193483
I0526 07:30:00.952105 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0193484 (* 1 = 0.0193484 loss)
I0526 07:30:00.952113 15117 sgd_solver.cpp:294] Iteration 36560, lr = 0.002
I0526 07:30:07.240902 15117 solver.cpp:233] Iteration 36570, loss = 0.0263827
I0526 07:30:07.240934 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0263829 (* 1 = 0.0263829 loss)
I0526 07:30:07.240942 15117 sgd_solver.cpp:294] Iteration 36570, lr = 0.002
I0526 07:30:13.531666 15117 solver.cpp:233] Iteration 36580, loss = 0.0506539
I0526 07:30:13.531708 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0506541 (* 1 = 0.0506541 loss)
I0526 07:30:13.531715 15117 sgd_solver.cpp:294] Iteration 36580, lr = 0.002
I0526 07:30:19.819061 15117 solver.cpp:233] Iteration 36590, loss = 0.0233789
I0526 07:30:19.819108 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0233791 (* 1 = 0.0233791 loss)
I0526 07:30:19.819115 15117 sgd_solver.cpp:294] Iteration 36590, lr = 0.002
I0526 07:30:25.510334 15117 solver.cpp:342] Iteration 36600, Testing net (#0)
I0526 07:30:38.297009 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9041
I0526 07:30:38.297055 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.396595 (* 1 = 0.396595 loss)
I0526 07:30:38.894876 15117 solver.cpp:233] Iteration 36600, loss = 0.014816
I0526 07:30:38.894911 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0148161 (* 1 = 0.0148161 loss)
I0526 07:30:38.894917 15117 sgd_solver.cpp:294] Iteration 36600, lr = 0.002
I0526 07:30:45.183452 15117 solver.cpp:233] Iteration 36610, loss = 0.0176873
I0526 07:30:45.183492 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0176874 (* 1 = 0.0176874 loss)
I0526 07:30:45.183500 15117 sgd_solver.cpp:294] Iteration 36610, lr = 0.002
I0526 07:30:51.466742 15117 solver.cpp:233] Iteration 36620, loss = 0.0333005
I0526 07:30:51.466786 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0333007 (* 1 = 0.0333007 loss)
I0526 07:30:51.466794 15117 sgd_solver.cpp:294] Iteration 36620, lr = 0.002
I0526 07:30:57.756135 15117 solver.cpp:233] Iteration 36630, loss = 0.011312
I0526 07:30:57.756325 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0113122 (* 1 = 0.0113122 loss)
I0526 07:30:57.756355 15117 sgd_solver.cpp:294] Iteration 36630, lr = 0.002
I0526 07:31:04.046537 15117 solver.cpp:233] Iteration 36640, loss = 0.0191801
I0526 07:31:04.046578 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0191803 (* 1 = 0.0191803 loss)
I0526 07:31:04.046592 15117 sgd_solver.cpp:294] Iteration 36640, lr = 0.002
I0526 07:31:10.335947 15117 solver.cpp:233] Iteration 36650, loss = 0.0200171
I0526 07:31:10.335979 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0200173 (* 1 = 0.0200173 loss)
I0526 07:31:10.335985 15117 sgd_solver.cpp:294] Iteration 36650, lr = 0.002
I0526 07:31:16.624166 15117 solver.cpp:233] Iteration 36660, loss = 0.0172931
I0526 07:31:16.624212 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0172932 (* 1 = 0.0172932 loss)
I0526 07:31:16.624219 15117 sgd_solver.cpp:294] Iteration 36660, lr = 0.002
I0526 07:31:22.908511 15117 solver.cpp:233] Iteration 36670, loss = 0.0281082
I0526 07:31:22.908555 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0281084 (* 1 = 0.0281084 loss)
I0526 07:31:22.908563 15117 sgd_solver.cpp:294] Iteration 36670, lr = 0.002
I0526 07:31:29.198707 15117 solver.cpp:233] Iteration 36680, loss = 0.0179354
I0526 07:31:29.198963 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0179355 (* 1 = 0.0179355 loss)
I0526 07:31:29.198992 15117 sgd_solver.cpp:294] Iteration 36680, lr = 0.002
I0526 07:31:35.489590 15117 solver.cpp:233] Iteration 36690, loss = 0.0312782
I0526 07:31:35.489637 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0312784 (* 1 = 0.0312784 loss)
I0526 07:31:35.489645 15117 sgd_solver.cpp:294] Iteration 36690, lr = 0.002
I0526 07:31:41.184370 15117 solver.cpp:342] Iteration 36700, Testing net (#0)
I0526 07:31:53.964334 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9022
I0526 07:31:53.964391 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.414197 (* 1 = 0.414197 loss)
I0526 07:31:54.562398 15117 solver.cpp:233] Iteration 36700, loss = 0.0262464
I0526 07:31:54.562424 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0262466 (* 1 = 0.0262466 loss)
I0526 07:31:54.562432 15117 sgd_solver.cpp:294] Iteration 36700, lr = 0.002
I0526 07:32:00.854578 15117 solver.cpp:233] Iteration 36710, loss = 0.0057492
I0526 07:32:00.854814 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00574936 (* 1 = 0.00574936 loss)
I0526 07:32:00.854849 15117 sgd_solver.cpp:294] Iteration 36710, lr = 0.002
I0526 07:32:07.146860 15117 solver.cpp:233] Iteration 36720, loss = 0.0415096
I0526 07:32:07.146898 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0415097 (* 1 = 0.0415097 loss)
I0526 07:32:07.146905 15117 sgd_solver.cpp:294] Iteration 36720, lr = 0.002
I0526 07:32:13.439479 15117 solver.cpp:233] Iteration 36730, loss = 0.0330222
I0526 07:32:13.439518 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0330224 (* 1 = 0.0330224 loss)
I0526 07:32:13.439527 15117 sgd_solver.cpp:294] Iteration 36730, lr = 0.002
I0526 07:32:19.730047 15117 solver.cpp:233] Iteration 36740, loss = 0.0219056
I0526 07:32:19.730079 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0219058 (* 1 = 0.0219058 loss)
I0526 07:32:19.730087 15117 sgd_solver.cpp:294] Iteration 36740, lr = 0.002
I0526 07:32:26.014143 15117 solver.cpp:233] Iteration 36750, loss = 0.0154969
I0526 07:32:26.014184 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0154971 (* 1 = 0.0154971 loss)
I0526 07:32:26.014192 15117 sgd_solver.cpp:294] Iteration 36750, lr = 0.002
I0526 07:32:32.297654 15117 solver.cpp:233] Iteration 36760, loss = 0.0175157
I0526 07:32:32.297839 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0175158 (* 1 = 0.0175158 loss)
I0526 07:32:32.297868 15117 sgd_solver.cpp:294] Iteration 36760, lr = 0.002
I0526 07:32:38.589860 15117 solver.cpp:233] Iteration 36770, loss = 0.0139395
I0526 07:32:38.589897 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0139396 (* 1 = 0.0139396 loss)
I0526 07:32:38.589905 15117 sgd_solver.cpp:294] Iteration 36770, lr = 0.002
I0526 07:32:44.877039 15117 solver.cpp:233] Iteration 36780, loss = 0.0453506
I0526 07:32:44.877090 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0453507 (* 1 = 0.0453507 loss)
I0526 07:32:44.877099 15117 sgd_solver.cpp:294] Iteration 36780, lr = 0.002
I0526 07:32:51.166503 15117 solver.cpp:233] Iteration 36790, loss = 0.0445021
I0526 07:32:51.166545 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0445023 (* 1 = 0.0445023 loss)
I0526 07:32:51.166553 15117 sgd_solver.cpp:294] Iteration 36790, lr = 0.002
I0526 07:32:56.857156 15117 solver.cpp:342] Iteration 36800, Testing net (#0)
I0526 07:33:09.640743 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9043
I0526 07:33:09.640974 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.407034 (* 1 = 0.407034 loss)
I0526 07:33:10.237316 15117 solver.cpp:233] Iteration 36800, loss = 0.0258873
I0526 07:33:10.237352 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0258874 (* 1 = 0.0258874 loss)
I0526 07:33:10.237360 15117 sgd_solver.cpp:294] Iteration 36800, lr = 0.002
I0526 07:33:16.526746 15117 solver.cpp:233] Iteration 36810, loss = 0.0500853
I0526 07:33:16.526787 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0500855 (* 1 = 0.0500855 loss)
I0526 07:33:16.526795 15117 sgd_solver.cpp:294] Iteration 36810, lr = 0.002
I0526 07:33:22.813585 15117 solver.cpp:233] Iteration 36820, loss = 0.0111433
I0526 07:33:22.813623 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0111435 (* 1 = 0.0111435 loss)
I0526 07:33:22.813632 15117 sgd_solver.cpp:294] Iteration 36820, lr = 0.002
I0526 07:33:29.096339 15117 solver.cpp:233] Iteration 36830, loss = 0.0114546
I0526 07:33:29.096382 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0114548 (* 1 = 0.0114548 loss)
I0526 07:33:29.096390 15117 sgd_solver.cpp:294] Iteration 36830, lr = 0.002
I0526 07:33:35.382762 15117 solver.cpp:233] Iteration 36840, loss = 0.00840245
I0526 07:33:35.382803 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00840261 (* 1 = 0.00840261 loss)
I0526 07:33:35.382810 15117 sgd_solver.cpp:294] Iteration 36840, lr = 0.002
I0526 07:33:41.669845 15117 solver.cpp:233] Iteration 36850, loss = 0.0288956
I0526 07:33:41.670038 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0288958 (* 1 = 0.0288958 loss)
I0526 07:33:41.670068 15117 sgd_solver.cpp:294] Iteration 36850, lr = 0.002
I0526 07:33:47.956835 15117 solver.cpp:233] Iteration 36860, loss = 0.0146971
I0526 07:33:47.956878 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0146972 (* 1 = 0.0146972 loss)
I0526 07:33:47.956885 15117 sgd_solver.cpp:294] Iteration 36860, lr = 0.002
I0526 07:33:54.246184 15117 solver.cpp:233] Iteration 36870, loss = 0.0134024
I0526 07:33:54.246224 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0134026 (* 1 = 0.0134026 loss)
I0526 07:33:54.246232 15117 sgd_solver.cpp:294] Iteration 36870, lr = 0.002
I0526 07:34:00.535744 15117 solver.cpp:233] Iteration 36880, loss = 0.0127649
I0526 07:34:00.535789 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0127651 (* 1 = 0.0127651 loss)
I0526 07:34:00.535795 15117 sgd_solver.cpp:294] Iteration 36880, lr = 0.002
I0526 07:34:06.826400 15117 solver.cpp:233] Iteration 36890, loss = 0.0211496
I0526 07:34:06.826443 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0211497 (* 1 = 0.0211497 loss)
I0526 07:34:06.826450 15117 sgd_solver.cpp:294] Iteration 36890, lr = 0.002
I0526 07:34:12.519870 15117 solver.cpp:342] Iteration 36900, Testing net (#0)
I0526 07:34:25.298933 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9033
I0526 07:34:25.298982 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.421984 (* 1 = 0.421984 loss)
I0526 07:34:25.896417 15117 solver.cpp:233] Iteration 36900, loss = 0.0144783
I0526 07:34:25.896453 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0144785 (* 1 = 0.0144785 loss)
I0526 07:34:25.896461 15117 sgd_solver.cpp:294] Iteration 36900, lr = 0.002
I0526 07:34:32.181967 15117 solver.cpp:233] Iteration 36910, loss = 0.032437
I0526 07:34:32.182013 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0324372 (* 1 = 0.0324372 loss)
I0526 07:34:32.182020 15117 sgd_solver.cpp:294] Iteration 36910, lr = 0.002
I0526 07:34:38.468833 15117 solver.cpp:233] Iteration 36920, loss = 0.0134204
I0526 07:34:38.468874 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0134205 (* 1 = 0.0134205 loss)
I0526 07:34:38.468883 15117 sgd_solver.cpp:294] Iteration 36920, lr = 0.002
I0526 07:34:44.756070 15117 solver.cpp:233] Iteration 36930, loss = 0.0119815
I0526 07:34:44.756327 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0119816 (* 1 = 0.0119816 loss)
I0526 07:34:44.756356 15117 sgd_solver.cpp:294] Iteration 36930, lr = 0.002
I0526 07:34:51.049602 15117 solver.cpp:233] Iteration 36940, loss = 0.0136456
I0526 07:34:51.049629 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0136458 (* 1 = 0.0136458 loss)
I0526 07:34:51.049636 15117 sgd_solver.cpp:294] Iteration 36940, lr = 0.002
I0526 07:34:57.339990 15117 solver.cpp:233] Iteration 36950, loss = 0.00989074
I0526 07:34:57.340045 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0098909 (* 1 = 0.0098909 loss)
I0526 07:34:57.340054 15117 sgd_solver.cpp:294] Iteration 36950, lr = 0.002
I0526 07:35:03.630607 15117 solver.cpp:233] Iteration 36960, loss = 0.0163439
I0526 07:35:03.630661 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0163441 (* 1 = 0.0163441 loss)
I0526 07:35:03.630668 15117 sgd_solver.cpp:294] Iteration 36960, lr = 0.002
I0526 07:35:09.922714 15117 solver.cpp:233] Iteration 36970, loss = 0.0602082
I0526 07:35:09.922757 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0602083 (* 1 = 0.0602083 loss)
I0526 07:35:09.922765 15117 sgd_solver.cpp:294] Iteration 36970, lr = 0.002
I0526 07:35:16.210618 15117 solver.cpp:233] Iteration 36980, loss = 0.0122981
I0526 07:35:16.210858 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0122983 (* 1 = 0.0122983 loss)
I0526 07:35:16.210887 15117 sgd_solver.cpp:294] Iteration 36980, lr = 0.002
I0526 07:35:22.501373 15117 solver.cpp:233] Iteration 36990, loss = 0.013254
I0526 07:35:22.501418 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0132542 (* 1 = 0.0132542 loss)
I0526 07:35:22.501425 15117 sgd_solver.cpp:294] Iteration 36990, lr = 0.002
I0526 07:35:28.188436 15117 solver.cpp:342] Iteration 37000, Testing net (#0)
I0526 07:35:40.971503 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9045
I0526 07:35:40.971549 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.399288 (* 1 = 0.399288 loss)
I0526 07:35:41.568616 15117 solver.cpp:233] Iteration 37000, loss = 0.0314653
I0526 07:35:41.568655 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0314654 (* 1 = 0.0314654 loss)
I0526 07:35:41.568662 15117 sgd_solver.cpp:294] Iteration 37000, lr = 0.002
I0526 07:35:47.857689 15117 solver.cpp:233] Iteration 37010, loss = 0.0195479
I0526 07:35:47.857908 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0195481 (* 1 = 0.0195481 loss)
I0526 07:35:47.857938 15117 sgd_solver.cpp:294] Iteration 37010, lr = 0.002
I0526 07:35:54.149457 15117 solver.cpp:233] Iteration 37020, loss = 0.0139139
I0526 07:35:54.149500 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0139141 (* 1 = 0.0139141 loss)
I0526 07:35:54.149507 15117 sgd_solver.cpp:294] Iteration 37020, lr = 0.002
I0526 07:36:00.435214 15117 solver.cpp:233] Iteration 37030, loss = 0.0417862
I0526 07:36:00.435245 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0417863 (* 1 = 0.0417863 loss)
I0526 07:36:00.435251 15117 sgd_solver.cpp:294] Iteration 37030, lr = 0.002
I0526 07:36:06.725083 15117 solver.cpp:233] Iteration 37040, loss = 0.0120868
I0526 07:36:06.725126 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0120869 (* 1 = 0.0120869 loss)
I0526 07:36:06.725132 15117 sgd_solver.cpp:294] Iteration 37040, lr = 0.002
I0526 07:36:13.015501 15117 solver.cpp:233] Iteration 37050, loss = 0.0133332
I0526 07:36:13.015543 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0133334 (* 1 = 0.0133334 loss)
I0526 07:36:13.015550 15117 sgd_solver.cpp:294] Iteration 37050, lr = 0.002
I0526 07:36:19.302112 15117 solver.cpp:233] Iteration 37060, loss = 0.0264428
I0526 07:36:19.302335 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.026443 (* 1 = 0.026443 loss)
I0526 07:36:19.302392 15117 sgd_solver.cpp:294] Iteration 37060, lr = 0.002
I0526 07:36:25.592560 15117 solver.cpp:233] Iteration 37070, loss = 0.020539
I0526 07:36:25.592591 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0205392 (* 1 = 0.0205392 loss)
I0526 07:36:25.592597 15117 sgd_solver.cpp:294] Iteration 37070, lr = 0.002
I0526 07:36:31.877930 15117 solver.cpp:233] Iteration 37080, loss = 0.0149126
I0526 07:36:31.877970 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0149128 (* 1 = 0.0149128 loss)
I0526 07:36:31.877977 15117 sgd_solver.cpp:294] Iteration 37080, lr = 0.002
I0526 07:36:38.166008 15117 solver.cpp:233] Iteration 37090, loss = 0.0131519
I0526 07:36:38.166051 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0131521 (* 1 = 0.0131521 loss)
I0526 07:36:38.166059 15117 sgd_solver.cpp:294] Iteration 37090, lr = 0.002
I0526 07:36:43.857547 15117 solver.cpp:342] Iteration 37100, Testing net (#0)
I0526 07:36:56.638918 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9
I0526 07:36:56.639149 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.41251 (* 1 = 0.41251 loss)
I0526 07:36:57.238088 15117 solver.cpp:233] Iteration 37100, loss = 0.0146783
I0526 07:36:57.238134 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0146785 (* 1 = 0.0146785 loss)
I0526 07:36:57.238143 15117 sgd_solver.cpp:294] Iteration 37100, lr = 0.002
I0526 07:37:03.529168 15117 solver.cpp:233] Iteration 37110, loss = 0.0129516
I0526 07:37:03.529196 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0129517 (* 1 = 0.0129517 loss)
I0526 07:37:03.529203 15117 sgd_solver.cpp:294] Iteration 37110, lr = 0.002
I0526 07:37:09.818737 15117 solver.cpp:233] Iteration 37120, loss = 0.00729528
I0526 07:37:09.818780 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00729545 (* 1 = 0.00729545 loss)
I0526 07:37:09.818788 15117 sgd_solver.cpp:294] Iteration 37120, lr = 0.002
I0526 07:37:16.110800 15117 solver.cpp:233] Iteration 37130, loss = 0.0135973
I0526 07:37:16.110843 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0135974 (* 1 = 0.0135974 loss)
I0526 07:37:16.110851 15117 sgd_solver.cpp:294] Iteration 37130, lr = 0.002
I0526 07:37:22.400996 15117 solver.cpp:233] Iteration 37140, loss = 0.0282873
I0526 07:37:22.401051 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0282874 (* 1 = 0.0282874 loss)
I0526 07:37:22.401059 15117 sgd_solver.cpp:294] Iteration 37140, lr = 0.002
I0526 07:37:28.689524 15117 solver.cpp:233] Iteration 37150, loss = 0.0152044
I0526 07:37:28.689730 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0152045 (* 1 = 0.0152045 loss)
I0526 07:37:28.689759 15117 sgd_solver.cpp:294] Iteration 37150, lr = 0.002
I0526 07:37:34.984004 15117 solver.cpp:233] Iteration 37160, loss = 0.0220069
I0526 07:37:34.984047 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0220071 (* 1 = 0.0220071 loss)
I0526 07:37:34.984055 15117 sgd_solver.cpp:294] Iteration 37160, lr = 0.002
I0526 07:37:41.273006 15117 solver.cpp:233] Iteration 37170, loss = 0.0246897
I0526 07:37:41.273048 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0246898 (* 1 = 0.0246898 loss)
I0526 07:37:41.273056 15117 sgd_solver.cpp:294] Iteration 37170, lr = 0.002
I0526 07:37:47.556550 15117 solver.cpp:233] Iteration 37180, loss = 0.0336456
I0526 07:37:47.556594 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0336458 (* 1 = 0.0336458 loss)
I0526 07:37:47.556602 15117 sgd_solver.cpp:294] Iteration 37180, lr = 0.002
I0526 07:37:53.842630 15117 solver.cpp:233] Iteration 37190, loss = 0.0115829
I0526 07:37:53.842674 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0115831 (* 1 = 0.0115831 loss)
I0526 07:37:53.842681 15117 sgd_solver.cpp:294] Iteration 37190, lr = 0.002
I0526 07:37:59.534413 15117 solver.cpp:342] Iteration 37200, Testing net (#0)
I0526 07:38:12.321816 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9035
I0526 07:38:12.321856 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.408046 (* 1 = 0.408046 loss)
I0526 07:38:12.918716 15117 solver.cpp:233] Iteration 37200, loss = 0.0262891
I0526 07:38:12.918756 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0262892 (* 1 = 0.0262892 loss)
I0526 07:38:12.918763 15117 sgd_solver.cpp:294] Iteration 37200, lr = 0.002
I0526 07:38:19.207269 15117 solver.cpp:233] Iteration 37210, loss = 0.0226095
I0526 07:38:19.207312 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0226097 (* 1 = 0.0226097 loss)
I0526 07:38:19.207319 15117 sgd_solver.cpp:294] Iteration 37210, lr = 0.002
I0526 07:38:25.498304 15117 solver.cpp:233] Iteration 37220, loss = 0.0216213
I0526 07:38:25.498345 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0216214 (* 1 = 0.0216214 loss)
I0526 07:38:25.498356 15117 sgd_solver.cpp:294] Iteration 37220, lr = 0.002
I0526 07:38:31.785531 15117 solver.cpp:233] Iteration 37230, loss = 0.0136054
I0526 07:38:31.785748 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0136056 (* 1 = 0.0136056 loss)
I0526 07:38:31.785773 15117 sgd_solver.cpp:294] Iteration 37230, lr = 0.002
I0526 07:38:38.078676 15117 solver.cpp:233] Iteration 37240, loss = 0.0184388
I0526 07:38:38.078721 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.018439 (* 1 = 0.018439 loss)
I0526 07:38:38.078728 15117 sgd_solver.cpp:294] Iteration 37240, lr = 0.002
I0526 07:38:44.365571 15117 solver.cpp:233] Iteration 37250, loss = 0.0182275
I0526 07:38:44.365615 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0182277 (* 1 = 0.0182277 loss)
I0526 07:38:44.365623 15117 sgd_solver.cpp:294] Iteration 37250, lr = 0.002
I0526 07:38:50.650094 15117 solver.cpp:233] Iteration 37260, loss = 0.0215506
I0526 07:38:50.650136 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0215508 (* 1 = 0.0215508 loss)
I0526 07:38:50.650144 15117 sgd_solver.cpp:294] Iteration 37260, lr = 0.002
I0526 07:38:56.932833 15117 solver.cpp:233] Iteration 37270, loss = 0.0152479
I0526 07:38:56.932875 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0152481 (* 1 = 0.0152481 loss)
I0526 07:38:56.932883 15117 sgd_solver.cpp:294] Iteration 37270, lr = 0.002
I0526 07:39:03.222688 15117 solver.cpp:233] Iteration 37280, loss = 0.0294545
I0526 07:39:03.222915 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0294546 (* 1 = 0.0294546 loss)
I0526 07:39:03.222945 15117 sgd_solver.cpp:294] Iteration 37280, lr = 0.002
I0526 07:39:09.511909 15117 solver.cpp:233] Iteration 37290, loss = 0.0108488
I0526 07:39:09.511950 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.010849 (* 1 = 0.010849 loss)
I0526 07:39:09.511956 15117 sgd_solver.cpp:294] Iteration 37290, lr = 0.002
I0526 07:39:15.202358 15117 solver.cpp:342] Iteration 37300, Testing net (#0)
I0526 07:39:27.983546 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.904
I0526 07:39:27.983588 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.411113 (* 1 = 0.411113 loss)
I0526 07:39:28.580411 15117 solver.cpp:233] Iteration 37300, loss = 0.0337312
I0526 07:39:28.580451 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0337314 (* 1 = 0.0337314 loss)
I0526 07:39:28.580458 15117 sgd_solver.cpp:294] Iteration 37300, lr = 0.002
I0526 07:39:34.869568 15117 solver.cpp:233] Iteration 37310, loss = 0.0457354
I0526 07:39:34.869829 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0457355 (* 1 = 0.0457355 loss)
I0526 07:39:34.869858 15117 sgd_solver.cpp:294] Iteration 37310, lr = 0.002
I0526 07:39:41.161206 15117 solver.cpp:233] Iteration 37320, loss = 0.0389505
I0526 07:39:41.161237 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0389506 (* 1 = 0.0389506 loss)
I0526 07:39:41.161244 15117 sgd_solver.cpp:294] Iteration 37320, lr = 0.002
I0526 07:39:47.445421 15117 solver.cpp:233] Iteration 37330, loss = 0.0273703
I0526 07:39:47.445464 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0273705 (* 1 = 0.0273705 loss)
I0526 07:39:47.445472 15117 sgd_solver.cpp:294] Iteration 37330, lr = 0.002
I0526 07:39:53.732486 15117 solver.cpp:233] Iteration 37340, loss = 0.0295047
I0526 07:39:53.732528 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0295049 (* 1 = 0.0295049 loss)
I0526 07:39:53.732537 15117 sgd_solver.cpp:294] Iteration 37340, lr = 0.002
I0526 07:40:00.021471 15117 solver.cpp:233] Iteration 37350, loss = 0.0278996
I0526 07:40:00.021517 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0278998 (* 1 = 0.0278998 loss)
I0526 07:40:00.021524 15117 sgd_solver.cpp:294] Iteration 37350, lr = 0.002
I0526 07:40:06.313802 15117 solver.cpp:233] Iteration 37360, loss = 0.036306
I0526 07:40:06.314029 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0363062 (* 1 = 0.0363062 loss)
I0526 07:40:06.314057 15117 sgd_solver.cpp:294] Iteration 37360, lr = 0.002
I0526 07:40:12.604750 15117 solver.cpp:233] Iteration 37370, loss = 0.0124228
I0526 07:40:12.604790 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0124229 (* 1 = 0.0124229 loss)
I0526 07:40:12.604797 15117 sgd_solver.cpp:294] Iteration 37370, lr = 0.002
I0526 07:40:18.895678 15117 solver.cpp:233] Iteration 37380, loss = 0.0117237
I0526 07:40:18.895721 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0117239 (* 1 = 0.0117239 loss)
I0526 07:40:18.895728 15117 sgd_solver.cpp:294] Iteration 37380, lr = 0.002
I0526 07:40:25.183286 15117 solver.cpp:233] Iteration 37390, loss = 0.0167445
I0526 07:40:25.183329 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0167447 (* 1 = 0.0167447 loss)
I0526 07:40:25.183336 15117 sgd_solver.cpp:294] Iteration 37390, lr = 0.002
I0526 07:40:30.875844 15117 solver.cpp:342] Iteration 37400, Testing net (#0)
I0526 07:40:43.654156 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9045
I0526 07:40:43.654268 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.405054 (* 1 = 0.405054 loss)
I0526 07:40:44.251654 15117 solver.cpp:233] Iteration 37400, loss = 0.0363815
I0526 07:40:44.251699 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0363816 (* 1 = 0.0363816 loss)
I0526 07:40:44.251706 15117 sgd_solver.cpp:294] Iteration 37400, lr = 0.002
I0526 07:40:50.537292 15117 solver.cpp:233] Iteration 37410, loss = 0.0337353
I0526 07:40:50.537335 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0337355 (* 1 = 0.0337355 loss)
I0526 07:40:50.537343 15117 sgd_solver.cpp:294] Iteration 37410, lr = 0.002
I0526 07:40:56.820253 15117 solver.cpp:233] Iteration 37420, loss = 0.07144
I0526 07:40:56.820297 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0714401 (* 1 = 0.0714401 loss)
I0526 07:40:56.820303 15117 sgd_solver.cpp:294] Iteration 37420, lr = 0.002
I0526 07:41:03.105870 15117 solver.cpp:233] Iteration 37430, loss = 0.0272839
I0526 07:41:03.105913 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.027284 (* 1 = 0.027284 loss)
I0526 07:41:03.105921 15117 sgd_solver.cpp:294] Iteration 37430, lr = 0.002
I0526 07:41:09.393371 15117 solver.cpp:233] Iteration 37440, loss = 0.0190757
I0526 07:41:09.393412 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0190759 (* 1 = 0.0190759 loss)
I0526 07:41:09.393419 15117 sgd_solver.cpp:294] Iteration 37440, lr = 0.002
I0526 07:41:15.681310 15117 solver.cpp:233] Iteration 37450, loss = 0.0151944
I0526 07:41:15.681532 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0151945 (* 1 = 0.0151945 loss)
I0526 07:41:15.681571 15117 sgd_solver.cpp:294] Iteration 37450, lr = 0.002
I0526 07:41:21.970613 15117 solver.cpp:233] Iteration 37460, loss = 0.0103902
I0526 07:41:21.970657 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0103903 (* 1 = 0.0103903 loss)
I0526 07:41:21.970674 15117 sgd_solver.cpp:294] Iteration 37460, lr = 0.002
I0526 07:41:28.256949 15117 solver.cpp:233] Iteration 37470, loss = 0.0085204
I0526 07:41:28.256990 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00852058 (* 1 = 0.00852058 loss)
I0526 07:41:28.256997 15117 sgd_solver.cpp:294] Iteration 37470, lr = 0.002
I0526 07:41:34.545821 15117 solver.cpp:233] Iteration 37480, loss = 0.0235401
I0526 07:41:34.545866 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0235403 (* 1 = 0.0235403 loss)
I0526 07:41:34.545873 15117 sgd_solver.cpp:294] Iteration 37480, lr = 0.002
I0526 07:41:40.830706 15117 solver.cpp:233] Iteration 37490, loss = 0.0106163
I0526 07:41:40.830760 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0106165 (* 1 = 0.0106165 loss)
I0526 07:41:40.830766 15117 sgd_solver.cpp:294] Iteration 37490, lr = 0.002
I0526 07:41:46.522347 15117 solver.cpp:342] Iteration 37500, Testing net (#0)
I0526 07:41:59.309391 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9024
I0526 07:41:59.309439 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.39741 (* 1 = 0.39741 loss)
I0526 07:41:59.907052 15117 solver.cpp:233] Iteration 37500, loss = 0.0290182
I0526 07:41:59.907096 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0290184 (* 1 = 0.0290184 loss)
I0526 07:41:59.907104 15117 sgd_solver.cpp:294] Iteration 37500, lr = 0.002
I0526 07:42:06.193545 15117 solver.cpp:233] Iteration 37510, loss = 0.0292748
I0526 07:42:06.193589 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.029275 (* 1 = 0.029275 loss)
I0526 07:42:06.193598 15117 sgd_solver.cpp:294] Iteration 37510, lr = 0.002
I0526 07:42:12.482300 15117 solver.cpp:233] Iteration 37520, loss = 0.0107352
I0526 07:42:12.482342 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0107354 (* 1 = 0.0107354 loss)
I0526 07:42:12.482348 15117 sgd_solver.cpp:294] Iteration 37520, lr = 0.002
I0526 07:42:18.769081 15117 solver.cpp:233] Iteration 37530, loss = 0.0166681
I0526 07:42:18.769287 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0166683 (* 1 = 0.0166683 loss)
I0526 07:42:18.769315 15117 sgd_solver.cpp:294] Iteration 37530, lr = 0.002
I0526 07:42:25.060258 15117 solver.cpp:233] Iteration 37540, loss = 0.0325059
I0526 07:42:25.060302 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0325061 (* 1 = 0.0325061 loss)
I0526 07:42:25.060308 15117 sgd_solver.cpp:294] Iteration 37540, lr = 0.002
I0526 07:42:31.349813 15117 solver.cpp:233] Iteration 37550, loss = 0.0156768
I0526 07:42:31.349867 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.015677 (* 1 = 0.015677 loss)
I0526 07:42:31.349874 15117 sgd_solver.cpp:294] Iteration 37550, lr = 0.002
I0526 07:42:37.638362 15117 solver.cpp:233] Iteration 37560, loss = 0.0139871
I0526 07:42:37.638406 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0139873 (* 1 = 0.0139873 loss)
I0526 07:42:37.638412 15117 sgd_solver.cpp:294] Iteration 37560, lr = 0.002
I0526 07:42:43.927073 15117 solver.cpp:233] Iteration 37570, loss = 0.0158391
I0526 07:42:43.927112 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0158393 (* 1 = 0.0158393 loss)
I0526 07:42:43.927119 15117 sgd_solver.cpp:294] Iteration 37570, lr = 0.002
I0526 07:42:50.216493 15117 solver.cpp:233] Iteration 37580, loss = 0.0259945
I0526 07:42:50.216665 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0259947 (* 1 = 0.0259947 loss)
I0526 07:42:50.216694 15117 sgd_solver.cpp:294] Iteration 37580, lr = 0.002
I0526 07:42:56.504604 15117 solver.cpp:233] Iteration 37590, loss = 0.0251144
I0526 07:42:56.504647 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0251145 (* 1 = 0.0251145 loss)
I0526 07:42:56.504662 15117 sgd_solver.cpp:294] Iteration 37590, lr = 0.002
I0526 07:43:02.196529 15117 solver.cpp:342] Iteration 37600, Testing net (#0)
I0526 07:43:14.976301 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9046
I0526 07:43:14.976346 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.406518 (* 1 = 0.406518 loss)
I0526 07:43:15.571763 15117 solver.cpp:233] Iteration 37600, loss = 0.00641315
I0526 07:43:15.571802 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00641334 (* 1 = 0.00641334 loss)
I0526 07:43:15.571810 15117 sgd_solver.cpp:294] Iteration 37600, lr = 0.002
I0526 07:43:21.858729 15117 solver.cpp:233] Iteration 37610, loss = 0.0268551
I0526 07:43:21.858989 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0268553 (* 1 = 0.0268553 loss)
I0526 07:43:21.859019 15117 sgd_solver.cpp:294] Iteration 37610, lr = 0.002
I0526 07:43:28.152768 15117 solver.cpp:233] Iteration 37620, loss = 0.0103871
I0526 07:43:28.152809 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0103873 (* 1 = 0.0103873 loss)
I0526 07:43:28.152817 15117 sgd_solver.cpp:294] Iteration 37620, lr = 0.002
I0526 07:43:34.441256 15117 solver.cpp:233] Iteration 37630, loss = 0.00739598
I0526 07:43:34.441298 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00739617 (* 1 = 0.00739617 loss)
I0526 07:43:34.441306 15117 sgd_solver.cpp:294] Iteration 37630, lr = 0.002
I0526 07:43:40.733466 15117 solver.cpp:233] Iteration 37640, loss = 0.0135898
I0526 07:43:40.733508 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.01359 (* 1 = 0.01359 loss)
I0526 07:43:40.733515 15117 sgd_solver.cpp:294] Iteration 37640, lr = 0.002
I0526 07:43:47.022733 15117 solver.cpp:233] Iteration 37650, loss = 0.0388443
I0526 07:43:47.022778 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0388445 (* 1 = 0.0388445 loss)
I0526 07:43:47.022784 15117 sgd_solver.cpp:294] Iteration 37650, lr = 0.002
I0526 07:43:53.310253 15117 solver.cpp:233] Iteration 37660, loss = 0.0286503
I0526 07:43:53.310494 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0286505 (* 1 = 0.0286505 loss)
I0526 07:43:53.310523 15117 sgd_solver.cpp:294] Iteration 37660, lr = 0.002
I0526 07:43:59.602396 15117 solver.cpp:233] Iteration 37670, loss = 0.0217925
I0526 07:43:59.602432 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0217927 (* 1 = 0.0217927 loss)
I0526 07:43:59.602439 15117 sgd_solver.cpp:294] Iteration 37670, lr = 0.002
I0526 07:44:05.892359 15117 solver.cpp:233] Iteration 37680, loss = 0.0196631
I0526 07:44:05.892401 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0196633 (* 1 = 0.0196633 loss)
I0526 07:44:05.892408 15117 sgd_solver.cpp:294] Iteration 37680, lr = 0.002
I0526 07:44:12.175812 15117 solver.cpp:233] Iteration 37690, loss = 0.0133312
I0526 07:44:12.175859 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0133313 (* 1 = 0.0133313 loss)
I0526 07:44:12.175866 15117 sgd_solver.cpp:294] Iteration 37690, lr = 0.002
I0526 07:44:17.866539 15117 solver.cpp:342] Iteration 37700, Testing net (#0)
I0526 07:44:30.647913 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9026
I0526 07:44:30.648138 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.401853 (* 1 = 0.401853 loss)
I0526 07:44:31.245303 15117 solver.cpp:233] Iteration 37700, loss = 0.0229829
I0526 07:44:31.245352 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0229831 (* 1 = 0.0229831 loss)
I0526 07:44:31.245360 15117 sgd_solver.cpp:294] Iteration 37700, lr = 0.002
I0526 07:44:37.533987 15117 solver.cpp:233] Iteration 37710, loss = 0.0245776
I0526 07:44:37.534034 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0245777 (* 1 = 0.0245777 loss)
I0526 07:44:37.534042 15117 sgd_solver.cpp:294] Iteration 37710, lr = 0.002
I0526 07:44:43.824118 15117 solver.cpp:233] Iteration 37720, loss = 0.00873777
I0526 07:44:43.824158 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00873796 (* 1 = 0.00873796 loss)
I0526 07:44:43.824170 15117 sgd_solver.cpp:294] Iteration 37720, lr = 0.002
I0526 07:44:50.114406 15117 solver.cpp:233] Iteration 37730, loss = 0.0123293
I0526 07:44:50.114446 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0123295 (* 1 = 0.0123295 loss)
I0526 07:44:50.114454 15117 sgd_solver.cpp:294] Iteration 37730, lr = 0.002
I0526 07:44:56.404721 15117 solver.cpp:233] Iteration 37740, loss = 0.0215889
I0526 07:44:56.404764 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0215891 (* 1 = 0.0215891 loss)
I0526 07:44:56.404772 15117 sgd_solver.cpp:294] Iteration 37740, lr = 0.002
I0526 07:45:02.696560 15117 solver.cpp:233] Iteration 37750, loss = 0.0156224
I0526 07:45:02.696811 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0156226 (* 1 = 0.0156226 loss)
I0526 07:45:02.696841 15117 sgd_solver.cpp:294] Iteration 37750, lr = 0.002
I0526 07:45:08.984745 15117 solver.cpp:233] Iteration 37760, loss = 0.0211035
I0526 07:45:08.984791 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0211037 (* 1 = 0.0211037 loss)
I0526 07:45:08.984798 15117 sgd_solver.cpp:294] Iteration 37760, lr = 0.002
I0526 07:45:15.274893 15117 solver.cpp:233] Iteration 37770, loss = 0.0259332
I0526 07:45:15.274936 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0259334 (* 1 = 0.0259334 loss)
I0526 07:45:15.274943 15117 sgd_solver.cpp:294] Iteration 37770, lr = 0.002
I0526 07:45:21.562515 15117 solver.cpp:233] Iteration 37780, loss = 0.018491
I0526 07:45:21.562556 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0184912 (* 1 = 0.0184912 loss)
I0526 07:45:21.562562 15117 sgd_solver.cpp:294] Iteration 37780, lr = 0.002
I0526 07:45:27.845834 15117 solver.cpp:233] Iteration 37790, loss = 0.00982011
I0526 07:45:27.845880 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00982029 (* 1 = 0.00982029 loss)
I0526 07:45:27.845886 15117 sgd_solver.cpp:294] Iteration 37790, lr = 0.002
I0526 07:45:33.541425 15117 solver.cpp:342] Iteration 37800, Testing net (#0)
I0526 07:45:46.319321 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9024
I0526 07:45:46.319370 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.417535 (* 1 = 0.417535 loss)
I0526 07:45:46.916601 15117 solver.cpp:233] Iteration 37800, loss = 0.0111317
I0526 07:45:46.916641 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0111319 (* 1 = 0.0111319 loss)
I0526 07:45:46.916648 15117 sgd_solver.cpp:294] Iteration 37800, lr = 0.002
I0526 07:45:53.206485 15117 solver.cpp:233] Iteration 37810, loss = 0.0384835
I0526 07:45:53.206531 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0384837 (* 1 = 0.0384837 loss)
I0526 07:45:53.206537 15117 sgd_solver.cpp:294] Iteration 37810, lr = 0.002
I0526 07:45:59.496075 15117 solver.cpp:233] Iteration 37820, loss = 0.0142916
I0526 07:45:59.496117 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0142918 (* 1 = 0.0142918 loss)
I0526 07:45:59.496125 15117 sgd_solver.cpp:294] Iteration 37820, lr = 0.002
I0526 07:46:05.781976 15117 solver.cpp:233] Iteration 37830, loss = 0.0093675
I0526 07:46:05.782196 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00936768 (* 1 = 0.00936768 loss)
I0526 07:46:05.782225 15117 sgd_solver.cpp:294] Iteration 37830, lr = 0.002
I0526 07:46:12.072016 15117 solver.cpp:233] Iteration 37840, loss = 0.0195518
I0526 07:46:12.072062 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.019552 (* 1 = 0.019552 loss)
I0526 07:46:12.072068 15117 sgd_solver.cpp:294] Iteration 37840, lr = 0.002
I0526 07:46:18.357785 15117 solver.cpp:233] Iteration 37850, loss = 0.0246597
I0526 07:46:18.357826 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0246599 (* 1 = 0.0246599 loss)
I0526 07:46:18.357833 15117 sgd_solver.cpp:294] Iteration 37850, lr = 0.002
I0526 07:46:24.645244 15117 solver.cpp:233] Iteration 37860, loss = 0.00588768
I0526 07:46:24.645292 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00588787 (* 1 = 0.00588787 loss)
I0526 07:46:24.645299 15117 sgd_solver.cpp:294] Iteration 37860, lr = 0.002
I0526 07:46:30.934835 15117 solver.cpp:233] Iteration 37870, loss = 0.0296675
I0526 07:46:30.934878 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0296677 (* 1 = 0.0296677 loss)
I0526 07:46:30.934885 15117 sgd_solver.cpp:294] Iteration 37870, lr = 0.002
I0526 07:46:37.226105 15117 solver.cpp:233] Iteration 37880, loss = 0.011412
I0526 07:46:37.226253 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0114122 (* 1 = 0.0114122 loss)
I0526 07:46:37.226263 15117 sgd_solver.cpp:294] Iteration 37880, lr = 0.002
I0526 07:46:43.517179 15117 solver.cpp:233] Iteration 37890, loss = 0.0311393
I0526 07:46:43.517223 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0311395 (* 1 = 0.0311395 loss)
I0526 07:46:43.517230 15117 sgd_solver.cpp:294] Iteration 37890, lr = 0.002
I0526 07:46:49.209020 15117 solver.cpp:342] Iteration 37900, Testing net (#0)
I0526 07:47:01.992259 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9027
I0526 07:47:01.992305 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.407107 (* 1 = 0.407107 loss)
I0526 07:47:02.589869 15117 solver.cpp:233] Iteration 37900, loss = 0.0280893
I0526 07:47:02.589901 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0280895 (* 1 = 0.0280895 loss)
I0526 07:47:02.589908 15117 sgd_solver.cpp:294] Iteration 37900, lr = 0.002
I0526 07:47:08.877825 15117 solver.cpp:233] Iteration 37910, loss = 0.0125777
I0526 07:47:08.878041 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0125779 (* 1 = 0.0125779 loss)
I0526 07:47:08.878070 15117 sgd_solver.cpp:294] Iteration 37910, lr = 0.002
I0526 07:47:15.171229 15117 solver.cpp:233] Iteration 37920, loss = 0.0254291
I0526 07:47:15.171273 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0254293 (* 1 = 0.0254293 loss)
I0526 07:47:15.171281 15117 sgd_solver.cpp:294] Iteration 37920, lr = 0.002
I0526 07:47:21.458573 15117 solver.cpp:233] Iteration 37930, loss = 0.0213537
I0526 07:47:21.458616 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0213539 (* 1 = 0.0213539 loss)
I0526 07:47:21.458623 15117 sgd_solver.cpp:294] Iteration 37930, lr = 0.002
I0526 07:47:27.750572 15117 solver.cpp:233] Iteration 37940, loss = 0.00979871
I0526 07:47:27.750617 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0097989 (* 1 = 0.0097989 loss)
I0526 07:47:27.750624 15117 sgd_solver.cpp:294] Iteration 37940, lr = 0.002
I0526 07:47:34.039369 15117 solver.cpp:233] Iteration 37950, loss = 0.0314496
I0526 07:47:34.039410 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0314498 (* 1 = 0.0314498 loss)
I0526 07:47:34.039417 15117 sgd_solver.cpp:294] Iteration 37950, lr = 0.002
I0526 07:47:40.332128 15117 solver.cpp:233] Iteration 37960, loss = 0.0445395
I0526 07:47:40.332355 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0445397 (* 1 = 0.0445397 loss)
I0526 07:47:40.332384 15117 sgd_solver.cpp:294] Iteration 37960, lr = 0.002
I0526 07:47:46.626021 15117 solver.cpp:233] Iteration 37970, loss = 0.00892561
I0526 07:47:46.626062 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00892579 (* 1 = 0.00892579 loss)
I0526 07:47:46.626070 15117 sgd_solver.cpp:294] Iteration 37970, lr = 0.002
I0526 07:47:52.917204 15117 solver.cpp:233] Iteration 37980, loss = 0.0153593
I0526 07:47:52.917249 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0153595 (* 1 = 0.0153595 loss)
I0526 07:47:52.917256 15117 sgd_solver.cpp:294] Iteration 37980, lr = 0.002
I0526 07:47:59.207149 15117 solver.cpp:233] Iteration 37990, loss = 0.0160631
I0526 07:47:59.207185 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0160633 (* 1 = 0.0160633 loss)
I0526 07:47:59.207192 15117 sgd_solver.cpp:294] Iteration 37990, lr = 0.002
I0526 07:48:04.899556 15117 solver.cpp:342] Iteration 38000, Testing net (#0)
I0526 07:48:17.693924 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9003
I0526 07:48:17.694211 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.439691 (* 1 = 0.439691 loss)
I0526 07:48:18.291263 15117 solver.cpp:233] Iteration 38000, loss = 0.0346968
I0526 07:48:18.291306 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.034697 (* 1 = 0.034697 loss)
I0526 07:48:18.291312 15117 sgd_solver.cpp:294] Iteration 38000, lr = 0.002
I0526 07:48:24.576578 15117 solver.cpp:233] Iteration 38010, loss = 0.0302995
I0526 07:48:24.576622 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0302997 (* 1 = 0.0302997 loss)
I0526 07:48:24.576629 15117 sgd_solver.cpp:294] Iteration 38010, lr = 0.002
I0526 07:48:30.867107 15117 solver.cpp:233] Iteration 38020, loss = 0.0170021
I0526 07:48:30.867147 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0170023 (* 1 = 0.0170023 loss)
I0526 07:48:30.867153 15117 sgd_solver.cpp:294] Iteration 38020, lr = 0.002
I0526 07:48:37.159715 15117 solver.cpp:233] Iteration 38030, loss = 0.0210376
I0526 07:48:37.159767 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0210378 (* 1 = 0.0210378 loss)
I0526 07:48:37.159775 15117 sgd_solver.cpp:294] Iteration 38030, lr = 0.002
I0526 07:48:43.450489 15117 solver.cpp:233] Iteration 38040, loss = 0.0316048
I0526 07:48:43.450518 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0316049 (* 1 = 0.0316049 loss)
I0526 07:48:43.450525 15117 sgd_solver.cpp:294] Iteration 38040, lr = 0.002
I0526 07:48:49.743124 15117 solver.cpp:233] Iteration 38050, loss = 0.0319367
I0526 07:48:49.743340 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0319369 (* 1 = 0.0319369 loss)
I0526 07:48:49.743371 15117 sgd_solver.cpp:294] Iteration 38050, lr = 0.002
I0526 07:48:56.033833 15117 solver.cpp:233] Iteration 38060, loss = 0.0370407
I0526 07:48:56.033877 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0370409 (* 1 = 0.0370409 loss)
I0526 07:48:56.033885 15117 sgd_solver.cpp:294] Iteration 38060, lr = 0.002
I0526 07:49:02.324371 15117 solver.cpp:233] Iteration 38070, loss = 0.0300612
I0526 07:49:02.324414 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0300614 (* 1 = 0.0300614 loss)
I0526 07:49:02.324421 15117 sgd_solver.cpp:294] Iteration 38070, lr = 0.002
I0526 07:49:08.618247 15117 solver.cpp:233] Iteration 38080, loss = 0.0176346
I0526 07:49:08.618289 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0176348 (* 1 = 0.0176348 loss)
I0526 07:49:08.618295 15117 sgd_solver.cpp:294] Iteration 38080, lr = 0.002
I0526 07:49:14.907985 15117 solver.cpp:233] Iteration 38090, loss = 0.0145022
I0526 07:49:14.908023 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0145024 (* 1 = 0.0145024 loss)
I0526 07:49:14.908030 15117 sgd_solver.cpp:294] Iteration 38090, lr = 0.002
I0526 07:49:20.603204 15117 solver.cpp:342] Iteration 38100, Testing net (#0)
I0526 07:49:33.398547 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9015
I0526 07:49:33.398594 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.421204 (* 1 = 0.421204 loss)
I0526 07:49:33.995506 15117 solver.cpp:233] Iteration 38100, loss = 0.0325727
I0526 07:49:33.995542 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0325729 (* 1 = 0.0325729 loss)
I0526 07:49:33.995548 15117 sgd_solver.cpp:294] Iteration 38100, lr = 0.002
I0526 07:49:40.288908 15117 solver.cpp:233] Iteration 38110, loss = 0.0569895
I0526 07:49:40.288954 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0569897 (* 1 = 0.0569897 loss)
I0526 07:49:40.288962 15117 sgd_solver.cpp:294] Iteration 38110, lr = 0.002
I0526 07:49:46.583060 15117 solver.cpp:233] Iteration 38120, loss = 0.0164668
I0526 07:49:46.583109 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.016467 (* 1 = 0.016467 loss)
I0526 07:49:46.583117 15117 sgd_solver.cpp:294] Iteration 38120, lr = 0.002
I0526 07:49:52.874497 15117 solver.cpp:233] Iteration 38130, loss = 0.0181915
I0526 07:49:52.874671 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0181917 (* 1 = 0.0181917 loss)
I0526 07:49:52.874680 15117 sgd_solver.cpp:294] Iteration 38130, lr = 0.002
I0526 07:49:59.164024 15117 solver.cpp:233] Iteration 38140, loss = 0.0159228
I0526 07:49:59.164067 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.015923 (* 1 = 0.015923 loss)
I0526 07:49:59.164073 15117 sgd_solver.cpp:294] Iteration 38140, lr = 0.002
I0526 07:50:05.452711 15117 solver.cpp:233] Iteration 38150, loss = 0.0113903
I0526 07:50:05.452759 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0113905 (* 1 = 0.0113905 loss)
I0526 07:50:05.452766 15117 sgd_solver.cpp:294] Iteration 38150, lr = 0.002
I0526 07:50:11.742178 15117 solver.cpp:233] Iteration 38160, loss = 0.0127176
I0526 07:50:11.742218 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0127178 (* 1 = 0.0127178 loss)
I0526 07:50:11.742225 15117 sgd_solver.cpp:294] Iteration 38160, lr = 0.002
I0526 07:50:18.032085 15117 solver.cpp:233] Iteration 38170, loss = 0.0111103
I0526 07:50:18.032127 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0111105 (* 1 = 0.0111105 loss)
I0526 07:50:18.032135 15117 sgd_solver.cpp:294] Iteration 38170, lr = 0.002
I0526 07:50:24.320210 15117 solver.cpp:233] Iteration 38180, loss = 0.0249567
I0526 07:50:24.320430 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0249569 (* 1 = 0.0249569 loss)
I0526 07:50:24.320459 15117 sgd_solver.cpp:294] Iteration 38180, lr = 0.002
I0526 07:50:30.611619 15117 solver.cpp:233] Iteration 38190, loss = 0.00854417
I0526 07:50:30.611662 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00854437 (* 1 = 0.00854437 loss)
I0526 07:50:30.611670 15117 sgd_solver.cpp:294] Iteration 38190, lr = 0.002
I0526 07:50:36.300487 15117 solver.cpp:342] Iteration 38200, Testing net (#0)
I0526 07:50:49.081470 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9017
I0526 07:50:49.081509 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.417473 (* 1 = 0.417473 loss)
I0526 07:50:49.677243 15117 solver.cpp:233] Iteration 38200, loss = 0.0155078
I0526 07:50:49.677279 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.015508 (* 1 = 0.015508 loss)
I0526 07:50:49.677286 15117 sgd_solver.cpp:294] Iteration 38200, lr = 0.002
I0526 07:50:55.969995 15117 solver.cpp:233] Iteration 38210, loss = 0.0354271
I0526 07:50:55.970124 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0354273 (* 1 = 0.0354273 loss)
I0526 07:50:55.970132 15117 sgd_solver.cpp:294] Iteration 38210, lr = 0.002
I0526 07:51:02.260581 15117 solver.cpp:233] Iteration 38220, loss = 0.00316138
I0526 07:51:02.260622 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00316157 (* 1 = 0.00316157 loss)
I0526 07:51:02.260628 15117 sgd_solver.cpp:294] Iteration 38220, lr = 0.002
I0526 07:51:08.550541 15117 solver.cpp:233] Iteration 38230, loss = 0.0170897
I0526 07:51:08.550583 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0170899 (* 1 = 0.0170899 loss)
I0526 07:51:08.550590 15117 sgd_solver.cpp:294] Iteration 38230, lr = 0.002
I0526 07:51:14.840639 15117 solver.cpp:233] Iteration 38240, loss = 0.0448215
I0526 07:51:14.840682 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0448217 (* 1 = 0.0448217 loss)
I0526 07:51:14.840688 15117 sgd_solver.cpp:294] Iteration 38240, lr = 0.002
I0526 07:51:21.130066 15117 solver.cpp:233] Iteration 38250, loss = 0.0226813
I0526 07:51:21.130112 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0226815 (* 1 = 0.0226815 loss)
I0526 07:51:21.130120 15117 sgd_solver.cpp:294] Iteration 38250, lr = 0.002
I0526 07:51:27.421474 15117 solver.cpp:233] Iteration 38260, loss = 0.00790527
I0526 07:51:27.421735 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00790547 (* 1 = 0.00790547 loss)
I0526 07:51:27.421763 15117 sgd_solver.cpp:294] Iteration 38260, lr = 0.002
I0526 07:51:33.710621 15117 solver.cpp:233] Iteration 38270, loss = 0.0296423
I0526 07:51:33.710665 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0296425 (* 1 = 0.0296425 loss)
I0526 07:51:33.710680 15117 sgd_solver.cpp:294] Iteration 38270, lr = 0.002
I0526 07:51:39.996801 15117 solver.cpp:233] Iteration 38280, loss = 0.0332685
I0526 07:51:39.996847 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0332687 (* 1 = 0.0332687 loss)
I0526 07:51:39.996856 15117 sgd_solver.cpp:294] Iteration 38280, lr = 0.002
I0526 07:51:46.288216 15117 solver.cpp:233] Iteration 38290, loss = 0.0143519
I0526 07:51:46.288252 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0143521 (* 1 = 0.0143521 loss)
I0526 07:51:46.288259 15117 sgd_solver.cpp:294] Iteration 38290, lr = 0.002
I0526 07:51:51.983055 15117 solver.cpp:342] Iteration 38300, Testing net (#0)
I0526 07:52:04.757910 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9043
I0526 07:52:04.758127 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.414436 (* 1 = 0.414436 loss)
I0526 07:52:05.355866 15117 solver.cpp:233] Iteration 38300, loss = 0.00796538
I0526 07:52:05.355913 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00796557 (* 1 = 0.00796557 loss)
I0526 07:52:05.355921 15117 sgd_solver.cpp:294] Iteration 38300, lr = 0.002
I0526 07:52:11.648918 15117 solver.cpp:233] Iteration 38310, loss = 0.00832391
I0526 07:52:11.648946 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0083241 (* 1 = 0.0083241 loss)
I0526 07:52:11.648952 15117 sgd_solver.cpp:294] Iteration 38310, lr = 0.002
I0526 07:52:17.938235 15117 solver.cpp:233] Iteration 38320, loss = 0.0311451
I0526 07:52:17.938277 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0311453 (* 1 = 0.0311453 loss)
I0526 07:52:17.938283 15117 sgd_solver.cpp:294] Iteration 38320, lr = 0.002
I0526 07:52:24.228674 15117 solver.cpp:233] Iteration 38330, loss = 0.00434556
I0526 07:52:24.228716 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00434576 (* 1 = 0.00434576 loss)
I0526 07:52:24.228724 15117 sgd_solver.cpp:294] Iteration 38330, lr = 0.002
I0526 07:52:30.515326 15117 solver.cpp:233] Iteration 38340, loss = 0.0187469
I0526 07:52:30.515368 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0187471 (* 1 = 0.0187471 loss)
I0526 07:52:30.515375 15117 sgd_solver.cpp:294] Iteration 38340, lr = 0.002
I0526 07:52:36.803472 15117 solver.cpp:233] Iteration 38350, loss = 0.00888676
I0526 07:52:36.803696 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00888695 (* 1 = 0.00888695 loss)
I0526 07:52:36.803726 15117 sgd_solver.cpp:294] Iteration 38350, lr = 0.002
I0526 07:52:43.090958 15117 solver.cpp:233] Iteration 38360, loss = 0.0616042
I0526 07:52:43.091002 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0616044 (* 1 = 0.0616044 loss)
I0526 07:52:43.091011 15117 sgd_solver.cpp:294] Iteration 38360, lr = 0.002
I0526 07:52:49.379724 15117 solver.cpp:233] Iteration 38370, loss = 0.0114525
I0526 07:52:49.379767 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0114527 (* 1 = 0.0114527 loss)
I0526 07:52:49.379775 15117 sgd_solver.cpp:294] Iteration 38370, lr = 0.002
I0526 07:52:55.668404 15117 solver.cpp:233] Iteration 38380, loss = 0.015853
I0526 07:52:55.668444 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0158532 (* 1 = 0.0158532 loss)
I0526 07:52:55.668452 15117 sgd_solver.cpp:294] Iteration 38380, lr = 0.002
I0526 07:53:01.954583 15117 solver.cpp:233] Iteration 38390, loss = 0.0247473
I0526 07:53:01.954628 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0247475 (* 1 = 0.0247475 loss)
I0526 07:53:01.954646 15117 sgd_solver.cpp:294] Iteration 38390, lr = 0.002
I0526 07:53:07.647341 15117 solver.cpp:342] Iteration 38400, Testing net (#0)
I0526 07:53:20.430446 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9005
I0526 07:53:20.430500 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.434279 (* 1 = 0.434279 loss)
I0526 07:53:21.027657 15117 solver.cpp:233] Iteration 38400, loss = 0.0187072
I0526 07:53:21.027688 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0187074 (* 1 = 0.0187074 loss)
I0526 07:53:21.027695 15117 sgd_solver.cpp:294] Iteration 38400, lr = 0.002
I0526 07:53:27.319200 15117 solver.cpp:233] Iteration 38410, loss = 0.0106159
I0526 07:53:27.319231 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0106161 (* 1 = 0.0106161 loss)
I0526 07:53:27.319237 15117 sgd_solver.cpp:294] Iteration 38410, lr = 0.002
I0526 07:53:33.608841 15117 solver.cpp:233] Iteration 38420, loss = 0.0218579
I0526 07:53:33.608883 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0218581 (* 1 = 0.0218581 loss)
I0526 07:53:33.608891 15117 sgd_solver.cpp:294] Iteration 38420, lr = 0.002
I0526 07:53:39.896371 15117 solver.cpp:233] Iteration 38430, loss = 0.00704426
I0526 07:53:39.896601 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00704446 (* 1 = 0.00704446 loss)
I0526 07:53:39.896631 15117 sgd_solver.cpp:294] Iteration 38430, lr = 0.002
I0526 07:53:46.180846 15117 solver.cpp:233] Iteration 38440, loss = 0.0272689
I0526 07:53:46.180888 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0272691 (* 1 = 0.0272691 loss)
I0526 07:53:46.180896 15117 sgd_solver.cpp:294] Iteration 38440, lr = 0.002
I0526 07:53:52.466644 15117 solver.cpp:233] Iteration 38450, loss = 0.0500267
I0526 07:53:52.466701 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0500269 (* 1 = 0.0500269 loss)
I0526 07:53:52.466707 15117 sgd_solver.cpp:294] Iteration 38450, lr = 0.002
I0526 07:53:58.755201 15117 solver.cpp:233] Iteration 38460, loss = 0.0396071
I0526 07:53:58.755245 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0396073 (* 1 = 0.0396073 loss)
I0526 07:53:58.755252 15117 sgd_solver.cpp:294] Iteration 38460, lr = 0.002
I0526 07:54:05.041779 15117 solver.cpp:233] Iteration 38470, loss = 0.0266345
I0526 07:54:05.041821 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0266347 (* 1 = 0.0266347 loss)
I0526 07:54:05.041827 15117 sgd_solver.cpp:294] Iteration 38470, lr = 0.002
I0526 07:54:11.329416 15117 solver.cpp:233] Iteration 38480, loss = 0.0121827
I0526 07:54:11.329624 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0121828 (* 1 = 0.0121828 loss)
I0526 07:54:11.329653 15117 sgd_solver.cpp:294] Iteration 38480, lr = 0.002
I0526 07:54:17.618772 15117 solver.cpp:233] Iteration 38490, loss = 0.0153647
I0526 07:54:17.618813 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0153649 (* 1 = 0.0153649 loss)
I0526 07:54:17.618820 15117 sgd_solver.cpp:294] Iteration 38490, lr = 0.002
I0526 07:54:23.310444 15117 solver.cpp:342] Iteration 38500, Testing net (#0)
I0526 07:54:36.090040 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9064
I0526 07:54:36.090066 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.399199 (* 1 = 0.399199 loss)
I0526 07:54:36.687675 15117 solver.cpp:233] Iteration 38500, loss = 0.016993
I0526 07:54:36.687714 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0169932 (* 1 = 0.0169932 loss)
I0526 07:54:36.687721 15117 sgd_solver.cpp:294] Iteration 38500, lr = 0.002
I0526 07:54:42.970495 15117 solver.cpp:233] Iteration 38510, loss = 0.0112419
I0526 07:54:42.970736 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.011242 (* 1 = 0.011242 loss)
I0526 07:54:42.970762 15117 sgd_solver.cpp:294] Iteration 38510, lr = 0.002
I0526 07:54:49.258061 15117 solver.cpp:233] Iteration 38520, loss = 0.00758142
I0526 07:54:49.258105 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00758161 (* 1 = 0.00758161 loss)
I0526 07:54:49.258112 15117 sgd_solver.cpp:294] Iteration 38520, lr = 0.002
I0526 07:54:55.540292 15117 solver.cpp:233] Iteration 38530, loss = 0.0366975
I0526 07:54:55.540336 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0366977 (* 1 = 0.0366977 loss)
I0526 07:54:55.540349 15117 sgd_solver.cpp:294] Iteration 38530, lr = 0.002
I0526 07:55:01.828613 15117 solver.cpp:233] Iteration 38540, loss = 0.0227339
I0526 07:55:01.828676 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0227341 (* 1 = 0.0227341 loss)
I0526 07:55:01.828683 15117 sgd_solver.cpp:294] Iteration 38540, lr = 0.002
I0526 07:55:08.118222 15117 solver.cpp:233] Iteration 38550, loss = 0.0116944
I0526 07:55:08.118268 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0116946 (* 1 = 0.0116946 loss)
I0526 07:55:08.118273 15117 sgd_solver.cpp:294] Iteration 38550, lr = 0.002
I0526 07:55:14.405335 15117 solver.cpp:233] Iteration 38560, loss = 0.0154664
I0526 07:55:14.405575 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0154666 (* 1 = 0.0154666 loss)
I0526 07:55:14.405603 15117 sgd_solver.cpp:294] Iteration 38560, lr = 0.002
I0526 07:55:20.700605 15117 solver.cpp:233] Iteration 38570, loss = 0.00815728
I0526 07:55:20.700642 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00815748 (* 1 = 0.00815748 loss)
I0526 07:55:20.700650 15117 sgd_solver.cpp:294] Iteration 38570, lr = 0.002
I0526 07:55:26.989852 15117 solver.cpp:233] Iteration 38580, loss = 0.0260795
I0526 07:55:26.989897 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0260797 (* 1 = 0.0260797 loss)
I0526 07:55:26.989903 15117 sgd_solver.cpp:294] Iteration 38580, lr = 0.002
I0526 07:55:33.276367 15117 solver.cpp:233] Iteration 38590, loss = 0.0333381
I0526 07:55:33.276420 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0333383 (* 1 = 0.0333383 loss)
I0526 07:55:33.276427 15117 sgd_solver.cpp:294] Iteration 38590, lr = 0.002
I0526 07:55:38.968916 15117 solver.cpp:342] Iteration 38600, Testing net (#0)
I0526 07:55:51.745357 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9029
I0526 07:55:51.745764 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.417397 (* 1 = 0.417397 loss)
I0526 07:55:52.344383 15117 solver.cpp:233] Iteration 38600, loss = 0.0292854
I0526 07:55:52.344441 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0292856 (* 1 = 0.0292856 loss)
I0526 07:55:52.344449 15117 sgd_solver.cpp:294] Iteration 38600, lr = 0.002
I0526 07:55:58.632002 15117 solver.cpp:233] Iteration 38610, loss = 0.021781
I0526 07:55:58.632032 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0217812 (* 1 = 0.0217812 loss)
I0526 07:55:58.632040 15117 sgd_solver.cpp:294] Iteration 38610, lr = 0.002
I0526 07:56:04.918473 15117 solver.cpp:233] Iteration 38620, loss = 0.0152973
I0526 07:56:04.918517 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0152975 (* 1 = 0.0152975 loss)
I0526 07:56:04.918525 15117 sgd_solver.cpp:294] Iteration 38620, lr = 0.002
I0526 07:56:11.210207 15117 solver.cpp:233] Iteration 38630, loss = 0.0187211
I0526 07:56:11.210249 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0187213 (* 1 = 0.0187213 loss)
I0526 07:56:11.210256 15117 sgd_solver.cpp:294] Iteration 38630, lr = 0.002
I0526 07:56:17.501353 15117 solver.cpp:233] Iteration 38640, loss = 0.00963917
I0526 07:56:17.501399 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00963937 (* 1 = 0.00963937 loss)
I0526 07:56:17.501405 15117 sgd_solver.cpp:294] Iteration 38640, lr = 0.002
I0526 07:56:23.790405 15117 solver.cpp:233] Iteration 38650, loss = 0.0103209
I0526 07:56:23.790513 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0103211 (* 1 = 0.0103211 loss)
I0526 07:56:23.790520 15117 sgd_solver.cpp:294] Iteration 38650, lr = 0.002
I0526 07:56:30.078280 15117 solver.cpp:233] Iteration 38660, loss = 0.0283294
I0526 07:56:30.078323 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0283296 (* 1 = 0.0283296 loss)
I0526 07:56:30.078330 15117 sgd_solver.cpp:294] Iteration 38660, lr = 0.002
I0526 07:56:36.368651 15117 solver.cpp:233] Iteration 38670, loss = 0.0211775
I0526 07:56:36.368700 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0211777 (* 1 = 0.0211777 loss)
I0526 07:56:36.368706 15117 sgd_solver.cpp:294] Iteration 38670, lr = 0.002
I0526 07:56:42.658622 15117 solver.cpp:233] Iteration 38680, loss = 0.00937976
I0526 07:56:42.658663 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00937996 (* 1 = 0.00937996 loss)
I0526 07:56:42.658669 15117 sgd_solver.cpp:294] Iteration 38680, lr = 0.002
I0526 07:56:48.947203 15117 solver.cpp:233] Iteration 38690, loss = 0.0115024
I0526 07:56:48.947248 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0115026 (* 1 = 0.0115026 loss)
I0526 07:56:48.947257 15117 sgd_solver.cpp:294] Iteration 38690, lr = 0.002
I0526 07:56:54.635555 15117 solver.cpp:342] Iteration 38700, Testing net (#0)
I0526 07:57:07.422381 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9028
I0526 07:57:07.422420 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.414295 (* 1 = 0.414295 loss)
I0526 07:57:08.019779 15117 solver.cpp:233] Iteration 38700, loss = 0.0484288
I0526 07:57:08.019810 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.048429 (* 1 = 0.048429 loss)
I0526 07:57:08.019817 15117 sgd_solver.cpp:294] Iteration 38700, lr = 0.002
I0526 07:57:14.306669 15117 solver.cpp:233] Iteration 38710, loss = 0.0357835
I0526 07:57:14.306713 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0357837 (* 1 = 0.0357837 loss)
I0526 07:57:14.306720 15117 sgd_solver.cpp:294] Iteration 38710, lr = 0.002
I0526 07:57:20.597888 15117 solver.cpp:233] Iteration 38720, loss = 0.0102333
I0526 07:57:20.597929 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0102335 (* 1 = 0.0102335 loss)
I0526 07:57:20.597936 15117 sgd_solver.cpp:294] Iteration 38720, lr = 0.002
I0526 07:57:26.889955 15117 solver.cpp:233] Iteration 38730, loss = 0.0125872
I0526 07:57:26.890089 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0125874 (* 1 = 0.0125874 loss)
I0526 07:57:26.890099 15117 sgd_solver.cpp:294] Iteration 38730, lr = 0.002
I0526 07:57:33.180901 15117 solver.cpp:233] Iteration 38740, loss = 0.0309039
I0526 07:57:33.180943 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0309041 (* 1 = 0.0309041 loss)
I0526 07:57:33.180949 15117 sgd_solver.cpp:294] Iteration 38740, lr = 0.002
I0526 07:57:39.470502 15117 solver.cpp:233] Iteration 38750, loss = 0.0136363
I0526 07:57:39.470546 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0136365 (* 1 = 0.0136365 loss)
I0526 07:57:39.470553 15117 sgd_solver.cpp:294] Iteration 38750, lr = 0.002
I0526 07:57:45.760160 15117 solver.cpp:233] Iteration 38760, loss = 0.0297708
I0526 07:57:45.760207 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.029771 (* 1 = 0.029771 loss)
I0526 07:57:45.760215 15117 sgd_solver.cpp:294] Iteration 38760, lr = 0.002
I0526 07:57:52.048413 15117 solver.cpp:233] Iteration 38770, loss = 0.0300396
I0526 07:57:52.048454 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0300398 (* 1 = 0.0300398 loss)
I0526 07:57:52.048460 15117 sgd_solver.cpp:294] Iteration 38770, lr = 0.002
I0526 07:57:58.334342 15117 solver.cpp:233] Iteration 38780, loss = 0.0226015
I0526 07:57:58.334570 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0226017 (* 1 = 0.0226017 loss)
I0526 07:57:58.334599 15117 sgd_solver.cpp:294] Iteration 38780, lr = 0.002
I0526 07:58:04.620262 15117 solver.cpp:233] Iteration 38790, loss = 0.0188607
I0526 07:58:04.620307 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0188609 (* 1 = 0.0188609 loss)
I0526 07:58:04.620316 15117 sgd_solver.cpp:294] Iteration 38790, lr = 0.002
I0526 07:58:10.309509 15117 solver.cpp:342] Iteration 38800, Testing net (#0)
I0526 07:58:23.093164 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9026
I0526 07:58:23.093211 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.421903 (* 1 = 0.421903 loss)
I0526 07:58:23.689249 15117 solver.cpp:233] Iteration 38800, loss = 0.0182387
I0526 07:58:23.689290 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0182389 (* 1 = 0.0182389 loss)
I0526 07:58:23.689297 15117 sgd_solver.cpp:294] Iteration 38800, lr = 0.002
I0526 07:58:29.980010 15117 solver.cpp:233] Iteration 38810, loss = 0.0300907
I0526 07:58:29.980275 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0300909 (* 1 = 0.0300909 loss)
I0526 07:58:29.980304 15117 sgd_solver.cpp:294] Iteration 38810, lr = 0.002
I0526 07:58:36.268862 15117 solver.cpp:233] Iteration 38820, loss = 0.00889857
I0526 07:58:36.268903 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00889876 (* 1 = 0.00889876 loss)
I0526 07:58:36.268910 15117 sgd_solver.cpp:294] Iteration 38820, lr = 0.002
I0526 07:58:42.560544 15117 solver.cpp:233] Iteration 38830, loss = 0.00973087
I0526 07:58:42.560570 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00973106 (* 1 = 0.00973106 loss)
I0526 07:58:42.560577 15117 sgd_solver.cpp:294] Iteration 38830, lr = 0.002
I0526 07:58:48.848583 15117 solver.cpp:233] Iteration 38840, loss = 0.0194244
I0526 07:58:48.848640 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0194246 (* 1 = 0.0194246 loss)
I0526 07:58:48.848651 15117 sgd_solver.cpp:294] Iteration 38840, lr = 0.002
I0526 07:58:55.140831 15117 solver.cpp:233] Iteration 38850, loss = 0.0311111
I0526 07:58:55.140873 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0311113 (* 1 = 0.0311113 loss)
I0526 07:58:55.140882 15117 sgd_solver.cpp:294] Iteration 38850, lr = 0.002
I0526 07:59:01.428370 15117 solver.cpp:233] Iteration 38860, loss = 0.0139967
I0526 07:59:01.428593 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0139969 (* 1 = 0.0139969 loss)
I0526 07:59:01.428632 15117 sgd_solver.cpp:294] Iteration 38860, lr = 0.002
I0526 07:59:07.717005 15117 solver.cpp:233] Iteration 38870, loss = 0.0117886
I0526 07:59:07.717049 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0117888 (* 1 = 0.0117888 loss)
I0526 07:59:07.717057 15117 sgd_solver.cpp:294] Iteration 38870, lr = 0.002
I0526 07:59:14.007525 15117 solver.cpp:233] Iteration 38880, loss = 0.0338623
I0526 07:59:14.007572 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0338625 (* 1 = 0.0338625 loss)
I0526 07:59:14.007580 15117 sgd_solver.cpp:294] Iteration 38880, lr = 0.002
I0526 07:59:20.295099 15117 solver.cpp:233] Iteration 38890, loss = 0.0179358
I0526 07:59:20.295140 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.017936 (* 1 = 0.017936 loss)
I0526 07:59:20.295147 15117 sgd_solver.cpp:294] Iteration 38890, lr = 0.002
I0526 07:59:25.987740 15117 solver.cpp:342] Iteration 38900, Testing net (#0)
I0526 07:59:38.777184 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9031
I0526 07:59:38.777315 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.414731 (* 1 = 0.414731 loss)
I0526 07:59:39.374652 15117 solver.cpp:233] Iteration 38900, loss = 0.0124684
I0526 07:59:39.374696 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0124686 (* 1 = 0.0124686 loss)
I0526 07:59:39.374703 15117 sgd_solver.cpp:294] Iteration 38900, lr = 0.002
I0526 07:59:45.664397 15117 solver.cpp:233] Iteration 38910, loss = 0.0126784
I0526 07:59:45.664441 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0126786 (* 1 = 0.0126786 loss)
I0526 07:59:45.664448 15117 sgd_solver.cpp:294] Iteration 38910, lr = 0.002
I0526 07:59:51.952489 15117 solver.cpp:233] Iteration 38920, loss = 0.0157573
I0526 07:59:51.952533 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0157575 (* 1 = 0.0157575 loss)
I0526 07:59:51.952540 15117 sgd_solver.cpp:294] Iteration 38920, lr = 0.002
I0526 07:59:58.238768 15117 solver.cpp:233] Iteration 38930, loss = 0.0454449
I0526 07:59:58.238811 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.045445 (* 1 = 0.045445 loss)
I0526 07:59:58.238818 15117 sgd_solver.cpp:294] Iteration 38930, lr = 0.002
I0526 08:00:04.531023 15117 solver.cpp:233] Iteration 38940, loss = 0.0226147
I0526 08:00:04.531067 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0226149 (* 1 = 0.0226149 loss)
I0526 08:00:04.531075 15117 sgd_solver.cpp:294] Iteration 38940, lr = 0.002
I0526 08:00:10.818781 15117 solver.cpp:233] Iteration 38950, loss = 0.00440058
I0526 08:00:10.819048 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00440077 (* 1 = 0.00440077 loss)
I0526 08:00:10.819078 15117 sgd_solver.cpp:294] Iteration 38950, lr = 0.002
I0526 08:00:17.107964 15117 solver.cpp:233] Iteration 38960, loss = 0.0174056
I0526 08:00:17.108011 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0174058 (* 1 = 0.0174058 loss)
I0526 08:00:17.108017 15117 sgd_solver.cpp:294] Iteration 38960, lr = 0.002
I0526 08:00:23.398324 15117 solver.cpp:233] Iteration 38970, loss = 0.0281821
I0526 08:00:23.398386 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0281823 (* 1 = 0.0281823 loss)
I0526 08:00:23.398394 15117 sgd_solver.cpp:294] Iteration 38970, lr = 0.002
I0526 08:00:29.688031 15117 solver.cpp:233] Iteration 38980, loss = 0.012202
I0526 08:00:29.688074 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0122022 (* 1 = 0.0122022 loss)
I0526 08:00:29.688081 15117 sgd_solver.cpp:294] Iteration 38980, lr = 0.002
I0526 08:00:35.982455 15117 solver.cpp:233] Iteration 38990, loss = 0.00907561
I0526 08:00:35.982497 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0090758 (* 1 = 0.0090758 loss)
I0526 08:00:35.982506 15117 sgd_solver.cpp:294] Iteration 38990, lr = 0.002
I0526 08:00:41.676221 15117 solver.cpp:342] Iteration 39000, Testing net (#0)
I0526 08:00:54.462800 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9012
I0526 08:00:54.462847 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.419871 (* 1 = 0.419871 loss)
I0526 08:00:55.059793 15117 solver.cpp:233] Iteration 39000, loss = 0.00915882
I0526 08:00:55.059828 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00915901 (* 1 = 0.00915901 loss)
I0526 08:00:55.059834 15117 sgd_solver.cpp:294] Iteration 39000, lr = 0.002
I0526 08:01:01.349905 15117 solver.cpp:233] Iteration 39010, loss = 0.0101417
I0526 08:01:01.349933 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0101419 (* 1 = 0.0101419 loss)
I0526 08:01:01.349941 15117 sgd_solver.cpp:294] Iteration 39010, lr = 0.002
I0526 08:01:07.636332 15117 solver.cpp:233] Iteration 39020, loss = 0.0111297
I0526 08:01:07.636373 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0111299 (* 1 = 0.0111299 loss)
I0526 08:01:07.636381 15117 sgd_solver.cpp:294] Iteration 39020, lr = 0.002
I0526 08:01:13.922514 15117 solver.cpp:233] Iteration 39030, loss = 0.0129024
I0526 08:01:13.922754 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0129026 (* 1 = 0.0129026 loss)
I0526 08:01:13.922783 15117 sgd_solver.cpp:294] Iteration 39030, lr = 0.002
I0526 08:01:20.214846 15117 solver.cpp:233] Iteration 39040, loss = 0.0146715
I0526 08:01:20.214890 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0146717 (* 1 = 0.0146717 loss)
I0526 08:01:20.214897 15117 sgd_solver.cpp:294] Iteration 39040, lr = 0.002
I0526 08:01:26.504962 15117 solver.cpp:233] Iteration 39050, loss = 0.0285524
I0526 08:01:26.505007 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0285526 (* 1 = 0.0285526 loss)
I0526 08:01:26.505014 15117 sgd_solver.cpp:294] Iteration 39050, lr = 0.002
I0526 08:01:32.796802 15117 solver.cpp:233] Iteration 39060, loss = 0.0266632
I0526 08:01:32.796846 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0266634 (* 1 = 0.0266634 loss)
I0526 08:01:32.796854 15117 sgd_solver.cpp:294] Iteration 39060, lr = 0.002
I0526 08:01:39.083395 15117 solver.cpp:233] Iteration 39070, loss = 0.00727928
I0526 08:01:39.083437 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00727948 (* 1 = 0.00727948 loss)
I0526 08:01:39.083444 15117 sgd_solver.cpp:294] Iteration 39070, lr = 0.002
I0526 08:01:45.370214 15117 solver.cpp:233] Iteration 39080, loss = 0.00831723
I0526 08:01:45.370472 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00831742 (* 1 = 0.00831742 loss)
I0526 08:01:45.370501 15117 sgd_solver.cpp:294] Iteration 39080, lr = 0.002
I0526 08:01:51.664254 15117 solver.cpp:233] Iteration 39090, loss = 0.0377886
I0526 08:01:51.664297 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0377888 (* 1 = 0.0377888 loss)
I0526 08:01:51.664304 15117 sgd_solver.cpp:294] Iteration 39090, lr = 0.002
I0526 08:01:57.354550 15117 solver.cpp:342] Iteration 39100, Testing net (#0)
I0526 08:02:10.142190 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9046
I0526 08:02:10.142236 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.413044 (* 1 = 0.413044 loss)
I0526 08:02:10.738219 15117 solver.cpp:233] Iteration 39100, loss = 0.0299631
I0526 08:02:10.738256 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0299633 (* 1 = 0.0299633 loss)
I0526 08:02:10.738263 15117 sgd_solver.cpp:294] Iteration 39100, lr = 0.002
I0526 08:02:17.025270 15117 solver.cpp:233] Iteration 39110, loss = 0.010577
I0526 08:02:17.025503 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0105772 (* 1 = 0.0105772 loss)
I0526 08:02:17.025533 15117 sgd_solver.cpp:294] Iteration 39110, lr = 0.002
I0526 08:02:23.313379 15117 solver.cpp:233] Iteration 39120, loss = 0.0421588
I0526 08:02:23.313423 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.042159 (* 1 = 0.042159 loss)
I0526 08:02:23.313431 15117 sgd_solver.cpp:294] Iteration 39120, lr = 0.002
I0526 08:02:29.604356 15117 solver.cpp:233] Iteration 39130, loss = 0.0186257
I0526 08:02:29.604398 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0186258 (* 1 = 0.0186258 loss)
I0526 08:02:29.604403 15117 sgd_solver.cpp:294] Iteration 39130, lr = 0.002
I0526 08:02:35.889618 15117 solver.cpp:233] Iteration 39140, loss = 0.00858867
I0526 08:02:35.889647 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00858886 (* 1 = 0.00858886 loss)
I0526 08:02:35.889663 15117 sgd_solver.cpp:294] Iteration 39140, lr = 0.002
I0526 08:02:42.181871 15117 solver.cpp:233] Iteration 39150, loss = 0.0189111
I0526 08:02:42.181915 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0189113 (* 1 = 0.0189113 loss)
I0526 08:02:42.181921 15117 sgd_solver.cpp:294] Iteration 39150, lr = 0.002
I0526 08:02:48.467594 15117 solver.cpp:233] Iteration 39160, loss = 0.0494918
I0526 08:02:48.467829 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.049492 (* 1 = 0.049492 loss)
I0526 08:02:48.467861 15117 sgd_solver.cpp:294] Iteration 39160, lr = 0.002
I0526 08:02:54.763829 15117 solver.cpp:233] Iteration 39170, loss = 0.0478914
I0526 08:02:54.763876 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0478915 (* 1 = 0.0478915 loss)
I0526 08:02:54.763883 15117 sgd_solver.cpp:294] Iteration 39170, lr = 0.002
I0526 08:03:01.056756 15117 solver.cpp:233] Iteration 39180, loss = 0.0170816
I0526 08:03:01.056785 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0170818 (* 1 = 0.0170818 loss)
I0526 08:03:01.056792 15117 sgd_solver.cpp:294] Iteration 39180, lr = 0.002
I0526 08:03:07.349375 15117 solver.cpp:233] Iteration 39190, loss = 0.0281218
I0526 08:03:07.349419 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.028122 (* 1 = 0.028122 loss)
I0526 08:03:07.349427 15117 sgd_solver.cpp:294] Iteration 39190, lr = 0.002
I0526 08:03:13.043839 15117 solver.cpp:342] Iteration 39200, Testing net (#0)
I0526 08:03:25.830260 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9005
I0526 08:03:25.830504 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.439434 (* 1 = 0.439434 loss)
I0526 08:03:26.428025 15117 solver.cpp:233] Iteration 39200, loss = 0.0405734
I0526 08:03:26.428066 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0405736 (* 1 = 0.0405736 loss)
I0526 08:03:26.428081 15117 sgd_solver.cpp:294] Iteration 39200, lr = 0.002
I0526 08:03:32.721515 15117 solver.cpp:233] Iteration 39210, loss = 0.0105428
I0526 08:03:32.721557 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.010543 (* 1 = 0.010543 loss)
I0526 08:03:32.721563 15117 sgd_solver.cpp:294] Iteration 39210, lr = 0.002
I0526 08:03:39.010207 15117 solver.cpp:233] Iteration 39220, loss = 0.0205817
I0526 08:03:39.010251 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0205819 (* 1 = 0.0205819 loss)
I0526 08:03:39.010257 15117 sgd_solver.cpp:294] Iteration 39220, lr = 0.002
I0526 08:03:45.300911 15117 solver.cpp:233] Iteration 39230, loss = 0.0334106
I0526 08:03:45.300953 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0334108 (* 1 = 0.0334108 loss)
I0526 08:03:45.300961 15117 sgd_solver.cpp:294] Iteration 39230, lr = 0.002
I0526 08:03:51.591835 15117 solver.cpp:233] Iteration 39240, loss = 0.023268
I0526 08:03:51.591884 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0232682 (* 1 = 0.0232682 loss)
I0526 08:03:51.591892 15117 sgd_solver.cpp:294] Iteration 39240, lr = 0.002
I0526 08:03:57.879734 15117 solver.cpp:233] Iteration 39250, loss = 0.0216182
I0526 08:03:57.879983 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0216184 (* 1 = 0.0216184 loss)
I0526 08:03:57.880009 15117 sgd_solver.cpp:294] Iteration 39250, lr = 0.002
I0526 08:04:04.169672 15117 solver.cpp:233] Iteration 39260, loss = 0.0146792
I0526 08:04:04.169718 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0146794 (* 1 = 0.0146794 loss)
I0526 08:04:04.169724 15117 sgd_solver.cpp:294] Iteration 39260, lr = 0.002
I0526 08:04:10.457406 15117 solver.cpp:233] Iteration 39270, loss = 0.024337
I0526 08:04:10.457435 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0243372 (* 1 = 0.0243372 loss)
I0526 08:04:10.457442 15117 sgd_solver.cpp:294] Iteration 39270, lr = 0.002
I0526 08:04:16.744747 15117 solver.cpp:233] Iteration 39280, loss = 0.00671154
I0526 08:04:16.744791 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00671173 (* 1 = 0.00671173 loss)
I0526 08:04:16.744798 15117 sgd_solver.cpp:294] Iteration 39280, lr = 0.002
I0526 08:04:23.035270 15117 solver.cpp:233] Iteration 39290, loss = 0.0234431
I0526 08:04:23.035318 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0234433 (* 1 = 0.0234433 loss)
I0526 08:04:23.035326 15117 sgd_solver.cpp:294] Iteration 39290, lr = 0.002
I0526 08:04:28.724392 15117 solver.cpp:342] Iteration 39300, Testing net (#0)
I0526 08:04:41.508440 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8983
I0526 08:04:41.508486 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.4351 (* 1 = 0.4351 loss)
I0526 08:04:42.106076 15117 solver.cpp:233] Iteration 39300, loss = 0.0165018
I0526 08:04:42.106107 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.016502 (* 1 = 0.016502 loss)
I0526 08:04:42.106115 15117 sgd_solver.cpp:294] Iteration 39300, lr = 0.002
I0526 08:04:48.395797 15117 solver.cpp:233] Iteration 39310, loss = 0.0118156
I0526 08:04:48.395841 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0118158 (* 1 = 0.0118158 loss)
I0526 08:04:48.395849 15117 sgd_solver.cpp:294] Iteration 39310, lr = 0.002
I0526 08:04:54.687916 15117 solver.cpp:233] Iteration 39320, loss = 0.0368542
I0526 08:04:54.687948 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0368544 (* 1 = 0.0368544 loss)
I0526 08:04:54.687955 15117 sgd_solver.cpp:294] Iteration 39320, lr = 0.002
I0526 08:05:00.976836 15117 solver.cpp:233] Iteration 39330, loss = 0.00755191
I0526 08:05:00.976984 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0075521 (* 1 = 0.0075521 loss)
I0526 08:05:00.976994 15117 sgd_solver.cpp:294] Iteration 39330, lr = 0.002
I0526 08:05:07.268378 15117 solver.cpp:233] Iteration 39340, loss = 0.0352979
I0526 08:05:07.268419 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0352981 (* 1 = 0.0352981 loss)
I0526 08:05:07.268432 15117 sgd_solver.cpp:294] Iteration 39340, lr = 0.002
I0526 08:05:13.559129 15117 solver.cpp:233] Iteration 39350, loss = 0.00900128
I0526 08:05:13.559170 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00900147 (* 1 = 0.00900147 loss)
I0526 08:05:13.559177 15117 sgd_solver.cpp:294] Iteration 39350, lr = 0.002
I0526 08:05:19.848029 15117 solver.cpp:233] Iteration 39360, loss = 0.0331694
I0526 08:05:19.848068 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0331696 (* 1 = 0.0331696 loss)
I0526 08:05:19.848075 15117 sgd_solver.cpp:294] Iteration 39360, lr = 0.002
I0526 08:05:26.136868 15117 solver.cpp:233] Iteration 39370, loss = 0.0210344
I0526 08:05:26.136909 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0210346 (* 1 = 0.0210346 loss)
I0526 08:05:26.136916 15117 sgd_solver.cpp:294] Iteration 39370, lr = 0.002
I0526 08:05:32.423013 15117 solver.cpp:233] Iteration 39380, loss = 0.0110208
I0526 08:05:32.423184 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.011021 (* 1 = 0.011021 loss)
I0526 08:05:32.423194 15117 sgd_solver.cpp:294] Iteration 39380, lr = 0.002
I0526 08:05:38.709942 15117 solver.cpp:233] Iteration 39390, loss = 0.0260395
I0526 08:05:38.709969 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0260396 (* 1 = 0.0260396 loss)
I0526 08:05:38.709975 15117 sgd_solver.cpp:294] Iteration 39390, lr = 0.002
I0526 08:05:44.400336 15117 solver.cpp:342] Iteration 39400, Testing net (#0)
I0526 08:05:57.183401 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9039
I0526 08:05:57.183449 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.421318 (* 1 = 0.421318 loss)
I0526 08:05:57.779706 15117 solver.cpp:233] Iteration 39400, loss = 0.0344638
I0526 08:05:57.779738 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.034464 (* 1 = 0.034464 loss)
I0526 08:05:57.779745 15117 sgd_solver.cpp:294] Iteration 39400, lr = 0.002
I0526 08:06:04.068017 15117 solver.cpp:233] Iteration 39410, loss = 0.0138918
I0526 08:06:04.068142 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.013892 (* 1 = 0.013892 loss)
I0526 08:06:04.068151 15117 sgd_solver.cpp:294] Iteration 39410, lr = 0.002
I0526 08:06:10.355309 15117 solver.cpp:233] Iteration 39420, loss = 0.00902775
I0526 08:06:10.355351 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00902795 (* 1 = 0.00902795 loss)
I0526 08:06:10.355358 15117 sgd_solver.cpp:294] Iteration 39420, lr = 0.002
I0526 08:06:16.645745 15117 solver.cpp:233] Iteration 39430, loss = 0.0235605
I0526 08:06:16.645787 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0235607 (* 1 = 0.0235607 loss)
I0526 08:06:16.645793 15117 sgd_solver.cpp:294] Iteration 39430, lr = 0.002
I0526 08:06:22.933668 15117 solver.cpp:233] Iteration 39440, loss = 0.0117117
I0526 08:06:22.933709 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0117119 (* 1 = 0.0117119 loss)
I0526 08:06:22.933717 15117 sgd_solver.cpp:294] Iteration 39440, lr = 0.002
I0526 08:06:29.221776 15117 solver.cpp:233] Iteration 39450, loss = 0.0192672
I0526 08:06:29.221822 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0192674 (* 1 = 0.0192674 loss)
I0526 08:06:29.221829 15117 sgd_solver.cpp:294] Iteration 39450, lr = 0.002
I0526 08:06:35.509513 15117 solver.cpp:233] Iteration 39460, loss = 0.00746166
I0526 08:06:35.509728 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00746186 (* 1 = 0.00746186 loss)
I0526 08:06:35.509760 15117 sgd_solver.cpp:294] Iteration 39460, lr = 0.002
I0526 08:06:41.806733 15117 solver.cpp:233] Iteration 39470, loss = 0.0222697
I0526 08:06:41.806776 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0222699 (* 1 = 0.0222699 loss)
I0526 08:06:41.806782 15117 sgd_solver.cpp:294] Iteration 39470, lr = 0.002
I0526 08:06:48.096177 15117 solver.cpp:233] Iteration 39480, loss = 0.00910542
I0526 08:06:48.096221 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00910561 (* 1 = 0.00910561 loss)
I0526 08:06:48.096233 15117 sgd_solver.cpp:294] Iteration 39480, lr = 0.002
I0526 08:06:54.385754 15117 solver.cpp:233] Iteration 39490, loss = 0.0372831
I0526 08:06:54.385797 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0372833 (* 1 = 0.0372833 loss)
I0526 08:06:54.385804 15117 sgd_solver.cpp:294] Iteration 39490, lr = 0.002
I0526 08:07:00.079661 15117 solver.cpp:342] Iteration 39500, Testing net (#0)
I0526 08:07:12.866976 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9009
I0526 08:07:12.867228 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.440447 (* 1 = 0.440447 loss)
I0526 08:07:13.468082 15117 solver.cpp:233] Iteration 39500, loss = 0.00744182
I0526 08:07:13.468145 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00744202 (* 1 = 0.00744202 loss)
I0526 08:07:13.468158 15117 sgd_solver.cpp:294] Iteration 39500, lr = 0.002
I0526 08:07:19.759673 15117 solver.cpp:233] Iteration 39510, loss = 0.0360175
I0526 08:07:19.759716 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0360177 (* 1 = 0.0360177 loss)
I0526 08:07:19.759722 15117 sgd_solver.cpp:294] Iteration 39510, lr = 0.002
I0526 08:07:26.046648 15117 solver.cpp:233] Iteration 39520, loss = 0.0114568
I0526 08:07:26.046705 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.011457 (* 1 = 0.011457 loss)
I0526 08:07:26.046713 15117 sgd_solver.cpp:294] Iteration 39520, lr = 0.002
I0526 08:07:32.335638 15117 solver.cpp:233] Iteration 39530, loss = 0.00449892
I0526 08:07:32.335677 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00449912 (* 1 = 0.00449912 loss)
I0526 08:07:32.335685 15117 sgd_solver.cpp:294] Iteration 39530, lr = 0.002
I0526 08:07:38.622906 15117 solver.cpp:233] Iteration 39540, loss = 0.00973015
I0526 08:07:38.622937 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00973035 (* 1 = 0.00973035 loss)
I0526 08:07:38.622944 15117 sgd_solver.cpp:294] Iteration 39540, lr = 0.002
I0526 08:07:44.913177 15117 solver.cpp:233] Iteration 39550, loss = 0.0148891
I0526 08:07:44.913305 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0148893 (* 1 = 0.0148893 loss)
I0526 08:07:44.913313 15117 sgd_solver.cpp:294] Iteration 39550, lr = 0.002
I0526 08:07:51.200330 15117 solver.cpp:233] Iteration 39560, loss = 0.0217976
I0526 08:07:51.200371 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0217978 (* 1 = 0.0217978 loss)
I0526 08:07:51.200378 15117 sgd_solver.cpp:294] Iteration 39560, lr = 0.002
I0526 08:07:57.488519 15117 solver.cpp:233] Iteration 39570, loss = 0.0331753
I0526 08:07:57.488562 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0331755 (* 1 = 0.0331755 loss)
I0526 08:07:57.488569 15117 sgd_solver.cpp:294] Iteration 39570, lr = 0.002
I0526 08:08:03.780805 15117 solver.cpp:233] Iteration 39580, loss = 0.0219573
I0526 08:08:03.780833 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0219575 (* 1 = 0.0219575 loss)
I0526 08:08:03.780838 15117 sgd_solver.cpp:294] Iteration 39580, lr = 0.002
I0526 08:08:10.066346 15117 solver.cpp:233] Iteration 39590, loss = 0.0059998
I0526 08:08:10.066406 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00600001 (* 1 = 0.00600001 loss)
I0526 08:08:10.066413 15117 sgd_solver.cpp:294] Iteration 39590, lr = 0.002
I0526 08:08:15.759670 15117 solver.cpp:342] Iteration 39600, Testing net (#0)
I0526 08:08:28.544195 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.904
I0526 08:08:28.544241 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.440351 (* 1 = 0.440351 loss)
I0526 08:08:29.141224 15117 solver.cpp:233] Iteration 39600, loss = 0.0203818
I0526 08:08:29.141259 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.020382 (* 1 = 0.020382 loss)
I0526 08:08:29.141266 15117 sgd_solver.cpp:294] Iteration 39600, lr = 0.002
I0526 08:08:35.427619 15117 solver.cpp:233] Iteration 39610, loss = 0.0112941
I0526 08:08:35.427667 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0112943 (* 1 = 0.0112943 loss)
I0526 08:08:35.427675 15117 sgd_solver.cpp:294] Iteration 39610, lr = 0.002
I0526 08:08:41.715848 15117 solver.cpp:233] Iteration 39620, loss = 0.0357447
I0526 08:08:41.715893 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0357449 (* 1 = 0.0357449 loss)
I0526 08:08:41.715900 15117 sgd_solver.cpp:294] Iteration 39620, lr = 0.002
I0526 08:08:48.005542 15117 solver.cpp:233] Iteration 39630, loss = 0.0203578
I0526 08:08:48.005779 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.020358 (* 1 = 0.020358 loss)
I0526 08:08:48.005810 15117 sgd_solver.cpp:294] Iteration 39630, lr = 0.002
I0526 08:08:54.298115 15117 solver.cpp:233] Iteration 39640, loss = 0.0115855
I0526 08:08:54.298161 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0115857 (* 1 = 0.0115857 loss)
I0526 08:08:54.298167 15117 sgd_solver.cpp:294] Iteration 39640, lr = 0.002
I0526 08:09:00.588639 15117 solver.cpp:233] Iteration 39650, loss = 0.0195956
I0526 08:09:00.588681 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0195958 (* 1 = 0.0195958 loss)
I0526 08:09:00.588688 15117 sgd_solver.cpp:294] Iteration 39650, lr = 0.002
I0526 08:09:06.878561 15117 solver.cpp:233] Iteration 39660, loss = 0.0174503
I0526 08:09:06.878602 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0174505 (* 1 = 0.0174505 loss)
I0526 08:09:06.878610 15117 sgd_solver.cpp:294] Iteration 39660, lr = 0.002
I0526 08:09:13.163506 15117 solver.cpp:233] Iteration 39670, loss = 0.0284894
I0526 08:09:13.163534 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0284896 (* 1 = 0.0284896 loss)
I0526 08:09:13.163542 15117 sgd_solver.cpp:294] Iteration 39670, lr = 0.002
I0526 08:09:19.453152 15117 solver.cpp:233] Iteration 39680, loss = 0.018429
I0526 08:09:19.453372 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0184292 (* 1 = 0.0184292 loss)
I0526 08:09:19.453397 15117 sgd_solver.cpp:294] Iteration 39680, lr = 0.002
I0526 08:09:25.743984 15117 solver.cpp:233] Iteration 39690, loss = 0.0133816
I0526 08:09:25.744032 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0133819 (* 1 = 0.0133819 loss)
I0526 08:09:25.744040 15117 sgd_solver.cpp:294] Iteration 39690, lr = 0.002
I0526 08:09:31.436910 15117 solver.cpp:342] Iteration 39700, Testing net (#0)
I0526 08:09:44.229166 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9027
I0526 08:09:44.229212 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.429437 (* 1 = 0.429437 loss)
I0526 08:09:44.825801 15117 solver.cpp:233] Iteration 39700, loss = 0.0286488
I0526 08:09:44.825842 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0286491 (* 1 = 0.0286491 loss)
I0526 08:09:44.825850 15117 sgd_solver.cpp:294] Iteration 39700, lr = 0.002
I0526 08:09:51.115284 15117 solver.cpp:233] Iteration 39710, loss = 0.00610061
I0526 08:09:51.115432 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00610082 (* 1 = 0.00610082 loss)
I0526 08:09:51.115442 15117 sgd_solver.cpp:294] Iteration 39710, lr = 0.002
I0526 08:09:57.405709 15117 solver.cpp:233] Iteration 39720, loss = 0.016931
I0526 08:09:57.405735 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0169312 (* 1 = 0.0169312 loss)
I0526 08:09:57.405742 15117 sgd_solver.cpp:294] Iteration 39720, lr = 0.002
I0526 08:10:03.694396 15117 solver.cpp:233] Iteration 39730, loss = 0.00959581
I0526 08:10:03.694439 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00959602 (* 1 = 0.00959602 loss)
I0526 08:10:03.694447 15117 sgd_solver.cpp:294] Iteration 39730, lr = 0.002
I0526 08:10:09.987354 15117 solver.cpp:233] Iteration 39740, loss = 0.0113454
I0526 08:10:09.987396 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0113456 (* 1 = 0.0113456 loss)
I0526 08:10:09.987403 15117 sgd_solver.cpp:294] Iteration 39740, lr = 0.002
I0526 08:10:16.279726 15117 solver.cpp:233] Iteration 39750, loss = 0.0287708
I0526 08:10:16.279778 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.028771 (* 1 = 0.028771 loss)
I0526 08:10:16.279785 15117 sgd_solver.cpp:294] Iteration 39750, lr = 0.002
I0526 08:10:22.567714 15117 solver.cpp:233] Iteration 39760, loss = 0.00839029
I0526 08:10:22.567862 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0083905 (* 1 = 0.0083905 loss)
I0526 08:10:22.567872 15117 sgd_solver.cpp:294] Iteration 39760, lr = 0.002
I0526 08:10:28.857162 15117 solver.cpp:233] Iteration 39770, loss = 0.010987
I0526 08:10:28.857203 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0109872 (* 1 = 0.0109872 loss)
I0526 08:10:28.857210 15117 sgd_solver.cpp:294] Iteration 39770, lr = 0.002
I0526 08:10:35.149425 15117 solver.cpp:233] Iteration 39780, loss = 0.0314488
I0526 08:10:35.149468 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.031449 (* 1 = 0.031449 loss)
I0526 08:10:35.149476 15117 sgd_solver.cpp:294] Iteration 39780, lr = 0.002
I0526 08:10:41.434371 15117 solver.cpp:233] Iteration 39790, loss = 0.0296441
I0526 08:10:41.434425 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0296443 (* 1 = 0.0296443 loss)
I0526 08:10:41.434433 15117 sgd_solver.cpp:294] Iteration 39790, lr = 0.002
I0526 08:10:47.124024 15117 solver.cpp:342] Iteration 39800, Testing net (#0)
I0526 08:10:59.907618 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9044
I0526 08:10:59.907686 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.429188 (* 1 = 0.429188 loss)
I0526 08:11:00.504626 15117 solver.cpp:233] Iteration 39800, loss = 0.0227712
I0526 08:11:00.504653 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0227714 (* 1 = 0.0227714 loss)
I0526 08:11:00.504660 15117 sgd_solver.cpp:294] Iteration 39800, lr = 0.002
I0526 08:11:06.792383 15117 solver.cpp:233] Iteration 39810, loss = 0.026592
I0526 08:11:06.792428 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0265922 (* 1 = 0.0265922 loss)
I0526 08:11:06.792435 15117 sgd_solver.cpp:294] Iteration 39810, lr = 0.002
I0526 08:11:13.083811 15117 solver.cpp:233] Iteration 39820, loss = 0.0177898
I0526 08:11:13.083852 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.01779 (* 1 = 0.01779 loss)
I0526 08:11:13.083858 15117 sgd_solver.cpp:294] Iteration 39820, lr = 0.002
I0526 08:11:19.370739 15117 solver.cpp:233] Iteration 39830, loss = 0.0244873
I0526 08:11:19.370781 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0244875 (* 1 = 0.0244875 loss)
I0526 08:11:19.370789 15117 sgd_solver.cpp:294] Iteration 39830, lr = 0.002
I0526 08:11:25.656390 15117 solver.cpp:233] Iteration 39840, loss = 0.0186758
I0526 08:11:25.656419 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.018676 (* 1 = 0.018676 loss)
I0526 08:11:25.656425 15117 sgd_solver.cpp:294] Iteration 39840, lr = 0.002
I0526 08:11:31.944355 15117 solver.cpp:233] Iteration 39850, loss = 0.0306079
I0526 08:11:31.944576 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0306081 (* 1 = 0.0306081 loss)
I0526 08:11:31.944603 15117 sgd_solver.cpp:294] Iteration 39850, lr = 0.002
I0526 08:11:38.235960 15117 solver.cpp:233] Iteration 39860, loss = 0.0384053
I0526 08:11:38.236002 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0384055 (* 1 = 0.0384055 loss)
I0526 08:11:38.236011 15117 sgd_solver.cpp:294] Iteration 39860, lr = 0.002
I0526 08:11:44.524482 15117 solver.cpp:233] Iteration 39870, loss = 0.0243367
I0526 08:11:44.524524 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0243369 (* 1 = 0.0243369 loss)
I0526 08:11:44.524533 15117 sgd_solver.cpp:294] Iteration 39870, lr = 0.002
I0526 08:11:50.811383 15117 solver.cpp:233] Iteration 39880, loss = 0.0153485
I0526 08:11:50.811427 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0153487 (* 1 = 0.0153487 loss)
I0526 08:11:50.811435 15117 sgd_solver.cpp:294] Iteration 39880, lr = 0.002
I0526 08:11:57.099905 15117 solver.cpp:233] Iteration 39890, loss = 0.0100907
I0526 08:11:57.099946 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0100909 (* 1 = 0.0100909 loss)
I0526 08:11:57.099954 15117 sgd_solver.cpp:294] Iteration 39890, lr = 0.002
I0526 08:12:02.792171 15117 solver.cpp:342] Iteration 39900, Testing net (#0)
I0526 08:12:15.573581 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.904
I0526 08:12:15.573623 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.424092 (* 1 = 0.424092 loss)
I0526 08:12:16.170013 15117 solver.cpp:233] Iteration 39900, loss = 0.00443788
I0526 08:12:16.170053 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00443809 (* 1 = 0.00443809 loss)
I0526 08:12:16.170059 15117 sgd_solver.cpp:294] Iteration 39900, lr = 0.002
I0526 08:12:22.461664 15117 solver.cpp:233] Iteration 39910, loss = 0.0311441
I0526 08:12:22.461709 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0311444 (* 1 = 0.0311444 loss)
I0526 08:12:22.461715 15117 sgd_solver.cpp:294] Iteration 39910, lr = 0.002
I0526 08:12:28.751528 15117 solver.cpp:233] Iteration 39920, loss = 0.0644944
I0526 08:12:28.751570 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0644946 (* 1 = 0.0644946 loss)
I0526 08:12:28.751576 15117 sgd_solver.cpp:294] Iteration 39920, lr = 0.002
I0526 08:12:35.042026 15117 solver.cpp:233] Iteration 39930, loss = 0.0130797
I0526 08:12:35.042243 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0130799 (* 1 = 0.0130799 loss)
I0526 08:12:35.042273 15117 sgd_solver.cpp:294] Iteration 39930, lr = 0.002
I0526 08:12:41.332085 15117 solver.cpp:233] Iteration 39940, loss = 0.00679374
I0526 08:12:41.332129 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00679395 (* 1 = 0.00679395 loss)
I0526 08:12:41.332135 15117 sgd_solver.cpp:294] Iteration 39940, lr = 0.002
I0526 08:12:47.622189 15117 solver.cpp:233] Iteration 39950, loss = 0.0161755
I0526 08:12:47.622232 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0161757 (* 1 = 0.0161757 loss)
I0526 08:12:47.622239 15117 sgd_solver.cpp:294] Iteration 39950, lr = 0.002
I0526 08:12:53.909612 15117 solver.cpp:233] Iteration 39960, loss = 0.00722558
I0526 08:12:53.909656 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00722579 (* 1 = 0.00722579 loss)
I0526 08:12:53.909663 15117 sgd_solver.cpp:294] Iteration 39960, lr = 0.002
I0526 08:13:00.197952 15117 solver.cpp:233] Iteration 39970, loss = 0.0138448
I0526 08:13:00.197993 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.013845 (* 1 = 0.013845 loss)
I0526 08:13:00.197999 15117 sgd_solver.cpp:294] Iteration 39970, lr = 0.002
I0526 08:13:06.486584 15117 solver.cpp:233] Iteration 39980, loss = 0.01988
I0526 08:13:06.487071 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0198802 (* 1 = 0.0198802 loss)
I0526 08:13:06.487078 15117 sgd_solver.cpp:294] Iteration 39980, lr = 0.002
I0526 08:13:12.777688 15117 solver.cpp:233] Iteration 39990, loss = 0.0312266
I0526 08:13:12.777725 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0312268 (* 1 = 0.0312268 loss)
I0526 08:13:12.777734 15117 sgd_solver.cpp:294] Iteration 39990, lr = 0.002
I0526 08:13:18.469260 15117 solver.cpp:342] Iteration 40000, Testing net (#0)
I0526 08:13:31.260402 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9021
I0526 08:13:31.260443 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.425732 (* 1 = 0.425732 loss)
I0526 08:13:31.858237 15117 solver.cpp:233] Iteration 40000, loss = 0.0404703
I0526 08:13:31.858279 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0404705 (* 1 = 0.0404705 loss)
I0526 08:13:31.858286 15117 sgd_solver.cpp:294] Iteration 40000, lr = 0.002
I0526 08:13:38.144140 15117 solver.cpp:233] Iteration 40010, loss = 0.0199986
I0526 08:13:38.144392 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0199989 (* 1 = 0.0199989 loss)
I0526 08:13:38.144423 15117 sgd_solver.cpp:294] Iteration 40010, lr = 0.002
I0526 08:13:44.436697 15117 solver.cpp:233] Iteration 40020, loss = 0.00696924
I0526 08:13:44.436739 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00696944 (* 1 = 0.00696944 loss)
I0526 08:13:44.436746 15117 sgd_solver.cpp:294] Iteration 40020, lr = 0.002
I0526 08:13:50.727054 15117 solver.cpp:233] Iteration 40030, loss = 0.0106623
I0526 08:13:50.727099 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0106625 (* 1 = 0.0106625 loss)
I0526 08:13:50.727107 15117 sgd_solver.cpp:294] Iteration 40030, lr = 0.002
I0526 08:13:57.012979 15117 solver.cpp:233] Iteration 40040, loss = 0.0430808
I0526 08:13:57.013021 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.043081 (* 1 = 0.043081 loss)
I0526 08:13:57.013028 15117 sgd_solver.cpp:294] Iteration 40040, lr = 0.002
I0526 08:14:03.301807 15117 solver.cpp:233] Iteration 40050, loss = 0.0193671
I0526 08:14:03.301853 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0193673 (* 1 = 0.0193673 loss)
I0526 08:14:03.301862 15117 sgd_solver.cpp:294] Iteration 40050, lr = 0.002
I0526 08:14:09.591821 15117 solver.cpp:233] Iteration 40060, loss = 0.0131949
I0526 08:14:09.592059 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0131951 (* 1 = 0.0131951 loss)
I0526 08:14:09.592088 15117 sgd_solver.cpp:294] Iteration 40060, lr = 0.002
I0526 08:14:15.881763 15117 solver.cpp:233] Iteration 40070, loss = 0.0215242
I0526 08:14:15.881803 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0215244 (* 1 = 0.0215244 loss)
I0526 08:14:15.881810 15117 sgd_solver.cpp:294] Iteration 40070, lr = 0.002
I0526 08:14:22.172279 15117 solver.cpp:233] Iteration 40080, loss = 0.0421383
I0526 08:14:22.172322 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0421385 (* 1 = 0.0421385 loss)
I0526 08:14:22.172329 15117 sgd_solver.cpp:294] Iteration 40080, lr = 0.002
I0526 08:14:28.461990 15117 solver.cpp:233] Iteration 40090, loss = 0.00861399
I0526 08:14:28.462033 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0086142 (* 1 = 0.0086142 loss)
I0526 08:14:28.462039 15117 sgd_solver.cpp:294] Iteration 40090, lr = 0.002
I0526 08:14:34.152441 15117 solver.cpp:342] Iteration 40100, Testing net (#0)
I0526 08:14:46.939415 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9029
I0526 08:14:46.939633 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.431725 (* 1 = 0.431725 loss)
I0526 08:14:47.535187 15117 solver.cpp:233] Iteration 40100, loss = 0.0254063
I0526 08:14:47.535213 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0254065 (* 1 = 0.0254065 loss)
I0526 08:14:47.535220 15117 sgd_solver.cpp:294] Iteration 40100, lr = 0.002
I0526 08:14:53.820811 15117 solver.cpp:233] Iteration 40110, loss = 0.0153075
I0526 08:14:53.820852 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0153077 (* 1 = 0.0153077 loss)
I0526 08:14:53.820858 15117 sgd_solver.cpp:294] Iteration 40110, lr = 0.002
I0526 08:15:00.107553 15117 solver.cpp:233] Iteration 40120, loss = 0.0133928
I0526 08:15:00.107594 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.013393 (* 1 = 0.013393 loss)
I0526 08:15:00.107601 15117 sgd_solver.cpp:294] Iteration 40120, lr = 0.002
I0526 08:15:06.393476 15117 solver.cpp:233] Iteration 40130, loss = 0.0144873
I0526 08:15:06.393520 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0144875 (* 1 = 0.0144875 loss)
I0526 08:15:06.393527 15117 sgd_solver.cpp:294] Iteration 40130, lr = 0.002
I0526 08:15:12.682025 15117 solver.cpp:233] Iteration 40140, loss = 0.0149072
I0526 08:15:12.682066 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0149074 (* 1 = 0.0149074 loss)
I0526 08:15:12.682072 15117 sgd_solver.cpp:294] Iteration 40140, lr = 0.002
I0526 08:15:18.972465 15117 solver.cpp:233] Iteration 40150, loss = 0.0101452
I0526 08:15:18.972693 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0101454 (* 1 = 0.0101454 loss)
I0526 08:15:18.972734 15117 sgd_solver.cpp:294] Iteration 40150, lr = 0.002
I0526 08:15:25.267207 15117 solver.cpp:233] Iteration 40160, loss = 0.0100085
I0526 08:15:25.267241 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0100087 (* 1 = 0.0100087 loss)
I0526 08:15:25.267248 15117 sgd_solver.cpp:294] Iteration 40160, lr = 0.002
I0526 08:15:31.553042 15117 solver.cpp:233] Iteration 40170, loss = 0.0152258
I0526 08:15:31.553092 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.015226 (* 1 = 0.015226 loss)
I0526 08:15:31.553099 15117 sgd_solver.cpp:294] Iteration 40170, lr = 0.002
I0526 08:15:37.844573 15117 solver.cpp:233] Iteration 40180, loss = 0.0201223
I0526 08:15:37.844617 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0201225 (* 1 = 0.0201225 loss)
I0526 08:15:37.844625 15117 sgd_solver.cpp:294] Iteration 40180, lr = 0.002
I0526 08:15:44.130985 15117 solver.cpp:233] Iteration 40190, loss = 0.00716096
I0526 08:15:44.131028 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00716117 (* 1 = 0.00716117 loss)
I0526 08:15:44.131036 15117 sgd_solver.cpp:294] Iteration 40190, lr = 0.002
I0526 08:15:49.824002 15117 solver.cpp:342] Iteration 40200, Testing net (#0)
I0526 08:16:02.604089 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9041
I0526 08:16:02.604135 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.422176 (* 1 = 0.422176 loss)
I0526 08:16:03.201586 15117 solver.cpp:233] Iteration 40200, loss = 0.0158443
I0526 08:16:03.201627 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0158445 (* 1 = 0.0158445 loss)
I0526 08:16:03.201634 15117 sgd_solver.cpp:294] Iteration 40200, lr = 0.002
I0526 08:16:09.486820 15117 solver.cpp:233] Iteration 40210, loss = 0.00814165
I0526 08:16:09.486850 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00814185 (* 1 = 0.00814185 loss)
I0526 08:16:09.486856 15117 sgd_solver.cpp:294] Iteration 40210, lr = 0.002
I0526 08:16:15.777220 15117 solver.cpp:233] Iteration 40220, loss = 0.00524135
I0526 08:16:15.777261 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00524154 (* 1 = 0.00524154 loss)
I0526 08:16:15.777268 15117 sgd_solver.cpp:294] Iteration 40220, lr = 0.002
I0526 08:16:22.069162 15117 solver.cpp:233] Iteration 40230, loss = 0.00948972
I0526 08:16:22.069386 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00948991 (* 1 = 0.00948991 loss)
I0526 08:16:22.069414 15117 sgd_solver.cpp:294] Iteration 40230, lr = 0.002
I0526 08:16:28.359489 15117 solver.cpp:233] Iteration 40240, loss = 0.0159544
I0526 08:16:28.359535 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0159546 (* 1 = 0.0159546 loss)
I0526 08:16:28.359542 15117 sgd_solver.cpp:294] Iteration 40240, lr = 0.002
I0526 08:16:34.640954 15117 solver.cpp:233] Iteration 40250, loss = 0.0205105
I0526 08:16:34.641002 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0205107 (* 1 = 0.0205107 loss)
I0526 08:16:34.641011 15117 sgd_solver.cpp:294] Iteration 40250, lr = 0.002
I0526 08:16:40.929747 15117 solver.cpp:233] Iteration 40260, loss = 0.0191466
I0526 08:16:40.929795 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0191468 (* 1 = 0.0191468 loss)
I0526 08:16:40.929801 15117 sgd_solver.cpp:294] Iteration 40260, lr = 0.002
I0526 08:16:47.218215 15117 solver.cpp:233] Iteration 40270, loss = 0.0294846
I0526 08:16:47.218257 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0294848 (* 1 = 0.0294848 loss)
I0526 08:16:47.218264 15117 sgd_solver.cpp:294] Iteration 40270, lr = 0.002
I0526 08:16:53.507385 15117 solver.cpp:233] Iteration 40280, loss = 0.0199439
I0526 08:16:53.507607 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0199441 (* 1 = 0.0199441 loss)
I0526 08:16:53.507637 15117 sgd_solver.cpp:294] Iteration 40280, lr = 0.002
I0526 08:16:59.798497 15117 solver.cpp:233] Iteration 40290, loss = 0.0255362
I0526 08:16:59.798540 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0255364 (* 1 = 0.0255364 loss)
I0526 08:16:59.798552 15117 sgd_solver.cpp:294] Iteration 40290, lr = 0.002
I0526 08:17:05.484424 15117 solver.cpp:342] Iteration 40300, Testing net (#0)
I0526 08:17:18.269351 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9015
I0526 08:17:18.269397 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.427938 (* 1 = 0.427938 loss)
I0526 08:17:18.866770 15117 solver.cpp:233] Iteration 40300, loss = 0.022182
I0526 08:17:18.866803 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0221822 (* 1 = 0.0221822 loss)
I0526 08:17:18.866811 15117 sgd_solver.cpp:294] Iteration 40300, lr = 0.002
I0526 08:17:25.159739 15117 solver.cpp:233] Iteration 40310, loss = 0.00855356
I0526 08:17:25.159910 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00855376 (* 1 = 0.00855376 loss)
I0526 08:17:25.159919 15117 sgd_solver.cpp:294] Iteration 40310, lr = 0.002
I0526 08:17:31.455384 15117 solver.cpp:233] Iteration 40320, loss = 0.053648
I0526 08:17:31.455428 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0536482 (* 1 = 0.0536482 loss)
I0526 08:17:31.455435 15117 sgd_solver.cpp:294] Iteration 40320, lr = 0.002
I0526 08:17:37.745277 15117 solver.cpp:233] Iteration 40330, loss = 0.0104395
I0526 08:17:37.745321 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0104397 (* 1 = 0.0104397 loss)
I0526 08:17:37.745327 15117 sgd_solver.cpp:294] Iteration 40330, lr = 0.002
I0526 08:17:44.033329 15117 solver.cpp:233] Iteration 40340, loss = 0.0329915
I0526 08:17:44.033370 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0329917 (* 1 = 0.0329917 loss)
I0526 08:17:44.033376 15117 sgd_solver.cpp:294] Iteration 40340, lr = 0.002
I0526 08:17:50.323153 15117 solver.cpp:233] Iteration 40350, loss = 0.0184215
I0526 08:17:50.323200 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0184217 (* 1 = 0.0184217 loss)
I0526 08:17:50.323207 15117 sgd_solver.cpp:294] Iteration 40350, lr = 0.002
I0526 08:17:56.613956 15117 solver.cpp:233] Iteration 40360, loss = 0.019429
I0526 08:17:56.614173 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0194292 (* 1 = 0.0194292 loss)
I0526 08:17:56.614204 15117 sgd_solver.cpp:294] Iteration 40360, lr = 0.002
I0526 08:18:02.902828 15117 solver.cpp:233] Iteration 40370, loss = 0.0274444
I0526 08:18:02.902873 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0274446 (* 1 = 0.0274446 loss)
I0526 08:18:02.902879 15117 sgd_solver.cpp:294] Iteration 40370, lr = 0.002
I0526 08:18:09.188647 15117 solver.cpp:233] Iteration 40380, loss = 0.00575841
I0526 08:18:09.188716 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00575861 (* 1 = 0.00575861 loss)
I0526 08:18:09.188730 15117 sgd_solver.cpp:294] Iteration 40380, lr = 0.002
I0526 08:18:15.470912 15117 solver.cpp:233] Iteration 40390, loss = 0.0124621
I0526 08:18:15.470960 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0124623 (* 1 = 0.0124623 loss)
I0526 08:18:15.470968 15117 sgd_solver.cpp:294] Iteration 40390, lr = 0.002
I0526 08:18:21.158053 15117 solver.cpp:342] Iteration 40400, Testing net (#0)
I0526 08:18:33.943714 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9015
I0526 08:18:33.943843 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.429164 (* 1 = 0.429164 loss)
I0526 08:18:34.539751 15117 solver.cpp:233] Iteration 40400, loss = 0.015339
I0526 08:18:34.539815 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0153392 (* 1 = 0.0153392 loss)
I0526 08:18:34.539829 15117 sgd_solver.cpp:294] Iteration 40400, lr = 0.002
I0526 08:18:40.826052 15117 solver.cpp:233] Iteration 40410, loss = 0.0188266
I0526 08:18:40.826097 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0188268 (* 1 = 0.0188268 loss)
I0526 08:18:40.826104 15117 sgd_solver.cpp:294] Iteration 40410, lr = 0.002
I0526 08:18:47.113486 15117 solver.cpp:233] Iteration 40420, loss = 0.0149189
I0526 08:18:47.113528 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0149191 (* 1 = 0.0149191 loss)
I0526 08:18:47.113540 15117 sgd_solver.cpp:294] Iteration 40420, lr = 0.002
I0526 08:18:53.403265 15117 solver.cpp:233] Iteration 40430, loss = 0.0233014
I0526 08:18:53.403307 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0233016 (* 1 = 0.0233016 loss)
I0526 08:18:53.403314 15117 sgd_solver.cpp:294] Iteration 40430, lr = 0.002
I0526 08:18:59.686583 15117 solver.cpp:233] Iteration 40440, loss = 0.00316376
I0526 08:18:59.686622 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00316395 (* 1 = 0.00316395 loss)
I0526 08:18:59.686630 15117 sgd_solver.cpp:294] Iteration 40440, lr = 0.002
I0526 08:19:05.976177 15117 solver.cpp:233] Iteration 40450, loss = 0.01456
I0526 08:19:05.976435 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0145602 (* 1 = 0.0145602 loss)
I0526 08:19:05.976465 15117 sgd_solver.cpp:294] Iteration 40450, lr = 0.002
I0526 08:19:12.262276 15117 solver.cpp:233] Iteration 40460, loss = 0.0159141
I0526 08:19:12.262320 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0159143 (* 1 = 0.0159143 loss)
I0526 08:19:12.262326 15117 sgd_solver.cpp:294] Iteration 40460, lr = 0.002
I0526 08:19:18.544778 15117 solver.cpp:233] Iteration 40470, loss = 0.0129724
I0526 08:19:18.544821 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0129726 (* 1 = 0.0129726 loss)
I0526 08:19:18.544828 15117 sgd_solver.cpp:294] Iteration 40470, lr = 0.002
I0526 08:19:24.834015 15117 solver.cpp:233] Iteration 40480, loss = 0.0137235
I0526 08:19:24.834058 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0137237 (* 1 = 0.0137237 loss)
I0526 08:19:24.834064 15117 sgd_solver.cpp:294] Iteration 40480, lr = 0.002
I0526 08:19:31.125327 15117 solver.cpp:233] Iteration 40490, loss = 0.010818
I0526 08:19:31.125355 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0108182 (* 1 = 0.0108182 loss)
I0526 08:19:31.125361 15117 sgd_solver.cpp:294] Iteration 40490, lr = 0.002
I0526 08:19:36.816802 15117 solver.cpp:342] Iteration 40500, Testing net (#0)
I0526 08:19:49.598151 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9027
I0526 08:19:49.598193 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.427398 (* 1 = 0.427398 loss)
I0526 08:19:50.195017 15117 solver.cpp:233] Iteration 40500, loss = 0.0123363
I0526 08:19:50.195061 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0123365 (* 1 = 0.0123365 loss)
I0526 08:19:50.195068 15117 sgd_solver.cpp:294] Iteration 40500, lr = 0.002
I0526 08:19:56.485956 15117 solver.cpp:233] Iteration 40510, loss = 0.0109349
I0526 08:19:56.485997 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0109351 (* 1 = 0.0109351 loss)
I0526 08:19:56.486004 15117 sgd_solver.cpp:294] Iteration 40510, lr = 0.002
I0526 08:20:02.775679 15117 solver.cpp:233] Iteration 40520, loss = 0.017436
I0526 08:20:02.775718 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0174362 (* 1 = 0.0174362 loss)
I0526 08:20:02.775725 15117 sgd_solver.cpp:294] Iteration 40520, lr = 0.002
I0526 08:20:09.061193 15117 solver.cpp:233] Iteration 40530, loss = 0.011458
I0526 08:20:09.061326 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0114582 (* 1 = 0.0114582 loss)
I0526 08:20:09.061334 15117 sgd_solver.cpp:294] Iteration 40530, lr = 0.002
I0526 08:20:15.349977 15117 solver.cpp:233] Iteration 40540, loss = 0.0219193
I0526 08:20:15.350019 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0219195 (* 1 = 0.0219195 loss)
I0526 08:20:15.350026 15117 sgd_solver.cpp:294] Iteration 40540, lr = 0.002
I0526 08:20:21.638810 15117 solver.cpp:233] Iteration 40550, loss = 0.0209149
I0526 08:20:21.638856 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0209151 (* 1 = 0.0209151 loss)
I0526 08:20:21.638864 15117 sgd_solver.cpp:294] Iteration 40550, lr = 0.002
I0526 08:20:27.927806 15117 solver.cpp:233] Iteration 40560, loss = 0.0211121
I0526 08:20:27.927853 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0211123 (* 1 = 0.0211123 loss)
I0526 08:20:27.927860 15117 sgd_solver.cpp:294] Iteration 40560, lr = 0.002
I0526 08:20:34.218931 15117 solver.cpp:233] Iteration 40570, loss = 0.0418451
I0526 08:20:34.218972 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0418453 (* 1 = 0.0418453 loss)
I0526 08:20:34.218979 15117 sgd_solver.cpp:294] Iteration 40570, lr = 0.002
I0526 08:20:40.509388 15117 solver.cpp:233] Iteration 40580, loss = 0.00556113
I0526 08:20:40.509497 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00556132 (* 1 = 0.00556132 loss)
I0526 08:20:40.509505 15117 sgd_solver.cpp:294] Iteration 40580, lr = 0.002
I0526 08:20:46.797860 15117 solver.cpp:233] Iteration 40590, loss = 0.00608018
I0526 08:20:46.797900 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00608037 (* 1 = 0.00608037 loss)
I0526 08:20:46.797907 15117 sgd_solver.cpp:294] Iteration 40590, lr = 0.002
I0526 08:20:52.489045 15117 solver.cpp:342] Iteration 40600, Testing net (#0)
I0526 08:21:05.273144 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8991
I0526 08:21:05.273183 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.444239 (* 1 = 0.444239 loss)
I0526 08:21:05.869920 15117 solver.cpp:233] Iteration 40600, loss = 0.0133143
I0526 08:21:05.869961 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0133145 (* 1 = 0.0133145 loss)
I0526 08:21:05.869967 15117 sgd_solver.cpp:294] Iteration 40600, lr = 0.002
I0526 08:21:12.159296 15117 solver.cpp:233] Iteration 40610, loss = 0.0157812
I0526 08:21:12.159409 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0157814 (* 1 = 0.0157814 loss)
I0526 08:21:12.159417 15117 sgd_solver.cpp:294] Iteration 40610, lr = 0.002
I0526 08:21:18.446741 15117 solver.cpp:233] Iteration 40620, loss = 0.0133295
I0526 08:21:18.446781 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0133297 (* 1 = 0.0133297 loss)
I0526 08:21:18.446789 15117 sgd_solver.cpp:294] Iteration 40620, lr = 0.002
I0526 08:21:24.735424 15117 solver.cpp:233] Iteration 40630, loss = 0.0309689
I0526 08:21:24.735469 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0309691 (* 1 = 0.0309691 loss)
I0526 08:21:24.735476 15117 sgd_solver.cpp:294] Iteration 40630, lr = 0.002
I0526 08:21:31.025192 15117 solver.cpp:233] Iteration 40640, loss = 0.0190485
I0526 08:21:31.025231 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0190486 (* 1 = 0.0190486 loss)
I0526 08:21:31.025238 15117 sgd_solver.cpp:294] Iteration 40640, lr = 0.002
I0526 08:21:37.311377 15117 solver.cpp:233] Iteration 40650, loss = 0.0138312
I0526 08:21:37.311419 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0138314 (* 1 = 0.0138314 loss)
I0526 08:21:37.311426 15117 sgd_solver.cpp:294] Iteration 40650, lr = 0.002
I0526 08:21:43.599886 15117 solver.cpp:233] Iteration 40660, loss = 0.0168773
I0526 08:21:43.600008 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0168775 (* 1 = 0.0168775 loss)
I0526 08:21:43.600018 15117 sgd_solver.cpp:294] Iteration 40660, lr = 0.002
I0526 08:21:49.889926 15117 solver.cpp:233] Iteration 40670, loss = 0.039017
I0526 08:21:49.889967 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0390172 (* 1 = 0.0390172 loss)
I0526 08:21:49.889974 15117 sgd_solver.cpp:294] Iteration 40670, lr = 0.002
I0526 08:21:56.177826 15117 solver.cpp:233] Iteration 40680, loss = 0.0182104
I0526 08:21:56.177867 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0182106 (* 1 = 0.0182106 loss)
I0526 08:21:56.177875 15117 sgd_solver.cpp:294] Iteration 40680, lr = 0.002
I0526 08:22:02.466975 15117 solver.cpp:233] Iteration 40690, loss = 0.00710518
I0526 08:22:02.467017 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00710537 (* 1 = 0.00710537 loss)
I0526 08:22:02.467023 15117 sgd_solver.cpp:294] Iteration 40690, lr = 0.002
I0526 08:22:08.157377 15117 solver.cpp:342] Iteration 40700, Testing net (#0)
I0526 08:22:20.949132 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9033
I0526 08:22:20.949326 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.423774 (* 1 = 0.423774 loss)
I0526 08:22:21.546267 15117 solver.cpp:233] Iteration 40700, loss = 0.0336914
I0526 08:22:21.546309 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0336916 (* 1 = 0.0336916 loss)
I0526 08:22:21.546316 15117 sgd_solver.cpp:294] Iteration 40700, lr = 0.002
I0526 08:22:27.834523 15117 solver.cpp:233] Iteration 40710, loss = 0.0187936
I0526 08:22:27.834565 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0187938 (* 1 = 0.0187938 loss)
I0526 08:22:27.834573 15117 sgd_solver.cpp:294] Iteration 40710, lr = 0.002
I0526 08:22:34.120822 15117 solver.cpp:233] Iteration 40720, loss = 0.00850522
I0526 08:22:34.120863 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00850542 (* 1 = 0.00850542 loss)
I0526 08:22:34.120870 15117 sgd_solver.cpp:294] Iteration 40720, lr = 0.002
I0526 08:22:40.408793 15117 solver.cpp:233] Iteration 40730, loss = 0.00487779
I0526 08:22:40.408848 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00487799 (* 1 = 0.00487799 loss)
I0526 08:22:40.408854 15117 sgd_solver.cpp:294] Iteration 40730, lr = 0.002
I0526 08:22:46.699245 15117 solver.cpp:233] Iteration 40740, loss = 0.0458494
I0526 08:22:46.699297 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0458496 (* 1 = 0.0458496 loss)
I0526 08:22:46.699304 15117 sgd_solver.cpp:294] Iteration 40740, lr = 0.002
I0526 08:22:52.986621 15117 solver.cpp:233] Iteration 40750, loss = 0.011536
I0526 08:22:52.986824 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0115362 (* 1 = 0.0115362 loss)
I0526 08:22:52.986853 15117 sgd_solver.cpp:294] Iteration 40750, lr = 0.002
I0526 08:22:59.281627 15117 solver.cpp:233] Iteration 40760, loss = 0.0128803
I0526 08:22:59.281672 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0128804 (* 1 = 0.0128804 loss)
I0526 08:22:59.281679 15117 sgd_solver.cpp:294] Iteration 40760, lr = 0.002
I0526 08:23:05.572839 15117 solver.cpp:233] Iteration 40770, loss = 0.0476849
I0526 08:23:05.572880 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0476851 (* 1 = 0.0476851 loss)
I0526 08:23:05.572887 15117 sgd_solver.cpp:294] Iteration 40770, lr = 0.002
I0526 08:23:11.866191 15117 solver.cpp:233] Iteration 40780, loss = 0.0172775
I0526 08:23:11.866231 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0172777 (* 1 = 0.0172777 loss)
I0526 08:23:11.866238 15117 sgd_solver.cpp:294] Iteration 40780, lr = 0.002
I0526 08:23:18.158766 15117 solver.cpp:233] Iteration 40790, loss = 0.0108176
I0526 08:23:18.158807 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0108178 (* 1 = 0.0108178 loss)
I0526 08:23:18.158813 15117 sgd_solver.cpp:294] Iteration 40790, lr = 0.002
I0526 08:23:23.847865 15117 solver.cpp:342] Iteration 40800, Testing net (#0)
I0526 08:23:36.630812 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8995
I0526 08:23:36.630859 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.428393 (* 1 = 0.428393 loss)
I0526 08:23:37.228590 15117 solver.cpp:233] Iteration 40800, loss = 0.0281136
I0526 08:23:37.228629 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0281138 (* 1 = 0.0281138 loss)
I0526 08:23:37.228636 15117 sgd_solver.cpp:294] Iteration 40800, lr = 0.002
I0526 08:23:43.516791 15117 solver.cpp:233] Iteration 40810, loss = 0.0122144
I0526 08:23:43.516832 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0122146 (* 1 = 0.0122146 loss)
I0526 08:23:43.516839 15117 sgd_solver.cpp:294] Iteration 40810, lr = 0.002
I0526 08:23:49.803691 15117 solver.cpp:233] Iteration 40820, loss = 0.00756662
I0526 08:23:49.803732 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00756681 (* 1 = 0.00756681 loss)
I0526 08:23:49.803740 15117 sgd_solver.cpp:294] Iteration 40820, lr = 0.002
I0526 08:23:56.093488 15117 solver.cpp:233] Iteration 40830, loss = 0.0353169
I0526 08:23:56.093644 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0353171 (* 1 = 0.0353171 loss)
I0526 08:23:56.093654 15117 sgd_solver.cpp:294] Iteration 40830, lr = 0.002
I0526 08:24:02.380391 15117 solver.cpp:233] Iteration 40840, loss = 0.0508004
I0526 08:24:02.380431 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0508006 (* 1 = 0.0508006 loss)
I0526 08:24:02.380439 15117 sgd_solver.cpp:294] Iteration 40840, lr = 0.002
I0526 08:24:08.672755 15117 solver.cpp:233] Iteration 40850, loss = 0.0136013
I0526 08:24:08.672799 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0136015 (* 1 = 0.0136015 loss)
I0526 08:24:08.672806 15117 sgd_solver.cpp:294] Iteration 40850, lr = 0.002
I0526 08:24:14.962599 15117 solver.cpp:233] Iteration 40860, loss = 0.022021
I0526 08:24:14.962642 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0220211 (* 1 = 0.0220211 loss)
I0526 08:24:14.962651 15117 sgd_solver.cpp:294] Iteration 40860, lr = 0.002
I0526 08:24:21.254256 15117 solver.cpp:233] Iteration 40870, loss = 0.02079
I0526 08:24:21.254299 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0207902 (* 1 = 0.0207902 loss)
I0526 08:24:21.254307 15117 sgd_solver.cpp:294] Iteration 40870, lr = 0.002
I0526 08:24:27.542790 15117 solver.cpp:233] Iteration 40880, loss = 0.00792466
I0526 08:24:27.543023 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00792485 (* 1 = 0.00792485 loss)
I0526 08:24:27.543052 15117 sgd_solver.cpp:294] Iteration 40880, lr = 0.002
I0526 08:24:33.832617 15117 solver.cpp:233] Iteration 40890, loss = 0.0243238
I0526 08:24:33.832660 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.024324 (* 1 = 0.024324 loss)
I0526 08:24:33.832669 15117 sgd_solver.cpp:294] Iteration 40890, lr = 0.002
I0526 08:24:39.527482 15117 solver.cpp:342] Iteration 40900, Testing net (#0)
I0526 08:24:52.308832 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9037
I0526 08:24:52.308881 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.411748 (* 1 = 0.411748 loss)
I0526 08:24:52.904948 15117 solver.cpp:233] Iteration 40900, loss = 0.0318403
I0526 08:24:52.904988 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0318405 (* 1 = 0.0318405 loss)
I0526 08:24:52.904994 15117 sgd_solver.cpp:294] Iteration 40900, lr = 0.002
I0526 08:24:59.194389 15117 solver.cpp:233] Iteration 40910, loss = 0.011637
I0526 08:24:59.194592 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0116372 (* 1 = 0.0116372 loss)
I0526 08:24:59.194622 15117 sgd_solver.cpp:294] Iteration 40910, lr = 0.002
I0526 08:25:05.488075 15117 solver.cpp:233] Iteration 40920, loss = 0.00389301
I0526 08:25:05.488121 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00389321 (* 1 = 0.00389321 loss)
I0526 08:25:05.488128 15117 sgd_solver.cpp:294] Iteration 40920, lr = 0.002
I0526 08:25:11.779024 15117 solver.cpp:233] Iteration 40930, loss = 0.00873932
I0526 08:25:11.779062 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00873952 (* 1 = 0.00873952 loss)
I0526 08:25:11.779069 15117 sgd_solver.cpp:294] Iteration 40930, lr = 0.002
I0526 08:25:18.064321 15117 solver.cpp:233] Iteration 40940, loss = 0.0344689
I0526 08:25:18.064362 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0344691 (* 1 = 0.0344691 loss)
I0526 08:25:18.064368 15117 sgd_solver.cpp:294] Iteration 40940, lr = 0.002
I0526 08:25:24.352754 15117 solver.cpp:233] Iteration 40950, loss = 0.0239083
I0526 08:25:24.352795 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0239085 (* 1 = 0.0239085 loss)
I0526 08:25:24.352802 15117 sgd_solver.cpp:294] Iteration 40950, lr = 0.002
I0526 08:25:30.641151 15117 solver.cpp:233] Iteration 40960, loss = 0.0185791
I0526 08:25:30.641305 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0185793 (* 1 = 0.0185793 loss)
I0526 08:25:30.641314 15117 sgd_solver.cpp:294] Iteration 40960, lr = 0.002
I0526 08:25:36.924577 15117 solver.cpp:233] Iteration 40970, loss = 0.00564179
I0526 08:25:36.924621 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00564199 (* 1 = 0.00564199 loss)
I0526 08:25:36.924629 15117 sgd_solver.cpp:294] Iteration 40970, lr = 0.002
I0526 08:25:43.210896 15117 solver.cpp:233] Iteration 40980, loss = 0.0229384
I0526 08:25:43.210938 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0229386 (* 1 = 0.0229386 loss)
I0526 08:25:43.210947 15117 sgd_solver.cpp:294] Iteration 40980, lr = 0.002
I0526 08:25:49.500663 15117 solver.cpp:233] Iteration 40990, loss = 0.00457411
I0526 08:25:49.500689 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00457431 (* 1 = 0.00457431 loss)
I0526 08:25:49.500696 15117 sgd_solver.cpp:294] Iteration 40990, lr = 0.002
I0526 08:25:55.188294 15117 solver.cpp:342] Iteration 41000, Testing net (#0)
I0526 08:26:07.981274 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9012
I0526 08:26:07.981500 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.428239 (* 1 = 0.428239 loss)
I0526 08:26:08.580952 15117 solver.cpp:233] Iteration 41000, loss = 0.0238867
I0526 08:26:08.580992 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0238869 (* 1 = 0.0238869 loss)
I0526 08:26:08.580999 15117 sgd_solver.cpp:294] Iteration 41000, lr = 0.002
I0526 08:26:14.871052 15117 solver.cpp:233] Iteration 41010, loss = 0.00725129
I0526 08:26:14.871086 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00725149 (* 1 = 0.00725149 loss)
I0526 08:26:14.871093 15117 sgd_solver.cpp:294] Iteration 41010, lr = 0.002
I0526 08:26:21.164857 15117 solver.cpp:233] Iteration 41020, loss = 0.0118031
I0526 08:26:21.164902 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0118033 (* 1 = 0.0118033 loss)
I0526 08:26:21.164908 15117 sgd_solver.cpp:294] Iteration 41020, lr = 0.002
I0526 08:26:27.449859 15117 solver.cpp:233] Iteration 41030, loss = 0.0105733
I0526 08:26:27.449903 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0105735 (* 1 = 0.0105735 loss)
I0526 08:26:27.449910 15117 sgd_solver.cpp:294] Iteration 41030, lr = 0.002
I0526 08:26:33.741693 15117 solver.cpp:233] Iteration 41040, loss = 0.0102604
I0526 08:26:33.741740 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0102606 (* 1 = 0.0102606 loss)
I0526 08:26:33.741747 15117 sgd_solver.cpp:294] Iteration 41040, lr = 0.002
I0526 08:26:40.030633 15117 solver.cpp:233] Iteration 41050, loss = 0.0244765
I0526 08:26:40.030829 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0244767 (* 1 = 0.0244767 loss)
I0526 08:26:40.030859 15117 sgd_solver.cpp:294] Iteration 41050, lr = 0.002
I0526 08:26:46.318034 15117 solver.cpp:233] Iteration 41060, loss = 0.0389456
I0526 08:26:46.318084 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0389458 (* 1 = 0.0389458 loss)
I0526 08:26:46.318092 15117 sgd_solver.cpp:294] Iteration 41060, lr = 0.002
I0526 08:26:52.604055 15117 solver.cpp:233] Iteration 41070, loss = 0.0197717
I0526 08:26:52.604091 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0197719 (* 1 = 0.0197719 loss)
I0526 08:26:52.604099 15117 sgd_solver.cpp:294] Iteration 41070, lr = 0.002
I0526 08:26:58.891777 15117 solver.cpp:233] Iteration 41080, loss = 0.0133265
I0526 08:26:58.891821 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0133266 (* 1 = 0.0133266 loss)
I0526 08:26:58.891829 15117 sgd_solver.cpp:294] Iteration 41080, lr = 0.002
I0526 08:27:05.182157 15117 solver.cpp:233] Iteration 41090, loss = 0.0119414
I0526 08:27:05.182199 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0119416 (* 1 = 0.0119416 loss)
I0526 08:27:05.182204 15117 sgd_solver.cpp:294] Iteration 41090, lr = 0.002
I0526 08:27:10.876039 15117 solver.cpp:342] Iteration 41100, Testing net (#0)
I0526 08:27:23.659348 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9021
I0526 08:27:23.659399 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.438551 (* 1 = 0.438551 loss)
I0526 08:27:24.256434 15117 solver.cpp:233] Iteration 41100, loss = 0.00994097
I0526 08:27:24.256467 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00994116 (* 1 = 0.00994116 loss)
I0526 08:27:24.256474 15117 sgd_solver.cpp:294] Iteration 41100, lr = 0.002
I0526 08:27:30.547260 15117 solver.cpp:233] Iteration 41110, loss = 0.0189831
I0526 08:27:30.547302 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0189833 (* 1 = 0.0189833 loss)
I0526 08:27:30.547310 15117 sgd_solver.cpp:294] Iteration 41110, lr = 0.002
I0526 08:27:36.837738 15117 solver.cpp:233] Iteration 41120, loss = 0.0081099
I0526 08:27:36.837780 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0081101 (* 1 = 0.0081101 loss)
I0526 08:27:36.837787 15117 sgd_solver.cpp:294] Iteration 41120, lr = 0.002
I0526 08:27:43.127895 15117 solver.cpp:233] Iteration 41130, loss = 0.0109859
I0526 08:27:43.128082 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0109861 (* 1 = 0.0109861 loss)
I0526 08:27:43.128118 15117 sgd_solver.cpp:294] Iteration 41130, lr = 0.002
I0526 08:27:49.420667 15117 solver.cpp:233] Iteration 41140, loss = 0.0165871
I0526 08:27:49.420711 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0165873 (* 1 = 0.0165873 loss)
I0526 08:27:49.420719 15117 sgd_solver.cpp:294] Iteration 41140, lr = 0.002
I0526 08:27:55.710705 15117 solver.cpp:233] Iteration 41150, loss = 0.037801
I0526 08:27:55.710746 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0378012 (* 1 = 0.0378012 loss)
I0526 08:27:55.710753 15117 sgd_solver.cpp:294] Iteration 41150, lr = 0.002
I0526 08:28:02.003278 15117 solver.cpp:233] Iteration 41160, loss = 0.00978549
I0526 08:28:02.003322 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0097857 (* 1 = 0.0097857 loss)
I0526 08:28:02.003329 15117 sgd_solver.cpp:294] Iteration 41160, lr = 0.002
I0526 08:28:08.293007 15117 solver.cpp:233] Iteration 41170, loss = 0.016366
I0526 08:28:08.293048 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0163662 (* 1 = 0.0163662 loss)
I0526 08:28:08.293056 15117 sgd_solver.cpp:294] Iteration 41170, lr = 0.002
I0526 08:28:14.583881 15117 solver.cpp:233] Iteration 41180, loss = 0.0130986
I0526 08:28:14.584094 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0130988 (* 1 = 0.0130988 loss)
I0526 08:28:14.584120 15117 sgd_solver.cpp:294] Iteration 41180, lr = 0.002
I0526 08:28:20.871796 15117 solver.cpp:233] Iteration 41190, loss = 0.0153771
I0526 08:28:20.871850 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0153773 (* 1 = 0.0153773 loss)
I0526 08:28:20.871857 15117 sgd_solver.cpp:294] Iteration 41190, lr = 0.002
I0526 08:28:26.567327 15117 solver.cpp:342] Iteration 41200, Testing net (#0)
I0526 08:28:39.351310 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9024
I0526 08:28:39.351356 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.436211 (* 1 = 0.436211 loss)
I0526 08:28:39.947886 15117 solver.cpp:233] Iteration 41200, loss = 0.0111899
I0526 08:28:39.947923 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0111901 (* 1 = 0.0111901 loss)
I0526 08:28:39.947931 15117 sgd_solver.cpp:294] Iteration 41200, lr = 0.002
I0526 08:28:46.235249 15117 solver.cpp:233] Iteration 41210, loss = 0.00878453
I0526 08:28:46.235468 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00878473 (* 1 = 0.00878473 loss)
I0526 08:28:46.235498 15117 sgd_solver.cpp:294] Iteration 41210, lr = 0.002
I0526 08:28:52.522055 15117 solver.cpp:233] Iteration 41220, loss = 0.0170438
I0526 08:28:52.522101 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.017044 (* 1 = 0.017044 loss)
I0526 08:28:52.522109 15117 sgd_solver.cpp:294] Iteration 41220, lr = 0.002
I0526 08:28:58.809559 15117 solver.cpp:233] Iteration 41230, loss = 0.0190764
I0526 08:28:58.809603 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0190766 (* 1 = 0.0190766 loss)
I0526 08:28:58.809617 15117 sgd_solver.cpp:294] Iteration 41230, lr = 0.002
I0526 08:29:05.097558 15117 solver.cpp:233] Iteration 41240, loss = 0.0398892
I0526 08:29:05.097599 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0398894 (* 1 = 0.0398894 loss)
I0526 08:29:05.097605 15117 sgd_solver.cpp:294] Iteration 41240, lr = 0.002
I0526 08:29:11.385083 15117 solver.cpp:233] Iteration 41250, loss = 0.0221786
I0526 08:29:11.385125 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0221788 (* 1 = 0.0221788 loss)
I0526 08:29:11.385133 15117 sgd_solver.cpp:294] Iteration 41250, lr = 0.002
I0526 08:29:17.671983 15117 solver.cpp:233] Iteration 41260, loss = 0.0101323
I0526 08:29:17.672220 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0101325 (* 1 = 0.0101325 loss)
I0526 08:29:17.672250 15117 sgd_solver.cpp:294] Iteration 41260, lr = 0.002
I0526 08:29:23.965989 15117 solver.cpp:233] Iteration 41270, loss = 0.016878
I0526 08:29:23.966032 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0168782 (* 1 = 0.0168782 loss)
I0526 08:29:23.966040 15117 sgd_solver.cpp:294] Iteration 41270, lr = 0.002
I0526 08:29:30.255988 15117 solver.cpp:233] Iteration 41280, loss = 0.00892987
I0526 08:29:30.256029 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00893007 (* 1 = 0.00893007 loss)
I0526 08:29:30.256036 15117 sgd_solver.cpp:294] Iteration 41280, lr = 0.002
I0526 08:29:36.543527 15117 solver.cpp:233] Iteration 41290, loss = 0.00961094
I0526 08:29:36.543570 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00961114 (* 1 = 0.00961114 loss)
I0526 08:29:36.543576 15117 sgd_solver.cpp:294] Iteration 41290, lr = 0.002
I0526 08:29:42.236610 15117 solver.cpp:342] Iteration 41300, Testing net (#0)
I0526 08:29:55.015661 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9046
I0526 08:29:55.015873 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.439672 (* 1 = 0.439672 loss)
I0526 08:29:55.613343 15117 solver.cpp:233] Iteration 41300, loss = 0.0164377
I0526 08:29:55.613385 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0164379 (* 1 = 0.0164379 loss)
I0526 08:29:55.613392 15117 sgd_solver.cpp:294] Iteration 41300, lr = 0.002
I0526 08:30:01.902456 15117 solver.cpp:233] Iteration 41310, loss = 0.00646681
I0526 08:30:01.902499 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00646701 (* 1 = 0.00646701 loss)
I0526 08:30:01.902505 15117 sgd_solver.cpp:294] Iteration 41310, lr = 0.002
I0526 08:30:08.187954 15117 solver.cpp:233] Iteration 41320, loss = 0.0140511
I0526 08:30:08.187997 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0140513 (* 1 = 0.0140513 loss)
I0526 08:30:08.188004 15117 sgd_solver.cpp:294] Iteration 41320, lr = 0.002
I0526 08:30:14.475262 15117 solver.cpp:233] Iteration 41330, loss = 0.0284169
I0526 08:30:14.475303 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0284171 (* 1 = 0.0284171 loss)
I0526 08:30:14.475311 15117 sgd_solver.cpp:294] Iteration 41330, lr = 0.002
I0526 08:30:20.764745 15117 solver.cpp:233] Iteration 41340, loss = 0.0208854
I0526 08:30:20.764775 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0208855 (* 1 = 0.0208855 loss)
I0526 08:30:20.764781 15117 sgd_solver.cpp:294] Iteration 41340, lr = 0.002
I0526 08:30:27.057451 15117 solver.cpp:233] Iteration 41350, loss = 0.0334007
I0526 08:30:27.057582 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0334009 (* 1 = 0.0334009 loss)
I0526 08:30:27.057590 15117 sgd_solver.cpp:294] Iteration 41350, lr = 0.002
I0526 08:30:33.347998 15117 solver.cpp:233] Iteration 41360, loss = 0.0233585
I0526 08:30:33.348040 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0233587 (* 1 = 0.0233587 loss)
I0526 08:30:33.348047 15117 sgd_solver.cpp:294] Iteration 41360, lr = 0.002
I0526 08:30:39.637797 15117 solver.cpp:233] Iteration 41370, loss = 0.00506433
I0526 08:30:39.637845 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00506453 (* 1 = 0.00506453 loss)
I0526 08:30:39.637851 15117 sgd_solver.cpp:294] Iteration 41370, lr = 0.002
I0526 08:30:45.926947 15117 solver.cpp:233] Iteration 41380, loss = 0.0137179
I0526 08:30:45.926990 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0137181 (* 1 = 0.0137181 loss)
I0526 08:30:45.926996 15117 sgd_solver.cpp:294] Iteration 41380, lr = 0.002
I0526 08:30:52.213135 15117 solver.cpp:233] Iteration 41390, loss = 0.0160708
I0526 08:30:52.213177 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.016071 (* 1 = 0.016071 loss)
I0526 08:30:52.213184 15117 sgd_solver.cpp:294] Iteration 41390, lr = 0.002
I0526 08:30:57.901989 15117 solver.cpp:342] Iteration 41400, Testing net (#0)
I0526 08:31:10.683267 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9024
I0526 08:31:10.683312 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.422664 (* 1 = 0.422664 loss)
I0526 08:31:11.280777 15117 solver.cpp:233] Iteration 41400, loss = 0.0123572
I0526 08:31:11.280809 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0123574 (* 1 = 0.0123574 loss)
I0526 08:31:11.280817 15117 sgd_solver.cpp:294] Iteration 41400, lr = 0.002
I0526 08:31:17.570631 15117 solver.cpp:233] Iteration 41410, loss = 0.00782602
I0526 08:31:17.570673 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00782623 (* 1 = 0.00782623 loss)
I0526 08:31:17.570680 15117 sgd_solver.cpp:294] Iteration 41410, lr = 0.002
I0526 08:31:23.859575 15117 solver.cpp:233] Iteration 41420, loss = 0.0198478
I0526 08:31:23.859614 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.019848 (* 1 = 0.019848 loss)
I0526 08:31:23.859621 15117 sgd_solver.cpp:294] Iteration 41420, lr = 0.002
I0526 08:31:30.148944 15117 solver.cpp:233] Iteration 41430, loss = 0.0485395
I0526 08:31:30.149153 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0485397 (* 1 = 0.0485397 loss)
I0526 08:31:30.149180 15117 sgd_solver.cpp:294] Iteration 41430, lr = 0.002
I0526 08:31:36.442031 15117 solver.cpp:233] Iteration 41440, loss = 0.00876459
I0526 08:31:36.442075 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0087648 (* 1 = 0.0087648 loss)
I0526 08:31:36.442081 15117 sgd_solver.cpp:294] Iteration 41440, lr = 0.002
I0526 08:31:42.732750 15117 solver.cpp:233] Iteration 41450, loss = 0.0231452
I0526 08:31:42.732791 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0231454 (* 1 = 0.0231454 loss)
I0526 08:31:42.732798 15117 sgd_solver.cpp:294] Iteration 41450, lr = 0.002
I0526 08:31:49.019212 15117 solver.cpp:233] Iteration 41460, loss = 0.0269931
I0526 08:31:49.019256 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0269933 (* 1 = 0.0269933 loss)
I0526 08:31:49.019263 15117 sgd_solver.cpp:294] Iteration 41460, lr = 0.002
I0526 08:31:55.310744 15117 solver.cpp:233] Iteration 41470, loss = 0.0263168
I0526 08:31:55.310786 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.026317 (* 1 = 0.026317 loss)
I0526 08:31:55.310792 15117 sgd_solver.cpp:294] Iteration 41470, lr = 0.002
I0526 08:32:01.597750 15117 solver.cpp:233] Iteration 41480, loss = 0.0193221
I0526 08:32:01.597976 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0193223 (* 1 = 0.0193223 loss)
I0526 08:32:01.598006 15117 sgd_solver.cpp:294] Iteration 41480, lr = 0.002
I0526 08:32:07.887677 15117 solver.cpp:233] Iteration 41490, loss = 0.0102132
I0526 08:32:07.887717 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0102134 (* 1 = 0.0102134 loss)
I0526 08:32:07.887724 15117 sgd_solver.cpp:294] Iteration 41490, lr = 0.002
I0526 08:32:13.581512 15117 solver.cpp:342] Iteration 41500, Testing net (#0)
I0526 08:32:26.363755 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9041
I0526 08:32:26.363795 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.429385 (* 1 = 0.429385 loss)
I0526 08:32:26.959460 15117 solver.cpp:233] Iteration 41500, loss = 0.0265887
I0526 08:32:26.959504 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0265889 (* 1 = 0.0265889 loss)
I0526 08:32:26.959511 15117 sgd_solver.cpp:294] Iteration 41500, lr = 0.002
I0526 08:32:33.246243 15117 solver.cpp:233] Iteration 41510, loss = 0.0190512
I0526 08:32:33.246417 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0190514 (* 1 = 0.0190514 loss)
I0526 08:32:33.246426 15117 sgd_solver.cpp:294] Iteration 41510, lr = 0.002
I0526 08:32:39.537863 15117 solver.cpp:233] Iteration 41520, loss = 0.00895881
I0526 08:32:39.537904 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00895902 (* 1 = 0.00895902 loss)
I0526 08:32:39.537910 15117 sgd_solver.cpp:294] Iteration 41520, lr = 0.002
I0526 08:32:45.825237 15117 solver.cpp:233] Iteration 41530, loss = 0.0222804
I0526 08:32:45.825280 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0222807 (* 1 = 0.0222807 loss)
I0526 08:32:45.825287 15117 sgd_solver.cpp:294] Iteration 41530, lr = 0.002
I0526 08:32:52.108932 15117 solver.cpp:233] Iteration 41540, loss = 0.00423318
I0526 08:32:52.108975 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00423338 (* 1 = 0.00423338 loss)
I0526 08:32:52.108981 15117 sgd_solver.cpp:294] Iteration 41540, lr = 0.002
I0526 08:32:58.399606 15117 solver.cpp:233] Iteration 41550, loss = 0.00988508
I0526 08:32:58.399652 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0098853 (* 1 = 0.0098853 loss)
I0526 08:32:58.399659 15117 sgd_solver.cpp:294] Iteration 41550, lr = 0.002
I0526 08:33:04.685495 15117 solver.cpp:233] Iteration 41560, loss = 0.0110244
I0526 08:33:04.685621 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0110246 (* 1 = 0.0110246 loss)
I0526 08:33:04.685631 15117 sgd_solver.cpp:294] Iteration 41560, lr = 0.002
I0526 08:33:10.970757 15117 solver.cpp:233] Iteration 41570, loss = 0.0254478
I0526 08:33:10.970796 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.025448 (* 1 = 0.025448 loss)
I0526 08:33:10.970803 15117 sgd_solver.cpp:294] Iteration 41570, lr = 0.002
I0526 08:33:17.259582 15117 solver.cpp:233] Iteration 41580, loss = 0.0144619
I0526 08:33:17.259624 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0144621 (* 1 = 0.0144621 loss)
I0526 08:33:17.259630 15117 sgd_solver.cpp:294] Iteration 41580, lr = 0.002
I0526 08:33:23.548575 15117 solver.cpp:233] Iteration 41590, loss = 0.0113443
I0526 08:33:23.548615 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0113445 (* 1 = 0.0113445 loss)
I0526 08:33:23.548622 15117 sgd_solver.cpp:294] Iteration 41590, lr = 0.002
I0526 08:33:29.238988 15117 solver.cpp:342] Iteration 41600, Testing net (#0)
I0526 08:33:42.022009 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.901
I0526 08:33:42.022214 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.443585 (* 1 = 0.443585 loss)
I0526 08:33:42.620278 15117 solver.cpp:233] Iteration 41600, loss = 0.0112602
I0526 08:33:42.620324 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0112604 (* 1 = 0.0112604 loss)
I0526 08:33:42.620333 15117 sgd_solver.cpp:294] Iteration 41600, lr = 0.002
I0526 08:33:48.907672 15117 solver.cpp:233] Iteration 41610, loss = 0.0110362
I0526 08:33:48.907717 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0110364 (* 1 = 0.0110364 loss)
I0526 08:33:48.907724 15117 sgd_solver.cpp:294] Iteration 41610, lr = 0.002
I0526 08:33:55.197105 15117 solver.cpp:233] Iteration 41620, loss = 0.00639502
I0526 08:33:55.197147 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00639524 (* 1 = 0.00639524 loss)
I0526 08:33:55.197154 15117 sgd_solver.cpp:294] Iteration 41620, lr = 0.002
I0526 08:34:01.485498 15117 solver.cpp:233] Iteration 41630, loss = 0.00669576
I0526 08:34:01.485543 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00669598 (* 1 = 0.00669598 loss)
I0526 08:34:01.485550 15117 sgd_solver.cpp:294] Iteration 41630, lr = 0.002
I0526 08:34:07.770619 15117 solver.cpp:233] Iteration 41640, loss = 0.0202722
I0526 08:34:07.770663 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0202724 (* 1 = 0.0202724 loss)
I0526 08:34:07.770669 15117 sgd_solver.cpp:294] Iteration 41640, lr = 0.002
I0526 08:34:14.057081 15117 solver.cpp:233] Iteration 41650, loss = 0.00577169
I0526 08:34:14.057329 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00577191 (* 1 = 0.00577191 loss)
I0526 08:34:14.057356 15117 sgd_solver.cpp:294] Iteration 41650, lr = 0.002
I0526 08:34:20.342833 15117 solver.cpp:233] Iteration 41660, loss = 0.00840972
I0526 08:34:20.342875 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00840993 (* 1 = 0.00840993 loss)
I0526 08:34:20.342881 15117 sgd_solver.cpp:294] Iteration 41660, lr = 0.002
I0526 08:34:26.629783 15117 solver.cpp:233] Iteration 41670, loss = 0.010308
I0526 08:34:26.629825 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0103082 (* 1 = 0.0103082 loss)
I0526 08:34:26.629832 15117 sgd_solver.cpp:294] Iteration 41670, lr = 0.002
I0526 08:34:32.916208 15117 solver.cpp:233] Iteration 41680, loss = 0.0149268
I0526 08:34:32.916251 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.014927 (* 1 = 0.014927 loss)
I0526 08:34:32.916257 15117 sgd_solver.cpp:294] Iteration 41680, lr = 0.002
I0526 08:34:39.200472 15117 solver.cpp:233] Iteration 41690, loss = 0.00508575
I0526 08:34:39.200512 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00508597 (* 1 = 0.00508597 loss)
I0526 08:34:39.200520 15117 sgd_solver.cpp:294] Iteration 41690, lr = 0.002
I0526 08:34:44.893000 15117 solver.cpp:342] Iteration 41700, Testing net (#0)
I0526 08:34:57.671615 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9019
I0526 08:34:57.671656 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.428849 (* 1 = 0.428849 loss)
I0526 08:34:58.268359 15117 solver.cpp:233] Iteration 41700, loss = 0.0284849
I0526 08:34:58.268396 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0284852 (* 1 = 0.0284852 loss)
I0526 08:34:58.268404 15117 sgd_solver.cpp:294] Iteration 41700, lr = 0.002
I0526 08:35:04.559336 15117 solver.cpp:233] Iteration 41710, loss = 0.0155656
I0526 08:35:04.559381 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0155658 (* 1 = 0.0155658 loss)
I0526 08:35:04.559387 15117 sgd_solver.cpp:294] Iteration 41710, lr = 0.002
I0526 08:35:10.844841 15117 solver.cpp:233] Iteration 41720, loss = 0.0115454
I0526 08:35:10.844882 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0115456 (* 1 = 0.0115456 loss)
I0526 08:35:10.844889 15117 sgd_solver.cpp:294] Iteration 41720, lr = 0.002
I0526 08:35:17.131460 15117 solver.cpp:233] Iteration 41730, loss = 0.0139278
I0526 08:35:17.131587 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.013928 (* 1 = 0.013928 loss)
I0526 08:35:17.131594 15117 sgd_solver.cpp:294] Iteration 41730, lr = 0.002
I0526 08:35:23.419114 15117 solver.cpp:233] Iteration 41740, loss = 0.0243604
I0526 08:35:23.419154 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0243606 (* 1 = 0.0243606 loss)
I0526 08:35:23.419162 15117 sgd_solver.cpp:294] Iteration 41740, lr = 0.002
I0526 08:35:29.709750 15117 solver.cpp:233] Iteration 41750, loss = 0.00507274
I0526 08:35:29.709808 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00507296 (* 1 = 0.00507296 loss)
I0526 08:35:29.709815 15117 sgd_solver.cpp:294] Iteration 41750, lr = 0.002
I0526 08:35:35.999902 15117 solver.cpp:233] Iteration 41760, loss = 0.0136098
I0526 08:35:35.999943 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.01361 (* 1 = 0.01361 loss)
I0526 08:35:35.999949 15117 sgd_solver.cpp:294] Iteration 41760, lr = 0.002
I0526 08:35:42.288307 15117 solver.cpp:233] Iteration 41770, loss = 0.0175399
I0526 08:35:42.288349 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0175402 (* 1 = 0.0175402 loss)
I0526 08:35:42.288357 15117 sgd_solver.cpp:294] Iteration 41770, lr = 0.002
I0526 08:35:48.577114 15117 solver.cpp:233] Iteration 41780, loss = 0.0125252
I0526 08:35:48.577340 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0125254 (* 1 = 0.0125254 loss)
I0526 08:35:48.577369 15117 sgd_solver.cpp:294] Iteration 41780, lr = 0.002
I0526 08:35:54.869647 15117 solver.cpp:233] Iteration 41790, loss = 0.0280339
I0526 08:35:54.869685 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0280341 (* 1 = 0.0280341 loss)
I0526 08:35:54.869693 15117 sgd_solver.cpp:294] Iteration 41790, lr = 0.002
I0526 08:36:00.554862 15117 solver.cpp:342] Iteration 41800, Testing net (#0)
I0526 08:36:13.323492 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9004
I0526 08:36:13.323539 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.439075 (* 1 = 0.439075 loss)
I0526 08:36:13.920264 15117 solver.cpp:233] Iteration 41800, loss = 0.0233163
I0526 08:36:13.920302 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0233165 (* 1 = 0.0233165 loss)
I0526 08:36:13.920310 15117 sgd_solver.cpp:294] Iteration 41800, lr = 0.002
I0526 08:36:20.204823 15117 solver.cpp:233] Iteration 41810, loss = 0.0155947
I0526 08:36:20.205039 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0155949 (* 1 = 0.0155949 loss)
I0526 08:36:20.205065 15117 sgd_solver.cpp:294] Iteration 41810, lr = 0.002
I0526 08:36:26.492636 15117 solver.cpp:233] Iteration 41820, loss = 0.012705
I0526 08:36:26.492676 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0127053 (* 1 = 0.0127053 loss)
I0526 08:36:26.492682 15117 sgd_solver.cpp:294] Iteration 41820, lr = 0.002
I0526 08:36:32.781559 15117 solver.cpp:233] Iteration 41830, loss = 0.00414378
I0526 08:36:32.781600 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00414401 (* 1 = 0.00414401 loss)
I0526 08:36:32.781607 15117 sgd_solver.cpp:294] Iteration 41830, lr = 0.002
I0526 08:36:39.072990 15117 solver.cpp:233] Iteration 41840, loss = 0.0403401
I0526 08:36:39.073031 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0403403 (* 1 = 0.0403403 loss)
I0526 08:36:39.073038 15117 sgd_solver.cpp:294] Iteration 41840, lr = 0.002
I0526 08:36:45.361075 15117 solver.cpp:233] Iteration 41850, loss = 0.00463641
I0526 08:36:45.361115 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00463664 (* 1 = 0.00463664 loss)
I0526 08:36:45.361122 15117 sgd_solver.cpp:294] Iteration 41850, lr = 0.002
I0526 08:36:51.648722 15117 solver.cpp:233] Iteration 41860, loss = 0.0166762
I0526 08:36:51.648936 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0166764 (* 1 = 0.0166764 loss)
I0526 08:36:51.648964 15117 sgd_solver.cpp:294] Iteration 41860, lr = 0.002
I0526 08:36:57.939607 15117 solver.cpp:233] Iteration 41870, loss = 0.00981207
I0526 08:36:57.939648 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0098123 (* 1 = 0.0098123 loss)
I0526 08:36:57.939654 15117 sgd_solver.cpp:294] Iteration 41870, lr = 0.002
I0526 08:37:04.229179 15117 solver.cpp:233] Iteration 41880, loss = 0.0142488
I0526 08:37:04.229223 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.014249 (* 1 = 0.014249 loss)
I0526 08:37:04.229231 15117 sgd_solver.cpp:294] Iteration 41880, lr = 0.002
I0526 08:37:10.516412 15117 solver.cpp:233] Iteration 41890, loss = 0.0138554
I0526 08:37:10.516451 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0138556 (* 1 = 0.0138556 loss)
I0526 08:37:10.516458 15117 sgd_solver.cpp:294] Iteration 41890, lr = 0.002
I0526 08:37:16.205927 15117 solver.cpp:342] Iteration 41900, Testing net (#0)
I0526 08:37:28.985507 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9068
I0526 08:37:28.985635 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.415849 (* 1 = 0.415849 loss)
I0526 08:37:29.581497 15117 solver.cpp:233] Iteration 41900, loss = 0.00496624
I0526 08:37:29.581529 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00496646 (* 1 = 0.00496646 loss)
I0526 08:37:29.581542 15117 sgd_solver.cpp:294] Iteration 41900, lr = 0.002
I0526 08:37:35.869321 15117 solver.cpp:233] Iteration 41910, loss = 0.0192489
I0526 08:37:35.869359 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0192491 (* 1 = 0.0192491 loss)
I0526 08:37:35.869365 15117 sgd_solver.cpp:294] Iteration 41910, lr = 0.002
I0526 08:37:42.160362 15117 solver.cpp:233] Iteration 41920, loss = 0.00375345
I0526 08:37:42.160400 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00375368 (* 1 = 0.00375368 loss)
I0526 08:37:42.160408 15117 sgd_solver.cpp:294] Iteration 41920, lr = 0.002
I0526 08:37:48.450108 15117 solver.cpp:233] Iteration 41930, loss = 0.0308626
I0526 08:37:48.450150 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0308628 (* 1 = 0.0308628 loss)
I0526 08:37:48.450156 15117 sgd_solver.cpp:294] Iteration 41930, lr = 0.002
I0526 08:37:54.741112 15117 solver.cpp:233] Iteration 41940, loss = 0.00588334
I0526 08:37:54.741154 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00588357 (* 1 = 0.00588357 loss)
I0526 08:37:54.741161 15117 sgd_solver.cpp:294] Iteration 41940, lr = 0.002
I0526 08:38:01.032730 15117 solver.cpp:233] Iteration 41950, loss = 0.00973641
I0526 08:38:01.033006 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00973664 (* 1 = 0.00973664 loss)
I0526 08:38:01.033032 15117 sgd_solver.cpp:294] Iteration 41950, lr = 0.002
I0526 08:38:07.321805 15117 solver.cpp:233] Iteration 41960, loss = 0.0233174
I0526 08:38:07.321841 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0233176 (* 1 = 0.0233176 loss)
I0526 08:38:07.321848 15117 sgd_solver.cpp:294] Iteration 41960, lr = 0.002
I0526 08:38:13.612038 15117 solver.cpp:233] Iteration 41970, loss = 0.021516
I0526 08:38:13.612087 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0215162 (* 1 = 0.0215162 loss)
I0526 08:38:13.612094 15117 sgd_solver.cpp:294] Iteration 41970, lr = 0.002
I0526 08:38:19.900197 15117 solver.cpp:233] Iteration 41980, loss = 0.0321713
I0526 08:38:19.900239 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0321715 (* 1 = 0.0321715 loss)
I0526 08:38:19.900246 15117 sgd_solver.cpp:294] Iteration 41980, lr = 0.002
I0526 08:38:26.187829 15117 solver.cpp:233] Iteration 41990, loss = 0.0125651
I0526 08:38:26.187867 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0125653 (* 1 = 0.0125653 loss)
I0526 08:38:26.187875 15117 sgd_solver.cpp:294] Iteration 41990, lr = 0.002
I0526 08:38:31.878651 15117 solver.cpp:342] Iteration 42000, Testing net (#0)
I0526 08:38:44.664664 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9018
I0526 08:38:44.664710 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.443711 (* 1 = 0.443711 loss)
I0526 08:38:45.261925 15117 solver.cpp:233] Iteration 42000, loss = 0.00314142
I0526 08:38:45.261968 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00314165 (* 1 = 0.00314165 loss)
I0526 08:38:45.261976 15117 sgd_solver.cpp:294] Iteration 42000, lr = 0.002
I0526 08:38:51.551946 15117 solver.cpp:233] Iteration 42010, loss = 0.0104599
I0526 08:38:51.551985 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0104602 (* 1 = 0.0104602 loss)
I0526 08:38:51.551991 15117 sgd_solver.cpp:294] Iteration 42010, lr = 0.002
I0526 08:38:57.841951 15117 solver.cpp:233] Iteration 42020, loss = 0.0101226
I0526 08:38:57.841992 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0101228 (* 1 = 0.0101228 loss)
I0526 08:38:57.841998 15117 sgd_solver.cpp:294] Iteration 42020, lr = 0.002
I0526 08:39:04.132128 15117 solver.cpp:233] Iteration 42030, loss = 0.0153729
I0526 08:39:04.132350 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0153732 (* 1 = 0.0153732 loss)
I0526 08:39:04.132380 15117 sgd_solver.cpp:294] Iteration 42030, lr = 0.002
I0526 08:39:10.423339 15117 solver.cpp:233] Iteration 42040, loss = 0.00859799
I0526 08:39:10.423379 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00859822 (* 1 = 0.00859822 loss)
I0526 08:39:10.423391 15117 sgd_solver.cpp:294] Iteration 42040, lr = 0.002
I0526 08:39:16.714725 15117 solver.cpp:233] Iteration 42050, loss = 0.0133288
I0526 08:39:16.714771 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.013329 (* 1 = 0.013329 loss)
I0526 08:39:16.714779 15117 sgd_solver.cpp:294] Iteration 42050, lr = 0.002
I0526 08:39:23.004611 15117 solver.cpp:233] Iteration 42060, loss = 0.00699387
I0526 08:39:23.004652 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0069941 (* 1 = 0.0069941 loss)
I0526 08:39:23.004659 15117 sgd_solver.cpp:294] Iteration 42060, lr = 0.002
I0526 08:39:29.293118 15117 solver.cpp:233] Iteration 42070, loss = 0.0154974
I0526 08:39:29.293162 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0154976 (* 1 = 0.0154976 loss)
I0526 08:39:29.293169 15117 sgd_solver.cpp:294] Iteration 42070, lr = 0.002
I0526 08:39:35.582310 15117 solver.cpp:233] Iteration 42080, loss = 0.00813174
I0526 08:39:35.582501 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00813198 (* 1 = 0.00813198 loss)
I0526 08:39:35.582510 15117 sgd_solver.cpp:294] Iteration 42080, lr = 0.002
I0526 08:39:41.872519 15117 solver.cpp:233] Iteration 42090, loss = 0.0126296
I0526 08:39:41.872560 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0126298 (* 1 = 0.0126298 loss)
I0526 08:39:41.872580 15117 sgd_solver.cpp:294] Iteration 42090, lr = 0.002
I0526 08:39:47.564152 15117 solver.cpp:342] Iteration 42100, Testing net (#0)
I0526 08:40:00.349550 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9043
I0526 08:40:00.349596 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.426765 (* 1 = 0.426765 loss)
I0526 08:40:00.946936 15117 solver.cpp:233] Iteration 42100, loss = 0.00707269
I0526 08:40:00.946960 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00707292 (* 1 = 0.00707292 loss)
I0526 08:40:00.946967 15117 sgd_solver.cpp:294] Iteration 42100, lr = 0.002
I0526 08:40:07.239132 15117 solver.cpp:233] Iteration 42110, loss = 0.00725484
I0526 08:40:07.239348 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00725506 (* 1 = 0.00725506 loss)
I0526 08:40:07.239373 15117 sgd_solver.cpp:294] Iteration 42110, lr = 0.002
I0526 08:40:13.531893 15117 solver.cpp:233] Iteration 42120, loss = 0.0222073
I0526 08:40:13.531941 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0222075 (* 1 = 0.0222075 loss)
I0526 08:40:13.531949 15117 sgd_solver.cpp:294] Iteration 42120, lr = 0.002
I0526 08:40:19.821368 15117 solver.cpp:233] Iteration 42130, loss = 0.00652176
I0526 08:40:19.821409 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00652199 (* 1 = 0.00652199 loss)
I0526 08:40:19.821416 15117 sgd_solver.cpp:294] Iteration 42130, lr = 0.002
I0526 08:40:26.109102 15117 solver.cpp:233] Iteration 42140, loss = 0.00790688
I0526 08:40:26.109144 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0079071 (* 1 = 0.0079071 loss)
I0526 08:40:26.109151 15117 sgd_solver.cpp:294] Iteration 42140, lr = 0.002
I0526 08:40:32.398355 15117 solver.cpp:233] Iteration 42150, loss = 0.0147356
I0526 08:40:32.398413 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0147358 (* 1 = 0.0147358 loss)
I0526 08:40:32.398422 15117 sgd_solver.cpp:294] Iteration 42150, lr = 0.002
I0526 08:40:38.683221 15117 solver.cpp:233] Iteration 42160, loss = 0.00967391
I0526 08:40:38.683426 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00967414 (* 1 = 0.00967414 loss)
I0526 08:40:38.683452 15117 sgd_solver.cpp:294] Iteration 42160, lr = 0.002
I0526 08:40:44.974226 15117 solver.cpp:233] Iteration 42170, loss = 0.0212673
I0526 08:40:44.974272 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0212675 (* 1 = 0.0212675 loss)
I0526 08:40:44.974279 15117 sgd_solver.cpp:294] Iteration 42170, lr = 0.002
I0526 08:40:51.265173 15117 solver.cpp:233] Iteration 42180, loss = 0.0174218
I0526 08:40:51.265223 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.017422 (* 1 = 0.017422 loss)
I0526 08:40:51.265231 15117 sgd_solver.cpp:294] Iteration 42180, lr = 0.002
I0526 08:40:57.554883 15117 solver.cpp:233] Iteration 42190, loss = 0.0036188
I0526 08:40:57.554925 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00361903 (* 1 = 0.00361903 loss)
I0526 08:40:57.554932 15117 sgd_solver.cpp:294] Iteration 42190, lr = 0.002
I0526 08:41:03.249765 15117 solver.cpp:342] Iteration 42200, Testing net (#0)
I0526 08:41:16.032779 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.903
I0526 08:41:16.033041 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.431788 (* 1 = 0.431788 loss)
I0526 08:41:16.635144 15117 solver.cpp:233] Iteration 42200, loss = 0.00764489
I0526 08:41:16.635179 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00764512 (* 1 = 0.00764512 loss)
I0526 08:41:16.635187 15117 sgd_solver.cpp:294] Iteration 42200, lr = 0.002
I0526 08:41:22.926028 15117 solver.cpp:233] Iteration 42210, loss = 0.00916963
I0526 08:41:22.926075 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00916986 (* 1 = 0.00916986 loss)
I0526 08:41:22.926081 15117 sgd_solver.cpp:294] Iteration 42210, lr = 0.002
I0526 08:41:29.218711 15117 solver.cpp:233] Iteration 42220, loss = 0.00857815
I0526 08:41:29.218756 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00857837 (* 1 = 0.00857837 loss)
I0526 08:41:29.218763 15117 sgd_solver.cpp:294] Iteration 42220, lr = 0.002
I0526 08:41:35.503942 15117 solver.cpp:233] Iteration 42230, loss = 0.0171696
I0526 08:41:35.503988 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0171698 (* 1 = 0.0171698 loss)
I0526 08:41:35.503995 15117 sgd_solver.cpp:294] Iteration 42230, lr = 0.002
I0526 08:41:41.794157 15117 solver.cpp:233] Iteration 42240, loss = 0.039482
I0526 08:41:41.794198 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0394823 (* 1 = 0.0394823 loss)
I0526 08:41:41.794204 15117 sgd_solver.cpp:294] Iteration 42240, lr = 0.002
I0526 08:41:48.086045 15117 solver.cpp:233] Iteration 42250, loss = 0.0178254
I0526 08:41:48.086263 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0178256 (* 1 = 0.0178256 loss)
I0526 08:41:48.086293 15117 sgd_solver.cpp:294] Iteration 42250, lr = 0.002
I0526 08:41:54.378152 15117 solver.cpp:233] Iteration 42260, loss = 0.0224756
I0526 08:41:54.378203 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0224758 (* 1 = 0.0224758 loss)
I0526 08:41:54.378211 15117 sgd_solver.cpp:294] Iteration 42260, lr = 0.002
I0526 08:42:00.670744 15117 solver.cpp:233] Iteration 42270, loss = 0.0193857
I0526 08:42:00.670785 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0193859 (* 1 = 0.0193859 loss)
I0526 08:42:00.670792 15117 sgd_solver.cpp:294] Iteration 42270, lr = 0.002
I0526 08:42:06.962316 15117 solver.cpp:233] Iteration 42280, loss = 0.00743806
I0526 08:42:06.962359 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00743829 (* 1 = 0.00743829 loss)
I0526 08:42:06.962378 15117 sgd_solver.cpp:294] Iteration 42280, lr = 0.002
I0526 08:42:13.254653 15117 solver.cpp:233] Iteration 42290, loss = 0.0102583
I0526 08:42:13.254705 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0102586 (* 1 = 0.0102586 loss)
I0526 08:42:13.254712 15117 sgd_solver.cpp:294] Iteration 42290, lr = 0.002
I0526 08:42:18.947051 15117 solver.cpp:342] Iteration 42300, Testing net (#0)
I0526 08:42:31.734393 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8997
I0526 08:42:31.734439 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.451906 (* 1 = 0.451906 loss)
I0526 08:42:32.330694 15117 solver.cpp:233] Iteration 42300, loss = 0.0410575
I0526 08:42:32.330736 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0410578 (* 1 = 0.0410578 loss)
I0526 08:42:32.330744 15117 sgd_solver.cpp:294] Iteration 42300, lr = 0.002
I0526 08:42:38.619129 15117 solver.cpp:233] Iteration 42310, loss = 0.00850436
I0526 08:42:38.619179 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00850459 (* 1 = 0.00850459 loss)
I0526 08:42:38.619185 15117 sgd_solver.cpp:294] Iteration 42310, lr = 0.002
I0526 08:42:44.910902 15117 solver.cpp:233] Iteration 42320, loss = 0.00342361
I0526 08:42:44.910950 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00342384 (* 1 = 0.00342384 loss)
I0526 08:42:44.910958 15117 sgd_solver.cpp:294] Iteration 42320, lr = 0.002
I0526 08:42:51.203649 15117 solver.cpp:233] Iteration 42330, loss = 0.0279186
I0526 08:42:51.203796 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0279188 (* 1 = 0.0279188 loss)
I0526 08:42:51.203805 15117 sgd_solver.cpp:294] Iteration 42330, lr = 0.002
I0526 08:42:57.492707 15117 solver.cpp:233] Iteration 42340, loss = 0.0233044
I0526 08:42:57.492746 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0233046 (* 1 = 0.0233046 loss)
I0526 08:42:57.492753 15117 sgd_solver.cpp:294] Iteration 42340, lr = 0.002
I0526 08:43:03.781350 15117 solver.cpp:233] Iteration 42350, loss = 0.0103057
I0526 08:43:03.781394 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0103059 (* 1 = 0.0103059 loss)
I0526 08:43:03.781401 15117 sgd_solver.cpp:294] Iteration 42350, lr = 0.002
I0526 08:43:10.071043 15117 solver.cpp:233] Iteration 42360, loss = 0.00726966
I0526 08:43:10.071085 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0072699 (* 1 = 0.0072699 loss)
I0526 08:43:10.071092 15117 sgd_solver.cpp:294] Iteration 42360, lr = 0.002
I0526 08:43:16.359279 15117 solver.cpp:233] Iteration 42370, loss = 0.029617
I0526 08:43:16.359321 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0296172 (* 1 = 0.0296172 loss)
I0526 08:43:16.359328 15117 sgd_solver.cpp:294] Iteration 42370, lr = 0.002
I0526 08:43:22.650439 15117 solver.cpp:233] Iteration 42380, loss = 0.0135642
I0526 08:43:22.650650 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0135645 (* 1 = 0.0135645 loss)
I0526 08:43:22.650676 15117 sgd_solver.cpp:294] Iteration 42380, lr = 0.002
I0526 08:43:28.942134 15117 solver.cpp:233] Iteration 42390, loss = 0.00925692
I0526 08:43:28.942170 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00925715 (* 1 = 0.00925715 loss)
I0526 08:43:28.942178 15117 sgd_solver.cpp:294] Iteration 42390, lr = 0.002
I0526 08:43:34.631826 15117 solver.cpp:342] Iteration 42400, Testing net (#0)
I0526 08:43:47.405326 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9007
I0526 08:43:47.405362 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.428859 (* 1 = 0.428859 loss)
I0526 08:43:48.002637 15117 solver.cpp:233] Iteration 42400, loss = 0.0159289
I0526 08:43:48.002676 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0159291 (* 1 = 0.0159291 loss)
I0526 08:43:48.002683 15117 sgd_solver.cpp:294] Iteration 42400, lr = 0.002
I0526 08:43:54.291210 15117 solver.cpp:233] Iteration 42410, loss = 0.0200292
I0526 08:43:54.291446 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0200295 (* 1 = 0.0200295 loss)
I0526 08:43:54.291476 15117 sgd_solver.cpp:294] Iteration 42410, lr = 0.002
I0526 08:44:00.583626 15117 solver.cpp:233] Iteration 42420, loss = 0.0101754
I0526 08:44:00.583674 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0101756 (* 1 = 0.0101756 loss)
I0526 08:44:00.583683 15117 sgd_solver.cpp:294] Iteration 42420, lr = 0.002
I0526 08:44:06.873910 15117 solver.cpp:233] Iteration 42430, loss = 0.00669408
I0526 08:44:06.873953 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00669431 (* 1 = 0.00669431 loss)
I0526 08:44:06.873960 15117 sgd_solver.cpp:294] Iteration 42430, lr = 0.002
I0526 08:44:13.164885 15117 solver.cpp:233] Iteration 42440, loss = 0.00996537
I0526 08:44:13.164927 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0099656 (* 1 = 0.0099656 loss)
I0526 08:44:13.164933 15117 sgd_solver.cpp:294] Iteration 42440, lr = 0.002
I0526 08:44:19.453094 15117 solver.cpp:233] Iteration 42450, loss = 0.0128045
I0526 08:44:19.453135 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0128048 (* 1 = 0.0128048 loss)
I0526 08:44:19.453142 15117 sgd_solver.cpp:294] Iteration 42450, lr = 0.002
I0526 08:44:25.740123 15117 solver.cpp:233] Iteration 42460, loss = 0.00916879
I0526 08:44:25.740363 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00916902 (* 1 = 0.00916902 loss)
I0526 08:44:25.740392 15117 sgd_solver.cpp:294] Iteration 42460, lr = 0.002
I0526 08:44:32.030097 15117 solver.cpp:233] Iteration 42470, loss = 0.00478577
I0526 08:44:32.030128 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.004786 (* 1 = 0.004786 loss)
I0526 08:44:32.030134 15117 sgd_solver.cpp:294] Iteration 42470, lr = 0.002
I0526 08:44:38.313730 15117 solver.cpp:233] Iteration 42480, loss = 0.0054375
I0526 08:44:38.313781 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00543773 (* 1 = 0.00543773 loss)
I0526 08:44:38.313788 15117 sgd_solver.cpp:294] Iteration 42480, lr = 0.002
I0526 08:44:44.598384 15117 solver.cpp:233] Iteration 42490, loss = 0.00627761
I0526 08:44:44.598438 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00627784 (* 1 = 0.00627784 loss)
I0526 08:44:44.598445 15117 sgd_solver.cpp:294] Iteration 42490, lr = 0.002
I0526 08:44:50.289933 15117 solver.cpp:342] Iteration 42500, Testing net (#0)
I0526 08:45:03.064560 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9029
I0526 08:45:03.064698 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.438165 (* 1 = 0.438165 loss)
I0526 08:45:03.662330 15117 solver.cpp:233] Iteration 42500, loss = 0.00785519
I0526 08:45:03.662371 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00785542 (* 1 = 0.00785542 loss)
I0526 08:45:03.662379 15117 sgd_solver.cpp:294] Iteration 42500, lr = 0.002
I0526 08:45:09.954316 15117 solver.cpp:233] Iteration 42510, loss = 0.00721865
I0526 08:45:09.954375 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00721888 (* 1 = 0.00721888 loss)
I0526 08:45:09.954382 15117 sgd_solver.cpp:294] Iteration 42510, lr = 0.002
I0526 08:45:16.245116 15117 solver.cpp:233] Iteration 42520, loss = 0.00880164
I0526 08:45:16.245147 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00880186 (* 1 = 0.00880186 loss)
I0526 08:45:16.245153 15117 sgd_solver.cpp:294] Iteration 42520, lr = 0.002
I0526 08:45:22.533294 15117 solver.cpp:233] Iteration 42530, loss = 0.00851914
I0526 08:45:22.533335 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00851937 (* 1 = 0.00851937 loss)
I0526 08:45:22.533341 15117 sgd_solver.cpp:294] Iteration 42530, lr = 0.002
I0526 08:45:28.823230 15117 solver.cpp:233] Iteration 42540, loss = 0.0238676
I0526 08:45:28.823276 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0238678 (* 1 = 0.0238678 loss)
I0526 08:45:28.823282 15117 sgd_solver.cpp:294] Iteration 42540, lr = 0.002
I0526 08:45:35.109860 15117 solver.cpp:233] Iteration 42550, loss = 0.0187129
I0526 08:45:35.110074 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0187132 (* 1 = 0.0187132 loss)
I0526 08:45:35.110102 15117 sgd_solver.cpp:294] Iteration 42550, lr = 0.002
I0526 08:45:41.397755 15117 solver.cpp:233] Iteration 42560, loss = 0.0369261
I0526 08:45:41.397800 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0369263 (* 1 = 0.0369263 loss)
I0526 08:45:41.397807 15117 sgd_solver.cpp:294] Iteration 42560, lr = 0.002
I0526 08:45:47.683243 15117 solver.cpp:233] Iteration 42570, loss = 0.00367383
I0526 08:45:47.683286 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00367406 (* 1 = 0.00367406 loss)
I0526 08:45:47.683293 15117 sgd_solver.cpp:294] Iteration 42570, lr = 0.002
I0526 08:45:53.972844 15117 solver.cpp:233] Iteration 42580, loss = 0.0198405
I0526 08:45:53.972880 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0198407 (* 1 = 0.0198407 loss)
I0526 08:45:53.972893 15117 sgd_solver.cpp:294] Iteration 42580, lr = 0.002
I0526 08:46:00.260171 15117 solver.cpp:233] Iteration 42590, loss = 0.0133142
I0526 08:46:00.260213 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0133145 (* 1 = 0.0133145 loss)
I0526 08:46:00.260221 15117 sgd_solver.cpp:294] Iteration 42590, lr = 0.002
I0526 08:46:05.952054 15117 solver.cpp:342] Iteration 42600, Testing net (#0)
I0526 08:46:18.731109 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9034
I0526 08:46:18.731153 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.438731 (* 1 = 0.438731 loss)
I0526 08:46:19.327953 15117 solver.cpp:233] Iteration 42600, loss = 0.0114156
I0526 08:46:19.327986 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0114159 (* 1 = 0.0114159 loss)
I0526 08:46:19.327992 15117 sgd_solver.cpp:294] Iteration 42600, lr = 0.002
I0526 08:46:25.615859 15117 solver.cpp:233] Iteration 42610, loss = 0.00679125
I0526 08:46:25.615901 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00679148 (* 1 = 0.00679148 loss)
I0526 08:46:25.615908 15117 sgd_solver.cpp:294] Iteration 42610, lr = 0.002
I0526 08:46:31.904670 15117 solver.cpp:233] Iteration 42620, loss = 0.0137909
I0526 08:46:31.904712 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0137911 (* 1 = 0.0137911 loss)
I0526 08:46:31.904719 15117 sgd_solver.cpp:294] Iteration 42620, lr = 0.002
I0526 08:46:38.193130 15117 solver.cpp:233] Iteration 42630, loss = 0.0219227
I0526 08:46:38.193269 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.021923 (* 1 = 0.021923 loss)
I0526 08:46:38.193279 15117 sgd_solver.cpp:294] Iteration 42630, lr = 0.002
I0526 08:46:44.481748 15117 solver.cpp:233] Iteration 42640, loss = 0.0138678
I0526 08:46:44.481789 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.013868 (* 1 = 0.013868 loss)
I0526 08:46:44.481796 15117 sgd_solver.cpp:294] Iteration 42640, lr = 0.002
I0526 08:46:50.769951 15117 solver.cpp:233] Iteration 42650, loss = 0.0150916
I0526 08:46:50.769994 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0150918 (* 1 = 0.0150918 loss)
I0526 08:46:50.770002 15117 sgd_solver.cpp:294] Iteration 42650, lr = 0.002
I0526 08:46:57.053768 15117 solver.cpp:233] Iteration 42660, loss = 0.0297962
I0526 08:46:57.053810 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0297964 (* 1 = 0.0297964 loss)
I0526 08:46:57.053817 15117 sgd_solver.cpp:294] Iteration 42660, lr = 0.002
I0526 08:47:03.342912 15117 solver.cpp:233] Iteration 42670, loss = 0.0123607
I0526 08:47:03.342937 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.012361 (* 1 = 0.012361 loss)
I0526 08:47:03.342943 15117 sgd_solver.cpp:294] Iteration 42670, lr = 0.002
I0526 08:47:09.632218 15117 solver.cpp:233] Iteration 42680, loss = 0.0245353
I0526 08:47:09.632432 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0245355 (* 1 = 0.0245355 loss)
I0526 08:47:09.632458 15117 sgd_solver.cpp:294] Iteration 42680, lr = 0.002
I0526 08:47:15.923151 15117 solver.cpp:233] Iteration 42690, loss = 0.0183949
I0526 08:47:15.923194 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0183952 (* 1 = 0.0183952 loss)
I0526 08:47:15.923202 15117 sgd_solver.cpp:294] Iteration 42690, lr = 0.002
I0526 08:47:21.615871 15117 solver.cpp:342] Iteration 42700, Testing net (#0)
I0526 08:47:34.393786 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9008
I0526 08:47:34.393828 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.447792 (* 1 = 0.447792 loss)
I0526 08:47:34.991497 15117 solver.cpp:233] Iteration 42700, loss = 0.0154614
I0526 08:47:34.991533 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0154616 (* 1 = 0.0154616 loss)
I0526 08:47:34.991540 15117 sgd_solver.cpp:294] Iteration 42700, lr = 0.002
I0526 08:47:41.280517 15117 solver.cpp:233] Iteration 42710, loss = 0.00489132
I0526 08:47:41.280663 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00489154 (* 1 = 0.00489154 loss)
I0526 08:47:41.280676 15117 sgd_solver.cpp:294] Iteration 42710, lr = 0.002
I0526 08:47:47.568321 15117 solver.cpp:233] Iteration 42720, loss = 0.0258538
I0526 08:47:47.568363 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.025854 (* 1 = 0.025854 loss)
I0526 08:47:47.568372 15117 sgd_solver.cpp:294] Iteration 42720, lr = 0.002
I0526 08:47:53.855581 15117 solver.cpp:233] Iteration 42730, loss = 0.0111783
I0526 08:47:53.855624 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0111786 (* 1 = 0.0111786 loss)
I0526 08:47:53.855633 15117 sgd_solver.cpp:294] Iteration 42730, lr = 0.002
I0526 08:48:00.144203 15117 solver.cpp:233] Iteration 42740, loss = 0.00409588
I0526 08:48:00.144244 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0040961 (* 1 = 0.0040961 loss)
I0526 08:48:00.144251 15117 sgd_solver.cpp:294] Iteration 42740, lr = 0.002
I0526 08:48:06.431449 15117 solver.cpp:233] Iteration 42750, loss = 0.011768
I0526 08:48:06.431490 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0117683 (* 1 = 0.0117683 loss)
I0526 08:48:06.431498 15117 sgd_solver.cpp:294] Iteration 42750, lr = 0.002
I0526 08:48:12.722787 15117 solver.cpp:233] Iteration 42760, loss = 0.00355187
I0526 08:48:12.722990 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00355209 (* 1 = 0.00355209 loss)
I0526 08:48:12.723018 15117 sgd_solver.cpp:294] Iteration 42760, lr = 0.002
I0526 08:48:19.013619 15117 solver.cpp:233] Iteration 42770, loss = 0.0238443
I0526 08:48:19.013665 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0238445 (* 1 = 0.0238445 loss)
I0526 08:48:19.013672 15117 sgd_solver.cpp:294] Iteration 42770, lr = 0.002
I0526 08:48:25.302091 15117 solver.cpp:233] Iteration 42780, loss = 0.0111231
I0526 08:48:25.302134 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0111233 (* 1 = 0.0111233 loss)
I0526 08:48:25.302141 15117 sgd_solver.cpp:294] Iteration 42780, lr = 0.002
I0526 08:48:31.591841 15117 solver.cpp:233] Iteration 42790, loss = 0.0061259
I0526 08:48:31.591889 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00612613 (* 1 = 0.00612613 loss)
I0526 08:48:31.591897 15117 sgd_solver.cpp:294] Iteration 42790, lr = 0.002
I0526 08:48:37.286043 15117 solver.cpp:342] Iteration 42800, Testing net (#0)
I0526 08:48:50.074040 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9044
I0526 08:48:50.074254 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.443554 (* 1 = 0.443554 loss)
I0526 08:48:50.671504 15117 solver.cpp:233] Iteration 42800, loss = 0.0095304
I0526 08:48:50.671540 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00953063 (* 1 = 0.00953063 loss)
I0526 08:48:50.671548 15117 sgd_solver.cpp:294] Iteration 42800, lr = 0.002
I0526 08:48:56.958621 15117 solver.cpp:233] Iteration 42810, loss = 0.0141221
I0526 08:48:56.958663 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0141223 (* 1 = 0.0141223 loss)
I0526 08:48:56.958670 15117 sgd_solver.cpp:294] Iteration 42810, lr = 0.002
I0526 08:49:03.244114 15117 solver.cpp:233] Iteration 42820, loss = 0.0156628
I0526 08:49:03.244159 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0156631 (* 1 = 0.0156631 loss)
I0526 08:49:03.244166 15117 sgd_solver.cpp:294] Iteration 42820, lr = 0.002
I0526 08:49:09.534342 15117 solver.cpp:233] Iteration 42830, loss = 0.0147538
I0526 08:49:09.534396 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.014754 (* 1 = 0.014754 loss)
I0526 08:49:09.534404 15117 sgd_solver.cpp:294] Iteration 42830, lr = 0.002
I0526 08:49:15.827234 15117 solver.cpp:233] Iteration 42840, loss = 0.022206
I0526 08:49:15.827270 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0222062 (* 1 = 0.0222062 loss)
I0526 08:49:15.827276 15117 sgd_solver.cpp:294] Iteration 42840, lr = 0.002
I0526 08:49:22.119262 15117 solver.cpp:233] Iteration 42850, loss = 0.0158342
I0526 08:49:22.119527 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0158345 (* 1 = 0.0158345 loss)
I0526 08:49:22.119567 15117 sgd_solver.cpp:294] Iteration 42850, lr = 0.002
I0526 08:49:28.409610 15117 solver.cpp:233] Iteration 42860, loss = 0.00844623
I0526 08:49:28.409651 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00844645 (* 1 = 0.00844645 loss)
I0526 08:49:28.409658 15117 sgd_solver.cpp:294] Iteration 42860, lr = 0.002
I0526 08:49:34.698539 15117 solver.cpp:233] Iteration 42870, loss = 0.0175735
I0526 08:49:34.698575 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0175737 (* 1 = 0.0175737 loss)
I0526 08:49:34.698583 15117 sgd_solver.cpp:294] Iteration 42870, lr = 0.002
I0526 08:49:40.987171 15117 solver.cpp:233] Iteration 42880, loss = 0.00696368
I0526 08:49:40.987213 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0069639 (* 1 = 0.0069639 loss)
I0526 08:49:40.987221 15117 sgd_solver.cpp:294] Iteration 42880, lr = 0.002
I0526 08:49:47.275604 15117 solver.cpp:233] Iteration 42890, loss = 0.00589101
I0526 08:49:47.275648 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00589123 (* 1 = 0.00589123 loss)
I0526 08:49:47.275655 15117 sgd_solver.cpp:294] Iteration 42890, lr = 0.002
I0526 08:49:52.967795 15117 solver.cpp:342] Iteration 42900, Testing net (#0)
I0526 08:50:05.750648 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9043
I0526 08:50:05.750702 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.441319 (* 1 = 0.441319 loss)
I0526 08:50:06.348387 15117 solver.cpp:233] Iteration 42900, loss = 0.0296896
I0526 08:50:06.348420 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0296898 (* 1 = 0.0296898 loss)
I0526 08:50:06.348428 15117 sgd_solver.cpp:294] Iteration 42900, lr = 0.002
I0526 08:50:12.638245 15117 solver.cpp:233] Iteration 42910, loss = 0.0199442
I0526 08:50:12.638273 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0199444 (* 1 = 0.0199444 loss)
I0526 08:50:12.638279 15117 sgd_solver.cpp:294] Iteration 42910, lr = 0.002
I0526 08:50:18.930734 15117 solver.cpp:233] Iteration 42920, loss = 0.0100666
I0526 08:50:18.930779 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0100669 (* 1 = 0.0100669 loss)
I0526 08:50:18.930786 15117 sgd_solver.cpp:294] Iteration 42920, lr = 0.002
I0526 08:50:25.222703 15117 solver.cpp:233] Iteration 42930, loss = 0.0214132
I0526 08:50:25.222839 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0214134 (* 1 = 0.0214134 loss)
I0526 08:50:25.222847 15117 sgd_solver.cpp:294] Iteration 42930, lr = 0.002
I0526 08:50:31.511924 15117 solver.cpp:233] Iteration 42940, loss = 0.0217869
I0526 08:50:31.511972 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0217872 (* 1 = 0.0217872 loss)
I0526 08:50:31.511979 15117 sgd_solver.cpp:294] Iteration 42940, lr = 0.002
I0526 08:50:37.801509 15117 solver.cpp:233] Iteration 42950, loss = 0.0135638
I0526 08:50:37.801549 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.013564 (* 1 = 0.013564 loss)
I0526 08:50:37.801556 15117 sgd_solver.cpp:294] Iteration 42950, lr = 0.002
I0526 08:50:44.092506 15117 solver.cpp:233] Iteration 42960, loss = 0.00821009
I0526 08:50:44.092547 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0082103 (* 1 = 0.0082103 loss)
I0526 08:50:44.092555 15117 sgd_solver.cpp:294] Iteration 42960, lr = 0.002
I0526 08:50:50.383234 15117 solver.cpp:233] Iteration 42970, loss = 0.0224384
I0526 08:50:50.383275 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0224387 (* 1 = 0.0224387 loss)
I0526 08:50:50.383282 15117 sgd_solver.cpp:294] Iteration 42970, lr = 0.002
I0526 08:50:56.673295 15117 solver.cpp:233] Iteration 42980, loss = 0.00751138
I0526 08:50:56.673522 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00751159 (* 1 = 0.00751159 loss)
I0526 08:50:56.673552 15117 sgd_solver.cpp:294] Iteration 42980, lr = 0.002
I0526 08:51:02.968063 15117 solver.cpp:233] Iteration 42990, loss = 0.00474203
I0526 08:51:02.968114 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00474224 (* 1 = 0.00474224 loss)
I0526 08:51:02.968122 15117 sgd_solver.cpp:294] Iteration 42990, lr = 0.002
I0526 08:51:08.658156 15117 solver.cpp:342] Iteration 43000, Testing net (#0)
I0526 08:51:21.442955 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9012
I0526 08:51:21.442997 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.439528 (* 1 = 0.439528 loss)
I0526 08:51:22.040467 15117 solver.cpp:233] Iteration 43000, loss = 0.0207588
I0526 08:51:22.040508 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.020759 (* 1 = 0.020759 loss)
I0526 08:51:22.040514 15117 sgd_solver.cpp:294] Iteration 43000, lr = 0.002
I0526 08:51:28.329107 15117 solver.cpp:233] Iteration 43010, loss = 0.0171728
I0526 08:51:28.329363 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.017173 (* 1 = 0.017173 loss)
I0526 08:51:28.329391 15117 sgd_solver.cpp:294] Iteration 43010, lr = 0.002
I0526 08:51:34.624778 15117 solver.cpp:233] Iteration 43020, loss = 0.0129932
I0526 08:51:34.624824 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0129934 (* 1 = 0.0129934 loss)
I0526 08:51:34.624830 15117 sgd_solver.cpp:294] Iteration 43020, lr = 0.002
I0526 08:51:40.914105 15117 solver.cpp:233] Iteration 43030, loss = 0.0141229
I0526 08:51:40.914132 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0141231 (* 1 = 0.0141231 loss)
I0526 08:51:40.914139 15117 sgd_solver.cpp:294] Iteration 43030, lr = 0.002
I0526 08:51:47.204957 15117 solver.cpp:233] Iteration 43040, loss = 0.0104972
I0526 08:51:47.205000 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0104974 (* 1 = 0.0104974 loss)
I0526 08:51:47.205008 15117 sgd_solver.cpp:294] Iteration 43040, lr = 0.002
I0526 08:51:53.497179 15117 solver.cpp:233] Iteration 43050, loss = 0.00988096
I0526 08:51:53.497220 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00988116 (* 1 = 0.00988116 loss)
I0526 08:51:53.497226 15117 sgd_solver.cpp:294] Iteration 43050, lr = 0.002
I0526 08:51:59.786435 15117 solver.cpp:233] Iteration 43060, loss = 0.0293783
I0526 08:51:59.786648 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0293785 (* 1 = 0.0293785 loss)
I0526 08:51:59.786674 15117 sgd_solver.cpp:294] Iteration 43060, lr = 0.002
I0526 08:52:06.075394 15117 solver.cpp:233] Iteration 43070, loss = 0.0281307
I0526 08:52:06.075441 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.028131 (* 1 = 0.028131 loss)
I0526 08:52:06.075449 15117 sgd_solver.cpp:294] Iteration 43070, lr = 0.002
I0526 08:52:12.360566 15117 solver.cpp:233] Iteration 43080, loss = 0.0111066
I0526 08:52:12.360610 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0111068 (* 1 = 0.0111068 loss)
I0526 08:52:12.360616 15117 sgd_solver.cpp:294] Iteration 43080, lr = 0.002
I0526 08:52:18.646250 15117 solver.cpp:233] Iteration 43090, loss = 0.00365586
I0526 08:52:18.646294 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00365607 (* 1 = 0.00365607 loss)
I0526 08:52:18.646301 15117 sgd_solver.cpp:294] Iteration 43090, lr = 0.002
I0526 08:52:24.337865 15117 solver.cpp:342] Iteration 43100, Testing net (#0)
I0526 08:52:37.121346 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8992
I0526 08:52:37.121465 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.457412 (* 1 = 0.457412 loss)
I0526 08:52:37.719446 15117 solver.cpp:233] Iteration 43100, loss = 0.0168554
I0526 08:52:37.719480 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0168556 (* 1 = 0.0168556 loss)
I0526 08:52:37.719487 15117 sgd_solver.cpp:294] Iteration 43100, lr = 0.002
I0526 08:52:44.013008 15117 solver.cpp:233] Iteration 43110, loss = 0.012068
I0526 08:52:44.013051 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0120682 (* 1 = 0.0120682 loss)
I0526 08:52:44.013058 15117 sgd_solver.cpp:294] Iteration 43110, lr = 0.002
I0526 08:52:50.298080 15117 solver.cpp:233] Iteration 43120, loss = 0.0505952
I0526 08:52:50.298115 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0505954 (* 1 = 0.0505954 loss)
I0526 08:52:50.298122 15117 sgd_solver.cpp:294] Iteration 43120, lr = 0.002
I0526 08:52:56.587662 15117 solver.cpp:233] Iteration 43130, loss = 0.0057812
I0526 08:52:56.587703 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00578141 (* 1 = 0.00578141 loss)
I0526 08:52:56.587712 15117 sgd_solver.cpp:294] Iteration 43130, lr = 0.002
I0526 08:53:02.877892 15117 solver.cpp:233] Iteration 43140, loss = 0.0109007
I0526 08:53:02.877939 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.010901 (* 1 = 0.010901 loss)
I0526 08:53:02.877948 15117 sgd_solver.cpp:294] Iteration 43140, lr = 0.002
I0526 08:53:09.162346 15117 solver.cpp:233] Iteration 43150, loss = 0.00783695
I0526 08:53:09.162508 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00783716 (* 1 = 0.00783716 loss)
I0526 08:53:09.162518 15117 sgd_solver.cpp:294] Iteration 43150, lr = 0.002
I0526 08:53:15.450235 15117 solver.cpp:233] Iteration 43160, loss = 0.0110474
I0526 08:53:15.450275 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0110476 (* 1 = 0.0110476 loss)
I0526 08:53:15.450283 15117 sgd_solver.cpp:294] Iteration 43160, lr = 0.002
I0526 08:53:21.739928 15117 solver.cpp:233] Iteration 43170, loss = 0.0126991
I0526 08:53:21.739974 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0126994 (* 1 = 0.0126994 loss)
I0526 08:53:21.739981 15117 sgd_solver.cpp:294] Iteration 43170, lr = 0.002
I0526 08:53:28.031497 15117 solver.cpp:233] Iteration 43180, loss = 0.00594263
I0526 08:53:28.031538 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00594284 (* 1 = 0.00594284 loss)
I0526 08:53:28.031543 15117 sgd_solver.cpp:294] Iteration 43180, lr = 0.002
I0526 08:53:34.319998 15117 solver.cpp:233] Iteration 43190, loss = 0.00505202
I0526 08:53:34.320040 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00505223 (* 1 = 0.00505223 loss)
I0526 08:53:34.320047 15117 sgd_solver.cpp:294] Iteration 43190, lr = 0.002
I0526 08:53:40.014796 15117 solver.cpp:342] Iteration 43200, Testing net (#0)
I0526 08:53:52.798600 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9007
I0526 08:53:52.798645 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.436161 (* 1 = 0.436161 loss)
I0526 08:53:53.395373 15117 solver.cpp:233] Iteration 43200, loss = 0.00872914
I0526 08:53:53.395407 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00872935 (* 1 = 0.00872935 loss)
I0526 08:53:53.395414 15117 sgd_solver.cpp:294] Iteration 43200, lr = 0.002
I0526 08:53:59.685611 15117 solver.cpp:233] Iteration 43210, loss = 0.0140479
I0526 08:53:59.685643 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0140482 (* 1 = 0.0140482 loss)
I0526 08:53:59.685652 15117 sgd_solver.cpp:294] Iteration 43210, lr = 0.002
I0526 08:54:05.976300 15117 solver.cpp:233] Iteration 43220, loss = 0.0276339
I0526 08:54:05.976343 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0276341 (* 1 = 0.0276341 loss)
I0526 08:54:05.976351 15117 sgd_solver.cpp:294] Iteration 43220, lr = 0.002
I0526 08:54:12.261386 15117 solver.cpp:233] Iteration 43230, loss = 0.0089112
I0526 08:54:12.261587 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00891141 (* 1 = 0.00891141 loss)
I0526 08:54:12.261615 15117 sgd_solver.cpp:294] Iteration 43230, lr = 0.002
I0526 08:54:18.550052 15117 solver.cpp:233] Iteration 43240, loss = 0.0108409
I0526 08:54:18.550096 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0108411 (* 1 = 0.0108411 loss)
I0526 08:54:18.550102 15117 sgd_solver.cpp:294] Iteration 43240, lr = 0.002
I0526 08:54:24.841711 15117 solver.cpp:233] Iteration 43250, loss = 0.00539697
I0526 08:54:24.841752 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00539718 (* 1 = 0.00539718 loss)
I0526 08:54:24.841758 15117 sgd_solver.cpp:294] Iteration 43250, lr = 0.002
I0526 08:54:31.130427 15117 solver.cpp:233] Iteration 43260, loss = 0.00958835
I0526 08:54:31.130468 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00958856 (* 1 = 0.00958856 loss)
I0526 08:54:31.130476 15117 sgd_solver.cpp:294] Iteration 43260, lr = 0.002
I0526 08:54:37.418496 15117 solver.cpp:233] Iteration 43270, loss = 0.0261771
I0526 08:54:37.418540 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0261773 (* 1 = 0.0261773 loss)
I0526 08:54:37.418547 15117 sgd_solver.cpp:294] Iteration 43270, lr = 0.002
I0526 08:54:43.706076 15117 solver.cpp:233] Iteration 43280, loss = 0.0106316
I0526 08:54:43.706333 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0106318 (* 1 = 0.0106318 loss)
I0526 08:54:43.706385 15117 sgd_solver.cpp:294] Iteration 43280, lr = 0.002
I0526 08:54:49.994562 15117 solver.cpp:233] Iteration 43290, loss = 0.00673564
I0526 08:54:49.994606 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00673585 (* 1 = 0.00673585 loss)
I0526 08:54:49.994613 15117 sgd_solver.cpp:294] Iteration 43290, lr = 0.002
I0526 08:54:55.687577 15117 solver.cpp:342] Iteration 43300, Testing net (#0)
I0526 08:55:08.471956 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9032
I0526 08:55:08.472012 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.442481 (* 1 = 0.442481 loss)
I0526 08:55:09.069006 15117 solver.cpp:233] Iteration 43300, loss = 0.00927563
I0526 08:55:09.069046 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00927584 (* 1 = 0.00927584 loss)
I0526 08:55:09.069053 15117 sgd_solver.cpp:294] Iteration 43300, lr = 0.002
I0526 08:55:15.355351 15117 solver.cpp:233] Iteration 43310, loss = 0.0413732
I0526 08:55:15.355552 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0413734 (* 1 = 0.0413734 loss)
I0526 08:55:15.355579 15117 sgd_solver.cpp:294] Iteration 43310, lr = 0.002
I0526 08:55:21.646680 15117 solver.cpp:233] Iteration 43320, loss = 0.0141363
I0526 08:55:21.646723 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0141365 (* 1 = 0.0141365 loss)
I0526 08:55:21.646729 15117 sgd_solver.cpp:294] Iteration 43320, lr = 0.002
I0526 08:55:27.938002 15117 solver.cpp:233] Iteration 43330, loss = 0.00669472
I0526 08:55:27.938042 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00669493 (* 1 = 0.00669493 loss)
I0526 08:55:27.938050 15117 sgd_solver.cpp:294] Iteration 43330, lr = 0.002
I0526 08:55:34.226930 15117 solver.cpp:233] Iteration 43340, loss = 0.010722
I0526 08:55:34.226975 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0107222 (* 1 = 0.0107222 loss)
I0526 08:55:34.226982 15117 sgd_solver.cpp:294] Iteration 43340, lr = 0.002
I0526 08:55:40.515882 15117 solver.cpp:233] Iteration 43350, loss = 0.0109442
I0526 08:55:40.515923 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0109444 (* 1 = 0.0109444 loss)
I0526 08:55:40.515928 15117 sgd_solver.cpp:294] Iteration 43350, lr = 0.002
I0526 08:55:46.803692 15117 solver.cpp:233] Iteration 43360, loss = 0.0309717
I0526 08:55:46.803748 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0309719 (* 1 = 0.0309719 loss)
I0526 08:55:46.803756 15117 sgd_solver.cpp:294] Iteration 43360, lr = 0.002
I0526 08:55:53.092456 15117 solver.cpp:233] Iteration 43370, loss = 0.00824326
I0526 08:55:53.092496 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00824347 (* 1 = 0.00824347 loss)
I0526 08:55:53.092504 15117 sgd_solver.cpp:294] Iteration 43370, lr = 0.002
I0526 08:55:59.379281 15117 solver.cpp:233] Iteration 43380, loss = 0.00994646
I0526 08:55:59.379323 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00994667 (* 1 = 0.00994667 loss)
I0526 08:55:59.379328 15117 sgd_solver.cpp:294] Iteration 43380, lr = 0.002
I0526 08:56:05.669174 15117 solver.cpp:233] Iteration 43390, loss = 0.0204097
I0526 08:56:05.669219 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.02041 (* 1 = 0.02041 loss)
I0526 08:56:05.669232 15117 sgd_solver.cpp:294] Iteration 43390, lr = 0.002
I0526 08:56:11.360898 15117 solver.cpp:342] Iteration 43400, Testing net (#0)
I0526 08:56:24.143028 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.905
I0526 08:56:24.143286 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.433111 (* 1 = 0.433111 loss)
I0526 08:56:24.744776 15117 solver.cpp:233] Iteration 43400, loss = 0.0064053
I0526 08:56:24.744839 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00640551 (* 1 = 0.00640551 loss)
I0526 08:56:24.744850 15117 sgd_solver.cpp:294] Iteration 43400, lr = 0.002
I0526 08:56:31.031493 15117 solver.cpp:233] Iteration 43410, loss = 0.0340923
I0526 08:56:31.031535 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0340925 (* 1 = 0.0340925 loss)
I0526 08:56:31.031543 15117 sgd_solver.cpp:294] Iteration 43410, lr = 0.002
I0526 08:56:37.317118 15117 solver.cpp:233] Iteration 43420, loss = 0.0187369
I0526 08:56:37.317172 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0187371 (* 1 = 0.0187371 loss)
I0526 08:56:37.317178 15117 sgd_solver.cpp:294] Iteration 43420, lr = 0.002
I0526 08:56:43.604827 15117 solver.cpp:233] Iteration 43430, loss = 0.0141073
I0526 08:56:43.604868 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0141075 (* 1 = 0.0141075 loss)
I0526 08:56:43.604876 15117 sgd_solver.cpp:294] Iteration 43430, lr = 0.002
I0526 08:56:49.894450 15117 solver.cpp:233] Iteration 43440, loss = 0.0132477
I0526 08:56:49.894495 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0132479 (* 1 = 0.0132479 loss)
I0526 08:56:49.894503 15117 sgd_solver.cpp:294] Iteration 43440, lr = 0.002
I0526 08:56:56.182958 15117 solver.cpp:233] Iteration 43450, loss = 0.0118682
I0526 08:56:56.183166 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0118684 (* 1 = 0.0118684 loss)
I0526 08:56:56.183192 15117 sgd_solver.cpp:294] Iteration 43450, lr = 0.002
I0526 08:57:02.474752 15117 solver.cpp:233] Iteration 43460, loss = 0.0112941
I0526 08:57:02.474797 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0112944 (* 1 = 0.0112944 loss)
I0526 08:57:02.474804 15117 sgd_solver.cpp:294] Iteration 43460, lr = 0.002
I0526 08:57:08.763151 15117 solver.cpp:233] Iteration 43470, loss = 0.0239521
I0526 08:57:08.763191 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0239523 (* 1 = 0.0239523 loss)
I0526 08:57:08.763198 15117 sgd_solver.cpp:294] Iteration 43470, lr = 0.002
I0526 08:57:15.054410 15117 solver.cpp:233] Iteration 43480, loss = 0.00242593
I0526 08:57:15.054443 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00242613 (* 1 = 0.00242613 loss)
I0526 08:57:15.054450 15117 sgd_solver.cpp:294] Iteration 43480, lr = 0.002
I0526 08:57:21.342592 15117 solver.cpp:233] Iteration 43490, loss = 0.00296018
I0526 08:57:21.342636 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00296039 (* 1 = 0.00296039 loss)
I0526 08:57:21.342644 15117 sgd_solver.cpp:294] Iteration 43490, lr = 0.002
I0526 08:57:27.034245 15117 solver.cpp:342] Iteration 43500, Testing net (#0)
I0526 08:57:39.812453 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9022
I0526 08:57:39.812500 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.455571 (* 1 = 0.455571 loss)
I0526 08:57:40.408911 15117 solver.cpp:233] Iteration 43500, loss = 0.0107281
I0526 08:57:40.408947 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0107283 (* 1 = 0.0107283 loss)
I0526 08:57:40.408954 15117 sgd_solver.cpp:294] Iteration 43500, lr = 0.002
I0526 08:57:46.698820 15117 solver.cpp:233] Iteration 43510, loss = 0.009882
I0526 08:57:46.698864 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00988221 (* 1 = 0.00988221 loss)
I0526 08:57:46.698870 15117 sgd_solver.cpp:294] Iteration 43510, lr = 0.002
I0526 08:57:52.988641 15117 solver.cpp:233] Iteration 43520, loss = 0.010261
I0526 08:57:52.988680 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0102612 (* 1 = 0.0102612 loss)
I0526 08:57:52.988693 15117 sgd_solver.cpp:294] Iteration 43520, lr = 0.002
I0526 08:57:59.276507 15117 solver.cpp:233] Iteration 43530, loss = 0.0244652
I0526 08:57:59.276667 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0244654 (* 1 = 0.0244654 loss)
I0526 08:57:59.276675 15117 sgd_solver.cpp:294] Iteration 43530, lr = 0.002
I0526 08:58:05.562739 15117 solver.cpp:233] Iteration 43540, loss = 0.00537746
I0526 08:58:05.562783 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00537767 (* 1 = 0.00537767 loss)
I0526 08:58:05.562790 15117 sgd_solver.cpp:294] Iteration 43540, lr = 0.002
I0526 08:58:11.851641 15117 solver.cpp:233] Iteration 43550, loss = 0.0167102
I0526 08:58:11.851680 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0167104 (* 1 = 0.0167104 loss)
I0526 08:58:11.851687 15117 sgd_solver.cpp:294] Iteration 43550, lr = 0.002
I0526 08:58:18.138155 15117 solver.cpp:233] Iteration 43560, loss = 0.0179696
I0526 08:58:18.138200 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0179698 (* 1 = 0.0179698 loss)
I0526 08:58:18.138207 15117 sgd_solver.cpp:294] Iteration 43560, lr = 0.002
I0526 08:58:24.424780 15117 solver.cpp:233] Iteration 43570, loss = 0.0230326
I0526 08:58:24.424823 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0230328 (* 1 = 0.0230328 loss)
I0526 08:58:24.424829 15117 sgd_solver.cpp:294] Iteration 43570, lr = 0.002
I0526 08:58:30.709933 15117 solver.cpp:233] Iteration 43580, loss = 0.00905055
I0526 08:58:30.710047 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00905075 (* 1 = 0.00905075 loss)
I0526 08:58:30.710054 15117 sgd_solver.cpp:294] Iteration 43580, lr = 0.002
I0526 08:58:36.999652 15117 solver.cpp:233] Iteration 43590, loss = 0.0166937
I0526 08:58:36.999696 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0166939 (* 1 = 0.0166939 loss)
I0526 08:58:36.999702 15117 sgd_solver.cpp:294] Iteration 43590, lr = 0.002
I0526 08:58:42.694579 15117 solver.cpp:342] Iteration 43600, Testing net (#0)
I0526 08:58:55.482522 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9032
I0526 08:58:55.482568 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.436179 (* 1 = 0.436179 loss)
I0526 08:58:56.079007 15117 solver.cpp:233] Iteration 43600, loss = 0.0609064
I0526 08:58:56.079042 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0609067 (* 1 = 0.0609067 loss)
I0526 08:58:56.079049 15117 sgd_solver.cpp:294] Iteration 43600, lr = 0.002
I0526 08:59:02.369576 15117 solver.cpp:233] Iteration 43610, loss = 0.00847335
I0526 08:59:02.369688 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00847355 (* 1 = 0.00847355 loss)
I0526 08:59:02.369698 15117 sgd_solver.cpp:294] Iteration 43610, lr = 0.002
I0526 08:59:08.661234 15117 solver.cpp:233] Iteration 43620, loss = 0.00527912
I0526 08:59:08.661265 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00527933 (* 1 = 0.00527933 loss)
I0526 08:59:08.661273 15117 sgd_solver.cpp:294] Iteration 43620, lr = 0.002
I0526 08:59:14.949110 15117 solver.cpp:233] Iteration 43630, loss = 0.0123273
I0526 08:59:14.949149 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0123275 (* 1 = 0.0123275 loss)
I0526 08:59:14.949156 15117 sgd_solver.cpp:294] Iteration 43630, lr = 0.002
I0526 08:59:21.234089 15117 solver.cpp:233] Iteration 43640, loss = 0.00883799
I0526 08:59:21.234133 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00883819 (* 1 = 0.00883819 loss)
I0526 08:59:21.234140 15117 sgd_solver.cpp:294] Iteration 43640, lr = 0.002
I0526 08:59:27.519285 15117 solver.cpp:233] Iteration 43650, loss = 0.0194336
I0526 08:59:27.519326 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0194338 (* 1 = 0.0194338 loss)
I0526 08:59:27.519333 15117 sgd_solver.cpp:294] Iteration 43650, lr = 0.002
I0526 08:59:33.804304 15117 solver.cpp:233] Iteration 43660, loss = 0.0291403
I0526 08:59:33.804565 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0291405 (* 1 = 0.0291405 loss)
I0526 08:59:33.804600 15117 sgd_solver.cpp:294] Iteration 43660, lr = 0.002
I0526 08:59:40.090221 15117 solver.cpp:233] Iteration 43670, loss = 0.0101356
I0526 08:59:40.090265 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0101358 (* 1 = 0.0101358 loss)
I0526 08:59:40.090271 15117 sgd_solver.cpp:294] Iteration 43670, lr = 0.002
I0526 08:59:46.382726 15117 solver.cpp:233] Iteration 43680, loss = 0.00351098
I0526 08:59:46.382766 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00351118 (* 1 = 0.00351118 loss)
I0526 08:59:46.382773 15117 sgd_solver.cpp:294] Iteration 43680, lr = 0.002
I0526 08:59:52.672379 15117 solver.cpp:233] Iteration 43690, loss = 0.0121731
I0526 08:59:52.672420 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0121733 (* 1 = 0.0121733 loss)
I0526 08:59:52.672427 15117 sgd_solver.cpp:294] Iteration 43690, lr = 0.002
I0526 08:59:58.370210 15117 solver.cpp:342] Iteration 43700, Testing net (#0)
I0526 09:00:11.149883 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.903
I0526 09:00:11.150135 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.451565 (* 1 = 0.451565 loss)
I0526 09:00:11.751951 15117 solver.cpp:233] Iteration 43700, loss = 0.0228977
I0526 09:00:11.751983 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0228979 (* 1 = 0.0228979 loss)
I0526 09:00:11.751991 15117 sgd_solver.cpp:294] Iteration 43700, lr = 0.002
I0526 09:00:18.042619 15117 solver.cpp:233] Iteration 43710, loss = 0.015893
I0526 09:00:18.042667 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0158932 (* 1 = 0.0158932 loss)
I0526 09:00:18.042685 15117 sgd_solver.cpp:294] Iteration 43710, lr = 0.002
I0526 09:00:24.331025 15117 solver.cpp:233] Iteration 43720, loss = 0.00667913
I0526 09:00:24.331073 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00667934 (* 1 = 0.00667934 loss)
I0526 09:00:24.331081 15117 sgd_solver.cpp:294] Iteration 43720, lr = 0.002
I0526 09:00:30.620640 15117 solver.cpp:233] Iteration 43730, loss = 0.00946907
I0526 09:00:30.620682 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00946927 (* 1 = 0.00946927 loss)
I0526 09:00:30.620689 15117 sgd_solver.cpp:294] Iteration 43730, lr = 0.002
I0526 09:00:36.908514 15117 solver.cpp:233] Iteration 43740, loss = 0.0125672
I0526 09:00:36.908555 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0125675 (* 1 = 0.0125675 loss)
I0526 09:00:36.908563 15117 sgd_solver.cpp:294] Iteration 43740, lr = 0.002
I0526 09:00:43.197852 15117 solver.cpp:233] Iteration 43750, loss = 0.00604723
I0526 09:00:43.197975 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00604743 (* 1 = 0.00604743 loss)
I0526 09:00:43.197984 15117 sgd_solver.cpp:294] Iteration 43750, lr = 0.002
I0526 09:00:49.490070 15117 solver.cpp:233] Iteration 43760, loss = 0.0216622
I0526 09:00:49.490113 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0216624 (* 1 = 0.0216624 loss)
I0526 09:00:49.490119 15117 sgd_solver.cpp:294] Iteration 43760, lr = 0.002
I0526 09:00:55.780351 15117 solver.cpp:233] Iteration 43770, loss = 0.00422078
I0526 09:00:55.780383 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00422098 (* 1 = 0.00422098 loss)
I0526 09:00:55.780391 15117 sgd_solver.cpp:294] Iteration 43770, lr = 0.002
I0526 09:01:02.069869 15117 solver.cpp:233] Iteration 43780, loss = 0.0174076
I0526 09:01:02.069908 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0174078 (* 1 = 0.0174078 loss)
I0526 09:01:02.069916 15117 sgd_solver.cpp:294] Iteration 43780, lr = 0.002
I0526 09:01:08.362344 15117 solver.cpp:233] Iteration 43790, loss = 0.0115735
I0526 09:01:08.362397 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0115737 (* 1 = 0.0115737 loss)
I0526 09:01:08.362404 15117 sgd_solver.cpp:294] Iteration 43790, lr = 0.002
I0526 09:01:14.055527 15117 solver.cpp:342] Iteration 43800, Testing net (#0)
I0526 09:01:26.848214 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9009
I0526 09:01:26.848260 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.452974 (* 1 = 0.452974 loss)
I0526 09:01:27.445407 15117 solver.cpp:233] Iteration 43800, loss = 0.015955
I0526 09:01:27.445446 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0159552 (* 1 = 0.0159552 loss)
I0526 09:01:27.445452 15117 sgd_solver.cpp:294] Iteration 43800, lr = 0.002
I0526 09:01:33.736778 15117 solver.cpp:233] Iteration 43810, loss = 0.00399709
I0526 09:01:33.736820 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00399729 (* 1 = 0.00399729 loss)
I0526 09:01:33.736829 15117 sgd_solver.cpp:294] Iteration 43810, lr = 0.002
I0526 09:01:40.023876 15117 solver.cpp:233] Iteration 43820, loss = 0.0128084
I0526 09:01:40.023924 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0128086 (* 1 = 0.0128086 loss)
I0526 09:01:40.023932 15117 sgd_solver.cpp:294] Iteration 43820, lr = 0.002
I0526 09:01:46.315419 15117 solver.cpp:233] Iteration 43830, loss = 0.0108163
I0526 09:01:46.315552 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0108165 (* 1 = 0.0108165 loss)
I0526 09:01:46.315562 15117 sgd_solver.cpp:294] Iteration 43830, lr = 0.002
I0526 09:01:52.604527 15117 solver.cpp:233] Iteration 43840, loss = 0.0147001
I0526 09:01:52.604569 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0147003 (* 1 = 0.0147003 loss)
I0526 09:01:52.604575 15117 sgd_solver.cpp:294] Iteration 43840, lr = 0.002
I0526 09:01:58.892858 15117 solver.cpp:233] Iteration 43850, loss = 0.000946486
I0526 09:01:58.892901 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000946691 (* 1 = 0.000946691 loss)
I0526 09:01:58.892909 15117 sgd_solver.cpp:294] Iteration 43850, lr = 0.002
I0526 09:02:05.184080 15117 solver.cpp:233] Iteration 43860, loss = 0.0275456
I0526 09:02:05.184123 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0275458 (* 1 = 0.0275458 loss)
I0526 09:02:05.184130 15117 sgd_solver.cpp:294] Iteration 43860, lr = 0.002
I0526 09:02:11.474727 15117 solver.cpp:233] Iteration 43870, loss = 0.012553
I0526 09:02:11.474771 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0125532 (* 1 = 0.0125532 loss)
I0526 09:02:11.474779 15117 sgd_solver.cpp:294] Iteration 43870, lr = 0.002
I0526 09:02:17.763381 15117 solver.cpp:233] Iteration 43880, loss = 0.00457225
I0526 09:02:17.763578 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00457246 (* 1 = 0.00457246 loss)
I0526 09:02:17.763607 15117 sgd_solver.cpp:294] Iteration 43880, lr = 0.002
I0526 09:02:24.052475 15117 solver.cpp:233] Iteration 43890, loss = 0.0148056
I0526 09:02:24.052517 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0148058 (* 1 = 0.0148058 loss)
I0526 09:02:24.052525 15117 sgd_solver.cpp:294] Iteration 43890, lr = 0.002
I0526 09:02:29.747400 15117 solver.cpp:342] Iteration 43900, Testing net (#0)
I0526 09:02:42.535902 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9038
I0526 09:02:42.535948 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.446546 (* 1 = 0.446546 loss)
I0526 09:02:43.132961 15117 solver.cpp:233] Iteration 43900, loss = 0.00982772
I0526 09:02:43.133002 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00982793 (* 1 = 0.00982793 loss)
I0526 09:02:43.133008 15117 sgd_solver.cpp:294] Iteration 43900, lr = 0.002
I0526 09:02:49.417140 15117 solver.cpp:233] Iteration 43910, loss = 0.0178273
I0526 09:02:49.417244 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0178275 (* 1 = 0.0178275 loss)
I0526 09:02:49.417253 15117 sgd_solver.cpp:294] Iteration 43910, lr = 0.002
I0526 09:02:55.705327 15117 solver.cpp:233] Iteration 43920, loss = 0.0145036
I0526 09:02:55.705369 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0145038 (* 1 = 0.0145038 loss)
I0526 09:02:55.705376 15117 sgd_solver.cpp:294] Iteration 43920, lr = 0.002
I0526 09:03:01.996747 15117 solver.cpp:233] Iteration 43930, loss = 0.0180395
I0526 09:03:01.996788 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0180397 (* 1 = 0.0180397 loss)
I0526 09:03:01.996795 15117 sgd_solver.cpp:294] Iteration 43930, lr = 0.002
I0526 09:03:08.286893 15117 solver.cpp:233] Iteration 43940, loss = 0.0174408
I0526 09:03:08.286945 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.017441 (* 1 = 0.017441 loss)
I0526 09:03:08.286952 15117 sgd_solver.cpp:294] Iteration 43940, lr = 0.002
I0526 09:03:14.577376 15117 solver.cpp:233] Iteration 43950, loss = 0.0114125
I0526 09:03:14.577419 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0114127 (* 1 = 0.0114127 loss)
I0526 09:03:14.577426 15117 sgd_solver.cpp:294] Iteration 43950, lr = 0.002
I0526 09:03:20.867930 15117 solver.cpp:233] Iteration 43960, loss = 0.00710117
I0526 09:03:20.868191 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00710137 (* 1 = 0.00710137 loss)
I0526 09:03:20.868218 15117 sgd_solver.cpp:294] Iteration 43960, lr = 0.002
I0526 09:03:27.150449 15117 solver.cpp:233] Iteration 43970, loss = 0.00709302
I0526 09:03:27.150495 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00709322 (* 1 = 0.00709322 loss)
I0526 09:03:27.150501 15117 sgd_solver.cpp:294] Iteration 43970, lr = 0.002
I0526 09:03:33.439185 15117 solver.cpp:233] Iteration 43980, loss = 0.0206671
I0526 09:03:33.439229 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0206673 (* 1 = 0.0206673 loss)
I0526 09:03:33.439235 15117 sgd_solver.cpp:294] Iteration 43980, lr = 0.002
I0526 09:03:39.728255 15117 solver.cpp:233] Iteration 43990, loss = 0.0378658
I0526 09:03:39.728302 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.037866 (* 1 = 0.037866 loss)
I0526 09:03:39.728309 15117 sgd_solver.cpp:294] Iteration 43990, lr = 0.002
I0526 09:03:45.418620 15117 solver.cpp:342] Iteration 44000, Testing net (#0)
I0526 09:03:58.198774 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9019
I0526 09:03:58.199019 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.451768 (* 1 = 0.451768 loss)
I0526 09:03:58.795809 15117 solver.cpp:233] Iteration 44000, loss = 0.00898659
I0526 09:03:58.795848 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00898679 (* 1 = 0.00898679 loss)
I0526 09:03:58.795855 15117 sgd_solver.cpp:294] Iteration 44000, lr = 0.002
I0526 09:04:05.083251 15117 solver.cpp:233] Iteration 44010, loss = 0.0237404
I0526 09:04:05.083292 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0237406 (* 1 = 0.0237406 loss)
I0526 09:04:05.083298 15117 sgd_solver.cpp:294] Iteration 44010, lr = 0.002
I0526 09:04:11.374254 15117 solver.cpp:233] Iteration 44020, loss = 0.0137057
I0526 09:04:11.374299 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0137059 (* 1 = 0.0137059 loss)
I0526 09:04:11.374305 15117 sgd_solver.cpp:294] Iteration 44020, lr = 0.002
I0526 09:04:17.665458 15117 solver.cpp:233] Iteration 44030, loss = 0.00988461
I0526 09:04:17.665511 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00988482 (* 1 = 0.00988482 loss)
I0526 09:04:17.665529 15117 sgd_solver.cpp:294] Iteration 44030, lr = 0.002
I0526 09:04:23.954601 15117 solver.cpp:233] Iteration 44040, loss = 0.00726077
I0526 09:04:23.954644 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00726097 (* 1 = 0.00726097 loss)
I0526 09:04:23.954651 15117 sgd_solver.cpp:294] Iteration 44040, lr = 0.002
I0526 09:04:30.243865 15117 solver.cpp:233] Iteration 44050, loss = 0.016826
I0526 09:04:30.244096 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0168262 (* 1 = 0.0168262 loss)
I0526 09:04:30.244128 15117 sgd_solver.cpp:294] Iteration 44050, lr = 0.002
I0526 09:04:36.535943 15117 solver.cpp:233] Iteration 44060, loss = 0.00385003
I0526 09:04:36.535989 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00385024 (* 1 = 0.00385024 loss)
I0526 09:04:36.535995 15117 sgd_solver.cpp:294] Iteration 44060, lr = 0.002
I0526 09:04:42.824501 15117 solver.cpp:233] Iteration 44070, loss = 0.033975
I0526 09:04:42.824544 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0339752 (* 1 = 0.0339752 loss)
I0526 09:04:42.824553 15117 sgd_solver.cpp:294] Iteration 44070, lr = 0.002
I0526 09:04:49.109917 15117 solver.cpp:233] Iteration 44080, loss = 0.00824119
I0526 09:04:49.109958 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00824139 (* 1 = 0.00824139 loss)
I0526 09:04:49.109966 15117 sgd_solver.cpp:294] Iteration 44080, lr = 0.002
I0526 09:04:55.397158 15117 solver.cpp:233] Iteration 44090, loss = 0.0127223
I0526 09:04:55.397193 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0127226 (* 1 = 0.0127226 loss)
I0526 09:04:55.397200 15117 sgd_solver.cpp:294] Iteration 44090, lr = 0.002
I0526 09:05:01.087692 15117 solver.cpp:342] Iteration 44100, Testing net (#0)
I0526 09:05:13.873244 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9022
I0526 09:05:13.873289 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.452097 (* 1 = 0.452097 loss)
I0526 09:05:14.469523 15117 solver.cpp:233] Iteration 44100, loss = 0.0234919
I0526 09:05:14.469558 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0234921 (* 1 = 0.0234921 loss)
I0526 09:05:14.469565 15117 sgd_solver.cpp:294] Iteration 44100, lr = 0.002
I0526 09:05:20.756861 15117 solver.cpp:233] Iteration 44110, loss = 0.00727651
I0526 09:05:20.756903 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00727671 (* 1 = 0.00727671 loss)
I0526 09:05:20.756911 15117 sgd_solver.cpp:294] Iteration 44110, lr = 0.002
I0526 09:05:27.043745 15117 solver.cpp:233] Iteration 44120, loss = 0.00880557
I0526 09:05:27.043789 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00880578 (* 1 = 0.00880578 loss)
I0526 09:05:27.043797 15117 sgd_solver.cpp:294] Iteration 44120, lr = 0.002
I0526 09:05:33.333385 15117 solver.cpp:233] Iteration 44130, loss = 0.01421
I0526 09:05:33.333626 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0142102 (* 1 = 0.0142102 loss)
I0526 09:05:33.333657 15117 sgd_solver.cpp:294] Iteration 44130, lr = 0.002
I0526 09:05:39.630393 15117 solver.cpp:233] Iteration 44140, loss = 0.0226389
I0526 09:05:39.630441 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0226391 (* 1 = 0.0226391 loss)
I0526 09:05:39.630450 15117 sgd_solver.cpp:294] Iteration 44140, lr = 0.002
I0526 09:05:45.921694 15117 solver.cpp:233] Iteration 44150, loss = 0.033667
I0526 09:05:45.921730 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0336672 (* 1 = 0.0336672 loss)
I0526 09:05:45.921738 15117 sgd_solver.cpp:294] Iteration 44150, lr = 0.002
I0526 09:05:52.206243 15117 solver.cpp:233] Iteration 44160, loss = 0.0071665
I0526 09:05:52.206284 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00716671 (* 1 = 0.00716671 loss)
I0526 09:05:52.206291 15117 sgd_solver.cpp:294] Iteration 44160, lr = 0.002
I0526 09:05:58.489704 15117 solver.cpp:233] Iteration 44170, loss = 0.0266608
I0526 09:05:58.489748 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.026661 (* 1 = 0.026661 loss)
I0526 09:05:58.489756 15117 sgd_solver.cpp:294] Iteration 44170, lr = 0.002
I0526 09:06:04.773566 15117 solver.cpp:233] Iteration 44180, loss = 0.011565
I0526 09:06:04.773706 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0115652 (* 1 = 0.0115652 loss)
I0526 09:06:04.773715 15117 sgd_solver.cpp:294] Iteration 44180, lr = 0.002
I0526 09:06:11.065342 15117 solver.cpp:233] Iteration 44190, loss = 0.00483976
I0526 09:06:11.065384 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00483997 (* 1 = 0.00483997 loss)
I0526 09:06:11.065392 15117 sgd_solver.cpp:294] Iteration 44190, lr = 0.002
I0526 09:06:16.756244 15117 solver.cpp:342] Iteration 44200, Testing net (#0)
I0526 09:06:29.533622 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.904
I0526 09:06:29.533671 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.436188 (* 1 = 0.436188 loss)
I0526 09:06:30.130439 15117 solver.cpp:233] Iteration 44200, loss = 0.0269195
I0526 09:06:30.130475 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0269197 (* 1 = 0.0269197 loss)
I0526 09:06:30.130481 15117 sgd_solver.cpp:294] Iteration 44200, lr = 0.002
I0526 09:06:36.412353 15117 solver.cpp:233] Iteration 44210, loss = 0.0156076
I0526 09:06:36.412530 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0156079 (* 1 = 0.0156079 loss)
I0526 09:06:36.412539 15117 sgd_solver.cpp:294] Iteration 44210, lr = 0.002
I0526 09:06:42.703543 15117 solver.cpp:233] Iteration 44220, loss = 0.00645173
I0526 09:06:42.703588 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00645193 (* 1 = 0.00645193 loss)
I0526 09:06:42.703594 15117 sgd_solver.cpp:294] Iteration 44220, lr = 0.002
I0526 09:06:48.989101 15117 solver.cpp:233] Iteration 44230, loss = 0.0126479
I0526 09:06:48.989142 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0126481 (* 1 = 0.0126481 loss)
I0526 09:06:48.989150 15117 sgd_solver.cpp:294] Iteration 44230, lr = 0.002
I0526 09:06:55.275403 15117 solver.cpp:233] Iteration 44240, loss = 0.00456718
I0526 09:06:55.275447 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00456739 (* 1 = 0.00456739 loss)
I0526 09:06:55.275455 15117 sgd_solver.cpp:294] Iteration 44240, lr = 0.002
I0526 09:07:01.563354 15117 solver.cpp:233] Iteration 44250, loss = 0.0292808
I0526 09:07:01.563400 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.029281 (* 1 = 0.029281 loss)
I0526 09:07:01.563407 15117 sgd_solver.cpp:294] Iteration 44250, lr = 0.002
I0526 09:07:07.852520 15117 solver.cpp:233] Iteration 44260, loss = 0.010361
I0526 09:07:07.852735 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0103612 (* 1 = 0.0103612 loss)
I0526 09:07:07.852762 15117 sgd_solver.cpp:294] Iteration 44260, lr = 0.002
I0526 09:07:14.143553 15117 solver.cpp:233] Iteration 44270, loss = 0.00936912
I0526 09:07:14.143600 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00936933 (* 1 = 0.00936933 loss)
I0526 09:07:14.143607 15117 sgd_solver.cpp:294] Iteration 44270, lr = 0.002
I0526 09:07:20.432880 15117 solver.cpp:233] Iteration 44280, loss = 0.00904109
I0526 09:07:20.432916 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0090413 (* 1 = 0.0090413 loss)
I0526 09:07:20.432924 15117 sgd_solver.cpp:294] Iteration 44280, lr = 0.002
I0526 09:07:26.720720 15117 solver.cpp:233] Iteration 44290, loss = 0.0107452
I0526 09:07:26.720762 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0107454 (* 1 = 0.0107454 loss)
I0526 09:07:26.720769 15117 sgd_solver.cpp:294] Iteration 44290, lr = 0.002
I0526 09:07:32.409817 15117 solver.cpp:342] Iteration 44300, Testing net (#0)
I0526 09:07:45.187472 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9031
I0526 09:07:45.187661 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.442201 (* 1 = 0.442201 loss)
I0526 09:07:45.785739 15117 solver.cpp:233] Iteration 44300, loss = 0.0110408
I0526 09:07:45.785787 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.011041 (* 1 = 0.011041 loss)
I0526 09:07:45.785796 15117 sgd_solver.cpp:294] Iteration 44300, lr = 0.002
I0526 09:07:52.073941 15117 solver.cpp:233] Iteration 44310, loss = 0.0209528
I0526 09:07:52.073997 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.020953 (* 1 = 0.020953 loss)
I0526 09:07:52.074004 15117 sgd_solver.cpp:294] Iteration 44310, lr = 0.002
I0526 09:07:58.361618 15117 solver.cpp:233] Iteration 44320, loss = 0.0155806
I0526 09:07:58.361660 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0155808 (* 1 = 0.0155808 loss)
I0526 09:07:58.361667 15117 sgd_solver.cpp:294] Iteration 44320, lr = 0.002
I0526 09:08:04.647512 15117 solver.cpp:233] Iteration 44330, loss = 0.0197538
I0526 09:08:04.647558 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.019754 (* 1 = 0.019754 loss)
I0526 09:08:04.647572 15117 sgd_solver.cpp:294] Iteration 44330, lr = 0.002
I0526 09:08:10.937322 15117 solver.cpp:233] Iteration 44340, loss = 0.0181456
I0526 09:08:10.937363 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0181459 (* 1 = 0.0181459 loss)
I0526 09:08:10.937371 15117 sgd_solver.cpp:294] Iteration 44340, lr = 0.002
I0526 09:08:17.229682 15117 solver.cpp:233] Iteration 44350, loss = 0.00940113
I0526 09:08:17.229862 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00940134 (* 1 = 0.00940134 loss)
I0526 09:08:17.229871 15117 sgd_solver.cpp:294] Iteration 44350, lr = 0.002
I0526 09:08:23.521338 15117 solver.cpp:233] Iteration 44360, loss = 0.00759142
I0526 09:08:23.521385 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00759163 (* 1 = 0.00759163 loss)
I0526 09:08:23.521394 15117 sgd_solver.cpp:294] Iteration 44360, lr = 0.002
I0526 09:08:29.807634 15117 solver.cpp:233] Iteration 44370, loss = 0.0115074
I0526 09:08:29.807675 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0115076 (* 1 = 0.0115076 loss)
I0526 09:08:29.807683 15117 sgd_solver.cpp:294] Iteration 44370, lr = 0.002
I0526 09:08:36.105621 15117 solver.cpp:233] Iteration 44380, loss = 0.0179152
I0526 09:08:36.105664 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0179154 (* 1 = 0.0179154 loss)
I0526 09:08:36.105671 15117 sgd_solver.cpp:294] Iteration 44380, lr = 0.002
I0526 09:08:42.395571 15117 solver.cpp:233] Iteration 44390, loss = 0.010998
I0526 09:08:42.395614 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0109982 (* 1 = 0.0109982 loss)
I0526 09:08:42.395622 15117 sgd_solver.cpp:294] Iteration 44390, lr = 0.002
I0526 09:08:48.088667 15117 solver.cpp:342] Iteration 44400, Testing net (#0)
I0526 09:09:00.867971 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9
I0526 09:09:00.868016 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.442555 (* 1 = 0.442555 loss)
I0526 09:09:01.464467 15117 solver.cpp:233] Iteration 44400, loss = 0.0252782
I0526 09:09:01.464507 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0252784 (* 1 = 0.0252784 loss)
I0526 09:09:01.464515 15117 sgd_solver.cpp:294] Iteration 44400, lr = 0.002
I0526 09:09:07.749305 15117 solver.cpp:233] Iteration 44410, loss = 0.018781
I0526 09:09:07.749349 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0187812 (* 1 = 0.0187812 loss)
I0526 09:09:07.749357 15117 sgd_solver.cpp:294] Iteration 44410, lr = 0.002
I0526 09:09:14.035717 15117 solver.cpp:233] Iteration 44420, loss = 0.0092889
I0526 09:09:14.035758 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00928912 (* 1 = 0.00928912 loss)
I0526 09:09:14.035765 15117 sgd_solver.cpp:294] Iteration 44420, lr = 0.002
I0526 09:09:20.324645 15117 solver.cpp:233] Iteration 44430, loss = 0.00396892
I0526 09:09:20.324846 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00396913 (* 1 = 0.00396913 loss)
I0526 09:09:20.324875 15117 sgd_solver.cpp:294] Iteration 44430, lr = 0.002
I0526 09:09:26.620678 15117 solver.cpp:233] Iteration 44440, loss = 0.0184566
I0526 09:09:26.620721 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0184568 (* 1 = 0.0184568 loss)
I0526 09:09:26.620728 15117 sgd_solver.cpp:294] Iteration 44440, lr = 0.002
I0526 09:09:32.911211 15117 solver.cpp:233] Iteration 44450, loss = 0.0138866
I0526 09:09:32.911243 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0138868 (* 1 = 0.0138868 loss)
I0526 09:09:32.911250 15117 sgd_solver.cpp:294] Iteration 44450, lr = 0.002
I0526 09:09:39.195585 15117 solver.cpp:233] Iteration 44460, loss = 0.0212857
I0526 09:09:39.195627 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.021286 (* 1 = 0.021286 loss)
I0526 09:09:39.195634 15117 sgd_solver.cpp:294] Iteration 44460, lr = 0.002
I0526 09:09:45.484406 15117 solver.cpp:233] Iteration 44470, loss = 0.0119421
I0526 09:09:45.484453 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0119423 (* 1 = 0.0119423 loss)
I0526 09:09:45.484460 15117 sgd_solver.cpp:294] Iteration 44470, lr = 0.002
I0526 09:09:51.771378 15117 solver.cpp:233] Iteration 44480, loss = 0.0403659
I0526 09:09:51.771533 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0403661 (* 1 = 0.0403661 loss)
I0526 09:09:51.771543 15117 sgd_solver.cpp:294] Iteration 44480, lr = 0.002
I0526 09:09:58.060652 15117 solver.cpp:233] Iteration 44490, loss = 0.0164414
I0526 09:09:58.060685 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0164416 (* 1 = 0.0164416 loss)
I0526 09:09:58.060693 15117 sgd_solver.cpp:294] Iteration 44490, lr = 0.002
I0526 09:10:03.750864 15117 solver.cpp:342] Iteration 44500, Testing net (#0)
I0526 09:10:16.539821 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9016
I0526 09:10:16.539863 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.440381 (* 1 = 0.440381 loss)
I0526 09:10:17.136957 15117 solver.cpp:233] Iteration 44500, loss = 0.0161687
I0526 09:10:17.136996 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.016169 (* 1 = 0.016169 loss)
I0526 09:10:17.137003 15117 sgd_solver.cpp:294] Iteration 44500, lr = 0.002
I0526 09:10:23.427731 15117 solver.cpp:233] Iteration 44510, loss = 0.00369631
I0526 09:10:23.427947 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00369652 (* 1 = 0.00369652 loss)
I0526 09:10:23.427976 15117 sgd_solver.cpp:294] Iteration 44510, lr = 0.002
I0526 09:10:29.718744 15117 solver.cpp:233] Iteration 44520, loss = 0.0177836
I0526 09:10:29.718785 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0177838 (* 1 = 0.0177838 loss)
I0526 09:10:29.718791 15117 sgd_solver.cpp:294] Iteration 44520, lr = 0.002
I0526 09:10:36.007961 15117 solver.cpp:233] Iteration 44530, loss = 0.0271223
I0526 09:10:36.007993 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0271225 (* 1 = 0.0271225 loss)
I0526 09:10:36.008000 15117 sgd_solver.cpp:294] Iteration 44530, lr = 0.002
I0526 09:10:42.301630 15117 solver.cpp:233] Iteration 44540, loss = 0.0072726
I0526 09:10:42.301671 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00727281 (* 1 = 0.00727281 loss)
I0526 09:10:42.301677 15117 sgd_solver.cpp:294] Iteration 44540, lr = 0.002
I0526 09:10:48.590479 15117 solver.cpp:233] Iteration 44550, loss = 0.0081523
I0526 09:10:48.590524 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00815251 (* 1 = 0.00815251 loss)
I0526 09:10:48.590531 15117 sgd_solver.cpp:294] Iteration 44550, lr = 0.002
I0526 09:10:54.875541 15117 solver.cpp:233] Iteration 44560, loss = 0.013411
I0526 09:10:54.875764 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0134113 (* 1 = 0.0134113 loss)
I0526 09:10:54.875794 15117 sgd_solver.cpp:294] Iteration 44560, lr = 0.002
I0526 09:11:01.166232 15117 solver.cpp:233] Iteration 44570, loss = 0.0205158
I0526 09:11:01.166275 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.020516 (* 1 = 0.020516 loss)
I0526 09:11:01.166282 15117 sgd_solver.cpp:294] Iteration 44570, lr = 0.002
I0526 09:11:07.454537 15117 solver.cpp:233] Iteration 44580, loss = 0.00687749
I0526 09:11:07.454582 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0068777 (* 1 = 0.0068777 loss)
I0526 09:11:07.454591 15117 sgd_solver.cpp:294] Iteration 44580, lr = 0.002
I0526 09:11:13.744866 15117 solver.cpp:233] Iteration 44590, loss = 0.00257148
I0526 09:11:13.744910 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00257169 (* 1 = 0.00257169 loss)
I0526 09:11:13.744918 15117 sgd_solver.cpp:294] Iteration 44590, lr = 0.002
I0526 09:11:19.441643 15117 solver.cpp:342] Iteration 44600, Testing net (#0)
I0526 09:11:32.222131 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9015
I0526 09:11:32.222407 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.440036 (* 1 = 0.440036 loss)
I0526 09:11:32.819923 15117 solver.cpp:233] Iteration 44600, loss = 0.0206318
I0526 09:11:32.819974 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.020632 (* 1 = 0.020632 loss)
I0526 09:11:32.819983 15117 sgd_solver.cpp:294] Iteration 44600, lr = 0.002
I0526 09:11:39.109585 15117 solver.cpp:233] Iteration 44610, loss = 0.00753688
I0526 09:11:39.109627 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00753709 (* 1 = 0.00753709 loss)
I0526 09:11:39.109633 15117 sgd_solver.cpp:294] Iteration 44610, lr = 0.002
I0526 09:11:45.400476 15117 solver.cpp:233] Iteration 44620, loss = 0.0227283
I0526 09:11:45.400519 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0227285 (* 1 = 0.0227285 loss)
I0526 09:11:45.400527 15117 sgd_solver.cpp:294] Iteration 44620, lr = 0.002
I0526 09:11:51.691659 15117 solver.cpp:233] Iteration 44630, loss = 0.0199184
I0526 09:11:51.691704 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0199186 (* 1 = 0.0199186 loss)
I0526 09:11:51.691711 15117 sgd_solver.cpp:294] Iteration 44630, lr = 0.002
I0526 09:11:57.980196 15117 solver.cpp:233] Iteration 44640, loss = 0.00887775
I0526 09:11:57.980238 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00887797 (* 1 = 0.00887797 loss)
I0526 09:11:57.980245 15117 sgd_solver.cpp:294] Iteration 44640, lr = 0.002
I0526 09:12:04.268462 15117 solver.cpp:233] Iteration 44650, loss = 0.0104972
I0526 09:12:04.268687 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0104974 (* 1 = 0.0104974 loss)
I0526 09:12:04.268712 15117 sgd_solver.cpp:294] Iteration 44650, lr = 0.002
I0526 09:12:10.558398 15117 solver.cpp:233] Iteration 44660, loss = 0.00647351
I0526 09:12:10.558444 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00647373 (* 1 = 0.00647373 loss)
I0526 09:12:10.558451 15117 sgd_solver.cpp:294] Iteration 44660, lr = 0.002
I0526 09:12:16.844784 15117 solver.cpp:233] Iteration 44670, loss = 0.0265236
I0526 09:12:16.844825 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0265238 (* 1 = 0.0265238 loss)
I0526 09:12:16.844832 15117 sgd_solver.cpp:294] Iteration 44670, lr = 0.002
I0526 09:12:23.131379 15117 solver.cpp:233] Iteration 44680, loss = 0.00991195
I0526 09:12:23.131409 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00991217 (* 1 = 0.00991217 loss)
I0526 09:12:23.131415 15117 sgd_solver.cpp:294] Iteration 44680, lr = 0.002
I0526 09:12:29.419987 15117 solver.cpp:233] Iteration 44690, loss = 0.00678167
I0526 09:12:29.420027 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00678188 (* 1 = 0.00678188 loss)
I0526 09:12:29.420034 15117 sgd_solver.cpp:294] Iteration 44690, lr = 0.002
I0526 09:12:35.116349 15117 solver.cpp:342] Iteration 44700, Testing net (#0)
I0526 09:12:47.898088 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.901
I0526 09:12:47.898134 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.446005 (* 1 = 0.446005 loss)
I0526 09:12:48.494910 15117 solver.cpp:233] Iteration 44700, loss = 0.0140545
I0526 09:12:48.494935 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0140547 (* 1 = 0.0140547 loss)
I0526 09:12:48.494941 15117 sgd_solver.cpp:294] Iteration 44700, lr = 0.002
I0526 09:12:54.786926 15117 solver.cpp:233] Iteration 44710, loss = 0.036924
I0526 09:12:54.786967 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0369242 (* 1 = 0.0369242 loss)
I0526 09:12:54.786973 15117 sgd_solver.cpp:294] Iteration 44710, lr = 0.002
I0526 09:13:01.077144 15117 solver.cpp:233] Iteration 44720, loss = 0.0149952
I0526 09:13:01.077186 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0149954 (* 1 = 0.0149954 loss)
I0526 09:13:01.077193 15117 sgd_solver.cpp:294] Iteration 44720, lr = 0.002
I0526 09:13:07.367010 15117 solver.cpp:233] Iteration 44730, loss = 0.0136224
I0526 09:13:07.367233 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0136226 (* 1 = 0.0136226 loss)
I0526 09:13:07.367262 15117 sgd_solver.cpp:294] Iteration 44730, lr = 0.002
I0526 09:13:13.653353 15117 solver.cpp:233] Iteration 44740, loss = 0.0116132
I0526 09:13:13.653398 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0116135 (* 1 = 0.0116135 loss)
I0526 09:13:13.653406 15117 sgd_solver.cpp:294] Iteration 44740, lr = 0.002
I0526 09:13:19.942236 15117 solver.cpp:233] Iteration 44750, loss = 0.00701248
I0526 09:13:19.942279 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00701269 (* 1 = 0.00701269 loss)
I0526 09:13:19.942287 15117 sgd_solver.cpp:294] Iteration 44750, lr = 0.002
I0526 09:13:26.229784 15117 solver.cpp:233] Iteration 44760, loss = 0.00806872
I0526 09:13:26.229815 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00806894 (* 1 = 0.00806894 loss)
I0526 09:13:26.229823 15117 sgd_solver.cpp:294] Iteration 44760, lr = 0.002
I0526 09:13:32.517990 15117 solver.cpp:233] Iteration 44770, loss = 0.0208148
I0526 09:13:32.518030 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.020815 (* 1 = 0.020815 loss)
I0526 09:13:32.518038 15117 sgd_solver.cpp:294] Iteration 44770, lr = 0.002
I0526 09:13:38.808037 15117 solver.cpp:233] Iteration 44780, loss = 0.0117847
I0526 09:13:38.808284 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0117849 (* 1 = 0.0117849 loss)
I0526 09:13:38.808311 15117 sgd_solver.cpp:294] Iteration 44780, lr = 0.002
I0526 09:13:45.096573 15117 solver.cpp:233] Iteration 44790, loss = 0.0178571
I0526 09:13:45.096614 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0178574 (* 1 = 0.0178574 loss)
I0526 09:13:45.096621 15117 sgd_solver.cpp:294] Iteration 44790, lr = 0.002
I0526 09:13:50.786528 15117 solver.cpp:342] Iteration 44800, Testing net (#0)
I0526 09:14:03.564416 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9043
I0526 09:14:03.564462 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.444863 (* 1 = 0.444863 loss)
I0526 09:14:04.162030 15117 solver.cpp:233] Iteration 44800, loss = 0.00548958
I0526 09:14:04.162067 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0054898 (* 1 = 0.0054898 loss)
I0526 09:14:04.162075 15117 sgd_solver.cpp:294] Iteration 44800, lr = 0.002
I0526 09:14:10.448434 15117 solver.cpp:233] Iteration 44810, loss = 0.0260866
I0526 09:14:10.448650 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0260868 (* 1 = 0.0260868 loss)
I0526 09:14:10.448679 15117 sgd_solver.cpp:294] Iteration 44810, lr = 0.002
I0526 09:14:16.740226 15117 solver.cpp:233] Iteration 44820, loss = 0.00313863
I0526 09:14:16.740265 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00313885 (* 1 = 0.00313885 loss)
I0526 09:14:16.740272 15117 sgd_solver.cpp:294] Iteration 44820, lr = 0.002
I0526 09:14:23.029116 15117 solver.cpp:233] Iteration 44830, loss = 0.00855323
I0526 09:14:23.029162 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00855345 (* 1 = 0.00855345 loss)
I0526 09:14:23.029170 15117 sgd_solver.cpp:294] Iteration 44830, lr = 0.002
I0526 09:14:29.314898 15117 solver.cpp:233] Iteration 44840, loss = 0.0220737
I0526 09:14:29.314940 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.022074 (* 1 = 0.022074 loss)
I0526 09:14:29.314949 15117 sgd_solver.cpp:294] Iteration 44840, lr = 0.002
I0526 09:14:35.603879 15117 solver.cpp:233] Iteration 44850, loss = 0.00560623
I0526 09:14:35.603925 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00560646 (* 1 = 0.00560646 loss)
I0526 09:14:35.603932 15117 sgd_solver.cpp:294] Iteration 44850, lr = 0.002
I0526 09:14:41.892308 15117 solver.cpp:233] Iteration 44860, loss = 0.0105901
I0526 09:14:41.892418 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0105903 (* 1 = 0.0105903 loss)
I0526 09:14:41.892427 15117 sgd_solver.cpp:294] Iteration 44860, lr = 0.002
I0526 09:14:48.184435 15117 solver.cpp:233] Iteration 44870, loss = 0.0344327
I0526 09:14:48.184483 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0344329 (* 1 = 0.0344329 loss)
I0526 09:14:48.184489 15117 sgd_solver.cpp:294] Iteration 44870, lr = 0.002
I0526 09:14:54.472880 15117 solver.cpp:233] Iteration 44880, loss = 0.00583567
I0526 09:14:54.472923 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00583589 (* 1 = 0.00583589 loss)
I0526 09:14:54.472929 15117 sgd_solver.cpp:294] Iteration 44880, lr = 0.002
I0526 09:15:00.763635 15117 solver.cpp:233] Iteration 44890, loss = 0.0447841
I0526 09:15:00.763676 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0447843 (* 1 = 0.0447843 loss)
I0526 09:15:00.763684 15117 sgd_solver.cpp:294] Iteration 44890, lr = 0.002
I0526 09:15:06.455885 15117 solver.cpp:342] Iteration 44900, Testing net (#0)
I0526 09:15:19.245474 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9042
I0526 09:15:19.245733 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.443715 (* 1 = 0.443715 loss)
I0526 09:15:19.843103 15117 solver.cpp:233] Iteration 44900, loss = 0.00761843
I0526 09:15:19.843143 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00761865 (* 1 = 0.00761865 loss)
I0526 09:15:19.843152 15117 sgd_solver.cpp:294] Iteration 44900, lr = 0.002
I0526 09:15:26.129771 15117 solver.cpp:233] Iteration 44910, loss = 0.0103535
I0526 09:15:26.129814 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0103537 (* 1 = 0.0103537 loss)
I0526 09:15:26.129822 15117 sgd_solver.cpp:294] Iteration 44910, lr = 0.002
I0526 09:15:32.416654 15117 solver.cpp:233] Iteration 44920, loss = 0.020753
I0526 09:15:32.416697 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0207532 (* 1 = 0.0207532 loss)
I0526 09:15:32.416705 15117 sgd_solver.cpp:294] Iteration 44920, lr = 0.002
I0526 09:15:38.706552 15117 solver.cpp:233] Iteration 44930, loss = 0.0216705
I0526 09:15:38.706600 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0216708 (* 1 = 0.0216708 loss)
I0526 09:15:38.706607 15117 sgd_solver.cpp:294] Iteration 44930, lr = 0.002
I0526 09:15:44.992285 15117 solver.cpp:233] Iteration 44940, loss = 0.0112782
I0526 09:15:44.992312 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0112784 (* 1 = 0.0112784 loss)
I0526 09:15:44.992319 15117 sgd_solver.cpp:294] Iteration 44940, lr = 0.002
I0526 09:15:51.281060 15117 solver.cpp:233] Iteration 44950, loss = 0.0214189
I0526 09:15:51.281287 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0214191 (* 1 = 0.0214191 loss)
I0526 09:15:51.281317 15117 sgd_solver.cpp:294] Iteration 44950, lr = 0.002
I0526 09:15:57.574527 15117 solver.cpp:233] Iteration 44960, loss = 0.0188395
I0526 09:15:57.574568 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0188397 (* 1 = 0.0188397 loss)
I0526 09:15:57.574576 15117 sgd_solver.cpp:294] Iteration 44960, lr = 0.002
I0526 09:16:03.865736 15117 solver.cpp:233] Iteration 44970, loss = 0.00643504
I0526 09:16:03.865779 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00643526 (* 1 = 0.00643526 loss)
I0526 09:16:03.865787 15117 sgd_solver.cpp:294] Iteration 44970, lr = 0.002
I0526 09:16:10.154700 15117 solver.cpp:233] Iteration 44980, loss = 0.0117981
I0526 09:16:10.154741 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0117983 (* 1 = 0.0117983 loss)
I0526 09:16:10.154747 15117 sgd_solver.cpp:294] Iteration 44980, lr = 0.002
I0526 09:16:16.443209 15117 solver.cpp:233] Iteration 44990, loss = 0.0146545
I0526 09:16:16.443235 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0146548 (* 1 = 0.0146548 loss)
I0526 09:16:16.443243 15117 sgd_solver.cpp:294] Iteration 44990, lr = 0.002
I0526 09:16:22.135141 15117 solver.cpp:342] Iteration 45000, Testing net (#0)
I0526 09:16:34.925168 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9003
I0526 09:16:34.925216 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.462931 (* 1 = 0.462931 loss)
I0526 09:16:35.522613 15117 solver.cpp:233] Iteration 45000, loss = 0.0115747
I0526 09:16:35.522653 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0115749 (* 1 = 0.0115749 loss)
I0526 09:16:35.522666 15117 sgd_solver.cpp:294] Iteration 45000, lr = 0.002
I0526 09:16:41.811497 15117 solver.cpp:233] Iteration 45010, loss = 0.0156163
I0526 09:16:41.811538 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0156165 (* 1 = 0.0156165 loss)
I0526 09:16:41.811545 15117 sgd_solver.cpp:294] Iteration 45010, lr = 0.002
I0526 09:16:48.102241 15117 solver.cpp:233] Iteration 45020, loss = 0.0124251
I0526 09:16:48.102286 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0124253 (* 1 = 0.0124253 loss)
I0526 09:16:48.102293 15117 sgd_solver.cpp:294] Iteration 45020, lr = 0.002
I0526 09:16:54.393319 15117 solver.cpp:233] Iteration 45030, loss = 0.0113847
I0526 09:16:54.393576 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0113849 (* 1 = 0.0113849 loss)
I0526 09:16:54.393604 15117 sgd_solver.cpp:294] Iteration 45030, lr = 0.002
I0526 09:17:00.684648 15117 solver.cpp:233] Iteration 45040, loss = 0.022594
I0526 09:17:00.684689 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0225942 (* 1 = 0.0225942 loss)
I0526 09:17:00.684696 15117 sgd_solver.cpp:294] Iteration 45040, lr = 0.002
I0526 09:17:06.968863 15117 solver.cpp:233] Iteration 45050, loss = 0.0199896
I0526 09:17:06.968907 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0199898 (* 1 = 0.0199898 loss)
I0526 09:17:06.968914 15117 sgd_solver.cpp:294] Iteration 45050, lr = 0.002
I0526 09:17:13.255237 15117 solver.cpp:233] Iteration 45060, loss = 0.0112172
I0526 09:17:13.255288 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0112174 (* 1 = 0.0112174 loss)
I0526 09:17:13.255296 15117 sgd_solver.cpp:294] Iteration 45060, lr = 0.002
I0526 09:17:19.542803 15117 solver.cpp:233] Iteration 45070, loss = 0.0102403
I0526 09:17:19.542845 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0102405 (* 1 = 0.0102405 loss)
I0526 09:17:19.542852 15117 sgd_solver.cpp:294] Iteration 45070, lr = 0.002
I0526 09:17:25.830869 15117 solver.cpp:233] Iteration 45080, loss = 0.00649498
I0526 09:17:25.830976 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0064952 (* 1 = 0.0064952 loss)
I0526 09:17:25.830984 15117 sgd_solver.cpp:294] Iteration 45080, lr = 0.002
I0526 09:17:32.124658 15117 solver.cpp:233] Iteration 45090, loss = 0.00897262
I0526 09:17:32.124711 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00897283 (* 1 = 0.00897283 loss)
I0526 09:17:32.124719 15117 sgd_solver.cpp:294] Iteration 45090, lr = 0.002
I0526 09:17:37.811827 15117 solver.cpp:342] Iteration 45100, Testing net (#0)
I0526 09:17:50.594153 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9054
I0526 09:17:50.594198 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.444577 (* 1 = 0.444577 loss)
I0526 09:17:51.191608 15117 solver.cpp:233] Iteration 45100, loss = 0.0136496
I0526 09:17:51.191642 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0136498 (* 1 = 0.0136498 loss)
I0526 09:17:51.191649 15117 sgd_solver.cpp:294] Iteration 45100, lr = 0.002
I0526 09:17:57.481768 15117 solver.cpp:233] Iteration 45110, loss = 0.0114474
I0526 09:17:57.481986 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0114476 (* 1 = 0.0114476 loss)
I0526 09:17:57.482015 15117 sgd_solver.cpp:294] Iteration 45110, lr = 0.002
I0526 09:18:03.773759 15117 solver.cpp:233] Iteration 45120, loss = 0.00813758
I0526 09:18:03.773792 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0081378 (* 1 = 0.0081378 loss)
I0526 09:18:03.773798 15117 sgd_solver.cpp:294] Iteration 45120, lr = 0.002
I0526 09:18:10.063779 15117 solver.cpp:233] Iteration 45130, loss = 0.0255376
I0526 09:18:10.063820 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0255378 (* 1 = 0.0255378 loss)
I0526 09:18:10.063827 15117 sgd_solver.cpp:294] Iteration 45130, lr = 0.002
I0526 09:18:16.352865 15117 solver.cpp:233] Iteration 45140, loss = 0.00227906
I0526 09:18:16.352906 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00227928 (* 1 = 0.00227928 loss)
I0526 09:18:16.352918 15117 sgd_solver.cpp:294] Iteration 45140, lr = 0.002
I0526 09:18:22.643781 15117 solver.cpp:233] Iteration 45150, loss = 0.00790038
I0526 09:18:22.643826 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00790059 (* 1 = 0.00790059 loss)
I0526 09:18:22.643832 15117 sgd_solver.cpp:294] Iteration 45150, lr = 0.002
I0526 09:18:28.932821 15117 solver.cpp:233] Iteration 45160, loss = 0.0202154
I0526 09:18:28.933056 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0202156 (* 1 = 0.0202156 loss)
I0526 09:18:28.933085 15117 sgd_solver.cpp:294] Iteration 45160, lr = 0.002
I0526 09:18:35.222084 15117 solver.cpp:233] Iteration 45170, loss = 0.0126661
I0526 09:18:35.222127 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0126664 (* 1 = 0.0126664 loss)
I0526 09:18:35.222136 15117 sgd_solver.cpp:294] Iteration 45170, lr = 0.002
I0526 09:18:41.509856 15117 solver.cpp:233] Iteration 45180, loss = 0.0138698
I0526 09:18:41.509898 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.01387 (* 1 = 0.01387 loss)
I0526 09:18:41.509907 15117 sgd_solver.cpp:294] Iteration 45180, lr = 0.002
I0526 09:18:47.792505 15117 solver.cpp:233] Iteration 45190, loss = 0.0136462
I0526 09:18:47.792546 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0136465 (* 1 = 0.0136465 loss)
I0526 09:18:47.792553 15117 sgd_solver.cpp:294] Iteration 45190, lr = 0.002
I0526 09:18:53.484236 15117 solver.cpp:342] Iteration 45200, Testing net (#0)
I0526 09:19:06.267098 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9051
I0526 09:19:06.267320 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.446003 (* 1 = 0.446003 loss)
I0526 09:19:06.866395 15117 solver.cpp:233] Iteration 45200, loss = 0.0128459
I0526 09:19:06.866430 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0128461 (* 1 = 0.0128461 loss)
I0526 09:19:06.866439 15117 sgd_solver.cpp:294] Iteration 45200, lr = 0.002
I0526 09:19:13.159173 15117 solver.cpp:233] Iteration 45210, loss = 0.00692793
I0526 09:19:13.159217 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00692815 (* 1 = 0.00692815 loss)
I0526 09:19:13.159224 15117 sgd_solver.cpp:294] Iteration 45210, lr = 0.002
I0526 09:19:19.447490 15117 solver.cpp:233] Iteration 45220, loss = 0.00648448
I0526 09:19:19.447531 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0064847 (* 1 = 0.0064847 loss)
I0526 09:19:19.447540 15117 sgd_solver.cpp:294] Iteration 45220, lr = 0.002
I0526 09:19:25.737298 15117 solver.cpp:233] Iteration 45230, loss = 0.00656834
I0526 09:19:25.737339 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00656856 (* 1 = 0.00656856 loss)
I0526 09:19:25.737346 15117 sgd_solver.cpp:294] Iteration 45230, lr = 0.002
I0526 09:19:32.025919 15117 solver.cpp:233] Iteration 45240, loss = 0.00181519
I0526 09:19:32.025964 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00181542 (* 1 = 0.00181542 loss)
I0526 09:19:32.025971 15117 sgd_solver.cpp:294] Iteration 45240, lr = 0.002
I0526 09:19:38.311918 15117 solver.cpp:233] Iteration 45250, loss = 0.00551795
I0526 09:19:38.311995 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00551817 (* 1 = 0.00551817 loss)
I0526 09:19:38.312003 15117 sgd_solver.cpp:294] Iteration 45250, lr = 0.002
I0526 09:19:44.595902 15117 solver.cpp:233] Iteration 45260, loss = 0.0184423
I0526 09:19:44.595949 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0184425 (* 1 = 0.0184425 loss)
I0526 09:19:44.595957 15117 sgd_solver.cpp:294] Iteration 45260, lr = 0.002
I0526 09:19:50.883519 15117 solver.cpp:233] Iteration 45270, loss = 0.0176614
I0526 09:19:50.883560 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0176616 (* 1 = 0.0176616 loss)
I0526 09:19:50.883568 15117 sgd_solver.cpp:294] Iteration 45270, lr = 0.002
I0526 09:19:57.172562 15117 solver.cpp:233] Iteration 45280, loss = 0.00925138
I0526 09:19:57.172612 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0092516 (* 1 = 0.0092516 loss)
I0526 09:19:57.172621 15117 sgd_solver.cpp:294] Iteration 45280, lr = 0.002
I0526 09:20:03.459017 15117 solver.cpp:233] Iteration 45290, loss = 0.00716619
I0526 09:20:03.459060 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00716641 (* 1 = 0.00716641 loss)
I0526 09:20:03.459067 15117 sgd_solver.cpp:294] Iteration 45290, lr = 0.002
I0526 09:20:09.149619 15117 solver.cpp:342] Iteration 45300, Testing net (#0)
I0526 09:20:21.937254 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.905
I0526 09:20:21.937300 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.443824 (* 1 = 0.443824 loss)
I0526 09:20:22.534930 15117 solver.cpp:233] Iteration 45300, loss = 0.0211763
I0526 09:20:22.534972 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0211765 (* 1 = 0.0211765 loss)
I0526 09:20:22.534979 15117 sgd_solver.cpp:294] Iteration 45300, lr = 0.002
I0526 09:20:28.822916 15117 solver.cpp:233] Iteration 45310, loss = 0.0204933
I0526 09:20:28.822969 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0204935 (* 1 = 0.0204935 loss)
I0526 09:20:28.822976 15117 sgd_solver.cpp:294] Iteration 45310, lr = 0.002
I0526 09:20:35.112994 15117 solver.cpp:233] Iteration 45320, loss = 0.00459792
I0526 09:20:35.113035 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00459814 (* 1 = 0.00459814 loss)
I0526 09:20:35.113042 15117 sgd_solver.cpp:294] Iteration 45320, lr = 0.002
I0526 09:20:41.401608 15117 solver.cpp:233] Iteration 45330, loss = 0.0198739
I0526 09:20:41.401834 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0198741 (* 1 = 0.0198741 loss)
I0526 09:20:41.401862 15117 sgd_solver.cpp:294] Iteration 45330, lr = 0.002
I0526 09:20:47.690410 15117 solver.cpp:233] Iteration 45340, loss = 0.0160394
I0526 09:20:47.690454 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0160396 (* 1 = 0.0160396 loss)
I0526 09:20:47.690460 15117 sgd_solver.cpp:294] Iteration 45340, lr = 0.002
I0526 09:20:53.976374 15117 solver.cpp:233] Iteration 45350, loss = 0.0171424
I0526 09:20:53.976402 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0171426 (* 1 = 0.0171426 loss)
I0526 09:20:53.976409 15117 sgd_solver.cpp:294] Iteration 45350, lr = 0.002
I0526 09:21:00.262933 15117 solver.cpp:233] Iteration 45360, loss = 0.0264159
I0526 09:21:00.262976 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0264161 (* 1 = 0.0264161 loss)
I0526 09:21:00.262984 15117 sgd_solver.cpp:294] Iteration 45360, lr = 0.002
I0526 09:21:06.552093 15117 solver.cpp:233] Iteration 45370, loss = 0.0074117
I0526 09:21:06.552132 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00741192 (* 1 = 0.00741192 loss)
I0526 09:21:06.552139 15117 sgd_solver.cpp:294] Iteration 45370, lr = 0.002
I0526 09:21:12.839272 15117 solver.cpp:233] Iteration 45380, loss = 0.013621
I0526 09:21:12.839483 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0136212 (* 1 = 0.0136212 loss)
I0526 09:21:12.839509 15117 sgd_solver.cpp:294] Iteration 45380, lr = 0.002
I0526 09:21:19.128460 15117 solver.cpp:233] Iteration 45390, loss = 0.0195754
I0526 09:21:19.128500 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0195756 (* 1 = 0.0195756 loss)
I0526 09:21:19.128507 15117 sgd_solver.cpp:294] Iteration 45390, lr = 0.002
I0526 09:21:24.817244 15117 solver.cpp:342] Iteration 45400, Testing net (#0)
I0526 09:21:37.600013 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8998
I0526 09:21:37.600060 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.453369 (* 1 = 0.453369 loss)
I0526 09:21:38.197031 15117 solver.cpp:233] Iteration 45400, loss = 0.00987471
I0526 09:21:38.197070 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00987493 (* 1 = 0.00987493 loss)
I0526 09:21:38.197077 15117 sgd_solver.cpp:294] Iteration 45400, lr = 0.002
I0526 09:21:44.484160 15117 solver.cpp:233] Iteration 45410, loss = 0.0177373
I0526 09:21:44.484423 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0177375 (* 1 = 0.0177375 loss)
I0526 09:21:44.484453 15117 sgd_solver.cpp:294] Iteration 45410, lr = 0.002
I0526 09:21:50.770607 15117 solver.cpp:233] Iteration 45420, loss = 0.0087536
I0526 09:21:50.770651 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00875382 (* 1 = 0.00875382 loss)
I0526 09:21:50.770658 15117 sgd_solver.cpp:294] Iteration 45420, lr = 0.002
I0526 09:21:57.056973 15117 solver.cpp:233] Iteration 45430, loss = 0.00523153
I0526 09:21:57.057003 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00523175 (* 1 = 0.00523175 loss)
I0526 09:21:57.057010 15117 sgd_solver.cpp:294] Iteration 45430, lr = 0.002
I0526 09:22:03.348348 15117 solver.cpp:233] Iteration 45440, loss = 0.0142228
I0526 09:22:03.348389 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0142231 (* 1 = 0.0142231 loss)
I0526 09:22:03.348397 15117 sgd_solver.cpp:294] Iteration 45440, lr = 0.002
I0526 09:22:09.638182 15117 solver.cpp:233] Iteration 45450, loss = 0.0116154
I0526 09:22:09.638222 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0116157 (* 1 = 0.0116157 loss)
I0526 09:22:09.638229 15117 sgd_solver.cpp:294] Iteration 45450, lr = 0.002
I0526 09:22:15.926764 15117 solver.cpp:233] Iteration 45460, loss = 0.0105952
I0526 09:22:15.926987 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0105954 (* 1 = 0.0105954 loss)
I0526 09:22:15.927017 15117 sgd_solver.cpp:294] Iteration 45460, lr = 0.002
I0526 09:22:22.214838 15117 solver.cpp:233] Iteration 45470, loss = 0.0142415
I0526 09:22:22.214880 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0142417 (* 1 = 0.0142417 loss)
I0526 09:22:22.214887 15117 sgd_solver.cpp:294] Iteration 45470, lr = 0.002
I0526 09:22:28.505748 15117 solver.cpp:233] Iteration 45480, loss = 0.0256172
I0526 09:22:28.505790 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0256174 (* 1 = 0.0256174 loss)
I0526 09:22:28.505798 15117 sgd_solver.cpp:294] Iteration 45480, lr = 0.002
I0526 09:22:34.794543 15117 solver.cpp:233] Iteration 45490, loss = 0.0276799
I0526 09:22:34.794584 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0276801 (* 1 = 0.0276801 loss)
I0526 09:22:34.794591 15117 sgd_solver.cpp:294] Iteration 45490, lr = 0.002
I0526 09:22:40.486472 15117 solver.cpp:342] Iteration 45500, Testing net (#0)
I0526 09:22:53.269862 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9021
I0526 09:22:53.270076 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.441108 (* 1 = 0.441108 loss)
I0526 09:22:53.866175 15117 solver.cpp:233] Iteration 45500, loss = 0.00845042
I0526 09:22:53.866216 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00845064 (* 1 = 0.00845064 loss)
I0526 09:22:53.866224 15117 sgd_solver.cpp:294] Iteration 45500, lr = 0.002
I0526 09:23:00.150756 15117 solver.cpp:233] Iteration 45510, loss = 0.0289222
I0526 09:23:00.150800 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0289224 (* 1 = 0.0289224 loss)
I0526 09:23:00.150807 15117 sgd_solver.cpp:294] Iteration 45510, lr = 0.002
I0526 09:23:06.437283 15117 solver.cpp:233] Iteration 45520, loss = 0.0153757
I0526 09:23:06.437321 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.015376 (* 1 = 0.015376 loss)
I0526 09:23:06.437328 15117 sgd_solver.cpp:294] Iteration 45520, lr = 0.002
I0526 09:23:12.726099 15117 solver.cpp:233] Iteration 45530, loss = 0.0350794
I0526 09:23:12.726140 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0350796 (* 1 = 0.0350796 loss)
I0526 09:23:12.726147 15117 sgd_solver.cpp:294] Iteration 45530, lr = 0.002
I0526 09:23:19.019160 15117 solver.cpp:233] Iteration 45540, loss = 0.0139111
I0526 09:23:19.019199 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0139113 (* 1 = 0.0139113 loss)
I0526 09:23:19.019207 15117 sgd_solver.cpp:294] Iteration 45540, lr = 0.002
I0526 09:23:25.308101 15117 solver.cpp:233] Iteration 45550, loss = 0.0302757
I0526 09:23:25.308274 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.030276 (* 1 = 0.030276 loss)
I0526 09:23:25.308282 15117 sgd_solver.cpp:294] Iteration 45550, lr = 0.002
I0526 09:23:31.599696 15117 solver.cpp:233] Iteration 45560, loss = 0.0104103
I0526 09:23:31.599740 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0104105 (* 1 = 0.0104105 loss)
I0526 09:23:31.599746 15117 sgd_solver.cpp:294] Iteration 45560, lr = 0.002
I0526 09:23:37.890280 15117 solver.cpp:233] Iteration 45570, loss = 0.0165263
I0526 09:23:37.890321 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0165265 (* 1 = 0.0165265 loss)
I0526 09:23:37.890328 15117 sgd_solver.cpp:294] Iteration 45570, lr = 0.002
I0526 09:23:44.181448 15117 solver.cpp:233] Iteration 45580, loss = 0.00709237
I0526 09:23:44.181490 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0070926 (* 1 = 0.0070926 loss)
I0526 09:23:44.181498 15117 sgd_solver.cpp:294] Iteration 45580, lr = 0.002
I0526 09:23:50.471930 15117 solver.cpp:233] Iteration 45590, loss = 0.0142232
I0526 09:23:50.471972 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0142234 (* 1 = 0.0142234 loss)
I0526 09:23:50.471979 15117 sgd_solver.cpp:294] Iteration 45590, lr = 0.002
I0526 09:23:56.160661 15117 solver.cpp:342] Iteration 45600, Testing net (#0)
I0526 09:24:08.945492 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9012
I0526 09:24:08.945536 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.443777 (* 1 = 0.443777 loss)
I0526 09:24:09.542433 15117 solver.cpp:233] Iteration 45600, loss = 0.0200164
I0526 09:24:09.542459 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0200166 (* 1 = 0.0200166 loss)
I0526 09:24:09.542465 15117 sgd_solver.cpp:294] Iteration 45600, lr = 0.002
I0526 09:24:15.829823 15117 solver.cpp:233] Iteration 45610, loss = 0.0384562
I0526 09:24:15.829866 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0384564 (* 1 = 0.0384564 loss)
I0526 09:24:15.829874 15117 sgd_solver.cpp:294] Iteration 45610, lr = 0.002
I0526 09:24:22.121489 15117 solver.cpp:233] Iteration 45620, loss = 0.0281931
I0526 09:24:22.121531 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0281934 (* 1 = 0.0281934 loss)
I0526 09:24:22.121537 15117 sgd_solver.cpp:294] Iteration 45620, lr = 0.002
I0526 09:24:28.411751 15117 solver.cpp:233] Iteration 45630, loss = 0.00350519
I0526 09:24:28.411881 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00350541 (* 1 = 0.00350541 loss)
I0526 09:24:28.411890 15117 sgd_solver.cpp:294] Iteration 45630, lr = 0.002
I0526 09:24:34.704056 15117 solver.cpp:233] Iteration 45640, loss = 0.00674111
I0526 09:24:34.704097 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00674133 (* 1 = 0.00674133 loss)
I0526 09:24:34.704103 15117 sgd_solver.cpp:294] Iteration 45640, lr = 0.002
I0526 09:24:40.992444 15117 solver.cpp:233] Iteration 45650, loss = 0.0263165
I0526 09:24:40.992487 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0263167 (* 1 = 0.0263167 loss)
I0526 09:24:40.992494 15117 sgd_solver.cpp:294] Iteration 45650, lr = 0.002
I0526 09:24:47.286977 15117 solver.cpp:233] Iteration 45660, loss = 0.0122064
I0526 09:24:47.287020 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0122067 (* 1 = 0.0122067 loss)
I0526 09:24:47.287027 15117 sgd_solver.cpp:294] Iteration 45660, lr = 0.002
I0526 09:24:53.575237 15117 solver.cpp:233] Iteration 45670, loss = 0.0256799
I0526 09:24:53.575278 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0256802 (* 1 = 0.0256802 loss)
I0526 09:24:53.575284 15117 sgd_solver.cpp:294] Iteration 45670, lr = 0.002
I0526 09:24:59.861274 15117 solver.cpp:233] Iteration 45680, loss = 0.00926181
I0526 09:24:59.862241 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00926204 (* 1 = 0.00926204 loss)
I0526 09:24:59.862267 15117 sgd_solver.cpp:294] Iteration 45680, lr = 0.002
I0526 09:25:06.147120 15117 solver.cpp:233] Iteration 45690, loss = 0.00894356
I0526 09:25:06.147166 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00894379 (* 1 = 0.00894379 loss)
I0526 09:25:06.147173 15117 sgd_solver.cpp:294] Iteration 45690, lr = 0.002
I0526 09:25:11.838268 15117 solver.cpp:342] Iteration 45700, Testing net (#0)
I0526 09:25:24.617274 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9012
I0526 09:25:24.617316 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.451252 (* 1 = 0.451252 loss)
I0526 09:25:25.214789 15117 solver.cpp:233] Iteration 45700, loss = 0.029738
I0526 09:25:25.214828 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0297383 (* 1 = 0.0297383 loss)
I0526 09:25:25.214834 15117 sgd_solver.cpp:294] Iteration 45700, lr = 0.002
I0526 09:25:31.507300 15117 solver.cpp:233] Iteration 45710, loss = 0.00922709
I0526 09:25:31.507437 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00922732 (* 1 = 0.00922732 loss)
I0526 09:25:31.507447 15117 sgd_solver.cpp:294] Iteration 45710, lr = 0.002
I0526 09:25:37.796679 15117 solver.cpp:233] Iteration 45720, loss = 0.00941047
I0526 09:25:37.796720 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0094107 (* 1 = 0.0094107 loss)
I0526 09:25:37.796727 15117 sgd_solver.cpp:294] Iteration 45720, lr = 0.002
I0526 09:25:44.081818 15117 solver.cpp:233] Iteration 45730, loss = 0.00540291
I0526 09:25:44.081861 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00540314 (* 1 = 0.00540314 loss)
I0526 09:25:44.081867 15117 sgd_solver.cpp:294] Iteration 45730, lr = 0.002
I0526 09:25:50.374294 15117 solver.cpp:233] Iteration 45740, loss = 0.0150283
I0526 09:25:50.374336 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0150286 (* 1 = 0.0150286 loss)
I0526 09:25:50.374342 15117 sgd_solver.cpp:294] Iteration 45740, lr = 0.002
I0526 09:25:56.666296 15117 solver.cpp:233] Iteration 45750, loss = 0.0115872
I0526 09:25:56.666340 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0115875 (* 1 = 0.0115875 loss)
I0526 09:25:56.666348 15117 sgd_solver.cpp:294] Iteration 45750, lr = 0.002
I0526 09:26:02.952510 15117 solver.cpp:233] Iteration 45760, loss = 0.0184039
I0526 09:26:02.952646 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0184041 (* 1 = 0.0184041 loss)
I0526 09:26:02.952654 15117 sgd_solver.cpp:294] Iteration 45760, lr = 0.002
I0526 09:26:09.239703 15117 solver.cpp:233] Iteration 45770, loss = 0.0062814
I0526 09:26:09.239743 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00628163 (* 1 = 0.00628163 loss)
I0526 09:26:09.239751 15117 sgd_solver.cpp:294] Iteration 45770, lr = 0.002
I0526 09:26:15.529578 15117 solver.cpp:233] Iteration 45780, loss = 0.00537223
I0526 09:26:15.529623 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00537246 (* 1 = 0.00537246 loss)
I0526 09:26:15.529629 15117 sgd_solver.cpp:294] Iteration 45780, lr = 0.002
I0526 09:26:21.823400 15117 solver.cpp:233] Iteration 45790, loss = 0.00920119
I0526 09:26:21.823441 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00920142 (* 1 = 0.00920142 loss)
I0526 09:26:21.823448 15117 sgd_solver.cpp:294] Iteration 45790, lr = 0.002
I0526 09:26:27.516834 15117 solver.cpp:342] Iteration 45800, Testing net (#0)
I0526 09:26:40.300555 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9035
I0526 09:26:40.300770 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.44903 (* 1 = 0.44903 loss)
I0526 09:26:40.902281 15117 solver.cpp:233] Iteration 45800, loss = 0.0050007
I0526 09:26:40.902343 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00500093 (* 1 = 0.00500093 loss)
I0526 09:26:40.902361 15117 sgd_solver.cpp:294] Iteration 45800, lr = 0.002
I0526 09:26:47.195053 15117 solver.cpp:233] Iteration 45810, loss = 0.0141686
I0526 09:26:47.195097 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0141688 (* 1 = 0.0141688 loss)
I0526 09:26:47.195109 15117 sgd_solver.cpp:294] Iteration 45810, lr = 0.002
I0526 09:26:53.488127 15117 solver.cpp:233] Iteration 45820, loss = 0.0155511
I0526 09:26:53.488155 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0155514 (* 1 = 0.0155514 loss)
I0526 09:26:53.488162 15117 sgd_solver.cpp:294] Iteration 45820, lr = 0.002
I0526 09:26:59.777859 15117 solver.cpp:233] Iteration 45830, loss = 0.0130472
I0526 09:26:59.777904 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0130474 (* 1 = 0.0130474 loss)
I0526 09:26:59.777910 15117 sgd_solver.cpp:294] Iteration 45830, lr = 0.002
I0526 09:27:06.068646 15117 solver.cpp:233] Iteration 45840, loss = 0.0151259
I0526 09:27:06.068687 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0151261 (* 1 = 0.0151261 loss)
I0526 09:27:06.068694 15117 sgd_solver.cpp:294] Iteration 45840, lr = 0.002
I0526 09:27:12.360164 15117 solver.cpp:233] Iteration 45850, loss = 0.0100717
I0526 09:27:12.360412 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.010072 (* 1 = 0.010072 loss)
I0526 09:27:12.360441 15117 sgd_solver.cpp:294] Iteration 45850, lr = 0.002
I0526 09:27:18.651908 15117 solver.cpp:233] Iteration 45860, loss = 0.00849385
I0526 09:27:18.651952 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00849408 (* 1 = 0.00849408 loss)
I0526 09:27:18.651959 15117 sgd_solver.cpp:294] Iteration 45860, lr = 0.002
I0526 09:27:24.940346 15117 solver.cpp:233] Iteration 45870, loss = 0.00810409
I0526 09:27:24.940387 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00810433 (* 1 = 0.00810433 loss)
I0526 09:27:24.940394 15117 sgd_solver.cpp:294] Iteration 45870, lr = 0.002
I0526 09:27:31.230440 15117 solver.cpp:233] Iteration 45880, loss = 0.00979568
I0526 09:27:31.230484 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00979592 (* 1 = 0.00979592 loss)
I0526 09:27:31.230490 15117 sgd_solver.cpp:294] Iteration 45880, lr = 0.002
I0526 09:27:37.520660 15117 solver.cpp:233] Iteration 45890, loss = 0.00892124
I0526 09:27:37.520687 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00892147 (* 1 = 0.00892147 loss)
I0526 09:27:37.520694 15117 sgd_solver.cpp:294] Iteration 45890, lr = 0.002
I0526 09:27:43.211753 15117 solver.cpp:342] Iteration 45900, Testing net (#0)
I0526 09:27:55.999980 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9013
I0526 09:27:56.000025 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.436024 (* 1 = 0.436024 loss)
I0526 09:27:56.596501 15117 solver.cpp:233] Iteration 45900, loss = 0.0313367
I0526 09:27:56.596542 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.031337 (* 1 = 0.031337 loss)
I0526 09:27:56.596549 15117 sgd_solver.cpp:294] Iteration 45900, lr = 0.002
I0526 09:28:02.883462 15117 solver.cpp:233] Iteration 45910, loss = 0.0377271
I0526 09:28:02.883489 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0377274 (* 1 = 0.0377274 loss)
I0526 09:28:02.883496 15117 sgd_solver.cpp:294] Iteration 45910, lr = 0.002
I0526 09:28:09.175843 15117 solver.cpp:233] Iteration 45920, loss = 0.00867209
I0526 09:28:09.175885 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00867233 (* 1 = 0.00867233 loss)
I0526 09:28:09.175891 15117 sgd_solver.cpp:294] Iteration 45920, lr = 0.002
I0526 09:28:15.465980 15117 solver.cpp:233] Iteration 45930, loss = 0.0136558
I0526 09:28:15.466217 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0136561 (* 1 = 0.0136561 loss)
I0526 09:28:15.466246 15117 sgd_solver.cpp:294] Iteration 45930, lr = 0.002
I0526 09:28:21.757138 15117 solver.cpp:233] Iteration 45940, loss = 0.00322826
I0526 09:28:21.757180 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0032285 (* 1 = 0.0032285 loss)
I0526 09:28:21.757189 15117 sgd_solver.cpp:294] Iteration 45940, lr = 0.002
I0526 09:28:28.048436 15117 solver.cpp:233] Iteration 45950, loss = 0.0160703
I0526 09:28:28.048481 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0160705 (* 1 = 0.0160705 loss)
I0526 09:28:28.048492 15117 sgd_solver.cpp:294] Iteration 45950, lr = 0.002
I0526 09:28:34.334646 15117 solver.cpp:233] Iteration 45960, loss = 0.00525603
I0526 09:28:34.334699 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00525626 (* 1 = 0.00525626 loss)
I0526 09:28:34.334707 15117 sgd_solver.cpp:294] Iteration 45960, lr = 0.002
I0526 09:28:40.627094 15117 solver.cpp:233] Iteration 45970, loss = 0.00811526
I0526 09:28:40.627121 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00811549 (* 1 = 0.00811549 loss)
I0526 09:28:40.627127 15117 sgd_solver.cpp:294] Iteration 45970, lr = 0.002
I0526 09:28:46.919105 15117 solver.cpp:233] Iteration 45980, loss = 0.00527216
I0526 09:28:46.919361 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0052724 (* 1 = 0.0052724 loss)
I0526 09:28:46.919391 15117 sgd_solver.cpp:294] Iteration 45980, lr = 0.002
I0526 09:28:53.211087 15117 solver.cpp:233] Iteration 45990, loss = 0.00799987
I0526 09:28:53.211128 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0080001 (* 1 = 0.0080001 loss)
I0526 09:28:53.211135 15117 sgd_solver.cpp:294] Iteration 45990, lr = 0.002
I0526 09:28:58.904165 15117 solver.cpp:342] Iteration 46000, Testing net (#0)
I0526 09:29:11.684428 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9043
I0526 09:29:11.684474 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.444477 (* 1 = 0.444477 loss)
I0526 09:29:12.281381 15117 solver.cpp:233] Iteration 46000, loss = 0.00883027
I0526 09:29:12.281422 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00883051 (* 1 = 0.00883051 loss)
I0526 09:29:12.281430 15117 sgd_solver.cpp:294] Iteration 46000, lr = 0.002
I0526 09:29:18.570101 15117 solver.cpp:233] Iteration 46010, loss = 0.0113391
I0526 09:29:18.570324 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0113394 (* 1 = 0.0113394 loss)
I0526 09:29:18.570379 15117 sgd_solver.cpp:294] Iteration 46010, lr = 0.002
I0526 09:29:24.859457 15117 solver.cpp:233] Iteration 46020, loss = 0.00796799
I0526 09:29:24.859496 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00796823 (* 1 = 0.00796823 loss)
I0526 09:29:24.859503 15117 sgd_solver.cpp:294] Iteration 46020, lr = 0.002
I0526 09:29:31.151952 15117 solver.cpp:233] Iteration 46030, loss = 0.0115115
I0526 09:29:31.152006 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0115117 (* 1 = 0.0115117 loss)
I0526 09:29:31.152014 15117 sgd_solver.cpp:294] Iteration 46030, lr = 0.002
I0526 09:29:37.441853 15117 solver.cpp:233] Iteration 46040, loss = 0.0114956
I0526 09:29:37.441893 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0114958 (* 1 = 0.0114958 loss)
I0526 09:29:37.441900 15117 sgd_solver.cpp:294] Iteration 46040, lr = 0.002
I0526 09:29:43.731850 15117 solver.cpp:233] Iteration 46050, loss = 0.0108849
I0526 09:29:43.731897 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0108851 (* 1 = 0.0108851 loss)
I0526 09:29:43.731904 15117 sgd_solver.cpp:294] Iteration 46050, lr = 0.002
I0526 09:29:50.024011 15117 solver.cpp:233] Iteration 46060, loss = 0.00859362
I0526 09:29:50.024224 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00859386 (* 1 = 0.00859386 loss)
I0526 09:29:50.024255 15117 sgd_solver.cpp:294] Iteration 46060, lr = 0.002
I0526 09:29:56.318256 15117 solver.cpp:233] Iteration 46070, loss = 0.0172062
I0526 09:29:56.318305 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0172065 (* 1 = 0.0172065 loss)
I0526 09:29:56.318313 15117 sgd_solver.cpp:294] Iteration 46070, lr = 0.002
I0526 09:30:02.607285 15117 solver.cpp:233] Iteration 46080, loss = 0.00885639
I0526 09:30:02.607326 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00885662 (* 1 = 0.00885662 loss)
I0526 09:30:02.607332 15117 sgd_solver.cpp:294] Iteration 46080, lr = 0.002
I0526 09:30:08.900722 15117 solver.cpp:233] Iteration 46090, loss = 0.0310902
I0526 09:30:08.900769 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0310904 (* 1 = 0.0310904 loss)
I0526 09:30:08.900777 15117 sgd_solver.cpp:294] Iteration 46090, lr = 0.002
I0526 09:30:14.592911 15117 solver.cpp:342] Iteration 46100, Testing net (#0)
I0526 09:30:27.373199 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9031
I0526 09:30:27.373481 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.441134 (* 1 = 0.441134 loss)
I0526 09:30:27.971106 15117 solver.cpp:233] Iteration 46100, loss = 0.0115731
I0526 09:30:27.971138 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0115733 (* 1 = 0.0115733 loss)
I0526 09:30:27.971146 15117 sgd_solver.cpp:294] Iteration 46100, lr = 0.002
I0526 09:30:34.261291 15117 solver.cpp:233] Iteration 46110, loss = 0.0224664
I0526 09:30:34.261332 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0224666 (* 1 = 0.0224666 loss)
I0526 09:30:34.261338 15117 sgd_solver.cpp:294] Iteration 46110, lr = 0.002
I0526 09:30:40.548336 15117 solver.cpp:233] Iteration 46120, loss = 0.0216351
I0526 09:30:40.548378 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0216354 (* 1 = 0.0216354 loss)
I0526 09:30:40.548385 15117 sgd_solver.cpp:294] Iteration 46120, lr = 0.002
I0526 09:30:46.835489 15117 solver.cpp:233] Iteration 46130, loss = 0.00608813
I0526 09:30:46.835535 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00608836 (* 1 = 0.00608836 loss)
I0526 09:30:46.835541 15117 sgd_solver.cpp:294] Iteration 46130, lr = 0.002
I0526 09:30:53.126581 15117 solver.cpp:233] Iteration 46140, loss = 0.00836457
I0526 09:30:53.126615 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00836481 (* 1 = 0.00836481 loss)
I0526 09:30:53.126621 15117 sgd_solver.cpp:294] Iteration 46140, lr = 0.002
I0526 09:30:59.417672 15117 solver.cpp:233] Iteration 46150, loss = 0.00881113
I0526 09:30:59.417906 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00881137 (* 1 = 0.00881137 loss)
I0526 09:30:59.417937 15117 sgd_solver.cpp:294] Iteration 46150, lr = 0.002
I0526 09:31:05.711448 15117 solver.cpp:233] Iteration 46160, loss = 0.010234
I0526 09:31:05.711494 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0102342 (* 1 = 0.0102342 loss)
I0526 09:31:05.711501 15117 sgd_solver.cpp:294] Iteration 46160, lr = 0.002
I0526 09:31:11.996937 15117 solver.cpp:233] Iteration 46170, loss = 0.00652618
I0526 09:31:11.996979 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00652642 (* 1 = 0.00652642 loss)
I0526 09:31:11.996986 15117 sgd_solver.cpp:294] Iteration 46170, lr = 0.002
I0526 09:31:18.288005 15117 solver.cpp:233] Iteration 46180, loss = 0.0191369
I0526 09:31:18.288048 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0191371 (* 1 = 0.0191371 loss)
I0526 09:31:18.288055 15117 sgd_solver.cpp:294] Iteration 46180, lr = 0.002
I0526 09:31:24.574100 15117 solver.cpp:233] Iteration 46190, loss = 0.0228643
I0526 09:31:24.574141 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0228645 (* 1 = 0.0228645 loss)
I0526 09:31:24.574147 15117 sgd_solver.cpp:294] Iteration 46190, lr = 0.002
I0526 09:31:30.264343 15117 solver.cpp:342] Iteration 46200, Testing net (#0)
I0526 09:31:43.046283 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8977
I0526 09:31:43.046327 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.471609 (* 1 = 0.471609 loss)
I0526 09:31:43.643142 15117 solver.cpp:233] Iteration 46200, loss = 0.0266778
I0526 09:31:43.643177 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.026678 (* 1 = 0.026678 loss)
I0526 09:31:43.643184 15117 sgd_solver.cpp:294] Iteration 46200, lr = 0.002
I0526 09:31:49.933622 15117 solver.cpp:233] Iteration 46210, loss = 0.00467527
I0526 09:31:49.933663 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0046755 (* 1 = 0.0046755 loss)
I0526 09:31:49.933670 15117 sgd_solver.cpp:294] Iteration 46210, lr = 0.002
I0526 09:31:56.222517 15117 solver.cpp:233] Iteration 46220, loss = 0.0144925
I0526 09:31:56.222549 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0144928 (* 1 = 0.0144928 loss)
I0526 09:31:56.222558 15117 sgd_solver.cpp:294] Iteration 46220, lr = 0.002
I0526 09:32:02.510756 15117 solver.cpp:233] Iteration 46230, loss = 0.0339683
I0526 09:32:02.510910 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0339685 (* 1 = 0.0339685 loss)
I0526 09:32:02.510920 15117 sgd_solver.cpp:294] Iteration 46230, lr = 0.002
I0526 09:32:08.799829 15117 solver.cpp:233] Iteration 46240, loss = 0.00305869
I0526 09:32:08.799870 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00305892 (* 1 = 0.00305892 loss)
I0526 09:32:08.799876 15117 sgd_solver.cpp:294] Iteration 46240, lr = 0.002
I0526 09:32:15.085511 15117 solver.cpp:233] Iteration 46250, loss = 0.0111667
I0526 09:32:15.085554 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0111669 (* 1 = 0.0111669 loss)
I0526 09:32:15.085561 15117 sgd_solver.cpp:294] Iteration 46250, lr = 0.002
I0526 09:32:21.378777 15117 solver.cpp:233] Iteration 46260, loss = 0.0106409
I0526 09:32:21.378820 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0106411 (* 1 = 0.0106411 loss)
I0526 09:32:21.378828 15117 sgd_solver.cpp:294] Iteration 46260, lr = 0.002
I0526 09:32:27.664024 15117 solver.cpp:233] Iteration 46270, loss = 0.00563518
I0526 09:32:27.664069 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00563541 (* 1 = 0.00563541 loss)
I0526 09:32:27.664077 15117 sgd_solver.cpp:294] Iteration 46270, lr = 0.002
I0526 09:32:33.947952 15117 solver.cpp:233] Iteration 46280, loss = 0.011413
I0526 09:32:33.948166 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0114132 (* 1 = 0.0114132 loss)
I0526 09:32:33.948195 15117 sgd_solver.cpp:294] Iteration 46280, lr = 0.002
I0526 09:32:40.238662 15117 solver.cpp:233] Iteration 46290, loss = 0.023934
I0526 09:32:40.238692 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0239342 (* 1 = 0.0239342 loss)
I0526 09:32:40.238698 15117 sgd_solver.cpp:294] Iteration 46290, lr = 0.002
I0526 09:32:45.930739 15117 solver.cpp:342] Iteration 46300, Testing net (#0)
I0526 09:32:58.710136 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9023
I0526 09:32:58.710182 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.449548 (* 1 = 0.449548 loss)
I0526 09:32:59.307471 15117 solver.cpp:233] Iteration 46300, loss = 0.00795002
I0526 09:32:59.307510 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00795025 (* 1 = 0.00795025 loss)
I0526 09:32:59.307518 15117 sgd_solver.cpp:294] Iteration 46300, lr = 0.002
I0526 09:33:05.599983 15117 solver.cpp:233] Iteration 46310, loss = 0.0179306
I0526 09:33:05.600159 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0179308 (* 1 = 0.0179308 loss)
I0526 09:33:05.600189 15117 sgd_solver.cpp:294] Iteration 46310, lr = 0.002
I0526 09:33:11.894094 15117 solver.cpp:233] Iteration 46320, loss = 0.00699012
I0526 09:33:11.894136 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00699035 (* 1 = 0.00699035 loss)
I0526 09:33:11.894145 15117 sgd_solver.cpp:294] Iteration 46320, lr = 0.002
I0526 09:33:18.185295 15117 solver.cpp:233] Iteration 46330, loss = 0.00288055
I0526 09:33:18.185335 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00288078 (* 1 = 0.00288078 loss)
I0526 09:33:18.185343 15117 sgd_solver.cpp:294] Iteration 46330, lr = 0.002
I0526 09:33:24.472020 15117 solver.cpp:233] Iteration 46340, loss = 0.00619037
I0526 09:33:24.472064 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0061906 (* 1 = 0.0061906 loss)
I0526 09:33:24.472070 15117 sgd_solver.cpp:294] Iteration 46340, lr = 0.002
I0526 09:33:30.758961 15117 solver.cpp:233] Iteration 46350, loss = 0.00888193
I0526 09:33:30.759003 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00888216 (* 1 = 0.00888216 loss)
I0526 09:33:30.759011 15117 sgd_solver.cpp:294] Iteration 46350, lr = 0.002
I0526 09:33:37.040855 15117 solver.cpp:233] Iteration 46360, loss = 0.00946887
I0526 09:33:37.041120 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0094691 (* 1 = 0.0094691 loss)
I0526 09:33:37.041149 15117 sgd_solver.cpp:294] Iteration 46360, lr = 0.002
I0526 09:33:43.330801 15117 solver.cpp:233] Iteration 46370, loss = 0.0406433
I0526 09:33:43.330842 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0406435 (* 1 = 0.0406435 loss)
I0526 09:33:43.330847 15117 sgd_solver.cpp:294] Iteration 46370, lr = 0.002
I0526 09:33:49.621968 15117 solver.cpp:233] Iteration 46380, loss = 0.0196101
I0526 09:33:49.622016 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0196103 (* 1 = 0.0196103 loss)
I0526 09:33:49.622023 15117 sgd_solver.cpp:294] Iteration 46380, lr = 0.002
I0526 09:33:55.906859 15117 solver.cpp:233] Iteration 46390, loss = 0.0101121
I0526 09:33:55.906900 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0101123 (* 1 = 0.0101123 loss)
I0526 09:33:55.906906 15117 sgd_solver.cpp:294] Iteration 46390, lr = 0.002
I0526 09:34:01.602275 15117 solver.cpp:342] Iteration 46400, Testing net (#0)
I0526 09:34:14.387989 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9018
I0526 09:34:14.388234 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.45337 (* 1 = 0.45337 loss)
I0526 09:34:14.986675 15117 solver.cpp:233] Iteration 46400, loss = 0.00841551
I0526 09:34:14.986726 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00841574 (* 1 = 0.00841574 loss)
I0526 09:34:14.986733 15117 sgd_solver.cpp:294] Iteration 46400, lr = 0.002
I0526 09:34:21.278173 15117 solver.cpp:233] Iteration 46410, loss = 0.0333372
I0526 09:34:21.278218 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0333375 (* 1 = 0.0333375 loss)
I0526 09:34:21.278224 15117 sgd_solver.cpp:294] Iteration 46410, lr = 0.002
I0526 09:34:27.566773 15117 solver.cpp:233] Iteration 46420, loss = 0.0249075
I0526 09:34:27.566813 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0249077 (* 1 = 0.0249077 loss)
I0526 09:34:27.566820 15117 sgd_solver.cpp:294] Iteration 46420, lr = 0.002
I0526 09:34:33.856286 15117 solver.cpp:233] Iteration 46430, loss = 0.00764355
I0526 09:34:33.856326 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00764378 (* 1 = 0.00764378 loss)
I0526 09:34:33.856333 15117 sgd_solver.cpp:294] Iteration 46430, lr = 0.002
I0526 09:34:40.141718 15117 solver.cpp:233] Iteration 46440, loss = 0.00570079
I0526 09:34:40.141762 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00570102 (* 1 = 0.00570102 loss)
I0526 09:34:40.141769 15117 sgd_solver.cpp:294] Iteration 46440, lr = 0.002
I0526 09:34:46.432879 15117 solver.cpp:233] Iteration 46450, loss = 0.0161723
I0526 09:34:46.432977 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0161725 (* 1 = 0.0161725 loss)
I0526 09:34:46.432986 15117 sgd_solver.cpp:294] Iteration 46450, lr = 0.002
I0526 09:34:52.723079 15117 solver.cpp:233] Iteration 46460, loss = 0.0125339
I0526 09:34:52.723126 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0125341 (* 1 = 0.0125341 loss)
I0526 09:34:52.723134 15117 sgd_solver.cpp:294] Iteration 46460, lr = 0.002
I0526 09:34:59.012274 15117 solver.cpp:233] Iteration 46470, loss = 0.00480882
I0526 09:34:59.012317 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00480904 (* 1 = 0.00480904 loss)
I0526 09:34:59.012325 15117 sgd_solver.cpp:294] Iteration 46470, lr = 0.002
I0526 09:35:05.304740 15117 solver.cpp:233] Iteration 46480, loss = 0.0069731
I0526 09:35:05.304783 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00697332 (* 1 = 0.00697332 loss)
I0526 09:35:05.304790 15117 sgd_solver.cpp:294] Iteration 46480, lr = 0.002
I0526 09:35:11.594398 15117 solver.cpp:233] Iteration 46490, loss = 0.0132364
I0526 09:35:11.594431 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0132366 (* 1 = 0.0132366 loss)
I0526 09:35:11.594445 15117 sgd_solver.cpp:294] Iteration 46490, lr = 0.002
I0526 09:35:17.285380 15117 solver.cpp:342] Iteration 46500, Testing net (#0)
I0526 09:35:30.069973 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9019
I0526 09:35:30.070019 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.447822 (* 1 = 0.447822 loss)
I0526 09:35:30.667176 15117 solver.cpp:233] Iteration 46500, loss = 0.0053063
I0526 09:35:30.667212 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00530653 (* 1 = 0.00530653 loss)
I0526 09:35:30.667218 15117 sgd_solver.cpp:294] Iteration 46500, lr = 0.002
I0526 09:35:36.957236 15117 solver.cpp:233] Iteration 46510, loss = 0.024506
I0526 09:35:36.957278 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0245062 (* 1 = 0.0245062 loss)
I0526 09:35:36.957285 15117 sgd_solver.cpp:294] Iteration 46510, lr = 0.002
I0526 09:35:43.245796 15117 solver.cpp:233] Iteration 46520, loss = 0.013718
I0526 09:35:43.245837 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0137182 (* 1 = 0.0137182 loss)
I0526 09:35:43.245843 15117 sgd_solver.cpp:294] Iteration 46520, lr = 0.002
I0526 09:35:49.534121 15117 solver.cpp:233] Iteration 46530, loss = 0.0433226
I0526 09:35:49.534317 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0433229 (* 1 = 0.0433229 loss)
I0526 09:35:49.534345 15117 sgd_solver.cpp:294] Iteration 46530, lr = 0.002
I0526 09:35:55.823595 15117 solver.cpp:233] Iteration 46540, loss = 0.010043
I0526 09:35:55.823634 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0100433 (* 1 = 0.0100433 loss)
I0526 09:35:55.823642 15117 sgd_solver.cpp:294] Iteration 46540, lr = 0.002
I0526 09:36:02.116008 15117 solver.cpp:233] Iteration 46550, loss = 0.0064988
I0526 09:36:02.116051 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00649903 (* 1 = 0.00649903 loss)
I0526 09:36:02.116057 15117 sgd_solver.cpp:294] Iteration 46550, lr = 0.002
I0526 09:36:08.409324 15117 solver.cpp:233] Iteration 46560, loss = 0.0198327
I0526 09:36:08.409368 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0198329 (* 1 = 0.0198329 loss)
I0526 09:36:08.409373 15117 sgd_solver.cpp:294] Iteration 46560, lr = 0.002
I0526 09:36:14.695066 15117 solver.cpp:233] Iteration 46570, loss = 0.0220458
I0526 09:36:14.695108 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.022046 (* 1 = 0.022046 loss)
I0526 09:36:14.695116 15117 sgd_solver.cpp:294] Iteration 46570, lr = 0.002
I0526 09:36:20.985932 15117 solver.cpp:233] Iteration 46580, loss = 0.022535
I0526 09:36:20.986150 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0225352 (* 1 = 0.0225352 loss)
I0526 09:36:20.986181 15117 sgd_solver.cpp:294] Iteration 46580, lr = 0.002
I0526 09:36:27.275971 15117 solver.cpp:233] Iteration 46590, loss = 0.00589406
I0526 09:36:27.276015 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00589429 (* 1 = 0.00589429 loss)
I0526 09:36:27.276021 15117 sgd_solver.cpp:294] Iteration 46590, lr = 0.002
I0526 09:36:32.967830 15117 solver.cpp:342] Iteration 46600, Testing net (#0)
I0526 09:36:45.750116 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9005
I0526 09:36:45.750162 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.465544 (* 1 = 0.465544 loss)
I0526 09:36:46.347093 15117 solver.cpp:233] Iteration 46600, loss = 0.0100029
I0526 09:36:46.347136 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0100031 (* 1 = 0.0100031 loss)
I0526 09:36:46.347154 15117 sgd_solver.cpp:294] Iteration 46600, lr = 0.002
I0526 09:36:52.634727 15117 solver.cpp:233] Iteration 46610, loss = 0.00562386
I0526 09:36:52.634939 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0056241 (* 1 = 0.0056241 loss)
I0526 09:36:52.634968 15117 sgd_solver.cpp:294] Iteration 46610, lr = 0.002
I0526 09:36:58.922832 15117 solver.cpp:233] Iteration 46620, loss = 0.00898217
I0526 09:36:58.922871 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0089824 (* 1 = 0.0089824 loss)
I0526 09:36:58.922884 15117 sgd_solver.cpp:294] Iteration 46620, lr = 0.002
I0526 09:37:05.214480 15117 solver.cpp:233] Iteration 46630, loss = 0.00806432
I0526 09:37:05.214525 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00806455 (* 1 = 0.00806455 loss)
I0526 09:37:05.214532 15117 sgd_solver.cpp:294] Iteration 46630, lr = 0.002
I0526 09:37:11.500366 15117 solver.cpp:233] Iteration 46640, loss = 0.00525224
I0526 09:37:11.500409 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00525247 (* 1 = 0.00525247 loss)
I0526 09:37:11.500416 15117 sgd_solver.cpp:294] Iteration 46640, lr = 0.002
I0526 09:37:17.787195 15117 solver.cpp:233] Iteration 46650, loss = 0.0204652
I0526 09:37:17.787238 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0204654 (* 1 = 0.0204654 loss)
I0526 09:37:17.787245 15117 sgd_solver.cpp:294] Iteration 46650, lr = 0.002
I0526 09:37:24.076299 15117 solver.cpp:233] Iteration 46660, loss = 0.0276518
I0526 09:37:24.076474 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0276521 (* 1 = 0.0276521 loss)
I0526 09:37:24.076484 15117 sgd_solver.cpp:294] Iteration 46660, lr = 0.002
I0526 09:37:30.368872 15117 solver.cpp:233] Iteration 46670, loss = 0.00378431
I0526 09:37:30.368916 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00378454 (* 1 = 0.00378454 loss)
I0526 09:37:30.368921 15117 sgd_solver.cpp:294] Iteration 46670, lr = 0.002
I0526 09:37:36.653900 15117 solver.cpp:233] Iteration 46680, loss = 0.00278824
I0526 09:37:36.653942 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00278847 (* 1 = 0.00278847 loss)
I0526 09:37:36.653950 15117 sgd_solver.cpp:294] Iteration 46680, lr = 0.002
I0526 09:37:42.942970 15117 solver.cpp:233] Iteration 46690, loss = 0.00620541
I0526 09:37:42.943011 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00620564 (* 1 = 0.00620564 loss)
I0526 09:37:42.943018 15117 sgd_solver.cpp:294] Iteration 46690, lr = 0.002
I0526 09:37:48.634676 15117 solver.cpp:342] Iteration 46700, Testing net (#0)
I0526 09:38:01.421129 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9027
I0526 09:38:01.421350 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.447197 (* 1 = 0.447197 loss)
I0526 09:38:02.018949 15117 solver.cpp:233] Iteration 46700, loss = 0.0133956
I0526 09:38:02.018996 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0133958 (* 1 = 0.0133958 loss)
I0526 09:38:02.019004 15117 sgd_solver.cpp:294] Iteration 46700, lr = 0.002
I0526 09:38:08.311121 15117 solver.cpp:233] Iteration 46710, loss = 0.00617011
I0526 09:38:08.311164 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00617034 (* 1 = 0.00617034 loss)
I0526 09:38:08.311170 15117 sgd_solver.cpp:294] Iteration 46710, lr = 0.002
I0526 09:38:14.600081 15117 solver.cpp:233] Iteration 46720, loss = 0.0173903
I0526 09:38:14.600123 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0173905 (* 1 = 0.0173905 loss)
I0526 09:38:14.600131 15117 sgd_solver.cpp:294] Iteration 46720, lr = 0.002
I0526 09:38:20.886330 15117 solver.cpp:233] Iteration 46730, loss = 0.00960045
I0526 09:38:20.886379 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00960068 (* 1 = 0.00960068 loss)
I0526 09:38:20.886385 15117 sgd_solver.cpp:294] Iteration 46730, lr = 0.002
I0526 09:38:27.177335 15117 solver.cpp:233] Iteration 46740, loss = 0.0193141
I0526 09:38:27.177376 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0193143 (* 1 = 0.0193143 loss)
I0526 09:38:27.177383 15117 sgd_solver.cpp:294] Iteration 46740, lr = 0.002
I0526 09:38:33.467641 15117 solver.cpp:233] Iteration 46750, loss = 0.00630358
I0526 09:38:33.467849 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0063038 (* 1 = 0.0063038 loss)
I0526 09:38:33.467880 15117 sgd_solver.cpp:294] Iteration 46750, lr = 0.002
I0526 09:38:39.757482 15117 solver.cpp:233] Iteration 46760, loss = 0.0560992
I0526 09:38:39.757531 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0560995 (* 1 = 0.0560995 loss)
I0526 09:38:39.757539 15117 sgd_solver.cpp:294] Iteration 46760, lr = 0.002
I0526 09:38:46.048640 15117 solver.cpp:233] Iteration 46770, loss = 0.016094
I0526 09:38:46.048683 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0160942 (* 1 = 0.0160942 loss)
I0526 09:38:46.048691 15117 sgd_solver.cpp:294] Iteration 46770, lr = 0.002
I0526 09:38:52.337327 15117 solver.cpp:233] Iteration 46780, loss = 0.016264
I0526 09:38:52.337385 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0162642 (* 1 = 0.0162642 loss)
I0526 09:38:52.337393 15117 sgd_solver.cpp:294] Iteration 46780, lr = 0.002
I0526 09:38:58.627210 15117 solver.cpp:233] Iteration 46790, loss = 0.0122805
I0526 09:38:58.627254 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0122807 (* 1 = 0.0122807 loss)
I0526 09:38:58.627261 15117 sgd_solver.cpp:294] Iteration 46790, lr = 0.002
I0526 09:39:04.320410 15117 solver.cpp:342] Iteration 46800, Testing net (#0)
I0526 09:39:17.112231 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.904
I0526 09:39:17.112275 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.446947 (* 1 = 0.446947 loss)
I0526 09:39:17.708552 15117 solver.cpp:233] Iteration 46800, loss = 0.00836161
I0526 09:39:17.708590 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00836184 (* 1 = 0.00836184 loss)
I0526 09:39:17.708596 15117 sgd_solver.cpp:294] Iteration 46800, lr = 0.002
I0526 09:39:23.999860 15117 solver.cpp:233] Iteration 46810, loss = 0.00475897
I0526 09:39:23.999902 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00475919 (* 1 = 0.00475919 loss)
I0526 09:39:23.999908 15117 sgd_solver.cpp:294] Iteration 46810, lr = 0.002
I0526 09:39:30.288993 15117 solver.cpp:233] Iteration 46820, loss = 0.014583
I0526 09:39:30.289034 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0145833 (* 1 = 0.0145833 loss)
I0526 09:39:30.289041 15117 sgd_solver.cpp:294] Iteration 46820, lr = 0.002
I0526 09:39:36.578989 15117 solver.cpp:233] Iteration 46830, loss = 0.00926877
I0526 09:39:36.579185 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.009269 (* 1 = 0.009269 loss)
I0526 09:39:36.579216 15117 sgd_solver.cpp:294] Iteration 46830, lr = 0.002
I0526 09:39:42.867568 15117 solver.cpp:233] Iteration 46840, loss = 0.0141536
I0526 09:39:42.867617 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0141538 (* 1 = 0.0141538 loss)
I0526 09:39:42.867624 15117 sgd_solver.cpp:294] Iteration 46840, lr = 0.002
I0526 09:39:49.155566 15117 solver.cpp:233] Iteration 46850, loss = 0.0291361
I0526 09:39:49.155612 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0291363 (* 1 = 0.0291363 loss)
I0526 09:39:49.155621 15117 sgd_solver.cpp:294] Iteration 46850, lr = 0.002
I0526 09:39:55.444795 15117 solver.cpp:233] Iteration 46860, loss = 0.00935215
I0526 09:39:55.444840 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00935237 (* 1 = 0.00935237 loss)
I0526 09:39:55.444847 15117 sgd_solver.cpp:294] Iteration 46860, lr = 0.002
I0526 09:40:01.732626 15117 solver.cpp:233] Iteration 46870, loss = 0.0156206
I0526 09:40:01.732669 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0156208 (* 1 = 0.0156208 loss)
I0526 09:40:01.732676 15117 sgd_solver.cpp:294] Iteration 46870, lr = 0.002
I0526 09:40:08.020865 15117 solver.cpp:233] Iteration 46880, loss = 0.00821408
I0526 09:40:08.021000 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0082143 (* 1 = 0.0082143 loss)
I0526 09:40:08.021008 15117 sgd_solver.cpp:294] Iteration 46880, lr = 0.002
I0526 09:40:14.309660 15117 solver.cpp:233] Iteration 46890, loss = 0.0233168
I0526 09:40:14.309701 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.023317 (* 1 = 0.023317 loss)
I0526 09:40:14.309708 15117 sgd_solver.cpp:294] Iteration 46890, lr = 0.002
I0526 09:40:19.999788 15117 solver.cpp:342] Iteration 46900, Testing net (#0)
I0526 09:40:32.786715 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.903
I0526 09:40:32.786759 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.451028 (* 1 = 0.451028 loss)
I0526 09:40:33.384171 15117 solver.cpp:233] Iteration 46900, loss = 0.00762163
I0526 09:40:33.384204 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00762186 (* 1 = 0.00762186 loss)
I0526 09:40:33.384212 15117 sgd_solver.cpp:294] Iteration 46900, lr = 0.002
I0526 09:40:39.672672 15117 solver.cpp:233] Iteration 46910, loss = 0.0170149
I0526 09:40:39.672929 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0170152 (* 1 = 0.0170152 loss)
I0526 09:40:39.672957 15117 sgd_solver.cpp:294] Iteration 46910, lr = 0.002
I0526 09:40:45.965993 15117 solver.cpp:233] Iteration 46920, loss = 0.0225274
I0526 09:40:45.966034 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0225276 (* 1 = 0.0225276 loss)
I0526 09:40:45.966042 15117 sgd_solver.cpp:294] Iteration 46920, lr = 0.002
I0526 09:40:52.254942 15117 solver.cpp:233] Iteration 46930, loss = 0.0146937
I0526 09:40:52.254986 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0146939 (* 1 = 0.0146939 loss)
I0526 09:40:52.254992 15117 sgd_solver.cpp:294] Iteration 46930, lr = 0.002
I0526 09:40:58.544342 15117 solver.cpp:233] Iteration 46940, loss = 0.0134608
I0526 09:40:58.544383 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.013461 (* 1 = 0.013461 loss)
I0526 09:40:58.544389 15117 sgd_solver.cpp:294] Iteration 46940, lr = 0.002
I0526 09:41:04.831876 15117 solver.cpp:233] Iteration 46950, loss = 0.00709421
I0526 09:41:04.831917 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00709443 (* 1 = 0.00709443 loss)
I0526 09:41:04.831923 15117 sgd_solver.cpp:294] Iteration 46950, lr = 0.002
I0526 09:41:11.119261 15117 solver.cpp:233] Iteration 46960, loss = 0.0197444
I0526 09:41:11.119452 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0197446 (* 1 = 0.0197446 loss)
I0526 09:41:11.119482 15117 sgd_solver.cpp:294] Iteration 46960, lr = 0.002
I0526 09:41:17.407907 15117 solver.cpp:233] Iteration 46970, loss = 0.0318365
I0526 09:41:17.407948 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0318367 (* 1 = 0.0318367 loss)
I0526 09:41:17.407956 15117 sgd_solver.cpp:294] Iteration 46970, lr = 0.002
I0526 09:41:23.694315 15117 solver.cpp:233] Iteration 46980, loss = 0.00887689
I0526 09:41:23.694347 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00887711 (* 1 = 0.00887711 loss)
I0526 09:41:23.694370 15117 sgd_solver.cpp:294] Iteration 46980, lr = 0.002
I0526 09:41:29.983413 15117 solver.cpp:233] Iteration 46990, loss = 0.0086512
I0526 09:41:29.983456 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00865142 (* 1 = 0.00865142 loss)
I0526 09:41:29.983464 15117 sgd_solver.cpp:294] Iteration 46990, lr = 0.002
I0526 09:41:35.676061 15117 solver.cpp:342] Iteration 47000, Testing net (#0)
I0526 09:41:48.465852 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.898
I0526 09:41:48.466058 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.466188 (* 1 = 0.466188 loss)
I0526 09:41:49.066424 15117 solver.cpp:233] Iteration 47000, loss = 0.00445861
I0526 09:41:49.066485 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00445884 (* 1 = 0.00445884 loss)
I0526 09:41:49.066496 15117 sgd_solver.cpp:294] Iteration 47000, lr = 0.002
I0526 09:41:55.354558 15117 solver.cpp:233] Iteration 47010, loss = 0.0235679
I0526 09:41:55.354604 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0235681 (* 1 = 0.0235681 loss)
I0526 09:41:55.354614 15117 sgd_solver.cpp:294] Iteration 47010, lr = 0.002
I0526 09:42:01.640672 15117 solver.cpp:233] Iteration 47020, loss = 0.0114153
I0526 09:42:01.640714 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0114155 (* 1 = 0.0114155 loss)
I0526 09:42:01.640722 15117 sgd_solver.cpp:294] Iteration 47020, lr = 0.002
I0526 09:42:07.925405 15117 solver.cpp:233] Iteration 47030, loss = 0.0254209
I0526 09:42:07.925448 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0254211 (* 1 = 0.0254211 loss)
I0526 09:42:07.925456 15117 sgd_solver.cpp:294] Iteration 47030, lr = 0.002
I0526 09:42:14.216207 15117 solver.cpp:233] Iteration 47040, loss = 0.00433809
I0526 09:42:14.216248 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00433832 (* 1 = 0.00433832 loss)
I0526 09:42:14.216254 15117 sgd_solver.cpp:294] Iteration 47040, lr = 0.002
I0526 09:42:20.507982 15117 solver.cpp:233] Iteration 47050, loss = 0.0113546
I0526 09:42:20.508234 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0113548 (* 1 = 0.0113548 loss)
I0526 09:42:20.508260 15117 sgd_solver.cpp:294] Iteration 47050, lr = 0.002
I0526 09:42:26.798887 15117 solver.cpp:233] Iteration 47060, loss = 0.0334461
I0526 09:42:26.798928 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0334464 (* 1 = 0.0334464 loss)
I0526 09:42:26.798935 15117 sgd_solver.cpp:294] Iteration 47060, lr = 0.002
I0526 09:42:33.083593 15117 solver.cpp:233] Iteration 47070, loss = 0.00498654
I0526 09:42:33.083634 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00498677 (* 1 = 0.00498677 loss)
I0526 09:42:33.083641 15117 sgd_solver.cpp:294] Iteration 47070, lr = 0.002
I0526 09:42:39.375213 15117 solver.cpp:233] Iteration 47080, loss = 0.00614858
I0526 09:42:39.375269 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0061488 (* 1 = 0.0061488 loss)
I0526 09:42:39.375277 15117 sgd_solver.cpp:294] Iteration 47080, lr = 0.002
I0526 09:42:45.661137 15117 solver.cpp:233] Iteration 47090, loss = 0.0161647
I0526 09:42:45.661178 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0161649 (* 1 = 0.0161649 loss)
I0526 09:42:45.661185 15117 sgd_solver.cpp:294] Iteration 47090, lr = 0.002
I0526 09:42:51.353133 15117 solver.cpp:342] Iteration 47100, Testing net (#0)
I0526 09:43:04.147025 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9027
I0526 09:43:04.147068 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.449748 (* 1 = 0.449748 loss)
I0526 09:43:04.744171 15117 solver.cpp:233] Iteration 47100, loss = 0.0101068
I0526 09:43:04.744215 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0101071 (* 1 = 0.0101071 loss)
I0526 09:43:04.744222 15117 sgd_solver.cpp:294] Iteration 47100, lr = 0.002
I0526 09:43:11.032160 15117 solver.cpp:233] Iteration 47110, loss = 0.0150694
I0526 09:43:11.032205 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0150697 (* 1 = 0.0150697 loss)
I0526 09:43:11.032212 15117 sgd_solver.cpp:294] Iteration 47110, lr = 0.002
I0526 09:43:17.323537 15117 solver.cpp:233] Iteration 47120, loss = 0.0128292
I0526 09:43:17.323577 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0128294 (* 1 = 0.0128294 loss)
I0526 09:43:17.323583 15117 sgd_solver.cpp:294] Iteration 47120, lr = 0.002
I0526 09:43:23.613091 15117 solver.cpp:233] Iteration 47130, loss = 0.00532723
I0526 09:43:23.613317 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00532745 (* 1 = 0.00532745 loss)
I0526 09:43:23.613346 15117 sgd_solver.cpp:294] Iteration 47130, lr = 0.002
I0526 09:43:29.903939 15117 solver.cpp:233] Iteration 47140, loss = 0.0238839
I0526 09:43:29.903980 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0238841 (* 1 = 0.0238841 loss)
I0526 09:43:29.903986 15117 sgd_solver.cpp:294] Iteration 47140, lr = 0.002
I0526 09:43:36.192421 15117 solver.cpp:233] Iteration 47150, loss = 0.00992015
I0526 09:43:36.192467 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00992037 (* 1 = 0.00992037 loss)
I0526 09:43:36.192474 15117 sgd_solver.cpp:294] Iteration 47150, lr = 0.002
I0526 09:43:42.480118 15117 solver.cpp:233] Iteration 47160, loss = 0.00776289
I0526 09:43:42.480164 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00776312 (* 1 = 0.00776312 loss)
I0526 09:43:42.480175 15117 sgd_solver.cpp:294] Iteration 47160, lr = 0.002
I0526 09:43:48.770644 15117 solver.cpp:233] Iteration 47170, loss = 0.00304829
I0526 09:43:48.770697 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00304851 (* 1 = 0.00304851 loss)
I0526 09:43:48.770704 15117 sgd_solver.cpp:294] Iteration 47170, lr = 0.002
I0526 09:43:55.060783 15117 solver.cpp:233] Iteration 47180, loss = 0.00836493
I0526 09:43:55.061038 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00836515 (* 1 = 0.00836515 loss)
I0526 09:43:55.061067 15117 sgd_solver.cpp:294] Iteration 47180, lr = 0.002
I0526 09:44:01.355425 15117 solver.cpp:233] Iteration 47190, loss = 0.0192521
I0526 09:44:01.355459 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0192523 (* 1 = 0.0192523 loss)
I0526 09:44:01.355465 15117 sgd_solver.cpp:294] Iteration 47190, lr = 0.002
I0526 09:44:07.048741 15117 solver.cpp:342] Iteration 47200, Testing net (#0)
I0526 09:44:19.832600 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8987
I0526 09:44:19.832645 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.466286 (* 1 = 0.466286 loss)
I0526 09:44:20.428658 15117 solver.cpp:233] Iteration 47200, loss = 0.0318901
I0526 09:44:20.428684 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0318903 (* 1 = 0.0318903 loss)
I0526 09:44:20.428691 15117 sgd_solver.cpp:294] Iteration 47200, lr = 0.002
I0526 09:44:26.720208 15117 solver.cpp:233] Iteration 47210, loss = 0.0138218
I0526 09:44:26.720422 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0138221 (* 1 = 0.0138221 loss)
I0526 09:44:26.720451 15117 sgd_solver.cpp:294] Iteration 47210, lr = 0.002
I0526 09:44:33.011947 15117 solver.cpp:233] Iteration 47220, loss = 0.0072438
I0526 09:44:33.011989 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00724402 (* 1 = 0.00724402 loss)
I0526 09:44:33.011996 15117 sgd_solver.cpp:294] Iteration 47220, lr = 0.002
I0526 09:44:39.302150 15117 solver.cpp:233] Iteration 47230, loss = 0.0145245
I0526 09:44:39.302194 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0145247 (* 1 = 0.0145247 loss)
I0526 09:44:39.302201 15117 sgd_solver.cpp:294] Iteration 47230, lr = 0.002
I0526 09:44:45.594534 15117 solver.cpp:233] Iteration 47240, loss = 0.00370169
I0526 09:44:45.594571 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00370191 (* 1 = 0.00370191 loss)
I0526 09:44:45.594578 15117 sgd_solver.cpp:294] Iteration 47240, lr = 0.002
I0526 09:44:51.883307 15117 solver.cpp:233] Iteration 47250, loss = 0.0130514
I0526 09:44:51.883350 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0130517 (* 1 = 0.0130517 loss)
I0526 09:44:51.883358 15117 sgd_solver.cpp:294] Iteration 47250, lr = 0.002
I0526 09:44:58.173876 15117 solver.cpp:233] Iteration 47260, loss = 0.0103432
I0526 09:44:58.174106 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0103434 (* 1 = 0.0103434 loss)
I0526 09:44:58.174135 15117 sgd_solver.cpp:294] Iteration 47260, lr = 0.002
I0526 09:45:04.467177 15117 solver.cpp:233] Iteration 47270, loss = 0.0156139
I0526 09:45:04.467218 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0156141 (* 1 = 0.0156141 loss)
I0526 09:45:04.467226 15117 sgd_solver.cpp:294] Iteration 47270, lr = 0.002
I0526 09:45:10.756346 15117 solver.cpp:233] Iteration 47280, loss = 0.0043701
I0526 09:45:10.756392 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00437032 (* 1 = 0.00437032 loss)
I0526 09:45:10.756399 15117 sgd_solver.cpp:294] Iteration 47280, lr = 0.002
I0526 09:45:17.043099 15117 solver.cpp:233] Iteration 47290, loss = 0.00408803
I0526 09:45:17.043141 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00408825 (* 1 = 0.00408825 loss)
I0526 09:45:17.043148 15117 sgd_solver.cpp:294] Iteration 47290, lr = 0.002
I0526 09:45:22.732480 15117 solver.cpp:342] Iteration 47300, Testing net (#0)
I0526 09:45:35.513886 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8998
I0526 09:45:35.514103 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.463161 (* 1 = 0.463161 loss)
I0526 09:45:36.111589 15117 solver.cpp:233] Iteration 47300, loss = 0.0090512
I0526 09:45:36.111630 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00905142 (* 1 = 0.00905142 loss)
I0526 09:45:36.111637 15117 sgd_solver.cpp:294] Iteration 47300, lr = 0.002
I0526 09:45:42.400817 15117 solver.cpp:233] Iteration 47310, loss = 0.00281928
I0526 09:45:42.400859 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00281951 (* 1 = 0.00281951 loss)
I0526 09:45:42.400866 15117 sgd_solver.cpp:294] Iteration 47310, lr = 0.002
I0526 09:45:48.688987 15117 solver.cpp:233] Iteration 47320, loss = 0.00476649
I0526 09:45:48.689029 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00476672 (* 1 = 0.00476672 loss)
I0526 09:45:48.689036 15117 sgd_solver.cpp:294] Iteration 47320, lr = 0.002
I0526 09:45:54.978055 15117 solver.cpp:233] Iteration 47330, loss = 0.004714
I0526 09:45:54.978098 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00471423 (* 1 = 0.00471423 loss)
I0526 09:45:54.978106 15117 sgd_solver.cpp:294] Iteration 47330, lr = 0.002
I0526 09:46:01.266948 15117 solver.cpp:233] Iteration 47340, loss = 0.0127842
I0526 09:46:01.266988 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0127844 (* 1 = 0.0127844 loss)
I0526 09:46:01.266995 15117 sgd_solver.cpp:294] Iteration 47340, lr = 0.002
I0526 09:46:07.558148 15117 solver.cpp:233] Iteration 47350, loss = 0.0135516
I0526 09:46:07.558418 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0135518 (* 1 = 0.0135518 loss)
I0526 09:46:07.558455 15117 sgd_solver.cpp:294] Iteration 47350, lr = 0.002
I0526 09:46:13.850795 15117 solver.cpp:233] Iteration 47360, loss = 0.00825089
I0526 09:46:13.850841 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00825112 (* 1 = 0.00825112 loss)
I0526 09:46:13.850848 15117 sgd_solver.cpp:294] Iteration 47360, lr = 0.002
I0526 09:46:20.134488 15117 solver.cpp:233] Iteration 47370, loss = 0.00826736
I0526 09:46:20.134531 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00826759 (* 1 = 0.00826759 loss)
I0526 09:46:20.134538 15117 sgd_solver.cpp:294] Iteration 47370, lr = 0.002
I0526 09:46:26.421607 15117 solver.cpp:233] Iteration 47380, loss = 0.0342195
I0526 09:46:26.421650 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0342197 (* 1 = 0.0342197 loss)
I0526 09:46:26.421658 15117 sgd_solver.cpp:294] Iteration 47380, lr = 0.002
I0526 09:46:32.710889 15117 solver.cpp:233] Iteration 47390, loss = 0.0200582
I0526 09:46:32.710932 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0200584 (* 1 = 0.0200584 loss)
I0526 09:46:32.710938 15117 sgd_solver.cpp:294] Iteration 47390, lr = 0.002
I0526 09:46:38.402806 15117 solver.cpp:342] Iteration 47400, Testing net (#0)
I0526 09:46:51.192915 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8997
I0526 09:46:51.192961 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.472363 (* 1 = 0.472363 loss)
I0526 09:46:51.789621 15117 solver.cpp:233] Iteration 47400, loss = 0.0122259
I0526 09:46:51.789655 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0122261 (* 1 = 0.0122261 loss)
I0526 09:46:51.789662 15117 sgd_solver.cpp:294] Iteration 47400, lr = 0.002
I0526 09:46:58.077775 15117 solver.cpp:233] Iteration 47410, loss = 0.00330695
I0526 09:46:58.077816 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00330718 (* 1 = 0.00330718 loss)
I0526 09:46:58.077824 15117 sgd_solver.cpp:294] Iteration 47410, lr = 0.002
I0526 09:47:04.367851 15117 solver.cpp:233] Iteration 47420, loss = 0.00517027
I0526 09:47:04.367882 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0051705 (* 1 = 0.0051705 loss)
I0526 09:47:04.367888 15117 sgd_solver.cpp:294] Iteration 47420, lr = 0.002
I0526 09:47:10.657779 15117 solver.cpp:233] Iteration 47430, loss = 0.0149397
I0526 09:47:10.658052 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0149399 (* 1 = 0.0149399 loss)
I0526 09:47:10.658082 15117 sgd_solver.cpp:294] Iteration 47430, lr = 0.002
I0526 09:47:16.949658 15117 solver.cpp:233] Iteration 47440, loss = 0.0304438
I0526 09:47:16.949708 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.030444 (* 1 = 0.030444 loss)
I0526 09:47:16.949717 15117 sgd_solver.cpp:294] Iteration 47440, lr = 0.002
I0526 09:47:23.229338 15117 solver.cpp:233] Iteration 47450, loss = 0.00543883
I0526 09:47:23.229382 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00543906 (* 1 = 0.00543906 loss)
I0526 09:47:23.229389 15117 sgd_solver.cpp:294] Iteration 47450, lr = 0.002
I0526 09:47:29.517269 15117 solver.cpp:233] Iteration 47460, loss = 0.00860775
I0526 09:47:29.517315 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00860798 (* 1 = 0.00860798 loss)
I0526 09:47:29.517323 15117 sgd_solver.cpp:294] Iteration 47460, lr = 0.002
I0526 09:47:35.807385 15117 solver.cpp:233] Iteration 47470, loss = 0.00516974
I0526 09:47:35.807426 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00516997 (* 1 = 0.00516997 loss)
I0526 09:47:35.807433 15117 sgd_solver.cpp:294] Iteration 47470, lr = 0.002
I0526 09:47:42.094293 15117 solver.cpp:233] Iteration 47480, loss = 0.0296849
I0526 09:47:42.094512 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0296851 (* 1 = 0.0296851 loss)
I0526 09:47:42.094540 15117 sgd_solver.cpp:294] Iteration 47480, lr = 0.002
I0526 09:47:48.384788 15117 solver.cpp:233] Iteration 47490, loss = 0.0293769
I0526 09:47:48.384830 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0293771 (* 1 = 0.0293771 loss)
I0526 09:47:48.384837 15117 sgd_solver.cpp:294] Iteration 47490, lr = 0.002
I0526 09:47:54.075883 15117 solver.cpp:342] Iteration 47500, Testing net (#0)
I0526 09:48:06.860368 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9041
I0526 09:48:06.860409 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.448065 (* 1 = 0.448065 loss)
I0526 09:48:07.456666 15117 solver.cpp:233] Iteration 47500, loss = 0.00891456
I0526 09:48:07.456707 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00891479 (* 1 = 0.00891479 loss)
I0526 09:48:07.456713 15117 sgd_solver.cpp:294] Iteration 47500, lr = 0.002
I0526 09:48:13.745965 15117 solver.cpp:233] Iteration 47510, loss = 0.00357693
I0526 09:48:13.746181 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00357716 (* 1 = 0.00357716 loss)
I0526 09:48:13.746207 15117 sgd_solver.cpp:294] Iteration 47510, lr = 0.002
I0526 09:48:20.032163 15117 solver.cpp:233] Iteration 47520, loss = 0.00541388
I0526 09:48:20.032210 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00541411 (* 1 = 0.00541411 loss)
I0526 09:48:20.032218 15117 sgd_solver.cpp:294] Iteration 47520, lr = 0.002
I0526 09:48:26.317299 15117 solver.cpp:233] Iteration 47530, loss = 0.0206914
I0526 09:48:26.317343 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0206916 (* 1 = 0.0206916 loss)
I0526 09:48:26.317351 15117 sgd_solver.cpp:294] Iteration 47530, lr = 0.002
I0526 09:48:32.604074 15117 solver.cpp:233] Iteration 47540, loss = 0.0022627
I0526 09:48:32.604120 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00226293 (* 1 = 0.00226293 loss)
I0526 09:48:32.604127 15117 sgd_solver.cpp:294] Iteration 47540, lr = 0.002
I0526 09:48:38.893270 15117 solver.cpp:233] Iteration 47550, loss = 0.0129656
I0526 09:48:38.893311 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0129659 (* 1 = 0.0129659 loss)
I0526 09:48:38.893317 15117 sgd_solver.cpp:294] Iteration 47550, lr = 0.002
I0526 09:48:45.181926 15117 solver.cpp:233] Iteration 47560, loss = 0.00606862
I0526 09:48:45.182149 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00606885 (* 1 = 0.00606885 loss)
I0526 09:48:45.182178 15117 sgd_solver.cpp:294] Iteration 47560, lr = 0.002
I0526 09:48:51.472023 15117 solver.cpp:233] Iteration 47570, loss = 0.0197364
I0526 09:48:51.472070 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0197366 (* 1 = 0.0197366 loss)
I0526 09:48:51.472079 15117 sgd_solver.cpp:294] Iteration 47570, lr = 0.002
I0526 09:48:57.758076 15117 solver.cpp:233] Iteration 47580, loss = 0.00605003
I0526 09:48:57.758118 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00605026 (* 1 = 0.00605026 loss)
I0526 09:48:57.758126 15117 sgd_solver.cpp:294] Iteration 47580, lr = 0.002
I0526 09:49:04.048853 15117 solver.cpp:233] Iteration 47590, loss = 0.0212541
I0526 09:49:04.048897 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0212543 (* 1 = 0.0212543 loss)
I0526 09:49:04.048904 15117 sgd_solver.cpp:294] Iteration 47590, lr = 0.002
I0526 09:49:09.740593 15117 solver.cpp:342] Iteration 47600, Testing net (#0)
I0526 09:49:22.523478 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9032
I0526 09:49:22.523650 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.452874 (* 1 = 0.452874 loss)
I0526 09:49:23.119904 15117 solver.cpp:233] Iteration 47600, loss = 0.0205357
I0526 09:49:23.119946 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0205359 (* 1 = 0.0205359 loss)
I0526 09:49:23.119953 15117 sgd_solver.cpp:294] Iteration 47600, lr = 0.002
I0526 09:49:29.405750 15117 solver.cpp:233] Iteration 47610, loss = 0.00868981
I0526 09:49:29.405791 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00869004 (* 1 = 0.00869004 loss)
I0526 09:49:29.405799 15117 sgd_solver.cpp:294] Iteration 47610, lr = 0.002
I0526 09:49:35.694489 15117 solver.cpp:233] Iteration 47620, loss = 0.00478807
I0526 09:49:35.694535 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00478831 (* 1 = 0.00478831 loss)
I0526 09:49:35.694541 15117 sgd_solver.cpp:294] Iteration 47620, lr = 0.002
I0526 09:49:41.979789 15117 solver.cpp:233] Iteration 47630, loss = 0.0170646
I0526 09:49:41.979830 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0170648 (* 1 = 0.0170648 loss)
I0526 09:49:41.979837 15117 sgd_solver.cpp:294] Iteration 47630, lr = 0.002
I0526 09:49:48.268162 15117 solver.cpp:233] Iteration 47640, loss = 0.00279299
I0526 09:49:48.268199 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00279322 (* 1 = 0.00279322 loss)
I0526 09:49:48.268206 15117 sgd_solver.cpp:294] Iteration 47640, lr = 0.002
I0526 09:49:54.559443 15117 solver.cpp:233] Iteration 47650, loss = 0.0100173
I0526 09:49:54.559684 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0100175 (* 1 = 0.0100175 loss)
I0526 09:49:54.559713 15117 sgd_solver.cpp:294] Iteration 47650, lr = 0.002
I0526 09:50:00.853077 15117 solver.cpp:233] Iteration 47660, loss = 0.0132839
I0526 09:50:00.853127 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0132841 (* 1 = 0.0132841 loss)
I0526 09:50:00.853135 15117 sgd_solver.cpp:294] Iteration 47660, lr = 0.002
I0526 09:50:07.142894 15117 solver.cpp:233] Iteration 47670, loss = 0.010691
I0526 09:50:07.142935 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0106912 (* 1 = 0.0106912 loss)
I0526 09:50:07.142941 15117 sgd_solver.cpp:294] Iteration 47670, lr = 0.002
I0526 09:50:13.432283 15117 solver.cpp:233] Iteration 47680, loss = 0.0064949
I0526 09:50:13.432314 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00649513 (* 1 = 0.00649513 loss)
I0526 09:50:13.432322 15117 sgd_solver.cpp:294] Iteration 47680, lr = 0.002
I0526 09:50:19.720638 15117 solver.cpp:233] Iteration 47690, loss = 0.00580359
I0526 09:50:19.720680 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00580383 (* 1 = 0.00580383 loss)
I0526 09:50:19.720687 15117 sgd_solver.cpp:294] Iteration 47690, lr = 0.002
I0526 09:50:25.413137 15117 solver.cpp:342] Iteration 47700, Testing net (#0)
I0526 09:50:38.184753 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9045
I0526 09:50:38.184800 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.439599 (* 1 = 0.439599 loss)
I0526 09:50:38.781231 15117 solver.cpp:233] Iteration 47700, loss = 0.0165996
I0526 09:50:38.781271 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0165998 (* 1 = 0.0165998 loss)
I0526 09:50:38.781280 15117 sgd_solver.cpp:294] Iteration 47700, lr = 0.002
I0526 09:50:45.068075 15117 solver.cpp:233] Iteration 47710, loss = 0.0302571
I0526 09:50:45.068116 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0302573 (* 1 = 0.0302573 loss)
I0526 09:50:45.068122 15117 sgd_solver.cpp:294] Iteration 47710, lr = 0.002
I0526 09:50:51.357461 15117 solver.cpp:233] Iteration 47720, loss = 0.0183151
I0526 09:50:51.357504 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0183153 (* 1 = 0.0183153 loss)
I0526 09:50:51.357511 15117 sgd_solver.cpp:294] Iteration 47720, lr = 0.002
I0526 09:50:57.647326 15117 solver.cpp:233] Iteration 47730, loss = 0.0065865
I0526 09:50:57.647482 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00658673 (* 1 = 0.00658673 loss)
I0526 09:50:57.647491 15117 sgd_solver.cpp:294] Iteration 47730, lr = 0.002
I0526 09:51:03.937638 15117 solver.cpp:233] Iteration 47740, loss = 0.00678939
I0526 09:51:03.937682 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00678962 (* 1 = 0.00678962 loss)
I0526 09:51:03.937690 15117 sgd_solver.cpp:294] Iteration 47740, lr = 0.002
I0526 09:51:10.225495 15117 solver.cpp:233] Iteration 47750, loss = 0.0110102
I0526 09:51:10.225536 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0110104 (* 1 = 0.0110104 loss)
I0526 09:51:10.225543 15117 sgd_solver.cpp:294] Iteration 47750, lr = 0.002
I0526 09:51:16.514097 15117 solver.cpp:233] Iteration 47760, loss = 0.0153455
I0526 09:51:16.514143 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0153457 (* 1 = 0.0153457 loss)
I0526 09:51:16.514152 15117 sgd_solver.cpp:294] Iteration 47760, lr = 0.002
I0526 09:51:22.799429 15117 solver.cpp:233] Iteration 47770, loss = 0.00509325
I0526 09:51:22.799470 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00509348 (* 1 = 0.00509348 loss)
I0526 09:51:22.799477 15117 sgd_solver.cpp:294] Iteration 47770, lr = 0.002
I0526 09:51:29.087553 15117 solver.cpp:233] Iteration 47780, loss = 0.0094378
I0526 09:51:29.087684 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00943803 (* 1 = 0.00943803 loss)
I0526 09:51:29.087693 15117 sgd_solver.cpp:294] Iteration 47780, lr = 0.002
I0526 09:51:35.371505 15117 solver.cpp:233] Iteration 47790, loss = 0.00769448
I0526 09:51:35.371549 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00769471 (* 1 = 0.00769471 loss)
I0526 09:51:35.371557 15117 sgd_solver.cpp:294] Iteration 47790, lr = 0.002
I0526 09:51:41.058550 15117 solver.cpp:342] Iteration 47800, Testing net (#0)
I0526 09:51:53.839857 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.8982
I0526 09:51:53.839902 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.477788 (* 1 = 0.477788 loss)
I0526 09:51:54.437208 15117 solver.cpp:233] Iteration 47800, loss = 0.0265222
I0526 09:51:54.437245 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0265224 (* 1 = 0.0265224 loss)
I0526 09:51:54.437252 15117 sgd_solver.cpp:294] Iteration 47800, lr = 0.002
I0526 09:52:00.726966 15117 solver.cpp:233] Iteration 47810, loss = 0.0117262
I0526 09:52:00.727205 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0117264 (* 1 = 0.0117264 loss)
I0526 09:52:00.727234 15117 sgd_solver.cpp:294] Iteration 47810, lr = 0.002
I0526 09:52:07.011982 15117 solver.cpp:233] Iteration 47820, loss = 0.0216892
I0526 09:52:07.012020 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0216894 (* 1 = 0.0216894 loss)
I0526 09:52:07.012028 15117 sgd_solver.cpp:294] Iteration 47820, lr = 0.002
I0526 09:52:13.300839 15117 solver.cpp:233] Iteration 47830, loss = 0.0209849
I0526 09:52:13.300880 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0209851 (* 1 = 0.0209851 loss)
I0526 09:52:13.300894 15117 sgd_solver.cpp:294] Iteration 47830, lr = 0.002
I0526 09:52:19.589362 15117 solver.cpp:233] Iteration 47840, loss = 0.0276849
I0526 09:52:19.589406 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0276851 (* 1 = 0.0276851 loss)
I0526 09:52:19.589413 15117 sgd_solver.cpp:294] Iteration 47840, lr = 0.002
I0526 09:52:25.873342 15117 solver.cpp:233] Iteration 47850, loss = 0.0117364
I0526 09:52:25.873383 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0117366 (* 1 = 0.0117366 loss)
I0526 09:52:25.873389 15117 sgd_solver.cpp:294] Iteration 47850, lr = 0.002
I0526 09:52:32.161687 15117 solver.cpp:233] Iteration 47860, loss = 0.0215007
I0526 09:52:32.161936 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.021501 (* 1 = 0.021501 loss)
I0526 09:52:32.161962 15117 sgd_solver.cpp:294] Iteration 47860, lr = 0.002
I0526 09:52:38.453012 15117 solver.cpp:233] Iteration 47870, loss = 0.00254752
I0526 09:52:38.453057 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00254774 (* 1 = 0.00254774 loss)
I0526 09:52:38.453063 15117 sgd_solver.cpp:294] Iteration 47870, lr = 0.002
I0526 09:52:44.740531 15117 solver.cpp:233] Iteration 47880, loss = 0.00987489
I0526 09:52:44.740573 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00987512 (* 1 = 0.00987512 loss)
I0526 09:52:44.740581 15117 sgd_solver.cpp:294] Iteration 47880, lr = 0.002
I0526 09:52:51.028625 15117 solver.cpp:233] Iteration 47890, loss = 0.00775299
I0526 09:52:51.028666 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00775321 (* 1 = 0.00775321 loss)
I0526 09:52:51.028673 15117 sgd_solver.cpp:294] Iteration 47890, lr = 0.002
I0526 09:52:56.719703 15117 solver.cpp:342] Iteration 47900, Testing net (#0)
I0526 09:53:09.494067 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9021
I0526 09:53:09.494256 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.45828 (* 1 = 0.45828 loss)
I0526 09:53:10.090602 15117 solver.cpp:233] Iteration 47900, loss = 0.00210414
I0526 09:53:10.090644 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00210437 (* 1 = 0.00210437 loss)
I0526 09:53:10.090651 15117 sgd_solver.cpp:294] Iteration 47900, lr = 0.002
I0526 09:53:16.382024 15117 solver.cpp:233] Iteration 47910, loss = 0.00396705
I0526 09:53:16.382051 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00396727 (* 1 = 0.00396727 loss)
I0526 09:53:16.382057 15117 sgd_solver.cpp:294] Iteration 47910, lr = 0.002
I0526 09:53:22.669751 15117 solver.cpp:233] Iteration 47920, loss = 0.00937945
I0526 09:53:22.669793 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00937967 (* 1 = 0.00937967 loss)
I0526 09:53:22.669800 15117 sgd_solver.cpp:294] Iteration 47920, lr = 0.002
I0526 09:53:28.957116 15117 solver.cpp:233] Iteration 47930, loss = 0.0268573
I0526 09:53:28.957159 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0268575 (* 1 = 0.0268575 loss)
I0526 09:53:28.957165 15117 sgd_solver.cpp:294] Iteration 47930, lr = 0.002
I0526 09:53:35.245889 15117 solver.cpp:233] Iteration 47940, loss = 0.00351205
I0526 09:53:35.245934 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00351227 (* 1 = 0.00351227 loss)
I0526 09:53:35.245941 15117 sgd_solver.cpp:294] Iteration 47940, lr = 0.002
I0526 09:53:41.534286 15117 solver.cpp:233] Iteration 47950, loss = 0.0118034
I0526 09:53:41.534473 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0118036 (* 1 = 0.0118036 loss)
I0526 09:53:41.534503 15117 sgd_solver.cpp:294] Iteration 47950, lr = 0.002
I0526 09:53:47.820514 15117 solver.cpp:233] Iteration 47960, loss = 0.00969424
I0526 09:53:47.820571 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00969446 (* 1 = 0.00969446 loss)
I0526 09:53:47.820580 15117 sgd_solver.cpp:294] Iteration 47960, lr = 0.002
I0526 09:53:54.110723 15117 solver.cpp:233] Iteration 47970, loss = 0.00505881
I0526 09:53:54.110762 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00505903 (* 1 = 0.00505903 loss)
I0526 09:53:54.110775 15117 sgd_solver.cpp:294] Iteration 47970, lr = 0.002
I0526 09:54:00.400866 15117 solver.cpp:233] Iteration 47980, loss = 0.0347455
I0526 09:54:00.400907 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0347457 (* 1 = 0.0347457 loss)
I0526 09:54:00.400913 15117 sgd_solver.cpp:294] Iteration 47980, lr = 0.002
I0526 09:54:06.690332 15117 solver.cpp:233] Iteration 47990, loss = 0.00581743
I0526 09:54:06.690379 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00581766 (* 1 = 0.00581766 loss)
I0526 09:54:06.690387 15117 sgd_solver.cpp:294] Iteration 47990, lr = 0.002
I0526 09:54:12.381953 15117 solver.cpp:342] Iteration 48000, Testing net (#0)
I0526 09:54:25.162758 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9032
I0526 09:54:25.162801 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.457379 (* 1 = 0.457379 loss)
I0526 09:54:25.759181 15117 solver.cpp:233] Iteration 48000, loss = 0.00453376
I0526 09:54:25.759222 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00453398 (* 1 = 0.00453398 loss)
I0526 09:54:25.759228 15117 sgd_solver.cpp:234] MultiStep Status: Iteration 48000, step = 2
I0526 09:54:25.759232 15117 sgd_solver.cpp:294] Iteration 48000, lr = 0.0002
I0526 09:54:32.048063 15117 solver.cpp:233] Iteration 48010, loss = 0.0123884
I0526 09:54:32.048108 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0123887 (* 1 = 0.0123887 loss)
I0526 09:54:32.048115 15117 sgd_solver.cpp:294] Iteration 48010, lr = 0.0002
I0526 09:54:38.335754 15117 solver.cpp:233] Iteration 48020, loss = 0.00645688
I0526 09:54:38.335795 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0064571 (* 1 = 0.0064571 loss)
I0526 09:54:38.335801 15117 sgd_solver.cpp:294] Iteration 48020, lr = 0.0002
I0526 09:54:44.617708 15117 solver.cpp:233] Iteration 48030, loss = 0.00935607
I0526 09:54:44.617907 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00935629 (* 1 = 0.00935629 loss)
I0526 09:54:44.617936 15117 sgd_solver.cpp:294] Iteration 48030, lr = 0.0002
I0526 09:54:50.903602 15117 solver.cpp:233] Iteration 48040, loss = 0.0119451
I0526 09:54:50.903648 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0119453 (* 1 = 0.0119453 loss)
I0526 09:54:50.903656 15117 sgd_solver.cpp:294] Iteration 48040, lr = 0.0002
I0526 09:54:57.190060 15117 solver.cpp:233] Iteration 48050, loss = 0.0116512
I0526 09:54:57.190099 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0116514 (* 1 = 0.0116514 loss)
I0526 09:54:57.190106 15117 sgd_solver.cpp:294] Iteration 48050, lr = 0.0002
I0526 09:55:03.478873 15117 solver.cpp:233] Iteration 48060, loss = 0.0130027
I0526 09:55:03.478910 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0130029 (* 1 = 0.0130029 loss)
I0526 09:55:03.478917 15117 sgd_solver.cpp:294] Iteration 48060, lr = 0.0002
I0526 09:55:09.767227 15117 solver.cpp:233] Iteration 48070, loss = 0.0120914
I0526 09:55:09.767267 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0120916 (* 1 = 0.0120916 loss)
I0526 09:55:09.767274 15117 sgd_solver.cpp:294] Iteration 48070, lr = 0.0002
I0526 09:55:16.054867 15117 solver.cpp:233] Iteration 48080, loss = 0.00420229
I0526 09:55:16.055104 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00420251 (* 1 = 0.00420251 loss)
I0526 09:55:16.055133 15117 sgd_solver.cpp:294] Iteration 48080, lr = 0.0002
I0526 09:55:22.347440 15117 solver.cpp:233] Iteration 48090, loss = 0.0844571
I0526 09:55:22.347481 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0844573 (* 1 = 0.0844573 loss)
I0526 09:55:22.347488 15117 sgd_solver.cpp:294] Iteration 48090, lr = 0.0002
I0526 09:55:28.041143 15117 solver.cpp:342] Iteration 48100, Testing net (#0)
I0526 09:55:40.824892 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.904
I0526 09:55:40.824936 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.453038 (* 1 = 0.453038 loss)
I0526 09:55:41.422054 15117 solver.cpp:233] Iteration 48100, loss = 0.00236281
I0526 09:55:41.422094 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00236304 (* 1 = 0.00236304 loss)
I0526 09:55:41.422101 15117 sgd_solver.cpp:294] Iteration 48100, lr = 0.0002
I0526 09:55:47.710412 15117 solver.cpp:233] Iteration 48110, loss = 0.00566298
I0526 09:55:47.710566 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00566321 (* 1 = 0.00566321 loss)
I0526 09:55:47.710575 15117 sgd_solver.cpp:294] Iteration 48110, lr = 0.0002
I0526 09:55:53.999373 15117 solver.cpp:233] Iteration 48120, loss = 0.00691847
I0526 09:55:53.999415 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00691869 (* 1 = 0.00691869 loss)
I0526 09:55:53.999423 15117 sgd_solver.cpp:294] Iteration 48120, lr = 0.0002
I0526 09:56:00.288162 15117 solver.cpp:233] Iteration 48130, loss = 0.0332742
I0526 09:56:00.288203 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0332744 (* 1 = 0.0332744 loss)
I0526 09:56:00.288210 15117 sgd_solver.cpp:294] Iteration 48130, lr = 0.0002
I0526 09:56:06.575778 15117 solver.cpp:233] Iteration 48140, loss = 0.00247634
I0526 09:56:06.575819 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00247657 (* 1 = 0.00247657 loss)
I0526 09:56:06.575825 15117 sgd_solver.cpp:294] Iteration 48140, lr = 0.0002
I0526 09:56:12.866557 15117 solver.cpp:233] Iteration 48150, loss = 0.00840824
I0526 09:56:12.866598 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00840847 (* 1 = 0.00840847 loss)
I0526 09:56:12.866606 15117 sgd_solver.cpp:294] Iteration 48150, lr = 0.0002
I0526 09:56:19.154402 15117 solver.cpp:233] Iteration 48160, loss = 0.0126762
I0526 09:56:19.154625 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0126765 (* 1 = 0.0126765 loss)
I0526 09:56:19.154655 15117 sgd_solver.cpp:294] Iteration 48160, lr = 0.0002
I0526 09:56:25.448951 15117 solver.cpp:233] Iteration 48170, loss = 0.0156702
I0526 09:56:25.448992 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0156704 (* 1 = 0.0156704 loss)
I0526 09:56:25.448999 15117 sgd_solver.cpp:294] Iteration 48170, lr = 0.0002
I0526 09:56:31.738502 15117 solver.cpp:233] Iteration 48180, loss = 0.00769441
I0526 09:56:31.738546 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00769464 (* 1 = 0.00769464 loss)
I0526 09:56:31.738554 15117 sgd_solver.cpp:294] Iteration 48180, lr = 0.0002
I0526 09:56:38.028615 15117 solver.cpp:233] Iteration 48190, loss = 0.00852007
I0526 09:56:38.028658 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0085203 (* 1 = 0.0085203 loss)
I0526 09:56:38.028666 15117 sgd_solver.cpp:294] Iteration 48190, lr = 0.0002
I0526 09:56:43.719483 15117 solver.cpp:342] Iteration 48200, Testing net (#0)
I0526 09:56:56.496314 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9039
I0526 09:56:56.496518 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.457855 (* 1 = 0.457855 loss)
I0526 09:56:57.093926 15117 solver.cpp:233] Iteration 48200, loss = 0.00633305
I0526 09:56:57.093967 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00633328 (* 1 = 0.00633328 loss)
I0526 09:56:57.093976 15117 sgd_solver.cpp:294] Iteration 48200, lr = 0.0002
I0526 09:57:03.388067 15117 solver.cpp:233] Iteration 48210, loss = 0.0133412
I0526 09:57:03.388109 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0133414 (* 1 = 0.0133414 loss)
I0526 09:57:03.388116 15117 sgd_solver.cpp:294] Iteration 48210, lr = 0.0002
I0526 09:57:09.675680 15117 solver.cpp:233] Iteration 48220, loss = 0.0119728
I0526 09:57:09.675721 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.011973 (* 1 = 0.011973 loss)
I0526 09:57:09.675727 15117 sgd_solver.cpp:294] Iteration 48220, lr = 0.0002
I0526 09:57:15.969784 15117 solver.cpp:233] Iteration 48230, loss = 0.00715189
I0526 09:57:15.969815 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00715212 (* 1 = 0.00715212 loss)
I0526 09:57:15.969827 15117 sgd_solver.cpp:294] Iteration 48230, lr = 0.0002
I0526 09:57:22.261023 15117 solver.cpp:233] Iteration 48240, loss = 0.00545704
I0526 09:57:22.261064 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00545727 (* 1 = 0.00545727 loss)
I0526 09:57:22.261070 15117 sgd_solver.cpp:294] Iteration 48240, lr = 0.0002
I0526 09:57:28.552276 15117 solver.cpp:233] Iteration 48250, loss = 0.00247475
I0526 09:57:28.552558 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00247498 (* 1 = 0.00247498 loss)
I0526 09:57:28.552587 15117 sgd_solver.cpp:294] Iteration 48250, lr = 0.0002
I0526 09:57:34.842154 15117 solver.cpp:233] Iteration 48260, loss = 0.0233212
I0526 09:57:34.842197 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0233215 (* 1 = 0.0233215 loss)
I0526 09:57:34.842205 15117 sgd_solver.cpp:294] Iteration 48260, lr = 0.0002
I0526 09:57:41.129981 15117 solver.cpp:233] Iteration 48270, loss = 0.00649162
I0526 09:57:41.130024 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00649186 (* 1 = 0.00649186 loss)
I0526 09:57:41.130031 15117 sgd_solver.cpp:294] Iteration 48270, lr = 0.0002
I0526 09:57:47.422621 15117 solver.cpp:233] Iteration 48280, loss = 0.00653553
I0526 09:57:47.422663 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00653576 (* 1 = 0.00653576 loss)
I0526 09:57:47.422670 15117 sgd_solver.cpp:294] Iteration 48280, lr = 0.0002
I0526 09:57:53.711905 15117 solver.cpp:233] Iteration 48290, loss = 0.00277713
I0526 09:57:53.711962 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00277737 (* 1 = 0.00277737 loss)
I0526 09:57:53.711971 15117 sgd_solver.cpp:294] Iteration 48290, lr = 0.0002
I0526 09:57:59.402420 15117 solver.cpp:342] Iteration 48300, Testing net (#0)
I0526 09:58:12.192420 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9068
I0526 09:58:12.192466 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.446873 (* 1 = 0.446873 loss)
I0526 09:58:12.789901 15117 solver.cpp:233] Iteration 48300, loss = 0.0058615
I0526 09:58:12.789948 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00586173 (* 1 = 0.00586173 loss)
I0526 09:58:12.789957 15117 sgd_solver.cpp:294] Iteration 48300, lr = 0.0002
I0526 09:58:19.082722 15117 solver.cpp:233] Iteration 48310, loss = 0.0177498
I0526 09:58:19.082764 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.01775 (* 1 = 0.01775 loss)
I0526 09:58:19.082772 15117 sgd_solver.cpp:294] Iteration 48310, lr = 0.0002
I0526 09:58:25.370472 15117 solver.cpp:233] Iteration 48320, loss = 0.0285644
I0526 09:58:25.370501 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0285647 (* 1 = 0.0285647 loss)
I0526 09:58:25.370507 15117 sgd_solver.cpp:294] Iteration 48320, lr = 0.0002
I0526 09:58:31.659792 15117 solver.cpp:233] Iteration 48330, loss = 0.00673209
I0526 09:58:31.659996 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00673232 (* 1 = 0.00673232 loss)
I0526 09:58:31.660020 15117 sgd_solver.cpp:294] Iteration 48330, lr = 0.0002
I0526 09:58:37.949358 15117 solver.cpp:233] Iteration 48340, loss = 0.00801835
I0526 09:58:37.949404 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00801858 (* 1 = 0.00801858 loss)
I0526 09:58:37.949410 15117 sgd_solver.cpp:294] Iteration 48340, lr = 0.0002
I0526 09:58:44.239117 15117 solver.cpp:233] Iteration 48350, loss = 0.00367584
I0526 09:58:44.239161 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00367608 (* 1 = 0.00367608 loss)
I0526 09:58:44.239167 15117 sgd_solver.cpp:294] Iteration 48350, lr = 0.0002
I0526 09:58:50.527918 15117 solver.cpp:233] Iteration 48360, loss = 0.00648185
I0526 09:58:50.527962 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00648208 (* 1 = 0.00648208 loss)
I0526 09:58:50.527969 15117 sgd_solver.cpp:294] Iteration 48360, lr = 0.0002
I0526 09:58:56.818503 15117 solver.cpp:233] Iteration 48370, loss = 0.00251719
I0526 09:58:56.818549 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00251742 (* 1 = 0.00251742 loss)
I0526 09:58:56.818563 15117 sgd_solver.cpp:294] Iteration 48370, lr = 0.0002
I0526 09:59:03.104063 15117 solver.cpp:233] Iteration 48380, loss = 0.0126946
I0526 09:59:03.104307 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0126948 (* 1 = 0.0126948 loss)
I0526 09:59:03.104333 15117 sgd_solver.cpp:294] Iteration 48380, lr = 0.0002
I0526 09:59:09.390854 15117 solver.cpp:233] Iteration 48390, loss = 0.0291787
I0526 09:59:09.390889 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0291789 (* 1 = 0.0291789 loss)
I0526 09:59:09.390897 15117 sgd_solver.cpp:294] Iteration 48390, lr = 0.0002
I0526 09:59:15.085454 15117 solver.cpp:342] Iteration 48400, Testing net (#0)
I0526 09:59:27.871814 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9058
I0526 09:59:27.871858 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.435001 (* 1 = 0.435001 loss)
I0526 09:59:28.468214 15117 solver.cpp:233] Iteration 48400, loss = 0.0109878
I0526 09:59:28.468253 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0109881 (* 1 = 0.0109881 loss)
I0526 09:59:28.468261 15117 sgd_solver.cpp:294] Iteration 48400, lr = 0.0002
I0526 09:59:34.760517 15117 solver.cpp:233] Iteration 48410, loss = 0.00416543
I0526 09:59:34.760743 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00416566 (* 1 = 0.00416566 loss)
I0526 09:59:34.760772 15117 sgd_solver.cpp:294] Iteration 48410, lr = 0.0002
I0526 09:59:41.050575 15117 solver.cpp:233] Iteration 48420, loss = 0.011459
I0526 09:59:41.050621 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0114592 (* 1 = 0.0114592 loss)
I0526 09:59:41.050628 15117 sgd_solver.cpp:294] Iteration 48420, lr = 0.0002
I0526 09:59:47.341758 15117 solver.cpp:233] Iteration 48430, loss = 0.00674322
I0526 09:59:47.341799 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00674345 (* 1 = 0.00674345 loss)
I0526 09:59:47.341805 15117 sgd_solver.cpp:294] Iteration 48430, lr = 0.0002
I0526 09:59:53.630411 15117 solver.cpp:233] Iteration 48440, loss = 0.0321912
I0526 09:59:53.630453 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0321914 (* 1 = 0.0321914 loss)
I0526 09:59:53.630460 15117 sgd_solver.cpp:294] Iteration 48440, lr = 0.0002
I0526 09:59:59.917007 15117 solver.cpp:233] Iteration 48450, loss = 0.00584166
I0526 09:59:59.917052 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00584189 (* 1 = 0.00584189 loss)
I0526 09:59:59.917059 15117 sgd_solver.cpp:294] Iteration 48450, lr = 0.0002
I0526 10:00:06.203786 15117 solver.cpp:233] Iteration 48460, loss = 0.00375589
I0526 10:00:06.203969 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00375613 (* 1 = 0.00375613 loss)
I0526 10:00:06.203997 15117 sgd_solver.cpp:294] Iteration 48460, lr = 0.0002
I0526 10:00:12.492393 15117 solver.cpp:233] Iteration 48470, loss = 0.00986999
I0526 10:00:12.492424 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00987022 (* 1 = 0.00987022 loss)
I0526 10:00:12.492431 15117 sgd_solver.cpp:294] Iteration 48470, lr = 0.0002
I0526 10:00:18.779755 15117 solver.cpp:233] Iteration 48480, loss = 0.0110027
I0526 10:00:18.779796 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0110029 (* 1 = 0.0110029 loss)
I0526 10:00:18.779803 15117 sgd_solver.cpp:294] Iteration 48480, lr = 0.0002
I0526 10:00:25.068977 15117 solver.cpp:233] Iteration 48490, loss = 0.0273048
I0526 10:00:25.069017 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.027305 (* 1 = 0.027305 loss)
I0526 10:00:25.069025 15117 sgd_solver.cpp:294] Iteration 48490, lr = 0.0002
I0526 10:00:30.761107 15117 solver.cpp:342] Iteration 48500, Testing net (#0)
I0526 10:00:43.546082 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.905
I0526 10:00:43.546339 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.443553 (* 1 = 0.443553 loss)
I0526 10:00:44.145014 15117 solver.cpp:233] Iteration 48500, loss = 0.0043618
I0526 10:00:44.145054 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00436204 (* 1 = 0.00436204 loss)
I0526 10:00:44.145061 15117 sgd_solver.cpp:294] Iteration 48500, lr = 0.0002
I0526 10:00:50.431588 15117 solver.cpp:233] Iteration 48510, loss = 0.0277697
I0526 10:00:50.431628 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0277699 (* 1 = 0.0277699 loss)
I0526 10:00:50.431635 15117 sgd_solver.cpp:294] Iteration 48510, lr = 0.0002
I0526 10:00:56.719202 15117 solver.cpp:233] Iteration 48520, loss = 0.00456395
I0526 10:00:56.719250 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00456419 (* 1 = 0.00456419 loss)
I0526 10:00:56.719257 15117 sgd_solver.cpp:294] Iteration 48520, lr = 0.0002
I0526 10:01:03.004292 15117 solver.cpp:233] Iteration 48530, loss = 0.0120278
I0526 10:01:03.004333 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0120281 (* 1 = 0.0120281 loss)
I0526 10:01:03.004338 15117 sgd_solver.cpp:294] Iteration 48530, lr = 0.0002
I0526 10:01:09.290016 15117 solver.cpp:233] Iteration 48540, loss = 0.00133468
I0526 10:01:09.290060 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00133492 (* 1 = 0.00133492 loss)
I0526 10:01:09.290068 15117 sgd_solver.cpp:294] Iteration 48540, lr = 0.0002
I0526 10:01:15.573614 15117 solver.cpp:233] Iteration 48550, loss = 0.0211559
I0526 10:01:15.573812 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0211561 (* 1 = 0.0211561 loss)
I0526 10:01:15.573840 15117 sgd_solver.cpp:294] Iteration 48550, lr = 0.0002
I0526 10:01:21.866575 15117 solver.cpp:233] Iteration 48560, loss = 0.0138579
I0526 10:01:21.866611 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0138581 (* 1 = 0.0138581 loss)
I0526 10:01:21.866619 15117 sgd_solver.cpp:294] Iteration 48560, lr = 0.0002
I0526 10:01:28.155665 15117 solver.cpp:233] Iteration 48570, loss = 0.00162263
I0526 10:01:28.155709 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00162287 (* 1 = 0.00162287 loss)
I0526 10:01:28.155715 15117 sgd_solver.cpp:294] Iteration 48570, lr = 0.0002
I0526 10:01:34.442719 15117 solver.cpp:233] Iteration 48580, loss = 0.00463281
I0526 10:01:34.442764 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00463305 (* 1 = 0.00463305 loss)
I0526 10:01:34.442770 15117 sgd_solver.cpp:294] Iteration 48580, lr = 0.0002
I0526 10:01:40.730475 15117 solver.cpp:233] Iteration 48590, loss = 0.00448388
I0526 10:01:40.730517 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00448412 (* 1 = 0.00448412 loss)
I0526 10:01:40.730525 15117 sgd_solver.cpp:294] Iteration 48590, lr = 0.0002
I0526 10:01:46.419867 15117 solver.cpp:342] Iteration 48600, Testing net (#0)
I0526 10:01:59.200737 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9039
I0526 10:01:59.200784 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.445574 (* 1 = 0.445574 loss)
I0526 10:01:59.797585 15117 solver.cpp:233] Iteration 48600, loss = 0.00348039
I0526 10:01:59.797616 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00348063 (* 1 = 0.00348063 loss)
I0526 10:01:59.797623 15117 sgd_solver.cpp:294] Iteration 48600, lr = 0.0002
I0526 10:02:06.089169 15117 solver.cpp:233] Iteration 48610, loss = 0.00610982
I0526 10:02:06.089213 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00611006 (* 1 = 0.00611006 loss)
I0526 10:02:06.089221 15117 sgd_solver.cpp:294] Iteration 48610, lr = 0.0002
I0526 10:02:12.376631 15117 solver.cpp:233] Iteration 48620, loss = 0.00548885
I0526 10:02:12.376672 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00548909 (* 1 = 0.00548909 loss)
I0526 10:02:12.376679 15117 sgd_solver.cpp:294] Iteration 48620, lr = 0.0002
I0526 10:02:18.663928 15117 solver.cpp:233] Iteration 48630, loss = 0.0123399
I0526 10:02:18.664167 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0123401 (* 1 = 0.0123401 loss)
I0526 10:02:18.664197 15117 sgd_solver.cpp:294] Iteration 48630, lr = 0.0002
I0526 10:02:24.953630 15117 solver.cpp:233] Iteration 48640, loss = 0.00560659
I0526 10:02:24.953675 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00560683 (* 1 = 0.00560683 loss)
I0526 10:02:24.953682 15117 sgd_solver.cpp:294] Iteration 48640, lr = 0.0002
I0526 10:02:31.241572 15117 solver.cpp:233] Iteration 48650, loss = 0.00608823
I0526 10:02:31.241617 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00608847 (* 1 = 0.00608847 loss)
I0526 10:02:31.241626 15117 sgd_solver.cpp:294] Iteration 48650, lr = 0.0002
I0526 10:02:37.528808 15117 solver.cpp:233] Iteration 48660, loss = 0.00532353
I0526 10:02:37.528853 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00532377 (* 1 = 0.00532377 loss)
I0526 10:02:37.528861 15117 sgd_solver.cpp:294] Iteration 48660, lr = 0.0002
I0526 10:02:43.818953 15117 solver.cpp:233] Iteration 48670, loss = 0.00345429
I0526 10:02:43.818994 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00345453 (* 1 = 0.00345453 loss)
I0526 10:02:43.819001 15117 sgd_solver.cpp:294] Iteration 48670, lr = 0.0002
I0526 10:02:50.106158 15117 solver.cpp:233] Iteration 48680, loss = 0.0172464
I0526 10:02:50.106395 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0172467 (* 1 = 0.0172467 loss)
I0526 10:02:50.106426 15117 sgd_solver.cpp:294] Iteration 48680, lr = 0.0002
I0526 10:02:56.396903 15117 solver.cpp:233] Iteration 48690, loss = 0.00437252
I0526 10:02:56.396945 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00437276 (* 1 = 0.00437276 loss)
I0526 10:02:56.396953 15117 sgd_solver.cpp:294] Iteration 48690, lr = 0.0002
I0526 10:03:02.085155 15117 solver.cpp:342] Iteration 48700, Testing net (#0)
I0526 10:03:14.857038 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9041
I0526 10:03:14.857082 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.446084 (* 1 = 0.446084 loss)
I0526 10:03:15.454550 15117 solver.cpp:233] Iteration 48700, loss = 0.0171937
I0526 10:03:15.454591 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0171939 (* 1 = 0.0171939 loss)
I0526 10:03:15.454598 15117 sgd_solver.cpp:294] Iteration 48700, lr = 0.0002
I0526 10:03:21.740826 15117 solver.cpp:233] Iteration 48710, loss = 0.008809
I0526 10:03:21.741032 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00880925 (* 1 = 0.00880925 loss)
I0526 10:03:21.741058 15117 sgd_solver.cpp:294] Iteration 48710, lr = 0.0002
I0526 10:03:28.029963 15117 solver.cpp:233] Iteration 48720, loss = 0.0117827
I0526 10:03:28.030002 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.011783 (* 1 = 0.011783 loss)
I0526 10:03:28.030009 15117 sgd_solver.cpp:294] Iteration 48720, lr = 0.0002
I0526 10:03:34.319504 15117 solver.cpp:233] Iteration 48730, loss = 0.00359778
I0526 10:03:34.319547 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00359802 (* 1 = 0.00359802 loss)
I0526 10:03:34.319555 15117 sgd_solver.cpp:294] Iteration 48730, lr = 0.0002
I0526 10:03:40.607220 15117 solver.cpp:233] Iteration 48740, loss = 0.00105794
I0526 10:03:40.607262 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00105818 (* 1 = 0.00105818 loss)
I0526 10:03:40.607269 15117 sgd_solver.cpp:294] Iteration 48740, lr = 0.0002
I0526 10:03:46.897760 15117 solver.cpp:233] Iteration 48750, loss = 0.00838583
I0526 10:03:46.897802 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00838607 (* 1 = 0.00838607 loss)
I0526 10:03:46.897809 15117 sgd_solver.cpp:294] Iteration 48750, lr = 0.0002
I0526 10:03:53.186740 15117 solver.cpp:233] Iteration 48760, loss = 0.0104364
I0526 10:03:53.186946 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0104366 (* 1 = 0.0104366 loss)
I0526 10:03:53.186976 15117 sgd_solver.cpp:294] Iteration 48760, lr = 0.0002
I0526 10:03:59.477668 15117 solver.cpp:233] Iteration 48770, loss = 0.00882377
I0526 10:03:59.477712 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00882402 (* 1 = 0.00882402 loss)
I0526 10:03:59.477725 15117 sgd_solver.cpp:294] Iteration 48770, lr = 0.0002
I0526 10:04:05.764711 15117 solver.cpp:233] Iteration 48780, loss = 0.0126333
I0526 10:04:05.764755 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0126336 (* 1 = 0.0126336 loss)
I0526 10:04:05.764761 15117 sgd_solver.cpp:294] Iteration 48780, lr = 0.0002
I0526 10:04:12.057611 15117 solver.cpp:233] Iteration 48790, loss = 0.00688232
I0526 10:04:12.057651 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00688257 (* 1 = 0.00688257 loss)
I0526 10:04:12.057657 15117 sgd_solver.cpp:294] Iteration 48790, lr = 0.0002
I0526 10:04:17.748769 15117 solver.cpp:342] Iteration 48800, Testing net (#0)
I0526 10:04:30.524701 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9043
I0526 10:04:30.524966 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.451902 (* 1 = 0.451902 loss)
I0526 10:04:31.123998 15117 solver.cpp:233] Iteration 48800, loss = 0.0105671
I0526 10:04:31.124063 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0105674 (* 1 = 0.0105674 loss)
I0526 10:04:31.124074 15117 sgd_solver.cpp:294] Iteration 48800, lr = 0.0002
I0526 10:04:37.414594 15117 solver.cpp:233] Iteration 48810, loss = 0.0312718
I0526 10:04:37.414641 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0312721 (* 1 = 0.0312721 loss)
I0526 10:04:37.414659 15117 sgd_solver.cpp:294] Iteration 48810, lr = 0.0002
I0526 10:04:43.703513 15117 solver.cpp:233] Iteration 48820, loss = 0.00906161
I0526 10:04:43.703555 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00906186 (* 1 = 0.00906186 loss)
I0526 10:04:43.703562 15117 sgd_solver.cpp:294] Iteration 48820, lr = 0.0002
I0526 10:04:49.995167 15117 solver.cpp:233] Iteration 48830, loss = 0.00703714
I0526 10:04:49.995200 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00703739 (* 1 = 0.00703739 loss)
I0526 10:04:49.995208 15117 sgd_solver.cpp:294] Iteration 48830, lr = 0.0002
I0526 10:04:56.282232 15117 solver.cpp:233] Iteration 48840, loss = 0.00585835
I0526 10:04:56.282275 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00585859 (* 1 = 0.00585859 loss)
I0526 10:04:56.282281 15117 sgd_solver.cpp:294] Iteration 48840, lr = 0.0002
I0526 10:05:02.570633 15117 solver.cpp:233] Iteration 48850, loss = 0.00540754
I0526 10:05:02.570765 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00540779 (* 1 = 0.00540779 loss)
I0526 10:05:02.570773 15117 sgd_solver.cpp:294] Iteration 48850, lr = 0.0002
I0526 10:05:08.862815 15117 solver.cpp:233] Iteration 48860, loss = 0.0194475
I0526 10:05:08.862859 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0194478 (* 1 = 0.0194478 loss)
I0526 10:05:08.862866 15117 sgd_solver.cpp:294] Iteration 48860, lr = 0.0002
I0526 10:05:15.152802 15117 solver.cpp:233] Iteration 48870, loss = 0.0111356
I0526 10:05:15.152843 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0111358 (* 1 = 0.0111358 loss)
I0526 10:05:15.152849 15117 sgd_solver.cpp:294] Iteration 48870, lr = 0.0002
I0526 10:05:21.445101 15117 solver.cpp:233] Iteration 48880, loss = 0.037525
I0526 10:05:21.445147 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0375253 (* 1 = 0.0375253 loss)
I0526 10:05:21.445155 15117 sgd_solver.cpp:294] Iteration 48880, lr = 0.0002
I0526 10:05:27.731878 15117 solver.cpp:233] Iteration 48890, loss = 0.0245092
I0526 10:05:27.731921 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0245094 (* 1 = 0.0245094 loss)
I0526 10:05:27.731930 15117 sgd_solver.cpp:294] Iteration 48890, lr = 0.0002
I0526 10:05:33.419219 15117 solver.cpp:342] Iteration 48900, Testing net (#0)
I0526 10:05:46.192978 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9058
I0526 10:05:46.193019 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.443848 (* 1 = 0.443848 loss)
I0526 10:05:46.790460 15117 solver.cpp:233] Iteration 48900, loss = 0.00614053
I0526 10:05:46.790508 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00614078 (* 1 = 0.00614078 loss)
I0526 10:05:46.790515 15117 sgd_solver.cpp:294] Iteration 48900, lr = 0.0002
I0526 10:05:53.080720 15117 solver.cpp:233] Iteration 48910, loss = 0.0186958
I0526 10:05:53.080763 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0186961 (* 1 = 0.0186961 loss)
I0526 10:05:53.080770 15117 sgd_solver.cpp:294] Iteration 48910, lr = 0.0002
I0526 10:05:59.372107 15117 solver.cpp:233] Iteration 48920, loss = 0.0119638
I0526 10:05:59.372148 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.011964 (* 1 = 0.011964 loss)
I0526 10:05:59.372154 15117 sgd_solver.cpp:294] Iteration 48920, lr = 0.0002
I0526 10:06:05.662173 15117 solver.cpp:233] Iteration 48930, loss = 0.0159682
I0526 10:06:05.662482 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0159685 (* 1 = 0.0159685 loss)
I0526 10:06:05.662513 15117 sgd_solver.cpp:294] Iteration 48930, lr = 0.0002
I0526 10:06:11.955324 15117 solver.cpp:233] Iteration 48940, loss = 0.00873523
I0526 10:06:11.955368 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00873548 (* 1 = 0.00873548 loss)
I0526 10:06:11.955375 15117 sgd_solver.cpp:294] Iteration 48940, lr = 0.0002
I0526 10:06:18.247938 15117 solver.cpp:233] Iteration 48950, loss = 0.0205341
I0526 10:06:18.247978 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0205343 (* 1 = 0.0205343 loss)
I0526 10:06:18.247984 15117 sgd_solver.cpp:294] Iteration 48950, lr = 0.0002
I0526 10:06:24.539597 15117 solver.cpp:233] Iteration 48960, loss = 0.00441962
I0526 10:06:24.539635 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00441987 (* 1 = 0.00441987 loss)
I0526 10:06:24.539643 15117 sgd_solver.cpp:294] Iteration 48960, lr = 0.0002
I0526 10:06:30.824162 15117 solver.cpp:233] Iteration 48970, loss = 0.0178993
I0526 10:06:30.824203 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0178996 (* 1 = 0.0178996 loss)
I0526 10:06:30.824209 15117 sgd_solver.cpp:294] Iteration 48970, lr = 0.0002
I0526 10:06:37.111740 15117 solver.cpp:233] Iteration 48980, loss = 0.00287858
I0526 10:06:37.111956 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00287883 (* 1 = 0.00287883 loss)
I0526 10:06:37.111984 15117 sgd_solver.cpp:294] Iteration 48980, lr = 0.0002
I0526 10:06:43.406208 15117 solver.cpp:233] Iteration 48990, loss = 0.0069435
I0526 10:06:43.406235 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00694376 (* 1 = 0.00694376 loss)
I0526 10:06:43.406242 15117 sgd_solver.cpp:294] Iteration 48990, lr = 0.0002
I0526 10:06:49.097146 15117 solver.cpp:342] Iteration 49000, Testing net (#0)
I0526 10:07:01.881386 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9036
I0526 10:07:01.881428 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.444896 (* 1 = 0.444896 loss)
I0526 10:07:02.478941 15117 solver.cpp:233] Iteration 49000, loss = 0.0121169
I0526 10:07:02.478979 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0121172 (* 1 = 0.0121172 loss)
I0526 10:07:02.478986 15117 sgd_solver.cpp:294] Iteration 49000, lr = 0.0002
I0526 10:07:08.770570 15117 solver.cpp:233] Iteration 49010, loss = 0.00854743
I0526 10:07:08.770756 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00854769 (* 1 = 0.00854769 loss)
I0526 10:07:08.770787 15117 sgd_solver.cpp:294] Iteration 49010, lr = 0.0002
I0526 10:07:15.061503 15117 solver.cpp:233] Iteration 49020, loss = 0.029326
I0526 10:07:15.061542 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0293263 (* 1 = 0.0293263 loss)
I0526 10:07:15.061549 15117 sgd_solver.cpp:294] Iteration 49020, lr = 0.0002
I0526 10:07:21.351676 15117 solver.cpp:233] Iteration 49030, loss = 0.0042395
I0526 10:07:21.351721 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00423976 (* 1 = 0.00423976 loss)
I0526 10:07:21.351727 15117 sgd_solver.cpp:294] Iteration 49030, lr = 0.0002
I0526 10:07:27.638859 15117 solver.cpp:233] Iteration 49040, loss = 0.00364387
I0526 10:07:27.638906 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00364413 (* 1 = 0.00364413 loss)
I0526 10:07:27.638912 15117 sgd_solver.cpp:294] Iteration 49040, lr = 0.0002
I0526 10:07:33.927443 15117 solver.cpp:233] Iteration 49050, loss = 0.0186955
I0526 10:07:33.927489 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0186957 (* 1 = 0.0186957 loss)
I0526 10:07:33.927497 15117 sgd_solver.cpp:294] Iteration 49050, lr = 0.0002
I0526 10:07:40.214020 15117 solver.cpp:233] Iteration 49060, loss = 0.00528315
I0526 10:07:40.214282 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00528342 (* 1 = 0.00528342 loss)
I0526 10:07:40.214308 15117 sgd_solver.cpp:294] Iteration 49060, lr = 0.0002
I0526 10:07:46.505415 15117 solver.cpp:233] Iteration 49070, loss = 0.0101488
I0526 10:07:46.505456 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.010149 (* 1 = 0.010149 loss)
I0526 10:07:46.505463 15117 sgd_solver.cpp:294] Iteration 49070, lr = 0.0002
I0526 10:07:52.795251 15117 solver.cpp:233] Iteration 49080, loss = 0.0320468
I0526 10:07:52.795294 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.032047 (* 1 = 0.032047 loss)
I0526 10:07:52.795300 15117 sgd_solver.cpp:294] Iteration 49080, lr = 0.0002
I0526 10:07:59.086920 15117 solver.cpp:233] Iteration 49090, loss = 0.00974275
I0526 10:07:59.086961 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00974301 (* 1 = 0.00974301 loss)
I0526 10:07:59.086967 15117 sgd_solver.cpp:294] Iteration 49090, lr = 0.0002
I0526 10:08:04.781224 15117 solver.cpp:342] Iteration 49100, Testing net (#0)
I0526 10:08:17.559797 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9059
I0526 10:08:17.560029 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.446848 (* 1 = 0.446848 loss)
I0526 10:08:18.159098 15117 solver.cpp:233] Iteration 49100, loss = 0.013884
I0526 10:08:18.159144 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0138843 (* 1 = 0.0138843 loss)
I0526 10:08:18.159152 15117 sgd_solver.cpp:294] Iteration 49100, lr = 0.0002
I0526 10:08:24.450908 15117 solver.cpp:233] Iteration 49110, loss = 0.00750664
I0526 10:08:24.450950 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0075069 (* 1 = 0.0075069 loss)
I0526 10:08:24.450956 15117 sgd_solver.cpp:294] Iteration 49110, lr = 0.0002
I0526 10:08:30.739778 15117 solver.cpp:233] Iteration 49120, loss = 0.00263104
I0526 10:08:30.739819 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0026313 (* 1 = 0.0026313 loss)
I0526 10:08:30.739825 15117 sgd_solver.cpp:294] Iteration 49120, lr = 0.0002
I0526 10:08:37.021982 15117 solver.cpp:233] Iteration 49130, loss = 0.0168764
I0526 10:08:37.022025 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0168766 (* 1 = 0.0168766 loss)
I0526 10:08:37.022032 15117 sgd_solver.cpp:294] Iteration 49130, lr = 0.0002
I0526 10:08:43.311832 15117 solver.cpp:233] Iteration 49140, loss = 0.00731856
I0526 10:08:43.311878 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00731883 (* 1 = 0.00731883 loss)
I0526 10:08:43.311885 15117 sgd_solver.cpp:294] Iteration 49140, lr = 0.0002
I0526 10:08:49.601280 15117 solver.cpp:233] Iteration 49150, loss = 0.00810686
I0526 10:08:49.601466 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00810713 (* 1 = 0.00810713 loss)
I0526 10:08:49.601493 15117 sgd_solver.cpp:294] Iteration 49150, lr = 0.0002
I0526 10:08:55.919145 15117 solver.cpp:233] Iteration 49160, loss = 0.00746007
I0526 10:08:55.919188 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00746034 (* 1 = 0.00746034 loss)
I0526 10:08:55.919194 15117 sgd_solver.cpp:294] Iteration 49160, lr = 0.0002
I0526 10:09:02.236071 15117 solver.cpp:233] Iteration 49170, loss = 0.009318
I0526 10:09:02.236115 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00931827 (* 1 = 0.00931827 loss)
I0526 10:09:02.236122 15117 sgd_solver.cpp:294] Iteration 49170, lr = 0.0002
I0526 10:09:08.528533 15117 solver.cpp:233] Iteration 49180, loss = 0.0133166
I0526 10:09:08.528576 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0133169 (* 1 = 0.0133169 loss)
I0526 10:09:08.528584 15117 sgd_solver.cpp:294] Iteration 49180, lr = 0.0002
I0526 10:09:14.821306 15117 solver.cpp:233] Iteration 49190, loss = 0.0138834
I0526 10:09:14.821349 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0138836 (* 1 = 0.0138836 loss)
I0526 10:09:14.821355 15117 sgd_solver.cpp:294] Iteration 49190, lr = 0.0002
I0526 10:09:20.514297 15117 solver.cpp:342] Iteration 49200, Testing net (#0)
I0526 10:09:33.299530 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9044
I0526 10:09:33.299572 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.426117 (* 1 = 0.426117 loss)
I0526 10:09:33.896420 15117 solver.cpp:233] Iteration 49200, loss = 0.0308229
I0526 10:09:33.896452 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0308231 (* 1 = 0.0308231 loss)
I0526 10:09:33.896459 15117 sgd_solver.cpp:294] Iteration 49200, lr = 0.0002
I0526 10:09:40.184633 15117 solver.cpp:233] Iteration 49210, loss = 0.00162214
I0526 10:09:40.184676 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0016224 (* 1 = 0.0016224 loss)
I0526 10:09:40.184684 15117 sgd_solver.cpp:294] Iteration 49210, lr = 0.0002
I0526 10:09:46.468508 15117 solver.cpp:233] Iteration 49220, loss = 0.0123334
I0526 10:09:46.468549 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0123337 (* 1 = 0.0123337 loss)
I0526 10:09:46.468555 15117 sgd_solver.cpp:294] Iteration 49220, lr = 0.0002
I0526 10:09:52.754200 15117 solver.cpp:233] Iteration 49230, loss = 0.0117628
I0526 10:09:52.754433 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0117631 (* 1 = 0.0117631 loss)
I0526 10:09:52.754462 15117 sgd_solver.cpp:294] Iteration 49230, lr = 0.0002
I0526 10:09:59.045802 15117 solver.cpp:233] Iteration 49240, loss = 0.0108442
I0526 10:09:59.045845 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0108444 (* 1 = 0.0108444 loss)
I0526 10:09:59.045852 15117 sgd_solver.cpp:294] Iteration 49240, lr = 0.0002
I0526 10:10:05.337491 15117 solver.cpp:233] Iteration 49250, loss = 0.0135907
I0526 10:10:05.337537 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.013591 (* 1 = 0.013591 loss)
I0526 10:10:05.337543 15117 sgd_solver.cpp:294] Iteration 49250, lr = 0.0002
I0526 10:10:11.624312 15117 solver.cpp:233] Iteration 49260, loss = 0.0063854
I0526 10:10:11.624352 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00638566 (* 1 = 0.00638566 loss)
I0526 10:10:11.624358 15117 sgd_solver.cpp:294] Iteration 49260, lr = 0.0002
I0526 10:10:17.911468 15117 solver.cpp:233] Iteration 49270, loss = 0.00939653
I0526 10:10:17.911510 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00939679 (* 1 = 0.00939679 loss)
I0526 10:10:17.911517 15117 sgd_solver.cpp:294] Iteration 49270, lr = 0.0002
I0526 10:10:24.200872 15117 solver.cpp:233] Iteration 49280, loss = 0.0144599
I0526 10:10:24.201079 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0144602 (* 1 = 0.0144602 loss)
I0526 10:10:24.201107 15117 sgd_solver.cpp:294] Iteration 49280, lr = 0.0002
I0526 10:10:30.492151 15117 solver.cpp:233] Iteration 49290, loss = 0.0185891
I0526 10:10:30.492193 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0185894 (* 1 = 0.0185894 loss)
I0526 10:10:30.492200 15117 sgd_solver.cpp:294] Iteration 49290, lr = 0.0002
I0526 10:10:36.186486 15117 solver.cpp:342] Iteration 49300, Testing net (#0)
I0526 10:10:48.967854 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9055
I0526 10:10:48.967896 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.447406 (* 1 = 0.447406 loss)
I0526 10:10:49.564754 15117 solver.cpp:233] Iteration 49300, loss = 0.0096467
I0526 10:10:49.564796 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00964695 (* 1 = 0.00964695 loss)
I0526 10:10:49.564810 15117 sgd_solver.cpp:294] Iteration 49300, lr = 0.0002
I0526 10:10:55.849784 15117 solver.cpp:233] Iteration 49310, loss = 0.0141042
I0526 10:10:55.850024 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0141045 (* 1 = 0.0141045 loss)
I0526 10:10:55.850054 15117 sgd_solver.cpp:294] Iteration 49310, lr = 0.0002
I0526 10:11:02.140311 15117 solver.cpp:233] Iteration 49320, loss = 0.0352395
I0526 10:11:02.140354 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0352398 (* 1 = 0.0352398 loss)
I0526 10:11:02.140362 15117 sgd_solver.cpp:294] Iteration 49320, lr = 0.0002
I0526 10:11:08.428987 15117 solver.cpp:233] Iteration 49330, loss = 0.00519203
I0526 10:11:08.429018 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00519229 (* 1 = 0.00519229 loss)
I0526 10:11:08.429024 15117 sgd_solver.cpp:294] Iteration 49330, lr = 0.0002
I0526 10:11:14.717789 15117 solver.cpp:233] Iteration 49340, loss = 0.00912532
I0526 10:11:14.717829 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00912557 (* 1 = 0.00912557 loss)
I0526 10:11:14.717836 15117 sgd_solver.cpp:294] Iteration 49340, lr = 0.0002
I0526 10:11:21.007694 15117 solver.cpp:233] Iteration 49350, loss = 0.00468166
I0526 10:11:21.007740 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00468192 (* 1 = 0.00468192 loss)
I0526 10:11:21.007747 15117 sgd_solver.cpp:294] Iteration 49350, lr = 0.0002
I0526 10:11:27.296764 15117 solver.cpp:233] Iteration 49360, loss = 0.0240868
I0526 10:11:27.296908 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0240871 (* 1 = 0.0240871 loss)
I0526 10:11:27.296917 15117 sgd_solver.cpp:294] Iteration 49360, lr = 0.0002
I0526 10:11:33.585080 15117 solver.cpp:233] Iteration 49370, loss = 0.00480883
I0526 10:11:33.585119 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00480909 (* 1 = 0.00480909 loss)
I0526 10:11:33.585126 15117 sgd_solver.cpp:294] Iteration 49370, lr = 0.0002
I0526 10:11:39.877933 15117 solver.cpp:233] Iteration 49380, loss = 0.00278108
I0526 10:11:39.877975 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00278134 (* 1 = 0.00278134 loss)
I0526 10:11:39.877982 15117 sgd_solver.cpp:294] Iteration 49380, lr = 0.0002
I0526 10:11:46.169268 15117 solver.cpp:233] Iteration 49390, loss = 0.0129286
I0526 10:11:46.169309 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0129288 (* 1 = 0.0129288 loss)
I0526 10:11:46.169317 15117 sgd_solver.cpp:294] Iteration 49390, lr = 0.0002
I0526 10:11:51.859102 15117 solver.cpp:342] Iteration 49400, Testing net (#0)
I0526 10:12:04.637017 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9055
I0526 10:12:04.637130 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.455875 (* 1 = 0.455875 loss)
I0526 10:12:05.233862 15117 solver.cpp:233] Iteration 49400, loss = 0.00141804
I0526 10:12:05.233898 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0014183 (* 1 = 0.0014183 loss)
I0526 10:12:05.233906 15117 sgd_solver.cpp:294] Iteration 49400, lr = 0.0002
I0526 10:12:11.517884 15117 solver.cpp:233] Iteration 49410, loss = 0.0051203
I0526 10:12:11.517923 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00512055 (* 1 = 0.00512055 loss)
I0526 10:12:11.517930 15117 sgd_solver.cpp:294] Iteration 49410, lr = 0.0002
I0526 10:12:17.810372 15117 solver.cpp:233] Iteration 49420, loss = 0.00956806
I0526 10:12:17.810406 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00956831 (* 1 = 0.00956831 loss)
I0526 10:12:17.810413 15117 sgd_solver.cpp:294] Iteration 49420, lr = 0.0002
I0526 10:12:24.098145 15117 solver.cpp:233] Iteration 49430, loss = 0.0157211
I0526 10:12:24.098188 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0157213 (* 1 = 0.0157213 loss)
I0526 10:12:24.098196 15117 sgd_solver.cpp:294] Iteration 49430, lr = 0.0002
I0526 10:12:30.383275 15117 solver.cpp:233] Iteration 49440, loss = 0.0192144
I0526 10:12:30.383316 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0192146 (* 1 = 0.0192146 loss)
I0526 10:12:30.383328 15117 sgd_solver.cpp:294] Iteration 49440, lr = 0.0002
I0526 10:12:36.673760 15117 solver.cpp:233] Iteration 49450, loss = 0.00770357
I0526 10:12:36.674016 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00770382 (* 1 = 0.00770382 loss)
I0526 10:12:36.674046 15117 sgd_solver.cpp:294] Iteration 49450, lr = 0.0002
I0526 10:12:42.960949 15117 solver.cpp:233] Iteration 49460, loss = 0.0138569
I0526 10:12:42.960988 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0138572 (* 1 = 0.0138572 loss)
I0526 10:12:42.960994 15117 sgd_solver.cpp:294] Iteration 49460, lr = 0.0002
I0526 10:12:49.249547 15117 solver.cpp:233] Iteration 49470, loss = 0.00555444
I0526 10:12:49.249591 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00555469 (* 1 = 0.00555469 loss)
I0526 10:12:49.249599 15117 sgd_solver.cpp:294] Iteration 49470, lr = 0.0002
I0526 10:12:55.532918 15117 solver.cpp:233] Iteration 49480, loss = 0.0119559
I0526 10:12:55.532959 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0119561 (* 1 = 0.0119561 loss)
I0526 10:12:55.532966 15117 sgd_solver.cpp:294] Iteration 49480, lr = 0.0002
I0526 10:13:01.818994 15117 solver.cpp:233] Iteration 49490, loss = 0.0125698
I0526 10:13:01.819034 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0125701 (* 1 = 0.0125701 loss)
I0526 10:13:01.819041 15117 sgd_solver.cpp:294] Iteration 49490, lr = 0.0002
I0526 10:13:07.509132 15117 solver.cpp:342] Iteration 49500, Testing net (#0)
I0526 10:13:20.281695 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9059
I0526 10:13:20.281741 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.445863 (* 1 = 0.445863 loss)
I0526 10:13:20.879096 15117 solver.cpp:233] Iteration 49500, loss = 0.0046803
I0526 10:13:20.879134 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00468055 (* 1 = 0.00468055 loss)
I0526 10:13:20.879142 15117 sgd_solver.cpp:294] Iteration 49500, lr = 0.0002
I0526 10:13:27.164765 15117 solver.cpp:233] Iteration 49510, loss = 0.0110494
I0526 10:13:27.164793 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0110496 (* 1 = 0.0110496 loss)
I0526 10:13:27.164798 15117 sgd_solver.cpp:294] Iteration 49510, lr = 0.0002
I0526 10:13:33.453660 15117 solver.cpp:233] Iteration 49520, loss = 0.0115961
I0526 10:13:33.453708 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0115963 (* 1 = 0.0115963 loss)
I0526 10:13:33.453716 15117 sgd_solver.cpp:294] Iteration 49520, lr = 0.0002
I0526 10:13:39.742606 15117 solver.cpp:233] Iteration 49530, loss = 0.00555134
I0526 10:13:39.742820 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00555159 (* 1 = 0.00555159 loss)
I0526 10:13:39.742846 15117 sgd_solver.cpp:294] Iteration 49530, lr = 0.0002
I0526 10:13:46.032542 15117 solver.cpp:233] Iteration 49540, loss = 0.00644418
I0526 10:13:46.032588 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00644443 (* 1 = 0.00644443 loss)
I0526 10:13:46.032594 15117 sgd_solver.cpp:294] Iteration 49540, lr = 0.0002
I0526 10:13:52.322059 15117 solver.cpp:233] Iteration 49550, loss = 0.00410771
I0526 10:13:52.322104 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00410796 (* 1 = 0.00410796 loss)
I0526 10:13:52.322111 15117 sgd_solver.cpp:294] Iteration 49550, lr = 0.0002
I0526 10:13:58.608266 15117 solver.cpp:233] Iteration 49560, loss = 0.0179298
I0526 10:13:58.608307 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0179301 (* 1 = 0.0179301 loss)
I0526 10:13:58.608315 15117 sgd_solver.cpp:294] Iteration 49560, lr = 0.0002
I0526 10:14:04.894587 15117 solver.cpp:233] Iteration 49570, loss = 0.0162803
I0526 10:14:04.894632 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0162806 (* 1 = 0.0162806 loss)
I0526 10:14:04.894640 15117 sgd_solver.cpp:294] Iteration 49570, lr = 0.0002
I0526 10:14:11.182535 15117 solver.cpp:233] Iteration 49580, loss = 0.011909
I0526 10:14:11.182809 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0119093 (* 1 = 0.0119093 loss)
I0526 10:14:11.182837 15117 sgd_solver.cpp:294] Iteration 49580, lr = 0.0002
I0526 10:14:17.469821 15117 solver.cpp:233] Iteration 49590, loss = 0.00110059
I0526 10:14:17.469861 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00110084 (* 1 = 0.00110084 loss)
I0526 10:14:17.469868 15117 sgd_solver.cpp:294] Iteration 49590, lr = 0.0002
I0526 10:14:23.160907 15117 solver.cpp:342] Iteration 49600, Testing net (#0)
I0526 10:14:35.945039 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9039
I0526 10:14:35.945086 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.45476 (* 1 = 0.45476 loss)
I0526 10:14:36.542757 15117 solver.cpp:233] Iteration 49600, loss = 0.00630605
I0526 10:14:36.542796 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0063063 (* 1 = 0.0063063 loss)
I0526 10:14:36.542803 15117 sgd_solver.cpp:294] Iteration 49600, lr = 0.0002
I0526 10:14:42.831864 15117 solver.cpp:233] Iteration 49610, loss = 0.00704542
I0526 10:14:42.831997 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00704567 (* 1 = 0.00704567 loss)
I0526 10:14:42.832005 15117 sgd_solver.cpp:294] Iteration 49610, lr = 0.0002
I0526 10:14:49.120961 15117 solver.cpp:233] Iteration 49620, loss = 0.0105646
I0526 10:14:49.121004 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0105648 (* 1 = 0.0105648 loss)
I0526 10:14:49.121011 15117 sgd_solver.cpp:294] Iteration 49620, lr = 0.0002
I0526 10:14:55.411437 15117 solver.cpp:233] Iteration 49630, loss = 0.0149715
I0526 10:14:55.411478 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0149717 (* 1 = 0.0149717 loss)
I0526 10:14:55.411484 15117 sgd_solver.cpp:294] Iteration 49630, lr = 0.0002
I0526 10:15:01.698859 15117 solver.cpp:233] Iteration 49640, loss = 0.0076998
I0526 10:15:01.698902 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00770005 (* 1 = 0.00770005 loss)
I0526 10:15:01.698910 15117 sgd_solver.cpp:294] Iteration 49640, lr = 0.0002
I0526 10:15:07.989279 15117 solver.cpp:233] Iteration 49650, loss = 0.00544029
I0526 10:15:07.989325 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00544053 (* 1 = 0.00544053 loss)
I0526 10:15:07.989331 15117 sgd_solver.cpp:294] Iteration 49650, lr = 0.0002
I0526 10:15:14.279028 15117 solver.cpp:233] Iteration 49660, loss = 0.00675224
I0526 10:15:14.279127 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00675248 (* 1 = 0.00675248 loss)
I0526 10:15:14.279135 15117 sgd_solver.cpp:294] Iteration 49660, lr = 0.0002
I0526 10:15:20.570052 15117 solver.cpp:233] Iteration 49670, loss = 0.013303
I0526 10:15:20.570096 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0133032 (* 1 = 0.0133032 loss)
I0526 10:15:20.570102 15117 sgd_solver.cpp:294] Iteration 49670, lr = 0.0002
I0526 10:15:26.860167 15117 solver.cpp:233] Iteration 49680, loss = 0.0064775
I0526 10:15:26.860193 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00647775 (* 1 = 0.00647775 loss)
I0526 10:15:26.860200 15117 sgd_solver.cpp:294] Iteration 49680, lr = 0.0002
I0526 10:15:33.151525 15117 solver.cpp:233] Iteration 49690, loss = 0.0060243
I0526 10:15:33.151566 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00602455 (* 1 = 0.00602455 loss)
I0526 10:15:33.151572 15117 sgd_solver.cpp:294] Iteration 49690, lr = 0.0002
I0526 10:15:38.842097 15117 solver.cpp:342] Iteration 49700, Testing net (#0)
I0526 10:15:51.635514 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9045
I0526 10:15:51.635745 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.445989 (* 1 = 0.445989 loss)
I0526 10:15:52.233280 15117 solver.cpp:233] Iteration 49700, loss = 0.0134479
I0526 10:15:52.233311 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0134481 (* 1 = 0.0134481 loss)
I0526 10:15:52.233319 15117 sgd_solver.cpp:294] Iteration 49700, lr = 0.0002
I0526 10:15:58.522469 15117 solver.cpp:233] Iteration 49710, loss = 0.0139894
I0526 10:15:58.522511 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0139896 (* 1 = 0.0139896 loss)
I0526 10:15:58.522517 15117 sgd_solver.cpp:294] Iteration 49710, lr = 0.0002
I0526 10:16:04.811096 15117 solver.cpp:233] Iteration 49720, loss = 0.0149499
I0526 10:16:04.811141 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0149501 (* 1 = 0.0149501 loss)
I0526 10:16:04.811149 15117 sgd_solver.cpp:294] Iteration 49720, lr = 0.0002
I0526 10:16:11.096545 15117 solver.cpp:233] Iteration 49730, loss = 0.00364212
I0526 10:16:11.096587 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00364236 (* 1 = 0.00364236 loss)
I0526 10:16:11.096595 15117 sgd_solver.cpp:294] Iteration 49730, lr = 0.0002
I0526 10:16:17.388298 15117 solver.cpp:233] Iteration 49740, loss = 0.0106556
I0526 10:16:17.388339 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0106558 (* 1 = 0.0106558 loss)
I0526 10:16:17.388346 15117 sgd_solver.cpp:294] Iteration 49740, lr = 0.0002
I0526 10:16:23.681169 15117 solver.cpp:233] Iteration 49750, loss = 0.0180657
I0526 10:16:23.681336 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0180659 (* 1 = 0.0180659 loss)
I0526 10:16:23.681345 15117 sgd_solver.cpp:294] Iteration 49750, lr = 0.0002
I0526 10:16:29.971782 15117 solver.cpp:233] Iteration 49760, loss = 0.0116122
I0526 10:16:29.971822 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0116125 (* 1 = 0.0116125 loss)
I0526 10:16:29.971829 15117 sgd_solver.cpp:294] Iteration 49760, lr = 0.0002
I0526 10:16:36.262473 15117 solver.cpp:233] Iteration 49770, loss = 0.00992709
I0526 10:16:36.262517 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00992733 (* 1 = 0.00992733 loss)
I0526 10:16:36.262524 15117 sgd_solver.cpp:294] Iteration 49770, lr = 0.0002
I0526 10:16:42.551990 15117 solver.cpp:233] Iteration 49780, loss = 0.026376
I0526 10:16:42.552031 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0263762 (* 1 = 0.0263762 loss)
I0526 10:16:42.552038 15117 sgd_solver.cpp:294] Iteration 49780, lr = 0.0002
I0526 10:16:48.843400 15117 solver.cpp:233] Iteration 49790, loss = 0.00962711
I0526 10:16:48.843444 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00962735 (* 1 = 0.00962735 loss)
I0526 10:16:48.843451 15117 sgd_solver.cpp:294] Iteration 49790, lr = 0.0002
I0526 10:16:54.538368 15117 solver.cpp:342] Iteration 49800, Testing net (#0)
I0526 10:17:07.326839 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.904
I0526 10:17:07.326887 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.44397 (* 1 = 0.44397 loss)
I0526 10:17:07.923127 15117 solver.cpp:233] Iteration 49800, loss = 0.00550793
I0526 10:17:07.923169 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00550817 (* 1 = 0.00550817 loss)
I0526 10:17:07.923177 15117 sgd_solver.cpp:294] Iteration 49800, lr = 0.0002
I0526 10:17:14.215319 15117 solver.cpp:233] Iteration 49810, loss = 0.00816575
I0526 10:17:14.215363 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00816599 (* 1 = 0.00816599 loss)
I0526 10:17:14.215369 15117 sgd_solver.cpp:294] Iteration 49810, lr = 0.0002
I0526 10:17:20.503263 15117 solver.cpp:233] Iteration 49820, loss = 0.0128654
I0526 10:17:20.503309 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0128657 (* 1 = 0.0128657 loss)
I0526 10:17:20.503315 15117 sgd_solver.cpp:294] Iteration 49820, lr = 0.0002
I0526 10:17:26.797175 15117 solver.cpp:233] Iteration 49830, loss = 0.00550524
I0526 10:17:26.797407 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00550548 (* 1 = 0.00550548 loss)
I0526 10:17:26.797436 15117 sgd_solver.cpp:294] Iteration 49830, lr = 0.0002
I0526 10:17:33.087939 15117 solver.cpp:233] Iteration 49840, loss = 0.00542954
I0526 10:17:33.087980 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00542978 (* 1 = 0.00542978 loss)
I0526 10:17:33.087993 15117 sgd_solver.cpp:294] Iteration 49840, lr = 0.0002
I0526 10:17:39.379633 15117 solver.cpp:233] Iteration 49850, loss = 0.0210761
I0526 10:17:39.379679 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0210764 (* 1 = 0.0210764 loss)
I0526 10:17:39.379686 15117 sgd_solver.cpp:294] Iteration 49850, lr = 0.0002
I0526 10:17:45.671247 15117 solver.cpp:233] Iteration 49860, loss = 0.00788222
I0526 10:17:45.671289 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00788246 (* 1 = 0.00788246 loss)
I0526 10:17:45.671296 15117 sgd_solver.cpp:294] Iteration 49860, lr = 0.0002
I0526 10:17:51.964082 15117 solver.cpp:233] Iteration 49870, loss = 0.0026419
I0526 10:17:51.964125 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00264214 (* 1 = 0.00264214 loss)
I0526 10:17:51.964133 15117 sgd_solver.cpp:294] Iteration 49870, lr = 0.0002
I0526 10:17:58.257398 15117 solver.cpp:233] Iteration 49880, loss = 0.00793162
I0526 10:17:58.257603 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00793186 (* 1 = 0.00793186 loss)
I0526 10:17:58.257628 15117 sgd_solver.cpp:294] Iteration 49880, lr = 0.0002
I0526 10:18:04.548728 15117 solver.cpp:233] Iteration 49890, loss = 0.00248603
I0526 10:18:04.548773 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00248628 (* 1 = 0.00248628 loss)
I0526 10:18:04.548779 15117 sgd_solver.cpp:294] Iteration 49890, lr = 0.0002
I0526 10:18:10.237895 15117 solver.cpp:342] Iteration 49900, Testing net (#0)
I0526 10:18:23.022547 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9038
I0526 10:18:23.022590 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.449629 (* 1 = 0.449629 loss)
I0526 10:18:23.619973 15117 solver.cpp:233] Iteration 49900, loss = 0.00900539
I0526 10:18:23.620013 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00900564 (* 1 = 0.00900564 loss)
I0526 10:18:23.620021 15117 sgd_solver.cpp:294] Iteration 49900, lr = 0.0002
I0526 10:18:29.907290 15117 solver.cpp:233] Iteration 49910, loss = 0.00809746
I0526 10:18:29.907506 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00809771 (* 1 = 0.00809771 loss)
I0526 10:18:29.907536 15117 sgd_solver.cpp:294] Iteration 49910, lr = 0.0002
I0526 10:18:36.202292 15117 solver.cpp:233] Iteration 49920, loss = 0.00996111
I0526 10:18:36.202324 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00996136 (* 1 = 0.00996136 loss)
I0526 10:18:36.202332 15117 sgd_solver.cpp:294] Iteration 49920, lr = 0.0002
I0526 10:18:42.493513 15117 solver.cpp:233] Iteration 49930, loss = 0.00760685
I0526 10:18:42.493554 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0076071 (* 1 = 0.0076071 loss)
I0526 10:18:42.493561 15117 sgd_solver.cpp:294] Iteration 49930, lr = 0.0002
I0526 10:18:48.784723 15117 solver.cpp:233] Iteration 49940, loss = 0.0096565
I0526 10:18:48.784768 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00965674 (* 1 = 0.00965674 loss)
I0526 10:18:48.784775 15117 sgd_solver.cpp:294] Iteration 49940, lr = 0.0002
I0526 10:18:55.076752 15117 solver.cpp:233] Iteration 49950, loss = 0.00435095
I0526 10:18:55.076793 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00435119 (* 1 = 0.00435119 loss)
I0526 10:18:55.076800 15117 sgd_solver.cpp:294] Iteration 49950, lr = 0.0002
I0526 10:19:01.368700 15117 solver.cpp:233] Iteration 49960, loss = 0.00425574
I0526 10:19:01.368877 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00425598 (* 1 = 0.00425598 loss)
I0526 10:19:01.368904 15117 sgd_solver.cpp:294] Iteration 49960, lr = 0.0002
I0526 10:19:07.663322 15117 solver.cpp:233] Iteration 49970, loss = 0.00666491
I0526 10:19:07.663365 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00666515 (* 1 = 0.00666515 loss)
I0526 10:19:07.663372 15117 sgd_solver.cpp:294] Iteration 49970, lr = 0.0002
I0526 10:19:13.953765 15117 solver.cpp:233] Iteration 49980, loss = 0.0376896
I0526 10:19:13.953812 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0376898 (* 1 = 0.0376898 loss)
I0526 10:19:13.953820 15117 sgd_solver.cpp:294] Iteration 49980, lr = 0.0002
I0526 10:19:20.244179 15117 solver.cpp:233] Iteration 49990, loss = 0.00880547
I0526 10:19:20.244223 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00880571 (* 1 = 0.00880571 loss)
I0526 10:19:20.244230 15117 sgd_solver.cpp:294] Iteration 49990, lr = 0.0002
I0526 10:19:25.935158 15117 solver.cpp:342] Iteration 50000, Testing net (#0)
I0526 10:19:38.711537 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9062
I0526 10:19:38.711801 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.438517 (* 1 = 0.438517 loss)
I0526 10:19:39.309548 15117 solver.cpp:233] Iteration 50000, loss = 0.0107738
I0526 10:19:39.309584 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.010774 (* 1 = 0.010774 loss)
I0526 10:19:39.309592 15117 sgd_solver.cpp:294] Iteration 50000, lr = 0.0002
I0526 10:19:45.600932 15117 solver.cpp:233] Iteration 50010, loss = 0.0301706
I0526 10:19:45.600975 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0301708 (* 1 = 0.0301708 loss)
I0526 10:19:45.600981 15117 sgd_solver.cpp:294] Iteration 50010, lr = 0.0002
I0526 10:19:51.890528 15117 solver.cpp:233] Iteration 50020, loss = 0.0043317
I0526 10:19:51.890573 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00433194 (* 1 = 0.00433194 loss)
I0526 10:19:51.890579 15117 sgd_solver.cpp:294] Iteration 50020, lr = 0.0002
I0526 10:19:58.182916 15117 solver.cpp:233] Iteration 50030, loss = 0.0199031
I0526 10:19:58.182955 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0199033 (* 1 = 0.0199033 loss)
I0526 10:19:58.182960 15117 sgd_solver.cpp:294] Iteration 50030, lr = 0.0002
I0526 10:20:04.472944 15117 solver.cpp:233] Iteration 50040, loss = 0.0108265
I0526 10:20:04.472986 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0108267 (* 1 = 0.0108267 loss)
I0526 10:20:04.472993 15117 sgd_solver.cpp:294] Iteration 50040, lr = 0.0002
I0526 10:20:10.762804 15117 solver.cpp:233] Iteration 50050, loss = 0.0228281
I0526 10:20:10.762907 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0228283 (* 1 = 0.0228283 loss)
I0526 10:20:10.762915 15117 sgd_solver.cpp:294] Iteration 50050, lr = 0.0002
I0526 10:20:17.056154 15117 solver.cpp:233] Iteration 50060, loss = 0.00519456
I0526 10:20:17.056200 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00519479 (* 1 = 0.00519479 loss)
I0526 10:20:17.056208 15117 sgd_solver.cpp:294] Iteration 50060, lr = 0.0002
I0526 10:20:23.348656 15117 solver.cpp:233] Iteration 50070, loss = 0.00420614
I0526 10:20:23.348701 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00420638 (* 1 = 0.00420638 loss)
I0526 10:20:23.348708 15117 sgd_solver.cpp:294] Iteration 50070, lr = 0.0002
I0526 10:20:29.639158 15117 solver.cpp:233] Iteration 50080, loss = 0.00857378
I0526 10:20:29.639199 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00857402 (* 1 = 0.00857402 loss)
I0526 10:20:29.639206 15117 sgd_solver.cpp:294] Iteration 50080, lr = 0.0002
I0526 10:20:35.929267 15117 solver.cpp:233] Iteration 50090, loss = 0.00399241
I0526 10:20:35.929311 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00399264 (* 1 = 0.00399264 loss)
I0526 10:20:35.929318 15117 sgd_solver.cpp:294] Iteration 50090, lr = 0.0002
I0526 10:20:41.623896 15117 solver.cpp:342] Iteration 50100, Testing net (#0)
I0526 10:20:54.404961 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9063
I0526 10:20:54.405005 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.447644 (* 1 = 0.447644 loss)
I0526 10:20:55.001447 15117 solver.cpp:233] Iteration 50100, loss = 0.00489391
I0526 10:20:55.001488 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00489415 (* 1 = 0.00489415 loss)
I0526 10:20:55.001495 15117 sgd_solver.cpp:294] Iteration 50100, lr = 0.0002
I0526 10:21:01.285555 15117 solver.cpp:233] Iteration 50110, loss = 0.0093921
I0526 10:21:01.285593 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00939234 (* 1 = 0.00939234 loss)
I0526 10:21:01.285600 15117 sgd_solver.cpp:294] Iteration 50110, lr = 0.0002
I0526 10:21:07.570883 15117 solver.cpp:233] Iteration 50120, loss = 0.0208515
I0526 10:21:07.570929 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0208517 (* 1 = 0.0208517 loss)
I0526 10:21:07.570935 15117 sgd_solver.cpp:294] Iteration 50120, lr = 0.0002
I0526 10:21:13.863517 15117 solver.cpp:233] Iteration 50130, loss = 0.0224217
I0526 10:21:13.863777 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.022422 (* 1 = 0.022422 loss)
I0526 10:21:13.863803 15117 sgd_solver.cpp:294] Iteration 50130, lr = 0.0002
I0526 10:21:20.152145 15117 solver.cpp:233] Iteration 50140, loss = 0.0165538
I0526 10:21:20.152192 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0165541 (* 1 = 0.0165541 loss)
I0526 10:21:20.152199 15117 sgd_solver.cpp:294] Iteration 50140, lr = 0.0002
I0526 10:21:26.438887 15117 solver.cpp:233] Iteration 50150, loss = 0.00568666
I0526 10:21:26.438930 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0056869 (* 1 = 0.0056869 loss)
I0526 10:21:26.438937 15117 sgd_solver.cpp:294] Iteration 50150, lr = 0.0002
I0526 10:21:32.725054 15117 solver.cpp:233] Iteration 50160, loss = 0.00654855
I0526 10:21:32.725095 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00654879 (* 1 = 0.00654879 loss)
I0526 10:21:32.725102 15117 sgd_solver.cpp:294] Iteration 50160, lr = 0.0002
I0526 10:21:39.014730 15117 solver.cpp:233] Iteration 50170, loss = 0.00359041
I0526 10:21:39.014773 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00359065 (* 1 = 0.00359065 loss)
I0526 10:21:39.014780 15117 sgd_solver.cpp:294] Iteration 50170, lr = 0.0002
I0526 10:21:45.304314 15117 solver.cpp:233] Iteration 50180, loss = 0.0140164
I0526 10:21:45.304514 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0140167 (* 1 = 0.0140167 loss)
I0526 10:21:45.304539 15117 sgd_solver.cpp:294] Iteration 50180, lr = 0.0002
I0526 10:21:51.596334 15117 solver.cpp:233] Iteration 50190, loss = 0.015739
I0526 10:21:51.596380 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0157393 (* 1 = 0.0157393 loss)
I0526 10:21:51.596387 15117 sgd_solver.cpp:294] Iteration 50190, lr = 0.0002
I0526 10:21:57.288272 15117 solver.cpp:342] Iteration 50200, Testing net (#0)
I0526 10:22:10.075896 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9052
I0526 10:22:10.075942 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.454965 (* 1 = 0.454965 loss)
I0526 10:22:10.672817 15117 solver.cpp:233] Iteration 50200, loss = 0.0352494
I0526 10:22:10.672857 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0352496 (* 1 = 0.0352496 loss)
I0526 10:22:10.672863 15117 sgd_solver.cpp:294] Iteration 50200, lr = 0.0002
I0526 10:22:16.961797 15117 solver.cpp:233] Iteration 50210, loss = 0.0307001
I0526 10:22:16.962028 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0307003 (* 1 = 0.0307003 loss)
I0526 10:22:16.962056 15117 sgd_solver.cpp:294] Iteration 50210, lr = 0.0002
I0526 10:22:23.251904 15117 solver.cpp:233] Iteration 50220, loss = 0.0226314
I0526 10:22:23.251948 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0226316 (* 1 = 0.0226316 loss)
I0526 10:22:23.251955 15117 sgd_solver.cpp:294] Iteration 50220, lr = 0.0002
I0526 10:22:29.535513 15117 solver.cpp:233] Iteration 50230, loss = 0.00863113
I0526 10:22:29.535557 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00863137 (* 1 = 0.00863137 loss)
I0526 10:22:29.535562 15117 sgd_solver.cpp:294] Iteration 50230, lr = 0.0002
I0526 10:22:35.820760 15117 solver.cpp:233] Iteration 50240, loss = 0.0113267
I0526 10:22:35.820802 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.011327 (* 1 = 0.011327 loss)
I0526 10:22:35.820809 15117 sgd_solver.cpp:294] Iteration 50240, lr = 0.0002
I0526 10:22:42.110733 15117 solver.cpp:233] Iteration 50250, loss = 0.0110997
I0526 10:22:42.110776 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0110999 (* 1 = 0.0110999 loss)
I0526 10:22:42.110783 15117 sgd_solver.cpp:294] Iteration 50250, lr = 0.0002
I0526 10:22:48.399924 15117 solver.cpp:233] Iteration 50260, loss = 0.00802011
I0526 10:22:48.400188 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00802035 (* 1 = 0.00802035 loss)
I0526 10:22:48.400218 15117 sgd_solver.cpp:294] Iteration 50260, lr = 0.0002
I0526 10:22:54.689266 15117 solver.cpp:233] Iteration 50270, loss = 0.0121828
I0526 10:22:54.689312 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.012183 (* 1 = 0.012183 loss)
I0526 10:22:54.689319 15117 sgd_solver.cpp:294] Iteration 50270, lr = 0.0002
I0526 10:23:00.978178 15117 solver.cpp:233] Iteration 50280, loss = 0.0168584
I0526 10:23:00.978219 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0168586 (* 1 = 0.0168586 loss)
I0526 10:23:00.978226 15117 sgd_solver.cpp:294] Iteration 50280, lr = 0.0002
I0526 10:23:07.267069 15117 solver.cpp:233] Iteration 50290, loss = 0.0145724
I0526 10:23:07.267114 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0145727 (* 1 = 0.0145727 loss)
I0526 10:23:07.267132 15117 sgd_solver.cpp:294] Iteration 50290, lr = 0.0002
I0526 10:23:12.961571 15117 solver.cpp:342] Iteration 50300, Testing net (#0)
I0526 10:23:25.740417 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9053
I0526 10:23:25.740636 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.446872 (* 1 = 0.446872 loss)
I0526 10:23:26.337270 15117 solver.cpp:233] Iteration 50300, loss = 0.00675393
I0526 10:23:26.337311 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00675417 (* 1 = 0.00675417 loss)
I0526 10:23:26.337318 15117 sgd_solver.cpp:294] Iteration 50300, lr = 0.0002
I0526 10:23:32.623854 15117 solver.cpp:233] Iteration 50310, loss = 0.00738893
I0526 10:23:32.623898 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00738916 (* 1 = 0.00738916 loss)
I0526 10:23:32.623904 15117 sgd_solver.cpp:294] Iteration 50310, lr = 0.0002
I0526 10:23:38.908424 15117 solver.cpp:233] Iteration 50320, loss = 0.00684256
I0526 10:23:38.908466 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00684279 (* 1 = 0.00684279 loss)
I0526 10:23:38.908473 15117 sgd_solver.cpp:294] Iteration 50320, lr = 0.0002
I0526 10:23:45.191926 15117 solver.cpp:233] Iteration 50330, loss = 0.00410282
I0526 10:23:45.191967 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00410306 (* 1 = 0.00410306 loss)
I0526 10:23:45.191974 15117 sgd_solver.cpp:294] Iteration 50330, lr = 0.0002
I0526 10:23:51.482522 15117 solver.cpp:233] Iteration 50340, loss = 0.0186406
I0526 10:23:51.482563 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0186408 (* 1 = 0.0186408 loss)
I0526 10:23:51.482581 15117 sgd_solver.cpp:294] Iteration 50340, lr = 0.0002
I0526 10:23:57.771226 15117 solver.cpp:233] Iteration 50350, loss = 0.0164053
I0526 10:23:57.771428 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0164055 (* 1 = 0.0164055 loss)
I0526 10:23:57.771457 15117 sgd_solver.cpp:294] Iteration 50350, lr = 0.0002
I0526 10:24:04.057451 15117 solver.cpp:233] Iteration 50360, loss = 0.0027535
I0526 10:24:04.057498 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00275373 (* 1 = 0.00275373 loss)
I0526 10:24:04.057507 15117 sgd_solver.cpp:294] Iteration 50360, lr = 0.0002
I0526 10:24:10.341138 15117 solver.cpp:233] Iteration 50370, loss = 0.0115483
I0526 10:24:10.341177 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0115485 (* 1 = 0.0115485 loss)
I0526 10:24:10.341184 15117 sgd_solver.cpp:294] Iteration 50370, lr = 0.0002
I0526 10:24:16.628711 15117 solver.cpp:233] Iteration 50380, loss = 0.00684334
I0526 10:24:16.628752 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00684358 (* 1 = 0.00684358 loss)
I0526 10:24:16.628764 15117 sgd_solver.cpp:294] Iteration 50380, lr = 0.0002
I0526 10:24:22.915216 15117 solver.cpp:233] Iteration 50390, loss = 0.0117351
I0526 10:24:22.915257 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0117353 (* 1 = 0.0117353 loss)
I0526 10:24:22.915264 15117 sgd_solver.cpp:294] Iteration 50390, lr = 0.0002
I0526 10:24:28.606140 15117 solver.cpp:342] Iteration 50400, Testing net (#0)
I0526 10:24:41.390025 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.903
I0526 10:24:41.390074 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.450729 (* 1 = 0.450729 loss)
I0526 10:24:41.987140 15117 solver.cpp:233] Iteration 50400, loss = 0.0102682
I0526 10:24:41.987180 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0102684 (* 1 = 0.0102684 loss)
I0526 10:24:41.987187 15117 sgd_solver.cpp:294] Iteration 50400, lr = 0.0002
I0526 10:24:48.276659 15117 solver.cpp:233] Iteration 50410, loss = 0.00947491
I0526 10:24:48.276700 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00947515 (* 1 = 0.00947515 loss)
I0526 10:24:48.276705 15117 sgd_solver.cpp:294] Iteration 50410, lr = 0.0002
I0526 10:24:54.562549 15117 solver.cpp:233] Iteration 50420, loss = 0.0145282
I0526 10:24:54.562593 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0145285 (* 1 = 0.0145285 loss)
I0526 10:24:54.562600 15117 sgd_solver.cpp:294] Iteration 50420, lr = 0.0002
I0526 10:25:00.851239 15117 solver.cpp:233] Iteration 50430, loss = 0.0092301
I0526 10:25:00.851449 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00923034 (* 1 = 0.00923034 loss)
I0526 10:25:00.851476 15117 sgd_solver.cpp:294] Iteration 50430, lr = 0.0002
I0526 10:25:07.144147 15117 solver.cpp:233] Iteration 50440, loss = 0.00986636
I0526 10:25:07.144191 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0098666 (* 1 = 0.0098666 loss)
I0526 10:25:07.144198 15117 sgd_solver.cpp:294] Iteration 50440, lr = 0.0002
I0526 10:25:13.431071 15117 solver.cpp:233] Iteration 50450, loss = 0.00769917
I0526 10:25:13.431103 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0076994 (* 1 = 0.0076994 loss)
I0526 10:25:13.431112 15117 sgd_solver.cpp:294] Iteration 50450, lr = 0.0002
I0526 10:25:19.720156 15117 solver.cpp:233] Iteration 50460, loss = 0.0304162
I0526 10:25:19.720201 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0304164 (* 1 = 0.0304164 loss)
I0526 10:25:19.720207 15117 sgd_solver.cpp:294] Iteration 50460, lr = 0.0002
I0526 10:25:26.004889 15117 solver.cpp:233] Iteration 50470, loss = 0.044638
I0526 10:25:26.004928 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0446383 (* 1 = 0.0446383 loss)
I0526 10:25:26.004935 15117 sgd_solver.cpp:294] Iteration 50470, lr = 0.0002
I0526 10:25:32.292464 15117 solver.cpp:233] Iteration 50480, loss = 0.0128977
I0526 10:25:32.292668 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.012898 (* 1 = 0.012898 loss)
I0526 10:25:32.292695 15117 sgd_solver.cpp:294] Iteration 50480, lr = 0.0002
I0526 10:25:38.579993 15117 solver.cpp:233] Iteration 50490, loss = 0.00647556
I0526 10:25:38.580037 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00647579 (* 1 = 0.00647579 loss)
I0526 10:25:38.580044 15117 sgd_solver.cpp:294] Iteration 50490, lr = 0.0002
I0526 10:25:44.269989 15117 solver.cpp:342] Iteration 50500, Testing net (#0)
I0526 10:25:57.050150 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9063
I0526 10:25:57.050194 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.439704 (* 1 = 0.439704 loss)
I0526 10:25:57.646311 15117 solver.cpp:233] Iteration 50500, loss = 0.0300375
I0526 10:25:57.646352 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0300377 (* 1 = 0.0300377 loss)
I0526 10:25:57.646363 15117 sgd_solver.cpp:294] Iteration 50500, lr = 0.0002
I0526 10:26:03.934427 15117 solver.cpp:233] Iteration 50510, loss = 0.0144717
I0526 10:26:03.934705 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0144719 (* 1 = 0.0144719 loss)
I0526 10:26:03.934746 15117 sgd_solver.cpp:294] Iteration 50510, lr = 0.0002
I0526 10:26:10.226526 15117 solver.cpp:233] Iteration 50520, loss = 0.0256071
I0526 10:26:10.226567 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0256073 (* 1 = 0.0256073 loss)
I0526 10:26:10.226574 15117 sgd_solver.cpp:294] Iteration 50520, lr = 0.0002
I0526 10:26:16.516597 15117 solver.cpp:233] Iteration 50530, loss = 0.0104104
I0526 10:26:16.516633 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0104107 (* 1 = 0.0104107 loss)
I0526 10:26:16.516640 15117 sgd_solver.cpp:294] Iteration 50530, lr = 0.0002
I0526 10:26:22.806398 15117 solver.cpp:233] Iteration 50540, loss = 0.021688
I0526 10:26:22.806442 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0216883 (* 1 = 0.0216883 loss)
I0526 10:26:22.806449 15117 sgd_solver.cpp:294] Iteration 50540, lr = 0.0002
I0526 10:26:29.097471 15117 solver.cpp:233] Iteration 50550, loss = 0.00912328
I0526 10:26:29.097513 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00912351 (* 1 = 0.00912351 loss)
I0526 10:26:29.097519 15117 sgd_solver.cpp:294] Iteration 50550, lr = 0.0002
I0526 10:26:35.388664 15117 solver.cpp:233] Iteration 50560, loss = 0.00874007
I0526 10:26:35.388891 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00874031 (* 1 = 0.00874031 loss)
I0526 10:26:35.388919 15117 sgd_solver.cpp:294] Iteration 50560, lr = 0.0002
I0526 10:26:41.678391 15117 solver.cpp:233] Iteration 50570, loss = 0.0208787
I0526 10:26:41.678436 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0208789 (* 1 = 0.0208789 loss)
I0526 10:26:41.678444 15117 sgd_solver.cpp:294] Iteration 50570, lr = 0.0002
I0526 10:26:47.965205 15117 solver.cpp:233] Iteration 50580, loss = 0.00913819
I0526 10:26:47.965247 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00913842 (* 1 = 0.00913842 loss)
I0526 10:26:47.965255 15117 sgd_solver.cpp:294] Iteration 50580, lr = 0.0002
I0526 10:26:54.255112 15117 solver.cpp:233] Iteration 50590, loss = 0.0179214
I0526 10:26:54.255156 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0179217 (* 1 = 0.0179217 loss)
I0526 10:26:54.255162 15117 sgd_solver.cpp:294] Iteration 50590, lr = 0.0002
I0526 10:26:59.945766 15117 solver.cpp:342] Iteration 50600, Testing net (#0)
I0526 10:27:12.734982 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9038
I0526 10:27:12.735208 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.455128 (* 1 = 0.455128 loss)
I0526 10:27:13.332849 15117 solver.cpp:233] Iteration 50600, loss = 0.0165509
I0526 10:27:13.332908 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0165511 (* 1 = 0.0165511 loss)
I0526 10:27:13.332919 15117 sgd_solver.cpp:294] Iteration 50600, lr = 0.0002
I0526 10:27:19.625115 15117 solver.cpp:233] Iteration 50610, loss = 0.0074093
I0526 10:27:19.625157 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00740954 (* 1 = 0.00740954 loss)
I0526 10:27:19.625164 15117 sgd_solver.cpp:294] Iteration 50610, lr = 0.0002
I0526 10:27:25.916568 15117 solver.cpp:233] Iteration 50620, loss = 0.00236688
I0526 10:27:25.916595 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00236711 (* 1 = 0.00236711 loss)
I0526 10:27:25.916604 15117 sgd_solver.cpp:294] Iteration 50620, lr = 0.0002
I0526 10:27:32.205041 15117 solver.cpp:233] Iteration 50630, loss = 0.00624401
I0526 10:27:32.205081 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00624424 (* 1 = 0.00624424 loss)
I0526 10:27:32.205088 15117 sgd_solver.cpp:294] Iteration 50630, lr = 0.0002
I0526 10:27:38.495556 15117 solver.cpp:233] Iteration 50640, loss = 0.00374029
I0526 10:27:38.495599 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00374052 (* 1 = 0.00374052 loss)
I0526 10:27:38.495606 15117 sgd_solver.cpp:294] Iteration 50640, lr = 0.0002
I0526 10:27:44.779222 15117 solver.cpp:233] Iteration 50650, loss = 0.0164339
I0526 10:27:44.779508 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0164342 (* 1 = 0.0164342 loss)
I0526 10:27:44.779539 15117 sgd_solver.cpp:294] Iteration 50650, lr = 0.0002
I0526 10:27:51.068671 15117 solver.cpp:233] Iteration 50660, loss = 0.00578674
I0526 10:27:51.068720 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00578697 (* 1 = 0.00578697 loss)
I0526 10:27:51.068728 15117 sgd_solver.cpp:294] Iteration 50660, lr = 0.0002
I0526 10:27:57.356778 15117 solver.cpp:233] Iteration 50670, loss = 0.00571367
I0526 10:27:57.356827 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0057139 (* 1 = 0.0057139 loss)
I0526 10:27:57.356833 15117 sgd_solver.cpp:294] Iteration 50670, lr = 0.0002
I0526 10:28:03.648427 15117 solver.cpp:233] Iteration 50680, loss = 0.00298995
I0526 10:28:03.648473 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00299018 (* 1 = 0.00299018 loss)
I0526 10:28:03.648480 15117 sgd_solver.cpp:294] Iteration 50680, lr = 0.0002
I0526 10:28:09.936554 15117 solver.cpp:233] Iteration 50690, loss = 0.0124154
I0526 10:28:09.936583 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0124156 (* 1 = 0.0124156 loss)
I0526 10:28:09.936589 15117 sgd_solver.cpp:294] Iteration 50690, lr = 0.0002
I0526 10:28:15.628531 15117 solver.cpp:342] Iteration 50700, Testing net (#0)
I0526 10:28:28.430145 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9067
I0526 10:28:28.430192 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.43835 (* 1 = 0.43835 loss)
I0526 10:28:29.027580 15117 solver.cpp:233] Iteration 50700, loss = 0.0240856
I0526 10:28:29.027612 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0240858 (* 1 = 0.0240858 loss)
I0526 10:28:29.027619 15117 sgd_solver.cpp:294] Iteration 50700, lr = 0.0002
I0526 10:28:35.316377 15117 solver.cpp:233] Iteration 50710, loss = 0.0203675
I0526 10:28:35.316419 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0203677 (* 1 = 0.0203677 loss)
I0526 10:28:35.316426 15117 sgd_solver.cpp:294] Iteration 50710, lr = 0.0002
I0526 10:28:41.604338 15117 solver.cpp:233] Iteration 50720, loss = 0.00563958
I0526 10:28:41.604390 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00563981 (* 1 = 0.00563981 loss)
I0526 10:28:41.604398 15117 sgd_solver.cpp:294] Iteration 50720, lr = 0.0002
I0526 10:28:47.890425 15117 solver.cpp:233] Iteration 50730, loss = 0.00394399
I0526 10:28:47.890640 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00394422 (* 1 = 0.00394422 loss)
I0526 10:28:47.890671 15117 sgd_solver.cpp:294] Iteration 50730, lr = 0.0002
I0526 10:28:54.184289 15117 solver.cpp:233] Iteration 50740, loss = 0.00897084
I0526 10:28:54.184334 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00897107 (* 1 = 0.00897107 loss)
I0526 10:28:54.184342 15117 sgd_solver.cpp:294] Iteration 50740, lr = 0.0002
I0526 10:29:00.474858 15117 solver.cpp:233] Iteration 50750, loss = 0.0150793
I0526 10:29:00.474900 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0150796 (* 1 = 0.0150796 loss)
I0526 10:29:00.474907 15117 sgd_solver.cpp:294] Iteration 50750, lr = 0.0002
I0526 10:29:06.765974 15117 solver.cpp:233] Iteration 50760, loss = 0.00527122
I0526 10:29:06.766007 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00527145 (* 1 = 0.00527145 loss)
I0526 10:29:06.766015 15117 sgd_solver.cpp:294] Iteration 50760, lr = 0.0002
I0526 10:29:13.056260 15117 solver.cpp:233] Iteration 50770, loss = 0.00981233
I0526 10:29:13.056303 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00981255 (* 1 = 0.00981255 loss)
I0526 10:29:13.056309 15117 sgd_solver.cpp:294] Iteration 50770, lr = 0.0002
I0526 10:29:19.342622 15117 solver.cpp:233] Iteration 50780, loss = 0.00863707
I0526 10:29:19.342842 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0086373 (* 1 = 0.0086373 loss)
I0526 10:29:19.342867 15117 sgd_solver.cpp:294] Iteration 50780, lr = 0.0002
I0526 10:29:25.632956 15117 solver.cpp:233] Iteration 50790, loss = 0.00465884
I0526 10:29:25.632998 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00465907 (* 1 = 0.00465907 loss)
I0526 10:29:25.633004 15117 sgd_solver.cpp:294] Iteration 50790, lr = 0.0002
I0526 10:29:31.323607 15117 solver.cpp:342] Iteration 50800, Testing net (#0)
I0526 10:29:44.109323 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9065
I0526 10:29:44.109369 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.452029 (* 1 = 0.452029 loss)
I0526 10:29:44.706118 15117 solver.cpp:233] Iteration 50800, loss = 0.0153759
I0526 10:29:44.706159 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0153761 (* 1 = 0.0153761 loss)
I0526 10:29:44.706166 15117 sgd_solver.cpp:294] Iteration 50800, lr = 0.0002
I0526 10:29:50.994864 15117 solver.cpp:233] Iteration 50810, loss = 0.00974053
I0526 10:29:50.995015 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00974075 (* 1 = 0.00974075 loss)
I0526 10:29:50.995024 15117 sgd_solver.cpp:294] Iteration 50810, lr = 0.0002
I0526 10:29:57.280155 15117 solver.cpp:233] Iteration 50820, loss = 0.0270038
I0526 10:29:57.280195 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0270041 (* 1 = 0.0270041 loss)
I0526 10:29:57.280202 15117 sgd_solver.cpp:294] Iteration 50820, lr = 0.0002
I0526 10:30:03.571069 15117 solver.cpp:233] Iteration 50830, loss = 0.00568258
I0526 10:30:03.571113 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0056828 (* 1 = 0.0056828 loss)
I0526 10:30:03.571120 15117 sgd_solver.cpp:294] Iteration 50830, lr = 0.0002
I0526 10:30:09.862038 15117 solver.cpp:233] Iteration 50840, loss = 0.00995864
I0526 10:30:09.862078 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00995887 (* 1 = 0.00995887 loss)
I0526 10:30:09.862085 15117 sgd_solver.cpp:294] Iteration 50840, lr = 0.0002
I0526 10:30:16.149852 15117 solver.cpp:233] Iteration 50850, loss = 0.00965199
I0526 10:30:16.149893 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00965221 (* 1 = 0.00965221 loss)
I0526 10:30:16.149899 15117 sgd_solver.cpp:294] Iteration 50850, lr = 0.0002
I0526 10:30:22.437996 15117 solver.cpp:233] Iteration 50860, loss = 0.0289028
I0526 10:30:22.438237 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0289031 (* 1 = 0.0289031 loss)
I0526 10:30:22.438267 15117 sgd_solver.cpp:294] Iteration 50860, lr = 0.0002
I0526 10:30:28.728102 15117 solver.cpp:233] Iteration 50870, loss = 0.0090397
I0526 10:30:28.728145 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00903992 (* 1 = 0.00903992 loss)
I0526 10:30:28.728152 15117 sgd_solver.cpp:294] Iteration 50870, lr = 0.0002
I0526 10:30:35.019553 15117 solver.cpp:233] Iteration 50880, loss = 0.00514274
I0526 10:30:35.019598 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00514296 (* 1 = 0.00514296 loss)
I0526 10:30:35.019603 15117 sgd_solver.cpp:294] Iteration 50880, lr = 0.0002
I0526 10:30:41.310402 15117 solver.cpp:233] Iteration 50890, loss = 0.00652634
I0526 10:30:41.310444 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00652656 (* 1 = 0.00652656 loss)
I0526 10:30:41.310451 15117 sgd_solver.cpp:294] Iteration 50890, lr = 0.0002
I0526 10:30:47.000768 15117 solver.cpp:342] Iteration 50900, Testing net (#0)
I0526 10:30:59.781335 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9045
I0526 10:30:59.781543 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.4541 (* 1 = 0.4541 loss)
I0526 10:31:00.379945 15117 solver.cpp:233] Iteration 50900, loss = 0.00476218
I0526 10:31:00.379992 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0047624 (* 1 = 0.0047624 loss)
I0526 10:31:00.380002 15117 sgd_solver.cpp:294] Iteration 50900, lr = 0.0002
I0526 10:31:06.668612 15117 solver.cpp:233] Iteration 50910, loss = 0.00946022
I0526 10:31:06.668654 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00946044 (* 1 = 0.00946044 loss)
I0526 10:31:06.668668 15117 sgd_solver.cpp:294] Iteration 50910, lr = 0.0002
I0526 10:31:12.957219 15117 solver.cpp:233] Iteration 50920, loss = 0.0185437
I0526 10:31:12.957260 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0185439 (* 1 = 0.0185439 loss)
I0526 10:31:12.957267 15117 sgd_solver.cpp:294] Iteration 50920, lr = 0.0002
I0526 10:31:19.245002 15117 solver.cpp:233] Iteration 50930, loss = 0.00696014
I0526 10:31:19.245038 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00696036 (* 1 = 0.00696036 loss)
I0526 10:31:19.245044 15117 sgd_solver.cpp:294] Iteration 50930, lr = 0.0002
I0526 10:31:25.532982 15117 solver.cpp:233] Iteration 50940, loss = 0.00654875
I0526 10:31:25.533023 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00654896 (* 1 = 0.00654896 loss)
I0526 10:31:25.533030 15117 sgd_solver.cpp:294] Iteration 50940, lr = 0.0002
I0526 10:31:31.821142 15117 solver.cpp:233] Iteration 50950, loss = 0.00530136
I0526 10:31:31.821316 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00530158 (* 1 = 0.00530158 loss)
I0526 10:31:31.821326 15117 sgd_solver.cpp:294] Iteration 50950, lr = 0.0002
I0526 10:31:38.110178 15117 solver.cpp:233] Iteration 50960, loss = 0.0188771
I0526 10:31:38.110220 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0188773 (* 1 = 0.0188773 loss)
I0526 10:31:38.110227 15117 sgd_solver.cpp:294] Iteration 50960, lr = 0.0002
I0526 10:31:44.398928 15117 solver.cpp:233] Iteration 50970, loss = 0.00518877
I0526 10:31:44.398969 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00518899 (* 1 = 0.00518899 loss)
I0526 10:31:44.398975 15117 sgd_solver.cpp:294] Iteration 50970, lr = 0.0002
I0526 10:31:50.692971 15117 solver.cpp:233] Iteration 50980, loss = 0.00975381
I0526 10:31:50.693011 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00975402 (* 1 = 0.00975402 loss)
I0526 10:31:50.693017 15117 sgd_solver.cpp:294] Iteration 50980, lr = 0.0002
I0526 10:31:56.982403 15117 solver.cpp:233] Iteration 50990, loss = 0.00738861
I0526 10:31:56.982445 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00738883 (* 1 = 0.00738883 loss)
I0526 10:31:56.982452 15117 sgd_solver.cpp:294] Iteration 50990, lr = 0.0002
I0526 10:32:02.671850 15117 solver.cpp:342] Iteration 51000, Testing net (#0)
I0526 10:32:15.458055 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9052
I0526 10:32:15.458099 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.442333 (* 1 = 0.442333 loss)
I0526 10:32:16.055177 15117 solver.cpp:233] Iteration 51000, loss = 0.0234593
I0526 10:32:16.055214 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0234595 (* 1 = 0.0234595 loss)
I0526 10:32:16.055222 15117 sgd_solver.cpp:294] Iteration 51000, lr = 0.0002
I0526 10:32:22.344759 15117 solver.cpp:233] Iteration 51010, loss = 0.0028455
I0526 10:32:22.344801 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00284571 (* 1 = 0.00284571 loss)
I0526 10:32:22.344807 15117 sgd_solver.cpp:294] Iteration 51010, lr = 0.0002
I0526 10:32:28.632872 15117 solver.cpp:233] Iteration 51020, loss = 0.0142455
I0526 10:32:28.632912 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0142457 (* 1 = 0.0142457 loss)
I0526 10:32:28.632920 15117 sgd_solver.cpp:294] Iteration 51020, lr = 0.0002
I0526 10:32:34.922235 15117 solver.cpp:233] Iteration 51030, loss = 0.019862
I0526 10:32:34.922462 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0198622 (* 1 = 0.0198622 loss)
I0526 10:32:34.922492 15117 sgd_solver.cpp:294] Iteration 51030, lr = 0.0002
I0526 10:32:41.215795 15117 solver.cpp:233] Iteration 51040, loss = 0.0353943
I0526 10:32:41.215838 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0353946 (* 1 = 0.0353946 loss)
I0526 10:32:41.215845 15117 sgd_solver.cpp:294] Iteration 51040, lr = 0.0002
I0526 10:32:47.504416 15117 solver.cpp:233] Iteration 51050, loss = 0.00828278
I0526 10:32:47.504473 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.008283 (* 1 = 0.008283 loss)
I0526 10:32:47.504485 15117 sgd_solver.cpp:294] Iteration 51050, lr = 0.0002
I0526 10:32:53.794473 15117 solver.cpp:233] Iteration 51060, loss = 0.0396768
I0526 10:32:53.794517 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0396771 (* 1 = 0.0396771 loss)
I0526 10:32:53.794523 15117 sgd_solver.cpp:294] Iteration 51060, lr = 0.0002
I0526 10:33:00.083900 15117 solver.cpp:233] Iteration 51070, loss = 0.0080003
I0526 10:33:00.083946 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00800052 (* 1 = 0.00800052 loss)
I0526 10:33:00.083953 15117 sgd_solver.cpp:294] Iteration 51070, lr = 0.0002
I0526 10:33:06.371433 15117 solver.cpp:233] Iteration 51080, loss = 0.00370219
I0526 10:33:06.371690 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00370241 (* 1 = 0.00370241 loss)
I0526 10:33:06.371721 15117 sgd_solver.cpp:294] Iteration 51080, lr = 0.0002
I0526 10:33:12.657253 15117 solver.cpp:233] Iteration 51090, loss = 0.00658219
I0526 10:33:12.657294 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0065824 (* 1 = 0.0065824 loss)
I0526 10:33:12.657301 15117 sgd_solver.cpp:294] Iteration 51090, lr = 0.0002
I0526 10:33:18.350045 15117 solver.cpp:342] Iteration 51100, Testing net (#0)
I0526 10:33:31.128373 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9068
I0526 10:33:31.128417 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.441538 (* 1 = 0.441538 loss)
I0526 10:33:31.724491 15117 solver.cpp:233] Iteration 51100, loss = 0.00473423
I0526 10:33:31.724525 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00473445 (* 1 = 0.00473445 loss)
I0526 10:33:31.724532 15117 sgd_solver.cpp:294] Iteration 51100, lr = 0.0002
I0526 10:33:38.012109 15117 solver.cpp:233] Iteration 51110, loss = 0.00443596
I0526 10:33:38.012354 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00443618 (* 1 = 0.00443618 loss)
I0526 10:33:38.012382 15117 sgd_solver.cpp:294] Iteration 51110, lr = 0.0002
I0526 10:33:44.304848 15117 solver.cpp:233] Iteration 51120, loss = 0.0140899
I0526 10:33:44.304891 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0140901 (* 1 = 0.0140901 loss)
I0526 10:33:44.304898 15117 sgd_solver.cpp:294] Iteration 51120, lr = 0.0002
I0526 10:33:50.595454 15117 solver.cpp:233] Iteration 51130, loss = 0.00551455
I0526 10:33:50.595494 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00551477 (* 1 = 0.00551477 loss)
I0526 10:33:50.595501 15117 sgd_solver.cpp:294] Iteration 51130, lr = 0.0002
I0526 10:33:56.882591 15117 solver.cpp:233] Iteration 51140, loss = 0.0440579
I0526 10:33:56.882624 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0440581 (* 1 = 0.0440581 loss)
I0526 10:33:56.882632 15117 sgd_solver.cpp:294] Iteration 51140, lr = 0.0002
I0526 10:34:03.171854 15117 solver.cpp:233] Iteration 51150, loss = 0.00414617
I0526 10:34:03.171898 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00414639 (* 1 = 0.00414639 loss)
I0526 10:34:03.171905 15117 sgd_solver.cpp:294] Iteration 51150, lr = 0.0002
I0526 10:34:09.458894 15117 solver.cpp:233] Iteration 51160, loss = 0.00552072
I0526 10:34:09.459116 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00552094 (* 1 = 0.00552094 loss)
I0526 10:34:09.459146 15117 sgd_solver.cpp:294] Iteration 51160, lr = 0.0002
I0526 10:34:15.745741 15117 solver.cpp:233] Iteration 51170, loss = 0.0110889
I0526 10:34:15.745784 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0110891 (* 1 = 0.0110891 loss)
I0526 10:34:15.745790 15117 sgd_solver.cpp:294] Iteration 51170, lr = 0.0002
I0526 10:34:22.032068 15117 solver.cpp:233] Iteration 51180, loss = 0.0463676
I0526 10:34:22.032109 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0463678 (* 1 = 0.0463678 loss)
I0526 10:34:22.032115 15117 sgd_solver.cpp:294] Iteration 51180, lr = 0.0002
I0526 10:34:28.317488 15117 solver.cpp:233] Iteration 51190, loss = 0.00669329
I0526 10:34:28.317535 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00669351 (* 1 = 0.00669351 loss)
I0526 10:34:28.317541 15117 sgd_solver.cpp:294] Iteration 51190, lr = 0.0002
I0526 10:34:34.008086 15117 solver.cpp:342] Iteration 51200, Testing net (#0)
I0526 10:34:46.786617 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9039
I0526 10:34:46.786809 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.452211 (* 1 = 0.452211 loss)
I0526 10:34:47.384297 15117 solver.cpp:233] Iteration 51200, loss = 0.0290074
I0526 10:34:47.384330 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0290077 (* 1 = 0.0290077 loss)
I0526 10:34:47.384336 15117 sgd_solver.cpp:294] Iteration 51200, lr = 0.0002
I0526 10:34:53.673678 15117 solver.cpp:233] Iteration 51210, loss = 0.0109237
I0526 10:34:53.673718 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0109239 (* 1 = 0.0109239 loss)
I0526 10:34:53.673724 15117 sgd_solver.cpp:294] Iteration 51210, lr = 0.0002
I0526 10:34:59.963125 15117 solver.cpp:233] Iteration 51220, loss = 0.00325556
I0526 10:34:59.963167 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00325578 (* 1 = 0.00325578 loss)
I0526 10:34:59.963173 15117 sgd_solver.cpp:294] Iteration 51220, lr = 0.0002
I0526 10:35:06.248982 15117 solver.cpp:233] Iteration 51230, loss = 0.00524713
I0526 10:35:06.249022 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00524735 (* 1 = 0.00524735 loss)
I0526 10:35:06.249029 15117 sgd_solver.cpp:294] Iteration 51230, lr = 0.0002
I0526 10:35:12.533366 15117 solver.cpp:233] Iteration 51240, loss = 0.010519
I0526 10:35:12.533407 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0105192 (* 1 = 0.0105192 loss)
I0526 10:35:12.533414 15117 sgd_solver.cpp:294] Iteration 51240, lr = 0.0002
I0526 10:35:18.821058 15117 solver.cpp:233] Iteration 51250, loss = 0.0139761
I0526 10:35:18.821280 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0139764 (* 1 = 0.0139764 loss)
I0526 10:35:18.821318 15117 sgd_solver.cpp:294] Iteration 51250, lr = 0.0002
I0526 10:35:25.113505 15117 solver.cpp:233] Iteration 51260, loss = 0.00605049
I0526 10:35:25.113548 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00605071 (* 1 = 0.00605071 loss)
I0526 10:35:25.113554 15117 sgd_solver.cpp:294] Iteration 51260, lr = 0.0002
I0526 10:35:31.402195 15117 solver.cpp:233] Iteration 51270, loss = 0.00498718
I0526 10:35:31.402240 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00498741 (* 1 = 0.00498741 loss)
I0526 10:35:31.402246 15117 sgd_solver.cpp:294] Iteration 51270, lr = 0.0002
I0526 10:35:37.690721 15117 solver.cpp:233] Iteration 51280, loss = 0.00642969
I0526 10:35:37.690760 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00642991 (* 1 = 0.00642991 loss)
I0526 10:35:37.690768 15117 sgd_solver.cpp:294] Iteration 51280, lr = 0.0002
I0526 10:35:43.980850 15117 solver.cpp:233] Iteration 51290, loss = 0.0128601
I0526 10:35:43.980897 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0128603 (* 1 = 0.0128603 loss)
I0526 10:35:43.980904 15117 sgd_solver.cpp:294] Iteration 51290, lr = 0.0002
I0526 10:35:49.674687 15117 solver.cpp:342] Iteration 51300, Testing net (#0)
I0526 10:36:02.462008 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9034
I0526 10:36:02.462056 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.453856 (* 1 = 0.453856 loss)
I0526 10:36:03.058039 15117 solver.cpp:233] Iteration 51300, loss = 0.0126412
I0526 10:36:03.058079 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0126414 (* 1 = 0.0126414 loss)
I0526 10:36:03.058085 15117 sgd_solver.cpp:294] Iteration 51300, lr = 0.0002
I0526 10:36:09.345109 15117 solver.cpp:233] Iteration 51310, loss = 0.00376667
I0526 10:36:09.345151 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00376689 (* 1 = 0.00376689 loss)
I0526 10:36:09.345158 15117 sgd_solver.cpp:294] Iteration 51310, lr = 0.0002
I0526 10:36:15.631747 15117 solver.cpp:233] Iteration 51320, loss = 0.00559609
I0526 10:36:15.631793 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00559632 (* 1 = 0.00559632 loss)
I0526 10:36:15.631811 15117 sgd_solver.cpp:294] Iteration 51320, lr = 0.0002
I0526 10:36:21.916422 15117 solver.cpp:233] Iteration 51330, loss = 0.00400088
I0526 10:36:21.916631 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00400111 (* 1 = 0.00400111 loss)
I0526 10:36:21.916659 15117 sgd_solver.cpp:294] Iteration 51330, lr = 0.0002
I0526 10:36:28.211603 15117 solver.cpp:233] Iteration 51340, loss = 0.0185336
I0526 10:36:28.211657 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0185339 (* 1 = 0.0185339 loss)
I0526 10:36:28.211663 15117 sgd_solver.cpp:294] Iteration 51340, lr = 0.0002
I0526 10:36:34.505298 15117 solver.cpp:233] Iteration 51350, loss = 0.0237806
I0526 10:36:34.505345 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0237808 (* 1 = 0.0237808 loss)
I0526 10:36:34.505353 15117 sgd_solver.cpp:294] Iteration 51350, lr = 0.0002
I0526 10:36:40.795704 15117 solver.cpp:233] Iteration 51360, loss = 0.0134818
I0526 10:36:40.795747 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.013482 (* 1 = 0.013482 loss)
I0526 10:36:40.795753 15117 sgd_solver.cpp:294] Iteration 51360, lr = 0.0002
I0526 10:36:47.082285 15117 solver.cpp:233] Iteration 51370, loss = 0.00750053
I0526 10:36:47.082314 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00750075 (* 1 = 0.00750075 loss)
I0526 10:36:47.082320 15117 sgd_solver.cpp:294] Iteration 51370, lr = 0.0002
I0526 10:36:53.371738 15117 solver.cpp:233] Iteration 51380, loss = 0.00631266
I0526 10:36:53.371958 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00631288 (* 1 = 0.00631288 loss)
I0526 10:36:53.371986 15117 sgd_solver.cpp:294] Iteration 51380, lr = 0.0002
I0526 10:36:59.662304 15117 solver.cpp:233] Iteration 51390, loss = 0.00465563
I0526 10:36:59.662349 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00465585 (* 1 = 0.00465585 loss)
I0526 10:36:59.662372 15117 sgd_solver.cpp:294] Iteration 51390, lr = 0.0002
I0526 10:37:05.356561 15117 solver.cpp:342] Iteration 51400, Testing net (#0)
I0526 10:37:18.139415 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9066
I0526 10:37:18.139461 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.438825 (* 1 = 0.438825 loss)
I0526 10:37:18.735846 15117 solver.cpp:233] Iteration 51400, loss = 0.0222877
I0526 10:37:18.735888 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0222879 (* 1 = 0.0222879 loss)
I0526 10:37:18.735894 15117 sgd_solver.cpp:294] Iteration 51400, lr = 0.0002
I0526 10:37:25.024348 15117 solver.cpp:233] Iteration 51410, loss = 0.00948725
I0526 10:37:25.024557 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00948747 (* 1 = 0.00948747 loss)
I0526 10:37:25.024587 15117 sgd_solver.cpp:294] Iteration 51410, lr = 0.0002
I0526 10:37:31.318794 15117 solver.cpp:233] Iteration 51420, loss = 0.0143108
I0526 10:37:31.318837 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.014311 (* 1 = 0.014311 loss)
I0526 10:37:31.318845 15117 sgd_solver.cpp:294] Iteration 51420, lr = 0.0002
I0526 10:37:37.608986 15117 solver.cpp:233] Iteration 51430, loss = 0.0160329
I0526 10:37:37.609030 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0160331 (* 1 = 0.0160331 loss)
I0526 10:37:37.609036 15117 sgd_solver.cpp:294] Iteration 51430, lr = 0.0002
I0526 10:37:43.903187 15117 solver.cpp:233] Iteration 51440, loss = 0.0108826
I0526 10:37:43.903234 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0108828 (* 1 = 0.0108828 loss)
I0526 10:37:43.903241 15117 sgd_solver.cpp:294] Iteration 51440, lr = 0.0002
I0526 10:37:50.193366 15117 solver.cpp:233] Iteration 51450, loss = 0.00794123
I0526 10:37:50.193408 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00794145 (* 1 = 0.00794145 loss)
I0526 10:37:50.193419 15117 sgd_solver.cpp:294] Iteration 51450, lr = 0.0002
I0526 10:37:56.485859 15117 solver.cpp:233] Iteration 51460, loss = 0.00829576
I0526 10:37:56.486104 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00829598 (* 1 = 0.00829598 loss)
I0526 10:37:56.486132 15117 sgd_solver.cpp:294] Iteration 51460, lr = 0.0002
I0526 10:38:02.780174 15117 solver.cpp:233] Iteration 51470, loss = 0.0203734
I0526 10:38:02.780218 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0203736 (* 1 = 0.0203736 loss)
I0526 10:38:02.780225 15117 sgd_solver.cpp:294] Iteration 51470, lr = 0.0002
I0526 10:38:09.068140 15117 solver.cpp:233] Iteration 51480, loss = 0.00585116
I0526 10:38:09.068181 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00585138 (* 1 = 0.00585138 loss)
I0526 10:38:09.068188 15117 sgd_solver.cpp:294] Iteration 51480, lr = 0.0002
I0526 10:38:15.361258 15117 solver.cpp:233] Iteration 51490, loss = 0.00583209
I0526 10:38:15.361301 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00583231 (* 1 = 0.00583231 loss)
I0526 10:38:15.361307 15117 sgd_solver.cpp:294] Iteration 51490, lr = 0.0002
I0526 10:38:21.053347 15117 solver.cpp:342] Iteration 51500, Testing net (#0)
I0526 10:38:33.827883 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9061
I0526 10:38:33.828022 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.447392 (* 1 = 0.447392 loss)
I0526 10:38:34.423810 15117 solver.cpp:233] Iteration 51500, loss = 0.00833436
I0526 10:38:34.423843 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00833458 (* 1 = 0.00833458 loss)
I0526 10:38:34.423851 15117 sgd_solver.cpp:294] Iteration 51500, lr = 0.0002
I0526 10:38:40.713218 15117 solver.cpp:233] Iteration 51510, loss = 0.0105493
I0526 10:38:40.713259 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0105495 (* 1 = 0.0105495 loss)
I0526 10:38:40.713265 15117 sgd_solver.cpp:294] Iteration 51510, lr = 0.0002
I0526 10:38:47.004971 15117 solver.cpp:233] Iteration 51520, loss = 0.00844851
I0526 10:38:47.005017 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00844873 (* 1 = 0.00844873 loss)
I0526 10:38:47.005023 15117 sgd_solver.cpp:294] Iteration 51520, lr = 0.0002
I0526 10:38:53.296161 15117 solver.cpp:233] Iteration 51530, loss = 0.00906412
I0526 10:38:53.296203 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00906434 (* 1 = 0.00906434 loss)
I0526 10:38:53.296211 15117 sgd_solver.cpp:294] Iteration 51530, lr = 0.0002
I0526 10:38:59.587554 15117 solver.cpp:233] Iteration 51540, loss = 0.0143908
I0526 10:38:59.587606 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0143911 (* 1 = 0.0143911 loss)
I0526 10:38:59.587613 15117 sgd_solver.cpp:294] Iteration 51540, lr = 0.0002
I0526 10:39:05.874788 15117 solver.cpp:233] Iteration 51550, loss = 0.00335818
I0526 10:39:05.874987 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0033584 (* 1 = 0.0033584 loss)
I0526 10:39:05.875015 15117 sgd_solver.cpp:294] Iteration 51550, lr = 0.0002
I0526 10:39:12.166265 15117 solver.cpp:233] Iteration 51560, loss = 0.0351827
I0526 10:39:12.166313 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.035183 (* 1 = 0.035183 loss)
I0526 10:39:12.166321 15117 sgd_solver.cpp:294] Iteration 51560, lr = 0.0002
I0526 10:39:18.455575 15117 solver.cpp:233] Iteration 51570, loss = 0.0118607
I0526 10:39:18.455618 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.011861 (* 1 = 0.011861 loss)
I0526 10:39:18.455624 15117 sgd_solver.cpp:294] Iteration 51570, lr = 0.0002
I0526 10:39:24.744616 15117 solver.cpp:233] Iteration 51580, loss = 0.00338493
I0526 10:39:24.744663 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00338515 (* 1 = 0.00338515 loss)
I0526 10:39:24.744669 15117 sgd_solver.cpp:294] Iteration 51580, lr = 0.0002
I0526 10:39:31.032609 15117 solver.cpp:233] Iteration 51590, loss = 0.0102277
I0526 10:39:31.032660 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0102279 (* 1 = 0.0102279 loss)
I0526 10:39:31.032667 15117 sgd_solver.cpp:294] Iteration 51590, lr = 0.0002
I0526 10:39:36.726850 15117 solver.cpp:342] Iteration 51600, Testing net (#0)
I0526 10:39:49.512758 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9039
I0526 10:39:49.512806 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.443054 (* 1 = 0.443054 loss)
I0526 10:39:50.109426 15117 solver.cpp:233] Iteration 51600, loss = 0.0093031
I0526 10:39:50.109467 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00930332 (* 1 = 0.00930332 loss)
I0526 10:39:50.109475 15117 sgd_solver.cpp:294] Iteration 51600, lr = 0.0002
I0526 10:39:56.400300 15117 solver.cpp:233] Iteration 51610, loss = 0.0143094
I0526 10:39:56.400342 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0143096 (* 1 = 0.0143096 loss)
I0526 10:39:56.400348 15117 sgd_solver.cpp:294] Iteration 51610, lr = 0.0002
I0526 10:40:02.691212 15117 solver.cpp:233] Iteration 51620, loss = 0.00808279
I0526 10:40:02.691256 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00808301 (* 1 = 0.00808301 loss)
I0526 10:40:02.691262 15117 sgd_solver.cpp:294] Iteration 51620, lr = 0.0002
I0526 10:40:08.982275 15117 solver.cpp:233] Iteration 51630, loss = 0.011977
I0526 10:40:08.982414 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0119772 (* 1 = 0.0119772 loss)
I0526 10:40:08.982421 15117 sgd_solver.cpp:294] Iteration 51630, lr = 0.0002
I0526 10:40:15.271041 15117 solver.cpp:233] Iteration 51640, loss = 0.00481942
I0526 10:40:15.271085 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00481965 (* 1 = 0.00481965 loss)
I0526 10:40:15.271091 15117 sgd_solver.cpp:294] Iteration 51640, lr = 0.0002
I0526 10:40:21.562623 15117 solver.cpp:233] Iteration 51650, loss = 0.00843275
I0526 10:40:21.562665 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00843298 (* 1 = 0.00843298 loss)
I0526 10:40:21.562671 15117 sgd_solver.cpp:294] Iteration 51650, lr = 0.0002
I0526 10:40:27.850564 15117 solver.cpp:233] Iteration 51660, loss = 0.0118314
I0526 10:40:27.850610 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0118316 (* 1 = 0.0118316 loss)
I0526 10:40:27.850617 15117 sgd_solver.cpp:294] Iteration 51660, lr = 0.0002
I0526 10:40:34.135061 15117 solver.cpp:233] Iteration 51670, loss = 0.014738
I0526 10:40:34.135104 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0147382 (* 1 = 0.0147382 loss)
I0526 10:40:34.135112 15117 sgd_solver.cpp:294] Iteration 51670, lr = 0.0002
I0526 10:40:40.425818 15117 solver.cpp:233] Iteration 51680, loss = 0.0103515
I0526 10:40:40.425945 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0103517 (* 1 = 0.0103517 loss)
I0526 10:40:40.425953 15117 sgd_solver.cpp:294] Iteration 51680, lr = 0.0002
I0526 10:40:46.715319 15117 solver.cpp:233] Iteration 51690, loss = 0.00967581
I0526 10:40:46.715363 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00967604 (* 1 = 0.00967604 loss)
I0526 10:40:46.715370 15117 sgd_solver.cpp:294] Iteration 51690, lr = 0.0002
I0526 10:40:52.406878 15117 solver.cpp:342] Iteration 51700, Testing net (#0)
I0526 10:41:05.191193 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9068
I0526 10:41:05.191239 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.443539 (* 1 = 0.443539 loss)
I0526 10:41:05.788422 15117 solver.cpp:233] Iteration 51700, loss = 0.0307498
I0526 10:41:05.788462 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0307501 (* 1 = 0.0307501 loss)
I0526 10:41:05.788480 15117 sgd_solver.cpp:294] Iteration 51700, lr = 0.0002
I0526 10:41:12.078955 15117 solver.cpp:233] Iteration 51710, loss = 0.00603579
I0526 10:41:12.079165 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00603601 (* 1 = 0.00603601 loss)
I0526 10:41:12.079195 15117 sgd_solver.cpp:294] Iteration 51710, lr = 0.0002
I0526 10:41:18.371942 15117 solver.cpp:233] Iteration 51720, loss = 0.00447434
I0526 10:41:18.371994 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00447456 (* 1 = 0.00447456 loss)
I0526 10:41:18.372002 15117 sgd_solver.cpp:294] Iteration 51720, lr = 0.0002
I0526 10:41:24.662379 15117 solver.cpp:233] Iteration 51730, loss = 0.033028
I0526 10:41:24.662421 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0330282 (* 1 = 0.0330282 loss)
I0526 10:41:24.662428 15117 sgd_solver.cpp:294] Iteration 51730, lr = 0.0002
I0526 10:41:30.950404 15117 solver.cpp:233] Iteration 51740, loss = 0.00591341
I0526 10:41:30.950450 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00591363 (* 1 = 0.00591363 loss)
I0526 10:41:30.950458 15117 sgd_solver.cpp:294] Iteration 51740, lr = 0.0002
I0526 10:41:37.237931 15117 solver.cpp:233] Iteration 51750, loss = 0.00370162
I0526 10:41:37.237974 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00370184 (* 1 = 0.00370184 loss)
I0526 10:41:37.237982 15117 sgd_solver.cpp:294] Iteration 51750, lr = 0.0002
I0526 10:41:43.529187 15117 solver.cpp:233] Iteration 51760, loss = 0.0241656
I0526 10:41:43.529449 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0241659 (* 1 = 0.0241659 loss)
I0526 10:41:43.529479 15117 sgd_solver.cpp:294] Iteration 51760, lr = 0.0002
I0526 10:41:49.822515 15117 solver.cpp:233] Iteration 51770, loss = 0.0178914
I0526 10:41:49.822561 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0178916 (* 1 = 0.0178916 loss)
I0526 10:41:49.822568 15117 sgd_solver.cpp:294] Iteration 51770, lr = 0.0002
I0526 10:41:56.115427 15117 solver.cpp:233] Iteration 51780, loss = 0.00546019
I0526 10:41:56.115469 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00546042 (* 1 = 0.00546042 loss)
I0526 10:41:56.115476 15117 sgd_solver.cpp:294] Iteration 51780, lr = 0.0002
I0526 10:42:02.407328 15117 solver.cpp:233] Iteration 51790, loss = 0.00463447
I0526 10:42:02.407372 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0046347 (* 1 = 0.0046347 loss)
I0526 10:42:02.407379 15117 sgd_solver.cpp:294] Iteration 51790, lr = 0.0002
I0526 10:42:08.100899 15117 solver.cpp:342] Iteration 51800, Testing net (#0)
I0526 10:42:20.894244 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9021
I0526 10:42:20.894381 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.464245 (* 1 = 0.464245 loss)
I0526 10:42:21.490881 15117 solver.cpp:233] Iteration 51800, loss = 0.0137611
I0526 10:42:21.490909 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0137613 (* 1 = 0.0137613 loss)
I0526 10:42:21.490917 15117 sgd_solver.cpp:294] Iteration 51800, lr = 0.0002
I0526 10:42:27.780022 15117 solver.cpp:233] Iteration 51810, loss = 0.0247102
I0526 10:42:27.780063 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0247104 (* 1 = 0.0247104 loss)
I0526 10:42:27.780071 15117 sgd_solver.cpp:294] Iteration 51810, lr = 0.0002
I0526 10:42:34.067330 15117 solver.cpp:233] Iteration 51820, loss = 0.0117487
I0526 10:42:34.067373 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.011749 (* 1 = 0.011749 loss)
I0526 10:42:34.067380 15117 sgd_solver.cpp:294] Iteration 51820, lr = 0.0002
I0526 10:42:40.353763 15117 solver.cpp:233] Iteration 51830, loss = 0.0199916
I0526 10:42:40.353806 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0199918 (* 1 = 0.0199918 loss)
I0526 10:42:40.353813 15117 sgd_solver.cpp:294] Iteration 51830, lr = 0.0002
I0526 10:42:46.643263 15117 solver.cpp:233] Iteration 51840, loss = 0.00456735
I0526 10:42:46.643306 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00456757 (* 1 = 0.00456757 loss)
I0526 10:42:46.643312 15117 sgd_solver.cpp:294] Iteration 51840, lr = 0.0002
I0526 10:42:52.932626 15117 solver.cpp:233] Iteration 51850, loss = 0.0105311
I0526 10:42:52.932893 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0105314 (* 1 = 0.0105314 loss)
I0526 10:42:52.932919 15117 sgd_solver.cpp:294] Iteration 51850, lr = 0.0002
I0526 10:42:59.223376 15117 solver.cpp:233] Iteration 51860, loss = 0.0108353
I0526 10:42:59.223425 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0108355 (* 1 = 0.0108355 loss)
I0526 10:42:59.223433 15117 sgd_solver.cpp:294] Iteration 51860, lr = 0.0002
I0526 10:43:05.512733 15117 solver.cpp:233] Iteration 51870, loss = 0.0128279
I0526 10:43:05.512773 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0128282 (* 1 = 0.0128282 loss)
I0526 10:43:05.512780 15117 sgd_solver.cpp:294] Iteration 51870, lr = 0.0002
I0526 10:43:11.804780 15117 solver.cpp:233] Iteration 51880, loss = 0.00931306
I0526 10:43:11.804822 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00931329 (* 1 = 0.00931329 loss)
I0526 10:43:11.804828 15117 sgd_solver.cpp:294] Iteration 51880, lr = 0.0002
I0526 10:43:18.086874 15117 solver.cpp:233] Iteration 51890, loss = 0.00369838
I0526 10:43:18.086917 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00369861 (* 1 = 0.00369861 loss)
I0526 10:43:18.086925 15117 sgd_solver.cpp:294] Iteration 51890, lr = 0.0002
I0526 10:43:23.780242 15117 solver.cpp:342] Iteration 51900, Testing net (#0)
I0526 10:43:36.564930 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9067
I0526 10:43:36.564977 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.450723 (* 1 = 0.450723 loss)
I0526 10:43:37.161837 15117 solver.cpp:233] Iteration 51900, loss = 0.00478467
I0526 10:43:37.161880 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00478489 (* 1 = 0.00478489 loss)
I0526 10:43:37.161887 15117 sgd_solver.cpp:294] Iteration 51900, lr = 0.0002
I0526 10:43:43.447605 15117 solver.cpp:233] Iteration 51910, loss = 0.00382048
I0526 10:43:43.447649 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0038207 (* 1 = 0.0038207 loss)
I0526 10:43:43.447656 15117 sgd_solver.cpp:294] Iteration 51910, lr = 0.0002
I0526 10:43:49.735319 15117 solver.cpp:233] Iteration 51920, loss = 0.00802167
I0526 10:43:49.735362 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0080219 (* 1 = 0.0080219 loss)
I0526 10:43:49.735368 15117 sgd_solver.cpp:294] Iteration 51920, lr = 0.0002
I0526 10:43:56.024685 15117 solver.cpp:233] Iteration 51930, loss = 0.0116367
I0526 10:43:56.024902 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0116369 (* 1 = 0.0116369 loss)
I0526 10:43:56.024931 15117 sgd_solver.cpp:294] Iteration 51930, lr = 0.0002
I0526 10:44:02.316542 15117 solver.cpp:233] Iteration 51940, loss = 0.011363
I0526 10:44:02.316588 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0113632 (* 1 = 0.0113632 loss)
I0526 10:44:02.316596 15117 sgd_solver.cpp:294] Iteration 51940, lr = 0.0002
I0526 10:44:08.605195 15117 solver.cpp:233] Iteration 51950, loss = 0.00297498
I0526 10:44:08.605237 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00297521 (* 1 = 0.00297521 loss)
I0526 10:44:08.605244 15117 sgd_solver.cpp:294] Iteration 51950, lr = 0.0002
I0526 10:44:14.895037 15117 solver.cpp:233] Iteration 51960, loss = 0.0128128
I0526 10:44:14.895081 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0128131 (* 1 = 0.0128131 loss)
I0526 10:44:14.895089 15117 sgd_solver.cpp:294] Iteration 51960, lr = 0.0002
I0526 10:44:21.182626 15117 solver.cpp:233] Iteration 51970, loss = 0.0200691
I0526 10:44:21.182668 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0200693 (* 1 = 0.0200693 loss)
I0526 10:44:21.182675 15117 sgd_solver.cpp:294] Iteration 51970, lr = 0.0002
I0526 10:44:27.472745 15117 solver.cpp:233] Iteration 51980, loss = 0.0235626
I0526 10:44:27.472930 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0235629 (* 1 = 0.0235629 loss)
I0526 10:44:27.472959 15117 sgd_solver.cpp:294] Iteration 51980, lr = 0.0002
I0526 10:44:33.764953 15117 solver.cpp:233] Iteration 51990, loss = 0.0126823
I0526 10:44:33.764998 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0126825 (* 1 = 0.0126825 loss)
I0526 10:44:33.765012 15117 sgd_solver.cpp:294] Iteration 51990, lr = 0.0002
I0526 10:44:39.455054 15117 solver.cpp:342] Iteration 52000, Testing net (#0)
I0526 10:44:52.237210 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9049
I0526 10:44:52.237252 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.443043 (* 1 = 0.443043 loss)
I0526 10:44:52.835141 15117 solver.cpp:233] Iteration 52000, loss = 0.0123959
I0526 10:44:52.835168 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0123961 (* 1 = 0.0123961 loss)
I0526 10:44:52.835186 15117 sgd_solver.cpp:294] Iteration 52000, lr = 0.0002
I0526 10:44:59.125452 15117 solver.cpp:233] Iteration 52010, loss = 0.0190771
I0526 10:44:59.125629 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0190773 (* 1 = 0.0190773 loss)
I0526 10:44:59.125638 15117 sgd_solver.cpp:294] Iteration 52010, lr = 0.0002
I0526 10:45:05.412148 15117 solver.cpp:233] Iteration 52020, loss = 0.00333977
I0526 10:45:05.412189 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00333999 (* 1 = 0.00333999 loss)
I0526 10:45:05.412196 15117 sgd_solver.cpp:294] Iteration 52020, lr = 0.0002
I0526 10:45:11.694950 15117 solver.cpp:233] Iteration 52030, loss = 0.00876558
I0526 10:45:11.694990 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0087658 (* 1 = 0.0087658 loss)
I0526 10:45:11.694998 15117 sgd_solver.cpp:294] Iteration 52030, lr = 0.0002
I0526 10:45:17.982981 15117 solver.cpp:233] Iteration 52040, loss = 0.00891661
I0526 10:45:17.983026 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00891683 (* 1 = 0.00891683 loss)
I0526 10:45:17.983033 15117 sgd_solver.cpp:294] Iteration 52040, lr = 0.0002
I0526 10:45:24.272604 15117 solver.cpp:233] Iteration 52050, loss = 0.00965155
I0526 10:45:24.272646 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00965177 (* 1 = 0.00965177 loss)
I0526 10:45:24.272652 15117 sgd_solver.cpp:294] Iteration 52050, lr = 0.0002
I0526 10:45:30.561607 15117 solver.cpp:233] Iteration 52060, loss = 0.0192524
I0526 10:45:30.561739 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0192527 (* 1 = 0.0192527 loss)
I0526 10:45:30.561748 15117 sgd_solver.cpp:294] Iteration 52060, lr = 0.0002
I0526 10:45:36.850631 15117 solver.cpp:233] Iteration 52070, loss = 0.0119407
I0526 10:45:36.850672 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0119409 (* 1 = 0.0119409 loss)
I0526 10:45:36.850678 15117 sgd_solver.cpp:294] Iteration 52070, lr = 0.0002
I0526 10:45:43.136725 15117 solver.cpp:233] Iteration 52080, loss = 0.00375529
I0526 10:45:43.136766 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00375551 (* 1 = 0.00375551 loss)
I0526 10:45:43.136772 15117 sgd_solver.cpp:294] Iteration 52080, lr = 0.0002
I0526 10:45:49.424976 15117 solver.cpp:233] Iteration 52090, loss = 0.0102312
I0526 10:45:49.425019 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0102314 (* 1 = 0.0102314 loss)
I0526 10:45:49.425026 15117 sgd_solver.cpp:294] Iteration 52090, lr = 0.0002
I0526 10:45:55.114200 15117 solver.cpp:342] Iteration 52100, Testing net (#0)
I0526 10:46:07.900076 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9043
I0526 10:46:07.900202 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.460064 (* 1 = 0.460064 loss)
I0526 10:46:08.497604 15117 solver.cpp:233] Iteration 52100, loss = 0.00627801
I0526 10:46:08.497642 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00627824 (* 1 = 0.00627824 loss)
I0526 10:46:08.497648 15117 sgd_solver.cpp:294] Iteration 52100, lr = 0.0002
I0526 10:46:14.786201 15117 solver.cpp:233] Iteration 52110, loss = 0.00358877
I0526 10:46:14.786244 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.003589 (* 1 = 0.003589 loss)
I0526 10:46:14.786252 15117 sgd_solver.cpp:294] Iteration 52110, lr = 0.0002
I0526 10:46:21.074173 15117 solver.cpp:233] Iteration 52120, loss = 0.0173491
I0526 10:46:21.074214 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0173494 (* 1 = 0.0173494 loss)
I0526 10:46:21.074228 15117 sgd_solver.cpp:294] Iteration 52120, lr = 0.0002
I0526 10:46:27.363068 15117 solver.cpp:233] Iteration 52130, loss = 0.00650713
I0526 10:46:27.363095 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00650736 (* 1 = 0.00650736 loss)
I0526 10:46:27.363102 15117 sgd_solver.cpp:294] Iteration 52130, lr = 0.0002
I0526 10:46:33.650053 15117 solver.cpp:233] Iteration 52140, loss = 0.0117439
I0526 10:46:33.650094 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0117441 (* 1 = 0.0117441 loss)
I0526 10:46:33.650101 15117 sgd_solver.cpp:294] Iteration 52140, lr = 0.0002
I0526 10:46:39.935508 15117 solver.cpp:233] Iteration 52150, loss = 0.00954444
I0526 10:46:39.935734 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00954466 (* 1 = 0.00954466 loss)
I0526 10:46:39.935763 15117 sgd_solver.cpp:294] Iteration 52150, lr = 0.0002
I0526 10:46:46.224078 15117 solver.cpp:233] Iteration 52160, loss = 0.00990034
I0526 10:46:46.224125 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00990056 (* 1 = 0.00990056 loss)
I0526 10:46:46.224133 15117 sgd_solver.cpp:294] Iteration 52160, lr = 0.0002
I0526 10:46:52.514165 15117 solver.cpp:233] Iteration 52170, loss = 0.010161
I0526 10:46:52.514207 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0101613 (* 1 = 0.0101613 loss)
I0526 10:46:52.514215 15117 sgd_solver.cpp:294] Iteration 52170, lr = 0.0002
I0526 10:46:58.801647 15117 solver.cpp:233] Iteration 52180, loss = 0.00488502
I0526 10:46:58.801694 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00488524 (* 1 = 0.00488524 loss)
I0526 10:46:58.801702 15117 sgd_solver.cpp:294] Iteration 52180, lr = 0.0002
I0526 10:47:05.093139 15117 solver.cpp:233] Iteration 52190, loss = 0.0139589
I0526 10:47:05.093181 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0139592 (* 1 = 0.0139592 loss)
I0526 10:47:05.093188 15117 sgd_solver.cpp:294] Iteration 52190, lr = 0.0002
I0526 10:47:10.787472 15117 solver.cpp:342] Iteration 52200, Testing net (#0)
I0526 10:47:23.578948 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9038
I0526 10:47:23.578994 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.449024 (* 1 = 0.449024 loss)
I0526 10:47:24.176811 15117 solver.cpp:233] Iteration 52200, loss = 0.0107164
I0526 10:47:24.176849 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0107166 (* 1 = 0.0107166 loss)
I0526 10:47:24.176856 15117 sgd_solver.cpp:294] Iteration 52200, lr = 0.0002
I0526 10:47:30.465265 15117 solver.cpp:233] Iteration 52210, loss = 0.00833804
I0526 10:47:30.465308 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00833826 (* 1 = 0.00833826 loss)
I0526 10:47:30.465315 15117 sgd_solver.cpp:294] Iteration 52210, lr = 0.0002
I0526 10:47:36.753820 15117 solver.cpp:233] Iteration 52220, loss = 0.017323
I0526 10:47:36.753861 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0173232 (* 1 = 0.0173232 loss)
I0526 10:47:36.753867 15117 sgd_solver.cpp:294] Iteration 52220, lr = 0.0002
I0526 10:47:43.041645 15117 solver.cpp:233] Iteration 52230, loss = 0.00809836
I0526 10:47:43.041769 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00809859 (* 1 = 0.00809859 loss)
I0526 10:47:43.041777 15117 sgd_solver.cpp:294] Iteration 52230, lr = 0.0002
I0526 10:47:49.328711 15117 solver.cpp:233] Iteration 52240, loss = 0.00493124
I0526 10:47:49.328753 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00493147 (* 1 = 0.00493147 loss)
I0526 10:47:49.328760 15117 sgd_solver.cpp:294] Iteration 52240, lr = 0.0002
I0526 10:47:55.619525 15117 solver.cpp:233] Iteration 52250, loss = 0.00860788
I0526 10:47:55.619568 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0086081 (* 1 = 0.0086081 loss)
I0526 10:47:55.619576 15117 sgd_solver.cpp:294] Iteration 52250, lr = 0.0002
I0526 10:48:01.903766 15117 solver.cpp:233] Iteration 52260, loss = 0.00673103
I0526 10:48:01.903816 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00673125 (* 1 = 0.00673125 loss)
I0526 10:48:01.903825 15117 sgd_solver.cpp:294] Iteration 52260, lr = 0.0002
I0526 10:48:08.193610 15117 solver.cpp:233] Iteration 52270, loss = 0.00453501
I0526 10:48:08.193652 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00453524 (* 1 = 0.00453524 loss)
I0526 10:48:08.193660 15117 sgd_solver.cpp:294] Iteration 52270, lr = 0.0002
I0526 10:48:14.482930 15117 solver.cpp:233] Iteration 52280, loss = 0.0050939
I0526 10:48:14.483187 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00509412 (* 1 = 0.00509412 loss)
I0526 10:48:14.483227 15117 sgd_solver.cpp:294] Iteration 52280, lr = 0.0002
I0526 10:48:20.772668 15117 solver.cpp:233] Iteration 52290, loss = 0.0208399
I0526 10:48:20.772711 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0208401 (* 1 = 0.0208401 loss)
I0526 10:48:20.772719 15117 sgd_solver.cpp:294] Iteration 52290, lr = 0.0002
I0526 10:48:26.466042 15117 solver.cpp:342] Iteration 52300, Testing net (#0)
I0526 10:48:39.254125 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9043
I0526 10:48:39.254173 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.45201 (* 1 = 0.45201 loss)
I0526 10:48:39.851222 15117 solver.cpp:233] Iteration 52300, loss = 0.00474424
I0526 10:48:39.851264 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00474447 (* 1 = 0.00474447 loss)
I0526 10:48:39.851271 15117 sgd_solver.cpp:294] Iteration 52300, lr = 0.0002
I0526 10:48:46.139060 15117 solver.cpp:233] Iteration 52310, loss = 0.0128445
I0526 10:48:46.139186 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0128448 (* 1 = 0.0128448 loss)
I0526 10:48:46.139195 15117 sgd_solver.cpp:294] Iteration 52310, lr = 0.0002
I0526 10:48:52.427110 15117 solver.cpp:233] Iteration 52320, loss = 0.00799528
I0526 10:48:52.427150 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0079955 (* 1 = 0.0079955 loss)
I0526 10:48:52.427156 15117 sgd_solver.cpp:294] Iteration 52320, lr = 0.0002
I0526 10:48:58.712472 15117 solver.cpp:233] Iteration 52330, loss = 0.0333641
I0526 10:48:58.712520 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0333643 (* 1 = 0.0333643 loss)
I0526 10:48:58.712528 15117 sgd_solver.cpp:294] Iteration 52330, lr = 0.0002
I0526 10:49:04.997869 15117 solver.cpp:233] Iteration 52340, loss = 0.00427939
I0526 10:49:04.997911 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00427961 (* 1 = 0.00427961 loss)
I0526 10:49:04.997918 15117 sgd_solver.cpp:294] Iteration 52340, lr = 0.0002
I0526 10:49:11.284085 15117 solver.cpp:233] Iteration 52350, loss = 0.00627295
I0526 10:49:11.284126 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00627317 (* 1 = 0.00627317 loss)
I0526 10:49:11.284133 15117 sgd_solver.cpp:294] Iteration 52350, lr = 0.0002
I0526 10:49:17.574733 15117 solver.cpp:233] Iteration 52360, loss = 0.00848503
I0526 10:49:17.574944 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00848525 (* 1 = 0.00848525 loss)
I0526 10:49:17.574971 15117 sgd_solver.cpp:294] Iteration 52360, lr = 0.0002
I0526 10:49:23.861616 15117 solver.cpp:233] Iteration 52370, loss = 0.00809962
I0526 10:49:23.861646 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00809984 (* 1 = 0.00809984 loss)
I0526 10:49:23.861654 15117 sgd_solver.cpp:294] Iteration 52370, lr = 0.0002
I0526 10:49:30.149286 15117 solver.cpp:233] Iteration 52380, loss = 0.0121601
I0526 10:49:30.149329 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0121603 (* 1 = 0.0121603 loss)
I0526 10:49:30.149336 15117 sgd_solver.cpp:294] Iteration 52380, lr = 0.0002
I0526 10:49:36.439610 15117 solver.cpp:233] Iteration 52390, loss = 0.00903267
I0526 10:49:36.439651 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00903289 (* 1 = 0.00903289 loss)
I0526 10:49:36.439658 15117 sgd_solver.cpp:294] Iteration 52390, lr = 0.0002
I0526 10:49:42.134146 15117 solver.cpp:342] Iteration 52400, Testing net (#0)
I0526 10:49:54.915156 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9045
I0526 10:49:54.915387 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.443977 (* 1 = 0.443977 loss)
I0526 10:49:55.511976 15117 solver.cpp:233] Iteration 52400, loss = 0.0215074
I0526 10:49:55.512012 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0215077 (* 1 = 0.0215077 loss)
I0526 10:49:55.512019 15117 sgd_solver.cpp:294] Iteration 52400, lr = 0.0002
I0526 10:50:01.802404 15117 solver.cpp:233] Iteration 52410, loss = 0.0105708
I0526 10:50:01.802448 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.010571 (* 1 = 0.010571 loss)
I0526 10:50:01.802455 15117 sgd_solver.cpp:294] Iteration 52410, lr = 0.0002
I0526 10:50:08.087982 15117 solver.cpp:233] Iteration 52420, loss = 0.0125386
I0526 10:50:08.088024 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0125388 (* 1 = 0.0125388 loss)
I0526 10:50:08.088032 15117 sgd_solver.cpp:294] Iteration 52420, lr = 0.0002
I0526 10:50:14.379061 15117 solver.cpp:233] Iteration 52430, loss = 0.0186645
I0526 10:50:14.379117 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0186647 (* 1 = 0.0186647 loss)
I0526 10:50:14.379125 15117 sgd_solver.cpp:294] Iteration 52430, lr = 0.0002
I0526 10:50:20.665118 15117 solver.cpp:233] Iteration 52440, loss = 0.00805696
I0526 10:50:20.665160 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00805719 (* 1 = 0.00805719 loss)
I0526 10:50:20.665166 15117 sgd_solver.cpp:294] Iteration 52440, lr = 0.0002
I0526 10:50:26.955919 15117 solver.cpp:233] Iteration 52450, loss = 0.00532069
I0526 10:50:26.956022 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00532092 (* 1 = 0.00532092 loss)
I0526 10:50:26.956030 15117 sgd_solver.cpp:294] Iteration 52450, lr = 0.0002
I0526 10:50:33.248271 15117 solver.cpp:233] Iteration 52460, loss = 0.0063704
I0526 10:50:33.248316 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00637063 (* 1 = 0.00637063 loss)
I0526 10:50:33.248323 15117 sgd_solver.cpp:294] Iteration 52460, lr = 0.0002
I0526 10:50:39.537168 15117 solver.cpp:233] Iteration 52470, loss = 0.00272929
I0526 10:50:39.537209 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00272952 (* 1 = 0.00272952 loss)
I0526 10:50:39.537216 15117 sgd_solver.cpp:294] Iteration 52470, lr = 0.0002
I0526 10:50:45.829411 15117 solver.cpp:233] Iteration 52480, loss = 0.0102988
I0526 10:50:45.829454 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.010299 (* 1 = 0.010299 loss)
I0526 10:50:45.829462 15117 sgd_solver.cpp:294] Iteration 52480, lr = 0.0002
I0526 10:50:52.118316 15117 solver.cpp:233] Iteration 52490, loss = 0.0145216
I0526 10:50:52.118373 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0145218 (* 1 = 0.0145218 loss)
I0526 10:50:52.118381 15117 sgd_solver.cpp:294] Iteration 52490, lr = 0.0002
I0526 10:50:57.809867 15117 solver.cpp:342] Iteration 52500, Testing net (#0)
I0526 10:51:10.596959 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9047
I0526 10:51:10.597007 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.445893 (* 1 = 0.445893 loss)
I0526 10:51:11.193430 15117 solver.cpp:233] Iteration 52500, loss = 0.00810243
I0526 10:51:11.193470 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00810265 (* 1 = 0.00810265 loss)
I0526 10:51:11.193477 15117 sgd_solver.cpp:294] Iteration 52500, lr = 0.0002
I0526 10:51:17.482952 15117 solver.cpp:233] Iteration 52510, loss = 0.00949628
I0526 10:51:17.482998 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0094965 (* 1 = 0.0094965 loss)
I0526 10:51:17.483005 15117 sgd_solver.cpp:294] Iteration 52510, lr = 0.0002
I0526 10:51:23.774832 15117 solver.cpp:233] Iteration 52520, loss = 0.00916113
I0526 10:51:23.774874 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00916136 (* 1 = 0.00916136 loss)
I0526 10:51:23.774888 15117 sgd_solver.cpp:294] Iteration 52520, lr = 0.0002
I0526 10:51:30.063213 15117 solver.cpp:233] Iteration 52530, loss = 0.0109417
I0526 10:51:30.063470 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0109419 (* 1 = 0.0109419 loss)
I0526 10:51:30.063499 15117 sgd_solver.cpp:294] Iteration 52530, lr = 0.0002
I0526 10:51:36.356552 15117 solver.cpp:233] Iteration 52540, loss = 0.0341199
I0526 10:51:36.356595 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0341201 (* 1 = 0.0341201 loss)
I0526 10:51:36.356601 15117 sgd_solver.cpp:294] Iteration 52540, lr = 0.0002
I0526 10:51:42.645851 15117 solver.cpp:233] Iteration 52550, loss = 0.00797739
I0526 10:51:42.645895 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00797762 (* 1 = 0.00797762 loss)
I0526 10:51:42.645901 15117 sgd_solver.cpp:294] Iteration 52550, lr = 0.0002
I0526 10:51:48.938551 15117 solver.cpp:233] Iteration 52560, loss = 0.00395238
I0526 10:51:48.938596 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0039526 (* 1 = 0.0039526 loss)
I0526 10:51:48.938602 15117 sgd_solver.cpp:294] Iteration 52560, lr = 0.0002
I0526 10:51:55.229634 15117 solver.cpp:233] Iteration 52570, loss = 0.0223772
I0526 10:51:55.229660 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0223774 (* 1 = 0.0223774 loss)
I0526 10:51:55.229667 15117 sgd_solver.cpp:294] Iteration 52570, lr = 0.0002
I0526 10:52:01.521790 15117 solver.cpp:233] Iteration 52580, loss = 0.00219841
I0526 10:52:01.521965 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00219863 (* 1 = 0.00219863 loss)
I0526 10:52:01.521993 15117 sgd_solver.cpp:294] Iteration 52580, lr = 0.0002
I0526 10:52:07.810994 15117 solver.cpp:233] Iteration 52590, loss = 0.00294394
I0526 10:52:07.811038 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00294417 (* 1 = 0.00294417 loss)
I0526 10:52:07.811045 15117 sgd_solver.cpp:294] Iteration 52590, lr = 0.0002
I0526 10:52:13.503929 15117 solver.cpp:342] Iteration 52600, Testing net (#0)
I0526 10:52:26.304777 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9039
I0526 10:52:26.304824 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.460858 (* 1 = 0.460858 loss)
I0526 10:52:26.900688 15117 solver.cpp:233] Iteration 52600, loss = 0.00790101
I0526 10:52:26.900729 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00790124 (* 1 = 0.00790124 loss)
I0526 10:52:26.900737 15117 sgd_solver.cpp:294] Iteration 52600, lr = 0.0002
I0526 10:52:33.188845 15117 solver.cpp:233] Iteration 52610, loss = 0.00889747
I0526 10:52:33.189059 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0088977 (* 1 = 0.0088977 loss)
I0526 10:52:33.189090 15117 sgd_solver.cpp:294] Iteration 52610, lr = 0.0002
I0526 10:52:39.481184 15117 solver.cpp:233] Iteration 52620, loss = 0.0150142
I0526 10:52:39.481226 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0150144 (* 1 = 0.0150144 loss)
I0526 10:52:39.481233 15117 sgd_solver.cpp:294] Iteration 52620, lr = 0.0002
I0526 10:52:45.771322 15117 solver.cpp:233] Iteration 52630, loss = 0.00511956
I0526 10:52:45.771364 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00511978 (* 1 = 0.00511978 loss)
I0526 10:52:45.771371 15117 sgd_solver.cpp:294] Iteration 52630, lr = 0.0002
I0526 10:52:52.062666 15117 solver.cpp:233] Iteration 52640, loss = 0.00379627
I0526 10:52:52.062721 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00379649 (* 1 = 0.00379649 loss)
I0526 10:52:52.062728 15117 sgd_solver.cpp:294] Iteration 52640, lr = 0.0002
I0526 10:52:58.353436 15117 solver.cpp:233] Iteration 52650, loss = 0.00725976
I0526 10:52:58.353477 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00725998 (* 1 = 0.00725998 loss)
I0526 10:52:58.353483 15117 sgd_solver.cpp:294] Iteration 52650, lr = 0.0002
I0526 10:53:04.642474 15117 solver.cpp:233] Iteration 52660, loss = 0.00634651
I0526 10:53:04.642748 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00634673 (* 1 = 0.00634673 loss)
I0526 10:53:04.642778 15117 sgd_solver.cpp:294] Iteration 52660, lr = 0.0002
I0526 10:53:10.933742 15117 solver.cpp:233] Iteration 52670, loss = 0.00736144
I0526 10:53:10.933784 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00736166 (* 1 = 0.00736166 loss)
I0526 10:53:10.933791 15117 sgd_solver.cpp:294] Iteration 52670, lr = 0.0002
I0526 10:53:17.219291 15117 solver.cpp:233] Iteration 52680, loss = 0.0119985
I0526 10:53:17.219336 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0119987 (* 1 = 0.0119987 loss)
I0526 10:53:17.219343 15117 sgd_solver.cpp:294] Iteration 52680, lr = 0.0002
I0526 10:53:23.508062 15117 solver.cpp:233] Iteration 52690, loss = 0.0137046
I0526 10:53:23.508102 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0137048 (* 1 = 0.0137048 loss)
I0526 10:53:23.508108 15117 sgd_solver.cpp:294] Iteration 52690, lr = 0.0002
I0526 10:53:29.201995 15117 solver.cpp:342] Iteration 52700, Testing net (#0)
I0526 10:53:41.984838 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9037
I0526 10:53:41.985062 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.455926 (* 1 = 0.455926 loss)
I0526 10:53:42.585988 15117 solver.cpp:233] Iteration 52700, loss = 0.00493772
I0526 10:53:42.586050 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00493794 (* 1 = 0.00493794 loss)
I0526 10:53:42.586061 15117 sgd_solver.cpp:294] Iteration 52700, lr = 0.0002
I0526 10:53:48.876818 15117 solver.cpp:233] Iteration 52710, loss = 0.0253071
I0526 10:53:48.876854 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0253074 (* 1 = 0.0253074 loss)
I0526 10:53:48.876862 15117 sgd_solver.cpp:294] Iteration 52710, lr = 0.0002
I0526 10:53:55.166396 15117 solver.cpp:233] Iteration 52720, loss = 0.0102031
I0526 10:53:55.166437 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0102033 (* 1 = 0.0102033 loss)
I0526 10:53:55.166445 15117 sgd_solver.cpp:294] Iteration 52720, lr = 0.0002
I0526 10:54:01.455607 15117 solver.cpp:233] Iteration 52730, loss = 0.0054137
I0526 10:54:01.455651 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00541391 (* 1 = 0.00541391 loss)
I0526 10:54:01.455657 15117 sgd_solver.cpp:294] Iteration 52730, lr = 0.0002
I0526 10:54:07.746239 15117 solver.cpp:233] Iteration 52740, loss = 0.00882405
I0526 10:54:07.746280 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00882427 (* 1 = 0.00882427 loss)
I0526 10:54:07.746286 15117 sgd_solver.cpp:294] Iteration 52740, lr = 0.0002
I0526 10:54:14.035982 15117 solver.cpp:233] Iteration 52750, loss = 0.00948202
I0526 10:54:14.036221 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00948224 (* 1 = 0.00948224 loss)
I0526 10:54:14.036252 15117 sgd_solver.cpp:294] Iteration 52750, lr = 0.0002
I0526 10:54:20.325413 15117 solver.cpp:233] Iteration 52760, loss = 0.014429
I0526 10:54:20.325456 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0144292 (* 1 = 0.0144292 loss)
I0526 10:54:20.325464 15117 sgd_solver.cpp:294] Iteration 52760, lr = 0.0002
I0526 10:54:26.612053 15117 solver.cpp:233] Iteration 52770, loss = 0.0150691
I0526 10:54:26.612082 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0150694 (* 1 = 0.0150694 loss)
I0526 10:54:26.612089 15117 sgd_solver.cpp:294] Iteration 52770, lr = 0.0002
I0526 10:54:32.901758 15117 solver.cpp:233] Iteration 52780, loss = 0.0141316
I0526 10:54:32.901800 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0141319 (* 1 = 0.0141319 loss)
I0526 10:54:32.901808 15117 sgd_solver.cpp:294] Iteration 52780, lr = 0.0002
I0526 10:54:39.190148 15117 solver.cpp:233] Iteration 52790, loss = 0.00839878
I0526 10:54:39.190189 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.008399 (* 1 = 0.008399 loss)
I0526 10:54:39.190196 15117 sgd_solver.cpp:294] Iteration 52790, lr = 0.0002
I0526 10:54:44.881598 15117 solver.cpp:342] Iteration 52800, Testing net (#0)
I0526 10:54:57.668115 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9037
I0526 10:54:57.668153 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.450691 (* 1 = 0.450691 loss)
I0526 10:54:58.265460 15117 solver.cpp:233] Iteration 52800, loss = 0.00569056
I0526 10:54:58.265499 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00569078 (* 1 = 0.00569078 loss)
I0526 10:54:58.265507 15117 sgd_solver.cpp:294] Iteration 52800, lr = 0.0002
I0526 10:55:04.554986 15117 solver.cpp:233] Iteration 52810, loss = 0.0102801
I0526 10:55:04.555029 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0102804 (* 1 = 0.0102804 loss)
I0526 10:55:04.555037 15117 sgd_solver.cpp:294] Iteration 52810, lr = 0.0002
I0526 10:55:10.845289 15117 solver.cpp:233] Iteration 52820, loss = 0.0168461
I0526 10:55:10.845331 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0168463 (* 1 = 0.0168463 loss)
I0526 10:55:10.845338 15117 sgd_solver.cpp:294] Iteration 52820, lr = 0.0002
I0526 10:55:17.131922 15117 solver.cpp:233] Iteration 52830, loss = 0.00782616
I0526 10:55:17.132131 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00782638 (* 1 = 0.00782638 loss)
I0526 10:55:17.132160 15117 sgd_solver.cpp:294] Iteration 52830, lr = 0.0002
I0526 10:55:23.423877 15117 solver.cpp:233] Iteration 52840, loss = 0.00816166
I0526 10:55:23.423920 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00816188 (* 1 = 0.00816188 loss)
I0526 10:55:23.423928 15117 sgd_solver.cpp:294] Iteration 52840, lr = 0.0002
I0526 10:55:29.710746 15117 solver.cpp:233] Iteration 52850, loss = 0.0287596
I0526 10:55:29.710788 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0287599 (* 1 = 0.0287599 loss)
I0526 10:55:29.710796 15117 sgd_solver.cpp:294] Iteration 52850, lr = 0.0002
I0526 10:55:36.000543 15117 solver.cpp:233] Iteration 52860, loss = 0.00961128
I0526 10:55:36.000587 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0096115 (* 1 = 0.0096115 loss)
I0526 10:55:36.000594 15117 sgd_solver.cpp:294] Iteration 52860, lr = 0.0002
I0526 10:55:42.289793 15117 solver.cpp:233] Iteration 52870, loss = 0.0105411
I0526 10:55:42.289835 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0105413 (* 1 = 0.0105413 loss)
I0526 10:55:42.289842 15117 sgd_solver.cpp:294] Iteration 52870, lr = 0.0002
I0526 10:55:48.572921 15117 solver.cpp:233] Iteration 52880, loss = 0.00444235
I0526 10:55:48.573142 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00444257 (* 1 = 0.00444257 loss)
I0526 10:55:48.573170 15117 sgd_solver.cpp:294] Iteration 52880, lr = 0.0002
I0526 10:55:54.863020 15117 solver.cpp:233] Iteration 52890, loss = 0.00512327
I0526 10:55:54.863065 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00512349 (* 1 = 0.00512349 loss)
I0526 10:55:54.863072 15117 sgd_solver.cpp:294] Iteration 52890, lr = 0.0002
I0526 10:56:00.557687 15117 solver.cpp:342] Iteration 52900, Testing net (#0)
I0526 10:56:13.341868 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9064
I0526 10:56:13.341910 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.443133 (* 1 = 0.443133 loss)
I0526 10:56:13.939318 15117 solver.cpp:233] Iteration 52900, loss = 0.0214428
I0526 10:56:13.939363 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0214431 (* 1 = 0.0214431 loss)
I0526 10:56:13.939368 15117 sgd_solver.cpp:294] Iteration 52900, lr = 0.0002
I0526 10:56:20.230810 15117 solver.cpp:233] Iteration 52910, loss = 0.0121749
I0526 10:56:20.231016 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0121751 (* 1 = 0.0121751 loss)
I0526 10:56:20.231045 15117 sgd_solver.cpp:294] Iteration 52910, lr = 0.0002
I0526 10:56:26.522210 15117 solver.cpp:233] Iteration 52920, loss = 0.0106255
I0526 10:56:26.522253 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0106257 (* 1 = 0.0106257 loss)
I0526 10:56:26.522260 15117 sgd_solver.cpp:294] Iteration 52920, lr = 0.0002
I0526 10:56:32.811950 15117 solver.cpp:233] Iteration 52930, loss = 0.00386786
I0526 10:56:32.811980 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00386808 (* 1 = 0.00386808 loss)
I0526 10:56:32.811986 15117 sgd_solver.cpp:294] Iteration 52930, lr = 0.0002
I0526 10:56:39.101727 15117 solver.cpp:233] Iteration 52940, loss = 0.0025713
I0526 10:56:39.101765 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00257152 (* 1 = 0.00257152 loss)
I0526 10:56:39.101771 15117 sgd_solver.cpp:294] Iteration 52940, lr = 0.0002
I0526 10:56:45.393939 15117 solver.cpp:233] Iteration 52950, loss = 0.018792
I0526 10:56:45.393983 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0187922 (* 1 = 0.0187922 loss)
I0526 10:56:45.393990 15117 sgd_solver.cpp:294] Iteration 52950, lr = 0.0002
I0526 10:56:51.686316 15117 solver.cpp:233] Iteration 52960, loss = 0.00367433
I0526 10:56:51.686614 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00367455 (* 1 = 0.00367455 loss)
I0526 10:56:51.686645 15117 sgd_solver.cpp:294] Iteration 52960, lr = 0.0002
I0526 10:56:57.973553 15117 solver.cpp:233] Iteration 52970, loss = 0.0102391
I0526 10:56:57.973583 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0102393 (* 1 = 0.0102393 loss)
I0526 10:56:57.973590 15117 sgd_solver.cpp:294] Iteration 52970, lr = 0.0002
I0526 10:57:04.259270 15117 solver.cpp:233] Iteration 52980, loss = 0.00672449
I0526 10:57:04.259315 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0067247 (* 1 = 0.0067247 loss)
I0526 10:57:04.259321 15117 sgd_solver.cpp:294] Iteration 52980, lr = 0.0002
I0526 10:57:10.549211 15117 solver.cpp:233] Iteration 52990, loss = 0.0166062
I0526 10:57:10.549252 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0166064 (* 1 = 0.0166064 loss)
I0526 10:57:10.549258 15117 sgd_solver.cpp:294] Iteration 52990, lr = 0.0002
I0526 10:57:16.243921 15117 solver.cpp:342] Iteration 53000, Testing net (#0)
I0526 10:57:29.028786 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9039
I0526 10:57:29.029012 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.444025 (* 1 = 0.444025 loss)
I0526 10:57:29.626706 15117 solver.cpp:233] Iteration 53000, loss = 0.00975457
I0526 10:57:29.626754 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00975479 (* 1 = 0.00975479 loss)
I0526 10:57:29.626762 15117 sgd_solver.cpp:294] Iteration 53000, lr = 0.0002
I0526 10:57:35.913775 15117 solver.cpp:233] Iteration 53010, loss = 0.013816
I0526 10:57:35.913816 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0138162 (* 1 = 0.0138162 loss)
I0526 10:57:35.913823 15117 sgd_solver.cpp:294] Iteration 53010, lr = 0.0002
I0526 10:57:42.200716 15117 solver.cpp:233] Iteration 53020, loss = 0.011038
I0526 10:57:42.200757 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0110382 (* 1 = 0.0110382 loss)
I0526 10:57:42.200762 15117 sgd_solver.cpp:294] Iteration 53020, lr = 0.0002
I0526 10:57:48.490252 15117 solver.cpp:233] Iteration 53030, loss = 0.0210117
I0526 10:57:48.490296 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.021012 (* 1 = 0.021012 loss)
I0526 10:57:48.490303 15117 sgd_solver.cpp:294] Iteration 53030, lr = 0.0002
I0526 10:57:54.777726 15117 solver.cpp:233] Iteration 53040, loss = 0.00845964
I0526 10:57:54.777767 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00845987 (* 1 = 0.00845987 loss)
I0526 10:57:54.777775 15117 sgd_solver.cpp:294] Iteration 53040, lr = 0.0002
I0526 10:58:01.063803 15117 solver.cpp:233] Iteration 53050, loss = 0.0155704
I0526 10:58:01.064050 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0155706 (* 1 = 0.0155706 loss)
I0526 10:58:01.064079 15117 sgd_solver.cpp:294] Iteration 53050, lr = 0.0002
I0526 10:58:07.349805 15117 solver.cpp:233] Iteration 53060, loss = 0.00825609
I0526 10:58:07.349843 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00825632 (* 1 = 0.00825632 loss)
I0526 10:58:07.349855 15117 sgd_solver.cpp:294] Iteration 53060, lr = 0.0002
I0526 10:58:13.633318 15117 solver.cpp:233] Iteration 53070, loss = 0.0169698
I0526 10:58:13.633361 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.01697 (* 1 = 0.01697 loss)
I0526 10:58:13.633368 15117 sgd_solver.cpp:294] Iteration 53070, lr = 0.0002
I0526 10:58:19.925792 15117 solver.cpp:233] Iteration 53080, loss = 0.00294114
I0526 10:58:19.925837 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00294136 (* 1 = 0.00294136 loss)
I0526 10:58:19.925844 15117 sgd_solver.cpp:294] Iteration 53080, lr = 0.0002
I0526 10:58:26.214762 15117 solver.cpp:233] Iteration 53090, loss = 0.00578004
I0526 10:58:26.214803 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00578027 (* 1 = 0.00578027 loss)
I0526 10:58:26.214810 15117 sgd_solver.cpp:294] Iteration 53090, lr = 0.0002
I0526 10:58:31.905484 15117 solver.cpp:342] Iteration 53100, Testing net (#0)
I0526 10:58:44.733002 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9062
I0526 10:58:44.733048 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.450192 (* 1 = 0.450192 loss)
I0526 10:58:45.333297 15117 solver.cpp:233] Iteration 53100, loss = 0.0109181
I0526 10:58:45.333320 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0109183 (* 1 = 0.0109183 loss)
I0526 10:58:45.333328 15117 sgd_solver.cpp:294] Iteration 53100, lr = 0.0002
I0526 10:58:51.651823 15117 solver.cpp:233] Iteration 53110, loss = 0.00956507
I0526 10:58:51.651873 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00956529 (* 1 = 0.00956529 loss)
I0526 10:58:51.651880 15117 sgd_solver.cpp:294] Iteration 53110, lr = 0.0002
I0526 10:58:57.972520 15117 solver.cpp:233] Iteration 53120, loss = 0.0103142
I0526 10:58:57.972559 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0103144 (* 1 = 0.0103144 loss)
I0526 10:58:57.972566 15117 sgd_solver.cpp:294] Iteration 53120, lr = 0.0002
I0526 10:59:04.290683 15117 solver.cpp:233] Iteration 53130, loss = 0.0179913
I0526 10:59:04.290913 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0179915 (* 1 = 0.0179915 loss)
I0526 10:59:04.290942 15117 sgd_solver.cpp:294] Iteration 53130, lr = 0.0002
I0526 10:59:10.610443 15117 solver.cpp:233] Iteration 53140, loss = 0.0109911
I0526 10:59:10.610486 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0109914 (* 1 = 0.0109914 loss)
I0526 10:59:10.610494 15117 sgd_solver.cpp:294] Iteration 53140, lr = 0.0002
I0526 10:59:16.929735 15117 solver.cpp:233] Iteration 53150, loss = 0.00497618
I0526 10:59:16.929780 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0049764 (* 1 = 0.0049764 loss)
I0526 10:59:16.929787 15117 sgd_solver.cpp:294] Iteration 53150, lr = 0.0002
I0526 10:59:23.250483 15117 solver.cpp:233] Iteration 53160, loss = 0.0157977
I0526 10:59:23.250530 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0157979 (* 1 = 0.0157979 loss)
I0526 10:59:23.250536 15117 sgd_solver.cpp:294] Iteration 53160, lr = 0.0002
I0526 10:59:29.571266 15117 solver.cpp:233] Iteration 53170, loss = 0.0144031
I0526 10:59:29.571300 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0144033 (* 1 = 0.0144033 loss)
I0526 10:59:29.571305 15117 sgd_solver.cpp:294] Iteration 53170, lr = 0.0002
I0526 10:59:35.889674 15117 solver.cpp:233] Iteration 53180, loss = 0.0249575
I0526 10:59:35.889876 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0249577 (* 1 = 0.0249577 loss)
I0526 10:59:35.889904 15117 sgd_solver.cpp:294] Iteration 53180, lr = 0.0002
I0526 10:59:42.203315 15117 solver.cpp:233] Iteration 53190, loss = 0.0113446
I0526 10:59:42.203363 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0113448 (* 1 = 0.0113448 loss)
I0526 10:59:42.203371 15117 sgd_solver.cpp:294] Iteration 53190, lr = 0.0002
I0526 10:59:47.905292 15117 solver.cpp:342] Iteration 53200, Testing net (#0)
I0526 11:00:00.683187 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.905
I0526 11:00:00.683235 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.447276 (* 1 = 0.447276 loss)
I0526 11:00:01.279917 15117 solver.cpp:233] Iteration 53200, loss = 0.00462705
I0526 11:00:01.279953 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00462727 (* 1 = 0.00462727 loss)
I0526 11:00:01.279959 15117 sgd_solver.cpp:294] Iteration 53200, lr = 0.0002
I0526 11:00:07.567070 15117 solver.cpp:233] Iteration 53210, loss = 0.00541382
I0526 11:00:07.567320 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00541404 (* 1 = 0.00541404 loss)
I0526 11:00:07.567347 15117 sgd_solver.cpp:294] Iteration 53210, lr = 0.0002
I0526 11:00:13.857729 15117 solver.cpp:233] Iteration 53220, loss = 0.0125784
I0526 11:00:13.857770 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0125787 (* 1 = 0.0125787 loss)
I0526 11:00:13.857777 15117 sgd_solver.cpp:294] Iteration 53220, lr = 0.0002
I0526 11:00:20.149432 15117 solver.cpp:233] Iteration 53230, loss = 0.00627365
I0526 11:00:20.149474 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00627387 (* 1 = 0.00627387 loss)
I0526 11:00:20.149482 15117 sgd_solver.cpp:294] Iteration 53230, lr = 0.0002
I0526 11:00:26.439847 15117 solver.cpp:233] Iteration 53240, loss = 0.00936627
I0526 11:00:26.439890 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00936649 (* 1 = 0.00936649 loss)
I0526 11:00:26.439898 15117 sgd_solver.cpp:294] Iteration 53240, lr = 0.0002
I0526 11:00:32.728085 15117 solver.cpp:233] Iteration 53250, loss = 0.0572415
I0526 11:00:32.728127 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0572417 (* 1 = 0.0572417 loss)
I0526 11:00:32.728133 15117 sgd_solver.cpp:294] Iteration 53250, lr = 0.0002
I0526 11:00:39.016090 15117 solver.cpp:233] Iteration 53260, loss = 0.015731
I0526 11:00:39.016224 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0157312 (* 1 = 0.0157312 loss)
I0526 11:00:39.016234 15117 sgd_solver.cpp:294] Iteration 53260, lr = 0.0002
I0526 11:00:45.300478 15117 solver.cpp:233] Iteration 53270, loss = 0.00893688
I0526 11:00:45.300521 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0089371 (* 1 = 0.0089371 loss)
I0526 11:00:45.300529 15117 sgd_solver.cpp:294] Iteration 53270, lr = 0.0002
I0526 11:00:51.589937 15117 solver.cpp:233] Iteration 53280, loss = 0.0111877
I0526 11:00:51.589980 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0111879 (* 1 = 0.0111879 loss)
I0526 11:00:51.589987 15117 sgd_solver.cpp:294] Iteration 53280, lr = 0.0002
I0526 11:00:57.875411 15117 solver.cpp:233] Iteration 53290, loss = 0.0116579
I0526 11:00:57.875452 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0116581 (* 1 = 0.0116581 loss)
I0526 11:00:57.875458 15117 sgd_solver.cpp:294] Iteration 53290, lr = 0.0002
I0526 11:01:03.568639 15117 solver.cpp:342] Iteration 53300, Testing net (#0)
I0526 11:01:16.344422 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9046
I0526 11:01:16.344650 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.460305 (* 1 = 0.460305 loss)
I0526 11:01:16.943120 15117 solver.cpp:233] Iteration 53300, loss = 0.0113044
I0526 11:01:16.943163 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0113047 (* 1 = 0.0113047 loss)
I0526 11:01:16.943171 15117 sgd_solver.cpp:294] Iteration 53300, lr = 0.0002
I0526 11:01:23.231586 15117 solver.cpp:233] Iteration 53310, loss = 0.00657396
I0526 11:01:23.231621 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00657418 (* 1 = 0.00657418 loss)
I0526 11:01:23.231627 15117 sgd_solver.cpp:294] Iteration 53310, lr = 0.0002
I0526 11:01:29.518569 15117 solver.cpp:233] Iteration 53320, loss = 0.0119863
I0526 11:01:29.518611 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0119865 (* 1 = 0.0119865 loss)
I0526 11:01:29.518617 15117 sgd_solver.cpp:294] Iteration 53320, lr = 0.0002
I0526 11:01:35.806643 15117 solver.cpp:233] Iteration 53330, loss = 0.00630112
I0526 11:01:35.806702 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00630134 (* 1 = 0.00630134 loss)
I0526 11:01:35.806710 15117 sgd_solver.cpp:294] Iteration 53330, lr = 0.0002
I0526 11:01:42.092306 15117 solver.cpp:233] Iteration 53340, loss = 0.0135903
I0526 11:01:42.092350 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0135905 (* 1 = 0.0135905 loss)
I0526 11:01:42.092357 15117 sgd_solver.cpp:294] Iteration 53340, lr = 0.0002
I0526 11:01:48.378121 15117 solver.cpp:233] Iteration 53350, loss = 0.00744342
I0526 11:01:48.378393 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00744365 (* 1 = 0.00744365 loss)
I0526 11:01:48.378423 15117 sgd_solver.cpp:294] Iteration 53350, lr = 0.0002
I0526 11:01:54.666213 15117 solver.cpp:233] Iteration 53360, loss = 0.0125321
I0526 11:01:54.666257 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0125323 (* 1 = 0.0125323 loss)
I0526 11:01:54.666265 15117 sgd_solver.cpp:294] Iteration 53360, lr = 0.0002
I0526 11:02:00.952867 15117 solver.cpp:233] Iteration 53370, loss = 0.0101347
I0526 11:02:00.952900 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0101349 (* 1 = 0.0101349 loss)
I0526 11:02:00.952908 15117 sgd_solver.cpp:294] Iteration 53370, lr = 0.0002
I0526 11:02:07.245324 15117 solver.cpp:233] Iteration 53380, loss = 0.00334521
I0526 11:02:07.245368 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00334544 (* 1 = 0.00334544 loss)
I0526 11:02:07.245373 15117 sgd_solver.cpp:294] Iteration 53380, lr = 0.0002
I0526 11:02:13.533140 15117 solver.cpp:233] Iteration 53390, loss = 0.022648
I0526 11:02:13.533179 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0226482 (* 1 = 0.0226482 loss)
I0526 11:02:13.533185 15117 sgd_solver.cpp:294] Iteration 53390, lr = 0.0002
I0526 11:02:19.225379 15117 solver.cpp:342] Iteration 53400, Testing net (#0)
I0526 11:02:32.013819 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9045
I0526 11:02:32.013864 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.450466 (* 1 = 0.450466 loss)
I0526 11:02:32.611276 15117 solver.cpp:233] Iteration 53400, loss = 0.00976762
I0526 11:02:32.611315 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00976784 (* 1 = 0.00976784 loss)
I0526 11:02:32.611323 15117 sgd_solver.cpp:294] Iteration 53400, lr = 0.0002
I0526 11:02:38.897480 15117 solver.cpp:233] Iteration 53410, loss = 0.0051961
I0526 11:02:38.897521 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00519633 (* 1 = 0.00519633 loss)
I0526 11:02:38.897528 15117 sgd_solver.cpp:294] Iteration 53410, lr = 0.0002
I0526 11:02:45.182412 15117 solver.cpp:233] Iteration 53420, loss = 0.00516526
I0526 11:02:45.182454 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00516549 (* 1 = 0.00516549 loss)
I0526 11:02:45.182462 15117 sgd_solver.cpp:294] Iteration 53420, lr = 0.0002
I0526 11:02:51.468343 15117 solver.cpp:233] Iteration 53430, loss = 0.00545809
I0526 11:02:51.468523 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00545831 (* 1 = 0.00545831 loss)
I0526 11:02:51.468554 15117 sgd_solver.cpp:294] Iteration 53430, lr = 0.0002
I0526 11:02:57.759192 15117 solver.cpp:233] Iteration 53440, loss = 0.0129413
I0526 11:02:57.759238 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0129416 (* 1 = 0.0129416 loss)
I0526 11:02:57.759245 15117 sgd_solver.cpp:294] Iteration 53440, lr = 0.0002
I0526 11:03:04.048147 15117 solver.cpp:233] Iteration 53450, loss = 0.00303197
I0526 11:03:04.048183 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0030322 (* 1 = 0.0030322 loss)
I0526 11:03:04.048190 15117 sgd_solver.cpp:294] Iteration 53450, lr = 0.0002
I0526 11:03:10.337105 15117 solver.cpp:233] Iteration 53460, loss = 0.0263242
I0526 11:03:10.337149 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0263244 (* 1 = 0.0263244 loss)
I0526 11:03:10.337157 15117 sgd_solver.cpp:294] Iteration 53460, lr = 0.0002
I0526 11:03:16.626384 15117 solver.cpp:233] Iteration 53470, loss = 0.00743513
I0526 11:03:16.626428 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00743535 (* 1 = 0.00743535 loss)
I0526 11:03:16.626435 15117 sgd_solver.cpp:294] Iteration 53470, lr = 0.0002
I0526 11:03:22.916518 15117 solver.cpp:233] Iteration 53480, loss = 0.00586043
I0526 11:03:22.916787 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00586065 (* 1 = 0.00586065 loss)
I0526 11:03:22.916817 15117 sgd_solver.cpp:294] Iteration 53480, lr = 0.0002
I0526 11:03:29.207509 15117 solver.cpp:233] Iteration 53490, loss = 0.0102984
I0526 11:03:29.207551 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0102986 (* 1 = 0.0102986 loss)
I0526 11:03:29.207557 15117 sgd_solver.cpp:294] Iteration 53490, lr = 0.0002
I0526 11:03:34.898794 15117 solver.cpp:342] Iteration 53500, Testing net (#0)
I0526 11:03:47.683274 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9041
I0526 11:03:47.683321 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.440838 (* 1 = 0.440838 loss)
I0526 11:03:48.280092 15117 solver.cpp:233] Iteration 53500, loss = 0.0154172
I0526 11:03:48.280133 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0154175 (* 1 = 0.0154175 loss)
I0526 11:03:48.280139 15117 sgd_solver.cpp:294] Iteration 53500, lr = 0.0002
I0526 11:03:54.565915 15117 solver.cpp:233] Iteration 53510, loss = 0.00533744
I0526 11:03:54.566035 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00533767 (* 1 = 0.00533767 loss)
I0526 11:03:54.566043 15117 sgd_solver.cpp:294] Iteration 53510, lr = 0.0002
I0526 11:04:00.855897 15117 solver.cpp:233] Iteration 53520, loss = 0.0139203
I0526 11:04:00.855939 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0139205 (* 1 = 0.0139205 loss)
I0526 11:04:00.855947 15117 sgd_solver.cpp:294] Iteration 53520, lr = 0.0002
I0526 11:04:07.145707 15117 solver.cpp:233] Iteration 53530, loss = 0.0119772
I0526 11:04:07.145735 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0119774 (* 1 = 0.0119774 loss)
I0526 11:04:07.145741 15117 sgd_solver.cpp:294] Iteration 53530, lr = 0.0002
I0526 11:04:13.435012 15117 solver.cpp:233] Iteration 53540, loss = 0.00985256
I0526 11:04:13.435052 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00985278 (* 1 = 0.00985278 loss)
I0526 11:04:13.435060 15117 sgd_solver.cpp:294] Iteration 53540, lr = 0.0002
I0526 11:04:19.723477 15117 solver.cpp:233] Iteration 53550, loss = 0.0113192
I0526 11:04:19.723521 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0113194 (* 1 = 0.0113194 loss)
I0526 11:04:19.723528 15117 sgd_solver.cpp:294] Iteration 53550, lr = 0.0002
I0526 11:04:26.014906 15117 solver.cpp:233] Iteration 53560, loss = 0.00436503
I0526 11:04:26.015125 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00436525 (* 1 = 0.00436525 loss)
I0526 11:04:26.015152 15117 sgd_solver.cpp:294] Iteration 53560, lr = 0.0002
I0526 11:04:32.306669 15117 solver.cpp:233] Iteration 53570, loss = 0.0143315
I0526 11:04:32.306723 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0143317 (* 1 = 0.0143317 loss)
I0526 11:04:32.306730 15117 sgd_solver.cpp:294] Iteration 53570, lr = 0.0002
I0526 11:04:38.595034 15117 solver.cpp:233] Iteration 53580, loss = 0.0129581
I0526 11:04:38.595087 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0129583 (* 1 = 0.0129583 loss)
I0526 11:04:38.595093 15117 sgd_solver.cpp:294] Iteration 53580, lr = 0.0002
I0526 11:04:44.880100 15117 solver.cpp:233] Iteration 53590, loss = 0.00531366
I0526 11:04:44.880141 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00531389 (* 1 = 0.00531389 loss)
I0526 11:04:44.880146 15117 sgd_solver.cpp:294] Iteration 53590, lr = 0.0002
I0526 11:04:50.571516 15117 solver.cpp:342] Iteration 53600, Testing net (#0)
I0526 11:05:03.348502 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9033
I0526 11:05:03.348785 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.460473 (* 1 = 0.460473 loss)
I0526 11:05:03.947008 15117 solver.cpp:233] Iteration 53600, loss = 0.011278
I0526 11:05:03.947054 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0112782 (* 1 = 0.0112782 loss)
I0526 11:05:03.947062 15117 sgd_solver.cpp:294] Iteration 53600, lr = 0.0002
I0526 11:05:10.232043 15117 solver.cpp:233] Iteration 53610, loss = 0.0324676
I0526 11:05:10.232085 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0324679 (* 1 = 0.0324679 loss)
I0526 11:05:10.232092 15117 sgd_solver.cpp:294] Iteration 53610, lr = 0.0002
I0526 11:05:16.523566 15117 solver.cpp:233] Iteration 53620, loss = 0.0146261
I0526 11:05:16.523609 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0146263 (* 1 = 0.0146263 loss)
I0526 11:05:16.523617 15117 sgd_solver.cpp:294] Iteration 53620, lr = 0.0002
I0526 11:05:22.812121 15117 solver.cpp:233] Iteration 53630, loss = 0.00929149
I0526 11:05:22.812161 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00929172 (* 1 = 0.00929172 loss)
I0526 11:05:22.812168 15117 sgd_solver.cpp:294] Iteration 53630, lr = 0.0002
I0526 11:05:29.101526 15117 solver.cpp:233] Iteration 53640, loss = 0.010676
I0526 11:05:29.101565 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0106762 (* 1 = 0.0106762 loss)
I0526 11:05:29.101572 15117 sgd_solver.cpp:294] Iteration 53640, lr = 0.0002
I0526 11:05:35.389817 15117 solver.cpp:233] Iteration 53650, loss = 0.0178023
I0526 11:05:35.390033 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0178026 (* 1 = 0.0178026 loss)
I0526 11:05:35.390064 15117 sgd_solver.cpp:294] Iteration 53650, lr = 0.0002
I0526 11:05:41.682402 15117 solver.cpp:233] Iteration 53660, loss = 0.0142733
I0526 11:05:41.682446 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0142735 (* 1 = 0.0142735 loss)
I0526 11:05:41.682453 15117 sgd_solver.cpp:294] Iteration 53660, lr = 0.0002
I0526 11:05:47.971710 15117 solver.cpp:233] Iteration 53670, loss = 0.00566749
I0526 11:05:47.971753 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00566771 (* 1 = 0.00566771 loss)
I0526 11:05:47.971761 15117 sgd_solver.cpp:294] Iteration 53670, lr = 0.0002
I0526 11:05:54.261337 15117 solver.cpp:233] Iteration 53680, loss = 0.00589093
I0526 11:05:54.261379 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00589115 (* 1 = 0.00589115 loss)
I0526 11:05:54.261385 15117 sgd_solver.cpp:294] Iteration 53680, lr = 0.0002
I0526 11:06:00.551134 15117 solver.cpp:233] Iteration 53690, loss = 0.00505034
I0526 11:06:00.551182 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00505056 (* 1 = 0.00505056 loss)
I0526 11:06:00.551190 15117 sgd_solver.cpp:294] Iteration 53690, lr = 0.0002
I0526 11:06:06.244684 15117 solver.cpp:342] Iteration 53700, Testing net (#0)
I0526 11:06:19.032407 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9048
I0526 11:06:19.032454 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.455956 (* 1 = 0.455956 loss)
I0526 11:06:19.629950 15117 solver.cpp:233] Iteration 53700, loss = 0.0196729
I0526 11:06:19.629989 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0196732 (* 1 = 0.0196732 loss)
I0526 11:06:19.629997 15117 sgd_solver.cpp:294] Iteration 53700, lr = 0.0002
I0526 11:06:25.919617 15117 solver.cpp:233] Iteration 53710, loss = 0.00910405
I0526 11:06:25.919658 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00910427 (* 1 = 0.00910427 loss)
I0526 11:06:25.919666 15117 sgd_solver.cpp:294] Iteration 53710, lr = 0.0002
I0526 11:06:32.210261 15117 solver.cpp:233] Iteration 53720, loss = 0.0296768
I0526 11:06:32.210305 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0296771 (* 1 = 0.0296771 loss)
I0526 11:06:32.210312 15117 sgd_solver.cpp:294] Iteration 53720, lr = 0.0002
I0526 11:06:38.500524 15117 solver.cpp:233] Iteration 53730, loss = 0.00243828
I0526 11:06:38.500777 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00243851 (* 1 = 0.00243851 loss)
I0526 11:06:38.500816 15117 sgd_solver.cpp:294] Iteration 53730, lr = 0.0002
I0526 11:06:44.794976 15117 solver.cpp:233] Iteration 53740, loss = 0.0447051
I0526 11:06:44.795020 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0447053 (* 1 = 0.0447053 loss)
I0526 11:06:44.795027 15117 sgd_solver.cpp:294] Iteration 53740, lr = 0.0002
I0526 11:06:51.086731 15117 solver.cpp:233] Iteration 53750, loss = 0.0233106
I0526 11:06:51.086778 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0233108 (* 1 = 0.0233108 loss)
I0526 11:06:51.086786 15117 sgd_solver.cpp:294] Iteration 53750, lr = 0.0002
I0526 11:06:57.374331 15117 solver.cpp:233] Iteration 53760, loss = 0.0104433
I0526 11:06:57.374388 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0104435 (* 1 = 0.0104435 loss)
I0526 11:06:57.374397 15117 sgd_solver.cpp:294] Iteration 53760, lr = 0.0002
I0526 11:07:03.660415 15117 solver.cpp:233] Iteration 53770, loss = 0.00219473
I0526 11:07:03.660459 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00219495 (* 1 = 0.00219495 loss)
I0526 11:07:03.660465 15117 sgd_solver.cpp:294] Iteration 53770, lr = 0.0002
I0526 11:07:09.950305 15117 solver.cpp:233] Iteration 53780, loss = 0.0189141
I0526 11:07:09.950433 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0189143 (* 1 = 0.0189143 loss)
I0526 11:07:09.950441 15117 sgd_solver.cpp:294] Iteration 53780, lr = 0.0002
I0526 11:07:16.240200 15117 solver.cpp:233] Iteration 53790, loss = 0.00451454
I0526 11:07:16.240244 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00451476 (* 1 = 0.00451476 loss)
I0526 11:07:16.240252 15117 sgd_solver.cpp:294] Iteration 53790, lr = 0.0002
I0526 11:07:21.931344 15117 solver.cpp:342] Iteration 53800, Testing net (#0)
I0526 11:07:34.715694 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9048
I0526 11:07:34.715739 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.440558 (* 1 = 0.440558 loss)
I0526 11:07:35.312651 15117 solver.cpp:233] Iteration 53800, loss = 0.00908578
I0526 11:07:35.312691 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.009086 (* 1 = 0.009086 loss)
I0526 11:07:35.312698 15117 sgd_solver.cpp:294] Iteration 53800, lr = 0.0002
I0526 11:07:41.603549 15117 solver.cpp:233] Iteration 53810, loss = 0.0039298
I0526 11:07:41.603752 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00393002 (* 1 = 0.00393002 loss)
I0526 11:07:41.603780 15117 sgd_solver.cpp:294] Iteration 53810, lr = 0.0002
I0526 11:07:47.895279 15117 solver.cpp:233] Iteration 53820, loss = 0.0157768
I0526 11:07:47.895324 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.015777 (* 1 = 0.015777 loss)
I0526 11:07:47.895331 15117 sgd_solver.cpp:294] Iteration 53820, lr = 0.0002
I0526 11:07:54.185184 15117 solver.cpp:233] Iteration 53830, loss = 0.0135433
I0526 11:07:54.185225 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0135435 (* 1 = 0.0135435 loss)
I0526 11:07:54.185231 15117 sgd_solver.cpp:294] Iteration 53830, lr = 0.0002
I0526 11:08:00.471421 15117 solver.cpp:233] Iteration 53840, loss = 0.0243439
I0526 11:08:00.471469 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0243441 (* 1 = 0.0243441 loss)
I0526 11:08:00.471477 15117 sgd_solver.cpp:294] Iteration 53840, lr = 0.0002
I0526 11:08:06.757843 15117 solver.cpp:233] Iteration 53850, loss = 0.0238919
I0526 11:08:06.757885 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0238921 (* 1 = 0.0238921 loss)
I0526 11:08:06.757892 15117 sgd_solver.cpp:294] Iteration 53850, lr = 0.0002
I0526 11:08:13.042857 15117 solver.cpp:233] Iteration 53860, loss = 0.00410804
I0526 11:08:13.042973 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00410827 (* 1 = 0.00410827 loss)
I0526 11:08:13.042981 15117 sgd_solver.cpp:294] Iteration 53860, lr = 0.0002
I0526 11:08:19.333168 15117 solver.cpp:233] Iteration 53870, loss = 0.0226325
I0526 11:08:19.333220 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0226328 (* 1 = 0.0226328 loss)
I0526 11:08:19.333226 15117 sgd_solver.cpp:294] Iteration 53870, lr = 0.0002
I0526 11:08:25.622493 15117 solver.cpp:233] Iteration 53880, loss = 0.00515411
I0526 11:08:25.622526 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00515434 (* 1 = 0.00515434 loss)
I0526 11:08:25.622534 15117 sgd_solver.cpp:294] Iteration 53880, lr = 0.0002
I0526 11:08:31.911800 15117 solver.cpp:233] Iteration 53890, loss = 0.0136672
I0526 11:08:31.911844 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0136674 (* 1 = 0.0136674 loss)
I0526 11:08:31.911850 15117 sgd_solver.cpp:294] Iteration 53890, lr = 0.0002
I0526 11:08:37.601825 15117 solver.cpp:342] Iteration 53900, Testing net (#0)
I0526 11:08:50.384506 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9054
I0526 11:08:50.384755 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.451585 (* 1 = 0.451585 loss)
I0526 11:08:50.983434 15117 solver.cpp:233] Iteration 53900, loss = 0.0183003
I0526 11:08:50.983479 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0183005 (* 1 = 0.0183005 loss)
I0526 11:08:50.983489 15117 sgd_solver.cpp:294] Iteration 53900, lr = 0.0002
I0526 11:08:57.272948 15117 solver.cpp:233] Iteration 53910, loss = 0.00610016
I0526 11:08:57.272989 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00610038 (* 1 = 0.00610038 loss)
I0526 11:08:57.272994 15117 sgd_solver.cpp:294] Iteration 53910, lr = 0.0002
I0526 11:09:03.559340 15117 solver.cpp:233] Iteration 53920, loss = 0.0113896
I0526 11:09:03.559384 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0113898 (* 1 = 0.0113898 loss)
I0526 11:09:03.559391 15117 sgd_solver.cpp:294] Iteration 53920, lr = 0.0002
I0526 11:09:09.845939 15117 solver.cpp:233] Iteration 53930, loss = 0.0075167
I0526 11:09:09.845980 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00751692 (* 1 = 0.00751692 loss)
I0526 11:09:09.845988 15117 sgd_solver.cpp:294] Iteration 53930, lr = 0.0002
I0526 11:09:16.136386 15117 solver.cpp:233] Iteration 53940, loss = 0.00366271
I0526 11:09:16.136430 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00366294 (* 1 = 0.00366294 loss)
I0526 11:09:16.136436 15117 sgd_solver.cpp:294] Iteration 53940, lr = 0.0002
I0526 11:09:22.426898 15117 solver.cpp:233] Iteration 53950, loss = 0.0100105
I0526 11:09:22.427106 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0100108 (* 1 = 0.0100108 loss)
I0526 11:09:22.427135 15117 sgd_solver.cpp:294] Iteration 53950, lr = 0.0002
I0526 11:09:28.718783 15117 solver.cpp:233] Iteration 53960, loss = 0.0375802
I0526 11:09:28.718812 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0375804 (* 1 = 0.0375804 loss)
I0526 11:09:28.718819 15117 sgd_solver.cpp:294] Iteration 53960, lr = 0.0002
I0526 11:09:35.007149 15117 solver.cpp:233] Iteration 53970, loss = 0.0219711
I0526 11:09:35.007192 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0219713 (* 1 = 0.0219713 loss)
I0526 11:09:35.007200 15117 sgd_solver.cpp:294] Iteration 53970, lr = 0.0002
I0526 11:09:41.295949 15117 solver.cpp:233] Iteration 53980, loss = 0.0237234
I0526 11:09:41.295990 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0237237 (* 1 = 0.0237237 loss)
I0526 11:09:41.295996 15117 sgd_solver.cpp:294] Iteration 53980, lr = 0.0002
I0526 11:09:47.587290 15117 solver.cpp:233] Iteration 53990, loss = 0.00878301
I0526 11:09:47.587332 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00878323 (* 1 = 0.00878323 loss)
I0526 11:09:47.587339 15117 sgd_solver.cpp:294] Iteration 53990, lr = 0.0002
I0526 11:09:53.280746 15117 solver.cpp:342] Iteration 54000, Testing net (#0)
I0526 11:10:06.070797 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9057
I0526 11:10:06.070842 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.454896 (* 1 = 0.454896 loss)
I0526 11:10:06.667779 15117 solver.cpp:233] Iteration 54000, loss = 0.0175075
I0526 11:10:06.667820 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0175078 (* 1 = 0.0175078 loss)
I0526 11:10:06.667829 15117 sgd_solver.cpp:294] Iteration 54000, lr = 0.0002
I0526 11:10:12.956781 15117 solver.cpp:233] Iteration 54010, loss = 0.023077
I0526 11:10:12.956823 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0230772 (* 1 = 0.0230772 loss)
I0526 11:10:12.956830 15117 sgd_solver.cpp:294] Iteration 54010, lr = 0.0002
I0526 11:10:19.246656 15117 solver.cpp:233] Iteration 54020, loss = 0.00506525
I0526 11:10:19.246711 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00506548 (* 1 = 0.00506548 loss)
I0526 11:10:19.246718 15117 sgd_solver.cpp:294] Iteration 54020, lr = 0.0002
I0526 11:10:25.531493 15117 solver.cpp:233] Iteration 54030, loss = 0.00203745
I0526 11:10:25.531716 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00203767 (* 1 = 0.00203767 loss)
I0526 11:10:25.531746 15117 sgd_solver.cpp:294] Iteration 54030, lr = 0.0002
I0526 11:10:31.823106 15117 solver.cpp:233] Iteration 54040, loss = 0.0100157
I0526 11:10:31.823137 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0100159 (* 1 = 0.0100159 loss)
I0526 11:10:31.823144 15117 sgd_solver.cpp:294] Iteration 54040, lr = 0.0002
I0526 11:10:38.112350 15117 solver.cpp:233] Iteration 54050, loss = 0.00616307
I0526 11:10:38.112391 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00616329 (* 1 = 0.00616329 loss)
I0526 11:10:38.112398 15117 sgd_solver.cpp:294] Iteration 54050, lr = 0.0002
I0526 11:10:44.401994 15117 solver.cpp:233] Iteration 54060, loss = 0.00544463
I0526 11:10:44.402039 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00544485 (* 1 = 0.00544485 loss)
I0526 11:10:44.402045 15117 sgd_solver.cpp:294] Iteration 54060, lr = 0.0002
I0526 11:10:50.693236 15117 solver.cpp:233] Iteration 54070, loss = 0.0161516
I0526 11:10:50.693279 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0161518 (* 1 = 0.0161518 loss)
I0526 11:10:50.693286 15117 sgd_solver.cpp:294] Iteration 54070, lr = 0.0002
I0526 11:10:56.982712 15117 solver.cpp:233] Iteration 54080, loss = 0.00823364
I0526 11:10:56.982905 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00823387 (* 1 = 0.00823387 loss)
I0526 11:10:56.982935 15117 sgd_solver.cpp:294] Iteration 54080, lr = 0.0002
I0526 11:11:03.276520 15117 solver.cpp:233] Iteration 54090, loss = 0.0166633
I0526 11:11:03.276564 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0166635 (* 1 = 0.0166635 loss)
I0526 11:11:03.276572 15117 sgd_solver.cpp:294] Iteration 54090, lr = 0.0002
I0526 11:11:08.968632 15117 solver.cpp:342] Iteration 54100, Testing net (#0)
I0526 11:11:21.742718 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9064
I0526 11:11:21.742761 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.437304 (* 1 = 0.437304 loss)
I0526 11:11:22.338992 15117 solver.cpp:233] Iteration 54100, loss = 0.0333473
I0526 11:11:22.339030 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0333475 (* 1 = 0.0333475 loss)
I0526 11:11:22.339035 15117 sgd_solver.cpp:294] Iteration 54100, lr = 0.0002
I0526 11:11:28.630748 15117 solver.cpp:233] Iteration 54110, loss = 0.00916619
I0526 11:11:28.630964 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00916642 (* 1 = 0.00916642 loss)
I0526 11:11:28.630995 15117 sgd_solver.cpp:294] Iteration 54110, lr = 0.0002
I0526 11:11:34.918303 15117 solver.cpp:233] Iteration 54120, loss = 0.0167691
I0526 11:11:34.918334 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0167694 (* 1 = 0.0167694 loss)
I0526 11:11:34.918340 15117 sgd_solver.cpp:294] Iteration 54120, lr = 0.0002
I0526 11:11:41.209425 15117 solver.cpp:233] Iteration 54130, loss = 0.0113155
I0526 11:11:41.209465 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0113157 (* 1 = 0.0113157 loss)
I0526 11:11:41.209477 15117 sgd_solver.cpp:294] Iteration 54130, lr = 0.0002
I0526 11:11:47.500504 15117 solver.cpp:233] Iteration 54140, loss = 0.013406
I0526 11:11:47.500546 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0134062 (* 1 = 0.0134062 loss)
I0526 11:11:47.500552 15117 sgd_solver.cpp:294] Iteration 54140, lr = 0.0002
I0526 11:11:53.790910 15117 solver.cpp:233] Iteration 54150, loss = 0.0110652
I0526 11:11:53.790952 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0110654 (* 1 = 0.0110654 loss)
I0526 11:11:53.790959 15117 sgd_solver.cpp:294] Iteration 54150, lr = 0.0002
I0526 11:12:00.079211 15117 solver.cpp:233] Iteration 54160, loss = 0.00818862
I0526 11:12:00.079458 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00818884 (* 1 = 0.00818884 loss)
I0526 11:12:00.079488 15117 sgd_solver.cpp:294] Iteration 54160, lr = 0.0002
I0526 11:12:06.371259 15117 solver.cpp:233] Iteration 54170, loss = 0.0104632
I0526 11:12:06.371302 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0104634 (* 1 = 0.0104634 loss)
I0526 11:12:06.371309 15117 sgd_solver.cpp:294] Iteration 54170, lr = 0.0002
I0526 11:12:12.660166 15117 solver.cpp:233] Iteration 54180, loss = 0.0077834
I0526 11:12:12.660207 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00778361 (* 1 = 0.00778361 loss)
I0526 11:12:12.660214 15117 sgd_solver.cpp:294] Iteration 54180, lr = 0.0002
I0526 11:12:18.947968 15117 solver.cpp:233] Iteration 54190, loss = 0.00692348
I0526 11:12:18.948014 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0069237 (* 1 = 0.0069237 loss)
I0526 11:12:18.948020 15117 sgd_solver.cpp:294] Iteration 54190, lr = 0.0002
I0526 11:12:24.639065 15117 solver.cpp:342] Iteration 54200, Testing net (#0)
I0526 11:12:37.422933 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9036
I0526 11:12:37.423161 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.449318 (* 1 = 0.449318 loss)
I0526 11:12:38.020790 15117 solver.cpp:233] Iteration 54200, loss = 0.00248532
I0526 11:12:38.020829 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00248553 (* 1 = 0.00248553 loss)
I0526 11:12:38.020836 15117 sgd_solver.cpp:294] Iteration 54200, lr = 0.0002
I0526 11:12:44.309049 15117 solver.cpp:233] Iteration 54210, loss = 0.0064347
I0526 11:12:44.309078 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00643492 (* 1 = 0.00643492 loss)
I0526 11:12:44.309085 15117 sgd_solver.cpp:294] Iteration 54210, lr = 0.0002
I0526 11:12:50.599450 15117 solver.cpp:233] Iteration 54220, loss = 0.00325974
I0526 11:12:50.599491 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00325996 (* 1 = 0.00325996 loss)
I0526 11:12:50.599498 15117 sgd_solver.cpp:294] Iteration 54220, lr = 0.0002
I0526 11:12:56.887892 15117 solver.cpp:233] Iteration 54230, loss = 0.010091
I0526 11:12:56.887938 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0100912 (* 1 = 0.0100912 loss)
I0526 11:12:56.887944 15117 sgd_solver.cpp:294] Iteration 54230, lr = 0.0002
I0526 11:13:03.177935 15117 solver.cpp:233] Iteration 54240, loss = 0.00491426
I0526 11:13:03.177978 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00491447 (* 1 = 0.00491447 loss)
I0526 11:13:03.177984 15117 sgd_solver.cpp:294] Iteration 54240, lr = 0.0002
I0526 11:13:09.466404 15117 solver.cpp:233] Iteration 54250, loss = 0.00340405
I0526 11:13:09.466601 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00340427 (* 1 = 0.00340427 loss)
I0526 11:13:09.466627 15117 sgd_solver.cpp:294] Iteration 54250, lr = 0.0002
I0526 11:13:15.753795 15117 solver.cpp:233] Iteration 54260, loss = 0.00943249
I0526 11:13:15.753839 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0094327 (* 1 = 0.0094327 loss)
I0526 11:13:15.753846 15117 sgd_solver.cpp:294] Iteration 54260, lr = 0.0002
I0526 11:13:22.038010 15117 solver.cpp:233] Iteration 54270, loss = 0.00489759
I0526 11:13:22.038051 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00489781 (* 1 = 0.00489781 loss)
I0526 11:13:22.038064 15117 sgd_solver.cpp:294] Iteration 54270, lr = 0.0002
I0526 11:13:28.324944 15117 solver.cpp:233] Iteration 54280, loss = 0.0154392
I0526 11:13:28.324987 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0154394 (* 1 = 0.0154394 loss)
I0526 11:13:28.324993 15117 sgd_solver.cpp:294] Iteration 54280, lr = 0.0002
I0526 11:13:34.615502 15117 solver.cpp:233] Iteration 54290, loss = 0.0119515
I0526 11:13:34.615543 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0119518 (* 1 = 0.0119518 loss)
I0526 11:13:34.615550 15117 sgd_solver.cpp:294] Iteration 54290, lr = 0.0002
I0526 11:13:40.310051 15117 solver.cpp:342] Iteration 54300, Testing net (#0)
I0526 11:13:53.081490 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9037
I0526 11:13:53.081531 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.451657 (* 1 = 0.451657 loss)
I0526 11:13:53.678239 15117 solver.cpp:233] Iteration 54300, loss = 0.0102557
I0526 11:13:53.678284 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0102559 (* 1 = 0.0102559 loss)
I0526 11:13:53.678290 15117 sgd_solver.cpp:294] Iteration 54300, lr = 0.0002
I0526 11:13:59.966325 15117 solver.cpp:233] Iteration 54310, loss = 0.0121377
I0526 11:13:59.966380 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0121379 (* 1 = 0.0121379 loss)
I0526 11:13:59.966387 15117 sgd_solver.cpp:294] Iteration 54310, lr = 0.0002
I0526 11:14:06.257051 15117 solver.cpp:233] Iteration 54320, loss = 0.0153555
I0526 11:14:06.257094 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0153557 (* 1 = 0.0153557 loss)
I0526 11:14:06.257102 15117 sgd_solver.cpp:294] Iteration 54320, lr = 0.0002
I0526 11:14:12.545245 15117 solver.cpp:233] Iteration 54330, loss = 0.00400548
I0526 11:14:12.545459 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00400569 (* 1 = 0.00400569 loss)
I0526 11:14:12.545487 15117 sgd_solver.cpp:294] Iteration 54330, lr = 0.0002
I0526 11:14:18.835947 15117 solver.cpp:233] Iteration 54340, loss = 0.00482052
I0526 11:14:18.835989 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00482073 (* 1 = 0.00482073 loss)
I0526 11:14:18.835996 15117 sgd_solver.cpp:294] Iteration 54340, lr = 0.0002
I0526 11:14:25.123718 15117 solver.cpp:233] Iteration 54350, loss = 0.00369603
I0526 11:14:25.123762 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00369624 (* 1 = 0.00369624 loss)
I0526 11:14:25.123770 15117 sgd_solver.cpp:294] Iteration 54350, lr = 0.0002
I0526 11:14:31.413564 15117 solver.cpp:233] Iteration 54360, loss = 0.00464768
I0526 11:14:31.413609 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00464789 (* 1 = 0.00464789 loss)
I0526 11:14:31.413617 15117 sgd_solver.cpp:294] Iteration 54360, lr = 0.0002
I0526 11:14:37.701506 15117 solver.cpp:233] Iteration 54370, loss = 0.00370173
I0526 11:14:37.701548 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00370194 (* 1 = 0.00370194 loss)
I0526 11:14:37.701555 15117 sgd_solver.cpp:294] Iteration 54370, lr = 0.0002
I0526 11:14:43.989574 15117 solver.cpp:233] Iteration 54380, loss = 0.0123866
I0526 11:14:43.989805 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0123868 (* 1 = 0.0123868 loss)
I0526 11:14:43.989835 15117 sgd_solver.cpp:294] Iteration 54380, lr = 0.0002
I0526 11:14:50.280807 15117 solver.cpp:233] Iteration 54390, loss = 0.0161665
I0526 11:14:50.280849 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0161667 (* 1 = 0.0161667 loss)
I0526 11:14:50.280855 15117 sgd_solver.cpp:294] Iteration 54390, lr = 0.0002
I0526 11:14:55.972030 15117 solver.cpp:342] Iteration 54400, Testing net (#0)
I0526 11:15:08.750658 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9047
I0526 11:15:08.750702 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.451874 (* 1 = 0.451874 loss)
I0526 11:15:09.348089 15117 solver.cpp:233] Iteration 54400, loss = 0.0218644
I0526 11:15:09.348132 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0218646 (* 1 = 0.0218646 loss)
I0526 11:15:09.348140 15117 sgd_solver.cpp:294] Iteration 54400, lr = 0.0002
I0526 11:15:15.639046 15117 solver.cpp:233] Iteration 54410, loss = 0.0126066
I0526 11:15:15.639216 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0126068 (* 1 = 0.0126068 loss)
I0526 11:15:15.639225 15117 sgd_solver.cpp:294] Iteration 54410, lr = 0.0002
I0526 11:15:21.925923 15117 solver.cpp:233] Iteration 54420, loss = 0.0084849
I0526 11:15:21.925966 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00848511 (* 1 = 0.00848511 loss)
I0526 11:15:21.925973 15117 sgd_solver.cpp:294] Iteration 54420, lr = 0.0002
I0526 11:15:28.210338 15117 solver.cpp:233] Iteration 54430, loss = 0.00768232
I0526 11:15:28.210407 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00768253 (* 1 = 0.00768253 loss)
I0526 11:15:28.210414 15117 sgd_solver.cpp:294] Iteration 54430, lr = 0.0002
I0526 11:15:34.499943 15117 solver.cpp:233] Iteration 54440, loss = 0.0189035
I0526 11:15:34.499976 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0189037 (* 1 = 0.0189037 loss)
I0526 11:15:34.499982 15117 sgd_solver.cpp:294] Iteration 54440, lr = 0.0002
I0526 11:15:40.788947 15117 solver.cpp:233] Iteration 54450, loss = 0.0135641
I0526 11:15:40.788987 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0135643 (* 1 = 0.0135643 loss)
I0526 11:15:40.788993 15117 sgd_solver.cpp:294] Iteration 54450, lr = 0.0002
I0526 11:15:47.074417 15117 solver.cpp:233] Iteration 54460, loss = 0.00743917
I0526 11:15:47.074662 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00743938 (* 1 = 0.00743938 loss)
I0526 11:15:47.074698 15117 sgd_solver.cpp:294] Iteration 54460, lr = 0.0002
I0526 11:15:53.365825 15117 solver.cpp:233] Iteration 54470, loss = 0.00273612
I0526 11:15:53.365867 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00273633 (* 1 = 0.00273633 loss)
I0526 11:15:53.365875 15117 sgd_solver.cpp:294] Iteration 54470, lr = 0.0002
I0526 11:15:59.655771 15117 solver.cpp:233] Iteration 54480, loss = 0.0040629
I0526 11:15:59.655812 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00406311 (* 1 = 0.00406311 loss)
I0526 11:15:59.655818 15117 sgd_solver.cpp:294] Iteration 54480, lr = 0.0002
I0526 11:16:05.945314 15117 solver.cpp:233] Iteration 54490, loss = 0.0163788
I0526 11:16:05.945343 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.016379 (* 1 = 0.016379 loss)
I0526 11:16:05.945349 15117 sgd_solver.cpp:294] Iteration 54490, lr = 0.0002
I0526 11:16:11.639142 15117 solver.cpp:342] Iteration 54500, Testing net (#0)
I0526 11:16:24.426342 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9048
I0526 11:16:24.426568 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.455159 (* 1 = 0.455159 loss)
I0526 11:16:25.024544 15117 solver.cpp:233] Iteration 54500, loss = 0.00232956
I0526 11:16:25.024592 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00232977 (* 1 = 0.00232977 loss)
I0526 11:16:25.024601 15117 sgd_solver.cpp:294] Iteration 54500, lr = 0.0002
I0526 11:16:31.312994 15117 solver.cpp:233] Iteration 54510, loss = 0.0151599
I0526 11:16:31.313035 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0151601 (* 1 = 0.0151601 loss)
I0526 11:16:31.313042 15117 sgd_solver.cpp:294] Iteration 54510, lr = 0.0002
I0526 11:16:37.598121 15117 solver.cpp:233] Iteration 54520, loss = 0.0176918
I0526 11:16:37.598160 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.017692 (* 1 = 0.017692 loss)
I0526 11:16:37.598167 15117 sgd_solver.cpp:294] Iteration 54520, lr = 0.0002
I0526 11:16:43.890477 15117 solver.cpp:233] Iteration 54530, loss = 0.00804978
I0526 11:16:43.890521 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00804999 (* 1 = 0.00804999 loss)
I0526 11:16:43.890527 15117 sgd_solver.cpp:294] Iteration 54530, lr = 0.0002
I0526 11:16:50.179466 15117 solver.cpp:233] Iteration 54540, loss = 0.00300666
I0526 11:16:50.179508 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00300687 (* 1 = 0.00300687 loss)
I0526 11:16:50.179515 15117 sgd_solver.cpp:294] Iteration 54540, lr = 0.0002
I0526 11:16:56.470077 15117 solver.cpp:233] Iteration 54550, loss = 0.011981
I0526 11:16:56.470181 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0119812 (* 1 = 0.0119812 loss)
I0526 11:16:56.470190 15117 sgd_solver.cpp:294] Iteration 54550, lr = 0.0002
I0526 11:17:02.763712 15117 solver.cpp:233] Iteration 54560, loss = 0.0054397
I0526 11:17:02.763748 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0054399 (* 1 = 0.0054399 loss)
I0526 11:17:02.763754 15117 sgd_solver.cpp:294] Iteration 54560, lr = 0.0002
I0526 11:17:09.054989 15117 solver.cpp:233] Iteration 54570, loss = 0.0141062
I0526 11:17:09.055030 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0141064 (* 1 = 0.0141064 loss)
I0526 11:17:09.055037 15117 sgd_solver.cpp:294] Iteration 54570, lr = 0.0002
I0526 11:17:15.344614 15117 solver.cpp:233] Iteration 54580, loss = 0.00874835
I0526 11:17:15.344653 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00874856 (* 1 = 0.00874856 loss)
I0526 11:17:15.344660 15117 sgd_solver.cpp:294] Iteration 54580, lr = 0.0002
I0526 11:17:21.629613 15117 solver.cpp:233] Iteration 54590, loss = 0.00412535
I0526 11:17:21.629657 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00412556 (* 1 = 0.00412556 loss)
I0526 11:17:21.629663 15117 sgd_solver.cpp:294] Iteration 54590, lr = 0.0002
I0526 11:17:27.320449 15117 solver.cpp:342] Iteration 54600, Testing net (#0)
I0526 11:17:40.104799 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9068
I0526 11:17:40.104849 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.442116 (* 1 = 0.442116 loss)
I0526 11:17:40.701531 15117 solver.cpp:233] Iteration 54600, loss = 0.00840108
I0526 11:17:40.701572 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00840129 (* 1 = 0.00840129 loss)
I0526 11:17:40.701581 15117 sgd_solver.cpp:294] Iteration 54600, lr = 0.0002
I0526 11:17:46.990718 15117 solver.cpp:233] Iteration 54610, loss = 0.0146069
I0526 11:17:46.990767 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0146071 (* 1 = 0.0146071 loss)
I0526 11:17:46.990773 15117 sgd_solver.cpp:294] Iteration 54610, lr = 0.0002
I0526 11:17:53.281003 15117 solver.cpp:233] Iteration 54620, loss = 0.00631581
I0526 11:17:53.281044 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00631602 (* 1 = 0.00631602 loss)
I0526 11:17:53.281049 15117 sgd_solver.cpp:294] Iteration 54620, lr = 0.0002
I0526 11:17:59.567030 15117 solver.cpp:233] Iteration 54630, loss = 0.00842279
I0526 11:17:59.567253 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.008423 (* 1 = 0.008423 loss)
I0526 11:17:59.567281 15117 sgd_solver.cpp:294] Iteration 54630, lr = 0.0002
I0526 11:18:05.859843 15117 solver.cpp:233] Iteration 54640, loss = 0.0184946
I0526 11:18:05.859887 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0184948 (* 1 = 0.0184948 loss)
I0526 11:18:05.859894 15117 sgd_solver.cpp:294] Iteration 54640, lr = 0.0002
I0526 11:18:12.150990 15117 solver.cpp:233] Iteration 54650, loss = 0.0167344
I0526 11:18:12.151031 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0167346 (* 1 = 0.0167346 loss)
I0526 11:18:12.151037 15117 sgd_solver.cpp:294] Iteration 54650, lr = 0.0002
I0526 11:18:18.441090 15117 solver.cpp:233] Iteration 54660, loss = 0.00841215
I0526 11:18:18.441133 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00841236 (* 1 = 0.00841236 loss)
I0526 11:18:18.441140 15117 sgd_solver.cpp:294] Iteration 54660, lr = 0.0002
I0526 11:18:24.732254 15117 solver.cpp:233] Iteration 54670, loss = 0.00990299
I0526 11:18:24.732295 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0099032 (* 1 = 0.0099032 loss)
I0526 11:18:24.732306 15117 sgd_solver.cpp:294] Iteration 54670, lr = 0.0002
I0526 11:18:31.024960 15117 solver.cpp:233] Iteration 54680, loss = 0.0105891
I0526 11:18:31.025063 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0105893 (* 1 = 0.0105893 loss)
I0526 11:18:31.025073 15117 sgd_solver.cpp:294] Iteration 54680, lr = 0.0002
I0526 11:18:37.313004 15117 solver.cpp:233] Iteration 54690, loss = 0.00986253
I0526 11:18:37.313047 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00986274 (* 1 = 0.00986274 loss)
I0526 11:18:37.313055 15117 sgd_solver.cpp:294] Iteration 54690, lr = 0.0002
I0526 11:18:43.002099 15117 solver.cpp:342] Iteration 54700, Testing net (#0)
I0526 11:18:55.788329 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9037
I0526 11:18:55.788378 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.450236 (* 1 = 0.450236 loss)
I0526 11:18:56.385758 15117 solver.cpp:233] Iteration 54700, loss = 0.00501397
I0526 11:18:56.385795 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00501418 (* 1 = 0.00501418 loss)
I0526 11:18:56.385802 15117 sgd_solver.cpp:294] Iteration 54700, lr = 0.0002
I0526 11:19:02.676614 15117 solver.cpp:233] Iteration 54710, loss = 0.0224002
I0526 11:19:02.676820 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0224004 (* 1 = 0.0224004 loss)
I0526 11:19:02.676847 15117 sgd_solver.cpp:294] Iteration 54710, lr = 0.0002
I0526 11:19:08.970613 15117 solver.cpp:233] Iteration 54720, loss = 0.00486604
I0526 11:19:08.970657 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00486625 (* 1 = 0.00486625 loss)
I0526 11:19:08.970664 15117 sgd_solver.cpp:294] Iteration 54720, lr = 0.0002
I0526 11:19:15.262334 15117 solver.cpp:233] Iteration 54730, loss = 0.00246449
I0526 11:19:15.262382 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0024647 (* 1 = 0.0024647 loss)
I0526 11:19:15.262388 15117 sgd_solver.cpp:294] Iteration 54730, lr = 0.0002
I0526 11:19:21.552361 15117 solver.cpp:233] Iteration 54740, loss = 0.00728067
I0526 11:19:21.552402 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00728088 (* 1 = 0.00728088 loss)
I0526 11:19:21.552409 15117 sgd_solver.cpp:294] Iteration 54740, lr = 0.0002
I0526 11:19:27.843904 15117 solver.cpp:233] Iteration 54750, loss = 0.0253073
I0526 11:19:27.843945 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0253075 (* 1 = 0.0253075 loss)
I0526 11:19:27.843951 15117 sgd_solver.cpp:294] Iteration 54750, lr = 0.0002
I0526 11:19:34.135520 15117 solver.cpp:233] Iteration 54760, loss = 0.00794539
I0526 11:19:34.135740 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0079456 (* 1 = 0.0079456 loss)
I0526 11:19:34.135769 15117 sgd_solver.cpp:294] Iteration 54760, lr = 0.0002
I0526 11:19:40.426735 15117 solver.cpp:233] Iteration 54770, loss = 0.00352363
I0526 11:19:40.426780 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00352384 (* 1 = 0.00352384 loss)
I0526 11:19:40.426789 15117 sgd_solver.cpp:294] Iteration 54770, lr = 0.0002
I0526 11:19:46.715636 15117 solver.cpp:233] Iteration 54780, loss = 0.00893864
I0526 11:19:46.715684 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00893884 (* 1 = 0.00893884 loss)
I0526 11:19:46.715692 15117 sgd_solver.cpp:294] Iteration 54780, lr = 0.0002
I0526 11:19:53.004699 15117 solver.cpp:233] Iteration 54790, loss = 0.00355421
I0526 11:19:53.004740 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00355442 (* 1 = 0.00355442 loss)
I0526 11:19:53.004747 15117 sgd_solver.cpp:294] Iteration 54790, lr = 0.0002
I0526 11:19:58.700419 15117 solver.cpp:342] Iteration 54800, Testing net (#0)
I0526 11:20:11.485071 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9061
I0526 11:20:11.485136 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.453737 (* 1 = 0.453737 loss)
I0526 11:20:12.082881 15117 solver.cpp:233] Iteration 54800, loss = 0.0109811
I0526 11:20:12.082918 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0109813 (* 1 = 0.0109813 loss)
I0526 11:20:12.082931 15117 sgd_solver.cpp:294] Iteration 54800, lr = 0.0002
I0526 11:20:18.371242 15117 solver.cpp:233] Iteration 54810, loss = 0.0142692
I0526 11:20:18.371284 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0142694 (* 1 = 0.0142694 loss)
I0526 11:20:18.371291 15117 sgd_solver.cpp:294] Iteration 54810, lr = 0.0002
I0526 11:20:24.658841 15117 solver.cpp:233] Iteration 54820, loss = 0.0147911
I0526 11:20:24.658881 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0147913 (* 1 = 0.0147913 loss)
I0526 11:20:24.658888 15117 sgd_solver.cpp:294] Iteration 54820, lr = 0.0002
I0526 11:20:30.947347 15117 solver.cpp:233] Iteration 54830, loss = 0.00974782
I0526 11:20:30.947386 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00974803 (* 1 = 0.00974803 loss)
I0526 11:20:30.947393 15117 sgd_solver.cpp:294] Iteration 54830, lr = 0.0002
I0526 11:20:37.236744 15117 solver.cpp:233] Iteration 54840, loss = 0.00522771
I0526 11:20:37.236788 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00522792 (* 1 = 0.00522792 loss)
I0526 11:20:37.236794 15117 sgd_solver.cpp:294] Iteration 54840, lr = 0.0002
I0526 11:20:43.522708 15117 solver.cpp:233] Iteration 54850, loss = 0.00329982
I0526 11:20:43.522878 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00330003 (* 1 = 0.00330003 loss)
I0526 11:20:43.522887 15117 sgd_solver.cpp:294] Iteration 54850, lr = 0.0002
I0526 11:20:49.808491 15117 solver.cpp:233] Iteration 54860, loss = 0.0213687
I0526 11:20:49.808537 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0213689 (* 1 = 0.0213689 loss)
I0526 11:20:49.808543 15117 sgd_solver.cpp:294] Iteration 54860, lr = 0.0002
I0526 11:20:56.096654 15117 solver.cpp:233] Iteration 54870, loss = 0.00697816
I0526 11:20:56.096695 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00697837 (* 1 = 0.00697837 loss)
I0526 11:20:56.096701 15117 sgd_solver.cpp:294] Iteration 54870, lr = 0.0002
I0526 11:21:02.385344 15117 solver.cpp:233] Iteration 54880, loss = 0.0275282
I0526 11:21:02.385390 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0275284 (* 1 = 0.0275284 loss)
I0526 11:21:02.385396 15117 sgd_solver.cpp:294] Iteration 54880, lr = 0.0002
I0526 11:21:08.672205 15117 solver.cpp:233] Iteration 54890, loss = 0.00560469
I0526 11:21:08.672245 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0056049 (* 1 = 0.0056049 loss)
I0526 11:21:08.672252 15117 sgd_solver.cpp:294] Iteration 54890, lr = 0.0002
I0526 11:21:14.366387 15117 solver.cpp:342] Iteration 54900, Testing net (#0)
I0526 11:21:27.157773 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9049
I0526 11:21:27.157815 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.447142 (* 1 = 0.447142 loss)
I0526 11:21:27.755650 15117 solver.cpp:233] Iteration 54900, loss = 0.0162947
I0526 11:21:27.755687 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0162949 (* 1 = 0.0162949 loss)
I0526 11:21:27.755694 15117 sgd_solver.cpp:294] Iteration 54900, lr = 0.0002
I0526 11:21:34.046031 15117 solver.cpp:233] Iteration 54910, loss = 0.0157615
I0526 11:21:34.046072 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0157617 (* 1 = 0.0157617 loss)
I0526 11:21:34.046078 15117 sgd_solver.cpp:294] Iteration 54910, lr = 0.0002
I0526 11:21:40.333606 15117 solver.cpp:233] Iteration 54920, loss = 0.00384857
I0526 11:21:40.333631 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00384878 (* 1 = 0.00384878 loss)
I0526 11:21:40.333638 15117 sgd_solver.cpp:294] Iteration 54920, lr = 0.0002
I0526 11:21:46.621904 15117 solver.cpp:233] Iteration 54930, loss = 0.020107
I0526 11:21:46.622110 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0201072 (* 1 = 0.0201072 loss)
I0526 11:21:46.622139 15117 sgd_solver.cpp:294] Iteration 54930, lr = 0.0002
I0526 11:21:52.912829 15117 solver.cpp:233] Iteration 54940, loss = 0.00366479
I0526 11:21:52.912880 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00366499 (* 1 = 0.00366499 loss)
I0526 11:21:52.912888 15117 sgd_solver.cpp:294] Iteration 54940, lr = 0.0002
I0526 11:21:59.202500 15117 solver.cpp:233] Iteration 54950, loss = 0.0240832
I0526 11:21:59.202543 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0240834 (* 1 = 0.0240834 loss)
I0526 11:21:59.202550 15117 sgd_solver.cpp:294] Iteration 54950, lr = 0.0002
I0526 11:22:05.493955 15117 solver.cpp:233] Iteration 54960, loss = 0.00672221
I0526 11:22:05.493999 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00672241 (* 1 = 0.00672241 loss)
I0526 11:22:05.494006 15117 sgd_solver.cpp:294] Iteration 54960, lr = 0.0002
I0526 11:22:11.788259 15117 solver.cpp:233] Iteration 54970, loss = 0.00239903
I0526 11:22:11.788302 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00239924 (* 1 = 0.00239924 loss)
I0526 11:22:11.788310 15117 sgd_solver.cpp:294] Iteration 54970, lr = 0.0002
I0526 11:22:18.077461 15117 solver.cpp:233] Iteration 54980, loss = 0.0125667
I0526 11:22:18.077728 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0125669 (* 1 = 0.0125669 loss)
I0526 11:22:18.077762 15117 sgd_solver.cpp:294] Iteration 54980, lr = 0.0002
I0526 11:22:24.371763 15117 solver.cpp:233] Iteration 54990, loss = 0.00457439
I0526 11:22:24.371805 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0045746 (* 1 = 0.0045746 loss)
I0526 11:22:24.371812 15117 sgd_solver.cpp:294] Iteration 54990, lr = 0.0002
I0526 11:22:30.063809 15117 solver.cpp:342] Iteration 55000, Testing net (#0)
I0526 11:22:42.842021 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.903
I0526 11:22:42.842066 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.462438 (* 1 = 0.462438 loss)
I0526 11:22:43.438442 15117 solver.cpp:233] Iteration 55000, loss = 0.00970861
I0526 11:22:43.438477 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00970881 (* 1 = 0.00970881 loss)
I0526 11:22:43.438483 15117 sgd_solver.cpp:294] Iteration 55000, lr = 0.0002
I0526 11:22:49.729825 15117 solver.cpp:233] Iteration 55010, loss = 0.00483371
I0526 11:22:49.730029 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00483391 (* 1 = 0.00483391 loss)
I0526 11:22:49.730057 15117 sgd_solver.cpp:294] Iteration 55010, lr = 0.0002
I0526 11:22:56.017060 15117 solver.cpp:233] Iteration 55020, loss = 0.00529411
I0526 11:22:56.017103 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00529432 (* 1 = 0.00529432 loss)
I0526 11:22:56.017110 15117 sgd_solver.cpp:294] Iteration 55020, lr = 0.0002
I0526 11:23:02.302417 15117 solver.cpp:233] Iteration 55030, loss = 0.0269978
I0526 11:23:02.302458 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.026998 (* 1 = 0.026998 loss)
I0526 11:23:02.302464 15117 sgd_solver.cpp:294] Iteration 55030, lr = 0.0002
I0526 11:23:08.589988 15117 solver.cpp:233] Iteration 55040, loss = 0.02037
I0526 11:23:08.590029 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0203702 (* 1 = 0.0203702 loss)
I0526 11:23:08.590035 15117 sgd_solver.cpp:294] Iteration 55040, lr = 0.0002
I0526 11:23:14.882400 15117 solver.cpp:233] Iteration 55050, loss = 0.00897434
I0526 11:23:14.882446 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00897455 (* 1 = 0.00897455 loss)
I0526 11:23:14.882453 15117 sgd_solver.cpp:294] Iteration 55050, lr = 0.0002
I0526 11:23:21.172937 15117 solver.cpp:233] Iteration 55060, loss = 0.0181274
I0526 11:23:21.173161 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0181276 (* 1 = 0.0181276 loss)
I0526 11:23:21.173192 15117 sgd_solver.cpp:294] Iteration 55060, lr = 0.0002
I0526 11:23:27.461856 15117 solver.cpp:233] Iteration 55070, loss = 0.00737642
I0526 11:23:27.461899 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00737663 (* 1 = 0.00737663 loss)
I0526 11:23:27.461905 15117 sgd_solver.cpp:294] Iteration 55070, lr = 0.0002
I0526 11:23:33.747992 15117 solver.cpp:233] Iteration 55080, loss = 0.00816832
I0526 11:23:33.748034 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00816853 (* 1 = 0.00816853 loss)
I0526 11:23:33.748041 15117 sgd_solver.cpp:294] Iteration 55080, lr = 0.0002
I0526 11:23:40.040750 15117 solver.cpp:233] Iteration 55090, loss = 0.0193645
I0526 11:23:40.040794 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0193647 (* 1 = 0.0193647 loss)
I0526 11:23:40.040802 15117 sgd_solver.cpp:294] Iteration 55090, lr = 0.0002
I0526 11:23:45.732604 15117 solver.cpp:342] Iteration 55100, Testing net (#0)
I0526 11:23:58.516743 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9047
I0526 11:23:58.517004 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.45199 (* 1 = 0.45199 loss)
I0526 11:23:59.113021 15117 solver.cpp:233] Iteration 55100, loss = 0.0141421
I0526 11:23:59.113061 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0141423 (* 1 = 0.0141423 loss)
I0526 11:23:59.113068 15117 sgd_solver.cpp:294] Iteration 55100, lr = 0.0002
I0526 11:24:05.397289 15117 solver.cpp:233] Iteration 55110, loss = 0.00570637
I0526 11:24:05.397323 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00570657 (* 1 = 0.00570657 loss)
I0526 11:24:05.397330 15117 sgd_solver.cpp:294] Iteration 55110, lr = 0.0002
I0526 11:24:11.685462 15117 solver.cpp:233] Iteration 55120, loss = 0.0230139
I0526 11:24:11.685506 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0230141 (* 1 = 0.0230141 loss)
I0526 11:24:11.685513 15117 sgd_solver.cpp:294] Iteration 55120, lr = 0.0002
I0526 11:24:17.975267 15117 solver.cpp:233] Iteration 55130, loss = 0.00851125
I0526 11:24:17.975306 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00851145 (* 1 = 0.00851145 loss)
I0526 11:24:17.975313 15117 sgd_solver.cpp:294] Iteration 55130, lr = 0.0002
I0526 11:24:24.264575 15117 solver.cpp:233] Iteration 55140, loss = 0.0165075
I0526 11:24:24.264616 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0165077 (* 1 = 0.0165077 loss)
I0526 11:24:24.264622 15117 sgd_solver.cpp:294] Iteration 55140, lr = 0.0002
I0526 11:24:30.550474 15117 solver.cpp:233] Iteration 55150, loss = 0.012201
I0526 11:24:30.550685 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0122012 (* 1 = 0.0122012 loss)
I0526 11:24:30.550719 15117 sgd_solver.cpp:294] Iteration 55150, lr = 0.0002
I0526 11:24:36.842123 15117 solver.cpp:233] Iteration 55160, loss = 0.00662511
I0526 11:24:36.842152 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00662531 (* 1 = 0.00662531 loss)
I0526 11:24:36.842159 15117 sgd_solver.cpp:294] Iteration 55160, lr = 0.0002
I0526 11:24:43.130635 15117 solver.cpp:233] Iteration 55170, loss = 0.00861013
I0526 11:24:43.130676 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00861033 (* 1 = 0.00861033 loss)
I0526 11:24:43.130683 15117 sgd_solver.cpp:294] Iteration 55170, lr = 0.0002
I0526 11:24:49.421864 15117 solver.cpp:233] Iteration 55180, loss = 0.00865795
I0526 11:24:49.421905 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00865815 (* 1 = 0.00865815 loss)
I0526 11:24:49.421911 15117 sgd_solver.cpp:294] Iteration 55180, lr = 0.0002
I0526 11:24:55.712198 15117 solver.cpp:233] Iteration 55190, loss = 0.0147236
I0526 11:24:55.712239 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0147238 (* 1 = 0.0147238 loss)
I0526 11:24:55.712247 15117 sgd_solver.cpp:294] Iteration 55190, lr = 0.0002
I0526 11:25:01.401021 15117 solver.cpp:342] Iteration 55200, Testing net (#0)
I0526 11:25:14.180362 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9053
I0526 11:25:14.180408 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.449391 (* 1 = 0.449391 loss)
I0526 11:25:14.777673 15117 solver.cpp:233] Iteration 55200, loss = 0.00640821
I0526 11:25:14.777706 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00640841 (* 1 = 0.00640841 loss)
I0526 11:25:14.777719 15117 sgd_solver.cpp:294] Iteration 55200, lr = 0.0002
I0526 11:25:21.068505 15117 solver.cpp:233] Iteration 55210, loss = 0.00663269
I0526 11:25:21.068537 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00663289 (* 1 = 0.00663289 loss)
I0526 11:25:21.068544 15117 sgd_solver.cpp:294] Iteration 55210, lr = 0.0002
I0526 11:25:27.359786 15117 solver.cpp:233] Iteration 55220, loss = 0.00779359
I0526 11:25:27.359841 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00779379 (* 1 = 0.00779379 loss)
I0526 11:25:27.359849 15117 sgd_solver.cpp:294] Iteration 55220, lr = 0.0002
I0526 11:25:33.650495 15117 solver.cpp:233] Iteration 55230, loss = 0.0149419
I0526 11:25:33.650717 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0149421 (* 1 = 0.0149421 loss)
I0526 11:25:33.650743 15117 sgd_solver.cpp:294] Iteration 55230, lr = 0.0002
I0526 11:25:39.944293 15117 solver.cpp:233] Iteration 55240, loss = 0.00512707
I0526 11:25:39.944339 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00512727 (* 1 = 0.00512727 loss)
I0526 11:25:39.944345 15117 sgd_solver.cpp:294] Iteration 55240, lr = 0.0002
I0526 11:25:46.235728 15117 solver.cpp:233] Iteration 55250, loss = 0.00586066
I0526 11:25:46.235761 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00586087 (* 1 = 0.00586087 loss)
I0526 11:25:46.235769 15117 sgd_solver.cpp:294] Iteration 55250, lr = 0.0002
I0526 11:25:52.524704 15117 solver.cpp:233] Iteration 55260, loss = 0.00661211
I0526 11:25:52.524745 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00661232 (* 1 = 0.00661232 loss)
I0526 11:25:52.524752 15117 sgd_solver.cpp:294] Iteration 55260, lr = 0.0002
I0526 11:25:58.813380 15117 solver.cpp:233] Iteration 55270, loss = 0.0125709
I0526 11:25:58.813423 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0125711 (* 1 = 0.0125711 loss)
I0526 11:25:58.813429 15117 sgd_solver.cpp:294] Iteration 55270, lr = 0.0002
I0526 11:26:05.097609 15117 solver.cpp:233] Iteration 55280, loss = 0.01918
I0526 11:26:05.097829 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0191802 (* 1 = 0.0191802 loss)
I0526 11:26:05.097861 15117 sgd_solver.cpp:294] Iteration 55280, lr = 0.0002
I0526 11:26:11.384218 15117 solver.cpp:233] Iteration 55290, loss = 0.00718436
I0526 11:26:11.384263 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00718457 (* 1 = 0.00718457 loss)
I0526 11:26:11.384269 15117 sgd_solver.cpp:294] Iteration 55290, lr = 0.0002
I0526 11:26:17.077699 15117 solver.cpp:342] Iteration 55300, Testing net (#0)
I0526 11:26:29.854070 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9032
I0526 11:26:29.854107 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.443027 (* 1 = 0.443027 loss)
I0526 11:26:30.451751 15117 solver.cpp:233] Iteration 55300, loss = 0.00271631
I0526 11:26:30.451784 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00271652 (* 1 = 0.00271652 loss)
I0526 11:26:30.451792 15117 sgd_solver.cpp:294] Iteration 55300, lr = 0.0002
I0526 11:26:36.738227 15117 solver.cpp:233] Iteration 55310, loss = 0.00323309
I0526 11:26:36.738463 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00323329 (* 1 = 0.00323329 loss)
I0526 11:26:36.738502 15117 sgd_solver.cpp:294] Iteration 55310, lr = 0.0002
I0526 11:26:43.028456 15117 solver.cpp:233] Iteration 55320, loss = 0.00716816
I0526 11:26:43.028502 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00716837 (* 1 = 0.00716837 loss)
I0526 11:26:43.028509 15117 sgd_solver.cpp:294] Iteration 55320, lr = 0.0002
I0526 11:26:49.317864 15117 solver.cpp:233] Iteration 55330, loss = 0.00727625
I0526 11:26:49.317904 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00727645 (* 1 = 0.00727645 loss)
I0526 11:26:49.317911 15117 sgd_solver.cpp:294] Iteration 55330, lr = 0.0002
I0526 11:26:55.608337 15117 solver.cpp:233] Iteration 55340, loss = 0.0174004
I0526 11:26:55.608381 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0174007 (* 1 = 0.0174007 loss)
I0526 11:26:55.608395 15117 sgd_solver.cpp:294] Iteration 55340, lr = 0.0002
I0526 11:27:01.894614 15117 solver.cpp:233] Iteration 55350, loss = 0.0215241
I0526 11:27:01.894655 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0215243 (* 1 = 0.0215243 loss)
I0526 11:27:01.894662 15117 sgd_solver.cpp:294] Iteration 55350, lr = 0.0002
I0526 11:27:08.182781 15117 solver.cpp:233] Iteration 55360, loss = 0.00639231
I0526 11:27:08.183035 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00639251 (* 1 = 0.00639251 loss)
I0526 11:27:08.183064 15117 sgd_solver.cpp:294] Iteration 55360, lr = 0.0002
I0526 11:27:14.471252 15117 solver.cpp:233] Iteration 55370, loss = 0.0107738
I0526 11:27:14.471299 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.010774 (* 1 = 0.010774 loss)
I0526 11:27:14.471307 15117 sgd_solver.cpp:294] Iteration 55370, lr = 0.0002
I0526 11:27:20.755679 15117 solver.cpp:233] Iteration 55380, loss = 0.00585362
I0526 11:27:20.755720 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00585382 (* 1 = 0.00585382 loss)
I0526 11:27:20.755728 15117 sgd_solver.cpp:294] Iteration 55380, lr = 0.0002
I0526 11:27:27.045291 15117 solver.cpp:233] Iteration 55390, loss = 0.0127001
I0526 11:27:27.045334 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0127003 (* 1 = 0.0127003 loss)
I0526 11:27:27.045341 15117 sgd_solver.cpp:294] Iteration 55390, lr = 0.0002
I0526 11:27:32.738760 15117 solver.cpp:342] Iteration 55400, Testing net (#0)
I0526 11:27:45.517719 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9052
I0526 11:27:45.517933 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.445242 (* 1 = 0.445242 loss)
I0526 11:27:46.114917 15117 solver.cpp:233] Iteration 55400, loss = 0.00777953
I0526 11:27:46.114956 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00777973 (* 1 = 0.00777973 loss)
I0526 11:27:46.114964 15117 sgd_solver.cpp:294] Iteration 55400, lr = 0.0002
I0526 11:27:52.404675 15117 solver.cpp:233] Iteration 55410, loss = 0.00629347
I0526 11:27:52.404716 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00629367 (* 1 = 0.00629367 loss)
I0526 11:27:52.404723 15117 sgd_solver.cpp:294] Iteration 55410, lr = 0.0002
I0526 11:27:58.694262 15117 solver.cpp:233] Iteration 55420, loss = 0.00890064
I0526 11:27:58.694306 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00890084 (* 1 = 0.00890084 loss)
I0526 11:27:58.694314 15117 sgd_solver.cpp:294] Iteration 55420, lr = 0.0002
I0526 11:28:04.986587 15117 solver.cpp:233] Iteration 55430, loss = 0.013037
I0526 11:28:04.986614 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0130372 (* 1 = 0.0130372 loss)
I0526 11:28:04.986623 15117 sgd_solver.cpp:294] Iteration 55430, lr = 0.0002
I0526 11:28:11.279186 15117 solver.cpp:233] Iteration 55440, loss = 0.00511926
I0526 11:28:11.279229 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00511946 (* 1 = 0.00511946 loss)
I0526 11:28:11.279237 15117 sgd_solver.cpp:294] Iteration 55440, lr = 0.0002
I0526 11:28:17.568328 15117 solver.cpp:233] Iteration 55450, loss = 0.00644897
I0526 11:28:17.568446 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00644917 (* 1 = 0.00644917 loss)
I0526 11:28:17.568455 15117 sgd_solver.cpp:294] Iteration 55450, lr = 0.0002
I0526 11:28:23.859369 15117 solver.cpp:233] Iteration 55460, loss = 0.00933734
I0526 11:28:23.859411 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00933754 (* 1 = 0.00933754 loss)
I0526 11:28:23.859418 15117 sgd_solver.cpp:294] Iteration 55460, lr = 0.0002
I0526 11:28:30.151392 15117 solver.cpp:233] Iteration 55470, loss = 0.00959951
I0526 11:28:30.151434 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00959971 (* 1 = 0.00959971 loss)
I0526 11:28:30.151442 15117 sgd_solver.cpp:294] Iteration 55470, lr = 0.0002
I0526 11:28:36.438151 15117 solver.cpp:233] Iteration 55480, loss = 0.0148583
I0526 11:28:36.438199 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0148585 (* 1 = 0.0148585 loss)
I0526 11:28:36.438205 15117 sgd_solver.cpp:294] Iteration 55480, lr = 0.0002
I0526 11:28:42.730383 15117 solver.cpp:233] Iteration 55490, loss = 0.0130372
I0526 11:28:42.730428 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0130374 (* 1 = 0.0130374 loss)
I0526 11:28:42.730435 15117 sgd_solver.cpp:294] Iteration 55490, lr = 0.0002
I0526 11:28:48.427544 15117 solver.cpp:342] Iteration 55500, Testing net (#0)
I0526 11:29:01.226904 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9041
I0526 11:29:01.226950 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.446899 (* 1 = 0.446899 loss)
I0526 11:29:01.824642 15117 solver.cpp:233] Iteration 55500, loss = 0.0134408
I0526 11:29:01.824684 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.013441 (* 1 = 0.013441 loss)
I0526 11:29:01.824692 15117 sgd_solver.cpp:294] Iteration 55500, lr = 0.0002
I0526 11:29:08.114166 15117 solver.cpp:233] Iteration 55510, loss = 0.0119702
I0526 11:29:08.114205 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0119704 (* 1 = 0.0119704 loss)
I0526 11:29:08.114212 15117 sgd_solver.cpp:294] Iteration 55510, lr = 0.0002
I0526 11:29:14.402238 15117 solver.cpp:233] Iteration 55520, loss = 0.0086122
I0526 11:29:14.402284 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00861241 (* 1 = 0.00861241 loss)
I0526 11:29:14.402292 15117 sgd_solver.cpp:294] Iteration 55520, lr = 0.0002
I0526 11:29:20.691438 15117 solver.cpp:233] Iteration 55530, loss = 0.0228874
I0526 11:29:20.691619 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0228876 (* 1 = 0.0228876 loss)
I0526 11:29:20.691647 15117 sgd_solver.cpp:294] Iteration 55530, lr = 0.0002
I0526 11:29:26.984176 15117 solver.cpp:233] Iteration 55540, loss = 0.0090682
I0526 11:29:26.984221 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00906841 (* 1 = 0.00906841 loss)
I0526 11:29:26.984228 15117 sgd_solver.cpp:294] Iteration 55540, lr = 0.0002
I0526 11:29:33.274049 15117 solver.cpp:233] Iteration 55550, loss = 0.0134816
I0526 11:29:33.274091 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0134818 (* 1 = 0.0134818 loss)
I0526 11:29:33.274098 15117 sgd_solver.cpp:294] Iteration 55550, lr = 0.0002
I0526 11:29:39.560825 15117 solver.cpp:233] Iteration 55560, loss = 0.00840483
I0526 11:29:39.560868 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00840504 (* 1 = 0.00840504 loss)
I0526 11:29:39.560874 15117 sgd_solver.cpp:294] Iteration 55560, lr = 0.0002
I0526 11:29:45.849650 15117 solver.cpp:233] Iteration 55570, loss = 0.0162628
I0526 11:29:45.849694 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.016263 (* 1 = 0.016263 loss)
I0526 11:29:45.849700 15117 sgd_solver.cpp:294] Iteration 55570, lr = 0.0002
I0526 11:29:52.138927 15117 solver.cpp:233] Iteration 55580, loss = 0.00662046
I0526 11:29:52.139111 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00662067 (* 1 = 0.00662067 loss)
I0526 11:29:52.139139 15117 sgd_solver.cpp:294] Iteration 55580, lr = 0.0002
I0526 11:29:58.432566 15117 solver.cpp:233] Iteration 55590, loss = 0.00492024
I0526 11:29:58.432610 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00492044 (* 1 = 0.00492044 loss)
I0526 11:29:58.432616 15117 sgd_solver.cpp:294] Iteration 55590, lr = 0.0002
I0526 11:30:04.124243 15117 solver.cpp:342] Iteration 55600, Testing net (#0)
I0526 11:30:16.906627 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9042
I0526 11:30:16.906673 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.44872 (* 1 = 0.44872 loss)
I0526 11:30:17.503351 15117 solver.cpp:233] Iteration 55600, loss = 0.0291167
I0526 11:30:17.503393 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0291169 (* 1 = 0.0291169 loss)
I0526 11:30:17.503401 15117 sgd_solver.cpp:294] Iteration 55600, lr = 0.0002
I0526 11:30:23.788934 15117 solver.cpp:233] Iteration 55610, loss = 0.0147835
I0526 11:30:23.789189 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0147837 (* 1 = 0.0147837 loss)
I0526 11:30:23.789218 15117 sgd_solver.cpp:294] Iteration 55610, lr = 0.0002
I0526 11:30:30.078891 15117 solver.cpp:233] Iteration 55620, loss = 0.00863527
I0526 11:30:30.078928 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00863547 (* 1 = 0.00863547 loss)
I0526 11:30:30.078935 15117 sgd_solver.cpp:294] Iteration 55620, lr = 0.0002
I0526 11:30:36.369298 15117 solver.cpp:233] Iteration 55630, loss = 0.00446779
I0526 11:30:36.369339 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00446799 (* 1 = 0.00446799 loss)
I0526 11:30:36.369345 15117 sgd_solver.cpp:294] Iteration 55630, lr = 0.0002
I0526 11:30:42.655889 15117 solver.cpp:233] Iteration 55640, loss = 0.0138315
I0526 11:30:42.655932 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0138317 (* 1 = 0.0138317 loss)
I0526 11:30:42.655939 15117 sgd_solver.cpp:294] Iteration 55640, lr = 0.0002
I0526 11:30:48.946115 15117 solver.cpp:233] Iteration 55650, loss = 0.031827
I0526 11:30:48.946156 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0318272 (* 1 = 0.0318272 loss)
I0526 11:30:48.946163 15117 sgd_solver.cpp:294] Iteration 55650, lr = 0.0002
I0526 11:30:55.232942 15117 solver.cpp:233] Iteration 55660, loss = 0.0130776
I0526 11:30:55.233052 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0130778 (* 1 = 0.0130778 loss)
I0526 11:30:55.233059 15117 sgd_solver.cpp:294] Iteration 55660, lr = 0.0002
I0526 11:31:01.522882 15117 solver.cpp:233] Iteration 55670, loss = 0.00576366
I0526 11:31:01.522922 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00576386 (* 1 = 0.00576386 loss)
I0526 11:31:01.522928 15117 sgd_solver.cpp:294] Iteration 55670, lr = 0.0002
I0526 11:31:07.813218 15117 solver.cpp:233] Iteration 55680, loss = 0.010553
I0526 11:31:07.813261 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0105532 (* 1 = 0.0105532 loss)
I0526 11:31:07.813267 15117 sgd_solver.cpp:294] Iteration 55680, lr = 0.0002
I0526 11:31:14.102812 15117 solver.cpp:233] Iteration 55690, loss = 0.0175228
I0526 11:31:14.102855 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.017523 (* 1 = 0.017523 loss)
I0526 11:31:14.102861 15117 sgd_solver.cpp:294] Iteration 55690, lr = 0.0002
I0526 11:31:19.793526 15117 solver.cpp:342] Iteration 55700, Testing net (#0)
I0526 11:31:32.564867 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9043
I0526 11:31:32.565083 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.448558 (* 1 = 0.448558 loss)
I0526 11:31:33.166271 15117 solver.cpp:233] Iteration 55700, loss = 0.00349244
I0526 11:31:33.166333 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00349264 (* 1 = 0.00349264 loss)
I0526 11:31:33.166344 15117 sgd_solver.cpp:294] Iteration 55700, lr = 0.0002
I0526 11:31:39.465832 15117 solver.cpp:233] Iteration 55710, loss = 0.00999297
I0526 11:31:39.465874 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00999317 (* 1 = 0.00999317 loss)
I0526 11:31:39.465881 15117 sgd_solver.cpp:294] Iteration 55710, lr = 0.0002
I0526 11:31:45.756772 15117 solver.cpp:233] Iteration 55720, loss = 0.010653
I0526 11:31:45.756815 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0106532 (* 1 = 0.0106532 loss)
I0526 11:31:45.756821 15117 sgd_solver.cpp:294] Iteration 55720, lr = 0.0002
I0526 11:31:52.046211 15117 solver.cpp:233] Iteration 55730, loss = 0.00302748
I0526 11:31:52.046253 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00302768 (* 1 = 0.00302768 loss)
I0526 11:31:52.046259 15117 sgd_solver.cpp:294] Iteration 55730, lr = 0.0002
I0526 11:31:58.336663 15117 solver.cpp:233] Iteration 55740, loss = 0.019065
I0526 11:31:58.336706 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0190652 (* 1 = 0.0190652 loss)
I0526 11:31:58.336719 15117 sgd_solver.cpp:294] Iteration 55740, lr = 0.0002
I0526 11:32:04.625766 15117 solver.cpp:233] Iteration 55750, loss = 0.00622787
I0526 11:32:04.626014 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00622807 (* 1 = 0.00622807 loss)
I0526 11:32:04.626044 15117 sgd_solver.cpp:294] Iteration 55750, lr = 0.0002
I0526 11:32:10.916872 15117 solver.cpp:233] Iteration 55760, loss = 0.0245441
I0526 11:32:10.916915 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0245443 (* 1 = 0.0245443 loss)
I0526 11:32:10.916921 15117 sgd_solver.cpp:294] Iteration 55760, lr = 0.0002
I0526 11:32:17.208160 15117 solver.cpp:233] Iteration 55770, loss = 0.0357504
I0526 11:32:17.208200 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0357506 (* 1 = 0.0357506 loss)
I0526 11:32:17.208207 15117 sgd_solver.cpp:294] Iteration 55770, lr = 0.0002
I0526 11:32:23.496479 15117 solver.cpp:233] Iteration 55780, loss = 0.00463337
I0526 11:32:23.496523 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00463357 (* 1 = 0.00463357 loss)
I0526 11:32:23.496531 15117 sgd_solver.cpp:294] Iteration 55780, lr = 0.0002
I0526 11:32:29.781276 15117 solver.cpp:233] Iteration 55790, loss = 0.00820438
I0526 11:32:29.781318 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00820457 (* 1 = 0.00820457 loss)
I0526 11:32:29.781325 15117 sgd_solver.cpp:294] Iteration 55790, lr = 0.0002
I0526 11:32:35.468271 15117 solver.cpp:342] Iteration 55800, Testing net (#0)
I0526 11:32:48.257329 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9052
I0526 11:32:48.257376 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.444015 (* 1 = 0.444015 loss)
I0526 11:32:48.854182 15117 solver.cpp:233] Iteration 55800, loss = 0.00471627
I0526 11:32:48.854219 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00471647 (* 1 = 0.00471647 loss)
I0526 11:32:48.854226 15117 sgd_solver.cpp:294] Iteration 55800, lr = 0.0002
I0526 11:32:55.142283 15117 solver.cpp:233] Iteration 55810, loss = 0.00867335
I0526 11:32:55.142324 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00867355 (* 1 = 0.00867355 loss)
I0526 11:32:55.142331 15117 sgd_solver.cpp:294] Iteration 55810, lr = 0.0002
I0526 11:33:01.432725 15117 solver.cpp:233] Iteration 55820, loss = 0.0133177
I0526 11:33:01.432765 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0133179 (* 1 = 0.0133179 loss)
I0526 11:33:01.432771 15117 sgd_solver.cpp:294] Iteration 55820, lr = 0.0002
I0526 11:33:07.726079 15117 solver.cpp:233] Iteration 55830, loss = 0.00671806
I0526 11:33:07.726296 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00671826 (* 1 = 0.00671826 loss)
I0526 11:33:07.726328 15117 sgd_solver.cpp:294] Iteration 55830, lr = 0.0002
I0526 11:33:14.015466 15117 solver.cpp:233] Iteration 55840, loss = 0.00369614
I0526 11:33:14.015507 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00369634 (* 1 = 0.00369634 loss)
I0526 11:33:14.015514 15117 sgd_solver.cpp:294] Iteration 55840, lr = 0.0002
I0526 11:33:20.304672 15117 solver.cpp:233] Iteration 55850, loss = 0.00238741
I0526 11:33:20.304716 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0023876 (* 1 = 0.0023876 loss)
I0526 11:33:20.304723 15117 sgd_solver.cpp:294] Iteration 55850, lr = 0.0002
I0526 11:33:26.591249 15117 solver.cpp:233] Iteration 55860, loss = 0.0101954
I0526 11:33:26.591298 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0101956 (* 1 = 0.0101956 loss)
I0526 11:33:26.591305 15117 sgd_solver.cpp:294] Iteration 55860, lr = 0.0002
I0526 11:33:32.877388 15117 solver.cpp:233] Iteration 55870, loss = 0.00731929
I0526 11:33:32.877430 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00731948 (* 1 = 0.00731948 loss)
I0526 11:33:32.877437 15117 sgd_solver.cpp:294] Iteration 55870, lr = 0.0002
I0526 11:33:39.162657 15117 solver.cpp:233] Iteration 55880, loss = 0.00572795
I0526 11:33:39.162947 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00572814 (* 1 = 0.00572814 loss)
I0526 11:33:39.162992 15117 sgd_solver.cpp:294] Iteration 55880, lr = 0.0002
I0526 11:33:45.454314 15117 solver.cpp:233] Iteration 55890, loss = 0.0106731
I0526 11:33:45.454375 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0106733 (* 1 = 0.0106733 loss)
I0526 11:33:45.454382 15117 sgd_solver.cpp:294] Iteration 55890, lr = 0.0002
I0526 11:33:51.147595 15117 solver.cpp:342] Iteration 55900, Testing net (#0)
I0526 11:34:03.921908 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9081
I0526 11:34:03.921954 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.440806 (* 1 = 0.440806 loss)
I0526 11:34:04.519451 15117 solver.cpp:233] Iteration 55900, loss = 0.00911183
I0526 11:34:04.519490 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00911202 (* 1 = 0.00911202 loss)
I0526 11:34:04.519496 15117 sgd_solver.cpp:294] Iteration 55900, lr = 0.0002
I0526 11:34:10.809813 15117 solver.cpp:233] Iteration 55910, loss = 0.0086558
I0526 11:34:10.810030 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.008656 (* 1 = 0.008656 loss)
I0526 11:34:10.810057 15117 sgd_solver.cpp:294] Iteration 55910, lr = 0.0002
I0526 11:34:17.099815 15117 solver.cpp:233] Iteration 55920, loss = 0.00834186
I0526 11:34:17.099859 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00834205 (* 1 = 0.00834205 loss)
I0526 11:34:17.099866 15117 sgd_solver.cpp:294] Iteration 55920, lr = 0.0002
I0526 11:34:23.391032 15117 solver.cpp:233] Iteration 55930, loss = 0.0253151
I0526 11:34:23.391086 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0253153 (* 1 = 0.0253153 loss)
I0526 11:34:23.391095 15117 sgd_solver.cpp:294] Iteration 55930, lr = 0.0002
I0526 11:34:29.783084 15117 solver.cpp:233] Iteration 55940, loss = 0.00774114
I0526 11:34:29.783129 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00774133 (* 1 = 0.00774133 loss)
I0526 11:34:29.783136 15117 sgd_solver.cpp:294] Iteration 55940, lr = 0.0002
I0526 11:34:36.210207 15117 solver.cpp:233] Iteration 55950, loss = 0.010968
I0526 11:34:36.210249 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0109682 (* 1 = 0.0109682 loss)
I0526 11:34:36.210256 15117 sgd_solver.cpp:294] Iteration 55950, lr = 0.0002
I0526 11:34:42.533439 15117 solver.cpp:233] Iteration 55960, loss = 0.00889983
I0526 11:34:42.533668 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00890003 (* 1 = 0.00890003 loss)
I0526 11:34:42.533699 15117 sgd_solver.cpp:294] Iteration 55960, lr = 0.0002
I0526 11:34:48.847363 15117 solver.cpp:233] Iteration 55970, loss = 0.00528218
I0526 11:34:48.847405 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00528238 (* 1 = 0.00528238 loss)
I0526 11:34:48.847411 15117 sgd_solver.cpp:294] Iteration 55970, lr = 0.0002
I0526 11:34:55.186784 15117 solver.cpp:233] Iteration 55980, loss = 0.00436836
I0526 11:34:55.186827 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00436856 (* 1 = 0.00436856 loss)
I0526 11:34:55.186835 15117 sgd_solver.cpp:294] Iteration 55980, lr = 0.0002
I0526 11:35:01.476337 15117 solver.cpp:233] Iteration 55990, loss = 0.00532101
I0526 11:35:01.476382 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0053212 (* 1 = 0.0053212 loss)
I0526 11:35:01.476390 15117 sgd_solver.cpp:294] Iteration 55990, lr = 0.0002
I0526 11:35:07.166777 15117 solver.cpp:342] Iteration 56000, Testing net (#0)
I0526 11:35:19.946205 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9041
I0526 11:35:19.946316 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.447659 (* 1 = 0.447659 loss)
I0526 11:35:20.542732 15117 solver.cpp:233] Iteration 56000, loss = 0.0135688
I0526 11:35:20.542764 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.013569 (* 1 = 0.013569 loss)
I0526 11:35:20.542771 15117 sgd_solver.cpp:294] Iteration 56000, lr = 0.0002
I0526 11:35:26.829293 15117 solver.cpp:233] Iteration 56010, loss = 0.00273254
I0526 11:35:26.829345 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00273274 (* 1 = 0.00273274 loss)
I0526 11:35:26.829352 15117 sgd_solver.cpp:294] Iteration 56010, lr = 0.0002
I0526 11:35:33.114326 15117 solver.cpp:233] Iteration 56020, loss = 0.00818006
I0526 11:35:33.114382 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00818026 (* 1 = 0.00818026 loss)
I0526 11:35:33.114390 15117 sgd_solver.cpp:294] Iteration 56020, lr = 0.0002
I0526 11:35:39.399248 15117 solver.cpp:233] Iteration 56030, loss = 0.00618604
I0526 11:35:39.399286 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00618623 (* 1 = 0.00618623 loss)
I0526 11:35:39.399293 15117 sgd_solver.cpp:294] Iteration 56030, lr = 0.0002
I0526 11:35:45.686000 15117 solver.cpp:233] Iteration 56040, loss = 0.0040555
I0526 11:35:45.686043 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0040557 (* 1 = 0.0040557 loss)
I0526 11:35:45.686049 15117 sgd_solver.cpp:294] Iteration 56040, lr = 0.0002
I0526 11:35:51.971567 15117 solver.cpp:233] Iteration 56050, loss = 0.00597061
I0526 11:35:51.971837 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0059708 (* 1 = 0.0059708 loss)
I0526 11:35:51.971864 15117 sgd_solver.cpp:294] Iteration 56050, lr = 0.0002
I0526 11:35:58.261639 15117 solver.cpp:233] Iteration 56060, loss = 0.0111717
I0526 11:35:58.261699 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0111719 (* 1 = 0.0111719 loss)
I0526 11:35:58.261706 15117 sgd_solver.cpp:294] Iteration 56060, lr = 0.0002
I0526 11:36:04.545832 15117 solver.cpp:233] Iteration 56070, loss = 0.00855964
I0526 11:36:04.545868 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00855983 (* 1 = 0.00855983 loss)
I0526 11:36:04.545876 15117 sgd_solver.cpp:294] Iteration 56070, lr = 0.0002
I0526 11:36:10.834091 15117 solver.cpp:233] Iteration 56080, loss = 0.00811837
I0526 11:36:10.834131 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00811856 (* 1 = 0.00811856 loss)
I0526 11:36:10.834137 15117 sgd_solver.cpp:294] Iteration 56080, lr = 0.0002
I0526 11:36:17.129557 15117 solver.cpp:233] Iteration 56090, loss = 0.0120762
I0526 11:36:17.129601 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0120764 (* 1 = 0.0120764 loss)
I0526 11:36:17.129608 15117 sgd_solver.cpp:294] Iteration 56090, lr = 0.0002
I0526 11:36:22.843312 15117 solver.cpp:342] Iteration 56100, Testing net (#0)
I0526 11:36:35.648176 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.902
I0526 11:36:35.648221 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.45954 (* 1 = 0.45954 loss)
I0526 11:36:36.245347 15117 solver.cpp:233] Iteration 56100, loss = 0.00891707
I0526 11:36:36.245385 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00891726 (* 1 = 0.00891726 loss)
I0526 11:36:36.245393 15117 sgd_solver.cpp:294] Iteration 56100, lr = 0.0002
I0526 11:36:42.555323 15117 solver.cpp:233] Iteration 56110, loss = 0.0193112
I0526 11:36:42.555356 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0193114 (* 1 = 0.0193114 loss)
I0526 11:36:42.555363 15117 sgd_solver.cpp:294] Iteration 56110, lr = 0.0002
I0526 11:36:48.864032 15117 solver.cpp:233] Iteration 56120, loss = 0.00549868
I0526 11:36:48.864073 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00549887 (* 1 = 0.00549887 loss)
I0526 11:36:48.864079 15117 sgd_solver.cpp:294] Iteration 56120, lr = 0.0002
I0526 11:36:55.177599 15117 solver.cpp:233] Iteration 56130, loss = 0.00340745
I0526 11:36:55.177891 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00340764 (* 1 = 0.00340764 loss)
I0526 11:36:55.177917 15117 sgd_solver.cpp:294] Iteration 56130, lr = 0.0002
I0526 11:37:01.493670 15117 solver.cpp:233] Iteration 56140, loss = 0.00651945
I0526 11:37:01.493715 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00651964 (* 1 = 0.00651964 loss)
I0526 11:37:01.493721 15117 sgd_solver.cpp:294] Iteration 56140, lr = 0.0002
I0526 11:37:07.807687 15117 solver.cpp:233] Iteration 56150, loss = 0.0064538
I0526 11:37:07.807725 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00645399 (* 1 = 0.00645399 loss)
I0526 11:37:07.807734 15117 sgd_solver.cpp:294] Iteration 56150, lr = 0.0002
I0526 11:37:14.183998 15117 solver.cpp:233] Iteration 56160, loss = 0.0105534
I0526 11:37:14.184036 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0105536 (* 1 = 0.0105536 loss)
I0526 11:37:14.184041 15117 sgd_solver.cpp:294] Iteration 56160, lr = 0.0002
I0526 11:37:20.506374 15117 solver.cpp:233] Iteration 56170, loss = 0.0084416
I0526 11:37:20.506417 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00844179 (* 1 = 0.00844179 loss)
I0526 11:37:20.506424 15117 sgd_solver.cpp:294] Iteration 56170, lr = 0.0002
I0526 11:37:26.823624 15117 solver.cpp:233] Iteration 56180, loss = 0.0338077
I0526 11:37:26.823784 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0338079 (* 1 = 0.0338079 loss)
I0526 11:37:26.823793 15117 sgd_solver.cpp:294] Iteration 56180, lr = 0.0002
I0526 11:37:33.138945 15117 solver.cpp:233] Iteration 56190, loss = 0.010077
I0526 11:37:33.138984 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0100772 (* 1 = 0.0100772 loss)
I0526 11:37:33.138991 15117 sgd_solver.cpp:294] Iteration 56190, lr = 0.0002
I0526 11:37:38.856986 15117 solver.cpp:342] Iteration 56200, Testing net (#0)
I0526 11:37:51.700229 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.905
I0526 11:37:51.700271 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.445337 (* 1 = 0.445337 loss)
I0526 11:37:52.301231 15117 solver.cpp:233] Iteration 56200, loss = 0.0119733
I0526 11:37:52.301270 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0119735 (* 1 = 0.0119735 loss)
I0526 11:37:52.301276 15117 sgd_solver.cpp:294] Iteration 56200, lr = 0.0002
I0526 11:37:58.681020 15117 solver.cpp:233] Iteration 56210, loss = 0.00712098
I0526 11:37:58.681264 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00712117 (* 1 = 0.00712117 loss)
I0526 11:37:58.681293 15117 sgd_solver.cpp:294] Iteration 56210, lr = 0.0002
I0526 11:38:05.025255 15117 solver.cpp:233] Iteration 56220, loss = 0.00573816
I0526 11:38:05.025296 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00573834 (* 1 = 0.00573834 loss)
I0526 11:38:05.025303 15117 sgd_solver.cpp:294] Iteration 56220, lr = 0.0002
I0526 11:38:11.360359 15117 solver.cpp:233] Iteration 56230, loss = 0.0066094
I0526 11:38:11.360399 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00660958 (* 1 = 0.00660958 loss)
I0526 11:38:11.360406 15117 sgd_solver.cpp:294] Iteration 56230, lr = 0.0002
I0526 11:38:17.697024 15117 solver.cpp:233] Iteration 56240, loss = 0.0290082
I0526 11:38:17.697072 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0290084 (* 1 = 0.0290084 loss)
I0526 11:38:17.697079 15117 sgd_solver.cpp:294] Iteration 56240, lr = 0.0002
I0526 11:38:24.052700 15117 solver.cpp:233] Iteration 56250, loss = 0.0130476
I0526 11:38:24.052745 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0130478 (* 1 = 0.0130478 loss)
I0526 11:38:24.052753 15117 sgd_solver.cpp:294] Iteration 56250, lr = 0.0002
I0526 11:38:30.398253 15117 solver.cpp:233] Iteration 56260, loss = 0.0144773
I0526 11:38:30.398510 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0144775 (* 1 = 0.0144775 loss)
I0526 11:38:30.398535 15117 sgd_solver.cpp:294] Iteration 56260, lr = 0.0002
I0526 11:38:36.711009 15117 solver.cpp:233] Iteration 56270, loss = 0.00795778
I0526 11:38:36.711050 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00795797 (* 1 = 0.00795797 loss)
I0526 11:38:36.711057 15117 sgd_solver.cpp:294] Iteration 56270, lr = 0.0002
I0526 11:38:42.999235 15117 solver.cpp:233] Iteration 56280, loss = 0.0230272
I0526 11:38:42.999277 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0230274 (* 1 = 0.0230274 loss)
I0526 11:38:42.999290 15117 sgd_solver.cpp:294] Iteration 56280, lr = 0.0002
I0526 11:38:49.285588 15117 solver.cpp:233] Iteration 56290, loss = 0.0239202
I0526 11:38:49.285631 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0239204 (* 1 = 0.0239204 loss)
I0526 11:38:49.285639 15117 sgd_solver.cpp:294] Iteration 56290, lr = 0.0002
I0526 11:38:54.979596 15117 solver.cpp:342] Iteration 56300, Testing net (#0)
I0526 11:39:07.768411 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9044
I0526 11:39:07.768682 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.447702 (* 1 = 0.447702 loss)
I0526 11:39:08.369066 15117 solver.cpp:233] Iteration 56300, loss = 0.00429985
I0526 11:39:08.369130 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00430004 (* 1 = 0.00430004 loss)
I0526 11:39:08.369141 15117 sgd_solver.cpp:294] Iteration 56300, lr = 0.0002
I0526 11:39:14.661926 15117 solver.cpp:233] Iteration 56310, loss = 0.00541423
I0526 11:39:14.661970 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00541441 (* 1 = 0.00541441 loss)
I0526 11:39:14.661978 15117 sgd_solver.cpp:294] Iteration 56310, lr = 0.0002
I0526 11:39:20.950600 15117 solver.cpp:233] Iteration 56320, loss = 0.00556344
I0526 11:39:20.950642 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00556363 (* 1 = 0.00556363 loss)
I0526 11:39:20.950649 15117 sgd_solver.cpp:294] Iteration 56320, lr = 0.0002
I0526 11:39:27.237588 15117 solver.cpp:233] Iteration 56330, loss = 0.0094227
I0526 11:39:27.237635 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00942289 (* 1 = 0.00942289 loss)
I0526 11:39:27.237643 15117 sgd_solver.cpp:294] Iteration 56330, lr = 0.0002
I0526 11:39:33.527042 15117 solver.cpp:233] Iteration 56340, loss = 0.00360569
I0526 11:39:33.527081 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00360588 (* 1 = 0.00360588 loss)
I0526 11:39:33.527087 15117 sgd_solver.cpp:294] Iteration 56340, lr = 0.0002
I0526 11:39:39.818009 15117 solver.cpp:233] Iteration 56350, loss = 0.00293193
I0526 11:39:39.818241 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00293212 (* 1 = 0.00293212 loss)
I0526 11:39:39.818270 15117 sgd_solver.cpp:294] Iteration 56350, lr = 0.0002
I0526 11:39:46.105784 15117 solver.cpp:233] Iteration 56360, loss = 0.0252398
I0526 11:39:46.105829 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.02524 (* 1 = 0.02524 loss)
I0526 11:39:46.105834 15117 sgd_solver.cpp:294] Iteration 56360, lr = 0.0002
I0526 11:39:52.395742 15117 solver.cpp:233] Iteration 56370, loss = 0.00936676
I0526 11:39:52.395783 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00936695 (* 1 = 0.00936695 loss)
I0526 11:39:52.395790 15117 sgd_solver.cpp:294] Iteration 56370, lr = 0.0002
I0526 11:39:58.687836 15117 solver.cpp:233] Iteration 56380, loss = 0.00611246
I0526 11:39:58.687883 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00611265 (* 1 = 0.00611265 loss)
I0526 11:39:58.687891 15117 sgd_solver.cpp:294] Iteration 56380, lr = 0.0002
I0526 11:40:04.975262 15117 solver.cpp:233] Iteration 56390, loss = 0.0137596
I0526 11:40:04.975303 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0137598 (* 1 = 0.0137598 loss)
I0526 11:40:04.975311 15117 sgd_solver.cpp:294] Iteration 56390, lr = 0.0002
I0526 11:40:10.669812 15117 solver.cpp:342] Iteration 56400, Testing net (#0)
I0526 11:40:23.453912 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9078
I0526 11:40:23.453956 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.440025 (* 1 = 0.440025 loss)
I0526 11:40:24.050935 15117 solver.cpp:233] Iteration 56400, loss = 0.00750396
I0526 11:40:24.050976 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00750415 (* 1 = 0.00750415 loss)
I0526 11:40:24.050982 15117 sgd_solver.cpp:294] Iteration 56400, lr = 0.0002
I0526 11:40:30.339536 15117 solver.cpp:233] Iteration 56410, loss = 0.0123814
I0526 11:40:30.339586 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0123816 (* 1 = 0.0123816 loss)
I0526 11:40:30.339593 15117 sgd_solver.cpp:294] Iteration 56410, lr = 0.0002
I0526 11:40:36.627275 15117 solver.cpp:233] Iteration 56420, loss = 0.00722372
I0526 11:40:36.627320 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00722391 (* 1 = 0.00722391 loss)
I0526 11:40:36.627327 15117 sgd_solver.cpp:294] Iteration 56420, lr = 0.0002
I0526 11:40:42.921177 15117 solver.cpp:233] Iteration 56430, loss = 0.00744056
I0526 11:40:42.921429 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00744075 (* 1 = 0.00744075 loss)
I0526 11:40:42.921457 15117 sgd_solver.cpp:294] Iteration 56430, lr = 0.0002
I0526 11:40:49.213793 15117 solver.cpp:233] Iteration 56440, loss = 0.00693193
I0526 11:40:49.213834 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00693212 (* 1 = 0.00693212 loss)
I0526 11:40:49.213840 15117 sgd_solver.cpp:294] Iteration 56440, lr = 0.0002
I0526 11:40:55.504454 15117 solver.cpp:233] Iteration 56450, loss = 0.0410478
I0526 11:40:55.504494 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.041048 (* 1 = 0.041048 loss)
I0526 11:40:55.504501 15117 sgd_solver.cpp:294] Iteration 56450, lr = 0.0002
I0526 11:41:01.793434 15117 solver.cpp:233] Iteration 56460, loss = 0.015341
I0526 11:41:01.793478 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0153412 (* 1 = 0.0153412 loss)
I0526 11:41:01.793484 15117 sgd_solver.cpp:294] Iteration 56460, lr = 0.0002
I0526 11:41:08.079175 15117 solver.cpp:233] Iteration 56470, loss = 0.00270747
I0526 11:41:08.079218 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00270766 (* 1 = 0.00270766 loss)
I0526 11:41:08.079226 15117 sgd_solver.cpp:294] Iteration 56470, lr = 0.0002
I0526 11:41:14.368363 15117 solver.cpp:233] Iteration 56480, loss = 0.00653296
I0526 11:41:14.368526 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00653314 (* 1 = 0.00653314 loss)
I0526 11:41:14.368556 15117 sgd_solver.cpp:294] Iteration 56480, lr = 0.0002
I0526 11:41:20.655136 15117 solver.cpp:233] Iteration 56490, loss = 0.0169878
I0526 11:41:20.655163 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.016988 (* 1 = 0.016988 loss)
I0526 11:41:20.655169 15117 sgd_solver.cpp:294] Iteration 56490, lr = 0.0002
I0526 11:41:26.346667 15117 solver.cpp:342] Iteration 56500, Testing net (#0)
I0526 11:41:39.135498 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9016
I0526 11:41:39.135540 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.457206 (* 1 = 0.457206 loss)
I0526 11:41:39.731050 15117 solver.cpp:233] Iteration 56500, loss = 0.0125117
I0526 11:41:39.731088 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0125119 (* 1 = 0.0125119 loss)
I0526 11:41:39.731096 15117 sgd_solver.cpp:294] Iteration 56500, lr = 0.0002
I0526 11:41:46.019394 15117 solver.cpp:233] Iteration 56510, loss = 0.0179137
I0526 11:41:46.019634 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0179139 (* 1 = 0.0179139 loss)
I0526 11:41:46.019664 15117 sgd_solver.cpp:294] Iteration 56510, lr = 0.0002
I0526 11:41:52.312547 15117 solver.cpp:233] Iteration 56520, loss = 0.0179451
I0526 11:41:52.312592 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0179453 (* 1 = 0.0179453 loss)
I0526 11:41:52.312599 15117 sgd_solver.cpp:294] Iteration 56520, lr = 0.0002
I0526 11:41:58.600208 15117 solver.cpp:233] Iteration 56530, loss = 0.00791184
I0526 11:41:58.600252 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00791203 (* 1 = 0.00791203 loss)
I0526 11:41:58.600260 15117 sgd_solver.cpp:294] Iteration 56530, lr = 0.0002
I0526 11:42:04.886132 15117 solver.cpp:233] Iteration 56540, loss = 0.0060891
I0526 11:42:04.886175 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00608929 (* 1 = 0.00608929 loss)
I0526 11:42:04.886183 15117 sgd_solver.cpp:294] Iteration 56540, lr = 0.0002
I0526 11:42:11.174865 15117 solver.cpp:233] Iteration 56550, loss = 0.00950173
I0526 11:42:11.174911 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00950192 (* 1 = 0.00950192 loss)
I0526 11:42:11.174918 15117 sgd_solver.cpp:294] Iteration 56550, lr = 0.0002
I0526 11:42:17.462165 15117 solver.cpp:233] Iteration 56560, loss = 0.0150059
I0526 11:42:17.462318 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0150061 (* 1 = 0.0150061 loss)
I0526 11:42:17.462327 15117 sgd_solver.cpp:294] Iteration 56560, lr = 0.0002
I0526 11:42:23.749781 15117 solver.cpp:233] Iteration 56570, loss = 0.00653834
I0526 11:42:23.749827 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00653852 (* 1 = 0.00653852 loss)
I0526 11:42:23.749835 15117 sgd_solver.cpp:294] Iteration 56570, lr = 0.0002
I0526 11:42:30.037319 15117 solver.cpp:233] Iteration 56580, loss = 0.00236834
I0526 11:42:30.037355 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00236853 (* 1 = 0.00236853 loss)
I0526 11:42:30.037361 15117 sgd_solver.cpp:294] Iteration 56580, lr = 0.0002
I0526 11:42:36.325079 15117 solver.cpp:233] Iteration 56590, loss = 0.00523108
I0526 11:42:36.325124 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00523127 (* 1 = 0.00523127 loss)
I0526 11:42:36.325131 15117 sgd_solver.cpp:294] Iteration 56590, lr = 0.0002
I0526 11:42:42.012565 15117 solver.cpp:342] Iteration 56600, Testing net (#0)
I0526 11:42:54.794119 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9064
I0526 11:42:54.794349 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.451161 (* 1 = 0.451161 loss)
I0526 11:42:55.393338 15117 solver.cpp:233] Iteration 56600, loss = 0.0137888
I0526 11:42:55.393385 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.013789 (* 1 = 0.013789 loss)
I0526 11:42:55.393394 15117 sgd_solver.cpp:294] Iteration 56600, lr = 0.0002
I0526 11:43:01.684198 15117 solver.cpp:233] Iteration 56610, loss = 0.00461965
I0526 11:43:01.684239 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00461983 (* 1 = 0.00461983 loss)
I0526 11:43:01.684247 15117 sgd_solver.cpp:294] Iteration 56610, lr = 0.0002
I0526 11:43:07.969784 15117 solver.cpp:233] Iteration 56620, loss = 0.0184771
I0526 11:43:07.969828 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0184772 (* 1 = 0.0184772 loss)
I0526 11:43:07.969835 15117 sgd_solver.cpp:294] Iteration 56620, lr = 0.0002
I0526 11:43:14.254268 15117 solver.cpp:233] Iteration 56630, loss = 0.0311383
I0526 11:43:14.254307 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0311385 (* 1 = 0.0311385 loss)
I0526 11:43:14.254313 15117 sgd_solver.cpp:294] Iteration 56630, lr = 0.0002
I0526 11:43:20.543889 15117 solver.cpp:233] Iteration 56640, loss = 0.00938327
I0526 11:43:20.543931 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00938345 (* 1 = 0.00938345 loss)
I0526 11:43:20.543938 15117 sgd_solver.cpp:294] Iteration 56640, lr = 0.0002
I0526 11:43:26.835428 15117 solver.cpp:233] Iteration 56650, loss = 0.0233706
I0526 11:43:26.835655 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0233708 (* 1 = 0.0233708 loss)
I0526 11:43:26.835685 15117 sgd_solver.cpp:294] Iteration 56650, lr = 0.0002
I0526 11:43:33.126926 15117 solver.cpp:233] Iteration 56660, loss = 0.00490246
I0526 11:43:33.126968 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00490264 (* 1 = 0.00490264 loss)
I0526 11:43:33.126976 15117 sgd_solver.cpp:294] Iteration 56660, lr = 0.0002
I0526 11:43:39.416301 15117 solver.cpp:233] Iteration 56670, loss = 0.0062597
I0526 11:43:39.416345 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00625989 (* 1 = 0.00625989 loss)
I0526 11:43:39.416352 15117 sgd_solver.cpp:294] Iteration 56670, lr = 0.0002
I0526 11:43:45.702404 15117 solver.cpp:233] Iteration 56680, loss = 0.00852484
I0526 11:43:45.702447 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00852503 (* 1 = 0.00852503 loss)
I0526 11:43:45.702455 15117 sgd_solver.cpp:294] Iteration 56680, lr = 0.0002
I0526 11:43:51.991849 15117 solver.cpp:233] Iteration 56690, loss = 0.0072469
I0526 11:43:51.991891 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00724709 (* 1 = 0.00724709 loss)
I0526 11:43:51.991899 15117 sgd_solver.cpp:294] Iteration 56690, lr = 0.0002
I0526 11:43:57.688014 15117 solver.cpp:342] Iteration 56700, Testing net (#0)
I0526 11:44:10.478550 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9054
I0526 11:44:10.478598 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.439938 (* 1 = 0.439938 loss)
I0526 11:44:11.074126 15117 solver.cpp:233] Iteration 56700, loss = 0.00757325
I0526 11:44:11.074165 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00757344 (* 1 = 0.00757344 loss)
I0526 11:44:11.074172 15117 sgd_solver.cpp:294] Iteration 56700, lr = 0.0002
I0526 11:44:17.364008 15117 solver.cpp:233] Iteration 56710, loss = 0.0228654
I0526 11:44:17.364049 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0228656 (* 1 = 0.0228656 loss)
I0526 11:44:17.364055 15117 sgd_solver.cpp:294] Iteration 56710, lr = 0.0002
I0526 11:44:23.654337 15117 solver.cpp:233] Iteration 56720, loss = 0.0158727
I0526 11:44:23.654386 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0158729 (* 1 = 0.0158729 loss)
I0526 11:44:23.654392 15117 sgd_solver.cpp:294] Iteration 56720, lr = 0.0002
I0526 11:44:29.942551 15117 solver.cpp:233] Iteration 56730, loss = 0.0215201
I0526 11:44:29.942641 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0215203 (* 1 = 0.0215203 loss)
I0526 11:44:29.942651 15117 sgd_solver.cpp:294] Iteration 56730, lr = 0.0002
I0526 11:44:36.229954 15117 solver.cpp:233] Iteration 56740, loss = 0.00751184
I0526 11:44:36.229996 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00751202 (* 1 = 0.00751202 loss)
I0526 11:44:36.230003 15117 sgd_solver.cpp:294] Iteration 56740, lr = 0.0002
I0526 11:44:42.523133 15117 solver.cpp:233] Iteration 56750, loss = 0.0269985
I0526 11:44:42.523175 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0269987 (* 1 = 0.0269987 loss)
I0526 11:44:42.523183 15117 sgd_solver.cpp:294] Iteration 56750, lr = 0.0002
I0526 11:44:48.808202 15117 solver.cpp:233] Iteration 56760, loss = 0.00654786
I0526 11:44:48.808244 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00654805 (* 1 = 0.00654805 loss)
I0526 11:44:48.808251 15117 sgd_solver.cpp:294] Iteration 56760, lr = 0.0002
I0526 11:44:55.090394 15117 solver.cpp:233] Iteration 56770, loss = 0.00293279
I0526 11:44:55.090436 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00293297 (* 1 = 0.00293297 loss)
I0526 11:44:55.090443 15117 sgd_solver.cpp:294] Iteration 56770, lr = 0.0002
I0526 11:45:01.381795 15117 solver.cpp:233] Iteration 56780, loss = 0.0144512
I0526 11:45:01.382015 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0144514 (* 1 = 0.0144514 loss)
I0526 11:45:01.382045 15117 sgd_solver.cpp:294] Iteration 56780, lr = 0.0002
I0526 11:45:07.671540 15117 solver.cpp:233] Iteration 56790, loss = 0.0048413
I0526 11:45:07.671571 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00484148 (* 1 = 0.00484148 loss)
I0526 11:45:07.671578 15117 sgd_solver.cpp:294] Iteration 56790, lr = 0.0002
I0526 11:45:13.364265 15117 solver.cpp:342] Iteration 56800, Testing net (#0)
I0526 11:45:26.154479 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9072
I0526 11:45:26.154525 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.438507 (* 1 = 0.438507 loss)
I0526 11:45:26.751916 15117 solver.cpp:233] Iteration 56800, loss = 0.0189266
I0526 11:45:26.751956 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0189268 (* 1 = 0.0189268 loss)
I0526 11:45:26.751963 15117 sgd_solver.cpp:294] Iteration 56800, lr = 0.0002
I0526 11:45:33.041095 15117 solver.cpp:233] Iteration 56810, loss = 0.00922288
I0526 11:45:33.041332 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00922307 (* 1 = 0.00922307 loss)
I0526 11:45:33.041370 15117 sgd_solver.cpp:294] Iteration 56810, lr = 0.0002
I0526 11:45:39.335297 15117 solver.cpp:233] Iteration 56820, loss = 0.0507134
I0526 11:45:39.335342 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0507136 (* 1 = 0.0507136 loss)
I0526 11:45:39.335350 15117 sgd_solver.cpp:294] Iteration 56820, lr = 0.0002
I0526 11:45:45.621701 15117 solver.cpp:233] Iteration 56830, loss = 0.0187011
I0526 11:45:45.621743 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0187013 (* 1 = 0.0187013 loss)
I0526 11:45:45.621750 15117 sgd_solver.cpp:294] Iteration 56830, lr = 0.0002
I0526 11:45:51.909656 15117 solver.cpp:233] Iteration 56840, loss = 0.0292122
I0526 11:45:51.909699 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0292124 (* 1 = 0.0292124 loss)
I0526 11:45:51.909706 15117 sgd_solver.cpp:294] Iteration 56840, lr = 0.0002
I0526 11:45:58.201875 15117 solver.cpp:233] Iteration 56850, loss = 0.00587758
I0526 11:45:58.201916 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00587776 (* 1 = 0.00587776 loss)
I0526 11:45:58.201922 15117 sgd_solver.cpp:294] Iteration 56850, lr = 0.0002
I0526 11:46:04.494403 15117 solver.cpp:233] Iteration 56860, loss = 0.00372821
I0526 11:46:04.494645 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0037284 (* 1 = 0.0037284 loss)
I0526 11:46:04.494683 15117 sgd_solver.cpp:294] Iteration 56860, lr = 0.0002
I0526 11:46:10.786754 15117 solver.cpp:233] Iteration 56870, loss = 0.00245288
I0526 11:46:10.786783 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00245306 (* 1 = 0.00245306 loss)
I0526 11:46:10.786790 15117 sgd_solver.cpp:294] Iteration 56870, lr = 0.0002
I0526 11:46:17.079643 15117 solver.cpp:233] Iteration 56880, loss = 0.0235856
I0526 11:46:17.079684 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0235858 (* 1 = 0.0235858 loss)
I0526 11:46:17.079691 15117 sgd_solver.cpp:294] Iteration 56880, lr = 0.0002
I0526 11:46:23.369179 15117 solver.cpp:233] Iteration 56890, loss = 0.020384
I0526 11:46:23.369225 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0203841 (* 1 = 0.0203841 loss)
I0526 11:46:23.369232 15117 sgd_solver.cpp:294] Iteration 56890, lr = 0.0002
I0526 11:46:29.061396 15117 solver.cpp:342] Iteration 56900, Testing net (#0)
I0526 11:46:41.842850 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9055
I0526 11:46:41.842968 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.451103 (* 1 = 0.451103 loss)
I0526 11:46:42.439987 15117 solver.cpp:233] Iteration 56900, loss = 0.0122571
I0526 11:46:42.440024 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0122573 (* 1 = 0.0122573 loss)
I0526 11:46:42.440032 15117 sgd_solver.cpp:294] Iteration 56900, lr = 0.0002
I0526 11:46:48.725509 15117 solver.cpp:233] Iteration 56910, loss = 0.00764462
I0526 11:46:48.725553 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0076448 (* 1 = 0.0076448 loss)
I0526 11:46:48.725560 15117 sgd_solver.cpp:294] Iteration 56910, lr = 0.0002
I0526 11:46:55.011598 15117 solver.cpp:233] Iteration 56920, loss = 0.00496227
I0526 11:46:55.011644 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00496246 (* 1 = 0.00496246 loss)
I0526 11:46:55.011652 15117 sgd_solver.cpp:294] Iteration 56920, lr = 0.0002
I0526 11:47:01.300626 15117 solver.cpp:233] Iteration 56930, loss = 0.0189459
I0526 11:47:01.300668 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.018946 (* 1 = 0.018946 loss)
I0526 11:47:01.300674 15117 sgd_solver.cpp:294] Iteration 56930, lr = 0.0002
I0526 11:47:07.590083 15117 solver.cpp:233] Iteration 56940, loss = 0.00575836
I0526 11:47:07.590126 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00575854 (* 1 = 0.00575854 loss)
I0526 11:47:07.590133 15117 sgd_solver.cpp:294] Iteration 56940, lr = 0.0002
I0526 11:47:13.879562 15117 solver.cpp:233] Iteration 56950, loss = 0.00708976
I0526 11:47:13.879844 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00708994 (* 1 = 0.00708994 loss)
I0526 11:47:13.879871 15117 sgd_solver.cpp:294] Iteration 56950, lr = 0.0002
I0526 11:47:20.173110 15117 solver.cpp:233] Iteration 56960, loss = 0.00850989
I0526 11:47:20.173156 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00851007 (* 1 = 0.00851007 loss)
I0526 11:47:20.173163 15117 sgd_solver.cpp:294] Iteration 56960, lr = 0.0002
I0526 11:47:26.465852 15117 solver.cpp:233] Iteration 56970, loss = 0.00353621
I0526 11:47:26.465894 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00353639 (* 1 = 0.00353639 loss)
I0526 11:47:26.465901 15117 sgd_solver.cpp:294] Iteration 56970, lr = 0.0002
I0526 11:47:32.755784 15117 solver.cpp:233] Iteration 56980, loss = 0.00249327
I0526 11:47:32.755826 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00249345 (* 1 = 0.00249345 loss)
I0526 11:47:32.755833 15117 sgd_solver.cpp:294] Iteration 56980, lr = 0.0002
I0526 11:47:39.043087 15117 solver.cpp:233] Iteration 56990, loss = 0.00742067
I0526 11:47:39.043130 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00742085 (* 1 = 0.00742085 loss)
I0526 11:47:39.043138 15117 sgd_solver.cpp:294] Iteration 56990, lr = 0.0002
I0526 11:47:44.736922 15117 solver.cpp:342] Iteration 57000, Testing net (#0)
I0526 11:47:57.525012 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.905
I0526 11:47:57.525058 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.449515 (* 1 = 0.449515 loss)
I0526 11:47:58.120302 15117 solver.cpp:233] Iteration 57000, loss = 0.00790196
I0526 11:47:58.120342 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00790214 (* 1 = 0.00790214 loss)
I0526 11:47:58.120348 15117 sgd_solver.cpp:294] Iteration 57000, lr = 0.0002
I0526 11:48:04.411756 15117 solver.cpp:233] Iteration 57010, loss = 0.00456224
I0526 11:48:04.411792 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00456242 (* 1 = 0.00456242 loss)
I0526 11:48:04.411799 15117 sgd_solver.cpp:294] Iteration 57010, lr = 0.0002
I0526 11:48:10.700166 15117 solver.cpp:233] Iteration 57020, loss = 0.0156474
I0526 11:48:10.700206 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0156476 (* 1 = 0.0156476 loss)
I0526 11:48:10.700212 15117 sgd_solver.cpp:294] Iteration 57020, lr = 0.0002
I0526 11:48:16.985352 15117 solver.cpp:233] Iteration 57030, loss = 0.0093082
I0526 11:48:16.985558 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00930838 (* 1 = 0.00930838 loss)
I0526 11:48:16.985589 15117 sgd_solver.cpp:294] Iteration 57030, lr = 0.0002
I0526 11:48:23.277866 15117 solver.cpp:233] Iteration 57040, loss = 0.0144949
I0526 11:48:23.277910 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.014495 (* 1 = 0.014495 loss)
I0526 11:48:23.277917 15117 sgd_solver.cpp:294] Iteration 57040, lr = 0.0002
I0526 11:48:29.565207 15117 solver.cpp:233] Iteration 57050, loss = 0.00434728
I0526 11:48:29.565234 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00434745 (* 1 = 0.00434745 loss)
I0526 11:48:29.565240 15117 sgd_solver.cpp:294] Iteration 57050, lr = 0.0002
I0526 11:48:35.853827 15117 solver.cpp:233] Iteration 57060, loss = 0.0127135
I0526 11:48:35.853870 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0127137 (* 1 = 0.0127137 loss)
I0526 11:48:35.853878 15117 sgd_solver.cpp:294] Iteration 57060, lr = 0.0002
I0526 11:48:42.142858 15117 solver.cpp:233] Iteration 57070, loss = 0.0431108
I0526 11:48:42.142899 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.043111 (* 1 = 0.043111 loss)
I0526 11:48:42.142907 15117 sgd_solver.cpp:294] Iteration 57070, lr = 0.0002
I0526 11:48:48.431602 15117 solver.cpp:233] Iteration 57080, loss = 0.0049925
I0526 11:48:48.431820 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00499268 (* 1 = 0.00499268 loss)
I0526 11:48:48.431850 15117 sgd_solver.cpp:294] Iteration 57080, lr = 0.0002
I0526 11:48:54.719703 15117 solver.cpp:233] Iteration 57090, loss = 0.0106634
I0526 11:48:54.719744 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0106636 (* 1 = 0.0106636 loss)
I0526 11:48:54.719751 15117 sgd_solver.cpp:294] Iteration 57090, lr = 0.0002
I0526 11:49:00.408411 15117 solver.cpp:342] Iteration 57100, Testing net (#0)
I0526 11:49:13.192545 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9048
I0526 11:49:13.192590 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.44733 (* 1 = 0.44733 loss)
I0526 11:49:13.789723 15117 solver.cpp:233] Iteration 57100, loss = 0.00481741
I0526 11:49:13.789755 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00481759 (* 1 = 0.00481759 loss)
I0526 11:49:13.789762 15117 sgd_solver.cpp:294] Iteration 57100, lr = 0.0002
I0526 11:49:20.079852 15117 solver.cpp:233] Iteration 57110, loss = 0.0290927
I0526 11:49:20.080114 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0290928 (* 1 = 0.0290928 loss)
I0526 11:49:20.080142 15117 sgd_solver.cpp:294] Iteration 57110, lr = 0.0002
I0526 11:49:26.370898 15117 solver.cpp:233] Iteration 57120, loss = 0.00597385
I0526 11:49:26.370940 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00597403 (* 1 = 0.00597403 loss)
I0526 11:49:26.370947 15117 sgd_solver.cpp:294] Iteration 57120, lr = 0.0002
I0526 11:49:32.661842 15117 solver.cpp:233] Iteration 57130, loss = 0.0170681
I0526 11:49:32.661885 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0170683 (* 1 = 0.0170683 loss)
I0526 11:49:32.661892 15117 sgd_solver.cpp:294] Iteration 57130, lr = 0.0002
I0526 11:49:38.949443 15117 solver.cpp:233] Iteration 57140, loss = 0.0155995
I0526 11:49:38.949484 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0155997 (* 1 = 0.0155997 loss)
I0526 11:49:38.949492 15117 sgd_solver.cpp:294] Iteration 57140, lr = 0.0002
I0526 11:49:45.240303 15117 solver.cpp:233] Iteration 57150, loss = 0.00595669
I0526 11:49:45.240345 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00595687 (* 1 = 0.00595687 loss)
I0526 11:49:45.240352 15117 sgd_solver.cpp:294] Iteration 57150, lr = 0.0002
I0526 11:49:51.530560 15117 solver.cpp:233] Iteration 57160, loss = 0.00937466
I0526 11:49:51.530688 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00937484 (* 1 = 0.00937484 loss)
I0526 11:49:51.530696 15117 sgd_solver.cpp:294] Iteration 57160, lr = 0.0002
I0526 11:49:57.821405 15117 solver.cpp:233] Iteration 57170, loss = 0.0171538
I0526 11:49:57.821445 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0171539 (* 1 = 0.0171539 loss)
I0526 11:49:57.821452 15117 sgd_solver.cpp:294] Iteration 57170, lr = 0.0002
I0526 11:50:04.110431 15117 solver.cpp:233] Iteration 57180, loss = 0.00613419
I0526 11:50:04.110472 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00613437 (* 1 = 0.00613437 loss)
I0526 11:50:04.110481 15117 sgd_solver.cpp:294] Iteration 57180, lr = 0.0002
I0526 11:50:10.396287 15117 solver.cpp:233] Iteration 57190, loss = 0.0042534
I0526 11:50:10.396328 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00425358 (* 1 = 0.00425358 loss)
I0526 11:50:10.396335 15117 sgd_solver.cpp:294] Iteration 57190, lr = 0.0002
I0526 11:50:16.088426 15117 solver.cpp:342] Iteration 57200, Testing net (#0)
I0526 11:50:28.867394 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9036
I0526 11:50:28.867511 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.454593 (* 1 = 0.454593 loss)
I0526 11:50:29.464859 15117 solver.cpp:233] Iteration 57200, loss = 0.0038082
I0526 11:50:29.464893 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00380837 (* 1 = 0.00380837 loss)
I0526 11:50:29.464900 15117 sgd_solver.cpp:294] Iteration 57200, lr = 0.0002
I0526 11:50:35.753964 15117 solver.cpp:233] Iteration 57210, loss = 0.0117963
I0526 11:50:35.754006 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0117965 (* 1 = 0.0117965 loss)
I0526 11:50:35.754014 15117 sgd_solver.cpp:294] Iteration 57210, lr = 0.0002
I0526 11:50:42.043804 15117 solver.cpp:233] Iteration 57220, loss = 0.0119837
I0526 11:50:42.043833 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0119839 (* 1 = 0.0119839 loss)
I0526 11:50:42.043838 15117 sgd_solver.cpp:294] Iteration 57220, lr = 0.0002
I0526 11:50:48.329141 15117 solver.cpp:233] Iteration 57230, loss = 0.00339767
I0526 11:50:48.329182 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00339784 (* 1 = 0.00339784 loss)
I0526 11:50:48.329190 15117 sgd_solver.cpp:294] Iteration 57230, lr = 0.0002
I0526 11:50:54.618762 15117 solver.cpp:233] Iteration 57240, loss = 0.0205087
I0526 11:50:54.618804 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0205089 (* 1 = 0.0205089 loss)
I0526 11:50:54.618811 15117 sgd_solver.cpp:294] Iteration 57240, lr = 0.0002
I0526 11:51:00.908843 15117 solver.cpp:233] Iteration 57250, loss = 0.003492
I0526 11:51:00.909096 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00349218 (* 1 = 0.00349218 loss)
I0526 11:51:00.909127 15117 sgd_solver.cpp:294] Iteration 57250, lr = 0.0002
I0526 11:51:07.193254 15117 solver.cpp:233] Iteration 57260, loss = 0.00394862
I0526 11:51:07.193300 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0039488 (* 1 = 0.0039488 loss)
I0526 11:51:07.193307 15117 sgd_solver.cpp:294] Iteration 57260, lr = 0.0002
I0526 11:51:13.478205 15117 solver.cpp:233] Iteration 57270, loss = 0.00351164
I0526 11:51:13.478250 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00351182 (* 1 = 0.00351182 loss)
I0526 11:51:13.478256 15117 sgd_solver.cpp:294] Iteration 57270, lr = 0.0002
I0526 11:51:19.764854 15117 solver.cpp:233] Iteration 57280, loss = 0.0164849
I0526 11:51:19.764895 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0164851 (* 1 = 0.0164851 loss)
I0526 11:51:19.764902 15117 sgd_solver.cpp:294] Iteration 57280, lr = 0.0002
I0526 11:51:26.053462 15117 solver.cpp:233] Iteration 57290, loss = 0.00556462
I0526 11:51:26.053503 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00556479 (* 1 = 0.00556479 loss)
I0526 11:51:26.053509 15117 sgd_solver.cpp:294] Iteration 57290, lr = 0.0002
I0526 11:51:31.744488 15117 solver.cpp:342] Iteration 57300, Testing net (#0)
I0526 11:51:44.528523 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9062
I0526 11:51:44.528570 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.443662 (* 1 = 0.443662 loss)
I0526 11:51:45.126138 15117 solver.cpp:233] Iteration 57300, loss = 0.00991593
I0526 11:51:45.126176 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00991611 (* 1 = 0.00991611 loss)
I0526 11:51:45.126183 15117 sgd_solver.cpp:294] Iteration 57300, lr = 0.0002
I0526 11:51:51.415254 15117 solver.cpp:233] Iteration 57310, loss = 0.00900075
I0526 11:51:51.415297 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00900092 (* 1 = 0.00900092 loss)
I0526 11:51:51.415302 15117 sgd_solver.cpp:294] Iteration 57310, lr = 0.0002
I0526 11:51:57.700552 15117 solver.cpp:233] Iteration 57320, loss = 0.00433938
I0526 11:51:57.700595 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00433956 (* 1 = 0.00433956 loss)
I0526 11:51:57.700603 15117 sgd_solver.cpp:294] Iteration 57320, lr = 0.0002
I0526 11:52:03.985378 15117 solver.cpp:233] Iteration 57330, loss = 0.0173329
I0526 11:52:03.985585 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0173331 (* 1 = 0.0173331 loss)
I0526 11:52:03.985611 15117 sgd_solver.cpp:294] Iteration 57330, lr = 0.0002
I0526 11:52:10.275472 15117 solver.cpp:233] Iteration 57340, loss = 0.0358974
I0526 11:52:10.275517 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0358976 (* 1 = 0.0358976 loss)
I0526 11:52:10.275526 15117 sgd_solver.cpp:294] Iteration 57340, lr = 0.0002
I0526 11:52:16.561942 15117 solver.cpp:233] Iteration 57350, loss = 0.00800387
I0526 11:52:16.561997 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00800405 (* 1 = 0.00800405 loss)
I0526 11:52:16.562011 15117 sgd_solver.cpp:294] Iteration 57350, lr = 0.0002
I0526 11:52:22.848872 15117 solver.cpp:233] Iteration 57360, loss = 0.00211263
I0526 11:52:22.848915 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00211281 (* 1 = 0.00211281 loss)
I0526 11:52:22.848922 15117 sgd_solver.cpp:294] Iteration 57360, lr = 0.0002
I0526 11:52:29.140733 15117 solver.cpp:233] Iteration 57370, loss = 0.0105129
I0526 11:52:29.140775 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0105131 (* 1 = 0.0105131 loss)
I0526 11:52:29.140781 15117 sgd_solver.cpp:294] Iteration 57370, lr = 0.0002
I0526 11:52:35.425703 15117 solver.cpp:233] Iteration 57380, loss = 0.0115181
I0526 11:52:35.425920 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0115182 (* 1 = 0.0115182 loss)
I0526 11:52:35.425946 15117 sgd_solver.cpp:294] Iteration 57380, lr = 0.0002
I0526 11:52:41.720119 15117 solver.cpp:233] Iteration 57390, loss = 0.00823368
I0526 11:52:41.720160 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00823385 (* 1 = 0.00823385 loss)
I0526 11:52:41.720165 15117 sgd_solver.cpp:294] Iteration 57390, lr = 0.0002
I0526 11:52:47.412870 15117 solver.cpp:342] Iteration 57400, Testing net (#0)
I0526 11:53:00.204124 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9043
I0526 11:53:00.204172 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.451666 (* 1 = 0.451666 loss)
I0526 11:53:00.800199 15117 solver.cpp:233] Iteration 57400, loss = 0.0187229
I0526 11:53:00.800238 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.018723 (* 1 = 0.018723 loss)
I0526 11:53:00.800246 15117 sgd_solver.cpp:294] Iteration 57400, lr = 0.0002
I0526 11:53:07.086462 15117 solver.cpp:233] Iteration 57410, loss = 0.0061457
I0526 11:53:07.086674 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00614588 (* 1 = 0.00614588 loss)
I0526 11:53:07.086700 15117 sgd_solver.cpp:294] Iteration 57410, lr = 0.0002
I0526 11:53:13.377673 15117 solver.cpp:233] Iteration 57420, loss = 0.0155759
I0526 11:53:13.377722 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.015576 (* 1 = 0.015576 loss)
I0526 11:53:13.377729 15117 sgd_solver.cpp:294] Iteration 57420, lr = 0.0002
I0526 11:53:19.666267 15117 solver.cpp:233] Iteration 57430, loss = 0.0059471
I0526 11:53:19.666308 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00594727 (* 1 = 0.00594727 loss)
I0526 11:53:19.666316 15117 sgd_solver.cpp:294] Iteration 57430, lr = 0.0002
I0526 11:53:25.954941 15117 solver.cpp:233] Iteration 57440, loss = 0.0107819
I0526 11:53:25.954984 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0107821 (* 1 = 0.0107821 loss)
I0526 11:53:25.954991 15117 sgd_solver.cpp:294] Iteration 57440, lr = 0.0002
I0526 11:53:32.242744 15117 solver.cpp:233] Iteration 57450, loss = 0.00650254
I0526 11:53:32.242789 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00650271 (* 1 = 0.00650271 loss)
I0526 11:53:32.242796 15117 sgd_solver.cpp:294] Iteration 57450, lr = 0.0002
I0526 11:53:38.530956 15117 solver.cpp:233] Iteration 57460, loss = 0.0117331
I0526 11:53:38.531080 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0117333 (* 1 = 0.0117333 loss)
I0526 11:53:38.531088 15117 sgd_solver.cpp:294] Iteration 57460, lr = 0.0002
I0526 11:53:44.818825 15117 solver.cpp:233] Iteration 57470, loss = 0.0123735
I0526 11:53:44.818867 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0123737 (* 1 = 0.0123737 loss)
I0526 11:53:44.818873 15117 sgd_solver.cpp:294] Iteration 57470, lr = 0.0002
I0526 11:53:51.106968 15117 solver.cpp:233] Iteration 57480, loss = 0.00709219
I0526 11:53:51.106997 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00709236 (* 1 = 0.00709236 loss)
I0526 11:53:51.107003 15117 sgd_solver.cpp:294] Iteration 57480, lr = 0.0002
I0526 11:53:57.397332 15117 solver.cpp:233] Iteration 57490, loss = 0.0176394
I0526 11:53:57.397384 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0176395 (* 1 = 0.0176395 loss)
I0526 11:53:57.397392 15117 sgd_solver.cpp:294] Iteration 57490, lr = 0.0002
I0526 11:54:03.091768 15117 solver.cpp:342] Iteration 57500, Testing net (#0)
I0526 11:54:15.872848 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9049
I0526 11:54:15.873112 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.456995 (* 1 = 0.456995 loss)
I0526 11:54:16.474046 15117 solver.cpp:233] Iteration 57500, loss = 0.00738798
I0526 11:54:16.474112 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00738815 (* 1 = 0.00738815 loss)
I0526 11:54:16.474123 15117 sgd_solver.cpp:294] Iteration 57500, lr = 0.0002
I0526 11:54:22.762038 15117 solver.cpp:233] Iteration 57510, loss = 0.00743034
I0526 11:54:22.762084 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0074305 (* 1 = 0.0074305 loss)
I0526 11:54:22.762090 15117 sgd_solver.cpp:294] Iteration 57510, lr = 0.0002
I0526 11:54:29.049626 15117 solver.cpp:233] Iteration 57520, loss = 0.0140446
I0526 11:54:29.049661 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0140447 (* 1 = 0.0140447 loss)
I0526 11:54:29.049669 15117 sgd_solver.cpp:294] Iteration 57520, lr = 0.0002
I0526 11:54:35.337311 15117 solver.cpp:233] Iteration 57530, loss = 0.00932092
I0526 11:54:35.337352 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00932108 (* 1 = 0.00932108 loss)
I0526 11:54:35.337358 15117 sgd_solver.cpp:294] Iteration 57530, lr = 0.0002
I0526 11:54:41.620832 15117 solver.cpp:233] Iteration 57540, loss = 0.00452399
I0526 11:54:41.620873 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00452415 (* 1 = 0.00452415 loss)
I0526 11:54:41.620879 15117 sgd_solver.cpp:294] Iteration 57540, lr = 0.0002
I0526 11:54:47.911830 15117 solver.cpp:233] Iteration 57550, loss = 0.00492381
I0526 11:54:47.911983 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00492397 (* 1 = 0.00492397 loss)
I0526 11:54:47.912009 15117 sgd_solver.cpp:294] Iteration 57550, lr = 0.0002
I0526 11:54:54.202179 15117 solver.cpp:233] Iteration 57560, loss = 0.0111222
I0526 11:54:54.202222 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0111223 (* 1 = 0.0111223 loss)
I0526 11:54:54.202229 15117 sgd_solver.cpp:294] Iteration 57560, lr = 0.0002
I0526 11:55:00.490476 15117 solver.cpp:233] Iteration 57570, loss = 0.0105065
I0526 11:55:00.490520 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0105066 (* 1 = 0.0105066 loss)
I0526 11:55:00.490525 15117 sgd_solver.cpp:294] Iteration 57570, lr = 0.0002
I0526 11:55:06.777539 15117 solver.cpp:233] Iteration 57580, loss = 0.00572088
I0526 11:55:06.777580 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00572104 (* 1 = 0.00572104 loss)
I0526 11:55:06.777586 15117 sgd_solver.cpp:294] Iteration 57580, lr = 0.0002
I0526 11:55:13.069425 15117 solver.cpp:233] Iteration 57590, loss = 0.00562008
I0526 11:55:13.069468 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00562024 (* 1 = 0.00562024 loss)
I0526 11:55:13.069474 15117 sgd_solver.cpp:294] Iteration 57590, lr = 0.0002
I0526 11:55:18.762663 15117 solver.cpp:342] Iteration 57600, Testing net (#0)
I0526 11:55:31.546844 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9029
I0526 11:55:31.546893 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.464427 (* 1 = 0.464427 loss)
I0526 11:55:32.144350 15117 solver.cpp:233] Iteration 57600, loss = 0.00974004
I0526 11:55:32.144389 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0097402 (* 1 = 0.0097402 loss)
I0526 11:55:32.144397 15117 sgd_solver.cpp:294] Iteration 57600, lr = 0.0002
I0526 11:55:38.431771 15117 solver.cpp:233] Iteration 57610, loss = 0.00679707
I0526 11:55:38.431812 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00679723 (* 1 = 0.00679723 loss)
I0526 11:55:38.431818 15117 sgd_solver.cpp:294] Iteration 57610, lr = 0.0002
I0526 11:55:44.719275 15117 solver.cpp:233] Iteration 57620, loss = 0.00585952
I0526 11:55:44.719318 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00585968 (* 1 = 0.00585968 loss)
I0526 11:55:44.719326 15117 sgd_solver.cpp:294] Iteration 57620, lr = 0.0002
I0526 11:55:51.008847 15117 solver.cpp:233] Iteration 57630, loss = 0.00754169
I0526 11:55:51.009137 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00754185 (* 1 = 0.00754185 loss)
I0526 11:55:51.009168 15117 sgd_solver.cpp:294] Iteration 57630, lr = 0.0002
I0526 11:55:57.300500 15117 solver.cpp:233] Iteration 57640, loss = 0.00372667
I0526 11:55:57.300542 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00372683 (* 1 = 0.00372683 loss)
I0526 11:55:57.300549 15117 sgd_solver.cpp:294] Iteration 57640, lr = 0.0002
I0526 11:56:03.592372 15117 solver.cpp:233] Iteration 57650, loss = 0.013213
I0526 11:56:03.592417 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0132131 (* 1 = 0.0132131 loss)
I0526 11:56:03.592424 15117 sgd_solver.cpp:294] Iteration 57650, lr = 0.0002
I0526 11:56:09.884209 15117 solver.cpp:233] Iteration 57660, loss = 0.0107231
I0526 11:56:09.884250 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0107233 (* 1 = 0.0107233 loss)
I0526 11:56:09.884258 15117 sgd_solver.cpp:294] Iteration 57660, lr = 0.0002
I0526 11:56:16.177022 15117 solver.cpp:233] Iteration 57670, loss = 0.0108992
I0526 11:56:16.177060 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0108993 (* 1 = 0.0108993 loss)
I0526 11:56:16.177067 15117 sgd_solver.cpp:294] Iteration 57670, lr = 0.0002
I0526 11:56:22.464895 15117 solver.cpp:233] Iteration 57680, loss = 0.00990036
I0526 11:56:22.465117 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00990052 (* 1 = 0.00990052 loss)
I0526 11:56:22.465144 15117 sgd_solver.cpp:294] Iteration 57680, lr = 0.0002
I0526 11:56:28.751884 15117 solver.cpp:233] Iteration 57690, loss = 0.0122508
I0526 11:56:28.751927 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.012251 (* 1 = 0.012251 loss)
I0526 11:56:28.751935 15117 sgd_solver.cpp:294] Iteration 57690, lr = 0.0002
I0526 11:56:34.442154 15117 solver.cpp:342] Iteration 57700, Testing net (#0)
I0526 11:56:47.223538 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9048
I0526 11:56:47.223583 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.451029 (* 1 = 0.451029 loss)
I0526 11:56:47.820423 15117 solver.cpp:233] Iteration 57700, loss = 0.00222466
I0526 11:56:47.820466 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00222482 (* 1 = 0.00222482 loss)
I0526 11:56:47.820472 15117 sgd_solver.cpp:294] Iteration 57700, lr = 0.0002
I0526 11:56:54.108705 15117 solver.cpp:233] Iteration 57710, loss = 0.00719953
I0526 11:56:54.108893 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00719969 (* 1 = 0.00719969 loss)
I0526 11:56:54.108923 15117 sgd_solver.cpp:294] Iteration 57710, lr = 0.0002
I0526 11:57:00.399547 15117 solver.cpp:233] Iteration 57720, loss = 0.0101602
I0526 11:57:00.399590 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0101604 (* 1 = 0.0101604 loss)
I0526 11:57:00.399597 15117 sgd_solver.cpp:294] Iteration 57720, lr = 0.0002
I0526 11:57:06.685353 15117 solver.cpp:233] Iteration 57730, loss = 0.00433803
I0526 11:57:06.685395 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00433819 (* 1 = 0.00433819 loss)
I0526 11:57:06.685401 15117 sgd_solver.cpp:294] Iteration 57730, lr = 0.0002
I0526 11:57:12.974797 15117 solver.cpp:233] Iteration 57740, loss = 0.0179158
I0526 11:57:12.974840 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.017916 (* 1 = 0.017916 loss)
I0526 11:57:12.974848 15117 sgd_solver.cpp:294] Iteration 57740, lr = 0.0002
I0526 11:57:19.265766 15117 solver.cpp:233] Iteration 57750, loss = 0.00163751
I0526 11:57:19.265810 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00163767 (* 1 = 0.00163767 loss)
I0526 11:57:19.265820 15117 sgd_solver.cpp:294] Iteration 57750, lr = 0.0002
I0526 11:57:25.556133 15117 solver.cpp:233] Iteration 57760, loss = 0.00337236
I0526 11:57:25.556409 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00337252 (* 1 = 0.00337252 loss)
I0526 11:57:25.556438 15117 sgd_solver.cpp:294] Iteration 57760, lr = 0.0002
I0526 11:57:31.844663 15117 solver.cpp:233] Iteration 57770, loss = 0.00959048
I0526 11:57:31.844708 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00959065 (* 1 = 0.00959065 loss)
I0526 11:57:31.844717 15117 sgd_solver.cpp:294] Iteration 57770, lr = 0.0002
I0526 11:57:38.132443 15117 solver.cpp:233] Iteration 57780, loss = 0.00612495
I0526 11:57:38.132483 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00612511 (* 1 = 0.00612511 loss)
I0526 11:57:38.132489 15117 sgd_solver.cpp:294] Iteration 57780, lr = 0.0002
I0526 11:57:44.424363 15117 solver.cpp:233] Iteration 57790, loss = 0.00352765
I0526 11:57:44.424407 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00352781 (* 1 = 0.00352781 loss)
I0526 11:57:44.424412 15117 sgd_solver.cpp:294] Iteration 57790, lr = 0.0002
I0526 11:57:50.116727 15117 solver.cpp:342] Iteration 57800, Testing net (#0)
I0526 11:58:02.901929 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9055
I0526 11:58:02.902168 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.455714 (* 1 = 0.455714 loss)
I0526 11:58:03.499080 15117 solver.cpp:233] Iteration 57800, loss = 0.0254279
I0526 11:58:03.499114 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0254281 (* 1 = 0.0254281 loss)
I0526 11:58:03.499119 15117 sgd_solver.cpp:294] Iteration 57800, lr = 0.0002
I0526 11:58:09.790436 15117 solver.cpp:233] Iteration 57810, loss = 0.0111992
I0526 11:58:09.790478 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0111994 (* 1 = 0.0111994 loss)
I0526 11:58:09.790485 15117 sgd_solver.cpp:294] Iteration 57810, lr = 0.0002
I0526 11:58:16.082334 15117 solver.cpp:233] Iteration 57820, loss = 0.00837427
I0526 11:58:16.082381 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00837444 (* 1 = 0.00837444 loss)
I0526 11:58:16.082387 15117 sgd_solver.cpp:294] Iteration 57820, lr = 0.0002
I0526 11:58:22.416196 15117 solver.cpp:233] Iteration 57830, loss = 0.00150461
I0526 11:58:22.416239 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00150477 (* 1 = 0.00150477 loss)
I0526 11:58:22.416244 15117 sgd_solver.cpp:294] Iteration 57830, lr = 0.0002
I0526 11:58:28.709991 15117 solver.cpp:233] Iteration 57840, loss = 0.00765356
I0526 11:58:28.710036 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00765373 (* 1 = 0.00765373 loss)
I0526 11:58:28.710043 15117 sgd_solver.cpp:294] Iteration 57840, lr = 0.0002
I0526 11:58:34.994182 15117 solver.cpp:233] Iteration 57850, loss = 0.00517629
I0526 11:58:34.994303 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00517645 (* 1 = 0.00517645 loss)
I0526 11:58:34.994312 15117 sgd_solver.cpp:294] Iteration 57850, lr = 0.0002
I0526 11:58:41.278090 15117 solver.cpp:233] Iteration 57860, loss = 0.00558643
I0526 11:58:41.278129 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00558659 (* 1 = 0.00558659 loss)
I0526 11:58:41.278136 15117 sgd_solver.cpp:294] Iteration 57860, lr = 0.0002
I0526 11:58:47.563432 15117 solver.cpp:233] Iteration 57870, loss = 0.0127194
I0526 11:58:47.563473 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0127196 (* 1 = 0.0127196 loss)
I0526 11:58:47.563480 15117 sgd_solver.cpp:294] Iteration 57870, lr = 0.0002
I0526 11:58:53.848124 15117 solver.cpp:233] Iteration 57880, loss = 0.0222618
I0526 11:58:53.848167 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.022262 (* 1 = 0.022262 loss)
I0526 11:58:53.848173 15117 sgd_solver.cpp:294] Iteration 57880, lr = 0.0002
I0526 11:59:00.134147 15117 solver.cpp:233] Iteration 57890, loss = 0.0155318
I0526 11:59:00.134176 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.015532 (* 1 = 0.015532 loss)
I0526 11:59:00.134189 15117 sgd_solver.cpp:294] Iteration 57890, lr = 0.0002
I0526 11:59:05.827651 15117 solver.cpp:342] Iteration 57900, Testing net (#0)
I0526 11:59:18.615855 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9053
I0526 11:59:18.615903 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.443555 (* 1 = 0.443555 loss)
I0526 11:59:19.212105 15117 solver.cpp:233] Iteration 57900, loss = 0.00329013
I0526 11:59:19.212137 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00329029 (* 1 = 0.00329029 loss)
I0526 11:59:19.212144 15117 sgd_solver.cpp:294] Iteration 57900, lr = 0.0002
I0526 11:59:25.497114 15117 solver.cpp:233] Iteration 57910, loss = 0.00849123
I0526 11:59:25.497154 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00849139 (* 1 = 0.00849139 loss)
I0526 11:59:25.497161 15117 sgd_solver.cpp:294] Iteration 57910, lr = 0.0002
I0526 11:59:31.784533 15117 solver.cpp:233] Iteration 57920, loss = 0.0105979
I0526 11:59:31.784576 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.010598 (* 1 = 0.010598 loss)
I0526 11:59:31.784584 15117 sgd_solver.cpp:294] Iteration 57920, lr = 0.0002
I0526 11:59:38.070303 15117 solver.cpp:233] Iteration 57930, loss = 0.0101262
I0526 11:59:38.070497 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0101264 (* 1 = 0.0101264 loss)
I0526 11:59:38.070524 15117 sgd_solver.cpp:294] Iteration 57930, lr = 0.0002
I0526 11:59:44.358162 15117 solver.cpp:233] Iteration 57940, loss = 0.0352612
I0526 11:59:44.358206 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0352613 (* 1 = 0.0352613 loss)
I0526 11:59:44.358212 15117 sgd_solver.cpp:294] Iteration 57940, lr = 0.0002
I0526 11:59:50.646117 15117 solver.cpp:233] Iteration 57950, loss = 0.0198069
I0526 11:59:50.646144 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0198071 (* 1 = 0.0198071 loss)
I0526 11:59:50.646152 15117 sgd_solver.cpp:294] Iteration 57950, lr = 0.0002
I0526 11:59:56.933277 15117 solver.cpp:233] Iteration 57960, loss = 0.00553441
I0526 11:59:56.933320 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00553457 (* 1 = 0.00553457 loss)
I0526 11:59:56.933326 15117 sgd_solver.cpp:294] Iteration 57960, lr = 0.0002
I0526 12:00:03.218700 15117 solver.cpp:233] Iteration 57970, loss = 0.00913783
I0526 12:00:03.218737 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00913799 (* 1 = 0.00913799 loss)
I0526 12:00:03.218744 15117 sgd_solver.cpp:294] Iteration 57970, lr = 0.0002
I0526 12:00:09.503736 15117 solver.cpp:233] Iteration 57980, loss = 0.0125369
I0526 12:00:09.503860 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.012537 (* 1 = 0.012537 loss)
I0526 12:00:09.503870 15117 sgd_solver.cpp:294] Iteration 57980, lr = 0.0002
I0526 12:00:15.790079 15117 solver.cpp:233] Iteration 57990, loss = 0.0112986
I0526 12:00:15.790119 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0112987 (* 1 = 0.0112987 loss)
I0526 12:00:15.790125 15117 sgd_solver.cpp:294] Iteration 57990, lr = 0.0002
I0526 12:00:21.477200 15117 solver.cpp:342] Iteration 58000, Testing net (#0)
I0526 12:00:34.261133 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9052
I0526 12:00:34.261176 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.436363 (* 1 = 0.436363 loss)
I0526 12:00:34.857962 15117 solver.cpp:233] Iteration 58000, loss = 0.00184552
I0526 12:00:34.857990 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00184568 (* 1 = 0.00184568 loss)
I0526 12:00:34.857998 15117 sgd_solver.cpp:294] Iteration 58000, lr = 0.0002
I0526 12:00:41.143684 15117 solver.cpp:233] Iteration 58010, loss = 0.0103588
I0526 12:00:41.143882 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0103589 (* 1 = 0.0103589 loss)
I0526 12:00:41.143908 15117 sgd_solver.cpp:294] Iteration 58010, lr = 0.0002
I0526 12:00:47.430804 15117 solver.cpp:233] Iteration 58020, loss = 0.011725
I0526 12:00:47.430853 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0117252 (* 1 = 0.0117252 loss)
I0526 12:00:47.430860 15117 sgd_solver.cpp:294] Iteration 58020, lr = 0.0002
I0526 12:00:53.716274 15117 solver.cpp:233] Iteration 58030, loss = 0.0075926
I0526 12:00:53.716315 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00759276 (* 1 = 0.00759276 loss)
I0526 12:00:53.716321 15117 sgd_solver.cpp:294] Iteration 58030, lr = 0.0002
I0526 12:01:00.001312 15117 solver.cpp:233] Iteration 58040, loss = 0.00294942
I0526 12:01:00.001353 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00294958 (* 1 = 0.00294958 loss)
I0526 12:01:00.001360 15117 sgd_solver.cpp:294] Iteration 58040, lr = 0.0002
I0526 12:01:06.285610 15117 solver.cpp:233] Iteration 58050, loss = 0.0127771
I0526 12:01:06.285651 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0127772 (* 1 = 0.0127772 loss)
I0526 12:01:06.285658 15117 sgd_solver.cpp:294] Iteration 58050, lr = 0.0002
I0526 12:01:12.570102 15117 solver.cpp:233] Iteration 58060, loss = 0.00231982
I0526 12:01:12.570397 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00231998 (* 1 = 0.00231998 loss)
I0526 12:01:12.570427 15117 sgd_solver.cpp:294] Iteration 58060, lr = 0.0002
I0526 12:01:18.881629 15117 solver.cpp:233] Iteration 58070, loss = 0.0202468
I0526 12:01:18.881671 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0202469 (* 1 = 0.0202469 loss)
I0526 12:01:18.881690 15117 sgd_solver.cpp:294] Iteration 58070, lr = 0.0002
I0526 12:01:25.220284 15117 solver.cpp:233] Iteration 58080, loss = 0.0321627
I0526 12:01:25.220324 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0321629 (* 1 = 0.0321629 loss)
I0526 12:01:25.220331 15117 sgd_solver.cpp:294] Iteration 58080, lr = 0.0002
I0526 12:01:31.556360 15117 solver.cpp:233] Iteration 58090, loss = 0.0106202
I0526 12:01:31.556401 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0106204 (* 1 = 0.0106204 loss)
I0526 12:01:31.556407 15117 sgd_solver.cpp:294] Iteration 58090, lr = 0.0002
I0526 12:01:37.290771 15117 solver.cpp:342] Iteration 58100, Testing net (#0)
I0526 12:01:50.122658 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9041
I0526 12:01:50.122814 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.450257 (* 1 = 0.450257 loss)
I0526 12:01:50.724167 15117 solver.cpp:233] Iteration 58100, loss = 0.0206772
I0526 12:01:50.724192 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0206774 (* 1 = 0.0206774 loss)
I0526 12:01:50.724200 15117 sgd_solver.cpp:294] Iteration 58100, lr = 0.0002
I0526 12:01:57.060868 15117 solver.cpp:233] Iteration 58110, loss = 0.0113193
I0526 12:01:57.060909 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0113194 (* 1 = 0.0113194 loss)
I0526 12:01:57.060915 15117 sgd_solver.cpp:294] Iteration 58110, lr = 0.0002
I0526 12:02:03.399581 15117 solver.cpp:233] Iteration 58120, loss = 0.0221006
I0526 12:02:03.399634 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0221007 (* 1 = 0.0221007 loss)
I0526 12:02:03.399641 15117 sgd_solver.cpp:294] Iteration 58120, lr = 0.0002
I0526 12:02:09.735208 15117 solver.cpp:233] Iteration 58130, loss = 0.00886966
I0526 12:02:09.735249 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00886981 (* 1 = 0.00886981 loss)
I0526 12:02:09.735255 15117 sgd_solver.cpp:294] Iteration 58130, lr = 0.0002
I0526 12:02:16.070653 15117 solver.cpp:233] Iteration 58140, loss = 0.00254057
I0526 12:02:16.070695 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00254072 (* 1 = 0.00254072 loss)
I0526 12:02:16.070703 15117 sgd_solver.cpp:294] Iteration 58140, lr = 0.0002
I0526 12:02:22.402302 15117 solver.cpp:233] Iteration 58150, loss = 0.0262323
I0526 12:02:22.402529 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0262324 (* 1 = 0.0262324 loss)
I0526 12:02:22.402556 15117 sgd_solver.cpp:294] Iteration 58150, lr = 0.0002
I0526 12:02:28.739634 15117 solver.cpp:233] Iteration 58160, loss = 0.00431413
I0526 12:02:28.739677 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00431428 (* 1 = 0.00431428 loss)
I0526 12:02:28.739686 15117 sgd_solver.cpp:294] Iteration 58160, lr = 0.0002
I0526 12:02:35.077018 15117 solver.cpp:233] Iteration 58170, loss = 0.00634342
I0526 12:02:35.077054 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00634358 (* 1 = 0.00634358 loss)
I0526 12:02:35.077061 15117 sgd_solver.cpp:294] Iteration 58170, lr = 0.0002
I0526 12:02:41.412544 15117 solver.cpp:233] Iteration 58180, loss = 0.00653257
I0526 12:02:41.412583 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00653273 (* 1 = 0.00653273 loss)
I0526 12:02:41.412590 15117 sgd_solver.cpp:294] Iteration 58180, lr = 0.0002
I0526 12:02:47.745142 15117 solver.cpp:233] Iteration 58190, loss = 0.00526079
I0526 12:02:47.745196 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00526095 (* 1 = 0.00526095 loss)
I0526 12:02:47.745204 15117 sgd_solver.cpp:294] Iteration 58190, lr = 0.0002
I0526 12:02:53.480767 15117 solver.cpp:342] Iteration 58200, Testing net (#0)
I0526 12:03:06.313575 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.905
I0526 12:03:06.313619 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.442026 (* 1 = 0.442026 loss)
I0526 12:03:06.915405 15117 solver.cpp:233] Iteration 58200, loss = 0.00410904
I0526 12:03:06.915446 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0041092 (* 1 = 0.0041092 loss)
I0526 12:03:06.915454 15117 sgd_solver.cpp:294] Iteration 58200, lr = 0.0002
I0526 12:03:13.252315 15117 solver.cpp:233] Iteration 58210, loss = 0.00732473
I0526 12:03:13.252357 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00732489 (* 1 = 0.00732489 loss)
I0526 12:03:13.252365 15117 sgd_solver.cpp:294] Iteration 58210, lr = 0.0002
I0526 12:03:19.589211 15117 solver.cpp:233] Iteration 58220, loss = 0.0210301
I0526 12:03:19.589252 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0210302 (* 1 = 0.0210302 loss)
I0526 12:03:19.589259 15117 sgd_solver.cpp:294] Iteration 58220, lr = 0.0002
I0526 12:03:25.928879 15117 solver.cpp:233] Iteration 58230, loss = 0.0113274
I0526 12:03:25.929038 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0113276 (* 1 = 0.0113276 loss)
I0526 12:03:25.929046 15117 sgd_solver.cpp:294] Iteration 58230, lr = 0.0002
I0526 12:03:32.265595 15117 solver.cpp:233] Iteration 58240, loss = 0.00905753
I0526 12:03:32.265635 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00905769 (* 1 = 0.00905769 loss)
I0526 12:03:32.265642 15117 sgd_solver.cpp:294] Iteration 58240, lr = 0.0002
I0526 12:03:38.580564 15117 solver.cpp:233] Iteration 58250, loss = 0.0272963
I0526 12:03:38.580601 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0272964 (* 1 = 0.0272964 loss)
I0526 12:03:38.580608 15117 sgd_solver.cpp:294] Iteration 58250, lr = 0.0002
I0526 12:03:44.892419 15117 solver.cpp:233] Iteration 58260, loss = 0.0353107
I0526 12:03:44.892459 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0353108 (* 1 = 0.0353108 loss)
I0526 12:03:44.892467 15117 sgd_solver.cpp:294] Iteration 58260, lr = 0.0002
I0526 12:03:51.203480 15117 solver.cpp:233] Iteration 58270, loss = 0.00580768
I0526 12:03:51.203518 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00580783 (* 1 = 0.00580783 loss)
I0526 12:03:51.203536 15117 sgd_solver.cpp:294] Iteration 58270, lr = 0.0002
I0526 12:03:57.512737 15117 solver.cpp:233] Iteration 58280, loss = 0.00996645
I0526 12:03:57.512871 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00996661 (* 1 = 0.00996661 loss)
I0526 12:03:57.512881 15117 sgd_solver.cpp:294] Iteration 58280, lr = 0.0002
I0526 12:04:03.797514 15117 solver.cpp:233] Iteration 58290, loss = 0.0119588
I0526 12:04:03.797555 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0119589 (* 1 = 0.0119589 loss)
I0526 12:04:03.797567 15117 sgd_solver.cpp:294] Iteration 58290, lr = 0.0002
I0526 12:04:09.482161 15117 solver.cpp:342] Iteration 58300, Testing net (#0)
I0526 12:04:22.255386 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9046
I0526 12:04:22.255431 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.449942 (* 1 = 0.449942 loss)
I0526 12:04:22.851099 15117 solver.cpp:233] Iteration 58300, loss = 0.0162807
I0526 12:04:22.851130 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0162808 (* 1 = 0.0162808 loss)
I0526 12:04:22.851136 15117 sgd_solver.cpp:294] Iteration 58300, lr = 0.0002
I0526 12:04:29.132725 15117 solver.cpp:233] Iteration 58310, loss = 0.0121788
I0526 12:04:29.132874 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0121789 (* 1 = 0.0121789 loss)
I0526 12:04:29.132882 15117 sgd_solver.cpp:294] Iteration 58310, lr = 0.0002
I0526 12:04:35.417738 15117 solver.cpp:233] Iteration 58320, loss = 0.0132405
I0526 12:04:35.417778 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0132407 (* 1 = 0.0132407 loss)
I0526 12:04:35.417785 15117 sgd_solver.cpp:294] Iteration 58320, lr = 0.0002
I0526 12:04:41.726438 15117 solver.cpp:233] Iteration 58330, loss = 0.0167014
I0526 12:04:41.726482 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0167015 (* 1 = 0.0167015 loss)
I0526 12:04:41.726490 15117 sgd_solver.cpp:294] Iteration 58330, lr = 0.0002
I0526 12:04:48.035045 15117 solver.cpp:233] Iteration 58340, loss = 0.00926243
I0526 12:04:48.035084 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00926258 (* 1 = 0.00926258 loss)
I0526 12:04:48.035090 15117 sgd_solver.cpp:294] Iteration 58340, lr = 0.0002
I0526 12:04:54.362092 15117 solver.cpp:233] Iteration 58350, loss = 0.00719406
I0526 12:04:54.362138 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0071942 (* 1 = 0.0071942 loss)
I0526 12:04:54.362146 15117 sgd_solver.cpp:294] Iteration 58350, lr = 0.0002
I0526 12:05:00.738035 15117 solver.cpp:233] Iteration 58360, loss = 0.00402385
I0526 12:05:00.738178 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.004024 (* 1 = 0.004024 loss)
I0526 12:05:00.738188 15117 sgd_solver.cpp:294] Iteration 58360, lr = 0.0002
I0526 12:05:07.122921 15117 solver.cpp:233] Iteration 58370, loss = 0.00667355
I0526 12:05:07.122970 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0066737 (* 1 = 0.0066737 loss)
I0526 12:05:07.122979 15117 sgd_solver.cpp:294] Iteration 58370, lr = 0.0002
I0526 12:05:13.436666 15117 solver.cpp:233] Iteration 58380, loss = 0.0184038
I0526 12:05:13.436709 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.018404 (* 1 = 0.018404 loss)
I0526 12:05:13.436717 15117 sgd_solver.cpp:294] Iteration 58380, lr = 0.0002
I0526 12:05:19.749132 15117 solver.cpp:233] Iteration 58390, loss = 0.00963292
I0526 12:05:19.749179 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00963307 (* 1 = 0.00963307 loss)
I0526 12:05:19.749187 15117 sgd_solver.cpp:294] Iteration 58390, lr = 0.0002
I0526 12:05:25.500280 15117 solver.cpp:342] Iteration 58400, Testing net (#0)
I0526 12:05:38.309970 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.905
I0526 12:05:38.310194 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.460425 (* 1 = 0.460425 loss)
I0526 12:05:38.910536 15117 solver.cpp:233] Iteration 58400, loss = 0.0247341
I0526 12:05:38.910589 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0247342 (* 1 = 0.0247342 loss)
I0526 12:05:38.910598 15117 sgd_solver.cpp:294] Iteration 58400, lr = 0.0002
I0526 12:05:45.225246 15117 solver.cpp:233] Iteration 58410, loss = 0.0218022
I0526 12:05:45.225296 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0218023 (* 1 = 0.0218023 loss)
I0526 12:05:45.225306 15117 sgd_solver.cpp:294] Iteration 58410, lr = 0.0002
I0526 12:05:51.536916 15117 solver.cpp:233] Iteration 58420, loss = 0.0182721
I0526 12:05:51.536964 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0182723 (* 1 = 0.0182723 loss)
I0526 12:05:51.536979 15117 sgd_solver.cpp:294] Iteration 58420, lr = 0.0002
I0526 12:05:57.827410 15117 solver.cpp:233] Iteration 58430, loss = 0.00947576
I0526 12:05:57.827464 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00947591 (* 1 = 0.00947591 loss)
I0526 12:05:57.827473 15117 sgd_solver.cpp:294] Iteration 58430, lr = 0.0002
I0526 12:06:04.112859 15117 solver.cpp:233] Iteration 58440, loss = 0.004927
I0526 12:06:04.112907 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00492715 (* 1 = 0.00492715 loss)
I0526 12:06:04.112916 15117 sgd_solver.cpp:294] Iteration 58440, lr = 0.0002
I0526 12:06:10.412205 15117 solver.cpp:233] Iteration 58450, loss = 0.0212561
I0526 12:06:10.412444 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0212562 (* 1 = 0.0212562 loss)
I0526 12:06:10.412470 15117 sgd_solver.cpp:294] Iteration 58450, lr = 0.0002
I0526 12:06:16.755463 15117 solver.cpp:233] Iteration 58460, loss = 0.0050203
I0526 12:06:16.755517 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00502045 (* 1 = 0.00502045 loss)
I0526 12:06:16.755527 15117 sgd_solver.cpp:294] Iteration 58460, lr = 0.0002
I0526 12:06:23.046721 15117 solver.cpp:233] Iteration 58470, loss = 0.00694817
I0526 12:06:23.046769 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00694832 (* 1 = 0.00694832 loss)
I0526 12:06:23.046778 15117 sgd_solver.cpp:294] Iteration 58470, lr = 0.0002
I0526 12:06:29.332686 15117 solver.cpp:233] Iteration 58480, loss = 0.00926095
I0526 12:06:29.332741 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0092611 (* 1 = 0.0092611 loss)
I0526 12:06:29.332749 15117 sgd_solver.cpp:294] Iteration 58480, lr = 0.0002
I0526 12:06:35.617758 15117 solver.cpp:233] Iteration 58490, loss = 0.00350378
I0526 12:06:35.617805 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00350393 (* 1 = 0.00350393 loss)
I0526 12:06:35.617813 15117 sgd_solver.cpp:294] Iteration 58490, lr = 0.0002
I0526 12:06:41.304179 15117 solver.cpp:342] Iteration 58500, Testing net (#0)
I0526 12:06:54.110236 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9064
I0526 12:06:54.110287 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.443779 (* 1 = 0.443779 loss)
I0526 12:06:54.710031 15117 solver.cpp:233] Iteration 58500, loss = 0.0145486
I0526 12:06:54.710077 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0145488 (* 1 = 0.0145488 loss)
I0526 12:06:54.710085 15117 sgd_solver.cpp:294] Iteration 58500, lr = 0.0002
I0526 12:07:01.019150 15117 solver.cpp:233] Iteration 58510, loss = 0.00825293
I0526 12:07:01.019201 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00825308 (* 1 = 0.00825308 loss)
I0526 12:07:01.019210 15117 sgd_solver.cpp:294] Iteration 58510, lr = 0.0002
I0526 12:07:07.343294 15117 solver.cpp:233] Iteration 58520, loss = 0.0160632
I0526 12:07:07.343339 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0160633 (* 1 = 0.0160633 loss)
I0526 12:07:07.343348 15117 sgd_solver.cpp:294] Iteration 58520, lr = 0.0002
I0526 12:07:13.652828 15117 solver.cpp:233] Iteration 58530, loss = 0.026722
I0526 12:07:13.653017 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0267222 (* 1 = 0.0267222 loss)
I0526 12:07:13.653026 15117 sgd_solver.cpp:294] Iteration 58530, lr = 0.0002
I0526 12:07:19.946773 15117 solver.cpp:233] Iteration 58540, loss = 0.00382701
I0526 12:07:19.946820 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00382716 (* 1 = 0.00382716 loss)
I0526 12:07:19.946828 15117 sgd_solver.cpp:294] Iteration 58540, lr = 0.0002
I0526 12:07:26.245363 15117 solver.cpp:233] Iteration 58550, loss = 0.0213491
I0526 12:07:26.245410 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0213492 (* 1 = 0.0213492 loss)
I0526 12:07:26.245419 15117 sgd_solver.cpp:294] Iteration 58550, lr = 0.0002
I0526 12:07:32.555500 15117 solver.cpp:233] Iteration 58560, loss = 0.0102243
I0526 12:07:32.555557 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0102245 (* 1 = 0.0102245 loss)
I0526 12:07:32.555564 15117 sgd_solver.cpp:294] Iteration 58560, lr = 0.0002
I0526 12:07:38.867918 15117 solver.cpp:233] Iteration 58570, loss = 0.0238465
I0526 12:07:38.867964 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0238467 (* 1 = 0.0238467 loss)
I0526 12:07:38.867972 15117 sgd_solver.cpp:294] Iteration 58570, lr = 0.0002
I0526 12:07:45.179497 15117 solver.cpp:233] Iteration 58580, loss = 0.00959639
I0526 12:07:45.179766 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00959654 (* 1 = 0.00959654 loss)
I0526 12:07:45.179795 15117 sgd_solver.cpp:294] Iteration 58580, lr = 0.0002
I0526 12:07:51.489418 15117 solver.cpp:233] Iteration 58590, loss = 0.00290427
I0526 12:07:51.489466 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00290442 (* 1 = 0.00290442 loss)
I0526 12:07:51.489475 15117 sgd_solver.cpp:294] Iteration 58590, lr = 0.0002
I0526 12:07:57.201808 15117 solver.cpp:342] Iteration 58600, Testing net (#0)
I0526 12:08:10.106528 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9028
I0526 12:08:10.106590 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.461294 (* 1 = 0.461294 loss)
I0526 12:08:10.705363 15117 solver.cpp:233] Iteration 58600, loss = 0.00200059
I0526 12:08:10.705418 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00200074 (* 1 = 0.00200074 loss)
I0526 12:08:10.705428 15117 sgd_solver.cpp:294] Iteration 58600, lr = 0.0002
I0526 12:08:16.994995 15117 solver.cpp:233] Iteration 58610, loss = 0.0106225
I0526 12:08:16.995141 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0106226 (* 1 = 0.0106226 loss)
I0526 12:08:16.995151 15117 sgd_solver.cpp:294] Iteration 58610, lr = 0.0002
I0526 12:08:23.283591 15117 solver.cpp:233] Iteration 58620, loss = 0.0146926
I0526 12:08:23.283633 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0146928 (* 1 = 0.0146928 loss)
I0526 12:08:23.283643 15117 sgd_solver.cpp:294] Iteration 58620, lr = 0.0002
I0526 12:08:29.573189 15117 solver.cpp:233] Iteration 58630, loss = 0.0133886
I0526 12:08:29.573225 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0133888 (* 1 = 0.0133888 loss)
I0526 12:08:29.573232 15117 sgd_solver.cpp:294] Iteration 58630, lr = 0.0002
I0526 12:08:35.858156 15117 solver.cpp:233] Iteration 58640, loss = 0.00584639
I0526 12:08:35.858201 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00584654 (* 1 = 0.00584654 loss)
I0526 12:08:35.858209 15117 sgd_solver.cpp:294] Iteration 58640, lr = 0.0002
I0526 12:08:42.144873 15117 solver.cpp:233] Iteration 58650, loss = 0.00325555
I0526 12:08:42.144919 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00325571 (* 1 = 0.00325571 loss)
I0526 12:08:42.144927 15117 sgd_solver.cpp:294] Iteration 58650, lr = 0.0002
I0526 12:08:48.434032 15117 solver.cpp:233] Iteration 58660, loss = 0.0120208
I0526 12:08:48.434231 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.012021 (* 1 = 0.012021 loss)
I0526 12:08:48.434258 15117 sgd_solver.cpp:294] Iteration 58660, lr = 0.0002
I0526 12:08:54.734072 15117 solver.cpp:233] Iteration 58670, loss = 0.0331281
I0526 12:08:54.734120 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0331283 (* 1 = 0.0331283 loss)
I0526 12:08:54.734128 15117 sgd_solver.cpp:294] Iteration 58670, lr = 0.0002
I0526 12:09:01.020287 15117 solver.cpp:233] Iteration 58680, loss = 0.00491929
I0526 12:09:01.020330 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00491944 (* 1 = 0.00491944 loss)
I0526 12:09:01.020336 15117 sgd_solver.cpp:294] Iteration 58680, lr = 0.0002
I0526 12:09:07.307997 15117 solver.cpp:233] Iteration 58690, loss = 0.00596211
I0526 12:09:07.308038 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00596226 (* 1 = 0.00596226 loss)
I0526 12:09:07.308044 15117 sgd_solver.cpp:294] Iteration 58690, lr = 0.0002
I0526 12:09:12.997189 15117 solver.cpp:342] Iteration 58700, Testing net (#0)
I0526 12:09:25.775583 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9051
I0526 12:09:25.775745 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.45088 (* 1 = 0.45088 loss)
I0526 12:09:26.372251 15117 solver.cpp:233] Iteration 58700, loss = 0.0141762
I0526 12:09:26.372275 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0141764 (* 1 = 0.0141764 loss)
I0526 12:09:26.372282 15117 sgd_solver.cpp:294] Iteration 58700, lr = 0.0002
I0526 12:09:32.662598 15117 solver.cpp:233] Iteration 58710, loss = 0.0112085
I0526 12:09:32.662642 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0112086 (* 1 = 0.0112086 loss)
I0526 12:09:32.662649 15117 sgd_solver.cpp:294] Iteration 58710, lr = 0.0002
I0526 12:09:38.949008 15117 solver.cpp:233] Iteration 58720, loss = 0.00409444
I0526 12:09:38.949049 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00409459 (* 1 = 0.00409459 loss)
I0526 12:09:38.949055 15117 sgd_solver.cpp:294] Iteration 58720, lr = 0.0002
I0526 12:09:45.237459 15117 solver.cpp:233] Iteration 58730, loss = 0.0132563
I0526 12:09:45.237498 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0132565 (* 1 = 0.0132565 loss)
I0526 12:09:45.237504 15117 sgd_solver.cpp:294] Iteration 58730, lr = 0.0002
I0526 12:09:51.523897 15117 solver.cpp:233] Iteration 58740, loss = 0.0121839
I0526 12:09:51.523934 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0121841 (* 1 = 0.0121841 loss)
I0526 12:09:51.523941 15117 sgd_solver.cpp:294] Iteration 58740, lr = 0.0002
I0526 12:09:57.812059 15117 solver.cpp:233] Iteration 58750, loss = 0.0111332
I0526 12:09:57.812180 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0111334 (* 1 = 0.0111334 loss)
I0526 12:09:57.812188 15117 sgd_solver.cpp:294] Iteration 58750, lr = 0.0002
I0526 12:10:04.098572 15117 solver.cpp:233] Iteration 58760, loss = 0.00763715
I0526 12:10:04.098613 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0076373 (* 1 = 0.0076373 loss)
I0526 12:10:04.098620 15117 sgd_solver.cpp:294] Iteration 58760, lr = 0.0002
I0526 12:10:10.381299 15117 solver.cpp:233] Iteration 58770, loss = 0.0100754
I0526 12:10:10.381340 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0100755 (* 1 = 0.0100755 loss)
I0526 12:10:10.381345 15117 sgd_solver.cpp:294] Iteration 58770, lr = 0.0002
I0526 12:10:16.666935 15117 solver.cpp:233] Iteration 58780, loss = 0.00803224
I0526 12:10:16.666978 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00803239 (* 1 = 0.00803239 loss)
I0526 12:10:16.666985 15117 sgd_solver.cpp:294] Iteration 58780, lr = 0.0002
I0526 12:10:22.954874 15117 solver.cpp:233] Iteration 58790, loss = 0.00520002
I0526 12:10:22.954926 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00520017 (* 1 = 0.00520017 loss)
I0526 12:10:22.954933 15117 sgd_solver.cpp:294] Iteration 58790, lr = 0.0002
I0526 12:10:28.646896 15117 solver.cpp:342] Iteration 58800, Testing net (#0)
I0526 12:10:41.433753 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9045
I0526 12:10:41.433794 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.447026 (* 1 = 0.447026 loss)
I0526 12:10:42.030750 15117 solver.cpp:233] Iteration 58800, loss = 0.00338878
I0526 12:10:42.030787 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00338893 (* 1 = 0.00338893 loss)
I0526 12:10:42.030794 15117 sgd_solver.cpp:294] Iteration 58800, lr = 0.0002
I0526 12:10:48.319779 15117 solver.cpp:233] Iteration 58810, loss = 0.00594253
I0526 12:10:48.319821 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00594268 (* 1 = 0.00594268 loss)
I0526 12:10:48.319828 15117 sgd_solver.cpp:294] Iteration 58810, lr = 0.0002
I0526 12:10:54.617096 15117 solver.cpp:233] Iteration 58820, loss = 0.0222541
I0526 12:10:54.617125 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0222543 (* 1 = 0.0222543 loss)
I0526 12:10:54.617131 15117 sgd_solver.cpp:294] Iteration 58820, lr = 0.0002
I0526 12:11:00.927877 15117 solver.cpp:233] Iteration 58830, loss = 0.00394512
I0526 12:11:00.928031 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00394527 (* 1 = 0.00394527 loss)
I0526 12:11:00.928040 15117 sgd_solver.cpp:294] Iteration 58830, lr = 0.0002
I0526 12:11:07.242630 15117 solver.cpp:233] Iteration 58840, loss = 0.00602706
I0526 12:11:07.242740 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00602721 (* 1 = 0.00602721 loss)
I0526 12:11:07.242749 15117 sgd_solver.cpp:294] Iteration 58840, lr = 0.0002
I0526 12:11:13.553542 15117 solver.cpp:233] Iteration 58850, loss = 0.00554416
I0526 12:11:13.553585 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00554431 (* 1 = 0.00554431 loss)
I0526 12:11:13.553591 15117 sgd_solver.cpp:294] Iteration 58850, lr = 0.0002
I0526 12:11:19.866013 15117 solver.cpp:233] Iteration 58860, loss = 0.00429687
I0526 12:11:19.866044 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00429702 (* 1 = 0.00429702 loss)
I0526 12:11:19.866050 15117 sgd_solver.cpp:294] Iteration 58860, lr = 0.0002
I0526 12:11:26.179016 15117 solver.cpp:233] Iteration 58870, loss = 0.0127036
I0526 12:11:26.179057 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0127038 (* 1 = 0.0127038 loss)
I0526 12:11:26.179064 15117 sgd_solver.cpp:294] Iteration 58870, lr = 0.0002
I0526 12:11:32.492919 15117 solver.cpp:233] Iteration 58880, loss = 0.0215302
I0526 12:11:32.493044 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0215303 (* 1 = 0.0215303 loss)
I0526 12:11:32.493052 15117 sgd_solver.cpp:294] Iteration 58880, lr = 0.0002
I0526 12:11:38.801295 15117 solver.cpp:233] Iteration 58890, loss = 0.017626
I0526 12:11:38.801337 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0176262 (* 1 = 0.0176262 loss)
I0526 12:11:38.801343 15117 sgd_solver.cpp:294] Iteration 58890, lr = 0.0002
I0526 12:11:44.512732 15117 solver.cpp:342] Iteration 58900, Testing net (#0)
I0526 12:11:57.321533 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.905
I0526 12:11:57.321578 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.448909 (* 1 = 0.448909 loss)
I0526 12:11:57.920862 15117 solver.cpp:233] Iteration 58900, loss = 0.00940733
I0526 12:11:57.920917 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00940748 (* 1 = 0.00940748 loss)
I0526 12:11:57.920925 15117 sgd_solver.cpp:294] Iteration 58900, lr = 0.0002
I0526 12:12:04.228317 15117 solver.cpp:233] Iteration 58910, loss = 0.011229
I0526 12:12:04.228421 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0112292 (* 1 = 0.0112292 loss)
I0526 12:12:04.228430 15117 sgd_solver.cpp:294] Iteration 58910, lr = 0.0002
I0526 12:12:10.539366 15117 solver.cpp:233] Iteration 58920, loss = 0.0125792
I0526 12:12:10.539402 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0125794 (* 1 = 0.0125794 loss)
I0526 12:12:10.539409 15117 sgd_solver.cpp:294] Iteration 58920, lr = 0.0002
I0526 12:12:16.851423 15117 solver.cpp:233] Iteration 58930, loss = 0.00628968
I0526 12:12:16.851461 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00628983 (* 1 = 0.00628983 loss)
I0526 12:12:16.851469 15117 sgd_solver.cpp:294] Iteration 58930, lr = 0.0002
I0526 12:12:23.161340 15117 solver.cpp:233] Iteration 58940, loss = 0.00519525
I0526 12:12:23.161377 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0051954 (* 1 = 0.0051954 loss)
I0526 12:12:23.161384 15117 sgd_solver.cpp:294] Iteration 58940, lr = 0.0002
I0526 12:12:29.471534 15117 solver.cpp:233] Iteration 58950, loss = 0.0110239
I0526 12:12:29.471575 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.011024 (* 1 = 0.011024 loss)
I0526 12:12:29.471581 15117 sgd_solver.cpp:294] Iteration 58950, lr = 0.0002
I0526 12:12:35.769565 15117 solver.cpp:233] Iteration 58960, loss = 0.00498862
I0526 12:12:35.769704 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00498877 (* 1 = 0.00498877 loss)
I0526 12:12:35.769717 15117 sgd_solver.cpp:294] Iteration 58960, lr = 0.0002
I0526 12:12:42.053834 15117 solver.cpp:233] Iteration 58970, loss = 0.00754748
I0526 12:12:42.053863 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00754763 (* 1 = 0.00754763 loss)
I0526 12:12:42.053869 15117 sgd_solver.cpp:294] Iteration 58970, lr = 0.0002
I0526 12:12:48.341250 15117 solver.cpp:233] Iteration 58980, loss = 0.0126933
I0526 12:12:48.341294 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0126934 (* 1 = 0.0126934 loss)
I0526 12:12:48.341300 15117 sgd_solver.cpp:294] Iteration 58980, lr = 0.0002
I0526 12:12:54.627876 15117 solver.cpp:233] Iteration 58990, loss = 0.00740091
I0526 12:12:54.627909 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00740106 (* 1 = 0.00740106 loss)
I0526 12:12:54.627917 15117 sgd_solver.cpp:294] Iteration 58990, lr = 0.0002
I0526 12:13:00.315948 15117 solver.cpp:342] Iteration 59000, Testing net (#0)
I0526 12:13:13.113054 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9062
I0526 12:13:13.113286 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.434272 (* 1 = 0.434272 loss)
I0526 12:13:13.712132 15117 solver.cpp:233] Iteration 59000, loss = 0.00325156
I0526 12:13:13.712174 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00325171 (* 1 = 0.00325171 loss)
I0526 12:13:13.712184 15117 sgd_solver.cpp:294] Iteration 59000, lr = 0.0002
I0526 12:13:20.022403 15117 solver.cpp:233] Iteration 59010, loss = 0.0167504
I0526 12:13:20.022430 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0167505 (* 1 = 0.0167505 loss)
I0526 12:13:20.022438 15117 sgd_solver.cpp:294] Iteration 59010, lr = 0.0002
I0526 12:13:26.332006 15117 solver.cpp:233] Iteration 59020, loss = 0.0055529
I0526 12:13:26.332048 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00555306 (* 1 = 0.00555306 loss)
I0526 12:13:26.332056 15117 sgd_solver.cpp:294] Iteration 59020, lr = 0.0002
I0526 12:13:32.643317 15117 solver.cpp:233] Iteration 59030, loss = 0.004693
I0526 12:13:32.643354 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00469315 (* 1 = 0.00469315 loss)
I0526 12:13:32.643360 15117 sgd_solver.cpp:294] Iteration 59030, lr = 0.0002
I0526 12:13:38.955680 15117 solver.cpp:233] Iteration 59040, loss = 0.0195123
I0526 12:13:38.955718 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0195125 (* 1 = 0.0195125 loss)
I0526 12:13:38.955724 15117 sgd_solver.cpp:294] Iteration 59040, lr = 0.0002
I0526 12:13:45.262470 15117 solver.cpp:233] Iteration 59050, loss = 0.021964
I0526 12:13:45.262588 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0219642 (* 1 = 0.0219642 loss)
I0526 12:13:45.262596 15117 sgd_solver.cpp:294] Iteration 59050, lr = 0.0002
I0526 12:13:51.573812 15117 solver.cpp:233] Iteration 59060, loss = 0.00903511
I0526 12:13:51.573853 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00903526 (* 1 = 0.00903526 loss)
I0526 12:13:51.573860 15117 sgd_solver.cpp:294] Iteration 59060, lr = 0.0002
I0526 12:13:57.885946 15117 solver.cpp:233] Iteration 59070, loss = 0.0153755
I0526 12:13:57.885989 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0153757 (* 1 = 0.0153757 loss)
I0526 12:13:57.885995 15117 sgd_solver.cpp:294] Iteration 59070, lr = 0.0002
I0526 12:14:04.195395 15117 solver.cpp:233] Iteration 59080, loss = 0.0115802
I0526 12:14:04.195436 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0115804 (* 1 = 0.0115804 loss)
I0526 12:14:04.195443 15117 sgd_solver.cpp:294] Iteration 59080, lr = 0.0002
I0526 12:14:10.504258 15117 solver.cpp:233] Iteration 59090, loss = 0.0058023
I0526 12:14:10.504302 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00580246 (* 1 = 0.00580246 loss)
I0526 12:14:10.504308 15117 sgd_solver.cpp:294] Iteration 59090, lr = 0.0002
I0526 12:14:16.212939 15117 solver.cpp:342] Iteration 59100, Testing net (#0)
I0526 12:14:29.022713 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.907
I0526 12:14:29.022761 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.445219 (* 1 = 0.445219 loss)
I0526 12:14:29.622710 15117 solver.cpp:233] Iteration 59100, loss = 0.00571243
I0526 12:14:29.622750 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00571258 (* 1 = 0.00571258 loss)
I0526 12:14:29.622757 15117 sgd_solver.cpp:294] Iteration 59100, lr = 0.0002
I0526 12:14:35.930938 15117 solver.cpp:233] Iteration 59110, loss = 0.00577219
I0526 12:14:35.930975 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00577235 (* 1 = 0.00577235 loss)
I0526 12:14:35.930984 15117 sgd_solver.cpp:294] Iteration 59110, lr = 0.0002
I0526 12:14:42.242260 15117 solver.cpp:233] Iteration 59120, loss = 0.00984235
I0526 12:14:42.242296 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00984251 (* 1 = 0.00984251 loss)
I0526 12:14:42.242303 15117 sgd_solver.cpp:294] Iteration 59120, lr = 0.0002
I0526 12:14:48.552078 15117 solver.cpp:233] Iteration 59130, loss = 0.00867346
I0526 12:14:48.552201 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00867362 (* 1 = 0.00867362 loss)
I0526 12:14:48.552211 15117 sgd_solver.cpp:294] Iteration 59130, lr = 0.0002
I0526 12:14:54.865650 15117 solver.cpp:233] Iteration 59140, loss = 0.00363229
I0526 12:14:54.865687 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00363245 (* 1 = 0.00363245 loss)
I0526 12:14:54.865694 15117 sgd_solver.cpp:294] Iteration 59140, lr = 0.0002
I0526 12:15:01.176533 15117 solver.cpp:233] Iteration 59150, loss = 0.00544473
I0526 12:15:01.176591 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00544489 (* 1 = 0.00544489 loss)
I0526 12:15:01.176599 15117 sgd_solver.cpp:294] Iteration 59150, lr = 0.0002
I0526 12:15:07.484443 15117 solver.cpp:233] Iteration 59160, loss = 0.00938709
I0526 12:15:07.484483 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00938725 (* 1 = 0.00938725 loss)
I0526 12:15:07.484489 15117 sgd_solver.cpp:294] Iteration 59160, lr = 0.0002
I0526 12:15:13.799518 15117 solver.cpp:233] Iteration 59170, loss = 0.0200695
I0526 12:15:13.799561 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0200696 (* 1 = 0.0200696 loss)
I0526 12:15:13.799568 15117 sgd_solver.cpp:294] Iteration 59170, lr = 0.0002
I0526 12:15:20.107604 15117 solver.cpp:233] Iteration 59180, loss = 0.00380723
I0526 12:15:20.107724 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00380738 (* 1 = 0.00380738 loss)
I0526 12:15:20.107733 15117 sgd_solver.cpp:294] Iteration 59180, lr = 0.0002
I0526 12:15:26.417665 15117 solver.cpp:233] Iteration 59190, loss = 0.00227657
I0526 12:15:26.417706 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00227672 (* 1 = 0.00227672 loss)
I0526 12:15:26.417713 15117 sgd_solver.cpp:294] Iteration 59190, lr = 0.0002
I0526 12:15:32.122342 15117 solver.cpp:342] Iteration 59200, Testing net (#0)
I0526 12:15:44.932508 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9068
I0526 12:15:44.932555 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.444907 (* 1 = 0.444907 loss)
I0526 12:15:45.531919 15117 solver.cpp:233] Iteration 59200, loss = 0.00833413
I0526 12:15:45.531950 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00833428 (* 1 = 0.00833428 loss)
I0526 12:15:45.531957 15117 sgd_solver.cpp:294] Iteration 59200, lr = 0.0002
I0526 12:15:51.839712 15117 solver.cpp:233] Iteration 59210, loss = 0.00645183
I0526 12:15:51.839918 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00645199 (* 1 = 0.00645199 loss)
I0526 12:15:51.839946 15117 sgd_solver.cpp:294] Iteration 59210, lr = 0.0002
I0526 12:15:58.151679 15117 solver.cpp:233] Iteration 59220, loss = 0.00466159
I0526 12:15:58.151707 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00466175 (* 1 = 0.00466175 loss)
I0526 12:15:58.151715 15117 sgd_solver.cpp:294] Iteration 59220, lr = 0.0002
I0526 12:16:04.462951 15117 solver.cpp:233] Iteration 59230, loss = 0.00833246
I0526 12:16:04.462995 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00833262 (* 1 = 0.00833262 loss)
I0526 12:16:04.463001 15117 sgd_solver.cpp:294] Iteration 59230, lr = 0.0002
I0526 12:16:10.776501 15117 solver.cpp:233] Iteration 59240, loss = 0.00261605
I0526 12:16:10.776541 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00261621 (* 1 = 0.00261621 loss)
I0526 12:16:10.776547 15117 sgd_solver.cpp:294] Iteration 59240, lr = 0.0002
I0526 12:16:17.097287 15117 solver.cpp:233] Iteration 59250, loss = 0.00845864
I0526 12:16:17.097332 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00845879 (* 1 = 0.00845879 loss)
I0526 12:16:17.097338 15117 sgd_solver.cpp:294] Iteration 59250, lr = 0.0002
I0526 12:16:23.433948 15117 solver.cpp:233] Iteration 59260, loss = 0.0114278
I0526 12:16:23.434224 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.011428 (* 1 = 0.011428 loss)
I0526 12:16:23.434253 15117 sgd_solver.cpp:294] Iteration 59260, lr = 0.0002
I0526 12:16:29.771755 15117 solver.cpp:233] Iteration 59270, loss = 0.00887547
I0526 12:16:29.771795 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00887563 (* 1 = 0.00887563 loss)
I0526 12:16:29.771801 15117 sgd_solver.cpp:294] Iteration 59270, lr = 0.0002
I0526 12:16:36.106359 15117 solver.cpp:233] Iteration 59280, loss = 0.00365262
I0526 12:16:36.106400 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00365278 (* 1 = 0.00365278 loss)
I0526 12:16:36.106407 15117 sgd_solver.cpp:294] Iteration 59280, lr = 0.0002
I0526 12:16:42.436605 15117 solver.cpp:233] Iteration 59290, loss = 0.0172572
I0526 12:16:42.436657 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0172573 (* 1 = 0.0172573 loss)
I0526 12:16:42.436663 15117 sgd_solver.cpp:294] Iteration 59290, lr = 0.0002
I0526 12:16:48.173450 15117 solver.cpp:342] Iteration 59300, Testing net (#0)
I0526 12:17:00.998980 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9059
I0526 12:17:00.999114 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.452237 (* 1 = 0.452237 loss)
I0526 12:17:01.597223 15117 solver.cpp:233] Iteration 59300, loss = 0.0144654
I0526 12:17:01.597262 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0144655 (* 1 = 0.0144655 loss)
I0526 12:17:01.597270 15117 sgd_solver.cpp:294] Iteration 59300, lr = 0.0002
I0526 12:17:07.909721 15117 solver.cpp:233] Iteration 59310, loss = 0.00743543
I0526 12:17:07.909761 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00743559 (* 1 = 0.00743559 loss)
I0526 12:17:07.909768 15117 sgd_solver.cpp:294] Iteration 59310, lr = 0.0002
I0526 12:17:14.223484 15117 solver.cpp:233] Iteration 59320, loss = 0.0174554
I0526 12:17:14.223526 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0174555 (* 1 = 0.0174555 loss)
I0526 12:17:14.223533 15117 sgd_solver.cpp:294] Iteration 59320, lr = 0.0002
I0526 12:17:20.535753 15117 solver.cpp:233] Iteration 59330, loss = 0.00997838
I0526 12:17:20.535792 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00997854 (* 1 = 0.00997854 loss)
I0526 12:17:20.535799 15117 sgd_solver.cpp:294] Iteration 59330, lr = 0.0002
I0526 12:17:26.831537 15117 solver.cpp:233] Iteration 59340, loss = 0.00530805
I0526 12:17:26.831578 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00530821 (* 1 = 0.00530821 loss)
I0526 12:17:26.831584 15117 sgd_solver.cpp:294] Iteration 59340, lr = 0.0002
I0526 12:17:33.119504 15117 solver.cpp:233] Iteration 59350, loss = 0.0109267
I0526 12:17:33.119632 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0109268 (* 1 = 0.0109268 loss)
I0526 12:17:33.119640 15117 sgd_solver.cpp:294] Iteration 59350, lr = 0.0002
I0526 12:17:39.402370 15117 solver.cpp:233] Iteration 59360, loss = 0.00829351
I0526 12:17:39.402415 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00829366 (* 1 = 0.00829366 loss)
I0526 12:17:39.402426 15117 sgd_solver.cpp:294] Iteration 59360, lr = 0.0002
I0526 12:17:45.690433 15117 solver.cpp:233] Iteration 59370, loss = 0.00751203
I0526 12:17:45.690475 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00751218 (* 1 = 0.00751218 loss)
I0526 12:17:45.690481 15117 sgd_solver.cpp:294] Iteration 59370, lr = 0.0002
I0526 12:17:51.975863 15117 solver.cpp:233] Iteration 59380, loss = 0.00449527
I0526 12:17:51.975903 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00449543 (* 1 = 0.00449543 loss)
I0526 12:17:51.975909 15117 sgd_solver.cpp:294] Iteration 59380, lr = 0.0002
I0526 12:17:58.262298 15117 solver.cpp:233] Iteration 59390, loss = 0.00351543
I0526 12:17:58.262341 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00351559 (* 1 = 0.00351559 loss)
I0526 12:17:58.262347 15117 sgd_solver.cpp:294] Iteration 59390, lr = 0.0002
I0526 12:18:03.952941 15117 solver.cpp:342] Iteration 59400, Testing net (#0)
I0526 12:18:16.739156 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9042
I0526 12:18:16.739203 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.450069 (* 1 = 0.450069 loss)
I0526 12:18:17.335981 15117 solver.cpp:233] Iteration 59400, loss = 0.0139968
I0526 12:18:17.336014 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.013997 (* 1 = 0.013997 loss)
I0526 12:18:17.336021 15117 sgd_solver.cpp:294] Iteration 59400, lr = 0.0002
I0526 12:18:23.623548 15117 solver.cpp:233] Iteration 59410, loss = 0.0106447
I0526 12:18:23.623584 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0106448 (* 1 = 0.0106448 loss)
I0526 12:18:23.623589 15117 sgd_solver.cpp:294] Iteration 59410, lr = 0.0002
I0526 12:18:29.908990 15117 solver.cpp:233] Iteration 59420, loss = 0.0101284
I0526 12:18:29.909034 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0101286 (* 1 = 0.0101286 loss)
I0526 12:18:29.909041 15117 sgd_solver.cpp:294] Iteration 59420, lr = 0.0002
I0526 12:18:36.194566 15117 solver.cpp:233] Iteration 59430, loss = 0.0127804
I0526 12:18:36.194690 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0127806 (* 1 = 0.0127806 loss)
I0526 12:18:36.194700 15117 sgd_solver.cpp:294] Iteration 59430, lr = 0.0002
I0526 12:18:42.480830 15117 solver.cpp:233] Iteration 59440, loss = 0.0155907
I0526 12:18:42.480870 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0155909 (* 1 = 0.0155909 loss)
I0526 12:18:42.480877 15117 sgd_solver.cpp:294] Iteration 59440, lr = 0.0002
I0526 12:18:48.764825 15117 solver.cpp:233] Iteration 59450, loss = 0.0125046
I0526 12:18:48.764853 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0125047 (* 1 = 0.0125047 loss)
I0526 12:18:48.764859 15117 sgd_solver.cpp:294] Iteration 59450, lr = 0.0002
I0526 12:18:55.057981 15117 solver.cpp:233] Iteration 59460, loss = 0.032027
I0526 12:18:55.058022 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0320272 (* 1 = 0.0320272 loss)
I0526 12:18:55.058028 15117 sgd_solver.cpp:294] Iteration 59460, lr = 0.0002
I0526 12:19:01.368233 15117 solver.cpp:233] Iteration 59470, loss = 0.00992924
I0526 12:19:01.368283 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00992939 (* 1 = 0.00992939 loss)
I0526 12:19:01.368289 15117 sgd_solver.cpp:294] Iteration 59470, lr = 0.0002
I0526 12:19:07.680874 15117 solver.cpp:233] Iteration 59480, loss = 0.00941611
I0526 12:19:07.680959 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00941627 (* 1 = 0.00941627 loss)
I0526 12:19:07.680968 15117 sgd_solver.cpp:294] Iteration 59480, lr = 0.0002
I0526 12:19:13.991575 15117 solver.cpp:233] Iteration 59490, loss = 0.0100799
I0526 12:19:13.991605 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0100801 (* 1 = 0.0100801 loss)
I0526 12:19:13.991611 15117 sgd_solver.cpp:294] Iteration 59490, lr = 0.0002
I0526 12:19:19.705025 15117 solver.cpp:342] Iteration 59500, Testing net (#0)
I0526 12:19:32.522117 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9044
I0526 12:19:32.522168 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.452907 (* 1 = 0.452907 loss)
I0526 12:19:33.121994 15117 solver.cpp:233] Iteration 59500, loss = 0.0112498
I0526 12:19:33.122032 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0112499 (* 1 = 0.0112499 loss)
I0526 12:19:33.122040 15117 sgd_solver.cpp:294] Iteration 59500, lr = 0.0002
I0526 12:19:39.435304 15117 solver.cpp:233] Iteration 59510, loss = 0.0414595
I0526 12:19:39.435545 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0414597 (* 1 = 0.0414597 loss)
I0526 12:19:39.435572 15117 sgd_solver.cpp:294] Iteration 59510, lr = 0.0002
I0526 12:19:45.754065 15117 solver.cpp:233] Iteration 59520, loss = 0.0164569
I0526 12:19:45.754112 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.016457 (* 1 = 0.016457 loss)
I0526 12:19:45.754118 15117 sgd_solver.cpp:294] Iteration 59520, lr = 0.0002
I0526 12:19:52.078461 15117 solver.cpp:233] Iteration 59530, loss = 0.00904094
I0526 12:19:52.078490 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0090411 (* 1 = 0.0090411 loss)
I0526 12:19:52.078495 15117 sgd_solver.cpp:294] Iteration 59530, lr = 0.0002
I0526 12:19:58.397683 15117 solver.cpp:233] Iteration 59540, loss = 0.0069184
I0526 12:19:58.397728 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00691856 (* 1 = 0.00691856 loss)
I0526 12:19:58.397735 15117 sgd_solver.cpp:294] Iteration 59540, lr = 0.0002
I0526 12:20:04.722904 15117 solver.cpp:233] Iteration 59550, loss = 0.00763413
I0526 12:20:04.722945 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0076343 (* 1 = 0.0076343 loss)
I0526 12:20:04.722954 15117 sgd_solver.cpp:294] Iteration 59550, lr = 0.0002
I0526 12:20:11.043843 15117 solver.cpp:233] Iteration 59560, loss = 0.00516714
I0526 12:20:11.044060 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0051673 (* 1 = 0.0051673 loss)
I0526 12:20:11.044088 15117 sgd_solver.cpp:294] Iteration 59560, lr = 0.0002
I0526 12:20:17.362612 15117 solver.cpp:233] Iteration 59570, loss = 0.0177864
I0526 12:20:17.362643 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0177866 (* 1 = 0.0177866 loss)
I0526 12:20:17.362649 15117 sgd_solver.cpp:294] Iteration 59570, lr = 0.0002
I0526 12:20:23.682077 15117 solver.cpp:233] Iteration 59580, loss = 0.00441773
I0526 12:20:23.682129 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00441789 (* 1 = 0.00441789 loss)
I0526 12:20:23.682137 15117 sgd_solver.cpp:294] Iteration 59580, lr = 0.0002
I0526 12:20:29.999205 15117 solver.cpp:233] Iteration 59590, loss = 0.0078295
I0526 12:20:29.999249 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00782966 (* 1 = 0.00782966 loss)
I0526 12:20:29.999256 15117 sgd_solver.cpp:294] Iteration 59590, lr = 0.0002
I0526 12:20:35.720268 15117 solver.cpp:342] Iteration 59600, Testing net (#0)
I0526 12:20:48.508688 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9065
I0526 12:20:48.508899 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.442061 (* 1 = 0.442061 loss)
I0526 12:20:49.106534 15117 solver.cpp:233] Iteration 59600, loss = 0.00592007
I0526 12:20:49.106576 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00592023 (* 1 = 0.00592023 loss)
I0526 12:20:49.106583 15117 sgd_solver.cpp:294] Iteration 59600, lr = 0.0002
I0526 12:20:55.394943 15117 solver.cpp:233] Iteration 59610, loss = 0.0397518
I0526 12:20:55.394984 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.039752 (* 1 = 0.039752 loss)
I0526 12:20:55.394991 15117 sgd_solver.cpp:294] Iteration 59610, lr = 0.0002
I0526 12:21:01.684520 15117 solver.cpp:233] Iteration 59620, loss = 0.00489269
I0526 12:21:01.684563 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00489285 (* 1 = 0.00489285 loss)
I0526 12:21:01.684571 15117 sgd_solver.cpp:294] Iteration 59620, lr = 0.0002
I0526 12:21:07.975330 15117 solver.cpp:233] Iteration 59630, loss = 0.00621842
I0526 12:21:07.975378 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00621859 (* 1 = 0.00621859 loss)
I0526 12:21:07.975385 15117 sgd_solver.cpp:294] Iteration 59630, lr = 0.0002
I0526 12:21:14.265765 15117 solver.cpp:233] Iteration 59640, loss = 0.0115141
I0526 12:21:14.265810 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0115143 (* 1 = 0.0115143 loss)
I0526 12:21:14.265816 15117 sgd_solver.cpp:294] Iteration 59640, lr = 0.0002
I0526 12:21:20.560967 15117 solver.cpp:233] Iteration 59650, loss = 0.0149598
I0526 12:21:20.561204 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.01496 (* 1 = 0.01496 loss)
I0526 12:21:20.561233 15117 sgd_solver.cpp:294] Iteration 59650, lr = 0.0002
I0526 12:21:26.856609 15117 solver.cpp:233] Iteration 59660, loss = 0.0149227
I0526 12:21:26.856652 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0149229 (* 1 = 0.0149229 loss)
I0526 12:21:26.856658 15117 sgd_solver.cpp:294] Iteration 59660, lr = 0.0002
I0526 12:21:33.145978 15117 solver.cpp:233] Iteration 59670, loss = 0.0163045
I0526 12:21:33.146023 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0163046 (* 1 = 0.0163046 loss)
I0526 12:21:33.146028 15117 sgd_solver.cpp:294] Iteration 59670, lr = 0.0002
I0526 12:21:39.438760 15117 solver.cpp:233] Iteration 59680, loss = 0.00879395
I0526 12:21:39.438803 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00879411 (* 1 = 0.00879411 loss)
I0526 12:21:39.438810 15117 sgd_solver.cpp:294] Iteration 59680, lr = 0.0002
I0526 12:21:45.724616 15117 solver.cpp:233] Iteration 59690, loss = 0.00904319
I0526 12:21:45.724659 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00904335 (* 1 = 0.00904335 loss)
I0526 12:21:45.724668 15117 sgd_solver.cpp:294] Iteration 59690, lr = 0.0002
I0526 12:21:51.418377 15117 solver.cpp:342] Iteration 59700, Testing net (#0)
I0526 12:22:04.201253 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9029
I0526 12:22:04.201300 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.468254 (* 1 = 0.468254 loss)
I0526 12:22:04.797992 15117 solver.cpp:233] Iteration 59700, loss = 0.0209165
I0526 12:22:04.798018 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0209167 (* 1 = 0.0209167 loss)
I0526 12:22:04.798025 15117 sgd_solver.cpp:294] Iteration 59700, lr = 0.0002
I0526 12:22:11.085804 15117 solver.cpp:233] Iteration 59710, loss = 0.00777831
I0526 12:22:11.085846 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00777847 (* 1 = 0.00777847 loss)
I0526 12:22:11.085853 15117 sgd_solver.cpp:294] Iteration 59710, lr = 0.0002
I0526 12:22:17.376649 15117 solver.cpp:233] Iteration 59720, loss = 0.0162164
I0526 12:22:17.376691 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0162165 (* 1 = 0.0162165 loss)
I0526 12:22:17.376698 15117 sgd_solver.cpp:294] Iteration 59720, lr = 0.0002
I0526 12:22:23.666515 15117 solver.cpp:233] Iteration 59730, loss = 0.0143006
I0526 12:22:23.666743 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0143008 (* 1 = 0.0143008 loss)
I0526 12:22:23.666771 15117 sgd_solver.cpp:294] Iteration 59730, lr = 0.0002
I0526 12:22:29.963147 15117 solver.cpp:233] Iteration 59740, loss = 0.00691941
I0526 12:22:29.963178 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00691957 (* 1 = 0.00691957 loss)
I0526 12:22:29.963186 15117 sgd_solver.cpp:294] Iteration 59740, lr = 0.0002
I0526 12:22:36.252975 15117 solver.cpp:233] Iteration 59750, loss = 0.00797609
I0526 12:22:36.253018 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00797625 (* 1 = 0.00797625 loss)
I0526 12:22:36.253026 15117 sgd_solver.cpp:294] Iteration 59750, lr = 0.0002
I0526 12:22:42.545117 15117 solver.cpp:233] Iteration 59760, loss = 0.00636353
I0526 12:22:42.545167 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0063637 (* 1 = 0.0063637 loss)
I0526 12:22:42.545174 15117 sgd_solver.cpp:294] Iteration 59760, lr = 0.0002
I0526 12:22:48.831440 15117 solver.cpp:233] Iteration 59770, loss = 0.0118902
I0526 12:22:48.831485 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0118904 (* 1 = 0.0118904 loss)
I0526 12:22:48.831492 15117 sgd_solver.cpp:294] Iteration 59770, lr = 0.0002
I0526 12:22:55.117827 15117 solver.cpp:233] Iteration 59780, loss = 0.00451437
I0526 12:22:55.118057 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00451453 (* 1 = 0.00451453 loss)
I0526 12:22:55.118086 15117 sgd_solver.cpp:294] Iteration 59780, lr = 0.0002
I0526 12:23:01.410647 15117 solver.cpp:233] Iteration 59790, loss = 0.0168593
I0526 12:23:01.410694 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0168595 (* 1 = 0.0168595 loss)
I0526 12:23:01.410702 15117 sgd_solver.cpp:294] Iteration 59790, lr = 0.0002
I0526 12:23:07.103483 15117 solver.cpp:342] Iteration 59800, Testing net (#0)
I0526 12:23:19.884099 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9045
I0526 12:23:19.884143 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.455883 (* 1 = 0.455883 loss)
I0526 12:23:20.481669 15117 solver.cpp:233] Iteration 59800, loss = 0.0037974
I0526 12:23:20.481709 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00379756 (* 1 = 0.00379756 loss)
I0526 12:23:20.481715 15117 sgd_solver.cpp:294] Iteration 59800, lr = 0.0002
I0526 12:23:26.774549 15117 solver.cpp:233] Iteration 59810, loss = 0.0036345
I0526 12:23:26.774786 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00363466 (* 1 = 0.00363466 loss)
I0526 12:23:26.774816 15117 sgd_solver.cpp:294] Iteration 59810, lr = 0.0002
I0526 12:23:33.067517 15117 solver.cpp:233] Iteration 59820, loss = 0.00388714
I0526 12:23:33.067562 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0038873 (* 1 = 0.0038873 loss)
I0526 12:23:33.067569 15117 sgd_solver.cpp:294] Iteration 59820, lr = 0.0002
I0526 12:23:39.357049 15117 solver.cpp:233] Iteration 59830, loss = 0.00683266
I0526 12:23:39.357084 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00683282 (* 1 = 0.00683282 loss)
I0526 12:23:39.357090 15117 sgd_solver.cpp:294] Iteration 59830, lr = 0.0002
I0526 12:23:45.646677 15117 solver.cpp:233] Iteration 59840, loss = 0.00769558
I0526 12:23:45.646723 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00769575 (* 1 = 0.00769575 loss)
I0526 12:23:45.646730 15117 sgd_solver.cpp:294] Iteration 59840, lr = 0.0002
I0526 12:23:51.934031 15117 solver.cpp:233] Iteration 59850, loss = 0.00648776
I0526 12:23:51.934073 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00648792 (* 1 = 0.00648792 loss)
I0526 12:23:51.934080 15117 sgd_solver.cpp:294] Iteration 59850, lr = 0.0002
I0526 12:23:58.221294 15117 solver.cpp:233] Iteration 59860, loss = 0.0124012
I0526 12:23:58.221525 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0124014 (* 1 = 0.0124014 loss)
I0526 12:23:58.221554 15117 sgd_solver.cpp:294] Iteration 59860, lr = 0.0002
I0526 12:24:04.509613 15117 solver.cpp:233] Iteration 59870, loss = 0.0107294
I0526 12:24:04.509655 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0107295 (* 1 = 0.0107295 loss)
I0526 12:24:04.509662 15117 sgd_solver.cpp:294] Iteration 59870, lr = 0.0002
I0526 12:24:10.798470 15117 solver.cpp:233] Iteration 59880, loss = 0.0249406
I0526 12:24:10.798512 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0249408 (* 1 = 0.0249408 loss)
I0526 12:24:10.798519 15117 sgd_solver.cpp:294] Iteration 59880, lr = 0.0002
I0526 12:24:17.085106 15117 solver.cpp:233] Iteration 59890, loss = 0.0056239
I0526 12:24:17.085137 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00562406 (* 1 = 0.00562406 loss)
I0526 12:24:17.085145 15117 sgd_solver.cpp:294] Iteration 59890, lr = 0.0002
I0526 12:24:22.777215 15117 solver.cpp:342] Iteration 59900, Testing net (#0)
I0526 12:24:35.559731 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9043
I0526 12:24:35.559994 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.457402 (* 1 = 0.457402 loss)
I0526 12:24:36.160527 15117 solver.cpp:233] Iteration 59900, loss = 0.0117571
I0526 12:24:36.160588 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0117573 (* 1 = 0.0117573 loss)
I0526 12:24:36.160600 15117 sgd_solver.cpp:294] Iteration 59900, lr = 0.0002
I0526 12:24:42.448573 15117 solver.cpp:233] Iteration 59910, loss = 0.0124376
I0526 12:24:42.448601 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0124378 (* 1 = 0.0124378 loss)
I0526 12:24:42.448608 15117 sgd_solver.cpp:294] Iteration 59910, lr = 0.0002
I0526 12:24:48.735281 15117 solver.cpp:233] Iteration 59920, loss = 0.00973273
I0526 12:24:48.735326 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00973289 (* 1 = 0.00973289 loss)
I0526 12:24:48.735332 15117 sgd_solver.cpp:294] Iteration 59920, lr = 0.0002
I0526 12:24:55.023077 15117 solver.cpp:233] Iteration 59930, loss = 0.0113553
I0526 12:24:55.023119 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0113555 (* 1 = 0.0113555 loss)
I0526 12:24:55.023126 15117 sgd_solver.cpp:294] Iteration 59930, lr = 0.0002
I0526 12:25:01.308660 15117 solver.cpp:233] Iteration 59940, loss = 0.00536497
I0526 12:25:01.308706 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00536513 (* 1 = 0.00536513 loss)
I0526 12:25:01.308712 15117 sgd_solver.cpp:294] Iteration 59940, lr = 0.0002
I0526 12:25:07.594733 15117 solver.cpp:233] Iteration 59950, loss = 0.0047347
I0526 12:25:07.594964 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00473486 (* 1 = 0.00473486 loss)
I0526 12:25:07.594990 15117 sgd_solver.cpp:294] Iteration 59950, lr = 0.0002
I0526 12:25:13.880728 15117 solver.cpp:233] Iteration 59960, loss = 0.00976264
I0526 12:25:13.880776 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0097628 (* 1 = 0.0097628 loss)
I0526 12:25:13.880784 15117 sgd_solver.cpp:294] Iteration 59960, lr = 0.0002
I0526 12:25:20.169391 15117 solver.cpp:233] Iteration 59970, loss = 0.0084422
I0526 12:25:20.169433 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00844236 (* 1 = 0.00844236 loss)
I0526 12:25:20.169440 15117 sgd_solver.cpp:294] Iteration 59970, lr = 0.0002
I0526 12:25:26.455360 15117 solver.cpp:233] Iteration 59980, loss = 0.00742885
I0526 12:25:26.455387 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00742901 (* 1 = 0.00742901 loss)
I0526 12:25:26.455394 15117 sgd_solver.cpp:294] Iteration 59980, lr = 0.0002
I0526 12:25:32.741474 15117 solver.cpp:233] Iteration 59990, loss = 0.00475733
I0526 12:25:32.741518 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00475749 (* 1 = 0.00475749 loss)
I0526 12:25:32.741526 15117 sgd_solver.cpp:294] Iteration 59990, lr = 0.0002
I0526 12:25:38.428747 15117 solver.cpp:342] Iteration 60000, Testing net (#0)
I0526 12:25:51.216521 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9071
I0526 12:25:51.216568 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.441943 (* 1 = 0.441943 loss)
I0526 12:25:51.812814 15117 solver.cpp:233] Iteration 60000, loss = 0.00670471
I0526 12:25:51.812854 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00670487 (* 1 = 0.00670487 loss)
I0526 12:25:51.812860 15117 sgd_solver.cpp:294] Iteration 60000, lr = 0.0002
I0526 12:25:58.102645 15117 solver.cpp:233] Iteration 60010, loss = 0.0023013
I0526 12:25:58.102705 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00230146 (* 1 = 0.00230146 loss)
I0526 12:25:58.102712 15117 sgd_solver.cpp:294] Iteration 60010, lr = 0.0002
I0526 12:26:04.389602 15117 solver.cpp:233] Iteration 60020, loss = 0.0129461
I0526 12:26:04.389644 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0129462 (* 1 = 0.0129462 loss)
I0526 12:26:04.389652 15117 sgd_solver.cpp:294] Iteration 60020, lr = 0.0002
I0526 12:26:10.679198 15117 solver.cpp:233] Iteration 60030, loss = 0.00731662
I0526 12:26:10.679467 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00731678 (* 1 = 0.00731678 loss)
I0526 12:26:10.679508 15117 sgd_solver.cpp:294] Iteration 60030, lr = 0.0002
I0526 12:26:16.971779 15117 solver.cpp:233] Iteration 60040, loss = 0.00482482
I0526 12:26:16.971827 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00482498 (* 1 = 0.00482498 loss)
I0526 12:26:16.971834 15117 sgd_solver.cpp:294] Iteration 60040, lr = 0.0002
I0526 12:26:23.262722 15117 solver.cpp:233] Iteration 60050, loss = 0.0084161
I0526 12:26:23.262763 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00841626 (* 1 = 0.00841626 loss)
I0526 12:26:23.262771 15117 sgd_solver.cpp:294] Iteration 60050, lr = 0.0002
I0526 12:26:29.551985 15117 solver.cpp:233] Iteration 60060, loss = 0.00484187
I0526 12:26:29.552027 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00484203 (* 1 = 0.00484203 loss)
I0526 12:26:29.552034 15117 sgd_solver.cpp:294] Iteration 60060, lr = 0.0002
I0526 12:26:35.842622 15117 solver.cpp:233] Iteration 60070, loss = 0.00774619
I0526 12:26:35.842664 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00774635 (* 1 = 0.00774635 loss)
I0526 12:26:35.842672 15117 sgd_solver.cpp:294] Iteration 60070, lr = 0.0002
I0526 12:26:42.134567 15117 solver.cpp:233] Iteration 60080, loss = 0.005894
I0526 12:26:42.134790 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00589415 (* 1 = 0.00589415 loss)
I0526 12:26:42.134820 15117 sgd_solver.cpp:294] Iteration 60080, lr = 0.0002
I0526 12:26:48.425318 15117 solver.cpp:233] Iteration 60090, loss = 0.00623404
I0526 12:26:48.425361 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0062342 (* 1 = 0.0062342 loss)
I0526 12:26:48.425369 15117 sgd_solver.cpp:294] Iteration 60090, lr = 0.0002
I0526 12:26:54.119994 15117 solver.cpp:342] Iteration 60100, Testing net (#0)
I0526 12:27:06.901609 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9057
I0526 12:27:06.901654 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.453138 (* 1 = 0.453138 loss)
I0526 12:27:07.498783 15117 solver.cpp:233] Iteration 60100, loss = 0.0032061
I0526 12:27:07.498822 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00320626 (* 1 = 0.00320626 loss)
I0526 12:27:07.498831 15117 sgd_solver.cpp:294] Iteration 60100, lr = 0.0002
I0526 12:27:13.786347 15117 solver.cpp:233] Iteration 60110, loss = 0.00919604
I0526 12:27:13.786562 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00919619 (* 1 = 0.00919619 loss)
I0526 12:27:13.786592 15117 sgd_solver.cpp:294] Iteration 60110, lr = 0.0002
I0526 12:27:20.076505 15117 solver.cpp:233] Iteration 60120, loss = 0.00455526
I0526 12:27:20.076546 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00455542 (* 1 = 0.00455542 loss)
I0526 12:27:20.076553 15117 sgd_solver.cpp:294] Iteration 60120, lr = 0.0002
I0526 12:27:26.364948 15117 solver.cpp:233] Iteration 60130, loss = 0.00584343
I0526 12:27:26.364989 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00584359 (* 1 = 0.00584359 loss)
I0526 12:27:26.364996 15117 sgd_solver.cpp:294] Iteration 60130, lr = 0.0002
I0526 12:27:32.657393 15117 solver.cpp:233] Iteration 60140, loss = 0.0152572
I0526 12:27:32.657426 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0152574 (* 1 = 0.0152574 loss)
I0526 12:27:32.657434 15117 sgd_solver.cpp:294] Iteration 60140, lr = 0.0002
I0526 12:27:38.947088 15117 solver.cpp:233] Iteration 60150, loss = 0.00283114
I0526 12:27:38.947129 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0028313 (* 1 = 0.0028313 loss)
I0526 12:27:38.947136 15117 sgd_solver.cpp:294] Iteration 60150, lr = 0.0002
I0526 12:27:45.239061 15117 solver.cpp:233] Iteration 60160, loss = 0.00514742
I0526 12:27:45.239282 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00514759 (* 1 = 0.00514759 loss)
I0526 12:27:45.239311 15117 sgd_solver.cpp:294] Iteration 60160, lr = 0.0002
I0526 12:27:51.531666 15117 solver.cpp:233] Iteration 60170, loss = 0.0179144
I0526 12:27:51.531713 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0179146 (* 1 = 0.0179146 loss)
I0526 12:27:51.531720 15117 sgd_solver.cpp:294] Iteration 60170, lr = 0.0002
I0526 12:27:57.821251 15117 solver.cpp:233] Iteration 60180, loss = 0.0143416
I0526 12:27:57.821297 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0143418 (* 1 = 0.0143418 loss)
I0526 12:27:57.821303 15117 sgd_solver.cpp:294] Iteration 60180, lr = 0.0002
I0526 12:28:04.109335 15117 solver.cpp:233] Iteration 60190, loss = 0.0187902
I0526 12:28:04.109376 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0187903 (* 1 = 0.0187903 loss)
I0526 12:28:04.109383 15117 sgd_solver.cpp:294] Iteration 60190, lr = 0.0002
I0526 12:28:09.801894 15117 solver.cpp:342] Iteration 60200, Testing net (#0)
I0526 12:28:22.584137 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9044
I0526 12:28:22.584395 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.460861 (* 1 = 0.460861 loss)
I0526 12:28:23.182716 15117 solver.cpp:233] Iteration 60200, loss = 0.010383
I0526 12:28:23.182763 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0103832 (* 1 = 0.0103832 loss)
I0526 12:28:23.182772 15117 sgd_solver.cpp:294] Iteration 60200, lr = 0.0002
I0526 12:28:29.472452 15117 solver.cpp:233] Iteration 60210, loss = 0.00406014
I0526 12:28:29.472494 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0040603 (* 1 = 0.0040603 loss)
I0526 12:28:29.472501 15117 sgd_solver.cpp:294] Iteration 60210, lr = 0.0002
I0526 12:28:35.760885 15117 solver.cpp:233] Iteration 60220, loss = 0.0263038
I0526 12:28:35.760926 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.026304 (* 1 = 0.026304 loss)
I0526 12:28:35.760932 15117 sgd_solver.cpp:294] Iteration 60220, lr = 0.0002
I0526 12:28:42.052403 15117 solver.cpp:233] Iteration 60230, loss = 0.00527862
I0526 12:28:42.052430 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00527879 (* 1 = 0.00527879 loss)
I0526 12:28:42.052436 15117 sgd_solver.cpp:294] Iteration 60230, lr = 0.0002
I0526 12:28:48.339820 15117 solver.cpp:233] Iteration 60240, loss = 0.00768205
I0526 12:28:48.339864 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00768222 (* 1 = 0.00768222 loss)
I0526 12:28:48.339871 15117 sgd_solver.cpp:294] Iteration 60240, lr = 0.0002
I0526 12:28:54.629091 15117 solver.cpp:233] Iteration 60250, loss = 0.00569028
I0526 12:28:54.629323 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00569045 (* 1 = 0.00569045 loss)
I0526 12:28:54.629351 15117 sgd_solver.cpp:294] Iteration 60250, lr = 0.0002
I0526 12:29:00.919752 15117 solver.cpp:233] Iteration 60260, loss = 0.00437663
I0526 12:29:00.919797 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0043768 (* 1 = 0.0043768 loss)
I0526 12:29:00.919805 15117 sgd_solver.cpp:294] Iteration 60260, lr = 0.0002
I0526 12:29:07.212822 15117 solver.cpp:233] Iteration 60270, loss = 0.00515663
I0526 12:29:07.212863 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0051568 (* 1 = 0.0051568 loss)
I0526 12:29:07.212870 15117 sgd_solver.cpp:294] Iteration 60270, lr = 0.0002
I0526 12:29:13.503943 15117 solver.cpp:233] Iteration 60280, loss = 0.0110536
I0526 12:29:13.503988 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0110537 (* 1 = 0.0110537 loss)
I0526 12:29:13.503994 15117 sgd_solver.cpp:294] Iteration 60280, lr = 0.0002
I0526 12:29:19.787946 15117 solver.cpp:233] Iteration 60290, loss = 0.0062651
I0526 12:29:19.787982 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00626527 (* 1 = 0.00626527 loss)
I0526 12:29:19.787989 15117 sgd_solver.cpp:294] Iteration 60290, lr = 0.0002
I0526 12:29:25.478173 15117 solver.cpp:342] Iteration 60300, Testing net (#0)
I0526 12:29:38.270020 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9046
I0526 12:29:38.270067 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.452001 (* 1 = 0.452001 loss)
I0526 12:29:38.866736 15117 solver.cpp:233] Iteration 60300, loss = 0.0087334
I0526 12:29:38.866775 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00873357 (* 1 = 0.00873357 loss)
I0526 12:29:38.866782 15117 sgd_solver.cpp:294] Iteration 60300, lr = 0.0002
I0526 12:29:45.157033 15117 solver.cpp:233] Iteration 60310, loss = 0.00567817
I0526 12:29:45.157063 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00567834 (* 1 = 0.00567834 loss)
I0526 12:29:45.157070 15117 sgd_solver.cpp:294] Iteration 60310, lr = 0.0002
I0526 12:29:51.444344 15117 solver.cpp:233] Iteration 60320, loss = 0.0164099
I0526 12:29:51.444385 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.01641 (* 1 = 0.01641 loss)
I0526 12:29:51.444391 15117 sgd_solver.cpp:294] Iteration 60320, lr = 0.0002
I0526 12:29:57.735340 15117 solver.cpp:233] Iteration 60330, loss = 0.00538779
I0526 12:29:57.735608 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00538796 (* 1 = 0.00538796 loss)
I0526 12:29:57.735635 15117 sgd_solver.cpp:294] Iteration 60330, lr = 0.0002
I0526 12:30:04.028731 15117 solver.cpp:233] Iteration 60340, loss = 0.0176617
I0526 12:30:04.028772 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0176619 (* 1 = 0.0176619 loss)
I0526 12:30:04.028779 15117 sgd_solver.cpp:294] Iteration 60340, lr = 0.0002
I0526 12:30:10.320158 15117 solver.cpp:233] Iteration 60350, loss = 0.00537146
I0526 12:30:10.320202 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00537163 (* 1 = 0.00537163 loss)
I0526 12:30:10.320209 15117 sgd_solver.cpp:294] Iteration 60350, lr = 0.0002
I0526 12:30:16.609542 15117 solver.cpp:233] Iteration 60360, loss = 0.00825822
I0526 12:30:16.609586 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00825839 (* 1 = 0.00825839 loss)
I0526 12:30:16.609593 15117 sgd_solver.cpp:294] Iteration 60360, lr = 0.0002
I0526 12:30:22.899097 15117 solver.cpp:233] Iteration 60370, loss = 0.00963667
I0526 12:30:22.899127 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00963684 (* 1 = 0.00963684 loss)
I0526 12:30:22.899133 15117 sgd_solver.cpp:294] Iteration 60370, lr = 0.0002
I0526 12:30:29.189908 15117 solver.cpp:233] Iteration 60380, loss = 0.0306099
I0526 12:30:29.190131 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.03061 (* 1 = 0.03061 loss)
I0526 12:30:29.190160 15117 sgd_solver.cpp:294] Iteration 60380, lr = 0.0002
I0526 12:30:35.482648 15117 solver.cpp:233] Iteration 60390, loss = 0.00370616
I0526 12:30:35.482693 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00370633 (* 1 = 0.00370633 loss)
I0526 12:30:35.482700 15117 sgd_solver.cpp:294] Iteration 60390, lr = 0.0002
I0526 12:30:41.177335 15117 solver.cpp:342] Iteration 60400, Testing net (#0)
I0526 12:30:53.965524 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9056
I0526 12:30:53.965558 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.446265 (* 1 = 0.446265 loss)
I0526 12:30:54.561383 15117 solver.cpp:233] Iteration 60400, loss = 0.0152104
I0526 12:30:54.561424 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0152106 (* 1 = 0.0152106 loss)
I0526 12:30:54.561430 15117 sgd_solver.cpp:294] Iteration 60400, lr = 0.0002
I0526 12:31:00.852784 15117 solver.cpp:233] Iteration 60410, loss = 0.00431743
I0526 12:31:00.852983 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00431761 (* 1 = 0.00431761 loss)
I0526 12:31:00.853013 15117 sgd_solver.cpp:294] Iteration 60410, lr = 0.0002
I0526 12:31:07.146684 15117 solver.cpp:233] Iteration 60420, loss = 0.0111882
I0526 12:31:07.146725 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0111884 (* 1 = 0.0111884 loss)
I0526 12:31:07.146733 15117 sgd_solver.cpp:294] Iteration 60420, lr = 0.0002
I0526 12:31:13.434643 15117 solver.cpp:233] Iteration 60430, loss = 0.0116664
I0526 12:31:13.434679 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0116666 (* 1 = 0.0116666 loss)
I0526 12:31:13.434702 15117 sgd_solver.cpp:294] Iteration 60430, lr = 0.0002
I0526 12:31:19.725368 15117 solver.cpp:233] Iteration 60440, loss = 0.0061923
I0526 12:31:19.725407 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00619247 (* 1 = 0.00619247 loss)
I0526 12:31:19.725414 15117 sgd_solver.cpp:294] Iteration 60440, lr = 0.0002
I0526 12:31:26.011384 15117 solver.cpp:233] Iteration 60450, loss = 0.0067192
I0526 12:31:26.011426 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00671938 (* 1 = 0.00671938 loss)
I0526 12:31:26.011433 15117 sgd_solver.cpp:294] Iteration 60450, lr = 0.0002
I0526 12:31:32.300942 15117 solver.cpp:233] Iteration 60460, loss = 0.0157967
I0526 12:31:32.301188 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0157969 (* 1 = 0.0157969 loss)
I0526 12:31:32.301218 15117 sgd_solver.cpp:294] Iteration 60460, lr = 0.0002
I0526 12:31:38.592196 15117 solver.cpp:233] Iteration 60470, loss = 0.00348235
I0526 12:31:38.592236 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00348253 (* 1 = 0.00348253 loss)
I0526 12:31:38.592242 15117 sgd_solver.cpp:294] Iteration 60470, lr = 0.0002
I0526 12:31:44.882853 15117 solver.cpp:233] Iteration 60480, loss = 0.0036476
I0526 12:31:44.882897 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00364777 (* 1 = 0.00364777 loss)
I0526 12:31:44.882905 15117 sgd_solver.cpp:294] Iteration 60480, lr = 0.0002
I0526 12:31:51.174857 15117 solver.cpp:233] Iteration 60490, loss = 0.00485295
I0526 12:31:51.174902 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00485313 (* 1 = 0.00485313 loss)
I0526 12:31:51.174909 15117 sgd_solver.cpp:294] Iteration 60490, lr = 0.0002
I0526 12:31:56.868104 15117 solver.cpp:342] Iteration 60500, Testing net (#0)
I0526 12:32:09.651365 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9059
I0526 12:32:09.651592 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.460442 (* 1 = 0.460442 loss)
I0526 12:32:10.250288 15117 solver.cpp:233] Iteration 60500, loss = 0.00842529
I0526 12:32:10.250334 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00842547 (* 1 = 0.00842547 loss)
I0526 12:32:10.250342 15117 sgd_solver.cpp:294] Iteration 60500, lr = 0.0002
I0526 12:32:16.541370 15117 solver.cpp:233] Iteration 60510, loss = 0.00912134
I0526 12:32:16.541414 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00912152 (* 1 = 0.00912152 loss)
I0526 12:32:16.541421 15117 sgd_solver.cpp:294] Iteration 60510, lr = 0.0002
I0526 12:32:22.829766 15117 solver.cpp:233] Iteration 60520, loss = 0.0068373
I0526 12:32:22.829808 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00683747 (* 1 = 0.00683747 loss)
I0526 12:32:22.829815 15117 sgd_solver.cpp:294] Iteration 60520, lr = 0.0002
I0526 12:32:29.114626 15117 solver.cpp:233] Iteration 60530, loss = 0.0150929
I0526 12:32:29.114672 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.015093 (* 1 = 0.015093 loss)
I0526 12:32:29.114681 15117 sgd_solver.cpp:294] Iteration 60530, lr = 0.0002
I0526 12:32:35.403276 15117 solver.cpp:233] Iteration 60540, loss = 0.0145039
I0526 12:32:35.403317 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0145041 (* 1 = 0.0145041 loss)
I0526 12:32:35.403324 15117 sgd_solver.cpp:294] Iteration 60540, lr = 0.0002
I0526 12:32:41.696743 15117 solver.cpp:233] Iteration 60550, loss = 0.00695241
I0526 12:32:41.696964 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00695259 (* 1 = 0.00695259 loss)
I0526 12:32:41.696993 15117 sgd_solver.cpp:294] Iteration 60550, lr = 0.0002
I0526 12:32:47.989462 15117 solver.cpp:233] Iteration 60560, loss = 0.00130515
I0526 12:32:47.989509 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00130532 (* 1 = 0.00130532 loss)
I0526 12:32:47.989516 15117 sgd_solver.cpp:294] Iteration 60560, lr = 0.0002
I0526 12:32:54.279186 15117 solver.cpp:233] Iteration 60570, loss = 0.00737518
I0526 12:32:54.279227 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00737535 (* 1 = 0.00737535 loss)
I0526 12:32:54.279239 15117 sgd_solver.cpp:294] Iteration 60570, lr = 0.0002
I0526 12:33:00.570631 15117 solver.cpp:233] Iteration 60580, loss = 0.00810556
I0526 12:33:00.570672 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00810574 (* 1 = 0.00810574 loss)
I0526 12:33:00.570679 15117 sgd_solver.cpp:294] Iteration 60580, lr = 0.0002
I0526 12:33:06.858665 15117 solver.cpp:233] Iteration 60590, loss = 0.0119505
I0526 12:33:06.858707 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0119507 (* 1 = 0.0119507 loss)
I0526 12:33:06.858714 15117 sgd_solver.cpp:294] Iteration 60590, lr = 0.0002
I0526 12:33:12.545303 15117 solver.cpp:342] Iteration 60600, Testing net (#0)
I0526 12:33:25.324380 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9044
I0526 12:33:25.324429 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.457771 (* 1 = 0.457771 loss)
I0526 12:33:25.921000 15117 solver.cpp:233] Iteration 60600, loss = 0.0110063
I0526 12:33:25.921039 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0110064 (* 1 = 0.0110064 loss)
I0526 12:33:25.921047 15117 sgd_solver.cpp:294] Iteration 60600, lr = 0.0002
I0526 12:33:32.207064 15117 solver.cpp:233] Iteration 60610, loss = 0.0100311
I0526 12:33:32.207109 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0100312 (* 1 = 0.0100312 loss)
I0526 12:33:32.207118 15117 sgd_solver.cpp:294] Iteration 60610, lr = 0.0002
I0526 12:33:38.500563 15117 solver.cpp:233] Iteration 60620, loss = 0.00714903
I0526 12:33:38.500605 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0071492 (* 1 = 0.0071492 loss)
I0526 12:33:38.500612 15117 sgd_solver.cpp:294] Iteration 60620, lr = 0.0002
I0526 12:33:44.793545 15117 solver.cpp:233] Iteration 60630, loss = 0.00929265
I0526 12:33:44.793694 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00929282 (* 1 = 0.00929282 loss)
I0526 12:33:44.793704 15117 sgd_solver.cpp:294] Iteration 60630, lr = 0.0002
I0526 12:33:51.085175 15117 solver.cpp:233] Iteration 60640, loss = 0.00769578
I0526 12:33:51.085216 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00769595 (* 1 = 0.00769595 loss)
I0526 12:33:51.085222 15117 sgd_solver.cpp:294] Iteration 60640, lr = 0.0002
I0526 12:33:57.378077 15117 solver.cpp:233] Iteration 60650, loss = 0.0142507
I0526 12:33:57.378118 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0142508 (* 1 = 0.0142508 loss)
I0526 12:33:57.378125 15117 sgd_solver.cpp:294] Iteration 60650, lr = 0.0002
I0526 12:34:03.669854 15117 solver.cpp:233] Iteration 60660, loss = 0.00922641
I0526 12:34:03.669898 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00922658 (* 1 = 0.00922658 loss)
I0526 12:34:03.669904 15117 sgd_solver.cpp:294] Iteration 60660, lr = 0.0002
I0526 12:34:09.959976 15117 solver.cpp:233] Iteration 60670, loss = 0.0102052
I0526 12:34:09.960017 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0102053 (* 1 = 0.0102053 loss)
I0526 12:34:09.960023 15117 sgd_solver.cpp:294] Iteration 60670, lr = 0.0002
I0526 12:34:16.251279 15117 solver.cpp:233] Iteration 60680, loss = 0.00634902
I0526 12:34:16.251497 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00634919 (* 1 = 0.00634919 loss)
I0526 12:34:16.251525 15117 sgd_solver.cpp:294] Iteration 60680, lr = 0.0002
I0526 12:34:22.541900 15117 solver.cpp:233] Iteration 60690, loss = 0.00793771
I0526 12:34:22.541941 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00793787 (* 1 = 0.00793787 loss)
I0526 12:34:22.541949 15117 sgd_solver.cpp:294] Iteration 60690, lr = 0.0002
I0526 12:34:28.235822 15117 solver.cpp:342] Iteration 60700, Testing net (#0)
I0526 12:34:41.040377 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9048
I0526 12:34:41.040442 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.452731 (* 1 = 0.452731 loss)
I0526 12:34:41.637718 15117 solver.cpp:233] Iteration 60700, loss = 0.00958454
I0526 12:34:41.637791 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00958471 (* 1 = 0.00958471 loss)
I0526 12:34:41.637802 15117 sgd_solver.cpp:294] Iteration 60700, lr = 0.0002
I0526 12:34:47.930228 15117 solver.cpp:233] Iteration 60710, loss = 0.0137236
I0526 12:34:47.930461 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0137238 (* 1 = 0.0137238 loss)
I0526 12:34:47.930488 15117 sgd_solver.cpp:294] Iteration 60710, lr = 0.0002
I0526 12:34:54.218935 15117 solver.cpp:233] Iteration 60720, loss = 0.00729559
I0526 12:34:54.218979 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00729575 (* 1 = 0.00729575 loss)
I0526 12:34:54.218986 15117 sgd_solver.cpp:294] Iteration 60720, lr = 0.0002
I0526 12:35:00.509555 15117 solver.cpp:233] Iteration 60730, loss = 0.0081485
I0526 12:35:00.509600 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00814866 (* 1 = 0.00814866 loss)
I0526 12:35:00.509608 15117 sgd_solver.cpp:294] Iteration 60730, lr = 0.0002
I0526 12:35:06.799599 15117 solver.cpp:233] Iteration 60740, loss = 0.00248672
I0526 12:35:06.799643 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00248689 (* 1 = 0.00248689 loss)
I0526 12:35:06.799649 15117 sgd_solver.cpp:294] Iteration 60740, lr = 0.0002
I0526 12:35:13.085557 15117 solver.cpp:233] Iteration 60750, loss = 0.00290309
I0526 12:35:13.085602 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00290326 (* 1 = 0.00290326 loss)
I0526 12:35:13.085608 15117 sgd_solver.cpp:294] Iteration 60750, lr = 0.0002
I0526 12:35:19.378418 15117 solver.cpp:233] Iteration 60760, loss = 0.018096
I0526 12:35:19.378631 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0180961 (* 1 = 0.0180961 loss)
I0526 12:35:19.378660 15117 sgd_solver.cpp:294] Iteration 60760, lr = 0.0002
I0526 12:35:25.667489 15117 solver.cpp:233] Iteration 60770, loss = 0.0198306
I0526 12:35:25.667532 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0198308 (* 1 = 0.0198308 loss)
I0526 12:35:25.667541 15117 sgd_solver.cpp:294] Iteration 60770, lr = 0.0002
I0526 12:35:31.953739 15117 solver.cpp:233] Iteration 60780, loss = 0.00278626
I0526 12:35:31.953783 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00278643 (* 1 = 0.00278643 loss)
I0526 12:35:31.953791 15117 sgd_solver.cpp:294] Iteration 60780, lr = 0.0002
I0526 12:35:38.238463 15117 solver.cpp:233] Iteration 60790, loss = 0.00798931
I0526 12:35:38.238509 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00798948 (* 1 = 0.00798948 loss)
I0526 12:35:38.238517 15117 sgd_solver.cpp:294] Iteration 60790, lr = 0.0002
I0526 12:35:43.928807 15117 solver.cpp:342] Iteration 60800, Testing net (#0)
I0526 12:35:56.715983 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9049
I0526 12:35:56.716198 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.453706 (* 1 = 0.453706 loss)
I0526 12:35:57.312147 15117 solver.cpp:233] Iteration 60800, loss = 0.00891659
I0526 12:35:57.312194 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00891676 (* 1 = 0.00891676 loss)
I0526 12:35:57.312203 15117 sgd_solver.cpp:294] Iteration 60800, lr = 0.0002
I0526 12:36:03.600847 15117 solver.cpp:233] Iteration 60810, loss = 0.00697967
I0526 12:36:03.600873 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00697984 (* 1 = 0.00697984 loss)
I0526 12:36:03.600880 15117 sgd_solver.cpp:294] Iteration 60810, lr = 0.0002
I0526 12:36:09.885287 15117 solver.cpp:233] Iteration 60820, loss = 0.00736577
I0526 12:36:09.885330 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00736594 (* 1 = 0.00736594 loss)
I0526 12:36:09.885337 15117 sgd_solver.cpp:294] Iteration 60820, lr = 0.0002
I0526 12:36:16.170425 15117 solver.cpp:233] Iteration 60830, loss = 0.00542347
I0526 12:36:16.170469 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00542363 (* 1 = 0.00542363 loss)
I0526 12:36:16.170476 15117 sgd_solver.cpp:294] Iteration 60830, lr = 0.0002
I0526 12:36:22.459801 15117 solver.cpp:233] Iteration 60840, loss = 0.00246018
I0526 12:36:22.459846 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00246034 (* 1 = 0.00246034 loss)
I0526 12:36:22.459852 15117 sgd_solver.cpp:294] Iteration 60840, lr = 0.0002
I0526 12:36:28.751608 15117 solver.cpp:233] Iteration 60850, loss = 0.0049624
I0526 12:36:28.751868 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00496256 (* 1 = 0.00496256 loss)
I0526 12:36:28.751898 15117 sgd_solver.cpp:294] Iteration 60850, lr = 0.0002
I0526 12:36:35.039060 15117 solver.cpp:233] Iteration 60860, loss = 0.035114
I0526 12:36:35.039114 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0351141 (* 1 = 0.0351141 loss)
I0526 12:36:35.039122 15117 sgd_solver.cpp:294] Iteration 60860, lr = 0.0002
I0526 12:36:41.323787 15117 solver.cpp:233] Iteration 60870, loss = 0.0115913
I0526 12:36:41.323832 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0115915 (* 1 = 0.0115915 loss)
I0526 12:36:41.323838 15117 sgd_solver.cpp:294] Iteration 60870, lr = 0.0002
I0526 12:36:47.609598 15117 solver.cpp:233] Iteration 60880, loss = 0.00506534
I0526 12:36:47.609632 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0050655 (* 1 = 0.0050655 loss)
I0526 12:36:47.609638 15117 sgd_solver.cpp:294] Iteration 60880, lr = 0.0002
I0526 12:36:53.896401 15117 solver.cpp:233] Iteration 60890, loss = 0.00409965
I0526 12:36:53.896447 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00409981 (* 1 = 0.00409981 loss)
I0526 12:36:53.896456 15117 sgd_solver.cpp:294] Iteration 60890, lr = 0.0002
I0526 12:36:59.589666 15117 solver.cpp:342] Iteration 60900, Testing net (#0)
I0526 12:37:12.369427 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9034
I0526 12:37:12.369475 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.445002 (* 1 = 0.445002 loss)
I0526 12:37:12.966897 15117 solver.cpp:233] Iteration 60900, loss = 0.0119505
I0526 12:37:12.966925 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0119506 (* 1 = 0.0119506 loss)
I0526 12:37:12.966933 15117 sgd_solver.cpp:294] Iteration 60900, lr = 0.0002
I0526 12:37:19.256867 15117 solver.cpp:233] Iteration 60910, loss = 0.0101981
I0526 12:37:19.256909 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0101982 (* 1 = 0.0101982 loss)
I0526 12:37:19.256916 15117 sgd_solver.cpp:294] Iteration 60910, lr = 0.0002
I0526 12:37:25.548205 15117 solver.cpp:233] Iteration 60920, loss = 0.00865113
I0526 12:37:25.548249 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00865129 (* 1 = 0.00865129 loss)
I0526 12:37:25.548256 15117 sgd_solver.cpp:294] Iteration 60920, lr = 0.0002
I0526 12:37:31.836760 15117 solver.cpp:233] Iteration 60930, loss = 0.00450306
I0526 12:37:31.836967 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00450323 (* 1 = 0.00450323 loss)
I0526 12:37:31.836995 15117 sgd_solver.cpp:294] Iteration 60930, lr = 0.0002
I0526 12:37:38.130323 15117 solver.cpp:233] Iteration 60940, loss = 0.014631
I0526 12:37:38.130385 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0146312 (* 1 = 0.0146312 loss)
I0526 12:37:38.130393 15117 sgd_solver.cpp:294] Iteration 60940, lr = 0.0002
I0526 12:37:44.422292 15117 solver.cpp:233] Iteration 60950, loss = 0.00563383
I0526 12:37:44.422338 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00563399 (* 1 = 0.00563399 loss)
I0526 12:37:44.422345 15117 sgd_solver.cpp:294] Iteration 60950, lr = 0.0002
I0526 12:37:50.710333 15117 solver.cpp:233] Iteration 60960, loss = 0.0180311
I0526 12:37:50.710371 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0180313 (* 1 = 0.0180313 loss)
I0526 12:37:50.710377 15117 sgd_solver.cpp:294] Iteration 60960, lr = 0.0002
I0526 12:37:56.999152 15117 solver.cpp:233] Iteration 60970, loss = 0.0132548
I0526 12:37:56.999196 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.013255 (* 1 = 0.013255 loss)
I0526 12:37:56.999208 15117 sgd_solver.cpp:294] Iteration 60970, lr = 0.0002
I0526 12:38:03.289890 15117 solver.cpp:233] Iteration 60980, loss = 0.00551702
I0526 12:38:03.290143 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00551718 (* 1 = 0.00551718 loss)
I0526 12:38:03.290172 15117 sgd_solver.cpp:294] Iteration 60980, lr = 0.0002
I0526 12:38:09.582576 15117 solver.cpp:233] Iteration 60990, loss = 0.00824469
I0526 12:38:09.582623 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00824485 (* 1 = 0.00824485 loss)
I0526 12:38:09.582631 15117 sgd_solver.cpp:294] Iteration 60990, lr = 0.0002
I0526 12:38:15.275403 15117 solver.cpp:342] Iteration 61000, Testing net (#0)
I0526 12:38:28.052268 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9049
I0526 12:38:28.052312 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.448307 (* 1 = 0.448307 loss)
I0526 12:38:28.648865 15117 solver.cpp:233] Iteration 61000, loss = 0.0123237
I0526 12:38:28.648902 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0123239 (* 1 = 0.0123239 loss)
I0526 12:38:28.648910 15117 sgd_solver.cpp:294] Iteration 61000, lr = 0.0002
I0526 12:38:34.940237 15117 solver.cpp:233] Iteration 61010, loss = 0.0099695
I0526 12:38:34.940362 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00996966 (* 1 = 0.00996966 loss)
I0526 12:38:34.940371 15117 sgd_solver.cpp:294] Iteration 61010, lr = 0.0002
I0526 12:38:41.228096 15117 solver.cpp:233] Iteration 61020, loss = 0.00878871
I0526 12:38:41.228142 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00878887 (* 1 = 0.00878887 loss)
I0526 12:38:41.228148 15117 sgd_solver.cpp:294] Iteration 61020, lr = 0.0002
I0526 12:38:47.513335 15117 solver.cpp:233] Iteration 61030, loss = 0.0237006
I0526 12:38:47.513378 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0237008 (* 1 = 0.0237008 loss)
I0526 12:38:47.513386 15117 sgd_solver.cpp:294] Iteration 61030, lr = 0.0002
I0526 12:38:53.802444 15117 solver.cpp:233] Iteration 61040, loss = 0.00464383
I0526 12:38:53.802489 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00464399 (* 1 = 0.00464399 loss)
I0526 12:38:53.802497 15117 sgd_solver.cpp:294] Iteration 61040, lr = 0.0002
I0526 12:39:00.093641 15117 solver.cpp:233] Iteration 61050, loss = 0.00882098
I0526 12:39:00.093674 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00882114 (* 1 = 0.00882114 loss)
I0526 12:39:00.093680 15117 sgd_solver.cpp:294] Iteration 61050, lr = 0.0002
I0526 12:39:06.380388 15117 solver.cpp:233] Iteration 61060, loss = 0.00921145
I0526 12:39:06.380579 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0092116 (* 1 = 0.0092116 loss)
I0526 12:39:06.380609 15117 sgd_solver.cpp:294] Iteration 61060, lr = 0.0002
I0526 12:39:12.668897 15117 solver.cpp:233] Iteration 61070, loss = 0.00782778
I0526 12:39:12.668939 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00782794 (* 1 = 0.00782794 loss)
I0526 12:39:12.668946 15117 sgd_solver.cpp:294] Iteration 61070, lr = 0.0002
I0526 12:39:18.958875 15117 solver.cpp:233] Iteration 61080, loss = 0.00719557
I0526 12:39:18.958915 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00719573 (* 1 = 0.00719573 loss)
I0526 12:39:18.958921 15117 sgd_solver.cpp:294] Iteration 61080, lr = 0.0002
I0526 12:39:25.244218 15117 solver.cpp:233] Iteration 61090, loss = 0.00966425
I0526 12:39:25.244261 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00966441 (* 1 = 0.00966441 loss)
I0526 12:39:25.244266 15117 sgd_solver.cpp:294] Iteration 61090, lr = 0.0002
I0526 12:39:30.936719 15117 solver.cpp:342] Iteration 61100, Testing net (#0)
I0526 12:39:43.725688 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.904
I0526 12:39:43.725914 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.460948 (* 1 = 0.460948 loss)
I0526 12:39:44.323479 15117 solver.cpp:233] Iteration 61100, loss = 0.00532595
I0526 12:39:44.323539 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00532611 (* 1 = 0.00532611 loss)
I0526 12:39:44.323545 15117 sgd_solver.cpp:294] Iteration 61100, lr = 0.0002
I0526 12:39:50.614446 15117 solver.cpp:233] Iteration 61110, loss = 0.00607308
I0526 12:39:50.614488 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00607324 (* 1 = 0.00607324 loss)
I0526 12:39:50.614495 15117 sgd_solver.cpp:294] Iteration 61110, lr = 0.0002
I0526 12:39:56.904309 15117 solver.cpp:233] Iteration 61120, loss = 0.00796222
I0526 12:39:56.904355 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00796238 (* 1 = 0.00796238 loss)
I0526 12:39:56.904361 15117 sgd_solver.cpp:294] Iteration 61120, lr = 0.0002
I0526 12:40:03.193570 15117 solver.cpp:233] Iteration 61130, loss = 0.00295857
I0526 12:40:03.193614 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00295873 (* 1 = 0.00295873 loss)
I0526 12:40:03.193620 15117 sgd_solver.cpp:294] Iteration 61130, lr = 0.0002
I0526 12:40:09.486210 15117 solver.cpp:233] Iteration 61140, loss = 0.00412749
I0526 12:40:09.486253 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00412765 (* 1 = 0.00412765 loss)
I0526 12:40:09.486260 15117 sgd_solver.cpp:294] Iteration 61140, lr = 0.0002
I0526 12:40:15.776345 15117 solver.cpp:233] Iteration 61150, loss = 0.00738757
I0526 12:40:15.776624 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00738773 (* 1 = 0.00738773 loss)
I0526 12:40:15.776656 15117 sgd_solver.cpp:294] Iteration 61150, lr = 0.0002
I0526 12:40:22.075546 15117 solver.cpp:233] Iteration 61160, loss = 0.01908
I0526 12:40:22.075592 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0190802 (* 1 = 0.0190802 loss)
I0526 12:40:22.075599 15117 sgd_solver.cpp:294] Iteration 61160, lr = 0.0002
I0526 12:40:28.363898 15117 solver.cpp:233] Iteration 61170, loss = 0.00680487
I0526 12:40:28.363939 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00680503 (* 1 = 0.00680503 loss)
I0526 12:40:28.363945 15117 sgd_solver.cpp:294] Iteration 61170, lr = 0.0002
I0526 12:40:34.653023 15117 solver.cpp:233] Iteration 61180, loss = 0.00670847
I0526 12:40:34.653064 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00670862 (* 1 = 0.00670862 loss)
I0526 12:40:34.653070 15117 sgd_solver.cpp:294] Iteration 61180, lr = 0.0002
I0526 12:40:40.947332 15117 solver.cpp:233] Iteration 61190, loss = 0.0185353
I0526 12:40:40.947378 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0185354 (* 1 = 0.0185354 loss)
I0526 12:40:40.947386 15117 sgd_solver.cpp:294] Iteration 61190, lr = 0.0002
I0526 12:40:46.642401 15117 solver.cpp:342] Iteration 61200, Testing net (#0)
I0526 12:40:59.428102 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9047
I0526 12:40:59.428148 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.44978 (* 1 = 0.44978 loss)
I0526 12:41:00.024044 15117 solver.cpp:233] Iteration 61200, loss = 0.0338247
I0526 12:41:00.024085 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0338249 (* 1 = 0.0338249 loss)
I0526 12:41:00.024092 15117 sgd_solver.cpp:294] Iteration 61200, lr = 0.0002
I0526 12:41:06.310070 15117 solver.cpp:233] Iteration 61210, loss = 0.010984
I0526 12:41:06.310127 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0109841 (* 1 = 0.0109841 loss)
I0526 12:41:06.310134 15117 sgd_solver.cpp:294] Iteration 61210, lr = 0.0002
I0526 12:41:12.599151 15117 solver.cpp:233] Iteration 61220, loss = 0.00711735
I0526 12:41:12.599192 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00711751 (* 1 = 0.00711751 loss)
I0526 12:41:12.599200 15117 sgd_solver.cpp:294] Iteration 61220, lr = 0.0002
I0526 12:41:18.892297 15117 solver.cpp:233] Iteration 61230, loss = 0.00514442
I0526 12:41:18.892489 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00514457 (* 1 = 0.00514457 loss)
I0526 12:41:18.892518 15117 sgd_solver.cpp:294] Iteration 61230, lr = 0.0002
I0526 12:41:25.185989 15117 solver.cpp:233] Iteration 61240, loss = 0.0121129
I0526 12:41:25.186034 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0121131 (* 1 = 0.0121131 loss)
I0526 12:41:25.186043 15117 sgd_solver.cpp:294] Iteration 61240, lr = 0.0002
I0526 12:41:31.475224 15117 solver.cpp:233] Iteration 61250, loss = 0.00563087
I0526 12:41:31.475266 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00563103 (* 1 = 0.00563103 loss)
I0526 12:41:31.475273 15117 sgd_solver.cpp:294] Iteration 61250, lr = 0.0002
I0526 12:41:37.768291 15117 solver.cpp:233] Iteration 61260, loss = 0.00600376
I0526 12:41:37.768337 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00600392 (* 1 = 0.00600392 loss)
I0526 12:41:37.768343 15117 sgd_solver.cpp:294] Iteration 61260, lr = 0.0002
I0526 12:41:44.057335 15117 solver.cpp:233] Iteration 61270, loss = 0.0109324
I0526 12:41:44.057376 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0109325 (* 1 = 0.0109325 loss)
I0526 12:41:44.057384 15117 sgd_solver.cpp:294] Iteration 61270, lr = 0.0002
I0526 12:41:50.347283 15117 solver.cpp:233] Iteration 61280, loss = 0.0204508
I0526 12:41:50.347527 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0204509 (* 1 = 0.0204509 loss)
I0526 12:41:50.347553 15117 sgd_solver.cpp:294] Iteration 61280, lr = 0.0002
I0526 12:41:56.635768 15117 solver.cpp:233] Iteration 61290, loss = 0.0162926
I0526 12:41:56.635812 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0162928 (* 1 = 0.0162928 loss)
I0526 12:41:56.635820 15117 sgd_solver.cpp:294] Iteration 61290, lr = 0.0002
I0526 12:42:02.326066 15117 solver.cpp:342] Iteration 61300, Testing net (#0)
I0526 12:42:15.105706 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9053
I0526 12:42:15.105753 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.452615 (* 1 = 0.452615 loss)
I0526 12:42:15.700892 15117 solver.cpp:233] Iteration 61300, loss = 0.0082764
I0526 12:42:15.700930 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00827656 (* 1 = 0.00827656 loss)
I0526 12:42:15.700937 15117 sgd_solver.cpp:294] Iteration 61300, lr = 0.0002
I0526 12:42:21.994930 15117 solver.cpp:233] Iteration 61310, loss = 0.0155454
I0526 12:42:21.995056 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0155456 (* 1 = 0.0155456 loss)
I0526 12:42:21.995064 15117 sgd_solver.cpp:294] Iteration 61310, lr = 0.0002
I0526 12:42:28.286322 15117 solver.cpp:233] Iteration 61320, loss = 0.00976733
I0526 12:42:28.286370 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00976749 (* 1 = 0.00976749 loss)
I0526 12:42:28.286376 15117 sgd_solver.cpp:294] Iteration 61320, lr = 0.0002
I0526 12:42:34.576758 15117 solver.cpp:233] Iteration 61330, loss = 0.00569691
I0526 12:42:34.576802 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00569707 (* 1 = 0.00569707 loss)
I0526 12:42:34.576808 15117 sgd_solver.cpp:294] Iteration 61330, lr = 0.0002
I0526 12:42:40.867462 15117 solver.cpp:233] Iteration 61340, loss = 0.0135219
I0526 12:42:40.867491 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0135221 (* 1 = 0.0135221 loss)
I0526 12:42:40.867497 15117 sgd_solver.cpp:294] Iteration 61340, lr = 0.0002
I0526 12:42:47.156117 15117 solver.cpp:233] Iteration 61350, loss = 0.00185101
I0526 12:42:47.156158 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00185117 (* 1 = 0.00185117 loss)
I0526 12:42:47.156165 15117 sgd_solver.cpp:294] Iteration 61350, lr = 0.0002
I0526 12:42:53.444741 15117 solver.cpp:233] Iteration 61360, loss = 0.0092804
I0526 12:42:53.444870 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00928057 (* 1 = 0.00928057 loss)
I0526 12:42:53.444877 15117 sgd_solver.cpp:294] Iteration 61360, lr = 0.0002
I0526 12:42:59.730196 15117 solver.cpp:233] Iteration 61370, loss = 0.0143218
I0526 12:42:59.730238 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.014322 (* 1 = 0.014322 loss)
I0526 12:42:59.730245 15117 sgd_solver.cpp:294] Iteration 61370, lr = 0.0002
I0526 12:43:06.016134 15117 solver.cpp:233] Iteration 61380, loss = 0.0111379
I0526 12:43:06.016180 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0111381 (* 1 = 0.0111381 loss)
I0526 12:43:06.016187 15117 sgd_solver.cpp:294] Iteration 61380, lr = 0.0002
I0526 12:43:12.303565 15117 solver.cpp:233] Iteration 61390, loss = 0.0125924
I0526 12:43:12.303608 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0125925 (* 1 = 0.0125925 loss)
I0526 12:43:12.303617 15117 sgd_solver.cpp:294] Iteration 61390, lr = 0.0002
I0526 12:43:17.993487 15117 solver.cpp:342] Iteration 61400, Testing net (#0)
I0526 12:43:30.778383 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9059
I0526 12:43:30.778645 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.452012 (* 1 = 0.452012 loss)
I0526 12:43:31.377876 15117 solver.cpp:233] Iteration 61400, loss = 0.00856855
I0526 12:43:31.377923 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00856871 (* 1 = 0.00856871 loss)
I0526 12:43:31.377933 15117 sgd_solver.cpp:294] Iteration 61400, lr = 0.0002
I0526 12:43:37.663071 15117 solver.cpp:233] Iteration 61410, loss = 0.0118007
I0526 12:43:37.663116 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0118009 (* 1 = 0.0118009 loss)
I0526 12:43:37.663123 15117 sgd_solver.cpp:294] Iteration 61410, lr = 0.0002
I0526 12:43:43.951930 15117 solver.cpp:233] Iteration 61420, loss = 0.00532703
I0526 12:43:43.951973 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00532719 (* 1 = 0.00532719 loss)
I0526 12:43:43.951980 15117 sgd_solver.cpp:294] Iteration 61420, lr = 0.0002
I0526 12:43:50.241269 15117 solver.cpp:233] Iteration 61430, loss = 0.0226444
I0526 12:43:50.241312 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0226446 (* 1 = 0.0226446 loss)
I0526 12:43:50.241317 15117 sgd_solver.cpp:294] Iteration 61430, lr = 0.0002
I0526 12:43:56.527403 15117 solver.cpp:233] Iteration 61440, loss = 0.00567367
I0526 12:43:56.527446 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00567383 (* 1 = 0.00567383 loss)
I0526 12:43:56.527453 15117 sgd_solver.cpp:294] Iteration 61440, lr = 0.0002
I0526 12:44:02.812305 15117 solver.cpp:233] Iteration 61450, loss = 0.0173185
I0526 12:44:02.812526 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0173187 (* 1 = 0.0173187 loss)
I0526 12:44:02.812556 15117 sgd_solver.cpp:294] Iteration 61450, lr = 0.0002
I0526 12:44:09.101723 15117 solver.cpp:233] Iteration 61460, loss = 0.00325558
I0526 12:44:09.101768 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00325574 (* 1 = 0.00325574 loss)
I0526 12:44:09.101774 15117 sgd_solver.cpp:294] Iteration 61460, lr = 0.0002
I0526 12:44:15.390352 15117 solver.cpp:233] Iteration 61470, loss = 0.0104394
I0526 12:44:15.390401 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0104396 (* 1 = 0.0104396 loss)
I0526 12:44:15.390410 15117 sgd_solver.cpp:294] Iteration 61470, lr = 0.0002
I0526 12:44:21.680047 15117 solver.cpp:233] Iteration 61480, loss = 0.00748562
I0526 12:44:21.680091 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00748578 (* 1 = 0.00748578 loss)
I0526 12:44:21.680097 15117 sgd_solver.cpp:294] Iteration 61480, lr = 0.0002
I0526 12:44:27.967032 15117 solver.cpp:233] Iteration 61490, loss = 0.00395675
I0526 12:44:27.967074 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00395691 (* 1 = 0.00395691 loss)
I0526 12:44:27.967082 15117 sgd_solver.cpp:294] Iteration 61490, lr = 0.0002
I0526 12:44:33.658502 15117 solver.cpp:342] Iteration 61500, Testing net (#0)
I0526 12:44:46.442993 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9042
I0526 12:44:46.443040 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.447672 (* 1 = 0.447672 loss)
I0526 12:44:47.040032 15117 solver.cpp:233] Iteration 61500, loss = 0.0165298
I0526 12:44:47.040072 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0165299 (* 1 = 0.0165299 loss)
I0526 12:44:47.040086 15117 sgd_solver.cpp:294] Iteration 61500, lr = 0.0002
I0526 12:44:53.329114 15117 solver.cpp:233] Iteration 61510, loss = 0.016871
I0526 12:44:53.329159 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0168712 (* 1 = 0.0168712 loss)
I0526 12:44:53.329165 15117 sgd_solver.cpp:294] Iteration 61510, lr = 0.0002
I0526 12:44:59.617509 15117 solver.cpp:233] Iteration 61520, loss = 0.0150347
I0526 12:44:59.617552 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0150349 (* 1 = 0.0150349 loss)
I0526 12:44:59.617558 15117 sgd_solver.cpp:294] Iteration 61520, lr = 0.0002
I0526 12:45:05.905606 15117 solver.cpp:233] Iteration 61530, loss = 0.0159887
I0526 12:45:05.905793 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0159889 (* 1 = 0.0159889 loss)
I0526 12:45:05.905802 15117 sgd_solver.cpp:294] Iteration 61530, lr = 0.0002
I0526 12:45:12.194042 15117 solver.cpp:233] Iteration 61540, loss = 0.00576882
I0526 12:45:12.194084 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00576898 (* 1 = 0.00576898 loss)
I0526 12:45:12.194092 15117 sgd_solver.cpp:294] Iteration 61540, lr = 0.0002
I0526 12:45:18.483834 15117 solver.cpp:233] Iteration 61550, loss = 0.00391212
I0526 12:45:18.483877 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00391227 (* 1 = 0.00391227 loss)
I0526 12:45:18.483885 15117 sgd_solver.cpp:294] Iteration 61550, lr = 0.0002
I0526 12:45:24.773767 15117 solver.cpp:233] Iteration 61560, loss = 0.00234693
I0526 12:45:24.773809 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00234709 (* 1 = 0.00234709 loss)
I0526 12:45:24.773816 15117 sgd_solver.cpp:294] Iteration 61560, lr = 0.0002
I0526 12:45:31.063381 15117 solver.cpp:233] Iteration 61570, loss = 0.0017728
I0526 12:45:31.063422 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00177296 (* 1 = 0.00177296 loss)
I0526 12:45:31.063429 15117 sgd_solver.cpp:294] Iteration 61570, lr = 0.0002
I0526 12:45:37.350981 15117 solver.cpp:233] Iteration 61580, loss = 0.0162124
I0526 12:45:37.351229 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0162126 (* 1 = 0.0162126 loss)
I0526 12:45:37.351259 15117 sgd_solver.cpp:294] Iteration 61580, lr = 0.0002
I0526 12:45:43.643715 15117 solver.cpp:233] Iteration 61590, loss = 0.0087632
I0526 12:45:43.643766 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00876336 (* 1 = 0.00876336 loss)
I0526 12:45:43.643774 15117 sgd_solver.cpp:294] Iteration 61590, lr = 0.0002
I0526 12:45:49.333072 15117 solver.cpp:342] Iteration 61600, Testing net (#0)
I0526 12:46:02.112826 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9057
I0526 12:46:02.112856 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.449169 (* 1 = 0.449169 loss)
I0526 12:46:02.710546 15117 solver.cpp:233] Iteration 61600, loss = 0.0181877
I0526 12:46:02.710587 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0181879 (* 1 = 0.0181879 loss)
I0526 12:46:02.710594 15117 sgd_solver.cpp:294] Iteration 61600, lr = 0.0002
I0526 12:46:08.999188 15117 solver.cpp:233] Iteration 61610, loss = 0.0147422
I0526 12:46:08.999300 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0147423 (* 1 = 0.0147423 loss)
I0526 12:46:08.999307 15117 sgd_solver.cpp:294] Iteration 61610, lr = 0.0002
I0526 12:46:15.282070 15117 solver.cpp:233] Iteration 61620, loss = 0.010855
I0526 12:46:15.282115 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0108551 (* 1 = 0.0108551 loss)
I0526 12:46:15.282122 15117 sgd_solver.cpp:294] Iteration 61620, lr = 0.0002
I0526 12:46:21.562723 15117 solver.cpp:233] Iteration 61630, loss = 0.00503933
I0526 12:46:21.562764 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00503949 (* 1 = 0.00503949 loss)
I0526 12:46:21.562770 15117 sgd_solver.cpp:294] Iteration 61630, lr = 0.0002
I0526 12:46:27.850003 15117 solver.cpp:233] Iteration 61640, loss = 0.00462435
I0526 12:46:27.850051 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00462451 (* 1 = 0.00462451 loss)
I0526 12:46:27.850057 15117 sgd_solver.cpp:294] Iteration 61640, lr = 0.0002
I0526 12:46:34.140751 15117 solver.cpp:233] Iteration 61650, loss = 0.0022813
I0526 12:46:34.140794 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00228146 (* 1 = 0.00228146 loss)
I0526 12:46:34.140800 15117 sgd_solver.cpp:294] Iteration 61650, lr = 0.0002
I0526 12:46:40.430338 15117 solver.cpp:233] Iteration 61660, loss = 0.00795748
I0526 12:46:40.430624 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00795764 (* 1 = 0.00795764 loss)
I0526 12:46:40.430652 15117 sgd_solver.cpp:294] Iteration 61660, lr = 0.0002
I0526 12:46:46.722350 15117 solver.cpp:233] Iteration 61670, loss = 0.0111856
I0526 12:46:46.722400 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0111858 (* 1 = 0.0111858 loss)
I0526 12:46:46.722407 15117 sgd_solver.cpp:294] Iteration 61670, lr = 0.0002
I0526 12:46:53.012308 15117 solver.cpp:233] Iteration 61680, loss = 0.00550437
I0526 12:46:53.012349 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00550453 (* 1 = 0.00550453 loss)
I0526 12:46:53.012357 15117 sgd_solver.cpp:294] Iteration 61680, lr = 0.0002
I0526 12:46:59.300882 15117 solver.cpp:233] Iteration 61690, loss = 0.00534512
I0526 12:46:59.300926 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00534528 (* 1 = 0.00534528 loss)
I0526 12:46:59.300935 15117 sgd_solver.cpp:294] Iteration 61690, lr = 0.0002
I0526 12:47:04.992465 15117 solver.cpp:342] Iteration 61700, Testing net (#0)
I0526 12:47:17.775450 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.904
I0526 12:47:17.775684 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.455578 (* 1 = 0.455578 loss)
I0526 12:47:18.373291 15117 solver.cpp:233] Iteration 61700, loss = 0.0118966
I0526 12:47:18.373335 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0118967 (* 1 = 0.0118967 loss)
I0526 12:47:18.373343 15117 sgd_solver.cpp:294] Iteration 61700, lr = 0.0002
I0526 12:47:24.655338 15117 solver.cpp:233] Iteration 61710, loss = 0.00277396
I0526 12:47:24.655378 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00277411 (* 1 = 0.00277411 loss)
I0526 12:47:24.655385 15117 sgd_solver.cpp:294] Iteration 61710, lr = 0.0002
I0526 12:47:30.939983 15117 solver.cpp:233] Iteration 61720, loss = 0.00860869
I0526 12:47:30.940026 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00860884 (* 1 = 0.00860884 loss)
I0526 12:47:30.940033 15117 sgd_solver.cpp:294] Iteration 61720, lr = 0.0002
I0526 12:47:37.225445 15117 solver.cpp:233] Iteration 61730, loss = 0.00746155
I0526 12:47:37.225484 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00746171 (* 1 = 0.00746171 loss)
I0526 12:47:37.225492 15117 sgd_solver.cpp:294] Iteration 61730, lr = 0.0002
I0526 12:47:43.513937 15117 solver.cpp:233] Iteration 61740, loss = 0.0148321
I0526 12:47:43.513969 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0148322 (* 1 = 0.0148322 loss)
I0526 12:47:43.513977 15117 sgd_solver.cpp:294] Iteration 61740, lr = 0.0002
I0526 12:47:49.798632 15117 solver.cpp:233] Iteration 61750, loss = 0.0143046
I0526 12:47:49.798862 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0143048 (* 1 = 0.0143048 loss)
I0526 12:47:49.798893 15117 sgd_solver.cpp:294] Iteration 61750, lr = 0.0002
I0526 12:47:56.091084 15117 solver.cpp:233] Iteration 61760, loss = 0.0100805
I0526 12:47:56.091128 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0100806 (* 1 = 0.0100806 loss)
I0526 12:47:56.091135 15117 sgd_solver.cpp:294] Iteration 61760, lr = 0.0002
I0526 12:48:02.377498 15117 solver.cpp:233] Iteration 61770, loss = 0.0185212
I0526 12:48:02.377540 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0185213 (* 1 = 0.0185213 loss)
I0526 12:48:02.377547 15117 sgd_solver.cpp:294] Iteration 61770, lr = 0.0002
I0526 12:48:08.663467 15117 solver.cpp:233] Iteration 61780, loss = 0.00820342
I0526 12:48:08.663507 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00820358 (* 1 = 0.00820358 loss)
I0526 12:48:08.663513 15117 sgd_solver.cpp:294] Iteration 61780, lr = 0.0002
I0526 12:48:14.953747 15117 solver.cpp:233] Iteration 61790, loss = 0.00525796
I0526 12:48:14.953793 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00525812 (* 1 = 0.00525812 loss)
I0526 12:48:14.953800 15117 sgd_solver.cpp:294] Iteration 61790, lr = 0.0002
I0526 12:48:20.641700 15117 solver.cpp:342] Iteration 61800, Testing net (#0)
I0526 12:48:33.422230 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9047
I0526 12:48:33.422276 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.454841 (* 1 = 0.454841 loss)
I0526 12:48:34.018476 15117 solver.cpp:233] Iteration 61800, loss = 0.027752
I0526 12:48:34.018518 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0277522 (* 1 = 0.0277522 loss)
I0526 12:48:34.018525 15117 sgd_solver.cpp:294] Iteration 61800, lr = 0.0002
I0526 12:48:40.308383 15117 solver.cpp:233] Iteration 61810, loss = 0.00739719
I0526 12:48:40.308424 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00739735 (* 1 = 0.00739735 loss)
I0526 12:48:40.308431 15117 sgd_solver.cpp:294] Iteration 61810, lr = 0.0002
I0526 12:48:46.598745 15117 solver.cpp:233] Iteration 61820, loss = 0.013241
I0526 12:48:46.598788 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0132411 (* 1 = 0.0132411 loss)
I0526 12:48:46.598795 15117 sgd_solver.cpp:294] Iteration 61820, lr = 0.0002
I0526 12:48:52.890694 15117 solver.cpp:233] Iteration 61830, loss = 0.0110403
I0526 12:48:52.890920 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0110405 (* 1 = 0.0110405 loss)
I0526 12:48:52.890949 15117 sgd_solver.cpp:294] Iteration 61830, lr = 0.0002
I0526 12:48:59.181638 15117 solver.cpp:233] Iteration 61840, loss = 0.0357257
I0526 12:48:59.181681 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0357258 (* 1 = 0.0357258 loss)
I0526 12:48:59.181689 15117 sgd_solver.cpp:294] Iteration 61840, lr = 0.0002
I0526 12:49:05.469836 15117 solver.cpp:233] Iteration 61850, loss = 0.0107967
I0526 12:49:05.469877 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0107969 (* 1 = 0.0107969 loss)
I0526 12:49:05.469882 15117 sgd_solver.cpp:294] Iteration 61850, lr = 0.0002
I0526 12:49:11.759994 15117 solver.cpp:233] Iteration 61860, loss = 0.0111345
I0526 12:49:11.760037 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0111347 (* 1 = 0.0111347 loss)
I0526 12:49:11.760045 15117 sgd_solver.cpp:294] Iteration 61860, lr = 0.0002
I0526 12:49:18.050783 15117 solver.cpp:233] Iteration 61870, loss = 0.0315775
I0526 12:49:18.050827 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0315777 (* 1 = 0.0315777 loss)
I0526 12:49:18.050834 15117 sgd_solver.cpp:294] Iteration 61870, lr = 0.0002
I0526 12:49:24.339135 15117 solver.cpp:233] Iteration 61880, loss = 0.00450808
I0526 12:49:24.339344 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00450824 (* 1 = 0.00450824 loss)
I0526 12:49:24.339373 15117 sgd_solver.cpp:294] Iteration 61880, lr = 0.0002
I0526 12:49:30.628487 15117 solver.cpp:233] Iteration 61890, loss = 0.028463
I0526 12:49:30.628525 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0284631 (* 1 = 0.0284631 loss)
I0526 12:49:30.628532 15117 sgd_solver.cpp:294] Iteration 61890, lr = 0.0002
I0526 12:49:36.322216 15117 solver.cpp:342] Iteration 61900, Testing net (#0)
I0526 12:49:49.103701 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9043
I0526 12:49:49.103746 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.452982 (* 1 = 0.452982 loss)
I0526 12:49:49.700815 15117 solver.cpp:233] Iteration 61900, loss = 0.00409678
I0526 12:49:49.700855 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00409694 (* 1 = 0.00409694 loss)
I0526 12:49:49.700861 15117 sgd_solver.cpp:294] Iteration 61900, lr = 0.0002
I0526 12:49:55.992488 15117 solver.cpp:233] Iteration 61910, loss = 0.00611662
I0526 12:49:55.992743 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00611678 (* 1 = 0.00611678 loss)
I0526 12:49:55.992770 15117 sgd_solver.cpp:294] Iteration 61910, lr = 0.0002
I0526 12:50:02.283615 15117 solver.cpp:233] Iteration 61920, loss = 0.00296671
I0526 12:50:02.283658 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00296687 (* 1 = 0.00296687 loss)
I0526 12:50:02.283664 15117 sgd_solver.cpp:294] Iteration 61920, lr = 0.0002
I0526 12:50:08.569733 15117 solver.cpp:233] Iteration 61930, loss = 0.00844556
I0526 12:50:08.569775 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00844572 (* 1 = 0.00844572 loss)
I0526 12:50:08.569782 15117 sgd_solver.cpp:294] Iteration 61930, lr = 0.0002
I0526 12:50:14.860327 15117 solver.cpp:233] Iteration 61940, loss = 0.0174391
I0526 12:50:14.860371 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0174392 (* 1 = 0.0174392 loss)
I0526 12:50:14.860378 15117 sgd_solver.cpp:294] Iteration 61940, lr = 0.0002
I0526 12:50:21.150269 15117 solver.cpp:233] Iteration 61950, loss = 0.00531265
I0526 12:50:21.150311 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00531281 (* 1 = 0.00531281 loss)
I0526 12:50:21.150318 15117 sgd_solver.cpp:294] Iteration 61950, lr = 0.0002
I0526 12:50:27.438161 15117 solver.cpp:233] Iteration 61960, loss = 0.00425252
I0526 12:50:27.438397 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00425268 (* 1 = 0.00425268 loss)
I0526 12:50:27.438423 15117 sgd_solver.cpp:294] Iteration 61960, lr = 0.0002
I0526 12:50:33.726712 15117 solver.cpp:233] Iteration 61970, loss = 0.00912842
I0526 12:50:33.726752 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00912858 (* 1 = 0.00912858 loss)
I0526 12:50:33.726759 15117 sgd_solver.cpp:294] Iteration 61970, lr = 0.0002
I0526 12:50:40.015435 15117 solver.cpp:233] Iteration 61980, loss = 0.0165595
I0526 12:50:40.015476 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0165597 (* 1 = 0.0165597 loss)
I0526 12:50:40.015483 15117 sgd_solver.cpp:294] Iteration 61980, lr = 0.0002
I0526 12:50:46.304333 15117 solver.cpp:233] Iteration 61990, loss = 0.00718382
I0526 12:50:46.304378 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00718398 (* 1 = 0.00718398 loss)
I0526 12:50:46.304385 15117 sgd_solver.cpp:294] Iteration 61990, lr = 0.0002
I0526 12:50:51.996332 15117 solver.cpp:342] Iteration 62000, Testing net (#0)
I0526 12:51:04.790580 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9059
I0526 12:51:04.790812 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.440424 (* 1 = 0.440424 loss)
I0526 12:51:05.391926 15117 solver.cpp:233] Iteration 62000, loss = 0.0214157
I0526 12:51:05.391988 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0214158 (* 1 = 0.0214158 loss)
I0526 12:51:05.391999 15117 sgd_solver.cpp:294] Iteration 62000, lr = 0.0002
I0526 12:51:11.682888 15117 solver.cpp:233] Iteration 62010, loss = 0.00606927
I0526 12:51:11.682929 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00606943 (* 1 = 0.00606943 loss)
I0526 12:51:11.682936 15117 sgd_solver.cpp:294] Iteration 62010, lr = 0.0002
I0526 12:51:17.974357 15117 solver.cpp:233] Iteration 62020, loss = 0.0210496
I0526 12:51:17.974402 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0210497 (* 1 = 0.0210497 loss)
I0526 12:51:17.974409 15117 sgd_solver.cpp:294] Iteration 62020, lr = 0.0002
I0526 12:51:24.262434 15117 solver.cpp:233] Iteration 62030, loss = 0.0173084
I0526 12:51:24.262480 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0173085 (* 1 = 0.0173085 loss)
I0526 12:51:24.262486 15117 sgd_solver.cpp:294] Iteration 62030, lr = 0.0002
I0526 12:51:30.548583 15117 solver.cpp:233] Iteration 62040, loss = 0.00716232
I0526 12:51:30.548626 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00716248 (* 1 = 0.00716248 loss)
I0526 12:51:30.548640 15117 sgd_solver.cpp:294] Iteration 62040, lr = 0.0002
I0526 12:51:36.833679 15117 solver.cpp:233] Iteration 62050, loss = 0.00394257
I0526 12:51:36.833950 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00394273 (* 1 = 0.00394273 loss)
I0526 12:51:36.833978 15117 sgd_solver.cpp:294] Iteration 62050, lr = 0.0002
I0526 12:51:43.122517 15117 solver.cpp:233] Iteration 62060, loss = 0.0272047
I0526 12:51:43.122562 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0272049 (* 1 = 0.0272049 loss)
I0526 12:51:43.122570 15117 sgd_solver.cpp:294] Iteration 62060, lr = 0.0002
I0526 12:51:49.415958 15117 solver.cpp:233] Iteration 62070, loss = 0.0157973
I0526 12:51:49.415999 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0157975 (* 1 = 0.0157975 loss)
I0526 12:51:49.416005 15117 sgd_solver.cpp:294] Iteration 62070, lr = 0.0002
I0526 12:51:55.707135 15117 solver.cpp:233] Iteration 62080, loss = 0.00839831
I0526 12:51:55.707180 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00839847 (* 1 = 0.00839847 loss)
I0526 12:51:55.707186 15117 sgd_solver.cpp:294] Iteration 62080, lr = 0.0002
I0526 12:52:01.994580 15117 solver.cpp:233] Iteration 62090, loss = 0.00298529
I0526 12:52:01.994622 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00298545 (* 1 = 0.00298545 loss)
I0526 12:52:01.994629 15117 sgd_solver.cpp:294] Iteration 62090, lr = 0.0002
I0526 12:52:07.688823 15117 solver.cpp:342] Iteration 62100, Testing net (#0)
I0526 12:52:20.483752 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9039
I0526 12:52:20.483796 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.455598 (* 1 = 0.455598 loss)
I0526 12:52:21.081394 15117 solver.cpp:233] Iteration 62100, loss = 0.00163047
I0526 12:52:21.081435 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00163063 (* 1 = 0.00163063 loss)
I0526 12:52:21.081442 15117 sgd_solver.cpp:294] Iteration 62100, lr = 0.0002
I0526 12:52:27.370687 15117 solver.cpp:233] Iteration 62110, loss = 0.00638926
I0526 12:52:27.370743 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00638942 (* 1 = 0.00638942 loss)
I0526 12:52:27.370750 15117 sgd_solver.cpp:294] Iteration 62110, lr = 0.0002
I0526 12:52:33.659216 15117 solver.cpp:233] Iteration 62120, loss = 0.0238042
I0526 12:52:33.659260 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0238043 (* 1 = 0.0238043 loss)
I0526 12:52:33.659268 15117 sgd_solver.cpp:294] Iteration 62120, lr = 0.0002
I0526 12:52:39.946336 15117 solver.cpp:233] Iteration 62130, loss = 0.00701777
I0526 12:52:39.946491 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00701793 (* 1 = 0.00701793 loss)
I0526 12:52:39.946499 15117 sgd_solver.cpp:294] Iteration 62130, lr = 0.0002
I0526 12:52:46.230725 15117 solver.cpp:233] Iteration 62140, loss = 0.00921883
I0526 12:52:46.230763 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00921899 (* 1 = 0.00921899 loss)
I0526 12:52:46.230770 15117 sgd_solver.cpp:294] Iteration 62140, lr = 0.0002
I0526 12:52:52.518030 15117 solver.cpp:233] Iteration 62150, loss = 0.00257947
I0526 12:52:52.518076 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00257963 (* 1 = 0.00257963 loss)
I0526 12:52:52.518084 15117 sgd_solver.cpp:294] Iteration 62150, lr = 0.0002
I0526 12:52:58.805356 15117 solver.cpp:233] Iteration 62160, loss = 0.0159684
I0526 12:52:58.805397 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0159685 (* 1 = 0.0159685 loss)
I0526 12:52:58.805402 15117 sgd_solver.cpp:294] Iteration 62160, lr = 0.0002
I0526 12:53:05.093916 15117 solver.cpp:233] Iteration 62170, loss = 0.0204231
I0526 12:53:05.093956 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0204233 (* 1 = 0.0204233 loss)
I0526 12:53:05.093963 15117 sgd_solver.cpp:294] Iteration 62170, lr = 0.0002
I0526 12:53:11.386389 15117 solver.cpp:233] Iteration 62180, loss = 0.0118362
I0526 12:53:11.386667 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0118363 (* 1 = 0.0118363 loss)
I0526 12:53:11.386696 15117 sgd_solver.cpp:294] Iteration 62180, lr = 0.0002
I0526 12:53:17.677719 15117 solver.cpp:233] Iteration 62190, loss = 0.00813592
I0526 12:53:17.677762 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00813609 (* 1 = 0.00813609 loss)
I0526 12:53:17.677769 15117 sgd_solver.cpp:294] Iteration 62190, lr = 0.0002
I0526 12:53:23.368638 15117 solver.cpp:342] Iteration 62200, Testing net (#0)
I0526 12:53:36.152758 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9034
I0526 12:53:36.152801 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.455028 (* 1 = 0.455028 loss)
I0526 12:53:36.749975 15117 solver.cpp:233] Iteration 62200, loss = 0.0262371
I0526 12:53:36.750025 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0262373 (* 1 = 0.0262373 loss)
I0526 12:53:36.750031 15117 sgd_solver.cpp:294] Iteration 62200, lr = 0.0002
I0526 12:53:43.036381 15117 solver.cpp:233] Iteration 62210, loss = 0.00946494
I0526 12:53:43.036576 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0094651 (* 1 = 0.0094651 loss)
I0526 12:53:43.036605 15117 sgd_solver.cpp:294] Iteration 62210, lr = 0.0002
I0526 12:53:49.328635 15117 solver.cpp:233] Iteration 62220, loss = 0.0180405
I0526 12:53:49.328663 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0180407 (* 1 = 0.0180407 loss)
I0526 12:53:49.328670 15117 sgd_solver.cpp:294] Iteration 62220, lr = 0.0002
I0526 12:53:55.618878 15117 solver.cpp:233] Iteration 62230, loss = 0.00491735
I0526 12:53:55.618921 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00491751 (* 1 = 0.00491751 loss)
I0526 12:53:55.618928 15117 sgd_solver.cpp:294] Iteration 62230, lr = 0.0002
I0526 12:54:01.908855 15117 solver.cpp:233] Iteration 62240, loss = 0.00291513
I0526 12:54:01.908897 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00291529 (* 1 = 0.00291529 loss)
I0526 12:54:01.908903 15117 sgd_solver.cpp:294] Iteration 62240, lr = 0.0002
I0526 12:54:08.195718 15117 solver.cpp:233] Iteration 62250, loss = 0.013253
I0526 12:54:08.195763 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0132531 (* 1 = 0.0132531 loss)
I0526 12:54:08.195771 15117 sgd_solver.cpp:294] Iteration 62250, lr = 0.0002
I0526 12:54:14.484956 15117 solver.cpp:233] Iteration 62260, loss = 0.00540607
I0526 12:54:14.485133 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00540623 (* 1 = 0.00540623 loss)
I0526 12:54:14.485162 15117 sgd_solver.cpp:294] Iteration 62260, lr = 0.0002
I0526 12:54:20.779824 15117 solver.cpp:233] Iteration 62270, loss = 0.00460665
I0526 12:54:20.779863 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00460681 (* 1 = 0.00460681 loss)
I0526 12:54:20.779870 15117 sgd_solver.cpp:294] Iteration 62270, lr = 0.0002
I0526 12:54:27.068076 15117 solver.cpp:233] Iteration 62280, loss = 0.0127829
I0526 12:54:27.068120 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0127831 (* 1 = 0.0127831 loss)
I0526 12:54:27.068127 15117 sgd_solver.cpp:294] Iteration 62280, lr = 0.0002
I0526 12:54:33.359412 15117 solver.cpp:233] Iteration 62290, loss = 0.00403344
I0526 12:54:33.359458 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0040336 (* 1 = 0.0040336 loss)
I0526 12:54:33.359465 15117 sgd_solver.cpp:294] Iteration 62290, lr = 0.0002
I0526 12:54:39.052209 15117 solver.cpp:342] Iteration 62300, Testing net (#0)
I0526 12:54:51.837431 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.905
I0526 12:54:51.837671 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.448269 (* 1 = 0.448269 loss)
I0526 12:54:52.435503 15117 solver.cpp:233] Iteration 62300, loss = 0.00727832
I0526 12:54:52.435551 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00727848 (* 1 = 0.00727848 loss)
I0526 12:54:52.435559 15117 sgd_solver.cpp:294] Iteration 62300, lr = 0.0002
I0526 12:54:58.724182 15117 solver.cpp:233] Iteration 62310, loss = 0.00992894
I0526 12:54:58.724220 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0099291 (* 1 = 0.0099291 loss)
I0526 12:54:58.724227 15117 sgd_solver.cpp:294] Iteration 62310, lr = 0.0002
I0526 12:55:05.012135 15117 solver.cpp:233] Iteration 62320, loss = 0.0109022
I0526 12:55:05.012177 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0109024 (* 1 = 0.0109024 loss)
I0526 12:55:05.012184 15117 sgd_solver.cpp:294] Iteration 62320, lr = 0.0002
I0526 12:55:11.299588 15117 solver.cpp:233] Iteration 62330, loss = 0.0075045
I0526 12:55:11.299633 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00750466 (* 1 = 0.00750466 loss)
I0526 12:55:11.299639 15117 sgd_solver.cpp:294] Iteration 62330, lr = 0.0002
I0526 12:55:17.588929 15117 solver.cpp:233] Iteration 62340, loss = 0.0173863
I0526 12:55:17.588971 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0173864 (* 1 = 0.0173864 loss)
I0526 12:55:17.588979 15117 sgd_solver.cpp:294] Iteration 62340, lr = 0.0002
I0526 12:55:23.875735 15117 solver.cpp:233] Iteration 62350, loss = 0.0112645
I0526 12:55:23.875979 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0112647 (* 1 = 0.0112647 loss)
I0526 12:55:23.876004 15117 sgd_solver.cpp:294] Iteration 62350, lr = 0.0002
I0526 12:55:30.166008 15117 solver.cpp:233] Iteration 62360, loss = 0.0141604
I0526 12:55:30.166074 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0141606 (* 1 = 0.0141606 loss)
I0526 12:55:30.166080 15117 sgd_solver.cpp:294] Iteration 62360, lr = 0.0002
I0526 12:55:36.453428 15117 solver.cpp:233] Iteration 62370, loss = 0.00356512
I0526 12:55:36.453475 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00356529 (* 1 = 0.00356529 loss)
I0526 12:55:36.453482 15117 sgd_solver.cpp:294] Iteration 62370, lr = 0.0002
I0526 12:55:42.740182 15117 solver.cpp:233] Iteration 62380, loss = 0.00534694
I0526 12:55:42.740226 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0053471 (* 1 = 0.0053471 loss)
I0526 12:55:42.740232 15117 sgd_solver.cpp:294] Iteration 62380, lr = 0.0002
I0526 12:55:49.026089 15117 solver.cpp:233] Iteration 62390, loss = 0.0186031
I0526 12:55:49.026131 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0186032 (* 1 = 0.0186032 loss)
I0526 12:55:49.026139 15117 sgd_solver.cpp:294] Iteration 62390, lr = 0.0002
I0526 12:55:54.718227 15117 solver.cpp:342] Iteration 62400, Testing net (#0)
I0526 12:56:07.500110 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9058
I0526 12:56:07.500156 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.446159 (* 1 = 0.446159 loss)
I0526 12:56:08.096300 15117 solver.cpp:233] Iteration 62400, loss = 0.00883572
I0526 12:56:08.096341 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00883589 (* 1 = 0.00883589 loss)
I0526 12:56:08.096349 15117 sgd_solver.cpp:294] Iteration 62400, lr = 0.0002
I0526 12:56:14.381417 15117 solver.cpp:233] Iteration 62410, loss = 0.0123652
I0526 12:56:14.381458 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0123654 (* 1 = 0.0123654 loss)
I0526 12:56:14.381466 15117 sgd_solver.cpp:294] Iteration 62410, lr = 0.0002
I0526 12:56:20.669482 15117 solver.cpp:233] Iteration 62420, loss = 0.0085519
I0526 12:56:20.669523 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00855207 (* 1 = 0.00855207 loss)
I0526 12:56:20.669529 15117 sgd_solver.cpp:294] Iteration 62420, lr = 0.0002
I0526 12:56:26.957751 15117 solver.cpp:233] Iteration 62430, loss = 0.00250394
I0526 12:56:26.957880 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00250411 (* 1 = 0.00250411 loss)
I0526 12:56:26.957887 15117 sgd_solver.cpp:294] Iteration 62430, lr = 0.0002
I0526 12:56:33.248416 15117 solver.cpp:233] Iteration 62440, loss = 0.00357747
I0526 12:56:33.248447 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00357764 (* 1 = 0.00357764 loss)
I0526 12:56:33.248459 15117 sgd_solver.cpp:294] Iteration 62440, lr = 0.0002
I0526 12:56:39.537683 15117 solver.cpp:233] Iteration 62450, loss = 0.0146216
I0526 12:56:39.537729 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0146218 (* 1 = 0.0146218 loss)
I0526 12:56:39.537734 15117 sgd_solver.cpp:294] Iteration 62450, lr = 0.0002
I0526 12:56:45.824949 15117 solver.cpp:233] Iteration 62460, loss = 0.00491167
I0526 12:56:45.824990 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00491184 (* 1 = 0.00491184 loss)
I0526 12:56:45.824997 15117 sgd_solver.cpp:294] Iteration 62460, lr = 0.0002
I0526 12:56:52.110297 15117 solver.cpp:233] Iteration 62470, loss = 0.0277294
I0526 12:56:52.110342 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0277296 (* 1 = 0.0277296 loss)
I0526 12:56:52.110348 15117 sgd_solver.cpp:294] Iteration 62470, lr = 0.0002
I0526 12:56:58.397863 15117 solver.cpp:233] Iteration 62480, loss = 0.0310789
I0526 12:56:58.398113 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0310791 (* 1 = 0.0310791 loss)
I0526 12:56:58.398139 15117 sgd_solver.cpp:294] Iteration 62480, lr = 0.0002
I0526 12:57:04.689429 15117 solver.cpp:233] Iteration 62490, loss = 0.00922097
I0526 12:57:04.689472 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00922113 (* 1 = 0.00922113 loss)
I0526 12:57:04.689479 15117 sgd_solver.cpp:294] Iteration 62490, lr = 0.0002
I0526 12:57:10.381733 15117 solver.cpp:342] Iteration 62500, Testing net (#0)
I0526 12:57:23.169888 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9053
I0526 12:57:23.169934 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.451206 (* 1 = 0.451206 loss)
I0526 12:57:23.767110 15117 solver.cpp:233] Iteration 62500, loss = 0.0064585
I0526 12:57:23.767150 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00645866 (* 1 = 0.00645866 loss)
I0526 12:57:23.767158 15117 sgd_solver.cpp:294] Iteration 62500, lr = 0.0002
I0526 12:57:30.055255 15117 solver.cpp:233] Iteration 62510, loss = 0.0132317
I0526 12:57:30.055371 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0132319 (* 1 = 0.0132319 loss)
I0526 12:57:30.055378 15117 sgd_solver.cpp:294] Iteration 62510, lr = 0.0002
I0526 12:57:36.346174 15117 solver.cpp:233] Iteration 62520, loss = 0.00304181
I0526 12:57:36.346223 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00304198 (* 1 = 0.00304198 loss)
I0526 12:57:36.346230 15117 sgd_solver.cpp:294] Iteration 62520, lr = 0.0002
I0526 12:57:42.632982 15117 solver.cpp:233] Iteration 62530, loss = 0.0123271
I0526 12:57:42.633008 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0123273 (* 1 = 0.0123273 loss)
I0526 12:57:42.633013 15117 sgd_solver.cpp:294] Iteration 62530, lr = 0.0002
I0526 12:57:48.921149 15117 solver.cpp:233] Iteration 62540, loss = 0.0151921
I0526 12:57:48.921190 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0151922 (* 1 = 0.0151922 loss)
I0526 12:57:48.921196 15117 sgd_solver.cpp:294] Iteration 62540, lr = 0.0002
I0526 12:57:55.206722 15117 solver.cpp:233] Iteration 62550, loss = 0.0112597
I0526 12:57:55.206766 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0112599 (* 1 = 0.0112599 loss)
I0526 12:57:55.206773 15117 sgd_solver.cpp:294] Iteration 62550, lr = 0.0002
I0526 12:58:01.489600 15117 solver.cpp:233] Iteration 62560, loss = 0.00442876
I0526 12:58:01.489706 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00442892 (* 1 = 0.00442892 loss)
I0526 12:58:01.489714 15117 sgd_solver.cpp:294] Iteration 62560, lr = 0.0002
I0526 12:58:07.781455 15117 solver.cpp:233] Iteration 62570, loss = 0.0193979
I0526 12:58:07.781498 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0193981 (* 1 = 0.0193981 loss)
I0526 12:58:07.781505 15117 sgd_solver.cpp:294] Iteration 62570, lr = 0.0002
I0526 12:58:14.070022 15117 solver.cpp:233] Iteration 62580, loss = 0.00528643
I0526 12:58:14.070065 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0052866 (* 1 = 0.0052866 loss)
I0526 12:58:14.070077 15117 sgd_solver.cpp:294] Iteration 62580, lr = 0.0002
I0526 12:58:20.357833 15117 solver.cpp:233] Iteration 62590, loss = 0.00198124
I0526 12:58:20.357874 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0019814 (* 1 = 0.0019814 loss)
I0526 12:58:20.357880 15117 sgd_solver.cpp:294] Iteration 62590, lr = 0.0002
I0526 12:58:26.046870 15117 solver.cpp:342] Iteration 62600, Testing net (#0)
I0526 12:58:38.837280 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9067
I0526 12:58:38.837440 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.443589 (* 1 = 0.443589 loss)
I0526 12:58:39.435055 15117 solver.cpp:233] Iteration 62600, loss = 0.00422098
I0526 12:58:39.435096 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00422114 (* 1 = 0.00422114 loss)
I0526 12:58:39.435103 15117 sgd_solver.cpp:294] Iteration 62600, lr = 0.0002
I0526 12:58:45.721813 15117 solver.cpp:233] Iteration 62610, loss = 0.00223432
I0526 12:58:45.721853 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00223448 (* 1 = 0.00223448 loss)
I0526 12:58:45.721860 15117 sgd_solver.cpp:294] Iteration 62610, lr = 0.0002
I0526 12:58:52.009757 15117 solver.cpp:233] Iteration 62620, loss = 0.0159733
I0526 12:58:52.009801 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0159735 (* 1 = 0.0159735 loss)
I0526 12:58:52.009820 15117 sgd_solver.cpp:294] Iteration 62620, lr = 0.0002
I0526 12:58:58.295145 15117 solver.cpp:233] Iteration 62630, loss = 0.00907402
I0526 12:58:58.295187 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00907419 (* 1 = 0.00907419 loss)
I0526 12:58:58.295194 15117 sgd_solver.cpp:294] Iteration 62630, lr = 0.0002
I0526 12:59:04.580150 15117 solver.cpp:233] Iteration 62640, loss = 0.00864948
I0526 12:59:04.580193 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00864964 (* 1 = 0.00864964 loss)
I0526 12:59:04.580199 15117 sgd_solver.cpp:294] Iteration 62640, lr = 0.0002
I0526 12:59:10.867996 15117 solver.cpp:233] Iteration 62650, loss = 0.0138003
I0526 12:59:10.868217 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0138004 (* 1 = 0.0138004 loss)
I0526 12:59:10.868243 15117 sgd_solver.cpp:294] Iteration 62650, lr = 0.0002
I0526 12:59:17.163674 15117 solver.cpp:233] Iteration 62660, loss = 0.0111489
I0526 12:59:17.163719 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0111491 (* 1 = 0.0111491 loss)
I0526 12:59:17.163727 15117 sgd_solver.cpp:294] Iteration 62660, lr = 0.0002
I0526 12:59:23.452873 15117 solver.cpp:233] Iteration 62670, loss = 0.0140205
I0526 12:59:23.452918 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0140206 (* 1 = 0.0140206 loss)
I0526 12:59:23.452924 15117 sgd_solver.cpp:294] Iteration 62670, lr = 0.0002
I0526 12:59:29.742153 15117 solver.cpp:233] Iteration 62680, loss = 0.00495383
I0526 12:59:29.742194 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00495399 (* 1 = 0.00495399 loss)
I0526 12:59:29.742202 15117 sgd_solver.cpp:294] Iteration 62680, lr = 0.0002
I0526 12:59:36.032682 15117 solver.cpp:233] Iteration 62690, loss = 0.00663603
I0526 12:59:36.032722 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0066362 (* 1 = 0.0066362 loss)
I0526 12:59:36.032729 15117 sgd_solver.cpp:294] Iteration 62690, lr = 0.0002
I0526 12:59:41.723671 15117 solver.cpp:342] Iteration 62700, Testing net (#0)
I0526 12:59:54.504258 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9035
I0526 12:59:54.504305 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.454884 (* 1 = 0.454884 loss)
I0526 12:59:55.100924 15117 solver.cpp:233] Iteration 62700, loss = 0.00695543
I0526 12:59:55.100957 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0069556 (* 1 = 0.0069556 loss)
I0526 12:59:55.100965 15117 sgd_solver.cpp:294] Iteration 62700, lr = 0.0002
I0526 13:00:01.384204 15117 solver.cpp:233] Iteration 62710, loss = 0.00339263
I0526 13:00:01.384253 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0033928 (* 1 = 0.0033928 loss)
I0526 13:00:01.384263 15117 sgd_solver.cpp:294] Iteration 62710, lr = 0.0002
I0526 13:00:07.669988 15117 solver.cpp:233] Iteration 62720, loss = 0.00477729
I0526 13:00:07.670032 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00477746 (* 1 = 0.00477746 loss)
I0526 13:00:07.670039 15117 sgd_solver.cpp:294] Iteration 62720, lr = 0.0002
I0526 13:00:13.963688 15117 solver.cpp:233] Iteration 62730, loss = 0.00380177
I0526 13:00:13.963942 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00380193 (* 1 = 0.00380193 loss)
I0526 13:00:13.963968 15117 sgd_solver.cpp:294] Iteration 62730, lr = 0.0002
I0526 13:00:20.258316 15117 solver.cpp:233] Iteration 62740, loss = 0.0151367
I0526 13:00:20.258374 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0151368 (* 1 = 0.0151368 loss)
I0526 13:00:20.258383 15117 sgd_solver.cpp:294] Iteration 62740, lr = 0.0002
I0526 13:00:26.546744 15117 solver.cpp:233] Iteration 62750, loss = 0.00463332
I0526 13:00:26.546787 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00463348 (* 1 = 0.00463348 loss)
I0526 13:00:26.546793 15117 sgd_solver.cpp:294] Iteration 62750, lr = 0.0002
I0526 13:00:32.837105 15117 solver.cpp:233] Iteration 62760, loss = 0.00234564
I0526 13:00:32.837148 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0023458 (* 1 = 0.0023458 loss)
I0526 13:00:32.837155 15117 sgd_solver.cpp:294] Iteration 62760, lr = 0.0002
I0526 13:00:39.125027 15117 solver.cpp:233] Iteration 62770, loss = 0.018392
I0526 13:00:39.125063 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0183922 (* 1 = 0.0183922 loss)
I0526 13:00:39.125071 15117 sgd_solver.cpp:294] Iteration 62770, lr = 0.0002
I0526 13:00:45.417805 15117 solver.cpp:233] Iteration 62780, loss = 0.025633
I0526 13:00:45.417935 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0256332 (* 1 = 0.0256332 loss)
I0526 13:00:45.417943 15117 sgd_solver.cpp:294] Iteration 62780, lr = 0.0002
I0526 13:00:51.707810 15117 solver.cpp:233] Iteration 62790, loss = 0.00722613
I0526 13:00:51.707855 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00722629 (* 1 = 0.00722629 loss)
I0526 13:00:51.707862 15117 sgd_solver.cpp:294] Iteration 62790, lr = 0.0002
I0526 13:00:57.404605 15117 solver.cpp:342] Iteration 62800, Testing net (#0)
I0526 13:01:10.190053 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9041
I0526 13:01:10.190100 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.464293 (* 1 = 0.464293 loss)
I0526 13:01:10.785328 15117 solver.cpp:233] Iteration 62800, loss = 0.00422418
I0526 13:01:10.785372 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00422433 (* 1 = 0.00422433 loss)
I0526 13:01:10.785378 15117 sgd_solver.cpp:294] Iteration 62800, lr = 0.0002
I0526 13:01:17.073408 15117 solver.cpp:233] Iteration 62810, loss = 0.0204376
I0526 13:01:17.073621 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0204378 (* 1 = 0.0204378 loss)
I0526 13:01:17.073647 15117 sgd_solver.cpp:294] Iteration 62810, lr = 0.0002
I0526 13:01:23.365528 15117 solver.cpp:233] Iteration 62820, loss = 0.00592796
I0526 13:01:23.365572 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00592811 (* 1 = 0.00592811 loss)
I0526 13:01:23.365579 15117 sgd_solver.cpp:294] Iteration 62820, lr = 0.0002
I0526 13:01:29.655248 15117 solver.cpp:233] Iteration 62830, loss = 0.0133381
I0526 13:01:29.655289 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0133382 (* 1 = 0.0133382 loss)
I0526 13:01:29.655297 15117 sgd_solver.cpp:294] Iteration 62830, lr = 0.0002
I0526 13:01:35.947278 15117 solver.cpp:233] Iteration 62840, loss = 0.00693191
I0526 13:01:35.947320 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00693207 (* 1 = 0.00693207 loss)
I0526 13:01:35.947326 15117 sgd_solver.cpp:294] Iteration 62840, lr = 0.0002
I0526 13:01:42.239182 15117 solver.cpp:233] Iteration 62850, loss = 0.017995
I0526 13:01:42.239226 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0179951 (* 1 = 0.0179951 loss)
I0526 13:01:42.239233 15117 sgd_solver.cpp:294] Iteration 62850, lr = 0.0002
I0526 13:01:48.528481 15117 solver.cpp:233] Iteration 62860, loss = 0.00776342
I0526 13:01:48.528729 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00776358 (* 1 = 0.00776358 loss)
I0526 13:01:48.528756 15117 sgd_solver.cpp:294] Iteration 62860, lr = 0.0002
I0526 13:01:54.819950 15117 solver.cpp:233] Iteration 62870, loss = 0.00798448
I0526 13:01:54.819994 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00798463 (* 1 = 0.00798463 loss)
I0526 13:01:54.820001 15117 sgd_solver.cpp:294] Iteration 62870, lr = 0.0002
I0526 13:02:01.113003 15117 solver.cpp:233] Iteration 62880, loss = 0.00378248
I0526 13:02:01.113046 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00378264 (* 1 = 0.00378264 loss)
I0526 13:02:01.113054 15117 sgd_solver.cpp:294] Iteration 62880, lr = 0.0002
I0526 13:02:07.404950 15117 solver.cpp:233] Iteration 62890, loss = 0.00995607
I0526 13:02:07.404999 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00995623 (* 1 = 0.00995623 loss)
I0526 13:02:07.405005 15117 sgd_solver.cpp:294] Iteration 62890, lr = 0.0002
I0526 13:02:13.093847 15117 solver.cpp:342] Iteration 62900, Testing net (#0)
I0526 13:02:25.882586 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9036
I0526 13:02:25.882823 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.461025 (* 1 = 0.461025 loss)
I0526 13:02:26.480298 15117 solver.cpp:233] Iteration 62900, loss = 0.00568683
I0526 13:02:26.480337 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00568699 (* 1 = 0.00568699 loss)
I0526 13:02:26.480345 15117 sgd_solver.cpp:294] Iteration 62900, lr = 0.0002
I0526 13:02:32.770439 15117 solver.cpp:233] Iteration 62910, loss = 0.0064918
I0526 13:02:32.770481 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00649196 (* 1 = 0.00649196 loss)
I0526 13:02:32.770488 15117 sgd_solver.cpp:294] Iteration 62910, lr = 0.0002
I0526 13:02:39.060642 15117 solver.cpp:233] Iteration 62920, loss = 0.0353172
I0526 13:02:39.060679 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0353173 (* 1 = 0.0353173 loss)
I0526 13:02:39.060685 15117 sgd_solver.cpp:294] Iteration 62920, lr = 0.0002
I0526 13:02:45.351980 15117 solver.cpp:233] Iteration 62930, loss = 0.0202044
I0526 13:02:45.352021 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0202046 (* 1 = 0.0202046 loss)
I0526 13:02:45.352027 15117 sgd_solver.cpp:294] Iteration 62930, lr = 0.0002
I0526 13:02:51.643527 15117 solver.cpp:233] Iteration 62940, loss = 0.00881045
I0526 13:02:51.643574 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00881061 (* 1 = 0.00881061 loss)
I0526 13:02:51.643581 15117 sgd_solver.cpp:294] Iteration 62940, lr = 0.0002
I0526 13:02:57.932690 15117 solver.cpp:233] Iteration 62950, loss = 0.0060092
I0526 13:02:57.932911 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00600936 (* 1 = 0.00600936 loss)
I0526 13:02:57.932940 15117 sgd_solver.cpp:294] Iteration 62950, lr = 0.0002
I0526 13:03:04.226963 15117 solver.cpp:233] Iteration 62960, loss = 0.00276151
I0526 13:03:04.227005 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00276167 (* 1 = 0.00276167 loss)
I0526 13:03:04.227012 15117 sgd_solver.cpp:294] Iteration 62960, lr = 0.0002
I0526 13:03:10.518779 15117 solver.cpp:233] Iteration 62970, loss = 0.0161351
I0526 13:03:10.518822 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0161352 (* 1 = 0.0161352 loss)
I0526 13:03:10.518829 15117 sgd_solver.cpp:294] Iteration 62970, lr = 0.0002
I0526 13:03:16.805682 15117 solver.cpp:233] Iteration 62980, loss = 0.00478577
I0526 13:03:16.805723 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00478593 (* 1 = 0.00478593 loss)
I0526 13:03:16.805737 15117 sgd_solver.cpp:294] Iteration 62980, lr = 0.0002
I0526 13:03:23.092422 15117 solver.cpp:233] Iteration 62990, loss = 0.00427847
I0526 13:03:23.092463 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00427863 (* 1 = 0.00427863 loss)
I0526 13:03:23.092470 15117 sgd_solver.cpp:294] Iteration 62990, lr = 0.0002
I0526 13:03:28.785099 15117 solver.cpp:342] Iteration 63000, Testing net (#0)
I0526 13:03:41.578697 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9055
I0526 13:03:41.578744 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.439411 (* 1 = 0.439411 loss)
I0526 13:03:42.175057 15117 solver.cpp:233] Iteration 63000, loss = 0.00378621
I0526 13:03:42.175094 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00378637 (* 1 = 0.00378637 loss)
I0526 13:03:42.175102 15117 sgd_solver.cpp:294] Iteration 63000, lr = 0.0002
I0526 13:03:48.464639 15117 solver.cpp:233] Iteration 63010, loss = 0.00572493
I0526 13:03:48.464682 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00572509 (* 1 = 0.00572509 loss)
I0526 13:03:48.464689 15117 sgd_solver.cpp:294] Iteration 63010, lr = 0.0002
I0526 13:03:54.754757 15117 solver.cpp:233] Iteration 63020, loss = 0.00650385
I0526 13:03:54.754801 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.006504 (* 1 = 0.006504 loss)
I0526 13:03:54.754807 15117 sgd_solver.cpp:294] Iteration 63020, lr = 0.0002
I0526 13:04:01.043727 15117 solver.cpp:233] Iteration 63030, loss = 0.00985664
I0526 13:04:01.043849 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00985679 (* 1 = 0.00985679 loss)
I0526 13:04:01.043858 15117 sgd_solver.cpp:294] Iteration 63030, lr = 0.0002
I0526 13:04:07.330503 15117 solver.cpp:233] Iteration 63040, loss = 0.0152432
I0526 13:04:07.330540 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0152433 (* 1 = 0.0152433 loss)
I0526 13:04:07.330549 15117 sgd_solver.cpp:294] Iteration 63040, lr = 0.0002
I0526 13:04:13.619540 15117 solver.cpp:233] Iteration 63050, loss = 0.00528094
I0526 13:04:13.619582 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0052811 (* 1 = 0.0052811 loss)
I0526 13:04:13.619590 15117 sgd_solver.cpp:294] Iteration 63050, lr = 0.0002
I0526 13:04:19.907248 15117 solver.cpp:233] Iteration 63060, loss = 0.015958
I0526 13:04:19.907289 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0159582 (* 1 = 0.0159582 loss)
I0526 13:04:19.907296 15117 sgd_solver.cpp:294] Iteration 63060, lr = 0.0002
I0526 13:04:26.195587 15117 solver.cpp:233] Iteration 63070, loss = 0.00750091
I0526 13:04:26.195631 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00750106 (* 1 = 0.00750106 loss)
I0526 13:04:26.195637 15117 sgd_solver.cpp:294] Iteration 63070, lr = 0.0002
I0526 13:04:32.488055 15117 solver.cpp:233] Iteration 63080, loss = 0.0127069
I0526 13:04:32.488273 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.012707 (* 1 = 0.012707 loss)
I0526 13:04:32.488302 15117 sgd_solver.cpp:294] Iteration 63080, lr = 0.0002
I0526 13:04:38.778635 15117 solver.cpp:233] Iteration 63090, loss = 0.00151636
I0526 13:04:38.778693 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00151651 (* 1 = 0.00151651 loss)
I0526 13:04:38.778700 15117 sgd_solver.cpp:294] Iteration 63090, lr = 0.0002
I0526 13:04:44.469800 15117 solver.cpp:342] Iteration 63100, Testing net (#0)
I0526 13:04:57.249935 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9058
I0526 13:04:57.249984 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.444253 (* 1 = 0.444253 loss)
I0526 13:04:57.847645 15117 solver.cpp:233] Iteration 63100, loss = 0.0033769
I0526 13:04:57.847687 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00337706 (* 1 = 0.00337706 loss)
I0526 13:04:57.847693 15117 sgd_solver.cpp:294] Iteration 63100, lr = 0.0002
I0526 13:05:04.137987 15117 solver.cpp:233] Iteration 63110, loss = 0.00685631
I0526 13:05:04.138243 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00685646 (* 1 = 0.00685646 loss)
I0526 13:05:04.138286 15117 sgd_solver.cpp:294] Iteration 63110, lr = 0.0002
I0526 13:05:10.428117 15117 solver.cpp:233] Iteration 63120, loss = 0.00332749
I0526 13:05:10.428159 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00332764 (* 1 = 0.00332764 loss)
I0526 13:05:10.428166 15117 sgd_solver.cpp:294] Iteration 63120, lr = 0.0002
I0526 13:05:16.712045 15117 solver.cpp:233] Iteration 63130, loss = 0.013285
I0526 13:05:16.712087 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0132852 (* 1 = 0.0132852 loss)
I0526 13:05:16.712095 15117 sgd_solver.cpp:294] Iteration 63130, lr = 0.0002
I0526 13:05:22.999976 15117 solver.cpp:233] Iteration 63140, loss = 0.0243156
I0526 13:05:23.000020 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0243158 (* 1 = 0.0243158 loss)
I0526 13:05:23.000027 15117 sgd_solver.cpp:294] Iteration 63140, lr = 0.0002
I0526 13:05:29.286010 15117 solver.cpp:233] Iteration 63150, loss = 0.00565997
I0526 13:05:29.286046 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00566012 (* 1 = 0.00566012 loss)
I0526 13:05:29.286053 15117 sgd_solver.cpp:294] Iteration 63150, lr = 0.0002
I0526 13:05:35.570962 15117 solver.cpp:233] Iteration 63160, loss = 0.00337644
I0526 13:05:35.571168 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00337659 (* 1 = 0.00337659 loss)
I0526 13:05:35.571197 15117 sgd_solver.cpp:294] Iteration 63160, lr = 0.0002
I0526 13:05:41.860527 15117 solver.cpp:233] Iteration 63170, loss = 0.0245847
I0526 13:05:41.860571 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0245848 (* 1 = 0.0245848 loss)
I0526 13:05:41.860579 15117 sgd_solver.cpp:294] Iteration 63170, lr = 0.0002
I0526 13:05:48.152168 15117 solver.cpp:233] Iteration 63180, loss = 0.0102633
I0526 13:05:48.152209 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0102635 (* 1 = 0.0102635 loss)
I0526 13:05:48.152215 15117 sgd_solver.cpp:294] Iteration 63180, lr = 0.0002
I0526 13:05:54.442276 15117 solver.cpp:233] Iteration 63190, loss = 0.0130996
I0526 13:05:54.442318 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0130998 (* 1 = 0.0130998 loss)
I0526 13:05:54.442324 15117 sgd_solver.cpp:294] Iteration 63190, lr = 0.0002
I0526 13:06:00.136566 15117 solver.cpp:342] Iteration 63200, Testing net (#0)
I0526 13:06:12.913409 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9051
I0526 13:06:12.913635 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.456594 (* 1 = 0.456594 loss)
I0526 13:06:13.509938 15117 solver.cpp:233] Iteration 63200, loss = 0.00741424
I0526 13:06:13.509977 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00741438 (* 1 = 0.00741438 loss)
I0526 13:06:13.509985 15117 sgd_solver.cpp:294] Iteration 63200, lr = 0.0002
I0526 13:06:19.798979 15117 solver.cpp:233] Iteration 63210, loss = 0.0200701
I0526 13:06:19.799015 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0200702 (* 1 = 0.0200702 loss)
I0526 13:06:19.799022 15117 sgd_solver.cpp:294] Iteration 63210, lr = 0.0002
I0526 13:06:26.085443 15117 solver.cpp:233] Iteration 63220, loss = 0.00327916
I0526 13:06:26.085486 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00327931 (* 1 = 0.00327931 loss)
I0526 13:06:26.085494 15117 sgd_solver.cpp:294] Iteration 63220, lr = 0.0002
I0526 13:06:32.376695 15117 solver.cpp:233] Iteration 63230, loss = 0.0117075
I0526 13:06:32.376737 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0117076 (* 1 = 0.0117076 loss)
I0526 13:06:32.376744 15117 sgd_solver.cpp:294] Iteration 63230, lr = 0.0002
I0526 13:06:38.667546 15117 solver.cpp:233] Iteration 63240, loss = 0.0130945
I0526 13:06:38.667580 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0130947 (* 1 = 0.0130947 loss)
I0526 13:06:38.667587 15117 sgd_solver.cpp:294] Iteration 63240, lr = 0.0002
I0526 13:06:44.958051 15117 solver.cpp:233] Iteration 63250, loss = 0.00952853
I0526 13:06:44.958245 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00952868 (* 1 = 0.00952868 loss)
I0526 13:06:44.958255 15117 sgd_solver.cpp:294] Iteration 63250, lr = 0.0002
I0526 13:06:51.246064 15117 solver.cpp:233] Iteration 63260, loss = 0.00316004
I0526 13:06:51.246109 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00316018 (* 1 = 0.00316018 loss)
I0526 13:06:51.246114 15117 sgd_solver.cpp:294] Iteration 63260, lr = 0.0002
I0526 13:06:57.535799 15117 solver.cpp:233] Iteration 63270, loss = 0.0068389
I0526 13:06:57.535841 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00683904 (* 1 = 0.00683904 loss)
I0526 13:06:57.535848 15117 sgd_solver.cpp:294] Iteration 63270, lr = 0.0002
I0526 13:07:03.824600 15117 solver.cpp:233] Iteration 63280, loss = 0.0140577
I0526 13:07:03.824640 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0140578 (* 1 = 0.0140578 loss)
I0526 13:07:03.824646 15117 sgd_solver.cpp:294] Iteration 63280, lr = 0.0002
I0526 13:07:10.115185 15117 solver.cpp:233] Iteration 63290, loss = 0.00406934
I0526 13:07:10.115226 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00406949 (* 1 = 0.00406949 loss)
I0526 13:07:10.115233 15117 sgd_solver.cpp:294] Iteration 63290, lr = 0.0002
I0526 13:07:15.809327 15117 solver.cpp:342] Iteration 63300, Testing net (#0)
I0526 13:07:28.587028 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9046
I0526 13:07:28.587074 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.452599 (* 1 = 0.452599 loss)
I0526 13:07:29.183656 15117 solver.cpp:233] Iteration 63300, loss = 0.0133178
I0526 13:07:29.183697 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.013318 (* 1 = 0.013318 loss)
I0526 13:07:29.183706 15117 sgd_solver.cpp:294] Iteration 63300, lr = 0.0002
I0526 13:07:35.471791 15117 solver.cpp:233] Iteration 63310, loss = 0.00696443
I0526 13:07:35.471833 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00696458 (* 1 = 0.00696458 loss)
I0526 13:07:35.471842 15117 sgd_solver.cpp:294] Iteration 63310, lr = 0.0002
I0526 13:07:41.761107 15117 solver.cpp:233] Iteration 63320, loss = 0.0153038
I0526 13:07:41.761152 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.015304 (* 1 = 0.015304 loss)
I0526 13:07:41.761159 15117 sgd_solver.cpp:294] Iteration 63320, lr = 0.0002
I0526 13:07:48.046603 15117 solver.cpp:233] Iteration 63330, loss = 0.0160224
I0526 13:07:48.046730 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0160225 (* 1 = 0.0160225 loss)
I0526 13:07:48.046738 15117 sgd_solver.cpp:294] Iteration 63330, lr = 0.0002
I0526 13:07:54.338543 15117 solver.cpp:233] Iteration 63340, loss = 0.00913846
I0526 13:07:54.338587 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0091386 (* 1 = 0.0091386 loss)
I0526 13:07:54.338594 15117 sgd_solver.cpp:294] Iteration 63340, lr = 0.0002
I0526 13:08:00.627058 15117 solver.cpp:233] Iteration 63350, loss = 0.0132289
I0526 13:08:00.627100 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.013229 (* 1 = 0.013229 loss)
I0526 13:08:00.627107 15117 sgd_solver.cpp:294] Iteration 63350, lr = 0.0002
I0526 13:08:06.915243 15117 solver.cpp:233] Iteration 63360, loss = 0.0186311
I0526 13:08:06.915287 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0186313 (* 1 = 0.0186313 loss)
I0526 13:08:06.915294 15117 sgd_solver.cpp:294] Iteration 63360, lr = 0.0002
I0526 13:08:13.203759 15117 solver.cpp:233] Iteration 63370, loss = 0.0155461
I0526 13:08:13.203799 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0155462 (* 1 = 0.0155462 loss)
I0526 13:08:13.203805 15117 sgd_solver.cpp:294] Iteration 63370, lr = 0.0002
I0526 13:08:19.494076 15117 solver.cpp:233] Iteration 63380, loss = 0.0191618
I0526 13:08:19.494292 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0191619 (* 1 = 0.0191619 loss)
I0526 13:08:19.494320 15117 sgd_solver.cpp:294] Iteration 63380, lr = 0.0002
I0526 13:08:25.786208 15117 solver.cpp:233] Iteration 63390, loss = 0.00569464
I0526 13:08:25.786253 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00569477 (* 1 = 0.00569477 loss)
I0526 13:08:25.786260 15117 sgd_solver.cpp:294] Iteration 63390, lr = 0.0002
I0526 13:08:31.477953 15117 solver.cpp:342] Iteration 63400, Testing net (#0)
I0526 13:08:44.252140 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9044
I0526 13:08:44.252184 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.457655 (* 1 = 0.457655 loss)
I0526 13:08:44.848762 15117 solver.cpp:233] Iteration 63400, loss = 0.0215021
I0526 13:08:44.848798 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0215023 (* 1 = 0.0215023 loss)
I0526 13:08:44.848805 15117 sgd_solver.cpp:294] Iteration 63400, lr = 0.0002
I0526 13:08:51.134292 15117 solver.cpp:233] Iteration 63410, loss = 0.00504307
I0526 13:08:51.134539 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00504321 (* 1 = 0.00504321 loss)
I0526 13:08:51.134569 15117 sgd_solver.cpp:294] Iteration 63410, lr = 0.0002
I0526 13:08:57.423319 15117 solver.cpp:233] Iteration 63420, loss = 0.0142956
I0526 13:08:57.423362 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0142957 (* 1 = 0.0142957 loss)
I0526 13:08:57.423369 15117 sgd_solver.cpp:294] Iteration 63420, lr = 0.0002
I0526 13:09:03.711966 15117 solver.cpp:233] Iteration 63430, loss = 0.00476532
I0526 13:09:03.712007 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00476546 (* 1 = 0.00476546 loss)
I0526 13:09:03.712014 15117 sgd_solver.cpp:294] Iteration 63430, lr = 0.0002
I0526 13:09:09.998958 15117 solver.cpp:233] Iteration 63440, loss = 0.0135638
I0526 13:09:09.999001 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0135639 (* 1 = 0.0135639 loss)
I0526 13:09:09.999007 15117 sgd_solver.cpp:294] Iteration 63440, lr = 0.0002
I0526 13:09:16.284354 15117 solver.cpp:233] Iteration 63450, loss = 0.0132345
I0526 13:09:16.284399 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0132347 (* 1 = 0.0132347 loss)
I0526 13:09:16.284406 15117 sgd_solver.cpp:294] Iteration 63450, lr = 0.0002
I0526 13:09:22.573379 15117 solver.cpp:233] Iteration 63460, loss = 0.0102124
I0526 13:09:22.573611 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0102125 (* 1 = 0.0102125 loss)
I0526 13:09:22.573639 15117 sgd_solver.cpp:294] Iteration 63460, lr = 0.0002
I0526 13:09:28.863200 15117 solver.cpp:233] Iteration 63470, loss = 0.00421449
I0526 13:09:28.863237 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00421463 (* 1 = 0.00421463 loss)
I0526 13:09:28.863245 15117 sgd_solver.cpp:294] Iteration 63470, lr = 0.0002
I0526 13:09:35.150923 15117 solver.cpp:233] Iteration 63480, loss = 0.00276375
I0526 13:09:35.150967 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00276389 (* 1 = 0.00276389 loss)
I0526 13:09:35.150975 15117 sgd_solver.cpp:294] Iteration 63480, lr = 0.0002
I0526 13:09:41.435291 15117 solver.cpp:233] Iteration 63490, loss = 0.00946011
I0526 13:09:41.435334 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00946026 (* 1 = 0.00946026 loss)
I0526 13:09:41.435341 15117 sgd_solver.cpp:294] Iteration 63490, lr = 0.0002
I0526 13:09:47.129248 15117 solver.cpp:342] Iteration 63500, Testing net (#0)
I0526 13:09:59.918270 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9034
I0526 13:09:59.918493 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.459438 (* 1 = 0.459438 loss)
I0526 13:10:00.514750 15117 solver.cpp:233] Iteration 63500, loss = 0.0133609
I0526 13:10:00.514791 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0133611 (* 1 = 0.0133611 loss)
I0526 13:10:00.514797 15117 sgd_solver.cpp:294] Iteration 63500, lr = 0.0002
I0526 13:10:06.802635 15117 solver.cpp:233] Iteration 63510, loss = 0.00530434
I0526 13:10:06.802693 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00530448 (* 1 = 0.00530448 loss)
I0526 13:10:06.802706 15117 sgd_solver.cpp:294] Iteration 63510, lr = 0.0002
I0526 13:10:13.094187 15117 solver.cpp:233] Iteration 63520, loss = 0.0071846
I0526 13:10:13.094228 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00718474 (* 1 = 0.00718474 loss)
I0526 13:10:13.094235 15117 sgd_solver.cpp:294] Iteration 63520, lr = 0.0002
I0526 13:10:19.384424 15117 solver.cpp:233] Iteration 63530, loss = 0.0286586
I0526 13:10:19.384466 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0286588 (* 1 = 0.0286588 loss)
I0526 13:10:19.384472 15117 sgd_solver.cpp:294] Iteration 63530, lr = 0.0002
I0526 13:10:25.669345 15117 solver.cpp:233] Iteration 63540, loss = 0.00691759
I0526 13:10:25.669389 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00691773 (* 1 = 0.00691773 loss)
I0526 13:10:25.669395 15117 sgd_solver.cpp:294] Iteration 63540, lr = 0.0002
I0526 13:10:31.960268 15117 solver.cpp:233] Iteration 63550, loss = 0.00765839
I0526 13:10:31.960527 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00765853 (* 1 = 0.00765853 loss)
I0526 13:10:31.960556 15117 sgd_solver.cpp:294] Iteration 63550, lr = 0.0002
I0526 13:10:38.246476 15117 solver.cpp:233] Iteration 63560, loss = 0.00938292
I0526 13:10:38.246523 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00938306 (* 1 = 0.00938306 loss)
I0526 13:10:38.246531 15117 sgd_solver.cpp:294] Iteration 63560, lr = 0.0002
I0526 13:10:44.533135 15117 solver.cpp:233] Iteration 63570, loss = 0.0052995
I0526 13:10:44.533177 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00529964 (* 1 = 0.00529964 loss)
I0526 13:10:44.533185 15117 sgd_solver.cpp:294] Iteration 63570, lr = 0.0002
I0526 13:10:50.822537 15117 solver.cpp:233] Iteration 63580, loss = 0.0131918
I0526 13:10:50.822576 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0131919 (* 1 = 0.0131919 loss)
I0526 13:10:50.822583 15117 sgd_solver.cpp:294] Iteration 63580, lr = 0.0002
I0526 13:10:57.112009 15117 solver.cpp:233] Iteration 63590, loss = 0.0159895
I0526 13:10:57.112051 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0159896 (* 1 = 0.0159896 loss)
I0526 13:10:57.112058 15117 sgd_solver.cpp:294] Iteration 63590, lr = 0.0002
I0526 13:11:02.801749 15117 solver.cpp:342] Iteration 63600, Testing net (#0)
I0526 13:11:15.590721 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9
I0526 13:11:15.590769 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.457189 (* 1 = 0.457189 loss)
I0526 13:11:16.187770 15117 solver.cpp:233] Iteration 63600, loss = 0.0102214
I0526 13:11:16.187808 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0102216 (* 1 = 0.0102216 loss)
I0526 13:11:16.187815 15117 sgd_solver.cpp:294] Iteration 63600, lr = 0.0002
I0526 13:11:22.481796 15117 solver.cpp:233] Iteration 63610, loss = 0.0266771
I0526 13:11:22.481832 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0266773 (* 1 = 0.0266773 loss)
I0526 13:11:22.481840 15117 sgd_solver.cpp:294] Iteration 63610, lr = 0.0002
I0526 13:11:28.769106 15117 solver.cpp:233] Iteration 63620, loss = 0.0160459
I0526 13:11:28.769146 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0160461 (* 1 = 0.0160461 loss)
I0526 13:11:28.769153 15117 sgd_solver.cpp:294] Iteration 63620, lr = 0.0002
I0526 13:11:35.060070 15117 solver.cpp:233] Iteration 63630, loss = 0.00382373
I0526 13:11:35.060286 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00382388 (* 1 = 0.00382388 loss)
I0526 13:11:35.060315 15117 sgd_solver.cpp:294] Iteration 63630, lr = 0.0002
I0526 13:11:41.349601 15117 solver.cpp:233] Iteration 63640, loss = 0.00535544
I0526 13:11:41.349647 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00535559 (* 1 = 0.00535559 loss)
I0526 13:11:41.349654 15117 sgd_solver.cpp:294] Iteration 63640, lr = 0.0002
I0526 13:11:47.639873 15117 solver.cpp:233] Iteration 63650, loss = 0.0202607
I0526 13:11:47.639916 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0202609 (* 1 = 0.0202609 loss)
I0526 13:11:47.639930 15117 sgd_solver.cpp:294] Iteration 63650, lr = 0.0002
I0526 13:11:53.929929 15117 solver.cpp:233] Iteration 63660, loss = 0.00605346
I0526 13:11:53.929973 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00605361 (* 1 = 0.00605361 loss)
I0526 13:11:53.929980 15117 sgd_solver.cpp:294] Iteration 63660, lr = 0.0002
I0526 13:12:00.215962 15117 solver.cpp:233] Iteration 63670, loss = 0.00795726
I0526 13:12:00.216003 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00795741 (* 1 = 0.00795741 loss)
I0526 13:12:00.216011 15117 sgd_solver.cpp:294] Iteration 63670, lr = 0.0002
I0526 13:12:06.508175 15117 solver.cpp:233] Iteration 63680, loss = 0.00439938
I0526 13:12:06.508447 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00439953 (* 1 = 0.00439953 loss)
I0526 13:12:06.508477 15117 sgd_solver.cpp:294] Iteration 63680, lr = 0.0002
I0526 13:12:12.802860 15117 solver.cpp:233] Iteration 63690, loss = 0.00240295
I0526 13:12:12.802902 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0024031 (* 1 = 0.0024031 loss)
I0526 13:12:12.802909 15117 sgd_solver.cpp:294] Iteration 63690, lr = 0.0002
I0526 13:12:18.496572 15117 solver.cpp:342] Iteration 63700, Testing net (#0)
I0526 13:12:31.278403 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9082
I0526 13:12:31.278448 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.438127 (* 1 = 0.438127 loss)
I0526 13:12:31.876169 15117 solver.cpp:233] Iteration 63700, loss = 0.0228982
I0526 13:12:31.876210 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0228984 (* 1 = 0.0228984 loss)
I0526 13:12:31.876217 15117 sgd_solver.cpp:294] Iteration 63700, lr = 0.0002
I0526 13:12:38.166286 15117 solver.cpp:233] Iteration 63710, loss = 0.00366639
I0526 13:12:38.166426 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00366654 (* 1 = 0.00366654 loss)
I0526 13:12:38.166435 15117 sgd_solver.cpp:294] Iteration 63710, lr = 0.0002
I0526 13:12:44.457540 15117 solver.cpp:233] Iteration 63720, loss = 0.0125561
I0526 13:12:44.457583 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0125563 (* 1 = 0.0125563 loss)
I0526 13:12:44.457592 15117 sgd_solver.cpp:294] Iteration 63720, lr = 0.0002
I0526 13:12:50.742743 15117 solver.cpp:233] Iteration 63730, loss = 0.00382828
I0526 13:12:50.742785 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00382843 (* 1 = 0.00382843 loss)
I0526 13:12:50.742792 15117 sgd_solver.cpp:294] Iteration 63730, lr = 0.0002
I0526 13:12:57.030978 15117 solver.cpp:233] Iteration 63740, loss = 0.00932561
I0526 13:12:57.031023 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00932576 (* 1 = 0.00932576 loss)
I0526 13:12:57.031028 15117 sgd_solver.cpp:294] Iteration 63740, lr = 0.0002
I0526 13:13:03.319658 15117 solver.cpp:233] Iteration 63750, loss = 0.00714846
I0526 13:13:03.319701 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00714861 (* 1 = 0.00714861 loss)
I0526 13:13:03.319710 15117 sgd_solver.cpp:294] Iteration 63750, lr = 0.0002
I0526 13:13:09.604567 15117 solver.cpp:233] Iteration 63760, loss = 0.00956308
I0526 13:13:09.604784 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00956323 (* 1 = 0.00956323 loss)
I0526 13:13:09.604814 15117 sgd_solver.cpp:294] Iteration 63760, lr = 0.0002
I0526 13:13:15.894049 15117 solver.cpp:233] Iteration 63770, loss = 0.015286
I0526 13:13:15.894090 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0152861 (* 1 = 0.0152861 loss)
I0526 13:13:15.894098 15117 sgd_solver.cpp:294] Iteration 63770, lr = 0.0002
I0526 13:13:22.184828 15117 solver.cpp:233] Iteration 63780, loss = 0.0106649
I0526 13:13:22.184875 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0106651 (* 1 = 0.0106651 loss)
I0526 13:13:22.184882 15117 sgd_solver.cpp:294] Iteration 63780, lr = 0.0002
I0526 13:13:28.476485 15117 solver.cpp:233] Iteration 63790, loss = 0.017961
I0526 13:13:28.476536 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0179611 (* 1 = 0.0179611 loss)
I0526 13:13:28.476542 15117 sgd_solver.cpp:294] Iteration 63790, lr = 0.0002
I0526 13:13:34.166160 15117 solver.cpp:342] Iteration 63800, Testing net (#0)
I0526 13:13:46.947515 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9052
I0526 13:13:46.947777 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.449932 (* 1 = 0.449932 loss)
I0526 13:13:47.545527 15117 solver.cpp:233] Iteration 63800, loss = 0.00586026
I0526 13:13:47.545578 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00586041 (* 1 = 0.00586041 loss)
I0526 13:13:47.545586 15117 sgd_solver.cpp:294] Iteration 63800, lr = 0.0002
I0526 13:13:53.831073 15117 solver.cpp:233] Iteration 63810, loss = 0.0173207
I0526 13:13:53.831116 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0173209 (* 1 = 0.0173209 loss)
I0526 13:13:53.831125 15117 sgd_solver.cpp:294] Iteration 63810, lr = 0.0002
I0526 13:14:00.119197 15117 solver.cpp:233] Iteration 63820, loss = 0.00502151
I0526 13:14:00.119245 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00502166 (* 1 = 0.00502166 loss)
I0526 13:14:00.119251 15117 sgd_solver.cpp:294] Iteration 63820, lr = 0.0002
I0526 13:14:06.408438 15117 solver.cpp:233] Iteration 63830, loss = 0.00990901
I0526 13:14:06.408479 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00990916 (* 1 = 0.00990916 loss)
I0526 13:14:06.408486 15117 sgd_solver.cpp:294] Iteration 63830, lr = 0.0002
I0526 13:14:12.697111 15117 solver.cpp:233] Iteration 63840, loss = 0.0086808
I0526 13:14:12.697154 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00868095 (* 1 = 0.00868095 loss)
I0526 13:14:12.697160 15117 sgd_solver.cpp:294] Iteration 63840, lr = 0.0002
I0526 13:14:18.985985 15117 solver.cpp:233] Iteration 63850, loss = 0.0178243
I0526 13:14:18.986177 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0178245 (* 1 = 0.0178245 loss)
I0526 13:14:18.986207 15117 sgd_solver.cpp:294] Iteration 63850, lr = 0.0002
I0526 13:14:25.276324 15117 solver.cpp:233] Iteration 63860, loss = 0.00667669
I0526 13:14:25.276365 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00667684 (* 1 = 0.00667684 loss)
I0526 13:14:25.276372 15117 sgd_solver.cpp:294] Iteration 63860, lr = 0.0002
I0526 13:14:31.566181 15117 solver.cpp:233] Iteration 63870, loss = 0.00559756
I0526 13:14:31.566226 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00559771 (* 1 = 0.00559771 loss)
I0526 13:14:31.566231 15117 sgd_solver.cpp:294] Iteration 63870, lr = 0.0002
I0526 13:14:37.856114 15117 solver.cpp:233] Iteration 63880, loss = 0.0153604
I0526 13:14:37.856156 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0153606 (* 1 = 0.0153606 loss)
I0526 13:14:37.856163 15117 sgd_solver.cpp:294] Iteration 63880, lr = 0.0002
I0526 13:14:44.144101 15117 solver.cpp:233] Iteration 63890, loss = 0.00636892
I0526 13:14:44.144145 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00636907 (* 1 = 0.00636907 loss)
I0526 13:14:44.144151 15117 sgd_solver.cpp:294] Iteration 63890, lr = 0.0002
I0526 13:14:49.832731 15117 solver.cpp:342] Iteration 63900, Testing net (#0)
I0526 13:15:02.609990 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9056
I0526 13:15:02.610029 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.456731 (* 1 = 0.456731 loss)
I0526 13:15:03.206154 15117 solver.cpp:233] Iteration 63900, loss = 0.00997127
I0526 13:15:03.206197 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00997143 (* 1 = 0.00997143 loss)
I0526 13:15:03.206203 15117 sgd_solver.cpp:294] Iteration 63900, lr = 0.0002
I0526 13:15:09.495611 15117 solver.cpp:233] Iteration 63910, loss = 0.00696749
I0526 13:15:09.495654 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00696764 (* 1 = 0.00696764 loss)
I0526 13:15:09.495662 15117 sgd_solver.cpp:294] Iteration 63910, lr = 0.0002
I0526 13:15:15.783598 15117 solver.cpp:233] Iteration 63920, loss = 0.0207308
I0526 13:15:15.783643 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.020731 (* 1 = 0.020731 loss)
I0526 13:15:15.783649 15117 sgd_solver.cpp:294] Iteration 63920, lr = 0.0002
I0526 13:15:22.072329 15117 solver.cpp:233] Iteration 63930, loss = 0.00460227
I0526 13:15:22.072587 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00460243 (* 1 = 0.00460243 loss)
I0526 13:15:22.072613 15117 sgd_solver.cpp:294] Iteration 63930, lr = 0.0002
I0526 13:15:28.365882 15117 solver.cpp:233] Iteration 63940, loss = 0.00910519
I0526 13:15:28.365917 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00910534 (* 1 = 0.00910534 loss)
I0526 13:15:28.365924 15117 sgd_solver.cpp:294] Iteration 63940, lr = 0.0002
I0526 13:15:34.654728 15117 solver.cpp:233] Iteration 63950, loss = 0.00639484
I0526 13:15:34.654772 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00639499 (* 1 = 0.00639499 loss)
I0526 13:15:34.654778 15117 sgd_solver.cpp:294] Iteration 63950, lr = 0.0002
I0526 13:15:40.943477 15117 solver.cpp:233] Iteration 63960, loss = 0.0113184
I0526 13:15:40.943522 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0113186 (* 1 = 0.0113186 loss)
I0526 13:15:40.943529 15117 sgd_solver.cpp:294] Iteration 63960, lr = 0.0002
I0526 13:15:47.233781 15117 solver.cpp:233] Iteration 63970, loss = 0.00594622
I0526 13:15:47.233824 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00594638 (* 1 = 0.00594638 loss)
I0526 13:15:47.233831 15117 sgd_solver.cpp:294] Iteration 63970, lr = 0.0002
I0526 13:15:53.522796 15117 solver.cpp:233] Iteration 63980, loss = 0.00242481
I0526 13:15:53.522929 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00242496 (* 1 = 0.00242496 loss)
I0526 13:15:53.522936 15117 sgd_solver.cpp:294] Iteration 63980, lr = 0.0002
I0526 13:15:59.806264 15117 solver.cpp:233] Iteration 63990, loss = 0.0115108
I0526 13:15:59.806311 15117 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0115109 (* 1 = 0.0115109 loss)
I0526 13:15:59.806318 15117 sgd_solver.cpp:294] Iteration 63990, lr = 0.0002
I0526 13:16:05.495074 15117 solver.cpp:459] Snapshotting to binary proto file _iter_64000.caffemodel
I0526 13:16:05.532526 15117 sgd_solver.cpp:458] Snapshotting solver state to binary proto file _iter_64000.solverstate
I0526 13:16:05.719069 15117 solver.cpp:322] Iteration 64000, loss = 0.00697469
I0526 13:16:05.719094 15117 solver.cpp:342] Iteration 64000, Testing net (#0)
I0526 13:16:18.506597 15117 solver.cpp:409]     Test net output #0: Accuracy = 0.9075
I0526 13:16:18.506649 15117 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.436954 (* 1 = 0.436954 loss)
I0526 13:16:18.506659 15117 solver.cpp:327] Optimization Done.
I0526 13:16:18.506664 15117 caffe.cpp:222] Optimization Done.
