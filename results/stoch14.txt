WARNING: Logging before InitGoogleLogging() is written to STDERR
I0525 23:46:16.761443 15394 solver.cpp:53] Initializing solver from parameters: 
train_net: "examples/stochastic_depth/residual_train.prototxt"
test_net: "examples/stochastic_depth/residual_test.prototxt"
test_iter: 100
test_interval: 100
base_lr: 0.02
display: 10
max_iter: 64000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
solver_mode: GPU
random_seed: 831486
stepvalue: 32000
stepvalue: 48000
type: "Nesterov"
I0525 23:46:16.761736 15394 solver.cpp:86] Creating training net from train_net file: examples/stochastic_depth/residual_train.prototxt
I0525 23:46:16.767319 15394 net.cpp:148] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "/scratch/pas282/caffe/examples/cifar10/cifar10_train_leveldb_padding0"
    batch_size: 128
    backend: LEVELDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise4"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Input1"
  type: "Input"
  top: "Input1"
  input_param {
    shape {
      dim: 128
      dim: 16
      dim: 16
      dim: 16
    }
  }
}
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "Pooling1"
  bottom: "Input1"
  top: "Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Concat1"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Pooling2"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling2"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Input2"
  type: "Input"
  top: "Input2"
  input_param {
    shape {
      dim: 128
      dim: 32
      dim: 8
      dim: 8
    }
  }
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "Pooling2"
  bottom: "Input2"
  top: "Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Concat2"
  bottom: "Convolution21"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution22"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution22"
  top: "Convolution22"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Convolution22"
  top: "Convolution23"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution23"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution24"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution25"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution26"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution27"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution28"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution28"
  top: "Convolution28"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution29"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Pooling3"
  type: "Pooling"
  bottom: "Eltwise14"
  top: "Pooling3"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling3"
  top: "InnerProduct1"
  inner_product_param {
    num_output: 10
    bias_term: true
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
I0525 23:46:16.768141 15394 layer_factory.hpp:77] Creating layer Data1
I0525 23:46:16.769392 15394 net.cpp:190] Creating Layer Data1
I0525 23:46:16.769453 15394 net.cpp:579] Data1 -> Data1
I0525 23:46:16.769529 15394 net.cpp:579] Data1 -> Data2
I0525 23:46:16.805218 15398 db_leveldb.cpp:18] Opened leveldb /scratch/pas282/caffe/examples/cifar10/cifar10_train_leveldb_padding0
I0525 23:46:16.833379 15394 data_layer.cpp:41] output data size: 128,3,32,32
I0525 23:46:16.838162 15394 net.cpp:240] Setting up Data1
I0525 23:46:16.838234 15394 net.cpp:247] Top shape: 128 3 32 32 (393216)
I0525 23:46:16.838241 15394 net.cpp:247] Top shape: 128 (128)
I0525 23:46:16.838245 15394 net.cpp:255] Memory required for data: 1573376
I0525 23:46:16.838264 15394 layer_factory.hpp:77] Creating layer Convolution1
I0525 23:46:16.842442 15394 net.cpp:190] Creating Layer Convolution1
I0525 23:46:16.842500 15394 net.cpp:605] Convolution1 <- Data1
I0525 23:46:16.842536 15394 net.cpp:579] Convolution1 -> Convolution1
I0525 23:46:16.843880 15394 net.cpp:240] Setting up Convolution1
I0525 23:46:16.843929 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.843933 15394 net.cpp:255] Memory required for data: 9961984
I0525 23:46:16.843967 15394 layer_factory.hpp:77] Creating layer BatchNorm1
I0525 23:46:16.843991 15394 net.cpp:190] Creating Layer BatchNorm1
I0525 23:46:16.843998 15394 net.cpp:605] BatchNorm1 <- Convolution1
I0525 23:46:16.844007 15394 net.cpp:566] BatchNorm1 -> Convolution1 (in-place)
I0525 23:46:16.844218 15394 net.cpp:240] Setting up BatchNorm1
I0525 23:46:16.844229 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.844233 15394 net.cpp:255] Memory required for data: 18350592
I0525 23:46:16.844252 15394 layer_factory.hpp:77] Creating layer Scale1
I0525 23:46:16.844264 15394 net.cpp:190] Creating Layer Scale1
I0525 23:46:16.844269 15394 net.cpp:605] Scale1 <- Convolution1
I0525 23:46:16.844274 15394 net.cpp:566] Scale1 -> Convolution1 (in-place)
I0525 23:46:16.844321 15394 layer_factory.hpp:77] Creating layer Scale1
I0525 23:46:16.844460 15394 net.cpp:240] Setting up Scale1
I0525 23:46:16.844468 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.844472 15394 net.cpp:255] Memory required for data: 26739200
I0525 23:46:16.844481 15394 layer_factory.hpp:77] Creating layer ReLU1
I0525 23:46:16.844493 15394 net.cpp:190] Creating Layer ReLU1
I0525 23:46:16.844498 15394 net.cpp:605] ReLU1 <- Convolution1
I0525 23:46:16.844504 15394 net.cpp:566] ReLU1 -> Convolution1 (in-place)
I0525 23:46:16.844522 15394 net.cpp:240] Setting up ReLU1
I0525 23:46:16.844527 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.844530 15394 net.cpp:255] Memory required for data: 35127808
I0525 23:46:16.844534 15394 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0525 23:46:16.844549 15394 net.cpp:190] Creating Layer Convolution1_ReLU1_0_split
I0525 23:46:16.844554 15394 net.cpp:605] Convolution1_ReLU1_0_split <- Convolution1
I0525 23:46:16.844560 15394 net.cpp:579] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0525 23:46:16.844568 15394 net.cpp:579] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0525 23:46:16.844612 15394 net.cpp:240] Setting up Convolution1_ReLU1_0_split
I0525 23:46:16.844621 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.844626 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.844630 15394 net.cpp:255] Memory required for data: 51905024
I0525 23:46:16.844633 15394 layer_factory.hpp:77] Creating layer Convolution2
I0525 23:46:16.844648 15394 net.cpp:190] Creating Layer Convolution2
I0525 23:46:16.844652 15394 net.cpp:605] Convolution2 <- Convolution1_ReLU1_0_split_0
I0525 23:46:16.844660 15394 net.cpp:579] Convolution2 -> Convolution2
I0525 23:46:16.848340 15399 blocking_queue.cpp:50] Waiting for data
I0525 23:46:16.851632 15394 net.cpp:240] Setting up Convolution2
I0525 23:46:16.851685 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.851689 15394 net.cpp:255] Memory required for data: 60293632
I0525 23:46:16.851717 15394 layer_factory.hpp:77] Creating layer BatchNorm2
I0525 23:46:16.851737 15394 net.cpp:190] Creating Layer BatchNorm2
I0525 23:46:16.851742 15394 net.cpp:605] BatchNorm2 <- Convolution2
I0525 23:46:16.851757 15394 net.cpp:566] BatchNorm2 -> Convolution2 (in-place)
I0525 23:46:16.851943 15394 net.cpp:240] Setting up BatchNorm2
I0525 23:46:16.851953 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.851955 15394 net.cpp:255] Memory required for data: 68682240
I0525 23:46:16.851970 15394 layer_factory.hpp:77] Creating layer Scale2
I0525 23:46:16.851984 15394 net.cpp:190] Creating Layer Scale2
I0525 23:46:16.851989 15394 net.cpp:605] Scale2 <- Convolution2
I0525 23:46:16.851995 15394 net.cpp:566] Scale2 -> Convolution2 (in-place)
I0525 23:46:16.852038 15394 layer_factory.hpp:77] Creating layer Scale2
I0525 23:46:16.852149 15394 net.cpp:240] Setting up Scale2
I0525 23:46:16.852159 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.852161 15394 net.cpp:255] Memory required for data: 77070848
I0525 23:46:16.852170 15394 layer_factory.hpp:77] Creating layer ReLU2
I0525 23:46:16.852180 15394 net.cpp:190] Creating Layer ReLU2
I0525 23:46:16.852185 15394 net.cpp:605] ReLU2 <- Convolution2
I0525 23:46:16.852191 15394 net.cpp:566] ReLU2 -> Convolution2 (in-place)
I0525 23:46:16.852200 15394 net.cpp:240] Setting up ReLU2
I0525 23:46:16.852206 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.852210 15394 net.cpp:255] Memory required for data: 85459456
I0525 23:46:16.852213 15394 layer_factory.hpp:77] Creating layer Convolution3
I0525 23:46:16.852227 15394 net.cpp:190] Creating Layer Convolution3
I0525 23:46:16.852231 15394 net.cpp:605] Convolution3 <- Convolution2
I0525 23:46:16.852238 15394 net.cpp:579] Convolution3 -> Convolution3
I0525 23:46:16.852555 15394 net.cpp:240] Setting up Convolution3
I0525 23:46:16.852566 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.852571 15394 net.cpp:255] Memory required for data: 93848064
I0525 23:46:16.852587 15394 layer_factory.hpp:77] Creating layer BatchNorm3
I0525 23:46:16.852599 15394 net.cpp:190] Creating Layer BatchNorm3
I0525 23:46:16.852604 15394 net.cpp:605] BatchNorm3 <- Convolution3
I0525 23:46:16.852610 15394 net.cpp:566] BatchNorm3 -> Convolution3 (in-place)
I0525 23:46:16.852797 15394 net.cpp:240] Setting up BatchNorm3
I0525 23:46:16.852805 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.852809 15394 net.cpp:255] Memory required for data: 102236672
I0525 23:46:16.852826 15394 layer_factory.hpp:77] Creating layer Scale3
I0525 23:46:16.852835 15394 net.cpp:190] Creating Layer Scale3
I0525 23:46:16.852841 15394 net.cpp:605] Scale3 <- Convolution3
I0525 23:46:16.852847 15394 net.cpp:566] Scale3 -> Convolution3 (in-place)
I0525 23:46:16.852890 15394 layer_factory.hpp:77] Creating layer Scale3
I0525 23:46:16.853003 15394 net.cpp:240] Setting up Scale3
I0525 23:46:16.853011 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.853014 15394 net.cpp:255] Memory required for data: 110625280
I0525 23:46:16.853023 15394 layer_factory.hpp:77] Creating layer Eltwise1
I0525 23:46:16.853031 15394 net.cpp:190] Creating Layer Eltwise1
I0525 23:46:16.853039 15394 net.cpp:605] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0525 23:46:16.853044 15394 net.cpp:605] Eltwise1 <- Convolution3
I0525 23:46:16.853051 15394 net.cpp:579] Eltwise1 -> Eltwise1
I0525 23:46:16.853088 15394 net.cpp:240] Setting up Eltwise1
I0525 23:46:16.853096 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.853099 15394 net.cpp:255] Memory required for data: 119013888
I0525 23:46:16.853102 15394 layer_factory.hpp:77] Creating layer ReLU3
I0525 23:46:16.853113 15394 net.cpp:190] Creating Layer ReLU3
I0525 23:46:16.853117 15394 net.cpp:605] ReLU3 <- Eltwise1
I0525 23:46:16.853123 15394 net.cpp:566] ReLU3 -> Eltwise1 (in-place)
I0525 23:46:16.853129 15394 net.cpp:240] Setting up ReLU3
I0525 23:46:16.853135 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.853138 15394 net.cpp:255] Memory required for data: 127402496
I0525 23:46:16.853142 15394 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0525 23:46:16.853148 15394 net.cpp:190] Creating Layer Eltwise1_ReLU3_0_split
I0525 23:46:16.853152 15394 net.cpp:605] Eltwise1_ReLU3_0_split <- Eltwise1
I0525 23:46:16.853158 15394 net.cpp:579] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0525 23:46:16.853166 15394 net.cpp:579] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0525 23:46:16.853205 15394 net.cpp:240] Setting up Eltwise1_ReLU3_0_split
I0525 23:46:16.853214 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.853219 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.853221 15394 net.cpp:255] Memory required for data: 144179712
I0525 23:46:16.853225 15394 layer_factory.hpp:77] Creating layer Convolution4
I0525 23:46:16.853241 15394 net.cpp:190] Creating Layer Convolution4
I0525 23:46:16.853246 15394 net.cpp:605] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0525 23:46:16.853253 15394 net.cpp:579] Convolution4 -> Convolution4
I0525 23:46:16.853546 15394 net.cpp:240] Setting up Convolution4
I0525 23:46:16.853556 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.853559 15394 net.cpp:255] Memory required for data: 152568320
I0525 23:46:16.853569 15394 layer_factory.hpp:77] Creating layer BatchNorm4
I0525 23:46:16.853579 15394 net.cpp:190] Creating Layer BatchNorm4
I0525 23:46:16.853584 15394 net.cpp:605] BatchNorm4 <- Convolution4
I0525 23:46:16.853591 15394 net.cpp:566] BatchNorm4 -> Convolution4 (in-place)
I0525 23:46:16.853772 15394 net.cpp:240] Setting up BatchNorm4
I0525 23:46:16.853781 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.853785 15394 net.cpp:255] Memory required for data: 160956928
I0525 23:46:16.853795 15394 layer_factory.hpp:77] Creating layer Scale4
I0525 23:46:16.853807 15394 net.cpp:190] Creating Layer Scale4
I0525 23:46:16.853812 15394 net.cpp:605] Scale4 <- Convolution4
I0525 23:46:16.853817 15394 net.cpp:566] Scale4 -> Convolution4 (in-place)
I0525 23:46:16.853865 15394 layer_factory.hpp:77] Creating layer Scale4
I0525 23:46:16.854001 15394 net.cpp:240] Setting up Scale4
I0525 23:46:16.854010 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.854013 15394 net.cpp:255] Memory required for data: 169345536
I0525 23:46:16.854022 15394 layer_factory.hpp:77] Creating layer ReLU4
I0525 23:46:16.854029 15394 net.cpp:190] Creating Layer ReLU4
I0525 23:46:16.854034 15394 net.cpp:605] ReLU4 <- Convolution4
I0525 23:46:16.854043 15394 net.cpp:566] ReLU4 -> Convolution4 (in-place)
I0525 23:46:16.854049 15394 net.cpp:240] Setting up ReLU4
I0525 23:46:16.854054 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.854058 15394 net.cpp:255] Memory required for data: 177734144
I0525 23:46:16.854061 15394 layer_factory.hpp:77] Creating layer Convolution5
I0525 23:46:16.854074 15394 net.cpp:190] Creating Layer Convolution5
I0525 23:46:16.854077 15394 net.cpp:605] Convolution5 <- Convolution4
I0525 23:46:16.854084 15394 net.cpp:579] Convolution5 -> Convolution5
I0525 23:46:16.854383 15394 net.cpp:240] Setting up Convolution5
I0525 23:46:16.854394 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.854398 15394 net.cpp:255] Memory required for data: 186122752
I0525 23:46:16.854405 15394 layer_factory.hpp:77] Creating layer BatchNorm5
I0525 23:46:16.854415 15394 net.cpp:190] Creating Layer BatchNorm5
I0525 23:46:16.854419 15394 net.cpp:605] BatchNorm5 <- Convolution5
I0525 23:46:16.854428 15394 net.cpp:566] BatchNorm5 -> Convolution5 (in-place)
I0525 23:46:16.854600 15394 net.cpp:240] Setting up BatchNorm5
I0525 23:46:16.854609 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.854612 15394 net.cpp:255] Memory required for data: 194511360
I0525 23:46:16.854634 15394 layer_factory.hpp:77] Creating layer Scale5
I0525 23:46:16.854643 15394 net.cpp:190] Creating Layer Scale5
I0525 23:46:16.854647 15394 net.cpp:605] Scale5 <- Convolution5
I0525 23:46:16.854653 15394 net.cpp:566] Scale5 -> Convolution5 (in-place)
I0525 23:46:16.854693 15394 layer_factory.hpp:77] Creating layer Scale5
I0525 23:46:16.854801 15394 net.cpp:240] Setting up Scale5
I0525 23:46:16.854809 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.854812 15394 net.cpp:255] Memory required for data: 202899968
I0525 23:46:16.854821 15394 layer_factory.hpp:77] Creating layer Eltwise2
I0525 23:46:16.854831 15394 net.cpp:190] Creating Layer Eltwise2
I0525 23:46:16.854837 15394 net.cpp:605] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0525 23:46:16.854842 15394 net.cpp:605] Eltwise2 <- Convolution5
I0525 23:46:16.854847 15394 net.cpp:579] Eltwise2 -> Eltwise2
I0525 23:46:16.854872 15394 net.cpp:240] Setting up Eltwise2
I0525 23:46:16.854879 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.854882 15394 net.cpp:255] Memory required for data: 211288576
I0525 23:46:16.854885 15394 layer_factory.hpp:77] Creating layer ReLU5
I0525 23:46:16.854894 15394 net.cpp:190] Creating Layer ReLU5
I0525 23:46:16.854898 15394 net.cpp:605] ReLU5 <- Eltwise2
I0525 23:46:16.854904 15394 net.cpp:566] ReLU5 -> Eltwise2 (in-place)
I0525 23:46:16.854910 15394 net.cpp:240] Setting up ReLU5
I0525 23:46:16.854915 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.854919 15394 net.cpp:255] Memory required for data: 219677184
I0525 23:46:16.854923 15394 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0525 23:46:16.854929 15394 net.cpp:190] Creating Layer Eltwise2_ReLU5_0_split
I0525 23:46:16.854933 15394 net.cpp:605] Eltwise2_ReLU5_0_split <- Eltwise2
I0525 23:46:16.854938 15394 net.cpp:579] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0525 23:46:16.854944 15394 net.cpp:579] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0525 23:46:16.854980 15394 net.cpp:240] Setting up Eltwise2_ReLU5_0_split
I0525 23:46:16.854987 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.854992 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.854995 15394 net.cpp:255] Memory required for data: 236454400
I0525 23:46:16.855006 15394 layer_factory.hpp:77] Creating layer Convolution6
I0525 23:46:16.855020 15394 net.cpp:190] Creating Layer Convolution6
I0525 23:46:16.855024 15394 net.cpp:605] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0525 23:46:16.855031 15394 net.cpp:579] Convolution6 -> Convolution6
I0525 23:46:16.855330 15394 net.cpp:240] Setting up Convolution6
I0525 23:46:16.855340 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.855345 15394 net.cpp:255] Memory required for data: 244843008
I0525 23:46:16.855353 15394 layer_factory.hpp:77] Creating layer BatchNorm6
I0525 23:46:16.855363 15394 net.cpp:190] Creating Layer BatchNorm6
I0525 23:46:16.855367 15394 net.cpp:605] BatchNorm6 <- Convolution6
I0525 23:46:16.855372 15394 net.cpp:566] BatchNorm6 -> Convolution6 (in-place)
I0525 23:46:16.858409 15394 net.cpp:240] Setting up BatchNorm6
I0525 23:46:16.858463 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.858467 15394 net.cpp:255] Memory required for data: 253231616
I0525 23:46:16.858491 15394 layer_factory.hpp:77] Creating layer Scale6
I0525 23:46:16.858512 15394 net.cpp:190] Creating Layer Scale6
I0525 23:46:16.858520 15394 net.cpp:605] Scale6 <- Convolution6
I0525 23:46:16.858530 15394 net.cpp:566] Scale6 -> Convolution6 (in-place)
I0525 23:46:16.858621 15394 layer_factory.hpp:77] Creating layer Scale6
I0525 23:46:16.858755 15394 net.cpp:240] Setting up Scale6
I0525 23:46:16.858767 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.858770 15394 net.cpp:255] Memory required for data: 261620224
I0525 23:46:16.858780 15394 layer_factory.hpp:77] Creating layer ReLU6
I0525 23:46:16.858788 15394 net.cpp:190] Creating Layer ReLU6
I0525 23:46:16.858793 15394 net.cpp:605] ReLU6 <- Convolution6
I0525 23:46:16.858798 15394 net.cpp:566] ReLU6 -> Convolution6 (in-place)
I0525 23:46:16.858805 15394 net.cpp:240] Setting up ReLU6
I0525 23:46:16.858811 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.858814 15394 net.cpp:255] Memory required for data: 270008832
I0525 23:46:16.858817 15394 layer_factory.hpp:77] Creating layer Convolution7
I0525 23:46:16.858832 15394 net.cpp:190] Creating Layer Convolution7
I0525 23:46:16.858836 15394 net.cpp:605] Convolution7 <- Convolution6
I0525 23:46:16.858845 15394 net.cpp:579] Convolution7 -> Convolution7
I0525 23:46:16.859179 15394 net.cpp:240] Setting up Convolution7
I0525 23:46:16.859190 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.859194 15394 net.cpp:255] Memory required for data: 278397440
I0525 23:46:16.859203 15394 layer_factory.hpp:77] Creating layer BatchNorm7
I0525 23:46:16.859215 15394 net.cpp:190] Creating Layer BatchNorm7
I0525 23:46:16.859218 15394 net.cpp:605] BatchNorm7 <- Convolution7
I0525 23:46:16.859227 15394 net.cpp:566] BatchNorm7 -> Convolution7 (in-place)
I0525 23:46:16.859411 15394 net.cpp:240] Setting up BatchNorm7
I0525 23:46:16.859421 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.859423 15394 net.cpp:255] Memory required for data: 286786048
I0525 23:46:16.859433 15394 layer_factory.hpp:77] Creating layer Scale7
I0525 23:46:16.859450 15394 net.cpp:190] Creating Layer Scale7
I0525 23:46:16.859455 15394 net.cpp:605] Scale7 <- Convolution7
I0525 23:46:16.859462 15394 net.cpp:566] Scale7 -> Convolution7 (in-place)
I0525 23:46:16.859506 15394 layer_factory.hpp:77] Creating layer Scale7
I0525 23:46:16.859624 15394 net.cpp:240] Setting up Scale7
I0525 23:46:16.859633 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.859637 15394 net.cpp:255] Memory required for data: 295174656
I0525 23:46:16.859645 15394 layer_factory.hpp:77] Creating layer Eltwise3
I0525 23:46:16.859657 15394 net.cpp:190] Creating Layer Eltwise3
I0525 23:46:16.859661 15394 net.cpp:605] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0525 23:46:16.859666 15394 net.cpp:605] Eltwise3 <- Convolution7
I0525 23:46:16.859673 15394 net.cpp:579] Eltwise3 -> Eltwise3
I0525 23:46:16.859701 15394 net.cpp:240] Setting up Eltwise3
I0525 23:46:16.859709 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.859722 15394 net.cpp:255] Memory required for data: 303563264
I0525 23:46:16.859727 15394 layer_factory.hpp:77] Creating layer ReLU7
I0525 23:46:16.859736 15394 net.cpp:190] Creating Layer ReLU7
I0525 23:46:16.859740 15394 net.cpp:605] ReLU7 <- Eltwise3
I0525 23:46:16.859748 15394 net.cpp:566] ReLU7 -> Eltwise3 (in-place)
I0525 23:46:16.859756 15394 net.cpp:240] Setting up ReLU7
I0525 23:46:16.859761 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.859766 15394 net.cpp:255] Memory required for data: 311951872
I0525 23:46:16.859768 15394 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0525 23:46:16.859776 15394 net.cpp:190] Creating Layer Eltwise3_ReLU7_0_split
I0525 23:46:16.859781 15394 net.cpp:605] Eltwise3_ReLU7_0_split <- Eltwise3
I0525 23:46:16.859786 15394 net.cpp:579] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0525 23:46:16.859792 15394 net.cpp:579] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0525 23:46:16.859828 15394 net.cpp:240] Setting up Eltwise3_ReLU7_0_split
I0525 23:46:16.859835 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.859839 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.859843 15394 net.cpp:255] Memory required for data: 328729088
I0525 23:46:16.859846 15394 layer_factory.hpp:77] Creating layer Convolution8
I0525 23:46:16.859856 15394 net.cpp:190] Creating Layer Convolution8
I0525 23:46:16.859861 15394 net.cpp:605] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0525 23:46:16.859869 15394 net.cpp:579] Convolution8 -> Convolution8
I0525 23:46:16.860180 15394 net.cpp:240] Setting up Convolution8
I0525 23:46:16.860191 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.860195 15394 net.cpp:255] Memory required for data: 337117696
I0525 23:46:16.860205 15394 layer_factory.hpp:77] Creating layer BatchNorm8
I0525 23:46:16.860214 15394 net.cpp:190] Creating Layer BatchNorm8
I0525 23:46:16.860219 15394 net.cpp:605] BatchNorm8 <- Convolution8
I0525 23:46:16.860226 15394 net.cpp:566] BatchNorm8 -> Convolution8 (in-place)
I0525 23:46:16.860412 15394 net.cpp:240] Setting up BatchNorm8
I0525 23:46:16.860421 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.860424 15394 net.cpp:255] Memory required for data: 345506304
I0525 23:46:16.860435 15394 layer_factory.hpp:77] Creating layer Scale8
I0525 23:46:16.860443 15394 net.cpp:190] Creating Layer Scale8
I0525 23:46:16.860447 15394 net.cpp:605] Scale8 <- Convolution8
I0525 23:46:16.860453 15394 net.cpp:566] Scale8 -> Convolution8 (in-place)
I0525 23:46:16.860492 15394 layer_factory.hpp:77] Creating layer Scale8
I0525 23:46:16.860608 15394 net.cpp:240] Setting up Scale8
I0525 23:46:16.860618 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.860621 15394 net.cpp:255] Memory required for data: 353894912
I0525 23:46:16.860630 15394 layer_factory.hpp:77] Creating layer ReLU8
I0525 23:46:16.860638 15394 net.cpp:190] Creating Layer ReLU8
I0525 23:46:16.860642 15394 net.cpp:605] ReLU8 <- Convolution8
I0525 23:46:16.860651 15394 net.cpp:566] ReLU8 -> Convolution8 (in-place)
I0525 23:46:16.860657 15394 net.cpp:240] Setting up ReLU8
I0525 23:46:16.860662 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.860666 15394 net.cpp:255] Memory required for data: 362283520
I0525 23:46:16.860669 15394 layer_factory.hpp:77] Creating layer Convolution9
I0525 23:46:16.860679 15394 net.cpp:190] Creating Layer Convolution9
I0525 23:46:16.860683 15394 net.cpp:605] Convolution9 <- Convolution8
I0525 23:46:16.860694 15394 net.cpp:579] Convolution9 -> Convolution9
I0525 23:46:16.861021 15394 net.cpp:240] Setting up Convolution9
I0525 23:46:16.861032 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.861035 15394 net.cpp:255] Memory required for data: 370672128
I0525 23:46:16.861045 15394 layer_factory.hpp:77] Creating layer BatchNorm9
I0525 23:46:16.861054 15394 net.cpp:190] Creating Layer BatchNorm9
I0525 23:46:16.861058 15394 net.cpp:605] BatchNorm9 <- Convolution9
I0525 23:46:16.866425 15394 net.cpp:566] BatchNorm9 -> Convolution9 (in-place)
I0525 23:46:16.870573 15394 net.cpp:240] Setting up BatchNorm9
I0525 23:46:16.870611 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.870615 15394 net.cpp:255] Memory required for data: 379060736
I0525 23:46:16.870638 15394 layer_factory.hpp:77] Creating layer Scale9
I0525 23:46:16.870656 15394 net.cpp:190] Creating Layer Scale9
I0525 23:46:16.870663 15394 net.cpp:605] Scale9 <- Convolution9
I0525 23:46:16.870676 15394 net.cpp:566] Scale9 -> Convolution9 (in-place)
I0525 23:46:16.870728 15394 layer_factory.hpp:77] Creating layer Scale9
I0525 23:46:16.870852 15394 net.cpp:240] Setting up Scale9
I0525 23:46:16.870860 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.870864 15394 net.cpp:255] Memory required for data: 387449344
I0525 23:46:16.870875 15394 layer_factory.hpp:77] Creating layer Eltwise4
I0525 23:46:16.870887 15394 net.cpp:190] Creating Layer Eltwise4
I0525 23:46:16.870893 15394 net.cpp:605] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0525 23:46:16.870898 15394 net.cpp:605] Eltwise4 <- Convolution9
I0525 23:46:16.870905 15394 net.cpp:579] Eltwise4 -> Eltwise4
I0525 23:46:16.870957 15394 net.cpp:240] Setting up Eltwise4
I0525 23:46:16.870968 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.870971 15394 net.cpp:255] Memory required for data: 395837952
I0525 23:46:16.870975 15394 layer_factory.hpp:77] Creating layer ReLU9
I0525 23:46:16.870983 15394 net.cpp:190] Creating Layer ReLU9
I0525 23:46:16.870987 15394 net.cpp:605] ReLU9 <- Eltwise4
I0525 23:46:16.870995 15394 net.cpp:566] ReLU9 -> Eltwise4 (in-place)
I0525 23:46:16.871003 15394 net.cpp:240] Setting up ReLU9
I0525 23:46:16.871008 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.871012 15394 net.cpp:255] Memory required for data: 404226560
I0525 23:46:16.871016 15394 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0525 23:46:16.871022 15394 net.cpp:190] Creating Layer Eltwise4_ReLU9_0_split
I0525 23:46:16.871026 15394 net.cpp:605] Eltwise4_ReLU9_0_split <- Eltwise4
I0525 23:46:16.871032 15394 net.cpp:579] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0525 23:46:16.871038 15394 net.cpp:579] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0525 23:46:16.871085 15394 net.cpp:240] Setting up Eltwise4_ReLU9_0_split
I0525 23:46:16.871093 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.871098 15394 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0525 23:46:16.871101 15394 net.cpp:255] Memory required for data: 421003776
I0525 23:46:16.871105 15394 layer_factory.hpp:77] Creating layer Pooling1
I0525 23:46:16.871114 15394 net.cpp:190] Creating Layer Pooling1
I0525 23:46:16.871119 15394 net.cpp:605] Pooling1 <- Eltwise4_ReLU9_0_split_0
I0525 23:46:16.871129 15394 net.cpp:579] Pooling1 -> Pooling1
I0525 23:46:16.871173 15394 net.cpp:240] Setting up Pooling1
I0525 23:46:16.871181 15394 net.cpp:247] Top shape: 128 16 16 16 (524288)
I0525 23:46:16.871183 15394 net.cpp:255] Memory required for data: 423100928
I0525 23:46:16.871187 15394 layer_factory.hpp:77] Creating layer Input1
I0525 23:46:16.871198 15394 net.cpp:190] Creating Layer Input1
I0525 23:46:16.871206 15394 net.cpp:579] Input1 -> Input1
I0525 23:46:16.871239 15394 net.cpp:240] Setting up Input1
I0525 23:46:16.871248 15394 net.cpp:247] Top shape: 128 16 16 16 (524288)
I0525 23:46:16.871251 15394 net.cpp:255] Memory required for data: 425198080
I0525 23:46:16.871254 15394 layer_factory.hpp:77] Creating layer Concat1
I0525 23:46:16.871263 15394 net.cpp:190] Creating Layer Concat1
I0525 23:46:16.871268 15394 net.cpp:605] Concat1 <- Pooling1
I0525 23:46:16.871273 15394 net.cpp:605] Concat1 <- Input1
I0525 23:46:16.871279 15394 net.cpp:579] Concat1 -> Concat1
I0525 23:46:16.871311 15394 net.cpp:240] Setting up Concat1
I0525 23:46:16.871318 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.871322 15394 net.cpp:255] Memory required for data: 429392384
I0525 23:46:16.871326 15394 layer_factory.hpp:77] Creating layer Convolution10
I0525 23:46:16.871351 15394 net.cpp:190] Creating Layer Convolution10
I0525 23:46:16.871357 15394 net.cpp:605] Convolution10 <- Eltwise4_ReLU9_0_split_1
I0525 23:46:16.871366 15394 net.cpp:579] Convolution10 -> Convolution10
I0525 23:46:16.872642 15394 net.cpp:240] Setting up Convolution10
I0525 23:46:16.872680 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.872684 15394 net.cpp:255] Memory required for data: 433586688
I0525 23:46:16.872720 15394 layer_factory.hpp:77] Creating layer BatchNorm10
I0525 23:46:16.872736 15394 net.cpp:190] Creating Layer BatchNorm10
I0525 23:46:16.872743 15394 net.cpp:605] BatchNorm10 <- Convolution10
I0525 23:46:16.872753 15394 net.cpp:566] BatchNorm10 -> Convolution10 (in-place)
I0525 23:46:16.872938 15394 net.cpp:240] Setting up BatchNorm10
I0525 23:46:16.872951 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.872954 15394 net.cpp:255] Memory required for data: 437780992
I0525 23:46:16.872966 15394 layer_factory.hpp:77] Creating layer Scale10
I0525 23:46:16.872975 15394 net.cpp:190] Creating Layer Scale10
I0525 23:46:16.872979 15394 net.cpp:605] Scale10 <- Convolution10
I0525 23:46:16.872990 15394 net.cpp:566] Scale10 -> Convolution10 (in-place)
I0525 23:46:16.873028 15394 layer_factory.hpp:77] Creating layer Scale10
I0525 23:46:16.873143 15394 net.cpp:240] Setting up Scale10
I0525 23:46:16.873153 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.873157 15394 net.cpp:255] Memory required for data: 441975296
I0525 23:46:16.873168 15394 layer_factory.hpp:77] Creating layer ReLU10
I0525 23:46:16.873175 15394 net.cpp:190] Creating Layer ReLU10
I0525 23:46:16.873180 15394 net.cpp:605] ReLU10 <- Convolution10
I0525 23:46:16.873186 15394 net.cpp:566] ReLU10 -> Convolution10 (in-place)
I0525 23:46:16.873193 15394 net.cpp:240] Setting up ReLU10
I0525 23:46:16.873198 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.873203 15394 net.cpp:255] Memory required for data: 446169600
I0525 23:46:16.873205 15394 layer_factory.hpp:77] Creating layer Convolution11
I0525 23:46:16.873220 15394 net.cpp:190] Creating Layer Convolution11
I0525 23:46:16.873224 15394 net.cpp:605] Convolution11 <- Convolution10
I0525 23:46:16.873234 15394 net.cpp:579] Convolution11 -> Convolution11
I0525 23:46:16.873800 15394 net.cpp:240] Setting up Convolution11
I0525 23:46:16.873813 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.873817 15394 net.cpp:255] Memory required for data: 450363904
I0525 23:46:16.873826 15394 layer_factory.hpp:77] Creating layer BatchNorm11
I0525 23:46:16.873838 15394 net.cpp:190] Creating Layer BatchNorm11
I0525 23:46:16.873843 15394 net.cpp:605] BatchNorm11 <- Convolution11
I0525 23:46:16.873857 15394 net.cpp:566] BatchNorm11 -> Convolution11 (in-place)
I0525 23:46:16.874033 15394 net.cpp:240] Setting up BatchNorm11
I0525 23:46:16.874042 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.874045 15394 net.cpp:255] Memory required for data: 454558208
I0525 23:46:16.874056 15394 layer_factory.hpp:77] Creating layer Scale11
I0525 23:46:16.874066 15394 net.cpp:190] Creating Layer Scale11
I0525 23:46:16.874070 15394 net.cpp:605] Scale11 <- Convolution11
I0525 23:46:16.874078 15394 net.cpp:566] Scale11 -> Convolution11 (in-place)
I0525 23:46:16.874114 15394 layer_factory.hpp:77] Creating layer Scale11
I0525 23:46:16.874227 15394 net.cpp:240] Setting up Scale11
I0525 23:46:16.874234 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.874238 15394 net.cpp:255] Memory required for data: 458752512
I0525 23:46:16.874246 15394 layer_factory.hpp:77] Creating layer Eltwise5
I0525 23:46:16.874255 15394 net.cpp:190] Creating Layer Eltwise5
I0525 23:46:16.874260 15394 net.cpp:605] Eltwise5 <- Concat1
I0525 23:46:16.874265 15394 net.cpp:605] Eltwise5 <- Convolution11
I0525 23:46:16.874275 15394 net.cpp:579] Eltwise5 -> Eltwise5
I0525 23:46:16.874297 15394 net.cpp:240] Setting up Eltwise5
I0525 23:46:16.874305 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.874308 15394 net.cpp:255] Memory required for data: 462946816
I0525 23:46:16.874320 15394 layer_factory.hpp:77] Creating layer ReLU11
I0525 23:46:16.874331 15394 net.cpp:190] Creating Layer ReLU11
I0525 23:46:16.874336 15394 net.cpp:605] ReLU11 <- Eltwise5
I0525 23:46:16.874341 15394 net.cpp:566] ReLU11 -> Eltwise5 (in-place)
I0525 23:46:16.874349 15394 net.cpp:240] Setting up ReLU11
I0525 23:46:16.874363 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.874367 15394 net.cpp:255] Memory required for data: 467141120
I0525 23:46:16.874372 15394 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0525 23:46:16.874378 15394 net.cpp:190] Creating Layer Eltwise5_ReLU11_0_split
I0525 23:46:16.874382 15394 net.cpp:605] Eltwise5_ReLU11_0_split <- Eltwise5
I0525 23:46:16.874387 15394 net.cpp:579] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0525 23:46:16.874398 15394 net.cpp:579] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0525 23:46:16.874439 15394 net.cpp:240] Setting up Eltwise5_ReLU11_0_split
I0525 23:46:16.874446 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.874455 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.874459 15394 net.cpp:255] Memory required for data: 475529728
I0525 23:46:16.874462 15394 layer_factory.hpp:77] Creating layer Convolution12
I0525 23:46:16.874474 15394 net.cpp:190] Creating Layer Convolution12
I0525 23:46:16.874477 15394 net.cpp:605] Convolution12 <- Eltwise5_ReLU11_0_split_0
I0525 23:46:16.874485 15394 net.cpp:579] Convolution12 -> Convolution12
I0525 23:46:16.875022 15394 net.cpp:240] Setting up Convolution12
I0525 23:46:16.875036 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.875039 15394 net.cpp:255] Memory required for data: 479724032
I0525 23:46:16.875049 15394 layer_factory.hpp:77] Creating layer BatchNorm12
I0525 23:46:16.875059 15394 net.cpp:190] Creating Layer BatchNorm12
I0525 23:46:16.875064 15394 net.cpp:605] BatchNorm12 <- Convolution12
I0525 23:46:16.875071 15394 net.cpp:566] BatchNorm12 -> Convolution12 (in-place)
I0525 23:46:16.875248 15394 net.cpp:240] Setting up BatchNorm12
I0525 23:46:16.875257 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.875262 15394 net.cpp:255] Memory required for data: 483918336
I0525 23:46:16.875272 15394 layer_factory.hpp:77] Creating layer Scale12
I0525 23:46:16.875280 15394 net.cpp:190] Creating Layer Scale12
I0525 23:46:16.875284 15394 net.cpp:605] Scale12 <- Convolution12
I0525 23:46:16.875290 15394 net.cpp:566] Scale12 -> Convolution12 (in-place)
I0525 23:46:16.875334 15394 layer_factory.hpp:77] Creating layer Scale12
I0525 23:46:16.878415 15394 net.cpp:240] Setting up Scale12
I0525 23:46:16.878463 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.878468 15394 net.cpp:255] Memory required for data: 488112640
I0525 23:46:16.878494 15394 layer_factory.hpp:77] Creating layer ReLU12
I0525 23:46:16.878512 15394 net.cpp:190] Creating Layer ReLU12
I0525 23:46:16.878520 15394 net.cpp:605] ReLU12 <- Convolution12
I0525 23:46:16.878532 15394 net.cpp:566] ReLU12 -> Convolution12 (in-place)
I0525 23:46:16.878546 15394 net.cpp:240] Setting up ReLU12
I0525 23:46:16.878552 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.878556 15394 net.cpp:255] Memory required for data: 492306944
I0525 23:46:16.878559 15394 layer_factory.hpp:77] Creating layer Convolution13
I0525 23:46:16.878573 15394 net.cpp:190] Creating Layer Convolution13
I0525 23:46:16.878578 15394 net.cpp:605] Convolution13 <- Convolution12
I0525 23:46:16.878587 15394 net.cpp:579] Convolution13 -> Convolution13
I0525 23:46:16.879228 15394 net.cpp:240] Setting up Convolution13
I0525 23:46:16.879251 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.879253 15394 net.cpp:255] Memory required for data: 496501248
I0525 23:46:16.879268 15394 layer_factory.hpp:77] Creating layer BatchNorm13
I0525 23:46:16.879297 15394 net.cpp:190] Creating Layer BatchNorm13
I0525 23:46:16.879304 15394 net.cpp:605] BatchNorm13 <- Convolution13
I0525 23:46:16.879314 15394 net.cpp:566] BatchNorm13 -> Convolution13 (in-place)
I0525 23:46:16.879523 15394 net.cpp:240] Setting up BatchNorm13
I0525 23:46:16.879534 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.879539 15394 net.cpp:255] Memory required for data: 500695552
I0525 23:46:16.879551 15394 layer_factory.hpp:77] Creating layer Scale13
I0525 23:46:16.879562 15394 net.cpp:190] Creating Layer Scale13
I0525 23:46:16.879566 15394 net.cpp:605] Scale13 <- Convolution13
I0525 23:46:16.879576 15394 net.cpp:566] Scale13 -> Convolution13 (in-place)
I0525 23:46:16.879618 15394 layer_factory.hpp:77] Creating layer Scale13
I0525 23:46:16.879735 15394 net.cpp:240] Setting up Scale13
I0525 23:46:16.879745 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.879748 15394 net.cpp:255] Memory required for data: 504889856
I0525 23:46:16.879757 15394 layer_factory.hpp:77] Creating layer Eltwise6
I0525 23:46:16.879766 15394 net.cpp:190] Creating Layer Eltwise6
I0525 23:46:16.879771 15394 net.cpp:605] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0525 23:46:16.879776 15394 net.cpp:605] Eltwise6 <- Convolution13
I0525 23:46:16.879791 15394 net.cpp:579] Eltwise6 -> Eltwise6
I0525 23:46:16.879814 15394 net.cpp:240] Setting up Eltwise6
I0525 23:46:16.879822 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.879824 15394 net.cpp:255] Memory required for data: 509084160
I0525 23:46:16.879828 15394 layer_factory.hpp:77] Creating layer ReLU13
I0525 23:46:16.879837 15394 net.cpp:190] Creating Layer ReLU13
I0525 23:46:16.879842 15394 net.cpp:605] ReLU13 <- Eltwise6
I0525 23:46:16.879848 15394 net.cpp:566] ReLU13 -> Eltwise6 (in-place)
I0525 23:46:16.879853 15394 net.cpp:240] Setting up ReLU13
I0525 23:46:16.879858 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.879861 15394 net.cpp:255] Memory required for data: 513278464
I0525 23:46:16.879865 15394 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0525 23:46:16.879873 15394 net.cpp:190] Creating Layer Eltwise6_ReLU13_0_split
I0525 23:46:16.879876 15394 net.cpp:605] Eltwise6_ReLU13_0_split <- Eltwise6
I0525 23:46:16.879881 15394 net.cpp:579] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0525 23:46:16.879890 15394 net.cpp:579] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0525 23:46:16.879925 15394 net.cpp:240] Setting up Eltwise6_ReLU13_0_split
I0525 23:46:16.879931 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.879936 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.879940 15394 net.cpp:255] Memory required for data: 521667072
I0525 23:46:16.879943 15394 layer_factory.hpp:77] Creating layer Convolution14
I0525 23:46:16.879957 15394 net.cpp:190] Creating Layer Convolution14
I0525 23:46:16.879962 15394 net.cpp:605] Convolution14 <- Eltwise6_ReLU13_0_split_0
I0525 23:46:16.879969 15394 net.cpp:579] Convolution14 -> Convolution14
I0525 23:46:16.880523 15394 net.cpp:240] Setting up Convolution14
I0525 23:46:16.880538 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.880542 15394 net.cpp:255] Memory required for data: 525861376
I0525 23:46:16.880553 15394 layer_factory.hpp:77] Creating layer BatchNorm14
I0525 23:46:16.880566 15394 net.cpp:190] Creating Layer BatchNorm14
I0525 23:46:16.880570 15394 net.cpp:605] BatchNorm14 <- Convolution14
I0525 23:46:16.880578 15394 net.cpp:566] BatchNorm14 -> Convolution14 (in-place)
I0525 23:46:16.880786 15394 net.cpp:240] Setting up BatchNorm14
I0525 23:46:16.880797 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.880800 15394 net.cpp:255] Memory required for data: 530055680
I0525 23:46:16.880812 15394 layer_factory.hpp:77] Creating layer Scale14
I0525 23:46:16.880825 15394 net.cpp:190] Creating Layer Scale14
I0525 23:46:16.880830 15394 net.cpp:605] Scale14 <- Convolution14
I0525 23:46:16.880834 15394 net.cpp:566] Scale14 -> Convolution14 (in-place)
I0525 23:46:16.880875 15394 layer_factory.hpp:77] Creating layer Scale14
I0525 23:46:16.880996 15394 net.cpp:240] Setting up Scale14
I0525 23:46:16.881005 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.881016 15394 net.cpp:255] Memory required for data: 534249984
I0525 23:46:16.881026 15394 layer_factory.hpp:77] Creating layer ReLU14
I0525 23:46:16.881036 15394 net.cpp:190] Creating Layer ReLU14
I0525 23:46:16.881041 15394 net.cpp:605] ReLU14 <- Convolution14
I0525 23:46:16.881047 15394 net.cpp:566] ReLU14 -> Convolution14 (in-place)
I0525 23:46:16.881053 15394 net.cpp:240] Setting up ReLU14
I0525 23:46:16.881058 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.881062 15394 net.cpp:255] Memory required for data: 538444288
I0525 23:46:16.881065 15394 layer_factory.hpp:77] Creating layer Convolution15
I0525 23:46:16.881078 15394 net.cpp:190] Creating Layer Convolution15
I0525 23:46:16.881083 15394 net.cpp:605] Convolution15 <- Convolution14
I0525 23:46:16.881088 15394 net.cpp:579] Convolution15 -> Convolution15
I0525 23:46:16.881628 15394 net.cpp:240] Setting up Convolution15
I0525 23:46:16.881644 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.881647 15394 net.cpp:255] Memory required for data: 542638592
I0525 23:46:16.881656 15394 layer_factory.hpp:77] Creating layer BatchNorm15
I0525 23:46:16.881667 15394 net.cpp:190] Creating Layer BatchNorm15
I0525 23:46:16.881674 15394 net.cpp:605] BatchNorm15 <- Convolution15
I0525 23:46:16.881680 15394 net.cpp:566] BatchNorm15 -> Convolution15 (in-place)
I0525 23:46:16.881860 15394 net.cpp:240] Setting up BatchNorm15
I0525 23:46:16.881868 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.881872 15394 net.cpp:255] Memory required for data: 546832896
I0525 23:46:16.881886 15394 layer_factory.hpp:77] Creating layer Scale15
I0525 23:46:16.881894 15394 net.cpp:190] Creating Layer Scale15
I0525 23:46:16.881899 15394 net.cpp:605] Scale15 <- Convolution15
I0525 23:46:16.881904 15394 net.cpp:566] Scale15 -> Convolution15 (in-place)
I0525 23:46:16.881943 15394 layer_factory.hpp:77] Creating layer Scale15
I0525 23:46:16.882061 15394 net.cpp:240] Setting up Scale15
I0525 23:46:16.882069 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.882073 15394 net.cpp:255] Memory required for data: 551027200
I0525 23:46:16.882084 15394 layer_factory.hpp:77] Creating layer Eltwise7
I0525 23:46:16.882093 15394 net.cpp:190] Creating Layer Eltwise7
I0525 23:46:16.882099 15394 net.cpp:605] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0525 23:46:16.882105 15394 net.cpp:605] Eltwise7 <- Convolution15
I0525 23:46:16.882113 15394 net.cpp:579] Eltwise7 -> Eltwise7
I0525 23:46:16.882138 15394 net.cpp:240] Setting up Eltwise7
I0525 23:46:16.882144 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.882148 15394 net.cpp:255] Memory required for data: 555221504
I0525 23:46:16.882151 15394 layer_factory.hpp:77] Creating layer ReLU15
I0525 23:46:16.882158 15394 net.cpp:190] Creating Layer ReLU15
I0525 23:46:16.882163 15394 net.cpp:605] ReLU15 <- Eltwise7
I0525 23:46:16.882170 15394 net.cpp:566] ReLU15 -> Eltwise7 (in-place)
I0525 23:46:16.882177 15394 net.cpp:240] Setting up ReLU15
I0525 23:46:16.882182 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.882186 15394 net.cpp:255] Memory required for data: 559415808
I0525 23:46:16.882189 15394 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0525 23:46:16.882196 15394 net.cpp:190] Creating Layer Eltwise7_ReLU15_0_split
I0525 23:46:16.882200 15394 net.cpp:605] Eltwise7_ReLU15_0_split <- Eltwise7
I0525 23:46:16.882205 15394 net.cpp:579] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0525 23:46:16.882212 15394 net.cpp:579] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0525 23:46:16.882248 15394 net.cpp:240] Setting up Eltwise7_ReLU15_0_split
I0525 23:46:16.882256 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.882261 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.882264 15394 net.cpp:255] Memory required for data: 567804416
I0525 23:46:16.882268 15394 layer_factory.hpp:77] Creating layer Convolution16
I0525 23:46:16.882278 15394 net.cpp:190] Creating Layer Convolution16
I0525 23:46:16.882290 15394 net.cpp:605] Convolution16 <- Eltwise7_ReLU15_0_split_0
I0525 23:46:16.882302 15394 net.cpp:579] Convolution16 -> Convolution16
I0525 23:46:16.886418 15394 net.cpp:240] Setting up Convolution16
I0525 23:46:16.886472 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.886476 15394 net.cpp:255] Memory required for data: 571998720
I0525 23:46:16.886499 15394 layer_factory.hpp:77] Creating layer BatchNorm16
I0525 23:46:16.886514 15394 net.cpp:190] Creating Layer BatchNorm16
I0525 23:46:16.886523 15394 net.cpp:605] BatchNorm16 <- Convolution16
I0525 23:46:16.886535 15394 net.cpp:566] BatchNorm16 -> Convolution16 (in-place)
I0525 23:46:16.886790 15394 net.cpp:240] Setting up BatchNorm16
I0525 23:46:16.886801 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.886806 15394 net.cpp:255] Memory required for data: 576193024
I0525 23:46:16.886817 15394 layer_factory.hpp:77] Creating layer Scale16
I0525 23:46:16.886828 15394 net.cpp:190] Creating Layer Scale16
I0525 23:46:16.886833 15394 net.cpp:605] Scale16 <- Convolution16
I0525 23:46:16.886840 15394 net.cpp:566] Scale16 -> Convolution16 (in-place)
I0525 23:46:16.886886 15394 layer_factory.hpp:77] Creating layer Scale16
I0525 23:46:16.887006 15394 net.cpp:240] Setting up Scale16
I0525 23:46:16.887017 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.887019 15394 net.cpp:255] Memory required for data: 580387328
I0525 23:46:16.887029 15394 layer_factory.hpp:77] Creating layer ReLU16
I0525 23:46:16.887039 15394 net.cpp:190] Creating Layer ReLU16
I0525 23:46:16.887045 15394 net.cpp:605] ReLU16 <- Convolution16
I0525 23:46:16.887051 15394 net.cpp:566] ReLU16 -> Convolution16 (in-place)
I0525 23:46:16.887059 15394 net.cpp:240] Setting up ReLU16
I0525 23:46:16.887064 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.887068 15394 net.cpp:255] Memory required for data: 584581632
I0525 23:46:16.887073 15394 layer_factory.hpp:77] Creating layer Convolution17
I0525 23:46:16.887086 15394 net.cpp:190] Creating Layer Convolution17
I0525 23:46:16.887090 15394 net.cpp:605] Convolution17 <- Convolution16
I0525 23:46:16.887099 15394 net.cpp:579] Convolution17 -> Convolution17
I0525 23:46:16.887673 15394 net.cpp:240] Setting up Convolution17
I0525 23:46:16.887688 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.887692 15394 net.cpp:255] Memory required for data: 588775936
I0525 23:46:16.887701 15394 layer_factory.hpp:77] Creating layer BatchNorm17
I0525 23:46:16.887712 15394 net.cpp:190] Creating Layer BatchNorm17
I0525 23:46:16.887717 15394 net.cpp:605] BatchNorm17 <- Convolution17
I0525 23:46:16.887724 15394 net.cpp:566] BatchNorm17 -> Convolution17 (in-place)
I0525 23:46:16.887922 15394 net.cpp:240] Setting up BatchNorm17
I0525 23:46:16.887931 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.887934 15394 net.cpp:255] Memory required for data: 592970240
I0525 23:46:16.887946 15394 layer_factory.hpp:77] Creating layer Scale17
I0525 23:46:16.887956 15394 net.cpp:190] Creating Layer Scale17
I0525 23:46:16.887960 15394 net.cpp:605] Scale17 <- Convolution17
I0525 23:46:16.887969 15394 net.cpp:566] Scale17 -> Convolution17 (in-place)
I0525 23:46:16.888005 15394 layer_factory.hpp:77] Creating layer Scale17
I0525 23:46:16.888118 15394 net.cpp:240] Setting up Scale17
I0525 23:46:16.888128 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.888133 15394 net.cpp:255] Memory required for data: 597164544
I0525 23:46:16.888141 15394 layer_factory.hpp:77] Creating layer Eltwise8
I0525 23:46:16.888150 15394 net.cpp:190] Creating Layer Eltwise8
I0525 23:46:16.888157 15394 net.cpp:605] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0525 23:46:16.888162 15394 net.cpp:605] Eltwise8 <- Convolution17
I0525 23:46:16.888170 15394 net.cpp:579] Eltwise8 -> Eltwise8
I0525 23:46:16.888206 15394 net.cpp:240] Setting up Eltwise8
I0525 23:46:16.888212 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.888216 15394 net.cpp:255] Memory required for data: 601358848
I0525 23:46:16.888228 15394 layer_factory.hpp:77] Creating layer ReLU17
I0525 23:46:16.888236 15394 net.cpp:190] Creating Layer ReLU17
I0525 23:46:16.888241 15394 net.cpp:605] ReLU17 <- Eltwise8
I0525 23:46:16.888248 15394 net.cpp:566] ReLU17 -> Eltwise8 (in-place)
I0525 23:46:16.888255 15394 net.cpp:240] Setting up ReLU17
I0525 23:46:16.888262 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.888264 15394 net.cpp:255] Memory required for data: 605553152
I0525 23:46:16.888268 15394 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0525 23:46:16.888274 15394 net.cpp:190] Creating Layer Eltwise8_ReLU17_0_split
I0525 23:46:16.888278 15394 net.cpp:605] Eltwise8_ReLU17_0_split <- Eltwise8
I0525 23:46:16.888283 15394 net.cpp:579] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0525 23:46:16.888290 15394 net.cpp:579] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0525 23:46:16.888329 15394 net.cpp:240] Setting up Eltwise8_ReLU17_0_split
I0525 23:46:16.888335 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.888339 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.888342 15394 net.cpp:255] Memory required for data: 613941760
I0525 23:46:16.888346 15394 layer_factory.hpp:77] Creating layer Convolution18
I0525 23:46:16.888360 15394 net.cpp:190] Creating Layer Convolution18
I0525 23:46:16.888365 15394 net.cpp:605] Convolution18 <- Eltwise8_ReLU17_0_split_0
I0525 23:46:16.888371 15394 net.cpp:579] Convolution18 -> Convolution18
I0525 23:46:16.888916 15394 net.cpp:240] Setting up Convolution18
I0525 23:46:16.888926 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.888931 15394 net.cpp:255] Memory required for data: 618136064
I0525 23:46:16.888942 15394 layer_factory.hpp:77] Creating layer BatchNorm18
I0525 23:46:16.888962 15394 net.cpp:190] Creating Layer BatchNorm18
I0525 23:46:16.888967 15394 net.cpp:605] BatchNorm18 <- Convolution18
I0525 23:46:16.888974 15394 net.cpp:566] BatchNorm18 -> Convolution18 (in-place)
I0525 23:46:16.889149 15394 net.cpp:240] Setting up BatchNorm18
I0525 23:46:16.889158 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.889163 15394 net.cpp:255] Memory required for data: 622330368
I0525 23:46:16.889173 15394 layer_factory.hpp:77] Creating layer Scale18
I0525 23:46:16.889186 15394 net.cpp:190] Creating Layer Scale18
I0525 23:46:16.889190 15394 net.cpp:605] Scale18 <- Convolution18
I0525 23:46:16.889196 15394 net.cpp:566] Scale18 -> Convolution18 (in-place)
I0525 23:46:16.889235 15394 layer_factory.hpp:77] Creating layer Scale18
I0525 23:46:16.889351 15394 net.cpp:240] Setting up Scale18
I0525 23:46:16.889360 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.889364 15394 net.cpp:255] Memory required for data: 626524672
I0525 23:46:16.889372 15394 layer_factory.hpp:77] Creating layer ReLU18
I0525 23:46:16.889379 15394 net.cpp:190] Creating Layer ReLU18
I0525 23:46:16.889384 15394 net.cpp:605] ReLU18 <- Convolution18
I0525 23:46:16.889391 15394 net.cpp:566] ReLU18 -> Convolution18 (in-place)
I0525 23:46:16.889400 15394 net.cpp:240] Setting up ReLU18
I0525 23:46:16.889405 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.889407 15394 net.cpp:255] Memory required for data: 630718976
I0525 23:46:16.889411 15394 layer_factory.hpp:77] Creating layer Convolution19
I0525 23:46:16.889423 15394 net.cpp:190] Creating Layer Convolution19
I0525 23:46:16.889428 15394 net.cpp:605] Convolution19 <- Convolution18
I0525 23:46:16.889435 15394 net.cpp:579] Convolution19 -> Convolution19
I0525 23:46:16.889969 15394 net.cpp:240] Setting up Convolution19
I0525 23:46:16.889982 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.889986 15394 net.cpp:255] Memory required for data: 634913280
I0525 23:46:16.889994 15394 layer_factory.hpp:77] Creating layer BatchNorm19
I0525 23:46:16.890005 15394 net.cpp:190] Creating Layer BatchNorm19
I0525 23:46:16.890009 15394 net.cpp:605] BatchNorm19 <- Convolution19
I0525 23:46:16.890015 15394 net.cpp:566] BatchNorm19 -> Convolution19 (in-place)
I0525 23:46:16.890213 15394 net.cpp:240] Setting up BatchNorm19
I0525 23:46:16.890224 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.890228 15394 net.cpp:255] Memory required for data: 639107584
I0525 23:46:16.890269 15394 layer_factory.hpp:77] Creating layer Scale19
I0525 23:46:16.890288 15394 net.cpp:190] Creating Layer Scale19
I0525 23:46:16.890293 15394 net.cpp:605] Scale19 <- Convolution19
I0525 23:46:16.890300 15394 net.cpp:566] Scale19 -> Convolution19 (in-place)
I0525 23:46:16.890339 15394 layer_factory.hpp:77] Creating layer Scale19
I0525 23:46:16.890475 15394 net.cpp:240] Setting up Scale19
I0525 23:46:16.890485 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.890488 15394 net.cpp:255] Memory required for data: 643301888
I0525 23:46:16.890496 15394 layer_factory.hpp:77] Creating layer Eltwise9
I0525 23:46:16.890506 15394 net.cpp:190] Creating Layer Eltwise9
I0525 23:46:16.890511 15394 net.cpp:605] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0525 23:46:16.890516 15394 net.cpp:605] Eltwise9 <- Convolution19
I0525 23:46:16.890522 15394 net.cpp:579] Eltwise9 -> Eltwise9
I0525 23:46:16.890547 15394 net.cpp:240] Setting up Eltwise9
I0525 23:46:16.890555 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.890558 15394 net.cpp:255] Memory required for data: 647496192
I0525 23:46:16.890563 15394 layer_factory.hpp:77] Creating layer ReLU19
I0525 23:46:16.890569 15394 net.cpp:190] Creating Layer ReLU19
I0525 23:46:16.890575 15394 net.cpp:605] ReLU19 <- Eltwise9
I0525 23:46:16.890580 15394 net.cpp:566] ReLU19 -> Eltwise9 (in-place)
I0525 23:46:16.890588 15394 net.cpp:240] Setting up ReLU19
I0525 23:46:16.890593 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.890596 15394 net.cpp:255] Memory required for data: 651690496
I0525 23:46:16.890600 15394 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0525 23:46:16.890609 15394 net.cpp:190] Creating Layer Eltwise9_ReLU19_0_split
I0525 23:46:16.890612 15394 net.cpp:605] Eltwise9_ReLU19_0_split <- Eltwise9
I0525 23:46:16.890617 15394 net.cpp:579] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0525 23:46:16.890626 15394 net.cpp:579] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0525 23:46:16.890666 15394 net.cpp:240] Setting up Eltwise9_ReLU19_0_split
I0525 23:46:16.890673 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.890678 15394 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0525 23:46:16.890681 15394 net.cpp:255] Memory required for data: 660079104
I0525 23:46:16.890684 15394 layer_factory.hpp:77] Creating layer Pooling2
I0525 23:46:16.890696 15394 net.cpp:190] Creating Layer Pooling2
I0525 23:46:16.890700 15394 net.cpp:605] Pooling2 <- Eltwise9_ReLU19_0_split_0
I0525 23:46:16.890707 15394 net.cpp:579] Pooling2 -> Pooling2
I0525 23:46:16.890730 15394 net.cpp:240] Setting up Pooling2
I0525 23:46:16.890738 15394 net.cpp:247] Top shape: 128 32 8 8 (262144)
I0525 23:46:16.890740 15394 net.cpp:255] Memory required for data: 661127680
I0525 23:46:16.890744 15394 layer_factory.hpp:77] Creating layer Input2
I0525 23:46:16.890754 15394 net.cpp:190] Creating Layer Input2
I0525 23:46:16.890763 15394 net.cpp:579] Input2 -> Input2
I0525 23:46:16.890791 15394 net.cpp:240] Setting up Input2
I0525 23:46:16.890797 15394 net.cpp:247] Top shape: 128 32 8 8 (262144)
I0525 23:46:16.890800 15394 net.cpp:255] Memory required for data: 662176256
I0525 23:46:16.890805 15394 layer_factory.hpp:77] Creating layer Concat2
I0525 23:46:16.890812 15394 net.cpp:190] Creating Layer Concat2
I0525 23:46:16.890816 15394 net.cpp:605] Concat2 <- Pooling2
I0525 23:46:16.890821 15394 net.cpp:605] Concat2 <- Input2
I0525 23:46:16.890828 15394 net.cpp:579] Concat2 -> Concat2
I0525 23:46:16.890856 15394 net.cpp:240] Setting up Concat2
I0525 23:46:16.890863 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.890866 15394 net.cpp:255] Memory required for data: 664273408
I0525 23:46:16.890871 15394 layer_factory.hpp:77] Creating layer Convolution20
I0525 23:46:16.890883 15394 net.cpp:190] Creating Layer Convolution20
I0525 23:46:16.890895 15394 net.cpp:605] Convolution20 <- Eltwise9_ReLU19_0_split_1
I0525 23:46:16.890907 15394 net.cpp:579] Convolution20 -> Convolution20
I0525 23:46:16.892737 15394 net.cpp:240] Setting up Convolution20
I0525 23:46:16.892789 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.892794 15394 net.cpp:255] Memory required for data: 666370560
I0525 23:46:16.892812 15394 layer_factory.hpp:77] Creating layer BatchNorm20
I0525 23:46:16.892830 15394 net.cpp:190] Creating Layer BatchNorm20
I0525 23:46:16.892840 15394 net.cpp:605] BatchNorm20 <- Convolution20
I0525 23:46:16.892849 15394 net.cpp:566] BatchNorm20 -> Convolution20 (in-place)
I0525 23:46:16.893085 15394 net.cpp:240] Setting up BatchNorm20
I0525 23:46:16.893098 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.893102 15394 net.cpp:255] Memory required for data: 668467712
I0525 23:46:16.893115 15394 layer_factory.hpp:77] Creating layer Scale20
I0525 23:46:16.893126 15394 net.cpp:190] Creating Layer Scale20
I0525 23:46:16.893131 15394 net.cpp:605] Scale20 <- Convolution20
I0525 23:46:16.893136 15394 net.cpp:566] Scale20 -> Convolution20 (in-place)
I0525 23:46:16.900354 15394 layer_factory.hpp:77] Creating layer Scale20
I0525 23:46:16.900626 15394 net.cpp:240] Setting up Scale20
I0525 23:46:16.900645 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.900648 15394 net.cpp:255] Memory required for data: 670564864
I0525 23:46:16.900666 15394 layer_factory.hpp:77] Creating layer ReLU20
I0525 23:46:16.900677 15394 net.cpp:190] Creating Layer ReLU20
I0525 23:46:16.900687 15394 net.cpp:605] ReLU20 <- Convolution20
I0525 23:46:16.900696 15394 net.cpp:566] ReLU20 -> Convolution20 (in-place)
I0525 23:46:16.900707 15394 net.cpp:240] Setting up ReLU20
I0525 23:46:16.900712 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.900715 15394 net.cpp:255] Memory required for data: 672662016
I0525 23:46:16.900718 15394 layer_factory.hpp:77] Creating layer Convolution21
I0525 23:46:16.900733 15394 net.cpp:190] Creating Layer Convolution21
I0525 23:46:16.900738 15394 net.cpp:605] Convolution21 <- Convolution20
I0525 23:46:16.900746 15394 net.cpp:579] Convolution21 -> Convolution21
I0525 23:46:16.902334 15394 net.cpp:240] Setting up Convolution21
I0525 23:46:16.902393 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.902398 15394 net.cpp:255] Memory required for data: 674759168
I0525 23:46:16.902415 15394 layer_factory.hpp:77] Creating layer BatchNorm21
I0525 23:46:16.902429 15394 net.cpp:190] Creating Layer BatchNorm21
I0525 23:46:16.902436 15394 net.cpp:605] BatchNorm21 <- Convolution21
I0525 23:46:16.902451 15394 net.cpp:566] BatchNorm21 -> Convolution21 (in-place)
I0525 23:46:16.902660 15394 net.cpp:240] Setting up BatchNorm21
I0525 23:46:16.902672 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.902675 15394 net.cpp:255] Memory required for data: 676856320
I0525 23:46:16.902689 15394 layer_factory.hpp:77] Creating layer Scale21
I0525 23:46:16.902699 15394 net.cpp:190] Creating Layer Scale21
I0525 23:46:16.902704 15394 net.cpp:605] Scale21 <- Convolution21
I0525 23:46:16.902711 15394 net.cpp:566] Scale21 -> Convolution21 (in-place)
I0525 23:46:16.902753 15394 layer_factory.hpp:77] Creating layer Scale21
I0525 23:46:16.902878 15394 net.cpp:240] Setting up Scale21
I0525 23:46:16.902886 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.902890 15394 net.cpp:255] Memory required for data: 678953472
I0525 23:46:16.902899 15394 layer_factory.hpp:77] Creating layer Eltwise10
I0525 23:46:16.902909 15394 net.cpp:190] Creating Layer Eltwise10
I0525 23:46:16.902914 15394 net.cpp:605] Eltwise10 <- Concat2
I0525 23:46:16.902920 15394 net.cpp:605] Eltwise10 <- Convolution21
I0525 23:46:16.902935 15394 net.cpp:579] Eltwise10 -> Eltwise10
I0525 23:46:16.902961 15394 net.cpp:240] Setting up Eltwise10
I0525 23:46:16.902967 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.902971 15394 net.cpp:255] Memory required for data: 681050624
I0525 23:46:16.902987 15394 layer_factory.hpp:77] Creating layer ReLU21
I0525 23:46:16.902998 15394 net.cpp:190] Creating Layer ReLU21
I0525 23:46:16.903003 15394 net.cpp:605] ReLU21 <- Eltwise10
I0525 23:46:16.903009 15394 net.cpp:566] ReLU21 -> Eltwise10 (in-place)
I0525 23:46:16.903017 15394 net.cpp:240] Setting up ReLU21
I0525 23:46:16.903022 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.903025 15394 net.cpp:255] Memory required for data: 683147776
I0525 23:46:16.903028 15394 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0525 23:46:16.903035 15394 net.cpp:190] Creating Layer Eltwise10_ReLU21_0_split
I0525 23:46:16.903039 15394 net.cpp:605] Eltwise10_ReLU21_0_split <- Eltwise10
I0525 23:46:16.903048 15394 net.cpp:579] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0525 23:46:16.903055 15394 net.cpp:579] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0525 23:46:16.903091 15394 net.cpp:240] Setting up Eltwise10_ReLU21_0_split
I0525 23:46:16.903098 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.903102 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.903105 15394 net.cpp:255] Memory required for data: 687342080
I0525 23:46:16.903110 15394 layer_factory.hpp:77] Creating layer Convolution22
I0525 23:46:16.903123 15394 net.cpp:190] Creating Layer Convolution22
I0525 23:46:16.903128 15394 net.cpp:605] Convolution22 <- Eltwise10_ReLU21_0_split_0
I0525 23:46:16.903136 15394 net.cpp:579] Convolution22 -> Convolution22
I0525 23:46:16.904716 15394 net.cpp:240] Setting up Convolution22
I0525 23:46:16.904752 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.904758 15394 net.cpp:255] Memory required for data: 689439232
I0525 23:46:16.904775 15394 layer_factory.hpp:77] Creating layer BatchNorm22
I0525 23:46:16.904790 15394 net.cpp:190] Creating Layer BatchNorm22
I0525 23:46:16.904798 15394 net.cpp:605] BatchNorm22 <- Convolution22
I0525 23:46:16.904806 15394 net.cpp:566] BatchNorm22 -> Convolution22 (in-place)
I0525 23:46:16.905024 15394 net.cpp:240] Setting up BatchNorm22
I0525 23:46:16.905036 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.905040 15394 net.cpp:255] Memory required for data: 691536384
I0525 23:46:16.905051 15394 layer_factory.hpp:77] Creating layer Scale22
I0525 23:46:16.905062 15394 net.cpp:190] Creating Layer Scale22
I0525 23:46:16.905067 15394 net.cpp:605] Scale22 <- Convolution22
I0525 23:46:16.905074 15394 net.cpp:566] Scale22 -> Convolution22 (in-place)
I0525 23:46:16.905120 15394 layer_factory.hpp:77] Creating layer Scale22
I0525 23:46:16.905244 15394 net.cpp:240] Setting up Scale22
I0525 23:46:16.905253 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.905256 15394 net.cpp:255] Memory required for data: 693633536
I0525 23:46:16.905266 15394 layer_factory.hpp:77] Creating layer ReLU22
I0525 23:46:16.905277 15394 net.cpp:190] Creating Layer ReLU22
I0525 23:46:16.905282 15394 net.cpp:605] ReLU22 <- Convolution22
I0525 23:46:16.905287 15394 net.cpp:566] ReLU22 -> Convolution22 (in-place)
I0525 23:46:16.905294 15394 net.cpp:240] Setting up ReLU22
I0525 23:46:16.905299 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.905303 15394 net.cpp:255] Memory required for data: 695730688
I0525 23:46:16.905306 15394 layer_factory.hpp:77] Creating layer Convolution23
I0525 23:46:16.905321 15394 net.cpp:190] Creating Layer Convolution23
I0525 23:46:16.905325 15394 net.cpp:605] Convolution23 <- Convolution22
I0525 23:46:16.905335 15394 net.cpp:579] Convolution23 -> Convolution23
I0525 23:46:16.906909 15394 net.cpp:240] Setting up Convolution23
I0525 23:46:16.906952 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.906957 15394 net.cpp:255] Memory required for data: 697827840
I0525 23:46:16.906973 15394 layer_factory.hpp:77] Creating layer BatchNorm23
I0525 23:46:16.906986 15394 net.cpp:190] Creating Layer BatchNorm23
I0525 23:46:16.906993 15394 net.cpp:605] BatchNorm23 <- Convolution23
I0525 23:46:16.907004 15394 net.cpp:566] BatchNorm23 -> Convolution23 (in-place)
I0525 23:46:16.907222 15394 net.cpp:240] Setting up BatchNorm23
I0525 23:46:16.907234 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.907238 15394 net.cpp:255] Memory required for data: 699924992
I0525 23:46:16.907253 15394 layer_factory.hpp:77] Creating layer Scale23
I0525 23:46:16.907265 15394 net.cpp:190] Creating Layer Scale23
I0525 23:46:16.907270 15394 net.cpp:605] Scale23 <- Convolution23
I0525 23:46:16.907277 15394 net.cpp:566] Scale23 -> Convolution23 (in-place)
I0525 23:46:16.907318 15394 layer_factory.hpp:77] Creating layer Scale23
I0525 23:46:16.907444 15394 net.cpp:240] Setting up Scale23
I0525 23:46:16.907454 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.907457 15394 net.cpp:255] Memory required for data: 702022144
I0525 23:46:16.907465 15394 layer_factory.hpp:77] Creating layer Eltwise11
I0525 23:46:16.907476 15394 net.cpp:190] Creating Layer Eltwise11
I0525 23:46:16.907483 15394 net.cpp:605] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0525 23:46:16.907488 15394 net.cpp:605] Eltwise11 <- Convolution23
I0525 23:46:16.907496 15394 net.cpp:579] Eltwise11 -> Eltwise11
I0525 23:46:16.907522 15394 net.cpp:240] Setting up Eltwise11
I0525 23:46:16.907529 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.907533 15394 net.cpp:255] Memory required for data: 704119296
I0525 23:46:16.907537 15394 layer_factory.hpp:77] Creating layer ReLU23
I0525 23:46:16.907544 15394 net.cpp:190] Creating Layer ReLU23
I0525 23:46:16.907548 15394 net.cpp:605] ReLU23 <- Eltwise11
I0525 23:46:16.907554 15394 net.cpp:566] ReLU23 -> Eltwise11 (in-place)
I0525 23:46:16.907562 15394 net.cpp:240] Setting up ReLU23
I0525 23:46:16.907567 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.907569 15394 net.cpp:255] Memory required for data: 706216448
I0525 23:46:16.907573 15394 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0525 23:46:16.907580 15394 net.cpp:190] Creating Layer Eltwise11_ReLU23_0_split
I0525 23:46:16.907583 15394 net.cpp:605] Eltwise11_ReLU23_0_split <- Eltwise11
I0525 23:46:16.907591 15394 net.cpp:579] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0525 23:46:16.907609 15394 net.cpp:579] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0525 23:46:16.907649 15394 net.cpp:240] Setting up Eltwise11_ReLU23_0_split
I0525 23:46:16.907656 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.907661 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.907665 15394 net.cpp:255] Memory required for data: 710410752
I0525 23:46:16.907668 15394 layer_factory.hpp:77] Creating layer Convolution24
I0525 23:46:16.907682 15394 net.cpp:190] Creating Layer Convolution24
I0525 23:46:16.907687 15394 net.cpp:605] Convolution24 <- Eltwise11_ReLU23_0_split_0
I0525 23:46:16.907694 15394 net.cpp:579] Convolution24 -> Convolution24
I0525 23:46:16.909276 15394 net.cpp:240] Setting up Convolution24
I0525 23:46:16.909312 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.909317 15394 net.cpp:255] Memory required for data: 712507904
I0525 23:46:16.909333 15394 layer_factory.hpp:77] Creating layer BatchNorm24
I0525 23:46:16.909348 15394 net.cpp:190] Creating Layer BatchNorm24
I0525 23:46:16.909356 15394 net.cpp:605] BatchNorm24 <- Convolution24
I0525 23:46:16.909368 15394 net.cpp:566] BatchNorm24 -> Convolution24 (in-place)
I0525 23:46:16.909569 15394 net.cpp:240] Setting up BatchNorm24
I0525 23:46:16.909579 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.909582 15394 net.cpp:255] Memory required for data: 714605056
I0525 23:46:16.909596 15394 layer_factory.hpp:77] Creating layer Scale24
I0525 23:46:16.909616 15394 net.cpp:190] Creating Layer Scale24
I0525 23:46:16.909622 15394 net.cpp:605] Scale24 <- Convolution24
I0525 23:46:16.909628 15394 net.cpp:566] Scale24 -> Convolution24 (in-place)
I0525 23:46:16.909675 15394 layer_factory.hpp:77] Creating layer Scale24
I0525 23:46:16.909802 15394 net.cpp:240] Setting up Scale24
I0525 23:46:16.909812 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.909816 15394 net.cpp:255] Memory required for data: 716702208
I0525 23:46:16.909832 15394 layer_factory.hpp:77] Creating layer ReLU24
I0525 23:46:16.909845 15394 net.cpp:190] Creating Layer ReLU24
I0525 23:46:16.909850 15394 net.cpp:605] ReLU24 <- Convolution24
I0525 23:46:16.909857 15394 net.cpp:566] ReLU24 -> Convolution24 (in-place)
I0525 23:46:16.909864 15394 net.cpp:240] Setting up ReLU24
I0525 23:46:16.909869 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.909873 15394 net.cpp:255] Memory required for data: 718799360
I0525 23:46:16.909876 15394 layer_factory.hpp:77] Creating layer Convolution25
I0525 23:46:16.909893 15394 net.cpp:190] Creating Layer Convolution25
I0525 23:46:16.909898 15394 net.cpp:605] Convolution25 <- Convolution24
I0525 23:46:16.909909 15394 net.cpp:579] Convolution25 -> Convolution25
I0525 23:46:16.911478 15394 net.cpp:240] Setting up Convolution25
I0525 23:46:16.911517 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.911521 15394 net.cpp:255] Memory required for data: 720896512
I0525 23:46:16.911537 15394 layer_factory.hpp:77] Creating layer BatchNorm25
I0525 23:46:16.911550 15394 net.cpp:190] Creating Layer BatchNorm25
I0525 23:46:16.911556 15394 net.cpp:605] BatchNorm25 <- Convolution25
I0525 23:46:16.911566 15394 net.cpp:566] BatchNorm25 -> Convolution25 (in-place)
I0525 23:46:16.911767 15394 net.cpp:240] Setting up BatchNorm25
I0525 23:46:16.911777 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.911780 15394 net.cpp:255] Memory required for data: 722993664
I0525 23:46:16.911794 15394 layer_factory.hpp:77] Creating layer Scale25
I0525 23:46:16.911828 15394 net.cpp:190] Creating Layer Scale25
I0525 23:46:16.911834 15394 net.cpp:605] Scale25 <- Convolution25
I0525 23:46:16.911840 15394 net.cpp:566] Scale25 -> Convolution25 (in-place)
I0525 23:46:16.911891 15394 layer_factory.hpp:77] Creating layer Scale25
I0525 23:46:16.912027 15394 net.cpp:240] Setting up Scale25
I0525 23:46:16.912039 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.912042 15394 net.cpp:255] Memory required for data: 725090816
I0525 23:46:16.912052 15394 layer_factory.hpp:77] Creating layer Eltwise12
I0525 23:46:16.912065 15394 net.cpp:190] Creating Layer Eltwise12
I0525 23:46:16.912071 15394 net.cpp:605] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0525 23:46:16.912077 15394 net.cpp:605] Eltwise12 <- Convolution25
I0525 23:46:16.912083 15394 net.cpp:579] Eltwise12 -> Eltwise12
I0525 23:46:16.912107 15394 net.cpp:240] Setting up Eltwise12
I0525 23:46:16.912114 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.912118 15394 net.cpp:255] Memory required for data: 727187968
I0525 23:46:16.912122 15394 layer_factory.hpp:77] Creating layer ReLU25
I0525 23:46:16.912132 15394 net.cpp:190] Creating Layer ReLU25
I0525 23:46:16.912137 15394 net.cpp:605] ReLU25 <- Eltwise12
I0525 23:46:16.912142 15394 net.cpp:566] ReLU25 -> Eltwise12 (in-place)
I0525 23:46:16.912148 15394 net.cpp:240] Setting up ReLU25
I0525 23:46:16.912153 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.912158 15394 net.cpp:255] Memory required for data: 729285120
I0525 23:46:16.912160 15394 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I0525 23:46:16.912168 15394 net.cpp:190] Creating Layer Eltwise12_ReLU25_0_split
I0525 23:46:16.912173 15394 net.cpp:605] Eltwise12_ReLU25_0_split <- Eltwise12
I0525 23:46:16.912178 15394 net.cpp:579] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I0525 23:46:16.912184 15394 net.cpp:579] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I0525 23:46:16.912228 15394 net.cpp:240] Setting up Eltwise12_ReLU25_0_split
I0525 23:46:16.912235 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.912240 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.912243 15394 net.cpp:255] Memory required for data: 733479424
I0525 23:46:16.912247 15394 layer_factory.hpp:77] Creating layer Convolution26
I0525 23:46:16.912261 15394 net.cpp:190] Creating Layer Convolution26
I0525 23:46:16.912266 15394 net.cpp:605] Convolution26 <- Eltwise12_ReLU25_0_split_0
I0525 23:46:16.912282 15394 net.cpp:579] Convolution26 -> Convolution26
I0525 23:46:16.913866 15394 net.cpp:240] Setting up Convolution26
I0525 23:46:16.913903 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.913908 15394 net.cpp:255] Memory required for data: 735576576
I0525 23:46:16.913923 15394 layer_factory.hpp:77] Creating layer BatchNorm26
I0525 23:46:16.913939 15394 net.cpp:190] Creating Layer BatchNorm26
I0525 23:46:16.913947 15394 net.cpp:605] BatchNorm26 <- Convolution26
I0525 23:46:16.913957 15394 net.cpp:566] BatchNorm26 -> Convolution26 (in-place)
I0525 23:46:16.914176 15394 net.cpp:240] Setting up BatchNorm26
I0525 23:46:16.914187 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.914191 15394 net.cpp:255] Memory required for data: 737673728
I0525 23:46:16.914204 15394 layer_factory.hpp:77] Creating layer Scale26
I0525 23:46:16.914217 15394 net.cpp:190] Creating Layer Scale26
I0525 23:46:16.914223 15394 net.cpp:605] Scale26 <- Convolution26
I0525 23:46:16.914229 15394 net.cpp:566] Scale26 -> Convolution26 (in-place)
I0525 23:46:16.914275 15394 layer_factory.hpp:77] Creating layer Scale26
I0525 23:46:16.916972 15394 net.cpp:240] Setting up Scale26
I0525 23:46:16.917028 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.917033 15394 net.cpp:255] Memory required for data: 739770880
I0525 23:46:16.917060 15394 layer_factory.hpp:77] Creating layer ReLU26
I0525 23:46:16.917078 15394 net.cpp:190] Creating Layer ReLU26
I0525 23:46:16.917086 15394 net.cpp:605] ReLU26 <- Convolution26
I0525 23:46:16.917099 15394 net.cpp:566] ReLU26 -> Convolution26 (in-place)
I0525 23:46:16.917114 15394 net.cpp:240] Setting up ReLU26
I0525 23:46:16.917119 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.917122 15394 net.cpp:255] Memory required for data: 741868032
I0525 23:46:16.917125 15394 layer_factory.hpp:77] Creating layer Convolution27
I0525 23:46:16.917143 15394 net.cpp:190] Creating Layer Convolution27
I0525 23:46:16.917147 15394 net.cpp:605] Convolution27 <- Convolution26
I0525 23:46:16.917156 15394 net.cpp:579] Convolution27 -> Convolution27
I0525 23:46:16.919740 15394 net.cpp:240] Setting up Convolution27
I0525 23:46:16.919791 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.919795 15394 net.cpp:255] Memory required for data: 743965184
I0525 23:46:16.919812 15394 layer_factory.hpp:77] Creating layer BatchNorm27
I0525 23:46:16.919831 15394 net.cpp:190] Creating Layer BatchNorm27
I0525 23:46:16.919839 15394 net.cpp:605] BatchNorm27 <- Convolution27
I0525 23:46:16.919850 15394 net.cpp:566] BatchNorm27 -> Convolution27 (in-place)
I0525 23:46:16.920066 15394 net.cpp:240] Setting up BatchNorm27
I0525 23:46:16.920076 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.920080 15394 net.cpp:255] Memory required for data: 746062336
I0525 23:46:16.920094 15394 layer_factory.hpp:77] Creating layer Scale27
I0525 23:46:16.920111 15394 net.cpp:190] Creating Layer Scale27
I0525 23:46:16.920116 15394 net.cpp:605] Scale27 <- Convolution27
I0525 23:46:16.920122 15394 net.cpp:566] Scale27 -> Convolution27 (in-place)
I0525 23:46:16.920169 15394 layer_factory.hpp:77] Creating layer Scale27
I0525 23:46:16.920295 15394 net.cpp:240] Setting up Scale27
I0525 23:46:16.920305 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.920308 15394 net.cpp:255] Memory required for data: 748159488
I0525 23:46:16.920320 15394 layer_factory.hpp:77] Creating layer Eltwise13
I0525 23:46:16.920328 15394 net.cpp:190] Creating Layer Eltwise13
I0525 23:46:16.920336 15394 net.cpp:605] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I0525 23:46:16.920342 15394 net.cpp:605] Eltwise13 <- Convolution27
I0525 23:46:16.920351 15394 net.cpp:579] Eltwise13 -> Eltwise13
I0525 23:46:16.920374 15394 net.cpp:240] Setting up Eltwise13
I0525 23:46:16.920382 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.920385 15394 net.cpp:255] Memory required for data: 750256640
I0525 23:46:16.920388 15394 layer_factory.hpp:77] Creating layer ReLU27
I0525 23:46:16.920406 15394 net.cpp:190] Creating Layer ReLU27
I0525 23:46:16.920413 15394 net.cpp:605] ReLU27 <- Eltwise13
I0525 23:46:16.920420 15394 net.cpp:566] ReLU27 -> Eltwise13 (in-place)
I0525 23:46:16.920428 15394 net.cpp:240] Setting up ReLU27
I0525 23:46:16.920434 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.920438 15394 net.cpp:255] Memory required for data: 752353792
I0525 23:46:16.920441 15394 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I0525 23:46:16.920447 15394 net.cpp:190] Creating Layer Eltwise13_ReLU27_0_split
I0525 23:46:16.920451 15394 net.cpp:605] Eltwise13_ReLU27_0_split <- Eltwise13
I0525 23:46:16.920457 15394 net.cpp:579] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I0525 23:46:16.920464 15394 net.cpp:579] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I0525 23:46:16.920502 15394 net.cpp:240] Setting up Eltwise13_ReLU27_0_split
I0525 23:46:16.920509 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.920513 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.920517 15394 net.cpp:255] Memory required for data: 756548096
I0525 23:46:16.920521 15394 layer_factory.hpp:77] Creating layer Convolution28
I0525 23:46:16.920531 15394 net.cpp:190] Creating Layer Convolution28
I0525 23:46:16.920536 15394 net.cpp:605] Convolution28 <- Eltwise13_ReLU27_0_split_0
I0525 23:46:16.920545 15394 net.cpp:579] Convolution28 -> Convolution28
I0525 23:46:16.922127 15394 net.cpp:240] Setting up Convolution28
I0525 23:46:16.922166 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.922170 15394 net.cpp:255] Memory required for data: 758645248
I0525 23:46:16.922186 15394 layer_factory.hpp:77] Creating layer BatchNorm28
I0525 23:46:16.922201 15394 net.cpp:190] Creating Layer BatchNorm28
I0525 23:46:16.922209 15394 net.cpp:605] BatchNorm28 <- Convolution28
I0525 23:46:16.922219 15394 net.cpp:566] BatchNorm28 -> Convolution28 (in-place)
I0525 23:46:16.922448 15394 net.cpp:240] Setting up BatchNorm28
I0525 23:46:16.922461 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.922466 15394 net.cpp:255] Memory required for data: 760742400
I0525 23:46:16.922482 15394 layer_factory.hpp:77] Creating layer Scale28
I0525 23:46:16.922494 15394 net.cpp:190] Creating Layer Scale28
I0525 23:46:16.922500 15394 net.cpp:605] Scale28 <- Convolution28
I0525 23:46:16.922508 15394 net.cpp:566] Scale28 -> Convolution28 (in-place)
I0525 23:46:16.922551 15394 layer_factory.hpp:77] Creating layer Scale28
I0525 23:46:16.922680 15394 net.cpp:240] Setting up Scale28
I0525 23:46:16.922689 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.922693 15394 net.cpp:255] Memory required for data: 762839552
I0525 23:46:16.922701 15394 layer_factory.hpp:77] Creating layer ReLU28
I0525 23:46:16.922709 15394 net.cpp:190] Creating Layer ReLU28
I0525 23:46:16.922713 15394 net.cpp:605] ReLU28 <- Convolution28
I0525 23:46:16.922722 15394 net.cpp:566] ReLU28 -> Convolution28 (in-place)
I0525 23:46:16.922731 15394 net.cpp:240] Setting up ReLU28
I0525 23:46:16.922736 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.922739 15394 net.cpp:255] Memory required for data: 764936704
I0525 23:46:16.922744 15394 layer_factory.hpp:77] Creating layer Convolution29
I0525 23:46:16.922757 15394 net.cpp:190] Creating Layer Convolution29
I0525 23:46:16.922761 15394 net.cpp:605] Convolution29 <- Convolution28
I0525 23:46:16.922768 15394 net.cpp:579] Convolution29 -> Convolution29
I0525 23:46:16.924352 15394 net.cpp:240] Setting up Convolution29
I0525 23:46:16.924391 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.924396 15394 net.cpp:255] Memory required for data: 767033856
I0525 23:46:16.924412 15394 layer_factory.hpp:77] Creating layer BatchNorm29
I0525 23:46:16.924428 15394 net.cpp:190] Creating Layer BatchNorm29
I0525 23:46:16.924434 15394 net.cpp:605] BatchNorm29 <- Convolution29
I0525 23:46:16.924443 15394 net.cpp:566] BatchNorm29 -> Convolution29 (in-place)
I0525 23:46:16.924649 15394 net.cpp:240] Setting up BatchNorm29
I0525 23:46:16.924667 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.924672 15394 net.cpp:255] Memory required for data: 769131008
I0525 23:46:16.924686 15394 layer_factory.hpp:77] Creating layer Scale29
I0525 23:46:16.924697 15394 net.cpp:190] Creating Layer Scale29
I0525 23:46:16.924702 15394 net.cpp:605] Scale29 <- Convolution29
I0525 23:46:16.924708 15394 net.cpp:566] Scale29 -> Convolution29 (in-place)
I0525 23:46:16.924757 15394 layer_factory.hpp:77] Creating layer Scale29
I0525 23:46:16.924885 15394 net.cpp:240] Setting up Scale29
I0525 23:46:16.924895 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.924898 15394 net.cpp:255] Memory required for data: 771228160
I0525 23:46:16.924907 15394 layer_factory.hpp:77] Creating layer Eltwise14
I0525 23:46:16.924918 15394 net.cpp:190] Creating Layer Eltwise14
I0525 23:46:16.924926 15394 net.cpp:605] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I0525 23:46:16.924931 15394 net.cpp:605] Eltwise14 <- Convolution29
I0525 23:46:16.924937 15394 net.cpp:579] Eltwise14 -> Eltwise14
I0525 23:46:16.924962 15394 net.cpp:240] Setting up Eltwise14
I0525 23:46:16.924969 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.924973 15394 net.cpp:255] Memory required for data: 773325312
I0525 23:46:16.924975 15394 layer_factory.hpp:77] Creating layer ReLU29
I0525 23:46:16.924985 15394 net.cpp:190] Creating Layer ReLU29
I0525 23:46:16.924990 15394 net.cpp:605] ReLU29 <- Eltwise14
I0525 23:46:16.924995 15394 net.cpp:566] ReLU29 -> Eltwise14 (in-place)
I0525 23:46:16.925003 15394 net.cpp:240] Setting up ReLU29
I0525 23:46:16.925007 15394 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0525 23:46:16.925011 15394 net.cpp:255] Memory required for data: 775422464
I0525 23:46:16.925015 15394 layer_factory.hpp:77] Creating layer Pooling3
I0525 23:46:16.925024 15394 net.cpp:190] Creating Layer Pooling3
I0525 23:46:16.925029 15394 net.cpp:605] Pooling3 <- Eltwise14
I0525 23:46:16.925035 15394 net.cpp:579] Pooling3 -> Pooling3
I0525 23:46:16.925067 15394 net.cpp:240] Setting up Pooling3
I0525 23:46:16.925074 15394 net.cpp:247] Top shape: 128 64 1 1 (8192)
I0525 23:46:16.925077 15394 net.cpp:255] Memory required for data: 775455232
I0525 23:46:16.925081 15394 layer_factory.hpp:77] Creating layer InnerProduct1
I0525 23:46:16.925091 15394 net.cpp:190] Creating Layer InnerProduct1
I0525 23:46:16.925094 15394 net.cpp:605] InnerProduct1 <- Pooling3
I0525 23:46:16.925101 15394 net.cpp:579] InnerProduct1 -> InnerProduct1
I0525 23:46:16.925266 15394 net.cpp:240] Setting up InnerProduct1
I0525 23:46:16.925277 15394 net.cpp:247] Top shape: 128 10 (1280)
I0525 23:46:16.925281 15394 net.cpp:255] Memory required for data: 775460352
I0525 23:46:16.925290 15394 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0525 23:46:16.925314 15394 net.cpp:190] Creating Layer SoftmaxWithLoss1
I0525 23:46:16.925318 15394 net.cpp:605] SoftmaxWithLoss1 <- InnerProduct1
I0525 23:46:16.925323 15394 net.cpp:605] SoftmaxWithLoss1 <- Data2
I0525 23:46:16.925333 15394 net.cpp:579] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0525 23:46:16.925351 15394 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0525 23:46:16.925452 15394 net.cpp:240] Setting up SoftmaxWithLoss1
I0525 23:46:16.925462 15394 net.cpp:247] Top shape: (1)
I0525 23:46:16.925464 15394 net.cpp:250]     with loss weight 1
I0525 23:46:16.925505 15394 net.cpp:255] Memory required for data: 775460356
I0525 23:46:16.925509 15394 net.cpp:316] SoftmaxWithLoss1 needs backward computation.
I0525 23:46:16.925513 15394 net.cpp:316] InnerProduct1 needs backward computation.
I0525 23:46:16.925518 15394 net.cpp:316] Pooling3 needs backward computation.
I0525 23:46:16.925520 15394 net.cpp:316] ReLU29 needs backward computation.
I0525 23:46:16.925523 15394 net.cpp:316] Eltwise14 needs backward computation.
I0525 23:46:16.925528 15394 net.cpp:316] Scale29 needs backward computation.
I0525 23:46:16.925531 15394 net.cpp:316] BatchNorm29 needs backward computation.
I0525 23:46:16.925534 15394 net.cpp:316] Convolution29 needs backward computation.
I0525 23:46:16.925539 15394 net.cpp:316] ReLU28 needs backward computation.
I0525 23:46:16.925551 15394 net.cpp:316] Scale28 needs backward computation.
I0525 23:46:16.925555 15394 net.cpp:316] BatchNorm28 needs backward computation.
I0525 23:46:16.925559 15394 net.cpp:316] Convolution28 needs backward computation.
I0525 23:46:16.925564 15394 net.cpp:316] Eltwise13_ReLU27_0_split needs backward computation.
I0525 23:46:16.925566 15394 net.cpp:316] ReLU27 needs backward computation.
I0525 23:46:16.925570 15394 net.cpp:316] Eltwise13 needs backward computation.
I0525 23:46:16.925575 15394 net.cpp:316] Scale27 needs backward computation.
I0525 23:46:16.925578 15394 net.cpp:316] BatchNorm27 needs backward computation.
I0525 23:46:16.925581 15394 net.cpp:316] Convolution27 needs backward computation.
I0525 23:46:16.925585 15394 net.cpp:316] ReLU26 needs backward computation.
I0525 23:46:16.925588 15394 net.cpp:316] Scale26 needs backward computation.
I0525 23:46:16.925592 15394 net.cpp:316] BatchNorm26 needs backward computation.
I0525 23:46:16.925595 15394 net.cpp:316] Convolution26 needs backward computation.
I0525 23:46:16.925600 15394 net.cpp:316] Eltwise12_ReLU25_0_split needs backward computation.
I0525 23:46:16.925603 15394 net.cpp:316] ReLU25 needs backward computation.
I0525 23:46:16.925606 15394 net.cpp:316] Eltwise12 needs backward computation.
I0525 23:46:16.925611 15394 net.cpp:316] Scale25 needs backward computation.
I0525 23:46:16.925614 15394 net.cpp:316] BatchNorm25 needs backward computation.
I0525 23:46:16.925618 15394 net.cpp:316] Convolution25 needs backward computation.
I0525 23:46:16.925621 15394 net.cpp:316] ReLU24 needs backward computation.
I0525 23:46:16.925626 15394 net.cpp:316] Scale24 needs backward computation.
I0525 23:46:16.925628 15394 net.cpp:316] BatchNorm24 needs backward computation.
I0525 23:46:16.925632 15394 net.cpp:316] Convolution24 needs backward computation.
I0525 23:46:16.925637 15394 net.cpp:316] Eltwise11_ReLU23_0_split needs backward computation.
I0525 23:46:16.925640 15394 net.cpp:316] ReLU23 needs backward computation.
I0525 23:46:16.925643 15394 net.cpp:316] Eltwise11 needs backward computation.
I0525 23:46:16.925647 15394 net.cpp:316] Scale23 needs backward computation.
I0525 23:46:16.925652 15394 net.cpp:316] BatchNorm23 needs backward computation.
I0525 23:46:16.925654 15394 net.cpp:316] Convolution23 needs backward computation.
I0525 23:46:16.925658 15394 net.cpp:316] ReLU22 needs backward computation.
I0525 23:46:16.925662 15394 net.cpp:316] Scale22 needs backward computation.
I0525 23:46:16.925665 15394 net.cpp:316] BatchNorm22 needs backward computation.
I0525 23:46:16.925668 15394 net.cpp:316] Convolution22 needs backward computation.
I0525 23:46:16.925673 15394 net.cpp:316] Eltwise10_ReLU21_0_split needs backward computation.
I0525 23:46:16.925676 15394 net.cpp:316] ReLU21 needs backward computation.
I0525 23:46:16.925679 15394 net.cpp:316] Eltwise10 needs backward computation.
I0525 23:46:16.925684 15394 net.cpp:316] Scale21 needs backward computation.
I0525 23:46:16.925688 15394 net.cpp:316] BatchNorm21 needs backward computation.
I0525 23:46:16.925691 15394 net.cpp:316] Convolution21 needs backward computation.
I0525 23:46:16.925695 15394 net.cpp:316] ReLU20 needs backward computation.
I0525 23:46:16.925699 15394 net.cpp:316] Scale20 needs backward computation.
I0525 23:46:16.925703 15394 net.cpp:316] BatchNorm20 needs backward computation.
I0525 23:46:16.925705 15394 net.cpp:316] Convolution20 needs backward computation.
I0525 23:46:16.925709 15394 net.cpp:316] Concat2 needs backward computation.
I0525 23:46:16.925714 15394 net.cpp:318] Input2 does not need backward computation.
I0525 23:46:16.925719 15394 net.cpp:316] Pooling2 needs backward computation.
I0525 23:46:16.925722 15394 net.cpp:316] Eltwise9_ReLU19_0_split needs backward computation.
I0525 23:46:16.925726 15394 net.cpp:316] ReLU19 needs backward computation.
I0525 23:46:16.925730 15394 net.cpp:316] Eltwise9 needs backward computation.
I0525 23:46:16.925735 15394 net.cpp:316] Scale19 needs backward computation.
I0525 23:46:16.925743 15394 net.cpp:316] BatchNorm19 needs backward computation.
I0525 23:46:16.925746 15394 net.cpp:316] Convolution19 needs backward computation.
I0525 23:46:16.925750 15394 net.cpp:316] ReLU18 needs backward computation.
I0525 23:46:16.925755 15394 net.cpp:316] Scale18 needs backward computation.
I0525 23:46:16.925757 15394 net.cpp:316] BatchNorm18 needs backward computation.
I0525 23:46:16.925761 15394 net.cpp:316] Convolution18 needs backward computation.
I0525 23:46:16.925765 15394 net.cpp:316] Eltwise8_ReLU17_0_split needs backward computation.
I0525 23:46:16.925770 15394 net.cpp:316] ReLU17 needs backward computation.
I0525 23:46:16.925772 15394 net.cpp:316] Eltwise8 needs backward computation.
I0525 23:46:16.925776 15394 net.cpp:316] Scale17 needs backward computation.
I0525 23:46:16.925781 15394 net.cpp:316] BatchNorm17 needs backward computation.
I0525 23:46:16.925783 15394 net.cpp:316] Convolution17 needs backward computation.
I0525 23:46:16.925791 15394 net.cpp:316] ReLU16 needs backward computation.
I0525 23:46:16.925794 15394 net.cpp:316] Scale16 needs backward computation.
I0525 23:46:16.925797 15394 net.cpp:316] BatchNorm16 needs backward computation.
I0525 23:46:16.925801 15394 net.cpp:316] Convolution16 needs backward computation.
I0525 23:46:16.925806 15394 net.cpp:316] Eltwise7_ReLU15_0_split needs backward computation.
I0525 23:46:16.925809 15394 net.cpp:316] ReLU15 needs backward computation.
I0525 23:46:16.925812 15394 net.cpp:316] Eltwise7 needs backward computation.
I0525 23:46:16.925817 15394 net.cpp:316] Scale15 needs backward computation.
I0525 23:46:16.925820 15394 net.cpp:316] BatchNorm15 needs backward computation.
I0525 23:46:16.925824 15394 net.cpp:316] Convolution15 needs backward computation.
I0525 23:46:16.925828 15394 net.cpp:316] ReLU14 needs backward computation.
I0525 23:46:16.925832 15394 net.cpp:316] Scale14 needs backward computation.
I0525 23:46:16.925835 15394 net.cpp:316] BatchNorm14 needs backward computation.
I0525 23:46:16.925838 15394 net.cpp:316] Convolution14 needs backward computation.
I0525 23:46:16.925843 15394 net.cpp:316] Eltwise6_ReLU13_0_split needs backward computation.
I0525 23:46:16.925846 15394 net.cpp:316] ReLU13 needs backward computation.
I0525 23:46:16.925849 15394 net.cpp:316] Eltwise6 needs backward computation.
I0525 23:46:16.925854 15394 net.cpp:316] Scale13 needs backward computation.
I0525 23:46:16.925858 15394 net.cpp:316] BatchNorm13 needs backward computation.
I0525 23:46:16.925861 15394 net.cpp:316] Convolution13 needs backward computation.
I0525 23:46:16.925865 15394 net.cpp:316] ReLU12 needs backward computation.
I0525 23:46:16.925868 15394 net.cpp:316] Scale12 needs backward computation.
I0525 23:46:16.925873 15394 net.cpp:316] BatchNorm12 needs backward computation.
I0525 23:46:16.925875 15394 net.cpp:316] Convolution12 needs backward computation.
I0525 23:46:16.925879 15394 net.cpp:316] Eltwise5_ReLU11_0_split needs backward computation.
I0525 23:46:16.925884 15394 net.cpp:316] ReLU11 needs backward computation.
I0525 23:46:16.925887 15394 net.cpp:316] Eltwise5 needs backward computation.
I0525 23:46:16.925891 15394 net.cpp:316] Scale11 needs backward computation.
I0525 23:46:16.925895 15394 net.cpp:316] BatchNorm11 needs backward computation.
I0525 23:46:16.925899 15394 net.cpp:316] Convolution11 needs backward computation.
I0525 23:46:16.925902 15394 net.cpp:316] ReLU10 needs backward computation.
I0525 23:46:16.925905 15394 net.cpp:316] Scale10 needs backward computation.
I0525 23:46:16.925909 15394 net.cpp:316] BatchNorm10 needs backward computation.
I0525 23:46:16.925912 15394 net.cpp:316] Convolution10 needs backward computation.
I0525 23:46:16.925917 15394 net.cpp:316] Concat1 needs backward computation.
I0525 23:46:16.925921 15394 net.cpp:318] Input1 does not need backward computation.
I0525 23:46:16.925925 15394 net.cpp:316] Pooling1 needs backward computation.
I0525 23:46:16.925930 15394 net.cpp:316] Eltwise4_ReLU9_0_split needs backward computation.
I0525 23:46:16.925933 15394 net.cpp:316] ReLU9 needs backward computation.
I0525 23:46:16.925940 15394 net.cpp:316] Eltwise4 needs backward computation.
I0525 23:46:16.925945 15394 net.cpp:316] Scale9 needs backward computation.
I0525 23:46:16.925947 15394 net.cpp:316] BatchNorm9 needs backward computation.
I0525 23:46:16.925951 15394 net.cpp:316] Convolution9 needs backward computation.
I0525 23:46:16.925956 15394 net.cpp:316] ReLU8 needs backward computation.
I0525 23:46:16.925958 15394 net.cpp:316] Scale8 needs backward computation.
I0525 23:46:16.925962 15394 net.cpp:316] BatchNorm8 needs backward computation.
I0525 23:46:16.925966 15394 net.cpp:316] Convolution8 needs backward computation.
I0525 23:46:16.925969 15394 net.cpp:316] Eltwise3_ReLU7_0_split needs backward computation.
I0525 23:46:16.925973 15394 net.cpp:316] ReLU7 needs backward computation.
I0525 23:46:16.925976 15394 net.cpp:316] Eltwise3 needs backward computation.
I0525 23:46:16.925981 15394 net.cpp:316] Scale7 needs backward computation.
I0525 23:46:16.925984 15394 net.cpp:316] BatchNorm7 needs backward computation.
I0525 23:46:16.925988 15394 net.cpp:316] Convolution7 needs backward computation.
I0525 23:46:16.925992 15394 net.cpp:316] ReLU6 needs backward computation.
I0525 23:46:16.925997 15394 net.cpp:316] Scale6 needs backward computation.
I0525 23:46:16.925999 15394 net.cpp:316] BatchNorm6 needs backward computation.
I0525 23:46:16.926003 15394 net.cpp:316] Convolution6 needs backward computation.
I0525 23:46:16.926007 15394 net.cpp:316] Eltwise2_ReLU5_0_split needs backward computation.
I0525 23:46:16.926012 15394 net.cpp:316] ReLU5 needs backward computation.
I0525 23:46:16.926015 15394 net.cpp:316] Eltwise2 needs backward computation.
I0525 23:46:16.926019 15394 net.cpp:316] Scale5 needs backward computation.
I0525 23:46:16.926023 15394 net.cpp:316] BatchNorm5 needs backward computation.
I0525 23:46:16.926028 15394 net.cpp:316] Convolution5 needs backward computation.
I0525 23:46:16.926030 15394 net.cpp:316] ReLU4 needs backward computation.
I0525 23:46:16.926034 15394 net.cpp:316] Scale4 needs backward computation.
I0525 23:46:16.926038 15394 net.cpp:316] BatchNorm4 needs backward computation.
I0525 23:46:16.926041 15394 net.cpp:316] Convolution4 needs backward computation.
I0525 23:46:16.926045 15394 net.cpp:316] Eltwise1_ReLU3_0_split needs backward computation.
I0525 23:46:16.926049 15394 net.cpp:316] ReLU3 needs backward computation.
I0525 23:46:16.926054 15394 net.cpp:316] Eltwise1 needs backward computation.
I0525 23:46:16.926057 15394 net.cpp:316] Scale3 needs backward computation.
I0525 23:46:16.926061 15394 net.cpp:316] BatchNorm3 needs backward computation.
I0525 23:46:16.926064 15394 net.cpp:316] Convolution3 needs backward computation.
I0525 23:46:16.926069 15394 net.cpp:316] ReLU2 needs backward computation.
I0525 23:46:16.926072 15394 net.cpp:316] Scale2 needs backward computation.
I0525 23:46:16.926075 15394 net.cpp:316] BatchNorm2 needs backward computation.
I0525 23:46:16.926079 15394 net.cpp:316] Convolution2 needs backward computation.
I0525 23:46:16.926084 15394 net.cpp:316] Convolution1_ReLU1_0_split needs backward computation.
I0525 23:46:16.926087 15394 net.cpp:316] ReLU1 needs backward computation.
I0525 23:46:16.926091 15394 net.cpp:316] Scale1 needs backward computation.
I0525 23:46:16.926095 15394 net.cpp:316] BatchNorm1 needs backward computation.
I0525 23:46:16.926098 15394 net.cpp:316] Convolution1 needs backward computation.
I0525 23:46:16.926103 15394 net.cpp:318] Data1 does not need backward computation.
I0525 23:46:16.926106 15394 net.cpp:360] This network produces output SoftmaxWithLoss1
I0525 23:46:16.926213 15394 net.cpp:374] Network initialization done.
I0525 23:46:16.934427 15394 solver.cpp:186] Creating test net (#0) specified by test_net file: examples/stochastic_depth/residual_test.prototxt
I0525 23:46:16.935611 15394 net.cpp:148] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "/scratch/pas282/caffe/examples/cifar10/cifar10_test_leveldb_padding0"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise4"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Input1"
  type: "Input"
  top: "Input1"
  input_param {
    shape {
      dim: 100
      dim: 16
      dim: 16
      dim: 16
    }
  }
}
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "Pooling1"
  bottom: "Input1"
  top: "Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Concat1"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Pooling2"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling2"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Input2"
  type: "Input"
  top: "Input2"
  input_param {
    shape {
      dim: 100
      dim: 32
      dim: 8
      dim: 8
    }
  }
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "Pooling2"
  bottom: "Input2"
  top: "Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Concat2"
  bottom: "Convolution21"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution22"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution22"
  top: "Convolution22"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Convolution22"
  top: "Convolution23"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution23"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution24"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution25"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution26"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution27"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution28"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution28"
  top: "Convolution28"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution29"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Pooling3"
  type: "Pooling"
  bottom: "Eltwise14"
  top: "Pooling3"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling3"
  top: "InnerProduct1"
  inner_product_param {
    num_output: 10
    bias_term: true
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Accuracy"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "Accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
I0525 23:46:16.936329 15394 layer_factory.hpp:77] Creating layer Data1
I0525 23:46:16.936556 15394 net.cpp:190] Creating Layer Data1
I0525 23:46:16.936573 15394 net.cpp:579] Data1 -> Data1
I0525 23:46:16.936594 15394 net.cpp:579] Data1 -> Data2
I0525 23:46:16.993352 15400 db_leveldb.cpp:18] Opened leveldb /scratch/pas282/caffe/examples/cifar10/cifar10_test_leveldb_padding0
I0525 23:46:16.993968 15394 data_layer.cpp:41] output data size: 100,3,32,32
I0525 23:46:17.000449 15394 net.cpp:240] Setting up Data1
I0525 23:46:17.000504 15394 net.cpp:247] Top shape: 100 3 32 32 (307200)
I0525 23:46:17.000510 15394 net.cpp:247] Top shape: 100 (100)
I0525 23:46:17.000514 15394 net.cpp:255] Memory required for data: 1229200
I0525 23:46:17.000524 15394 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0525 23:46:17.000541 15394 net.cpp:190] Creating Layer Data2_Data1_1_split
I0525 23:46:17.000547 15394 net.cpp:605] Data2_Data1_1_split <- Data2
I0525 23:46:17.000558 15394 net.cpp:579] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0525 23:46:17.006484 15394 net.cpp:579] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0525 23:46:17.006644 15394 net.cpp:240] Setting up Data2_Data1_1_split
I0525 23:46:17.006659 15394 net.cpp:247] Top shape: 100 (100)
I0525 23:46:17.006664 15394 net.cpp:247] Top shape: 100 (100)
I0525 23:46:17.006667 15394 net.cpp:255] Memory required for data: 1230000
I0525 23:46:17.006675 15394 layer_factory.hpp:77] Creating layer Convolution1
I0525 23:46:17.006698 15394 net.cpp:190] Creating Layer Convolution1
I0525 23:46:17.006705 15394 net.cpp:605] Convolution1 <- Data1
I0525 23:46:17.006727 15394 net.cpp:579] Convolution1 -> Convolution1
I0525 23:46:17.007068 15394 net.cpp:240] Setting up Convolution1
I0525 23:46:17.007081 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.007086 15394 net.cpp:255] Memory required for data: 7783600
I0525 23:46:17.007100 15394 layer_factory.hpp:77] Creating layer BatchNorm1
I0525 23:46:17.007113 15394 net.cpp:190] Creating Layer BatchNorm1
I0525 23:46:17.007118 15394 net.cpp:605] BatchNorm1 <- Convolution1
I0525 23:46:17.007125 15394 net.cpp:566] BatchNorm1 -> Convolution1 (in-place)
I0525 23:46:17.007344 15394 net.cpp:240] Setting up BatchNorm1
I0525 23:46:17.007354 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.007357 15394 net.cpp:255] Memory required for data: 14337200
I0525 23:46:17.007374 15394 layer_factory.hpp:77] Creating layer Scale1
I0525 23:46:17.007390 15394 net.cpp:190] Creating Layer Scale1
I0525 23:46:17.007395 15394 net.cpp:605] Scale1 <- Convolution1
I0525 23:46:17.007400 15394 net.cpp:566] Scale1 -> Convolution1 (in-place)
I0525 23:46:17.007458 15394 layer_factory.hpp:77] Creating layer Scale1
I0525 23:46:17.007583 15394 net.cpp:240] Setting up Scale1
I0525 23:46:17.007592 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.007603 15394 net.cpp:255] Memory required for data: 20890800
I0525 23:46:17.007612 15394 layer_factory.hpp:77] Creating layer ReLU1
I0525 23:46:17.007621 15394 net.cpp:190] Creating Layer ReLU1
I0525 23:46:17.007627 15394 net.cpp:605] ReLU1 <- Convolution1
I0525 23:46:17.007637 15394 net.cpp:566] ReLU1 -> Convolution1 (in-place)
I0525 23:46:17.007644 15394 net.cpp:240] Setting up ReLU1
I0525 23:46:17.007649 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.007652 15394 net.cpp:255] Memory required for data: 27444400
I0525 23:46:17.007657 15394 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0525 23:46:17.007663 15394 net.cpp:190] Creating Layer Convolution1_ReLU1_0_split
I0525 23:46:17.007668 15394 net.cpp:605] Convolution1_ReLU1_0_split <- Convolution1
I0525 23:46:17.007673 15394 net.cpp:579] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0525 23:46:17.007683 15394 net.cpp:579] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0525 23:46:17.007772 15394 net.cpp:240] Setting up Convolution1_ReLU1_0_split
I0525 23:46:17.007784 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.007788 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.007791 15394 net.cpp:255] Memory required for data: 40551600
I0525 23:46:17.007797 15394 layer_factory.hpp:77] Creating layer Convolution2
I0525 23:46:17.007809 15394 net.cpp:190] Creating Layer Convolution2
I0525 23:46:17.007813 15394 net.cpp:605] Convolution2 <- Convolution1_ReLU1_0_split_0
I0525 23:46:17.007822 15394 net.cpp:579] Convolution2 -> Convolution2
I0525 23:46:17.008291 15394 net.cpp:240] Setting up Convolution2
I0525 23:46:17.008306 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.008311 15394 net.cpp:255] Memory required for data: 47105200
I0525 23:46:17.008325 15394 layer_factory.hpp:77] Creating layer BatchNorm2
I0525 23:46:17.008339 15394 net.cpp:190] Creating Layer BatchNorm2
I0525 23:46:17.008344 15394 net.cpp:605] BatchNorm2 <- Convolution2
I0525 23:46:17.008354 15394 net.cpp:566] BatchNorm2 -> Convolution2 (in-place)
I0525 23:46:17.008569 15394 net.cpp:240] Setting up BatchNorm2
I0525 23:46:17.008579 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.008582 15394 net.cpp:255] Memory required for data: 53658800
I0525 23:46:17.008594 15394 layer_factory.hpp:77] Creating layer Scale2
I0525 23:46:17.008605 15394 net.cpp:190] Creating Layer Scale2
I0525 23:46:17.008608 15394 net.cpp:605] Scale2 <- Convolution2
I0525 23:46:17.008615 15394 net.cpp:566] Scale2 -> Convolution2 (in-place)
I0525 23:46:17.008666 15394 layer_factory.hpp:77] Creating layer Scale2
I0525 23:46:17.008790 15394 net.cpp:240] Setting up Scale2
I0525 23:46:17.008798 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.008803 15394 net.cpp:255] Memory required for data: 60212400
I0525 23:46:17.008812 15394 layer_factory.hpp:77] Creating layer ReLU2
I0525 23:46:17.008819 15394 net.cpp:190] Creating Layer ReLU2
I0525 23:46:17.008824 15394 net.cpp:605] ReLU2 <- Convolution2
I0525 23:46:17.008833 15394 net.cpp:566] ReLU2 -> Convolution2 (in-place)
I0525 23:46:17.008841 15394 net.cpp:240] Setting up ReLU2
I0525 23:46:17.008846 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.008851 15394 net.cpp:255] Memory required for data: 66766000
I0525 23:46:17.008853 15394 layer_factory.hpp:77] Creating layer Convolution3
I0525 23:46:17.008864 15394 net.cpp:190] Creating Layer Convolution3
I0525 23:46:17.008868 15394 net.cpp:605] Convolution3 <- Convolution2
I0525 23:46:17.008877 15394 net.cpp:579] Convolution3 -> Convolution3
I0525 23:46:17.009205 15394 net.cpp:240] Setting up Convolution3
I0525 23:46:17.009217 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.009222 15394 net.cpp:255] Memory required for data: 73319600
I0525 23:46:17.009230 15394 layer_factory.hpp:77] Creating layer BatchNorm3
I0525 23:46:17.009238 15394 net.cpp:190] Creating Layer BatchNorm3
I0525 23:46:17.009250 15394 net.cpp:605] BatchNorm3 <- Convolution3
I0525 23:46:17.009259 15394 net.cpp:566] BatchNorm3 -> Convolution3 (in-place)
I0525 23:46:17.009459 15394 net.cpp:240] Setting up BatchNorm3
I0525 23:46:17.009469 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.009472 15394 net.cpp:255] Memory required for data: 79873200
I0525 23:46:17.009486 15394 layer_factory.hpp:77] Creating layer Scale3
I0525 23:46:17.009500 15394 net.cpp:190] Creating Layer Scale3
I0525 23:46:17.009503 15394 net.cpp:605] Scale3 <- Convolution3
I0525 23:46:17.009510 15394 net.cpp:566] Scale3 -> Convolution3 (in-place)
I0525 23:46:17.009557 15394 layer_factory.hpp:77] Creating layer Scale3
I0525 23:46:17.009676 15394 net.cpp:240] Setting up Scale3
I0525 23:46:17.009685 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.009688 15394 net.cpp:255] Memory required for data: 86426800
I0525 23:46:17.009696 15394 layer_factory.hpp:77] Creating layer Eltwise1
I0525 23:46:17.009704 15394 net.cpp:190] Creating Layer Eltwise1
I0525 23:46:17.009709 15394 net.cpp:605] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0525 23:46:17.009714 15394 net.cpp:605] Eltwise1 <- Convolution3
I0525 23:46:17.009722 15394 net.cpp:579] Eltwise1 -> Eltwise1
I0525 23:46:17.009753 15394 net.cpp:240] Setting up Eltwise1
I0525 23:46:17.009760 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.009764 15394 net.cpp:255] Memory required for data: 92980400
I0525 23:46:17.009768 15394 layer_factory.hpp:77] Creating layer ReLU3
I0525 23:46:17.009774 15394 net.cpp:190] Creating Layer ReLU3
I0525 23:46:17.009778 15394 net.cpp:605] ReLU3 <- Eltwise1
I0525 23:46:17.009784 15394 net.cpp:566] ReLU3 -> Eltwise1 (in-place)
I0525 23:46:17.009793 15394 net.cpp:240] Setting up ReLU3
I0525 23:46:17.009798 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.009800 15394 net.cpp:255] Memory required for data: 99534000
I0525 23:46:17.009804 15394 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0525 23:46:17.009816 15394 net.cpp:190] Creating Layer Eltwise1_ReLU3_0_split
I0525 23:46:17.009821 15394 net.cpp:605] Eltwise1_ReLU3_0_split <- Eltwise1
I0525 23:46:17.009826 15394 net.cpp:579] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0525 23:46:17.009834 15394 net.cpp:579] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0525 23:46:17.009871 15394 net.cpp:240] Setting up Eltwise1_ReLU3_0_split
I0525 23:46:17.009878 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.009882 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.009886 15394 net.cpp:255] Memory required for data: 112641200
I0525 23:46:17.009889 15394 layer_factory.hpp:77] Creating layer Convolution4
I0525 23:46:17.009901 15394 net.cpp:190] Creating Layer Convolution4
I0525 23:46:17.009904 15394 net.cpp:605] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0525 23:46:17.009914 15394 net.cpp:579] Convolution4 -> Convolution4
I0525 23:46:17.010313 15394 net.cpp:240] Setting up Convolution4
I0525 23:46:17.010327 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.010331 15394 net.cpp:255] Memory required for data: 119194800
I0525 23:46:17.010340 15394 layer_factory.hpp:77] Creating layer BatchNorm4
I0525 23:46:17.010351 15394 net.cpp:190] Creating Layer BatchNorm4
I0525 23:46:17.010362 15394 net.cpp:605] BatchNorm4 <- Convolution4
I0525 23:46:17.010368 15394 net.cpp:566] BatchNorm4 -> Convolution4 (in-place)
I0525 23:46:17.010715 15394 net.cpp:240] Setting up BatchNorm4
I0525 23:46:17.010730 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.010735 15394 net.cpp:255] Memory required for data: 125748400
I0525 23:46:17.010746 15394 layer_factory.hpp:77] Creating layer Scale4
I0525 23:46:17.010757 15394 net.cpp:190] Creating Layer Scale4
I0525 23:46:17.010761 15394 net.cpp:605] Scale4 <- Convolution4
I0525 23:46:17.010768 15394 net.cpp:566] Scale4 -> Convolution4 (in-place)
I0525 23:46:17.010820 15394 layer_factory.hpp:77] Creating layer Scale4
I0525 23:46:17.010957 15394 net.cpp:240] Setting up Scale4
I0525 23:46:17.010974 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.010978 15394 net.cpp:255] Memory required for data: 132302000
I0525 23:46:17.010987 15394 layer_factory.hpp:77] Creating layer ReLU4
I0525 23:46:17.010998 15394 net.cpp:190] Creating Layer ReLU4
I0525 23:46:17.011001 15394 net.cpp:605] ReLU4 <- Convolution4
I0525 23:46:17.011008 15394 net.cpp:566] ReLU4 -> Convolution4 (in-place)
I0525 23:46:17.011014 15394 net.cpp:240] Setting up ReLU4
I0525 23:46:17.011020 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.011023 15394 net.cpp:255] Memory required for data: 138855600
I0525 23:46:17.011026 15394 layer_factory.hpp:77] Creating layer Convolution5
I0525 23:46:17.011040 15394 net.cpp:190] Creating Layer Convolution5
I0525 23:46:17.011044 15394 net.cpp:605] Convolution5 <- Convolution4
I0525 23:46:17.011051 15394 net.cpp:579] Convolution5 -> Convolution5
I0525 23:46:17.011385 15394 net.cpp:240] Setting up Convolution5
I0525 23:46:17.011396 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.011399 15394 net.cpp:255] Memory required for data: 145409200
I0525 23:46:17.011409 15394 layer_factory.hpp:77] Creating layer BatchNorm5
I0525 23:46:17.011418 15394 net.cpp:190] Creating Layer BatchNorm5
I0525 23:46:17.011423 15394 net.cpp:605] BatchNorm5 <- Convolution5
I0525 23:46:17.011428 15394 net.cpp:566] BatchNorm5 -> Convolution5 (in-place)
I0525 23:46:17.011628 15394 net.cpp:240] Setting up BatchNorm5
I0525 23:46:17.011637 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.011641 15394 net.cpp:255] Memory required for data: 151962800
I0525 23:46:17.011664 15394 layer_factory.hpp:77] Creating layer Scale5
I0525 23:46:17.011673 15394 net.cpp:190] Creating Layer Scale5
I0525 23:46:17.011678 15394 net.cpp:605] Scale5 <- Convolution5
I0525 23:46:17.011684 15394 net.cpp:566] Scale5 -> Convolution5 (in-place)
I0525 23:46:17.011734 15394 layer_factory.hpp:77] Creating layer Scale5
I0525 23:46:17.011862 15394 net.cpp:240] Setting up Scale5
I0525 23:46:17.011871 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.011874 15394 net.cpp:255] Memory required for data: 158516400
I0525 23:46:17.011883 15394 layer_factory.hpp:77] Creating layer Eltwise2
I0525 23:46:17.011903 15394 net.cpp:190] Creating Layer Eltwise2
I0525 23:46:17.011909 15394 net.cpp:605] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0525 23:46:17.011914 15394 net.cpp:605] Eltwise2 <- Convolution5
I0525 23:46:17.011920 15394 net.cpp:579] Eltwise2 -> Eltwise2
I0525 23:46:17.011953 15394 net.cpp:240] Setting up Eltwise2
I0525 23:46:17.011961 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.011965 15394 net.cpp:255] Memory required for data: 165070000
I0525 23:46:17.011970 15394 layer_factory.hpp:77] Creating layer ReLU5
I0525 23:46:17.011976 15394 net.cpp:190] Creating Layer ReLU5
I0525 23:46:17.011981 15394 net.cpp:605] ReLU5 <- Eltwise2
I0525 23:46:17.011991 15394 net.cpp:566] ReLU5 -> Eltwise2 (in-place)
I0525 23:46:17.011997 15394 net.cpp:240] Setting up ReLU5
I0525 23:46:17.012002 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.012006 15394 net.cpp:255] Memory required for data: 171623600
I0525 23:46:17.012009 15394 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0525 23:46:17.012017 15394 net.cpp:190] Creating Layer Eltwise2_ReLU5_0_split
I0525 23:46:17.012019 15394 net.cpp:605] Eltwise2_ReLU5_0_split <- Eltwise2
I0525 23:46:17.012025 15394 net.cpp:579] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0525 23:46:17.012032 15394 net.cpp:579] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0525 23:46:17.012073 15394 net.cpp:240] Setting up Eltwise2_ReLU5_0_split
I0525 23:46:17.012080 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.012086 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.012089 15394 net.cpp:255] Memory required for data: 184730800
I0525 23:46:17.012094 15394 layer_factory.hpp:77] Creating layer Convolution6
I0525 23:46:17.012104 15394 net.cpp:190] Creating Layer Convolution6
I0525 23:46:17.012116 15394 net.cpp:605] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0525 23:46:17.012140 15394 net.cpp:579] Convolution6 -> Convolution6
I0525 23:46:17.012465 15394 net.cpp:240] Setting up Convolution6
I0525 23:46:17.012475 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.012478 15394 net.cpp:255] Memory required for data: 191284400
I0525 23:46:17.012487 15394 layer_factory.hpp:77] Creating layer BatchNorm6
I0525 23:46:17.012495 15394 net.cpp:190] Creating Layer BatchNorm6
I0525 23:46:17.012500 15394 net.cpp:605] BatchNorm6 <- Convolution6
I0525 23:46:17.012508 15394 net.cpp:566] BatchNorm6 -> Convolution6 (in-place)
I0525 23:46:17.012707 15394 net.cpp:240] Setting up BatchNorm6
I0525 23:46:17.012717 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.012720 15394 net.cpp:255] Memory required for data: 197838000
I0525 23:46:17.012732 15394 layer_factory.hpp:77] Creating layer Scale6
I0525 23:46:17.012739 15394 net.cpp:190] Creating Layer Scale6
I0525 23:46:17.012744 15394 net.cpp:605] Scale6 <- Convolution6
I0525 23:46:17.012750 15394 net.cpp:566] Scale6 -> Convolution6 (in-place)
I0525 23:46:17.012797 15394 layer_factory.hpp:77] Creating layer Scale6
I0525 23:46:17.012915 15394 net.cpp:240] Setting up Scale6
I0525 23:46:17.012924 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.012928 15394 net.cpp:255] Memory required for data: 204391600
I0525 23:46:17.012936 15394 layer_factory.hpp:77] Creating layer ReLU6
I0525 23:46:17.012948 15394 net.cpp:190] Creating Layer ReLU6
I0525 23:46:17.012951 15394 net.cpp:605] ReLU6 <- Convolution6
I0525 23:46:17.012958 15394 net.cpp:566] ReLU6 -> Convolution6 (in-place)
I0525 23:46:17.012964 15394 net.cpp:240] Setting up ReLU6
I0525 23:46:17.012969 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.012974 15394 net.cpp:255] Memory required for data: 210945200
I0525 23:46:17.012976 15394 layer_factory.hpp:77] Creating layer Convolution7
I0525 23:46:17.012989 15394 net.cpp:190] Creating Layer Convolution7
I0525 23:46:17.012994 15394 net.cpp:605] Convolution7 <- Convolution6
I0525 23:46:17.013001 15394 net.cpp:579] Convolution7 -> Convolution7
I0525 23:46:17.014456 15394 net.cpp:240] Setting up Convolution7
I0525 23:46:17.015606 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.015626 15394 net.cpp:255] Memory required for data: 217498800
I0525 23:46:17.015645 15394 layer_factory.hpp:77] Creating layer BatchNorm7
I0525 23:46:17.015672 15394 net.cpp:190] Creating Layer BatchNorm7
I0525 23:46:17.015681 15394 net.cpp:605] BatchNorm7 <- Convolution7
I0525 23:46:17.015691 15394 net.cpp:566] BatchNorm7 -> Convolution7 (in-place)
I0525 23:46:17.016000 15394 net.cpp:240] Setting up BatchNorm7
I0525 23:46:17.016013 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.016017 15394 net.cpp:255] Memory required for data: 224052400
I0525 23:46:17.016032 15394 layer_factory.hpp:77] Creating layer Scale7
I0525 23:46:17.016047 15394 net.cpp:190] Creating Layer Scale7
I0525 23:46:17.016052 15394 net.cpp:605] Scale7 <- Convolution7
I0525 23:46:17.016058 15394 net.cpp:566] Scale7 -> Convolution7 (in-place)
I0525 23:46:17.016113 15394 layer_factory.hpp:77] Creating layer Scale7
I0525 23:46:17.016237 15394 net.cpp:240] Setting up Scale7
I0525 23:46:17.016244 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.016247 15394 net.cpp:255] Memory required for data: 230606000
I0525 23:46:17.016257 15394 layer_factory.hpp:77] Creating layer Eltwise3
I0525 23:46:17.016266 15394 net.cpp:190] Creating Layer Eltwise3
I0525 23:46:17.016273 15394 net.cpp:605] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0525 23:46:17.016278 15394 net.cpp:605] Eltwise3 <- Convolution7
I0525 23:46:17.016283 15394 net.cpp:579] Eltwise3 -> Eltwise3
I0525 23:46:17.016312 15394 net.cpp:240] Setting up Eltwise3
I0525 23:46:17.016319 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.016322 15394 net.cpp:255] Memory required for data: 237159600
I0525 23:46:17.016325 15394 layer_factory.hpp:77] Creating layer ReLU7
I0525 23:46:17.016342 15394 net.cpp:190] Creating Layer ReLU7
I0525 23:46:17.016346 15394 net.cpp:605] ReLU7 <- Eltwise3
I0525 23:46:17.016353 15394 net.cpp:566] ReLU7 -> Eltwise3 (in-place)
I0525 23:46:17.016360 15394 net.cpp:240] Setting up ReLU7
I0525 23:46:17.016366 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.016368 15394 net.cpp:255] Memory required for data: 243713200
I0525 23:46:17.016372 15394 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0525 23:46:17.016378 15394 net.cpp:190] Creating Layer Eltwise3_ReLU7_0_split
I0525 23:46:17.016382 15394 net.cpp:605] Eltwise3_ReLU7_0_split <- Eltwise3
I0525 23:46:17.016386 15394 net.cpp:579] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0525 23:46:17.016393 15394 net.cpp:579] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0525 23:46:17.016429 15394 net.cpp:240] Setting up Eltwise3_ReLU7_0_split
I0525 23:46:17.016435 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.016439 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.016443 15394 net.cpp:255] Memory required for data: 256820400
I0525 23:46:17.016446 15394 layer_factory.hpp:77] Creating layer Convolution8
I0525 23:46:17.016458 15394 net.cpp:190] Creating Layer Convolution8
I0525 23:46:17.016463 15394 net.cpp:605] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0525 23:46:17.016470 15394 net.cpp:579] Convolution8 -> Convolution8
I0525 23:46:17.018004 15394 net.cpp:240] Setting up Convolution8
I0525 23:46:17.018046 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.018051 15394 net.cpp:255] Memory required for data: 263374000
I0525 23:46:17.018066 15394 layer_factory.hpp:77] Creating layer BatchNorm8
I0525 23:46:17.018079 15394 net.cpp:190] Creating Layer BatchNorm8
I0525 23:46:17.018086 15394 net.cpp:605] BatchNorm8 <- Convolution8
I0525 23:46:17.018098 15394 net.cpp:566] BatchNorm8 -> Convolution8 (in-place)
I0525 23:46:17.018311 15394 net.cpp:240] Setting up BatchNorm8
I0525 23:46:17.018321 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.018323 15394 net.cpp:255] Memory required for data: 269927600
I0525 23:46:17.018335 15394 layer_factory.hpp:77] Creating layer Scale8
I0525 23:46:17.018344 15394 net.cpp:190] Creating Layer Scale8
I0525 23:46:17.018349 15394 net.cpp:605] Scale8 <- Convolution8
I0525 23:46:17.018365 15394 net.cpp:566] Scale8 -> Convolution8 (in-place)
I0525 23:46:17.018415 15394 layer_factory.hpp:77] Creating layer Scale8
I0525 23:46:17.018532 15394 net.cpp:240] Setting up Scale8
I0525 23:46:17.018540 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.018543 15394 net.cpp:255] Memory required for data: 276481200
I0525 23:46:17.018553 15394 layer_factory.hpp:77] Creating layer ReLU8
I0525 23:46:17.018563 15394 net.cpp:190] Creating Layer ReLU8
I0525 23:46:17.018566 15394 net.cpp:605] ReLU8 <- Convolution8
I0525 23:46:17.018571 15394 net.cpp:566] ReLU8 -> Convolution8 (in-place)
I0525 23:46:17.018579 15394 net.cpp:240] Setting up ReLU8
I0525 23:46:17.018584 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.018587 15394 net.cpp:255] Memory required for data: 283034800
I0525 23:46:17.018590 15394 layer_factory.hpp:77] Creating layer Convolution9
I0525 23:46:17.018604 15394 net.cpp:190] Creating Layer Convolution9
I0525 23:46:17.018609 15394 net.cpp:605] Convolution9 <- Convolution8
I0525 23:46:17.018615 15394 net.cpp:579] Convolution9 -> Convolution9
I0525 23:46:17.020140 15394 net.cpp:240] Setting up Convolution9
I0525 23:46:17.020181 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.020185 15394 net.cpp:255] Memory required for data: 289588400
I0525 23:46:17.020200 15394 layer_factory.hpp:77] Creating layer BatchNorm9
I0525 23:46:17.020212 15394 net.cpp:190] Creating Layer BatchNorm9
I0525 23:46:17.020220 15394 net.cpp:605] BatchNorm9 <- Convolution9
I0525 23:46:17.020231 15394 net.cpp:566] BatchNorm9 -> Convolution9 (in-place)
I0525 23:46:17.020438 15394 net.cpp:240] Setting up BatchNorm9
I0525 23:46:17.020447 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.020459 15394 net.cpp:255] Memory required for data: 296142000
I0525 23:46:17.020473 15394 layer_factory.hpp:77] Creating layer Scale9
I0525 23:46:17.020483 15394 net.cpp:190] Creating Layer Scale9
I0525 23:46:17.020486 15394 net.cpp:605] Scale9 <- Convolution9
I0525 23:46:17.020495 15394 net.cpp:566] Scale9 -> Convolution9 (in-place)
I0525 23:46:17.020542 15394 layer_factory.hpp:77] Creating layer Scale9
I0525 23:46:17.020658 15394 net.cpp:240] Setting up Scale9
I0525 23:46:17.020668 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.020671 15394 net.cpp:255] Memory required for data: 302695600
I0525 23:46:17.020679 15394 layer_factory.hpp:77] Creating layer Eltwise4
I0525 23:46:17.020689 15394 net.cpp:190] Creating Layer Eltwise4
I0525 23:46:17.020694 15394 net.cpp:605] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0525 23:46:17.020699 15394 net.cpp:605] Eltwise4 <- Convolution9
I0525 23:46:17.020704 15394 net.cpp:579] Eltwise4 -> Eltwise4
I0525 23:46:17.020733 15394 net.cpp:240] Setting up Eltwise4
I0525 23:46:17.020740 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.020742 15394 net.cpp:255] Memory required for data: 309249200
I0525 23:46:17.020745 15394 layer_factory.hpp:77] Creating layer ReLU9
I0525 23:46:17.020756 15394 net.cpp:190] Creating Layer ReLU9
I0525 23:46:17.020758 15394 net.cpp:605] ReLU9 <- Eltwise4
I0525 23:46:17.020764 15394 net.cpp:566] ReLU9 -> Eltwise4 (in-place)
I0525 23:46:17.020771 15394 net.cpp:240] Setting up ReLU9
I0525 23:46:17.020776 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.020778 15394 net.cpp:255] Memory required for data: 315802800
I0525 23:46:17.020781 15394 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0525 23:46:17.020788 15394 net.cpp:190] Creating Layer Eltwise4_ReLU9_0_split
I0525 23:46:17.020792 15394 net.cpp:605] Eltwise4_ReLU9_0_split <- Eltwise4
I0525 23:46:17.020797 15394 net.cpp:579] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0525 23:46:17.020804 15394 net.cpp:579] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0525 23:46:17.020838 15394 net.cpp:240] Setting up Eltwise4_ReLU9_0_split
I0525 23:46:17.020844 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.020848 15394 net.cpp:247] Top shape: 100 16 32 32 (1638400)
I0525 23:46:17.020851 15394 net.cpp:255] Memory required for data: 328910000
I0525 23:46:17.020854 15394 layer_factory.hpp:77] Creating layer Pooling1
I0525 23:46:17.020864 15394 net.cpp:190] Creating Layer Pooling1
I0525 23:46:17.020869 15394 net.cpp:605] Pooling1 <- Eltwise4_ReLU9_0_split_0
I0525 23:46:17.020874 15394 net.cpp:579] Pooling1 -> Pooling1
I0525 23:46:17.022048 15394 net.cpp:240] Setting up Pooling1
I0525 23:46:17.022085 15394 net.cpp:247] Top shape: 100 16 16 16 (409600)
I0525 23:46:17.022089 15394 net.cpp:255] Memory required for data: 330548400
I0525 23:46:17.022095 15394 layer_factory.hpp:77] Creating layer Input1
I0525 23:46:17.022110 15394 net.cpp:190] Creating Layer Input1
I0525 23:46:17.022121 15394 net.cpp:579] Input1 -> Input1
I0525 23:46:17.022166 15394 net.cpp:240] Setting up Input1
I0525 23:46:17.022173 15394 net.cpp:247] Top shape: 100 16 16 16 (409600)
I0525 23:46:17.022176 15394 net.cpp:255] Memory required for data: 332186800
I0525 23:46:17.022181 15394 layer_factory.hpp:77] Creating layer Concat1
I0525 23:46:17.022188 15394 net.cpp:190] Creating Layer Concat1
I0525 23:46:17.022193 15394 net.cpp:605] Concat1 <- Pooling1
I0525 23:46:17.022198 15394 net.cpp:605] Concat1 <- Input1
I0525 23:46:17.022209 15394 net.cpp:579] Concat1 -> Concat1
I0525 23:46:17.023102 15394 net.cpp:240] Setting up Concat1
I0525 23:46:17.023141 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.023145 15394 net.cpp:255] Memory required for data: 335463600
I0525 23:46:17.023151 15394 layer_factory.hpp:77] Creating layer Convolution10
I0525 23:46:17.023166 15394 net.cpp:190] Creating Layer Convolution10
I0525 23:46:17.023174 15394 net.cpp:605] Convolution10 <- Eltwise4_ReLU9_0_split_1
I0525 23:46:17.023198 15394 net.cpp:579] Convolution10 -> Convolution10
I0525 23:46:17.023654 15394 net.cpp:240] Setting up Convolution10
I0525 23:46:17.023669 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.023671 15394 net.cpp:255] Memory required for data: 338740400
I0525 23:46:17.023705 15394 layer_factory.hpp:77] Creating layer BatchNorm10
I0525 23:46:17.023715 15394 net.cpp:190] Creating Layer BatchNorm10
I0525 23:46:17.023720 15394 net.cpp:605] BatchNorm10 <- Convolution10
I0525 23:46:17.023730 15394 net.cpp:566] BatchNorm10 -> Convolution10 (in-place)
I0525 23:46:17.023936 15394 net.cpp:240] Setting up BatchNorm10
I0525 23:46:17.023946 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.023949 15394 net.cpp:255] Memory required for data: 342017200
I0525 23:46:17.023960 15394 layer_factory.hpp:77] Creating layer Scale10
I0525 23:46:17.023970 15394 net.cpp:190] Creating Layer Scale10
I0525 23:46:17.023974 15394 net.cpp:605] Scale10 <- Convolution10
I0525 23:46:17.023979 15394 net.cpp:566] Scale10 -> Convolution10 (in-place)
I0525 23:46:17.024029 15394 layer_factory.hpp:77] Creating layer Scale10
I0525 23:46:17.024189 15394 net.cpp:240] Setting up Scale10
I0525 23:46:17.024201 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.024204 15394 net.cpp:255] Memory required for data: 345294000
I0525 23:46:17.024215 15394 layer_factory.hpp:77] Creating layer ReLU10
I0525 23:46:17.024224 15394 net.cpp:190] Creating Layer ReLU10
I0525 23:46:17.024227 15394 net.cpp:605] ReLU10 <- Convolution10
I0525 23:46:17.024232 15394 net.cpp:566] ReLU10 -> Convolution10 (in-place)
I0525 23:46:17.024240 15394 net.cpp:240] Setting up ReLU10
I0525 23:46:17.024245 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.024250 15394 net.cpp:255] Memory required for data: 348570800
I0525 23:46:17.024253 15394 layer_factory.hpp:77] Creating layer Convolution11
I0525 23:46:17.024265 15394 net.cpp:190] Creating Layer Convolution11
I0525 23:46:17.024268 15394 net.cpp:605] Convolution11 <- Convolution10
I0525 23:46:17.024276 15394 net.cpp:579] Convolution11 -> Convolution11
I0525 23:46:17.024835 15394 net.cpp:240] Setting up Convolution11
I0525 23:46:17.024848 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.024852 15394 net.cpp:255] Memory required for data: 351847600
I0525 23:46:17.024860 15394 layer_factory.hpp:77] Creating layer BatchNorm11
I0525 23:46:17.024871 15394 net.cpp:190] Creating Layer BatchNorm11
I0525 23:46:17.024875 15394 net.cpp:605] BatchNorm11 <- Convolution11
I0525 23:46:17.024883 15394 net.cpp:566] BatchNorm11 -> Convolution11 (in-place)
I0525 23:46:17.025076 15394 net.cpp:240] Setting up BatchNorm11
I0525 23:46:17.025084 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.025089 15394 net.cpp:255] Memory required for data: 355124400
I0525 23:46:17.025099 15394 layer_factory.hpp:77] Creating layer Scale11
I0525 23:46:17.025107 15394 net.cpp:190] Creating Layer Scale11
I0525 23:46:17.025111 15394 net.cpp:605] Scale11 <- Convolution11
I0525 23:46:17.025120 15394 net.cpp:566] Scale11 -> Convolution11 (in-place)
I0525 23:46:17.026263 15394 layer_factory.hpp:77] Creating layer Scale11
I0525 23:46:17.026486 15394 net.cpp:240] Setting up Scale11
I0525 23:46:17.026499 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.026504 15394 net.cpp:255] Memory required for data: 358401200
I0525 23:46:17.026517 15394 layer_factory.hpp:77] Creating layer Eltwise5
I0525 23:46:17.026527 15394 net.cpp:190] Creating Layer Eltwise5
I0525 23:46:17.026535 15394 net.cpp:605] Eltwise5 <- Concat1
I0525 23:46:17.026541 15394 net.cpp:605] Eltwise5 <- Convolution11
I0525 23:46:17.026551 15394 net.cpp:579] Eltwise5 -> Eltwise5
I0525 23:46:17.026585 15394 net.cpp:240] Setting up Eltwise5
I0525 23:46:17.026592 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.026597 15394 net.cpp:255] Memory required for data: 361678000
I0525 23:46:17.026599 15394 layer_factory.hpp:77] Creating layer ReLU11
I0525 23:46:17.026607 15394 net.cpp:190] Creating Layer ReLU11
I0525 23:46:17.026619 15394 net.cpp:605] ReLU11 <- Eltwise5
I0525 23:46:17.026628 15394 net.cpp:566] ReLU11 -> Eltwise5 (in-place)
I0525 23:46:17.026634 15394 net.cpp:240] Setting up ReLU11
I0525 23:46:17.026639 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.026643 15394 net.cpp:255] Memory required for data: 364954800
I0525 23:46:17.026645 15394 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0525 23:46:17.026653 15394 net.cpp:190] Creating Layer Eltwise5_ReLU11_0_split
I0525 23:46:17.026655 15394 net.cpp:605] Eltwise5_ReLU11_0_split <- Eltwise5
I0525 23:46:17.026660 15394 net.cpp:579] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0525 23:46:17.026667 15394 net.cpp:579] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0525 23:46:17.026707 15394 net.cpp:240] Setting up Eltwise5_ReLU11_0_split
I0525 23:46:17.026713 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.026717 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.026721 15394 net.cpp:255] Memory required for data: 371508400
I0525 23:46:17.026724 15394 layer_factory.hpp:77] Creating layer Convolution12
I0525 23:46:17.026734 15394 net.cpp:190] Creating Layer Convolution12
I0525 23:46:17.026738 15394 net.cpp:605] Convolution12 <- Eltwise5_ReLU11_0_split_0
I0525 23:46:17.026747 15394 net.cpp:579] Convolution12 -> Convolution12
I0525 23:46:17.028501 15394 net.cpp:240] Setting up Convolution12
I0525 23:46:17.028538 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.028543 15394 net.cpp:255] Memory required for data: 374785200
I0525 23:46:17.028561 15394 layer_factory.hpp:77] Creating layer BatchNorm12
I0525 23:46:17.028575 15394 net.cpp:190] Creating Layer BatchNorm12
I0525 23:46:17.028583 15394 net.cpp:605] BatchNorm12 <- Convolution12
I0525 23:46:17.028594 15394 net.cpp:566] BatchNorm12 -> Convolution12 (in-place)
I0525 23:46:17.028812 15394 net.cpp:240] Setting up BatchNorm12
I0525 23:46:17.028822 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.028826 15394 net.cpp:255] Memory required for data: 378062000
I0525 23:46:17.028839 15394 layer_factory.hpp:77] Creating layer Scale12
I0525 23:46:17.028851 15394 net.cpp:190] Creating Layer Scale12
I0525 23:46:17.028854 15394 net.cpp:605] Scale12 <- Convolution12
I0525 23:46:17.028861 15394 net.cpp:566] Scale12 -> Convolution12 (in-place)
I0525 23:46:17.028908 15394 layer_factory.hpp:77] Creating layer Scale12
I0525 23:46:17.029041 15394 net.cpp:240] Setting up Scale12
I0525 23:46:17.029048 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.029052 15394 net.cpp:255] Memory required for data: 381338800
I0525 23:46:17.029060 15394 layer_factory.hpp:77] Creating layer ReLU12
I0525 23:46:17.029070 15394 net.cpp:190] Creating Layer ReLU12
I0525 23:46:17.029074 15394 net.cpp:605] ReLU12 <- Convolution12
I0525 23:46:17.029080 15394 net.cpp:566] ReLU12 -> Convolution12 (in-place)
I0525 23:46:17.029088 15394 net.cpp:240] Setting up ReLU12
I0525 23:46:17.029091 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.029095 15394 net.cpp:255] Memory required for data: 384615600
I0525 23:46:17.029098 15394 layer_factory.hpp:77] Creating layer Convolution13
I0525 23:46:17.029124 15394 net.cpp:190] Creating Layer Convolution13
I0525 23:46:17.029129 15394 net.cpp:605] Convolution13 <- Convolution12
I0525 23:46:17.029135 15394 net.cpp:579] Convolution13 -> Convolution13
I0525 23:46:17.030902 15394 net.cpp:240] Setting up Convolution13
I0525 23:46:17.030948 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.030952 15394 net.cpp:255] Memory required for data: 387892400
I0525 23:46:17.030968 15394 layer_factory.hpp:77] Creating layer BatchNorm13
I0525 23:46:17.030985 15394 net.cpp:190] Creating Layer BatchNorm13
I0525 23:46:17.030992 15394 net.cpp:605] BatchNorm13 <- Convolution13
I0525 23:46:17.031002 15394 net.cpp:566] BatchNorm13 -> Convolution13 (in-place)
I0525 23:46:17.031195 15394 net.cpp:240] Setting up BatchNorm13
I0525 23:46:17.031204 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.031219 15394 net.cpp:255] Memory required for data: 391169200
I0525 23:46:17.031231 15394 layer_factory.hpp:77] Creating layer Scale13
I0525 23:46:17.031244 15394 net.cpp:190] Creating Layer Scale13
I0525 23:46:17.031249 15394 net.cpp:605] Scale13 <- Convolution13
I0525 23:46:17.031253 15394 net.cpp:566] Scale13 -> Convolution13 (in-place)
I0525 23:46:17.031301 15394 layer_factory.hpp:77] Creating layer Scale13
I0525 23:46:17.031419 15394 net.cpp:240] Setting up Scale13
I0525 23:46:17.031427 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.031430 15394 net.cpp:255] Memory required for data: 394446000
I0525 23:46:17.031438 15394 layer_factory.hpp:77] Creating layer Eltwise6
I0525 23:46:17.031461 15394 net.cpp:190] Creating Layer Eltwise6
I0525 23:46:17.031467 15394 net.cpp:605] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0525 23:46:17.031472 15394 net.cpp:605] Eltwise6 <- Convolution13
I0525 23:46:17.031479 15394 net.cpp:579] Eltwise6 -> Eltwise6
I0525 23:46:17.031505 15394 net.cpp:240] Setting up Eltwise6
I0525 23:46:17.031512 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.031514 15394 net.cpp:255] Memory required for data: 397722800
I0525 23:46:17.031518 15394 layer_factory.hpp:77] Creating layer ReLU13
I0525 23:46:17.031524 15394 net.cpp:190] Creating Layer ReLU13
I0525 23:46:17.031528 15394 net.cpp:605] ReLU13 <- Eltwise6
I0525 23:46:17.031533 15394 net.cpp:566] ReLU13 -> Eltwise6 (in-place)
I0525 23:46:17.031539 15394 net.cpp:240] Setting up ReLU13
I0525 23:46:17.031544 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.031548 15394 net.cpp:255] Memory required for data: 400999600
I0525 23:46:17.031550 15394 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0525 23:46:17.031559 15394 net.cpp:190] Creating Layer Eltwise6_ReLU13_0_split
I0525 23:46:17.031563 15394 net.cpp:605] Eltwise6_ReLU13_0_split <- Eltwise6
I0525 23:46:17.032667 15394 net.cpp:579] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0525 23:46:17.032721 15394 net.cpp:579] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0525 23:46:17.032821 15394 net.cpp:240] Setting up Eltwise6_ReLU13_0_split
I0525 23:46:17.032832 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.032837 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.032840 15394 net.cpp:255] Memory required for data: 407553200
I0525 23:46:17.032847 15394 layer_factory.hpp:77] Creating layer Convolution14
I0525 23:46:17.032863 15394 net.cpp:190] Creating Layer Convolution14
I0525 23:46:17.032868 15394 net.cpp:605] Convolution14 <- Eltwise6_ReLU13_0_split_0
I0525 23:46:17.032877 15394 net.cpp:579] Convolution14 -> Convolution14
I0525 23:46:17.033494 15394 net.cpp:240] Setting up Convolution14
I0525 23:46:17.033514 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.033519 15394 net.cpp:255] Memory required for data: 410830000
I0525 23:46:17.033530 15394 layer_factory.hpp:77] Creating layer BatchNorm14
I0525 23:46:17.033540 15394 net.cpp:190] Creating Layer BatchNorm14
I0525 23:46:17.033545 15394 net.cpp:605] BatchNorm14 <- Convolution14
I0525 23:46:17.033555 15394 net.cpp:566] BatchNorm14 -> Convolution14 (in-place)
I0525 23:46:17.034906 15394 net.cpp:240] Setting up BatchNorm14
I0525 23:46:17.034940 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.034945 15394 net.cpp:255] Memory required for data: 414106800
I0525 23:46:17.034965 15394 layer_factory.hpp:77] Creating layer Scale14
I0525 23:46:17.034979 15394 net.cpp:190] Creating Layer Scale14
I0525 23:46:17.034986 15394 net.cpp:605] Scale14 <- Convolution14
I0525 23:46:17.034994 15394 net.cpp:566] Scale14 -> Convolution14 (in-place)
I0525 23:46:17.035056 15394 layer_factory.hpp:77] Creating layer Scale14
I0525 23:46:17.035183 15394 net.cpp:240] Setting up Scale14
I0525 23:46:17.035190 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.035194 15394 net.cpp:255] Memory required for data: 417383600
I0525 23:46:17.035203 15394 layer_factory.hpp:77] Creating layer ReLU14
I0525 23:46:17.035219 15394 net.cpp:190] Creating Layer ReLU14
I0525 23:46:17.035224 15394 net.cpp:605] ReLU14 <- Convolution14
I0525 23:46:17.035230 15394 net.cpp:566] ReLU14 -> Convolution14 (in-place)
I0525 23:46:17.035238 15394 net.cpp:240] Setting up ReLU14
I0525 23:46:17.035241 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.035245 15394 net.cpp:255] Memory required for data: 420660400
I0525 23:46:17.035248 15394 layer_factory.hpp:77] Creating layer Convolution15
I0525 23:46:17.035261 15394 net.cpp:190] Creating Layer Convolution15
I0525 23:46:17.035265 15394 net.cpp:605] Convolution15 <- Convolution14
I0525 23:46:17.035271 15394 net.cpp:579] Convolution15 -> Convolution15
I0525 23:46:17.037247 15394 net.cpp:240] Setting up Convolution15
I0525 23:46:17.037298 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.037303 15394 net.cpp:255] Memory required for data: 423937200
I0525 23:46:17.037324 15394 layer_factory.hpp:77] Creating layer BatchNorm15
I0525 23:46:17.037343 15394 net.cpp:190] Creating Layer BatchNorm15
I0525 23:46:17.037353 15394 net.cpp:605] BatchNorm15 <- Convolution15
I0525 23:46:17.037365 15394 net.cpp:566] BatchNorm15 -> Convolution15 (in-place)
I0525 23:46:17.037657 15394 net.cpp:240] Setting up BatchNorm15
I0525 23:46:17.037667 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.037670 15394 net.cpp:255] Memory required for data: 427214000
I0525 23:46:17.037683 15394 layer_factory.hpp:77] Creating layer Scale15
I0525 23:46:17.037694 15394 net.cpp:190] Creating Layer Scale15
I0525 23:46:17.037698 15394 net.cpp:605] Scale15 <- Convolution15
I0525 23:46:17.037704 15394 net.cpp:566] Scale15 -> Convolution15 (in-place)
I0525 23:46:17.037760 15394 layer_factory.hpp:77] Creating layer Scale15
I0525 23:46:17.037881 15394 net.cpp:240] Setting up Scale15
I0525 23:46:17.037890 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.037894 15394 net.cpp:255] Memory required for data: 430490800
I0525 23:46:17.037902 15394 layer_factory.hpp:77] Creating layer Eltwise7
I0525 23:46:17.037914 15394 net.cpp:190] Creating Layer Eltwise7
I0525 23:46:17.037919 15394 net.cpp:605] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0525 23:46:17.037925 15394 net.cpp:605] Eltwise7 <- Convolution15
I0525 23:46:17.037931 15394 net.cpp:579] Eltwise7 -> Eltwise7
I0525 23:46:17.037956 15394 net.cpp:240] Setting up Eltwise7
I0525 23:46:17.037962 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.037966 15394 net.cpp:255] Memory required for data: 433767600
I0525 23:46:17.037969 15394 layer_factory.hpp:77] Creating layer ReLU15
I0525 23:46:17.037978 15394 net.cpp:190] Creating Layer ReLU15
I0525 23:46:17.037981 15394 net.cpp:605] ReLU15 <- Eltwise7
I0525 23:46:17.037989 15394 net.cpp:566] ReLU15 -> Eltwise7 (in-place)
I0525 23:46:17.037997 15394 net.cpp:240] Setting up ReLU15
I0525 23:46:17.038002 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.038004 15394 net.cpp:255] Memory required for data: 437044400
I0525 23:46:17.038008 15394 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0525 23:46:17.038014 15394 net.cpp:190] Creating Layer Eltwise7_ReLU15_0_split
I0525 23:46:17.038018 15394 net.cpp:605] Eltwise7_ReLU15_0_split <- Eltwise7
I0525 23:46:17.038022 15394 net.cpp:579] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0525 23:46:17.038029 15394 net.cpp:579] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0525 23:46:17.038065 15394 net.cpp:240] Setting up Eltwise7_ReLU15_0_split
I0525 23:46:17.038071 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.038076 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.038079 15394 net.cpp:255] Memory required for data: 443598000
I0525 23:46:17.038084 15394 layer_factory.hpp:77] Creating layer Convolution16
I0525 23:46:17.038099 15394 net.cpp:190] Creating Layer Convolution16
I0525 23:46:17.038103 15394 net.cpp:605] Convolution16 <- Eltwise7_ReLU15_0_split_0
I0525 23:46:17.038110 15394 net.cpp:579] Convolution16 -> Convolution16
I0525 23:46:17.038727 15394 net.cpp:240] Setting up Convolution16
I0525 23:46:17.038753 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.038758 15394 net.cpp:255] Memory required for data: 446874800
I0525 23:46:17.038769 15394 layer_factory.hpp:77] Creating layer BatchNorm16
I0525 23:46:17.038782 15394 net.cpp:190] Creating Layer BatchNorm16
I0525 23:46:17.038787 15394 net.cpp:605] BatchNorm16 <- Convolution16
I0525 23:46:17.038795 15394 net.cpp:566] BatchNorm16 -> Convolution16 (in-place)
I0525 23:46:17.038990 15394 net.cpp:240] Setting up BatchNorm16
I0525 23:46:17.038997 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.039001 15394 net.cpp:255] Memory required for data: 450151600
I0525 23:46:17.039012 15394 layer_factory.hpp:77] Creating layer Scale16
I0525 23:46:17.039024 15394 net.cpp:190] Creating Layer Scale16
I0525 23:46:17.039028 15394 net.cpp:605] Scale16 <- Convolution16
I0525 23:46:17.039033 15394 net.cpp:566] Scale16 -> Convolution16 (in-place)
I0525 23:46:17.039082 15394 layer_factory.hpp:77] Creating layer Scale16
I0525 23:46:17.039211 15394 net.cpp:240] Setting up Scale16
I0525 23:46:17.039218 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.039222 15394 net.cpp:255] Memory required for data: 453428400
I0525 23:46:17.039230 15394 layer_factory.hpp:77] Creating layer ReLU16
I0525 23:46:17.039240 15394 net.cpp:190] Creating Layer ReLU16
I0525 23:46:17.039245 15394 net.cpp:605] ReLU16 <- Convolution16
I0525 23:46:17.039250 15394 net.cpp:566] ReLU16 -> Convolution16 (in-place)
I0525 23:46:17.039258 15394 net.cpp:240] Setting up ReLU16
I0525 23:46:17.039261 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.039264 15394 net.cpp:255] Memory required for data: 456705200
I0525 23:46:17.039268 15394 layer_factory.hpp:77] Creating layer Convolution17
I0525 23:46:17.039283 15394 net.cpp:190] Creating Layer Convolution17
I0525 23:46:17.039288 15394 net.cpp:605] Convolution17 <- Convolution16
I0525 23:46:17.039295 15394 net.cpp:579] Convolution17 -> Convolution17
I0525 23:46:17.039897 15394 net.cpp:240] Setting up Convolution17
I0525 23:46:17.039912 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.039916 15394 net.cpp:255] Memory required for data: 459982000
I0525 23:46:17.039926 15394 layer_factory.hpp:77] Creating layer BatchNorm17
I0525 23:46:17.039935 15394 net.cpp:190] Creating Layer BatchNorm17
I0525 23:46:17.039940 15394 net.cpp:605] BatchNorm17 <- Convolution17
I0525 23:46:17.039945 15394 net.cpp:566] BatchNorm17 -> Convolution17 (in-place)
I0525 23:46:17.042387 15394 net.cpp:240] Setting up BatchNorm17
I0525 23:46:17.042429 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.042433 15394 net.cpp:255] Memory required for data: 463258800
I0525 23:46:17.042459 15394 layer_factory.hpp:77] Creating layer Scale17
I0525 23:46:17.042476 15394 net.cpp:190] Creating Layer Scale17
I0525 23:46:17.042484 15394 net.cpp:605] Scale17 <- Convolution17
I0525 23:46:17.042493 15394 net.cpp:566] Scale17 -> Convolution17 (in-place)
I0525 23:46:17.042630 15394 layer_factory.hpp:77] Creating layer Scale17
I0525 23:46:17.042786 15394 net.cpp:240] Setting up Scale17
I0525 23:46:17.042793 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.042796 15394 net.cpp:255] Memory required for data: 466535600
I0525 23:46:17.042807 15394 layer_factory.hpp:77] Creating layer Eltwise8
I0525 23:46:17.042817 15394 net.cpp:190] Creating Layer Eltwise8
I0525 23:46:17.042824 15394 net.cpp:605] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0525 23:46:17.042830 15394 net.cpp:605] Eltwise8 <- Convolution17
I0525 23:46:17.042840 15394 net.cpp:579] Eltwise8 -> Eltwise8
I0525 23:46:17.042865 15394 net.cpp:240] Setting up Eltwise8
I0525 23:46:17.042870 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.042873 15394 net.cpp:255] Memory required for data: 469812400
I0525 23:46:17.042877 15394 layer_factory.hpp:77] Creating layer ReLU17
I0525 23:46:17.042886 15394 net.cpp:190] Creating Layer ReLU17
I0525 23:46:17.042889 15394 net.cpp:605] ReLU17 <- Eltwise8
I0525 23:46:17.042903 15394 net.cpp:566] ReLU17 -> Eltwise8 (in-place)
I0525 23:46:17.042911 15394 net.cpp:240] Setting up ReLU17
I0525 23:46:17.042915 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.042918 15394 net.cpp:255] Memory required for data: 473089200
I0525 23:46:17.042922 15394 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0525 23:46:17.042928 15394 net.cpp:190] Creating Layer Eltwise8_ReLU17_0_split
I0525 23:46:17.042932 15394 net.cpp:605] Eltwise8_ReLU17_0_split <- Eltwise8
I0525 23:46:17.042937 15394 net.cpp:579] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0525 23:46:17.042943 15394 net.cpp:579] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0525 23:46:17.042984 15394 net.cpp:240] Setting up Eltwise8_ReLU17_0_split
I0525 23:46:17.042990 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.042995 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.042999 15394 net.cpp:255] Memory required for data: 479642800
I0525 23:46:17.043001 15394 layer_factory.hpp:77] Creating layer Convolution18
I0525 23:46:17.043016 15394 net.cpp:190] Creating Layer Convolution18
I0525 23:46:17.043020 15394 net.cpp:605] Convolution18 <- Eltwise8_ReLU17_0_split_0
I0525 23:46:17.043030 15394 net.cpp:579] Convolution18 -> Convolution18
I0525 23:46:17.044555 15394 net.cpp:240] Setting up Convolution18
I0525 23:46:17.044600 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.044605 15394 net.cpp:255] Memory required for data: 482919600
I0525 23:46:17.044621 15394 layer_factory.hpp:77] Creating layer BatchNorm18
I0525 23:46:17.044641 15394 net.cpp:190] Creating Layer BatchNorm18
I0525 23:46:17.044648 15394 net.cpp:605] BatchNorm18 <- Convolution18
I0525 23:46:17.044658 15394 net.cpp:566] BatchNorm18 -> Convolution18 (in-place)
I0525 23:46:17.044874 15394 net.cpp:240] Setting up BatchNorm18
I0525 23:46:17.044883 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.044885 15394 net.cpp:255] Memory required for data: 486196400
I0525 23:46:17.044896 15394 layer_factory.hpp:77] Creating layer Scale18
I0525 23:46:17.044909 15394 net.cpp:190] Creating Layer Scale18
I0525 23:46:17.044912 15394 net.cpp:605] Scale18 <- Convolution18
I0525 23:46:17.044919 15394 net.cpp:566] Scale18 -> Convolution18 (in-place)
I0525 23:46:17.044971 15394 layer_factory.hpp:77] Creating layer Scale18
I0525 23:46:17.045112 15394 net.cpp:240] Setting up Scale18
I0525 23:46:17.045120 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.045125 15394 net.cpp:255] Memory required for data: 489473200
I0525 23:46:17.045132 15394 layer_factory.hpp:77] Creating layer ReLU18
I0525 23:46:17.045142 15394 net.cpp:190] Creating Layer ReLU18
I0525 23:46:17.045147 15394 net.cpp:605] ReLU18 <- Convolution18
I0525 23:46:17.045153 15394 net.cpp:566] ReLU18 -> Convolution18 (in-place)
I0525 23:46:17.045161 15394 net.cpp:240] Setting up ReLU18
I0525 23:46:17.045166 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.045168 15394 net.cpp:255] Memory required for data: 492750000
I0525 23:46:17.045172 15394 layer_factory.hpp:77] Creating layer Convolution19
I0525 23:46:17.045186 15394 net.cpp:190] Creating Layer Convolution19
I0525 23:46:17.045189 15394 net.cpp:605] Convolution19 <- Convolution18
I0525 23:46:17.045197 15394 net.cpp:579] Convolution19 -> Convolution19
I0525 23:46:17.045769 15394 net.cpp:240] Setting up Convolution19
I0525 23:46:17.045783 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.045788 15394 net.cpp:255] Memory required for data: 496026800
I0525 23:46:17.045797 15394 layer_factory.hpp:77] Creating layer BatchNorm19
I0525 23:46:17.045810 15394 net.cpp:190] Creating Layer BatchNorm19
I0525 23:46:17.045814 15394 net.cpp:605] BatchNorm19 <- Convolution19
I0525 23:46:17.045820 15394 net.cpp:566] BatchNorm19 -> Convolution19 (in-place)
I0525 23:46:17.046010 15394 net.cpp:240] Setting up BatchNorm19
I0525 23:46:17.046016 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.046020 15394 net.cpp:255] Memory required for data: 499303600
I0525 23:46:17.046073 15394 layer_factory.hpp:77] Creating layer Scale19
I0525 23:46:17.046085 15394 net.cpp:190] Creating Layer Scale19
I0525 23:46:17.046090 15394 net.cpp:605] Scale19 <- Convolution19
I0525 23:46:17.046097 15394 net.cpp:566] Scale19 -> Convolution19 (in-place)
I0525 23:46:17.046149 15394 layer_factory.hpp:77] Creating layer Scale19
I0525 23:46:17.046263 15394 net.cpp:240] Setting up Scale19
I0525 23:46:17.046272 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.046274 15394 net.cpp:255] Memory required for data: 502580400
I0525 23:46:17.046283 15394 layer_factory.hpp:77] Creating layer Eltwise9
I0525 23:46:17.046294 15394 net.cpp:190] Creating Layer Eltwise9
I0525 23:46:17.046301 15394 net.cpp:605] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0525 23:46:17.046306 15394 net.cpp:605] Eltwise9 <- Convolution19
I0525 23:46:17.046313 15394 net.cpp:579] Eltwise9 -> Eltwise9
I0525 23:46:17.046334 15394 net.cpp:240] Setting up Eltwise9
I0525 23:46:17.046340 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.046344 15394 net.cpp:255] Memory required for data: 505857200
I0525 23:46:17.046347 15394 layer_factory.hpp:77] Creating layer ReLU19
I0525 23:46:17.046365 15394 net.cpp:190] Creating Layer ReLU19
I0525 23:46:17.046370 15394 net.cpp:605] ReLU19 <- Eltwise9
I0525 23:46:17.046375 15394 net.cpp:566] ReLU19 -> Eltwise9 (in-place)
I0525 23:46:17.046381 15394 net.cpp:240] Setting up ReLU19
I0525 23:46:17.046386 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.046388 15394 net.cpp:255] Memory required for data: 509134000
I0525 23:46:17.046392 15394 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0525 23:46:17.046402 15394 net.cpp:190] Creating Layer Eltwise9_ReLU19_0_split
I0525 23:46:17.046406 15394 net.cpp:605] Eltwise9_ReLU19_0_split <- Eltwise9
I0525 23:46:17.046411 15394 net.cpp:579] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0525 23:46:17.046418 15394 net.cpp:579] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0525 23:46:17.046458 15394 net.cpp:240] Setting up Eltwise9_ReLU19_0_split
I0525 23:46:17.046463 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.046468 15394 net.cpp:247] Top shape: 100 32 16 16 (819200)
I0525 23:46:17.046470 15394 net.cpp:255] Memory required for data: 515687600
I0525 23:46:17.046474 15394 layer_factory.hpp:77] Creating layer Pooling2
I0525 23:46:17.046483 15394 net.cpp:190] Creating Layer Pooling2
I0525 23:46:17.046486 15394 net.cpp:605] Pooling2 <- Eltwise9_ReLU19_0_split_0
I0525 23:46:17.046491 15394 net.cpp:579] Pooling2 -> Pooling2
I0525 23:46:17.046515 15394 net.cpp:240] Setting up Pooling2
I0525 23:46:17.046521 15394 net.cpp:247] Top shape: 100 32 8 8 (204800)
I0525 23:46:17.046525 15394 net.cpp:255] Memory required for data: 516506800
I0525 23:46:17.046527 15394 layer_factory.hpp:77] Creating layer Input2
I0525 23:46:17.046541 15394 net.cpp:190] Creating Layer Input2
I0525 23:46:17.046546 15394 net.cpp:579] Input2 -> Input2
I0525 23:46:17.046571 15394 net.cpp:240] Setting up Input2
I0525 23:46:17.046576 15394 net.cpp:247] Top shape: 100 32 8 8 (204800)
I0525 23:46:17.046578 15394 net.cpp:255] Memory required for data: 517326000
I0525 23:46:17.046582 15394 layer_factory.hpp:77] Creating layer Concat2
I0525 23:46:17.046592 15394 net.cpp:190] Creating Layer Concat2
I0525 23:46:17.046597 15394 net.cpp:605] Concat2 <- Pooling2
I0525 23:46:17.046600 15394 net.cpp:605] Concat2 <- Input2
I0525 23:46:17.046607 15394 net.cpp:579] Concat2 -> Concat2
I0525 23:46:17.046633 15394 net.cpp:240] Setting up Concat2
I0525 23:46:17.046638 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.046641 15394 net.cpp:255] Memory required for data: 518964400
I0525 23:46:17.046645 15394 layer_factory.hpp:77] Creating layer Convolution20
I0525 23:46:17.046658 15394 net.cpp:190] Creating Layer Convolution20
I0525 23:46:17.046663 15394 net.cpp:605] Convolution20 <- Eltwise9_ReLU19_0_split_1
I0525 23:46:17.046672 15394 net.cpp:579] Convolution20 -> Convolution20
I0525 23:46:17.047616 15394 net.cpp:240] Setting up Convolution20
I0525 23:46:17.047648 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.047653 15394 net.cpp:255] Memory required for data: 520602800
I0525 23:46:17.047667 15394 layer_factory.hpp:77] Creating layer BatchNorm20
I0525 23:46:17.047683 15394 net.cpp:190] Creating Layer BatchNorm20
I0525 23:46:17.047689 15394 net.cpp:605] BatchNorm20 <- Convolution20
I0525 23:46:17.047698 15394 net.cpp:566] BatchNorm20 -> Convolution20 (in-place)
I0525 23:46:17.047905 15394 net.cpp:240] Setting up BatchNorm20
I0525 23:46:17.047914 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.047916 15394 net.cpp:255] Memory required for data: 522241200
I0525 23:46:17.047927 15394 layer_factory.hpp:77] Creating layer Scale20
I0525 23:46:17.047940 15394 net.cpp:190] Creating Layer Scale20
I0525 23:46:17.047943 15394 net.cpp:605] Scale20 <- Convolution20
I0525 23:46:17.047950 15394 net.cpp:566] Scale20 -> Convolution20 (in-place)
I0525 23:46:17.048002 15394 layer_factory.hpp:77] Creating layer Scale20
I0525 23:46:17.048120 15394 net.cpp:240] Setting up Scale20
I0525 23:46:17.048127 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.048130 15394 net.cpp:255] Memory required for data: 523879600
I0525 23:46:17.048141 15394 layer_factory.hpp:77] Creating layer ReLU20
I0525 23:46:17.048148 15394 net.cpp:190] Creating Layer ReLU20
I0525 23:46:17.048152 15394 net.cpp:605] ReLU20 <- Convolution20
I0525 23:46:17.048161 15394 net.cpp:566] ReLU20 -> Convolution20 (in-place)
I0525 23:46:17.048167 15394 net.cpp:240] Setting up ReLU20
I0525 23:46:17.048171 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.048174 15394 net.cpp:255] Memory required for data: 525518000
I0525 23:46:17.048178 15394 layer_factory.hpp:77] Creating layer Convolution21
I0525 23:46:17.048190 15394 net.cpp:190] Creating Layer Convolution21
I0525 23:46:17.048193 15394 net.cpp:605] Convolution21 <- Convolution20
I0525 23:46:17.048202 15394 net.cpp:579] Convolution21 -> Convolution21
I0525 23:46:17.049799 15394 net.cpp:240] Setting up Convolution21
I0525 23:46:17.049830 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.049834 15394 net.cpp:255] Memory required for data: 527156400
I0525 23:46:17.049849 15394 layer_factory.hpp:77] Creating layer BatchNorm21
I0525 23:46:17.049863 15394 net.cpp:190] Creating Layer BatchNorm21
I0525 23:46:17.049870 15394 net.cpp:605] BatchNorm21 <- Convolution21
I0525 23:46:17.049880 15394 net.cpp:566] BatchNorm21 -> Convolution21 (in-place)
I0525 23:46:17.050086 15394 net.cpp:240] Setting up BatchNorm21
I0525 23:46:17.050093 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.050097 15394 net.cpp:255] Memory required for data: 528794800
I0525 23:46:17.050108 15394 layer_factory.hpp:77] Creating layer Scale21
I0525 23:46:17.050119 15394 net.cpp:190] Creating Layer Scale21
I0525 23:46:17.050124 15394 net.cpp:605] Scale21 <- Convolution21
I0525 23:46:17.050129 15394 net.cpp:566] Scale21 -> Convolution21 (in-place)
I0525 23:46:17.050181 15394 layer_factory.hpp:77] Creating layer Scale21
I0525 23:46:17.050313 15394 net.cpp:240] Setting up Scale21
I0525 23:46:17.050323 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.050326 15394 net.cpp:255] Memory required for data: 530433200
I0525 23:46:17.050334 15394 layer_factory.hpp:77] Creating layer Eltwise10
I0525 23:46:17.050345 15394 net.cpp:190] Creating Layer Eltwise10
I0525 23:46:17.050351 15394 net.cpp:605] Eltwise10 <- Concat2
I0525 23:46:17.050366 15394 net.cpp:605] Eltwise10 <- Convolution21
I0525 23:46:17.050374 15394 net.cpp:579] Eltwise10 -> Eltwise10
I0525 23:46:17.050405 15394 net.cpp:240] Setting up Eltwise10
I0525 23:46:17.050411 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.050415 15394 net.cpp:255] Memory required for data: 532071600
I0525 23:46:17.050418 15394 layer_factory.hpp:77] Creating layer ReLU21
I0525 23:46:17.050426 15394 net.cpp:190] Creating Layer ReLU21
I0525 23:46:17.050429 15394 net.cpp:605] ReLU21 <- Eltwise10
I0525 23:46:17.050436 15394 net.cpp:566] ReLU21 -> Eltwise10 (in-place)
I0525 23:46:17.050448 15394 net.cpp:240] Setting up ReLU21
I0525 23:46:17.050453 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.050457 15394 net.cpp:255] Memory required for data: 533710000
I0525 23:46:17.050460 15394 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0525 23:46:17.050467 15394 net.cpp:190] Creating Layer Eltwise10_ReLU21_0_split
I0525 23:46:17.050470 15394 net.cpp:605] Eltwise10_ReLU21_0_split <- Eltwise10
I0525 23:46:17.050475 15394 net.cpp:579] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0525 23:46:17.050482 15394 net.cpp:579] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0525 23:46:17.050518 15394 net.cpp:240] Setting up Eltwise10_ReLU21_0_split
I0525 23:46:17.050524 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.050529 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.050531 15394 net.cpp:255] Memory required for data: 536986800
I0525 23:46:17.050535 15394 layer_factory.hpp:77] Creating layer Convolution22
I0525 23:46:17.050546 15394 net.cpp:190] Creating Layer Convolution22
I0525 23:46:17.050550 15394 net.cpp:605] Convolution22 <- Eltwise10_ReLU21_0_split_0
I0525 23:46:17.050560 15394 net.cpp:579] Convolution22 -> Convolution22
I0525 23:46:17.052186 15394 net.cpp:240] Setting up Convolution22
I0525 23:46:17.052213 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.052217 15394 net.cpp:255] Memory required for data: 538625200
I0525 23:46:17.052234 15394 layer_factory.hpp:77] Creating layer BatchNorm22
I0525 23:46:17.052248 15394 net.cpp:190] Creating Layer BatchNorm22
I0525 23:46:17.052256 15394 net.cpp:605] BatchNorm22 <- Convolution22
I0525 23:46:17.052265 15394 net.cpp:566] BatchNorm22 -> Convolution22 (in-place)
I0525 23:46:17.052474 15394 net.cpp:240] Setting up BatchNorm22
I0525 23:46:17.052481 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.052484 15394 net.cpp:255] Memory required for data: 540263600
I0525 23:46:17.052495 15394 layer_factory.hpp:77] Creating layer Scale22
I0525 23:46:17.052506 15394 net.cpp:190] Creating Layer Scale22
I0525 23:46:17.052510 15394 net.cpp:605] Scale22 <- Convolution22
I0525 23:46:17.052516 15394 net.cpp:566] Scale22 -> Convolution22 (in-place)
I0525 23:46:17.052569 15394 layer_factory.hpp:77] Creating layer Scale22
I0525 23:46:17.052695 15394 net.cpp:240] Setting up Scale22
I0525 23:46:17.052701 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.052705 15394 net.cpp:255] Memory required for data: 541902000
I0525 23:46:17.052713 15394 layer_factory.hpp:77] Creating layer ReLU22
I0525 23:46:17.052723 15394 net.cpp:190] Creating Layer ReLU22
I0525 23:46:17.052727 15394 net.cpp:605] ReLU22 <- Convolution22
I0525 23:46:17.052732 15394 net.cpp:566] ReLU22 -> Convolution22 (in-place)
I0525 23:46:17.052739 15394 net.cpp:240] Setting up ReLU22
I0525 23:46:17.052743 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.052747 15394 net.cpp:255] Memory required for data: 543540400
I0525 23:46:17.052750 15394 layer_factory.hpp:77] Creating layer Convolution23
I0525 23:46:17.052765 15394 net.cpp:190] Creating Layer Convolution23
I0525 23:46:17.052769 15394 net.cpp:605] Convolution23 <- Convolution22
I0525 23:46:17.052778 15394 net.cpp:579] Convolution23 -> Convolution23
I0525 23:46:17.054420 15394 net.cpp:240] Setting up Convolution23
I0525 23:46:17.054458 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.054463 15394 net.cpp:255] Memory required for data: 545178800
I0525 23:46:17.054481 15394 layer_factory.hpp:77] Creating layer BatchNorm23
I0525 23:46:17.054507 15394 net.cpp:190] Creating Layer BatchNorm23
I0525 23:46:17.054515 15394 net.cpp:605] BatchNorm23 <- Convolution23
I0525 23:46:17.054525 15394 net.cpp:566] BatchNorm23 -> Convolution23 (in-place)
I0525 23:46:17.054734 15394 net.cpp:240] Setting up BatchNorm23
I0525 23:46:17.054743 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.054746 15394 net.cpp:255] Memory required for data: 546817200
I0525 23:46:17.054765 15394 layer_factory.hpp:77] Creating layer Scale23
I0525 23:46:17.054775 15394 net.cpp:190] Creating Layer Scale23
I0525 23:46:17.054780 15394 net.cpp:605] Scale23 <- Convolution23
I0525 23:46:17.054785 15394 net.cpp:566] Scale23 -> Convolution23 (in-place)
I0525 23:46:17.054837 15394 layer_factory.hpp:77] Creating layer Scale23
I0525 23:46:17.054957 15394 net.cpp:240] Setting up Scale23
I0525 23:46:17.054965 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.054968 15394 net.cpp:255] Memory required for data: 548455600
I0525 23:46:17.054976 15394 layer_factory.hpp:77] Creating layer Eltwise11
I0525 23:46:17.054988 15394 net.cpp:190] Creating Layer Eltwise11
I0525 23:46:17.054994 15394 net.cpp:605] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0525 23:46:17.055001 15394 net.cpp:605] Eltwise11 <- Convolution23
I0525 23:46:17.055006 15394 net.cpp:579] Eltwise11 -> Eltwise11
I0525 23:46:17.055032 15394 net.cpp:240] Setting up Eltwise11
I0525 23:46:17.055038 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.055042 15394 net.cpp:255] Memory required for data: 550094000
I0525 23:46:17.055044 15394 layer_factory.hpp:77] Creating layer ReLU23
I0525 23:46:17.055054 15394 net.cpp:190] Creating Layer ReLU23
I0525 23:46:17.055058 15394 net.cpp:605] ReLU23 <- Eltwise11
I0525 23:46:17.055063 15394 net.cpp:566] ReLU23 -> Eltwise11 (in-place)
I0525 23:46:17.055069 15394 net.cpp:240] Setting up ReLU23
I0525 23:46:17.055074 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.055078 15394 net.cpp:255] Memory required for data: 551732400
I0525 23:46:17.055081 15394 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0525 23:46:17.055088 15394 net.cpp:190] Creating Layer Eltwise11_ReLU23_0_split
I0525 23:46:17.055091 15394 net.cpp:605] Eltwise11_ReLU23_0_split <- Eltwise11
I0525 23:46:17.055096 15394 net.cpp:579] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0525 23:46:17.055102 15394 net.cpp:579] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0525 23:46:17.055136 15394 net.cpp:240] Setting up Eltwise11_ReLU23_0_split
I0525 23:46:17.055142 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.055146 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.055150 15394 net.cpp:255] Memory required for data: 555009200
I0525 23:46:17.055153 15394 layer_factory.hpp:77] Creating layer Convolution24
I0525 23:46:17.055167 15394 net.cpp:190] Creating Layer Convolution24
I0525 23:46:17.055171 15394 net.cpp:605] Convolution24 <- Eltwise11_ReLU23_0_split_0
I0525 23:46:17.055178 15394 net.cpp:579] Convolution24 -> Convolution24
I0525 23:46:17.057682 15394 net.cpp:240] Setting up Convolution24
I0525 23:46:17.057728 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.057731 15394 net.cpp:255] Memory required for data: 556647600
I0525 23:46:17.057749 15394 layer_factory.hpp:77] Creating layer BatchNorm24
I0525 23:46:17.057770 15394 net.cpp:190] Creating Layer BatchNorm24
I0525 23:46:17.057780 15394 net.cpp:605] BatchNorm24 <- Convolution24
I0525 23:46:17.057786 15394 net.cpp:566] BatchNorm24 -> Convolution24 (in-place)
I0525 23:46:17.058020 15394 net.cpp:240] Setting up BatchNorm24
I0525 23:46:17.058028 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.058032 15394 net.cpp:255] Memory required for data: 558286000
I0525 23:46:17.058043 15394 layer_factory.hpp:77] Creating layer Scale24
I0525 23:46:17.058053 15394 net.cpp:190] Creating Layer Scale24
I0525 23:46:17.058058 15394 net.cpp:605] Scale24 <- Convolution24
I0525 23:46:17.058063 15394 net.cpp:566] Scale24 -> Convolution24 (in-place)
I0525 23:46:17.058120 15394 layer_factory.hpp:77] Creating layer Scale24
I0525 23:46:17.058253 15394 net.cpp:240] Setting up Scale24
I0525 23:46:17.058260 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.058264 15394 net.cpp:255] Memory required for data: 559924400
I0525 23:46:17.058272 15394 layer_factory.hpp:77] Creating layer ReLU24
I0525 23:46:17.058280 15394 net.cpp:190] Creating Layer ReLU24
I0525 23:46:17.058284 15394 net.cpp:605] ReLU24 <- Convolution24
I0525 23:46:17.058297 15394 net.cpp:566] ReLU24 -> Convolution24 (in-place)
I0525 23:46:17.058305 15394 net.cpp:240] Setting up ReLU24
I0525 23:46:17.058310 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.058313 15394 net.cpp:255] Memory required for data: 561562800
I0525 23:46:17.058317 15394 layer_factory.hpp:77] Creating layer Convolution25
I0525 23:46:17.058331 15394 net.cpp:190] Creating Layer Convolution25
I0525 23:46:17.058336 15394 net.cpp:605] Convolution25 <- Convolution24
I0525 23:46:17.058341 15394 net.cpp:579] Convolution25 -> Convolution25
I0525 23:46:17.059952 15394 net.cpp:240] Setting up Convolution25
I0525 23:46:17.059988 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.059991 15394 net.cpp:255] Memory required for data: 563201200
I0525 23:46:17.060008 15394 layer_factory.hpp:77] Creating layer BatchNorm25
I0525 23:46:17.060058 15394 net.cpp:190] Creating Layer BatchNorm25
I0525 23:46:17.060067 15394 net.cpp:605] BatchNorm25 <- Convolution25
I0525 23:46:17.060076 15394 net.cpp:566] BatchNorm25 -> Convolution25 (in-place)
I0525 23:46:17.060293 15394 net.cpp:240] Setting up BatchNorm25
I0525 23:46:17.060302 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.060305 15394 net.cpp:255] Memory required for data: 564839600
I0525 23:46:17.060319 15394 layer_factory.hpp:77] Creating layer Scale25
I0525 23:46:17.060330 15394 net.cpp:190] Creating Layer Scale25
I0525 23:46:17.060335 15394 net.cpp:605] Scale25 <- Convolution25
I0525 23:46:17.060340 15394 net.cpp:566] Scale25 -> Convolution25 (in-place)
I0525 23:46:17.060396 15394 layer_factory.hpp:77] Creating layer Scale25
I0525 23:46:17.060516 15394 net.cpp:240] Setting up Scale25
I0525 23:46:17.060523 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.060528 15394 net.cpp:255] Memory required for data: 566478000
I0525 23:46:17.060535 15394 layer_factory.hpp:77] Creating layer Eltwise12
I0525 23:46:17.060546 15394 net.cpp:190] Creating Layer Eltwise12
I0525 23:46:17.060554 15394 net.cpp:605] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0525 23:46:17.060559 15394 net.cpp:605] Eltwise12 <- Convolution25
I0525 23:46:17.060564 15394 net.cpp:579] Eltwise12 -> Eltwise12
I0525 23:46:17.060595 15394 net.cpp:240] Setting up Eltwise12
I0525 23:46:17.060601 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.060605 15394 net.cpp:255] Memory required for data: 568116400
I0525 23:46:17.060608 15394 layer_factory.hpp:77] Creating layer ReLU25
I0525 23:46:17.060616 15394 net.cpp:190] Creating Layer ReLU25
I0525 23:46:17.060619 15394 net.cpp:605] ReLU25 <- Eltwise12
I0525 23:46:17.060624 15394 net.cpp:566] ReLU25 -> Eltwise12 (in-place)
I0525 23:46:17.060631 15394 net.cpp:240] Setting up ReLU25
I0525 23:46:17.060636 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.060639 15394 net.cpp:255] Memory required for data: 569754800
I0525 23:46:17.060642 15394 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I0525 23:46:17.060649 15394 net.cpp:190] Creating Layer Eltwise12_ReLU25_0_split
I0525 23:46:17.060652 15394 net.cpp:605] Eltwise12_ReLU25_0_split <- Eltwise12
I0525 23:46:17.060657 15394 net.cpp:579] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I0525 23:46:17.060664 15394 net.cpp:579] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I0525 23:46:17.060700 15394 net.cpp:240] Setting up Eltwise12_ReLU25_0_split
I0525 23:46:17.060705 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.060710 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.060714 15394 net.cpp:255] Memory required for data: 573031600
I0525 23:46:17.060716 15394 layer_factory.hpp:77] Creating layer Convolution26
I0525 23:46:17.060731 15394 net.cpp:190] Creating Layer Convolution26
I0525 23:46:17.060736 15394 net.cpp:605] Convolution26 <- Eltwise12_ReLU25_0_split_0
I0525 23:46:17.060742 15394 net.cpp:579] Convolution26 -> Convolution26
I0525 23:46:17.062341 15394 net.cpp:240] Setting up Convolution26
I0525 23:46:17.062381 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.062392 15394 net.cpp:255] Memory required for data: 574670000
I0525 23:46:17.062409 15394 layer_factory.hpp:77] Creating layer BatchNorm26
I0525 23:46:17.062436 15394 net.cpp:190] Creating Layer BatchNorm26
I0525 23:46:17.062445 15394 net.cpp:605] BatchNorm26 <- Convolution26
I0525 23:46:17.062454 15394 net.cpp:566] BatchNorm26 -> Convolution26 (in-place)
I0525 23:46:17.062666 15394 net.cpp:240] Setting up BatchNorm26
I0525 23:46:17.062674 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.062677 15394 net.cpp:255] Memory required for data: 576308400
I0525 23:46:17.062690 15394 layer_factory.hpp:77] Creating layer Scale26
I0525 23:46:17.062701 15394 net.cpp:190] Creating Layer Scale26
I0525 23:46:17.062705 15394 net.cpp:605] Scale26 <- Convolution26
I0525 23:46:17.062711 15394 net.cpp:566] Scale26 -> Convolution26 (in-place)
I0525 23:46:17.062765 15394 layer_factory.hpp:77] Creating layer Scale26
I0525 23:46:17.062890 15394 net.cpp:240] Setting up Scale26
I0525 23:46:17.062896 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.062899 15394 net.cpp:255] Memory required for data: 577946800
I0525 23:46:17.062908 15394 layer_factory.hpp:77] Creating layer ReLU26
I0525 23:46:17.062919 15394 net.cpp:190] Creating Layer ReLU26
I0525 23:46:17.062923 15394 net.cpp:605] ReLU26 <- Convolution26
I0525 23:46:17.062928 15394 net.cpp:566] ReLU26 -> Convolution26 (in-place)
I0525 23:46:17.062935 15394 net.cpp:240] Setting up ReLU26
I0525 23:46:17.062940 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.062943 15394 net.cpp:255] Memory required for data: 579585200
I0525 23:46:17.062947 15394 layer_factory.hpp:77] Creating layer Convolution27
I0525 23:46:17.062963 15394 net.cpp:190] Creating Layer Convolution27
I0525 23:46:17.062968 15394 net.cpp:605] Convolution27 <- Convolution26
I0525 23:46:17.062973 15394 net.cpp:579] Convolution27 -> Convolution27
I0525 23:46:17.064566 15394 net.cpp:240] Setting up Convolution27
I0525 23:46:17.064594 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.064599 15394 net.cpp:255] Memory required for data: 581223600
I0525 23:46:17.064612 15394 layer_factory.hpp:77] Creating layer BatchNorm27
I0525 23:46:17.064627 15394 net.cpp:190] Creating Layer BatchNorm27
I0525 23:46:17.064635 15394 net.cpp:605] BatchNorm27 <- Convolution27
I0525 23:46:17.064645 15394 net.cpp:566] BatchNorm27 -> Convolution27 (in-place)
I0525 23:46:17.064848 15394 net.cpp:240] Setting up BatchNorm27
I0525 23:46:17.064856 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.064858 15394 net.cpp:255] Memory required for data: 582862000
I0525 23:46:17.064869 15394 layer_factory.hpp:77] Creating layer Scale27
I0525 23:46:17.064882 15394 net.cpp:190] Creating Layer Scale27
I0525 23:46:17.064885 15394 net.cpp:605] Scale27 <- Convolution27
I0525 23:46:17.064891 15394 net.cpp:566] Scale27 -> Convolution27 (in-place)
I0525 23:46:17.064944 15394 layer_factory.hpp:77] Creating layer Scale27
I0525 23:46:17.065073 15394 net.cpp:240] Setting up Scale27
I0525 23:46:17.065081 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.065085 15394 net.cpp:255] Memory required for data: 584500400
I0525 23:46:17.065093 15394 layer_factory.hpp:77] Creating layer Eltwise13
I0525 23:46:17.065104 15394 net.cpp:190] Creating Layer Eltwise13
I0525 23:46:17.065109 15394 net.cpp:605] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I0525 23:46:17.065114 15394 net.cpp:605] Eltwise13 <- Convolution27
I0525 23:46:17.065124 15394 net.cpp:579] Eltwise13 -> Eltwise13
I0525 23:46:17.065151 15394 net.cpp:240] Setting up Eltwise13
I0525 23:46:17.065157 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.065160 15394 net.cpp:255] Memory required for data: 586138800
I0525 23:46:17.065163 15394 layer_factory.hpp:77] Creating layer ReLU27
I0525 23:46:17.065174 15394 net.cpp:190] Creating Layer ReLU27
I0525 23:46:17.065178 15394 net.cpp:605] ReLU27 <- Eltwise13
I0525 23:46:17.065182 15394 net.cpp:566] ReLU27 -> Eltwise13 (in-place)
I0525 23:46:17.065189 15394 net.cpp:240] Setting up ReLU27
I0525 23:46:17.065199 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.065203 15394 net.cpp:255] Memory required for data: 587777200
I0525 23:46:17.065207 15394 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I0525 23:46:17.065213 15394 net.cpp:190] Creating Layer Eltwise13_ReLU27_0_split
I0525 23:46:17.065217 15394 net.cpp:605] Eltwise13_ReLU27_0_split <- Eltwise13
I0525 23:46:17.065222 15394 net.cpp:579] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I0525 23:46:17.065228 15394 net.cpp:579] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I0525 23:46:17.065263 15394 net.cpp:240] Setting up Eltwise13_ReLU27_0_split
I0525 23:46:17.065269 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.065274 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.065276 15394 net.cpp:255] Memory required for data: 591054000
I0525 23:46:17.065279 15394 layer_factory.hpp:77] Creating layer Convolution28
I0525 23:46:17.065292 15394 net.cpp:190] Creating Layer Convolution28
I0525 23:46:17.065296 15394 net.cpp:605] Convolution28 <- Eltwise13_ReLU27_0_split_0
I0525 23:46:17.065304 15394 net.cpp:579] Convolution28 -> Convolution28
I0525 23:46:17.066900 15394 net.cpp:240] Setting up Convolution28
I0525 23:46:17.066928 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.066933 15394 net.cpp:255] Memory required for data: 592692400
I0525 23:46:17.066948 15394 layer_factory.hpp:77] Creating layer BatchNorm28
I0525 23:46:17.066967 15394 net.cpp:190] Creating Layer BatchNorm28
I0525 23:46:17.066977 15394 net.cpp:605] BatchNorm28 <- Convolution28
I0525 23:46:17.066985 15394 net.cpp:566] BatchNorm28 -> Convolution28 (in-place)
I0525 23:46:17.067188 15394 net.cpp:240] Setting up BatchNorm28
I0525 23:46:17.067195 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.067199 15394 net.cpp:255] Memory required for data: 594330800
I0525 23:46:17.067210 15394 layer_factory.hpp:77] Creating layer Scale28
I0525 23:46:17.067222 15394 net.cpp:190] Creating Layer Scale28
I0525 23:46:17.067226 15394 net.cpp:605] Scale28 <- Convolution28
I0525 23:46:17.067231 15394 net.cpp:566] Scale28 -> Convolution28 (in-place)
I0525 23:46:17.067283 15394 layer_factory.hpp:77] Creating layer Scale28
I0525 23:46:17.067404 15394 net.cpp:240] Setting up Scale28
I0525 23:46:17.067410 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.067414 15394 net.cpp:255] Memory required for data: 595969200
I0525 23:46:17.067425 15394 layer_factory.hpp:77] Creating layer ReLU28
I0525 23:46:17.067432 15394 net.cpp:190] Creating Layer ReLU28
I0525 23:46:17.067436 15394 net.cpp:605] ReLU28 <- Convolution28
I0525 23:46:17.067443 15394 net.cpp:566] ReLU28 -> Convolution28 (in-place)
I0525 23:46:17.067451 15394 net.cpp:240] Setting up ReLU28
I0525 23:46:17.067456 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.067458 15394 net.cpp:255] Memory required for data: 597607600
I0525 23:46:17.067462 15394 layer_factory.hpp:77] Creating layer Convolution29
I0525 23:46:17.067476 15394 net.cpp:190] Creating Layer Convolution29
I0525 23:46:17.067479 15394 net.cpp:605] Convolution29 <- Convolution28
I0525 23:46:17.067487 15394 net.cpp:579] Convolution29 -> Convolution29
I0525 23:46:17.069082 15394 net.cpp:240] Setting up Convolution29
I0525 23:46:17.069110 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.069114 15394 net.cpp:255] Memory required for data: 599246000
I0525 23:46:17.069129 15394 layer_factory.hpp:77] Creating layer BatchNorm29
I0525 23:46:17.069146 15394 net.cpp:190] Creating Layer BatchNorm29
I0525 23:46:17.069154 15394 net.cpp:605] BatchNorm29 <- Convolution29
I0525 23:46:17.069161 15394 net.cpp:566] BatchNorm29 -> Convolution29 (in-place)
I0525 23:46:17.069381 15394 net.cpp:240] Setting up BatchNorm29
I0525 23:46:17.069391 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.069393 15394 net.cpp:255] Memory required for data: 600884400
I0525 23:46:17.069404 15394 layer_factory.hpp:77] Creating layer Scale29
I0525 23:46:17.069422 15394 net.cpp:190] Creating Layer Scale29
I0525 23:46:17.069430 15394 net.cpp:605] Scale29 <- Convolution29
I0525 23:46:17.069437 15394 net.cpp:566] Scale29 -> Convolution29 (in-place)
I0525 23:46:17.069494 15394 layer_factory.hpp:77] Creating layer Scale29
I0525 23:46:17.069614 15394 net.cpp:240] Setting up Scale29
I0525 23:46:17.069620 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.069624 15394 net.cpp:255] Memory required for data: 602522800
I0525 23:46:17.069631 15394 layer_factory.hpp:77] Creating layer Eltwise14
I0525 23:46:17.069644 15394 net.cpp:190] Creating Layer Eltwise14
I0525 23:46:17.069650 15394 net.cpp:605] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I0525 23:46:17.069655 15394 net.cpp:605] Eltwise14 <- Convolution29
I0525 23:46:17.069661 15394 net.cpp:579] Eltwise14 -> Eltwise14
I0525 23:46:17.069689 15394 net.cpp:240] Setting up Eltwise14
I0525 23:46:17.069694 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.069697 15394 net.cpp:255] Memory required for data: 604161200
I0525 23:46:17.069700 15394 layer_factory.hpp:77] Creating layer ReLU29
I0525 23:46:17.069708 15394 net.cpp:190] Creating Layer ReLU29
I0525 23:46:17.069711 15394 net.cpp:605] ReLU29 <- Eltwise14
I0525 23:46:17.069718 15394 net.cpp:566] ReLU29 -> Eltwise14 (in-place)
I0525 23:46:17.069725 15394 net.cpp:240] Setting up ReLU29
I0525 23:46:17.069730 15394 net.cpp:247] Top shape: 100 64 8 8 (409600)
I0525 23:46:17.069732 15394 net.cpp:255] Memory required for data: 605799600
I0525 23:46:17.069736 15394 layer_factory.hpp:77] Creating layer Pooling3
I0525 23:46:17.069746 15394 net.cpp:190] Creating Layer Pooling3
I0525 23:46:17.069749 15394 net.cpp:605] Pooling3 <- Eltwise14
I0525 23:46:17.069756 15394 net.cpp:579] Pooling3 -> Pooling3
I0525 23:46:17.069782 15394 net.cpp:240] Setting up Pooling3
I0525 23:46:17.069787 15394 net.cpp:247] Top shape: 100 64 1 1 (6400)
I0525 23:46:17.069790 15394 net.cpp:255] Memory required for data: 605825200
I0525 23:46:17.069793 15394 layer_factory.hpp:77] Creating layer InnerProduct1
I0525 23:46:17.069807 15394 net.cpp:190] Creating Layer InnerProduct1
I0525 23:46:17.069810 15394 net.cpp:605] InnerProduct1 <- Pooling3
I0525 23:46:17.069816 15394 net.cpp:579] InnerProduct1 -> InnerProduct1
I0525 23:46:17.069990 15394 net.cpp:240] Setting up InnerProduct1
I0525 23:46:17.069999 15394 net.cpp:247] Top shape: 100 10 (1000)
I0525 23:46:17.070003 15394 net.cpp:255] Memory required for data: 605829200
I0525 23:46:17.070010 15394 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0525 23:46:17.070020 15394 net.cpp:190] Creating Layer InnerProduct1_InnerProduct1_0_split
I0525 23:46:17.070024 15394 net.cpp:605] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0525 23:46:17.070030 15394 net.cpp:579] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0525 23:46:17.070037 15394 net.cpp:579] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0525 23:46:17.070075 15394 net.cpp:240] Setting up InnerProduct1_InnerProduct1_0_split
I0525 23:46:17.070080 15394 net.cpp:247] Top shape: 100 10 (1000)
I0525 23:46:17.070085 15394 net.cpp:247] Top shape: 100 10 (1000)
I0525 23:46:17.070088 15394 net.cpp:255] Memory required for data: 605837200
I0525 23:46:17.070091 15394 layer_factory.hpp:77] Creating layer Accuracy
I0525 23:46:17.070099 15394 net.cpp:190] Creating Layer Accuracy
I0525 23:46:17.070103 15394 net.cpp:605] Accuracy <- InnerProduct1_InnerProduct1_0_split_0
I0525 23:46:17.070109 15394 net.cpp:605] Accuracy <- Data2_Data1_1_split_0
I0525 23:46:17.070118 15394 net.cpp:579] Accuracy -> Accuracy
I0525 23:46:17.070137 15394 net.cpp:240] Setting up Accuracy
I0525 23:46:17.070142 15394 net.cpp:247] Top shape: (1)
I0525 23:46:17.070145 15394 net.cpp:255] Memory required for data: 605837204
I0525 23:46:17.070148 15394 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0525 23:46:17.070155 15394 net.cpp:190] Creating Layer SoftmaxWithLoss1
I0525 23:46:17.070159 15394 net.cpp:605] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_1
I0525 23:46:17.070170 15394 net.cpp:605] SoftmaxWithLoss1 <- Data2_Data1_1_split_1
I0525 23:46:17.070175 15394 net.cpp:579] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0525 23:46:17.070185 15394 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0525 23:46:17.070281 15394 net.cpp:240] Setting up SoftmaxWithLoss1
I0525 23:46:17.070288 15394 net.cpp:247] Top shape: (1)
I0525 23:46:17.070291 15394 net.cpp:250]     with loss weight 1
I0525 23:46:17.070307 15394 net.cpp:255] Memory required for data: 605837208
I0525 23:46:17.070309 15394 net.cpp:316] SoftmaxWithLoss1 needs backward computation.
I0525 23:46:17.070314 15394 net.cpp:318] Accuracy does not need backward computation.
I0525 23:46:17.070318 15394 net.cpp:316] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0525 23:46:17.070322 15394 net.cpp:316] InnerProduct1 needs backward computation.
I0525 23:46:17.070324 15394 net.cpp:316] Pooling3 needs backward computation.
I0525 23:46:17.070328 15394 net.cpp:316] ReLU29 needs backward computation.
I0525 23:46:17.070332 15394 net.cpp:316] Eltwise14 needs backward computation.
I0525 23:46:17.070335 15394 net.cpp:316] Scale29 needs backward computation.
I0525 23:46:17.070338 15394 net.cpp:316] BatchNorm29 needs backward computation.
I0525 23:46:17.070341 15394 net.cpp:316] Convolution29 needs backward computation.
I0525 23:46:17.070345 15394 net.cpp:316] ReLU28 needs backward computation.
I0525 23:46:17.070349 15394 net.cpp:316] Scale28 needs backward computation.
I0525 23:46:17.070363 15394 net.cpp:316] BatchNorm28 needs backward computation.
I0525 23:46:17.070366 15394 net.cpp:316] Convolution28 needs backward computation.
I0525 23:46:17.070370 15394 net.cpp:316] Eltwise13_ReLU27_0_split needs backward computation.
I0525 23:46:17.070375 15394 net.cpp:316] ReLU27 needs backward computation.
I0525 23:46:17.070379 15394 net.cpp:316] Eltwise13 needs backward computation.
I0525 23:46:17.070382 15394 net.cpp:316] Scale27 needs backward computation.
I0525 23:46:17.070386 15394 net.cpp:316] BatchNorm27 needs backward computation.
I0525 23:46:17.070390 15394 net.cpp:316] Convolution27 needs backward computation.
I0525 23:46:17.070394 15394 net.cpp:316] ReLU26 needs backward computation.
I0525 23:46:17.070397 15394 net.cpp:316] Scale26 needs backward computation.
I0525 23:46:17.070400 15394 net.cpp:316] BatchNorm26 needs backward computation.
I0525 23:46:17.070407 15394 net.cpp:316] Convolution26 needs backward computation.
I0525 23:46:17.070411 15394 net.cpp:316] Eltwise12_ReLU25_0_split needs backward computation.
I0525 23:46:17.070415 15394 net.cpp:316] ReLU25 needs backward computation.
I0525 23:46:17.070420 15394 net.cpp:316] Eltwise12 needs backward computation.
I0525 23:46:17.070423 15394 net.cpp:316] Scale25 needs backward computation.
I0525 23:46:17.070427 15394 net.cpp:316] BatchNorm25 needs backward computation.
I0525 23:46:17.070430 15394 net.cpp:316] Convolution25 needs backward computation.
I0525 23:46:17.070435 15394 net.cpp:316] ReLU24 needs backward computation.
I0525 23:46:17.070438 15394 net.cpp:316] Scale24 needs backward computation.
I0525 23:46:17.070441 15394 net.cpp:316] BatchNorm24 needs backward computation.
I0525 23:46:17.070446 15394 net.cpp:316] Convolution24 needs backward computation.
I0525 23:46:17.070449 15394 net.cpp:316] Eltwise11_ReLU23_0_split needs backward computation.
I0525 23:46:17.070454 15394 net.cpp:316] ReLU23 needs backward computation.
I0525 23:46:17.070457 15394 net.cpp:316] Eltwise11 needs backward computation.
I0525 23:46:17.070461 15394 net.cpp:316] Scale23 needs backward computation.
I0525 23:46:17.070466 15394 net.cpp:316] BatchNorm23 needs backward computation.
I0525 23:46:17.070469 15394 net.cpp:316] Convolution23 needs backward computation.
I0525 23:46:17.070472 15394 net.cpp:316] ReLU22 needs backward computation.
I0525 23:46:17.070477 15394 net.cpp:316] Scale22 needs backward computation.
I0525 23:46:17.070480 15394 net.cpp:316] BatchNorm22 needs backward computation.
I0525 23:46:17.070483 15394 net.cpp:316] Convolution22 needs backward computation.
I0525 23:46:17.070490 15394 net.cpp:316] Eltwise10_ReLU21_0_split needs backward computation.
I0525 23:46:17.070494 15394 net.cpp:316] ReLU21 needs backward computation.
I0525 23:46:17.070498 15394 net.cpp:316] Eltwise10 needs backward computation.
I0525 23:46:17.070503 15394 net.cpp:316] Scale21 needs backward computation.
I0525 23:46:17.070508 15394 net.cpp:316] BatchNorm21 needs backward computation.
I0525 23:46:17.070510 15394 net.cpp:316] Convolution21 needs backward computation.
I0525 23:46:17.070514 15394 net.cpp:316] ReLU20 needs backward computation.
I0525 23:46:17.070518 15394 net.cpp:316] Scale20 needs backward computation.
I0525 23:46:17.070521 15394 net.cpp:316] BatchNorm20 needs backward computation.
I0525 23:46:17.070525 15394 net.cpp:316] Convolution20 needs backward computation.
I0525 23:46:17.070529 15394 net.cpp:316] Concat2 needs backward computation.
I0525 23:46:17.070534 15394 net.cpp:318] Input2 does not need backward computation.
I0525 23:46:17.070538 15394 net.cpp:316] Pooling2 needs backward computation.
I0525 23:46:17.070541 15394 net.cpp:316] Eltwise9_ReLU19_0_split needs backward computation.
I0525 23:46:17.070546 15394 net.cpp:316] ReLU19 needs backward computation.
I0525 23:46:17.070550 15394 net.cpp:316] Eltwise9 needs backward computation.
I0525 23:46:17.070555 15394 net.cpp:316] Scale19 needs backward computation.
I0525 23:46:17.070559 15394 net.cpp:316] BatchNorm19 needs backward computation.
I0525 23:46:17.070562 15394 net.cpp:316] Convolution19 needs backward computation.
I0525 23:46:17.070567 15394 net.cpp:316] ReLU18 needs backward computation.
I0525 23:46:17.070570 15394 net.cpp:316] Scale18 needs backward computation.
I0525 23:46:17.070574 15394 net.cpp:316] BatchNorm18 needs backward computation.
I0525 23:46:17.070577 15394 net.cpp:316] Convolution18 needs backward computation.
I0525 23:46:17.070582 15394 net.cpp:316] Eltwise8_ReLU17_0_split needs backward computation.
I0525 23:46:17.070586 15394 net.cpp:316] ReLU17 needs backward computation.
I0525 23:46:17.070590 15394 net.cpp:316] Eltwise8 needs backward computation.
I0525 23:46:17.070595 15394 net.cpp:316] Scale17 needs backward computation.
I0525 23:46:17.070598 15394 net.cpp:316] BatchNorm17 needs backward computation.
I0525 23:46:17.070601 15394 net.cpp:316] Convolution17 needs backward computation.
I0525 23:46:17.070605 15394 net.cpp:316] ReLU16 needs backward computation.
I0525 23:46:17.070610 15394 net.cpp:316] Scale16 needs backward computation.
I0525 23:46:17.070612 15394 net.cpp:316] BatchNorm16 needs backward computation.
I0525 23:46:17.070616 15394 net.cpp:316] Convolution16 needs backward computation.
I0525 23:46:17.070621 15394 net.cpp:316] Eltwise7_ReLU15_0_split needs backward computation.
I0525 23:46:17.070624 15394 net.cpp:316] ReLU15 needs backward computation.
I0525 23:46:17.070627 15394 net.cpp:316] Eltwise7 needs backward computation.
I0525 23:46:17.070631 15394 net.cpp:316] Scale15 needs backward computation.
I0525 23:46:17.070636 15394 net.cpp:316] BatchNorm15 needs backward computation.
I0525 23:46:17.070638 15394 net.cpp:316] Convolution15 needs backward computation.
I0525 23:46:17.070643 15394 net.cpp:316] ReLU14 needs backward computation.
I0525 23:46:17.070647 15394 net.cpp:316] Scale14 needs backward computation.
I0525 23:46:17.070650 15394 net.cpp:316] BatchNorm14 needs backward computation.
I0525 23:46:17.070654 15394 net.cpp:316] Convolution14 needs backward computation.
I0525 23:46:17.070658 15394 net.cpp:316] Eltwise6_ReLU13_0_split needs backward computation.
I0525 23:46:17.070662 15394 net.cpp:316] ReLU13 needs backward computation.
I0525 23:46:17.070667 15394 net.cpp:316] Eltwise6 needs backward computation.
I0525 23:46:17.070672 15394 net.cpp:316] Scale13 needs backward computation.
I0525 23:46:17.070674 15394 net.cpp:316] BatchNorm13 needs backward computation.
I0525 23:46:17.070678 15394 net.cpp:316] Convolution13 needs backward computation.
I0525 23:46:17.070683 15394 net.cpp:316] ReLU12 needs backward computation.
I0525 23:46:17.070686 15394 net.cpp:316] Scale12 needs backward computation.
I0525 23:46:17.070693 15394 net.cpp:316] BatchNorm12 needs backward computation.
I0525 23:46:17.070696 15394 net.cpp:316] Convolution12 needs backward computation.
I0525 23:46:17.070700 15394 net.cpp:316] Eltwise5_ReLU11_0_split needs backward computation.
I0525 23:46:17.070704 15394 net.cpp:316] ReLU11 needs backward computation.
I0525 23:46:17.070708 15394 net.cpp:316] Eltwise5 needs backward computation.
I0525 23:46:17.070713 15394 net.cpp:316] Scale11 needs backward computation.
I0525 23:46:17.070718 15394 net.cpp:316] BatchNorm11 needs backward computation.
I0525 23:46:17.070721 15394 net.cpp:316] Convolution11 needs backward computation.
I0525 23:46:17.070725 15394 net.cpp:316] ReLU10 needs backward computation.
I0525 23:46:17.070729 15394 net.cpp:316] Scale10 needs backward computation.
I0525 23:46:17.070732 15394 net.cpp:316] BatchNorm10 needs backward computation.
I0525 23:46:17.070736 15394 net.cpp:316] Convolution10 needs backward computation.
I0525 23:46:17.070740 15394 net.cpp:316] Concat1 needs backward computation.
I0525 23:46:17.070745 15394 net.cpp:318] Input1 does not need backward computation.
I0525 23:46:17.070749 15394 net.cpp:316] Pooling1 needs backward computation.
I0525 23:46:17.070754 15394 net.cpp:316] Eltwise4_ReLU9_0_split needs backward computation.
I0525 23:46:17.070757 15394 net.cpp:316] ReLU9 needs backward computation.
I0525 23:46:17.070761 15394 net.cpp:316] Eltwise4 needs backward computation.
I0525 23:46:17.070768 15394 net.cpp:316] Scale9 needs backward computation.
I0525 23:46:17.070772 15394 net.cpp:316] BatchNorm9 needs backward computation.
I0525 23:46:17.070776 15394 net.cpp:316] Convolution9 needs backward computation.
I0525 23:46:17.070780 15394 net.cpp:316] ReLU8 needs backward computation.
I0525 23:46:17.070785 15394 net.cpp:316] Scale8 needs backward computation.
I0525 23:46:17.070790 15394 net.cpp:316] BatchNorm8 needs backward computation.
I0525 23:46:17.070792 15394 net.cpp:316] Convolution8 needs backward computation.
I0525 23:46:17.070797 15394 net.cpp:316] Eltwise3_ReLU7_0_split needs backward computation.
I0525 23:46:17.070801 15394 net.cpp:316] ReLU7 needs backward computation.
I0525 23:46:17.070806 15394 net.cpp:316] Eltwise3 needs backward computation.
I0525 23:46:17.070811 15394 net.cpp:316] Scale7 needs backward computation.
I0525 23:46:17.070814 15394 net.cpp:316] BatchNorm7 needs backward computation.
I0525 23:46:17.070818 15394 net.cpp:316] Convolution7 needs backward computation.
I0525 23:46:17.070822 15394 net.cpp:316] ReLU6 needs backward computation.
I0525 23:46:17.070827 15394 net.cpp:316] Scale6 needs backward computation.
I0525 23:46:17.070830 15394 net.cpp:316] BatchNorm6 needs backward computation.
I0525 23:46:17.070834 15394 net.cpp:316] Convolution6 needs backward computation.
I0525 23:46:17.070838 15394 net.cpp:316] Eltwise2_ReLU5_0_split needs backward computation.
I0525 23:46:17.070842 15394 net.cpp:316] ReLU5 needs backward computation.
I0525 23:46:17.070847 15394 net.cpp:316] Eltwise2 needs backward computation.
I0525 23:46:17.070850 15394 net.cpp:316] Scale5 needs backward computation.
I0525 23:46:17.070854 15394 net.cpp:316] BatchNorm5 needs backward computation.
I0525 23:46:17.070858 15394 net.cpp:316] Convolution5 needs backward computation.
I0525 23:46:17.070863 15394 net.cpp:316] ReLU4 needs backward computation.
I0525 23:46:17.070866 15394 net.cpp:316] Scale4 needs backward computation.
I0525 23:46:17.070870 15394 net.cpp:316] BatchNorm4 needs backward computation.
I0525 23:46:17.070874 15394 net.cpp:316] Convolution4 needs backward computation.
I0525 23:46:17.070878 15394 net.cpp:316] Eltwise1_ReLU3_0_split needs backward computation.
I0525 23:46:17.070883 15394 net.cpp:316] ReLU3 needs backward computation.
I0525 23:46:17.070888 15394 net.cpp:316] Eltwise1 needs backward computation.
I0525 23:46:17.070893 15394 net.cpp:316] Scale3 needs backward computation.
I0525 23:46:17.070896 15394 net.cpp:316] BatchNorm3 needs backward computation.
I0525 23:46:17.070899 15394 net.cpp:316] Convolution3 needs backward computation.
I0525 23:46:17.070907 15394 net.cpp:316] ReLU2 needs backward computation.
I0525 23:46:17.070911 15394 net.cpp:316] Scale2 needs backward computation.
I0525 23:46:17.070914 15394 net.cpp:316] BatchNorm2 needs backward computation.
I0525 23:46:17.070919 15394 net.cpp:316] Convolution2 needs backward computation.
I0525 23:46:17.070924 15394 net.cpp:316] Convolution1_ReLU1_0_split needs backward computation.
I0525 23:46:17.070927 15394 net.cpp:316] ReLU1 needs backward computation.
I0525 23:46:17.070931 15394 net.cpp:316] Scale1 needs backward computation.
I0525 23:46:17.070935 15394 net.cpp:316] BatchNorm1 needs backward computation.
I0525 23:46:17.070938 15394 net.cpp:316] Convolution1 needs backward computation.
I0525 23:46:17.070943 15394 net.cpp:318] Data2_Data1_1_split does not need backward computation.
I0525 23:46:17.070948 15394 net.cpp:318] Data1 does not need backward computation.
I0525 23:46:17.070951 15394 net.cpp:360] This network produces output Accuracy
I0525 23:46:17.070958 15394 net.cpp:360] This network produces output SoftmaxWithLoss1
I0525 23:46:17.071054 15394 net.cpp:374] Network initialization done.
I0525 23:46:17.071830 15394 solver.cpp:65] Solver scaffolding done.
params_lr: 205	has_params_lr: 205	params_weight_decay: 205	has_params_decay: 205
layers; 154
params: 205
I0525 23:46:17.092283 15394 main.cpp:406] Solving 
I0525 23:46:17.092308 15394 main.cpp:407] Learning Rate Policy: multistep
I0525 23:46:17.097170 15394 main.cpp:465] Iteration 0, Testing net (#0)
I0525 23:46:30.291182 15394 main.cpp:532]     Test net output #0: Accuracy = 0.1
I0525 23:46:30.291261 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0525 23:46:30.833910 15394 main.cpp:354] Iteration 0, loss = 4.00076
I0525 23:46:30.834018 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 4.00076 (* 1 = 4.00076 loss)
I0525 23:46:30.834055 15394 sgd_solver.cpp:43] Iteration 0, lr = 0.02
I0525 23:46:36.160377 15394 main.cpp:354] Iteration 10, loss = 2.0631
I0525 23:46:36.160447 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 2.0631 (* 1 = 2.0631 loss)
I0525 23:46:36.160459 15394 sgd_solver.cpp:43] Iteration 10, lr = 0.02
I0525 23:46:41.417902 15394 main.cpp:354] Iteration 20, loss = 2.14422
I0525 23:46:41.417971 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 2.14422 (* 1 = 2.14422 loss)
I0525 23:46:41.417982 15394 sgd_solver.cpp:43] Iteration 20, lr = 0.02
I0525 23:46:46.628695 15394 main.cpp:354] Iteration 30, loss = 2.05434
I0525 23:46:46.628763 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 2.05434 (* 1 = 2.05434 loss)
I0525 23:46:46.628773 15394 sgd_solver.cpp:43] Iteration 30, lr = 0.02
I0525 23:46:51.990613 15394 main.cpp:354] Iteration 40, loss = 1.9141
I0525 23:46:51.990689 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.9141 (* 1 = 1.9141 loss)
I0525 23:46:51.990700 15394 sgd_solver.cpp:43] Iteration 40, lr = 0.02
I0525 23:46:56.832470 15394 main.cpp:354] Iteration 50, loss = 1.98113
I0525 23:46:56.832536 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.98113 (* 1 = 1.98113 loss)
I0525 23:46:56.832547 15394 sgd_solver.cpp:43] Iteration 50, lr = 0.02
I0525 23:47:01.801635 15394 main.cpp:354] Iteration 60, loss = 1.94534
I0525 23:47:01.801699 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.94534 (* 1 = 1.94534 loss)
I0525 23:47:01.801709 15394 sgd_solver.cpp:43] Iteration 60, lr = 0.02
I0525 23:47:07.074970 15394 main.cpp:354] Iteration 70, loss = 1.91991
I0525 23:47:07.075037 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.91991 (* 1 = 1.91991 loss)
I0525 23:47:07.075047 15394 sgd_solver.cpp:43] Iteration 70, lr = 0.02
I0525 23:47:12.288275 15394 main.cpp:354] Iteration 80, loss = 1.76396
I0525 23:47:12.288337 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.76396 (* 1 = 1.76396 loss)
I0525 23:47:12.288348 15394 sgd_solver.cpp:43] Iteration 80, lr = 0.02
I0525 23:47:17.548984 15394 main.cpp:354] Iteration 90, loss = 1.93096
I0525 23:47:17.549042 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.93096 (* 1 = 1.93096 loss)
I0525 23:47:17.549059 15394 sgd_solver.cpp:43] Iteration 90, lr = 0.02
I0525 23:47:21.696485 15394 main.cpp:465] Iteration 100, Testing net (#0)
I0525 23:47:34.838358 15394 main.cpp:532]     Test net output #0: Accuracy = 0.286
I0525 23:47:34.838423 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 2.20591 (* 1 = 2.20591 loss)
I0525 23:47:35.380049 15394 main.cpp:354] Iteration 100, loss = 1.68433
I0525 23:47:35.380127 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.68433 (* 1 = 1.68433 loss)
I0525 23:47:35.380142 15394 sgd_solver.cpp:43] Iteration 100, lr = 0.02
I0525 23:47:40.636106 15394 main.cpp:354] Iteration 110, loss = 1.82933
I0525 23:47:40.636171 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.82933 (* 1 = 1.82933 loss)
I0525 23:47:40.636181 15394 sgd_solver.cpp:43] Iteration 110, lr = 0.02
I0525 23:47:45.642323 15394 main.cpp:354] Iteration 120, loss = 1.92121
I0525 23:47:45.642385 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.92121 (* 1 = 1.92121 loss)
I0525 23:47:45.642395 15394 sgd_solver.cpp:43] Iteration 120, lr = 0.02
I0525 23:47:50.685569 15394 main.cpp:354] Iteration 130, loss = 1.74078
I0525 23:47:50.685636 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.74078 (* 1 = 1.74078 loss)
I0525 23:47:50.685645 15394 sgd_solver.cpp:43] Iteration 130, lr = 0.02
I0525 23:47:55.669654 15394 main.cpp:354] Iteration 140, loss = 1.79626
I0525 23:47:55.669721 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.79626 (* 1 = 1.79626 loss)
I0525 23:47:55.669730 15394 sgd_solver.cpp:43] Iteration 140, lr = 0.02
I0525 23:48:00.871875 15394 main.cpp:354] Iteration 150, loss = 1.75031
I0525 23:48:00.871955 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.75031 (* 1 = 1.75031 loss)
I0525 23:48:00.871965 15394 sgd_solver.cpp:43] Iteration 150, lr = 0.02
I0525 23:48:06.520393 15394 main.cpp:354] Iteration 160, loss = 1.66115
I0525 23:48:06.520469 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.66115 (* 1 = 1.66115 loss)
I0525 23:48:06.520480 15394 sgd_solver.cpp:43] Iteration 160, lr = 0.02
I0525 23:48:11.337769 15394 main.cpp:354] Iteration 170, loss = 1.74041
I0525 23:48:11.337838 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.74041 (* 1 = 1.74041 loss)
I0525 23:48:11.337849 15394 sgd_solver.cpp:43] Iteration 170, lr = 0.02
I0525 23:48:16.112133 15394 main.cpp:354] Iteration 180, loss = 1.77907
I0525 23:48:16.112207 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.77907 (* 1 = 1.77907 loss)
I0525 23:48:16.112220 15394 sgd_solver.cpp:43] Iteration 180, lr = 0.02
I0525 23:48:21.545780 15394 main.cpp:354] Iteration 190, loss = 1.53311
I0525 23:48:21.545850 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.53311 (* 1 = 1.53311 loss)
I0525 23:48:21.545861 15394 sgd_solver.cpp:43] Iteration 190, lr = 0.02
I0525 23:48:25.893293 15394 main.cpp:465] Iteration 200, Testing net (#0)
I0525 23:48:39.060314 15394 main.cpp:532]     Test net output #0: Accuracy = 0.1867
I0525 23:48:39.060400 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 2.9937 (* 1 = 2.9937 loss)
I0525 23:48:39.529860 15394 main.cpp:354] Iteration 200, loss = 1.68691
I0525 23:48:39.529933 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.68691 (* 1 = 1.68691 loss)
I0525 23:48:39.529950 15394 sgd_solver.cpp:43] Iteration 200, lr = 0.02
I0525 23:48:44.435869 15394 main.cpp:354] Iteration 210, loss = 1.6871
I0525 23:48:44.435940 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.6871 (* 1 = 1.6871 loss)
I0525 23:48:44.435951 15394 sgd_solver.cpp:43] Iteration 210, lr = 0.02
I0525 23:48:49.825775 15394 main.cpp:354] Iteration 220, loss = 1.63995
I0525 23:48:49.825851 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.63995 (* 1 = 1.63995 loss)
I0525 23:48:49.825862 15394 sgd_solver.cpp:43] Iteration 220, lr = 0.02
I0525 23:48:54.407124 15394 main.cpp:354] Iteration 230, loss = 1.6983
I0525 23:48:54.407192 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.6983 (* 1 = 1.6983 loss)
I0525 23:48:54.407203 15394 sgd_solver.cpp:43] Iteration 230, lr = 0.02
I0525 23:48:59.134093 15394 main.cpp:354] Iteration 240, loss = 1.75353
I0525 23:48:59.134155 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.75353 (* 1 = 1.75353 loss)
I0525 23:48:59.134166 15394 sgd_solver.cpp:43] Iteration 240, lr = 0.02
I0525 23:49:04.574723 15394 main.cpp:354] Iteration 250, loss = 1.64068
I0525 23:49:04.574800 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.64068 (* 1 = 1.64068 loss)
I0525 23:49:04.574810 15394 sgd_solver.cpp:43] Iteration 250, lr = 0.02
I0525 23:49:09.686049 15394 main.cpp:354] Iteration 260, loss = 1.60459
I0525 23:49:09.686130 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.60459 (* 1 = 1.60459 loss)
I0525 23:49:09.686139 15394 sgd_solver.cpp:43] Iteration 260, lr = 0.02
I0525 23:49:14.859066 15394 main.cpp:354] Iteration 270, loss = 1.5226
I0525 23:49:14.859130 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.5226 (* 1 = 1.5226 loss)
I0525 23:49:14.859141 15394 sgd_solver.cpp:43] Iteration 270, lr = 0.02
I0525 23:49:19.907737 15394 main.cpp:354] Iteration 280, loss = 1.53471
I0525 23:49:19.907807 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.53471 (* 1 = 1.53471 loss)
I0525 23:49:19.907819 15394 sgd_solver.cpp:43] Iteration 280, lr = 0.02
I0525 23:49:25.034317 15394 main.cpp:354] Iteration 290, loss = 1.67636
I0525 23:49:25.034390 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.67636 (* 1 = 1.67636 loss)
I0525 23:49:25.034401 15394 sgd_solver.cpp:43] Iteration 290, lr = 0.02
I0525 23:49:29.521951 15394 main.cpp:465] Iteration 300, Testing net (#0)
I0525 23:49:42.644029 15394 main.cpp:532]     Test net output #0: Accuracy = 0.2639
I0525 23:49:42.644089 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 2.5393 (* 1 = 2.5393 loss)
I0525 23:49:43.118511 15394 main.cpp:354] Iteration 300, loss = 1.68464
I0525 23:49:43.118583 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.68464 (* 1 = 1.68464 loss)
I0525 23:49:43.118594 15394 sgd_solver.cpp:43] Iteration 300, lr = 0.02
I0525 23:49:48.424140 15394 main.cpp:354] Iteration 310, loss = 1.65868
I0525 23:49:48.424213 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.65868 (* 1 = 1.65868 loss)
I0525 23:49:48.424224 15394 sgd_solver.cpp:43] Iteration 310, lr = 0.02
I0525 23:49:53.731993 15394 main.cpp:354] Iteration 320, loss = 1.58703
I0525 23:49:53.732061 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.58703 (* 1 = 1.58703 loss)
I0525 23:49:53.732072 15394 sgd_solver.cpp:43] Iteration 320, lr = 0.02
I0525 23:49:59.341135 15394 main.cpp:354] Iteration 330, loss = 1.47936
I0525 23:49:59.341202 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.47936 (* 1 = 1.47936 loss)
I0525 23:49:59.341213 15394 sgd_solver.cpp:43] Iteration 330, lr = 0.02
I0525 23:50:04.602768 15394 main.cpp:354] Iteration 340, loss = 1.48887
I0525 23:50:04.602839 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.48887 (* 1 = 1.48887 loss)
I0525 23:50:04.602849 15394 sgd_solver.cpp:43] Iteration 340, lr = 0.02
I0525 23:50:09.887441 15394 main.cpp:354] Iteration 350, loss = 1.55127
I0525 23:50:09.887517 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.55127 (* 1 = 1.55127 loss)
I0525 23:50:09.887527 15394 sgd_solver.cpp:43] Iteration 350, lr = 0.02
I0525 23:50:14.772755 15394 main.cpp:354] Iteration 360, loss = 1.53058
I0525 23:50:14.772819 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.53058 (* 1 = 1.53058 loss)
I0525 23:50:14.772830 15394 sgd_solver.cpp:43] Iteration 360, lr = 0.02
I0525 23:50:19.473556 15394 main.cpp:354] Iteration 370, loss = 1.36234
I0525 23:50:19.473618 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.36234 (* 1 = 1.36234 loss)
I0525 23:50:19.473628 15394 sgd_solver.cpp:43] Iteration 370, lr = 0.02
I0525 23:50:24.459615 15394 main.cpp:354] Iteration 380, loss = 1.40431
I0525 23:50:24.459684 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.40431 (* 1 = 1.40431 loss)
I0525 23:50:24.459697 15394 sgd_solver.cpp:43] Iteration 380, lr = 0.02
I0525 23:50:29.642331 15394 main.cpp:354] Iteration 390, loss = 1.65508
I0525 23:50:29.642418 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.65508 (* 1 = 1.65508 loss)
I0525 23:50:29.642429 15394 sgd_solver.cpp:43] Iteration 390, lr = 0.02
I0525 23:50:34.182761 15394 main.cpp:465] Iteration 400, Testing net (#0)
I0525 23:50:47.309034 15394 main.cpp:532]     Test net output #0: Accuracy = 0.2607
I0525 23:50:47.309094 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 3.65114 (* 1 = 3.65114 loss)
I0525 23:50:47.853121 15394 main.cpp:354] Iteration 400, loss = 1.41616
I0525 23:50:47.853188 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.41616 (* 1 = 1.41616 loss)
I0525 23:50:47.853200 15394 sgd_solver.cpp:43] Iteration 400, lr = 0.02
I0525 23:50:52.474830 15394 main.cpp:354] Iteration 410, loss = 1.35994
I0525 23:50:52.474905 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.35994 (* 1 = 1.35994 loss)
I0525 23:50:52.474915 15394 sgd_solver.cpp:43] Iteration 410, lr = 0.02
I0525 23:50:57.727253 15394 main.cpp:354] Iteration 420, loss = 1.35552
I0525 23:50:57.727320 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.35552 (* 1 = 1.35552 loss)
I0525 23:50:57.727331 15394 sgd_solver.cpp:43] Iteration 420, lr = 0.02
I0525 23:51:02.695456 15394 main.cpp:354] Iteration 430, loss = 1.603
I0525 23:51:02.695518 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.603 (* 1 = 1.603 loss)
I0525 23:51:02.695528 15394 sgd_solver.cpp:43] Iteration 430, lr = 0.02
I0525 23:51:07.749270 15394 main.cpp:354] Iteration 440, loss = 1.43088
I0525 23:51:07.749341 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.43088 (* 1 = 1.43088 loss)
I0525 23:51:07.749352 15394 sgd_solver.cpp:43] Iteration 440, lr = 0.02
I0525 23:51:13.171072 15394 main.cpp:354] Iteration 450, loss = 1.41202
I0525 23:51:13.171145 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.41202 (* 1 = 1.41202 loss)
I0525 23:51:13.171156 15394 sgd_solver.cpp:43] Iteration 450, lr = 0.02
I0525 23:51:18.338883 15394 main.cpp:354] Iteration 460, loss = 1.43365
I0525 23:51:18.338958 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.43365 (* 1 = 1.43365 loss)
I0525 23:51:18.338971 15394 sgd_solver.cpp:43] Iteration 460, lr = 0.02
I0525 23:51:23.284778 15394 main.cpp:354] Iteration 470, loss = 1.67012
I0525 23:51:23.284842 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.67012 (* 1 = 1.67012 loss)
I0525 23:51:23.284852 15394 sgd_solver.cpp:43] Iteration 470, lr = 0.02
I0525 23:51:28.034435 15394 main.cpp:354] Iteration 480, loss = 1.50764
I0525 23:51:28.034505 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.50764 (* 1 = 1.50764 loss)
I0525 23:51:28.034515 15394 sgd_solver.cpp:43] Iteration 480, lr = 0.02
I0525 23:51:32.827003 15394 main.cpp:354] Iteration 490, loss = 1.30717
I0525 23:51:32.827076 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.30717 (* 1 = 1.30717 loss)
I0525 23:51:32.827087 15394 sgd_solver.cpp:43] Iteration 490, lr = 0.02
I0525 23:51:37.303463 15394 main.cpp:465] Iteration 500, Testing net (#0)
I0525 23:51:50.450667 15394 main.cpp:532]     Test net output #0: Accuracy = 0.2902
I0525 23:51:50.450738 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 2.69393 (* 1 = 2.69393 loss)
I0525 23:51:50.919497 15394 main.cpp:354] Iteration 500, loss = 1.50578
I0525 23:51:50.919570 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.50578 (* 1 = 1.50578 loss)
I0525 23:51:50.919587 15394 sgd_solver.cpp:43] Iteration 500, lr = 0.02
I0525 23:51:55.900532 15394 main.cpp:354] Iteration 510, loss = 1.28685
I0525 23:51:55.900607 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.28685 (* 1 = 1.28685 loss)
I0525 23:51:55.900631 15394 sgd_solver.cpp:43] Iteration 510, lr = 0.02
I0525 23:52:00.995961 15394 main.cpp:354] Iteration 520, loss = 1.46306
I0525 23:52:00.996031 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.46306 (* 1 = 1.46306 loss)
I0525 23:52:00.996042 15394 sgd_solver.cpp:43] Iteration 520, lr = 0.02
I0525 23:52:05.834024 15394 main.cpp:354] Iteration 530, loss = 1.54489
I0525 23:52:05.834110 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.54489 (* 1 = 1.54489 loss)
I0525 23:52:05.834120 15394 sgd_solver.cpp:43] Iteration 530, lr = 0.02
I0525 23:52:10.982149 15394 main.cpp:354] Iteration 540, loss = 1.42334
I0525 23:52:10.982220 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.42334 (* 1 = 1.42334 loss)
I0525 23:52:10.982231 15394 sgd_solver.cpp:43] Iteration 540, lr = 0.02
I0525 23:52:16.060801 15394 main.cpp:354] Iteration 550, loss = 1.56001
I0525 23:52:16.060874 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.56001 (* 1 = 1.56001 loss)
I0525 23:52:16.060886 15394 sgd_solver.cpp:43] Iteration 550, lr = 0.02
I0525 23:52:21.241863 15394 main.cpp:354] Iteration 560, loss = 1.35491
I0525 23:52:21.241947 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.35491 (* 1 = 1.35491 loss)
I0525 23:52:21.241958 15394 sgd_solver.cpp:43] Iteration 560, lr = 0.02
I0525 23:52:26.329586 15394 main.cpp:354] Iteration 570, loss = 1.46363
I0525 23:52:26.329656 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.46363 (* 1 = 1.46363 loss)
I0525 23:52:26.329668 15394 sgd_solver.cpp:43] Iteration 570, lr = 0.02
I0525 23:52:31.357336 15394 main.cpp:354] Iteration 580, loss = 1.38641
I0525 23:52:31.357406 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.38641 (* 1 = 1.38641 loss)
I0525 23:52:31.357417 15394 sgd_solver.cpp:43] Iteration 580, lr = 0.02
I0525 23:52:36.257416 15394 main.cpp:354] Iteration 590, loss = 1.19741
I0525 23:52:36.257495 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.19741 (* 1 = 1.19741 loss)
I0525 23:52:36.257506 15394 sgd_solver.cpp:43] Iteration 590, lr = 0.02
I0525 23:52:40.800784 15394 main.cpp:465] Iteration 600, Testing net (#0)
I0525 23:52:53.944022 15394 main.cpp:532]     Test net output #0: Accuracy = 0.2524
I0525 23:52:53.944082 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 3.34978 (* 1 = 3.34978 loss)
I0525 23:52:54.348479 15394 main.cpp:354] Iteration 600, loss = 1.46693
I0525 23:52:54.348554 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.46693 (* 1 = 1.46693 loss)
I0525 23:52:54.348569 15394 sgd_solver.cpp:43] Iteration 600, lr = 0.02
I0525 23:52:59.208472 15394 main.cpp:354] Iteration 610, loss = 1.37715
I0525 23:52:59.208541 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.37715 (* 1 = 1.37715 loss)
I0525 23:52:59.208552 15394 sgd_solver.cpp:43] Iteration 610, lr = 0.02
I0525 23:53:04.047436 15394 main.cpp:354] Iteration 620, loss = 1.38678
I0525 23:53:04.047523 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.38678 (* 1 = 1.38678 loss)
I0525 23:53:04.047534 15394 sgd_solver.cpp:43] Iteration 620, lr = 0.02
I0525 23:53:08.763622 15394 main.cpp:354] Iteration 630, loss = 1.51337
I0525 23:53:08.763690 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.51337 (* 1 = 1.51337 loss)
I0525 23:53:08.763700 15394 sgd_solver.cpp:43] Iteration 630, lr = 0.02
I0525 23:53:13.641752 15394 main.cpp:354] Iteration 640, loss = 1.37017
I0525 23:53:13.641824 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.37017 (* 1 = 1.37017 loss)
I0525 23:53:13.641835 15394 sgd_solver.cpp:43] Iteration 640, lr = 0.02
I0525 23:53:18.521118 15394 main.cpp:354] Iteration 650, loss = 1.30699
I0525 23:53:18.521196 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.30699 (* 1 = 1.30699 loss)
I0525 23:53:18.521209 15394 sgd_solver.cpp:43] Iteration 650, lr = 0.02
I0525 23:53:23.428210 15394 main.cpp:354] Iteration 660, loss = 1.54468
I0525 23:53:23.428282 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.54468 (* 1 = 1.54468 loss)
I0525 23:53:23.428309 15394 sgd_solver.cpp:43] Iteration 660, lr = 0.02
I0525 23:53:28.231593 15394 main.cpp:354] Iteration 670, loss = 1.45086
I0525 23:53:28.231663 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.45086 (* 1 = 1.45086 loss)
I0525 23:53:28.231675 15394 sgd_solver.cpp:43] Iteration 670, lr = 0.02
I0525 23:53:33.727125 15394 main.cpp:354] Iteration 680, loss = 1.36557
I0525 23:53:33.727200 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.36557 (* 1 = 1.36557 loss)
I0525 23:53:33.727211 15394 sgd_solver.cpp:43] Iteration 680, lr = 0.02
I0525 23:53:38.978322 15394 main.cpp:354] Iteration 690, loss = 1.48254
I0525 23:53:38.978396 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.48254 (* 1 = 1.48254 loss)
I0525 23:53:38.978407 15394 sgd_solver.cpp:43] Iteration 690, lr = 0.02
I0525 23:53:43.820390 15394 main.cpp:465] Iteration 700, Testing net (#0)
I0525 23:53:57.026708 15394 main.cpp:532]     Test net output #0: Accuracy = 0.2957
I0525 23:53:57.026775 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 2.6582 (* 1 = 2.6582 loss)
I0525 23:53:57.529580 15394 main.cpp:354] Iteration 700, loss = 1.39918
I0525 23:53:57.529664 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.39918 (* 1 = 1.39918 loss)
I0525 23:53:57.529683 15394 sgd_solver.cpp:43] Iteration 700, lr = 0.02
I0525 23:54:02.758580 15394 main.cpp:354] Iteration 710, loss = 1.38356
I0525 23:54:02.758647 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.38356 (* 1 = 1.38356 loss)
I0525 23:54:02.758657 15394 sgd_solver.cpp:43] Iteration 710, lr = 0.02
I0525 23:54:07.487388 15394 main.cpp:354] Iteration 720, loss = 1.34194
I0525 23:54:07.487457 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.34194 (* 1 = 1.34194 loss)
I0525 23:54:07.487468 15394 sgd_solver.cpp:43] Iteration 720, lr = 0.02
I0525 23:54:12.156524 15394 main.cpp:354] Iteration 730, loss = 1.43323
I0525 23:54:12.156586 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.43323 (* 1 = 1.43323 loss)
I0525 23:54:12.156597 15394 sgd_solver.cpp:43] Iteration 730, lr = 0.02
I0525 23:54:17.384331 15394 main.cpp:354] Iteration 740, loss = 1.37658
I0525 23:54:17.384399 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.37658 (* 1 = 1.37658 loss)
I0525 23:54:17.384410 15394 sgd_solver.cpp:43] Iteration 740, lr = 0.02
I0525 23:54:22.799901 15394 main.cpp:354] Iteration 750, loss = 1.27805
I0525 23:54:22.799974 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.27805 (* 1 = 1.27805 loss)
I0525 23:54:22.799985 15394 sgd_solver.cpp:43] Iteration 750, lr = 0.02
I0525 23:54:27.838593 15394 main.cpp:354] Iteration 760, loss = 1.22796
I0525 23:54:27.838657 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.22796 (* 1 = 1.22796 loss)
I0525 23:54:27.838667 15394 sgd_solver.cpp:43] Iteration 760, lr = 0.02
I0525 23:54:32.922813 15394 main.cpp:354] Iteration 770, loss = 1.26711
I0525 23:54:32.922894 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.26711 (* 1 = 1.26711 loss)
I0525 23:54:32.922907 15394 sgd_solver.cpp:43] Iteration 770, lr = 0.02
I0525 23:54:37.929302 15394 main.cpp:354] Iteration 780, loss = 1.2028
I0525 23:54:37.929368 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.2028 (* 1 = 1.2028 loss)
I0525 23:54:37.929380 15394 sgd_solver.cpp:43] Iteration 780, lr = 0.02
I0525 23:54:43.196205 15394 main.cpp:354] Iteration 790, loss = 1.14792
I0525 23:54:43.196269 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.14792 (* 1 = 1.14792 loss)
I0525 23:54:43.196281 15394 sgd_solver.cpp:43] Iteration 790, lr = 0.02
I0525 23:54:47.587057 15394 main.cpp:465] Iteration 800, Testing net (#0)
I0525 23:55:00.729115 15394 main.cpp:532]     Test net output #0: Accuracy = 0.2598
I0525 23:55:00.729177 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 4.29642 (* 1 = 4.29642 loss)
I0525 23:55:01.304267 15394 main.cpp:354] Iteration 800, loss = 1.14647
I0525 23:55:01.304350 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.14647 (* 1 = 1.14647 loss)
I0525 23:55:01.304366 15394 sgd_solver.cpp:43] Iteration 800, lr = 0.02
I0525 23:55:06.254806 15394 main.cpp:354] Iteration 810, loss = 1.16098
I0525 23:55:06.254880 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.16098 (* 1 = 1.16098 loss)
I0525 23:55:06.254891 15394 sgd_solver.cpp:43] Iteration 810, lr = 0.02
I0525 23:55:11.582630 15394 main.cpp:354] Iteration 820, loss = 1.3406
I0525 23:55:11.582690 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.3406 (* 1 = 1.3406 loss)
I0525 23:55:11.582700 15394 sgd_solver.cpp:43] Iteration 820, lr = 0.02
I0525 23:55:16.247957 15394 main.cpp:354] Iteration 830, loss = 1.23815
I0525 23:55:16.248023 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.23815 (* 1 = 1.23815 loss)
I0525 23:55:16.248034 15394 sgd_solver.cpp:43] Iteration 830, lr = 0.02
I0525 23:55:21.331058 15394 main.cpp:354] Iteration 840, loss = 1.29365
I0525 23:55:21.331125 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.29365 (* 1 = 1.29365 loss)
I0525 23:55:21.331135 15394 sgd_solver.cpp:43] Iteration 840, lr = 0.02
I0525 23:55:26.433023 15394 main.cpp:354] Iteration 850, loss = 1.27294
I0525 23:55:26.433084 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.27294 (* 1 = 1.27294 loss)
I0525 23:55:26.433094 15394 sgd_solver.cpp:43] Iteration 850, lr = 0.02
I0525 23:55:31.330322 15394 main.cpp:354] Iteration 860, loss = 1.15068
I0525 23:55:31.330389 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.15068 (* 1 = 1.15068 loss)
I0525 23:55:31.330399 15394 sgd_solver.cpp:43] Iteration 860, lr = 0.02
I0525 23:55:35.996466 15394 main.cpp:354] Iteration 870, loss = 1.25486
I0525 23:55:35.996541 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.25486 (* 1 = 1.25486 loss)
I0525 23:55:35.996551 15394 sgd_solver.cpp:43] Iteration 870, lr = 0.02
I0525 23:55:40.990701 15394 main.cpp:354] Iteration 880, loss = 1.26552
I0525 23:55:40.990767 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.26552 (* 1 = 1.26552 loss)
I0525 23:55:40.990777 15394 sgd_solver.cpp:43] Iteration 880, lr = 0.02
I0525 23:55:45.752905 15394 main.cpp:354] Iteration 890, loss = 1.16596
I0525 23:55:45.752966 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.16596 (* 1 = 1.16596 loss)
I0525 23:55:45.752976 15394 sgd_solver.cpp:43] Iteration 890, lr = 0.02
I0525 23:55:50.404681 15394 main.cpp:465] Iteration 900, Testing net (#0)
I0525 23:56:03.548130 15394 main.cpp:532]     Test net output #0: Accuracy = 0.2626
I0525 23:56:03.548197 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 3.68707 (* 1 = 3.68707 loss)
I0525 23:56:04.018127 15394 main.cpp:354] Iteration 900, loss = 1.27325
I0525 23:56:04.018199 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.27325 (* 1 = 1.27325 loss)
I0525 23:56:04.018214 15394 sgd_solver.cpp:43] Iteration 900, lr = 0.02
I0525 23:56:08.970907 15394 main.cpp:354] Iteration 910, loss = 1.43113
I0525 23:56:08.970973 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.43113 (* 1 = 1.43113 loss)
I0525 23:56:08.970984 15394 sgd_solver.cpp:43] Iteration 910, lr = 0.02
I0525 23:56:13.811056 15394 main.cpp:354] Iteration 920, loss = 1.2916
I0525 23:56:13.811125 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.2916 (* 1 = 1.2916 loss)
I0525 23:56:13.811136 15394 sgd_solver.cpp:43] Iteration 920, lr = 0.02
I0525 23:56:18.901729 15394 main.cpp:354] Iteration 930, loss = 1.36711
I0525 23:56:18.901799 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.36711 (* 1 = 1.36711 loss)
I0525 23:56:18.901809 15394 sgd_solver.cpp:43] Iteration 930, lr = 0.02
I0525 23:56:24.168043 15394 main.cpp:354] Iteration 940, loss = 1.23955
I0525 23:56:24.168105 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.23955 (* 1 = 1.23955 loss)
I0525 23:56:24.168117 15394 sgd_solver.cpp:43] Iteration 940, lr = 0.02
I0525 23:56:29.484891 15394 main.cpp:354] Iteration 950, loss = 1.0857
I0525 23:56:29.484956 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.0857 (* 1 = 1.0857 loss)
I0525 23:56:29.484967 15394 sgd_solver.cpp:43] Iteration 950, lr = 0.02
I0525 23:56:34.680312 15394 main.cpp:354] Iteration 960, loss = 1.13121
I0525 23:56:34.680388 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.13121 (* 1 = 1.13121 loss)
I0525 23:56:34.680400 15394 sgd_solver.cpp:43] Iteration 960, lr = 0.02
I0525 23:56:39.934244 15394 main.cpp:354] Iteration 970, loss = 1.14413
I0525 23:56:39.934304 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.14413 (* 1 = 1.14413 loss)
I0525 23:56:39.934314 15394 sgd_solver.cpp:43] Iteration 970, lr = 0.02
I0525 23:56:45.136955 15394 main.cpp:354] Iteration 980, loss = 1.13137
I0525 23:56:45.137024 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.13137 (* 1 = 1.13137 loss)
I0525 23:56:45.137035 15394 sgd_solver.cpp:43] Iteration 980, lr = 0.02
I0525 23:56:50.154669 15394 main.cpp:354] Iteration 990, loss = 1.20179
I0525 23:56:50.154736 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.20179 (* 1 = 1.20179 loss)
I0525 23:56:50.154745 15394 sgd_solver.cpp:43] Iteration 990, lr = 0.02
I0525 23:56:54.932245 15394 main.cpp:465] Iteration 1000, Testing net (#0)
I0525 23:57:08.154511 15394 main.cpp:532]     Test net output #0: Accuracy = 0.2392
I0525 23:57:08.154583 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 3.82072 (* 1 = 3.82072 loss)
I0525 23:57:08.592689 15394 main.cpp:354] Iteration 1000, loss = 1.21403
I0525 23:57:08.592764 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.21403 (* 1 = 1.21403 loss)
I0525 23:57:08.592778 15394 sgd_solver.cpp:43] Iteration 1000, lr = 0.02
I0525 23:57:13.764266 15394 main.cpp:354] Iteration 1010, loss = 0.947101
I0525 23:57:13.764338 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.947101 (* 1 = 0.947101 loss)
I0525 23:57:13.764349 15394 sgd_solver.cpp:43] Iteration 1010, lr = 0.02
I0525 23:57:19.042155 15394 main.cpp:354] Iteration 1020, loss = 1.24848
I0525 23:57:19.042232 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.24848 (* 1 = 1.24848 loss)
I0525 23:57:19.042243 15394 sgd_solver.cpp:43] Iteration 1020, lr = 0.02
I0525 23:57:24.167614 15394 main.cpp:354] Iteration 1030, loss = 1.21744
I0525 23:57:24.167683 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.21744 (* 1 = 1.21744 loss)
I0525 23:57:24.167695 15394 sgd_solver.cpp:43] Iteration 1030, lr = 0.02
I0525 23:57:28.991549 15394 main.cpp:354] Iteration 1040, loss = 1.18114
I0525 23:57:28.991614 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.18114 (* 1 = 1.18114 loss)
I0525 23:57:28.991626 15394 sgd_solver.cpp:43] Iteration 1040, lr = 0.02
I0525 23:57:33.889241 15394 main.cpp:354] Iteration 1050, loss = 1.06879
I0525 23:57:33.889317 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.06879 (* 1 = 1.06879 loss)
I0525 23:57:33.889328 15394 sgd_solver.cpp:43] Iteration 1050, lr = 0.02
I0525 23:57:39.071266 15394 main.cpp:354] Iteration 1060, loss = 1.12133
I0525 23:57:39.071354 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.12133 (* 1 = 1.12133 loss)
I0525 23:57:39.071367 15394 sgd_solver.cpp:43] Iteration 1060, lr = 0.02
I0525 23:57:43.940980 15394 main.cpp:354] Iteration 1070, loss = 1.13157
I0525 23:57:43.941052 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.13157 (* 1 = 1.13157 loss)
I0525 23:57:43.941064 15394 sgd_solver.cpp:43] Iteration 1070, lr = 0.02
I0525 23:57:48.648597 15394 main.cpp:354] Iteration 1080, loss = 1.25263
I0525 23:57:48.648687 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.25263 (* 1 = 1.25263 loss)
I0525 23:57:48.648699 15394 sgd_solver.cpp:43] Iteration 1080, lr = 0.02
I0525 23:57:53.649206 15394 main.cpp:354] Iteration 1090, loss = 1.34884
I0525 23:57:53.649272 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.34884 (* 1 = 1.34884 loss)
I0525 23:57:53.649296 15394 sgd_solver.cpp:43] Iteration 1090, lr = 0.02
I0525 23:57:58.208297 15394 main.cpp:465] Iteration 1100, Testing net (#0)
I0525 23:58:11.457007 15394 main.cpp:532]     Test net output #0: Accuracy = 0.4327
I0525 23:58:11.457070 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.82623 (* 1 = 1.82623 loss)
I0525 23:58:11.922755 15394 main.cpp:354] Iteration 1100, loss = 1.22124
I0525 23:58:11.922857 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.22124 (* 1 = 1.22124 loss)
I0525 23:58:11.922871 15394 sgd_solver.cpp:43] Iteration 1100, lr = 0.02
I0525 23:58:16.840736 15394 main.cpp:354] Iteration 1110, loss = 1.23457
I0525 23:58:16.840806 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.23457 (* 1 = 1.23457 loss)
I0525 23:58:16.840817 15394 sgd_solver.cpp:43] Iteration 1110, lr = 0.02
I0525 23:58:21.633884 15394 main.cpp:354] Iteration 1120, loss = 1.1295
I0525 23:58:21.633954 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.1295 (* 1 = 1.1295 loss)
I0525 23:58:21.633963 15394 sgd_solver.cpp:43] Iteration 1120, lr = 0.02
I0525 23:58:26.929306 15394 main.cpp:354] Iteration 1130, loss = 1.12899
I0525 23:58:26.929368 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.12899 (* 1 = 1.12899 loss)
I0525 23:58:26.929378 15394 sgd_solver.cpp:43] Iteration 1130, lr = 0.02
I0525 23:58:32.307745 15394 main.cpp:354] Iteration 1140, loss = 1.04363
I0525 23:58:32.307819 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.04363 (* 1 = 1.04363 loss)
I0525 23:58:32.307829 15394 sgd_solver.cpp:43] Iteration 1140, lr = 0.02
I0525 23:58:37.399699 15394 main.cpp:354] Iteration 1150, loss = 1.11472
I0525 23:58:37.399773 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.11472 (* 1 = 1.11472 loss)
I0525 23:58:37.399783 15394 sgd_solver.cpp:43] Iteration 1150, lr = 0.02
I0525 23:58:42.140491 15394 main.cpp:354] Iteration 1160, loss = 1.16422
I0525 23:58:42.140553 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.16422 (* 1 = 1.16422 loss)
I0525 23:58:42.140563 15394 sgd_solver.cpp:43] Iteration 1160, lr = 0.02
I0525 23:58:47.383731 15394 main.cpp:354] Iteration 1170, loss = 0.989993
I0525 23:58:47.383797 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.989993 (* 1 = 0.989993 loss)
I0525 23:58:47.383808 15394 sgd_solver.cpp:43] Iteration 1170, lr = 0.02
I0525 23:58:52.100476 15394 main.cpp:354] Iteration 1180, loss = 1.07949
I0525 23:58:52.100548 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.07949 (* 1 = 1.07949 loss)
I0525 23:58:52.100558 15394 sgd_solver.cpp:43] Iteration 1180, lr = 0.02
I0525 23:58:57.496642 15394 main.cpp:354] Iteration 1190, loss = 1.09148
I0525 23:58:57.496712 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.09148 (* 1 = 1.09148 loss)
I0525 23:58:57.496724 15394 sgd_solver.cpp:43] Iteration 1190, lr = 0.02
I0525 23:59:02.051965 15394 main.cpp:465] Iteration 1200, Testing net (#0)
I0525 23:59:15.281816 15394 main.cpp:532]     Test net output #0: Accuracy = 0.3491
I0525 23:59:15.281883 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 2.4734 (* 1 = 2.4734 loss)
I0525 23:59:15.716387 15394 main.cpp:354] Iteration 1200, loss = 0.932472
I0525 23:59:15.716461 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.932472 (* 1 = 0.932472 loss)
I0525 23:59:15.716478 15394 sgd_solver.cpp:43] Iteration 1200, lr = 0.02
I0525 23:59:20.667409 15394 main.cpp:354] Iteration 1210, loss = 1.20367
I0525 23:59:20.667484 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.20367 (* 1 = 1.20367 loss)
I0525 23:59:20.667495 15394 sgd_solver.cpp:43] Iteration 1210, lr = 0.02
I0525 23:59:25.808454 15394 main.cpp:354] Iteration 1220, loss = 1.16227
I0525 23:59:25.808521 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.16227 (* 1 = 1.16227 loss)
I0525 23:59:25.808531 15394 sgd_solver.cpp:43] Iteration 1220, lr = 0.02
I0525 23:59:30.861896 15394 main.cpp:354] Iteration 1230, loss = 1.04547
I0525 23:59:30.861974 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.04547 (* 1 = 1.04547 loss)
I0525 23:59:30.861985 15394 sgd_solver.cpp:43] Iteration 1230, lr = 0.02
I0525 23:59:35.798564 15394 main.cpp:354] Iteration 1240, loss = 1.15491
I0525 23:59:35.798637 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.15491 (* 1 = 1.15491 loss)
I0525 23:59:35.798648 15394 sgd_solver.cpp:43] Iteration 1240, lr = 0.02
I0525 23:59:41.021813 15394 main.cpp:354] Iteration 1250, loss = 1.03909
I0525 23:59:41.021879 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.03909 (* 1 = 1.03909 loss)
I0525 23:59:41.021889 15394 sgd_solver.cpp:43] Iteration 1250, lr = 0.02
I0525 23:59:45.942800 15394 main.cpp:354] Iteration 1260, loss = 1.1101
I0525 23:59:45.942870 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.1101 (* 1 = 1.1101 loss)
I0525 23:59:45.942881 15394 sgd_solver.cpp:43] Iteration 1260, lr = 0.02
I0525 23:59:51.369911 15394 main.cpp:354] Iteration 1270, loss = 1.13696
I0525 23:59:51.369989 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.13696 (* 1 = 1.13696 loss)
I0525 23:59:51.370002 15394 sgd_solver.cpp:43] Iteration 1270, lr = 0.02
I0525 23:59:56.477196 15394 main.cpp:354] Iteration 1280, loss = 1.09194
I0525 23:59:56.477264 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.09194 (* 1 = 1.09194 loss)
I0525 23:59:56.477275 15394 sgd_solver.cpp:43] Iteration 1280, lr = 0.02
I0526 00:00:01.443970 15394 main.cpp:354] Iteration 1290, loss = 1.15758
I0526 00:00:01.444042 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.15758 (* 1 = 1.15758 loss)
I0526 00:00:01.444054 15394 sgd_solver.cpp:43] Iteration 1290, lr = 0.02
I0526 00:00:06.314628 15394 main.cpp:465] Iteration 1300, Testing net (#0)
I0526 00:00:19.502621 15394 main.cpp:532]     Test net output #0: Accuracy = 0.233
I0526 00:00:19.502682 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 4.34564 (* 1 = 4.34564 loss)
I0526 00:00:20.003774 15394 main.cpp:354] Iteration 1300, loss = 1.07567
I0526 00:00:20.003847 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.07567 (* 1 = 1.07567 loss)
I0526 00:00:20.003865 15394 sgd_solver.cpp:43] Iteration 1300, lr = 0.02
I0526 00:00:25.159477 15394 main.cpp:354] Iteration 1310, loss = 1.26456
I0526 00:00:25.159546 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.26456 (* 1 = 1.26456 loss)
I0526 00:00:25.159559 15394 sgd_solver.cpp:43] Iteration 1310, lr = 0.02
I0526 00:00:30.201968 15394 main.cpp:354] Iteration 1320, loss = 1.15725
I0526 00:00:30.202035 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.15725 (* 1 = 1.15725 loss)
I0526 00:00:30.202046 15394 sgd_solver.cpp:43] Iteration 1320, lr = 0.02
I0526 00:00:35.591065 15394 main.cpp:354] Iteration 1330, loss = 1.12321
I0526 00:00:35.591135 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.12321 (* 1 = 1.12321 loss)
I0526 00:00:35.591146 15394 sgd_solver.cpp:43] Iteration 1330, lr = 0.02
I0526 00:00:40.934312 15394 main.cpp:354] Iteration 1340, loss = 1.16401
I0526 00:00:40.934381 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.16401 (* 1 = 1.16401 loss)
I0526 00:00:40.934391 15394 sgd_solver.cpp:43] Iteration 1340, lr = 0.02
I0526 00:00:46.274346 15394 main.cpp:354] Iteration 1350, loss = 1.15308
I0526 00:00:46.274410 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.15308 (* 1 = 1.15308 loss)
I0526 00:00:46.274420 15394 sgd_solver.cpp:43] Iteration 1350, lr = 0.02
I0526 00:00:51.504811 15394 main.cpp:354] Iteration 1360, loss = 0.860046
I0526 00:00:51.504890 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.860046 (* 1 = 0.860046 loss)
I0526 00:00:51.504901 15394 sgd_solver.cpp:43] Iteration 1360, lr = 0.02
I0526 00:00:56.561660 15394 main.cpp:354] Iteration 1370, loss = 1.10419
I0526 00:00:56.561728 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.10419 (* 1 = 1.10419 loss)
I0526 00:00:56.561739 15394 sgd_solver.cpp:43] Iteration 1370, lr = 0.02
I0526 00:01:00.823483 15394 main.cpp:354] Iteration 1380, loss = 1.19735
I0526 00:01:00.823549 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.19735 (* 1 = 1.19735 loss)
I0526 00:01:00.823559 15394 sgd_solver.cpp:43] Iteration 1380, lr = 0.02
I0526 00:01:06.163696 15394 main.cpp:354] Iteration 1390, loss = 1.00745
I0526 00:01:06.163770 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.00745 (* 1 = 1.00745 loss)
I0526 00:01:06.163782 15394 sgd_solver.cpp:43] Iteration 1390, lr = 0.02
I0526 00:01:10.869482 15394 main.cpp:465] Iteration 1400, Testing net (#0)
I0526 00:01:24.055579 15394 main.cpp:532]     Test net output #0: Accuracy = 0.4121
I0526 00:01:24.055642 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 2.48798 (* 1 = 2.48798 loss)
I0526 00:01:24.594496 15394 main.cpp:354] Iteration 1400, loss = 0.987178
I0526 00:01:24.594568 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.987178 (* 1 = 0.987178 loss)
I0526 00:01:24.594581 15394 sgd_solver.cpp:43] Iteration 1400, lr = 0.02
I0526 00:01:29.845790 15394 main.cpp:354] Iteration 1410, loss = 0.924839
I0526 00:01:29.845860 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.924839 (* 1 = 0.924839 loss)
I0526 00:01:29.845871 15394 sgd_solver.cpp:43] Iteration 1410, lr = 0.02
I0526 00:01:35.130653 15394 main.cpp:354] Iteration 1420, loss = 1.27703
I0526 00:01:35.130733 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.27703 (* 1 = 1.27703 loss)
I0526 00:01:35.130745 15394 sgd_solver.cpp:43] Iteration 1420, lr = 0.02
I0526 00:01:39.648378 15394 main.cpp:354] Iteration 1430, loss = 1.01518
I0526 00:01:39.648444 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.01518 (* 1 = 1.01518 loss)
I0526 00:01:39.648455 15394 sgd_solver.cpp:43] Iteration 1430, lr = 0.02
I0526 00:01:44.347884 15394 main.cpp:354] Iteration 1440, loss = 1.19135
I0526 00:01:44.347993 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.19135 (* 1 = 1.19135 loss)
I0526 00:01:44.348006 15394 sgd_solver.cpp:43] Iteration 1440, lr = 0.02
I0526 00:01:49.852669 15394 main.cpp:354] Iteration 1450, loss = 1.12391
I0526 00:01:49.852742 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.12391 (* 1 = 1.12391 loss)
I0526 00:01:49.852753 15394 sgd_solver.cpp:43] Iteration 1450, lr = 0.02
I0526 00:01:54.983000 15394 main.cpp:354] Iteration 1460, loss = 1.21034
I0526 00:01:54.983069 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.21034 (* 1 = 1.21034 loss)
I0526 00:01:54.983081 15394 sgd_solver.cpp:43] Iteration 1460, lr = 0.02
I0526 00:01:59.519678 15394 main.cpp:354] Iteration 1470, loss = 0.989212
I0526 00:01:59.519748 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.989212 (* 1 = 0.989212 loss)
I0526 00:01:59.519760 15394 sgd_solver.cpp:43] Iteration 1470, lr = 0.02
I0526 00:02:04.397258 15394 main.cpp:354] Iteration 1480, loss = 0.821856
I0526 00:02:04.397325 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.821856 (* 1 = 0.821856 loss)
I0526 00:02:04.397335 15394 sgd_solver.cpp:43] Iteration 1480, lr = 0.02
I0526 00:02:09.580397 15394 main.cpp:354] Iteration 1490, loss = 1.1464
I0526 00:02:09.580466 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.1464 (* 1 = 1.1464 loss)
I0526 00:02:09.580476 15394 sgd_solver.cpp:43] Iteration 1490, lr = 0.02
I0526 00:02:13.810423 15394 main.cpp:465] Iteration 1500, Testing net (#0)
I0526 00:02:27.150310 15394 main.cpp:532]     Test net output #0: Accuracy = 0.5055
I0526 00:02:27.150382 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.5728 (* 1 = 1.5728 loss)
I0526 00:02:27.617671 15394 main.cpp:354] Iteration 1500, loss = 1.06164
I0526 00:02:27.617744 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.06164 (* 1 = 1.06164 loss)
I0526 00:02:27.617759 15394 sgd_solver.cpp:43] Iteration 1500, lr = 0.02
I0526 00:02:33.401209 15394 main.cpp:354] Iteration 1510, loss = 0.93486
I0526 00:02:33.401283 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.93486 (* 1 = 0.93486 loss)
I0526 00:02:33.401307 15394 sgd_solver.cpp:43] Iteration 1510, lr = 0.02
I0526 00:02:38.267406 15394 main.cpp:354] Iteration 1520, loss = 1.05585
I0526 00:02:38.267465 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.05585 (* 1 = 1.05585 loss)
I0526 00:02:38.267477 15394 sgd_solver.cpp:43] Iteration 1520, lr = 0.02
I0526 00:02:43.564106 15394 main.cpp:354] Iteration 1530, loss = 0.955883
I0526 00:02:43.564170 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.955883 (* 1 = 0.955883 loss)
I0526 00:02:43.564182 15394 sgd_solver.cpp:43] Iteration 1530, lr = 0.02
I0526 00:02:49.004668 15394 main.cpp:354] Iteration 1540, loss = 0.958912
I0526 00:02:49.004750 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.958912 (* 1 = 0.958912 loss)
I0526 00:02:49.004760 15394 sgd_solver.cpp:43] Iteration 1540, lr = 0.02
I0526 00:02:54.017686 15394 main.cpp:354] Iteration 1550, loss = 0.896992
I0526 00:02:54.017750 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.896992 (* 1 = 0.896992 loss)
I0526 00:02:54.017761 15394 sgd_solver.cpp:43] Iteration 1550, lr = 0.02
I0526 00:02:59.470669 15394 main.cpp:354] Iteration 1560, loss = 1.12649
I0526 00:02:59.470733 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.12649 (* 1 = 1.12649 loss)
I0526 00:02:59.470744 15394 sgd_solver.cpp:43] Iteration 1560, lr = 0.02
I0526 00:03:04.255596 15394 main.cpp:354] Iteration 1570, loss = 0.894966
I0526 00:03:04.255668 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.894966 (* 1 = 0.894966 loss)
I0526 00:03:04.255679 15394 sgd_solver.cpp:43] Iteration 1570, lr = 0.02
I0526 00:03:09.318883 15394 main.cpp:354] Iteration 1580, loss = 0.989457
I0526 00:03:09.318950 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.989457 (* 1 = 0.989457 loss)
I0526 00:03:09.318963 15394 sgd_solver.cpp:43] Iteration 1580, lr = 0.02
I0526 00:03:14.060389 15394 main.cpp:354] Iteration 1590, loss = 1.21447
I0526 00:03:14.060452 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.21447 (* 1 = 1.21447 loss)
I0526 00:03:14.060463 15394 sgd_solver.cpp:43] Iteration 1590, lr = 0.02
I0526 00:03:18.926879 15394 main.cpp:465] Iteration 1600, Testing net (#0)
I0526 00:03:32.094601 15394 main.cpp:532]     Test net output #0: Accuracy = 0.4513
I0526 00:03:32.094667 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 2.12099 (* 1 = 2.12099 loss)
I0526 00:03:32.528048 15394 main.cpp:354] Iteration 1600, loss = 1.07666
I0526 00:03:32.528120 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.07666 (* 1 = 1.07666 loss)
I0526 00:03:32.528131 15394 sgd_solver.cpp:43] Iteration 1600, lr = 0.02
I0526 00:03:37.334878 15394 main.cpp:354] Iteration 1610, loss = 0.948177
I0526 00:03:37.334954 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.948177 (* 1 = 0.948177 loss)
I0526 00:03:37.334964 15394 sgd_solver.cpp:43] Iteration 1610, lr = 0.02
I0526 00:03:42.597802 15394 main.cpp:354] Iteration 1620, loss = 1.18764
I0526 00:03:42.597868 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.18764 (* 1 = 1.18764 loss)
I0526 00:03:42.597879 15394 sgd_solver.cpp:43] Iteration 1620, lr = 0.02
I0526 00:03:48.035362 15394 main.cpp:354] Iteration 1630, loss = 1.02023
I0526 00:03:48.035439 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.02023 (* 1 = 1.02023 loss)
I0526 00:03:48.035454 15394 sgd_solver.cpp:43] Iteration 1630, lr = 0.02
I0526 00:03:53.201732 15394 main.cpp:354] Iteration 1640, loss = 0.896512
I0526 00:03:53.201800 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.896512 (* 1 = 0.896512 loss)
I0526 00:03:53.201812 15394 sgd_solver.cpp:43] Iteration 1640, lr = 0.02
I0526 00:03:58.537729 15394 main.cpp:354] Iteration 1650, loss = 0.937586
I0526 00:03:58.537796 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.937586 (* 1 = 0.937586 loss)
I0526 00:03:58.537806 15394 sgd_solver.cpp:43] Iteration 1650, lr = 0.02
I0526 00:04:03.801314 15394 main.cpp:354] Iteration 1660, loss = 1.20314
I0526 00:04:03.801388 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.20314 (* 1 = 1.20314 loss)
I0526 00:04:03.801399 15394 sgd_solver.cpp:43] Iteration 1660, lr = 0.02
I0526 00:04:08.281473 15394 main.cpp:354] Iteration 1670, loss = 1.1974
I0526 00:04:08.281544 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.1974 (* 1 = 1.1974 loss)
I0526 00:04:08.281556 15394 sgd_solver.cpp:43] Iteration 1670, lr = 0.02
I0526 00:04:13.437702 15394 main.cpp:354] Iteration 1680, loss = 0.933304
I0526 00:04:13.437768 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.933304 (* 1 = 0.933304 loss)
I0526 00:04:13.437780 15394 sgd_solver.cpp:43] Iteration 1680, lr = 0.02
I0526 00:04:18.326546 15394 main.cpp:354] Iteration 1690, loss = 0.919467
I0526 00:04:18.326623 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.919467 (* 1 = 0.919467 loss)
I0526 00:04:18.326637 15394 sgd_solver.cpp:43] Iteration 1690, lr = 0.02
I0526 00:04:23.252532 15394 main.cpp:465] Iteration 1700, Testing net (#0)
I0526 00:04:36.413929 15394 main.cpp:532]     Test net output #0: Accuracy = 0.4716
I0526 00:04:36.413993 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.96214 (* 1 = 1.96214 loss)
I0526 00:04:36.711678 15394 main.cpp:354] Iteration 1700, loss = 1.4508
I0526 00:04:36.711751 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.4508 (* 1 = 1.4508 loss)
I0526 00:04:36.711767 15394 sgd_solver.cpp:43] Iteration 1700, lr = 0.02
I0526 00:04:41.837579 15394 main.cpp:354] Iteration 1710, loss = 1.03575
I0526 00:04:41.837652 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.03575 (* 1 = 1.03575 loss)
I0526 00:04:41.837664 15394 sgd_solver.cpp:43] Iteration 1710, lr = 0.02
I0526 00:04:46.908551 15394 main.cpp:354] Iteration 1720, loss = 1.18936
I0526 00:04:46.908613 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.18936 (* 1 = 1.18936 loss)
I0526 00:04:46.908623 15394 sgd_solver.cpp:43] Iteration 1720, lr = 0.02
I0526 00:04:52.133147 15394 main.cpp:354] Iteration 1730, loss = 1.14479
I0526 00:04:52.133216 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.14479 (* 1 = 1.14479 loss)
I0526 00:04:52.133227 15394 sgd_solver.cpp:43] Iteration 1730, lr = 0.02
I0526 00:04:57.244379 15394 main.cpp:354] Iteration 1740, loss = 1.07186
I0526 00:04:57.244446 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.07186 (* 1 = 1.07186 loss)
I0526 00:04:57.244457 15394 sgd_solver.cpp:43] Iteration 1740, lr = 0.02
I0526 00:05:02.116858 15394 main.cpp:354] Iteration 1750, loss = 0.790194
I0526 00:05:02.116930 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.790194 (* 1 = 0.790194 loss)
I0526 00:05:02.116941 15394 sgd_solver.cpp:43] Iteration 1750, lr = 0.02
I0526 00:05:07.626976 15394 main.cpp:354] Iteration 1760, loss = 0.880486
I0526 00:05:07.627053 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.880486 (* 1 = 0.880486 loss)
I0526 00:05:07.627064 15394 sgd_solver.cpp:43] Iteration 1760, lr = 0.02
I0526 00:05:12.686998 15394 main.cpp:354] Iteration 1770, loss = 0.998362
I0526 00:05:12.687062 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.998362 (* 1 = 0.998362 loss)
I0526 00:05:12.687073 15394 sgd_solver.cpp:43] Iteration 1770, lr = 0.02
I0526 00:05:17.696523 15394 main.cpp:354] Iteration 1780, loss = 0.967002
I0526 00:05:17.696594 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.967002 (* 1 = 0.967002 loss)
I0526 00:05:17.696605 15394 sgd_solver.cpp:43] Iteration 1780, lr = 0.02
I0526 00:05:22.905542 15394 main.cpp:354] Iteration 1790, loss = 1.15378
I0526 00:05:22.905621 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.15378 (* 1 = 1.15378 loss)
I0526 00:05:22.905632 15394 sgd_solver.cpp:43] Iteration 1790, lr = 0.02
I0526 00:05:27.697748 15394 main.cpp:465] Iteration 1800, Testing net (#0)
I0526 00:05:40.880185 15394 main.cpp:532]     Test net output #0: Accuracy = 0.5197
I0526 00:05:40.880262 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.77584 (* 1 = 1.77584 loss)
I0526 00:05:41.315886 15394 main.cpp:354] Iteration 1800, loss = 1.01894
I0526 00:05:41.315971 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.01894 (* 1 = 1.01894 loss)
I0526 00:05:41.315987 15394 sgd_solver.cpp:43] Iteration 1800, lr = 0.02
I0526 00:05:46.810595 15394 main.cpp:354] Iteration 1810, loss = 0.783721
I0526 00:05:46.810659 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.783721 (* 1 = 0.783721 loss)
I0526 00:05:46.810670 15394 sgd_solver.cpp:43] Iteration 1810, lr = 0.02
I0526 00:05:51.920493 15394 main.cpp:354] Iteration 1820, loss = 1.17912
I0526 00:05:51.920570 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.17912 (* 1 = 1.17912 loss)
I0526 00:05:51.920583 15394 sgd_solver.cpp:43] Iteration 1820, lr = 0.02
I0526 00:05:57.217305 15394 main.cpp:354] Iteration 1830, loss = 0.995408
I0526 00:05:57.217375 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.995408 (* 1 = 0.995408 loss)
I0526 00:05:57.217386 15394 sgd_solver.cpp:43] Iteration 1830, lr = 0.02
I0526 00:06:02.257313 15394 main.cpp:354] Iteration 1840, loss = 1.00046
I0526 00:06:02.257376 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.00046 (* 1 = 1.00046 loss)
I0526 00:06:02.257386 15394 sgd_solver.cpp:43] Iteration 1840, lr = 0.02
I0526 00:06:07.553673 15394 main.cpp:354] Iteration 1850, loss = 0.928893
I0526 00:06:07.553747 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.928893 (* 1 = 0.928893 loss)
I0526 00:06:07.553758 15394 sgd_solver.cpp:43] Iteration 1850, lr = 0.02
I0526 00:06:12.932009 15394 main.cpp:354] Iteration 1860, loss = 0.899778
I0526 00:06:12.932080 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.899778 (* 1 = 0.899778 loss)
I0526 00:06:12.932090 15394 sgd_solver.cpp:43] Iteration 1860, lr = 0.02
I0526 00:06:18.226143 15394 main.cpp:354] Iteration 1870, loss = 1.17269
I0526 00:06:18.226224 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.17269 (* 1 = 1.17269 loss)
I0526 00:06:18.226238 15394 sgd_solver.cpp:43] Iteration 1870, lr = 0.02
I0526 00:06:23.034660 15394 main.cpp:354] Iteration 1880, loss = 0.978812
I0526 00:06:23.034735 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.978812 (* 1 = 0.978812 loss)
I0526 00:06:23.034747 15394 sgd_solver.cpp:43] Iteration 1880, lr = 0.02
I0526 00:06:27.918920 15394 main.cpp:354] Iteration 1890, loss = 0.966115
I0526 00:06:27.918990 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.966115 (* 1 = 0.966115 loss)
I0526 00:06:27.919001 15394 sgd_solver.cpp:43] Iteration 1890, lr = 0.02
I0526 00:06:32.540734 15394 main.cpp:465] Iteration 1900, Testing net (#0)
I0526 00:06:45.744609 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6065
I0526 00:06:45.744676 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.17287 (* 1 = 1.17287 loss)
I0526 00:06:46.183668 15394 main.cpp:354] Iteration 1900, loss = 1.18818
I0526 00:06:46.183738 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.18818 (* 1 = 1.18818 loss)
I0526 00:06:46.183755 15394 sgd_solver.cpp:43] Iteration 1900, lr = 0.02
I0526 00:06:51.203517 15394 main.cpp:354] Iteration 1910, loss = 0.902064
I0526 00:06:51.203599 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.902064 (* 1 = 0.902064 loss)
I0526 00:06:51.203610 15394 sgd_solver.cpp:43] Iteration 1910, lr = 0.02
I0526 00:06:56.520112 15394 main.cpp:354] Iteration 1920, loss = 0.841285
I0526 00:06:56.520181 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.841285 (* 1 = 0.841285 loss)
I0526 00:06:56.520193 15394 sgd_solver.cpp:43] Iteration 1920, lr = 0.02
I0526 00:07:01.185832 15394 main.cpp:354] Iteration 1930, loss = 0.914451
I0526 00:07:01.185904 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.914451 (* 1 = 0.914451 loss)
I0526 00:07:01.185915 15394 sgd_solver.cpp:43] Iteration 1930, lr = 0.02
I0526 00:07:06.299909 15394 main.cpp:354] Iteration 1940, loss = 0.790683
I0526 00:07:06.300009 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.790683 (* 1 = 0.790683 loss)
I0526 00:07:06.300020 15394 sgd_solver.cpp:43] Iteration 1940, lr = 0.02
I0526 00:07:11.182555 15394 main.cpp:354] Iteration 1950, loss = 1.06881
I0526 00:07:11.182621 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.06881 (* 1 = 1.06881 loss)
I0526 00:07:11.182631 15394 sgd_solver.cpp:43] Iteration 1950, lr = 0.02
I0526 00:07:16.164233 15394 main.cpp:354] Iteration 1960, loss = 0.998461
I0526 00:07:16.164306 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.998461 (* 1 = 0.998461 loss)
I0526 00:07:16.164316 15394 sgd_solver.cpp:43] Iteration 1960, lr = 0.02
I0526 00:07:21.471366 15394 main.cpp:354] Iteration 1970, loss = 0.784571
I0526 00:07:21.471437 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.784571 (* 1 = 0.784571 loss)
I0526 00:07:21.471448 15394 sgd_solver.cpp:43] Iteration 1970, lr = 0.02
I0526 00:07:26.164589 15394 main.cpp:354] Iteration 1980, loss = 1.12567
I0526 00:07:26.164654 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.12567 (* 1 = 1.12567 loss)
I0526 00:07:26.164665 15394 sgd_solver.cpp:43] Iteration 1980, lr = 0.02
I0526 00:07:31.182327 15394 main.cpp:354] Iteration 1990, loss = 0.956775
I0526 00:07:31.182400 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.956775 (* 1 = 0.956775 loss)
I0526 00:07:31.182411 15394 sgd_solver.cpp:43] Iteration 1990, lr = 0.02
I0526 00:07:35.959444 15394 main.cpp:465] Iteration 2000, Testing net (#0)
I0526 00:07:49.219087 15394 main.cpp:532]     Test net output #0: Accuracy = 0.4024
I0526 00:07:49.219151 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 3.16944 (* 1 = 3.16944 loss)
I0526 00:07:49.727530 15394 main.cpp:354] Iteration 2000, loss = 1.03651
I0526 00:07:49.727598 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.03651 (* 1 = 1.03651 loss)
I0526 00:07:49.727613 15394 sgd_solver.cpp:43] Iteration 2000, lr = 0.02
I0526 00:07:54.589121 15394 main.cpp:354] Iteration 2010, loss = 0.945981
I0526 00:07:54.589185 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.945981 (* 1 = 0.945981 loss)
I0526 00:07:54.589196 15394 sgd_solver.cpp:43] Iteration 2010, lr = 0.02
I0526 00:07:59.903303 15394 main.cpp:354] Iteration 2020, loss = 0.725648
I0526 00:07:59.903369 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.725648 (* 1 = 0.725648 loss)
I0526 00:07:59.903380 15394 sgd_solver.cpp:43] Iteration 2020, lr = 0.02
I0526 00:08:04.532079 15394 main.cpp:354] Iteration 2030, loss = 1.25297
I0526 00:08:04.532153 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.25297 (* 1 = 1.25297 loss)
I0526 00:08:04.532166 15394 sgd_solver.cpp:43] Iteration 2030, lr = 0.02
I0526 00:08:09.102653 15394 main.cpp:354] Iteration 2040, loss = 1.04404
I0526 00:08:09.102720 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.04404 (* 1 = 1.04404 loss)
I0526 00:08:09.102730 15394 sgd_solver.cpp:43] Iteration 2040, lr = 0.02
I0526 00:08:14.559125 15394 main.cpp:354] Iteration 2050, loss = 0.88623
I0526 00:08:14.559196 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.88623 (* 1 = 0.88623 loss)
I0526 00:08:14.559207 15394 sgd_solver.cpp:43] Iteration 2050, lr = 0.02
I0526 00:08:19.360116 15394 main.cpp:354] Iteration 2060, loss = 1.22921
I0526 00:08:19.360193 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.22921 (* 1 = 1.22921 loss)
I0526 00:08:19.360205 15394 sgd_solver.cpp:43] Iteration 2060, lr = 0.02
I0526 00:08:24.449921 15394 main.cpp:354] Iteration 2070, loss = 0.959649
I0526 00:08:24.449981 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.959649 (* 1 = 0.959649 loss)
I0526 00:08:24.449991 15394 sgd_solver.cpp:43] Iteration 2070, lr = 0.02
I0526 00:08:29.793042 15394 main.cpp:354] Iteration 2080, loss = 0.926575
I0526 00:08:29.793110 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.926575 (* 1 = 0.926575 loss)
I0526 00:08:29.793129 15394 sgd_solver.cpp:43] Iteration 2080, lr = 0.02
I0526 00:08:34.789602 15394 main.cpp:354] Iteration 2090, loss = 1.01327
I0526 00:08:34.789672 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.01327 (* 1 = 1.01327 loss)
I0526 00:08:34.789682 15394 sgd_solver.cpp:43] Iteration 2090, lr = 0.02
I0526 00:08:39.473604 15394 main.cpp:465] Iteration 2100, Testing net (#0)
I0526 00:08:52.755046 15394 main.cpp:532]     Test net output #0: Accuracy = 0.5911
I0526 00:08:52.755120 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.22197 (* 1 = 1.22197 loss)
I0526 00:08:53.184989 15394 main.cpp:354] Iteration 2100, loss = 0.935145
I0526 00:08:53.185060 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.935145 (* 1 = 0.935145 loss)
I0526 00:08:53.185077 15394 sgd_solver.cpp:43] Iteration 2100, lr = 0.02
I0526 00:08:58.405701 15394 main.cpp:354] Iteration 2110, loss = 0.929929
I0526 00:08:58.405767 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.929929 (* 1 = 0.929929 loss)
I0526 00:08:58.405778 15394 sgd_solver.cpp:43] Iteration 2110, lr = 0.02
I0526 00:09:03.229755 15394 main.cpp:354] Iteration 2120, loss = 0.977681
I0526 00:09:03.229835 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.977681 (* 1 = 0.977681 loss)
I0526 00:09:03.229851 15394 sgd_solver.cpp:43] Iteration 2120, lr = 0.02
I0526 00:09:08.348032 15394 main.cpp:354] Iteration 2130, loss = 0.978559
I0526 00:09:08.348100 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.978559 (* 1 = 0.978559 loss)
I0526 00:09:08.348110 15394 sgd_solver.cpp:43] Iteration 2130, lr = 0.02
I0526 00:09:13.517601 15394 main.cpp:354] Iteration 2140, loss = 1.00617
I0526 00:09:13.517670 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.00617 (* 1 = 1.00617 loss)
I0526 00:09:13.517681 15394 sgd_solver.cpp:43] Iteration 2140, lr = 0.02
I0526 00:09:18.783037 15394 main.cpp:354] Iteration 2150, loss = 1.06687
I0526 00:09:18.783108 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.06687 (* 1 = 1.06687 loss)
I0526 00:09:18.783119 15394 sgd_solver.cpp:43] Iteration 2150, lr = 0.02
I0526 00:09:24.046643 15394 main.cpp:354] Iteration 2160, loss = 0.773502
I0526 00:09:24.046713 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.773502 (* 1 = 0.773502 loss)
I0526 00:09:24.046726 15394 sgd_solver.cpp:43] Iteration 2160, lr = 0.02
I0526 00:09:29.020650 15394 main.cpp:354] Iteration 2170, loss = 0.754358
I0526 00:09:29.020716 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.754358 (* 1 = 0.754358 loss)
I0526 00:09:29.020728 15394 sgd_solver.cpp:43] Iteration 2170, lr = 0.02
I0526 00:09:34.341094 15394 main.cpp:354] Iteration 2180, loss = 1.11482
I0526 00:09:34.341168 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.11482 (* 1 = 1.11482 loss)
I0526 00:09:34.341181 15394 sgd_solver.cpp:43] Iteration 2180, lr = 0.02
I0526 00:09:39.269372 15394 main.cpp:354] Iteration 2190, loss = 0.791402
I0526 00:09:39.269434 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.791402 (* 1 = 0.791402 loss)
I0526 00:09:39.269445 15394 sgd_solver.cpp:43] Iteration 2190, lr = 0.02
I0526 00:09:43.790892 15394 main.cpp:465] Iteration 2200, Testing net (#0)
I0526 00:09:57.018877 15394 main.cpp:532]     Test net output #0: Accuracy = 0.5014
I0526 00:09:57.018935 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.75622 (* 1 = 1.75622 loss)
I0526 00:09:57.594477 15394 main.cpp:354] Iteration 2200, loss = 0.811182
I0526 00:09:57.594550 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.811182 (* 1 = 0.811182 loss)
I0526 00:09:57.594564 15394 sgd_solver.cpp:43] Iteration 2200, lr = 0.02
I0526 00:10:02.359028 15394 main.cpp:354] Iteration 2210, loss = 1.04711
I0526 00:10:02.359098 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.04711 (* 1 = 1.04711 loss)
I0526 00:10:02.359109 15394 sgd_solver.cpp:43] Iteration 2210, lr = 0.02
I0526 00:10:07.476477 15394 main.cpp:354] Iteration 2220, loss = 0.994271
I0526 00:10:07.476572 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.994271 (* 1 = 0.994271 loss)
I0526 00:10:07.476583 15394 sgd_solver.cpp:43] Iteration 2220, lr = 0.02
I0526 00:10:12.195027 15394 main.cpp:354] Iteration 2230, loss = 0.976222
I0526 00:10:12.195091 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.976222 (* 1 = 0.976222 loss)
I0526 00:10:12.195102 15394 sgd_solver.cpp:43] Iteration 2230, lr = 0.02
I0526 00:10:17.307925 15394 main.cpp:354] Iteration 2240, loss = 1.02599
I0526 00:10:17.307989 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.02599 (* 1 = 1.02599 loss)
I0526 00:10:17.308001 15394 sgd_solver.cpp:43] Iteration 2240, lr = 0.02
I0526 00:10:22.949511 15394 main.cpp:354] Iteration 2250, loss = 1.08525
I0526 00:10:22.949575 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.08525 (* 1 = 1.08525 loss)
I0526 00:10:22.949585 15394 sgd_solver.cpp:43] Iteration 2250, lr = 0.02
I0526 00:10:28.501966 15394 main.cpp:354] Iteration 2260, loss = 0.829054
I0526 00:10:28.502038 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.829054 (* 1 = 0.829054 loss)
I0526 00:10:28.502048 15394 sgd_solver.cpp:43] Iteration 2260, lr = 0.02
I0526 00:10:33.631620 15394 main.cpp:354] Iteration 2270, loss = 1.06188
I0526 00:10:33.631700 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.06188 (* 1 = 1.06188 loss)
I0526 00:10:33.631712 15394 sgd_solver.cpp:43] Iteration 2270, lr = 0.02
I0526 00:10:38.249766 15394 main.cpp:354] Iteration 2280, loss = 0.862235
I0526 00:10:38.249841 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.862235 (* 1 = 0.862235 loss)
I0526 00:10:38.249852 15394 sgd_solver.cpp:43] Iteration 2280, lr = 0.02
I0526 00:10:43.199422 15394 main.cpp:354] Iteration 2290, loss = 0.88397
I0526 00:10:43.199488 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.88397 (* 1 = 0.88397 loss)
I0526 00:10:43.199501 15394 sgd_solver.cpp:43] Iteration 2290, lr = 0.02
I0526 00:10:47.604138 15394 main.cpp:465] Iteration 2300, Testing net (#0)
I0526 00:11:00.822208 15394 main.cpp:532]     Test net output #0: Accuracy = 0.619
I0526 00:11:00.822273 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.16088 (* 1 = 1.16088 loss)
I0526 00:11:01.332028 15394 main.cpp:354] Iteration 2300, loss = 0.874269
I0526 00:11:01.332103 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.874269 (* 1 = 0.874269 loss)
I0526 00:11:01.332120 15394 sgd_solver.cpp:43] Iteration 2300, lr = 0.02
I0526 00:11:06.498461 15394 main.cpp:354] Iteration 2310, loss = 0.866458
I0526 00:11:06.498536 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.866458 (* 1 = 0.866458 loss)
I0526 00:11:06.498548 15394 sgd_solver.cpp:43] Iteration 2310, lr = 0.02
I0526 00:11:11.230779 15394 main.cpp:354] Iteration 2320, loss = 1.01981
I0526 00:11:11.230844 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.01981 (* 1 = 1.01981 loss)
I0526 00:11:11.230854 15394 sgd_solver.cpp:43] Iteration 2320, lr = 0.02
I0526 00:11:16.411458 15394 main.cpp:354] Iteration 2330, loss = 0.814512
I0526 00:11:16.411522 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.814512 (* 1 = 0.814512 loss)
I0526 00:11:16.411533 15394 sgd_solver.cpp:43] Iteration 2330, lr = 0.02
I0526 00:11:21.766132 15394 main.cpp:354] Iteration 2340, loss = 0.819869
I0526 00:11:21.766202 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.819869 (* 1 = 0.819869 loss)
I0526 00:11:21.766213 15394 sgd_solver.cpp:43] Iteration 2340, lr = 0.02
I0526 00:11:26.647665 15394 main.cpp:354] Iteration 2350, loss = 0.957528
I0526 00:11:26.647729 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.957528 (* 1 = 0.957528 loss)
I0526 00:11:26.647740 15394 sgd_solver.cpp:43] Iteration 2350, lr = 0.02
I0526 00:11:31.920820 15394 main.cpp:354] Iteration 2360, loss = 0.784293
I0526 00:11:31.920886 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.784293 (* 1 = 0.784293 loss)
I0526 00:11:31.920907 15394 sgd_solver.cpp:43] Iteration 2360, lr = 0.02
I0526 00:11:36.868796 15394 main.cpp:354] Iteration 2370, loss = 1.12871
I0526 00:11:36.868867 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.12871 (* 1 = 1.12871 loss)
I0526 00:11:36.868878 15394 sgd_solver.cpp:43] Iteration 2370, lr = 0.02
I0526 00:11:41.873385 15394 main.cpp:354] Iteration 2380, loss = 0.843476
I0526 00:11:41.873456 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.843476 (* 1 = 0.843476 loss)
I0526 00:11:41.873466 15394 sgd_solver.cpp:43] Iteration 2380, lr = 0.02
I0526 00:11:46.836772 15394 main.cpp:354] Iteration 2390, loss = 0.73901
I0526 00:11:46.836843 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.73901 (* 1 = 0.73901 loss)
I0526 00:11:46.836854 15394 sgd_solver.cpp:43] Iteration 2390, lr = 0.02
I0526 00:11:51.469873 15394 main.cpp:465] Iteration 2400, Testing net (#0)
I0526 00:12:04.641952 15394 main.cpp:532]     Test net output #0: Accuracy = 0.3961
I0526 00:12:04.642012 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 2.53292 (* 1 = 2.53292 loss)
I0526 00:12:05.253454 15394 main.cpp:354] Iteration 2400, loss = 0.781468
I0526 00:12:05.253525 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.781468 (* 1 = 0.781468 loss)
I0526 00:12:05.253540 15394 sgd_solver.cpp:43] Iteration 2400, lr = 0.02
I0526 00:12:10.350462 15394 main.cpp:354] Iteration 2410, loss = 0.858253
I0526 00:12:10.350530 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.858253 (* 1 = 0.858253 loss)
I0526 00:12:10.350543 15394 sgd_solver.cpp:43] Iteration 2410, lr = 0.02
I0526 00:12:15.556244 15394 main.cpp:354] Iteration 2420, loss = 0.884288
I0526 00:12:15.556309 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.884288 (* 1 = 0.884288 loss)
I0526 00:12:15.556320 15394 sgd_solver.cpp:43] Iteration 2420, lr = 0.02
I0526 00:12:20.859400 15394 main.cpp:354] Iteration 2430, loss = 0.872622
I0526 00:12:20.859477 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.872622 (* 1 = 0.872622 loss)
I0526 00:12:20.859488 15394 sgd_solver.cpp:43] Iteration 2430, lr = 0.02
I0526 00:12:26.018316 15394 main.cpp:354] Iteration 2440, loss = 1.0065
I0526 00:12:26.018388 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.0065 (* 1 = 1.0065 loss)
I0526 00:12:26.018398 15394 sgd_solver.cpp:43] Iteration 2440, lr = 0.02
I0526 00:12:31.287963 15394 main.cpp:354] Iteration 2450, loss = 0.933228
I0526 00:12:31.288033 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.933228 (* 1 = 0.933228 loss)
I0526 00:12:31.288045 15394 sgd_solver.cpp:43] Iteration 2450, lr = 0.02
I0526 00:12:35.878576 15394 main.cpp:354] Iteration 2460, loss = 1.02629
I0526 00:12:35.878646 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.02629 (* 1 = 1.02629 loss)
I0526 00:12:35.878656 15394 sgd_solver.cpp:43] Iteration 2460, lr = 0.02
I0526 00:12:40.932243 15394 main.cpp:354] Iteration 2470, loss = 0.86564
I0526 00:12:40.932310 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.86564 (* 1 = 0.86564 loss)
I0526 00:12:40.932323 15394 sgd_solver.cpp:43] Iteration 2470, lr = 0.02
I0526 00:12:46.005359 15394 main.cpp:354] Iteration 2480, loss = 1.10731
I0526 00:12:46.005425 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.10731 (* 1 = 1.10731 loss)
I0526 00:12:46.005436 15394 sgd_solver.cpp:43] Iteration 2480, lr = 0.02
I0526 00:12:50.894896 15394 main.cpp:354] Iteration 2490, loss = 0.820694
I0526 00:12:50.894982 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.820694 (* 1 = 0.820694 loss)
I0526 00:12:50.894995 15394 sgd_solver.cpp:43] Iteration 2490, lr = 0.02
I0526 00:12:55.750740 15394 main.cpp:465] Iteration 2500, Testing net (#0)
I0526 00:13:08.980695 15394 main.cpp:532]     Test net output #0: Accuracy = 0.4362
I0526 00:13:08.980762 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 2.18265 (* 1 = 2.18265 loss)
I0526 00:13:09.415473 15394 main.cpp:354] Iteration 2500, loss = 0.958264
I0526 00:13:09.415558 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.958264 (* 1 = 0.958264 loss)
I0526 00:13:09.415573 15394 sgd_solver.cpp:43] Iteration 2500, lr = 0.02
I0526 00:13:14.690023 15394 main.cpp:354] Iteration 2510, loss = 0.939277
I0526 00:13:14.690094 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.939277 (* 1 = 0.939277 loss)
I0526 00:13:14.690104 15394 sgd_solver.cpp:43] Iteration 2510, lr = 0.02
I0526 00:13:20.042167 15394 main.cpp:354] Iteration 2520, loss = 0.839558
I0526 00:13:20.042237 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.839558 (* 1 = 0.839558 loss)
I0526 00:13:20.042248 15394 sgd_solver.cpp:43] Iteration 2520, lr = 0.02
I0526 00:13:25.481611 15394 main.cpp:354] Iteration 2530, loss = 0.719546
I0526 00:13:25.481683 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.719546 (* 1 = 0.719546 loss)
I0526 00:13:25.481694 15394 sgd_solver.cpp:43] Iteration 2530, lr = 0.02
I0526 00:13:30.145766 15394 main.cpp:354] Iteration 2540, loss = 0.904759
I0526 00:13:30.145830 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.904759 (* 1 = 0.904759 loss)
I0526 00:13:30.145840 15394 sgd_solver.cpp:43] Iteration 2540, lr = 0.02
I0526 00:13:35.277225 15394 main.cpp:354] Iteration 2550, loss = 0.892312
I0526 00:13:35.277297 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.892312 (* 1 = 0.892312 loss)
I0526 00:13:35.277308 15394 sgd_solver.cpp:43] Iteration 2550, lr = 0.02
I0526 00:13:40.507561 15394 main.cpp:354] Iteration 2560, loss = 0.784911
I0526 00:13:40.507627 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.784911 (* 1 = 0.784911 loss)
I0526 00:13:40.507637 15394 sgd_solver.cpp:43] Iteration 2560, lr = 0.02
I0526 00:13:45.530670 15394 main.cpp:354] Iteration 2570, loss = 0.855955
I0526 00:13:45.530740 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.855955 (* 1 = 0.855955 loss)
I0526 00:13:45.530750 15394 sgd_solver.cpp:43] Iteration 2570, lr = 0.02
I0526 00:13:50.480195 15394 main.cpp:354] Iteration 2580, loss = 0.898564
I0526 00:13:50.480268 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.898564 (* 1 = 0.898564 loss)
I0526 00:13:50.480278 15394 sgd_solver.cpp:43] Iteration 2580, lr = 0.02
I0526 00:13:55.848626 15394 main.cpp:354] Iteration 2590, loss = 0.675266
I0526 00:13:55.848698 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.675266 (* 1 = 0.675266 loss)
I0526 00:13:55.848709 15394 sgd_solver.cpp:43] Iteration 2590, lr = 0.02
I0526 00:14:00.348737 15394 main.cpp:465] Iteration 2600, Testing net (#0)
I0526 00:14:13.537648 15394 main.cpp:532]     Test net output #0: Accuracy = 0.5373
I0526 00:14:13.537708 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.44975 (* 1 = 1.44975 loss)
I0526 00:14:14.046224 15394 main.cpp:354] Iteration 2600, loss = 1.00405
I0526 00:14:14.046298 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.00405 (* 1 = 1.00405 loss)
I0526 00:14:14.046315 15394 sgd_solver.cpp:43] Iteration 2600, lr = 0.02
I0526 00:14:18.886955 15394 main.cpp:354] Iteration 2610, loss = 0.684471
I0526 00:14:18.887027 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.684471 (* 1 = 0.684471 loss)
I0526 00:14:18.887037 15394 sgd_solver.cpp:43] Iteration 2610, lr = 0.02
I0526 00:14:23.794044 15394 main.cpp:354] Iteration 2620, loss = 0.793071
I0526 00:14:23.794108 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.793071 (* 1 = 0.793071 loss)
I0526 00:14:23.794119 15394 sgd_solver.cpp:43] Iteration 2620, lr = 0.02
I0526 00:14:29.128926 15394 main.cpp:354] Iteration 2630, loss = 0.845157
I0526 00:14:29.128994 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.845157 (* 1 = 0.845157 loss)
I0526 00:14:29.129006 15394 sgd_solver.cpp:43] Iteration 2630, lr = 0.02
I0526 00:14:34.633729 15394 main.cpp:354] Iteration 2640, loss = 1.04068
I0526 00:14:34.633806 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.04068 (* 1 = 1.04068 loss)
I0526 00:14:34.633823 15394 sgd_solver.cpp:43] Iteration 2640, lr = 0.02
I0526 00:14:39.597785 15394 main.cpp:354] Iteration 2650, loss = 0.751347
I0526 00:14:39.597849 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.751347 (* 1 = 0.751347 loss)
I0526 00:14:39.597862 15394 sgd_solver.cpp:43] Iteration 2650, lr = 0.02
I0526 00:14:44.961555 15394 main.cpp:354] Iteration 2660, loss = 0.788911
I0526 00:14:44.961617 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.788911 (* 1 = 0.788911 loss)
I0526 00:14:44.961628 15394 sgd_solver.cpp:43] Iteration 2660, lr = 0.02
I0526 00:14:49.845679 15394 main.cpp:354] Iteration 2670, loss = 1.18684
I0526 00:14:49.845741 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.18684 (* 1 = 1.18684 loss)
I0526 00:14:49.845751 15394 sgd_solver.cpp:43] Iteration 2670, lr = 0.02
I0526 00:14:54.983567 15394 main.cpp:354] Iteration 2680, loss = 0.727913
I0526 00:14:54.983619 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.727913 (* 1 = 0.727913 loss)
I0526 00:14:54.983629 15394 sgd_solver.cpp:43] Iteration 2680, lr = 0.02
I0526 00:14:59.851536 15394 main.cpp:354] Iteration 2690, loss = 0.937083
I0526 00:14:59.851601 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.937083 (* 1 = 0.937083 loss)
I0526 00:14:59.851611 15394 sgd_solver.cpp:43] Iteration 2690, lr = 0.02
I0526 00:15:04.674372 15394 main.cpp:465] Iteration 2700, Testing net (#0)
I0526 00:15:17.845517 15394 main.cpp:532]     Test net output #0: Accuracy = 0.5992
I0526 00:15:17.845579 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.32831 (* 1 = 1.32831 loss)
I0526 00:15:18.276489 15394 main.cpp:354] Iteration 2700, loss = 0.991794
I0526 00:15:18.276568 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.991794 (* 1 = 0.991794 loss)
I0526 00:15:18.276587 15394 sgd_solver.cpp:43] Iteration 2700, lr = 0.02
I0526 00:15:23.756348 15394 main.cpp:354] Iteration 2710, loss = 0.632372
I0526 00:15:23.756409 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.632372 (* 1 = 0.632372 loss)
I0526 00:15:23.756422 15394 sgd_solver.cpp:43] Iteration 2710, lr = 0.02
I0526 00:15:28.544335 15394 main.cpp:354] Iteration 2720, loss = 0.916145
I0526 00:15:28.544399 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.916145 (* 1 = 0.916145 loss)
I0526 00:15:28.544409 15394 sgd_solver.cpp:43] Iteration 2720, lr = 0.02
I0526 00:15:33.614140 15394 main.cpp:354] Iteration 2730, loss = 0.83138
I0526 00:15:33.614217 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.83138 (* 1 = 0.83138 loss)
I0526 00:15:33.614229 15394 sgd_solver.cpp:43] Iteration 2730, lr = 0.02
I0526 00:15:38.153908 15394 main.cpp:354] Iteration 2740, loss = 0.971556
I0526 00:15:38.153980 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.971556 (* 1 = 0.971556 loss)
I0526 00:15:38.153990 15394 sgd_solver.cpp:43] Iteration 2740, lr = 0.02
I0526 00:15:43.646615 15394 main.cpp:354] Iteration 2750, loss = 0.790073
I0526 00:15:43.646682 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.790073 (* 1 = 0.790073 loss)
I0526 00:15:43.646692 15394 sgd_solver.cpp:43] Iteration 2750, lr = 0.02
I0526 00:15:48.706745 15394 main.cpp:354] Iteration 2760, loss = 1.13124
I0526 00:15:48.706821 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.13124 (* 1 = 1.13124 loss)
I0526 00:15:48.706832 15394 sgd_solver.cpp:43] Iteration 2760, lr = 0.02
I0526 00:15:53.757652 15394 main.cpp:354] Iteration 2770, loss = 0.904662
I0526 00:15:53.757722 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.904662 (* 1 = 0.904662 loss)
I0526 00:15:53.757732 15394 sgd_solver.cpp:43] Iteration 2770, lr = 0.02
I0526 00:15:58.733711 15394 main.cpp:354] Iteration 2780, loss = 0.957846
I0526 00:15:58.733772 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.957846 (* 1 = 0.957846 loss)
I0526 00:15:58.733781 15394 sgd_solver.cpp:43] Iteration 2780, lr = 0.02
I0526 00:16:03.620712 15394 main.cpp:354] Iteration 2790, loss = 0.777761
I0526 00:16:03.620803 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.777761 (* 1 = 0.777761 loss)
I0526 00:16:03.620813 15394 sgd_solver.cpp:43] Iteration 2790, lr = 0.02
I0526 00:16:08.078029 15394 main.cpp:465] Iteration 2800, Testing net (#0)
I0526 00:16:21.238903 15394 main.cpp:532]     Test net output #0: Accuracy = 0.5603
I0526 00:16:21.238971 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.52558 (* 1 = 1.52558 loss)
I0526 00:16:21.706367 15394 main.cpp:354] Iteration 2800, loss = 0.908302
I0526 00:16:21.706435 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.908302 (* 1 = 0.908302 loss)
I0526 00:16:21.706452 15394 sgd_solver.cpp:43] Iteration 2800, lr = 0.02
I0526 00:16:26.798442 15394 main.cpp:354] Iteration 2810, loss = 0.834952
I0526 00:16:26.798509 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.834952 (* 1 = 0.834952 loss)
I0526 00:16:26.798521 15394 sgd_solver.cpp:43] Iteration 2810, lr = 0.02
I0526 00:16:32.426023 15394 main.cpp:354] Iteration 2820, loss = 0.768391
I0526 00:16:32.426086 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.768391 (* 1 = 0.768391 loss)
I0526 00:16:32.426096 15394 sgd_solver.cpp:43] Iteration 2820, lr = 0.02
I0526 00:16:37.706524 15394 main.cpp:354] Iteration 2830, loss = 0.964073
I0526 00:16:37.706596 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.964073 (* 1 = 0.964073 loss)
I0526 00:16:37.706607 15394 sgd_solver.cpp:43] Iteration 2830, lr = 0.02
I0526 00:16:42.829890 15394 main.cpp:354] Iteration 2840, loss = 0.966433
I0526 00:16:42.829954 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.966433 (* 1 = 0.966433 loss)
I0526 00:16:42.829965 15394 sgd_solver.cpp:43] Iteration 2840, lr = 0.02
I0526 00:16:47.431633 15394 main.cpp:354] Iteration 2850, loss = 0.873638
I0526 00:16:47.431699 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.873638 (* 1 = 0.873638 loss)
I0526 00:16:47.431710 15394 sgd_solver.cpp:43] Iteration 2850, lr = 0.02
I0526 00:16:52.251492 15394 main.cpp:354] Iteration 2860, loss = 1.061
I0526 00:16:52.251564 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.061 (* 1 = 1.061 loss)
I0526 00:16:52.251575 15394 sgd_solver.cpp:43] Iteration 2860, lr = 0.02
I0526 00:16:57.411146 15394 main.cpp:354] Iteration 2870, loss = 0.997672
I0526 00:16:57.411213 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.997672 (* 1 = 0.997672 loss)
I0526 00:16:57.411224 15394 sgd_solver.cpp:43] Iteration 2870, lr = 0.02
I0526 00:17:02.692199 15394 main.cpp:354] Iteration 2880, loss = 0.833404
I0526 00:17:02.692265 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.833404 (* 1 = 0.833404 loss)
I0526 00:17:02.692276 15394 sgd_solver.cpp:43] Iteration 2880, lr = 0.02
I0526 00:17:07.836529 15394 main.cpp:354] Iteration 2890, loss = 1.15793
I0526 00:17:07.836604 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.15793 (* 1 = 1.15793 loss)
I0526 00:17:07.836616 15394 sgd_solver.cpp:43] Iteration 2890, lr = 0.02
I0526 00:17:12.399405 15394 main.cpp:465] Iteration 2900, Testing net (#0)
I0526 00:17:25.579701 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6597
I0526 00:17:25.579771 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.973351 (* 1 = 0.973351 loss)
I0526 00:17:26.154698 15394 main.cpp:354] Iteration 2900, loss = 0.825116
I0526 00:17:26.154773 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.825116 (* 1 = 0.825116 loss)
I0526 00:17:26.154790 15394 sgd_solver.cpp:43] Iteration 2900, lr = 0.02
I0526 00:17:31.194411 15394 main.cpp:354] Iteration 2910, loss = 1.02149
I0526 00:17:31.194478 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.02149 (* 1 = 1.02149 loss)
I0526 00:17:31.194489 15394 sgd_solver.cpp:43] Iteration 2910, lr = 0.02
I0526 00:17:36.614433 15394 main.cpp:354] Iteration 2920, loss = 0.935288
I0526 00:17:36.614511 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.935288 (* 1 = 0.935288 loss)
I0526 00:17:36.614529 15394 sgd_solver.cpp:43] Iteration 2920, lr = 0.02
I0526 00:17:41.762476 15394 main.cpp:354] Iteration 2930, loss = 0.721602
I0526 00:17:41.762543 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.721602 (* 1 = 0.721602 loss)
I0526 00:17:41.762554 15394 sgd_solver.cpp:43] Iteration 2930, lr = 0.02
I0526 00:17:46.820243 15394 main.cpp:354] Iteration 2940, loss = 0.695643
I0526 00:17:46.820313 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.695643 (* 1 = 0.695643 loss)
I0526 00:17:46.820325 15394 sgd_solver.cpp:43] Iteration 2940, lr = 0.02
I0526 00:17:52.386730 15394 main.cpp:354] Iteration 2950, loss = 0.809982
I0526 00:17:52.386802 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.809982 (* 1 = 0.809982 loss)
I0526 00:17:52.386813 15394 sgd_solver.cpp:43] Iteration 2950, lr = 0.02
I0526 00:17:57.272663 15394 main.cpp:354] Iteration 2960, loss = 0.626806
I0526 00:17:57.272732 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.626806 (* 1 = 0.626806 loss)
I0526 00:17:57.272742 15394 sgd_solver.cpp:43] Iteration 2960, lr = 0.02
I0526 00:18:02.436441 15394 main.cpp:354] Iteration 2970, loss = 0.75354
I0526 00:18:02.436513 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.75354 (* 1 = 0.75354 loss)
I0526 00:18:02.436524 15394 sgd_solver.cpp:43] Iteration 2970, lr = 0.02
I0526 00:18:07.668134 15394 main.cpp:354] Iteration 2980, loss = 0.790795
I0526 00:18:07.668205 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.790795 (* 1 = 0.790795 loss)
I0526 00:18:07.668215 15394 sgd_solver.cpp:43] Iteration 2980, lr = 0.02
I0526 00:18:13.001374 15394 main.cpp:354] Iteration 2990, loss = 0.812438
I0526 00:18:13.001444 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.812438 (* 1 = 0.812438 loss)
I0526 00:18:13.001456 15394 sgd_solver.cpp:43] Iteration 2990, lr = 0.02
I0526 00:18:17.809231 15394 main.cpp:465] Iteration 3000, Testing net (#0)
I0526 00:18:31.021646 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6018
I0526 00:18:31.021708 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.16689 (* 1 = 1.16689 loss)
I0526 00:18:31.596895 15394 main.cpp:354] Iteration 3000, loss = 0.866117
I0526 00:18:31.596954 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.866117 (* 1 = 0.866117 loss)
I0526 00:18:31.596971 15394 sgd_solver.cpp:43] Iteration 3000, lr = 0.02
I0526 00:18:36.822785 15394 main.cpp:354] Iteration 3010, loss = 0.893568
I0526 00:18:36.822875 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.893568 (* 1 = 0.893568 loss)
I0526 00:18:36.822886 15394 sgd_solver.cpp:43] Iteration 3010, lr = 0.02
I0526 00:18:41.794493 15394 main.cpp:354] Iteration 3020, loss = 0.753905
I0526 00:18:41.794561 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.753905 (* 1 = 0.753905 loss)
I0526 00:18:41.794572 15394 sgd_solver.cpp:43] Iteration 3020, lr = 0.02
I0526 00:18:46.619998 15394 main.cpp:354] Iteration 3030, loss = 0.963462
I0526 00:18:46.620069 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.963462 (* 1 = 0.963462 loss)
I0526 00:18:46.620079 15394 sgd_solver.cpp:43] Iteration 3030, lr = 0.02
I0526 00:18:51.762259 15394 main.cpp:354] Iteration 3040, loss = 0.847929
I0526 00:18:51.762334 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.847929 (* 1 = 0.847929 loss)
I0526 00:18:51.762346 15394 sgd_solver.cpp:43] Iteration 3040, lr = 0.02
I0526 00:18:56.596371 15394 main.cpp:354] Iteration 3050, loss = 0.768847
I0526 00:18:56.596458 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.768847 (* 1 = 0.768847 loss)
I0526 00:18:56.596469 15394 sgd_solver.cpp:43] Iteration 3050, lr = 0.02
I0526 00:19:01.977500 15394 main.cpp:354] Iteration 3060, loss = 0.674461
I0526 00:19:01.977569 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.674461 (* 1 = 0.674461 loss)
I0526 00:19:01.977579 15394 sgd_solver.cpp:43] Iteration 3060, lr = 0.02
I0526 00:19:07.224814 15394 main.cpp:354] Iteration 3070, loss = 0.885211
I0526 00:19:07.224898 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.885211 (* 1 = 0.885211 loss)
I0526 00:19:07.224910 15394 sgd_solver.cpp:43] Iteration 3070, lr = 0.02
I0526 00:19:12.554632 15394 main.cpp:354] Iteration 3080, loss = 0.697596
I0526 00:19:12.554697 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.697596 (* 1 = 0.697596 loss)
I0526 00:19:12.554708 15394 sgd_solver.cpp:43] Iteration 3080, lr = 0.02
I0526 00:19:17.653899 15394 main.cpp:354] Iteration 3090, loss = 0.711917
I0526 00:19:17.653965 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.711917 (* 1 = 0.711917 loss)
I0526 00:19:17.653976 15394 sgd_solver.cpp:43] Iteration 3090, lr = 0.02
I0526 00:19:22.217594 15394 main.cpp:465] Iteration 3100, Testing net (#0)
I0526 00:19:35.443166 15394 main.cpp:532]     Test net output #0: Accuracy = 0.5324
I0526 00:19:35.443228 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.62436 (* 1 = 1.62436 loss)
I0526 00:19:35.950723 15394 main.cpp:354] Iteration 3100, loss = 0.792542
I0526 00:19:35.950793 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.792542 (* 1 = 0.792542 loss)
I0526 00:19:35.950809 15394 sgd_solver.cpp:43] Iteration 3100, lr = 0.02
I0526 00:19:41.483861 15394 main.cpp:354] Iteration 3110, loss = 0.68244
I0526 00:19:41.483928 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.68244 (* 1 = 0.68244 loss)
I0526 00:19:41.483939 15394 sgd_solver.cpp:43] Iteration 3110, lr = 0.02
I0526 00:19:46.907873 15394 main.cpp:354] Iteration 3120, loss = 0.889159
I0526 00:19:46.907939 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.889159 (* 1 = 0.889159 loss)
I0526 00:19:46.907949 15394 sgd_solver.cpp:43] Iteration 3120, lr = 0.02
I0526 00:19:51.522306 15394 main.cpp:354] Iteration 3130, loss = 0.982301
I0526 00:19:51.522382 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.982301 (* 1 = 0.982301 loss)
I0526 00:19:51.522392 15394 sgd_solver.cpp:43] Iteration 3130, lr = 0.02
I0526 00:19:56.531380 15394 main.cpp:354] Iteration 3140, loss = 0.880781
I0526 00:19:56.531445 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.880781 (* 1 = 0.880781 loss)
I0526 00:19:56.531455 15394 sgd_solver.cpp:43] Iteration 3140, lr = 0.02
I0526 00:20:01.742969 15394 main.cpp:354] Iteration 3150, loss = 0.721602
I0526 00:20:01.743037 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.721602 (* 1 = 0.721602 loss)
I0526 00:20:01.743049 15394 sgd_solver.cpp:43] Iteration 3150, lr = 0.02
I0526 00:20:07.284621 15394 main.cpp:354] Iteration 3160, loss = 0.860279
I0526 00:20:07.284693 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.860279 (* 1 = 0.860279 loss)
I0526 00:20:07.284704 15394 sgd_solver.cpp:43] Iteration 3160, lr = 0.02
I0526 00:20:12.350725 15394 main.cpp:354] Iteration 3170, loss = 0.927784
I0526 00:20:12.350792 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.927784 (* 1 = 0.927784 loss)
I0526 00:20:12.350802 15394 sgd_solver.cpp:43] Iteration 3170, lr = 0.02
I0526 00:20:17.245031 15394 main.cpp:354] Iteration 3180, loss = 0.944098
I0526 00:20:17.245098 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.944098 (* 1 = 0.944098 loss)
I0526 00:20:17.245108 15394 sgd_solver.cpp:43] Iteration 3180, lr = 0.02
I0526 00:20:22.402420 15394 main.cpp:354] Iteration 3190, loss = 0.74101
I0526 00:20:22.402492 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.74101 (* 1 = 0.74101 loss)
I0526 00:20:22.402503 15394 sgd_solver.cpp:43] Iteration 3190, lr = 0.02
I0526 00:20:27.013970 15394 main.cpp:465] Iteration 3200, Testing net (#0)
I0526 00:20:40.246474 15394 main.cpp:532]     Test net output #0: Accuracy = 0.4421
I0526 00:20:40.246538 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.93471 (* 1 = 1.93471 loss)
I0526 00:20:40.712975 15394 main.cpp:354] Iteration 3200, loss = 0.731107
I0526 00:20:40.713043 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.731107 (* 1 = 0.731107 loss)
I0526 00:20:40.713068 15394 sgd_solver.cpp:43] Iteration 3200, lr = 0.02
I0526 00:20:45.531812 15394 main.cpp:354] Iteration 3210, loss = 0.843863
I0526 00:20:45.531877 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.843863 (* 1 = 0.843863 loss)
I0526 00:20:45.531885 15394 sgd_solver.cpp:43] Iteration 3210, lr = 0.02
I0526 00:20:50.613608 15394 main.cpp:354] Iteration 3220, loss = 0.727866
I0526 00:20:50.613678 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.727866 (* 1 = 0.727866 loss)
I0526 00:20:50.613688 15394 sgd_solver.cpp:43] Iteration 3220, lr = 0.02
I0526 00:20:56.042114 15394 main.cpp:354] Iteration 3230, loss = 0.809776
I0526 00:20:56.042183 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.809776 (* 1 = 0.809776 loss)
I0526 00:20:56.042194 15394 sgd_solver.cpp:43] Iteration 3230, lr = 0.02
I0526 00:21:01.071918 15394 main.cpp:354] Iteration 3240, loss = 0.835995
I0526 00:21:01.071980 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.835995 (* 1 = 0.835995 loss)
I0526 00:21:01.071991 15394 sgd_solver.cpp:43] Iteration 3240, lr = 0.02
I0526 00:21:05.953408 15394 main.cpp:354] Iteration 3250, loss = 0.934491
I0526 00:21:05.953480 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.934491 (* 1 = 0.934491 loss)
I0526 00:21:05.953491 15394 sgd_solver.cpp:43] Iteration 3250, lr = 0.02
I0526 00:21:10.542152 15394 main.cpp:354] Iteration 3260, loss = 0.972099
I0526 00:21:10.542217 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.972099 (* 1 = 0.972099 loss)
I0526 00:21:10.542228 15394 sgd_solver.cpp:43] Iteration 3260, lr = 0.02
I0526 00:21:15.577576 15394 main.cpp:354] Iteration 3270, loss = 0.900846
I0526 00:21:15.577653 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.900846 (* 1 = 0.900846 loss)
I0526 00:21:15.577664 15394 sgd_solver.cpp:43] Iteration 3270, lr = 0.02
I0526 00:21:20.102298 15394 main.cpp:354] Iteration 3280, loss = 0.887998
I0526 00:21:20.102376 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.887998 (* 1 = 0.887998 loss)
I0526 00:21:20.102387 15394 sgd_solver.cpp:43] Iteration 3280, lr = 0.02
I0526 00:21:24.511703 15394 main.cpp:354] Iteration 3290, loss = 0.698681
I0526 00:21:24.511771 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.698681 (* 1 = 0.698681 loss)
I0526 00:21:24.511782 15394 sgd_solver.cpp:43] Iteration 3290, lr = 0.02
I0526 00:21:29.102391 15394 main.cpp:465] Iteration 3300, Testing net (#0)
I0526 00:21:42.247781 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6687
I0526 00:21:42.247844 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.992194 (* 1 = 0.992194 loss)
I0526 00:21:42.718472 15394 main.cpp:354] Iteration 3300, loss = 0.910819
I0526 00:21:42.718544 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.910819 (* 1 = 0.910819 loss)
I0526 00:21:42.718561 15394 sgd_solver.cpp:43] Iteration 3300, lr = 0.02
I0526 00:21:47.589746 15394 main.cpp:354] Iteration 3310, loss = 0.719024
I0526 00:21:47.589815 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.719024 (* 1 = 0.719024 loss)
I0526 00:21:47.589828 15394 sgd_solver.cpp:43] Iteration 3310, lr = 0.02
I0526 00:21:52.867743 15394 main.cpp:354] Iteration 3320, loss = 0.542848
I0526 00:21:52.867815 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.542848 (* 1 = 0.542848 loss)
I0526 00:21:52.867825 15394 sgd_solver.cpp:43] Iteration 3320, lr = 0.02
I0526 00:21:57.692881 15394 main.cpp:354] Iteration 3330, loss = 0.714707
I0526 00:21:57.692951 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.714707 (* 1 = 0.714707 loss)
I0526 00:21:57.692962 15394 sgd_solver.cpp:43] Iteration 3330, lr = 0.02
I0526 00:22:02.810888 15394 main.cpp:354] Iteration 3340, loss = 0.945542
I0526 00:22:02.810950 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.945542 (* 1 = 0.945542 loss)
I0526 00:22:02.810962 15394 sgd_solver.cpp:43] Iteration 3340, lr = 0.02
I0526 00:22:07.829710 15394 main.cpp:354] Iteration 3350, loss = 0.636087
I0526 00:22:07.829793 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.636087 (* 1 = 0.636087 loss)
I0526 00:22:07.829803 15394 sgd_solver.cpp:43] Iteration 3350, lr = 0.02
I0526 00:22:13.081570 15394 main.cpp:354] Iteration 3360, loss = 0.880909
I0526 00:22:13.081634 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.880909 (* 1 = 0.880909 loss)
I0526 00:22:13.081645 15394 sgd_solver.cpp:43] Iteration 3360, lr = 0.02
I0526 00:22:18.158685 15394 main.cpp:354] Iteration 3370, loss = 0.998332
I0526 00:22:18.158758 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.998332 (* 1 = 0.998332 loss)
I0526 00:22:18.158774 15394 sgd_solver.cpp:43] Iteration 3370, lr = 0.02
I0526 00:22:23.281066 15394 main.cpp:354] Iteration 3380, loss = 0.736554
I0526 00:22:23.281131 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.736554 (* 1 = 0.736554 loss)
I0526 00:22:23.281141 15394 sgd_solver.cpp:43] Iteration 3380, lr = 0.02
I0526 00:22:28.461915 15394 main.cpp:354] Iteration 3390, loss = 0.89066
I0526 00:22:28.461979 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.89066 (* 1 = 0.89066 loss)
I0526 00:22:28.461989 15394 sgd_solver.cpp:43] Iteration 3390, lr = 0.02
I0526 00:22:32.771920 15394 main.cpp:465] Iteration 3400, Testing net (#0)
I0526 00:22:45.934522 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6588
I0526 00:22:45.934587 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.952075 (* 1 = 0.952075 loss)
I0526 00:22:46.363155 15394 main.cpp:354] Iteration 3400, loss = 0.862918
I0526 00:22:46.363222 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.862918 (* 1 = 0.862918 loss)
I0526 00:22:46.363240 15394 sgd_solver.cpp:43] Iteration 3400, lr = 0.02
I0526 00:22:51.388787 15394 main.cpp:354] Iteration 3410, loss = 0.745453
I0526 00:22:51.388851 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.745453 (* 1 = 0.745453 loss)
I0526 00:22:51.388862 15394 sgd_solver.cpp:43] Iteration 3410, lr = 0.02
I0526 00:22:55.906150 15394 main.cpp:354] Iteration 3420, loss = 0.987661
I0526 00:22:55.906218 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.987661 (* 1 = 0.987661 loss)
I0526 00:22:55.906229 15394 sgd_solver.cpp:43] Iteration 3420, lr = 0.02
I0526 00:23:00.764688 15394 main.cpp:354] Iteration 3430, loss = 0.744209
I0526 00:23:00.764755 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.744209 (* 1 = 0.744209 loss)
I0526 00:23:00.764765 15394 sgd_solver.cpp:43] Iteration 3430, lr = 0.02
I0526 00:23:05.799851 15394 main.cpp:354] Iteration 3440, loss = 0.955252
I0526 00:23:05.799922 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.955252 (* 1 = 0.955252 loss)
I0526 00:23:05.799933 15394 sgd_solver.cpp:43] Iteration 3440, lr = 0.02
I0526 00:23:10.459486 15394 main.cpp:354] Iteration 3450, loss = 0.663318
I0526 00:23:10.459548 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.663318 (* 1 = 0.663318 loss)
I0526 00:23:10.459558 15394 sgd_solver.cpp:43] Iteration 3450, lr = 0.02
I0526 00:23:15.618680 15394 main.cpp:354] Iteration 3460, loss = 0.954826
I0526 00:23:15.618741 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.954826 (* 1 = 0.954826 loss)
I0526 00:23:15.618751 15394 sgd_solver.cpp:43] Iteration 3460, lr = 0.02
I0526 00:23:20.813494 15394 main.cpp:354] Iteration 3470, loss = 0.700451
I0526 00:23:20.813567 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.700451 (* 1 = 0.700451 loss)
I0526 00:23:20.813577 15394 sgd_solver.cpp:43] Iteration 3470, lr = 0.02
I0526 00:23:25.969662 15394 main.cpp:354] Iteration 3480, loss = 0.83368
I0526 00:23:25.969727 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.83368 (* 1 = 0.83368 loss)
I0526 00:23:25.969737 15394 sgd_solver.cpp:43] Iteration 3480, lr = 0.02
I0526 00:23:30.867041 15394 main.cpp:354] Iteration 3490, loss = 0.588356
I0526 00:23:30.867103 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.588356 (* 1 = 0.588356 loss)
I0526 00:23:30.867127 15394 sgd_solver.cpp:43] Iteration 3490, lr = 0.02
I0526 00:23:35.565343 15394 main.cpp:465] Iteration 3500, Testing net (#0)
I0526 00:23:48.713233 15394 main.cpp:532]     Test net output #0: Accuracy = 0.5886
I0526 00:23:48.713295 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.32176 (* 1 = 1.32176 loss)
I0526 00:23:49.218569 15394 main.cpp:354] Iteration 3500, loss = 0.865608
I0526 00:23:49.218636 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.865608 (* 1 = 0.865608 loss)
I0526 00:23:49.218652 15394 sgd_solver.cpp:43] Iteration 3500, lr = 0.02
I0526 00:23:53.988417 15394 main.cpp:354] Iteration 3510, loss = 0.909915
I0526 00:23:53.988479 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.909915 (* 1 = 0.909915 loss)
I0526 00:23:53.988490 15394 sgd_solver.cpp:43] Iteration 3510, lr = 0.02
I0526 00:23:59.359771 15394 main.cpp:354] Iteration 3520, loss = 0.983351
I0526 00:23:59.359833 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.983351 (* 1 = 0.983351 loss)
I0526 00:23:59.359843 15394 sgd_solver.cpp:43] Iteration 3520, lr = 0.02
I0526 00:24:04.640904 15394 main.cpp:354] Iteration 3530, loss = 0.78326
I0526 00:24:04.640980 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.78326 (* 1 = 0.78326 loss)
I0526 00:24:04.640990 15394 sgd_solver.cpp:43] Iteration 3530, lr = 0.02
I0526 00:24:09.804064 15394 main.cpp:354] Iteration 3540, loss = 0.677068
I0526 00:24:09.804131 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.677068 (* 1 = 0.677068 loss)
I0526 00:24:09.804142 15394 sgd_solver.cpp:43] Iteration 3540, lr = 0.02
I0526 00:24:15.007441 15394 main.cpp:354] Iteration 3550, loss = 0.84019
I0526 00:24:15.007503 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.84019 (* 1 = 0.84019 loss)
I0526 00:24:15.007513 15394 sgd_solver.cpp:43] Iteration 3550, lr = 0.02
I0526 00:24:19.400527 15394 main.cpp:354] Iteration 3560, loss = 0.770404
I0526 00:24:19.400601 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.770404 (* 1 = 0.770404 loss)
I0526 00:24:19.400614 15394 sgd_solver.cpp:43] Iteration 3560, lr = 0.02
I0526 00:24:24.302999 15394 main.cpp:354] Iteration 3570, loss = 0.942584
I0526 00:24:24.303063 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.942584 (* 1 = 0.942584 loss)
I0526 00:24:24.303074 15394 sgd_solver.cpp:43] Iteration 3570, lr = 0.02
I0526 00:24:29.762995 15394 main.cpp:354] Iteration 3580, loss = 0.899087
I0526 00:24:29.763058 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.899087 (* 1 = 0.899087 loss)
I0526 00:24:29.763067 15394 sgd_solver.cpp:43] Iteration 3580, lr = 0.02
I0526 00:24:35.390483 15394 main.cpp:354] Iteration 3590, loss = 0.714262
I0526 00:24:35.390559 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.714262 (* 1 = 0.714262 loss)
I0526 00:24:35.390569 15394 sgd_solver.cpp:43] Iteration 3590, lr = 0.02
I0526 00:24:40.208006 15394 main.cpp:465] Iteration 3600, Testing net (#0)
I0526 00:24:53.342465 15394 main.cpp:532]     Test net output #0: Accuracy = 0.5207
I0526 00:24:53.342530 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.41014 (* 1 = 1.41014 loss)
I0526 00:24:53.741941 15394 main.cpp:354] Iteration 3600, loss = 0.928173
I0526 00:24:53.742009 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.928173 (* 1 = 0.928173 loss)
I0526 00:24:53.742022 15394 sgd_solver.cpp:43] Iteration 3600, lr = 0.02
I0526 00:24:58.833886 15394 main.cpp:354] Iteration 3610, loss = 0.811191
I0526 00:24:58.833945 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.811191 (* 1 = 0.811191 loss)
I0526 00:24:58.833956 15394 sgd_solver.cpp:43] Iteration 3610, lr = 0.02
I0526 00:25:04.166405 15394 main.cpp:354] Iteration 3620, loss = 0.865803
I0526 00:25:04.166476 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.865803 (* 1 = 0.865803 loss)
I0526 00:25:04.166486 15394 sgd_solver.cpp:43] Iteration 3620, lr = 0.02
I0526 00:25:08.664540 15394 main.cpp:354] Iteration 3630, loss = 0.72775
I0526 00:25:08.664616 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.72775 (* 1 = 0.72775 loss)
I0526 00:25:08.664626 15394 sgd_solver.cpp:43] Iteration 3630, lr = 0.02
I0526 00:25:13.546303 15394 main.cpp:354] Iteration 3640, loss = 0.886294
I0526 00:25:13.546370 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.886294 (* 1 = 0.886294 loss)
I0526 00:25:13.546381 15394 sgd_solver.cpp:43] Iteration 3640, lr = 0.02
I0526 00:25:18.568506 15394 main.cpp:354] Iteration 3650, loss = 0.762491
I0526 00:25:18.568575 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.762491 (* 1 = 0.762491 loss)
I0526 00:25:18.568586 15394 sgd_solver.cpp:43] Iteration 3650, lr = 0.02
I0526 00:25:23.965793 15394 main.cpp:354] Iteration 3660, loss = 0.851298
I0526 00:25:23.965858 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.851298 (* 1 = 0.851298 loss)
I0526 00:25:23.965869 15394 sgd_solver.cpp:43] Iteration 3660, lr = 0.02
I0526 00:25:29.070242 15394 main.cpp:354] Iteration 3670, loss = 0.988508
I0526 00:25:29.070305 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.988508 (* 1 = 0.988508 loss)
I0526 00:25:29.070317 15394 sgd_solver.cpp:43] Iteration 3670, lr = 0.02
I0526 00:25:34.461467 15394 main.cpp:354] Iteration 3680, loss = 0.654374
I0526 00:25:34.461544 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.654374 (* 1 = 0.654374 loss)
I0526 00:25:34.461554 15394 sgd_solver.cpp:43] Iteration 3680, lr = 0.02
I0526 00:25:39.249873 15394 main.cpp:354] Iteration 3690, loss = 0.898806
I0526 00:25:39.249941 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.898806 (* 1 = 0.898806 loss)
I0526 00:25:39.249951 15394 sgd_solver.cpp:43] Iteration 3690, lr = 0.02
I0526 00:25:43.837436 15394 main.cpp:465] Iteration 3700, Testing net (#0)
I0526 00:25:57.029990 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6048
I0526 00:25:57.030058 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.14951 (* 1 = 1.14951 loss)
I0526 00:25:57.501773 15394 main.cpp:354] Iteration 3700, loss = 0.689376
I0526 00:25:57.501842 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.689376 (* 1 = 0.689376 loss)
I0526 00:25:57.501857 15394 sgd_solver.cpp:43] Iteration 3700, lr = 0.02
I0526 00:26:02.507375 15394 main.cpp:354] Iteration 3710, loss = 0.640872
I0526 00:26:02.507441 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.640872 (* 1 = 0.640872 loss)
I0526 00:26:02.507450 15394 sgd_solver.cpp:43] Iteration 3710, lr = 0.02
I0526 00:26:07.823359 15394 main.cpp:354] Iteration 3720, loss = 0.804006
I0526 00:26:07.823441 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.804006 (* 1 = 0.804006 loss)
I0526 00:26:07.823451 15394 sgd_solver.cpp:43] Iteration 3720, lr = 0.02
I0526 00:26:13.317772 15394 main.cpp:354] Iteration 3730, loss = 0.815189
I0526 00:26:13.317832 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.815189 (* 1 = 0.815189 loss)
I0526 00:26:13.317842 15394 sgd_solver.cpp:43] Iteration 3730, lr = 0.02
I0526 00:26:18.561326 15394 main.cpp:354] Iteration 3740, loss = 0.697992
I0526 00:26:18.561403 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.697992 (* 1 = 0.697992 loss)
I0526 00:26:18.561415 15394 sgd_solver.cpp:43] Iteration 3740, lr = 0.02
I0526 00:26:23.948078 15394 main.cpp:354] Iteration 3750, loss = 0.72509
I0526 00:26:23.948142 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.72509 (* 1 = 0.72509 loss)
I0526 00:26:23.948153 15394 sgd_solver.cpp:43] Iteration 3750, lr = 0.02
I0526 00:26:29.343000 15394 main.cpp:354] Iteration 3760, loss = 0.78057
I0526 00:26:29.343063 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.78057 (* 1 = 0.78057 loss)
I0526 00:26:29.343075 15394 sgd_solver.cpp:43] Iteration 3760, lr = 0.02
I0526 00:26:34.266340 15394 main.cpp:354] Iteration 3770, loss = 0.785089
I0526 00:26:34.266422 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.785089 (* 1 = 0.785089 loss)
I0526 00:26:34.266443 15394 sgd_solver.cpp:43] Iteration 3770, lr = 0.02
I0526 00:26:39.360411 15394 main.cpp:354] Iteration 3780, loss = 0.871399
I0526 00:26:39.360481 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.871399 (* 1 = 0.871399 loss)
I0526 00:26:39.360492 15394 sgd_solver.cpp:43] Iteration 3780, lr = 0.02
I0526 00:26:44.003626 15394 main.cpp:354] Iteration 3790, loss = 0.876818
I0526 00:26:44.003689 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.876818 (* 1 = 0.876818 loss)
I0526 00:26:44.003697 15394 sgd_solver.cpp:43] Iteration 3790, lr = 0.02
I0526 00:26:48.492552 15394 main.cpp:465] Iteration 3800, Testing net (#0)
I0526 00:27:01.629891 15394 main.cpp:532]     Test net output #0: Accuracy = 0.4877
I0526 00:27:01.629948 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.62277 (* 1 = 1.62277 loss)
I0526 00:27:02.131916 15394 main.cpp:354] Iteration 3800, loss = 0.749409
I0526 00:27:02.131983 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.749409 (* 1 = 0.749409 loss)
I0526 00:27:02.131994 15394 sgd_solver.cpp:43] Iteration 3800, lr = 0.02
I0526 00:27:07.492882 15394 main.cpp:354] Iteration 3810, loss = 0.792539
I0526 00:27:07.492951 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.792539 (* 1 = 0.792539 loss)
I0526 00:27:07.492962 15394 sgd_solver.cpp:43] Iteration 3810, lr = 0.02
I0526 00:27:12.448379 15394 main.cpp:354] Iteration 3820, loss = 0.78438
I0526 00:27:12.448441 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.78438 (* 1 = 0.78438 loss)
I0526 00:27:12.448452 15394 sgd_solver.cpp:43] Iteration 3820, lr = 0.02
I0526 00:27:17.532075 15394 main.cpp:354] Iteration 3830, loss = 0.63557
I0526 00:27:17.532145 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.63557 (* 1 = 0.63557 loss)
I0526 00:27:17.532156 15394 sgd_solver.cpp:43] Iteration 3830, lr = 0.02
I0526 00:27:22.800320 15394 main.cpp:354] Iteration 3840, loss = 1.00744
I0526 00:27:22.800390 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.00744 (* 1 = 1.00744 loss)
I0526 00:27:22.800402 15394 sgd_solver.cpp:43] Iteration 3840, lr = 0.02
I0526 00:27:27.658741 15394 main.cpp:354] Iteration 3850, loss = 0.81834
I0526 00:27:27.658802 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.81834 (* 1 = 0.81834 loss)
I0526 00:27:27.658812 15394 sgd_solver.cpp:43] Iteration 3850, lr = 0.02
I0526 00:27:32.462453 15394 main.cpp:354] Iteration 3860, loss = 0.90493
I0526 00:27:32.462519 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.90493 (* 1 = 0.90493 loss)
I0526 00:27:32.462529 15394 sgd_solver.cpp:43] Iteration 3860, lr = 0.02
I0526 00:27:37.428216 15394 main.cpp:354] Iteration 3870, loss = 0.639148
I0526 00:27:37.428292 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.639148 (* 1 = 0.639148 loss)
I0526 00:27:37.428303 15394 sgd_solver.cpp:43] Iteration 3870, lr = 0.02
I0526 00:27:42.507736 15394 main.cpp:354] Iteration 3880, loss = 0.685584
I0526 00:27:42.507803 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.685584 (* 1 = 0.685584 loss)
I0526 00:27:42.507814 15394 sgd_solver.cpp:43] Iteration 3880, lr = 0.02
I0526 00:27:47.630923 15394 main.cpp:354] Iteration 3890, loss = 0.704365
I0526 00:27:47.630990 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.704365 (* 1 = 0.704365 loss)
I0526 00:27:47.631002 15394 sgd_solver.cpp:43] Iteration 3890, lr = 0.02
I0526 00:27:52.187741 15394 main.cpp:465] Iteration 3900, Testing net (#0)
I0526 00:28:05.362386 15394 main.cpp:532]     Test net output #0: Accuracy = 0.5378
I0526 00:28:05.362448 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.34672 (* 1 = 1.34672 loss)
I0526 00:28:05.799715 15394 main.cpp:354] Iteration 3900, loss = 0.710196
I0526 00:28:05.799780 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.710196 (* 1 = 0.710196 loss)
I0526 00:28:05.799798 15394 sgd_solver.cpp:43] Iteration 3900, lr = 0.02
I0526 00:28:10.619114 15394 main.cpp:354] Iteration 3910, loss = 0.620729
I0526 00:28:10.619185 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.620729 (* 1 = 0.620729 loss)
I0526 00:28:10.619197 15394 sgd_solver.cpp:43] Iteration 3910, lr = 0.02
I0526 00:28:15.177976 15394 main.cpp:354] Iteration 3920, loss = 0.989845
I0526 00:28:15.178040 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.989845 (* 1 = 0.989845 loss)
I0526 00:28:15.178050 15394 sgd_solver.cpp:43] Iteration 3920, lr = 0.02
I0526 00:28:20.098476 15394 main.cpp:354] Iteration 3930, loss = 0.647888
I0526 00:28:20.098551 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.647888 (* 1 = 0.647888 loss)
I0526 00:28:20.098562 15394 sgd_solver.cpp:43] Iteration 3930, lr = 0.02
I0526 00:28:24.872611 15394 main.cpp:354] Iteration 3940, loss = 0.750033
I0526 00:28:24.872678 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.750033 (* 1 = 0.750033 loss)
I0526 00:28:24.872689 15394 sgd_solver.cpp:43] Iteration 3940, lr = 0.02
I0526 00:28:30.139407 15394 main.cpp:354] Iteration 3950, loss = 0.658031
I0526 00:28:30.139474 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.658031 (* 1 = 0.658031 loss)
I0526 00:28:30.139484 15394 sgd_solver.cpp:43] Iteration 3950, lr = 0.02
I0526 00:28:35.218169 15394 main.cpp:354] Iteration 3960, loss = 0.597436
I0526 00:28:35.218241 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.597436 (* 1 = 0.597436 loss)
I0526 00:28:35.218252 15394 sgd_solver.cpp:43] Iteration 3960, lr = 0.02
I0526 00:28:40.465684 15394 main.cpp:354] Iteration 3970, loss = 0.802632
I0526 00:28:40.465751 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.802632 (* 1 = 0.802632 loss)
I0526 00:28:40.465762 15394 sgd_solver.cpp:43] Iteration 3970, lr = 0.02
I0526 00:28:45.488337 15394 main.cpp:354] Iteration 3980, loss = 0.714494
I0526 00:28:45.488401 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.714494 (* 1 = 0.714494 loss)
I0526 00:28:45.488411 15394 sgd_solver.cpp:43] Iteration 3980, lr = 0.02
I0526 00:28:50.312633 15394 main.cpp:354] Iteration 3990, loss = 0.756278
I0526 00:28:50.312705 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.756278 (* 1 = 0.756278 loss)
I0526 00:28:50.312716 15394 sgd_solver.cpp:43] Iteration 3990, lr = 0.02
I0526 00:28:54.596655 15394 main.cpp:465] Iteration 4000, Testing net (#0)
I0526 00:29:07.737704 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7027
I0526 00:29:07.737767 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.89805 (* 1 = 0.89805 loss)
I0526 00:29:08.174310 15394 main.cpp:354] Iteration 4000, loss = 0.846326
I0526 00:29:08.174381 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.846326 (* 1 = 0.846326 loss)
I0526 00:29:08.174397 15394 sgd_solver.cpp:43] Iteration 4000, lr = 0.02
I0526 00:29:13.554981 15394 main.cpp:354] Iteration 4010, loss = 0.856278
I0526 00:29:13.555058 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.856278 (* 1 = 0.856278 loss)
I0526 00:29:13.555069 15394 sgd_solver.cpp:43] Iteration 4010, lr = 0.02
I0526 00:29:18.934844 15394 main.cpp:354] Iteration 4020, loss = 0.73363
I0526 00:29:18.934911 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.73363 (* 1 = 0.73363 loss)
I0526 00:29:18.934922 15394 sgd_solver.cpp:43] Iteration 4020, lr = 0.02
I0526 00:29:24.073807 15394 main.cpp:354] Iteration 4030, loss = 0.860196
I0526 00:29:24.073870 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.860196 (* 1 = 0.860196 loss)
I0526 00:29:24.073881 15394 sgd_solver.cpp:43] Iteration 4030, lr = 0.02
I0526 00:29:28.761327 15394 main.cpp:354] Iteration 4040, loss = 0.745967
I0526 00:29:28.761395 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.745967 (* 1 = 0.745967 loss)
I0526 00:29:28.761406 15394 sgd_solver.cpp:43] Iteration 4040, lr = 0.02
I0526 00:29:33.495337 15394 main.cpp:354] Iteration 4050, loss = 0.778043
I0526 00:29:33.495404 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.778043 (* 1 = 0.778043 loss)
I0526 00:29:33.495429 15394 sgd_solver.cpp:43] Iteration 4050, lr = 0.02
I0526 00:29:38.098623 15394 main.cpp:354] Iteration 4060, loss = 0.926904
I0526 00:29:38.098686 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.926904 (* 1 = 0.926904 loss)
I0526 00:29:38.098697 15394 sgd_solver.cpp:43] Iteration 4060, lr = 0.02
I0526 00:29:43.578675 15394 main.cpp:354] Iteration 4070, loss = 0.760223
I0526 00:29:43.578739 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.760223 (* 1 = 0.760223 loss)
I0526 00:29:43.578750 15394 sgd_solver.cpp:43] Iteration 4070, lr = 0.02
I0526 00:29:49.089795 15394 main.cpp:354] Iteration 4080, loss = 0.725796
I0526 00:29:49.089869 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.725796 (* 1 = 0.725796 loss)
I0526 00:29:49.089879 15394 sgd_solver.cpp:43] Iteration 4080, lr = 0.02
I0526 00:29:54.177983 15394 main.cpp:354] Iteration 4090, loss = 0.736571
I0526 00:29:54.178051 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.736571 (* 1 = 0.736571 loss)
I0526 00:29:54.178062 15394 sgd_solver.cpp:43] Iteration 4090, lr = 0.02
I0526 00:29:58.553077 15394 main.cpp:465] Iteration 4100, Testing net (#0)
I0526 00:30:11.727447 15394 main.cpp:532]     Test net output #0: Accuracy = 0.5889
I0526 00:30:11.727506 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.24291 (* 1 = 1.24291 loss)
I0526 00:30:12.060657 15394 main.cpp:354] Iteration 4100, loss = 0.977262
I0526 00:30:12.060724 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.977262 (* 1 = 0.977262 loss)
I0526 00:30:12.060739 15394 sgd_solver.cpp:43] Iteration 4100, lr = 0.02
I0526 00:30:17.004070 15394 main.cpp:354] Iteration 4110, loss = 0.65505
I0526 00:30:17.004135 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.65505 (* 1 = 0.65505 loss)
I0526 00:30:17.004147 15394 sgd_solver.cpp:43] Iteration 4110, lr = 0.02
I0526 00:30:22.309527 15394 main.cpp:354] Iteration 4120, loss = 0.755607
I0526 00:30:22.309598 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.755607 (* 1 = 0.755607 loss)
I0526 00:30:22.309610 15394 sgd_solver.cpp:43] Iteration 4120, lr = 0.02
I0526 00:30:27.757542 15394 main.cpp:354] Iteration 4130, loss = 0.873802
I0526 00:30:27.757607 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.873802 (* 1 = 0.873802 loss)
I0526 00:30:27.757618 15394 sgd_solver.cpp:43] Iteration 4130, lr = 0.02
I0526 00:30:32.846691 15394 main.cpp:354] Iteration 4140, loss = 0.6035
I0526 00:30:32.846758 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.6035 (* 1 = 0.6035 loss)
I0526 00:30:32.846770 15394 sgd_solver.cpp:43] Iteration 4140, lr = 0.02
I0526 00:30:38.183841 15394 main.cpp:354] Iteration 4150, loss = 0.535408
I0526 00:30:38.183907 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.535408 (* 1 = 0.535408 loss)
I0526 00:30:38.183917 15394 sgd_solver.cpp:43] Iteration 4150, lr = 0.02
I0526 00:30:43.131917 15394 main.cpp:354] Iteration 4160, loss = 0.709571
I0526 00:30:43.131985 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.709571 (* 1 = 0.709571 loss)
I0526 00:30:43.131997 15394 sgd_solver.cpp:43] Iteration 4160, lr = 0.02
I0526 00:30:48.160609 15394 main.cpp:354] Iteration 4170, loss = 0.726815
I0526 00:30:48.160684 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.726815 (* 1 = 0.726815 loss)
I0526 00:30:48.160698 15394 sgd_solver.cpp:43] Iteration 4170, lr = 0.02
I0526 00:30:53.170506 15394 main.cpp:354] Iteration 4180, loss = 0.778395
I0526 00:30:53.170567 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.778395 (* 1 = 0.778395 loss)
I0526 00:30:53.170578 15394 sgd_solver.cpp:43] Iteration 4180, lr = 0.02
I0526 00:30:58.769974 15394 main.cpp:354] Iteration 4190, loss = 0.623104
I0526 00:30:58.770037 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.623104 (* 1 = 0.623104 loss)
I0526 00:30:58.770048 15394 sgd_solver.cpp:43] Iteration 4190, lr = 0.02
I0526 00:31:03.107957 15394 main.cpp:465] Iteration 4200, Testing net (#0)
I0526 00:31:16.243422 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6646
I0526 00:31:16.243484 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.962042 (* 1 = 0.962042 loss)
I0526 00:31:16.713826 15394 main.cpp:354] Iteration 4200, loss = 0.753493
I0526 00:31:16.713892 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.753493 (* 1 = 0.753493 loss)
I0526 00:31:16.713902 15394 sgd_solver.cpp:43] Iteration 4200, lr = 0.02
I0526 00:31:21.343174 15394 main.cpp:354] Iteration 4210, loss = 0.750544
I0526 00:31:21.343243 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.750544 (* 1 = 0.750544 loss)
I0526 00:31:21.343255 15394 sgd_solver.cpp:43] Iteration 4210, lr = 0.02
I0526 00:31:25.828006 15394 main.cpp:354] Iteration 4220, loss = 0.772603
I0526 00:31:25.828074 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.772603 (* 1 = 0.772603 loss)
I0526 00:31:25.828085 15394 sgd_solver.cpp:43] Iteration 4220, lr = 0.02
I0526 00:31:30.996470 15394 main.cpp:354] Iteration 4230, loss = 0.907896
I0526 00:31:30.996536 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.907896 (* 1 = 0.907896 loss)
I0526 00:31:30.996547 15394 sgd_solver.cpp:43] Iteration 4230, lr = 0.02
I0526 00:31:36.237179 15394 main.cpp:354] Iteration 4240, loss = 0.92727
I0526 00:31:36.237248 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.92727 (* 1 = 0.92727 loss)
I0526 00:31:36.237259 15394 sgd_solver.cpp:43] Iteration 4240, lr = 0.02
I0526 00:31:41.557852 15394 main.cpp:354] Iteration 4250, loss = 0.642204
I0526 00:31:41.557914 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.642204 (* 1 = 0.642204 loss)
I0526 00:31:41.557924 15394 sgd_solver.cpp:43] Iteration 4250, lr = 0.02
I0526 00:31:46.618333 15394 main.cpp:354] Iteration 4260, loss = 0.948466
I0526 00:31:46.618398 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.948466 (* 1 = 0.948466 loss)
I0526 00:31:46.618409 15394 sgd_solver.cpp:43] Iteration 4260, lr = 0.02
I0526 00:31:51.873621 15394 main.cpp:354] Iteration 4270, loss = 0.772015
I0526 00:31:51.873697 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.772015 (* 1 = 0.772015 loss)
I0526 00:31:51.873708 15394 sgd_solver.cpp:43] Iteration 4270, lr = 0.02
I0526 00:31:56.880228 15394 main.cpp:354] Iteration 4280, loss = 1.20942
I0526 00:31:56.880287 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.20942 (* 1 = 1.20942 loss)
I0526 00:31:56.880297 15394 sgd_solver.cpp:43] Iteration 4280, lr = 0.02
I0526 00:32:01.501296 15394 main.cpp:354] Iteration 4290, loss = 0.721841
I0526 00:32:01.501363 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.721841 (* 1 = 0.721841 loss)
I0526 00:32:01.501374 15394 sgd_solver.cpp:43] Iteration 4290, lr = 0.02
I0526 00:32:06.318984 15394 main.cpp:465] Iteration 4300, Testing net (#0)
I0526 00:32:19.462976 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6879
I0526 00:32:19.463040 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.930403 (* 1 = 0.930403 loss)
I0526 00:32:19.970888 15394 main.cpp:354] Iteration 4300, loss = 0.6552
I0526 00:32:19.970962 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.6552 (* 1 = 0.6552 loss)
I0526 00:32:19.970975 15394 sgd_solver.cpp:43] Iteration 4300, lr = 0.02
I0526 00:32:24.870168 15394 main.cpp:354] Iteration 4310, loss = 0.605018
I0526 00:32:24.870234 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.605018 (* 1 = 0.605018 loss)
I0526 00:32:24.870245 15394 sgd_solver.cpp:43] Iteration 4310, lr = 0.02
I0526 00:32:30.017160 15394 main.cpp:354] Iteration 4320, loss = 0.835024
I0526 00:32:30.017225 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.835024 (* 1 = 0.835024 loss)
I0526 00:32:30.017235 15394 sgd_solver.cpp:43] Iteration 4320, lr = 0.02
I0526 00:32:34.909288 15394 main.cpp:354] Iteration 4330, loss = 0.766363
I0526 00:32:34.909358 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.766363 (* 1 = 0.766363 loss)
I0526 00:32:34.909379 15394 sgd_solver.cpp:43] Iteration 4330, lr = 0.02
I0526 00:32:39.979830 15394 main.cpp:354] Iteration 4340, loss = 0.74691
I0526 00:32:39.979895 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.74691 (* 1 = 0.74691 loss)
I0526 00:32:39.979907 15394 sgd_solver.cpp:43] Iteration 4340, lr = 0.02
I0526 00:32:44.927345 15394 main.cpp:354] Iteration 4350, loss = 0.720271
I0526 00:32:44.927413 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.720271 (* 1 = 0.720271 loss)
I0526 00:32:44.927424 15394 sgd_solver.cpp:43] Iteration 4350, lr = 0.02
I0526 00:32:50.065636 15394 main.cpp:354] Iteration 4360, loss = 0.737365
I0526 00:32:50.065706 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.737365 (* 1 = 0.737365 loss)
I0526 00:32:50.065716 15394 sgd_solver.cpp:43] Iteration 4360, lr = 0.02
I0526 00:32:55.208758 15394 main.cpp:354] Iteration 4370, loss = 0.743653
I0526 00:32:55.208822 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.743653 (* 1 = 0.743653 loss)
I0526 00:32:55.208832 15394 sgd_solver.cpp:43] Iteration 4370, lr = 0.02
I0526 00:33:00.432584 15394 main.cpp:354] Iteration 4380, loss = 0.711653
I0526 00:33:00.432648 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.711653 (* 1 = 0.711653 loss)
I0526 00:33:00.432658 15394 sgd_solver.cpp:43] Iteration 4380, lr = 0.02
I0526 00:33:05.165560 15394 main.cpp:354] Iteration 4390, loss = 0.61596
I0526 00:33:05.165633 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.61596 (* 1 = 0.61596 loss)
I0526 00:33:05.165644 15394 sgd_solver.cpp:43] Iteration 4390, lr = 0.02
I0526 00:33:09.790550 15394 main.cpp:465] Iteration 4400, Testing net (#0)
I0526 00:33:23.006343 15394 main.cpp:532]     Test net output #0: Accuracy = 0.5884
I0526 00:33:23.006413 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.35489 (* 1 = 1.35489 loss)
I0526 00:33:23.437427 15394 main.cpp:354] Iteration 4400, loss = 0.823994
I0526 00:33:23.437505 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.823994 (* 1 = 0.823994 loss)
I0526 00:33:23.437520 15394 sgd_solver.cpp:43] Iteration 4400, lr = 0.02
I0526 00:33:27.958986 15394 main.cpp:354] Iteration 4410, loss = 0.628254
I0526 00:33:27.959054 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.628254 (* 1 = 0.628254 loss)
I0526 00:33:27.959066 15394 sgd_solver.cpp:43] Iteration 4410, lr = 0.02
I0526 00:33:32.698379 15394 main.cpp:354] Iteration 4420, loss = 0.65268
I0526 00:33:32.698451 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.65268 (* 1 = 0.65268 loss)
I0526 00:33:32.698462 15394 sgd_solver.cpp:43] Iteration 4420, lr = 0.02
I0526 00:33:37.861140 15394 main.cpp:354] Iteration 4430, loss = 0.648729
I0526 00:33:37.861215 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.648729 (* 1 = 0.648729 loss)
I0526 00:33:37.861227 15394 sgd_solver.cpp:43] Iteration 4430, lr = 0.02
I0526 00:33:43.093430 15394 main.cpp:354] Iteration 4440, loss = 0.858083
I0526 00:33:43.093493 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.858083 (* 1 = 0.858083 loss)
I0526 00:33:43.093502 15394 sgd_solver.cpp:43] Iteration 4440, lr = 0.02
I0526 00:33:48.071789 15394 main.cpp:354] Iteration 4450, loss = 0.639452
I0526 00:33:48.071876 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.639452 (* 1 = 0.639452 loss)
I0526 00:33:48.071892 15394 sgd_solver.cpp:43] Iteration 4450, lr = 0.02
I0526 00:33:52.988674 15394 main.cpp:354] Iteration 4460, loss = 0.731482
I0526 00:33:52.988744 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.731482 (* 1 = 0.731482 loss)
I0526 00:33:52.988754 15394 sgd_solver.cpp:43] Iteration 4460, lr = 0.02
I0526 00:33:57.911810 15394 main.cpp:354] Iteration 4470, loss = 0.711503
I0526 00:33:57.911876 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.711503 (* 1 = 0.711503 loss)
I0526 00:33:57.911888 15394 sgd_solver.cpp:43] Iteration 4470, lr = 0.02
I0526 00:34:02.965303 15394 main.cpp:354] Iteration 4480, loss = 0.854015
I0526 00:34:02.965397 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.854015 (* 1 = 0.854015 loss)
I0526 00:34:02.965414 15394 sgd_solver.cpp:43] Iteration 4480, lr = 0.02
I0526 00:34:08.374338 15394 main.cpp:354] Iteration 4490, loss = 0.696698
I0526 00:34:08.374413 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.696698 (* 1 = 0.696698 loss)
I0526 00:34:08.374424 15394 sgd_solver.cpp:43] Iteration 4490, lr = 0.02
I0526 00:34:13.040227 15394 main.cpp:465] Iteration 4500, Testing net (#0)
I0526 00:34:26.189201 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6379
I0526 00:34:26.189272 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.11505 (* 1 = 1.11505 loss)
I0526 00:34:26.697859 15394 main.cpp:354] Iteration 4500, loss = 0.636557
I0526 00:34:26.697937 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.636557 (* 1 = 0.636557 loss)
I0526 00:34:26.697953 15394 sgd_solver.cpp:43] Iteration 4500, lr = 0.02
I0526 00:34:31.344717 15394 main.cpp:354] Iteration 4510, loss = 0.749554
I0526 00:34:31.344784 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.749554 (* 1 = 0.749554 loss)
I0526 00:34:31.344795 15394 sgd_solver.cpp:43] Iteration 4510, lr = 0.02
I0526 00:34:36.118453 15394 main.cpp:354] Iteration 4520, loss = 0.883166
I0526 00:34:36.118530 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.883166 (* 1 = 0.883166 loss)
I0526 00:34:36.118540 15394 sgd_solver.cpp:43] Iteration 4520, lr = 0.02
I0526 00:34:40.918026 15394 main.cpp:354] Iteration 4530, loss = 0.800583
I0526 00:34:40.918089 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.800583 (* 1 = 0.800583 loss)
I0526 00:34:40.918099 15394 sgd_solver.cpp:43] Iteration 4530, lr = 0.02
I0526 00:34:45.731780 15394 main.cpp:354] Iteration 4540, loss = 0.73172
I0526 00:34:45.731850 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.73172 (* 1 = 0.73172 loss)
I0526 00:34:45.731860 15394 sgd_solver.cpp:43] Iteration 4540, lr = 0.02
I0526 00:34:50.646533 15394 main.cpp:354] Iteration 4550, loss = 0.783961
I0526 00:34:50.646601 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.783961 (* 1 = 0.783961 loss)
I0526 00:34:50.646613 15394 sgd_solver.cpp:43] Iteration 4550, lr = 0.02
I0526 00:34:55.458729 15394 main.cpp:354] Iteration 4560, loss = 0.668425
I0526 00:34:55.458793 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.668425 (* 1 = 0.668425 loss)
I0526 00:34:55.458803 15394 sgd_solver.cpp:43] Iteration 4560, lr = 0.02
I0526 00:35:00.932155 15394 main.cpp:354] Iteration 4570, loss = 0.865893
I0526 00:35:00.932219 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.865893 (* 1 = 0.865893 loss)
I0526 00:35:00.932229 15394 sgd_solver.cpp:43] Iteration 4570, lr = 0.02
I0526 00:35:06.374706 15394 main.cpp:354] Iteration 4580, loss = 0.669995
I0526 00:35:06.374778 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.669995 (* 1 = 0.669995 loss)
I0526 00:35:06.374788 15394 sgd_solver.cpp:43] Iteration 4580, lr = 0.02
I0526 00:35:14.465682 15394 main.cpp:354] Iteration 4590, loss = 0.677479
I0526 00:35:14.465744 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.677479 (* 1 = 0.677479 loss)
I0526 00:35:14.465754 15394 sgd_solver.cpp:43] Iteration 4590, lr = 0.02
I0526 00:35:24.963110 15394 main.cpp:465] Iteration 4600, Testing net (#0)
I0526 00:35:54.483170 15394 main.cpp:532]     Test net output #0: Accuracy = 0.586
I0526 00:35:54.483237 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.19421 (* 1 = 1.19421 loss)
I0526 00:35:55.170464 15394 main.cpp:354] Iteration 4600, loss = 0.554639
I0526 00:35:55.170532 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.554639 (* 1 = 0.554639 loss)
I0526 00:35:55.170548 15394 sgd_solver.cpp:43] Iteration 4600, lr = 0.02
I0526 00:36:05.515292 15394 main.cpp:354] Iteration 4610, loss = 0.741567
I0526 00:36:05.515363 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.741567 (* 1 = 0.741567 loss)
I0526 00:36:05.515388 15394 sgd_solver.cpp:43] Iteration 4610, lr = 0.02
I0526 00:36:16.724458 15394 main.cpp:354] Iteration 4620, loss = 0.721715
I0526 00:36:16.724520 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.721715 (* 1 = 0.721715 loss)
I0526 00:36:16.724531 15394 sgd_solver.cpp:43] Iteration 4620, lr = 0.02
I0526 00:36:28.068958 15394 main.cpp:354] Iteration 4630, loss = 0.826661
I0526 00:36:28.069025 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.826661 (* 1 = 0.826661 loss)
I0526 00:36:28.069036 15394 sgd_solver.cpp:43] Iteration 4630, lr = 0.02
I0526 00:36:39.848361 15394 main.cpp:354] Iteration 4640, loss = 0.658739
I0526 00:36:39.848433 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.658739 (* 1 = 0.658739 loss)
I0526 00:36:39.848444 15394 sgd_solver.cpp:43] Iteration 4640, lr = 0.02
I0526 00:36:51.292634 15394 main.cpp:354] Iteration 4650, loss = 0.810799
I0526 00:36:51.292701 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.810799 (* 1 = 0.810799 loss)
I0526 00:36:51.292711 15394 sgd_solver.cpp:43] Iteration 4650, lr = 0.02
I0526 00:37:02.472113 15394 main.cpp:354] Iteration 4660, loss = 0.717108
I0526 00:37:02.472177 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.717108 (* 1 = 0.717108 loss)
I0526 00:37:02.472187 15394 sgd_solver.cpp:43] Iteration 4660, lr = 0.02
I0526 00:37:12.989876 15394 main.cpp:354] Iteration 4670, loss = 0.679083
I0526 00:37:12.989945 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.679083 (* 1 = 0.679083 loss)
I0526 00:37:12.989956 15394 sgd_solver.cpp:43] Iteration 4670, lr = 0.02
I0526 00:37:24.805865 15394 main.cpp:354] Iteration 4680, loss = 0.631958
I0526 00:37:24.805934 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.631958 (* 1 = 0.631958 loss)
I0526 00:37:24.805945 15394 sgd_solver.cpp:43] Iteration 4680, lr = 0.02
I0526 00:37:35.915789 15394 main.cpp:354] Iteration 4690, loss = 0.672319
I0526 00:37:35.915859 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.672319 (* 1 = 0.672319 loss)
I0526 00:37:35.915870 15394 sgd_solver.cpp:43] Iteration 4690, lr = 0.02
I0526 00:37:46.973655 15394 main.cpp:465] Iteration 4700, Testing net (#0)
I0526 00:38:17.148465 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7097
I0526 00:38:17.148527 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.825765 (* 1 = 0.825765 loss)
I0526 00:38:18.323552 15394 main.cpp:354] Iteration 4700, loss = 0.561585
I0526 00:38:18.323626 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.561585 (* 1 = 0.561585 loss)
I0526 00:38:18.323639 15394 sgd_solver.cpp:43] Iteration 4700, lr = 0.02
I0526 00:38:29.161964 15394 main.cpp:354] Iteration 4710, loss = 0.72097
I0526 00:38:29.162025 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.72097 (* 1 = 0.72097 loss)
I0526 00:38:29.162035 15394 sgd_solver.cpp:43] Iteration 4710, lr = 0.02
I0526 00:38:40.206681 15394 main.cpp:354] Iteration 4720, loss = 0.743022
I0526 00:38:40.206748 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.743022 (* 1 = 0.743022 loss)
I0526 00:38:40.206759 15394 sgd_solver.cpp:43] Iteration 4720, lr = 0.02
I0526 00:38:51.273326 15394 main.cpp:354] Iteration 4730, loss = 0.782566
I0526 00:38:51.273398 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.782566 (* 1 = 0.782566 loss)
I0526 00:38:51.273408 15394 sgd_solver.cpp:43] Iteration 4730, lr = 0.02
I0526 00:39:02.486990 15394 main.cpp:354] Iteration 4740, loss = 0.636239
I0526 00:39:02.487052 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.636239 (* 1 = 0.636239 loss)
I0526 00:39:02.487063 15394 sgd_solver.cpp:43] Iteration 4740, lr = 0.02
I0526 00:39:13.325912 15394 main.cpp:354] Iteration 4750, loss = 0.92743
I0526 00:39:13.325981 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.92743 (* 1 = 0.92743 loss)
I0526 00:39:13.325994 15394 sgd_solver.cpp:43] Iteration 4750, lr = 0.02
I0526 00:39:24.530120 15394 main.cpp:354] Iteration 4760, loss = 0.672421
I0526 00:39:24.530199 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.672421 (* 1 = 0.672421 loss)
I0526 00:39:24.530210 15394 sgd_solver.cpp:43] Iteration 4760, lr = 0.02
I0526 00:39:35.585721 15394 main.cpp:354] Iteration 4770, loss = 0.768729
I0526 00:39:35.585793 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.768729 (* 1 = 0.768729 loss)
I0526 00:39:35.585804 15394 sgd_solver.cpp:43] Iteration 4770, lr = 0.02
I0526 00:39:46.744676 15394 main.cpp:354] Iteration 4780, loss = 0.638526
I0526 00:39:46.744741 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.638526 (* 1 = 0.638526 loss)
I0526 00:39:46.744751 15394 sgd_solver.cpp:43] Iteration 4780, lr = 0.02
I0526 00:39:57.089455 15394 main.cpp:354] Iteration 4790, loss = 0.798839
I0526 00:39:57.089522 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.798839 (* 1 = 0.798839 loss)
I0526 00:39:57.089534 15394 sgd_solver.cpp:43] Iteration 4790, lr = 0.02
I0526 00:40:06.956800 15394 main.cpp:465] Iteration 4800, Testing net (#0)
I0526 00:40:37.363283 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6235
I0526 00:40:37.363345 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.10829 (* 1 = 1.10829 loss)
I0526 00:40:38.454437 15394 main.cpp:354] Iteration 4800, loss = 0.712097
I0526 00:40:38.454505 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.712097 (* 1 = 0.712097 loss)
I0526 00:40:38.454522 15394 sgd_solver.cpp:43] Iteration 4800, lr = 0.02
I0526 00:40:49.376049 15394 main.cpp:354] Iteration 4810, loss = 1.00155
I0526 00:40:49.376116 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.00155 (* 1 = 1.00155 loss)
I0526 00:40:49.376127 15394 sgd_solver.cpp:43] Iteration 4810, lr = 0.02
I0526 00:41:00.844627 15394 main.cpp:354] Iteration 4820, loss = 0.615689
I0526 00:41:00.844687 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.615689 (* 1 = 0.615689 loss)
I0526 00:41:00.844699 15394 sgd_solver.cpp:43] Iteration 4820, lr = 0.02
I0526 00:41:12.092672 15394 main.cpp:354] Iteration 4830, loss = 0.816571
I0526 00:41:12.092746 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.816571 (* 1 = 0.816571 loss)
I0526 00:41:12.092756 15394 sgd_solver.cpp:43] Iteration 4830, lr = 0.02
I0526 00:41:23.657043 15394 main.cpp:354] Iteration 4840, loss = 0.552053
I0526 00:41:23.657110 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.552053 (* 1 = 0.552053 loss)
I0526 00:41:23.657122 15394 sgd_solver.cpp:43] Iteration 4840, lr = 0.02
I0526 00:41:34.424962 15394 main.cpp:354] Iteration 4850, loss = 0.653038
I0526 00:41:34.425038 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.653038 (* 1 = 0.653038 loss)
I0526 00:41:34.425050 15394 sgd_solver.cpp:43] Iteration 4850, lr = 0.02
I0526 00:41:45.286519 15394 main.cpp:354] Iteration 4860, loss = 0.854085
I0526 00:41:45.286586 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.854085 (* 1 = 0.854085 loss)
I0526 00:41:45.286597 15394 sgd_solver.cpp:43] Iteration 4860, lr = 0.02
I0526 00:41:56.585935 15394 main.cpp:354] Iteration 4870, loss = 0.681219
I0526 00:41:56.586004 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.681219 (* 1 = 0.681219 loss)
I0526 00:41:56.586014 15394 sgd_solver.cpp:43] Iteration 4870, lr = 0.02
I0526 00:42:08.474593 15394 main.cpp:354] Iteration 4880, loss = 0.62186
I0526 00:42:08.474661 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.62186 (* 1 = 0.62186 loss)
I0526 00:42:08.474673 15394 sgd_solver.cpp:43] Iteration 4880, lr = 0.02
I0526 00:42:19.544608 15394 main.cpp:354] Iteration 4890, loss = 0.646794
I0526 00:42:19.544680 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.646794 (* 1 = 0.646794 loss)
I0526 00:42:19.544692 15394 sgd_solver.cpp:43] Iteration 4890, lr = 0.02
I0526 00:42:29.774448 15394 main.cpp:465] Iteration 4900, Testing net (#0)
I0526 00:43:00.258831 15394 main.cpp:532]     Test net output #0: Accuracy = 0.725
I0526 00:43:00.258901 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.798736 (* 1 = 0.798736 loss)
I0526 00:43:01.376723 15394 main.cpp:354] Iteration 4900, loss = 0.689454
I0526 00:43:01.376790 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.689454 (* 1 = 0.689454 loss)
I0526 00:43:01.376803 15394 sgd_solver.cpp:43] Iteration 4900, lr = 0.02
I0526 00:43:12.571105 15394 main.cpp:354] Iteration 4910, loss = 0.682782
I0526 00:43:12.571176 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.682782 (* 1 = 0.682782 loss)
I0526 00:43:12.571187 15394 sgd_solver.cpp:43] Iteration 4910, lr = 0.02
I0526 00:43:24.077111 15394 main.cpp:354] Iteration 4920, loss = 0.731514
I0526 00:43:24.077183 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.731514 (* 1 = 0.731514 loss)
I0526 00:43:24.077194 15394 sgd_solver.cpp:43] Iteration 4920, lr = 0.02
I0526 00:43:35.273542 15394 main.cpp:354] Iteration 4930, loss = 0.627257
I0526 00:43:35.273617 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.627257 (* 1 = 0.627257 loss)
I0526 00:43:35.273628 15394 sgd_solver.cpp:43] Iteration 4930, lr = 0.02
I0526 00:43:45.990536 15394 main.cpp:354] Iteration 4940, loss = 0.567128
I0526 00:43:45.990597 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.567128 (* 1 = 0.567128 loss)
I0526 00:43:45.990608 15394 sgd_solver.cpp:43] Iteration 4940, lr = 0.02
I0526 00:43:57.694321 15394 main.cpp:354] Iteration 4950, loss = 0.826139
I0526 00:43:57.694394 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.826139 (* 1 = 0.826139 loss)
I0526 00:43:57.694406 15394 sgd_solver.cpp:43] Iteration 4950, lr = 0.02
I0526 00:44:08.756897 15394 main.cpp:354] Iteration 4960, loss = 0.671068
I0526 00:44:08.756964 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.671068 (* 1 = 0.671068 loss)
I0526 00:44:08.756974 15394 sgd_solver.cpp:43] Iteration 4960, lr = 0.02
I0526 00:44:20.860754 15394 main.cpp:354] Iteration 4970, loss = 0.472451
I0526 00:44:20.860833 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.472451 (* 1 = 0.472451 loss)
I0526 00:44:20.860844 15394 sgd_solver.cpp:43] Iteration 4970, lr = 0.02
I0526 00:44:32.172252 15394 main.cpp:354] Iteration 4980, loss = 0.758788
I0526 00:44:32.172317 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.758788 (* 1 = 0.758788 loss)
I0526 00:44:32.172328 15394 sgd_solver.cpp:43] Iteration 4980, lr = 0.02
I0526 00:44:43.033056 15394 main.cpp:354] Iteration 4990, loss = 0.471339
I0526 00:44:43.033126 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.471339 (* 1 = 0.471339 loss)
I0526 00:44:43.033138 15394 sgd_solver.cpp:43] Iteration 4990, lr = 0.02
I0526 00:44:52.951261 15394 main.cpp:465] Iteration 5000, Testing net (#0)
I0526 00:45:23.263707 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6921
I0526 00:45:23.263767 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.88649 (* 1 = 0.88649 loss)
I0526 00:45:24.302449 15394 main.cpp:354] Iteration 5000, loss = 0.57861
I0526 00:45:24.302510 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.57861 (* 1 = 0.57861 loss)
I0526 00:45:24.302526 15394 sgd_solver.cpp:43] Iteration 5000, lr = 0.02
I0526 00:45:35.459275 15394 main.cpp:354] Iteration 5010, loss = 0.733221
I0526 00:45:35.459342 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.733221 (* 1 = 0.733221 loss)
I0526 00:45:35.459352 15394 sgd_solver.cpp:43] Iteration 5010, lr = 0.02
I0526 00:45:46.822556 15394 main.cpp:354] Iteration 5020, loss = 0.590238
I0526 00:45:46.822615 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.590238 (* 1 = 0.590238 loss)
I0526 00:45:46.822626 15394 sgd_solver.cpp:43] Iteration 5020, lr = 0.02
I0526 00:45:58.279786 15394 main.cpp:354] Iteration 5030, loss = 0.793644
I0526 00:45:58.279857 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.793644 (* 1 = 0.793644 loss)
I0526 00:45:58.279868 15394 sgd_solver.cpp:43] Iteration 5030, lr = 0.02
I0526 00:46:09.767997 15394 main.cpp:354] Iteration 5040, loss = 0.579272
I0526 00:46:09.768077 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.579272 (* 1 = 0.579272 loss)
I0526 00:46:09.768090 15394 sgd_solver.cpp:43] Iteration 5040, lr = 0.02
I0526 00:46:21.178498 15394 main.cpp:354] Iteration 5050, loss = 0.71908
I0526 00:46:21.178568 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.71908 (* 1 = 0.71908 loss)
I0526 00:46:21.178580 15394 sgd_solver.cpp:43] Iteration 5050, lr = 0.02
I0526 00:46:32.056772 15394 main.cpp:354] Iteration 5060, loss = 0.802364
I0526 00:46:32.056843 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.802364 (* 1 = 0.802364 loss)
I0526 00:46:32.056855 15394 sgd_solver.cpp:43] Iteration 5060, lr = 0.02
I0526 00:46:43.004889 15394 main.cpp:354] Iteration 5070, loss = 0.568993
I0526 00:46:43.004961 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.568993 (* 1 = 0.568993 loss)
I0526 00:46:43.004972 15394 sgd_solver.cpp:43] Iteration 5070, lr = 0.02
I0526 00:46:54.615645 15394 main.cpp:354] Iteration 5080, loss = 0.773559
I0526 00:46:54.615711 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.773559 (* 1 = 0.773559 loss)
I0526 00:46:54.615721 15394 sgd_solver.cpp:43] Iteration 5080, lr = 0.02
I0526 00:47:06.671383 15394 main.cpp:354] Iteration 5090, loss = 0.659796
I0526 00:47:06.671453 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.659796 (* 1 = 0.659796 loss)
I0526 00:47:06.671464 15394 sgd_solver.cpp:43] Iteration 5090, lr = 0.02
I0526 00:47:17.240031 15394 main.cpp:465] Iteration 5100, Testing net (#0)
I0526 00:47:47.268651 15394 main.cpp:532]     Test net output #0: Accuracy = 0.5812
I0526 00:47:47.268728 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.47132 (* 1 = 1.47132 loss)
I0526 00:47:48.019748 15394 main.cpp:354] Iteration 5100, loss = 0.772973
I0526 00:47:48.019819 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.772973 (* 1 = 0.772973 loss)
I0526 00:47:48.019832 15394 sgd_solver.cpp:43] Iteration 5100, lr = 0.02
I0526 00:47:59.229578 15394 main.cpp:354] Iteration 5110, loss = 0.761821
I0526 00:47:59.229645 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.761821 (* 1 = 0.761821 loss)
I0526 00:47:59.229655 15394 sgd_solver.cpp:43] Iteration 5110, lr = 0.02
I0526 00:48:10.174957 15394 main.cpp:354] Iteration 5120, loss = 0.771909
I0526 00:48:10.175024 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.771909 (* 1 = 0.771909 loss)
I0526 00:48:10.175034 15394 sgd_solver.cpp:43] Iteration 5120, lr = 0.02
I0526 00:48:21.488176 15394 main.cpp:354] Iteration 5130, loss = 0.719929
I0526 00:48:21.488248 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.719929 (* 1 = 0.719929 loss)
I0526 00:48:21.488260 15394 sgd_solver.cpp:43] Iteration 5130, lr = 0.02
I0526 00:48:32.496605 15394 main.cpp:354] Iteration 5140, loss = 0.712825
I0526 00:48:32.496665 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.712825 (* 1 = 0.712825 loss)
I0526 00:48:32.496675 15394 sgd_solver.cpp:43] Iteration 5140, lr = 0.02
I0526 00:48:43.405609 15394 main.cpp:354] Iteration 5150, loss = 0.705729
I0526 00:48:43.405685 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.705729 (* 1 = 0.705729 loss)
I0526 00:48:43.405695 15394 sgd_solver.cpp:43] Iteration 5150, lr = 0.02
I0526 00:48:54.666867 15394 main.cpp:354] Iteration 5160, loss = 0.87289
I0526 00:48:54.666949 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.87289 (* 1 = 0.87289 loss)
I0526 00:48:54.666961 15394 sgd_solver.cpp:43] Iteration 5160, lr = 0.02
I0526 00:49:06.186569 15394 main.cpp:354] Iteration 5170, loss = 0.71763
I0526 00:49:06.186641 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.71763 (* 1 = 0.71763 loss)
I0526 00:49:06.186652 15394 sgd_solver.cpp:43] Iteration 5170, lr = 0.02
I0526 00:49:17.328728 15394 main.cpp:354] Iteration 5180, loss = 0.807666
I0526 00:49:17.328794 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.807666 (* 1 = 0.807666 loss)
I0526 00:49:17.328814 15394 sgd_solver.cpp:43] Iteration 5180, lr = 0.02
I0526 00:49:28.451975 15394 main.cpp:354] Iteration 5190, loss = 0.721185
I0526 00:49:28.452044 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.721186 (* 1 = 0.721186 loss)
I0526 00:49:28.452054 15394 sgd_solver.cpp:43] Iteration 5190, lr = 0.02
I0526 00:49:38.100759 15394 main.cpp:465] Iteration 5200, Testing net (#0)
I0526 00:50:07.925220 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6109
I0526 00:50:07.925284 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.26399 (* 1 = 1.26399 loss)
I0526 00:50:09.021215 15394 main.cpp:354] Iteration 5200, loss = 0.780217
I0526 00:50:09.021286 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.780217 (* 1 = 0.780217 loss)
I0526 00:50:09.021299 15394 sgd_solver.cpp:43] Iteration 5200, lr = 0.02
I0526 00:50:20.804761 15394 main.cpp:354] Iteration 5210, loss = 0.560682
I0526 00:50:20.804844 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.560682 (* 1 = 0.560682 loss)
I0526 00:50:20.804857 15394 sgd_solver.cpp:43] Iteration 5210, lr = 0.02
I0526 00:50:31.620021 15394 main.cpp:354] Iteration 5220, loss = 0.74866
I0526 00:50:31.620085 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.748661 (* 1 = 0.748661 loss)
I0526 00:50:31.620095 15394 sgd_solver.cpp:43] Iteration 5220, lr = 0.02
I0526 00:50:42.106909 15394 main.cpp:354] Iteration 5230, loss = 0.547088
I0526 00:50:42.106979 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.547088 (* 1 = 0.547088 loss)
I0526 00:50:42.106992 15394 sgd_solver.cpp:43] Iteration 5230, lr = 0.02
I0526 00:50:53.493304 15394 main.cpp:354] Iteration 5240, loss = 0.645969
I0526 00:50:53.493376 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.64597 (* 1 = 0.64597 loss)
I0526 00:50:53.493386 15394 sgd_solver.cpp:43] Iteration 5240, lr = 0.02
I0526 00:51:05.532343 15394 main.cpp:354] Iteration 5250, loss = 0.644736
I0526 00:51:05.532418 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.644736 (* 1 = 0.644736 loss)
I0526 00:51:05.532429 15394 sgd_solver.cpp:43] Iteration 5250, lr = 0.02
I0526 00:51:16.468839 15394 main.cpp:354] Iteration 5260, loss = 1.41833
I0526 00:51:16.468904 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.41833 (* 1 = 1.41833 loss)
I0526 00:51:16.468914 15394 sgd_solver.cpp:43] Iteration 5260, lr = 0.02
I0526 00:51:28.165341 15394 main.cpp:354] Iteration 5270, loss = 0.593282
I0526 00:51:28.165412 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.593282 (* 1 = 0.593282 loss)
I0526 00:51:28.165423 15394 sgd_solver.cpp:43] Iteration 5270, lr = 0.02
I0526 00:51:39.503991 15394 main.cpp:354] Iteration 5280, loss = 0.701854
I0526 00:51:39.504065 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.701855 (* 1 = 0.701855 loss)
I0526 00:51:39.504076 15394 sgd_solver.cpp:43] Iteration 5280, lr = 0.02
I0526 00:51:51.419059 15394 main.cpp:354] Iteration 5290, loss = 0.566646
I0526 00:51:51.419126 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.566647 (* 1 = 0.566647 loss)
I0526 00:51:51.419137 15394 sgd_solver.cpp:43] Iteration 5290, lr = 0.02
I0526 00:52:01.674643 15394 main.cpp:465] Iteration 5300, Testing net (#0)
I0526 00:52:31.401734 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7059
I0526 00:52:31.401799 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.86957 (* 1 = 0.86957 loss)
I0526 00:52:32.396782 15394 main.cpp:354] Iteration 5300, loss = 0.691428
I0526 00:52:32.396848 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.691428 (* 1 = 0.691428 loss)
I0526 00:52:32.396862 15394 sgd_solver.cpp:43] Iteration 5300, lr = 0.02
I0526 00:52:43.704936 15394 main.cpp:354] Iteration 5310, loss = 0.561726
I0526 00:52:43.705008 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.561726 (* 1 = 0.561726 loss)
I0526 00:52:43.705018 15394 sgd_solver.cpp:43] Iteration 5310, lr = 0.02
I0526 00:52:54.507897 15394 main.cpp:354] Iteration 5320, loss = 0.57983
I0526 00:52:54.507966 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.57983 (* 1 = 0.57983 loss)
I0526 00:52:54.507977 15394 sgd_solver.cpp:43] Iteration 5320, lr = 0.02
I0526 00:53:06.018121 15394 main.cpp:354] Iteration 5330, loss = 0.722406
I0526 00:53:06.018192 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.722407 (* 1 = 0.722407 loss)
I0526 00:53:06.018203 15394 sgd_solver.cpp:43] Iteration 5330, lr = 0.02
I0526 00:53:17.434186 15394 main.cpp:354] Iteration 5340, loss = 0.74797
I0526 00:53:17.434248 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.747971 (* 1 = 0.747971 loss)
I0526 00:53:17.434259 15394 sgd_solver.cpp:43] Iteration 5340, lr = 0.02
I0526 00:53:29.130697 15394 main.cpp:354] Iteration 5350, loss = 0.49158
I0526 00:53:29.130766 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.49158 (* 1 = 0.49158 loss)
I0526 00:53:29.130777 15394 sgd_solver.cpp:43] Iteration 5350, lr = 0.02
I0526 00:53:40.878597 15394 main.cpp:354] Iteration 5360, loss = 0.605316
I0526 00:53:40.878671 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.605316 (* 1 = 0.605316 loss)
I0526 00:53:40.878682 15394 sgd_solver.cpp:43] Iteration 5360, lr = 0.02
I0526 00:53:52.179095 15394 main.cpp:354] Iteration 5370, loss = 0.903933
I0526 00:53:52.179168 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.903933 (* 1 = 0.903933 loss)
I0526 00:53:52.179180 15394 sgd_solver.cpp:43] Iteration 5370, lr = 0.02
I0526 00:54:03.184798 15394 main.cpp:354] Iteration 5380, loss = 0.703456
I0526 00:54:03.184911 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.703456 (* 1 = 0.703456 loss)
I0526 00:54:03.184928 15394 sgd_solver.cpp:43] Iteration 5380, lr = 0.02
I0526 00:54:15.254511 15394 main.cpp:354] Iteration 5390, loss = 0.527995
I0526 00:54:15.254576 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.527995 (* 1 = 0.527995 loss)
I0526 00:54:15.254587 15394 sgd_solver.cpp:43] Iteration 5390, lr = 0.02
I0526 00:54:26.083852 15394 main.cpp:465] Iteration 5400, Testing net (#0)
I0526 00:54:55.921562 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6284
I0526 00:54:55.921627 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.1223 (* 1 = 1.1223 loss)
I0526 00:54:56.810390 15394 main.cpp:354] Iteration 5400, loss = 0.658443
I0526 00:54:56.810461 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.658444 (* 1 = 0.658444 loss)
I0526 00:54:56.810474 15394 sgd_solver.cpp:43] Iteration 5400, lr = 0.02
I0526 00:55:07.397979 15394 main.cpp:354] Iteration 5410, loss = 0.933442
I0526 00:55:07.398057 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.933442 (* 1 = 0.933442 loss)
I0526 00:55:07.398069 15394 sgd_solver.cpp:43] Iteration 5410, lr = 0.02
I0526 00:55:18.543252 15394 main.cpp:354] Iteration 5420, loss = 0.672869
I0526 00:55:18.543334 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.672869 (* 1 = 0.672869 loss)
I0526 00:55:18.543345 15394 sgd_solver.cpp:43] Iteration 5420, lr = 0.02
I0526 00:55:30.050823 15394 main.cpp:354] Iteration 5430, loss = 0.799817
I0526 00:55:30.050894 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.799817 (* 1 = 0.799817 loss)
I0526 00:55:30.050905 15394 sgd_solver.cpp:43] Iteration 5430, lr = 0.02
I0526 00:55:42.078289 15394 main.cpp:354] Iteration 5440, loss = 0.742079
I0526 00:55:42.078363 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.742079 (* 1 = 0.742079 loss)
I0526 00:55:42.078374 15394 sgd_solver.cpp:43] Iteration 5440, lr = 0.02
I0526 00:55:52.139430 15394 main.cpp:354] Iteration 5450, loss = 0.821835
I0526 00:55:52.139500 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.821835 (* 1 = 0.821835 loss)
I0526 00:55:52.139513 15394 sgd_solver.cpp:43] Iteration 5450, lr = 0.02
I0526 00:56:02.761484 15394 main.cpp:354] Iteration 5460, loss = 0.476163
I0526 00:56:02.761554 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.476164 (* 1 = 0.476164 loss)
I0526 00:56:02.761584 15394 sgd_solver.cpp:43] Iteration 5460, lr = 0.02
I0526 00:56:14.689895 15394 main.cpp:354] Iteration 5470, loss = 0.458906
I0526 00:56:14.689971 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.458906 (* 1 = 0.458906 loss)
I0526 00:56:14.689985 15394 sgd_solver.cpp:43] Iteration 5470, lr = 0.02
I0526 00:56:26.195313 15394 main.cpp:354] Iteration 5480, loss = 0.695665
I0526 00:56:26.195391 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.695665 (* 1 = 0.695665 loss)
I0526 00:56:26.195402 15394 sgd_solver.cpp:43] Iteration 5480, lr = 0.02
I0526 00:56:36.912900 15394 main.cpp:354] Iteration 5490, loss = 0.601107
I0526 00:56:36.912978 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.601108 (* 1 = 0.601108 loss)
I0526 00:56:36.912988 15394 sgd_solver.cpp:43] Iteration 5490, lr = 0.02
I0526 00:56:46.569941 15394 main.cpp:465] Iteration 5500, Testing net (#0)
I0526 00:57:16.667368 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6662
I0526 00:57:16.667434 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.946046 (* 1 = 0.946046 loss)
I0526 00:57:17.690956 15394 main.cpp:354] Iteration 5500, loss = 0.682822
I0526 00:57:17.691025 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.682822 (* 1 = 0.682822 loss)
I0526 00:57:17.691042 15394 sgd_solver.cpp:43] Iteration 5500, lr = 0.02
I0526 00:57:28.706470 15394 main.cpp:354] Iteration 5510, loss = 0.653585
I0526 00:57:28.706533 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.653585 (* 1 = 0.653585 loss)
I0526 00:57:28.706544 15394 sgd_solver.cpp:43] Iteration 5510, lr = 0.02
I0526 00:57:39.549690 15394 main.cpp:354] Iteration 5520, loss = 0.793505
I0526 00:57:39.549760 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.793506 (* 1 = 0.793506 loss)
I0526 00:57:39.549772 15394 sgd_solver.cpp:43] Iteration 5520, lr = 0.02
I0526 00:57:50.706045 15394 main.cpp:354] Iteration 5530, loss = 0.636635
I0526 00:57:50.706120 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.636635 (* 1 = 0.636635 loss)
I0526 00:57:50.706130 15394 sgd_solver.cpp:43] Iteration 5530, lr = 0.02
I0526 00:58:02.582511 15394 main.cpp:354] Iteration 5540, loss = 0.703359
I0526 00:58:02.582587 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.703359 (* 1 = 0.703359 loss)
I0526 00:58:02.582597 15394 sgd_solver.cpp:43] Iteration 5540, lr = 0.02
I0526 00:58:12.826419 15394 main.cpp:354] Iteration 5550, loss = 0.996594
I0526 00:58:12.826483 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.996594 (* 1 = 0.996594 loss)
I0526 00:58:12.826493 15394 sgd_solver.cpp:43] Iteration 5550, lr = 0.02
I0526 00:58:23.536850 15394 main.cpp:354] Iteration 5560, loss = 0.817046
I0526 00:58:23.536916 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.817046 (* 1 = 0.817046 loss)
I0526 00:58:23.536927 15394 sgd_solver.cpp:43] Iteration 5560, lr = 0.02
I0526 00:58:34.134336 15394 main.cpp:354] Iteration 5570, loss = 0.748226
I0526 00:58:34.134413 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.748226 (* 1 = 0.748226 loss)
I0526 00:58:34.134424 15394 sgd_solver.cpp:43] Iteration 5570, lr = 0.02
I0526 00:58:45.249357 15394 main.cpp:354] Iteration 5580, loss = 0.690797
I0526 00:58:45.249430 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.690797 (* 1 = 0.690797 loss)
I0526 00:58:45.249441 15394 sgd_solver.cpp:43] Iteration 5580, lr = 0.02
I0526 00:58:56.249106 15394 main.cpp:354] Iteration 5590, loss = 0.750411
I0526 00:58:56.249171 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.750411 (* 1 = 0.750411 loss)
I0526 00:58:56.249181 15394 sgd_solver.cpp:43] Iteration 5590, lr = 0.02
I0526 00:59:06.882491 15394 main.cpp:465] Iteration 5600, Testing net (#0)
I0526 00:59:36.573012 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6797
I0526 00:59:36.573079 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.918025 (* 1 = 0.918025 loss)
I0526 00:59:37.858278 15394 main.cpp:354] Iteration 5600, loss = 0.509196
I0526 00:59:37.858345 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.509197 (* 1 = 0.509197 loss)
I0526 00:59:37.858366 15394 sgd_solver.cpp:43] Iteration 5600, lr = 0.02
I0526 00:59:48.401373 15394 main.cpp:354] Iteration 5610, loss = 0.846515
I0526 00:59:48.401453 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.846515 (* 1 = 0.846515 loss)
I0526 00:59:48.401464 15394 sgd_solver.cpp:43] Iteration 5610, lr = 0.02
I0526 01:00:00.285150 15394 main.cpp:354] Iteration 5620, loss = 0.496056
I0526 01:00:00.285219 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.496056 (* 1 = 0.496056 loss)
I0526 01:00:00.285230 15394 sgd_solver.cpp:43] Iteration 5620, lr = 0.02
I0526 01:00:11.526765 15394 main.cpp:354] Iteration 5630, loss = 0.574923
I0526 01:00:11.526837 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.574924 (* 1 = 0.574924 loss)
I0526 01:00:11.526849 15394 sgd_solver.cpp:43] Iteration 5630, lr = 0.02
I0526 01:00:22.355444 15394 main.cpp:354] Iteration 5640, loss = 0.63445
I0526 01:00:22.355525 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.63445 (* 1 = 0.63445 loss)
I0526 01:00:22.355535 15394 sgd_solver.cpp:43] Iteration 5640, lr = 0.02
I0526 01:00:34.272786 15394 main.cpp:354] Iteration 5650, loss = 0.526712
I0526 01:00:34.272864 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.526712 (* 1 = 0.526712 loss)
I0526 01:00:34.272876 15394 sgd_solver.cpp:43] Iteration 5650, lr = 0.02
I0526 01:00:45.370760 15394 main.cpp:354] Iteration 5660, loss = 0.57731
I0526 01:00:45.370839 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.577311 (* 1 = 0.577311 loss)
I0526 01:00:45.370851 15394 sgd_solver.cpp:43] Iteration 5660, lr = 0.02
I0526 01:00:56.584019 15394 main.cpp:354] Iteration 5670, loss = 0.870125
I0526 01:00:56.584084 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.870125 (* 1 = 0.870125 loss)
I0526 01:00:56.584095 15394 sgd_solver.cpp:43] Iteration 5670, lr = 0.02
I0526 01:01:07.318243 15394 main.cpp:354] Iteration 5680, loss = 0.833801
I0526 01:01:07.318325 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.833801 (* 1 = 0.833801 loss)
I0526 01:01:07.318337 15394 sgd_solver.cpp:43] Iteration 5680, lr = 0.02
I0526 01:01:18.505187 15394 main.cpp:354] Iteration 5690, loss = 0.72791
I0526 01:01:18.505262 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.72791 (* 1 = 0.72791 loss)
I0526 01:01:18.505275 15394 sgd_solver.cpp:43] Iteration 5690, lr = 0.02
I0526 01:01:29.422543 15394 main.cpp:465] Iteration 5700, Testing net (#0)
I0526 01:01:59.402501 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7402
I0526 01:01:59.402571 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.74517 (* 1 = 0.74517 loss)
I0526 01:02:00.239815 15394 main.cpp:354] Iteration 5700, loss = 0.945082
I0526 01:02:00.239887 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.945082 (* 1 = 0.945082 loss)
I0526 01:02:00.239905 15394 sgd_solver.cpp:43] Iteration 5700, lr = 0.02
I0526 01:02:11.843380 15394 main.cpp:354] Iteration 5710, loss = 0.803987
I0526 01:02:11.843451 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.803987 (* 1 = 0.803987 loss)
I0526 01:02:11.843463 15394 sgd_solver.cpp:43] Iteration 5710, lr = 0.02
I0526 01:02:23.625931 15394 main.cpp:354] Iteration 5720, loss = 0.63555
I0526 01:02:23.626006 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.63555 (* 1 = 0.63555 loss)
I0526 01:02:23.626019 15394 sgd_solver.cpp:43] Iteration 5720, lr = 0.02
I0526 01:02:35.214735 15394 main.cpp:354] Iteration 5730, loss = 0.751506
I0526 01:02:35.214809 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.751506 (* 1 = 0.751506 loss)
I0526 01:02:35.214821 15394 sgd_solver.cpp:43] Iteration 5730, lr = 0.02
I0526 01:02:46.568872 15394 main.cpp:354] Iteration 5740, loss = 0.652567
I0526 01:02:46.568953 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.652568 (* 1 = 0.652568 loss)
I0526 01:02:46.568974 15394 sgd_solver.cpp:43] Iteration 5740, lr = 0.02
I0526 01:02:57.981145 15394 main.cpp:354] Iteration 5750, loss = 0.614432
I0526 01:02:57.981220 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.614432 (* 1 = 0.614432 loss)
I0526 01:02:57.981231 15394 sgd_solver.cpp:43] Iteration 5750, lr = 0.02
I0526 01:03:09.714848 15394 main.cpp:354] Iteration 5760, loss = 0.85174
I0526 01:03:09.714932 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.85174 (* 1 = 0.85174 loss)
I0526 01:03:09.714944 15394 sgd_solver.cpp:43] Iteration 5760, lr = 0.02
I0526 01:03:21.145735 15394 main.cpp:354] Iteration 5770, loss = 0.689143
I0526 01:03:21.145805 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.689143 (* 1 = 0.689143 loss)
I0526 01:03:21.145817 15394 sgd_solver.cpp:43] Iteration 5770, lr = 0.02
I0526 01:03:31.646729 15394 main.cpp:354] Iteration 5780, loss = 0.657385
I0526 01:03:31.646803 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.657385 (* 1 = 0.657385 loss)
I0526 01:03:31.646813 15394 sgd_solver.cpp:43] Iteration 5780, lr = 0.02
I0526 01:03:42.845070 15394 main.cpp:354] Iteration 5790, loss = 0.44344
I0526 01:03:42.845139 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.44344 (* 1 = 0.44344 loss)
I0526 01:03:42.845150 15394 sgd_solver.cpp:43] Iteration 5790, lr = 0.02
I0526 01:03:53.379658 15394 main.cpp:465] Iteration 5800, Testing net (#0)
I0526 01:04:22.869601 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6652
I0526 01:04:22.869673 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.962795 (* 1 = 0.962795 loss)
I0526 01:04:23.717234 15394 main.cpp:354] Iteration 5800, loss = 0.714615
I0526 01:04:23.717310 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.714615 (* 1 = 0.714615 loss)
I0526 01:04:23.717326 15394 sgd_solver.cpp:43] Iteration 5800, lr = 0.02
I0526 01:04:35.029615 15394 main.cpp:354] Iteration 5810, loss = 0.76792
I0526 01:04:35.029707 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.76792 (* 1 = 0.76792 loss)
I0526 01:04:35.029718 15394 sgd_solver.cpp:43] Iteration 5810, lr = 0.02
I0526 01:04:46.678588 15394 main.cpp:354] Iteration 5820, loss = 0.60956
I0526 01:04:46.678659 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.60956 (* 1 = 0.60956 loss)
I0526 01:04:46.678670 15394 sgd_solver.cpp:43] Iteration 5820, lr = 0.02
I0526 01:04:58.093015 15394 main.cpp:354] Iteration 5830, loss = 0.695586
I0526 01:04:58.093088 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.695586 (* 1 = 0.695586 loss)
I0526 01:04:58.093099 15394 sgd_solver.cpp:43] Iteration 5830, lr = 0.02
I0526 01:05:08.530283 15394 main.cpp:354] Iteration 5840, loss = 0.443537
I0526 01:05:08.530377 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.443537 (* 1 = 0.443537 loss)
I0526 01:05:08.530390 15394 sgd_solver.cpp:43] Iteration 5840, lr = 0.02
I0526 01:05:19.927914 15394 main.cpp:354] Iteration 5850, loss = 0.63307
I0526 01:05:19.928005 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.63307 (* 1 = 0.63307 loss)
I0526 01:05:19.928017 15394 sgd_solver.cpp:43] Iteration 5850, lr = 0.02
I0526 01:05:31.271694 15394 main.cpp:354] Iteration 5860, loss = 0.478087
I0526 01:05:31.271762 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.478087 (* 1 = 0.478087 loss)
I0526 01:05:31.271773 15394 sgd_solver.cpp:43] Iteration 5860, lr = 0.02
I0526 01:05:42.625763 15394 main.cpp:354] Iteration 5870, loss = 0.580633
I0526 01:05:42.625830 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.580634 (* 1 = 0.580634 loss)
I0526 01:05:42.625841 15394 sgd_solver.cpp:43] Iteration 5870, lr = 0.02
I0526 01:05:54.020802 15394 main.cpp:354] Iteration 5880, loss = 0.512474
I0526 01:05:54.020870 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.512474 (* 1 = 0.512474 loss)
I0526 01:05:54.020880 15394 sgd_solver.cpp:43] Iteration 5880, lr = 0.02
I0526 01:06:04.633610 15394 main.cpp:354] Iteration 5890, loss = 0.536568
I0526 01:06:04.633687 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.536568 (* 1 = 0.536568 loss)
I0526 01:06:04.633697 15394 sgd_solver.cpp:43] Iteration 5890, lr = 0.02
I0526 01:06:15.207535 15394 main.cpp:465] Iteration 5900, Testing net (#0)
I0526 01:06:45.020155 15394 main.cpp:532]     Test net output #0: Accuracy = 0.645
I0526 01:06:45.020223 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.11046 (* 1 = 1.11046 loss)
I0526 01:06:46.078287 15394 main.cpp:354] Iteration 5900, loss = 0.683197
I0526 01:06:46.078368 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.683197 (* 1 = 0.683197 loss)
I0526 01:06:46.078385 15394 sgd_solver.cpp:43] Iteration 5900, lr = 0.02
I0526 01:06:57.076618 15394 main.cpp:354] Iteration 5910, loss = 0.540094
I0526 01:06:57.076683 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.540094 (* 1 = 0.540094 loss)
I0526 01:06:57.076694 15394 sgd_solver.cpp:43] Iteration 5910, lr = 0.02
I0526 01:07:07.555491 15394 main.cpp:354] Iteration 5920, loss = 0.725037
I0526 01:07:07.555562 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.725037 (* 1 = 0.725037 loss)
I0526 01:07:07.555572 15394 sgd_solver.cpp:43] Iteration 5920, lr = 0.02
I0526 01:07:19.161015 15394 main.cpp:354] Iteration 5930, loss = 0.573979
I0526 01:07:19.161092 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.573979 (* 1 = 0.573979 loss)
I0526 01:07:19.161101 15394 sgd_solver.cpp:43] Iteration 5930, lr = 0.02
I0526 01:07:30.435770 15394 main.cpp:354] Iteration 5940, loss = 0.700728
I0526 01:07:30.435839 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.700728 (* 1 = 0.700728 loss)
I0526 01:07:30.435850 15394 sgd_solver.cpp:43] Iteration 5940, lr = 0.02
I0526 01:07:42.030270 15394 main.cpp:354] Iteration 5950, loss = 0.696709
I0526 01:07:42.030334 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.696709 (* 1 = 0.696709 loss)
I0526 01:07:42.030345 15394 sgd_solver.cpp:43] Iteration 5950, lr = 0.02
I0526 01:07:53.669584 15394 main.cpp:354] Iteration 5960, loss = 0.573596
I0526 01:07:53.669659 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.573596 (* 1 = 0.573596 loss)
I0526 01:07:53.669670 15394 sgd_solver.cpp:43] Iteration 5960, lr = 0.02
I0526 01:08:04.739168 15394 main.cpp:354] Iteration 5970, loss = 0.752182
I0526 01:08:04.739238 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.752182 (* 1 = 0.752182 loss)
I0526 01:08:04.739249 15394 sgd_solver.cpp:43] Iteration 5970, lr = 0.02
I0526 01:08:16.091114 15394 main.cpp:354] Iteration 5980, loss = 0.415726
I0526 01:08:16.091184 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.415726 (* 1 = 0.415726 loss)
I0526 01:08:16.091194 15394 sgd_solver.cpp:43] Iteration 5980, lr = 0.02
I0526 01:08:26.656211 15394 main.cpp:354] Iteration 5990, loss = 0.666634
I0526 01:08:26.656276 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.666634 (* 1 = 0.666634 loss)
I0526 01:08:26.656287 15394 sgd_solver.cpp:43] Iteration 5990, lr = 0.02
I0526 01:08:36.741545 15394 main.cpp:465] Iteration 6000, Testing net (#0)
I0526 01:09:06.852149 15394 main.cpp:532]     Test net output #0: Accuracy = 0.5779
I0526 01:09:06.852221 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.249 (* 1 = 1.249 loss)
I0526 01:09:08.066493 15394 main.cpp:354] Iteration 6000, loss = 0.624592
I0526 01:09:08.066570 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.624593 (* 1 = 0.624593 loss)
I0526 01:09:08.066589 15394 sgd_solver.cpp:43] Iteration 6000, lr = 0.02
I0526 01:09:18.620334 15394 main.cpp:354] Iteration 6010, loss = 0.500809
I0526 01:09:18.620410 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.500809 (* 1 = 0.500809 loss)
I0526 01:09:18.620422 15394 sgd_solver.cpp:43] Iteration 6010, lr = 0.02
I0526 01:09:30.540473 15394 main.cpp:354] Iteration 6020, loss = 0.459608
I0526 01:09:30.540549 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.459608 (* 1 = 0.459608 loss)
I0526 01:09:30.540571 15394 sgd_solver.cpp:43] Iteration 6020, lr = 0.02
I0526 01:09:41.568801 15394 main.cpp:354] Iteration 6030, loss = 0.504384
I0526 01:09:41.568871 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.504384 (* 1 = 0.504384 loss)
I0526 01:09:41.568881 15394 sgd_solver.cpp:43] Iteration 6030, lr = 0.02
I0526 01:09:52.653795 15394 main.cpp:354] Iteration 6040, loss = 0.842343
I0526 01:09:52.653866 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.842343 (* 1 = 0.842343 loss)
I0526 01:09:52.653877 15394 sgd_solver.cpp:43] Iteration 6040, lr = 0.02
I0526 01:10:04.194974 15394 main.cpp:354] Iteration 6050, loss = 0.685296
I0526 01:10:04.195046 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.685296 (* 1 = 0.685296 loss)
I0526 01:10:04.195057 15394 sgd_solver.cpp:43] Iteration 6050, lr = 0.02
I0526 01:10:16.171892 15394 main.cpp:354] Iteration 6060, loss = 0.676601
I0526 01:10:16.171963 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.676601 (* 1 = 0.676601 loss)
I0526 01:10:16.171973 15394 sgd_solver.cpp:43] Iteration 6060, lr = 0.02
I0526 01:10:27.717931 15394 main.cpp:354] Iteration 6070, loss = 0.831365
I0526 01:10:27.718000 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.831365 (* 1 = 0.831365 loss)
I0526 01:10:27.718010 15394 sgd_solver.cpp:43] Iteration 6070, lr = 0.02
I0526 01:10:39.278208 15394 main.cpp:354] Iteration 6080, loss = 0.554398
I0526 01:10:39.278278 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.554398 (* 1 = 0.554398 loss)
I0526 01:10:39.278290 15394 sgd_solver.cpp:43] Iteration 6080, lr = 0.02
I0526 01:10:49.170825 15394 main.cpp:354] Iteration 6090, loss = 0.653157
I0526 01:10:49.170893 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.653157 (* 1 = 0.653157 loss)
I0526 01:10:49.170904 15394 sgd_solver.cpp:43] Iteration 6090, lr = 0.02
I0526 01:10:58.919000 15394 main.cpp:465] Iteration 6100, Testing net (#0)
I0526 01:11:29.178755 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6861
I0526 01:11:29.178825 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.930415 (* 1 = 0.930415 loss)
I0526 01:11:30.017309 15394 main.cpp:354] Iteration 6100, loss = 0.733815
I0526 01:11:30.017380 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.733816 (* 1 = 0.733816 loss)
I0526 01:11:30.017395 15394 sgd_solver.cpp:43] Iteration 6100, lr = 0.02
I0526 01:11:40.468456 15394 main.cpp:354] Iteration 6110, loss = 0.778188
I0526 01:11:40.468523 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.778188 (* 1 = 0.778188 loss)
I0526 01:11:40.468534 15394 sgd_solver.cpp:43] Iteration 6110, lr = 0.02
I0526 01:11:51.516505 15394 main.cpp:354] Iteration 6120, loss = 0.67141
I0526 01:11:51.516582 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.67141 (* 1 = 0.67141 loss)
I0526 01:11:51.516593 15394 sgd_solver.cpp:43] Iteration 6120, lr = 0.02
I0526 01:12:03.547010 15394 main.cpp:354] Iteration 6130, loss = 0.621174
I0526 01:12:03.547091 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.621174 (* 1 = 0.621174 loss)
I0526 01:12:03.547103 15394 sgd_solver.cpp:43] Iteration 6130, lr = 0.02
I0526 01:12:14.718821 15394 main.cpp:354] Iteration 6140, loss = 1.00565
I0526 01:12:14.718899 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.00565 (* 1 = 1.00565 loss)
I0526 01:12:14.718916 15394 sgd_solver.cpp:43] Iteration 6140, lr = 0.02
I0526 01:12:25.876463 15394 main.cpp:354] Iteration 6150, loss = 0.744099
I0526 01:12:25.876528 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.744099 (* 1 = 0.744099 loss)
I0526 01:12:25.876538 15394 sgd_solver.cpp:43] Iteration 6150, lr = 0.02
I0526 01:12:37.702538 15394 main.cpp:354] Iteration 6160, loss = 0.521187
I0526 01:12:37.702616 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.521187 (* 1 = 0.521187 loss)
I0526 01:12:37.702628 15394 sgd_solver.cpp:43] Iteration 6160, lr = 0.02
I0526 01:12:48.544376 15394 main.cpp:354] Iteration 6170, loss = 0.921814
I0526 01:12:48.544448 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.921814 (* 1 = 0.921814 loss)
I0526 01:12:48.544461 15394 sgd_solver.cpp:43] Iteration 6170, lr = 0.02
I0526 01:13:00.105954 15394 main.cpp:354] Iteration 6180, loss = 0.643694
I0526 01:13:00.106025 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.643694 (* 1 = 0.643694 loss)
I0526 01:13:00.106040 15394 sgd_solver.cpp:43] Iteration 6180, lr = 0.02
I0526 01:13:11.366446 15394 main.cpp:354] Iteration 6190, loss = 0.448972
I0526 01:13:11.366514 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.448972 (* 1 = 0.448972 loss)
I0526 01:13:11.366525 15394 sgd_solver.cpp:43] Iteration 6190, lr = 0.02
I0526 01:13:21.068127 15394 main.cpp:465] Iteration 6200, Testing net (#0)
I0526 01:13:51.562670 15394 main.cpp:532]     Test net output #0: Accuracy = 0.733
I0526 01:13:51.562736 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.796515 (* 1 = 0.796515 loss)
I0526 01:13:52.535627 15394 main.cpp:354] Iteration 6200, loss = 0.597837
I0526 01:13:52.535701 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.597837 (* 1 = 0.597837 loss)
I0526 01:13:52.535718 15394 sgd_solver.cpp:43] Iteration 6200, lr = 0.02
I0526 01:14:03.447485 15394 main.cpp:354] Iteration 6210, loss = 0.667907
I0526 01:14:03.447558 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.667907 (* 1 = 0.667907 loss)
I0526 01:14:03.447569 15394 sgd_solver.cpp:43] Iteration 6210, lr = 0.02
I0526 01:14:14.502897 15394 main.cpp:354] Iteration 6220, loss = 0.688736
I0526 01:14:14.502981 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.688736 (* 1 = 0.688736 loss)
I0526 01:14:14.502996 15394 sgd_solver.cpp:43] Iteration 6220, lr = 0.02
I0526 01:14:26.451913 15394 main.cpp:354] Iteration 6230, loss = 0.559361
I0526 01:14:26.451978 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.559361 (* 1 = 0.559361 loss)
I0526 01:14:26.451989 15394 sgd_solver.cpp:43] Iteration 6230, lr = 0.02
I0526 01:14:37.277731 15394 main.cpp:354] Iteration 6240, loss = 0.683762
I0526 01:14:37.277804 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.683762 (* 1 = 0.683762 loss)
I0526 01:14:37.277817 15394 sgd_solver.cpp:43] Iteration 6240, lr = 0.02
I0526 01:14:48.040405 15394 main.cpp:354] Iteration 6250, loss = 0.531598
I0526 01:14:48.040478 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.531598 (* 1 = 0.531598 loss)
I0526 01:14:48.040489 15394 sgd_solver.cpp:43] Iteration 6250, lr = 0.02
I0526 01:14:59.163285 15394 main.cpp:354] Iteration 6260, loss = 0.703161
I0526 01:14:59.163362 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.703161 (* 1 = 0.703161 loss)
I0526 01:14:59.163378 15394 sgd_solver.cpp:43] Iteration 6260, lr = 0.02
I0526 01:15:10.087901 15394 main.cpp:354] Iteration 6270, loss = 0.859768
I0526 01:15:10.087966 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.859768 (* 1 = 0.859768 loss)
I0526 01:15:10.087976 15394 sgd_solver.cpp:43] Iteration 6270, lr = 0.02
I0526 01:15:21.158005 15394 main.cpp:354] Iteration 6280, loss = 0.717171
I0526 01:15:21.158074 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.717171 (* 1 = 0.717171 loss)
I0526 01:15:21.158085 15394 sgd_solver.cpp:43] Iteration 6280, lr = 0.02
I0526 01:15:32.502394 15394 main.cpp:354] Iteration 6290, loss = 0.689936
I0526 01:15:32.502465 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.689936 (* 1 = 0.689936 loss)
I0526 01:15:32.502476 15394 sgd_solver.cpp:43] Iteration 6290, lr = 0.02
I0526 01:15:42.429860 15394 main.cpp:465] Iteration 6300, Testing net (#0)
I0526 01:16:12.820353 15394 main.cpp:532]     Test net output #0: Accuracy = 0.762
I0526 01:16:12.820412 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.699543 (* 1 = 0.699543 loss)
I0526 01:16:13.904124 15394 main.cpp:354] Iteration 6300, loss = 0.632414
I0526 01:16:13.904196 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.632414 (* 1 = 0.632414 loss)
I0526 01:16:13.904227 15394 sgd_solver.cpp:43] Iteration 6300, lr = 0.02
I0526 01:16:24.134549 15394 main.cpp:354] Iteration 6310, loss = 0.506102
I0526 01:16:24.134618 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.506103 (* 1 = 0.506103 loss)
I0526 01:16:24.134629 15394 sgd_solver.cpp:43] Iteration 6310, lr = 0.02
I0526 01:16:35.193150 15394 main.cpp:354] Iteration 6320, loss = 0.930278
I0526 01:16:35.193224 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.930278 (* 1 = 0.930278 loss)
I0526 01:16:35.193236 15394 sgd_solver.cpp:43] Iteration 6320, lr = 0.02
I0526 01:16:46.914402 15394 main.cpp:354] Iteration 6330, loss = 0.482125
I0526 01:16:46.914486 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.482125 (* 1 = 0.482125 loss)
I0526 01:16:46.914499 15394 sgd_solver.cpp:43] Iteration 6330, lr = 0.02
I0526 01:16:57.978345 15394 main.cpp:354] Iteration 6340, loss = 0.460386
I0526 01:16:57.978415 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.460386 (* 1 = 0.460386 loss)
I0526 01:16:57.978426 15394 sgd_solver.cpp:43] Iteration 6340, lr = 0.02
I0526 01:17:09.103425 15394 main.cpp:354] Iteration 6350, loss = 1.05794
I0526 01:17:09.103489 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.05794 (* 1 = 1.05794 loss)
I0526 01:17:09.103500 15394 sgd_solver.cpp:43] Iteration 6350, lr = 0.02
I0526 01:17:20.111760 15394 main.cpp:354] Iteration 6360, loss = 0.63293
I0526 01:17:20.111834 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.63293 (* 1 = 0.63293 loss)
I0526 01:17:20.111845 15394 sgd_solver.cpp:43] Iteration 6360, lr = 0.02
I0526 01:17:31.434865 15394 main.cpp:354] Iteration 6370, loss = 0.444642
I0526 01:17:31.434963 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.444642 (* 1 = 0.444642 loss)
I0526 01:17:31.434976 15394 sgd_solver.cpp:43] Iteration 6370, lr = 0.02
I0526 01:17:42.847834 15394 main.cpp:354] Iteration 6380, loss = 0.479513
I0526 01:17:42.847906 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.479513 (* 1 = 0.479513 loss)
I0526 01:17:42.847918 15394 sgd_solver.cpp:43] Iteration 6380, lr = 0.02
I0526 01:17:54.170264 15394 main.cpp:354] Iteration 6390, loss = 0.760759
I0526 01:17:54.170336 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.76076 (* 1 = 0.76076 loss)
I0526 01:17:54.170347 15394 sgd_solver.cpp:43] Iteration 6390, lr = 0.02
I0526 01:18:02.728991 15394 main.cpp:465] Iteration 6400, Testing net (#0)
I0526 01:18:32.931989 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7215
I0526 01:18:32.932061 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.788856 (* 1 = 0.788856 loss)
I0526 01:18:34.031581 15394 main.cpp:354] Iteration 6400, loss = 0.517995
I0526 01:18:34.031651 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.517995 (* 1 = 0.517995 loss)
I0526 01:18:34.031666 15394 sgd_solver.cpp:43] Iteration 6400, lr = 0.02
I0526 01:18:45.251750 15394 main.cpp:354] Iteration 6410, loss = 0.518528
I0526 01:18:45.251816 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.518529 (* 1 = 0.518529 loss)
I0526 01:18:45.251826 15394 sgd_solver.cpp:43] Iteration 6410, lr = 0.02
I0526 01:18:55.900962 15394 main.cpp:354] Iteration 6420, loss = 0.814093
I0526 01:18:55.901031 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.814093 (* 1 = 0.814093 loss)
I0526 01:18:55.901041 15394 sgd_solver.cpp:43] Iteration 6420, lr = 0.02
I0526 01:19:07.375311 15394 main.cpp:354] Iteration 6430, loss = 0.613484
I0526 01:19:07.375387 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.613484 (* 1 = 0.613484 loss)
I0526 01:19:07.375399 15394 sgd_solver.cpp:43] Iteration 6430, lr = 0.02
I0526 01:19:18.335124 15394 main.cpp:354] Iteration 6440, loss = 0.667754
I0526 01:19:18.335189 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.667754 (* 1 = 0.667754 loss)
I0526 01:19:18.335201 15394 sgd_solver.cpp:43] Iteration 6440, lr = 0.02
I0526 01:19:30.198364 15394 main.cpp:354] Iteration 6450, loss = 0.740634
I0526 01:19:30.198431 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.740635 (* 1 = 0.740635 loss)
I0526 01:19:30.198442 15394 sgd_solver.cpp:43] Iteration 6450, lr = 0.02
I0526 01:19:40.590932 15394 main.cpp:354] Iteration 6460, loss = 0.68004
I0526 01:19:40.591003 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.68004 (* 1 = 0.68004 loss)
I0526 01:19:40.591015 15394 sgd_solver.cpp:43] Iteration 6460, lr = 0.02
I0526 01:19:51.346988 15394 main.cpp:354] Iteration 6470, loss = 0.425167
I0526 01:19:51.347064 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.425167 (* 1 = 0.425167 loss)
I0526 01:19:51.347079 15394 sgd_solver.cpp:43] Iteration 6470, lr = 0.02
I0526 01:20:02.981246 15394 main.cpp:354] Iteration 6480, loss = 0.486773
I0526 01:20:02.981310 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.486773 (* 1 = 0.486773 loss)
I0526 01:20:02.981322 15394 sgd_solver.cpp:43] Iteration 6480, lr = 0.02
I0526 01:20:14.344527 15394 main.cpp:354] Iteration 6490, loss = 0.834253
I0526 01:20:14.344605 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.834253 (* 1 = 0.834253 loss)
I0526 01:20:14.344616 15394 sgd_solver.cpp:43] Iteration 6490, lr = 0.02
I0526 01:20:24.456501 15394 main.cpp:465] Iteration 6500, Testing net (#0)
I0526 01:20:54.529901 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6173
I0526 01:20:54.529968 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.12835 (* 1 = 1.12835 loss)
I0526 01:20:55.253265 15394 main.cpp:354] Iteration 6500, loss = 0.786503
I0526 01:20:55.253329 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.786504 (* 1 = 0.786504 loss)
I0526 01:20:55.253345 15394 sgd_solver.cpp:43] Iteration 6500, lr = 0.02
I0526 01:21:07.241760 15394 main.cpp:354] Iteration 6510, loss = 0.559477
I0526 01:21:07.241829 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.559477 (* 1 = 0.559477 loss)
I0526 01:21:07.241840 15394 sgd_solver.cpp:43] Iteration 6510, lr = 0.02
I0526 01:21:17.507508 15394 main.cpp:354] Iteration 6520, loss = 0.654242
I0526 01:21:17.507572 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.654243 (* 1 = 0.654243 loss)
I0526 01:21:17.507583 15394 sgd_solver.cpp:43] Iteration 6520, lr = 0.02
I0526 01:21:28.556432 15394 main.cpp:354] Iteration 6530, loss = 0.63857
I0526 01:21:28.556510 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.63857 (* 1 = 0.63857 loss)
I0526 01:21:28.556520 15394 sgd_solver.cpp:43] Iteration 6530, lr = 0.02
I0526 01:21:40.477113 15394 main.cpp:354] Iteration 6540, loss = 0.564265
I0526 01:21:40.477190 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.564265 (* 1 = 0.564265 loss)
I0526 01:21:40.477203 15394 sgd_solver.cpp:43] Iteration 6540, lr = 0.02
I0526 01:21:51.497623 15394 main.cpp:354] Iteration 6550, loss = 0.6488
I0526 01:21:51.497705 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.648801 (* 1 = 0.648801 loss)
I0526 01:21:51.497720 15394 sgd_solver.cpp:43] Iteration 6550, lr = 0.02
I0526 01:22:02.867768 15394 main.cpp:354] Iteration 6560, loss = 0.903577
I0526 01:22:02.867835 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.903577 (* 1 = 0.903577 loss)
I0526 01:22:02.867846 15394 sgd_solver.cpp:43] Iteration 6560, lr = 0.02
I0526 01:22:14.080968 15394 main.cpp:354] Iteration 6570, loss = 0.680575
I0526 01:22:14.081043 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.680575 (* 1 = 0.680575 loss)
I0526 01:22:14.081054 15394 sgd_solver.cpp:43] Iteration 6570, lr = 0.02
I0526 01:22:25.281955 15394 main.cpp:354] Iteration 6580, loss = 0.44196
I0526 01:22:25.282024 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.44196 (* 1 = 0.44196 loss)
I0526 01:22:25.282037 15394 sgd_solver.cpp:43] Iteration 6580, lr = 0.02
I0526 01:22:36.885095 15394 main.cpp:354] Iteration 6590, loss = 0.465712
I0526 01:22:36.885167 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.465712 (* 1 = 0.465712 loss)
I0526 01:22:36.885195 15394 sgd_solver.cpp:43] Iteration 6590, lr = 0.02
I0526 01:22:47.532817 15394 main.cpp:465] Iteration 6600, Testing net (#0)
I0526 01:23:16.822710 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6805
I0526 01:23:16.822774 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.926435 (* 1 = 0.926435 loss)
I0526 01:23:17.859545 15394 main.cpp:354] Iteration 6600, loss = 0.679065
I0526 01:23:17.859616 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.679065 (* 1 = 0.679065 loss)
I0526 01:23:17.859633 15394 sgd_solver.cpp:43] Iteration 6600, lr = 0.02
I0526 01:23:29.389344 15394 main.cpp:354] Iteration 6610, loss = 0.454588
I0526 01:23:29.389415 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.454588 (* 1 = 0.454588 loss)
I0526 01:23:29.389425 15394 sgd_solver.cpp:43] Iteration 6610, lr = 0.02
I0526 01:23:40.519305 15394 main.cpp:354] Iteration 6620, loss = 0.627957
I0526 01:23:40.519387 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.627957 (* 1 = 0.627957 loss)
I0526 01:23:40.519397 15394 sgd_solver.cpp:43] Iteration 6620, lr = 0.02
I0526 01:23:51.423084 15394 main.cpp:354] Iteration 6630, loss = 0.500809
I0526 01:23:51.423157 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.500809 (* 1 = 0.500809 loss)
I0526 01:23:51.423171 15394 sgd_solver.cpp:43] Iteration 6630, lr = 0.02
I0526 01:24:02.782038 15394 main.cpp:354] Iteration 6640, loss = 0.636532
I0526 01:24:02.782104 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.636532 (* 1 = 0.636532 loss)
I0526 01:24:02.782114 15394 sgd_solver.cpp:43] Iteration 6640, lr = 0.02
I0526 01:24:14.206856 15394 main.cpp:354] Iteration 6650, loss = 0.502063
I0526 01:24:14.206926 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.502063 (* 1 = 0.502063 loss)
I0526 01:24:14.206938 15394 sgd_solver.cpp:43] Iteration 6650, lr = 0.02
I0526 01:24:26.090822 15394 main.cpp:354] Iteration 6660, loss = 0.366213
I0526 01:24:26.090895 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.366213 (* 1 = 0.366213 loss)
I0526 01:24:26.090906 15394 sgd_solver.cpp:43] Iteration 6660, lr = 0.02
I0526 01:24:36.634775 15394 main.cpp:354] Iteration 6670, loss = 0.643582
I0526 01:24:36.634851 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.643582 (* 1 = 0.643582 loss)
I0526 01:24:36.634865 15394 sgd_solver.cpp:43] Iteration 6670, lr = 0.02
I0526 01:24:48.691900 15394 main.cpp:354] Iteration 6680, loss = 0.889851
I0526 01:24:48.691964 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.889851 (* 1 = 0.889851 loss)
I0526 01:24:48.691975 15394 sgd_solver.cpp:43] Iteration 6680, lr = 0.02
I0526 01:24:59.501616 15394 main.cpp:354] Iteration 6690, loss = 0.560724
I0526 01:24:59.501687 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.560725 (* 1 = 0.560725 loss)
I0526 01:24:59.501698 15394 sgd_solver.cpp:43] Iteration 6690, lr = 0.02
I0526 01:25:09.829933 15394 main.cpp:465] Iteration 6700, Testing net (#0)
I0526 01:25:39.170697 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6178
I0526 01:25:39.170765 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.10825 (* 1 = 1.10825 loss)
I0526 01:25:40.358234 15394 main.cpp:354] Iteration 6700, loss = 0.563125
I0526 01:25:40.358306 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.563125 (* 1 = 0.563125 loss)
I0526 01:25:40.358320 15394 sgd_solver.cpp:43] Iteration 6700, lr = 0.02
I0526 01:25:51.251044 15394 main.cpp:354] Iteration 6710, loss = 0.56748
I0526 01:25:51.251121 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.56748 (* 1 = 0.56748 loss)
I0526 01:25:51.251134 15394 sgd_solver.cpp:43] Iteration 6710, lr = 0.02
I0526 01:26:02.348728 15394 main.cpp:354] Iteration 6720, loss = 0.57088
I0526 01:26:02.348795 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.57088 (* 1 = 0.57088 loss)
I0526 01:26:02.348806 15394 sgd_solver.cpp:43] Iteration 6720, lr = 0.02
I0526 01:26:13.528998 15394 main.cpp:354] Iteration 6730, loss = 0.492359
I0526 01:26:13.529063 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.492359 (* 1 = 0.492359 loss)
I0526 01:26:13.529073 15394 sgd_solver.cpp:43] Iteration 6730, lr = 0.02
I0526 01:26:24.634408 15394 main.cpp:354] Iteration 6740, loss = 0.515758
I0526 01:26:24.634488 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.515758 (* 1 = 0.515758 loss)
I0526 01:26:24.634500 15394 sgd_solver.cpp:43] Iteration 6740, lr = 0.02
I0526 01:26:35.366535 15394 main.cpp:354] Iteration 6750, loss = 0.590928
I0526 01:26:35.366600 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.590928 (* 1 = 0.590928 loss)
I0526 01:26:35.366611 15394 sgd_solver.cpp:43] Iteration 6750, lr = 0.02
I0526 01:26:46.956589 15394 main.cpp:354] Iteration 6760, loss = 0.512892
I0526 01:26:46.956660 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.512892 (* 1 = 0.512892 loss)
I0526 01:26:46.956670 15394 sgd_solver.cpp:43] Iteration 6760, lr = 0.02
I0526 01:26:58.279531 15394 main.cpp:354] Iteration 6770, loss = 0.686448
I0526 01:26:58.279613 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.686448 (* 1 = 0.686448 loss)
I0526 01:26:58.279623 15394 sgd_solver.cpp:43] Iteration 6770, lr = 0.02
I0526 01:27:09.423310 15394 main.cpp:354] Iteration 6780, loss = 0.606806
I0526 01:27:09.423391 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.606806 (* 1 = 0.606806 loss)
I0526 01:27:09.423403 15394 sgd_solver.cpp:43] Iteration 6780, lr = 0.02
I0526 01:27:20.518661 15394 main.cpp:354] Iteration 6790, loss = 0.72451
I0526 01:27:20.518729 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.72451 (* 1 = 0.72451 loss)
I0526 01:27:20.518740 15394 sgd_solver.cpp:43] Iteration 6790, lr = 0.02
I0526 01:27:30.572005 15394 main.cpp:465] Iteration 6800, Testing net (#0)
I0526 01:28:00.572305 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6679
I0526 01:28:00.572373 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.925903 (* 1 = 0.925903 loss)
I0526 01:28:01.774018 15394 main.cpp:354] Iteration 6800, loss = 0.666362
I0526 01:28:01.774087 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.666362 (* 1 = 0.666362 loss)
I0526 01:28:01.774103 15394 sgd_solver.cpp:43] Iteration 6800, lr = 0.02
I0526 01:28:13.173751 15394 main.cpp:354] Iteration 6810, loss = 0.75982
I0526 01:28:13.173856 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.75982 (* 1 = 0.75982 loss)
I0526 01:28:13.173871 15394 sgd_solver.cpp:43] Iteration 6810, lr = 0.02
I0526 01:28:24.450486 15394 main.cpp:354] Iteration 6820, loss = 0.662936
I0526 01:28:24.450567 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.662936 (* 1 = 0.662936 loss)
I0526 01:28:24.450579 15394 sgd_solver.cpp:43] Iteration 6820, lr = 0.02
I0526 01:28:34.542475 15394 main.cpp:354] Iteration 6830, loss = 0.651042
I0526 01:28:34.542547 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.651042 (* 1 = 0.651042 loss)
I0526 01:28:34.542558 15394 sgd_solver.cpp:43] Iteration 6830, lr = 0.02
I0526 01:28:45.972532 15394 main.cpp:354] Iteration 6840, loss = 0.541764
I0526 01:28:45.972605 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.541765 (* 1 = 0.541765 loss)
I0526 01:28:45.972616 15394 sgd_solver.cpp:43] Iteration 6840, lr = 0.02
I0526 01:28:57.554178 15394 main.cpp:354] Iteration 6850, loss = 0.6266
I0526 01:28:57.554245 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.6266 (* 1 = 0.6266 loss)
I0526 01:28:57.554256 15394 sgd_solver.cpp:43] Iteration 6850, lr = 0.02
I0526 01:29:07.836946 15394 main.cpp:354] Iteration 6860, loss = 0.64069
I0526 01:29:07.837014 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.640691 (* 1 = 0.640691 loss)
I0526 01:29:07.837025 15394 sgd_solver.cpp:43] Iteration 6860, lr = 0.02
I0526 01:29:18.690629 15394 main.cpp:354] Iteration 6870, loss = 0.431917
I0526 01:29:18.690692 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.431918 (* 1 = 0.431918 loss)
I0526 01:29:18.690708 15394 sgd_solver.cpp:43] Iteration 6870, lr = 0.02
I0526 01:29:28.987049 15394 main.cpp:354] Iteration 6880, loss = 0.754721
I0526 01:29:28.987121 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.754721 (* 1 = 0.754721 loss)
I0526 01:29:28.987131 15394 sgd_solver.cpp:43] Iteration 6880, lr = 0.02
I0526 01:29:40.280508 15394 main.cpp:354] Iteration 6890, loss = 0.678336
I0526 01:29:40.280586 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.678336 (* 1 = 0.678336 loss)
I0526 01:29:40.280596 15394 sgd_solver.cpp:43] Iteration 6890, lr = 0.02
I0526 01:29:50.943277 15394 main.cpp:465] Iteration 6900, Testing net (#0)
I0526 01:30:20.580623 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6157
I0526 01:30:20.580685 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.12055 (* 1 = 1.12055 loss)
I0526 01:30:21.629721 15394 main.cpp:354] Iteration 6900, loss = 0.611319
I0526 01:30:21.629801 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.61132 (* 1 = 0.61132 loss)
I0526 01:30:21.629817 15394 sgd_solver.cpp:43] Iteration 6900, lr = 0.02
I0526 01:30:32.953873 15394 main.cpp:354] Iteration 6910, loss = 0.417416
I0526 01:30:32.953940 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.417417 (* 1 = 0.417417 loss)
I0526 01:30:32.953951 15394 sgd_solver.cpp:43] Iteration 6910, lr = 0.02
I0526 01:30:44.404748 15394 main.cpp:354] Iteration 6920, loss = 0.611711
I0526 01:30:44.404816 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.611711 (* 1 = 0.611711 loss)
I0526 01:30:44.404827 15394 sgd_solver.cpp:43] Iteration 6920, lr = 0.02
I0526 01:30:55.871697 15394 main.cpp:354] Iteration 6930, loss = 0.622318
I0526 01:30:55.871765 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.622319 (* 1 = 0.622319 loss)
I0526 01:30:55.871775 15394 sgd_solver.cpp:43] Iteration 6930, lr = 0.02
I0526 01:31:07.095680 15394 main.cpp:354] Iteration 6940, loss = 0.495093
I0526 01:31:07.095754 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.495093 (* 1 = 0.495093 loss)
I0526 01:31:07.095767 15394 sgd_solver.cpp:43] Iteration 6940, lr = 0.02
I0526 01:31:18.380295 15394 main.cpp:354] Iteration 6950, loss = 0.572767
I0526 01:31:18.380359 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.572767 (* 1 = 0.572767 loss)
I0526 01:31:18.380368 15394 sgd_solver.cpp:43] Iteration 6950, lr = 0.02
I0526 01:31:29.385764 15394 main.cpp:354] Iteration 6960, loss = 0.831097
I0526 01:31:29.385835 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.831097 (* 1 = 0.831097 loss)
I0526 01:31:29.385846 15394 sgd_solver.cpp:43] Iteration 6960, lr = 0.02
I0526 01:31:41.668817 15394 main.cpp:354] Iteration 6970, loss = 0.487596
I0526 01:31:41.668892 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.487596 (* 1 = 0.487596 loss)
I0526 01:31:41.668903 15394 sgd_solver.cpp:43] Iteration 6970, lr = 0.02
I0526 01:31:52.773918 15394 main.cpp:354] Iteration 6980, loss = 0.622519
I0526 01:31:52.773984 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.62252 (* 1 = 0.62252 loss)
I0526 01:31:52.773994 15394 sgd_solver.cpp:43] Iteration 6980, lr = 0.02
I0526 01:32:03.872951 15394 main.cpp:354] Iteration 6990, loss = 0.564797
I0526 01:32:03.873013 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.564797 (* 1 = 0.564797 loss)
I0526 01:32:03.873023 15394 sgd_solver.cpp:43] Iteration 6990, lr = 0.02
I0526 01:32:14.564375 15394 main.cpp:465] Iteration 7000, Testing net (#0)
I0526 01:32:44.436391 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7391
I0526 01:32:44.436458 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.73053 (* 1 = 0.73053 loss)
I0526 01:32:45.508363 15394 main.cpp:354] Iteration 7000, loss = 0.55628
I0526 01:32:45.508431 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.55628 (* 1 = 0.55628 loss)
I0526 01:32:45.508446 15394 sgd_solver.cpp:43] Iteration 7000, lr = 0.02
I0526 01:32:56.728724 15394 main.cpp:354] Iteration 7010, loss = 0.491412
I0526 01:32:56.728791 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.491413 (* 1 = 0.491413 loss)
I0526 01:32:56.728802 15394 sgd_solver.cpp:43] Iteration 7010, lr = 0.02
I0526 01:33:08.298960 15394 main.cpp:354] Iteration 7020, loss = 0.462478
I0526 01:33:08.299036 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.462478 (* 1 = 0.462478 loss)
I0526 01:33:08.299046 15394 sgd_solver.cpp:43] Iteration 7020, lr = 0.02
I0526 01:33:19.352820 15394 main.cpp:354] Iteration 7030, loss = 0.437742
I0526 01:33:19.352891 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.437742 (* 1 = 0.437742 loss)
I0526 01:33:19.352901 15394 sgd_solver.cpp:43] Iteration 7030, lr = 0.02
I0526 01:33:30.268504 15394 main.cpp:354] Iteration 7040, loss = 0.508805
I0526 01:33:30.268575 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.508805 (* 1 = 0.508805 loss)
I0526 01:33:30.268586 15394 sgd_solver.cpp:43] Iteration 7040, lr = 0.02
I0526 01:33:41.142504 15394 main.cpp:354] Iteration 7050, loss = 0.399151
I0526 01:33:41.142578 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.399151 (* 1 = 0.399151 loss)
I0526 01:33:41.142590 15394 sgd_solver.cpp:43] Iteration 7050, lr = 0.02
I0526 01:33:52.038288 15394 main.cpp:354] Iteration 7060, loss = 0.536811
I0526 01:33:52.038372 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.536811 (* 1 = 0.536811 loss)
I0526 01:33:52.038383 15394 sgd_solver.cpp:43] Iteration 7060, lr = 0.02
I0526 01:34:03.858145 15394 main.cpp:354] Iteration 7070, loss = 0.79587
I0526 01:34:03.858217 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.79587 (* 1 = 0.79587 loss)
I0526 01:34:03.858227 15394 sgd_solver.cpp:43] Iteration 7070, lr = 0.02
I0526 01:34:14.889973 15394 main.cpp:354] Iteration 7080, loss = 0.572287
I0526 01:34:14.890039 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.572287 (* 1 = 0.572287 loss)
I0526 01:34:14.890049 15394 sgd_solver.cpp:43] Iteration 7080, lr = 0.02
I0526 01:34:26.525620 15394 main.cpp:354] Iteration 7090, loss = 0.681431
I0526 01:34:26.525691 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.681431 (* 1 = 0.681431 loss)
I0526 01:34:26.525702 15394 sgd_solver.cpp:43] Iteration 7090, lr = 0.02
I0526 01:34:36.364229 15394 main.cpp:465] Iteration 7100, Testing net (#0)
I0526 01:35:06.351507 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6924
I0526 01:35:06.351577 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.846495 (* 1 = 0.846495 loss)
I0526 01:35:07.301353 15394 main.cpp:354] Iteration 7100, loss = 0.59533
I0526 01:35:07.301421 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.59533 (* 1 = 0.59533 loss)
I0526 01:35:07.301440 15394 sgd_solver.cpp:43] Iteration 7100, lr = 0.02
I0526 01:35:19.078598 15394 main.cpp:354] Iteration 7110, loss = 0.671103
I0526 01:35:19.078663 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.671103 (* 1 = 0.671103 loss)
I0526 01:35:19.078673 15394 sgd_solver.cpp:43] Iteration 7110, lr = 0.02
I0526 01:35:30.091126 15394 main.cpp:354] Iteration 7120, loss = 0.611842
I0526 01:35:30.091195 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.611842 (* 1 = 0.611842 loss)
I0526 01:35:30.091207 15394 sgd_solver.cpp:43] Iteration 7120, lr = 0.02
I0526 01:35:41.781601 15394 main.cpp:354] Iteration 7130, loss = 0.618466
I0526 01:35:41.781677 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.618466 (* 1 = 0.618466 loss)
I0526 01:35:41.781689 15394 sgd_solver.cpp:43] Iteration 7130, lr = 0.02
I0526 01:35:53.182206 15394 main.cpp:354] Iteration 7140, loss = 0.682721
I0526 01:35:53.182274 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.682722 (* 1 = 0.682722 loss)
I0526 01:35:53.182284 15394 sgd_solver.cpp:43] Iteration 7140, lr = 0.02
I0526 01:36:04.859381 15394 main.cpp:354] Iteration 7150, loss = 0.687866
I0526 01:36:04.859441 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.687866 (* 1 = 0.687866 loss)
I0526 01:36:04.859460 15394 sgd_solver.cpp:43] Iteration 7150, lr = 0.02
I0526 01:36:16.103231 15394 main.cpp:354] Iteration 7160, loss = 0.827911
I0526 01:36:16.103307 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.827911 (* 1 = 0.827911 loss)
I0526 01:36:16.103317 15394 sgd_solver.cpp:43] Iteration 7160, lr = 0.02
I0526 01:36:27.359053 15394 main.cpp:354] Iteration 7170, loss = 0.479718
I0526 01:36:27.359122 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.479718 (* 1 = 0.479718 loss)
I0526 01:36:27.359133 15394 sgd_solver.cpp:43] Iteration 7170, lr = 0.02
I0526 01:36:39.346678 15394 main.cpp:354] Iteration 7180, loss = 0.580371
I0526 01:36:39.346751 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.580371 (* 1 = 0.580371 loss)
I0526 01:36:39.346763 15394 sgd_solver.cpp:43] Iteration 7180, lr = 0.02
I0526 01:36:50.348176 15394 main.cpp:354] Iteration 7190, loss = 0.680233
I0526 01:36:50.348242 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.680234 (* 1 = 0.680234 loss)
I0526 01:36:50.348253 15394 sgd_solver.cpp:43] Iteration 7190, lr = 0.02
I0526 01:37:01.210810 15394 main.cpp:465] Iteration 7200, Testing net (#0)
I0526 01:37:30.914767 15394 main.cpp:532]     Test net output #0: Accuracy = 0.5455
I0526 01:37:30.914831 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.25611 (* 1 = 1.25611 loss)
I0526 01:37:32.071151 15394 main.cpp:354] Iteration 7200, loss = 0.529395
I0526 01:37:32.071230 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.529395 (* 1 = 0.529395 loss)
I0526 01:37:32.071245 15394 sgd_solver.cpp:43] Iteration 7200, lr = 0.02
I0526 01:37:43.792771 15394 main.cpp:354] Iteration 7210, loss = 0.589049
I0526 01:37:43.792841 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.589049 (* 1 = 0.589049 loss)
I0526 01:37:43.792852 15394 sgd_solver.cpp:43] Iteration 7210, lr = 0.02
I0526 01:37:54.711566 15394 main.cpp:354] Iteration 7220, loss = 0.65535
I0526 01:37:54.711639 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.65535 (* 1 = 0.65535 loss)
I0526 01:37:54.711650 15394 sgd_solver.cpp:43] Iteration 7220, lr = 0.02
I0526 01:38:05.791996 15394 main.cpp:354] Iteration 7230, loss = 0.980705
I0526 01:38:05.792079 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.980705 (* 1 = 0.980705 loss)
I0526 01:38:05.792096 15394 sgd_solver.cpp:43] Iteration 7230, lr = 0.02
I0526 01:38:16.336680 15394 main.cpp:354] Iteration 7240, loss = 0.469129
I0526 01:38:16.336746 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.469129 (* 1 = 0.469129 loss)
I0526 01:38:16.336758 15394 sgd_solver.cpp:43] Iteration 7240, lr = 0.02
I0526 01:38:27.878284 15394 main.cpp:354] Iteration 7250, loss = 0.406197
I0526 01:38:27.878363 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.406197 (* 1 = 0.406197 loss)
I0526 01:38:27.878374 15394 sgd_solver.cpp:43] Iteration 7250, lr = 0.02
I0526 01:38:39.481557 15394 main.cpp:354] Iteration 7260, loss = 0.445346
I0526 01:38:39.481626 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.445346 (* 1 = 0.445346 loss)
I0526 01:38:39.481637 15394 sgd_solver.cpp:43] Iteration 7260, lr = 0.02
I0526 01:38:50.852332 15394 main.cpp:354] Iteration 7270, loss = 0.706768
I0526 01:38:50.852413 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.706768 (* 1 = 0.706768 loss)
I0526 01:38:50.852429 15394 sgd_solver.cpp:43] Iteration 7270, lr = 0.02
I0526 01:39:01.584436 15394 main.cpp:354] Iteration 7280, loss = 0.64435
I0526 01:39:01.584501 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.644351 (* 1 = 0.644351 loss)
I0526 01:39:01.584511 15394 sgd_solver.cpp:43] Iteration 7280, lr = 0.02
I0526 01:39:12.317420 15394 main.cpp:354] Iteration 7290, loss = 0.604741
I0526 01:39:12.317483 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.604741 (* 1 = 0.604741 loss)
I0526 01:39:12.317494 15394 sgd_solver.cpp:43] Iteration 7290, lr = 0.02
I0526 01:39:22.670603 15394 main.cpp:465] Iteration 7300, Testing net (#0)
I0526 01:39:52.755192 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6144
I0526 01:39:52.755254 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.08103 (* 1 = 1.08103 loss)
I0526 01:39:53.832736 15394 main.cpp:354] Iteration 7300, loss = 0.63606
I0526 01:39:53.832805 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.63606 (* 1 = 0.63606 loss)
I0526 01:39:53.832819 15394 sgd_solver.cpp:43] Iteration 7300, lr = 0.02
I0526 01:40:05.765872 15394 main.cpp:354] Iteration 7310, loss = 0.56462
I0526 01:40:05.765949 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.56462 (* 1 = 0.56462 loss)
I0526 01:40:05.765964 15394 sgd_solver.cpp:43] Iteration 7310, lr = 0.02
I0526 01:40:17.204708 15394 main.cpp:354] Iteration 7320, loss = 0.64861
I0526 01:40:17.204767 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.64861 (* 1 = 0.64861 loss)
I0526 01:40:17.204777 15394 sgd_solver.cpp:43] Iteration 7320, lr = 0.02
I0526 01:40:29.252652 15394 main.cpp:354] Iteration 7330, loss = 0.569979
I0526 01:40:29.252728 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.569979 (* 1 = 0.569979 loss)
I0526 01:40:29.252738 15394 sgd_solver.cpp:43] Iteration 7330, lr = 0.02
I0526 01:40:39.481405 15394 main.cpp:354] Iteration 7340, loss = 0.586372
I0526 01:40:39.481477 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.586372 (* 1 = 0.586372 loss)
I0526 01:40:39.481489 15394 sgd_solver.cpp:43] Iteration 7340, lr = 0.02
I0526 01:40:50.949450 15394 main.cpp:354] Iteration 7350, loss = 0.686316
I0526 01:40:50.949527 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.686316 (* 1 = 0.686316 loss)
I0526 01:40:50.949547 15394 sgd_solver.cpp:43] Iteration 7350, lr = 0.02
I0526 01:41:01.759160 15394 main.cpp:354] Iteration 7360, loss = 0.476915
I0526 01:41:01.759229 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.476915 (* 1 = 0.476915 loss)
I0526 01:41:01.759240 15394 sgd_solver.cpp:43] Iteration 7360, lr = 0.02
I0526 01:41:13.080541 15394 main.cpp:354] Iteration 7370, loss = 0.561686
I0526 01:41:13.080608 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.561686 (* 1 = 0.561686 loss)
I0526 01:41:13.080620 15394 sgd_solver.cpp:43] Iteration 7370, lr = 0.02
I0526 01:41:24.673867 15394 main.cpp:354] Iteration 7380, loss = 0.577061
I0526 01:41:24.673936 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.577061 (* 1 = 0.577061 loss)
I0526 01:41:24.673948 15394 sgd_solver.cpp:43] Iteration 7380, lr = 0.02
I0526 01:41:35.589853 15394 main.cpp:354] Iteration 7390, loss = 0.495191
I0526 01:41:35.589916 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.495191 (* 1 = 0.495191 loss)
I0526 01:41:35.589926 15394 sgd_solver.cpp:43] Iteration 7390, lr = 0.02
I0526 01:41:45.696492 15394 main.cpp:465] Iteration 7400, Testing net (#0)
I0526 01:42:16.008515 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6726
I0526 01:42:16.008585 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.04527 (* 1 = 1.04527 loss)
I0526 01:42:16.768643 15394 main.cpp:354] Iteration 7400, loss = 0.513353
I0526 01:42:16.768717 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.513353 (* 1 = 0.513353 loss)
I0526 01:42:16.768735 15394 sgd_solver.cpp:43] Iteration 7400, lr = 0.02
I0526 01:42:26.929416 15394 main.cpp:354] Iteration 7410, loss = 0.52094
I0526 01:42:26.929491 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.52094 (* 1 = 0.52094 loss)
I0526 01:42:26.929503 15394 sgd_solver.cpp:43] Iteration 7410, lr = 0.02
I0526 01:42:38.283380 15394 main.cpp:354] Iteration 7420, loss = 0.486698
I0526 01:42:38.283457 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.486698 (* 1 = 0.486698 loss)
I0526 01:42:38.283469 15394 sgd_solver.cpp:43] Iteration 7420, lr = 0.02
I0526 01:42:49.968929 15394 main.cpp:354] Iteration 7430, loss = 0.681981
I0526 01:42:49.968993 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.681981 (* 1 = 0.681981 loss)
I0526 01:42:49.969015 15394 sgd_solver.cpp:43] Iteration 7430, lr = 0.02
I0526 01:43:02.039891 15394 main.cpp:354] Iteration 7440, loss = 0.388348
I0526 01:43:02.039969 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.388348 (* 1 = 0.388348 loss)
I0526 01:43:02.039981 15394 sgd_solver.cpp:43] Iteration 7440, lr = 0.02
I0526 01:43:12.575906 15394 main.cpp:354] Iteration 7450, loss = 0.525263
I0526 01:43:12.575978 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.525263 (* 1 = 0.525263 loss)
I0526 01:43:12.575990 15394 sgd_solver.cpp:43] Iteration 7450, lr = 0.02
I0526 01:43:24.154718 15394 main.cpp:354] Iteration 7460, loss = 0.741208
I0526 01:43:24.154794 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.741208 (* 1 = 0.741208 loss)
I0526 01:43:24.154806 15394 sgd_solver.cpp:43] Iteration 7460, lr = 0.02
I0526 01:43:35.192932 15394 main.cpp:354] Iteration 7470, loss = 0.509144
I0526 01:43:35.193001 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.509144 (* 1 = 0.509144 loss)
I0526 01:43:35.193013 15394 sgd_solver.cpp:43] Iteration 7470, lr = 0.02
I0526 01:43:46.882053 15394 main.cpp:354] Iteration 7480, loss = 0.509217
I0526 01:43:46.882128 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.509217 (* 1 = 0.509217 loss)
I0526 01:43:46.882140 15394 sgd_solver.cpp:43] Iteration 7480, lr = 0.02
I0526 01:43:58.259690 15394 main.cpp:354] Iteration 7490, loss = 0.583985
I0526 01:43:58.259763 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.583985 (* 1 = 0.583985 loss)
I0526 01:43:58.259775 15394 sgd_solver.cpp:43] Iteration 7490, lr = 0.02
I0526 01:44:08.401973 15394 main.cpp:465] Iteration 7500, Testing net (#0)
I0526 01:44:38.836093 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6907
I0526 01:44:38.836160 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.944806 (* 1 = 0.944806 loss)
I0526 01:44:39.899325 15394 main.cpp:354] Iteration 7500, loss = 0.447876
I0526 01:44:39.899399 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.447876 (* 1 = 0.447876 loss)
I0526 01:44:39.899417 15394 sgd_solver.cpp:43] Iteration 7500, lr = 0.02
I0526 01:44:50.403301 15394 main.cpp:354] Iteration 7510, loss = 0.626413
I0526 01:44:50.403367 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.626413 (* 1 = 0.626413 loss)
I0526 01:44:50.403378 15394 sgd_solver.cpp:43] Iteration 7510, lr = 0.02
I0526 01:45:01.159451 15394 main.cpp:354] Iteration 7520, loss = 0.555398
I0526 01:45:01.159519 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.555398 (* 1 = 0.555398 loss)
I0526 01:45:01.159530 15394 sgd_solver.cpp:43] Iteration 7520, lr = 0.02
I0526 01:45:12.532914 15394 main.cpp:354] Iteration 7530, loss = 0.524425
I0526 01:45:12.532994 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.524425 (* 1 = 0.524425 loss)
I0526 01:45:12.533005 15394 sgd_solver.cpp:43] Iteration 7530, lr = 0.02
I0526 01:45:22.936285 15394 main.cpp:354] Iteration 7540, loss = 0.570695
I0526 01:45:22.936357 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.570695 (* 1 = 0.570695 loss)
I0526 01:45:22.936367 15394 sgd_solver.cpp:43] Iteration 7540, lr = 0.02
I0526 01:45:34.104334 15394 main.cpp:354] Iteration 7550, loss = 0.794388
I0526 01:45:34.104400 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.794389 (* 1 = 0.794389 loss)
I0526 01:45:34.104411 15394 sgd_solver.cpp:43] Iteration 7550, lr = 0.02
I0526 01:45:45.361898 15394 main.cpp:354] Iteration 7560, loss = 0.672777
I0526 01:45:45.361970 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.672777 (* 1 = 0.672777 loss)
I0526 01:45:45.361982 15394 sgd_solver.cpp:43] Iteration 7560, lr = 0.02
I0526 01:45:57.045831 15394 main.cpp:354] Iteration 7570, loss = 0.446722
I0526 01:45:57.045905 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.446722 (* 1 = 0.446722 loss)
I0526 01:45:57.045917 15394 sgd_solver.cpp:43] Iteration 7570, lr = 0.02
I0526 01:46:07.478991 15394 main.cpp:354] Iteration 7580, loss = 0.645826
I0526 01:46:07.479060 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.645826 (* 1 = 0.645826 loss)
I0526 01:46:07.479070 15394 sgd_solver.cpp:43] Iteration 7580, lr = 0.02
I0526 01:46:18.821956 15394 main.cpp:354] Iteration 7590, loss = 0.53954
I0526 01:46:18.822016 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.53954 (* 1 = 0.53954 loss)
I0526 01:46:18.822026 15394 sgd_solver.cpp:43] Iteration 7590, lr = 0.02
I0526 01:46:29.210705 15394 main.cpp:465] Iteration 7600, Testing net (#0)
I0526 01:46:59.391803 15394 main.cpp:532]     Test net output #0: Accuracy = 0.708
I0526 01:46:59.391867 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.884854 (* 1 = 0.884854 loss)
I0526 01:47:00.255085 15394 main.cpp:354] Iteration 7600, loss = 0.72332
I0526 01:47:00.255151 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.723321 (* 1 = 0.723321 loss)
I0526 01:47:00.255167 15394 sgd_solver.cpp:43] Iteration 7600, lr = 0.02
I0526 01:47:12.033304 15394 main.cpp:354] Iteration 7610, loss = 0.536961
I0526 01:47:12.033385 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.536961 (* 1 = 0.536961 loss)
I0526 01:47:12.033396 15394 sgd_solver.cpp:43] Iteration 7610, lr = 0.02
I0526 01:47:22.861858 15394 main.cpp:354] Iteration 7620, loss = 0.519691
I0526 01:47:22.861953 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.519691 (* 1 = 0.519691 loss)
I0526 01:47:22.861964 15394 sgd_solver.cpp:43] Iteration 7620, lr = 0.02
I0526 01:47:34.236683 15394 main.cpp:354] Iteration 7630, loss = 0.583062
I0526 01:47:34.236765 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.583062 (* 1 = 0.583062 loss)
I0526 01:47:34.236778 15394 sgd_solver.cpp:43] Iteration 7630, lr = 0.02
I0526 01:47:44.825737 15394 main.cpp:354] Iteration 7640, loss = 0.386233
I0526 01:47:44.825814 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.386233 (* 1 = 0.386233 loss)
I0526 01:47:44.825824 15394 sgd_solver.cpp:43] Iteration 7640, lr = 0.02
I0526 01:47:55.970911 15394 main.cpp:354] Iteration 7650, loss = 0.611898
I0526 01:47:55.970989 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.611899 (* 1 = 0.611899 loss)
I0526 01:47:55.970999 15394 sgd_solver.cpp:43] Iteration 7650, lr = 0.02
I0526 01:48:07.138002 15394 main.cpp:354] Iteration 7660, loss = 0.575468
I0526 01:48:07.138069 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.575468 (* 1 = 0.575468 loss)
I0526 01:48:07.138082 15394 sgd_solver.cpp:43] Iteration 7660, lr = 0.02
I0526 01:48:19.465355 15394 main.cpp:354] Iteration 7670, loss = 0.488532
I0526 01:48:19.465420 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.488532 (* 1 = 0.488532 loss)
I0526 01:48:19.465430 15394 sgd_solver.cpp:43] Iteration 7670, lr = 0.02
I0526 01:48:32.051487 15394 main.cpp:354] Iteration 7680, loss = 0.628391
I0526 01:48:32.051560 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.628391 (* 1 = 0.628391 loss)
I0526 01:48:32.051571 15394 sgd_solver.cpp:43] Iteration 7680, lr = 0.02
I0526 01:48:43.582674 15394 main.cpp:354] Iteration 7690, loss = 0.822389
I0526 01:48:43.582746 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.822389 (* 1 = 0.822389 loss)
I0526 01:48:43.582756 15394 sgd_solver.cpp:43] Iteration 7690, lr = 0.02
I0526 01:48:53.100630 15394 main.cpp:465] Iteration 7700, Testing net (#0)
I0526 01:49:23.426621 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6848
I0526 01:49:23.426684 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.950755 (* 1 = 0.950755 loss)
I0526 01:49:24.382786 15394 main.cpp:354] Iteration 7700, loss = 0.590964
I0526 01:49:24.382856 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.590964 (* 1 = 0.590964 loss)
I0526 01:49:24.382872 15394 sgd_solver.cpp:43] Iteration 7700, lr = 0.02
I0526 01:49:35.573593 15394 main.cpp:354] Iteration 7710, loss = 0.823328
I0526 01:49:35.573669 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.823328 (* 1 = 0.823328 loss)
I0526 01:49:35.573698 15394 sgd_solver.cpp:43] Iteration 7710, lr = 0.02
I0526 01:49:47.042946 15394 main.cpp:354] Iteration 7720, loss = 0.583179
I0526 01:49:47.043011 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.58318 (* 1 = 0.58318 loss)
I0526 01:49:47.043022 15394 sgd_solver.cpp:43] Iteration 7720, lr = 0.02
I0526 01:49:58.951222 15394 main.cpp:354] Iteration 7730, loss = 0.485507
I0526 01:49:58.951292 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.485507 (* 1 = 0.485507 loss)
I0526 01:49:58.951303 15394 sgd_solver.cpp:43] Iteration 7730, lr = 0.02
I0526 01:50:08.997869 15394 main.cpp:354] Iteration 7740, loss = 0.540087
I0526 01:50:08.997939 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.540088 (* 1 = 0.540088 loss)
I0526 01:50:08.997951 15394 sgd_solver.cpp:43] Iteration 7740, lr = 0.02
I0526 01:50:20.162037 15394 main.cpp:354] Iteration 7750, loss = 0.677518
I0526 01:50:20.162109 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.677518 (* 1 = 0.677518 loss)
I0526 01:50:20.162120 15394 sgd_solver.cpp:43] Iteration 7750, lr = 0.02
I0526 01:50:30.884021 15394 main.cpp:354] Iteration 7760, loss = 0.743747
I0526 01:50:30.884090 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.743748 (* 1 = 0.743748 loss)
I0526 01:50:30.884100 15394 sgd_solver.cpp:43] Iteration 7760, lr = 0.02
I0526 01:50:42.232836 15394 main.cpp:354] Iteration 7770, loss = 0.636356
I0526 01:50:42.232904 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.636356 (* 1 = 0.636356 loss)
I0526 01:50:42.232915 15394 sgd_solver.cpp:43] Iteration 7770, lr = 0.02
I0526 01:50:53.509451 15394 main.cpp:354] Iteration 7780, loss = 0.638519
I0526 01:50:53.509521 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.638519 (* 1 = 0.638519 loss)
I0526 01:50:53.509532 15394 sgd_solver.cpp:43] Iteration 7780, lr = 0.02
I0526 01:51:05.055686 15394 main.cpp:354] Iteration 7790, loss = 0.533834
I0526 01:51:05.055752 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.533834 (* 1 = 0.533834 loss)
I0526 01:51:05.055762 15394 sgd_solver.cpp:43] Iteration 7790, lr = 0.02
I0526 01:51:14.715155 15394 main.cpp:465] Iteration 7800, Testing net (#0)
I0526 01:51:45.063531 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7611
I0526 01:51:45.063591 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.682265 (* 1 = 0.682265 loss)
I0526 01:51:45.942747 15394 main.cpp:354] Iteration 7800, loss = 0.532265
I0526 01:51:45.942816 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.532265 (* 1 = 0.532265 loss)
I0526 01:51:45.942829 15394 sgd_solver.cpp:43] Iteration 7800, lr = 0.02
I0526 01:51:56.909729 15394 main.cpp:354] Iteration 7810, loss = 0.627147
I0526 01:51:56.909796 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.627147 (* 1 = 0.627147 loss)
I0526 01:51:56.909807 15394 sgd_solver.cpp:43] Iteration 7810, lr = 0.02
I0526 01:52:08.231586 15394 main.cpp:354] Iteration 7820, loss = 0.513728
I0526 01:52:08.231652 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.513728 (* 1 = 0.513728 loss)
I0526 01:52:08.231662 15394 sgd_solver.cpp:43] Iteration 7820, lr = 0.02
I0526 01:52:20.044091 15394 main.cpp:354] Iteration 7830, loss = 0.419103
I0526 01:52:20.044158 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.419103 (* 1 = 0.419103 loss)
I0526 01:52:20.044170 15394 sgd_solver.cpp:43] Iteration 7830, lr = 0.02
I0526 01:52:31.169673 15394 main.cpp:354] Iteration 7840, loss = 0.573539
I0526 01:52:31.169740 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.57354 (* 1 = 0.57354 loss)
I0526 01:52:31.169750 15394 sgd_solver.cpp:43] Iteration 7840, lr = 0.02
I0526 01:52:42.598844 15394 main.cpp:354] Iteration 7850, loss = 0.519583
I0526 01:52:42.598913 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.519583 (* 1 = 0.519583 loss)
I0526 01:52:42.598924 15394 sgd_solver.cpp:43] Iteration 7850, lr = 0.02
I0526 01:52:53.134902 15394 main.cpp:354] Iteration 7860, loss = 0.556299
I0526 01:52:53.134969 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.556299 (* 1 = 0.556299 loss)
I0526 01:52:53.134980 15394 sgd_solver.cpp:43] Iteration 7860, lr = 0.02
I0526 01:53:04.970988 15394 main.cpp:354] Iteration 7870, loss = 0.547312
I0526 01:53:04.971047 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.547312 (* 1 = 0.547312 loss)
I0526 01:53:04.971057 15394 sgd_solver.cpp:43] Iteration 7870, lr = 0.02
I0526 01:53:16.127761 15394 main.cpp:354] Iteration 7880, loss = 0.790621
I0526 01:53:16.127830 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.790621 (* 1 = 0.790621 loss)
I0526 01:53:16.127840 15394 sgd_solver.cpp:43] Iteration 7880, lr = 0.02
I0526 01:53:27.986711 15394 main.cpp:354] Iteration 7890, loss = 0.588006
I0526 01:53:27.986780 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.588006 (* 1 = 0.588006 loss)
I0526 01:53:27.986791 15394 sgd_solver.cpp:43] Iteration 7890, lr = 0.02
I0526 01:53:37.577776 15394 main.cpp:465] Iteration 7900, Testing net (#0)
I0526 01:54:07.961498 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7487
I0526 01:54:07.961567 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.740566 (* 1 = 0.740566 loss)
I0526 01:54:08.933120 15394 main.cpp:354] Iteration 7900, loss = 0.471816
I0526 01:54:08.933190 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.471816 (* 1 = 0.471816 loss)
I0526 01:54:08.933204 15394 sgd_solver.cpp:43] Iteration 7900, lr = 0.02
I0526 01:54:20.870946 15394 main.cpp:354] Iteration 7910, loss = 0.642058
I0526 01:54:20.871007 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.642058 (* 1 = 0.642058 loss)
I0526 01:54:20.871018 15394 sgd_solver.cpp:43] Iteration 7910, lr = 0.02
I0526 01:54:31.717309 15394 main.cpp:354] Iteration 7920, loss = 0.546713
I0526 01:54:31.717375 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.546713 (* 1 = 0.546713 loss)
I0526 01:54:31.717386 15394 sgd_solver.cpp:43] Iteration 7920, lr = 0.02
I0526 01:54:43.621999 15394 main.cpp:354] Iteration 7930, loss = 0.57166
I0526 01:54:43.622068 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.571661 (* 1 = 0.571661 loss)
I0526 01:54:43.622079 15394 sgd_solver.cpp:43] Iteration 7930, lr = 0.02
I0526 01:54:54.739908 15394 main.cpp:354] Iteration 7940, loss = 0.624979
I0526 01:54:54.739974 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.624979 (* 1 = 0.624979 loss)
I0526 01:54:54.739984 15394 sgd_solver.cpp:43] Iteration 7940, lr = 0.02
I0526 01:55:06.686885 15394 main.cpp:354] Iteration 7950, loss = 0.507633
I0526 01:55:06.686951 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.507633 (* 1 = 0.507633 loss)
I0526 01:55:06.686961 15394 sgd_solver.cpp:43] Iteration 7950, lr = 0.02
I0526 01:55:16.587163 15394 main.cpp:354] Iteration 7960, loss = 0.534634
I0526 01:55:16.587234 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.534634 (* 1 = 0.534634 loss)
I0526 01:55:16.587249 15394 sgd_solver.cpp:43] Iteration 7960, lr = 0.02
I0526 01:55:28.639346 15394 main.cpp:354] Iteration 7970, loss = 0.572028
I0526 01:55:28.639408 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.572029 (* 1 = 0.572029 loss)
I0526 01:55:28.639420 15394 sgd_solver.cpp:43] Iteration 7970, lr = 0.02
I0526 01:55:39.295512 15394 main.cpp:354] Iteration 7980, loss = 0.599576
I0526 01:55:39.295575 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.599576 (* 1 = 0.599576 loss)
I0526 01:55:39.295586 15394 sgd_solver.cpp:43] Iteration 7980, lr = 0.02
I0526 01:55:50.327805 15394 main.cpp:354] Iteration 7990, loss = 0.607568
I0526 01:55:50.327873 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.607568 (* 1 = 0.607568 loss)
I0526 01:55:50.327883 15394 sgd_solver.cpp:43] Iteration 7990, lr = 0.02
I0526 01:56:00.489487 15394 main.cpp:465] Iteration 8000, Testing net (#0)
I0526 01:56:30.800351 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7053
I0526 01:56:30.800410 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.838164 (* 1 = 0.838164 loss)
I0526 01:56:31.936158 15394 main.cpp:354] Iteration 8000, loss = 0.385931
I0526 01:56:31.936228 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.385931 (* 1 = 0.385931 loss)
I0526 01:56:31.936244 15394 sgd_solver.cpp:43] Iteration 8000, lr = 0.02
I0526 01:56:42.428083 15394 main.cpp:354] Iteration 8010, loss = 0.495031
I0526 01:56:42.428153 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.495031 (* 1 = 0.495031 loss)
I0526 01:56:42.428163 15394 sgd_solver.cpp:43] Iteration 8010, lr = 0.02
I0526 01:56:53.706542 15394 main.cpp:354] Iteration 8020, loss = 0.579615
I0526 01:56:53.706609 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.579615 (* 1 = 0.579615 loss)
I0526 01:56:53.706619 15394 sgd_solver.cpp:43] Iteration 8020, lr = 0.02
I0526 01:57:04.771534 15394 main.cpp:354] Iteration 8030, loss = 0.596557
I0526 01:57:04.771600 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.596557 (* 1 = 0.596557 loss)
I0526 01:57:04.771610 15394 sgd_solver.cpp:43] Iteration 8030, lr = 0.02
I0526 01:57:16.339654 15394 main.cpp:354] Iteration 8040, loss = 0.525644
I0526 01:57:16.339718 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.525644 (* 1 = 0.525644 loss)
I0526 01:57:16.339727 15394 sgd_solver.cpp:43] Iteration 8040, lr = 0.02
I0526 01:57:27.494391 15394 main.cpp:354] Iteration 8050, loss = 0.651174
I0526 01:57:27.494451 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.651174 (* 1 = 0.651174 loss)
I0526 01:57:27.494462 15394 sgd_solver.cpp:43] Iteration 8050, lr = 0.02
I0526 01:57:38.053850 15394 main.cpp:354] Iteration 8060, loss = 0.471305
I0526 01:57:38.053918 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.471305 (* 1 = 0.471305 loss)
I0526 01:57:38.053930 15394 sgd_solver.cpp:43] Iteration 8060, lr = 0.02
I0526 01:57:49.159036 15394 main.cpp:354] Iteration 8070, loss = 0.696652
I0526 01:57:49.159104 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.696652 (* 1 = 0.696652 loss)
I0526 01:57:49.159116 15394 sgd_solver.cpp:43] Iteration 8070, lr = 0.02
I0526 01:58:01.134744 15394 main.cpp:354] Iteration 8080, loss = 0.543413
I0526 01:58:01.134811 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.543413 (* 1 = 0.543413 loss)
I0526 01:58:01.134822 15394 sgd_solver.cpp:43] Iteration 8080, lr = 0.02
I0526 01:58:11.760784 15394 main.cpp:354] Iteration 8090, loss = 0.525674
I0526 01:58:11.760844 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.525674 (* 1 = 0.525674 loss)
I0526 01:58:11.760854 15394 sgd_solver.cpp:43] Iteration 8090, lr = 0.02
I0526 01:58:22.446980 15394 main.cpp:465] Iteration 8100, Testing net (#0)
I0526 01:58:52.623196 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6621
I0526 01:58:52.623256 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.03182 (* 1 = 1.03182 loss)
I0526 01:58:53.791467 15394 main.cpp:354] Iteration 8100, loss = 0.602455
I0526 01:58:53.791533 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.602455 (* 1 = 0.602455 loss)
I0526 01:58:53.791550 15394 sgd_solver.cpp:43] Iteration 8100, lr = 0.02
I0526 01:59:05.374603 15394 main.cpp:354] Iteration 8110, loss = 0.509373
I0526 01:59:05.374671 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.509373 (* 1 = 0.509373 loss)
I0526 01:59:05.374683 15394 sgd_solver.cpp:43] Iteration 8110, lr = 0.02
I0526 01:59:15.795892 15394 main.cpp:354] Iteration 8120, loss = 0.623318
I0526 01:59:15.795961 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.623318 (* 1 = 0.623318 loss)
I0526 01:59:15.795971 15394 sgd_solver.cpp:43] Iteration 8120, lr = 0.02
I0526 01:59:26.708605 15394 main.cpp:354] Iteration 8130, loss = 0.464201
I0526 01:59:26.708665 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.464201 (* 1 = 0.464201 loss)
I0526 01:59:26.708685 15394 sgd_solver.cpp:43] Iteration 8130, lr = 0.02
I0526 01:59:38.690271 15394 main.cpp:354] Iteration 8140, loss = 0.491579
I0526 01:59:38.690341 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.491579 (* 1 = 0.491579 loss)
I0526 01:59:38.690357 15394 sgd_solver.cpp:43] Iteration 8140, lr = 0.02
I0526 01:59:50.571704 15394 main.cpp:354] Iteration 8150, loss = 0.535582
I0526 01:59:50.571769 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.535583 (* 1 = 0.535583 loss)
I0526 01:59:50.571779 15394 sgd_solver.cpp:43] Iteration 8150, lr = 0.02
I0526 02:00:01.414000 15394 main.cpp:354] Iteration 8160, loss = 0.750938
I0526 02:00:01.414067 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.750938 (* 1 = 0.750938 loss)
I0526 02:00:01.414078 15394 sgd_solver.cpp:43] Iteration 8160, lr = 0.02
I0526 02:00:12.268079 15394 main.cpp:354] Iteration 8170, loss = 0.43696
I0526 02:00:12.268147 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.43696 (* 1 = 0.43696 loss)
I0526 02:00:12.268157 15394 sgd_solver.cpp:43] Iteration 8170, lr = 0.02
I0526 02:00:23.862038 15394 main.cpp:354] Iteration 8180, loss = 0.614734
I0526 02:00:23.862110 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.614734 (* 1 = 0.614734 loss)
I0526 02:00:23.862121 15394 sgd_solver.cpp:43] Iteration 8180, lr = 0.02
I0526 02:00:35.289567 15394 main.cpp:354] Iteration 8190, loss = 0.526916
I0526 02:00:35.289625 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.526916 (* 1 = 0.526916 loss)
I0526 02:00:35.289634 15394 sgd_solver.cpp:43] Iteration 8190, lr = 0.02
I0526 02:00:45.194404 15394 main.cpp:465] Iteration 8200, Testing net (#0)
I0526 02:01:15.287070 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7013
I0526 02:01:15.287129 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.878296 (* 1 = 0.878296 loss)
I0526 02:01:16.255918 15394 main.cpp:354] Iteration 8200, loss = 0.550236
I0526 02:01:16.255983 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.550236 (* 1 = 0.550236 loss)
I0526 02:01:16.255998 15394 sgd_solver.cpp:43] Iteration 8200, lr = 0.02
I0526 02:01:27.671167 15394 main.cpp:354] Iteration 8210, loss = 0.443542
I0526 02:01:27.671232 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.443542 (* 1 = 0.443542 loss)
I0526 02:01:27.671242 15394 sgd_solver.cpp:43] Iteration 8210, lr = 0.02
I0526 02:01:38.365464 15394 main.cpp:354] Iteration 8220, loss = 0.788161
I0526 02:01:38.365531 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.788161 (* 1 = 0.788161 loss)
I0526 02:01:38.365545 15394 sgd_solver.cpp:43] Iteration 8220, lr = 0.02
I0526 02:01:49.922505 15394 main.cpp:354] Iteration 8230, loss = 0.457811
I0526 02:01:49.922574 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.457812 (* 1 = 0.457812 loss)
I0526 02:01:49.922585 15394 sgd_solver.cpp:43] Iteration 8230, lr = 0.02
I0526 02:02:02.491659 15394 main.cpp:354] Iteration 8240, loss = 0.370889
I0526 02:02:02.491729 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.370889 (* 1 = 0.370889 loss)
I0526 02:02:02.491740 15394 sgd_solver.cpp:43] Iteration 8240, lr = 0.02
I0526 02:02:14.278564 15394 main.cpp:354] Iteration 8250, loss = 0.57495
I0526 02:02:14.278623 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.57495 (* 1 = 0.57495 loss)
I0526 02:02:14.278635 15394 sgd_solver.cpp:43] Iteration 8250, lr = 0.02
I0526 02:02:24.388533 15394 main.cpp:354] Iteration 8260, loss = 0.737067
I0526 02:02:24.388602 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.737067 (* 1 = 0.737067 loss)
I0526 02:02:24.388612 15394 sgd_solver.cpp:43] Iteration 8260, lr = 0.02
I0526 02:02:35.432844 15394 main.cpp:354] Iteration 8270, loss = 0.524875
I0526 02:02:35.432911 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.524875 (* 1 = 0.524875 loss)
I0526 02:02:35.432922 15394 sgd_solver.cpp:43] Iteration 8270, lr = 0.02
I0526 02:02:46.631415 15394 main.cpp:354] Iteration 8280, loss = 0.484091
I0526 02:02:46.631489 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.484091 (* 1 = 0.484091 loss)
I0526 02:02:46.631500 15394 sgd_solver.cpp:43] Iteration 8280, lr = 0.02
I0526 02:02:57.812906 15394 main.cpp:354] Iteration 8290, loss = 0.544335
I0526 02:02:57.812969 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.544336 (* 1 = 0.544336 loss)
I0526 02:02:57.812981 15394 sgd_solver.cpp:43] Iteration 8290, lr = 0.02
I0526 02:03:08.558269 15394 main.cpp:465] Iteration 8300, Testing net (#0)
I0526 02:03:38.545553 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7314
I0526 02:03:38.545613 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.788623 (* 1 = 0.788623 loss)
I0526 02:03:39.515885 15394 main.cpp:354] Iteration 8300, loss = 0.580736
I0526 02:03:39.515952 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.580736 (* 1 = 0.580736 loss)
I0526 02:03:39.515969 15394 sgd_solver.cpp:43] Iteration 8300, lr = 0.02
I0526 02:03:50.481371 15394 main.cpp:354] Iteration 8310, loss = 0.817428
I0526 02:03:50.481434 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.817428 (* 1 = 0.817428 loss)
I0526 02:03:50.481444 15394 sgd_solver.cpp:43] Iteration 8310, lr = 0.02
I0526 02:04:01.959126 15394 main.cpp:354] Iteration 8320, loss = 0.497995
I0526 02:04:01.959192 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.497996 (* 1 = 0.497996 loss)
I0526 02:04:01.959203 15394 sgd_solver.cpp:43] Iteration 8320, lr = 0.02
I0526 02:04:11.932337 15394 main.cpp:354] Iteration 8330, loss = 0.599178
I0526 02:04:11.932397 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.599178 (* 1 = 0.599178 loss)
I0526 02:04:11.932406 15394 sgd_solver.cpp:43] Iteration 8330, lr = 0.02
I0526 02:04:23.407058 15394 main.cpp:354] Iteration 8340, loss = 0.399826
I0526 02:04:23.407129 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.399827 (* 1 = 0.399827 loss)
I0526 02:04:23.407140 15394 sgd_solver.cpp:43] Iteration 8340, lr = 0.02
I0526 02:04:33.932178 15394 main.cpp:354] Iteration 8350, loss = 0.479739
I0526 02:04:33.932252 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.479739 (* 1 = 0.479739 loss)
I0526 02:04:33.932266 15394 sgd_solver.cpp:43] Iteration 8350, lr = 0.02
I0526 02:04:45.824093 15394 main.cpp:354] Iteration 8360, loss = 0.521673
I0526 02:04:45.824157 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.521673 (* 1 = 0.521673 loss)
I0526 02:04:45.824167 15394 sgd_solver.cpp:43] Iteration 8360, lr = 0.02
I0526 02:04:57.509541 15394 main.cpp:354] Iteration 8370, loss = 0.548783
I0526 02:04:57.509606 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.548783 (* 1 = 0.548783 loss)
I0526 02:04:57.509618 15394 sgd_solver.cpp:43] Iteration 8370, lr = 0.02
I0526 02:05:08.166776 15394 main.cpp:354] Iteration 8380, loss = 0.612496
I0526 02:05:08.166839 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.612496 (* 1 = 0.612496 loss)
I0526 02:05:08.166849 15394 sgd_solver.cpp:43] Iteration 8380, lr = 0.02
I0526 02:05:19.862018 15394 main.cpp:354] Iteration 8390, loss = 0.491992
I0526 02:05:19.862085 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.491993 (* 1 = 0.491993 loss)
I0526 02:05:19.862095 15394 sgd_solver.cpp:43] Iteration 8390, lr = 0.02
I0526 02:05:30.067538 15394 main.cpp:465] Iteration 8400, Testing net (#0)
I0526 02:06:00.319910 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7259
I0526 02:06:00.319979 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.802651 (* 1 = 0.802651 loss)
I0526 02:06:01.247205 15394 main.cpp:354] Iteration 8400, loss = 0.861718
I0526 02:06:01.247283 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.861719 (* 1 = 0.861719 loss)
I0526 02:06:01.247306 15394 sgd_solver.cpp:43] Iteration 8400, lr = 0.02
I0526 02:06:12.471487 15394 main.cpp:354] Iteration 8410, loss = 0.453756
I0526 02:06:12.471560 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.453756 (* 1 = 0.453756 loss)
I0526 02:06:12.471580 15394 sgd_solver.cpp:43] Iteration 8410, lr = 0.02
I0526 02:06:23.862385 15394 main.cpp:354] Iteration 8420, loss = 0.508551
I0526 02:06:23.862457 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.508551 (* 1 = 0.508551 loss)
I0526 02:06:23.862471 15394 sgd_solver.cpp:43] Iteration 8420, lr = 0.02
I0526 02:06:35.613755 15394 main.cpp:354] Iteration 8430, loss = 0.519355
I0526 02:06:35.613831 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.519355 (* 1 = 0.519355 loss)
I0526 02:06:35.613848 15394 sgd_solver.cpp:43] Iteration 8430, lr = 0.02
I0526 02:06:46.625109 15394 main.cpp:354] Iteration 8440, loss = 0.519272
I0526 02:06:46.625180 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.519272 (* 1 = 0.519272 loss)
I0526 02:06:46.625190 15394 sgd_solver.cpp:43] Iteration 8440, lr = 0.02
I0526 02:06:57.878860 15394 main.cpp:354] Iteration 8450, loss = 0.508062
I0526 02:06:57.878931 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.508062 (* 1 = 0.508062 loss)
I0526 02:06:57.878942 15394 sgd_solver.cpp:43] Iteration 8450, lr = 0.02
I0526 02:07:08.315696 15394 main.cpp:354] Iteration 8460, loss = 0.7124
I0526 02:07:08.315783 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.712401 (* 1 = 0.712401 loss)
I0526 02:07:08.315800 15394 sgd_solver.cpp:43] Iteration 8460, lr = 0.02
I0526 02:07:19.243005 15394 main.cpp:354] Iteration 8470, loss = 0.541802
I0526 02:07:19.243063 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.541803 (* 1 = 0.541803 loss)
I0526 02:07:19.243074 15394 sgd_solver.cpp:43] Iteration 8470, lr = 0.02
I0526 02:07:30.868492 15394 main.cpp:354] Iteration 8480, loss = 0.555398
I0526 02:07:30.868559 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.555398 (* 1 = 0.555398 loss)
I0526 02:07:30.868569 15394 sgd_solver.cpp:43] Iteration 8480, lr = 0.02
I0526 02:07:41.952286 15394 main.cpp:354] Iteration 8490, loss = 0.612259
I0526 02:07:41.952352 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.61226 (* 1 = 0.61226 loss)
I0526 02:07:41.952361 15394 sgd_solver.cpp:43] Iteration 8490, lr = 0.02
I0526 02:07:51.856981 15394 main.cpp:465] Iteration 8500, Testing net (#0)
I0526 02:08:21.926276 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7862
I0526 02:08:21.926332 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.63579 (* 1 = 0.63579 loss)
I0526 02:08:22.996376 15394 main.cpp:354] Iteration 8500, loss = 0.571543
I0526 02:08:22.996440 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.571543 (* 1 = 0.571543 loss)
I0526 02:08:22.996456 15394 sgd_solver.cpp:43] Iteration 8500, lr = 0.02
I0526 02:08:34.729023 15394 main.cpp:354] Iteration 8510, loss = 0.46793
I0526 02:08:34.729090 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.46793 (* 1 = 0.46793 loss)
I0526 02:08:34.729101 15394 sgd_solver.cpp:43] Iteration 8510, lr = 0.02
I0526 02:08:45.882513 15394 main.cpp:354] Iteration 8520, loss = 0.623624
I0526 02:08:45.882577 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.623625 (* 1 = 0.623625 loss)
I0526 02:08:45.882587 15394 sgd_solver.cpp:43] Iteration 8520, lr = 0.02
I0526 02:08:56.871044 15394 main.cpp:354] Iteration 8530, loss = 0.554763
I0526 02:08:56.871107 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.554763 (* 1 = 0.554763 loss)
I0526 02:08:56.871119 15394 sgd_solver.cpp:43] Iteration 8530, lr = 0.02
I0526 02:09:08.302634 15394 main.cpp:354] Iteration 8540, loss = 0.594418
I0526 02:09:08.302695 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.594419 (* 1 = 0.594419 loss)
I0526 02:09:08.302706 15394 sgd_solver.cpp:43] Iteration 8540, lr = 0.02
I0526 02:09:19.743494 15394 main.cpp:354] Iteration 8550, loss = 0.522401
I0526 02:09:19.743557 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.522401 (* 1 = 0.522401 loss)
I0526 02:09:19.743567 15394 sgd_solver.cpp:43] Iteration 8550, lr = 0.02
I0526 02:09:31.174437 15394 main.cpp:354] Iteration 8560, loss = 0.462542
I0526 02:09:31.174511 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.462543 (* 1 = 0.462543 loss)
I0526 02:09:31.174523 15394 sgd_solver.cpp:43] Iteration 8560, lr = 0.02
I0526 02:09:42.423019 15394 main.cpp:354] Iteration 8570, loss = 0.556881
I0526 02:09:42.423085 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.556881 (* 1 = 0.556881 loss)
I0526 02:09:42.423095 15394 sgd_solver.cpp:43] Iteration 8570, lr = 0.02
I0526 02:09:52.921169 15394 main.cpp:354] Iteration 8580, loss = 0.70118
I0526 02:09:52.921229 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.70118 (* 1 = 0.70118 loss)
I0526 02:09:52.921241 15394 sgd_solver.cpp:43] Iteration 8580, lr = 0.02
I0526 02:10:04.205029 15394 main.cpp:354] Iteration 8590, loss = 0.793008
I0526 02:10:04.205095 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.793008 (* 1 = 0.793008 loss)
I0526 02:10:04.205106 15394 sgd_solver.cpp:43] Iteration 8590, lr = 0.02
I0526 02:10:15.448058 15394 main.cpp:465] Iteration 8600, Testing net (#0)
I0526 02:10:45.555017 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7235
I0526 02:10:45.555078 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.811523 (* 1 = 0.811523 loss)
I0526 02:10:46.690377 15394 main.cpp:354] Iteration 8600, loss = 0.574696
I0526 02:10:46.690438 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.574696 (* 1 = 0.574696 loss)
I0526 02:10:46.690451 15394 sgd_solver.cpp:43] Iteration 8600, lr = 0.02
I0526 02:10:57.802633 15394 main.cpp:354] Iteration 8610, loss = 0.561153
I0526 02:10:57.802696 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.561154 (* 1 = 0.561154 loss)
I0526 02:10:57.802706 15394 sgd_solver.cpp:43] Iteration 8610, lr = 0.02
I0526 02:11:09.374442 15394 main.cpp:354] Iteration 8620, loss = 0.699283
I0526 02:11:09.374496 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.699283 (* 1 = 0.699283 loss)
I0526 02:11:09.374506 15394 sgd_solver.cpp:43] Iteration 8620, lr = 0.02
I0526 02:11:20.304675 15394 main.cpp:354] Iteration 8630, loss = 0.353423
I0526 02:11:20.304743 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.353423 (* 1 = 0.353423 loss)
I0526 02:11:20.304754 15394 sgd_solver.cpp:43] Iteration 8630, lr = 0.02
I0526 02:11:32.438782 15394 main.cpp:354] Iteration 8640, loss = 0.477909
I0526 02:11:32.438849 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.477909 (* 1 = 0.477909 loss)
I0526 02:11:32.438868 15394 sgd_solver.cpp:43] Iteration 8640, lr = 0.02
I0526 02:11:43.831176 15394 main.cpp:354] Iteration 8650, loss = 0.400357
I0526 02:11:43.831241 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.400358 (* 1 = 0.400358 loss)
I0526 02:11:43.831251 15394 sgd_solver.cpp:43] Iteration 8650, lr = 0.02
I0526 02:11:55.853624 15394 main.cpp:354] Iteration 8660, loss = 0.526221
I0526 02:11:55.853690 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.526221 (* 1 = 0.526221 loss)
I0526 02:11:55.853700 15394 sgd_solver.cpp:43] Iteration 8660, lr = 0.02
I0526 02:12:07.292155 15394 main.cpp:354] Iteration 8670, loss = 0.505136
I0526 02:12:07.292214 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.505136 (* 1 = 0.505136 loss)
I0526 02:12:07.292224 15394 sgd_solver.cpp:43] Iteration 8670, lr = 0.02
I0526 02:12:18.559907 15394 main.cpp:354] Iteration 8680, loss = 0.462162
I0526 02:12:18.559978 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.462162 (* 1 = 0.462162 loss)
I0526 02:12:18.559990 15394 sgd_solver.cpp:43] Iteration 8680, lr = 0.02
I0526 02:12:29.632608 15394 main.cpp:354] Iteration 8690, loss = 0.547302
I0526 02:12:29.632666 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.547302 (* 1 = 0.547302 loss)
I0526 02:12:29.632676 15394 sgd_solver.cpp:43] Iteration 8690, lr = 0.02
I0526 02:12:40.541769 15394 main.cpp:465] Iteration 8700, Testing net (#0)
I0526 02:13:10.713527 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7122
I0526 02:13:10.713584 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.845289 (* 1 = 0.845289 loss)
I0526 02:13:11.672919 15394 main.cpp:354] Iteration 8700, loss = 0.702402
I0526 02:13:11.672978 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.702402 (* 1 = 0.702402 loss)
I0526 02:13:11.672994 15394 sgd_solver.cpp:43] Iteration 8700, lr = 0.02
I0526 02:13:22.968184 15394 main.cpp:354] Iteration 8710, loss = 0.658215
I0526 02:13:22.968246 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.658215 (* 1 = 0.658215 loss)
I0526 02:13:22.968257 15394 sgd_solver.cpp:43] Iteration 8710, lr = 0.02
I0526 02:13:34.066457 15394 main.cpp:354] Iteration 8720, loss = 0.429245
I0526 02:13:34.066520 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.429246 (* 1 = 0.429246 loss)
I0526 02:13:34.066529 15394 sgd_solver.cpp:43] Iteration 8720, lr = 0.02
I0526 02:13:45.320545 15394 main.cpp:354] Iteration 8730, loss = 0.718278
I0526 02:13:45.320603 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.718278 (* 1 = 0.718278 loss)
I0526 02:13:45.320614 15394 sgd_solver.cpp:43] Iteration 8730, lr = 0.02
I0526 02:13:57.159169 15394 main.cpp:354] Iteration 8740, loss = 0.460482
I0526 02:13:57.159227 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.460482 (* 1 = 0.460482 loss)
I0526 02:13:57.159238 15394 sgd_solver.cpp:43] Iteration 8740, lr = 0.02
I0526 02:14:09.093497 15394 main.cpp:354] Iteration 8750, loss = 0.791749
I0526 02:14:09.093560 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.791749 (* 1 = 0.791749 loss)
I0526 02:14:09.093571 15394 sgd_solver.cpp:43] Iteration 8750, lr = 0.02
I0526 02:14:20.423739 15394 main.cpp:354] Iteration 8760, loss = 0.607461
I0526 02:14:20.423813 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.607462 (* 1 = 0.607462 loss)
I0526 02:14:20.423828 15394 sgd_solver.cpp:43] Iteration 8760, lr = 0.02
I0526 02:14:31.909981 15394 main.cpp:354] Iteration 8770, loss = 0.521401
I0526 02:14:31.910050 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.521401 (* 1 = 0.521401 loss)
I0526 02:14:31.910064 15394 sgd_solver.cpp:43] Iteration 8770, lr = 0.02
I0526 02:14:43.439555 15394 main.cpp:354] Iteration 8780, loss = 0.584938
I0526 02:14:43.439620 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.584938 (* 1 = 0.584938 loss)
I0526 02:14:43.439631 15394 sgd_solver.cpp:43] Iteration 8780, lr = 0.02
I0526 02:14:54.629797 15394 main.cpp:354] Iteration 8790, loss = 0.707989
I0526 02:14:54.629858 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.707989 (* 1 = 0.707989 loss)
I0526 02:14:54.629868 15394 sgd_solver.cpp:43] Iteration 8790, lr = 0.02
I0526 02:15:04.808600 15394 main.cpp:465] Iteration 8800, Testing net (#0)
I0526 02:15:34.916990 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7255
I0526 02:15:34.917049 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.80716 (* 1 = 0.80716 loss)
I0526 02:15:35.892390 15394 main.cpp:354] Iteration 8800, loss = 0.485401
I0526 02:15:35.892453 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.485401 (* 1 = 0.485401 loss)
I0526 02:15:35.892470 15394 sgd_solver.cpp:43] Iteration 8800, lr = 0.02
I0526 02:15:46.546886 15394 main.cpp:354] Iteration 8810, loss = 0.598383
I0526 02:15:46.546952 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.598383 (* 1 = 0.598383 loss)
I0526 02:15:46.546962 15394 sgd_solver.cpp:43] Iteration 8810, lr = 0.02
I0526 02:15:57.992924 15394 main.cpp:354] Iteration 8820, loss = 0.463718
I0526 02:15:57.992993 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.463718 (* 1 = 0.463718 loss)
I0526 02:15:57.993007 15394 sgd_solver.cpp:43] Iteration 8820, lr = 0.02
I0526 02:16:09.447907 15394 main.cpp:354] Iteration 8830, loss = 0.483084
I0526 02:16:09.447981 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.483084 (* 1 = 0.483084 loss)
I0526 02:16:09.447995 15394 sgd_solver.cpp:43] Iteration 8830, lr = 0.02
I0526 02:16:19.782655 15394 main.cpp:354] Iteration 8840, loss = 0.477088
I0526 02:16:19.782732 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.477088 (* 1 = 0.477088 loss)
I0526 02:16:19.782747 15394 sgd_solver.cpp:43] Iteration 8840, lr = 0.02
I0526 02:16:31.540295 15394 main.cpp:354] Iteration 8850, loss = 0.795372
I0526 02:16:31.540380 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.795372 (* 1 = 0.795372 loss)
I0526 02:16:31.540398 15394 sgd_solver.cpp:43] Iteration 8850, lr = 0.02
I0526 02:16:43.201375 15394 main.cpp:354] Iteration 8860, loss = 0.418138
I0526 02:16:43.201437 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.418138 (* 1 = 0.418138 loss)
I0526 02:16:43.201448 15394 sgd_solver.cpp:43] Iteration 8860, lr = 0.02
I0526 02:16:53.529134 15394 main.cpp:354] Iteration 8870, loss = 0.558267
I0526 02:16:53.529201 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.558267 (* 1 = 0.558267 loss)
I0526 02:16:53.529211 15394 sgd_solver.cpp:43] Iteration 8870, lr = 0.02
I0526 02:17:04.643643 15394 main.cpp:354] Iteration 8880, loss = 0.563735
I0526 02:17:04.643710 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.563735 (* 1 = 0.563735 loss)
I0526 02:17:04.643720 15394 sgd_solver.cpp:43] Iteration 8880, lr = 0.02
I0526 02:17:16.611764 15394 main.cpp:354] Iteration 8890, loss = 0.592483
I0526 02:17:16.611835 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.592483 (* 1 = 0.592483 loss)
I0526 02:17:16.611851 15394 sgd_solver.cpp:43] Iteration 8890, lr = 0.02
I0526 02:17:26.717211 15394 main.cpp:465] Iteration 8900, Testing net (#0)
I0526 02:17:56.696586 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7019
I0526 02:17:56.696641 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.91028 (* 1 = 0.91028 loss)
I0526 02:17:57.554989 15394 main.cpp:354] Iteration 8900, loss = 0.490574
I0526 02:17:57.555049 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.490575 (* 1 = 0.490575 loss)
I0526 02:17:57.555063 15394 sgd_solver.cpp:43] Iteration 8900, lr = 0.02
I0526 02:18:09.309412 15394 main.cpp:354] Iteration 8910, loss = 0.447062
I0526 02:18:09.309474 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.447062 (* 1 = 0.447062 loss)
I0526 02:18:09.309485 15394 sgd_solver.cpp:43] Iteration 8910, lr = 0.02
I0526 02:18:21.053079 15394 main.cpp:354] Iteration 8920, loss = 0.440704
I0526 02:18:21.053136 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.440704 (* 1 = 0.440704 loss)
I0526 02:18:21.053146 15394 sgd_solver.cpp:43] Iteration 8920, lr = 0.02
I0526 02:18:31.310520 15394 main.cpp:354] Iteration 8930, loss = 0.480121
I0526 02:18:31.310588 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.480122 (* 1 = 0.480122 loss)
I0526 02:18:31.310600 15394 sgd_solver.cpp:43] Iteration 8930, lr = 0.02
I0526 02:18:41.721684 15394 main.cpp:354] Iteration 8940, loss = 0.846943
I0526 02:18:41.721756 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.846943 (* 1 = 0.846943 loss)
I0526 02:18:41.721771 15394 sgd_solver.cpp:43] Iteration 8940, lr = 0.02
I0526 02:18:52.522938 15394 main.cpp:354] Iteration 8950, loss = 0.554383
I0526 02:18:52.523006 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.554383 (* 1 = 0.554383 loss)
I0526 02:18:52.523017 15394 sgd_solver.cpp:43] Iteration 8950, lr = 0.02
I0526 02:19:03.932358 15394 main.cpp:354] Iteration 8960, loss = 1.29826
I0526 02:19:03.932422 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.29826 (* 1 = 1.29826 loss)
I0526 02:19:03.932432 15394 sgd_solver.cpp:43] Iteration 8960, lr = 0.02
I0526 02:19:15.707552 15394 main.cpp:354] Iteration 8970, loss = 0.466835
I0526 02:19:15.707631 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.466835 (* 1 = 0.466835 loss)
I0526 02:19:15.707644 15394 sgd_solver.cpp:43] Iteration 8970, lr = 0.02
I0526 02:19:26.513895 15394 main.cpp:354] Iteration 8980, loss = 0.576055
I0526 02:19:26.513977 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.576056 (* 1 = 0.576056 loss)
I0526 02:19:26.513999 15394 sgd_solver.cpp:43] Iteration 8980, lr = 0.02
I0526 02:19:37.770855 15394 main.cpp:354] Iteration 8990, loss = 0.665418
I0526 02:19:37.770933 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.665419 (* 1 = 0.665419 loss)
I0526 02:19:37.770947 15394 sgd_solver.cpp:43] Iteration 8990, lr = 0.02
I0526 02:19:48.816833 15394 main.cpp:465] Iteration 9000, Testing net (#0)
I0526 02:20:18.961889 15394 main.cpp:532]     Test net output #0: Accuracy = 0.736
I0526 02:20:18.961949 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.755332 (* 1 = 0.755332 loss)
I0526 02:20:20.055704 15394 main.cpp:354] Iteration 9000, loss = 0.409588
I0526 02:20:20.055774 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.409588 (* 1 = 0.409588 loss)
I0526 02:20:20.055793 15394 sgd_solver.cpp:43] Iteration 9000, lr = 0.02
I0526 02:20:31.498136 15394 main.cpp:354] Iteration 9010, loss = 0.748684
I0526 02:20:31.498205 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.748684 (* 1 = 0.748684 loss)
I0526 02:20:31.498219 15394 sgd_solver.cpp:43] Iteration 9010, lr = 0.02
I0526 02:20:43.272335 15394 main.cpp:354] Iteration 9020, loss = 0.517028
I0526 02:20:43.272406 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.517028 (* 1 = 0.517028 loss)
I0526 02:20:43.272420 15394 sgd_solver.cpp:43] Iteration 9020, lr = 0.02
I0526 02:20:54.479810 15394 main.cpp:354] Iteration 9030, loss = 0.499725
I0526 02:20:54.479881 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.499725 (* 1 = 0.499725 loss)
I0526 02:20:54.479892 15394 sgd_solver.cpp:43] Iteration 9030, lr = 0.02
I0526 02:21:04.903864 15394 main.cpp:354] Iteration 9040, loss = 0.545282
I0526 02:21:04.903937 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.545282 (* 1 = 0.545282 loss)
I0526 02:21:04.903952 15394 sgd_solver.cpp:43] Iteration 9040, lr = 0.02
I0526 02:21:15.816145 15394 main.cpp:354] Iteration 9050, loss = 0.456703
I0526 02:21:15.816215 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.456704 (* 1 = 0.456704 loss)
I0526 02:21:15.816231 15394 sgd_solver.cpp:43] Iteration 9050, lr = 0.02
I0526 02:21:26.651793 15394 main.cpp:354] Iteration 9060, loss = 0.435782
I0526 02:21:26.651857 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.435782 (* 1 = 0.435782 loss)
I0526 02:21:26.651867 15394 sgd_solver.cpp:43] Iteration 9060, lr = 0.02
I0526 02:21:38.689096 15394 main.cpp:354] Iteration 9070, loss = 0.573905
I0526 02:21:38.689170 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.573905 (* 1 = 0.573905 loss)
I0526 02:21:38.689188 15394 sgd_solver.cpp:43] Iteration 9070, lr = 0.02
I0526 02:21:49.854416 15394 main.cpp:354] Iteration 9080, loss = 0.63284
I0526 02:21:49.854475 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.63284 (* 1 = 0.63284 loss)
I0526 02:21:49.854485 15394 sgd_solver.cpp:43] Iteration 9080, lr = 0.02
I0526 02:22:01.625017 15394 main.cpp:354] Iteration 9090, loss = 0.546686
I0526 02:22:01.625078 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.546686 (* 1 = 0.546686 loss)
I0526 02:22:01.625088 15394 sgd_solver.cpp:43] Iteration 9090, lr = 0.02
I0526 02:22:11.081519 15394 main.cpp:465] Iteration 9100, Testing net (#0)
I0526 02:22:41.215540 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7213
I0526 02:22:41.215597 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.801061 (* 1 = 0.801061 loss)
I0526 02:22:42.351105 15394 main.cpp:354] Iteration 9100, loss = 0.526637
I0526 02:22:42.351168 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.526638 (* 1 = 0.526638 loss)
I0526 02:22:42.351182 15394 sgd_solver.cpp:43] Iteration 9100, lr = 0.02
I0526 02:22:53.250644 15394 main.cpp:354] Iteration 9110, loss = 0.524802
I0526 02:22:53.250704 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.524802 (* 1 = 0.524802 loss)
I0526 02:22:53.250713 15394 sgd_solver.cpp:43] Iteration 9110, lr = 0.02
I0526 02:23:04.762303 15394 main.cpp:354] Iteration 9120, loss = 0.519193
I0526 02:23:04.762374 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.519193 (* 1 = 0.519193 loss)
I0526 02:23:04.762385 15394 sgd_solver.cpp:43] Iteration 9120, lr = 0.02
I0526 02:23:16.116071 15394 main.cpp:354] Iteration 9130, loss = 0.571731
I0526 02:23:16.116137 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.571731 (* 1 = 0.571731 loss)
I0526 02:23:16.116147 15394 sgd_solver.cpp:43] Iteration 9130, lr = 0.02
I0526 02:23:26.866719 15394 main.cpp:354] Iteration 9140, loss = 0.487819
I0526 02:23:26.866781 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.487819 (* 1 = 0.487819 loss)
I0526 02:23:26.866792 15394 sgd_solver.cpp:43] Iteration 9140, lr = 0.02
I0526 02:23:38.159706 15394 main.cpp:354] Iteration 9150, loss = 0.543819
I0526 02:23:38.159762 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.54382 (* 1 = 0.54382 loss)
I0526 02:23:38.159772 15394 sgd_solver.cpp:43] Iteration 9150, lr = 0.02
I0526 02:23:49.924387 15394 main.cpp:354] Iteration 9160, loss = 0.531279
I0526 02:23:49.924454 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.53128 (* 1 = 0.53128 loss)
I0526 02:23:49.924464 15394 sgd_solver.cpp:43] Iteration 9160, lr = 0.02
I0526 02:24:01.070956 15394 main.cpp:354] Iteration 9170, loss = 0.580964
I0526 02:24:01.071022 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.580964 (* 1 = 0.580964 loss)
I0526 02:24:01.071033 15394 sgd_solver.cpp:43] Iteration 9170, lr = 0.02
I0526 02:24:12.290485 15394 main.cpp:354] Iteration 9180, loss = 0.336778
I0526 02:24:12.290549 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.336778 (* 1 = 0.336778 loss)
I0526 02:24:12.290560 15394 sgd_solver.cpp:43] Iteration 9180, lr = 0.02
I0526 02:24:23.068261 15394 main.cpp:354] Iteration 9190, loss = 0.466069
I0526 02:24:23.068320 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.466069 (* 1 = 0.466069 loss)
I0526 02:24:23.068331 15394 sgd_solver.cpp:43] Iteration 9190, lr = 0.02
I0526 02:24:33.125838 15394 main.cpp:465] Iteration 9200, Testing net (#0)
I0526 02:25:03.120594 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7468
I0526 02:25:03.120652 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.726298 (* 1 = 0.726298 loss)
I0526 02:25:04.161010 15394 main.cpp:354] Iteration 9200, loss = 0.567793
I0526 02:25:04.161075 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.567793 (* 1 = 0.567793 loss)
I0526 02:25:04.161092 15394 sgd_solver.cpp:43] Iteration 9200, lr = 0.02
I0526 02:25:14.433677 15394 main.cpp:354] Iteration 9210, loss = 0.472781
I0526 02:25:14.433745 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.472781 (* 1 = 0.472781 loss)
I0526 02:25:14.433759 15394 sgd_solver.cpp:43] Iteration 9210, lr = 0.02
I0526 02:25:26.010516 15394 main.cpp:354] Iteration 9220, loss = 0.402155
I0526 02:25:26.010581 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.402156 (* 1 = 0.402156 loss)
I0526 02:25:26.010591 15394 sgd_solver.cpp:43] Iteration 9220, lr = 0.02
I0526 02:25:37.373520 15394 main.cpp:354] Iteration 9230, loss = 0.610828
I0526 02:25:37.373584 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.610828 (* 1 = 0.610828 loss)
I0526 02:25:37.373594 15394 sgd_solver.cpp:43] Iteration 9230, lr = 0.02
I0526 02:25:48.519245 15394 main.cpp:354] Iteration 9240, loss = 0.491971
I0526 02:25:48.519300 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.491971 (* 1 = 0.491971 loss)
I0526 02:25:48.519311 15394 sgd_solver.cpp:43] Iteration 9240, lr = 0.02
I0526 02:25:59.360045 15394 main.cpp:354] Iteration 9250, loss = 0.774116
I0526 02:25:59.360110 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.774116 (* 1 = 0.774116 loss)
I0526 02:25:59.360121 15394 sgd_solver.cpp:43] Iteration 9250, lr = 0.02
I0526 02:26:11.262323 15394 main.cpp:354] Iteration 9260, loss = 0.422982
I0526 02:26:11.262395 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.422982 (* 1 = 0.422982 loss)
I0526 02:26:11.262413 15394 sgd_solver.cpp:43] Iteration 9260, lr = 0.02
I0526 02:26:21.884052 15394 main.cpp:354] Iteration 9270, loss = 0.478004
I0526 02:26:21.884115 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.478005 (* 1 = 0.478005 loss)
I0526 02:26:21.884124 15394 sgd_solver.cpp:43] Iteration 9270, lr = 0.02
I0526 02:26:33.522650 15394 main.cpp:354] Iteration 9280, loss = 0.649446
I0526 02:26:33.522716 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.649446 (* 1 = 0.649446 loss)
I0526 02:26:33.522725 15394 sgd_solver.cpp:43] Iteration 9280, lr = 0.02
I0526 02:26:44.826668 15394 main.cpp:354] Iteration 9290, loss = 0.670828
I0526 02:26:44.826731 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.670828 (* 1 = 0.670828 loss)
I0526 02:26:44.826740 15394 sgd_solver.cpp:43] Iteration 9290, lr = 0.02
I0526 02:26:56.150542 15394 main.cpp:465] Iteration 9300, Testing net (#0)
I0526 02:27:26.219583 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6493
I0526 02:27:26.219640 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.0115 (* 1 = 1.0115 loss)
I0526 02:27:27.333255 15394 main.cpp:354] Iteration 9300, loss = 0.505432
I0526 02:27:27.333314 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.505432 (* 1 = 0.505432 loss)
I0526 02:27:27.333330 15394 sgd_solver.cpp:43] Iteration 9300, lr = 0.02
I0526 02:27:38.535071 15394 main.cpp:354] Iteration 9310, loss = 0.616438
I0526 02:27:38.535136 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.616438 (* 1 = 0.616438 loss)
I0526 02:27:38.535146 15394 sgd_solver.cpp:43] Iteration 9310, lr = 0.02
I0526 02:27:50.354946 15394 main.cpp:354] Iteration 9320, loss = 0.616194
I0526 02:27:50.355007 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.616194 (* 1 = 0.616194 loss)
I0526 02:27:50.355017 15394 sgd_solver.cpp:43] Iteration 9320, lr = 0.02
I0526 02:28:01.250525 15394 main.cpp:354] Iteration 9330, loss = 0.885881
I0526 02:28:01.250586 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.885881 (* 1 = 0.885881 loss)
I0526 02:28:01.250597 15394 sgd_solver.cpp:43] Iteration 9330, lr = 0.02
I0526 02:28:12.562723 15394 main.cpp:354] Iteration 9340, loss = 0.375069
I0526 02:28:12.562790 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.37507 (* 1 = 0.37507 loss)
I0526 02:28:12.562804 15394 sgd_solver.cpp:43] Iteration 9340, lr = 0.02
I0526 02:28:23.974197 15394 main.cpp:354] Iteration 9350, loss = 0.481482
I0526 02:28:23.974256 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.481482 (* 1 = 0.481482 loss)
I0526 02:28:23.974267 15394 sgd_solver.cpp:43] Iteration 9350, lr = 0.02
I0526 02:28:35.340505 15394 main.cpp:354] Iteration 9360, loss = 0.431495
I0526 02:28:35.340572 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.431495 (* 1 = 0.431495 loss)
I0526 02:28:35.340585 15394 sgd_solver.cpp:43] Iteration 9360, lr = 0.02
I0526 02:28:47.131716 15394 main.cpp:354] Iteration 9370, loss = 0.549025
I0526 02:28:47.131793 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.549025 (* 1 = 0.549025 loss)
I0526 02:28:47.131806 15394 sgd_solver.cpp:43] Iteration 9370, lr = 0.02
I0526 02:28:58.089607 15394 main.cpp:354] Iteration 9380, loss = 0.6978
I0526 02:28:58.089673 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.697801 (* 1 = 0.697801 loss)
I0526 02:28:58.089684 15394 sgd_solver.cpp:43] Iteration 9380, lr = 0.02
I0526 02:29:09.269058 15394 main.cpp:354] Iteration 9390, loss = 0.755938
I0526 02:29:09.269124 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.755938 (* 1 = 0.755938 loss)
I0526 02:29:09.269135 15394 sgd_solver.cpp:43] Iteration 9390, lr = 0.02
I0526 02:29:20.035372 15394 main.cpp:465] Iteration 9400, Testing net (#0)
I0526 02:29:50.007688 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7344
I0526 02:29:50.007760 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.767058 (* 1 = 0.767058 loss)
I0526 02:29:50.791496 15394 main.cpp:354] Iteration 9400, loss = 0.579209
I0526 02:29:50.791563 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.579209 (* 1 = 0.579209 loss)
I0526 02:29:50.791575 15394 sgd_solver.cpp:43] Iteration 9400, lr = 0.02
I0526 02:30:01.695833 15394 main.cpp:354] Iteration 9410, loss = 0.512997
I0526 02:30:01.695899 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.512997 (* 1 = 0.512997 loss)
I0526 02:30:01.695909 15394 sgd_solver.cpp:43] Iteration 9410, lr = 0.02
I0526 02:30:12.960482 15394 main.cpp:354] Iteration 9420, loss = 0.52463
I0526 02:30:12.960546 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.524631 (* 1 = 0.524631 loss)
I0526 02:30:12.960556 15394 sgd_solver.cpp:43] Iteration 9420, lr = 0.02
I0526 02:30:24.543145 15394 main.cpp:354] Iteration 9430, loss = 0.641739
I0526 02:30:24.543210 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.641739 (* 1 = 0.641739 loss)
I0526 02:30:24.543220 15394 sgd_solver.cpp:43] Iteration 9430, lr = 0.02
I0526 02:30:35.389277 15394 main.cpp:354] Iteration 9440, loss = 0.477346
I0526 02:30:35.389340 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.477346 (* 1 = 0.477346 loss)
I0526 02:30:35.389350 15394 sgd_solver.cpp:43] Iteration 9440, lr = 0.02
I0526 02:30:47.338659 15394 main.cpp:354] Iteration 9450, loss = 0.451952
I0526 02:30:47.338719 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.451952 (* 1 = 0.451952 loss)
I0526 02:30:47.338728 15394 sgd_solver.cpp:43] Iteration 9450, lr = 0.02
I0526 02:30:58.471657 15394 main.cpp:354] Iteration 9460, loss = 0.786411
I0526 02:30:58.471721 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.786411 (* 1 = 0.786411 loss)
I0526 02:30:58.471732 15394 sgd_solver.cpp:43] Iteration 9460, lr = 0.02
I0526 02:31:09.998414 15394 main.cpp:354] Iteration 9470, loss = 0.533037
I0526 02:31:09.998479 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.533038 (* 1 = 0.533038 loss)
I0526 02:31:09.998489 15394 sgd_solver.cpp:43] Iteration 9470, lr = 0.02
I0526 02:31:21.691167 15394 main.cpp:354] Iteration 9480, loss = 0.605451
I0526 02:31:21.691233 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.605451 (* 1 = 0.605451 loss)
I0526 02:31:21.691243 15394 sgd_solver.cpp:43] Iteration 9480, lr = 0.02
I0526 02:31:32.858767 15394 main.cpp:354] Iteration 9490, loss = 0.627424
I0526 02:31:32.858841 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.627424 (* 1 = 0.627424 loss)
I0526 02:31:32.858855 15394 sgd_solver.cpp:43] Iteration 9490, lr = 0.02
I0526 02:31:42.915016 15394 main.cpp:465] Iteration 9500, Testing net (#0)
I0526 02:32:12.984786 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6808
I0526 02:32:12.984846 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.998629 (* 1 = 0.998629 loss)
I0526 02:32:13.875146 15394 main.cpp:354] Iteration 9500, loss = 0.625764
I0526 02:32:13.875216 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.625764 (* 1 = 0.625764 loss)
I0526 02:32:13.875229 15394 sgd_solver.cpp:43] Iteration 9500, lr = 0.02
I0526 02:32:25.392382 15394 main.cpp:354] Iteration 9510, loss = 0.614768
I0526 02:32:25.392455 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.614768 (* 1 = 0.614768 loss)
I0526 02:32:25.392474 15394 sgd_solver.cpp:43] Iteration 9510, lr = 0.02
I0526 02:32:37.339509 15394 main.cpp:354] Iteration 9520, loss = 0.657097
I0526 02:32:37.339577 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.657097 (* 1 = 0.657097 loss)
I0526 02:32:37.339588 15394 sgd_solver.cpp:43] Iteration 9520, lr = 0.02
I0526 02:32:48.214836 15394 main.cpp:354] Iteration 9530, loss = 0.452759
I0526 02:32:48.214905 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.452759 (* 1 = 0.452759 loss)
I0526 02:32:48.214920 15394 sgd_solver.cpp:43] Iteration 9530, lr = 0.02
I0526 02:32:59.668781 15394 main.cpp:354] Iteration 9540, loss = 0.460859
I0526 02:32:59.668848 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.460859 (* 1 = 0.460859 loss)
I0526 02:32:59.668867 15394 sgd_solver.cpp:43] Iteration 9540, lr = 0.02
I0526 02:33:11.295248 15394 main.cpp:354] Iteration 9550, loss = 0.568218
I0526 02:33:11.295310 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.568218 (* 1 = 0.568218 loss)
I0526 02:33:11.295320 15394 sgd_solver.cpp:43] Iteration 9550, lr = 0.02
I0526 02:33:23.146872 15394 main.cpp:354] Iteration 9560, loss = 0.547874
I0526 02:33:23.146931 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.547874 (* 1 = 0.547874 loss)
I0526 02:33:23.146941 15394 sgd_solver.cpp:43] Iteration 9560, lr = 0.02
I0526 02:33:34.771646 15394 main.cpp:354] Iteration 9570, loss = 0.379333
I0526 02:33:34.771708 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.379333 (* 1 = 0.379333 loss)
I0526 02:33:34.771718 15394 sgd_solver.cpp:43] Iteration 9570, lr = 0.02
I0526 02:33:46.241153 15394 main.cpp:354] Iteration 9580, loss = 0.429008
I0526 02:33:46.241216 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.429008 (* 1 = 0.429008 loss)
I0526 02:33:46.241226 15394 sgd_solver.cpp:43] Iteration 9580, lr = 0.02
I0526 02:33:57.778529 15394 main.cpp:354] Iteration 9590, loss = 0.562503
I0526 02:33:57.778592 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.562503 (* 1 = 0.562503 loss)
I0526 02:33:57.778602 15394 sgd_solver.cpp:43] Iteration 9590, lr = 0.02
I0526 02:34:08.158159 15394 main.cpp:465] Iteration 9600, Testing net (#0)
I0526 02:34:38.348773 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7599
I0526 02:34:38.348829 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.69499 (* 1 = 0.69499 loss)
I0526 02:34:39.505659 15394 main.cpp:354] Iteration 9600, loss = 0.474535
I0526 02:34:39.505723 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.474536 (* 1 = 0.474536 loss)
I0526 02:34:39.505739 15394 sgd_solver.cpp:43] Iteration 9600, lr = 0.02
I0526 02:34:50.913195 15394 main.cpp:354] Iteration 9610, loss = 0.758746
I0526 02:34:50.913264 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.758746 (* 1 = 0.758746 loss)
I0526 02:34:50.913277 15394 sgd_solver.cpp:43] Iteration 9610, lr = 0.02
I0526 02:35:01.391960 15394 main.cpp:354] Iteration 9620, loss = 0.511945
I0526 02:35:01.392020 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.511945 (* 1 = 0.511945 loss)
I0526 02:35:01.392030 15394 sgd_solver.cpp:43] Iteration 9620, lr = 0.02
I0526 02:35:12.621264 15394 main.cpp:354] Iteration 9630, loss = 0.5396
I0526 02:35:12.621325 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.5396 (* 1 = 0.5396 loss)
I0526 02:35:12.621340 15394 sgd_solver.cpp:43] Iteration 9630, lr = 0.02
I0526 02:35:23.731176 15394 main.cpp:354] Iteration 9640, loss = 0.57019
I0526 02:35:23.731230 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.570191 (* 1 = 0.570191 loss)
I0526 02:35:23.731240 15394 sgd_solver.cpp:43] Iteration 9640, lr = 0.02
I0526 02:35:35.497789 15394 main.cpp:354] Iteration 9650, loss = 0.480882
I0526 02:35:35.497853 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.480882 (* 1 = 0.480882 loss)
I0526 02:35:35.497862 15394 sgd_solver.cpp:43] Iteration 9650, lr = 0.02
I0526 02:35:47.213335 15394 main.cpp:354] Iteration 9660, loss = 0.470222
I0526 02:35:47.213402 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.470223 (* 1 = 0.470223 loss)
I0526 02:35:47.213413 15394 sgd_solver.cpp:43] Iteration 9660, lr = 0.02
I0526 02:35:58.127463 15394 main.cpp:354] Iteration 9670, loss = 0.58601
I0526 02:35:58.127523 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.58601 (* 1 = 0.58601 loss)
I0526 02:35:58.127533 15394 sgd_solver.cpp:43] Iteration 9670, lr = 0.02
I0526 02:36:08.332547 15394 main.cpp:354] Iteration 9680, loss = 0.5938
I0526 02:36:08.332603 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.5938 (* 1 = 0.5938 loss)
I0526 02:36:08.332613 15394 sgd_solver.cpp:43] Iteration 9680, lr = 0.02
I0526 02:36:19.427536 15394 main.cpp:354] Iteration 9690, loss = 0.603925
I0526 02:36:19.427598 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.603925 (* 1 = 0.603925 loss)
I0526 02:36:19.427608 15394 sgd_solver.cpp:43] Iteration 9690, lr = 0.02
I0526 02:36:29.918540 15394 main.cpp:465] Iteration 9700, Testing net (#0)
I0526 02:37:00.122875 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6964
I0526 02:37:00.122936 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.951678 (* 1 = 0.951678 loss)
I0526 02:37:01.315994 15394 main.cpp:354] Iteration 9700, loss = 0.489599
I0526 02:37:01.316061 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.489599 (* 1 = 0.489599 loss)
I0526 02:37:01.316076 15394 sgd_solver.cpp:43] Iteration 9700, lr = 0.02
I0526 02:37:12.465095 15394 main.cpp:354] Iteration 9710, loss = 0.843151
I0526 02:37:12.465157 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.843151 (* 1 = 0.843151 loss)
I0526 02:37:12.465168 15394 sgd_solver.cpp:43] Iteration 9710, lr = 0.02
I0526 02:37:23.497217 15394 main.cpp:354] Iteration 9720, loss = 0.552574
I0526 02:37:23.497290 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.552574 (* 1 = 0.552574 loss)
I0526 02:37:23.497303 15394 sgd_solver.cpp:43] Iteration 9720, lr = 0.02
I0526 02:37:35.705842 15394 main.cpp:354] Iteration 9730, loss = 0.504525
I0526 02:37:35.705910 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.504525 (* 1 = 0.504525 loss)
I0526 02:37:35.705925 15394 sgd_solver.cpp:43] Iteration 9730, lr = 0.02
I0526 02:37:46.909456 15394 main.cpp:354] Iteration 9740, loss = 0.287427
I0526 02:37:46.909530 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.287427 (* 1 = 0.287427 loss)
I0526 02:37:46.909544 15394 sgd_solver.cpp:43] Iteration 9740, lr = 0.02
I0526 02:37:57.832329 15394 main.cpp:354] Iteration 9750, loss = 0.739191
I0526 02:37:57.832398 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.739191 (* 1 = 0.739191 loss)
I0526 02:37:57.832413 15394 sgd_solver.cpp:43] Iteration 9750, lr = 0.02
I0526 02:38:08.816692 15394 main.cpp:354] Iteration 9760, loss = 0.630771
I0526 02:38:08.816756 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.630771 (* 1 = 0.630771 loss)
I0526 02:38:08.816767 15394 sgd_solver.cpp:43] Iteration 9760, lr = 0.02
I0526 02:38:20.758287 15394 main.cpp:354] Iteration 9770, loss = 0.763782
I0526 02:38:20.758358 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.763782 (* 1 = 0.763782 loss)
I0526 02:38:20.758368 15394 sgd_solver.cpp:43] Iteration 9770, lr = 0.02
I0526 02:38:31.661773 15394 main.cpp:354] Iteration 9780, loss = 0.721064
I0526 02:38:31.661837 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.721065 (* 1 = 0.721065 loss)
I0526 02:38:31.661847 15394 sgd_solver.cpp:43] Iteration 9780, lr = 0.02
I0526 02:38:42.407377 15394 main.cpp:354] Iteration 9790, loss = 0.435041
I0526 02:38:42.407449 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.435041 (* 1 = 0.435041 loss)
I0526 02:38:42.407464 15394 sgd_solver.cpp:43] Iteration 9790, lr = 0.02
I0526 02:38:52.689431 15394 main.cpp:465] Iteration 9800, Testing net (#0)
I0526 02:39:23.017400 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6508
I0526 02:39:23.017482 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.07957 (* 1 = 1.07957 loss)
I0526 02:39:23.788138 15394 main.cpp:354] Iteration 9800, loss = 0.769952
I0526 02:39:23.788204 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.769952 (* 1 = 0.769952 loss)
I0526 02:39:23.788219 15394 sgd_solver.cpp:43] Iteration 9800, lr = 0.02
I0526 02:39:34.722733 15394 main.cpp:354] Iteration 9810, loss = 0.587532
I0526 02:39:34.722803 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.587532 (* 1 = 0.587532 loss)
I0526 02:39:34.722817 15394 sgd_solver.cpp:43] Iteration 9810, lr = 0.02
I0526 02:39:46.021296 15394 main.cpp:354] Iteration 9820, loss = 0.451867
I0526 02:39:46.021361 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.451868 (* 1 = 0.451868 loss)
I0526 02:39:46.021390 15394 sgd_solver.cpp:43] Iteration 9820, lr = 0.02
I0526 02:39:57.930156 15394 main.cpp:354] Iteration 9830, loss = 0.560756
I0526 02:39:57.930223 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.560757 (* 1 = 0.560757 loss)
I0526 02:39:57.930234 15394 sgd_solver.cpp:43] Iteration 9830, lr = 0.02
I0526 02:40:09.332644 15394 main.cpp:354] Iteration 9840, loss = 0.401864
I0526 02:40:09.332700 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.401864 (* 1 = 0.401864 loss)
I0526 02:40:09.332711 15394 sgd_solver.cpp:43] Iteration 9840, lr = 0.02
I0526 02:40:20.342401 15394 main.cpp:354] Iteration 9850, loss = 0.429742
I0526 02:40:20.342465 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.429743 (* 1 = 0.429743 loss)
I0526 02:40:20.342475 15394 sgd_solver.cpp:43] Iteration 9850, lr = 0.02
I0526 02:40:31.611968 15394 main.cpp:354] Iteration 9860, loss = 0.400124
I0526 02:40:31.612041 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.400125 (* 1 = 0.400125 loss)
I0526 02:40:31.612054 15394 sgd_solver.cpp:43] Iteration 9860, lr = 0.02
I0526 02:40:42.302592 15394 main.cpp:354] Iteration 9870, loss = 0.642717
I0526 02:40:42.302661 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.642717 (* 1 = 0.642717 loss)
I0526 02:40:42.302680 15394 sgd_solver.cpp:43] Iteration 9870, lr = 0.02
I0526 02:40:54.031397 15394 main.cpp:354] Iteration 9880, loss = 0.407019
I0526 02:40:54.031461 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.407019 (* 1 = 0.407019 loss)
I0526 02:40:54.031474 15394 sgd_solver.cpp:43] Iteration 9880, lr = 0.02
I0526 02:41:05.307684 15394 main.cpp:354] Iteration 9890, loss = 0.519379
I0526 02:41:05.307747 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.51938 (* 1 = 0.51938 loss)
I0526 02:41:05.307757 15394 sgd_solver.cpp:43] Iteration 9890, lr = 0.02
I0526 02:41:15.632935 15394 main.cpp:465] Iteration 9900, Testing net (#0)
I0526 02:41:45.841949 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7561
I0526 02:41:45.842006 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.71728 (* 1 = 0.71728 loss)
I0526 02:41:46.770161 15394 main.cpp:354] Iteration 9900, loss = 0.595272
I0526 02:41:46.770226 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.595272 (* 1 = 0.595272 loss)
I0526 02:41:46.770243 15394 sgd_solver.cpp:43] Iteration 9900, lr = 0.02
I0526 02:41:57.747556 15394 main.cpp:354] Iteration 9910, loss = 0.60987
I0526 02:41:57.747612 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.60987 (* 1 = 0.60987 loss)
I0526 02:41:57.747622 15394 sgd_solver.cpp:43] Iteration 9910, lr = 0.02
I0526 02:42:09.156199 15394 main.cpp:354] Iteration 9920, loss = 0.63651
I0526 02:42:09.156262 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.63651 (* 1 = 0.63651 loss)
I0526 02:42:09.156273 15394 sgd_solver.cpp:43] Iteration 9920, lr = 0.02
I0526 02:42:20.773707 15394 main.cpp:354] Iteration 9930, loss = 0.46593
I0526 02:42:20.773769 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.46593 (* 1 = 0.46593 loss)
I0526 02:42:20.773780 15394 sgd_solver.cpp:43] Iteration 9930, lr = 0.02
I0526 02:42:30.573158 15394 main.cpp:354] Iteration 9940, loss = 0.675614
I0526 02:42:30.573231 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.675614 (* 1 = 0.675614 loss)
I0526 02:42:30.573241 15394 sgd_solver.cpp:43] Iteration 9940, lr = 0.02
I0526 02:42:41.756502 15394 main.cpp:354] Iteration 9950, loss = 0.44244
I0526 02:42:41.756566 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.442441 (* 1 = 0.442441 loss)
I0526 02:42:41.756575 15394 sgd_solver.cpp:43] Iteration 9950, lr = 0.02
I0526 02:42:53.426987 15394 main.cpp:354] Iteration 9960, loss = 0.394259
I0526 02:42:53.427052 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.394259 (* 1 = 0.394259 loss)
I0526 02:42:53.427062 15394 sgd_solver.cpp:43] Iteration 9960, lr = 0.02
I0526 02:43:04.798154 15394 main.cpp:354] Iteration 9970, loss = 0.46156
I0526 02:43:04.798215 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.46156 (* 1 = 0.46156 loss)
I0526 02:43:04.798225 15394 sgd_solver.cpp:43] Iteration 9970, lr = 0.02
I0526 02:43:16.604789 15394 main.cpp:354] Iteration 9980, loss = 0.546806
I0526 02:43:16.604862 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.546807 (* 1 = 0.546807 loss)
I0526 02:43:16.604872 15394 sgd_solver.cpp:43] Iteration 9980, lr = 0.02
I0526 02:43:28.402252 15394 main.cpp:354] Iteration 9990, loss = 0.448497
I0526 02:43:28.402318 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.448497 (* 1 = 0.448497 loss)
I0526 02:43:28.402333 15394 sgd_solver.cpp:43] Iteration 9990, lr = 0.02
I0526 02:43:38.864058 15394 main.cpp:465] Iteration 10000, Testing net (#0)
I0526 02:44:09.410373 15394 main.cpp:532]     Test net output #0: Accuracy = 0.748
I0526 02:44:09.410424 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.752364 (* 1 = 0.752364 loss)
I0526 02:44:10.436338 15394 main.cpp:354] Iteration 10000, loss = 0.536136
I0526 02:44:10.436409 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.536137 (* 1 = 0.536137 loss)
I0526 02:44:10.436425 15394 sgd_solver.cpp:43] Iteration 10000, lr = 0.02
I0526 02:44:21.363728 15394 main.cpp:354] Iteration 10010, loss = 0.467686
I0526 02:44:21.363806 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.467686 (* 1 = 0.467686 loss)
I0526 02:44:21.363817 15394 sgd_solver.cpp:43] Iteration 10010, lr = 0.02
I0526 02:44:32.763977 15394 main.cpp:354] Iteration 10020, loss = 0.533726
I0526 02:44:32.764050 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.533726 (* 1 = 0.533726 loss)
I0526 02:44:32.764067 15394 sgd_solver.cpp:43] Iteration 10020, lr = 0.02
I0526 02:44:43.947926 15394 main.cpp:354] Iteration 10030, loss = 0.680432
I0526 02:44:43.947989 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.680432 (* 1 = 0.680432 loss)
I0526 02:44:43.947999 15394 sgd_solver.cpp:43] Iteration 10030, lr = 0.02
I0526 02:44:55.299187 15394 main.cpp:354] Iteration 10040, loss = 0.526595
I0526 02:44:55.299253 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.526595 (* 1 = 0.526595 loss)
I0526 02:44:55.299263 15394 sgd_solver.cpp:43] Iteration 10040, lr = 0.02
I0526 02:45:06.207957 15394 main.cpp:354] Iteration 10050, loss = 0.699761
I0526 02:45:06.208036 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.699762 (* 1 = 0.699762 loss)
I0526 02:45:06.208051 15394 sgd_solver.cpp:43] Iteration 10050, lr = 0.02
I0526 02:45:18.070008 15394 main.cpp:354] Iteration 10060, loss = 0.528871
I0526 02:45:18.070085 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.528871 (* 1 = 0.528871 loss)
I0526 02:45:18.070094 15394 sgd_solver.cpp:43] Iteration 10060, lr = 0.02
I0526 02:45:29.599654 15394 main.cpp:354] Iteration 10070, loss = 0.478984
I0526 02:45:29.599730 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.478984 (* 1 = 0.478984 loss)
I0526 02:45:29.599745 15394 sgd_solver.cpp:43] Iteration 10070, lr = 0.02
I0526 02:45:41.558589 15394 main.cpp:354] Iteration 10080, loss = 0.353849
I0526 02:45:41.558660 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.353849 (* 1 = 0.353849 loss)
I0526 02:45:41.558675 15394 sgd_solver.cpp:43] Iteration 10080, lr = 0.02
I0526 02:45:52.837103 15394 main.cpp:354] Iteration 10090, loss = 0.670434
I0526 02:45:52.837175 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.670434 (* 1 = 0.670434 loss)
I0526 02:45:52.837190 15394 sgd_solver.cpp:43] Iteration 10090, lr = 0.02
I0526 02:46:03.817263 15394 main.cpp:465] Iteration 10100, Testing net (#0)
I0526 02:46:34.440008 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6909
I0526 02:46:34.440071 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.925565 (* 1 = 0.925565 loss)
I0526 02:46:35.502171 15394 main.cpp:354] Iteration 10100, loss = 0.530805
I0526 02:46:35.502234 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.530805 (* 1 = 0.530805 loss)
I0526 02:46:35.502255 15394 sgd_solver.cpp:43] Iteration 10100, lr = 0.02
I0526 02:46:46.634344 15394 main.cpp:354] Iteration 10110, loss = 0.565123
I0526 02:46:46.634423 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.565124 (* 1 = 0.565124 loss)
I0526 02:46:46.634433 15394 sgd_solver.cpp:43] Iteration 10110, lr = 0.02
I0526 02:46:57.777552 15394 main.cpp:354] Iteration 10120, loss = 0.366208
I0526 02:46:57.777607 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.366208 (* 1 = 0.366208 loss)
I0526 02:46:57.777618 15394 sgd_solver.cpp:43] Iteration 10120, lr = 0.02
I0526 02:47:09.878309 15394 main.cpp:354] Iteration 10130, loss = 0.473864
I0526 02:47:09.878376 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.473864 (* 1 = 0.473864 loss)
I0526 02:47:09.878386 15394 sgd_solver.cpp:43] Iteration 10130, lr = 0.02
I0526 02:47:21.396143 15394 main.cpp:354] Iteration 10140, loss = 0.474223
I0526 02:47:21.396220 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.474223 (* 1 = 0.474223 loss)
I0526 02:47:21.396231 15394 sgd_solver.cpp:43] Iteration 10140, lr = 0.02
I0526 02:47:32.478962 15394 main.cpp:354] Iteration 10150, loss = 0.474172
I0526 02:47:32.479028 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.474172 (* 1 = 0.474172 loss)
I0526 02:47:32.479039 15394 sgd_solver.cpp:43] Iteration 10150, lr = 0.02
I0526 02:47:43.464756 15394 main.cpp:354] Iteration 10160, loss = 0.469629
I0526 02:47:43.464812 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.469629 (* 1 = 0.469629 loss)
I0526 02:47:43.464823 15394 sgd_solver.cpp:43] Iteration 10160, lr = 0.02
I0526 02:47:55.062119 15394 main.cpp:354] Iteration 10170, loss = 0.510682
I0526 02:47:55.062183 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.510683 (* 1 = 0.510683 loss)
I0526 02:47:55.062193 15394 sgd_solver.cpp:43] Iteration 10170, lr = 0.02
I0526 02:48:05.821673 15394 main.cpp:354] Iteration 10180, loss = 0.527971
I0526 02:48:05.821738 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.527971 (* 1 = 0.527971 loss)
I0526 02:48:05.821748 15394 sgd_solver.cpp:43] Iteration 10180, lr = 0.02
I0526 02:48:16.787335 15394 main.cpp:354] Iteration 10190, loss = 0.447383
I0526 02:48:16.787410 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.447384 (* 1 = 0.447384 loss)
I0526 02:48:16.787418 15394 sgd_solver.cpp:43] Iteration 10190, lr = 0.02
I0526 02:48:27.276654 15394 main.cpp:465] Iteration 10200, Testing net (#0)
I0526 02:48:57.812696 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6952
I0526 02:48:57.812752 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.882056 (* 1 = 0.882056 loss)
I0526 02:48:58.844316 15394 main.cpp:354] Iteration 10200, loss = 0.541583
I0526 02:48:58.844378 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.541583 (* 1 = 0.541583 loss)
I0526 02:48:58.844394 15394 sgd_solver.cpp:43] Iteration 10200, lr = 0.02
I0526 02:49:09.904541 15394 main.cpp:354] Iteration 10210, loss = 0.524987
I0526 02:49:09.904610 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.524987 (* 1 = 0.524987 loss)
I0526 02:49:09.904620 15394 sgd_solver.cpp:43] Iteration 10210, lr = 0.02
I0526 02:49:20.958776 15394 main.cpp:354] Iteration 10220, loss = 0.670501
I0526 02:49:20.958858 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.670501 (* 1 = 0.670501 loss)
I0526 02:49:20.958870 15394 sgd_solver.cpp:43] Iteration 10220, lr = 0.02
I0526 02:49:32.115875 15394 main.cpp:354] Iteration 10230, loss = 0.449703
I0526 02:49:32.115942 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.449703 (* 1 = 0.449703 loss)
I0526 02:49:32.115957 15394 sgd_solver.cpp:43] Iteration 10230, lr = 0.02
I0526 02:49:44.151568 15394 main.cpp:354] Iteration 10240, loss = 0.493875
I0526 02:49:44.151643 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.493876 (* 1 = 0.493876 loss)
I0526 02:49:44.151667 15394 sgd_solver.cpp:43] Iteration 10240, lr = 0.02
I0526 02:49:55.675252 15394 main.cpp:354] Iteration 10250, loss = 0.393849
I0526 02:49:55.675324 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.393849 (* 1 = 0.393849 loss)
I0526 02:49:55.675339 15394 sgd_solver.cpp:43] Iteration 10250, lr = 0.02
I0526 02:50:06.783341 15394 main.cpp:354] Iteration 10260, loss = 0.599375
I0526 02:50:06.783399 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.599375 (* 1 = 0.599375 loss)
I0526 02:50:06.783411 15394 sgd_solver.cpp:43] Iteration 10260, lr = 0.02
I0526 02:50:18.045462 15394 main.cpp:354] Iteration 10270, loss = 0.419345
I0526 02:50:18.045536 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.419345 (* 1 = 0.419345 loss)
I0526 02:50:18.045552 15394 sgd_solver.cpp:43] Iteration 10270, lr = 0.02
I0526 02:50:30.046746 15394 main.cpp:354] Iteration 10280, loss = 0.440192
I0526 02:50:30.046800 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.440192 (* 1 = 0.440192 loss)
I0526 02:50:30.046811 15394 sgd_solver.cpp:43] Iteration 10280, lr = 0.02
I0526 02:50:41.650341 15394 main.cpp:354] Iteration 10290, loss = 0.396553
I0526 02:50:41.650403 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.396554 (* 1 = 0.396554 loss)
I0526 02:50:41.650415 15394 sgd_solver.cpp:43] Iteration 10290, lr = 0.02
I0526 02:50:51.254623 15394 main.cpp:465] Iteration 10300, Testing net (#0)
I0526 02:51:21.866796 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6481
I0526 02:51:21.866864 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.06174 (* 1 = 1.06174 loss)
I0526 02:51:23.153625 15394 main.cpp:354] Iteration 10300, loss = 0.591293
I0526 02:51:23.153687 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.591293 (* 1 = 0.591293 loss)
I0526 02:51:23.153702 15394 sgd_solver.cpp:43] Iteration 10300, lr = 0.02
I0526 02:51:34.864248 15394 main.cpp:354] Iteration 10310, loss = 0.496258
I0526 02:51:34.864312 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.496258 (* 1 = 0.496258 loss)
I0526 02:51:34.864322 15394 sgd_solver.cpp:43] Iteration 10310, lr = 0.02
I0526 02:51:46.418730 15394 main.cpp:354] Iteration 10320, loss = 0.525851
I0526 02:51:46.418787 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.525851 (* 1 = 0.525851 loss)
I0526 02:51:46.418797 15394 sgd_solver.cpp:43] Iteration 10320, lr = 0.02
I0526 02:51:57.519175 15394 main.cpp:354] Iteration 10330, loss = 0.388033
I0526 02:51:57.519239 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.388033 (* 1 = 0.388033 loss)
I0526 02:51:57.519249 15394 sgd_solver.cpp:43] Iteration 10330, lr = 0.02
I0526 02:52:08.726719 15394 main.cpp:354] Iteration 10340, loss = 0.583529
I0526 02:52:08.726788 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.58353 (* 1 = 0.58353 loss)
I0526 02:52:08.726797 15394 sgd_solver.cpp:43] Iteration 10340, lr = 0.02
I0526 02:52:20.001220 15394 main.cpp:354] Iteration 10350, loss = 0.735967
I0526 02:52:20.001284 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.735967 (* 1 = 0.735967 loss)
I0526 02:52:20.001294 15394 sgd_solver.cpp:43] Iteration 10350, lr = 0.02
I0526 02:52:30.737429 15394 main.cpp:354] Iteration 10360, loss = 0.543646
I0526 02:52:30.737486 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.543646 (* 1 = 0.543646 loss)
I0526 02:52:30.737496 15394 sgd_solver.cpp:43] Iteration 10360, lr = 0.02
I0526 02:52:42.246825 15394 main.cpp:354] Iteration 10370, loss = 0.439272
I0526 02:52:42.246892 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.439272 (* 1 = 0.439272 loss)
I0526 02:52:42.246903 15394 sgd_solver.cpp:43] Iteration 10370, lr = 0.02
I0526 02:52:53.725932 15394 main.cpp:354] Iteration 10380, loss = 0.620319
I0526 02:52:53.725996 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.620319 (* 1 = 0.620319 loss)
I0526 02:52:53.726006 15394 sgd_solver.cpp:43] Iteration 10380, lr = 0.02
I0526 02:53:04.585863 15394 main.cpp:354] Iteration 10390, loss = 0.395902
I0526 02:53:04.585933 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.395902 (* 1 = 0.395902 loss)
I0526 02:53:04.585944 15394 sgd_solver.cpp:43] Iteration 10390, lr = 0.02
I0526 02:53:15.125167 15394 main.cpp:465] Iteration 10400, Testing net (#0)
I0526 02:53:45.737328 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6659
I0526 02:53:45.737380 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.07816 (* 1 = 1.07816 loss)
I0526 02:53:46.555711 15394 main.cpp:354] Iteration 10400, loss = 0.702945
I0526 02:53:46.555770 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.702945 (* 1 = 0.702945 loss)
I0526 02:53:46.555784 15394 sgd_solver.cpp:43] Iteration 10400, lr = 0.02
I0526 02:53:58.044070 15394 main.cpp:354] Iteration 10410, loss = 0.721267
I0526 02:53:58.044134 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.721267 (* 1 = 0.721267 loss)
I0526 02:53:58.044144 15394 sgd_solver.cpp:43] Iteration 10410, lr = 0.02
I0526 02:54:10.187379 15394 main.cpp:354] Iteration 10420, loss = 0.520735
I0526 02:54:10.187445 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.520735 (* 1 = 0.520735 loss)
I0526 02:54:10.187455 15394 sgd_solver.cpp:43] Iteration 10420, lr = 0.02
I0526 02:54:21.461102 15394 main.cpp:354] Iteration 10430, loss = 0.575587
I0526 02:54:21.461164 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.575587 (* 1 = 0.575587 loss)
I0526 02:54:21.461174 15394 sgd_solver.cpp:43] Iteration 10430, lr = 0.02
I0526 02:54:32.999543 15394 main.cpp:354] Iteration 10440, loss = 0.367561
I0526 02:54:32.999617 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.367561 (* 1 = 0.367561 loss)
I0526 02:54:32.999632 15394 sgd_solver.cpp:43] Iteration 10440, lr = 0.02
I0526 02:54:44.517356 15394 main.cpp:354] Iteration 10450, loss = 0.748023
I0526 02:54:44.517412 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.748024 (* 1 = 0.748024 loss)
I0526 02:54:44.517421 15394 sgd_solver.cpp:43] Iteration 10450, lr = 0.02
I0526 02:54:55.272821 15394 main.cpp:354] Iteration 10460, loss = 0.369877
I0526 02:54:55.272886 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.369877 (* 1 = 0.369877 loss)
I0526 02:54:55.272897 15394 sgd_solver.cpp:43] Iteration 10460, lr = 0.02
I0526 02:55:07.115713 15394 main.cpp:354] Iteration 10470, loss = 0.525756
I0526 02:55:07.115774 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.525757 (* 1 = 0.525757 loss)
I0526 02:55:07.115784 15394 sgd_solver.cpp:43] Iteration 10470, lr = 0.02
I0526 02:55:18.235631 15394 main.cpp:354] Iteration 10480, loss = 0.506727
I0526 02:55:18.235705 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.506727 (* 1 = 0.506727 loss)
I0526 02:55:18.235719 15394 sgd_solver.cpp:43] Iteration 10480, lr = 0.02
I0526 02:55:28.714131 15394 main.cpp:354] Iteration 10490, loss = 0.680702
I0526 02:55:28.714195 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.680702 (* 1 = 0.680702 loss)
I0526 02:55:28.714205 15394 sgd_solver.cpp:43] Iteration 10490, lr = 0.02
I0526 02:55:38.749284 15394 main.cpp:465] Iteration 10500, Testing net (#0)
I0526 02:56:09.329535 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7048
I0526 02:56:09.329596 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.867046 (* 1 = 0.867046 loss)
I0526 02:56:10.123316 15394 main.cpp:354] Iteration 10500, loss = 0.567627
I0526 02:56:10.123378 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.567628 (* 1 = 0.567628 loss)
I0526 02:56:10.123389 15394 sgd_solver.cpp:43] Iteration 10500, lr = 0.02
I0526 02:56:21.100484 15394 main.cpp:354] Iteration 10510, loss = 0.468714
I0526 02:56:21.100548 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.468715 (* 1 = 0.468715 loss)
I0526 02:56:21.100558 15394 sgd_solver.cpp:43] Iteration 10510, lr = 0.02
I0526 02:56:31.634907 15394 main.cpp:354] Iteration 10520, loss = 0.694074
I0526 02:56:31.634961 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.694074 (* 1 = 0.694074 loss)
I0526 02:56:31.634980 15394 sgd_solver.cpp:43] Iteration 10520, lr = 0.02
I0526 02:56:43.371619 15394 main.cpp:354] Iteration 10530, loss = 0.503061
I0526 02:56:43.371685 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.503061 (* 1 = 0.503061 loss)
I0526 02:56:43.371695 15394 sgd_solver.cpp:43] Iteration 10530, lr = 0.02
I0526 02:56:55.025408 15394 main.cpp:354] Iteration 10540, loss = 0.452279
I0526 02:56:55.025481 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.452279 (* 1 = 0.452279 loss)
I0526 02:56:55.025495 15394 sgd_solver.cpp:43] Iteration 10540, lr = 0.02
I0526 02:57:05.973039 15394 main.cpp:354] Iteration 10550, loss = 0.405391
I0526 02:57:05.973112 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.405391 (* 1 = 0.405391 loss)
I0526 02:57:05.973122 15394 sgd_solver.cpp:43] Iteration 10550, lr = 0.02
I0526 02:57:16.000268 15394 main.cpp:354] Iteration 10560, loss = 0.627936
I0526 02:57:16.000335 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.627936 (* 1 = 0.627936 loss)
I0526 02:57:16.000350 15394 sgd_solver.cpp:43] Iteration 10560, lr = 0.02
I0526 02:57:27.681851 15394 main.cpp:354] Iteration 10570, loss = 0.521821
I0526 02:57:27.681926 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.521821 (* 1 = 0.521821 loss)
I0526 02:57:27.681941 15394 sgd_solver.cpp:43] Iteration 10570, lr = 0.02
I0526 02:57:39.917448 15394 main.cpp:354] Iteration 10580, loss = 0.378924
I0526 02:57:39.917522 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.378924 (* 1 = 0.378924 loss)
I0526 02:57:39.917536 15394 sgd_solver.cpp:43] Iteration 10580, lr = 0.02
I0526 02:57:50.714409 15394 main.cpp:354] Iteration 10590, loss = 0.472801
I0526 02:57:50.714481 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.472801 (* 1 = 0.472801 loss)
I0526 02:57:50.714495 15394 sgd_solver.cpp:43] Iteration 10590, lr = 0.02
I0526 02:58:00.755372 15394 main.cpp:465] Iteration 10600, Testing net (#0)
I0526 02:58:31.281189 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7911
I0526 02:58:31.281246 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.607883 (* 1 = 0.607883 loss)
I0526 02:58:32.560026 15394 main.cpp:354] Iteration 10600, loss = 0.497142
I0526 02:58:32.560091 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.497142 (* 1 = 0.497142 loss)
I0526 02:58:32.560106 15394 sgd_solver.cpp:43] Iteration 10600, lr = 0.02
I0526 02:58:43.189631 15394 main.cpp:354] Iteration 10610, loss = 0.632905
I0526 02:58:43.189697 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.632906 (* 1 = 0.632906 loss)
I0526 02:58:43.189718 15394 sgd_solver.cpp:43] Iteration 10610, lr = 0.02
I0526 02:58:54.868288 15394 main.cpp:354] Iteration 10620, loss = 0.386034
I0526 02:58:54.868361 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.386034 (* 1 = 0.386034 loss)
I0526 02:58:54.868372 15394 sgd_solver.cpp:43] Iteration 10620, lr = 0.02
I0526 02:59:06.472719 15394 main.cpp:354] Iteration 10630, loss = 0.453459
I0526 02:59:06.472790 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.453459 (* 1 = 0.453459 loss)
I0526 02:59:06.472813 15394 sgd_solver.cpp:43] Iteration 10630, lr = 0.02
I0526 02:59:17.915825 15394 main.cpp:354] Iteration 10640, loss = 0.393934
I0526 02:59:17.915889 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.393934 (* 1 = 0.393934 loss)
I0526 02:59:17.915900 15394 sgd_solver.cpp:43] Iteration 10640, lr = 0.02
I0526 02:59:29.553622 15394 main.cpp:354] Iteration 10650, loss = 0.60718
I0526 02:59:29.553686 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.607181 (* 1 = 0.607181 loss)
I0526 02:59:29.553696 15394 sgd_solver.cpp:43] Iteration 10650, lr = 0.02
I0526 02:59:40.596484 15394 main.cpp:354] Iteration 10660, loss = 0.481339
I0526 02:59:40.596549 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.481339 (* 1 = 0.481339 loss)
I0526 02:59:40.596567 15394 sgd_solver.cpp:43] Iteration 10660, lr = 0.02
I0526 02:59:51.951406 15394 main.cpp:354] Iteration 10670, loss = 0.532188
I0526 02:59:51.951468 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.532188 (* 1 = 0.532188 loss)
I0526 02:59:51.951479 15394 sgd_solver.cpp:43] Iteration 10670, lr = 0.02
I0526 03:00:03.639824 15394 main.cpp:354] Iteration 10680, loss = 0.345531
I0526 03:00:03.639885 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.345531 (* 1 = 0.345531 loss)
I0526 03:00:03.639895 15394 sgd_solver.cpp:43] Iteration 10680, lr = 0.02
I0526 03:00:15.099387 15394 main.cpp:354] Iteration 10690, loss = 0.521152
I0526 03:00:15.099453 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.521152 (* 1 = 0.521152 loss)
I0526 03:00:15.099462 15394 sgd_solver.cpp:43] Iteration 10690, lr = 0.02
I0526 03:00:24.967634 15394 main.cpp:465] Iteration 10700, Testing net (#0)
I0526 03:00:55.636140 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6475
I0526 03:00:55.636198 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.1812 (* 1 = 1.1812 loss)
I0526 03:00:56.818941 15394 main.cpp:354] Iteration 10700, loss = 0.49559
I0526 03:00:56.819003 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.495591 (* 1 = 0.495591 loss)
I0526 03:00:56.819020 15394 sgd_solver.cpp:43] Iteration 10700, lr = 0.02
I0526 03:01:07.815584 15394 main.cpp:354] Iteration 10710, loss = 0.462085
I0526 03:01:07.815645 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.462086 (* 1 = 0.462086 loss)
I0526 03:01:07.815655 15394 sgd_solver.cpp:43] Iteration 10710, lr = 0.02
I0526 03:01:18.649783 15394 main.cpp:354] Iteration 10720, loss = 0.678281
I0526 03:01:18.649848 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.678282 (* 1 = 0.678282 loss)
I0526 03:01:18.649858 15394 sgd_solver.cpp:43] Iteration 10720, lr = 0.02
I0526 03:01:30.122191 15394 main.cpp:354] Iteration 10730, loss = 0.563023
I0526 03:01:30.122259 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.563023 (* 1 = 0.563023 loss)
I0526 03:01:30.122272 15394 sgd_solver.cpp:43] Iteration 10730, lr = 0.02
I0526 03:01:41.254345 15394 main.cpp:354] Iteration 10740, loss = 0.465902
I0526 03:01:41.254415 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.465903 (* 1 = 0.465903 loss)
I0526 03:01:41.254426 15394 sgd_solver.cpp:43] Iteration 10740, lr = 0.02
I0526 03:01:52.555223 15394 main.cpp:354] Iteration 10750, loss = 0.373705
I0526 03:01:52.555286 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.373706 (* 1 = 0.373706 loss)
I0526 03:01:52.555296 15394 sgd_solver.cpp:43] Iteration 10750, lr = 0.02
I0526 03:02:03.862140 15394 main.cpp:354] Iteration 10760, loss = 0.363352
I0526 03:02:03.862196 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.363353 (* 1 = 0.363353 loss)
I0526 03:02:03.862206 15394 sgd_solver.cpp:43] Iteration 10760, lr = 0.02
I0526 03:02:15.123944 15394 main.cpp:354] Iteration 10770, loss = 0.589265
I0526 03:02:15.124007 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.589266 (* 1 = 0.589266 loss)
I0526 03:02:15.124018 15394 sgd_solver.cpp:43] Iteration 10770, lr = 0.02
I0526 03:02:26.491971 15394 main.cpp:354] Iteration 10780, loss = 0.51679
I0526 03:02:26.492027 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.516791 (* 1 = 0.516791 loss)
I0526 03:02:26.492036 15394 sgd_solver.cpp:43] Iteration 10780, lr = 0.02
I0526 03:02:37.879873 15394 main.cpp:354] Iteration 10790, loss = 0.538742
I0526 03:02:37.879935 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.538743 (* 1 = 0.538743 loss)
I0526 03:02:37.879946 15394 sgd_solver.cpp:43] Iteration 10790, lr = 0.02
I0526 03:02:48.162183 15394 main.cpp:465] Iteration 10800, Testing net (#0)
I0526 03:03:18.896160 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7246
I0526 03:03:18.896220 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.872258 (* 1 = 0.872258 loss)
I0526 03:03:19.946080 15394 main.cpp:354] Iteration 10800, loss = 0.462763
I0526 03:03:19.946148 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.462763 (* 1 = 0.462763 loss)
I0526 03:03:19.946161 15394 sgd_solver.cpp:43] Iteration 10800, lr = 0.02
I0526 03:03:30.305987 15394 main.cpp:354] Iteration 10810, loss = 0.692821
I0526 03:03:30.306057 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.692821 (* 1 = 0.692821 loss)
I0526 03:03:30.306071 15394 sgd_solver.cpp:43] Iteration 10810, lr = 0.02
I0526 03:03:41.628626 15394 main.cpp:354] Iteration 10820, loss = 0.583165
I0526 03:03:41.628687 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.583165 (* 1 = 0.583165 loss)
I0526 03:03:41.628697 15394 sgd_solver.cpp:43] Iteration 10820, lr = 0.02
I0526 03:03:53.021121 15394 main.cpp:354] Iteration 10830, loss = 0.374673
I0526 03:03:53.021193 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.374673 (* 1 = 0.374673 loss)
I0526 03:03:53.021203 15394 sgd_solver.cpp:43] Iteration 10830, lr = 0.02
I0526 03:04:04.794379 15394 main.cpp:354] Iteration 10840, loss = 0.429762
I0526 03:04:04.794445 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.429762 (* 1 = 0.429762 loss)
I0526 03:04:04.794456 15394 sgd_solver.cpp:43] Iteration 10840, lr = 0.02
I0526 03:04:15.705799 15394 main.cpp:354] Iteration 10850, loss = 0.618323
I0526 03:04:15.705857 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.618323 (* 1 = 0.618323 loss)
I0526 03:04:15.705865 15394 sgd_solver.cpp:43] Iteration 10850, lr = 0.02
I0526 03:04:26.697952 15394 main.cpp:354] Iteration 10860, loss = 0.512428
I0526 03:04:26.698015 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.512428 (* 1 = 0.512428 loss)
I0526 03:04:26.698025 15394 sgd_solver.cpp:43] Iteration 10860, lr = 0.02
I0526 03:04:37.482564 15394 main.cpp:354] Iteration 10870, loss = 0.656366
I0526 03:04:37.482622 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.656366 (* 1 = 0.656366 loss)
I0526 03:04:37.482632 15394 sgd_solver.cpp:43] Iteration 10870, lr = 0.02
I0526 03:04:49.247632 15394 main.cpp:354] Iteration 10880, loss = 0.466082
I0526 03:04:49.247691 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.466083 (* 1 = 0.466083 loss)
I0526 03:04:49.247700 15394 sgd_solver.cpp:43] Iteration 10880, lr = 0.02
I0526 03:05:01.237977 15394 main.cpp:354] Iteration 10890, loss = 0.367676
I0526 03:05:01.238044 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.367676 (* 1 = 0.367676 loss)
I0526 03:05:01.238051 15394 sgd_solver.cpp:43] Iteration 10890, lr = 0.02
I0526 03:05:11.843252 15394 main.cpp:465] Iteration 10900, Testing net (#0)
I0526 03:05:42.638806 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7544
I0526 03:05:42.638869 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.744356 (* 1 = 0.744356 loss)
I0526 03:05:43.606081 15394 main.cpp:354] Iteration 10900, loss = 0.521373
I0526 03:05:43.606134 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.521373 (* 1 = 0.521373 loss)
I0526 03:05:43.606145 15394 sgd_solver.cpp:43] Iteration 10900, lr = 0.02
I0526 03:05:55.593034 15394 main.cpp:354] Iteration 10910, loss = 0.456697
I0526 03:05:55.593091 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.456697 (* 1 = 0.456697 loss)
I0526 03:05:55.593101 15394 sgd_solver.cpp:43] Iteration 10910, lr = 0.02
I0526 03:06:06.693210 15394 main.cpp:354] Iteration 10920, loss = 0.438976
I0526 03:06:06.693259 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.438976 (* 1 = 0.438976 loss)
I0526 03:06:06.693267 15394 sgd_solver.cpp:43] Iteration 10920, lr = 0.02
I0526 03:06:18.529752 15394 main.cpp:354] Iteration 10930, loss = 0.453498
I0526 03:06:18.529808 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.453498 (* 1 = 0.453498 loss)
I0526 03:06:18.529817 15394 sgd_solver.cpp:43] Iteration 10930, lr = 0.02
I0526 03:06:30.656076 15394 main.cpp:354] Iteration 10940, loss = 0.400175
I0526 03:06:30.656131 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.400175 (* 1 = 0.400175 loss)
I0526 03:06:30.656147 15394 sgd_solver.cpp:43] Iteration 10940, lr = 0.02
I0526 03:06:42.223662 15394 main.cpp:354] Iteration 10950, loss = 0.451362
I0526 03:06:42.223721 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.451362 (* 1 = 0.451362 loss)
I0526 03:06:42.223731 15394 sgd_solver.cpp:43] Iteration 10950, lr = 0.02
I0526 03:06:53.202713 15394 main.cpp:354] Iteration 10960, loss = 0.490047
I0526 03:06:53.202769 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.490048 (* 1 = 0.490048 loss)
I0526 03:06:53.202778 15394 sgd_solver.cpp:43] Iteration 10960, lr = 0.02
I0526 03:07:04.537284 15394 main.cpp:354] Iteration 10970, loss = 0.368139
I0526 03:07:04.537336 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.368139 (* 1 = 0.368139 loss)
I0526 03:07:04.537346 15394 sgd_solver.cpp:43] Iteration 10970, lr = 0.02
I0526 03:07:16.610551 15394 main.cpp:354] Iteration 10980, loss = 0.397479
I0526 03:07:16.610608 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.397479 (* 1 = 0.397479 loss)
I0526 03:07:16.610617 15394 sgd_solver.cpp:43] Iteration 10980, lr = 0.02
I0526 03:07:28.505352 15394 main.cpp:354] Iteration 10990, loss = 0.491436
I0526 03:07:28.505411 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.491436 (* 1 = 0.491436 loss)
I0526 03:07:28.505420 15394 sgd_solver.cpp:43] Iteration 10990, lr = 0.02
I0526 03:07:38.994676 15394 main.cpp:465] Iteration 11000, Testing net (#0)
I0526 03:08:09.699578 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7324
I0526 03:08:09.699633 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.808247 (* 1 = 0.808247 loss)
I0526 03:08:10.809370 15394 main.cpp:354] Iteration 11000, loss = 0.462441
I0526 03:08:10.809434 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.462441 (* 1 = 0.462441 loss)
I0526 03:08:10.809445 15394 sgd_solver.cpp:43] Iteration 11000, lr = 0.02
I0526 03:08:21.832929 15394 main.cpp:354] Iteration 11010, loss = 0.542268
I0526 03:08:21.832996 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.542268 (* 1 = 0.542268 loss)
I0526 03:08:21.833005 15394 sgd_solver.cpp:43] Iteration 11010, lr = 0.02
I0526 03:08:32.627727 15394 main.cpp:354] Iteration 11020, loss = 1.04229
I0526 03:08:32.627782 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.04229 (* 1 = 1.04229 loss)
I0526 03:08:32.627792 15394 sgd_solver.cpp:43] Iteration 11020, lr = 0.02
I0526 03:08:43.716446 15394 main.cpp:354] Iteration 11030, loss = 0.832528
I0526 03:08:43.716501 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.832528 (* 1 = 0.832528 loss)
I0526 03:08:43.716511 15394 sgd_solver.cpp:43] Iteration 11030, lr = 0.02
I0526 03:08:55.846149 15394 main.cpp:354] Iteration 11040, loss = 0.393326
I0526 03:08:55.846205 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.393326 (* 1 = 0.393326 loss)
I0526 03:08:55.846215 15394 sgd_solver.cpp:43] Iteration 11040, lr = 0.02
I0526 03:09:07.246222 15394 main.cpp:354] Iteration 11050, loss = 0.45284
I0526 03:09:07.246269 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.45284 (* 1 = 0.45284 loss)
I0526 03:09:07.246278 15394 sgd_solver.cpp:43] Iteration 11050, lr = 0.02
I0526 03:09:18.464310 15394 main.cpp:354] Iteration 11060, loss = 0.665015
I0526 03:09:18.464365 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.665016 (* 1 = 0.665016 loss)
I0526 03:09:18.464375 15394 sgd_solver.cpp:43] Iteration 11060, lr = 0.02
I0526 03:09:29.595283 15394 main.cpp:354] Iteration 11070, loss = 0.457869
I0526 03:09:29.595337 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.45787 (* 1 = 0.45787 loss)
I0526 03:09:29.595348 15394 sgd_solver.cpp:43] Iteration 11070, lr = 0.02
I0526 03:09:40.292498 15394 main.cpp:354] Iteration 11080, loss = 0.670045
I0526 03:09:40.292554 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.670045 (* 1 = 0.670045 loss)
I0526 03:09:40.292563 15394 sgd_solver.cpp:43] Iteration 11080, lr = 0.02
I0526 03:09:52.465656 15394 main.cpp:354] Iteration 11090, loss = 0.439695
I0526 03:09:52.465715 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.439695 (* 1 = 0.439695 loss)
I0526 03:09:52.465724 15394 sgd_solver.cpp:43] Iteration 11090, lr = 0.02
I0526 03:10:02.742941 15394 main.cpp:465] Iteration 11100, Testing net (#0)
I0526 03:10:33.484002 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7382
I0526 03:10:33.484055 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.826549 (* 1 = 0.826549 loss)
I0526 03:10:34.462846 15394 main.cpp:354] Iteration 11100, loss = 0.412791
I0526 03:10:34.462903 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.412792 (* 1 = 0.412792 loss)
I0526 03:10:34.462913 15394 sgd_solver.cpp:43] Iteration 11100, lr = 0.02
I0526 03:10:45.272483 15394 main.cpp:354] Iteration 11110, loss = 0.409539
I0526 03:10:45.272548 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.409539 (* 1 = 0.409539 loss)
I0526 03:10:45.272559 15394 sgd_solver.cpp:43] Iteration 11110, lr = 0.02
I0526 03:10:57.031405 15394 main.cpp:354] Iteration 11120, loss = 0.543399
I0526 03:10:57.031466 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.543399 (* 1 = 0.543399 loss)
I0526 03:10:57.031474 15394 sgd_solver.cpp:43] Iteration 11120, lr = 0.02
I0526 03:11:08.629986 15394 main.cpp:354] Iteration 11130, loss = 0.541254
I0526 03:11:08.630048 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.541255 (* 1 = 0.541255 loss)
I0526 03:11:08.630060 15394 sgd_solver.cpp:43] Iteration 11130, lr = 0.02
I0526 03:11:19.982847 15394 main.cpp:354] Iteration 11140, loss = 0.810422
I0526 03:11:19.982900 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.810423 (* 1 = 0.810423 loss)
I0526 03:11:19.982910 15394 sgd_solver.cpp:43] Iteration 11140, lr = 0.02
I0526 03:11:31.748314 15394 main.cpp:354] Iteration 11150, loss = 0.453148
I0526 03:11:31.748368 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.453148 (* 1 = 0.453148 loss)
I0526 03:11:31.748376 15394 sgd_solver.cpp:43] Iteration 11150, lr = 0.02
I0526 03:11:43.182512 15394 main.cpp:354] Iteration 11160, loss = 0.57672
I0526 03:11:43.182566 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.57672 (* 1 = 0.57672 loss)
I0526 03:11:43.182575 15394 sgd_solver.cpp:43] Iteration 11160, lr = 0.02
I0526 03:11:54.479383 15394 main.cpp:354] Iteration 11170, loss = 0.561928
I0526 03:11:54.479449 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.561928 (* 1 = 0.561928 loss)
I0526 03:11:54.479460 15394 sgd_solver.cpp:43] Iteration 11170, lr = 0.02
I0526 03:12:05.912593 15394 main.cpp:354] Iteration 11180, loss = 0.404391
I0526 03:12:05.912647 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.404392 (* 1 = 0.404392 loss)
I0526 03:12:05.912657 15394 sgd_solver.cpp:43] Iteration 11180, lr = 0.02
I0526 03:12:17.377558 15394 main.cpp:354] Iteration 11190, loss = 0.369089
I0526 03:12:17.377619 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.369089 (* 1 = 0.369089 loss)
I0526 03:12:17.377640 15394 sgd_solver.cpp:43] Iteration 11190, lr = 0.02
I0526 03:12:26.830566 15394 main.cpp:465] Iteration 11200, Testing net (#0)
I0526 03:12:57.534006 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6589
I0526 03:12:57.534070 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.17081 (* 1 = 1.17081 loss)
I0526 03:12:58.670208 15394 main.cpp:354] Iteration 11200, loss = 0.639969
I0526 03:12:58.670266 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.639969 (* 1 = 0.639969 loss)
I0526 03:12:58.670277 15394 sgd_solver.cpp:43] Iteration 11200, lr = 0.02
I0526 03:13:09.683092 15394 main.cpp:354] Iteration 11210, loss = 0.761618
I0526 03:13:09.683148 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.761618 (* 1 = 0.761618 loss)
I0526 03:13:09.683157 15394 sgd_solver.cpp:43] Iteration 11210, lr = 0.02
I0526 03:13:21.451732 15394 main.cpp:354] Iteration 11220, loss = 0.369916
I0526 03:13:21.451792 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.369916 (* 1 = 0.369916 loss)
I0526 03:13:21.451800 15394 sgd_solver.cpp:43] Iteration 11220, lr = 0.02
I0526 03:13:33.622619 15394 main.cpp:354] Iteration 11230, loss = 0.384239
I0526 03:13:33.622678 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.38424 (* 1 = 0.38424 loss)
I0526 03:13:33.622699 15394 sgd_solver.cpp:43] Iteration 11230, lr = 0.02
I0526 03:13:44.984771 15394 main.cpp:354] Iteration 11240, loss = 0.391365
I0526 03:13:44.984825 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.391366 (* 1 = 0.391366 loss)
I0526 03:13:44.984834 15394 sgd_solver.cpp:43] Iteration 11240, lr = 0.02
I0526 03:13:55.888649 15394 main.cpp:354] Iteration 11250, loss = 0.545228
I0526 03:13:55.888707 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.545228 (* 1 = 0.545228 loss)
I0526 03:13:55.888716 15394 sgd_solver.cpp:43] Iteration 11250, lr = 0.02
I0526 03:14:07.664708 15394 main.cpp:354] Iteration 11260, loss = 0.438723
I0526 03:14:07.664772 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.438723 (* 1 = 0.438723 loss)
I0526 03:14:07.664783 15394 sgd_solver.cpp:43] Iteration 11260, lr = 0.02
I0526 03:14:19.357736 15394 main.cpp:354] Iteration 11270, loss = 0.314549
I0526 03:14:19.357795 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.31455 (* 1 = 0.31455 loss)
I0526 03:14:19.357805 15394 sgd_solver.cpp:43] Iteration 11270, lr = 0.02
I0526 03:14:31.243244 15394 main.cpp:354] Iteration 11280, loss = 0.415331
I0526 03:14:31.243295 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.415331 (* 1 = 0.415331 loss)
I0526 03:14:31.243304 15394 sgd_solver.cpp:43] Iteration 11280, lr = 0.02
I0526 03:14:41.541400 15394 main.cpp:354] Iteration 11290, loss = 0.467238
I0526 03:14:41.541458 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.467238 (* 1 = 0.467238 loss)
I0526 03:14:41.541468 15394 sgd_solver.cpp:43] Iteration 11290, lr = 0.02
I0526 03:14:51.771960 15394 main.cpp:465] Iteration 11300, Testing net (#0)
I0526 03:15:22.541115 15394 main.cpp:532]     Test net output #0: Accuracy = 0.76
I0526 03:15:22.541169 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.701216 (* 1 = 0.701216 loss)
I0526 03:15:23.447317 15394 main.cpp:354] Iteration 11300, loss = 0.517872
I0526 03:15:23.447373 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.517872 (* 1 = 0.517872 loss)
I0526 03:15:23.447383 15394 sgd_solver.cpp:43] Iteration 11300, lr = 0.02
I0526 03:15:34.830740 15394 main.cpp:354] Iteration 11310, loss = 0.709929
I0526 03:15:34.830790 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.709929 (* 1 = 0.709929 loss)
I0526 03:15:34.830799 15394 sgd_solver.cpp:43] Iteration 11310, lr = 0.02
I0526 03:15:46.144876 15394 main.cpp:354] Iteration 11320, loss = 0.439891
I0526 03:15:46.144929 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.439892 (* 1 = 0.439892 loss)
I0526 03:15:46.144938 15394 sgd_solver.cpp:43] Iteration 11320, lr = 0.02
I0526 03:15:58.537960 15394 main.cpp:354] Iteration 11330, loss = 0.478998
I0526 03:15:58.538019 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.478998 (* 1 = 0.478998 loss)
I0526 03:15:58.538039 15394 sgd_solver.cpp:43] Iteration 11330, lr = 0.02
I0526 03:16:10.595942 15394 main.cpp:354] Iteration 11340, loss = 0.456327
I0526 03:16:10.595999 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.456327 (* 1 = 0.456327 loss)
I0526 03:16:10.596007 15394 sgd_solver.cpp:43] Iteration 11340, lr = 0.02
I0526 03:16:22.506003 15394 main.cpp:354] Iteration 11350, loss = 0.375894
I0526 03:16:22.506060 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.375894 (* 1 = 0.375894 loss)
I0526 03:16:22.506069 15394 sgd_solver.cpp:43] Iteration 11350, lr = 0.02
I0526 03:16:33.986143 15394 main.cpp:354] Iteration 11360, loss = 0.486764
I0526 03:16:33.986213 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.486764 (* 1 = 0.486764 loss)
I0526 03:16:33.986229 15394 sgd_solver.cpp:43] Iteration 11360, lr = 0.02
I0526 03:16:45.063164 15394 main.cpp:354] Iteration 11370, loss = 0.586023
I0526 03:16:45.063220 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.586023 (* 1 = 0.586023 loss)
I0526 03:16:45.063230 15394 sgd_solver.cpp:43] Iteration 11370, lr = 0.02
I0526 03:16:56.719589 15394 main.cpp:354] Iteration 11380, loss = 0.501149
I0526 03:16:56.719630 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.501149 (* 1 = 0.501149 loss)
I0526 03:16:56.719637 15394 sgd_solver.cpp:43] Iteration 11380, lr = 0.02
I0526 03:17:08.518923 15394 main.cpp:354] Iteration 11390, loss = 0.460495
I0526 03:17:08.518980 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.460495 (* 1 = 0.460495 loss)
I0526 03:17:08.518990 15394 sgd_solver.cpp:43] Iteration 11390, lr = 0.02
I0526 03:17:19.371168 15394 main.cpp:465] Iteration 11400, Testing net (#0)
I0526 03:17:49.817003 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7707
I0526 03:17:49.817059 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.655925 (* 1 = 0.655925 loss)
I0526 03:17:50.830559 15394 main.cpp:354] Iteration 11400, loss = 0.496825
I0526 03:17:50.830618 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.496825 (* 1 = 0.496825 loss)
I0526 03:17:50.830631 15394 sgd_solver.cpp:43] Iteration 11400, lr = 0.02
I0526 03:18:01.760365 15394 main.cpp:354] Iteration 11410, loss = 0.751565
I0526 03:18:01.760418 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.751565 (* 1 = 0.751565 loss)
I0526 03:18:01.760428 15394 sgd_solver.cpp:43] Iteration 11410, lr = 0.02
I0526 03:18:13.109483 15394 main.cpp:354] Iteration 11420, loss = 0.625057
I0526 03:18:13.109542 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.625057 (* 1 = 0.625057 loss)
I0526 03:18:13.109552 15394 sgd_solver.cpp:43] Iteration 11420, lr = 0.02
I0526 03:18:24.797344 15394 main.cpp:354] Iteration 11430, loss = 0.560179
I0526 03:18:24.797401 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.56018 (* 1 = 0.56018 loss)
I0526 03:18:24.797411 15394 sgd_solver.cpp:43] Iteration 11430, lr = 0.02
I0526 03:18:36.747663 15394 main.cpp:354] Iteration 11440, loss = 0.469687
I0526 03:18:36.747723 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.469688 (* 1 = 0.469688 loss)
I0526 03:18:36.747733 15394 sgd_solver.cpp:43] Iteration 11440, lr = 0.02
I0526 03:18:47.826129 15394 main.cpp:354] Iteration 11450, loss = 0.559944
I0526 03:18:47.826184 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.559944 (* 1 = 0.559944 loss)
I0526 03:18:47.826195 15394 sgd_solver.cpp:43] Iteration 11450, lr = 0.02
I0526 03:18:59.105587 15394 main.cpp:354] Iteration 11460, loss = 0.513638
I0526 03:18:59.105648 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.513638 (* 1 = 0.513638 loss)
I0526 03:18:59.105657 15394 sgd_solver.cpp:43] Iteration 11460, lr = 0.02
I0526 03:19:09.641816 15394 main.cpp:354] Iteration 11470, loss = 0.74596
I0526 03:19:09.641875 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.74596 (* 1 = 0.74596 loss)
I0526 03:19:09.641883 15394 sgd_solver.cpp:43] Iteration 11470, lr = 0.02
I0526 03:19:20.703336 15394 main.cpp:354] Iteration 11480, loss = 0.29491
I0526 03:19:20.703395 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.29491 (* 1 = 0.29491 loss)
I0526 03:19:20.703404 15394 sgd_solver.cpp:43] Iteration 11480, lr = 0.02
I0526 03:19:31.707958 15394 main.cpp:354] Iteration 11490, loss = 0.466363
I0526 03:19:31.708017 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.466364 (* 1 = 0.466364 loss)
I0526 03:19:31.708027 15394 sgd_solver.cpp:43] Iteration 11490, lr = 0.02
I0526 03:19:41.444237 15394 main.cpp:465] Iteration 11500, Testing net (#0)
I0526 03:20:12.046638 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6983
I0526 03:20:12.046703 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.871891 (* 1 = 0.871891 loss)
I0526 03:20:13.155838 15394 main.cpp:354] Iteration 11500, loss = 0.421746
I0526 03:20:13.155903 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.421747 (* 1 = 0.421747 loss)
I0526 03:20:13.155913 15394 sgd_solver.cpp:43] Iteration 11500, lr = 0.02
I0526 03:20:23.964985 15394 main.cpp:354] Iteration 11510, loss = 0.420514
I0526 03:20:23.965049 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.420514 (* 1 = 0.420514 loss)
I0526 03:20:23.965057 15394 sgd_solver.cpp:43] Iteration 11510, lr = 0.02
I0526 03:20:35.369935 15394 main.cpp:354] Iteration 11520, loss = 0.477573
I0526 03:20:35.369989 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.477573 (* 1 = 0.477573 loss)
I0526 03:20:35.369998 15394 sgd_solver.cpp:43] Iteration 11520, lr = 0.02
I0526 03:20:47.373353 15394 main.cpp:354] Iteration 11530, loss = 0.577755
I0526 03:20:47.373409 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.577755 (* 1 = 0.577755 loss)
I0526 03:20:47.373419 15394 sgd_solver.cpp:43] Iteration 11530, lr = 0.02
I0526 03:20:58.000603 15394 main.cpp:354] Iteration 11540, loss = 0.453991
I0526 03:20:58.000659 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.453992 (* 1 = 0.453992 loss)
I0526 03:20:58.000669 15394 sgd_solver.cpp:43] Iteration 11540, lr = 0.02
I0526 03:21:08.665292 15394 main.cpp:354] Iteration 11550, loss = 0.615576
I0526 03:21:08.665341 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.615576 (* 1 = 0.615576 loss)
I0526 03:21:08.665349 15394 sgd_solver.cpp:43] Iteration 11550, lr = 0.02
I0526 03:21:19.927564 15394 main.cpp:354] Iteration 11560, loss = 0.3926
I0526 03:21:19.927619 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.3926 (* 1 = 0.3926 loss)
I0526 03:21:19.927628 15394 sgd_solver.cpp:43] Iteration 11560, lr = 0.02
I0526 03:21:32.066814 15394 main.cpp:354] Iteration 11570, loss = 0.434866
I0526 03:21:32.066881 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.434866 (* 1 = 0.434866 loss)
I0526 03:21:32.066890 15394 sgd_solver.cpp:43] Iteration 11570, lr = 0.02
I0526 03:21:42.796846 15394 main.cpp:354] Iteration 11580, loss = 0.462073
I0526 03:21:42.796902 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.462073 (* 1 = 0.462073 loss)
I0526 03:21:42.796912 15394 sgd_solver.cpp:43] Iteration 11580, lr = 0.02
I0526 03:21:53.850903 15394 main.cpp:354] Iteration 11590, loss = 0.599687
I0526 03:21:53.850961 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.599687 (* 1 = 0.599687 loss)
I0526 03:21:53.850970 15394 sgd_solver.cpp:43] Iteration 11590, lr = 0.02
I0526 03:22:03.346010 15394 main.cpp:465] Iteration 11600, Testing net (#0)
I0526 03:22:33.965266 15394 main.cpp:532]     Test net output #0: Accuracy = 0.747
I0526 03:22:33.965327 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.695526 (* 1 = 0.695526 loss)
I0526 03:22:35.030931 15394 main.cpp:354] Iteration 11600, loss = 0.417455
I0526 03:22:35.030985 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.417456 (* 1 = 0.417456 loss)
I0526 03:22:35.030997 15394 sgd_solver.cpp:43] Iteration 11600, lr = 0.02
I0526 03:22:46.933374 15394 main.cpp:354] Iteration 11610, loss = 0.325036
I0526 03:22:46.933425 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.325036 (* 1 = 0.325036 loss)
I0526 03:22:46.933434 15394 sgd_solver.cpp:43] Iteration 11610, lr = 0.02
I0526 03:22:57.780470 15394 main.cpp:354] Iteration 11620, loss = 0.476823
I0526 03:22:57.780524 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.476823 (* 1 = 0.476823 loss)
I0526 03:22:57.780531 15394 sgd_solver.cpp:43] Iteration 11620, lr = 0.02
I0526 03:23:10.246837 15394 main.cpp:354] Iteration 11630, loss = 0.447538
I0526 03:23:10.246892 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.447538 (* 1 = 0.447538 loss)
I0526 03:23:10.246901 15394 sgd_solver.cpp:43] Iteration 11630, lr = 0.02
I0526 03:23:21.555421 15394 main.cpp:354] Iteration 11640, loss = 0.642733
I0526 03:23:21.555474 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.642733 (* 1 = 0.642733 loss)
I0526 03:23:21.555488 15394 sgd_solver.cpp:43] Iteration 11640, lr = 0.02
I0526 03:23:32.734791 15394 main.cpp:354] Iteration 11650, loss = 0.587458
I0526 03:23:32.734843 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.587459 (* 1 = 0.587459 loss)
I0526 03:23:32.734851 15394 sgd_solver.cpp:43] Iteration 11650, lr = 0.02
I0526 03:23:44.273434 15394 main.cpp:354] Iteration 11660, loss = 0.486618
I0526 03:23:44.273488 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.486618 (* 1 = 0.486618 loss)
I0526 03:23:44.273496 15394 sgd_solver.cpp:43] Iteration 11660, lr = 0.02
I0526 03:23:56.591037 15394 main.cpp:354] Iteration 11670, loss = 0.408412
I0526 03:23:56.591089 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.408412 (* 1 = 0.408412 loss)
I0526 03:23:56.591099 15394 sgd_solver.cpp:43] Iteration 11670, lr = 0.02
I0526 03:24:07.917408 15394 main.cpp:354] Iteration 11680, loss = 0.630231
I0526 03:24:07.917457 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.630231 (* 1 = 0.630231 loss)
I0526 03:24:07.917465 15394 sgd_solver.cpp:43] Iteration 11680, lr = 0.02
I0526 03:24:19.507865 15394 main.cpp:354] Iteration 11690, loss = 0.527658
I0526 03:24:19.507918 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.527658 (* 1 = 0.527658 loss)
I0526 03:24:19.507928 15394 sgd_solver.cpp:43] Iteration 11690, lr = 0.02
I0526 03:24:29.431434 15394 main.cpp:465] Iteration 11700, Testing net (#0)
I0526 03:25:00.127274 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7596
I0526 03:25:00.127323 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.711473 (* 1 = 0.711473 loss)
I0526 03:25:01.474263 15394 main.cpp:354] Iteration 11700, loss = 0.473813
I0526 03:25:01.474313 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.473814 (* 1 = 0.473814 loss)
I0526 03:25:01.474324 15394 sgd_solver.cpp:43] Iteration 11700, lr = 0.02
I0526 03:25:12.267928 15394 main.cpp:354] Iteration 11710, loss = 0.433332
I0526 03:25:12.267979 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.433332 (* 1 = 0.433332 loss)
I0526 03:25:12.267989 15394 sgd_solver.cpp:43] Iteration 11710, lr = 0.02
I0526 03:25:24.236989 15394 main.cpp:354] Iteration 11720, loss = 0.309384
I0526 03:25:24.237038 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.309384 (* 1 = 0.309384 loss)
I0526 03:25:24.237046 15394 sgd_solver.cpp:43] Iteration 11720, lr = 0.02
I0526 03:25:35.079504 15394 main.cpp:354] Iteration 11730, loss = 1.11609
I0526 03:25:35.079566 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.11609 (* 1 = 1.11609 loss)
I0526 03:25:35.079577 15394 sgd_solver.cpp:43] Iteration 11730, lr = 0.02
I0526 03:25:46.651250 15394 main.cpp:354] Iteration 11740, loss = 0.361452
I0526 03:25:46.651298 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.361452 (* 1 = 0.361452 loss)
I0526 03:25:46.651307 15394 sgd_solver.cpp:43] Iteration 11740, lr = 0.02
I0526 03:25:57.445325 15394 main.cpp:354] Iteration 11750, loss = 0.5567
I0526 03:25:57.445389 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.5567 (* 1 = 0.5567 loss)
I0526 03:25:57.445399 15394 sgd_solver.cpp:43] Iteration 11750, lr = 0.02
I0526 03:26:08.092928 15394 main.cpp:354] Iteration 11760, loss = 0.459903
I0526 03:26:08.092984 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.459903 (* 1 = 0.459903 loss)
I0526 03:26:08.092993 15394 sgd_solver.cpp:43] Iteration 11760, lr = 0.02
I0526 03:26:19.430290 15394 main.cpp:354] Iteration 11770, loss = 0.405919
I0526 03:26:19.430344 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.405919 (* 1 = 0.405919 loss)
I0526 03:26:19.430364 15394 sgd_solver.cpp:43] Iteration 11770, lr = 0.02
I0526 03:26:30.402825 15394 main.cpp:354] Iteration 11780, loss = 0.657447
I0526 03:26:30.402871 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.657447 (* 1 = 0.657447 loss)
I0526 03:26:30.402886 15394 sgd_solver.cpp:43] Iteration 11780, lr = 0.02
I0526 03:26:42.845646 15394 main.cpp:354] Iteration 11790, loss = 0.413194
I0526 03:26:42.845700 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.413195 (* 1 = 0.413195 loss)
I0526 03:26:42.845710 15394 sgd_solver.cpp:43] Iteration 11790, lr = 0.02
I0526 03:26:53.489862 15394 main.cpp:465] Iteration 11800, Testing net (#0)
I0526 03:27:24.246899 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7476
I0526 03:27:24.246960 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.727575 (* 1 = 0.727575 loss)
I0526 03:27:25.277711 15394 main.cpp:354] Iteration 11800, loss = 0.603476
I0526 03:27:25.277762 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.603476 (* 1 = 0.603476 loss)
I0526 03:27:25.277782 15394 sgd_solver.cpp:43] Iteration 11800, lr = 0.02
I0526 03:27:36.837697 15394 main.cpp:354] Iteration 11810, loss = 0.834094
I0526 03:27:36.837759 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.834094 (* 1 = 0.834094 loss)
I0526 03:27:36.837769 15394 sgd_solver.cpp:43] Iteration 11810, lr = 0.02
I0526 03:27:48.291395 15394 main.cpp:354] Iteration 11820, loss = 0.473822
I0526 03:27:48.291445 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.473822 (* 1 = 0.473822 loss)
I0526 03:27:48.291453 15394 sgd_solver.cpp:43] Iteration 11820, lr = 0.02
I0526 03:27:59.462436 15394 main.cpp:354] Iteration 11830, loss = 0.816945
I0526 03:27:59.462491 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.816946 (* 1 = 0.816946 loss)
I0526 03:27:59.462499 15394 sgd_solver.cpp:43] Iteration 11830, lr = 0.02
I0526 03:28:11.014340 15394 main.cpp:354] Iteration 11840, loss = 0.436303
I0526 03:28:11.014395 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.436303 (* 1 = 0.436303 loss)
I0526 03:28:11.014403 15394 sgd_solver.cpp:43] Iteration 11840, lr = 0.02
I0526 03:28:22.772893 15394 main.cpp:354] Iteration 11850, loss = 0.453744
I0526 03:28:22.772945 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.453744 (* 1 = 0.453744 loss)
I0526 03:28:22.772954 15394 sgd_solver.cpp:43] Iteration 11850, lr = 0.02
I0526 03:28:34.788086 15394 main.cpp:354] Iteration 11860, loss = 0.536173
I0526 03:28:34.788142 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.536173 (* 1 = 0.536173 loss)
I0526 03:28:34.788153 15394 sgd_solver.cpp:43] Iteration 11860, lr = 0.02
I0526 03:28:45.389523 15394 main.cpp:354] Iteration 11870, loss = 0.387451
I0526 03:28:45.389571 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.387452 (* 1 = 0.387452 loss)
I0526 03:28:45.389580 15394 sgd_solver.cpp:43] Iteration 11870, lr = 0.02
I0526 03:28:56.559384 15394 main.cpp:354] Iteration 11880, loss = 0.505086
I0526 03:28:56.559434 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.505086 (* 1 = 0.505086 loss)
I0526 03:28:56.559442 15394 sgd_solver.cpp:43] Iteration 11880, lr = 0.02
I0526 03:29:08.316424 15394 main.cpp:354] Iteration 11890, loss = 0.519857
I0526 03:29:08.316483 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.519858 (* 1 = 0.519858 loss)
I0526 03:29:08.316491 15394 sgd_solver.cpp:43] Iteration 11890, lr = 0.02
I0526 03:29:18.620124 15394 main.cpp:465] Iteration 11900, Testing net (#0)
I0526 03:29:49.349490 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7374
I0526 03:29:49.349539 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.771461 (* 1 = 0.771461 loss)
I0526 03:29:50.095041 15394 main.cpp:354] Iteration 11900, loss = 0.721933
I0526 03:29:50.095090 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.721933 (* 1 = 0.721933 loss)
I0526 03:29:50.095099 15394 sgd_solver.cpp:43] Iteration 11900, lr = 0.02
I0526 03:30:01.247356 15394 main.cpp:354] Iteration 11910, loss = 0.352295
I0526 03:30:01.247406 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.352295 (* 1 = 0.352295 loss)
I0526 03:30:01.247414 15394 sgd_solver.cpp:43] Iteration 11910, lr = 0.02
I0526 03:30:13.198117 15394 main.cpp:354] Iteration 11920, loss = 0.34715
I0526 03:30:13.198174 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.347151 (* 1 = 0.347151 loss)
I0526 03:30:13.198184 15394 sgd_solver.cpp:43] Iteration 11920, lr = 0.02
I0526 03:30:24.488231 15394 main.cpp:354] Iteration 11930, loss = 0.721838
I0526 03:30:24.488286 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.721839 (* 1 = 0.721839 loss)
I0526 03:30:24.488294 15394 sgd_solver.cpp:43] Iteration 11930, lr = 0.02
I0526 03:30:35.797788 15394 main.cpp:354] Iteration 11940, loss = 0.508242
I0526 03:30:35.797839 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.508243 (* 1 = 0.508243 loss)
I0526 03:30:35.797848 15394 sgd_solver.cpp:43] Iteration 11940, lr = 0.02
I0526 03:30:46.769927 15394 main.cpp:354] Iteration 11950, loss = 0.453475
I0526 03:30:46.769973 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.453475 (* 1 = 0.453475 loss)
I0526 03:30:46.769981 15394 sgd_solver.cpp:43] Iteration 11950, lr = 0.02
I0526 03:30:57.798718 15394 main.cpp:354] Iteration 11960, loss = 0.459418
I0526 03:30:57.798781 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.459418 (* 1 = 0.459418 loss)
I0526 03:30:57.798790 15394 sgd_solver.cpp:43] Iteration 11960, lr = 0.02
I0526 03:31:10.169548 15394 main.cpp:354] Iteration 11970, loss = 0.47115
I0526 03:31:10.169600 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.47115 (* 1 = 0.47115 loss)
I0526 03:31:10.169608 15394 sgd_solver.cpp:43] Iteration 11970, lr = 0.02
I0526 03:31:21.582069 15394 main.cpp:354] Iteration 11980, loss = 0.575335
I0526 03:31:21.582125 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.575336 (* 1 = 0.575336 loss)
I0526 03:31:21.582134 15394 sgd_solver.cpp:43] Iteration 11980, lr = 0.02
I0526 03:31:32.603560 15394 main.cpp:354] Iteration 11990, loss = 0.425741
I0526 03:31:32.603616 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.425741 (* 1 = 0.425741 loss)
I0526 03:31:32.603624 15394 sgd_solver.cpp:43] Iteration 11990, lr = 0.02
I0526 03:31:42.611676 15394 main.cpp:465] Iteration 12000, Testing net (#0)
I0526 03:32:13.360916 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7442
I0526 03:32:13.360977 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.769646 (* 1 = 0.769646 loss)
I0526 03:32:14.635511 15394 main.cpp:354] Iteration 12000, loss = 0.494267
I0526 03:32:14.635563 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.494267 (* 1 = 0.494267 loss)
I0526 03:32:14.635574 15394 sgd_solver.cpp:43] Iteration 12000, lr = 0.02
I0526 03:32:25.698611 15394 main.cpp:354] Iteration 12010, loss = 0.680383
I0526 03:32:25.698660 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.680383 (* 1 = 0.680383 loss)
I0526 03:32:25.698668 15394 sgd_solver.cpp:43] Iteration 12010, lr = 0.02
I0526 03:32:36.839515 15394 main.cpp:354] Iteration 12020, loss = 0.502718
I0526 03:32:36.839567 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.502718 (* 1 = 0.502718 loss)
I0526 03:32:36.839576 15394 sgd_solver.cpp:43] Iteration 12020, lr = 0.02
I0526 03:32:47.820386 15394 main.cpp:354] Iteration 12030, loss = 0.741578
I0526 03:32:47.820449 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.741579 (* 1 = 0.741579 loss)
I0526 03:32:47.820458 15394 sgd_solver.cpp:43] Iteration 12030, lr = 0.02
I0526 03:32:58.992187 15394 main.cpp:354] Iteration 12040, loss = 0.376654
I0526 03:32:58.992234 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.376654 (* 1 = 0.376654 loss)
I0526 03:32:58.992243 15394 sgd_solver.cpp:43] Iteration 12040, lr = 0.02
I0526 03:33:10.078451 15394 main.cpp:354] Iteration 12050, loss = 0.406623
I0526 03:33:10.078501 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.406623 (* 1 = 0.406623 loss)
I0526 03:33:10.078510 15394 sgd_solver.cpp:43] Iteration 12050, lr = 0.02
I0526 03:33:20.592361 15394 main.cpp:354] Iteration 12060, loss = 0.635959
I0526 03:33:20.592408 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.635959 (* 1 = 0.635959 loss)
I0526 03:33:20.592422 15394 sgd_solver.cpp:43] Iteration 12060, lr = 0.02
I0526 03:33:31.570832 15394 main.cpp:354] Iteration 12070, loss = 0.624726
I0526 03:33:31.570885 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.624726 (* 1 = 0.624726 loss)
I0526 03:33:31.570895 15394 sgd_solver.cpp:43] Iteration 12070, lr = 0.02
I0526 03:33:43.071274 15394 main.cpp:354] Iteration 12080, loss = 0.593528
I0526 03:33:43.071339 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.593528 (* 1 = 0.593528 loss)
I0526 03:33:43.071351 15394 sgd_solver.cpp:43] Iteration 12080, lr = 0.02
I0526 03:33:54.822250 15394 main.cpp:354] Iteration 12090, loss = 0.5812
I0526 03:33:54.822299 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.5812 (* 1 = 0.5812 loss)
I0526 03:33:54.822307 15394 sgd_solver.cpp:43] Iteration 12090, lr = 0.02
I0526 03:34:04.816120 15394 main.cpp:465] Iteration 12100, Testing net (#0)
I0526 03:34:35.521373 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7436
I0526 03:34:35.521420 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.791295 (* 1 = 0.791295 loss)
I0526 03:34:36.430593 15394 main.cpp:354] Iteration 12100, loss = 0.407537
I0526 03:34:36.430646 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.407537 (* 1 = 0.407537 loss)
I0526 03:34:36.430658 15394 sgd_solver.cpp:43] Iteration 12100, lr = 0.02
I0526 03:34:48.089386 15394 main.cpp:354] Iteration 12110, loss = 0.362653
I0526 03:34:48.089438 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.362654 (* 1 = 0.362654 loss)
I0526 03:34:48.089447 15394 sgd_solver.cpp:43] Iteration 12110, lr = 0.02
I0526 03:34:59.347471 15394 main.cpp:354] Iteration 12120, loss = 0.430356
I0526 03:34:59.347523 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.430356 (* 1 = 0.430356 loss)
I0526 03:34:59.347532 15394 sgd_solver.cpp:43] Iteration 12120, lr = 0.02
I0526 03:35:10.903256 15394 main.cpp:354] Iteration 12130, loss = 0.325362
I0526 03:35:10.903304 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.325362 (* 1 = 0.325362 loss)
I0526 03:35:10.903312 15394 sgd_solver.cpp:43] Iteration 12130, lr = 0.02
I0526 03:35:22.696027 15394 main.cpp:354] Iteration 12140, loss = 0.369812
I0526 03:35:22.696074 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.369812 (* 1 = 0.369812 loss)
I0526 03:35:22.696081 15394 sgd_solver.cpp:43] Iteration 12140, lr = 0.02
I0526 03:35:33.547008 15394 main.cpp:354] Iteration 12150, loss = 0.415575
I0526 03:35:33.547049 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.415575 (* 1 = 0.415575 loss)
I0526 03:35:33.547057 15394 sgd_solver.cpp:43] Iteration 12150, lr = 0.02
I0526 03:35:44.742934 15394 main.cpp:354] Iteration 12160, loss = 0.354896
I0526 03:35:44.742985 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.354896 (* 1 = 0.354896 loss)
I0526 03:35:44.742992 15394 sgd_solver.cpp:43] Iteration 12160, lr = 0.02
I0526 03:35:55.933238 15394 main.cpp:354] Iteration 12170, loss = 0.482434
I0526 03:35:55.933282 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.482435 (* 1 = 0.482435 loss)
I0526 03:35:55.933291 15394 sgd_solver.cpp:43] Iteration 12170, lr = 0.02
I0526 03:36:06.958696 15394 main.cpp:354] Iteration 12180, loss = 0.352476
I0526 03:36:06.958747 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.352476 (* 1 = 0.352476 loss)
I0526 03:36:06.958755 15394 sgd_solver.cpp:43] Iteration 12180, lr = 0.02
I0526 03:36:18.876495 15394 main.cpp:354] Iteration 12190, loss = 0.394993
I0526 03:36:18.876550 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.394993 (* 1 = 0.394993 loss)
I0526 03:36:18.876560 15394 sgd_solver.cpp:43] Iteration 12190, lr = 0.02
I0526 03:36:29.222090 15394 main.cpp:465] Iteration 12200, Testing net (#0)
I0526 03:37:00.025485 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7596
I0526 03:37:00.025535 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.765876 (* 1 = 0.765876 loss)
I0526 03:37:01.122249 15394 main.cpp:354] Iteration 12200, loss = 0.481774
I0526 03:37:01.122321 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.481774 (* 1 = 0.481774 loss)
I0526 03:37:01.122331 15394 sgd_solver.cpp:43] Iteration 12200, lr = 0.02
I0526 03:37:12.644232 15394 main.cpp:354] Iteration 12210, loss = 0.410079
I0526 03:37:12.644284 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.410079 (* 1 = 0.410079 loss)
I0526 03:37:12.644292 15394 sgd_solver.cpp:43] Iteration 12210, lr = 0.02
I0526 03:37:24.555856 15394 main.cpp:354] Iteration 12220, loss = 0.482732
I0526 03:37:24.555905 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.482732 (* 1 = 0.482732 loss)
I0526 03:37:24.555914 15394 sgd_solver.cpp:43] Iteration 12220, lr = 0.02
I0526 03:37:36.045305 15394 main.cpp:354] Iteration 12230, loss = 0.431515
I0526 03:37:36.045367 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.431515 (* 1 = 0.431515 loss)
I0526 03:37:36.045375 15394 sgd_solver.cpp:43] Iteration 12230, lr = 0.02
I0526 03:37:48.500206 15394 main.cpp:354] Iteration 12240, loss = 0.391613
I0526 03:37:48.500257 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.391613 (* 1 = 0.391613 loss)
I0526 03:37:48.500267 15394 sgd_solver.cpp:43] Iteration 12240, lr = 0.02
I0526 03:37:59.345744 15394 main.cpp:354] Iteration 12250, loss = 0.482057
I0526 03:37:59.345798 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.482057 (* 1 = 0.482057 loss)
I0526 03:37:59.345808 15394 sgd_solver.cpp:43] Iteration 12250, lr = 0.02
I0526 03:38:11.059748 15394 main.cpp:354] Iteration 12260, loss = 0.312908
I0526 03:38:11.059794 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.312909 (* 1 = 0.312909 loss)
I0526 03:38:11.059803 15394 sgd_solver.cpp:43] Iteration 12260, lr = 0.02
I0526 03:38:22.084307 15394 main.cpp:354] Iteration 12270, loss = 0.482946
I0526 03:38:22.084358 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.482946 (* 1 = 0.482946 loss)
I0526 03:38:22.084367 15394 sgd_solver.cpp:43] Iteration 12270, lr = 0.02
I0526 03:38:32.913673 15394 main.cpp:354] Iteration 12280, loss = 0.498928
I0526 03:38:32.913724 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.498929 (* 1 = 0.498929 loss)
I0526 03:38:32.913733 15394 sgd_solver.cpp:43] Iteration 12280, lr = 0.02
I0526 03:38:44.681625 15394 main.cpp:354] Iteration 12290, loss = 0.526949
I0526 03:38:44.681669 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.52695 (* 1 = 0.52695 loss)
I0526 03:38:44.681677 15394 sgd_solver.cpp:43] Iteration 12290, lr = 0.02
I0526 03:38:55.594065 15394 main.cpp:465] Iteration 12300, Testing net (#0)
I0526 03:39:26.387770 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7475
I0526 03:39:26.387817 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.752741 (* 1 = 0.752741 loss)
I0526 03:39:27.352758 15394 main.cpp:354] Iteration 12300, loss = 0.650051
I0526 03:39:27.352807 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.650051 (* 1 = 0.650051 loss)
I0526 03:39:27.352816 15394 sgd_solver.cpp:43] Iteration 12300, lr = 0.02
I0526 03:39:38.788547 15394 main.cpp:354] Iteration 12310, loss = 0.497316
I0526 03:39:38.788596 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.497316 (* 1 = 0.497316 loss)
I0526 03:39:38.788604 15394 sgd_solver.cpp:43] Iteration 12310, lr = 0.02
I0526 03:39:50.486345 15394 main.cpp:354] Iteration 12320, loss = 0.703792
I0526 03:39:50.486409 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.703792 (* 1 = 0.703792 loss)
I0526 03:39:50.486418 15394 sgd_solver.cpp:43] Iteration 12320, lr = 0.02
I0526 03:40:02.575286 15394 main.cpp:354] Iteration 12330, loss = 0.44383
I0526 03:40:02.575341 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.44383 (* 1 = 0.44383 loss)
I0526 03:40:02.575350 15394 sgd_solver.cpp:43] Iteration 12330, lr = 0.02
I0526 03:40:14.757124 15394 main.cpp:354] Iteration 12340, loss = 0.434036
I0526 03:40:14.757180 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.434036 (* 1 = 0.434036 loss)
I0526 03:40:14.757190 15394 sgd_solver.cpp:43] Iteration 12340, lr = 0.02
I0526 03:40:25.905460 15394 main.cpp:354] Iteration 12350, loss = 0.697215
I0526 03:40:25.905508 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.697216 (* 1 = 0.697216 loss)
I0526 03:40:25.905517 15394 sgd_solver.cpp:43] Iteration 12350, lr = 0.02
I0526 03:40:37.162185 15394 main.cpp:354] Iteration 12360, loss = 0.436646
I0526 03:40:37.162242 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.436647 (* 1 = 0.436647 loss)
I0526 03:40:37.162252 15394 sgd_solver.cpp:43] Iteration 12360, lr = 0.02
I0526 03:40:49.202152 15394 main.cpp:354] Iteration 12370, loss = 0.450467
I0526 03:40:49.202201 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.450468 (* 1 = 0.450468 loss)
I0526 03:40:49.202209 15394 sgd_solver.cpp:43] Iteration 12370, lr = 0.02
I0526 03:40:59.975493 15394 main.cpp:354] Iteration 12380, loss = 0.515381
I0526 03:40:59.975553 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.515381 (* 1 = 0.515381 loss)
I0526 03:40:59.975563 15394 sgd_solver.cpp:43] Iteration 12380, lr = 0.02
I0526 03:41:11.091270 15394 main.cpp:354] Iteration 12390, loss = 0.338237
I0526 03:41:11.091318 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.338237 (* 1 = 0.338237 loss)
I0526 03:41:11.091327 15394 sgd_solver.cpp:43] Iteration 12390, lr = 0.02
I0526 03:41:22.209199 15394 main.cpp:465] Iteration 12400, Testing net (#0)
I0526 03:41:52.825278 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8055
I0526 03:41:52.825337 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.591105 (* 1 = 0.591105 loss)
I0526 03:41:53.792114 15394 main.cpp:354] Iteration 12400, loss = 0.498215
I0526 03:41:53.792170 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.498216 (* 1 = 0.498216 loss)
I0526 03:41:53.792177 15394 sgd_solver.cpp:43] Iteration 12400, lr = 0.02
I0526 03:42:04.750917 15394 main.cpp:354] Iteration 12410, loss = 0.476015
I0526 03:42:04.750980 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.476016 (* 1 = 0.476016 loss)
I0526 03:42:04.750988 15394 sgd_solver.cpp:43] Iteration 12410, lr = 0.02
I0526 03:42:16.118896 15394 main.cpp:354] Iteration 12420, loss = 0.556548
I0526 03:42:16.118952 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.556549 (* 1 = 0.556549 loss)
I0526 03:42:16.118962 15394 sgd_solver.cpp:43] Iteration 12420, lr = 0.02
I0526 03:42:28.076879 15394 main.cpp:354] Iteration 12430, loss = 0.417194
I0526 03:42:28.076959 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.417194 (* 1 = 0.417194 loss)
I0526 03:42:28.076970 15394 sgd_solver.cpp:43] Iteration 12430, lr = 0.02
I0526 03:42:38.645310 15394 main.cpp:354] Iteration 12440, loss = 0.385366
I0526 03:42:38.645364 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.385366 (* 1 = 0.385366 loss)
I0526 03:42:38.645373 15394 sgd_solver.cpp:43] Iteration 12440, lr = 0.02
I0526 03:42:49.347576 15394 main.cpp:354] Iteration 12450, loss = 0.798083
I0526 03:42:49.347620 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.798083 (* 1 = 0.798083 loss)
I0526 03:42:49.347628 15394 sgd_solver.cpp:43] Iteration 12450, lr = 0.02
I0526 03:43:01.228687 15394 main.cpp:354] Iteration 12460, loss = 0.76134
I0526 03:43:01.228744 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.761341 (* 1 = 0.761341 loss)
I0526 03:43:01.228752 15394 sgd_solver.cpp:43] Iteration 12460, lr = 0.02
I0526 03:43:13.118868 15394 main.cpp:354] Iteration 12470, loss = 0.429807
I0526 03:43:13.118927 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.429807 (* 1 = 0.429807 loss)
I0526 03:43:13.118949 15394 sgd_solver.cpp:43] Iteration 12470, lr = 0.02
I0526 03:43:24.020143 15394 main.cpp:354] Iteration 12480, loss = 0.57528
I0526 03:43:24.020171 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.57528 (* 1 = 0.57528 loss)
I0526 03:43:24.020184 15394 sgd_solver.cpp:43] Iteration 12480, lr = 0.02
I0526 03:43:36.024031 15394 main.cpp:354] Iteration 12490, loss = 0.444455
I0526 03:43:36.024098 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.444455 (* 1 = 0.444455 loss)
I0526 03:43:36.024106 15394 sgd_solver.cpp:43] Iteration 12490, lr = 0.02
I0526 03:43:46.359439 15394 main.cpp:465] Iteration 12500, Testing net (#0)
I0526 03:44:16.926857 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7652
I0526 03:44:16.926900 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.719775 (* 1 = 0.719775 loss)
I0526 03:44:18.064394 15394 main.cpp:354] Iteration 12500, loss = 0.270111
I0526 03:44:18.064451 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.270111 (* 1 = 0.270111 loss)
I0526 03:44:18.064461 15394 sgd_solver.cpp:43] Iteration 12500, lr = 0.02
I0526 03:44:28.866818 15394 main.cpp:354] Iteration 12510, loss = 0.473837
I0526 03:44:28.866873 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.473838 (* 1 = 0.473838 loss)
I0526 03:44:28.866881 15394 sgd_solver.cpp:43] Iteration 12510, lr = 0.02
I0526 03:44:39.991334 15394 main.cpp:354] Iteration 12520, loss = 0.272866
I0526 03:44:39.991387 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.272867 (* 1 = 0.272867 loss)
I0526 03:44:39.991396 15394 sgd_solver.cpp:43] Iteration 12520, lr = 0.02
I0526 03:44:51.691642 15394 main.cpp:354] Iteration 12530, loss = 0.686183
I0526 03:44:51.691700 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.686183 (* 1 = 0.686183 loss)
I0526 03:44:51.691710 15394 sgd_solver.cpp:43] Iteration 12530, lr = 0.02
I0526 03:45:03.799151 15394 main.cpp:354] Iteration 12540, loss = 0.659423
I0526 03:45:03.799207 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.659423 (* 1 = 0.659423 loss)
I0526 03:45:03.799216 15394 sgd_solver.cpp:43] Iteration 12540, lr = 0.02
I0526 03:45:15.950553 15394 main.cpp:354] Iteration 12550, loss = 0.383852
I0526 03:45:15.950615 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.383852 (* 1 = 0.383852 loss)
I0526 03:45:15.950623 15394 sgd_solver.cpp:43] Iteration 12550, lr = 0.02
I0526 03:45:26.686082 15394 main.cpp:354] Iteration 12560, loss = 0.703035
I0526 03:45:26.686131 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.703035 (* 1 = 0.703035 loss)
I0526 03:45:26.686141 15394 sgd_solver.cpp:43] Iteration 12560, lr = 0.02
I0526 03:45:38.437168 15394 main.cpp:354] Iteration 12570, loss = 0.621397
I0526 03:45:38.437216 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.621397 (* 1 = 0.621397 loss)
I0526 03:45:38.437223 15394 sgd_solver.cpp:43] Iteration 12570, lr = 0.02
I0526 03:45:49.717604 15394 main.cpp:354] Iteration 12580, loss = 0.653391
I0526 03:45:49.717649 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.653391 (* 1 = 0.653391 loss)
I0526 03:45:49.717656 15394 sgd_solver.cpp:43] Iteration 12580, lr = 0.02
I0526 03:46:01.367362 15394 main.cpp:354] Iteration 12590, loss = 0.315742
I0526 03:46:01.367415 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.315743 (* 1 = 0.315743 loss)
I0526 03:46:01.367424 15394 sgd_solver.cpp:43] Iteration 12590, lr = 0.02
I0526 03:46:12.109840 15394 main.cpp:465] Iteration 12600, Testing net (#0)
I0526 03:46:42.721894 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8119
I0526 03:46:42.721940 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.545515 (* 1 = 0.545515 loss)
I0526 03:46:43.675222 15394 main.cpp:354] Iteration 12600, loss = 0.415392
I0526 03:46:43.675266 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.415392 (* 1 = 0.415392 loss)
I0526 03:46:43.675274 15394 sgd_solver.cpp:43] Iteration 12600, lr = 0.02
I0526 03:46:55.877959 15394 main.cpp:354] Iteration 12610, loss = 0.439888
I0526 03:46:55.878000 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.439888 (* 1 = 0.439888 loss)
I0526 03:46:55.878008 15394 sgd_solver.cpp:43] Iteration 12610, lr = 0.02
I0526 03:47:06.353436 15394 main.cpp:354] Iteration 12620, loss = 0.357979
I0526 03:47:06.353482 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.357979 (* 1 = 0.357979 loss)
I0526 03:47:06.353488 15394 sgd_solver.cpp:43] Iteration 12620, lr = 0.02
I0526 03:47:17.294417 15394 main.cpp:354] Iteration 12630, loss = 0.398444
I0526 03:47:17.294466 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.398445 (* 1 = 0.398445 loss)
I0526 03:47:17.294474 15394 sgd_solver.cpp:43] Iteration 12630, lr = 0.02
I0526 03:47:28.789465 15394 main.cpp:354] Iteration 12640, loss = 0.438848
I0526 03:47:28.789512 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.438848 (* 1 = 0.438848 loss)
I0526 03:47:28.789521 15394 sgd_solver.cpp:43] Iteration 12640, lr = 0.02
I0526 03:47:39.944221 15394 main.cpp:354] Iteration 12650, loss = 0.326801
I0526 03:47:39.944272 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.326801 (* 1 = 0.326801 loss)
I0526 03:47:39.944279 15394 sgd_solver.cpp:43] Iteration 12650, lr = 0.02
I0526 03:47:51.250499 15394 main.cpp:354] Iteration 12660, loss = 0.475501
I0526 03:47:51.250536 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.475501 (* 1 = 0.475501 loss)
I0526 03:47:51.250543 15394 sgd_solver.cpp:43] Iteration 12660, lr = 0.02
I0526 03:48:02.808303 15394 main.cpp:354] Iteration 12670, loss = 0.603023
I0526 03:48:02.808357 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.603023 (* 1 = 0.603023 loss)
I0526 03:48:02.808364 15394 sgd_solver.cpp:43] Iteration 12670, lr = 0.02
I0526 03:48:13.694551 15394 main.cpp:354] Iteration 12680, loss = 0.664735
I0526 03:48:13.694594 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.664736 (* 1 = 0.664736 loss)
I0526 03:48:13.694602 15394 sgd_solver.cpp:43] Iteration 12680, lr = 0.02
I0526 03:48:25.258100 15394 main.cpp:354] Iteration 12690, loss = 0.614024
I0526 03:48:25.258134 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.614025 (* 1 = 0.614025 loss)
I0526 03:48:25.258142 15394 sgd_solver.cpp:43] Iteration 12690, lr = 0.02
I0526 03:48:36.027251 15394 main.cpp:465] Iteration 12700, Testing net (#0)
I0526 03:49:06.675549 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7757
I0526 03:49:06.675601 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.644696 (* 1 = 0.644696 loss)
I0526 03:49:07.475769 15394 main.cpp:354] Iteration 12700, loss = 0.868333
I0526 03:49:07.475796 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.868333 (* 1 = 0.868333 loss)
I0526 03:49:07.475803 15394 sgd_solver.cpp:43] Iteration 12700, lr = 0.02
I0526 03:49:18.437736 15394 main.cpp:354] Iteration 12710, loss = 0.467128
I0526 03:49:18.437777 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.467129 (* 1 = 0.467129 loss)
I0526 03:49:18.437784 15394 sgd_solver.cpp:43] Iteration 12710, lr = 0.02
I0526 03:49:29.715863 15394 main.cpp:354] Iteration 12720, loss = 0.382721
I0526 03:49:29.715906 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.382722 (* 1 = 0.382722 loss)
I0526 03:49:29.715915 15394 sgd_solver.cpp:43] Iteration 12720, lr = 0.02
I0526 03:49:41.010239 15394 main.cpp:354] Iteration 12730, loss = 0.407595
I0526 03:49:41.010284 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.407596 (* 1 = 0.407596 loss)
I0526 03:49:41.010293 15394 sgd_solver.cpp:43] Iteration 12730, lr = 0.02
I0526 03:49:52.698889 15394 main.cpp:354] Iteration 12740, loss = 0.672072
I0526 03:49:52.698943 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.672073 (* 1 = 0.672073 loss)
I0526 03:49:52.698950 15394 sgd_solver.cpp:43] Iteration 12740, lr = 0.02
I0526 03:50:03.730005 15394 main.cpp:354] Iteration 12750, loss = 0.503362
I0526 03:50:03.730046 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.503362 (* 1 = 0.503362 loss)
I0526 03:50:03.730062 15394 sgd_solver.cpp:43] Iteration 12750, lr = 0.02
I0526 03:50:15.071658 15394 main.cpp:354] Iteration 12760, loss = 0.653128
I0526 03:50:15.071707 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.653128 (* 1 = 0.653128 loss)
I0526 03:50:15.071714 15394 sgd_solver.cpp:43] Iteration 12760, lr = 0.02
I0526 03:50:26.918016 15394 main.cpp:354] Iteration 12770, loss = 0.502607
I0526 03:50:26.918053 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.502607 (* 1 = 0.502607 loss)
I0526 03:50:26.918061 15394 sgd_solver.cpp:43] Iteration 12770, lr = 0.02
I0526 03:50:38.316288 15394 main.cpp:354] Iteration 12780, loss = 0.407416
I0526 03:50:38.316329 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.407416 (* 1 = 0.407416 loss)
I0526 03:50:38.316335 15394 sgd_solver.cpp:43] Iteration 12780, lr = 0.02
I0526 03:50:49.990417 15394 main.cpp:354] Iteration 12790, loss = 0.482055
I0526 03:50:49.990461 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.482056 (* 1 = 0.482056 loss)
I0526 03:50:49.990470 15394 sgd_solver.cpp:43] Iteration 12790, lr = 0.02
I0526 03:50:59.397893 15394 main.cpp:465] Iteration 12800, Testing net (#0)
I0526 03:51:30.061882 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7598
I0526 03:51:30.061923 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.670302 (* 1 = 0.670302 loss)
I0526 03:51:31.091963 15394 main.cpp:354] Iteration 12800, loss = 0.509989
I0526 03:51:31.092006 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.509989 (* 1 = 0.509989 loss)
I0526 03:51:31.092015 15394 sgd_solver.cpp:43] Iteration 12800, lr = 0.02
I0526 03:51:42.335536 15394 main.cpp:354] Iteration 12810, loss = 0.620992
I0526 03:51:42.335572 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.620992 (* 1 = 0.620992 loss)
I0526 03:51:42.335577 15394 sgd_solver.cpp:43] Iteration 12810, lr = 0.02
I0526 03:51:53.927264 15394 main.cpp:354] Iteration 12820, loss = 0.500535
I0526 03:51:53.927309 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.500535 (* 1 = 0.500535 loss)
I0526 03:51:53.927315 15394 sgd_solver.cpp:43] Iteration 12820, lr = 0.02
I0526 03:52:04.860862 15394 main.cpp:354] Iteration 12830, loss = 0.349991
I0526 03:52:04.860919 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.349991 (* 1 = 0.349991 loss)
I0526 03:52:04.860927 15394 sgd_solver.cpp:43] Iteration 12830, lr = 0.02
I0526 03:52:16.613477 15394 main.cpp:354] Iteration 12840, loss = 0.31641
I0526 03:52:16.613533 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.316411 (* 1 = 0.316411 loss)
I0526 03:52:16.613551 15394 sgd_solver.cpp:43] Iteration 12840, lr = 0.02
I0526 03:52:27.723469 15394 main.cpp:354] Iteration 12850, loss = 0.567406
I0526 03:52:27.723512 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.567407 (* 1 = 0.567407 loss)
I0526 03:52:27.723521 15394 sgd_solver.cpp:43] Iteration 12850, lr = 0.02
I0526 03:52:38.349153 15394 main.cpp:354] Iteration 12860, loss = 0.434904
I0526 03:52:38.349194 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.434905 (* 1 = 0.434905 loss)
I0526 03:52:38.349200 15394 sgd_solver.cpp:43] Iteration 12860, lr = 0.02
I0526 03:52:49.866130 15394 main.cpp:354] Iteration 12870, loss = 0.419953
I0526 03:52:49.866171 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.419953 (* 1 = 0.419953 loss)
I0526 03:52:49.866178 15394 sgd_solver.cpp:43] Iteration 12870, lr = 0.02
I0526 03:53:02.072306 15394 main.cpp:354] Iteration 12880, loss = 0.321759
I0526 03:53:02.072350 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.321759 (* 1 = 0.321759 loss)
I0526 03:53:02.072356 15394 sgd_solver.cpp:43] Iteration 12880, lr = 0.02
I0526 03:53:12.947556 15394 main.cpp:354] Iteration 12890, loss = 0.408156
I0526 03:53:12.947600 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.408156 (* 1 = 0.408156 loss)
I0526 03:53:12.947608 15394 sgd_solver.cpp:43] Iteration 12890, lr = 0.02
I0526 03:53:23.049799 15394 main.cpp:465] Iteration 12900, Testing net (#0)
I0526 03:53:53.681988 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7726
I0526 03:53:53.682034 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.699855 (* 1 = 0.699855 loss)
I0526 03:53:54.682957 15394 main.cpp:354] Iteration 12900, loss = 0.435244
I0526 03:53:54.682997 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.435244 (* 1 = 0.435244 loss)
I0526 03:53:54.683006 15394 sgd_solver.cpp:43] Iteration 12900, lr = 0.02
I0526 03:54:06.411295 15394 main.cpp:354] Iteration 12910, loss = 0.319336
I0526 03:54:06.411341 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.319336 (* 1 = 0.319336 loss)
I0526 03:54:06.411350 15394 sgd_solver.cpp:43] Iteration 12910, lr = 0.02
I0526 03:54:17.746829 15394 main.cpp:354] Iteration 12920, loss = 0.583645
I0526 03:54:17.746870 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.583645 (* 1 = 0.583645 loss)
I0526 03:54:17.746877 15394 sgd_solver.cpp:43] Iteration 12920, lr = 0.02
I0526 03:54:29.331945 15394 main.cpp:354] Iteration 12930, loss = 0.687576
I0526 03:54:29.331989 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.687576 (* 1 = 0.687576 loss)
I0526 03:54:29.331995 15394 sgd_solver.cpp:43] Iteration 12930, lr = 0.02
I0526 03:54:40.280803 15394 main.cpp:354] Iteration 12940, loss = 0.429715
I0526 03:54:40.280845 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.429715 (* 1 = 0.429715 loss)
I0526 03:54:40.280853 15394 sgd_solver.cpp:43] Iteration 12940, lr = 0.02
I0526 03:54:51.591893 15394 main.cpp:354] Iteration 12950, loss = 0.555304
I0526 03:54:51.591934 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.555304 (* 1 = 0.555304 loss)
I0526 03:54:51.591940 15394 sgd_solver.cpp:43] Iteration 12950, lr = 0.02
I0526 03:55:03.176537 15394 main.cpp:354] Iteration 12960, loss = 0.489968
I0526 03:55:03.176569 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.489968 (* 1 = 0.489968 loss)
I0526 03:55:03.176576 15394 sgd_solver.cpp:43] Iteration 12960, lr = 0.02
I0526 03:55:13.830953 15394 main.cpp:354] Iteration 12970, loss = 0.625974
I0526 03:55:13.831007 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.625974 (* 1 = 0.625974 loss)
I0526 03:55:13.831013 15394 sgd_solver.cpp:43] Iteration 12970, lr = 0.02
I0526 03:55:25.173764 15394 main.cpp:354] Iteration 12980, loss = 0.387102
I0526 03:55:25.173804 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.387102 (* 1 = 0.387102 loss)
I0526 03:55:25.173810 15394 sgd_solver.cpp:43] Iteration 12980, lr = 0.02
I0526 03:55:36.978196 15394 main.cpp:354] Iteration 12990, loss = 0.447259
I0526 03:55:36.978252 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.447259 (* 1 = 0.447259 loss)
I0526 03:55:36.978262 15394 sgd_solver.cpp:43] Iteration 12990, lr = 0.02
I0526 03:55:46.796499 15394 main.cpp:465] Iteration 13000, Testing net (#0)
I0526 03:56:17.495007 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7696
I0526 03:56:17.495045 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.695312 (* 1 = 0.695312 loss)
I0526 03:56:18.455870 15394 main.cpp:354] Iteration 13000, loss = 0.47839
I0526 03:56:18.455911 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.47839 (* 1 = 0.47839 loss)
I0526 03:56:18.455919 15394 sgd_solver.cpp:43] Iteration 13000, lr = 0.02
I0526 03:56:29.806619 15394 main.cpp:354] Iteration 13010, loss = 0.562176
I0526 03:56:29.806663 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.562176 (* 1 = 0.562176 loss)
I0526 03:56:29.806669 15394 sgd_solver.cpp:43] Iteration 13010, lr = 0.02
I0526 03:56:41.790308 15394 main.cpp:354] Iteration 13020, loss = 0.455813
I0526 03:56:41.790349 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.455813 (* 1 = 0.455813 loss)
I0526 03:56:41.790360 15394 sgd_solver.cpp:43] Iteration 13020, lr = 0.02
I0526 03:56:53.416816 15394 main.cpp:354] Iteration 13030, loss = 0.28901
I0526 03:56:53.416862 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.28901 (* 1 = 0.28901 loss)
I0526 03:56:53.416868 15394 sgd_solver.cpp:43] Iteration 13030, lr = 0.02
I0526 03:57:04.813913 15394 main.cpp:354] Iteration 13040, loss = 0.551165
I0526 03:57:04.813956 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.551165 (* 1 = 0.551165 loss)
I0526 03:57:04.813962 15394 sgd_solver.cpp:43] Iteration 13040, lr = 0.02
I0526 03:57:15.631125 15394 main.cpp:354] Iteration 13050, loss = 0.536982
I0526 03:57:15.631170 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.536982 (* 1 = 0.536982 loss)
I0526 03:57:15.631177 15394 sgd_solver.cpp:43] Iteration 13050, lr = 0.02
I0526 03:57:27.450366 15394 main.cpp:354] Iteration 13060, loss = 0.579137
I0526 03:57:27.450404 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.579137 (* 1 = 0.579137 loss)
I0526 03:57:27.450412 15394 sgd_solver.cpp:43] Iteration 13060, lr = 0.02
I0526 03:57:39.223984 15394 main.cpp:354] Iteration 13070, loss = 0.439338
I0526 03:57:39.224030 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.439338 (* 1 = 0.439338 loss)
I0526 03:57:39.224035 15394 sgd_solver.cpp:43] Iteration 13070, lr = 0.02
I0526 03:57:50.197674 15394 main.cpp:354] Iteration 13080, loss = 0.742619
I0526 03:57:50.197718 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.742619 (* 1 = 0.742619 loss)
I0526 03:57:50.197726 15394 sgd_solver.cpp:43] Iteration 13080, lr = 0.02
I0526 03:58:01.706732 15394 main.cpp:354] Iteration 13090, loss = 0.481862
I0526 03:58:01.706773 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.481862 (* 1 = 0.481862 loss)
I0526 03:58:01.706779 15394 sgd_solver.cpp:43] Iteration 13090, lr = 0.02
I0526 03:58:11.987689 15394 main.cpp:465] Iteration 13100, Testing net (#0)
I0526 03:58:42.657686 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7563
I0526 03:58:42.657727 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.759672 (* 1 = 0.759672 loss)
I0526 03:58:43.653415 15394 main.cpp:354] Iteration 13100, loss = 0.674256
I0526 03:58:43.653456 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.674256 (* 1 = 0.674256 loss)
I0526 03:58:43.653465 15394 sgd_solver.cpp:43] Iteration 13100, lr = 0.02
I0526 03:58:54.529369 15394 main.cpp:354] Iteration 13110, loss = 0.540404
I0526 03:58:54.529417 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.540404 (* 1 = 0.540404 loss)
I0526 03:58:54.529424 15394 sgd_solver.cpp:43] Iteration 13110, lr = 0.02
I0526 03:59:06.014736 15394 main.cpp:354] Iteration 13120, loss = 0.289648
I0526 03:59:06.014776 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.289648 (* 1 = 0.289648 loss)
I0526 03:59:06.014782 15394 sgd_solver.cpp:43] Iteration 13120, lr = 0.02
I0526 03:59:18.063577 15394 main.cpp:354] Iteration 13130, loss = 0.616533
I0526 03:59:18.063621 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.616533 (* 1 = 0.616533 loss)
I0526 03:59:18.063628 15394 sgd_solver.cpp:43] Iteration 13130, lr = 0.02
I0526 03:59:30.082136 15394 main.cpp:354] Iteration 13140, loss = 0.531019
I0526 03:59:30.082175 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.531019 (* 1 = 0.531019 loss)
I0526 03:59:30.082180 15394 sgd_solver.cpp:43] Iteration 13140, lr = 0.02
I0526 03:59:40.308634 15394 main.cpp:354] Iteration 13150, loss = 0.529056
I0526 03:59:40.308675 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.529056 (* 1 = 0.529056 loss)
I0526 03:59:40.308681 15394 sgd_solver.cpp:43] Iteration 13150, lr = 0.02
I0526 03:59:51.368517 15394 main.cpp:354] Iteration 13160, loss = 0.395146
I0526 03:59:51.368564 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.395147 (* 1 = 0.395147 loss)
I0526 03:59:51.368571 15394 sgd_solver.cpp:43] Iteration 13160, lr = 0.02
I0526 04:00:02.054896 15394 main.cpp:354] Iteration 13170, loss = 0.417414
I0526 04:00:02.054939 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.417414 (* 1 = 0.417414 loss)
I0526 04:00:02.054945 15394 sgd_solver.cpp:43] Iteration 13170, lr = 0.02
I0526 04:00:13.581853 15394 main.cpp:354] Iteration 13180, loss = 0.606187
I0526 04:00:13.581902 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.606187 (* 1 = 0.606187 loss)
I0526 04:00:13.581910 15394 sgd_solver.cpp:43] Iteration 13180, lr = 0.02
I0526 04:00:23.809998 15394 main.cpp:354] Iteration 13190, loss = 0.43082
I0526 04:00:23.810039 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.43082 (* 1 = 0.43082 loss)
I0526 04:00:23.810046 15394 sgd_solver.cpp:43] Iteration 13190, lr = 0.02
I0526 04:00:34.371117 15394 main.cpp:465] Iteration 13200, Testing net (#0)
I0526 04:01:04.902528 15394 main.cpp:532]     Test net output #0: Accuracy = 0.735
I0526 04:01:04.902570 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.782925 (* 1 = 0.782925 loss)
I0526 04:01:05.863880 15394 main.cpp:354] Iteration 13200, loss = 0.621757
I0526 04:01:05.863925 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.621757 (* 1 = 0.621757 loss)
I0526 04:01:05.863934 15394 sgd_solver.cpp:43] Iteration 13200, lr = 0.02
I0526 04:01:16.706184 15394 main.cpp:354] Iteration 13210, loss = 0.551969
I0526 04:01:16.706226 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.551969 (* 1 = 0.551969 loss)
I0526 04:01:16.706233 15394 sgd_solver.cpp:43] Iteration 13210, lr = 0.02
I0526 04:01:28.080016 15394 main.cpp:354] Iteration 13220, loss = 0.581436
I0526 04:01:28.080060 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.581437 (* 1 = 0.581437 loss)
I0526 04:01:28.080068 15394 sgd_solver.cpp:43] Iteration 13220, lr = 0.02
I0526 04:01:39.371249 15394 main.cpp:354] Iteration 13230, loss = 0.792764
I0526 04:01:39.371292 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.792764 (* 1 = 0.792764 loss)
I0526 04:01:39.371299 15394 sgd_solver.cpp:43] Iteration 13230, lr = 0.02
I0526 04:01:50.786624 15394 main.cpp:354] Iteration 13240, loss = 0.505161
I0526 04:01:50.786676 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.505161 (* 1 = 0.505161 loss)
I0526 04:01:50.786684 15394 sgd_solver.cpp:43] Iteration 13240, lr = 0.02
I0526 04:02:01.610448 15394 main.cpp:354] Iteration 13250, loss = 1.05762
I0526 04:02:01.610479 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.05762 (* 1 = 1.05762 loss)
I0526 04:02:01.610486 15394 sgd_solver.cpp:43] Iteration 13250, lr = 0.02
I0526 04:02:13.108618 15394 main.cpp:354] Iteration 13260, loss = 0.322424
I0526 04:02:13.108666 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.322424 (* 1 = 0.322424 loss)
I0526 04:02:13.108675 15394 sgd_solver.cpp:43] Iteration 13260, lr = 0.02
I0526 04:02:24.273072 15394 main.cpp:354] Iteration 13270, loss = 0.373259
I0526 04:02:24.273114 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.37326 (* 1 = 0.37326 loss)
I0526 04:02:24.273123 15394 sgd_solver.cpp:43] Iteration 13270, lr = 0.02
I0526 04:02:36.016515 15394 main.cpp:354] Iteration 13280, loss = 0.224785
I0526 04:02:36.016557 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.224785 (* 1 = 0.224785 loss)
I0526 04:02:36.016564 15394 sgd_solver.cpp:43] Iteration 13280, lr = 0.02
I0526 04:02:47.784057 15394 main.cpp:354] Iteration 13290, loss = 0.404173
I0526 04:02:47.784101 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.404173 (* 1 = 0.404173 loss)
I0526 04:02:47.784107 15394 sgd_solver.cpp:43] Iteration 13290, lr = 0.02
I0526 04:02:58.024112 15394 main.cpp:465] Iteration 13300, Testing net (#0)
I0526 04:03:28.626714 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7066
I0526 04:03:28.626770 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.898495 (* 1 = 0.898495 loss)
I0526 04:03:29.899541 15394 main.cpp:354] Iteration 13300, loss = 0.308453
I0526 04:03:29.899575 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.308453 (* 1 = 0.308453 loss)
I0526 04:03:29.899583 15394 sgd_solver.cpp:43] Iteration 13300, lr = 0.02
I0526 04:03:41.693543 15394 main.cpp:354] Iteration 13310, loss = 0.499081
I0526 04:03:41.693583 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.499081 (* 1 = 0.499081 loss)
I0526 04:03:41.693595 15394 sgd_solver.cpp:43] Iteration 13310, lr = 0.02
I0526 04:03:53.011634 15394 main.cpp:354] Iteration 13320, loss = 0.712105
I0526 04:03:53.011675 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.712105 (* 1 = 0.712105 loss)
I0526 04:03:53.011682 15394 sgd_solver.cpp:43] Iteration 13320, lr = 0.02
I0526 04:04:05.087952 15394 main.cpp:354] Iteration 13330, loss = 0.418769
I0526 04:04:05.087996 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.418769 (* 1 = 0.418769 loss)
I0526 04:04:05.088003 15394 sgd_solver.cpp:43] Iteration 13330, lr = 0.02
I0526 04:04:15.792444 15394 main.cpp:354] Iteration 13340, loss = 0.679395
I0526 04:04:15.792500 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.679395 (* 1 = 0.679395 loss)
I0526 04:04:15.792517 15394 sgd_solver.cpp:43] Iteration 13340, lr = 0.02
I0526 04:04:27.986680 15394 main.cpp:354] Iteration 13350, loss = 0.331625
I0526 04:04:27.986716 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.331625 (* 1 = 0.331625 loss)
I0526 04:04:27.986726 15394 sgd_solver.cpp:43] Iteration 13350, lr = 0.02
I0526 04:04:39.338871 15394 main.cpp:354] Iteration 13360, loss = 0.507706
I0526 04:04:39.338914 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.507706 (* 1 = 0.507706 loss)
I0526 04:04:39.338922 15394 sgd_solver.cpp:43] Iteration 13360, lr = 0.02
I0526 04:04:51.089491 15394 main.cpp:354] Iteration 13370, loss = 0.347009
I0526 04:04:51.089531 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.347009 (* 1 = 0.347009 loss)
I0526 04:04:51.089539 15394 sgd_solver.cpp:43] Iteration 13370, lr = 0.02
I0526 04:05:02.872129 15394 main.cpp:354] Iteration 13380, loss = 0.397031
I0526 04:05:02.872174 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.397031 (* 1 = 0.397031 loss)
I0526 04:05:02.872181 15394 sgd_solver.cpp:43] Iteration 13380, lr = 0.02
I0526 04:05:13.343531 15394 main.cpp:354] Iteration 13390, loss = 0.565778
I0526 04:05:13.343577 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.565778 (* 1 = 0.565778 loss)
I0526 04:05:13.343585 15394 sgd_solver.cpp:43] Iteration 13390, lr = 0.02
I0526 04:05:23.677449 15394 main.cpp:465] Iteration 13400, Testing net (#0)
I0526 04:05:54.384371 15394 main.cpp:532]     Test net output #0: Accuracy = 0.758
I0526 04:05:54.384408 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.70386 (* 1 = 0.70386 loss)
I0526 04:05:55.391038 15394 main.cpp:354] Iteration 13400, loss = 0.45626
I0526 04:05:55.391098 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.45626 (* 1 = 0.45626 loss)
I0526 04:05:55.391108 15394 sgd_solver.cpp:43] Iteration 13400, lr = 0.02
I0526 04:06:05.727414 15394 main.cpp:354] Iteration 13410, loss = 0.566287
I0526 04:06:05.727460 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.566288 (* 1 = 0.566288 loss)
I0526 04:06:05.727469 15394 sgd_solver.cpp:43] Iteration 13410, lr = 0.02
I0526 04:06:17.553220 15394 main.cpp:354] Iteration 13420, loss = 0.408122
I0526 04:06:17.553261 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.408122 (* 1 = 0.408122 loss)
I0526 04:06:17.553268 15394 sgd_solver.cpp:43] Iteration 13420, lr = 0.02
I0526 04:06:29.146884 15394 main.cpp:354] Iteration 13430, loss = 0.591577
I0526 04:06:29.146939 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.591577 (* 1 = 0.591577 loss)
I0526 04:06:29.146946 15394 sgd_solver.cpp:43] Iteration 13430, lr = 0.02
I0526 04:06:39.756444 15394 main.cpp:354] Iteration 13440, loss = 0.489043
I0526 04:06:39.756484 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.489043 (* 1 = 0.489043 loss)
I0526 04:06:39.756490 15394 sgd_solver.cpp:43] Iteration 13440, lr = 0.02
I0526 04:06:51.649652 15394 main.cpp:354] Iteration 13450, loss = 0.404194
I0526 04:06:51.649693 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.404194 (* 1 = 0.404194 loss)
I0526 04:06:51.649710 15394 sgd_solver.cpp:43] Iteration 13450, lr = 0.02
I0526 04:07:02.811944 15394 main.cpp:354] Iteration 13460, loss = 0.540495
I0526 04:07:02.811990 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.540495 (* 1 = 0.540495 loss)
I0526 04:07:02.811997 15394 sgd_solver.cpp:43] Iteration 13460, lr = 0.02
I0526 04:07:15.158313 15394 main.cpp:354] Iteration 13470, loss = 0.540686
I0526 04:07:15.158357 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.540686 (* 1 = 0.540686 loss)
I0526 04:07:15.158375 15394 sgd_solver.cpp:43] Iteration 13470, lr = 0.02
I0526 04:07:26.569411 15394 main.cpp:354] Iteration 13480, loss = 0.366682
I0526 04:07:26.569461 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.366682 (* 1 = 0.366682 loss)
I0526 04:07:26.569469 15394 sgd_solver.cpp:43] Iteration 13480, lr = 0.02
I0526 04:07:38.086212 15394 main.cpp:354] Iteration 13490, loss = 0.477576
I0526 04:07:38.086254 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.477576 (* 1 = 0.477576 loss)
I0526 04:07:38.086261 15394 sgd_solver.cpp:43] Iteration 13490, lr = 0.02
I0526 04:07:48.535449 15394 main.cpp:465] Iteration 13500, Testing net (#0)
I0526 04:08:19.224720 15394 main.cpp:532]     Test net output #0: Accuracy = 0.747
I0526 04:08:19.224764 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.772245 (* 1 = 0.772245 loss)
I0526 04:08:20.436193 15394 main.cpp:354] Iteration 13500, loss = 0.391086
I0526 04:08:20.436233 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.391086 (* 1 = 0.391086 loss)
I0526 04:08:20.436252 15394 sgd_solver.cpp:43] Iteration 13500, lr = 0.02
I0526 04:08:32.203281 15394 main.cpp:354] Iteration 13510, loss = 0.293735
I0526 04:08:32.203326 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.293735 (* 1 = 0.293735 loss)
I0526 04:08:32.203332 15394 sgd_solver.cpp:43] Iteration 13510, lr = 0.02
I0526 04:08:43.935557 15394 main.cpp:354] Iteration 13520, loss = 0.412965
I0526 04:08:43.935600 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.412965 (* 1 = 0.412965 loss)
I0526 04:08:43.935608 15394 sgd_solver.cpp:43] Iteration 13520, lr = 0.02
I0526 04:08:55.420920 15394 main.cpp:354] Iteration 13530, loss = 0.416385
I0526 04:08:55.420958 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.416385 (* 1 = 0.416385 loss)
I0526 04:08:55.420964 15394 sgd_solver.cpp:43] Iteration 13530, lr = 0.02
I0526 04:09:07.679018 15394 main.cpp:354] Iteration 13540, loss = 0.510843
I0526 04:09:07.679054 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.510843 (* 1 = 0.510843 loss)
I0526 04:09:07.679061 15394 sgd_solver.cpp:43] Iteration 13540, lr = 0.02
I0526 04:09:19.467767 15394 main.cpp:354] Iteration 13550, loss = 0.3625
I0526 04:09:19.467809 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.3625 (* 1 = 0.3625 loss)
I0526 04:09:19.467816 15394 sgd_solver.cpp:43] Iteration 13550, lr = 0.02
I0526 04:09:30.463040 15394 main.cpp:354] Iteration 13560, loss = 0.629472
I0526 04:09:30.463083 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.629472 (* 1 = 0.629472 loss)
I0526 04:09:30.463088 15394 sgd_solver.cpp:43] Iteration 13560, lr = 0.02
I0526 04:09:41.575253 15394 main.cpp:354] Iteration 13570, loss = 0.597815
I0526 04:09:41.575292 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.597815 (* 1 = 0.597815 loss)
I0526 04:09:41.575299 15394 sgd_solver.cpp:43] Iteration 13570, lr = 0.02
I0526 04:09:53.203236 15394 main.cpp:354] Iteration 13580, loss = 0.458805
I0526 04:09:53.203280 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.458805 (* 1 = 0.458805 loss)
I0526 04:09:53.203287 15394 sgd_solver.cpp:43] Iteration 13580, lr = 0.02
I0526 04:10:04.362073 15394 main.cpp:354] Iteration 13590, loss = 0.595706
I0526 04:10:04.362107 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.595706 (* 1 = 0.595706 loss)
I0526 04:10:04.362112 15394 sgd_solver.cpp:43] Iteration 13590, lr = 0.02
I0526 04:10:14.692596 15394 main.cpp:465] Iteration 13600, Testing net (#0)
I0526 04:10:45.447907 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7304
I0526 04:10:45.447950 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.807224 (* 1 = 0.807224 loss)
I0526 04:10:46.414443 15394 main.cpp:354] Iteration 13600, loss = 0.628107
I0526 04:10:46.414481 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.628108 (* 1 = 0.628108 loss)
I0526 04:10:46.414489 15394 sgd_solver.cpp:43] Iteration 13600, lr = 0.02
I0526 04:10:57.966262 15394 main.cpp:354] Iteration 13610, loss = 0.415709
I0526 04:10:57.966305 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.415709 (* 1 = 0.415709 loss)
I0526 04:10:57.966312 15394 sgd_solver.cpp:43] Iteration 13610, lr = 0.02
I0526 04:11:09.683220 15394 main.cpp:354] Iteration 13620, loss = 0.568782
I0526 04:11:09.683260 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.568782 (* 1 = 0.568782 loss)
I0526 04:11:09.683269 15394 sgd_solver.cpp:43] Iteration 13620, lr = 0.02
I0526 04:11:20.911757 15394 main.cpp:354] Iteration 13630, loss = 0.495113
I0526 04:11:20.911797 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.495113 (* 1 = 0.495113 loss)
I0526 04:11:20.911803 15394 sgd_solver.cpp:43] Iteration 13630, lr = 0.02
I0526 04:11:32.083586 15394 main.cpp:354] Iteration 13640, loss = 0.573569
I0526 04:11:32.083626 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.573569 (* 1 = 0.573569 loss)
I0526 04:11:32.083643 15394 sgd_solver.cpp:43] Iteration 13640, lr = 0.02
I0526 04:11:43.104980 15394 main.cpp:354] Iteration 13650, loss = 0.429657
I0526 04:11:43.105020 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.429657 (* 1 = 0.429657 loss)
I0526 04:11:43.105028 15394 sgd_solver.cpp:43] Iteration 13650, lr = 0.02
I0526 04:11:54.486027 15394 main.cpp:354] Iteration 13660, loss = 0.462913
I0526 04:11:54.486063 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.462913 (* 1 = 0.462913 loss)
I0526 04:11:54.486070 15394 sgd_solver.cpp:43] Iteration 13660, lr = 0.02
I0526 04:12:06.135087 15394 main.cpp:354] Iteration 13670, loss = 0.430626
I0526 04:12:06.135129 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.430626 (* 1 = 0.430626 loss)
I0526 04:12:06.135136 15394 sgd_solver.cpp:43] Iteration 13670, lr = 0.02
I0526 04:12:17.676792 15394 main.cpp:354] Iteration 13680, loss = 0.35707
I0526 04:12:17.676836 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.35707 (* 1 = 0.35707 loss)
I0526 04:12:17.676844 15394 sgd_solver.cpp:43] Iteration 13680, lr = 0.02
I0526 04:12:29.642230 15394 main.cpp:354] Iteration 13690, loss = 0.347794
I0526 04:12:29.642278 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.347794 (* 1 = 0.347794 loss)
I0526 04:12:29.642287 15394 sgd_solver.cpp:43] Iteration 13690, lr = 0.02
I0526 04:12:39.318460 15394 main.cpp:465] Iteration 13700, Testing net (#0)
I0526 04:13:09.952059 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7478
I0526 04:13:09.952096 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.798028 (* 1 = 0.798028 loss)
I0526 04:13:11.049698 15394 main.cpp:354] Iteration 13700, loss = 0.357965
I0526 04:13:11.049741 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.357965 (* 1 = 0.357965 loss)
I0526 04:13:11.049749 15394 sgd_solver.cpp:43] Iteration 13700, lr = 0.02
I0526 04:13:22.652590 15394 main.cpp:354] Iteration 13710, loss = 0.580336
I0526 04:13:22.652643 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.580336 (* 1 = 0.580336 loss)
I0526 04:13:22.652649 15394 sgd_solver.cpp:43] Iteration 13710, lr = 0.02
I0526 04:13:33.940922 15394 main.cpp:354] Iteration 13720, loss = 0.727218
I0526 04:13:33.940953 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.727218 (* 1 = 0.727218 loss)
I0526 04:13:33.940960 15394 sgd_solver.cpp:43] Iteration 13720, lr = 0.02
I0526 04:13:44.958694 15394 main.cpp:354] Iteration 13730, loss = 0.514972
I0526 04:13:44.958740 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.514972 (* 1 = 0.514972 loss)
I0526 04:13:44.958752 15394 sgd_solver.cpp:43] Iteration 13730, lr = 0.02
I0526 04:13:56.742053 15394 main.cpp:354] Iteration 13740, loss = 0.649228
I0526 04:13:56.742090 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.649228 (* 1 = 0.649228 loss)
I0526 04:13:56.742096 15394 sgd_solver.cpp:43] Iteration 13740, lr = 0.02
I0526 04:14:07.911895 15394 main.cpp:354] Iteration 13750, loss = 0.350073
I0526 04:14:07.911936 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.350073 (* 1 = 0.350073 loss)
I0526 04:14:07.911943 15394 sgd_solver.cpp:43] Iteration 13750, lr = 0.02
I0526 04:14:19.590879 15394 main.cpp:354] Iteration 13760, loss = 0.484805
I0526 04:14:19.590920 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.484805 (* 1 = 0.484805 loss)
I0526 04:14:19.590927 15394 sgd_solver.cpp:43] Iteration 13760, lr = 0.02
I0526 04:14:31.034854 15394 main.cpp:354] Iteration 13770, loss = 0.431043
I0526 04:14:31.034899 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.431043 (* 1 = 0.431043 loss)
I0526 04:14:31.034906 15394 sgd_solver.cpp:43] Iteration 13770, lr = 0.02
I0526 04:14:42.663508 15394 main.cpp:354] Iteration 13780, loss = 0.442054
I0526 04:14:42.663547 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.442054 (* 1 = 0.442054 loss)
I0526 04:14:42.663553 15394 sgd_solver.cpp:43] Iteration 13780, lr = 0.02
I0526 04:14:53.331411 15394 main.cpp:354] Iteration 13790, loss = 0.431908
I0526 04:14:53.331454 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.431908 (* 1 = 0.431908 loss)
I0526 04:14:53.331464 15394 sgd_solver.cpp:43] Iteration 13790, lr = 0.02
I0526 04:15:04.035212 15394 main.cpp:465] Iteration 13800, Testing net (#0)
I0526 04:15:34.675408 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7469
I0526 04:15:34.675448 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.752391 (* 1 = 0.752391 loss)
I0526 04:15:35.855352 15394 main.cpp:354] Iteration 13800, loss = 0.51601
I0526 04:15:35.855396 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.51601 (* 1 = 0.51601 loss)
I0526 04:15:35.855406 15394 sgd_solver.cpp:43] Iteration 13800, lr = 0.02
I0526 04:15:47.072402 15394 main.cpp:354] Iteration 13810, loss = 0.494633
I0526 04:15:47.072434 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.494633 (* 1 = 0.494633 loss)
I0526 04:15:47.072441 15394 sgd_solver.cpp:43] Iteration 13810, lr = 0.02
I0526 04:15:58.991484 15394 main.cpp:354] Iteration 13820, loss = 0.594891
I0526 04:15:58.991526 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.594892 (* 1 = 0.594892 loss)
I0526 04:15:58.991533 15394 sgd_solver.cpp:43] Iteration 13820, lr = 0.02
I0526 04:16:09.635268 15394 main.cpp:354] Iteration 13830, loss = 0.804537
I0526 04:16:09.635311 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.804537 (* 1 = 0.804537 loss)
I0526 04:16:09.635318 15394 sgd_solver.cpp:43] Iteration 13830, lr = 0.02
I0526 04:16:21.078347 15394 main.cpp:354] Iteration 13840, loss = 0.50022
I0526 04:16:21.078392 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.50022 (* 1 = 0.50022 loss)
I0526 04:16:21.078399 15394 sgd_solver.cpp:43] Iteration 13840, lr = 0.02
I0526 04:16:31.965170 15394 main.cpp:354] Iteration 13850, loss = 0.492823
I0526 04:16:31.965207 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.492824 (* 1 = 0.492824 loss)
I0526 04:16:31.965215 15394 sgd_solver.cpp:43] Iteration 13850, lr = 0.02
I0526 04:16:43.514087 15394 main.cpp:354] Iteration 13860, loss = 0.349781
I0526 04:16:43.514132 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.349781 (* 1 = 0.349781 loss)
I0526 04:16:43.514139 15394 sgd_solver.cpp:43] Iteration 13860, lr = 0.02
I0526 04:16:54.511992 15394 main.cpp:354] Iteration 13870, loss = 0.366387
I0526 04:16:54.512034 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.366387 (* 1 = 0.366387 loss)
I0526 04:16:54.512042 15394 sgd_solver.cpp:43] Iteration 13870, lr = 0.02
I0526 04:17:06.268806 15394 main.cpp:354] Iteration 13880, loss = 0.428022
I0526 04:17:06.268863 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.428022 (* 1 = 0.428022 loss)
I0526 04:17:06.268872 15394 sgd_solver.cpp:43] Iteration 13880, lr = 0.02
I0526 04:17:18.001653 15394 main.cpp:354] Iteration 13890, loss = 0.347717
I0526 04:17:18.001698 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.347717 (* 1 = 0.347717 loss)
I0526 04:17:18.001705 15394 sgd_solver.cpp:43] Iteration 13890, lr = 0.02
I0526 04:17:28.024533 15394 main.cpp:465] Iteration 13900, Testing net (#0)
I0526 04:17:58.595618 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7157
I0526 04:17:58.595670 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.925426 (* 1 = 0.925426 loss)
I0526 04:17:59.749202 15394 main.cpp:354] Iteration 13900, loss = 0.421413
I0526 04:17:59.749241 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.421413 (* 1 = 0.421413 loss)
I0526 04:17:59.749251 15394 sgd_solver.cpp:43] Iteration 13900, lr = 0.02
I0526 04:18:11.407398 15394 main.cpp:354] Iteration 13910, loss = 0.362987
I0526 04:18:11.407438 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.362987 (* 1 = 0.362987 loss)
I0526 04:18:11.407444 15394 sgd_solver.cpp:43] Iteration 13910, lr = 0.02
I0526 04:18:22.756026 15394 main.cpp:354] Iteration 13920, loss = 0.483081
I0526 04:18:22.756078 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.483081 (* 1 = 0.483081 loss)
I0526 04:18:22.756085 15394 sgd_solver.cpp:43] Iteration 13920, lr = 0.02
I0526 04:18:34.688174 15394 main.cpp:354] Iteration 13930, loss = 0.522906
I0526 04:18:34.688220 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.522906 (* 1 = 0.522906 loss)
I0526 04:18:34.688227 15394 sgd_solver.cpp:43] Iteration 13930, lr = 0.02
I0526 04:18:46.199565 15394 main.cpp:354] Iteration 13940, loss = 0.505995
I0526 04:18:46.199622 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.505996 (* 1 = 0.505996 loss)
I0526 04:18:46.199630 15394 sgd_solver.cpp:43] Iteration 13940, lr = 0.02
I0526 04:18:56.882225 15394 main.cpp:354] Iteration 13950, loss = 0.40155
I0526 04:18:56.882264 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.401551 (* 1 = 0.401551 loss)
I0526 04:18:56.882272 15394 sgd_solver.cpp:43] Iteration 13950, lr = 0.02
I0526 04:19:08.286474 15394 main.cpp:354] Iteration 13960, loss = 0.477989
I0526 04:19:08.286515 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.477989 (* 1 = 0.477989 loss)
I0526 04:19:08.286522 15394 sgd_solver.cpp:43] Iteration 13960, lr = 0.02
I0526 04:19:19.345330 15394 main.cpp:354] Iteration 13970, loss = 0.595763
I0526 04:19:19.345372 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.595763 (* 1 = 0.595763 loss)
I0526 04:19:19.345379 15394 sgd_solver.cpp:43] Iteration 13970, lr = 0.02
I0526 04:19:31.696663 15394 main.cpp:354] Iteration 13980, loss = 0.196807
I0526 04:19:31.696707 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.196808 (* 1 = 0.196808 loss)
I0526 04:19:31.696713 15394 sgd_solver.cpp:43] Iteration 13980, lr = 0.02
I0526 04:19:41.851173 15394 main.cpp:354] Iteration 13990, loss = 0.497777
I0526 04:19:41.851212 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.497777 (* 1 = 0.497777 loss)
I0526 04:19:41.851217 15394 sgd_solver.cpp:43] Iteration 13990, lr = 0.02
I0526 04:19:52.232249 15394 main.cpp:465] Iteration 14000, Testing net (#0)
I0526 04:20:22.872376 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7709
I0526 04:20:22.872416 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.677734 (* 1 = 0.677734 loss)
I0526 04:20:23.988704 15394 main.cpp:354] Iteration 14000, loss = 0.427469
I0526 04:20:23.988747 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.427469 (* 1 = 0.427469 loss)
I0526 04:20:23.988754 15394 sgd_solver.cpp:43] Iteration 14000, lr = 0.02
I0526 04:20:35.275434 15394 main.cpp:354] Iteration 14010, loss = 0.420983
I0526 04:20:35.275475 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.420983 (* 1 = 0.420983 loss)
I0526 04:20:35.275486 15394 sgd_solver.cpp:43] Iteration 14010, lr = 0.02
I0526 04:20:46.369701 15394 main.cpp:354] Iteration 14020, loss = 0.282098
I0526 04:20:46.369740 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.282098 (* 1 = 0.282098 loss)
I0526 04:20:46.369745 15394 sgd_solver.cpp:43] Iteration 14020, lr = 0.02
I0526 04:20:56.807234 15394 main.cpp:354] Iteration 14030, loss = 0.416579
I0526 04:20:56.807271 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.416579 (* 1 = 0.416579 loss)
I0526 04:20:56.807277 15394 sgd_solver.cpp:43] Iteration 14030, lr = 0.02
I0526 04:21:08.286859 15394 main.cpp:354] Iteration 14040, loss = 0.228725
I0526 04:21:08.286902 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.228725 (* 1 = 0.228725 loss)
I0526 04:21:08.286909 15394 sgd_solver.cpp:43] Iteration 14040, lr = 0.02
I0526 04:21:20.226461 15394 main.cpp:354] Iteration 14050, loss = 0.353036
I0526 04:21:20.226516 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.353036 (* 1 = 0.353036 loss)
I0526 04:21:20.226524 15394 sgd_solver.cpp:43] Iteration 14050, lr = 0.02
I0526 04:21:31.884552 15394 main.cpp:354] Iteration 14060, loss = 0.407891
I0526 04:21:31.884596 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.407892 (* 1 = 0.407892 loss)
I0526 04:21:31.884604 15394 sgd_solver.cpp:43] Iteration 14060, lr = 0.02
I0526 04:21:43.566879 15394 main.cpp:354] Iteration 14070, loss = 0.319676
I0526 04:21:43.566920 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.319676 (* 1 = 0.319676 loss)
I0526 04:21:43.566926 15394 sgd_solver.cpp:43] Iteration 14070, lr = 0.02
I0526 04:21:55.229399 15394 main.cpp:354] Iteration 14080, loss = 0.376422
I0526 04:21:55.229449 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.376422 (* 1 = 0.376422 loss)
I0526 04:21:55.229456 15394 sgd_solver.cpp:43] Iteration 14080, lr = 0.02
I0526 04:22:06.568994 15394 main.cpp:354] Iteration 14090, loss = 0.518762
I0526 04:22:06.569047 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.518762 (* 1 = 0.518762 loss)
I0526 04:22:06.569053 15394 sgd_solver.cpp:43] Iteration 14090, lr = 0.02
I0526 04:22:16.722537 15394 main.cpp:465] Iteration 14100, Testing net (#0)
I0526 04:22:47.382213 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7256
I0526 04:22:47.382256 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.870373 (* 1 = 0.870373 loss)
I0526 04:22:48.479881 15394 main.cpp:354] Iteration 14100, loss = 0.442117
I0526 04:22:48.479921 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.442117 (* 1 = 0.442117 loss)
I0526 04:22:48.479931 15394 sgd_solver.cpp:43] Iteration 14100, lr = 0.02
I0526 04:22:59.074090 15394 main.cpp:354] Iteration 14110, loss = 0.387352
I0526 04:22:59.074122 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.387352 (* 1 = 0.387352 loss)
I0526 04:22:59.074141 15394 sgd_solver.cpp:43] Iteration 14110, lr = 0.02
I0526 04:23:11.103091 15394 main.cpp:354] Iteration 14120, loss = 0.330689
I0526 04:23:11.103140 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.33069 (* 1 = 0.33069 loss)
I0526 04:23:11.103147 15394 sgd_solver.cpp:43] Iteration 14120, lr = 0.02
I0526 04:23:22.383059 15394 main.cpp:354] Iteration 14130, loss = 0.451132
I0526 04:23:22.383103 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.451132 (* 1 = 0.451132 loss)
I0526 04:23:22.383111 15394 sgd_solver.cpp:43] Iteration 14130, lr = 0.02
I0526 04:23:33.457317 15394 main.cpp:354] Iteration 14140, loss = 0.564401
I0526 04:23:33.457356 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.564401 (* 1 = 0.564401 loss)
I0526 04:23:33.457362 15394 sgd_solver.cpp:43] Iteration 14140, lr = 0.02
I0526 04:23:43.968518 15394 main.cpp:354] Iteration 14150, loss = 0.302694
I0526 04:23:43.968560 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.302694 (* 1 = 0.302694 loss)
I0526 04:23:43.968578 15394 sgd_solver.cpp:43] Iteration 14150, lr = 0.02
I0526 04:23:55.969292 15394 main.cpp:354] Iteration 14160, loss = 0.41425
I0526 04:23:55.969336 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.41425 (* 1 = 0.41425 loss)
I0526 04:23:55.969342 15394 sgd_solver.cpp:43] Iteration 14160, lr = 0.02
I0526 04:24:07.418696 15394 main.cpp:354] Iteration 14170, loss = 0.476085
I0526 04:24:07.418738 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.476085 (* 1 = 0.476085 loss)
I0526 04:24:07.418746 15394 sgd_solver.cpp:43] Iteration 14170, lr = 0.02
I0526 04:24:18.078941 15394 main.cpp:354] Iteration 14180, loss = 0.422384
I0526 04:24:18.078984 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.422384 (* 1 = 0.422384 loss)
I0526 04:24:18.078991 15394 sgd_solver.cpp:43] Iteration 14180, lr = 0.02
I0526 04:24:29.536454 15394 main.cpp:354] Iteration 14190, loss = 0.507049
I0526 04:24:29.536507 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.507049 (* 1 = 0.507049 loss)
I0526 04:24:29.536514 15394 sgd_solver.cpp:43] Iteration 14190, lr = 0.02
I0526 04:24:39.435808 15394 main.cpp:465] Iteration 14200, Testing net (#0)
I0526 04:25:10.185010 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7765
I0526 04:25:10.185062 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.664606 (* 1 = 0.664606 loss)
I0526 04:25:11.439489 15394 main.cpp:354] Iteration 14200, loss = 0.357451
I0526 04:25:11.439535 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.357451 (* 1 = 0.357451 loss)
I0526 04:25:11.439544 15394 sgd_solver.cpp:43] Iteration 14200, lr = 0.02
I0526 04:25:22.109263 15394 main.cpp:354] Iteration 14210, loss = 0.262819
I0526 04:25:22.109304 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.262819 (* 1 = 0.262819 loss)
I0526 04:25:22.109311 15394 sgd_solver.cpp:43] Iteration 14210, lr = 0.02
I0526 04:25:32.898999 15394 main.cpp:354] Iteration 14220, loss = 0.58178
I0526 04:25:32.899041 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.58178 (* 1 = 0.58178 loss)
I0526 04:25:32.899049 15394 sgd_solver.cpp:43] Iteration 14220, lr = 0.02
I0526 04:25:44.223194 15394 main.cpp:354] Iteration 14230, loss = 0.58228
I0526 04:25:44.223229 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.58228 (* 1 = 0.58228 loss)
I0526 04:25:44.223237 15394 sgd_solver.cpp:43] Iteration 14230, lr = 0.02
I0526 04:25:55.337986 15394 main.cpp:354] Iteration 14240, loss = 0.650828
I0526 04:25:55.338027 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.650828 (* 1 = 0.650828 loss)
I0526 04:25:55.338045 15394 sgd_solver.cpp:43] Iteration 14240, lr = 0.02
I0526 04:26:06.921350 15394 main.cpp:354] Iteration 14250, loss = 0.294243
I0526 04:26:06.921391 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.294243 (* 1 = 0.294243 loss)
I0526 04:26:06.921397 15394 sgd_solver.cpp:43] Iteration 14250, lr = 0.02
I0526 04:26:18.528841 15394 main.cpp:354] Iteration 14260, loss = 0.396951
I0526 04:26:18.528885 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.396951 (* 1 = 0.396951 loss)
I0526 04:26:18.528892 15394 sgd_solver.cpp:43] Iteration 14260, lr = 0.02
I0526 04:26:30.010262 15394 main.cpp:354] Iteration 14270, loss = 0.574877
I0526 04:26:30.010306 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.574877 (* 1 = 0.574877 loss)
I0526 04:26:30.010313 15394 sgd_solver.cpp:43] Iteration 14270, lr = 0.02
I0526 04:26:41.575736 15394 main.cpp:354] Iteration 14280, loss = 0.629369
I0526 04:26:41.575788 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.629369 (* 1 = 0.629369 loss)
I0526 04:26:41.575796 15394 sgd_solver.cpp:43] Iteration 14280, lr = 0.02
I0526 04:26:53.247422 15394 main.cpp:354] Iteration 14290, loss = 0.672264
I0526 04:26:53.247463 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.672264 (* 1 = 0.672264 loss)
I0526 04:26:53.247469 15394 sgd_solver.cpp:43] Iteration 14290, lr = 0.02
I0526 04:27:03.486827 15394 main.cpp:465] Iteration 14300, Testing net (#0)
I0526 04:27:34.201009 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7519
I0526 04:27:34.201050 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.785268 (* 1 = 0.785268 loss)
I0526 04:27:35.166939 15394 main.cpp:354] Iteration 14300, loss = 0.634241
I0526 04:27:35.166980 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.634241 (* 1 = 0.634241 loss)
I0526 04:27:35.166988 15394 sgd_solver.cpp:43] Iteration 14300, lr = 0.02
I0526 04:27:46.037257 15394 main.cpp:354] Iteration 14310, loss = 0.372451
I0526 04:27:46.037322 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.372451 (* 1 = 0.372451 loss)
I0526 04:27:46.037341 15394 sgd_solver.cpp:43] Iteration 14310, lr = 0.02
I0526 04:27:56.628203 15394 main.cpp:354] Iteration 14320, loss = 0.708407
I0526 04:27:56.628243 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.708407 (* 1 = 0.708407 loss)
I0526 04:27:56.628249 15394 sgd_solver.cpp:43] Iteration 14320, lr = 0.02
I0526 04:28:08.656626 15394 main.cpp:354] Iteration 14330, loss = 0.400955
I0526 04:28:08.656668 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.400955 (* 1 = 0.400955 loss)
I0526 04:28:08.656675 15394 sgd_solver.cpp:43] Iteration 14330, lr = 0.02
I0526 04:28:20.069967 15394 main.cpp:354] Iteration 14340, loss = 0.429127
I0526 04:28:20.070011 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.429127 (* 1 = 0.429127 loss)
I0526 04:28:20.070019 15394 sgd_solver.cpp:43] Iteration 14340, lr = 0.02
I0526 04:28:31.569540 15394 main.cpp:354] Iteration 14350, loss = 0.432528
I0526 04:28:31.569581 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.432528 (* 1 = 0.432528 loss)
I0526 04:28:31.569587 15394 sgd_solver.cpp:43] Iteration 14350, lr = 0.02
I0526 04:28:43.052801 15394 main.cpp:354] Iteration 14360, loss = 0.474902
I0526 04:28:43.052858 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.474902 (* 1 = 0.474902 loss)
I0526 04:28:43.052866 15394 sgd_solver.cpp:43] Iteration 14360, lr = 0.02
I0526 04:28:54.881134 15394 main.cpp:354] Iteration 14370, loss = 0.40551
I0526 04:28:54.881175 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.40551 (* 1 = 0.40551 loss)
I0526 04:28:54.881182 15394 sgd_solver.cpp:43] Iteration 14370, lr = 0.02
I0526 04:29:06.808317 15394 main.cpp:354] Iteration 14380, loss = 0.297577
I0526 04:29:06.808352 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.297577 (* 1 = 0.297577 loss)
I0526 04:29:06.808359 15394 sgd_solver.cpp:43] Iteration 14380, lr = 0.02
I0526 04:29:17.793977 15394 main.cpp:354] Iteration 14390, loss = 0.387275
I0526 04:29:17.794019 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.387275 (* 1 = 0.387275 loss)
I0526 04:29:17.794028 15394 sgd_solver.cpp:43] Iteration 14390, lr = 0.02
I0526 04:29:28.331677 15394 main.cpp:465] Iteration 14400, Testing net (#0)
I0526 04:29:58.934798 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7774
I0526 04:29:58.934837 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.649631 (* 1 = 0.649631 loss)
I0526 04:29:59.956662 15394 main.cpp:354] Iteration 14400, loss = 0.448737
I0526 04:29:59.956707 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.448738 (* 1 = 0.448738 loss)
I0526 04:29:59.956715 15394 sgd_solver.cpp:43] Iteration 14400, lr = 0.02
I0526 04:30:10.904119 15394 main.cpp:354] Iteration 14410, loss = 0.418037
I0526 04:30:10.904161 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.418037 (* 1 = 0.418037 loss)
I0526 04:30:10.904181 15394 sgd_solver.cpp:43] Iteration 14410, lr = 0.02
I0526 04:30:21.943907 15394 main.cpp:354] Iteration 14420, loss = 0.405475
I0526 04:30:21.943953 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.405475 (* 1 = 0.405475 loss)
I0526 04:30:21.943960 15394 sgd_solver.cpp:43] Iteration 14420, lr = 0.02
I0526 04:30:31.742051 15394 main.cpp:354] Iteration 14430, loss = 0.525401
I0526 04:30:31.742094 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.525401 (* 1 = 0.525401 loss)
I0526 04:30:31.742105 15394 sgd_solver.cpp:43] Iteration 14430, lr = 0.02
I0526 04:30:43.777622 15394 main.cpp:354] Iteration 14440, loss = 0.331602
I0526 04:30:43.777667 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.331602 (* 1 = 0.331602 loss)
I0526 04:30:43.777676 15394 sgd_solver.cpp:43] Iteration 14440, lr = 0.02
I0526 04:30:55.485899 15394 main.cpp:354] Iteration 14450, loss = 0.289432
I0526 04:30:55.485930 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.289433 (* 1 = 0.289433 loss)
I0526 04:30:55.485936 15394 sgd_solver.cpp:43] Iteration 14450, lr = 0.02
I0526 04:31:06.594712 15394 main.cpp:354] Iteration 14460, loss = 0.411428
I0526 04:31:06.594755 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.411428 (* 1 = 0.411428 loss)
I0526 04:31:06.594761 15394 sgd_solver.cpp:43] Iteration 14460, lr = 0.02
I0526 04:31:18.342411 15394 main.cpp:354] Iteration 14470, loss = 0.387558
I0526 04:31:18.342454 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.387558 (* 1 = 0.387558 loss)
I0526 04:31:18.342463 15394 sgd_solver.cpp:43] Iteration 14470, lr = 0.02
I0526 04:31:30.083927 15394 main.cpp:354] Iteration 14480, loss = 0.520299
I0526 04:31:30.083973 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.520299 (* 1 = 0.520299 loss)
I0526 04:31:30.083982 15394 sgd_solver.cpp:43] Iteration 14480, lr = 0.02
I0526 04:31:41.163846 15394 main.cpp:354] Iteration 14490, loss = 0.477823
I0526 04:31:41.163884 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.477823 (* 1 = 0.477823 loss)
I0526 04:31:41.163892 15394 sgd_solver.cpp:43] Iteration 14490, lr = 0.02
I0526 04:31:50.861305 15394 main.cpp:465] Iteration 14500, Testing net (#0)
I0526 04:32:21.475162 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6797
I0526 04:32:21.475203 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.03461 (* 1 = 1.03461 loss)
I0526 04:32:22.758993 15394 main.cpp:354] Iteration 14500, loss = 0.406441
I0526 04:32:22.759045 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.406441 (* 1 = 0.406441 loss)
I0526 04:32:22.759054 15394 sgd_solver.cpp:43] Iteration 14500, lr = 0.02
I0526 04:32:33.802247 15394 main.cpp:354] Iteration 14510, loss = 0.330254
I0526 04:32:33.802287 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.330254 (* 1 = 0.330254 loss)
I0526 04:32:33.802294 15394 sgd_solver.cpp:43] Iteration 14510, lr = 0.02
I0526 04:32:46.444627 15394 main.cpp:354] Iteration 14520, loss = 0.356199
I0526 04:32:46.444682 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.356199 (* 1 = 0.356199 loss)
I0526 04:32:46.444690 15394 sgd_solver.cpp:43] Iteration 14520, lr = 0.02
I0526 04:32:57.075716 15394 main.cpp:354] Iteration 14530, loss = 0.626898
I0526 04:32:57.075769 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.626898 (* 1 = 0.626898 loss)
I0526 04:32:57.075776 15394 sgd_solver.cpp:43] Iteration 14530, lr = 0.02
I0526 04:33:09.615773 15394 main.cpp:354] Iteration 14540, loss = 0.469197
I0526 04:33:09.615818 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.469197 (* 1 = 0.469197 loss)
I0526 04:33:09.615825 15394 sgd_solver.cpp:43] Iteration 14540, lr = 0.02
I0526 04:33:20.226433 15394 main.cpp:354] Iteration 14550, loss = 0.369241
I0526 04:33:20.226475 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.369241 (* 1 = 0.369241 loss)
I0526 04:33:20.226481 15394 sgd_solver.cpp:43] Iteration 14550, lr = 0.02
I0526 04:33:32.160151 15394 main.cpp:354] Iteration 14560, loss = 0.506872
I0526 04:33:32.160192 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.506872 (* 1 = 0.506872 loss)
I0526 04:33:32.160199 15394 sgd_solver.cpp:43] Iteration 14560, lr = 0.02
I0526 04:33:43.055985 15394 main.cpp:354] Iteration 14570, loss = 0.320316
I0526 04:33:43.056027 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.320316 (* 1 = 0.320316 loss)
I0526 04:33:43.056035 15394 sgd_solver.cpp:43] Iteration 14570, lr = 0.02
I0526 04:33:54.741513 15394 main.cpp:354] Iteration 14580, loss = 0.410205
I0526 04:33:54.741562 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.410205 (* 1 = 0.410205 loss)
I0526 04:33:54.741580 15394 sgd_solver.cpp:43] Iteration 14580, lr = 0.02
I0526 04:34:06.247990 15394 main.cpp:354] Iteration 14590, loss = 0.430637
I0526 04:34:06.248036 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.430637 (* 1 = 0.430637 loss)
I0526 04:34:06.248044 15394 sgd_solver.cpp:43] Iteration 14590, lr = 0.02
I0526 04:34:17.027321 15394 main.cpp:465] Iteration 14600, Testing net (#0)
I0526 04:34:47.721617 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6408
I0526 04:34:47.721658 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.26099 (* 1 = 1.26099 loss)
I0526 04:34:48.855573 15394 main.cpp:354] Iteration 14600, loss = 0.341736
I0526 04:34:48.855615 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.341737 (* 1 = 0.341737 loss)
I0526 04:34:48.855624 15394 sgd_solver.cpp:43] Iteration 14600, lr = 0.02
I0526 04:35:00.218148 15394 main.cpp:354] Iteration 14610, loss = 0.38302
I0526 04:35:00.218200 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.38302 (* 1 = 0.38302 loss)
I0526 04:35:00.218207 15394 sgd_solver.cpp:43] Iteration 14610, lr = 0.02
I0526 04:35:11.853536 15394 main.cpp:354] Iteration 14620, loss = 0.318926
I0526 04:35:11.853574 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.318926 (* 1 = 0.318926 loss)
I0526 04:35:11.853580 15394 sgd_solver.cpp:43] Iteration 14620, lr = 0.02
I0526 04:35:23.934629 15394 main.cpp:354] Iteration 14630, loss = 0.412525
I0526 04:35:23.934675 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.412525 (* 1 = 0.412525 loss)
I0526 04:35:23.934684 15394 sgd_solver.cpp:43] Iteration 14630, lr = 0.02
I0526 04:35:35.630554 15394 main.cpp:354] Iteration 14640, loss = 0.686754
I0526 04:35:35.630599 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.686754 (* 1 = 0.686754 loss)
I0526 04:35:35.630604 15394 sgd_solver.cpp:43] Iteration 14640, lr = 0.02
I0526 04:35:46.838361 15394 main.cpp:354] Iteration 14650, loss = 0.555997
I0526 04:35:46.838405 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.555997 (* 1 = 0.555997 loss)
I0526 04:35:46.838423 15394 sgd_solver.cpp:43] Iteration 14650, lr = 0.02
I0526 04:35:57.246214 15394 main.cpp:354] Iteration 14660, loss = 0.620276
I0526 04:35:57.246268 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.620276 (* 1 = 0.620276 loss)
I0526 04:35:57.246274 15394 sgd_solver.cpp:43] Iteration 14660, lr = 0.02
I0526 04:36:09.442376 15394 main.cpp:354] Iteration 14670, loss = 0.428379
I0526 04:36:09.442422 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.428379 (* 1 = 0.428379 loss)
I0526 04:36:09.442440 15394 sgd_solver.cpp:43] Iteration 14670, lr = 0.02
I0526 04:36:20.445092 15394 main.cpp:354] Iteration 14680, loss = 0.494748
I0526 04:36:20.445134 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.494748 (* 1 = 0.494748 loss)
I0526 04:36:20.445140 15394 sgd_solver.cpp:43] Iteration 14680, lr = 0.02
I0526 04:36:31.944692 15394 main.cpp:354] Iteration 14690, loss = 0.315141
I0526 04:36:31.944736 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.315142 (* 1 = 0.315142 loss)
I0526 04:36:31.944744 15394 sgd_solver.cpp:43] Iteration 14690, lr = 0.02
I0526 04:36:42.073916 15394 main.cpp:465] Iteration 14700, Testing net (#0)
I0526 04:37:12.682432 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7414
I0526 04:37:12.682476 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.813751 (* 1 = 0.813751 loss)
I0526 04:37:13.809273 15394 main.cpp:354] Iteration 14700, loss = 0.343909
I0526 04:37:13.809314 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.34391 (* 1 = 0.34391 loss)
I0526 04:37:13.809322 15394 sgd_solver.cpp:43] Iteration 14700, lr = 0.02
I0526 04:37:24.821913 15394 main.cpp:354] Iteration 14710, loss = 0.419685
I0526 04:37:24.821957 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.419685 (* 1 = 0.419685 loss)
I0526 04:37:24.821964 15394 sgd_solver.cpp:43] Iteration 14710, lr = 0.02
I0526 04:37:36.095113 15394 main.cpp:354] Iteration 14720, loss = 0.505644
I0526 04:37:36.095155 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.505644 (* 1 = 0.505644 loss)
I0526 04:37:36.095161 15394 sgd_solver.cpp:43] Iteration 14720, lr = 0.02
I0526 04:37:47.451968 15394 main.cpp:354] Iteration 14730, loss = 0.559995
I0526 04:37:47.452010 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.559995 (* 1 = 0.559995 loss)
I0526 04:37:47.452018 15394 sgd_solver.cpp:43] Iteration 14730, lr = 0.02
I0526 04:37:58.723484 15394 main.cpp:354] Iteration 14740, loss = 0.537383
I0526 04:37:58.723529 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.537383 (* 1 = 0.537383 loss)
I0526 04:37:58.723537 15394 sgd_solver.cpp:43] Iteration 14740, lr = 0.02
I0526 04:38:09.402359 15394 main.cpp:354] Iteration 14750, loss = 0.57704
I0526 04:38:09.402397 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.57704 (* 1 = 0.57704 loss)
I0526 04:38:09.402405 15394 sgd_solver.cpp:43] Iteration 14750, lr = 0.02
I0526 04:38:20.543817 15394 main.cpp:354] Iteration 14760, loss = 0.447269
I0526 04:38:20.543861 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.447269 (* 1 = 0.447269 loss)
I0526 04:38:20.543869 15394 sgd_solver.cpp:43] Iteration 14760, lr = 0.02
I0526 04:38:31.917433 15394 main.cpp:354] Iteration 14770, loss = 0.513167
I0526 04:38:31.917474 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.513167 (* 1 = 0.513167 loss)
I0526 04:38:31.917481 15394 sgd_solver.cpp:43] Iteration 14770, lr = 0.02
I0526 04:38:43.248826 15394 main.cpp:354] Iteration 14780, loss = 0.434384
I0526 04:38:43.248870 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.434384 (* 1 = 0.434384 loss)
I0526 04:38:43.248879 15394 sgd_solver.cpp:43] Iteration 14780, lr = 0.02
I0526 04:38:54.016469 15394 main.cpp:354] Iteration 14790, loss = 0.645592
I0526 04:38:54.016507 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.645592 (* 1 = 0.645592 loss)
I0526 04:38:54.016515 15394 sgd_solver.cpp:43] Iteration 14790, lr = 0.02
I0526 04:39:04.362128 15394 main.cpp:465] Iteration 14800, Testing net (#0)
I0526 04:39:34.954798 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7513
I0526 04:39:34.954844 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.752171 (* 1 = 0.752171 loss)
I0526 04:39:36.177161 15394 main.cpp:354] Iteration 14800, loss = 0.364398
I0526 04:39:36.177196 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.364398 (* 1 = 0.364398 loss)
I0526 04:39:36.177204 15394 sgd_solver.cpp:43] Iteration 14800, lr = 0.02
I0526 04:39:47.386533 15394 main.cpp:354] Iteration 14810, loss = 0.690711
I0526 04:39:47.386575 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.690712 (* 1 = 0.690712 loss)
I0526 04:39:47.386584 15394 sgd_solver.cpp:43] Iteration 14810, lr = 0.02
I0526 04:39:58.451928 15394 main.cpp:354] Iteration 14820, loss = 0.415172
I0526 04:39:58.451970 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.415172 (* 1 = 0.415172 loss)
I0526 04:39:58.451978 15394 sgd_solver.cpp:43] Iteration 14820, lr = 0.02
I0526 04:40:09.328763 15394 main.cpp:354] Iteration 14830, loss = 0.558031
I0526 04:40:09.328804 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.558031 (* 1 = 0.558031 loss)
I0526 04:40:09.328810 15394 sgd_solver.cpp:43] Iteration 14830, lr = 0.02
I0526 04:40:20.847618 15394 main.cpp:354] Iteration 14840, loss = 0.603491
I0526 04:40:20.847661 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.603491 (* 1 = 0.603491 loss)
I0526 04:40:20.847669 15394 sgd_solver.cpp:43] Iteration 14840, lr = 0.02
I0526 04:40:32.340714 15394 main.cpp:354] Iteration 14850, loss = 0.480002
I0526 04:40:32.340747 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.480002 (* 1 = 0.480002 loss)
I0526 04:40:32.340760 15394 sgd_solver.cpp:43] Iteration 14850, lr = 0.02
I0526 04:40:43.918207 15394 main.cpp:354] Iteration 14860, loss = 0.44278
I0526 04:40:43.918269 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.442781 (* 1 = 0.442781 loss)
I0526 04:40:43.918278 15394 sgd_solver.cpp:43] Iteration 14860, lr = 0.02
I0526 04:40:55.519217 15394 main.cpp:354] Iteration 14870, loss = 0.482168
I0526 04:40:55.519255 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.482168 (* 1 = 0.482168 loss)
I0526 04:40:55.519263 15394 sgd_solver.cpp:43] Iteration 14870, lr = 0.02
I0526 04:41:06.493968 15394 main.cpp:354] Iteration 14880, loss = 0.346662
I0526 04:41:06.494009 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.346662 (* 1 = 0.346662 loss)
I0526 04:41:06.494015 15394 sgd_solver.cpp:43] Iteration 14880, lr = 0.02
I0526 04:41:17.611816 15394 main.cpp:354] Iteration 14890, loss = 0.302817
I0526 04:41:17.611848 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.302817 (* 1 = 0.302817 loss)
I0526 04:41:17.611855 15394 sgd_solver.cpp:43] Iteration 14890, lr = 0.02
I0526 04:41:28.381398 15394 main.cpp:465] Iteration 14900, Testing net (#0)
I0526 04:41:58.997284 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8216
I0526 04:41:58.997329 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.51241 (* 1 = 0.51241 loss)
I0526 04:42:00.111098 15394 main.cpp:354] Iteration 14900, loss = 0.3546
I0526 04:42:00.111138 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.3546 (* 1 = 0.3546 loss)
I0526 04:42:00.111147 15394 sgd_solver.cpp:43] Iteration 14900, lr = 0.02
I0526 04:42:11.330216 15394 main.cpp:354] Iteration 14910, loss = 0.468247
I0526 04:42:11.330255 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.468247 (* 1 = 0.468247 loss)
I0526 04:42:11.330262 15394 sgd_solver.cpp:43] Iteration 14910, lr = 0.02
I0526 04:42:23.384138 15394 main.cpp:354] Iteration 14920, loss = 0.427649
I0526 04:42:23.384193 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.427649 (* 1 = 0.427649 loss)
I0526 04:42:23.384202 15394 sgd_solver.cpp:43] Iteration 14920, lr = 0.02
I0526 04:42:34.730748 15394 main.cpp:354] Iteration 14930, loss = 0.809278
I0526 04:42:34.730793 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.809278 (* 1 = 0.809278 loss)
I0526 04:42:34.730800 15394 sgd_solver.cpp:43] Iteration 14930, lr = 0.02
I0526 04:42:46.463732 15394 main.cpp:354] Iteration 14940, loss = 0.565676
I0526 04:42:46.463779 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.565676 (* 1 = 0.565676 loss)
I0526 04:42:46.463788 15394 sgd_solver.cpp:43] Iteration 14940, lr = 0.02
I0526 04:42:56.959656 15394 main.cpp:354] Iteration 14950, loss = 0.465109
I0526 04:42:56.959694 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.465109 (* 1 = 0.465109 loss)
I0526 04:42:56.959702 15394 sgd_solver.cpp:43] Iteration 14950, lr = 0.02
I0526 04:43:08.155984 15394 main.cpp:354] Iteration 14960, loss = 0.406494
I0526 04:43:08.156025 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.406494 (* 1 = 0.406494 loss)
I0526 04:43:08.156033 15394 sgd_solver.cpp:43] Iteration 14960, lr = 0.02
I0526 04:43:18.672541 15394 main.cpp:354] Iteration 14970, loss = 0.454903
I0526 04:43:18.672583 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.454904 (* 1 = 0.454904 loss)
I0526 04:43:18.672590 15394 sgd_solver.cpp:43] Iteration 14970, lr = 0.02
I0526 04:43:30.417559 15394 main.cpp:354] Iteration 14980, loss = 0.305745
I0526 04:43:30.417616 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.305745 (* 1 = 0.305745 loss)
I0526 04:43:30.417623 15394 sgd_solver.cpp:43] Iteration 14980, lr = 0.02
I0526 04:43:42.294590 15394 main.cpp:354] Iteration 14990, loss = 0.380416
I0526 04:43:42.294630 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.380416 (* 1 = 0.380416 loss)
I0526 04:43:42.294636 15394 sgd_solver.cpp:43] Iteration 14990, lr = 0.02
I0526 04:43:52.328620 15394 main.cpp:465] Iteration 15000, Testing net (#0)
I0526 04:44:22.995523 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7261
I0526 04:44:22.995563 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.863594 (* 1 = 0.863594 loss)
I0526 04:44:23.894461 15394 main.cpp:354] Iteration 15000, loss = 0.63907
I0526 04:44:23.894501 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.63907 (* 1 = 0.63907 loss)
I0526 04:44:23.894510 15394 sgd_solver.cpp:43] Iteration 15000, lr = 0.02
I0526 04:44:34.811287 15394 main.cpp:354] Iteration 15010, loss = 0.427246
I0526 04:44:34.811328 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.427246 (* 1 = 0.427246 loss)
I0526 04:44:34.811336 15394 sgd_solver.cpp:43] Iteration 15010, lr = 0.02
I0526 04:44:46.563925 15394 main.cpp:354] Iteration 15020, loss = 0.390473
I0526 04:44:46.563977 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.390474 (* 1 = 0.390474 loss)
I0526 04:44:46.563983 15394 sgd_solver.cpp:43] Iteration 15020, lr = 0.02
I0526 04:44:58.304481 15394 main.cpp:354] Iteration 15030, loss = 0.404282
I0526 04:44:58.304523 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.404282 (* 1 = 0.404282 loss)
I0526 04:44:58.304532 15394 sgd_solver.cpp:43] Iteration 15030, lr = 0.02
I0526 04:45:09.647466 15394 main.cpp:354] Iteration 15040, loss = 0.442511
I0526 04:45:09.647505 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.442511 (* 1 = 0.442511 loss)
I0526 04:45:09.647512 15394 sgd_solver.cpp:43] Iteration 15040, lr = 0.02
I0526 04:45:20.407987 15394 main.cpp:354] Iteration 15050, loss = 0.352046
I0526 04:45:20.408030 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.352046 (* 1 = 0.352046 loss)
I0526 04:45:20.408036 15394 sgd_solver.cpp:43] Iteration 15050, lr = 0.02
I0526 04:45:32.165091 15394 main.cpp:354] Iteration 15060, loss = 0.41176
I0526 04:45:32.165138 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.41176 (* 1 = 0.41176 loss)
I0526 04:45:32.165144 15394 sgd_solver.cpp:43] Iteration 15060, lr = 0.02
I0526 04:45:43.336035 15394 main.cpp:354] Iteration 15070, loss = 0.245972
I0526 04:45:43.336074 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.245972 (* 1 = 0.245972 loss)
I0526 04:45:43.336082 15394 sgd_solver.cpp:43] Iteration 15070, lr = 0.02
I0526 04:45:55.222062 15394 main.cpp:354] Iteration 15080, loss = 0.322559
I0526 04:45:55.222103 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.322559 (* 1 = 0.322559 loss)
I0526 04:45:55.222110 15394 sgd_solver.cpp:43] Iteration 15080, lr = 0.02
I0526 04:46:06.669890 15394 main.cpp:354] Iteration 15090, loss = 0.351157
I0526 04:46:06.669941 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.351157 (* 1 = 0.351157 loss)
I0526 04:46:06.669948 15394 sgd_solver.cpp:43] Iteration 15090, lr = 0.02
I0526 04:46:17.783522 15394 main.cpp:465] Iteration 15100, Testing net (#0)
I0526 04:46:48.495350 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7814
I0526 04:46:48.495394 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.626793 (* 1 = 0.626793 loss)
I0526 04:46:49.283246 15394 main.cpp:354] Iteration 15100, loss = 0.799866
I0526 04:46:49.283290 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.799866 (* 1 = 0.799866 loss)
I0526 04:46:49.283299 15394 sgd_solver.cpp:43] Iteration 15100, lr = 0.02
I0526 04:47:00.935709 15394 main.cpp:354] Iteration 15110, loss = 0.263111
I0526 04:47:00.935748 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.263111 (* 1 = 0.263111 loss)
I0526 04:47:00.935755 15394 sgd_solver.cpp:43] Iteration 15110, lr = 0.02
I0526 04:47:12.123172 15394 main.cpp:354] Iteration 15120, loss = 0.361288
I0526 04:47:12.123208 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.361288 (* 1 = 0.361288 loss)
I0526 04:47:12.123214 15394 sgd_solver.cpp:43] Iteration 15120, lr = 0.02
I0526 04:47:24.275367 15394 main.cpp:354] Iteration 15130, loss = 0.453493
I0526 04:47:24.275411 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.453494 (* 1 = 0.453494 loss)
I0526 04:47:24.275421 15394 sgd_solver.cpp:43] Iteration 15130, lr = 0.02
I0526 04:47:36.420838 15394 main.cpp:354] Iteration 15140, loss = 0.402743
I0526 04:47:36.420881 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.402743 (* 1 = 0.402743 loss)
I0526 04:47:36.420886 15394 sgd_solver.cpp:43] Iteration 15140, lr = 0.02
I0526 04:47:47.954715 15394 main.cpp:354] Iteration 15150, loss = 0.349515
I0526 04:47:47.954754 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.349515 (* 1 = 0.349515 loss)
I0526 04:47:47.954761 15394 sgd_solver.cpp:43] Iteration 15150, lr = 0.02
I0526 04:47:58.970178 15394 main.cpp:354] Iteration 15160, loss = 0.51633
I0526 04:47:58.970234 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.51633 (* 1 = 0.51633 loss)
I0526 04:47:58.970242 15394 sgd_solver.cpp:43] Iteration 15160, lr = 0.02
I0526 04:48:10.573626 15394 main.cpp:354] Iteration 15170, loss = 0.460406
I0526 04:48:10.573664 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.460406 (* 1 = 0.460406 loss)
I0526 04:48:10.573670 15394 sgd_solver.cpp:43] Iteration 15170, lr = 0.02
I0526 04:48:21.994195 15394 main.cpp:354] Iteration 15180, loss = 0.458437
I0526 04:48:21.994235 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.458437 (* 1 = 0.458437 loss)
I0526 04:48:21.994241 15394 sgd_solver.cpp:43] Iteration 15180, lr = 0.02
I0526 04:48:34.144197 15394 main.cpp:354] Iteration 15190, loss = 0.382633
I0526 04:48:34.144237 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.382633 (* 1 = 0.382633 loss)
I0526 04:48:34.144244 15394 sgd_solver.cpp:43] Iteration 15190, lr = 0.02
I0526 04:48:44.705901 15394 main.cpp:465] Iteration 15200, Testing net (#0)
I0526 04:49:15.379778 15394 main.cpp:532]     Test net output #0: Accuracy = 0.5925
I0526 04:49:15.379822 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.85228 (* 1 = 1.85228 loss)
I0526 04:49:16.484488 15394 main.cpp:354] Iteration 15200, loss = 0.385828
I0526 04:49:16.484534 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.385829 (* 1 = 0.385829 loss)
I0526 04:49:16.484541 15394 sgd_solver.cpp:43] Iteration 15200, lr = 0.02
I0526 04:49:28.495965 15394 main.cpp:354] Iteration 15210, loss = 0.457241
I0526 04:49:28.496006 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.457241 (* 1 = 0.457241 loss)
I0526 04:49:28.496013 15394 sgd_solver.cpp:43] Iteration 15210, lr = 0.02
I0526 04:49:40.355908 15394 main.cpp:354] Iteration 15220, loss = 0.295826
I0526 04:49:40.355947 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.295826 (* 1 = 0.295826 loss)
I0526 04:49:40.355954 15394 sgd_solver.cpp:43] Iteration 15220, lr = 0.02
I0526 04:49:51.405540 15394 main.cpp:354] Iteration 15230, loss = 0.628409
I0526 04:49:51.405585 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.628409 (* 1 = 0.628409 loss)
I0526 04:49:51.405591 15394 sgd_solver.cpp:43] Iteration 15230, lr = 0.02
I0526 04:50:02.636394 15394 main.cpp:354] Iteration 15240, loss = 0.540457
I0526 04:50:02.636433 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.540457 (* 1 = 0.540457 loss)
I0526 04:50:02.636451 15394 sgd_solver.cpp:43] Iteration 15240, lr = 0.02
I0526 04:50:13.399338 15394 main.cpp:354] Iteration 15250, loss = 0.302385
I0526 04:50:13.399377 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.302385 (* 1 = 0.302385 loss)
I0526 04:50:13.399384 15394 sgd_solver.cpp:43] Iteration 15250, lr = 0.02
I0526 04:50:24.422495 15394 main.cpp:354] Iteration 15260, loss = 0.691901
I0526 04:50:24.422535 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.691901 (* 1 = 0.691901 loss)
I0526 04:50:24.422541 15394 sgd_solver.cpp:43] Iteration 15260, lr = 0.02
I0526 04:50:35.607107 15394 main.cpp:354] Iteration 15270, loss = 0.427658
I0526 04:50:35.607151 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.427658 (* 1 = 0.427658 loss)
I0526 04:50:35.607163 15394 sgd_solver.cpp:43] Iteration 15270, lr = 0.02
I0526 04:50:47.048306 15394 main.cpp:354] Iteration 15280, loss = 0.297615
I0526 04:50:47.048347 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.297615 (* 1 = 0.297615 loss)
I0526 04:50:47.048353 15394 sgd_solver.cpp:43] Iteration 15280, lr = 0.02
I0526 04:50:58.691809 15394 main.cpp:354] Iteration 15290, loss = 0.42691
I0526 04:50:58.691854 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.42691 (* 1 = 0.42691 loss)
I0526 04:50:58.691861 15394 sgd_solver.cpp:43] Iteration 15290, lr = 0.02
I0526 04:51:08.963786 15394 main.cpp:465] Iteration 15300, Testing net (#0)
I0526 04:51:39.618157 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6539
I0526 04:51:39.618187 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.11455 (* 1 = 1.11455 loss)
I0526 04:51:40.733861 15394 main.cpp:354] Iteration 15300, loss = 0.320289
I0526 04:51:40.733903 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.320289 (* 1 = 0.320289 loss)
I0526 04:51:40.733913 15394 sgd_solver.cpp:43] Iteration 15300, lr = 0.02
I0526 04:51:51.518250 15394 main.cpp:354] Iteration 15310, loss = 0.639859
I0526 04:51:51.518293 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.639859 (* 1 = 0.639859 loss)
I0526 04:51:51.518301 15394 sgd_solver.cpp:43] Iteration 15310, lr = 0.02
I0526 04:52:03.276451 15394 main.cpp:354] Iteration 15320, loss = 0.293748
I0526 04:52:03.276494 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.293748 (* 1 = 0.293748 loss)
I0526 04:52:03.276501 15394 sgd_solver.cpp:43] Iteration 15320, lr = 0.02
I0526 04:52:14.483012 15394 main.cpp:354] Iteration 15330, loss = 0.450274
I0526 04:52:14.483057 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.450274 (* 1 = 0.450274 loss)
I0526 04:52:14.483064 15394 sgd_solver.cpp:43] Iteration 15330, lr = 0.02
I0526 04:52:26.075512 15394 main.cpp:354] Iteration 15340, loss = 0.469425
I0526 04:52:26.075548 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.469425 (* 1 = 0.469425 loss)
I0526 04:52:26.075556 15394 sgd_solver.cpp:43] Iteration 15340, lr = 0.02
I0526 04:52:37.117923 15394 main.cpp:354] Iteration 15350, loss = 0.398509
I0526 04:52:37.117965 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.39851 (* 1 = 0.39851 loss)
I0526 04:52:37.117974 15394 sgd_solver.cpp:43] Iteration 15350, lr = 0.02
I0526 04:52:48.593117 15394 main.cpp:354] Iteration 15360, loss = 0.374717
I0526 04:52:48.593159 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.374717 (* 1 = 0.374717 loss)
I0526 04:52:48.593168 15394 sgd_solver.cpp:43] Iteration 15360, lr = 0.02
I0526 04:53:00.023386 15394 main.cpp:354] Iteration 15370, loss = 0.446002
I0526 04:53:00.023427 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.446002 (* 1 = 0.446002 loss)
I0526 04:53:00.023433 15394 sgd_solver.cpp:43] Iteration 15370, lr = 0.02
I0526 04:53:11.967139 15394 main.cpp:354] Iteration 15380, loss = 0.381888
I0526 04:53:11.967180 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.381888 (* 1 = 0.381888 loss)
I0526 04:53:11.967187 15394 sgd_solver.cpp:43] Iteration 15380, lr = 0.02
I0526 04:53:23.268378 15394 main.cpp:354] Iteration 15390, loss = 0.498866
I0526 04:53:23.268435 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.498866 (* 1 = 0.498866 loss)
I0526 04:53:23.268441 15394 sgd_solver.cpp:43] Iteration 15390, lr = 0.02
I0526 04:53:34.034665 15394 main.cpp:465] Iteration 15400, Testing net (#0)
I0526 04:54:04.717689 15394 main.cpp:532]     Test net output #0: Accuracy = 0.796
I0526 04:54:04.717733 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.597787 (* 1 = 0.597787 loss)
I0526 04:54:05.752620 15394 main.cpp:354] Iteration 15400, loss = 0.494774
I0526 04:54:05.752653 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.494774 (* 1 = 0.494774 loss)
I0526 04:54:05.752663 15394 sgd_solver.cpp:43] Iteration 15400, lr = 0.02
I0526 04:54:16.566081 15394 main.cpp:354] Iteration 15410, loss = 0.47043
I0526 04:54:16.566138 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.47043 (* 1 = 0.47043 loss)
I0526 04:54:16.566155 15394 sgd_solver.cpp:43] Iteration 15410, lr = 0.02
I0526 04:54:26.926230 15394 main.cpp:354] Iteration 15420, loss = 0.381398
I0526 04:54:26.926272 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.381399 (* 1 = 0.381399 loss)
I0526 04:54:26.926280 15394 sgd_solver.cpp:43] Iteration 15420, lr = 0.02
I0526 04:54:38.582094 15394 main.cpp:354] Iteration 15430, loss = 0.299693
I0526 04:54:38.582136 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.299693 (* 1 = 0.299693 loss)
I0526 04:54:38.582144 15394 sgd_solver.cpp:43] Iteration 15430, lr = 0.02
I0526 04:54:50.621323 15394 main.cpp:354] Iteration 15440, loss = 0.374102
I0526 04:54:50.621374 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.374103 (* 1 = 0.374103 loss)
I0526 04:54:50.621381 15394 sgd_solver.cpp:43] Iteration 15440, lr = 0.02
I0526 04:55:01.148547 15394 main.cpp:354] Iteration 15450, loss = 0.811264
I0526 04:55:01.148586 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.811265 (* 1 = 0.811265 loss)
I0526 04:55:01.148593 15394 sgd_solver.cpp:43] Iteration 15450, lr = 0.02
I0526 04:55:12.639125 15394 main.cpp:354] Iteration 15460, loss = 0.426048
I0526 04:55:12.639166 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.426048 (* 1 = 0.426048 loss)
I0526 04:55:12.639173 15394 sgd_solver.cpp:43] Iteration 15460, lr = 0.02
I0526 04:55:23.884536 15394 main.cpp:354] Iteration 15470, loss = 0.4521
I0526 04:55:23.884580 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.452101 (* 1 = 0.452101 loss)
I0526 04:55:23.884588 15394 sgd_solver.cpp:43] Iteration 15470, lr = 0.02
I0526 04:55:35.221783 15394 main.cpp:354] Iteration 15480, loss = 0.288651
I0526 04:55:35.221832 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.288651 (* 1 = 0.288651 loss)
I0526 04:55:35.221838 15394 sgd_solver.cpp:43] Iteration 15480, lr = 0.02
I0526 04:55:46.757870 15394 main.cpp:354] Iteration 15490, loss = 0.34811
I0526 04:55:46.757915 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.348111 (* 1 = 0.348111 loss)
I0526 04:55:46.757922 15394 sgd_solver.cpp:43] Iteration 15490, lr = 0.02
I0526 04:55:57.240262 15394 main.cpp:465] Iteration 15500, Testing net (#0)
I0526 04:56:27.869997 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7221
I0526 04:56:27.870049 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.800262 (* 1 = 0.800262 loss)
I0526 04:56:28.837417 15394 main.cpp:354] Iteration 15500, loss = 0.41681
I0526 04:56:28.837458 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.41681 (* 1 = 0.41681 loss)
I0526 04:56:28.837466 15394 sgd_solver.cpp:43] Iteration 15500, lr = 0.02
I0526 04:56:39.612298 15394 main.cpp:354] Iteration 15510, loss = 0.384235
I0526 04:56:39.612332 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.384236 (* 1 = 0.384236 loss)
I0526 04:56:39.612339 15394 sgd_solver.cpp:43] Iteration 15510, lr = 0.02
I0526 04:56:51.436750 15394 main.cpp:354] Iteration 15520, loss = 0.262623
I0526 04:56:51.436794 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.262623 (* 1 = 0.262623 loss)
I0526 04:56:51.436803 15394 sgd_solver.cpp:43] Iteration 15520, lr = 0.02
I0526 04:57:02.739368 15394 main.cpp:354] Iteration 15530, loss = 0.482622
I0526 04:57:02.739414 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.482622 (* 1 = 0.482622 loss)
I0526 04:57:02.739423 15394 sgd_solver.cpp:43] Iteration 15530, lr = 0.02
I0526 04:57:14.947510 15394 main.cpp:354] Iteration 15540, loss = 0.316093
I0526 04:57:14.947553 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.316093 (* 1 = 0.316093 loss)
I0526 04:57:14.947561 15394 sgd_solver.cpp:43] Iteration 15540, lr = 0.02
I0526 04:57:26.864382 15394 main.cpp:354] Iteration 15550, loss = 0.374116
I0526 04:57:26.864421 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.374116 (* 1 = 0.374116 loss)
I0526 04:57:26.864434 15394 sgd_solver.cpp:43] Iteration 15550, lr = 0.02
I0526 04:57:37.858335 15394 main.cpp:354] Iteration 15560, loss = 0.497313
I0526 04:57:37.858394 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.497313 (* 1 = 0.497313 loss)
I0526 04:57:37.858402 15394 sgd_solver.cpp:43] Iteration 15560, lr = 0.02
I0526 04:57:49.637886 15394 main.cpp:354] Iteration 15570, loss = 0.498393
I0526 04:57:49.637926 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.498393 (* 1 = 0.498393 loss)
I0526 04:57:49.637934 15394 sgd_solver.cpp:43] Iteration 15570, lr = 0.02
I0526 04:58:00.055485 15394 main.cpp:354] Iteration 15580, loss = 0.656698
I0526 04:58:00.055529 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.656698 (* 1 = 0.656698 loss)
I0526 04:58:00.055536 15394 sgd_solver.cpp:43] Iteration 15580, lr = 0.02
I0526 04:58:11.021044 15394 main.cpp:354] Iteration 15590, loss = 0.35313
I0526 04:58:11.021086 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.353131 (* 1 = 0.353131 loss)
I0526 04:58:11.021095 15394 sgd_solver.cpp:43] Iteration 15590, lr = 0.02
I0526 04:58:21.654700 15394 main.cpp:465] Iteration 15600, Testing net (#0)
I0526 04:58:52.311600 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7484
I0526 04:58:52.311643 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.744557 (* 1 = 0.744557 loss)
I0526 04:58:53.575904 15394 main.cpp:354] Iteration 15600, loss = 0.298584
I0526 04:58:53.575944 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.298585 (* 1 = 0.298585 loss)
I0526 04:58:53.575953 15394 sgd_solver.cpp:43] Iteration 15600, lr = 0.02
I0526 04:59:05.131228 15394 main.cpp:354] Iteration 15610, loss = 0.458085
I0526 04:59:05.131269 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.458085 (* 1 = 0.458085 loss)
I0526 04:59:05.131276 15394 sgd_solver.cpp:43] Iteration 15610, lr = 0.02
I0526 04:59:16.342226 15394 main.cpp:354] Iteration 15620, loss = 0.5055
I0526 04:59:16.342278 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.5055 (* 1 = 0.5055 loss)
I0526 04:59:16.342285 15394 sgd_solver.cpp:43] Iteration 15620, lr = 0.02
I0526 04:59:27.819485 15394 main.cpp:354] Iteration 15630, loss = 0.547271
I0526 04:59:27.819528 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.547271 (* 1 = 0.547271 loss)
I0526 04:59:27.819537 15394 sgd_solver.cpp:43] Iteration 15630, lr = 0.02
I0526 04:59:39.722275 15394 main.cpp:354] Iteration 15640, loss = 0.35607
I0526 04:59:39.722317 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.35607 (* 1 = 0.35607 loss)
I0526 04:59:39.722324 15394 sgd_solver.cpp:43] Iteration 15640, lr = 0.02
I0526 04:59:51.280642 15394 main.cpp:354] Iteration 15650, loss = 0.399147
I0526 04:59:51.280685 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.399147 (* 1 = 0.399147 loss)
I0526 04:59:51.280692 15394 sgd_solver.cpp:43] Iteration 15650, lr = 0.02
I0526 05:00:03.376232 15394 main.cpp:354] Iteration 15660, loss = 0.496151
I0526 05:00:03.376276 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.496151 (* 1 = 0.496151 loss)
I0526 05:00:03.376282 15394 sgd_solver.cpp:43] Iteration 15660, lr = 0.02
I0526 05:00:14.157645 15394 main.cpp:354] Iteration 15670, loss = 0.730883
I0526 05:00:14.157678 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.730883 (* 1 = 0.730883 loss)
I0526 05:00:14.157685 15394 sgd_solver.cpp:43] Iteration 15670, lr = 0.02
I0526 05:00:25.615483 15394 main.cpp:354] Iteration 15680, loss = 0.563794
I0526 05:00:25.615520 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.563794 (* 1 = 0.563794 loss)
I0526 05:00:25.615527 15394 sgd_solver.cpp:43] Iteration 15680, lr = 0.02
I0526 05:00:36.135967 15394 main.cpp:354] Iteration 15690, loss = 0.254821
I0526 05:00:36.136023 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.254821 (* 1 = 0.254821 loss)
I0526 05:00:36.136029 15394 sgd_solver.cpp:43] Iteration 15690, lr = 0.02
I0526 05:00:46.137588 15394 main.cpp:465] Iteration 15700, Testing net (#0)
I0526 05:01:16.667042 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7258
I0526 05:01:16.667078 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.810267 (* 1 = 0.810267 loss)
I0526 05:01:17.850919 15394 main.cpp:354] Iteration 15700, loss = 0.3273
I0526 05:01:17.850952 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.3273 (* 1 = 0.3273 loss)
I0526 05:01:17.850961 15394 sgd_solver.cpp:43] Iteration 15700, lr = 0.02
I0526 05:01:29.041805 15394 main.cpp:354] Iteration 15710, loss = 0.517556
I0526 05:01:29.041847 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.517557 (* 1 = 0.517557 loss)
I0526 05:01:29.041857 15394 sgd_solver.cpp:43] Iteration 15710, lr = 0.02
I0526 05:01:41.021739 15394 main.cpp:354] Iteration 15720, loss = 0.336265
I0526 05:01:41.021781 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.336265 (* 1 = 0.336265 loss)
I0526 05:01:41.021788 15394 sgd_solver.cpp:43] Iteration 15720, lr = 0.02
I0526 05:01:52.502523 15394 main.cpp:354] Iteration 15730, loss = 0.523759
I0526 05:01:52.502567 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.523759 (* 1 = 0.523759 loss)
I0526 05:01:52.502573 15394 sgd_solver.cpp:43] Iteration 15730, lr = 0.02
I0526 05:02:03.351444 15394 main.cpp:354] Iteration 15740, loss = 0.320085
I0526 05:02:03.351511 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.320085 (* 1 = 0.320085 loss)
I0526 05:02:03.351519 15394 sgd_solver.cpp:43] Iteration 15740, lr = 0.02
I0526 05:02:14.306746 15394 main.cpp:354] Iteration 15750, loss = 0.525883
I0526 05:02:14.306787 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.525884 (* 1 = 0.525884 loss)
I0526 05:02:14.306793 15394 sgd_solver.cpp:43] Iteration 15750, lr = 0.02
I0526 05:02:25.614282 15394 main.cpp:354] Iteration 15760, loss = 0.44982
I0526 05:02:25.614321 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.44982 (* 1 = 0.44982 loss)
I0526 05:02:25.614327 15394 sgd_solver.cpp:43] Iteration 15760, lr = 0.02
I0526 05:02:37.391713 15394 main.cpp:354] Iteration 15770, loss = 0.459687
I0526 05:02:37.391755 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.459688 (* 1 = 0.459688 loss)
I0526 05:02:37.391762 15394 sgd_solver.cpp:43] Iteration 15770, lr = 0.02
I0526 05:02:48.411849 15394 main.cpp:354] Iteration 15780, loss = 0.704792
I0526 05:02:48.411891 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.704792 (* 1 = 0.704792 loss)
I0526 05:02:48.411898 15394 sgd_solver.cpp:43] Iteration 15780, lr = 0.02
I0526 05:02:59.282955 15394 main.cpp:354] Iteration 15790, loss = 0.477115
I0526 05:02:59.282989 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.477116 (* 1 = 0.477116 loss)
I0526 05:02:59.282995 15394 sgd_solver.cpp:43] Iteration 15790, lr = 0.02
I0526 05:03:09.833860 15394 main.cpp:465] Iteration 15800, Testing net (#0)
I0526 05:03:40.502945 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7617
I0526 05:03:40.502987 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.722959 (* 1 = 0.722959 loss)
I0526 05:03:41.459813 15394 main.cpp:354] Iteration 15800, loss = 0.611887
I0526 05:03:41.459852 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.611887 (* 1 = 0.611887 loss)
I0526 05:03:41.459861 15394 sgd_solver.cpp:43] Iteration 15800, lr = 0.02
I0526 05:03:53.059847 15394 main.cpp:354] Iteration 15810, loss = 0.514665
I0526 05:03:53.059891 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.514665 (* 1 = 0.514665 loss)
I0526 05:03:53.059909 15394 sgd_solver.cpp:43] Iteration 15810, lr = 0.02
I0526 05:04:04.854574 15394 main.cpp:354] Iteration 15820, loss = 0.26863
I0526 05:04:04.854625 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.26863 (* 1 = 0.26863 loss)
I0526 05:04:04.854634 15394 sgd_solver.cpp:43] Iteration 15820, lr = 0.02
I0526 05:04:16.865833 15394 main.cpp:354] Iteration 15830, loss = 0.304635
I0526 05:04:16.865883 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.304635 (* 1 = 0.304635 loss)
I0526 05:04:16.865891 15394 sgd_solver.cpp:43] Iteration 15830, lr = 0.02
I0526 05:04:28.558993 15394 main.cpp:354] Iteration 15840, loss = 0.477094
I0526 05:04:28.559039 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.477094 (* 1 = 0.477094 loss)
I0526 05:04:28.559051 15394 sgd_solver.cpp:43] Iteration 15840, lr = 0.02
I0526 05:04:40.139853 15394 main.cpp:354] Iteration 15850, loss = 0.314689
I0526 05:04:40.139886 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.314689 (* 1 = 0.314689 loss)
I0526 05:04:40.139894 15394 sgd_solver.cpp:43] Iteration 15850, lr = 0.02
I0526 05:04:52.177651 15394 main.cpp:354] Iteration 15860, loss = 0.469993
I0526 05:04:52.177695 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.469993 (* 1 = 0.469993 loss)
I0526 05:04:52.177701 15394 sgd_solver.cpp:43] Iteration 15860, lr = 0.02
I0526 05:05:03.428608 15394 main.cpp:354] Iteration 15870, loss = 0.514523
I0526 05:05:03.428653 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.514523 (* 1 = 0.514523 loss)
I0526 05:05:03.428659 15394 sgd_solver.cpp:43] Iteration 15870, lr = 0.02
I0526 05:05:15.203656 15394 main.cpp:354] Iteration 15880, loss = 0.351458
I0526 05:05:15.203699 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.351458 (* 1 = 0.351458 loss)
I0526 05:05:15.203706 15394 sgd_solver.cpp:43] Iteration 15880, lr = 0.02
I0526 05:05:26.651866 15394 main.cpp:354] Iteration 15890, loss = 0.595974
I0526 05:05:26.651906 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.595974 (* 1 = 0.595974 loss)
I0526 05:05:26.651913 15394 sgd_solver.cpp:43] Iteration 15890, lr = 0.02
I0526 05:05:36.831382 15394 main.cpp:465] Iteration 15900, Testing net (#0)
I0526 05:06:07.448099 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7848
I0526 05:06:07.448143 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.67105 (* 1 = 0.67105 loss)
I0526 05:06:08.485644 15394 main.cpp:354] Iteration 15900, loss = 0.395085
I0526 05:06:08.485684 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.395085 (* 1 = 0.395085 loss)
I0526 05:06:08.485692 15394 sgd_solver.cpp:43] Iteration 15900, lr = 0.02
I0526 05:06:20.471027 15394 main.cpp:354] Iteration 15910, loss = 0.421451
I0526 05:06:20.471067 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.421451 (* 1 = 0.421451 loss)
I0526 05:06:20.471074 15394 sgd_solver.cpp:43] Iteration 15910, lr = 0.02
I0526 05:06:32.837926 15394 main.cpp:354] Iteration 15920, loss = 0.476159
I0526 05:06:32.837970 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.476159 (* 1 = 0.476159 loss)
I0526 05:06:32.837978 15394 sgd_solver.cpp:43] Iteration 15920, lr = 0.02
I0526 05:06:45.297823 15394 main.cpp:354] Iteration 15930, loss = 0.530811
I0526 05:06:45.297868 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.530811 (* 1 = 0.530811 loss)
I0526 05:06:45.297874 15394 sgd_solver.cpp:43] Iteration 15930, lr = 0.02
I0526 05:06:56.853130 15394 main.cpp:354] Iteration 15940, loss = 0.393316
I0526 05:06:56.853173 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.393317 (* 1 = 0.393317 loss)
I0526 05:06:56.853179 15394 sgd_solver.cpp:43] Iteration 15940, lr = 0.02
I0526 05:07:07.832172 15394 main.cpp:354] Iteration 15950, loss = 0.542731
I0526 05:07:07.832227 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.542731 (* 1 = 0.542731 loss)
I0526 05:07:07.832236 15394 sgd_solver.cpp:43] Iteration 15950, lr = 0.02
I0526 05:07:18.886729 15394 main.cpp:354] Iteration 15960, loss = 0.668703
I0526 05:07:18.886772 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.668703 (* 1 = 0.668703 loss)
I0526 05:07:18.886780 15394 sgd_solver.cpp:43] Iteration 15960, lr = 0.02
I0526 05:07:30.558934 15394 main.cpp:354] Iteration 15970, loss = 0.527482
I0526 05:07:30.558990 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.527483 (* 1 = 0.527483 loss)
I0526 05:07:30.559001 15394 sgd_solver.cpp:43] Iteration 15970, lr = 0.02
I0526 05:07:41.638953 15394 main.cpp:354] Iteration 15980, loss = 0.421271
I0526 05:07:41.638993 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.421271 (* 1 = 0.421271 loss)
I0526 05:07:41.639000 15394 sgd_solver.cpp:43] Iteration 15980, lr = 0.02
I0526 05:07:53.664129 15394 main.cpp:354] Iteration 15990, loss = 0.219349
I0526 05:07:53.664172 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.219349 (* 1 = 0.219349 loss)
I0526 05:07:53.664180 15394 sgd_solver.cpp:43] Iteration 15990, lr = 0.02
I0526 05:08:03.759374 15394 main.cpp:465] Iteration 16000, Testing net (#0)
I0526 05:08:34.319869 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8007
I0526 05:08:34.319907 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.576767 (* 1 = 0.576767 loss)
I0526 05:08:35.394410 15394 main.cpp:354] Iteration 16000, loss = 0.375092
I0526 05:08:35.394443 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.375092 (* 1 = 0.375092 loss)
I0526 05:08:35.394451 15394 sgd_solver.cpp:43] Iteration 16000, lr = 0.02
I0526 05:08:46.661047 15394 main.cpp:354] Iteration 16010, loss = 0.561801
I0526 05:08:46.661087 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.561801 (* 1 = 0.561801 loss)
I0526 05:08:46.661093 15394 sgd_solver.cpp:43] Iteration 16010, lr = 0.02
I0526 05:08:58.118829 15394 main.cpp:354] Iteration 16020, loss = 0.459233
I0526 05:08:58.118867 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.459233 (* 1 = 0.459233 loss)
I0526 05:08:58.118873 15394 sgd_solver.cpp:43] Iteration 16020, lr = 0.02
I0526 05:09:09.510095 15394 main.cpp:354] Iteration 16030, loss = 0.298792
I0526 05:09:09.510139 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.298793 (* 1 = 0.298793 loss)
I0526 05:09:09.510146 15394 sgd_solver.cpp:43] Iteration 16030, lr = 0.02
I0526 05:09:20.603322 15394 main.cpp:354] Iteration 16040, loss = 0.43925
I0526 05:09:20.603363 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.43925 (* 1 = 0.43925 loss)
I0526 05:09:20.603370 15394 sgd_solver.cpp:43] Iteration 16040, lr = 0.02
I0526 05:09:32.121155 15394 main.cpp:354] Iteration 16050, loss = 0.38104
I0526 05:09:32.121193 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.38104 (* 1 = 0.38104 loss)
I0526 05:09:32.121201 15394 sgd_solver.cpp:43] Iteration 16050, lr = 0.02
I0526 05:09:43.444435 15394 main.cpp:354] Iteration 16060, loss = 0.474694
I0526 05:09:43.444483 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.474694 (* 1 = 0.474694 loss)
I0526 05:09:43.444494 15394 sgd_solver.cpp:43] Iteration 16060, lr = 0.02
I0526 05:09:55.088114 15394 main.cpp:354] Iteration 16070, loss = 0.302525
I0526 05:09:55.088153 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.302525 (* 1 = 0.302525 loss)
I0526 05:09:55.088160 15394 sgd_solver.cpp:43] Iteration 16070, lr = 0.02
I0526 05:10:06.288668 15394 main.cpp:354] Iteration 16080, loss = 0.572112
I0526 05:10:06.288713 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.572112 (* 1 = 0.572112 loss)
I0526 05:10:06.288720 15394 sgd_solver.cpp:43] Iteration 16080, lr = 0.02
I0526 05:10:17.235635 15394 main.cpp:354] Iteration 16090, loss = 0.319785
I0526 05:10:17.235677 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.319785 (* 1 = 0.319785 loss)
I0526 05:10:17.235683 15394 sgd_solver.cpp:43] Iteration 16090, lr = 0.02
I0526 05:10:27.715993 15394 main.cpp:465] Iteration 16100, Testing net (#0)
I0526 05:10:58.248818 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7601
I0526 05:10:58.248862 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.698592 (* 1 = 0.698592 loss)
I0526 05:10:59.354784 15394 main.cpp:354] Iteration 16100, loss = 0.309225
I0526 05:10:59.354827 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.309225 (* 1 = 0.309225 loss)
I0526 05:10:59.354837 15394 sgd_solver.cpp:43] Iteration 16100, lr = 0.02
I0526 05:11:10.779220 15394 main.cpp:354] Iteration 16110, loss = 0.475182
I0526 05:11:10.779266 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.475182 (* 1 = 0.475182 loss)
I0526 05:11:10.779274 15394 sgd_solver.cpp:43] Iteration 16110, lr = 0.02
I0526 05:11:23.203951 15394 main.cpp:354] Iteration 16120, loss = 0.370087
I0526 05:11:23.203994 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.370087 (* 1 = 0.370087 loss)
I0526 05:11:23.203999 15394 sgd_solver.cpp:43] Iteration 16120, lr = 0.02
I0526 05:11:34.296259 15394 main.cpp:354] Iteration 16130, loss = 0.420314
I0526 05:11:34.296303 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.420315 (* 1 = 0.420315 loss)
I0526 05:11:34.296310 15394 sgd_solver.cpp:43] Iteration 16130, lr = 0.02
I0526 05:11:46.169065 15394 main.cpp:354] Iteration 16140, loss = 0.413894
I0526 05:11:46.169095 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.413894 (* 1 = 0.413894 loss)
I0526 05:11:46.169100 15394 sgd_solver.cpp:43] Iteration 16140, lr = 0.02
I0526 05:11:57.316740 15394 main.cpp:354] Iteration 16150, loss = 0.364166
I0526 05:11:57.316781 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.364166 (* 1 = 0.364166 loss)
I0526 05:11:57.316787 15394 sgd_solver.cpp:43] Iteration 16150, lr = 0.02
I0526 05:12:08.502933 15394 main.cpp:354] Iteration 16160, loss = 0.596612
I0526 05:12:08.502979 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.596612 (* 1 = 0.596612 loss)
I0526 05:12:08.502987 15394 sgd_solver.cpp:43] Iteration 16160, lr = 0.02
I0526 05:12:20.330293 15394 main.cpp:354] Iteration 16170, loss = 0.415768
I0526 05:12:20.330344 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.415769 (* 1 = 0.415769 loss)
I0526 05:12:20.330351 15394 sgd_solver.cpp:43] Iteration 16170, lr = 0.02
I0526 05:12:31.881935 15394 main.cpp:354] Iteration 16180, loss = 0.438008
I0526 05:12:31.881978 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.438008 (* 1 = 0.438008 loss)
I0526 05:12:31.881983 15394 sgd_solver.cpp:43] Iteration 16180, lr = 0.02
I0526 05:12:43.173048 15394 main.cpp:354] Iteration 16190, loss = 0.401897
I0526 05:12:43.173074 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.401897 (* 1 = 0.401897 loss)
I0526 05:12:43.173081 15394 sgd_solver.cpp:43] Iteration 16190, lr = 0.02
I0526 05:12:52.540132 15394 main.cpp:465] Iteration 16200, Testing net (#0)
I0526 05:13:23.107048 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6796
I0526 05:13:23.107090 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.908386 (* 1 = 0.908386 loss)
I0526 05:13:24.220603 15394 main.cpp:354] Iteration 16200, loss = 0.313058
I0526 05:13:24.220646 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.313058 (* 1 = 0.313058 loss)
I0526 05:13:24.220654 15394 sgd_solver.cpp:43] Iteration 16200, lr = 0.02
I0526 05:13:35.477023 15394 main.cpp:354] Iteration 16210, loss = 0.376796
I0526 05:13:35.477066 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.376797 (* 1 = 0.376797 loss)
I0526 05:13:35.477073 15394 sgd_solver.cpp:43] Iteration 16210, lr = 0.02
I0526 05:13:47.226922 15394 main.cpp:354] Iteration 16220, loss = 0.469746
I0526 05:13:47.226963 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.469746 (* 1 = 0.469746 loss)
I0526 05:13:47.226969 15394 sgd_solver.cpp:43] Iteration 16220, lr = 0.02
I0526 05:13:58.231088 15394 main.cpp:354] Iteration 16230, loss = 0.52292
I0526 05:13:58.231133 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.52292 (* 1 = 0.52292 loss)
I0526 05:13:58.231142 15394 sgd_solver.cpp:43] Iteration 16230, lr = 0.02
I0526 05:14:09.809317 15394 main.cpp:354] Iteration 16240, loss = 0.4874
I0526 05:14:09.809358 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.4874 (* 1 = 0.4874 loss)
I0526 05:14:09.809376 15394 sgd_solver.cpp:43] Iteration 16240, lr = 0.02
I0526 05:14:21.482548 15394 main.cpp:354] Iteration 16250, loss = 0.402764
I0526 05:14:21.482594 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.402764 (* 1 = 0.402764 loss)
I0526 05:14:21.482606 15394 sgd_solver.cpp:43] Iteration 16250, lr = 0.02
I0526 05:14:33.132371 15394 main.cpp:354] Iteration 16260, loss = 0.380295
I0526 05:14:33.132413 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.380295 (* 1 = 0.380295 loss)
I0526 05:14:33.132421 15394 sgd_solver.cpp:43] Iteration 16260, lr = 0.02
I0526 05:14:45.001519 15394 main.cpp:354] Iteration 16270, loss = 0.439364
I0526 05:14:45.001564 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.439364 (* 1 = 0.439364 loss)
I0526 05:14:45.001572 15394 sgd_solver.cpp:43] Iteration 16270, lr = 0.02
I0526 05:14:56.967700 15394 main.cpp:354] Iteration 16280, loss = 0.527794
I0526 05:14:56.967731 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.527794 (* 1 = 0.527794 loss)
I0526 05:14:56.967738 15394 sgd_solver.cpp:43] Iteration 16280, lr = 0.02
I0526 05:15:08.602393 15394 main.cpp:354] Iteration 16290, loss = 0.499915
I0526 05:15:08.602448 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.499915 (* 1 = 0.499915 loss)
I0526 05:15:08.602455 15394 sgd_solver.cpp:43] Iteration 16290, lr = 0.02
I0526 05:15:19.072571 15394 main.cpp:465] Iteration 16300, Testing net (#0)
I0526 05:15:49.530021 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7616
I0526 05:15:49.530072 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.715097 (* 1 = 0.715097 loss)
I0526 05:15:50.492697 15394 main.cpp:354] Iteration 16300, loss = 0.447797
I0526 05:15:50.492739 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.447797 (* 1 = 0.447797 loss)
I0526 05:15:50.492748 15394 sgd_solver.cpp:43] Iteration 16300, lr = 0.02
I0526 05:16:02.054024 15394 main.cpp:354] Iteration 16310, loss = 0.371581
I0526 05:16:02.054070 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.371581 (* 1 = 0.371581 loss)
I0526 05:16:02.054080 15394 sgd_solver.cpp:43] Iteration 16310, lr = 0.02
I0526 05:16:12.452155 15394 main.cpp:354] Iteration 16320, loss = 0.514094
I0526 05:16:12.452193 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.514095 (* 1 = 0.514095 loss)
I0526 05:16:12.452199 15394 sgd_solver.cpp:43] Iteration 16320, lr = 0.02
I0526 05:16:23.614887 15394 main.cpp:354] Iteration 16330, loss = 0.226086
I0526 05:16:23.614933 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.226086 (* 1 = 0.226086 loss)
I0526 05:16:23.614938 15394 sgd_solver.cpp:43] Iteration 16330, lr = 0.02
I0526 05:16:34.815448 15394 main.cpp:354] Iteration 16340, loss = 0.397596
I0526 05:16:34.815502 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.397596 (* 1 = 0.397596 loss)
I0526 05:16:34.815510 15394 sgd_solver.cpp:43] Iteration 16340, lr = 0.02
I0526 05:16:46.070479 15394 main.cpp:354] Iteration 16350, loss = 0.47078
I0526 05:16:46.070520 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.47078 (* 1 = 0.47078 loss)
I0526 05:16:46.070528 15394 sgd_solver.cpp:43] Iteration 16350, lr = 0.02
I0526 05:16:57.490901 15394 main.cpp:354] Iteration 16360, loss = 0.497527
I0526 05:16:57.490929 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.497527 (* 1 = 0.497527 loss)
I0526 05:16:57.490936 15394 sgd_solver.cpp:43] Iteration 16360, lr = 0.02
I0526 05:17:09.046536 15394 main.cpp:354] Iteration 16370, loss = 0.323457
I0526 05:17:09.046572 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.323458 (* 1 = 0.323458 loss)
I0526 05:17:09.046579 15394 sgd_solver.cpp:43] Iteration 16370, lr = 0.02
I0526 05:17:20.367069 15394 main.cpp:354] Iteration 16380, loss = 0.427344
I0526 05:17:20.367112 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.427344 (* 1 = 0.427344 loss)
I0526 05:17:20.367120 15394 sgd_solver.cpp:43] Iteration 16380, lr = 0.02
I0526 05:17:31.444372 15394 main.cpp:354] Iteration 16390, loss = 0.290147
I0526 05:17:31.444417 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.290147 (* 1 = 0.290147 loss)
I0526 05:17:31.444429 15394 sgd_solver.cpp:43] Iteration 16390, lr = 0.02
I0526 05:17:41.509177 15394 main.cpp:465] Iteration 16400, Testing net (#0)
I0526 05:18:12.079758 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7804
I0526 05:18:12.079800 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.662362 (* 1 = 0.662362 loss)
I0526 05:18:13.079123 15394 main.cpp:354] Iteration 16400, loss = 0.464739
I0526 05:18:13.079150 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.464739 (* 1 = 0.464739 loss)
I0526 05:18:13.079159 15394 sgd_solver.cpp:43] Iteration 16400, lr = 0.02
I0526 05:18:24.601294 15394 main.cpp:354] Iteration 16410, loss = 0.295385
I0526 05:18:24.601335 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.295385 (* 1 = 0.295385 loss)
I0526 05:18:24.601341 15394 sgd_solver.cpp:43] Iteration 16410, lr = 0.02
I0526 05:18:36.455025 15394 main.cpp:354] Iteration 16420, loss = 0.402346
I0526 05:18:36.455067 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.402346 (* 1 = 0.402346 loss)
I0526 05:18:36.455075 15394 sgd_solver.cpp:43] Iteration 16420, lr = 0.02
I0526 05:18:47.914206 15394 main.cpp:354] Iteration 16430, loss = 0.267955
I0526 05:18:47.914248 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.267955 (* 1 = 0.267955 loss)
I0526 05:18:47.914257 15394 sgd_solver.cpp:43] Iteration 16430, lr = 0.02
I0526 05:18:58.976163 15394 main.cpp:354] Iteration 16440, loss = 0.383067
I0526 05:18:58.976217 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.383067 (* 1 = 0.383067 loss)
I0526 05:18:58.976225 15394 sgd_solver.cpp:43] Iteration 16440, lr = 0.02
I0526 05:19:09.775653 15394 main.cpp:354] Iteration 16450, loss = 0.483575
I0526 05:19:09.775691 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.483576 (* 1 = 0.483576 loss)
I0526 05:19:09.775696 15394 sgd_solver.cpp:43] Iteration 16450, lr = 0.02
I0526 05:19:21.245368 15394 main.cpp:354] Iteration 16460, loss = 0.453214
I0526 05:19:21.245410 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.453215 (* 1 = 0.453215 loss)
I0526 05:19:21.245419 15394 sgd_solver.cpp:43] Iteration 16460, lr = 0.02
I0526 05:19:31.850469 15394 main.cpp:354] Iteration 16470, loss = 0.503148
I0526 05:19:31.850513 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.503148 (* 1 = 0.503148 loss)
I0526 05:19:31.850522 15394 sgd_solver.cpp:43] Iteration 16470, lr = 0.02
I0526 05:19:43.283360 15394 main.cpp:354] Iteration 16480, loss = 0.316264
I0526 05:19:43.283423 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.316265 (* 1 = 0.316265 loss)
I0526 05:19:43.283432 15394 sgd_solver.cpp:43] Iteration 16480, lr = 0.02
I0526 05:19:54.583331 15394 main.cpp:354] Iteration 16490, loss = 0.497446
I0526 05:19:54.583370 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.497446 (* 1 = 0.497446 loss)
I0526 05:19:54.583377 15394 sgd_solver.cpp:43] Iteration 16490, lr = 0.02
I0526 05:20:04.418614 15394 main.cpp:465] Iteration 16500, Testing net (#0)
I0526 05:20:34.951776 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8032
I0526 05:20:34.951818 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.570378 (* 1 = 0.570378 loss)
I0526 05:20:36.220106 15394 main.cpp:354] Iteration 16500, loss = 0.229738
I0526 05:20:36.220155 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.229738 (* 1 = 0.229738 loss)
I0526 05:20:36.220162 15394 sgd_solver.cpp:43] Iteration 16500, lr = 0.02
I0526 05:20:46.665035 15394 main.cpp:354] Iteration 16510, loss = 0.39974
I0526 05:20:46.665076 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.39974 (* 1 = 0.39974 loss)
I0526 05:20:46.665083 15394 sgd_solver.cpp:43] Iteration 16510, lr = 0.02
I0526 05:20:57.752594 15394 main.cpp:354] Iteration 16520, loss = 0.295399
I0526 05:20:57.752632 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.295399 (* 1 = 0.295399 loss)
I0526 05:20:57.752640 15394 sgd_solver.cpp:43] Iteration 16520, lr = 0.02
I0526 05:21:09.566066 15394 main.cpp:354] Iteration 16530, loss = 0.346107
I0526 05:21:09.566118 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.346107 (* 1 = 0.346107 loss)
I0526 05:21:09.566124 15394 sgd_solver.cpp:43] Iteration 16530, lr = 0.02
I0526 05:21:20.599010 15394 main.cpp:354] Iteration 16540, loss = 0.480063
I0526 05:21:20.599055 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.480064 (* 1 = 0.480064 loss)
I0526 05:21:20.599061 15394 sgd_solver.cpp:43] Iteration 16540, lr = 0.02
I0526 05:21:31.419934 15394 main.cpp:354] Iteration 16550, loss = 0.445459
I0526 05:21:31.419975 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.445459 (* 1 = 0.445459 loss)
I0526 05:21:31.419982 15394 sgd_solver.cpp:43] Iteration 16550, lr = 0.02
I0526 05:21:42.140800 15394 main.cpp:354] Iteration 16560, loss = 0.507933
I0526 05:21:42.140841 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.507933 (* 1 = 0.507933 loss)
I0526 05:21:42.140847 15394 sgd_solver.cpp:43] Iteration 16560, lr = 0.02
I0526 05:21:54.000198 15394 main.cpp:354] Iteration 16570, loss = 0.368076
I0526 05:21:54.000248 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.368076 (* 1 = 0.368076 loss)
I0526 05:21:54.000257 15394 sgd_solver.cpp:43] Iteration 16570, lr = 0.02
I0526 05:22:05.453766 15394 main.cpp:354] Iteration 16580, loss = 0.372919
I0526 05:22:05.453810 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.372919 (* 1 = 0.372919 loss)
I0526 05:22:05.453819 15394 sgd_solver.cpp:43] Iteration 16580, lr = 0.02
I0526 05:22:17.071830 15394 main.cpp:354] Iteration 16590, loss = 0.346946
I0526 05:22:17.071871 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.346946 (* 1 = 0.346946 loss)
I0526 05:22:17.071879 15394 sgd_solver.cpp:43] Iteration 16590, lr = 0.02
I0526 05:22:27.188654 15394 main.cpp:465] Iteration 16600, Testing net (#0)
I0526 05:22:57.748847 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7294
I0526 05:22:57.748893 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.808195 (* 1 = 0.808195 loss)
I0526 05:22:58.630077 15394 main.cpp:354] Iteration 16600, loss = 0.546602
I0526 05:22:58.630117 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.546602 (* 1 = 0.546602 loss)
I0526 05:22:58.630126 15394 sgd_solver.cpp:43] Iteration 16600, lr = 0.02
I0526 05:23:10.081444 15394 main.cpp:354] Iteration 16610, loss = 0.311759
I0526 05:23:10.081486 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.311759 (* 1 = 0.311759 loss)
I0526 05:23:10.081492 15394 sgd_solver.cpp:43] Iteration 16610, lr = 0.02
I0526 05:23:20.566838 15394 main.cpp:354] Iteration 16620, loss = 0.422009
I0526 05:23:20.566879 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.422009 (* 1 = 0.422009 loss)
I0526 05:23:20.566885 15394 sgd_solver.cpp:43] Iteration 16620, lr = 0.02
I0526 05:23:31.570610 15394 main.cpp:354] Iteration 16630, loss = 0.47412
I0526 05:23:31.570657 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.47412 (* 1 = 0.47412 loss)
I0526 05:23:31.570674 15394 sgd_solver.cpp:43] Iteration 16630, lr = 0.02
I0526 05:23:43.347195 15394 main.cpp:354] Iteration 16640, loss = 0.270754
I0526 05:23:43.347226 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.270754 (* 1 = 0.270754 loss)
I0526 05:23:43.347234 15394 sgd_solver.cpp:43] Iteration 16640, lr = 0.02
I0526 05:23:54.016860 15394 main.cpp:354] Iteration 16650, loss = 0.344555
I0526 05:23:54.016896 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.344555 (* 1 = 0.344555 loss)
I0526 05:23:54.016902 15394 sgd_solver.cpp:43] Iteration 16650, lr = 0.02
I0526 05:24:06.086403 15394 main.cpp:354] Iteration 16660, loss = 0.408812
I0526 05:24:06.086447 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.408812 (* 1 = 0.408812 loss)
I0526 05:24:06.086455 15394 sgd_solver.cpp:43] Iteration 16660, lr = 0.02
I0526 05:24:17.937695 15394 main.cpp:354] Iteration 16670, loss = 0.384017
I0526 05:24:17.937737 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.384017 (* 1 = 0.384017 loss)
I0526 05:24:17.937749 15394 sgd_solver.cpp:43] Iteration 16670, lr = 0.02
I0526 05:24:29.408439 15394 main.cpp:354] Iteration 16680, loss = 0.461031
I0526 05:24:29.408483 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.461031 (* 1 = 0.461031 loss)
I0526 05:24:29.408493 15394 sgd_solver.cpp:43] Iteration 16680, lr = 0.02
I0526 05:24:41.219444 15394 main.cpp:354] Iteration 16690, loss = 0.373327
I0526 05:24:41.219477 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.373327 (* 1 = 0.373327 loss)
I0526 05:24:41.219485 15394 sgd_solver.cpp:43] Iteration 16690, lr = 0.02
I0526 05:24:51.181444 15394 main.cpp:465] Iteration 16700, Testing net (#0)
I0526 05:25:21.714009 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8098
I0526 05:25:21.714046 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.550144 (* 1 = 0.550144 loss)
I0526 05:25:22.828716 15394 main.cpp:354] Iteration 16700, loss = 0.400953
I0526 05:25:22.828764 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.400953 (* 1 = 0.400953 loss)
I0526 05:25:22.828773 15394 sgd_solver.cpp:43] Iteration 16700, lr = 0.02
I0526 05:25:34.501781 15394 main.cpp:354] Iteration 16710, loss = 0.362606
I0526 05:25:34.501821 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.362606 (* 1 = 0.362606 loss)
I0526 05:25:34.501838 15394 sgd_solver.cpp:43] Iteration 16710, lr = 0.02
I0526 05:25:46.003834 15394 main.cpp:354] Iteration 16720, loss = 0.331401
I0526 05:25:46.003876 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.331401 (* 1 = 0.331401 loss)
I0526 05:25:46.003883 15394 sgd_solver.cpp:43] Iteration 16720, lr = 0.02
I0526 05:25:57.400298 15394 main.cpp:354] Iteration 16730, loss = 0.723604
I0526 05:25:57.400348 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.723604 (* 1 = 0.723604 loss)
I0526 05:25:57.400354 15394 sgd_solver.cpp:43] Iteration 16730, lr = 0.02
I0526 05:26:08.748626 15394 main.cpp:354] Iteration 16740, loss = 0.501587
I0526 05:26:08.748672 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.501587 (* 1 = 0.501587 loss)
I0526 05:26:08.748679 15394 sgd_solver.cpp:43] Iteration 16740, lr = 0.02
I0526 05:26:20.254061 15394 main.cpp:354] Iteration 16750, loss = 0.349493
I0526 05:26:20.254103 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.349493 (* 1 = 0.349493 loss)
I0526 05:26:20.254109 15394 sgd_solver.cpp:43] Iteration 16750, lr = 0.02
I0526 05:26:31.627218 15394 main.cpp:354] Iteration 16760, loss = 0.34922
I0526 05:26:31.627262 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.34922 (* 1 = 0.34922 loss)
I0526 05:26:31.627269 15394 sgd_solver.cpp:43] Iteration 16760, lr = 0.02
I0526 05:26:42.891103 15394 main.cpp:354] Iteration 16770, loss = 0.418964
I0526 05:26:42.891144 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.418964 (* 1 = 0.418964 loss)
I0526 05:26:42.891149 15394 sgd_solver.cpp:43] Iteration 16770, lr = 0.02
I0526 05:26:54.691752 15394 main.cpp:354] Iteration 16780, loss = 0.354089
I0526 05:26:54.691795 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.354089 (* 1 = 0.354089 loss)
I0526 05:26:54.691802 15394 sgd_solver.cpp:43] Iteration 16780, lr = 0.02
I0526 05:27:06.336210 15394 main.cpp:354] Iteration 16790, loss = 0.373309
I0526 05:27:06.336261 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.373309 (* 1 = 0.373309 loss)
I0526 05:27:06.336268 15394 sgd_solver.cpp:43] Iteration 16790, lr = 0.02
I0526 05:27:17.133862 15394 main.cpp:465] Iteration 16800, Testing net (#0)
I0526 05:27:47.741471 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8313
I0526 05:27:47.741510 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.491568 (* 1 = 0.491568 loss)
I0526 05:27:48.968261 15394 main.cpp:354] Iteration 16800, loss = 0.242272
I0526 05:27:48.968312 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.242272 (* 1 = 0.242272 loss)
I0526 05:27:48.968319 15394 sgd_solver.cpp:43] Iteration 16800, lr = 0.02
I0526 05:28:00.770895 15394 main.cpp:354] Iteration 16810, loss = 0.408378
I0526 05:28:00.770937 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.408378 (* 1 = 0.408378 loss)
I0526 05:28:00.770944 15394 sgd_solver.cpp:43] Iteration 16810, lr = 0.02
I0526 05:28:12.884109 15394 main.cpp:354] Iteration 16820, loss = 0.391421
I0526 05:28:12.884157 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.391421 (* 1 = 0.391421 loss)
I0526 05:28:12.884165 15394 sgd_solver.cpp:43] Iteration 16820, lr = 0.02
I0526 05:28:23.951606 15394 main.cpp:354] Iteration 16830, loss = 0.336519
I0526 05:28:23.951649 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.336519 (* 1 = 0.336519 loss)
I0526 05:28:23.951656 15394 sgd_solver.cpp:43] Iteration 16830, lr = 0.02
I0526 05:28:35.424393 15394 main.cpp:354] Iteration 16840, loss = 0.589171
I0526 05:28:35.424442 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.589171 (* 1 = 0.589171 loss)
I0526 05:28:35.424449 15394 sgd_solver.cpp:43] Iteration 16840, lr = 0.02
I0526 05:28:46.725320 15394 main.cpp:354] Iteration 16850, loss = 0.471354
I0526 05:28:46.725365 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.471354 (* 1 = 0.471354 loss)
I0526 05:28:46.725374 15394 sgd_solver.cpp:43] Iteration 16850, lr = 0.02
I0526 05:28:58.006415 15394 main.cpp:354] Iteration 16860, loss = 0.32644
I0526 05:28:58.006458 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.32644 (* 1 = 0.32644 loss)
I0526 05:28:58.006466 15394 sgd_solver.cpp:43] Iteration 16860, lr = 0.02
I0526 05:29:09.849606 15394 main.cpp:354] Iteration 16870, loss = 0.324107
I0526 05:29:09.849647 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.324107 (* 1 = 0.324107 loss)
I0526 05:29:09.849653 15394 sgd_solver.cpp:43] Iteration 16870, lr = 0.02
I0526 05:29:20.187947 15394 main.cpp:354] Iteration 16880, loss = 0.400042
I0526 05:29:20.187986 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.400042 (* 1 = 0.400042 loss)
I0526 05:29:20.187994 15394 sgd_solver.cpp:43] Iteration 16880, lr = 0.02
I0526 05:29:31.646880 15394 main.cpp:354] Iteration 16890, loss = 0.332366
I0526 05:29:31.646922 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.332366 (* 1 = 0.332366 loss)
I0526 05:29:31.646929 15394 sgd_solver.cpp:43] Iteration 16890, lr = 0.02
I0526 05:29:42.062885 15394 main.cpp:465] Iteration 16900, Testing net (#0)
I0526 05:30:12.611253 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8236
I0526 05:30:12.611294 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.52233 (* 1 = 0.52233 loss)
I0526 05:30:13.547291 15394 main.cpp:354] Iteration 16900, loss = 0.52444
I0526 05:30:13.547334 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.52444 (* 1 = 0.52444 loss)
I0526 05:30:13.547343 15394 sgd_solver.cpp:43] Iteration 16900, lr = 0.02
I0526 05:30:25.665071 15394 main.cpp:354] Iteration 16910, loss = 0.406594
I0526 05:30:25.665109 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.406594 (* 1 = 0.406594 loss)
I0526 05:30:25.665115 15394 sgd_solver.cpp:43] Iteration 16910, lr = 0.02
I0526 05:30:37.274818 15394 main.cpp:354] Iteration 16920, loss = 0.324304
I0526 05:30:37.274863 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.324304 (* 1 = 0.324304 loss)
I0526 05:30:37.274869 15394 sgd_solver.cpp:43] Iteration 16920, lr = 0.02
I0526 05:30:48.780980 15394 main.cpp:354] Iteration 16930, loss = 0.313838
I0526 05:30:48.781014 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.313838 (* 1 = 0.313838 loss)
I0526 05:30:48.781021 15394 sgd_solver.cpp:43] Iteration 16930, lr = 0.02
I0526 05:30:59.903412 15394 main.cpp:354] Iteration 16940, loss = 0.525854
I0526 05:30:59.903465 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.525854 (* 1 = 0.525854 loss)
I0526 05:30:59.903471 15394 sgd_solver.cpp:43] Iteration 16940, lr = 0.02
I0526 05:31:11.235343 15394 main.cpp:354] Iteration 16950, loss = 0.345034
I0526 05:31:11.235388 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.345034 (* 1 = 0.345034 loss)
I0526 05:31:11.235395 15394 sgd_solver.cpp:43] Iteration 16950, lr = 0.02
I0526 05:31:22.220829 15394 main.cpp:354] Iteration 16960, loss = 0.575159
I0526 05:31:22.220880 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.575159 (* 1 = 0.575159 loss)
I0526 05:31:22.220888 15394 sgd_solver.cpp:43] Iteration 16960, lr = 0.02
I0526 05:31:33.761201 15394 main.cpp:354] Iteration 16970, loss = 0.238761
I0526 05:31:33.761256 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.238761 (* 1 = 0.238761 loss)
I0526 05:31:33.761265 15394 sgd_solver.cpp:43] Iteration 16970, lr = 0.02
I0526 05:31:45.463891 15394 main.cpp:354] Iteration 16980, loss = 0.311466
I0526 05:31:45.463945 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.311466 (* 1 = 0.311466 loss)
I0526 05:31:45.463955 15394 sgd_solver.cpp:43] Iteration 16980, lr = 0.02
I0526 05:31:56.801087 15394 main.cpp:354] Iteration 16990, loss = 0.483939
I0526 05:31:56.801126 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.483939 (* 1 = 0.483939 loss)
I0526 05:31:56.801131 15394 sgd_solver.cpp:43] Iteration 16990, lr = 0.02
I0526 05:32:06.924908 15394 main.cpp:465] Iteration 17000, Testing net (#0)
I0526 05:32:37.460369 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7957
I0526 05:32:37.460412 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.647606 (* 1 = 0.647606 loss)
I0526 05:32:38.495551 15394 main.cpp:354] Iteration 17000, loss = 0.345668
I0526 05:32:38.495591 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.345668 (* 1 = 0.345668 loss)
I0526 05:32:38.495599 15394 sgd_solver.cpp:43] Iteration 17000, lr = 0.02
I0526 05:32:50.131913 15394 main.cpp:354] Iteration 17010, loss = 0.218838
I0526 05:32:50.131966 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.218838 (* 1 = 0.218838 loss)
I0526 05:32:50.131973 15394 sgd_solver.cpp:43] Iteration 17010, lr = 0.02
I0526 05:33:01.173975 15394 main.cpp:354] Iteration 17020, loss = 0.550281
I0526 05:33:01.174028 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.550281 (* 1 = 0.550281 loss)
I0526 05:33:01.174036 15394 sgd_solver.cpp:43] Iteration 17020, lr = 0.02
I0526 05:33:12.335680 15394 main.cpp:354] Iteration 17030, loss = 0.519611
I0526 05:33:12.335721 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.519611 (* 1 = 0.519611 loss)
I0526 05:33:12.335728 15394 sgd_solver.cpp:43] Iteration 17030, lr = 0.02
I0526 05:33:23.714792 15394 main.cpp:354] Iteration 17040, loss = 0.366094
I0526 05:33:23.714838 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.366094 (* 1 = 0.366094 loss)
I0526 05:33:23.714845 15394 sgd_solver.cpp:43] Iteration 17040, lr = 0.02
I0526 05:33:34.604820 15394 main.cpp:354] Iteration 17050, loss = 0.401638
I0526 05:33:34.604859 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.401638 (* 1 = 0.401638 loss)
I0526 05:33:34.604866 15394 sgd_solver.cpp:43] Iteration 17050, lr = 0.02
I0526 05:33:45.607017 15394 main.cpp:354] Iteration 17060, loss = 0.358909
I0526 05:33:45.607062 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.358909 (* 1 = 0.358909 loss)
I0526 05:33:45.607070 15394 sgd_solver.cpp:43] Iteration 17060, lr = 0.02
I0526 05:33:57.826302 15394 main.cpp:354] Iteration 17070, loss = 0.371139
I0526 05:33:57.826340 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.371139 (* 1 = 0.371139 loss)
I0526 05:33:57.826349 15394 sgd_solver.cpp:43] Iteration 17070, lr = 0.02
I0526 05:34:08.898214 15394 main.cpp:354] Iteration 17080, loss = 0.315643
I0526 05:34:08.898253 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.315643 (* 1 = 0.315643 loss)
I0526 05:34:08.898260 15394 sgd_solver.cpp:43] Iteration 17080, lr = 0.02
I0526 05:34:20.460752 15394 main.cpp:354] Iteration 17090, loss = 0.566963
I0526 05:34:20.460796 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.566963 (* 1 = 0.566963 loss)
I0526 05:34:20.460819 15394 sgd_solver.cpp:43] Iteration 17090, lr = 0.02
I0526 05:34:31.457406 15394 main.cpp:465] Iteration 17100, Testing net (#0)
I0526 05:35:02.037765 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7915
I0526 05:35:02.037804 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.621203 (* 1 = 0.621203 loss)
I0526 05:35:03.241565 15394 main.cpp:354] Iteration 17100, loss = 0.316858
I0526 05:35:03.241610 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.316858 (* 1 = 0.316858 loss)
I0526 05:35:03.241618 15394 sgd_solver.cpp:43] Iteration 17100, lr = 0.02
I0526 05:35:14.577322 15394 main.cpp:354] Iteration 17110, loss = 0.442475
I0526 05:35:14.577368 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.442475 (* 1 = 0.442475 loss)
I0526 05:35:14.577375 15394 sgd_solver.cpp:43] Iteration 17110, lr = 0.02
I0526 05:35:26.050096 15394 main.cpp:354] Iteration 17120, loss = 0.69688
I0526 05:35:26.050132 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.69688 (* 1 = 0.69688 loss)
I0526 05:35:26.050138 15394 sgd_solver.cpp:43] Iteration 17120, lr = 0.02
I0526 05:35:37.253906 15394 main.cpp:354] Iteration 17130, loss = 0.529584
I0526 05:35:37.253950 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.529584 (* 1 = 0.529584 loss)
I0526 05:35:37.253957 15394 sgd_solver.cpp:43] Iteration 17130, lr = 0.02
I0526 05:35:48.348567 15394 main.cpp:354] Iteration 17140, loss = 0.411489
I0526 05:35:48.348613 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.411489 (* 1 = 0.411489 loss)
I0526 05:35:48.348619 15394 sgd_solver.cpp:43] Iteration 17140, lr = 0.02
I0526 05:35:59.457576 15394 main.cpp:354] Iteration 17150, loss = 0.488192
I0526 05:35:59.457615 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.488192 (* 1 = 0.488192 loss)
I0526 05:35:59.457623 15394 sgd_solver.cpp:43] Iteration 17150, lr = 0.02
I0526 05:36:11.166371 15394 main.cpp:354] Iteration 17160, loss = 0.438392
I0526 05:36:11.166412 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.438392 (* 1 = 0.438392 loss)
I0526 05:36:11.166419 15394 sgd_solver.cpp:43] Iteration 17160, lr = 0.02
I0526 05:36:22.834640 15394 main.cpp:354] Iteration 17170, loss = 0.429798
I0526 05:36:22.834686 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.429798 (* 1 = 0.429798 loss)
I0526 05:36:22.834694 15394 sgd_solver.cpp:43] Iteration 17170, lr = 0.02
I0526 05:36:33.854722 15394 main.cpp:354] Iteration 17180, loss = 0.527369
I0526 05:36:33.854763 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.527369 (* 1 = 0.527369 loss)
I0526 05:36:33.854769 15394 sgd_solver.cpp:43] Iteration 17180, lr = 0.02
I0526 05:36:44.771180 15394 main.cpp:354] Iteration 17190, loss = 0.364351
I0526 05:36:44.771214 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.364351 (* 1 = 0.364351 loss)
I0526 05:36:44.771219 15394 sgd_solver.cpp:43] Iteration 17190, lr = 0.02
I0526 05:36:55.602402 15394 main.cpp:465] Iteration 17200, Testing net (#0)
I0526 05:37:26.183598 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8467
I0526 05:37:26.183636 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.451648 (* 1 = 0.451648 loss)
I0526 05:37:27.062536 15394 main.cpp:354] Iteration 17200, loss = 0.495996
I0526 05:37:27.062573 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.495996 (* 1 = 0.495996 loss)
I0526 05:37:27.062582 15394 sgd_solver.cpp:43] Iteration 17200, lr = 0.02
I0526 05:37:37.999809 15394 main.cpp:354] Iteration 17210, loss = 0.384182
I0526 05:37:37.999848 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.384182 (* 1 = 0.384182 loss)
I0526 05:37:37.999855 15394 sgd_solver.cpp:43] Iteration 17210, lr = 0.02
I0526 05:37:49.684043 15394 main.cpp:354] Iteration 17220, loss = 0.337295
I0526 05:37:49.684084 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.337295 (* 1 = 0.337295 loss)
I0526 05:37:49.684090 15394 sgd_solver.cpp:43] Iteration 17220, lr = 0.02
I0526 05:38:01.514989 15394 main.cpp:354] Iteration 17230, loss = 0.210307
I0526 05:38:01.515029 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.210307 (* 1 = 0.210307 loss)
I0526 05:38:01.515036 15394 sgd_solver.cpp:43] Iteration 17230, lr = 0.02
I0526 05:38:12.652433 15394 main.cpp:354] Iteration 17240, loss = 0.363426
I0526 05:38:12.652473 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.363426 (* 1 = 0.363426 loss)
I0526 05:38:12.652479 15394 sgd_solver.cpp:43] Iteration 17240, lr = 0.02
I0526 05:38:23.899155 15394 main.cpp:354] Iteration 17250, loss = 0.383846
I0526 05:38:23.899200 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.383846 (* 1 = 0.383846 loss)
I0526 05:38:23.899209 15394 sgd_solver.cpp:43] Iteration 17250, lr = 0.02
I0526 05:38:35.416946 15394 main.cpp:354] Iteration 17260, loss = 0.550065
I0526 05:38:35.416987 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.550065 (* 1 = 0.550065 loss)
I0526 05:38:35.416995 15394 sgd_solver.cpp:43] Iteration 17260, lr = 0.02
I0526 05:38:47.704099 15394 main.cpp:354] Iteration 17270, loss = 0.518927
I0526 05:38:47.704147 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.518927 (* 1 = 0.518927 loss)
I0526 05:38:47.704156 15394 sgd_solver.cpp:43] Iteration 17270, lr = 0.02
I0526 05:38:59.590011 15394 main.cpp:354] Iteration 17280, loss = 0.269467
I0526 05:38:59.590050 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.269467 (* 1 = 0.269467 loss)
I0526 05:38:59.590057 15394 sgd_solver.cpp:43] Iteration 17280, lr = 0.02
I0526 05:39:11.654988 15394 main.cpp:354] Iteration 17290, loss = 0.244205
I0526 05:39:11.655028 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.244205 (* 1 = 0.244205 loss)
I0526 05:39:11.655035 15394 sgd_solver.cpp:43] Iteration 17290, lr = 0.02
I0526 05:39:22.151911 15394 main.cpp:465] Iteration 17300, Testing net (#0)
I0526 05:39:52.643184 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7934
I0526 05:39:52.643230 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.61338 (* 1 = 0.61338 loss)
I0526 05:39:53.441293 15394 main.cpp:354] Iteration 17300, loss = 0.563762
I0526 05:39:53.441334 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.563762 (* 1 = 0.563762 loss)
I0526 05:39:53.441344 15394 sgd_solver.cpp:43] Iteration 17300, lr = 0.02
I0526 05:40:04.697736 15394 main.cpp:354] Iteration 17310, loss = 0.517407
I0526 05:40:04.697782 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.517407 (* 1 = 0.517407 loss)
I0526 05:40:04.697790 15394 sgd_solver.cpp:43] Iteration 17310, lr = 0.02
I0526 05:40:14.865274 15394 main.cpp:354] Iteration 17320, loss = 0.426569
I0526 05:40:14.865317 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.426569 (* 1 = 0.426569 loss)
I0526 05:40:14.865325 15394 sgd_solver.cpp:43] Iteration 17320, lr = 0.02
I0526 05:40:26.400703 15394 main.cpp:354] Iteration 17330, loss = 0.42522
I0526 05:40:26.400740 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.42522 (* 1 = 0.42522 loss)
I0526 05:40:26.400748 15394 sgd_solver.cpp:43] Iteration 17330, lr = 0.02
I0526 05:40:38.107009 15394 main.cpp:354] Iteration 17340, loss = 0.433999
I0526 05:40:38.107054 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.433999 (* 1 = 0.433999 loss)
I0526 05:40:38.107062 15394 sgd_solver.cpp:43] Iteration 17340, lr = 0.02
I0526 05:40:49.616118 15394 main.cpp:354] Iteration 17350, loss = 0.26694
I0526 05:40:49.616160 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.26694 (* 1 = 0.26694 loss)
I0526 05:40:49.616168 15394 sgd_solver.cpp:43] Iteration 17350, lr = 0.02
I0526 05:41:00.329044 15394 main.cpp:354] Iteration 17360, loss = 0.339634
I0526 05:41:00.329088 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.339634 (* 1 = 0.339634 loss)
I0526 05:41:00.329094 15394 sgd_solver.cpp:43] Iteration 17360, lr = 0.02
I0526 05:41:11.830802 15394 main.cpp:354] Iteration 17370, loss = 0.399268
I0526 05:41:11.830842 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.399268 (* 1 = 0.399268 loss)
I0526 05:41:11.830849 15394 sgd_solver.cpp:43] Iteration 17370, lr = 0.02
I0526 05:41:23.175526 15394 main.cpp:354] Iteration 17380, loss = 0.390051
I0526 05:41:23.175567 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.390051 (* 1 = 0.390051 loss)
I0526 05:41:23.175575 15394 sgd_solver.cpp:43] Iteration 17380, lr = 0.02
I0526 05:41:34.976686 15394 main.cpp:354] Iteration 17390, loss = 0.418745
I0526 05:41:34.976730 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.418745 (* 1 = 0.418745 loss)
I0526 05:41:34.976737 15394 sgd_solver.cpp:43] Iteration 17390, lr = 0.02
I0526 05:41:44.993784 15394 main.cpp:465] Iteration 17400, Testing net (#0)
I0526 05:42:15.528586 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7777
I0526 05:42:15.528623 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.67334 (* 1 = 0.67334 loss)
I0526 05:42:16.650897 15394 main.cpp:354] Iteration 17400, loss = 0.301017
I0526 05:42:16.650939 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.301017 (* 1 = 0.301017 loss)
I0526 05:42:16.650948 15394 sgd_solver.cpp:43] Iteration 17400, lr = 0.02
I0526 05:42:27.711556 15394 main.cpp:354] Iteration 17410, loss = 0.401863
I0526 05:42:27.711593 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.401863 (* 1 = 0.401863 loss)
I0526 05:42:27.711601 15394 sgd_solver.cpp:43] Iteration 17410, lr = 0.02
I0526 05:42:39.730387 15394 main.cpp:354] Iteration 17420, loss = 0.527653
I0526 05:42:39.730432 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.527653 (* 1 = 0.527653 loss)
I0526 05:42:39.730439 15394 sgd_solver.cpp:43] Iteration 17420, lr = 0.02
I0526 05:42:51.398108 15394 main.cpp:354] Iteration 17430, loss = 0.336501
I0526 05:42:51.398154 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.336501 (* 1 = 0.336501 loss)
I0526 05:42:51.398160 15394 sgd_solver.cpp:43] Iteration 17430, lr = 0.02
I0526 05:43:02.999097 15394 main.cpp:354] Iteration 17440, loss = 0.291156
I0526 05:43:02.999140 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.291156 (* 1 = 0.291156 loss)
I0526 05:43:02.999146 15394 sgd_solver.cpp:43] Iteration 17440, lr = 0.02
I0526 05:43:14.694600 15394 main.cpp:354] Iteration 17450, loss = 0.439782
I0526 05:43:14.694643 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.439782 (* 1 = 0.439782 loss)
I0526 05:43:14.694649 15394 sgd_solver.cpp:43] Iteration 17450, lr = 0.02
I0526 05:43:25.517313 15394 main.cpp:354] Iteration 17460, loss = 0.415411
I0526 05:43:25.517354 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.415411 (* 1 = 0.415411 loss)
I0526 05:43:25.517359 15394 sgd_solver.cpp:43] Iteration 17460, lr = 0.02
I0526 05:43:36.255045 15394 main.cpp:354] Iteration 17470, loss = 0.305022
I0526 05:43:36.255087 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.305022 (* 1 = 0.305022 loss)
I0526 05:43:36.255095 15394 sgd_solver.cpp:43] Iteration 17470, lr = 0.02
I0526 05:43:47.366442 15394 main.cpp:354] Iteration 17480, loss = 0.344734
I0526 05:43:47.366487 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.344734 (* 1 = 0.344734 loss)
I0526 05:43:47.366494 15394 sgd_solver.cpp:43] Iteration 17480, lr = 0.02
I0526 05:43:59.243738 15394 main.cpp:354] Iteration 17490, loss = 0.32458
I0526 05:43:59.243794 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.32458 (* 1 = 0.32458 loss)
I0526 05:43:59.243814 15394 sgd_solver.cpp:43] Iteration 17490, lr = 0.02
I0526 05:44:09.972954 15394 main.cpp:465] Iteration 17500, Testing net (#0)
I0526 05:44:40.511613 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7492
I0526 05:44:40.511639 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.78766 (* 1 = 0.78766 loss)
I0526 05:44:41.689565 15394 main.cpp:354] Iteration 17500, loss = 0.226639
I0526 05:44:41.689607 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.226639 (* 1 = 0.226639 loss)
I0526 05:44:41.689622 15394 sgd_solver.cpp:43] Iteration 17500, lr = 0.02
I0526 05:44:53.383772 15394 main.cpp:354] Iteration 17510, loss = 0.395076
I0526 05:44:53.383806 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.395076 (* 1 = 0.395076 loss)
I0526 05:44:53.383815 15394 sgd_solver.cpp:43] Iteration 17510, lr = 0.02
I0526 05:45:04.624915 15394 main.cpp:354] Iteration 17520, loss = 0.323376
I0526 05:45:04.624960 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.323376 (* 1 = 0.323376 loss)
I0526 05:45:04.624968 15394 sgd_solver.cpp:43] Iteration 17520, lr = 0.02
I0526 05:45:15.515815 15394 main.cpp:354] Iteration 17530, loss = 0.464271
I0526 05:45:15.515856 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.464271 (* 1 = 0.464271 loss)
I0526 05:45:15.515863 15394 sgd_solver.cpp:43] Iteration 17530, lr = 0.02
I0526 05:45:26.985533 15394 main.cpp:354] Iteration 17540, loss = 0.322998
I0526 05:45:26.985574 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.322998 (* 1 = 0.322998 loss)
I0526 05:45:26.985581 15394 sgd_solver.cpp:43] Iteration 17540, lr = 0.02
I0526 05:45:38.201974 15394 main.cpp:354] Iteration 17550, loss = 0.507224
I0526 05:45:38.202005 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.507224 (* 1 = 0.507224 loss)
I0526 05:45:38.202013 15394 sgd_solver.cpp:43] Iteration 17550, lr = 0.02
I0526 05:45:50.689767 15394 main.cpp:354] Iteration 17560, loss = 0.481852
I0526 05:45:50.689798 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.481852 (* 1 = 0.481852 loss)
I0526 05:45:50.689805 15394 sgd_solver.cpp:43] Iteration 17560, lr = 0.02
I0526 05:46:02.187608 15394 main.cpp:354] Iteration 17570, loss = 0.308137
I0526 05:46:02.187650 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.308137 (* 1 = 0.308137 loss)
I0526 05:46:02.187657 15394 sgd_solver.cpp:43] Iteration 17570, lr = 0.02
I0526 05:46:13.555583 15394 main.cpp:354] Iteration 17580, loss = 0.596219
I0526 05:46:13.555627 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.596219 (* 1 = 0.596219 loss)
I0526 05:46:13.555635 15394 sgd_solver.cpp:43] Iteration 17580, lr = 0.02
I0526 05:46:24.607983 15394 main.cpp:354] Iteration 17590, loss = 0.388493
I0526 05:46:24.608026 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.388493 (* 1 = 0.388493 loss)
I0526 05:46:24.608032 15394 sgd_solver.cpp:43] Iteration 17590, lr = 0.02
I0526 05:46:35.353705 15394 main.cpp:465] Iteration 17600, Testing net (#0)
I0526 05:47:05.807374 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7932
I0526 05:47:05.807413 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.603211 (* 1 = 0.603211 loss)
I0526 05:47:07.002197 15394 main.cpp:354] Iteration 17600, loss = 0.206895
I0526 05:47:07.002228 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206895 (* 1 = 0.206895 loss)
I0526 05:47:07.002236 15394 sgd_solver.cpp:43] Iteration 17600, lr = 0.02
I0526 05:47:18.314827 15394 main.cpp:354] Iteration 17610, loss = 0.494349
I0526 05:47:18.314894 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.494349 (* 1 = 0.494349 loss)
I0526 05:47:18.314901 15394 sgd_solver.cpp:43] Iteration 17610, lr = 0.02
I0526 05:47:29.706639 15394 main.cpp:354] Iteration 17620, loss = 0.404694
I0526 05:47:29.706681 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.404694 (* 1 = 0.404694 loss)
I0526 05:47:29.706698 15394 sgd_solver.cpp:43] Iteration 17620, lr = 0.02
I0526 05:47:41.637753 15394 main.cpp:354] Iteration 17630, loss = 0.37921
I0526 05:47:41.637799 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.37921 (* 1 = 0.37921 loss)
I0526 05:47:41.637806 15394 sgd_solver.cpp:43] Iteration 17630, lr = 0.02
I0526 05:47:51.993497 15394 main.cpp:354] Iteration 17640, loss = 0.432965
I0526 05:47:51.993537 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.432965 (* 1 = 0.432965 loss)
I0526 05:47:51.993544 15394 sgd_solver.cpp:43] Iteration 17640, lr = 0.02
I0526 05:48:02.659472 15394 main.cpp:354] Iteration 17650, loss = 0.402823
I0526 05:48:02.659513 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.402823 (* 1 = 0.402823 loss)
I0526 05:48:02.659520 15394 sgd_solver.cpp:43] Iteration 17650, lr = 0.02
I0526 05:48:14.580847 15394 main.cpp:354] Iteration 17660, loss = 0.490899
I0526 05:48:14.580888 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.490899 (* 1 = 0.490899 loss)
I0526 05:48:14.580895 15394 sgd_solver.cpp:43] Iteration 17660, lr = 0.02
I0526 05:48:26.368435 15394 main.cpp:354] Iteration 17670, loss = 0.458935
I0526 05:48:26.368474 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.458935 (* 1 = 0.458935 loss)
I0526 05:48:26.368479 15394 sgd_solver.cpp:43] Iteration 17670, lr = 0.02
I0526 05:48:36.832095 15394 main.cpp:354] Iteration 17680, loss = 0.416543
I0526 05:48:36.832140 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.416543 (* 1 = 0.416543 loss)
I0526 05:48:36.832147 15394 sgd_solver.cpp:43] Iteration 17680, lr = 0.02
I0526 05:48:48.091851 15394 main.cpp:354] Iteration 17690, loss = 0.339167
I0526 05:48:48.091893 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.339167 (* 1 = 0.339167 loss)
I0526 05:48:48.091902 15394 sgd_solver.cpp:43] Iteration 17690, lr = 0.02
I0526 05:48:58.173312 15394 main.cpp:465] Iteration 17700, Testing net (#0)
I0526 05:49:28.710777 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8091
I0526 05:49:28.710821 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.554323 (* 1 = 0.554323 loss)
I0526 05:49:29.793181 15394 main.cpp:354] Iteration 17700, loss = 0.565396
I0526 05:49:29.793220 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.565396 (* 1 = 0.565396 loss)
I0526 05:49:29.793228 15394 sgd_solver.cpp:43] Iteration 17700, lr = 0.02
I0526 05:49:42.370412 15394 main.cpp:354] Iteration 17710, loss = 0.450549
I0526 05:49:42.370450 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.450549 (* 1 = 0.450549 loss)
I0526 05:49:42.370457 15394 sgd_solver.cpp:43] Iteration 17710, lr = 0.02
I0526 05:49:53.450320 15394 main.cpp:354] Iteration 17720, loss = 1.19075
I0526 05:49:53.450363 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.19075 (* 1 = 1.19075 loss)
I0526 05:49:53.450371 15394 sgd_solver.cpp:43] Iteration 17720, lr = 0.02
I0526 05:50:05.566222 15394 main.cpp:354] Iteration 17730, loss = 0.26077
I0526 05:50:05.566263 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.26077 (* 1 = 0.26077 loss)
I0526 05:50:05.566282 15394 sgd_solver.cpp:43] Iteration 17730, lr = 0.02
I0526 05:50:16.561172 15394 main.cpp:354] Iteration 17740, loss = 0.445136
I0526 05:50:16.561215 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.445136 (* 1 = 0.445136 loss)
I0526 05:50:16.561221 15394 sgd_solver.cpp:43] Iteration 17740, lr = 0.02
I0526 05:50:27.847002 15394 main.cpp:354] Iteration 17750, loss = 0.345947
I0526 05:50:27.847040 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.345947 (* 1 = 0.345947 loss)
I0526 05:50:27.847046 15394 sgd_solver.cpp:43] Iteration 17750, lr = 0.02
I0526 05:50:39.121703 15394 main.cpp:354] Iteration 17760, loss = 0.95399
I0526 05:50:39.121747 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.95399 (* 1 = 0.95399 loss)
I0526 05:50:39.121763 15394 sgd_solver.cpp:43] Iteration 17760, lr = 0.02
I0526 05:50:50.443191 15394 main.cpp:354] Iteration 17770, loss = 0.448366
I0526 05:50:50.443230 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.448366 (* 1 = 0.448366 loss)
I0526 05:50:50.443238 15394 sgd_solver.cpp:43] Iteration 17770, lr = 0.02
I0526 05:51:02.006624 15394 main.cpp:354] Iteration 17780, loss = 0.478327
I0526 05:51:02.006657 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.478327 (* 1 = 0.478327 loss)
I0526 05:51:02.006665 15394 sgd_solver.cpp:43] Iteration 17780, lr = 0.02
I0526 05:51:12.788007 15394 main.cpp:354] Iteration 17790, loss = 0.380938
I0526 05:51:12.788046 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.380938 (* 1 = 0.380938 loss)
I0526 05:51:12.788058 15394 sgd_solver.cpp:43] Iteration 17790, lr = 0.02
I0526 05:51:23.246520 15394 main.cpp:465] Iteration 17800, Testing net (#0)
I0526 05:51:53.711004 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7981
I0526 05:51:53.711045 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.581873 (* 1 = 0.581873 loss)
I0526 05:51:54.764734 15394 main.cpp:354] Iteration 17800, loss = 0.42241
I0526 05:51:54.764773 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.42241 (* 1 = 0.42241 loss)
I0526 05:51:54.764782 15394 sgd_solver.cpp:43] Iteration 17800, lr = 0.02
I0526 05:52:05.844240 15394 main.cpp:354] Iteration 17810, loss = 0.397321
I0526 05:52:05.844292 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.397321 (* 1 = 0.397321 loss)
I0526 05:52:05.844298 15394 sgd_solver.cpp:43] Iteration 17810, lr = 0.02
I0526 05:52:16.999061 15394 main.cpp:354] Iteration 17820, loss = 0.335461
I0526 05:52:16.999102 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.335461 (* 1 = 0.335461 loss)
I0526 05:52:16.999109 15394 sgd_solver.cpp:43] Iteration 17820, lr = 0.02
I0526 05:52:27.971804 15394 main.cpp:354] Iteration 17830, loss = 0.440291
I0526 05:52:27.971845 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.440291 (* 1 = 0.440291 loss)
I0526 05:52:27.971853 15394 sgd_solver.cpp:43] Iteration 17830, lr = 0.02
I0526 05:52:39.637320 15394 main.cpp:354] Iteration 17840, loss = 0.470385
I0526 05:52:39.637362 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.470385 (* 1 = 0.470385 loss)
I0526 05:52:39.637367 15394 sgd_solver.cpp:43] Iteration 17840, lr = 0.02
I0526 05:52:51.028085 15394 main.cpp:354] Iteration 17850, loss = 0.330082
I0526 05:52:51.028127 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.330082 (* 1 = 0.330082 loss)
I0526 05:52:51.028134 15394 sgd_solver.cpp:43] Iteration 17850, lr = 0.02
I0526 05:53:02.237463 15394 main.cpp:354] Iteration 17860, loss = 0.359382
I0526 05:53:02.237504 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.359382 (* 1 = 0.359382 loss)
I0526 05:53:02.237511 15394 sgd_solver.cpp:43] Iteration 17860, lr = 0.02
I0526 05:53:13.365741 15394 main.cpp:354] Iteration 17870, loss = 0.282616
I0526 05:53:13.365777 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.282616 (* 1 = 0.282616 loss)
I0526 05:53:13.365785 15394 sgd_solver.cpp:43] Iteration 17870, lr = 0.02
I0526 05:53:25.136601 15394 main.cpp:354] Iteration 17880, loss = 0.540553
I0526 05:53:25.136646 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.540553 (* 1 = 0.540553 loss)
I0526 05:53:25.136651 15394 sgd_solver.cpp:43] Iteration 17880, lr = 0.02
I0526 05:53:36.704183 15394 main.cpp:354] Iteration 17890, loss = 0.31189
I0526 05:53:36.704226 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.31189 (* 1 = 0.31189 loss)
I0526 05:53:36.704232 15394 sgd_solver.cpp:43] Iteration 17890, lr = 0.02
I0526 05:53:46.875270 15394 main.cpp:465] Iteration 17900, Testing net (#0)
I0526 05:54:17.320868 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8226
I0526 05:54:17.320912 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.534558 (* 1 = 0.534558 loss)
I0526 05:54:18.449487 15394 main.cpp:354] Iteration 17900, loss = 0.300883
I0526 05:54:18.449528 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.300883 (* 1 = 0.300883 loss)
I0526 05:54:18.449537 15394 sgd_solver.cpp:43] Iteration 17900, lr = 0.02
I0526 05:54:29.944442 15394 main.cpp:354] Iteration 17910, loss = 0.370814
I0526 05:54:29.944484 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.370814 (* 1 = 0.370814 loss)
I0526 05:54:29.944491 15394 sgd_solver.cpp:43] Iteration 17910, lr = 0.02
I0526 05:54:41.267763 15394 main.cpp:354] Iteration 17920, loss = 0.379228
I0526 05:54:41.267814 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.379228 (* 1 = 0.379228 loss)
I0526 05:54:41.267827 15394 sgd_solver.cpp:43] Iteration 17920, lr = 0.02
I0526 05:54:53.145891 15394 main.cpp:354] Iteration 17930, loss = 0.507747
I0526 05:54:53.145933 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.507747 (* 1 = 0.507747 loss)
I0526 05:54:53.145941 15394 sgd_solver.cpp:43] Iteration 17930, lr = 0.02
I0526 05:55:04.633985 15394 main.cpp:354] Iteration 17940, loss = 0.343322
I0526 05:55:04.634026 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.343322 (* 1 = 0.343322 loss)
I0526 05:55:04.634033 15394 sgd_solver.cpp:43] Iteration 17940, lr = 0.02
I0526 05:55:15.782475 15394 main.cpp:354] Iteration 17950, loss = 0.348063
I0526 05:55:15.782524 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.348063 (* 1 = 0.348063 loss)
I0526 05:55:15.782534 15394 sgd_solver.cpp:43] Iteration 17950, lr = 0.02
I0526 05:55:26.915825 15394 main.cpp:354] Iteration 17960, loss = 0.308244
I0526 05:55:26.915880 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.308244 (* 1 = 0.308244 loss)
I0526 05:55:26.915889 15394 sgd_solver.cpp:43] Iteration 17960, lr = 0.02
I0526 05:55:38.210870 15394 main.cpp:354] Iteration 17970, loss = 0.324979
I0526 05:55:38.210911 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.324979 (* 1 = 0.324979 loss)
I0526 05:55:38.210918 15394 sgd_solver.cpp:43] Iteration 17970, lr = 0.02
I0526 05:55:49.793505 15394 main.cpp:354] Iteration 17980, loss = 0.525091
I0526 05:55:49.793560 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.525091 (* 1 = 0.525091 loss)
I0526 05:55:49.793566 15394 sgd_solver.cpp:43] Iteration 17980, lr = 0.02
I0526 05:56:00.928274 15394 main.cpp:354] Iteration 17990, loss = 0.315697
I0526 05:56:00.928314 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.315697 (* 1 = 0.315697 loss)
I0526 05:56:00.928321 15394 sgd_solver.cpp:43] Iteration 17990, lr = 0.02
I0526 05:56:11.208956 15394 main.cpp:465] Iteration 18000, Testing net (#0)
I0526 05:56:41.756793 15394 main.cpp:532]     Test net output #0: Accuracy = 0.684
I0526 05:56:41.756837 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.10248 (* 1 = 1.10248 loss)
I0526 05:56:42.934459 15394 main.cpp:354] Iteration 18000, loss = 0.414233
I0526 05:56:42.934514 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.414233 (* 1 = 0.414233 loss)
I0526 05:56:42.934525 15394 sgd_solver.cpp:43] Iteration 18000, lr = 0.02
I0526 05:56:53.769606 15394 main.cpp:354] Iteration 18010, loss = 0.360036
I0526 05:56:53.769647 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.360036 (* 1 = 0.360036 loss)
I0526 05:56:53.769654 15394 sgd_solver.cpp:43] Iteration 18010, lr = 0.02
I0526 05:57:05.718739 15394 main.cpp:354] Iteration 18020, loss = 0.408535
I0526 05:57:05.718780 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.408534 (* 1 = 0.408534 loss)
I0526 05:57:05.718786 15394 sgd_solver.cpp:43] Iteration 18020, lr = 0.02
I0526 05:57:17.584645 15394 main.cpp:354] Iteration 18030, loss = 0.510492
I0526 05:57:17.584692 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.510492 (* 1 = 0.510492 loss)
I0526 05:57:17.584698 15394 sgd_solver.cpp:43] Iteration 18030, lr = 0.02
I0526 05:57:28.818428 15394 main.cpp:354] Iteration 18040, loss = 0.356373
I0526 05:57:28.818460 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.356373 (* 1 = 0.356373 loss)
I0526 05:57:28.818469 15394 sgd_solver.cpp:43] Iteration 18040, lr = 0.02
I0526 05:57:39.950135 15394 main.cpp:354] Iteration 18050, loss = 0.471808
I0526 05:57:39.950172 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.471808 (* 1 = 0.471808 loss)
I0526 05:57:39.950178 15394 sgd_solver.cpp:43] Iteration 18050, lr = 0.02
I0526 05:57:51.561635 15394 main.cpp:354] Iteration 18060, loss = 0.600176
I0526 05:57:51.561681 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.600176 (* 1 = 0.600176 loss)
I0526 05:57:51.561687 15394 sgd_solver.cpp:43] Iteration 18060, lr = 0.02
I0526 05:58:03.270262 15394 main.cpp:354] Iteration 18070, loss = 0.484451
I0526 05:58:03.270310 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.484451 (* 1 = 0.484451 loss)
I0526 05:58:03.270318 15394 sgd_solver.cpp:43] Iteration 18070, lr = 0.02
I0526 05:58:14.832651 15394 main.cpp:354] Iteration 18080, loss = 0.481478
I0526 05:58:14.832696 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.481478 (* 1 = 0.481478 loss)
I0526 05:58:14.832703 15394 sgd_solver.cpp:43] Iteration 18080, lr = 0.02
I0526 05:58:26.392921 15394 main.cpp:354] Iteration 18090, loss = 0.302921
I0526 05:58:26.392953 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.302921 (* 1 = 0.302921 loss)
I0526 05:58:26.392961 15394 sgd_solver.cpp:43] Iteration 18090, lr = 0.02
I0526 05:58:36.678572 15394 main.cpp:465] Iteration 18100, Testing net (#0)
I0526 05:59:07.095561 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7598
I0526 05:59:07.095604 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.745676 (* 1 = 0.745676 loss)
I0526 05:59:08.042294 15394 main.cpp:354] Iteration 18100, loss = 0.367376
I0526 05:59:08.042341 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.367376 (* 1 = 0.367376 loss)
I0526 05:59:08.042349 15394 sgd_solver.cpp:43] Iteration 18100, lr = 0.02
I0526 05:59:19.663105 15394 main.cpp:354] Iteration 18110, loss = 0.434614
I0526 05:59:19.663142 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.434614 (* 1 = 0.434614 loss)
I0526 05:59:19.663151 15394 sgd_solver.cpp:43] Iteration 18110, lr = 0.02
I0526 05:59:30.040323 15394 main.cpp:354] Iteration 18120, loss = 0.400514
I0526 05:59:30.040352 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.400514 (* 1 = 0.400514 loss)
I0526 05:59:30.040359 15394 sgd_solver.cpp:43] Iteration 18120, lr = 0.02
I0526 05:59:41.892683 15394 main.cpp:354] Iteration 18130, loss = 0.34967
I0526 05:59:41.892724 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.34967 (* 1 = 0.34967 loss)
I0526 05:59:41.892730 15394 sgd_solver.cpp:43] Iteration 18130, lr = 0.02
I0526 05:59:53.075731 15394 main.cpp:354] Iteration 18140, loss = 0.528165
I0526 05:59:53.075775 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.528165 (* 1 = 0.528165 loss)
I0526 05:59:53.075783 15394 sgd_solver.cpp:43] Iteration 18140, lr = 0.02
I0526 06:00:04.834878 15394 main.cpp:354] Iteration 18150, loss = 0.289226
I0526 06:00:04.834918 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.289226 (* 1 = 0.289226 loss)
I0526 06:00:04.834924 15394 sgd_solver.cpp:43] Iteration 18150, lr = 0.02
I0526 06:00:15.782308 15394 main.cpp:354] Iteration 18160, loss = 0.493027
I0526 06:00:15.782349 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.493027 (* 1 = 0.493027 loss)
I0526 06:00:15.782361 15394 sgd_solver.cpp:43] Iteration 18160, lr = 0.02
I0526 06:00:27.638860 15394 main.cpp:354] Iteration 18170, loss = 0.464864
I0526 06:00:27.638903 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.464864 (* 1 = 0.464864 loss)
I0526 06:00:27.638911 15394 sgd_solver.cpp:43] Iteration 18170, lr = 0.02
I0526 06:00:38.608978 15394 main.cpp:354] Iteration 18180, loss = 0.59236
I0526 06:00:38.609019 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.59236 (* 1 = 0.59236 loss)
I0526 06:00:38.609026 15394 sgd_solver.cpp:43] Iteration 18180, lr = 0.02
I0526 06:00:50.120313 15394 main.cpp:354] Iteration 18190, loss = 0.361549
I0526 06:00:50.120362 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.361549 (* 1 = 0.361549 loss)
I0526 06:00:50.120369 15394 sgd_solver.cpp:43] Iteration 18190, lr = 0.02
I0526 06:01:00.385478 15394 main.cpp:465] Iteration 18200, Testing net (#0)
I0526 06:01:30.885061 15394 main.cpp:532]     Test net output #0: Accuracy = 0.741
I0526 06:01:30.885104 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.791103 (* 1 = 0.791103 loss)
I0526 06:01:32.160959 15394 main.cpp:354] Iteration 18200, loss = 0.266246
I0526 06:01:32.161000 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.266246 (* 1 = 0.266246 loss)
I0526 06:01:32.161015 15394 sgd_solver.cpp:43] Iteration 18200, lr = 0.02
I0526 06:01:43.013155 15394 main.cpp:354] Iteration 18210, loss = 0.420879
I0526 06:01:43.013218 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.420879 (* 1 = 0.420879 loss)
I0526 06:01:43.013226 15394 sgd_solver.cpp:43] Iteration 18210, lr = 0.02
I0526 06:01:54.190992 15394 main.cpp:354] Iteration 18220, loss = 0.556704
I0526 06:01:54.191035 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.556704 (* 1 = 0.556704 loss)
I0526 06:01:54.191041 15394 sgd_solver.cpp:43] Iteration 18220, lr = 0.02
I0526 06:02:05.616077 15394 main.cpp:354] Iteration 18230, loss = 0.358581
I0526 06:02:05.616119 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.358581 (* 1 = 0.358581 loss)
I0526 06:02:05.616125 15394 sgd_solver.cpp:43] Iteration 18230, lr = 0.02
I0526 06:02:17.206789 15394 main.cpp:354] Iteration 18240, loss = 0.39975
I0526 06:02:17.206830 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.39975 (* 1 = 0.39975 loss)
I0526 06:02:17.206837 15394 sgd_solver.cpp:43] Iteration 18240, lr = 0.02
I0526 06:02:28.539083 15394 main.cpp:354] Iteration 18250, loss = 0.5855
I0526 06:02:28.539127 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.5855 (* 1 = 0.5855 loss)
I0526 06:02:28.539134 15394 sgd_solver.cpp:43] Iteration 18250, lr = 0.02
I0526 06:02:40.300909 15394 main.cpp:354] Iteration 18260, loss = 0.582902
I0526 06:02:40.300943 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.582902 (* 1 = 0.582902 loss)
I0526 06:02:40.300951 15394 sgd_solver.cpp:43] Iteration 18260, lr = 0.02
I0526 06:02:51.770655 15394 main.cpp:354] Iteration 18270, loss = 0.52819
I0526 06:02:51.770699 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.52819 (* 1 = 0.52819 loss)
I0526 06:02:51.770706 15394 sgd_solver.cpp:43] Iteration 18270, lr = 0.02
I0526 06:03:02.748602 15394 main.cpp:354] Iteration 18280, loss = 0.276073
I0526 06:03:02.748642 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.276073 (* 1 = 0.276073 loss)
I0526 06:03:02.748651 15394 sgd_solver.cpp:43] Iteration 18280, lr = 0.02
I0526 06:03:14.474611 15394 main.cpp:354] Iteration 18290, loss = 0.239669
I0526 06:03:14.474653 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.239669 (* 1 = 0.239669 loss)
I0526 06:03:14.474661 15394 sgd_solver.cpp:43] Iteration 18290, lr = 0.02
I0526 06:03:25.128106 15394 main.cpp:465] Iteration 18300, Testing net (#0)
I0526 06:03:55.588773 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8116
I0526 06:03:55.588810 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.571827 (* 1 = 0.571827 loss)
I0526 06:03:56.649282 15394 main.cpp:354] Iteration 18300, loss = 0.397498
I0526 06:03:56.649314 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.397498 (* 1 = 0.397498 loss)
I0526 06:03:56.649322 15394 sgd_solver.cpp:43] Iteration 18300, lr = 0.02
I0526 06:04:08.628916 15394 main.cpp:354] Iteration 18310, loss = 0.42327
I0526 06:04:08.628958 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.42327 (* 1 = 0.42327 loss)
I0526 06:04:08.628967 15394 sgd_solver.cpp:43] Iteration 18310, lr = 0.02
I0526 06:04:20.578902 15394 main.cpp:354] Iteration 18320, loss = 0.546135
I0526 06:04:20.578944 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.546134 (* 1 = 0.546134 loss)
I0526 06:04:20.578951 15394 sgd_solver.cpp:43] Iteration 18320, lr = 0.02
I0526 06:04:31.727594 15394 main.cpp:354] Iteration 18330, loss = 0.627916
I0526 06:04:31.727638 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.627916 (* 1 = 0.627916 loss)
I0526 06:04:31.727644 15394 sgd_solver.cpp:43] Iteration 18330, lr = 0.02
I0526 06:04:43.302207 15394 main.cpp:354] Iteration 18340, loss = 0.263381
I0526 06:04:43.302256 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.263381 (* 1 = 0.263381 loss)
I0526 06:04:43.302263 15394 sgd_solver.cpp:43] Iteration 18340, lr = 0.02
I0526 06:04:54.619443 15394 main.cpp:354] Iteration 18350, loss = 0.312967
I0526 06:04:54.619483 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.312967 (* 1 = 0.312967 loss)
I0526 06:04:54.619489 15394 sgd_solver.cpp:43] Iteration 18350, lr = 0.02
I0526 06:05:06.160171 15394 main.cpp:354] Iteration 18360, loss = 0.262442
I0526 06:05:06.160209 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.262442 (* 1 = 0.262442 loss)
I0526 06:05:06.160217 15394 sgd_solver.cpp:43] Iteration 18360, lr = 0.02
I0526 06:05:17.226021 15394 main.cpp:354] Iteration 18370, loss = 0.499501
I0526 06:05:17.226061 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.499501 (* 1 = 0.499501 loss)
I0526 06:05:17.226068 15394 sgd_solver.cpp:43] Iteration 18370, lr = 0.02
I0526 06:05:27.975903 15394 main.cpp:354] Iteration 18380, loss = 0.284033
I0526 06:05:27.975940 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.284033 (* 1 = 0.284033 loss)
I0526 06:05:27.975949 15394 sgd_solver.cpp:43] Iteration 18380, lr = 0.02
I0526 06:05:39.449803 15394 main.cpp:354] Iteration 18390, loss = 0.48368
I0526 06:05:39.449849 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.48368 (* 1 = 0.48368 loss)
I0526 06:05:39.449856 15394 sgd_solver.cpp:43] Iteration 18390, lr = 0.02
I0526 06:05:49.527554 15394 main.cpp:465] Iteration 18400, Testing net (#0)
I0526 06:06:20.054500 15394 main.cpp:532]     Test net output #0: Accuracy = 0.807
I0526 06:06:20.054544 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.576636 (* 1 = 0.576636 loss)
I0526 06:06:21.183210 15394 main.cpp:354] Iteration 18400, loss = 0.361835
I0526 06:06:21.183254 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.361835 (* 1 = 0.361835 loss)
I0526 06:06:21.183262 15394 sgd_solver.cpp:43] Iteration 18400, lr = 0.02
I0526 06:06:32.222465 15394 main.cpp:354] Iteration 18410, loss = 0.257087
I0526 06:06:32.222518 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.257087 (* 1 = 0.257087 loss)
I0526 06:06:32.222525 15394 sgd_solver.cpp:43] Iteration 18410, lr = 0.02
I0526 06:06:44.032245 15394 main.cpp:354] Iteration 18420, loss = 0.450339
I0526 06:06:44.032289 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.450339 (* 1 = 0.450339 loss)
I0526 06:06:44.032297 15394 sgd_solver.cpp:43] Iteration 18420, lr = 0.02
I0526 06:06:55.752276 15394 main.cpp:354] Iteration 18430, loss = 0.329007
I0526 06:06:55.752318 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.329007 (* 1 = 0.329007 loss)
I0526 06:06:55.752326 15394 sgd_solver.cpp:43] Iteration 18430, lr = 0.02
I0526 06:07:07.702541 15394 main.cpp:354] Iteration 18440, loss = 0.407279
I0526 06:07:07.702580 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.407279 (* 1 = 0.407279 loss)
I0526 06:07:07.702587 15394 sgd_solver.cpp:43] Iteration 18440, lr = 0.02
I0526 06:07:18.644798 15394 main.cpp:354] Iteration 18450, loss = 0.412933
I0526 06:07:18.644840 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.412933 (* 1 = 0.412933 loss)
I0526 06:07:18.644847 15394 sgd_solver.cpp:43] Iteration 18450, lr = 0.02
I0526 06:07:29.026733 15394 main.cpp:354] Iteration 18460, loss = 0.305118
I0526 06:07:29.026772 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.305118 (* 1 = 0.305118 loss)
I0526 06:07:29.026779 15394 sgd_solver.cpp:43] Iteration 18460, lr = 0.02
I0526 06:07:40.803836 15394 main.cpp:354] Iteration 18470, loss = 0.461905
I0526 06:07:40.803879 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.461905 (* 1 = 0.461905 loss)
I0526 06:07:40.803886 15394 sgd_solver.cpp:43] Iteration 18470, lr = 0.02
I0526 06:07:52.607106 15394 main.cpp:354] Iteration 18480, loss = 0.332851
I0526 06:07:52.607146 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.332851 (* 1 = 0.332851 loss)
I0526 06:07:52.607153 15394 sgd_solver.cpp:43] Iteration 18480, lr = 0.02
I0526 06:08:03.689831 15394 main.cpp:354] Iteration 18490, loss = 0.464103
I0526 06:08:03.689879 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.464103 (* 1 = 0.464103 loss)
I0526 06:08:03.689888 15394 sgd_solver.cpp:43] Iteration 18490, lr = 0.02
I0526 06:08:14.401994 15394 main.cpp:465] Iteration 18500, Testing net (#0)
I0526 06:08:44.915980 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8232
I0526 06:08:44.916021 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.506086 (* 1 = 0.506086 loss)
I0526 06:08:46.109833 15394 main.cpp:354] Iteration 18500, loss = 0.358093
I0526 06:08:46.109875 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.358092 (* 1 = 0.358092 loss)
I0526 06:08:46.109884 15394 sgd_solver.cpp:43] Iteration 18500, lr = 0.02
I0526 06:08:57.430214 15394 main.cpp:354] Iteration 18510, loss = 0.277752
I0526 06:08:57.430274 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.277752 (* 1 = 0.277752 loss)
I0526 06:08:57.430281 15394 sgd_solver.cpp:43] Iteration 18510, lr = 0.02
I0526 06:09:08.921736 15394 main.cpp:354] Iteration 18520, loss = 0.16185
I0526 06:09:08.921777 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.16185 (* 1 = 0.16185 loss)
I0526 06:09:08.921784 15394 sgd_solver.cpp:43] Iteration 18520, lr = 0.02
I0526 06:09:20.234269 15394 main.cpp:354] Iteration 18530, loss = 0.356471
I0526 06:09:20.234316 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.35647 (* 1 = 0.35647 loss)
I0526 06:09:20.234324 15394 sgd_solver.cpp:43] Iteration 18530, lr = 0.02
I0526 06:09:31.687234 15394 main.cpp:354] Iteration 18540, loss = 0.3775
I0526 06:09:31.687278 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.3775 (* 1 = 0.3775 loss)
I0526 06:09:31.687283 15394 sgd_solver.cpp:43] Iteration 18540, lr = 0.02
I0526 06:09:43.671741 15394 main.cpp:354] Iteration 18550, loss = 0.452541
I0526 06:09:43.671780 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.452541 (* 1 = 0.452541 loss)
I0526 06:09:43.671787 15394 sgd_solver.cpp:43] Iteration 18550, lr = 0.02
I0526 06:09:54.597218 15394 main.cpp:354] Iteration 18560, loss = 0.306148
I0526 06:09:54.597262 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.306148 (* 1 = 0.306148 loss)
I0526 06:09:54.597270 15394 sgd_solver.cpp:43] Iteration 18560, lr = 0.02
I0526 06:10:05.598165 15394 main.cpp:354] Iteration 18570, loss = 0.56986
I0526 06:10:05.598208 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.569859 (* 1 = 0.569859 loss)
I0526 06:10:05.598215 15394 sgd_solver.cpp:43] Iteration 18570, lr = 0.02
I0526 06:10:17.140166 15394 main.cpp:354] Iteration 18580, loss = 0.438932
I0526 06:10:17.140194 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.438932 (* 1 = 0.438932 loss)
I0526 06:10:17.140202 15394 sgd_solver.cpp:43] Iteration 18580, lr = 0.02
I0526 06:10:28.523633 15394 main.cpp:354] Iteration 18590, loss = 0.289487
I0526 06:10:28.523675 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.289486 (* 1 = 0.289486 loss)
I0526 06:10:28.523684 15394 sgd_solver.cpp:43] Iteration 18590, lr = 0.02
I0526 06:10:38.528296 15394 main.cpp:465] Iteration 18600, Testing net (#0)
I0526 06:11:09.019438 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7983
I0526 06:11:09.019482 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.603351 (* 1 = 0.603351 loss)
I0526 06:11:10.145885 15394 main.cpp:354] Iteration 18600, loss = 0.56497
I0526 06:11:10.145947 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.564969 (* 1 = 0.564969 loss)
I0526 06:11:10.145956 15394 sgd_solver.cpp:43] Iteration 18600, lr = 0.02
I0526 06:11:21.436928 15394 main.cpp:354] Iteration 18610, loss = 0.410083
I0526 06:11:21.436966 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.410083 (* 1 = 0.410083 loss)
I0526 06:11:21.436974 15394 sgd_solver.cpp:43] Iteration 18610, lr = 0.02
I0526 06:11:31.864792 15394 main.cpp:354] Iteration 18620, loss = 0.483657
I0526 06:11:31.864830 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.483657 (* 1 = 0.483657 loss)
I0526 06:11:31.864841 15394 sgd_solver.cpp:43] Iteration 18620, lr = 0.02
I0526 06:11:42.734477 15394 main.cpp:354] Iteration 18630, loss = 0.354454
I0526 06:11:42.734515 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.354454 (* 1 = 0.354454 loss)
I0526 06:11:42.734522 15394 sgd_solver.cpp:43] Iteration 18630, lr = 0.02
I0526 06:11:54.233925 15394 main.cpp:354] Iteration 18640, loss = 0.305552
I0526 06:11:54.233973 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.305552 (* 1 = 0.305552 loss)
I0526 06:11:54.233980 15394 sgd_solver.cpp:43] Iteration 18640, lr = 0.02
I0526 06:12:05.305907 15394 main.cpp:354] Iteration 18650, loss = 0.355377
I0526 06:12:05.305941 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.355377 (* 1 = 0.355377 loss)
I0526 06:12:05.305949 15394 sgd_solver.cpp:43] Iteration 18650, lr = 0.02
I0526 06:12:16.709451 15394 main.cpp:354] Iteration 18660, loss = 0.385708
I0526 06:12:16.709496 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.385707 (* 1 = 0.385707 loss)
I0526 06:12:16.709501 15394 sgd_solver.cpp:43] Iteration 18660, lr = 0.02
I0526 06:12:28.029235 15394 main.cpp:354] Iteration 18670, loss = 0.525153
I0526 06:12:28.029275 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.525153 (* 1 = 0.525153 loss)
I0526 06:12:28.029283 15394 sgd_solver.cpp:43] Iteration 18670, lr = 0.02
I0526 06:12:39.308552 15394 main.cpp:354] Iteration 18680, loss = 0.2682
I0526 06:12:39.308593 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.2682 (* 1 = 0.2682 loss)
I0526 06:12:39.308600 15394 sgd_solver.cpp:43] Iteration 18680, lr = 0.02
I0526 06:12:51.057250 15394 main.cpp:354] Iteration 18690, loss = 0.346559
I0526 06:12:51.057287 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.346559 (* 1 = 0.346559 loss)
I0526 06:12:51.057294 15394 sgd_solver.cpp:43] Iteration 18690, lr = 0.02
I0526 06:13:01.962622 15394 main.cpp:465] Iteration 18700, Testing net (#0)
I0526 06:13:32.485442 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8293
I0526 06:13:32.485486 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.497503 (* 1 = 0.497503 loss)
I0526 06:13:33.686375 15394 main.cpp:354] Iteration 18700, loss = 0.28651
I0526 06:13:33.686416 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.28651 (* 1 = 0.28651 loss)
I0526 06:13:33.686424 15394 sgd_solver.cpp:43] Iteration 18700, lr = 0.02
I0526 06:13:44.759634 15394 main.cpp:354] Iteration 18710, loss = 0.356653
I0526 06:13:44.759673 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.356653 (* 1 = 0.356653 loss)
I0526 06:13:44.759680 15394 sgd_solver.cpp:43] Iteration 18710, lr = 0.02
I0526 06:13:56.169294 15394 main.cpp:354] Iteration 18720, loss = 0.317728
I0526 06:13:56.169333 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.317728 (* 1 = 0.317728 loss)
I0526 06:13:56.169342 15394 sgd_solver.cpp:43] Iteration 18720, lr = 0.02
I0526 06:14:07.696274 15394 main.cpp:354] Iteration 18730, loss = 0.275147
I0526 06:14:07.696329 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.275147 (* 1 = 0.275147 loss)
I0526 06:14:07.696336 15394 sgd_solver.cpp:43] Iteration 18730, lr = 0.02
I0526 06:14:18.955904 15394 main.cpp:354] Iteration 18740, loss = 0.428143
I0526 06:14:18.955971 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.428143 (* 1 = 0.428143 loss)
I0526 06:14:18.955978 15394 sgd_solver.cpp:43] Iteration 18740, lr = 0.02
I0526 06:14:30.833112 15394 main.cpp:354] Iteration 18750, loss = 0.175482
I0526 06:14:30.833145 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.175482 (* 1 = 0.175482 loss)
I0526 06:14:30.833153 15394 sgd_solver.cpp:43] Iteration 18750, lr = 0.02
I0526 06:14:42.086074 15394 main.cpp:354] Iteration 18760, loss = 0.332264
I0526 06:14:42.086117 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.332264 (* 1 = 0.332264 loss)
I0526 06:14:42.086123 15394 sgd_solver.cpp:43] Iteration 18760, lr = 0.02
I0526 06:14:53.720741 15394 main.cpp:354] Iteration 18770, loss = 0.225963
I0526 06:14:53.720782 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.225963 (* 1 = 0.225963 loss)
I0526 06:14:53.720788 15394 sgd_solver.cpp:43] Iteration 18770, lr = 0.02
I0526 06:15:04.544412 15394 main.cpp:354] Iteration 18780, loss = 0.34204
I0526 06:15:04.544455 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.34204 (* 1 = 0.34204 loss)
I0526 06:15:04.544461 15394 sgd_solver.cpp:43] Iteration 18780, lr = 0.02
I0526 06:15:16.475782 15394 main.cpp:354] Iteration 18790, loss = 0.364874
I0526 06:15:16.475826 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.364874 (* 1 = 0.364874 loss)
I0526 06:15:16.475832 15394 sgd_solver.cpp:43] Iteration 18790, lr = 0.02
I0526 06:15:27.160897 15394 main.cpp:465] Iteration 18800, Testing net (#0)
I0526 06:15:57.758627 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7923
I0526 06:15:57.758667 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.65644 (* 1 = 0.65644 loss)
I0526 06:15:58.964862 15394 main.cpp:354] Iteration 18800, loss = 0.342564
I0526 06:15:58.964902 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.342564 (* 1 = 0.342564 loss)
I0526 06:15:58.964910 15394 sgd_solver.cpp:43] Iteration 18800, lr = 0.02
I0526 06:16:09.296644 15394 main.cpp:354] Iteration 18810, loss = 1.03485
I0526 06:16:09.296708 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.03485 (* 1 = 1.03485 loss)
I0526 06:16:09.296715 15394 sgd_solver.cpp:43] Iteration 18810, lr = 0.02
I0526 06:16:21.231650 15394 main.cpp:354] Iteration 18820, loss = 0.288142
I0526 06:16:21.231700 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.288142 (* 1 = 0.288142 loss)
I0526 06:16:21.231709 15394 sgd_solver.cpp:43] Iteration 18820, lr = 0.02
I0526 06:16:33.004575 15394 main.cpp:354] Iteration 18830, loss = 0.320572
I0526 06:16:33.004621 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.320572 (* 1 = 0.320572 loss)
I0526 06:16:33.004626 15394 sgd_solver.cpp:43] Iteration 18830, lr = 0.02
I0526 06:16:44.503948 15394 main.cpp:354] Iteration 18840, loss = 0.444778
I0526 06:16:44.503978 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.444778 (* 1 = 0.444778 loss)
I0526 06:16:44.503984 15394 sgd_solver.cpp:43] Iteration 18840, lr = 0.02
I0526 06:16:54.847858 15394 main.cpp:354] Iteration 18850, loss = 0.26538
I0526 06:16:54.847903 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.26538 (* 1 = 0.26538 loss)
I0526 06:16:54.847909 15394 sgd_solver.cpp:43] Iteration 18850, lr = 0.02
I0526 06:17:06.706213 15394 main.cpp:354] Iteration 18860, loss = 0.404375
I0526 06:17:06.706255 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.404375 (* 1 = 0.404375 loss)
I0526 06:17:06.706262 15394 sgd_solver.cpp:43] Iteration 18860, lr = 0.02
I0526 06:17:17.962486 15394 main.cpp:354] Iteration 18870, loss = 0.356026
I0526 06:17:17.962548 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.356026 (* 1 = 0.356026 loss)
I0526 06:17:17.962556 15394 sgd_solver.cpp:43] Iteration 18870, lr = 0.02
I0526 06:17:30.280009 15394 main.cpp:354] Iteration 18880, loss = 0.298131
I0526 06:17:30.280047 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.298131 (* 1 = 0.298131 loss)
I0526 06:17:30.280055 15394 sgd_solver.cpp:43] Iteration 18880, lr = 0.02
I0526 06:17:41.946722 15394 main.cpp:354] Iteration 18890, loss = 0.451114
I0526 06:17:41.946763 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.451114 (* 1 = 0.451114 loss)
I0526 06:17:41.946770 15394 sgd_solver.cpp:43] Iteration 18890, lr = 0.02
I0526 06:17:52.075935 15394 main.cpp:465] Iteration 18900, Testing net (#0)
I0526 06:18:22.591081 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7983
I0526 06:18:22.591122 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.602505 (* 1 = 0.602505 loss)
I0526 06:18:23.609933 15394 main.cpp:354] Iteration 18900, loss = 0.385824
I0526 06:18:23.609978 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.385824 (* 1 = 0.385824 loss)
I0526 06:18:23.609993 15394 sgd_solver.cpp:43] Iteration 18900, lr = 0.02
I0526 06:18:34.965481 15394 main.cpp:354] Iteration 18910, loss = 0.516492
I0526 06:18:34.965523 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.516492 (* 1 = 0.516492 loss)
I0526 06:18:34.965530 15394 sgd_solver.cpp:43] Iteration 18910, lr = 0.02
I0526 06:18:46.309315 15394 main.cpp:354] Iteration 18920, loss = 0.613792
I0526 06:18:46.309355 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.613792 (* 1 = 0.613792 loss)
I0526 06:18:46.309362 15394 sgd_solver.cpp:43] Iteration 18920, lr = 0.02
I0526 06:18:57.396303 15394 main.cpp:354] Iteration 18930, loss = 0.500192
I0526 06:18:57.396339 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.500192 (* 1 = 0.500192 loss)
I0526 06:18:57.396345 15394 sgd_solver.cpp:43] Iteration 18930, lr = 0.02
I0526 06:19:08.491672 15394 main.cpp:354] Iteration 18940, loss = 0.631398
I0526 06:19:08.491717 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.631398 (* 1 = 0.631398 loss)
I0526 06:19:08.491725 15394 sgd_solver.cpp:43] Iteration 18940, lr = 0.02
I0526 06:19:19.896226 15394 main.cpp:354] Iteration 18950, loss = 0.587502
I0526 06:19:19.896267 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.587502 (* 1 = 0.587502 loss)
I0526 06:19:19.896275 15394 sgd_solver.cpp:43] Iteration 18950, lr = 0.02
I0526 06:19:31.301045 15394 main.cpp:354] Iteration 18960, loss = 0.379595
I0526 06:19:31.301101 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.379595 (* 1 = 0.379595 loss)
I0526 06:19:31.301108 15394 sgd_solver.cpp:43] Iteration 18960, lr = 0.02
I0526 06:19:42.807101 15394 main.cpp:354] Iteration 18970, loss = 0.405971
I0526 06:19:42.807135 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.405971 (* 1 = 0.405971 loss)
I0526 06:19:42.807143 15394 sgd_solver.cpp:43] Iteration 18970, lr = 0.02
I0526 06:19:54.010002 15394 main.cpp:354] Iteration 18980, loss = 0.288262
I0526 06:19:54.010047 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.288261 (* 1 = 0.288261 loss)
I0526 06:19:54.010054 15394 sgd_solver.cpp:43] Iteration 18980, lr = 0.02
I0526 06:20:06.217464 15394 main.cpp:354] Iteration 18990, loss = 0.489786
I0526 06:20:06.217528 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.489786 (* 1 = 0.489786 loss)
I0526 06:20:06.217535 15394 sgd_solver.cpp:43] Iteration 18990, lr = 0.02
I0526 06:20:16.486469 15394 main.cpp:465] Iteration 19000, Testing net (#0)
I0526 06:20:46.976733 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8407
I0526 06:20:46.976778 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.462658 (* 1 = 0.462658 loss)
I0526 06:20:47.881340 15394 main.cpp:354] Iteration 19000, loss = 0.549337
I0526 06:20:47.881381 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.549337 (* 1 = 0.549337 loss)
I0526 06:20:47.881392 15394 sgd_solver.cpp:43] Iteration 19000, lr = 0.02
I0526 06:21:00.194711 15394 main.cpp:354] Iteration 19010, loss = 0.287304
I0526 06:21:00.194752 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.287304 (* 1 = 0.287304 loss)
I0526 06:21:00.194759 15394 sgd_solver.cpp:43] Iteration 19010, lr = 0.02
I0526 06:21:11.459229 15394 main.cpp:354] Iteration 19020, loss = 0.548846
I0526 06:21:11.459255 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.548846 (* 1 = 0.548846 loss)
I0526 06:21:11.459261 15394 sgd_solver.cpp:43] Iteration 19020, lr = 0.02
I0526 06:21:23.099578 15394 main.cpp:354] Iteration 19030, loss = 0.195966
I0526 06:21:23.099618 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.195966 (* 1 = 0.195966 loss)
I0526 06:21:23.099637 15394 sgd_solver.cpp:43] Iteration 19030, lr = 0.02
I0526 06:21:33.374440 15394 main.cpp:354] Iteration 19040, loss = 1.65222
I0526 06:21:33.374481 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.65222 (* 1 = 1.65222 loss)
I0526 06:21:33.374503 15394 sgd_solver.cpp:43] Iteration 19040, lr = 0.02
I0526 06:21:45.354579 15394 main.cpp:354] Iteration 19050, loss = 0.405238
I0526 06:21:45.354634 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.405238 (* 1 = 0.405238 loss)
I0526 06:21:45.354640 15394 sgd_solver.cpp:43] Iteration 19050, lr = 0.02
I0526 06:21:56.809276 15394 main.cpp:354] Iteration 19060, loss = 0.635876
I0526 06:21:56.809315 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.635876 (* 1 = 0.635876 loss)
I0526 06:21:56.809324 15394 sgd_solver.cpp:43] Iteration 19060, lr = 0.02
I0526 06:22:08.952285 15394 main.cpp:354] Iteration 19070, loss = 0.336275
I0526 06:22:08.952322 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.336275 (* 1 = 0.336275 loss)
I0526 06:22:08.952328 15394 sgd_solver.cpp:43] Iteration 19070, lr = 0.02
I0526 06:22:20.478690 15394 main.cpp:354] Iteration 19080, loss = 0.330277
I0526 06:22:20.478734 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.330277 (* 1 = 0.330277 loss)
I0526 06:22:20.478741 15394 sgd_solver.cpp:43] Iteration 19080, lr = 0.02
I0526 06:22:32.408205 15394 main.cpp:354] Iteration 19090, loss = 0.264267
I0526 06:22:32.408247 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.264266 (* 1 = 0.264266 loss)
I0526 06:22:32.408254 15394 sgd_solver.cpp:43] Iteration 19090, lr = 0.02
I0526 06:22:43.059588 15394 main.cpp:465] Iteration 19100, Testing net (#0)
I0526 06:23:13.628042 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7954
I0526 06:23:13.628096 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.627368 (* 1 = 0.627368 loss)
I0526 06:23:14.920280 15394 main.cpp:354] Iteration 19100, loss = 0.370013
I0526 06:23:14.920325 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.370013 (* 1 = 0.370013 loss)
I0526 06:23:14.920336 15394 sgd_solver.cpp:43] Iteration 19100, lr = 0.02
I0526 06:23:26.458897 15394 main.cpp:354] Iteration 19110, loss = 0.281339
I0526 06:23:26.458936 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.281339 (* 1 = 0.281339 loss)
I0526 06:23:26.458945 15394 sgd_solver.cpp:43] Iteration 19110, lr = 0.02
I0526 06:23:38.307703 15394 main.cpp:354] Iteration 19120, loss = 0.433939
I0526 06:23:38.307742 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.433939 (* 1 = 0.433939 loss)
I0526 06:23:38.307749 15394 sgd_solver.cpp:43] Iteration 19120, lr = 0.02
I0526 06:23:49.344315 15394 main.cpp:354] Iteration 19130, loss = 0.285748
I0526 06:23:49.344360 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.285748 (* 1 = 0.285748 loss)
I0526 06:23:49.344367 15394 sgd_solver.cpp:43] Iteration 19130, lr = 0.02
I0526 06:24:01.553608 15394 main.cpp:354] Iteration 19140, loss = 0.337386
I0526 06:24:01.553650 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.337386 (* 1 = 0.337386 loss)
I0526 06:24:01.553658 15394 sgd_solver.cpp:43] Iteration 19140, lr = 0.02
I0526 06:24:12.286846 15394 main.cpp:354] Iteration 19150, loss = 0.412096
I0526 06:24:12.286882 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.412096 (* 1 = 0.412096 loss)
I0526 06:24:12.286890 15394 sgd_solver.cpp:43] Iteration 19150, lr = 0.02
I0526 06:24:23.858815 15394 main.cpp:354] Iteration 19160, loss = 0.245948
I0526 06:24:23.858856 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.245948 (* 1 = 0.245948 loss)
I0526 06:24:23.858865 15394 sgd_solver.cpp:43] Iteration 19160, lr = 0.02
I0526 06:24:35.366302 15394 main.cpp:354] Iteration 19170, loss = 0.405904
I0526 06:24:35.366343 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.405904 (* 1 = 0.405904 loss)
I0526 06:24:35.366351 15394 sgd_solver.cpp:43] Iteration 19170, lr = 0.02
I0526 06:24:47.238709 15394 main.cpp:354] Iteration 19180, loss = 0.576536
I0526 06:24:47.238739 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.576536 (* 1 = 0.576536 loss)
I0526 06:24:47.238746 15394 sgd_solver.cpp:43] Iteration 19180, lr = 0.02
I0526 06:24:57.711874 15394 main.cpp:354] Iteration 19190, loss = 0.309458
I0526 06:24:57.711916 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.309458 (* 1 = 0.309458 loss)
I0526 06:24:57.711923 15394 sgd_solver.cpp:43] Iteration 19190, lr = 0.02
I0526 06:25:07.669106 15394 main.cpp:465] Iteration 19200, Testing net (#0)
I0526 06:25:38.022235 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8256
I0526 06:25:38.022272 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.5265 (* 1 = 0.5265 loss)
I0526 06:25:39.140086 15394 main.cpp:354] Iteration 19200, loss = 0.275886
I0526 06:25:39.140127 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.275885 (* 1 = 0.275885 loss)
I0526 06:25:39.140136 15394 sgd_solver.cpp:43] Iteration 19200, lr = 0.02
I0526 06:25:51.161780 15394 main.cpp:354] Iteration 19210, loss = 0.370779
I0526 06:25:51.161824 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.370779 (* 1 = 0.370779 loss)
I0526 06:25:51.161831 15394 sgd_solver.cpp:43] Iteration 19210, lr = 0.02
I0526 06:26:02.285158 15394 main.cpp:354] Iteration 19220, loss = 0.481871
I0526 06:26:02.285199 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.481871 (* 1 = 0.481871 loss)
I0526 06:26:02.285207 15394 sgd_solver.cpp:43] Iteration 19220, lr = 0.02
I0526 06:26:13.171087 15394 main.cpp:354] Iteration 19230, loss = 0.336084
I0526 06:26:13.171123 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.336084 (* 1 = 0.336084 loss)
I0526 06:26:13.171130 15394 sgd_solver.cpp:43] Iteration 19230, lr = 0.02
I0526 06:26:24.560964 15394 main.cpp:354] Iteration 19240, loss = 0.323001
I0526 06:26:24.561008 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.323001 (* 1 = 0.323001 loss)
I0526 06:26:24.561017 15394 sgd_solver.cpp:43] Iteration 19240, lr = 0.02
I0526 06:26:36.319191 15394 main.cpp:354] Iteration 19250, loss = 0.325591
I0526 06:26:36.319231 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.325591 (* 1 = 0.325591 loss)
I0526 06:26:36.319237 15394 sgd_solver.cpp:43] Iteration 19250, lr = 0.02
I0526 06:26:47.763211 15394 main.cpp:354] Iteration 19260, loss = 0.352048
I0526 06:26:47.763247 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.352048 (* 1 = 0.352048 loss)
I0526 06:26:47.763254 15394 sgd_solver.cpp:43] Iteration 19260, lr = 0.02
I0526 06:26:58.778429 15394 main.cpp:354] Iteration 19270, loss = 0.49349
I0526 06:26:58.778483 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.49349 (* 1 = 0.49349 loss)
I0526 06:26:58.778492 15394 sgd_solver.cpp:43] Iteration 19270, lr = 0.02
I0526 06:27:10.270174 15394 main.cpp:354] Iteration 19280, loss = 0.272529
I0526 06:27:10.270217 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.272529 (* 1 = 0.272529 loss)
I0526 06:27:10.270225 15394 sgd_solver.cpp:43] Iteration 19280, lr = 0.02
I0526 06:27:20.925160 15394 main.cpp:354] Iteration 19290, loss = 0.593591
I0526 06:27:20.925202 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.593591 (* 1 = 0.593591 loss)
I0526 06:27:20.925209 15394 sgd_solver.cpp:43] Iteration 19290, lr = 0.02
I0526 06:27:31.266021 15394 main.cpp:465] Iteration 19300, Testing net (#0)
I0526 06:28:01.795702 15394 main.cpp:532]     Test net output #0: Accuracy = 0.6714
I0526 06:28:01.795744 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.1364 (* 1 = 1.1364 loss)
I0526 06:28:02.871732 15394 main.cpp:354] Iteration 19300, loss = 0.361927
I0526 06:28:02.871773 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.361927 (* 1 = 0.361927 loss)
I0526 06:28:02.871780 15394 sgd_solver.cpp:43] Iteration 19300, lr = 0.02
I0526 06:28:13.944020 15394 main.cpp:354] Iteration 19310, loss = 0.530312
I0526 06:28:13.944061 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.530312 (* 1 = 0.530312 loss)
I0526 06:28:13.944068 15394 sgd_solver.cpp:43] Iteration 19310, lr = 0.02
I0526 06:28:25.499084 15394 main.cpp:354] Iteration 19320, loss = 0.473732
I0526 06:28:25.499128 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.473732 (* 1 = 0.473732 loss)
I0526 06:28:25.499141 15394 sgd_solver.cpp:43] Iteration 19320, lr = 0.02
I0526 06:28:37.659314 15394 main.cpp:354] Iteration 19330, loss = 0.46064
I0526 06:28:37.659356 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.46064 (* 1 = 0.46064 loss)
I0526 06:28:37.659364 15394 sgd_solver.cpp:43] Iteration 19330, lr = 0.02
I0526 06:28:49.111416 15394 main.cpp:354] Iteration 19340, loss = 0.317932
I0526 06:28:49.111454 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.317932 (* 1 = 0.317932 loss)
I0526 06:28:49.111461 15394 sgd_solver.cpp:43] Iteration 19340, lr = 0.02
I0526 06:29:00.981307 15394 main.cpp:354] Iteration 19350, loss = 0.494466
I0526 06:29:00.981345 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.494466 (* 1 = 0.494466 loss)
I0526 06:29:00.981354 15394 sgd_solver.cpp:43] Iteration 19350, lr = 0.02
I0526 06:29:12.651414 15394 main.cpp:354] Iteration 19360, loss = 0.318316
I0526 06:29:12.651453 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.318316 (* 1 = 0.318316 loss)
I0526 06:29:12.651459 15394 sgd_solver.cpp:43] Iteration 19360, lr = 0.02
I0526 06:29:24.281718 15394 main.cpp:354] Iteration 19370, loss = 0.227537
I0526 06:29:24.281760 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.227537 (* 1 = 0.227537 loss)
I0526 06:29:24.281766 15394 sgd_solver.cpp:43] Iteration 19370, lr = 0.02
I0526 06:29:35.059609 15394 main.cpp:354] Iteration 19380, loss = 0.771458
I0526 06:29:35.059665 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.771458 (* 1 = 0.771458 loss)
I0526 06:29:35.059672 15394 sgd_solver.cpp:43] Iteration 19380, lr = 0.02
I0526 06:29:47.113538 15394 main.cpp:354] Iteration 19390, loss = 0.452888
I0526 06:29:47.113580 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.452887 (* 1 = 0.452887 loss)
I0526 06:29:47.113586 15394 sgd_solver.cpp:43] Iteration 19390, lr = 0.02
I0526 06:29:58.151309 15394 main.cpp:465] Iteration 19400, Testing net (#0)
I0526 06:30:28.614874 15394 main.cpp:532]     Test net output #0: Accuracy = 0.746
I0526 06:30:28.614915 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.738735 (* 1 = 0.738735 loss)
I0526 06:30:29.671607 15394 main.cpp:354] Iteration 19400, loss = 0.481654
I0526 06:30:29.671641 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.481654 (* 1 = 0.481654 loss)
I0526 06:30:29.671650 15394 sgd_solver.cpp:43] Iteration 19400, lr = 0.02
I0526 06:30:41.601863 15394 main.cpp:354] Iteration 19410, loss = 0.236553
I0526 06:30:41.601908 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.236553 (* 1 = 0.236553 loss)
I0526 06:30:41.601915 15394 sgd_solver.cpp:43] Iteration 19410, lr = 0.02
I0526 06:30:52.894500 15394 main.cpp:354] Iteration 19420, loss = 0.270389
I0526 06:30:52.894542 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.270389 (* 1 = 0.270389 loss)
I0526 06:30:52.894549 15394 sgd_solver.cpp:43] Iteration 19420, lr = 0.02
I0526 06:31:04.432605 15394 main.cpp:354] Iteration 19430, loss = 0.563633
I0526 06:31:04.432659 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.563632 (* 1 = 0.563632 loss)
I0526 06:31:04.432667 15394 sgd_solver.cpp:43] Iteration 19430, lr = 0.02
I0526 06:31:15.461861 15394 main.cpp:354] Iteration 19440, loss = 0.282781
I0526 06:31:15.461904 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.282781 (* 1 = 0.282781 loss)
I0526 06:31:15.461910 15394 sgd_solver.cpp:43] Iteration 19440, lr = 0.02
I0526 06:31:27.353298 15394 main.cpp:354] Iteration 19450, loss = 0.340833
I0526 06:31:27.353329 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.340833 (* 1 = 0.340833 loss)
I0526 06:31:27.353337 15394 sgd_solver.cpp:43] Iteration 19450, lr = 0.02
I0526 06:31:39.755991 15394 main.cpp:354] Iteration 19460, loss = 0.452444
I0526 06:31:39.756027 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.452444 (* 1 = 0.452444 loss)
I0526 06:31:39.756034 15394 sgd_solver.cpp:43] Iteration 19460, lr = 0.02
I0526 06:31:51.010392 15394 main.cpp:354] Iteration 19470, loss = 0.287931
I0526 06:31:51.010437 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.287931 (* 1 = 0.287931 loss)
I0526 06:31:51.010455 15394 sgd_solver.cpp:43] Iteration 19470, lr = 0.02
I0526 06:32:01.749125 15394 main.cpp:354] Iteration 19480, loss = 0.736231
I0526 06:32:01.749166 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.736231 (* 1 = 0.736231 loss)
I0526 06:32:01.749172 15394 sgd_solver.cpp:43] Iteration 19480, lr = 0.02
I0526 06:32:13.170091 15394 main.cpp:354] Iteration 19490, loss = 0.383657
I0526 06:32:13.170131 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.383656 (* 1 = 0.383656 loss)
I0526 06:32:13.170138 15394 sgd_solver.cpp:43] Iteration 19490, lr = 0.02
I0526 06:32:24.015990 15394 main.cpp:465] Iteration 19500, Testing net (#0)
I0526 06:32:54.445019 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8137
I0526 06:32:54.445057 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.541711 (* 1 = 0.541711 loss)
I0526 06:32:55.109606 15394 main.cpp:354] Iteration 19500, loss = 0.711316
I0526 06:32:55.109642 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.711316 (* 1 = 0.711316 loss)
I0526 06:32:55.109649 15394 sgd_solver.cpp:43] Iteration 19500, lr = 0.02
I0526 06:33:06.582345 15394 main.cpp:354] Iteration 19510, loss = 0.267609
I0526 06:33:06.582391 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.267609 (* 1 = 0.267609 loss)
I0526 06:33:06.582398 15394 sgd_solver.cpp:43] Iteration 19510, lr = 0.02
I0526 06:33:18.179400 15394 main.cpp:354] Iteration 19520, loss = 0.295651
I0526 06:33:18.179441 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.295651 (* 1 = 0.295651 loss)
I0526 06:33:18.179447 15394 sgd_solver.cpp:43] Iteration 19520, lr = 0.02
I0526 06:33:29.395756 15394 main.cpp:354] Iteration 19530, loss = 0.216625
I0526 06:33:29.395797 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.216625 (* 1 = 0.216625 loss)
I0526 06:33:29.395804 15394 sgd_solver.cpp:43] Iteration 19530, lr = 0.02
I0526 06:33:40.113586 15394 main.cpp:354] Iteration 19540, loss = 0.390156
I0526 06:33:40.113616 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.390156 (* 1 = 0.390156 loss)
I0526 06:33:40.113623 15394 sgd_solver.cpp:43] Iteration 19540, lr = 0.02
I0526 06:33:51.519317 15394 main.cpp:354] Iteration 19550, loss = 0.161426
I0526 06:33:51.519359 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.161425 (* 1 = 0.161425 loss)
I0526 06:33:51.519366 15394 sgd_solver.cpp:43] Iteration 19550, lr = 0.02
I0526 06:34:03.372118 15394 main.cpp:354] Iteration 19560, loss = 0.308489
I0526 06:34:03.372162 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.308489 (* 1 = 0.308489 loss)
I0526 06:34:03.372169 15394 sgd_solver.cpp:43] Iteration 19560, lr = 0.02
I0526 06:34:14.420270 15394 main.cpp:354] Iteration 19570, loss = 0.534736
I0526 06:34:14.420310 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.534736 (* 1 = 0.534736 loss)
I0526 06:34:14.420316 15394 sgd_solver.cpp:43] Iteration 19570, lr = 0.02
I0526 06:34:25.470324 15394 main.cpp:354] Iteration 19580, loss = 0.392791
I0526 06:34:25.470368 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.392791 (* 1 = 0.392791 loss)
I0526 06:34:25.470376 15394 sgd_solver.cpp:43] Iteration 19580, lr = 0.02
I0526 06:34:36.357698 15394 main.cpp:354] Iteration 19590, loss = 0.443345
I0526 06:34:36.357739 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.443345 (* 1 = 0.443345 loss)
I0526 06:34:36.357746 15394 sgd_solver.cpp:43] Iteration 19590, lr = 0.02
I0526 06:34:47.050339 15394 main.cpp:465] Iteration 19600, Testing net (#0)
I0526 06:35:17.448354 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7936
I0526 06:35:17.448398 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.599721 (* 1 = 0.599721 loss)
I0526 06:35:18.585147 15394 main.cpp:354] Iteration 19600, loss = 0.226406
I0526 06:35:18.585196 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.226406 (* 1 = 0.226406 loss)
I0526 06:35:18.585204 15394 sgd_solver.cpp:43] Iteration 19600, lr = 0.02
I0526 06:35:29.054877 15394 main.cpp:354] Iteration 19610, loss = 0.416657
I0526 06:35:29.054913 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.416657 (* 1 = 0.416657 loss)
I0526 06:35:29.054920 15394 sgd_solver.cpp:43] Iteration 19610, lr = 0.02
I0526 06:35:39.939749 15394 main.cpp:354] Iteration 19620, loss = 0.343036
I0526 06:35:39.939792 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.343036 (* 1 = 0.343036 loss)
I0526 06:35:39.939800 15394 sgd_solver.cpp:43] Iteration 19620, lr = 0.02
I0526 06:35:50.926383 15394 main.cpp:354] Iteration 19630, loss = 0.419359
I0526 06:35:50.926435 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.419359 (* 1 = 0.419359 loss)
I0526 06:35:50.926443 15394 sgd_solver.cpp:43] Iteration 19630, lr = 0.02
I0526 06:36:02.759157 15394 main.cpp:354] Iteration 19640, loss = 0.290105
I0526 06:36:02.759202 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.290105 (* 1 = 0.290105 loss)
I0526 06:36:02.759210 15394 sgd_solver.cpp:43] Iteration 19640, lr = 0.02
I0526 06:36:14.316112 15394 main.cpp:354] Iteration 19650, loss = 0.443414
I0526 06:36:14.316154 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.443414 (* 1 = 0.443414 loss)
I0526 06:36:14.316160 15394 sgd_solver.cpp:43] Iteration 19650, lr = 0.02
I0526 06:36:25.516423 15394 main.cpp:354] Iteration 19660, loss = 0.542296
I0526 06:36:25.516463 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.542296 (* 1 = 0.542296 loss)
I0526 06:36:25.516470 15394 sgd_solver.cpp:43] Iteration 19660, lr = 0.02
I0526 06:36:36.560026 15394 main.cpp:354] Iteration 19670, loss = 0.373582
I0526 06:36:36.560067 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.373581 (* 1 = 0.373581 loss)
I0526 06:36:36.560075 15394 sgd_solver.cpp:43] Iteration 19670, lr = 0.02
I0526 06:36:48.239593 15394 main.cpp:354] Iteration 19680, loss = 0.457599
I0526 06:36:48.239636 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.457599 (* 1 = 0.457599 loss)
I0526 06:36:48.239642 15394 sgd_solver.cpp:43] Iteration 19680, lr = 0.02
I0526 06:36:59.386801 15394 main.cpp:354] Iteration 19690, loss = 0.408731
I0526 06:36:59.386837 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.408731 (* 1 = 0.408731 loss)
I0526 06:36:59.386843 15394 sgd_solver.cpp:43] Iteration 19690, lr = 0.02
I0526 06:37:09.835369 15394 main.cpp:465] Iteration 19700, Testing net (#0)
I0526 06:37:40.264574 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8052
I0526 06:37:40.264612 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.581675 (* 1 = 0.581675 loss)
I0526 06:37:41.509742 15394 main.cpp:354] Iteration 19700, loss = 0.405191
I0526 06:37:41.509778 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.405191 (* 1 = 0.405191 loss)
I0526 06:37:41.509786 15394 sgd_solver.cpp:43] Iteration 19700, lr = 0.02
I0526 06:37:53.172703 15394 main.cpp:354] Iteration 19710, loss = 0.358667
I0526 06:37:53.172747 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.358667 (* 1 = 0.358667 loss)
I0526 06:37:53.172755 15394 sgd_solver.cpp:43] Iteration 19710, lr = 0.02
I0526 06:38:04.885269 15394 main.cpp:354] Iteration 19720, loss = 0.399808
I0526 06:38:04.885313 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.399808 (* 1 = 0.399808 loss)
I0526 06:38:04.885319 15394 sgd_solver.cpp:43] Iteration 19720, lr = 0.02
I0526 06:38:16.251541 15394 main.cpp:354] Iteration 19730, loss = 0.388756
I0526 06:38:16.251585 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.388756 (* 1 = 0.388756 loss)
I0526 06:38:16.251590 15394 sgd_solver.cpp:43] Iteration 19730, lr = 0.02
I0526 06:38:27.418570 15394 main.cpp:354] Iteration 19740, loss = 0.424248
I0526 06:38:27.418622 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.424248 (* 1 = 0.424248 loss)
I0526 06:38:27.418635 15394 sgd_solver.cpp:43] Iteration 19740, lr = 0.02
I0526 06:38:38.813984 15394 main.cpp:354] Iteration 19750, loss = 0.29348
I0526 06:38:38.814016 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.29348 (* 1 = 0.29348 loss)
I0526 06:38:38.814023 15394 sgd_solver.cpp:43] Iteration 19750, lr = 0.02
I0526 06:38:49.957440 15394 main.cpp:354] Iteration 19760, loss = 0.264649
I0526 06:38:49.957484 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.264649 (* 1 = 0.264649 loss)
I0526 06:38:49.957490 15394 sgd_solver.cpp:43] Iteration 19760, lr = 0.02
I0526 06:39:00.946804 15394 main.cpp:354] Iteration 19770, loss = 0.422337
I0526 06:39:00.946869 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.422337 (* 1 = 0.422337 loss)
I0526 06:39:00.946877 15394 sgd_solver.cpp:43] Iteration 19770, lr = 0.02
I0526 06:39:12.469178 15394 main.cpp:354] Iteration 19780, loss = 0.342195
I0526 06:39:12.469216 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.342195 (* 1 = 0.342195 loss)
I0526 06:39:12.469223 15394 sgd_solver.cpp:43] Iteration 19780, lr = 0.02
I0526 06:39:24.960916 15394 main.cpp:354] Iteration 19790, loss = 0.376216
I0526 06:39:24.960958 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.376216 (* 1 = 0.376216 loss)
I0526 06:39:24.960964 15394 sgd_solver.cpp:43] Iteration 19790, lr = 0.02
I0526 06:39:35.016326 15394 main.cpp:465] Iteration 19800, Testing net (#0)
I0526 06:40:05.460748 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7446
I0526 06:40:05.460790 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.757095 (* 1 = 0.757095 loss)
I0526 06:40:06.442842 15394 main.cpp:354] Iteration 19800, loss = 0.422367
I0526 06:40:06.442881 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.422367 (* 1 = 0.422367 loss)
I0526 06:40:06.442888 15394 sgd_solver.cpp:43] Iteration 19800, lr = 0.02
I0526 06:40:18.152690 15394 main.cpp:354] Iteration 19810, loss = 0.322932
I0526 06:40:18.152742 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.322932 (* 1 = 0.322932 loss)
I0526 06:40:18.152748 15394 sgd_solver.cpp:43] Iteration 19810, lr = 0.02
I0526 06:40:29.650002 15394 main.cpp:354] Iteration 19820, loss = 0.327995
I0526 06:40:29.650043 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.327995 (* 1 = 0.327995 loss)
I0526 06:40:29.650049 15394 sgd_solver.cpp:43] Iteration 19820, lr = 0.02
I0526 06:40:40.609896 15394 main.cpp:354] Iteration 19830, loss = 0.371679
I0526 06:40:40.609941 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.371679 (* 1 = 0.371679 loss)
I0526 06:40:40.609947 15394 sgd_solver.cpp:43] Iteration 19830, lr = 0.02
I0526 06:40:51.349388 15394 main.cpp:354] Iteration 19840, loss = 0.299248
I0526 06:40:51.349432 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.299248 (* 1 = 0.299248 loss)
I0526 06:40:51.349439 15394 sgd_solver.cpp:43] Iteration 19840, lr = 0.02
I0526 06:41:02.769003 15394 main.cpp:354] Iteration 19850, loss = 0.291964
I0526 06:41:02.769045 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.291964 (* 1 = 0.291964 loss)
I0526 06:41:02.769053 15394 sgd_solver.cpp:43] Iteration 19850, lr = 0.02
I0526 06:41:14.588027 15394 main.cpp:354] Iteration 19860, loss = 0.207245
I0526 06:41:14.588065 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.207245 (* 1 = 0.207245 loss)
I0526 06:41:14.588073 15394 sgd_solver.cpp:43] Iteration 19860, lr = 0.02
I0526 06:41:26.044736 15394 main.cpp:354] Iteration 19870, loss = 0.301453
I0526 06:41:26.044778 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.301453 (* 1 = 0.301453 loss)
I0526 06:41:26.044785 15394 sgd_solver.cpp:43] Iteration 19870, lr = 0.02
I0526 06:41:36.632599 15394 main.cpp:354] Iteration 19880, loss = 0.257295
I0526 06:41:36.632637 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.257295 (* 1 = 0.257295 loss)
I0526 06:41:36.632643 15394 sgd_solver.cpp:43] Iteration 19880, lr = 0.02
I0526 06:41:47.722926 15394 main.cpp:354] Iteration 19890, loss = 0.342812
I0526 06:41:47.722970 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.342812 (* 1 = 0.342812 loss)
I0526 06:41:47.722976 15394 sgd_solver.cpp:43] Iteration 19890, lr = 0.02
I0526 06:41:57.752573 15394 main.cpp:465] Iteration 19900, Testing net (#0)
I0526 06:42:28.246520 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8032
I0526 06:42:28.246562 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.602348 (* 1 = 0.602348 loss)
I0526 06:42:29.212590 15394 main.cpp:354] Iteration 19900, loss = 0.354307
I0526 06:42:29.212630 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.354306 (* 1 = 0.354306 loss)
I0526 06:42:29.212637 15394 sgd_solver.cpp:43] Iteration 19900, lr = 0.02
I0526 06:42:39.760049 15394 main.cpp:354] Iteration 19910, loss = 0.364159
I0526 06:42:39.760089 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.364159 (* 1 = 0.364159 loss)
I0526 06:42:39.760097 15394 sgd_solver.cpp:43] Iteration 19910, lr = 0.02
I0526 06:42:51.204584 15394 main.cpp:354] Iteration 19920, loss = 0.296306
I0526 06:42:51.204624 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.296305 (* 1 = 0.296305 loss)
I0526 06:42:51.204632 15394 sgd_solver.cpp:43] Iteration 19920, lr = 0.02
I0526 06:43:02.897956 15394 main.cpp:354] Iteration 19930, loss = 0.443824
I0526 06:43:02.897996 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.443824 (* 1 = 0.443824 loss)
I0526 06:43:02.898003 15394 sgd_solver.cpp:43] Iteration 19930, lr = 0.02
I0526 06:43:14.027875 15394 main.cpp:354] Iteration 19940, loss = 0.325048
I0526 06:43:14.027912 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.325048 (* 1 = 0.325048 loss)
I0526 06:43:14.027920 15394 sgd_solver.cpp:43] Iteration 19940, lr = 0.02
I0526 06:43:25.727351 15394 main.cpp:354] Iteration 19950, loss = 0.322042
I0526 06:43:25.727396 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.322042 (* 1 = 0.322042 loss)
I0526 06:43:25.727404 15394 sgd_solver.cpp:43] Iteration 19950, lr = 0.02
I0526 06:43:37.225013 15394 main.cpp:354] Iteration 19960, loss = 0.496765
I0526 06:43:37.225059 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.496765 (* 1 = 0.496765 loss)
I0526 06:43:37.225067 15394 sgd_solver.cpp:43] Iteration 19960, lr = 0.02
I0526 06:43:49.270033 15394 main.cpp:354] Iteration 19970, loss = 0.246325
I0526 06:43:49.270076 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.246325 (* 1 = 0.246325 loss)
I0526 06:43:49.270083 15394 sgd_solver.cpp:43] Iteration 19970, lr = 0.02
I0526 06:44:00.651787 15394 main.cpp:354] Iteration 19980, loss = 0.31063
I0526 06:44:00.651850 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.31063 (* 1 = 0.31063 loss)
I0526 06:44:00.651862 15394 sgd_solver.cpp:43] Iteration 19980, lr = 0.02
I0526 06:44:11.784304 15394 main.cpp:354] Iteration 19990, loss = 0.752084
I0526 06:44:11.784346 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.752083 (* 1 = 0.752083 loss)
I0526 06:44:11.784353 15394 sgd_solver.cpp:43] Iteration 19990, lr = 0.02
I0526 06:44:22.391477 15394 main.cpp:465] Iteration 20000, Testing net (#0)
I0526 06:44:52.941025 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7392
I0526 06:44:52.941071 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.762041 (* 1 = 0.762041 loss)
I0526 06:44:54.051797 15394 main.cpp:354] Iteration 20000, loss = 0.307357
I0526 06:44:54.051854 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.307357 (* 1 = 0.307357 loss)
I0526 06:44:54.051864 15394 sgd_solver.cpp:43] Iteration 20000, lr = 0.02
I0526 06:45:04.556532 15394 main.cpp:354] Iteration 20010, loss = 0.292761
I0526 06:45:04.556581 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.292761 (* 1 = 0.292761 loss)
I0526 06:45:04.556589 15394 sgd_solver.cpp:43] Iteration 20010, lr = 0.02
I0526 06:45:15.918828 15394 main.cpp:354] Iteration 20020, loss = 0.364723
I0526 06:45:15.918884 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.364723 (* 1 = 0.364723 loss)
I0526 06:45:15.918894 15394 sgd_solver.cpp:43] Iteration 20020, lr = 0.02
I0526 06:45:27.157780 15394 main.cpp:354] Iteration 20030, loss = 0.300849
I0526 06:45:27.157824 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.300849 (* 1 = 0.300849 loss)
I0526 06:45:27.157830 15394 sgd_solver.cpp:43] Iteration 20030, lr = 0.02
I0526 06:45:38.278614 15394 main.cpp:354] Iteration 20040, loss = 0.381317
I0526 06:45:38.278666 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.381317 (* 1 = 0.381317 loss)
I0526 06:45:38.278671 15394 sgd_solver.cpp:43] Iteration 20040, lr = 0.02
I0526 06:45:49.478971 15394 main.cpp:354] Iteration 20050, loss = 0.511502
I0526 06:45:49.479009 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.511502 (* 1 = 0.511502 loss)
I0526 06:45:49.479015 15394 sgd_solver.cpp:43] Iteration 20050, lr = 0.02
I0526 06:46:00.968737 15394 main.cpp:354] Iteration 20060, loss = 0.30138
I0526 06:46:00.968780 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.30138 (* 1 = 0.30138 loss)
I0526 06:46:00.968786 15394 sgd_solver.cpp:43] Iteration 20060, lr = 0.02
I0526 06:46:12.912866 15394 main.cpp:354] Iteration 20070, loss = 0.369547
I0526 06:46:12.912911 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.369546 (* 1 = 0.369546 loss)
I0526 06:46:12.912927 15394 sgd_solver.cpp:43] Iteration 20070, lr = 0.02
I0526 06:46:23.850232 15394 main.cpp:354] Iteration 20080, loss = 0.319321
I0526 06:46:23.850275 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.319321 (* 1 = 0.319321 loss)
I0526 06:46:23.850281 15394 sgd_solver.cpp:43] Iteration 20080, lr = 0.02
I0526 06:46:35.399929 15394 main.cpp:354] Iteration 20090, loss = 0.47957
I0526 06:46:35.399963 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.47957 (* 1 = 0.47957 loss)
I0526 06:46:35.399971 15394 sgd_solver.cpp:43] Iteration 20090, lr = 0.02
I0526 06:46:45.736711 15394 main.cpp:465] Iteration 20100, Testing net (#0)
I0526 06:47:16.263825 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7566
I0526 06:47:16.263880 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.73377 (* 1 = 0.73377 loss)
I0526 06:47:17.379262 15394 main.cpp:354] Iteration 20100, loss = 0.374195
I0526 06:47:17.379302 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.374194 (* 1 = 0.374194 loss)
I0526 06:47:17.379309 15394 sgd_solver.cpp:43] Iteration 20100, lr = 0.02
I0526 06:47:28.921988 15394 main.cpp:354] Iteration 20110, loss = 0.295969
I0526 06:47:28.922035 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.295969 (* 1 = 0.295969 loss)
I0526 06:47:28.922044 15394 sgd_solver.cpp:43] Iteration 20110, lr = 0.02
I0526 06:47:40.837877 15394 main.cpp:354] Iteration 20120, loss = 0.269887
I0526 06:47:40.837918 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.269887 (* 1 = 0.269887 loss)
I0526 06:47:40.837925 15394 sgd_solver.cpp:43] Iteration 20120, lr = 0.02
I0526 06:47:52.208847 15394 main.cpp:354] Iteration 20130, loss = 0.306744
I0526 06:47:52.208894 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.306744 (* 1 = 0.306744 loss)
I0526 06:47:52.208911 15394 sgd_solver.cpp:43] Iteration 20130, lr = 0.02
I0526 06:48:03.478031 15394 main.cpp:354] Iteration 20140, loss = 0.36843
I0526 06:48:03.478062 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.36843 (* 1 = 0.36843 loss)
I0526 06:48:03.478070 15394 sgd_solver.cpp:43] Iteration 20140, lr = 0.02
I0526 06:48:15.019414 15394 main.cpp:354] Iteration 20150, loss = 0.420754
I0526 06:48:15.019462 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.420753 (* 1 = 0.420753 loss)
I0526 06:48:15.019470 15394 sgd_solver.cpp:43] Iteration 20150, lr = 0.02
I0526 06:48:26.382330 15394 main.cpp:354] Iteration 20160, loss = 0.683922
I0526 06:48:26.382378 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.683922 (* 1 = 0.683922 loss)
I0526 06:48:26.382391 15394 sgd_solver.cpp:43] Iteration 20160, lr = 0.02
I0526 06:48:38.311063 15394 main.cpp:354] Iteration 20170, loss = 0.329703
I0526 06:48:38.311110 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.329702 (* 1 = 0.329702 loss)
I0526 06:48:38.311118 15394 sgd_solver.cpp:43] Iteration 20170, lr = 0.02
I0526 06:48:49.697363 15394 main.cpp:354] Iteration 20180, loss = 0.487974
I0526 06:48:49.697401 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.487973 (* 1 = 0.487973 loss)
I0526 06:48:49.697408 15394 sgd_solver.cpp:43] Iteration 20180, lr = 0.02
I0526 06:49:01.800113 15394 main.cpp:354] Iteration 20190, loss = 0.394194
I0526 06:49:01.800158 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.394194 (* 1 = 0.394194 loss)
I0526 06:49:01.800165 15394 sgd_solver.cpp:43] Iteration 20190, lr = 0.02
I0526 06:49:12.590682 15394 main.cpp:465] Iteration 20200, Testing net (#0)
I0526 06:49:43.068459 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8286
I0526 06:49:43.068503 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.521902 (* 1 = 0.521902 loss)
I0526 06:49:43.972105 15394 main.cpp:354] Iteration 20200, loss = 0.548409
I0526 06:49:43.972146 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.548409 (* 1 = 0.548409 loss)
I0526 06:49:43.972153 15394 sgd_solver.cpp:43] Iteration 20200, lr = 0.02
I0526 06:49:55.624469 15394 main.cpp:354] Iteration 20210, loss = 0.429453
I0526 06:49:55.624514 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.429453 (* 1 = 0.429453 loss)
I0526 06:49:55.624522 15394 sgd_solver.cpp:43] Iteration 20210, lr = 0.02
I0526 06:50:07.683748 15394 main.cpp:354] Iteration 20220, loss = 0.387368
I0526 06:50:07.683790 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.387368 (* 1 = 0.387368 loss)
I0526 06:50:07.683797 15394 sgd_solver.cpp:43] Iteration 20220, lr = 0.02
I0526 06:50:18.881476 15394 main.cpp:354] Iteration 20230, loss = 0.209968
I0526 06:50:18.881516 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.209968 (* 1 = 0.209968 loss)
I0526 06:50:18.881523 15394 sgd_solver.cpp:43] Iteration 20230, lr = 0.02
I0526 06:50:30.550156 15394 main.cpp:354] Iteration 20240, loss = 0.39396
I0526 06:50:30.550197 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.39396 (* 1 = 0.39396 loss)
I0526 06:50:30.550204 15394 sgd_solver.cpp:43] Iteration 20240, lr = 0.02
I0526 06:50:42.733711 15394 main.cpp:354] Iteration 20250, loss = 0.377154
I0526 06:50:42.733747 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.377154 (* 1 = 0.377154 loss)
I0526 06:50:42.733754 15394 sgd_solver.cpp:43] Iteration 20250, lr = 0.02
I0526 06:50:54.723381 15394 main.cpp:354] Iteration 20260, loss = 0.424418
I0526 06:50:54.723425 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.424418 (* 1 = 0.424418 loss)
I0526 06:50:54.723433 15394 sgd_solver.cpp:43] Iteration 20260, lr = 0.02
I0526 06:51:05.962340 15394 main.cpp:354] Iteration 20270, loss = 0.262203
I0526 06:51:05.962383 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.262203 (* 1 = 0.262203 loss)
I0526 06:51:05.962390 15394 sgd_solver.cpp:43] Iteration 20270, lr = 0.02
I0526 06:51:17.638052 15394 main.cpp:354] Iteration 20280, loss = 0.479825
I0526 06:51:17.638094 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.479825 (* 1 = 0.479825 loss)
I0526 06:51:17.638101 15394 sgd_solver.cpp:43] Iteration 20280, lr = 0.02
I0526 06:51:28.768359 15394 main.cpp:354] Iteration 20290, loss = 0.384349
I0526 06:51:28.768402 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.384348 (* 1 = 0.384348 loss)
I0526 06:51:28.768419 15394 sgd_solver.cpp:43] Iteration 20290, lr = 0.02
I0526 06:51:38.786842 15394 main.cpp:465] Iteration 20300, Testing net (#0)
I0526 06:52:09.206974 15394 main.cpp:532]     Test net output #0: Accuracy = 0.813
I0526 06:52:09.207021 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.590352 (* 1 = 0.590352 loss)
I0526 06:52:10.326370 15394 main.cpp:354] Iteration 20300, loss = 0.324344
I0526 06:52:10.326409 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.324344 (* 1 = 0.324344 loss)
I0526 06:52:10.326417 15394 sgd_solver.cpp:43] Iteration 20300, lr = 0.02
I0526 06:52:21.198532 15394 main.cpp:354] Iteration 20310, loss = 0.285836
I0526 06:52:21.198571 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.285836 (* 1 = 0.285836 loss)
I0526 06:52:21.198577 15394 sgd_solver.cpp:43] Iteration 20310, lr = 0.02
I0526 06:52:32.750674 15394 main.cpp:354] Iteration 20320, loss = 0.285347
I0526 06:52:32.750728 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.285347 (* 1 = 0.285347 loss)
I0526 06:52:32.750735 15394 sgd_solver.cpp:43] Iteration 20320, lr = 0.02
I0526 06:52:44.319794 15394 main.cpp:354] Iteration 20330, loss = 0.302251
I0526 06:52:44.319838 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.302251 (* 1 = 0.302251 loss)
I0526 06:52:44.319844 15394 sgd_solver.cpp:43] Iteration 20330, lr = 0.02
I0526 06:52:55.745232 15394 main.cpp:354] Iteration 20340, loss = 0.373061
I0526 06:52:55.745266 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.373061 (* 1 = 0.373061 loss)
I0526 06:52:55.745273 15394 sgd_solver.cpp:43] Iteration 20340, lr = 0.02
I0526 06:53:06.832937 15394 main.cpp:354] Iteration 20350, loss = 0.458126
I0526 06:53:06.832976 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.458125 (* 1 = 0.458125 loss)
I0526 06:53:06.832984 15394 sgd_solver.cpp:43] Iteration 20350, lr = 0.02
I0526 06:53:17.382067 15394 main.cpp:354] Iteration 20360, loss = 0.361586
I0526 06:53:17.382120 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.361586 (* 1 = 0.361586 loss)
I0526 06:53:17.382128 15394 sgd_solver.cpp:43] Iteration 20360, lr = 0.02
I0526 06:53:29.103338 15394 main.cpp:354] Iteration 20370, loss = 0.353316
I0526 06:53:29.103384 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.353316 (* 1 = 0.353316 loss)
I0526 06:53:29.103391 15394 sgd_solver.cpp:43] Iteration 20370, lr = 0.02
I0526 06:53:40.343181 15394 main.cpp:354] Iteration 20380, loss = 0.395015
I0526 06:53:40.343225 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.395015 (* 1 = 0.395015 loss)
I0526 06:53:40.343232 15394 sgd_solver.cpp:43] Iteration 20380, lr = 0.02
I0526 06:53:52.023094 15394 main.cpp:354] Iteration 20390, loss = 0.318241
I0526 06:53:52.023142 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.318241 (* 1 = 0.318241 loss)
I0526 06:53:52.023152 15394 sgd_solver.cpp:43] Iteration 20390, lr = 0.02
I0526 06:54:02.332080 15394 main.cpp:465] Iteration 20400, Testing net (#0)
I0526 06:54:32.841891 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7724
I0526 06:54:32.841934 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.69496 (* 1 = 0.69496 loss)
I0526 06:54:33.796205 15394 main.cpp:354] Iteration 20400, loss = 0.291032
I0526 06:54:33.796244 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.291031 (* 1 = 0.291031 loss)
I0526 06:54:33.796252 15394 sgd_solver.cpp:43] Iteration 20400, lr = 0.02
I0526 06:54:45.529707 15394 main.cpp:354] Iteration 20410, loss = 0.33957
I0526 06:54:45.529759 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.33957 (* 1 = 0.33957 loss)
I0526 06:54:45.529767 15394 sgd_solver.cpp:43] Iteration 20410, lr = 0.02
I0526 06:54:57.016993 15394 main.cpp:354] Iteration 20420, loss = 0.420598
I0526 06:54:57.017035 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.420598 (* 1 = 0.420598 loss)
I0526 06:54:57.017055 15394 sgd_solver.cpp:43] Iteration 20420, lr = 0.02
I0526 06:55:08.262032 15394 main.cpp:354] Iteration 20430, loss = 0.273334
I0526 06:55:08.262069 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.273334 (* 1 = 0.273334 loss)
I0526 06:55:08.262079 15394 sgd_solver.cpp:43] Iteration 20430, lr = 0.02
I0526 06:55:19.689328 15394 main.cpp:354] Iteration 20440, loss = 0.561021
I0526 06:55:19.689366 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.561021 (* 1 = 0.561021 loss)
I0526 06:55:19.689379 15394 sgd_solver.cpp:43] Iteration 20440, lr = 0.02
I0526 06:55:31.153705 15394 main.cpp:354] Iteration 20450, loss = 0.326079
I0526 06:55:31.153770 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.326079 (* 1 = 0.326079 loss)
I0526 06:55:31.153777 15394 sgd_solver.cpp:43] Iteration 20450, lr = 0.02
I0526 06:55:42.256681 15394 main.cpp:354] Iteration 20460, loss = 0.259368
I0526 06:55:42.256727 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.259368 (* 1 = 0.259368 loss)
I0526 06:55:42.256734 15394 sgd_solver.cpp:43] Iteration 20460, lr = 0.02
I0526 06:55:52.959380 15394 main.cpp:354] Iteration 20470, loss = 0.263533
I0526 06:55:52.959425 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.263533 (* 1 = 0.263533 loss)
I0526 06:55:52.959432 15394 sgd_solver.cpp:43] Iteration 20470, lr = 0.02
I0526 06:56:04.171589 15394 main.cpp:354] Iteration 20480, loss = 0.451166
I0526 06:56:04.171628 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.451166 (* 1 = 0.451166 loss)
I0526 06:56:04.171635 15394 sgd_solver.cpp:43] Iteration 20480, lr = 0.02
I0526 06:56:15.629706 15394 main.cpp:354] Iteration 20490, loss = 0.632844
I0526 06:56:15.629755 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.632844 (* 1 = 0.632844 loss)
I0526 06:56:15.629762 15394 sgd_solver.cpp:43] Iteration 20490, lr = 0.02
I0526 06:56:26.161355 15394 main.cpp:465] Iteration 20500, Testing net (#0)
I0526 06:56:56.647611 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7594
I0526 06:56:56.647651 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.746712 (* 1 = 0.746712 loss)
I0526 06:56:57.560276 15394 main.cpp:354] Iteration 20500, loss = 0.279317
I0526 06:56:57.560312 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.279317 (* 1 = 0.279317 loss)
I0526 06:56:57.560320 15394 sgd_solver.cpp:43] Iteration 20500, lr = 0.02
I0526 06:57:09.105687 15394 main.cpp:354] Iteration 20510, loss = 0.189349
I0526 06:57:09.105733 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.189349 (* 1 = 0.189349 loss)
I0526 06:57:09.105742 15394 sgd_solver.cpp:43] Iteration 20510, lr = 0.02
I0526 06:57:20.717655 15394 main.cpp:354] Iteration 20520, loss = 0.430243
I0526 06:57:20.717699 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.430243 (* 1 = 0.430243 loss)
I0526 06:57:20.717705 15394 sgd_solver.cpp:43] Iteration 20520, lr = 0.02
I0526 06:57:31.611079 15394 main.cpp:354] Iteration 20530, loss = 0.311265
I0526 06:57:31.611125 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.311265 (* 1 = 0.311265 loss)
I0526 06:57:31.611134 15394 sgd_solver.cpp:43] Iteration 20530, lr = 0.02
I0526 06:57:42.002316 15394 main.cpp:354] Iteration 20540, loss = 0.315646
I0526 06:57:42.002358 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.315646 (* 1 = 0.315646 loss)
I0526 06:57:42.002365 15394 sgd_solver.cpp:43] Iteration 20540, lr = 0.02
I0526 06:57:53.381006 15394 main.cpp:354] Iteration 20550, loss = 0.507057
I0526 06:57:53.381047 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.507057 (* 1 = 0.507057 loss)
I0526 06:57:53.381054 15394 sgd_solver.cpp:43] Iteration 20550, lr = 0.02
I0526 06:58:05.212050 15394 main.cpp:354] Iteration 20560, loss = 0.346462
I0526 06:58:05.212101 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.346462 (* 1 = 0.346462 loss)
I0526 06:58:05.212119 15394 sgd_solver.cpp:43] Iteration 20560, lr = 0.02
I0526 06:58:17.078027 15394 main.cpp:354] Iteration 20570, loss = 0.568611
I0526 06:58:17.078089 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.568611 (* 1 = 0.568611 loss)
I0526 06:58:17.078096 15394 sgd_solver.cpp:43] Iteration 20570, lr = 0.02
I0526 06:58:27.977146 15394 main.cpp:354] Iteration 20580, loss = 0.523136
I0526 06:58:27.977200 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.523136 (* 1 = 0.523136 loss)
I0526 06:58:27.977210 15394 sgd_solver.cpp:43] Iteration 20580, lr = 0.02
I0526 06:58:39.810884 15394 main.cpp:354] Iteration 20590, loss = 0.394233
I0526 06:58:39.810948 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.394233 (* 1 = 0.394233 loss)
I0526 06:58:39.810956 15394 sgd_solver.cpp:43] Iteration 20590, lr = 0.02
I0526 06:58:49.904666 15394 main.cpp:465] Iteration 20600, Testing net (#0)
I0526 06:59:20.408709 15394 main.cpp:532]     Test net output #0: Accuracy = 0.822
I0526 06:59:20.408751 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.535954 (* 1 = 0.535954 loss)
I0526 06:59:21.383939 15394 main.cpp:354] Iteration 20600, loss = 0.458835
I0526 06:59:21.383980 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.458835 (* 1 = 0.458835 loss)
I0526 06:59:21.383988 15394 sgd_solver.cpp:43] Iteration 20600, lr = 0.02
I0526 06:59:33.095784 15394 main.cpp:354] Iteration 20610, loss = 0.396051
I0526 06:59:33.095829 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.396051 (* 1 = 0.396051 loss)
I0526 06:59:33.095834 15394 sgd_solver.cpp:43] Iteration 20610, lr = 0.02
I0526 06:59:45.279942 15394 main.cpp:354] Iteration 20620, loss = 0.371637
I0526 06:59:45.279983 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.371637 (* 1 = 0.371637 loss)
I0526 06:59:45.279990 15394 sgd_solver.cpp:43] Iteration 20620, lr = 0.02
I0526 06:59:56.338491 15394 main.cpp:354] Iteration 20630, loss = 0.37763
I0526 06:59:56.338536 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.37763 (* 1 = 0.37763 loss)
I0526 06:59:56.338544 15394 sgd_solver.cpp:43] Iteration 20630, lr = 0.02
I0526 07:00:07.650751 15394 main.cpp:354] Iteration 20640, loss = 0.471425
I0526 07:00:07.650795 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.471424 (* 1 = 0.471424 loss)
I0526 07:00:07.650804 15394 sgd_solver.cpp:43] Iteration 20640, lr = 0.02
I0526 07:00:18.679867 15394 main.cpp:354] Iteration 20650, loss = 0.508601
I0526 07:00:18.679905 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.508601 (* 1 = 0.508601 loss)
I0526 07:00:18.679913 15394 sgd_solver.cpp:43] Iteration 20650, lr = 0.02
I0526 07:00:30.626093 15394 main.cpp:354] Iteration 20660, loss = 0.36387
I0526 07:00:30.626137 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.36387 (* 1 = 0.36387 loss)
I0526 07:00:30.626144 15394 sgd_solver.cpp:43] Iteration 20660, lr = 0.02
I0526 07:00:42.354814 15394 main.cpp:354] Iteration 20670, loss = 0.284084
I0526 07:00:42.354858 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.284084 (* 1 = 0.284084 loss)
I0526 07:00:42.354864 15394 sgd_solver.cpp:43] Iteration 20670, lr = 0.02
I0526 07:00:53.136196 15394 main.cpp:354] Iteration 20680, loss = 0.291487
I0526 07:00:53.136248 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.291487 (* 1 = 0.291487 loss)
I0526 07:00:53.136255 15394 sgd_solver.cpp:43] Iteration 20680, lr = 0.02
I0526 07:01:04.755244 15394 main.cpp:354] Iteration 20690, loss = 0.268656
I0526 07:01:04.755277 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.268656 (* 1 = 0.268656 loss)
I0526 07:01:04.755285 15394 sgd_solver.cpp:43] Iteration 20690, lr = 0.02
I0526 07:01:14.616098 15394 main.cpp:465] Iteration 20700, Testing net (#0)
I0526 07:01:45.031813 15394 main.cpp:532]     Test net output #0: Accuracy = 0.801
I0526 07:01:45.031857 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.595488 (* 1 = 0.595488 loss)
I0526 07:01:46.221879 15394 main.cpp:354] Iteration 20700, loss = 0.253157
I0526 07:01:46.221920 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.253157 (* 1 = 0.253157 loss)
I0526 07:01:46.221928 15394 sgd_solver.cpp:43] Iteration 20700, lr = 0.02
I0526 07:01:57.806957 15394 main.cpp:354] Iteration 20710, loss = 0.1626
I0526 07:01:57.807008 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.1626 (* 1 = 0.1626 loss)
I0526 07:01:57.807016 15394 sgd_solver.cpp:43] Iteration 20710, lr = 0.02
I0526 07:02:09.753732 15394 main.cpp:354] Iteration 20720, loss = 0.321934
I0526 07:02:09.753782 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.321934 (* 1 = 0.321934 loss)
I0526 07:02:09.753788 15394 sgd_solver.cpp:43] Iteration 20720, lr = 0.02
I0526 07:02:21.177989 15394 main.cpp:354] Iteration 20730, loss = 0.355136
I0526 07:02:21.178036 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.355136 (* 1 = 0.355136 loss)
I0526 07:02:21.178043 15394 sgd_solver.cpp:43] Iteration 20730, lr = 0.02
I0526 07:02:32.543501 15394 main.cpp:354] Iteration 20740, loss = 0.229604
I0526 07:02:32.543542 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.229604 (* 1 = 0.229604 loss)
I0526 07:02:32.543550 15394 sgd_solver.cpp:43] Iteration 20740, lr = 0.02
I0526 07:02:43.523999 15394 main.cpp:354] Iteration 20750, loss = 0.375464
I0526 07:02:43.524044 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.375464 (* 1 = 0.375464 loss)
I0526 07:02:43.524051 15394 sgd_solver.cpp:43] Iteration 20750, lr = 0.02
I0526 07:02:54.865912 15394 main.cpp:354] Iteration 20760, loss = 0.38327
I0526 07:02:54.865957 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.38327 (* 1 = 0.38327 loss)
I0526 07:02:54.865964 15394 sgd_solver.cpp:43] Iteration 20760, lr = 0.02
I0526 07:03:06.657996 15394 main.cpp:354] Iteration 20770, loss = 0.387787
I0526 07:03:06.658038 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.387787 (* 1 = 0.387787 loss)
I0526 07:03:06.658046 15394 sgd_solver.cpp:43] Iteration 20770, lr = 0.02
I0526 07:03:18.616355 15394 main.cpp:354] Iteration 20780, loss = 0.346798
I0526 07:03:18.616391 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.346798 (* 1 = 0.346798 loss)
I0526 07:03:18.616399 15394 sgd_solver.cpp:43] Iteration 20780, lr = 0.02
I0526 07:03:29.845741 15394 main.cpp:354] Iteration 20790, loss = 0.267954
I0526 07:03:29.845784 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.267954 (* 1 = 0.267954 loss)
I0526 07:03:29.845791 15394 sgd_solver.cpp:43] Iteration 20790, lr = 0.02
I0526 07:03:40.386085 15394 main.cpp:465] Iteration 20800, Testing net (#0)
I0526 07:04:10.788801 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8008
I0526 07:04:10.788846 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.622632 (* 1 = 0.622632 loss)
I0526 07:04:11.902437 15394 main.cpp:354] Iteration 20800, loss = 0.32286
I0526 07:04:11.902478 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.32286 (* 1 = 0.32286 loss)
I0526 07:04:11.902487 15394 sgd_solver.cpp:43] Iteration 20800, lr = 0.02
I0526 07:04:23.117461 15394 main.cpp:354] Iteration 20810, loss = 0.532213
I0526 07:04:23.117509 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.532213 (* 1 = 0.532213 loss)
I0526 07:04:23.117517 15394 sgd_solver.cpp:43] Iteration 20810, lr = 0.02
I0526 07:04:34.184398 15394 main.cpp:354] Iteration 20820, loss = 0.359196
I0526 07:04:34.184427 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.359196 (* 1 = 0.359196 loss)
I0526 07:04:34.184433 15394 sgd_solver.cpp:43] Iteration 20820, lr = 0.02
I0526 07:04:45.738924 15394 main.cpp:354] Iteration 20830, loss = 0.274417
I0526 07:04:45.738968 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.274417 (* 1 = 0.274417 loss)
I0526 07:04:45.738976 15394 sgd_solver.cpp:43] Iteration 20830, lr = 0.02
I0526 07:04:57.664319 15394 main.cpp:354] Iteration 20840, loss = 0.320448
I0526 07:04:57.664358 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.320447 (* 1 = 0.320447 loss)
I0526 07:04:57.664366 15394 sgd_solver.cpp:43] Iteration 20840, lr = 0.02
I0526 07:05:09.216948 15394 main.cpp:354] Iteration 20850, loss = 0.319422
I0526 07:05:09.216992 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.319422 (* 1 = 0.319422 loss)
I0526 07:05:09.217000 15394 sgd_solver.cpp:43] Iteration 20850, lr = 0.02
I0526 07:05:20.990149 15394 main.cpp:354] Iteration 20860, loss = 0.500942
I0526 07:05:20.990187 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.500942 (* 1 = 0.500942 loss)
I0526 07:05:20.990197 15394 sgd_solver.cpp:43] Iteration 20860, lr = 0.02
I0526 07:05:32.152904 15394 main.cpp:354] Iteration 20870, loss = 0.505226
I0526 07:05:32.152945 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.505226 (* 1 = 0.505226 loss)
I0526 07:05:32.152952 15394 sgd_solver.cpp:43] Iteration 20870, lr = 0.02
I0526 07:05:43.580688 15394 main.cpp:354] Iteration 20880, loss = 0.383247
I0526 07:05:43.580740 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.383247 (* 1 = 0.383247 loss)
I0526 07:05:43.580747 15394 sgd_solver.cpp:43] Iteration 20880, lr = 0.02
I0526 07:05:54.524677 15394 main.cpp:354] Iteration 20890, loss = 0.335244
I0526 07:05:54.524719 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.335244 (* 1 = 0.335244 loss)
I0526 07:05:54.524726 15394 sgd_solver.cpp:43] Iteration 20890, lr = 0.02
I0526 07:06:04.220706 15394 main.cpp:465] Iteration 20900, Testing net (#0)
I0526 07:06:34.679940 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8415
I0526 07:06:34.679986 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.45837 (* 1 = 0.45837 loss)
I0526 07:06:35.696519 15394 main.cpp:354] Iteration 20900, loss = 0.502493
I0526 07:06:35.696559 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.502493 (* 1 = 0.502493 loss)
I0526 07:06:35.696568 15394 sgd_solver.cpp:43] Iteration 20900, lr = 0.02
I0526 07:06:46.505344 15394 main.cpp:354] Iteration 20910, loss = 0.334101
I0526 07:06:46.505383 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.334101 (* 1 = 0.334101 loss)
I0526 07:06:46.505390 15394 sgd_solver.cpp:43] Iteration 20910, lr = 0.02
I0526 07:06:57.820762 15394 main.cpp:354] Iteration 20920, loss = 0.316608
I0526 07:06:57.820806 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.316608 (* 1 = 0.316608 loss)
I0526 07:06:57.820812 15394 sgd_solver.cpp:43] Iteration 20920, lr = 0.02
I0526 07:07:08.344980 15394 main.cpp:354] Iteration 20930, loss = 0.611127
I0526 07:07:08.345032 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.611127 (* 1 = 0.611127 loss)
I0526 07:07:08.345039 15394 sgd_solver.cpp:43] Iteration 20930, lr = 0.02
I0526 07:07:19.413470 15394 main.cpp:354] Iteration 20940, loss = 0.285088
I0526 07:07:19.413502 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.285088 (* 1 = 0.285088 loss)
I0526 07:07:19.413509 15394 sgd_solver.cpp:43] Iteration 20940, lr = 0.02
I0526 07:07:30.864553 15394 main.cpp:354] Iteration 20950, loss = 0.336195
I0526 07:07:30.864598 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.336195 (* 1 = 0.336195 loss)
I0526 07:07:30.864603 15394 sgd_solver.cpp:43] Iteration 20950, lr = 0.02
I0526 07:07:42.543413 15394 main.cpp:354] Iteration 20960, loss = 0.689918
I0526 07:07:42.543455 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.689918 (* 1 = 0.689918 loss)
I0526 07:07:42.543462 15394 sgd_solver.cpp:43] Iteration 20960, lr = 0.02
I0526 07:07:53.699874 15394 main.cpp:354] Iteration 20970, loss = 0.455462
I0526 07:07:53.699918 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.455461 (* 1 = 0.455461 loss)
I0526 07:07:53.699926 15394 sgd_solver.cpp:43] Iteration 20970, lr = 0.02
I0526 07:08:05.093209 15394 main.cpp:354] Iteration 20980, loss = 0.455404
I0526 07:08:05.093248 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.455404 (* 1 = 0.455404 loss)
I0526 07:08:05.093255 15394 sgd_solver.cpp:43] Iteration 20980, lr = 0.02
I0526 07:08:16.567808 15394 main.cpp:354] Iteration 20990, loss = 0.515432
I0526 07:08:16.567839 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.515432 (* 1 = 0.515432 loss)
I0526 07:08:16.567847 15394 sgd_solver.cpp:43] Iteration 20990, lr = 0.02
I0526 07:08:27.911842 15394 main.cpp:465] Iteration 21000, Testing net (#0)
I0526 07:08:58.413043 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8255
I0526 07:08:58.413094 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.514456 (* 1 = 0.514456 loss)
I0526 07:08:59.389554 15394 main.cpp:354] Iteration 21000, loss = 0.550162
I0526 07:08:59.389600 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.550161 (* 1 = 0.550161 loss)
I0526 07:08:59.389608 15394 sgd_solver.cpp:43] Iteration 21000, lr = 0.02
I0526 07:09:10.120132 15394 main.cpp:354] Iteration 21010, loss = 0.508486
I0526 07:09:10.120175 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.508486 (* 1 = 0.508486 loss)
I0526 07:09:10.120182 15394 sgd_solver.cpp:43] Iteration 21010, lr = 0.02
I0526 07:09:22.197670 15394 main.cpp:354] Iteration 21020, loss = 0.422317
I0526 07:09:22.197712 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.422317 (* 1 = 0.422317 loss)
I0526 07:09:22.197721 15394 sgd_solver.cpp:43] Iteration 21020, lr = 0.02
I0526 07:09:32.953673 15394 main.cpp:354] Iteration 21030, loss = 0.488268
I0526 07:09:32.953708 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.488268 (* 1 = 0.488268 loss)
I0526 07:09:32.953714 15394 sgd_solver.cpp:43] Iteration 21030, lr = 0.02
I0526 07:09:44.455891 15394 main.cpp:354] Iteration 21040, loss = 0.448829
I0526 07:09:44.455934 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.448829 (* 1 = 0.448829 loss)
I0526 07:09:44.455940 15394 sgd_solver.cpp:43] Iteration 21040, lr = 0.02
I0526 07:09:55.873206 15394 main.cpp:354] Iteration 21050, loss = 0.53296
I0526 07:09:55.873257 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.53296 (* 1 = 0.53296 loss)
I0526 07:09:55.873265 15394 sgd_solver.cpp:43] Iteration 21050, lr = 0.02
I0526 07:10:07.401180 15394 main.cpp:354] Iteration 21060, loss = 0.304157
I0526 07:10:07.401222 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.304157 (* 1 = 0.304157 loss)
I0526 07:10:07.401231 15394 sgd_solver.cpp:43] Iteration 21060, lr = 0.02
I0526 07:10:19.213620 15394 main.cpp:354] Iteration 21070, loss = 0.45997
I0526 07:10:19.213661 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.45997 (* 1 = 0.45997 loss)
I0526 07:10:19.213668 15394 sgd_solver.cpp:43] Iteration 21070, lr = 0.02
I0526 07:10:29.850195 15394 main.cpp:354] Iteration 21080, loss = 0.601517
I0526 07:10:29.850229 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.601517 (* 1 = 0.601517 loss)
I0526 07:10:29.850235 15394 sgd_solver.cpp:43] Iteration 21080, lr = 0.02
I0526 07:10:40.263535 15394 main.cpp:354] Iteration 21090, loss = 0.365005
I0526 07:10:40.263578 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.365005 (* 1 = 0.365005 loss)
I0526 07:10:40.263584 15394 sgd_solver.cpp:43] Iteration 21090, lr = 0.02
I0526 07:10:50.684679 15394 main.cpp:465] Iteration 21100, Testing net (#0)
I0526 07:11:21.197980 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8231
I0526 07:11:21.198019 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.529546 (* 1 = 0.529546 loss)
I0526 07:11:22.170198 15394 main.cpp:354] Iteration 21100, loss = 0.387508
I0526 07:11:22.170238 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.387507 (* 1 = 0.387507 loss)
I0526 07:11:22.170246 15394 sgd_solver.cpp:43] Iteration 21100, lr = 0.02
I0526 07:11:33.973682 15394 main.cpp:354] Iteration 21110, loss = 0.456313
I0526 07:11:33.973728 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.456313 (* 1 = 0.456313 loss)
I0526 07:11:33.973736 15394 sgd_solver.cpp:43] Iteration 21110, lr = 0.02
I0526 07:11:45.549859 15394 main.cpp:354] Iteration 21120, loss = 0.542226
I0526 07:11:45.549899 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.542226 (* 1 = 0.542226 loss)
I0526 07:11:45.549906 15394 sgd_solver.cpp:43] Iteration 21120, lr = 0.02
I0526 07:11:57.562299 15394 main.cpp:354] Iteration 21130, loss = 0.301216
I0526 07:11:57.562340 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.301215 (* 1 = 0.301215 loss)
I0526 07:11:57.562347 15394 sgd_solver.cpp:43] Iteration 21130, lr = 0.02
I0526 07:12:09.192795 15394 main.cpp:354] Iteration 21140, loss = 0.735255
I0526 07:12:09.192842 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.735254 (* 1 = 0.735254 loss)
I0526 07:12:09.192849 15394 sgd_solver.cpp:43] Iteration 21140, lr = 0.02
I0526 07:12:20.422242 15394 main.cpp:354] Iteration 21150, loss = 0.489287
I0526 07:12:20.422291 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.489287 (* 1 = 0.489287 loss)
I0526 07:12:20.422297 15394 sgd_solver.cpp:43] Iteration 21150, lr = 0.02
I0526 07:12:32.337216 15394 main.cpp:354] Iteration 21160, loss = 0.441391
I0526 07:12:32.337255 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.441391 (* 1 = 0.441391 loss)
I0526 07:12:32.337262 15394 sgd_solver.cpp:43] Iteration 21160, lr = 0.02
I0526 07:12:43.616948 15394 main.cpp:354] Iteration 21170, loss = 0.362487
I0526 07:12:43.616991 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.362486 (* 1 = 0.362486 loss)
I0526 07:12:43.616999 15394 sgd_solver.cpp:43] Iteration 21170, lr = 0.02
I0526 07:12:54.878840 15394 main.cpp:354] Iteration 21180, loss = 0.291506
I0526 07:12:54.878885 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.291506 (* 1 = 0.291506 loss)
I0526 07:12:54.878892 15394 sgd_solver.cpp:43] Iteration 21180, lr = 0.02
I0526 07:13:06.091696 15394 main.cpp:354] Iteration 21190, loss = 0.355139
I0526 07:13:06.091734 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.355139 (* 1 = 0.355139 loss)
I0526 07:13:06.091742 15394 sgd_solver.cpp:43] Iteration 21190, lr = 0.02
I0526 07:13:16.919929 15394 main.cpp:465] Iteration 21200, Testing net (#0)
I0526 07:13:47.482113 15394 main.cpp:532]     Test net output #0: Accuracy = 0.815
I0526 07:13:47.482151 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.567065 (* 1 = 0.567065 loss)
I0526 07:13:48.695785 15394 main.cpp:354] Iteration 21200, loss = 0.389837
I0526 07:13:48.695825 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.389836 (* 1 = 0.389836 loss)
I0526 07:13:48.695834 15394 sgd_solver.cpp:43] Iteration 21200, lr = 0.02
I0526 07:13:59.761339 15394 main.cpp:354] Iteration 21210, loss = 0.719861
I0526 07:13:59.761386 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.719861 (* 1 = 0.719861 loss)
I0526 07:13:59.761404 15394 sgd_solver.cpp:43] Iteration 21210, lr = 0.02
I0526 07:14:10.408540 15394 main.cpp:354] Iteration 21220, loss = 0.492395
I0526 07:14:10.408586 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.492394 (* 1 = 0.492394 loss)
I0526 07:14:10.408592 15394 sgd_solver.cpp:43] Iteration 21220, lr = 0.02
I0526 07:14:22.437243 15394 main.cpp:354] Iteration 21230, loss = 0.299549
I0526 07:14:22.437284 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.299549 (* 1 = 0.299549 loss)
I0526 07:14:22.437293 15394 sgd_solver.cpp:43] Iteration 21230, lr = 0.02
I0526 07:14:33.358278 15394 main.cpp:354] Iteration 21240, loss = 0.396841
I0526 07:14:33.358314 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.396841 (* 1 = 0.396841 loss)
I0526 07:14:33.358321 15394 sgd_solver.cpp:43] Iteration 21240, lr = 0.02
I0526 07:14:45.134925 15394 main.cpp:354] Iteration 21250, loss = 0.512708
I0526 07:14:45.134968 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.512708 (* 1 = 0.512708 loss)
I0526 07:14:45.134974 15394 sgd_solver.cpp:43] Iteration 21250, lr = 0.02
I0526 07:14:55.833505 15394 main.cpp:354] Iteration 21260, loss = 0.487692
I0526 07:14:55.833549 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.487692 (* 1 = 0.487692 loss)
I0526 07:14:55.833555 15394 sgd_solver.cpp:43] Iteration 21260, lr = 0.02
I0526 07:15:07.116420 15394 main.cpp:354] Iteration 21270, loss = 0.303062
I0526 07:15:07.116459 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.303061 (* 1 = 0.303061 loss)
I0526 07:15:07.116466 15394 sgd_solver.cpp:43] Iteration 21270, lr = 0.02
I0526 07:15:19.028314 15394 main.cpp:354] Iteration 21280, loss = 0.391859
I0526 07:15:19.028355 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.391858 (* 1 = 0.391858 loss)
I0526 07:15:19.028367 15394 sgd_solver.cpp:43] Iteration 21280, lr = 0.02
I0526 07:15:30.571892 15394 main.cpp:354] Iteration 21290, loss = 0.500087
I0526 07:15:30.571935 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.500087 (* 1 = 0.500087 loss)
I0526 07:15:30.571941 15394 sgd_solver.cpp:43] Iteration 21290, lr = 0.02
I0526 07:15:41.249858 15394 main.cpp:465] Iteration 21300, Testing net (#0)
I0526 07:16:11.792652 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7924
I0526 07:16:11.792707 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.647679 (* 1 = 0.647679 loss)
I0526 07:16:13.155810 15394 main.cpp:354] Iteration 21300, loss = 0.255076
I0526 07:16:13.155875 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.255076 (* 1 = 0.255076 loss)
I0526 07:16:13.155885 15394 sgd_solver.cpp:43] Iteration 21300, lr = 0.02
I0526 07:16:24.885505 15394 main.cpp:354] Iteration 21310, loss = 0.301679
I0526 07:16:24.885547 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.301679 (* 1 = 0.301679 loss)
I0526 07:16:24.885553 15394 sgd_solver.cpp:43] Iteration 21310, lr = 0.02
I0526 07:16:36.543488 15394 main.cpp:354] Iteration 21320, loss = 0.286957
I0526 07:16:36.543529 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.286957 (* 1 = 0.286957 loss)
I0526 07:16:36.543536 15394 sgd_solver.cpp:43] Iteration 21320, lr = 0.02
I0526 07:16:47.727537 15394 main.cpp:354] Iteration 21330, loss = 0.259475
I0526 07:16:47.727581 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.259475 (* 1 = 0.259475 loss)
I0526 07:16:47.727587 15394 sgd_solver.cpp:43] Iteration 21330, lr = 0.02
I0526 07:16:53.616986 15394 main.cpp:354] Iteration 21340, loss = 0.280388
I0526 07:16:53.617027 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.280388 (* 1 = 0.280388 loss)
I0526 07:16:53.617034 15394 sgd_solver.cpp:43] Iteration 21340, lr = 0.02
I0526 07:16:59.117820 15394 main.cpp:354] Iteration 21350, loss = 0.338769
I0526 07:16:59.117861 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.338769 (* 1 = 0.338769 loss)
I0526 07:16:59.117867 15394 sgd_solver.cpp:43] Iteration 21350, lr = 0.02
I0526 07:17:04.144348 15394 main.cpp:354] Iteration 21360, loss = 0.220208
I0526 07:17:04.144397 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.220208 (* 1 = 0.220208 loss)
I0526 07:17:04.144404 15394 sgd_solver.cpp:43] Iteration 21360, lr = 0.02
I0526 07:17:09.744915 15394 main.cpp:354] Iteration 21370, loss = 0.323181
I0526 07:17:09.744946 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.323181 (* 1 = 0.323181 loss)
I0526 07:17:09.744956 15394 sgd_solver.cpp:43] Iteration 21370, lr = 0.02
I0526 07:17:14.982154 15394 main.cpp:354] Iteration 21380, loss = 0.377594
I0526 07:17:14.982189 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.377593 (* 1 = 0.377593 loss)
I0526 07:17:14.982195 15394 sgd_solver.cpp:43] Iteration 21380, lr = 0.02
I0526 07:17:20.231150 15394 main.cpp:354] Iteration 21390, loss = 0.399265
I0526 07:17:20.231189 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.399265 (* 1 = 0.399265 loss)
I0526 07:17:20.231196 15394 sgd_solver.cpp:43] Iteration 21390, lr = 0.02
I0526 07:17:24.851187 15394 main.cpp:465] Iteration 21400, Testing net (#0)
I0526 07:17:38.014973 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7817
I0526 07:17:38.015012 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.693829 (* 1 = 0.693829 loss)
I0526 07:17:38.450882 15394 main.cpp:354] Iteration 21400, loss = 0.396178
I0526 07:17:38.450917 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.396177 (* 1 = 0.396177 loss)
I0526 07:17:38.450924 15394 sgd_solver.cpp:43] Iteration 21400, lr = 0.02
I0526 07:17:43.541472 15394 main.cpp:354] Iteration 21410, loss = 0.368374
I0526 07:17:43.541513 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.368374 (* 1 = 0.368374 loss)
I0526 07:17:43.541519 15394 sgd_solver.cpp:43] Iteration 21410, lr = 0.02
I0526 07:17:48.649021 15394 main.cpp:354] Iteration 21420, loss = 0.263083
I0526 07:17:48.649060 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.263082 (* 1 = 0.263082 loss)
I0526 07:17:48.649066 15394 sgd_solver.cpp:43] Iteration 21420, lr = 0.02
I0526 07:17:53.808948 15394 main.cpp:354] Iteration 21430, loss = 0.389768
I0526 07:17:53.808993 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.389768 (* 1 = 0.389768 loss)
I0526 07:17:53.809000 15394 sgd_solver.cpp:43] Iteration 21430, lr = 0.02
I0526 07:17:59.055142 15394 main.cpp:354] Iteration 21440, loss = 0.322647
I0526 07:17:59.055184 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.322646 (* 1 = 0.322646 loss)
I0526 07:17:59.055191 15394 sgd_solver.cpp:43] Iteration 21440, lr = 0.02
I0526 07:18:03.843855 15394 main.cpp:354] Iteration 21450, loss = 0.310901
I0526 07:18:03.843907 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.310901 (* 1 = 0.310901 loss)
I0526 07:18:03.843914 15394 sgd_solver.cpp:43] Iteration 21450, lr = 0.02
I0526 07:18:09.365231 15394 main.cpp:354] Iteration 21460, loss = 0.291714
I0526 07:18:09.365274 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.291714 (* 1 = 0.291714 loss)
I0526 07:18:09.365280 15394 sgd_solver.cpp:43] Iteration 21460, lr = 0.02
I0526 07:18:14.963433 15394 main.cpp:354] Iteration 21470, loss = 0.310066
I0526 07:18:14.963480 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.310066 (* 1 = 0.310066 loss)
I0526 07:18:14.963487 15394 sgd_solver.cpp:43] Iteration 21470, lr = 0.02
I0526 07:18:20.202312 15394 main.cpp:354] Iteration 21480, loss = 0.573168
I0526 07:18:20.202352 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.573168 (* 1 = 0.573168 loss)
I0526 07:18:20.202360 15394 sgd_solver.cpp:43] Iteration 21480, lr = 0.02
I0526 07:18:25.101128 15394 main.cpp:354] Iteration 21490, loss = 0.370932
I0526 07:18:25.101183 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.370932 (* 1 = 0.370932 loss)
I0526 07:18:25.101191 15394 sgd_solver.cpp:43] Iteration 21490, lr = 0.02
I0526 07:18:29.770042 15394 main.cpp:465] Iteration 21500, Testing net (#0)
I0526 07:18:42.920377 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8076
I0526 07:18:42.920418 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.577122 (* 1 = 0.577122 loss)
I0526 07:18:43.432081 15394 main.cpp:354] Iteration 21500, loss = 0.382608
I0526 07:18:43.432118 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.382608 (* 1 = 0.382608 loss)
I0526 07:18:43.432126 15394 sgd_solver.cpp:43] Iteration 21500, lr = 0.02
I0526 07:18:48.934564 15394 main.cpp:354] Iteration 21510, loss = 0.40451
I0526 07:18:48.934603 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.40451 (* 1 = 0.40451 loss)
I0526 07:18:48.934612 15394 sgd_solver.cpp:43] Iteration 21510, lr = 0.02
I0526 07:18:54.425045 15394 main.cpp:354] Iteration 21520, loss = 0.45359
I0526 07:18:54.425091 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.45359 (* 1 = 0.45359 loss)
I0526 07:18:54.425097 15394 sgd_solver.cpp:43] Iteration 21520, lr = 0.02
I0526 07:18:59.725677 15394 main.cpp:354] Iteration 21530, loss = 0.212959
I0526 07:18:59.725713 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.212959 (* 1 = 0.212959 loss)
I0526 07:18:59.725719 15394 sgd_solver.cpp:43] Iteration 21530, lr = 0.02
I0526 07:19:05.064273 15394 main.cpp:354] Iteration 21540, loss = 0.53936
I0526 07:19:05.064316 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.539359 (* 1 = 0.539359 loss)
I0526 07:19:05.064323 15394 sgd_solver.cpp:43] Iteration 21540, lr = 0.02
I0526 07:19:10.345422 15394 main.cpp:354] Iteration 21550, loss = 0.550563
I0526 07:19:10.345463 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.550562 (* 1 = 0.550562 loss)
I0526 07:19:10.345471 15394 sgd_solver.cpp:43] Iteration 21550, lr = 0.02
I0526 07:19:15.224964 15394 main.cpp:354] Iteration 21560, loss = 0.370778
I0526 07:19:15.225010 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.370778 (* 1 = 0.370778 loss)
I0526 07:19:15.225018 15394 sgd_solver.cpp:43] Iteration 21560, lr = 0.02
I0526 07:19:20.144268 15394 main.cpp:354] Iteration 21570, loss = 0.323523
I0526 07:19:20.144306 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.323522 (* 1 = 0.323522 loss)
I0526 07:19:20.144312 15394 sgd_solver.cpp:43] Iteration 21570, lr = 0.02
I0526 07:19:25.354087 15394 main.cpp:354] Iteration 21580, loss = 0.359336
I0526 07:19:25.354130 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.359336 (* 1 = 0.359336 loss)
I0526 07:19:25.354137 15394 sgd_solver.cpp:43] Iteration 21580, lr = 0.02
I0526 07:19:30.511011 15394 main.cpp:354] Iteration 21590, loss = 0.4427
I0526 07:19:30.511047 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.4427 (* 1 = 0.4427 loss)
I0526 07:19:30.511054 15394 sgd_solver.cpp:43] Iteration 21590, lr = 0.02
I0526 07:19:34.889284 15394 main.cpp:465] Iteration 21600, Testing net (#0)
I0526 07:19:48.037947 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8274
I0526 07:19:48.038002 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.53884 (* 1 = 0.53884 loss)
I0526 07:19:48.474702 15394 main.cpp:354] Iteration 21600, loss = 0.453704
I0526 07:19:48.474723 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.453704 (* 1 = 0.453704 loss)
I0526 07:19:48.474730 15394 sgd_solver.cpp:43] Iteration 21600, lr = 0.02
I0526 07:19:53.391927 15394 main.cpp:354] Iteration 21610, loss = 0.343308
I0526 07:19:53.391966 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.343307 (* 1 = 0.343307 loss)
I0526 07:19:53.391973 15394 sgd_solver.cpp:43] Iteration 21610, lr = 0.02
I0526 07:19:59.023551 15394 main.cpp:354] Iteration 21620, loss = 0.360348
I0526 07:19:59.023602 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.360347 (* 1 = 0.360347 loss)
I0526 07:19:59.023609 15394 sgd_solver.cpp:43] Iteration 21620, lr = 0.02
I0526 07:20:04.084414 15394 main.cpp:354] Iteration 21630, loss = 0.485199
I0526 07:20:04.084455 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.485199 (* 1 = 0.485199 loss)
I0526 07:20:04.084460 15394 sgd_solver.cpp:43] Iteration 21630, lr = 0.02
I0526 07:20:09.082492 15394 main.cpp:354] Iteration 21640, loss = 0.38304
I0526 07:20:09.082535 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.38304 (* 1 = 0.38304 loss)
I0526 07:20:09.082543 15394 sgd_solver.cpp:43] Iteration 21640, lr = 0.02
I0526 07:20:14.159461 15394 main.cpp:354] Iteration 21650, loss = 0.38935
I0526 07:20:14.159488 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.38935 (* 1 = 0.38935 loss)
I0526 07:20:14.159495 15394 sgd_solver.cpp:43] Iteration 21650, lr = 0.02
I0526 07:20:18.886718 15394 main.cpp:354] Iteration 21660, loss = 0.276977
I0526 07:20:18.886754 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.276977 (* 1 = 0.276977 loss)
I0526 07:20:18.886760 15394 sgd_solver.cpp:43] Iteration 21660, lr = 0.02
I0526 07:20:23.903758 15394 main.cpp:354] Iteration 21670, loss = 0.437815
I0526 07:20:23.903805 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.437815 (* 1 = 0.437815 loss)
I0526 07:20:23.903813 15394 sgd_solver.cpp:43] Iteration 21670, lr = 0.02
I0526 07:20:28.974998 15394 main.cpp:354] Iteration 21680, loss = 0.469022
I0526 07:20:28.975049 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.469022 (* 1 = 0.469022 loss)
I0526 07:20:28.975055 15394 sgd_solver.cpp:43] Iteration 21680, lr = 0.02
I0526 07:20:33.772454 15394 main.cpp:354] Iteration 21690, loss = 0.368317
I0526 07:20:33.772491 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.368317 (* 1 = 0.368317 loss)
I0526 07:20:33.772497 15394 sgd_solver.cpp:43] Iteration 21690, lr = 0.02
I0526 07:20:38.427047 15394 main.cpp:465] Iteration 21700, Testing net (#0)
I0526 07:20:51.566548 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8153
I0526 07:20:51.566593 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.57689 (* 1 = 0.57689 loss)
I0526 07:20:52.108387 15394 main.cpp:354] Iteration 21700, loss = 0.324697
I0526 07:20:52.108430 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.324697 (* 1 = 0.324697 loss)
I0526 07:20:52.108440 15394 sgd_solver.cpp:43] Iteration 21700, lr = 0.02
I0526 07:20:57.655422 15394 main.cpp:354] Iteration 21710, loss = 0.293097
I0526 07:20:57.655464 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.293097 (* 1 = 0.293097 loss)
I0526 07:20:57.655470 15394 sgd_solver.cpp:43] Iteration 21710, lr = 0.02
I0526 07:21:02.594714 15394 main.cpp:354] Iteration 21720, loss = 0.382634
I0526 07:21:02.594753 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.382634 (* 1 = 0.382634 loss)
I0526 07:21:02.594760 15394 sgd_solver.cpp:43] Iteration 21720, lr = 0.02
I0526 07:21:07.907495 15394 main.cpp:354] Iteration 21730, loss = 0.374706
I0526 07:21:07.907536 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.374706 (* 1 = 0.374706 loss)
I0526 07:21:07.907541 15394 sgd_solver.cpp:43] Iteration 21730, lr = 0.02
I0526 07:21:12.984102 15394 main.cpp:354] Iteration 21740, loss = 0.32753
I0526 07:21:12.984151 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.32753 (* 1 = 0.32753 loss)
I0526 07:21:12.984158 15394 sgd_solver.cpp:43] Iteration 21740, lr = 0.02
I0526 07:21:17.730362 15394 main.cpp:354] Iteration 21750, loss = 0.360182
I0526 07:21:17.730388 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.360182 (* 1 = 0.360182 loss)
I0526 07:21:17.730394 15394 sgd_solver.cpp:43] Iteration 21750, lr = 0.02
I0526 07:21:22.899523 15394 main.cpp:354] Iteration 21760, loss = 0.310281
I0526 07:21:22.899572 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.310281 (* 1 = 0.310281 loss)
I0526 07:21:22.899580 15394 sgd_solver.cpp:43] Iteration 21760, lr = 0.02
I0526 07:21:27.800596 15394 main.cpp:354] Iteration 21770, loss = 0.280213
I0526 07:21:27.800634 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.280213 (* 1 = 0.280213 loss)
I0526 07:21:27.800640 15394 sgd_solver.cpp:43] Iteration 21770, lr = 0.02
I0526 07:21:33.178571 15394 main.cpp:354] Iteration 21780, loss = 0.653896
I0526 07:21:33.178611 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.653895 (* 1 = 0.653895 loss)
I0526 07:21:33.178617 15394 sgd_solver.cpp:43] Iteration 21780, lr = 0.02
I0526 07:21:38.651417 15394 main.cpp:354] Iteration 21790, loss = 0.241851
I0526 07:21:38.651459 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.24185 (* 1 = 0.24185 loss)
I0526 07:21:38.651466 15394 sgd_solver.cpp:43] Iteration 21790, lr = 0.02
I0526 07:21:43.462414 15394 main.cpp:465] Iteration 21800, Testing net (#0)
I0526 07:21:56.554946 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7397
I0526 07:21:56.554986 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.896788 (* 1 = 0.896788 loss)
I0526 07:21:57.056797 15394 main.cpp:354] Iteration 21800, loss = 0.319867
I0526 07:21:57.056831 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.319867 (* 1 = 0.319867 loss)
I0526 07:21:57.056839 15394 sgd_solver.cpp:43] Iteration 21800, lr = 0.02
I0526 07:22:01.932430 15394 main.cpp:354] Iteration 21810, loss = 0.346623
I0526 07:22:01.932458 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.346622 (* 1 = 0.346622 loss)
I0526 07:22:01.932466 15394 sgd_solver.cpp:43] Iteration 21810, lr = 0.02
I0526 07:22:06.947342 15394 main.cpp:354] Iteration 21820, loss = 0.449259
I0526 07:22:06.947387 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.449259 (* 1 = 0.449259 loss)
I0526 07:22:06.947396 15394 sgd_solver.cpp:43] Iteration 21820, lr = 0.02
I0526 07:22:11.813740 15394 main.cpp:354] Iteration 21830, loss = 0.636659
I0526 07:22:11.813778 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.636659 (* 1 = 0.636659 loss)
I0526 07:22:11.813784 15394 sgd_solver.cpp:43] Iteration 21830, lr = 0.02
I0526 07:22:16.511790 15394 main.cpp:354] Iteration 21840, loss = 0.172322
I0526 07:22:16.511828 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.172322 (* 1 = 0.172322 loss)
I0526 07:22:16.511834 15394 sgd_solver.cpp:43] Iteration 21840, lr = 0.02
I0526 07:22:21.914201 15394 main.cpp:354] Iteration 21850, loss = 0.266696
I0526 07:22:21.914242 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.266696 (* 1 = 0.266696 loss)
I0526 07:22:21.914249 15394 sgd_solver.cpp:43] Iteration 21850, lr = 0.02
I0526 07:22:27.141312 15394 main.cpp:354] Iteration 21860, loss = 0.275813
I0526 07:22:27.141340 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.275813 (* 1 = 0.275813 loss)
I0526 07:22:27.141345 15394 sgd_solver.cpp:43] Iteration 21860, lr = 0.02
I0526 07:22:32.477718 15394 main.cpp:354] Iteration 21870, loss = 0.413944
I0526 07:22:32.477753 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.413944 (* 1 = 0.413944 loss)
I0526 07:22:32.477761 15394 sgd_solver.cpp:43] Iteration 21870, lr = 0.02
I0526 07:22:37.706912 15394 main.cpp:354] Iteration 21880, loss = 0.629726
I0526 07:22:37.706953 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.629726 (* 1 = 0.629726 loss)
I0526 07:22:37.706959 15394 sgd_solver.cpp:43] Iteration 21880, lr = 0.02
I0526 07:22:42.709604 15394 main.cpp:354] Iteration 21890, loss = 0.247716
I0526 07:22:42.709645 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.247716 (* 1 = 0.247716 loss)
I0526 07:22:42.709651 15394 sgd_solver.cpp:43] Iteration 21890, lr = 0.02
I0526 07:22:47.394484 15394 main.cpp:465] Iteration 21900, Testing net (#0)
I0526 07:23:00.476997 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8078
I0526 07:23:00.477036 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.590404 (* 1 = 0.590404 loss)
I0526 07:23:00.942387 15394 main.cpp:354] Iteration 21900, loss = 0.414163
I0526 07:23:00.942430 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.414162 (* 1 = 0.414162 loss)
I0526 07:23:00.942437 15394 sgd_solver.cpp:43] Iteration 21900, lr = 0.02
I0526 07:23:05.746752 15394 main.cpp:354] Iteration 21910, loss = 0.438324
I0526 07:23:05.746793 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.438323 (* 1 = 0.438323 loss)
I0526 07:23:05.746798 15394 sgd_solver.cpp:43] Iteration 21910, lr = 0.02
I0526 07:23:11.017396 15394 main.cpp:354] Iteration 21920, loss = 0.283686
I0526 07:23:11.017434 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.283686 (* 1 = 0.283686 loss)
I0526 07:23:11.017441 15394 sgd_solver.cpp:43] Iteration 21920, lr = 0.02
I0526 07:23:16.313235 15394 main.cpp:354] Iteration 21930, loss = 0.461753
I0526 07:23:16.313282 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.461753 (* 1 = 0.461753 loss)
I0526 07:23:16.313289 15394 sgd_solver.cpp:43] Iteration 21930, lr = 0.02
I0526 07:23:21.672579 15394 main.cpp:354] Iteration 21940, loss = 0.426565
I0526 07:23:21.672617 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.426565 (* 1 = 0.426565 loss)
I0526 07:23:21.672623 15394 sgd_solver.cpp:43] Iteration 21940, lr = 0.02
I0526 07:23:26.837330 15394 main.cpp:354] Iteration 21950, loss = 0.339189
I0526 07:23:26.837368 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.339189 (* 1 = 0.339189 loss)
I0526 07:23:26.837374 15394 sgd_solver.cpp:43] Iteration 21950, lr = 0.02
I0526 07:23:32.006434 15394 main.cpp:354] Iteration 21960, loss = 0.333278
I0526 07:23:32.006476 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.333278 (* 1 = 0.333278 loss)
I0526 07:23:32.006484 15394 sgd_solver.cpp:43] Iteration 21960, lr = 0.02
I0526 07:23:37.005244 15394 main.cpp:354] Iteration 21970, loss = 0.318654
I0526 07:23:37.005280 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.318654 (* 1 = 0.318654 loss)
I0526 07:23:37.005286 15394 sgd_solver.cpp:43] Iteration 21970, lr = 0.02
I0526 07:23:42.259897 15394 main.cpp:354] Iteration 21980, loss = 0.297583
I0526 07:23:42.259937 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.297582 (* 1 = 0.297582 loss)
I0526 07:23:42.259948 15394 sgd_solver.cpp:43] Iteration 21980, lr = 0.02
I0526 07:23:46.875085 15394 main.cpp:354] Iteration 21990, loss = 0.284932
I0526 07:23:46.875128 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.284931 (* 1 = 0.284931 loss)
I0526 07:23:46.875133 15394 sgd_solver.cpp:43] Iteration 21990, lr = 0.02
I0526 07:23:51.361273 15394 main.cpp:465] Iteration 22000, Testing net (#0)
I0526 07:24:04.447794 15394 main.cpp:532]     Test net output #0: Accuracy = 0.84
I0526 07:24:04.447835 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.47454 (* 1 = 0.47454 loss)
I0526 07:24:04.913851 15394 main.cpp:354] Iteration 22000, loss = 0.455617
I0526 07:24:04.913890 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.455616 (* 1 = 0.455616 loss)
I0526 07:24:04.913897 15394 sgd_solver.cpp:43] Iteration 22000, lr = 0.02
I0526 07:24:09.370040 15394 main.cpp:354] Iteration 22010, loss = 0.56643
I0526 07:24:09.370077 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.566429 (* 1 = 0.566429 loss)
I0526 07:24:09.370085 15394 sgd_solver.cpp:43] Iteration 22010, lr = 0.02
I0526 07:24:14.711426 15394 main.cpp:354] Iteration 22020, loss = 0.416503
I0526 07:24:14.711475 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.416503 (* 1 = 0.416503 loss)
I0526 07:24:14.711483 15394 sgd_solver.cpp:43] Iteration 22020, lr = 0.02
I0526 07:24:19.897063 15394 main.cpp:354] Iteration 22030, loss = 0.481341
I0526 07:24:19.897105 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.481341 (* 1 = 0.481341 loss)
I0526 07:24:19.897112 15394 sgd_solver.cpp:43] Iteration 22030, lr = 0.02
I0526 07:24:25.002238 15394 main.cpp:354] Iteration 22040, loss = 0.303008
I0526 07:24:25.002274 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.303007 (* 1 = 0.303007 loss)
I0526 07:24:25.002280 15394 sgd_solver.cpp:43] Iteration 22040, lr = 0.02
I0526 07:24:29.889191 15394 main.cpp:354] Iteration 22050, loss = 0.371188
I0526 07:24:29.889230 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.371188 (* 1 = 0.371188 loss)
I0526 07:24:29.889235 15394 sgd_solver.cpp:43] Iteration 22050, lr = 0.02
I0526 07:24:34.931846 15394 main.cpp:354] Iteration 22060, loss = 0.339678
I0526 07:24:34.931890 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.339678 (* 1 = 0.339678 loss)
I0526 07:24:34.931895 15394 sgd_solver.cpp:43] Iteration 22060, lr = 0.02
I0526 07:24:39.943073 15394 main.cpp:354] Iteration 22070, loss = 0.207294
I0526 07:24:39.943106 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.207294 (* 1 = 0.207294 loss)
I0526 07:24:39.943114 15394 sgd_solver.cpp:43] Iteration 22070, lr = 0.02
I0526 07:24:44.865638 15394 main.cpp:354] Iteration 22080, loss = 0.392066
I0526 07:24:44.865672 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.392066 (* 1 = 0.392066 loss)
I0526 07:24:44.865679 15394 sgd_solver.cpp:43] Iteration 22080, lr = 0.02
I0526 07:24:50.373185 15394 main.cpp:354] Iteration 22090, loss = 0.247512
I0526 07:24:50.373229 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.247512 (* 1 = 0.247512 loss)
I0526 07:24:50.373235 15394 sgd_solver.cpp:43] Iteration 22090, lr = 0.02
I0526 07:24:54.299247 15394 main.cpp:465] Iteration 22100, Testing net (#0)
I0526 07:25:07.369740 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8219
I0526 07:25:07.369784 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.535627 (* 1 = 0.535627 loss)
I0526 07:25:07.877777 15394 main.cpp:354] Iteration 22100, loss = 0.259815
I0526 07:25:07.877813 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.259814 (* 1 = 0.259814 loss)
I0526 07:25:07.877821 15394 sgd_solver.cpp:43] Iteration 22100, lr = 0.02
I0526 07:25:12.940345 15394 main.cpp:354] Iteration 22110, loss = 0.639458
I0526 07:25:12.940383 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.639458 (* 1 = 0.639458 loss)
I0526 07:25:12.940394 15394 sgd_solver.cpp:43] Iteration 22110, lr = 0.02
I0526 07:25:17.685109 15394 main.cpp:354] Iteration 22120, loss = 0.375903
I0526 07:25:17.685149 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.375902 (* 1 = 0.375902 loss)
I0526 07:25:17.685155 15394 sgd_solver.cpp:43] Iteration 22120, lr = 0.02
I0526 07:25:22.759078 15394 main.cpp:354] Iteration 22130, loss = 0.546445
I0526 07:25:22.759117 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.546445 (* 1 = 0.546445 loss)
I0526 07:25:22.759122 15394 sgd_solver.cpp:43] Iteration 22130, lr = 0.02
I0526 07:25:27.647047 15394 main.cpp:354] Iteration 22140, loss = 0.469593
I0526 07:25:27.647086 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.469592 (* 1 = 0.469592 loss)
I0526 07:25:27.647094 15394 sgd_solver.cpp:43] Iteration 22140, lr = 0.02
I0526 07:25:32.739701 15394 main.cpp:354] Iteration 22150, loss = 0.291899
I0526 07:25:32.739753 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.291899 (* 1 = 0.291899 loss)
I0526 07:25:32.739771 15394 sgd_solver.cpp:43] Iteration 22150, lr = 0.02
I0526 07:25:37.522927 15394 main.cpp:354] Iteration 22160, loss = 0.418226
I0526 07:25:37.522964 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.418226 (* 1 = 0.418226 loss)
I0526 07:25:37.522969 15394 sgd_solver.cpp:43] Iteration 22160, lr = 0.02
I0526 07:25:42.863852 15394 main.cpp:354] Iteration 22170, loss = 0.439193
I0526 07:25:42.863880 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.439193 (* 1 = 0.439193 loss)
I0526 07:25:42.863886 15394 sgd_solver.cpp:43] Iteration 22170, lr = 0.02
I0526 07:25:47.847080 15394 main.cpp:354] Iteration 22180, loss = 0.310293
I0526 07:25:47.847122 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.310292 (* 1 = 0.310292 loss)
I0526 07:25:47.847131 15394 sgd_solver.cpp:43] Iteration 22180, lr = 0.02
I0526 07:25:53.217835 15394 main.cpp:354] Iteration 22190, loss = 0.427502
I0526 07:25:53.217872 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.427502 (* 1 = 0.427502 loss)
I0526 07:25:53.217878 15394 sgd_solver.cpp:43] Iteration 22190, lr = 0.02
I0526 07:25:58.378427 15394 main.cpp:465] Iteration 22200, Testing net (#0)
I0526 07:26:11.462069 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7646
I0526 07:26:11.462111 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.725786 (* 1 = 0.725786 loss)
I0526 07:26:11.896611 15394 main.cpp:354] Iteration 22200, loss = 0.52619
I0526 07:26:11.896638 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.52619 (* 1 = 0.52619 loss)
I0526 07:26:11.896646 15394 sgd_solver.cpp:43] Iteration 22200, lr = 0.02
I0526 07:26:16.774492 15394 main.cpp:354] Iteration 22210, loss = 0.526801
I0526 07:26:16.774539 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.526801 (* 1 = 0.526801 loss)
I0526 07:26:16.774546 15394 sgd_solver.cpp:43] Iteration 22210, lr = 0.02
I0526 07:26:21.652678 15394 main.cpp:354] Iteration 22220, loss = 0.521862
I0526 07:26:21.652717 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.521861 (* 1 = 0.521861 loss)
I0526 07:26:21.652724 15394 sgd_solver.cpp:43] Iteration 22220, lr = 0.02
I0526 07:26:26.666182 15394 main.cpp:354] Iteration 22230, loss = 0.352492
I0526 07:26:26.666209 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.352492 (* 1 = 0.352492 loss)
I0526 07:26:26.666216 15394 sgd_solver.cpp:43] Iteration 22230, lr = 0.02
I0526 07:26:31.761260 15394 main.cpp:354] Iteration 22240, loss = 0.213066
I0526 07:26:31.761301 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.213066 (* 1 = 0.213066 loss)
I0526 07:26:31.761307 15394 sgd_solver.cpp:43] Iteration 22240, lr = 0.02
I0526 07:26:36.568403 15394 main.cpp:354] Iteration 22250, loss = 0.318613
I0526 07:26:36.568440 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.318613 (* 1 = 0.318613 loss)
I0526 07:26:36.568446 15394 sgd_solver.cpp:43] Iteration 22250, lr = 0.02
I0526 07:26:42.087079 15394 main.cpp:354] Iteration 22260, loss = 0.300786
I0526 07:26:42.087122 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.300786 (* 1 = 0.300786 loss)
I0526 07:26:42.087131 15394 sgd_solver.cpp:43] Iteration 22260, lr = 0.02
I0526 07:26:47.009063 15394 main.cpp:354] Iteration 22270, loss = 0.573516
I0526 07:26:47.009106 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.573516 (* 1 = 0.573516 loss)
I0526 07:26:47.009112 15394 sgd_solver.cpp:43] Iteration 22270, lr = 0.02
I0526 07:26:51.994829 15394 main.cpp:354] Iteration 22280, loss = 0.396169
I0526 07:26:51.994863 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.396169 (* 1 = 0.396169 loss)
I0526 07:26:51.994868 15394 sgd_solver.cpp:43] Iteration 22280, lr = 0.02
I0526 07:26:56.901362 15394 main.cpp:354] Iteration 22290, loss = 0.285023
I0526 07:26:56.901401 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.285023 (* 1 = 0.285023 loss)
I0526 07:26:56.901407 15394 sgd_solver.cpp:43] Iteration 22290, lr = 0.02
I0526 07:27:01.523157 15394 main.cpp:465] Iteration 22300, Testing net (#0)
I0526 07:27:14.596545 15394 main.cpp:532]     Test net output #0: Accuracy = 0.802
I0526 07:27:14.596585 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.625942 (* 1 = 0.625942 loss)
I0526 07:27:15.171509 15394 main.cpp:354] Iteration 22300, loss = 0.277625
I0526 07:27:15.171530 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.277624 (* 1 = 0.277624 loss)
I0526 07:27:15.171538 15394 sgd_solver.cpp:43] Iteration 22300, lr = 0.02
I0526 07:27:20.268318 15394 main.cpp:354] Iteration 22310, loss = 0.275828
I0526 07:27:20.268358 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.275828 (* 1 = 0.275828 loss)
I0526 07:27:20.268365 15394 sgd_solver.cpp:43] Iteration 22310, lr = 0.02
I0526 07:27:24.843431 15394 main.cpp:354] Iteration 22320, loss = 0.295238
I0526 07:27:24.843472 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.295238 (* 1 = 0.295238 loss)
I0526 07:27:24.843477 15394 sgd_solver.cpp:43] Iteration 22320, lr = 0.02
I0526 07:27:29.904110 15394 main.cpp:354] Iteration 22330, loss = 0.210354
I0526 07:27:29.904142 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.210354 (* 1 = 0.210354 loss)
I0526 07:27:29.904150 15394 sgd_solver.cpp:43] Iteration 22330, lr = 0.02
I0526 07:27:35.101346 15394 main.cpp:354] Iteration 22340, loss = 0.455711
I0526 07:27:35.101387 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.455711 (* 1 = 0.455711 loss)
I0526 07:27:35.101392 15394 sgd_solver.cpp:43] Iteration 22340, lr = 0.02
I0526 07:27:40.119647 15394 main.cpp:354] Iteration 22350, loss = 0.348861
I0526 07:27:40.119686 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.348861 (* 1 = 0.348861 loss)
I0526 07:27:40.119693 15394 sgd_solver.cpp:43] Iteration 22350, lr = 0.02
I0526 07:27:45.204040 15394 main.cpp:354] Iteration 22360, loss = 0.264895
I0526 07:27:45.204077 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.264895 (* 1 = 0.264895 loss)
I0526 07:27:45.204085 15394 sgd_solver.cpp:43] Iteration 22360, lr = 0.02
I0526 07:27:50.474436 15394 main.cpp:354] Iteration 22370, loss = 0.40083
I0526 07:27:50.474474 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.40083 (* 1 = 0.40083 loss)
I0526 07:27:50.474481 15394 sgd_solver.cpp:43] Iteration 22370, lr = 0.02
I0526 07:27:55.282140 15394 main.cpp:354] Iteration 22380, loss = 0.50243
I0526 07:27:55.282177 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.50243 (* 1 = 0.50243 loss)
I0526 07:27:55.282184 15394 sgd_solver.cpp:43] Iteration 22380, lr = 0.02
I0526 07:28:00.157805 15394 main.cpp:354] Iteration 22390, loss = 0.454998
I0526 07:28:00.157847 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.454998 (* 1 = 0.454998 loss)
I0526 07:28:00.157855 15394 sgd_solver.cpp:43] Iteration 22390, lr = 0.02
I0526 07:28:04.212481 15394 main.cpp:465] Iteration 22400, Testing net (#0)
I0526 07:28:17.282311 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7575
I0526 07:28:17.282376 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.825559 (* 1 = 0.825559 loss)
I0526 07:28:17.716070 15394 main.cpp:354] Iteration 22400, loss = 0.464734
I0526 07:28:17.716109 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.464734 (* 1 = 0.464734 loss)
I0526 07:28:17.716116 15394 sgd_solver.cpp:43] Iteration 22400, lr = 0.02
I0526 07:28:23.071496 15394 main.cpp:354] Iteration 22410, loss = 0.531115
I0526 07:28:23.071533 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.531115 (* 1 = 0.531115 loss)
I0526 07:28:23.071539 15394 sgd_solver.cpp:43] Iteration 22410, lr = 0.02
I0526 07:28:28.016805 15394 main.cpp:354] Iteration 22420, loss = 0.411802
I0526 07:28:28.016844 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.411802 (* 1 = 0.411802 loss)
I0526 07:28:28.016849 15394 sgd_solver.cpp:43] Iteration 22420, lr = 0.02
I0526 07:28:33.335119 15394 main.cpp:354] Iteration 22430, loss = 0.236028
I0526 07:28:33.335158 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.236028 (* 1 = 0.236028 loss)
I0526 07:28:33.335165 15394 sgd_solver.cpp:43] Iteration 22430, lr = 0.02
I0526 07:28:38.629580 15394 main.cpp:354] Iteration 22440, loss = 0.316834
I0526 07:28:38.629621 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.316834 (* 1 = 0.316834 loss)
I0526 07:28:38.629626 15394 sgd_solver.cpp:43] Iteration 22440, lr = 0.02
I0526 07:28:43.552291 15394 main.cpp:354] Iteration 22450, loss = 0.650702
I0526 07:28:43.552330 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.650702 (* 1 = 0.650702 loss)
I0526 07:28:43.552335 15394 sgd_solver.cpp:43] Iteration 22450, lr = 0.02
I0526 07:28:48.364984 15394 main.cpp:354] Iteration 22460, loss = 0.237977
I0526 07:28:48.365022 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.237977 (* 1 = 0.237977 loss)
I0526 07:28:48.365030 15394 sgd_solver.cpp:43] Iteration 22460, lr = 0.02
I0526 07:28:53.514631 15394 main.cpp:354] Iteration 22470, loss = 0.360128
I0526 07:28:53.514672 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.360128 (* 1 = 0.360128 loss)
I0526 07:28:53.514678 15394 sgd_solver.cpp:43] Iteration 22470, lr = 0.02
I0526 07:28:58.373296 15394 main.cpp:354] Iteration 22480, loss = 0.709406
I0526 07:28:58.373332 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.709406 (* 1 = 0.709406 loss)
I0526 07:28:58.373337 15394 sgd_solver.cpp:43] Iteration 22480, lr = 0.02
I0526 07:29:03.347295 15394 main.cpp:354] Iteration 22490, loss = 0.556918
I0526 07:29:03.347338 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.556918 (* 1 = 0.556918 loss)
I0526 07:29:03.347345 15394 sgd_solver.cpp:43] Iteration 22490, lr = 0.02
I0526 07:29:07.587983 15394 main.cpp:465] Iteration 22500, Testing net (#0)
I0526 07:29:20.667117 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8004
I0526 07:29:20.667157 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.673313 (* 1 = 0.673313 loss)
I0526 07:29:21.133268 15394 main.cpp:354] Iteration 22500, loss = 0.472348
I0526 07:29:21.133311 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.472348 (* 1 = 0.472348 loss)
I0526 07:29:21.133319 15394 sgd_solver.cpp:43] Iteration 22500, lr = 0.02
I0526 07:29:26.640115 15394 main.cpp:354] Iteration 22510, loss = 0.362826
I0526 07:29:26.640156 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.362826 (* 1 = 0.362826 loss)
I0526 07:29:26.640162 15394 sgd_solver.cpp:43] Iteration 22510, lr = 0.02
I0526 07:29:32.151206 15394 main.cpp:354] Iteration 22520, loss = 0.458849
I0526 07:29:32.151249 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.458849 (* 1 = 0.458849 loss)
I0526 07:29:32.151255 15394 sgd_solver.cpp:43] Iteration 22520, lr = 0.02
I0526 07:29:37.105998 15394 main.cpp:354] Iteration 22530, loss = 0.594238
I0526 07:29:37.106040 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.594237 (* 1 = 0.594237 loss)
I0526 07:29:37.106047 15394 sgd_solver.cpp:43] Iteration 22530, lr = 0.02
I0526 07:29:41.972235 15394 main.cpp:354] Iteration 22540, loss = 0.600011
I0526 07:29:41.972275 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.600011 (* 1 = 0.600011 loss)
I0526 07:29:41.972281 15394 sgd_solver.cpp:43] Iteration 22540, lr = 0.02
I0526 07:29:47.005828 15394 main.cpp:354] Iteration 22550, loss = 0.3458
I0526 07:29:47.005868 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.3458 (* 1 = 0.3458 loss)
I0526 07:29:47.005874 15394 sgd_solver.cpp:43] Iteration 22550, lr = 0.02
I0526 07:29:51.990098 15394 main.cpp:354] Iteration 22560, loss = 0.329259
I0526 07:29:51.990140 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.329259 (* 1 = 0.329259 loss)
I0526 07:29:51.990146 15394 sgd_solver.cpp:43] Iteration 22560, lr = 0.02
I0526 07:29:56.924964 15394 main.cpp:354] Iteration 22570, loss = 0.351218
I0526 07:29:56.925004 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.351218 (* 1 = 0.351218 loss)
I0526 07:29:56.925009 15394 sgd_solver.cpp:43] Iteration 22570, lr = 0.02
I0526 07:30:01.773368 15394 main.cpp:354] Iteration 22580, loss = 0.265733
I0526 07:30:01.773409 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.265733 (* 1 = 0.265733 loss)
I0526 07:30:01.773416 15394 sgd_solver.cpp:43] Iteration 22580, lr = 0.02
I0526 07:30:07.031394 15394 main.cpp:354] Iteration 22590, loss = 0.486021
I0526 07:30:07.031431 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.486021 (* 1 = 0.486021 loss)
I0526 07:30:07.031437 15394 sgd_solver.cpp:43] Iteration 22590, lr = 0.02
I0526 07:30:11.623411 15394 main.cpp:465] Iteration 22600, Testing net (#0)
I0526 07:30:24.707278 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8065
I0526 07:30:24.707316 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.624137 (* 1 = 0.624137 loss)
I0526 07:30:25.245791 15394 main.cpp:354] Iteration 22600, loss = 0.300904
I0526 07:30:25.245826 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.300904 (* 1 = 0.300904 loss)
I0526 07:30:25.245834 15394 sgd_solver.cpp:43] Iteration 22600, lr = 0.02
I0526 07:30:30.346133 15394 main.cpp:354] Iteration 22610, loss = 0.488871
I0526 07:30:30.346177 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.488871 (* 1 = 0.488871 loss)
I0526 07:30:30.346186 15394 sgd_solver.cpp:43] Iteration 22610, lr = 0.02
I0526 07:30:35.785362 15394 main.cpp:354] Iteration 22620, loss = 0.187585
I0526 07:30:35.785401 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187585 (* 1 = 0.187585 loss)
I0526 07:30:35.785408 15394 sgd_solver.cpp:43] Iteration 22620, lr = 0.02
I0526 07:30:40.778741 15394 main.cpp:354] Iteration 22630, loss = 0.416762
I0526 07:30:40.778781 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.416762 (* 1 = 0.416762 loss)
I0526 07:30:40.778789 15394 sgd_solver.cpp:43] Iteration 22630, lr = 0.02
I0526 07:30:45.769240 15394 main.cpp:354] Iteration 22640, loss = 0.38983
I0526 07:30:45.769279 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.38983 (* 1 = 0.38983 loss)
I0526 07:30:45.769286 15394 sgd_solver.cpp:43] Iteration 22640, lr = 0.02
I0526 07:30:50.227892 15394 main.cpp:354] Iteration 22650, loss = 0.468301
I0526 07:30:50.227927 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.468301 (* 1 = 0.468301 loss)
I0526 07:30:50.227934 15394 sgd_solver.cpp:43] Iteration 22650, lr = 0.02
I0526 07:30:55.173219 15394 main.cpp:354] Iteration 22660, loss = 0.419934
I0526 07:30:55.173255 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.419934 (* 1 = 0.419934 loss)
I0526 07:30:55.173260 15394 sgd_solver.cpp:43] Iteration 22660, lr = 0.02
I0526 07:31:00.396572 15394 main.cpp:354] Iteration 22670, loss = 0.304006
I0526 07:31:00.396615 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.304005 (* 1 = 0.304005 loss)
I0526 07:31:00.396622 15394 sgd_solver.cpp:43] Iteration 22670, lr = 0.02
I0526 07:31:05.465430 15394 main.cpp:354] Iteration 22680, loss = 0.255755
I0526 07:31:05.465471 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.255755 (* 1 = 0.255755 loss)
I0526 07:31:05.465477 15394 sgd_solver.cpp:43] Iteration 22680, lr = 0.02
I0526 07:31:10.212375 15394 main.cpp:354] Iteration 22690, loss = 0.249224
I0526 07:31:10.212412 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.249224 (* 1 = 0.249224 loss)
I0526 07:31:10.212419 15394 sgd_solver.cpp:43] Iteration 22690, lr = 0.02
I0526 07:31:14.884229 15394 main.cpp:465] Iteration 22700, Testing net (#0)
I0526 07:31:27.967789 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7638
I0526 07:31:27.967829 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.829743 (* 1 = 0.829743 loss)
I0526 07:31:28.404816 15394 main.cpp:354] Iteration 22700, loss = 0.406721
I0526 07:31:28.404853 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.406721 (* 1 = 0.406721 loss)
I0526 07:31:28.404860 15394 sgd_solver.cpp:43] Iteration 22700, lr = 0.02
I0526 07:31:33.777232 15394 main.cpp:354] Iteration 22710, loss = 0.258007
I0526 07:31:33.777274 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.258007 (* 1 = 0.258007 loss)
I0526 07:31:33.777281 15394 sgd_solver.cpp:43] Iteration 22710, lr = 0.02
I0526 07:31:38.647441 15394 main.cpp:354] Iteration 22720, loss = 0.362049
I0526 07:31:38.647485 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.362049 (* 1 = 0.362049 loss)
I0526 07:31:38.647490 15394 sgd_solver.cpp:43] Iteration 22720, lr = 0.02
I0526 07:31:44.168632 15394 main.cpp:354] Iteration 22730, loss = 0.247738
I0526 07:31:44.168673 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.247738 (* 1 = 0.247738 loss)
I0526 07:31:44.168680 15394 sgd_solver.cpp:43] Iteration 22730, lr = 0.02
I0526 07:31:49.260829 15394 main.cpp:354] Iteration 22740, loss = 0.328599
I0526 07:31:49.260869 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.328598 (* 1 = 0.328598 loss)
I0526 07:31:49.260876 15394 sgd_solver.cpp:43] Iteration 22740, lr = 0.02
I0526 07:31:54.087986 15394 main.cpp:354] Iteration 22750, loss = 0.343759
I0526 07:31:54.088016 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.343758 (* 1 = 0.343758 loss)
I0526 07:31:54.088023 15394 sgd_solver.cpp:43] Iteration 22750, lr = 0.02
I0526 07:31:59.403300 15394 main.cpp:354] Iteration 22760, loss = 0.528076
I0526 07:31:59.403339 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.528076 (* 1 = 0.528076 loss)
I0526 07:31:59.403347 15394 sgd_solver.cpp:43] Iteration 22760, lr = 0.02
I0526 07:32:04.287173 15394 main.cpp:354] Iteration 22770, loss = 0.306695
I0526 07:32:04.287209 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.306695 (* 1 = 0.306695 loss)
I0526 07:32:04.287215 15394 sgd_solver.cpp:43] Iteration 22770, lr = 0.02
I0526 07:32:09.633821 15394 main.cpp:354] Iteration 22780, loss = 0.717635
I0526 07:32:09.633863 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.717635 (* 1 = 0.717635 loss)
I0526 07:32:09.633869 15394 sgd_solver.cpp:43] Iteration 22780, lr = 0.02
I0526 07:32:15.083253 15394 main.cpp:354] Iteration 22790, loss = 0.244577
I0526 07:32:15.083290 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.244576 (* 1 = 0.244576 loss)
I0526 07:32:15.083297 15394 sgd_solver.cpp:43] Iteration 22790, lr = 0.02
I0526 07:32:19.570965 15394 main.cpp:465] Iteration 22800, Testing net (#0)
I0526 07:32:32.646500 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8282
I0526 07:32:32.646543 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.505992 (* 1 = 0.505992 loss)
I0526 07:32:33.221323 15394 main.cpp:354] Iteration 22800, loss = 0.40808
I0526 07:32:33.221357 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.40808 (* 1 = 0.40808 loss)
I0526 07:32:33.221365 15394 sgd_solver.cpp:43] Iteration 22800, lr = 0.02
I0526 07:32:38.001482 15394 main.cpp:354] Iteration 22810, loss = 0.225607
I0526 07:32:38.001519 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.225606 (* 1 = 0.225606 loss)
I0526 07:32:38.001533 15394 sgd_solver.cpp:43] Iteration 22810, lr = 0.02
I0526 07:32:42.977186 15394 main.cpp:354] Iteration 22820, loss = 0.546205
I0526 07:32:42.977226 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.546205 (* 1 = 0.546205 loss)
I0526 07:32:42.977231 15394 sgd_solver.cpp:43] Iteration 22820, lr = 0.02
I0526 07:32:48.012018 15394 main.cpp:354] Iteration 22830, loss = 0.397536
I0526 07:32:48.012058 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.397535 (* 1 = 0.397535 loss)
I0526 07:32:48.012063 15394 sgd_solver.cpp:43] Iteration 22830, lr = 0.02
I0526 07:32:53.434322 15394 main.cpp:354] Iteration 22840, loss = 0.369267
I0526 07:32:53.434378 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.369267 (* 1 = 0.369267 loss)
I0526 07:32:53.434397 15394 sgd_solver.cpp:43] Iteration 22840, lr = 0.02
I0526 07:32:59.029110 15394 main.cpp:354] Iteration 22850, loss = 0.256883
I0526 07:32:59.029152 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.256883 (* 1 = 0.256883 loss)
I0526 07:32:59.029161 15394 sgd_solver.cpp:43] Iteration 22850, lr = 0.02
I0526 07:33:03.575251 15394 main.cpp:354] Iteration 22860, loss = 0.274839
I0526 07:33:03.575291 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.274839 (* 1 = 0.274839 loss)
I0526 07:33:03.575299 15394 sgd_solver.cpp:43] Iteration 22860, lr = 0.02
I0526 07:33:08.975767 15394 main.cpp:354] Iteration 22870, loss = 0.167683
I0526 07:33:08.975808 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.167683 (* 1 = 0.167683 loss)
I0526 07:33:08.975816 15394 sgd_solver.cpp:43] Iteration 22870, lr = 0.02
I0526 07:33:13.935120 15394 main.cpp:354] Iteration 22880, loss = 0.410744
I0526 07:33:13.935159 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.410744 (* 1 = 0.410744 loss)
I0526 07:33:13.935166 15394 sgd_solver.cpp:43] Iteration 22880, lr = 0.02
I0526 07:33:18.543639 15394 main.cpp:354] Iteration 22890, loss = 0.375284
I0526 07:33:18.543678 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.375284 (* 1 = 0.375284 loss)
I0526 07:33:18.543684 15394 sgd_solver.cpp:43] Iteration 22890, lr = 0.02
I0526 07:33:23.098611 15394 main.cpp:465] Iteration 22900, Testing net (#0)
I0526 07:33:36.181625 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7729
I0526 07:33:36.181665 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.76037 (* 1 = 0.76037 loss)
I0526 07:33:36.648066 15394 main.cpp:354] Iteration 22900, loss = 0.234011
I0526 07:33:36.648102 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.234011 (* 1 = 0.234011 loss)
I0526 07:33:36.648109 15394 sgd_solver.cpp:43] Iteration 22900, lr = 0.02
I0526 07:33:41.733917 15394 main.cpp:354] Iteration 22910, loss = 0.503667
I0526 07:33:41.733952 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.503667 (* 1 = 0.503667 loss)
I0526 07:33:41.733958 15394 sgd_solver.cpp:43] Iteration 22910, lr = 0.02
I0526 07:33:46.724982 15394 main.cpp:354] Iteration 22920, loss = 0.404768
I0526 07:33:46.725019 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.404768 (* 1 = 0.404768 loss)
I0526 07:33:46.725025 15394 sgd_solver.cpp:43] Iteration 22920, lr = 0.02
I0526 07:33:52.172273 15394 main.cpp:354] Iteration 22930, loss = 0.378859
I0526 07:33:52.172312 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.378859 (* 1 = 0.378859 loss)
I0526 07:33:52.172318 15394 sgd_solver.cpp:43] Iteration 22930, lr = 0.02
I0526 07:33:57.473781 15394 main.cpp:354] Iteration 22940, loss = 0.227515
I0526 07:33:57.473825 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.227514 (* 1 = 0.227514 loss)
I0526 07:33:57.473832 15394 sgd_solver.cpp:43] Iteration 22940, lr = 0.02
I0526 07:34:02.136204 15394 main.cpp:354] Iteration 22950, loss = 0.528133
I0526 07:34:02.136243 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.528132 (* 1 = 0.528132 loss)
I0526 07:34:02.136250 15394 sgd_solver.cpp:43] Iteration 22950, lr = 0.02
I0526 07:34:07.363639 15394 main.cpp:354] Iteration 22960, loss = 0.276392
I0526 07:34:07.363678 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.276392 (* 1 = 0.276392 loss)
I0526 07:34:07.363685 15394 sgd_solver.cpp:43] Iteration 22960, lr = 0.02
I0526 07:34:12.026329 15394 main.cpp:354] Iteration 22970, loss = 0.465323
I0526 07:34:12.026374 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.465323 (* 1 = 0.465323 loss)
I0526 07:34:12.026381 15394 sgd_solver.cpp:43] Iteration 22970, lr = 0.02
I0526 07:34:17.456331 15394 main.cpp:354] Iteration 22980, loss = 0.283844
I0526 07:34:17.456372 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.283844 (* 1 = 0.283844 loss)
I0526 07:34:17.456378 15394 sgd_solver.cpp:43] Iteration 22980, lr = 0.02
I0526 07:34:22.415702 15394 main.cpp:354] Iteration 22990, loss = 0.492498
I0526 07:34:22.415742 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.492498 (* 1 = 0.492498 loss)
I0526 07:34:22.415750 15394 sgd_solver.cpp:43] Iteration 22990, lr = 0.02
I0526 07:34:26.827862 15394 main.cpp:465] Iteration 23000, Testing net (#0)
I0526 07:34:39.899772 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8171
I0526 07:34:39.899811 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.555281 (* 1 = 0.555281 loss)
I0526 07:34:40.437870 15394 main.cpp:354] Iteration 23000, loss = 0.33123
I0526 07:34:40.437903 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.331229 (* 1 = 0.331229 loss)
I0526 07:34:40.437911 15394 sgd_solver.cpp:43] Iteration 23000, lr = 0.02
I0526 07:34:45.853606 15394 main.cpp:354] Iteration 23010, loss = 0.223038
I0526 07:34:45.853644 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.223038 (* 1 = 0.223038 loss)
I0526 07:34:45.853652 15394 sgd_solver.cpp:43] Iteration 23010, lr = 0.02
I0526 07:34:50.965476 15394 main.cpp:354] Iteration 23020, loss = 0.318515
I0526 07:34:50.965512 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.318514 (* 1 = 0.318514 loss)
I0526 07:34:50.965518 15394 sgd_solver.cpp:43] Iteration 23020, lr = 0.02
I0526 07:34:55.990659 15394 main.cpp:354] Iteration 23030, loss = 0.481945
I0526 07:34:55.990700 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.481945 (* 1 = 0.481945 loss)
I0526 07:34:55.990705 15394 sgd_solver.cpp:43] Iteration 23030, lr = 0.02
I0526 07:35:00.729854 15394 main.cpp:354] Iteration 23040, loss = 0.284179
I0526 07:35:00.729894 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.284179 (* 1 = 0.284179 loss)
I0526 07:35:00.729902 15394 sgd_solver.cpp:43] Iteration 23040, lr = 0.02
I0526 07:35:05.582458 15394 main.cpp:354] Iteration 23050, loss = 0.270413
I0526 07:35:05.582494 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.270413 (* 1 = 0.270413 loss)
I0526 07:35:05.582499 15394 sgd_solver.cpp:43] Iteration 23050, lr = 0.02
I0526 07:35:10.728107 15394 main.cpp:354] Iteration 23060, loss = 0.44467
I0526 07:35:10.728150 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.44467 (* 1 = 0.44467 loss)
I0526 07:35:10.728157 15394 sgd_solver.cpp:43] Iteration 23060, lr = 0.02
I0526 07:35:16.233407 15394 main.cpp:354] Iteration 23070, loss = 0.305921
I0526 07:35:16.233438 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.305921 (* 1 = 0.305921 loss)
I0526 07:35:16.233443 15394 sgd_solver.cpp:43] Iteration 23070, lr = 0.02
I0526 07:35:21.464926 15394 main.cpp:354] Iteration 23080, loss = 0.873071
I0526 07:35:21.464962 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.873071 (* 1 = 0.873071 loss)
I0526 07:35:21.464969 15394 sgd_solver.cpp:43] Iteration 23080, lr = 0.02
I0526 07:35:26.409277 15394 main.cpp:354] Iteration 23090, loss = 0.303998
I0526 07:35:26.409317 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.303998 (* 1 = 0.303998 loss)
I0526 07:35:26.409323 15394 sgd_solver.cpp:43] Iteration 23090, lr = 0.02
I0526 07:35:31.337057 15394 main.cpp:465] Iteration 23100, Testing net (#0)
I0526 07:35:44.417811 15394 main.cpp:532]     Test net output #0: Accuracy = 0.855
I0526 07:35:44.417850 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.433315 (* 1 = 0.433315 loss)
I0526 07:35:44.960661 15394 main.cpp:354] Iteration 23100, loss = 0.386463
I0526 07:35:44.960703 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.386463 (* 1 = 0.386463 loss)
I0526 07:35:44.960711 15394 sgd_solver.cpp:43] Iteration 23100, lr = 0.02
I0526 07:35:49.991533 15394 main.cpp:354] Iteration 23110, loss = 0.548963
I0526 07:35:49.991572 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.548962 (* 1 = 0.548962 loss)
I0526 07:35:49.991578 15394 sgd_solver.cpp:43] Iteration 23110, lr = 0.02
I0526 07:35:55.061892 15394 main.cpp:354] Iteration 23120, loss = 0.442939
I0526 07:35:55.061935 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.442939 (* 1 = 0.442939 loss)
I0526 07:35:55.061941 15394 sgd_solver.cpp:43] Iteration 23120, lr = 0.02
I0526 07:36:00.210121 15394 main.cpp:354] Iteration 23130, loss = 0.272678
I0526 07:36:00.210160 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.272678 (* 1 = 0.272678 loss)
I0526 07:36:00.210167 15394 sgd_solver.cpp:43] Iteration 23130, lr = 0.02
I0526 07:36:05.085453 15394 main.cpp:354] Iteration 23140, loss = 0.297766
I0526 07:36:05.085492 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.297766 (* 1 = 0.297766 loss)
I0526 07:36:05.085500 15394 sgd_solver.cpp:43] Iteration 23140, lr = 0.02
I0526 07:36:09.683650 15394 main.cpp:354] Iteration 23150, loss = 0.562771
I0526 07:36:09.683691 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.562771 (* 1 = 0.562771 loss)
I0526 07:36:09.683701 15394 sgd_solver.cpp:43] Iteration 23150, lr = 0.02
I0526 07:36:14.897300 15394 main.cpp:354] Iteration 23160, loss = 0.370866
I0526 07:36:14.897339 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.370866 (* 1 = 0.370866 loss)
I0526 07:36:14.897344 15394 sgd_solver.cpp:43] Iteration 23160, lr = 0.02
I0526 07:36:20.049059 15394 main.cpp:354] Iteration 23170, loss = 0.302822
I0526 07:36:20.049098 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.302821 (* 1 = 0.302821 loss)
I0526 07:36:20.049104 15394 sgd_solver.cpp:43] Iteration 23170, lr = 0.02
I0526 07:36:25.156018 15394 main.cpp:354] Iteration 23180, loss = 0.335688
I0526 07:36:25.156062 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.335688 (* 1 = 0.335688 loss)
I0526 07:36:25.156069 15394 sgd_solver.cpp:43] Iteration 23180, lr = 0.02
I0526 07:36:30.264600 15394 main.cpp:354] Iteration 23190, loss = 0.510194
I0526 07:36:30.264641 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.510194 (* 1 = 0.510194 loss)
I0526 07:36:30.264647 15394 sgd_solver.cpp:43] Iteration 23190, lr = 0.02
I0526 07:36:34.577286 15394 main.cpp:465] Iteration 23200, Testing net (#0)
I0526 07:36:47.663986 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8241
I0526 07:36:47.664026 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.53473 (* 1 = 0.53473 loss)
I0526 07:36:48.135864 15394 main.cpp:354] Iteration 23200, loss = 0.242718
I0526 07:36:48.135906 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.242718 (* 1 = 0.242718 loss)
I0526 07:36:48.135915 15394 sgd_solver.cpp:43] Iteration 23200, lr = 0.02
I0526 07:36:53.155642 15394 main.cpp:354] Iteration 23210, loss = 0.468708
I0526 07:36:53.155683 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.468707 (* 1 = 0.468707 loss)
I0526 07:36:53.155689 15394 sgd_solver.cpp:43] Iteration 23210, lr = 0.02
I0526 07:36:58.233274 15394 main.cpp:354] Iteration 23220, loss = 0.365215
I0526 07:36:58.233320 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.365214 (* 1 = 0.365214 loss)
I0526 07:36:58.233326 15394 sgd_solver.cpp:43] Iteration 23220, lr = 0.02
I0526 07:37:03.460789 15394 main.cpp:354] Iteration 23230, loss = 0.30615
I0526 07:37:03.460829 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.30615 (* 1 = 0.30615 loss)
I0526 07:37:03.460840 15394 sgd_solver.cpp:43] Iteration 23230, lr = 0.02
I0526 07:37:08.637786 15394 main.cpp:354] Iteration 23240, loss = 0.532111
I0526 07:37:08.637828 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.532111 (* 1 = 0.532111 loss)
I0526 07:37:08.637835 15394 sgd_solver.cpp:43] Iteration 23240, lr = 0.02
I0526 07:37:13.391553 15394 main.cpp:354] Iteration 23250, loss = 0.317184
I0526 07:37:13.391593 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.317184 (* 1 = 0.317184 loss)
I0526 07:37:13.391600 15394 sgd_solver.cpp:43] Iteration 23250, lr = 0.02
I0526 07:37:18.337887 15394 main.cpp:354] Iteration 23260, loss = 0.258819
I0526 07:37:18.337927 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.258819 (* 1 = 0.258819 loss)
I0526 07:37:18.337934 15394 sgd_solver.cpp:43] Iteration 23260, lr = 0.02
I0526 07:37:23.512823 15394 main.cpp:354] Iteration 23270, loss = 0.405193
I0526 07:37:23.512864 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.405193 (* 1 = 0.405193 loss)
I0526 07:37:23.512873 15394 sgd_solver.cpp:43] Iteration 23270, lr = 0.02
I0526 07:37:28.494987 15394 main.cpp:354] Iteration 23280, loss = 0.390392
I0526 07:37:28.495028 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.390392 (* 1 = 0.390392 loss)
I0526 07:37:28.495033 15394 sgd_solver.cpp:43] Iteration 23280, lr = 0.02
I0526 07:37:33.448169 15394 main.cpp:354] Iteration 23290, loss = 0.378874
I0526 07:37:33.448210 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.378874 (* 1 = 0.378874 loss)
I0526 07:37:33.448216 15394 sgd_solver.cpp:43] Iteration 23290, lr = 0.02
I0526 07:37:38.249503 15394 main.cpp:465] Iteration 23300, Testing net (#0)
I0526 07:37:51.329135 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8168
I0526 07:37:51.329174 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.526347 (* 1 = 0.526347 loss)
I0526 07:37:51.831338 15394 main.cpp:354] Iteration 23300, loss = 0.297026
I0526 07:37:51.831374 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.297025 (* 1 = 0.297025 loss)
I0526 07:37:51.831382 15394 sgd_solver.cpp:43] Iteration 23300, lr = 0.02
I0526 07:37:56.762929 15394 main.cpp:354] Iteration 23310, loss = 0.305227
I0526 07:37:56.762971 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.305227 (* 1 = 0.305227 loss)
I0526 07:37:56.762979 15394 sgd_solver.cpp:43] Iteration 23310, lr = 0.02
I0526 07:38:01.733180 15394 main.cpp:354] Iteration 23320, loss = 0.566431
I0526 07:38:01.733222 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.566431 (* 1 = 0.566431 loss)
I0526 07:38:01.733228 15394 sgd_solver.cpp:43] Iteration 23320, lr = 0.02
I0526 07:38:06.641981 15394 main.cpp:354] Iteration 23330, loss = 0.275559
I0526 07:38:06.642020 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.275559 (* 1 = 0.275559 loss)
I0526 07:38:06.642027 15394 sgd_solver.cpp:43] Iteration 23330, lr = 0.02
I0526 07:38:11.984333 15394 main.cpp:354] Iteration 23340, loss = 0.291456
I0526 07:38:11.984375 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.291456 (* 1 = 0.291456 loss)
I0526 07:38:11.984382 15394 sgd_solver.cpp:43] Iteration 23340, lr = 0.02
I0526 07:38:17.456238 15394 main.cpp:354] Iteration 23350, loss = 0.248683
I0526 07:38:17.456277 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.248683 (* 1 = 0.248683 loss)
I0526 07:38:17.456284 15394 sgd_solver.cpp:43] Iteration 23350, lr = 0.02
I0526 07:38:22.988883 15394 main.cpp:354] Iteration 23360, loss = 0.336617
I0526 07:38:22.988922 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.336616 (* 1 = 0.336616 loss)
I0526 07:38:22.988929 15394 sgd_solver.cpp:43] Iteration 23360, lr = 0.02
I0526 07:38:27.322434 15394 main.cpp:354] Iteration 23370, loss = 0.327207
I0526 07:38:27.322474 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.327207 (* 1 = 0.327207 loss)
I0526 07:38:27.322481 15394 sgd_solver.cpp:43] Iteration 23370, lr = 0.02
I0526 07:38:32.050065 15394 main.cpp:354] Iteration 23380, loss = 0.554168
I0526 07:38:32.050096 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.554168 (* 1 = 0.554168 loss)
I0526 07:38:32.050103 15394 sgd_solver.cpp:43] Iteration 23380, lr = 0.02
I0526 07:38:36.754722 15394 main.cpp:354] Iteration 23390, loss = 0.389586
I0526 07:38:36.754761 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.389586 (* 1 = 0.389586 loss)
I0526 07:38:36.754767 15394 sgd_solver.cpp:43] Iteration 23390, lr = 0.02
I0526 07:38:41.275902 15394 main.cpp:465] Iteration 23400, Testing net (#0)
I0526 07:38:54.350080 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7884
I0526 07:38:54.350123 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.638092 (* 1 = 0.638092 loss)
I0526 07:38:54.747714 15394 main.cpp:354] Iteration 23400, loss = 0.894213
I0526 07:38:54.747756 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.894212 (* 1 = 0.894212 loss)
I0526 07:38:54.747763 15394 sgd_solver.cpp:43] Iteration 23400, lr = 0.02
I0526 07:38:59.943317 15394 main.cpp:354] Iteration 23410, loss = 0.424408
I0526 07:38:59.943356 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.424408 (* 1 = 0.424408 loss)
I0526 07:38:59.943363 15394 sgd_solver.cpp:43] Iteration 23410, lr = 0.02
I0526 07:39:04.787969 15394 main.cpp:354] Iteration 23420, loss = 0.731841
I0526 07:39:04.788009 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.731841 (* 1 = 0.731841 loss)
I0526 07:39:04.788015 15394 sgd_solver.cpp:43] Iteration 23420, lr = 0.02
I0526 07:39:09.817179 15394 main.cpp:354] Iteration 23430, loss = 0.29373
I0526 07:39:09.817219 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.29373 (* 1 = 0.29373 loss)
I0526 07:39:09.817225 15394 sgd_solver.cpp:43] Iteration 23430, lr = 0.02
I0526 07:39:15.162905 15394 main.cpp:354] Iteration 23440, loss = 0.377725
I0526 07:39:15.162945 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.377725 (* 1 = 0.377725 loss)
I0526 07:39:15.162950 15394 sgd_solver.cpp:43] Iteration 23440, lr = 0.02
I0526 07:39:20.152770 15394 main.cpp:354] Iteration 23450, loss = 0.29953
I0526 07:39:20.152812 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.29953 (* 1 = 0.29953 loss)
I0526 07:39:20.152819 15394 sgd_solver.cpp:43] Iteration 23450, lr = 0.02
I0526 07:39:25.320322 15394 main.cpp:354] Iteration 23460, loss = 0.578838
I0526 07:39:25.320365 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.578838 (* 1 = 0.578838 loss)
I0526 07:39:25.320374 15394 sgd_solver.cpp:43] Iteration 23460, lr = 0.02
I0526 07:39:30.062733 15394 main.cpp:354] Iteration 23470, loss = 0.309478
I0526 07:39:30.062777 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.309478 (* 1 = 0.309478 loss)
I0526 07:39:30.062783 15394 sgd_solver.cpp:43] Iteration 23470, lr = 0.02
I0526 07:39:35.444686 15394 main.cpp:354] Iteration 23480, loss = 0.295665
I0526 07:39:35.444721 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.295665 (* 1 = 0.295665 loss)
I0526 07:39:35.444727 15394 sgd_solver.cpp:43] Iteration 23480, lr = 0.02
I0526 07:39:40.643029 15394 main.cpp:354] Iteration 23490, loss = 0.38802
I0526 07:39:40.643082 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.38802 (* 1 = 0.38802 loss)
I0526 07:39:40.643090 15394 sgd_solver.cpp:43] Iteration 23490, lr = 0.02
I0526 07:39:44.788285 15394 main.cpp:465] Iteration 23500, Testing net (#0)
I0526 07:39:57.881608 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8349
I0526 07:39:57.881649 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.497436 (* 1 = 0.497436 loss)
I0526 07:39:58.390316 15394 main.cpp:354] Iteration 23500, loss = 0.424732
I0526 07:39:58.390350 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.424731 (* 1 = 0.424731 loss)
I0526 07:39:58.390373 15394 sgd_solver.cpp:43] Iteration 23500, lr = 0.02
I0526 07:40:02.863690 15394 main.cpp:354] Iteration 23510, loss = 0.577116
I0526 07:40:02.863729 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.577115 (* 1 = 0.577115 loss)
I0526 07:40:02.863740 15394 sgd_solver.cpp:43] Iteration 23510, lr = 0.02
I0526 07:40:07.936774 15394 main.cpp:354] Iteration 23520, loss = 0.456683
I0526 07:40:07.936815 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.456682 (* 1 = 0.456682 loss)
I0526 07:40:07.936823 15394 sgd_solver.cpp:43] Iteration 23520, lr = 0.02
I0526 07:40:12.915508 15394 main.cpp:354] Iteration 23530, loss = 0.187805
I0526 07:40:12.915539 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187804 (* 1 = 0.187804 loss)
I0526 07:40:12.915544 15394 sgd_solver.cpp:43] Iteration 23530, lr = 0.02
I0526 07:40:17.886335 15394 main.cpp:354] Iteration 23540, loss = 0.287052
I0526 07:40:17.886389 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.287051 (* 1 = 0.287051 loss)
I0526 07:40:17.886396 15394 sgd_solver.cpp:43] Iteration 23540, lr = 0.02
I0526 07:40:22.867827 15394 main.cpp:354] Iteration 23550, loss = 0.694703
I0526 07:40:22.867866 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.694703 (* 1 = 0.694703 loss)
I0526 07:40:22.867872 15394 sgd_solver.cpp:43] Iteration 23550, lr = 0.02
I0526 07:40:27.927392 15394 main.cpp:354] Iteration 23560, loss = 0.433631
I0526 07:40:27.927433 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.433631 (* 1 = 0.433631 loss)
I0526 07:40:27.927439 15394 sgd_solver.cpp:43] Iteration 23560, lr = 0.02
I0526 07:40:32.784238 15394 main.cpp:354] Iteration 23570, loss = 0.422114
I0526 07:40:32.784276 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.422114 (* 1 = 0.422114 loss)
I0526 07:40:32.784283 15394 sgd_solver.cpp:43] Iteration 23570, lr = 0.02
I0526 07:40:37.807066 15394 main.cpp:354] Iteration 23580, loss = 0.509428
I0526 07:40:37.807107 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.509428 (* 1 = 0.509428 loss)
I0526 07:40:37.807114 15394 sgd_solver.cpp:43] Iteration 23580, lr = 0.02
I0526 07:40:42.982826 15394 main.cpp:354] Iteration 23590, loss = 0.310193
I0526 07:40:42.982872 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.310193 (* 1 = 0.310193 loss)
I0526 07:40:42.982878 15394 sgd_solver.cpp:43] Iteration 23590, lr = 0.02
I0526 07:40:47.595798 15394 main.cpp:465] Iteration 23600, Testing net (#0)
I0526 07:41:00.675679 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7682
I0526 07:41:00.675719 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.682497 (* 1 = 0.682497 loss)
I0526 07:41:01.105875 15394 main.cpp:354] Iteration 23600, loss = 0.293666
I0526 07:41:01.105908 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.293665 (* 1 = 0.293665 loss)
I0526 07:41:01.105916 15394 sgd_solver.cpp:43] Iteration 23600, lr = 0.02
I0526 07:41:05.828809 15394 main.cpp:354] Iteration 23610, loss = 0.471893
I0526 07:41:05.828847 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.471893 (* 1 = 0.471893 loss)
I0526 07:41:05.828855 15394 sgd_solver.cpp:43] Iteration 23610, lr = 0.02
I0526 07:41:10.919986 15394 main.cpp:354] Iteration 23620, loss = 0.366167
I0526 07:41:10.920027 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.366166 (* 1 = 0.366166 loss)
I0526 07:41:10.920033 15394 sgd_solver.cpp:43] Iteration 23620, lr = 0.02
I0526 07:41:16.018352 15394 main.cpp:354] Iteration 23630, loss = 0.363923
I0526 07:41:16.018386 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.363923 (* 1 = 0.363923 loss)
I0526 07:41:16.018393 15394 sgd_solver.cpp:43] Iteration 23630, lr = 0.02
I0526 07:41:20.903889 15394 main.cpp:354] Iteration 23640, loss = 0.370535
I0526 07:41:20.903930 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.370534 (* 1 = 0.370534 loss)
I0526 07:41:20.903937 15394 sgd_solver.cpp:43] Iteration 23640, lr = 0.02
I0526 07:41:25.846647 15394 main.cpp:354] Iteration 23650, loss = 0.292847
I0526 07:41:25.846690 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.292846 (* 1 = 0.292846 loss)
I0526 07:41:25.846703 15394 sgd_solver.cpp:43] Iteration 23650, lr = 0.02
I0526 07:41:30.889662 15394 main.cpp:354] Iteration 23660, loss = 0.417584
I0526 07:41:30.889700 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.417583 (* 1 = 0.417583 loss)
I0526 07:41:30.889706 15394 sgd_solver.cpp:43] Iteration 23660, lr = 0.02
I0526 07:41:35.988700 15394 main.cpp:354] Iteration 23670, loss = 0.333559
I0526 07:41:35.988741 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.333559 (* 1 = 0.333559 loss)
I0526 07:41:35.988747 15394 sgd_solver.cpp:43] Iteration 23670, lr = 0.02
I0526 07:41:41.074278 15394 main.cpp:354] Iteration 23680, loss = 0.300628
I0526 07:41:41.074319 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.300628 (* 1 = 0.300628 loss)
I0526 07:41:41.074326 15394 sgd_solver.cpp:43] Iteration 23680, lr = 0.02
I0526 07:41:46.052517 15394 main.cpp:354] Iteration 23690, loss = 0.325969
I0526 07:41:46.052568 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.325969 (* 1 = 0.325969 loss)
I0526 07:41:46.052575 15394 sgd_solver.cpp:43] Iteration 23690, lr = 0.02
I0526 07:41:51.013180 15394 main.cpp:465] Iteration 23700, Testing net (#0)
I0526 07:42:04.091912 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7736
I0526 07:42:04.091953 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.679218 (* 1 = 0.679218 loss)
I0526 07:42:04.630878 15394 main.cpp:354] Iteration 23700, loss = 0.404114
I0526 07:42:04.630920 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.404114 (* 1 = 0.404114 loss)
I0526 07:42:04.630928 15394 sgd_solver.cpp:43] Iteration 23700, lr = 0.02
I0526 07:42:09.531574 15394 main.cpp:354] Iteration 23710, loss = 0.35839
I0526 07:42:09.531620 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.358389 (* 1 = 0.358389 loss)
I0526 07:42:09.531625 15394 sgd_solver.cpp:43] Iteration 23710, lr = 0.02
I0526 07:42:14.277560 15394 main.cpp:354] Iteration 23720, loss = 0.216237
I0526 07:42:14.277601 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.216237 (* 1 = 0.216237 loss)
I0526 07:42:14.277607 15394 sgd_solver.cpp:43] Iteration 23720, lr = 0.02
I0526 07:42:18.620838 15394 main.cpp:354] Iteration 23730, loss = 0.286695
I0526 07:42:18.620877 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.286695 (* 1 = 0.286695 loss)
I0526 07:42:18.620883 15394 sgd_solver.cpp:43] Iteration 23730, lr = 0.02
I0526 07:42:23.906481 15394 main.cpp:354] Iteration 23740, loss = 0.280501
I0526 07:42:23.906527 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.280501 (* 1 = 0.280501 loss)
I0526 07:42:23.906533 15394 sgd_solver.cpp:43] Iteration 23740, lr = 0.02
I0526 07:42:29.266005 15394 main.cpp:354] Iteration 23750, loss = 0.216917
I0526 07:42:29.266042 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.216917 (* 1 = 0.216917 loss)
I0526 07:42:29.266048 15394 sgd_solver.cpp:43] Iteration 23750, lr = 0.02
I0526 07:42:34.358548 15394 main.cpp:354] Iteration 23760, loss = 0.418956
I0526 07:42:34.358588 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.418955 (* 1 = 0.418955 loss)
I0526 07:42:34.358594 15394 sgd_solver.cpp:43] Iteration 23760, lr = 0.02
I0526 07:42:39.233203 15394 main.cpp:354] Iteration 23770, loss = 0.348325
I0526 07:42:39.233247 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.348325 (* 1 = 0.348325 loss)
I0526 07:42:39.233253 15394 sgd_solver.cpp:43] Iteration 23770, lr = 0.02
I0526 07:42:44.718479 15394 main.cpp:354] Iteration 23780, loss = 0.378232
I0526 07:42:44.718519 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.378232 (* 1 = 0.378232 loss)
I0526 07:42:44.718526 15394 sgd_solver.cpp:43] Iteration 23780, lr = 0.02
I0526 07:42:49.890980 15394 main.cpp:354] Iteration 23790, loss = 0.348202
I0526 07:42:49.891021 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.348201 (* 1 = 0.348201 loss)
I0526 07:42:49.891026 15394 sgd_solver.cpp:43] Iteration 23790, lr = 0.02
I0526 07:42:54.631361 15394 main.cpp:465] Iteration 23800, Testing net (#0)
I0526 07:43:07.715575 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8457
I0526 07:43:07.715616 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.459177 (* 1 = 0.459177 loss)
I0526 07:43:08.079999 15394 main.cpp:354] Iteration 23800, loss = 0.641957
I0526 07:43:08.080042 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.641957 (* 1 = 0.641957 loss)
I0526 07:43:08.080050 15394 sgd_solver.cpp:43] Iteration 23800, lr = 0.02
I0526 07:43:13.397411 15394 main.cpp:354] Iteration 23810, loss = 0.480367
I0526 07:43:13.397454 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.480367 (* 1 = 0.480367 loss)
I0526 07:43:13.397460 15394 sgd_solver.cpp:43] Iteration 23810, lr = 0.02
I0526 07:43:18.420374 15394 main.cpp:354] Iteration 23820, loss = 0.286383
I0526 07:43:18.420413 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.286382 (* 1 = 0.286382 loss)
I0526 07:43:18.420420 15394 sgd_solver.cpp:43] Iteration 23820, lr = 0.02
I0526 07:43:23.405827 15394 main.cpp:354] Iteration 23830, loss = 0.427813
I0526 07:43:23.405870 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.427813 (* 1 = 0.427813 loss)
I0526 07:43:23.405879 15394 sgd_solver.cpp:43] Iteration 23830, lr = 0.02
I0526 07:43:28.925520 15394 main.cpp:354] Iteration 23840, loss = 0.277488
I0526 07:43:28.925559 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.277488 (* 1 = 0.277488 loss)
I0526 07:43:28.925565 15394 sgd_solver.cpp:43] Iteration 23840, lr = 0.02
I0526 07:43:34.441828 15394 main.cpp:354] Iteration 23850, loss = 0.223397
I0526 07:43:34.441854 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.223397 (* 1 = 0.223397 loss)
I0526 07:43:34.441859 15394 sgd_solver.cpp:43] Iteration 23850, lr = 0.02
I0526 07:43:39.061393 15394 main.cpp:354] Iteration 23860, loss = 0.480052
I0526 07:43:39.061450 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.480052 (* 1 = 0.480052 loss)
I0526 07:43:39.061457 15394 sgd_solver.cpp:43] Iteration 23860, lr = 0.02
I0526 07:43:44.571722 15394 main.cpp:354] Iteration 23870, loss = 0.418614
I0526 07:43:44.571760 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.418613 (* 1 = 0.418613 loss)
I0526 07:43:44.571768 15394 sgd_solver.cpp:43] Iteration 23870, lr = 0.02
I0526 07:43:49.629575 15394 main.cpp:354] Iteration 23880, loss = 0.361781
I0526 07:43:49.629613 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.361781 (* 1 = 0.361781 loss)
I0526 07:43:49.629619 15394 sgd_solver.cpp:43] Iteration 23880, lr = 0.02
I0526 07:43:54.798717 15394 main.cpp:354] Iteration 23890, loss = 0.403813
I0526 07:43:54.798759 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.403812 (* 1 = 0.403812 loss)
I0526 07:43:54.798765 15394 sgd_solver.cpp:43] Iteration 23890, lr = 0.02
I0526 07:43:59.447832 15394 main.cpp:465] Iteration 23900, Testing net (#0)
I0526 07:44:12.535043 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7941
I0526 07:44:12.535081 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.637064 (* 1 = 0.637064 loss)
I0526 07:44:12.969372 15394 main.cpp:354] Iteration 23900, loss = 0.494756
I0526 07:44:12.969408 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.494756 (* 1 = 0.494756 loss)
I0526 07:44:12.969416 15394 sgd_solver.cpp:43] Iteration 23900, lr = 0.02
I0526 07:44:17.550120 15394 main.cpp:354] Iteration 23910, loss = 0.662788
I0526 07:44:17.550163 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.662788 (* 1 = 0.662788 loss)
I0526 07:44:17.550170 15394 sgd_solver.cpp:43] Iteration 23910, lr = 0.02
I0526 07:44:23.021332 15394 main.cpp:354] Iteration 23920, loss = 0.363403
I0526 07:44:23.021373 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.363402 (* 1 = 0.363402 loss)
I0526 07:44:23.021380 15394 sgd_solver.cpp:43] Iteration 23920, lr = 0.02
I0526 07:44:28.442216 15394 main.cpp:354] Iteration 23930, loss = 0.328988
I0526 07:44:28.442260 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.328987 (* 1 = 0.328987 loss)
I0526 07:44:28.442273 15394 sgd_solver.cpp:43] Iteration 23930, lr = 0.02
I0526 07:44:33.749707 15394 main.cpp:354] Iteration 23940, loss = 0.265176
I0526 07:44:33.749745 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.265175 (* 1 = 0.265175 loss)
I0526 07:44:33.749752 15394 sgd_solver.cpp:43] Iteration 23940, lr = 0.02
I0526 07:44:38.920145 15394 main.cpp:354] Iteration 23950, loss = 0.451042
I0526 07:44:38.920187 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.451042 (* 1 = 0.451042 loss)
I0526 07:44:38.920193 15394 sgd_solver.cpp:43] Iteration 23950, lr = 0.02
I0526 07:44:44.029453 15394 main.cpp:354] Iteration 23960, loss = 0.411562
I0526 07:44:44.029480 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.411562 (* 1 = 0.411562 loss)
I0526 07:44:44.029487 15394 sgd_solver.cpp:43] Iteration 23960, lr = 0.02
I0526 07:44:49.497073 15394 main.cpp:354] Iteration 23970, loss = 0.349893
I0526 07:44:49.497114 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.349892 (* 1 = 0.349892 loss)
I0526 07:44:49.497120 15394 sgd_solver.cpp:43] Iteration 23970, lr = 0.02
I0526 07:44:54.808430 15394 main.cpp:354] Iteration 23980, loss = 0.33435
I0526 07:44:54.808473 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.334349 (* 1 = 0.334349 loss)
I0526 07:44:54.808480 15394 sgd_solver.cpp:43] Iteration 23980, lr = 0.02
I0526 07:44:59.885107 15394 main.cpp:354] Iteration 23990, loss = 0.358405
I0526 07:44:59.885145 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.358404 (* 1 = 0.358404 loss)
I0526 07:44:59.885152 15394 sgd_solver.cpp:43] Iteration 23990, lr = 0.02
I0526 07:45:04.147054 15394 main.cpp:465] Iteration 24000, Testing net (#0)
I0526 07:45:17.230303 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8134
I0526 07:45:17.230343 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.55576 (* 1 = 0.55576 loss)
I0526 07:45:17.698808 15394 main.cpp:354] Iteration 24000, loss = 0.281975
I0526 07:45:17.698843 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.281975 (* 1 = 0.281975 loss)
I0526 07:45:17.698849 15394 sgd_solver.cpp:43] Iteration 24000, lr = 0.02
I0526 07:45:22.719262 15394 main.cpp:354] Iteration 24010, loss = 0.268763
I0526 07:45:22.719302 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.268763 (* 1 = 0.268763 loss)
I0526 07:45:22.719308 15394 sgd_solver.cpp:43] Iteration 24010, lr = 0.02
I0526 07:45:28.231642 15394 main.cpp:354] Iteration 24020, loss = 0.371505
I0526 07:45:28.231681 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.371505 (* 1 = 0.371505 loss)
I0526 07:45:28.231688 15394 sgd_solver.cpp:43] Iteration 24020, lr = 0.02
I0526 07:45:33.251651 15394 main.cpp:354] Iteration 24030, loss = 0.337742
I0526 07:45:33.251691 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.337742 (* 1 = 0.337742 loss)
I0526 07:45:33.251698 15394 sgd_solver.cpp:43] Iteration 24030, lr = 0.02
I0526 07:45:38.349294 15394 main.cpp:354] Iteration 24040, loss = 0.295205
I0526 07:45:38.349339 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.295205 (* 1 = 0.295205 loss)
I0526 07:45:38.349346 15394 sgd_solver.cpp:43] Iteration 24040, lr = 0.02
I0526 07:45:43.512881 15394 main.cpp:354] Iteration 24050, loss = 0.330204
I0526 07:45:43.512919 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.330204 (* 1 = 0.330204 loss)
I0526 07:45:43.512926 15394 sgd_solver.cpp:43] Iteration 24050, lr = 0.02
I0526 07:45:48.674202 15394 main.cpp:354] Iteration 24060, loss = 0.378705
I0526 07:45:48.674240 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.378704 (* 1 = 0.378704 loss)
I0526 07:45:48.674247 15394 sgd_solver.cpp:43] Iteration 24060, lr = 0.02
I0526 07:45:54.042302 15394 main.cpp:354] Iteration 24070, loss = 0.429881
I0526 07:45:54.042357 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.429881 (* 1 = 0.429881 loss)
I0526 07:45:54.042376 15394 sgd_solver.cpp:43] Iteration 24070, lr = 0.02
I0526 07:45:58.877985 15394 main.cpp:354] Iteration 24080, loss = 0.343021
I0526 07:45:58.878034 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.34302 (* 1 = 0.34302 loss)
I0526 07:45:58.878041 15394 sgd_solver.cpp:43] Iteration 24080, lr = 0.02
I0526 07:46:03.870817 15394 main.cpp:354] Iteration 24090, loss = 0.533082
I0526 07:46:03.870854 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.533082 (* 1 = 0.533082 loss)
I0526 07:46:03.870862 15394 sgd_solver.cpp:43] Iteration 24090, lr = 0.02
I0526 07:46:08.587419 15394 main.cpp:465] Iteration 24100, Testing net (#0)
I0526 07:46:21.676079 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8003
I0526 07:46:21.676116 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.608328 (* 1 = 0.608328 loss)
I0526 07:46:22.256750 15394 main.cpp:354] Iteration 24100, loss = 0.28655
I0526 07:46:22.256791 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.28655 (* 1 = 0.28655 loss)
I0526 07:46:22.256798 15394 sgd_solver.cpp:43] Iteration 24100, lr = 0.02
I0526 07:46:26.647430 15394 main.cpp:354] Iteration 24110, loss = 0.273085
I0526 07:46:26.647474 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.273084 (* 1 = 0.273084 loss)
I0526 07:46:26.647480 15394 sgd_solver.cpp:43] Iteration 24110, lr = 0.02
I0526 07:46:31.620792 15394 main.cpp:354] Iteration 24120, loss = 0.287087
I0526 07:46:31.620831 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.287086 (* 1 = 0.287086 loss)
I0526 07:46:31.620837 15394 sgd_solver.cpp:43] Iteration 24120, lr = 0.02
I0526 07:46:36.559779 15394 main.cpp:354] Iteration 24130, loss = 0.392544
I0526 07:46:36.559820 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.392544 (* 1 = 0.392544 loss)
I0526 07:46:36.559828 15394 sgd_solver.cpp:43] Iteration 24130, lr = 0.02
I0526 07:46:41.690423 15394 main.cpp:354] Iteration 24140, loss = 0.715807
I0526 07:46:41.690467 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.715807 (* 1 = 0.715807 loss)
I0526 07:46:41.690474 15394 sgd_solver.cpp:43] Iteration 24140, lr = 0.02
I0526 07:46:47.029640 15394 main.cpp:354] Iteration 24150, loss = 0.200267
I0526 07:46:47.029680 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.200266 (* 1 = 0.200266 loss)
I0526 07:46:47.029686 15394 sgd_solver.cpp:43] Iteration 24150, lr = 0.02
I0526 07:46:51.655946 15394 main.cpp:354] Iteration 24160, loss = 0.42785
I0526 07:46:51.655987 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.42785 (* 1 = 0.42785 loss)
I0526 07:46:51.655993 15394 sgd_solver.cpp:43] Iteration 24160, lr = 0.02
I0526 07:46:57.259268 15394 main.cpp:354] Iteration 24170, loss = 0.353144
I0526 07:46:57.259325 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.353144 (* 1 = 0.353144 loss)
I0526 07:46:57.259331 15394 sgd_solver.cpp:43] Iteration 24170, lr = 0.02
I0526 07:47:02.541476 15394 main.cpp:354] Iteration 24180, loss = 0.24962
I0526 07:47:02.541513 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.249619 (* 1 = 0.249619 loss)
I0526 07:47:02.541520 15394 sgd_solver.cpp:43] Iteration 24180, lr = 0.02
I0526 07:47:07.927186 15394 main.cpp:354] Iteration 24190, loss = 0.389477
I0526 07:47:07.927227 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.389476 (* 1 = 0.389476 loss)
I0526 07:47:07.927232 15394 sgd_solver.cpp:43] Iteration 24190, lr = 0.02
I0526 07:47:12.547785 15394 main.cpp:465] Iteration 24200, Testing net (#0)
I0526 07:47:25.639173 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7901
I0526 07:47:25.639215 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.716651 (* 1 = 0.716651 loss)
I0526 07:47:26.110168 15394 main.cpp:354] Iteration 24200, loss = 0.474599
I0526 07:47:26.110206 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.474599 (* 1 = 0.474599 loss)
I0526 07:47:26.110215 15394 sgd_solver.cpp:43] Iteration 24200, lr = 0.02
I0526 07:47:30.212213 15394 main.cpp:354] Iteration 24210, loss = 0.278748
I0526 07:47:30.212256 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.278747 (* 1 = 0.278747 loss)
I0526 07:47:30.212262 15394 sgd_solver.cpp:43] Iteration 24210, lr = 0.02
I0526 07:47:35.617841 15394 main.cpp:354] Iteration 24220, loss = 0.206974
I0526 07:47:35.617882 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206974 (* 1 = 0.206974 loss)
I0526 07:47:35.617887 15394 sgd_solver.cpp:43] Iteration 24220, lr = 0.02
I0526 07:47:40.697455 15394 main.cpp:354] Iteration 24230, loss = 0.361651
I0526 07:47:40.697491 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.361651 (* 1 = 0.361651 loss)
I0526 07:47:40.697499 15394 sgd_solver.cpp:43] Iteration 24230, lr = 0.02
I0526 07:47:45.887284 15394 main.cpp:354] Iteration 24240, loss = 0.241191
I0526 07:47:45.887323 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.241191 (* 1 = 0.241191 loss)
I0526 07:47:45.887329 15394 sgd_solver.cpp:43] Iteration 24240, lr = 0.02
I0526 07:47:50.665411 15394 main.cpp:354] Iteration 24250, loss = 0.433392
I0526 07:47:50.665451 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.433391 (* 1 = 0.433391 loss)
I0526 07:47:50.665457 15394 sgd_solver.cpp:43] Iteration 24250, lr = 0.02
I0526 07:47:55.359052 15394 main.cpp:354] Iteration 24260, loss = 0.382435
I0526 07:47:55.359093 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.382435 (* 1 = 0.382435 loss)
I0526 07:47:55.359099 15394 sgd_solver.cpp:43] Iteration 24260, lr = 0.02
I0526 07:48:00.094445 15394 main.cpp:354] Iteration 24270, loss = 0.320847
I0526 07:48:00.094485 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.320847 (* 1 = 0.320847 loss)
I0526 07:48:00.094492 15394 sgd_solver.cpp:43] Iteration 24270, lr = 0.02
I0526 07:48:05.684937 15394 main.cpp:354] Iteration 24280, loss = 0.557584
I0526 07:48:05.684976 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.557584 (* 1 = 0.557584 loss)
I0526 07:48:05.684983 15394 sgd_solver.cpp:43] Iteration 24280, lr = 0.02
I0526 07:48:10.661732 15394 main.cpp:354] Iteration 24290, loss = 0.468655
I0526 07:48:10.661777 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.468655 (* 1 = 0.468655 loss)
I0526 07:48:10.661784 15394 sgd_solver.cpp:43] Iteration 24290, lr = 0.02
I0526 07:48:15.350402 15394 main.cpp:465] Iteration 24300, Testing net (#0)
I0526 07:48:28.427395 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7766
I0526 07:48:28.427438 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.717273 (* 1 = 0.717273 loss)
I0526 07:48:28.893872 15394 main.cpp:354] Iteration 24300, loss = 0.457075
I0526 07:48:28.893904 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.457075 (* 1 = 0.457075 loss)
I0526 07:48:28.893913 15394 sgd_solver.cpp:43] Iteration 24300, lr = 0.02
I0526 07:48:33.875344 15394 main.cpp:354] Iteration 24310, loss = 0.500719
I0526 07:48:33.875382 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.500718 (* 1 = 0.500718 loss)
I0526 07:48:33.875390 15394 sgd_solver.cpp:43] Iteration 24310, lr = 0.02
I0526 07:48:38.195538 15394 main.cpp:354] Iteration 24320, loss = 0.815279
I0526 07:48:38.195575 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.815278 (* 1 = 0.815278 loss)
I0526 07:48:38.195582 15394 sgd_solver.cpp:43] Iteration 24320, lr = 0.02
I0526 07:48:43.431159 15394 main.cpp:354] Iteration 24330, loss = 0.375178
I0526 07:48:43.431202 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.375177 (* 1 = 0.375177 loss)
I0526 07:48:43.431208 15394 sgd_solver.cpp:43] Iteration 24330, lr = 0.02
I0526 07:48:49.015815 15394 main.cpp:354] Iteration 24340, loss = 0.279889
I0526 07:48:49.015851 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.279888 (* 1 = 0.279888 loss)
I0526 07:48:49.015867 15394 sgd_solver.cpp:43] Iteration 24340, lr = 0.02
I0526 07:48:53.821012 15394 main.cpp:354] Iteration 24350, loss = 0.34732
I0526 07:48:53.821054 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.347319 (* 1 = 0.347319 loss)
I0526 07:48:53.821065 15394 sgd_solver.cpp:43] Iteration 24350, lr = 0.02
I0526 07:48:58.752113 15394 main.cpp:354] Iteration 24360, loss = 0.3742
I0526 07:48:58.752152 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.3742 (* 1 = 0.3742 loss)
I0526 07:48:58.752158 15394 sgd_solver.cpp:43] Iteration 24360, lr = 0.02
I0526 07:49:03.973629 15394 main.cpp:354] Iteration 24370, loss = 0.22701
I0526 07:49:03.973670 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.227009 (* 1 = 0.227009 loss)
I0526 07:49:03.973676 15394 sgd_solver.cpp:43] Iteration 24370, lr = 0.02
I0526 07:49:09.427670 15394 main.cpp:354] Iteration 24380, loss = 0.302409
I0526 07:49:09.427711 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.302409 (* 1 = 0.302409 loss)
I0526 07:49:09.427716 15394 sgd_solver.cpp:43] Iteration 24380, lr = 0.02
I0526 07:49:14.506114 15394 main.cpp:354] Iteration 24390, loss = 0.336006
I0526 07:49:14.506151 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.336006 (* 1 = 0.336006 loss)
I0526 07:49:14.506157 15394 sgd_solver.cpp:43] Iteration 24390, lr = 0.02
I0526 07:49:18.657083 15394 main.cpp:465] Iteration 24400, Testing net (#0)
I0526 07:49:31.747472 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7626
I0526 07:49:31.747512 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.806105 (* 1 = 0.806105 loss)
I0526 07:49:32.213696 15394 main.cpp:354] Iteration 24400, loss = 0.437588
I0526 07:49:32.213737 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.437587 (* 1 = 0.437587 loss)
I0526 07:49:32.213745 15394 sgd_solver.cpp:43] Iteration 24400, lr = 0.02
I0526 07:49:37.368648 15394 main.cpp:354] Iteration 24410, loss = 0.527351
I0526 07:49:37.368686 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.527351 (* 1 = 0.527351 loss)
I0526 07:49:37.368692 15394 sgd_solver.cpp:43] Iteration 24410, lr = 0.02
I0526 07:49:42.504353 15394 main.cpp:354] Iteration 24420, loss = 0.290083
I0526 07:49:42.504397 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.290083 (* 1 = 0.290083 loss)
I0526 07:49:42.504405 15394 sgd_solver.cpp:43] Iteration 24420, lr = 0.02
I0526 07:49:48.034967 15394 main.cpp:354] Iteration 24430, loss = 0.477351
I0526 07:49:48.035006 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.47735 (* 1 = 0.47735 loss)
I0526 07:49:48.035012 15394 sgd_solver.cpp:43] Iteration 24430, lr = 0.02
I0526 07:49:53.122470 15394 main.cpp:354] Iteration 24440, loss = 0.465297
I0526 07:49:53.122499 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.465297 (* 1 = 0.465297 loss)
I0526 07:49:53.122506 15394 sgd_solver.cpp:43] Iteration 24440, lr = 0.02
I0526 07:49:58.295495 15394 main.cpp:354] Iteration 24450, loss = 0.434328
I0526 07:49:58.295537 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.434328 (* 1 = 0.434328 loss)
I0526 07:49:58.295543 15394 sgd_solver.cpp:43] Iteration 24450, lr = 0.02
I0526 07:50:03.311131 15394 main.cpp:354] Iteration 24460, loss = 0.330258
I0526 07:50:03.311172 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.330258 (* 1 = 0.330258 loss)
I0526 07:50:03.311178 15394 sgd_solver.cpp:43] Iteration 24460, lr = 0.02
I0526 07:50:08.473287 15394 main.cpp:354] Iteration 24470, loss = 0.475001
I0526 07:50:08.473330 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.475001 (* 1 = 0.475001 loss)
I0526 07:50:08.473335 15394 sgd_solver.cpp:43] Iteration 24470, lr = 0.02
I0526 07:50:13.437561 15394 main.cpp:354] Iteration 24480, loss = 0.233818
I0526 07:50:13.437602 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.233818 (* 1 = 0.233818 loss)
I0526 07:50:13.437608 15394 sgd_solver.cpp:43] Iteration 24480, lr = 0.02
I0526 07:50:18.529989 15394 main.cpp:354] Iteration 24490, loss = 0.283638
I0526 07:50:18.530021 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.283638 (* 1 = 0.283638 loss)
I0526 07:50:18.530028 15394 sgd_solver.cpp:43] Iteration 24490, lr = 0.02
I0526 07:50:22.644390 15394 main.cpp:465] Iteration 24500, Testing net (#0)
I0526 07:50:35.736867 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7691
I0526 07:50:35.736907 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.774719 (* 1 = 0.774719 loss)
I0526 07:50:36.281052 15394 main.cpp:354] Iteration 24500, loss = 0.287763
I0526 07:50:36.281077 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.287762 (* 1 = 0.287762 loss)
I0526 07:50:36.281085 15394 sgd_solver.cpp:43] Iteration 24500, lr = 0.02
I0526 07:50:41.920559 15394 main.cpp:354] Iteration 24510, loss = 0.245799
I0526 07:50:41.920599 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.245799 (* 1 = 0.245799 loss)
I0526 07:50:41.920606 15394 sgd_solver.cpp:43] Iteration 24510, lr = 0.02
I0526 07:50:47.008188 15394 main.cpp:354] Iteration 24520, loss = 0.468064
I0526 07:50:47.008230 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.468063 (* 1 = 0.468063 loss)
I0526 07:50:47.008237 15394 sgd_solver.cpp:43] Iteration 24520, lr = 0.02
I0526 07:50:52.510089 15394 main.cpp:354] Iteration 24530, loss = 0.368514
I0526 07:50:52.510131 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.368514 (* 1 = 0.368514 loss)
I0526 07:50:52.510138 15394 sgd_solver.cpp:43] Iteration 24530, lr = 0.02
I0526 07:50:57.400887 15394 main.cpp:354] Iteration 24540, loss = 0.23122
I0526 07:50:57.400926 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.231219 (* 1 = 0.231219 loss)
I0526 07:50:57.400933 15394 sgd_solver.cpp:43] Iteration 24540, lr = 0.02
I0526 07:51:02.393374 15394 main.cpp:354] Iteration 24550, loss = 0.337023
I0526 07:51:02.393405 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.337023 (* 1 = 0.337023 loss)
I0526 07:51:02.393412 15394 sgd_solver.cpp:43] Iteration 24550, lr = 0.02
I0526 07:51:07.517367 15394 main.cpp:354] Iteration 24560, loss = 0.473899
I0526 07:51:07.517406 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.473898 (* 1 = 0.473898 loss)
I0526 07:51:07.517413 15394 sgd_solver.cpp:43] Iteration 24560, lr = 0.02
I0526 07:51:12.327775 15394 main.cpp:354] Iteration 24570, loss = 0.578205
I0526 07:51:12.327813 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.578205 (* 1 = 0.578205 loss)
I0526 07:51:12.327819 15394 sgd_solver.cpp:43] Iteration 24570, lr = 0.02
I0526 07:51:17.418198 15394 main.cpp:354] Iteration 24580, loss = 0.415695
I0526 07:51:17.418241 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.415695 (* 1 = 0.415695 loss)
I0526 07:51:17.418247 15394 sgd_solver.cpp:43] Iteration 24580, lr = 0.02
I0526 07:51:22.473533 15394 main.cpp:354] Iteration 24590, loss = 0.284442
I0526 07:51:22.473572 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.284442 (* 1 = 0.284442 loss)
I0526 07:51:22.473578 15394 sgd_solver.cpp:43] Iteration 24590, lr = 0.02
I0526 07:51:27.038806 15394 main.cpp:465] Iteration 24600, Testing net (#0)
I0526 07:51:40.119573 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7742
I0526 07:51:40.119601 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.693387 (* 1 = 0.693387 loss)
I0526 07:51:40.658301 15394 main.cpp:354] Iteration 24600, loss = 0.274258
I0526 07:51:40.658326 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.274258 (* 1 = 0.274258 loss)
I0526 07:51:40.658334 15394 sgd_solver.cpp:43] Iteration 24600, lr = 0.02
I0526 07:51:45.811959 15394 main.cpp:354] Iteration 24610, loss = 0.302256
I0526 07:51:45.811998 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.302256 (* 1 = 0.302256 loss)
I0526 07:51:45.812005 15394 sgd_solver.cpp:43] Iteration 24610, lr = 0.02
I0526 07:51:51.010701 15394 main.cpp:354] Iteration 24620, loss = 0.233514
I0526 07:51:51.010745 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.233513 (* 1 = 0.233513 loss)
I0526 07:51:51.010762 15394 sgd_solver.cpp:43] Iteration 24620, lr = 0.02
I0526 07:51:56.395822 15394 main.cpp:354] Iteration 24630, loss = 0.250247
I0526 07:51:56.395867 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.250246 (* 1 = 0.250246 loss)
I0526 07:51:56.395874 15394 sgd_solver.cpp:43] Iteration 24630, lr = 0.02
I0526 07:52:01.417614 15394 main.cpp:354] Iteration 24640, loss = 0.381077
I0526 07:52:01.417659 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.381076 (* 1 = 0.381076 loss)
I0526 07:52:01.417666 15394 sgd_solver.cpp:43] Iteration 24640, lr = 0.02
I0526 07:52:06.458999 15394 main.cpp:354] Iteration 24650, loss = 0.254222
I0526 07:52:06.459040 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.254222 (* 1 = 0.254222 loss)
I0526 07:52:06.459048 15394 sgd_solver.cpp:43] Iteration 24650, lr = 0.02
I0526 07:52:11.542819 15394 main.cpp:354] Iteration 24660, loss = 0.340961
I0526 07:52:11.542855 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.34096 (* 1 = 0.34096 loss)
I0526 07:52:11.542861 15394 sgd_solver.cpp:43] Iteration 24660, lr = 0.02
I0526 07:52:16.886291 15394 main.cpp:354] Iteration 24670, loss = 0.386349
I0526 07:52:16.886343 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.386349 (* 1 = 0.386349 loss)
I0526 07:52:16.886353 15394 sgd_solver.cpp:43] Iteration 24670, lr = 0.02
I0526 07:52:21.804352 15394 main.cpp:354] Iteration 24680, loss = 0.254034
I0526 07:52:21.804394 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.254033 (* 1 = 0.254033 loss)
I0526 07:52:21.804400 15394 sgd_solver.cpp:43] Iteration 24680, lr = 0.02
I0526 07:52:26.896906 15394 main.cpp:354] Iteration 24690, loss = 0.333631
I0526 07:52:26.896945 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.333631 (* 1 = 0.333631 loss)
I0526 07:52:26.896952 15394 sgd_solver.cpp:43] Iteration 24690, lr = 0.02
I0526 07:52:32.042023 15394 main.cpp:465] Iteration 24700, Testing net (#0)
I0526 07:52:45.119848 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8125
I0526 07:52:45.119885 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.577325 (* 1 = 0.577325 loss)
I0526 07:52:45.554374 15394 main.cpp:354] Iteration 24700, loss = 0.474103
I0526 07:52:45.554404 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.474103 (* 1 = 0.474103 loss)
I0526 07:52:45.554411 15394 sgd_solver.cpp:43] Iteration 24700, lr = 0.02
I0526 07:52:50.474340 15394 main.cpp:354] Iteration 24710, loss = 0.239784
I0526 07:52:50.474405 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.239783 (* 1 = 0.239783 loss)
I0526 07:52:50.474411 15394 sgd_solver.cpp:43] Iteration 24710, lr = 0.02
I0526 07:52:55.240542 15394 main.cpp:354] Iteration 24720, loss = 0.390996
I0526 07:52:55.240583 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.390995 (* 1 = 0.390995 loss)
I0526 07:52:55.240589 15394 sgd_solver.cpp:43] Iteration 24720, lr = 0.02
I0526 07:53:00.545655 15394 main.cpp:354] Iteration 24730, loss = 0.269127
I0526 07:53:00.545708 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.269126 (* 1 = 0.269126 loss)
I0526 07:53:00.545716 15394 sgd_solver.cpp:43] Iteration 24730, lr = 0.02
I0526 07:53:05.897568 15394 main.cpp:354] Iteration 24740, loss = 0.381105
I0526 07:53:05.897609 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.381105 (* 1 = 0.381105 loss)
I0526 07:53:05.897616 15394 sgd_solver.cpp:43] Iteration 24740, lr = 0.02
I0526 07:53:10.757746 15394 main.cpp:354] Iteration 24750, loss = 0.414525
I0526 07:53:10.757792 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.414525 (* 1 = 0.414525 loss)
I0526 07:53:10.757799 15394 sgd_solver.cpp:43] Iteration 24750, lr = 0.02
I0526 07:53:16.010458 15394 main.cpp:354] Iteration 24760, loss = 0.246734
I0526 07:53:16.010502 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.246734 (* 1 = 0.246734 loss)
I0526 07:53:16.010510 15394 sgd_solver.cpp:43] Iteration 24760, lr = 0.02
I0526 07:53:21.465968 15394 main.cpp:354] Iteration 24770, loss = 0.199032
I0526 07:53:21.466006 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.199032 (* 1 = 0.199032 loss)
I0526 07:53:21.466018 15394 sgd_solver.cpp:43] Iteration 24770, lr = 0.02
I0526 07:53:26.838186 15394 main.cpp:354] Iteration 24780, loss = 0.281667
I0526 07:53:26.838227 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.281667 (* 1 = 0.281667 loss)
I0526 07:53:26.838234 15394 sgd_solver.cpp:43] Iteration 24780, lr = 0.02
I0526 07:53:32.179935 15394 main.cpp:354] Iteration 24790, loss = 0.42606
I0526 07:53:32.179975 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.42606 (* 1 = 0.42606 loss)
I0526 07:53:32.179981 15394 sgd_solver.cpp:43] Iteration 24790, lr = 0.02
I0526 07:53:36.974797 15394 main.cpp:465] Iteration 24800, Testing net (#0)
I0526 07:53:50.052809 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8181
I0526 07:53:50.052852 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.589939 (* 1 = 0.589939 loss)
I0526 07:53:50.525310 15394 main.cpp:354] Iteration 24800, loss = 0.346502
I0526 07:53:50.525332 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.346502 (* 1 = 0.346502 loss)
I0526 07:53:50.525341 15394 sgd_solver.cpp:43] Iteration 24800, lr = 0.02
I0526 07:53:55.332340 15394 main.cpp:354] Iteration 24810, loss = 0.509961
I0526 07:53:55.332383 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.509961 (* 1 = 0.509961 loss)
I0526 07:53:55.332389 15394 sgd_solver.cpp:43] Iteration 24810, lr = 0.02
I0526 07:53:59.906426 15394 main.cpp:354] Iteration 24820, loss = 0.563334
I0526 07:53:59.906464 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.563334 (* 1 = 0.563334 loss)
I0526 07:53:59.906471 15394 sgd_solver.cpp:43] Iteration 24820, lr = 0.02
I0526 07:54:05.072370 15394 main.cpp:354] Iteration 24830, loss = 0.321977
I0526 07:54:05.072393 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.321976 (* 1 = 0.321976 loss)
I0526 07:54:05.072401 15394 sgd_solver.cpp:43] Iteration 24830, lr = 0.02
I0526 07:54:10.441093 15394 main.cpp:354] Iteration 24840, loss = 0.333803
I0526 07:54:10.441134 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.333802 (* 1 = 0.333802 loss)
I0526 07:54:10.441141 15394 sgd_solver.cpp:43] Iteration 24840, lr = 0.02
I0526 07:54:15.598793 15394 main.cpp:354] Iteration 24850, loss = 0.428582
I0526 07:54:15.598832 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.428581 (* 1 = 0.428581 loss)
I0526 07:54:15.598839 15394 sgd_solver.cpp:43] Iteration 24850, lr = 0.02
I0526 07:54:20.681152 15394 main.cpp:354] Iteration 24860, loss = 0.31498
I0526 07:54:20.681192 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.31498 (* 1 = 0.31498 loss)
I0526 07:54:20.681200 15394 sgd_solver.cpp:43] Iteration 24860, lr = 0.02
I0526 07:54:25.732651 15394 main.cpp:354] Iteration 24870, loss = 0.265343
I0526 07:54:25.732699 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.265343 (* 1 = 0.265343 loss)
I0526 07:54:25.732707 15394 sgd_solver.cpp:43] Iteration 24870, lr = 0.02
I0526 07:54:31.067342 15394 main.cpp:354] Iteration 24880, loss = 0.438705
I0526 07:54:31.067381 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.438705 (* 1 = 0.438705 loss)
I0526 07:54:31.067389 15394 sgd_solver.cpp:43] Iteration 24880, lr = 0.02
I0526 07:54:36.012014 15394 main.cpp:354] Iteration 24890, loss = 0.38376
I0526 07:54:36.012058 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.38376 (* 1 = 0.38376 loss)
I0526 07:54:36.012065 15394 sgd_solver.cpp:43] Iteration 24890, lr = 0.02
I0526 07:54:40.598103 15394 main.cpp:465] Iteration 24900, Testing net (#0)
I0526 07:54:53.678601 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8329
I0526 07:54:53.678642 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.518062 (* 1 = 0.518062 loss)
I0526 07:54:54.180848 15394 main.cpp:354] Iteration 24900, loss = 0.288275
I0526 07:54:54.180884 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.288275 (* 1 = 0.288275 loss)
I0526 07:54:54.180891 15394 sgd_solver.cpp:43] Iteration 24900, lr = 0.02
I0526 07:54:59.226544 15394 main.cpp:354] Iteration 24910, loss = 0.310958
I0526 07:54:59.226591 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.310957 (* 1 = 0.310957 loss)
I0526 07:54:59.226598 15394 sgd_solver.cpp:43] Iteration 24910, lr = 0.02
I0526 07:55:04.644493 15394 main.cpp:354] Iteration 24920, loss = 0.341676
I0526 07:55:04.644536 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.341676 (* 1 = 0.341676 loss)
I0526 07:55:04.644542 15394 sgd_solver.cpp:43] Iteration 24920, lr = 0.02
I0526 07:55:09.909483 15394 main.cpp:354] Iteration 24930, loss = 0.441594
I0526 07:55:09.909526 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.441594 (* 1 = 0.441594 loss)
I0526 07:55:09.909534 15394 sgd_solver.cpp:43] Iteration 24930, lr = 0.02
I0526 07:55:15.099125 15394 main.cpp:354] Iteration 24940, loss = 0.349002
I0526 07:55:15.099164 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.349001 (* 1 = 0.349001 loss)
I0526 07:55:15.099170 15394 sgd_solver.cpp:43] Iteration 24940, lr = 0.02
I0526 07:55:20.530303 15394 main.cpp:354] Iteration 24950, loss = 0.300161
I0526 07:55:20.530342 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.300161 (* 1 = 0.300161 loss)
I0526 07:55:20.530349 15394 sgd_solver.cpp:43] Iteration 24950, lr = 0.02
I0526 07:55:25.225663 15394 main.cpp:354] Iteration 24960, loss = 0.450832
I0526 07:55:25.225708 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.450832 (* 1 = 0.450832 loss)
I0526 07:55:25.225713 15394 sgd_solver.cpp:43] Iteration 24960, lr = 0.02
I0526 07:55:30.252593 15394 main.cpp:354] Iteration 24970, loss = 0.319637
I0526 07:55:30.252631 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.319637 (* 1 = 0.319637 loss)
I0526 07:55:30.252637 15394 sgd_solver.cpp:43] Iteration 24970, lr = 0.02
I0526 07:55:35.488538 15394 main.cpp:354] Iteration 24980, loss = 0.305093
I0526 07:55:35.488581 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.305093 (* 1 = 0.305093 loss)
I0526 07:55:35.488587 15394 sgd_solver.cpp:43] Iteration 24980, lr = 0.02
I0526 07:55:40.460495 15394 main.cpp:354] Iteration 24990, loss = 0.328094
I0526 07:55:40.460542 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.328094 (* 1 = 0.328094 loss)
I0526 07:55:40.460549 15394 sgd_solver.cpp:43] Iteration 24990, lr = 0.02
I0526 07:55:45.060108 15394 main.cpp:465] Iteration 25000, Testing net (#0)
I0526 07:55:58.139971 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8212
I0526 07:55:58.140013 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.564094 (* 1 = 0.564094 loss)
I0526 07:55:58.643139 15394 main.cpp:354] Iteration 25000, loss = 0.243243
I0526 07:55:58.643159 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.243242 (* 1 = 0.243242 loss)
I0526 07:55:58.643167 15394 sgd_solver.cpp:43] Iteration 25000, lr = 0.02
I0526 07:56:03.404235 15394 main.cpp:354] Iteration 25010, loss = 0.375929
I0526 07:56:03.404275 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.375929 (* 1 = 0.375929 loss)
I0526 07:56:03.404281 15394 sgd_solver.cpp:43] Iteration 25010, lr = 0.02
I0526 07:56:08.337368 15394 main.cpp:354] Iteration 25020, loss = 0.333206
I0526 07:56:08.337409 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.333206 (* 1 = 0.333206 loss)
I0526 07:56:08.337415 15394 sgd_solver.cpp:43] Iteration 25020, lr = 0.02
I0526 07:56:13.520534 15394 main.cpp:354] Iteration 25030, loss = 0.367845
I0526 07:56:13.520587 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.367844 (* 1 = 0.367844 loss)
I0526 07:56:13.520594 15394 sgd_solver.cpp:43] Iteration 25030, lr = 0.02
I0526 07:56:18.343700 15394 main.cpp:354] Iteration 25040, loss = 0.569732
I0526 07:56:18.343740 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.569732 (* 1 = 0.569732 loss)
I0526 07:56:18.343747 15394 sgd_solver.cpp:43] Iteration 25040, lr = 0.02
I0526 07:56:23.733069 15394 main.cpp:354] Iteration 25050, loss = 0.350834
I0526 07:56:23.733114 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.350834 (* 1 = 0.350834 loss)
I0526 07:56:23.733120 15394 sgd_solver.cpp:43] Iteration 25050, lr = 0.02
I0526 07:56:28.376575 15394 main.cpp:354] Iteration 25060, loss = 0.196256
I0526 07:56:28.376618 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.196256 (* 1 = 0.196256 loss)
I0526 07:56:28.376624 15394 sgd_solver.cpp:43] Iteration 25060, lr = 0.02
I0526 07:56:33.311844 15394 main.cpp:354] Iteration 25070, loss = 0.282455
I0526 07:56:33.311885 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.282455 (* 1 = 0.282455 loss)
I0526 07:56:33.311892 15394 sgd_solver.cpp:43] Iteration 25070, lr = 0.02
I0526 07:56:38.263556 15394 main.cpp:354] Iteration 25080, loss = 0.592753
I0526 07:56:38.263595 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.592753 (* 1 = 0.592753 loss)
I0526 07:56:38.263602 15394 sgd_solver.cpp:43] Iteration 25080, lr = 0.02
I0526 07:56:43.479024 15394 main.cpp:354] Iteration 25090, loss = 0.248473
I0526 07:56:43.479068 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.248473 (* 1 = 0.248473 loss)
I0526 07:56:43.479075 15394 sgd_solver.cpp:43] Iteration 25090, lr = 0.02
I0526 07:56:48.233067 15394 main.cpp:465] Iteration 25100, Testing net (#0)
I0526 07:57:01.316925 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7971
I0526 07:57:01.316965 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.627081 (* 1 = 0.627081 loss)
I0526 07:57:01.792054 15394 main.cpp:354] Iteration 25100, loss = 0.199957
I0526 07:57:01.792106 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.199957 (* 1 = 0.199957 loss)
I0526 07:57:01.792115 15394 sgd_solver.cpp:43] Iteration 25100, lr = 0.02
I0526 07:57:07.198637 15394 main.cpp:354] Iteration 25110, loss = 0.347169
I0526 07:57:07.198676 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.347169 (* 1 = 0.347169 loss)
I0526 07:57:07.198683 15394 sgd_solver.cpp:43] Iteration 25110, lr = 0.02
I0526 07:57:12.458237 15394 main.cpp:354] Iteration 25120, loss = 0.324113
I0526 07:57:12.458281 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.324113 (* 1 = 0.324113 loss)
I0526 07:57:12.458288 15394 sgd_solver.cpp:43] Iteration 25120, lr = 0.02
I0526 07:57:17.724225 15394 main.cpp:354] Iteration 25130, loss = 0.488393
I0526 07:57:17.724266 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.488393 (* 1 = 0.488393 loss)
I0526 07:57:17.724272 15394 sgd_solver.cpp:43] Iteration 25130, lr = 0.02
I0526 07:57:22.974345 15394 main.cpp:354] Iteration 25140, loss = 0.447985
I0526 07:57:22.974382 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.447985 (* 1 = 0.447985 loss)
I0526 07:57:22.974390 15394 sgd_solver.cpp:43] Iteration 25140, lr = 0.02
I0526 07:57:27.207386 15394 main.cpp:354] Iteration 25150, loss = 0.250202
I0526 07:57:27.207425 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.250202 (* 1 = 0.250202 loss)
I0526 07:57:27.207432 15394 sgd_solver.cpp:43] Iteration 25150, lr = 0.02
I0526 07:57:32.267061 15394 main.cpp:354] Iteration 25160, loss = 0.534396
I0526 07:57:32.267099 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.534396 (* 1 = 0.534396 loss)
I0526 07:57:32.267105 15394 sgd_solver.cpp:43] Iteration 25160, lr = 0.02
I0526 07:57:37.620100 15394 main.cpp:354] Iteration 25170, loss = 0.267765
I0526 07:57:37.620142 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.267765 (* 1 = 0.267765 loss)
I0526 07:57:37.620149 15394 sgd_solver.cpp:43] Iteration 25170, lr = 0.02
I0526 07:57:43.286253 15394 main.cpp:354] Iteration 25180, loss = 0.331698
I0526 07:57:43.286298 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.331698 (* 1 = 0.331698 loss)
I0526 07:57:43.286304 15394 sgd_solver.cpp:43] Iteration 25180, lr = 0.02
I0526 07:57:48.594391 15394 main.cpp:354] Iteration 25190, loss = 0.386957
I0526 07:57:48.594431 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.386957 (* 1 = 0.386957 loss)
I0526 07:57:48.594444 15394 sgd_solver.cpp:43] Iteration 25190, lr = 0.02
I0526 07:57:53.220111 15394 main.cpp:465] Iteration 25200, Testing net (#0)
I0526 07:58:06.295322 15394 main.cpp:532]     Test net output #0: Accuracy = 0.84
I0526 07:58:06.295364 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.488141 (* 1 = 0.488141 loss)
I0526 07:58:06.693850 15394 main.cpp:354] Iteration 25200, loss = 0.533697
I0526 07:58:06.693887 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.533697 (* 1 = 0.533697 loss)
I0526 07:58:06.693894 15394 sgd_solver.cpp:43] Iteration 25200, lr = 0.02
I0526 07:58:11.684674 15394 main.cpp:354] Iteration 25210, loss = 0.530909
I0526 07:58:11.684718 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.530909 (* 1 = 0.530909 loss)
I0526 07:58:11.684725 15394 sgd_solver.cpp:43] Iteration 25210, lr = 0.02
I0526 07:58:16.620858 15394 main.cpp:354] Iteration 25220, loss = 0.2188
I0526 07:58:16.620898 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.2188 (* 1 = 0.2188 loss)
I0526 07:58:16.620904 15394 sgd_solver.cpp:43] Iteration 25220, lr = 0.02
I0526 07:58:21.920518 15394 main.cpp:354] Iteration 25230, loss = 0.32011
I0526 07:58:21.920559 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.32011 (* 1 = 0.32011 loss)
I0526 07:58:21.920567 15394 sgd_solver.cpp:43] Iteration 25230, lr = 0.02
I0526 07:58:27.149020 15394 main.cpp:354] Iteration 25240, loss = 0.542009
I0526 07:58:27.149063 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.542009 (* 1 = 0.542009 loss)
I0526 07:58:27.149070 15394 sgd_solver.cpp:43] Iteration 25240, lr = 0.02
I0526 07:58:32.237819 15394 main.cpp:354] Iteration 25250, loss = 0.349168
I0526 07:58:32.237859 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.349168 (* 1 = 0.349168 loss)
I0526 07:58:32.237864 15394 sgd_solver.cpp:43] Iteration 25250, lr = 0.02
I0526 07:58:37.548245 15394 main.cpp:354] Iteration 25260, loss = 0.412856
I0526 07:58:37.548285 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.412856 (* 1 = 0.412856 loss)
I0526 07:58:37.548290 15394 sgd_solver.cpp:43] Iteration 25260, lr = 0.02
I0526 07:58:42.384115 15394 main.cpp:354] Iteration 25270, loss = 0.307162
I0526 07:58:42.384158 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.307162 (* 1 = 0.307162 loss)
I0526 07:58:42.384165 15394 sgd_solver.cpp:43] Iteration 25270, lr = 0.02
I0526 07:58:47.725613 15394 main.cpp:354] Iteration 25280, loss = 0.390091
I0526 07:58:47.725651 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.39009 (* 1 = 0.39009 loss)
I0526 07:58:47.725658 15394 sgd_solver.cpp:43] Iteration 25280, lr = 0.02
I0526 07:58:52.763525 15394 main.cpp:354] Iteration 25290, loss = 0.274092
I0526 07:58:52.763564 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.274091 (* 1 = 0.274091 loss)
I0526 07:58:52.763571 15394 sgd_solver.cpp:43] Iteration 25290, lr = 0.02
I0526 07:58:57.403513 15394 main.cpp:465] Iteration 25300, Testing net (#0)
I0526 07:59:10.489936 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8143
I0526 07:59:10.489980 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.56599 (* 1 = 0.56599 loss)
I0526 07:59:10.963667 15394 main.cpp:354] Iteration 25300, loss = 0.341735
I0526 07:59:10.963709 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.341735 (* 1 = 0.341735 loss)
I0526 07:59:10.963717 15394 sgd_solver.cpp:43] Iteration 25300, lr = 0.02
I0526 07:59:15.973631 15394 main.cpp:354] Iteration 25310, loss = 0.700625
I0526 07:59:15.973671 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.700625 (* 1 = 0.700625 loss)
I0526 07:59:15.973677 15394 sgd_solver.cpp:43] Iteration 25310, lr = 0.02
I0526 07:59:21.007241 15394 main.cpp:354] Iteration 25320, loss = 0.392017
I0526 07:59:21.007282 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.392017 (* 1 = 0.392017 loss)
I0526 07:59:21.007288 15394 sgd_solver.cpp:43] Iteration 25320, lr = 0.02
I0526 07:59:25.948601 15394 main.cpp:354] Iteration 25330, loss = 0.316085
I0526 07:59:25.948647 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.316085 (* 1 = 0.316085 loss)
I0526 07:59:25.948653 15394 sgd_solver.cpp:43] Iteration 25330, lr = 0.02
I0526 07:59:31.157691 15394 main.cpp:354] Iteration 25340, loss = 0.275848
I0526 07:59:31.157732 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.275848 (* 1 = 0.275848 loss)
I0526 07:59:31.157739 15394 sgd_solver.cpp:43] Iteration 25340, lr = 0.02
I0526 07:59:36.185956 15394 main.cpp:354] Iteration 25350, loss = 0.336261
I0526 07:59:36.185993 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.336261 (* 1 = 0.336261 loss)
I0526 07:59:36.186000 15394 sgd_solver.cpp:43] Iteration 25350, lr = 0.02
I0526 07:59:41.484166 15394 main.cpp:354] Iteration 25360, loss = 0.243114
I0526 07:59:41.484210 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.243114 (* 1 = 0.243114 loss)
I0526 07:59:41.484217 15394 sgd_solver.cpp:43] Iteration 25360, lr = 0.02
I0526 07:59:46.154726 15394 main.cpp:354] Iteration 25370, loss = 0.385968
I0526 07:59:46.154767 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.385968 (* 1 = 0.385968 loss)
I0526 07:59:46.154774 15394 sgd_solver.cpp:43] Iteration 25370, lr = 0.02
I0526 07:59:51.152324 15394 main.cpp:354] Iteration 25380, loss = 0.336156
I0526 07:59:51.152364 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.336156 (* 1 = 0.336156 loss)
I0526 07:59:51.152370 15394 sgd_solver.cpp:43] Iteration 25380, lr = 0.02
I0526 07:59:56.097635 15394 main.cpp:354] Iteration 25390, loss = 0.516688
I0526 07:59:56.097678 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.516688 (* 1 = 0.516688 loss)
I0526 07:59:56.097684 15394 sgd_solver.cpp:43] Iteration 25390, lr = 0.02
I0526 08:00:00.338786 15394 main.cpp:465] Iteration 25400, Testing net (#0)
I0526 08:00:13.427507 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8549
I0526 08:00:13.427572 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.439868 (* 1 = 0.439868 loss)
I0526 08:00:14.003067 15394 main.cpp:354] Iteration 25400, loss = 0.1966
I0526 08:00:14.003108 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.1966 (* 1 = 0.1966 loss)
I0526 08:00:14.003115 15394 sgd_solver.cpp:43] Iteration 25400, lr = 0.02
I0526 08:00:19.316237 15394 main.cpp:354] Iteration 25410, loss = 0.199161
I0526 08:00:19.316279 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.199161 (* 1 = 0.199161 loss)
I0526 08:00:19.316287 15394 sgd_solver.cpp:43] Iteration 25410, lr = 0.02
I0526 08:00:24.986634 15394 main.cpp:354] Iteration 25420, loss = 0.361206
I0526 08:00:24.986688 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.361206 (* 1 = 0.361206 loss)
I0526 08:00:24.986706 15394 sgd_solver.cpp:43] Iteration 25420, lr = 0.02
I0526 08:00:30.240319 15394 main.cpp:354] Iteration 25430, loss = 0.695912
I0526 08:00:30.240353 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.695912 (* 1 = 0.695912 loss)
I0526 08:00:30.240360 15394 sgd_solver.cpp:43] Iteration 25430, lr = 0.02
I0526 08:00:35.302831 15394 main.cpp:354] Iteration 25440, loss = 0.283804
I0526 08:00:35.302871 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.283804 (* 1 = 0.283804 loss)
I0526 08:00:35.302876 15394 sgd_solver.cpp:43] Iteration 25440, lr = 0.02
I0526 08:00:40.278455 15394 main.cpp:354] Iteration 25450, loss = 0.38226
I0526 08:00:40.278499 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.38226 (* 1 = 0.38226 loss)
I0526 08:00:40.278506 15394 sgd_solver.cpp:43] Iteration 25450, lr = 0.02
I0526 08:00:45.221933 15394 main.cpp:354] Iteration 25460, loss = 0.441759
I0526 08:00:45.221973 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.441759 (* 1 = 0.441759 loss)
I0526 08:00:45.221982 15394 sgd_solver.cpp:43] Iteration 25460, lr = 0.02
I0526 08:00:50.725368 15394 main.cpp:354] Iteration 25470, loss = 0.498895
I0526 08:00:50.725406 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.498895 (* 1 = 0.498895 loss)
I0526 08:00:50.725419 15394 sgd_solver.cpp:43] Iteration 25470, lr = 0.02
I0526 08:00:55.767973 15394 main.cpp:354] Iteration 25480, loss = 0.27168
I0526 08:00:55.768019 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.27168 (* 1 = 0.27168 loss)
I0526 08:00:55.768028 15394 sgd_solver.cpp:43] Iteration 25480, lr = 0.02
I0526 08:01:00.886404 15394 main.cpp:354] Iteration 25490, loss = 0.292743
I0526 08:01:00.886445 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.292743 (* 1 = 0.292743 loss)
I0526 08:01:00.886451 15394 sgd_solver.cpp:43] Iteration 25490, lr = 0.02
I0526 08:01:05.717569 15394 main.cpp:465] Iteration 25500, Testing net (#0)
I0526 08:01:18.796481 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7794
I0526 08:01:18.796520 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.698959 (* 1 = 0.698959 loss)
I0526 08:01:19.303251 15394 main.cpp:354] Iteration 25500, loss = 0.284689
I0526 08:01:19.303287 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.284689 (* 1 = 0.284689 loss)
I0526 08:01:19.303294 15394 sgd_solver.cpp:43] Iteration 25500, lr = 0.02
I0526 08:01:24.126587 15394 main.cpp:354] Iteration 25510, loss = 0.377661
I0526 08:01:24.126627 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.377661 (* 1 = 0.377661 loss)
I0526 08:01:24.126634 15394 sgd_solver.cpp:43] Iteration 25510, lr = 0.02
I0526 08:01:28.802072 15394 main.cpp:354] Iteration 25520, loss = 0.429822
I0526 08:01:28.802112 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.429821 (* 1 = 0.429821 loss)
I0526 08:01:28.802119 15394 sgd_solver.cpp:43] Iteration 25520, lr = 0.02
I0526 08:01:33.875380 15394 main.cpp:354] Iteration 25530, loss = 0.253787
I0526 08:01:33.875421 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.253786 (* 1 = 0.253786 loss)
I0526 08:01:33.875427 15394 sgd_solver.cpp:43] Iteration 25530, lr = 0.02
I0526 08:01:39.315626 15394 main.cpp:354] Iteration 25540, loss = 0.390135
I0526 08:01:39.315651 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.390135 (* 1 = 0.390135 loss)
I0526 08:01:39.315659 15394 sgd_solver.cpp:43] Iteration 25540, lr = 0.02
I0526 08:01:43.779999 15394 main.cpp:354] Iteration 25550, loss = 0.448901
I0526 08:01:43.780040 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.448901 (* 1 = 0.448901 loss)
I0526 08:01:43.780047 15394 sgd_solver.cpp:43] Iteration 25550, lr = 0.02
I0526 08:01:48.834396 15394 main.cpp:354] Iteration 25560, loss = 0.473899
I0526 08:01:48.834439 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.473898 (* 1 = 0.473898 loss)
I0526 08:01:48.834444 15394 sgd_solver.cpp:43] Iteration 25560, lr = 0.02
I0526 08:01:53.925307 15394 main.cpp:354] Iteration 25570, loss = 0.363795
I0526 08:01:53.925346 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.363795 (* 1 = 0.363795 loss)
I0526 08:01:53.925354 15394 sgd_solver.cpp:43] Iteration 25570, lr = 0.02
I0526 08:01:58.291188 15394 main.cpp:354] Iteration 25580, loss = 0.859082
I0526 08:01:58.291245 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.859082 (* 1 = 0.859082 loss)
I0526 08:01:58.291254 15394 sgd_solver.cpp:43] Iteration 25580, lr = 0.02
I0526 08:02:03.515137 15394 main.cpp:354] Iteration 25590, loss = 0.243253
I0526 08:02:03.515178 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.243253 (* 1 = 0.243253 loss)
I0526 08:02:03.515185 15394 sgd_solver.cpp:43] Iteration 25590, lr = 0.02
I0526 08:02:07.737956 15394 main.cpp:465] Iteration 25600, Testing net (#0)
I0526 08:02:20.822715 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7825
I0526 08:02:20.822756 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.706579 (* 1 = 0.706579 loss)
I0526 08:02:21.361327 15394 main.cpp:354] Iteration 25600, loss = 0.303392
I0526 08:02:21.361366 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.303392 (* 1 = 0.303392 loss)
I0526 08:02:21.361372 15394 sgd_solver.cpp:43] Iteration 25600, lr = 0.02
I0526 08:02:26.029106 15394 main.cpp:354] Iteration 25610, loss = 0.670874
I0526 08:02:26.029152 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.670874 (* 1 = 0.670874 loss)
I0526 08:02:26.029160 15394 sgd_solver.cpp:43] Iteration 25610, lr = 0.02
I0526 08:02:30.549324 15394 main.cpp:354] Iteration 25620, loss = 0.695659
I0526 08:02:30.549363 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.695659 (* 1 = 0.695659 loss)
I0526 08:02:30.549371 15394 sgd_solver.cpp:43] Iteration 25620, lr = 0.02
I0526 08:02:35.442267 15394 main.cpp:354] Iteration 25630, loss = 0.472089
I0526 08:02:35.442307 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.472089 (* 1 = 0.472089 loss)
I0526 08:02:35.442313 15394 sgd_solver.cpp:43] Iteration 25630, lr = 0.02
I0526 08:02:40.204248 15394 main.cpp:354] Iteration 25640, loss = 0.332006
I0526 08:02:40.204293 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.332006 (* 1 = 0.332006 loss)
I0526 08:02:40.204301 15394 sgd_solver.cpp:43] Iteration 25640, lr = 0.02
I0526 08:02:44.949796 15394 main.cpp:354] Iteration 25650, loss = 0.648173
I0526 08:02:44.949836 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.648173 (* 1 = 0.648173 loss)
I0526 08:02:44.949841 15394 sgd_solver.cpp:43] Iteration 25650, lr = 0.02
I0526 08:02:50.237642 15394 main.cpp:354] Iteration 25660, loss = 0.368176
I0526 08:02:50.237681 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.368175 (* 1 = 0.368175 loss)
I0526 08:02:50.237689 15394 sgd_solver.cpp:43] Iteration 25660, lr = 0.02
I0526 08:02:55.687450 15394 main.cpp:354] Iteration 25670, loss = 0.223333
I0526 08:02:55.687494 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.223332 (* 1 = 0.223332 loss)
I0526 08:02:55.687500 15394 sgd_solver.cpp:43] Iteration 25670, lr = 0.02
I0526 08:03:00.678239 15394 main.cpp:354] Iteration 25680, loss = 0.415608
I0526 08:03:00.678278 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.415608 (* 1 = 0.415608 loss)
I0526 08:03:00.678284 15394 sgd_solver.cpp:43] Iteration 25680, lr = 0.02
I0526 08:03:05.972182 15394 main.cpp:354] Iteration 25690, loss = 0.38027
I0526 08:03:05.972232 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.38027 (* 1 = 0.38027 loss)
I0526 08:03:05.972239 15394 sgd_solver.cpp:43] Iteration 25690, lr = 0.02
I0526 08:03:10.663568 15394 main.cpp:465] Iteration 25700, Testing net (#0)
I0526 08:03:23.742602 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7597
I0526 08:03:23.742645 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.83228 (* 1 = 0.83228 loss)
I0526 08:03:24.103667 15394 main.cpp:354] Iteration 25700, loss = 0.959415
I0526 08:03:24.103709 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.959415 (* 1 = 0.959415 loss)
I0526 08:03:24.103716 15394 sgd_solver.cpp:43] Iteration 25700, lr = 0.02
I0526 08:03:29.131239 15394 main.cpp:354] Iteration 25710, loss = 0.53514
I0526 08:03:29.131281 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.53514 (* 1 = 0.53514 loss)
I0526 08:03:29.131289 15394 sgd_solver.cpp:43] Iteration 25710, lr = 0.02
I0526 08:03:34.298218 15394 main.cpp:354] Iteration 25720, loss = 0.200218
I0526 08:03:34.298259 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.200217 (* 1 = 0.200217 loss)
I0526 08:03:34.298266 15394 sgd_solver.cpp:43] Iteration 25720, lr = 0.02
I0526 08:03:39.253728 15394 main.cpp:354] Iteration 25730, loss = 0.311841
I0526 08:03:39.253763 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.311841 (* 1 = 0.311841 loss)
I0526 08:03:39.253770 15394 sgd_solver.cpp:43] Iteration 25730, lr = 0.02
I0526 08:03:44.265862 15394 main.cpp:354] Iteration 25740, loss = 0.332428
I0526 08:03:44.265907 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.332428 (* 1 = 0.332428 loss)
I0526 08:03:44.265913 15394 sgd_solver.cpp:43] Iteration 25740, lr = 0.02
I0526 08:03:49.669411 15394 main.cpp:354] Iteration 25750, loss = 0.304117
I0526 08:03:49.669457 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.304116 (* 1 = 0.304116 loss)
I0526 08:03:49.669463 15394 sgd_solver.cpp:43] Iteration 25750, lr = 0.02
I0526 08:03:54.698135 15394 main.cpp:354] Iteration 25760, loss = 0.559518
I0526 08:03:54.698176 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.559518 (* 1 = 0.559518 loss)
I0526 08:03:54.698182 15394 sgd_solver.cpp:43] Iteration 25760, lr = 0.02
I0526 08:03:59.607218 15394 main.cpp:354] Iteration 25770, loss = 0.500498
I0526 08:03:59.607259 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.500498 (* 1 = 0.500498 loss)
I0526 08:03:59.607266 15394 sgd_solver.cpp:43] Iteration 25770, lr = 0.02
I0526 08:04:04.769538 15394 main.cpp:354] Iteration 25780, loss = 0.220313
I0526 08:04:04.769572 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.220313 (* 1 = 0.220313 loss)
I0526 08:04:04.769578 15394 sgd_solver.cpp:43] Iteration 25780, lr = 0.02
I0526 08:04:10.196528 15394 main.cpp:354] Iteration 25790, loss = 0.174369
I0526 08:04:10.196571 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.174369 (* 1 = 0.174369 loss)
I0526 08:04:10.196578 15394 sgd_solver.cpp:43] Iteration 25790, lr = 0.02
I0526 08:04:15.186498 15394 main.cpp:465] Iteration 25800, Testing net (#0)
I0526 08:04:28.261891 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8165
I0526 08:04:28.261931 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.602433 (* 1 = 0.602433 loss)
I0526 08:04:28.620928 15394 main.cpp:354] Iteration 25800, loss = 0.629273
I0526 08:04:28.620965 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.629273 (* 1 = 0.629273 loss)
I0526 08:04:28.620971 15394 sgd_solver.cpp:43] Iteration 25800, lr = 0.02
I0526 08:04:33.622954 15394 main.cpp:354] Iteration 25810, loss = 0.324205
I0526 08:04:33.623003 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.324205 (* 1 = 0.324205 loss)
I0526 08:04:33.623011 15394 sgd_solver.cpp:43] Iteration 25810, lr = 0.02
I0526 08:04:38.644827 15394 main.cpp:354] Iteration 25820, loss = 0.445349
I0526 08:04:38.644867 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.445349 (* 1 = 0.445349 loss)
I0526 08:04:38.644875 15394 sgd_solver.cpp:43] Iteration 25820, lr = 0.02
I0526 08:04:44.026765 15394 main.cpp:354] Iteration 25830, loss = 0.280764
I0526 08:04:44.026806 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.280764 (* 1 = 0.280764 loss)
I0526 08:04:44.026813 15394 sgd_solver.cpp:43] Iteration 25830, lr = 0.02
I0526 08:04:49.253686 15394 main.cpp:354] Iteration 25840, loss = 0.319854
I0526 08:04:49.253731 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.319854 (* 1 = 0.319854 loss)
I0526 08:04:49.253737 15394 sgd_solver.cpp:43] Iteration 25840, lr = 0.02
I0526 08:04:54.642954 15394 main.cpp:354] Iteration 25850, loss = 0.236327
I0526 08:04:54.642994 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.236327 (* 1 = 0.236327 loss)
I0526 08:04:54.643000 15394 sgd_solver.cpp:43] Iteration 25850, lr = 0.02
I0526 08:04:59.765684 15394 main.cpp:354] Iteration 25860, loss = 0.446287
I0526 08:04:59.765724 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.446287 (* 1 = 0.446287 loss)
I0526 08:04:59.765732 15394 sgd_solver.cpp:43] Iteration 25860, lr = 0.02
I0526 08:05:04.546627 15394 main.cpp:354] Iteration 25870, loss = 0.41232
I0526 08:05:04.546671 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.41232 (* 1 = 0.41232 loss)
I0526 08:05:04.546679 15394 sgd_solver.cpp:43] Iteration 25870, lr = 0.02
I0526 08:05:09.537065 15394 main.cpp:354] Iteration 25880, loss = 0.444263
I0526 08:05:09.537104 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.444262 (* 1 = 0.444262 loss)
I0526 08:05:09.537111 15394 sgd_solver.cpp:43] Iteration 25880, lr = 0.02
I0526 08:05:14.762392 15394 main.cpp:354] Iteration 25890, loss = 0.365069
I0526 08:05:14.762431 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.365068 (* 1 = 0.365068 loss)
I0526 08:05:14.762444 15394 sgd_solver.cpp:43] Iteration 25890, lr = 0.02
I0526 08:05:19.460355 15394 main.cpp:465] Iteration 25900, Testing net (#0)
I0526 08:05:32.539597 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7926
I0526 08:05:32.539624 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.631623 (* 1 = 0.631623 loss)
I0526 08:05:33.047324 15394 main.cpp:354] Iteration 25900, loss = 0.378639
I0526 08:05:33.047348 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.378639 (* 1 = 0.378639 loss)
I0526 08:05:33.047355 15394 sgd_solver.cpp:43] Iteration 25900, lr = 0.02
I0526 08:05:38.353698 15394 main.cpp:354] Iteration 25910, loss = 0.378863
I0526 08:05:38.353737 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.378863 (* 1 = 0.378863 loss)
I0526 08:05:38.353744 15394 sgd_solver.cpp:43] Iteration 25910, lr = 0.02
I0526 08:05:43.622786 15394 main.cpp:354] Iteration 25920, loss = 0.313722
I0526 08:05:43.622825 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.313722 (* 1 = 0.313722 loss)
I0526 08:05:43.622831 15394 sgd_solver.cpp:43] Iteration 25920, lr = 0.02
I0526 08:05:48.404507 15394 main.cpp:354] Iteration 25930, loss = 0.621165
I0526 08:05:48.404551 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.621165 (* 1 = 0.621165 loss)
I0526 08:05:48.404557 15394 sgd_solver.cpp:43] Iteration 25930, lr = 0.02
I0526 08:05:52.661945 15394 main.cpp:354] Iteration 25940, loss = 0.368555
I0526 08:05:52.661985 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.368555 (* 1 = 0.368555 loss)
I0526 08:05:52.661993 15394 sgd_solver.cpp:43] Iteration 25940, lr = 0.02
I0526 08:05:57.226043 15394 main.cpp:354] Iteration 25950, loss = 0.507713
I0526 08:05:57.226073 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.507713 (* 1 = 0.507713 loss)
I0526 08:05:57.226080 15394 sgd_solver.cpp:43] Iteration 25950, lr = 0.02
I0526 08:06:02.236966 15394 main.cpp:354] Iteration 25960, loss = 0.324987
I0526 08:06:02.237005 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.324987 (* 1 = 0.324987 loss)
I0526 08:06:02.237011 15394 sgd_solver.cpp:43] Iteration 25960, lr = 0.02
I0526 08:06:06.944633 15394 main.cpp:354] Iteration 25970, loss = 0.452803
I0526 08:06:06.944676 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.452803 (* 1 = 0.452803 loss)
I0526 08:06:06.944682 15394 sgd_solver.cpp:43] Iteration 25970, lr = 0.02
I0526 08:06:11.973572 15394 main.cpp:354] Iteration 25980, loss = 0.277396
I0526 08:06:11.973613 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.277396 (* 1 = 0.277396 loss)
I0526 08:06:11.973619 15394 sgd_solver.cpp:43] Iteration 25980, lr = 0.02
I0526 08:06:17.277472 15394 main.cpp:354] Iteration 25990, loss = 0.396532
I0526 08:06:17.277508 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.396532 (* 1 = 0.396532 loss)
I0526 08:06:17.277514 15394 sgd_solver.cpp:43] Iteration 25990, lr = 0.02
I0526 08:06:21.826077 15394 main.cpp:465] Iteration 26000, Testing net (#0)
I0526 08:06:34.908084 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8205
I0526 08:06:34.908128 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.543866 (* 1 = 0.543866 loss)
I0526 08:06:35.380501 15394 main.cpp:354] Iteration 26000, loss = 0.263979
I0526 08:06:35.380542 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.263979 (* 1 = 0.263979 loss)
I0526 08:06:35.380549 15394 sgd_solver.cpp:43] Iteration 26000, lr = 0.02
I0526 08:06:40.443495 15394 main.cpp:354] Iteration 26010, loss = 0.209297
I0526 08:06:40.443534 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.209296 (* 1 = 0.209296 loss)
I0526 08:06:40.443541 15394 sgd_solver.cpp:43] Iteration 26010, lr = 0.02
I0526 08:06:45.481417 15394 main.cpp:354] Iteration 26020, loss = 0.401252
I0526 08:06:45.481458 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.401252 (* 1 = 0.401252 loss)
I0526 08:06:45.481465 15394 sgd_solver.cpp:43] Iteration 26020, lr = 0.02
I0526 08:06:50.431869 15394 main.cpp:354] Iteration 26030, loss = 0.332676
I0526 08:06:50.431913 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.332676 (* 1 = 0.332676 loss)
I0526 08:06:50.431921 15394 sgd_solver.cpp:43] Iteration 26030, lr = 0.02
I0526 08:06:55.245761 15394 main.cpp:354] Iteration 26040, loss = 0.457888
I0526 08:06:55.245815 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.457888 (* 1 = 0.457888 loss)
I0526 08:06:55.245821 15394 sgd_solver.cpp:43] Iteration 26040, lr = 0.02
I0526 08:07:00.723858 15394 main.cpp:354] Iteration 26050, loss = 0.586803
I0526 08:07:00.723902 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.586802 (* 1 = 0.586802 loss)
I0526 08:07:00.723909 15394 sgd_solver.cpp:43] Iteration 26050, lr = 0.02
I0526 08:07:06.006002 15394 main.cpp:354] Iteration 26060, loss = 0.501848
I0526 08:07:06.006045 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.501847 (* 1 = 0.501847 loss)
I0526 08:07:06.006052 15394 sgd_solver.cpp:43] Iteration 26060, lr = 0.02
I0526 08:07:10.494464 15394 main.cpp:354] Iteration 26070, loss = 0.348734
I0526 08:07:10.494504 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.348734 (* 1 = 0.348734 loss)
I0526 08:07:10.494511 15394 sgd_solver.cpp:43] Iteration 26070, lr = 0.02
I0526 08:07:15.145220 15394 main.cpp:354] Iteration 26080, loss = 0.427437
I0526 08:07:15.145265 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.427436 (* 1 = 0.427436 loss)
I0526 08:07:15.145272 15394 sgd_solver.cpp:43] Iteration 26080, lr = 0.02
I0526 08:07:20.760177 15394 main.cpp:354] Iteration 26090, loss = 0.308777
I0526 08:07:20.760216 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.308777 (* 1 = 0.308777 loss)
I0526 08:07:20.760224 15394 sgd_solver.cpp:43] Iteration 26090, lr = 0.02
I0526 08:07:25.415467 15394 main.cpp:465] Iteration 26100, Testing net (#0)
I0526 08:07:38.496424 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7795
I0526 08:07:38.496475 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.666647 (* 1 = 0.666647 loss)
I0526 08:07:38.934031 15394 main.cpp:354] Iteration 26100, loss = 0.335548
I0526 08:07:38.934057 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.335547 (* 1 = 0.335547 loss)
I0526 08:07:38.934065 15394 sgd_solver.cpp:43] Iteration 26100, lr = 0.02
I0526 08:07:44.057679 15394 main.cpp:354] Iteration 26110, loss = 0.299613
I0526 08:07:44.057723 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.299612 (* 1 = 0.299612 loss)
I0526 08:07:44.057730 15394 sgd_solver.cpp:43] Iteration 26110, lr = 0.02
I0526 08:07:48.810909 15394 main.cpp:354] Iteration 26120, loss = 0.408645
I0526 08:07:48.810948 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.408645 (* 1 = 0.408645 loss)
I0526 08:07:48.810955 15394 sgd_solver.cpp:43] Iteration 26120, lr = 0.02
I0526 08:07:53.763967 15394 main.cpp:354] Iteration 26130, loss = 0.316314
I0526 08:07:53.764006 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.316314 (* 1 = 0.316314 loss)
I0526 08:07:53.764013 15394 sgd_solver.cpp:43] Iteration 26130, lr = 0.02
I0526 08:07:58.547507 15394 main.cpp:354] Iteration 26140, loss = 0.490383
I0526 08:07:58.547549 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.490383 (* 1 = 0.490383 loss)
I0526 08:07:58.547555 15394 sgd_solver.cpp:43] Iteration 26140, lr = 0.02
I0526 08:08:03.478628 15394 main.cpp:354] Iteration 26150, loss = 0.157984
I0526 08:08:03.478682 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.157984 (* 1 = 0.157984 loss)
I0526 08:08:03.478688 15394 sgd_solver.cpp:43] Iteration 26150, lr = 0.02
I0526 08:08:08.678230 15394 main.cpp:354] Iteration 26160, loss = 0.348582
I0526 08:08:08.678268 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.348581 (* 1 = 0.348581 loss)
I0526 08:08:08.678274 15394 sgd_solver.cpp:43] Iteration 26160, lr = 0.02
I0526 08:08:13.921931 15394 main.cpp:354] Iteration 26170, loss = 0.310933
I0526 08:08:13.921980 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.310933 (* 1 = 0.310933 loss)
I0526 08:08:13.921988 15394 sgd_solver.cpp:43] Iteration 26170, lr = 0.02
I0526 08:08:19.273573 15394 main.cpp:354] Iteration 26180, loss = 0.244234
I0526 08:08:19.273612 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.244234 (* 1 = 0.244234 loss)
I0526 08:08:19.273619 15394 sgd_solver.cpp:43] Iteration 26180, lr = 0.02
I0526 08:08:24.505625 15394 main.cpp:354] Iteration 26190, loss = 0.398837
I0526 08:08:24.505663 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.398837 (* 1 = 0.398837 loss)
I0526 08:08:24.505671 15394 sgd_solver.cpp:43] Iteration 26190, lr = 0.02
I0526 08:08:28.904822 15394 main.cpp:465] Iteration 26200, Testing net (#0)
I0526 08:08:41.990775 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7416
I0526 08:08:41.990813 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.886315 (* 1 = 0.886315 loss)
I0526 08:08:42.530493 15394 main.cpp:354] Iteration 26200, loss = 0.287776
I0526 08:08:42.530529 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.287776 (* 1 = 0.287776 loss)
I0526 08:08:42.530535 15394 sgd_solver.cpp:43] Iteration 26200, lr = 0.02
I0526 08:08:47.418382 15394 main.cpp:354] Iteration 26210, loss = 0.695312
I0526 08:08:47.418422 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.695312 (* 1 = 0.695312 loss)
I0526 08:08:47.418429 15394 sgd_solver.cpp:43] Iteration 26210, lr = 0.02
I0526 08:08:52.440577 15394 main.cpp:354] Iteration 26220, loss = 0.338656
I0526 08:08:52.440616 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.338656 (* 1 = 0.338656 loss)
I0526 08:08:52.440623 15394 sgd_solver.cpp:43] Iteration 26220, lr = 0.02
I0526 08:08:57.550631 15394 main.cpp:354] Iteration 26230, loss = 0.473851
I0526 08:08:57.550675 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.473851 (* 1 = 0.473851 loss)
I0526 08:08:57.550693 15394 sgd_solver.cpp:43] Iteration 26230, lr = 0.02
I0526 08:09:02.358115 15394 main.cpp:354] Iteration 26240, loss = 0.424765
I0526 08:09:02.358155 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.424765 (* 1 = 0.424765 loss)
I0526 08:09:02.358161 15394 sgd_solver.cpp:43] Iteration 26240, lr = 0.02
I0526 08:09:07.874311 15394 main.cpp:354] Iteration 26250, loss = 0.277763
I0526 08:09:07.874351 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.277763 (* 1 = 0.277763 loss)
I0526 08:09:07.874363 15394 sgd_solver.cpp:43] Iteration 26250, lr = 0.02
I0526 08:09:12.880852 15394 main.cpp:354] Iteration 26260, loss = 0.314765
I0526 08:09:12.880906 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.314765 (* 1 = 0.314765 loss)
I0526 08:09:12.880913 15394 sgd_solver.cpp:43] Iteration 26260, lr = 0.02
I0526 08:09:18.410506 15394 main.cpp:354] Iteration 26270, loss = 0.335859
I0526 08:09:18.410547 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.335859 (* 1 = 0.335859 loss)
I0526 08:09:18.410553 15394 sgd_solver.cpp:43] Iteration 26270, lr = 0.02
I0526 08:09:23.415401 15394 main.cpp:354] Iteration 26280, loss = 0.461793
I0526 08:09:23.415441 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.461793 (* 1 = 0.461793 loss)
I0526 08:09:23.415448 15394 sgd_solver.cpp:43] Iteration 26280, lr = 0.02
I0526 08:09:28.203608 15394 main.cpp:354] Iteration 26290, loss = 0.277608
I0526 08:09:28.203649 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.277608 (* 1 = 0.277608 loss)
I0526 08:09:28.203655 15394 sgd_solver.cpp:43] Iteration 26290, lr = 0.02
I0526 08:09:32.689664 15394 main.cpp:465] Iteration 26300, Testing net (#0)
I0526 08:09:45.771009 15394 main.cpp:532]     Test net output #0: Accuracy = 0.771
I0526 08:09:45.771051 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.72946 (* 1 = 0.72946 loss)
I0526 08:09:46.273298 15394 main.cpp:354] Iteration 26300, loss = 0.437574
I0526 08:09:46.273340 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.437574 (* 1 = 0.437574 loss)
I0526 08:09:46.273353 15394 sgd_solver.cpp:43] Iteration 26300, lr = 0.02
I0526 08:09:51.421859 15394 main.cpp:354] Iteration 26310, loss = 0.394985
I0526 08:09:51.421890 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.394985 (* 1 = 0.394985 loss)
I0526 08:09:51.421896 15394 sgd_solver.cpp:43] Iteration 26310, lr = 0.02
I0526 08:09:56.998834 15394 main.cpp:354] Iteration 26320, loss = 0.355553
I0526 08:09:56.998879 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.355553 (* 1 = 0.355553 loss)
I0526 08:09:56.998886 15394 sgd_solver.cpp:43] Iteration 26320, lr = 0.02
I0526 08:10:01.957161 15394 main.cpp:354] Iteration 26330, loss = 0.327942
I0526 08:10:01.957201 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.327942 (* 1 = 0.327942 loss)
I0526 08:10:01.957206 15394 sgd_solver.cpp:43] Iteration 26330, lr = 0.02
I0526 08:10:07.163276 15394 main.cpp:354] Iteration 26340, loss = 0.416374
I0526 08:10:07.163316 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.416374 (* 1 = 0.416374 loss)
I0526 08:10:07.163321 15394 sgd_solver.cpp:43] Iteration 26340, lr = 0.02
I0526 08:10:11.982447 15394 main.cpp:354] Iteration 26350, loss = 0.244425
I0526 08:10:11.982491 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.244424 (* 1 = 0.244424 loss)
I0526 08:10:11.982498 15394 sgd_solver.cpp:43] Iteration 26350, lr = 0.02
I0526 08:10:17.423118 15394 main.cpp:354] Iteration 26360, loss = 0.326302
I0526 08:10:17.423157 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.326302 (* 1 = 0.326302 loss)
I0526 08:10:17.423163 15394 sgd_solver.cpp:43] Iteration 26360, lr = 0.02
I0526 08:10:22.364122 15394 main.cpp:354] Iteration 26370, loss = 0.350253
I0526 08:10:22.364163 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.350253 (* 1 = 0.350253 loss)
I0526 08:10:22.364169 15394 sgd_solver.cpp:43] Iteration 26370, lr = 0.02
I0526 08:10:27.328646 15394 main.cpp:354] Iteration 26380, loss = 0.432604
I0526 08:10:27.328692 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.432604 (* 1 = 0.432604 loss)
I0526 08:10:27.328699 15394 sgd_solver.cpp:43] Iteration 26380, lr = 0.02
I0526 08:10:32.326231 15394 main.cpp:354] Iteration 26390, loss = 0.324973
I0526 08:10:32.326270 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.324973 (* 1 = 0.324973 loss)
I0526 08:10:32.326277 15394 sgd_solver.cpp:43] Iteration 26390, lr = 0.02
I0526 08:10:36.321915 15394 main.cpp:465] Iteration 26400, Testing net (#0)
I0526 08:10:49.403864 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7314
I0526 08:10:49.403909 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.930147 (* 1 = 0.930147 loss)
I0526 08:10:49.909000 15394 main.cpp:354] Iteration 26400, loss = 0.306346
I0526 08:10:49.909041 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.306345 (* 1 = 0.306345 loss)
I0526 08:10:49.909050 15394 sgd_solver.cpp:43] Iteration 26400, lr = 0.02
I0526 08:10:55.369262 15394 main.cpp:354] Iteration 26410, loss = 0.285544
I0526 08:10:55.369302 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.285544 (* 1 = 0.285544 loss)
I0526 08:10:55.369310 15394 sgd_solver.cpp:43] Iteration 26410, lr = 0.02
I0526 08:11:00.355141 15394 main.cpp:354] Iteration 26420, loss = 0.278485
I0526 08:11:00.355181 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.278484 (* 1 = 0.278484 loss)
I0526 08:11:00.355188 15394 sgd_solver.cpp:43] Iteration 26420, lr = 0.02
I0526 08:11:05.256232 15394 main.cpp:354] Iteration 26430, loss = 0.449492
I0526 08:11:05.256270 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.449492 (* 1 = 0.449492 loss)
I0526 08:11:05.256278 15394 sgd_solver.cpp:43] Iteration 26430, lr = 0.02
I0526 08:11:10.111076 15394 main.cpp:354] Iteration 26440, loss = 0.404036
I0526 08:11:10.111115 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.404035 (* 1 = 0.404035 loss)
I0526 08:11:10.111122 15394 sgd_solver.cpp:43] Iteration 26440, lr = 0.02
I0526 08:11:14.988844 15394 main.cpp:354] Iteration 26450, loss = 0.248819
I0526 08:11:14.988886 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.248819 (* 1 = 0.248819 loss)
I0526 08:11:14.988893 15394 sgd_solver.cpp:43] Iteration 26450, lr = 0.02
I0526 08:11:20.139371 15394 main.cpp:354] Iteration 26460, loss = 0.426864
I0526 08:11:20.139410 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.426864 (* 1 = 0.426864 loss)
I0526 08:11:20.139417 15394 sgd_solver.cpp:43] Iteration 26460, lr = 0.02
I0526 08:11:25.467612 15394 main.cpp:354] Iteration 26470, loss = 0.326295
I0526 08:11:25.467653 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.326295 (* 1 = 0.326295 loss)
I0526 08:11:25.467659 15394 sgd_solver.cpp:43] Iteration 26470, lr = 0.02
I0526 08:11:30.583591 15394 main.cpp:354] Iteration 26480, loss = 0.202677
I0526 08:11:30.583634 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.202677 (* 1 = 0.202677 loss)
I0526 08:11:30.583642 15394 sgd_solver.cpp:43] Iteration 26480, lr = 0.02
I0526 08:11:35.718144 15394 main.cpp:354] Iteration 26490, loss = 0.289397
I0526 08:11:35.718185 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.289396 (* 1 = 0.289396 loss)
I0526 08:11:35.718192 15394 sgd_solver.cpp:43] Iteration 26490, lr = 0.02
I0526 08:11:40.552793 15394 main.cpp:465] Iteration 26500, Testing net (#0)
I0526 08:11:53.641674 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7178
I0526 08:11:53.641716 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 1.00244 (* 1 = 1.00244 loss)
I0526 08:11:54.119065 15394 main.cpp:354] Iteration 26500, loss = 0.346296
I0526 08:11:54.119104 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.346295 (* 1 = 0.346295 loss)
I0526 08:11:54.119112 15394 sgd_solver.cpp:43] Iteration 26500, lr = 0.02
I0526 08:11:59.294307 15394 main.cpp:354] Iteration 26510, loss = 0.288637
I0526 08:11:59.294350 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.288637 (* 1 = 0.288637 loss)
I0526 08:11:59.294361 15394 sgd_solver.cpp:43] Iteration 26510, lr = 0.02
I0526 08:12:03.666087 15394 main.cpp:354] Iteration 26520, loss = 0.584367
I0526 08:12:03.666126 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.584367 (* 1 = 0.584367 loss)
I0526 08:12:03.666133 15394 sgd_solver.cpp:43] Iteration 26520, lr = 0.02
I0526 08:12:08.789593 15394 main.cpp:354] Iteration 26530, loss = 0.370604
I0526 08:12:08.789634 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.370604 (* 1 = 0.370604 loss)
I0526 08:12:08.789640 15394 sgd_solver.cpp:43] Iteration 26530, lr = 0.02
I0526 08:12:13.832880 15394 main.cpp:354] Iteration 26540, loss = 0.169862
I0526 08:12:13.832926 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.169862 (* 1 = 0.169862 loss)
I0526 08:12:13.832933 15394 sgd_solver.cpp:43] Iteration 26540, lr = 0.02
I0526 08:12:19.370225 15394 main.cpp:354] Iteration 26550, loss = 0.177164
I0526 08:12:19.370266 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.177163 (* 1 = 0.177163 loss)
I0526 08:12:19.370272 15394 sgd_solver.cpp:43] Iteration 26550, lr = 0.02
I0526 08:12:24.168084 15394 main.cpp:354] Iteration 26560, loss = 0.284622
I0526 08:12:24.168123 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.284621 (* 1 = 0.284621 loss)
I0526 08:12:24.168129 15394 sgd_solver.cpp:43] Iteration 26560, lr = 0.02
I0526 08:12:28.755837 15394 main.cpp:354] Iteration 26570, loss = 0.285058
I0526 08:12:28.755864 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.285057 (* 1 = 0.285057 loss)
I0526 08:12:28.755870 15394 sgd_solver.cpp:43] Iteration 26570, lr = 0.02
I0526 08:12:33.861207 15394 main.cpp:354] Iteration 26580, loss = 0.387429
I0526 08:12:33.861245 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.387429 (* 1 = 0.387429 loss)
I0526 08:12:33.861251 15394 sgd_solver.cpp:43] Iteration 26580, lr = 0.02
I0526 08:12:38.986439 15394 main.cpp:354] Iteration 26590, loss = 0.322456
I0526 08:12:38.986484 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.322456 (* 1 = 0.322456 loss)
I0526 08:12:38.986491 15394 sgd_solver.cpp:43] Iteration 26590, lr = 0.02
I0526 08:12:43.890889 15394 main.cpp:465] Iteration 26600, Testing net (#0)
I0526 08:12:56.976713 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7609
I0526 08:12:56.976754 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.807276 (* 1 = 0.807276 loss)
I0526 08:12:57.409162 15394 main.cpp:354] Iteration 26600, loss = 0.522377
I0526 08:12:57.409201 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.522377 (* 1 = 0.522377 loss)
I0526 08:12:57.409209 15394 sgd_solver.cpp:43] Iteration 26600, lr = 0.02
I0526 08:13:02.523135 15394 main.cpp:354] Iteration 26610, loss = 0.382553
I0526 08:13:02.523176 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.382552 (* 1 = 0.382552 loss)
I0526 08:13:02.523182 15394 sgd_solver.cpp:43] Iteration 26610, lr = 0.02
I0526 08:13:07.033171 15394 main.cpp:354] Iteration 26620, loss = 0.409631
I0526 08:13:07.033205 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.409631 (* 1 = 0.409631 loss)
I0526 08:13:07.033211 15394 sgd_solver.cpp:43] Iteration 26620, lr = 0.02
I0526 08:13:12.223067 15394 main.cpp:354] Iteration 26630, loss = 0.312792
I0526 08:13:12.223110 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.312792 (* 1 = 0.312792 loss)
I0526 08:13:12.223117 15394 sgd_solver.cpp:43] Iteration 26630, lr = 0.02
I0526 08:13:17.247139 15394 main.cpp:354] Iteration 26640, loss = 0.310322
I0526 08:13:17.247179 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.310321 (* 1 = 0.310321 loss)
I0526 08:13:17.247186 15394 sgd_solver.cpp:43] Iteration 26640, lr = 0.02
I0526 08:13:22.284847 15394 main.cpp:354] Iteration 26650, loss = 0.273644
I0526 08:13:22.284885 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.273644 (* 1 = 0.273644 loss)
I0526 08:13:22.284893 15394 sgd_solver.cpp:43] Iteration 26650, lr = 0.02
I0526 08:13:27.703616 15394 main.cpp:354] Iteration 26660, loss = 0.447628
I0526 08:13:27.703660 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.447628 (* 1 = 0.447628 loss)
I0526 08:13:27.703666 15394 sgd_solver.cpp:43] Iteration 26660, lr = 0.02
I0526 08:13:32.978929 15394 main.cpp:354] Iteration 26670, loss = 0.628157
I0526 08:13:32.978967 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.628157 (* 1 = 0.628157 loss)
I0526 08:13:32.978973 15394 sgd_solver.cpp:43] Iteration 26670, lr = 0.02
I0526 08:13:38.408049 15394 main.cpp:354] Iteration 26680, loss = 0.227079
I0526 08:13:38.408090 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.227079 (* 1 = 0.227079 loss)
I0526 08:13:38.408097 15394 sgd_solver.cpp:43] Iteration 26680, lr = 0.02
I0526 08:13:43.098266 15394 main.cpp:354] Iteration 26690, loss = 0.745215
I0526 08:13:43.098309 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.745215 (* 1 = 0.745215 loss)
I0526 08:13:43.098315 15394 sgd_solver.cpp:43] Iteration 26690, lr = 0.02
I0526 08:13:47.897452 15394 main.cpp:465] Iteration 26700, Testing net (#0)
I0526 08:14:00.979156 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7901
I0526 08:14:00.979197 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.678182 (* 1 = 0.678182 loss)
I0526 08:14:01.449851 15394 main.cpp:354] Iteration 26700, loss = 0.37744
I0526 08:14:01.449882 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.377439 (* 1 = 0.377439 loss)
I0526 08:14:01.449889 15394 sgd_solver.cpp:43] Iteration 26700, lr = 0.02
I0526 08:14:06.063200 15394 main.cpp:354] Iteration 26710, loss = 0.740733
I0526 08:14:06.063238 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.740733 (* 1 = 0.740733 loss)
I0526 08:14:06.063246 15394 sgd_solver.cpp:43] Iteration 26710, lr = 0.02
I0526 08:14:10.978584 15394 main.cpp:354] Iteration 26720, loss = 0.351796
I0526 08:14:10.978623 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.351796 (* 1 = 0.351796 loss)
I0526 08:14:10.978634 15394 sgd_solver.cpp:43] Iteration 26720, lr = 0.02
I0526 08:14:16.071213 15394 main.cpp:354] Iteration 26730, loss = 0.424777
I0526 08:14:16.071246 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.424777 (* 1 = 0.424777 loss)
I0526 08:14:16.071254 15394 sgd_solver.cpp:43] Iteration 26730, lr = 0.02
I0526 08:14:21.312705 15394 main.cpp:354] Iteration 26740, loss = 0.32357
I0526 08:14:21.312744 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.32357 (* 1 = 0.32357 loss)
I0526 08:14:21.312750 15394 sgd_solver.cpp:43] Iteration 26740, lr = 0.02
I0526 08:14:26.503793 15394 main.cpp:354] Iteration 26750, loss = 0.242696
I0526 08:14:26.503834 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.242696 (* 1 = 0.242696 loss)
I0526 08:14:26.503841 15394 sgd_solver.cpp:43] Iteration 26750, lr = 0.02
I0526 08:14:31.603709 15394 main.cpp:354] Iteration 26760, loss = 0.401609
I0526 08:14:31.603749 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.401608 (* 1 = 0.401608 loss)
I0526 08:14:31.603754 15394 sgd_solver.cpp:43] Iteration 26760, lr = 0.02
I0526 08:14:36.942287 15394 main.cpp:354] Iteration 26770, loss = 0.352179
I0526 08:14:36.942328 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.352178 (* 1 = 0.352178 loss)
I0526 08:14:36.942335 15394 sgd_solver.cpp:43] Iteration 26770, lr = 0.02
I0526 08:14:42.304198 15394 main.cpp:354] Iteration 26780, loss = 0.292953
I0526 08:14:42.304257 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.292953 (* 1 = 0.292953 loss)
I0526 08:14:42.304265 15394 sgd_solver.cpp:43] Iteration 26780, lr = 0.02
I0526 08:14:47.195375 15394 main.cpp:354] Iteration 26790, loss = 0.271977
I0526 08:14:47.195411 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.271977 (* 1 = 0.271977 loss)
I0526 08:14:47.195418 15394 sgd_solver.cpp:43] Iteration 26790, lr = 0.02
I0526 08:14:51.361196 15394 main.cpp:465] Iteration 26800, Testing net (#0)
I0526 08:15:04.440302 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8349
I0526 08:15:04.440342 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.511607 (* 1 = 0.511607 loss)
I0526 08:15:04.979773 15394 main.cpp:354] Iteration 26800, loss = 0.251515
I0526 08:15:04.979809 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.251515 (* 1 = 0.251515 loss)
I0526 08:15:04.979815 15394 sgd_solver.cpp:43] Iteration 26800, lr = 0.02
I0526 08:15:09.783378 15394 main.cpp:354] Iteration 26810, loss = 0.427017
I0526 08:15:09.783421 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.427017 (* 1 = 0.427017 loss)
I0526 08:15:09.783427 15394 sgd_solver.cpp:43] Iteration 26810, lr = 0.02
I0526 08:15:14.762022 15394 main.cpp:354] Iteration 26820, loss = 0.746439
I0526 08:15:14.762064 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.746439 (* 1 = 0.746439 loss)
I0526 08:15:14.762071 15394 sgd_solver.cpp:43] Iteration 26820, lr = 0.02
I0526 08:15:19.791091 15394 main.cpp:354] Iteration 26830, loss = 0.251866
I0526 08:15:19.791131 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.251865 (* 1 = 0.251865 loss)
I0526 08:15:19.791138 15394 sgd_solver.cpp:43] Iteration 26830, lr = 0.02
I0526 08:15:24.900115 15394 main.cpp:354] Iteration 26840, loss = 0.390316
I0526 08:15:24.900154 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.390316 (* 1 = 0.390316 loss)
I0526 08:15:24.900161 15394 sgd_solver.cpp:43] Iteration 26840, lr = 0.02
I0526 08:15:30.072350 15394 main.cpp:354] Iteration 26850, loss = 0.274633
I0526 08:15:30.072392 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.274632 (* 1 = 0.274632 loss)
I0526 08:15:30.072398 15394 sgd_solver.cpp:43] Iteration 26850, lr = 0.02
I0526 08:15:35.164389 15394 main.cpp:354] Iteration 26860, loss = 0.46842
I0526 08:15:35.164433 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.46842 (* 1 = 0.46842 loss)
I0526 08:15:35.164439 15394 sgd_solver.cpp:43] Iteration 26860, lr = 0.02
I0526 08:15:39.987411 15394 main.cpp:354] Iteration 26870, loss = 0.266208
I0526 08:15:39.987454 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.266208 (* 1 = 0.266208 loss)
I0526 08:15:39.987462 15394 sgd_solver.cpp:43] Iteration 26870, lr = 0.02
I0526 08:15:45.525467 15394 main.cpp:354] Iteration 26880, loss = 0.141972
I0526 08:15:45.525509 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.141972 (* 1 = 0.141972 loss)
I0526 08:15:45.525516 15394 sgd_solver.cpp:43] Iteration 26880, lr = 0.02
I0526 08:15:50.770150 15394 main.cpp:354] Iteration 26890, loss = 0.39761
I0526 08:15:50.770195 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.397609 (* 1 = 0.397609 loss)
I0526 08:15:50.770201 15394 sgd_solver.cpp:43] Iteration 26890, lr = 0.02
I0526 08:15:55.362860 15394 main.cpp:465] Iteration 26900, Testing net (#0)
I0526 08:16:08.445854 15394 main.cpp:532]     Test net output #0: Accuracy = 0.85
I0526 08:16:08.445894 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.468937 (* 1 = 0.468937 loss)
I0526 08:16:08.985124 15394 main.cpp:354] Iteration 26900, loss = 0.181991
I0526 08:16:08.985159 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.181991 (* 1 = 0.181991 loss)
I0526 08:16:08.985167 15394 sgd_solver.cpp:43] Iteration 26900, lr = 0.02
I0526 08:16:14.638011 15394 main.cpp:354] Iteration 26910, loss = 0.315839
I0526 08:16:14.638049 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.315839 (* 1 = 0.315839 loss)
I0526 08:16:14.638056 15394 sgd_solver.cpp:43] Iteration 26910, lr = 0.02
I0526 08:16:19.948669 15394 main.cpp:354] Iteration 26920, loss = 0.263405
I0526 08:16:19.948714 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.263405 (* 1 = 0.263405 loss)
I0526 08:16:19.948719 15394 sgd_solver.cpp:43] Iteration 26920, lr = 0.02
I0526 08:16:24.593935 15394 main.cpp:354] Iteration 26930, loss = 0.456771
I0526 08:16:24.593974 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.456771 (* 1 = 0.456771 loss)
I0526 08:16:24.593981 15394 sgd_solver.cpp:43] Iteration 26930, lr = 0.02
I0526 08:16:29.689808 15394 main.cpp:354] Iteration 26940, loss = 0.392991
I0526 08:16:29.689849 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.392991 (* 1 = 0.392991 loss)
I0526 08:16:29.689856 15394 sgd_solver.cpp:43] Iteration 26940, lr = 0.02
I0526 08:16:35.027945 15394 main.cpp:354] Iteration 26950, loss = 0.239184
I0526 08:16:35.027976 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.239184 (* 1 = 0.239184 loss)
I0526 08:16:35.027981 15394 sgd_solver.cpp:43] Iteration 26950, lr = 0.02
I0526 08:16:39.934710 15394 main.cpp:354] Iteration 26960, loss = 0.293628
I0526 08:16:39.934751 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.293628 (* 1 = 0.293628 loss)
I0526 08:16:39.934756 15394 sgd_solver.cpp:43] Iteration 26960, lr = 0.02
I0526 08:16:45.278170 15394 main.cpp:354] Iteration 26970, loss = 0.358323
I0526 08:16:45.278210 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.358322 (* 1 = 0.358322 loss)
I0526 08:16:45.278216 15394 sgd_solver.cpp:43] Iteration 26970, lr = 0.02
I0526 08:16:50.620937 15394 main.cpp:354] Iteration 26980, loss = 0.294408
I0526 08:16:50.620980 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.294407 (* 1 = 0.294407 loss)
I0526 08:16:50.620985 15394 sgd_solver.cpp:43] Iteration 26980, lr = 0.02
I0526 08:16:56.014987 15394 main.cpp:354] Iteration 26990, loss = 0.108545
I0526 08:16:56.015030 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.108545 (* 1 = 0.108545 loss)
I0526 08:16:56.015038 15394 sgd_solver.cpp:43] Iteration 26990, lr = 0.02
I0526 08:17:00.776231 15394 main.cpp:465] Iteration 27000, Testing net (#0)
I0526 08:17:13.853618 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7829
I0526 08:17:13.853660 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.720622 (* 1 = 0.720622 loss)
I0526 08:17:14.253088 15394 main.cpp:354] Iteration 27000, loss = 0.429008
I0526 08:17:14.253129 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.429008 (* 1 = 0.429008 loss)
I0526 08:17:14.253144 15394 sgd_solver.cpp:43] Iteration 27000, lr = 0.02
I0526 08:17:19.417608 15394 main.cpp:354] Iteration 27010, loss = 0.351296
I0526 08:17:19.417646 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.351296 (* 1 = 0.351296 loss)
I0526 08:17:19.417654 15394 sgd_solver.cpp:43] Iteration 27010, lr = 0.02
I0526 08:17:24.424546 15394 main.cpp:354] Iteration 27020, loss = 0.437798
I0526 08:17:24.424587 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.437798 (* 1 = 0.437798 loss)
I0526 08:17:24.424592 15394 sgd_solver.cpp:43] Iteration 27020, lr = 0.02
I0526 08:17:29.227354 15394 main.cpp:354] Iteration 27030, loss = 0.302425
I0526 08:17:29.227391 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.302424 (* 1 = 0.302424 loss)
I0526 08:17:29.227397 15394 sgd_solver.cpp:43] Iteration 27030, lr = 0.02
I0526 08:17:34.021332 15394 main.cpp:354] Iteration 27040, loss = 0.39808
I0526 08:17:34.021373 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.39808 (* 1 = 0.39808 loss)
I0526 08:17:34.021380 15394 sgd_solver.cpp:43] Iteration 27040, lr = 0.02
I0526 08:17:39.305886 15394 main.cpp:354] Iteration 27050, loss = 0.264597
I0526 08:17:39.305927 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.264597 (* 1 = 0.264597 loss)
I0526 08:17:39.305933 15394 sgd_solver.cpp:43] Iteration 27050, lr = 0.02
I0526 08:17:44.174757 15394 main.cpp:354] Iteration 27060, loss = 0.425962
I0526 08:17:44.174793 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.425962 (* 1 = 0.425962 loss)
I0526 08:17:44.174799 15394 sgd_solver.cpp:43] Iteration 27060, lr = 0.02
I0526 08:17:49.472628 15394 main.cpp:354] Iteration 27070, loss = 0.277934
I0526 08:17:49.472669 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.277933 (* 1 = 0.277933 loss)
I0526 08:17:49.472676 15394 sgd_solver.cpp:43] Iteration 27070, lr = 0.02
I0526 08:17:55.014154 15394 main.cpp:354] Iteration 27080, loss = 0.442645
I0526 08:17:55.014194 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.442645 (* 1 = 0.442645 loss)
I0526 08:17:55.014199 15394 sgd_solver.cpp:43] Iteration 27080, lr = 0.02
I0526 08:18:00.462378 15394 main.cpp:354] Iteration 27090, loss = 0.24126
I0526 08:18:00.462419 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.24126 (* 1 = 0.24126 loss)
I0526 08:18:00.462425 15394 sgd_solver.cpp:43] Iteration 27090, lr = 0.02
I0526 08:18:04.912258 15394 main.cpp:465] Iteration 27100, Testing net (#0)
I0526 08:18:18.002221 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8493
I0526 08:18:18.002264 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.453277 (* 1 = 0.453277 loss)
I0526 08:18:18.443197 15394 main.cpp:354] Iteration 27100, loss = 0.266445
I0526 08:18:18.443239 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.266445 (* 1 = 0.266445 loss)
I0526 08:18:18.443246 15394 sgd_solver.cpp:43] Iteration 27100, lr = 0.02
I0526 08:18:23.284749 15394 main.cpp:354] Iteration 27110, loss = 0.365153
I0526 08:18:23.284792 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.365153 (* 1 = 0.365153 loss)
I0526 08:18:23.284800 15394 sgd_solver.cpp:43] Iteration 27110, lr = 0.02
I0526 08:18:28.373306 15394 main.cpp:354] Iteration 27120, loss = 0.342873
I0526 08:18:28.373348 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.342873 (* 1 = 0.342873 loss)
I0526 08:18:28.373355 15394 sgd_solver.cpp:43] Iteration 27120, lr = 0.02
I0526 08:18:33.186872 15394 main.cpp:354] Iteration 27130, loss = 0.586876
I0526 08:18:33.186915 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.586876 (* 1 = 0.586876 loss)
I0526 08:18:33.186924 15394 sgd_solver.cpp:43] Iteration 27130, lr = 0.02
I0526 08:18:38.621037 15394 main.cpp:354] Iteration 27140, loss = 0.455116
I0526 08:18:38.621075 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.455116 (* 1 = 0.455116 loss)
I0526 08:18:38.621088 15394 sgd_solver.cpp:43] Iteration 27140, lr = 0.02
I0526 08:18:43.061290 15394 main.cpp:354] Iteration 27150, loss = 0.634749
I0526 08:18:43.061334 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.634749 (* 1 = 0.634749 loss)
I0526 08:18:43.061341 15394 sgd_solver.cpp:43] Iteration 27150, lr = 0.02
I0526 08:18:48.445912 15394 main.cpp:354] Iteration 27160, loss = 0.295842
I0526 08:18:48.445951 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.295842 (* 1 = 0.295842 loss)
I0526 08:18:48.445958 15394 sgd_solver.cpp:43] Iteration 27160, lr = 0.02
I0526 08:18:53.682613 15394 main.cpp:354] Iteration 27170, loss = 0.354807
I0526 08:18:53.682641 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.354806 (* 1 = 0.354806 loss)
I0526 08:18:53.682646 15394 sgd_solver.cpp:43] Iteration 27170, lr = 0.02
I0526 08:18:58.479984 15394 main.cpp:354] Iteration 27180, loss = 0.381818
I0526 08:18:58.480026 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.381818 (* 1 = 0.381818 loss)
I0526 08:18:58.480032 15394 sgd_solver.cpp:43] Iteration 27180, lr = 0.02
I0526 08:19:03.484112 15394 main.cpp:354] Iteration 27190, loss = 0.181628
I0526 08:19:03.484149 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.181628 (* 1 = 0.181628 loss)
I0526 08:19:03.484156 15394 sgd_solver.cpp:43] Iteration 27190, lr = 0.02
I0526 08:19:07.939697 15394 main.cpp:465] Iteration 27200, Testing net (#0)
I0526 08:19:21.020938 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8392
I0526 08:19:21.020980 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.519845 (* 1 = 0.519845 loss)
I0526 08:19:21.456009 15394 main.cpp:354] Iteration 27200, loss = 0.334967
I0526 08:19:21.456044 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.334967 (* 1 = 0.334967 loss)
I0526 08:19:21.456053 15394 sgd_solver.cpp:43] Iteration 27200, lr = 0.02
I0526 08:19:26.026958 15394 main.cpp:354] Iteration 27210, loss = 1.23061
I0526 08:19:26.026998 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.23061 (* 1 = 1.23061 loss)
I0526 08:19:26.027003 15394 sgd_solver.cpp:43] Iteration 27210, lr = 0.02
I0526 08:19:30.699666 15394 main.cpp:354] Iteration 27220, loss = 0.32238
I0526 08:19:30.699709 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.32238 (* 1 = 0.32238 loss)
I0526 08:19:30.699717 15394 sgd_solver.cpp:43] Iteration 27220, lr = 0.02
I0526 08:19:35.659139 15394 main.cpp:354] Iteration 27230, loss = 0.259745
I0526 08:19:35.659180 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.259745 (* 1 = 0.259745 loss)
I0526 08:19:35.659186 15394 sgd_solver.cpp:43] Iteration 27230, lr = 0.02
I0526 08:19:41.099329 15394 main.cpp:354] Iteration 27240, loss = 0.353519
I0526 08:19:41.099370 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.353518 (* 1 = 0.353518 loss)
I0526 08:19:41.099377 15394 sgd_solver.cpp:43] Iteration 27240, lr = 0.02
I0526 08:19:45.984472 15394 main.cpp:354] Iteration 27250, loss = 0.500489
I0526 08:19:45.984515 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.500489 (* 1 = 0.500489 loss)
I0526 08:19:45.984522 15394 sgd_solver.cpp:43] Iteration 27250, lr = 0.02
I0526 08:19:51.298727 15394 main.cpp:354] Iteration 27260, loss = 0.369353
I0526 08:19:51.298765 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.369353 (* 1 = 0.369353 loss)
I0526 08:19:51.298773 15394 sgd_solver.cpp:43] Iteration 27260, lr = 0.02
I0526 08:19:56.495780 15394 main.cpp:354] Iteration 27270, loss = 0.407335
I0526 08:19:56.495806 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.407335 (* 1 = 0.407335 loss)
I0526 08:19:56.495813 15394 sgd_solver.cpp:43] Iteration 27270, lr = 0.02
I0526 08:20:01.620647 15394 main.cpp:354] Iteration 27280, loss = 0.310746
I0526 08:20:01.620689 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.310746 (* 1 = 0.310746 loss)
I0526 08:20:01.620697 15394 sgd_solver.cpp:43] Iteration 27280, lr = 0.02
I0526 08:20:06.836206 15394 main.cpp:354] Iteration 27290, loss = 0.299416
I0526 08:20:06.836253 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.299416 (* 1 = 0.299416 loss)
I0526 08:20:06.836259 15394 sgd_solver.cpp:43] Iteration 27290, lr = 0.02
I0526 08:20:11.515869 15394 main.cpp:465] Iteration 27300, Testing net (#0)
I0526 08:20:24.599906 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8321
I0526 08:20:24.599946 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.517288 (* 1 = 0.517288 loss)
I0526 08:20:25.102764 15394 main.cpp:354] Iteration 27300, loss = 0.36133
I0526 08:20:25.102799 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.361329 (* 1 = 0.361329 loss)
I0526 08:20:25.102807 15394 sgd_solver.cpp:43] Iteration 27300, lr = 0.02
I0526 08:20:30.650233 15394 main.cpp:354] Iteration 27310, loss = 0.313285
I0526 08:20:30.650279 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.313285 (* 1 = 0.313285 loss)
I0526 08:20:30.650286 15394 sgd_solver.cpp:43] Iteration 27310, lr = 0.02
I0526 08:20:36.052337 15394 main.cpp:354] Iteration 27320, loss = 0.375838
I0526 08:20:36.052376 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.375838 (* 1 = 0.375838 loss)
I0526 08:20:36.052382 15394 sgd_solver.cpp:43] Iteration 27320, lr = 0.02
I0526 08:20:40.712102 15394 main.cpp:354] Iteration 27330, loss = 0.605773
I0526 08:20:40.712128 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.605772 (* 1 = 0.605772 loss)
I0526 08:20:40.712136 15394 sgd_solver.cpp:43] Iteration 27330, lr = 0.02
I0526 08:20:45.321956 15394 main.cpp:354] Iteration 27340, loss = 0.435994
I0526 08:20:45.322000 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.435994 (* 1 = 0.435994 loss)
I0526 08:20:45.322005 15394 sgd_solver.cpp:43] Iteration 27340, lr = 0.02
I0526 08:20:50.634934 15394 main.cpp:354] Iteration 27350, loss = 0.520414
I0526 08:20:50.634974 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.520414 (* 1 = 0.520414 loss)
I0526 08:20:50.634979 15394 sgd_solver.cpp:43] Iteration 27350, lr = 0.02
I0526 08:20:55.712633 15394 main.cpp:354] Iteration 27360, loss = 0.485214
I0526 08:20:55.712673 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.485213 (* 1 = 0.485213 loss)
I0526 08:20:55.712680 15394 sgd_solver.cpp:43] Iteration 27360, lr = 0.02
I0526 08:21:00.532238 15394 main.cpp:354] Iteration 27370, loss = 0.44895
I0526 08:21:00.532282 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.448949 (* 1 = 0.448949 loss)
I0526 08:21:00.532289 15394 sgd_solver.cpp:43] Iteration 27370, lr = 0.02
I0526 08:21:04.931221 15394 main.cpp:354] Iteration 27380, loss = 0.460003
I0526 08:21:04.931260 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.460003 (* 1 = 0.460003 loss)
I0526 08:21:04.931267 15394 sgd_solver.cpp:43] Iteration 27380, lr = 0.02
I0526 08:21:10.118957 15394 main.cpp:354] Iteration 27390, loss = 0.326891
I0526 08:21:10.118993 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.326891 (* 1 = 0.326891 loss)
I0526 08:21:10.119000 15394 sgd_solver.cpp:43] Iteration 27390, lr = 0.02
I0526 08:21:14.748159 15394 main.cpp:465] Iteration 27400, Testing net (#0)
I0526 08:21:27.824007 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8244
I0526 08:21:27.824049 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.559924 (* 1 = 0.559924 loss)
I0526 08:21:28.290637 15394 main.cpp:354] Iteration 27400, loss = 0.418578
I0526 08:21:28.290683 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.418578 (* 1 = 0.418578 loss)
I0526 08:21:28.290693 15394 sgd_solver.cpp:43] Iteration 27400, lr = 0.02
I0526 08:21:33.604203 15394 main.cpp:354] Iteration 27410, loss = 0.428512
I0526 08:21:33.604241 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.428511 (* 1 = 0.428511 loss)
I0526 08:21:33.604248 15394 sgd_solver.cpp:43] Iteration 27410, lr = 0.02
I0526 08:21:38.702600 15394 main.cpp:354] Iteration 27420, loss = 0.278037
I0526 08:21:38.702643 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.278036 (* 1 = 0.278036 loss)
I0526 08:21:38.702656 15394 sgd_solver.cpp:43] Iteration 27420, lr = 0.02
I0526 08:21:43.698572 15394 main.cpp:354] Iteration 27430, loss = 0.324525
I0526 08:21:43.698608 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.324525 (* 1 = 0.324525 loss)
I0526 08:21:43.698614 15394 sgd_solver.cpp:43] Iteration 27430, lr = 0.02
I0526 08:21:48.704721 15394 main.cpp:354] Iteration 27440, loss = 0.319313
I0526 08:21:48.704761 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.319313 (* 1 = 0.319313 loss)
I0526 08:21:48.704767 15394 sgd_solver.cpp:43] Iteration 27440, lr = 0.02
I0526 08:21:53.306839 15394 main.cpp:354] Iteration 27450, loss = 0.443021
I0526 08:21:53.306879 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.443021 (* 1 = 0.443021 loss)
I0526 08:21:53.306886 15394 sgd_solver.cpp:43] Iteration 27450, lr = 0.02
I0526 08:21:58.404585 15394 main.cpp:354] Iteration 27460, loss = 0.420125
I0526 08:21:58.404629 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.420124 (* 1 = 0.420124 loss)
I0526 08:21:58.404636 15394 sgd_solver.cpp:43] Iteration 27460, lr = 0.02
I0526 08:22:03.810082 15394 main.cpp:354] Iteration 27470, loss = 0.273083
I0526 08:22:03.810123 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.273083 (* 1 = 0.273083 loss)
I0526 08:22:03.810129 15394 sgd_solver.cpp:43] Iteration 27470, lr = 0.02
I0526 08:22:08.808228 15394 main.cpp:354] Iteration 27480, loss = 0.287343
I0526 08:22:08.808267 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.287343 (* 1 = 0.287343 loss)
I0526 08:22:08.808275 15394 sgd_solver.cpp:43] Iteration 27480, lr = 0.02
I0526 08:22:13.896000 15394 main.cpp:354] Iteration 27490, loss = 0.397754
I0526 08:22:13.896046 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.397754 (* 1 = 0.397754 loss)
I0526 08:22:13.896054 15394 sgd_solver.cpp:43] Iteration 27490, lr = 0.02
I0526 08:22:18.632366 15394 main.cpp:465] Iteration 27500, Testing net (#0)
I0526 08:22:31.718446 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7585
I0526 08:22:31.718488 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.757346 (* 1 = 0.757346 loss)
I0526 08:22:32.220775 15394 main.cpp:354] Iteration 27500, loss = 0.419789
I0526 08:22:32.220806 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.419789 (* 1 = 0.419789 loss)
I0526 08:22:32.220814 15394 sgd_solver.cpp:43] Iteration 27500, lr = 0.02
I0526 08:22:37.095957 15394 main.cpp:354] Iteration 27510, loss = 0.432552
I0526 08:22:37.095995 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.432552 (* 1 = 0.432552 loss)
I0526 08:22:37.096002 15394 sgd_solver.cpp:43] Iteration 27510, lr = 0.02
I0526 08:22:42.127961 15394 main.cpp:354] Iteration 27520, loss = 0.270984
I0526 08:22:42.128001 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.270983 (* 1 = 0.270983 loss)
I0526 08:22:42.128008 15394 sgd_solver.cpp:43] Iteration 27520, lr = 0.02
I0526 08:22:47.132470 15394 main.cpp:354] Iteration 27530, loss = 0.344092
I0526 08:22:47.132503 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.344091 (* 1 = 0.344091 loss)
I0526 08:22:47.132510 15394 sgd_solver.cpp:43] Iteration 27530, lr = 0.02
I0526 08:22:52.007601 15394 main.cpp:354] Iteration 27540, loss = 0.330225
I0526 08:22:52.007642 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.330225 (* 1 = 0.330225 loss)
I0526 08:22:52.007648 15394 sgd_solver.cpp:43] Iteration 27540, lr = 0.02
I0526 08:22:57.238529 15394 main.cpp:354] Iteration 27550, loss = 0.234772
I0526 08:22:57.238570 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.234772 (* 1 = 0.234772 loss)
I0526 08:22:57.238577 15394 sgd_solver.cpp:43] Iteration 27550, lr = 0.02
I0526 08:23:02.559833 15394 main.cpp:354] Iteration 27560, loss = 0.330638
I0526 08:23:02.559875 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.330638 (* 1 = 0.330638 loss)
I0526 08:23:02.559881 15394 sgd_solver.cpp:43] Iteration 27560, lr = 0.02
I0526 08:23:07.480841 15394 main.cpp:354] Iteration 27570, loss = 0.385254
I0526 08:23:07.480880 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.385254 (* 1 = 0.385254 loss)
I0526 08:23:07.480885 15394 sgd_solver.cpp:43] Iteration 27570, lr = 0.02
I0526 08:23:12.231091 15394 main.cpp:354] Iteration 27580, loss = 0.219897
I0526 08:23:12.231123 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.219897 (* 1 = 0.219897 loss)
I0526 08:23:12.231129 15394 sgd_solver.cpp:43] Iteration 27580, lr = 0.02
I0526 08:23:17.270088 15394 main.cpp:354] Iteration 27590, loss = 0.469221
I0526 08:23:17.270129 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.469221 (* 1 = 0.469221 loss)
I0526 08:23:17.270135 15394 sgd_solver.cpp:43] Iteration 27590, lr = 0.02
I0526 08:23:21.884378 15394 main.cpp:465] Iteration 27600, Testing net (#0)
I0526 08:23:34.963511 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7509
I0526 08:23:34.963551 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.79308 (* 1 = 0.79308 loss)
I0526 08:23:35.472453 15394 main.cpp:354] Iteration 27600, loss = 0.397843
I0526 08:23:35.472496 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.397842 (* 1 = 0.397842 loss)
I0526 08:23:35.472504 15394 sgd_solver.cpp:43] Iteration 27600, lr = 0.02
I0526 08:23:40.940181 15394 main.cpp:354] Iteration 27610, loss = 0.61784
I0526 08:23:40.940222 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.61784 (* 1 = 0.61784 loss)
I0526 08:23:40.940227 15394 sgd_solver.cpp:43] Iteration 27610, lr = 0.02
I0526 08:23:45.864552 15394 main.cpp:354] Iteration 27620, loss = 0.348129
I0526 08:23:45.864595 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.348129 (* 1 = 0.348129 loss)
I0526 08:23:45.864603 15394 sgd_solver.cpp:43] Iteration 27620, lr = 0.02
I0526 08:23:51.058387 15394 main.cpp:354] Iteration 27630, loss = 0.418533
I0526 08:23:51.058428 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.418533 (* 1 = 0.418533 loss)
I0526 08:23:51.058434 15394 sgd_solver.cpp:43] Iteration 27630, lr = 0.02
I0526 08:23:56.498148 15394 main.cpp:354] Iteration 27640, loss = 0.341042
I0526 08:23:56.498177 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.341041 (* 1 = 0.341041 loss)
I0526 08:23:56.498183 15394 sgd_solver.cpp:43] Iteration 27640, lr = 0.02
I0526 08:24:01.627756 15394 main.cpp:354] Iteration 27650, loss = 0.379223
I0526 08:24:01.627802 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.379223 (* 1 = 0.379223 loss)
I0526 08:24:01.627810 15394 sgd_solver.cpp:43] Iteration 27650, lr = 0.02
I0526 08:24:06.567867 15394 main.cpp:354] Iteration 27660, loss = 0.279898
I0526 08:24:06.567906 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.279898 (* 1 = 0.279898 loss)
I0526 08:24:06.567914 15394 sgd_solver.cpp:43] Iteration 27660, lr = 0.02
I0526 08:24:11.545579 15394 main.cpp:354] Iteration 27670, loss = 0.294024
I0526 08:24:11.545619 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.294023 (* 1 = 0.294023 loss)
I0526 08:24:11.545625 15394 sgd_solver.cpp:43] Iteration 27670, lr = 0.02
I0526 08:24:17.056377 15394 main.cpp:354] Iteration 27680, loss = 0.294161
I0526 08:24:17.056422 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.294161 (* 1 = 0.294161 loss)
I0526 08:24:17.056428 15394 sgd_solver.cpp:43] Iteration 27680, lr = 0.02
I0526 08:24:22.232353 15394 main.cpp:354] Iteration 27690, loss = 0.291703
I0526 08:24:22.232394 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.291703 (* 1 = 0.291703 loss)
I0526 08:24:22.232400 15394 sgd_solver.cpp:43] Iteration 27690, lr = 0.02
I0526 08:24:26.797905 15394 main.cpp:465] Iteration 27700, Testing net (#0)
I0526 08:24:39.885164 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8314
I0526 08:24:39.885205 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.503258 (* 1 = 0.503258 loss)
I0526 08:24:40.461038 15394 main.cpp:354] Iteration 27700, loss = 0.217408
I0526 08:24:40.461088 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.217407 (* 1 = 0.217407 loss)
I0526 08:24:40.461098 15394 sgd_solver.cpp:43] Iteration 27700, lr = 0.02
I0526 08:24:45.195042 15394 main.cpp:354] Iteration 27710, loss = 0.386949
I0526 08:24:45.195086 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.386949 (* 1 = 0.386949 loss)
I0526 08:24:45.195093 15394 sgd_solver.cpp:43] Iteration 27710, lr = 0.02
I0526 08:24:49.675715 15394 main.cpp:354] Iteration 27720, loss = 0.309339
I0526 08:24:49.675756 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.309339 (* 1 = 0.309339 loss)
I0526 08:24:49.675762 15394 sgd_solver.cpp:43] Iteration 27720, lr = 0.02
I0526 08:24:55.189831 15394 main.cpp:354] Iteration 27730, loss = 0.314733
I0526 08:24:55.189882 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.314733 (* 1 = 0.314733 loss)
I0526 08:24:55.189888 15394 sgd_solver.cpp:43] Iteration 27730, lr = 0.02
I0526 08:25:00.516839 15394 main.cpp:354] Iteration 27740, loss = 0.422654
I0526 08:25:00.516880 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.422654 (* 1 = 0.422654 loss)
I0526 08:25:00.516885 15394 sgd_solver.cpp:43] Iteration 27740, lr = 0.02
I0526 08:25:05.951776 15394 main.cpp:354] Iteration 27750, loss = 0.325606
I0526 08:25:05.951812 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.325606 (* 1 = 0.325606 loss)
I0526 08:25:05.951820 15394 sgd_solver.cpp:43] Iteration 27750, lr = 0.02
I0526 08:25:11.077772 15394 main.cpp:354] Iteration 27760, loss = 0.335739
I0526 08:25:11.077816 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.335738 (* 1 = 0.335738 loss)
I0526 08:25:11.077822 15394 sgd_solver.cpp:43] Iteration 27760, lr = 0.02
I0526 08:25:15.830153 15394 main.cpp:354] Iteration 27770, loss = 0.325636
I0526 08:25:15.830195 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.325636 (* 1 = 0.325636 loss)
I0526 08:25:15.830201 15394 sgd_solver.cpp:43] Iteration 27770, lr = 0.02
I0526 08:25:21.134594 15394 main.cpp:354] Iteration 27780, loss = 0.276594
I0526 08:25:21.134634 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.276593 (* 1 = 0.276593 loss)
I0526 08:25:21.134640 15394 sgd_solver.cpp:43] Iteration 27780, lr = 0.02
I0526 08:25:26.118566 15394 main.cpp:354] Iteration 27790, loss = 0.417749
I0526 08:25:26.118605 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.417749 (* 1 = 0.417749 loss)
I0526 08:25:26.118613 15394 sgd_solver.cpp:43] Iteration 27790, lr = 0.02
I0526 08:25:30.998503 15394 main.cpp:465] Iteration 27800, Testing net (#0)
I0526 08:25:44.078642 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8264
I0526 08:25:44.078685 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.536636 (* 1 = 0.536636 loss)
I0526 08:25:44.477988 15394 main.cpp:354] Iteration 27800, loss = 0.304148
I0526 08:25:44.478009 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.304148 (* 1 = 0.304148 loss)
I0526 08:25:44.478018 15394 sgd_solver.cpp:43] Iteration 27800, lr = 0.02
I0526 08:25:49.354375 15394 main.cpp:354] Iteration 27810, loss = 0.310163
I0526 08:25:49.354429 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.310163 (* 1 = 0.310163 loss)
I0526 08:25:49.354437 15394 sgd_solver.cpp:43] Iteration 27810, lr = 0.02
I0526 08:25:54.308229 15394 main.cpp:354] Iteration 27820, loss = 0.283159
I0526 08:25:54.308269 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.283159 (* 1 = 0.283159 loss)
I0526 08:25:54.308274 15394 sgd_solver.cpp:43] Iteration 27820, lr = 0.02
I0526 08:25:59.120936 15394 main.cpp:354] Iteration 27830, loss = 0.301499
I0526 08:25:59.120981 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.301499 (* 1 = 0.301499 loss)
I0526 08:25:59.120988 15394 sgd_solver.cpp:43] Iteration 27830, lr = 0.02
I0526 08:26:04.232687 15394 main.cpp:354] Iteration 27840, loss = 0.255132
I0526 08:26:04.232728 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.255132 (* 1 = 0.255132 loss)
I0526 08:26:04.232739 15394 sgd_solver.cpp:43] Iteration 27840, lr = 0.02
I0526 08:26:09.307205 15394 main.cpp:354] Iteration 27850, loss = 0.446916
I0526 08:26:09.307246 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.446915 (* 1 = 0.446915 loss)
I0526 08:26:09.307253 15394 sgd_solver.cpp:43] Iteration 27850, lr = 0.02
I0526 08:26:14.330862 15394 main.cpp:354] Iteration 27860, loss = 0.361629
I0526 08:26:14.330904 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.361629 (* 1 = 0.361629 loss)
I0526 08:26:14.330909 15394 sgd_solver.cpp:43] Iteration 27860, lr = 0.02
I0526 08:26:19.533536 15394 main.cpp:354] Iteration 27870, loss = 0.448196
I0526 08:26:19.533576 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.448195 (* 1 = 0.448195 loss)
I0526 08:26:19.533581 15394 sgd_solver.cpp:43] Iteration 27870, lr = 0.02
I0526 08:26:24.251714 15394 main.cpp:354] Iteration 27880, loss = 0.300996
I0526 08:26:24.251766 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.300996 (* 1 = 0.300996 loss)
I0526 08:26:24.251772 15394 sgd_solver.cpp:43] Iteration 27880, lr = 0.02
I0526 08:26:28.831776 15394 main.cpp:354] Iteration 27890, loss = 0.386199
I0526 08:26:28.831818 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.386199 (* 1 = 0.386199 loss)
I0526 08:26:28.831827 15394 sgd_solver.cpp:43] Iteration 27890, lr = 0.02
I0526 08:26:33.369869 15394 main.cpp:465] Iteration 27900, Testing net (#0)
I0526 08:26:46.447994 15394 main.cpp:532]     Test net output #0: Accuracy = 0.795
I0526 08:26:46.448030 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.671759 (* 1 = 0.671759 loss)
I0526 08:26:47.023594 15394 main.cpp:354] Iteration 27900, loss = 0.365111
I0526 08:26:47.023633 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.36511 (* 1 = 0.36511 loss)
I0526 08:26:47.023639 15394 sgd_solver.cpp:43] Iteration 27900, lr = 0.02
I0526 08:26:52.165321 15394 main.cpp:354] Iteration 27910, loss = 0.310456
I0526 08:26:52.165362 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.310456 (* 1 = 0.310456 loss)
I0526 08:26:52.165369 15394 sgd_solver.cpp:43] Iteration 27910, lr = 0.02
I0526 08:26:57.130573 15394 main.cpp:354] Iteration 27920, loss = 0.563149
I0526 08:26:57.130617 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.563149 (* 1 = 0.563149 loss)
I0526 08:26:57.130625 15394 sgd_solver.cpp:43] Iteration 27920, lr = 0.02
I0526 08:27:01.992700 15394 main.cpp:354] Iteration 27930, loss = 0.381329
I0526 08:27:01.992743 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.381329 (* 1 = 0.381329 loss)
I0526 08:27:01.992749 15394 sgd_solver.cpp:43] Iteration 27930, lr = 0.02
I0526 08:27:07.291065 15394 main.cpp:354] Iteration 27940, loss = 0.192335
I0526 08:27:07.291105 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.192334 (* 1 = 0.192334 loss)
I0526 08:27:07.291110 15394 sgd_solver.cpp:43] Iteration 27940, lr = 0.02
I0526 08:27:12.417058 15394 main.cpp:354] Iteration 27950, loss = 0.340995
I0526 08:27:12.417099 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.340995 (* 1 = 0.340995 loss)
I0526 08:27:12.417106 15394 sgd_solver.cpp:43] Iteration 27950, lr = 0.02
I0526 08:27:17.223445 15394 main.cpp:354] Iteration 27960, loss = 0.208587
I0526 08:27:17.223489 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.208587 (* 1 = 0.208587 loss)
I0526 08:27:17.223495 15394 sgd_solver.cpp:43] Iteration 27960, lr = 0.02
I0526 08:27:22.518100 15394 main.cpp:354] Iteration 27970, loss = 0.224184
I0526 08:27:22.518141 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.224184 (* 1 = 0.224184 loss)
I0526 08:27:22.518148 15394 sgd_solver.cpp:43] Iteration 27970, lr = 0.02
I0526 08:27:27.887174 15394 main.cpp:354] Iteration 27980, loss = 0.44798
I0526 08:27:27.887217 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.44798 (* 1 = 0.44798 loss)
I0526 08:27:27.887223 15394 sgd_solver.cpp:43] Iteration 27980, lr = 0.02
I0526 08:27:33.105753 15394 main.cpp:354] Iteration 27990, loss = 0.344002
I0526 08:27:33.105795 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.344002 (* 1 = 0.344002 loss)
I0526 08:27:33.105803 15394 sgd_solver.cpp:43] Iteration 27990, lr = 0.02
I0526 08:27:37.308749 15394 main.cpp:465] Iteration 28000, Testing net (#0)
I0526 08:27:50.387920 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8512
I0526 08:27:50.387961 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.439377 (* 1 = 0.439377 loss)
I0526 08:27:50.784373 15394 main.cpp:354] Iteration 28000, loss = 0.448847
I0526 08:27:50.784413 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.448847 (* 1 = 0.448847 loss)
I0526 08:27:50.784421 15394 sgd_solver.cpp:43] Iteration 28000, lr = 0.02
I0526 08:27:55.866447 15394 main.cpp:354] Iteration 28010, loss = 0.35493
I0526 08:27:55.866475 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.35493 (* 1 = 0.35493 loss)
I0526 08:27:55.866482 15394 sgd_solver.cpp:43] Iteration 28010, lr = 0.02
I0526 08:28:01.058106 15394 main.cpp:354] Iteration 28020, loss = 0.258125
I0526 08:28:01.058148 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.258125 (* 1 = 0.258125 loss)
I0526 08:28:01.058154 15394 sgd_solver.cpp:43] Iteration 28020, lr = 0.02
I0526 08:28:06.426893 15394 main.cpp:354] Iteration 28030, loss = 0.38224
I0526 08:28:06.426934 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.382239 (* 1 = 0.382239 loss)
I0526 08:28:06.426940 15394 sgd_solver.cpp:43] Iteration 28030, lr = 0.02
I0526 08:28:11.428900 15394 main.cpp:354] Iteration 28040, loss = 0.469999
I0526 08:28:11.428937 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.469999 (* 1 = 0.469999 loss)
I0526 08:28:11.428943 15394 sgd_solver.cpp:43] Iteration 28040, lr = 0.02
I0526 08:28:16.310416 15394 main.cpp:354] Iteration 28050, loss = 0.327687
I0526 08:28:16.310459 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.327686 (* 1 = 0.327686 loss)
I0526 08:28:16.310467 15394 sgd_solver.cpp:43] Iteration 28050, lr = 0.02
I0526 08:28:21.542017 15394 main.cpp:354] Iteration 28060, loss = 0.479422
I0526 08:28:21.542057 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.479422 (* 1 = 0.479422 loss)
I0526 08:28:21.542064 15394 sgd_solver.cpp:43] Iteration 28060, lr = 0.02
I0526 08:28:26.772670 15394 main.cpp:354] Iteration 28070, loss = 0.457803
I0526 08:28:26.772706 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.457803 (* 1 = 0.457803 loss)
I0526 08:28:26.772712 15394 sgd_solver.cpp:43] Iteration 28070, lr = 0.02
I0526 08:28:31.875586 15394 main.cpp:354] Iteration 28080, loss = 0.362045
I0526 08:28:31.875629 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.362045 (* 1 = 0.362045 loss)
I0526 08:28:31.875638 15394 sgd_solver.cpp:43] Iteration 28080, lr = 0.02
I0526 08:28:36.970576 15394 main.cpp:354] Iteration 28090, loss = 0.206476
I0526 08:28:36.970618 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206475 (* 1 = 0.206475 loss)
I0526 08:28:36.970624 15394 sgd_solver.cpp:43] Iteration 28090, lr = 0.02
I0526 08:28:41.485124 15394 main.cpp:465] Iteration 28100, Testing net (#0)
I0526 08:28:54.564030 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8268
I0526 08:28:54.564069 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.555133 (* 1 = 0.555133 loss)
I0526 08:28:54.994300 15394 main.cpp:354] Iteration 28100, loss = 0.308321
I0526 08:28:54.994333 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.308321 (* 1 = 0.308321 loss)
I0526 08:28:54.994341 15394 sgd_solver.cpp:43] Iteration 28100, lr = 0.02
I0526 08:29:00.359664 15394 main.cpp:354] Iteration 28110, loss = 0.240018
I0526 08:29:00.359707 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.240017 (* 1 = 0.240017 loss)
I0526 08:29:00.359714 15394 sgd_solver.cpp:43] Iteration 28110, lr = 0.02
I0526 08:29:05.729086 15394 main.cpp:354] Iteration 28120, loss = 0.422075
I0526 08:29:05.729128 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.422075 (* 1 = 0.422075 loss)
I0526 08:29:05.729135 15394 sgd_solver.cpp:43] Iteration 28120, lr = 0.02
I0526 08:29:10.750071 15394 main.cpp:354] Iteration 28130, loss = 0.429896
I0526 08:29:10.750107 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.429896 (* 1 = 0.429896 loss)
I0526 08:29:10.750113 15394 sgd_solver.cpp:43] Iteration 28130, lr = 0.02
I0526 08:29:15.555105 15394 main.cpp:354] Iteration 28140, loss = 0.367416
I0526 08:29:15.555147 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.367416 (* 1 = 0.367416 loss)
I0526 08:29:15.555153 15394 sgd_solver.cpp:43] Iteration 28140, lr = 0.02
I0526 08:29:21.016439 15394 main.cpp:354] Iteration 28150, loss = 0.167996
I0526 08:29:21.016479 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.167996 (* 1 = 0.167996 loss)
I0526 08:29:21.016485 15394 sgd_solver.cpp:43] Iteration 28150, lr = 0.02
I0526 08:29:26.351953 15394 main.cpp:354] Iteration 28160, loss = 0.344823
I0526 08:29:26.351991 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.344823 (* 1 = 0.344823 loss)
I0526 08:29:26.351999 15394 sgd_solver.cpp:43] Iteration 28160, lr = 0.02
I0526 08:29:31.447798 15394 main.cpp:354] Iteration 28170, loss = 0.327592
I0526 08:29:31.447842 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.327592 (* 1 = 0.327592 loss)
I0526 08:29:31.447849 15394 sgd_solver.cpp:43] Iteration 28170, lr = 0.02
I0526 08:29:36.937669 15394 main.cpp:354] Iteration 28180, loss = 0.477458
I0526 08:29:36.937701 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.477458 (* 1 = 0.477458 loss)
I0526 08:29:36.937707 15394 sgd_solver.cpp:43] Iteration 28180, lr = 0.02
I0526 08:29:41.816474 15394 main.cpp:354] Iteration 28190, loss = 0.726056
I0526 08:29:41.816514 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.726056 (* 1 = 0.726056 loss)
I0526 08:29:41.816520 15394 sgd_solver.cpp:43] Iteration 28190, lr = 0.02
I0526 08:29:46.074800 15394 main.cpp:465] Iteration 28200, Testing net (#0)
I0526 08:29:59.149523 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8218
I0526 08:29:59.149564 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.54009 (* 1 = 0.54009 loss)
I0526 08:29:59.586737 15394 main.cpp:354] Iteration 28200, loss = 0.312899
I0526 08:29:59.586776 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.312899 (* 1 = 0.312899 loss)
I0526 08:29:59.586784 15394 sgd_solver.cpp:43] Iteration 28200, lr = 0.02
I0526 08:30:04.823468 15394 main.cpp:354] Iteration 28210, loss = 0.636163
I0526 08:30:04.823506 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.636163 (* 1 = 0.636163 loss)
I0526 08:30:04.823513 15394 sgd_solver.cpp:43] Iteration 28210, lr = 0.02
I0526 08:30:09.805325 15394 main.cpp:354] Iteration 28220, loss = 0.395721
I0526 08:30:09.805363 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.395721 (* 1 = 0.395721 loss)
I0526 08:30:09.805369 15394 sgd_solver.cpp:43] Iteration 28220, lr = 0.02
I0526 08:30:15.173919 15394 main.cpp:354] Iteration 28230, loss = 0.2684
I0526 08:30:15.173961 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.2684 (* 1 = 0.2684 loss)
I0526 08:30:15.173967 15394 sgd_solver.cpp:43] Iteration 28230, lr = 0.02
I0526 08:30:20.597542 15394 main.cpp:354] Iteration 28240, loss = 0.249955
I0526 08:30:20.597580 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.249955 (* 1 = 0.249955 loss)
I0526 08:30:20.597587 15394 sgd_solver.cpp:43] Iteration 28240, lr = 0.02
I0526 08:30:25.554301 15394 main.cpp:354] Iteration 28250, loss = 0.526514
I0526 08:30:25.554340 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.526514 (* 1 = 0.526514 loss)
I0526 08:30:25.554347 15394 sgd_solver.cpp:43] Iteration 28250, lr = 0.02
I0526 08:30:30.314040 15394 main.cpp:354] Iteration 28260, loss = 0.461614
I0526 08:30:30.314086 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.461614 (* 1 = 0.461614 loss)
I0526 08:30:30.314100 15394 sgd_solver.cpp:43] Iteration 28260, lr = 0.02
I0526 08:30:35.200342 15394 main.cpp:354] Iteration 28270, loss = 0.445558
I0526 08:30:35.200383 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.445558 (* 1 = 0.445558 loss)
I0526 08:30:35.200389 15394 sgd_solver.cpp:43] Iteration 28270, lr = 0.02
I0526 08:30:39.877269 15394 main.cpp:354] Iteration 28280, loss = 0.514131
I0526 08:30:39.877296 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.514131 (* 1 = 0.514131 loss)
I0526 08:30:39.877302 15394 sgd_solver.cpp:43] Iteration 28280, lr = 0.02
I0526 08:30:44.864096 15394 main.cpp:354] Iteration 28290, loss = 0.277044
I0526 08:30:44.864140 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.277044 (* 1 = 0.277044 loss)
I0526 08:30:44.864145 15394 sgd_solver.cpp:43] Iteration 28290, lr = 0.02
I0526 08:30:49.406041 15394 main.cpp:465] Iteration 28300, Testing net (#0)
I0526 08:31:02.493506 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8445
I0526 08:31:02.493546 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.493858 (* 1 = 0.493858 loss)
I0526 08:31:02.966012 15394 main.cpp:354] Iteration 28300, loss = 0.448302
I0526 08:31:02.966053 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.448302 (* 1 = 0.448302 loss)
I0526 08:31:02.966061 15394 sgd_solver.cpp:43] Iteration 28300, lr = 0.02
I0526 08:31:07.930873 15394 main.cpp:354] Iteration 28310, loss = 0.410348
I0526 08:31:07.930917 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.410348 (* 1 = 0.410348 loss)
I0526 08:31:07.930924 15394 sgd_solver.cpp:43] Iteration 28310, lr = 0.02
I0526 08:31:13.138921 15394 main.cpp:354] Iteration 28320, loss = 0.118475
I0526 08:31:13.138962 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.118475 (* 1 = 0.118475 loss)
I0526 08:31:13.138969 15394 sgd_solver.cpp:43] Iteration 28320, lr = 0.02
I0526 08:31:18.233402 15394 main.cpp:354] Iteration 28330, loss = 0.218143
I0526 08:31:18.233439 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.218142 (* 1 = 0.218142 loss)
I0526 08:31:18.233445 15394 sgd_solver.cpp:43] Iteration 28330, lr = 0.02
I0526 08:31:23.112712 15394 main.cpp:354] Iteration 28340, loss = 0.271325
I0526 08:31:23.112751 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.271324 (* 1 = 0.271324 loss)
I0526 08:31:23.112757 15394 sgd_solver.cpp:43] Iteration 28340, lr = 0.02
I0526 08:31:28.288264 15394 main.cpp:354] Iteration 28350, loss = 0.415913
I0526 08:31:28.288306 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.415913 (* 1 = 0.415913 loss)
I0526 08:31:28.288312 15394 sgd_solver.cpp:43] Iteration 28350, lr = 0.02
I0526 08:31:33.562527 15394 main.cpp:354] Iteration 28360, loss = 0.339532
I0526 08:31:33.562568 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.339532 (* 1 = 0.339532 loss)
I0526 08:31:33.562575 15394 sgd_solver.cpp:43] Iteration 28360, lr = 0.02
I0526 08:31:38.377456 15394 main.cpp:354] Iteration 28370, loss = 0.37787
I0526 08:31:38.377496 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.37787 (* 1 = 0.37787 loss)
I0526 08:31:38.377502 15394 sgd_solver.cpp:43] Iteration 28370, lr = 0.02
I0526 08:31:43.257690 15394 main.cpp:354] Iteration 28380, loss = 0.321179
I0526 08:31:43.257731 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.321179 (* 1 = 0.321179 loss)
I0526 08:31:43.257738 15394 sgd_solver.cpp:43] Iteration 28380, lr = 0.02
I0526 08:31:48.139405 15394 main.cpp:354] Iteration 28390, loss = 0.407983
I0526 08:31:48.139444 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.407982 (* 1 = 0.407982 loss)
I0526 08:31:48.139451 15394 sgd_solver.cpp:43] Iteration 28390, lr = 0.02
I0526 08:31:52.923156 15394 main.cpp:465] Iteration 28400, Testing net (#0)
I0526 08:32:06.011883 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8503
I0526 08:32:06.011924 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.446191 (* 1 = 0.446191 loss)
I0526 08:32:06.410071 15394 main.cpp:354] Iteration 28400, loss = 0.526904
I0526 08:32:06.410112 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.526904 (* 1 = 0.526904 loss)
I0526 08:32:06.410120 15394 sgd_solver.cpp:43] Iteration 28400, lr = 0.02
I0526 08:32:11.513717 15394 main.cpp:354] Iteration 28410, loss = 0.335843
I0526 08:32:11.513757 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.335842 (* 1 = 0.335842 loss)
I0526 08:32:11.513764 15394 sgd_solver.cpp:43] Iteration 28410, lr = 0.02
I0526 08:32:16.392403 15394 main.cpp:354] Iteration 28420, loss = 0.338668
I0526 08:32:16.392447 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.338667 (* 1 = 0.338667 loss)
I0526 08:32:16.392454 15394 sgd_solver.cpp:43] Iteration 28420, lr = 0.02
I0526 08:32:21.415377 15394 main.cpp:354] Iteration 28430, loss = 0.374135
I0526 08:32:21.415416 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.374135 (* 1 = 0.374135 loss)
I0526 08:32:21.415423 15394 sgd_solver.cpp:43] Iteration 28430, lr = 0.02
I0526 08:32:26.218273 15394 main.cpp:354] Iteration 28440, loss = 0.528819
I0526 08:32:26.218313 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.528819 (* 1 = 0.528819 loss)
I0526 08:32:26.218320 15394 sgd_solver.cpp:43] Iteration 28440, lr = 0.02
I0526 08:32:31.445611 15394 main.cpp:354] Iteration 28450, loss = 0.359553
I0526 08:32:31.445655 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.359552 (* 1 = 0.359552 loss)
I0526 08:32:31.445662 15394 sgd_solver.cpp:43] Iteration 28450, lr = 0.02
I0526 08:32:36.465533 15394 main.cpp:354] Iteration 28460, loss = 0.340088
I0526 08:32:36.465574 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.340088 (* 1 = 0.340088 loss)
I0526 08:32:36.465580 15394 sgd_solver.cpp:43] Iteration 28460, lr = 0.02
I0526 08:32:41.553093 15394 main.cpp:354] Iteration 28470, loss = 0.377515
I0526 08:32:41.553133 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.377515 (* 1 = 0.377515 loss)
I0526 08:32:41.553140 15394 sgd_solver.cpp:43] Iteration 28470, lr = 0.02
I0526 08:32:46.827858 15394 main.cpp:354] Iteration 28480, loss = 0.34177
I0526 08:32:46.827899 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.34177 (* 1 = 0.34177 loss)
I0526 08:32:46.827906 15394 sgd_solver.cpp:43] Iteration 28480, lr = 0.02
I0526 08:32:52.240118 15394 main.cpp:354] Iteration 28490, loss = 0.17818
I0526 08:32:52.240145 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.17818 (* 1 = 0.17818 loss)
I0526 08:32:52.240152 15394 sgd_solver.cpp:43] Iteration 28490, lr = 0.02
I0526 08:32:56.805281 15394 main.cpp:465] Iteration 28500, Testing net (#0)
I0526 08:33:09.883976 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8347
I0526 08:33:09.884016 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.498911 (* 1 = 0.498911 loss)
I0526 08:33:10.313948 15394 main.cpp:354] Iteration 28500, loss = 0.419705
I0526 08:33:10.313987 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.419705 (* 1 = 0.419705 loss)
I0526 08:33:10.313994 15394 sgd_solver.cpp:43] Iteration 28500, lr = 0.02
I0526 08:33:14.952412 15394 main.cpp:354] Iteration 28510, loss = 0.382645
I0526 08:33:14.952456 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.382645 (* 1 = 0.382645 loss)
I0526 08:33:14.952462 15394 sgd_solver.cpp:43] Iteration 28510, lr = 0.02
I0526 08:33:20.276249 15394 main.cpp:354] Iteration 28520, loss = 0.32708
I0526 08:33:20.276288 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.327079 (* 1 = 0.327079 loss)
I0526 08:33:20.276294 15394 sgd_solver.cpp:43] Iteration 28520, lr = 0.02
I0526 08:33:25.381721 15394 main.cpp:354] Iteration 28530, loss = 0.271173
I0526 08:33:25.381762 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.271173 (* 1 = 0.271173 loss)
I0526 08:33:25.381769 15394 sgd_solver.cpp:43] Iteration 28530, lr = 0.02
I0526 08:33:30.303530 15394 main.cpp:354] Iteration 28540, loss = 0.263794
I0526 08:33:30.303573 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.263793 (* 1 = 0.263793 loss)
I0526 08:33:30.303586 15394 sgd_solver.cpp:43] Iteration 28540, lr = 0.02
I0526 08:33:35.253582 15394 main.cpp:354] Iteration 28550, loss = 0.36097
I0526 08:33:35.253623 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.36097 (* 1 = 0.36097 loss)
I0526 08:33:35.253630 15394 sgd_solver.cpp:43] Iteration 28550, lr = 0.02
I0526 08:33:40.519644 15394 main.cpp:354] Iteration 28560, loss = 0.222966
I0526 08:33:40.519685 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.222966 (* 1 = 0.222966 loss)
I0526 08:33:40.519691 15394 sgd_solver.cpp:43] Iteration 28560, lr = 0.02
I0526 08:33:46.161970 15394 main.cpp:354] Iteration 28570, loss = 0.285163
I0526 08:33:46.162012 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.285163 (* 1 = 0.285163 loss)
I0526 08:33:46.162019 15394 sgd_solver.cpp:43] Iteration 28570, lr = 0.02
I0526 08:33:51.264693 15394 main.cpp:354] Iteration 28580, loss = 0.338292
I0526 08:33:51.264734 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.338292 (* 1 = 0.338292 loss)
I0526 08:33:51.264740 15394 sgd_solver.cpp:43] Iteration 28580, lr = 0.02
I0526 08:33:56.206061 15394 main.cpp:354] Iteration 28590, loss = 0.21464
I0526 08:33:56.206106 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.214639 (* 1 = 0.214639 loss)
I0526 08:33:56.206112 15394 sgd_solver.cpp:43] Iteration 28590, lr = 0.02
I0526 08:34:00.220448 15394 main.cpp:465] Iteration 28600, Testing net (#0)
I0526 08:34:13.299582 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8404
I0526 08:34:13.299619 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.484246 (* 1 = 0.484246 loss)
I0526 08:34:13.631695 15394 main.cpp:354] Iteration 28600, loss = 0.502382
I0526 08:34:13.631736 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.502382 (* 1 = 0.502382 loss)
I0526 08:34:13.631743 15394 sgd_solver.cpp:43] Iteration 28600, lr = 0.02
I0526 08:34:18.551112 15394 main.cpp:354] Iteration 28610, loss = 0.294644
I0526 08:34:18.551151 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.294643 (* 1 = 0.294643 loss)
I0526 08:34:18.551156 15394 sgd_solver.cpp:43] Iteration 28610, lr = 0.02
I0526 08:34:23.563510 15394 main.cpp:354] Iteration 28620, loss = 0.257771
I0526 08:34:23.563549 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.25777 (* 1 = 0.25777 loss)
I0526 08:34:23.563555 15394 sgd_solver.cpp:43] Iteration 28620, lr = 0.02
I0526 08:34:28.433948 15394 main.cpp:354] Iteration 28630, loss = 0.16219
I0526 08:34:28.433990 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.16219 (* 1 = 0.16219 loss)
I0526 08:34:28.433997 15394 sgd_solver.cpp:43] Iteration 28630, lr = 0.02
I0526 08:34:33.466922 15394 main.cpp:354] Iteration 28640, loss = 0.304584
I0526 08:34:33.466958 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.304583 (* 1 = 0.304583 loss)
I0526 08:34:33.466964 15394 sgd_solver.cpp:43] Iteration 28640, lr = 0.02
I0526 08:34:38.564728 15394 main.cpp:354] Iteration 28650, loss = 0.370166
I0526 08:34:38.564766 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.370166 (* 1 = 0.370166 loss)
I0526 08:34:38.564772 15394 sgd_solver.cpp:43] Iteration 28650, lr = 0.02
I0526 08:34:43.853783 15394 main.cpp:354] Iteration 28660, loss = 0.299413
I0526 08:34:43.853826 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.299413 (* 1 = 0.299413 loss)
I0526 08:34:43.853832 15394 sgd_solver.cpp:43] Iteration 28660, lr = 0.02
I0526 08:34:48.745404 15394 main.cpp:354] Iteration 28670, loss = 0.273166
I0526 08:34:48.745445 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.273166 (* 1 = 0.273166 loss)
I0526 08:34:48.745452 15394 sgd_solver.cpp:43] Iteration 28670, lr = 0.02
I0526 08:34:53.240473 15394 main.cpp:354] Iteration 28680, loss = 0.497125
I0526 08:34:53.240512 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.497124 (* 1 = 0.497124 loss)
I0526 08:34:53.240525 15394 sgd_solver.cpp:43] Iteration 28680, lr = 0.02
I0526 08:34:58.797514 15394 main.cpp:354] Iteration 28690, loss = 0.296383
I0526 08:34:58.797554 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.296383 (* 1 = 0.296383 loss)
I0526 08:34:58.797560 15394 sgd_solver.cpp:43] Iteration 28690, lr = 0.02
I0526 08:35:03.721245 15394 main.cpp:465] Iteration 28700, Testing net (#0)
I0526 08:35:16.799070 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8463
I0526 08:35:16.799111 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.482933 (* 1 = 0.482933 loss)
I0526 08:35:17.264575 15394 main.cpp:354] Iteration 28700, loss = 0.312065
I0526 08:35:17.264603 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.312065 (* 1 = 0.312065 loss)
I0526 08:35:17.264611 15394 sgd_solver.cpp:43] Iteration 28700, lr = 0.02
I0526 08:35:22.081460 15394 main.cpp:354] Iteration 28710, loss = 0.381793
I0526 08:35:22.081501 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.381792 (* 1 = 0.381792 loss)
I0526 08:35:22.081506 15394 sgd_solver.cpp:43] Iteration 28710, lr = 0.02
I0526 08:35:27.078609 15394 main.cpp:354] Iteration 28720, loss = 0.301168
I0526 08:35:27.078650 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.301168 (* 1 = 0.301168 loss)
I0526 08:35:27.078658 15394 sgd_solver.cpp:43] Iteration 28720, lr = 0.02
I0526 08:35:32.054915 15394 main.cpp:354] Iteration 28730, loss = 0.240086
I0526 08:35:32.054958 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.240085 (* 1 = 0.240085 loss)
I0526 08:35:32.054965 15394 sgd_solver.cpp:43] Iteration 28730, lr = 0.02
I0526 08:35:37.134265 15394 main.cpp:354] Iteration 28740, loss = 0.428807
I0526 08:35:37.134305 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.428806 (* 1 = 0.428806 loss)
I0526 08:35:37.134311 15394 sgd_solver.cpp:43] Iteration 28740, lr = 0.02
I0526 08:35:42.355896 15394 main.cpp:354] Iteration 28750, loss = 0.40952
I0526 08:35:42.355922 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.40952 (* 1 = 0.40952 loss)
I0526 08:35:42.355928 15394 sgd_solver.cpp:43] Iteration 28750, lr = 0.02
I0526 08:35:46.729995 15394 main.cpp:354] Iteration 28760, loss = 0.38511
I0526 08:35:46.730041 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.38511 (* 1 = 0.38511 loss)
I0526 08:35:46.730046 15394 sgd_solver.cpp:43] Iteration 28760, lr = 0.02
I0526 08:35:51.728006 15394 main.cpp:354] Iteration 28770, loss = 0.47544
I0526 08:35:51.728047 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.47544 (* 1 = 0.47544 loss)
I0526 08:35:51.728055 15394 sgd_solver.cpp:43] Iteration 28770, lr = 0.02
I0526 08:35:56.829664 15394 main.cpp:354] Iteration 28780, loss = 0.709926
I0526 08:35:56.829704 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.709926 (* 1 = 0.709926 loss)
I0526 08:35:56.829711 15394 sgd_solver.cpp:43] Iteration 28780, lr = 0.02
I0526 08:36:01.466920 15394 main.cpp:354] Iteration 28790, loss = 0.2948
I0526 08:36:01.466964 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.2948 (* 1 = 0.2948 loss)
I0526 08:36:01.466970 15394 sgd_solver.cpp:43] Iteration 28790, lr = 0.02
I0526 08:36:05.973773 15394 main.cpp:465] Iteration 28800, Testing net (#0)
I0526 08:36:19.055004 15394 main.cpp:532]     Test net output #0: Accuracy = 0.838
I0526 08:36:19.055045 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.482639 (* 1 = 0.482639 loss)
I0526 08:36:19.559350 15394 main.cpp:354] Iteration 28800, loss = 0.395246
I0526 08:36:19.559389 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.395245 (* 1 = 0.395245 loss)
I0526 08:36:19.559398 15394 sgd_solver.cpp:43] Iteration 28800, lr = 0.02
I0526 08:36:24.378455 15394 main.cpp:354] Iteration 28810, loss = 0.310699
I0526 08:36:24.378496 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.310699 (* 1 = 0.310699 loss)
I0526 08:36:24.378504 15394 sgd_solver.cpp:43] Iteration 28810, lr = 0.02
I0526 08:36:29.552801 15394 main.cpp:354] Iteration 28820, loss = 0.222186
I0526 08:36:29.552850 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.222186 (* 1 = 0.222186 loss)
I0526 08:36:29.552857 15394 sgd_solver.cpp:43] Iteration 28820, lr = 0.02
I0526 08:36:34.526684 15394 main.cpp:354] Iteration 28830, loss = 0.22854
I0526 08:36:34.526722 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.22854 (* 1 = 0.22854 loss)
I0526 08:36:34.526728 15394 sgd_solver.cpp:43] Iteration 28830, lr = 0.02
I0526 08:36:39.613304 15394 main.cpp:354] Iteration 28840, loss = 0.262813
I0526 08:36:39.613343 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.262813 (* 1 = 0.262813 loss)
I0526 08:36:39.613350 15394 sgd_solver.cpp:43] Iteration 28840, lr = 0.02
I0526 08:36:44.778553 15394 main.cpp:354] Iteration 28850, loss = 0.439656
I0526 08:36:44.778596 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.439656 (* 1 = 0.439656 loss)
I0526 08:36:44.778602 15394 sgd_solver.cpp:43] Iteration 28850, lr = 0.02
I0526 08:36:49.181602 15394 main.cpp:354] Iteration 28860, loss = 0.465481
I0526 08:36:49.181639 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.465481 (* 1 = 0.465481 loss)
I0526 08:36:49.181645 15394 sgd_solver.cpp:43] Iteration 28860, lr = 0.02
I0526 08:36:53.638525 15394 main.cpp:354] Iteration 28870, loss = 0.406428
I0526 08:36:53.638564 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.406428 (* 1 = 0.406428 loss)
I0526 08:36:53.638571 15394 sgd_solver.cpp:43] Iteration 28870, lr = 0.02
I0526 08:36:58.641499 15394 main.cpp:354] Iteration 28880, loss = 0.392814
I0526 08:36:58.641541 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.392814 (* 1 = 0.392814 loss)
I0526 08:36:58.641548 15394 sgd_solver.cpp:43] Iteration 28880, lr = 0.02
I0526 08:37:03.556612 15394 main.cpp:354] Iteration 28890, loss = 0.338762
I0526 08:37:03.556649 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.338762 (* 1 = 0.338762 loss)
I0526 08:37:03.556656 15394 sgd_solver.cpp:43] Iteration 28890, lr = 0.02
I0526 08:37:08.285331 15394 main.cpp:465] Iteration 28900, Testing net (#0)
I0526 08:37:21.360770 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8362
I0526 08:37:21.360810 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.488875 (* 1 = 0.488875 loss)
I0526 08:37:21.759218 15394 main.cpp:354] Iteration 28900, loss = 0.380857
I0526 08:37:21.759258 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.380856 (* 1 = 0.380856 loss)
I0526 08:37:21.759265 15394 sgd_solver.cpp:43] Iteration 28900, lr = 0.02
I0526 08:37:26.282595 15394 main.cpp:354] Iteration 28910, loss = 0.268041
I0526 08:37:26.282635 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.268041 (* 1 = 0.268041 loss)
I0526 08:37:26.282642 15394 sgd_solver.cpp:43] Iteration 28910, lr = 0.02
I0526 08:37:31.511833 15394 main.cpp:354] Iteration 28920, loss = 0.417775
I0526 08:37:31.511876 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.417774 (* 1 = 0.417774 loss)
I0526 08:37:31.511883 15394 sgd_solver.cpp:43] Iteration 28920, lr = 0.02
I0526 08:37:36.380949 15394 main.cpp:354] Iteration 28930, loss = 0.279088
I0526 08:37:36.380983 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.279088 (* 1 = 0.279088 loss)
I0526 08:37:36.380990 15394 sgd_solver.cpp:43] Iteration 28930, lr = 0.02
I0526 08:37:41.320718 15394 main.cpp:354] Iteration 28940, loss = 0.219866
I0526 08:37:41.320757 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.219865 (* 1 = 0.219865 loss)
I0526 08:37:41.320765 15394 sgd_solver.cpp:43] Iteration 28940, lr = 0.02
I0526 08:37:46.322283 15394 main.cpp:354] Iteration 28950, loss = 0.271067
I0526 08:37:46.322327 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.271067 (* 1 = 0.271067 loss)
I0526 08:37:46.322334 15394 sgd_solver.cpp:43] Iteration 28950, lr = 0.02
I0526 08:37:51.529201 15394 main.cpp:354] Iteration 28960, loss = 0.244354
I0526 08:37:51.529240 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.244353 (* 1 = 0.244353 loss)
I0526 08:37:51.529253 15394 sgd_solver.cpp:43] Iteration 28960, lr = 0.02
I0526 08:37:56.963042 15394 main.cpp:354] Iteration 28970, loss = 0.447739
I0526 08:37:56.963083 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.447739 (* 1 = 0.447739 loss)
I0526 08:37:56.963088 15394 sgd_solver.cpp:43] Iteration 28970, lr = 0.02
I0526 08:38:01.794855 15394 main.cpp:354] Iteration 28980, loss = 0.251652
I0526 08:38:01.794898 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.251652 (* 1 = 0.251652 loss)
I0526 08:38:01.794904 15394 sgd_solver.cpp:43] Iteration 28980, lr = 0.02
I0526 08:38:07.112401 15394 main.cpp:354] Iteration 28990, loss = 0.330807
I0526 08:38:07.112442 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.330807 (* 1 = 0.330807 loss)
I0526 08:38:07.112448 15394 sgd_solver.cpp:43] Iteration 28990, lr = 0.02
I0526 08:38:12.371460 15394 main.cpp:465] Iteration 29000, Testing net (#0)
I0526 08:38:25.461483 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8111
I0526 08:38:25.461524 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.630372 (* 1 = 0.630372 loss)
I0526 08:38:25.829449 15394 main.cpp:354] Iteration 29000, loss = 0.352342
I0526 08:38:25.829488 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.352342 (* 1 = 0.352342 loss)
I0526 08:38:25.829496 15394 sgd_solver.cpp:43] Iteration 29000, lr = 0.02
I0526 08:38:31.098189 15394 main.cpp:354] Iteration 29010, loss = 0.414125
I0526 08:38:31.098234 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.414125 (* 1 = 0.414125 loss)
I0526 08:38:31.098240 15394 sgd_solver.cpp:43] Iteration 29010, lr = 0.02
I0526 08:38:36.263847 15394 main.cpp:354] Iteration 29020, loss = 0.385937
I0526 08:38:36.263886 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.385937 (* 1 = 0.385937 loss)
I0526 08:38:36.263895 15394 sgd_solver.cpp:43] Iteration 29020, lr = 0.02
I0526 08:38:41.338034 15394 main.cpp:354] Iteration 29030, loss = 0.450092
I0526 08:38:41.338073 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.450092 (* 1 = 0.450092 loss)
I0526 08:38:41.338079 15394 sgd_solver.cpp:43] Iteration 29030, lr = 0.02
I0526 08:38:46.481477 15394 main.cpp:354] Iteration 29040, loss = 0.211988
I0526 08:38:46.481523 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.211988 (* 1 = 0.211988 loss)
I0526 08:38:46.481529 15394 sgd_solver.cpp:43] Iteration 29040, lr = 0.02
I0526 08:38:51.746373 15394 main.cpp:354] Iteration 29050, loss = 0.422866
I0526 08:38:51.746399 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.422866 (* 1 = 0.422866 loss)
I0526 08:38:51.746405 15394 sgd_solver.cpp:43] Iteration 29050, lr = 0.02
I0526 08:38:56.849390 15394 main.cpp:354] Iteration 29060, loss = 0.178543
I0526 08:38:56.849428 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.178543 (* 1 = 0.178543 loss)
I0526 08:38:56.849434 15394 sgd_solver.cpp:43] Iteration 29060, lr = 0.02
I0526 08:39:01.942606 15394 main.cpp:354] Iteration 29070, loss = 0.457659
I0526 08:39:01.942651 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.457659 (* 1 = 0.457659 loss)
I0526 08:39:01.942657 15394 sgd_solver.cpp:43] Iteration 29070, lr = 0.02
I0526 08:39:07.099550 15394 main.cpp:354] Iteration 29080, loss = 0.259351
I0526 08:39:07.099588 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.259351 (* 1 = 0.259351 loss)
I0526 08:39:07.099594 15394 sgd_solver.cpp:43] Iteration 29080, lr = 0.02
I0526 08:39:12.029670 15394 main.cpp:354] Iteration 29090, loss = 0.45738
I0526 08:39:12.029709 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.45738 (* 1 = 0.45738 loss)
I0526 08:39:12.029716 15394 sgd_solver.cpp:43] Iteration 29090, lr = 0.02
I0526 08:39:16.268429 15394 main.cpp:465] Iteration 29100, Testing net (#0)
I0526 08:39:29.349409 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8347
I0526 08:39:29.349438 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.482419 (* 1 = 0.482419 loss)
I0526 08:39:29.890486 15394 main.cpp:354] Iteration 29100, loss = 0.322336
I0526 08:39:29.890512 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.322336 (* 1 = 0.322336 loss)
I0526 08:39:29.890521 15394 sgd_solver.cpp:43] Iteration 29100, lr = 0.02
I0526 08:39:34.867427 15394 main.cpp:354] Iteration 29110, loss = 0.354014
I0526 08:39:34.867466 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.354014 (* 1 = 0.354014 loss)
I0526 08:39:34.867471 15394 sgd_solver.cpp:43] Iteration 29110, lr = 0.02
I0526 08:39:40.194797 15394 main.cpp:354] Iteration 29120, loss = 0.108375
I0526 08:39:40.194835 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.108375 (* 1 = 0.108375 loss)
I0526 08:39:40.194842 15394 sgd_solver.cpp:43] Iteration 29120, lr = 0.02
I0526 08:39:45.233083 15394 main.cpp:354] Iteration 29130, loss = 0.356772
I0526 08:39:45.233126 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.356772 (* 1 = 0.356772 loss)
I0526 08:39:45.233132 15394 sgd_solver.cpp:43] Iteration 29130, lr = 0.02
I0526 08:39:50.443889 15394 main.cpp:354] Iteration 29140, loss = 0.192175
I0526 08:39:50.443930 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.192175 (* 1 = 0.192175 loss)
I0526 08:39:50.443938 15394 sgd_solver.cpp:43] Iteration 29140, lr = 0.02
I0526 08:39:55.303998 15394 main.cpp:354] Iteration 29150, loss = 0.271013
I0526 08:39:55.304035 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.271013 (* 1 = 0.271013 loss)
I0526 08:39:55.304042 15394 sgd_solver.cpp:43] Iteration 29150, lr = 0.02
I0526 08:40:00.706337 15394 main.cpp:354] Iteration 29160, loss = 0.255188
I0526 08:40:00.706387 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.255188 (* 1 = 0.255188 loss)
I0526 08:40:00.706393 15394 sgd_solver.cpp:43] Iteration 29160, lr = 0.02
I0526 08:40:05.926733 15394 main.cpp:354] Iteration 29170, loss = 0.354495
I0526 08:40:05.926771 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.354495 (* 1 = 0.354495 loss)
I0526 08:40:05.926777 15394 sgd_solver.cpp:43] Iteration 29170, lr = 0.02
I0526 08:40:11.082535 15394 main.cpp:354] Iteration 29180, loss = 0.419585
I0526 08:40:11.082574 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.419585 (* 1 = 0.419585 loss)
I0526 08:40:11.082581 15394 sgd_solver.cpp:43] Iteration 29180, lr = 0.02
I0526 08:40:15.797693 15394 main.cpp:354] Iteration 29190, loss = 0.281657
I0526 08:40:15.797736 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.281657 (* 1 = 0.281657 loss)
I0526 08:40:15.797742 15394 sgd_solver.cpp:43] Iteration 29190, lr = 0.02
I0526 08:40:20.367367 15394 main.cpp:465] Iteration 29200, Testing net (#0)
I0526 08:40:33.453591 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8532
I0526 08:40:33.453631 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.432947 (* 1 = 0.432947 loss)
I0526 08:40:33.961621 15394 main.cpp:354] Iteration 29200, loss = 0.388012
I0526 08:40:33.961663 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.388012 (* 1 = 0.388012 loss)
I0526 08:40:33.961671 15394 sgd_solver.cpp:43] Iteration 29200, lr = 0.02
I0526 08:40:39.151638 15394 main.cpp:354] Iteration 29210, loss = 0.255675
I0526 08:40:39.151698 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.255675 (* 1 = 0.255675 loss)
I0526 08:40:39.151710 15394 sgd_solver.cpp:43] Iteration 29210, lr = 0.02
I0526 08:40:43.761327 15394 main.cpp:354] Iteration 29220, loss = 0.250914
I0526 08:40:43.761370 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.250914 (* 1 = 0.250914 loss)
I0526 08:40:43.761378 15394 sgd_solver.cpp:43] Iteration 29220, lr = 0.02
I0526 08:40:48.784071 15394 main.cpp:354] Iteration 29230, loss = 0.354587
I0526 08:40:48.784111 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.354587 (* 1 = 0.354587 loss)
I0526 08:40:48.784118 15394 sgd_solver.cpp:43] Iteration 29230, lr = 0.02
I0526 08:40:53.854801 15394 main.cpp:354] Iteration 29240, loss = 0.299288
I0526 08:40:53.854846 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.299288 (* 1 = 0.299288 loss)
I0526 08:40:53.854853 15394 sgd_solver.cpp:43] Iteration 29240, lr = 0.02
I0526 08:40:58.863764 15394 main.cpp:354] Iteration 29250, loss = 0.270752
I0526 08:40:58.863806 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.270751 (* 1 = 0.270751 loss)
I0526 08:40:58.863816 15394 sgd_solver.cpp:43] Iteration 29250, lr = 0.02
I0526 08:41:03.824865 15394 main.cpp:354] Iteration 29260, loss = 0.220014
I0526 08:41:03.824904 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.220014 (* 1 = 0.220014 loss)
I0526 08:41:03.824911 15394 sgd_solver.cpp:43] Iteration 29260, lr = 0.02
I0526 08:41:09.033782 15394 main.cpp:354] Iteration 29270, loss = 0.279674
I0526 08:41:09.033821 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.279674 (* 1 = 0.279674 loss)
I0526 08:41:09.033828 15394 sgd_solver.cpp:43] Iteration 29270, lr = 0.02
I0526 08:41:14.125700 15394 main.cpp:354] Iteration 29280, loss = 0.407781
I0526 08:41:14.125747 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.407781 (* 1 = 0.407781 loss)
I0526 08:41:14.125756 15394 sgd_solver.cpp:43] Iteration 29280, lr = 0.02
I0526 08:41:19.666221 15394 main.cpp:354] Iteration 29290, loss = 0.198849
I0526 08:41:19.666261 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.198849 (* 1 = 0.198849 loss)
I0526 08:41:19.666268 15394 sgd_solver.cpp:43] Iteration 29290, lr = 0.02
I0526 08:41:24.362048 15394 main.cpp:465] Iteration 29300, Testing net (#0)
I0526 08:41:37.452483 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8223
I0526 08:41:37.452523 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.532496 (* 1 = 0.532496 loss)
I0526 08:41:37.958032 15394 main.cpp:354] Iteration 29300, loss = 0.182617
I0526 08:41:37.958055 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.182617 (* 1 = 0.182617 loss)
I0526 08:41:37.958062 15394 sgd_solver.cpp:43] Iteration 29300, lr = 0.02
I0526 08:41:43.167521 15394 main.cpp:354] Iteration 29310, loss = 0.430137
I0526 08:41:43.167563 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.430136 (* 1 = 0.430136 loss)
I0526 08:41:43.167570 15394 sgd_solver.cpp:43] Iteration 29310, lr = 0.02
I0526 08:41:48.331882 15394 main.cpp:354] Iteration 29320, loss = 0.341779
I0526 08:41:48.331923 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.341778 (* 1 = 0.341778 loss)
I0526 08:41:48.331928 15394 sgd_solver.cpp:43] Iteration 29320, lr = 0.02
I0526 08:41:52.916126 15394 main.cpp:354] Iteration 29330, loss = 0.539558
I0526 08:41:52.916164 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.539558 (* 1 = 0.539558 loss)
I0526 08:41:52.916170 15394 sgd_solver.cpp:43] Iteration 29330, lr = 0.02
I0526 08:41:58.077919 15394 main.cpp:354] Iteration 29340, loss = 0.330242
I0526 08:41:58.077962 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.330242 (* 1 = 0.330242 loss)
I0526 08:41:58.077970 15394 sgd_solver.cpp:43] Iteration 29340, lr = 0.02
I0526 08:42:02.518947 15394 main.cpp:354] Iteration 29350, loss = 0.328134
I0526 08:42:02.518986 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.328134 (* 1 = 0.328134 loss)
I0526 08:42:02.518992 15394 sgd_solver.cpp:43] Iteration 29350, lr = 0.02
I0526 08:42:07.062961 15394 main.cpp:354] Iteration 29360, loss = 0.500557
I0526 08:42:07.062991 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.500557 (* 1 = 0.500557 loss)
I0526 08:42:07.062997 15394 sgd_solver.cpp:43] Iteration 29360, lr = 0.02
I0526 08:42:11.916916 15394 main.cpp:354] Iteration 29370, loss = 0.177593
I0526 08:42:11.916954 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.177593 (* 1 = 0.177593 loss)
I0526 08:42:11.916961 15394 sgd_solver.cpp:43] Iteration 29370, lr = 0.02
I0526 08:42:16.611656 15394 main.cpp:354] Iteration 29380, loss = 0.287282
I0526 08:42:16.611701 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.287282 (* 1 = 0.287282 loss)
I0526 08:42:16.611712 15394 sgd_solver.cpp:43] Iteration 29380, lr = 0.02
I0526 08:42:21.447399 15394 main.cpp:354] Iteration 29390, loss = 0.280923
I0526 08:42:21.447443 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.280923 (* 1 = 0.280923 loss)
I0526 08:42:21.447449 15394 sgd_solver.cpp:43] Iteration 29390, lr = 0.02
I0526 08:42:25.756794 15394 main.cpp:465] Iteration 29400, Testing net (#0)
I0526 08:42:38.831764 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7568
I0526 08:42:38.831795 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.755706 (* 1 = 0.755706 loss)
I0526 08:42:39.337468 15394 main.cpp:354] Iteration 29400, loss = 0.384436
I0526 08:42:39.337503 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.384436 (* 1 = 0.384436 loss)
I0526 08:42:39.337512 15394 sgd_solver.cpp:43] Iteration 29400, lr = 0.02
I0526 08:42:44.313427 15394 main.cpp:354] Iteration 29410, loss = 0.266311
I0526 08:42:44.313469 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.266311 (* 1 = 0.266311 loss)
I0526 08:42:44.313475 15394 sgd_solver.cpp:43] Iteration 29410, lr = 0.02
I0526 08:42:48.971343 15394 main.cpp:354] Iteration 29420, loss = 0.461354
I0526 08:42:48.971381 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.461353 (* 1 = 0.461353 loss)
I0526 08:42:48.971387 15394 sgd_solver.cpp:43] Iteration 29420, lr = 0.02
I0526 08:42:53.535908 15394 main.cpp:354] Iteration 29430, loss = 0.256021
I0526 08:42:53.535948 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.256021 (* 1 = 0.256021 loss)
I0526 08:42:53.535955 15394 sgd_solver.cpp:43] Iteration 29430, lr = 0.02
I0526 08:42:58.885195 15394 main.cpp:354] Iteration 29440, loss = 0.356576
I0526 08:42:58.885238 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.356575 (* 1 = 0.356575 loss)
I0526 08:42:58.885244 15394 sgd_solver.cpp:43] Iteration 29440, lr = 0.02
I0526 08:43:04.096614 15394 main.cpp:354] Iteration 29450, loss = 0.223762
I0526 08:43:04.096639 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.223761 (* 1 = 0.223761 loss)
I0526 08:43:04.096647 15394 sgd_solver.cpp:43] Iteration 29450, lr = 0.02
I0526 08:43:09.056749 15394 main.cpp:354] Iteration 29460, loss = 0.358332
I0526 08:43:09.056788 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.358332 (* 1 = 0.358332 loss)
I0526 08:43:09.056794 15394 sgd_solver.cpp:43] Iteration 29460, lr = 0.02
I0526 08:43:13.758343 15394 main.cpp:354] Iteration 29470, loss = 0.223895
I0526 08:43:13.758401 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.223894 (* 1 = 0.223894 loss)
I0526 08:43:13.758407 15394 sgd_solver.cpp:43] Iteration 29470, lr = 0.02
I0526 08:43:18.714900 15394 main.cpp:354] Iteration 29480, loss = 0.55234
I0526 08:43:18.714938 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.55234 (* 1 = 0.55234 loss)
I0526 08:43:18.714946 15394 sgd_solver.cpp:43] Iteration 29480, lr = 0.02
I0526 08:43:23.782238 15394 main.cpp:354] Iteration 29490, loss = 0.27972
I0526 08:43:23.782276 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.27972 (* 1 = 0.27972 loss)
I0526 08:43:23.782282 15394 sgd_solver.cpp:43] Iteration 29490, lr = 0.02
I0526 08:43:28.620194 15394 main.cpp:465] Iteration 29500, Testing net (#0)
I0526 08:43:41.702239 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8109
I0526 08:43:41.702280 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.558019 (* 1 = 0.558019 loss)
I0526 08:43:42.169075 15394 main.cpp:354] Iteration 29500, loss = 0.312008
I0526 08:43:42.169116 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.312008 (* 1 = 0.312008 loss)
I0526 08:43:42.169124 15394 sgd_solver.cpp:43] Iteration 29500, lr = 0.02
I0526 08:43:47.267230 15394 main.cpp:354] Iteration 29510, loss = 0.283015
I0526 08:43:47.267272 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.283015 (* 1 = 0.283015 loss)
I0526 08:43:47.267279 15394 sgd_solver.cpp:43] Iteration 29510, lr = 0.02
I0526 08:43:52.510871 15394 main.cpp:354] Iteration 29520, loss = 0.334186
I0526 08:43:52.510910 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.334186 (* 1 = 0.334186 loss)
I0526 08:43:52.510916 15394 sgd_solver.cpp:43] Iteration 29520, lr = 0.02
I0526 08:43:57.292050 15394 main.cpp:354] Iteration 29530, loss = 0.303916
I0526 08:43:57.292091 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.303916 (* 1 = 0.303916 loss)
I0526 08:43:57.292098 15394 sgd_solver.cpp:43] Iteration 29530, lr = 0.02
I0526 08:44:02.581385 15394 main.cpp:354] Iteration 29540, loss = 0.435758
I0526 08:44:02.581424 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.435758 (* 1 = 0.435758 loss)
I0526 08:44:02.581430 15394 sgd_solver.cpp:43] Iteration 29540, lr = 0.02
I0526 08:44:07.405339 15394 main.cpp:354] Iteration 29550, loss = 0.409358
I0526 08:44:07.405375 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.409357 (* 1 = 0.409357 loss)
I0526 08:44:07.405380 15394 sgd_solver.cpp:43] Iteration 29550, lr = 0.02
I0526 08:44:12.211660 15394 main.cpp:354] Iteration 29560, loss = 0.399566
I0526 08:44:12.211700 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.399566 (* 1 = 0.399566 loss)
I0526 08:44:12.211706 15394 sgd_solver.cpp:43] Iteration 29560, lr = 0.02
I0526 08:44:17.204445 15394 main.cpp:354] Iteration 29570, loss = 0.486998
I0526 08:44:17.204491 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.486998 (* 1 = 0.486998 loss)
I0526 08:44:17.204498 15394 sgd_solver.cpp:43] Iteration 29570, lr = 0.02
I0526 08:44:22.305492 15394 main.cpp:354] Iteration 29580, loss = 0.188729
I0526 08:44:22.305531 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.188729 (* 1 = 0.188729 loss)
I0526 08:44:22.305538 15394 sgd_solver.cpp:43] Iteration 29580, lr = 0.02
I0526 08:44:27.132825 15394 main.cpp:354] Iteration 29590, loss = 0.56831
I0526 08:44:27.132866 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.56831 (* 1 = 0.56831 loss)
I0526 08:44:27.132872 15394 sgd_solver.cpp:43] Iteration 29590, lr = 0.02
I0526 08:44:31.900647 15394 main.cpp:465] Iteration 29600, Testing net (#0)
I0526 08:44:44.982985 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8015
I0526 08:44:44.983028 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.642074 (* 1 = 0.642074 loss)
I0526 08:44:45.380481 15394 main.cpp:354] Iteration 29600, loss = 0.631586
I0526 08:44:45.380519 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.631586 (* 1 = 0.631586 loss)
I0526 08:44:45.380527 15394 sgd_solver.cpp:43] Iteration 29600, lr = 0.02
I0526 08:44:49.984201 15394 main.cpp:354] Iteration 29610, loss = 0.455399
I0526 08:44:49.984244 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.455399 (* 1 = 0.455399 loss)
I0526 08:44:49.984251 15394 sgd_solver.cpp:43] Iteration 29610, lr = 0.02
I0526 08:44:55.403854 15394 main.cpp:354] Iteration 29620, loss = 0.201742
I0526 08:44:55.403895 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.201742 (* 1 = 0.201742 loss)
I0526 08:44:55.403903 15394 sgd_solver.cpp:43] Iteration 29620, lr = 0.02
I0526 08:45:00.534260 15394 main.cpp:354] Iteration 29630, loss = 0.288767
I0526 08:45:00.534304 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.288766 (* 1 = 0.288766 loss)
I0526 08:45:00.534312 15394 sgd_solver.cpp:43] Iteration 29630, lr = 0.02
I0526 08:45:05.893698 15394 main.cpp:354] Iteration 29640, loss = 0.283976
I0526 08:45:05.893738 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.283975 (* 1 = 0.283975 loss)
I0526 08:45:05.893744 15394 sgd_solver.cpp:43] Iteration 29640, lr = 0.02
I0526 08:45:11.180341 15394 main.cpp:354] Iteration 29650, loss = 0.330834
I0526 08:45:11.180382 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.330834 (* 1 = 0.330834 loss)
I0526 08:45:11.180388 15394 sgd_solver.cpp:43] Iteration 29650, lr = 0.02
I0526 08:45:15.946928 15394 main.cpp:354] Iteration 29660, loss = 0.311472
I0526 08:45:15.946979 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.311472 (* 1 = 0.311472 loss)
I0526 08:45:15.946986 15394 sgd_solver.cpp:43] Iteration 29660, lr = 0.02
I0526 08:45:21.226357 15394 main.cpp:354] Iteration 29670, loss = 0.283064
I0526 08:45:21.226399 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.283064 (* 1 = 0.283064 loss)
I0526 08:45:21.226407 15394 sgd_solver.cpp:43] Iteration 29670, lr = 0.02
I0526 08:45:25.960677 15394 main.cpp:354] Iteration 29680, loss = 0.399551
I0526 08:45:25.960716 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.399551 (* 1 = 0.399551 loss)
I0526 08:45:25.960722 15394 sgd_solver.cpp:43] Iteration 29680, lr = 0.02
I0526 08:45:30.911782 15394 main.cpp:354] Iteration 29690, loss = 0.3182
I0526 08:45:30.911825 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.318199 (* 1 = 0.318199 loss)
I0526 08:45:30.911831 15394 sgd_solver.cpp:43] Iteration 29690, lr = 0.02
I0526 08:45:35.269443 15394 main.cpp:465] Iteration 29700, Testing net (#0)
I0526 08:45:48.354631 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7886
I0526 08:45:48.354684 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.691102 (* 1 = 0.691102 loss)
I0526 08:45:48.784118 15394 main.cpp:354] Iteration 29700, loss = 0.390604
I0526 08:45:48.784152 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.390604 (* 1 = 0.390604 loss)
I0526 08:45:48.784159 15394 sgd_solver.cpp:43] Iteration 29700, lr = 0.02
I0526 08:45:53.760639 15394 main.cpp:354] Iteration 29710, loss = 0.33338
I0526 08:45:53.760680 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.333379 (* 1 = 0.333379 loss)
I0526 08:45:53.760686 15394 sgd_solver.cpp:43] Iteration 29710, lr = 0.02
I0526 08:45:58.974776 15394 main.cpp:354] Iteration 29720, loss = 0.224625
I0526 08:45:58.974822 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.224625 (* 1 = 0.224625 loss)
I0526 08:45:58.974828 15394 sgd_solver.cpp:43] Iteration 29720, lr = 0.02
I0526 08:46:04.152814 15394 main.cpp:354] Iteration 29730, loss = 0.288848
I0526 08:46:04.152854 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.288847 (* 1 = 0.288847 loss)
I0526 08:46:04.152861 15394 sgd_solver.cpp:43] Iteration 29730, lr = 0.02
I0526 08:46:09.636397 15394 main.cpp:354] Iteration 29740, loss = 0.272611
I0526 08:46:09.636437 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.272611 (* 1 = 0.272611 loss)
I0526 08:46:09.636445 15394 sgd_solver.cpp:43] Iteration 29740, lr = 0.02
I0526 08:46:13.908445 15394 main.cpp:354] Iteration 29750, loss = 0.732481
I0526 08:46:13.908491 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.732481 (* 1 = 0.732481 loss)
I0526 08:46:13.908499 15394 sgd_solver.cpp:43] Iteration 29750, lr = 0.02
I0526 08:46:18.836782 15394 main.cpp:354] Iteration 29760, loss = 0.400837
I0526 08:46:18.836814 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.400837 (* 1 = 0.400837 loss)
I0526 08:46:18.836822 15394 sgd_solver.cpp:43] Iteration 29760, lr = 0.02
I0526 08:46:23.942975 15394 main.cpp:354] Iteration 29770, loss = 0.436033
I0526 08:46:23.943016 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.436033 (* 1 = 0.436033 loss)
I0526 08:46:23.943022 15394 sgd_solver.cpp:43] Iteration 29770, lr = 0.02
I0526 08:46:29.062399 15394 main.cpp:354] Iteration 29780, loss = 0.232825
I0526 08:46:29.062441 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.232825 (* 1 = 0.232825 loss)
I0526 08:46:29.062448 15394 sgd_solver.cpp:43] Iteration 29780, lr = 0.02
I0526 08:46:34.529223 15394 main.cpp:354] Iteration 29790, loss = 0.386699
I0526 08:46:34.529265 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.386699 (* 1 = 0.386699 loss)
I0526 08:46:34.529271 15394 sgd_solver.cpp:43] Iteration 29790, lr = 0.02
I0526 08:46:39.099230 15394 main.cpp:465] Iteration 29800, Testing net (#0)
I0526 08:46:52.177424 15394 main.cpp:532]     Test net output #0: Accuracy = 0.867
I0526 08:46:52.177469 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.405518 (* 1 = 0.405518 loss)
I0526 08:46:52.716806 15394 main.cpp:354] Iteration 29800, loss = 0.292615
I0526 08:46:52.716845 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.292615 (* 1 = 0.292615 loss)
I0526 08:46:52.716853 15394 sgd_solver.cpp:43] Iteration 29800, lr = 0.02
I0526 08:46:58.021808 15394 main.cpp:354] Iteration 29810, loss = 0.544472
I0526 08:46:58.021849 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.544472 (* 1 = 0.544472 loss)
I0526 08:46:58.021857 15394 sgd_solver.cpp:43] Iteration 29810, lr = 0.02
I0526 08:47:03.334666 15394 main.cpp:354] Iteration 29820, loss = 0.285713
I0526 08:47:03.334707 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.285713 (* 1 = 0.285713 loss)
I0526 08:47:03.334713 15394 sgd_solver.cpp:43] Iteration 29820, lr = 0.02
I0526 08:47:08.360743 15394 main.cpp:354] Iteration 29830, loss = 0.30881
I0526 08:47:08.360783 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.30881 (* 1 = 0.30881 loss)
I0526 08:47:08.360790 15394 sgd_solver.cpp:43] Iteration 29830, lr = 0.02
I0526 08:47:13.660297 15394 main.cpp:354] Iteration 29840, loss = 0.23497
I0526 08:47:13.660341 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.23497 (* 1 = 0.23497 loss)
I0526 08:47:13.660346 15394 sgd_solver.cpp:43] Iteration 29840, lr = 0.02
I0526 08:47:17.653311 15394 main.cpp:354] Iteration 29850, loss = 0.253066
I0526 08:47:17.653352 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.253066 (* 1 = 0.253066 loss)
I0526 08:47:17.653359 15394 sgd_solver.cpp:43] Iteration 29850, lr = 0.02
I0526 08:47:22.805371 15394 main.cpp:354] Iteration 29860, loss = 0.308713
I0526 08:47:22.805410 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.308713 (* 1 = 0.308713 loss)
I0526 08:47:22.805418 15394 sgd_solver.cpp:43] Iteration 29860, lr = 0.02
I0526 08:47:27.503290 15394 main.cpp:354] Iteration 29870, loss = 0.292851
I0526 08:47:27.503332 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.292851 (* 1 = 0.292851 loss)
I0526 08:47:27.503340 15394 sgd_solver.cpp:43] Iteration 29870, lr = 0.02
I0526 08:47:32.190425 15394 main.cpp:354] Iteration 29880, loss = 0.364163
I0526 08:47:32.190471 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.364163 (* 1 = 0.364163 loss)
I0526 08:47:32.190479 15394 sgd_solver.cpp:43] Iteration 29880, lr = 0.02
I0526 08:47:37.361659 15394 main.cpp:354] Iteration 29890, loss = 0.428911
I0526 08:47:37.361698 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.428911 (* 1 = 0.428911 loss)
I0526 08:47:37.361704 15394 sgd_solver.cpp:43] Iteration 29890, lr = 0.02
I0526 08:47:41.820951 15394 main.cpp:465] Iteration 29900, Testing net (#0)
I0526 08:47:54.904742 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8537
I0526 08:47:54.904781 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.434696 (* 1 = 0.434696 loss)
I0526 08:47:55.406337 15394 main.cpp:354] Iteration 29900, loss = 0.35347
I0526 08:47:55.406391 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.35347 (* 1 = 0.35347 loss)
I0526 08:47:55.406399 15394 sgd_solver.cpp:43] Iteration 29900, lr = 0.02
I0526 08:48:00.357264 15394 main.cpp:354] Iteration 29910, loss = 0.320334
I0526 08:48:00.357300 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.320333 (* 1 = 0.320333 loss)
I0526 08:48:00.357306 15394 sgd_solver.cpp:43] Iteration 29910, lr = 0.02
I0526 08:48:05.504981 15394 main.cpp:354] Iteration 29920, loss = 0.368129
I0526 08:48:05.505018 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.368129 (* 1 = 0.368129 loss)
I0526 08:48:05.505025 15394 sgd_solver.cpp:43] Iteration 29920, lr = 0.02
I0526 08:48:10.585537 15394 main.cpp:354] Iteration 29930, loss = 0.282234
I0526 08:48:10.585577 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.282234 (* 1 = 0.282234 loss)
I0526 08:48:10.585582 15394 sgd_solver.cpp:43] Iteration 29930, lr = 0.02
I0526 08:48:15.767931 15394 main.cpp:354] Iteration 29940, loss = 0.219129
I0526 08:48:15.767974 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.219129 (* 1 = 0.219129 loss)
I0526 08:48:15.767981 15394 sgd_solver.cpp:43] Iteration 29940, lr = 0.02
I0526 08:48:20.802115 15394 main.cpp:354] Iteration 29950, loss = 0.426384
I0526 08:48:20.802155 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.426384 (* 1 = 0.426384 loss)
I0526 08:48:20.802160 15394 sgd_solver.cpp:43] Iteration 29950, lr = 0.02
I0526 08:48:25.650058 15394 main.cpp:354] Iteration 29960, loss = 0.352756
I0526 08:48:25.650086 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.352756 (* 1 = 0.352756 loss)
I0526 08:48:25.650094 15394 sgd_solver.cpp:43] Iteration 29960, lr = 0.02
I0526 08:48:30.240200 15394 main.cpp:354] Iteration 29970, loss = 0.590169
I0526 08:48:30.240247 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.590169 (* 1 = 0.590169 loss)
I0526 08:48:30.240254 15394 sgd_solver.cpp:43] Iteration 29970, lr = 0.02
I0526 08:48:35.352718 15394 main.cpp:354] Iteration 29980, loss = 0.332313
I0526 08:48:35.352757 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.332313 (* 1 = 0.332313 loss)
I0526 08:48:35.352763 15394 sgd_solver.cpp:43] Iteration 29980, lr = 0.02
I0526 08:48:40.510529 15394 main.cpp:354] Iteration 29990, loss = 0.326901
I0526 08:48:40.510567 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.326901 (* 1 = 0.326901 loss)
I0526 08:48:40.510576 15394 sgd_solver.cpp:43] Iteration 29990, lr = 0.02
I0526 08:48:45.529417 15394 main.cpp:465] Iteration 30000, Testing net (#0)
I0526 08:48:58.604967 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8087
I0526 08:48:58.605008 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.637751 (* 1 = 0.637751 loss)
I0526 08:48:59.106422 15394 main.cpp:354] Iteration 30000, loss = 0.218994
I0526 08:48:59.106475 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.218994 (* 1 = 0.218994 loss)
I0526 08:48:59.106483 15394 sgd_solver.cpp:43] Iteration 30000, lr = 0.02
I0526 08:49:04.208132 15394 main.cpp:354] Iteration 30010, loss = 0.310501
I0526 08:49:04.208171 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.310501 (* 1 = 0.310501 loss)
I0526 08:49:04.208178 15394 sgd_solver.cpp:43] Iteration 30010, lr = 0.02
I0526 08:49:09.520548 15394 main.cpp:354] Iteration 30020, loss = 0.153762
I0526 08:49:09.520584 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.153762 (* 1 = 0.153762 loss)
I0526 08:49:09.520591 15394 sgd_solver.cpp:43] Iteration 30020, lr = 0.02
I0526 08:49:14.382302 15394 main.cpp:354] Iteration 30030, loss = 0.376239
I0526 08:49:14.382342 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.376239 (* 1 = 0.376239 loss)
I0526 08:49:14.382349 15394 sgd_solver.cpp:43] Iteration 30030, lr = 0.02
I0526 08:49:19.398752 15394 main.cpp:354] Iteration 30040, loss = 0.311635
I0526 08:49:19.398790 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.311635 (* 1 = 0.311635 loss)
I0526 08:49:19.398797 15394 sgd_solver.cpp:43] Iteration 30040, lr = 0.02
I0526 08:49:24.137899 15394 main.cpp:354] Iteration 30050, loss = 0.331755
I0526 08:49:24.137938 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.331754 (* 1 = 0.331754 loss)
I0526 08:49:24.137944 15394 sgd_solver.cpp:43] Iteration 30050, lr = 0.02
I0526 08:49:28.812005 15394 main.cpp:354] Iteration 30060, loss = 0.322162
I0526 08:49:28.812041 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.322162 (* 1 = 0.322162 loss)
I0526 08:49:28.812047 15394 sgd_solver.cpp:43] Iteration 30060, lr = 0.02
I0526 08:49:34.273056 15394 main.cpp:354] Iteration 30070, loss = 0.194753
I0526 08:49:34.273097 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.194752 (* 1 = 0.194752 loss)
I0526 08:49:34.273104 15394 sgd_solver.cpp:43] Iteration 30070, lr = 0.02
I0526 08:49:39.482586 15394 main.cpp:354] Iteration 30080, loss = 0.407825
I0526 08:49:39.482636 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.407824 (* 1 = 0.407824 loss)
I0526 08:49:39.482650 15394 sgd_solver.cpp:43] Iteration 30080, lr = 0.02
I0526 08:49:44.378885 15394 main.cpp:354] Iteration 30090, loss = 0.352381
I0526 08:49:44.378926 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.352381 (* 1 = 0.352381 loss)
I0526 08:49:44.378932 15394 sgd_solver.cpp:43] Iteration 30090, lr = 0.02
I0526 08:49:48.754176 15394 main.cpp:465] Iteration 30100, Testing net (#0)
I0526 08:50:01.839035 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8316
I0526 08:50:01.839077 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.521234 (* 1 = 0.521234 loss)
I0526 08:50:02.280069 15394 main.cpp:354] Iteration 30100, loss = 0.255233
I0526 08:50:02.280113 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.255233 (* 1 = 0.255233 loss)
I0526 08:50:02.280122 15394 sgd_solver.cpp:43] Iteration 30100, lr = 0.02
I0526 08:50:07.524750 15394 main.cpp:354] Iteration 30110, loss = 0.348767
I0526 08:50:07.524791 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.348767 (* 1 = 0.348767 loss)
I0526 08:50:07.524798 15394 sgd_solver.cpp:43] Iteration 30110, lr = 0.02
I0526 08:50:12.410768 15394 main.cpp:354] Iteration 30120, loss = 0.560978
I0526 08:50:12.410806 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.560978 (* 1 = 0.560978 loss)
I0526 08:50:12.410812 15394 sgd_solver.cpp:43] Iteration 30120, lr = 0.02
I0526 08:50:16.793963 15394 main.cpp:354] Iteration 30130, loss = 0.275594
I0526 08:50:16.794006 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.275594 (* 1 = 0.275594 loss)
I0526 08:50:16.794025 15394 sgd_solver.cpp:43] Iteration 30130, lr = 0.02
I0526 08:50:21.841199 15394 main.cpp:354] Iteration 30140, loss = 0.413783
I0526 08:50:21.841240 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.413783 (* 1 = 0.413783 loss)
I0526 08:50:21.841246 15394 sgd_solver.cpp:43] Iteration 30140, lr = 0.02
I0526 08:50:26.911543 15394 main.cpp:354] Iteration 30150, loss = 0.447675
I0526 08:50:26.911582 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.447674 (* 1 = 0.447674 loss)
I0526 08:50:26.911588 15394 sgd_solver.cpp:43] Iteration 30150, lr = 0.02
I0526 08:50:32.363082 15394 main.cpp:354] Iteration 30160, loss = 0.447855
I0526 08:50:32.363126 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.447855 (* 1 = 0.447855 loss)
I0526 08:50:32.363131 15394 sgd_solver.cpp:43] Iteration 30160, lr = 0.02
I0526 08:50:37.094110 15394 main.cpp:354] Iteration 30170, loss = 0.384733
I0526 08:50:37.094151 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.384733 (* 1 = 0.384733 loss)
I0526 08:50:37.094157 15394 sgd_solver.cpp:43] Iteration 30170, lr = 0.02
I0526 08:50:42.072973 15394 main.cpp:354] Iteration 30180, loss = 0.33947
I0526 08:50:42.073014 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.33947 (* 1 = 0.33947 loss)
I0526 08:50:42.073020 15394 sgd_solver.cpp:43] Iteration 30180, lr = 0.02
I0526 08:50:47.084586 15394 main.cpp:354] Iteration 30190, loss = 0.387438
I0526 08:50:47.084642 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.387438 (* 1 = 0.387438 loss)
I0526 08:50:47.084650 15394 sgd_solver.cpp:43] Iteration 30190, lr = 0.02
I0526 08:50:51.474155 15394 main.cpp:465] Iteration 30200, Testing net (#0)
I0526 08:51:04.558972 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8191
I0526 08:51:04.559013 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.526068 (* 1 = 0.526068 loss)
I0526 08:51:04.958555 15394 main.cpp:354] Iteration 30200, loss = 0.384329
I0526 08:51:04.958596 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.384329 (* 1 = 0.384329 loss)
I0526 08:51:04.958606 15394 sgd_solver.cpp:43] Iteration 30200, lr = 0.02
I0526 08:51:09.952271 15394 main.cpp:354] Iteration 30210, loss = 0.482807
I0526 08:51:09.952313 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.482807 (* 1 = 0.482807 loss)
I0526 08:51:09.952327 15394 sgd_solver.cpp:43] Iteration 30210, lr = 0.02
I0526 08:51:14.864892 15394 main.cpp:354] Iteration 30220, loss = 0.512904
I0526 08:51:14.864933 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.512904 (* 1 = 0.512904 loss)
I0526 08:51:14.864940 15394 sgd_solver.cpp:43] Iteration 30220, lr = 0.02
I0526 08:51:19.951228 15394 main.cpp:354] Iteration 30230, loss = 0.215415
I0526 08:51:19.951272 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.215415 (* 1 = 0.215415 loss)
I0526 08:51:19.951278 15394 sgd_solver.cpp:43] Iteration 30230, lr = 0.02
I0526 08:51:25.111853 15394 main.cpp:354] Iteration 30240, loss = 0.247367
I0526 08:51:25.111894 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.247366 (* 1 = 0.247366 loss)
I0526 08:51:25.111901 15394 sgd_solver.cpp:43] Iteration 30240, lr = 0.02
I0526 08:51:30.348052 15394 main.cpp:354] Iteration 30250, loss = 0.186808
I0526 08:51:30.348094 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186808 (* 1 = 0.186808 loss)
I0526 08:51:30.348101 15394 sgd_solver.cpp:43] Iteration 30250, lr = 0.02
I0526 08:51:35.717924 15394 main.cpp:354] Iteration 30260, loss = 0.28947
I0526 08:51:35.717964 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.28947 (* 1 = 0.28947 loss)
I0526 08:51:35.717972 15394 sgd_solver.cpp:43] Iteration 30260, lr = 0.02
I0526 08:51:40.743767 15394 main.cpp:354] Iteration 30270, loss = 0.230318
I0526 08:51:40.743805 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.230317 (* 1 = 0.230317 loss)
I0526 08:51:40.743811 15394 sgd_solver.cpp:43] Iteration 30270, lr = 0.02
I0526 08:51:46.061332 15394 main.cpp:354] Iteration 30280, loss = 0.223204
I0526 08:51:46.061373 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.223204 (* 1 = 0.223204 loss)
I0526 08:51:46.061380 15394 sgd_solver.cpp:43] Iteration 30280, lr = 0.02
I0526 08:51:51.648722 15394 main.cpp:354] Iteration 30290, loss = 0.334321
I0526 08:51:51.648764 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.334321 (* 1 = 0.334321 loss)
I0526 08:51:51.648772 15394 sgd_solver.cpp:43] Iteration 30290, lr = 0.02
I0526 08:51:55.861413 15394 main.cpp:465] Iteration 30300, Testing net (#0)
I0526 08:52:08.947286 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8072
I0526 08:52:08.947326 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.618186 (* 1 = 0.618186 loss)
I0526 08:52:09.381944 15394 main.cpp:354] Iteration 30300, loss = 0.334887
I0526 08:52:09.381979 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.334886 (* 1 = 0.334886 loss)
I0526 08:52:09.381988 15394 sgd_solver.cpp:43] Iteration 30300, lr = 0.02
I0526 08:52:14.418218 15394 main.cpp:354] Iteration 30310, loss = 0.308915
I0526 08:52:14.418261 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.308915 (* 1 = 0.308915 loss)
I0526 08:52:14.418267 15394 sgd_solver.cpp:43] Iteration 30310, lr = 0.02
I0526 08:52:19.673395 15394 main.cpp:354] Iteration 30320, loss = 0.429125
I0526 08:52:19.673434 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.429125 (* 1 = 0.429125 loss)
I0526 08:52:19.673441 15394 sgd_solver.cpp:43] Iteration 30320, lr = 0.02
I0526 08:52:24.594586 15394 main.cpp:354] Iteration 30330, loss = 0.293858
I0526 08:52:24.594626 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.293858 (* 1 = 0.293858 loss)
I0526 08:52:24.594635 15394 sgd_solver.cpp:43] Iteration 30330, lr = 0.02
I0526 08:52:29.846209 15394 main.cpp:354] Iteration 30340, loss = 0.300658
I0526 08:52:29.846253 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.300658 (* 1 = 0.300658 loss)
I0526 08:52:29.846261 15394 sgd_solver.cpp:43] Iteration 30340, lr = 0.02
I0526 08:52:35.254691 15394 main.cpp:354] Iteration 30350, loss = 0.159401
I0526 08:52:35.254732 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.159401 (* 1 = 0.159401 loss)
I0526 08:52:35.254739 15394 sgd_solver.cpp:43] Iteration 30350, lr = 0.02
I0526 08:52:40.356602 15394 main.cpp:354] Iteration 30360, loss = 0.33281
I0526 08:52:40.356647 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.33281 (* 1 = 0.33281 loss)
I0526 08:52:40.356653 15394 sgd_solver.cpp:43] Iteration 30360, lr = 0.02
I0526 08:52:45.400904 15394 main.cpp:354] Iteration 30370, loss = 0.321229
I0526 08:52:45.400948 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.321229 (* 1 = 0.321229 loss)
I0526 08:52:45.400954 15394 sgd_solver.cpp:43] Iteration 30370, lr = 0.02
I0526 08:52:50.272857 15394 main.cpp:354] Iteration 30380, loss = 0.284019
I0526 08:52:50.272897 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.284019 (* 1 = 0.284019 loss)
I0526 08:52:50.272903 15394 sgd_solver.cpp:43] Iteration 30380, lr = 0.02
I0526 08:52:55.786476 15394 main.cpp:354] Iteration 30390, loss = 0.345174
I0526 08:52:55.786515 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.345174 (* 1 = 0.345174 loss)
I0526 08:52:55.786521 15394 sgd_solver.cpp:43] Iteration 30390, lr = 0.02
I0526 08:53:00.117005 15394 main.cpp:465] Iteration 30400, Testing net (#0)
I0526 08:53:13.199796 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8367
I0526 08:53:13.199839 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.495635 (* 1 = 0.495635 loss)
I0526 08:53:13.531003 15394 main.cpp:354] Iteration 30400, loss = 0.780064
I0526 08:53:13.531033 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.780064 (* 1 = 0.780064 loss)
I0526 08:53:13.531043 15394 sgd_solver.cpp:43] Iteration 30400, lr = 0.02
I0526 08:53:18.622179 15394 main.cpp:354] Iteration 30410, loss = 0.295624
I0526 08:53:18.622218 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.295624 (* 1 = 0.295624 loss)
I0526 08:53:18.622225 15394 sgd_solver.cpp:43] Iteration 30410, lr = 0.02
I0526 08:53:23.185091 15394 main.cpp:354] Iteration 30420, loss = 0.514129
I0526 08:53:23.185129 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.514129 (* 1 = 0.514129 loss)
I0526 08:53:23.185135 15394 sgd_solver.cpp:43] Iteration 30420, lr = 0.02
I0526 08:53:28.357944 15394 main.cpp:354] Iteration 30430, loss = 0.333376
I0526 08:53:28.357980 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.333376 (* 1 = 0.333376 loss)
I0526 08:53:28.357985 15394 sgd_solver.cpp:43] Iteration 30430, lr = 0.02
I0526 08:53:33.012907 15394 main.cpp:354] Iteration 30440, loss = 0.457297
I0526 08:53:33.012946 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.457296 (* 1 = 0.457296 loss)
I0526 08:53:33.012953 15394 sgd_solver.cpp:43] Iteration 30440, lr = 0.02
I0526 08:53:38.396368 15394 main.cpp:354] Iteration 30450, loss = 0.260026
I0526 08:53:38.396406 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.260026 (* 1 = 0.260026 loss)
I0526 08:53:38.396414 15394 sgd_solver.cpp:43] Iteration 30450, lr = 0.02
I0526 08:53:43.210300 15394 main.cpp:354] Iteration 30460, loss = 0.217712
I0526 08:53:43.210343 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.217712 (* 1 = 0.217712 loss)
I0526 08:53:43.210351 15394 sgd_solver.cpp:43] Iteration 30460, lr = 0.02
I0526 08:53:48.583691 15394 main.cpp:354] Iteration 30470, loss = 0.161567
I0526 08:53:48.583734 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.161567 (* 1 = 0.161567 loss)
I0526 08:53:48.583741 15394 sgd_solver.cpp:43] Iteration 30470, lr = 0.02
I0526 08:53:54.022646 15394 main.cpp:354] Iteration 30480, loss = 0.227165
I0526 08:53:54.022683 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.227164 (* 1 = 0.227164 loss)
I0526 08:53:54.022691 15394 sgd_solver.cpp:43] Iteration 30480, lr = 0.02
I0526 08:53:59.498863 15394 main.cpp:354] Iteration 30490, loss = 0.171815
I0526 08:53:59.498908 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.171815 (* 1 = 0.171815 loss)
I0526 08:53:59.498914 15394 sgd_solver.cpp:43] Iteration 30490, lr = 0.02
I0526 08:54:04.177069 15394 main.cpp:465] Iteration 30500, Testing net (#0)
I0526 08:54:17.261814 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8114
I0526 08:54:17.261860 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.600875 (* 1 = 0.600875 loss)
I0526 08:54:17.733014 15394 main.cpp:354] Iteration 30500, loss = 0.368231
I0526 08:54:17.733055 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.368231 (* 1 = 0.368231 loss)
I0526 08:54:17.733063 15394 sgd_solver.cpp:43] Iteration 30500, lr = 0.02
I0526 08:54:22.875532 15394 main.cpp:354] Iteration 30510, loss = 0.318501
I0526 08:54:22.875573 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.3185 (* 1 = 0.3185 loss)
I0526 08:54:22.875579 15394 sgd_solver.cpp:43] Iteration 30510, lr = 0.02
I0526 08:54:27.846066 15394 main.cpp:354] Iteration 30520, loss = 0.192611
I0526 08:54:27.846109 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.192611 (* 1 = 0.192611 loss)
I0526 08:54:27.846117 15394 sgd_solver.cpp:43] Iteration 30520, lr = 0.02
I0526 08:54:32.998224 15394 main.cpp:354] Iteration 30530, loss = 0.510323
I0526 08:54:32.998262 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.510323 (* 1 = 0.510323 loss)
I0526 08:54:32.998268 15394 sgd_solver.cpp:43] Iteration 30530, lr = 0.02
I0526 08:54:37.777081 15394 main.cpp:354] Iteration 30540, loss = 0.301113
I0526 08:54:37.777107 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.301113 (* 1 = 0.301113 loss)
I0526 08:54:37.777113 15394 sgd_solver.cpp:43] Iteration 30540, lr = 0.02
I0526 08:54:42.583145 15394 main.cpp:354] Iteration 30550, loss = 0.441347
I0526 08:54:42.583184 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.441347 (* 1 = 0.441347 loss)
I0526 08:54:42.583189 15394 sgd_solver.cpp:43] Iteration 30550, lr = 0.02
I0526 08:54:47.645474 15394 main.cpp:354] Iteration 30560, loss = 0.532256
I0526 08:54:47.645519 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.532256 (* 1 = 0.532256 loss)
I0526 08:54:47.645524 15394 sgd_solver.cpp:43] Iteration 30560, lr = 0.02
I0526 08:54:52.958289 15394 main.cpp:354] Iteration 30570, loss = 0.388354
I0526 08:54:52.958328 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.388353 (* 1 = 0.388353 loss)
I0526 08:54:52.958335 15394 sgd_solver.cpp:43] Iteration 30570, lr = 0.02
I0526 08:54:58.173894 15394 main.cpp:354] Iteration 30580, loss = 0.467809
I0526 08:54:58.173951 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.467809 (* 1 = 0.467809 loss)
I0526 08:54:58.173960 15394 sgd_solver.cpp:43] Iteration 30580, lr = 0.02
I0526 08:55:02.697911 15394 main.cpp:354] Iteration 30590, loss = 0.334903
I0526 08:55:02.697952 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.334903 (* 1 = 0.334903 loss)
I0526 08:55:02.697958 15394 sgd_solver.cpp:43] Iteration 30590, lr = 0.02
I0526 08:55:07.249807 15394 main.cpp:465] Iteration 30600, Testing net (#0)
I0526 08:55:20.344175 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8431
I0526 08:55:20.344214 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.47575 (* 1 = 0.47575 loss)
I0526 08:55:20.785128 15394 main.cpp:354] Iteration 30600, loss = 0.305013
I0526 08:55:20.785169 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.305013 (* 1 = 0.305013 loss)
I0526 08:55:20.785177 15394 sgd_solver.cpp:43] Iteration 30600, lr = 0.02
I0526 08:55:26.032609 15394 main.cpp:354] Iteration 30610, loss = 0.382791
I0526 08:55:26.032647 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.382791 (* 1 = 0.382791 loss)
I0526 08:55:26.032655 15394 sgd_solver.cpp:43] Iteration 30610, lr = 0.02
I0526 08:55:30.974122 15394 main.cpp:354] Iteration 30620, loss = 0.5809
I0526 08:55:30.974164 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.5809 (* 1 = 0.5809 loss)
I0526 08:55:30.974171 15394 sgd_solver.cpp:43] Iteration 30620, lr = 0.02
I0526 08:55:36.136097 15394 main.cpp:354] Iteration 30630, loss = 0.392913
I0526 08:55:36.136137 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.392913 (* 1 = 0.392913 loss)
I0526 08:55:36.136142 15394 sgd_solver.cpp:43] Iteration 30630, lr = 0.02
I0526 08:55:40.728094 15394 main.cpp:354] Iteration 30640, loss = 0.343276
I0526 08:55:40.728122 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.343275 (* 1 = 0.343275 loss)
I0526 08:55:40.728129 15394 sgd_solver.cpp:43] Iteration 30640, lr = 0.02
I0526 08:55:46.353358 15394 main.cpp:354] Iteration 30650, loss = 0.259294
I0526 08:55:46.353401 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.259294 (* 1 = 0.259294 loss)
I0526 08:55:46.353407 15394 sgd_solver.cpp:43] Iteration 30650, lr = 0.02
I0526 08:55:51.469138 15394 main.cpp:354] Iteration 30660, loss = 0.307582
I0526 08:55:51.469177 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.307582 (* 1 = 0.307582 loss)
I0526 08:55:51.469184 15394 sgd_solver.cpp:43] Iteration 30660, lr = 0.02
I0526 08:55:56.500823 15394 main.cpp:354] Iteration 30670, loss = 0.231988
I0526 08:55:56.500861 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.231988 (* 1 = 0.231988 loss)
I0526 08:55:56.500867 15394 sgd_solver.cpp:43] Iteration 30670, lr = 0.02
I0526 08:56:01.641500 15394 main.cpp:354] Iteration 30680, loss = 0.346416
I0526 08:56:01.641542 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.346416 (* 1 = 0.346416 loss)
I0526 08:56:01.641548 15394 sgd_solver.cpp:43] Iteration 30680, lr = 0.02
I0526 08:56:06.855641 15394 main.cpp:354] Iteration 30690, loss = 0.541526
I0526 08:56:06.855681 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.541526 (* 1 = 0.541526 loss)
I0526 08:56:06.855687 15394 sgd_solver.cpp:43] Iteration 30690, lr = 0.02
I0526 08:56:10.895109 15394 main.cpp:465] Iteration 30700, Testing net (#0)
I0526 08:56:23.982899 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8636
I0526 08:56:23.982942 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.419279 (* 1 = 0.419279 loss)
I0526 08:56:24.522881 15394 main.cpp:354] Iteration 30700, loss = 0.282702
I0526 08:56:24.522913 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.282702 (* 1 = 0.282702 loss)
I0526 08:56:24.522922 15394 sgd_solver.cpp:43] Iteration 30700, lr = 0.02
I0526 08:56:29.362745 15394 main.cpp:354] Iteration 30710, loss = 0.302018
I0526 08:56:29.362787 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.302017 (* 1 = 0.302017 loss)
I0526 08:56:29.362792 15394 sgd_solver.cpp:43] Iteration 30710, lr = 0.02
I0526 08:56:34.648582 15394 main.cpp:354] Iteration 30720, loss = 0.303085
I0526 08:56:34.648622 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.303085 (* 1 = 0.303085 loss)
I0526 08:56:34.648628 15394 sgd_solver.cpp:43] Iteration 30720, lr = 0.02
I0526 08:56:40.212776 15394 main.cpp:354] Iteration 30730, loss = 0.335776
I0526 08:56:40.212815 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.335776 (* 1 = 0.335776 loss)
I0526 08:56:40.212822 15394 sgd_solver.cpp:43] Iteration 30730, lr = 0.02
I0526 08:56:45.669713 15394 main.cpp:354] Iteration 30740, loss = 0.248838
I0526 08:56:45.669756 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.248838 (* 1 = 0.248838 loss)
I0526 08:56:45.669762 15394 sgd_solver.cpp:43] Iteration 30740, lr = 0.02
I0526 08:56:50.769897 15394 main.cpp:354] Iteration 30750, loss = 0.270216
I0526 08:56:50.769937 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.270216 (* 1 = 0.270216 loss)
I0526 08:56:50.769943 15394 sgd_solver.cpp:43] Iteration 30750, lr = 0.02
I0526 08:56:55.507658 15394 main.cpp:354] Iteration 30760, loss = 0.776115
I0526 08:56:55.507697 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.776114 (* 1 = 0.776114 loss)
I0526 08:56:55.507704 15394 sgd_solver.cpp:43] Iteration 30760, lr = 0.02
I0526 08:57:00.321971 15394 main.cpp:354] Iteration 30770, loss = 0.379077
I0526 08:57:00.322013 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.379077 (* 1 = 0.379077 loss)
I0526 08:57:00.322021 15394 sgd_solver.cpp:43] Iteration 30770, lr = 0.02
I0526 08:57:05.118301 15394 main.cpp:354] Iteration 30780, loss = 0.372802
I0526 08:57:05.118345 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.372802 (* 1 = 0.372802 loss)
I0526 08:57:05.118351 15394 sgd_solver.cpp:43] Iteration 30780, lr = 0.02
I0526 08:57:10.414497 15394 main.cpp:354] Iteration 30790, loss = 0.249818
I0526 08:57:10.414536 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.249818 (* 1 = 0.249818 loss)
I0526 08:57:10.414543 15394 sgd_solver.cpp:43] Iteration 30790, lr = 0.02
I0526 08:57:14.965253 15394 main.cpp:465] Iteration 30800, Testing net (#0)
I0526 08:57:28.051630 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8357
I0526 08:57:28.051669 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.497507 (* 1 = 0.497507 loss)
I0526 08:57:28.554028 15394 main.cpp:354] Iteration 30800, loss = 0.282941
I0526 08:57:28.554069 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.28294 (* 1 = 0.28294 loss)
I0526 08:57:28.554077 15394 sgd_solver.cpp:43] Iteration 30800, lr = 0.02
I0526 08:57:33.760082 15394 main.cpp:354] Iteration 30810, loss = 0.383281
I0526 08:57:33.760123 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.383281 (* 1 = 0.383281 loss)
I0526 08:57:33.760130 15394 sgd_solver.cpp:43] Iteration 30810, lr = 0.02
I0526 08:57:39.211994 15394 main.cpp:354] Iteration 30820, loss = 0.28954
I0526 08:57:39.212034 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.28954 (* 1 = 0.28954 loss)
I0526 08:57:39.212041 15394 sgd_solver.cpp:43] Iteration 30820, lr = 0.02
I0526 08:57:44.241973 15394 main.cpp:354] Iteration 30830, loss = 0.387927
I0526 08:57:44.242014 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.387927 (* 1 = 0.387927 loss)
I0526 08:57:44.242022 15394 sgd_solver.cpp:43] Iteration 30830, lr = 0.02
I0526 08:57:49.376567 15394 main.cpp:354] Iteration 30840, loss = 0.371695
I0526 08:57:49.376605 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.371695 (* 1 = 0.371695 loss)
I0526 08:57:49.376612 15394 sgd_solver.cpp:43] Iteration 30840, lr = 0.02
I0526 08:57:54.443368 15394 main.cpp:354] Iteration 30850, loss = 0.229836
I0526 08:57:54.443408 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.229836 (* 1 = 0.229836 loss)
I0526 08:57:54.443414 15394 sgd_solver.cpp:43] Iteration 30850, lr = 0.02
I0526 08:57:59.427574 15394 main.cpp:354] Iteration 30860, loss = 0.195518
I0526 08:57:59.427604 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.195517 (* 1 = 0.195517 loss)
I0526 08:57:59.427610 15394 sgd_solver.cpp:43] Iteration 30860, lr = 0.02
I0526 08:58:04.590626 15394 main.cpp:354] Iteration 30870, loss = 0.213496
I0526 08:58:04.590664 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.213496 (* 1 = 0.213496 loss)
I0526 08:58:04.590672 15394 sgd_solver.cpp:43] Iteration 30870, lr = 0.02
I0526 08:58:09.683282 15394 main.cpp:354] Iteration 30880, loss = 0.195183
I0526 08:58:09.683322 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.195182 (* 1 = 0.195182 loss)
I0526 08:58:09.683329 15394 sgd_solver.cpp:43] Iteration 30880, lr = 0.02
I0526 08:58:14.839485 15394 main.cpp:354] Iteration 30890, loss = 0.170472
I0526 08:58:14.839526 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.170472 (* 1 = 0.170472 loss)
I0526 08:58:14.839532 15394 sgd_solver.cpp:43] Iteration 30890, lr = 0.02
I0526 08:58:19.773814 15394 main.cpp:465] Iteration 30900, Testing net (#0)
I0526 08:58:32.861073 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7767
I0526 08:58:32.861112 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.775829 (* 1 = 0.775829 loss)
I0526 08:58:33.330210 15394 main.cpp:354] Iteration 30900, loss = 0.350382
I0526 08:58:33.330247 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.350381 (* 1 = 0.350381 loss)
I0526 08:58:33.330255 15394 sgd_solver.cpp:43] Iteration 30900, lr = 0.02
I0526 08:58:37.849870 15394 main.cpp:354] Iteration 30910, loss = 0.293571
I0526 08:58:37.849908 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.293571 (* 1 = 0.293571 loss)
I0526 08:58:37.849920 15394 sgd_solver.cpp:43] Iteration 30910, lr = 0.02
I0526 08:58:43.247026 15394 main.cpp:354] Iteration 30920, loss = 0.290699
I0526 08:58:43.247069 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.290699 (* 1 = 0.290699 loss)
I0526 08:58:43.247078 15394 sgd_solver.cpp:43] Iteration 30920, lr = 0.02
I0526 08:58:48.359518 15394 main.cpp:354] Iteration 30930, loss = 0.29807
I0526 08:58:48.359557 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.29807 (* 1 = 0.29807 loss)
I0526 08:58:48.359565 15394 sgd_solver.cpp:43] Iteration 30930, lr = 0.02
I0526 08:58:53.090559 15394 main.cpp:354] Iteration 30940, loss = 0.233218
I0526 08:58:53.090602 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.233218 (* 1 = 0.233218 loss)
I0526 08:58:53.090610 15394 sgd_solver.cpp:43] Iteration 30940, lr = 0.02
I0526 08:58:58.379544 15394 main.cpp:354] Iteration 30950, loss = 0.482696
I0526 08:58:58.379597 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.482696 (* 1 = 0.482696 loss)
I0526 08:58:58.379603 15394 sgd_solver.cpp:43] Iteration 30950, lr = 0.02
I0526 08:59:03.383862 15394 main.cpp:354] Iteration 30960, loss = 0.210792
I0526 08:59:03.383903 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.210792 (* 1 = 0.210792 loss)
I0526 08:59:03.383909 15394 sgd_solver.cpp:43] Iteration 30960, lr = 0.02
I0526 08:59:08.567767 15394 main.cpp:354] Iteration 30970, loss = 0.282597
I0526 08:59:08.567807 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.282597 (* 1 = 0.282597 loss)
I0526 08:59:08.567813 15394 sgd_solver.cpp:43] Iteration 30970, lr = 0.02
I0526 08:59:13.683056 15394 main.cpp:354] Iteration 30980, loss = 0.240466
I0526 08:59:13.683096 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.240466 (* 1 = 0.240466 loss)
I0526 08:59:13.683102 15394 sgd_solver.cpp:43] Iteration 30980, lr = 0.02
I0526 08:59:18.673483 15394 main.cpp:354] Iteration 30990, loss = 0.341128
I0526 08:59:18.673522 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.341128 (* 1 = 0.341128 loss)
I0526 08:59:18.673529 15394 sgd_solver.cpp:43] Iteration 30990, lr = 0.02
I0526 08:59:23.202275 15394 main.cpp:465] Iteration 31000, Testing net (#0)
I0526 08:59:36.285933 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8541
I0526 08:59:36.285971 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.431722 (* 1 = 0.431722 loss)
I0526 08:59:36.758404 15394 main.cpp:354] Iteration 31000, loss = 0.300142
I0526 08:59:36.758445 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.300142 (* 1 = 0.300142 loss)
I0526 08:59:36.758453 15394 sgd_solver.cpp:43] Iteration 31000, lr = 0.02
I0526 08:59:41.739401 15394 main.cpp:354] Iteration 31010, loss = 0.247616
I0526 08:59:41.739442 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.247616 (* 1 = 0.247616 loss)
I0526 08:59:41.739449 15394 sgd_solver.cpp:43] Iteration 31010, lr = 0.02
I0526 08:59:46.254812 15394 main.cpp:354] Iteration 31020, loss = 0.180533
I0526 08:59:46.254855 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.180533 (* 1 = 0.180533 loss)
I0526 08:59:46.254863 15394 sgd_solver.cpp:43] Iteration 31020, lr = 0.02
I0526 08:59:51.004005 15394 main.cpp:354] Iteration 31030, loss = 0.336196
I0526 08:59:51.004046 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.336196 (* 1 = 0.336196 loss)
I0526 08:59:51.004053 15394 sgd_solver.cpp:43] Iteration 31030, lr = 0.02
I0526 08:59:55.969449 15394 main.cpp:354] Iteration 31040, loss = 0.274027
I0526 08:59:55.969488 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.274027 (* 1 = 0.274027 loss)
I0526 08:59:55.969496 15394 sgd_solver.cpp:43] Iteration 31040, lr = 0.02
I0526 09:00:00.849867 15394 main.cpp:354] Iteration 31050, loss = 0.469309
I0526 09:00:00.849910 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.469308 (* 1 = 0.469308 loss)
I0526 09:00:00.849916 15394 sgd_solver.cpp:43] Iteration 31050, lr = 0.02
I0526 09:00:06.093366 15394 main.cpp:354] Iteration 31060, loss = 0.296785
I0526 09:00:06.093406 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.296785 (* 1 = 0.296785 loss)
I0526 09:00:06.093413 15394 sgd_solver.cpp:43] Iteration 31060, lr = 0.02
I0526 09:00:11.402590 15394 main.cpp:354] Iteration 31070, loss = 0.520594
I0526 09:00:11.402626 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.520593 (* 1 = 0.520593 loss)
I0526 09:00:11.402632 15394 sgd_solver.cpp:43] Iteration 31070, lr = 0.02
I0526 09:00:16.723871 15394 main.cpp:354] Iteration 31080, loss = 0.344274
I0526 09:00:16.723917 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.344274 (* 1 = 0.344274 loss)
I0526 09:00:16.723923 15394 sgd_solver.cpp:43] Iteration 31080, lr = 0.02
I0526 09:00:22.032491 15394 main.cpp:354] Iteration 31090, loss = 0.235587
I0526 09:00:22.032529 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235587 (* 1 = 0.235587 loss)
I0526 09:00:22.032536 15394 sgd_solver.cpp:43] Iteration 31090, lr = 0.02
I0526 09:00:26.769484 15394 main.cpp:465] Iteration 31100, Testing net (#0)
I0526 09:00:39.856899 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8299
I0526 09:00:39.856942 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.499589 (* 1 = 0.499589 loss)
I0526 09:00:40.256778 15394 main.cpp:354] Iteration 31100, loss = 0.375387
I0526 09:00:40.256817 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.375387 (* 1 = 0.375387 loss)
I0526 09:00:40.256825 15394 sgd_solver.cpp:43] Iteration 31100, lr = 0.02
I0526 09:00:45.348400 15394 main.cpp:354] Iteration 31110, loss = 0.278174
I0526 09:00:45.348444 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.278174 (* 1 = 0.278174 loss)
I0526 09:00:45.348451 15394 sgd_solver.cpp:43] Iteration 31110, lr = 0.02
I0526 09:00:50.841521 15394 main.cpp:354] Iteration 31120, loss = 0.226942
I0526 09:00:50.841559 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.226942 (* 1 = 0.226942 loss)
I0526 09:00:50.841567 15394 sgd_solver.cpp:43] Iteration 31120, lr = 0.02
I0526 09:00:55.746942 15394 main.cpp:354] Iteration 31130, loss = 0.23312
I0526 09:00:55.746983 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.23312 (* 1 = 0.23312 loss)
I0526 09:00:55.746989 15394 sgd_solver.cpp:43] Iteration 31130, lr = 0.02
I0526 09:01:00.902588 15394 main.cpp:354] Iteration 31140, loss = 0.273452
I0526 09:01:00.902633 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.273452 (* 1 = 0.273452 loss)
I0526 09:01:00.902642 15394 sgd_solver.cpp:43] Iteration 31140, lr = 0.02
I0526 09:01:05.931933 15394 main.cpp:354] Iteration 31150, loss = 0.528908
I0526 09:01:05.931974 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.528908 (* 1 = 0.528908 loss)
I0526 09:01:05.931980 15394 sgd_solver.cpp:43] Iteration 31150, lr = 0.02
I0526 09:01:10.854935 15394 main.cpp:354] Iteration 31160, loss = 0.256194
I0526 09:01:10.854977 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.256194 (* 1 = 0.256194 loss)
I0526 09:01:10.854984 15394 sgd_solver.cpp:43] Iteration 31160, lr = 0.02
I0526 09:01:15.934377 15394 main.cpp:354] Iteration 31170, loss = 0.458204
I0526 09:01:15.934422 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.458204 (* 1 = 0.458204 loss)
I0526 09:01:15.934428 15394 sgd_solver.cpp:43] Iteration 31170, lr = 0.02
I0526 09:01:20.675940 15394 main.cpp:354] Iteration 31180, loss = 0.701924
I0526 09:01:20.675983 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.701924 (* 1 = 0.701924 loss)
I0526 09:01:20.675990 15394 sgd_solver.cpp:43] Iteration 31180, lr = 0.02
I0526 09:01:25.486197 15394 main.cpp:354] Iteration 31190, loss = 0.313094
I0526 09:01:25.486238 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.313094 (* 1 = 0.313094 loss)
I0526 09:01:25.486245 15394 sgd_solver.cpp:43] Iteration 31190, lr = 0.02
I0526 09:01:30.030504 15394 main.cpp:465] Iteration 31200, Testing net (#0)
I0526 09:01:43.117734 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8007
I0526 09:01:43.117779 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.65912 (* 1 = 0.65912 loss)
I0526 09:01:43.583796 15394 main.cpp:354] Iteration 31200, loss = 0.289199
I0526 09:01:43.583837 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.289198 (* 1 = 0.289198 loss)
I0526 09:01:43.583844 15394 sgd_solver.cpp:43] Iteration 31200, lr = 0.02
I0526 09:01:48.797715 15394 main.cpp:354] Iteration 31210, loss = 0.272954
I0526 09:01:48.797755 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.272954 (* 1 = 0.272954 loss)
I0526 09:01:48.797762 15394 sgd_solver.cpp:43] Iteration 31210, lr = 0.02
I0526 09:01:53.934437 15394 main.cpp:354] Iteration 31220, loss = 0.179676
I0526 09:01:53.934476 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.179675 (* 1 = 0.179675 loss)
I0526 09:01:53.934483 15394 sgd_solver.cpp:43] Iteration 31220, lr = 0.02
I0526 09:01:59.246296 15394 main.cpp:354] Iteration 31230, loss = 0.363158
I0526 09:01:59.246331 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.363157 (* 1 = 0.363157 loss)
I0526 09:01:59.246338 15394 sgd_solver.cpp:43] Iteration 31230, lr = 0.02
I0526 09:02:04.583247 15394 main.cpp:354] Iteration 31240, loss = 0.302902
I0526 09:02:04.583287 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.302902 (* 1 = 0.302902 loss)
I0526 09:02:04.583292 15394 sgd_solver.cpp:43] Iteration 31240, lr = 0.02
I0526 09:02:09.731149 15394 main.cpp:354] Iteration 31250, loss = 0.296108
I0526 09:02:09.731187 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.296108 (* 1 = 0.296108 loss)
I0526 09:02:09.731194 15394 sgd_solver.cpp:43] Iteration 31250, lr = 0.02
I0526 09:02:14.989132 15394 main.cpp:354] Iteration 31260, loss = 0.319549
I0526 09:02:14.989174 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.319549 (* 1 = 0.319549 loss)
I0526 09:02:14.989181 15394 sgd_solver.cpp:43] Iteration 31260, lr = 0.02
I0526 09:02:20.164285 15394 main.cpp:354] Iteration 31270, loss = 0.18077
I0526 09:02:20.164324 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.18077 (* 1 = 0.18077 loss)
I0526 09:02:20.164330 15394 sgd_solver.cpp:43] Iteration 31270, lr = 0.02
I0526 09:02:25.416098 15394 main.cpp:354] Iteration 31280, loss = 0.419384
I0526 09:02:25.416136 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.419384 (* 1 = 0.419384 loss)
I0526 09:02:25.416142 15394 sgd_solver.cpp:43] Iteration 31280, lr = 0.02
I0526 09:02:30.842320 15394 main.cpp:354] Iteration 31290, loss = 0.302291
I0526 09:02:30.842368 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.302291 (* 1 = 0.302291 loss)
I0526 09:02:30.842375 15394 sgd_solver.cpp:43] Iteration 31290, lr = 0.02
I0526 09:02:35.423460 15394 main.cpp:465] Iteration 31300, Testing net (#0)
I0526 09:02:48.509106 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7868
I0526 09:02:48.509148 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.739642 (* 1 = 0.739642 loss)
I0526 09:02:49.084265 15394 main.cpp:354] Iteration 31300, loss = 0.280659
I0526 09:02:49.084307 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.280658 (* 1 = 0.280658 loss)
I0526 09:02:49.084316 15394 sgd_solver.cpp:43] Iteration 31300, lr = 0.02
I0526 09:02:54.238440 15394 main.cpp:354] Iteration 31310, loss = 0.30342
I0526 09:02:54.238483 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.30342 (* 1 = 0.30342 loss)
I0526 09:02:54.238490 15394 sgd_solver.cpp:43] Iteration 31310, lr = 0.02
I0526 09:02:59.318881 15394 main.cpp:354] Iteration 31320, loss = 0.2919
I0526 09:02:59.318923 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.291899 (* 1 = 0.291899 loss)
I0526 09:02:59.318930 15394 sgd_solver.cpp:43] Iteration 31320, lr = 0.02
I0526 09:03:04.274704 15394 main.cpp:354] Iteration 31330, loss = 0.234031
I0526 09:03:04.274744 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.234031 (* 1 = 0.234031 loss)
I0526 09:03:04.274756 15394 sgd_solver.cpp:43] Iteration 31330, lr = 0.02
I0526 09:03:08.904005 15394 main.cpp:354] Iteration 31340, loss = 0.243952
I0526 09:03:08.904042 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.243952 (* 1 = 0.243952 loss)
I0526 09:03:08.904047 15394 sgd_solver.cpp:43] Iteration 31340, lr = 0.02
I0526 09:03:13.984760 15394 main.cpp:354] Iteration 31350, loss = 0.181012
I0526 09:03:13.984802 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.181012 (* 1 = 0.181012 loss)
I0526 09:03:13.984808 15394 sgd_solver.cpp:43] Iteration 31350, lr = 0.02
I0526 09:03:18.661545 15394 main.cpp:354] Iteration 31360, loss = 0.311621
I0526 09:03:18.661584 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.311621 (* 1 = 0.311621 loss)
I0526 09:03:18.661590 15394 sgd_solver.cpp:43] Iteration 31360, lr = 0.02
I0526 09:03:24.388525 15394 main.cpp:354] Iteration 31370, loss = 0.224025
I0526 09:03:24.388566 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.224025 (* 1 = 0.224025 loss)
I0526 09:03:24.388571 15394 sgd_solver.cpp:43] Iteration 31370, lr = 0.02
I0526 09:03:28.744951 15394 main.cpp:354] Iteration 31380, loss = 0.342614
I0526 09:03:28.744997 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.342614 (* 1 = 0.342614 loss)
I0526 09:03:28.745003 15394 sgd_solver.cpp:43] Iteration 31380, lr = 0.02
I0526 09:03:33.834949 15394 main.cpp:354] Iteration 31390, loss = 0.350658
I0526 09:03:33.834975 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.350657 (* 1 = 0.350657 loss)
I0526 09:03:33.834982 15394 sgd_solver.cpp:43] Iteration 31390, lr = 0.02
I0526 09:03:38.582849 15394 main.cpp:465] Iteration 31400, Testing net (#0)
I0526 09:03:51.665437 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8434
I0526 09:03:51.665477 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.4762 (* 1 = 0.4762 loss)
I0526 09:03:52.102579 15394 main.cpp:354] Iteration 31400, loss = 0.301794
I0526 09:03:52.102622 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.301793 (* 1 = 0.301793 loss)
I0526 09:03:52.102632 15394 sgd_solver.cpp:43] Iteration 31400, lr = 0.02
I0526 09:03:56.680949 15394 main.cpp:354] Iteration 31410, loss = 0.349667
I0526 09:03:56.680989 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.349667 (* 1 = 0.349667 loss)
I0526 09:03:56.680996 15394 sgd_solver.cpp:43] Iteration 31410, lr = 0.02
I0526 09:04:01.626585 15394 main.cpp:354] Iteration 31420, loss = 0.352831
I0526 09:04:01.626629 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.352831 (* 1 = 0.352831 loss)
I0526 09:04:01.626636 15394 sgd_solver.cpp:43] Iteration 31420, lr = 0.02
I0526 09:04:06.677007 15394 main.cpp:354] Iteration 31430, loss = 0.331031
I0526 09:04:06.677047 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.331031 (* 1 = 0.331031 loss)
I0526 09:04:06.677053 15394 sgd_solver.cpp:43] Iteration 31430, lr = 0.02
I0526 09:04:11.894014 15394 main.cpp:354] Iteration 31440, loss = 0.410312
I0526 09:04:11.894052 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.410312 (* 1 = 0.410312 loss)
I0526 09:04:11.894059 15394 sgd_solver.cpp:43] Iteration 31440, lr = 0.02
I0526 09:04:16.891046 15394 main.cpp:354] Iteration 31450, loss = 0.374775
I0526 09:04:16.891089 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.374775 (* 1 = 0.374775 loss)
I0526 09:04:16.891096 15394 sgd_solver.cpp:43] Iteration 31450, lr = 0.02
I0526 09:04:21.612998 15394 main.cpp:354] Iteration 31460, loss = 0.337476
I0526 09:04:21.613039 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.337476 (* 1 = 0.337476 loss)
I0526 09:04:21.613045 15394 sgd_solver.cpp:43] Iteration 31460, lr = 0.02
I0526 09:04:26.791168 15394 main.cpp:354] Iteration 31470, loss = 0.268321
I0526 09:04:26.791208 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.268321 (* 1 = 0.268321 loss)
I0526 09:04:26.791213 15394 sgd_solver.cpp:43] Iteration 31470, lr = 0.02
I0526 09:04:31.902904 15394 main.cpp:354] Iteration 31480, loss = 0.262948
I0526 09:04:31.902946 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.262948 (* 1 = 0.262948 loss)
I0526 09:04:31.902952 15394 sgd_solver.cpp:43] Iteration 31480, lr = 0.02
I0526 09:04:36.931504 15394 main.cpp:354] Iteration 31490, loss = 0.586987
I0526 09:04:36.931541 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.586986 (* 1 = 0.586986 loss)
I0526 09:04:36.931548 15394 sgd_solver.cpp:43] Iteration 31490, lr = 0.02
I0526 09:04:41.479603 15394 main.cpp:465] Iteration 31500, Testing net (#0)
I0526 09:04:54.565229 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8337
I0526 09:04:54.565273 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.531161 (* 1 = 0.531161 loss)
I0526 09:04:55.104455 15394 main.cpp:354] Iteration 31500, loss = 0.341178
I0526 09:04:55.104495 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.341178 (* 1 = 0.341178 loss)
I0526 09:04:55.104501 15394 sgd_solver.cpp:43] Iteration 31500, lr = 0.02
I0526 09:05:00.459202 15394 main.cpp:354] Iteration 31510, loss = 0.451102
I0526 09:05:00.459249 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.451101 (* 1 = 0.451101 loss)
I0526 09:05:00.459255 15394 sgd_solver.cpp:43] Iteration 31510, lr = 0.02
I0526 09:05:05.283956 15394 main.cpp:354] Iteration 31520, loss = 0.695765
I0526 09:05:05.283996 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.695765 (* 1 = 0.695765 loss)
I0526 09:05:05.284003 15394 sgd_solver.cpp:43] Iteration 31520, lr = 0.02
I0526 09:05:10.438650 15394 main.cpp:354] Iteration 31530, loss = 0.305056
I0526 09:05:10.438694 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.305056 (* 1 = 0.305056 loss)
I0526 09:05:10.438700 15394 sgd_solver.cpp:43] Iteration 31530, lr = 0.02
I0526 09:05:15.523330 15394 main.cpp:354] Iteration 31540, loss = 0.2852
I0526 09:05:15.523373 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.285199 (* 1 = 0.285199 loss)
I0526 09:05:15.523380 15394 sgd_solver.cpp:43] Iteration 31540, lr = 0.02
I0526 09:05:20.956852 15394 main.cpp:354] Iteration 31550, loss = 0.264114
I0526 09:05:20.956884 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.264114 (* 1 = 0.264114 loss)
I0526 09:05:20.956892 15394 sgd_solver.cpp:43] Iteration 31550, lr = 0.02
I0526 09:05:26.341315 15394 main.cpp:354] Iteration 31560, loss = 0.299922
I0526 09:05:26.341354 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.299921 (* 1 = 0.299921 loss)
I0526 09:05:26.341361 15394 sgd_solver.cpp:43] Iteration 31560, lr = 0.02
I0526 09:05:31.349413 15394 main.cpp:354] Iteration 31570, loss = 0.494057
I0526 09:05:31.349455 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.494057 (* 1 = 0.494057 loss)
I0526 09:05:31.349462 15394 sgd_solver.cpp:43] Iteration 31570, lr = 0.02
I0526 09:05:36.168743 15394 main.cpp:354] Iteration 31580, loss = 0.223408
I0526 09:05:36.168782 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.223408 (* 1 = 0.223408 loss)
I0526 09:05:36.168788 15394 sgd_solver.cpp:43] Iteration 31580, lr = 0.02
I0526 09:05:40.863050 15394 main.cpp:354] Iteration 31590, loss = 0.390858
I0526 09:05:40.863088 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.390858 (* 1 = 0.390858 loss)
I0526 09:05:40.863095 15394 sgd_solver.cpp:43] Iteration 31590, lr = 0.02
I0526 09:05:45.916769 15394 main.cpp:465] Iteration 31600, Testing net (#0)
I0526 09:05:59.001008 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8435
I0526 09:05:59.001049 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.480787 (* 1 = 0.480787 loss)
I0526 09:05:59.544607 15394 main.cpp:354] Iteration 31600, loss = 0.264181
I0526 09:05:59.544648 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.264181 (* 1 = 0.264181 loss)
I0526 09:05:59.544656 15394 sgd_solver.cpp:43] Iteration 31600, lr = 0.02
I0526 09:06:04.301065 15394 main.cpp:354] Iteration 31610, loss = 0.243661
I0526 09:06:04.301111 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.243661 (* 1 = 0.243661 loss)
I0526 09:06:04.301118 15394 sgd_solver.cpp:43] Iteration 31610, lr = 0.02
I0526 09:06:09.520169 15394 main.cpp:354] Iteration 31620, loss = 0.322005
I0526 09:06:09.520210 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.322005 (* 1 = 0.322005 loss)
I0526 09:06:09.520216 15394 sgd_solver.cpp:43] Iteration 31620, lr = 0.02
I0526 09:06:14.525267 15394 main.cpp:354] Iteration 31630, loss = 0.174244
I0526 09:06:14.525313 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.174244 (* 1 = 0.174244 loss)
I0526 09:06:14.525321 15394 sgd_solver.cpp:43] Iteration 31630, lr = 0.02
I0526 09:06:20.078673 15394 main.cpp:354] Iteration 31640, loss = 0.274219
I0526 09:06:20.078716 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.274218 (* 1 = 0.274218 loss)
I0526 09:06:20.078723 15394 sgd_solver.cpp:43] Iteration 31640, lr = 0.02
I0526 09:06:25.380342 15394 main.cpp:354] Iteration 31650, loss = 0.233299
I0526 09:06:25.380381 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.233299 (* 1 = 0.233299 loss)
I0526 09:06:25.380388 15394 sgd_solver.cpp:43] Iteration 31650, lr = 0.02
I0526 09:06:30.675313 15394 main.cpp:354] Iteration 31660, loss = 0.152844
I0526 09:06:30.675366 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.152844 (* 1 = 0.152844 loss)
I0526 09:06:30.675374 15394 sgd_solver.cpp:43] Iteration 31660, lr = 0.02
I0526 09:06:36.259318 15394 main.cpp:354] Iteration 31670, loss = 0.216465
I0526 09:06:36.259357 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.216465 (* 1 = 0.216465 loss)
I0526 09:06:36.259364 15394 sgd_solver.cpp:43] Iteration 31670, lr = 0.02
I0526 09:06:40.850003 15394 main.cpp:354] Iteration 31680, loss = 0.38178
I0526 09:06:40.850044 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.381779 (* 1 = 0.381779 loss)
I0526 09:06:40.850049 15394 sgd_solver.cpp:43] Iteration 31680, lr = 0.02
I0526 09:06:46.168020 15394 main.cpp:354] Iteration 31690, loss = 0.258661
I0526 09:06:46.168063 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.258661 (* 1 = 0.258661 loss)
I0526 09:06:46.168071 15394 sgd_solver.cpp:43] Iteration 31690, lr = 0.02
I0526 09:06:50.966745 15394 main.cpp:465] Iteration 31700, Testing net (#0)
I0526 09:07:04.049749 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8085
I0526 09:07:04.049792 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.605296 (* 1 = 0.605296 loss)
I0526 09:07:04.491339 15394 main.cpp:354] Iteration 31700, loss = 0.269548
I0526 09:07:04.491379 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.269547 (* 1 = 0.269547 loss)
I0526 09:07:04.491387 15394 sgd_solver.cpp:43] Iteration 31700, lr = 0.02
I0526 09:07:09.627132 15394 main.cpp:354] Iteration 31710, loss = 0.505026
I0526 09:07:09.627171 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.505025 (* 1 = 0.505025 loss)
I0526 09:07:09.627178 15394 sgd_solver.cpp:43] Iteration 31710, lr = 0.02
I0526 09:07:14.982388 15394 main.cpp:354] Iteration 31720, loss = 0.520007
I0526 09:07:14.982431 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.520007 (* 1 = 0.520007 loss)
I0526 09:07:14.982439 15394 sgd_solver.cpp:43] Iteration 31720, lr = 0.02
I0526 09:07:20.142884 15394 main.cpp:354] Iteration 31730, loss = 0.149943
I0526 09:07:20.142922 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.149943 (* 1 = 0.149943 loss)
I0526 09:07:20.142930 15394 sgd_solver.cpp:43] Iteration 31730, lr = 0.02
I0526 09:07:25.455142 15394 main.cpp:354] Iteration 31740, loss = 0.211672
I0526 09:07:25.455183 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.211672 (* 1 = 0.211672 loss)
I0526 09:07:25.455188 15394 sgd_solver.cpp:43] Iteration 31740, lr = 0.02
I0526 09:07:29.986234 15394 main.cpp:354] Iteration 31750, loss = 0.238413
I0526 09:07:29.986279 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.238413 (* 1 = 0.238413 loss)
I0526 09:07:29.986289 15394 sgd_solver.cpp:43] Iteration 31750, lr = 0.02
I0526 09:07:34.942930 15394 main.cpp:354] Iteration 31760, loss = 0.316682
I0526 09:07:34.942970 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.316682 (* 1 = 0.316682 loss)
I0526 09:07:34.942977 15394 sgd_solver.cpp:43] Iteration 31760, lr = 0.02
I0526 09:07:40.110569 15394 main.cpp:354] Iteration 31770, loss = 0.396439
I0526 09:07:40.110611 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.396438 (* 1 = 0.396438 loss)
I0526 09:07:40.110618 15394 sgd_solver.cpp:43] Iteration 31770, lr = 0.02
I0526 09:07:44.782187 15394 main.cpp:354] Iteration 31780, loss = 0.20044
I0526 09:07:44.782234 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.20044 (* 1 = 0.20044 loss)
I0526 09:07:44.782243 15394 sgd_solver.cpp:43] Iteration 31780, lr = 0.02
I0526 09:07:49.696738 15394 main.cpp:354] Iteration 31790, loss = 0.233949
I0526 09:07:49.696777 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.233948 (* 1 = 0.233948 loss)
I0526 09:07:49.696784 15394 sgd_solver.cpp:43] Iteration 31790, lr = 0.02
I0526 09:07:53.756860 15394 main.cpp:465] Iteration 31800, Testing net (#0)
I0526 09:08:06.846809 15394 main.cpp:532]     Test net output #0: Accuracy = 0.7909
I0526 09:08:06.846851 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.675676 (* 1 = 0.675676 loss)
I0526 09:08:07.313514 15394 main.cpp:354] Iteration 31800, loss = 0.408758
I0526 09:08:07.313554 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.408758 (* 1 = 0.408758 loss)
I0526 09:08:07.313561 15394 sgd_solver.cpp:43] Iteration 31800, lr = 0.02
I0526 09:08:12.213784 15394 main.cpp:354] Iteration 31810, loss = 0.301377
I0526 09:08:12.213824 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.301377 (* 1 = 0.301377 loss)
I0526 09:08:12.213830 15394 sgd_solver.cpp:43] Iteration 31810, lr = 0.02
I0526 09:08:17.261662 15394 main.cpp:354] Iteration 31820, loss = 0.249942
I0526 09:08:17.261690 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.249942 (* 1 = 0.249942 loss)
I0526 09:08:17.261698 15394 sgd_solver.cpp:43] Iteration 31820, lr = 0.02
I0526 09:08:22.519382 15394 main.cpp:354] Iteration 31830, loss = 0.375698
I0526 09:08:22.519425 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.375698 (* 1 = 0.375698 loss)
I0526 09:08:22.519433 15394 sgd_solver.cpp:43] Iteration 31830, lr = 0.02
I0526 09:08:27.672302 15394 main.cpp:354] Iteration 31840, loss = 0.261369
I0526 09:08:27.672341 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.261369 (* 1 = 0.261369 loss)
I0526 09:08:27.672348 15394 sgd_solver.cpp:43] Iteration 31840, lr = 0.02
I0526 09:08:32.926167 15394 main.cpp:354] Iteration 31850, loss = 0.402399
I0526 09:08:32.926213 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.402398 (* 1 = 0.402398 loss)
I0526 09:08:32.926228 15394 sgd_solver.cpp:43] Iteration 31850, lr = 0.02
I0526 09:08:37.816298 15394 main.cpp:354] Iteration 31860, loss = 0.242928
I0526 09:08:37.816339 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.242928 (* 1 = 0.242928 loss)
I0526 09:08:37.816346 15394 sgd_solver.cpp:43] Iteration 31860, lr = 0.02
I0526 09:08:42.783042 15394 main.cpp:354] Iteration 31870, loss = 0.475279
I0526 09:08:42.783087 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.475279 (* 1 = 0.475279 loss)
I0526 09:08:42.783094 15394 sgd_solver.cpp:43] Iteration 31870, lr = 0.02
I0526 09:08:48.121700 15394 main.cpp:354] Iteration 31880, loss = 0.403915
I0526 09:08:48.121739 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.403915 (* 1 = 0.403915 loss)
I0526 09:08:48.121747 15394 sgd_solver.cpp:43] Iteration 31880, lr = 0.02
I0526 09:08:53.662050 15394 main.cpp:354] Iteration 31890, loss = 0.298512
I0526 09:08:53.662092 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.298512 (* 1 = 0.298512 loss)
I0526 09:08:53.662099 15394 sgd_solver.cpp:43] Iteration 31890, lr = 0.02
I0526 09:08:58.454527 15394 main.cpp:465] Iteration 31900, Testing net (#0)
I0526 09:09:11.540113 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8409
I0526 09:09:11.540151 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.465485 (* 1 = 0.465485 loss)
I0526 09:09:11.902876 15394 main.cpp:354] Iteration 31900, loss = 0.593483
I0526 09:09:11.902918 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.593483 (* 1 = 0.593483 loss)
I0526 09:09:11.902925 15394 sgd_solver.cpp:43] Iteration 31900, lr = 0.02
I0526 09:09:16.952108 15394 main.cpp:354] Iteration 31910, loss = 0.234484
I0526 09:09:16.952153 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.234484 (* 1 = 0.234484 loss)
I0526 09:09:16.952160 15394 sgd_solver.cpp:43] Iteration 31910, lr = 0.02
I0526 09:09:22.118358 15394 main.cpp:354] Iteration 31920, loss = 0.47311
I0526 09:09:22.118408 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.47311 (* 1 = 0.47311 loss)
I0526 09:09:22.118415 15394 sgd_solver.cpp:43] Iteration 31920, lr = 0.02
I0526 09:09:27.417706 15394 main.cpp:354] Iteration 31930, loss = 0.355727
I0526 09:09:27.417758 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.355727 (* 1 = 0.355727 loss)
I0526 09:09:27.417765 15394 sgd_solver.cpp:43] Iteration 31930, lr = 0.02
I0526 09:09:32.585027 15394 main.cpp:354] Iteration 31940, loss = 0.297847
I0526 09:09:32.585077 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.297847 (* 1 = 0.297847 loss)
I0526 09:09:32.585083 15394 sgd_solver.cpp:43] Iteration 31940, lr = 0.02
I0526 09:09:37.886567 15394 main.cpp:354] Iteration 31950, loss = 0.344218
I0526 09:09:37.886606 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.344218 (* 1 = 0.344218 loss)
I0526 09:09:37.886612 15394 sgd_solver.cpp:43] Iteration 31950, lr = 0.02
I0526 09:09:42.777297 15394 main.cpp:354] Iteration 31960, loss = 0.433582
I0526 09:09:42.777339 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.433582 (* 1 = 0.433582 loss)
I0526 09:09:42.777348 15394 sgd_solver.cpp:43] Iteration 31960, lr = 0.02
I0526 09:09:47.908591 15394 main.cpp:354] Iteration 31970, loss = 0.241518
I0526 09:09:47.908633 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.241517 (* 1 = 0.241517 loss)
I0526 09:09:47.908640 15394 sgd_solver.cpp:43] Iteration 31970, lr = 0.02
I0526 09:09:53.034819 15394 main.cpp:354] Iteration 31980, loss = 0.264885
I0526 09:09:53.034862 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.264885 (* 1 = 0.264885 loss)
I0526 09:09:53.034868 15394 sgd_solver.cpp:43] Iteration 31980, lr = 0.02
I0526 09:09:57.799562 15394 main.cpp:354] Iteration 31990, loss = 0.457094
I0526 09:09:57.799602 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.457094 (* 1 = 0.457094 loss)
I0526 09:09:57.799607 15394 sgd_solver.cpp:43] Iteration 31990, lr = 0.02
I0526 09:10:01.989709 15394 main.cpp:465] Iteration 32000, Testing net (#0)
I0526 09:10:15.077822 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8355
I0526 09:10:15.077862 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.489559 (* 1 = 0.489559 loss)
I0526 09:10:15.580564 15394 main.cpp:354] Iteration 32000, loss = 0.350369
I0526 09:10:15.580607 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.350369 (* 1 = 0.350369 loss)
I0526 09:10:15.580615 15394 sgd_solver.cpp:234] MultiStep Status: Iteration 32000, step = 1
I0526 09:10:15.580620 15394 sgd_solver.cpp:43] Iteration 32000, lr = 0.002
I0526 09:10:21.158154 15394 main.cpp:354] Iteration 32010, loss = 0.124205
I0526 09:10:21.158206 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.124205 (* 1 = 0.124205 loss)
I0526 09:10:21.158213 15394 sgd_solver.cpp:43] Iteration 32010, lr = 0.002
I0526 09:10:26.184206 15394 main.cpp:354] Iteration 32020, loss = 0.334881
I0526 09:10:26.184245 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.334881 (* 1 = 0.334881 loss)
I0526 09:10:26.184252 15394 sgd_solver.cpp:43] Iteration 32020, lr = 0.002
I0526 09:10:31.214409 15394 main.cpp:354] Iteration 32030, loss = 0.310174
I0526 09:10:31.214452 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.310173 (* 1 = 0.310173 loss)
I0526 09:10:31.214458 15394 sgd_solver.cpp:43] Iteration 32030, lr = 0.002
I0526 09:10:35.888057 15394 main.cpp:354] Iteration 32040, loss = 0.183104
I0526 09:10:35.888098 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.183104 (* 1 = 0.183104 loss)
I0526 09:10:35.888104 15394 sgd_solver.cpp:43] Iteration 32040, lr = 0.002
I0526 09:10:40.922783 15394 main.cpp:354] Iteration 32050, loss = 0.289484
I0526 09:10:40.922823 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.289484 (* 1 = 0.289484 loss)
I0526 09:10:40.922829 15394 sgd_solver.cpp:43] Iteration 32050, lr = 0.002
I0526 09:10:46.224457 15394 main.cpp:354] Iteration 32060, loss = 0.199128
I0526 09:10:46.224499 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.199128 (* 1 = 0.199128 loss)
I0526 09:10:46.224506 15394 sgd_solver.cpp:43] Iteration 32060, lr = 0.002
I0526 09:10:51.390988 15394 main.cpp:354] Iteration 32070, loss = 0.535247
I0526 09:10:51.391026 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.535247 (* 1 = 0.535247 loss)
I0526 09:10:51.391032 15394 sgd_solver.cpp:43] Iteration 32070, lr = 0.002
I0526 09:10:56.117377 15394 main.cpp:354] Iteration 32080, loss = 0.555968
I0526 09:10:56.117415 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.555968 (* 1 = 0.555968 loss)
I0526 09:10:56.117421 15394 sgd_solver.cpp:43] Iteration 32080, lr = 0.002
I0526 09:11:01.211153 15394 main.cpp:354] Iteration 32090, loss = 0.351353
I0526 09:11:01.211184 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.351353 (* 1 = 0.351353 loss)
I0526 09:11:01.211191 15394 sgd_solver.cpp:43] Iteration 32090, lr = 0.002
I0526 09:11:06.123549 15394 main.cpp:465] Iteration 32100, Testing net (#0)
I0526 09:11:19.216362 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8656
I0526 09:11:19.216404 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.406076 (* 1 = 0.406076 loss)
I0526 09:11:19.721138 15394 main.cpp:354] Iteration 32100, loss = 0.159479
I0526 09:11:19.721174 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.159479 (* 1 = 0.159479 loss)
I0526 09:11:19.721182 15394 sgd_solver.cpp:43] Iteration 32100, lr = 0.002
I0526 09:11:24.853566 15394 main.cpp:354] Iteration 32110, loss = 0.282813
I0526 09:11:24.853607 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.282813 (* 1 = 0.282813 loss)
I0526 09:11:24.853615 15394 sgd_solver.cpp:43] Iteration 32110, lr = 0.002
I0526 09:11:30.120609 15394 main.cpp:354] Iteration 32120, loss = 0.160757
I0526 09:11:30.120663 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.160757 (* 1 = 0.160757 loss)
I0526 09:11:30.120671 15394 sgd_solver.cpp:43] Iteration 32120, lr = 0.002
I0526 09:11:35.520695 15394 main.cpp:354] Iteration 32130, loss = 0.295168
I0526 09:11:35.520735 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.295168 (* 1 = 0.295168 loss)
I0526 09:11:35.520741 15394 sgd_solver.cpp:43] Iteration 32130, lr = 0.002
I0526 09:11:40.718026 15394 main.cpp:354] Iteration 32140, loss = 0.206046
I0526 09:11:40.718068 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206046 (* 1 = 0.206046 loss)
I0526 09:11:40.718075 15394 sgd_solver.cpp:43] Iteration 32140, lr = 0.002
I0526 09:11:45.607234 15394 main.cpp:354] Iteration 32150, loss = 0.271692
I0526 09:11:45.607264 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.271692 (* 1 = 0.271692 loss)
I0526 09:11:45.607270 15394 sgd_solver.cpp:43] Iteration 32150, lr = 0.002
I0526 09:11:50.194419 15394 main.cpp:354] Iteration 32160, loss = 0.360593
I0526 09:11:50.194460 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.360593 (* 1 = 0.360593 loss)
I0526 09:11:50.194468 15394 sgd_solver.cpp:43] Iteration 32160, lr = 0.002
I0526 09:11:55.287092 15394 main.cpp:354] Iteration 32170, loss = 0.148682
I0526 09:11:55.287132 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.148682 (* 1 = 0.148682 loss)
I0526 09:11:55.287143 15394 sgd_solver.cpp:43] Iteration 32170, lr = 0.002
I0526 09:12:00.006799 15394 main.cpp:354] Iteration 32180, loss = 0.507422
I0526 09:12:00.006855 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.507422 (* 1 = 0.507422 loss)
I0526 09:12:00.006862 15394 sgd_solver.cpp:43] Iteration 32180, lr = 0.002
I0526 09:12:04.764889 15394 main.cpp:354] Iteration 32190, loss = 0.444072
I0526 09:12:04.764928 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.444072 (* 1 = 0.444072 loss)
I0526 09:12:04.764935 15394 sgd_solver.cpp:43] Iteration 32190, lr = 0.002
I0526 09:12:09.391707 15394 main.cpp:465] Iteration 32200, Testing net (#0)
I0526 09:12:22.480751 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8732
I0526 09:12:22.480792 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.378472 (* 1 = 0.378472 loss)
I0526 09:12:23.025909 15394 main.cpp:354] Iteration 32200, loss = 0.246341
I0526 09:12:23.025949 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.246341 (* 1 = 0.246341 loss)
I0526 09:12:23.025955 15394 sgd_solver.cpp:43] Iteration 32200, lr = 0.002
I0526 09:12:28.286309 15394 main.cpp:354] Iteration 32210, loss = 0.300139
I0526 09:12:28.286351 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.300138 (* 1 = 0.300138 loss)
I0526 09:12:28.286375 15394 sgd_solver.cpp:43] Iteration 32210, lr = 0.002
I0526 09:12:33.325340 15394 main.cpp:354] Iteration 32220, loss = 0.282475
I0526 09:12:33.325379 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.282475 (* 1 = 0.282475 loss)
I0526 09:12:33.325386 15394 sgd_solver.cpp:43] Iteration 32220, lr = 0.002
I0526 09:12:38.215201 15394 main.cpp:354] Iteration 32230, loss = 0.288839
I0526 09:12:38.215241 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.288838 (* 1 = 0.288838 loss)
I0526 09:12:38.215248 15394 sgd_solver.cpp:43] Iteration 32230, lr = 0.002
I0526 09:12:43.086869 15394 main.cpp:354] Iteration 32240, loss = 0.415538
I0526 09:12:43.086911 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.415537 (* 1 = 0.415537 loss)
I0526 09:12:43.086920 15394 sgd_solver.cpp:43] Iteration 32240, lr = 0.002
I0526 09:12:48.018923 15394 main.cpp:354] Iteration 32250, loss = 0.251813
I0526 09:12:48.018951 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.251812 (* 1 = 0.251812 loss)
I0526 09:12:48.018957 15394 sgd_solver.cpp:43] Iteration 32250, lr = 0.002
I0526 09:12:52.978329 15394 main.cpp:354] Iteration 32260, loss = 0.138316
I0526 09:12:52.978390 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.138315 (* 1 = 0.138315 loss)
I0526 09:12:52.978399 15394 sgd_solver.cpp:43] Iteration 32260, lr = 0.002
I0526 09:12:57.916673 15394 main.cpp:354] Iteration 32270, loss = 0.383145
I0526 09:12:57.916718 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.383144 (* 1 = 0.383144 loss)
I0526 09:12:57.916726 15394 sgd_solver.cpp:43] Iteration 32270, lr = 0.002
I0526 09:13:03.332391 15394 main.cpp:354] Iteration 32280, loss = 0.258422
I0526 09:13:03.332430 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.258422 (* 1 = 0.258422 loss)
I0526 09:13:03.332437 15394 sgd_solver.cpp:43] Iteration 32280, lr = 0.002
I0526 09:13:08.167390 15394 main.cpp:354] Iteration 32290, loss = 0.208962
I0526 09:13:08.167430 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.208961 (* 1 = 0.208961 loss)
I0526 09:13:08.167436 15394 sgd_solver.cpp:43] Iteration 32290, lr = 0.002
I0526 09:13:12.913256 15394 main.cpp:465] Iteration 32300, Testing net (#0)
I0526 09:13:26.001325 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8801
I0526 09:13:26.001363 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.354316 (* 1 = 0.354316 loss)
I0526 09:13:26.540786 15394 main.cpp:354] Iteration 32300, loss = 0.218061
I0526 09:13:26.540822 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.21806 (* 1 = 0.21806 loss)
I0526 09:13:26.540837 15394 sgd_solver.cpp:43] Iteration 32300, lr = 0.002
I0526 09:13:31.891702 15394 main.cpp:354] Iteration 32310, loss = 0.144252
I0526 09:13:31.891746 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.144252 (* 1 = 0.144252 loss)
I0526 09:13:31.891752 15394 sgd_solver.cpp:43] Iteration 32310, lr = 0.002
I0526 09:13:37.121076 15394 main.cpp:354] Iteration 32320, loss = 0.238709
I0526 09:13:37.121119 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.238709 (* 1 = 0.238709 loss)
I0526 09:13:37.121124 15394 sgd_solver.cpp:43] Iteration 32320, lr = 0.002
I0526 09:13:41.789041 15394 main.cpp:354] Iteration 32330, loss = 0.25054
I0526 09:13:41.789082 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.25054 (* 1 = 0.25054 loss)
I0526 09:13:41.789088 15394 sgd_solver.cpp:43] Iteration 32330, lr = 0.002
I0526 09:13:46.594460 15394 main.cpp:354] Iteration 32340, loss = 0.362401
I0526 09:13:46.594502 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.362401 (* 1 = 0.362401 loss)
I0526 09:13:46.594509 15394 sgd_solver.cpp:43] Iteration 32340, lr = 0.002
I0526 09:13:51.712759 15394 main.cpp:354] Iteration 32350, loss = 0.251379
I0526 09:13:51.712811 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.251379 (* 1 = 0.251379 loss)
I0526 09:13:51.712818 15394 sgd_solver.cpp:43] Iteration 32350, lr = 0.002
I0526 09:13:56.984690 15394 main.cpp:354] Iteration 32360, loss = 0.12313
I0526 09:13:56.984730 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.12313 (* 1 = 0.12313 loss)
I0526 09:13:56.984737 15394 sgd_solver.cpp:43] Iteration 32360, lr = 0.002
I0526 09:14:02.078321 15394 main.cpp:354] Iteration 32370, loss = 0.16124
I0526 09:14:02.078368 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.16124 (* 1 = 0.16124 loss)
I0526 09:14:02.078377 15394 sgd_solver.cpp:43] Iteration 32370, lr = 0.002
I0526 09:14:07.029064 15394 main.cpp:354] Iteration 32380, loss = 0.205755
I0526 09:14:07.029105 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.205755 (* 1 = 0.205755 loss)
I0526 09:14:07.029112 15394 sgd_solver.cpp:43] Iteration 32380, lr = 0.002
I0526 09:14:12.524915 15394 main.cpp:354] Iteration 32390, loss = 0.286379
I0526 09:14:12.524955 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.286379 (* 1 = 0.286379 loss)
I0526 09:14:12.524961 15394 sgd_solver.cpp:43] Iteration 32390, lr = 0.002
I0526 09:14:17.463963 15394 main.cpp:465] Iteration 32400, Testing net (#0)
I0526 09:14:30.551940 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8803
I0526 09:14:30.551981 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.349295 (* 1 = 0.349295 loss)
I0526 09:14:30.952039 15394 main.cpp:354] Iteration 32400, loss = 0.230899
I0526 09:14:30.952075 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.230898 (* 1 = 0.230898 loss)
I0526 09:14:30.952082 15394 sgd_solver.cpp:43] Iteration 32400, lr = 0.002
I0526 09:14:35.969611 15394 main.cpp:354] Iteration 32410, loss = 0.293348
I0526 09:14:35.969645 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.293348 (* 1 = 0.293348 loss)
I0526 09:14:35.969650 15394 sgd_solver.cpp:43] Iteration 32410, lr = 0.002
I0526 09:14:41.146277 15394 main.cpp:354] Iteration 32420, loss = 0.168068
I0526 09:14:41.146317 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.168068 (* 1 = 0.168068 loss)
I0526 09:14:41.146324 15394 sgd_solver.cpp:43] Iteration 32420, lr = 0.002
I0526 09:14:46.126014 15394 main.cpp:354] Iteration 32430, loss = 0.345233
I0526 09:14:46.126060 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.345232 (* 1 = 0.345232 loss)
I0526 09:14:46.126065 15394 sgd_solver.cpp:43] Iteration 32430, lr = 0.002
I0526 09:14:51.124214 15394 main.cpp:354] Iteration 32440, loss = 0.263548
I0526 09:14:51.124256 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.263548 (* 1 = 0.263548 loss)
I0526 09:14:51.124264 15394 sgd_solver.cpp:43] Iteration 32440, lr = 0.002
I0526 09:14:56.300263 15394 main.cpp:354] Iteration 32450, loss = 0.187611
I0526 09:14:56.300302 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187611 (* 1 = 0.187611 loss)
I0526 09:14:56.300307 15394 sgd_solver.cpp:43] Iteration 32450, lr = 0.002
I0526 09:15:00.958463 15394 main.cpp:354] Iteration 32460, loss = 0.472896
I0526 09:15:00.958493 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.472896 (* 1 = 0.472896 loss)
I0526 09:15:00.958499 15394 sgd_solver.cpp:43] Iteration 32460, lr = 0.002
I0526 09:15:06.061620 15394 main.cpp:354] Iteration 32470, loss = 0.181728
I0526 09:15:06.061658 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.181728 (* 1 = 0.181728 loss)
I0526 09:15:06.061664 15394 sgd_solver.cpp:43] Iteration 32470, lr = 0.002
I0526 09:15:11.107457 15394 main.cpp:354] Iteration 32480, loss = 0.220785
I0526 09:15:11.107497 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.220785 (* 1 = 0.220785 loss)
I0526 09:15:11.107506 15394 sgd_solver.cpp:43] Iteration 32480, lr = 0.002
I0526 09:15:16.331071 15394 main.cpp:354] Iteration 32490, loss = 0.242964
I0526 09:15:16.331115 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.242963 (* 1 = 0.242963 loss)
I0526 09:15:16.331121 15394 sgd_solver.cpp:43] Iteration 32490, lr = 0.002
I0526 09:15:20.690362 15394 main.cpp:465] Iteration 32500, Testing net (#0)
I0526 09:15:33.769532 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8768
I0526 09:15:33.769572 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.370297 (* 1 = 0.370297 loss)
I0526 09:15:34.308889 15394 main.cpp:354] Iteration 32500, loss = 0.177352
I0526 09:15:34.308928 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.177352 (* 1 = 0.177352 loss)
I0526 09:15:34.308935 15394 sgd_solver.cpp:43] Iteration 32500, lr = 0.002
I0526 09:15:39.185333 15394 main.cpp:354] Iteration 32510, loss = 0.176686
I0526 09:15:39.185366 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.176685 (* 1 = 0.176685 loss)
I0526 09:15:39.185374 15394 sgd_solver.cpp:43] Iteration 32510, lr = 0.002
I0526 09:15:44.686660 15394 main.cpp:354] Iteration 32520, loss = 0.236315
I0526 09:15:44.686713 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.236315 (* 1 = 0.236315 loss)
I0526 09:15:44.686719 15394 sgd_solver.cpp:43] Iteration 32520, lr = 0.002
I0526 09:15:50.098340 15394 main.cpp:354] Iteration 32530, loss = 0.219951
I0526 09:15:50.098394 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.219951 (* 1 = 0.219951 loss)
I0526 09:15:50.098402 15394 sgd_solver.cpp:43] Iteration 32530, lr = 0.002
I0526 09:15:55.647094 15394 main.cpp:354] Iteration 32540, loss = 0.173603
I0526 09:15:55.647135 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.173603 (* 1 = 0.173603 loss)
I0526 09:15:55.647142 15394 sgd_solver.cpp:43] Iteration 32540, lr = 0.002
I0526 09:16:00.807814 15394 main.cpp:354] Iteration 32550, loss = 0.351932
I0526 09:16:00.807857 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.351932 (* 1 = 0.351932 loss)
I0526 09:16:00.807863 15394 sgd_solver.cpp:43] Iteration 32550, lr = 0.002
I0526 09:16:06.190775 15394 main.cpp:354] Iteration 32560, loss = 0.269152
I0526 09:16:06.190815 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.269152 (* 1 = 0.269152 loss)
I0526 09:16:06.190822 15394 sgd_solver.cpp:43] Iteration 32560, lr = 0.002
I0526 09:16:11.493655 15394 main.cpp:354] Iteration 32570, loss = 0.389611
I0526 09:16:11.493695 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.389611 (* 1 = 0.389611 loss)
I0526 09:16:11.493700 15394 sgd_solver.cpp:43] Iteration 32570, lr = 0.002
I0526 09:16:16.396502 15394 main.cpp:354] Iteration 32580, loss = 0.172871
I0526 09:16:16.396544 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.172871 (* 1 = 0.172871 loss)
I0526 09:16:16.396551 15394 sgd_solver.cpp:43] Iteration 32580, lr = 0.002
I0526 09:16:21.654654 15394 main.cpp:354] Iteration 32590, loss = 0.289254
I0526 09:16:21.654711 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.289253 (* 1 = 0.289253 loss)
I0526 09:16:21.654717 15394 sgd_solver.cpp:43] Iteration 32590, lr = 0.002
I0526 09:16:26.380704 15394 main.cpp:465] Iteration 32600, Testing net (#0)
I0526 09:16:39.468441 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8811
I0526 09:16:39.468482 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.349797 (* 1 = 0.349797 loss)
I0526 09:16:40.014149 15394 main.cpp:354] Iteration 32600, loss = 0.210629
I0526 09:16:40.014196 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.210629 (* 1 = 0.210629 loss)
I0526 09:16:40.014204 15394 sgd_solver.cpp:43] Iteration 32600, lr = 0.002
I0526 09:16:45.157464 15394 main.cpp:354] Iteration 32610, loss = 0.252789
I0526 09:16:45.157508 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.252789 (* 1 = 0.252789 loss)
I0526 09:16:45.157516 15394 sgd_solver.cpp:43] Iteration 32610, lr = 0.002
I0526 09:16:50.604508 15394 main.cpp:354] Iteration 32620, loss = 0.209176
I0526 09:16:50.604548 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.209176 (* 1 = 0.209176 loss)
I0526 09:16:50.604554 15394 sgd_solver.cpp:43] Iteration 32620, lr = 0.002
I0526 09:16:55.942165 15394 main.cpp:354] Iteration 32630, loss = 0.246108
I0526 09:16:55.942204 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.246108 (* 1 = 0.246108 loss)
I0526 09:16:55.942211 15394 sgd_solver.cpp:43] Iteration 32630, lr = 0.002
I0526 09:17:01.125661 15394 main.cpp:354] Iteration 32640, loss = 0.200218
I0526 09:17:01.125694 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.200218 (* 1 = 0.200218 loss)
I0526 09:17:01.125700 15394 sgd_solver.cpp:43] Iteration 32640, lr = 0.002
I0526 09:17:05.934705 15394 main.cpp:354] Iteration 32650, loss = 0.376971
I0526 09:17:05.934746 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.376971 (* 1 = 0.376971 loss)
I0526 09:17:05.934751 15394 sgd_solver.cpp:43] Iteration 32650, lr = 0.002
I0526 09:17:10.810222 15394 main.cpp:354] Iteration 32660, loss = 0.288506
I0526 09:17:10.810262 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.288506 (* 1 = 0.288506 loss)
I0526 09:17:10.810269 15394 sgd_solver.cpp:43] Iteration 32660, lr = 0.002
I0526 09:17:15.940130 15394 main.cpp:354] Iteration 32670, loss = 0.222495
I0526 09:17:15.940172 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.222495 (* 1 = 0.222495 loss)
I0526 09:17:15.940178 15394 sgd_solver.cpp:43] Iteration 32670, lr = 0.002
I0526 09:17:20.630154 15394 main.cpp:354] Iteration 32680, loss = 0.284109
I0526 09:17:20.630193 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.284109 (* 1 = 0.284109 loss)
I0526 09:17:20.630199 15394 sgd_solver.cpp:43] Iteration 32680, lr = 0.002
I0526 09:17:25.568725 15394 main.cpp:354] Iteration 32690, loss = 0.208735
I0526 09:17:25.568764 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.208735 (* 1 = 0.208735 loss)
I0526 09:17:25.568771 15394 sgd_solver.cpp:43] Iteration 32690, lr = 0.002
I0526 09:17:30.154557 15394 main.cpp:465] Iteration 32700, Testing net (#0)
I0526 09:17:43.240905 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8844
I0526 09:17:43.240947 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.351006 (* 1 = 0.351006 loss)
I0526 09:17:43.743731 15394 main.cpp:354] Iteration 32700, loss = 0.173003
I0526 09:17:43.743774 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.173002 (* 1 = 0.173002 loss)
I0526 09:17:43.743782 15394 sgd_solver.cpp:43] Iteration 32700, lr = 0.002
I0526 09:17:49.062963 15394 main.cpp:354] Iteration 32710, loss = 0.328864
I0526 09:17:49.063027 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.328863 (* 1 = 0.328863 loss)
I0526 09:17:49.063035 15394 sgd_solver.cpp:43] Iteration 32710, lr = 0.002
I0526 09:17:54.173257 15394 main.cpp:354] Iteration 32720, loss = 0.28609
I0526 09:17:54.173297 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.286089 (* 1 = 0.286089 loss)
I0526 09:17:54.173310 15394 sgd_solver.cpp:43] Iteration 32720, lr = 0.002
I0526 09:17:59.264654 15394 main.cpp:354] Iteration 32730, loss = 0.190909
I0526 09:17:59.264696 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.190909 (* 1 = 0.190909 loss)
I0526 09:17:59.264703 15394 sgd_solver.cpp:43] Iteration 32730, lr = 0.002
I0526 09:18:03.738324 15394 main.cpp:354] Iteration 32740, loss = 0.244564
I0526 09:18:03.738368 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.244564 (* 1 = 0.244564 loss)
I0526 09:18:03.738374 15394 sgd_solver.cpp:43] Iteration 32740, lr = 0.002
I0526 09:18:08.514459 15394 main.cpp:354] Iteration 32750, loss = 0.272369
I0526 09:18:08.514499 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.272369 (* 1 = 0.272369 loss)
I0526 09:18:08.514508 15394 sgd_solver.cpp:43] Iteration 32750, lr = 0.002
I0526 09:18:13.575052 15394 main.cpp:354] Iteration 32760, loss = 0.413062
I0526 09:18:13.575095 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.413062 (* 1 = 0.413062 loss)
I0526 09:18:13.575101 15394 sgd_solver.cpp:43] Iteration 32760, lr = 0.002
I0526 09:18:18.718019 15394 main.cpp:354] Iteration 32770, loss = 0.181981
I0526 09:18:18.718058 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.181981 (* 1 = 0.181981 loss)
I0526 09:18:18.718065 15394 sgd_solver.cpp:43] Iteration 32770, lr = 0.002
I0526 09:18:23.911803 15394 main.cpp:354] Iteration 32780, loss = 0.30948
I0526 09:18:23.911844 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.30948 (* 1 = 0.30948 loss)
I0526 09:18:23.911850 15394 sgd_solver.cpp:43] Iteration 32780, lr = 0.002
I0526 09:18:28.895159 15394 main.cpp:354] Iteration 32790, loss = 0.134454
I0526 09:18:28.895201 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.134453 (* 1 = 0.134453 loss)
I0526 09:18:28.895207 15394 sgd_solver.cpp:43] Iteration 32790, lr = 0.002
I0526 09:18:33.544109 15394 main.cpp:465] Iteration 32800, Testing net (#0)
I0526 09:18:46.623859 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8869
I0526 09:18:46.623899 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.339429 (* 1 = 0.339429 loss)
I0526 09:18:47.061584 15394 main.cpp:354] Iteration 32800, loss = 0.210094
I0526 09:18:47.061615 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.210094 (* 1 = 0.210094 loss)
I0526 09:18:47.061624 15394 sgd_solver.cpp:43] Iteration 32800, lr = 0.002
I0526 09:18:51.283063 15394 main.cpp:354] Iteration 32810, loss = 0.365925
I0526 09:18:51.283102 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.365925 (* 1 = 0.365925 loss)
I0526 09:18:51.283108 15394 sgd_solver.cpp:43] Iteration 32810, lr = 0.002
I0526 09:18:56.578158 15394 main.cpp:354] Iteration 32820, loss = 0.177744
I0526 09:18:56.578200 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.177744 (* 1 = 0.177744 loss)
I0526 09:18:56.578207 15394 sgd_solver.cpp:43] Iteration 32820, lr = 0.002
I0526 09:19:01.362117 15394 main.cpp:354] Iteration 32830, loss = 0.215571
I0526 09:19:01.362159 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.21557 (* 1 = 0.21557 loss)
I0526 09:19:01.362166 15394 sgd_solver.cpp:43] Iteration 32830, lr = 0.002
I0526 09:19:06.710325 15394 main.cpp:354] Iteration 32840, loss = 0.21306
I0526 09:19:06.710358 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.21306 (* 1 = 0.21306 loss)
I0526 09:19:06.710376 15394 sgd_solver.cpp:43] Iteration 32840, lr = 0.002
I0526 09:19:11.527408 15394 main.cpp:354] Iteration 32850, loss = 0.145134
I0526 09:19:11.527449 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.145133 (* 1 = 0.145133 loss)
I0526 09:19:11.527456 15394 sgd_solver.cpp:43] Iteration 32850, lr = 0.002
I0526 09:19:16.353664 15394 main.cpp:354] Iteration 32860, loss = 0.337414
I0526 09:19:16.353708 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.337414 (* 1 = 0.337414 loss)
I0526 09:19:16.353714 15394 sgd_solver.cpp:43] Iteration 32860, lr = 0.002
I0526 09:19:21.450057 15394 main.cpp:354] Iteration 32870, loss = 0.184414
I0526 09:19:21.450098 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.184414 (* 1 = 0.184414 loss)
I0526 09:19:21.450103 15394 sgd_solver.cpp:43] Iteration 32870, lr = 0.002
I0526 09:19:26.126157 15394 main.cpp:354] Iteration 32880, loss = 0.24373
I0526 09:19:26.126191 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.24373 (* 1 = 0.24373 loss)
I0526 09:19:26.126197 15394 sgd_solver.cpp:43] Iteration 32880, lr = 0.002
I0526 09:19:31.366379 15394 main.cpp:354] Iteration 32890, loss = 0.235545
I0526 09:19:31.366425 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235545 (* 1 = 0.235545 loss)
I0526 09:19:31.366431 15394 sgd_solver.cpp:43] Iteration 32890, lr = 0.002
I0526 09:19:36.342007 15394 main.cpp:465] Iteration 32900, Testing net (#0)
I0526 09:19:49.429494 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8743
I0526 09:19:49.429533 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.373583 (* 1 = 0.373583 loss)
I0526 09:19:49.968719 15394 main.cpp:354] Iteration 32900, loss = 0.140439
I0526 09:19:49.968755 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.140439 (* 1 = 0.140439 loss)
I0526 09:19:49.968762 15394 sgd_solver.cpp:43] Iteration 32900, lr = 0.002
I0526 09:19:55.319644 15394 main.cpp:354] Iteration 32910, loss = 0.294704
I0526 09:19:55.319685 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.294704 (* 1 = 0.294704 loss)
I0526 09:19:55.319692 15394 sgd_solver.cpp:43] Iteration 32910, lr = 0.002
I0526 09:20:00.777794 15394 main.cpp:354] Iteration 32920, loss = 0.238711
I0526 09:20:00.777840 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.238711 (* 1 = 0.238711 loss)
I0526 09:20:00.777848 15394 sgd_solver.cpp:43] Iteration 32920, lr = 0.002
I0526 09:20:05.132722 15394 main.cpp:354] Iteration 32930, loss = 0.335935
I0526 09:20:05.132763 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.335935 (* 1 = 0.335935 loss)
I0526 09:20:05.132771 15394 sgd_solver.cpp:43] Iteration 32930, lr = 0.002
I0526 09:20:09.792003 15394 main.cpp:354] Iteration 32940, loss = 0.41052
I0526 09:20:09.792045 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.41052 (* 1 = 0.41052 loss)
I0526 09:20:09.792053 15394 sgd_solver.cpp:43] Iteration 32940, lr = 0.002
I0526 09:20:14.836906 15394 main.cpp:354] Iteration 32950, loss = 0.186258
I0526 09:20:14.836948 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186257 (* 1 = 0.186257 loss)
I0526 09:20:14.836954 15394 sgd_solver.cpp:43] Iteration 32950, lr = 0.002
I0526 09:20:20.112762 15394 main.cpp:354] Iteration 32960, loss = 0.182667
I0526 09:20:20.112802 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.182667 (* 1 = 0.182667 loss)
I0526 09:20:20.112809 15394 sgd_solver.cpp:43] Iteration 32960, lr = 0.002
I0526 09:20:25.268100 15394 main.cpp:354] Iteration 32970, loss = 0.265191
I0526 09:20:25.268139 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.26519 (* 1 = 0.26519 loss)
I0526 09:20:25.268146 15394 sgd_solver.cpp:43] Iteration 32970, lr = 0.002
I0526 09:20:30.589659 15394 main.cpp:354] Iteration 32980, loss = 0.384813
I0526 09:20:30.589701 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.384813 (* 1 = 0.384813 loss)
I0526 09:20:30.589709 15394 sgd_solver.cpp:43] Iteration 32980, lr = 0.002
I0526 09:20:35.954430 15394 main.cpp:354] Iteration 32990, loss = 0.188913
I0526 09:20:35.954471 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.188913 (* 1 = 0.188913 loss)
I0526 09:20:35.954478 15394 sgd_solver.cpp:43] Iteration 32990, lr = 0.002
I0526 09:20:40.657413 15394 main.cpp:465] Iteration 33000, Testing net (#0)
I0526 09:20:53.730314 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8865
I0526 09:20:53.730360 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.335048 (* 1 = 0.335048 loss)
I0526 09:20:54.232201 15394 main.cpp:354] Iteration 33000, loss = 0.158759
I0526 09:20:54.232237 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.158758 (* 1 = 0.158758 loss)
I0526 09:20:54.232246 15394 sgd_solver.cpp:43] Iteration 33000, lr = 0.002
I0526 09:20:59.526564 15394 main.cpp:354] Iteration 33010, loss = 0.263974
I0526 09:20:59.526608 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.263974 (* 1 = 0.263974 loss)
I0526 09:20:59.526614 15394 sgd_solver.cpp:43] Iteration 33010, lr = 0.002
I0526 09:21:04.566638 15394 main.cpp:354] Iteration 33020, loss = 0.282569
I0526 09:21:04.566679 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.282569 (* 1 = 0.282569 loss)
I0526 09:21:04.566684 15394 sgd_solver.cpp:43] Iteration 33020, lr = 0.002
I0526 09:21:09.797729 15394 main.cpp:354] Iteration 33030, loss = 0.298542
I0526 09:21:09.797767 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.298542 (* 1 = 0.298542 loss)
I0526 09:21:09.797775 15394 sgd_solver.cpp:43] Iteration 33030, lr = 0.002
I0526 09:21:14.779043 15394 main.cpp:354] Iteration 33040, loss = 0.394147
I0526 09:21:14.779088 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.394147 (* 1 = 0.394147 loss)
I0526 09:21:14.779095 15394 sgd_solver.cpp:43] Iteration 33040, lr = 0.002
I0526 09:21:19.977255 15394 main.cpp:354] Iteration 33050, loss = 0.220934
I0526 09:21:19.977295 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.220933 (* 1 = 0.220933 loss)
I0526 09:21:19.977301 15394 sgd_solver.cpp:43] Iteration 33050, lr = 0.002
I0526 09:21:24.671094 15394 main.cpp:354] Iteration 33060, loss = 0.224178
I0526 09:21:24.671133 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.224178 (* 1 = 0.224178 loss)
I0526 09:21:24.671139 15394 sgd_solver.cpp:43] Iteration 33060, lr = 0.002
I0526 09:21:29.217103 15394 main.cpp:354] Iteration 33070, loss = 0.408775
I0526 09:21:29.217145 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.408775 (* 1 = 0.408775 loss)
I0526 09:21:29.217152 15394 sgd_solver.cpp:43] Iteration 33070, lr = 0.002
I0526 09:21:34.556365 15394 main.cpp:354] Iteration 33080, loss = 0.297362
I0526 09:21:34.556404 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.297362 (* 1 = 0.297362 loss)
I0526 09:21:34.556412 15394 sgd_solver.cpp:43] Iteration 33080, lr = 0.002
I0526 09:21:39.500560 15394 main.cpp:354] Iteration 33090, loss = 0.748044
I0526 09:21:39.500598 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.748043 (* 1 = 0.748043 loss)
I0526 09:21:39.500605 15394 sgd_solver.cpp:43] Iteration 33090, lr = 0.002
I0526 09:21:43.912153 15394 main.cpp:465] Iteration 33100, Testing net (#0)
I0526 09:21:56.995306 15394 main.cpp:532]     Test net output #0: Accuracy = 0.884
I0526 09:21:56.995347 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.344591 (* 1 = 0.344591 loss)
I0526 09:21:57.259724 15394 main.cpp:354] Iteration 33100, loss = 0.868899
I0526 09:21:57.259752 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.868899 (* 1 = 0.868899 loss)
I0526 09:21:57.259758 15394 sgd_solver.cpp:43] Iteration 33100, lr = 0.002
I0526 09:22:02.277305 15394 main.cpp:354] Iteration 33110, loss = 0.280104
I0526 09:22:02.277348 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.280103 (* 1 = 0.280103 loss)
I0526 09:22:02.277354 15394 sgd_solver.cpp:43] Iteration 33110, lr = 0.002
I0526 09:22:07.819461 15394 main.cpp:354] Iteration 33120, loss = 0.209477
I0526 09:22:07.819500 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.209477 (* 1 = 0.209477 loss)
I0526 09:22:07.819507 15394 sgd_solver.cpp:43] Iteration 33120, lr = 0.002
I0526 09:22:12.998632 15394 main.cpp:354] Iteration 33130, loss = 0.141333
I0526 09:22:12.998677 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.141332 (* 1 = 0.141332 loss)
I0526 09:22:12.998684 15394 sgd_solver.cpp:43] Iteration 33130, lr = 0.002
I0526 09:22:18.436283 15394 main.cpp:354] Iteration 33140, loss = 0.200209
I0526 09:22:18.436322 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.200209 (* 1 = 0.200209 loss)
I0526 09:22:18.436334 15394 sgd_solver.cpp:43] Iteration 33140, lr = 0.002
I0526 09:22:23.444774 15394 main.cpp:354] Iteration 33150, loss = 0.218617
I0526 09:22:23.444813 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.218616 (* 1 = 0.218616 loss)
I0526 09:22:23.444818 15394 sgd_solver.cpp:43] Iteration 33150, lr = 0.002
I0526 09:22:27.887691 15394 main.cpp:354] Iteration 33160, loss = 0.229949
I0526 09:22:27.887732 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.229949 (* 1 = 0.229949 loss)
I0526 09:22:27.887738 15394 sgd_solver.cpp:43] Iteration 33160, lr = 0.002
I0526 09:22:32.734598 15394 main.cpp:354] Iteration 33170, loss = 0.191714
I0526 09:22:32.734645 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.191714 (* 1 = 0.191714 loss)
I0526 09:22:32.734652 15394 sgd_solver.cpp:43] Iteration 33170, lr = 0.002
I0526 09:22:37.718741 15394 main.cpp:354] Iteration 33180, loss = 0.240438
I0526 09:22:37.718781 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.240438 (* 1 = 0.240438 loss)
I0526 09:22:37.718787 15394 sgd_solver.cpp:43] Iteration 33180, lr = 0.002
I0526 09:22:42.998229 15394 main.cpp:354] Iteration 33190, loss = 0.341287
I0526 09:22:42.998275 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.341287 (* 1 = 0.341287 loss)
I0526 09:22:42.998281 15394 sgd_solver.cpp:43] Iteration 33190, lr = 0.002
I0526 09:22:47.446578 15394 main.cpp:465] Iteration 33200, Testing net (#0)
I0526 09:23:00.527724 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8881
I0526 09:23:00.527775 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.328279 (* 1 = 0.328279 loss)
I0526 09:23:01.036006 15394 main.cpp:354] Iteration 33200, loss = 0.161744
I0526 09:23:01.036042 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.161744 (* 1 = 0.161744 loss)
I0526 09:23:01.036051 15394 sgd_solver.cpp:43] Iteration 33200, lr = 0.002
I0526 09:23:06.090646 15394 main.cpp:354] Iteration 33210, loss = 0.128838
I0526 09:23:06.090687 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.128838 (* 1 = 0.128838 loss)
I0526 09:23:06.090693 15394 sgd_solver.cpp:43] Iteration 33210, lr = 0.002
I0526 09:23:11.458756 15394 main.cpp:354] Iteration 33220, loss = 0.218306
I0526 09:23:11.458796 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.218306 (* 1 = 0.218306 loss)
I0526 09:23:11.458801 15394 sgd_solver.cpp:43] Iteration 33220, lr = 0.002
I0526 09:23:16.949089 15394 main.cpp:354] Iteration 33230, loss = 0.336051
I0526 09:23:16.949131 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.336051 (* 1 = 0.336051 loss)
I0526 09:23:16.949136 15394 sgd_solver.cpp:43] Iteration 33230, lr = 0.002
I0526 09:23:21.983315 15394 main.cpp:354] Iteration 33240, loss = 0.144418
I0526 09:23:21.983355 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.144418 (* 1 = 0.144418 loss)
I0526 09:23:21.983361 15394 sgd_solver.cpp:43] Iteration 33240, lr = 0.002
I0526 09:23:27.073953 15394 main.cpp:354] Iteration 33250, loss = 0.241577
I0526 09:23:27.073994 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.241577 (* 1 = 0.241577 loss)
I0526 09:23:27.074002 15394 sgd_solver.cpp:43] Iteration 33250, lr = 0.002
I0526 09:23:31.782541 15394 main.cpp:354] Iteration 33260, loss = 0.269514
I0526 09:23:31.782572 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.269514 (* 1 = 0.269514 loss)
I0526 09:23:31.782578 15394 sgd_solver.cpp:43] Iteration 33260, lr = 0.002
I0526 09:23:36.851488 15394 main.cpp:354] Iteration 33270, loss = 0.298399
I0526 09:23:36.851527 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.298399 (* 1 = 0.298399 loss)
I0526 09:23:36.851533 15394 sgd_solver.cpp:43] Iteration 33270, lr = 0.002
I0526 09:23:41.674440 15394 main.cpp:354] Iteration 33280, loss = 0.816173
I0526 09:23:41.674479 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.816173 (* 1 = 0.816173 loss)
I0526 09:23:41.674484 15394 sgd_solver.cpp:43] Iteration 33280, lr = 0.002
I0526 09:23:46.655206 15394 main.cpp:354] Iteration 33290, loss = 0.15776
I0526 09:23:46.655249 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.15776 (* 1 = 0.15776 loss)
I0526 09:23:46.655256 15394 sgd_solver.cpp:43] Iteration 33290, lr = 0.002
I0526 09:23:51.357453 15394 main.cpp:465] Iteration 33300, Testing net (#0)
I0526 09:24:04.440291 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8812
I0526 09:24:04.440331 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.350023 (* 1 = 0.350023 loss)
I0526 09:24:04.811303 15394 main.cpp:354] Iteration 33300, loss = 0.278499
I0526 09:24:04.811349 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.278499 (* 1 = 0.278499 loss)
I0526 09:24:04.811357 15394 sgd_solver.cpp:43] Iteration 33300, lr = 0.002
I0526 09:24:09.431972 15394 main.cpp:354] Iteration 33310, loss = 0.31898
I0526 09:24:09.432008 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.318979 (* 1 = 0.318979 loss)
I0526 09:24:09.432014 15394 sgd_solver.cpp:43] Iteration 33310, lr = 0.002
I0526 09:24:14.153091 15394 main.cpp:354] Iteration 33320, loss = 0.384768
I0526 09:24:14.153136 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.384768 (* 1 = 0.384768 loss)
I0526 09:24:14.153141 15394 sgd_solver.cpp:43] Iteration 33320, lr = 0.002
I0526 09:24:19.089731 15394 main.cpp:354] Iteration 33330, loss = 0.253716
I0526 09:24:19.089771 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.253716 (* 1 = 0.253716 loss)
I0526 09:24:19.089777 15394 sgd_solver.cpp:43] Iteration 33330, lr = 0.002
I0526 09:24:24.507216 15394 main.cpp:354] Iteration 33340, loss = 0.236381
I0526 09:24:24.507254 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.236381 (* 1 = 0.236381 loss)
I0526 09:24:24.507261 15394 sgd_solver.cpp:43] Iteration 33340, lr = 0.002
I0526 09:24:29.308770 15394 main.cpp:354] Iteration 33350, loss = 0.208634
I0526 09:24:29.308814 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.208634 (* 1 = 0.208634 loss)
I0526 09:24:29.308820 15394 sgd_solver.cpp:43] Iteration 33350, lr = 0.002
I0526 09:24:34.840297 15394 main.cpp:354] Iteration 33360, loss = 0.289376
I0526 09:24:34.840329 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.289376 (* 1 = 0.289376 loss)
I0526 09:24:34.840335 15394 sgd_solver.cpp:43] Iteration 33360, lr = 0.002
I0526 09:24:39.668170 15394 main.cpp:354] Iteration 33370, loss = 0.255842
I0526 09:24:39.668208 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.255842 (* 1 = 0.255842 loss)
I0526 09:24:39.668215 15394 sgd_solver.cpp:43] Iteration 33370, lr = 0.002
I0526 09:24:44.621222 15394 main.cpp:354] Iteration 33380, loss = 0.204943
I0526 09:24:44.621266 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204943 (* 1 = 0.204943 loss)
I0526 09:24:44.621273 15394 sgd_solver.cpp:43] Iteration 33380, lr = 0.002
I0526 09:24:49.778497 15394 main.cpp:354] Iteration 33390, loss = 0.394483
I0526 09:24:49.778537 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.394483 (* 1 = 0.394483 loss)
I0526 09:24:49.778543 15394 sgd_solver.cpp:43] Iteration 33390, lr = 0.002
I0526 09:24:54.409065 15394 main.cpp:465] Iteration 33400, Testing net (#0)
I0526 09:25:07.497267 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8913
I0526 09:25:07.497309 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.326552 (* 1 = 0.326552 loss)
I0526 09:25:07.890748 15394 main.cpp:354] Iteration 33400, loss = 0.565018
I0526 09:25:07.890775 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.565017 (* 1 = 0.565017 loss)
I0526 09:25:07.890784 15394 sgd_solver.cpp:43] Iteration 33400, lr = 0.002
I0526 09:25:13.038590 15394 main.cpp:354] Iteration 33410, loss = 0.416952
I0526 09:25:13.038633 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.416952 (* 1 = 0.416952 loss)
I0526 09:25:13.038641 15394 sgd_solver.cpp:43] Iteration 33410, lr = 0.002
I0526 09:25:18.278444 15394 main.cpp:354] Iteration 33420, loss = 0.199619
I0526 09:25:18.278491 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.199619 (* 1 = 0.199619 loss)
I0526 09:25:18.278497 15394 sgd_solver.cpp:43] Iteration 33420, lr = 0.002
I0526 09:25:23.292373 15394 main.cpp:354] Iteration 33430, loss = 0.206045
I0526 09:25:23.292415 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206045 (* 1 = 0.206045 loss)
I0526 09:25:23.292423 15394 sgd_solver.cpp:43] Iteration 33430, lr = 0.002
I0526 09:25:27.836216 15394 main.cpp:354] Iteration 33440, loss = 0.325362
I0526 09:25:27.836256 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.325362 (* 1 = 0.325362 loss)
I0526 09:25:27.836261 15394 sgd_solver.cpp:43] Iteration 33440, lr = 0.002
I0526 09:25:32.573197 15394 main.cpp:354] Iteration 33450, loss = 0.196684
I0526 09:25:32.573240 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.196684 (* 1 = 0.196684 loss)
I0526 09:25:32.573247 15394 sgd_solver.cpp:43] Iteration 33450, lr = 0.002
I0526 09:25:37.874533 15394 main.cpp:354] Iteration 33460, loss = 0.227577
I0526 09:25:37.874562 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.227577 (* 1 = 0.227577 loss)
I0526 09:25:37.874567 15394 sgd_solver.cpp:43] Iteration 33460, lr = 0.002
I0526 09:25:43.129292 15394 main.cpp:354] Iteration 33470, loss = 0.247284
I0526 09:25:43.129336 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.247284 (* 1 = 0.247284 loss)
I0526 09:25:43.129343 15394 sgd_solver.cpp:43] Iteration 33470, lr = 0.002
I0526 09:25:48.655825 15394 main.cpp:354] Iteration 33480, loss = 0.232423
I0526 09:25:48.655865 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.232423 (* 1 = 0.232423 loss)
I0526 09:25:48.655871 15394 sgd_solver.cpp:43] Iteration 33480, lr = 0.002
I0526 09:25:54.123052 15394 main.cpp:354] Iteration 33490, loss = 0.35787
I0526 09:25:54.123092 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.357869 (* 1 = 0.357869 loss)
I0526 09:25:54.123100 15394 sgd_solver.cpp:43] Iteration 33490, lr = 0.002
I0526 09:25:58.539005 15394 main.cpp:465] Iteration 33500, Testing net (#0)
I0526 09:26:11.621140 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8888
I0526 09:26:11.621178 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.338097 (* 1 = 0.338097 loss)
I0526 09:26:12.086536 15394 main.cpp:354] Iteration 33500, loss = 0.269779
I0526 09:26:12.086573 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.269779 (* 1 = 0.269779 loss)
I0526 09:26:12.086580 15394 sgd_solver.cpp:43] Iteration 33500, lr = 0.002
I0526 09:26:17.312152 15394 main.cpp:354] Iteration 33510, loss = 0.237497
I0526 09:26:17.312196 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.237497 (* 1 = 0.237497 loss)
I0526 09:26:17.312201 15394 sgd_solver.cpp:43] Iteration 33510, lr = 0.002
I0526 09:26:22.208225 15394 main.cpp:354] Iteration 33520, loss = 0.310449
I0526 09:26:22.208250 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.310449 (* 1 = 0.310449 loss)
I0526 09:26:22.208256 15394 sgd_solver.cpp:43] Iteration 33520, lr = 0.002
I0526 09:26:27.534415 15394 main.cpp:354] Iteration 33530, loss = 0.273103
I0526 09:26:27.534445 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.273103 (* 1 = 0.273103 loss)
I0526 09:26:27.534451 15394 sgd_solver.cpp:43] Iteration 33530, lr = 0.002
I0526 09:26:32.421596 15394 main.cpp:354] Iteration 33540, loss = 0.316468
I0526 09:26:32.421641 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.316468 (* 1 = 0.316468 loss)
I0526 09:26:32.421651 15394 sgd_solver.cpp:43] Iteration 33540, lr = 0.002
I0526 09:26:37.945017 15394 main.cpp:354] Iteration 33550, loss = 0.207314
I0526 09:26:37.945060 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.207314 (* 1 = 0.207314 loss)
I0526 09:26:37.945066 15394 sgd_solver.cpp:43] Iteration 33550, lr = 0.002
I0526 09:26:43.148860 15394 main.cpp:354] Iteration 33560, loss = 0.117969
I0526 09:26:43.148905 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.117969 (* 1 = 0.117969 loss)
I0526 09:26:43.148916 15394 sgd_solver.cpp:43] Iteration 33560, lr = 0.002
I0526 09:26:47.999049 15394 main.cpp:354] Iteration 33570, loss = 0.332263
I0526 09:26:47.999089 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.332263 (* 1 = 0.332263 loss)
I0526 09:26:47.999095 15394 sgd_solver.cpp:43] Iteration 33570, lr = 0.002
I0526 09:26:53.178427 15394 main.cpp:354] Iteration 33580, loss = 0.158987
I0526 09:26:53.178469 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.158986 (* 1 = 0.158986 loss)
I0526 09:26:53.178477 15394 sgd_solver.cpp:43] Iteration 33580, lr = 0.002
I0526 09:26:58.541254 15394 main.cpp:354] Iteration 33590, loss = 0.18462
I0526 09:26:58.541292 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.18462 (* 1 = 0.18462 loss)
I0526 09:26:58.541299 15394 sgd_solver.cpp:43] Iteration 33590, lr = 0.002
I0526 09:27:03.379595 15394 main.cpp:465] Iteration 33600, Testing net (#0)
I0526 09:27:16.472112 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8883
I0526 09:27:16.472156 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.332741 (* 1 = 0.332741 loss)
I0526 09:27:16.938061 15394 main.cpp:354] Iteration 33600, loss = 0.26209
I0526 09:27:16.938099 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.262089 (* 1 = 0.262089 loss)
I0526 09:27:16.938107 15394 sgd_solver.cpp:43] Iteration 33600, lr = 0.002
I0526 09:27:21.924973 15394 main.cpp:354] Iteration 33610, loss = 0.520308
I0526 09:27:21.925012 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.520308 (* 1 = 0.520308 loss)
I0526 09:27:21.925019 15394 sgd_solver.cpp:43] Iteration 33610, lr = 0.002
I0526 09:27:27.142575 15394 main.cpp:354] Iteration 33620, loss = 0.269624
I0526 09:27:27.142614 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.269624 (* 1 = 0.269624 loss)
I0526 09:27:27.142621 15394 sgd_solver.cpp:43] Iteration 33620, lr = 0.002
I0526 09:27:32.468737 15394 main.cpp:354] Iteration 33630, loss = 0.289741
I0526 09:27:32.468778 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.289741 (* 1 = 0.289741 loss)
I0526 09:27:32.468786 15394 sgd_solver.cpp:43] Iteration 33630, lr = 0.002
I0526 09:27:37.427568 15394 main.cpp:354] Iteration 33640, loss = 0.169337
I0526 09:27:37.427608 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.169337 (* 1 = 0.169337 loss)
I0526 09:27:37.427614 15394 sgd_solver.cpp:43] Iteration 33640, lr = 0.002
I0526 09:27:42.607306 15394 main.cpp:354] Iteration 33650, loss = 0.267935
I0526 09:27:42.607343 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.267935 (* 1 = 0.267935 loss)
I0526 09:27:42.607349 15394 sgd_solver.cpp:43] Iteration 33650, lr = 0.002
I0526 09:27:47.101207 15394 main.cpp:354] Iteration 33660, loss = 0.382988
I0526 09:27:47.101254 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.382988 (* 1 = 0.382988 loss)
I0526 09:27:47.101261 15394 sgd_solver.cpp:43] Iteration 33660, lr = 0.002
I0526 09:27:52.120697 15394 main.cpp:354] Iteration 33670, loss = 0.266885
I0526 09:27:52.120736 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.266885 (* 1 = 0.266885 loss)
I0526 09:27:52.120743 15394 sgd_solver.cpp:43] Iteration 33670, lr = 0.002
I0526 09:27:57.338527 15394 main.cpp:354] Iteration 33680, loss = 0.263986
I0526 09:27:57.338579 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.263986 (* 1 = 0.263986 loss)
I0526 09:27:57.338587 15394 sgd_solver.cpp:43] Iteration 33680, lr = 0.002
I0526 09:28:02.687201 15394 main.cpp:354] Iteration 33690, loss = 0.22346
I0526 09:28:02.687247 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.22346 (* 1 = 0.22346 loss)
I0526 09:28:02.687252 15394 sgd_solver.cpp:43] Iteration 33690, lr = 0.002
I0526 09:28:06.957412 15394 main.cpp:465] Iteration 33700, Testing net (#0)
I0526 09:28:20.042105 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8827
I0526 09:28:20.042146 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.350791 (* 1 = 0.350791 loss)
I0526 09:28:20.514058 15394 main.cpp:354] Iteration 33700, loss = 0.285225
I0526 09:28:20.514089 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.285225 (* 1 = 0.285225 loss)
I0526 09:28:20.514097 15394 sgd_solver.cpp:43] Iteration 33700, lr = 0.002
I0526 09:28:25.503633 15394 main.cpp:354] Iteration 33710, loss = 0.815705
I0526 09:28:25.503674 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.815705 (* 1 = 0.815705 loss)
I0526 09:28:25.503680 15394 sgd_solver.cpp:43] Iteration 33710, lr = 0.002
I0526 09:28:30.080088 15394 main.cpp:354] Iteration 33720, loss = 0.251281
I0526 09:28:30.080135 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.25128 (* 1 = 0.25128 loss)
I0526 09:28:30.080142 15394 sgd_solver.cpp:43] Iteration 33720, lr = 0.002
I0526 09:28:35.514008 15394 main.cpp:354] Iteration 33730, loss = 0.382326
I0526 09:28:35.514046 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.382326 (* 1 = 0.382326 loss)
I0526 09:28:35.514052 15394 sgd_solver.cpp:43] Iteration 33730, lr = 0.002
I0526 09:28:40.276399 15394 main.cpp:354] Iteration 33740, loss = 0.46986
I0526 09:28:40.276438 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.46986 (* 1 = 0.46986 loss)
I0526 09:28:40.276445 15394 sgd_solver.cpp:43] Iteration 33740, lr = 0.002
I0526 09:28:45.232698 15394 main.cpp:354] Iteration 33750, loss = 0.388793
I0526 09:28:45.232743 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.388793 (* 1 = 0.388793 loss)
I0526 09:28:45.232748 15394 sgd_solver.cpp:43] Iteration 33750, lr = 0.002
I0526 09:28:49.901087 15394 main.cpp:354] Iteration 33760, loss = 0.455911
I0526 09:28:49.901125 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.455911 (* 1 = 0.455911 loss)
I0526 09:28:49.901131 15394 sgd_solver.cpp:43] Iteration 33760, lr = 0.002
I0526 09:28:55.060030 15394 main.cpp:354] Iteration 33770, loss = 0.250573
I0526 09:28:55.060070 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.250573 (* 1 = 0.250573 loss)
I0526 09:28:55.060075 15394 sgd_solver.cpp:43] Iteration 33770, lr = 0.002
I0526 09:29:00.688377 15394 main.cpp:354] Iteration 33780, loss = 0.232811
I0526 09:29:00.688422 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.23281 (* 1 = 0.23281 loss)
I0526 09:29:00.688429 15394 sgd_solver.cpp:43] Iteration 33780, lr = 0.002
I0526 09:29:05.748874 15394 main.cpp:354] Iteration 33790, loss = 0.289202
I0526 09:29:05.748914 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.289202 (* 1 = 0.289202 loss)
I0526 09:29:05.748920 15394 sgd_solver.cpp:43] Iteration 33790, lr = 0.002
I0526 09:29:09.955760 15394 main.cpp:465] Iteration 33800, Testing net (#0)
I0526 09:29:23.047423 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8876
I0526 09:29:23.047464 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.331563 (* 1 = 0.331563 loss)
I0526 09:29:23.484886 15394 main.cpp:354] Iteration 33800, loss = 0.194285
I0526 09:29:23.484917 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.194285 (* 1 = 0.194285 loss)
I0526 09:29:23.484925 15394 sgd_solver.cpp:43] Iteration 33800, lr = 0.002
I0526 09:29:28.330219 15394 main.cpp:354] Iteration 33810, loss = 0.216218
I0526 09:29:28.330261 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.216217 (* 1 = 0.216217 loss)
I0526 09:29:28.330270 15394 sgd_solver.cpp:43] Iteration 33810, lr = 0.002
I0526 09:29:33.072901 15394 main.cpp:354] Iteration 33820, loss = 0.376549
I0526 09:29:33.072943 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.376549 (* 1 = 0.376549 loss)
I0526 09:29:33.072949 15394 sgd_solver.cpp:43] Iteration 33820, lr = 0.002
I0526 09:29:38.380547 15394 main.cpp:354] Iteration 33830, loss = 0.194571
I0526 09:29:38.380586 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.194571 (* 1 = 0.194571 loss)
I0526 09:29:38.380592 15394 sgd_solver.cpp:43] Iteration 33830, lr = 0.002
I0526 09:29:43.763253 15394 main.cpp:354] Iteration 33840, loss = 0.246525
I0526 09:29:43.763280 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.246525 (* 1 = 0.246525 loss)
I0526 09:29:43.763286 15394 sgd_solver.cpp:43] Iteration 33840, lr = 0.002
I0526 09:29:48.824987 15394 main.cpp:354] Iteration 33850, loss = 0.484392
I0526 09:29:48.825027 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.484392 (* 1 = 0.484392 loss)
I0526 09:29:48.825034 15394 sgd_solver.cpp:43] Iteration 33850, lr = 0.002
I0526 09:29:53.743742 15394 main.cpp:354] Iteration 33860, loss = 0.19738
I0526 09:29:53.743782 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.19738 (* 1 = 0.19738 loss)
I0526 09:29:53.743788 15394 sgd_solver.cpp:43] Iteration 33860, lr = 0.002
I0526 09:29:59.062445 15394 main.cpp:354] Iteration 33870, loss = 0.196326
I0526 09:29:59.062490 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.196326 (* 1 = 0.196326 loss)
I0526 09:29:59.062497 15394 sgd_solver.cpp:43] Iteration 33870, lr = 0.002
I0526 09:30:04.300264 15394 main.cpp:354] Iteration 33880, loss = 0.248233
I0526 09:30:04.300305 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.248233 (* 1 = 0.248233 loss)
I0526 09:30:04.300312 15394 sgd_solver.cpp:43] Iteration 33880, lr = 0.002
I0526 09:30:09.479368 15394 main.cpp:354] Iteration 33890, loss = 0.26594
I0526 09:30:09.479409 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.26594 (* 1 = 0.26594 loss)
I0526 09:30:09.479415 15394 sgd_solver.cpp:43] Iteration 33890, lr = 0.002
I0526 09:30:14.175637 15394 main.cpp:465] Iteration 33900, Testing net (#0)
I0526 09:30:27.258327 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8912
I0526 09:30:27.258379 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.32957 (* 1 = 0.32957 loss)
I0526 09:30:27.797144 15394 main.cpp:354] Iteration 33900, loss = 0.215308
I0526 09:30:27.797175 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.215308 (* 1 = 0.215308 loss)
I0526 09:30:27.797183 15394 sgd_solver.cpp:43] Iteration 33900, lr = 0.002
I0526 09:30:33.067178 15394 main.cpp:354] Iteration 33910, loss = 0.206794
I0526 09:30:33.067220 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206794 (* 1 = 0.206794 loss)
I0526 09:30:33.067226 15394 sgd_solver.cpp:43] Iteration 33910, lr = 0.002
I0526 09:30:37.961577 15394 main.cpp:354] Iteration 33920, loss = 0.149967
I0526 09:30:37.961618 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.149967 (* 1 = 0.149967 loss)
I0526 09:30:37.961624 15394 sgd_solver.cpp:43] Iteration 33920, lr = 0.002
I0526 09:30:43.020293 15394 main.cpp:354] Iteration 33930, loss = 0.237921
I0526 09:30:43.020340 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.237921 (* 1 = 0.237921 loss)
I0526 09:30:43.020349 15394 sgd_solver.cpp:43] Iteration 33930, lr = 0.002
I0526 09:30:47.395548 15394 main.cpp:354] Iteration 33940, loss = 0.311754
I0526 09:30:47.395586 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.311753 (* 1 = 0.311753 loss)
I0526 09:30:47.395592 15394 sgd_solver.cpp:43] Iteration 33940, lr = 0.002
I0526 09:30:52.574816 15394 main.cpp:354] Iteration 33950, loss = 0.202077
I0526 09:30:52.574857 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.202076 (* 1 = 0.202076 loss)
I0526 09:30:52.574864 15394 sgd_solver.cpp:43] Iteration 33950, lr = 0.002
I0526 09:30:57.864449 15394 main.cpp:354] Iteration 33960, loss = 0.155308
I0526 09:30:57.864487 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.155308 (* 1 = 0.155308 loss)
I0526 09:30:57.864493 15394 sgd_solver.cpp:43] Iteration 33960, lr = 0.002
I0526 09:31:03.118010 15394 main.cpp:354] Iteration 33970, loss = 0.217346
I0526 09:31:03.118052 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.217346 (* 1 = 0.217346 loss)
I0526 09:31:03.118058 15394 sgd_solver.cpp:43] Iteration 33970, lr = 0.002
I0526 09:31:08.436728 15394 main.cpp:354] Iteration 33980, loss = 0.309189
I0526 09:31:08.436769 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.309189 (* 1 = 0.309189 loss)
I0526 09:31:08.436780 15394 sgd_solver.cpp:43] Iteration 33980, lr = 0.002
I0526 09:31:12.967382 15394 main.cpp:354] Iteration 33990, loss = 0.294062
I0526 09:31:12.967420 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.294062 (* 1 = 0.294062 loss)
I0526 09:31:12.967427 15394 sgd_solver.cpp:43] Iteration 33990, lr = 0.002
I0526 09:31:17.088665 15394 main.cpp:465] Iteration 34000, Testing net (#0)
I0526 09:31:30.178220 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8923
I0526 09:31:30.178261 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.333458 (* 1 = 0.333458 loss)
I0526 09:31:30.607794 15394 main.cpp:354] Iteration 34000, loss = 0.298268
I0526 09:31:30.607831 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.298268 (* 1 = 0.298268 loss)
I0526 09:31:30.607839 15394 sgd_solver.cpp:43] Iteration 34000, lr = 0.002
I0526 09:31:35.199770 15394 main.cpp:354] Iteration 34010, loss = 0.282062
I0526 09:31:35.199810 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.282061 (* 1 = 0.282061 loss)
I0526 09:31:35.199816 15394 sgd_solver.cpp:43] Iteration 34010, lr = 0.002
I0526 09:31:40.342383 15394 main.cpp:354] Iteration 34020, loss = 0.280026
I0526 09:31:40.342423 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.280026 (* 1 = 0.280026 loss)
I0526 09:31:40.342430 15394 sgd_solver.cpp:43] Iteration 34020, lr = 0.002
I0526 09:31:45.687072 15394 main.cpp:354] Iteration 34030, loss = 0.144423
I0526 09:31:45.687115 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.144423 (* 1 = 0.144423 loss)
I0526 09:31:45.687121 15394 sgd_solver.cpp:43] Iteration 34030, lr = 0.002
I0526 09:31:50.817085 15394 main.cpp:354] Iteration 34040, loss = 0.264114
I0526 09:31:50.817124 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.264113 (* 1 = 0.264113 loss)
I0526 09:31:50.817131 15394 sgd_solver.cpp:43] Iteration 34040, lr = 0.002
I0526 09:31:56.191923 15394 main.cpp:354] Iteration 34050, loss = 0.128109
I0526 09:31:56.191965 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.128108 (* 1 = 0.128108 loss)
I0526 09:31:56.191972 15394 sgd_solver.cpp:43] Iteration 34050, lr = 0.002
I0526 09:32:01.268496 15394 main.cpp:354] Iteration 34060, loss = 0.167138
I0526 09:32:01.268539 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.167137 (* 1 = 0.167137 loss)
I0526 09:32:01.268545 15394 sgd_solver.cpp:43] Iteration 34060, lr = 0.002
I0526 09:32:06.349050 15394 main.cpp:354] Iteration 34070, loss = 0.179569
I0526 09:32:06.349089 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.179568 (* 1 = 0.179568 loss)
I0526 09:32:06.349095 15394 sgd_solver.cpp:43] Iteration 34070, lr = 0.002
I0526 09:32:11.268728 15394 main.cpp:354] Iteration 34080, loss = 0.438275
I0526 09:32:11.268766 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.438275 (* 1 = 0.438275 loss)
I0526 09:32:11.268772 15394 sgd_solver.cpp:43] Iteration 34080, lr = 0.002
I0526 09:32:17.005692 15394 main.cpp:354] Iteration 34090, loss = 0.246678
I0526 09:32:17.005734 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.246678 (* 1 = 0.246678 loss)
I0526 09:32:17.005740 15394 sgd_solver.cpp:43] Iteration 34090, lr = 0.002
I0526 09:32:21.628029 15394 main.cpp:465] Iteration 34100, Testing net (#0)
I0526 09:32:34.723456 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8895
I0526 09:32:34.723512 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.337198 (* 1 = 0.337198 loss)
I0526 09:32:35.123407 15394 main.cpp:354] Iteration 34100, loss = 0.460355
I0526 09:32:35.123456 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.460354 (* 1 = 0.460354 loss)
I0526 09:32:35.123466 15394 sgd_solver.cpp:43] Iteration 34100, lr = 0.002
I0526 09:32:40.192556 15394 main.cpp:354] Iteration 34110, loss = 0.410685
I0526 09:32:40.192601 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.410685 (* 1 = 0.410685 loss)
I0526 09:32:40.192615 15394 sgd_solver.cpp:43] Iteration 34110, lr = 0.002
I0526 09:32:44.808229 15394 main.cpp:354] Iteration 34120, loss = 0.162849
I0526 09:32:44.808272 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.162848 (* 1 = 0.162848 loss)
I0526 09:32:44.808280 15394 sgd_solver.cpp:43] Iteration 34120, lr = 0.002
I0526 09:32:50.294483 15394 main.cpp:354] Iteration 34130, loss = 0.250515
I0526 09:32:50.294524 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.250515 (* 1 = 0.250515 loss)
I0526 09:32:50.294531 15394 sgd_solver.cpp:43] Iteration 34130, lr = 0.002
I0526 09:32:55.470433 15394 main.cpp:354] Iteration 34140, loss = 0.222035
I0526 09:32:55.470474 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.222034 (* 1 = 0.222034 loss)
I0526 09:32:55.470481 15394 sgd_solver.cpp:43] Iteration 34140, lr = 0.002
I0526 09:33:00.214970 15394 main.cpp:354] Iteration 34150, loss = 0.306132
I0526 09:33:00.215013 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.306132 (* 1 = 0.306132 loss)
I0526 09:33:00.215018 15394 sgd_solver.cpp:43] Iteration 34150, lr = 0.002
I0526 09:33:05.146456 15394 main.cpp:354] Iteration 34160, loss = 0.14189
I0526 09:33:05.146494 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.14189 (* 1 = 0.14189 loss)
I0526 09:33:05.146502 15394 sgd_solver.cpp:43] Iteration 34160, lr = 0.002
I0526 09:33:10.408749 15394 main.cpp:354] Iteration 34170, loss = 0.294362
I0526 09:33:10.408800 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.294362 (* 1 = 0.294362 loss)
I0526 09:33:10.408807 15394 sgd_solver.cpp:43] Iteration 34170, lr = 0.002
I0526 09:33:15.618113 15394 main.cpp:354] Iteration 34180, loss = 0.190967
I0526 09:33:15.618155 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.190967 (* 1 = 0.190967 loss)
I0526 09:33:15.618161 15394 sgd_solver.cpp:43] Iteration 34180, lr = 0.002
I0526 09:33:20.711983 15394 main.cpp:354] Iteration 34190, loss = 0.323548
I0526 09:33:20.712021 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.323548 (* 1 = 0.323548 loss)
I0526 09:33:20.712028 15394 sgd_solver.cpp:43] Iteration 34190, lr = 0.002
I0526 09:33:25.168751 15394 main.cpp:465] Iteration 34200, Testing net (#0)
I0526 09:33:38.247474 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8904
I0526 09:33:38.247512 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.338798 (* 1 = 0.338798 loss)
I0526 09:33:38.653692 15394 main.cpp:354] Iteration 34200, loss = 0.43881
I0526 09:33:38.653729 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.438809 (* 1 = 0.438809 loss)
I0526 09:33:38.653738 15394 sgd_solver.cpp:43] Iteration 34200, lr = 0.002
I0526 09:33:43.337685 15394 main.cpp:354] Iteration 34210, loss = 0.248614
I0526 09:33:43.337714 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.248613 (* 1 = 0.248613 loss)
I0526 09:33:43.337721 15394 sgd_solver.cpp:43] Iteration 34210, lr = 0.002
I0526 09:33:48.423332 15394 main.cpp:354] Iteration 34220, loss = 0.167865
I0526 09:33:48.423370 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.167865 (* 1 = 0.167865 loss)
I0526 09:33:48.423377 15394 sgd_solver.cpp:43] Iteration 34220, lr = 0.002
I0526 09:33:53.443524 15394 main.cpp:354] Iteration 34230, loss = 0.275891
I0526 09:33:53.443562 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.27589 (* 1 = 0.27589 loss)
I0526 09:33:53.443567 15394 sgd_solver.cpp:43] Iteration 34230, lr = 0.002
I0526 09:33:58.324853 15394 main.cpp:354] Iteration 34240, loss = 0.425698
I0526 09:33:58.324893 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.425698 (* 1 = 0.425698 loss)
I0526 09:33:58.324900 15394 sgd_solver.cpp:43] Iteration 34240, lr = 0.002
I0526 09:34:03.363373 15394 main.cpp:354] Iteration 34250, loss = 0.232529
I0526 09:34:03.363411 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.232529 (* 1 = 0.232529 loss)
I0526 09:34:03.363418 15394 sgd_solver.cpp:43] Iteration 34250, lr = 0.002
I0526 09:34:08.533650 15394 main.cpp:354] Iteration 34260, loss = 0.281737
I0526 09:34:08.533689 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.281737 (* 1 = 0.281737 loss)
I0526 09:34:08.533695 15394 sgd_solver.cpp:43] Iteration 34260, lr = 0.002
I0526 09:34:13.235450 15394 main.cpp:354] Iteration 34270, loss = 0.148354
I0526 09:34:13.235493 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.148353 (* 1 = 0.148353 loss)
I0526 09:34:13.235502 15394 sgd_solver.cpp:43] Iteration 34270, lr = 0.002
I0526 09:34:17.975039 15394 main.cpp:354] Iteration 34280, loss = 0.360422
I0526 09:34:17.975080 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.360422 (* 1 = 0.360422 loss)
I0526 09:34:17.975086 15394 sgd_solver.cpp:43] Iteration 34280, lr = 0.002
I0526 09:34:22.745416 15394 main.cpp:354] Iteration 34290, loss = 0.111727
I0526 09:34:22.745456 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.111727 (* 1 = 0.111727 loss)
I0526 09:34:22.745462 15394 sgd_solver.cpp:43] Iteration 34290, lr = 0.002
I0526 09:34:27.708057 15394 main.cpp:465] Iteration 34300, Testing net (#0)
I0526 09:34:40.795699 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8897
I0526 09:34:40.795739 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.337756 (* 1 = 0.337756 loss)
I0526 09:34:41.262140 15394 main.cpp:354] Iteration 34300, loss = 0.29327
I0526 09:34:41.262176 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.29327 (* 1 = 0.29327 loss)
I0526 09:34:41.262183 15394 sgd_solver.cpp:43] Iteration 34300, lr = 0.002
I0526 09:34:46.215914 15394 main.cpp:354] Iteration 34310, loss = 0.275294
I0526 09:34:46.215957 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.275294 (* 1 = 0.275294 loss)
I0526 09:34:46.215963 15394 sgd_solver.cpp:43] Iteration 34310, lr = 0.002
I0526 09:34:51.128957 15394 main.cpp:354] Iteration 34320, loss = 0.249871
I0526 09:34:51.128993 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.249871 (* 1 = 0.249871 loss)
I0526 09:34:51.129000 15394 sgd_solver.cpp:43] Iteration 34320, lr = 0.002
I0526 09:34:56.078858 15394 main.cpp:354] Iteration 34330, loss = 0.251626
I0526 09:34:56.078901 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.251626 (* 1 = 0.251626 loss)
I0526 09:34:56.078907 15394 sgd_solver.cpp:43] Iteration 34330, lr = 0.002
I0526 09:35:01.233613 15394 main.cpp:354] Iteration 34340, loss = 0.139631
I0526 09:35:01.233654 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.13963 (* 1 = 0.13963 loss)
I0526 09:35:01.233660 15394 sgd_solver.cpp:43] Iteration 34340, lr = 0.002
I0526 09:35:06.584769 15394 main.cpp:354] Iteration 34350, loss = 0.223464
I0526 09:35:06.584806 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.223464 (* 1 = 0.223464 loss)
I0526 09:35:06.584812 15394 sgd_solver.cpp:43] Iteration 34350, lr = 0.002
I0526 09:35:11.251000 15394 main.cpp:354] Iteration 34360, loss = 0.25582
I0526 09:35:11.251039 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.25582 (* 1 = 0.25582 loss)
I0526 09:35:11.251046 15394 sgd_solver.cpp:43] Iteration 34360, lr = 0.002
I0526 09:35:16.029667 15394 main.cpp:354] Iteration 34370, loss = 0.286061
I0526 09:35:16.029712 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.286061 (* 1 = 0.286061 loss)
I0526 09:35:16.029719 15394 sgd_solver.cpp:43] Iteration 34370, lr = 0.002
I0526 09:35:20.783617 15394 main.cpp:354] Iteration 34380, loss = 0.277735
I0526 09:35:20.783656 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.277735 (* 1 = 0.277735 loss)
I0526 09:35:20.783663 15394 sgd_solver.cpp:43] Iteration 34380, lr = 0.002
I0526 09:35:26.149195 15394 main.cpp:354] Iteration 34390, loss = 0.188851
I0526 09:35:26.149236 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.188851 (* 1 = 0.188851 loss)
I0526 09:35:26.149245 15394 sgd_solver.cpp:43] Iteration 34390, lr = 0.002
I0526 09:35:30.818910 15394 main.cpp:465] Iteration 34400, Testing net (#0)
I0526 09:35:43.908354 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8882
I0526 09:35:43.908395 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.339152 (* 1 = 0.339152 loss)
I0526 09:35:44.447724 15394 main.cpp:354] Iteration 34400, loss = 0.124085
I0526 09:35:44.447756 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.124085 (* 1 = 0.124085 loss)
I0526 09:35:44.447763 15394 sgd_solver.cpp:43] Iteration 34400, lr = 0.002
I0526 09:35:49.309902 15394 main.cpp:354] Iteration 34410, loss = 0.224011
I0526 09:35:49.309943 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.224011 (* 1 = 0.224011 loss)
I0526 09:35:49.309950 15394 sgd_solver.cpp:43] Iteration 34410, lr = 0.002
I0526 09:35:54.689539 15394 main.cpp:354] Iteration 34420, loss = 0.34183
I0526 09:35:54.689577 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.34183 (* 1 = 0.34183 loss)
I0526 09:35:54.689584 15394 sgd_solver.cpp:43] Iteration 34420, lr = 0.002
I0526 09:35:59.499447 15394 main.cpp:354] Iteration 34430, loss = 0.38487
I0526 09:35:59.499491 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.384869 (* 1 = 0.384869 loss)
I0526 09:35:59.499498 15394 sgd_solver.cpp:43] Iteration 34430, lr = 0.002
I0526 09:36:04.350256 15394 main.cpp:354] Iteration 34440, loss = 0.260606
I0526 09:36:04.350296 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.260605 (* 1 = 0.260605 loss)
I0526 09:36:04.350302 15394 sgd_solver.cpp:43] Iteration 34440, lr = 0.002
I0526 09:36:09.584178 15394 main.cpp:354] Iteration 34450, loss = 0.14223
I0526 09:36:09.584220 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.14223 (* 1 = 0.14223 loss)
I0526 09:36:09.584226 15394 sgd_solver.cpp:43] Iteration 34450, lr = 0.002
I0526 09:36:14.769079 15394 main.cpp:354] Iteration 34460, loss = 0.181902
I0526 09:36:14.769114 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.181902 (* 1 = 0.181902 loss)
I0526 09:36:14.769121 15394 sgd_solver.cpp:43] Iteration 34460, lr = 0.002
I0526 09:36:19.834913 15394 main.cpp:354] Iteration 34470, loss = 0.21708
I0526 09:36:19.834952 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.21708 (* 1 = 0.21708 loss)
I0526 09:36:19.834959 15394 sgd_solver.cpp:43] Iteration 34470, lr = 0.002
I0526 09:36:24.694954 15394 main.cpp:354] Iteration 34480, loss = 0.308826
I0526 09:36:24.694994 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.308825 (* 1 = 0.308825 loss)
I0526 09:36:24.695000 15394 sgd_solver.cpp:43] Iteration 34480, lr = 0.002
I0526 09:36:29.752074 15394 main.cpp:354] Iteration 34490, loss = 0.163295
I0526 09:36:29.752117 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.163294 (* 1 = 0.163294 loss)
I0526 09:36:29.752125 15394 sgd_solver.cpp:43] Iteration 34490, lr = 0.002
I0526 09:36:34.043627 15394 main.cpp:465] Iteration 34500, Testing net (#0)
I0526 09:36:47.127122 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8861
I0526 09:36:47.127164 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.347488 (* 1 = 0.347488 loss)
I0526 09:36:47.557467 15394 main.cpp:354] Iteration 34500, loss = 0.348921
I0526 09:36:47.557489 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.348921 (* 1 = 0.348921 loss)
I0526 09:36:47.557497 15394 sgd_solver.cpp:43] Iteration 34500, lr = 0.002
I0526 09:36:52.272156 15394 main.cpp:354] Iteration 34510, loss = 0.25089
I0526 09:36:52.272197 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.25089 (* 1 = 0.25089 loss)
I0526 09:36:52.272202 15394 sgd_solver.cpp:43] Iteration 34510, lr = 0.002
I0526 09:36:57.546430 15394 main.cpp:354] Iteration 34520, loss = 0.2424
I0526 09:36:57.546470 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.2424 (* 1 = 0.2424 loss)
I0526 09:36:57.546478 15394 sgd_solver.cpp:43] Iteration 34520, lr = 0.002
I0526 09:37:02.833667 15394 main.cpp:354] Iteration 34530, loss = 0.235791
I0526 09:37:02.833709 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235791 (* 1 = 0.235791 loss)
I0526 09:37:02.833720 15394 sgd_solver.cpp:43] Iteration 34530, lr = 0.002
I0526 09:37:07.975581 15394 main.cpp:354] Iteration 34540, loss = 0.202718
I0526 09:37:07.975622 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.202718 (* 1 = 0.202718 loss)
I0526 09:37:07.975628 15394 sgd_solver.cpp:43] Iteration 34540, lr = 0.002
I0526 09:37:13.464882 15394 main.cpp:354] Iteration 34550, loss = 0.265424
I0526 09:37:13.464925 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.265424 (* 1 = 0.265424 loss)
I0526 09:37:13.464931 15394 sgd_solver.cpp:43] Iteration 34550, lr = 0.002
I0526 09:37:18.284518 15394 main.cpp:354] Iteration 34560, loss = 0.318211
I0526 09:37:18.284554 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.318211 (* 1 = 0.318211 loss)
I0526 09:37:18.284560 15394 sgd_solver.cpp:43] Iteration 34560, lr = 0.002
I0526 09:37:23.150122 15394 main.cpp:354] Iteration 34570, loss = 0.297138
I0526 09:37:23.150166 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.297138 (* 1 = 0.297138 loss)
I0526 09:37:23.150173 15394 sgd_solver.cpp:43] Iteration 34570, lr = 0.002
I0526 09:37:28.307193 15394 main.cpp:354] Iteration 34580, loss = 0.322919
I0526 09:37:28.307236 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.322918 (* 1 = 0.322918 loss)
I0526 09:37:28.307243 15394 sgd_solver.cpp:43] Iteration 34580, lr = 0.002
I0526 09:37:33.596729 15394 main.cpp:354] Iteration 34590, loss = 0.128373
I0526 09:37:33.596770 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.128373 (* 1 = 0.128373 loss)
I0526 09:37:33.596776 15394 sgd_solver.cpp:43] Iteration 34590, lr = 0.002
I0526 09:37:38.243109 15394 main.cpp:465] Iteration 34600, Testing net (#0)
I0526 09:37:51.331681 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8864
I0526 09:37:51.331720 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.349834 (* 1 = 0.349834 loss)
I0526 09:37:51.760851 15394 main.cpp:354] Iteration 34600, loss = 0.323185
I0526 09:37:51.760895 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.323185 (* 1 = 0.323185 loss)
I0526 09:37:51.760903 15394 sgd_solver.cpp:43] Iteration 34600, lr = 0.002
I0526 09:37:57.445560 15394 main.cpp:354] Iteration 34610, loss = 0.26605
I0526 09:37:57.445605 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.26605 (* 1 = 0.26605 loss)
I0526 09:37:57.445623 15394 sgd_solver.cpp:43] Iteration 34610, lr = 0.002
I0526 09:38:02.352272 15394 main.cpp:354] Iteration 34620, loss = 0.329593
I0526 09:38:02.352304 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.329593 (* 1 = 0.329593 loss)
I0526 09:38:02.352310 15394 sgd_solver.cpp:43] Iteration 34620, lr = 0.002
I0526 09:38:07.243567 15394 main.cpp:354] Iteration 34630, loss = 0.256868
I0526 09:38:07.243607 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.256867 (* 1 = 0.256867 loss)
I0526 09:38:07.243613 15394 sgd_solver.cpp:43] Iteration 34630, lr = 0.002
I0526 09:38:12.637217 15394 main.cpp:354] Iteration 34640, loss = 0.371168
I0526 09:38:12.637256 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.371168 (* 1 = 0.371168 loss)
I0526 09:38:12.637262 15394 sgd_solver.cpp:43] Iteration 34640, lr = 0.002
I0526 09:38:17.601102 15394 main.cpp:354] Iteration 34650, loss = 0.167879
I0526 09:38:17.601145 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.167878 (* 1 = 0.167878 loss)
I0526 09:38:17.601151 15394 sgd_solver.cpp:43] Iteration 34650, lr = 0.002
I0526 09:38:22.738215 15394 main.cpp:354] Iteration 34660, loss = 0.305288
I0526 09:38:22.738252 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.305288 (* 1 = 0.305288 loss)
I0526 09:38:22.738257 15394 sgd_solver.cpp:43] Iteration 34660, lr = 0.002
I0526 09:38:27.791573 15394 main.cpp:354] Iteration 34670, loss = 0.215604
I0526 09:38:27.791609 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.215603 (* 1 = 0.215603 loss)
I0526 09:38:27.791615 15394 sgd_solver.cpp:43] Iteration 34670, lr = 0.002
I0526 09:38:33.058558 15394 main.cpp:354] Iteration 34680, loss = 0.154906
I0526 09:38:33.058604 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.154906 (* 1 = 0.154906 loss)
I0526 09:38:33.058610 15394 sgd_solver.cpp:43] Iteration 34680, lr = 0.002
I0526 09:38:38.285678 15394 main.cpp:354] Iteration 34690, loss = 0.256416
I0526 09:38:38.285717 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.256416 (* 1 = 0.256416 loss)
I0526 09:38:38.285724 15394 sgd_solver.cpp:43] Iteration 34690, lr = 0.002
I0526 09:38:43.019196 15394 main.cpp:465] Iteration 34700, Testing net (#0)
I0526 09:38:56.112087 15394 main.cpp:532]     Test net output #0: Accuracy = 0.888
I0526 09:38:56.112128 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.334925 (* 1 = 0.334925 loss)
I0526 09:38:56.621575 15394 main.cpp:354] Iteration 34700, loss = 0.215272
I0526 09:38:56.621618 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.215272 (* 1 = 0.215272 loss)
I0526 09:38:56.621625 15394 sgd_solver.cpp:43] Iteration 34700, lr = 0.002
I0526 09:39:01.272892 15394 main.cpp:354] Iteration 34710, loss = 0.28833
I0526 09:39:01.272935 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.288329 (* 1 = 0.288329 loss)
I0526 09:39:01.272941 15394 sgd_solver.cpp:43] Iteration 34710, lr = 0.002
I0526 09:39:06.311255 15394 main.cpp:354] Iteration 34720, loss = 0.389293
I0526 09:39:06.311297 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.389293 (* 1 = 0.389293 loss)
I0526 09:39:06.311305 15394 sgd_solver.cpp:43] Iteration 34720, lr = 0.002
I0526 09:39:11.338496 15394 main.cpp:354] Iteration 34730, loss = 0.216992
I0526 09:39:11.338549 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.216992 (* 1 = 0.216992 loss)
I0526 09:39:11.338557 15394 sgd_solver.cpp:43] Iteration 34730, lr = 0.002
I0526 09:39:15.721674 15394 main.cpp:354] Iteration 34740, loss = 0.129916
I0526 09:39:15.721719 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.129916 (* 1 = 0.129916 loss)
I0526 09:39:15.721725 15394 sgd_solver.cpp:43] Iteration 34740, lr = 0.002
I0526 09:39:20.941469 15394 main.cpp:354] Iteration 34750, loss = 0.236285
I0526 09:39:20.941507 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.236285 (* 1 = 0.236285 loss)
I0526 09:39:20.941514 15394 sgd_solver.cpp:43] Iteration 34750, lr = 0.002
I0526 09:39:25.701797 15394 main.cpp:354] Iteration 34760, loss = 0.152926
I0526 09:39:25.701838 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.152926 (* 1 = 0.152926 loss)
I0526 09:39:25.701843 15394 sgd_solver.cpp:43] Iteration 34760, lr = 0.002
I0526 09:39:30.937153 15394 main.cpp:354] Iteration 34770, loss = 0.388664
I0526 09:39:30.937193 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.388664 (* 1 = 0.388664 loss)
I0526 09:39:30.937201 15394 sgd_solver.cpp:43] Iteration 34770, lr = 0.002
I0526 09:39:35.626260 15394 main.cpp:354] Iteration 34780, loss = 0.201228
I0526 09:39:35.626299 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.201228 (* 1 = 0.201228 loss)
I0526 09:39:35.626305 15394 sgd_solver.cpp:43] Iteration 34780, lr = 0.002
I0526 09:39:41.284827 15394 main.cpp:354] Iteration 34790, loss = 0.115161
I0526 09:39:41.284870 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.115161 (* 1 = 0.115161 loss)
I0526 09:39:41.284878 15394 sgd_solver.cpp:43] Iteration 34790, lr = 0.002
I0526 09:39:45.988715 15394 main.cpp:465] Iteration 34800, Testing net (#0)
I0526 09:39:59.072177 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8896
I0526 09:39:59.072218 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.335287 (* 1 = 0.335287 loss)
I0526 09:39:59.610909 15394 main.cpp:354] Iteration 34800, loss = 0.185173
I0526 09:39:59.610949 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.185173 (* 1 = 0.185173 loss)
I0526 09:39:59.610955 15394 sgd_solver.cpp:43] Iteration 34800, lr = 0.002
I0526 09:40:04.663888 15394 main.cpp:354] Iteration 34810, loss = 0.184757
I0526 09:40:04.663933 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.184757 (* 1 = 0.184757 loss)
I0526 09:40:04.663939 15394 sgd_solver.cpp:43] Iteration 34810, lr = 0.002
I0526 09:40:09.842123 15394 main.cpp:354] Iteration 34820, loss = 0.186699
I0526 09:40:09.842162 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186699 (* 1 = 0.186699 loss)
I0526 09:40:09.842169 15394 sgd_solver.cpp:43] Iteration 34820, lr = 0.002
I0526 09:40:14.965683 15394 main.cpp:354] Iteration 34830, loss = 0.238644
I0526 09:40:14.965723 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.238644 (* 1 = 0.238644 loss)
I0526 09:40:14.965730 15394 sgd_solver.cpp:43] Iteration 34830, lr = 0.002
I0526 09:40:20.410905 15394 main.cpp:354] Iteration 34840, loss = 0.138759
I0526 09:40:20.410953 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.138759 (* 1 = 0.138759 loss)
I0526 09:40:20.410960 15394 sgd_solver.cpp:43] Iteration 34840, lr = 0.002
I0526 09:40:25.530525 15394 main.cpp:354] Iteration 34850, loss = 0.179956
I0526 09:40:25.530568 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.179955 (* 1 = 0.179955 loss)
I0526 09:40:25.530576 15394 sgd_solver.cpp:43] Iteration 34850, lr = 0.002
I0526 09:40:30.223232 15394 main.cpp:354] Iteration 34860, loss = 0.215469
I0526 09:40:30.223278 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.215469 (* 1 = 0.215469 loss)
I0526 09:40:30.223285 15394 sgd_solver.cpp:43] Iteration 34860, lr = 0.002
I0526 09:40:35.557514 15394 main.cpp:354] Iteration 34870, loss = 0.292535
I0526 09:40:35.557554 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.292535 (* 1 = 0.292535 loss)
I0526 09:40:35.557560 15394 sgd_solver.cpp:43] Iteration 34870, lr = 0.002
I0526 09:40:40.418618 15394 main.cpp:354] Iteration 34880, loss = 0.148507
I0526 09:40:40.418658 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.148507 (* 1 = 0.148507 loss)
I0526 09:40:40.418665 15394 sgd_solver.cpp:43] Iteration 34880, lr = 0.002
I0526 09:40:45.322983 15394 main.cpp:354] Iteration 34890, loss = 0.507732
I0526 09:40:45.323024 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.507732 (* 1 = 0.507732 loss)
I0526 09:40:45.323030 15394 sgd_solver.cpp:43] Iteration 34890, lr = 0.002
I0526 09:40:50.116117 15394 main.cpp:465] Iteration 34900, Testing net (#0)
I0526 09:41:03.202884 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8884
I0526 09:41:03.202926 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.337433 (* 1 = 0.337433 loss)
I0526 09:41:03.710489 15394 main.cpp:354] Iteration 34900, loss = 0.1758
I0526 09:41:03.710528 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.1758 (* 1 = 0.1758 loss)
I0526 09:41:03.710536 15394 sgd_solver.cpp:43] Iteration 34900, lr = 0.002
I0526 09:41:08.744817 15394 main.cpp:354] Iteration 34910, loss = 0.455296
I0526 09:41:08.744856 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.455296 (* 1 = 0.455296 loss)
I0526 09:41:08.744863 15394 sgd_solver.cpp:43] Iteration 34910, lr = 0.002
I0526 09:41:13.612892 15394 main.cpp:354] Iteration 34920, loss = 0.188732
I0526 09:41:13.612936 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.188732 (* 1 = 0.188732 loss)
I0526 09:41:13.612943 15394 sgd_solver.cpp:43] Iteration 34920, lr = 0.002
I0526 09:41:18.384618 15394 main.cpp:354] Iteration 34930, loss = 0.25886
I0526 09:41:18.384655 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.258859 (* 1 = 0.258859 loss)
I0526 09:41:18.384662 15394 sgd_solver.cpp:43] Iteration 34930, lr = 0.002
I0526 09:41:23.624805 15394 main.cpp:354] Iteration 34940, loss = 0.141807
I0526 09:41:23.624845 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.141807 (* 1 = 0.141807 loss)
I0526 09:41:23.624851 15394 sgd_solver.cpp:43] Iteration 34940, lr = 0.002
I0526 09:41:28.967783 15394 main.cpp:354] Iteration 34950, loss = 0.135396
I0526 09:41:28.967828 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.135396 (* 1 = 0.135396 loss)
I0526 09:41:28.967839 15394 sgd_solver.cpp:43] Iteration 34950, lr = 0.002
I0526 09:41:33.835726 15394 main.cpp:354] Iteration 34960, loss = 0.192954
I0526 09:41:33.835762 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.192954 (* 1 = 0.192954 loss)
I0526 09:41:33.835768 15394 sgd_solver.cpp:43] Iteration 34960, lr = 0.002
I0526 09:41:39.084051 15394 main.cpp:354] Iteration 34970, loss = 0.264786
I0526 09:41:39.084092 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.264786 (* 1 = 0.264786 loss)
I0526 09:41:39.084100 15394 sgd_solver.cpp:43] Iteration 34970, lr = 0.002
I0526 09:41:43.662170 15394 main.cpp:354] Iteration 34980, loss = 0.181796
I0526 09:41:43.662215 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.181796 (* 1 = 0.181796 loss)
I0526 09:41:43.662223 15394 sgd_solver.cpp:43] Iteration 34980, lr = 0.002
I0526 09:41:48.197511 15394 main.cpp:354] Iteration 34990, loss = 0.44585
I0526 09:41:48.197552 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.44585 (* 1 = 0.44585 loss)
I0526 09:41:48.197558 15394 sgd_solver.cpp:43] Iteration 34990, lr = 0.002
I0526 09:41:52.645298 15394 main.cpp:465] Iteration 35000, Testing net (#0)
I0526 09:42:05.729770 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8848
I0526 09:42:05.729812 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.346902 (* 1 = 0.346902 loss)
I0526 09:42:06.232401 15394 main.cpp:354] Iteration 35000, loss = 0.221346
I0526 09:42:06.232441 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.221346 (* 1 = 0.221346 loss)
I0526 09:42:06.232448 15394 sgd_solver.cpp:43] Iteration 35000, lr = 0.002
I0526 09:42:10.970643 15394 main.cpp:354] Iteration 35010, loss = 0.371636
I0526 09:42:10.970695 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.371635 (* 1 = 0.371635 loss)
I0526 09:42:10.970701 15394 sgd_solver.cpp:43] Iteration 35010, lr = 0.002
I0526 09:42:15.898571 15394 main.cpp:354] Iteration 35020, loss = 0.164973
I0526 09:42:15.898619 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.164973 (* 1 = 0.164973 loss)
I0526 09:42:15.898627 15394 sgd_solver.cpp:43] Iteration 35020, lr = 0.002
I0526 09:42:21.031066 15394 main.cpp:354] Iteration 35030, loss = 0.316616
I0526 09:42:21.031095 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.316616 (* 1 = 0.316616 loss)
I0526 09:42:21.031102 15394 sgd_solver.cpp:43] Iteration 35030, lr = 0.002
I0526 09:42:26.213160 15394 main.cpp:354] Iteration 35040, loss = 0.260843
I0526 09:42:26.213201 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.260842 (* 1 = 0.260842 loss)
I0526 09:42:26.213207 15394 sgd_solver.cpp:43] Iteration 35040, lr = 0.002
I0526 09:42:32.045843 15394 main.cpp:354] Iteration 35050, loss = 0.274029
I0526 09:42:32.045886 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.274029 (* 1 = 0.274029 loss)
I0526 09:42:32.045892 15394 sgd_solver.cpp:43] Iteration 35050, lr = 0.002
I0526 09:42:37.493391 15394 main.cpp:354] Iteration 35060, loss = 0.0923379
I0526 09:42:37.493430 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0923377 (* 1 = 0.0923377 loss)
I0526 09:42:37.493437 15394 sgd_solver.cpp:43] Iteration 35060, lr = 0.002
I0526 09:42:42.300494 15394 main.cpp:354] Iteration 35070, loss = 0.264746
I0526 09:42:42.300535 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.264745 (* 1 = 0.264745 loss)
I0526 09:42:42.300541 15394 sgd_solver.cpp:43] Iteration 35070, lr = 0.002
I0526 09:42:47.587658 15394 main.cpp:354] Iteration 35080, loss = 0.210433
I0526 09:42:47.587702 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.210432 (* 1 = 0.210432 loss)
I0526 09:42:47.587708 15394 sgd_solver.cpp:43] Iteration 35080, lr = 0.002
I0526 09:42:52.706195 15394 main.cpp:354] Iteration 35090, loss = 0.351511
I0526 09:42:52.706235 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.351511 (* 1 = 0.351511 loss)
I0526 09:42:52.706243 15394 sgd_solver.cpp:43] Iteration 35090, lr = 0.002
I0526 09:42:57.005790 15394 main.cpp:465] Iteration 35100, Testing net (#0)
I0526 09:43:10.093513 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8897
I0526 09:43:10.093556 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.352755 (* 1 = 0.352755 loss)
I0526 09:43:10.560194 15394 main.cpp:354] Iteration 35100, loss = 0.156399
I0526 09:43:10.560230 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.156398 (* 1 = 0.156398 loss)
I0526 09:43:10.560237 15394 sgd_solver.cpp:43] Iteration 35100, lr = 0.002
I0526 09:43:15.738215 15394 main.cpp:354] Iteration 35110, loss = 0.213694
I0526 09:43:15.738258 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.213694 (* 1 = 0.213694 loss)
I0526 09:43:15.738265 15394 sgd_solver.cpp:43] Iteration 35110, lr = 0.002
I0526 09:43:20.951720 15394 main.cpp:354] Iteration 35120, loss = 0.162184
I0526 09:43:20.951758 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.162183 (* 1 = 0.162183 loss)
I0526 09:43:20.951764 15394 sgd_solver.cpp:43] Iteration 35120, lr = 0.002
I0526 09:43:25.990631 15394 main.cpp:354] Iteration 35130, loss = 0.251196
I0526 09:43:25.990671 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.251196 (* 1 = 0.251196 loss)
I0526 09:43:25.990689 15394 sgd_solver.cpp:43] Iteration 35130, lr = 0.002
I0526 09:43:31.297948 15394 main.cpp:354] Iteration 35140, loss = 0.284229
I0526 09:43:31.297988 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.284228 (* 1 = 0.284228 loss)
I0526 09:43:31.297994 15394 sgd_solver.cpp:43] Iteration 35140, lr = 0.002
I0526 09:43:36.311548 15394 main.cpp:354] Iteration 35150, loss = 0.149841
I0526 09:43:36.311573 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.149841 (* 1 = 0.149841 loss)
I0526 09:43:36.311580 15394 sgd_solver.cpp:43] Iteration 35150, lr = 0.002
I0526 09:43:41.469647 15394 main.cpp:354] Iteration 35160, loss = 0.178873
I0526 09:43:41.469688 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.178872 (* 1 = 0.178872 loss)
I0526 09:43:41.469696 15394 sgd_solver.cpp:43] Iteration 35160, lr = 0.002
I0526 09:43:46.512517 15394 main.cpp:354] Iteration 35170, loss = 0.404471
I0526 09:43:46.512559 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.404471 (* 1 = 0.404471 loss)
I0526 09:43:46.512567 15394 sgd_solver.cpp:43] Iteration 35170, lr = 0.002
I0526 09:43:51.631108 15394 main.cpp:354] Iteration 35180, loss = 0.255897
I0526 09:43:51.631148 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.255897 (* 1 = 0.255897 loss)
I0526 09:43:51.631155 15394 sgd_solver.cpp:43] Iteration 35180, lr = 0.002
I0526 09:43:56.312238 15394 main.cpp:354] Iteration 35190, loss = 0.552575
I0526 09:43:56.312279 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.552575 (* 1 = 0.552575 loss)
I0526 09:43:56.312285 15394 sgd_solver.cpp:43] Iteration 35190, lr = 0.002
I0526 09:44:01.237571 15394 main.cpp:465] Iteration 35200, Testing net (#0)
I0526 09:44:14.319459 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8909
I0526 09:44:14.319512 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.339322 (* 1 = 0.339322 loss)
I0526 09:44:14.822455 15394 main.cpp:354] Iteration 35200, loss = 0.227154
I0526 09:44:14.822499 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.227154 (* 1 = 0.227154 loss)
I0526 09:44:14.822506 15394 sgd_solver.cpp:43] Iteration 35200, lr = 0.002
I0526 09:44:20.053025 15394 main.cpp:354] Iteration 35210, loss = 0.234987
I0526 09:44:20.053056 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.234987 (* 1 = 0.234987 loss)
I0526 09:44:20.053063 15394 sgd_solver.cpp:43] Iteration 35210, lr = 0.002
I0526 09:44:24.795577 15394 main.cpp:354] Iteration 35220, loss = 0.287238
I0526 09:44:24.795619 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.287238 (* 1 = 0.287238 loss)
I0526 09:44:24.795625 15394 sgd_solver.cpp:43] Iteration 35220, lr = 0.002
I0526 09:44:29.698165 15394 main.cpp:354] Iteration 35230, loss = 0.351366
I0526 09:44:29.698215 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.351366 (* 1 = 0.351366 loss)
I0526 09:44:29.698221 15394 sgd_solver.cpp:43] Iteration 35230, lr = 0.002
I0526 09:44:34.861785 15394 main.cpp:354] Iteration 35240, loss = 0.499772
I0526 09:44:34.861824 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.499772 (* 1 = 0.499772 loss)
I0526 09:44:34.861830 15394 sgd_solver.cpp:43] Iteration 35240, lr = 0.002
I0526 09:44:39.682699 15394 main.cpp:354] Iteration 35250, loss = 0.20741
I0526 09:44:39.682724 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.20741 (* 1 = 0.20741 loss)
I0526 09:44:39.682731 15394 sgd_solver.cpp:43] Iteration 35250, lr = 0.002
I0526 09:44:45.129631 15394 main.cpp:354] Iteration 35260, loss = 0.174752
I0526 09:44:45.129674 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.174751 (* 1 = 0.174751 loss)
I0526 09:44:45.129681 15394 sgd_solver.cpp:43] Iteration 35260, lr = 0.002
I0526 09:44:50.287776 15394 main.cpp:354] Iteration 35270, loss = 0.192138
I0526 09:44:50.287817 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.192138 (* 1 = 0.192138 loss)
I0526 09:44:50.287824 15394 sgd_solver.cpp:43] Iteration 35270, lr = 0.002
I0526 09:44:55.829526 15394 main.cpp:354] Iteration 35280, loss = 0.355262
I0526 09:44:55.829565 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.355262 (* 1 = 0.355262 loss)
I0526 09:44:55.829571 15394 sgd_solver.cpp:43] Iteration 35280, lr = 0.002
I0526 09:45:00.886004 15394 main.cpp:354] Iteration 35290, loss = 0.191655
I0526 09:45:00.886047 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.191655 (* 1 = 0.191655 loss)
I0526 09:45:00.886054 15394 sgd_solver.cpp:43] Iteration 35290, lr = 0.002
I0526 09:45:05.896617 15394 main.cpp:465] Iteration 35300, Testing net (#0)
I0526 09:45:18.984195 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8915
I0526 09:45:18.984247 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.329576 (* 1 = 0.329576 loss)
I0526 09:45:19.489701 15394 main.cpp:354] Iteration 35300, loss = 0.305923
I0526 09:45:19.489732 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.305923 (* 1 = 0.305923 loss)
I0526 09:45:19.489740 15394 sgd_solver.cpp:43] Iteration 35300, lr = 0.002
I0526 09:45:24.652065 15394 main.cpp:354] Iteration 35310, loss = 0.0918887
I0526 09:45:24.652107 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0918884 (* 1 = 0.0918884 loss)
I0526 09:45:24.652113 15394 sgd_solver.cpp:43] Iteration 35310, lr = 0.002
I0526 09:45:30.011996 15394 main.cpp:354] Iteration 35320, loss = 0.260252
I0526 09:45:30.012040 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.260251 (* 1 = 0.260251 loss)
I0526 09:45:30.012048 15394 sgd_solver.cpp:43] Iteration 35320, lr = 0.002
I0526 09:45:34.948525 15394 main.cpp:354] Iteration 35330, loss = 0.286443
I0526 09:45:34.948570 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.286443 (* 1 = 0.286443 loss)
I0526 09:45:34.948577 15394 sgd_solver.cpp:43] Iteration 35330, lr = 0.002
I0526 09:45:39.876288 15394 main.cpp:354] Iteration 35340, loss = 0.260541
I0526 09:45:39.876327 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.260541 (* 1 = 0.260541 loss)
I0526 09:45:39.876333 15394 sgd_solver.cpp:43] Iteration 35340, lr = 0.002
I0526 09:45:45.020223 15394 main.cpp:354] Iteration 35350, loss = 0.258046
I0526 09:45:45.020265 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.258046 (* 1 = 0.258046 loss)
I0526 09:45:45.020272 15394 sgd_solver.cpp:43] Iteration 35350, lr = 0.002
I0526 09:45:50.322888 15394 main.cpp:354] Iteration 35360, loss = 0.181534
I0526 09:45:50.322929 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.181534 (* 1 = 0.181534 loss)
I0526 09:45:50.322937 15394 sgd_solver.cpp:43] Iteration 35360, lr = 0.002
I0526 09:45:55.443533 15394 main.cpp:354] Iteration 35370, loss = 0.0820535
I0526 09:45:55.443559 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0820533 (* 1 = 0.0820533 loss)
I0526 09:45:55.443572 15394 sgd_solver.cpp:43] Iteration 35370, lr = 0.002
I0526 09:46:00.380689 15394 main.cpp:354] Iteration 35380, loss = 0.281494
I0526 09:46:00.380729 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.281494 (* 1 = 0.281494 loss)
I0526 09:46:00.380736 15394 sgd_solver.cpp:43] Iteration 35380, lr = 0.002
I0526 09:46:05.256311 15394 main.cpp:354] Iteration 35390, loss = 0.386969
I0526 09:46:05.256350 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.386968 (* 1 = 0.386968 loss)
I0526 09:46:05.256356 15394 sgd_solver.cpp:43] Iteration 35390, lr = 0.002
I0526 09:46:09.942706 15394 main.cpp:465] Iteration 35400, Testing net (#0)
I0526 09:46:23.034495 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8875
I0526 09:46:23.034538 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.340751 (* 1 = 0.340751 loss)
I0526 09:46:23.500452 15394 main.cpp:354] Iteration 35400, loss = 0.182952
I0526 09:46:23.500495 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.182952 (* 1 = 0.182952 loss)
I0526 09:46:23.500504 15394 sgd_solver.cpp:43] Iteration 35400, lr = 0.002
I0526 09:46:28.684262 15394 main.cpp:354] Iteration 35410, loss = 0.23503
I0526 09:46:28.684304 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.23503 (* 1 = 0.23503 loss)
I0526 09:46:28.684310 15394 sgd_solver.cpp:43] Iteration 35410, lr = 0.002
I0526 09:46:33.309100 15394 main.cpp:354] Iteration 35420, loss = 0.350531
I0526 09:46:33.309137 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.350531 (* 1 = 0.350531 loss)
I0526 09:46:33.309144 15394 sgd_solver.cpp:43] Iteration 35420, lr = 0.002
I0526 09:46:38.747534 15394 main.cpp:354] Iteration 35430, loss = 0.206769
I0526 09:46:38.747575 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206768 (* 1 = 0.206768 loss)
I0526 09:46:38.747581 15394 sgd_solver.cpp:43] Iteration 35430, lr = 0.002
I0526 09:46:43.785533 15394 main.cpp:354] Iteration 35440, loss = 0.152645
I0526 09:46:43.785578 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.152645 (* 1 = 0.152645 loss)
I0526 09:46:43.785586 15394 sgd_solver.cpp:43] Iteration 35440, lr = 0.002
I0526 09:46:48.963289 15394 main.cpp:354] Iteration 35450, loss = 0.274375
I0526 09:46:48.963330 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.274375 (* 1 = 0.274375 loss)
I0526 09:46:48.963336 15394 sgd_solver.cpp:43] Iteration 35450, lr = 0.002
I0526 09:46:54.109845 15394 main.cpp:354] Iteration 35460, loss = 0.200154
I0526 09:46:54.109885 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.200153 (* 1 = 0.200153 loss)
I0526 09:46:54.109892 15394 sgd_solver.cpp:43] Iteration 35460, lr = 0.002
I0526 09:46:59.130293 15394 main.cpp:354] Iteration 35470, loss = 0.23574
I0526 09:46:59.130336 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.23574 (* 1 = 0.23574 loss)
I0526 09:46:59.130342 15394 sgd_solver.cpp:43] Iteration 35470, lr = 0.002
I0526 09:47:04.305101 15394 main.cpp:354] Iteration 35480, loss = 0.230598
I0526 09:47:04.305141 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.230597 (* 1 = 0.230597 loss)
I0526 09:47:04.305148 15394 sgd_solver.cpp:43] Iteration 35480, lr = 0.002
I0526 09:47:09.400142 15394 main.cpp:354] Iteration 35490, loss = 0.200023
I0526 09:47:09.400183 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.200022 (* 1 = 0.200022 loss)
I0526 09:47:09.400189 15394 sgd_solver.cpp:43] Iteration 35490, lr = 0.002
I0526 09:47:13.669734 15394 main.cpp:465] Iteration 35500, Testing net (#0)
I0526 09:47:26.750273 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8834
I0526 09:47:26.750315 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.35171 (* 1 = 0.35171 loss)
I0526 09:47:27.185472 15394 main.cpp:354] Iteration 35500, loss = 0.196946
I0526 09:47:27.185508 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.196946 (* 1 = 0.196946 loss)
I0526 09:47:27.185514 15394 sgd_solver.cpp:43] Iteration 35500, lr = 0.002
I0526 09:47:32.488327 15394 main.cpp:354] Iteration 35510, loss = 0.256257
I0526 09:47:32.488369 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.256257 (* 1 = 0.256257 loss)
I0526 09:47:32.488375 15394 sgd_solver.cpp:43] Iteration 35510, lr = 0.002
I0526 09:47:37.212502 15394 main.cpp:354] Iteration 35520, loss = 0.233226
I0526 09:47:37.212543 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.233225 (* 1 = 0.233225 loss)
I0526 09:47:37.212550 15394 sgd_solver.cpp:43] Iteration 35520, lr = 0.002
I0526 09:47:42.436823 15394 main.cpp:354] Iteration 35530, loss = 0.251261
I0526 09:47:42.436854 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.251261 (* 1 = 0.251261 loss)
I0526 09:47:42.436861 15394 sgd_solver.cpp:43] Iteration 35530, lr = 0.002
I0526 09:47:47.428427 15394 main.cpp:354] Iteration 35540, loss = 0.190727
I0526 09:47:47.428469 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.190726 (* 1 = 0.190726 loss)
I0526 09:47:47.428475 15394 sgd_solver.cpp:43] Iteration 35540, lr = 0.002
I0526 09:47:52.733031 15394 main.cpp:354] Iteration 35550, loss = 0.269131
I0526 09:47:52.733070 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.269131 (* 1 = 0.269131 loss)
I0526 09:47:52.733077 15394 sgd_solver.cpp:43] Iteration 35550, lr = 0.002
I0526 09:47:58.208093 15394 main.cpp:354] Iteration 35560, loss = 0.169291
I0526 09:47:58.208140 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.16929 (* 1 = 0.16929 loss)
I0526 09:47:58.208149 15394 sgd_solver.cpp:43] Iteration 35560, lr = 0.002
I0526 09:48:03.525084 15394 main.cpp:354] Iteration 35570, loss = 0.184895
I0526 09:48:03.525125 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.184895 (* 1 = 0.184895 loss)
I0526 09:48:03.525132 15394 sgd_solver.cpp:43] Iteration 35570, lr = 0.002
I0526 09:48:08.396323 15394 main.cpp:354] Iteration 35580, loss = 0.176885
I0526 09:48:08.396363 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.176885 (* 1 = 0.176885 loss)
I0526 09:48:08.396369 15394 sgd_solver.cpp:43] Iteration 35580, lr = 0.002
I0526 09:48:13.150442 15394 main.cpp:354] Iteration 35590, loss = 0.382215
I0526 09:48:13.150488 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.382215 (* 1 = 0.382215 loss)
I0526 09:48:13.150496 15394 sgd_solver.cpp:43] Iteration 35590, lr = 0.002
I0526 09:48:17.609303 15394 main.cpp:465] Iteration 35600, Testing net (#0)
I0526 09:48:30.689788 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8903
I0526 09:48:30.689841 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.340093 (* 1 = 0.340093 loss)
I0526 09:48:31.090104 15394 main.cpp:354] Iteration 35600, loss = 0.368772
I0526 09:48:31.090145 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.368772 (* 1 = 0.368772 loss)
I0526 09:48:31.090154 15394 sgd_solver.cpp:43] Iteration 35600, lr = 0.002
I0526 09:48:35.896251 15394 main.cpp:354] Iteration 35610, loss = 0.479614
I0526 09:48:35.896292 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.479614 (* 1 = 0.479614 loss)
I0526 09:48:35.896299 15394 sgd_solver.cpp:43] Iteration 35610, lr = 0.002
I0526 09:48:40.840953 15394 main.cpp:354] Iteration 35620, loss = 0.293527
I0526 09:48:40.841007 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.293526 (* 1 = 0.293526 loss)
I0526 09:48:40.841014 15394 sgd_solver.cpp:43] Iteration 35620, lr = 0.002
I0526 09:48:45.865625 15394 main.cpp:354] Iteration 35630, loss = 0.338757
I0526 09:48:45.865665 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.338757 (* 1 = 0.338757 loss)
I0526 09:48:45.865671 15394 sgd_solver.cpp:43] Iteration 35630, lr = 0.002
I0526 09:48:50.679486 15394 main.cpp:354] Iteration 35640, loss = 0.206718
I0526 09:48:50.679525 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206718 (* 1 = 0.206718 loss)
I0526 09:48:50.679533 15394 sgd_solver.cpp:43] Iteration 35640, lr = 0.002
I0526 09:48:55.635882 15394 main.cpp:354] Iteration 35650, loss = 0.495792
I0526 09:48:55.635931 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.495791 (* 1 = 0.495791 loss)
I0526 09:48:55.635937 15394 sgd_solver.cpp:43] Iteration 35650, lr = 0.002
I0526 09:49:00.220968 15394 main.cpp:354] Iteration 35660, loss = 0.176346
I0526 09:49:00.221007 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.176346 (* 1 = 0.176346 loss)
I0526 09:49:00.221014 15394 sgd_solver.cpp:43] Iteration 35660, lr = 0.002
I0526 09:49:05.899751 15394 main.cpp:354] Iteration 35670, loss = 0.172785
I0526 09:49:05.899792 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.172785 (* 1 = 0.172785 loss)
I0526 09:49:05.899798 15394 sgd_solver.cpp:43] Iteration 35670, lr = 0.002
I0526 09:49:10.643892 15394 main.cpp:354] Iteration 35680, loss = 0.430763
I0526 09:49:10.643937 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.430763 (* 1 = 0.430763 loss)
I0526 09:49:10.643945 15394 sgd_solver.cpp:43] Iteration 35680, lr = 0.002
I0526 09:49:15.136519 15394 main.cpp:354] Iteration 35690, loss = 0.199079
I0526 09:49:15.136560 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.199079 (* 1 = 0.199079 loss)
I0526 09:49:15.136567 15394 sgd_solver.cpp:43] Iteration 35690, lr = 0.002
I0526 09:49:19.210295 15394 main.cpp:465] Iteration 35700, Testing net (#0)
I0526 09:49:32.299422 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8921
I0526 09:49:32.299461 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.324963 (* 1 = 0.324963 loss)
I0526 09:49:32.839062 15394 main.cpp:354] Iteration 35700, loss = 0.123304
I0526 09:49:32.839100 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.123304 (* 1 = 0.123304 loss)
I0526 09:49:32.839109 15394 sgd_solver.cpp:43] Iteration 35700, lr = 0.002
I0526 09:49:37.906539 15394 main.cpp:354] Iteration 35710, loss = 0.163127
I0526 09:49:37.906584 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.163127 (* 1 = 0.163127 loss)
I0526 09:49:37.906592 15394 sgd_solver.cpp:43] Iteration 35710, lr = 0.002
I0526 09:49:43.108567 15394 main.cpp:354] Iteration 35720, loss = 0.175329
I0526 09:49:43.108609 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.175328 (* 1 = 0.175328 loss)
I0526 09:49:43.108615 15394 sgd_solver.cpp:43] Iteration 35720, lr = 0.002
I0526 09:49:48.268162 15394 main.cpp:354] Iteration 35730, loss = 0.206077
I0526 09:49:48.268199 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206076 (* 1 = 0.206076 loss)
I0526 09:49:48.268205 15394 sgd_solver.cpp:43] Iteration 35730, lr = 0.002
I0526 09:49:53.432219 15394 main.cpp:354] Iteration 35740, loss = 0.261832
I0526 09:49:53.432261 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.261832 (* 1 = 0.261832 loss)
I0526 09:49:53.432267 15394 sgd_solver.cpp:43] Iteration 35740, lr = 0.002
I0526 09:49:58.094445 15394 main.cpp:354] Iteration 35750, loss = 0.316788
I0526 09:49:58.094485 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.316788 (* 1 = 0.316788 loss)
I0526 09:49:58.094491 15394 sgd_solver.cpp:43] Iteration 35750, lr = 0.002
I0526 09:50:03.194067 15394 main.cpp:354] Iteration 35760, loss = 0.102802
I0526 09:50:03.194103 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.102802 (* 1 = 0.102802 loss)
I0526 09:50:03.194110 15394 sgd_solver.cpp:43] Iteration 35760, lr = 0.002
I0526 09:50:08.343809 15394 main.cpp:354] Iteration 35770, loss = 0.179659
I0526 09:50:08.343852 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.179659 (* 1 = 0.179659 loss)
I0526 09:50:08.343858 15394 sgd_solver.cpp:43] Iteration 35770, lr = 0.002
I0526 09:50:13.165693 15394 main.cpp:354] Iteration 35780, loss = 0.386373
I0526 09:50:13.165731 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.386373 (* 1 = 0.386373 loss)
I0526 09:50:13.165737 15394 sgd_solver.cpp:43] Iteration 35780, lr = 0.002
I0526 09:50:18.410810 15394 main.cpp:354] Iteration 35790, loss = 0.238177
I0526 09:50:18.410851 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.238177 (* 1 = 0.238177 loss)
I0526 09:50:18.410861 15394 sgd_solver.cpp:43] Iteration 35790, lr = 0.002
I0526 09:50:23.460289 15394 main.cpp:465] Iteration 35800, Testing net (#0)
I0526 09:50:36.535868 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8884
I0526 09:50:36.535909 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.342195 (* 1 = 0.342195 loss)
I0526 09:50:37.041208 15394 main.cpp:354] Iteration 35800, loss = 0.219411
I0526 09:50:37.041261 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.219411 (* 1 = 0.219411 loss)
I0526 09:50:37.041270 15394 sgd_solver.cpp:43] Iteration 35800, lr = 0.002
I0526 09:50:42.405931 15394 main.cpp:354] Iteration 35810, loss = 0.319844
I0526 09:50:42.405968 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.319844 (* 1 = 0.319844 loss)
I0526 09:50:42.405975 15394 sgd_solver.cpp:43] Iteration 35810, lr = 0.002
I0526 09:50:46.730288 15394 main.cpp:354] Iteration 35820, loss = 0.27458
I0526 09:50:46.730327 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.27458 (* 1 = 0.27458 loss)
I0526 09:50:46.730334 15394 sgd_solver.cpp:43] Iteration 35820, lr = 0.002
I0526 09:50:51.885081 15394 main.cpp:354] Iteration 35830, loss = 0.227069
I0526 09:50:51.885121 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.227068 (* 1 = 0.227068 loss)
I0526 09:50:51.885128 15394 sgd_solver.cpp:43] Iteration 35830, lr = 0.002
I0526 09:50:56.878715 15394 main.cpp:354] Iteration 35840, loss = 0.195135
I0526 09:50:56.878757 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.195134 (* 1 = 0.195134 loss)
I0526 09:50:56.878764 15394 sgd_solver.cpp:43] Iteration 35840, lr = 0.002
I0526 09:51:01.719372 15394 main.cpp:354] Iteration 35850, loss = 0.256315
I0526 09:51:01.719411 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.256315 (* 1 = 0.256315 loss)
I0526 09:51:01.719418 15394 sgd_solver.cpp:43] Iteration 35850, lr = 0.002
I0526 09:51:07.019281 15394 main.cpp:354] Iteration 35860, loss = 0.274411
I0526 09:51:07.019325 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.274411 (* 1 = 0.274411 loss)
I0526 09:51:07.019332 15394 sgd_solver.cpp:43] Iteration 35860, lr = 0.002
I0526 09:51:12.673579 15394 main.cpp:354] Iteration 35870, loss = 0.157818
I0526 09:51:12.673622 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.157818 (* 1 = 0.157818 loss)
I0526 09:51:12.673631 15394 sgd_solver.cpp:43] Iteration 35870, lr = 0.002
I0526 09:51:17.980583 15394 main.cpp:354] Iteration 35880, loss = 0.120968
I0526 09:51:17.980621 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.120968 (* 1 = 0.120968 loss)
I0526 09:51:17.980628 15394 sgd_solver.cpp:43] Iteration 35880, lr = 0.002
I0526 09:51:23.151528 15394 main.cpp:354] Iteration 35890, loss = 0.286967
I0526 09:51:23.151562 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.286967 (* 1 = 0.286967 loss)
I0526 09:51:23.151569 15394 sgd_solver.cpp:43] Iteration 35890, lr = 0.002
I0526 09:51:27.545080 15394 main.cpp:465] Iteration 35900, Testing net (#0)
I0526 09:51:40.617161 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8884
I0526 09:51:40.617213 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.346297 (* 1 = 0.346297 loss)
I0526 09:51:41.119436 15394 main.cpp:354] Iteration 35900, loss = 0.257223
I0526 09:51:41.119467 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.257223 (* 1 = 0.257223 loss)
I0526 09:51:41.119475 15394 sgd_solver.cpp:43] Iteration 35900, lr = 0.002
I0526 09:51:46.053062 15394 main.cpp:354] Iteration 35910, loss = 0.23773
I0526 09:51:46.053104 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.23773 (* 1 = 0.23773 loss)
I0526 09:51:46.053112 15394 sgd_solver.cpp:43] Iteration 35910, lr = 0.002
I0526 09:51:50.901618 15394 main.cpp:354] Iteration 35920, loss = 0.290151
I0526 09:51:50.901669 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.29015 (* 1 = 0.29015 loss)
I0526 09:51:50.901682 15394 sgd_solver.cpp:43] Iteration 35920, lr = 0.002
I0526 09:51:56.133973 15394 main.cpp:354] Iteration 35930, loss = 0.275566
I0526 09:51:56.134017 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.275565 (* 1 = 0.275565 loss)
I0526 09:51:56.134024 15394 sgd_solver.cpp:43] Iteration 35930, lr = 0.002
I0526 09:52:01.521929 15394 main.cpp:354] Iteration 35940, loss = 0.161422
I0526 09:52:01.521967 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.161422 (* 1 = 0.161422 loss)
I0526 09:52:01.521973 15394 sgd_solver.cpp:43] Iteration 35940, lr = 0.002
I0526 09:52:06.857836 15394 main.cpp:354] Iteration 35950, loss = 0.237328
I0526 09:52:06.857882 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.237328 (* 1 = 0.237328 loss)
I0526 09:52:06.857888 15394 sgd_solver.cpp:43] Iteration 35950, lr = 0.002
I0526 09:52:12.419365 15394 main.cpp:354] Iteration 35960, loss = 0.210006
I0526 09:52:12.419404 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.210005 (* 1 = 0.210005 loss)
I0526 09:52:12.419410 15394 sgd_solver.cpp:43] Iteration 35960, lr = 0.002
I0526 09:52:17.154825 15394 main.cpp:354] Iteration 35970, loss = 0.23056
I0526 09:52:17.154865 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.23056 (* 1 = 0.23056 loss)
I0526 09:52:17.154872 15394 sgd_solver.cpp:43] Iteration 35970, lr = 0.002
I0526 09:52:22.165773 15394 main.cpp:354] Iteration 35980, loss = 0.168493
I0526 09:52:22.165817 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.168492 (* 1 = 0.168492 loss)
I0526 09:52:22.165823 15394 sgd_solver.cpp:43] Iteration 35980, lr = 0.002
I0526 09:52:27.326539 15394 main.cpp:354] Iteration 35990, loss = 0.280944
I0526 09:52:27.326575 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.280943 (* 1 = 0.280943 loss)
I0526 09:52:27.326581 15394 sgd_solver.cpp:43] Iteration 35990, lr = 0.002
I0526 09:52:31.835017 15394 main.cpp:465] Iteration 36000, Testing net (#0)
I0526 09:52:44.924144 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8858
I0526 09:52:44.924183 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.353611 (* 1 = 0.353611 loss)
I0526 09:52:45.365592 15394 main.cpp:354] Iteration 36000, loss = 0.216299
I0526 09:52:45.365623 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.216299 (* 1 = 0.216299 loss)
I0526 09:52:45.365631 15394 sgd_solver.cpp:43] Iteration 36000, lr = 0.002
I0526 09:52:50.441594 15394 main.cpp:354] Iteration 36010, loss = 0.234566
I0526 09:52:50.441634 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.234566 (* 1 = 0.234566 loss)
I0526 09:52:50.441642 15394 sgd_solver.cpp:43] Iteration 36010, lr = 0.002
I0526 09:52:55.644248 15394 main.cpp:354] Iteration 36020, loss = 0.1966
I0526 09:52:55.644291 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.1966 (* 1 = 0.1966 loss)
I0526 09:52:55.644299 15394 sgd_solver.cpp:43] Iteration 36020, lr = 0.002
I0526 09:53:00.941536 15394 main.cpp:354] Iteration 36030, loss = 0.0914959
I0526 09:53:00.941577 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0914956 (* 1 = 0.0914956 loss)
I0526 09:53:00.941586 15394 sgd_solver.cpp:43] Iteration 36030, lr = 0.002
I0526 09:53:06.454221 15394 main.cpp:354] Iteration 36040, loss = 0.204278
I0526 09:53:06.454265 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204278 (* 1 = 0.204278 loss)
I0526 09:53:06.454274 15394 sgd_solver.cpp:43] Iteration 36040, lr = 0.002
I0526 09:53:11.563686 15394 main.cpp:354] Iteration 36050, loss = 0.304271
I0526 09:53:11.563726 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.30427 (* 1 = 0.30427 loss)
I0526 09:53:11.563733 15394 sgd_solver.cpp:43] Iteration 36050, lr = 0.002
I0526 09:53:16.363631 15394 main.cpp:354] Iteration 36060, loss = 0.366488
I0526 09:53:16.363670 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.366488 (* 1 = 0.366488 loss)
I0526 09:53:16.363677 15394 sgd_solver.cpp:43] Iteration 36060, lr = 0.002
I0526 09:53:21.483886 15394 main.cpp:354] Iteration 36070, loss = 0.262168
I0526 09:53:21.483934 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.262168 (* 1 = 0.262168 loss)
I0526 09:53:21.483942 15394 sgd_solver.cpp:43] Iteration 36070, lr = 0.002
I0526 09:53:26.314422 15394 main.cpp:354] Iteration 36080, loss = 0.291416
I0526 09:53:26.314460 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.291416 (* 1 = 0.291416 loss)
I0526 09:53:26.314466 15394 sgd_solver.cpp:43] Iteration 36080, lr = 0.002
I0526 09:53:31.048497 15394 main.cpp:354] Iteration 36090, loss = 0.227598
I0526 09:53:31.048535 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.227598 (* 1 = 0.227598 loss)
I0526 09:53:31.048542 15394 sgd_solver.cpp:43] Iteration 36090, lr = 0.002
I0526 09:53:35.914440 15394 main.cpp:465] Iteration 36100, Testing net (#0)
I0526 09:53:48.985275 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8863
I0526 09:53:48.985312 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.355729 (* 1 = 0.355729 loss)
I0526 09:53:49.457777 15394 main.cpp:354] Iteration 36100, loss = 0.111879
I0526 09:53:49.457813 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.111879 (* 1 = 0.111879 loss)
I0526 09:53:49.457821 15394 sgd_solver.cpp:43] Iteration 36100, lr = 0.002
I0526 09:53:54.435072 15394 main.cpp:354] Iteration 36110, loss = 0.3781
I0526 09:53:54.435117 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.378099 (* 1 = 0.378099 loss)
I0526 09:53:54.435122 15394 sgd_solver.cpp:43] Iteration 36110, lr = 0.002
I0526 09:53:59.391266 15394 main.cpp:354] Iteration 36120, loss = 0.17397
I0526 09:53:59.391304 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.173969 (* 1 = 0.173969 loss)
I0526 09:53:59.391310 15394 sgd_solver.cpp:43] Iteration 36120, lr = 0.002
I0526 09:54:04.699517 15394 main.cpp:354] Iteration 36130, loss = 0.2622
I0526 09:54:04.699554 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.2622 (* 1 = 0.2622 loss)
I0526 09:54:04.699561 15394 sgd_solver.cpp:43] Iteration 36130, lr = 0.002
I0526 09:54:09.309051 15394 main.cpp:354] Iteration 36140, loss = 0.287621
I0526 09:54:09.309094 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.28762 (* 1 = 0.28762 loss)
I0526 09:54:09.309100 15394 sgd_solver.cpp:43] Iteration 36140, lr = 0.002
I0526 09:54:14.409509 15394 main.cpp:354] Iteration 36150, loss = 0.18905
I0526 09:54:14.409549 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.18905 (* 1 = 0.18905 loss)
I0526 09:54:14.409556 15394 sgd_solver.cpp:43] Iteration 36150, lr = 0.002
I0526 09:54:19.875016 15394 main.cpp:354] Iteration 36160, loss = 0.275317
I0526 09:54:19.875056 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.275317 (* 1 = 0.275317 loss)
I0526 09:54:19.875063 15394 sgd_solver.cpp:43] Iteration 36160, lr = 0.002
I0526 09:54:24.887356 15394 main.cpp:354] Iteration 36170, loss = 0.268463
I0526 09:54:24.887403 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.268463 (* 1 = 0.268463 loss)
I0526 09:54:24.887409 15394 sgd_solver.cpp:43] Iteration 36170, lr = 0.002
I0526 09:54:29.893402 15394 main.cpp:354] Iteration 36180, loss = 0.195419
I0526 09:54:29.893443 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.195419 (* 1 = 0.195419 loss)
I0526 09:54:29.893450 15394 sgd_solver.cpp:43] Iteration 36180, lr = 0.002
I0526 09:54:34.743027 15394 main.cpp:354] Iteration 36190, loss = 0.24397
I0526 09:54:34.743067 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.24397 (* 1 = 0.24397 loss)
I0526 09:54:34.743072 15394 sgd_solver.cpp:43] Iteration 36190, lr = 0.002
I0526 09:54:39.471385 15394 main.cpp:465] Iteration 36200, Testing net (#0)
I0526 09:54:52.546830 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8804
I0526 09:54:52.546871 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.374864 (* 1 = 0.374864 loss)
I0526 09:54:52.976132 15394 main.cpp:354] Iteration 36200, loss = 0.43825
I0526 09:54:52.976171 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.43825 (* 1 = 0.43825 loss)
I0526 09:54:52.976182 15394 sgd_solver.cpp:43] Iteration 36200, lr = 0.002
I0526 09:54:57.817819 15394 main.cpp:354] Iteration 36210, loss = 0.149952
I0526 09:54:57.817850 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.149952 (* 1 = 0.149952 loss)
I0526 09:54:57.817857 15394 sgd_solver.cpp:43] Iteration 36210, lr = 0.002
I0526 09:55:03.050775 15394 main.cpp:354] Iteration 36220, loss = 0.0832118
I0526 09:55:03.050817 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0832116 (* 1 = 0.0832116 loss)
I0526 09:55:03.050823 15394 sgd_solver.cpp:43] Iteration 36220, lr = 0.002
I0526 09:55:08.084568 15394 main.cpp:354] Iteration 36230, loss = 0.280248
I0526 09:55:08.084610 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.280248 (* 1 = 0.280248 loss)
I0526 09:55:08.084617 15394 sgd_solver.cpp:43] Iteration 36230, lr = 0.002
I0526 09:55:13.244007 15394 main.cpp:354] Iteration 36240, loss = 0.195763
I0526 09:55:13.244045 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.195763 (* 1 = 0.195763 loss)
I0526 09:55:13.244052 15394 sgd_solver.cpp:43] Iteration 36240, lr = 0.002
I0526 09:55:17.908135 15394 main.cpp:354] Iteration 36250, loss = 0.12201
I0526 09:55:17.908174 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.122009 (* 1 = 0.122009 loss)
I0526 09:55:17.908180 15394 sgd_solver.cpp:43] Iteration 36250, lr = 0.002
I0526 09:55:22.762670 15394 main.cpp:354] Iteration 36260, loss = 0.117212
I0526 09:55:22.762722 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.117211 (* 1 = 0.117211 loss)
I0526 09:55:22.762728 15394 sgd_solver.cpp:43] Iteration 36260, lr = 0.002
I0526 09:55:27.442713 15394 main.cpp:354] Iteration 36270, loss = 0.153103
I0526 09:55:27.442754 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.153102 (* 1 = 0.153102 loss)
I0526 09:55:27.442759 15394 sgd_solver.cpp:43] Iteration 36270, lr = 0.002
I0526 09:55:32.390911 15394 main.cpp:354] Iteration 36280, loss = 0.150696
I0526 09:55:32.390951 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.150696 (* 1 = 0.150696 loss)
I0526 09:55:32.390959 15394 sgd_solver.cpp:43] Iteration 36280, lr = 0.002
I0526 09:55:37.804327 15394 main.cpp:354] Iteration 36290, loss = 0.131772
I0526 09:55:37.804375 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.131772 (* 1 = 0.131772 loss)
I0526 09:55:37.804383 15394 sgd_solver.cpp:43] Iteration 36290, lr = 0.002
I0526 09:55:42.709807 15394 main.cpp:465] Iteration 36300, Testing net (#0)
I0526 09:55:55.797608 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8886
I0526 09:55:55.797647 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.344701 (* 1 = 0.344701 loss)
I0526 09:55:56.300289 15394 main.cpp:354] Iteration 36300, loss = 0.204742
I0526 09:55:56.300326 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204742 (* 1 = 0.204742 loss)
I0526 09:55:56.300334 15394 sgd_solver.cpp:43] Iteration 36300, lr = 0.002
I0526 09:56:01.574031 15394 main.cpp:354] Iteration 36310, loss = 0.280185
I0526 09:56:01.574069 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.280184 (* 1 = 0.280184 loss)
I0526 09:56:01.574075 15394 sgd_solver.cpp:43] Iteration 36310, lr = 0.002
I0526 09:56:06.905232 15394 main.cpp:354] Iteration 36320, loss = 0.180363
I0526 09:56:06.905262 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.180363 (* 1 = 0.180363 loss)
I0526 09:56:06.905268 15394 sgd_solver.cpp:43] Iteration 36320, lr = 0.002
I0526 09:56:11.895117 15394 main.cpp:354] Iteration 36330, loss = 0.209243
I0526 09:56:11.895161 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.209243 (* 1 = 0.209243 loss)
I0526 09:56:11.895169 15394 sgd_solver.cpp:43] Iteration 36330, lr = 0.002
I0526 09:56:17.586112 15394 main.cpp:354] Iteration 36340, loss = 0.211785
I0526 09:56:17.586151 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.211785 (* 1 = 0.211785 loss)
I0526 09:56:17.586163 15394 sgd_solver.cpp:43] Iteration 36340, lr = 0.002
I0526 09:56:22.920492 15394 main.cpp:354] Iteration 36350, loss = 0.104737
I0526 09:56:22.920533 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.104737 (* 1 = 0.104737 loss)
I0526 09:56:22.920541 15394 sgd_solver.cpp:43] Iteration 36350, lr = 0.002
I0526 09:56:27.744735 15394 main.cpp:354] Iteration 36360, loss = 0.182065
I0526 09:56:27.744774 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.182065 (* 1 = 0.182065 loss)
I0526 09:56:27.744781 15394 sgd_solver.cpp:43] Iteration 36360, lr = 0.002
I0526 09:56:33.279690 15394 main.cpp:354] Iteration 36370, loss = 0.0702627
I0526 09:56:33.279728 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0702625 (* 1 = 0.0702625 loss)
I0526 09:56:33.279736 15394 sgd_solver.cpp:43] Iteration 36370, lr = 0.002
I0526 09:56:38.400187 15394 main.cpp:354] Iteration 36380, loss = 0.224502
I0526 09:56:38.400224 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.224502 (* 1 = 0.224502 loss)
I0526 09:56:38.400231 15394 sgd_solver.cpp:43] Iteration 36380, lr = 0.002
I0526 09:56:42.976830 15394 main.cpp:354] Iteration 36390, loss = 0.209714
I0526 09:56:42.976869 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.209713 (* 1 = 0.209713 loss)
I0526 09:56:42.976876 15394 sgd_solver.cpp:43] Iteration 36390, lr = 0.002
I0526 09:56:47.412041 15394 main.cpp:465] Iteration 36400, Testing net (#0)
I0526 09:57:00.497442 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8833
I0526 09:57:00.497484 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.360555 (* 1 = 0.360555 loss)
I0526 09:57:00.933380 15394 main.cpp:354] Iteration 36400, loss = 0.214001
I0526 09:57:00.933414 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.214001 (* 1 = 0.214001 loss)
I0526 09:57:00.933421 15394 sgd_solver.cpp:43] Iteration 36400, lr = 0.002
I0526 09:57:05.566776 15394 main.cpp:354] Iteration 36410, loss = 0.750339
I0526 09:57:05.566814 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.750339 (* 1 = 0.750339 loss)
I0526 09:57:05.566820 15394 sgd_solver.cpp:43] Iteration 36410, lr = 0.002
I0526 09:57:10.624460 15394 main.cpp:354] Iteration 36420, loss = 0.30148
I0526 09:57:10.624502 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.30148 (* 1 = 0.30148 loss)
I0526 09:57:10.624510 15394 sgd_solver.cpp:43] Iteration 36420, lr = 0.002
I0526 09:57:15.938649 15394 main.cpp:354] Iteration 36430, loss = 0.223835
I0526 09:57:15.938689 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.223835 (* 1 = 0.223835 loss)
I0526 09:57:15.938696 15394 sgd_solver.cpp:43] Iteration 36430, lr = 0.002
I0526 09:57:21.501354 15394 main.cpp:354] Iteration 36440, loss = 0.15712
I0526 09:57:21.501397 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.15712 (* 1 = 0.15712 loss)
I0526 09:57:21.501405 15394 sgd_solver.cpp:43] Iteration 36440, lr = 0.002
I0526 09:57:26.629016 15394 main.cpp:354] Iteration 36450, loss = 0.359342
I0526 09:57:26.629055 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.359342 (* 1 = 0.359342 loss)
I0526 09:57:26.629061 15394 sgd_solver.cpp:43] Iteration 36450, lr = 0.002
I0526 09:57:31.815850 15394 main.cpp:354] Iteration 36460, loss = 0.29707
I0526 09:57:31.815891 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.29707 (* 1 = 0.29707 loss)
I0526 09:57:31.815897 15394 sgd_solver.cpp:43] Iteration 36460, lr = 0.002
I0526 09:57:37.016753 15394 main.cpp:354] Iteration 36470, loss = 0.222778
I0526 09:57:37.016795 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.222778 (* 1 = 0.222778 loss)
I0526 09:57:37.016803 15394 sgd_solver.cpp:43] Iteration 36470, lr = 0.002
I0526 09:57:42.055061 15394 main.cpp:354] Iteration 36480, loss = 0.212647
I0526 09:57:42.055101 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.212647 (* 1 = 0.212647 loss)
I0526 09:57:42.055107 15394 sgd_solver.cpp:43] Iteration 36480, lr = 0.002
I0526 09:57:46.742826 15394 main.cpp:354] Iteration 36490, loss = 0.206155
I0526 09:57:46.742867 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206154 (* 1 = 0.206154 loss)
I0526 09:57:46.742874 15394 sgd_solver.cpp:43] Iteration 36490, lr = 0.002
I0526 09:57:51.315657 15394 main.cpp:465] Iteration 36500, Testing net (#0)
I0526 09:58:04.409107 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8914
I0526 09:58:04.409152 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.340639 (* 1 = 0.340639 loss)
I0526 09:58:04.875712 15394 main.cpp:354] Iteration 36500, loss = 0.213269
I0526 09:58:04.875753 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.213269 (* 1 = 0.213269 loss)
I0526 09:58:04.875762 15394 sgd_solver.cpp:43] Iteration 36500, lr = 0.002
I0526 09:58:09.983983 15394 main.cpp:354] Iteration 36510, loss = 0.176177
I0526 09:58:09.984025 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.176176 (* 1 = 0.176176 loss)
I0526 09:58:09.984032 15394 sgd_solver.cpp:43] Iteration 36510, lr = 0.002
I0526 09:58:15.065418 15394 main.cpp:354] Iteration 36520, loss = 0.243482
I0526 09:58:15.065456 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.243482 (* 1 = 0.243482 loss)
I0526 09:58:15.065462 15394 sgd_solver.cpp:43] Iteration 36520, lr = 0.002
I0526 09:58:19.994731 15394 main.cpp:354] Iteration 36530, loss = 0.153396
I0526 09:58:19.994770 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.153396 (* 1 = 0.153396 loss)
I0526 09:58:19.994776 15394 sgd_solver.cpp:43] Iteration 36530, lr = 0.002
I0526 09:58:25.355309 15394 main.cpp:354] Iteration 36540, loss = 0.207793
I0526 09:58:25.355350 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.207793 (* 1 = 0.207793 loss)
I0526 09:58:25.355357 15394 sgd_solver.cpp:43] Iteration 36540, lr = 0.002
I0526 09:58:30.460816 15394 main.cpp:354] Iteration 36550, loss = 0.192883
I0526 09:58:30.460853 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.192882 (* 1 = 0.192882 loss)
I0526 09:58:30.460860 15394 sgd_solver.cpp:43] Iteration 36550, lr = 0.002
I0526 09:58:35.639739 15394 main.cpp:354] Iteration 36560, loss = 0.174425
I0526 09:58:35.639783 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.174425 (* 1 = 0.174425 loss)
I0526 09:58:35.639791 15394 sgd_solver.cpp:43] Iteration 36560, lr = 0.002
I0526 09:58:40.830243 15394 main.cpp:354] Iteration 36570, loss = 0.433837
I0526 09:58:40.830287 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.433837 (* 1 = 0.433837 loss)
I0526 09:58:40.830294 15394 sgd_solver.cpp:43] Iteration 36570, lr = 0.002
I0526 09:58:46.156505 15394 main.cpp:354] Iteration 36580, loss = 0.116867
I0526 09:58:46.156544 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.116866 (* 1 = 0.116866 loss)
I0526 09:58:46.156550 15394 sgd_solver.cpp:43] Iteration 36580, lr = 0.002
I0526 09:58:51.461740 15394 main.cpp:354] Iteration 36590, loss = 0.335804
I0526 09:58:51.461786 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.335804 (* 1 = 0.335804 loss)
I0526 09:58:51.461794 15394 sgd_solver.cpp:43] Iteration 36590, lr = 0.002
I0526 09:58:55.974968 15394 main.cpp:465] Iteration 36600, Testing net (#0)
I0526 09:59:09.062535 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8938
I0526 09:59:09.062575 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.33417 (* 1 = 0.33417 loss)
I0526 09:59:09.534384 15394 main.cpp:354] Iteration 36600, loss = 0.185758
I0526 09:59:09.534412 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.185758 (* 1 = 0.185758 loss)
I0526 09:59:09.534421 15394 sgd_solver.cpp:43] Iteration 36600, lr = 0.002
I0526 09:59:14.794128 15394 main.cpp:354] Iteration 36610, loss = 0.155323
I0526 09:59:14.794167 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.155323 (* 1 = 0.155323 loss)
I0526 09:59:14.794173 15394 sgd_solver.cpp:43] Iteration 36610, lr = 0.002
I0526 09:59:19.815054 15394 main.cpp:354] Iteration 36620, loss = 0.302625
I0526 09:59:19.815102 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.302625 (* 1 = 0.302625 loss)
I0526 09:59:19.815109 15394 sgd_solver.cpp:43] Iteration 36620, lr = 0.002
I0526 09:59:25.002742 15394 main.cpp:354] Iteration 36630, loss = 0.177182
I0526 09:59:25.002786 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.177182 (* 1 = 0.177182 loss)
I0526 09:59:25.002794 15394 sgd_solver.cpp:43] Iteration 36630, lr = 0.002
I0526 09:59:30.043895 15394 main.cpp:354] Iteration 36640, loss = 0.128432
I0526 09:59:30.043932 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.128432 (* 1 = 0.128432 loss)
I0526 09:59:30.043939 15394 sgd_solver.cpp:43] Iteration 36640, lr = 0.002
I0526 09:59:34.868587 15394 main.cpp:354] Iteration 36650, loss = 0.188796
I0526 09:59:34.868616 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.188796 (* 1 = 0.188796 loss)
I0526 09:59:34.868623 15394 sgd_solver.cpp:43] Iteration 36650, lr = 0.002
I0526 09:59:39.760435 15394 main.cpp:354] Iteration 36660, loss = 0.255485
I0526 09:59:39.760478 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.255485 (* 1 = 0.255485 loss)
I0526 09:59:39.760483 15394 sgd_solver.cpp:43] Iteration 36660, lr = 0.002
I0526 09:59:44.282732 15394 main.cpp:354] Iteration 36670, loss = 0.286206
I0526 09:59:44.282771 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.286206 (* 1 = 0.286206 loss)
I0526 09:59:44.282778 15394 sgd_solver.cpp:43] Iteration 36670, lr = 0.002
I0526 09:59:49.253031 15394 main.cpp:354] Iteration 36680, loss = 0.112303
I0526 09:59:49.253070 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.112302 (* 1 = 0.112302 loss)
I0526 09:59:49.253077 15394 sgd_solver.cpp:43] Iteration 36680, lr = 0.002
I0526 09:59:54.266217 15394 main.cpp:354] Iteration 36690, loss = 0.270566
I0526 09:59:54.266255 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.270566 (* 1 = 0.270566 loss)
I0526 09:59:54.266263 15394 sgd_solver.cpp:43] Iteration 36690, lr = 0.002
I0526 09:59:58.894466 15394 main.cpp:465] Iteration 36700, Testing net (#0)
I0526 10:00:11.980226 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8893
I0526 10:00:11.980268 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.335009 (* 1 = 0.335009 loss)
I0526 10:00:12.453793 15394 main.cpp:354] Iteration 36700, loss = 0.267425
I0526 10:00:12.453822 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.267424 (* 1 = 0.267424 loss)
I0526 10:00:12.453831 15394 sgd_solver.cpp:43] Iteration 36700, lr = 0.002
I0526 10:00:17.263990 15394 main.cpp:354] Iteration 36710, loss = 0.12507
I0526 10:00:17.264031 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.12507 (* 1 = 0.12507 loss)
I0526 10:00:17.264039 15394 sgd_solver.cpp:43] Iteration 36710, lr = 0.002
I0526 10:00:22.200676 15394 main.cpp:354] Iteration 36720, loss = 0.141371
I0526 10:00:22.200717 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.14137 (* 1 = 0.14137 loss)
I0526 10:00:22.200724 15394 sgd_solver.cpp:43] Iteration 36720, lr = 0.002
I0526 10:00:27.098486 15394 main.cpp:354] Iteration 36730, loss = 0.413614
I0526 10:00:27.098526 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.413614 (* 1 = 0.413614 loss)
I0526 10:00:27.098531 15394 sgd_solver.cpp:43] Iteration 36730, lr = 0.002
I0526 10:00:32.188354 15394 main.cpp:354] Iteration 36740, loss = 0.139175
I0526 10:00:32.188395 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.139175 (* 1 = 0.139175 loss)
I0526 10:00:32.188402 15394 sgd_solver.cpp:43] Iteration 36740, lr = 0.002
I0526 10:00:37.413951 15394 main.cpp:354] Iteration 36750, loss = 0.238354
I0526 10:00:37.413997 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.238354 (* 1 = 0.238354 loss)
I0526 10:00:37.414005 15394 sgd_solver.cpp:43] Iteration 36750, lr = 0.002
I0526 10:00:42.927542 15394 main.cpp:354] Iteration 36760, loss = 0.101744
I0526 10:00:42.927582 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.101744 (* 1 = 0.101744 loss)
I0526 10:00:42.927595 15394 sgd_solver.cpp:43] Iteration 36760, lr = 0.002
I0526 10:00:47.773104 15394 main.cpp:354] Iteration 36770, loss = 0.122845
I0526 10:00:47.773145 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.122844 (* 1 = 0.122844 loss)
I0526 10:00:47.773151 15394 sgd_solver.cpp:43] Iteration 36770, lr = 0.002
I0526 10:00:52.741078 15394 main.cpp:354] Iteration 36780, loss = 0.300326
I0526 10:00:52.741122 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.300325 (* 1 = 0.300325 loss)
I0526 10:00:52.741129 15394 sgd_solver.cpp:43] Iteration 36780, lr = 0.002
I0526 10:00:57.658006 15394 main.cpp:354] Iteration 36790, loss = 0.157882
I0526 10:00:57.658046 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.157882 (* 1 = 0.157882 loss)
I0526 10:00:57.658053 15394 sgd_solver.cpp:43] Iteration 36790, lr = 0.002
I0526 10:01:02.693853 15394 main.cpp:465] Iteration 36800, Testing net (#0)
I0526 10:01:15.777628 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8898
I0526 10:01:15.777664 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.337254 (* 1 = 0.337254 loss)
I0526 10:01:16.280642 15394 main.cpp:354] Iteration 36800, loss = 0.215555
I0526 10:01:16.280678 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.215555 (* 1 = 0.215555 loss)
I0526 10:01:16.280685 15394 sgd_solver.cpp:43] Iteration 36800, lr = 0.002
I0526 10:01:21.530830 15394 main.cpp:354] Iteration 36810, loss = 0.427686
I0526 10:01:21.530872 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.427686 (* 1 = 0.427686 loss)
I0526 10:01:21.530879 15394 sgd_solver.cpp:43] Iteration 36810, lr = 0.002
I0526 10:01:26.768607 15394 main.cpp:354] Iteration 36820, loss = 0.199263
I0526 10:01:26.768649 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.199263 (* 1 = 0.199263 loss)
I0526 10:01:26.768656 15394 sgd_solver.cpp:43] Iteration 36820, lr = 0.002
I0526 10:01:31.623443 15394 main.cpp:354] Iteration 36830, loss = 0.226137
I0526 10:01:31.623483 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.226136 (* 1 = 0.226136 loss)
I0526 10:01:31.623489 15394 sgd_solver.cpp:43] Iteration 36830, lr = 0.002
I0526 10:01:36.637583 15394 main.cpp:354] Iteration 36840, loss = 0.21279
I0526 10:01:36.637624 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.212789 (* 1 = 0.212789 loss)
I0526 10:01:36.637631 15394 sgd_solver.cpp:43] Iteration 36840, lr = 0.002
I0526 10:01:42.169786 15394 main.cpp:354] Iteration 36850, loss = 0.203538
I0526 10:01:42.169823 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.203538 (* 1 = 0.203538 loss)
I0526 10:01:42.169831 15394 sgd_solver.cpp:43] Iteration 36850, lr = 0.002
I0526 10:01:47.751157 15394 main.cpp:354] Iteration 36860, loss = 0.218751
I0526 10:01:47.751197 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.218751 (* 1 = 0.218751 loss)
I0526 10:01:47.751204 15394 sgd_solver.cpp:43] Iteration 36860, lr = 0.002
I0526 10:01:53.017736 15394 main.cpp:354] Iteration 36870, loss = 0.22788
I0526 10:01:53.017781 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.22788 (* 1 = 0.22788 loss)
I0526 10:01:53.017786 15394 sgd_solver.cpp:43] Iteration 36870, lr = 0.002
I0526 10:01:58.453930 15394 main.cpp:354] Iteration 36880, loss = 0.204124
I0526 10:01:58.453969 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204124 (* 1 = 0.204124 loss)
I0526 10:01:58.453976 15394 sgd_solver.cpp:43] Iteration 36880, lr = 0.002
I0526 10:02:03.521247 15394 main.cpp:354] Iteration 36890, loss = 0.294878
I0526 10:02:03.521286 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.294878 (* 1 = 0.294878 loss)
I0526 10:02:03.521292 15394 sgd_solver.cpp:43] Iteration 36890, lr = 0.002
I0526 10:02:07.871938 15394 main.cpp:465] Iteration 36900, Testing net (#0)
I0526 10:02:20.952337 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8905
I0526 10:02:20.952375 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.341387 (* 1 = 0.341387 loss)
I0526 10:02:21.455020 15394 main.cpp:354] Iteration 36900, loss = 0.124177
I0526 10:02:21.455059 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.124176 (* 1 = 0.124176 loss)
I0526 10:02:21.455065 15394 sgd_solver.cpp:43] Iteration 36900, lr = 0.002
I0526 10:02:26.472975 15394 main.cpp:354] Iteration 36910, loss = 0.137783
I0526 10:02:26.473014 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.137783 (* 1 = 0.137783 loss)
I0526 10:02:26.473021 15394 sgd_solver.cpp:43] Iteration 36910, lr = 0.002
I0526 10:02:31.738922 15394 main.cpp:354] Iteration 36920, loss = 0.193704
I0526 10:02:31.738953 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.193703 (* 1 = 0.193703 loss)
I0526 10:02:31.738960 15394 sgd_solver.cpp:43] Iteration 36920, lr = 0.002
I0526 10:02:36.853888 15394 main.cpp:354] Iteration 36930, loss = 0.428181
I0526 10:02:36.853930 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.428181 (* 1 = 0.428181 loss)
I0526 10:02:36.853936 15394 sgd_solver.cpp:43] Iteration 36930, lr = 0.002
I0526 10:02:41.913864 15394 main.cpp:354] Iteration 36940, loss = 0.188323
I0526 10:02:41.913902 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.188323 (* 1 = 0.188323 loss)
I0526 10:02:41.913909 15394 sgd_solver.cpp:43] Iteration 36940, lr = 0.002
I0526 10:02:47.278980 15394 main.cpp:354] Iteration 36950, loss = 0.212737
I0526 10:02:47.279018 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.212736 (* 1 = 0.212736 loss)
I0526 10:02:47.279024 15394 sgd_solver.cpp:43] Iteration 36950, lr = 0.002
I0526 10:02:52.225476 15394 main.cpp:354] Iteration 36960, loss = 0.384236
I0526 10:02:52.225520 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.384236 (* 1 = 0.384236 loss)
I0526 10:02:52.225527 15394 sgd_solver.cpp:43] Iteration 36960, lr = 0.002
I0526 10:02:57.543109 15394 main.cpp:354] Iteration 36970, loss = 0.234175
I0526 10:02:57.543148 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.234174 (* 1 = 0.234174 loss)
I0526 10:02:57.543154 15394 sgd_solver.cpp:43] Iteration 36970, lr = 0.002
I0526 10:03:02.301692 15394 main.cpp:354] Iteration 36980, loss = 0.1991
I0526 10:03:02.301723 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.1991 (* 1 = 0.1991 loss)
I0526 10:03:02.301729 15394 sgd_solver.cpp:43] Iteration 36980, lr = 0.002
I0526 10:03:07.400419 15394 main.cpp:354] Iteration 36990, loss = 0.189141
I0526 10:03:07.400462 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.189141 (* 1 = 0.189141 loss)
I0526 10:03:07.400470 15394 sgd_solver.cpp:43] Iteration 36990, lr = 0.002
I0526 10:03:12.123623 15394 main.cpp:465] Iteration 37000, Testing net (#0)
I0526 10:03:25.210942 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8904
I0526 10:03:25.210983 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.342299 (* 1 = 0.342299 loss)
I0526 10:03:25.749985 15394 main.cpp:354] Iteration 37000, loss = 0.157081
I0526 10:03:25.750020 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.15708 (* 1 = 0.15708 loss)
I0526 10:03:25.750027 15394 sgd_solver.cpp:43] Iteration 37000, lr = 0.002
I0526 10:03:30.612548 15394 main.cpp:354] Iteration 37010, loss = 0.212524
I0526 10:03:30.612587 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.212523 (* 1 = 0.212523 loss)
I0526 10:03:30.612593 15394 sgd_solver.cpp:43] Iteration 37010, lr = 0.002
I0526 10:03:35.755934 15394 main.cpp:354] Iteration 37020, loss = 0.274094
I0526 10:03:35.755971 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.274093 (* 1 = 0.274093 loss)
I0526 10:03:35.755977 15394 sgd_solver.cpp:43] Iteration 37020, lr = 0.002
I0526 10:03:40.726063 15394 main.cpp:354] Iteration 37030, loss = 0.197104
I0526 10:03:40.726089 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.197104 (* 1 = 0.197104 loss)
I0526 10:03:40.726095 15394 sgd_solver.cpp:43] Iteration 37030, lr = 0.002
I0526 10:03:45.841955 15394 main.cpp:354] Iteration 37040, loss = 0.134405
I0526 10:03:45.842001 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.134405 (* 1 = 0.134405 loss)
I0526 10:03:45.842007 15394 sgd_solver.cpp:43] Iteration 37040, lr = 0.002
I0526 10:03:50.930462 15394 main.cpp:354] Iteration 37050, loss = 0.302218
I0526 10:03:50.930500 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.302218 (* 1 = 0.302218 loss)
I0526 10:03:50.930506 15394 sgd_solver.cpp:43] Iteration 37050, lr = 0.002
I0526 10:03:56.276046 15394 main.cpp:354] Iteration 37060, loss = 0.248911
I0526 10:03:56.276087 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.248911 (* 1 = 0.248911 loss)
I0526 10:03:56.276093 15394 sgd_solver.cpp:43] Iteration 37060, lr = 0.002
I0526 10:04:00.836752 15394 main.cpp:354] Iteration 37070, loss = 0.227973
I0526 10:04:00.836791 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.227973 (* 1 = 0.227973 loss)
I0526 10:04:00.836797 15394 sgd_solver.cpp:43] Iteration 37070, lr = 0.002
I0526 10:04:06.000133 15394 main.cpp:354] Iteration 37080, loss = 0.340014
I0526 10:04:06.000162 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.340014 (* 1 = 0.340014 loss)
I0526 10:04:06.000169 15394 sgd_solver.cpp:43] Iteration 37080, lr = 0.002
I0526 10:04:11.306509 15394 main.cpp:354] Iteration 37090, loss = 0.179133
I0526 10:04:11.306551 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.179133 (* 1 = 0.179133 loss)
I0526 10:04:11.306557 15394 sgd_solver.cpp:43] Iteration 37090, lr = 0.002
I0526 10:04:15.468273 15394 main.cpp:465] Iteration 37100, Testing net (#0)
I0526 10:04:28.551054 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8907
I0526 10:04:28.551097 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.338108 (* 1 = 0.338108 loss)
I0526 10:04:29.020056 15394 main.cpp:354] Iteration 37100, loss = 0.0955552
I0526 10:04:29.020098 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.095555 (* 1 = 0.095555 loss)
I0526 10:04:29.020105 15394 sgd_solver.cpp:43] Iteration 37100, lr = 0.002
I0526 10:04:33.779602 15394 main.cpp:354] Iteration 37110, loss = 0.178882
I0526 10:04:33.779640 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.178882 (* 1 = 0.178882 loss)
I0526 10:04:33.779646 15394 sgd_solver.cpp:43] Iteration 37110, lr = 0.002
I0526 10:04:39.146553 15394 main.cpp:354] Iteration 37120, loss = 0.101082
I0526 10:04:39.146595 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.101082 (* 1 = 0.101082 loss)
I0526 10:04:39.146601 15394 sgd_solver.cpp:43] Iteration 37120, lr = 0.002
I0526 10:04:44.383774 15394 main.cpp:354] Iteration 37130, loss = 0.162592
I0526 10:04:44.383810 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.162592 (* 1 = 0.162592 loss)
I0526 10:04:44.383816 15394 sgd_solver.cpp:43] Iteration 37130, lr = 0.002
I0526 10:04:49.581724 15394 main.cpp:354] Iteration 37140, loss = 0.16924
I0526 10:04:49.581763 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.169239 (* 1 = 0.169239 loss)
I0526 10:04:49.581768 15394 sgd_solver.cpp:43] Iteration 37140, lr = 0.002
I0526 10:04:54.222928 15394 main.cpp:354] Iteration 37150, loss = 0.164704
I0526 10:04:54.222970 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.164704 (* 1 = 0.164704 loss)
I0526 10:04:54.222975 15394 sgd_solver.cpp:43] Iteration 37150, lr = 0.002
I0526 10:04:59.467123 15394 main.cpp:354] Iteration 37160, loss = 0.172917
I0526 10:04:59.467165 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.172917 (* 1 = 0.172917 loss)
I0526 10:04:59.467172 15394 sgd_solver.cpp:43] Iteration 37160, lr = 0.002
I0526 10:05:05.088112 15394 main.cpp:354] Iteration 37170, loss = 0.222701
I0526 10:05:05.088153 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.222701 (* 1 = 0.222701 loss)
I0526 10:05:05.088158 15394 sgd_solver.cpp:43] Iteration 37170, lr = 0.002
I0526 10:05:10.323132 15394 main.cpp:354] Iteration 37180, loss = 0.200716
I0526 10:05:10.323174 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.200715 (* 1 = 0.200715 loss)
I0526 10:05:10.323185 15394 sgd_solver.cpp:43] Iteration 37180, lr = 0.002
I0526 10:05:15.745900 15394 main.cpp:354] Iteration 37190, loss = 0.167441
I0526 10:05:15.745934 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.167441 (* 1 = 0.167441 loss)
I0526 10:05:15.745940 15394 sgd_solver.cpp:43] Iteration 37190, lr = 0.002
I0526 10:05:20.786819 15394 main.cpp:465] Iteration 37200, Testing net (#0)
I0526 10:05:33.867925 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8905
I0526 10:05:33.867969 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.3375 (* 1 = 0.3375 loss)
I0526 10:05:34.302698 15394 main.cpp:354] Iteration 37200, loss = 0.359023
I0526 10:05:34.302739 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.359023 (* 1 = 0.359023 loss)
I0526 10:05:34.302747 15394 sgd_solver.cpp:43] Iteration 37200, lr = 0.002
I0526 10:05:39.190623 15394 main.cpp:354] Iteration 37210, loss = 0.296607
I0526 10:05:39.190668 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.296607 (* 1 = 0.296607 loss)
I0526 10:05:39.190687 15394 sgd_solver.cpp:43] Iteration 37210, lr = 0.002
I0526 10:05:43.916647 15394 main.cpp:354] Iteration 37220, loss = 0.234326
I0526 10:05:43.916684 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.234326 (* 1 = 0.234326 loss)
I0526 10:05:43.916692 15394 sgd_solver.cpp:43] Iteration 37220, lr = 0.002
I0526 10:05:48.704035 15394 main.cpp:354] Iteration 37230, loss = 0.228358
I0526 10:05:48.704071 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.228358 (* 1 = 0.228358 loss)
I0526 10:05:48.704077 15394 sgd_solver.cpp:43] Iteration 37230, lr = 0.002
I0526 10:05:54.037936 15394 main.cpp:354] Iteration 37240, loss = 0.14665
I0526 10:05:54.037979 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.14665 (* 1 = 0.14665 loss)
I0526 10:05:54.037986 15394 sgd_solver.cpp:43] Iteration 37240, lr = 0.002
I0526 10:05:59.406051 15394 main.cpp:354] Iteration 37250, loss = 0.131652
I0526 10:05:59.406078 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.131652 (* 1 = 0.131652 loss)
I0526 10:05:59.406085 15394 sgd_solver.cpp:43] Iteration 37250, lr = 0.002
I0526 10:06:04.414338 15394 main.cpp:354] Iteration 37260, loss = 0.168788
I0526 10:06:04.414393 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.168788 (* 1 = 0.168788 loss)
I0526 10:06:04.414399 15394 sgd_solver.cpp:43] Iteration 37260, lr = 0.002
I0526 10:06:09.032238 15394 main.cpp:354] Iteration 37270, loss = 0.146852
I0526 10:06:09.032280 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.146851 (* 1 = 0.146851 loss)
I0526 10:06:09.032287 15394 sgd_solver.cpp:43] Iteration 37270, lr = 0.002
I0526 10:06:14.551882 15394 main.cpp:354] Iteration 37280, loss = 0.335781
I0526 10:06:14.551930 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.335781 (* 1 = 0.335781 loss)
I0526 10:06:14.551939 15394 sgd_solver.cpp:43] Iteration 37280, lr = 0.002
I0526 10:06:20.021695 15394 main.cpp:354] Iteration 37290, loss = 0.146502
I0526 10:06:20.021735 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.146502 (* 1 = 0.146502 loss)
I0526 10:06:20.021742 15394 sgd_solver.cpp:43] Iteration 37290, lr = 0.002
I0526 10:06:24.510742 15394 main.cpp:465] Iteration 37300, Testing net (#0)
I0526 10:06:37.600549 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8918
I0526 10:06:37.600589 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.337037 (* 1 = 0.337037 loss)
I0526 10:06:38.068891 15394 main.cpp:354] Iteration 37300, loss = 0.277732
I0526 10:06:38.068928 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.277732 (* 1 = 0.277732 loss)
I0526 10:06:38.068935 15394 sgd_solver.cpp:43] Iteration 37300, lr = 0.002
I0526 10:06:42.920120 15394 main.cpp:354] Iteration 37310, loss = 0.241247
I0526 10:06:42.920159 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.241247 (* 1 = 0.241247 loss)
I0526 10:06:42.920166 15394 sgd_solver.cpp:43] Iteration 37310, lr = 0.002
I0526 10:06:47.932858 15394 main.cpp:354] Iteration 37320, loss = 0.276761
I0526 10:06:47.932900 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.27676 (* 1 = 0.27676 loss)
I0526 10:06:47.932907 15394 sgd_solver.cpp:43] Iteration 37320, lr = 0.002
I0526 10:06:53.391800 15394 main.cpp:354] Iteration 37330, loss = 0.248686
I0526 10:06:53.391842 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.248686 (* 1 = 0.248686 loss)
I0526 10:06:53.391849 15394 sgd_solver.cpp:43] Iteration 37330, lr = 0.002
I0526 10:06:58.341176 15394 main.cpp:354] Iteration 37340, loss = 0.199761
I0526 10:06:58.341213 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.199761 (* 1 = 0.199761 loss)
I0526 10:06:58.341219 15394 sgd_solver.cpp:43] Iteration 37340, lr = 0.002
I0526 10:07:03.360003 15394 main.cpp:354] Iteration 37350, loss = 0.365402
I0526 10:07:03.360043 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.365402 (* 1 = 0.365402 loss)
I0526 10:07:03.360049 15394 sgd_solver.cpp:43] Iteration 37350, lr = 0.002
I0526 10:07:08.652133 15394 main.cpp:354] Iteration 37360, loss = 0.190761
I0526 10:07:08.652174 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.190761 (* 1 = 0.190761 loss)
I0526 10:07:08.652181 15394 sgd_solver.cpp:43] Iteration 37360, lr = 0.002
I0526 10:07:13.879472 15394 main.cpp:354] Iteration 37370, loss = 0.193985
I0526 10:07:13.879509 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.193985 (* 1 = 0.193985 loss)
I0526 10:07:13.879515 15394 sgd_solver.cpp:43] Iteration 37370, lr = 0.002
I0526 10:07:18.211573 15394 main.cpp:354] Iteration 37380, loss = 0.54975
I0526 10:07:18.211612 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.54975 (* 1 = 0.54975 loss)
I0526 10:07:18.211617 15394 sgd_solver.cpp:43] Iteration 37380, lr = 0.002
I0526 10:07:23.238085 15394 main.cpp:354] Iteration 37390, loss = 0.169777
I0526 10:07:23.238127 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.169777 (* 1 = 0.169777 loss)
I0526 10:07:23.238133 15394 sgd_solver.cpp:43] Iteration 37390, lr = 0.002
I0526 10:07:28.143227 15394 main.cpp:465] Iteration 37400, Testing net (#0)
I0526 10:07:41.227886 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8941
I0526 10:07:41.227926 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.335905 (* 1 = 0.335905 loss)
I0526 10:07:41.662297 15394 main.cpp:354] Iteration 37400, loss = 0.308541
I0526 10:07:41.662344 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.30854 (* 1 = 0.30854 loss)
I0526 10:07:41.662356 15394 sgd_solver.cpp:43] Iteration 37400, lr = 0.002
I0526 10:07:46.850206 15394 main.cpp:354] Iteration 37410, loss = 0.320226
I0526 10:07:46.850234 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.320225 (* 1 = 0.320225 loss)
I0526 10:07:46.850239 15394 sgd_solver.cpp:43] Iteration 37410, lr = 0.002
I0526 10:07:52.070893 15394 main.cpp:354] Iteration 37420, loss = 0.3178
I0526 10:07:52.070932 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.3178 (* 1 = 0.3178 loss)
I0526 10:07:52.070940 15394 sgd_solver.cpp:43] Iteration 37420, lr = 0.002
I0526 10:07:56.923851 15394 main.cpp:354] Iteration 37430, loss = 0.232907
I0526 10:07:56.923892 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.232906 (* 1 = 0.232906 loss)
I0526 10:07:56.923898 15394 sgd_solver.cpp:43] Iteration 37430, lr = 0.002
I0526 10:08:01.903405 15394 main.cpp:354] Iteration 37440, loss = 0.262193
I0526 10:08:01.903442 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.262193 (* 1 = 0.262193 loss)
I0526 10:08:01.903450 15394 sgd_solver.cpp:43] Iteration 37440, lr = 0.002
I0526 10:08:06.612084 15394 main.cpp:354] Iteration 37450, loss = 0.138846
I0526 10:08:06.612128 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.138846 (* 1 = 0.138846 loss)
I0526 10:08:06.612136 15394 sgd_solver.cpp:43] Iteration 37450, lr = 0.002
I0526 10:08:11.575438 15394 main.cpp:354] Iteration 37460, loss = 0.19962
I0526 10:08:11.575484 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.19962 (* 1 = 0.19962 loss)
I0526 10:08:11.575491 15394 sgd_solver.cpp:43] Iteration 37460, lr = 0.002
I0526 10:08:16.590064 15394 main.cpp:354] Iteration 37470, loss = 0.183974
I0526 10:08:16.590103 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.183973 (* 1 = 0.183973 loss)
I0526 10:08:16.590111 15394 sgd_solver.cpp:43] Iteration 37470, lr = 0.002
I0526 10:08:21.571823 15394 main.cpp:354] Iteration 37480, loss = 0.187372
I0526 10:08:21.571866 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187372 (* 1 = 0.187372 loss)
I0526 10:08:21.571873 15394 sgd_solver.cpp:43] Iteration 37480, lr = 0.002
I0526 10:08:26.276638 15394 main.cpp:354] Iteration 37490, loss = 0.14237
I0526 10:08:26.276677 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.14237 (* 1 = 0.14237 loss)
I0526 10:08:26.276684 15394 sgd_solver.cpp:43] Iteration 37490, lr = 0.002
I0526 10:08:30.822644 15394 main.cpp:465] Iteration 37500, Testing net (#0)
I0526 10:08:43.898723 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8943
I0526 10:08:43.898761 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.327981 (* 1 = 0.327981 loss)
I0526 10:08:44.401599 15394 main.cpp:354] Iteration 37500, loss = 0.136131
I0526 10:08:44.401635 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.136131 (* 1 = 0.136131 loss)
I0526 10:08:44.401643 15394 sgd_solver.cpp:43] Iteration 37500, lr = 0.002
I0526 10:08:49.185992 15394 main.cpp:354] Iteration 37510, loss = 0.20548
I0526 10:08:49.186029 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.20548 (* 1 = 0.20548 loss)
I0526 10:08:49.186035 15394 sgd_solver.cpp:43] Iteration 37510, lr = 0.002
I0526 10:08:54.429512 15394 main.cpp:354] Iteration 37520, loss = 0.139126
I0526 10:08:54.429554 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.139125 (* 1 = 0.139125 loss)
I0526 10:08:54.429561 15394 sgd_solver.cpp:43] Iteration 37520, lr = 0.002
I0526 10:08:59.180836 15394 main.cpp:354] Iteration 37530, loss = 0.231549
I0526 10:08:59.180874 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.231548 (* 1 = 0.231548 loss)
I0526 10:08:59.180881 15394 sgd_solver.cpp:43] Iteration 37530, lr = 0.002
I0526 10:09:03.937068 15394 main.cpp:354] Iteration 37540, loss = 0.448559
I0526 10:09:03.937105 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.448559 (* 1 = 0.448559 loss)
I0526 10:09:03.937111 15394 sgd_solver.cpp:43] Iteration 37540, lr = 0.002
I0526 10:09:08.851894 15394 main.cpp:354] Iteration 37550, loss = 0.292325
I0526 10:09:08.851930 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.292325 (* 1 = 0.292325 loss)
I0526 10:09:08.851938 15394 sgd_solver.cpp:43] Iteration 37550, lr = 0.002
I0526 10:09:13.365506 15394 main.cpp:354] Iteration 37560, loss = 0.0972948
I0526 10:09:13.365545 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0972946 (* 1 = 0.0972946 loss)
I0526 10:09:13.365551 15394 sgd_solver.cpp:43] Iteration 37560, lr = 0.002
I0526 10:09:18.238508 15394 main.cpp:354] Iteration 37570, loss = 0.313569
I0526 10:09:18.238548 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.313569 (* 1 = 0.313569 loss)
I0526 10:09:18.238554 15394 sgd_solver.cpp:43] Iteration 37570, lr = 0.002
I0526 10:09:23.469481 15394 main.cpp:354] Iteration 37580, loss = 0.158321
I0526 10:09:23.469523 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.158321 (* 1 = 0.158321 loss)
I0526 10:09:23.469530 15394 sgd_solver.cpp:43] Iteration 37580, lr = 0.002
I0526 10:09:28.766909 15394 main.cpp:354] Iteration 37590, loss = 0.136437
I0526 10:09:28.766948 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.136437 (* 1 = 0.136437 loss)
I0526 10:09:28.766968 15394 sgd_solver.cpp:43] Iteration 37590, lr = 0.002
I0526 10:09:33.684167 15394 main.cpp:465] Iteration 37600, Testing net (#0)
I0526 10:09:46.770764 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8877
I0526 10:09:46.770807 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.340541 (* 1 = 0.340541 loss)
I0526 10:09:47.204282 15394 main.cpp:354] Iteration 37600, loss = 0.211973
I0526 10:09:47.204320 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.211973 (* 1 = 0.211973 loss)
I0526 10:09:47.204327 15394 sgd_solver.cpp:43] Iteration 37600, lr = 0.002
I0526 10:09:52.425660 15394 main.cpp:354] Iteration 37610, loss = 0.198019
I0526 10:09:52.425704 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.198019 (* 1 = 0.198019 loss)
I0526 10:09:52.425709 15394 sgd_solver.cpp:43] Iteration 37610, lr = 0.002
I0526 10:09:57.565330 15394 main.cpp:354] Iteration 37620, loss = 0.204549
I0526 10:09:57.565367 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204548 (* 1 = 0.204548 loss)
I0526 10:09:57.565374 15394 sgd_solver.cpp:43] Iteration 37620, lr = 0.002
I0526 10:10:03.011960 15394 main.cpp:354] Iteration 37630, loss = 0.245773
I0526 10:10:03.011996 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.245773 (* 1 = 0.245773 loss)
I0526 10:10:03.012002 15394 sgd_solver.cpp:43] Iteration 37630, lr = 0.002
I0526 10:10:08.371433 15394 main.cpp:354] Iteration 37640, loss = 0.181975
I0526 10:10:08.371475 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.181975 (* 1 = 0.181975 loss)
I0526 10:10:08.371481 15394 sgd_solver.cpp:43] Iteration 37640, lr = 0.002
I0526 10:10:13.166621 15394 main.cpp:354] Iteration 37650, loss = 0.504354
I0526 10:10:13.166661 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.504354 (* 1 = 0.504354 loss)
I0526 10:10:13.166667 15394 sgd_solver.cpp:43] Iteration 37650, lr = 0.002
I0526 10:10:18.326068 15394 main.cpp:354] Iteration 37660, loss = 0.293847
I0526 10:10:18.326099 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.293847 (* 1 = 0.293847 loss)
I0526 10:10:18.326107 15394 sgd_solver.cpp:43] Iteration 37660, lr = 0.002
I0526 10:10:23.117640 15394 main.cpp:354] Iteration 37670, loss = 0.266709
I0526 10:10:23.117683 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.266709 (* 1 = 0.266709 loss)
I0526 10:10:23.117689 15394 sgd_solver.cpp:43] Iteration 37670, lr = 0.002
I0526 10:10:28.225020 15394 main.cpp:354] Iteration 37680, loss = 0.304302
I0526 10:10:28.225060 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.304302 (* 1 = 0.304302 loss)
I0526 10:10:28.225067 15394 sgd_solver.cpp:43] Iteration 37680, lr = 0.002
I0526 10:10:33.753329 15394 main.cpp:354] Iteration 37690, loss = 0.192377
I0526 10:10:33.753367 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.192377 (* 1 = 0.192377 loss)
I0526 10:10:33.753374 15394 sgd_solver.cpp:43] Iteration 37690, lr = 0.002
I0526 10:10:38.859887 15394 main.cpp:465] Iteration 37700, Testing net (#0)
I0526 10:10:51.938812 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8895
I0526 10:10:51.938851 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.340352 (* 1 = 0.340352 loss)
I0526 10:10:52.481863 15394 main.cpp:354] Iteration 37700, loss = 0.21564
I0526 10:10:52.481896 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.21564 (* 1 = 0.21564 loss)
I0526 10:10:52.481904 15394 sgd_solver.cpp:43] Iteration 37700, lr = 0.002
I0526 10:10:57.699434 15394 main.cpp:354] Iteration 37710, loss = 0.21298
I0526 10:10:57.699476 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.21298 (* 1 = 0.21298 loss)
I0526 10:10:57.699482 15394 sgd_solver.cpp:43] Iteration 37710, lr = 0.002
I0526 10:11:03.130128 15394 main.cpp:354] Iteration 37720, loss = 0.19667
I0526 10:11:03.130167 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.19667 (* 1 = 0.19667 loss)
I0526 10:11:03.130173 15394 sgd_solver.cpp:43] Iteration 37720, lr = 0.002
I0526 10:11:07.976896 15394 main.cpp:354] Iteration 37730, loss = 0.190574
I0526 10:11:07.976936 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.190574 (* 1 = 0.190574 loss)
I0526 10:11:07.976943 15394 sgd_solver.cpp:43] Iteration 37730, lr = 0.002
I0526 10:11:12.828371 15394 main.cpp:354] Iteration 37740, loss = 0.394531
I0526 10:11:12.828409 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.39453 (* 1 = 0.39453 loss)
I0526 10:11:12.828415 15394 sgd_solver.cpp:43] Iteration 37740, lr = 0.002
I0526 10:11:17.957475 15394 main.cpp:354] Iteration 37750, loss = 0.189011
I0526 10:11:17.957516 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.189011 (* 1 = 0.189011 loss)
I0526 10:11:17.957523 15394 sgd_solver.cpp:43] Iteration 37750, lr = 0.002
I0526 10:11:23.196084 15394 main.cpp:354] Iteration 37760, loss = 0.24826
I0526 10:11:23.196126 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.24826 (* 1 = 0.24826 loss)
I0526 10:11:23.196132 15394 sgd_solver.cpp:43] Iteration 37760, lr = 0.002
I0526 10:11:28.508095 15394 main.cpp:354] Iteration 37770, loss = 0.283621
I0526 10:11:28.508134 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.28362 (* 1 = 0.28362 loss)
I0526 10:11:28.508141 15394 sgd_solver.cpp:43] Iteration 37770, lr = 0.002
I0526 10:11:33.425559 15394 main.cpp:354] Iteration 37780, loss = 0.237761
I0526 10:11:33.425600 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.23776 (* 1 = 0.23776 loss)
I0526 10:11:33.425606 15394 sgd_solver.cpp:43] Iteration 37780, lr = 0.002
I0526 10:11:38.436187 15394 main.cpp:354] Iteration 37790, loss = 0.168757
I0526 10:11:38.436228 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.168757 (* 1 = 0.168757 loss)
I0526 10:11:38.436234 15394 sgd_solver.cpp:43] Iteration 37790, lr = 0.002
I0526 10:11:43.020347 15394 main.cpp:465] Iteration 37800, Testing net (#0)
I0526 10:11:56.101117 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8837
I0526 10:11:56.101168 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.35177 (* 1 = 0.35177 loss)
I0526 10:11:56.608245 15394 main.cpp:354] Iteration 37800, loss = 0.197105
I0526 10:11:56.608289 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.197104 (* 1 = 0.197104 loss)
I0526 10:11:56.608296 15394 sgd_solver.cpp:43] Iteration 37800, lr = 0.002
I0526 10:12:02.027704 15394 main.cpp:354] Iteration 37810, loss = 0.284888
I0526 10:12:02.027745 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.284888 (* 1 = 0.284888 loss)
I0526 10:12:02.027751 15394 sgd_solver.cpp:43] Iteration 37810, lr = 0.002
I0526 10:12:07.239547 15394 main.cpp:354] Iteration 37820, loss = 0.415793
I0526 10:12:07.239589 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.415793 (* 1 = 0.415793 loss)
I0526 10:12:07.239596 15394 sgd_solver.cpp:43] Iteration 37820, lr = 0.002
I0526 10:12:12.316668 15394 main.cpp:354] Iteration 37830, loss = 0.14886
I0526 10:12:12.316706 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.148859 (* 1 = 0.148859 loss)
I0526 10:12:12.316712 15394 sgd_solver.cpp:43] Iteration 37830, lr = 0.002
I0526 10:12:17.487254 15394 main.cpp:354] Iteration 37840, loss = 0.0783224
I0526 10:12:17.487293 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0783221 (* 1 = 0.0783221 loss)
I0526 10:12:17.487299 15394 sgd_solver.cpp:43] Iteration 37840, lr = 0.002
I0526 10:12:22.851508 15394 main.cpp:354] Iteration 37850, loss = 0.257858
I0526 10:12:22.851549 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.257858 (* 1 = 0.257858 loss)
I0526 10:12:22.851555 15394 sgd_solver.cpp:43] Iteration 37850, lr = 0.002
I0526 10:12:27.781453 15394 main.cpp:354] Iteration 37860, loss = 0.136001
I0526 10:12:27.781491 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.136001 (* 1 = 0.136001 loss)
I0526 10:12:27.781498 15394 sgd_solver.cpp:43] Iteration 37860, lr = 0.002
I0526 10:12:32.788470 15394 main.cpp:354] Iteration 37870, loss = 0.192158
I0526 10:12:32.788509 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.192158 (* 1 = 0.192158 loss)
I0526 10:12:32.788516 15394 sgd_solver.cpp:43] Iteration 37870, lr = 0.002
I0526 10:12:37.637152 15394 main.cpp:354] Iteration 37880, loss = 0.215019
I0526 10:12:37.637202 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.215019 (* 1 = 0.215019 loss)
I0526 10:12:37.637209 15394 sgd_solver.cpp:43] Iteration 37880, lr = 0.002
I0526 10:12:42.682411 15394 main.cpp:354] Iteration 37890, loss = 0.254162
I0526 10:12:42.682453 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.254161 (* 1 = 0.254161 loss)
I0526 10:12:42.682461 15394 sgd_solver.cpp:43] Iteration 37890, lr = 0.002
I0526 10:12:47.139416 15394 main.cpp:465] Iteration 37900, Testing net (#0)
I0526 10:13:00.222955 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8883
I0526 10:13:00.223000 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.344478 (* 1 = 0.344478 loss)
I0526 10:13:00.725515 15394 main.cpp:354] Iteration 37900, loss = 0.200101
I0526 10:13:00.725556 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.2001 (* 1 = 0.2001 loss)
I0526 10:13:00.725564 15394 sgd_solver.cpp:43] Iteration 37900, lr = 0.002
I0526 10:13:06.062382 15394 main.cpp:354] Iteration 37910, loss = 0.107673
I0526 10:13:06.062422 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.107673 (* 1 = 0.107673 loss)
I0526 10:13:06.062429 15394 sgd_solver.cpp:43] Iteration 37910, lr = 0.002
I0526 10:13:11.506115 15394 main.cpp:354] Iteration 37920, loss = 0.163319
I0526 10:13:11.506160 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.163319 (* 1 = 0.163319 loss)
I0526 10:13:11.506168 15394 sgd_solver.cpp:43] Iteration 37920, lr = 0.002
I0526 10:13:16.918860 15394 main.cpp:354] Iteration 37930, loss = 0.343361
I0526 10:13:16.918902 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.343361 (* 1 = 0.343361 loss)
I0526 10:13:16.918910 15394 sgd_solver.cpp:43] Iteration 37930, lr = 0.002
I0526 10:13:21.812515 15394 main.cpp:354] Iteration 37940, loss = 0.229756
I0526 10:13:21.812559 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.229756 (* 1 = 0.229756 loss)
I0526 10:13:21.812566 15394 sgd_solver.cpp:43] Iteration 37940, lr = 0.002
I0526 10:13:26.668365 15394 main.cpp:354] Iteration 37950, loss = 0.207966
I0526 10:13:26.668402 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.207966 (* 1 = 0.207966 loss)
I0526 10:13:26.668408 15394 sgd_solver.cpp:43] Iteration 37950, lr = 0.002
I0526 10:13:31.810294 15394 main.cpp:354] Iteration 37960, loss = 0.401437
I0526 10:13:31.810344 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.401437 (* 1 = 0.401437 loss)
I0526 10:13:31.810351 15394 sgd_solver.cpp:43] Iteration 37960, lr = 0.002
I0526 10:13:36.659781 15394 main.cpp:354] Iteration 37970, loss = 0.194036
I0526 10:13:36.659824 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.194036 (* 1 = 0.194036 loss)
I0526 10:13:36.659832 15394 sgd_solver.cpp:43] Iteration 37970, lr = 0.002
I0526 10:13:42.193711 15394 main.cpp:354] Iteration 37980, loss = 0.201761
I0526 10:13:42.193752 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.20176 (* 1 = 0.20176 loss)
I0526 10:13:42.193758 15394 sgd_solver.cpp:43] Iteration 37980, lr = 0.002
I0526 10:13:47.561543 15394 main.cpp:354] Iteration 37990, loss = 0.159383
I0526 10:13:47.561584 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.159382 (* 1 = 0.159382 loss)
I0526 10:13:47.561591 15394 sgd_solver.cpp:43] Iteration 37990, lr = 0.002
I0526 10:13:52.571014 15394 main.cpp:465] Iteration 38000, Testing net (#0)
I0526 10:14:05.651464 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8881
I0526 10:14:05.651502 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.341564 (* 1 = 0.341564 loss)
I0526 10:14:06.160692 15394 main.cpp:354] Iteration 38000, loss = 0.131574
I0526 10:14:06.160729 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.131574 (* 1 = 0.131574 loss)
I0526 10:14:06.160737 15394 sgd_solver.cpp:43] Iteration 38000, lr = 0.002
I0526 10:14:11.640664 15394 main.cpp:354] Iteration 38010, loss = 0.237024
I0526 10:14:11.640703 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.237024 (* 1 = 0.237024 loss)
I0526 10:14:11.640715 15394 sgd_solver.cpp:43] Iteration 38010, lr = 0.002
I0526 10:14:16.649852 15394 main.cpp:354] Iteration 38020, loss = 0.194274
I0526 10:14:16.649891 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.194273 (* 1 = 0.194273 loss)
I0526 10:14:16.649899 15394 sgd_solver.cpp:43] Iteration 38020, lr = 0.002
I0526 10:14:21.912586 15394 main.cpp:354] Iteration 38030, loss = 0.213879
I0526 10:14:21.912628 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.213878 (* 1 = 0.213878 loss)
I0526 10:14:21.912636 15394 sgd_solver.cpp:43] Iteration 38030, lr = 0.002
I0526 10:14:26.812902 15394 main.cpp:354] Iteration 38040, loss = 0.199186
I0526 10:14:26.812943 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.199186 (* 1 = 0.199186 loss)
I0526 10:14:26.812952 15394 sgd_solver.cpp:43] Iteration 38040, lr = 0.002
I0526 10:14:32.112469 15394 main.cpp:354] Iteration 38050, loss = 0.412368
I0526 10:14:32.112509 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.412368 (* 1 = 0.412368 loss)
I0526 10:14:32.112515 15394 sgd_solver.cpp:43] Iteration 38050, lr = 0.002
I0526 10:14:36.991045 15394 main.cpp:354] Iteration 38060, loss = 0.875473
I0526 10:14:36.991086 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.875473 (* 1 = 0.875473 loss)
I0526 10:14:36.991092 15394 sgd_solver.cpp:43] Iteration 38060, lr = 0.002
I0526 10:14:42.517093 15394 main.cpp:354] Iteration 38070, loss = 0.140812
I0526 10:14:42.517133 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.140811 (* 1 = 0.140811 loss)
I0526 10:14:42.517140 15394 sgd_solver.cpp:43] Iteration 38070, lr = 0.002
I0526 10:14:47.180259 15394 main.cpp:354] Iteration 38080, loss = 0.307974
I0526 10:14:47.180297 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.307974 (* 1 = 0.307974 loss)
I0526 10:14:47.180305 15394 sgd_solver.cpp:43] Iteration 38080, lr = 0.002
I0526 10:14:52.711972 15394 main.cpp:354] Iteration 38090, loss = 0.190137
I0526 10:14:52.712014 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.190136 (* 1 = 0.190136 loss)
I0526 10:14:52.712021 15394 sgd_solver.cpp:43] Iteration 38090, lr = 0.002
I0526 10:14:57.441035 15394 main.cpp:465] Iteration 38100, Testing net (#0)
I0526 10:15:10.524035 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8913
I0526 10:15:10.524075 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.342182 (* 1 = 0.342182 loss)
I0526 10:15:10.990144 15394 main.cpp:354] Iteration 38100, loss = 0.235114
I0526 10:15:10.990185 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235114 (* 1 = 0.235114 loss)
I0526 10:15:10.990195 15394 sgd_solver.cpp:43] Iteration 38100, lr = 0.002
I0526 10:15:16.530943 15394 main.cpp:354] Iteration 38110, loss = 0.103777
I0526 10:15:16.530982 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.103777 (* 1 = 0.103777 loss)
I0526 10:15:16.530988 15394 sgd_solver.cpp:43] Iteration 38110, lr = 0.002
I0526 10:15:21.468979 15394 main.cpp:354] Iteration 38120, loss = 0.181348
I0526 10:15:21.469022 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.181348 (* 1 = 0.181348 loss)
I0526 10:15:21.469030 15394 sgd_solver.cpp:43] Iteration 38120, lr = 0.002
I0526 10:15:26.475091 15394 main.cpp:354] Iteration 38130, loss = 0.462876
I0526 10:15:26.475131 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.462876 (* 1 = 0.462876 loss)
I0526 10:15:26.475136 15394 sgd_solver.cpp:43] Iteration 38130, lr = 0.002
I0526 10:15:31.155505 15394 main.cpp:354] Iteration 38140, loss = 0.24696
I0526 10:15:31.155545 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.24696 (* 1 = 0.24696 loss)
I0526 10:15:31.155551 15394 sgd_solver.cpp:43] Iteration 38140, lr = 0.002
I0526 10:15:36.264158 15394 main.cpp:354] Iteration 38150, loss = 0.384789
I0526 10:15:36.264196 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.384789 (* 1 = 0.384789 loss)
I0526 10:15:36.264204 15394 sgd_solver.cpp:43] Iteration 38150, lr = 0.002
I0526 10:15:41.485939 15394 main.cpp:354] Iteration 38160, loss = 0.133639
I0526 10:15:41.485982 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.133639 (* 1 = 0.133639 loss)
I0526 10:15:41.485991 15394 sgd_solver.cpp:43] Iteration 38160, lr = 0.002
I0526 10:15:46.357548 15394 main.cpp:354] Iteration 38170, loss = 0.0849355
I0526 10:15:46.357588 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0849353 (* 1 = 0.0849353 loss)
I0526 10:15:46.357594 15394 sgd_solver.cpp:43] Iteration 38170, lr = 0.002
I0526 10:15:51.778069 15394 main.cpp:354] Iteration 38180, loss = 0.240422
I0526 10:15:51.778112 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.240422 (* 1 = 0.240422 loss)
I0526 10:15:51.778120 15394 sgd_solver.cpp:43] Iteration 38180, lr = 0.002
I0526 10:15:56.912755 15394 main.cpp:354] Iteration 38190, loss = 0.110171
I0526 10:15:56.912793 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.11017 (* 1 = 0.11017 loss)
I0526 10:15:56.912801 15394 sgd_solver.cpp:43] Iteration 38190, lr = 0.002
I0526 10:16:01.145041 15394 main.cpp:465] Iteration 38200, Testing net (#0)
I0526 10:16:14.227839 15394 main.cpp:532]     Test net output #0: Accuracy = 0.892
I0526 10:16:14.227880 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.333706 (* 1 = 0.333706 loss)
I0526 10:16:14.671489 15394 main.cpp:354] Iteration 38200, loss = 0.227844
I0526 10:16:14.671527 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.227843 (* 1 = 0.227843 loss)
I0526 10:16:14.671535 15394 sgd_solver.cpp:43] Iteration 38200, lr = 0.002
I0526 10:16:19.548302 15394 main.cpp:354] Iteration 38210, loss = 0.345182
I0526 10:16:19.548353 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.345182 (* 1 = 0.345182 loss)
I0526 10:16:19.548360 15394 sgd_solver.cpp:43] Iteration 38210, lr = 0.002
I0526 10:16:24.443799 15394 main.cpp:354] Iteration 38220, loss = 0.166942
I0526 10:16:24.443840 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.166942 (* 1 = 0.166942 loss)
I0526 10:16:24.443845 15394 sgd_solver.cpp:43] Iteration 38220, lr = 0.002
I0526 10:16:29.306475 15394 main.cpp:354] Iteration 38230, loss = 0.395414
I0526 10:16:29.306514 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.395414 (* 1 = 0.395414 loss)
I0526 10:16:29.306519 15394 sgd_solver.cpp:43] Iteration 38230, lr = 0.002
I0526 10:16:34.254413 15394 main.cpp:354] Iteration 38240, loss = 0.262968
I0526 10:16:34.254451 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.262968 (* 1 = 0.262968 loss)
I0526 10:16:34.254457 15394 sgd_solver.cpp:43] Iteration 38240, lr = 0.002
I0526 10:16:39.206591 15394 main.cpp:354] Iteration 38250, loss = 0.251034
I0526 10:16:39.206635 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.251034 (* 1 = 0.251034 loss)
I0526 10:16:39.206642 15394 sgd_solver.cpp:43] Iteration 38250, lr = 0.002
I0526 10:16:44.093371 15394 main.cpp:354] Iteration 38260, loss = 0.141844
I0526 10:16:44.093411 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.141844 (* 1 = 0.141844 loss)
I0526 10:16:44.093417 15394 sgd_solver.cpp:43] Iteration 38260, lr = 0.002
I0526 10:16:49.040814 15394 main.cpp:354] Iteration 38270, loss = 0.176117
I0526 10:16:49.040848 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.176116 (* 1 = 0.176116 loss)
I0526 10:16:49.040855 15394 sgd_solver.cpp:43] Iteration 38270, lr = 0.002
I0526 10:16:53.881652 15394 main.cpp:354] Iteration 38280, loss = 0.208352
I0526 10:16:53.881693 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.208351 (* 1 = 0.208351 loss)
I0526 10:16:53.881700 15394 sgd_solver.cpp:43] Iteration 38280, lr = 0.002
I0526 10:16:58.970252 15394 main.cpp:354] Iteration 38290, loss = 0.391924
I0526 10:16:58.970293 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.391923 (* 1 = 0.391923 loss)
I0526 10:16:58.970299 15394 sgd_solver.cpp:43] Iteration 38290, lr = 0.002
I0526 10:17:03.516188 15394 main.cpp:465] Iteration 38300, Testing net (#0)
I0526 10:17:16.598450 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8912
I0526 10:17:16.598489 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.331674 (* 1 = 0.331674 loss)
I0526 10:17:17.106710 15394 main.cpp:354] Iteration 38300, loss = 0.152276
I0526 10:17:17.106750 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.152276 (* 1 = 0.152276 loss)
I0526 10:17:17.106757 15394 sgd_solver.cpp:43] Iteration 38300, lr = 0.002
I0526 10:17:21.804133 15394 main.cpp:354] Iteration 38310, loss = 0.321654
I0526 10:17:21.804177 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.321653 (* 1 = 0.321653 loss)
I0526 10:17:21.804185 15394 sgd_solver.cpp:43] Iteration 38310, lr = 0.002
I0526 10:17:26.876070 15394 main.cpp:354] Iteration 38320, loss = 0.458171
I0526 10:17:26.876101 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.458171 (* 1 = 0.458171 loss)
I0526 10:17:26.876108 15394 sgd_solver.cpp:43] Iteration 38320, lr = 0.002
I0526 10:17:32.355478 15394 main.cpp:354] Iteration 38330, loss = 0.11454
I0526 10:17:32.355516 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.11454 (* 1 = 0.11454 loss)
I0526 10:17:32.355522 15394 sgd_solver.cpp:43] Iteration 38330, lr = 0.002
I0526 10:17:37.756345 15394 main.cpp:354] Iteration 38340, loss = 0.181911
I0526 10:17:37.756386 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.181911 (* 1 = 0.181911 loss)
I0526 10:17:37.756393 15394 sgd_solver.cpp:43] Iteration 38340, lr = 0.002
I0526 10:17:43.173233 15394 main.cpp:354] Iteration 38350, loss = 0.075701
I0526 10:17:43.173274 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0757008 (* 1 = 0.0757008 loss)
I0526 10:17:43.173280 15394 sgd_solver.cpp:43] Iteration 38350, lr = 0.002
I0526 10:17:48.043402 15394 main.cpp:354] Iteration 38360, loss = 0.377686
I0526 10:17:48.043442 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.377686 (* 1 = 0.377686 loss)
I0526 10:17:48.043448 15394 sgd_solver.cpp:43] Iteration 38360, lr = 0.002
I0526 10:17:52.640709 15394 main.cpp:354] Iteration 38370, loss = 0.180546
I0526 10:17:52.640754 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.180546 (* 1 = 0.180546 loss)
I0526 10:17:52.640761 15394 sgd_solver.cpp:43] Iteration 38370, lr = 0.002
I0526 10:17:57.909474 15394 main.cpp:354] Iteration 38380, loss = 0.264779
I0526 10:17:57.909514 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.264778 (* 1 = 0.264778 loss)
I0526 10:17:57.909521 15394 sgd_solver.cpp:43] Iteration 38380, lr = 0.002
I0526 10:18:02.818572 15394 main.cpp:354] Iteration 38390, loss = 0.288202
I0526 10:18:02.818613 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.288201 (* 1 = 0.288201 loss)
I0526 10:18:02.818619 15394 sgd_solver.cpp:43] Iteration 38390, lr = 0.002
I0526 10:18:07.296074 15394 main.cpp:465] Iteration 38400, Testing net (#0)
I0526 10:18:20.380424 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8876
I0526 10:18:20.380461 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.339653 (* 1 = 0.339653 loss)
I0526 10:18:20.846709 15394 main.cpp:354] Iteration 38400, loss = 0.271764
I0526 10:18:20.846750 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.271763 (* 1 = 0.271763 loss)
I0526 10:18:20.846757 15394 sgd_solver.cpp:43] Iteration 38400, lr = 0.002
I0526 10:18:25.921921 15394 main.cpp:354] Iteration 38410, loss = 0.288154
I0526 10:18:25.921959 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.288154 (* 1 = 0.288154 loss)
I0526 10:18:25.921967 15394 sgd_solver.cpp:43] Iteration 38410, lr = 0.002
I0526 10:18:30.812075 15394 main.cpp:354] Iteration 38420, loss = 0.538413
I0526 10:18:30.812114 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.538413 (* 1 = 0.538413 loss)
I0526 10:18:30.812120 15394 sgd_solver.cpp:43] Iteration 38420, lr = 0.002
I0526 10:18:35.920795 15394 main.cpp:354] Iteration 38430, loss = 0.26468
I0526 10:18:35.920835 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.26468 (* 1 = 0.26468 loss)
I0526 10:18:35.920846 15394 sgd_solver.cpp:43] Iteration 38430, lr = 0.002
I0526 10:18:40.277317 15394 main.cpp:354] Iteration 38440, loss = 0.236884
I0526 10:18:40.277359 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.236884 (* 1 = 0.236884 loss)
I0526 10:18:40.277364 15394 sgd_solver.cpp:43] Iteration 38440, lr = 0.002
I0526 10:18:45.543591 15394 main.cpp:354] Iteration 38450, loss = 0.195946
I0526 10:18:45.543629 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.195946 (* 1 = 0.195946 loss)
I0526 10:18:45.543635 15394 sgd_solver.cpp:43] Iteration 38450, lr = 0.002
I0526 10:18:50.854432 15394 main.cpp:354] Iteration 38460, loss = 0.18977
I0526 10:18:50.854470 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.18977 (* 1 = 0.18977 loss)
I0526 10:18:50.854477 15394 sgd_solver.cpp:43] Iteration 38460, lr = 0.002
I0526 10:18:55.897359 15394 main.cpp:354] Iteration 38470, loss = 0.489902
I0526 10:18:55.897400 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.489902 (* 1 = 0.489902 loss)
I0526 10:18:55.897408 15394 sgd_solver.cpp:43] Iteration 38470, lr = 0.002
I0526 10:19:00.696959 15394 main.cpp:354] Iteration 38480, loss = 0.108269
I0526 10:19:00.696996 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.108269 (* 1 = 0.108269 loss)
I0526 10:19:00.697003 15394 sgd_solver.cpp:43] Iteration 38480, lr = 0.002
I0526 10:19:05.865597 15394 main.cpp:354] Iteration 38490, loss = 0.137836
I0526 10:19:05.865638 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.137836 (* 1 = 0.137836 loss)
I0526 10:19:05.865643 15394 sgd_solver.cpp:43] Iteration 38490, lr = 0.002
I0526 10:19:10.407099 15394 main.cpp:465] Iteration 38500, Testing net (#0)
I0526 10:19:23.497829 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8867
I0526 10:19:23.497869 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.353673 (* 1 = 0.353673 loss)
I0526 10:19:23.964807 15394 main.cpp:354] Iteration 38500, loss = 0.143
I0526 10:19:23.964843 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.143 (* 1 = 0.143 loss)
I0526 10:19:23.964851 15394 sgd_solver.cpp:43] Iteration 38500, lr = 0.002
I0526 10:19:29.052880 15394 main.cpp:354] Iteration 38510, loss = 0.271468
I0526 10:19:29.052918 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.271467 (* 1 = 0.271467 loss)
I0526 10:19:29.052927 15394 sgd_solver.cpp:43] Iteration 38510, lr = 0.002
I0526 10:19:33.897034 15394 main.cpp:354] Iteration 38520, loss = 0.246932
I0526 10:19:33.897075 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.246932 (* 1 = 0.246932 loss)
I0526 10:19:33.897083 15394 sgd_solver.cpp:43] Iteration 38520, lr = 0.002
I0526 10:19:38.911732 15394 main.cpp:354] Iteration 38530, loss = 0.160866
I0526 10:19:38.911773 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.160865 (* 1 = 0.160865 loss)
I0526 10:19:38.911780 15394 sgd_solver.cpp:43] Iteration 38530, lr = 0.002
I0526 10:19:43.638103 15394 main.cpp:354] Iteration 38540, loss = 0.234295
I0526 10:19:43.638142 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.234295 (* 1 = 0.234295 loss)
I0526 10:19:43.638149 15394 sgd_solver.cpp:43] Iteration 38540, lr = 0.002
I0526 10:19:48.446908 15394 main.cpp:354] Iteration 38550, loss = 0.266448
I0526 10:19:48.446946 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.266448 (* 1 = 0.266448 loss)
I0526 10:19:48.446954 15394 sgd_solver.cpp:43] Iteration 38550, lr = 0.002
I0526 10:19:53.344187 15394 main.cpp:354] Iteration 38560, loss = 0.353121
I0526 10:19:53.344228 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.353121 (* 1 = 0.353121 loss)
I0526 10:19:53.344234 15394 sgd_solver.cpp:43] Iteration 38560, lr = 0.002
I0526 10:19:58.086765 15394 main.cpp:354] Iteration 38570, loss = 0.207619
I0526 10:19:58.086803 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.207618 (* 1 = 0.207618 loss)
I0526 10:19:58.086814 15394 sgd_solver.cpp:43] Iteration 38570, lr = 0.002
I0526 10:20:03.462867 15394 main.cpp:354] Iteration 38580, loss = 0.155555
I0526 10:20:03.462906 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.155555 (* 1 = 0.155555 loss)
I0526 10:20:03.462913 15394 sgd_solver.cpp:43] Iteration 38580, lr = 0.002
I0526 10:20:08.990139 15394 main.cpp:354] Iteration 38590, loss = 0.301081
I0526 10:20:08.990182 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.301081 (* 1 = 0.301081 loss)
I0526 10:20:08.990188 15394 sgd_solver.cpp:43] Iteration 38590, lr = 0.002
I0526 10:20:13.914752 15394 main.cpp:465] Iteration 38600, Testing net (#0)
I0526 10:20:26.999454 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8929
I0526 10:20:26.999495 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.337918 (* 1 = 0.337918 loss)
I0526 10:20:27.538151 15394 main.cpp:354] Iteration 38600, loss = 0.221802
I0526 10:20:27.538189 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.221802 (* 1 = 0.221802 loss)
I0526 10:20:27.538197 15394 sgd_solver.cpp:43] Iteration 38600, lr = 0.002
I0526 10:20:32.166452 15394 main.cpp:354] Iteration 38610, loss = 0.401206
I0526 10:20:32.166492 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.401206 (* 1 = 0.401206 loss)
I0526 10:20:32.166498 15394 sgd_solver.cpp:43] Iteration 38610, lr = 0.002
I0526 10:20:36.748623 15394 main.cpp:354] Iteration 38620, loss = 0.181474
I0526 10:20:36.748667 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.181474 (* 1 = 0.181474 loss)
I0526 10:20:36.748672 15394 sgd_solver.cpp:43] Iteration 38620, lr = 0.002
I0526 10:20:42.021349 15394 main.cpp:354] Iteration 38630, loss = 0.136746
I0526 10:20:42.021391 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.136746 (* 1 = 0.136746 loss)
I0526 10:20:42.021399 15394 sgd_solver.cpp:43] Iteration 38630, lr = 0.002
I0526 10:20:46.903828 15394 main.cpp:354] Iteration 38640, loss = 0.190242
I0526 10:20:46.903868 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.190241 (* 1 = 0.190241 loss)
I0526 10:20:46.903874 15394 sgd_solver.cpp:43] Iteration 38640, lr = 0.002
I0526 10:20:51.840368 15394 main.cpp:354] Iteration 38650, loss = 0.140633
I0526 10:20:51.840420 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.140632 (* 1 = 0.140632 loss)
I0526 10:20:51.840428 15394 sgd_solver.cpp:43] Iteration 38650, lr = 0.002
I0526 10:20:56.244434 15394 main.cpp:354] Iteration 38660, loss = 0.142577
I0526 10:20:56.244472 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.142577 (* 1 = 0.142577 loss)
I0526 10:20:56.244478 15394 sgd_solver.cpp:43] Iteration 38660, lr = 0.002
I0526 10:21:01.129932 15394 main.cpp:354] Iteration 38670, loss = 0.136109
I0526 10:21:01.129973 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.136109 (* 1 = 0.136109 loss)
I0526 10:21:01.129979 15394 sgd_solver.cpp:43] Iteration 38670, lr = 0.002
I0526 10:21:06.452801 15394 main.cpp:354] Iteration 38680, loss = 0.205598
I0526 10:21:06.452839 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.205598 (* 1 = 0.205598 loss)
I0526 10:21:06.452846 15394 sgd_solver.cpp:43] Iteration 38680, lr = 0.002
I0526 10:21:11.514906 15394 main.cpp:354] Iteration 38690, loss = 0.152316
I0526 10:21:11.514947 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.152316 (* 1 = 0.152316 loss)
I0526 10:21:11.514955 15394 sgd_solver.cpp:43] Iteration 38690, lr = 0.002
I0526 10:21:16.117523 15394 main.cpp:465] Iteration 38700, Testing net (#0)
I0526 10:21:29.203307 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8923
I0526 10:21:29.203348 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.331416 (* 1 = 0.331416 loss)
I0526 10:21:29.742561 15394 main.cpp:354] Iteration 38700, loss = 0.209247
I0526 10:21:29.742601 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.209247 (* 1 = 0.209247 loss)
I0526 10:21:29.742609 15394 sgd_solver.cpp:43] Iteration 38700, lr = 0.002
I0526 10:21:34.685868 15394 main.cpp:354] Iteration 38710, loss = 0.269206
I0526 10:21:34.685911 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.269206 (* 1 = 0.269206 loss)
I0526 10:21:34.685919 15394 sgd_solver.cpp:43] Iteration 38710, lr = 0.002
I0526 10:21:40.155951 15394 main.cpp:354] Iteration 38720, loss = 0.204557
I0526 10:21:40.155992 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204557 (* 1 = 0.204557 loss)
I0526 10:21:40.155998 15394 sgd_solver.cpp:43] Iteration 38720, lr = 0.002
I0526 10:21:45.218528 15394 main.cpp:354] Iteration 38730, loss = 0.537907
I0526 10:21:45.218567 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.537907 (* 1 = 0.537907 loss)
I0526 10:21:45.218574 15394 sgd_solver.cpp:43] Iteration 38730, lr = 0.002
I0526 10:21:50.379284 15394 main.cpp:354] Iteration 38740, loss = 0.159917
I0526 10:21:50.379324 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.159916 (* 1 = 0.159916 loss)
I0526 10:21:50.379331 15394 sgd_solver.cpp:43] Iteration 38740, lr = 0.002
I0526 10:21:56.038524 15394 main.cpp:354] Iteration 38750, loss = 0.275611
I0526 10:21:56.038568 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.275611 (* 1 = 0.275611 loss)
I0526 10:21:56.038575 15394 sgd_solver.cpp:43] Iteration 38750, lr = 0.002
I0526 10:22:01.493090 15394 main.cpp:354] Iteration 38760, loss = 0.12291
I0526 10:22:01.493129 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.12291 (* 1 = 0.12291 loss)
I0526 10:22:01.493137 15394 sgd_solver.cpp:43] Iteration 38760, lr = 0.002
I0526 10:22:06.288239 15394 main.cpp:354] Iteration 38770, loss = 0.31948
I0526 10:22:06.288277 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.319479 (* 1 = 0.319479 loss)
I0526 10:22:06.288285 15394 sgd_solver.cpp:43] Iteration 38770, lr = 0.002
I0526 10:22:11.093968 15394 main.cpp:354] Iteration 38780, loss = 0.179382
I0526 10:22:11.094008 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.179382 (* 1 = 0.179382 loss)
I0526 10:22:11.094014 15394 sgd_solver.cpp:43] Iteration 38780, lr = 0.002
I0526 10:22:15.891435 15394 main.cpp:354] Iteration 38790, loss = 0.312534
I0526 10:22:15.891474 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.312534 (* 1 = 0.312534 loss)
I0526 10:22:15.891480 15394 sgd_solver.cpp:43] Iteration 38790, lr = 0.002
I0526 10:22:20.360106 15394 main.cpp:465] Iteration 38800, Testing net (#0)
I0526 10:22:33.433454 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8897
I0526 10:22:33.433495 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.335664 (* 1 = 0.335664 loss)
I0526 10:22:33.901684 15394 main.cpp:354] Iteration 38800, loss = 0.304571
I0526 10:22:33.901705 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.304571 (* 1 = 0.304571 loss)
I0526 10:22:33.901713 15394 sgd_solver.cpp:43] Iteration 38800, lr = 0.002
I0526 10:22:39.254838 15394 main.cpp:354] Iteration 38810, loss = 0.321797
I0526 10:22:39.254880 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.321796 (* 1 = 0.321796 loss)
I0526 10:22:39.254887 15394 sgd_solver.cpp:43] Iteration 38810, lr = 0.002
I0526 10:22:44.339659 15394 main.cpp:354] Iteration 38820, loss = 0.356471
I0526 10:22:44.339699 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.356471 (* 1 = 0.356471 loss)
I0526 10:22:44.339704 15394 sgd_solver.cpp:43] Iteration 38820, lr = 0.002
I0526 10:22:49.424995 15394 main.cpp:354] Iteration 38830, loss = 0.21342
I0526 10:22:49.425037 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.213419 (* 1 = 0.213419 loss)
I0526 10:22:49.425043 15394 sgd_solver.cpp:43] Iteration 38830, lr = 0.002
I0526 10:22:54.794832 15394 main.cpp:354] Iteration 38840, loss = 0.345905
I0526 10:22:54.794862 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.345905 (* 1 = 0.345905 loss)
I0526 10:22:54.794869 15394 sgd_solver.cpp:43] Iteration 38840, lr = 0.002
I0526 10:22:59.974751 15394 main.cpp:354] Iteration 38850, loss = 0.237602
I0526 10:22:59.974792 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.237602 (* 1 = 0.237602 loss)
I0526 10:22:59.974803 15394 sgd_solver.cpp:43] Iteration 38850, lr = 0.002
I0526 10:23:04.750291 15394 main.cpp:354] Iteration 38860, loss = 0.28863
I0526 10:23:04.750330 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.28863 (* 1 = 0.28863 loss)
I0526 10:23:04.750336 15394 sgd_solver.cpp:43] Iteration 38860, lr = 0.002
I0526 10:23:10.111783 15394 main.cpp:354] Iteration 38870, loss = 0.181987
I0526 10:23:10.111825 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.181987 (* 1 = 0.181987 loss)
I0526 10:23:10.111832 15394 sgd_solver.cpp:43] Iteration 38870, lr = 0.002
I0526 10:23:14.841918 15394 main.cpp:354] Iteration 38880, loss = 0.255583
I0526 10:23:14.841958 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.255583 (* 1 = 0.255583 loss)
I0526 10:23:14.841964 15394 sgd_solver.cpp:43] Iteration 38880, lr = 0.002
I0526 10:23:19.832031 15394 main.cpp:354] Iteration 38890, loss = 0.312826
I0526 10:23:19.832070 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.312826 (* 1 = 0.312826 loss)
I0526 10:23:19.832077 15394 sgd_solver.cpp:43] Iteration 38890, lr = 0.002
I0526 10:23:24.448420 15394 main.cpp:465] Iteration 38900, Testing net (#0)
I0526 10:23:37.529857 15394 main.cpp:532]     Test net output #0: Accuracy = 0.885
I0526 10:23:37.529897 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.357262 (* 1 = 0.357262 loss)
I0526 10:23:38.032758 15394 main.cpp:354] Iteration 38900, loss = 0.207859
I0526 10:23:38.032798 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.207859 (* 1 = 0.207859 loss)
I0526 10:23:38.032804 15394 sgd_solver.cpp:43] Iteration 38900, lr = 0.002
I0526 10:23:43.296532 15394 main.cpp:354] Iteration 38910, loss = 0.166049
I0526 10:23:43.296571 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.166049 (* 1 = 0.166049 loss)
I0526 10:23:43.296577 15394 sgd_solver.cpp:43] Iteration 38910, lr = 0.002
I0526 10:23:48.735674 15394 main.cpp:354] Iteration 38920, loss = 0.153654
I0526 10:23:48.735713 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.153654 (* 1 = 0.153654 loss)
I0526 10:23:48.735719 15394 sgd_solver.cpp:43] Iteration 38920, lr = 0.002
I0526 10:23:54.117194 15394 main.cpp:354] Iteration 38930, loss = 0.284727
I0526 10:23:54.117238 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.284727 (* 1 = 0.284727 loss)
I0526 10:23:54.117244 15394 sgd_solver.cpp:43] Iteration 38930, lr = 0.002
I0526 10:23:59.367147 15394 main.cpp:354] Iteration 38940, loss = 0.251634
I0526 10:23:59.367189 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.251634 (* 1 = 0.251634 loss)
I0526 10:23:59.367195 15394 sgd_solver.cpp:43] Iteration 38940, lr = 0.002
I0526 10:24:04.688088 15394 main.cpp:354] Iteration 38950, loss = 0.0875388
I0526 10:24:04.688123 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0875385 (* 1 = 0.0875385 loss)
I0526 10:24:04.688130 15394 sgd_solver.cpp:43] Iteration 38950, lr = 0.002
I0526 10:24:09.745230 15394 main.cpp:354] Iteration 38960, loss = 0.492266
I0526 10:24:09.745273 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.492266 (* 1 = 0.492266 loss)
I0526 10:24:09.745280 15394 sgd_solver.cpp:43] Iteration 38960, lr = 0.002
I0526 10:24:14.395323 15394 main.cpp:354] Iteration 38970, loss = 0.351647
I0526 10:24:14.395361 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.351647 (* 1 = 0.351647 loss)
I0526 10:24:14.395367 15394 sgd_solver.cpp:43] Iteration 38970, lr = 0.002
I0526 10:24:19.170297 15394 main.cpp:354] Iteration 38980, loss = 0.238697
I0526 10:24:19.170336 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.238696 (* 1 = 0.238696 loss)
I0526 10:24:19.170341 15394 sgd_solver.cpp:43] Iteration 38980, lr = 0.002
I0526 10:24:24.266037 15394 main.cpp:354] Iteration 38990, loss = 0.183504
I0526 10:24:24.266079 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.183503 (* 1 = 0.183503 loss)
I0526 10:24:24.266091 15394 sgd_solver.cpp:43] Iteration 38990, lr = 0.002
I0526 10:24:28.998720 15394 main.cpp:465] Iteration 39000, Testing net (#0)
I0526 10:24:42.079419 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8861
I0526 10:24:42.079449 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.351673 (* 1 = 0.351673 loss)
I0526 10:24:42.659658 15394 main.cpp:354] Iteration 39000, loss = 0.17813
I0526 10:24:42.659696 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.178129 (* 1 = 0.178129 loss)
I0526 10:24:42.659703 15394 sgd_solver.cpp:43] Iteration 39000, lr = 0.002
I0526 10:24:47.331176 15394 main.cpp:354] Iteration 39010, loss = 0.161418
I0526 10:24:47.331214 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.161418 (* 1 = 0.161418 loss)
I0526 10:24:47.331221 15394 sgd_solver.cpp:43] Iteration 39010, lr = 0.002
I0526 10:24:52.280764 15394 main.cpp:354] Iteration 39020, loss = 0.153715
I0526 10:24:52.280807 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.153715 (* 1 = 0.153715 loss)
I0526 10:24:52.280812 15394 sgd_solver.cpp:43] Iteration 39020, lr = 0.002
I0526 10:24:57.092056 15394 main.cpp:354] Iteration 39030, loss = 0.266233
I0526 10:24:57.092095 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.266233 (* 1 = 0.266233 loss)
I0526 10:24:57.092102 15394 sgd_solver.cpp:43] Iteration 39030, lr = 0.002
I0526 10:25:02.656853 15394 main.cpp:354] Iteration 39040, loss = 0.108181
I0526 10:25:02.656891 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.108181 (* 1 = 0.108181 loss)
I0526 10:25:02.656899 15394 sgd_solver.cpp:43] Iteration 39040, lr = 0.002
I0526 10:25:08.423717 15394 main.cpp:354] Iteration 39050, loss = 0.1954
I0526 10:25:08.423758 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.1954 (* 1 = 0.1954 loss)
I0526 10:25:08.423765 15394 sgd_solver.cpp:43] Iteration 39050, lr = 0.002
I0526 10:25:13.394721 15394 main.cpp:354] Iteration 39060, loss = 0.480749
I0526 10:25:13.394757 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.480749 (* 1 = 0.480749 loss)
I0526 10:25:13.394763 15394 sgd_solver.cpp:43] Iteration 39060, lr = 0.002
I0526 10:25:18.135282 15394 main.cpp:354] Iteration 39070, loss = 0.320665
I0526 10:25:18.135323 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.320665 (* 1 = 0.320665 loss)
I0526 10:25:18.135329 15394 sgd_solver.cpp:43] Iteration 39070, lr = 0.002
I0526 10:25:23.388768 15394 main.cpp:354] Iteration 39080, loss = 0.135016
I0526 10:25:23.388810 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.135016 (* 1 = 0.135016 loss)
I0526 10:25:23.388818 15394 sgd_solver.cpp:43] Iteration 39080, lr = 0.002
I0526 10:25:28.366163 15394 main.cpp:354] Iteration 39090, loss = 0.27412
I0526 10:25:28.366201 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.274119 (* 1 = 0.274119 loss)
I0526 10:25:28.366207 15394 sgd_solver.cpp:43] Iteration 39090, lr = 0.002
I0526 10:25:32.872277 15394 main.cpp:465] Iteration 39100, Testing net (#0)
I0526 10:25:45.965258 15394 main.cpp:532]     Test net output #0: Accuracy = 0.889
I0526 10:25:45.965298 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.347875 (* 1 = 0.347875 loss)
I0526 10:25:46.540920 15394 main.cpp:354] Iteration 39100, loss = 0.133269
I0526 10:25:46.540959 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.133269 (* 1 = 0.133269 loss)
I0526 10:25:46.540967 15394 sgd_solver.cpp:43] Iteration 39100, lr = 0.002
I0526 10:25:51.127857 15394 main.cpp:354] Iteration 39110, loss = 0.229635
I0526 10:25:51.127897 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.229635 (* 1 = 0.229635 loss)
I0526 10:25:51.127904 15394 sgd_solver.cpp:43] Iteration 39110, lr = 0.002
I0526 10:25:55.981155 15394 main.cpp:354] Iteration 39120, loss = 0.42467
I0526 10:25:55.981201 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.42467 (* 1 = 0.42467 loss)
I0526 10:25:55.981209 15394 sgd_solver.cpp:43] Iteration 39120, lr = 0.002
I0526 10:26:01.014924 15394 main.cpp:354] Iteration 39130, loss = 0.229038
I0526 10:26:01.014962 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.229038 (* 1 = 0.229038 loss)
I0526 10:26:01.014969 15394 sgd_solver.cpp:43] Iteration 39130, lr = 0.002
I0526 10:26:05.994706 15394 main.cpp:354] Iteration 39140, loss = 0.127331
I0526 10:26:05.994745 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.127331 (* 1 = 0.127331 loss)
I0526 10:26:05.994750 15394 sgd_solver.cpp:43] Iteration 39140, lr = 0.002
I0526 10:26:11.271080 15394 main.cpp:354] Iteration 39150, loss = 0.179352
I0526 10:26:11.271121 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.179352 (* 1 = 0.179352 loss)
I0526 10:26:11.271127 15394 sgd_solver.cpp:43] Iteration 39150, lr = 0.002
I0526 10:26:16.360466 15394 main.cpp:354] Iteration 39160, loss = 0.154482
I0526 10:26:16.360504 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.154482 (* 1 = 0.154482 loss)
I0526 10:26:16.360512 15394 sgd_solver.cpp:43] Iteration 39160, lr = 0.002
I0526 10:26:21.764067 15394 main.cpp:354] Iteration 39170, loss = 0.233061
I0526 10:26:21.764108 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.233061 (* 1 = 0.233061 loss)
I0526 10:26:21.764116 15394 sgd_solver.cpp:43] Iteration 39170, lr = 0.002
I0526 10:26:27.039083 15394 main.cpp:354] Iteration 39180, loss = 0.204567
I0526 10:26:27.039122 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204567 (* 1 = 0.204567 loss)
I0526 10:26:27.039129 15394 sgd_solver.cpp:43] Iteration 39180, lr = 0.002
I0526 10:26:32.161734 15394 main.cpp:354] Iteration 39190, loss = 0.402715
I0526 10:26:32.161773 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.402715 (* 1 = 0.402715 loss)
I0526 10:26:32.161779 15394 sgd_solver.cpp:43] Iteration 39190, lr = 0.002
I0526 10:26:36.754346 15394 main.cpp:465] Iteration 39200, Testing net (#0)
I0526 10:26:49.837692 15394 main.cpp:532]     Test net output #0: Accuracy = 0.888
I0526 10:26:49.837730 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.351998 (* 1 = 0.351998 loss)
I0526 10:26:50.267813 15394 main.cpp:354] Iteration 39200, loss = 0.286594
I0526 10:26:50.267853 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.286593 (* 1 = 0.286593 loss)
I0526 10:26:50.267860 15394 sgd_solver.cpp:43] Iteration 39200, lr = 0.002
I0526 10:26:55.228648 15394 main.cpp:354] Iteration 39210, loss = 0.430498
I0526 10:26:55.228688 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.430498 (* 1 = 0.430498 loss)
I0526 10:26:55.228694 15394 sgd_solver.cpp:43] Iteration 39210, lr = 0.002
I0526 10:27:00.289736 15394 main.cpp:354] Iteration 39220, loss = 0.318911
I0526 10:27:00.289774 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.31891 (* 1 = 0.31891 loss)
I0526 10:27:00.289780 15394 sgd_solver.cpp:43] Iteration 39220, lr = 0.002
I0526 10:27:05.086508 15394 main.cpp:354] Iteration 39230, loss = 0.308299
I0526 10:27:05.086549 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.308299 (* 1 = 0.308299 loss)
I0526 10:27:05.086557 15394 sgd_solver.cpp:43] Iteration 39230, lr = 0.002
I0526 10:27:10.376090 15394 main.cpp:354] Iteration 39240, loss = 0.176334
I0526 10:27:10.376133 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.176334 (* 1 = 0.176334 loss)
I0526 10:27:10.376142 15394 sgd_solver.cpp:43] Iteration 39240, lr = 0.002
I0526 10:27:15.455960 15394 main.cpp:354] Iteration 39250, loss = 0.190803
I0526 10:27:15.455998 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.190803 (* 1 = 0.190803 loss)
I0526 10:27:15.456006 15394 sgd_solver.cpp:43] Iteration 39250, lr = 0.002
I0526 10:27:20.417655 15394 main.cpp:354] Iteration 39260, loss = 0.131907
I0526 10:27:20.417695 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.131907 (* 1 = 0.131907 loss)
I0526 10:27:20.417701 15394 sgd_solver.cpp:43] Iteration 39260, lr = 0.002
I0526 10:27:25.866953 15394 main.cpp:354] Iteration 39270, loss = 0.214368
I0526 10:27:25.867002 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.214368 (* 1 = 0.214368 loss)
I0526 10:27:25.867008 15394 sgd_solver.cpp:43] Iteration 39270, lr = 0.002
I0526 10:27:30.940559 15394 main.cpp:354] Iteration 39280, loss = 0.204166
I0526 10:27:30.940598 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204166 (* 1 = 0.204166 loss)
I0526 10:27:30.940603 15394 sgd_solver.cpp:43] Iteration 39280, lr = 0.002
I0526 10:27:35.997997 15394 main.cpp:354] Iteration 39290, loss = 0.160108
I0526 10:27:35.998035 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.160107 (* 1 = 0.160107 loss)
I0526 10:27:35.998041 15394 sgd_solver.cpp:43] Iteration 39290, lr = 0.002
I0526 10:27:40.550501 15394 main.cpp:465] Iteration 39300, Testing net (#0)
I0526 10:27:53.631129 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8876
I0526 10:27:53.631170 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.355441 (* 1 = 0.355441 loss)
I0526 10:27:54.101477 15394 main.cpp:354] Iteration 39300, loss = 0.332224
I0526 10:27:54.101516 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.332224 (* 1 = 0.332224 loss)
I0526 10:27:54.101524 15394 sgd_solver.cpp:43] Iteration 39300, lr = 0.002
I0526 10:27:59.110018 15394 main.cpp:354] Iteration 39310, loss = 0.276068
I0526 10:27:59.110054 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.276068 (* 1 = 0.276068 loss)
I0526 10:27:59.110061 15394 sgd_solver.cpp:43] Iteration 39310, lr = 0.002
I0526 10:28:04.554296 15394 main.cpp:354] Iteration 39320, loss = 0.245523
I0526 10:28:04.554334 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.245523 (* 1 = 0.245523 loss)
I0526 10:28:04.554342 15394 sgd_solver.cpp:43] Iteration 39320, lr = 0.002
I0526 10:28:09.435622 15394 main.cpp:354] Iteration 39330, loss = 0.218544
I0526 10:28:09.435664 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.218544 (* 1 = 0.218544 loss)
I0526 10:28:09.435672 15394 sgd_solver.cpp:43] Iteration 39330, lr = 0.002
I0526 10:28:13.873641 15394 main.cpp:354] Iteration 39340, loss = 0.243483
I0526 10:28:13.873682 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.243483 (* 1 = 0.243483 loss)
I0526 10:28:13.873688 15394 sgd_solver.cpp:43] Iteration 39340, lr = 0.002
I0526 10:28:18.722079 15394 main.cpp:354] Iteration 39350, loss = 0.141323
I0526 10:28:18.722120 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.141323 (* 1 = 0.141323 loss)
I0526 10:28:18.722127 15394 sgd_solver.cpp:43] Iteration 39350, lr = 0.002
I0526 10:28:23.987587 15394 main.cpp:354] Iteration 39360, loss = 0.200913
I0526 10:28:23.987629 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.200913 (* 1 = 0.200913 loss)
I0526 10:28:23.987637 15394 sgd_solver.cpp:43] Iteration 39360, lr = 0.002
I0526 10:28:28.745204 15394 main.cpp:354] Iteration 39370, loss = 0.245516
I0526 10:28:28.745235 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.245516 (* 1 = 0.245516 loss)
I0526 10:28:28.745241 15394 sgd_solver.cpp:43] Iteration 39370, lr = 0.002
I0526 10:28:33.654955 15394 main.cpp:354] Iteration 39380, loss = 0.184402
I0526 10:28:33.654994 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.184402 (* 1 = 0.184402 loss)
I0526 10:28:33.655000 15394 sgd_solver.cpp:43] Iteration 39380, lr = 0.002
I0526 10:28:38.391319 15394 main.cpp:354] Iteration 39390, loss = 0.283316
I0526 10:28:38.391358 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.283316 (* 1 = 0.283316 loss)
I0526 10:28:38.391366 15394 sgd_solver.cpp:43] Iteration 39390, lr = 0.002
I0526 10:28:42.763609 15394 main.cpp:465] Iteration 39400, Testing net (#0)
I0526 10:28:55.848604 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8899
I0526 10:28:55.848645 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.340286 (* 1 = 0.340286 loss)
I0526 10:28:56.248517 15394 main.cpp:354] Iteration 39400, loss = 0.257961
I0526 10:28:56.248556 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.25796 (* 1 = 0.25796 loss)
I0526 10:28:56.248570 15394 sgd_solver.cpp:43] Iteration 39400, lr = 0.002
I0526 10:29:01.324415 15394 main.cpp:354] Iteration 39410, loss = 0.296387
I0526 10:29:01.324453 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.296386 (* 1 = 0.296386 loss)
I0526 10:29:01.324460 15394 sgd_solver.cpp:43] Iteration 39410, lr = 0.002
I0526 10:29:06.538908 15394 main.cpp:354] Iteration 39420, loss = 0.129652
I0526 10:29:06.538952 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.129652 (* 1 = 0.129652 loss)
I0526 10:29:06.538959 15394 sgd_solver.cpp:43] Iteration 39420, lr = 0.002
I0526 10:29:11.465222 15394 main.cpp:354] Iteration 39430, loss = 0.121245
I0526 10:29:11.465260 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.121245 (* 1 = 0.121245 loss)
I0526 10:29:11.465266 15394 sgd_solver.cpp:43] Iteration 39430, lr = 0.002
I0526 10:29:16.780699 15394 main.cpp:354] Iteration 39440, loss = 0.911768
I0526 10:29:16.780737 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.911768 (* 1 = 0.911768 loss)
I0526 10:29:16.780745 15394 sgd_solver.cpp:43] Iteration 39440, lr = 0.002
I0526 10:29:21.936082 15394 main.cpp:354] Iteration 39450, loss = 0.259583
I0526 10:29:21.936125 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.259583 (* 1 = 0.259583 loss)
I0526 10:29:21.936131 15394 sgd_solver.cpp:43] Iteration 39450, lr = 0.002
I0526 10:29:26.961694 15394 main.cpp:354] Iteration 39460, loss = 0.198544
I0526 10:29:26.961733 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.198544 (* 1 = 0.198544 loss)
I0526 10:29:26.961740 15394 sgd_solver.cpp:43] Iteration 39460, lr = 0.002
I0526 10:29:32.267693 15394 main.cpp:354] Iteration 39470, loss = 0.215137
I0526 10:29:32.267732 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.215137 (* 1 = 0.215137 loss)
I0526 10:29:32.267740 15394 sgd_solver.cpp:43] Iteration 39470, lr = 0.002
I0526 10:29:37.246570 15394 main.cpp:354] Iteration 39480, loss = 0.519269
I0526 10:29:37.246618 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.519269 (* 1 = 0.519269 loss)
I0526 10:29:37.246625 15394 sgd_solver.cpp:43] Iteration 39480, lr = 0.002
I0526 10:29:41.884564 15394 main.cpp:354] Iteration 39490, loss = 0.148435
I0526 10:29:41.884613 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.148434 (* 1 = 0.148434 loss)
I0526 10:29:41.884620 15394 sgd_solver.cpp:43] Iteration 39490, lr = 0.002
I0526 10:29:46.254145 15394 main.cpp:465] Iteration 39500, Testing net (#0)
I0526 10:29:59.340386 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8908
I0526 10:29:59.340425 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.343207 (* 1 = 0.343207 loss)
I0526 10:29:59.772166 15394 main.cpp:354] Iteration 39500, loss = 0.306298
I0526 10:29:59.772198 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.306298 (* 1 = 0.306298 loss)
I0526 10:29:59.772207 15394 sgd_solver.cpp:43] Iteration 39500, lr = 0.002
I0526 10:30:04.846058 15394 main.cpp:354] Iteration 39510, loss = 0.353201
I0526 10:30:04.846098 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.353201 (* 1 = 0.353201 loss)
I0526 10:30:04.846104 15394 sgd_solver.cpp:43] Iteration 39510, lr = 0.002
I0526 10:30:09.909380 15394 main.cpp:354] Iteration 39520, loss = 0.303894
I0526 10:30:09.909415 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.303893 (* 1 = 0.303893 loss)
I0526 10:30:09.909421 15394 sgd_solver.cpp:43] Iteration 39520, lr = 0.002
I0526 10:30:15.219087 15394 main.cpp:354] Iteration 39530, loss = 0.227422
I0526 10:30:15.219126 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.227422 (* 1 = 0.227422 loss)
I0526 10:30:15.219132 15394 sgd_solver.cpp:43] Iteration 39530, lr = 0.002
I0526 10:30:20.458909 15394 main.cpp:354] Iteration 39540, loss = 0.197589
I0526 10:30:20.458948 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.197589 (* 1 = 0.197589 loss)
I0526 10:30:20.458956 15394 sgd_solver.cpp:43] Iteration 39540, lr = 0.002
I0526 10:30:25.486863 15394 main.cpp:354] Iteration 39550, loss = 0.156161
I0526 10:30:25.486906 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.15616 (* 1 = 0.15616 loss)
I0526 10:30:25.486912 15394 sgd_solver.cpp:43] Iteration 39550, lr = 0.002
I0526 10:30:30.309551 15394 main.cpp:354] Iteration 39560, loss = 0.443996
I0526 10:30:30.309592 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.443996 (* 1 = 0.443996 loss)
I0526 10:30:30.309597 15394 sgd_solver.cpp:43] Iteration 39560, lr = 0.002
I0526 10:30:35.129879 15394 main.cpp:354] Iteration 39570, loss = 0.13476
I0526 10:30:35.129911 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.134759 (* 1 = 0.134759 loss)
I0526 10:30:35.129917 15394 sgd_solver.cpp:43] Iteration 39570, lr = 0.002
I0526 10:30:40.319780 15394 main.cpp:354] Iteration 39580, loss = 0.233089
I0526 10:30:40.319846 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.233089 (* 1 = 0.233089 loss)
I0526 10:30:40.319854 15394 sgd_solver.cpp:43] Iteration 39580, lr = 0.002
I0526 10:30:45.862823 15394 main.cpp:354] Iteration 39590, loss = 0.133901
I0526 10:30:45.862860 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.133901 (* 1 = 0.133901 loss)
I0526 10:30:45.862866 15394 sgd_solver.cpp:43] Iteration 39590, lr = 0.002
I0526 10:30:50.431920 15394 main.cpp:465] Iteration 39600, Testing net (#0)
I0526 10:31:03.515918 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8873
I0526 10:31:03.515959 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.34846 (* 1 = 0.34846 loss)
I0526 10:31:04.017757 15394 main.cpp:354] Iteration 39600, loss = 0.127556
I0526 10:31:04.017796 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.127556 (* 1 = 0.127556 loss)
I0526 10:31:04.017803 15394 sgd_solver.cpp:43] Iteration 39600, lr = 0.002
I0526 10:31:09.047616 15394 main.cpp:354] Iteration 39610, loss = 0.35086
I0526 10:31:09.047659 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.35086 (* 1 = 0.35086 loss)
I0526 10:31:09.047665 15394 sgd_solver.cpp:43] Iteration 39610, lr = 0.002
I0526 10:31:14.200294 15394 main.cpp:354] Iteration 39620, loss = 0.264604
I0526 10:31:14.200335 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.264604 (* 1 = 0.264604 loss)
I0526 10:31:14.200340 15394 sgd_solver.cpp:43] Iteration 39620, lr = 0.002
I0526 10:31:18.804096 15394 main.cpp:354] Iteration 39630, loss = 0.324092
I0526 10:31:18.804134 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.324092 (* 1 = 0.324092 loss)
I0526 10:31:18.804141 15394 sgd_solver.cpp:43] Iteration 39630, lr = 0.002
I0526 10:31:23.817585 15394 main.cpp:354] Iteration 39640, loss = 0.239833
I0526 10:31:23.817626 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.239833 (* 1 = 0.239833 loss)
I0526 10:31:23.817633 15394 sgd_solver.cpp:43] Iteration 39640, lr = 0.002
I0526 10:31:29.057616 15394 main.cpp:354] Iteration 39650, loss = 0.286189
I0526 10:31:29.057656 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.286189 (* 1 = 0.286189 loss)
I0526 10:31:29.057662 15394 sgd_solver.cpp:43] Iteration 39650, lr = 0.002
I0526 10:31:34.429780 15394 main.cpp:354] Iteration 39660, loss = 0.173993
I0526 10:31:34.429818 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.173993 (* 1 = 0.173993 loss)
I0526 10:31:34.429826 15394 sgd_solver.cpp:43] Iteration 39660, lr = 0.002
I0526 10:31:39.850944 15394 main.cpp:354] Iteration 39670, loss = 0.211046
I0526 10:31:39.850987 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.211046 (* 1 = 0.211046 loss)
I0526 10:31:39.850993 15394 sgd_solver.cpp:43] Iteration 39670, lr = 0.002
I0526 10:31:45.054945 15394 main.cpp:354] Iteration 39680, loss = 0.124976
I0526 10:31:45.054982 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.124976 (* 1 = 0.124976 loss)
I0526 10:31:45.054988 15394 sgd_solver.cpp:43] Iteration 39680, lr = 0.002
I0526 10:31:50.221596 15394 main.cpp:354] Iteration 39690, loss = 0.150539
I0526 10:31:50.221640 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.150539 (* 1 = 0.150539 loss)
I0526 10:31:50.221647 15394 sgd_solver.cpp:43] Iteration 39690, lr = 0.002
I0526 10:31:54.516852 15394 main.cpp:465] Iteration 39700, Testing net (#0)
I0526 10:32:07.604326 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8818
I0526 10:32:07.604367 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.373397 (* 1 = 0.373397 loss)
I0526 10:32:08.111810 15394 main.cpp:354] Iteration 39700, loss = 0.230267
I0526 10:32:08.111855 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.230267 (* 1 = 0.230267 loss)
I0526 10:32:08.111863 15394 sgd_solver.cpp:43] Iteration 39700, lr = 0.002
I0526 10:32:13.117652 15394 main.cpp:354] Iteration 39710, loss = 0.33449
I0526 10:32:13.117693 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.33449 (* 1 = 0.33449 loss)
I0526 10:32:13.117700 15394 sgd_solver.cpp:43] Iteration 39710, lr = 0.002
I0526 10:32:17.631131 15394 main.cpp:354] Iteration 39720, loss = 0.281356
I0526 10:32:17.631171 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.281356 (* 1 = 0.281356 loss)
I0526 10:32:17.631177 15394 sgd_solver.cpp:43] Iteration 39720, lr = 0.002
I0526 10:32:22.424332 15394 main.cpp:354] Iteration 39730, loss = 0.225099
I0526 10:32:22.424368 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.225099 (* 1 = 0.225099 loss)
I0526 10:32:22.424376 15394 sgd_solver.cpp:43] Iteration 39730, lr = 0.002
I0526 10:32:27.511363 15394 main.cpp:354] Iteration 39740, loss = 0.316444
I0526 10:32:27.511402 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.316444 (* 1 = 0.316444 loss)
I0526 10:32:27.511409 15394 sgd_solver.cpp:43] Iteration 39740, lr = 0.002
I0526 10:32:32.507064 15394 main.cpp:354] Iteration 39750, loss = 0.317238
I0526 10:32:32.507105 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.317238 (* 1 = 0.317238 loss)
I0526 10:32:32.507112 15394 sgd_solver.cpp:43] Iteration 39750, lr = 0.002
I0526 10:32:37.665343 15394 main.cpp:354] Iteration 39760, loss = 0.26583
I0526 10:32:37.665387 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.26583 (* 1 = 0.26583 loss)
I0526 10:32:37.665395 15394 sgd_solver.cpp:43] Iteration 39760, lr = 0.002
I0526 10:32:42.664301 15394 main.cpp:354] Iteration 39770, loss = 0.230277
I0526 10:32:42.664341 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.230276 (* 1 = 0.230276 loss)
I0526 10:32:42.664347 15394 sgd_solver.cpp:43] Iteration 39770, lr = 0.002
I0526 10:32:47.921839 15394 main.cpp:354] Iteration 39780, loss = 0.171387
I0526 10:32:47.921872 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.171387 (* 1 = 0.171387 loss)
I0526 10:32:47.921880 15394 sgd_solver.cpp:43] Iteration 39780, lr = 0.002
I0526 10:32:52.839085 15394 main.cpp:354] Iteration 39790, loss = 0.266758
I0526 10:32:52.839128 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.266758 (* 1 = 0.266758 loss)
I0526 10:32:52.839134 15394 sgd_solver.cpp:43] Iteration 39790, lr = 0.002
I0526 10:32:57.372297 15394 main.cpp:465] Iteration 39800, Testing net (#0)
I0526 10:33:10.451043 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8877
I0526 10:33:10.451084 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.359035 (* 1 = 0.359035 loss)
I0526 10:33:10.853013 15394 main.cpp:354] Iteration 39800, loss = 0.246154
I0526 10:33:10.853051 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.246154 (* 1 = 0.246154 loss)
I0526 10:33:10.853060 15394 sgd_solver.cpp:43] Iteration 39800, lr = 0.002
I0526 10:33:16.403789 15394 main.cpp:354] Iteration 39810, loss = 0.0992073
I0526 10:33:16.403827 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0992071 (* 1 = 0.0992071 loss)
I0526 10:33:16.403833 15394 sgd_solver.cpp:43] Iteration 39810, lr = 0.002
I0526 10:33:21.511515 15394 main.cpp:354] Iteration 39820, loss = 0.202733
I0526 10:33:21.511556 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.202733 (* 1 = 0.202733 loss)
I0526 10:33:21.511569 15394 sgd_solver.cpp:43] Iteration 39820, lr = 0.002
I0526 10:33:26.559362 15394 main.cpp:354] Iteration 39830, loss = 0.193404
I0526 10:33:26.559406 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.193404 (* 1 = 0.193404 loss)
I0526 10:33:26.559413 15394 sgd_solver.cpp:43] Iteration 39830, lr = 0.002
I0526 10:33:31.965369 15394 main.cpp:354] Iteration 39840, loss = 0.135316
I0526 10:33:31.965396 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.135316 (* 1 = 0.135316 loss)
I0526 10:33:31.965402 15394 sgd_solver.cpp:43] Iteration 39840, lr = 0.002
I0526 10:33:36.792975 15394 main.cpp:354] Iteration 39850, loss = 0.177302
I0526 10:33:36.793018 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.177302 (* 1 = 0.177302 loss)
I0526 10:33:36.793026 15394 sgd_solver.cpp:43] Iteration 39850, lr = 0.002
I0526 10:33:41.515080 15394 main.cpp:354] Iteration 39860, loss = 0.480638
I0526 10:33:41.515120 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.480638 (* 1 = 0.480638 loss)
I0526 10:33:41.515125 15394 sgd_solver.cpp:43] Iteration 39860, lr = 0.002
I0526 10:33:46.526558 15394 main.cpp:354] Iteration 39870, loss = 0.373318
I0526 10:33:46.526598 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.373318 (* 1 = 0.373318 loss)
I0526 10:33:46.526605 15394 sgd_solver.cpp:43] Iteration 39870, lr = 0.002
I0526 10:33:50.982843 15394 main.cpp:354] Iteration 39880, loss = 0.238664
I0526 10:33:50.982870 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.238664 (* 1 = 0.238664 loss)
I0526 10:33:50.982877 15394 sgd_solver.cpp:43] Iteration 39880, lr = 0.002
I0526 10:33:56.432909 15394 main.cpp:354] Iteration 39890, loss = 0.161553
I0526 10:33:56.432950 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.161552 (* 1 = 0.161552 loss)
I0526 10:33:56.432956 15394 sgd_solver.cpp:43] Iteration 39890, lr = 0.002
I0526 10:34:01.196624 15394 main.cpp:465] Iteration 39900, Testing net (#0)
I0526 10:34:14.283462 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8872
I0526 10:34:14.283502 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.362909 (* 1 = 0.362909 loss)
I0526 10:34:14.755259 15394 main.cpp:354] Iteration 39900, loss = 0.160698
I0526 10:34:14.755298 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.160698 (* 1 = 0.160698 loss)
I0526 10:34:14.755306 15394 sgd_solver.cpp:43] Iteration 39900, lr = 0.002
I0526 10:34:19.612957 15394 main.cpp:354] Iteration 39910, loss = 0.200364
I0526 10:34:19.612998 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.200364 (* 1 = 0.200364 loss)
I0526 10:34:19.613003 15394 sgd_solver.cpp:43] Iteration 39910, lr = 0.002
I0526 10:34:24.983476 15394 main.cpp:354] Iteration 39920, loss = 0.288136
I0526 10:34:24.983518 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.288136 (* 1 = 0.288136 loss)
I0526 10:34:24.983525 15394 sgd_solver.cpp:43] Iteration 39920, lr = 0.002
I0526 10:34:29.976286 15394 main.cpp:354] Iteration 39930, loss = 0.301514
I0526 10:34:29.976325 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.301513 (* 1 = 0.301513 loss)
I0526 10:34:29.976331 15394 sgd_solver.cpp:43] Iteration 39930, lr = 0.002
I0526 10:34:34.845827 15394 main.cpp:354] Iteration 39940, loss = 0.511182
I0526 10:34:34.845867 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.511181 (* 1 = 0.511181 loss)
I0526 10:34:34.845875 15394 sgd_solver.cpp:43] Iteration 39940, lr = 0.002
I0526 10:34:40.133435 15394 main.cpp:354] Iteration 39950, loss = 0.261639
I0526 10:34:40.133481 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.261638 (* 1 = 0.261638 loss)
I0526 10:34:40.133487 15394 sgd_solver.cpp:43] Iteration 39950, lr = 0.002
I0526 10:34:45.080902 15394 main.cpp:354] Iteration 39960, loss = 0.428433
I0526 10:34:45.080941 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.428432 (* 1 = 0.428432 loss)
I0526 10:34:45.080947 15394 sgd_solver.cpp:43] Iteration 39960, lr = 0.002
I0526 10:34:50.350474 15394 main.cpp:354] Iteration 39970, loss = 0.171675
I0526 10:34:50.350515 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.171675 (* 1 = 0.171675 loss)
I0526 10:34:50.350522 15394 sgd_solver.cpp:43] Iteration 39970, lr = 0.002
I0526 10:34:55.435765 15394 main.cpp:354] Iteration 39980, loss = 0.185182
I0526 10:34:55.435808 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.185182 (* 1 = 0.185182 loss)
I0526 10:34:55.435816 15394 sgd_solver.cpp:43] Iteration 39980, lr = 0.002
I0526 10:35:00.566354 15394 main.cpp:354] Iteration 39990, loss = 0.199741
I0526 10:35:00.566391 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.199741 (* 1 = 0.199741 loss)
I0526 10:35:00.566398 15394 sgd_solver.cpp:43] Iteration 39990, lr = 0.002
I0526 10:35:04.847930 15394 main.cpp:465] Iteration 40000, Testing net (#0)
I0526 10:35:17.939584 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8934
I0526 10:35:17.939623 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.333614 (* 1 = 0.333614 loss)
I0526 10:35:18.374444 15394 main.cpp:354] Iteration 40000, loss = 0.43599
I0526 10:35:18.374485 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.435989 (* 1 = 0.435989 loss)
I0526 10:35:18.374492 15394 sgd_solver.cpp:43] Iteration 40000, lr = 0.002
I0526 10:35:23.166928 15394 main.cpp:354] Iteration 40010, loss = 0.451691
I0526 10:35:23.166973 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.451691 (* 1 = 0.451691 loss)
I0526 10:35:23.166980 15394 sgd_solver.cpp:43] Iteration 40010, lr = 0.002
I0526 10:35:28.033134 15394 main.cpp:354] Iteration 40020, loss = 0.155314
I0526 10:35:28.033174 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.155314 (* 1 = 0.155314 loss)
I0526 10:35:28.033179 15394 sgd_solver.cpp:43] Iteration 40020, lr = 0.002
I0526 10:35:33.425469 15394 main.cpp:354] Iteration 40030, loss = 0.217909
I0526 10:35:33.425508 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.217909 (* 1 = 0.217909 loss)
I0526 10:35:33.425514 15394 sgd_solver.cpp:43] Iteration 40030, lr = 0.002
I0526 10:35:38.380295 15394 main.cpp:354] Iteration 40040, loss = 0.413621
I0526 10:35:38.380338 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.413621 (* 1 = 0.413621 loss)
I0526 10:35:38.380345 15394 sgd_solver.cpp:43] Iteration 40040, lr = 0.002
I0526 10:35:43.262269 15394 main.cpp:354] Iteration 40050, loss = 0.137831
I0526 10:35:43.262310 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.137831 (* 1 = 0.137831 loss)
I0526 10:35:43.262315 15394 sgd_solver.cpp:43] Iteration 40050, lr = 0.002
I0526 10:35:48.553510 15394 main.cpp:354] Iteration 40060, loss = 0.17625
I0526 10:35:48.553549 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.176249 (* 1 = 0.176249 loss)
I0526 10:35:48.553555 15394 sgd_solver.cpp:43] Iteration 40060, lr = 0.002
I0526 10:35:53.329774 15394 main.cpp:354] Iteration 40070, loss = 0.188248
I0526 10:35:53.329818 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.188248 (* 1 = 0.188248 loss)
I0526 10:35:53.329824 15394 sgd_solver.cpp:43] Iteration 40070, lr = 0.002
I0526 10:35:58.171272 15394 main.cpp:354] Iteration 40080, loss = 0.356535
I0526 10:35:58.171316 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.356535 (* 1 = 0.356535 loss)
I0526 10:35:58.171324 15394 sgd_solver.cpp:43] Iteration 40080, lr = 0.002
I0526 10:36:03.517026 15394 main.cpp:354] Iteration 40090, loss = 0.184359
I0526 10:36:03.517058 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.184358 (* 1 = 0.184358 loss)
I0526 10:36:03.517066 15394 sgd_solver.cpp:43] Iteration 40090, lr = 0.002
I0526 10:36:07.969899 15394 main.cpp:465] Iteration 40100, Testing net (#0)
I0526 10:36:21.049221 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8912
I0526 10:36:21.049260 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.351767 (* 1 = 0.351767 loss)
I0526 10:36:21.520334 15394 main.cpp:354] Iteration 40100, loss = 0.342255
I0526 10:36:21.520380 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.342255 (* 1 = 0.342255 loss)
I0526 10:36:21.520386 15394 sgd_solver.cpp:43] Iteration 40100, lr = 0.002
I0526 10:36:26.879104 15394 main.cpp:354] Iteration 40110, loss = 0.304716
I0526 10:36:26.879145 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.304716 (* 1 = 0.304716 loss)
I0526 10:36:26.879153 15394 sgd_solver.cpp:43] Iteration 40110, lr = 0.002
I0526 10:36:32.009328 15394 main.cpp:354] Iteration 40120, loss = 0.223387
I0526 10:36:32.009368 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.223387 (* 1 = 0.223387 loss)
I0526 10:36:32.009376 15394 sgd_solver.cpp:43] Iteration 40120, lr = 0.002
I0526 10:36:37.345495 15394 main.cpp:354] Iteration 40130, loss = 0.22207
I0526 10:36:37.345536 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.222069 (* 1 = 0.222069 loss)
I0526 10:36:37.345543 15394 sgd_solver.cpp:43] Iteration 40130, lr = 0.002
I0526 10:36:42.487751 15394 main.cpp:354] Iteration 40140, loss = 0.189828
I0526 10:36:42.487792 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.189827 (* 1 = 0.189827 loss)
I0526 10:36:42.487797 15394 sgd_solver.cpp:43] Iteration 40140, lr = 0.002
I0526 10:36:47.080898 15394 main.cpp:354] Iteration 40150, loss = 0.32228
I0526 10:36:47.080936 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.322279 (* 1 = 0.322279 loss)
I0526 10:36:47.080943 15394 sgd_solver.cpp:43] Iteration 40150, lr = 0.002
I0526 10:36:52.051054 15394 main.cpp:354] Iteration 40160, loss = 0.2525
I0526 10:36:52.051097 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.2525 (* 1 = 0.2525 loss)
I0526 10:36:52.051105 15394 sgd_solver.cpp:43] Iteration 40160, lr = 0.002
I0526 10:36:57.155167 15394 main.cpp:354] Iteration 40170, loss = 0.308294
I0526 10:36:57.155207 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.308294 (* 1 = 0.308294 loss)
I0526 10:36:57.155213 15394 sgd_solver.cpp:43] Iteration 40170, lr = 0.002
I0526 10:37:02.605031 15394 main.cpp:354] Iteration 40180, loss = 0.197901
I0526 10:37:02.605068 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.1979 (* 1 = 0.1979 loss)
I0526 10:37:02.605075 15394 sgd_solver.cpp:43] Iteration 40180, lr = 0.002
I0526 10:37:07.387923 15394 main.cpp:354] Iteration 40190, loss = 0.282304
I0526 10:37:07.387969 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.282304 (* 1 = 0.282304 loss)
I0526 10:37:07.387976 15394 sgd_solver.cpp:43] Iteration 40190, lr = 0.002
I0526 10:37:11.704442 15394 main.cpp:465] Iteration 40200, Testing net (#0)
I0526 10:37:24.793666 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8903
I0526 10:37:24.793705 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.353896 (* 1 = 0.353896 loss)
I0526 10:37:25.300638 15394 main.cpp:354] Iteration 40200, loss = 0.139831
I0526 10:37:25.300675 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.139831 (* 1 = 0.139831 loss)
I0526 10:37:25.300683 15394 sgd_solver.cpp:43] Iteration 40200, lr = 0.002
I0526 10:37:30.019243 15394 main.cpp:354] Iteration 40210, loss = 0.210415
I0526 10:37:30.019282 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.210414 (* 1 = 0.210414 loss)
I0526 10:37:30.019289 15394 sgd_solver.cpp:43] Iteration 40210, lr = 0.002
I0526 10:37:35.168843 15394 main.cpp:354] Iteration 40220, loss = 0.251744
I0526 10:37:35.168881 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.251744 (* 1 = 0.251744 loss)
I0526 10:37:35.168887 15394 sgd_solver.cpp:43] Iteration 40220, lr = 0.002
I0526 10:37:40.073040 15394 main.cpp:354] Iteration 40230, loss = 0.334557
I0526 10:37:40.073097 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.334557 (* 1 = 0.334557 loss)
I0526 10:37:40.073104 15394 sgd_solver.cpp:43] Iteration 40230, lr = 0.002
I0526 10:37:45.318648 15394 main.cpp:354] Iteration 40240, loss = 0.276882
I0526 10:37:45.318688 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.276882 (* 1 = 0.276882 loss)
I0526 10:37:45.318699 15394 sgd_solver.cpp:43] Iteration 40240, lr = 0.002
I0526 10:37:50.338441 15394 main.cpp:354] Iteration 40250, loss = 0.25912
I0526 10:37:50.338466 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.25912 (* 1 = 0.25912 loss)
I0526 10:37:50.338472 15394 sgd_solver.cpp:43] Iteration 40250, lr = 0.002
I0526 10:37:55.600824 15394 main.cpp:354] Iteration 40260, loss = 0.144289
I0526 10:37:55.600867 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.144288 (* 1 = 0.144288 loss)
I0526 10:37:55.600874 15394 sgd_solver.cpp:43] Iteration 40260, lr = 0.002
I0526 10:38:01.012948 15394 main.cpp:354] Iteration 40270, loss = 0.253029
I0526 10:38:01.012989 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.253029 (* 1 = 0.253029 loss)
I0526 10:38:01.012996 15394 sgd_solver.cpp:43] Iteration 40270, lr = 0.002
I0526 10:38:05.787292 15394 main.cpp:354] Iteration 40280, loss = 0.232858
I0526 10:38:05.787329 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.232857 (* 1 = 0.232857 loss)
I0526 10:38:05.787335 15394 sgd_solver.cpp:43] Iteration 40280, lr = 0.002
I0526 10:38:11.054251 15394 main.cpp:354] Iteration 40290, loss = 0.257597
I0526 10:38:11.054293 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.257597 (* 1 = 0.257597 loss)
I0526 10:38:11.054301 15394 sgd_solver.cpp:43] Iteration 40290, lr = 0.002
I0526 10:38:15.572935 15394 main.cpp:465] Iteration 40300, Testing net (#0)
I0526 10:38:28.659201 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8853
I0526 10:38:28.659241 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.361983 (* 1 = 0.361983 loss)
I0526 10:38:29.162811 15394 main.cpp:354] Iteration 40300, loss = 0.122471
I0526 10:38:29.162855 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.12247 (* 1 = 0.12247 loss)
I0526 10:38:29.162864 15394 sgd_solver.cpp:43] Iteration 40300, lr = 0.002
I0526 10:38:33.848274 15394 main.cpp:354] Iteration 40310, loss = 0.179531
I0526 10:38:33.848300 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.179531 (* 1 = 0.179531 loss)
I0526 10:38:33.848307 15394 sgd_solver.cpp:43] Iteration 40310, lr = 0.002
I0526 10:38:38.817492 15394 main.cpp:354] Iteration 40320, loss = 0.301025
I0526 10:38:38.817534 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.301025 (* 1 = 0.301025 loss)
I0526 10:38:38.817540 15394 sgd_solver.cpp:43] Iteration 40320, lr = 0.002
I0526 10:38:44.039463 15394 main.cpp:354] Iteration 40330, loss = 0.133032
I0526 10:38:44.039500 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.133032 (* 1 = 0.133032 loss)
I0526 10:38:44.039507 15394 sgd_solver.cpp:43] Iteration 40330, lr = 0.002
I0526 10:38:48.733222 15394 main.cpp:354] Iteration 40340, loss = 0.278128
I0526 10:38:48.733260 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.278127 (* 1 = 0.278127 loss)
I0526 10:38:48.733268 15394 sgd_solver.cpp:43] Iteration 40340, lr = 0.002
I0526 10:38:53.881219 15394 main.cpp:354] Iteration 40350, loss = 0.245258
I0526 10:38:53.881256 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.245258 (* 1 = 0.245258 loss)
I0526 10:38:53.881263 15394 sgd_solver.cpp:43] Iteration 40350, lr = 0.002
I0526 10:38:59.139560 15394 main.cpp:354] Iteration 40360, loss = 0.227009
I0526 10:38:59.139598 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.227009 (* 1 = 0.227009 loss)
I0526 10:38:59.139605 15394 sgd_solver.cpp:43] Iteration 40360, lr = 0.002
I0526 10:39:03.936105 15394 main.cpp:354] Iteration 40370, loss = 0.383721
I0526 10:39:03.936143 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.383721 (* 1 = 0.383721 loss)
I0526 10:39:03.936149 15394 sgd_solver.cpp:43] Iteration 40370, lr = 0.002
I0526 10:39:09.161533 15394 main.cpp:354] Iteration 40380, loss = 0.167035
I0526 10:39:09.161576 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.167035 (* 1 = 0.167035 loss)
I0526 10:39:09.161582 15394 sgd_solver.cpp:43] Iteration 40380, lr = 0.002
I0526 10:39:14.464946 15394 main.cpp:354] Iteration 40390, loss = 0.234101
I0526 10:39:14.464984 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.234101 (* 1 = 0.234101 loss)
I0526 10:39:14.464990 15394 sgd_solver.cpp:43] Iteration 40390, lr = 0.002
I0526 10:39:18.866711 15394 main.cpp:465] Iteration 40400, Testing net (#0)
I0526 10:39:31.954357 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8888
I0526 10:39:31.954411 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.354367 (* 1 = 0.354367 loss)
I0526 10:39:32.530005 15394 main.cpp:354] Iteration 40400, loss = 0.186138
I0526 10:39:32.530045 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186138 (* 1 = 0.186138 loss)
I0526 10:39:32.530053 15394 sgd_solver.cpp:43] Iteration 40400, lr = 0.002
I0526 10:39:37.970854 15394 main.cpp:354] Iteration 40410, loss = 0.155015
I0526 10:39:37.970897 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.155015 (* 1 = 0.155015 loss)
I0526 10:39:37.970904 15394 sgd_solver.cpp:43] Iteration 40410, lr = 0.002
I0526 10:39:43.420765 15394 main.cpp:354] Iteration 40420, loss = 0.465223
I0526 10:39:43.420806 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.465222 (* 1 = 0.465222 loss)
I0526 10:39:43.420812 15394 sgd_solver.cpp:43] Iteration 40420, lr = 0.002
I0526 10:39:48.679721 15394 main.cpp:354] Iteration 40430, loss = 0.284283
I0526 10:39:48.679759 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.284283 (* 1 = 0.284283 loss)
I0526 10:39:48.679766 15394 sgd_solver.cpp:43] Iteration 40430, lr = 0.002
I0526 10:39:53.670306 15394 main.cpp:354] Iteration 40440, loss = 0.290172
I0526 10:39:53.670351 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.290171 (* 1 = 0.290171 loss)
I0526 10:39:53.670374 15394 sgd_solver.cpp:43] Iteration 40440, lr = 0.002
I0526 10:39:58.984695 15394 main.cpp:354] Iteration 40450, loss = 0.160181
I0526 10:39:58.984736 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.16018 (* 1 = 0.16018 loss)
I0526 10:39:58.984742 15394 sgd_solver.cpp:43] Iteration 40450, lr = 0.002
I0526 10:40:03.881919 15394 main.cpp:354] Iteration 40460, loss = 0.254745
I0526 10:40:03.881956 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.254745 (* 1 = 0.254745 loss)
I0526 10:40:03.881963 15394 sgd_solver.cpp:43] Iteration 40460, lr = 0.002
I0526 10:40:08.702545 15394 main.cpp:354] Iteration 40470, loss = 1.16817
I0526 10:40:08.702589 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.16817 (* 1 = 1.16817 loss)
I0526 10:40:08.702595 15394 sgd_solver.cpp:43] Iteration 40470, lr = 0.002
I0526 10:40:13.600069 15394 main.cpp:354] Iteration 40480, loss = 0.274463
I0526 10:40:13.600106 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.274463 (* 1 = 0.274463 loss)
I0526 10:40:13.600112 15394 sgd_solver.cpp:43] Iteration 40480, lr = 0.002
I0526 10:40:19.210654 15394 main.cpp:354] Iteration 40490, loss = 0.186835
I0526 10:40:19.210705 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186835 (* 1 = 0.186835 loss)
I0526 10:40:19.210711 15394 sgd_solver.cpp:43] Iteration 40490, lr = 0.002
I0526 10:40:24.116782 15394 main.cpp:465] Iteration 40500, Testing net (#0)
I0526 10:40:37.205466 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8908
I0526 10:40:37.205507 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.345538 (* 1 = 0.345538 loss)
I0526 10:40:37.708142 15394 main.cpp:354] Iteration 40500, loss = 0.209237
I0526 10:40:37.708181 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.209237 (* 1 = 0.209237 loss)
I0526 10:40:37.708189 15394 sgd_solver.cpp:43] Iteration 40500, lr = 0.002
I0526 10:40:42.977706 15394 main.cpp:354] Iteration 40510, loss = 0.218679
I0526 10:40:42.977748 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.218678 (* 1 = 0.218678 loss)
I0526 10:40:42.977754 15394 sgd_solver.cpp:43] Iteration 40510, lr = 0.002
I0526 10:40:47.892889 15394 main.cpp:354] Iteration 40520, loss = 0.173133
I0526 10:40:47.892935 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.173133 (* 1 = 0.173133 loss)
I0526 10:40:47.892940 15394 sgd_solver.cpp:43] Iteration 40520, lr = 0.002
I0526 10:40:52.746698 15394 main.cpp:354] Iteration 40530, loss = 0.41183
I0526 10:40:52.746742 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.41183 (* 1 = 0.41183 loss)
I0526 10:40:52.746747 15394 sgd_solver.cpp:43] Iteration 40530, lr = 0.002
I0526 10:40:57.769418 15394 main.cpp:354] Iteration 40540, loss = 0.144464
I0526 10:40:57.769459 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.144463 (* 1 = 0.144463 loss)
I0526 10:40:57.769465 15394 sgd_solver.cpp:43] Iteration 40540, lr = 0.002
I0526 10:41:02.935499 15394 main.cpp:354] Iteration 40550, loss = 0.384828
I0526 10:41:02.935539 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.384828 (* 1 = 0.384828 loss)
I0526 10:41:02.935546 15394 sgd_solver.cpp:43] Iteration 40550, lr = 0.002
I0526 10:41:07.269547 15394 main.cpp:354] Iteration 40560, loss = 0.327264
I0526 10:41:07.269589 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.327264 (* 1 = 0.327264 loss)
I0526 10:41:07.269595 15394 sgd_solver.cpp:43] Iteration 40560, lr = 0.002
I0526 10:41:12.150310 15394 main.cpp:354] Iteration 40570, loss = 0.241003
I0526 10:41:12.150343 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.241003 (* 1 = 0.241003 loss)
I0526 10:41:12.150349 15394 sgd_solver.cpp:43] Iteration 40570, lr = 0.002
I0526 10:41:17.523417 15394 main.cpp:354] Iteration 40580, loss = 0.170771
I0526 10:41:17.523459 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.170771 (* 1 = 0.170771 loss)
I0526 10:41:17.523466 15394 sgd_solver.cpp:43] Iteration 40580, lr = 0.002
I0526 10:41:22.659868 15394 main.cpp:354] Iteration 40590, loss = 0.156927
I0526 10:41:22.659912 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.156926 (* 1 = 0.156926 loss)
I0526 10:41:22.659919 15394 sgd_solver.cpp:43] Iteration 40590, lr = 0.002
I0526 10:41:27.534852 15394 main.cpp:465] Iteration 40600, Testing net (#0)
I0526 10:41:40.624371 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8917
I0526 10:41:40.624411 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.337848 (* 1 = 0.337848 loss)
I0526 10:41:41.127125 15394 main.cpp:354] Iteration 40600, loss = 0.164039
I0526 10:41:41.127164 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.164038 (* 1 = 0.164038 loss)
I0526 10:41:41.127171 15394 sgd_solver.cpp:43] Iteration 40600, lr = 0.002
I0526 10:41:45.936983 15394 main.cpp:354] Iteration 40610, loss = 0.306668
I0526 10:41:45.937021 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.306668 (* 1 = 0.306668 loss)
I0526 10:41:45.937027 15394 sgd_solver.cpp:43] Iteration 40610, lr = 0.002
I0526 10:41:50.807968 15394 main.cpp:354] Iteration 40620, loss = 0.241968
I0526 10:41:50.808008 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.241968 (* 1 = 0.241968 loss)
I0526 10:41:50.808015 15394 sgd_solver.cpp:43] Iteration 40620, lr = 0.002
I0526 10:41:56.143822 15394 main.cpp:354] Iteration 40630, loss = 0.274209
I0526 10:41:56.143851 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.274209 (* 1 = 0.274209 loss)
I0526 10:41:56.143857 15394 sgd_solver.cpp:43] Iteration 40630, lr = 0.002
I0526 10:42:00.819512 15394 main.cpp:354] Iteration 40640, loss = 0.193639
I0526 10:42:00.819553 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.193638 (* 1 = 0.193638 loss)
I0526 10:42:00.819560 15394 sgd_solver.cpp:43] Iteration 40640, lr = 0.002
I0526 10:42:05.712249 15394 main.cpp:354] Iteration 40650, loss = 0.171651
I0526 10:42:05.712291 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.17165 (* 1 = 0.17165 loss)
I0526 10:42:05.712297 15394 sgd_solver.cpp:43] Iteration 40650, lr = 0.002
I0526 10:42:11.019562 15394 main.cpp:354] Iteration 40660, loss = 0.170975
I0526 10:42:11.019606 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.170975 (* 1 = 0.170975 loss)
I0526 10:42:11.019620 15394 sgd_solver.cpp:43] Iteration 40660, lr = 0.002
I0526 10:42:15.991964 15394 main.cpp:354] Iteration 40670, loss = 0.301437
I0526 10:42:15.992004 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.301437 (* 1 = 0.301437 loss)
I0526 10:42:15.992010 15394 sgd_solver.cpp:43] Iteration 40670, lr = 0.002
I0526 10:42:21.381214 15394 main.cpp:354] Iteration 40680, loss = 0.328852
I0526 10:42:21.381248 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.328852 (* 1 = 0.328852 loss)
I0526 10:42:21.381255 15394 sgd_solver.cpp:43] Iteration 40680, lr = 0.002
I0526 10:42:26.364539 15394 main.cpp:354] Iteration 40690, loss = 0.273993
I0526 10:42:26.364583 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.273993 (* 1 = 0.273993 loss)
I0526 10:42:26.364590 15394 sgd_solver.cpp:43] Iteration 40690, lr = 0.002
I0526 10:42:30.929410 15394 main.cpp:465] Iteration 40700, Testing net (#0)
I0526 10:42:44.017621 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8895
I0526 10:42:44.017662 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.344168 (* 1 = 0.344168 loss)
I0526 10:42:44.598760 15394 main.cpp:354] Iteration 40700, loss = 0.107479
I0526 10:42:44.598801 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.107478 (* 1 = 0.107478 loss)
I0526 10:42:44.598809 15394 sgd_solver.cpp:43] Iteration 40700, lr = 0.002
I0526 10:42:49.999150 15394 main.cpp:354] Iteration 40710, loss = 0.197314
I0526 10:42:49.999189 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.197313 (* 1 = 0.197313 loss)
I0526 10:42:49.999196 15394 sgd_solver.cpp:43] Iteration 40710, lr = 0.002
I0526 10:42:54.784430 15394 main.cpp:354] Iteration 40720, loss = 0.319702
I0526 10:42:54.784472 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.319701 (* 1 = 0.319701 loss)
I0526 10:42:54.784478 15394 sgd_solver.cpp:43] Iteration 40720, lr = 0.002
I0526 10:42:59.855762 15394 main.cpp:354] Iteration 40730, loss = 0.182729
I0526 10:42:59.855799 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.182728 (* 1 = 0.182728 loss)
I0526 10:42:59.855805 15394 sgd_solver.cpp:43] Iteration 40730, lr = 0.002
I0526 10:43:04.712873 15394 main.cpp:354] Iteration 40740, loss = 0.198811
I0526 10:43:04.712930 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.19881 (* 1 = 0.19881 loss)
I0526 10:43:04.712940 15394 sgd_solver.cpp:43] Iteration 40740, lr = 0.002
I0526 10:43:09.979646 15394 main.cpp:354] Iteration 40750, loss = 0.243835
I0526 10:43:09.979702 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.243835 (* 1 = 0.243835 loss)
I0526 10:43:09.979709 15394 sgd_solver.cpp:43] Iteration 40750, lr = 0.002
I0526 10:43:14.785796 15394 main.cpp:354] Iteration 40760, loss = 0.268524
I0526 10:43:14.785837 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.268524 (* 1 = 0.268524 loss)
I0526 10:43:14.785843 15394 sgd_solver.cpp:43] Iteration 40760, lr = 0.002
I0526 10:43:19.610839 15394 main.cpp:354] Iteration 40770, loss = 0.257912
I0526 10:43:19.610879 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.257911 (* 1 = 0.257911 loss)
I0526 10:43:19.610885 15394 sgd_solver.cpp:43] Iteration 40770, lr = 0.002
I0526 10:43:24.654347 15394 main.cpp:354] Iteration 40780, loss = 0.192401
I0526 10:43:24.654394 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.1924 (* 1 = 0.1924 loss)
I0526 10:43:24.654402 15394 sgd_solver.cpp:43] Iteration 40780, lr = 0.002
I0526 10:43:29.946038 15394 main.cpp:354] Iteration 40790, loss = 0.185676
I0526 10:43:29.946079 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.185675 (* 1 = 0.185675 loss)
I0526 10:43:29.946086 15394 sgd_solver.cpp:43] Iteration 40790, lr = 0.002
I0526 10:43:34.551916 15394 main.cpp:465] Iteration 40800, Testing net (#0)
I0526 10:43:47.635749 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8907
I0526 10:43:47.635788 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.338199 (* 1 = 0.338199 loss)
I0526 10:43:48.065840 15394 main.cpp:354] Iteration 40800, loss = 0.354995
I0526 10:43:48.065879 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.354994 (* 1 = 0.354994 loss)
I0526 10:43:48.065888 15394 sgd_solver.cpp:43] Iteration 40800, lr = 0.002
I0526 10:43:53.364620 15394 main.cpp:354] Iteration 40810, loss = 0.166178
I0526 10:43:53.364660 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.166178 (* 1 = 0.166178 loss)
I0526 10:43:53.364666 15394 sgd_solver.cpp:43] Iteration 40810, lr = 0.002
I0526 10:43:58.949196 15394 main.cpp:354] Iteration 40820, loss = 0.0789131
I0526 10:43:58.949236 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0789127 (* 1 = 0.0789127 loss)
I0526 10:43:58.949244 15394 sgd_solver.cpp:43] Iteration 40820, lr = 0.002
I0526 10:44:04.209473 15394 main.cpp:354] Iteration 40830, loss = 0.144524
I0526 10:44:04.209514 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.144524 (* 1 = 0.144524 loss)
I0526 10:44:04.209522 15394 sgd_solver.cpp:43] Iteration 40830, lr = 0.002
I0526 10:44:09.160536 15394 main.cpp:354] Iteration 40840, loss = 0.227294
I0526 10:44:09.160579 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.227294 (* 1 = 0.227294 loss)
I0526 10:44:09.160586 15394 sgd_solver.cpp:43] Iteration 40840, lr = 0.002
I0526 10:44:14.034389 15394 main.cpp:354] Iteration 40850, loss = 0.23765
I0526 10:44:14.034428 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.23765 (* 1 = 0.23765 loss)
I0526 10:44:14.034435 15394 sgd_solver.cpp:43] Iteration 40850, lr = 0.002
I0526 10:44:18.896826 15394 main.cpp:354] Iteration 40860, loss = 0.34151
I0526 10:44:18.896867 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.34151 (* 1 = 0.34151 loss)
I0526 10:44:18.896872 15394 sgd_solver.cpp:43] Iteration 40860, lr = 0.002
I0526 10:44:23.839575 15394 main.cpp:354] Iteration 40870, loss = 0.290755
I0526 10:44:23.839617 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.290755 (* 1 = 0.290755 loss)
I0526 10:44:23.839623 15394 sgd_solver.cpp:43] Iteration 40870, lr = 0.002
I0526 10:44:28.866684 15394 main.cpp:354] Iteration 40880, loss = 0.272092
I0526 10:44:28.866736 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.272091 (* 1 = 0.272091 loss)
I0526 10:44:28.866742 15394 sgd_solver.cpp:43] Iteration 40880, lr = 0.002
I0526 10:44:34.155354 15394 main.cpp:354] Iteration 40890, loss = 0.35489
I0526 10:44:34.155382 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.35489 (* 1 = 0.35489 loss)
I0526 10:44:34.155390 15394 sgd_solver.cpp:43] Iteration 40890, lr = 0.002
I0526 10:44:38.965406 15394 main.cpp:465] Iteration 40900, Testing net (#0)
I0526 10:44:52.044363 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8928
I0526 10:44:52.044406 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.331632 (* 1 = 0.331632 loss)
I0526 10:44:52.480633 15394 main.cpp:354] Iteration 40900, loss = 0.195453
I0526 10:44:52.480664 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.195452 (* 1 = 0.195452 loss)
I0526 10:44:52.480671 15394 sgd_solver.cpp:43] Iteration 40900, lr = 0.002
I0526 10:44:57.519438 15394 main.cpp:354] Iteration 40910, loss = 0.161296
I0526 10:44:57.519476 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.161296 (* 1 = 0.161296 loss)
I0526 10:44:57.519482 15394 sgd_solver.cpp:43] Iteration 40910, lr = 0.002
I0526 10:45:02.605661 15394 main.cpp:354] Iteration 40920, loss = 0.290639
I0526 10:45:02.605701 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.290639 (* 1 = 0.290639 loss)
I0526 10:45:02.605707 15394 sgd_solver.cpp:43] Iteration 40920, lr = 0.002
I0526 10:45:07.666659 15394 main.cpp:354] Iteration 40930, loss = 0.19153
I0526 10:45:07.666713 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.19153 (* 1 = 0.19153 loss)
I0526 10:45:07.666720 15394 sgd_solver.cpp:43] Iteration 40930, lr = 0.002
I0526 10:45:12.948654 15394 main.cpp:354] Iteration 40940, loss = 0.251527
I0526 10:45:12.948694 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.251527 (* 1 = 0.251527 loss)
I0526 10:45:12.948701 15394 sgd_solver.cpp:43] Iteration 40940, lr = 0.002
I0526 10:45:18.125067 15394 main.cpp:354] Iteration 40950, loss = 0.157745
I0526 10:45:18.125092 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.157744 (* 1 = 0.157744 loss)
I0526 10:45:18.125098 15394 sgd_solver.cpp:43] Iteration 40950, lr = 0.002
I0526 10:45:22.872982 15394 main.cpp:354] Iteration 40960, loss = 0.32285
I0526 10:45:22.873025 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.32285 (* 1 = 0.32285 loss)
I0526 10:45:22.873033 15394 sgd_solver.cpp:43] Iteration 40960, lr = 0.002
I0526 10:45:27.967351 15394 main.cpp:354] Iteration 40970, loss = 0.15395
I0526 10:45:27.967389 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.153949 (* 1 = 0.153949 loss)
I0526 10:45:27.967396 15394 sgd_solver.cpp:43] Iteration 40970, lr = 0.002
I0526 10:45:33.282977 15394 main.cpp:354] Iteration 40980, loss = 0.25504
I0526 10:45:33.283017 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.25504 (* 1 = 0.25504 loss)
I0526 10:45:33.283023 15394 sgd_solver.cpp:43] Iteration 40980, lr = 0.002
I0526 10:45:38.630424 15394 main.cpp:354] Iteration 40990, loss = 0.145315
I0526 10:45:38.630466 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.145315 (* 1 = 0.145315 loss)
I0526 10:45:38.630473 15394 sgd_solver.cpp:43] Iteration 40990, lr = 0.002
I0526 10:45:42.760298 15394 main.cpp:465] Iteration 41000, Testing net (#0)
I0526 10:45:55.850486 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8946
I0526 10:45:55.850528 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.324981 (* 1 = 0.324981 loss)
I0526 10:45:56.355762 15394 main.cpp:354] Iteration 41000, loss = 0.193355
I0526 10:45:56.355818 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.193354 (* 1 = 0.193354 loss)
I0526 10:45:56.355825 15394 sgd_solver.cpp:43] Iteration 41000, lr = 0.002
I0526 10:46:01.673835 15394 main.cpp:354] Iteration 41010, loss = 0.146541
I0526 10:46:01.673877 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.146541 (* 1 = 0.146541 loss)
I0526 10:46:01.673884 15394 sgd_solver.cpp:43] Iteration 41010, lr = 0.002
I0526 10:46:07.111332 15394 main.cpp:354] Iteration 41020, loss = 0.397752
I0526 10:46:07.111377 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.397752 (* 1 = 0.397752 loss)
I0526 10:46:07.111385 15394 sgd_solver.cpp:43] Iteration 41020, lr = 0.002
I0526 10:46:11.989923 15394 main.cpp:354] Iteration 41030, loss = 0.392397
I0526 10:46:11.989964 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.392397 (* 1 = 0.392397 loss)
I0526 10:46:11.989970 15394 sgd_solver.cpp:43] Iteration 41030, lr = 0.002
I0526 10:46:16.959833 15394 main.cpp:354] Iteration 41040, loss = 0.140694
I0526 10:46:16.959873 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.140694 (* 1 = 0.140694 loss)
I0526 10:46:16.959880 15394 sgd_solver.cpp:43] Iteration 41040, lr = 0.002
I0526 10:46:21.997208 15394 main.cpp:354] Iteration 41050, loss = 0.239357
I0526 10:46:21.997251 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.239357 (* 1 = 0.239357 loss)
I0526 10:46:21.997258 15394 sgd_solver.cpp:43] Iteration 41050, lr = 0.002
I0526 10:46:27.315886 15394 main.cpp:354] Iteration 41060, loss = 0.271738
I0526 10:46:27.315925 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.271738 (* 1 = 0.271738 loss)
I0526 10:46:27.315932 15394 sgd_solver.cpp:43] Iteration 41060, lr = 0.002
I0526 10:46:32.535159 15394 main.cpp:354] Iteration 41070, loss = 0.213658
I0526 10:46:32.535199 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.213658 (* 1 = 0.213658 loss)
I0526 10:46:32.535207 15394 sgd_solver.cpp:43] Iteration 41070, lr = 0.002
I0526 10:46:37.931047 15394 main.cpp:354] Iteration 41080, loss = 0.213208
I0526 10:46:37.931092 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.213207 (* 1 = 0.213207 loss)
I0526 10:46:37.931104 15394 sgd_solver.cpp:43] Iteration 41080, lr = 0.002
I0526 10:46:42.860932 15394 main.cpp:354] Iteration 41090, loss = 0.14121
I0526 10:46:42.860971 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.14121 (* 1 = 0.14121 loss)
I0526 10:46:42.860976 15394 sgd_solver.cpp:43] Iteration 41090, lr = 0.002
I0526 10:46:47.855861 15394 main.cpp:465] Iteration 41100, Testing net (#0)
I0526 10:47:00.946817 15394 main.cpp:532]     Test net output #0: Accuracy = 0.893
I0526 10:47:00.946856 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.346307 (* 1 = 0.346307 loss)
I0526 10:47:01.522819 15394 main.cpp:354] Iteration 41100, loss = 0.119504
I0526 10:47:01.522856 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.119504 (* 1 = 0.119504 loss)
I0526 10:47:01.522863 15394 sgd_solver.cpp:43] Iteration 41100, lr = 0.002
I0526 10:47:06.609166 15394 main.cpp:354] Iteration 41110, loss = 0.206233
I0526 10:47:06.609211 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206232 (* 1 = 0.206232 loss)
I0526 10:47:06.609220 15394 sgd_solver.cpp:43] Iteration 41110, lr = 0.002
I0526 10:47:12.059885 15394 main.cpp:354] Iteration 41120, loss = 0.294748
I0526 10:47:12.059928 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.294748 (* 1 = 0.294748 loss)
I0526 10:47:12.059936 15394 sgd_solver.cpp:43] Iteration 41120, lr = 0.002
I0526 10:47:17.007299 15394 main.cpp:354] Iteration 41130, loss = 0.170949
I0526 10:47:17.007339 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.170948 (* 1 = 0.170948 loss)
I0526 10:47:17.007345 15394 sgd_solver.cpp:43] Iteration 41130, lr = 0.002
I0526 10:47:21.806247 15394 main.cpp:354] Iteration 41140, loss = 0.169078
I0526 10:47:21.806289 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.169077 (* 1 = 0.169077 loss)
I0526 10:47:21.806298 15394 sgd_solver.cpp:43] Iteration 41140, lr = 0.002
I0526 10:47:26.728304 15394 main.cpp:354] Iteration 41150, loss = 0.315466
I0526 10:47:26.728343 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.315465 (* 1 = 0.315465 loss)
I0526 10:47:26.728349 15394 sgd_solver.cpp:43] Iteration 41150, lr = 0.002
I0526 10:47:31.758940 15394 main.cpp:354] Iteration 41160, loss = 0.26117
I0526 10:47:31.758980 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.26117 (* 1 = 0.26117 loss)
I0526 10:47:31.758986 15394 sgd_solver.cpp:43] Iteration 41160, lr = 0.002
I0526 10:47:36.761212 15394 main.cpp:354] Iteration 41170, loss = 0.169079
I0526 10:47:36.761240 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.169078 (* 1 = 0.169078 loss)
I0526 10:47:36.761246 15394 sgd_solver.cpp:43] Iteration 41170, lr = 0.002
I0526 10:47:41.789198 15394 main.cpp:354] Iteration 41180, loss = 0.573406
I0526 10:47:41.789237 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.573406 (* 1 = 0.573406 loss)
I0526 10:47:41.789242 15394 sgd_solver.cpp:43] Iteration 41180, lr = 0.002
I0526 10:47:46.555116 15394 main.cpp:354] Iteration 41190, loss = 0.431365
I0526 10:47:46.555156 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.431365 (* 1 = 0.431365 loss)
I0526 10:47:46.555163 15394 sgd_solver.cpp:43] Iteration 41190, lr = 0.002
I0526 10:47:50.873126 15394 main.cpp:465] Iteration 41200, Testing net (#0)
I0526 10:48:03.963999 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8934
I0526 10:48:03.964038 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.333864 (* 1 = 0.333864 loss)
I0526 10:48:04.371235 15394 main.cpp:354] Iteration 41200, loss = 0.291635
I0526 10:48:04.371258 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.291635 (* 1 = 0.291635 loss)
I0526 10:48:04.371266 15394 sgd_solver.cpp:43] Iteration 41200, lr = 0.002
I0526 10:48:09.568869 15394 main.cpp:354] Iteration 41210, loss = 0.146342
I0526 10:48:09.568912 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.146342 (* 1 = 0.146342 loss)
I0526 10:48:09.568923 15394 sgd_solver.cpp:43] Iteration 41210, lr = 0.002
I0526 10:48:14.743582 15394 main.cpp:354] Iteration 41220, loss = 0.326509
I0526 10:48:14.743619 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.326509 (* 1 = 0.326509 loss)
I0526 10:48:14.743625 15394 sgd_solver.cpp:43] Iteration 41220, lr = 0.002
I0526 10:48:19.509846 15394 main.cpp:354] Iteration 41230, loss = 0.231246
I0526 10:48:19.509888 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.231246 (* 1 = 0.231246 loss)
I0526 10:48:19.509893 15394 sgd_solver.cpp:43] Iteration 41230, lr = 0.002
I0526 10:48:24.821755 15394 main.cpp:354] Iteration 41240, loss = 0.235462
I0526 10:48:24.821799 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235461 (* 1 = 0.235461 loss)
I0526 10:48:24.821805 15394 sgd_solver.cpp:43] Iteration 41240, lr = 0.002
I0526 10:48:30.262781 15394 main.cpp:354] Iteration 41250, loss = 0.20591
I0526 10:48:30.262821 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.205909 (* 1 = 0.205909 loss)
I0526 10:48:30.262828 15394 sgd_solver.cpp:43] Iteration 41250, lr = 0.002
I0526 10:48:35.424368 15394 main.cpp:354] Iteration 41260, loss = 0.30923
I0526 10:48:35.424409 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.30923 (* 1 = 0.30923 loss)
I0526 10:48:35.424417 15394 sgd_solver.cpp:43] Iteration 41260, lr = 0.002
I0526 10:48:40.312752 15394 main.cpp:354] Iteration 41270, loss = 0.26541
I0526 10:48:40.312793 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.265409 (* 1 = 0.265409 loss)
I0526 10:48:40.312799 15394 sgd_solver.cpp:43] Iteration 41270, lr = 0.002
I0526 10:48:45.185385 15394 main.cpp:354] Iteration 41280, loss = 0.260035
I0526 10:48:45.185425 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.260035 (* 1 = 0.260035 loss)
I0526 10:48:45.185431 15394 sgd_solver.cpp:43] Iteration 41280, lr = 0.002
I0526 10:48:50.481191 15394 main.cpp:354] Iteration 41290, loss = 0.156421
I0526 10:48:50.481231 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.15642 (* 1 = 0.15642 loss)
I0526 10:48:50.481237 15394 sgd_solver.cpp:43] Iteration 41290, lr = 0.002
I0526 10:48:55.160900 15394 main.cpp:465] Iteration 41300, Testing net (#0)
I0526 10:49:08.247392 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8989
I0526 10:49:08.247431 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.329715 (* 1 = 0.329715 loss)
I0526 10:49:08.578826 15394 main.cpp:354] Iteration 41300, loss = 0.455547
I0526 10:49:08.578848 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.455547 (* 1 = 0.455547 loss)
I0526 10:49:08.578856 15394 sgd_solver.cpp:43] Iteration 41300, lr = 0.002
I0526 10:49:13.405997 15394 main.cpp:354] Iteration 41310, loss = 0.338963
I0526 10:49:13.406047 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.338962 (* 1 = 0.338962 loss)
I0526 10:49:13.406054 15394 sgd_solver.cpp:43] Iteration 41310, lr = 0.002
I0526 10:49:18.579964 15394 main.cpp:354] Iteration 41320, loss = 0.312108
I0526 10:49:18.580004 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.312108 (* 1 = 0.312108 loss)
I0526 10:49:18.580010 15394 sgd_solver.cpp:43] Iteration 41320, lr = 0.002
I0526 10:49:23.607307 15394 main.cpp:354] Iteration 41330, loss = 0.233867
I0526 10:49:23.607348 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.233867 (* 1 = 0.233867 loss)
I0526 10:49:23.607354 15394 sgd_solver.cpp:43] Iteration 41330, lr = 0.002
I0526 10:49:28.632412 15394 main.cpp:354] Iteration 41340, loss = 0.455222
I0526 10:49:28.632457 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.455221 (* 1 = 0.455221 loss)
I0526 10:49:28.632462 15394 sgd_solver.cpp:43] Iteration 41340, lr = 0.002
I0526 10:49:33.313653 15394 main.cpp:354] Iteration 41350, loss = 0.405086
I0526 10:49:33.313693 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.405085 (* 1 = 0.405085 loss)
I0526 10:49:33.313699 15394 sgd_solver.cpp:43] Iteration 41350, lr = 0.002
I0526 10:49:38.480213 15394 main.cpp:354] Iteration 41360, loss = 0.231822
I0526 10:49:38.480257 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.231821 (* 1 = 0.231821 loss)
I0526 10:49:38.480263 15394 sgd_solver.cpp:43] Iteration 41360, lr = 0.002
I0526 10:49:43.317229 15394 main.cpp:354] Iteration 41370, loss = 0.186136
I0526 10:49:43.317268 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186135 (* 1 = 0.186135 loss)
I0526 10:49:43.317276 15394 sgd_solver.cpp:43] Iteration 41370, lr = 0.002
I0526 10:49:48.198164 15394 main.cpp:354] Iteration 41380, loss = 0.267213
I0526 10:49:48.198204 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.267213 (* 1 = 0.267213 loss)
I0526 10:49:48.198210 15394 sgd_solver.cpp:43] Iteration 41380, lr = 0.002
I0526 10:49:53.505069 15394 main.cpp:354] Iteration 41390, loss = 0.162134
I0526 10:49:53.505110 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.162133 (* 1 = 0.162133 loss)
I0526 10:49:53.505118 15394 sgd_solver.cpp:43] Iteration 41390, lr = 0.002
I0526 10:49:58.544877 15394 main.cpp:465] Iteration 41400, Testing net (#0)
I0526 10:50:11.634672 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8928
I0526 10:50:11.634727 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.330215 (* 1 = 0.330215 loss)
I0526 10:50:12.076220 15394 main.cpp:354] Iteration 41400, loss = 0.217857
I0526 10:50:12.076256 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.217857 (* 1 = 0.217857 loss)
I0526 10:50:12.076263 15394 sgd_solver.cpp:43] Iteration 41400, lr = 0.002
I0526 10:50:16.895810 15394 main.cpp:354] Iteration 41410, loss = 0.193047
I0526 10:50:16.895849 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.193047 (* 1 = 0.193047 loss)
I0526 10:50:16.895855 15394 sgd_solver.cpp:43] Iteration 41410, lr = 0.002
I0526 10:50:21.712909 15394 main.cpp:354] Iteration 41420, loss = 0.223463
I0526 10:50:21.712950 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.223463 (* 1 = 0.223463 loss)
I0526 10:50:21.712959 15394 sgd_solver.cpp:43] Iteration 41420, lr = 0.002
I0526 10:50:26.560313 15394 main.cpp:354] Iteration 41430, loss = 0.151362
I0526 10:50:26.560354 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.151362 (* 1 = 0.151362 loss)
I0526 10:50:26.560360 15394 sgd_solver.cpp:43] Iteration 41430, lr = 0.002
I0526 10:50:31.496680 15394 main.cpp:354] Iteration 41440, loss = 0.146667
I0526 10:50:31.496718 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.146666 (* 1 = 0.146666 loss)
I0526 10:50:31.496724 15394 sgd_solver.cpp:43] Iteration 41440, lr = 0.002
I0526 10:50:36.371292 15394 main.cpp:354] Iteration 41450, loss = 0.193651
I0526 10:50:36.371330 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.193651 (* 1 = 0.193651 loss)
I0526 10:50:36.371336 15394 sgd_solver.cpp:43] Iteration 41450, lr = 0.002
I0526 10:50:41.604220 15394 main.cpp:354] Iteration 41460, loss = 0.136625
I0526 10:50:41.604264 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.136625 (* 1 = 0.136625 loss)
I0526 10:50:41.604269 15394 sgd_solver.cpp:43] Iteration 41460, lr = 0.002
I0526 10:50:46.510210 15394 main.cpp:354] Iteration 41470, loss = 0.225934
I0526 10:50:46.510249 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.225934 (* 1 = 0.225934 loss)
I0526 10:50:46.510256 15394 sgd_solver.cpp:43] Iteration 41470, lr = 0.002
I0526 10:50:51.207640 15394 main.cpp:354] Iteration 41480, loss = 0.380791
I0526 10:50:51.207677 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.380791 (* 1 = 0.380791 loss)
I0526 10:50:51.207684 15394 sgd_solver.cpp:43] Iteration 41480, lr = 0.002
I0526 10:50:56.095309 15394 main.cpp:354] Iteration 41490, loss = 0.379229
I0526 10:50:56.095351 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.379229 (* 1 = 0.379229 loss)
I0526 10:50:56.095357 15394 sgd_solver.cpp:43] Iteration 41490, lr = 0.002
I0526 10:51:00.900125 15394 main.cpp:465] Iteration 41500, Testing net (#0)
I0526 10:51:13.980805 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8911
I0526 10:51:13.980845 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.340116 (* 1 = 0.340116 loss)
I0526 10:51:14.410660 15394 main.cpp:354] Iteration 41500, loss = 0.386056
I0526 10:51:14.410699 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.386056 (* 1 = 0.386056 loss)
I0526 10:51:14.410707 15394 sgd_solver.cpp:43] Iteration 41500, lr = 0.002
I0526 10:51:19.482219 15394 main.cpp:354] Iteration 41510, loss = 0.206776
I0526 10:51:19.482260 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206775 (* 1 = 0.206775 loss)
I0526 10:51:19.482266 15394 sgd_solver.cpp:43] Iteration 41510, lr = 0.002
I0526 10:51:24.079898 15394 main.cpp:354] Iteration 41520, loss = 0.331459
I0526 10:51:24.079936 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.331458 (* 1 = 0.331458 loss)
I0526 10:51:24.079942 15394 sgd_solver.cpp:43] Iteration 41520, lr = 0.002
I0526 10:51:28.882999 15394 main.cpp:354] Iteration 41530, loss = 0.355617
I0526 10:51:28.883038 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.355616 (* 1 = 0.355616 loss)
I0526 10:51:28.883044 15394 sgd_solver.cpp:43] Iteration 41530, lr = 0.002
I0526 10:51:33.986012 15394 main.cpp:354] Iteration 41540, loss = 0.129093
I0526 10:51:33.986050 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.129092 (* 1 = 0.129092 loss)
I0526 10:51:33.986057 15394 sgd_solver.cpp:43] Iteration 41540, lr = 0.002
I0526 10:51:39.146428 15394 main.cpp:354] Iteration 41550, loss = 0.310281
I0526 10:51:39.146471 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.310281 (* 1 = 0.310281 loss)
I0526 10:51:39.146477 15394 sgd_solver.cpp:43] Iteration 41550, lr = 0.002
I0526 10:51:44.264152 15394 main.cpp:354] Iteration 41560, loss = 0.120667
I0526 10:51:44.264190 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.120666 (* 1 = 0.120666 loss)
I0526 10:51:44.264196 15394 sgd_solver.cpp:43] Iteration 41560, lr = 0.002
I0526 10:51:49.678002 15394 main.cpp:354] Iteration 41570, loss = 0.212567
I0526 10:51:49.678041 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.212567 (* 1 = 0.212567 loss)
I0526 10:51:49.678047 15394 sgd_solver.cpp:43] Iteration 41570, lr = 0.002
I0526 10:51:55.097396 15394 main.cpp:354] Iteration 41580, loss = 0.160787
I0526 10:51:55.097440 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.160786 (* 1 = 0.160786 loss)
I0526 10:51:55.097447 15394 sgd_solver.cpp:43] Iteration 41580, lr = 0.002
I0526 10:52:00.544286 15394 main.cpp:354] Iteration 41590, loss = 0.213714
I0526 10:52:00.544325 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.213713 (* 1 = 0.213713 loss)
I0526 10:52:00.544332 15394 sgd_solver.cpp:43] Iteration 41590, lr = 0.002
I0526 10:52:05.228474 15394 main.cpp:465] Iteration 41600, Testing net (#0)
I0526 10:52:18.321221 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8921
I0526 10:52:18.321266 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.331674 (* 1 = 0.331674 loss)
I0526 10:52:18.688894 15394 main.cpp:354] Iteration 41600, loss = 0.413949
I0526 10:52:18.688932 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.413949 (* 1 = 0.413949 loss)
I0526 10:52:18.688941 15394 sgd_solver.cpp:43] Iteration 41600, lr = 0.002
I0526 10:52:23.392796 15394 main.cpp:354] Iteration 41610, loss = 0.275311
I0526 10:52:23.392841 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.275311 (* 1 = 0.275311 loss)
I0526 10:52:23.392848 15394 sgd_solver.cpp:43] Iteration 41610, lr = 0.002
I0526 10:52:28.180675 15394 main.cpp:354] Iteration 41620, loss = 0.121432
I0526 10:52:28.180712 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.121431 (* 1 = 0.121431 loss)
I0526 10:52:28.180718 15394 sgd_solver.cpp:43] Iteration 41620, lr = 0.002
I0526 10:52:32.936269 15394 main.cpp:354] Iteration 41630, loss = 0.241984
I0526 10:52:32.936307 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.241983 (* 1 = 0.241983 loss)
I0526 10:52:32.936318 15394 sgd_solver.cpp:43] Iteration 41630, lr = 0.002
I0526 10:52:37.892223 15394 main.cpp:354] Iteration 41640, loss = 0.162401
I0526 10:52:37.892266 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.162401 (* 1 = 0.162401 loss)
I0526 10:52:37.892272 15394 sgd_solver.cpp:43] Iteration 41640, lr = 0.002
I0526 10:52:42.699889 15394 main.cpp:354] Iteration 41650, loss = 0.16256
I0526 10:52:42.699928 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.16256 (* 1 = 0.16256 loss)
I0526 10:52:42.699935 15394 sgd_solver.cpp:43] Iteration 41650, lr = 0.002
I0526 10:52:48.030733 15394 main.cpp:354] Iteration 41660, loss = 0.176026
I0526 10:52:48.030774 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.176025 (* 1 = 0.176025 loss)
I0526 10:52:48.030781 15394 sgd_solver.cpp:43] Iteration 41660, lr = 0.002
I0526 10:52:53.267333 15394 main.cpp:354] Iteration 41670, loss = 0.285748
I0526 10:52:53.267374 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.285747 (* 1 = 0.285747 loss)
I0526 10:52:53.267380 15394 sgd_solver.cpp:43] Iteration 41670, lr = 0.002
I0526 10:52:58.478240 15394 main.cpp:354] Iteration 41680, loss = 0.255198
I0526 10:52:58.478265 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.255197 (* 1 = 0.255197 loss)
I0526 10:52:58.478271 15394 sgd_solver.cpp:43] Iteration 41680, lr = 0.002
I0526 10:53:03.664036 15394 main.cpp:354] Iteration 41690, loss = 0.20725
I0526 10:53:03.664077 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.207249 (* 1 = 0.207249 loss)
I0526 10:53:03.664083 15394 sgd_solver.cpp:43] Iteration 41690, lr = 0.002
I0526 10:53:08.354960 15394 main.cpp:465] Iteration 41700, Testing net (#0)
I0526 10:53:21.445641 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8895
I0526 10:53:21.445679 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.338994 (* 1 = 0.338994 loss)
I0526 10:53:21.948428 15394 main.cpp:354] Iteration 41700, loss = 0.144823
I0526 10:53:21.948467 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.144823 (* 1 = 0.144823 loss)
I0526 10:53:21.948473 15394 sgd_solver.cpp:43] Iteration 41700, lr = 0.002
I0526 10:53:27.386965 15394 main.cpp:354] Iteration 41710, loss = 0.186334
I0526 10:53:27.387004 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186334 (* 1 = 0.186334 loss)
I0526 10:53:27.387011 15394 sgd_solver.cpp:43] Iteration 41710, lr = 0.002
I0526 10:53:32.320049 15394 main.cpp:354] Iteration 41720, loss = 0.289481
I0526 10:53:32.320087 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.289481 (* 1 = 0.289481 loss)
I0526 10:53:32.320094 15394 sgd_solver.cpp:43] Iteration 41720, lr = 0.002
I0526 10:53:37.681143 15394 main.cpp:354] Iteration 41730, loss = 0.19728
I0526 10:53:37.681186 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.197279 (* 1 = 0.197279 loss)
I0526 10:53:37.681195 15394 sgd_solver.cpp:43] Iteration 41730, lr = 0.002
I0526 10:53:42.898784 15394 main.cpp:354] Iteration 41740, loss = 0.231599
I0526 10:53:42.898826 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.231598 (* 1 = 0.231598 loss)
I0526 10:53:42.898833 15394 sgd_solver.cpp:43] Iteration 41740, lr = 0.002
I0526 10:53:48.418282 15394 main.cpp:354] Iteration 41750, loss = 0.148453
I0526 10:53:48.418320 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.148452 (* 1 = 0.148452 loss)
I0526 10:53:48.418328 15394 sgd_solver.cpp:43] Iteration 41750, lr = 0.002
I0526 10:53:53.522505 15394 main.cpp:354] Iteration 41760, loss = 0.215004
I0526 10:53:53.522549 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.215004 (* 1 = 0.215004 loss)
I0526 10:53:53.522560 15394 sgd_solver.cpp:43] Iteration 41760, lr = 0.002
I0526 10:53:58.467118 15394 main.cpp:354] Iteration 41770, loss = 0.162557
I0526 10:53:58.467156 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.162556 (* 1 = 0.162556 loss)
I0526 10:53:58.467164 15394 sgd_solver.cpp:43] Iteration 41770, lr = 0.002
I0526 10:54:03.189939 15394 main.cpp:354] Iteration 41780, loss = 0.242153
I0526 10:54:03.189978 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.242152 (* 1 = 0.242152 loss)
I0526 10:54:03.189985 15394 sgd_solver.cpp:43] Iteration 41780, lr = 0.002
I0526 10:54:08.294644 15394 main.cpp:354] Iteration 41790, loss = 0.121775
I0526 10:54:08.294690 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.121775 (* 1 = 0.121775 loss)
I0526 10:54:08.294697 15394 sgd_solver.cpp:43] Iteration 41790, lr = 0.002
I0526 10:54:13.163198 15394 main.cpp:465] Iteration 41800, Testing net (#0)
I0526 10:54:26.248738 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8906
I0526 10:54:26.248778 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.334842 (* 1 = 0.334842 loss)
I0526 10:54:26.787930 15394 main.cpp:354] Iteration 41800, loss = 0.159748
I0526 10:54:26.787956 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.159748 (* 1 = 0.159748 loss)
I0526 10:54:26.787964 15394 sgd_solver.cpp:43] Iteration 41800, lr = 0.002
I0526 10:54:32.064162 15394 main.cpp:354] Iteration 41810, loss = 0.150113
I0526 10:54:32.064201 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.150113 (* 1 = 0.150113 loss)
I0526 10:54:32.064208 15394 sgd_solver.cpp:43] Iteration 41810, lr = 0.002
I0526 10:54:37.647234 15394 main.cpp:354] Iteration 41820, loss = 0.145523
I0526 10:54:37.647276 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.145522 (* 1 = 0.145522 loss)
I0526 10:54:37.647285 15394 sgd_solver.cpp:43] Iteration 41820, lr = 0.002
I0526 10:54:42.943246 15394 main.cpp:354] Iteration 41830, loss = 0.123352
I0526 10:54:42.943285 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.123351 (* 1 = 0.123351 loss)
I0526 10:54:42.943291 15394 sgd_solver.cpp:43] Iteration 41830, lr = 0.002
I0526 10:54:47.713295 15394 main.cpp:354] Iteration 41840, loss = 0.213083
I0526 10:54:47.713335 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.213083 (* 1 = 0.213083 loss)
I0526 10:54:47.713342 15394 sgd_solver.cpp:43] Iteration 41840, lr = 0.002
I0526 10:54:52.408938 15394 main.cpp:354] Iteration 41850, loss = 0.278133
I0526 10:54:52.408982 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.278133 (* 1 = 0.278133 loss)
I0526 10:54:52.408988 15394 sgd_solver.cpp:43] Iteration 41850, lr = 0.002
I0526 10:54:57.298533 15394 main.cpp:354] Iteration 41860, loss = 0.454093
I0526 10:54:57.298575 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.454093 (* 1 = 0.454093 loss)
I0526 10:54:57.298583 15394 sgd_solver.cpp:43] Iteration 41860, lr = 0.002
I0526 10:55:01.981801 15394 main.cpp:354] Iteration 41870, loss = 0.385033
I0526 10:55:01.981837 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.385032 (* 1 = 0.385032 loss)
I0526 10:55:01.981843 15394 sgd_solver.cpp:43] Iteration 41870, lr = 0.002
I0526 10:55:06.773819 15394 main.cpp:354] Iteration 41880, loss = 0.332571
I0526 10:55:06.773862 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.332571 (* 1 = 0.332571 loss)
I0526 10:55:06.773870 15394 sgd_solver.cpp:43] Iteration 41880, lr = 0.002
I0526 10:55:11.301882 15394 main.cpp:354] Iteration 41890, loss = 0.209331
I0526 10:55:11.301909 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.209331 (* 1 = 0.209331 loss)
I0526 10:55:11.301916 15394 sgd_solver.cpp:43] Iteration 41890, lr = 0.002
I0526 10:55:15.488941 15394 main.cpp:465] Iteration 41900, Testing net (#0)
I0526 10:55:28.573523 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8865
I0526 10:55:28.573565 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.352091 (* 1 = 0.352091 loss)
I0526 10:55:29.046941 15394 main.cpp:354] Iteration 41900, loss = 0.251684
I0526 10:55:29.046968 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.251684 (* 1 = 0.251684 loss)
I0526 10:55:29.046977 15394 sgd_solver.cpp:43] Iteration 41900, lr = 0.002
I0526 10:55:34.297865 15394 main.cpp:354] Iteration 41910, loss = 0.204655
I0526 10:55:34.297911 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204654 (* 1 = 0.204654 loss)
I0526 10:55:34.297919 15394 sgd_solver.cpp:43] Iteration 41910, lr = 0.002
I0526 10:55:39.514590 15394 main.cpp:354] Iteration 41920, loss = 0.10201
I0526 10:55:39.514634 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.102009 (* 1 = 0.102009 loss)
I0526 10:55:39.514641 15394 sgd_solver.cpp:43] Iteration 41920, lr = 0.002
I0526 10:55:44.821790 15394 main.cpp:354] Iteration 41930, loss = 0.13262
I0526 10:55:44.821830 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.132619 (* 1 = 0.132619 loss)
I0526 10:55:44.821835 15394 sgd_solver.cpp:43] Iteration 41930, lr = 0.002
I0526 10:55:49.867799 15394 main.cpp:354] Iteration 41940, loss = 0.206482
I0526 10:55:49.867838 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206481 (* 1 = 0.206481 loss)
I0526 10:55:49.867856 15394 sgd_solver.cpp:43] Iteration 41940, lr = 0.002
I0526 10:55:54.980415 15394 main.cpp:354] Iteration 41950, loss = 0.391174
I0526 10:55:54.980453 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.391174 (* 1 = 0.391174 loss)
I0526 10:55:54.980459 15394 sgd_solver.cpp:43] Iteration 41950, lr = 0.002
I0526 10:56:00.033671 15394 main.cpp:354] Iteration 41960, loss = 0.245489
I0526 10:56:00.033710 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.245489 (* 1 = 0.245489 loss)
I0526 10:56:00.033716 15394 sgd_solver.cpp:43] Iteration 41960, lr = 0.002
I0526 10:56:04.816331 15394 main.cpp:354] Iteration 41970, loss = 0.203901
I0526 10:56:04.816372 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.203901 (* 1 = 0.203901 loss)
I0526 10:56:04.816380 15394 sgd_solver.cpp:43] Iteration 41970, lr = 0.002
I0526 10:56:09.701023 15394 main.cpp:354] Iteration 41980, loss = 0.159185
I0526 10:56:09.701067 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.159184 (* 1 = 0.159184 loss)
I0526 10:56:09.701074 15394 sgd_solver.cpp:43] Iteration 41980, lr = 0.002
I0526 10:56:14.726830 15394 main.cpp:354] Iteration 41990, loss = 0.208052
I0526 10:56:14.726869 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.208051 (* 1 = 0.208051 loss)
I0526 10:56:14.726876 15394 sgd_solver.cpp:43] Iteration 41990, lr = 0.002
I0526 10:56:19.365332 15394 main.cpp:465] Iteration 42000, Testing net (#0)
I0526 10:56:32.456003 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8972
I0526 10:56:32.456043 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.32758 (* 1 = 0.32758 loss)
I0526 10:56:32.994907 15394 main.cpp:354] Iteration 42000, loss = 0.110502
I0526 10:56:32.994935 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.110502 (* 1 = 0.110502 loss)
I0526 10:56:32.994942 15394 sgd_solver.cpp:43] Iteration 42000, lr = 0.002
I0526 10:56:38.449371 15394 main.cpp:354] Iteration 42010, loss = 0.0811989
I0526 10:56:38.449416 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0811984 (* 1 = 0.0811984 loss)
I0526 10:56:38.449422 15394 sgd_solver.cpp:43] Iteration 42010, lr = 0.002
I0526 10:56:43.253222 15394 main.cpp:354] Iteration 42020, loss = 0.372855
I0526 10:56:43.253262 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.372854 (* 1 = 0.372854 loss)
I0526 10:56:43.253269 15394 sgd_solver.cpp:43] Iteration 42020, lr = 0.002
I0526 10:56:48.274142 15394 main.cpp:354] Iteration 42030, loss = 0.116627
I0526 10:56:48.274183 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.116626 (* 1 = 0.116626 loss)
I0526 10:56:48.274189 15394 sgd_solver.cpp:43] Iteration 42030, lr = 0.002
I0526 10:56:52.876032 15394 main.cpp:354] Iteration 42040, loss = 0.203758
I0526 10:56:52.876075 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.203758 (* 1 = 0.203758 loss)
I0526 10:56:52.876081 15394 sgd_solver.cpp:43] Iteration 42040, lr = 0.002
I0526 10:56:57.918766 15394 main.cpp:354] Iteration 42050, loss = 0.237001
I0526 10:56:57.918805 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.237 (* 1 = 0.237 loss)
I0526 10:56:57.918817 15394 sgd_solver.cpp:43] Iteration 42050, lr = 0.002
I0526 10:57:02.511479 15394 main.cpp:354] Iteration 42060, loss = 0.260153
I0526 10:57:02.511518 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.260152 (* 1 = 0.260152 loss)
I0526 10:57:02.511523 15394 sgd_solver.cpp:43] Iteration 42060, lr = 0.002
I0526 10:57:07.510213 15394 main.cpp:354] Iteration 42070, loss = 0.24191
I0526 10:57:07.510254 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.24191 (* 1 = 0.24191 loss)
I0526 10:57:07.510260 15394 sgd_solver.cpp:43] Iteration 42070, lr = 0.002
I0526 10:57:12.917230 15394 main.cpp:354] Iteration 42080, loss = 0.122916
I0526 10:57:12.917268 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.122916 (* 1 = 0.122916 loss)
I0526 10:57:12.917274 15394 sgd_solver.cpp:43] Iteration 42080, lr = 0.002
I0526 10:57:18.198871 15394 main.cpp:354] Iteration 42090, loss = 0.143242
I0526 10:57:18.198910 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.143241 (* 1 = 0.143241 loss)
I0526 10:57:18.198917 15394 sgd_solver.cpp:43] Iteration 42090, lr = 0.002
I0526 10:57:22.886195 15394 main.cpp:465] Iteration 42100, Testing net (#0)
I0526 10:57:35.976078 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8939
I0526 10:57:35.976111 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.339833 (* 1 = 0.339833 loss)
I0526 10:57:36.447152 15394 main.cpp:354] Iteration 42100, loss = 0.28289
I0526 10:57:36.447182 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.282889 (* 1 = 0.282889 loss)
I0526 10:57:36.447190 15394 sgd_solver.cpp:43] Iteration 42100, lr = 0.002
I0526 10:57:41.191900 15394 main.cpp:354] Iteration 42110, loss = 0.225068
I0526 10:57:41.191944 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.225068 (* 1 = 0.225068 loss)
I0526 10:57:41.191951 15394 sgd_solver.cpp:43] Iteration 42110, lr = 0.002
I0526 10:57:46.528800 15394 main.cpp:354] Iteration 42120, loss = 0.111376
I0526 10:57:46.528839 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.111376 (* 1 = 0.111376 loss)
I0526 10:57:46.528846 15394 sgd_solver.cpp:43] Iteration 42120, lr = 0.002
I0526 10:57:51.277434 15394 main.cpp:354] Iteration 42130, loss = 0.262258
I0526 10:57:51.277474 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.262258 (* 1 = 0.262258 loss)
I0526 10:57:51.277480 15394 sgd_solver.cpp:43] Iteration 42130, lr = 0.002
I0526 10:57:56.440788 15394 main.cpp:354] Iteration 42140, loss = 0.211704
I0526 10:57:56.440829 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.211704 (* 1 = 0.211704 loss)
I0526 10:57:56.440835 15394 sgd_solver.cpp:43] Iteration 42140, lr = 0.002
I0526 10:58:01.659894 15394 main.cpp:354] Iteration 42150, loss = 0.265828
I0526 10:58:01.659934 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.265827 (* 1 = 0.265827 loss)
I0526 10:58:01.659940 15394 sgd_solver.cpp:43] Iteration 42150, lr = 0.002
I0526 10:58:07.205261 15394 main.cpp:354] Iteration 42160, loss = 0.249215
I0526 10:58:07.205304 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.249214 (* 1 = 0.249214 loss)
I0526 10:58:07.205312 15394 sgd_solver.cpp:43] Iteration 42160, lr = 0.002
I0526 10:58:12.232429 15394 main.cpp:354] Iteration 42170, loss = 0.306959
I0526 10:58:12.232470 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.306959 (* 1 = 0.306959 loss)
I0526 10:58:12.232475 15394 sgd_solver.cpp:43] Iteration 42170, lr = 0.002
I0526 10:58:17.394472 15394 main.cpp:354] Iteration 42180, loss = 0.20095
I0526 10:58:17.394510 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.200949 (* 1 = 0.200949 loss)
I0526 10:58:17.394516 15394 sgd_solver.cpp:43] Iteration 42180, lr = 0.002
I0526 10:58:22.276461 15394 main.cpp:354] Iteration 42190, loss = 0.311062
I0526 10:58:22.276504 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.311061 (* 1 = 0.311061 loss)
I0526 10:58:22.276510 15394 sgd_solver.cpp:43] Iteration 42190, lr = 0.002
I0526 10:58:26.545045 15394 main.cpp:465] Iteration 42200, Testing net (#0)
I0526 10:58:39.648052 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8934
I0526 10:58:39.648093 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.338442 (* 1 = 0.338442 loss)
I0526 10:58:40.194316 15394 main.cpp:354] Iteration 42200, loss = 0.203673
I0526 10:58:40.194365 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.203673 (* 1 = 0.203673 loss)
I0526 10:58:40.194375 15394 sgd_solver.cpp:43] Iteration 42200, lr = 0.002
I0526 10:58:45.307772 15394 main.cpp:354] Iteration 42210, loss = 0.100823
I0526 10:58:45.307808 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.100823 (* 1 = 0.100823 loss)
I0526 10:58:45.307814 15394 sgd_solver.cpp:43] Iteration 42210, lr = 0.002
I0526 10:58:50.509160 15394 main.cpp:354] Iteration 42220, loss = 0.139383
I0526 10:58:50.509201 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.139383 (* 1 = 0.139383 loss)
I0526 10:58:50.509207 15394 sgd_solver.cpp:43] Iteration 42220, lr = 0.002
I0526 10:58:55.550127 15394 main.cpp:354] Iteration 42230, loss = 0.131744
I0526 10:58:55.550168 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.131744 (* 1 = 0.131744 loss)
I0526 10:58:55.550175 15394 sgd_solver.cpp:43] Iteration 42230, lr = 0.002
I0526 10:59:00.871395 15394 main.cpp:354] Iteration 42240, loss = 0.208755
I0526 10:59:00.871438 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.208755 (* 1 = 0.208755 loss)
I0526 10:59:00.871445 15394 sgd_solver.cpp:43] Iteration 42240, lr = 0.002
I0526 10:59:05.690184 15394 main.cpp:354] Iteration 42250, loss = 0.429445
I0526 10:59:05.690225 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.429444 (* 1 = 0.429444 loss)
I0526 10:59:05.690232 15394 sgd_solver.cpp:43] Iteration 42250, lr = 0.002
I0526 10:59:10.866399 15394 main.cpp:354] Iteration 42260, loss = 0.212608
I0526 10:59:10.866432 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.212608 (* 1 = 0.212608 loss)
I0526 10:59:10.866438 15394 sgd_solver.cpp:43] Iteration 42260, lr = 0.002
I0526 10:59:15.754021 15394 main.cpp:354] Iteration 42270, loss = 0.331026
I0526 10:59:15.754071 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.331026 (* 1 = 0.331026 loss)
I0526 10:59:15.754078 15394 sgd_solver.cpp:43] Iteration 42270, lr = 0.002
I0526 10:59:20.141505 15394 main.cpp:354] Iteration 42280, loss = 0.47775
I0526 10:59:20.141554 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.477749 (* 1 = 0.477749 loss)
I0526 10:59:20.141561 15394 sgd_solver.cpp:43] Iteration 42280, lr = 0.002
I0526 10:59:25.087813 15394 main.cpp:354] Iteration 42290, loss = 0.123517
I0526 10:59:25.087855 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.123516 (* 1 = 0.123516 loss)
I0526 10:59:25.087862 15394 sgd_solver.cpp:43] Iteration 42290, lr = 0.002
I0526 10:59:29.339164 15394 main.cpp:465] Iteration 42300, Testing net (#0)
I0526 10:59:42.461426 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8907
I0526 10:59:42.461460 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.350317 (* 1 = 0.350317 loss)
I0526 10:59:43.038899 15394 main.cpp:354] Iteration 42300, loss = 0.225569
I0526 10:59:43.038940 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.225568 (* 1 = 0.225568 loss)
I0526 10:59:43.038949 15394 sgd_solver.cpp:43] Iteration 42300, lr = 0.002
I0526 10:59:48.287979 15394 main.cpp:354] Iteration 42310, loss = 0.294726
I0526 10:59:48.288018 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.294726 (* 1 = 0.294726 loss)
I0526 10:59:48.288025 15394 sgd_solver.cpp:43] Iteration 42310, lr = 0.002
I0526 10:59:53.810632 15394 main.cpp:354] Iteration 42320, loss = 0.187663
I0526 10:59:53.810688 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187662 (* 1 = 0.187662 loss)
I0526 10:59:53.810694 15394 sgd_solver.cpp:43] Iteration 42320, lr = 0.002
I0526 10:59:58.881335 15394 main.cpp:354] Iteration 42330, loss = 0.332252
I0526 10:59:58.881379 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.332252 (* 1 = 0.332252 loss)
I0526 10:59:58.881387 15394 sgd_solver.cpp:43] Iteration 42330, lr = 0.002
I0526 11:00:03.937072 15394 main.cpp:354] Iteration 42340, loss = 0.268994
I0526 11:00:03.937110 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.268993 (* 1 = 0.268993 loss)
I0526 11:00:03.937116 15394 sgd_solver.cpp:43] Iteration 42340, lr = 0.002
I0526 11:00:09.137158 15394 main.cpp:354] Iteration 42350, loss = 0.0790235
I0526 11:00:09.137202 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.079023 (* 1 = 0.079023 loss)
I0526 11:00:09.137208 15394 sgd_solver.cpp:43] Iteration 42350, lr = 0.002
I0526 11:00:14.301254 15394 main.cpp:354] Iteration 42360, loss = 0.24139
I0526 11:00:14.301291 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.24139 (* 1 = 0.24139 loss)
I0526 11:00:14.301311 15394 sgd_solver.cpp:43] Iteration 42360, lr = 0.002
I0526 11:00:19.318910 15394 main.cpp:354] Iteration 42370, loss = 0.189489
I0526 11:00:19.318949 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.189488 (* 1 = 0.189488 loss)
I0526 11:00:19.318955 15394 sgd_solver.cpp:43] Iteration 42370, lr = 0.002
I0526 11:00:24.543792 15394 main.cpp:354] Iteration 42380, loss = 0.133845
I0526 11:00:24.543838 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.133845 (* 1 = 0.133845 loss)
I0526 11:00:24.543844 15394 sgd_solver.cpp:43] Iteration 42380, lr = 0.002
I0526 11:00:29.140377 15394 main.cpp:354] Iteration 42390, loss = 0.227114
I0526 11:00:29.140416 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.227113 (* 1 = 0.227113 loss)
I0526 11:00:29.140422 15394 sgd_solver.cpp:43] Iteration 42390, lr = 0.002
I0526 11:00:33.908701 15394 main.cpp:465] Iteration 42400, Testing net (#0)
I0526 11:00:46.993891 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8933
I0526 11:00:46.993930 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.336577 (* 1 = 0.336577 loss)
I0526 11:00:47.496425 15394 main.cpp:354] Iteration 42400, loss = 0.146209
I0526 11:00:47.496462 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.146209 (* 1 = 0.146209 loss)
I0526 11:00:47.496469 15394 sgd_solver.cpp:43] Iteration 42400, lr = 0.002
I0526 11:00:51.935709 15394 main.cpp:354] Iteration 42410, loss = 0.147324
I0526 11:00:51.935744 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.147323 (* 1 = 0.147323 loss)
I0526 11:00:51.935750 15394 sgd_solver.cpp:43] Iteration 42410, lr = 0.002
I0526 11:00:57.136505 15394 main.cpp:354] Iteration 42420, loss = 0.275086
I0526 11:00:57.136543 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.275086 (* 1 = 0.275086 loss)
I0526 11:00:57.136549 15394 sgd_solver.cpp:43] Iteration 42420, lr = 0.002
I0526 11:01:02.233388 15394 main.cpp:354] Iteration 42430, loss = 0.18996
I0526 11:01:02.233428 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.18996 (* 1 = 0.18996 loss)
I0526 11:01:02.233435 15394 sgd_solver.cpp:43] Iteration 42430, lr = 0.002
I0526 11:01:07.403116 15394 main.cpp:354] Iteration 42440, loss = 0.453526
I0526 11:01:07.403162 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.453526 (* 1 = 0.453526 loss)
I0526 11:01:07.403168 15394 sgd_solver.cpp:43] Iteration 42440, lr = 0.002
I0526 11:01:12.419113 15394 main.cpp:354] Iteration 42450, loss = 0.219219
I0526 11:01:12.419152 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.219218 (* 1 = 0.219218 loss)
I0526 11:01:12.419159 15394 sgd_solver.cpp:43] Iteration 42450, lr = 0.002
I0526 11:01:17.132134 15394 main.cpp:354] Iteration 42460, loss = 0.20083
I0526 11:01:17.132159 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.20083 (* 1 = 0.20083 loss)
I0526 11:01:17.132166 15394 sgd_solver.cpp:43] Iteration 42460, lr = 0.002
I0526 11:01:22.690937 15394 main.cpp:354] Iteration 42470, loss = 0.0986138
I0526 11:01:22.690980 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0986133 (* 1 = 0.0986133 loss)
I0526 11:01:22.690992 15394 sgd_solver.cpp:43] Iteration 42470, lr = 0.002
I0526 11:01:27.325286 15394 main.cpp:354] Iteration 42480, loss = 0.313932
I0526 11:01:27.325326 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.313932 (* 1 = 0.313932 loss)
I0526 11:01:27.325332 15394 sgd_solver.cpp:43] Iteration 42480, lr = 0.002
I0526 11:01:32.745193 15394 main.cpp:354] Iteration 42490, loss = 0.262688
I0526 11:01:32.745231 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.262688 (* 1 = 0.262688 loss)
I0526 11:01:32.745237 15394 sgd_solver.cpp:43] Iteration 42490, lr = 0.002
I0526 11:01:37.551607 15394 main.cpp:465] Iteration 42500, Testing net (#0)
I0526 11:01:50.638969 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8912
I0526 11:01:50.639009 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.344256 (* 1 = 0.344256 loss)
I0526 11:01:50.932240 15394 main.cpp:354] Iteration 42500, loss = 0.424379
I0526 11:01:50.932276 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.424378 (* 1 = 0.424378 loss)
I0526 11:01:50.932283 15394 sgd_solver.cpp:43] Iteration 42500, lr = 0.002
I0526 11:01:55.611143 15394 main.cpp:354] Iteration 42510, loss = 0.112481
I0526 11:01:55.611186 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.11248 (* 1 = 0.11248 loss)
I0526 11:01:55.611191 15394 sgd_solver.cpp:43] Iteration 42510, lr = 0.002
I0526 11:02:00.639912 15394 main.cpp:354] Iteration 42520, loss = 0.185395
I0526 11:02:00.639951 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.185394 (* 1 = 0.185394 loss)
I0526 11:02:00.639958 15394 sgd_solver.cpp:43] Iteration 42520, lr = 0.002
I0526 11:02:05.211297 15394 main.cpp:354] Iteration 42530, loss = 0.234107
I0526 11:02:05.211335 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.234106 (* 1 = 0.234106 loss)
I0526 11:02:05.211341 15394 sgd_solver.cpp:43] Iteration 42530, lr = 0.002
I0526 11:02:10.178690 15394 main.cpp:354] Iteration 42540, loss = 0.199888
I0526 11:02:10.178745 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.199888 (* 1 = 0.199888 loss)
I0526 11:02:10.178750 15394 sgd_solver.cpp:43] Iteration 42540, lr = 0.002
I0526 11:02:15.122666 15394 main.cpp:354] Iteration 42550, loss = 0.286713
I0526 11:02:15.122717 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.286713 (* 1 = 0.286713 loss)
I0526 11:02:15.122723 15394 sgd_solver.cpp:43] Iteration 42550, lr = 0.002
I0526 11:02:20.143769 15394 main.cpp:354] Iteration 42560, loss = 0.365585
I0526 11:02:20.143810 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.365584 (* 1 = 0.365584 loss)
I0526 11:02:20.143816 15394 sgd_solver.cpp:43] Iteration 42560, lr = 0.002
I0526 11:02:25.526576 15394 main.cpp:354] Iteration 42570, loss = 0.120123
I0526 11:02:25.526621 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.120122 (* 1 = 0.120122 loss)
I0526 11:02:25.526628 15394 sgd_solver.cpp:43] Iteration 42570, lr = 0.002
I0526 11:02:30.904052 15394 main.cpp:354] Iteration 42580, loss = 0.352442
I0526 11:02:30.904091 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.352442 (* 1 = 0.352442 loss)
I0526 11:02:30.904098 15394 sgd_solver.cpp:43] Iteration 42580, lr = 0.002
I0526 11:02:35.565335 15394 main.cpp:354] Iteration 42590, loss = 0.346487
I0526 11:02:35.565376 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.346486 (* 1 = 0.346486 loss)
I0526 11:02:35.565383 15394 sgd_solver.cpp:43] Iteration 42590, lr = 0.002
I0526 11:02:39.903785 15394 main.cpp:465] Iteration 42600, Testing net (#0)
I0526 11:02:52.983986 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8909
I0526 11:02:52.984025 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.346606 (* 1 = 0.346606 loss)
I0526 11:02:53.450925 15394 main.cpp:354] Iteration 42600, loss = 0.164217
I0526 11:02:53.450965 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.164216 (* 1 = 0.164216 loss)
I0526 11:02:53.450979 15394 sgd_solver.cpp:43] Iteration 42600, lr = 0.002
I0526 11:02:58.545169 15394 main.cpp:354] Iteration 42610, loss = 0.222959
I0526 11:02:58.545207 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.222959 (* 1 = 0.222959 loss)
I0526 11:02:58.545213 15394 sgd_solver.cpp:43] Iteration 42610, lr = 0.002
I0526 11:03:03.641230 15394 main.cpp:354] Iteration 42620, loss = 0.27228
I0526 11:03:03.641269 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.272279 (* 1 = 0.272279 loss)
I0526 11:03:03.641275 15394 sgd_solver.cpp:43] Iteration 42620, lr = 0.002
I0526 11:03:08.354519 15394 main.cpp:354] Iteration 42630, loss = 0.149508
I0526 11:03:08.354562 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.149507 (* 1 = 0.149507 loss)
I0526 11:03:08.354568 15394 sgd_solver.cpp:43] Iteration 42630, lr = 0.002
I0526 11:03:13.375715 15394 main.cpp:354] Iteration 42640, loss = 0.302533
I0526 11:03:13.375754 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.302532 (* 1 = 0.302532 loss)
I0526 11:03:13.375761 15394 sgd_solver.cpp:43] Iteration 42640, lr = 0.002
I0526 11:03:18.735242 15394 main.cpp:354] Iteration 42650, loss = 0.241555
I0526 11:03:18.735281 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.241554 (* 1 = 0.241554 loss)
I0526 11:03:18.735287 15394 sgd_solver.cpp:43] Iteration 42650, lr = 0.002
I0526 11:03:23.581125 15394 main.cpp:354] Iteration 42660, loss = 0.434233
I0526 11:03:23.581187 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.434233 (* 1 = 0.434233 loss)
I0526 11:03:23.581198 15394 sgd_solver.cpp:43] Iteration 42660, lr = 0.002
I0526 11:03:28.354542 15394 main.cpp:354] Iteration 42670, loss = 0.226706
I0526 11:03:28.354600 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.226705 (* 1 = 0.226705 loss)
I0526 11:03:28.354611 15394 sgd_solver.cpp:43] Iteration 42670, lr = 0.002
I0526 11:03:33.465335 15394 main.cpp:354] Iteration 42680, loss = 0.263227
I0526 11:03:33.465376 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.263226 (* 1 = 0.263226 loss)
I0526 11:03:33.465383 15394 sgd_solver.cpp:43] Iteration 42680, lr = 0.002
I0526 11:03:38.371246 15394 main.cpp:354] Iteration 42690, loss = 0.207602
I0526 11:03:38.371292 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.207601 (* 1 = 0.207601 loss)
I0526 11:03:38.371299 15394 sgd_solver.cpp:43] Iteration 42690, lr = 0.002
I0526 11:03:43.165410 15394 main.cpp:465] Iteration 42700, Testing net (#0)
I0526 11:03:56.253996 15394 main.cpp:532]     Test net output #0: Accuracy = 0.892
I0526 11:03:56.254040 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.33781 (* 1 = 0.33781 loss)
I0526 11:03:56.690476 15394 main.cpp:354] Iteration 42700, loss = 0.361539
I0526 11:03:56.690516 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.361539 (* 1 = 0.361539 loss)
I0526 11:03:56.690523 15394 sgd_solver.cpp:43] Iteration 42700, lr = 0.002
I0526 11:04:01.756322 15394 main.cpp:354] Iteration 42710, loss = 0.247938
I0526 11:04:01.756363 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.247937 (* 1 = 0.247937 loss)
I0526 11:04:01.756371 15394 sgd_solver.cpp:43] Iteration 42710, lr = 0.002
I0526 11:04:06.702060 15394 main.cpp:354] Iteration 42720, loss = 0.304936
I0526 11:04:06.702101 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.304935 (* 1 = 0.304935 loss)
I0526 11:04:06.702107 15394 sgd_solver.cpp:43] Iteration 42720, lr = 0.002
I0526 11:04:11.551252 15394 main.cpp:354] Iteration 42730, loss = 0.188037
I0526 11:04:11.551291 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.188036 (* 1 = 0.188036 loss)
I0526 11:04:11.551297 15394 sgd_solver.cpp:43] Iteration 42730, lr = 0.002
I0526 11:04:16.257961 15394 main.cpp:354] Iteration 42740, loss = 0.304398
I0526 11:04:16.258002 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.304398 (* 1 = 0.304398 loss)
I0526 11:04:16.258008 15394 sgd_solver.cpp:43] Iteration 42740, lr = 0.002
I0526 11:04:21.575989 15394 main.cpp:354] Iteration 42750, loss = 0.306422
I0526 11:04:21.576030 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.306422 (* 1 = 0.306422 loss)
I0526 11:04:21.576035 15394 sgd_solver.cpp:43] Iteration 42750, lr = 0.002
I0526 11:04:26.229668 15394 main.cpp:354] Iteration 42760, loss = 0.134116
I0526 11:04:26.229706 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.134116 (* 1 = 0.134116 loss)
I0526 11:04:26.229712 15394 sgd_solver.cpp:43] Iteration 42760, lr = 0.002
I0526 11:04:31.582000 15394 main.cpp:354] Iteration 42770, loss = 0.204136
I0526 11:04:31.582041 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204135 (* 1 = 0.204135 loss)
I0526 11:04:31.582047 15394 sgd_solver.cpp:43] Iteration 42770, lr = 0.002
I0526 11:04:36.711602 15394 main.cpp:354] Iteration 42780, loss = 0.401432
I0526 11:04:36.711642 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.401431 (* 1 = 0.401431 loss)
I0526 11:04:36.711647 15394 sgd_solver.cpp:43] Iteration 42780, lr = 0.002
I0526 11:04:41.821171 15394 main.cpp:354] Iteration 42790, loss = 0.212069
I0526 11:04:41.821214 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.212068 (* 1 = 0.212068 loss)
I0526 11:04:41.821221 15394 sgd_solver.cpp:43] Iteration 42790, lr = 0.002
I0526 11:04:46.395294 15394 main.cpp:465] Iteration 42800, Testing net (#0)
I0526 11:04:59.482833 15394 main.cpp:532]     Test net output #0: Accuracy = 0.892
I0526 11:04:59.482877 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.346198 (* 1 = 0.346198 loss)
I0526 11:05:00.094960 15394 main.cpp:354] Iteration 42800, loss = 0.326347
I0526 11:05:00.095005 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.326346 (* 1 = 0.326346 loss)
I0526 11:05:00.095015 15394 sgd_solver.cpp:43] Iteration 42800, lr = 0.002
I0526 11:05:04.973573 15394 main.cpp:354] Iteration 42810, loss = 0.25086
I0526 11:05:04.973616 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.250859 (* 1 = 0.250859 loss)
I0526 11:05:04.973623 15394 sgd_solver.cpp:43] Iteration 42810, lr = 0.002
I0526 11:05:10.367197 15394 main.cpp:354] Iteration 42820, loss = 0.207122
I0526 11:05:10.367228 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.207121 (* 1 = 0.207121 loss)
I0526 11:05:10.367235 15394 sgd_solver.cpp:43] Iteration 42820, lr = 0.002
I0526 11:05:15.531574 15394 main.cpp:354] Iteration 42830, loss = 0.103827
I0526 11:05:15.531612 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.103827 (* 1 = 0.103827 loss)
I0526 11:05:15.531618 15394 sgd_solver.cpp:43] Iteration 42830, lr = 0.002
I0526 11:05:20.370738 15394 main.cpp:354] Iteration 42840, loss = 0.997425
I0526 11:05:20.370777 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.997425 (* 1 = 0.997425 loss)
I0526 11:05:20.370784 15394 sgd_solver.cpp:43] Iteration 42840, lr = 0.002
I0526 11:05:25.182662 15394 main.cpp:354] Iteration 42850, loss = 0.0891107
I0526 11:05:25.182706 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0891102 (* 1 = 0.0891102 loss)
I0526 11:05:25.182713 15394 sgd_solver.cpp:43] Iteration 42850, lr = 0.002
I0526 11:05:30.227481 15394 main.cpp:354] Iteration 42860, loss = 0.108975
I0526 11:05:30.227522 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.108975 (* 1 = 0.108975 loss)
I0526 11:05:30.227530 15394 sgd_solver.cpp:43] Iteration 42860, lr = 0.002
I0526 11:05:35.099153 15394 main.cpp:354] Iteration 42870, loss = 0.203664
I0526 11:05:35.099192 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.203663 (* 1 = 0.203663 loss)
I0526 11:05:35.099200 15394 sgd_solver.cpp:43] Iteration 42870, lr = 0.002
I0526 11:05:40.104933 15394 main.cpp:354] Iteration 42880, loss = 0.328209
I0526 11:05:40.104979 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.328209 (* 1 = 0.328209 loss)
I0526 11:05:40.104985 15394 sgd_solver.cpp:43] Iteration 42880, lr = 0.002
I0526 11:05:45.246584 15394 main.cpp:354] Iteration 42890, loss = 0.104472
I0526 11:05:45.246624 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.104472 (* 1 = 0.104472 loss)
I0526 11:05:45.246636 15394 sgd_solver.cpp:43] Iteration 42890, lr = 0.002
I0526 11:05:49.799890 15394 main.cpp:465] Iteration 42900, Testing net (#0)
I0526 11:06:02.887574 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8924
I0526 11:06:02.887614 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.351114 (* 1 = 0.351114 loss)
I0526 11:06:03.358639 15394 main.cpp:354] Iteration 42900, loss = 0.186259
I0526 11:06:03.358680 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186259 (* 1 = 0.186259 loss)
I0526 11:06:03.358687 15394 sgd_solver.cpp:43] Iteration 42900, lr = 0.002
I0526 11:06:08.387387 15394 main.cpp:354] Iteration 42910, loss = 0.257199
I0526 11:06:08.387434 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.257199 (* 1 = 0.257199 loss)
I0526 11:06:08.387440 15394 sgd_solver.cpp:43] Iteration 42910, lr = 0.002
I0526 11:06:13.558095 15394 main.cpp:354] Iteration 42920, loss = 0.312272
I0526 11:06:13.558136 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.312271 (* 1 = 0.312271 loss)
I0526 11:06:13.558143 15394 sgd_solver.cpp:43] Iteration 42920, lr = 0.002
I0526 11:06:18.244421 15394 main.cpp:354] Iteration 42930, loss = 0.159694
I0526 11:06:18.244460 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.159693 (* 1 = 0.159693 loss)
I0526 11:06:18.244467 15394 sgd_solver.cpp:43] Iteration 42930, lr = 0.002
I0526 11:06:22.843920 15394 main.cpp:354] Iteration 42940, loss = 0.813195
I0526 11:06:22.843963 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.813195 (* 1 = 0.813195 loss)
I0526 11:06:22.843969 15394 sgd_solver.cpp:43] Iteration 42940, lr = 0.002
I0526 11:06:28.033323 15394 main.cpp:354] Iteration 42950, loss = 0.238628
I0526 11:06:28.033362 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.238627 (* 1 = 0.238627 loss)
I0526 11:06:28.033368 15394 sgd_solver.cpp:43] Iteration 42950, lr = 0.002
I0526 11:06:32.925626 15394 main.cpp:354] Iteration 42960, loss = 0.201622
I0526 11:06:32.925664 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.201622 (* 1 = 0.201622 loss)
I0526 11:06:32.925670 15394 sgd_solver.cpp:43] Iteration 42960, lr = 0.002
I0526 11:06:38.482931 15394 main.cpp:354] Iteration 42970, loss = 0.175612
I0526 11:06:38.482975 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.175612 (* 1 = 0.175612 loss)
I0526 11:06:38.482981 15394 sgd_solver.cpp:43] Iteration 42970, lr = 0.002
I0526 11:06:43.493273 15394 main.cpp:354] Iteration 42980, loss = 0.264848
I0526 11:06:43.493312 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.264848 (* 1 = 0.264848 loss)
I0526 11:06:43.493319 15394 sgd_solver.cpp:43] Iteration 42980, lr = 0.002
I0526 11:06:48.966509 15394 main.cpp:354] Iteration 42990, loss = 0.0756829
I0526 11:06:48.966547 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0756824 (* 1 = 0.0756824 loss)
I0526 11:06:48.966554 15394 sgd_solver.cpp:43] Iteration 42990, lr = 0.002
I0526 11:06:53.736026 15394 main.cpp:465] Iteration 43000, Testing net (#0)
I0526 11:07:06.822154 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8931
I0526 11:07:06.822193 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.347077 (* 1 = 0.347077 loss)
I0526 11:07:07.330703 15394 main.cpp:354] Iteration 43000, loss = 0.256887
I0526 11:07:07.330744 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.256887 (* 1 = 0.256887 loss)
I0526 11:07:07.330751 15394 sgd_solver.cpp:43] Iteration 43000, lr = 0.002
I0526 11:07:12.020319 15394 main.cpp:354] Iteration 43010, loss = 0.260484
I0526 11:07:12.020370 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.260483 (* 1 = 0.260483 loss)
I0526 11:07:12.020376 15394 sgd_solver.cpp:43] Iteration 43010, lr = 0.002
I0526 11:07:16.922063 15394 main.cpp:354] Iteration 43020, loss = 0.160715
I0526 11:07:16.922106 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.160715 (* 1 = 0.160715 loss)
I0526 11:07:16.922116 15394 sgd_solver.cpp:43] Iteration 43020, lr = 0.002
I0526 11:07:21.494529 15394 main.cpp:354] Iteration 43030, loss = 0.448831
I0526 11:07:21.494570 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.448831 (* 1 = 0.448831 loss)
I0526 11:07:21.494577 15394 sgd_solver.cpp:43] Iteration 43030, lr = 0.002
I0526 11:07:25.807865 15394 main.cpp:354] Iteration 43040, loss = 0.868858
I0526 11:07:25.807909 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.868858 (* 1 = 0.868858 loss)
I0526 11:07:25.807916 15394 sgd_solver.cpp:43] Iteration 43040, lr = 0.002
I0526 11:07:31.175731 15394 main.cpp:354] Iteration 43050, loss = 0.46739
I0526 11:07:31.175771 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.467389 (* 1 = 0.467389 loss)
I0526 11:07:31.175777 15394 sgd_solver.cpp:43] Iteration 43050, lr = 0.002
I0526 11:07:36.336275 15394 main.cpp:354] Iteration 43060, loss = 0.445595
I0526 11:07:36.336315 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.445595 (* 1 = 0.445595 loss)
I0526 11:07:36.336321 15394 sgd_solver.cpp:43] Iteration 43060, lr = 0.002
I0526 11:07:41.077206 15394 main.cpp:354] Iteration 43070, loss = 0.343571
I0526 11:07:41.077249 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.343571 (* 1 = 0.343571 loss)
I0526 11:07:41.077255 15394 sgd_solver.cpp:43] Iteration 43070, lr = 0.002
I0526 11:07:46.482898 15394 main.cpp:354] Iteration 43080, loss = 0.221853
I0526 11:07:46.482936 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.221852 (* 1 = 0.221852 loss)
I0526 11:07:46.482942 15394 sgd_solver.cpp:43] Iteration 43080, lr = 0.002
I0526 11:07:51.504515 15394 main.cpp:354] Iteration 43090, loss = 0.471141
I0526 11:07:51.504554 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.471141 (* 1 = 0.471141 loss)
I0526 11:07:51.504560 15394 sgd_solver.cpp:43] Iteration 43090, lr = 0.002
I0526 11:07:56.107626 15394 main.cpp:465] Iteration 43100, Testing net (#0)
I0526 11:08:09.203321 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8914
I0526 11:08:09.203362 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.351814 (* 1 = 0.351814 loss)
I0526 11:08:09.706010 15394 main.cpp:354] Iteration 43100, loss = 0.177455
I0526 11:08:09.706050 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.177454 (* 1 = 0.177454 loss)
I0526 11:08:09.706058 15394 sgd_solver.cpp:43] Iteration 43100, lr = 0.002
I0526 11:08:15.139453 15394 main.cpp:354] Iteration 43110, loss = 0.294106
I0526 11:08:15.139492 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.294105 (* 1 = 0.294105 loss)
I0526 11:08:15.139498 15394 sgd_solver.cpp:43] Iteration 43110, lr = 0.002
I0526 11:08:20.300079 15394 main.cpp:354] Iteration 43120, loss = 0.11811
I0526 11:08:20.300118 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.11811 (* 1 = 0.11811 loss)
I0526 11:08:20.300124 15394 sgd_solver.cpp:43] Iteration 43120, lr = 0.002
I0526 11:08:25.153745 15394 main.cpp:354] Iteration 43130, loss = 0.330134
I0526 11:08:25.153790 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.330133 (* 1 = 0.330133 loss)
I0526 11:08:25.153796 15394 sgd_solver.cpp:43] Iteration 43130, lr = 0.002
I0526 11:08:29.730419 15394 main.cpp:354] Iteration 43140, loss = 0.365209
I0526 11:08:29.730459 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.365209 (* 1 = 0.365209 loss)
I0526 11:08:29.730465 15394 sgd_solver.cpp:43] Iteration 43140, lr = 0.002
I0526 11:08:34.791573 15394 main.cpp:354] Iteration 43150, loss = 0.115343
I0526 11:08:34.791613 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.115343 (* 1 = 0.115343 loss)
I0526 11:08:34.791620 15394 sgd_solver.cpp:43] Iteration 43150, lr = 0.002
I0526 11:08:40.409580 15394 main.cpp:354] Iteration 43160, loss = 0.0926497
I0526 11:08:40.409623 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0926493 (* 1 = 0.0926493 loss)
I0526 11:08:40.409631 15394 sgd_solver.cpp:43] Iteration 43160, lr = 0.002
I0526 11:08:45.289788 15394 main.cpp:354] Iteration 43170, loss = 0.569374
I0526 11:08:45.289829 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.569373 (* 1 = 0.569373 loss)
I0526 11:08:45.289836 15394 sgd_solver.cpp:43] Iteration 43170, lr = 0.002
I0526 11:08:49.731573 15394 main.cpp:354] Iteration 43180, loss = 0.383397
I0526 11:08:49.731626 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.383396 (* 1 = 0.383396 loss)
I0526 11:08:49.731633 15394 sgd_solver.cpp:43] Iteration 43180, lr = 0.002
I0526 11:08:54.809633 15394 main.cpp:354] Iteration 43190, loss = 0.353278
I0526 11:08:54.809676 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.353278 (* 1 = 0.353278 loss)
I0526 11:08:54.809684 15394 sgd_solver.cpp:43] Iteration 43190, lr = 0.002
I0526 11:08:59.220911 15394 main.cpp:465] Iteration 43200, Testing net (#0)
I0526 11:09:12.308467 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8847
I0526 11:09:12.308509 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.364406 (* 1 = 0.364406 loss)
I0526 11:09:12.774842 15394 main.cpp:354] Iteration 43200, loss = 0.135283
I0526 11:09:12.774880 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.135283 (* 1 = 0.135283 loss)
I0526 11:09:12.774888 15394 sgd_solver.cpp:43] Iteration 43200, lr = 0.002
I0526 11:09:18.038491 15394 main.cpp:354] Iteration 43210, loss = 0.237283
I0526 11:09:18.038532 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.237282 (* 1 = 0.237282 loss)
I0526 11:09:18.038537 15394 sgd_solver.cpp:43] Iteration 43210, lr = 0.002
I0526 11:09:23.199136 15394 main.cpp:354] Iteration 43220, loss = 0.241441
I0526 11:09:23.199179 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.24144 (* 1 = 0.24144 loss)
I0526 11:09:23.199187 15394 sgd_solver.cpp:43] Iteration 43220, lr = 0.002
I0526 11:09:28.225268 15394 main.cpp:354] Iteration 43230, loss = 0.343855
I0526 11:09:28.225307 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.343854 (* 1 = 0.343854 loss)
I0526 11:09:28.225313 15394 sgd_solver.cpp:43] Iteration 43230, lr = 0.002
I0526 11:09:33.459506 15394 main.cpp:354] Iteration 43240, loss = 0.110523
I0526 11:09:33.459543 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.110522 (* 1 = 0.110522 loss)
I0526 11:09:33.459550 15394 sgd_solver.cpp:43] Iteration 43240, lr = 0.002
I0526 11:09:38.629588 15394 main.cpp:354] Iteration 43250, loss = 0.214051
I0526 11:09:38.629631 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.21405 (* 1 = 0.21405 loss)
I0526 11:09:38.629637 15394 sgd_solver.cpp:43] Iteration 43250, lr = 0.002
I0526 11:09:43.296088 15394 main.cpp:354] Iteration 43260, loss = 0.348452
I0526 11:09:43.296126 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.348452 (* 1 = 0.348452 loss)
I0526 11:09:43.296133 15394 sgd_solver.cpp:43] Iteration 43260, lr = 0.002
I0526 11:09:48.261767 15394 main.cpp:354] Iteration 43270, loss = 0.297712
I0526 11:09:48.261808 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.297711 (* 1 = 0.297711 loss)
I0526 11:09:48.261816 15394 sgd_solver.cpp:43] Iteration 43270, lr = 0.002
I0526 11:09:53.478184 15394 main.cpp:354] Iteration 43280, loss = 0.116852
I0526 11:09:53.478229 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.116852 (* 1 = 0.116852 loss)
I0526 11:09:53.478235 15394 sgd_solver.cpp:43] Iteration 43280, lr = 0.002
I0526 11:09:58.204793 15394 main.cpp:354] Iteration 43290, loss = 0.144369
I0526 11:09:58.204834 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.144368 (* 1 = 0.144368 loss)
I0526 11:09:58.204841 15394 sgd_solver.cpp:43] Iteration 43290, lr = 0.002
I0526 11:10:02.458089 15394 main.cpp:465] Iteration 43300, Testing net (#0)
I0526 11:10:15.546739 15394 main.cpp:532]     Test net output #0: Accuracy = 0.889
I0526 11:10:15.546778 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.363385 (* 1 = 0.363385 loss)
I0526 11:10:16.048516 15394 main.cpp:354] Iteration 43300, loss = 0.248047
I0526 11:10:16.048557 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.248047 (* 1 = 0.248047 loss)
I0526 11:10:16.048564 15394 sgd_solver.cpp:43] Iteration 43300, lr = 0.002
I0526 11:10:21.210464 15394 main.cpp:354] Iteration 43310, loss = 0.30864
I0526 11:10:21.210505 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.30864 (* 1 = 0.30864 loss)
I0526 11:10:21.210512 15394 sgd_solver.cpp:43] Iteration 43310, lr = 0.002
I0526 11:10:26.363466 15394 main.cpp:354] Iteration 43320, loss = 0.207445
I0526 11:10:26.363510 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.207444 (* 1 = 0.207444 loss)
I0526 11:10:26.363517 15394 sgd_solver.cpp:43] Iteration 43320, lr = 0.002
I0526 11:10:31.500671 15394 main.cpp:354] Iteration 43330, loss = 0.287098
I0526 11:10:31.500712 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.287097 (* 1 = 0.287097 loss)
I0526 11:10:31.500718 15394 sgd_solver.cpp:43] Iteration 43330, lr = 0.002
I0526 11:10:36.302350 15394 main.cpp:354] Iteration 43340, loss = 0.174591
I0526 11:10:36.302393 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.174591 (* 1 = 0.174591 loss)
I0526 11:10:36.302399 15394 sgd_solver.cpp:43] Iteration 43340, lr = 0.002
I0526 11:10:40.882942 15394 main.cpp:354] Iteration 43350, loss = 0.352426
I0526 11:10:40.882985 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.352425 (* 1 = 0.352425 loss)
I0526 11:10:40.882992 15394 sgd_solver.cpp:43] Iteration 43350, lr = 0.002
I0526 11:10:46.084635 15394 main.cpp:354] Iteration 43360, loss = 0.14891
I0526 11:10:46.084673 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.14891 (* 1 = 0.14891 loss)
I0526 11:10:46.084681 15394 sgd_solver.cpp:43] Iteration 43360, lr = 0.002
I0526 11:10:51.300117 15394 main.cpp:354] Iteration 43370, loss = 0.165507
I0526 11:10:51.300153 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.165507 (* 1 = 0.165507 loss)
I0526 11:10:51.300159 15394 sgd_solver.cpp:43] Iteration 43370, lr = 0.002
I0526 11:10:56.046970 15394 main.cpp:354] Iteration 43380, loss = 0.21666
I0526 11:10:56.047015 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.21666 (* 1 = 0.21666 loss)
I0526 11:10:56.047022 15394 sgd_solver.cpp:43] Iteration 43380, lr = 0.002
I0526 11:11:01.194994 15394 main.cpp:354] Iteration 43390, loss = 0.154866
I0526 11:11:01.195034 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.154865 (* 1 = 0.154865 loss)
I0526 11:11:01.195039 15394 sgd_solver.cpp:43] Iteration 43390, lr = 0.002
I0526 11:11:05.958114 15394 main.cpp:465] Iteration 43400, Testing net (#0)
I0526 11:11:19.044919 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8937
I0526 11:11:19.044961 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.336135 (* 1 = 0.336135 loss)
I0526 11:11:19.549942 15394 main.cpp:354] Iteration 43400, loss = 0.189045
I0526 11:11:19.549984 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.189044 (* 1 = 0.189044 loss)
I0526 11:11:19.549993 15394 sgd_solver.cpp:43] Iteration 43400, lr = 0.002
I0526 11:11:24.878970 15394 main.cpp:354] Iteration 43410, loss = 0.135824
I0526 11:11:24.879009 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.135823 (* 1 = 0.135823 loss)
I0526 11:11:24.879015 15394 sgd_solver.cpp:43] Iteration 43410, lr = 0.002
I0526 11:11:29.737471 15394 main.cpp:354] Iteration 43420, loss = 0.224307
I0526 11:11:29.737510 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.224306 (* 1 = 0.224306 loss)
I0526 11:11:29.737516 15394 sgd_solver.cpp:43] Iteration 43420, lr = 0.002
I0526 11:11:34.719947 15394 main.cpp:354] Iteration 43430, loss = 0.212331
I0526 11:11:34.719988 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.21233 (* 1 = 0.21233 loss)
I0526 11:11:34.719995 15394 sgd_solver.cpp:43] Iteration 43430, lr = 0.002
I0526 11:11:39.875243 15394 main.cpp:354] Iteration 43440, loss = 0.202685
I0526 11:11:39.875284 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.202685 (* 1 = 0.202685 loss)
I0526 11:11:39.875296 15394 sgd_solver.cpp:43] Iteration 43440, lr = 0.002
I0526 11:11:45.208760 15394 main.cpp:354] Iteration 43450, loss = 0.163123
I0526 11:11:45.208801 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.163123 (* 1 = 0.163123 loss)
I0526 11:11:45.208806 15394 sgd_solver.cpp:43] Iteration 43450, lr = 0.002
I0526 11:11:50.158443 15394 main.cpp:354] Iteration 43460, loss = 0.19707
I0526 11:11:50.158483 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.19707 (* 1 = 0.19707 loss)
I0526 11:11:50.158490 15394 sgd_solver.cpp:43] Iteration 43460, lr = 0.002
I0526 11:11:55.237568 15394 main.cpp:354] Iteration 43470, loss = 0.296559
I0526 11:11:55.237608 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.296559 (* 1 = 0.296559 loss)
I0526 11:11:55.237615 15394 sgd_solver.cpp:43] Iteration 43470, lr = 0.002
I0526 11:12:00.337606 15394 main.cpp:354] Iteration 43480, loss = 0.23749
I0526 11:12:00.337646 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.237489 (* 1 = 0.237489 loss)
I0526 11:12:00.337651 15394 sgd_solver.cpp:43] Iteration 43480, lr = 0.002
I0526 11:12:05.509138 15394 main.cpp:354] Iteration 43490, loss = 0.192397
I0526 11:12:05.509178 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.192396 (* 1 = 0.192396 loss)
I0526 11:12:05.509184 15394 sgd_solver.cpp:43] Iteration 43490, lr = 0.002
I0526 11:12:10.156255 15394 main.cpp:465] Iteration 43500, Testing net (#0)
I0526 11:12:23.243739 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8934
I0526 11:12:23.243778 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.338445 (* 1 = 0.338445 loss)
I0526 11:12:23.716418 15394 main.cpp:354] Iteration 43500, loss = 0.235618
I0526 11:12:23.716457 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235618 (* 1 = 0.235618 loss)
I0526 11:12:23.716465 15394 sgd_solver.cpp:43] Iteration 43500, lr = 0.002
I0526 11:12:29.249246 15394 main.cpp:354] Iteration 43510, loss = 0.115436
I0526 11:12:29.249287 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.115435 (* 1 = 0.115435 loss)
I0526 11:12:29.249295 15394 sgd_solver.cpp:43] Iteration 43510, lr = 0.002
I0526 11:12:33.974448 15394 main.cpp:354] Iteration 43520, loss = 0.221206
I0526 11:12:33.974493 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.221206 (* 1 = 0.221206 loss)
I0526 11:12:33.974501 15394 sgd_solver.cpp:43] Iteration 43520, lr = 0.002
I0526 11:12:39.339833 15394 main.cpp:354] Iteration 43530, loss = 0.234722
I0526 11:12:39.339872 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.234722 (* 1 = 0.234722 loss)
I0526 11:12:39.339879 15394 sgd_solver.cpp:43] Iteration 43530, lr = 0.002
I0526 11:12:44.137718 15394 main.cpp:354] Iteration 43540, loss = 0.258828
I0526 11:12:44.137759 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.258828 (* 1 = 0.258828 loss)
I0526 11:12:44.137765 15394 sgd_solver.cpp:43] Iteration 43540, lr = 0.002
I0526 11:12:48.568342 15394 main.cpp:354] Iteration 43550, loss = 0.263474
I0526 11:12:48.568384 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.263473 (* 1 = 0.263473 loss)
I0526 11:12:48.568392 15394 sgd_solver.cpp:43] Iteration 43550, lr = 0.002
I0526 11:12:53.104674 15394 main.cpp:354] Iteration 43560, loss = 0.267972
I0526 11:12:53.104712 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.267972 (* 1 = 0.267972 loss)
I0526 11:12:53.104717 15394 sgd_solver.cpp:43] Iteration 43560, lr = 0.002
I0526 11:12:58.196604 15394 main.cpp:354] Iteration 43570, loss = 0.44818
I0526 11:12:58.196642 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.448179 (* 1 = 0.448179 loss)
I0526 11:12:58.196648 15394 sgd_solver.cpp:43] Iteration 43570, lr = 0.002
I0526 11:13:03.850301 15394 main.cpp:354] Iteration 43580, loss = 0.222141
I0526 11:13:03.850343 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.222141 (* 1 = 0.222141 loss)
I0526 11:13:03.850350 15394 sgd_solver.cpp:43] Iteration 43580, lr = 0.002
I0526 11:13:08.904397 15394 main.cpp:354] Iteration 43590, loss = 0.252292
I0526 11:13:08.904435 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.252292 (* 1 = 0.252292 loss)
I0526 11:13:08.904443 15394 sgd_solver.cpp:43] Iteration 43590, lr = 0.002
I0526 11:13:13.154225 15394 main.cpp:465] Iteration 43600, Testing net (#0)
I0526 11:13:26.235932 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8913
I0526 11:13:26.235975 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.345839 (* 1 = 0.345839 loss)
I0526 11:13:26.714691 15394 main.cpp:354] Iteration 43600, loss = 0.251507
I0526 11:13:26.714730 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.251506 (* 1 = 0.251506 loss)
I0526 11:13:26.714737 15394 sgd_solver.cpp:43] Iteration 43600, lr = 0.002
I0526 11:13:31.903102 15394 main.cpp:354] Iteration 43610, loss = 0.146175
I0526 11:13:31.903146 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.146174 (* 1 = 0.146174 loss)
I0526 11:13:31.903153 15394 sgd_solver.cpp:43] Iteration 43610, lr = 0.002
I0526 11:13:36.841006 15394 main.cpp:354] Iteration 43620, loss = 0.129927
I0526 11:13:36.841045 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.129927 (* 1 = 0.129927 loss)
I0526 11:13:36.841051 15394 sgd_solver.cpp:43] Iteration 43620, lr = 0.002
I0526 11:13:41.983785 15394 main.cpp:354] Iteration 43630, loss = 0.18347
I0526 11:13:41.983825 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.18347 (* 1 = 0.18347 loss)
I0526 11:13:41.983832 15394 sgd_solver.cpp:43] Iteration 43630, lr = 0.002
I0526 11:13:47.288661 15394 main.cpp:354] Iteration 43640, loss = 0.29194
I0526 11:13:47.288703 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.291939 (* 1 = 0.291939 loss)
I0526 11:13:47.288710 15394 sgd_solver.cpp:43] Iteration 43640, lr = 0.002
I0526 11:13:52.391742 15394 main.cpp:354] Iteration 43650, loss = 0.226474
I0526 11:13:52.391782 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.226473 (* 1 = 0.226473 loss)
I0526 11:13:52.391789 15394 sgd_solver.cpp:43] Iteration 43650, lr = 0.002
I0526 11:13:57.494601 15394 main.cpp:354] Iteration 43660, loss = 0.336372
I0526 11:13:57.494640 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.336372 (* 1 = 0.336372 loss)
I0526 11:13:57.494647 15394 sgd_solver.cpp:43] Iteration 43660, lr = 0.002
I0526 11:14:02.479689 15394 main.cpp:354] Iteration 43670, loss = 0.240238
I0526 11:14:02.479734 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.240238 (* 1 = 0.240238 loss)
I0526 11:14:02.479740 15394 sgd_solver.cpp:43] Iteration 43670, lr = 0.002
I0526 11:14:07.418184 15394 main.cpp:354] Iteration 43680, loss = 0.104001
I0526 11:14:07.418222 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.104 (* 1 = 0.104 loss)
I0526 11:14:07.418229 15394 sgd_solver.cpp:43] Iteration 43680, lr = 0.002
I0526 11:14:12.361332 15394 main.cpp:354] Iteration 43690, loss = 0.229755
I0526 11:14:12.361371 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.229755 (* 1 = 0.229755 loss)
I0526 11:14:12.361378 15394 sgd_solver.cpp:43] Iteration 43690, lr = 0.002
I0526 11:14:16.847645 15394 main.cpp:465] Iteration 43700, Testing net (#0)
I0526 11:14:29.933310 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8935
I0526 11:14:29.933347 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.338881 (* 1 = 0.338881 loss)
I0526 11:14:30.436993 15394 main.cpp:354] Iteration 43700, loss = 0.152013
I0526 11:14:30.437033 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.152012 (* 1 = 0.152012 loss)
I0526 11:14:30.437041 15394 sgd_solver.cpp:43] Iteration 43700, lr = 0.002
I0526 11:14:35.349035 15394 main.cpp:354] Iteration 43710, loss = 0.189452
I0526 11:14:35.349074 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.189451 (* 1 = 0.189451 loss)
I0526 11:14:35.349081 15394 sgd_solver.cpp:43] Iteration 43710, lr = 0.002
I0526 11:14:39.881095 15394 main.cpp:354] Iteration 43720, loss = 0.204042
I0526 11:14:39.881140 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204041 (* 1 = 0.204041 loss)
I0526 11:14:39.881147 15394 sgd_solver.cpp:43] Iteration 43720, lr = 0.002
I0526 11:14:44.888371 15394 main.cpp:354] Iteration 43730, loss = 0.159275
I0526 11:14:44.888409 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.159274 (* 1 = 0.159274 loss)
I0526 11:14:44.888416 15394 sgd_solver.cpp:43] Iteration 43730, lr = 0.002
I0526 11:14:50.340065 15394 main.cpp:354] Iteration 43740, loss = 0.284219
I0526 11:14:50.340095 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.284218 (* 1 = 0.284218 loss)
I0526 11:14:50.340101 15394 sgd_solver.cpp:43] Iteration 43740, lr = 0.002
I0526 11:14:55.745128 15394 main.cpp:354] Iteration 43750, loss = 0.149944
I0526 11:14:55.745168 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.149944 (* 1 = 0.149944 loss)
I0526 11:14:55.745174 15394 sgd_solver.cpp:43] Iteration 43750, lr = 0.002
I0526 11:15:01.132530 15394 main.cpp:354] Iteration 43760, loss = 0.126017
I0526 11:15:01.132573 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.126017 (* 1 = 0.126017 loss)
I0526 11:15:01.132580 15394 sgd_solver.cpp:43] Iteration 43760, lr = 0.002
I0526 11:15:05.820415 15394 main.cpp:354] Iteration 43770, loss = 0.609279
I0526 11:15:05.820456 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.609278 (* 1 = 0.609278 loss)
I0526 11:15:05.820463 15394 sgd_solver.cpp:43] Iteration 43770, lr = 0.002
I0526 11:15:10.842325 15394 main.cpp:354] Iteration 43780, loss = 0.167922
I0526 11:15:10.842381 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.167921 (* 1 = 0.167921 loss)
I0526 11:15:10.842388 15394 sgd_solver.cpp:43] Iteration 43780, lr = 0.002
I0526 11:15:15.774083 15394 main.cpp:354] Iteration 43790, loss = 0.206859
I0526 11:15:15.774116 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206858 (* 1 = 0.206858 loss)
I0526 11:15:15.774122 15394 sgd_solver.cpp:43] Iteration 43790, lr = 0.002
I0526 11:15:20.632524 15394 main.cpp:465] Iteration 43800, Testing net (#0)
I0526 11:15:33.722584 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8928
I0526 11:15:33.722626 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.342983 (* 1 = 0.342983 loss)
I0526 11:15:34.297504 15394 main.cpp:354] Iteration 43800, loss = 0.1942
I0526 11:15:34.297545 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.1942 (* 1 = 0.1942 loss)
I0526 11:15:34.297552 15394 sgd_solver.cpp:43] Iteration 43800, lr = 0.002
I0526 11:15:39.826714 15394 main.cpp:354] Iteration 43810, loss = 0.1017
I0526 11:15:39.826753 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.101699 (* 1 = 0.101699 loss)
I0526 11:15:39.826761 15394 sgd_solver.cpp:43] Iteration 43810, lr = 0.002
I0526 11:15:45.242435 15394 main.cpp:354] Iteration 43820, loss = 0.330994
I0526 11:15:45.242477 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.330994 (* 1 = 0.330994 loss)
I0526 11:15:45.242486 15394 sgd_solver.cpp:43] Iteration 43820, lr = 0.002
I0526 11:15:50.185291 15394 main.cpp:354] Iteration 43830, loss = 0.163068
I0526 11:15:50.185331 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.163068 (* 1 = 0.163068 loss)
I0526 11:15:50.185338 15394 sgd_solver.cpp:43] Iteration 43830, lr = 0.002
I0526 11:15:55.267932 15394 main.cpp:354] Iteration 43840, loss = 0.222196
I0526 11:15:55.267971 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.222196 (* 1 = 0.222196 loss)
I0526 11:15:55.267976 15394 sgd_solver.cpp:43] Iteration 43840, lr = 0.002
I0526 11:16:00.083490 15394 main.cpp:354] Iteration 43850, loss = 0.0998354
I0526 11:16:00.083533 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.099835 (* 1 = 0.099835 loss)
I0526 11:16:00.083539 15394 sgd_solver.cpp:43] Iteration 43850, lr = 0.002
I0526 11:16:05.557164 15394 main.cpp:354] Iteration 43860, loss = 0.331486
I0526 11:16:05.557204 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.331486 (* 1 = 0.331486 loss)
I0526 11:16:05.557216 15394 sgd_solver.cpp:43] Iteration 43860, lr = 0.002
I0526 11:16:09.659770 15394 main.cpp:354] Iteration 43870, loss = 0.161233
I0526 11:16:09.659821 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.161232 (* 1 = 0.161232 loss)
I0526 11:16:09.659828 15394 sgd_solver.cpp:43] Iteration 43870, lr = 0.002
I0526 11:16:14.549659 15394 main.cpp:354] Iteration 43880, loss = 0.17505
I0526 11:16:14.549698 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.175049 (* 1 = 0.175049 loss)
I0526 11:16:14.549705 15394 sgd_solver.cpp:43] Iteration 43880, lr = 0.002
I0526 11:16:19.667527 15394 main.cpp:354] Iteration 43890, loss = 0.167003
I0526 11:16:19.667572 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.167003 (* 1 = 0.167003 loss)
I0526 11:16:19.667578 15394 sgd_solver.cpp:43] Iteration 43890, lr = 0.002
I0526 11:16:24.161423 15394 main.cpp:465] Iteration 43900, Testing net (#0)
I0526 11:16:37.247910 15394 main.cpp:532]     Test net output #0: Accuracy = 0.892
I0526 11:16:37.247954 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.344193 (* 1 = 0.344193 loss)
I0526 11:16:37.789024 15394 main.cpp:354] Iteration 43900, loss = 0.0866357
I0526 11:16:37.789052 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0866353 (* 1 = 0.0866353 loss)
I0526 11:16:37.789059 15394 sgd_solver.cpp:43] Iteration 43900, lr = 0.002
I0526 11:16:43.266007 15394 main.cpp:354] Iteration 43910, loss = 0.405338
I0526 11:16:43.266046 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.405338 (* 1 = 0.405338 loss)
I0526 11:16:43.266052 15394 sgd_solver.cpp:43] Iteration 43910, lr = 0.002
I0526 11:16:48.351389 15394 main.cpp:354] Iteration 43920, loss = 0.235334
I0526 11:16:48.351433 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235333 (* 1 = 0.235333 loss)
I0526 11:16:48.351438 15394 sgd_solver.cpp:43] Iteration 43920, lr = 0.002
I0526 11:16:53.147882 15394 main.cpp:354] Iteration 43930, loss = 0.306025
I0526 11:16:53.147922 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.306024 (* 1 = 0.306024 loss)
I0526 11:16:53.147927 15394 sgd_solver.cpp:43] Iteration 43930, lr = 0.002
I0526 11:16:57.891577 15394 main.cpp:354] Iteration 43940, loss = 0.46044
I0526 11:16:57.891618 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.460439 (* 1 = 0.460439 loss)
I0526 11:16:57.891625 15394 sgd_solver.cpp:43] Iteration 43940, lr = 0.002
I0526 11:17:02.629607 15394 main.cpp:354] Iteration 43950, loss = 0.275496
I0526 11:17:02.629652 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.275496 (* 1 = 0.275496 loss)
I0526 11:17:02.629658 15394 sgd_solver.cpp:43] Iteration 43950, lr = 0.002
I0526 11:17:07.969341 15394 main.cpp:354] Iteration 43960, loss = 0.209114
I0526 11:17:07.969380 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.209114 (* 1 = 0.209114 loss)
I0526 11:17:07.969386 15394 sgd_solver.cpp:43] Iteration 43960, lr = 0.002
I0526 11:17:12.886607 15394 main.cpp:354] Iteration 43970, loss = 0.2581
I0526 11:17:12.886646 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.258099 (* 1 = 0.258099 loss)
I0526 11:17:12.886653 15394 sgd_solver.cpp:43] Iteration 43970, lr = 0.002
I0526 11:17:17.723664 15394 main.cpp:354] Iteration 43980, loss = 0.198782
I0526 11:17:17.723707 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.198782 (* 1 = 0.198782 loss)
I0526 11:17:17.723714 15394 sgd_solver.cpp:43] Iteration 43980, lr = 0.002
I0526 11:17:23.050109 15394 main.cpp:354] Iteration 43990, loss = 0.213179
I0526 11:17:23.050149 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.213179 (* 1 = 0.213179 loss)
I0526 11:17:23.050156 15394 sgd_solver.cpp:43] Iteration 43990, lr = 0.002
I0526 11:17:27.993304 15394 main.cpp:465] Iteration 44000, Testing net (#0)
I0526 11:17:41.075547 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8901
I0526 11:17:41.075588 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.351885 (* 1 = 0.351885 loss)
I0526 11:17:41.437911 15394 main.cpp:354] Iteration 44000, loss = 0.517554
I0526 11:17:41.437950 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.517554 (* 1 = 0.517554 loss)
I0526 11:17:41.437958 15394 sgd_solver.cpp:43] Iteration 44000, lr = 0.002
I0526 11:17:46.167594 15394 main.cpp:354] Iteration 44010, loss = 0.293584
I0526 11:17:46.167639 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.293584 (* 1 = 0.293584 loss)
I0526 11:17:46.167645 15394 sgd_solver.cpp:43] Iteration 44010, lr = 0.002
I0526 11:17:51.120754 15394 main.cpp:354] Iteration 44020, loss = 0.357345
I0526 11:17:51.120792 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.357345 (* 1 = 0.357345 loss)
I0526 11:17:51.120798 15394 sgd_solver.cpp:43] Iteration 44020, lr = 0.002
I0526 11:17:56.496235 15394 main.cpp:354] Iteration 44030, loss = 0.189651
I0526 11:17:56.496273 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.189651 (* 1 = 0.189651 loss)
I0526 11:17:56.496280 15394 sgd_solver.cpp:43] Iteration 44030, lr = 0.002
I0526 11:18:01.495100 15394 main.cpp:354] Iteration 44040, loss = 0.151861
I0526 11:18:01.495144 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.151861 (* 1 = 0.151861 loss)
I0526 11:18:01.495151 15394 sgd_solver.cpp:43] Iteration 44040, lr = 0.002
I0526 11:18:06.439554 15394 main.cpp:354] Iteration 44050, loss = 0.147551
I0526 11:18:06.439587 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.147551 (* 1 = 0.147551 loss)
I0526 11:18:06.439594 15394 sgd_solver.cpp:43] Iteration 44050, lr = 0.002
I0526 11:18:11.561326 15394 main.cpp:354] Iteration 44060, loss = 0.30447
I0526 11:18:11.561365 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.304469 (* 1 = 0.304469 loss)
I0526 11:18:11.561372 15394 sgd_solver.cpp:43] Iteration 44060, lr = 0.002
I0526 11:18:16.958806 15394 main.cpp:354] Iteration 44070, loss = 0.262756
I0526 11:18:16.958848 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.262756 (* 1 = 0.262756 loss)
I0526 11:18:16.958855 15394 sgd_solver.cpp:43] Iteration 44070, lr = 0.002
I0526 11:18:21.775141 15394 main.cpp:354] Iteration 44080, loss = 0.209285
I0526 11:18:21.775179 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.209285 (* 1 = 0.209285 loss)
I0526 11:18:21.775187 15394 sgd_solver.cpp:43] Iteration 44080, lr = 0.002
I0526 11:18:27.073454 15394 main.cpp:354] Iteration 44090, loss = 0.140331
I0526 11:18:27.073493 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.14033 (* 1 = 0.14033 loss)
I0526 11:18:27.073500 15394 sgd_solver.cpp:43] Iteration 44090, lr = 0.002
I0526 11:18:31.735575 15394 main.cpp:465] Iteration 44100, Testing net (#0)
I0526 11:18:44.833745 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8939
I0526 11:18:44.833784 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.331241 (* 1 = 0.331241 loss)
I0526 11:18:45.341131 15394 main.cpp:354] Iteration 44100, loss = 0.212711
I0526 11:18:45.341174 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.212711 (* 1 = 0.212711 loss)
I0526 11:18:45.341183 15394 sgd_solver.cpp:43] Iteration 44100, lr = 0.002
I0526 11:18:50.225193 15394 main.cpp:354] Iteration 44110, loss = 0.445181
I0526 11:18:50.225229 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.44518 (* 1 = 0.44518 loss)
I0526 11:18:50.225236 15394 sgd_solver.cpp:43] Iteration 44110, lr = 0.002
I0526 11:18:55.315367 15394 main.cpp:354] Iteration 44120, loss = 0.238912
I0526 11:18:55.315407 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.238911 (* 1 = 0.238911 loss)
I0526 11:18:55.315414 15394 sgd_solver.cpp:43] Iteration 44120, lr = 0.002
I0526 11:19:00.487757 15394 main.cpp:354] Iteration 44130, loss = 0.133402
I0526 11:19:00.487798 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.133401 (* 1 = 0.133401 loss)
I0526 11:19:00.487807 15394 sgd_solver.cpp:43] Iteration 44130, lr = 0.002
I0526 11:19:05.285115 15394 main.cpp:354] Iteration 44140, loss = 0.195098
I0526 11:19:05.285161 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.195097 (* 1 = 0.195097 loss)
I0526 11:19:05.285166 15394 sgd_solver.cpp:43] Iteration 44140, lr = 0.002
I0526 11:19:10.414258 15394 main.cpp:354] Iteration 44150, loss = 0.214319
I0526 11:19:10.414296 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.214318 (* 1 = 0.214318 loss)
I0526 11:19:10.414302 15394 sgd_solver.cpp:43] Iteration 44150, lr = 0.002
I0526 11:19:15.860790 15394 main.cpp:354] Iteration 44160, loss = 0.115909
I0526 11:19:15.860828 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.115908 (* 1 = 0.115908 loss)
I0526 11:19:15.860833 15394 sgd_solver.cpp:43] Iteration 44160, lr = 0.002
I0526 11:19:20.799265 15394 main.cpp:354] Iteration 44170, loss = 0.654931
I0526 11:19:20.799306 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.654931 (* 1 = 0.654931 loss)
I0526 11:19:20.799312 15394 sgd_solver.cpp:43] Iteration 44170, lr = 0.002
I0526 11:19:25.315968 15394 main.cpp:354] Iteration 44180, loss = 0.367014
I0526 11:19:25.316005 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.367014 (* 1 = 0.367014 loss)
I0526 11:19:25.316011 15394 sgd_solver.cpp:43] Iteration 44180, lr = 0.002
I0526 11:19:30.325198 15394 main.cpp:354] Iteration 44190, loss = 0.351718
I0526 11:19:30.325237 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.351718 (* 1 = 0.351718 loss)
I0526 11:19:30.325243 15394 sgd_solver.cpp:43] Iteration 44190, lr = 0.002
I0526 11:19:34.922061 15394 main.cpp:465] Iteration 44200, Testing net (#0)
I0526 11:19:48.008435 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8897
I0526 11:19:48.008481 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.344892 (* 1 = 0.344892 loss)
I0526 11:19:48.515791 15394 main.cpp:354] Iteration 44200, loss = 0.188052
I0526 11:19:48.515830 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.188052 (* 1 = 0.188052 loss)
I0526 11:19:48.515839 15394 sgd_solver.cpp:43] Iteration 44200, lr = 0.002
I0526 11:19:53.901087 15394 main.cpp:354] Iteration 44210, loss = 0.285307
I0526 11:19:53.901132 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.285306 (* 1 = 0.285306 loss)
I0526 11:19:53.901139 15394 sgd_solver.cpp:43] Iteration 44210, lr = 0.002
I0526 11:19:59.054198 15394 main.cpp:354] Iteration 44220, loss = 0.179245
I0526 11:19:59.054239 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.179244 (* 1 = 0.179244 loss)
I0526 11:19:59.054246 15394 sgd_solver.cpp:43] Iteration 44220, lr = 0.002
I0526 11:20:04.221518 15394 main.cpp:354] Iteration 44230, loss = 0.247876
I0526 11:20:04.221562 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.247875 (* 1 = 0.247875 loss)
I0526 11:20:04.221570 15394 sgd_solver.cpp:43] Iteration 44230, lr = 0.002
I0526 11:20:09.527870 15394 main.cpp:354] Iteration 44240, loss = 0.212919
I0526 11:20:09.527910 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.212918 (* 1 = 0.212918 loss)
I0526 11:20:09.527917 15394 sgd_solver.cpp:43] Iteration 44240, lr = 0.002
I0526 11:20:14.846117 15394 main.cpp:354] Iteration 44250, loss = 0.17226
I0526 11:20:14.846156 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.172259 (* 1 = 0.172259 loss)
I0526 11:20:14.846163 15394 sgd_solver.cpp:43] Iteration 44250, lr = 0.002
I0526 11:20:19.935650 15394 main.cpp:354] Iteration 44260, loss = 0.173401
I0526 11:20:19.935693 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.173401 (* 1 = 0.173401 loss)
I0526 11:20:19.935699 15394 sgd_solver.cpp:43] Iteration 44260, lr = 0.002
I0526 11:20:24.938220 15394 main.cpp:354] Iteration 44270, loss = 0.33403
I0526 11:20:24.938253 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.33403 (* 1 = 0.33403 loss)
I0526 11:20:24.938258 15394 sgd_solver.cpp:43] Iteration 44270, lr = 0.002
I0526 11:20:29.860630 15394 main.cpp:354] Iteration 44280, loss = 0.151572
I0526 11:20:29.860668 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.151572 (* 1 = 0.151572 loss)
I0526 11:20:29.860680 15394 sgd_solver.cpp:43] Iteration 44280, lr = 0.002
I0526 11:20:35.060958 15394 main.cpp:354] Iteration 44290, loss = 0.262803
I0526 11:20:35.061005 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.262802 (* 1 = 0.262802 loss)
I0526 11:20:35.061012 15394 sgd_solver.cpp:43] Iteration 44290, lr = 0.002
I0526 11:20:39.644142 15394 main.cpp:465] Iteration 44300, Testing net (#0)
I0526 11:20:52.735513 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8906
I0526 11:20:52.735554 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.349145 (* 1 = 0.349145 loss)
I0526 11:20:53.346972 15394 main.cpp:354] Iteration 44300, loss = 0.174513
I0526 11:20:53.347014 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.174513 (* 1 = 0.174513 loss)
I0526 11:20:53.347023 15394 sgd_solver.cpp:43] Iteration 44300, lr = 0.002
I0526 11:20:58.591015 15394 main.cpp:354] Iteration 44310, loss = 0.320382
I0526 11:20:58.591054 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.320382 (* 1 = 0.320382 loss)
I0526 11:20:58.591061 15394 sgd_solver.cpp:43] Iteration 44310, lr = 0.002
I0526 11:21:03.705267 15394 main.cpp:354] Iteration 44320, loss = 0.217773
I0526 11:21:03.705312 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.217773 (* 1 = 0.217773 loss)
I0526 11:21:03.705317 15394 sgd_solver.cpp:43] Iteration 44320, lr = 0.002
I0526 11:21:08.929224 15394 main.cpp:354] Iteration 44330, loss = 0.283926
I0526 11:21:08.929257 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.283926 (* 1 = 0.283926 loss)
I0526 11:21:08.929265 15394 sgd_solver.cpp:43] Iteration 44330, lr = 0.002
I0526 11:21:13.970947 15394 main.cpp:354] Iteration 44340, loss = 0.201623
I0526 11:21:13.970988 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.201623 (* 1 = 0.201623 loss)
I0526 11:21:13.970993 15394 sgd_solver.cpp:43] Iteration 44340, lr = 0.002
I0526 11:21:19.143036 15394 main.cpp:354] Iteration 44350, loss = 0.353355
I0526 11:21:19.143092 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.353355 (* 1 = 0.353355 loss)
I0526 11:21:19.143100 15394 sgd_solver.cpp:43] Iteration 44350, lr = 0.002
I0526 11:21:24.283259 15394 main.cpp:354] Iteration 44360, loss = 0.216673
I0526 11:21:24.283298 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.216672 (* 1 = 0.216672 loss)
I0526 11:21:24.283305 15394 sgd_solver.cpp:43] Iteration 44360, lr = 0.002
I0526 11:21:29.900076 15394 main.cpp:354] Iteration 44370, loss = 0.117251
I0526 11:21:29.900115 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.117251 (* 1 = 0.117251 loss)
I0526 11:21:29.900121 15394 sgd_solver.cpp:43] Iteration 44370, lr = 0.002
I0526 11:21:35.055939 15394 main.cpp:354] Iteration 44380, loss = 0.344167
I0526 11:21:35.055981 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.344167 (* 1 = 0.344167 loss)
I0526 11:21:35.055987 15394 sgd_solver.cpp:43] Iteration 44380, lr = 0.002
I0526 11:21:39.845737 15394 main.cpp:354] Iteration 44390, loss = 0.304782
I0526 11:21:39.845778 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.304782 (* 1 = 0.304782 loss)
I0526 11:21:39.845784 15394 sgd_solver.cpp:43] Iteration 44390, lr = 0.002
I0526 11:21:43.908220 15394 main.cpp:465] Iteration 44400, Testing net (#0)
I0526 11:21:57.007086 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8858
I0526 11:21:57.007124 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.365042 (* 1 = 0.365042 loss)
I0526 11:21:57.510257 15394 main.cpp:354] Iteration 44400, loss = 0.263562
I0526 11:21:57.510308 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.263561 (* 1 = 0.263561 loss)
I0526 11:21:57.510316 15394 sgd_solver.cpp:43] Iteration 44400, lr = 0.002
I0526 11:22:01.764660 15394 main.cpp:354] Iteration 44410, loss = 0.196547
I0526 11:22:01.764703 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.196546 (* 1 = 0.196546 loss)
I0526 11:22:01.764717 15394 sgd_solver.cpp:43] Iteration 44410, lr = 0.002
I0526 11:22:06.914463 15394 main.cpp:354] Iteration 44420, loss = 0.169865
I0526 11:22:06.914507 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.169864 (* 1 = 0.169864 loss)
I0526 11:22:06.914513 15394 sgd_solver.cpp:43] Iteration 44420, lr = 0.002
I0526 11:22:11.878252 15394 main.cpp:354] Iteration 44430, loss = 0.272775
I0526 11:22:11.878286 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.272775 (* 1 = 0.272775 loss)
I0526 11:22:11.878293 15394 sgd_solver.cpp:43] Iteration 44430, lr = 0.002
I0526 11:22:17.266391 15394 main.cpp:354] Iteration 44440, loss = 0.153673
I0526 11:22:17.266438 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.153673 (* 1 = 0.153673 loss)
I0526 11:22:17.266445 15394 sgd_solver.cpp:43] Iteration 44440, lr = 0.002
I0526 11:22:22.025846 15394 main.cpp:354] Iteration 44450, loss = 0.231599
I0526 11:22:22.025885 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.231599 (* 1 = 0.231599 loss)
I0526 11:22:22.025892 15394 sgd_solver.cpp:43] Iteration 44450, lr = 0.002
I0526 11:22:27.344137 15394 main.cpp:354] Iteration 44460, loss = 0.350252
I0526 11:22:27.344179 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.350251 (* 1 = 0.350251 loss)
I0526 11:22:27.344187 15394 sgd_solver.cpp:43] Iteration 44460, lr = 0.002
I0526 11:22:32.297467 15394 main.cpp:354] Iteration 44470, loss = 0.110504
I0526 11:22:32.297509 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.110503 (* 1 = 0.110503 loss)
I0526 11:22:32.297516 15394 sgd_solver.cpp:43] Iteration 44470, lr = 0.002
I0526 11:22:37.196144 15394 main.cpp:354] Iteration 44480, loss = 0.204349
I0526 11:22:37.196184 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204348 (* 1 = 0.204348 loss)
I0526 11:22:37.196192 15394 sgd_solver.cpp:43] Iteration 44480, lr = 0.002
I0526 11:22:42.295449 15394 main.cpp:354] Iteration 44490, loss = 0.160489
I0526 11:22:42.295493 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.160488 (* 1 = 0.160488 loss)
I0526 11:22:42.295500 15394 sgd_solver.cpp:43] Iteration 44490, lr = 0.002
I0526 11:22:47.009150 15394 main.cpp:465] Iteration 44500, Testing net (#0)
I0526 11:23:00.092082 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8886
I0526 11:23:00.092128 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.352108 (* 1 = 0.352108 loss)
I0526 11:23:00.635188 15394 main.cpp:354] Iteration 44500, loss = 0.180988
I0526 11:23:00.635227 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.180987 (* 1 = 0.180987 loss)
I0526 11:23:00.635236 15394 sgd_solver.cpp:43] Iteration 44500, lr = 0.002
I0526 11:23:05.909198 15394 main.cpp:354] Iteration 44510, loss = 0.0929941
I0526 11:23:05.909236 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0929937 (* 1 = 0.0929937 loss)
I0526 11:23:05.909243 15394 sgd_solver.cpp:43] Iteration 44510, lr = 0.002
I0526 11:23:10.983779 15394 main.cpp:354] Iteration 44520, loss = 0.180798
I0526 11:23:10.983821 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.180798 (* 1 = 0.180798 loss)
I0526 11:23:10.983829 15394 sgd_solver.cpp:43] Iteration 44520, lr = 0.002
I0526 11:23:16.150193 15394 main.cpp:354] Iteration 44530, loss = 0.124751
I0526 11:23:16.150231 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.124751 (* 1 = 0.124751 loss)
I0526 11:23:16.150238 15394 sgd_solver.cpp:43] Iteration 44530, lr = 0.002
I0526 11:23:21.907248 15394 main.cpp:354] Iteration 44540, loss = 0.0982268
I0526 11:23:21.907285 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0982264 (* 1 = 0.0982264 loss)
I0526 11:23:21.907291 15394 sgd_solver.cpp:43] Iteration 44540, lr = 0.002
I0526 11:23:26.892901 15394 main.cpp:354] Iteration 44550, loss = 0.152218
I0526 11:23:26.892946 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.152218 (* 1 = 0.152218 loss)
I0526 11:23:26.892952 15394 sgd_solver.cpp:43] Iteration 44550, lr = 0.002
I0526 11:23:32.126643 15394 main.cpp:354] Iteration 44560, loss = 0.134986
I0526 11:23:32.126684 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.134985 (* 1 = 0.134985 loss)
I0526 11:23:32.126690 15394 sgd_solver.cpp:43] Iteration 44560, lr = 0.002
I0526 11:23:36.923777 15394 main.cpp:354] Iteration 44570, loss = 0.491992
I0526 11:23:36.923816 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.491992 (* 1 = 0.491992 loss)
I0526 11:23:36.923821 15394 sgd_solver.cpp:43] Iteration 44570, lr = 0.002
I0526 11:23:42.397514 15394 main.cpp:354] Iteration 44580, loss = 0.253223
I0526 11:23:42.397559 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.253223 (* 1 = 0.253223 loss)
I0526 11:23:42.397565 15394 sgd_solver.cpp:43] Iteration 44580, lr = 0.002
I0526 11:23:47.683385 15394 main.cpp:354] Iteration 44590, loss = 0.103441
I0526 11:23:47.683425 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.10344 (* 1 = 0.10344 loss)
I0526 11:23:47.683432 15394 sgd_solver.cpp:43] Iteration 44590, lr = 0.002
I0526 11:23:51.799938 15394 main.cpp:465] Iteration 44600, Testing net (#0)
I0526 11:24:04.886095 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8915
I0526 11:24:04.886135 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.351304 (* 1 = 0.351304 loss)
I0526 11:24:05.498008 15394 main.cpp:354] Iteration 44600, loss = 0.130666
I0526 11:24:05.498039 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.130665 (* 1 = 0.130665 loss)
I0526 11:24:05.498047 15394 sgd_solver.cpp:43] Iteration 44600, lr = 0.002
I0526 11:24:10.723690 15394 main.cpp:354] Iteration 44610, loss = 0.196474
I0526 11:24:10.723736 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.196474 (* 1 = 0.196474 loss)
I0526 11:24:10.723742 15394 sgd_solver.cpp:43] Iteration 44610, lr = 0.002
I0526 11:24:15.886514 15394 main.cpp:354] Iteration 44620, loss = 0.197523
I0526 11:24:15.886554 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.197523 (* 1 = 0.197523 loss)
I0526 11:24:15.886560 15394 sgd_solver.cpp:43] Iteration 44620, lr = 0.002
I0526 11:24:21.359566 15394 main.cpp:354] Iteration 44630, loss = 0.297676
I0526 11:24:21.359604 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.297675 (* 1 = 0.297675 loss)
I0526 11:24:21.359611 15394 sgd_solver.cpp:43] Iteration 44630, lr = 0.002
I0526 11:24:26.466580 15394 main.cpp:354] Iteration 44640, loss = 0.323176
I0526 11:24:26.466625 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.323175 (* 1 = 0.323175 loss)
I0526 11:24:26.466632 15394 sgd_solver.cpp:43] Iteration 44640, lr = 0.002
I0526 11:24:31.500201 15394 main.cpp:354] Iteration 44650, loss = 0.213636
I0526 11:24:31.500239 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.213636 (* 1 = 0.213636 loss)
I0526 11:24:31.500246 15394 sgd_solver.cpp:43] Iteration 44650, lr = 0.002
I0526 11:24:36.539952 15394 main.cpp:354] Iteration 44660, loss = 0.343104
I0526 11:24:36.539990 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.343103 (* 1 = 0.343103 loss)
I0526 11:24:36.539997 15394 sgd_solver.cpp:43] Iteration 44660, lr = 0.002
I0526 11:24:41.320806 15394 main.cpp:354] Iteration 44670, loss = 0.132718
I0526 11:24:41.320847 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.132717 (* 1 = 0.132717 loss)
I0526 11:24:41.320865 15394 sgd_solver.cpp:43] Iteration 44670, lr = 0.002
I0526 11:24:46.325230 15394 main.cpp:354] Iteration 44680, loss = 0.478707
I0526 11:24:46.325270 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.478707 (* 1 = 0.478707 loss)
I0526 11:24:46.325276 15394 sgd_solver.cpp:43] Iteration 44680, lr = 0.002
I0526 11:24:51.399520 15394 main.cpp:354] Iteration 44690, loss = 0.300949
I0526 11:24:51.399560 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.300949 (* 1 = 0.300949 loss)
I0526 11:24:51.399567 15394 sgd_solver.cpp:43] Iteration 44690, lr = 0.002
I0526 11:24:56.074797 15394 main.cpp:465] Iteration 44700, Testing net (#0)
I0526 11:25:09.155475 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8902
I0526 11:25:09.155519 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.353969 (* 1 = 0.353969 loss)
I0526 11:25:09.664454 15394 main.cpp:354] Iteration 44700, loss = 0.193239
I0526 11:25:09.664499 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.193239 (* 1 = 0.193239 loss)
I0526 11:25:09.664507 15394 sgd_solver.cpp:43] Iteration 44700, lr = 0.002
I0526 11:25:15.076272 15394 main.cpp:354] Iteration 44710, loss = 0.200251
I0526 11:25:15.076303 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.20025 (* 1 = 0.20025 loss)
I0526 11:25:15.076310 15394 sgd_solver.cpp:43] Iteration 44710, lr = 0.002
I0526 11:25:20.567282 15394 main.cpp:354] Iteration 44720, loss = 0.241263
I0526 11:25:20.567325 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.241262 (* 1 = 0.241262 loss)
I0526 11:25:20.567332 15394 sgd_solver.cpp:43] Iteration 44720, lr = 0.002
I0526 11:25:26.082185 15394 main.cpp:354] Iteration 44730, loss = 0.185496
I0526 11:25:26.082226 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.185495 (* 1 = 0.185495 loss)
I0526 11:25:26.082232 15394 sgd_solver.cpp:43] Iteration 44730, lr = 0.002
I0526 11:25:30.946825 15394 main.cpp:354] Iteration 44740, loss = 0.18056
I0526 11:25:30.946863 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.18056 (* 1 = 0.18056 loss)
I0526 11:25:30.946869 15394 sgd_solver.cpp:43] Iteration 44740, lr = 0.002
I0526 11:25:35.853396 15394 main.cpp:354] Iteration 44750, loss = 0.083399
I0526 11:25:35.853435 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0833987 (* 1 = 0.0833987 loss)
I0526 11:25:35.853441 15394 sgd_solver.cpp:43] Iteration 44750, lr = 0.002
I0526 11:25:40.626330 15394 main.cpp:354] Iteration 44760, loss = 0.643064
I0526 11:25:40.626391 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.643064 (* 1 = 0.643064 loss)
I0526 11:25:40.626399 15394 sgd_solver.cpp:43] Iteration 44760, lr = 0.002
I0526 11:25:45.706015 15394 main.cpp:354] Iteration 44770, loss = 0.146218
I0526 11:25:45.706055 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.146217 (* 1 = 0.146217 loss)
I0526 11:25:45.706061 15394 sgd_solver.cpp:43] Iteration 44770, lr = 0.002
I0526 11:25:50.867097 15394 main.cpp:354] Iteration 44780, loss = 0.29288
I0526 11:25:50.867136 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.29288 (* 1 = 0.29288 loss)
I0526 11:25:50.867143 15394 sgd_solver.cpp:43] Iteration 44780, lr = 0.002
I0526 11:25:56.010582 15394 main.cpp:354] Iteration 44790, loss = 0.219603
I0526 11:25:56.010627 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.219603 (* 1 = 0.219603 loss)
I0526 11:25:56.010634 15394 sgd_solver.cpp:43] Iteration 44790, lr = 0.002
I0526 11:26:00.363732 15394 main.cpp:465] Iteration 44800, Testing net (#0)
I0526 11:26:13.450525 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8914
I0526 11:26:13.450567 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.348976 (* 1 = 0.348976 loss)
I0526 11:26:13.992507 15394 main.cpp:354] Iteration 44800, loss = 0.295988
I0526 11:26:13.992547 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.295988 (* 1 = 0.295988 loss)
I0526 11:26:13.992554 15394 sgd_solver.cpp:43] Iteration 44800, lr = 0.002
I0526 11:26:19.312841 15394 main.cpp:354] Iteration 44810, loss = 0.172032
I0526 11:26:19.312881 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.172032 (* 1 = 0.172032 loss)
I0526 11:26:19.312890 15394 sgd_solver.cpp:43] Iteration 44810, lr = 0.002
I0526 11:26:24.644636 15394 main.cpp:354] Iteration 44820, loss = 0.734295
I0526 11:26:24.644692 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.734295 (* 1 = 0.734295 loss)
I0526 11:26:24.644700 15394 sgd_solver.cpp:43] Iteration 44820, lr = 0.002
I0526 11:26:29.694912 15394 main.cpp:354] Iteration 44830, loss = 0.187732
I0526 11:26:29.694953 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187731 (* 1 = 0.187731 loss)
I0526 11:26:29.694965 15394 sgd_solver.cpp:43] Iteration 44830, lr = 0.002
I0526 11:26:34.757444 15394 main.cpp:354] Iteration 44840, loss = 0.235362
I0526 11:26:34.757496 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235361 (* 1 = 0.235361 loss)
I0526 11:26:34.757503 15394 sgd_solver.cpp:43] Iteration 44840, lr = 0.002
I0526 11:26:39.730840 15394 main.cpp:354] Iteration 44850, loss = 0.175923
I0526 11:26:39.730883 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.175922 (* 1 = 0.175922 loss)
I0526 11:26:39.730890 15394 sgd_solver.cpp:43] Iteration 44850, lr = 0.002
I0526 11:26:45.063694 15394 main.cpp:354] Iteration 44860, loss = 0.200925
I0526 11:26:45.063733 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.200924 (* 1 = 0.200924 loss)
I0526 11:26:45.063740 15394 sgd_solver.cpp:43] Iteration 44860, lr = 0.002
I0526 11:26:50.074307 15394 main.cpp:354] Iteration 44870, loss = 0.267484
I0526 11:26:50.074345 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.267484 (* 1 = 0.267484 loss)
I0526 11:26:50.074352 15394 sgd_solver.cpp:43] Iteration 44870, lr = 0.002
I0526 11:26:55.014720 15394 main.cpp:354] Iteration 44880, loss = 0.222115
I0526 11:26:55.014775 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.222115 (* 1 = 0.222115 loss)
I0526 11:26:55.014782 15394 sgd_solver.cpp:43] Iteration 44880, lr = 0.002
I0526 11:27:00.349828 15394 main.cpp:354] Iteration 44890, loss = 0.218172
I0526 11:27:00.349866 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.218172 (* 1 = 0.218172 loss)
I0526 11:27:00.349872 15394 sgd_solver.cpp:43] Iteration 44890, lr = 0.002
I0526 11:27:05.313851 15394 main.cpp:465] Iteration 44900, Testing net (#0)
I0526 11:27:18.401361 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8924
I0526 11:27:18.401402 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.346222 (* 1 = 0.346222 loss)
I0526 11:27:18.873391 15394 main.cpp:354] Iteration 44900, loss = 0.139925
I0526 11:27:18.873423 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.139925 (* 1 = 0.139925 loss)
I0526 11:27:18.873430 15394 sgd_solver.cpp:43] Iteration 44900, lr = 0.002
I0526 11:27:23.526068 15394 main.cpp:354] Iteration 44910, loss = 0.469277
I0526 11:27:23.526110 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.469276 (* 1 = 0.469276 loss)
I0526 11:27:23.526118 15394 sgd_solver.cpp:43] Iteration 44910, lr = 0.002
I0526 11:27:28.538307 15394 main.cpp:354] Iteration 44920, loss = 0.161903
I0526 11:27:28.538347 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.161902 (* 1 = 0.161902 loss)
I0526 11:27:28.538358 15394 sgd_solver.cpp:43] Iteration 44920, lr = 0.002
I0526 11:27:34.063910 15394 main.cpp:354] Iteration 44930, loss = 0.0987902
I0526 11:27:34.063951 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.09879 (* 1 = 0.09879 loss)
I0526 11:27:34.063958 15394 sgd_solver.cpp:43] Iteration 44930, lr = 0.002
I0526 11:27:39.298054 15394 main.cpp:354] Iteration 44940, loss = 0.111773
I0526 11:27:39.298099 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.111773 (* 1 = 0.111773 loss)
I0526 11:27:39.298105 15394 sgd_solver.cpp:43] Iteration 44940, lr = 0.002
I0526 11:27:44.444706 15394 main.cpp:354] Iteration 44950, loss = 0.508919
I0526 11:27:44.444747 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.508919 (* 1 = 0.508919 loss)
I0526 11:27:44.444753 15394 sgd_solver.cpp:43] Iteration 44950, lr = 0.002
I0526 11:27:49.396224 15394 main.cpp:354] Iteration 44960, loss = 0.274085
I0526 11:27:49.396262 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.274085 (* 1 = 0.274085 loss)
I0526 11:27:49.396268 15394 sgd_solver.cpp:43] Iteration 44960, lr = 0.002
I0526 11:27:54.372200 15394 main.cpp:354] Iteration 44970, loss = 0.136213
I0526 11:27:54.372246 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.136213 (* 1 = 0.136213 loss)
I0526 11:27:54.372252 15394 sgd_solver.cpp:43] Iteration 44970, lr = 0.002
I0526 11:27:59.394374 15394 main.cpp:354] Iteration 44980, loss = 0.154372
I0526 11:27:59.394412 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.154371 (* 1 = 0.154371 loss)
I0526 11:27:59.394418 15394 sgd_solver.cpp:43] Iteration 44980, lr = 0.002
I0526 11:28:04.746775 15394 main.cpp:354] Iteration 44990, loss = 0.159456
I0526 11:28:04.746812 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.159455 (* 1 = 0.159455 loss)
I0526 11:28:04.746819 15394 sgd_solver.cpp:43] Iteration 44990, lr = 0.002
I0526 11:28:09.404202 15394 main.cpp:465] Iteration 45000, Testing net (#0)
I0526 11:28:22.492512 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8907
I0526 11:28:22.492549 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.342814 (* 1 = 0.342814 loss)
I0526 11:28:22.961002 15394 main.cpp:354] Iteration 45000, loss = 0.23068
I0526 11:28:22.961045 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.23068 (* 1 = 0.23068 loss)
I0526 11:28:22.961052 15394 sgd_solver.cpp:43] Iteration 45000, lr = 0.002
I0526 11:28:27.995424 15394 main.cpp:354] Iteration 45010, loss = 0.108131
I0526 11:28:27.995470 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.108131 (* 1 = 0.108131 loss)
I0526 11:28:27.995476 15394 sgd_solver.cpp:43] Iteration 45010, lr = 0.002
I0526 11:28:32.849227 15394 main.cpp:354] Iteration 45020, loss = 0.410693
I0526 11:28:32.849266 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.410693 (* 1 = 0.410693 loss)
I0526 11:28:32.849270 15394 sgd_solver.cpp:43] Iteration 45020, lr = 0.002
I0526 11:28:37.541441 15394 main.cpp:354] Iteration 45030, loss = 0.29114
I0526 11:28:37.541481 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.291139 (* 1 = 0.291139 loss)
I0526 11:28:37.541487 15394 sgd_solver.cpp:43] Iteration 45030, lr = 0.002
I0526 11:28:42.799906 15394 main.cpp:354] Iteration 45040, loss = 0.288704
I0526 11:28:42.799934 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.288704 (* 1 = 0.288704 loss)
I0526 11:28:42.799942 15394 sgd_solver.cpp:43] Iteration 45040, lr = 0.002
I0526 11:28:47.544459 15394 main.cpp:354] Iteration 45050, loss = 0.294547
I0526 11:28:47.544499 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.294547 (* 1 = 0.294547 loss)
I0526 11:28:47.544505 15394 sgd_solver.cpp:43] Iteration 45050, lr = 0.002
I0526 11:28:52.740020 15394 main.cpp:354] Iteration 45060, loss = 0.324402
I0526 11:28:52.740062 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.324401 (* 1 = 0.324401 loss)
I0526 11:28:52.740069 15394 sgd_solver.cpp:43] Iteration 45060, lr = 0.002
I0526 11:28:58.029184 15394 main.cpp:354] Iteration 45070, loss = 0.33003
I0526 11:28:58.029229 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.33003 (* 1 = 0.33003 loss)
I0526 11:28:58.029237 15394 sgd_solver.cpp:43] Iteration 45070, lr = 0.002
I0526 11:29:02.631803 15394 main.cpp:354] Iteration 45080, loss = 0.280494
I0526 11:29:02.631845 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.280493 (* 1 = 0.280493 loss)
I0526 11:29:02.631852 15394 sgd_solver.cpp:43] Iteration 45080, lr = 0.002
I0526 11:29:07.304731 15394 main.cpp:354] Iteration 45090, loss = 0.194886
I0526 11:29:07.304771 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.194886 (* 1 = 0.194886 loss)
I0526 11:29:07.304777 15394 sgd_solver.cpp:43] Iteration 45090, lr = 0.002
I0526 11:29:12.024477 15394 main.cpp:465] Iteration 45100, Testing net (#0)
I0526 11:29:25.105661 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8948
I0526 11:29:25.105701 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.33164 (* 1 = 0.33164 loss)
I0526 11:29:25.469614 15394 main.cpp:354] Iteration 45100, loss = 0.366798
I0526 11:29:25.469653 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.366798 (* 1 = 0.366798 loss)
I0526 11:29:25.469661 15394 sgd_solver.cpp:43] Iteration 45100, lr = 0.002
I0526 11:29:30.613668 15394 main.cpp:354] Iteration 45110, loss = 0.268846
I0526 11:29:30.613713 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.268846 (* 1 = 0.268846 loss)
I0526 11:29:30.613719 15394 sgd_solver.cpp:43] Iteration 45110, lr = 0.002
I0526 11:29:36.016149 15394 main.cpp:354] Iteration 45120, loss = 0.148467
I0526 11:29:36.016198 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.148467 (* 1 = 0.148467 loss)
I0526 11:29:36.016206 15394 sgd_solver.cpp:43] Iteration 45120, lr = 0.002
I0526 11:29:40.865998 15394 main.cpp:354] Iteration 45130, loss = 0.260836
I0526 11:29:40.866045 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.260836 (* 1 = 0.260836 loss)
I0526 11:29:40.866052 15394 sgd_solver.cpp:43] Iteration 45130, lr = 0.002
I0526 11:29:45.969259 15394 main.cpp:354] Iteration 45140, loss = 0.167299
I0526 11:29:45.969290 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.167299 (* 1 = 0.167299 loss)
I0526 11:29:45.969297 15394 sgd_solver.cpp:43] Iteration 45140, lr = 0.002
I0526 11:29:50.890707 15394 main.cpp:354] Iteration 45150, loss = 0.190268
I0526 11:29:50.890746 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.190268 (* 1 = 0.190268 loss)
I0526 11:29:50.890753 15394 sgd_solver.cpp:43] Iteration 45150, lr = 0.002
I0526 11:29:55.989874 15394 main.cpp:354] Iteration 45160, loss = 0.174677
I0526 11:29:55.989918 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.174677 (* 1 = 0.174677 loss)
I0526 11:29:55.989924 15394 sgd_solver.cpp:43] Iteration 45160, lr = 0.002
I0526 11:30:00.933733 15394 main.cpp:354] Iteration 45170, loss = 0.149138
I0526 11:30:00.933774 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.149138 (* 1 = 0.149138 loss)
I0526 11:30:00.933780 15394 sgd_solver.cpp:43] Iteration 45170, lr = 0.002
I0526 11:30:05.822526 15394 main.cpp:354] Iteration 45180, loss = 0.204378
I0526 11:30:05.822568 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204378 (* 1 = 0.204378 loss)
I0526 11:30:05.822576 15394 sgd_solver.cpp:43] Iteration 45180, lr = 0.002
I0526 11:30:11.261458 15394 main.cpp:354] Iteration 45190, loss = 0.233092
I0526 11:30:11.261502 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.233092 (* 1 = 0.233092 loss)
I0526 11:30:11.261509 15394 sgd_solver.cpp:43] Iteration 45190, lr = 0.002
I0526 11:30:16.096005 15394 main.cpp:465] Iteration 45200, Testing net (#0)
I0526 11:30:29.179708 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8903
I0526 11:30:29.179749 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.363005 (* 1 = 0.363005 loss)
I0526 11:30:29.688231 15394 main.cpp:354] Iteration 45200, loss = 0.205166
I0526 11:30:29.688273 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.205166 (* 1 = 0.205166 loss)
I0526 11:30:29.688282 15394 sgd_solver.cpp:43] Iteration 45200, lr = 0.002
I0526 11:30:34.965399 15394 main.cpp:354] Iteration 45210, loss = 0.146424
I0526 11:30:34.965437 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.146423 (* 1 = 0.146423 loss)
I0526 11:30:34.965443 15394 sgd_solver.cpp:43] Iteration 45210, lr = 0.002
I0526 11:30:40.087111 15394 main.cpp:354] Iteration 45220, loss = 0.208743
I0526 11:30:40.087154 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.208742 (* 1 = 0.208742 loss)
I0526 11:30:40.087162 15394 sgd_solver.cpp:43] Iteration 45220, lr = 0.002
I0526 11:30:45.044951 15394 main.cpp:354] Iteration 45230, loss = 0.118177
I0526 11:30:45.044991 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.118176 (* 1 = 0.118176 loss)
I0526 11:30:45.044997 15394 sgd_solver.cpp:43] Iteration 45230, lr = 0.002
I0526 11:30:49.896862 15394 main.cpp:354] Iteration 45240, loss = 0.173133
I0526 11:30:49.896901 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.173133 (* 1 = 0.173133 loss)
I0526 11:30:49.896908 15394 sgd_solver.cpp:43] Iteration 45240, lr = 0.002
I0526 11:30:54.927222 15394 main.cpp:354] Iteration 45250, loss = 0.323711
I0526 11:30:54.927264 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.323711 (* 1 = 0.323711 loss)
I0526 11:30:54.927278 15394 sgd_solver.cpp:43] Iteration 45250, lr = 0.002
I0526 11:30:59.761505 15394 main.cpp:354] Iteration 45260, loss = 0.729723
I0526 11:30:59.761544 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.729723 (* 1 = 0.729723 loss)
I0526 11:30:59.761551 15394 sgd_solver.cpp:43] Iteration 45260, lr = 0.002
I0526 11:31:04.259661 15394 main.cpp:354] Iteration 45270, loss = 0.141016
I0526 11:31:04.259701 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.141016 (* 1 = 0.141016 loss)
I0526 11:31:04.259707 15394 sgd_solver.cpp:43] Iteration 45270, lr = 0.002
I0526 11:31:09.426504 15394 main.cpp:354] Iteration 45280, loss = 0.235278
I0526 11:31:09.426547 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235278 (* 1 = 0.235278 loss)
I0526 11:31:09.426553 15394 sgd_solver.cpp:43] Iteration 45280, lr = 0.002
I0526 11:31:14.580663 15394 main.cpp:354] Iteration 45290, loss = 0.100741
I0526 11:31:14.580692 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.100741 (* 1 = 0.100741 loss)
I0526 11:31:14.580698 15394 sgd_solver.cpp:43] Iteration 45290, lr = 0.002
I0526 11:31:19.168043 15394 main.cpp:465] Iteration 45300, Testing net (#0)
I0526 11:31:32.251277 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8947
I0526 11:31:32.251319 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.340536 (* 1 = 0.340536 loss)
I0526 11:31:32.755379 15394 main.cpp:354] Iteration 45300, loss = 0.157177
I0526 11:31:32.755411 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.157177 (* 1 = 0.157177 loss)
I0526 11:31:32.755419 15394 sgd_solver.cpp:43] Iteration 45300, lr = 0.002
I0526 11:31:37.992677 15394 main.cpp:354] Iteration 45310, loss = 0.176373
I0526 11:31:37.992717 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.176372 (* 1 = 0.176372 loss)
I0526 11:31:37.992723 15394 sgd_solver.cpp:43] Iteration 45310, lr = 0.002
I0526 11:31:43.612191 15394 main.cpp:354] Iteration 45320, loss = 0.110825
I0526 11:31:43.612234 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.110825 (* 1 = 0.110825 loss)
I0526 11:31:43.612241 15394 sgd_solver.cpp:43] Iteration 45320, lr = 0.002
I0526 11:31:49.090417 15394 main.cpp:354] Iteration 45330, loss = 0.358827
I0526 11:31:49.090473 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.358827 (* 1 = 0.358827 loss)
I0526 11:31:49.090479 15394 sgd_solver.cpp:43] Iteration 45330, lr = 0.002
I0526 11:31:54.178675 15394 main.cpp:354] Iteration 45340, loss = 0.353133
I0526 11:31:54.178740 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.353133 (* 1 = 0.353133 loss)
I0526 11:31:54.178747 15394 sgd_solver.cpp:43] Iteration 45340, lr = 0.002
I0526 11:31:59.140705 15394 main.cpp:354] Iteration 45350, loss = 0.178413
I0526 11:31:59.140743 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.178413 (* 1 = 0.178413 loss)
I0526 11:31:59.140749 15394 sgd_solver.cpp:43] Iteration 45350, lr = 0.002
I0526 11:32:04.468358 15394 main.cpp:354] Iteration 45360, loss = 0.248204
I0526 11:32:04.468403 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.248204 (* 1 = 0.248204 loss)
I0526 11:32:04.468410 15394 sgd_solver.cpp:43] Iteration 45360, lr = 0.002
I0526 11:32:08.948801 15394 main.cpp:354] Iteration 45370, loss = 0.407256
I0526 11:32:08.948843 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.407256 (* 1 = 0.407256 loss)
I0526 11:32:08.948848 15394 sgd_solver.cpp:43] Iteration 45370, lr = 0.002
I0526 11:32:13.658946 15394 main.cpp:354] Iteration 45380, loss = 0.228308
I0526 11:32:13.658985 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.228308 (* 1 = 0.228308 loss)
I0526 11:32:13.658992 15394 sgd_solver.cpp:43] Iteration 45380, lr = 0.002
I0526 11:32:19.199767 15394 main.cpp:354] Iteration 45390, loss = 0.182991
I0526 11:32:19.199811 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.182991 (* 1 = 0.182991 loss)
I0526 11:32:19.199820 15394 sgd_solver.cpp:43] Iteration 45390, lr = 0.002
I0526 11:32:24.227599 15394 main.cpp:465] Iteration 45400, Testing net (#0)
I0526 11:32:37.313328 15394 main.cpp:532]     Test net output #0: Accuracy = 0.889
I0526 11:32:37.313369 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.353504 (* 1 = 0.353504 loss)
I0526 11:32:37.713547 15394 main.cpp:354] Iteration 45400, loss = 0.18078
I0526 11:32:37.713590 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.180779 (* 1 = 0.180779 loss)
I0526 11:32:37.713599 15394 sgd_solver.cpp:43] Iteration 45400, lr = 0.002
I0526 11:32:42.861774 15394 main.cpp:354] Iteration 45410, loss = 0.248602
I0526 11:32:42.861814 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.248601 (* 1 = 0.248601 loss)
I0526 11:32:42.861821 15394 sgd_solver.cpp:43] Iteration 45410, lr = 0.002
I0526 11:32:47.678606 15394 main.cpp:354] Iteration 45420, loss = 0.602589
I0526 11:32:47.678652 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.602589 (* 1 = 0.602589 loss)
I0526 11:32:47.678659 15394 sgd_solver.cpp:43] Iteration 45420, lr = 0.002
I0526 11:32:52.757028 15394 main.cpp:354] Iteration 45430, loss = 0.132273
I0526 11:32:52.757068 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.132272 (* 1 = 0.132272 loss)
I0526 11:32:52.757074 15394 sgd_solver.cpp:43] Iteration 45430, lr = 0.002
I0526 11:32:57.830981 15394 main.cpp:354] Iteration 45440, loss = 0.379438
I0526 11:32:57.831019 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.379437 (* 1 = 0.379437 loss)
I0526 11:32:57.831027 15394 sgd_solver.cpp:43] Iteration 45440, lr = 0.002
I0526 11:33:03.094465 15394 main.cpp:354] Iteration 45450, loss = 0.235803
I0526 11:33:03.094509 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235802 (* 1 = 0.235802 loss)
I0526 11:33:03.094516 15394 sgd_solver.cpp:43] Iteration 45450, lr = 0.002
I0526 11:33:08.395856 15394 main.cpp:354] Iteration 45460, loss = 0.187508
I0526 11:33:08.395915 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187507 (* 1 = 0.187507 loss)
I0526 11:33:08.395927 15394 sgd_solver.cpp:43] Iteration 45460, lr = 0.002
I0526 11:33:13.421000 15394 main.cpp:354] Iteration 45470, loss = 0.186353
I0526 11:33:13.421042 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186353 (* 1 = 0.186353 loss)
I0526 11:33:13.421049 15394 sgd_solver.cpp:43] Iteration 45470, lr = 0.002
I0526 11:33:18.419657 15394 main.cpp:354] Iteration 45480, loss = 0.31293
I0526 11:33:18.419699 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.31293 (* 1 = 0.31293 loss)
I0526 11:33:18.419706 15394 sgd_solver.cpp:43] Iteration 45480, lr = 0.002
I0526 11:33:23.730226 15394 main.cpp:354] Iteration 45490, loss = 0.237524
I0526 11:33:23.730265 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.237524 (* 1 = 0.237524 loss)
I0526 11:33:23.730271 15394 sgd_solver.cpp:43] Iteration 45490, lr = 0.002
I0526 11:33:28.620714 15394 main.cpp:465] Iteration 45500, Testing net (#0)
I0526 11:33:41.708570 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8942
I0526 11:33:41.708611 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.341534 (* 1 = 0.341534 loss)
I0526 11:33:42.252900 15394 main.cpp:354] Iteration 45500, loss = 0.1189
I0526 11:33:42.252946 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.1189 (* 1 = 0.1189 loss)
I0526 11:33:42.252954 15394 sgd_solver.cpp:43] Iteration 45500, lr = 0.002
I0526 11:33:47.398735 15394 main.cpp:354] Iteration 45510, loss = 0.154247
I0526 11:33:47.398777 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.154247 (* 1 = 0.154247 loss)
I0526 11:33:47.398783 15394 sgd_solver.cpp:43] Iteration 45510, lr = 0.002
I0526 11:33:52.379235 15394 main.cpp:354] Iteration 45520, loss = 0.22996
I0526 11:33:52.379276 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.229959 (* 1 = 0.229959 loss)
I0526 11:33:52.379282 15394 sgd_solver.cpp:43] Iteration 45520, lr = 0.002
I0526 11:33:57.734022 15394 main.cpp:354] Iteration 45530, loss = 0.326728
I0526 11:33:57.734068 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.326727 (* 1 = 0.326727 loss)
I0526 11:33:57.734076 15394 sgd_solver.cpp:43] Iteration 45530, lr = 0.002
I0526 11:34:02.583752 15394 main.cpp:354] Iteration 45540, loss = 0.326605
I0526 11:34:02.583796 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.326605 (* 1 = 0.326605 loss)
I0526 11:34:02.583801 15394 sgd_solver.cpp:43] Iteration 45540, lr = 0.002
I0526 11:34:07.565731 15394 main.cpp:354] Iteration 45550, loss = 0.236505
I0526 11:34:07.565769 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.236505 (* 1 = 0.236505 loss)
I0526 11:34:07.565788 15394 sgd_solver.cpp:43] Iteration 45550, lr = 0.002
I0526 11:34:12.847187 15394 main.cpp:354] Iteration 45560, loss = 0.130146
I0526 11:34:12.847226 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.130146 (* 1 = 0.130146 loss)
I0526 11:34:12.847232 15394 sgd_solver.cpp:43] Iteration 45560, lr = 0.002
I0526 11:34:17.863901 15394 main.cpp:354] Iteration 45570, loss = 0.61589
I0526 11:34:17.863943 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.615889 (* 1 = 0.615889 loss)
I0526 11:34:17.863950 15394 sgd_solver.cpp:43] Iteration 45570, lr = 0.002
I0526 11:34:23.130931 15394 main.cpp:354] Iteration 45580, loss = 0.241547
I0526 11:34:23.130969 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.241547 (* 1 = 0.241547 loss)
I0526 11:34:23.130975 15394 sgd_solver.cpp:43] Iteration 45580, lr = 0.002
I0526 11:34:27.984833 15394 main.cpp:354] Iteration 45590, loss = 0.302174
I0526 11:34:27.984876 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.302174 (* 1 = 0.302174 loss)
I0526 11:34:27.984884 15394 sgd_solver.cpp:43] Iteration 45590, lr = 0.002
I0526 11:34:32.254979 15394 main.cpp:465] Iteration 45600, Testing net (#0)
I0526 11:34:45.518834 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8834
I0526 11:34:45.518878 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.377409 (* 1 = 0.377409 loss)
I0526 11:34:45.985947 15394 main.cpp:354] Iteration 45600, loss = 0.230454
I0526 11:34:45.985990 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.230453 (* 1 = 0.230453 loss)
I0526 11:34:45.985996 15394 sgd_solver.cpp:43] Iteration 45600, lr = 0.002
I0526 11:34:51.320248 15394 main.cpp:354] Iteration 45610, loss = 0.211581
I0526 11:34:51.320289 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.211581 (* 1 = 0.211581 loss)
I0526 11:34:51.320297 15394 sgd_solver.cpp:43] Iteration 45610, lr = 0.002
I0526 11:34:56.785312 15394 main.cpp:354] Iteration 45620, loss = 0.42766
I0526 11:34:56.785356 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.427659 (* 1 = 0.427659 loss)
I0526 11:34:56.785365 15394 sgd_solver.cpp:43] Iteration 45620, lr = 0.002
I0526 11:35:02.480629 15394 main.cpp:354] Iteration 45630, loss = 0.0911492
I0526 11:35:02.480672 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0911489 (* 1 = 0.0911489 loss)
I0526 11:35:02.480679 15394 sgd_solver.cpp:43] Iteration 45630, lr = 0.002
I0526 11:35:15.738466 15394 main.cpp:354] Iteration 45640, loss = 0.259166
I0526 11:35:15.738507 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.259166 (* 1 = 0.259166 loss)
I0526 11:35:15.738513 15394 sgd_solver.cpp:43] Iteration 45640, lr = 0.002
I0526 11:35:27.069604 15394 main.cpp:354] Iteration 45650, loss = 0.235603
I0526 11:35:27.069636 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235602 (* 1 = 0.235602 loss)
I0526 11:35:27.069643 15394 sgd_solver.cpp:43] Iteration 45650, lr = 0.002
I0526 11:35:38.989105 15394 main.cpp:354] Iteration 45660, loss = 0.266861
I0526 11:35:38.989151 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.266861 (* 1 = 0.266861 loss)
I0526 11:35:38.989157 15394 sgd_solver.cpp:43] Iteration 45660, lr = 0.002
I0526 11:35:51.248826 15394 main.cpp:354] Iteration 45670, loss = 0.10983
I0526 11:35:51.248873 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.10983 (* 1 = 0.10983 loss)
I0526 11:35:51.248886 15394 sgd_solver.cpp:43] Iteration 45670, lr = 0.002
I0526 11:36:03.893097 15394 main.cpp:354] Iteration 45680, loss = 0.171839
I0526 11:36:03.893137 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.171839 (* 1 = 0.171839 loss)
I0526 11:36:03.893143 15394 sgd_solver.cpp:43] Iteration 45680, lr = 0.002
I0526 11:36:15.993233 15394 main.cpp:354] Iteration 45690, loss = 0.185312
I0526 11:36:15.993274 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.185311 (* 1 = 0.185311 loss)
I0526 11:36:15.993281 15394 sgd_solver.cpp:43] Iteration 45690, lr = 0.002
I0526 11:36:21.651289 15394 main.cpp:465] Iteration 45700, Testing net (#0)
I0526 11:36:41.585742 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8868
I0526 11:36:41.585784 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.353971 (* 1 = 0.353971 loss)
I0526 11:36:42.416463 15394 main.cpp:354] Iteration 45700, loss = 0.966823
I0526 11:36:42.416504 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.966822 (* 1 = 0.966822 loss)
I0526 11:36:42.416512 15394 sgd_solver.cpp:43] Iteration 45700, lr = 0.002
I0526 11:36:54.641510 15394 main.cpp:354] Iteration 45710, loss = 0.160551
I0526 11:36:54.641558 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.16055 (* 1 = 0.16055 loss)
I0526 11:36:54.641566 15394 sgd_solver.cpp:43] Iteration 45710, lr = 0.002
I0526 11:37:05.997714 15394 main.cpp:354] Iteration 45720, loss = 0.22789
I0526 11:37:05.997759 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.22789 (* 1 = 0.22789 loss)
I0526 11:37:05.997766 15394 sgd_solver.cpp:43] Iteration 45720, lr = 0.002
I0526 11:37:13.692142 15394 main.cpp:354] Iteration 45730, loss = 0.19642
I0526 11:37:13.692181 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.196419 (* 1 = 0.196419 loss)
I0526 11:37:13.692188 15394 sgd_solver.cpp:43] Iteration 45730, lr = 0.002
I0526 11:37:19.226157 15394 main.cpp:354] Iteration 45740, loss = 0.0680761
I0526 11:37:19.226203 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0680758 (* 1 = 0.0680758 loss)
I0526 11:37:19.226212 15394 sgd_solver.cpp:43] Iteration 45740, lr = 0.002
I0526 11:37:29.201807 15394 main.cpp:354] Iteration 45750, loss = 0.244778
I0526 11:37:29.201848 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.244778 (* 1 = 0.244778 loss)
I0526 11:37:29.201854 15394 sgd_solver.cpp:43] Iteration 45750, lr = 0.002
I0526 11:37:41.243125 15394 main.cpp:354] Iteration 45760, loss = 0.168
I0526 11:37:41.243172 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.168 (* 1 = 0.168 loss)
I0526 11:37:41.243180 15394 sgd_solver.cpp:43] Iteration 45760, lr = 0.002
I0526 11:37:50.234416 15394 main.cpp:354] Iteration 45770, loss = 0.114605
I0526 11:37:50.234458 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.114605 (* 1 = 0.114605 loss)
I0526 11:37:50.234467 15394 sgd_solver.cpp:43] Iteration 45770, lr = 0.002
I0526 11:37:55.744133 15394 main.cpp:354] Iteration 45780, loss = 0.168999
I0526 11:37:55.744195 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.168999 (* 1 = 0.168999 loss)
I0526 11:37:55.744205 15394 sgd_solver.cpp:43] Iteration 45780, lr = 0.002
I0526 11:38:01.275830 15394 main.cpp:354] Iteration 45790, loss = 0.12379
I0526 11:38:01.275871 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.12379 (* 1 = 0.12379 loss)
I0526 11:38:01.275877 15394 sgd_solver.cpp:43] Iteration 45790, lr = 0.002
I0526 11:38:08.968211 15394 main.cpp:465] Iteration 45800, Testing net (#0)
I0526 11:38:26.833434 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8856
I0526 11:38:26.833473 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.358678 (* 1 = 0.358678 loss)
I0526 11:38:27.376220 15394 main.cpp:354] Iteration 45800, loss = 0.143398
I0526 11:38:27.376260 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.143398 (* 1 = 0.143398 loss)
I0526 11:38:27.376268 15394 sgd_solver.cpp:43] Iteration 45800, lr = 0.002
I0526 11:38:32.492625 15394 main.cpp:354] Iteration 45810, loss = 0.429532
I0526 11:38:32.492666 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.429531 (* 1 = 0.429531 loss)
I0526 11:38:32.492671 15394 sgd_solver.cpp:43] Iteration 45810, lr = 0.002
I0526 11:38:37.549944 15394 main.cpp:354] Iteration 45820, loss = 0.253411
I0526 11:38:37.549983 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.253411 (* 1 = 0.253411 loss)
I0526 11:38:37.549990 15394 sgd_solver.cpp:43] Iteration 45820, lr = 0.002
I0526 11:38:42.494047 15394 main.cpp:354] Iteration 45830, loss = 0.317458
I0526 11:38:42.494088 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.317458 (* 1 = 0.317458 loss)
I0526 11:38:42.494096 15394 sgd_solver.cpp:43] Iteration 45830, lr = 0.002
I0526 11:38:47.702080 15394 main.cpp:354] Iteration 45840, loss = 0.205087
I0526 11:38:47.702123 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.205087 (* 1 = 0.205087 loss)
I0526 11:38:47.702131 15394 sgd_solver.cpp:43] Iteration 45840, lr = 0.002
I0526 11:38:52.792143 15394 main.cpp:354] Iteration 45850, loss = 0.0916678
I0526 11:38:52.792182 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0916675 (* 1 = 0.0916675 loss)
I0526 11:38:52.792188 15394 sgd_solver.cpp:43] Iteration 45850, lr = 0.002
I0526 11:38:57.954864 15394 main.cpp:354] Iteration 45860, loss = 0.27675
I0526 11:38:57.954906 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.276749 (* 1 = 0.276749 loss)
I0526 11:38:57.954915 15394 sgd_solver.cpp:43] Iteration 45860, lr = 0.002
I0526 11:39:03.219221 15394 main.cpp:354] Iteration 45870, loss = 0.15581
I0526 11:39:03.219264 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.15581 (* 1 = 0.15581 loss)
I0526 11:39:03.219271 15394 sgd_solver.cpp:43] Iteration 45870, lr = 0.002
I0526 11:39:07.562014 15394 main.cpp:354] Iteration 45880, loss = 0.142934
I0526 11:39:07.562054 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.142933 (* 1 = 0.142933 loss)
I0526 11:39:07.562062 15394 sgd_solver.cpp:43] Iteration 45880, lr = 0.002
I0526 11:39:12.511724 15394 main.cpp:354] Iteration 45890, loss = 0.193117
I0526 11:39:12.511762 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.193117 (* 1 = 0.193117 loss)
I0526 11:39:12.511770 15394 sgd_solver.cpp:43] Iteration 45890, lr = 0.002
I0526 11:39:16.751690 15394 main.cpp:465] Iteration 45900, Testing net (#0)
I0526 11:39:29.841213 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8925
I0526 11:39:29.841253 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.336887 (* 1 = 0.336887 loss)
I0526 11:39:30.385038 15394 main.cpp:354] Iteration 45900, loss = 0.271538
I0526 11:39:30.385089 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.271538 (* 1 = 0.271538 loss)
I0526 11:39:30.385097 15394 sgd_solver.cpp:43] Iteration 45900, lr = 0.002
I0526 11:39:35.208704 15394 main.cpp:354] Iteration 45910, loss = 0.20465
I0526 11:39:35.208746 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.20465 (* 1 = 0.20465 loss)
I0526 11:39:35.208753 15394 sgd_solver.cpp:43] Iteration 45910, lr = 0.002
I0526 11:39:40.216981 15394 main.cpp:354] Iteration 45920, loss = 0.241929
I0526 11:39:40.217012 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.241929 (* 1 = 0.241929 loss)
I0526 11:39:40.217020 15394 sgd_solver.cpp:43] Iteration 45920, lr = 0.002
I0526 11:39:45.305250 15394 main.cpp:354] Iteration 45930, loss = 0.195522
I0526 11:39:45.305289 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.195522 (* 1 = 0.195522 loss)
I0526 11:39:45.305295 15394 sgd_solver.cpp:43] Iteration 45930, lr = 0.002
I0526 11:39:50.413301 15394 main.cpp:354] Iteration 45940, loss = 0.178726
I0526 11:39:50.413343 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.178726 (* 1 = 0.178726 loss)
I0526 11:39:50.413350 15394 sgd_solver.cpp:43] Iteration 45940, lr = 0.002
I0526 11:39:55.606104 15394 main.cpp:354] Iteration 45950, loss = 0.232298
I0526 11:39:55.606150 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.232298 (* 1 = 0.232298 loss)
I0526 11:39:55.606158 15394 sgd_solver.cpp:43] Iteration 45950, lr = 0.002
I0526 11:40:00.213888 15394 main.cpp:354] Iteration 45960, loss = 0.730341
I0526 11:40:00.213927 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.730341 (* 1 = 0.730341 loss)
I0526 11:40:00.213933 15394 sgd_solver.cpp:43] Iteration 45960, lr = 0.002
I0526 11:40:05.457386 15394 main.cpp:354] Iteration 45970, loss = 0.224862
I0526 11:40:05.457424 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.224862 (* 1 = 0.224862 loss)
I0526 11:40:05.457432 15394 sgd_solver.cpp:43] Iteration 45970, lr = 0.002
I0526 11:40:10.481612 15394 main.cpp:354] Iteration 45980, loss = 0.186878
I0526 11:40:10.481650 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186877 (* 1 = 0.186877 loss)
I0526 11:40:10.481657 15394 sgd_solver.cpp:43] Iteration 45980, lr = 0.002
I0526 11:40:15.881629 15394 main.cpp:354] Iteration 45990, loss = 0.253815
I0526 11:40:15.881669 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.253815 (* 1 = 0.253815 loss)
I0526 11:40:15.881676 15394 sgd_solver.cpp:43] Iteration 45990, lr = 0.002
I0526 11:40:20.542858 15394 main.cpp:465] Iteration 46000, Testing net (#0)
I0526 11:40:33.625151 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8871
I0526 11:40:33.625195 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.355195 (* 1 = 0.355195 loss)
I0526 11:40:34.163588 15394 main.cpp:354] Iteration 46000, loss = 0.189122
I0526 11:40:34.163626 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.189122 (* 1 = 0.189122 loss)
I0526 11:40:34.163635 15394 sgd_solver.cpp:43] Iteration 46000, lr = 0.002
I0526 11:40:38.959969 15394 main.cpp:354] Iteration 46010, loss = 0.188089
I0526 11:40:38.960011 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.188089 (* 1 = 0.188089 loss)
I0526 11:40:38.960016 15394 sgd_solver.cpp:43] Iteration 46010, lr = 0.002
I0526 11:40:43.976846 15394 main.cpp:354] Iteration 46020, loss = 0.346997
I0526 11:40:43.976884 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.346996 (* 1 = 0.346996 loss)
I0526 11:40:43.976891 15394 sgd_solver.cpp:43] Iteration 46020, lr = 0.002
I0526 11:40:49.215618 15394 main.cpp:354] Iteration 46030, loss = 0.151592
I0526 11:40:49.215646 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.151591 (* 1 = 0.151591 loss)
I0526 11:40:49.215652 15394 sgd_solver.cpp:43] Iteration 46030, lr = 0.002
I0526 11:40:54.560706 15394 main.cpp:354] Iteration 46040, loss = 0.698125
I0526 11:40:54.560745 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.698125 (* 1 = 0.698125 loss)
I0526 11:40:54.560752 15394 sgd_solver.cpp:43] Iteration 46040, lr = 0.002
I0526 11:40:59.530148 15394 main.cpp:354] Iteration 46050, loss = 0.245075
I0526 11:40:59.530187 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.245075 (* 1 = 0.245075 loss)
I0526 11:40:59.530194 15394 sgd_solver.cpp:43] Iteration 46050, lr = 0.002
I0526 11:41:04.416955 15394 main.cpp:354] Iteration 46060, loss = 0.166134
I0526 11:41:04.416998 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.166134 (* 1 = 0.166134 loss)
I0526 11:41:04.417006 15394 sgd_solver.cpp:43] Iteration 46060, lr = 0.002
I0526 11:41:09.637286 15394 main.cpp:354] Iteration 46070, loss = 0.259143
I0526 11:41:09.637327 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.259143 (* 1 = 0.259143 loss)
I0526 11:41:09.637334 15394 sgd_solver.cpp:43] Iteration 46070, lr = 0.002
I0526 11:41:15.087266 15394 main.cpp:354] Iteration 46080, loss = 0.203158
I0526 11:41:15.087308 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.203157 (* 1 = 0.203157 loss)
I0526 11:41:15.087316 15394 sgd_solver.cpp:43] Iteration 46080, lr = 0.002
I0526 11:41:20.628629 15394 main.cpp:354] Iteration 46090, loss = 0.159441
I0526 11:41:20.628672 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.15944 (* 1 = 0.15944 loss)
I0526 11:41:20.628684 15394 sgd_solver.cpp:43] Iteration 46090, lr = 0.002
I0526 11:41:24.926785 15394 main.cpp:465] Iteration 46100, Testing net (#0)
I0526 11:41:38.006049 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8918
I0526 11:41:38.006090 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.336272 (* 1 = 0.336272 loss)
I0526 11:41:38.547076 15394 main.cpp:354] Iteration 46100, loss = 0.145104
I0526 11:41:38.547112 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.145104 (* 1 = 0.145104 loss)
I0526 11:41:38.547122 15394 sgd_solver.cpp:43] Iteration 46100, lr = 0.002
I0526 11:41:44.083415 15394 main.cpp:354] Iteration 46110, loss = 0.26952
I0526 11:41:44.083457 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.26952 (* 1 = 0.26952 loss)
I0526 11:41:44.083463 15394 sgd_solver.cpp:43] Iteration 46110, lr = 0.002
I0526 11:41:48.858860 15394 main.cpp:354] Iteration 46120, loss = 0.265666
I0526 11:41:48.858906 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.265666 (* 1 = 0.265666 loss)
I0526 11:41:48.858912 15394 sgd_solver.cpp:43] Iteration 46120, lr = 0.002
I0526 11:41:54.083704 15394 main.cpp:354] Iteration 46130, loss = 0.223316
I0526 11:41:54.083745 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.223316 (* 1 = 0.223316 loss)
I0526 11:41:54.083751 15394 sgd_solver.cpp:43] Iteration 46130, lr = 0.002
I0526 11:41:59.039012 15394 main.cpp:354] Iteration 46140, loss = 0.331424
I0526 11:41:59.039049 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.331423 (* 1 = 0.331423 loss)
I0526 11:41:59.039055 15394 sgd_solver.cpp:43] Iteration 46140, lr = 0.002
I0526 11:42:04.270496 15394 main.cpp:354] Iteration 46150, loss = 0.149362
I0526 11:42:04.270539 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.149361 (* 1 = 0.149361 loss)
I0526 11:42:04.270546 15394 sgd_solver.cpp:43] Iteration 46150, lr = 0.002
I0526 11:42:09.505753 15394 main.cpp:354] Iteration 46160, loss = 0.204606
I0526 11:42:09.505792 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204605 (* 1 = 0.204605 loss)
I0526 11:42:09.505800 15394 sgd_solver.cpp:43] Iteration 46160, lr = 0.002
I0526 11:42:14.902346 15394 main.cpp:354] Iteration 46170, loss = 0.181131
I0526 11:42:14.902395 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.181131 (* 1 = 0.181131 loss)
I0526 11:42:14.902401 15394 sgd_solver.cpp:43] Iteration 46170, lr = 0.002
I0526 11:42:20.043282 15394 main.cpp:354] Iteration 46180, loss = 0.18246
I0526 11:42:20.043324 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.18246 (* 1 = 0.18246 loss)
I0526 11:42:20.043331 15394 sgd_solver.cpp:43] Iteration 46180, lr = 0.002
I0526 11:42:25.403028 15394 main.cpp:354] Iteration 46190, loss = 0.196449
I0526 11:42:25.403070 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.196449 (* 1 = 0.196449 loss)
I0526 11:42:25.403076 15394 sgd_solver.cpp:43] Iteration 46190, lr = 0.002
I0526 11:42:29.676358 15394 main.cpp:465] Iteration 46200, Testing net (#0)
I0526 11:42:42.753995 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8831
I0526 11:42:42.754040 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.379194 (* 1 = 0.379194 loss)
I0526 11:42:43.293493 15394 main.cpp:354] Iteration 46200, loss = 0.302188
I0526 11:42:43.293537 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.302188 (* 1 = 0.302188 loss)
I0526 11:42:43.293547 15394 sgd_solver.cpp:43] Iteration 46200, lr = 0.002
I0526 11:42:48.524404 15394 main.cpp:354] Iteration 46210, loss = 0.258998
I0526 11:42:48.524448 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.258998 (* 1 = 0.258998 loss)
I0526 11:42:48.524456 15394 sgd_solver.cpp:43] Iteration 46210, lr = 0.002
I0526 11:42:53.358345 15394 main.cpp:354] Iteration 46220, loss = 0.336514
I0526 11:42:53.358398 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.336513 (* 1 = 0.336513 loss)
I0526 11:42:53.358412 15394 sgd_solver.cpp:43] Iteration 46220, lr = 0.002
I0526 11:42:58.933380 15394 main.cpp:354] Iteration 46230, loss = 0.181156
I0526 11:42:58.933419 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.181155 (* 1 = 0.181155 loss)
I0526 11:42:58.933425 15394 sgd_solver.cpp:43] Iteration 46230, lr = 0.002
I0526 11:43:03.491425 15394 main.cpp:354] Iteration 46240, loss = 0.217833
I0526 11:43:03.491467 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.217833 (* 1 = 0.217833 loss)
I0526 11:43:03.491473 15394 sgd_solver.cpp:43] Iteration 46240, lr = 0.002
I0526 11:43:08.642266 15394 main.cpp:354] Iteration 46250, loss = 0.248546
I0526 11:43:08.642304 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.248546 (* 1 = 0.248546 loss)
I0526 11:43:08.642312 15394 sgd_solver.cpp:43] Iteration 46250, lr = 0.002
I0526 11:43:13.736598 15394 main.cpp:354] Iteration 46260, loss = 0.337845
I0526 11:43:13.736639 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.337844 (* 1 = 0.337844 loss)
I0526 11:43:13.736646 15394 sgd_solver.cpp:43] Iteration 46260, lr = 0.002
I0526 11:43:19.046104 15394 main.cpp:354] Iteration 46270, loss = 0.0818827
I0526 11:43:19.046147 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0818825 (* 1 = 0.0818825 loss)
I0526 11:43:19.046154 15394 sgd_solver.cpp:43] Iteration 46270, lr = 0.002
I0526 11:43:23.751891 15394 main.cpp:354] Iteration 46280, loss = 0.337254
I0526 11:43:23.751929 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.337254 (* 1 = 0.337254 loss)
I0526 11:43:23.751935 15394 sgd_solver.cpp:43] Iteration 46280, lr = 0.002
I0526 11:43:28.950872 15394 main.cpp:354] Iteration 46290, loss = 0.183646
I0526 11:43:28.950911 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.183646 (* 1 = 0.183646 loss)
I0526 11:43:28.950917 15394 sgd_solver.cpp:43] Iteration 46290, lr = 0.002
I0526 11:43:33.630851 15394 main.cpp:465] Iteration 46300, Testing net (#0)
I0526 11:43:46.712705 15394 main.cpp:532]     Test net output #0: Accuracy = 0.89
I0526 11:43:46.712745 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.350748 (* 1 = 0.350748 loss)
I0526 11:43:47.077407 15394 main.cpp:354] Iteration 46300, loss = 0.414444
I0526 11:43:47.077443 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.414443 (* 1 = 0.414443 loss)
I0526 11:43:47.077451 15394 sgd_solver.cpp:43] Iteration 46300, lr = 0.002
I0526 11:43:52.599092 15394 main.cpp:354] Iteration 46310, loss = 0.187661
I0526 11:43:52.599131 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187661 (* 1 = 0.187661 loss)
I0526 11:43:52.599138 15394 sgd_solver.cpp:43] Iteration 46310, lr = 0.002
I0526 11:43:58.144356 15394 main.cpp:354] Iteration 46320, loss = 0.173184
I0526 11:43:58.144397 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.173184 (* 1 = 0.173184 loss)
I0526 11:43:58.144403 15394 sgd_solver.cpp:43] Iteration 46320, lr = 0.002
I0526 11:44:03.477463 15394 main.cpp:354] Iteration 46330, loss = 0.308164
I0526 11:44:03.477504 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.308164 (* 1 = 0.308164 loss)
I0526 11:44:03.477511 15394 sgd_solver.cpp:43] Iteration 46330, lr = 0.002
I0526 11:44:08.474726 15394 main.cpp:354] Iteration 46340, loss = 0.126757
I0526 11:44:08.474767 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.126757 (* 1 = 0.126757 loss)
I0526 11:44:08.474776 15394 sgd_solver.cpp:43] Iteration 46340, lr = 0.002
I0526 11:44:13.680143 15394 main.cpp:354] Iteration 46350, loss = 0.211507
I0526 11:44:13.680182 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.211507 (* 1 = 0.211507 loss)
I0526 11:44:13.680189 15394 sgd_solver.cpp:43] Iteration 46350, lr = 0.002
I0526 11:44:18.782358 15394 main.cpp:354] Iteration 46360, loss = 0.145256
I0526 11:44:18.782413 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.145255 (* 1 = 0.145255 loss)
I0526 11:44:18.782420 15394 sgd_solver.cpp:43] Iteration 46360, lr = 0.002
I0526 11:44:24.005825 15394 main.cpp:354] Iteration 46370, loss = 0.2085
I0526 11:44:24.005863 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.2085 (* 1 = 0.2085 loss)
I0526 11:44:24.005869 15394 sgd_solver.cpp:43] Iteration 46370, lr = 0.002
I0526 11:44:29.060874 15394 main.cpp:354] Iteration 46380, loss = 0.303005
I0526 11:44:29.060914 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.303004 (* 1 = 0.303004 loss)
I0526 11:44:29.060921 15394 sgd_solver.cpp:43] Iteration 46380, lr = 0.002
I0526 11:44:33.924788 15394 main.cpp:354] Iteration 46390, loss = 0.192209
I0526 11:44:33.924834 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.192209 (* 1 = 0.192209 loss)
I0526 11:44:33.924840 15394 sgd_solver.cpp:43] Iteration 46390, lr = 0.002
I0526 11:44:38.370702 15394 main.cpp:465] Iteration 46400, Testing net (#0)
I0526 11:44:51.454167 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8887
I0526 11:44:51.454207 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.342642 (* 1 = 0.342642 loss)
I0526 11:44:51.998042 15394 main.cpp:354] Iteration 46400, loss = 0.18897
I0526 11:44:51.998075 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.18897 (* 1 = 0.18897 loss)
I0526 11:44:51.998082 15394 sgd_solver.cpp:43] Iteration 46400, lr = 0.002
I0526 11:44:57.240619 15394 main.cpp:354] Iteration 46410, loss = 0.183975
I0526 11:44:57.240658 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.183975 (* 1 = 0.183975 loss)
I0526 11:44:57.240664 15394 sgd_solver.cpp:43] Iteration 46410, lr = 0.002
I0526 11:45:02.420370 15394 main.cpp:354] Iteration 46420, loss = 0.229905
I0526 11:45:02.420415 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.229904 (* 1 = 0.229904 loss)
I0526 11:45:02.420423 15394 sgd_solver.cpp:43] Iteration 46420, lr = 0.002
I0526 11:45:07.535303 15394 main.cpp:354] Iteration 46430, loss = 0.197406
I0526 11:45:07.535342 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.197406 (* 1 = 0.197406 loss)
I0526 11:45:07.535349 15394 sgd_solver.cpp:43] Iteration 46430, lr = 0.002
I0526 11:45:12.795758 15394 main.cpp:354] Iteration 46440, loss = 0.30582
I0526 11:45:12.795796 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.30582 (* 1 = 0.30582 loss)
I0526 11:45:12.795804 15394 sgd_solver.cpp:43] Iteration 46440, lr = 0.002
I0526 11:45:17.727720 15394 main.cpp:354] Iteration 46450, loss = 0.138825
I0526 11:45:17.727763 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.138825 (* 1 = 0.138825 loss)
I0526 11:45:17.727771 15394 sgd_solver.cpp:43] Iteration 46450, lr = 0.002
I0526 11:45:22.143816 15394 main.cpp:354] Iteration 46460, loss = 0.315928
I0526 11:45:22.143856 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.315927 (* 1 = 0.315927 loss)
I0526 11:45:22.143862 15394 sgd_solver.cpp:43] Iteration 46460, lr = 0.002
I0526 11:45:27.170418 15394 main.cpp:354] Iteration 46470, loss = 0.267886
I0526 11:45:27.170446 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.267885 (* 1 = 0.267885 loss)
I0526 11:45:27.170454 15394 sgd_solver.cpp:43] Iteration 46470, lr = 0.002
I0526 11:45:32.352210 15394 main.cpp:354] Iteration 46480, loss = 0.218758
I0526 11:45:32.352253 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.218758 (* 1 = 0.218758 loss)
I0526 11:45:32.352259 15394 sgd_solver.cpp:43] Iteration 46480, lr = 0.002
I0526 11:45:37.099208 15394 main.cpp:354] Iteration 46490, loss = 0.189231
I0526 11:45:37.099272 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.189231 (* 1 = 0.189231 loss)
I0526 11:45:37.099279 15394 sgd_solver.cpp:43] Iteration 46490, lr = 0.002
I0526 11:45:41.443321 15394 main.cpp:465] Iteration 46500, Testing net (#0)
I0526 11:45:54.535998 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8899
I0526 11:45:54.536039 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.339953 (* 1 = 0.339953 loss)
I0526 11:45:55.043479 15394 main.cpp:354] Iteration 46500, loss = 0.187393
I0526 11:45:55.043501 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187393 (* 1 = 0.187393 loss)
I0526 11:45:55.043514 15394 sgd_solver.cpp:43] Iteration 46500, lr = 0.002
I0526 11:46:00.130794 15394 main.cpp:354] Iteration 46510, loss = 0.313807
I0526 11:46:00.130833 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.313806 (* 1 = 0.313806 loss)
I0526 11:46:00.130839 15394 sgd_solver.cpp:43] Iteration 46510, lr = 0.002
I0526 11:46:05.162930 15394 main.cpp:354] Iteration 46520, loss = 0.223488
I0526 11:46:05.162974 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.223487 (* 1 = 0.223487 loss)
I0526 11:46:05.162981 15394 sgd_solver.cpp:43] Iteration 46520, lr = 0.002
I0526 11:46:10.699057 15394 main.cpp:354] Iteration 46530, loss = 0.266017
I0526 11:46:10.699100 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.266017 (* 1 = 0.266017 loss)
I0526 11:46:10.699105 15394 sgd_solver.cpp:43] Iteration 46530, lr = 0.002
I0526 11:46:15.378957 15394 main.cpp:354] Iteration 46540, loss = 0.279999
I0526 11:46:15.378995 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.279999 (* 1 = 0.279999 loss)
I0526 11:46:15.379001 15394 sgd_solver.cpp:43] Iteration 46540, lr = 0.002
I0526 11:46:20.429091 15394 main.cpp:354] Iteration 46550, loss = 0.102958
I0526 11:46:20.429134 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.102957 (* 1 = 0.102957 loss)
I0526 11:46:20.429141 15394 sgd_solver.cpp:43] Iteration 46550, lr = 0.002
I0526 11:46:25.463491 15394 main.cpp:354] Iteration 46560, loss = 0.128759
I0526 11:46:25.463531 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.128759 (* 1 = 0.128759 loss)
I0526 11:46:25.463536 15394 sgd_solver.cpp:43] Iteration 46560, lr = 0.002
I0526 11:46:31.202483 15394 main.cpp:354] Iteration 46570, loss = 0.129375
I0526 11:46:31.202523 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.129375 (* 1 = 0.129375 loss)
I0526 11:46:31.202531 15394 sgd_solver.cpp:43] Iteration 46570, lr = 0.002
I0526 11:46:36.147326 15394 main.cpp:354] Iteration 46580, loss = 0.277451
I0526 11:46:36.147369 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.27745 (* 1 = 0.27745 loss)
I0526 11:46:36.147377 15394 sgd_solver.cpp:43] Iteration 46580, lr = 0.002
I0526 11:46:40.875787 15394 main.cpp:354] Iteration 46590, loss = 0.506676
I0526 11:46:40.875828 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.506675 (* 1 = 0.506675 loss)
I0526 11:46:40.875834 15394 sgd_solver.cpp:43] Iteration 46590, lr = 0.002
I0526 11:46:45.406152 15394 main.cpp:465] Iteration 46600, Testing net (#0)
I0526 11:46:58.493212 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8813
I0526 11:46:58.493249 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.37193 (* 1 = 0.37193 loss)
I0526 11:46:59.032582 15394 main.cpp:354] Iteration 46600, loss = 0.132696
I0526 11:46:59.032618 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.132696 (* 1 = 0.132696 loss)
I0526 11:46:59.032626 15394 sgd_solver.cpp:43] Iteration 46600, lr = 0.002
I0526 11:47:04.359943 15394 main.cpp:354] Iteration 46610, loss = 0.358057
I0526 11:47:04.359984 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.358057 (* 1 = 0.358057 loss)
I0526 11:47:04.359990 15394 sgd_solver.cpp:43] Iteration 46610, lr = 0.002
I0526 11:47:09.039945 15394 main.cpp:354] Iteration 46620, loss = 0.244038
I0526 11:47:09.039985 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.244038 (* 1 = 0.244038 loss)
I0526 11:47:09.039991 15394 sgd_solver.cpp:43] Iteration 46620, lr = 0.002
I0526 11:47:14.137467 15394 main.cpp:354] Iteration 46630, loss = 0.218061
I0526 11:47:14.137504 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.218061 (* 1 = 0.218061 loss)
I0526 11:47:14.137511 15394 sgd_solver.cpp:43] Iteration 46630, lr = 0.002
I0526 11:47:19.306061 15394 main.cpp:354] Iteration 46640, loss = 0.195384
I0526 11:47:19.306104 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.195384 (* 1 = 0.195384 loss)
I0526 11:47:19.306114 15394 sgd_solver.cpp:43] Iteration 46640, lr = 0.002
I0526 11:47:24.724166 15394 main.cpp:354] Iteration 46650, loss = 0.264659
I0526 11:47:24.724206 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.264659 (* 1 = 0.264659 loss)
I0526 11:47:24.724212 15394 sgd_solver.cpp:43] Iteration 46650, lr = 0.002
I0526 11:47:29.598433 15394 main.cpp:354] Iteration 46660, loss = 0.500357
I0526 11:47:29.598472 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.500356 (* 1 = 0.500356 loss)
I0526 11:47:29.598479 15394 sgd_solver.cpp:43] Iteration 46660, lr = 0.002
I0526 11:47:34.737385 15394 main.cpp:354] Iteration 46670, loss = 0.115306
I0526 11:47:34.737426 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.115306 (* 1 = 0.115306 loss)
I0526 11:47:34.737433 15394 sgd_solver.cpp:43] Iteration 46670, lr = 0.002
I0526 11:47:40.020840 15394 main.cpp:354] Iteration 46680, loss = 0.254189
I0526 11:47:40.020879 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.254188 (* 1 = 0.254188 loss)
I0526 11:47:40.020885 15394 sgd_solver.cpp:43] Iteration 46680, lr = 0.002
I0526 11:47:45.312736 15394 main.cpp:354] Iteration 46690, loss = 0.134261
I0526 11:47:45.312775 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.134261 (* 1 = 0.134261 loss)
I0526 11:47:45.312783 15394 sgd_solver.cpp:43] Iteration 46690, lr = 0.002
I0526 11:47:50.399950 15394 main.cpp:465] Iteration 46700, Testing net (#0)
I0526 11:48:03.491387 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8939
I0526 11:48:03.491426 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.32979 (* 1 = 0.32979 loss)
I0526 11:48:03.965189 15394 main.cpp:354] Iteration 46700, loss = 0.19237
I0526 11:48:03.965229 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.19237 (* 1 = 0.19237 loss)
I0526 11:48:03.965236 15394 sgd_solver.cpp:43] Iteration 46700, lr = 0.002
I0526 11:48:08.856690 15394 main.cpp:354] Iteration 46710, loss = 0.135975
I0526 11:48:08.856731 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.135975 (* 1 = 0.135975 loss)
I0526 11:48:08.856737 15394 sgd_solver.cpp:43] Iteration 46710, lr = 0.002
I0526 11:48:14.504390 15394 main.cpp:354] Iteration 46720, loss = 0.142733
I0526 11:48:14.504431 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.142732 (* 1 = 0.142732 loss)
I0526 11:48:14.504438 15394 sgd_solver.cpp:43] Iteration 46720, lr = 0.002
I0526 11:48:19.739176 15394 main.cpp:354] Iteration 46730, loss = 0.276
I0526 11:48:19.739219 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.276 (* 1 = 0.276 loss)
I0526 11:48:19.739225 15394 sgd_solver.cpp:43] Iteration 46730, lr = 0.002
I0526 11:48:24.153439 15394 main.cpp:354] Iteration 46740, loss = 0.384641
I0526 11:48:24.153477 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.384641 (* 1 = 0.384641 loss)
I0526 11:48:24.153483 15394 sgd_solver.cpp:43] Iteration 46740, lr = 0.002
I0526 11:48:29.079501 15394 main.cpp:354] Iteration 46750, loss = 0.401737
I0526 11:48:29.079542 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.401736 (* 1 = 0.401736 loss)
I0526 11:48:29.079548 15394 sgd_solver.cpp:43] Iteration 46750, lr = 0.002
I0526 11:48:34.028512 15394 main.cpp:354] Iteration 46760, loss = 0.267877
I0526 11:48:34.028558 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.267877 (* 1 = 0.267877 loss)
I0526 11:48:34.028563 15394 sgd_solver.cpp:43] Iteration 46760, lr = 0.002
I0526 11:48:39.201791 15394 main.cpp:354] Iteration 46770, loss = 0.218712
I0526 11:48:39.201828 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.218712 (* 1 = 0.218712 loss)
I0526 11:48:39.201834 15394 sgd_solver.cpp:43] Iteration 46770, lr = 0.002
I0526 11:48:44.426565 15394 main.cpp:354] Iteration 46780, loss = 0.321162
I0526 11:48:44.426606 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.321162 (* 1 = 0.321162 loss)
I0526 11:48:44.426614 15394 sgd_solver.cpp:43] Iteration 46780, lr = 0.002
I0526 11:48:49.462667 15394 main.cpp:354] Iteration 46790, loss = 0.173751
I0526 11:48:49.462723 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.173751 (* 1 = 0.173751 loss)
I0526 11:48:49.462733 15394 sgd_solver.cpp:43] Iteration 46790, lr = 0.002
I0526 11:48:54.342118 15394 main.cpp:465] Iteration 46800, Testing net (#0)
I0526 11:49:07.422202 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8905
I0526 11:49:07.422246 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.345403 (* 1 = 0.345403 loss)
I0526 11:49:07.925369 15394 main.cpp:354] Iteration 46800, loss = 0.142415
I0526 11:49:07.925412 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.142415 (* 1 = 0.142415 loss)
I0526 11:49:07.925423 15394 sgd_solver.cpp:43] Iteration 46800, lr = 0.002
I0526 11:49:13.263432 15394 main.cpp:354] Iteration 46810, loss = 0.252447
I0526 11:49:13.263459 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.252447 (* 1 = 0.252447 loss)
I0526 11:49:13.263466 15394 sgd_solver.cpp:43] Iteration 46810, lr = 0.002
I0526 11:49:18.558820 15394 main.cpp:354] Iteration 46820, loss = 0.227425
I0526 11:49:18.558863 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.227425 (* 1 = 0.227425 loss)
I0526 11:49:18.558869 15394 sgd_solver.cpp:43] Iteration 46820, lr = 0.002
I0526 11:49:23.207612 15394 main.cpp:354] Iteration 46830, loss = 0.165039
I0526 11:49:23.207651 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.165038 (* 1 = 0.165038 loss)
I0526 11:49:23.207658 15394 sgd_solver.cpp:43] Iteration 46830, lr = 0.002
I0526 11:49:27.804565 15394 main.cpp:354] Iteration 46840, loss = 0.316741
I0526 11:49:27.804605 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.31674 (* 1 = 0.31674 loss)
I0526 11:49:27.804611 15394 sgd_solver.cpp:43] Iteration 46840, lr = 0.002
I0526 11:49:32.719507 15394 main.cpp:354] Iteration 46850, loss = 0.151772
I0526 11:49:32.719542 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.151772 (* 1 = 0.151772 loss)
I0526 11:49:32.719548 15394 sgd_solver.cpp:43] Iteration 46850, lr = 0.002
I0526 11:49:37.866832 15394 main.cpp:354] Iteration 46860, loss = 0.162591
I0526 11:49:37.866873 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.162591 (* 1 = 0.162591 loss)
I0526 11:49:37.866879 15394 sgd_solver.cpp:43] Iteration 46860, lr = 0.002
I0526 11:49:42.806783 15394 main.cpp:354] Iteration 46870, loss = 0.503261
I0526 11:49:42.806821 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.503261 (* 1 = 0.503261 loss)
I0526 11:49:42.806828 15394 sgd_solver.cpp:43] Iteration 46870, lr = 0.002
I0526 11:49:47.680480 15394 main.cpp:354] Iteration 46880, loss = 0.222222
I0526 11:49:47.680518 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.222222 (* 1 = 0.222222 loss)
I0526 11:49:47.680526 15394 sgd_solver.cpp:43] Iteration 46880, lr = 0.002
I0526 11:49:52.651980 15394 main.cpp:354] Iteration 46890, loss = 0.211295
I0526 11:49:52.652020 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.211295 (* 1 = 0.211295 loss)
I0526 11:49:52.652026 15394 sgd_solver.cpp:43] Iteration 46890, lr = 0.002
I0526 11:49:57.585875 15394 main.cpp:465] Iteration 46900, Testing net (#0)
I0526 11:50:10.663595 15394 main.cpp:532]     Test net output #0: Accuracy = 0.888
I0526 11:50:10.663633 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.357229 (* 1 = 0.357229 loss)
I0526 11:50:11.239648 15394 main.cpp:354] Iteration 46900, loss = 0.101855
I0526 11:50:11.239684 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.101854 (* 1 = 0.101854 loss)
I0526 11:50:11.239692 15394 sgd_solver.cpp:43] Iteration 46900, lr = 0.002
I0526 11:50:15.820679 15394 main.cpp:354] Iteration 46910, loss = 0.357535
I0526 11:50:15.820721 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.357535 (* 1 = 0.357535 loss)
I0526 11:50:15.820729 15394 sgd_solver.cpp:43] Iteration 46910, lr = 0.002
I0526 11:50:20.874488 15394 main.cpp:354] Iteration 46920, loss = 0.123185
I0526 11:50:20.874534 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.123184 (* 1 = 0.123184 loss)
I0526 11:50:20.874548 15394 sgd_solver.cpp:43] Iteration 46920, lr = 0.002
I0526 11:50:26.126704 15394 main.cpp:354] Iteration 46930, loss = 0.47242
I0526 11:50:26.126745 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.47242 (* 1 = 0.47242 loss)
I0526 11:50:26.126752 15394 sgd_solver.cpp:43] Iteration 46930, lr = 0.002
I0526 11:50:31.426424 15394 main.cpp:354] Iteration 46940, loss = 0.137218
I0526 11:50:31.426465 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.137218 (* 1 = 0.137218 loss)
I0526 11:50:31.426472 15394 sgd_solver.cpp:43] Iteration 46940, lr = 0.002
I0526 11:50:36.482421 15394 main.cpp:354] Iteration 46950, loss = 0.286342
I0526 11:50:36.482465 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.286341 (* 1 = 0.286341 loss)
I0526 11:50:36.482471 15394 sgd_solver.cpp:43] Iteration 46950, lr = 0.002
I0526 11:50:41.857447 15394 main.cpp:354] Iteration 46960, loss = 0.186816
I0526 11:50:41.857491 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186816 (* 1 = 0.186816 loss)
I0526 11:50:41.857507 15394 sgd_solver.cpp:43] Iteration 46960, lr = 0.002
I0526 11:50:47.142905 15394 main.cpp:354] Iteration 46970, loss = 0.183078
I0526 11:50:47.142949 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.183077 (* 1 = 0.183077 loss)
I0526 11:50:47.142956 15394 sgd_solver.cpp:43] Iteration 46970, lr = 0.002
I0526 11:50:52.247544 15394 main.cpp:354] Iteration 46980, loss = 0.298292
I0526 11:50:52.247586 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.298291 (* 1 = 0.298291 loss)
I0526 11:50:52.247592 15394 sgd_solver.cpp:43] Iteration 46980, lr = 0.002
I0526 11:50:57.488445 15394 main.cpp:354] Iteration 46990, loss = 0.138184
I0526 11:50:57.488484 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.138183 (* 1 = 0.138183 loss)
I0526 11:50:57.488490 15394 sgd_solver.cpp:43] Iteration 46990, lr = 0.002
I0526 11:51:02.312088 15394 main.cpp:465] Iteration 47000, Testing net (#0)
I0526 11:51:15.395246 15394 main.cpp:532]     Test net output #0: Accuracy = 0.89
I0526 11:51:15.395284 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.343642 (* 1 = 0.343642 loss)
I0526 11:51:15.861948 15394 main.cpp:354] Iteration 47000, loss = 0.226387
I0526 11:51:15.861984 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.226386 (* 1 = 0.226386 loss)
I0526 11:51:15.861992 15394 sgd_solver.cpp:43] Iteration 47000, lr = 0.002
I0526 11:51:21.066373 15394 main.cpp:354] Iteration 47010, loss = 0.280177
I0526 11:51:21.066416 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.280176 (* 1 = 0.280176 loss)
I0526 11:51:21.066422 15394 sgd_solver.cpp:43] Iteration 47010, lr = 0.002
I0526 11:51:26.209466 15394 main.cpp:354] Iteration 47020, loss = 0.18784
I0526 11:51:26.209502 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187839 (* 1 = 0.187839 loss)
I0526 11:51:26.209509 15394 sgd_solver.cpp:43] Iteration 47020, lr = 0.002
I0526 11:51:31.302115 15394 main.cpp:354] Iteration 47030, loss = 0.271273
I0526 11:51:31.302156 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.271273 (* 1 = 0.271273 loss)
I0526 11:51:31.302162 15394 sgd_solver.cpp:43] Iteration 47030, lr = 0.002
I0526 11:51:36.645509 15394 main.cpp:354] Iteration 47040, loss = 0.198684
I0526 11:51:36.645553 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.198684 (* 1 = 0.198684 loss)
I0526 11:51:36.645561 15394 sgd_solver.cpp:43] Iteration 47040, lr = 0.002
I0526 11:51:41.856237 15394 main.cpp:354] Iteration 47050, loss = 0.249709
I0526 11:51:41.856279 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.249708 (* 1 = 0.249708 loss)
I0526 11:51:41.856287 15394 sgd_solver.cpp:43] Iteration 47050, lr = 0.002
I0526 11:51:47.353974 15394 main.cpp:354] Iteration 47060, loss = 0.271311
I0526 11:51:47.354018 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.271311 (* 1 = 0.271311 loss)
I0526 11:51:47.354030 15394 sgd_solver.cpp:43] Iteration 47060, lr = 0.002
I0526 11:51:52.776041 15394 main.cpp:354] Iteration 47070, loss = 0.132052
I0526 11:51:52.776079 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.132051 (* 1 = 0.132051 loss)
I0526 11:51:52.776087 15394 sgd_solver.cpp:43] Iteration 47070, lr = 0.002
I0526 11:51:58.001600 15394 main.cpp:354] Iteration 47080, loss = 0.156027
I0526 11:51:58.001633 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.156027 (* 1 = 0.156027 loss)
I0526 11:51:58.001641 15394 sgd_solver.cpp:43] Iteration 47080, lr = 0.002
I0526 11:52:02.880224 15394 main.cpp:354] Iteration 47090, loss = 0.239955
I0526 11:52:02.880266 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.239955 (* 1 = 0.239955 loss)
I0526 11:52:02.880273 15394 sgd_solver.cpp:43] Iteration 47090, lr = 0.002
I0526 11:52:07.086349 15394 main.cpp:465] Iteration 47100, Testing net (#0)
I0526 11:52:20.168088 15394 main.cpp:532]     Test net output #0: Accuracy = 0.89
I0526 11:52:20.168129 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.349998 (* 1 = 0.349998 loss)
I0526 11:52:20.530745 15394 main.cpp:354] Iteration 47100, loss = 0.352406
I0526 11:52:20.530778 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.352406 (* 1 = 0.352406 loss)
I0526 11:52:20.530786 15394 sgd_solver.cpp:43] Iteration 47100, lr = 0.002
I0526 11:52:25.313783 15394 main.cpp:354] Iteration 47110, loss = 0.178923
I0526 11:52:25.313823 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.178922 (* 1 = 0.178922 loss)
I0526 11:52:25.313829 15394 sgd_solver.cpp:43] Iteration 47110, lr = 0.002
I0526 11:52:30.469877 15394 main.cpp:354] Iteration 47120, loss = 0.325594
I0526 11:52:30.469916 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.325594 (* 1 = 0.325594 loss)
I0526 11:52:30.469923 15394 sgd_solver.cpp:43] Iteration 47120, lr = 0.002
I0526 11:52:35.511140 15394 main.cpp:354] Iteration 47130, loss = 0.199019
I0526 11:52:35.511183 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.199018 (* 1 = 0.199018 loss)
I0526 11:52:35.511190 15394 sgd_solver.cpp:43] Iteration 47130, lr = 0.002
I0526 11:52:40.924088 15394 main.cpp:354] Iteration 47140, loss = 0.406935
I0526 11:52:40.924125 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.406934 (* 1 = 0.406934 loss)
I0526 11:52:40.924131 15394 sgd_solver.cpp:43] Iteration 47140, lr = 0.002
I0526 11:52:46.031922 15394 main.cpp:354] Iteration 47150, loss = 0.25161
I0526 11:52:46.031960 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.25161 (* 1 = 0.25161 loss)
I0526 11:52:46.031967 15394 sgd_solver.cpp:43] Iteration 47150, lr = 0.002
I0526 11:52:51.130802 15394 main.cpp:354] Iteration 47160, loss = 0.316525
I0526 11:52:51.130847 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.316525 (* 1 = 0.316525 loss)
I0526 11:52:51.130854 15394 sgd_solver.cpp:43] Iteration 47160, lr = 0.002
I0526 11:52:56.443079 15394 main.cpp:354] Iteration 47170, loss = 0.218326
I0526 11:52:56.443130 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.218325 (* 1 = 0.218325 loss)
I0526 11:52:56.443137 15394 sgd_solver.cpp:43] Iteration 47170, lr = 0.002
I0526 11:53:01.268806 15394 main.cpp:354] Iteration 47180, loss = 0.20791
I0526 11:53:01.268841 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.207909 (* 1 = 0.207909 loss)
I0526 11:53:01.268847 15394 sgd_solver.cpp:43] Iteration 47180, lr = 0.002
I0526 11:53:06.226771 15394 main.cpp:354] Iteration 47190, loss = 0.319691
I0526 11:53:06.226815 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.319691 (* 1 = 0.319691 loss)
I0526 11:53:06.226821 15394 sgd_solver.cpp:43] Iteration 47190, lr = 0.002
I0526 11:53:11.178339 15394 main.cpp:465] Iteration 47200, Testing net (#0)
I0526 11:53:24.272601 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8886
I0526 11:53:24.272640 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.346367 (* 1 = 0.346367 loss)
I0526 11:53:24.744189 15394 main.cpp:354] Iteration 47200, loss = 0.261638
I0526 11:53:24.744225 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.261638 (* 1 = 0.261638 loss)
I0526 11:53:24.744232 15394 sgd_solver.cpp:43] Iteration 47200, lr = 0.002
I0526 11:53:30.039908 15394 main.cpp:354] Iteration 47210, loss = 0.231694
I0526 11:53:30.039948 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.231694 (* 1 = 0.231694 loss)
I0526 11:53:30.039954 15394 sgd_solver.cpp:43] Iteration 47210, lr = 0.002
I0526 11:53:35.579455 15394 main.cpp:354] Iteration 47220, loss = 0.183961
I0526 11:53:35.579499 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.183961 (* 1 = 0.183961 loss)
I0526 11:53:35.579504 15394 sgd_solver.cpp:43] Iteration 47220, lr = 0.002
I0526 11:53:40.561266 15394 main.cpp:354] Iteration 47230, loss = 0.228634
I0526 11:53:40.561305 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.228633 (* 1 = 0.228633 loss)
I0526 11:53:40.561311 15394 sgd_solver.cpp:43] Iteration 47230, lr = 0.002
I0526 11:53:45.843418 15394 main.cpp:354] Iteration 47240, loss = 0.176773
I0526 11:53:45.843458 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.176773 (* 1 = 0.176773 loss)
I0526 11:53:45.843466 15394 sgd_solver.cpp:43] Iteration 47240, lr = 0.002
I0526 11:53:51.069059 15394 main.cpp:354] Iteration 47250, loss = 0.18282
I0526 11:53:51.069100 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.182819 (* 1 = 0.182819 loss)
I0526 11:53:51.069106 15394 sgd_solver.cpp:43] Iteration 47250, lr = 0.002
I0526 11:53:56.381276 15394 main.cpp:354] Iteration 47260, loss = 0.17412
I0526 11:53:56.381315 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.17412 (* 1 = 0.17412 loss)
I0526 11:53:56.381321 15394 sgd_solver.cpp:43] Iteration 47260, lr = 0.002
I0526 11:54:01.395231 15394 main.cpp:354] Iteration 47270, loss = 0.282381
I0526 11:54:01.395269 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.28238 (* 1 = 0.28238 loss)
I0526 11:54:01.395275 15394 sgd_solver.cpp:43] Iteration 47270, lr = 0.002
I0526 11:54:06.012372 15394 main.cpp:354] Iteration 47280, loss = 0.302511
I0526 11:54:06.012413 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.302511 (* 1 = 0.302511 loss)
I0526 11:54:06.012419 15394 sgd_solver.cpp:43] Iteration 47280, lr = 0.002
I0526 11:54:11.004350 15394 main.cpp:354] Iteration 47290, loss = 0.123526
I0526 11:54:11.004390 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.123526 (* 1 = 0.123526 loss)
I0526 11:54:11.004396 15394 sgd_solver.cpp:43] Iteration 47290, lr = 0.002
I0526 11:54:15.065842 15394 main.cpp:465] Iteration 47300, Testing net (#0)
I0526 11:54:28.158905 15394 main.cpp:532]     Test net output #0: Accuracy = 0.893
I0526 11:54:28.158947 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.332948 (* 1 = 0.332948 loss)
I0526 11:54:28.661919 15394 main.cpp:354] Iteration 47300, loss = 0.138349
I0526 11:54:28.661957 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.138349 (* 1 = 0.138349 loss)
I0526 11:54:28.661965 15394 sgd_solver.cpp:43] Iteration 47300, lr = 0.002
I0526 11:54:33.606894 15394 main.cpp:354] Iteration 47310, loss = 0.200332
I0526 11:54:33.606936 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.200332 (* 1 = 0.200332 loss)
I0526 11:54:33.606943 15394 sgd_solver.cpp:43] Iteration 47310, lr = 0.002
I0526 11:54:38.049080 15394 main.cpp:354] Iteration 47320, loss = 0.249817
I0526 11:54:38.049119 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.249816 (* 1 = 0.249816 loss)
I0526 11:54:38.049126 15394 sgd_solver.cpp:43] Iteration 47320, lr = 0.002
I0526 11:54:43.076772 15394 main.cpp:354] Iteration 47330, loss = 0.242553
I0526 11:54:43.076812 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.242553 (* 1 = 0.242553 loss)
I0526 11:54:43.076817 15394 sgd_solver.cpp:43] Iteration 47330, lr = 0.002
I0526 11:54:47.725411 15394 main.cpp:354] Iteration 47340, loss = 0.338613
I0526 11:54:47.725460 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.338613 (* 1 = 0.338613 loss)
I0526 11:54:47.725466 15394 sgd_solver.cpp:43] Iteration 47340, lr = 0.002
I0526 11:54:52.493307 15394 main.cpp:354] Iteration 47350, loss = 0.156673
I0526 11:54:52.493345 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.156673 (* 1 = 0.156673 loss)
I0526 11:54:52.493352 15394 sgd_solver.cpp:43] Iteration 47350, lr = 0.002
I0526 11:54:57.381947 15394 main.cpp:354] Iteration 47360, loss = 0.187327
I0526 11:54:57.381989 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187327 (* 1 = 0.187327 loss)
I0526 11:54:57.381995 15394 sgd_solver.cpp:43] Iteration 47360, lr = 0.002
I0526 11:55:02.293086 15394 main.cpp:354] Iteration 47370, loss = 0.498897
I0526 11:55:02.293128 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.498896 (* 1 = 0.498896 loss)
I0526 11:55:02.293133 15394 sgd_solver.cpp:43] Iteration 47370, lr = 0.002
I0526 11:55:07.584602 15394 main.cpp:354] Iteration 47380, loss = 0.169025
I0526 11:55:07.584643 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.169025 (* 1 = 0.169025 loss)
I0526 11:55:07.584650 15394 sgd_solver.cpp:43] Iteration 47380, lr = 0.002
I0526 11:55:13.091521 15394 main.cpp:354] Iteration 47390, loss = 0.128874
I0526 11:55:13.091544 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.128874 (* 1 = 0.128874 loss)
I0526 11:55:13.091550 15394 sgd_solver.cpp:43] Iteration 47390, lr = 0.002
I0526 11:55:17.511348 15394 main.cpp:465] Iteration 47400, Testing net (#0)
I0526 11:55:30.592097 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8925
I0526 11:55:30.592136 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.341811 (* 1 = 0.341811 loss)
I0526 11:55:30.985743 15394 main.cpp:354] Iteration 47400, loss = 0.448472
I0526 11:55:30.985780 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.448471 (* 1 = 0.448471 loss)
I0526 11:55:30.985787 15394 sgd_solver.cpp:43] Iteration 47400, lr = 0.002
I0526 11:55:36.154736 15394 main.cpp:354] Iteration 47410, loss = 0.478124
I0526 11:55:36.154779 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.478123 (* 1 = 0.478123 loss)
I0526 11:55:36.154786 15394 sgd_solver.cpp:43] Iteration 47410, lr = 0.002
I0526 11:55:41.398461 15394 main.cpp:354] Iteration 47420, loss = 0.283815
I0526 11:55:41.398502 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.283815 (* 1 = 0.283815 loss)
I0526 11:55:41.398510 15394 sgd_solver.cpp:43] Iteration 47420, lr = 0.002
I0526 11:55:46.620240 15394 main.cpp:354] Iteration 47430, loss = 0.149378
I0526 11:55:46.620280 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.149378 (* 1 = 0.149378 loss)
I0526 11:55:46.620287 15394 sgd_solver.cpp:43] Iteration 47430, lr = 0.002
I0526 11:55:51.434384 15394 main.cpp:354] Iteration 47440, loss = 0.799352
I0526 11:55:51.434424 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.799351 (* 1 = 0.799351 loss)
I0526 11:55:51.434432 15394 sgd_solver.cpp:43] Iteration 47440, lr = 0.002
I0526 11:55:55.809140 15394 main.cpp:354] Iteration 47450, loss = 0.361466
I0526 11:55:55.809193 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.361466 (* 1 = 0.361466 loss)
I0526 11:55:55.809201 15394 sgd_solver.cpp:43] Iteration 47450, lr = 0.002
I0526 11:56:00.901199 15394 main.cpp:354] Iteration 47460, loss = 0.151308
I0526 11:56:00.901237 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.151307 (* 1 = 0.151307 loss)
I0526 11:56:00.901242 15394 sgd_solver.cpp:43] Iteration 47460, lr = 0.002
I0526 11:56:05.181517 15394 main.cpp:354] Iteration 47470, loss = 0.288133
I0526 11:56:05.181560 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.288132 (* 1 = 0.288132 loss)
I0526 11:56:05.181566 15394 sgd_solver.cpp:43] Iteration 47470, lr = 0.002
I0526 11:56:10.315340 15394 main.cpp:354] Iteration 47480, loss = 0.252347
I0526 11:56:10.315373 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.252347 (* 1 = 0.252347 loss)
I0526 11:56:10.315387 15394 sgd_solver.cpp:43] Iteration 47480, lr = 0.002
I0526 11:56:15.591578 15394 main.cpp:354] Iteration 47490, loss = 0.30918
I0526 11:56:15.591617 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.30918 (* 1 = 0.30918 loss)
I0526 11:56:15.591624 15394 sgd_solver.cpp:43] Iteration 47490, lr = 0.002
I0526 11:56:20.040019 15394 main.cpp:465] Iteration 47500, Testing net (#0)
I0526 11:56:33.129942 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8889
I0526 11:56:33.129981 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.362536 (* 1 = 0.362536 loss)
I0526 11:56:33.674409 15394 main.cpp:354] Iteration 47500, loss = 0.233889
I0526 11:56:33.674446 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.233889 (* 1 = 0.233889 loss)
I0526 11:56:33.674454 15394 sgd_solver.cpp:43] Iteration 47500, lr = 0.002
I0526 11:56:38.955971 15394 main.cpp:354] Iteration 47510, loss = 0.321808
I0526 11:56:38.956009 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.321808 (* 1 = 0.321808 loss)
I0526 11:56:38.956017 15394 sgd_solver.cpp:43] Iteration 47510, lr = 0.002
I0526 11:56:43.808966 15394 main.cpp:354] Iteration 47520, loss = 0.208129
I0526 11:56:43.809007 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.208129 (* 1 = 0.208129 loss)
I0526 11:56:43.809015 15394 sgd_solver.cpp:43] Iteration 47520, lr = 0.002
I0526 11:56:48.815976 15394 main.cpp:354] Iteration 47530, loss = 0.325376
I0526 11:56:48.816022 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.325375 (* 1 = 0.325375 loss)
I0526 11:56:48.816030 15394 sgd_solver.cpp:43] Iteration 47530, lr = 0.002
I0526 11:56:53.834373 15394 main.cpp:354] Iteration 47540, loss = 0.194908
I0526 11:56:53.834414 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.194907 (* 1 = 0.194907 loss)
I0526 11:56:53.834419 15394 sgd_solver.cpp:43] Iteration 47540, lr = 0.002
I0526 11:56:58.820395 15394 main.cpp:354] Iteration 47550, loss = 0.337522
I0526 11:56:58.820435 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.337521 (* 1 = 0.337521 loss)
I0526 11:56:58.820441 15394 sgd_solver.cpp:43] Iteration 47550, lr = 0.002
I0526 11:57:04.037660 15394 main.cpp:354] Iteration 47560, loss = 0.144583
I0526 11:57:04.037703 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.144582 (* 1 = 0.144582 loss)
I0526 11:57:04.037709 15394 sgd_solver.cpp:43] Iteration 47560, lr = 0.002
I0526 11:57:09.381326 15394 main.cpp:354] Iteration 47570, loss = 0.34363
I0526 11:57:09.381366 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.34363 (* 1 = 0.34363 loss)
I0526 11:57:09.381371 15394 sgd_solver.cpp:43] Iteration 47570, lr = 0.002
I0526 11:57:14.499274 15394 main.cpp:354] Iteration 47580, loss = 0.208011
I0526 11:57:14.499313 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.208011 (* 1 = 0.208011 loss)
I0526 11:57:14.499320 15394 sgd_solver.cpp:43] Iteration 47580, lr = 0.002
I0526 11:57:19.341766 15394 main.cpp:354] Iteration 47590, loss = 0.324276
I0526 11:57:19.341802 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.324275 (* 1 = 0.324275 loss)
I0526 11:57:19.341809 15394 sgd_solver.cpp:43] Iteration 47590, lr = 0.002
I0526 11:57:23.953435 15394 main.cpp:465] Iteration 47600, Testing net (#0)
I0526 11:57:37.046120 15394 main.cpp:532]     Test net output #0: Accuracy = 0.888
I0526 11:57:37.046159 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.363327 (* 1 = 0.363327 loss)
I0526 11:57:37.516769 15394 main.cpp:354] Iteration 47600, loss = 0.180084
I0526 11:57:37.516793 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.180084 (* 1 = 0.180084 loss)
I0526 11:57:37.516800 15394 sgd_solver.cpp:43] Iteration 47600, lr = 0.002
I0526 11:57:42.586215 15394 main.cpp:354] Iteration 47610, loss = 0.224826
I0526 11:57:42.586256 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.224826 (* 1 = 0.224826 loss)
I0526 11:57:42.586261 15394 sgd_solver.cpp:43] Iteration 47610, lr = 0.002
I0526 11:57:47.845031 15394 main.cpp:354] Iteration 47620, loss = 0.168542
I0526 11:57:47.845074 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.168542 (* 1 = 0.168542 loss)
I0526 11:57:47.845082 15394 sgd_solver.cpp:43] Iteration 47620, lr = 0.002
I0526 11:57:53.075045 15394 main.cpp:354] Iteration 47630, loss = 0.108211
I0526 11:57:53.075085 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.10821 (* 1 = 0.10821 loss)
I0526 11:57:53.075093 15394 sgd_solver.cpp:43] Iteration 47630, lr = 0.002
I0526 11:57:58.175513 15394 main.cpp:354] Iteration 47640, loss = 0.135854
I0526 11:57:58.175554 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.135854 (* 1 = 0.135854 loss)
I0526 11:57:58.175560 15394 sgd_solver.cpp:43] Iteration 47640, lr = 0.002
I0526 11:58:02.984071 15394 main.cpp:354] Iteration 47650, loss = 0.401366
I0526 11:58:02.984114 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.401365 (* 1 = 0.401365 loss)
I0526 11:58:02.984122 15394 sgd_solver.cpp:43] Iteration 47650, lr = 0.002
I0526 11:58:08.070194 15394 main.cpp:354] Iteration 47660, loss = 0.133752
I0526 11:58:08.070232 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.133752 (* 1 = 0.133752 loss)
I0526 11:58:08.070240 15394 sgd_solver.cpp:43] Iteration 47660, lr = 0.002
I0526 11:58:13.244959 15394 main.cpp:354] Iteration 47670, loss = 0.217389
I0526 11:58:13.244999 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.217389 (* 1 = 0.217389 loss)
I0526 11:58:13.245007 15394 sgd_solver.cpp:43] Iteration 47670, lr = 0.002
I0526 11:58:18.033432 15394 main.cpp:354] Iteration 47680, loss = 0.225263
I0526 11:58:18.033475 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.225262 (* 1 = 0.225262 loss)
I0526 11:58:18.033481 15394 sgd_solver.cpp:43] Iteration 47680, lr = 0.002
I0526 11:58:23.197945 15394 main.cpp:354] Iteration 47690, loss = 0.167762
I0526 11:58:23.197983 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.167762 (* 1 = 0.167762 loss)
I0526 11:58:23.197990 15394 sgd_solver.cpp:43] Iteration 47690, lr = 0.002
I0526 11:58:27.911188 15394 main.cpp:465] Iteration 47700, Testing net (#0)
I0526 11:58:59.973875 15394 main.cpp:532]     Test net output #0: Accuracy = 0.888
I0526 11:58:59.973917 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.355636 (* 1 = 0.355636 loss)
I0526 11:59:01.109637 15394 main.cpp:354] Iteration 47700, loss = 0.14949
I0526 11:59:01.109675 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.149489 (* 1 = 0.149489 loss)
I0526 11:59:01.109683 15394 sgd_solver.cpp:43] Iteration 47700, lr = 0.002
I0526 11:59:13.078400 15394 main.cpp:354] Iteration 47710, loss = 0.414687
I0526 11:59:13.078445 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.414686 (* 1 = 0.414686 loss)
I0526 11:59:13.078452 15394 sgd_solver.cpp:43] Iteration 47710, lr = 0.002
I0526 11:59:25.649076 15394 main.cpp:354] Iteration 47720, loss = 0.474388
I0526 11:59:25.649107 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.474388 (* 1 = 0.474388 loss)
I0526 11:59:25.649114 15394 sgd_solver.cpp:43] Iteration 47720, lr = 0.002
I0526 11:59:37.680727 15394 main.cpp:354] Iteration 47730, loss = 0.157871
I0526 11:59:37.680773 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.15787 (* 1 = 0.15787 loss)
I0526 11:59:37.680779 15394 sgd_solver.cpp:43] Iteration 47730, lr = 0.002
I0526 11:59:50.499198 15394 main.cpp:354] Iteration 47740, loss = 0.271637
I0526 11:59:50.499241 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.271637 (* 1 = 0.271637 loss)
I0526 11:59:50.499248 15394 sgd_solver.cpp:43] Iteration 47740, lr = 0.002
I0526 12:00:02.511896 15394 main.cpp:354] Iteration 47750, loss = 0.107707
I0526 12:00:02.511940 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.107707 (* 1 = 0.107707 loss)
I0526 12:00:02.511947 15394 sgd_solver.cpp:43] Iteration 47750, lr = 0.002
I0526 12:00:14.549509 15394 main.cpp:354] Iteration 47760, loss = 0.345969
I0526 12:00:14.549553 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.345969 (* 1 = 0.345969 loss)
I0526 12:00:14.549561 15394 sgd_solver.cpp:43] Iteration 47760, lr = 0.002
I0526 12:00:27.482802 15394 main.cpp:354] Iteration 47770, loss = 0.162771
I0526 12:00:27.482847 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.162771 (* 1 = 0.162771 loss)
I0526 12:00:27.482854 15394 sgd_solver.cpp:43] Iteration 47770, lr = 0.002
I0526 12:00:40.543303 15394 main.cpp:354] Iteration 47780, loss = 0.149373
I0526 12:00:40.543347 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.149373 (* 1 = 0.149373 loss)
I0526 12:00:40.543354 15394 sgd_solver.cpp:43] Iteration 47780, lr = 0.002
I0526 12:00:51.647025 15394 main.cpp:354] Iteration 47790, loss = 0.240546
I0526 12:00:51.647071 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.240545 (* 1 = 0.240545 loss)
I0526 12:00:51.647078 15394 sgd_solver.cpp:43] Iteration 47790, lr = 0.002
I0526 12:01:03.183280 15394 main.cpp:465] Iteration 47800, Testing net (#0)
I0526 12:01:36.496656 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8898
I0526 12:01:36.496700 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.347492 (* 1 = 0.347492 loss)
I0526 12:01:37.500108 15394 main.cpp:354] Iteration 47800, loss = 0.317564
I0526 12:01:37.500144 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.317564 (* 1 = 0.317564 loss)
I0526 12:01:37.500151 15394 sgd_solver.cpp:43] Iteration 47800, lr = 0.002
I0526 12:01:50.531893 15394 main.cpp:354] Iteration 47810, loss = 0.103449
I0526 12:01:50.531924 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.103449 (* 1 = 0.103449 loss)
I0526 12:01:50.531931 15394 sgd_solver.cpp:43] Iteration 47810, lr = 0.002
I0526 12:02:01.866801 15394 main.cpp:354] Iteration 47820, loss = 0.349399
I0526 12:02:01.866840 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.349398 (* 1 = 0.349398 loss)
I0526 12:02:01.866848 15394 sgd_solver.cpp:43] Iteration 47820, lr = 0.002
I0526 12:02:14.329010 15394 main.cpp:354] Iteration 47830, loss = 0.120145
I0526 12:02:14.329051 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.120145 (* 1 = 0.120145 loss)
I0526 12:02:14.329058 15394 sgd_solver.cpp:43] Iteration 47830, lr = 0.002
I0526 12:02:26.461158 15394 main.cpp:354] Iteration 47840, loss = 0.176311
I0526 12:02:26.461199 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.176311 (* 1 = 0.176311 loss)
I0526 12:02:26.461205 15394 sgd_solver.cpp:43] Iteration 47840, lr = 0.002
I0526 12:02:38.188058 15394 main.cpp:354] Iteration 47850, loss = 0.283724
I0526 12:02:38.188108 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.283724 (* 1 = 0.283724 loss)
I0526 12:02:38.188115 15394 sgd_solver.cpp:43] Iteration 47850, lr = 0.002
I0526 12:02:50.700307 15394 main.cpp:354] Iteration 47860, loss = 0.693931
I0526 12:02:50.700352 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.693931 (* 1 = 0.693931 loss)
I0526 12:02:50.700359 15394 sgd_solver.cpp:43] Iteration 47860, lr = 0.002
I0526 12:03:03.813431 15394 main.cpp:354] Iteration 47870, loss = 0.188505
I0526 12:03:03.813477 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.188505 (* 1 = 0.188505 loss)
I0526 12:03:03.813484 15394 sgd_solver.cpp:43] Iteration 47870, lr = 0.002
I0526 12:03:16.559165 15394 main.cpp:354] Iteration 47880, loss = 0.192408
I0526 12:03:16.559206 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.192408 (* 1 = 0.192408 loss)
I0526 12:03:16.559213 15394 sgd_solver.cpp:43] Iteration 47880, lr = 0.002
I0526 12:03:28.838515 15394 main.cpp:354] Iteration 47890, loss = 0.154436
I0526 12:03:28.838559 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.154436 (* 1 = 0.154436 loss)
I0526 12:03:28.838567 15394 sgd_solver.cpp:43] Iteration 47890, lr = 0.002
I0526 12:03:40.030050 15394 main.cpp:465] Iteration 47900, Testing net (#0)
I0526 12:04:13.041820 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8917
I0526 12:04:13.041868 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.355545 (* 1 = 0.355545 loss)
I0526 12:04:14.243883 15394 main.cpp:354] Iteration 47900, loss = 0.19276
I0526 12:04:14.243929 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.19276 (* 1 = 0.19276 loss)
I0526 12:04:14.243938 15394 sgd_solver.cpp:43] Iteration 47900, lr = 0.002
I0526 12:04:26.964258 15394 main.cpp:354] Iteration 47910, loss = 0.204983
I0526 12:04:26.964303 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204983 (* 1 = 0.204983 loss)
I0526 12:04:26.964309 15394 sgd_solver.cpp:43] Iteration 47910, lr = 0.002
I0526 12:04:39.655282 15394 main.cpp:354] Iteration 47920, loss = 0.311
I0526 12:04:39.655325 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.310999 (* 1 = 0.310999 loss)
I0526 12:04:39.655331 15394 sgd_solver.cpp:43] Iteration 47920, lr = 0.002
I0526 12:04:51.776162 15394 main.cpp:354] Iteration 47930, loss = 0.248612
I0526 12:04:51.776211 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.248612 (* 1 = 0.248612 loss)
I0526 12:04:51.776217 15394 sgd_solver.cpp:43] Iteration 47930, lr = 0.002
I0526 12:05:03.287348 15394 main.cpp:354] Iteration 47940, loss = 0.154931
I0526 12:05:03.287405 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.154931 (* 1 = 0.154931 loss)
I0526 12:05:03.287417 15394 sgd_solver.cpp:43] Iteration 47940, lr = 0.002
I0526 12:05:15.935788 15394 main.cpp:354] Iteration 47950, loss = 0.319428
I0526 12:05:15.935828 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.319428 (* 1 = 0.319428 loss)
I0526 12:05:15.935834 15394 sgd_solver.cpp:43] Iteration 47950, lr = 0.002
I0526 12:05:28.146574 15394 main.cpp:354] Iteration 47960, loss = 0.335759
I0526 12:05:28.146623 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.335759 (* 1 = 0.335759 loss)
I0526 12:05:28.146631 15394 sgd_solver.cpp:43] Iteration 47960, lr = 0.002
I0526 12:05:40.201248 15394 main.cpp:354] Iteration 47970, loss = 0.106523
I0526 12:05:40.201297 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.106523 (* 1 = 0.106523 loss)
I0526 12:05:40.201304 15394 sgd_solver.cpp:43] Iteration 47970, lr = 0.002
I0526 12:05:52.867827 15394 main.cpp:354] Iteration 47980, loss = 0.24942
I0526 12:05:52.867887 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.24942 (* 1 = 0.24942 loss)
I0526 12:05:52.867895 15394 sgd_solver.cpp:43] Iteration 47980, lr = 0.002
I0526 12:06:05.331885 15394 main.cpp:354] Iteration 47990, loss = 0.969072
I0526 12:06:05.331936 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.969072 (* 1 = 0.969072 loss)
I0526 12:06:05.331945 15394 sgd_solver.cpp:43] Iteration 47990, lr = 0.002
I0526 12:06:16.243963 15394 main.cpp:465] Iteration 48000, Testing net (#0)
I0526 12:06:49.012262 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8904
I0526 12:06:49.012305 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.355153 (* 1 = 0.355153 loss)
I0526 12:06:50.026135 15394 main.cpp:354] Iteration 48000, loss = 0.240407
I0526 12:06:50.026185 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.240407 (* 1 = 0.240407 loss)
I0526 12:06:50.026193 15394 sgd_solver.cpp:234] MultiStep Status: Iteration 48000, step = 2
I0526 12:06:50.026197 15394 sgd_solver.cpp:43] Iteration 48000, lr = 0.0002
I0526 12:07:02.999861 15394 main.cpp:354] Iteration 48010, loss = 0.205331
I0526 12:07:02.999907 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.205331 (* 1 = 0.205331 loss)
I0526 12:07:02.999915 15394 sgd_solver.cpp:43] Iteration 48010, lr = 0.0002
I0526 12:07:14.571164 15394 main.cpp:354] Iteration 48020, loss = 0.221403
I0526 12:07:14.571220 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.221403 (* 1 = 0.221403 loss)
I0526 12:07:14.571229 15394 sgd_solver.cpp:43] Iteration 48020, lr = 0.0002
I0526 12:07:27.110606 15394 main.cpp:354] Iteration 48030, loss = 0.18162
I0526 12:07:27.110658 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.181619 (* 1 = 0.181619 loss)
I0526 12:07:27.110672 15394 sgd_solver.cpp:43] Iteration 48030, lr = 0.0002
I0526 12:07:39.049511 15394 main.cpp:354] Iteration 48040, loss = 0.211848
I0526 12:07:39.049561 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.211848 (* 1 = 0.211848 loss)
I0526 12:07:39.049568 15394 sgd_solver.cpp:43] Iteration 48040, lr = 0.0002
I0526 12:07:51.586552 15394 main.cpp:354] Iteration 48050, loss = 0.0920763
I0526 12:07:51.586611 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.092076 (* 1 = 0.092076 loss)
I0526 12:07:51.586619 15394 sgd_solver.cpp:43] Iteration 48050, lr = 0.0002
I0526 12:08:03.888671 15394 main.cpp:354] Iteration 48060, loss = 0.692157
I0526 12:08:03.888723 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.692157 (* 1 = 0.692157 loss)
I0526 12:08:03.888731 15394 sgd_solver.cpp:43] Iteration 48060, lr = 0.0002
I0526 12:08:15.358105 15394 main.cpp:354] Iteration 48070, loss = 0.246519
I0526 12:08:15.358152 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.246519 (* 1 = 0.246519 loss)
I0526 12:08:15.358161 15394 sgd_solver.cpp:43] Iteration 48070, lr = 0.0002
I0526 12:08:28.998095 15394 main.cpp:354] Iteration 48080, loss = 0.206395
I0526 12:08:28.998139 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206394 (* 1 = 0.206394 loss)
I0526 12:08:28.998147 15394 sgd_solver.cpp:43] Iteration 48080, lr = 0.0002
I0526 12:08:41.773277 15394 main.cpp:354] Iteration 48090, loss = 0.249613
I0526 12:08:41.773327 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.249612 (* 1 = 0.249612 loss)
I0526 12:08:41.773335 15394 sgd_solver.cpp:43] Iteration 48090, lr = 0.0002
I0526 12:08:52.782832 15394 main.cpp:465] Iteration 48100, Testing net (#0)
I0526 12:09:25.581475 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8894
I0526 12:09:25.581519 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.347422 (* 1 = 0.347422 loss)
I0526 12:09:26.648936 15394 main.cpp:354] Iteration 48100, loss = 0.25623
I0526 12:09:26.648970 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.25623 (* 1 = 0.25623 loss)
I0526 12:09:26.648978 15394 sgd_solver.cpp:43] Iteration 48100, lr = 0.0002
I0526 12:09:39.534905 15394 main.cpp:354] Iteration 48110, loss = 0.180655
I0526 12:09:39.534940 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.180654 (* 1 = 0.180654 loss)
I0526 12:09:39.534947 15394 sgd_solver.cpp:43] Iteration 48110, lr = 0.0002
I0526 12:09:52.416347 15394 main.cpp:354] Iteration 48120, loss = 0.149017
I0526 12:09:52.416388 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.149017 (* 1 = 0.149017 loss)
I0526 12:09:52.416396 15394 sgd_solver.cpp:43] Iteration 48120, lr = 0.0002
I0526 12:10:04.467047 15394 main.cpp:354] Iteration 48130, loss = 0.352607
I0526 12:10:04.467077 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.352607 (* 1 = 0.352607 loss)
I0526 12:10:04.467084 15394 sgd_solver.cpp:43] Iteration 48130, lr = 0.0002
I0526 12:10:17.482957 15394 main.cpp:354] Iteration 48140, loss = 0.141566
I0526 12:10:17.482997 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.141565 (* 1 = 0.141565 loss)
I0526 12:10:17.483005 15394 sgd_solver.cpp:43] Iteration 48140, lr = 0.0002
I0526 12:10:30.235355 15394 main.cpp:354] Iteration 48150, loss = 0.342569
I0526 12:10:30.235396 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.342569 (* 1 = 0.342569 loss)
I0526 12:10:30.235404 15394 sgd_solver.cpp:43] Iteration 48150, lr = 0.0002
I0526 12:10:42.519232 15394 main.cpp:354] Iteration 48160, loss = 0.276148
I0526 12:10:42.519263 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.276147 (* 1 = 0.276147 loss)
I0526 12:10:42.519270 15394 sgd_solver.cpp:43] Iteration 48160, lr = 0.0002
I0526 12:10:54.496234 15394 main.cpp:354] Iteration 48170, loss = 0.117194
I0526 12:10:54.496289 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.117194 (* 1 = 0.117194 loss)
I0526 12:10:54.496300 15394 sgd_solver.cpp:43] Iteration 48170, lr = 0.0002
I0526 12:11:06.231688 15394 main.cpp:354] Iteration 48180, loss = 0.373392
I0526 12:11:06.231731 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.373392 (* 1 = 0.373392 loss)
I0526 12:11:06.231739 15394 sgd_solver.cpp:43] Iteration 48180, lr = 0.0002
I0526 12:11:19.271288 15394 main.cpp:354] Iteration 48190, loss = 0.184007
I0526 12:11:19.271332 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.184006 (* 1 = 0.184006 loss)
I0526 12:11:19.271339 15394 sgd_solver.cpp:43] Iteration 48190, lr = 0.0002
I0526 12:11:31.109099 15394 main.cpp:465] Iteration 48200, Testing net (#0)
I0526 12:12:04.615211 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8905
I0526 12:12:04.615247 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.341543 (* 1 = 0.341543 loss)
I0526 12:12:05.799480 15394 main.cpp:354] Iteration 48200, loss = 0.141973
I0526 12:12:05.799523 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.141972 (* 1 = 0.141972 loss)
I0526 12:12:05.799531 15394 sgd_solver.cpp:43] Iteration 48200, lr = 0.0002
I0526 12:12:18.400691 15394 main.cpp:354] Iteration 48210, loss = 0.140452
I0526 12:12:18.400734 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.140452 (* 1 = 0.140452 loss)
I0526 12:12:18.400741 15394 sgd_solver.cpp:43] Iteration 48210, lr = 0.0002
I0526 12:12:29.823483 15394 main.cpp:354] Iteration 48220, loss = 0.0838427
I0526 12:12:29.823514 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0838423 (* 1 = 0.0838423 loss)
I0526 12:12:29.823520 15394 sgd_solver.cpp:43] Iteration 48220, lr = 0.0002
I0526 12:12:41.578979 15394 main.cpp:354] Iteration 48230, loss = 0.239096
I0526 12:12:41.579025 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.239096 (* 1 = 0.239096 loss)
I0526 12:12:41.579032 15394 sgd_solver.cpp:43] Iteration 48230, lr = 0.0002
I0526 12:12:54.507586 15394 main.cpp:354] Iteration 48240, loss = 0.244902
I0526 12:12:54.507630 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.244902 (* 1 = 0.244902 loss)
I0526 12:12:54.507637 15394 sgd_solver.cpp:43] Iteration 48240, lr = 0.0002
I0526 12:13:06.943918 15394 main.cpp:354] Iteration 48250, loss = 0.13238
I0526 12:13:06.943963 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.13238 (* 1 = 0.13238 loss)
I0526 12:13:06.943970 15394 sgd_solver.cpp:43] Iteration 48250, lr = 0.0002
I0526 12:13:19.607301 15394 main.cpp:354] Iteration 48260, loss = 0.111125
I0526 12:13:19.607348 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.111125 (* 1 = 0.111125 loss)
I0526 12:13:19.607355 15394 sgd_solver.cpp:43] Iteration 48260, lr = 0.0002
I0526 12:13:31.679780 15394 main.cpp:354] Iteration 48270, loss = 0.147981
I0526 12:13:31.679821 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.147981 (* 1 = 0.147981 loss)
I0526 12:13:31.679827 15394 sgd_solver.cpp:43] Iteration 48270, lr = 0.0002
I0526 12:13:44.347674 15394 main.cpp:354] Iteration 48280, loss = 0.090356
I0526 12:13:44.347718 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0903557 (* 1 = 0.0903557 loss)
I0526 12:13:44.347723 15394 sgd_solver.cpp:43] Iteration 48280, lr = 0.0002
I0526 12:13:56.711239 15394 main.cpp:354] Iteration 48290, loss = 0.404642
I0526 12:13:56.711282 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.404641 (* 1 = 0.404641 loss)
I0526 12:13:56.711288 15394 sgd_solver.cpp:43] Iteration 48290, lr = 0.0002
I0526 12:14:08.074928 15394 main.cpp:465] Iteration 48300, Testing net (#0)
I0526 12:14:41.426091 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8919
I0526 12:14:41.426132 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.34123 (* 1 = 0.34123 loss)
I0526 12:14:42.804689 15394 main.cpp:354] Iteration 48300, loss = 0.143592
I0526 12:14:42.804729 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.143592 (* 1 = 0.143592 loss)
I0526 12:14:42.804738 15394 sgd_solver.cpp:43] Iteration 48300, lr = 0.0002
I0526 12:14:55.135473 15394 main.cpp:354] Iteration 48310, loss = 0.254963
I0526 12:14:55.135509 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.254962 (* 1 = 0.254962 loss)
I0526 12:14:55.135516 15394 sgd_solver.cpp:43] Iteration 48310, lr = 0.0002
I0526 12:15:07.559963 15394 main.cpp:354] Iteration 48320, loss = 0.300686
I0526 12:15:07.559994 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.300686 (* 1 = 0.300686 loss)
I0526 12:15:07.560003 15394 sgd_solver.cpp:43] Iteration 48320, lr = 0.0002
I0526 12:15:20.858173 15394 main.cpp:354] Iteration 48330, loss = 0.122358
I0526 12:15:20.858216 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.122358 (* 1 = 0.122358 loss)
I0526 12:15:20.858222 15394 sgd_solver.cpp:43] Iteration 48330, lr = 0.0002
I0526 12:15:32.907470 15394 main.cpp:354] Iteration 48340, loss = 0.15754
I0526 12:15:32.907513 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.15754 (* 1 = 0.15754 loss)
I0526 12:15:32.907524 15394 sgd_solver.cpp:43] Iteration 48340, lr = 0.0002
I0526 12:15:45.579285 15394 main.cpp:354] Iteration 48350, loss = 0.170814
I0526 12:15:45.579315 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.170814 (* 1 = 0.170814 loss)
I0526 12:15:45.579324 15394 sgd_solver.cpp:43] Iteration 48350, lr = 0.0002
I0526 12:15:58.069109 15394 main.cpp:354] Iteration 48360, loss = 0.142868
I0526 12:15:58.069154 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.142867 (* 1 = 0.142867 loss)
I0526 12:15:58.069162 15394 sgd_solver.cpp:43] Iteration 48360, lr = 0.0002
I0526 12:16:09.995998 15394 main.cpp:354] Iteration 48370, loss = 0.347559
I0526 12:16:09.996042 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.347559 (* 1 = 0.347559 loss)
I0526 12:16:09.996049 15394 sgd_solver.cpp:43] Iteration 48370, lr = 0.0002
I0526 12:16:22.723083 15394 main.cpp:354] Iteration 48380, loss = 0.0736695
I0526 12:16:22.723129 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0736691 (* 1 = 0.0736691 loss)
I0526 12:16:22.723135 15394 sgd_solver.cpp:43] Iteration 48380, lr = 0.0002
I0526 12:16:35.957178 15394 main.cpp:354] Iteration 48390, loss = 0.192672
I0526 12:16:35.957222 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.192672 (* 1 = 0.192672 loss)
I0526 12:16:35.957229 15394 sgd_solver.cpp:43] Iteration 48390, lr = 0.0002
I0526 12:16:47.430387 15394 main.cpp:465] Iteration 48400, Testing net (#0)
I0526 12:17:20.823755 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8948
I0526 12:17:20.823789 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.332161 (* 1 = 0.332161 loss)
I0526 12:17:21.955379 15394 main.cpp:354] Iteration 48400, loss = 0.22328
I0526 12:17:21.955433 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.223279 (* 1 = 0.223279 loss)
I0526 12:17:21.955441 15394 sgd_solver.cpp:43] Iteration 48400, lr = 0.0002
I0526 12:17:34.560715 15394 main.cpp:354] Iteration 48410, loss = 0.618759
I0526 12:17:34.560758 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.618759 (* 1 = 0.618759 loss)
I0526 12:17:34.560765 15394 sgd_solver.cpp:43] Iteration 48410, lr = 0.0002
I0526 12:17:46.276924 15394 main.cpp:354] Iteration 48420, loss = 0.321369
I0526 12:17:46.276962 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.321369 (* 1 = 0.321369 loss)
I0526 12:17:46.276968 15394 sgd_solver.cpp:43] Iteration 48420, lr = 0.0002
I0526 12:17:59.250139 15394 main.cpp:354] Iteration 48430, loss = 0.121384
I0526 12:17:59.250180 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.121383 (* 1 = 0.121383 loss)
I0526 12:17:59.250188 15394 sgd_solver.cpp:43] Iteration 48430, lr = 0.0002
I0526 12:18:11.419749 15394 main.cpp:354] Iteration 48440, loss = 0.211924
I0526 12:18:11.419792 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.211923 (* 1 = 0.211923 loss)
I0526 12:18:11.419800 15394 sgd_solver.cpp:43] Iteration 48440, lr = 0.0002
I0526 12:18:23.277333 15394 main.cpp:354] Iteration 48450, loss = 0.309436
I0526 12:18:23.277384 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.309436 (* 1 = 0.309436 loss)
I0526 12:18:23.277390 15394 sgd_solver.cpp:43] Iteration 48450, lr = 0.0002
I0526 12:18:35.484078 15394 main.cpp:354] Iteration 48460, loss = 0.249719
I0526 12:18:35.484118 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.249718 (* 1 = 0.249718 loss)
I0526 12:18:35.484125 15394 sgd_solver.cpp:43] Iteration 48460, lr = 0.0002
I0526 12:18:48.748329 15394 main.cpp:354] Iteration 48470, loss = 0.204715
I0526 12:18:48.748373 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204714 (* 1 = 0.204714 loss)
I0526 12:18:48.748378 15394 sgd_solver.cpp:43] Iteration 48470, lr = 0.0002
I0526 12:19:00.584285 15394 main.cpp:354] Iteration 48480, loss = 0.233652
I0526 12:19:00.584326 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.233652 (* 1 = 0.233652 loss)
I0526 12:19:00.584331 15394 sgd_solver.cpp:43] Iteration 48480, lr = 0.0002
I0526 12:19:13.503156 15394 main.cpp:354] Iteration 48490, loss = 0.436852
I0526 12:19:13.503203 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.436852 (* 1 = 0.436852 loss)
I0526 12:19:13.503209 15394 sgd_solver.cpp:43] Iteration 48490, lr = 0.0002
I0526 12:19:24.672559 15394 main.cpp:465] Iteration 48500, Testing net (#0)
I0526 12:19:45.897990 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8941
I0526 12:19:45.898028 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.341355 (* 1 = 0.341355 loss)
I0526 12:19:46.370530 15394 main.cpp:354] Iteration 48500, loss = 0.260208
I0526 12:19:46.370554 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.260208 (* 1 = 0.260208 loss)
I0526 12:19:46.370563 15394 sgd_solver.cpp:43] Iteration 48500, lr = 0.0002
I0526 12:19:51.577713 15394 main.cpp:354] Iteration 48510, loss = 0.211262
I0526 12:19:51.577765 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.211262 (* 1 = 0.211262 loss)
I0526 12:19:51.577772 15394 sgd_solver.cpp:43] Iteration 48510, lr = 0.0002
I0526 12:19:56.360218 15394 main.cpp:354] Iteration 48520, loss = 0.354084
I0526 12:19:56.360255 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.354084 (* 1 = 0.354084 loss)
I0526 12:19:56.360262 15394 sgd_solver.cpp:43] Iteration 48520, lr = 0.0002
I0526 12:20:01.990118 15394 main.cpp:354] Iteration 48530, loss = 0.153095
I0526 12:20:01.990162 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.153094 (* 1 = 0.153094 loss)
I0526 12:20:01.990170 15394 sgd_solver.cpp:43] Iteration 48530, lr = 0.0002
I0526 12:20:06.742611 15394 main.cpp:354] Iteration 48540, loss = 0.175866
I0526 12:20:06.742652 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.175866 (* 1 = 0.175866 loss)
I0526 12:20:06.742660 15394 sgd_solver.cpp:43] Iteration 48540, lr = 0.0002
I0526 12:20:11.959288 15394 main.cpp:354] Iteration 48550, loss = 0.281055
I0526 12:20:11.959327 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.281055 (* 1 = 0.281055 loss)
I0526 12:20:11.959333 15394 sgd_solver.cpp:43] Iteration 48550, lr = 0.0002
I0526 12:20:16.974158 15394 main.cpp:354] Iteration 48560, loss = 0.429623
I0526 12:20:16.974211 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.429623 (* 1 = 0.429623 loss)
I0526 12:20:16.974220 15394 sgd_solver.cpp:43] Iteration 48560, lr = 0.0002
I0526 12:20:21.958071 15394 main.cpp:354] Iteration 48570, loss = 0.202974
I0526 12:20:21.958114 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.202974 (* 1 = 0.202974 loss)
I0526 12:20:21.958120 15394 sgd_solver.cpp:43] Iteration 48570, lr = 0.0002
I0526 12:20:27.673507 15394 main.cpp:354] Iteration 48580, loss = 0.256627
I0526 12:20:27.673547 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.256626 (* 1 = 0.256626 loss)
I0526 12:20:27.673552 15394 sgd_solver.cpp:43] Iteration 48580, lr = 0.0002
I0526 12:20:32.585551 15394 main.cpp:354] Iteration 48590, loss = 0.363555
I0526 12:20:32.585593 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.363555 (* 1 = 0.363555 loss)
I0526 12:20:32.585607 15394 sgd_solver.cpp:43] Iteration 48590, lr = 0.0002
I0526 12:20:37.184607 15394 main.cpp:465] Iteration 48600, Testing net (#0)
I0526 12:20:50.266430 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8931
I0526 12:20:50.266470 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.334777 (* 1 = 0.334777 loss)
I0526 12:20:50.774539 15394 main.cpp:354] Iteration 48600, loss = 0.180514
I0526 12:20:50.774576 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.180513 (* 1 = 0.180513 loss)
I0526 12:20:50.774583 15394 sgd_solver.cpp:43] Iteration 48600, lr = 0.0002
I0526 12:20:55.848892 15394 main.cpp:354] Iteration 48610, loss = 0.249622
I0526 12:20:55.848930 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.249622 (* 1 = 0.249622 loss)
I0526 12:20:55.848937 15394 sgd_solver.cpp:43] Iteration 48610, lr = 0.0002
I0526 12:21:00.901931 15394 main.cpp:354] Iteration 48620, loss = 0.229255
I0526 12:21:00.901970 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.229255 (* 1 = 0.229255 loss)
I0526 12:21:00.901978 15394 sgd_solver.cpp:43] Iteration 48620, lr = 0.0002
I0526 12:21:05.585870 15394 main.cpp:354] Iteration 48630, loss = 0.159673
I0526 12:21:05.585913 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.159673 (* 1 = 0.159673 loss)
I0526 12:21:05.585919 15394 sgd_solver.cpp:43] Iteration 48630, lr = 0.0002
I0526 12:21:10.456722 15394 main.cpp:354] Iteration 48640, loss = 0.253676
I0526 12:21:10.456759 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.253676 (* 1 = 0.253676 loss)
I0526 12:21:10.456766 15394 sgd_solver.cpp:43] Iteration 48640, lr = 0.0002
I0526 12:21:15.396033 15394 main.cpp:354] Iteration 48650, loss = 0.215287
I0526 12:21:15.396071 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.215287 (* 1 = 0.215287 loss)
I0526 12:21:15.396078 15394 sgd_solver.cpp:43] Iteration 48650, lr = 0.0002
I0526 12:21:20.326819 15394 main.cpp:354] Iteration 48660, loss = 0.217451
I0526 12:21:20.326864 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.217451 (* 1 = 0.217451 loss)
I0526 12:21:20.326870 15394 sgd_solver.cpp:43] Iteration 48660, lr = 0.0002
I0526 12:21:25.703395 15394 main.cpp:354] Iteration 48670, loss = 0.197494
I0526 12:21:25.703434 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.197494 (* 1 = 0.197494 loss)
I0526 12:21:25.703441 15394 sgd_solver.cpp:43] Iteration 48670, lr = 0.0002
I0526 12:21:30.997774 15394 main.cpp:354] Iteration 48680, loss = 0.273779
I0526 12:21:30.997817 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.273778 (* 1 = 0.273778 loss)
I0526 12:21:30.997823 15394 sgd_solver.cpp:43] Iteration 48680, lr = 0.0002
I0526 12:21:36.113859 15394 main.cpp:354] Iteration 48690, loss = 0.0876624
I0526 12:21:36.113900 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0876621 (* 1 = 0.0876621 loss)
I0526 12:21:36.113908 15394 sgd_solver.cpp:43] Iteration 48690, lr = 0.0002
I0526 12:21:40.626181 15394 main.cpp:465] Iteration 48700, Testing net (#0)
I0526 12:21:53.703680 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8936
I0526 12:21:53.703721 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.338909 (* 1 = 0.338909 loss)
I0526 12:21:54.103945 15394 main.cpp:354] Iteration 48700, loss = 0.279577
I0526 12:21:54.103986 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.279576 (* 1 = 0.279576 loss)
I0526 12:21:54.103996 15394 sgd_solver.cpp:43] Iteration 48700, lr = 0.0002
I0526 12:21:59.326472 15394 main.cpp:354] Iteration 48710, loss = 0.160391
I0526 12:21:59.326514 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.16039 (* 1 = 0.16039 loss)
I0526 12:21:59.326520 15394 sgd_solver.cpp:43] Iteration 48710, lr = 0.0002
I0526 12:22:04.489713 15394 main.cpp:354] Iteration 48720, loss = 0.0505738
I0526 12:22:04.489750 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0505735 (* 1 = 0.0505735 loss)
I0526 12:22:04.489763 15394 sgd_solver.cpp:43] Iteration 48720, lr = 0.0002
I0526 12:22:09.282569 15394 main.cpp:354] Iteration 48730, loss = 0.298671
I0526 12:22:09.282613 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.298671 (* 1 = 0.298671 loss)
I0526 12:22:09.282619 15394 sgd_solver.cpp:43] Iteration 48730, lr = 0.0002
I0526 12:22:14.436985 15394 main.cpp:354] Iteration 48740, loss = 0.193656
I0526 12:22:14.437026 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.193656 (* 1 = 0.193656 loss)
I0526 12:22:14.437033 15394 sgd_solver.cpp:43] Iteration 48740, lr = 0.0002
I0526 12:22:19.369140 15394 main.cpp:354] Iteration 48750, loss = 0.187453
I0526 12:22:19.369184 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187453 (* 1 = 0.187453 loss)
I0526 12:22:19.369189 15394 sgd_solver.cpp:43] Iteration 48750, lr = 0.0002
I0526 12:22:24.374445 15394 main.cpp:354] Iteration 48760, loss = 0.153493
I0526 12:22:24.374486 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.153492 (* 1 = 0.153492 loss)
I0526 12:22:24.374495 15394 sgd_solver.cpp:43] Iteration 48760, lr = 0.0002
I0526 12:22:29.582039 15394 main.cpp:354] Iteration 48770, loss = 0.098668
I0526 12:22:29.582079 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0986677 (* 1 = 0.0986677 loss)
I0526 12:22:29.582087 15394 sgd_solver.cpp:43] Iteration 48770, lr = 0.0002
I0526 12:22:34.820525 15394 main.cpp:354] Iteration 48780, loss = 0.117422
I0526 12:22:34.820566 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.117422 (* 1 = 0.117422 loss)
I0526 12:22:34.820574 15394 sgd_solver.cpp:43] Iteration 48780, lr = 0.0002
I0526 12:22:39.846567 15394 main.cpp:354] Iteration 48790, loss = 0.236785
I0526 12:22:39.846608 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.236785 (* 1 = 0.236785 loss)
I0526 12:22:39.846616 15394 sgd_solver.cpp:43] Iteration 48790, lr = 0.0002
I0526 12:22:44.369709 15394 main.cpp:465] Iteration 48800, Testing net (#0)
I0526 12:22:57.449436 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8941
I0526 12:22:57.449476 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.336776 (* 1 = 0.336776 loss)
I0526 12:22:57.952260 15394 main.cpp:354] Iteration 48800, loss = 0.215275
I0526 12:22:57.952296 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.215275 (* 1 = 0.215275 loss)
I0526 12:22:57.952303 15394 sgd_solver.cpp:43] Iteration 48800, lr = 0.0002
I0526 12:23:02.812314 15394 main.cpp:354] Iteration 48810, loss = 0.362942
I0526 12:23:02.812357 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.362941 (* 1 = 0.362941 loss)
I0526 12:23:02.812364 15394 sgd_solver.cpp:43] Iteration 48810, lr = 0.0002
I0526 12:23:07.929539 15394 main.cpp:354] Iteration 48820, loss = 0.140457
I0526 12:23:07.929580 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.140456 (* 1 = 0.140456 loss)
I0526 12:23:07.929587 15394 sgd_solver.cpp:43] Iteration 48820, lr = 0.0002
I0526 12:23:12.717002 15394 main.cpp:354] Iteration 48830, loss = 0.36479
I0526 12:23:12.717044 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.364789 (* 1 = 0.364789 loss)
I0526 12:23:12.717051 15394 sgd_solver.cpp:43] Iteration 48830, lr = 0.0002
I0526 12:23:17.858409 15394 main.cpp:354] Iteration 48840, loss = 0.289253
I0526 12:23:17.858455 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.289253 (* 1 = 0.289253 loss)
I0526 12:23:17.858463 15394 sgd_solver.cpp:43] Iteration 48840, lr = 0.0002
I0526 12:23:23.194392 15394 main.cpp:354] Iteration 48850, loss = 0.0640469
I0526 12:23:23.194432 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0640466 (* 1 = 0.0640466 loss)
I0526 12:23:23.194438 15394 sgd_solver.cpp:43] Iteration 48850, lr = 0.0002
I0526 12:23:28.535361 15394 main.cpp:354] Iteration 48860, loss = 0.23936
I0526 12:23:28.535399 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.23936 (* 1 = 0.23936 loss)
I0526 12:23:28.535406 15394 sgd_solver.cpp:43] Iteration 48860, lr = 0.0002
I0526 12:23:33.794600 15394 main.cpp:354] Iteration 48870, loss = 0.213176
I0526 12:23:33.794643 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.213176 (* 1 = 0.213176 loss)
I0526 12:23:33.794651 15394 sgd_solver.cpp:43] Iteration 48870, lr = 0.0002
I0526 12:23:38.772730 15394 main.cpp:354] Iteration 48880, loss = 0.301869
I0526 12:23:38.772769 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.301869 (* 1 = 0.301869 loss)
I0526 12:23:38.772775 15394 sgd_solver.cpp:43] Iteration 48880, lr = 0.0002
I0526 12:23:44.077631 15394 main.cpp:354] Iteration 48890, loss = 0.220477
I0526 12:23:44.077673 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.220476 (* 1 = 0.220476 loss)
I0526 12:23:44.077680 15394 sgd_solver.cpp:43] Iteration 48890, lr = 0.0002
I0526 12:23:48.697273 15394 main.cpp:465] Iteration 48900, Testing net (#0)
I0526 12:24:01.770140 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8929
I0526 12:24:01.770181 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.333393 (* 1 = 0.333393 loss)
I0526 12:24:02.203660 15394 main.cpp:354] Iteration 48900, loss = 0.300052
I0526 12:24:02.203694 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.300052 (* 1 = 0.300052 loss)
I0526 12:24:02.203702 15394 sgd_solver.cpp:43] Iteration 48900, lr = 0.0002
I0526 12:24:06.686316 15394 main.cpp:354] Iteration 48910, loss = 0.339474
I0526 12:24:06.686372 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.339474 (* 1 = 0.339474 loss)
I0526 12:24:06.686378 15394 sgd_solver.cpp:43] Iteration 48910, lr = 0.0002
I0526 12:24:12.016695 15394 main.cpp:354] Iteration 48920, loss = 0.170647
I0526 12:24:12.016734 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.170646 (* 1 = 0.170646 loss)
I0526 12:24:12.016741 15394 sgd_solver.cpp:43] Iteration 48920, lr = 0.0002
I0526 12:24:17.049850 15394 main.cpp:354] Iteration 48930, loss = 0.218899
I0526 12:24:17.049890 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.218899 (* 1 = 0.218899 loss)
I0526 12:24:17.049898 15394 sgd_solver.cpp:43] Iteration 48930, lr = 0.0002
I0526 12:24:21.988042 15394 main.cpp:354] Iteration 48940, loss = 0.162193
I0526 12:24:21.988086 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.162193 (* 1 = 0.162193 loss)
I0526 12:24:21.988093 15394 sgd_solver.cpp:43] Iteration 48940, lr = 0.0002
I0526 12:24:27.041124 15394 main.cpp:354] Iteration 48950, loss = 0.247044
I0526 12:24:27.041165 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.247044 (* 1 = 0.247044 loss)
I0526 12:24:27.041172 15394 sgd_solver.cpp:43] Iteration 48950, lr = 0.0002
I0526 12:24:32.129591 15394 main.cpp:354] Iteration 48960, loss = 0.254895
I0526 12:24:32.129634 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.254895 (* 1 = 0.254895 loss)
I0526 12:24:32.129643 15394 sgd_solver.cpp:43] Iteration 48960, lr = 0.0002
I0526 12:24:36.761369 15394 main.cpp:354] Iteration 48970, loss = 0.284856
I0526 12:24:36.761409 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.284856 (* 1 = 0.284856 loss)
I0526 12:24:36.761415 15394 sgd_solver.cpp:43] Iteration 48970, lr = 0.0002
I0526 12:24:41.877331 15394 main.cpp:354] Iteration 48980, loss = 0.165437
I0526 12:24:41.877369 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.165437 (* 1 = 0.165437 loss)
I0526 12:24:41.877377 15394 sgd_solver.cpp:43] Iteration 48980, lr = 0.0002
I0526 12:24:47.217603 15394 main.cpp:354] Iteration 48990, loss = 0.133766
I0526 12:24:47.217645 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.133766 (* 1 = 0.133766 loss)
I0526 12:24:47.217653 15394 sgd_solver.cpp:43] Iteration 48990, lr = 0.0002
I0526 12:24:52.171005 15394 main.cpp:465] Iteration 49000, Testing net (#0)
I0526 12:25:05.250216 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8942
I0526 12:25:05.250257 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.336404 (* 1 = 0.336404 loss)
I0526 12:25:05.787241 15394 main.cpp:354] Iteration 49000, loss = 0.129745
I0526 12:25:05.787281 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.129745 (* 1 = 0.129745 loss)
I0526 12:25:05.787291 15394 sgd_solver.cpp:43] Iteration 49000, lr = 0.0002
I0526 12:25:10.835948 15394 main.cpp:354] Iteration 49010, loss = 0.157735
I0526 12:25:10.836000 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.157734 (* 1 = 0.157734 loss)
I0526 12:25:10.836007 15394 sgd_solver.cpp:43] Iteration 49010, lr = 0.0002
I0526 12:25:15.561244 15394 main.cpp:354] Iteration 49020, loss = 0.242865
I0526 12:25:15.561282 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.242864 (* 1 = 0.242864 loss)
I0526 12:25:15.561288 15394 sgd_solver.cpp:43] Iteration 49020, lr = 0.0002
I0526 12:25:20.829385 15394 main.cpp:354] Iteration 49030, loss = 0.143834
I0526 12:25:20.829427 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.143834 (* 1 = 0.143834 loss)
I0526 12:25:20.829434 15394 sgd_solver.cpp:43] Iteration 49030, lr = 0.0002
I0526 12:25:26.085666 15394 main.cpp:354] Iteration 49040, loss = 0.220526
I0526 12:25:26.085705 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.220526 (* 1 = 0.220526 loss)
I0526 12:25:26.085712 15394 sgd_solver.cpp:43] Iteration 49040, lr = 0.0002
I0526 12:25:30.786803 15394 main.cpp:354] Iteration 49050, loss = 0.301296
I0526 12:25:30.786842 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.301295 (* 1 = 0.301295 loss)
I0526 12:25:30.786849 15394 sgd_solver.cpp:43] Iteration 49050, lr = 0.0002
I0526 12:25:35.878564 15394 main.cpp:354] Iteration 49060, loss = 0.229955
I0526 12:25:35.878607 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.229954 (* 1 = 0.229954 loss)
I0526 12:25:35.878612 15394 sgd_solver.cpp:43] Iteration 49060, lr = 0.0002
I0526 12:25:41.107794 15394 main.cpp:354] Iteration 49070, loss = 0.225065
I0526 12:25:41.107836 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.225065 (* 1 = 0.225065 loss)
I0526 12:25:41.107843 15394 sgd_solver.cpp:43] Iteration 49070, lr = 0.0002
I0526 12:25:45.991585 15394 main.cpp:354] Iteration 49080, loss = 0.165665
I0526 12:25:45.991627 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.165665 (* 1 = 0.165665 loss)
I0526 12:25:45.991634 15394 sgd_solver.cpp:43] Iteration 49080, lr = 0.0002
I0526 12:25:50.818130 15394 main.cpp:354] Iteration 49090, loss = 0.278565
I0526 12:25:50.818172 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.278565 (* 1 = 0.278565 loss)
I0526 12:25:50.818179 15394 sgd_solver.cpp:43] Iteration 49090, lr = 0.0002
I0526 12:25:55.324090 15394 main.cpp:465] Iteration 49100, Testing net (#0)
I0526 12:26:08.407910 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8949
I0526 12:26:08.407951 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.336456 (* 1 = 0.336456 loss)
I0526 12:26:08.982858 15394 main.cpp:354] Iteration 49100, loss = 0.0769889
I0526 12:26:08.982895 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0769886 (* 1 = 0.0769886 loss)
I0526 12:26:08.982903 15394 sgd_solver.cpp:43] Iteration 49100, lr = 0.0002
I0526 12:26:13.790594 15394 main.cpp:354] Iteration 49110, loss = 0.13639
I0526 12:26:13.790637 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.136389 (* 1 = 0.136389 loss)
I0526 12:26:13.790642 15394 sgd_solver.cpp:43] Iteration 49110, lr = 0.0002
I0526 12:26:18.947072 15394 main.cpp:354] Iteration 49120, loss = 0.171922
I0526 12:26:18.947113 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.171922 (* 1 = 0.171922 loss)
I0526 12:26:18.947119 15394 sgd_solver.cpp:43] Iteration 49120, lr = 0.0002
I0526 12:26:23.621439 15394 main.cpp:354] Iteration 49130, loss = 0.238185
I0526 12:26:23.621474 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.238185 (* 1 = 0.238185 loss)
I0526 12:26:23.621480 15394 sgd_solver.cpp:43] Iteration 49130, lr = 0.0002
I0526 12:26:28.741909 15394 main.cpp:354] Iteration 49140, loss = 0.108124
I0526 12:26:28.741948 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.108124 (* 1 = 0.108124 loss)
I0526 12:26:28.741961 15394 sgd_solver.cpp:43] Iteration 49140, lr = 0.0002
I0526 12:26:33.751035 15394 main.cpp:354] Iteration 49150, loss = 0.123923
I0526 12:26:33.751082 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.123922 (* 1 = 0.123922 loss)
I0526 12:26:33.751090 15394 sgd_solver.cpp:43] Iteration 49150, lr = 0.0002
I0526 12:26:38.848803 15394 main.cpp:354] Iteration 49160, loss = 0.206578
I0526 12:26:38.848842 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206578 (* 1 = 0.206578 loss)
I0526 12:26:38.848850 15394 sgd_solver.cpp:43] Iteration 49160, lr = 0.0002
I0526 12:26:44.091971 15394 main.cpp:354] Iteration 49170, loss = 0.183495
I0526 12:26:44.092011 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.183495 (* 1 = 0.183495 loss)
I0526 12:26:44.092018 15394 sgd_solver.cpp:43] Iteration 49170, lr = 0.0002
I0526 12:26:49.599201 15394 main.cpp:354] Iteration 49180, loss = 0.172058
I0526 12:26:49.599246 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.172058 (* 1 = 0.172058 loss)
I0526 12:26:49.599253 15394 sgd_solver.cpp:43] Iteration 49180, lr = 0.0002
I0526 12:26:54.848732 15394 main.cpp:354] Iteration 49190, loss = 0.221876
I0526 12:26:54.848772 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.221876 (* 1 = 0.221876 loss)
I0526 12:26:54.848778 15394 sgd_solver.cpp:43] Iteration 49190, lr = 0.0002
I0526 12:26:59.535362 15394 main.cpp:465] Iteration 49200, Testing net (#0)
I0526 12:27:12.619429 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8955
I0526 12:27:12.619469 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.331431 (* 1 = 0.331431 loss)
I0526 12:27:13.158754 15394 main.cpp:354] Iteration 49200, loss = 0.117476
I0526 12:27:13.158788 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.117476 (* 1 = 0.117476 loss)
I0526 12:27:13.158797 15394 sgd_solver.cpp:43] Iteration 49200, lr = 0.0002
I0526 12:27:18.325314 15394 main.cpp:354] Iteration 49210, loss = 0.107527
I0526 12:27:18.325356 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.107527 (* 1 = 0.107527 loss)
I0526 12:27:18.325362 15394 sgd_solver.cpp:43] Iteration 49210, lr = 0.0002
I0526 12:27:23.074436 15394 main.cpp:354] Iteration 49220, loss = 0.231485
I0526 12:27:23.074476 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.231484 (* 1 = 0.231484 loss)
I0526 12:27:23.074482 15394 sgd_solver.cpp:43] Iteration 49220, lr = 0.0002
I0526 12:27:27.862504 15394 main.cpp:354] Iteration 49230, loss = 0.180617
I0526 12:27:27.862546 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.180616 (* 1 = 0.180616 loss)
I0526 12:27:27.862553 15394 sgd_solver.cpp:43] Iteration 49230, lr = 0.0002
I0526 12:27:32.594830 15394 main.cpp:354] Iteration 49240, loss = 0.246749
I0526 12:27:32.594873 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.246748 (* 1 = 0.246748 loss)
I0526 12:27:32.594879 15394 sgd_solver.cpp:43] Iteration 49240, lr = 0.0002
I0526 12:27:37.377331 15394 main.cpp:354] Iteration 49250, loss = 0.294908
I0526 12:27:37.377372 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.294908 (* 1 = 0.294908 loss)
I0526 12:27:37.377377 15394 sgd_solver.cpp:43] Iteration 49250, lr = 0.0002
I0526 12:27:42.547273 15394 main.cpp:354] Iteration 49260, loss = 0.109404
I0526 12:27:42.547314 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.109404 (* 1 = 0.109404 loss)
I0526 12:27:42.547322 15394 sgd_solver.cpp:43] Iteration 49260, lr = 0.0002
I0526 12:27:47.252065 15394 main.cpp:354] Iteration 49270, loss = 0.239118
I0526 12:27:47.252109 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.239118 (* 1 = 0.239118 loss)
I0526 12:27:47.252115 15394 sgd_solver.cpp:43] Iteration 49270, lr = 0.0002
I0526 12:27:52.730110 15394 main.cpp:354] Iteration 49280, loss = 0.203486
I0526 12:27:52.730149 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.203486 (* 1 = 0.203486 loss)
I0526 12:27:52.730162 15394 sgd_solver.cpp:43] Iteration 49280, lr = 0.0002
I0526 12:27:58.343724 15394 main.cpp:354] Iteration 49290, loss = 0.160938
I0526 12:27:58.343761 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.160938 (* 1 = 0.160938 loss)
I0526 12:27:58.343768 15394 sgd_solver.cpp:43] Iteration 49290, lr = 0.0002
I0526 12:28:02.722462 15394 main.cpp:465] Iteration 49300, Testing net (#0)
I0526 12:28:15.812228 15394 main.cpp:532]     Test net output #0: Accuracy = 0.894
I0526 12:28:15.812268 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.333855 (* 1 = 0.333855 loss)
I0526 12:28:16.183058 15394 main.cpp:354] Iteration 49300, loss = 0.312185
I0526 12:28:16.183099 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.312185 (* 1 = 0.312185 loss)
I0526 12:28:16.183106 15394 sgd_solver.cpp:43] Iteration 49300, lr = 0.0002
I0526 12:28:21.275104 15394 main.cpp:354] Iteration 49310, loss = 0.416826
I0526 12:28:21.275146 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.416826 (* 1 = 0.416826 loss)
I0526 12:28:21.275153 15394 sgd_solver.cpp:43] Iteration 49310, lr = 0.0002
I0526 12:28:26.223331 15394 main.cpp:354] Iteration 49320, loss = 0.285475
I0526 12:28:26.223368 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.285475 (* 1 = 0.285475 loss)
I0526 12:28:26.223374 15394 sgd_solver.cpp:43] Iteration 49320, lr = 0.0002
I0526 12:28:31.540331 15394 main.cpp:354] Iteration 49330, loss = 0.196901
I0526 12:28:31.540371 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.196901 (* 1 = 0.196901 loss)
I0526 12:28:31.540377 15394 sgd_solver.cpp:43] Iteration 49330, lr = 0.0002
I0526 12:28:36.887636 15394 main.cpp:354] Iteration 49340, loss = 0.324307
I0526 12:28:36.887679 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.324306 (* 1 = 0.324306 loss)
I0526 12:28:36.887686 15394 sgd_solver.cpp:43] Iteration 49340, lr = 0.0002
I0526 12:28:41.723909 15394 main.cpp:354] Iteration 49350, loss = 0.139112
I0526 12:28:41.723948 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.139112 (* 1 = 0.139112 loss)
I0526 12:28:41.723954 15394 sgd_solver.cpp:43] Iteration 49350, lr = 0.0002
I0526 12:28:47.238493 15394 main.cpp:354] Iteration 49360, loss = 0.200002
I0526 12:28:47.238535 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.200001 (* 1 = 0.200001 loss)
I0526 12:28:47.238543 15394 sgd_solver.cpp:43] Iteration 49360, lr = 0.0002
I0526 12:28:51.796356 15394 main.cpp:354] Iteration 49370, loss = 0.245056
I0526 12:28:51.796396 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.245056 (* 1 = 0.245056 loss)
I0526 12:28:51.796401 15394 sgd_solver.cpp:43] Iteration 49370, lr = 0.0002
I0526 12:28:56.615619 15394 main.cpp:354] Iteration 49380, loss = 0.0869269
I0526 12:28:56.615661 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0869266 (* 1 = 0.0869266 loss)
I0526 12:28:56.615669 15394 sgd_solver.cpp:43] Iteration 49380, lr = 0.0002
I0526 12:29:01.841084 15394 main.cpp:354] Iteration 49390, loss = 0.250482
I0526 12:29:01.841125 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.250481 (* 1 = 0.250481 loss)
I0526 12:29:01.841133 15394 sgd_solver.cpp:43] Iteration 49390, lr = 0.0002
I0526 12:29:06.210697 15394 main.cpp:465] Iteration 49400, Testing net (#0)
I0526 12:29:19.302294 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8939
I0526 12:29:19.302335 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.338055 (* 1 = 0.338055 loss)
I0526 12:29:19.664944 15394 main.cpp:354] Iteration 49400, loss = 0.334904
I0526 12:29:19.664966 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.334903 (* 1 = 0.334903 loss)
I0526 12:29:19.664974 15394 sgd_solver.cpp:43] Iteration 49400, lr = 0.0002
I0526 12:29:25.005493 15394 main.cpp:354] Iteration 49410, loss = 0.176486
I0526 12:29:25.005532 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.176485 (* 1 = 0.176485 loss)
I0526 12:29:25.005538 15394 sgd_solver.cpp:43] Iteration 49410, lr = 0.0002
I0526 12:29:29.988107 15394 main.cpp:354] Iteration 49420, loss = 0.204114
I0526 12:29:29.988147 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204114 (* 1 = 0.204114 loss)
I0526 12:29:29.988154 15394 sgd_solver.cpp:43] Iteration 49420, lr = 0.0002
I0526 12:29:34.872994 15394 main.cpp:354] Iteration 49430, loss = 0.208524
I0526 12:29:34.873037 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.208524 (* 1 = 0.208524 loss)
I0526 12:29:34.873045 15394 sgd_solver.cpp:43] Iteration 49430, lr = 0.0002
I0526 12:29:40.005062 15394 main.cpp:354] Iteration 49440, loss = 0.33771
I0526 12:29:40.005101 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.33771 (* 1 = 0.33771 loss)
I0526 12:29:40.005107 15394 sgd_solver.cpp:43] Iteration 49440, lr = 0.0002
I0526 12:29:45.078903 15394 main.cpp:354] Iteration 49450, loss = 0.624581
I0526 12:29:45.078943 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.624581 (* 1 = 0.624581 loss)
I0526 12:29:45.078949 15394 sgd_solver.cpp:43] Iteration 49450, lr = 0.0002
I0526 12:29:49.837796 15394 main.cpp:354] Iteration 49460, loss = 0.398166
I0526 12:29:49.837839 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.398165 (* 1 = 0.398165 loss)
I0526 12:29:49.837846 15394 sgd_solver.cpp:43] Iteration 49460, lr = 0.0002
I0526 12:29:54.376014 15394 main.cpp:354] Iteration 49470, loss = 0.388116
I0526 12:29:54.376056 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.388116 (* 1 = 0.388116 loss)
I0526 12:29:54.376063 15394 sgd_solver.cpp:43] Iteration 49470, lr = 0.0002
I0526 12:29:59.321343 15394 main.cpp:354] Iteration 49480, loss = 0.320326
I0526 12:29:59.321383 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.320325 (* 1 = 0.320325 loss)
I0526 12:29:59.321389 15394 sgd_solver.cpp:43] Iteration 49480, lr = 0.0002
I0526 12:30:04.450666 15394 main.cpp:354] Iteration 49490, loss = 0.182794
I0526 12:30:04.450702 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.182794 (* 1 = 0.182794 loss)
I0526 12:30:04.450708 15394 sgd_solver.cpp:43] Iteration 49490, lr = 0.0002
I0526 12:30:09.044636 15394 main.cpp:465] Iteration 49500, Testing net (#0)
I0526 12:30:22.128303 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8937
I0526 12:30:22.128340 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.338847 (* 1 = 0.338847 loss)
I0526 12:30:22.667078 15394 main.cpp:354] Iteration 49500, loss = 0.0915412
I0526 12:30:22.667115 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0915408 (* 1 = 0.0915408 loss)
I0526 12:30:22.667124 15394 sgd_solver.cpp:43] Iteration 49500, lr = 0.0002
I0526 12:30:28.142242 15394 main.cpp:354] Iteration 49510, loss = 0.131627
I0526 12:30:28.142282 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.131626 (* 1 = 0.131626 loss)
I0526 12:30:28.142288 15394 sgd_solver.cpp:43] Iteration 49510, lr = 0.0002
I0526 12:30:33.374344 15394 main.cpp:354] Iteration 49520, loss = 0.255322
I0526 12:30:33.374403 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.255322 (* 1 = 0.255322 loss)
I0526 12:30:33.374410 15394 sgd_solver.cpp:43] Iteration 49520, lr = 0.0002
I0526 12:30:38.412036 15394 main.cpp:354] Iteration 49530, loss = 0.164792
I0526 12:30:38.412075 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.164791 (* 1 = 0.164791 loss)
I0526 12:30:38.412081 15394 sgd_solver.cpp:43] Iteration 49530, lr = 0.0002
I0526 12:30:43.866308 15394 main.cpp:354] Iteration 49540, loss = 0.0885735
I0526 12:30:43.866349 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0885731 (* 1 = 0.0885731 loss)
I0526 12:30:43.866361 15394 sgd_solver.cpp:43] Iteration 49540, lr = 0.0002
I0526 12:30:48.837260 15394 main.cpp:354] Iteration 49550, loss = 0.292391
I0526 12:30:48.837302 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.292391 (* 1 = 0.292391 loss)
I0526 12:30:48.837309 15394 sgd_solver.cpp:43] Iteration 49550, lr = 0.0002
I0526 12:30:53.934559 15394 main.cpp:354] Iteration 49560, loss = 0.272365
I0526 12:30:53.934607 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.272365 (* 1 = 0.272365 loss)
I0526 12:30:53.934615 15394 sgd_solver.cpp:43] Iteration 49560, lr = 0.0002
I0526 12:30:58.719321 15394 main.cpp:354] Iteration 49570, loss = 0.172869
I0526 12:30:58.719358 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.172868 (* 1 = 0.172868 loss)
I0526 12:30:58.719365 15394 sgd_solver.cpp:43] Iteration 49570, lr = 0.0002
I0526 12:31:03.593127 15394 main.cpp:354] Iteration 49580, loss = 0.426483
I0526 12:31:03.593169 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.426483 (* 1 = 0.426483 loss)
I0526 12:31:03.593175 15394 sgd_solver.cpp:43] Iteration 49580, lr = 0.0002
I0526 12:31:08.759300 15394 main.cpp:354] Iteration 49590, loss = 0.109742
I0526 12:31:08.759338 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.109742 (* 1 = 0.109742 loss)
I0526 12:31:08.759344 15394 sgd_solver.cpp:43] Iteration 49590, lr = 0.0002
I0526 12:31:13.414741 15394 main.cpp:465] Iteration 49600, Testing net (#0)
I0526 12:31:26.507695 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8965
I0526 12:31:26.507735 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.332083 (* 1 = 0.332083 loss)
I0526 12:31:27.010802 15394 main.cpp:354] Iteration 49600, loss = 0.156417
I0526 12:31:27.010841 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.156417 (* 1 = 0.156417 loss)
I0526 12:31:27.010848 15394 sgd_solver.cpp:43] Iteration 49600, lr = 0.0002
I0526 12:31:32.141886 15394 main.cpp:354] Iteration 49610, loss = 0.150548
I0526 12:31:32.141929 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.150548 (* 1 = 0.150548 loss)
I0526 12:31:32.141937 15394 sgd_solver.cpp:43] Iteration 49610, lr = 0.0002
I0526 12:31:37.010530 15394 main.cpp:354] Iteration 49620, loss = 0.120108
I0526 12:31:37.010570 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.120107 (* 1 = 0.120107 loss)
I0526 12:31:37.010576 15394 sgd_solver.cpp:43] Iteration 49620, lr = 0.0002
I0526 12:31:42.453660 15394 main.cpp:354] Iteration 49630, loss = 0.0931376
I0526 12:31:42.453703 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0931371 (* 1 = 0.0931371 loss)
I0526 12:31:42.453709 15394 sgd_solver.cpp:43] Iteration 49630, lr = 0.0002
I0526 12:31:47.511848 15394 main.cpp:354] Iteration 49640, loss = 0.225527
I0526 12:31:47.511891 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.225526 (* 1 = 0.225526 loss)
I0526 12:31:47.511898 15394 sgd_solver.cpp:43] Iteration 49640, lr = 0.0002
I0526 12:31:52.364231 15394 main.cpp:354] Iteration 49650, loss = 0.169813
I0526 12:31:52.364271 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.169812 (* 1 = 0.169812 loss)
I0526 12:31:52.364277 15394 sgd_solver.cpp:43] Iteration 49650, lr = 0.0002
I0526 12:31:57.231868 15394 main.cpp:354] Iteration 49660, loss = 0.187189
I0526 12:31:57.231907 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187188 (* 1 = 0.187188 loss)
I0526 12:31:57.231914 15394 sgd_solver.cpp:43] Iteration 49660, lr = 0.0002
I0526 12:32:01.910305 15394 main.cpp:354] Iteration 49670, loss = 0.257663
I0526 12:32:01.910349 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.257662 (* 1 = 0.257662 loss)
I0526 12:32:01.910373 15394 sgd_solver.cpp:43] Iteration 49670, lr = 0.0002
I0526 12:32:06.727649 15394 main.cpp:354] Iteration 49680, loss = 0.189885
I0526 12:32:06.727689 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.189884 (* 1 = 0.189884 loss)
I0526 12:32:06.727695 15394 sgd_solver.cpp:43] Iteration 49680, lr = 0.0002
I0526 12:32:12.084276 15394 main.cpp:354] Iteration 49690, loss = 0.117953
I0526 12:32:12.084316 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.117952 (* 1 = 0.117952 loss)
I0526 12:32:12.084322 15394 sgd_solver.cpp:43] Iteration 49690, lr = 0.0002
I0526 12:32:16.786123 15394 main.cpp:465] Iteration 49700, Testing net (#0)
I0526 12:32:29.879096 15394 main.cpp:532]     Test net output #0: Accuracy = 0.893
I0526 12:32:29.879142 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.330642 (* 1 = 0.330642 loss)
I0526 12:32:30.387370 15394 main.cpp:354] Iteration 49700, loss = 0.232788
I0526 12:32:30.387392 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.232787 (* 1 = 0.232787 loss)
I0526 12:32:30.387399 15394 sgd_solver.cpp:43] Iteration 49700, lr = 0.0002
I0526 12:32:35.591512 15394 main.cpp:354] Iteration 49710, loss = 0.0916084
I0526 12:32:35.591549 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0916079 (* 1 = 0.0916079 loss)
I0526 12:32:35.591555 15394 sgd_solver.cpp:43] Iteration 49710, lr = 0.0002
I0526 12:32:40.502393 15394 main.cpp:354] Iteration 49720, loss = 0.5457
I0526 12:32:40.502432 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.545699 (* 1 = 0.545699 loss)
I0526 12:32:40.502439 15394 sgd_solver.cpp:43] Iteration 49720, lr = 0.0002
I0526 12:32:45.391089 15394 main.cpp:354] Iteration 49730, loss = 0.171087
I0526 12:32:45.391130 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.171087 (* 1 = 0.171087 loss)
I0526 12:32:45.391139 15394 sgd_solver.cpp:43] Iteration 49730, lr = 0.0002
I0526 12:32:50.385797 15394 main.cpp:354] Iteration 49740, loss = 0.217903
I0526 12:32:50.385841 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.217903 (* 1 = 0.217903 loss)
I0526 12:32:50.385848 15394 sgd_solver.cpp:43] Iteration 49740, lr = 0.0002
I0526 12:32:55.785660 15394 main.cpp:354] Iteration 49750, loss = 0.206172
I0526 12:32:55.785701 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206172 (* 1 = 0.206172 loss)
I0526 12:32:55.785707 15394 sgd_solver.cpp:43] Iteration 49750, lr = 0.0002
I0526 12:33:01.183720 15394 main.cpp:354] Iteration 49760, loss = 0.282263
I0526 12:33:01.183760 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.282262 (* 1 = 0.282262 loss)
I0526 12:33:01.183768 15394 sgd_solver.cpp:43] Iteration 49760, lr = 0.0002
I0526 12:33:05.799494 15394 main.cpp:354] Iteration 49770, loss = 0.205234
I0526 12:33:05.799537 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.205234 (* 1 = 0.205234 loss)
I0526 12:33:05.799545 15394 sgd_solver.cpp:43] Iteration 49770, lr = 0.0002
I0526 12:33:10.659852 15394 main.cpp:354] Iteration 49780, loss = 0.235668
I0526 12:33:10.659891 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235667 (* 1 = 0.235667 loss)
I0526 12:33:10.659898 15394 sgd_solver.cpp:43] Iteration 49780, lr = 0.0002
I0526 12:33:16.047539 15394 main.cpp:354] Iteration 49790, loss = 0.198487
I0526 12:33:16.047580 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.198487 (* 1 = 0.198487 loss)
I0526 12:33:16.047587 15394 sgd_solver.cpp:43] Iteration 49790, lr = 0.0002
I0526 12:33:20.695585 15394 main.cpp:465] Iteration 49800, Testing net (#0)
I0526 12:33:33.783447 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8945
I0526 12:33:33.783488 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.330109 (* 1 = 0.330109 loss)
I0526 12:33:34.255002 15394 main.cpp:354] Iteration 49800, loss = 0.190923
I0526 12:33:34.255035 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.190923 (* 1 = 0.190923 loss)
I0526 12:33:34.255043 15394 sgd_solver.cpp:43] Iteration 49800, lr = 0.0002
I0526 12:33:39.488039 15394 main.cpp:354] Iteration 49810, loss = 0.35711
I0526 12:33:39.488077 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.35711 (* 1 = 0.35711 loss)
I0526 12:33:39.488083 15394 sgd_solver.cpp:43] Iteration 49810, lr = 0.0002
I0526 12:33:44.819849 15394 main.cpp:354] Iteration 49820, loss = 0.235472
I0526 12:33:44.819875 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235471 (* 1 = 0.235471 loss)
I0526 12:33:44.819882 15394 sgd_solver.cpp:43] Iteration 49820, lr = 0.0002
I0526 12:33:49.917137 15394 main.cpp:354] Iteration 49830, loss = 0.21674
I0526 12:33:49.917181 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.21674 (* 1 = 0.21674 loss)
I0526 12:33:49.917193 15394 sgd_solver.cpp:43] Iteration 49830, lr = 0.0002
I0526 12:33:54.765334 15394 main.cpp:354] Iteration 49840, loss = 0.134921
I0526 12:33:54.765377 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.13492 (* 1 = 0.13492 loss)
I0526 12:33:54.765383 15394 sgd_solver.cpp:43] Iteration 49840, lr = 0.0002
I0526 12:33:59.277997 15394 main.cpp:354] Iteration 49850, loss = 0.218823
I0526 12:33:59.278034 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.218822 (* 1 = 0.218822 loss)
I0526 12:33:59.278040 15394 sgd_solver.cpp:43] Iteration 49850, lr = 0.0002
I0526 12:34:04.503650 15394 main.cpp:354] Iteration 49860, loss = 0.17015
I0526 12:34:04.503697 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.170149 (* 1 = 0.170149 loss)
I0526 12:34:04.503705 15394 sgd_solver.cpp:43] Iteration 49860, lr = 0.0002
I0526 12:34:09.978579 15394 main.cpp:354] Iteration 49870, loss = 0.228722
I0526 12:34:09.978607 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.228721 (* 1 = 0.228721 loss)
I0526 12:34:09.978613 15394 sgd_solver.cpp:43] Iteration 49870, lr = 0.0002
I0526 12:34:14.992717 15394 main.cpp:354] Iteration 49880, loss = 0.280034
I0526 12:34:14.992755 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.280033 (* 1 = 0.280033 loss)
I0526 12:34:14.992761 15394 sgd_solver.cpp:43] Iteration 49880, lr = 0.0002
I0526 12:34:19.943466 15394 main.cpp:354] Iteration 49890, loss = 0.137389
I0526 12:34:19.943509 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.137388 (* 1 = 0.137388 loss)
I0526 12:34:19.943516 15394 sgd_solver.cpp:43] Iteration 49890, lr = 0.0002
I0526 12:34:24.623718 15394 main.cpp:465] Iteration 49900, Testing net (#0)
I0526 12:34:37.710993 15394 main.cpp:532]     Test net output #0: Accuracy = 0.895
I0526 12:34:37.711032 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.323434 (* 1 = 0.323434 loss)
I0526 12:34:38.211877 15394 main.cpp:354] Iteration 49900, loss = 0.180788
I0526 12:34:38.211912 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.180787 (* 1 = 0.180787 loss)
I0526 12:34:38.211920 15394 sgd_solver.cpp:43] Iteration 49900, lr = 0.0002
I0526 12:34:42.804978 15394 main.cpp:354] Iteration 49910, loss = 0.226956
I0526 12:34:42.805025 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.226956 (* 1 = 0.226956 loss)
I0526 12:34:42.805034 15394 sgd_solver.cpp:43] Iteration 49910, lr = 0.0002
I0526 12:34:47.783933 15394 main.cpp:354] Iteration 49920, loss = 0.28433
I0526 12:34:47.783974 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.28433 (* 1 = 0.28433 loss)
I0526 12:34:47.783982 15394 sgd_solver.cpp:43] Iteration 49920, lr = 0.0002
I0526 12:34:53.335997 15394 main.cpp:354] Iteration 49930, loss = 0.128793
I0526 12:34:53.336038 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.128792 (* 1 = 0.128792 loss)
I0526 12:34:53.336046 15394 sgd_solver.cpp:43] Iteration 49930, lr = 0.0002
I0526 12:34:58.550513 15394 main.cpp:354] Iteration 49940, loss = 0.200961
I0526 12:34:58.550552 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.200961 (* 1 = 0.200961 loss)
I0526 12:34:58.550559 15394 sgd_solver.cpp:43] Iteration 49940, lr = 0.0002
I0526 12:35:03.959489 15394 main.cpp:354] Iteration 49950, loss = 0.160989
I0526 12:35:03.959532 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.160988 (* 1 = 0.160988 loss)
I0526 12:35:03.959539 15394 sgd_solver.cpp:43] Iteration 49950, lr = 0.0002
I0526 12:35:09.051769 15394 main.cpp:354] Iteration 49960, loss = 0.209705
I0526 12:35:09.051810 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.209704 (* 1 = 0.209704 loss)
I0526 12:35:09.051816 15394 sgd_solver.cpp:43] Iteration 49960, lr = 0.0002
I0526 12:35:14.105715 15394 main.cpp:354] Iteration 49970, loss = 0.12956
I0526 12:35:14.105756 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.12956 (* 1 = 0.12956 loss)
I0526 12:35:14.105762 15394 sgd_solver.cpp:43] Iteration 49970, lr = 0.0002
I0526 12:35:19.177145 15394 main.cpp:354] Iteration 49980, loss = 0.233947
I0526 12:35:19.177189 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.233947 (* 1 = 0.233947 loss)
I0526 12:35:19.177196 15394 sgd_solver.cpp:43] Iteration 49980, lr = 0.0002
I0526 12:35:24.410235 15394 main.cpp:354] Iteration 49990, loss = 0.173549
I0526 12:35:24.410274 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.173549 (* 1 = 0.173549 loss)
I0526 12:35:24.410281 15394 sgd_solver.cpp:43] Iteration 49990, lr = 0.0002
I0526 12:35:28.707479 15394 main.cpp:465] Iteration 50000, Testing net (#0)
I0526 12:35:41.790341 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8955
I0526 12:35:41.790398 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.330867 (* 1 = 0.330867 loss)
I0526 12:35:42.294801 15394 main.cpp:354] Iteration 50000, loss = 0.168204
I0526 12:35:42.294842 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.168204 (* 1 = 0.168204 loss)
I0526 12:35:42.294850 15394 sgd_solver.cpp:43] Iteration 50000, lr = 0.0002
I0526 12:35:47.957170 15394 main.cpp:354] Iteration 50010, loss = 0.191272
I0526 12:35:47.957214 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.191271 (* 1 = 0.191271 loss)
I0526 12:35:47.957222 15394 sgd_solver.cpp:43] Iteration 50010, lr = 0.0002
I0526 12:35:53.291164 15394 main.cpp:354] Iteration 50020, loss = 0.109872
I0526 12:35:53.291208 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.109871 (* 1 = 0.109871 loss)
I0526 12:35:53.291215 15394 sgd_solver.cpp:43] Iteration 50020, lr = 0.0002
I0526 12:35:58.195389 15394 main.cpp:354] Iteration 50030, loss = 0.218229
I0526 12:35:58.195426 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.218229 (* 1 = 0.218229 loss)
I0526 12:35:58.195432 15394 sgd_solver.cpp:43] Iteration 50030, lr = 0.0002
I0526 12:36:03.568899 15394 main.cpp:354] Iteration 50040, loss = 0.164954
I0526 12:36:03.568941 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.164953 (* 1 = 0.164953 loss)
I0526 12:36:03.568948 15394 sgd_solver.cpp:43] Iteration 50040, lr = 0.0002
I0526 12:36:08.877815 15394 main.cpp:354] Iteration 50050, loss = 0.168265
I0526 12:36:08.877853 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.168264 (* 1 = 0.168264 loss)
I0526 12:36:08.877861 15394 sgd_solver.cpp:43] Iteration 50050, lr = 0.0002
I0526 12:36:13.497484 15394 main.cpp:354] Iteration 50060, loss = 0.212986
I0526 12:36:13.497524 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.212986 (* 1 = 0.212986 loss)
I0526 12:36:13.497530 15394 sgd_solver.cpp:43] Iteration 50060, lr = 0.0002
I0526 12:36:18.408531 15394 main.cpp:354] Iteration 50070, loss = 0.259999
I0526 12:36:18.408573 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.259999 (* 1 = 0.259999 loss)
I0526 12:36:18.408581 15394 sgd_solver.cpp:43] Iteration 50070, lr = 0.0002
I0526 12:36:23.374220 15394 main.cpp:354] Iteration 50080, loss = 0.271838
I0526 12:36:23.374258 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.271837 (* 1 = 0.271837 loss)
I0526 12:36:23.374265 15394 sgd_solver.cpp:43] Iteration 50080, lr = 0.0002
I0526 12:36:28.771699 15394 main.cpp:354] Iteration 50090, loss = 0.0667879
I0526 12:36:28.771726 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0667874 (* 1 = 0.0667874 loss)
I0526 12:36:28.771733 15394 sgd_solver.cpp:43] Iteration 50090, lr = 0.0002
I0526 12:36:33.851534 15394 main.cpp:465] Iteration 50100, Testing net (#0)
I0526 12:36:46.936842 15394 main.cpp:532]     Test net output #0: Accuracy = 0.894
I0526 12:36:46.936883 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.327773 (* 1 = 0.327773 loss)
I0526 12:36:47.232429 15394 main.cpp:354] Iteration 50100, loss = 0.458197
I0526 12:36:47.232468 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.458197 (* 1 = 0.458197 loss)
I0526 12:36:47.232475 15394 sgd_solver.cpp:43] Iteration 50100, lr = 0.0002
I0526 12:36:52.676573 15394 main.cpp:354] Iteration 50110, loss = 0.191435
I0526 12:36:52.676619 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.191435 (* 1 = 0.191435 loss)
I0526 12:36:52.676625 15394 sgd_solver.cpp:43] Iteration 50110, lr = 0.0002
I0526 12:36:57.617794 15394 main.cpp:354] Iteration 50120, loss = 0.186956
I0526 12:36:57.617835 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186955 (* 1 = 0.186955 loss)
I0526 12:36:57.617841 15394 sgd_solver.cpp:43] Iteration 50120, lr = 0.0002
I0526 12:37:02.736974 15394 main.cpp:354] Iteration 50130, loss = 0.206087
I0526 12:37:02.737015 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206087 (* 1 = 0.206087 loss)
I0526 12:37:02.737020 15394 sgd_solver.cpp:43] Iteration 50130, lr = 0.0002
I0526 12:37:07.591320 15394 main.cpp:354] Iteration 50140, loss = 0.280032
I0526 12:37:07.591361 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.280031 (* 1 = 0.280031 loss)
I0526 12:37:07.591367 15394 sgd_solver.cpp:43] Iteration 50140, lr = 0.0002
I0526 12:37:12.489213 15394 main.cpp:354] Iteration 50150, loss = 0.32312
I0526 12:37:12.489246 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.323119 (* 1 = 0.323119 loss)
I0526 12:37:12.489253 15394 sgd_solver.cpp:43] Iteration 50150, lr = 0.0002
I0526 12:37:17.718202 15394 main.cpp:354] Iteration 50160, loss = 0.354023
I0526 12:37:17.718245 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.354022 (* 1 = 0.354022 loss)
I0526 12:37:17.718252 15394 sgd_solver.cpp:43] Iteration 50160, lr = 0.0002
I0526 12:37:22.047413 15394 main.cpp:354] Iteration 50170, loss = 0.899642
I0526 12:37:22.047454 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.899642 (* 1 = 0.899642 loss)
I0526 12:37:22.047472 15394 sgd_solver.cpp:43] Iteration 50170, lr = 0.0002
I0526 12:37:27.427997 15394 main.cpp:354] Iteration 50180, loss = 0.16605
I0526 12:37:27.428035 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.166049 (* 1 = 0.166049 loss)
I0526 12:37:27.428042 15394 sgd_solver.cpp:43] Iteration 50180, lr = 0.0002
I0526 12:37:32.528226 15394 main.cpp:354] Iteration 50190, loss = 0.248091
I0526 12:37:32.528273 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.248091 (* 1 = 0.248091 loss)
I0526 12:37:32.528280 15394 sgd_solver.cpp:43] Iteration 50190, lr = 0.0002
I0526 12:37:37.091543 15394 main.cpp:465] Iteration 50200, Testing net (#0)
I0526 12:37:50.180598 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8961
I0526 12:37:50.180639 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.331874 (* 1 = 0.331874 loss)
I0526 12:37:50.683941 15394 main.cpp:354] Iteration 50200, loss = 0.28219
I0526 12:37:50.683974 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.282189 (* 1 = 0.282189 loss)
I0526 12:37:50.683982 15394 sgd_solver.cpp:43] Iteration 50200, lr = 0.0002
I0526 12:37:55.905534 15394 main.cpp:354] Iteration 50210, loss = 0.419844
I0526 12:37:55.905572 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.419844 (* 1 = 0.419844 loss)
I0526 12:37:55.905578 15394 sgd_solver.cpp:43] Iteration 50210, lr = 0.0002
I0526 12:38:00.587405 15394 main.cpp:354] Iteration 50220, loss = 0.147122
I0526 12:38:00.587445 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.147122 (* 1 = 0.147122 loss)
I0526 12:38:00.587451 15394 sgd_solver.cpp:43] Iteration 50220, lr = 0.0002
I0526 12:38:05.674545 15394 main.cpp:354] Iteration 50230, loss = 0.535424
I0526 12:38:05.674589 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.535424 (* 1 = 0.535424 loss)
I0526 12:38:05.674597 15394 sgd_solver.cpp:43] Iteration 50230, lr = 0.0002
I0526 12:38:10.872333 15394 main.cpp:354] Iteration 50240, loss = 0.263457
I0526 12:38:10.872370 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.263456 (* 1 = 0.263456 loss)
I0526 12:38:10.872376 15394 sgd_solver.cpp:43] Iteration 50240, lr = 0.0002
I0526 12:38:16.052454 15394 main.cpp:354] Iteration 50250, loss = 0.230672
I0526 12:38:16.052492 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.230672 (* 1 = 0.230672 loss)
I0526 12:38:16.052505 15394 sgd_solver.cpp:43] Iteration 50250, lr = 0.0002
I0526 12:38:21.379673 15394 main.cpp:354] Iteration 50260, loss = 0.285023
I0526 12:38:21.379716 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.285022 (* 1 = 0.285022 loss)
I0526 12:38:21.379724 15394 sgd_solver.cpp:43] Iteration 50260, lr = 0.0002
I0526 12:38:26.737481 15394 main.cpp:354] Iteration 50270, loss = 0.23491
I0526 12:38:26.737521 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.23491 (* 1 = 0.23491 loss)
I0526 12:38:26.737529 15394 sgd_solver.cpp:43] Iteration 50270, lr = 0.0002
I0526 12:38:31.796074 15394 main.cpp:354] Iteration 50280, loss = 0.121971
I0526 12:38:31.796115 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.121971 (* 1 = 0.121971 loss)
I0526 12:38:31.796123 15394 sgd_solver.cpp:43] Iteration 50280, lr = 0.0002
I0526 12:38:36.674820 15394 main.cpp:354] Iteration 50290, loss = 0.0989124
I0526 12:38:36.674868 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0989119 (* 1 = 0.0989119 loss)
I0526 12:38:36.674875 15394 sgd_solver.cpp:43] Iteration 50290, lr = 0.0002
I0526 12:38:41.441505 15394 main.cpp:465] Iteration 50300, Testing net (#0)
I0526 12:38:54.527554 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8949
I0526 12:38:54.527595 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.330845 (* 1 = 0.330845 loss)
I0526 12:38:54.927075 15394 main.cpp:354] Iteration 50300, loss = 0.220745
I0526 12:38:54.927108 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.220745 (* 1 = 0.220745 loss)
I0526 12:38:54.927115 15394 sgd_solver.cpp:43] Iteration 50300, lr = 0.0002
I0526 12:38:59.832449 15394 main.cpp:354] Iteration 50310, loss = 0.237878
I0526 12:38:59.832489 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.237878 (* 1 = 0.237878 loss)
I0526 12:38:59.832495 15394 sgd_solver.cpp:43] Iteration 50310, lr = 0.0002
I0526 12:39:04.705267 15394 main.cpp:354] Iteration 50320, loss = 0.24618
I0526 12:39:04.705310 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.24618 (* 1 = 0.24618 loss)
I0526 12:39:04.705317 15394 sgd_solver.cpp:43] Iteration 50320, lr = 0.0002
I0526 12:39:09.696713 15394 main.cpp:354] Iteration 50330, loss = 0.163464
I0526 12:39:09.696753 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.163464 (* 1 = 0.163464 loss)
I0526 12:39:09.696760 15394 sgd_solver.cpp:43] Iteration 50330, lr = 0.0002
I0526 12:39:14.791095 15394 main.cpp:354] Iteration 50340, loss = 0.145162
I0526 12:39:14.791136 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.145162 (* 1 = 0.145162 loss)
I0526 12:39:14.791141 15394 sgd_solver.cpp:43] Iteration 50340, lr = 0.0002
I0526 12:39:20.035923 15394 main.cpp:354] Iteration 50350, loss = 0.289991
I0526 12:39:20.035970 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.28999 (* 1 = 0.28999 loss)
I0526 12:39:20.035977 15394 sgd_solver.cpp:43] Iteration 50350, lr = 0.0002
I0526 12:39:25.135027 15394 main.cpp:354] Iteration 50360, loss = 0.159641
I0526 12:39:25.135068 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.15964 (* 1 = 0.15964 loss)
I0526 12:39:25.135074 15394 sgd_solver.cpp:43] Iteration 50360, lr = 0.0002
I0526 12:39:30.509106 15394 main.cpp:354] Iteration 50370, loss = 0.171849
I0526 12:39:30.509146 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.171848 (* 1 = 0.171848 loss)
I0526 12:39:30.509152 15394 sgd_solver.cpp:43] Iteration 50370, lr = 0.0002
I0526 12:39:36.063163 15394 main.cpp:354] Iteration 50380, loss = 0.138412
I0526 12:39:36.063206 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.138411 (* 1 = 0.138411 loss)
I0526 12:39:36.063213 15394 sgd_solver.cpp:43] Iteration 50380, lr = 0.0002
I0526 12:39:41.150521 15394 main.cpp:354] Iteration 50390, loss = 0.222633
I0526 12:39:41.150560 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.222632 (* 1 = 0.222632 loss)
I0526 12:39:41.150573 15394 sgd_solver.cpp:43] Iteration 50390, lr = 0.0002
I0526 12:39:45.727679 15394 main.cpp:465] Iteration 50400, Testing net (#0)
I0526 12:39:58.809695 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8962
I0526 12:39:58.809734 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.327668 (* 1 = 0.327668 loss)
I0526 12:39:59.347753 15394 main.cpp:354] Iteration 50400, loss = 0.21058
I0526 12:39:59.347793 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.21058 (* 1 = 0.21058 loss)
I0526 12:39:59.347801 15394 sgd_solver.cpp:43] Iteration 50400, lr = 0.0002
I0526 12:40:04.232507 15394 main.cpp:354] Iteration 50410, loss = 0.137828
I0526 12:40:04.232549 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.137827 (* 1 = 0.137827 loss)
I0526 12:40:04.232556 15394 sgd_solver.cpp:43] Iteration 50410, lr = 0.0002
I0526 12:40:09.699049 15394 main.cpp:354] Iteration 50420, loss = 0.215399
I0526 12:40:09.699081 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.215398 (* 1 = 0.215398 loss)
I0526 12:40:09.699089 15394 sgd_solver.cpp:43] Iteration 50420, lr = 0.0002
I0526 12:40:14.521327 15394 main.cpp:354] Iteration 50430, loss = 0.363995
I0526 12:40:14.521366 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.363995 (* 1 = 0.363995 loss)
I0526 12:40:14.521373 15394 sgd_solver.cpp:43] Iteration 50430, lr = 0.0002
I0526 12:40:19.468859 15394 main.cpp:354] Iteration 50440, loss = 0.173336
I0526 12:40:19.468901 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.173336 (* 1 = 0.173336 loss)
I0526 12:40:19.468909 15394 sgd_solver.cpp:43] Iteration 50440, lr = 0.0002
I0526 12:40:24.554268 15394 main.cpp:354] Iteration 50450, loss = 0.150355
I0526 12:40:24.554307 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.150354 (* 1 = 0.150354 loss)
I0526 12:40:24.554313 15394 sgd_solver.cpp:43] Iteration 50450, lr = 0.0002
I0526 12:40:29.602506 15394 main.cpp:354] Iteration 50460, loss = 0.452449
I0526 12:40:29.602545 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.452449 (* 1 = 0.452449 loss)
I0526 12:40:29.602550 15394 sgd_solver.cpp:43] Iteration 50460, lr = 0.0002
I0526 12:40:35.021586 15394 main.cpp:354] Iteration 50470, loss = 0.189432
I0526 12:40:35.021637 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.189431 (* 1 = 0.189431 loss)
I0526 12:40:35.021644 15394 sgd_solver.cpp:43] Iteration 50470, lr = 0.0002
I0526 12:40:40.017729 15394 main.cpp:354] Iteration 50480, loss = 0.245399
I0526 12:40:40.017767 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.245399 (* 1 = 0.245399 loss)
I0526 12:40:40.017773 15394 sgd_solver.cpp:43] Iteration 50480, lr = 0.0002
I0526 12:40:45.314911 15394 main.cpp:354] Iteration 50490, loss = 0.198697
I0526 12:40:45.314951 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.198696 (* 1 = 0.198696 loss)
I0526 12:40:45.314959 15394 sgd_solver.cpp:43] Iteration 50490, lr = 0.0002
I0526 12:40:49.685814 15394 main.cpp:465] Iteration 50500, Testing net (#0)
I0526 12:41:02.772758 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8961
I0526 12:41:02.772797 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.323875 (* 1 = 0.323875 loss)
I0526 12:41:03.213768 15394 main.cpp:354] Iteration 50500, loss = 0.115182
I0526 12:41:03.213806 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.115181 (* 1 = 0.115181 loss)
I0526 12:41:03.213814 15394 sgd_solver.cpp:43] Iteration 50500, lr = 0.0002
I0526 12:41:08.382637 15394 main.cpp:354] Iteration 50510, loss = 0.332439
I0526 12:41:08.382676 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.332438 (* 1 = 0.332438 loss)
I0526 12:41:08.382683 15394 sgd_solver.cpp:43] Iteration 50510, lr = 0.0002
I0526 12:41:13.366775 15394 main.cpp:354] Iteration 50520, loss = 0.457554
I0526 12:41:13.366813 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.457554 (* 1 = 0.457554 loss)
I0526 12:41:13.366819 15394 sgd_solver.cpp:43] Iteration 50520, lr = 0.0002
I0526 12:41:17.980731 15394 main.cpp:354] Iteration 50530, loss = 0.328792
I0526 12:41:17.980774 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.328792 (* 1 = 0.328792 loss)
I0526 12:41:17.980782 15394 sgd_solver.cpp:43] Iteration 50530, lr = 0.0002
I0526 12:41:22.769572 15394 main.cpp:354] Iteration 50540, loss = 0.294913
I0526 12:41:22.769611 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.294912 (* 1 = 0.294912 loss)
I0526 12:41:22.769618 15394 sgd_solver.cpp:43] Iteration 50540, lr = 0.0002
I0526 12:41:27.419829 15394 main.cpp:354] Iteration 50550, loss = 0.464831
I0526 12:41:27.419867 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.464831 (* 1 = 0.464831 loss)
I0526 12:41:27.419873 15394 sgd_solver.cpp:43] Iteration 50550, lr = 0.0002
I0526 12:41:31.903842 15394 main.cpp:354] Iteration 50560, loss = 0.314017
I0526 12:41:31.903882 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.314016 (* 1 = 0.314016 loss)
I0526 12:41:31.903888 15394 sgd_solver.cpp:43] Iteration 50560, lr = 0.0002
I0526 12:41:37.197849 15394 main.cpp:354] Iteration 50570, loss = 0.208837
I0526 12:41:37.197890 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.208836 (* 1 = 0.208836 loss)
I0526 12:41:37.197896 15394 sgd_solver.cpp:43] Iteration 50570, lr = 0.0002
I0526 12:41:42.074340 15394 main.cpp:354] Iteration 50580, loss = 0.313968
I0526 12:41:42.074383 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.313967 (* 1 = 0.313967 loss)
I0526 12:41:42.074389 15394 sgd_solver.cpp:43] Iteration 50580, lr = 0.0002
I0526 12:41:46.349720 15394 main.cpp:354] Iteration 50590, loss = 0.361544
I0526 12:41:46.349761 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.361544 (* 1 = 0.361544 loss)
I0526 12:41:46.349768 15394 sgd_solver.cpp:43] Iteration 50590, lr = 0.0002
I0526 12:41:51.334163 15394 main.cpp:465] Iteration 50600, Testing net (#0)
I0526 12:42:04.428351 15394 main.cpp:532]     Test net output #0: Accuracy = 0.894
I0526 12:42:04.428391 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.334733 (* 1 = 0.334733 loss)
I0526 12:42:04.858196 15394 main.cpp:354] Iteration 50600, loss = 0.314288
I0526 12:42:04.858237 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.314287 (* 1 = 0.314287 loss)
I0526 12:42:04.858247 15394 sgd_solver.cpp:43] Iteration 50600, lr = 0.0002
I0526 12:42:09.295925 15394 main.cpp:354] Iteration 50610, loss = 0.213954
I0526 12:42:09.295967 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.213954 (* 1 = 0.213954 loss)
I0526 12:42:09.295974 15394 sgd_solver.cpp:43] Iteration 50610, lr = 0.0002
I0526 12:42:14.386006 15394 main.cpp:354] Iteration 50620, loss = 0.28359
I0526 12:42:14.386047 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.28359 (* 1 = 0.28359 loss)
I0526 12:42:14.386054 15394 sgd_solver.cpp:43] Iteration 50620, lr = 0.0002
I0526 12:42:19.988443 15394 main.cpp:354] Iteration 50630, loss = 0.12508
I0526 12:42:19.988487 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.125079 (* 1 = 0.125079 loss)
I0526 12:42:19.988495 15394 sgd_solver.cpp:43] Iteration 50630, lr = 0.0002
I0526 12:42:25.226035 15394 main.cpp:354] Iteration 50640, loss = 0.281837
I0526 12:42:25.226074 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.281836 (* 1 = 0.281836 loss)
I0526 12:42:25.226080 15394 sgd_solver.cpp:43] Iteration 50640, lr = 0.0002
I0526 12:42:30.574944 15394 main.cpp:354] Iteration 50650, loss = 0.343464
I0526 12:42:30.574985 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.343463 (* 1 = 0.343463 loss)
I0526 12:42:30.574992 15394 sgd_solver.cpp:43] Iteration 50650, lr = 0.0002
I0526 12:42:35.619258 15394 main.cpp:354] Iteration 50660, loss = 0.170456
I0526 12:42:35.619302 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.170455 (* 1 = 0.170455 loss)
I0526 12:42:35.619307 15394 sgd_solver.cpp:43] Iteration 50660, lr = 0.0002
I0526 12:42:40.741725 15394 main.cpp:354] Iteration 50670, loss = 0.0833525
I0526 12:42:40.741767 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.083352 (* 1 = 0.083352 loss)
I0526 12:42:40.741775 15394 sgd_solver.cpp:43] Iteration 50670, lr = 0.0002
I0526 12:42:45.644069 15394 main.cpp:354] Iteration 50680, loss = 0.268718
I0526 12:42:45.644107 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.268718 (* 1 = 0.268718 loss)
I0526 12:42:45.644114 15394 sgd_solver.cpp:43] Iteration 50680, lr = 0.0002
I0526 12:42:50.651876 15394 main.cpp:354] Iteration 50690, loss = 0.117699
I0526 12:42:50.651919 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.117698 (* 1 = 0.117698 loss)
I0526 12:42:50.651926 15394 sgd_solver.cpp:43] Iteration 50690, lr = 0.0002
I0526 12:42:55.400745 15394 main.cpp:465] Iteration 50700, Testing net (#0)
I0526 12:43:08.486289 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8934
I0526 12:43:08.486328 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.334074 (* 1 = 0.334074 loss)
I0526 12:43:09.025208 15394 main.cpp:354] Iteration 50700, loss = 0.200356
I0526 12:43:09.025249 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.200356 (* 1 = 0.200356 loss)
I0526 12:43:09.025257 15394 sgd_solver.cpp:43] Iteration 50700, lr = 0.0002
I0526 12:43:13.816265 15394 main.cpp:354] Iteration 50710, loss = 0.310868
I0526 12:43:13.816305 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.310868 (* 1 = 0.310868 loss)
I0526 12:43:13.816313 15394 sgd_solver.cpp:43] Iteration 50710, lr = 0.0002
I0526 12:43:18.561269 15394 main.cpp:354] Iteration 50720, loss = 0.217576
I0526 12:43:18.561311 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.217576 (* 1 = 0.217576 loss)
I0526 12:43:18.561317 15394 sgd_solver.cpp:43] Iteration 50720, lr = 0.0002
I0526 12:43:23.160775 15394 main.cpp:354] Iteration 50730, loss = 0.311227
I0526 12:43:23.160814 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.311227 (* 1 = 0.311227 loss)
I0526 12:43:23.160820 15394 sgd_solver.cpp:43] Iteration 50730, lr = 0.0002
I0526 12:43:28.168175 15394 main.cpp:354] Iteration 50740, loss = 0.198032
I0526 12:43:28.168216 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.198032 (* 1 = 0.198032 loss)
I0526 12:43:28.168223 15394 sgd_solver.cpp:43] Iteration 50740, lr = 0.0002
I0526 12:43:33.193583 15394 main.cpp:354] Iteration 50750, loss = 0.438633
I0526 12:43:33.193629 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.438632 (* 1 = 0.438632 loss)
I0526 12:43:33.193635 15394 sgd_solver.cpp:43] Iteration 50750, lr = 0.0002
I0526 12:43:38.534090 15394 main.cpp:354] Iteration 50760, loss = 0.109259
I0526 12:43:38.534131 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.109258 (* 1 = 0.109258 loss)
I0526 12:43:38.534137 15394 sgd_solver.cpp:43] Iteration 50760, lr = 0.0002
I0526 12:43:43.901538 15394 main.cpp:354] Iteration 50770, loss = 0.156017
I0526 12:43:43.901576 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.156017 (* 1 = 0.156017 loss)
I0526 12:43:43.901582 15394 sgd_solver.cpp:43] Iteration 50770, lr = 0.0002
I0526 12:43:49.053377 15394 main.cpp:354] Iteration 50780, loss = 0.119808
I0526 12:43:49.053421 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.119807 (* 1 = 0.119807 loss)
I0526 12:43:49.053426 15394 sgd_solver.cpp:43] Iteration 50780, lr = 0.0002
I0526 12:43:53.987347 15394 main.cpp:354] Iteration 50790, loss = 0.439418
I0526 12:43:53.987387 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.439417 (* 1 = 0.439417 loss)
I0526 12:43:53.987393 15394 sgd_solver.cpp:43] Iteration 50790, lr = 0.0002
I0526 12:43:58.384582 15394 main.cpp:465] Iteration 50800, Testing net (#0)
I0526 12:44:11.463687 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8956
I0526 12:44:11.463728 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.330764 (* 1 = 0.330764 loss)
I0526 12:44:11.898823 15394 main.cpp:354] Iteration 50800, loss = 0.163584
I0526 12:44:11.898862 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.163583 (* 1 = 0.163583 loss)
I0526 12:44:11.898876 15394 sgd_solver.cpp:43] Iteration 50800, lr = 0.0002
I0526 12:44:16.839763 15394 main.cpp:354] Iteration 50810, loss = 0.207746
I0526 12:44:16.839802 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.207746 (* 1 = 0.207746 loss)
I0526 12:44:16.839808 15394 sgd_solver.cpp:43] Iteration 50810, lr = 0.0002
I0526 12:44:21.873169 15394 main.cpp:354] Iteration 50820, loss = 0.292726
I0526 12:44:21.873209 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.292726 (* 1 = 0.292726 loss)
I0526 12:44:21.873215 15394 sgd_solver.cpp:43] Iteration 50820, lr = 0.0002
I0526 12:44:26.607986 15394 main.cpp:354] Iteration 50830, loss = 0.294341
I0526 12:44:26.608026 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.29434 (* 1 = 0.29434 loss)
I0526 12:44:26.608031 15394 sgd_solver.cpp:43] Iteration 50830, lr = 0.0002
I0526 12:44:32.142356 15394 main.cpp:354] Iteration 50840, loss = 0.147064
I0526 12:44:32.142398 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.147064 (* 1 = 0.147064 loss)
I0526 12:44:32.142406 15394 sgd_solver.cpp:43] Iteration 50840, lr = 0.0002
I0526 12:44:37.254904 15394 main.cpp:354] Iteration 50850, loss = 0.141757
I0526 12:44:37.254943 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.141756 (* 1 = 0.141756 loss)
I0526 12:44:37.254951 15394 sgd_solver.cpp:43] Iteration 50850, lr = 0.0002
I0526 12:44:42.421171 15394 main.cpp:354] Iteration 50860, loss = 0.190302
I0526 12:44:42.421213 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.190302 (* 1 = 0.190302 loss)
I0526 12:44:42.421219 15394 sgd_solver.cpp:43] Iteration 50860, lr = 0.0002
I0526 12:44:47.150311 15394 main.cpp:354] Iteration 50870, loss = 0.208506
I0526 12:44:47.150343 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.208505 (* 1 = 0.208505 loss)
I0526 12:44:47.150352 15394 sgd_solver.cpp:43] Iteration 50870, lr = 0.0002
I0526 12:44:52.498162 15394 main.cpp:354] Iteration 50880, loss = 0.197026
I0526 12:44:52.498203 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.197025 (* 1 = 0.197025 loss)
I0526 12:44:52.498209 15394 sgd_solver.cpp:43] Iteration 50880, lr = 0.0002
I0526 12:44:57.475594 15394 main.cpp:354] Iteration 50890, loss = 0.186874
I0526 12:44:57.475635 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186874 (* 1 = 0.186874 loss)
I0526 12:44:57.475641 15394 sgd_solver.cpp:43] Iteration 50890, lr = 0.0002
I0526 12:45:01.816359 15394 main.cpp:465] Iteration 50900, Testing net (#0)
I0526 12:45:14.898399 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8946
I0526 12:45:14.898442 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.33348 (* 1 = 0.33348 loss)
I0526 12:45:15.364099 15394 main.cpp:354] Iteration 50900, loss = 0.190156
I0526 12:45:15.364132 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.190155 (* 1 = 0.190155 loss)
I0526 12:45:15.364140 15394 sgd_solver.cpp:43] Iteration 50900, lr = 0.0002
I0526 12:45:20.384218 15394 main.cpp:354] Iteration 50910, loss = 0.187439
I0526 12:45:20.384260 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187439 (* 1 = 0.187439 loss)
I0526 12:45:20.384266 15394 sgd_solver.cpp:43] Iteration 50910, lr = 0.0002
I0526 12:45:25.805243 15394 main.cpp:354] Iteration 50920, loss = 0.0922176
I0526 12:45:25.805284 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0922171 (* 1 = 0.0922171 loss)
I0526 12:45:25.805291 15394 sgd_solver.cpp:43] Iteration 50920, lr = 0.0002
I0526 12:45:31.289924 15394 main.cpp:354] Iteration 50930, loss = 0.179854
I0526 12:45:31.289963 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.179854 (* 1 = 0.179854 loss)
I0526 12:45:31.289970 15394 sgd_solver.cpp:43] Iteration 50930, lr = 0.0002
I0526 12:45:36.728559 15394 main.cpp:354] Iteration 50940, loss = 0.270898
I0526 12:45:36.728602 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.270898 (* 1 = 0.270898 loss)
I0526 12:45:36.728612 15394 sgd_solver.cpp:43] Iteration 50940, lr = 0.0002
I0526 12:45:41.479068 15394 main.cpp:354] Iteration 50950, loss = 0.255726
I0526 12:45:41.479107 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.255725 (* 1 = 0.255725 loss)
I0526 12:45:41.479113 15394 sgd_solver.cpp:43] Iteration 50950, lr = 0.0002
I0526 12:45:46.564745 15394 main.cpp:354] Iteration 50960, loss = 0.238119
I0526 12:45:46.564785 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.238119 (* 1 = 0.238119 loss)
I0526 12:45:46.564790 15394 sgd_solver.cpp:43] Iteration 50960, lr = 0.0002
I0526 12:45:51.825353 15394 main.cpp:354] Iteration 50970, loss = 0.416125
I0526 12:45:51.825394 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.416125 (* 1 = 0.416125 loss)
I0526 12:45:51.825400 15394 sgd_solver.cpp:43] Iteration 50970, lr = 0.0002
I0526 12:45:56.846874 15394 main.cpp:354] Iteration 50980, loss = 0.21632
I0526 12:45:56.846936 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.21632 (* 1 = 0.21632 loss)
I0526 12:45:56.846943 15394 sgd_solver.cpp:43] Iteration 50980, lr = 0.0002
I0526 12:46:02.002032 15394 main.cpp:354] Iteration 50990, loss = 0.168582
I0526 12:46:02.002074 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.168581 (* 1 = 0.168581 loss)
I0526 12:46:02.002082 15394 sgd_solver.cpp:43] Iteration 50990, lr = 0.0002
I0526 12:46:06.145741 15394 main.cpp:465] Iteration 51000, Testing net (#0)
I0526 12:46:19.232547 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8962
I0526 12:46:19.232586 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.330086 (* 1 = 0.330086 loss)
I0526 12:46:19.670501 15394 main.cpp:354] Iteration 51000, loss = 0.178738
I0526 12:46:19.670545 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.178738 (* 1 = 0.178738 loss)
I0526 12:46:19.670553 15394 sgd_solver.cpp:43] Iteration 51000, lr = 0.0002
I0526 12:46:25.006160 15394 main.cpp:354] Iteration 51010, loss = 0.140677
I0526 12:46:25.006211 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.140677 (* 1 = 0.140677 loss)
I0526 12:46:25.006218 15394 sgd_solver.cpp:43] Iteration 51010, lr = 0.0002
I0526 12:46:29.874627 15394 main.cpp:354] Iteration 51020, loss = 0.164799
I0526 12:46:29.874680 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.164799 (* 1 = 0.164799 loss)
I0526 12:46:29.874686 15394 sgd_solver.cpp:43] Iteration 51020, lr = 0.0002
I0526 12:46:35.265684 15394 main.cpp:354] Iteration 51030, loss = 0.192635
I0526 12:46:35.265727 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.192635 (* 1 = 0.192635 loss)
I0526 12:46:35.265733 15394 sgd_solver.cpp:43] Iteration 51030, lr = 0.0002
I0526 12:46:40.581315 15394 main.cpp:354] Iteration 51040, loss = 0.283735
I0526 12:46:40.581363 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.283734 (* 1 = 0.283734 loss)
I0526 12:46:40.581370 15394 sgd_solver.cpp:43] Iteration 51040, lr = 0.0002
I0526 12:46:45.575162 15394 main.cpp:354] Iteration 51050, loss = 0.151071
I0526 12:46:45.575199 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.151071 (* 1 = 0.151071 loss)
I0526 12:46:45.575206 15394 sgd_solver.cpp:43] Iteration 51050, lr = 0.0002
I0526 12:46:50.101310 15394 main.cpp:354] Iteration 51060, loss = 0.344026
I0526 12:46:50.101354 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.344025 (* 1 = 0.344025 loss)
I0526 12:46:50.101361 15394 sgd_solver.cpp:43] Iteration 51060, lr = 0.0002
I0526 12:46:55.108276 15394 main.cpp:354] Iteration 51070, loss = 0.367088
I0526 12:46:55.108314 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.367087 (* 1 = 0.367087 loss)
I0526 12:46:55.108320 15394 sgd_solver.cpp:43] Iteration 51070, lr = 0.0002
I0526 12:47:00.064388 15394 main.cpp:354] Iteration 51080, loss = 0.150405
I0526 12:47:00.064427 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.150405 (* 1 = 0.150405 loss)
I0526 12:47:00.064435 15394 sgd_solver.cpp:43] Iteration 51080, lr = 0.0002
I0526 12:47:05.354059 15394 main.cpp:354] Iteration 51090, loss = 0.155327
I0526 12:47:05.354104 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.155326 (* 1 = 0.155326 loss)
I0526 12:47:05.354110 15394 sgd_solver.cpp:43] Iteration 51090, lr = 0.0002
I0526 12:47:09.973084 15394 main.cpp:465] Iteration 51100, Testing net (#0)
I0526 12:47:23.055593 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8934
I0526 12:47:23.055639 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.338313 (* 1 = 0.338313 loss)
I0526 12:47:23.455828 15394 main.cpp:354] Iteration 51100, loss = 0.207906
I0526 12:47:23.455868 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.207906 (* 1 = 0.207906 loss)
I0526 12:47:23.455875 15394 sgd_solver.cpp:43] Iteration 51100, lr = 0.0002
I0526 12:47:28.291456 15394 main.cpp:354] Iteration 51110, loss = 0.165848
I0526 12:47:28.291497 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.165847 (* 1 = 0.165847 loss)
I0526 12:47:28.291504 15394 sgd_solver.cpp:43] Iteration 51110, lr = 0.0002
I0526 12:47:33.075047 15394 main.cpp:354] Iteration 51120, loss = 0.310117
I0526 12:47:33.075090 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.310116 (* 1 = 0.310116 loss)
I0526 12:47:33.075096 15394 sgd_solver.cpp:43] Iteration 51120, lr = 0.0002
I0526 12:47:38.364598 15394 main.cpp:354] Iteration 51130, loss = 0.210036
I0526 12:47:38.364639 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.210035 (* 1 = 0.210035 loss)
I0526 12:47:38.364646 15394 sgd_solver.cpp:43] Iteration 51130, lr = 0.0002
I0526 12:47:43.220679 15394 main.cpp:354] Iteration 51140, loss = 0.273484
I0526 12:47:43.220718 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.273483 (* 1 = 0.273483 loss)
I0526 12:47:43.220724 15394 sgd_solver.cpp:43] Iteration 51140, lr = 0.0002
I0526 12:47:48.492756 15394 main.cpp:354] Iteration 51150, loss = 0.13394
I0526 12:47:48.492797 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.133939 (* 1 = 0.133939 loss)
I0526 12:47:48.492804 15394 sgd_solver.cpp:43] Iteration 51150, lr = 0.0002
I0526 12:47:53.225555 15394 main.cpp:354] Iteration 51160, loss = 0.582472
I0526 12:47:53.225594 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.582471 (* 1 = 0.582471 loss)
I0526 12:47:53.225600 15394 sgd_solver.cpp:43] Iteration 51160, lr = 0.0002
I0526 12:47:58.623522 15394 main.cpp:354] Iteration 51170, loss = 0.104664
I0526 12:47:58.623560 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.104663 (* 1 = 0.104663 loss)
I0526 12:47:58.623566 15394 sgd_solver.cpp:43] Iteration 51170, lr = 0.0002
I0526 12:48:03.827033 15394 main.cpp:354] Iteration 51180, loss = 0.163974
I0526 12:48:03.827076 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.163973 (* 1 = 0.163973 loss)
I0526 12:48:03.827082 15394 sgd_solver.cpp:43] Iteration 51180, lr = 0.0002
I0526 12:48:08.994783 15394 main.cpp:354] Iteration 51190, loss = 0.160808
I0526 12:48:08.994822 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.160808 (* 1 = 0.160808 loss)
I0526 12:48:08.994827 15394 sgd_solver.cpp:43] Iteration 51190, lr = 0.0002
I0526 12:48:13.369832 15394 main.cpp:465] Iteration 51200, Testing net (#0)
I0526 12:48:26.449529 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8942
I0526 12:48:26.449571 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.338317 (* 1 = 0.338317 loss)
I0526 12:48:26.881413 15394 main.cpp:354] Iteration 51200, loss = 0.233127
I0526 12:48:26.881456 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.233126 (* 1 = 0.233126 loss)
I0526 12:48:26.881464 15394 sgd_solver.cpp:43] Iteration 51200, lr = 0.0002
I0526 12:48:32.159590 15394 main.cpp:354] Iteration 51210, loss = 0.273875
I0526 12:48:32.159633 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.273875 (* 1 = 0.273875 loss)
I0526 12:48:32.159641 15394 sgd_solver.cpp:43] Iteration 51210, lr = 0.0002
I0526 12:48:36.977624 15394 main.cpp:354] Iteration 51220, loss = 0.32455
I0526 12:48:36.977668 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.32455 (* 1 = 0.32455 loss)
I0526 12:48:36.977674 15394 sgd_solver.cpp:43] Iteration 51220, lr = 0.0002
I0526 12:48:42.005725 15394 main.cpp:354] Iteration 51230, loss = 0.243395
I0526 12:48:42.005765 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.243394 (* 1 = 0.243394 loss)
I0526 12:48:42.005771 15394 sgd_solver.cpp:43] Iteration 51230, lr = 0.0002
I0526 12:48:47.144825 15394 main.cpp:354] Iteration 51240, loss = 0.19879
I0526 12:48:47.144860 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.198789 (* 1 = 0.198789 loss)
I0526 12:48:47.144867 15394 sgd_solver.cpp:43] Iteration 51240, lr = 0.0002
I0526 12:48:52.373100 15394 main.cpp:354] Iteration 51250, loss = 0.203632
I0526 12:48:52.373137 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.203632 (* 1 = 0.203632 loss)
I0526 12:48:52.373143 15394 sgd_solver.cpp:43] Iteration 51250, lr = 0.0002
I0526 12:48:57.713433 15394 main.cpp:354] Iteration 51260, loss = 0.145059
I0526 12:48:57.713471 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.145058 (* 1 = 0.145058 loss)
I0526 12:48:57.713477 15394 sgd_solver.cpp:43] Iteration 51260, lr = 0.0002
I0526 12:49:02.660434 15394 main.cpp:354] Iteration 51270, loss = 0.157434
I0526 12:49:02.660477 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.157434 (* 1 = 0.157434 loss)
I0526 12:49:02.660483 15394 sgd_solver.cpp:43] Iteration 51270, lr = 0.0002
I0526 12:49:07.268018 15394 main.cpp:354] Iteration 51280, loss = 0.208785
I0526 12:49:07.268055 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.208784 (* 1 = 0.208784 loss)
I0526 12:49:07.268061 15394 sgd_solver.cpp:43] Iteration 51280, lr = 0.0002
I0526 12:49:12.121093 15394 main.cpp:354] Iteration 51290, loss = 0.21565
I0526 12:49:12.121125 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.215649 (* 1 = 0.215649 loss)
I0526 12:49:12.121131 15394 sgd_solver.cpp:43] Iteration 51290, lr = 0.0002
I0526 12:49:17.382382 15394 main.cpp:465] Iteration 51300, Testing net (#0)
I0526 12:49:30.463366 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8957
I0526 12:49:30.463402 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.332689 (* 1 = 0.332689 loss)
I0526 12:49:30.899875 15394 main.cpp:354] Iteration 51300, loss = 0.324549
I0526 12:49:30.899924 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.324549 (* 1 = 0.324549 loss)
I0526 12:49:30.899930 15394 sgd_solver.cpp:43] Iteration 51300, lr = 0.0002
I0526 12:49:35.862772 15394 main.cpp:354] Iteration 51310, loss = 0.511146
I0526 12:49:35.862814 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.511145 (* 1 = 0.511145 loss)
I0526 12:49:35.862819 15394 sgd_solver.cpp:43] Iteration 51310, lr = 0.0002
I0526 12:49:40.739785 15394 main.cpp:354] Iteration 51320, loss = 0.167938
I0526 12:49:40.739825 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.167938 (* 1 = 0.167938 loss)
I0526 12:49:40.739831 15394 sgd_solver.cpp:43] Iteration 51320, lr = 0.0002
I0526 12:49:46.078251 15394 main.cpp:354] Iteration 51330, loss = 0.158859
I0526 12:49:46.078292 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.158858 (* 1 = 0.158858 loss)
I0526 12:49:46.078299 15394 sgd_solver.cpp:43] Iteration 51330, lr = 0.0002
I0526 12:49:51.323038 15394 main.cpp:354] Iteration 51340, loss = 0.311119
I0526 12:49:51.323081 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.311119 (* 1 = 0.311119 loss)
I0526 12:49:51.323087 15394 sgd_solver.cpp:43] Iteration 51340, lr = 0.0002
I0526 12:49:56.412122 15394 main.cpp:354] Iteration 51350, loss = 0.188745
I0526 12:49:56.412160 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.188745 (* 1 = 0.188745 loss)
I0526 12:49:56.412168 15394 sgd_solver.cpp:43] Iteration 51350, lr = 0.0002
I0526 12:50:01.580620 15394 main.cpp:354] Iteration 51360, loss = 0.231429
I0526 12:50:01.580662 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.231429 (* 1 = 0.231429 loss)
I0526 12:50:01.580673 15394 sgd_solver.cpp:43] Iteration 51360, lr = 0.0002
I0526 12:50:06.422070 15394 main.cpp:354] Iteration 51370, loss = 0.186184
I0526 12:50:06.422111 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186184 (* 1 = 0.186184 loss)
I0526 12:50:06.422118 15394 sgd_solver.cpp:43] Iteration 51370, lr = 0.0002
I0526 12:50:11.163637 15394 main.cpp:354] Iteration 51380, loss = 0.308053
I0526 12:50:11.163676 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.308053 (* 1 = 0.308053 loss)
I0526 12:50:11.163681 15394 sgd_solver.cpp:43] Iteration 51380, lr = 0.0002
I0526 12:50:16.030879 15394 main.cpp:354] Iteration 51390, loss = 0.224549
I0526 12:50:16.030916 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.224549 (* 1 = 0.224549 loss)
I0526 12:50:16.030922 15394 sgd_solver.cpp:43] Iteration 51390, lr = 0.0002
I0526 12:50:20.409548 15394 main.cpp:465] Iteration 51400, Testing net (#0)
I0526 12:50:33.489828 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8963
I0526 12:50:33.489873 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.328908 (* 1 = 0.328908 loss)
I0526 12:50:33.858422 15394 main.cpp:354] Iteration 51400, loss = 0.451394
I0526 12:50:33.858454 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.451393 (* 1 = 0.451393 loss)
I0526 12:50:33.858464 15394 sgd_solver.cpp:43] Iteration 51400, lr = 0.0002
I0526 12:50:38.841011 15394 main.cpp:354] Iteration 51410, loss = 0.141155
I0526 12:50:38.841049 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.141155 (* 1 = 0.141155 loss)
I0526 12:50:38.841055 15394 sgd_solver.cpp:43] Iteration 51410, lr = 0.0002
I0526 12:50:43.990850 15394 main.cpp:354] Iteration 51420, loss = 0.261055
I0526 12:50:43.990890 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.261055 (* 1 = 0.261055 loss)
I0526 12:50:43.990897 15394 sgd_solver.cpp:43] Iteration 51420, lr = 0.0002
I0526 12:50:49.290588 15394 main.cpp:354] Iteration 51430, loss = 0.186573
I0526 12:50:49.290633 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186572 (* 1 = 0.186572 loss)
I0526 12:50:49.290639 15394 sgd_solver.cpp:43] Iteration 51430, lr = 0.0002
I0526 12:50:54.434172 15394 main.cpp:354] Iteration 51440, loss = 0.213202
I0526 12:50:54.434224 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.213201 (* 1 = 0.213201 loss)
I0526 12:50:54.434231 15394 sgd_solver.cpp:43] Iteration 51440, lr = 0.0002
I0526 12:50:59.297592 15394 main.cpp:354] Iteration 51450, loss = 0.232242
I0526 12:50:59.297631 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.232241 (* 1 = 0.232241 loss)
I0526 12:50:59.297637 15394 sgd_solver.cpp:43] Iteration 51450, lr = 0.0002
I0526 12:51:04.380708 15394 main.cpp:354] Iteration 51460, loss = 0.187633
I0526 12:51:04.380753 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187632 (* 1 = 0.187632 loss)
I0526 12:51:04.380759 15394 sgd_solver.cpp:43] Iteration 51460, lr = 0.0002
I0526 12:51:09.046952 15394 main.cpp:354] Iteration 51470, loss = 0.258608
I0526 12:51:09.046993 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.258608 (* 1 = 0.258608 loss)
I0526 12:51:09.046998 15394 sgd_solver.cpp:43] Iteration 51470, lr = 0.0002
I0526 12:51:14.407918 15394 main.cpp:354] Iteration 51480, loss = 0.0595283
I0526 12:51:14.407960 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0595278 (* 1 = 0.0595278 loss)
I0526 12:51:14.407968 15394 sgd_solver.cpp:43] Iteration 51480, lr = 0.0002
I0526 12:51:18.894496 15394 main.cpp:354] Iteration 51490, loss = 0.121449
I0526 12:51:18.894541 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.121448 (* 1 = 0.121448 loss)
I0526 12:51:18.894548 15394 sgd_solver.cpp:43] Iteration 51490, lr = 0.0002
I0526 12:51:23.356753 15394 main.cpp:465] Iteration 51500, Testing net (#0)
I0526 12:51:36.448552 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8961
I0526 12:51:36.448595 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.328787 (* 1 = 0.328787 loss)
I0526 12:51:36.990104 15394 main.cpp:354] Iteration 51500, loss = 0.222563
I0526 12:51:36.990137 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.222563 (* 1 = 0.222563 loss)
I0526 12:51:36.990146 15394 sgd_solver.cpp:43] Iteration 51500, lr = 0.0002
I0526 12:51:42.148170 15394 main.cpp:354] Iteration 51510, loss = 0.172533
I0526 12:51:42.148212 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.172533 (* 1 = 0.172533 loss)
I0526 12:51:42.148218 15394 sgd_solver.cpp:43] Iteration 51510, lr = 0.0002
I0526 12:51:47.018442 15394 main.cpp:354] Iteration 51520, loss = 0.201252
I0526 12:51:47.018484 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.201252 (* 1 = 0.201252 loss)
I0526 12:51:47.018491 15394 sgd_solver.cpp:43] Iteration 51520, lr = 0.0002
I0526 12:51:52.456554 15394 main.cpp:354] Iteration 51530, loss = 0.18712
I0526 12:51:52.456593 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187119 (* 1 = 0.187119 loss)
I0526 12:51:52.456598 15394 sgd_solver.cpp:43] Iteration 51530, lr = 0.0002
I0526 12:51:57.639705 15394 main.cpp:354] Iteration 51540, loss = 0.140483
I0526 12:51:57.639750 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.140482 (* 1 = 0.140482 loss)
I0526 12:51:57.639756 15394 sgd_solver.cpp:43] Iteration 51540, lr = 0.0002
I0526 12:52:02.893692 15394 main.cpp:354] Iteration 51550, loss = 0.231688
I0526 12:52:02.893733 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.231688 (* 1 = 0.231688 loss)
I0526 12:52:02.893738 15394 sgd_solver.cpp:43] Iteration 51550, lr = 0.0002
I0526 12:52:07.569306 15394 main.cpp:354] Iteration 51560, loss = 0.328208
I0526 12:52:07.569344 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.328208 (* 1 = 0.328208 loss)
I0526 12:52:07.569351 15394 sgd_solver.cpp:43] Iteration 51560, lr = 0.0002
I0526 12:52:12.369329 15394 main.cpp:354] Iteration 51570, loss = 0.182675
I0526 12:52:12.369374 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.182675 (* 1 = 0.182675 loss)
I0526 12:52:12.369382 15394 sgd_solver.cpp:43] Iteration 51570, lr = 0.0002
I0526 12:52:17.239881 15394 main.cpp:354] Iteration 51580, loss = 0.135205
I0526 12:52:17.239923 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.135204 (* 1 = 0.135204 loss)
I0526 12:52:17.239929 15394 sgd_solver.cpp:43] Iteration 51580, lr = 0.0002
I0526 12:52:22.403815 15394 main.cpp:354] Iteration 51590, loss = 0.157454
I0526 12:52:22.403854 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.157453 (* 1 = 0.157453 loss)
I0526 12:52:22.403861 15394 sgd_solver.cpp:43] Iteration 51590, lr = 0.0002
I0526 12:52:26.976091 15394 main.cpp:465] Iteration 51600, Testing net (#0)
I0526 12:52:40.066933 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8932
I0526 12:52:40.066962 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.329227 (* 1 = 0.329227 loss)
I0526 12:52:40.605578 15394 main.cpp:354] Iteration 51600, loss = 0.0877293
I0526 12:52:40.605607 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0877288 (* 1 = 0.0877288 loss)
I0526 12:52:40.605615 15394 sgd_solver.cpp:43] Iteration 51600, lr = 0.0002
I0526 12:52:45.708781 15394 main.cpp:354] Iteration 51610, loss = 0.303878
I0526 12:52:45.708819 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.303877 (* 1 = 0.303877 loss)
I0526 12:52:45.708827 15394 sgd_solver.cpp:43] Iteration 51610, lr = 0.0002
I0526 12:52:50.537761 15394 main.cpp:354] Iteration 51620, loss = 0.193009
I0526 12:52:50.537797 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.193009 (* 1 = 0.193009 loss)
I0526 12:52:50.537803 15394 sgd_solver.cpp:43] Iteration 51620, lr = 0.0002
I0526 12:52:55.244490 15394 main.cpp:354] Iteration 51630, loss = 0.284775
I0526 12:52:55.244532 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.284774 (* 1 = 0.284774 loss)
I0526 12:52:55.244539 15394 sgd_solver.cpp:43] Iteration 51630, lr = 0.0002
I0526 12:53:00.423768 15394 main.cpp:354] Iteration 51640, loss = 0.25731
I0526 12:53:00.423807 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.257309 (* 1 = 0.257309 loss)
I0526 12:53:00.423813 15394 sgd_solver.cpp:43] Iteration 51640, lr = 0.0002
I0526 12:53:05.361723 15394 main.cpp:354] Iteration 51650, loss = 0.106223
I0526 12:53:05.361759 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.106223 (* 1 = 0.106223 loss)
I0526 12:53:05.361766 15394 sgd_solver.cpp:43] Iteration 51650, lr = 0.0002
I0526 12:53:10.317633 15394 main.cpp:354] Iteration 51660, loss = 0.161826
I0526 12:53:10.317673 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.161826 (* 1 = 0.161826 loss)
I0526 12:53:10.317682 15394 sgd_solver.cpp:43] Iteration 51660, lr = 0.0002
I0526 12:53:15.006933 15394 main.cpp:354] Iteration 51670, loss = 0.484078
I0526 12:53:15.006973 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.484078 (* 1 = 0.484078 loss)
I0526 12:53:15.006978 15394 sgd_solver.cpp:43] Iteration 51670, lr = 0.0002
I0526 12:53:20.627297 15394 main.cpp:354] Iteration 51680, loss = 0.124349
I0526 12:53:20.627336 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.124348 (* 1 = 0.124348 loss)
I0526 12:53:20.627343 15394 sgd_solver.cpp:43] Iteration 51680, lr = 0.0002
I0526 12:53:26.023026 15394 main.cpp:354] Iteration 51690, loss = 0.246134
I0526 12:53:26.023068 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.246134 (* 1 = 0.246134 loss)
I0526 12:53:26.023074 15394 sgd_solver.cpp:43] Iteration 51690, lr = 0.0002
I0526 12:53:30.470095 15394 main.cpp:465] Iteration 51700, Testing net (#0)
I0526 12:53:43.558285 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8953
I0526 12:53:43.558329 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.331923 (* 1 = 0.331923 loss)
I0526 12:53:44.034814 15394 main.cpp:354] Iteration 51700, loss = 0.232557
I0526 12:53:44.034857 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.232556 (* 1 = 0.232556 loss)
I0526 12:53:44.034867 15394 sgd_solver.cpp:43] Iteration 51700, lr = 0.0002
I0526 12:53:49.096194 15394 main.cpp:354] Iteration 51710, loss = 0.560854
I0526 12:53:49.096233 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.560854 (* 1 = 0.560854 loss)
I0526 12:53:49.096240 15394 sgd_solver.cpp:43] Iteration 51710, lr = 0.0002
I0526 12:53:54.117661 15394 main.cpp:354] Iteration 51720, loss = 0.29846
I0526 12:53:54.117702 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.298459 (* 1 = 0.298459 loss)
I0526 12:53:54.117708 15394 sgd_solver.cpp:43] Iteration 51720, lr = 0.0002
I0526 12:53:59.270577 15394 main.cpp:354] Iteration 51730, loss = 0.295842
I0526 12:53:59.270622 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.295841 (* 1 = 0.295841 loss)
I0526 12:53:59.270628 15394 sgd_solver.cpp:43] Iteration 51730, lr = 0.0002
I0526 12:54:04.292353 15394 main.cpp:354] Iteration 51740, loss = 0.263259
I0526 12:54:04.292393 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.263258 (* 1 = 0.263258 loss)
I0526 12:54:04.292399 15394 sgd_solver.cpp:43] Iteration 51740, lr = 0.0002
I0526 12:54:09.314561 15394 main.cpp:354] Iteration 51750, loss = 0.126023
I0526 12:54:09.314601 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.126022 (* 1 = 0.126022 loss)
I0526 12:54:09.314607 15394 sgd_solver.cpp:43] Iteration 51750, lr = 0.0002
I0526 12:54:14.598709 15394 main.cpp:354] Iteration 51760, loss = 0.118674
I0526 12:54:14.598749 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.118674 (* 1 = 0.118674 loss)
I0526 12:54:14.598757 15394 sgd_solver.cpp:43] Iteration 51760, lr = 0.0002
I0526 12:54:20.115236 15394 main.cpp:354] Iteration 51770, loss = 0.219871
I0526 12:54:20.115277 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.21987 (* 1 = 0.21987 loss)
I0526 12:54:20.115283 15394 sgd_solver.cpp:43] Iteration 51770, lr = 0.0002
I0526 12:54:25.088618 15394 main.cpp:354] Iteration 51780, loss = 0.182347
I0526 12:54:25.088660 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.182346 (* 1 = 0.182346 loss)
I0526 12:54:25.088667 15394 sgd_solver.cpp:43] Iteration 51780, lr = 0.0002
I0526 12:54:29.857723 15394 main.cpp:354] Iteration 51790, loss = 0.307995
I0526 12:54:29.857766 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.307995 (* 1 = 0.307995 loss)
I0526 12:54:29.857774 15394 sgd_solver.cpp:43] Iteration 51790, lr = 0.0002
I0526 12:54:34.498484 15394 main.cpp:465] Iteration 51800, Testing net (#0)
I0526 12:54:47.584481 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8929
I0526 12:54:47.584524 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.3351 (* 1 = 0.3351 loss)
I0526 12:54:48.019002 15394 main.cpp:354] Iteration 51800, loss = 0.334056
I0526 12:54:48.019047 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.334056 (* 1 = 0.334056 loss)
I0526 12:54:48.019055 15394 sgd_solver.cpp:43] Iteration 51800, lr = 0.0002
I0526 12:54:53.244092 15394 main.cpp:354] Iteration 51810, loss = 0.228347
I0526 12:54:53.244132 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.228347 (* 1 = 0.228347 loss)
I0526 12:54:53.244139 15394 sgd_solver.cpp:43] Iteration 51810, lr = 0.0002
I0526 12:54:58.251857 15394 main.cpp:354] Iteration 51820, loss = 0.505341
I0526 12:54:58.251901 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.505341 (* 1 = 0.505341 loss)
I0526 12:54:58.251909 15394 sgd_solver.cpp:43] Iteration 51820, lr = 0.0002
I0526 12:55:03.525307 15394 main.cpp:354] Iteration 51830, loss = 0.177191
I0526 12:55:03.525349 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.177191 (* 1 = 0.177191 loss)
I0526 12:55:03.525357 15394 sgd_solver.cpp:43] Iteration 51830, lr = 0.0002
I0526 12:55:08.964398 15394 main.cpp:354] Iteration 51840, loss = 0.111249
I0526 12:55:08.964442 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.111248 (* 1 = 0.111248 loss)
I0526 12:55:08.964449 15394 sgd_solver.cpp:43] Iteration 51840, lr = 0.0002
I0526 12:55:14.092651 15394 main.cpp:354] Iteration 51850, loss = 0.135718
I0526 12:55:14.092691 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.135717 (* 1 = 0.135717 loss)
I0526 12:55:14.092699 15394 sgd_solver.cpp:43] Iteration 51850, lr = 0.0002
I0526 12:55:19.058303 15394 main.cpp:354] Iteration 51860, loss = 0.294491
I0526 12:55:19.058346 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.29449 (* 1 = 0.29449 loss)
I0526 12:55:19.058351 15394 sgd_solver.cpp:43] Iteration 51860, lr = 0.0002
I0526 12:55:24.087997 15394 main.cpp:354] Iteration 51870, loss = 0.225704
I0526 12:55:24.088027 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.225703 (* 1 = 0.225703 loss)
I0526 12:55:24.088033 15394 sgd_solver.cpp:43] Iteration 51870, lr = 0.0002
I0526 12:55:29.461475 15394 main.cpp:354] Iteration 51880, loss = 0.155728
I0526 12:55:29.461516 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.155728 (* 1 = 0.155728 loss)
I0526 12:55:29.461524 15394 sgd_solver.cpp:43] Iteration 51880, lr = 0.0002
I0526 12:55:34.335520 15394 main.cpp:354] Iteration 51890, loss = 0.117971
I0526 12:55:34.335561 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.117971 (* 1 = 0.117971 loss)
I0526 12:55:34.335567 15394 sgd_solver.cpp:43] Iteration 51890, lr = 0.0002
I0526 12:55:38.845857 15394 main.cpp:465] Iteration 51900, Testing net (#0)
I0526 12:55:51.930299 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8932
I0526 12:55:51.930341 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.337439 (* 1 = 0.337439 loss)
I0526 12:55:52.370615 15394 main.cpp:354] Iteration 51900, loss = 0.294811
I0526 12:55:52.370657 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.294811 (* 1 = 0.294811 loss)
I0526 12:55:52.370666 15394 sgd_solver.cpp:43] Iteration 51900, lr = 0.0002
I0526 12:55:57.615154 15394 main.cpp:354] Iteration 51910, loss = 0.29543
I0526 12:55:57.615191 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.295429 (* 1 = 0.295429 loss)
I0526 12:55:57.615205 15394 sgd_solver.cpp:43] Iteration 51910, lr = 0.0002
I0526 12:56:02.456090 15394 main.cpp:354] Iteration 51920, loss = 0.285428
I0526 12:56:02.456135 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.285428 (* 1 = 0.285428 loss)
I0526 12:56:02.456142 15394 sgd_solver.cpp:43] Iteration 51920, lr = 0.0002
I0526 12:56:07.179713 15394 main.cpp:354] Iteration 51930, loss = 0.202132
I0526 12:56:07.179756 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.202131 (* 1 = 0.202131 loss)
I0526 12:56:07.179764 15394 sgd_solver.cpp:43] Iteration 51930, lr = 0.0002
I0526 12:56:12.277218 15394 main.cpp:354] Iteration 51940, loss = 0.201237
I0526 12:56:12.277257 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.201236 (* 1 = 0.201236 loss)
I0526 12:56:12.277264 15394 sgd_solver.cpp:43] Iteration 51940, lr = 0.0002
I0526 12:56:17.418231 15394 main.cpp:354] Iteration 51950, loss = 0.194564
I0526 12:56:17.418270 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.194563 (* 1 = 0.194563 loss)
I0526 12:56:17.418277 15394 sgd_solver.cpp:43] Iteration 51950, lr = 0.0002
I0526 12:56:22.760385 15394 main.cpp:354] Iteration 51960, loss = 0.122034
I0526 12:56:22.760427 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.122033 (* 1 = 0.122033 loss)
I0526 12:56:22.760434 15394 sgd_solver.cpp:43] Iteration 51960, lr = 0.0002
I0526 12:56:27.712391 15394 main.cpp:354] Iteration 51970, loss = 0.216475
I0526 12:56:27.712431 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.216475 (* 1 = 0.216475 loss)
I0526 12:56:27.712438 15394 sgd_solver.cpp:43] Iteration 51970, lr = 0.0002
I0526 12:56:32.916514 15394 main.cpp:354] Iteration 51980, loss = 0.193038
I0526 12:56:32.916553 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.193038 (* 1 = 0.193038 loss)
I0526 12:56:32.916558 15394 sgd_solver.cpp:43] Iteration 51980, lr = 0.0002
I0526 12:56:38.029713 15394 main.cpp:354] Iteration 51990, loss = 0.0983126
I0526 12:56:38.029757 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0983121 (* 1 = 0.0983121 loss)
I0526 12:56:38.029763 15394 sgd_solver.cpp:43] Iteration 51990, lr = 0.0002
I0526 12:56:42.284142 15394 main.cpp:465] Iteration 52000, Testing net (#0)
I0526 12:56:55.368255 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8963
I0526 12:56:55.368297 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.329336 (* 1 = 0.329336 loss)
I0526 12:56:55.837256 15394 main.cpp:354] Iteration 52000, loss = 0.302121
I0526 12:56:55.837296 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.302121 (* 1 = 0.302121 loss)
I0526 12:56:55.837304 15394 sgd_solver.cpp:43] Iteration 52000, lr = 0.0002
I0526 12:57:01.076087 15394 main.cpp:354] Iteration 52010, loss = 0.0936225
I0526 12:57:01.076128 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.093622 (* 1 = 0.093622 loss)
I0526 12:57:01.076134 15394 sgd_solver.cpp:43] Iteration 52010, lr = 0.0002
I0526 12:57:06.079380 15394 main.cpp:354] Iteration 52020, loss = 0.249776
I0526 12:57:06.079423 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.249776 (* 1 = 0.249776 loss)
I0526 12:57:06.079430 15394 sgd_solver.cpp:43] Iteration 52020, lr = 0.0002
I0526 12:57:11.302736 15394 main.cpp:354] Iteration 52030, loss = 0.382275
I0526 12:57:11.302778 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.382275 (* 1 = 0.382275 loss)
I0526 12:57:11.302785 15394 sgd_solver.cpp:43] Iteration 52030, lr = 0.0002
I0526 12:57:16.603636 15394 main.cpp:354] Iteration 52040, loss = 0.182223
I0526 12:57:16.603677 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.182223 (* 1 = 0.182223 loss)
I0526 12:57:16.603683 15394 sgd_solver.cpp:43] Iteration 52040, lr = 0.0002
I0526 12:57:22.138568 15394 main.cpp:354] Iteration 52050, loss = 0.11455
I0526 12:57:22.138612 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.114549 (* 1 = 0.114549 loss)
I0526 12:57:22.138625 15394 sgd_solver.cpp:43] Iteration 52050, lr = 0.0002
I0526 12:57:27.267073 15394 main.cpp:354] Iteration 52060, loss = 0.401953
I0526 12:57:27.267113 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.401952 (* 1 = 0.401952 loss)
I0526 12:57:27.267119 15394 sgd_solver.cpp:43] Iteration 52060, lr = 0.0002
I0526 12:57:32.188802 15394 main.cpp:354] Iteration 52070, loss = 0.222364
I0526 12:57:32.188843 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.222364 (* 1 = 0.222364 loss)
I0526 12:57:32.188849 15394 sgd_solver.cpp:43] Iteration 52070, lr = 0.0002
I0526 12:57:37.273792 15394 main.cpp:354] Iteration 52080, loss = 0.192224
I0526 12:57:37.273835 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.192224 (* 1 = 0.192224 loss)
I0526 12:57:37.273843 15394 sgd_solver.cpp:43] Iteration 52080, lr = 0.0002
I0526 12:57:42.443878 15394 main.cpp:354] Iteration 52090, loss = 0.147377
I0526 12:57:42.443919 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.147376 (* 1 = 0.147376 loss)
I0526 12:57:42.443925 15394 sgd_solver.cpp:43] Iteration 52090, lr = 0.0002
I0526 12:57:47.386472 15394 main.cpp:465] Iteration 52100, Testing net (#0)
I0526 12:58:00.476445 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8957
I0526 12:58:00.476485 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.328757 (* 1 = 0.328757 loss)
I0526 12:58:00.942001 15394 main.cpp:354] Iteration 52100, loss = 0.24353
I0526 12:58:00.942041 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.243529 (* 1 = 0.243529 loss)
I0526 12:58:00.942049 15394 sgd_solver.cpp:43] Iteration 52100, lr = 0.0002
I0526 12:58:06.023792 15394 main.cpp:354] Iteration 52110, loss = 0.183097
I0526 12:58:06.023838 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.183096 (* 1 = 0.183096 loss)
I0526 12:58:06.023844 15394 sgd_solver.cpp:43] Iteration 52110, lr = 0.0002
I0526 12:58:11.325359 15394 main.cpp:354] Iteration 52120, loss = 0.274168
I0526 12:58:11.325399 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.274168 (* 1 = 0.274168 loss)
I0526 12:58:11.325407 15394 sgd_solver.cpp:43] Iteration 52120, lr = 0.0002
I0526 12:58:16.480368 15394 main.cpp:354] Iteration 52130, loss = 0.131911
I0526 12:58:16.480407 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.131911 (* 1 = 0.131911 loss)
I0526 12:58:16.480413 15394 sgd_solver.cpp:43] Iteration 52130, lr = 0.0002
I0526 12:58:21.398758 15394 main.cpp:354] Iteration 52140, loss = 0.390223
I0526 12:58:21.398802 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.390222 (* 1 = 0.390222 loss)
I0526 12:58:21.398808 15394 sgd_solver.cpp:43] Iteration 52140, lr = 0.0002
I0526 12:58:26.797416 15394 main.cpp:354] Iteration 52150, loss = 0.241019
I0526 12:58:26.797456 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.241018 (* 1 = 0.241018 loss)
I0526 12:58:26.797462 15394 sgd_solver.cpp:43] Iteration 52150, lr = 0.0002
I0526 12:58:31.966188 15394 main.cpp:354] Iteration 52160, loss = 0.245954
I0526 12:58:31.966241 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.245953 (* 1 = 0.245953 loss)
I0526 12:58:31.966249 15394 sgd_solver.cpp:43] Iteration 52160, lr = 0.0002
I0526 12:58:37.036644 15394 main.cpp:354] Iteration 52170, loss = 0.201408
I0526 12:58:37.036689 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.201408 (* 1 = 0.201408 loss)
I0526 12:58:37.036695 15394 sgd_solver.cpp:43] Iteration 52170, lr = 0.0002
I0526 12:58:42.544512 15394 main.cpp:354] Iteration 52180, loss = 0.116401
I0526 12:58:42.544550 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.116401 (* 1 = 0.116401 loss)
I0526 12:58:42.544558 15394 sgd_solver.cpp:43] Iteration 52180, lr = 0.0002
I0526 12:58:47.647886 15394 main.cpp:354] Iteration 52190, loss = 0.0920201
I0526 12:58:47.647925 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0920196 (* 1 = 0.0920196 loss)
I0526 12:58:47.647933 15394 sgd_solver.cpp:43] Iteration 52190, lr = 0.0002
I0526 12:58:52.357524 15394 main.cpp:465] Iteration 52200, Testing net (#0)
I0526 12:59:05.437108 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8968
I0526 12:59:05.437147 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.328491 (* 1 = 0.328491 loss)
I0526 12:59:05.727634 15394 main.cpp:354] Iteration 52200, loss = 0.671742
I0526 12:59:05.727665 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.671742 (* 1 = 0.671742 loss)
I0526 12:59:05.727674 15394 sgd_solver.cpp:43] Iteration 52200, lr = 0.0002
I0526 12:59:10.385303 15394 main.cpp:354] Iteration 52210, loss = 0.279717
I0526 12:59:10.385340 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.279716 (* 1 = 0.279716 loss)
I0526 12:59:10.385347 15394 sgd_solver.cpp:43] Iteration 52210, lr = 0.0002
I0526 12:59:15.406780 15394 main.cpp:354] Iteration 52220, loss = 0.187083
I0526 12:59:15.406821 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187083 (* 1 = 0.187083 loss)
I0526 12:59:15.406826 15394 sgd_solver.cpp:43] Iteration 52220, lr = 0.0002
I0526 12:59:20.188280 15394 main.cpp:354] Iteration 52230, loss = 0.11474
I0526 12:59:20.188324 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.11474 (* 1 = 0.11474 loss)
I0526 12:59:20.188331 15394 sgd_solver.cpp:43] Iteration 52230, lr = 0.0002
I0526 12:59:25.228137 15394 main.cpp:354] Iteration 52240, loss = 0.186824
I0526 12:59:25.228178 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186824 (* 1 = 0.186824 loss)
I0526 12:59:25.228185 15394 sgd_solver.cpp:43] Iteration 52240, lr = 0.0002
I0526 12:59:30.333101 15394 main.cpp:354] Iteration 52250, loss = 0.193619
I0526 12:59:30.333140 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.193618 (* 1 = 0.193618 loss)
I0526 12:59:30.333148 15394 sgd_solver.cpp:43] Iteration 52250, lr = 0.0002
I0526 12:59:35.083847 15394 main.cpp:354] Iteration 52260, loss = 0.404587
I0526 12:59:35.083890 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.404587 (* 1 = 0.404587 loss)
I0526 12:59:35.083897 15394 sgd_solver.cpp:43] Iteration 52260, lr = 0.0002
I0526 12:59:40.087363 15394 main.cpp:354] Iteration 52270, loss = 0.235575
I0526 12:59:40.087402 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235574 (* 1 = 0.235574 loss)
I0526 12:59:40.087409 15394 sgd_solver.cpp:43] Iteration 52270, lr = 0.0002
I0526 12:59:45.298262 15394 main.cpp:354] Iteration 52280, loss = 0.300404
I0526 12:59:45.298302 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.300404 (* 1 = 0.300404 loss)
I0526 12:59:45.298310 15394 sgd_solver.cpp:43] Iteration 52280, lr = 0.0002
I0526 12:59:50.176434 15394 main.cpp:354] Iteration 52290, loss = 0.316278
I0526 12:59:50.176477 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.316278 (* 1 = 0.316278 loss)
I0526 12:59:50.176486 15394 sgd_solver.cpp:43] Iteration 52290, lr = 0.0002
I0526 12:59:55.060830 15394 main.cpp:465] Iteration 52300, Testing net (#0)
I0526 13:00:08.149447 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8948
I0526 13:00:08.149485 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.332941 (* 1 = 0.332941 loss)
I0526 13:00:08.656971 15394 main.cpp:354] Iteration 52300, loss = 0.156244
I0526 13:00:08.657014 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.156243 (* 1 = 0.156243 loss)
I0526 13:00:08.657021 15394 sgd_solver.cpp:43] Iteration 52300, lr = 0.0002
I0526 13:00:13.707470 15394 main.cpp:354] Iteration 52310, loss = 0.0932438
I0526 13:00:13.707512 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0932433 (* 1 = 0.0932433 loss)
I0526 13:00:13.707518 15394 sgd_solver.cpp:43] Iteration 52310, lr = 0.0002
I0526 13:00:18.897943 15394 main.cpp:354] Iteration 52320, loss = 0.212893
I0526 13:00:18.897989 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.212893 (* 1 = 0.212893 loss)
I0526 13:00:18.897995 15394 sgd_solver.cpp:43] Iteration 52320, lr = 0.0002
I0526 13:00:23.912230 15394 main.cpp:354] Iteration 52330, loss = 0.326616
I0526 13:00:23.912276 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.326616 (* 1 = 0.326616 loss)
I0526 13:00:23.912282 15394 sgd_solver.cpp:43] Iteration 52330, lr = 0.0002
I0526 13:00:29.207564 15394 main.cpp:354] Iteration 52340, loss = 0.137002
I0526 13:00:29.207604 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.137001 (* 1 = 0.137001 loss)
I0526 13:00:29.207610 15394 sgd_solver.cpp:43] Iteration 52340, lr = 0.0002
I0526 13:00:34.234035 15394 main.cpp:354] Iteration 52350, loss = 0.218466
I0526 13:00:34.234078 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.218465 (* 1 = 0.218465 loss)
I0526 13:00:34.234086 15394 sgd_solver.cpp:43] Iteration 52350, lr = 0.0002
I0526 13:00:38.781360 15394 main.cpp:354] Iteration 52360, loss = 0.306208
I0526 13:00:38.781399 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.306207 (* 1 = 0.306207 loss)
I0526 13:00:38.781405 15394 sgd_solver.cpp:43] Iteration 52360, lr = 0.0002
I0526 13:00:43.675850 15394 main.cpp:354] Iteration 52370, loss = 0.732604
I0526 13:00:43.675890 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.732603 (* 1 = 0.732603 loss)
I0526 13:00:43.675897 15394 sgd_solver.cpp:43] Iteration 52370, lr = 0.0002
I0526 13:00:48.876893 15394 main.cpp:354] Iteration 52380, loss = 0.21062
I0526 13:00:48.876938 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.21062 (* 1 = 0.21062 loss)
I0526 13:00:48.876946 15394 sgd_solver.cpp:43] Iteration 52380, lr = 0.0002
I0526 13:00:53.924428 15394 main.cpp:354] Iteration 52390, loss = 0.153532
I0526 13:00:53.924468 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.153532 (* 1 = 0.153532 loss)
I0526 13:00:53.924474 15394 sgd_solver.cpp:43] Iteration 52390, lr = 0.0002
I0526 13:00:58.670174 15394 main.cpp:465] Iteration 52400, Testing net (#0)
I0526 13:01:11.752010 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8937
I0526 13:01:11.752054 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.334892 (* 1 = 0.334892 loss)
I0526 13:01:12.290969 15394 main.cpp:354] Iteration 52400, loss = 0.189299
I0526 13:01:12.291013 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.189299 (* 1 = 0.189299 loss)
I0526 13:01:12.291023 15394 sgd_solver.cpp:43] Iteration 52400, lr = 0.0002
I0526 13:01:17.523272 15394 main.cpp:354] Iteration 52410, loss = 0.269313
I0526 13:01:17.523310 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.269313 (* 1 = 0.269313 loss)
I0526 13:01:17.523318 15394 sgd_solver.cpp:43] Iteration 52410, lr = 0.0002
I0526 13:01:22.654202 15394 main.cpp:354] Iteration 52420, loss = 0.216586
I0526 13:01:22.654245 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.216586 (* 1 = 0.216586 loss)
I0526 13:01:22.654252 15394 sgd_solver.cpp:43] Iteration 52420, lr = 0.0002
I0526 13:01:27.765462 15394 main.cpp:354] Iteration 52430, loss = 0.14692
I0526 13:01:27.765516 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.14692 (* 1 = 0.14692 loss)
I0526 13:01:27.765522 15394 sgd_solver.cpp:43] Iteration 52430, lr = 0.0002
I0526 13:01:32.978107 15394 main.cpp:354] Iteration 52440, loss = 0.196942
I0526 13:01:32.978147 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.196942 (* 1 = 0.196942 loss)
I0526 13:01:32.978152 15394 sgd_solver.cpp:43] Iteration 52440, lr = 0.0002
I0526 13:01:37.881445 15394 main.cpp:354] Iteration 52450, loss = 0.286377
I0526 13:01:37.881489 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.286377 (* 1 = 0.286377 loss)
I0526 13:01:37.881495 15394 sgd_solver.cpp:43] Iteration 52450, lr = 0.0002
I0526 13:01:42.866057 15394 main.cpp:354] Iteration 52460, loss = 0.464711
I0526 13:01:42.866096 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.46471 (* 1 = 0.46471 loss)
I0526 13:01:42.866102 15394 sgd_solver.cpp:43] Iteration 52460, lr = 0.0002
I0526 13:01:48.224442 15394 main.cpp:354] Iteration 52470, loss = 0.132705
I0526 13:01:48.224480 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.132705 (* 1 = 0.132705 loss)
I0526 13:01:48.224493 15394 sgd_solver.cpp:43] Iteration 52470, lr = 0.0002
I0526 13:01:53.458633 15394 main.cpp:354] Iteration 52480, loss = 0.161047
I0526 13:01:53.458675 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.161047 (* 1 = 0.161047 loss)
I0526 13:01:53.458683 15394 sgd_solver.cpp:43] Iteration 52480, lr = 0.0002
I0526 13:01:59.056444 15394 main.cpp:354] Iteration 52490, loss = 0.196854
I0526 13:01:59.056486 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.196853 (* 1 = 0.196853 loss)
I0526 13:01:59.056493 15394 sgd_solver.cpp:43] Iteration 52490, lr = 0.0002
I0526 13:02:03.691171 15394 main.cpp:465] Iteration 52500, Testing net (#0)
I0526 13:02:16.779100 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8951
I0526 13:02:16.779139 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.327461 (* 1 = 0.327461 loss)
I0526 13:02:17.143004 15394 main.cpp:354] Iteration 52500, loss = 0.341797
I0526 13:02:17.143050 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.341797 (* 1 = 0.341797 loss)
I0526 13:02:17.143057 15394 sgd_solver.cpp:43] Iteration 52500, lr = 0.0002
I0526 13:02:22.582556 15394 main.cpp:354] Iteration 52510, loss = 0.244914
I0526 13:02:22.582598 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.244913 (* 1 = 0.244913 loss)
I0526 13:02:22.582605 15394 sgd_solver.cpp:43] Iteration 52510, lr = 0.0002
I0526 13:02:27.944290 15394 main.cpp:354] Iteration 52520, loss = 0.168838
I0526 13:02:27.944330 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.168838 (* 1 = 0.168838 loss)
I0526 13:02:27.944336 15394 sgd_solver.cpp:43] Iteration 52520, lr = 0.0002
I0526 13:02:33.339943 15394 main.cpp:354] Iteration 52530, loss = 0.14036
I0526 13:02:33.339979 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.140359 (* 1 = 0.140359 loss)
I0526 13:02:33.339985 15394 sgd_solver.cpp:43] Iteration 52530, lr = 0.0002
I0526 13:02:38.569046 15394 main.cpp:354] Iteration 52540, loss = 0.327811
I0526 13:02:38.569088 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.32781 (* 1 = 0.32781 loss)
I0526 13:02:38.569095 15394 sgd_solver.cpp:43] Iteration 52540, lr = 0.0002
I0526 13:02:43.710799 15394 main.cpp:354] Iteration 52550, loss = 0.178903
I0526 13:02:43.710839 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.178903 (* 1 = 0.178903 loss)
I0526 13:02:43.710846 15394 sgd_solver.cpp:43] Iteration 52550, lr = 0.0002
I0526 13:02:48.988833 15394 main.cpp:354] Iteration 52560, loss = 0.10993
I0526 13:02:48.988875 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.10993 (* 1 = 0.10993 loss)
I0526 13:02:48.988883 15394 sgd_solver.cpp:43] Iteration 52560, lr = 0.0002
I0526 13:02:54.219379 15394 main.cpp:354] Iteration 52570, loss = 0.0945277
I0526 13:02:54.219419 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0945272 (* 1 = 0.0945272 loss)
I0526 13:02:54.219425 15394 sgd_solver.cpp:43] Iteration 52570, lr = 0.0002
I0526 13:02:59.319501 15394 main.cpp:354] Iteration 52580, loss = 0.114755
I0526 13:02:59.319542 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.114754 (* 1 = 0.114754 loss)
I0526 13:02:59.319550 15394 sgd_solver.cpp:43] Iteration 52580, lr = 0.0002
I0526 13:03:04.680296 15394 main.cpp:354] Iteration 52590, loss = 0.246333
I0526 13:03:04.680340 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.246332 (* 1 = 0.246332 loss)
I0526 13:03:04.680347 15394 sgd_solver.cpp:43] Iteration 52590, lr = 0.0002
I0526 13:03:09.056828 15394 main.cpp:465] Iteration 52600, Testing net (#0)
I0526 13:03:22.148407 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8937
I0526 13:03:22.148448 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.337774 (* 1 = 0.337774 loss)
I0526 13:03:22.513893 15394 main.cpp:354] Iteration 52600, loss = 0.408694
I0526 13:03:22.513934 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.408693 (* 1 = 0.408693 loss)
I0526 13:03:22.513947 15394 sgd_solver.cpp:43] Iteration 52600, lr = 0.0002
I0526 13:03:27.174808 15394 main.cpp:354] Iteration 52610, loss = 0.225443
I0526 13:03:27.174847 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.225442 (* 1 = 0.225442 loss)
I0526 13:03:27.174854 15394 sgd_solver.cpp:43] Iteration 52610, lr = 0.0002
I0526 13:03:31.813191 15394 main.cpp:354] Iteration 52620, loss = 0.203488
I0526 13:03:31.813231 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.203488 (* 1 = 0.203488 loss)
I0526 13:03:31.813238 15394 sgd_solver.cpp:43] Iteration 52620, lr = 0.0002
I0526 13:03:36.631608 15394 main.cpp:354] Iteration 52630, loss = 0.165503
I0526 13:03:36.631652 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.165502 (* 1 = 0.165502 loss)
I0526 13:03:36.631659 15394 sgd_solver.cpp:43] Iteration 52630, lr = 0.0002
I0526 13:03:41.718622 15394 main.cpp:354] Iteration 52640, loss = 0.204852
I0526 13:03:41.718655 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204852 (* 1 = 0.204852 loss)
I0526 13:03:41.718662 15394 sgd_solver.cpp:43] Iteration 52640, lr = 0.0002
I0526 13:03:47.023593 15394 main.cpp:354] Iteration 52650, loss = 0.165668
I0526 13:03:47.023634 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.165667 (* 1 = 0.165667 loss)
I0526 13:03:47.023641 15394 sgd_solver.cpp:43] Iteration 52650, lr = 0.0002
I0526 13:03:51.945919 15394 main.cpp:354] Iteration 52660, loss = 0.235429
I0526 13:03:51.945962 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235428 (* 1 = 0.235428 loss)
I0526 13:03:51.945969 15394 sgd_solver.cpp:43] Iteration 52660, lr = 0.0002
I0526 13:03:56.858675 15394 main.cpp:354] Iteration 52670, loss = 0.198415
I0526 13:03:56.858716 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.198414 (* 1 = 0.198414 loss)
I0526 13:03:56.858721 15394 sgd_solver.cpp:43] Iteration 52670, lr = 0.0002
I0526 13:04:01.979465 15394 main.cpp:354] Iteration 52680, loss = 0.434247
I0526 13:04:01.979506 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.434246 (* 1 = 0.434246 loss)
I0526 13:04:01.979511 15394 sgd_solver.cpp:43] Iteration 52680, lr = 0.0002
I0526 13:04:07.144623 15394 main.cpp:354] Iteration 52690, loss = 0.284054
I0526 13:04:07.144666 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.284053 (* 1 = 0.284053 loss)
I0526 13:04:07.144672 15394 sgd_solver.cpp:43] Iteration 52690, lr = 0.0002
I0526 13:04:11.741981 15394 main.cpp:465] Iteration 52700, Testing net (#0)
I0526 13:04:24.822312 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8961
I0526 13:04:24.822360 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.330192 (* 1 = 0.330192 loss)
I0526 13:04:25.325561 15394 main.cpp:354] Iteration 52700, loss = 0.172353
I0526 13:04:25.325603 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.172352 (* 1 = 0.172352 loss)
I0526 13:04:25.325610 15394 sgd_solver.cpp:43] Iteration 52700, lr = 0.0002
I0526 13:04:30.482025 15394 main.cpp:354] Iteration 52710, loss = 0.147441
I0526 13:04:30.482065 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.147441 (* 1 = 0.147441 loss)
I0526 13:04:30.482072 15394 sgd_solver.cpp:43] Iteration 52710, lr = 0.0002
I0526 13:04:35.151417 15394 main.cpp:354] Iteration 52720, loss = 0.189386
I0526 13:04:35.151458 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.189385 (* 1 = 0.189385 loss)
I0526 13:04:35.151465 15394 sgd_solver.cpp:43] Iteration 52720, lr = 0.0002
I0526 13:04:40.533417 15394 main.cpp:354] Iteration 52730, loss = 0.234624
I0526 13:04:40.533457 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.234623 (* 1 = 0.234623 loss)
I0526 13:04:40.533464 15394 sgd_solver.cpp:43] Iteration 52730, lr = 0.0002
I0526 13:04:45.797395 15394 main.cpp:354] Iteration 52740, loss = 0.332572
I0526 13:04:45.797435 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.332571 (* 1 = 0.332571 loss)
I0526 13:04:45.797441 15394 sgd_solver.cpp:43] Iteration 52740, lr = 0.0002
I0526 13:04:50.617805 15394 main.cpp:354] Iteration 52750, loss = 0.272102
I0526 13:04:50.617851 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.272102 (* 1 = 0.272102 loss)
I0526 13:04:50.617857 15394 sgd_solver.cpp:43] Iteration 52750, lr = 0.0002
I0526 13:04:55.795061 15394 main.cpp:354] Iteration 52760, loss = 0.179663
I0526 13:04:55.795102 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.179663 (* 1 = 0.179663 loss)
I0526 13:04:55.795109 15394 sgd_solver.cpp:43] Iteration 52760, lr = 0.0002
I0526 13:05:00.641749 15394 main.cpp:354] Iteration 52770, loss = 0.230361
I0526 13:05:00.641794 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.23036 (* 1 = 0.23036 loss)
I0526 13:05:00.641801 15394 sgd_solver.cpp:43] Iteration 52770, lr = 0.0002
I0526 13:05:06.363711 15394 main.cpp:354] Iteration 52780, loss = 0.124257
I0526 13:05:06.363754 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.124256 (* 1 = 0.124256 loss)
I0526 13:05:06.363760 15394 sgd_solver.cpp:43] Iteration 52780, lr = 0.0002
I0526 13:05:11.031888 15394 main.cpp:354] Iteration 52790, loss = 0.268862
I0526 13:05:11.031924 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.268861 (* 1 = 0.268861 loss)
I0526 13:05:11.031930 15394 sgd_solver.cpp:43] Iteration 52790, lr = 0.0002
I0526 13:05:15.731976 15394 main.cpp:465] Iteration 52800, Testing net (#0)
I0526 13:05:28.824121 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8965
I0526 13:05:28.824162 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.326815 (* 1 = 0.326815 loss)
I0526 13:05:29.325522 15394 main.cpp:354] Iteration 52800, loss = 0.144724
I0526 13:05:29.325554 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.144724 (* 1 = 0.144724 loss)
I0526 13:05:29.325562 15394 sgd_solver.cpp:43] Iteration 52800, lr = 0.0002
I0526 13:05:34.363076 15394 main.cpp:354] Iteration 52810, loss = 0.150559
I0526 13:05:34.363121 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.150558 (* 1 = 0.150558 loss)
I0526 13:05:34.363127 15394 sgd_solver.cpp:43] Iteration 52810, lr = 0.0002
I0526 13:05:39.640753 15394 main.cpp:354] Iteration 52820, loss = 0.230274
I0526 13:05:39.640792 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.230273 (* 1 = 0.230273 loss)
I0526 13:05:39.640799 15394 sgd_solver.cpp:43] Iteration 52820, lr = 0.0002
I0526 13:05:45.024050 15394 main.cpp:354] Iteration 52830, loss = 0.254679
I0526 13:05:45.024091 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.254678 (* 1 = 0.254678 loss)
I0526 13:05:45.024096 15394 sgd_solver.cpp:43] Iteration 52830, lr = 0.0002
I0526 13:05:49.782428 15394 main.cpp:354] Iteration 52840, loss = 0.356027
I0526 13:05:49.782470 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.356027 (* 1 = 0.356027 loss)
I0526 13:05:49.782476 15394 sgd_solver.cpp:43] Iteration 52840, lr = 0.0002
I0526 13:05:54.890528 15394 main.cpp:354] Iteration 52850, loss = 0.144481
I0526 13:05:54.890571 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.14448 (* 1 = 0.14448 loss)
I0526 13:05:54.890578 15394 sgd_solver.cpp:43] Iteration 52850, lr = 0.0002
I0526 13:06:00.109212 15394 main.cpp:354] Iteration 52860, loss = 0.162386
I0526 13:06:00.109251 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.162385 (* 1 = 0.162385 loss)
I0526 13:06:00.109258 15394 sgd_solver.cpp:43] Iteration 52860, lr = 0.0002
I0526 13:06:05.067729 15394 main.cpp:354] Iteration 52870, loss = 0.206359
I0526 13:06:05.067773 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206358 (* 1 = 0.206358 loss)
I0526 13:06:05.067781 15394 sgd_solver.cpp:43] Iteration 52870, lr = 0.0002
I0526 13:06:09.918426 15394 main.cpp:354] Iteration 52880, loss = 0.254919
I0526 13:06:09.918469 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.254919 (* 1 = 0.254919 loss)
I0526 13:06:09.918478 15394 sgd_solver.cpp:43] Iteration 52880, lr = 0.0002
I0526 13:06:14.903385 15394 main.cpp:354] Iteration 52890, loss = 0.234334
I0526 13:06:14.903430 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.234333 (* 1 = 0.234333 loss)
I0526 13:06:14.903436 15394 sgd_solver.cpp:43] Iteration 52890, lr = 0.0002
I0526 13:06:19.526139 15394 main.cpp:465] Iteration 52900, Testing net (#0)
I0526 13:06:32.609774 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8949
I0526 13:06:32.609804 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.329889 (* 1 = 0.329889 loss)
I0526 13:06:32.978229 15394 main.cpp:354] Iteration 52900, loss = 0.339839
I0526 13:06:32.978260 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.339839 (* 1 = 0.339839 loss)
I0526 13:06:32.978266 15394 sgd_solver.cpp:43] Iteration 52900, lr = 0.0002
I0526 13:06:38.474406 15394 main.cpp:354] Iteration 52910, loss = 0.252376
I0526 13:06:38.474449 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.252376 (* 1 = 0.252376 loss)
I0526 13:06:38.474457 15394 sgd_solver.cpp:43] Iteration 52910, lr = 0.0002
I0526 13:06:43.746085 15394 main.cpp:354] Iteration 52920, loss = 0.142008
I0526 13:06:43.746127 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.142007 (* 1 = 0.142007 loss)
I0526 13:06:43.746134 15394 sgd_solver.cpp:43] Iteration 52920, lr = 0.0002
I0526 13:06:48.661942 15394 main.cpp:354] Iteration 52930, loss = 0.0980163
I0526 13:06:48.661988 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0980158 (* 1 = 0.0980158 loss)
I0526 13:06:48.661995 15394 sgd_solver.cpp:43] Iteration 52930, lr = 0.0002
I0526 13:06:53.885761 15394 main.cpp:354] Iteration 52940, loss = 0.151386
I0526 13:06:53.885802 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.151385 (* 1 = 0.151385 loss)
I0526 13:06:53.885808 15394 sgd_solver.cpp:43] Iteration 52940, lr = 0.0002
I0526 13:06:59.149294 15394 main.cpp:354] Iteration 52950, loss = 0.171207
I0526 13:06:59.149335 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.171206 (* 1 = 0.171206 loss)
I0526 13:06:59.149343 15394 sgd_solver.cpp:43] Iteration 52950, lr = 0.0002
I0526 13:07:04.390254 15394 main.cpp:354] Iteration 52960, loss = 0.156226
I0526 13:07:04.390296 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.156225 (* 1 = 0.156225 loss)
I0526 13:07:04.390303 15394 sgd_solver.cpp:43] Iteration 52960, lr = 0.0002
I0526 13:07:09.402951 15394 main.cpp:354] Iteration 52970, loss = 0.210563
I0526 13:07:09.402989 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.210563 (* 1 = 0.210563 loss)
I0526 13:07:09.402995 15394 sgd_solver.cpp:43] Iteration 52970, lr = 0.0002
I0526 13:07:14.364424 15394 main.cpp:354] Iteration 52980, loss = 0.417395
I0526 13:07:14.364462 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.417394 (* 1 = 0.417394 loss)
I0526 13:07:14.364469 15394 sgd_solver.cpp:43] Iteration 52980, lr = 0.0002
I0526 13:07:19.263523 15394 main.cpp:354] Iteration 52990, loss = 0.186757
I0526 13:07:19.263571 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186756 (* 1 = 0.186756 loss)
I0526 13:07:19.263578 15394 sgd_solver.cpp:43] Iteration 52990, lr = 0.0002
I0526 13:07:24.028643 15394 main.cpp:465] Iteration 53000, Testing net (#0)
I0526 13:07:37.116755 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8977
I0526 13:07:37.116793 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.330305 (* 1 = 0.330305 loss)
I0526 13:07:37.618196 15394 main.cpp:354] Iteration 53000, loss = 0.147709
I0526 13:07:37.618237 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.147709 (* 1 = 0.147709 loss)
I0526 13:07:37.618245 15394 sgd_solver.cpp:43] Iteration 53000, lr = 0.0002
I0526 13:07:42.526546 15394 main.cpp:354] Iteration 53010, loss = 0.33186
I0526 13:07:42.526587 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.331859 (* 1 = 0.331859 loss)
I0526 13:07:42.526593 15394 sgd_solver.cpp:43] Iteration 53010, lr = 0.0002
I0526 13:07:47.348665 15394 main.cpp:354] Iteration 53020, loss = 0.212846
I0526 13:07:47.348706 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.212846 (* 1 = 0.212846 loss)
I0526 13:07:47.348718 15394 sgd_solver.cpp:43] Iteration 53020, lr = 0.0002
I0526 13:07:52.071085 15394 main.cpp:354] Iteration 53030, loss = 0.203948
I0526 13:07:52.071132 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.203948 (* 1 = 0.203948 loss)
I0526 13:07:52.071140 15394 sgd_solver.cpp:43] Iteration 53030, lr = 0.0002
I0526 13:07:56.334481 15394 main.cpp:354] Iteration 53040, loss = 0.246746
I0526 13:07:56.334519 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.246745 (* 1 = 0.246745 loss)
I0526 13:07:56.334527 15394 sgd_solver.cpp:43] Iteration 53040, lr = 0.0002
I0526 13:08:01.185293 15394 main.cpp:354] Iteration 53050, loss = 0.371741
I0526 13:08:01.185329 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.37174 (* 1 = 0.37174 loss)
I0526 13:08:01.185335 15394 sgd_solver.cpp:43] Iteration 53050, lr = 0.0002
I0526 13:08:06.285131 15394 main.cpp:354] Iteration 53060, loss = 0.226445
I0526 13:08:06.285174 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.226445 (* 1 = 0.226445 loss)
I0526 13:08:06.285181 15394 sgd_solver.cpp:43] Iteration 53060, lr = 0.0002
I0526 13:08:11.359817 15394 main.cpp:354] Iteration 53070, loss = 0.18261
I0526 13:08:11.359856 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.18261 (* 1 = 0.18261 loss)
I0526 13:08:11.359863 15394 sgd_solver.cpp:43] Iteration 53070, lr = 0.0002
I0526 13:08:16.527940 15394 main.cpp:354] Iteration 53080, loss = 0.151712
I0526 13:08:16.527979 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.151711 (* 1 = 0.151711 loss)
I0526 13:08:16.527986 15394 sgd_solver.cpp:43] Iteration 53080, lr = 0.0002
I0526 13:08:21.323287 15394 main.cpp:354] Iteration 53090, loss = 0.146798
I0526 13:08:21.323330 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.146797 (* 1 = 0.146797 loss)
I0526 13:08:21.323336 15394 sgd_solver.cpp:43] Iteration 53090, lr = 0.0002
I0526 13:08:25.855715 15394 main.cpp:465] Iteration 53100, Testing net (#0)
I0526 13:08:38.934183 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8965
I0526 13:08:38.934226 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.333873 (* 1 = 0.333873 loss)
I0526 13:08:39.435909 15394 main.cpp:354] Iteration 53100, loss = 0.111888
I0526 13:08:39.435953 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.111887 (* 1 = 0.111887 loss)
I0526 13:08:39.435963 15394 sgd_solver.cpp:43] Iteration 53100, lr = 0.0002
I0526 13:08:44.523972 15394 main.cpp:354] Iteration 53110, loss = 0.140384
I0526 13:08:44.524004 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.140384 (* 1 = 0.140384 loss)
I0526 13:08:44.524013 15394 sgd_solver.cpp:43] Iteration 53110, lr = 0.0002
I0526 13:08:48.925061 15394 main.cpp:354] Iteration 53120, loss = 0.447306
I0526 13:08:48.925104 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.447306 (* 1 = 0.447306 loss)
I0526 13:08:48.925110 15394 sgd_solver.cpp:43] Iteration 53120, lr = 0.0002
I0526 13:08:53.880404 15394 main.cpp:354] Iteration 53130, loss = 0.343657
I0526 13:08:53.880445 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.343656 (* 1 = 0.343656 loss)
I0526 13:08:53.880450 15394 sgd_solver.cpp:43] Iteration 53130, lr = 0.0002
I0526 13:08:59.040453 15394 main.cpp:354] Iteration 53140, loss = 0.105145
I0526 13:08:59.040493 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.105144 (* 1 = 0.105144 loss)
I0526 13:08:59.040499 15394 sgd_solver.cpp:43] Iteration 53140, lr = 0.0002
I0526 13:09:04.283119 15394 main.cpp:354] Iteration 53150, loss = 0.0875281
I0526 13:09:04.283162 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0875275 (* 1 = 0.0875275 loss)
I0526 13:09:04.283169 15394 sgd_solver.cpp:43] Iteration 53150, lr = 0.0002
I0526 13:09:09.480438 15394 main.cpp:354] Iteration 53160, loss = 0.528635
I0526 13:09:09.480479 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.528635 (* 1 = 0.528635 loss)
I0526 13:09:09.480491 15394 sgd_solver.cpp:43] Iteration 53160, lr = 0.0002
I0526 13:09:14.573956 15394 main.cpp:354] Iteration 53170, loss = 0.164149
I0526 13:09:14.573997 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.164149 (* 1 = 0.164149 loss)
I0526 13:09:14.574002 15394 sgd_solver.cpp:43] Iteration 53170, lr = 0.0002
I0526 13:09:19.807461 15394 main.cpp:354] Iteration 53180, loss = 0.279005
I0526 13:09:19.807505 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.279004 (* 1 = 0.279004 loss)
I0526 13:09:19.807512 15394 sgd_solver.cpp:43] Iteration 53180, lr = 0.0002
I0526 13:09:24.606375 15394 main.cpp:354] Iteration 53190, loss = 0.0692199
I0526 13:09:24.606415 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0692193 (* 1 = 0.0692193 loss)
I0526 13:09:24.606421 15394 sgd_solver.cpp:43] Iteration 53190, lr = 0.0002
I0526 13:09:28.830844 15394 main.cpp:465] Iteration 53200, Testing net (#0)
I0526 13:09:41.918092 15394 main.cpp:532]     Test net output #0: Accuracy = 0.895
I0526 13:09:41.918133 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.331796 (* 1 = 0.331796 loss)
I0526 13:09:42.420068 15394 main.cpp:354] Iteration 53200, loss = 0.192296
I0526 13:09:42.420110 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.192296 (* 1 = 0.192296 loss)
I0526 13:09:42.420119 15394 sgd_solver.cpp:43] Iteration 53200, lr = 0.0002
I0526 13:09:47.442376 15394 main.cpp:354] Iteration 53210, loss = 0.209124
I0526 13:09:47.442410 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.209123 (* 1 = 0.209123 loss)
I0526 13:09:47.442417 15394 sgd_solver.cpp:43] Iteration 53210, lr = 0.0002
I0526 13:09:52.376102 15394 main.cpp:354] Iteration 53220, loss = 0.154851
I0526 13:09:52.376147 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.154851 (* 1 = 0.154851 loss)
I0526 13:09:52.376154 15394 sgd_solver.cpp:43] Iteration 53220, lr = 0.0002
I0526 13:09:57.859812 15394 main.cpp:354] Iteration 53230, loss = 0.308541
I0526 13:09:57.859853 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.30854 (* 1 = 0.30854 loss)
I0526 13:09:57.859860 15394 sgd_solver.cpp:43] Iteration 53230, lr = 0.0002
I0526 13:10:02.872584 15394 main.cpp:354] Iteration 53240, loss = 0.314056
I0526 13:10:02.872624 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.314055 (* 1 = 0.314055 loss)
I0526 13:10:02.872630 15394 sgd_solver.cpp:43] Iteration 53240, lr = 0.0002
I0526 13:10:07.857390 15394 main.cpp:354] Iteration 53250, loss = 0.247333
I0526 13:10:07.857432 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.247333 (* 1 = 0.247333 loss)
I0526 13:10:07.857439 15394 sgd_solver.cpp:43] Iteration 53250, lr = 0.0002
I0526 13:10:12.236367 15394 main.cpp:354] Iteration 53260, loss = 0.574849
I0526 13:10:12.236407 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.574848 (* 1 = 0.574848 loss)
I0526 13:10:12.236413 15394 sgd_solver.cpp:43] Iteration 53260, lr = 0.0002
I0526 13:10:17.627218 15394 main.cpp:354] Iteration 53270, loss = 0.248068
I0526 13:10:17.627259 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.248068 (* 1 = 0.248068 loss)
I0526 13:10:17.627266 15394 sgd_solver.cpp:43] Iteration 53270, lr = 0.0002
I0526 13:10:22.364302 15394 main.cpp:354] Iteration 53280, loss = 0.290769
I0526 13:10:22.364344 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.290768 (* 1 = 0.290768 loss)
I0526 13:10:22.364351 15394 sgd_solver.cpp:43] Iteration 53280, lr = 0.0002
I0526 13:10:27.399183 15394 main.cpp:354] Iteration 53290, loss = 0.192515
I0526 13:10:27.399222 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.192515 (* 1 = 0.192515 loss)
I0526 13:10:27.399230 15394 sgd_solver.cpp:43] Iteration 53290, lr = 0.0002
I0526 13:10:32.257108 15394 main.cpp:465] Iteration 53300, Testing net (#0)
I0526 13:10:45.343588 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8965
I0526 13:10:45.343627 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.330505 (* 1 = 0.330505 loss)
I0526 13:10:45.810379 15394 main.cpp:354] Iteration 53300, loss = 0.264876
I0526 13:10:45.810423 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.264875 (* 1 = 0.264875 loss)
I0526 13:10:45.810431 15394 sgd_solver.cpp:43] Iteration 53300, lr = 0.0002
I0526 13:10:51.062249 15394 main.cpp:354] Iteration 53310, loss = 0.186989
I0526 13:10:51.062280 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186988 (* 1 = 0.186988 loss)
I0526 13:10:51.062288 15394 sgd_solver.cpp:43] Iteration 53310, lr = 0.0002
I0526 13:10:56.190731 15394 main.cpp:354] Iteration 53320, loss = 0.146318
I0526 13:10:56.190770 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.146317 (* 1 = 0.146317 loss)
I0526 13:10:56.190776 15394 sgd_solver.cpp:43] Iteration 53320, lr = 0.0002
I0526 13:11:01.500773 15394 main.cpp:354] Iteration 53330, loss = 0.0926662
I0526 13:11:01.500813 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0926656 (* 1 = 0.0926656 loss)
I0526 13:11:01.500818 15394 sgd_solver.cpp:43] Iteration 53330, lr = 0.0002
I0526 13:11:06.707495 15394 main.cpp:354] Iteration 53340, loss = 0.136237
I0526 13:11:06.707538 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.136236 (* 1 = 0.136236 loss)
I0526 13:11:06.707546 15394 sgd_solver.cpp:43] Iteration 53340, lr = 0.0002
I0526 13:11:11.984475 15394 main.cpp:354] Iteration 53350, loss = 0.111167
I0526 13:11:11.984516 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.111166 (* 1 = 0.111166 loss)
I0526 13:11:11.984524 15394 sgd_solver.cpp:43] Iteration 53350, lr = 0.0002
I0526 13:11:16.825985 15394 main.cpp:354] Iteration 53360, loss = 0.24364
I0526 13:11:16.826022 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.243639 (* 1 = 0.243639 loss)
I0526 13:11:16.826028 15394 sgd_solver.cpp:43] Iteration 53360, lr = 0.0002
I0526 13:11:22.136642 15394 main.cpp:354] Iteration 53370, loss = 0.224062
I0526 13:11:22.136682 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.224062 (* 1 = 0.224062 loss)
I0526 13:11:22.136689 15394 sgd_solver.cpp:43] Iteration 53370, lr = 0.0002
I0526 13:11:27.223850 15394 main.cpp:354] Iteration 53380, loss = 0.244099
I0526 13:11:27.223891 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.244099 (* 1 = 0.244099 loss)
I0526 13:11:27.223896 15394 sgd_solver.cpp:43] Iteration 53380, lr = 0.0002
I0526 13:11:32.304245 15394 main.cpp:354] Iteration 53390, loss = 0.289167
I0526 13:11:32.304286 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.289166 (* 1 = 0.289166 loss)
I0526 13:11:32.304291 15394 sgd_solver.cpp:43] Iteration 53390, lr = 0.0002
I0526 13:11:36.929786 15394 main.cpp:465] Iteration 53400, Testing net (#0)
I0526 13:11:50.016674 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8952
I0526 13:11:50.016716 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.332279 (* 1 = 0.332279 loss)
I0526 13:11:50.526872 15394 main.cpp:354] Iteration 53400, loss = 0.111874
I0526 13:11:50.526913 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.111873 (* 1 = 0.111873 loss)
I0526 13:11:50.526921 15394 sgd_solver.cpp:43] Iteration 53400, lr = 0.0002
I0526 13:11:55.836244 15394 main.cpp:354] Iteration 53410, loss = 0.151067
I0526 13:11:55.836282 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.151066 (* 1 = 0.151066 loss)
I0526 13:11:55.836288 15394 sgd_solver.cpp:43] Iteration 53410, lr = 0.0002
I0526 13:12:00.987711 15394 main.cpp:354] Iteration 53420, loss = 0.259458
I0526 13:12:00.987752 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.259458 (* 1 = 0.259458 loss)
I0526 13:12:00.987759 15394 sgd_solver.cpp:43] Iteration 53420, lr = 0.0002
I0526 13:12:05.752356 15394 main.cpp:354] Iteration 53430, loss = 0.186345
I0526 13:12:05.752398 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186345 (* 1 = 0.186345 loss)
I0526 13:12:05.752404 15394 sgd_solver.cpp:43] Iteration 53430, lr = 0.0002
I0526 13:12:10.946290 15394 main.cpp:354] Iteration 53440, loss = 0.24168
I0526 13:12:10.946333 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.241679 (* 1 = 0.241679 loss)
I0526 13:12:10.946339 15394 sgd_solver.cpp:43] Iteration 53440, lr = 0.0002
I0526 13:12:16.010901 15394 main.cpp:354] Iteration 53450, loss = 0.275116
I0526 13:12:16.010941 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.275115 (* 1 = 0.275115 loss)
I0526 13:12:16.010948 15394 sgd_solver.cpp:43] Iteration 53450, lr = 0.0002
I0526 13:12:21.099786 15394 main.cpp:354] Iteration 53460, loss = 0.214679
I0526 13:12:21.099829 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.214678 (* 1 = 0.214678 loss)
I0526 13:12:21.099838 15394 sgd_solver.cpp:43] Iteration 53460, lr = 0.0002
I0526 13:12:26.063237 15394 main.cpp:354] Iteration 53470, loss = 0.186162
I0526 13:12:26.063277 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186162 (* 1 = 0.186162 loss)
I0526 13:12:26.063285 15394 sgd_solver.cpp:43] Iteration 53470, lr = 0.0002
I0526 13:12:30.805997 15394 main.cpp:354] Iteration 53480, loss = 0.193932
I0526 13:12:30.806038 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.193931 (* 1 = 0.193931 loss)
I0526 13:12:30.806046 15394 sgd_solver.cpp:43] Iteration 53480, lr = 0.0002
I0526 13:12:35.703634 15394 main.cpp:354] Iteration 53490, loss = 0.120104
I0526 13:12:35.703676 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.120103 (* 1 = 0.120103 loss)
I0526 13:12:35.703683 15394 sgd_solver.cpp:43] Iteration 53490, lr = 0.0002
I0526 13:12:40.554870 15394 main.cpp:465] Iteration 53500, Testing net (#0)
I0526 13:12:53.644445 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8949
I0526 13:12:53.644485 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.332563 (* 1 = 0.332563 loss)
I0526 13:12:54.115625 15394 main.cpp:354] Iteration 53500, loss = 0.174449
I0526 13:12:54.115665 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.174449 (* 1 = 0.174449 loss)
I0526 13:12:54.115674 15394 sgd_solver.cpp:43] Iteration 53500, lr = 0.0002
I0526 13:12:59.772511 15394 main.cpp:354] Iteration 53510, loss = 0.41736
I0526 13:12:59.772552 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.41736 (* 1 = 0.41736 loss)
I0526 13:12:59.772558 15394 sgd_solver.cpp:43] Iteration 53510, lr = 0.0002
I0526 13:13:04.776943 15394 main.cpp:354] Iteration 53520, loss = 0.250877
I0526 13:13:04.776986 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.250877 (* 1 = 0.250877 loss)
I0526 13:13:04.776993 15394 sgd_solver.cpp:43] Iteration 53520, lr = 0.0002
I0526 13:13:09.375602 15394 main.cpp:354] Iteration 53530, loss = 0.259716
I0526 13:13:09.375643 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.259715 (* 1 = 0.259715 loss)
I0526 13:13:09.375649 15394 sgd_solver.cpp:43] Iteration 53530, lr = 0.0002
I0526 13:13:14.434373 15394 main.cpp:354] Iteration 53540, loss = 0.211523
I0526 13:13:14.434417 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.211523 (* 1 = 0.211523 loss)
I0526 13:13:14.434422 15394 sgd_solver.cpp:43] Iteration 53540, lr = 0.0002
I0526 13:13:19.723027 15394 main.cpp:354] Iteration 53550, loss = 0.159382
I0526 13:13:19.723070 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.159382 (* 1 = 0.159382 loss)
I0526 13:13:19.723078 15394 sgd_solver.cpp:43] Iteration 53550, lr = 0.0002
I0526 13:13:24.962111 15394 main.cpp:354] Iteration 53560, loss = 0.191846
I0526 13:13:24.962152 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.191846 (* 1 = 0.191846 loss)
I0526 13:13:24.962157 15394 sgd_solver.cpp:43] Iteration 53560, lr = 0.0002
I0526 13:13:30.007825 15394 main.cpp:354] Iteration 53570, loss = 0.222387
I0526 13:13:30.007864 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.222386 (* 1 = 0.222386 loss)
I0526 13:13:30.007871 15394 sgd_solver.cpp:43] Iteration 53570, lr = 0.0002
I0526 13:13:35.321223 15394 main.cpp:354] Iteration 53580, loss = 0.260711
I0526 13:13:35.321267 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.26071 (* 1 = 0.26071 loss)
I0526 13:13:35.321280 15394 sgd_solver.cpp:43] Iteration 53580, lr = 0.0002
I0526 13:13:40.536429 15394 main.cpp:354] Iteration 53590, loss = 0.210198
I0526 13:13:40.536468 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.210197 (* 1 = 0.210197 loss)
I0526 13:13:40.536475 15394 sgd_solver.cpp:43] Iteration 53590, lr = 0.0002
I0526 13:13:45.060864 15394 main.cpp:465] Iteration 53600, Testing net (#0)
I0526 13:13:58.142001 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8974
I0526 13:13:58.142041 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.329659 (* 1 = 0.329659 loss)
I0526 13:13:58.681264 15394 main.cpp:354] Iteration 53600, loss = 0.141317
I0526 13:13:58.681304 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.141316 (* 1 = 0.141316 loss)
I0526 13:13:58.681313 15394 sgd_solver.cpp:43] Iteration 53600, lr = 0.0002
I0526 13:14:03.690879 15394 main.cpp:354] Iteration 53610, loss = 0.196631
I0526 13:14:03.690923 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.19663 (* 1 = 0.19663 loss)
I0526 13:14:03.690930 15394 sgd_solver.cpp:43] Iteration 53610, lr = 0.0002
I0526 13:14:08.999791 15394 main.cpp:354] Iteration 53620, loss = 0.246655
I0526 13:14:08.999830 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.246654 (* 1 = 0.246654 loss)
I0526 13:14:08.999836 15394 sgd_solver.cpp:43] Iteration 53620, lr = 0.0002
I0526 13:14:14.365075 15394 main.cpp:354] Iteration 53630, loss = 0.229994
I0526 13:14:14.365115 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.229993 (* 1 = 0.229993 loss)
I0526 13:14:14.365121 15394 sgd_solver.cpp:43] Iteration 53630, lr = 0.0002
I0526 13:14:19.566115 15394 main.cpp:354] Iteration 53640, loss = 0.169678
I0526 13:14:19.566154 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.169678 (* 1 = 0.169678 loss)
I0526 13:14:19.566160 15394 sgd_solver.cpp:43] Iteration 53640, lr = 0.0002
I0526 13:14:24.661661 15394 main.cpp:354] Iteration 53650, loss = 0.217527
I0526 13:14:24.661700 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.217527 (* 1 = 0.217527 loss)
I0526 13:14:24.661705 15394 sgd_solver.cpp:43] Iteration 53650, lr = 0.0002
I0526 13:14:29.863142 15394 main.cpp:354] Iteration 53660, loss = 0.271776
I0526 13:14:29.863179 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.271775 (* 1 = 0.271775 loss)
I0526 13:14:29.863185 15394 sgd_solver.cpp:43] Iteration 53660, lr = 0.0002
I0526 13:14:35.170068 15394 main.cpp:354] Iteration 53670, loss = 0.183948
I0526 13:14:35.170114 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.183947 (* 1 = 0.183947 loss)
I0526 13:14:35.170121 15394 sgd_solver.cpp:43] Iteration 53670, lr = 0.0002
I0526 13:14:39.783924 15394 main.cpp:354] Iteration 53680, loss = 0.175623
I0526 13:14:39.783963 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.175622 (* 1 = 0.175622 loss)
I0526 13:14:39.783970 15394 sgd_solver.cpp:43] Iteration 53680, lr = 0.0002
I0526 13:14:44.772073 15394 main.cpp:354] Iteration 53690, loss = 0.198089
I0526 13:14:44.772110 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.198088 (* 1 = 0.198088 loss)
I0526 13:14:44.772117 15394 sgd_solver.cpp:43] Iteration 53690, lr = 0.0002
I0526 13:14:48.917219 15394 main.cpp:465] Iteration 53700, Testing net (#0)
I0526 13:15:01.996894 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8956
I0526 13:15:01.996933 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.332494 (* 1 = 0.332494 loss)
I0526 13:15:02.570633 15394 main.cpp:354] Iteration 53700, loss = 0.137916
I0526 13:15:02.570677 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.137916 (* 1 = 0.137916 loss)
I0526 13:15:02.570695 15394 sgd_solver.cpp:43] Iteration 53700, lr = 0.0002
I0526 13:15:07.629251 15394 main.cpp:354] Iteration 53710, loss = 0.167694
I0526 13:15:07.629294 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.167694 (* 1 = 0.167694 loss)
I0526 13:15:07.629304 15394 sgd_solver.cpp:43] Iteration 53710, lr = 0.0002
I0526 13:15:12.857702 15394 main.cpp:354] Iteration 53720, loss = 0.281186
I0526 13:15:12.857741 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.281186 (* 1 = 0.281186 loss)
I0526 13:15:12.857748 15394 sgd_solver.cpp:43] Iteration 53720, lr = 0.0002
I0526 13:15:17.653712 15394 main.cpp:354] Iteration 53730, loss = 0.131353
I0526 13:15:17.653749 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.131353 (* 1 = 0.131353 loss)
I0526 13:15:17.653755 15394 sgd_solver.cpp:43] Iteration 53730, lr = 0.0002
I0526 13:15:23.103610 15394 main.cpp:354] Iteration 53740, loss = 0.194549
I0526 13:15:23.103652 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.194548 (* 1 = 0.194548 loss)
I0526 13:15:23.103658 15394 sgd_solver.cpp:43] Iteration 53740, lr = 0.0002
I0526 13:15:28.127549 15394 main.cpp:354] Iteration 53750, loss = 0.312372
I0526 13:15:28.127588 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.312372 (* 1 = 0.312372 loss)
I0526 13:15:28.127595 15394 sgd_solver.cpp:43] Iteration 53750, lr = 0.0002
I0526 13:15:32.934202 15394 main.cpp:354] Iteration 53760, loss = 0.378446
I0526 13:15:32.934242 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.378445 (* 1 = 0.378445 loss)
I0526 13:15:32.934248 15394 sgd_solver.cpp:43] Iteration 53760, lr = 0.0002
I0526 13:15:37.756780 15394 main.cpp:354] Iteration 53770, loss = 0.308007
I0526 13:15:37.756834 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.308007 (* 1 = 0.308007 loss)
I0526 13:15:37.756839 15394 sgd_solver.cpp:43] Iteration 53770, lr = 0.0002
I0526 13:15:42.618491 15394 main.cpp:354] Iteration 53780, loss = 0.273167
I0526 13:15:42.618532 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.273166 (* 1 = 0.273166 loss)
I0526 13:15:42.618538 15394 sgd_solver.cpp:43] Iteration 53780, lr = 0.0002
I0526 13:15:47.732087 15394 main.cpp:354] Iteration 53790, loss = 0.138286
I0526 13:15:47.732123 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.138285 (* 1 = 0.138285 loss)
I0526 13:15:47.732131 15394 sgd_solver.cpp:43] Iteration 53790, lr = 0.0002
I0526 13:15:52.485683 15394 main.cpp:465] Iteration 53800, Testing net (#0)
I0526 13:16:05.572800 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8941
I0526 13:16:05.572834 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.334237 (* 1 = 0.334237 loss)
I0526 13:16:06.043460 15394 main.cpp:354] Iteration 53800, loss = 0.301919
I0526 13:16:06.043494 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.301919 (* 1 = 0.301919 loss)
I0526 13:16:06.043501 15394 sgd_solver.cpp:43] Iteration 53800, lr = 0.0002
I0526 13:16:11.112922 15394 main.cpp:354] Iteration 53810, loss = 0.113292
I0526 13:16:11.112963 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.113292 (* 1 = 0.113292 loss)
I0526 13:16:11.112970 15394 sgd_solver.cpp:43] Iteration 53810, lr = 0.0002
I0526 13:16:16.624718 15394 main.cpp:354] Iteration 53820, loss = 0.160527
I0526 13:16:16.624771 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.160526 (* 1 = 0.160526 loss)
I0526 13:16:16.624789 15394 sgd_solver.cpp:43] Iteration 53820, lr = 0.0002
I0526 13:16:21.348949 15394 main.cpp:354] Iteration 53830, loss = 0.271813
I0526 13:16:21.348994 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.271813 (* 1 = 0.271813 loss)
I0526 13:16:21.348999 15394 sgd_solver.cpp:43] Iteration 53830, lr = 0.0002
I0526 13:16:26.779088 15394 main.cpp:354] Iteration 53840, loss = 0.243958
I0526 13:16:26.779125 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.243957 (* 1 = 0.243957 loss)
I0526 13:16:26.779131 15394 sgd_solver.cpp:43] Iteration 53840, lr = 0.0002
I0526 13:16:31.901639 15394 main.cpp:354] Iteration 53850, loss = 0.384651
I0526 13:16:31.901677 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.384651 (* 1 = 0.384651 loss)
I0526 13:16:31.901684 15394 sgd_solver.cpp:43] Iteration 53850, lr = 0.0002
I0526 13:16:36.937712 15394 main.cpp:354] Iteration 53860, loss = 0.418111
I0526 13:16:36.937754 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.41811 (* 1 = 0.41811 loss)
I0526 13:16:36.937759 15394 sgd_solver.cpp:43] Iteration 53860, lr = 0.0002
I0526 13:16:42.016345 15394 main.cpp:354] Iteration 53870, loss = 0.251113
I0526 13:16:42.016382 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.251113 (* 1 = 0.251113 loss)
I0526 13:16:42.016388 15394 sgd_solver.cpp:43] Iteration 53870, lr = 0.0002
I0526 13:16:46.532447 15394 main.cpp:354] Iteration 53880, loss = 0.159397
I0526 13:16:46.532481 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.159397 (* 1 = 0.159397 loss)
I0526 13:16:46.532488 15394 sgd_solver.cpp:43] Iteration 53880, lr = 0.0002
I0526 13:16:51.715960 15394 main.cpp:354] Iteration 53890, loss = 0.0912765
I0526 13:16:51.716001 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.091276 (* 1 = 0.091276 loss)
I0526 13:16:51.716008 15394 sgd_solver.cpp:43] Iteration 53890, lr = 0.0002
I0526 13:16:56.354640 15394 main.cpp:465] Iteration 53900, Testing net (#0)
I0526 13:17:09.426666 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8958
I0526 13:17:09.426708 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.336504 (* 1 = 0.336504 loss)
I0526 13:17:10.000766 15394 main.cpp:354] Iteration 53900, loss = 0.105454
I0526 13:17:10.000804 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.105453 (* 1 = 0.105453 loss)
I0526 13:17:10.000813 15394 sgd_solver.cpp:43] Iteration 53900, lr = 0.0002
I0526 13:17:14.884470 15394 main.cpp:354] Iteration 53910, loss = 0.243601
I0526 13:17:14.884507 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.243601 (* 1 = 0.243601 loss)
I0526 13:17:14.884513 15394 sgd_solver.cpp:43] Iteration 53910, lr = 0.0002
I0526 13:17:19.947814 15394 main.cpp:354] Iteration 53920, loss = 0.176757
I0526 13:17:19.947854 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.176757 (* 1 = 0.176757 loss)
I0526 13:17:19.947860 15394 sgd_solver.cpp:43] Iteration 53920, lr = 0.0002
I0526 13:17:24.989192 15394 main.cpp:354] Iteration 53930, loss = 0.0628443
I0526 13:17:24.989230 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0628438 (* 1 = 0.0628438 loss)
I0526 13:17:24.989236 15394 sgd_solver.cpp:43] Iteration 53930, lr = 0.0002
I0526 13:17:29.839443 15394 main.cpp:354] Iteration 53940, loss = 0.0975829
I0526 13:17:29.839484 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0975824 (* 1 = 0.0975824 loss)
I0526 13:17:29.839490 15394 sgd_solver.cpp:43] Iteration 53940, lr = 0.0002
I0526 13:17:34.846412 15394 main.cpp:354] Iteration 53950, loss = 0.142941
I0526 13:17:34.846449 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.14294 (* 1 = 0.14294 loss)
I0526 13:17:34.846456 15394 sgd_solver.cpp:43] Iteration 53950, lr = 0.0002
I0526 13:17:39.527281 15394 main.cpp:354] Iteration 53960, loss = 0.150276
I0526 13:17:39.527320 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.150276 (* 1 = 0.150276 loss)
I0526 13:17:39.527326 15394 sgd_solver.cpp:43] Iteration 53960, lr = 0.0002
I0526 13:17:44.109673 15394 main.cpp:354] Iteration 53970, loss = 0.584505
I0526 13:17:44.109707 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.584504 (* 1 = 0.584504 loss)
I0526 13:17:44.109714 15394 sgd_solver.cpp:43] Iteration 53970, lr = 0.0002
I0526 13:17:49.077905 15394 main.cpp:354] Iteration 53980, loss = 0.0865605
I0526 13:17:49.077946 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.08656 (* 1 = 0.08656 loss)
I0526 13:17:49.077953 15394 sgd_solver.cpp:43] Iteration 53980, lr = 0.0002
I0526 13:17:54.022971 15394 main.cpp:354] Iteration 53990, loss = 0.234227
I0526 13:17:54.023010 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.234226 (* 1 = 0.234226 loss)
I0526 13:17:54.023015 15394 sgd_solver.cpp:43] Iteration 53990, lr = 0.0002
I0526 13:17:58.675292 15394 main.cpp:465] Iteration 54000, Testing net (#0)
I0526 13:18:11.752964 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8956
I0526 13:18:11.753005 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.324125 (* 1 = 0.324125 loss)
I0526 13:18:12.224849 15394 main.cpp:354] Iteration 54000, loss = 0.118809
I0526 13:18:12.224879 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.118809 (* 1 = 0.118809 loss)
I0526 13:18:12.224887 15394 sgd_solver.cpp:43] Iteration 54000, lr = 0.0002
I0526 13:18:17.365461 15394 main.cpp:354] Iteration 54010, loss = 0.19178
I0526 13:18:17.365495 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.191779 (* 1 = 0.191779 loss)
I0526 13:18:17.365500 15394 sgd_solver.cpp:43] Iteration 54010, lr = 0.0002
I0526 13:18:22.159291 15394 main.cpp:354] Iteration 54020, loss = 0.174898
I0526 13:18:22.159332 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.174898 (* 1 = 0.174898 loss)
I0526 13:18:22.159337 15394 sgd_solver.cpp:43] Iteration 54020, lr = 0.0002
I0526 13:18:26.741159 15394 main.cpp:354] Iteration 54030, loss = 0.161773
I0526 13:18:26.741204 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.161773 (* 1 = 0.161773 loss)
I0526 13:18:26.741210 15394 sgd_solver.cpp:43] Iteration 54030, lr = 0.0002
I0526 13:18:32.080193 15394 main.cpp:354] Iteration 54040, loss = 0.228103
I0526 13:18:32.080229 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.228103 (* 1 = 0.228103 loss)
I0526 13:18:32.080235 15394 sgd_solver.cpp:43] Iteration 54040, lr = 0.0002
I0526 13:18:37.367156 15394 main.cpp:354] Iteration 54050, loss = 0.214754
I0526 13:18:37.367197 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.214754 (* 1 = 0.214754 loss)
I0526 13:18:37.367202 15394 sgd_solver.cpp:43] Iteration 54050, lr = 0.0002
I0526 13:18:42.235508 15394 main.cpp:354] Iteration 54060, loss = 0.5274
I0526 13:18:42.235548 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.527399 (* 1 = 0.527399 loss)
I0526 13:18:42.235553 15394 sgd_solver.cpp:43] Iteration 54060, lr = 0.0002
I0526 13:18:47.187389 15394 main.cpp:354] Iteration 54070, loss = 0.232396
I0526 13:18:47.187429 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.232396 (* 1 = 0.232396 loss)
I0526 13:18:47.187435 15394 sgd_solver.cpp:43] Iteration 54070, lr = 0.0002
I0526 13:18:52.827319 15394 main.cpp:354] Iteration 54080, loss = 0.0944763
I0526 13:18:52.827360 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0944758 (* 1 = 0.0944758 loss)
I0526 13:18:52.827365 15394 sgd_solver.cpp:43] Iteration 54080, lr = 0.0002
I0526 13:18:58.068114 15394 main.cpp:354] Iteration 54090, loss = 0.249281
I0526 13:18:58.068151 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.24928 (* 1 = 0.24928 loss)
I0526 13:18:58.068157 15394 sgd_solver.cpp:43] Iteration 54090, lr = 0.0002
I0526 13:19:02.615423 15394 main.cpp:465] Iteration 54100, Testing net (#0)
I0526 13:19:15.687155 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8962
I0526 13:19:15.687198 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.326467 (* 1 = 0.326467 loss)
I0526 13:19:16.155035 15394 main.cpp:354] Iteration 54100, loss = 0.304701
I0526 13:19:16.155069 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.3047 (* 1 = 0.3047 loss)
I0526 13:19:16.155077 15394 sgd_solver.cpp:43] Iteration 54100, lr = 0.0002
I0526 13:19:21.480934 15394 main.cpp:354] Iteration 54110, loss = 0.186441
I0526 13:19:21.480975 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.18644 (* 1 = 0.18644 loss)
I0526 13:19:21.480981 15394 sgd_solver.cpp:43] Iteration 54110, lr = 0.0002
I0526 13:19:26.330781 15394 main.cpp:354] Iteration 54120, loss = 0.138628
I0526 13:19:26.330818 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.138628 (* 1 = 0.138628 loss)
I0526 13:19:26.330824 15394 sgd_solver.cpp:43] Iteration 54120, lr = 0.0002
I0526 13:19:31.414048 15394 main.cpp:354] Iteration 54130, loss = 0.164317
I0526 13:19:31.414086 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.164316 (* 1 = 0.164316 loss)
I0526 13:19:31.414098 15394 sgd_solver.cpp:43] Iteration 54130, lr = 0.0002
I0526 13:19:36.694900 15394 main.cpp:354] Iteration 54140, loss = 0.20862
I0526 13:19:36.694941 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.20862 (* 1 = 0.20862 loss)
I0526 13:19:36.694947 15394 sgd_solver.cpp:43] Iteration 54140, lr = 0.0002
I0526 13:19:41.830664 15394 main.cpp:354] Iteration 54150, loss = 0.173235
I0526 13:19:41.830713 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.173235 (* 1 = 0.173235 loss)
I0526 13:19:41.830719 15394 sgd_solver.cpp:43] Iteration 54150, lr = 0.0002
I0526 13:19:47.351609 15394 main.cpp:354] Iteration 54160, loss = 0.247067
I0526 13:19:47.351649 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.247067 (* 1 = 0.247067 loss)
I0526 13:19:47.351656 15394 sgd_solver.cpp:43] Iteration 54160, lr = 0.0002
I0526 13:19:52.371800 15394 main.cpp:354] Iteration 54170, loss = 0.210623
I0526 13:19:52.371842 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.210623 (* 1 = 0.210623 loss)
I0526 13:19:52.371848 15394 sgd_solver.cpp:43] Iteration 54170, lr = 0.0002
I0526 13:19:57.282727 15394 main.cpp:354] Iteration 54180, loss = 0.216164
I0526 13:19:57.282763 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.216163 (* 1 = 0.216163 loss)
I0526 13:19:57.282769 15394 sgd_solver.cpp:43] Iteration 54180, lr = 0.0002
I0526 13:20:01.696661 15394 main.cpp:354] Iteration 54190, loss = 0.244158
I0526 13:20:01.696697 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.244158 (* 1 = 0.244158 loss)
I0526 13:20:01.696704 15394 sgd_solver.cpp:43] Iteration 54190, lr = 0.0002
I0526 13:20:06.302875 15394 main.cpp:465] Iteration 54200, Testing net (#0)
I0526 13:20:19.385632 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8951
I0526 13:20:19.385675 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.333725 (* 1 = 0.333725 loss)
I0526 13:20:19.889484 15394 main.cpp:354] Iteration 54200, loss = 0.147178
I0526 13:20:19.889523 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.147178 (* 1 = 0.147178 loss)
I0526 13:20:19.889531 15394 sgd_solver.cpp:43] Iteration 54200, lr = 0.0002
I0526 13:20:24.937175 15394 main.cpp:354] Iteration 54210, loss = 0.222993
I0526 13:20:24.937212 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.222992 (* 1 = 0.222992 loss)
I0526 13:20:24.937218 15394 sgd_solver.cpp:43] Iteration 54210, lr = 0.0002
I0526 13:20:29.898123 15394 main.cpp:354] Iteration 54220, loss = 0.187855
I0526 13:20:29.898162 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187855 (* 1 = 0.187855 loss)
I0526 13:20:29.898169 15394 sgd_solver.cpp:43] Iteration 54220, lr = 0.0002
I0526 13:20:34.926247 15394 main.cpp:354] Iteration 54230, loss = 0.126504
I0526 13:20:34.926287 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.126503 (* 1 = 0.126503 loss)
I0526 13:20:34.926295 15394 sgd_solver.cpp:43] Iteration 54230, lr = 0.0002
I0526 13:20:40.582885 15394 main.cpp:354] Iteration 54240, loss = 0.189212
I0526 13:20:40.582923 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.189212 (* 1 = 0.189212 loss)
I0526 13:20:40.582939 15394 sgd_solver.cpp:43] Iteration 54240, lr = 0.0002
I0526 13:20:45.969353 15394 main.cpp:354] Iteration 54250, loss = 0.170966
I0526 13:20:45.969389 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.170966 (* 1 = 0.170966 loss)
I0526 13:20:45.969395 15394 sgd_solver.cpp:43] Iteration 54250, lr = 0.0002
I0526 13:20:51.141225 15394 main.cpp:354] Iteration 54260, loss = 0.23325
I0526 13:20:51.141268 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.23325 (* 1 = 0.23325 loss)
I0526 13:20:51.141274 15394 sgd_solver.cpp:43] Iteration 54260, lr = 0.0002
I0526 13:20:56.518733 15394 main.cpp:354] Iteration 54270, loss = 0.129227
I0526 13:20:56.518771 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.129226 (* 1 = 0.129226 loss)
I0526 13:20:56.518784 15394 sgd_solver.cpp:43] Iteration 54270, lr = 0.0002
I0526 13:21:01.608444 15394 main.cpp:354] Iteration 54280, loss = 0.301586
I0526 13:21:01.608480 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.301585 (* 1 = 0.301585 loss)
I0526 13:21:01.608486 15394 sgd_solver.cpp:43] Iteration 54280, lr = 0.0002
I0526 13:21:06.725169 15394 main.cpp:354] Iteration 54290, loss = 0.169745
I0526 13:21:06.725209 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.169744 (* 1 = 0.169744 loss)
I0526 13:21:06.725215 15394 sgd_solver.cpp:43] Iteration 54290, lr = 0.0002
I0526 13:21:10.998513 15394 main.cpp:465] Iteration 54300, Testing net (#0)
I0526 13:21:24.095577 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8935
I0526 13:21:24.095620 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.340415 (* 1 = 0.340415 loss)
I0526 13:21:24.570037 15394 main.cpp:354] Iteration 54300, loss = 0.199908
I0526 13:21:24.570076 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.199908 (* 1 = 0.199908 loss)
I0526 13:21:24.570083 15394 sgd_solver.cpp:43] Iteration 54300, lr = 0.0002
I0526 13:21:29.770952 15394 main.cpp:354] Iteration 54310, loss = 0.244129
I0526 13:21:29.770990 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.244129 (* 1 = 0.244129 loss)
I0526 13:21:29.770997 15394 sgd_solver.cpp:43] Iteration 54310, lr = 0.0002
I0526 13:21:35.377943 15394 main.cpp:354] Iteration 54320, loss = 0.139441
I0526 13:21:35.377985 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.139441 (* 1 = 0.139441 loss)
I0526 13:21:35.377990 15394 sgd_solver.cpp:43] Iteration 54320, lr = 0.0002
I0526 13:21:40.271617 15394 main.cpp:354] Iteration 54330, loss = 0.425727
I0526 13:21:40.271662 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.425727 (* 1 = 0.425727 loss)
I0526 13:21:40.271668 15394 sgd_solver.cpp:43] Iteration 54330, lr = 0.0002
I0526 13:21:45.430502 15394 main.cpp:354] Iteration 54340, loss = 0.275852
I0526 13:21:45.430541 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.275851 (* 1 = 0.275851 loss)
I0526 13:21:45.430546 15394 sgd_solver.cpp:43] Iteration 54340, lr = 0.0002
I0526 13:21:50.636852 15394 main.cpp:354] Iteration 54350, loss = 0.164524
I0526 13:21:50.636893 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.164523 (* 1 = 0.164523 loss)
I0526 13:21:50.636899 15394 sgd_solver.cpp:43] Iteration 54350, lr = 0.0002
I0526 13:21:56.005138 15394 main.cpp:354] Iteration 54360, loss = 0.177996
I0526 13:21:56.005178 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.177995 (* 1 = 0.177995 loss)
I0526 13:21:56.005185 15394 sgd_solver.cpp:43] Iteration 54360, lr = 0.0002
I0526 13:22:00.912129 15394 main.cpp:354] Iteration 54370, loss = 0.116678
I0526 13:22:00.912168 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.116677 (* 1 = 0.116677 loss)
I0526 13:22:00.912173 15394 sgd_solver.cpp:43] Iteration 54370, lr = 0.0002
I0526 13:22:05.624577 15394 main.cpp:354] Iteration 54380, loss = 0.232126
I0526 13:22:05.624632 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.232126 (* 1 = 0.232126 loss)
I0526 13:22:05.624639 15394 sgd_solver.cpp:43] Iteration 54380, lr = 0.0002
I0526 13:22:10.677888 15394 main.cpp:354] Iteration 54390, loss = 0.0663039
I0526 13:22:10.677928 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0663035 (* 1 = 0.0663035 loss)
I0526 13:22:10.677934 15394 sgd_solver.cpp:43] Iteration 54390, lr = 0.0002
I0526 13:22:15.721320 15394 main.cpp:465] Iteration 54400, Testing net (#0)
I0526 13:22:28.821522 15394 main.cpp:532]     Test net output #0: Accuracy = 0.896
I0526 13:22:28.821560 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.329104 (* 1 = 0.329104 loss)
I0526 13:22:29.397485 15394 main.cpp:354] Iteration 54400, loss = 0.139619
I0526 13:22:29.397521 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.139619 (* 1 = 0.139619 loss)
I0526 13:22:29.397528 15394 sgd_solver.cpp:43] Iteration 54400, lr = 0.0002
I0526 13:22:34.645813 15394 main.cpp:354] Iteration 54410, loss = 0.0821425
I0526 13:22:34.645862 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.082142 (* 1 = 0.082142 loss)
I0526 13:22:34.645869 15394 sgd_solver.cpp:43] Iteration 54410, lr = 0.0002
I0526 13:22:39.981410 15394 main.cpp:354] Iteration 54420, loss = 0.124926
I0526 13:22:39.981448 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.124925 (* 1 = 0.124925 loss)
I0526 13:22:39.981454 15394 sgd_solver.cpp:43] Iteration 54420, lr = 0.0002
I0526 13:22:44.919574 15394 main.cpp:354] Iteration 54430, loss = 0.171746
I0526 13:22:44.919613 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.171745 (* 1 = 0.171745 loss)
I0526 13:22:44.919620 15394 sgd_solver.cpp:43] Iteration 54430, lr = 0.0002
I0526 13:22:49.849835 15394 main.cpp:354] Iteration 54440, loss = 0.23644
I0526 13:22:49.849879 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.23644 (* 1 = 0.23644 loss)
I0526 13:22:49.849884 15394 sgd_solver.cpp:43] Iteration 54440, lr = 0.0002
I0526 13:22:54.882597 15394 main.cpp:354] Iteration 54450, loss = 0.161007
I0526 13:22:54.882635 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.161007 (* 1 = 0.161007 loss)
I0526 13:22:54.882642 15394 sgd_solver.cpp:43] Iteration 54450, lr = 0.0002
I0526 13:22:59.939949 15394 main.cpp:354] Iteration 54460, loss = 0.246073
I0526 13:22:59.939990 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.246073 (* 1 = 0.246073 loss)
I0526 13:22:59.939997 15394 sgd_solver.cpp:43] Iteration 54460, lr = 0.0002
I0526 13:23:05.288269 15394 main.cpp:354] Iteration 54470, loss = 0.128194
I0526 13:23:05.288318 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.128194 (* 1 = 0.128194 loss)
I0526 13:23:05.288324 15394 sgd_solver.cpp:43] Iteration 54470, lr = 0.0002
I0526 13:23:10.734215 15394 main.cpp:354] Iteration 54480, loss = 0.201889
I0526 13:23:10.734252 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.201889 (* 1 = 0.201889 loss)
I0526 13:23:10.734257 15394 sgd_solver.cpp:43] Iteration 54480, lr = 0.0002
I0526 13:23:15.940382 15394 main.cpp:354] Iteration 54490, loss = 0.154175
I0526 13:23:15.940419 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.154174 (* 1 = 0.154174 loss)
I0526 13:23:15.940425 15394 sgd_solver.cpp:43] Iteration 54490, lr = 0.0002
I0526 13:23:20.942020 15394 main.cpp:465] Iteration 54500, Testing net (#0)
I0526 13:23:34.054152 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8948
I0526 13:23:34.054196 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.328347 (* 1 = 0.328347 loss)
I0526 13:23:34.596057 15394 main.cpp:354] Iteration 54500, loss = 0.0592816
I0526 13:23:34.596091 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0592811 (* 1 = 0.0592811 loss)
I0526 13:23:34.596099 15394 sgd_solver.cpp:43] Iteration 54500, lr = 0.0002
I0526 13:23:39.788072 15394 main.cpp:354] Iteration 54510, loss = 0.175817
I0526 13:23:39.788110 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.175817 (* 1 = 0.175817 loss)
I0526 13:23:39.788116 15394 sgd_solver.cpp:43] Iteration 54510, lr = 0.0002
I0526 13:23:44.870908 15394 main.cpp:354] Iteration 54520, loss = 0.123974
I0526 13:23:44.870945 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.123973 (* 1 = 0.123973 loss)
I0526 13:23:44.870951 15394 sgd_solver.cpp:43] Iteration 54520, lr = 0.0002
I0526 13:23:49.748342 15394 main.cpp:354] Iteration 54530, loss = 0.355404
I0526 13:23:49.748383 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.355404 (* 1 = 0.355404 loss)
I0526 13:23:49.748389 15394 sgd_solver.cpp:43] Iteration 54530, lr = 0.0002
I0526 13:23:54.882483 15394 main.cpp:354] Iteration 54540, loss = 0.19247
I0526 13:23:54.882519 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.19247 (* 1 = 0.19247 loss)
I0526 13:23:54.882525 15394 sgd_solver.cpp:43] Iteration 54540, lr = 0.0002
I0526 13:23:59.897631 15394 main.cpp:354] Iteration 54550, loss = 0.152659
I0526 13:23:59.897671 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.152658 (* 1 = 0.152658 loss)
I0526 13:23:59.897677 15394 sgd_solver.cpp:43] Iteration 54550, lr = 0.0002
I0526 13:24:05.027386 15394 main.cpp:354] Iteration 54560, loss = 0.416899
I0526 13:24:05.027441 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.416898 (* 1 = 0.416898 loss)
I0526 13:24:05.027447 15394 sgd_solver.cpp:43] Iteration 54560, lr = 0.0002
I0526 13:24:10.335675 15394 main.cpp:354] Iteration 54570, loss = 0.266432
I0526 13:24:10.335713 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.266432 (* 1 = 0.266432 loss)
I0526 13:24:10.335719 15394 sgd_solver.cpp:43] Iteration 54570, lr = 0.0002
I0526 13:24:15.509153 15394 main.cpp:354] Iteration 54580, loss = 0.14922
I0526 13:24:15.509191 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.14922 (* 1 = 0.14922 loss)
I0526 13:24:15.509197 15394 sgd_solver.cpp:43] Iteration 54580, lr = 0.0002
I0526 13:24:20.185307 15394 main.cpp:354] Iteration 54590, loss = 0.146719
I0526 13:24:20.185349 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.146718 (* 1 = 0.146718 loss)
I0526 13:24:20.185356 15394 sgd_solver.cpp:43] Iteration 54590, lr = 0.0002
I0526 13:24:25.004216 15394 main.cpp:465] Iteration 54600, Testing net (#0)
I0526 13:24:38.122411 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8965
I0526 13:24:38.122452 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.333375 (* 1 = 0.333375 loss)
I0526 13:24:38.661828 15394 main.cpp:354] Iteration 54600, loss = 0.229633
I0526 13:24:38.661867 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.229633 (* 1 = 0.229633 loss)
I0526 13:24:38.661876 15394 sgd_solver.cpp:43] Iteration 54600, lr = 0.0002
I0526 13:24:43.011883 15394 main.cpp:354] Iteration 54610, loss = 0.251704
I0526 13:24:43.011917 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.251704 (* 1 = 0.251704 loss)
I0526 13:24:43.011924 15394 sgd_solver.cpp:43] Iteration 54610, lr = 0.0002
I0526 13:24:48.084743 15394 main.cpp:354] Iteration 54620, loss = 0.270878
I0526 13:24:48.084776 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.270878 (* 1 = 0.270878 loss)
I0526 13:24:48.084782 15394 sgd_solver.cpp:43] Iteration 54620, lr = 0.0002
I0526 13:24:52.700786 15394 main.cpp:354] Iteration 54630, loss = 0.150905
I0526 13:24:52.700829 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.150904 (* 1 = 0.150904 loss)
I0526 13:24:52.700835 15394 sgd_solver.cpp:43] Iteration 54630, lr = 0.0002
I0526 13:24:57.833214 15394 main.cpp:354] Iteration 54640, loss = 0.18308
I0526 13:24:57.833250 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.18308 (* 1 = 0.18308 loss)
I0526 13:24:57.833256 15394 sgd_solver.cpp:43] Iteration 54640, lr = 0.0002
I0526 13:25:03.022001 15394 main.cpp:354] Iteration 54650, loss = 0.237026
I0526 13:25:03.022038 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.237026 (* 1 = 0.237026 loss)
I0526 13:25:03.022044 15394 sgd_solver.cpp:43] Iteration 54650, lr = 0.0002
I0526 13:25:08.618914 15394 main.cpp:354] Iteration 54660, loss = 0.300063
I0526 13:25:08.618957 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.300063 (* 1 = 0.300063 loss)
I0526 13:25:08.618963 15394 sgd_solver.cpp:43] Iteration 54660, lr = 0.0002
I0526 13:25:13.858436 15394 main.cpp:354] Iteration 54670, loss = 0.169972
I0526 13:25:13.858474 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.169971 (* 1 = 0.169971 loss)
I0526 13:25:13.858480 15394 sgd_solver.cpp:43] Iteration 54670, lr = 0.0002
I0526 13:25:19.298207 15394 main.cpp:354] Iteration 54680, loss = 0.132053
I0526 13:25:19.298246 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.132053 (* 1 = 0.132053 loss)
I0526 13:25:19.298254 15394 sgd_solver.cpp:43] Iteration 54680, lr = 0.0002
I0526 13:25:23.762070 15394 main.cpp:354] Iteration 54690, loss = 0.139925
I0526 13:25:23.762109 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.139924 (* 1 = 0.139924 loss)
I0526 13:25:23.762120 15394 sgd_solver.cpp:43] Iteration 54690, lr = 0.0002
I0526 13:25:28.392143 15394 main.cpp:465] Iteration 54700, Testing net (#0)
I0526 13:25:41.487656 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8963
I0526 13:25:41.487699 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.327881 (* 1 = 0.327881 loss)
I0526 13:25:42.026895 15394 main.cpp:354] Iteration 54700, loss = 0.102102
I0526 13:25:42.026934 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.102101 (* 1 = 0.102101 loss)
I0526 13:25:42.026942 15394 sgd_solver.cpp:43] Iteration 54700, lr = 0.0002
I0526 13:25:46.927634 15394 main.cpp:354] Iteration 54710, loss = 0.305699
I0526 13:25:46.927672 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.305698 (* 1 = 0.305698 loss)
I0526 13:25:46.927678 15394 sgd_solver.cpp:43] Iteration 54710, lr = 0.0002
I0526 13:25:52.170594 15394 main.cpp:354] Iteration 54720, loss = 0.240674
I0526 13:25:52.170634 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.240673 (* 1 = 0.240673 loss)
I0526 13:25:52.170639 15394 sgd_solver.cpp:43] Iteration 54720, lr = 0.0002
I0526 13:25:57.488826 15394 main.cpp:354] Iteration 54730, loss = 0.133424
I0526 13:25:57.488865 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.133423 (* 1 = 0.133423 loss)
I0526 13:25:57.488872 15394 sgd_solver.cpp:43] Iteration 54730, lr = 0.0002
I0526 13:26:02.905576 15394 main.cpp:354] Iteration 54740, loss = 0.151342
I0526 13:26:02.905614 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.151341 (* 1 = 0.151341 loss)
I0526 13:26:02.905621 15394 sgd_solver.cpp:43] Iteration 54740, lr = 0.0002
I0526 13:26:08.432384 15394 main.cpp:354] Iteration 54750, loss = 0.215431
I0526 13:26:08.432425 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.21543 (* 1 = 0.21543 loss)
I0526 13:26:08.432431 15394 sgd_solver.cpp:43] Iteration 54750, lr = 0.0002
I0526 13:26:13.655581 15394 main.cpp:354] Iteration 54760, loss = 0.528024
I0526 13:26:13.655618 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.528023 (* 1 = 0.528023 loss)
I0526 13:26:13.655623 15394 sgd_solver.cpp:43] Iteration 54760, lr = 0.0002
I0526 13:26:18.527551 15394 main.cpp:354] Iteration 54770, loss = 0.34914
I0526 13:26:18.527590 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.349139 (* 1 = 0.349139 loss)
I0526 13:26:18.527595 15394 sgd_solver.cpp:43] Iteration 54770, lr = 0.0002
I0526 13:26:23.922395 15394 main.cpp:354] Iteration 54780, loss = 0.0766907
I0526 13:26:23.922436 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0766903 (* 1 = 0.0766903 loss)
I0526 13:26:23.922442 15394 sgd_solver.cpp:43] Iteration 54780, lr = 0.0002
I0526 13:26:28.548799 15394 main.cpp:354] Iteration 54790, loss = 0.185049
I0526 13:26:28.548835 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.185048 (* 1 = 0.185048 loss)
I0526 13:26:28.548842 15394 sgd_solver.cpp:43] Iteration 54790, lr = 0.0002
I0526 13:26:32.993167 15394 main.cpp:465] Iteration 54800, Testing net (#0)
I0526 13:26:46.093359 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8978
I0526 13:26:46.093400 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.331939 (* 1 = 0.331939 loss)
I0526 13:26:46.673739 15394 main.cpp:354] Iteration 54800, loss = 0.127582
I0526 13:26:46.673774 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.127581 (* 1 = 0.127581 loss)
I0526 13:26:46.673784 15394 sgd_solver.cpp:43] Iteration 54800, lr = 0.0002
I0526 13:26:51.916780 15394 main.cpp:354] Iteration 54810, loss = 0.236413
I0526 13:26:51.916822 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.236413 (* 1 = 0.236413 loss)
I0526 13:26:51.916828 15394 sgd_solver.cpp:43] Iteration 54810, lr = 0.0002
I0526 13:26:57.046941 15394 main.cpp:354] Iteration 54820, loss = 0.195016
I0526 13:26:57.046979 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.195016 (* 1 = 0.195016 loss)
I0526 13:26:57.046990 15394 sgd_solver.cpp:43] Iteration 54820, lr = 0.0002
I0526 13:27:02.073062 15394 main.cpp:354] Iteration 54830, loss = 0.423291
I0526 13:27:02.073098 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.42329 (* 1 = 0.42329 loss)
I0526 13:27:02.073104 15394 sgd_solver.cpp:43] Iteration 54830, lr = 0.0002
I0526 13:27:07.193028 15394 main.cpp:354] Iteration 54840, loss = 0.250874
I0526 13:27:07.193071 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.250873 (* 1 = 0.250873 loss)
I0526 13:27:07.193078 15394 sgd_solver.cpp:43] Iteration 54840, lr = 0.0002
I0526 13:27:12.067636 15394 main.cpp:354] Iteration 54850, loss = 0.146573
I0526 13:27:12.067675 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.146572 (* 1 = 0.146572 loss)
I0526 13:27:12.067682 15394 sgd_solver.cpp:43] Iteration 54850, lr = 0.0002
I0526 13:27:17.035177 15394 main.cpp:354] Iteration 54860, loss = 0.456866
I0526 13:27:17.035214 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.456866 (* 1 = 0.456866 loss)
I0526 13:27:17.035220 15394 sgd_solver.cpp:43] Iteration 54860, lr = 0.0002
I0526 13:27:22.183632 15394 main.cpp:354] Iteration 54870, loss = 0.46271
I0526 13:27:22.183676 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.46271 (* 1 = 0.46271 loss)
I0526 13:27:22.183682 15394 sgd_solver.cpp:43] Iteration 54870, lr = 0.0002
I0526 13:27:27.488476 15394 main.cpp:354] Iteration 54880, loss = 0.201631
I0526 13:27:27.488513 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.201631 (* 1 = 0.201631 loss)
I0526 13:27:27.488518 15394 sgd_solver.cpp:43] Iteration 54880, lr = 0.0002
I0526 13:27:32.940079 15394 main.cpp:354] Iteration 54890, loss = 0.118169
I0526 13:27:32.940117 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.118168 (* 1 = 0.118168 loss)
I0526 13:27:32.940124 15394 sgd_solver.cpp:43] Iteration 54890, lr = 0.0002
I0526 13:27:37.915458 15394 main.cpp:465] Iteration 54900, Testing net (#0)
I0526 13:27:51.012449 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8958
I0526 13:27:51.012495 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.33512 (* 1 = 0.33512 loss)
I0526 13:27:51.478932 15394 main.cpp:354] Iteration 54900, loss = 0.262395
I0526 13:27:51.478971 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.262394 (* 1 = 0.262394 loss)
I0526 13:27:51.478979 15394 sgd_solver.cpp:43] Iteration 54900, lr = 0.0002
I0526 13:27:56.646404 15394 main.cpp:354] Iteration 54910, loss = 0.199887
I0526 13:27:56.646443 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.199886 (* 1 = 0.199886 loss)
I0526 13:27:56.646450 15394 sgd_solver.cpp:43] Iteration 54910, lr = 0.0002
I0526 13:28:01.696372 15394 main.cpp:354] Iteration 54920, loss = 0.14238
I0526 13:28:01.696408 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.142379 (* 1 = 0.142379 loss)
I0526 13:28:01.696414 15394 sgd_solver.cpp:43] Iteration 54920, lr = 0.0002
I0526 13:28:06.527189 15394 main.cpp:354] Iteration 54930, loss = 0.215985
I0526 13:28:06.527227 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.215985 (* 1 = 0.215985 loss)
I0526 13:28:06.527233 15394 sgd_solver.cpp:43] Iteration 54930, lr = 0.0002
I0526 13:28:11.776643 15394 main.cpp:354] Iteration 54940, loss = 0.199682
I0526 13:28:11.776679 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.199681 (* 1 = 0.199681 loss)
I0526 13:28:11.776685 15394 sgd_solver.cpp:43] Iteration 54940, lr = 0.0002
I0526 13:28:17.084141 15394 main.cpp:354] Iteration 54950, loss = 0.254883
I0526 13:28:17.084175 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.254882 (* 1 = 0.254882 loss)
I0526 13:28:17.084182 15394 sgd_solver.cpp:43] Iteration 54950, lr = 0.0002
I0526 13:28:22.226685 15394 main.cpp:354] Iteration 54960, loss = 0.209001
I0526 13:28:22.226739 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.209001 (* 1 = 0.209001 loss)
I0526 13:28:22.226745 15394 sgd_solver.cpp:43] Iteration 54960, lr = 0.0002
I0526 13:28:27.375669 15394 main.cpp:354] Iteration 54970, loss = 0.170151
I0526 13:28:27.375706 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.170151 (* 1 = 0.170151 loss)
I0526 13:28:27.375712 15394 sgd_solver.cpp:43] Iteration 54970, lr = 0.0002
I0526 13:28:32.363111 15394 main.cpp:354] Iteration 54980, loss = 0.315879
I0526 13:28:32.363143 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.315878 (* 1 = 0.315878 loss)
I0526 13:28:32.363149 15394 sgd_solver.cpp:43] Iteration 54980, lr = 0.0002
I0526 13:28:37.652808 15394 main.cpp:354] Iteration 54990, loss = 0.160788
I0526 13:28:37.652848 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.160788 (* 1 = 0.160788 loss)
I0526 13:28:37.652853 15394 sgd_solver.cpp:43] Iteration 54990, lr = 0.0002
I0526 13:28:42.317036 15394 main.cpp:465] Iteration 55000, Testing net (#0)
I0526 13:28:55.423804 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8961
I0526 13:28:55.423851 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.326612 (* 1 = 0.326612 loss)
I0526 13:28:55.926723 15394 main.cpp:354] Iteration 55000, loss = 0.126091
I0526 13:28:55.926754 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.126091 (* 1 = 0.126091 loss)
I0526 13:28:55.926762 15394 sgd_solver.cpp:43] Iteration 55000, lr = 0.0002
I0526 13:29:00.911913 15394 main.cpp:354] Iteration 55010, loss = 0.266559
I0526 13:29:00.911953 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.266559 (* 1 = 0.266559 loss)
I0526 13:29:00.911959 15394 sgd_solver.cpp:43] Iteration 55010, lr = 0.0002
I0526 13:29:05.953441 15394 main.cpp:354] Iteration 55020, loss = 0.147221
I0526 13:29:05.953480 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.147221 (* 1 = 0.147221 loss)
I0526 13:29:05.953485 15394 sgd_solver.cpp:43] Iteration 55020, lr = 0.0002
I0526 13:29:10.963033 15394 main.cpp:354] Iteration 55030, loss = 0.261401
I0526 13:29:10.963071 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.2614 (* 1 = 0.2614 loss)
I0526 13:29:10.963076 15394 sgd_solver.cpp:43] Iteration 55030, lr = 0.0002
I0526 13:29:15.786049 15394 main.cpp:354] Iteration 55040, loss = 0.238175
I0526 13:29:15.786087 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.238174 (* 1 = 0.238174 loss)
I0526 13:29:15.786092 15394 sgd_solver.cpp:43] Iteration 55040, lr = 0.0002
I0526 13:29:20.986562 15394 main.cpp:354] Iteration 55050, loss = 0.287736
I0526 13:29:20.986600 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.287736 (* 1 = 0.287736 loss)
I0526 13:29:20.986608 15394 sgd_solver.cpp:43] Iteration 55050, lr = 0.0002
I0526 13:29:25.743863 15394 main.cpp:354] Iteration 55060, loss = 0.22405
I0526 13:29:25.743902 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.224049 (* 1 = 0.224049 loss)
I0526 13:29:25.743908 15394 sgd_solver.cpp:43] Iteration 55060, lr = 0.0002
I0526 13:29:31.045274 15394 main.cpp:354] Iteration 55070, loss = 0.136338
I0526 13:29:31.045311 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.136338 (* 1 = 0.136338 loss)
I0526 13:29:31.045317 15394 sgd_solver.cpp:43] Iteration 55070, lr = 0.0002
I0526 13:29:35.638808 15394 main.cpp:354] Iteration 55080, loss = 0.203917
I0526 13:29:35.638849 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.203917 (* 1 = 0.203917 loss)
I0526 13:29:35.638855 15394 sgd_solver.cpp:43] Iteration 55080, lr = 0.0002
I0526 13:29:41.045642 15394 main.cpp:354] Iteration 55090, loss = 0.185423
I0526 13:29:41.045682 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.185423 (* 1 = 0.185423 loss)
I0526 13:29:41.045688 15394 sgd_solver.cpp:43] Iteration 55090, lr = 0.0002
I0526 13:29:45.602295 15394 main.cpp:465] Iteration 55100, Testing net (#0)
I0526 13:29:58.711073 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8966
I0526 13:29:58.711115 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.330068 (* 1 = 0.330068 loss)
I0526 13:29:59.286054 15394 main.cpp:354] Iteration 55100, loss = 0.0763048
I0526 13:29:59.286087 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0763044 (* 1 = 0.0763044 loss)
I0526 13:29:59.286097 15394 sgd_solver.cpp:43] Iteration 55100, lr = 0.0002
I0526 13:30:04.382417 15394 main.cpp:354] Iteration 55110, loss = 0.190069
I0526 13:30:04.382459 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.190069 (* 1 = 0.190069 loss)
I0526 13:30:04.382467 15394 sgd_solver.cpp:43] Iteration 55110, lr = 0.0002
I0526 13:30:09.595196 15394 main.cpp:354] Iteration 55120, loss = 0.226924
I0526 13:30:09.595232 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.226924 (* 1 = 0.226924 loss)
I0526 13:30:09.595237 15394 sgd_solver.cpp:43] Iteration 55120, lr = 0.0002
I0526 13:30:14.917587 15394 main.cpp:354] Iteration 55130, loss = 0.254068
I0526 13:30:14.917624 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.254068 (* 1 = 0.254068 loss)
I0526 13:30:14.917630 15394 sgd_solver.cpp:43] Iteration 55130, lr = 0.0002
I0526 13:30:20.057953 15394 main.cpp:354] Iteration 55140, loss = 0.220756
I0526 13:30:20.057994 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.220756 (* 1 = 0.220756 loss)
I0526 13:30:20.058001 15394 sgd_solver.cpp:43] Iteration 55140, lr = 0.0002
I0526 13:30:25.364608 15394 main.cpp:354] Iteration 55150, loss = 0.27201
I0526 13:30:25.364645 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.27201 (* 1 = 0.27201 loss)
I0526 13:30:25.364650 15394 sgd_solver.cpp:43] Iteration 55150, lr = 0.0002
I0526 13:30:30.321149 15394 main.cpp:354] Iteration 55160, loss = 0.24969
I0526 13:30:30.321189 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.249689 (* 1 = 0.249689 loss)
I0526 13:30:30.321195 15394 sgd_solver.cpp:43] Iteration 55160, lr = 0.0002
I0526 13:30:34.983819 15394 main.cpp:354] Iteration 55170, loss = 0.233627
I0526 13:30:34.983861 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.233626 (* 1 = 0.233626 loss)
I0526 13:30:34.983867 15394 sgd_solver.cpp:43] Iteration 55170, lr = 0.0002
I0526 13:30:39.861487 15394 main.cpp:354] Iteration 55180, loss = 0.289663
I0526 13:30:39.861523 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.289662 (* 1 = 0.289662 loss)
I0526 13:30:39.861531 15394 sgd_solver.cpp:43] Iteration 55180, lr = 0.0002
I0526 13:30:44.922648 15394 main.cpp:354] Iteration 55190, loss = 0.216502
I0526 13:30:44.922686 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.216501 (* 1 = 0.216501 loss)
I0526 13:30:44.922691 15394 sgd_solver.cpp:43] Iteration 55190, lr = 0.0002
I0526 13:30:49.711143 15394 main.cpp:465] Iteration 55200, Testing net (#0)
I0526 13:31:02.798342 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8968
I0526 13:31:02.798398 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.328235 (* 1 = 0.328235 loss)
I0526 13:31:03.301573 15394 main.cpp:354] Iteration 55200, loss = 0.310181
I0526 13:31:03.301604 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.31018 (* 1 = 0.31018 loss)
I0526 13:31:03.301611 15394 sgd_solver.cpp:43] Iteration 55200, lr = 0.0002
I0526 13:31:08.543772 15394 main.cpp:354] Iteration 55210, loss = 0.296296
I0526 13:31:08.543813 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.296295 (* 1 = 0.296295 loss)
I0526 13:31:08.543819 15394 sgd_solver.cpp:43] Iteration 55210, lr = 0.0002
I0526 13:31:13.670655 15394 main.cpp:354] Iteration 55220, loss = 0.275931
I0526 13:31:13.670693 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.275931 (* 1 = 0.275931 loss)
I0526 13:31:13.670711 15394 sgd_solver.cpp:43] Iteration 55220, lr = 0.0002
I0526 13:31:18.875974 15394 main.cpp:354] Iteration 55230, loss = 0.164643
I0526 13:31:18.876010 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.164642 (* 1 = 0.164642 loss)
I0526 13:31:18.876018 15394 sgd_solver.cpp:43] Iteration 55230, lr = 0.0002
I0526 13:31:24.215203 15394 main.cpp:354] Iteration 55240, loss = 0.225455
I0526 13:31:24.215240 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.225455 (* 1 = 0.225455 loss)
I0526 13:31:24.215251 15394 sgd_solver.cpp:43] Iteration 55240, lr = 0.0002
I0526 13:31:29.451843 15394 main.cpp:354] Iteration 55250, loss = 0.134718
I0526 13:31:29.451882 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.134718 (* 1 = 0.134718 loss)
I0526 13:31:29.451889 15394 sgd_solver.cpp:43] Iteration 55250, lr = 0.0002
I0526 13:31:34.201218 15394 main.cpp:354] Iteration 55260, loss = 0.211309
I0526 13:31:34.201259 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.211309 (* 1 = 0.211309 loss)
I0526 13:31:34.201266 15394 sgd_solver.cpp:43] Iteration 55260, lr = 0.0002
I0526 13:31:39.359292 15394 main.cpp:354] Iteration 55270, loss = 0.288915
I0526 13:31:39.359329 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.288914 (* 1 = 0.288914 loss)
I0526 13:31:39.359335 15394 sgd_solver.cpp:43] Iteration 55270, lr = 0.0002
I0526 13:31:44.300158 15394 main.cpp:354] Iteration 55280, loss = 0.170241
I0526 13:31:44.300196 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.170241 (* 1 = 0.170241 loss)
I0526 13:31:44.300201 15394 sgd_solver.cpp:43] Iteration 55280, lr = 0.0002
I0526 13:31:49.383517 15394 main.cpp:354] Iteration 55290, loss = 0.194818
I0526 13:31:49.383554 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.194818 (* 1 = 0.194818 loss)
I0526 13:31:49.383561 15394 sgd_solver.cpp:43] Iteration 55290, lr = 0.0002
I0526 13:31:53.766796 15394 main.cpp:465] Iteration 55300, Testing net (#0)
I0526 13:32:06.863000 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8965
I0526 13:32:06.863042 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.332572 (* 1 = 0.332572 loss)
I0526 13:32:07.401820 15394 main.cpp:354] Iteration 55300, loss = 0.258904
I0526 13:32:07.401854 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.258904 (* 1 = 0.258904 loss)
I0526 13:32:07.401860 15394 sgd_solver.cpp:43] Iteration 55300, lr = 0.0002
I0526 13:32:12.998430 15394 main.cpp:354] Iteration 55310, loss = 0.109647
I0526 13:32:12.998468 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.109646 (* 1 = 0.109646 loss)
I0526 13:32:12.998474 15394 sgd_solver.cpp:43] Iteration 55310, lr = 0.0002
I0526 13:32:18.213393 15394 main.cpp:354] Iteration 55320, loss = 0.204528
I0526 13:32:18.213431 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204528 (* 1 = 0.204528 loss)
I0526 13:32:18.213438 15394 sgd_solver.cpp:43] Iteration 55320, lr = 0.0002
I0526 13:32:23.114348 15394 main.cpp:354] Iteration 55330, loss = 0.285135
I0526 13:32:23.114390 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.285134 (* 1 = 0.285134 loss)
I0526 13:32:23.114397 15394 sgd_solver.cpp:43] Iteration 55330, lr = 0.0002
I0526 13:32:28.539400 15394 main.cpp:354] Iteration 55340, loss = 0.255361
I0526 13:32:28.539433 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.25536 (* 1 = 0.25536 loss)
I0526 13:32:28.539439 15394 sgd_solver.cpp:43] Iteration 55340, lr = 0.0002
I0526 13:32:33.635395 15394 main.cpp:354] Iteration 55350, loss = 0.218385
I0526 13:32:33.635435 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.218385 (* 1 = 0.218385 loss)
I0526 13:32:33.635442 15394 sgd_solver.cpp:43] Iteration 55350, lr = 0.0002
I0526 13:32:38.316252 15394 main.cpp:354] Iteration 55360, loss = 0.249164
I0526 13:32:38.316288 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.249164 (* 1 = 0.249164 loss)
I0526 13:32:38.316293 15394 sgd_solver.cpp:43] Iteration 55360, lr = 0.0002
I0526 13:32:43.472614 15394 main.cpp:354] Iteration 55370, loss = 0.132562
I0526 13:32:43.472650 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.132562 (* 1 = 0.132562 loss)
I0526 13:32:43.472656 15394 sgd_solver.cpp:43] Iteration 55370, lr = 0.0002
I0526 13:32:48.639190 15394 main.cpp:354] Iteration 55380, loss = 0.466818
I0526 13:32:48.639230 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.466818 (* 1 = 0.466818 loss)
I0526 13:32:48.639241 15394 sgd_solver.cpp:43] Iteration 55380, lr = 0.0002
I0526 13:32:53.876703 15394 main.cpp:354] Iteration 55390, loss = 0.0875773
I0526 13:32:53.876741 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0875769 (* 1 = 0.0875769 loss)
I0526 13:32:53.876749 15394 sgd_solver.cpp:43] Iteration 55390, lr = 0.0002
I0526 13:32:58.530663 15394 main.cpp:465] Iteration 55400, Testing net (#0)
I0526 13:33:11.627617 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8958
I0526 13:33:11.627660 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.329498 (* 1 = 0.329498 loss)
I0526 13:33:12.063581 15394 main.cpp:354] Iteration 55400, loss = 0.208402
I0526 13:33:12.063613 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.208402 (* 1 = 0.208402 loss)
I0526 13:33:12.063621 15394 sgd_solver.cpp:43] Iteration 55400, lr = 0.0002
I0526 13:33:16.970276 15394 main.cpp:354] Iteration 55410, loss = 0.172184
I0526 13:33:16.970314 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.172183 (* 1 = 0.172183 loss)
I0526 13:33:16.970319 15394 sgd_solver.cpp:43] Iteration 55410, lr = 0.0002
I0526 13:33:21.839383 15394 main.cpp:354] Iteration 55420, loss = 0.236647
I0526 13:33:21.839426 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.236647 (* 1 = 0.236647 loss)
I0526 13:33:21.839432 15394 sgd_solver.cpp:43] Iteration 55420, lr = 0.0002
I0526 13:33:26.936782 15394 main.cpp:354] Iteration 55430, loss = 0.423592
I0526 13:33:26.936820 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.423592 (* 1 = 0.423592 loss)
I0526 13:33:26.936826 15394 sgd_solver.cpp:43] Iteration 55430, lr = 0.0002
I0526 13:33:31.516979 15394 main.cpp:354] Iteration 55440, loss = 0.392432
I0526 13:33:31.517017 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.392431 (* 1 = 0.392431 loss)
I0526 13:33:31.517024 15394 sgd_solver.cpp:43] Iteration 55440, lr = 0.0002
I0526 13:33:36.267798 15394 main.cpp:354] Iteration 55450, loss = 0.162459
I0526 13:33:36.267843 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.162458 (* 1 = 0.162458 loss)
I0526 13:33:36.267848 15394 sgd_solver.cpp:43] Iteration 55450, lr = 0.0002
I0526 13:33:41.296391 15394 main.cpp:354] Iteration 55460, loss = 0.0810488
I0526 13:33:41.296425 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0810484 (* 1 = 0.0810484 loss)
I0526 13:33:41.296432 15394 sgd_solver.cpp:43] Iteration 55460, lr = 0.0002
I0526 13:33:46.453408 15394 main.cpp:354] Iteration 55470, loss = 0.134767
I0526 13:33:46.453449 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.134767 (* 1 = 0.134767 loss)
I0526 13:33:46.453454 15394 sgd_solver.cpp:43] Iteration 55470, lr = 0.0002
I0526 13:33:51.742554 15394 main.cpp:354] Iteration 55480, loss = 0.297109
I0526 13:33:51.742595 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.297109 (* 1 = 0.297109 loss)
I0526 13:33:51.742601 15394 sgd_solver.cpp:43] Iteration 55480, lr = 0.0002
I0526 13:33:56.904193 15394 main.cpp:354] Iteration 55490, loss = 0.118982
I0526 13:33:56.904227 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.118982 (* 1 = 0.118982 loss)
I0526 13:33:56.904233 15394 sgd_solver.cpp:43] Iteration 55490, lr = 0.0002
I0526 13:34:01.139506 15394 main.cpp:465] Iteration 55500, Testing net (#0)
I0526 13:34:14.248448 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8983
I0526 13:34:14.248487 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.328113 (* 1 = 0.328113 loss)
I0526 13:34:14.690233 15394 main.cpp:354] Iteration 55500, loss = 0.285193
I0526 13:34:14.690264 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.285192 (* 1 = 0.285192 loss)
I0526 13:34:14.690273 15394 sgd_solver.cpp:43] Iteration 55500, lr = 0.0002
I0526 13:34:19.707602 15394 main.cpp:354] Iteration 55510, loss = 0.186594
I0526 13:34:19.707645 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186593 (* 1 = 0.186593 loss)
I0526 13:34:19.707653 15394 sgd_solver.cpp:43] Iteration 55510, lr = 0.0002
I0526 13:34:24.114188 15394 main.cpp:354] Iteration 55520, loss = 1.15704
I0526 13:34:24.114222 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.15704 (* 1 = 1.15704 loss)
I0526 13:34:24.114228 15394 sgd_solver.cpp:43] Iteration 55520, lr = 0.0002
I0526 13:34:29.212931 15394 main.cpp:354] Iteration 55530, loss = 0.185054
I0526 13:34:29.212970 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.185053 (* 1 = 0.185053 loss)
I0526 13:34:29.212975 15394 sgd_solver.cpp:43] Iteration 55530, lr = 0.0002
I0526 13:34:34.022778 15394 main.cpp:354] Iteration 55540, loss = 0.202863
I0526 13:34:34.022819 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.202863 (* 1 = 0.202863 loss)
I0526 13:34:34.022826 15394 sgd_solver.cpp:43] Iteration 55540, lr = 0.0002
I0526 13:34:39.391808 15394 main.cpp:354] Iteration 55550, loss = 0.248308
I0526 13:34:39.391846 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.248308 (* 1 = 0.248308 loss)
I0526 13:34:39.391852 15394 sgd_solver.cpp:43] Iteration 55550, lr = 0.0002
I0526 13:34:45.207078 15394 main.cpp:354] Iteration 55560, loss = 0.268683
I0526 13:34:45.207115 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.268683 (* 1 = 0.268683 loss)
I0526 13:34:45.207123 15394 sgd_solver.cpp:43] Iteration 55560, lr = 0.0002
I0526 13:34:50.098734 15394 main.cpp:354] Iteration 55570, loss = 0.271762
I0526 13:34:50.098776 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.271761 (* 1 = 0.271761 loss)
I0526 13:34:50.098783 15394 sgd_solver.cpp:43] Iteration 55570, lr = 0.0002
I0526 13:34:55.543191 15394 main.cpp:354] Iteration 55580, loss = 0.143112
I0526 13:34:55.543228 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.143111 (* 1 = 0.143111 loss)
I0526 13:34:55.543234 15394 sgd_solver.cpp:43] Iteration 55580, lr = 0.0002
I0526 13:35:00.656107 15394 main.cpp:354] Iteration 55590, loss = 0.211276
I0526 13:35:00.656146 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.211276 (* 1 = 0.211276 loss)
I0526 13:35:00.656152 15394 sgd_solver.cpp:43] Iteration 55590, lr = 0.0002
I0526 13:35:05.096182 15394 main.cpp:465] Iteration 55600, Testing net (#0)
I0526 13:35:18.207808 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8955
I0526 13:35:18.207854 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.333659 (* 1 = 0.333659 loss)
I0526 13:35:18.674185 15394 main.cpp:354] Iteration 55600, loss = 0.342076
I0526 13:35:18.674227 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.342076 (* 1 = 0.342076 loss)
I0526 13:35:18.674237 15394 sgd_solver.cpp:43] Iteration 55600, lr = 0.0002
I0526 13:35:23.922619 15394 main.cpp:354] Iteration 55610, loss = 0.20048
I0526 13:35:23.922660 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.200479 (* 1 = 0.200479 loss)
I0526 13:35:23.922667 15394 sgd_solver.cpp:43] Iteration 55610, lr = 0.0002
I0526 13:35:29.239537 15394 main.cpp:354] Iteration 55620, loss = 0.325466
I0526 13:35:29.239573 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.325466 (* 1 = 0.325466 loss)
I0526 13:35:29.239579 15394 sgd_solver.cpp:43] Iteration 55620, lr = 0.0002
I0526 13:35:34.611346 15394 main.cpp:354] Iteration 55630, loss = 0.150346
I0526 13:35:34.611388 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.150345 (* 1 = 0.150345 loss)
I0526 13:35:34.611397 15394 sgd_solver.cpp:43] Iteration 55630, lr = 0.0002
I0526 13:35:39.501302 15394 main.cpp:354] Iteration 55640, loss = 0.180149
I0526 13:35:39.501340 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.180149 (* 1 = 0.180149 loss)
I0526 13:35:39.501346 15394 sgd_solver.cpp:43] Iteration 55640, lr = 0.0002
I0526 13:35:44.350091 15394 main.cpp:354] Iteration 55650, loss = 0.194463
I0526 13:35:44.350129 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.194463 (* 1 = 0.194463 loss)
I0526 13:35:44.350136 15394 sgd_solver.cpp:43] Iteration 55650, lr = 0.0002
I0526 13:35:49.601285 15394 main.cpp:354] Iteration 55660, loss = 0.41458
I0526 13:35:49.601328 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.41458 (* 1 = 0.41458 loss)
I0526 13:35:49.601335 15394 sgd_solver.cpp:43] Iteration 55660, lr = 0.0002
I0526 13:35:54.599834 15394 main.cpp:354] Iteration 55670, loss = 0.0987303
I0526 13:35:54.599874 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0987298 (* 1 = 0.0987298 loss)
I0526 13:35:54.599880 15394 sgd_solver.cpp:43] Iteration 55670, lr = 0.0002
I0526 13:35:59.813027 15394 main.cpp:354] Iteration 55680, loss = 0.183775
I0526 13:35:59.813066 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.183774 (* 1 = 0.183774 loss)
I0526 13:35:59.813072 15394 sgd_solver.cpp:43] Iteration 55680, lr = 0.0002
I0526 13:36:04.552462 15394 main.cpp:354] Iteration 55690, loss = 0.316476
I0526 13:36:04.552502 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.316475 (* 1 = 0.316475 loss)
I0526 13:36:04.552507 15394 sgd_solver.cpp:43] Iteration 55690, lr = 0.0002
I0526 13:36:09.134258 15394 main.cpp:465] Iteration 55700, Testing net (#0)
I0526 13:36:22.243856 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8988
I0526 13:36:22.243896 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.324556 (* 1 = 0.324556 loss)
I0526 13:36:22.746371 15394 main.cpp:354] Iteration 55700, loss = 0.2035
I0526 13:36:22.746402 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.203499 (* 1 = 0.203499 loss)
I0526 13:36:22.746410 15394 sgd_solver.cpp:43] Iteration 55700, lr = 0.0002
I0526 13:36:28.375522 15394 main.cpp:354] Iteration 55710, loss = 0.111357
I0526 13:36:28.375566 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.111356 (* 1 = 0.111356 loss)
I0526 13:36:28.375572 15394 sgd_solver.cpp:43] Iteration 55710, lr = 0.0002
I0526 13:36:33.702651 15394 main.cpp:354] Iteration 55720, loss = 0.249553
I0526 13:36:33.702690 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.249553 (* 1 = 0.249553 loss)
I0526 13:36:33.702697 15394 sgd_solver.cpp:43] Iteration 55720, lr = 0.0002
I0526 13:36:38.941326 15394 main.cpp:354] Iteration 55730, loss = 0.162618
I0526 13:36:38.941365 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.162617 (* 1 = 0.162617 loss)
I0526 13:36:38.941372 15394 sgd_solver.cpp:43] Iteration 55730, lr = 0.0002
I0526 13:36:44.042472 15394 main.cpp:354] Iteration 55740, loss = 0.143277
I0526 13:36:44.042510 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.143276 (* 1 = 0.143276 loss)
I0526 13:36:44.042516 15394 sgd_solver.cpp:43] Iteration 55740, lr = 0.0002
I0526 13:36:49.557788 15394 main.cpp:354] Iteration 55750, loss = 0.152931
I0526 13:36:49.557824 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.152931 (* 1 = 0.152931 loss)
I0526 13:36:49.557831 15394 sgd_solver.cpp:43] Iteration 55750, lr = 0.0002
I0526 13:36:54.855267 15394 main.cpp:354] Iteration 55760, loss = 0.331241
I0526 13:36:54.855304 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.33124 (* 1 = 0.33124 loss)
I0526 13:36:54.855309 15394 sgd_solver.cpp:43] Iteration 55760, lr = 0.0002
I0526 13:36:59.678234 15394 main.cpp:354] Iteration 55770, loss = 0.215827
I0526 13:36:59.678274 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.215827 (* 1 = 0.215827 loss)
I0526 13:36:59.678282 15394 sgd_solver.cpp:43] Iteration 55770, lr = 0.0002
I0526 13:37:04.915534 15394 main.cpp:354] Iteration 55780, loss = 0.0911107
I0526 13:37:04.915575 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0911102 (* 1 = 0.0911102 loss)
I0526 13:37:04.915581 15394 sgd_solver.cpp:43] Iteration 55780, lr = 0.0002
I0526 13:37:10.081955 15394 main.cpp:354] Iteration 55790, loss = 0.0939125
I0526 13:37:10.081992 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.093912 (* 1 = 0.093912 loss)
I0526 13:37:10.082000 15394 sgd_solver.cpp:43] Iteration 55790, lr = 0.0002
I0526 13:37:14.539299 15394 main.cpp:465] Iteration 55800, Testing net (#0)
I0526 13:37:27.643141 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8949
I0526 13:37:27.643187 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.330062 (* 1 = 0.330062 loss)
I0526 13:37:28.073182 15394 main.cpp:354] Iteration 55800, loss = 0.353464
I0526 13:37:28.073215 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.353463 (* 1 = 0.353463 loss)
I0526 13:37:28.073222 15394 sgd_solver.cpp:43] Iteration 55800, lr = 0.0002
I0526 13:37:32.817708 15394 main.cpp:354] Iteration 55810, loss = 0.298583
I0526 13:37:32.817749 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.298583 (* 1 = 0.298583 loss)
I0526 13:37:32.817754 15394 sgd_solver.cpp:43] Iteration 55810, lr = 0.0002
I0526 13:37:37.678717 15394 main.cpp:354] Iteration 55820, loss = 0.324729
I0526 13:37:37.678760 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.324729 (* 1 = 0.324729 loss)
I0526 13:37:37.678766 15394 sgd_solver.cpp:43] Iteration 55820, lr = 0.0002
I0526 13:37:42.162003 15394 main.cpp:354] Iteration 55830, loss = 0.405927
I0526 13:37:42.162040 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.405926 (* 1 = 0.405926 loss)
I0526 13:37:42.162045 15394 sgd_solver.cpp:43] Iteration 55830, lr = 0.0002
I0526 13:37:47.189827 15394 main.cpp:354] Iteration 55840, loss = 0.129574
I0526 13:37:47.189865 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.129574 (* 1 = 0.129574 loss)
I0526 13:37:47.189872 15394 sgd_solver.cpp:43] Iteration 55840, lr = 0.0002
I0526 13:37:51.820822 15394 main.cpp:354] Iteration 55850, loss = 0.15381
I0526 13:37:51.820864 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.153809 (* 1 = 0.153809 loss)
I0526 13:37:51.820871 15394 sgd_solver.cpp:43] Iteration 55850, lr = 0.0002
I0526 13:37:56.579196 15394 main.cpp:354] Iteration 55860, loss = 0.177891
I0526 13:37:56.579233 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.17789 (* 1 = 0.17789 loss)
I0526 13:37:56.579239 15394 sgd_solver.cpp:43] Iteration 55860, lr = 0.0002
I0526 13:38:01.441979 15394 main.cpp:354] Iteration 55870, loss = 0.156457
I0526 13:38:01.442019 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.156456 (* 1 = 0.156456 loss)
I0526 13:38:01.442025 15394 sgd_solver.cpp:43] Iteration 55870, lr = 0.0002
I0526 13:38:06.642335 15394 main.cpp:354] Iteration 55880, loss = 0.155132
I0526 13:38:06.642382 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.155132 (* 1 = 0.155132 loss)
I0526 13:38:06.642388 15394 sgd_solver.cpp:43] Iteration 55880, lr = 0.0002
I0526 13:38:11.712211 15394 main.cpp:354] Iteration 55890, loss = 0.10893
I0526 13:38:11.712249 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.108929 (* 1 = 0.108929 loss)
I0526 13:38:11.712256 15394 sgd_solver.cpp:43] Iteration 55890, lr = 0.0002
I0526 13:38:16.629112 15394 main.cpp:465] Iteration 55900, Testing net (#0)
I0526 13:38:29.734504 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8959
I0526 13:38:29.734541 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.332104 (* 1 = 0.332104 loss)
I0526 13:38:30.102459 15394 main.cpp:354] Iteration 55900, loss = 0.4302
I0526 13:38:30.102489 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.4302 (* 1 = 0.4302 loss)
I0526 13:38:30.102497 15394 sgd_solver.cpp:43] Iteration 55900, lr = 0.0002
I0526 13:38:35.415523 15394 main.cpp:354] Iteration 55910, loss = 0.119581
I0526 13:38:35.415575 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.119581 (* 1 = 0.119581 loss)
I0526 13:38:35.415580 15394 sgd_solver.cpp:43] Iteration 55910, lr = 0.0002
I0526 13:38:40.304431 15394 main.cpp:354] Iteration 55920, loss = 0.258859
I0526 13:38:40.304471 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.258858 (* 1 = 0.258858 loss)
I0526 13:38:40.304476 15394 sgd_solver.cpp:43] Iteration 55920, lr = 0.0002
I0526 13:38:45.393343 15394 main.cpp:354] Iteration 55930, loss = 0.124695
I0526 13:38:45.393379 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.124694 (* 1 = 0.124694 loss)
I0526 13:38:45.393390 15394 sgd_solver.cpp:43] Iteration 55930, lr = 0.0002
I0526 13:38:50.156105 15394 main.cpp:354] Iteration 55940, loss = 0.144286
I0526 13:38:50.156147 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.144285 (* 1 = 0.144285 loss)
I0526 13:38:50.156152 15394 sgd_solver.cpp:43] Iteration 55940, lr = 0.0002
I0526 13:38:55.464656 15394 main.cpp:354] Iteration 55950, loss = 0.254689
I0526 13:38:55.464695 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.254689 (* 1 = 0.254689 loss)
I0526 13:38:55.464701 15394 sgd_solver.cpp:43] Iteration 55950, lr = 0.0002
I0526 13:39:00.872403 15394 main.cpp:354] Iteration 55960, loss = 0.171713
I0526 13:39:00.872439 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.171713 (* 1 = 0.171713 loss)
I0526 13:39:00.872445 15394 sgd_solver.cpp:43] Iteration 55960, lr = 0.0002
I0526 13:39:06.116745 15394 main.cpp:354] Iteration 55970, loss = 0.16282
I0526 13:39:06.116787 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.16282 (* 1 = 0.16282 loss)
I0526 13:39:06.116794 15394 sgd_solver.cpp:43] Iteration 55970, lr = 0.0002
I0526 13:39:11.498590 15394 main.cpp:354] Iteration 55980, loss = 0.184275
I0526 13:39:11.498631 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.184274 (* 1 = 0.184274 loss)
I0526 13:39:11.498636 15394 sgd_solver.cpp:43] Iteration 55980, lr = 0.0002
I0526 13:39:16.064062 15394 main.cpp:354] Iteration 55990, loss = 0.215489
I0526 13:39:16.064100 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.215489 (* 1 = 0.215489 loss)
I0526 13:39:16.064105 15394 sgd_solver.cpp:43] Iteration 55990, lr = 0.0002
I0526 13:39:20.447655 15394 main.cpp:465] Iteration 56000, Testing net (#0)
I0526 13:39:33.559303 15394 main.cpp:532]     Test net output #0: Accuracy = 0.896
I0526 13:39:33.559340 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.326354 (* 1 = 0.326354 loss)
I0526 13:39:33.993839 15394 main.cpp:354] Iteration 56000, loss = 0.268052
I0526 13:39:33.993873 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.268052 (* 1 = 0.268052 loss)
I0526 13:39:33.993882 15394 sgd_solver.cpp:43] Iteration 56000, lr = 0.0002
I0526 13:39:39.368965 15394 main.cpp:354] Iteration 56010, loss = 0.0967883
I0526 13:39:39.369004 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0967878 (* 1 = 0.0967878 loss)
I0526 13:39:39.369010 15394 sgd_solver.cpp:43] Iteration 56010, lr = 0.0002
I0526 13:39:44.587368 15394 main.cpp:354] Iteration 56020, loss = 0.368883
I0526 13:39:44.587409 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.368882 (* 1 = 0.368882 loss)
I0526 13:39:44.587415 15394 sgd_solver.cpp:43] Iteration 56020, lr = 0.0002
I0526 13:39:49.498905 15394 main.cpp:354] Iteration 56030, loss = 0.206751
I0526 13:39:49.498947 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.20675 (* 1 = 0.20675 loss)
I0526 13:39:49.498953 15394 sgd_solver.cpp:43] Iteration 56030, lr = 0.0002
I0526 13:39:54.214968 15394 main.cpp:354] Iteration 56040, loss = 0.189247
I0526 13:39:54.215018 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.189246 (* 1 = 0.189246 loss)
I0526 13:39:54.215024 15394 sgd_solver.cpp:43] Iteration 56040, lr = 0.0002
I0526 13:39:59.669569 15394 main.cpp:354] Iteration 56050, loss = 0.182216
I0526 13:39:59.669606 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.182215 (* 1 = 0.182215 loss)
I0526 13:39:59.669612 15394 sgd_solver.cpp:43] Iteration 56050, lr = 0.0002
I0526 13:40:04.989214 15394 main.cpp:354] Iteration 56060, loss = 0.223769
I0526 13:40:04.989255 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.223769 (* 1 = 0.223769 loss)
I0526 13:40:04.989261 15394 sgd_solver.cpp:43] Iteration 56060, lr = 0.0002
I0526 13:40:10.388890 15394 main.cpp:354] Iteration 56070, loss = 0.291135
I0526 13:40:10.388928 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.291135 (* 1 = 0.291135 loss)
I0526 13:40:10.388936 15394 sgd_solver.cpp:43] Iteration 56070, lr = 0.0002
I0526 13:40:15.578507 15394 main.cpp:354] Iteration 56080, loss = 0.159079
I0526 13:40:15.578547 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.159079 (* 1 = 0.159079 loss)
I0526 13:40:15.578554 15394 sgd_solver.cpp:43] Iteration 56080, lr = 0.0002
I0526 13:40:20.881484 15394 main.cpp:354] Iteration 56090, loss = 0.125952
I0526 13:40:20.881522 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.125951 (* 1 = 0.125951 loss)
I0526 13:40:20.881530 15394 sgd_solver.cpp:43] Iteration 56090, lr = 0.0002
I0526 13:40:25.561233 15394 main.cpp:465] Iteration 56100, Testing net (#0)
I0526 13:40:38.665463 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8959
I0526 13:40:38.665514 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.331627 (* 1 = 0.331627 loss)
I0526 13:40:39.026064 15394 main.cpp:354] Iteration 56100, loss = 0.528951
I0526 13:40:39.026096 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.52895 (* 1 = 0.52895 loss)
I0526 13:40:39.026104 15394 sgd_solver.cpp:43] Iteration 56100, lr = 0.0002
I0526 13:40:44.262442 15394 main.cpp:354] Iteration 56110, loss = 0.147284
I0526 13:40:44.262480 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.147284 (* 1 = 0.147284 loss)
I0526 13:40:44.262485 15394 sgd_solver.cpp:43] Iteration 56110, lr = 0.0002
I0526 13:40:49.123544 15394 main.cpp:354] Iteration 56120, loss = 0.114015
I0526 13:40:49.123587 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.114014 (* 1 = 0.114014 loss)
I0526 13:40:49.123595 15394 sgd_solver.cpp:43] Iteration 56120, lr = 0.0002
I0526 13:40:54.293828 15394 main.cpp:354] Iteration 56130, loss = 0.129883
I0526 13:40:54.293867 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.129883 (* 1 = 0.129883 loss)
I0526 13:40:54.293874 15394 sgd_solver.cpp:43] Iteration 56130, lr = 0.0002
I0526 13:40:59.707289 15394 main.cpp:354] Iteration 56140, loss = 0.23557
I0526 13:40:59.707327 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235569 (* 1 = 0.235569 loss)
I0526 13:40:59.707334 15394 sgd_solver.cpp:43] Iteration 56140, lr = 0.0002
I0526 13:41:04.746218 15394 main.cpp:354] Iteration 56150, loss = 0.306492
I0526 13:41:04.746258 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.306492 (* 1 = 0.306492 loss)
I0526 13:41:04.746263 15394 sgd_solver.cpp:43] Iteration 56150, lr = 0.0002
I0526 13:41:09.556445 15394 main.cpp:354] Iteration 56160, loss = 0.170359
I0526 13:41:09.556483 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.170359 (* 1 = 0.170359 loss)
I0526 13:41:09.556488 15394 sgd_solver.cpp:43] Iteration 56160, lr = 0.0002
I0526 13:41:14.724833 15394 main.cpp:354] Iteration 56170, loss = 0.274696
I0526 13:41:14.724869 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.274696 (* 1 = 0.274696 loss)
I0526 13:41:14.724875 15394 sgd_solver.cpp:43] Iteration 56170, lr = 0.0002
I0526 13:41:19.226888 15394 main.cpp:354] Iteration 56180, loss = 0.263374
I0526 13:41:19.226928 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.263374 (* 1 = 0.263374 loss)
I0526 13:41:19.226933 15394 sgd_solver.cpp:43] Iteration 56180, lr = 0.0002
I0526 13:41:24.706727 15394 main.cpp:354] Iteration 56190, loss = 0.174506
I0526 13:41:24.706764 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.174505 (* 1 = 0.174505 loss)
I0526 13:41:24.706770 15394 sgd_solver.cpp:43] Iteration 56190, lr = 0.0002
I0526 13:41:29.488718 15394 main.cpp:465] Iteration 56200, Testing net (#0)
I0526 13:41:42.574769 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8977
I0526 13:41:42.574808 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.32743 (* 1 = 0.32743 loss)
I0526 13:41:43.113828 15394 main.cpp:354] Iteration 56200, loss = 0.156105
I0526 13:41:43.113867 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.156104 (* 1 = 0.156104 loss)
I0526 13:41:43.113876 15394 sgd_solver.cpp:43] Iteration 56200, lr = 0.0002
I0526 13:41:48.299355 15394 main.cpp:354] Iteration 56210, loss = 0.193877
I0526 13:41:48.299399 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.193876 (* 1 = 0.193876 loss)
I0526 13:41:48.299406 15394 sgd_solver.cpp:43] Iteration 56210, lr = 0.0002
I0526 13:41:53.534122 15394 main.cpp:354] Iteration 56220, loss = 0.247034
I0526 13:41:53.534167 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.247033 (* 1 = 0.247033 loss)
I0526 13:41:53.534173 15394 sgd_solver.cpp:43] Iteration 56220, lr = 0.0002
I0526 13:41:58.792539 15394 main.cpp:354] Iteration 56230, loss = 0.232276
I0526 13:41:58.792577 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.232276 (* 1 = 0.232276 loss)
I0526 13:41:58.792583 15394 sgd_solver.cpp:43] Iteration 56230, lr = 0.0002
I0526 13:42:03.858791 15394 main.cpp:354] Iteration 56240, loss = 0.19561
I0526 13:42:03.858834 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.19561 (* 1 = 0.19561 loss)
I0526 13:42:03.858840 15394 sgd_solver.cpp:43] Iteration 56240, lr = 0.0002
I0526 13:42:08.688268 15394 main.cpp:354] Iteration 56250, loss = 0.475546
I0526 13:42:08.688305 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.475546 (* 1 = 0.475546 loss)
I0526 13:42:08.688311 15394 sgd_solver.cpp:43] Iteration 56250, lr = 0.0002
I0526 13:42:13.769050 15394 main.cpp:354] Iteration 56260, loss = 0.159189
I0526 13:42:13.769085 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.159188 (* 1 = 0.159188 loss)
I0526 13:42:13.769091 15394 sgd_solver.cpp:43] Iteration 56260, lr = 0.0002
I0526 13:42:18.573135 15394 main.cpp:354] Iteration 56270, loss = 0.393982
I0526 13:42:18.573173 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.393982 (* 1 = 0.393982 loss)
I0526 13:42:18.573179 15394 sgd_solver.cpp:43] Iteration 56270, lr = 0.0002
I0526 13:42:23.296921 15394 main.cpp:354] Iteration 56280, loss = 0.277806
I0526 13:42:23.296962 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.277806 (* 1 = 0.277806 loss)
I0526 13:42:23.296967 15394 sgd_solver.cpp:43] Iteration 56280, lr = 0.0002
I0526 13:42:28.574378 15394 main.cpp:354] Iteration 56290, loss = 0.228787
I0526 13:42:28.574419 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.228787 (* 1 = 0.228787 loss)
I0526 13:42:28.574424 15394 sgd_solver.cpp:43] Iteration 56290, lr = 0.0002
I0526 13:42:33.290503 15394 main.cpp:465] Iteration 56300, Testing net (#0)
I0526 13:42:46.396849 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8992
I0526 13:42:46.396888 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.328039 (* 1 = 0.328039 loss)
I0526 13:42:46.902300 15394 main.cpp:354] Iteration 56300, loss = 0.179478
I0526 13:42:46.902330 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.179477 (* 1 = 0.179477 loss)
I0526 13:42:46.902338 15394 sgd_solver.cpp:43] Iteration 56300, lr = 0.0002
I0526 13:42:52.145184 15394 main.cpp:354] Iteration 56310, loss = 0.0978242
I0526 13:42:52.145225 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0978237 (* 1 = 0.0978237 loss)
I0526 13:42:52.145231 15394 sgd_solver.cpp:43] Iteration 56310, lr = 0.0002
I0526 13:42:57.160969 15394 main.cpp:354] Iteration 56320, loss = 0.253179
I0526 13:42:57.161007 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.253178 (* 1 = 0.253178 loss)
I0526 13:42:57.161013 15394 sgd_solver.cpp:43] Iteration 56320, lr = 0.0002
I0526 13:43:02.261893 15394 main.cpp:354] Iteration 56330, loss = 0.0775453
I0526 13:43:02.261932 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0775448 (* 1 = 0.0775448 loss)
I0526 13:43:02.261940 15394 sgd_solver.cpp:43] Iteration 56330, lr = 0.0002
I0526 13:43:07.475224 15394 main.cpp:354] Iteration 56340, loss = 0.172395
I0526 13:43:07.475265 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.172395 (* 1 = 0.172395 loss)
I0526 13:43:07.475270 15394 sgd_solver.cpp:43] Iteration 56340, lr = 0.0002
I0526 13:43:12.477643 15394 main.cpp:354] Iteration 56350, loss = 0.0919086
I0526 13:43:12.477681 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0919081 (* 1 = 0.0919081 loss)
I0526 13:43:12.477695 15394 sgd_solver.cpp:43] Iteration 56350, lr = 0.0002
I0526 13:43:17.400111 15394 main.cpp:354] Iteration 56360, loss = 0.264565
I0526 13:43:17.400146 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.264565 (* 1 = 0.264565 loss)
I0526 13:43:17.400152 15394 sgd_solver.cpp:43] Iteration 56360, lr = 0.0002
I0526 13:43:22.652863 15394 main.cpp:354] Iteration 56370, loss = 0.156527
I0526 13:43:22.652905 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.156527 (* 1 = 0.156527 loss)
I0526 13:43:22.652911 15394 sgd_solver.cpp:43] Iteration 56370, lr = 0.0002
I0526 13:43:27.993084 15394 main.cpp:354] Iteration 56380, loss = 0.181171
I0526 13:43:27.993124 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.181171 (* 1 = 0.181171 loss)
I0526 13:43:27.993130 15394 sgd_solver.cpp:43] Iteration 56380, lr = 0.0002
I0526 13:43:33.309094 15394 main.cpp:354] Iteration 56390, loss = 0.138729
I0526 13:43:33.309133 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.138729 (* 1 = 0.138729 loss)
I0526 13:43:33.309139 15394 sgd_solver.cpp:43] Iteration 56390, lr = 0.0002
I0526 13:43:38.253350 15394 main.cpp:465] Iteration 56400, Testing net (#0)
I0526 13:43:51.355350 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8962
I0526 13:43:51.355391 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.327244 (* 1 = 0.327244 loss)
I0526 13:43:51.858824 15394 main.cpp:354] Iteration 56400, loss = 0.231671
I0526 13:43:51.858856 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.231671 (* 1 = 0.231671 loss)
I0526 13:43:51.858865 15394 sgd_solver.cpp:43] Iteration 56400, lr = 0.0002
I0526 13:43:57.088577 15394 main.cpp:354] Iteration 56410, loss = 0.369983
I0526 13:43:57.088613 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.369983 (* 1 = 0.369983 loss)
I0526 13:43:57.088619 15394 sgd_solver.cpp:43] Iteration 56410, lr = 0.0002
I0526 13:44:01.865980 15394 main.cpp:354] Iteration 56420, loss = 0.177109
I0526 13:44:01.866022 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.177109 (* 1 = 0.177109 loss)
I0526 13:44:01.866029 15394 sgd_solver.cpp:43] Iteration 56420, lr = 0.0002
I0526 13:44:06.809541 15394 main.cpp:354] Iteration 56430, loss = 0.185827
I0526 13:44:06.809584 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.185826 (* 1 = 0.185826 loss)
I0526 13:44:06.809590 15394 sgd_solver.cpp:43] Iteration 56430, lr = 0.0002
I0526 13:44:12.040122 15394 main.cpp:354] Iteration 56440, loss = 0.289958
I0526 13:44:12.040155 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.289957 (* 1 = 0.289957 loss)
I0526 13:44:12.040161 15394 sgd_solver.cpp:43] Iteration 56440, lr = 0.0002
I0526 13:44:17.027746 15394 main.cpp:354] Iteration 56450, loss = 0.388442
I0526 13:44:17.027782 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.388441 (* 1 = 0.388441 loss)
I0526 13:44:17.027787 15394 sgd_solver.cpp:43] Iteration 56450, lr = 0.0002
I0526 13:44:22.482214 15394 main.cpp:354] Iteration 56460, loss = 0.153938
I0526 13:44:22.482252 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.153937 (* 1 = 0.153937 loss)
I0526 13:44:22.482259 15394 sgd_solver.cpp:43] Iteration 56460, lr = 0.0002
I0526 13:44:27.865340 15394 main.cpp:354] Iteration 56470, loss = 0.165829
I0526 13:44:27.865377 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.165828 (* 1 = 0.165828 loss)
I0526 13:44:27.865383 15394 sgd_solver.cpp:43] Iteration 56470, lr = 0.0002
I0526 13:44:32.674492 15394 main.cpp:354] Iteration 56480, loss = 0.208564
I0526 13:44:32.674530 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.208563 (* 1 = 0.208563 loss)
I0526 13:44:32.674536 15394 sgd_solver.cpp:43] Iteration 56480, lr = 0.0002
I0526 13:44:37.983409 15394 main.cpp:354] Iteration 56490, loss = 0.350173
I0526 13:44:37.983453 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.350173 (* 1 = 0.350173 loss)
I0526 13:44:37.983461 15394 sgd_solver.cpp:43] Iteration 56490, lr = 0.0002
I0526 13:44:42.115767 15394 main.cpp:465] Iteration 56500, Testing net (#0)
I0526 13:44:55.209480 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8976
I0526 13:44:55.209518 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.331223 (* 1 = 0.331223 loss)
I0526 13:44:55.724460 15394 main.cpp:354] Iteration 56500, loss = 0.280293
I0526 13:44:55.724493 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.280293 (* 1 = 0.280293 loss)
I0526 13:44:55.724501 15394 sgd_solver.cpp:43] Iteration 56500, lr = 0.0002
I0526 13:45:00.864399 15394 main.cpp:354] Iteration 56510, loss = 0.248327
I0526 13:45:00.864436 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.248327 (* 1 = 0.248327 loss)
I0526 13:45:00.864444 15394 sgd_solver.cpp:43] Iteration 56510, lr = 0.0002
I0526 13:45:05.678571 15394 main.cpp:354] Iteration 56520, loss = 0.303157
I0526 13:45:05.678613 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.303157 (* 1 = 0.303157 loss)
I0526 13:45:05.678619 15394 sgd_solver.cpp:43] Iteration 56520, lr = 0.0002
I0526 13:45:10.924451 15394 main.cpp:354] Iteration 56530, loss = 0.206238
I0526 13:45:10.924494 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206237 (* 1 = 0.206237 loss)
I0526 13:45:10.924499 15394 sgd_solver.cpp:43] Iteration 56530, lr = 0.0002
I0526 13:45:16.400362 15394 main.cpp:354] Iteration 56540, loss = 0.0938962
I0526 13:45:16.400398 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0938957 (* 1 = 0.0938957 loss)
I0526 13:45:16.400405 15394 sgd_solver.cpp:43] Iteration 56540, lr = 0.0002
I0526 13:45:21.361637 15394 main.cpp:354] Iteration 56550, loss = 0.176539
I0526 13:45:21.361676 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.176538 (* 1 = 0.176538 loss)
I0526 13:45:21.361682 15394 sgd_solver.cpp:43] Iteration 56550, lr = 0.0002
I0526 13:45:26.809705 15394 main.cpp:354] Iteration 56560, loss = 0.236276
I0526 13:45:26.809743 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.236276 (* 1 = 0.236276 loss)
I0526 13:45:26.809749 15394 sgd_solver.cpp:43] Iteration 56560, lr = 0.0002
I0526 13:45:32.185672 15394 main.cpp:354] Iteration 56570, loss = 0.150469
I0526 13:45:32.185708 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.150469 (* 1 = 0.150469 loss)
I0526 13:45:32.185714 15394 sgd_solver.cpp:43] Iteration 56570, lr = 0.0002
I0526 13:45:37.336089 15394 main.cpp:354] Iteration 56580, loss = 0.128645
I0526 13:45:37.336127 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.128644 (* 1 = 0.128644 loss)
I0526 13:45:37.336133 15394 sgd_solver.cpp:43] Iteration 56580, lr = 0.0002
I0526 13:45:42.539554 15394 main.cpp:354] Iteration 56590, loss = 0.145006
I0526 13:45:42.539592 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.145005 (* 1 = 0.145005 loss)
I0526 13:45:42.539599 15394 sgd_solver.cpp:43] Iteration 56590, lr = 0.0002
I0526 13:45:47.412420 15394 main.cpp:465] Iteration 56600, Testing net (#0)
I0526 13:46:00.515076 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8992
I0526 13:46:00.515120 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.325565 (* 1 = 0.325565 loss)
I0526 13:46:00.986857 15394 main.cpp:354] Iteration 56600, loss = 0.193693
I0526 13:46:00.986892 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.193692 (* 1 = 0.193692 loss)
I0526 13:46:00.986901 15394 sgd_solver.cpp:43] Iteration 56600, lr = 0.0002
I0526 13:46:06.122190 15394 main.cpp:354] Iteration 56610, loss = 0.213425
I0526 13:46:06.122231 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.213424 (* 1 = 0.213424 loss)
I0526 13:46:06.122237 15394 sgd_solver.cpp:43] Iteration 56610, lr = 0.0002
I0526 13:46:11.324555 15394 main.cpp:354] Iteration 56620, loss = 0.213755
I0526 13:46:11.324595 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.213754 (* 1 = 0.213754 loss)
I0526 13:46:11.324600 15394 sgd_solver.cpp:43] Iteration 56620, lr = 0.0002
I0526 13:46:16.229969 15394 main.cpp:354] Iteration 56630, loss = 0.235329
I0526 13:46:16.230010 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235328 (* 1 = 0.235328 loss)
I0526 13:46:16.230016 15394 sgd_solver.cpp:43] Iteration 56630, lr = 0.0002
I0526 13:46:21.153221 15394 main.cpp:354] Iteration 56640, loss = 0.180634
I0526 13:46:21.153264 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.180634 (* 1 = 0.180634 loss)
I0526 13:46:21.153270 15394 sgd_solver.cpp:43] Iteration 56640, lr = 0.0002
I0526 13:46:25.851583 15394 main.cpp:354] Iteration 56650, loss = 0.146661
I0526 13:46:25.851622 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.146661 (* 1 = 0.146661 loss)
I0526 13:46:25.851629 15394 sgd_solver.cpp:43] Iteration 56650, lr = 0.0002
I0526 13:46:31.291491 15394 main.cpp:354] Iteration 56660, loss = 0.081204
I0526 13:46:31.291527 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0812036 (* 1 = 0.0812036 loss)
I0526 13:46:31.291533 15394 sgd_solver.cpp:43] Iteration 56660, lr = 0.0002
I0526 13:46:36.267581 15394 main.cpp:354] Iteration 56670, loss = 0.197933
I0526 13:46:36.267635 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.197932 (* 1 = 0.197932 loss)
I0526 13:46:36.267642 15394 sgd_solver.cpp:43] Iteration 56670, lr = 0.0002
I0526 13:46:41.205468 15394 main.cpp:354] Iteration 56680, loss = 0.313947
I0526 13:46:41.205504 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.313947 (* 1 = 0.313947 loss)
I0526 13:46:41.205510 15394 sgd_solver.cpp:43] Iteration 56680, lr = 0.0002
I0526 13:46:46.170287 15394 main.cpp:354] Iteration 56690, loss = 0.227558
I0526 13:46:46.170322 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.227558 (* 1 = 0.227558 loss)
I0526 13:46:46.170330 15394 sgd_solver.cpp:43] Iteration 56690, lr = 0.0002
I0526 13:46:50.288702 15394 main.cpp:465] Iteration 56700, Testing net (#0)
I0526 13:47:03.390329 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8984
I0526 13:47:03.390370 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.330464 (* 1 = 0.330464 loss)
I0526 13:47:03.895464 15394 main.cpp:354] Iteration 56700, loss = 0.148119
I0526 13:47:03.895510 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.148119 (* 1 = 0.148119 loss)
I0526 13:47:03.895519 15394 sgd_solver.cpp:43] Iteration 56700, lr = 0.0002
I0526 13:47:09.085389 15394 main.cpp:354] Iteration 56710, loss = 0.206782
I0526 13:47:09.085425 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206781 (* 1 = 0.206781 loss)
I0526 13:47:09.085432 15394 sgd_solver.cpp:43] Iteration 56710, lr = 0.0002
I0526 13:47:14.066423 15394 main.cpp:354] Iteration 56720, loss = 0.218805
I0526 13:47:14.066458 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.218805 (* 1 = 0.218805 loss)
I0526 13:47:14.066464 15394 sgd_solver.cpp:43] Iteration 56720, lr = 0.0002
I0526 13:47:19.154696 15394 main.cpp:354] Iteration 56730, loss = 0.154505
I0526 13:47:19.154744 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.154505 (* 1 = 0.154505 loss)
I0526 13:47:19.154752 15394 sgd_solver.cpp:43] Iteration 56730, lr = 0.0002
I0526 13:47:24.244765 15394 main.cpp:354] Iteration 56740, loss = 0.191703
I0526 13:47:24.244802 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.191702 (* 1 = 0.191702 loss)
I0526 13:47:24.244808 15394 sgd_solver.cpp:43] Iteration 56740, lr = 0.0002
I0526 13:47:29.147951 15394 main.cpp:354] Iteration 56750, loss = 0.480257
I0526 13:47:29.147984 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.480256 (* 1 = 0.480256 loss)
I0526 13:47:29.147990 15394 sgd_solver.cpp:43] Iteration 56750, lr = 0.0002
I0526 13:47:34.059698 15394 main.cpp:354] Iteration 56760, loss = 0.203789
I0526 13:47:34.059736 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.203789 (* 1 = 0.203789 loss)
I0526 13:47:34.059743 15394 sgd_solver.cpp:43] Iteration 56760, lr = 0.0002
I0526 13:47:39.232540 15394 main.cpp:354] Iteration 56770, loss = 0.265574
I0526 13:47:39.232581 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.265574 (* 1 = 0.265574 loss)
I0526 13:47:39.232588 15394 sgd_solver.cpp:43] Iteration 56770, lr = 0.0002
I0526 13:47:44.128934 15394 main.cpp:354] Iteration 56780, loss = 0.183328
I0526 13:47:44.128968 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.183328 (* 1 = 0.183328 loss)
I0526 13:47:44.128975 15394 sgd_solver.cpp:43] Iteration 56780, lr = 0.0002
I0526 13:47:49.216176 15394 main.cpp:354] Iteration 56790, loss = 0.212725
I0526 13:47:49.216215 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.212724 (* 1 = 0.212724 loss)
I0526 13:47:49.216222 15394 sgd_solver.cpp:43] Iteration 56790, lr = 0.0002
I0526 13:47:53.905699 15394 main.cpp:465] Iteration 56800, Testing net (#0)
I0526 13:48:07.004704 15394 main.cpp:532]     Test net output #0: Accuracy = 0.899
I0526 13:48:07.004744 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.321135 (* 1 = 0.321135 loss)
I0526 13:48:07.508086 15394 main.cpp:354] Iteration 56800, loss = 0.26168
I0526 13:48:07.508117 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.26168 (* 1 = 0.26168 loss)
I0526 13:48:07.508126 15394 sgd_solver.cpp:43] Iteration 56800, lr = 0.0002
I0526 13:48:12.054586 15394 main.cpp:354] Iteration 56810, loss = 0.216982
I0526 13:48:12.054623 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.216981 (* 1 = 0.216981 loss)
I0526 13:48:12.054630 15394 sgd_solver.cpp:43] Iteration 56810, lr = 0.0002
I0526 13:48:17.032552 15394 main.cpp:354] Iteration 56820, loss = 0.277358
I0526 13:48:17.032588 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.277357 (* 1 = 0.277357 loss)
I0526 13:48:17.032593 15394 sgd_solver.cpp:43] Iteration 56820, lr = 0.0002
I0526 13:48:21.698458 15394 main.cpp:354] Iteration 56830, loss = 0.252151
I0526 13:48:21.698499 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.252151 (* 1 = 0.252151 loss)
I0526 13:48:21.698504 15394 sgd_solver.cpp:43] Iteration 56830, lr = 0.0002
I0526 13:48:27.190129 15394 main.cpp:354] Iteration 56840, loss = 0.178343
I0526 13:48:27.190162 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.178343 (* 1 = 0.178343 loss)
I0526 13:48:27.190168 15394 sgd_solver.cpp:43] Iteration 56840, lr = 0.0002
I0526 13:48:32.262969 15394 main.cpp:354] Iteration 56850, loss = 0.243652
I0526 13:48:32.263003 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.243651 (* 1 = 0.243651 loss)
I0526 13:48:32.263010 15394 sgd_solver.cpp:43] Iteration 56850, lr = 0.0002
I0526 13:48:37.202006 15394 main.cpp:354] Iteration 56860, loss = 0.290686
I0526 13:48:37.202045 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.290685 (* 1 = 0.290685 loss)
I0526 13:48:37.202051 15394 sgd_solver.cpp:43] Iteration 56860, lr = 0.0002
I0526 13:48:42.438652 15394 main.cpp:354] Iteration 56870, loss = 0.149098
I0526 13:48:42.438686 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.149097 (* 1 = 0.149097 loss)
I0526 13:48:42.438693 15394 sgd_solver.cpp:43] Iteration 56870, lr = 0.0002
I0526 13:48:47.650749 15394 main.cpp:354] Iteration 56880, loss = 0.237863
I0526 13:48:47.650782 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.237862 (* 1 = 0.237862 loss)
I0526 13:48:47.650789 15394 sgd_solver.cpp:43] Iteration 56880, lr = 0.0002
I0526 13:48:53.201591 15394 main.cpp:354] Iteration 56890, loss = 0.195286
I0526 13:48:53.201629 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.195286 (* 1 = 0.195286 loss)
I0526 13:48:53.201635 15394 sgd_solver.cpp:43] Iteration 56890, lr = 0.0002
I0526 13:48:57.735935 15394 main.cpp:465] Iteration 56900, Testing net (#0)
I0526 13:49:10.845063 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8979
I0526 13:49:10.845105 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.330939 (* 1 = 0.330939 loss)
I0526 13:49:11.311218 15394 main.cpp:354] Iteration 56900, loss = 0.318531
I0526 13:49:11.311261 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.318531 (* 1 = 0.318531 loss)
I0526 13:49:11.311285 15394 sgd_solver.cpp:43] Iteration 56900, lr = 0.0002
I0526 13:49:16.404124 15394 main.cpp:354] Iteration 56910, loss = 0.104647
I0526 13:49:16.404160 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.104647 (* 1 = 0.104647 loss)
I0526 13:49:16.404165 15394 sgd_solver.cpp:43] Iteration 56910, lr = 0.0002
I0526 13:49:21.062976 15394 main.cpp:354] Iteration 56920, loss = 0.280702
I0526 13:49:21.063014 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.280702 (* 1 = 0.280702 loss)
I0526 13:49:21.063020 15394 sgd_solver.cpp:43] Iteration 56920, lr = 0.0002
I0526 13:49:25.500001 15394 main.cpp:354] Iteration 56930, loss = 0.110191
I0526 13:49:25.500036 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.11019 (* 1 = 0.11019 loss)
I0526 13:49:25.500042 15394 sgd_solver.cpp:43] Iteration 56930, lr = 0.0002
I0526 13:49:30.146024 15394 main.cpp:354] Iteration 56940, loss = 0.131465
I0526 13:49:30.146057 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.131465 (* 1 = 0.131465 loss)
I0526 13:49:30.146064 15394 sgd_solver.cpp:43] Iteration 56940, lr = 0.0002
I0526 13:49:34.816651 15394 main.cpp:354] Iteration 56950, loss = 0.16812
I0526 13:49:34.816689 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.16812 (* 1 = 0.16812 loss)
I0526 13:49:34.816696 15394 sgd_solver.cpp:43] Iteration 56950, lr = 0.0002
I0526 13:49:40.092206 15394 main.cpp:354] Iteration 56960, loss = 0.22947
I0526 13:49:40.092242 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.229469 (* 1 = 0.229469 loss)
I0526 13:49:40.092247 15394 sgd_solver.cpp:43] Iteration 56960, lr = 0.0002
I0526 13:49:45.122122 15394 main.cpp:354] Iteration 56970, loss = 0.135125
I0526 13:49:45.122155 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.135125 (* 1 = 0.135125 loss)
I0526 13:49:45.122162 15394 sgd_solver.cpp:43] Iteration 56970, lr = 0.0002
I0526 13:49:50.079994 15394 main.cpp:354] Iteration 56980, loss = 0.163272
I0526 13:49:50.080032 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.163272 (* 1 = 0.163272 loss)
I0526 13:49:50.080039 15394 sgd_solver.cpp:43] Iteration 56980, lr = 0.0002
I0526 13:49:55.164978 15394 main.cpp:354] Iteration 56990, loss = 0.42201
I0526 13:49:55.165014 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.42201 (* 1 = 0.42201 loss)
I0526 13:49:55.165019 15394 sgd_solver.cpp:43] Iteration 56990, lr = 0.0002
I0526 13:49:59.433336 15394 main.cpp:465] Iteration 57000, Testing net (#0)
I0526 13:50:12.528491 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8958
I0526 13:50:12.528525 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.325172 (* 1 = 0.325172 loss)
I0526 13:50:13.002451 15394 main.cpp:354] Iteration 57000, loss = 0.258399
I0526 13:50:13.002482 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.258399 (* 1 = 0.258399 loss)
I0526 13:50:13.002490 15394 sgd_solver.cpp:43] Iteration 57000, lr = 0.0002
I0526 13:50:17.808673 15394 main.cpp:354] Iteration 57010, loss = 0.174085
I0526 13:50:17.808712 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.174085 (* 1 = 0.174085 loss)
I0526 13:50:17.808718 15394 sgd_solver.cpp:43] Iteration 57010, lr = 0.0002
I0526 13:50:22.929499 15394 main.cpp:354] Iteration 57020, loss = 0.23541
I0526 13:50:22.929538 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235409 (* 1 = 0.235409 loss)
I0526 13:50:22.929543 15394 sgd_solver.cpp:43] Iteration 57020, lr = 0.0002
I0526 13:50:27.996187 15394 main.cpp:354] Iteration 57030, loss = 0.15417
I0526 13:50:27.996222 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.154169 (* 1 = 0.154169 loss)
I0526 13:50:27.996227 15394 sgd_solver.cpp:43] Iteration 57030, lr = 0.0002
I0526 13:50:33.180078 15394 main.cpp:354] Iteration 57040, loss = 0.220273
I0526 13:50:33.180115 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.220273 (* 1 = 0.220273 loss)
I0526 13:50:33.180129 15394 sgd_solver.cpp:43] Iteration 57040, lr = 0.0002
I0526 13:50:38.493574 15394 main.cpp:354] Iteration 57050, loss = 0.132906
I0526 13:50:38.493625 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.132905 (* 1 = 0.132905 loss)
I0526 13:50:38.493631 15394 sgd_solver.cpp:43] Iteration 57050, lr = 0.0002
I0526 13:50:43.417896 15394 main.cpp:354] Iteration 57060, loss = 0.203999
I0526 13:50:43.417932 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.203999 (* 1 = 0.203999 loss)
I0526 13:50:43.417937 15394 sgd_solver.cpp:43] Iteration 57060, lr = 0.0002
I0526 13:50:48.506136 15394 main.cpp:354] Iteration 57070, loss = 0.319601
I0526 13:50:48.506175 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.319601 (* 1 = 0.319601 loss)
I0526 13:50:48.506182 15394 sgd_solver.cpp:43] Iteration 57070, lr = 0.0002
I0526 13:50:53.385732 15394 main.cpp:354] Iteration 57080, loss = 0.245393
I0526 13:50:53.385771 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.245393 (* 1 = 0.245393 loss)
I0526 13:50:53.385776 15394 sgd_solver.cpp:43] Iteration 57080, lr = 0.0002
I0526 13:50:58.356067 15394 main.cpp:354] Iteration 57090, loss = 0.186121
I0526 13:50:58.356102 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186121 (* 1 = 0.186121 loss)
I0526 13:50:58.356109 15394 sgd_solver.cpp:43] Iteration 57090, lr = 0.0002
I0526 13:51:02.987329 15394 main.cpp:465] Iteration 57100, Testing net (#0)
I0526 13:51:16.103863 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8981
I0526 13:51:16.103898 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.326102 (* 1 = 0.326102 loss)
I0526 13:51:16.612028 15394 main.cpp:354] Iteration 57100, loss = 0.138989
I0526 13:51:16.612067 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.138988 (* 1 = 0.138988 loss)
I0526 13:51:16.612076 15394 sgd_solver.cpp:43] Iteration 57100, lr = 0.0002
I0526 13:51:21.602980 15394 main.cpp:354] Iteration 57110, loss = 0.234068
I0526 13:51:21.603021 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.234067 (* 1 = 0.234067 loss)
I0526 13:51:21.603029 15394 sgd_solver.cpp:43] Iteration 57110, lr = 0.0002
I0526 13:51:26.712908 15394 main.cpp:354] Iteration 57120, loss = 0.096915
I0526 13:51:26.712944 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0969145 (* 1 = 0.0969145 loss)
I0526 13:51:26.712949 15394 sgd_solver.cpp:43] Iteration 57120, lr = 0.0002
I0526 13:51:31.958958 15394 main.cpp:354] Iteration 57130, loss = 0.151124
I0526 13:51:31.958992 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.151124 (* 1 = 0.151124 loss)
I0526 13:51:31.958999 15394 sgd_solver.cpp:43] Iteration 57130, lr = 0.0002
I0526 13:51:36.803987 15394 main.cpp:354] Iteration 57140, loss = 0.230605
I0526 13:51:36.804025 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.230605 (* 1 = 0.230605 loss)
I0526 13:51:36.804031 15394 sgd_solver.cpp:43] Iteration 57140, lr = 0.0002
I0526 13:51:42.095823 15394 main.cpp:354] Iteration 57150, loss = 0.235926
I0526 13:51:42.095860 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235926 (* 1 = 0.235926 loss)
I0526 13:51:42.095866 15394 sgd_solver.cpp:43] Iteration 57150, lr = 0.0002
I0526 13:51:46.379750 15394 main.cpp:354] Iteration 57160, loss = 0.18884
I0526 13:51:46.379782 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.188839 (* 1 = 0.188839 loss)
I0526 13:51:46.379789 15394 sgd_solver.cpp:43] Iteration 57160, lr = 0.0002
I0526 13:51:51.620887 15394 main.cpp:354] Iteration 57170, loss = 0.202567
I0526 13:51:51.620926 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.202567 (* 1 = 0.202567 loss)
I0526 13:51:51.620931 15394 sgd_solver.cpp:43] Iteration 57170, lr = 0.0002
I0526 13:51:56.915716 15394 main.cpp:354] Iteration 57180, loss = 0.271162
I0526 13:51:56.915766 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.271161 (* 1 = 0.271161 loss)
I0526 13:51:56.915772 15394 sgd_solver.cpp:43] Iteration 57180, lr = 0.0002
I0526 13:52:01.911613 15394 main.cpp:354] Iteration 57190, loss = 0.18689
I0526 13:52:01.911648 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.18689 (* 1 = 0.18689 loss)
I0526 13:52:01.911654 15394 sgd_solver.cpp:43] Iteration 57190, lr = 0.0002
I0526 13:52:06.392285 15394 main.cpp:465] Iteration 57200, Testing net (#0)
I0526 13:52:19.497061 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8973
I0526 13:52:19.497099 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.327557 (* 1 = 0.327557 loss)
I0526 13:52:19.964802 15394 main.cpp:354] Iteration 57200, loss = 0.25387
I0526 13:52:19.964834 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.253869 (* 1 = 0.253869 loss)
I0526 13:52:19.964843 15394 sgd_solver.cpp:43] Iteration 57200, lr = 0.0002
I0526 13:52:25.415464 15394 main.cpp:354] Iteration 57210, loss = 0.123036
I0526 13:52:25.415503 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.123035 (* 1 = 0.123035 loss)
I0526 13:52:25.415508 15394 sgd_solver.cpp:43] Iteration 57210, lr = 0.0002
I0526 13:52:30.671483 15394 main.cpp:354] Iteration 57220, loss = 0.244934
I0526 13:52:30.671519 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.244933 (* 1 = 0.244933 loss)
I0526 13:52:30.671526 15394 sgd_solver.cpp:43] Iteration 57220, lr = 0.0002
I0526 13:52:35.771211 15394 main.cpp:354] Iteration 57230, loss = 0.125782
I0526 13:52:35.771250 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.125781 (* 1 = 0.125781 loss)
I0526 13:52:35.771256 15394 sgd_solver.cpp:43] Iteration 57230, lr = 0.0002
I0526 13:52:41.001333 15394 main.cpp:354] Iteration 57240, loss = 0.161522
I0526 13:52:41.001371 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.161522 (* 1 = 0.161522 loss)
I0526 13:52:41.001379 15394 sgd_solver.cpp:43] Iteration 57240, lr = 0.0002
I0526 13:52:46.240254 15394 main.cpp:354] Iteration 57250, loss = 0.125979
I0526 13:52:46.240289 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.125979 (* 1 = 0.125979 loss)
I0526 13:52:46.240296 15394 sgd_solver.cpp:43] Iteration 57250, lr = 0.0002
I0526 13:52:51.201845 15394 main.cpp:354] Iteration 57260, loss = 0.319789
I0526 13:52:51.201886 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.319788 (* 1 = 0.319788 loss)
I0526 13:52:51.201892 15394 sgd_solver.cpp:43] Iteration 57260, lr = 0.0002
I0526 13:52:56.448161 15394 main.cpp:354] Iteration 57270, loss = 0.316757
I0526 13:52:56.448196 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.316756 (* 1 = 0.316756 loss)
I0526 13:52:56.448204 15394 sgd_solver.cpp:43] Iteration 57270, lr = 0.0002
I0526 13:53:01.327356 15394 main.cpp:354] Iteration 57280, loss = 0.168546
I0526 13:53:01.327394 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.168545 (* 1 = 0.168545 loss)
I0526 13:53:01.327400 15394 sgd_solver.cpp:43] Iteration 57280, lr = 0.0002
I0526 13:53:06.250599 15394 main.cpp:354] Iteration 57290, loss = 0.232927
I0526 13:53:06.250638 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.232926 (* 1 = 0.232926 loss)
I0526 13:53:06.250644 15394 sgd_solver.cpp:43] Iteration 57290, lr = 0.0002
I0526 13:53:11.037497 15394 main.cpp:465] Iteration 57300, Testing net (#0)
I0526 13:53:24.128574 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8961
I0526 13:53:24.128614 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.330418 (* 1 = 0.330418 loss)
I0526 13:53:24.595193 15394 main.cpp:354] Iteration 57300, loss = 0.24509
I0526 13:53:24.595228 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.245089 (* 1 = 0.245089 loss)
I0526 13:53:24.595235 15394 sgd_solver.cpp:43] Iteration 57300, lr = 0.0002
I0526 13:53:29.689749 15394 main.cpp:354] Iteration 57310, loss = 0.699963
I0526 13:53:29.689781 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.699962 (* 1 = 0.699962 loss)
I0526 13:53:29.689787 15394 sgd_solver.cpp:43] Iteration 57310, lr = 0.0002
I0526 13:53:34.542266 15394 main.cpp:354] Iteration 57320, loss = 0.154857
I0526 13:53:34.542335 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.154856 (* 1 = 0.154856 loss)
I0526 13:53:34.542343 15394 sgd_solver.cpp:43] Iteration 57320, lr = 0.0002
I0526 13:53:39.823160 15394 main.cpp:354] Iteration 57330, loss = 0.152693
I0526 13:53:39.823195 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.152692 (* 1 = 0.152692 loss)
I0526 13:53:39.823201 15394 sgd_solver.cpp:43] Iteration 57330, lr = 0.0002
I0526 13:53:45.234462 15394 main.cpp:354] Iteration 57340, loss = 0.193558
I0526 13:53:45.234498 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.193558 (* 1 = 0.193558 loss)
I0526 13:53:45.234503 15394 sgd_solver.cpp:43] Iteration 57340, lr = 0.0002
I0526 13:53:50.251512 15394 main.cpp:354] Iteration 57350, loss = 0.184346
I0526 13:53:50.251549 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.184346 (* 1 = 0.184346 loss)
I0526 13:53:50.251556 15394 sgd_solver.cpp:43] Iteration 57350, lr = 0.0002
I0526 13:53:55.411442 15394 main.cpp:354] Iteration 57360, loss = 0.091372
I0526 13:53:55.411475 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0913714 (* 1 = 0.0913714 loss)
I0526 13:53:55.411483 15394 sgd_solver.cpp:43] Iteration 57360, lr = 0.0002
I0526 13:54:00.474598 15394 main.cpp:354] Iteration 57370, loss = 0.204513
I0526 13:54:00.474633 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204512 (* 1 = 0.204512 loss)
I0526 13:54:00.474640 15394 sgd_solver.cpp:43] Iteration 57370, lr = 0.0002
I0526 13:54:05.632097 15394 main.cpp:354] Iteration 57380, loss = 0.137952
I0526 13:54:05.632135 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.137951 (* 1 = 0.137951 loss)
I0526 13:54:05.632141 15394 sgd_solver.cpp:43] Iteration 57380, lr = 0.0002
I0526 13:54:10.725553 15394 main.cpp:354] Iteration 57390, loss = 0.142423
I0526 13:54:10.725589 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.142423 (* 1 = 0.142423 loss)
I0526 13:54:10.725595 15394 sgd_solver.cpp:43] Iteration 57390, lr = 0.0002
I0526 13:54:14.881435 15394 main.cpp:465] Iteration 57400, Testing net (#0)
I0526 13:54:27.979184 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8985
I0526 13:54:27.979223 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.329123 (* 1 = 0.329123 loss)
I0526 13:54:28.408793 15394 main.cpp:354] Iteration 57400, loss = 0.176046
I0526 13:54:28.408826 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.176046 (* 1 = 0.176046 loss)
I0526 13:54:28.408834 15394 sgd_solver.cpp:43] Iteration 57400, lr = 0.0002
I0526 13:54:33.262799 15394 main.cpp:354] Iteration 57410, loss = 0.224013
I0526 13:54:33.262832 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.224012 (* 1 = 0.224012 loss)
I0526 13:54:33.262838 15394 sgd_solver.cpp:43] Iteration 57410, lr = 0.0002
I0526 13:54:38.367862 15394 main.cpp:354] Iteration 57420, loss = 0.138408
I0526 13:54:38.367913 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.138407 (* 1 = 0.138407 loss)
I0526 13:54:38.367920 15394 sgd_solver.cpp:43] Iteration 57420, lr = 0.0002
I0526 13:54:43.913159 15394 main.cpp:354] Iteration 57430, loss = 0.456334
I0526 13:54:43.913195 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.456333 (* 1 = 0.456333 loss)
I0526 13:54:43.913200 15394 sgd_solver.cpp:43] Iteration 57430, lr = 0.0002
I0526 13:54:48.838263 15394 main.cpp:354] Iteration 57440, loss = 0.121167
I0526 13:54:48.838304 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.121167 (* 1 = 0.121167 loss)
I0526 13:54:48.838310 15394 sgd_solver.cpp:43] Iteration 57440, lr = 0.0002
I0526 13:54:54.012996 15394 main.cpp:354] Iteration 57450, loss = 0.235629
I0526 13:54:54.013033 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235628 (* 1 = 0.235628 loss)
I0526 13:54:54.013039 15394 sgd_solver.cpp:43] Iteration 57450, lr = 0.0002
I0526 13:54:59.038591 15394 main.cpp:354] Iteration 57460, loss = 0.207199
I0526 13:54:59.038630 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.207198 (* 1 = 0.207198 loss)
I0526 13:54:59.038641 15394 sgd_solver.cpp:43] Iteration 57460, lr = 0.0002
I0526 13:55:04.255980 15394 main.cpp:354] Iteration 57470, loss = 0.221895
I0526 13:55:04.256019 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.221895 (* 1 = 0.221895 loss)
I0526 13:55:04.256026 15394 sgd_solver.cpp:43] Iteration 57470, lr = 0.0002
I0526 13:55:09.376057 15394 main.cpp:354] Iteration 57480, loss = 0.278795
I0526 13:55:09.376098 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.278794 (* 1 = 0.278794 loss)
I0526 13:55:09.376104 15394 sgd_solver.cpp:43] Iteration 57480, lr = 0.0002
I0526 13:55:14.634240 15394 main.cpp:354] Iteration 57490, loss = 0.26423
I0526 13:55:14.634295 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.26423 (* 1 = 0.26423 loss)
I0526 13:55:14.634305 15394 sgd_solver.cpp:43] Iteration 57490, lr = 0.0002
I0526 13:55:19.191071 15394 main.cpp:465] Iteration 57500, Testing net (#0)
I0526 13:55:32.636962 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8969
I0526 13:55:32.637007 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.336708 (* 1 = 0.336708 loss)
I0526 13:55:33.135095 15394 main.cpp:354] Iteration 57500, loss = 0.175828
I0526 13:55:33.135169 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.175827 (* 1 = 0.175827 loss)
I0526 13:55:33.135179 15394 sgd_solver.cpp:43] Iteration 57500, lr = 0.0002
I0526 13:55:37.855216 15394 main.cpp:354] Iteration 57510, loss = 0.260073
I0526 13:55:37.855259 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.260072 (* 1 = 0.260072 loss)
I0526 13:55:37.855267 15394 sgd_solver.cpp:43] Iteration 57510, lr = 0.0002
I0526 13:55:42.374472 15394 main.cpp:354] Iteration 57520, loss = 0.242854
I0526 13:55:42.374522 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.242853 (* 1 = 0.242853 loss)
I0526 13:55:42.374529 15394 sgd_solver.cpp:43] Iteration 57520, lr = 0.0002
I0526 13:55:47.604634 15394 main.cpp:354] Iteration 57530, loss = 0.278462
I0526 13:55:47.604671 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.278461 (* 1 = 0.278461 loss)
I0526 13:55:47.604677 15394 sgd_solver.cpp:43] Iteration 57530, lr = 0.0002
I0526 13:55:52.581473 15394 main.cpp:354] Iteration 57540, loss = 0.228275
I0526 13:55:52.581513 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.228274 (* 1 = 0.228274 loss)
I0526 13:55:52.581519 15394 sgd_solver.cpp:43] Iteration 57540, lr = 0.0002
I0526 13:55:57.837096 15394 main.cpp:354] Iteration 57550, loss = 0.224572
I0526 13:55:57.837131 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.224572 (* 1 = 0.224572 loss)
I0526 13:55:57.837138 15394 sgd_solver.cpp:43] Iteration 57550, lr = 0.0002
I0526 13:56:02.527982 15394 main.cpp:354] Iteration 57560, loss = 0.557835
I0526 13:56:02.528018 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.557835 (* 1 = 0.557835 loss)
I0526 13:56:02.528024 15394 sgd_solver.cpp:43] Iteration 57560, lr = 0.0002
I0526 13:56:07.245014 15394 main.cpp:354] Iteration 57570, loss = 0.377041
I0526 13:56:07.245056 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.377041 (* 1 = 0.377041 loss)
I0526 13:56:07.245061 15394 sgd_solver.cpp:43] Iteration 57570, lr = 0.0002
I0526 13:56:12.342507 15394 main.cpp:354] Iteration 57580, loss = 0.707425
I0526 13:56:12.342542 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.707425 (* 1 = 0.707425 loss)
I0526 13:56:12.342550 15394 sgd_solver.cpp:43] Iteration 57580, lr = 0.0002
I0526 13:56:17.414191 15394 main.cpp:354] Iteration 57590, loss = 0.393854
I0526 13:56:17.414227 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.393853 (* 1 = 0.393853 loss)
I0526 13:56:17.414234 15394 sgd_solver.cpp:43] Iteration 57590, lr = 0.0002
I0526 13:56:22.020678 15394 main.cpp:465] Iteration 57600, Testing net (#0)
I0526 13:56:35.131031 15394 main.cpp:532]     Test net output #0: Accuracy = 0.898
I0526 13:56:35.131069 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.328834 (* 1 = 0.328834 loss)
I0526 13:56:35.671241 15394 main.cpp:354] Iteration 57600, loss = 0.13854
I0526 13:56:35.671275 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.138539 (* 1 = 0.138539 loss)
I0526 13:56:35.671283 15394 sgd_solver.cpp:43] Iteration 57600, lr = 0.0002
I0526 13:56:41.071357 15394 main.cpp:354] Iteration 57610, loss = 0.17481
I0526 13:56:41.071393 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.17481 (* 1 = 0.17481 loss)
I0526 13:56:41.071399 15394 sgd_solver.cpp:43] Iteration 57610, lr = 0.0002
I0526 13:56:46.016548 15394 main.cpp:354] Iteration 57620, loss = 0.261977
I0526 13:56:46.016582 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.261977 (* 1 = 0.261977 loss)
I0526 13:56:46.016589 15394 sgd_solver.cpp:43] Iteration 57620, lr = 0.0002
I0526 13:56:51.099557 15394 main.cpp:354] Iteration 57630, loss = 0.254974
I0526 13:56:51.099599 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.254974 (* 1 = 0.254974 loss)
I0526 13:56:51.099606 15394 sgd_solver.cpp:43] Iteration 57630, lr = 0.0002
I0526 13:56:55.961149 15394 main.cpp:354] Iteration 57640, loss = 0.180676
I0526 13:56:55.961186 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.180675 (* 1 = 0.180675 loss)
I0526 13:56:55.961191 15394 sgd_solver.cpp:43] Iteration 57640, lr = 0.0002
I0526 13:57:01.181205 15394 main.cpp:354] Iteration 57650, loss = 0.274238
I0526 13:57:01.181241 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.274237 (* 1 = 0.274237 loss)
I0526 13:57:01.181246 15394 sgd_solver.cpp:43] Iteration 57650, lr = 0.0002
I0526 13:57:05.665325 15394 main.cpp:354] Iteration 57660, loss = 0.224754
I0526 13:57:05.665367 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.224753 (* 1 = 0.224753 loss)
I0526 13:57:05.665374 15394 sgd_solver.cpp:43] Iteration 57660, lr = 0.0002
I0526 13:57:11.055372 15394 main.cpp:354] Iteration 57670, loss = 0.147763
I0526 13:57:11.055419 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.147762 (* 1 = 0.147762 loss)
I0526 13:57:11.055425 15394 sgd_solver.cpp:43] Iteration 57670, lr = 0.0002
I0526 13:57:16.208047 15394 main.cpp:354] Iteration 57680, loss = 0.265352
I0526 13:57:16.208086 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.265351 (* 1 = 0.265351 loss)
I0526 13:57:16.208091 15394 sgd_solver.cpp:43] Iteration 57680, lr = 0.0002
I0526 13:57:21.370105 15394 main.cpp:354] Iteration 57690, loss = 0.149124
I0526 13:57:21.370146 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.149123 (* 1 = 0.149123 loss)
I0526 13:57:21.370151 15394 sgd_solver.cpp:43] Iteration 57690, lr = 0.0002
I0526 13:57:26.047045 15394 main.cpp:465] Iteration 57700, Testing net (#0)
I0526 13:57:39.151504 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8952
I0526 13:57:39.151543 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.332771 (* 1 = 0.332771 loss)
I0526 13:57:39.480931 15394 main.cpp:354] Iteration 57700, loss = 0.332325
I0526 13:57:39.480965 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.332324 (* 1 = 0.332324 loss)
I0526 13:57:39.480973 15394 sgd_solver.cpp:43] Iteration 57700, lr = 0.0002
I0526 13:57:44.219208 15394 main.cpp:354] Iteration 57710, loss = 0.230498
I0526 13:57:44.219246 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.230498 (* 1 = 0.230498 loss)
I0526 13:57:44.219252 15394 sgd_solver.cpp:43] Iteration 57710, lr = 0.0002
I0526 13:57:49.352421 15394 main.cpp:354] Iteration 57720, loss = 0.197182
I0526 13:57:49.352460 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.197182 (* 1 = 0.197182 loss)
I0526 13:57:49.352468 15394 sgd_solver.cpp:43] Iteration 57720, lr = 0.0002
I0526 13:57:53.924317 15394 main.cpp:354] Iteration 57730, loss = 0.388971
I0526 13:57:53.924366 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.388971 (* 1 = 0.388971 loss)
I0526 13:57:53.924373 15394 sgd_solver.cpp:43] Iteration 57730, lr = 0.0002
I0526 13:57:58.571732 15394 main.cpp:354] Iteration 57740, loss = 0.699995
I0526 13:57:58.571768 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.699994 (* 1 = 0.699994 loss)
I0526 13:57:58.571775 15394 sgd_solver.cpp:43] Iteration 57740, lr = 0.0002
I0526 13:58:03.858288 15394 main.cpp:354] Iteration 57750, loss = 0.169109
I0526 13:58:03.858338 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.169109 (* 1 = 0.169109 loss)
I0526 13:58:03.858345 15394 sgd_solver.cpp:43] Iteration 57750, lr = 0.0002
I0526 13:58:09.150651 15394 main.cpp:354] Iteration 57760, loss = 0.121253
I0526 13:58:09.150701 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.121252 (* 1 = 0.121252 loss)
I0526 13:58:09.150717 15394 sgd_solver.cpp:43] Iteration 57760, lr = 0.0002
I0526 13:58:14.348680 15394 main.cpp:354] Iteration 57770, loss = 0.136245
I0526 13:58:14.348716 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.136245 (* 1 = 0.136245 loss)
I0526 13:58:14.348723 15394 sgd_solver.cpp:43] Iteration 57770, lr = 0.0002
I0526 13:58:19.168752 15394 main.cpp:354] Iteration 57780, loss = 0.816777
I0526 13:58:19.168792 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.816777 (* 1 = 0.816777 loss)
I0526 13:58:19.168797 15394 sgd_solver.cpp:43] Iteration 57780, lr = 0.0002
I0526 13:58:24.753422 15394 main.cpp:354] Iteration 57790, loss = 0.0809157
I0526 13:58:24.753459 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0809152 (* 1 = 0.0809152 loss)
I0526 13:58:24.753465 15394 sgd_solver.cpp:43] Iteration 57790, lr = 0.0002
I0526 13:58:29.258838 15394 main.cpp:465] Iteration 57800, Testing net (#0)
I0526 13:58:42.360411 15394 main.cpp:532]     Test net output #0: Accuracy = 0.9
I0526 13:58:42.360450 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.328088 (* 1 = 0.328088 loss)
I0526 13:58:42.905148 15394 main.cpp:354] Iteration 57800, loss = 0.169796
I0526 13:58:42.905179 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.169795 (* 1 = 0.169795 loss)
I0526 13:58:42.905187 15394 sgd_solver.cpp:43] Iteration 57800, lr = 0.0002
I0526 13:58:47.824020 15394 main.cpp:354] Iteration 57810, loss = 0.195794
I0526 13:58:47.824054 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.195794 (* 1 = 0.195794 loss)
I0526 13:58:47.824060 15394 sgd_solver.cpp:43] Iteration 57810, lr = 0.0002
I0526 13:58:53.083938 15394 main.cpp:354] Iteration 57820, loss = 0.110693
I0526 13:58:53.083977 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.110692 (* 1 = 0.110692 loss)
I0526 13:58:53.083984 15394 sgd_solver.cpp:43] Iteration 57820, lr = 0.0002
I0526 13:58:57.544013 15394 main.cpp:354] Iteration 57830, loss = 0.119744
I0526 13:58:57.544052 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.119743 (* 1 = 0.119743 loss)
I0526 13:58:57.544059 15394 sgd_solver.cpp:43] Iteration 57830, lr = 0.0002
I0526 13:59:02.636003 15394 main.cpp:354] Iteration 57840, loss = 0.203606
I0526 13:59:02.636036 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.203606 (* 1 = 0.203606 loss)
I0526 13:59:02.636042 15394 sgd_solver.cpp:43] Iteration 57840, lr = 0.0002
I0526 13:59:08.282230 15394 main.cpp:354] Iteration 57850, loss = 0.0949546
I0526 13:59:08.282269 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0949541 (* 1 = 0.0949541 loss)
I0526 13:59:08.282276 15394 sgd_solver.cpp:43] Iteration 57850, lr = 0.0002
I0526 13:59:13.434056 15394 main.cpp:354] Iteration 57860, loss = 0.126697
I0526 13:59:13.434092 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.126697 (* 1 = 0.126697 loss)
I0526 13:59:13.434098 15394 sgd_solver.cpp:43] Iteration 57860, lr = 0.0002
I0526 13:59:18.998522 15394 main.cpp:354] Iteration 57870, loss = 0.146219
I0526 13:59:18.998558 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.146219 (* 1 = 0.146219 loss)
I0526 13:59:18.998565 15394 sgd_solver.cpp:43] Iteration 57870, lr = 0.0002
I0526 13:59:24.284946 15394 main.cpp:354] Iteration 57880, loss = 0.210902
I0526 13:59:24.284986 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.210902 (* 1 = 0.210902 loss)
I0526 13:59:24.284991 15394 sgd_solver.cpp:43] Iteration 57880, lr = 0.0002
I0526 13:59:29.311777 15394 main.cpp:354] Iteration 57890, loss = 0.184144
I0526 13:59:29.311815 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.184143 (* 1 = 0.184143 loss)
I0526 13:59:29.311822 15394 sgd_solver.cpp:43] Iteration 57890, lr = 0.0002
I0526 13:59:34.022047 15394 main.cpp:465] Iteration 57900, Testing net (#0)
I0526 13:59:47.118599 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8966
I0526 13:59:47.118646 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.327161 (* 1 = 0.327161 loss)
I0526 13:59:47.555047 15394 main.cpp:354] Iteration 57900, loss = 0.13871
I0526 13:59:47.555081 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.138709 (* 1 = 0.138709 loss)
I0526 13:59:47.555088 15394 sgd_solver.cpp:43] Iteration 57900, lr = 0.0002
I0526 13:59:52.714020 15394 main.cpp:354] Iteration 57910, loss = 0.185519
I0526 13:59:52.714059 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.185519 (* 1 = 0.185519 loss)
I0526 13:59:52.714066 15394 sgd_solver.cpp:43] Iteration 57910, lr = 0.0002
I0526 13:59:57.982769 15394 main.cpp:354] Iteration 57920, loss = 0.319833
I0526 13:59:57.982806 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.319832 (* 1 = 0.319832 loss)
I0526 13:59:57.982813 15394 sgd_solver.cpp:43] Iteration 57920, lr = 0.0002
I0526 14:00:02.863801 15394 main.cpp:354] Iteration 57930, loss = 0.580618
I0526 14:00:02.863842 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.580617 (* 1 = 0.580617 loss)
I0526 14:00:02.863847 15394 sgd_solver.cpp:43] Iteration 57930, lr = 0.0002
I0526 14:00:07.486723 15394 main.cpp:354] Iteration 57940, loss = 0.232547
I0526 14:00:07.486763 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.232547 (* 1 = 0.232547 loss)
I0526 14:00:07.486770 15394 sgd_solver.cpp:43] Iteration 57940, lr = 0.0002
I0526 14:00:13.039950 15394 main.cpp:354] Iteration 57950, loss = 0.140116
I0526 14:00:13.039986 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.140115 (* 1 = 0.140115 loss)
I0526 14:00:13.039994 15394 sgd_solver.cpp:43] Iteration 57950, lr = 0.0002
I0526 14:00:18.290598 15394 main.cpp:354] Iteration 57960, loss = 0.164423
I0526 14:00:18.290632 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.164423 (* 1 = 0.164423 loss)
I0526 14:00:18.290639 15394 sgd_solver.cpp:43] Iteration 57960, lr = 0.0002
I0526 14:00:23.395880 15394 main.cpp:354] Iteration 57970, loss = 0.240698
I0526 14:00:23.395931 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.240697 (* 1 = 0.240697 loss)
I0526 14:00:23.395938 15394 sgd_solver.cpp:43] Iteration 57970, lr = 0.0002
I0526 14:00:28.558763 15394 main.cpp:354] Iteration 57980, loss = 0.260506
I0526 14:00:28.558799 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.260506 (* 1 = 0.260506 loss)
I0526 14:00:28.558804 15394 sgd_solver.cpp:43] Iteration 57980, lr = 0.0002
I0526 14:00:33.800132 15394 main.cpp:354] Iteration 57990, loss = 0.261208
I0526 14:00:33.800168 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.261207 (* 1 = 0.261207 loss)
I0526 14:00:33.800173 15394 sgd_solver.cpp:43] Iteration 57990, lr = 0.0002
I0526 14:00:38.355839 15394 main.cpp:465] Iteration 58000, Testing net (#0)
I0526 14:00:51.510094 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8952
I0526 14:00:51.510133 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.326046 (* 1 = 0.326046 loss)
I0526 14:00:52.013538 15394 main.cpp:354] Iteration 58000, loss = 0.134339
I0526 14:00:52.013571 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.134339 (* 1 = 0.134339 loss)
I0526 14:00:52.013578 15394 sgd_solver.cpp:43] Iteration 58000, lr = 0.0002
I0526 14:00:56.743121 15394 main.cpp:354] Iteration 58010, loss = 0.206885
I0526 14:00:56.743158 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206885 (* 1 = 0.206885 loss)
I0526 14:00:56.743170 15394 sgd_solver.cpp:43] Iteration 58010, lr = 0.0002
I0526 14:01:01.695365 15394 main.cpp:354] Iteration 58020, loss = 0.280442
I0526 14:01:01.695404 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.280441 (* 1 = 0.280441 loss)
I0526 14:01:01.695410 15394 sgd_solver.cpp:43] Iteration 58020, lr = 0.0002
I0526 14:01:06.984650 15394 main.cpp:354] Iteration 58030, loss = 0.187333
I0526 14:01:06.984691 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187333 (* 1 = 0.187333 loss)
I0526 14:01:06.984699 15394 sgd_solver.cpp:43] Iteration 58030, lr = 0.0002
I0526 14:01:11.523191 15394 main.cpp:354] Iteration 58040, loss = 0.139046
I0526 14:01:11.523227 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.139045 (* 1 = 0.139045 loss)
I0526 14:01:11.523233 15394 sgd_solver.cpp:43] Iteration 58040, lr = 0.0002
I0526 14:01:16.903976 15394 main.cpp:354] Iteration 58050, loss = 0.222386
I0526 14:01:16.904014 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.222385 (* 1 = 0.222385 loss)
I0526 14:01:16.904021 15394 sgd_solver.cpp:43] Iteration 58050, lr = 0.0002
I0526 14:01:21.733523 15394 main.cpp:354] Iteration 58060, loss = 0.142064
I0526 14:01:21.733566 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.142064 (* 1 = 0.142064 loss)
I0526 14:01:21.733572 15394 sgd_solver.cpp:43] Iteration 58060, lr = 0.0002
I0526 14:01:26.941962 15394 main.cpp:354] Iteration 58070, loss = 0.452195
I0526 14:01:26.941998 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.452194 (* 1 = 0.452194 loss)
I0526 14:01:26.942003 15394 sgd_solver.cpp:43] Iteration 58070, lr = 0.0002
I0526 14:01:31.861871 15394 main.cpp:354] Iteration 58080, loss = 0.204851
I0526 14:01:31.861908 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.20485 (* 1 = 0.20485 loss)
I0526 14:01:31.861914 15394 sgd_solver.cpp:43] Iteration 58080, lr = 0.0002
I0526 14:01:36.869987 15394 main.cpp:354] Iteration 58090, loss = 0.286491
I0526 14:01:36.870028 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.286491 (* 1 = 0.286491 loss)
I0526 14:01:36.870033 15394 sgd_solver.cpp:43] Iteration 58090, lr = 0.0002
I0526 14:01:41.611030 15394 main.cpp:465] Iteration 58100, Testing net (#0)
I0526 14:01:54.715584 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8968
I0526 14:01:54.715634 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.328764 (* 1 = 0.328764 loss)
I0526 14:01:55.254415 15394 main.cpp:354] Iteration 58100, loss = 0.173916
I0526 14:01:55.254447 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.173915 (* 1 = 0.173915 loss)
I0526 14:01:55.254454 15394 sgd_solver.cpp:43] Iteration 58100, lr = 0.0002
I0526 14:02:00.725759 15394 main.cpp:354] Iteration 58110, loss = 0.25305
I0526 14:02:00.725795 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.253049 (* 1 = 0.253049 loss)
I0526 14:02:00.725802 15394 sgd_solver.cpp:43] Iteration 58110, lr = 0.0002
I0526 14:02:05.583365 15394 main.cpp:354] Iteration 58120, loss = 0.201869
I0526 14:02:05.583406 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.201869 (* 1 = 0.201869 loss)
I0526 14:02:05.583412 15394 sgd_solver.cpp:43] Iteration 58120, lr = 0.0002
I0526 14:02:10.309510 15394 main.cpp:354] Iteration 58130, loss = 0.165276
I0526 14:02:10.309548 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.165276 (* 1 = 0.165276 loss)
I0526 14:02:10.309554 15394 sgd_solver.cpp:43] Iteration 58130, lr = 0.0002
I0526 14:02:15.038852 15394 main.cpp:354] Iteration 58140, loss = 0.241401
I0526 14:02:15.038893 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.241401 (* 1 = 0.241401 loss)
I0526 14:02:15.038899 15394 sgd_solver.cpp:43] Iteration 58140, lr = 0.0002
I0526 14:02:20.656829 15394 main.cpp:354] Iteration 58150, loss = 0.202511
I0526 14:02:20.656867 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.202511 (* 1 = 0.202511 loss)
I0526 14:02:20.656880 15394 sgd_solver.cpp:43] Iteration 58150, lr = 0.0002
I0526 14:02:25.633958 15394 main.cpp:354] Iteration 58160, loss = 0.223669
I0526 14:02:25.633996 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.223668 (* 1 = 0.223668 loss)
I0526 14:02:25.634002 15394 sgd_solver.cpp:43] Iteration 58160, lr = 0.0002
I0526 14:02:30.781654 15394 main.cpp:354] Iteration 58170, loss = 0.188667
I0526 14:02:30.781692 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.188666 (* 1 = 0.188666 loss)
I0526 14:02:30.781697 15394 sgd_solver.cpp:43] Iteration 58170, lr = 0.0002
I0526 14:02:35.915030 15394 main.cpp:354] Iteration 58180, loss = 0.150498
I0526 14:02:35.915067 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.150498 (* 1 = 0.150498 loss)
I0526 14:02:35.915073 15394 sgd_solver.cpp:43] Iteration 58180, lr = 0.0002
I0526 14:02:41.555409 15394 main.cpp:354] Iteration 58190, loss = 0.107274
I0526 14:02:41.555447 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.107273 (* 1 = 0.107273 loss)
I0526 14:02:41.555454 15394 sgd_solver.cpp:43] Iteration 58190, lr = 0.0002
I0526 14:02:45.966003 15394 main.cpp:465] Iteration 58200, Testing net (#0)
I0526 14:02:59.071925 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8952
I0526 14:02:59.071961 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.329276 (* 1 = 0.329276 loss)
I0526 14:02:59.610918 15394 main.cpp:354] Iteration 58200, loss = 0.143001
I0526 14:02:59.610947 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.143 (* 1 = 0.143 loss)
I0526 14:02:59.610955 15394 sgd_solver.cpp:43] Iteration 58200, lr = 0.0002
I0526 14:03:04.897946 15394 main.cpp:354] Iteration 58210, loss = 0.114895
I0526 14:03:04.897986 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.114894 (* 1 = 0.114894 loss)
I0526 14:03:04.897992 15394 sgd_solver.cpp:43] Iteration 58210, lr = 0.0002
I0526 14:03:09.873059 15394 main.cpp:354] Iteration 58220, loss = 0.235898
I0526 14:03:09.873093 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235898 (* 1 = 0.235898 loss)
I0526 14:03:09.873100 15394 sgd_solver.cpp:43] Iteration 58220, lr = 0.0002
I0526 14:03:14.943742 15394 main.cpp:354] Iteration 58230, loss = 0.155665
I0526 14:03:14.943778 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.155665 (* 1 = 0.155665 loss)
I0526 14:03:14.943785 15394 sgd_solver.cpp:43] Iteration 58230, lr = 0.0002
I0526 14:03:19.969815 15394 main.cpp:354] Iteration 58240, loss = 0.150337
I0526 14:03:19.969857 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.150337 (* 1 = 0.150337 loss)
I0526 14:03:19.969863 15394 sgd_solver.cpp:43] Iteration 58240, lr = 0.0002
I0526 14:03:24.872656 15394 main.cpp:354] Iteration 58250, loss = 0.155508
I0526 14:03:24.872694 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.155508 (* 1 = 0.155508 loss)
I0526 14:03:24.872699 15394 sgd_solver.cpp:43] Iteration 58250, lr = 0.0002
I0526 14:03:29.978324 15394 main.cpp:354] Iteration 58260, loss = 0.246437
I0526 14:03:29.978363 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.246437 (* 1 = 0.246437 loss)
I0526 14:03:29.978368 15394 sgd_solver.cpp:43] Iteration 58260, lr = 0.0002
I0526 14:03:34.989413 15394 main.cpp:354] Iteration 58270, loss = 0.35577
I0526 14:03:34.989452 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.35577 (* 1 = 0.35577 loss)
I0526 14:03:34.989459 15394 sgd_solver.cpp:43] Iteration 58270, lr = 0.0002
I0526 14:03:40.359930 15394 main.cpp:354] Iteration 58280, loss = 0.0960864
I0526 14:03:40.359969 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0960859 (* 1 = 0.0960859 loss)
I0526 14:03:40.359977 15394 sgd_solver.cpp:43] Iteration 58280, lr = 0.0002
I0526 14:03:45.077308 15394 main.cpp:354] Iteration 58290, loss = 0.221079
I0526 14:03:45.077343 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.221078 (* 1 = 0.221078 loss)
I0526 14:03:45.077349 15394 sgd_solver.cpp:43] Iteration 58290, lr = 0.0002
I0526 14:03:49.946575 15394 main.cpp:465] Iteration 58300, Testing net (#0)
I0526 14:04:03.043154 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8966
I0526 14:04:03.043190 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.324337 (* 1 = 0.324337 loss)
I0526 14:04:03.480449 15394 main.cpp:354] Iteration 58300, loss = 0.201513
I0526 14:04:03.480485 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.201513 (* 1 = 0.201513 loss)
I0526 14:04:03.480492 15394 sgd_solver.cpp:43] Iteration 58300, lr = 0.0002
I0526 14:04:08.507307 15394 main.cpp:354] Iteration 58310, loss = 0.237794
I0526 14:04:08.507344 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.237793 (* 1 = 0.237793 loss)
I0526 14:04:08.507351 15394 sgd_solver.cpp:43] Iteration 58310, lr = 0.0002
I0526 14:04:13.657811 15394 main.cpp:354] Iteration 58320, loss = 0.203956
I0526 14:04:13.657847 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.203956 (* 1 = 0.203956 loss)
I0526 14:04:13.657853 15394 sgd_solver.cpp:43] Iteration 58320, lr = 0.0002
I0526 14:04:18.592391 15394 main.cpp:354] Iteration 58330, loss = 0.256137
I0526 14:04:18.592428 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.256136 (* 1 = 0.256136 loss)
I0526 14:04:18.592434 15394 sgd_solver.cpp:43] Iteration 58330, lr = 0.0002
I0526 14:04:23.123425 15394 main.cpp:354] Iteration 58340, loss = 0.257994
I0526 14:04:23.123466 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.257993 (* 1 = 0.257993 loss)
I0526 14:04:23.123472 15394 sgd_solver.cpp:43] Iteration 58340, lr = 0.0002
I0526 14:04:28.494274 15394 main.cpp:354] Iteration 58350, loss = 0.0861074
I0526 14:04:28.494309 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0861069 (* 1 = 0.0861069 loss)
I0526 14:04:28.494315 15394 sgd_solver.cpp:43] Iteration 58350, lr = 0.0002
I0526 14:04:33.654695 15394 main.cpp:354] Iteration 58360, loss = 0.226736
I0526 14:04:33.654731 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.226735 (* 1 = 0.226735 loss)
I0526 14:04:33.654737 15394 sgd_solver.cpp:43] Iteration 58360, lr = 0.0002
I0526 14:04:38.694125 15394 main.cpp:354] Iteration 58370, loss = 0.287379
I0526 14:04:38.694164 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.287378 (* 1 = 0.287378 loss)
I0526 14:04:38.694170 15394 sgd_solver.cpp:43] Iteration 58370, lr = 0.0002
I0526 14:04:43.888404 15394 main.cpp:354] Iteration 58380, loss = 0.272921
I0526 14:04:43.888438 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.27292 (* 1 = 0.27292 loss)
I0526 14:04:43.888444 15394 sgd_solver.cpp:43] Iteration 58380, lr = 0.0002
I0526 14:04:48.631054 15394 main.cpp:354] Iteration 58390, loss = 0.119784
I0526 14:04:48.631089 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.119783 (* 1 = 0.119783 loss)
I0526 14:04:48.631096 15394 sgd_solver.cpp:43] Iteration 58390, lr = 0.0002
I0526 14:04:53.275835 15394 main.cpp:465] Iteration 58400, Testing net (#0)
I0526 14:05:06.371644 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8948
I0526 14:05:06.371695 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.329303 (* 1 = 0.329303 loss)
I0526 14:05:06.947880 15394 main.cpp:354] Iteration 58400, loss = 0.242537
I0526 14:05:06.947913 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.242536 (* 1 = 0.242536 loss)
I0526 14:05:06.947922 15394 sgd_solver.cpp:43] Iteration 58400, lr = 0.0002
I0526 14:05:12.213994 15394 main.cpp:354] Iteration 58410, loss = 0.157549
I0526 14:05:12.214030 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.157548 (* 1 = 0.157548 loss)
I0526 14:05:12.214035 15394 sgd_solver.cpp:43] Iteration 58410, lr = 0.0002
I0526 14:05:17.236716 15394 main.cpp:354] Iteration 58420, loss = 0.16047
I0526 14:05:17.236753 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.16047 (* 1 = 0.16047 loss)
I0526 14:05:17.236758 15394 sgd_solver.cpp:43] Iteration 58420, lr = 0.0002
I0526 14:05:22.378913 15394 main.cpp:354] Iteration 58430, loss = 0.115851
I0526 14:05:22.378957 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.11585 (* 1 = 0.11585 loss)
I0526 14:05:22.378964 15394 sgd_solver.cpp:43] Iteration 58430, lr = 0.0002
I0526 14:05:27.858337 15394 main.cpp:354] Iteration 58440, loss = 0.107199
I0526 14:05:27.858386 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.107199 (* 1 = 0.107199 loss)
I0526 14:05:27.858392 15394 sgd_solver.cpp:43] Iteration 58440, lr = 0.0002
I0526 14:05:33.377619 15394 main.cpp:354] Iteration 58450, loss = 0.155031
I0526 14:05:33.377655 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.15503 (* 1 = 0.15503 loss)
I0526 14:05:33.377660 15394 sgd_solver.cpp:43] Iteration 58450, lr = 0.0002
I0526 14:05:38.756500 15394 main.cpp:354] Iteration 58460, loss = 0.27904
I0526 14:05:38.756539 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.27904 (* 1 = 0.27904 loss)
I0526 14:05:38.756546 15394 sgd_solver.cpp:43] Iteration 58460, lr = 0.0002
I0526 14:05:43.792242 15394 main.cpp:354] Iteration 58470, loss = 0.21208
I0526 14:05:43.792280 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.21208 (* 1 = 0.21208 loss)
I0526 14:05:43.792287 15394 sgd_solver.cpp:43] Iteration 58470, lr = 0.0002
I0526 14:05:48.526095 15394 main.cpp:354] Iteration 58480, loss = 0.162693
I0526 14:05:48.526130 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.162692 (* 1 = 0.162692 loss)
I0526 14:05:48.526137 15394 sgd_solver.cpp:43] Iteration 58480, lr = 0.0002
I0526 14:05:53.818533 15394 main.cpp:354] Iteration 58490, loss = 0.174066
I0526 14:05:53.818572 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.174066 (* 1 = 0.174066 loss)
I0526 14:05:53.818579 15394 sgd_solver.cpp:43] Iteration 58490, lr = 0.0002
I0526 14:05:58.527321 15394 main.cpp:465] Iteration 58500, Testing net (#0)
I0526 14:06:11.633833 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8961
I0526 14:06:11.633869 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.328304 (* 1 = 0.328304 loss)
I0526 14:06:12.142357 15394 main.cpp:354] Iteration 58500, loss = 0.286616
I0526 14:06:12.142400 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.286615 (* 1 = 0.286615 loss)
I0526 14:06:12.142406 15394 sgd_solver.cpp:43] Iteration 58500, lr = 0.0002
I0526 14:06:17.301091 15394 main.cpp:354] Iteration 58510, loss = 0.229746
I0526 14:06:17.301126 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.229745 (* 1 = 0.229745 loss)
I0526 14:06:17.301133 15394 sgd_solver.cpp:43] Iteration 58510, lr = 0.0002
I0526 14:06:23.046823 15394 main.cpp:354] Iteration 58520, loss = 0.284102
I0526 14:06:23.046877 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.284101 (* 1 = 0.284101 loss)
I0526 14:06:23.046885 15394 sgd_solver.cpp:43] Iteration 58520, lr = 0.0002
I0526 14:06:28.364629 15394 main.cpp:354] Iteration 58530, loss = 0.262458
I0526 14:06:28.364661 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.262458 (* 1 = 0.262458 loss)
I0526 14:06:28.364668 15394 sgd_solver.cpp:43] Iteration 58530, lr = 0.0002
I0526 14:06:33.337057 15394 main.cpp:354] Iteration 58540, loss = 0.315663
I0526 14:06:33.337092 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.315662 (* 1 = 0.315662 loss)
I0526 14:06:33.337097 15394 sgd_solver.cpp:43] Iteration 58540, lr = 0.0002
I0526 14:06:38.154273 15394 main.cpp:354] Iteration 58550, loss = 0.290294
I0526 14:06:38.154310 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.290293 (* 1 = 0.290293 loss)
I0526 14:06:38.154316 15394 sgd_solver.cpp:43] Iteration 58550, lr = 0.0002
I0526 14:06:43.471942 15394 main.cpp:354] Iteration 58560, loss = 0.148707
I0526 14:06:43.471976 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.148706 (* 1 = 0.148706 loss)
I0526 14:06:43.471982 15394 sgd_solver.cpp:43] Iteration 58560, lr = 0.0002
I0526 14:06:48.384353 15394 main.cpp:354] Iteration 58570, loss = 0.399197
I0526 14:06:48.384389 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.399197 (* 1 = 0.399197 loss)
I0526 14:06:48.384399 15394 sgd_solver.cpp:43] Iteration 58570, lr = 0.0002
I0526 14:06:53.225527 15394 main.cpp:354] Iteration 58580, loss = 0.249639
I0526 14:06:53.225564 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.249638 (* 1 = 0.249638 loss)
I0526 14:06:53.225570 15394 sgd_solver.cpp:43] Iteration 58580, lr = 0.0002
I0526 14:06:58.312084 15394 main.cpp:354] Iteration 58590, loss = 0.222449
I0526 14:06:58.312117 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.222449 (* 1 = 0.222449 loss)
I0526 14:06:58.312124 15394 sgd_solver.cpp:43] Iteration 58590, lr = 0.0002
I0526 14:07:02.954221 15394 main.cpp:465] Iteration 58600, Testing net (#0)
I0526 14:07:16.064039 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8957
I0526 14:07:16.064074 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.337943 (* 1 = 0.337943 loss)
I0526 14:07:16.569284 15394 main.cpp:354] Iteration 58600, loss = 0.192192
I0526 14:07:16.569316 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.192192 (* 1 = 0.192192 loss)
I0526 14:07:16.569324 15394 sgd_solver.cpp:43] Iteration 58600, lr = 0.0002
I0526 14:07:22.066269 15394 main.cpp:354] Iteration 58610, loss = 0.268186
I0526 14:07:22.066310 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.268185 (* 1 = 0.268185 loss)
I0526 14:07:22.066316 15394 sgd_solver.cpp:43] Iteration 58610, lr = 0.0002
I0526 14:07:27.394219 15394 main.cpp:354] Iteration 58620, loss = 0.360771
I0526 14:07:27.394258 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.360771 (* 1 = 0.360771 loss)
I0526 14:07:27.394263 15394 sgd_solver.cpp:43] Iteration 58620, lr = 0.0002
I0526 14:07:32.559756 15394 main.cpp:354] Iteration 58630, loss = 0.803769
I0526 14:07:32.559792 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.803769 (* 1 = 0.803769 loss)
I0526 14:07:32.559798 15394 sgd_solver.cpp:43] Iteration 58630, lr = 0.0002
I0526 14:07:37.165585 15394 main.cpp:354] Iteration 58640, loss = 0.634959
I0526 14:07:37.165626 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.634958 (* 1 = 0.634958 loss)
I0526 14:07:37.165632 15394 sgd_solver.cpp:43] Iteration 58640, lr = 0.0002
I0526 14:07:42.242461 15394 main.cpp:354] Iteration 58650, loss = 0.26578
I0526 14:07:42.242496 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.265779 (* 1 = 0.265779 loss)
I0526 14:07:42.242502 15394 sgd_solver.cpp:43] Iteration 58650, lr = 0.0002
I0526 14:07:46.899003 15394 main.cpp:354] Iteration 58660, loss = 0.142384
I0526 14:07:46.899035 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.142384 (* 1 = 0.142384 loss)
I0526 14:07:46.899042 15394 sgd_solver.cpp:43] Iteration 58660, lr = 0.0002
I0526 14:07:52.139850 15394 main.cpp:354] Iteration 58670, loss = 0.18731
I0526 14:07:52.139889 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.18731 (* 1 = 0.18731 loss)
I0526 14:07:52.139894 15394 sgd_solver.cpp:43] Iteration 58670, lr = 0.0002
I0526 14:07:57.547533 15394 main.cpp:354] Iteration 58680, loss = 0.148974
I0526 14:07:57.547569 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.148974 (* 1 = 0.148974 loss)
I0526 14:07:57.547575 15394 sgd_solver.cpp:43] Iteration 58680, lr = 0.0002
I0526 14:08:02.836217 15394 main.cpp:354] Iteration 58690, loss = 0.750063
I0526 14:08:02.836251 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.750063 (* 1 = 0.750063 loss)
I0526 14:08:02.836256 15394 sgd_solver.cpp:43] Iteration 58690, lr = 0.0002
I0526 14:08:07.584576 15394 main.cpp:465] Iteration 58700, Testing net (#0)
I0526 14:08:20.682108 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8964
I0526 14:08:20.682148 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.326812 (* 1 = 0.326812 loss)
I0526 14:08:21.221755 15394 main.cpp:354] Iteration 58700, loss = 0.204088
I0526 14:08:21.221791 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204088 (* 1 = 0.204088 loss)
I0526 14:08:21.221803 15394 sgd_solver.cpp:43] Iteration 58700, lr = 0.0002
I0526 14:08:26.339897 15394 main.cpp:354] Iteration 58710, loss = 0.249434
I0526 14:08:26.339934 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.249433 (* 1 = 0.249433 loss)
I0526 14:08:26.339941 15394 sgd_solver.cpp:43] Iteration 58710, lr = 0.0002
I0526 14:08:31.361105 15394 main.cpp:354] Iteration 58720, loss = 0.167744
I0526 14:08:31.361147 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.167744 (* 1 = 0.167744 loss)
I0526 14:08:31.361153 15394 sgd_solver.cpp:43] Iteration 58720, lr = 0.0002
I0526 14:08:36.254266 15394 main.cpp:354] Iteration 58730, loss = 0.157202
I0526 14:08:36.254304 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.157202 (* 1 = 0.157202 loss)
I0526 14:08:36.254310 15394 sgd_solver.cpp:43] Iteration 58730, lr = 0.0002
I0526 14:08:41.212435 15394 main.cpp:354] Iteration 58740, loss = 0.150138
I0526 14:08:41.212471 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.150138 (* 1 = 0.150138 loss)
I0526 14:08:41.212477 15394 sgd_solver.cpp:43] Iteration 58740, lr = 0.0002
I0526 14:08:46.387338 15394 main.cpp:354] Iteration 58750, loss = 0.218972
I0526 14:08:46.387374 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.218971 (* 1 = 0.218971 loss)
I0526 14:08:46.387380 15394 sgd_solver.cpp:43] Iteration 58750, lr = 0.0002
I0526 14:08:51.727836 15394 main.cpp:354] Iteration 58760, loss = 0.223285
I0526 14:08:51.727875 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.223285 (* 1 = 0.223285 loss)
I0526 14:08:51.727881 15394 sgd_solver.cpp:43] Iteration 58760, lr = 0.0002
I0526 14:08:56.745816 15394 main.cpp:354] Iteration 58770, loss = 0.123544
I0526 14:08:56.745853 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.123543 (* 1 = 0.123543 loss)
I0526 14:08:56.745859 15394 sgd_solver.cpp:43] Iteration 58770, lr = 0.0002
I0526 14:09:02.382813 15394 main.cpp:354] Iteration 58780, loss = 0.189509
I0526 14:09:02.382848 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.189508 (* 1 = 0.189508 loss)
I0526 14:09:02.382854 15394 sgd_solver.cpp:43] Iteration 58780, lr = 0.0002
I0526 14:09:07.782871 15394 main.cpp:354] Iteration 58790, loss = 0.149812
I0526 14:09:07.782913 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.149811 (* 1 = 0.149811 loss)
I0526 14:09:07.782920 15394 sgd_solver.cpp:43] Iteration 58790, lr = 0.0002
I0526 14:09:12.458089 15394 main.cpp:465] Iteration 58800, Testing net (#0)
I0526 14:09:25.554594 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8956
I0526 14:09:25.554631 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.330321 (* 1 = 0.330321 loss)
I0526 14:09:25.956004 15394 main.cpp:354] Iteration 58800, loss = 0.274045
I0526 14:09:25.956037 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.274045 (* 1 = 0.274045 loss)
I0526 14:09:25.956043 15394 sgd_solver.cpp:43] Iteration 58800, lr = 0.0002
I0526 14:09:30.893661 15394 main.cpp:354] Iteration 58810, loss = 0.262728
I0526 14:09:30.893698 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.262727 (* 1 = 0.262727 loss)
I0526 14:09:30.893704 15394 sgd_solver.cpp:43] Iteration 58810, lr = 0.0002
I0526 14:09:35.414263 15394 main.cpp:354] Iteration 58820, loss = 0.163865
I0526 14:09:35.414301 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.163864 (* 1 = 0.163864 loss)
I0526 14:09:35.414309 15394 sgd_solver.cpp:43] Iteration 58820, lr = 0.0002
I0526 14:09:40.507268 15394 main.cpp:354] Iteration 58830, loss = 0.216766
I0526 14:09:40.507308 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.216766 (* 1 = 0.216766 loss)
I0526 14:09:40.507314 15394 sgd_solver.cpp:43] Iteration 58830, lr = 0.0002
I0526 14:09:45.580468 15394 main.cpp:354] Iteration 58840, loss = 0.100786
I0526 14:09:45.580503 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.100785 (* 1 = 0.100785 loss)
I0526 14:09:45.580509 15394 sgd_solver.cpp:43] Iteration 58840, lr = 0.0002
I0526 14:09:50.686190 15394 main.cpp:354] Iteration 58850, loss = 0.322449
I0526 14:09:50.686230 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.322448 (* 1 = 0.322448 loss)
I0526 14:09:50.686236 15394 sgd_solver.cpp:43] Iteration 58850, lr = 0.0002
I0526 14:09:55.708169 15394 main.cpp:354] Iteration 58860, loss = 0.201211
I0526 14:09:55.708204 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.201211 (* 1 = 0.201211 loss)
I0526 14:09:55.708210 15394 sgd_solver.cpp:43] Iteration 58860, lr = 0.0002
I0526 14:10:00.742403 15394 main.cpp:354] Iteration 58870, loss = 0.538337
I0526 14:10:00.742439 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.538337 (* 1 = 0.538337 loss)
I0526 14:10:00.742445 15394 sgd_solver.cpp:43] Iteration 58870, lr = 0.0002
I0526 14:10:05.840327 15394 main.cpp:354] Iteration 58880, loss = 0.23921
I0526 14:10:05.840365 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.23921 (* 1 = 0.23921 loss)
I0526 14:10:05.840373 15394 sgd_solver.cpp:43] Iteration 58880, lr = 0.0002
I0526 14:10:10.658195 15394 main.cpp:354] Iteration 58890, loss = 0.446868
I0526 14:10:10.658231 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.446867 (* 1 = 0.446867 loss)
I0526 14:10:10.658236 15394 sgd_solver.cpp:43] Iteration 58890, lr = 0.0002
I0526 14:10:14.772512 15394 main.cpp:465] Iteration 58900, Testing net (#0)
I0526 14:10:27.893645 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8971
I0526 14:10:27.893682 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.324626 (* 1 = 0.324626 loss)
I0526 14:10:28.329246 15394 main.cpp:354] Iteration 58900, loss = 0.200475
I0526 14:10:28.329277 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.200475 (* 1 = 0.200475 loss)
I0526 14:10:28.329284 15394 sgd_solver.cpp:43] Iteration 58900, lr = 0.0002
I0526 14:10:33.858746 15394 main.cpp:354] Iteration 58910, loss = 0.200571
I0526 14:10:33.858796 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.20057 (* 1 = 0.20057 loss)
I0526 14:10:33.858805 15394 sgd_solver.cpp:43] Iteration 58910, lr = 0.0002
I0526 14:10:38.579632 15394 main.cpp:354] Iteration 58920, loss = 0.140977
I0526 14:10:38.579673 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.140976 (* 1 = 0.140976 loss)
I0526 14:10:38.579679 15394 sgd_solver.cpp:43] Iteration 58920, lr = 0.0002
I0526 14:10:43.902792 15394 main.cpp:354] Iteration 58930, loss = 0.292244
I0526 14:10:43.902830 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.292244 (* 1 = 0.292244 loss)
I0526 14:10:43.902837 15394 sgd_solver.cpp:43] Iteration 58930, lr = 0.0002
I0526 14:10:48.770129 15394 main.cpp:354] Iteration 58940, loss = 0.377058
I0526 14:10:48.770170 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.377057 (* 1 = 0.377057 loss)
I0526 14:10:48.770179 15394 sgd_solver.cpp:43] Iteration 58940, lr = 0.0002
I0526 14:10:54.509958 15394 main.cpp:354] Iteration 58950, loss = 0.19088
I0526 14:10:54.509999 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.190879 (* 1 = 0.190879 loss)
I0526 14:10:54.510004 15394 sgd_solver.cpp:43] Iteration 58950, lr = 0.0002
I0526 14:10:59.382308 15394 main.cpp:354] Iteration 58960, loss = 0.187062
I0526 14:10:59.382344 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187062 (* 1 = 0.187062 loss)
I0526 14:10:59.382350 15394 sgd_solver.cpp:43] Iteration 58960, lr = 0.0002
I0526 14:11:04.660064 15394 main.cpp:354] Iteration 58970, loss = 0.248874
I0526 14:11:04.660104 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.248874 (* 1 = 0.248874 loss)
I0526 14:11:04.660110 15394 sgd_solver.cpp:43] Iteration 58970, lr = 0.0002
I0526 14:11:09.806818 15394 main.cpp:354] Iteration 58980, loss = 0.228374
I0526 14:11:09.806854 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.228374 (* 1 = 0.228374 loss)
I0526 14:11:09.806860 15394 sgd_solver.cpp:43] Iteration 58980, lr = 0.0002
I0526 14:11:14.716917 15394 main.cpp:354] Iteration 58990, loss = 0.19895
I0526 14:11:14.716958 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.198949 (* 1 = 0.198949 loss)
I0526 14:11:14.716964 15394 sgd_solver.cpp:43] Iteration 58990, lr = 0.0002
I0526 14:11:19.275445 15394 main.cpp:465] Iteration 59000, Testing net (#0)
I0526 14:11:32.377941 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8968
I0526 14:11:32.377981 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.327665 (* 1 = 0.327665 loss)
I0526 14:11:32.881227 15394 main.cpp:354] Iteration 59000, loss = 0.138127
I0526 14:11:32.881249 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.138126 (* 1 = 0.138126 loss)
I0526 14:11:32.881256 15394 sgd_solver.cpp:43] Iteration 59000, lr = 0.0002
I0526 14:11:38.159932 15394 main.cpp:354] Iteration 59010, loss = 0.156352
I0526 14:11:38.159970 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.156352 (* 1 = 0.156352 loss)
I0526 14:11:38.159976 15394 sgd_solver.cpp:43] Iteration 59010, lr = 0.0002
I0526 14:11:43.591612 15394 main.cpp:354] Iteration 59020, loss = 0.209577
I0526 14:11:43.591647 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.209576 (* 1 = 0.209576 loss)
I0526 14:11:43.591653 15394 sgd_solver.cpp:43] Iteration 59020, lr = 0.0002
I0526 14:11:48.873219 15394 main.cpp:354] Iteration 59030, loss = 0.209592
I0526 14:11:48.873255 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.209591 (* 1 = 0.209591 loss)
I0526 14:11:48.873262 15394 sgd_solver.cpp:43] Iteration 59030, lr = 0.0002
I0526 14:11:54.034018 15394 main.cpp:354] Iteration 59040, loss = 0.221294
I0526 14:11:54.034060 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.221294 (* 1 = 0.221294 loss)
I0526 14:11:54.034066 15394 sgd_solver.cpp:43] Iteration 59040, lr = 0.0002
I0526 14:11:59.199705 15394 main.cpp:354] Iteration 59050, loss = 0.124338
I0526 14:11:59.199741 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.124337 (* 1 = 0.124337 loss)
I0526 14:11:59.199748 15394 sgd_solver.cpp:43] Iteration 59050, lr = 0.0002
I0526 14:12:04.285995 15394 main.cpp:354] Iteration 59060, loss = 0.185732
I0526 14:12:04.286032 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.185731 (* 1 = 0.185731 loss)
I0526 14:12:04.286039 15394 sgd_solver.cpp:43] Iteration 59060, lr = 0.0002
I0526 14:12:09.410969 15394 main.cpp:354] Iteration 59070, loss = 0.522928
I0526 14:12:09.411005 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.522928 (* 1 = 0.522928 loss)
I0526 14:12:09.411011 15394 sgd_solver.cpp:43] Iteration 59070, lr = 0.0002
I0526 14:12:14.300155 15394 main.cpp:354] Iteration 59080, loss = 0.132703
I0526 14:12:14.300189 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.132702 (* 1 = 0.132702 loss)
I0526 14:12:14.300195 15394 sgd_solver.cpp:43] Iteration 59080, lr = 0.0002
I0526 14:12:19.379027 15394 main.cpp:354] Iteration 59090, loss = 0.152664
I0526 14:12:19.379065 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.152663 (* 1 = 0.152663 loss)
I0526 14:12:19.379073 15394 sgd_solver.cpp:43] Iteration 59090, lr = 0.0002
I0526 14:12:24.271574 15394 main.cpp:465] Iteration 59100, Testing net (#0)
I0526 14:12:37.365886 15394 main.cpp:532]     Test net output #0: Accuracy = 0.898
I0526 14:12:37.365928 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.324899 (* 1 = 0.324899 loss)
I0526 14:12:37.699494 15394 main.cpp:354] Iteration 59100, loss = 0.308618
I0526 14:12:37.699520 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.308617 (* 1 = 0.308617 loss)
I0526 14:12:37.699528 15394 sgd_solver.cpp:43] Iteration 59100, lr = 0.0002
I0526 14:12:42.880787 15394 main.cpp:354] Iteration 59110, loss = 0.0864358
I0526 14:12:42.880823 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0864352 (* 1 = 0.0864352 loss)
I0526 14:12:42.880830 15394 sgd_solver.cpp:43] Iteration 59110, lr = 0.0002
I0526 14:12:48.118516 15394 main.cpp:354] Iteration 59120, loss = 0.275914
I0526 14:12:48.118554 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.275913 (* 1 = 0.275913 loss)
I0526 14:12:48.118566 15394 sgd_solver.cpp:43] Iteration 59120, lr = 0.0002
I0526 14:12:53.282047 15394 main.cpp:354] Iteration 59130, loss = 0.264587
I0526 14:12:53.282084 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.264587 (* 1 = 0.264587 loss)
I0526 14:12:53.282090 15394 sgd_solver.cpp:43] Iteration 59130, lr = 0.0002
I0526 14:12:58.760867 15394 main.cpp:354] Iteration 59140, loss = 0.220087
I0526 14:12:58.760906 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.220087 (* 1 = 0.220087 loss)
I0526 14:12:58.760912 15394 sgd_solver.cpp:43] Iteration 59140, lr = 0.0002
I0526 14:13:04.062000 15394 main.cpp:354] Iteration 59150, loss = 0.275507
I0526 14:13:04.062041 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.275506 (* 1 = 0.275506 loss)
I0526 14:13:04.062048 15394 sgd_solver.cpp:43] Iteration 59150, lr = 0.0002
I0526 14:13:09.072824 15394 main.cpp:354] Iteration 59160, loss = 0.389645
I0526 14:13:09.072859 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.389644 (* 1 = 0.389644 loss)
I0526 14:13:09.072865 15394 sgd_solver.cpp:43] Iteration 59160, lr = 0.0002
I0526 14:13:13.796200 15394 main.cpp:354] Iteration 59170, loss = 0.119067
I0526 14:13:13.796233 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.119067 (* 1 = 0.119067 loss)
I0526 14:13:13.796239 15394 sgd_solver.cpp:43] Iteration 59170, lr = 0.0002
I0526 14:13:18.823690 15394 main.cpp:354] Iteration 59180, loss = 0.135241
I0526 14:13:18.823724 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.135241 (* 1 = 0.135241 loss)
I0526 14:13:18.823730 15394 sgd_solver.cpp:43] Iteration 59180, lr = 0.0002
I0526 14:13:23.748522 15394 main.cpp:354] Iteration 59190, loss = 0.228853
I0526 14:13:23.748561 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.228852 (* 1 = 0.228852 loss)
I0526 14:13:23.748566 15394 sgd_solver.cpp:43] Iteration 59190, lr = 0.0002
I0526 14:13:28.361521 15394 main.cpp:465] Iteration 59200, Testing net (#0)
I0526 14:13:41.460135 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8973
I0526 14:13:41.460172 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.332584 (* 1 = 0.332584 loss)
I0526 14:13:41.998759 15394 main.cpp:354] Iteration 59200, loss = 0.0946909
I0526 14:13:41.998781 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0946903 (* 1 = 0.0946903 loss)
I0526 14:13:41.998790 15394 sgd_solver.cpp:43] Iteration 59200, lr = 0.0002
I0526 14:13:46.675312 15394 main.cpp:354] Iteration 59210, loss = 0.278009
I0526 14:13:46.675348 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.278009 (* 1 = 0.278009 loss)
I0526 14:13:46.675354 15394 sgd_solver.cpp:43] Iteration 59210, lr = 0.0002
I0526 14:13:51.052278 15394 main.cpp:354] Iteration 59220, loss = 0.192971
I0526 14:13:51.052317 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.192971 (* 1 = 0.192971 loss)
I0526 14:13:51.052323 15394 sgd_solver.cpp:43] Iteration 59220, lr = 0.0002
I0526 14:13:55.898793 15394 main.cpp:354] Iteration 59230, loss = 0.0890726
I0526 14:13:55.898829 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.089072 (* 1 = 0.089072 loss)
I0526 14:13:55.898835 15394 sgd_solver.cpp:43] Iteration 59230, lr = 0.0002
I0526 14:14:01.358278 15394 main.cpp:354] Iteration 59240, loss = 0.225063
I0526 14:14:01.358314 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.225062 (* 1 = 0.225062 loss)
I0526 14:14:01.358319 15394 sgd_solver.cpp:43] Iteration 59240, lr = 0.0002
I0526 14:14:06.394842 15394 main.cpp:354] Iteration 59250, loss = 0.155778
I0526 14:14:06.394884 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.155777 (* 1 = 0.155777 loss)
I0526 14:14:06.394891 15394 sgd_solver.cpp:43] Iteration 59250, lr = 0.0002
I0526 14:14:11.245277 15394 main.cpp:354] Iteration 59260, loss = 0.144325
I0526 14:14:11.245314 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.144325 (* 1 = 0.144325 loss)
I0526 14:14:11.245326 15394 sgd_solver.cpp:43] Iteration 59260, lr = 0.0002
I0526 14:14:16.142647 15394 main.cpp:354] Iteration 59270, loss = 0.104599
I0526 14:14:16.142707 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.104599 (* 1 = 0.104599 loss)
I0526 14:14:16.142714 15394 sgd_solver.cpp:43] Iteration 59270, lr = 0.0002
I0526 14:14:21.220809 15394 main.cpp:354] Iteration 59280, loss = 0.234958
I0526 14:14:21.220847 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.234957 (* 1 = 0.234957 loss)
I0526 14:14:21.220854 15394 sgd_solver.cpp:43] Iteration 59280, lr = 0.0002
I0526 14:14:26.475148 15394 main.cpp:354] Iteration 59290, loss = 0.333251
I0526 14:14:26.475184 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.33325 (* 1 = 0.33325 loss)
I0526 14:14:26.475190 15394 sgd_solver.cpp:43] Iteration 59290, lr = 0.0002
I0526 14:14:30.830476 15394 main.cpp:465] Iteration 59300, Testing net (#0)
I0526 14:14:43.937669 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8959
I0526 14:14:43.937706 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.32526 (* 1 = 0.32526 loss)
I0526 14:14:44.445427 15394 main.cpp:354] Iteration 59300, loss = 0.181688
I0526 14:14:44.445474 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.181688 (* 1 = 0.181688 loss)
I0526 14:14:44.445482 15394 sgd_solver.cpp:43] Iteration 59300, lr = 0.0002
I0526 14:14:49.292352 15394 main.cpp:354] Iteration 59310, loss = 0.37367
I0526 14:14:49.292392 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.373669 (* 1 = 0.373669 loss)
I0526 14:14:49.292400 15394 sgd_solver.cpp:43] Iteration 59310, lr = 0.0002
I0526 14:14:54.064749 15394 main.cpp:354] Iteration 59320, loss = 0.190693
I0526 14:14:54.064781 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.190693 (* 1 = 0.190693 loss)
I0526 14:14:54.064787 15394 sgd_solver.cpp:43] Iteration 59320, lr = 0.0002
I0526 14:14:59.396850 15394 main.cpp:354] Iteration 59330, loss = 0.191018
I0526 14:14:59.396888 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.191017 (* 1 = 0.191017 loss)
I0526 14:14:59.396893 15394 sgd_solver.cpp:43] Iteration 59330, lr = 0.0002
I0526 14:15:04.532138 15394 main.cpp:354] Iteration 59340, loss = 0.187694
I0526 14:15:04.532176 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187694 (* 1 = 0.187694 loss)
I0526 14:15:04.532182 15394 sgd_solver.cpp:43] Iteration 59340, lr = 0.0002
I0526 14:15:09.587577 15394 main.cpp:354] Iteration 59350, loss = 0.118041
I0526 14:15:09.587612 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.11804 (* 1 = 0.11804 loss)
I0526 14:15:09.587618 15394 sgd_solver.cpp:43] Iteration 59350, lr = 0.0002
I0526 14:15:14.678918 15394 main.cpp:354] Iteration 59360, loss = 0.160045
I0526 14:15:14.678956 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.160045 (* 1 = 0.160045 loss)
I0526 14:15:14.678961 15394 sgd_solver.cpp:43] Iteration 59360, lr = 0.0002
I0526 14:15:19.935097 15394 main.cpp:354] Iteration 59370, loss = 0.40623
I0526 14:15:19.935137 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.40623 (* 1 = 0.40623 loss)
I0526 14:15:19.935142 15394 sgd_solver.cpp:43] Iteration 59370, lr = 0.0002
I0526 14:15:25.056646 15394 main.cpp:354] Iteration 59380, loss = 0.570535
I0526 14:15:25.056684 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.570534 (* 1 = 0.570534 loss)
I0526 14:15:25.056689 15394 sgd_solver.cpp:43] Iteration 59380, lr = 0.0002
I0526 14:15:30.556718 15394 main.cpp:354] Iteration 59390, loss = 0.130866
I0526 14:15:30.556754 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.130866 (* 1 = 0.130866 loss)
I0526 14:15:30.556761 15394 sgd_solver.cpp:43] Iteration 59390, lr = 0.0002
I0526 14:15:34.974463 15394 main.cpp:465] Iteration 59400, Testing net (#0)
I0526 14:15:48.071089 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8962
I0526 14:15:48.071127 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.3303 (* 1 = 0.3303 loss)
I0526 14:15:48.647353 15394 main.cpp:354] Iteration 59400, loss = 0.0723252
I0526 14:15:48.647387 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0723246 (* 1 = 0.0723246 loss)
I0526 14:15:48.647392 15394 sgd_solver.cpp:43] Iteration 59400, lr = 0.0002
I0526 14:15:53.594607 15394 main.cpp:354] Iteration 59410, loss = 0.375081
I0526 14:15:53.594653 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.37508 (* 1 = 0.37508 loss)
I0526 14:15:53.594660 15394 sgd_solver.cpp:43] Iteration 59410, lr = 0.0002
I0526 14:15:58.819164 15394 main.cpp:354] Iteration 59420, loss = 0.148301
I0526 14:15:58.819200 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.148301 (* 1 = 0.148301 loss)
I0526 14:15:58.819206 15394 sgd_solver.cpp:43] Iteration 59420, lr = 0.0002
I0526 14:16:04.135102 15394 main.cpp:354] Iteration 59430, loss = 0.34956
I0526 14:16:04.135139 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.349559 (* 1 = 0.349559 loss)
I0526 14:16:04.135146 15394 sgd_solver.cpp:43] Iteration 59430, lr = 0.0002
I0526 14:16:09.097321 15394 main.cpp:354] Iteration 59440, loss = 0.128065
I0526 14:16:09.097354 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.128065 (* 1 = 0.128065 loss)
I0526 14:16:09.097362 15394 sgd_solver.cpp:43] Iteration 59440, lr = 0.0002
I0526 14:16:14.576210 15394 main.cpp:354] Iteration 59450, loss = 0.29525
I0526 14:16:14.576256 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.295249 (* 1 = 0.295249 loss)
I0526 14:16:14.576263 15394 sgd_solver.cpp:43] Iteration 59450, lr = 0.0002
I0526 14:16:20.059622 15394 main.cpp:354] Iteration 59460, loss = 0.104717
I0526 14:16:20.059659 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.104716 (* 1 = 0.104716 loss)
I0526 14:16:20.059666 15394 sgd_solver.cpp:43] Iteration 59460, lr = 0.0002
I0526 14:16:24.171818 15394 main.cpp:354] Iteration 59470, loss = 0.306423
I0526 14:16:24.171855 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.306422 (* 1 = 0.306422 loss)
I0526 14:16:24.171861 15394 sgd_solver.cpp:43] Iteration 59470, lr = 0.0002
I0526 14:16:29.286563 15394 main.cpp:354] Iteration 59480, loss = 0.250575
I0526 14:16:29.286599 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.250575 (* 1 = 0.250575 loss)
I0526 14:16:29.286607 15394 sgd_solver.cpp:43] Iteration 59480, lr = 0.0002
I0526 14:16:34.016834 15394 main.cpp:354] Iteration 59490, loss = 0.715241
I0526 14:16:34.016872 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.71524 (* 1 = 0.71524 loss)
I0526 14:16:34.016880 15394 sgd_solver.cpp:43] Iteration 59490, lr = 0.0002
I0526 14:16:38.289132 15394 main.cpp:465] Iteration 59500, Testing net (#0)
I0526 14:16:51.425679 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8938
I0526 14:16:51.425720 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.331447 (* 1 = 0.331447 loss)
I0526 14:16:51.931766 15394 main.cpp:354] Iteration 59500, loss = 0.202059
I0526 14:16:51.931798 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.202058 (* 1 = 0.202058 loss)
I0526 14:16:51.931807 15394 sgd_solver.cpp:43] Iteration 59500, lr = 0.0002
I0526 14:16:57.329794 15394 main.cpp:354] Iteration 59510, loss = 0.187131
I0526 14:16:57.329843 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.18713 (* 1 = 0.18713 loss)
I0526 14:16:57.329852 15394 sgd_solver.cpp:43] Iteration 59510, lr = 0.0002
I0526 14:17:02.514724 15394 main.cpp:354] Iteration 59520, loss = 0.238042
I0526 14:17:02.514760 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.238042 (* 1 = 0.238042 loss)
I0526 14:17:02.514765 15394 sgd_solver.cpp:43] Iteration 59520, lr = 0.0002
I0526 14:17:07.312083 15394 main.cpp:354] Iteration 59530, loss = 0.396851
I0526 14:17:07.312122 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.39685 (* 1 = 0.39685 loss)
I0526 14:17:07.312129 15394 sgd_solver.cpp:43] Iteration 59530, lr = 0.0002
I0526 14:17:12.253646 15394 main.cpp:354] Iteration 59540, loss = 0.274592
I0526 14:17:12.253686 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.274592 (* 1 = 0.274592 loss)
I0526 14:17:12.253692 15394 sgd_solver.cpp:43] Iteration 59540, lr = 0.0002
I0526 14:17:17.356729 15394 main.cpp:354] Iteration 59550, loss = 0.325849
I0526 14:17:17.356765 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.325849 (* 1 = 0.325849 loss)
I0526 14:17:17.356772 15394 sgd_solver.cpp:43] Iteration 59550, lr = 0.0002
I0526 14:17:21.837249 15394 main.cpp:354] Iteration 59560, loss = 0.321706
I0526 14:17:21.837287 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.321706 (* 1 = 0.321706 loss)
I0526 14:17:21.837293 15394 sgd_solver.cpp:43] Iteration 59560, lr = 0.0002
I0526 14:17:26.699189 15394 main.cpp:354] Iteration 59570, loss = 0.132467
I0526 14:17:26.699225 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.132466 (* 1 = 0.132466 loss)
I0526 14:17:26.699232 15394 sgd_solver.cpp:43] Iteration 59570, lr = 0.0002
I0526 14:17:31.873492 15394 main.cpp:354] Iteration 59580, loss = 0.242264
I0526 14:17:31.873528 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.242264 (* 1 = 0.242264 loss)
I0526 14:17:31.873534 15394 sgd_solver.cpp:43] Iteration 59580, lr = 0.0002
I0526 14:17:36.941364 15394 main.cpp:354] Iteration 59590, loss = 0.160967
I0526 14:17:36.941401 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.160966 (* 1 = 0.160966 loss)
I0526 14:17:36.941406 15394 sgd_solver.cpp:43] Iteration 59590, lr = 0.0002
I0526 14:17:41.243839 15394 main.cpp:465] Iteration 59600, Testing net (#0)
I0526 14:17:54.343188 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8945
I0526 14:17:54.343227 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.330512 (* 1 = 0.330512 loss)
I0526 14:17:54.852385 15394 main.cpp:354] Iteration 59600, loss = 0.0945358
I0526 14:17:54.852440 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0945352 (* 1 = 0.0945352 loss)
I0526 14:17:54.852450 15394 sgd_solver.cpp:43] Iteration 59600, lr = 0.0002
I0526 14:17:59.912434 15394 main.cpp:354] Iteration 59610, loss = 0.331213
I0526 14:17:59.912472 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.331212 (* 1 = 0.331212 loss)
I0526 14:17:59.912480 15394 sgd_solver.cpp:43] Iteration 59610, lr = 0.0002
I0526 14:18:05.045979 15394 main.cpp:354] Iteration 59620, loss = 0.273626
I0526 14:18:05.046033 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.273626 (* 1 = 0.273626 loss)
I0526 14:18:05.046041 15394 sgd_solver.cpp:43] Iteration 59620, lr = 0.0002
I0526 14:18:09.650660 15394 main.cpp:354] Iteration 59630, loss = 0.347063
I0526 14:18:09.650694 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.347063 (* 1 = 0.347063 loss)
I0526 14:18:09.650701 15394 sgd_solver.cpp:43] Iteration 59630, lr = 0.0002
I0526 14:18:14.851243 15394 main.cpp:354] Iteration 59640, loss = 0.232411
I0526 14:18:14.851279 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.23241 (* 1 = 0.23241 loss)
I0526 14:18:14.851285 15394 sgd_solver.cpp:43] Iteration 59640, lr = 0.0002
I0526 14:18:19.484320 15394 main.cpp:354] Iteration 59650, loss = 0.253366
I0526 14:18:19.484360 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.253366 (* 1 = 0.253366 loss)
I0526 14:18:19.484366 15394 sgd_solver.cpp:43] Iteration 59650, lr = 0.0002
I0526 14:18:24.140594 15394 main.cpp:354] Iteration 59660, loss = 0.324041
I0526 14:18:24.140628 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.324041 (* 1 = 0.324041 loss)
I0526 14:18:24.140635 15394 sgd_solver.cpp:43] Iteration 59660, lr = 0.0002
I0526 14:18:29.373296 15394 main.cpp:354] Iteration 59670, loss = 0.28246
I0526 14:18:29.373332 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.28246 (* 1 = 0.28246 loss)
I0526 14:18:29.373337 15394 sgd_solver.cpp:43] Iteration 59670, lr = 0.0002
I0526 14:18:34.272814 15394 main.cpp:354] Iteration 59680, loss = 0.304092
I0526 14:18:34.272850 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.304091 (* 1 = 0.304091 loss)
I0526 14:18:34.272862 15394 sgd_solver.cpp:43] Iteration 59680, lr = 0.0002
I0526 14:18:39.566185 15394 main.cpp:354] Iteration 59690, loss = 0.158951
I0526 14:18:39.566223 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.158951 (* 1 = 0.158951 loss)
I0526 14:18:39.566229 15394 sgd_solver.cpp:43] Iteration 59690, lr = 0.0002
I0526 14:18:44.527597 15394 main.cpp:465] Iteration 59700, Testing net (#0)
I0526 14:18:57.622174 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8962
I0526 14:18:57.622212 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.332295 (* 1 = 0.332295 loss)
I0526 14:18:58.093809 15394 main.cpp:354] Iteration 59700, loss = 0.26728
I0526 14:18:58.093842 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.267279 (* 1 = 0.267279 loss)
I0526 14:18:58.093850 15394 sgd_solver.cpp:43] Iteration 59700, lr = 0.0002
I0526 14:19:03.311563 15394 main.cpp:354] Iteration 59710, loss = 0.303393
I0526 14:19:03.311599 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.303392 (* 1 = 0.303392 loss)
I0526 14:19:03.311605 15394 sgd_solver.cpp:43] Iteration 59710, lr = 0.0002
I0526 14:19:08.786860 15394 main.cpp:354] Iteration 59720, loss = 0.291235
I0526 14:19:08.786900 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.291234 (* 1 = 0.291234 loss)
I0526 14:19:08.786906 15394 sgd_solver.cpp:43] Iteration 59720, lr = 0.0002
I0526 14:19:13.809646 15394 main.cpp:354] Iteration 59730, loss = 0.14117
I0526 14:19:13.809685 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.141169 (* 1 = 0.141169 loss)
I0526 14:19:13.809691 15394 sgd_solver.cpp:43] Iteration 59730, lr = 0.0002
I0526 14:19:18.757212 15394 main.cpp:354] Iteration 59740, loss = 0.0626718
I0526 14:19:18.757247 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0626712 (* 1 = 0.0626712 loss)
I0526 14:19:18.757253 15394 sgd_solver.cpp:43] Iteration 59740, lr = 0.0002
I0526 14:19:23.782423 15394 main.cpp:354] Iteration 59750, loss = 0.306383
I0526 14:19:23.782461 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.306382 (* 1 = 0.306382 loss)
I0526 14:19:23.782467 15394 sgd_solver.cpp:43] Iteration 59750, lr = 0.0002
I0526 14:19:28.648458 15394 main.cpp:354] Iteration 59760, loss = 0.398209
I0526 14:19:28.648494 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.398208 (* 1 = 0.398208 loss)
I0526 14:19:28.648499 15394 sgd_solver.cpp:43] Iteration 59760, lr = 0.0002
I0526 14:19:33.894906 15394 main.cpp:354] Iteration 59770, loss = 0.443768
I0526 14:19:33.894940 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.443768 (* 1 = 0.443768 loss)
I0526 14:19:33.894947 15394 sgd_solver.cpp:43] Iteration 59770, lr = 0.0002
I0526 14:19:38.979555 15394 main.cpp:354] Iteration 59780, loss = 0.36665
I0526 14:19:38.979590 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.36665 (* 1 = 0.36665 loss)
I0526 14:19:38.979598 15394 sgd_solver.cpp:43] Iteration 59780, lr = 0.0002
I0526 14:19:44.452208 15394 main.cpp:354] Iteration 59790, loss = 0.121365
I0526 14:19:44.452246 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.121364 (* 1 = 0.121364 loss)
I0526 14:19:44.452252 15394 sgd_solver.cpp:43] Iteration 59790, lr = 0.0002
I0526 14:19:48.854130 15394 main.cpp:465] Iteration 59800, Testing net (#0)
I0526 14:20:01.948331 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8933
I0526 14:20:01.948369 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.33607 (* 1 = 0.33607 loss)
I0526 14:20:02.422118 15394 main.cpp:354] Iteration 59800, loss = 0.202101
I0526 14:20:02.422149 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.2021 (* 1 = 0.2021 loss)
I0526 14:20:02.422157 15394 sgd_solver.cpp:43] Iteration 59800, lr = 0.0002
I0526 14:20:07.547722 15394 main.cpp:354] Iteration 59810, loss = 0.159766
I0526 14:20:07.547763 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.159766 (* 1 = 0.159766 loss)
I0526 14:20:07.547775 15394 sgd_solver.cpp:43] Iteration 59810, lr = 0.0002
I0526 14:20:12.414587 15394 main.cpp:354] Iteration 59820, loss = 0.125633
I0526 14:20:12.414620 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.125632 (* 1 = 0.125632 loss)
I0526 14:20:12.414628 15394 sgd_solver.cpp:43] Iteration 59820, lr = 0.0002
I0526 14:20:17.143040 15394 main.cpp:354] Iteration 59830, loss = 0.321062
I0526 14:20:17.143077 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.321062 (* 1 = 0.321062 loss)
I0526 14:20:17.143085 15394 sgd_solver.cpp:43] Iteration 59830, lr = 0.0002
I0526 14:20:21.820937 15394 main.cpp:354] Iteration 59840, loss = 0.270437
I0526 14:20:21.820976 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.270437 (* 1 = 0.270437 loss)
I0526 14:20:21.820982 15394 sgd_solver.cpp:43] Iteration 59840, lr = 0.0002
I0526 14:20:27.205309 15394 main.cpp:354] Iteration 59850, loss = 0.0949309
I0526 14:20:27.205343 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0949303 (* 1 = 0.0949303 loss)
I0526 14:20:27.205349 15394 sgd_solver.cpp:43] Iteration 59850, lr = 0.0002
I0526 14:20:32.433624 15394 main.cpp:354] Iteration 59860, loss = 0.135731
I0526 14:20:32.433657 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.135731 (* 1 = 0.135731 loss)
I0526 14:20:32.433665 15394 sgd_solver.cpp:43] Iteration 59860, lr = 0.0002
I0526 14:20:37.443498 15394 main.cpp:354] Iteration 59870, loss = 0.151396
I0526 14:20:37.443536 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.151396 (* 1 = 0.151396 loss)
I0526 14:20:37.443542 15394 sgd_solver.cpp:43] Iteration 59870, lr = 0.0002
I0526 14:20:41.918774 15394 main.cpp:354] Iteration 59880, loss = 0.207641
I0526 14:20:41.918810 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.20764 (* 1 = 0.20764 loss)
I0526 14:20:41.918817 15394 sgd_solver.cpp:43] Iteration 59880, lr = 0.0002
I0526 14:20:46.814168 15394 main.cpp:354] Iteration 59890, loss = 0.526529
I0526 14:20:46.814203 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.526529 (* 1 = 0.526529 loss)
I0526 14:20:46.814209 15394 sgd_solver.cpp:43] Iteration 59890, lr = 0.0002
I0526 14:20:51.315860 15394 main.cpp:465] Iteration 59900, Testing net (#0)
I0526 14:21:04.412663 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8944
I0526 14:21:04.412700 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.334688 (* 1 = 0.334688 loss)
I0526 14:21:04.878407 15394 main.cpp:354] Iteration 59900, loss = 0.379751
I0526 14:21:04.878443 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.379751 (* 1 = 0.379751 loss)
I0526 14:21:04.878450 15394 sgd_solver.cpp:43] Iteration 59900, lr = 0.0002
I0526 14:21:10.144984 15394 main.cpp:354] Iteration 59910, loss = 0.265755
I0526 14:21:10.145028 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.265755 (* 1 = 0.265755 loss)
I0526 14:21:10.145035 15394 sgd_solver.cpp:43] Iteration 59910, lr = 0.0002
I0526 14:21:14.903156 15394 main.cpp:354] Iteration 59920, loss = 0.200447
I0526 14:21:14.903192 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.200447 (* 1 = 0.200447 loss)
I0526 14:21:14.903198 15394 sgd_solver.cpp:43] Iteration 59920, lr = 0.0002
I0526 14:21:20.074926 15394 main.cpp:354] Iteration 59930, loss = 0.178496
I0526 14:21:20.074966 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.178495 (* 1 = 0.178495 loss)
I0526 14:21:20.074972 15394 sgd_solver.cpp:43] Iteration 59930, lr = 0.0002
I0526 14:21:25.098127 15394 main.cpp:354] Iteration 59940, loss = 0.248898
I0526 14:21:25.098165 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.248898 (* 1 = 0.248898 loss)
I0526 14:21:25.098171 15394 sgd_solver.cpp:43] Iteration 59940, lr = 0.0002
I0526 14:21:30.185623 15394 main.cpp:354] Iteration 59950, loss = 0.139317
I0526 14:21:30.185658 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.139316 (* 1 = 0.139316 loss)
I0526 14:21:30.185664 15394 sgd_solver.cpp:43] Iteration 59950, lr = 0.0002
I0526 14:21:35.399435 15394 main.cpp:354] Iteration 59960, loss = 0.127511
I0526 14:21:35.399473 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.127511 (* 1 = 0.127511 loss)
I0526 14:21:35.399479 15394 sgd_solver.cpp:43] Iteration 59960, lr = 0.0002
I0526 14:21:40.475396 15394 main.cpp:354] Iteration 59970, loss = 0.189838
I0526 14:21:40.475430 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.189838 (* 1 = 0.189838 loss)
I0526 14:21:40.475436 15394 sgd_solver.cpp:43] Iteration 59970, lr = 0.0002
I0526 14:21:45.339570 15394 main.cpp:354] Iteration 59980, loss = 0.182787
I0526 14:21:45.339604 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.182787 (* 1 = 0.182787 loss)
I0526 14:21:45.339610 15394 sgd_solver.cpp:43] Iteration 59980, lr = 0.0002
I0526 14:21:50.202294 15394 main.cpp:354] Iteration 59990, loss = 0.280213
I0526 14:21:50.202332 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.280212 (* 1 = 0.280212 loss)
I0526 14:21:50.202337 15394 sgd_solver.cpp:43] Iteration 59990, lr = 0.0002
I0526 14:21:54.650387 15394 main.cpp:465] Iteration 60000, Testing net (#0)
I0526 14:22:07.751631 15394 main.cpp:532]     Test net output #0: Accuracy = 0.897
I0526 14:22:07.751670 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.328255 (* 1 = 0.328255 loss)
I0526 14:22:08.054603 15394 main.cpp:354] Iteration 60000, loss = 0.552642
I0526 14:22:08.054639 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.552641 (* 1 = 0.552641 loss)
I0526 14:22:08.054647 15394 sgd_solver.cpp:43] Iteration 60000, lr = 0.0002
I0526 14:22:13.521013 15394 main.cpp:354] Iteration 60010, loss = 0.182617
I0526 14:22:13.521047 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.182616 (* 1 = 0.182616 loss)
I0526 14:22:13.521052 15394 sgd_solver.cpp:43] Iteration 60010, lr = 0.0002
I0526 14:22:18.901795 15394 main.cpp:354] Iteration 60020, loss = 0.406328
I0526 14:22:18.901831 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.406328 (* 1 = 0.406328 loss)
I0526 14:22:18.901837 15394 sgd_solver.cpp:43] Iteration 60020, lr = 0.0002
I0526 14:22:23.988802 15394 main.cpp:354] Iteration 60030, loss = 0.648499
I0526 14:22:23.988842 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.648498 (* 1 = 0.648498 loss)
I0526 14:22:23.988849 15394 sgd_solver.cpp:43] Iteration 60030, lr = 0.0002
I0526 14:22:29.276093 15394 main.cpp:354] Iteration 60040, loss = 0.102825
I0526 14:22:29.276129 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.102825 (* 1 = 0.102825 loss)
I0526 14:22:29.276134 15394 sgd_solver.cpp:43] Iteration 60040, lr = 0.0002
I0526 14:22:34.444777 15394 main.cpp:354] Iteration 60050, loss = 0.225231
I0526 14:22:34.444824 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.225231 (* 1 = 0.225231 loss)
I0526 14:22:34.444833 15394 sgd_solver.cpp:43] Iteration 60050, lr = 0.0002
I0526 14:22:39.600301 15394 main.cpp:354] Iteration 60060, loss = 0.13059
I0526 14:22:39.600340 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.130589 (* 1 = 0.130589 loss)
I0526 14:22:39.600347 15394 sgd_solver.cpp:43] Iteration 60060, lr = 0.0002
I0526 14:22:44.718206 15394 main.cpp:354] Iteration 60070, loss = 0.173882
I0526 14:22:44.718242 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.173881 (* 1 = 0.173881 loss)
I0526 14:22:44.718248 15394 sgd_solver.cpp:43] Iteration 60070, lr = 0.0002
I0526 14:22:49.912297 15394 main.cpp:354] Iteration 60080, loss = 0.17066
I0526 14:22:49.912333 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.17066 (* 1 = 0.17066 loss)
I0526 14:22:49.912338 15394 sgd_solver.cpp:43] Iteration 60080, lr = 0.0002
I0526 14:22:54.638064 15394 main.cpp:354] Iteration 60090, loss = 0.32026
I0526 14:22:54.638098 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.320259 (* 1 = 0.320259 loss)
I0526 14:22:54.638104 15394 sgd_solver.cpp:43] Iteration 60090, lr = 0.0002
I0526 14:22:59.246071 15394 main.cpp:465] Iteration 60100, Testing net (#0)
I0526 14:23:12.352470 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8942
I0526 14:23:12.352512 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.331394 (* 1 = 0.331394 loss)
I0526 14:23:12.824049 15394 main.cpp:354] Iteration 60100, loss = 0.174703
I0526 14:23:12.824086 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.174703 (* 1 = 0.174703 loss)
I0526 14:23:12.824095 15394 sgd_solver.cpp:43] Iteration 60100, lr = 0.0002
I0526 14:23:18.123497 15394 main.cpp:354] Iteration 60110, loss = 0.277068
I0526 14:23:18.123531 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.277068 (* 1 = 0.277068 loss)
I0526 14:23:18.123538 15394 sgd_solver.cpp:43] Iteration 60110, lr = 0.0002
I0526 14:23:22.680817 15394 main.cpp:354] Iteration 60120, loss = 0.229808
I0526 14:23:22.680855 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.229807 (* 1 = 0.229807 loss)
I0526 14:23:22.680861 15394 sgd_solver.cpp:43] Iteration 60120, lr = 0.0002
I0526 14:23:27.266970 15394 main.cpp:354] Iteration 60130, loss = 0.240566
I0526 14:23:27.267009 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.240565 (* 1 = 0.240565 loss)
I0526 14:23:27.267025 15394 sgd_solver.cpp:43] Iteration 60130, lr = 0.0002
I0526 14:23:32.513844 15394 main.cpp:354] Iteration 60140, loss = 0.161687
I0526 14:23:32.513881 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.161686 (* 1 = 0.161686 loss)
I0526 14:23:32.513886 15394 sgd_solver.cpp:43] Iteration 60140, lr = 0.0002
I0526 14:23:36.843829 15394 main.cpp:354] Iteration 60150, loss = 0.107375
I0526 14:23:36.843869 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.107374 (* 1 = 0.107374 loss)
I0526 14:23:36.843876 15394 sgd_solver.cpp:43] Iteration 60150, lr = 0.0002
I0526 14:23:41.997980 15394 main.cpp:354] Iteration 60160, loss = 0.113377
I0526 14:23:41.998015 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.113376 (* 1 = 0.113376 loss)
I0526 14:23:41.998023 15394 sgd_solver.cpp:43] Iteration 60160, lr = 0.0002
I0526 14:23:47.077517 15394 main.cpp:354] Iteration 60170, loss = 0.273413
I0526 14:23:47.077553 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.273412 (* 1 = 0.273412 loss)
I0526 14:23:47.077559 15394 sgd_solver.cpp:43] Iteration 60170, lr = 0.0002
I0526 14:23:51.740533 15394 main.cpp:354] Iteration 60180, loss = 0.235073
I0526 14:23:51.740571 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235072 (* 1 = 0.235072 loss)
I0526 14:23:51.740577 15394 sgd_solver.cpp:43] Iteration 60180, lr = 0.0002
I0526 14:23:56.799803 15394 main.cpp:354] Iteration 60190, loss = 0.193398
I0526 14:23:56.799835 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.193397 (* 1 = 0.193397 loss)
I0526 14:23:56.799841 15394 sgd_solver.cpp:43] Iteration 60190, lr = 0.0002
I0526 14:24:01.351995 15394 main.cpp:465] Iteration 60200, Testing net (#0)
I0526 14:24:14.454105 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8959
I0526 14:24:14.454141 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.334424 (* 1 = 0.334424 loss)
I0526 14:24:14.957437 15394 main.cpp:354] Iteration 60200, loss = 0.112927
I0526 14:24:14.957468 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.112926 (* 1 = 0.112926 loss)
I0526 14:24:14.957476 15394 sgd_solver.cpp:43] Iteration 60200, lr = 0.0002
I0526 14:24:19.859256 15394 main.cpp:354] Iteration 60210, loss = 0.174684
I0526 14:24:19.859298 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.174683 (* 1 = 0.174683 loss)
I0526 14:24:19.859304 15394 sgd_solver.cpp:43] Iteration 60210, lr = 0.0002
I0526 14:24:25.257387 15394 main.cpp:354] Iteration 60220, loss = 0.159808
I0526 14:24:25.257421 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.159807 (* 1 = 0.159807 loss)
I0526 14:24:25.257427 15394 sgd_solver.cpp:43] Iteration 60220, lr = 0.0002
I0526 14:24:30.129540 15394 main.cpp:354] Iteration 60230, loss = 0.153443
I0526 14:24:30.129578 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.153442 (* 1 = 0.153442 loss)
I0526 14:24:30.129590 15394 sgd_solver.cpp:43] Iteration 60230, lr = 0.0002
I0526 14:24:35.355916 15394 main.cpp:354] Iteration 60240, loss = 0.189689
I0526 14:24:35.355955 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.189689 (* 1 = 0.189689 loss)
I0526 14:24:35.355962 15394 sgd_solver.cpp:43] Iteration 60240, lr = 0.0002
I0526 14:24:40.264832 15394 main.cpp:354] Iteration 60250, loss = 0.20502
I0526 14:24:40.264868 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.205019 (* 1 = 0.205019 loss)
I0526 14:24:40.264873 15394 sgd_solver.cpp:43] Iteration 60250, lr = 0.0002
I0526 14:24:45.488663 15394 main.cpp:354] Iteration 60260, loss = 0.176441
I0526 14:24:45.488698 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.17644 (* 1 = 0.17644 loss)
I0526 14:24:45.488705 15394 sgd_solver.cpp:43] Iteration 60260, lr = 0.0002
I0526 14:24:50.406429 15394 main.cpp:354] Iteration 60270, loss = 0.225039
I0526 14:24:50.406471 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.225039 (* 1 = 0.225039 loss)
I0526 14:24:50.406476 15394 sgd_solver.cpp:43] Iteration 60270, lr = 0.0002
I0526 14:24:55.609637 15394 main.cpp:354] Iteration 60280, loss = 0.313127
I0526 14:24:55.609674 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.313126 (* 1 = 0.313126 loss)
I0526 14:24:55.609679 15394 sgd_solver.cpp:43] Iteration 60280, lr = 0.0002
I0526 14:25:00.360397 15394 main.cpp:354] Iteration 60290, loss = 0.336289
I0526 14:25:00.360432 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.336289 (* 1 = 0.336289 loss)
I0526 14:25:00.360440 15394 sgd_solver.cpp:43] Iteration 60290, lr = 0.0002
I0526 14:25:04.980990 15394 main.cpp:465] Iteration 60300, Testing net (#0)
I0526 14:25:18.074770 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8957
I0526 14:25:18.074818 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.332275 (* 1 = 0.332275 loss)
I0526 14:25:18.615789 15394 main.cpp:354] Iteration 60300, loss = 0.145277
I0526 14:25:18.615818 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.145276 (* 1 = 0.145276 loss)
I0526 14:25:18.615826 15394 sgd_solver.cpp:43] Iteration 60300, lr = 0.0002
I0526 14:25:23.518652 15394 main.cpp:354] Iteration 60310, loss = 0.121405
I0526 14:25:23.518693 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.121405 (* 1 = 0.121405 loss)
I0526 14:25:23.518700 15394 sgd_solver.cpp:43] Iteration 60310, lr = 0.0002
I0526 14:25:28.063213 15394 main.cpp:354] Iteration 60320, loss = 0.404359
I0526 14:25:28.063251 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.404358 (* 1 = 0.404358 loss)
I0526 14:25:28.063257 15394 sgd_solver.cpp:43] Iteration 60320, lr = 0.0002
I0526 14:25:33.045022 15394 main.cpp:354] Iteration 60330, loss = 0.1621
I0526 14:25:33.045055 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.1621 (* 1 = 0.1621 loss)
I0526 14:25:33.045063 15394 sgd_solver.cpp:43] Iteration 60330, lr = 0.0002
I0526 14:25:38.479948 15394 main.cpp:354] Iteration 60340, loss = 0.169209
I0526 14:25:38.479986 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.169208 (* 1 = 0.169208 loss)
I0526 14:25:38.479991 15394 sgd_solver.cpp:43] Iteration 60340, lr = 0.0002
I0526 14:25:44.041206 15394 main.cpp:354] Iteration 60350, loss = 0.233163
I0526 14:25:44.041241 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.233163 (* 1 = 0.233163 loss)
I0526 14:25:44.041247 15394 sgd_solver.cpp:43] Iteration 60350, lr = 0.0002
I0526 14:25:49.011111 15394 main.cpp:354] Iteration 60360, loss = 0.12522
I0526 14:25:49.011145 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.125219 (* 1 = 0.125219 loss)
I0526 14:25:49.011152 15394 sgd_solver.cpp:43] Iteration 60360, lr = 0.0002
I0526 14:25:54.399231 15394 main.cpp:354] Iteration 60370, loss = 0.11422
I0526 14:25:54.399271 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.114219 (* 1 = 0.114219 loss)
I0526 14:25:54.399282 15394 sgd_solver.cpp:43] Iteration 60370, lr = 0.0002
I0526 14:25:59.381139 15394 main.cpp:354] Iteration 60380, loss = 0.391992
I0526 14:25:59.381175 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.391991 (* 1 = 0.391991 loss)
I0526 14:25:59.381182 15394 sgd_solver.cpp:43] Iteration 60380, lr = 0.0002
I0526 14:26:04.645557 15394 main.cpp:354] Iteration 60390, loss = 0.0891331
I0526 14:26:04.645596 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0891325 (* 1 = 0.0891325 loss)
I0526 14:26:04.645602 15394 sgd_solver.cpp:43] Iteration 60390, lr = 0.0002
I0526 14:26:09.271639 15394 main.cpp:465] Iteration 60400, Testing net (#0)
I0526 14:26:22.369607 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8954
I0526 14:26:22.369644 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.335561 (* 1 = 0.335561 loss)
I0526 14:26:22.871973 15394 main.cpp:354] Iteration 60400, loss = 0.212612
I0526 14:26:22.872002 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.212611 (* 1 = 0.212611 loss)
I0526 14:26:22.872010 15394 sgd_solver.cpp:43] Iteration 60400, lr = 0.0002
I0526 14:26:27.875407 15394 main.cpp:354] Iteration 60410, loss = 0.246393
I0526 14:26:27.875447 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.246393 (* 1 = 0.246393 loss)
I0526 14:26:27.875453 15394 sgd_solver.cpp:43] Iteration 60410, lr = 0.0002
I0526 14:26:33.253895 15394 main.cpp:354] Iteration 60420, loss = 0.152735
I0526 14:26:33.253928 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.152735 (* 1 = 0.152735 loss)
I0526 14:26:33.253936 15394 sgd_solver.cpp:43] Iteration 60420, lr = 0.0002
I0526 14:26:38.518595 15394 main.cpp:354] Iteration 60430, loss = 0.30612
I0526 14:26:38.518635 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.30612 (* 1 = 0.30612 loss)
I0526 14:26:38.518640 15394 sgd_solver.cpp:43] Iteration 60430, lr = 0.0002
I0526 14:26:43.694738 15394 main.cpp:354] Iteration 60440, loss = 0.20626
I0526 14:26:43.694779 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.20626 (* 1 = 0.20626 loss)
I0526 14:26:43.694787 15394 sgd_solver.cpp:43] Iteration 60440, lr = 0.0002
I0526 14:26:48.836004 15394 main.cpp:354] Iteration 60450, loss = 0.116823
I0526 14:26:48.836038 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.116823 (* 1 = 0.116823 loss)
I0526 14:26:48.836045 15394 sgd_solver.cpp:43] Iteration 60450, lr = 0.0002
I0526 14:26:54.006661 15394 main.cpp:354] Iteration 60460, loss = 0.238068
I0526 14:26:54.006701 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.238067 (* 1 = 0.238067 loss)
I0526 14:26:54.006707 15394 sgd_solver.cpp:43] Iteration 60460, lr = 0.0002
I0526 14:26:58.656087 15394 main.cpp:354] Iteration 60470, loss = 0.115435
I0526 14:26:58.656126 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.115434 (* 1 = 0.115434 loss)
I0526 14:26:58.656131 15394 sgd_solver.cpp:43] Iteration 60470, lr = 0.0002
I0526 14:27:03.974315 15394 main.cpp:354] Iteration 60480, loss = 0.272362
I0526 14:27:03.974350 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.272361 (* 1 = 0.272361 loss)
I0526 14:27:03.974361 15394 sgd_solver.cpp:43] Iteration 60480, lr = 0.0002
I0526 14:27:08.000747 15394 main.cpp:354] Iteration 60490, loss = 0.37822
I0526 14:27:08.000788 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.378219 (* 1 = 0.378219 loss)
I0526 14:27:08.000794 15394 sgd_solver.cpp:43] Iteration 60490, lr = 0.0002
I0526 14:27:12.499173 15394 main.cpp:465] Iteration 60500, Testing net (#0)
I0526 14:27:25.578461 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8949
I0526 14:27:25.578502 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.326834 (* 1 = 0.326834 loss)
I0526 14:27:26.116996 15394 main.cpp:354] Iteration 60500, loss = 0.14531
I0526 14:27:26.117027 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.14531 (* 1 = 0.14531 loss)
I0526 14:27:26.117035 15394 sgd_solver.cpp:43] Iteration 60500, lr = 0.0002
I0526 14:27:31.054983 15394 main.cpp:354] Iteration 60510, loss = 0.231424
I0526 14:27:31.055022 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.231424 (* 1 = 0.231424 loss)
I0526 14:27:31.055028 15394 sgd_solver.cpp:43] Iteration 60510, lr = 0.0002
I0526 14:27:35.939663 15394 main.cpp:354] Iteration 60520, loss = 0.219492
I0526 14:27:35.939700 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.219491 (* 1 = 0.219491 loss)
I0526 14:27:35.939707 15394 sgd_solver.cpp:43] Iteration 60520, lr = 0.0002
I0526 14:27:40.807380 15394 main.cpp:354] Iteration 60530, loss = 0.180374
I0526 14:27:40.807415 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.180374 (* 1 = 0.180374 loss)
I0526 14:27:40.807422 15394 sgd_solver.cpp:43] Iteration 60530, lr = 0.0002
I0526 14:27:45.617921 15394 main.cpp:354] Iteration 60540, loss = 0.263425
I0526 14:27:45.617957 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.263424 (* 1 = 0.263424 loss)
I0526 14:27:45.617964 15394 sgd_solver.cpp:43] Iteration 60540, lr = 0.0002
I0526 14:27:50.417053 15394 main.cpp:354] Iteration 60550, loss = 0.0957759
I0526 14:27:50.417091 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0957753 (* 1 = 0.0957753 loss)
I0526 14:27:50.417098 15394 sgd_solver.cpp:43] Iteration 60550, lr = 0.0002
I0526 14:27:55.326807 15394 main.cpp:354] Iteration 60560, loss = 0.207008
I0526 14:27:55.326841 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.207008 (* 1 = 0.207008 loss)
I0526 14:27:55.326848 15394 sgd_solver.cpp:43] Iteration 60560, lr = 0.0002
I0526 14:28:00.148931 15394 main.cpp:354] Iteration 60570, loss = 0.317181
I0526 14:28:00.148967 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.317181 (* 1 = 0.317181 loss)
I0526 14:28:00.148973 15394 sgd_solver.cpp:43] Iteration 60570, lr = 0.0002
I0526 14:28:05.484853 15394 main.cpp:354] Iteration 60580, loss = 0.165231
I0526 14:28:05.484894 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.16523 (* 1 = 0.16523 loss)
I0526 14:28:05.484900 15394 sgd_solver.cpp:43] Iteration 60580, lr = 0.0002
I0526 14:28:10.442523 15394 main.cpp:354] Iteration 60590, loss = 0.242024
I0526 14:28:10.442558 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.242023 (* 1 = 0.242023 loss)
I0526 14:28:10.442564 15394 sgd_solver.cpp:43] Iteration 60590, lr = 0.0002
I0526 14:28:15.164167 15394 main.cpp:465] Iteration 60600, Testing net (#0)
I0526 14:28:28.257213 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8965
I0526 14:28:28.257251 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.330429 (* 1 = 0.330429 loss)
I0526 14:28:28.764015 15394 main.cpp:354] Iteration 60600, loss = 0.235883
I0526 14:28:28.764052 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235883 (* 1 = 0.235883 loss)
I0526 14:28:28.764060 15394 sgd_solver.cpp:43] Iteration 60600, lr = 0.0002
I0526 14:28:33.846283 15394 main.cpp:354] Iteration 60610, loss = 0.189812
I0526 14:28:33.846319 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.189812 (* 1 = 0.189812 loss)
I0526 14:28:33.846326 15394 sgd_solver.cpp:43] Iteration 60610, lr = 0.0002
I0526 14:28:39.076884 15394 main.cpp:354] Iteration 60620, loss = 0.193755
I0526 14:28:39.076927 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.193754 (* 1 = 0.193754 loss)
I0526 14:28:39.076936 15394 sgd_solver.cpp:43] Iteration 60620, lr = 0.0002
I0526 14:28:43.867243 15394 main.cpp:354] Iteration 60630, loss = 0.162866
I0526 14:28:43.867277 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.162865 (* 1 = 0.162865 loss)
I0526 14:28:43.867283 15394 sgd_solver.cpp:43] Iteration 60630, lr = 0.0002
I0526 14:28:49.002496 15394 main.cpp:354] Iteration 60640, loss = 0.0678774
I0526 14:28:49.002532 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0678768 (* 1 = 0.0678768 loss)
I0526 14:28:49.002537 15394 sgd_solver.cpp:43] Iteration 60640, lr = 0.0002
I0526 14:28:53.732681 15394 main.cpp:354] Iteration 60650, loss = 0.347278
I0526 14:28:53.732727 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.347277 (* 1 = 0.347277 loss)
I0526 14:28:53.732733 15394 sgd_solver.cpp:43] Iteration 60650, lr = 0.0002
I0526 14:28:58.721132 15394 main.cpp:354] Iteration 60660, loss = 0.170979
I0526 14:28:58.721168 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.170978 (* 1 = 0.170978 loss)
I0526 14:28:58.721174 15394 sgd_solver.cpp:43] Iteration 60660, lr = 0.0002
I0526 14:29:03.600379 15394 main.cpp:354] Iteration 60670, loss = 0.155718
I0526 14:29:03.600417 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.155717 (* 1 = 0.155717 loss)
I0526 14:29:03.600424 15394 sgd_solver.cpp:43] Iteration 60670, lr = 0.0002
I0526 14:29:08.730144 15394 main.cpp:354] Iteration 60680, loss = 0.252979
I0526 14:29:08.730180 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.252979 (* 1 = 0.252979 loss)
I0526 14:29:08.730187 15394 sgd_solver.cpp:43] Iteration 60680, lr = 0.0002
I0526 14:29:13.648545 15394 main.cpp:354] Iteration 60690, loss = 0.136668
I0526 14:29:13.648582 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.136668 (* 1 = 0.136668 loss)
I0526 14:29:13.648588 15394 sgd_solver.cpp:43] Iteration 60690, lr = 0.0002
I0526 14:29:18.491119 15394 main.cpp:465] Iteration 60700, Testing net (#0)
I0526 14:29:31.584507 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8968
I0526 14:29:31.584542 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.326369 (* 1 = 0.326369 loss)
I0526 14:29:32.052922 15394 main.cpp:354] Iteration 60700, loss = 0.162534
I0526 14:29:32.052953 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.162533 (* 1 = 0.162533 loss)
I0526 14:29:32.052960 15394 sgd_solver.cpp:43] Iteration 60700, lr = 0.0002
I0526 14:29:37.359585 15394 main.cpp:354] Iteration 60710, loss = 0.137111
I0526 14:29:37.359627 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.13711 (* 1 = 0.13711 loss)
I0526 14:29:37.359633 15394 sgd_solver.cpp:43] Iteration 60710, lr = 0.0002
I0526 14:29:42.321753 15394 main.cpp:354] Iteration 60720, loss = 0.206485
I0526 14:29:42.321789 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206484 (* 1 = 0.206484 loss)
I0526 14:29:42.321794 15394 sgd_solver.cpp:43] Iteration 60720, lr = 0.0002
I0526 14:29:47.439112 15394 main.cpp:354] Iteration 60730, loss = 0.307
I0526 14:29:47.439152 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.306999 (* 1 = 0.306999 loss)
I0526 14:29:47.439157 15394 sgd_solver.cpp:43] Iteration 60730, lr = 0.0002
I0526 14:29:52.312970 15394 main.cpp:354] Iteration 60740, loss = 0.199339
I0526 14:29:52.313010 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.199338 (* 1 = 0.199338 loss)
I0526 14:29:52.313016 15394 sgd_solver.cpp:43] Iteration 60740, lr = 0.0002
I0526 14:29:57.528304 15394 main.cpp:354] Iteration 60750, loss = 0.103278
I0526 14:29:57.528342 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.103277 (* 1 = 0.103277 loss)
I0526 14:29:57.528348 15394 sgd_solver.cpp:43] Iteration 60750, lr = 0.0002
I0526 14:30:02.631956 15394 main.cpp:354] Iteration 60760, loss = 0.108631
I0526 14:30:02.631991 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.10863 (* 1 = 0.10863 loss)
I0526 14:30:02.631997 15394 sgd_solver.cpp:43] Iteration 60760, lr = 0.0002
I0526 14:30:07.458925 15394 main.cpp:354] Iteration 60770, loss = 0.170975
I0526 14:30:07.458963 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.170974 (* 1 = 0.170974 loss)
I0526 14:30:07.458969 15394 sgd_solver.cpp:43] Iteration 60770, lr = 0.0002
I0526 14:30:12.823055 15394 main.cpp:354] Iteration 60780, loss = 0.121121
I0526 14:30:12.823091 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.12112 (* 1 = 0.12112 loss)
I0526 14:30:12.823096 15394 sgd_solver.cpp:43] Iteration 60780, lr = 0.0002
I0526 14:30:17.820533 15394 main.cpp:354] Iteration 60790, loss = 0.150863
I0526 14:30:17.820569 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.150862 (* 1 = 0.150862 loss)
I0526 14:30:17.820580 15394 sgd_solver.cpp:43] Iteration 60790, lr = 0.0002
I0526 14:30:22.097559 15394 main.cpp:465] Iteration 60800, Testing net (#0)
I0526 14:30:35.189069 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8957
I0526 14:30:35.189107 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.326556 (* 1 = 0.326556 loss)
I0526 14:30:35.623020 15394 main.cpp:354] Iteration 60800, loss = 0.492573
I0526 14:30:35.623052 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.492572 (* 1 = 0.492572 loss)
I0526 14:30:35.623060 15394 sgd_solver.cpp:43] Iteration 60800, lr = 0.0002
I0526 14:30:41.030187 15394 main.cpp:354] Iteration 60810, loss = 0.193808
I0526 14:30:41.030222 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.193807 (* 1 = 0.193807 loss)
I0526 14:30:41.030230 15394 sgd_solver.cpp:43] Iteration 60810, lr = 0.0002
I0526 14:30:45.539268 15394 main.cpp:354] Iteration 60820, loss = 0.237884
I0526 14:30:45.539304 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.237883 (* 1 = 0.237883 loss)
I0526 14:30:45.539310 15394 sgd_solver.cpp:43] Iteration 60820, lr = 0.0002
I0526 14:30:50.057752 15394 main.cpp:354] Iteration 60830, loss = 0.245681
I0526 14:30:50.057795 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.245681 (* 1 = 0.245681 loss)
I0526 14:30:50.057801 15394 sgd_solver.cpp:43] Iteration 60830, lr = 0.0002
I0526 14:30:54.973145 15394 main.cpp:354] Iteration 60840, loss = 0.23482
I0526 14:30:54.973178 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.234819 (* 1 = 0.234819 loss)
I0526 14:30:54.973186 15394 sgd_solver.cpp:43] Iteration 60840, lr = 0.0002
I0526 14:31:00.196588 15394 main.cpp:354] Iteration 60850, loss = 0.188694
I0526 14:31:00.196624 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.188694 (* 1 = 0.188694 loss)
I0526 14:31:00.196630 15394 sgd_solver.cpp:43] Iteration 60850, lr = 0.0002
I0526 14:31:05.538239 15394 main.cpp:354] Iteration 60860, loss = 0.164507
I0526 14:31:05.538276 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.164507 (* 1 = 0.164507 loss)
I0526 14:31:05.538282 15394 sgd_solver.cpp:43] Iteration 60860, lr = 0.0002
I0526 14:31:10.654479 15394 main.cpp:354] Iteration 60870, loss = 0.23033
I0526 14:31:10.654515 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.230329 (* 1 = 0.230329 loss)
I0526 14:31:10.654522 15394 sgd_solver.cpp:43] Iteration 60870, lr = 0.0002
I0526 14:31:15.797408 15394 main.cpp:354] Iteration 60880, loss = 0.133153
I0526 14:31:15.797447 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.133153 (* 1 = 0.133153 loss)
I0526 14:31:15.797453 15394 sgd_solver.cpp:43] Iteration 60880, lr = 0.0002
I0526 14:31:20.980576 15394 main.cpp:354] Iteration 60890, loss = 0.208419
I0526 14:31:20.980617 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.208418 (* 1 = 0.208418 loss)
I0526 14:31:20.980623 15394 sgd_solver.cpp:43] Iteration 60890, lr = 0.0002
I0526 14:31:25.273180 15394 main.cpp:465] Iteration 60900, Testing net (#0)
I0526 14:31:38.374672 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8937
I0526 14:31:38.374711 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.336636 (* 1 = 0.336636 loss)
I0526 14:31:38.771543 15394 main.cpp:354] Iteration 60900, loss = 0.390178
I0526 14:31:38.771574 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.390177 (* 1 = 0.390177 loss)
I0526 14:31:38.771580 15394 sgd_solver.cpp:43] Iteration 60900, lr = 0.0002
I0526 14:31:43.911036 15394 main.cpp:354] Iteration 60910, loss = 0.241662
I0526 14:31:43.911070 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.241661 (* 1 = 0.241661 loss)
I0526 14:31:43.911077 15394 sgd_solver.cpp:43] Iteration 60910, lr = 0.0002
I0526 14:31:48.717551 15394 main.cpp:354] Iteration 60920, loss = 0.0934139
I0526 14:31:48.717587 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0934133 (* 1 = 0.0934133 loss)
I0526 14:31:48.717600 15394 sgd_solver.cpp:43] Iteration 60920, lr = 0.0002
I0526 14:31:53.643790 15394 main.cpp:354] Iteration 60930, loss = 0.258707
I0526 14:31:53.643842 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.258706 (* 1 = 0.258706 loss)
I0526 14:31:53.643849 15394 sgd_solver.cpp:43] Iteration 60930, lr = 0.0002
I0526 14:31:59.125231 15394 main.cpp:354] Iteration 60940, loss = 0.0824396
I0526 14:31:59.125267 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.082439 (* 1 = 0.082439 loss)
I0526 14:31:59.125273 15394 sgd_solver.cpp:43] Iteration 60940, lr = 0.0002
I0526 14:32:04.276052 15394 main.cpp:354] Iteration 60950, loss = 0.11017
I0526 14:32:04.276090 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.11017 (* 1 = 0.11017 loss)
I0526 14:32:04.276098 15394 sgd_solver.cpp:43] Iteration 60950, lr = 0.0002
I0526 14:32:09.686883 15394 main.cpp:354] Iteration 60960, loss = 0.229961
I0526 14:32:09.686942 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.22996 (* 1 = 0.22996 loss)
I0526 14:32:09.686949 15394 sgd_solver.cpp:43] Iteration 60960, lr = 0.0002
I0526 14:32:14.573220 15394 main.cpp:354] Iteration 60970, loss = 0.23959
I0526 14:32:14.573254 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.23959 (* 1 = 0.23959 loss)
I0526 14:32:14.573261 15394 sgd_solver.cpp:43] Iteration 60970, lr = 0.0002
I0526 14:32:19.348929 15394 main.cpp:354] Iteration 60980, loss = 0.307866
I0526 14:32:19.348968 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.307865 (* 1 = 0.307865 loss)
I0526 14:32:19.348975 15394 sgd_solver.cpp:43] Iteration 60980, lr = 0.0002
I0526 14:32:24.452313 15394 main.cpp:354] Iteration 60990, loss = 0.213074
I0526 14:32:24.452352 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.213073 (* 1 = 0.213073 loss)
I0526 14:32:24.452358 15394 sgd_solver.cpp:43] Iteration 60990, lr = 0.0002
I0526 14:32:29.025996 15394 main.cpp:465] Iteration 61000, Testing net (#0)
I0526 14:32:42.122794 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8972
I0526 14:32:42.122833 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.331494 (* 1 = 0.331494 loss)
I0526 14:32:42.594262 15394 main.cpp:354] Iteration 61000, loss = 0.364936
I0526 14:32:42.594297 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.364936 (* 1 = 0.364936 loss)
I0526 14:32:42.594305 15394 sgd_solver.cpp:43] Iteration 61000, lr = 0.0002
I0526 14:32:47.562161 15394 main.cpp:354] Iteration 61010, loss = 0.280483
I0526 14:32:47.562198 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.280483 (* 1 = 0.280483 loss)
I0526 14:32:47.562204 15394 sgd_solver.cpp:43] Iteration 61010, lr = 0.0002
I0526 14:32:52.761041 15394 main.cpp:354] Iteration 61020, loss = 0.231481
I0526 14:32:52.761081 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.23148 (* 1 = 0.23148 loss)
I0526 14:32:52.761087 15394 sgd_solver.cpp:43] Iteration 61020, lr = 0.0002
I0526 14:32:58.188690 15394 main.cpp:354] Iteration 61030, loss = 0.0787563
I0526 14:32:58.188726 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0787557 (* 1 = 0.0787557 loss)
I0526 14:32:58.188733 15394 sgd_solver.cpp:43] Iteration 61030, lr = 0.0002
I0526 14:33:02.718538 15394 main.cpp:354] Iteration 61040, loss = 0.350361
I0526 14:33:02.718572 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.350361 (* 1 = 0.350361 loss)
I0526 14:33:02.718578 15394 sgd_solver.cpp:43] Iteration 61040, lr = 0.0002
I0526 14:33:07.516391 15394 main.cpp:354] Iteration 61050, loss = 0.161697
I0526 14:33:07.516429 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.161696 (* 1 = 0.161696 loss)
I0526 14:33:07.516435 15394 sgd_solver.cpp:43] Iteration 61050, lr = 0.0002
I0526 14:33:12.402961 15394 main.cpp:354] Iteration 61060, loss = 0.416354
I0526 14:33:12.402997 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.416354 (* 1 = 0.416354 loss)
I0526 14:33:12.403002 15394 sgd_solver.cpp:43] Iteration 61060, lr = 0.0002
I0526 14:33:17.484341 15394 main.cpp:354] Iteration 61070, loss = 0.17297
I0526 14:33:17.484378 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.172969 (* 1 = 0.172969 loss)
I0526 14:33:17.484383 15394 sgd_solver.cpp:43] Iteration 61070, lr = 0.0002
I0526 14:33:22.884155 15394 main.cpp:354] Iteration 61080, loss = 0.190375
I0526 14:33:22.884194 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.190374 (* 1 = 0.190374 loss)
I0526 14:33:22.884201 15394 sgd_solver.cpp:43] Iteration 61080, lr = 0.0002
I0526 14:33:27.910655 15394 main.cpp:354] Iteration 61090, loss = 0.176828
I0526 14:33:27.910691 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.176827 (* 1 = 0.176827 loss)
I0526 14:33:27.910696 15394 sgd_solver.cpp:43] Iteration 61090, lr = 0.0002
I0526 14:33:32.734879 15394 main.cpp:465] Iteration 61100, Testing net (#0)
I0526 14:33:45.825314 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8976
I0526 14:33:45.825350 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.324814 (* 1 = 0.324814 loss)
I0526 14:33:46.364560 15394 main.cpp:354] Iteration 61100, loss = 0.147829
I0526 14:33:46.364591 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.147828 (* 1 = 0.147828 loss)
I0526 14:33:46.364598 15394 sgd_solver.cpp:43] Iteration 61100, lr = 0.0002
I0526 14:33:51.138666 15394 main.cpp:354] Iteration 61110, loss = 0.121871
I0526 14:33:51.138706 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.12187 (* 1 = 0.12187 loss)
I0526 14:33:51.138712 15394 sgd_solver.cpp:43] Iteration 61110, lr = 0.0002
I0526 14:33:56.154016 15394 main.cpp:354] Iteration 61120, loss = 0.165069
I0526 14:33:56.154063 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.165068 (* 1 = 0.165068 loss)
I0526 14:33:56.154070 15394 sgd_solver.cpp:43] Iteration 61120, lr = 0.0002
I0526 14:34:00.740200 15394 main.cpp:354] Iteration 61130, loss = 0.189291
I0526 14:34:00.740239 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.18929 (* 1 = 0.18929 loss)
I0526 14:34:00.740244 15394 sgd_solver.cpp:43] Iteration 61130, lr = 0.0002
I0526 14:34:05.699398 15394 main.cpp:354] Iteration 61140, loss = 0.129394
I0526 14:34:05.699439 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.129393 (* 1 = 0.129393 loss)
I0526 14:34:05.699445 15394 sgd_solver.cpp:43] Iteration 61140, lr = 0.0002
I0526 14:34:10.566423 15394 main.cpp:354] Iteration 61150, loss = 0.223095
I0526 14:34:10.566458 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.223095 (* 1 = 0.223095 loss)
I0526 14:34:10.566465 15394 sgd_solver.cpp:43] Iteration 61150, lr = 0.0002
I0526 14:34:15.339815 15394 main.cpp:354] Iteration 61160, loss = 0.155975
I0526 14:34:15.339849 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.155975 (* 1 = 0.155975 loss)
I0526 14:34:15.339855 15394 sgd_solver.cpp:43] Iteration 61160, lr = 0.0002
I0526 14:34:20.287415 15394 main.cpp:354] Iteration 61170, loss = 0.364604
I0526 14:34:20.287454 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.364603 (* 1 = 0.364603 loss)
I0526 14:34:20.287459 15394 sgd_solver.cpp:43] Iteration 61170, lr = 0.0002
I0526 14:34:25.845190 15394 main.cpp:354] Iteration 61180, loss = 0.109011
I0526 14:34:25.845223 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.10901 (* 1 = 0.10901 loss)
I0526 14:34:25.845229 15394 sgd_solver.cpp:43] Iteration 61180, lr = 0.0002
I0526 14:34:31.008261 15394 main.cpp:354] Iteration 61190, loss = 0.110192
I0526 14:34:31.008296 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.110191 (* 1 = 0.110191 loss)
I0526 14:34:31.008302 15394 sgd_solver.cpp:43] Iteration 61190, lr = 0.0002
I0526 14:34:36.005671 15394 main.cpp:465] Iteration 61200, Testing net (#0)
I0526 14:34:49.110179 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8972
I0526 14:34:49.110219 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.330961 (* 1 = 0.330961 loss)
I0526 14:34:49.584069 15394 main.cpp:354] Iteration 61200, loss = 0.335486
I0526 14:34:49.584103 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.335485 (* 1 = 0.335485 loss)
I0526 14:34:49.584111 15394 sgd_solver.cpp:43] Iteration 61200, lr = 0.0002
I0526 14:34:54.641461 15394 main.cpp:354] Iteration 61210, loss = 0.193509
I0526 14:34:54.641495 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.193508 (* 1 = 0.193508 loss)
I0526 14:34:54.641501 15394 sgd_solver.cpp:43] Iteration 61210, lr = 0.0002
I0526 14:34:59.332975 15394 main.cpp:354] Iteration 61220, loss = 0.109732
I0526 14:34:59.333014 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.109731 (* 1 = 0.109731 loss)
I0526 14:34:59.333019 15394 sgd_solver.cpp:43] Iteration 61220, lr = 0.0002
I0526 14:35:04.214154 15394 main.cpp:354] Iteration 61230, loss = 0.296076
I0526 14:35:04.214193 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.296075 (* 1 = 0.296075 loss)
I0526 14:35:04.214201 15394 sgd_solver.cpp:43] Iteration 61230, lr = 0.0002
I0526 14:35:09.025889 15394 main.cpp:354] Iteration 61240, loss = 0.202309
I0526 14:35:09.025926 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.202308 (* 1 = 0.202308 loss)
I0526 14:35:09.025933 15394 sgd_solver.cpp:43] Iteration 61240, lr = 0.0002
I0526 14:35:14.308210 15394 main.cpp:354] Iteration 61250, loss = 0.147991
I0526 14:35:14.308246 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.14799 (* 1 = 0.14799 loss)
I0526 14:35:14.308254 15394 sgd_solver.cpp:43] Iteration 61250, lr = 0.0002
I0526 14:35:19.335223 15394 main.cpp:354] Iteration 61260, loss = 0.102396
I0526 14:35:19.335261 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.102395 (* 1 = 0.102395 loss)
I0526 14:35:19.335268 15394 sgd_solver.cpp:43] Iteration 61260, lr = 0.0002
I0526 14:35:24.386204 15394 main.cpp:354] Iteration 61270, loss = 0.106863
I0526 14:35:24.386240 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.106862 (* 1 = 0.106862 loss)
I0526 14:35:24.386246 15394 sgd_solver.cpp:43] Iteration 61270, lr = 0.0002
I0526 14:35:29.215023 15394 main.cpp:354] Iteration 61280, loss = 0.202554
I0526 14:35:29.215059 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.202553 (* 1 = 0.202553 loss)
I0526 14:35:29.215065 15394 sgd_solver.cpp:43] Iteration 61280, lr = 0.0002
I0526 14:35:34.387095 15394 main.cpp:354] Iteration 61290, loss = 0.211588
I0526 14:35:34.387136 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.211587 (* 1 = 0.211587 loss)
I0526 14:35:34.387143 15394 sgd_solver.cpp:43] Iteration 61290, lr = 0.0002
I0526 14:35:39.072073 15394 main.cpp:465] Iteration 61300, Testing net (#0)
I0526 14:35:52.178683 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8932
I0526 14:35:52.178721 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.337004 (* 1 = 0.337004 loss)
I0526 14:35:52.686408 15394 main.cpp:354] Iteration 61300, loss = 0.208319
I0526 14:35:52.686439 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.208318 (* 1 = 0.208318 loss)
I0526 14:35:52.686445 15394 sgd_solver.cpp:43] Iteration 61300, lr = 0.0002
I0526 14:35:57.304698 15394 main.cpp:354] Iteration 61310, loss = 0.19475
I0526 14:35:57.304733 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.19475 (* 1 = 0.19475 loss)
I0526 14:35:57.304738 15394 sgd_solver.cpp:43] Iteration 61310, lr = 0.0002
I0526 14:36:01.927358 15394 main.cpp:354] Iteration 61320, loss = 0.118065
I0526 14:36:01.927405 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.118064 (* 1 = 0.118064 loss)
I0526 14:36:01.927412 15394 sgd_solver.cpp:43] Iteration 61320, lr = 0.0002
I0526 14:36:06.831327 15394 main.cpp:354] Iteration 61330, loss = 0.257467
I0526 14:36:06.831367 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.257466 (* 1 = 0.257466 loss)
I0526 14:36:06.831372 15394 sgd_solver.cpp:43] Iteration 61330, lr = 0.0002
I0526 14:36:11.500708 15394 main.cpp:354] Iteration 61340, loss = 0.211124
I0526 14:36:11.500746 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.211123 (* 1 = 0.211123 loss)
I0526 14:36:11.500756 15394 sgd_solver.cpp:43] Iteration 61340, lr = 0.0002
I0526 14:36:16.753376 15394 main.cpp:354] Iteration 61350, loss = 0.149733
I0526 14:36:16.753410 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.149733 (* 1 = 0.149733 loss)
I0526 14:36:16.753417 15394 sgd_solver.cpp:43] Iteration 61350, lr = 0.0002
I0526 14:36:21.966822 15394 main.cpp:354] Iteration 61360, loss = 0.0935241
I0526 14:36:21.966861 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0935234 (* 1 = 0.0935234 loss)
I0526 14:36:21.966868 15394 sgd_solver.cpp:43] Iteration 61360, lr = 0.0002
I0526 14:36:26.796407 15394 main.cpp:354] Iteration 61370, loss = 0.295165
I0526 14:36:26.796447 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.295165 (* 1 = 0.295165 loss)
I0526 14:36:26.796452 15394 sgd_solver.cpp:43] Iteration 61370, lr = 0.0002
I0526 14:36:31.743057 15394 main.cpp:354] Iteration 61380, loss = 0.306679
I0526 14:36:31.743091 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.306678 (* 1 = 0.306678 loss)
I0526 14:36:31.743098 15394 sgd_solver.cpp:43] Iteration 61380, lr = 0.0002
I0526 14:36:36.141350 15394 main.cpp:354] Iteration 61390, loss = 0.918651
I0526 14:36:36.141391 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.91865 (* 1 = 0.91865 loss)
I0526 14:36:36.141397 15394 sgd_solver.cpp:43] Iteration 61390, lr = 0.0002
I0526 14:36:40.298034 15394 main.cpp:465] Iteration 61400, Testing net (#0)
I0526 14:36:53.390128 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8961
I0526 14:36:53.390169 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.332184 (* 1 = 0.332184 loss)
I0526 14:36:53.891973 15394 main.cpp:354] Iteration 61400, loss = 0.265826
I0526 14:36:53.892009 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.265825 (* 1 = 0.265825 loss)
I0526 14:36:53.892017 15394 sgd_solver.cpp:43] Iteration 61400, lr = 0.0002
I0526 14:36:58.767729 15394 main.cpp:354] Iteration 61410, loss = 0.401693
I0526 14:36:58.767765 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.401693 (* 1 = 0.401693 loss)
I0526 14:36:58.767771 15394 sgd_solver.cpp:43] Iteration 61410, lr = 0.0002
I0526 14:37:03.655228 15394 main.cpp:354] Iteration 61420, loss = 0.17991
I0526 14:37:03.655266 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.179909 (* 1 = 0.179909 loss)
I0526 14:37:03.655272 15394 sgd_solver.cpp:43] Iteration 61420, lr = 0.0002
I0526 14:37:08.787765 15394 main.cpp:354] Iteration 61430, loss = 0.25694
I0526 14:37:08.787806 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.256939 (* 1 = 0.256939 loss)
I0526 14:37:08.787813 15394 sgd_solver.cpp:43] Iteration 61430, lr = 0.0002
I0526 14:37:14.196203 15394 main.cpp:354] Iteration 61440, loss = 0.146193
I0526 14:37:14.196238 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.146192 (* 1 = 0.146192 loss)
I0526 14:37:14.196244 15394 sgd_solver.cpp:43] Iteration 61440, lr = 0.0002
I0526 14:37:18.837718 15394 main.cpp:354] Iteration 61450, loss = 0.409532
I0526 14:37:18.837754 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.409531 (* 1 = 0.409531 loss)
I0526 14:37:18.837760 15394 sgd_solver.cpp:43] Iteration 61450, lr = 0.0002
I0526 14:37:23.232115 15394 main.cpp:354] Iteration 61460, loss = 0.193634
I0526 14:37:23.232151 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.193633 (* 1 = 0.193633 loss)
I0526 14:37:23.232158 15394 sgd_solver.cpp:43] Iteration 61460, lr = 0.0002
I0526 14:37:28.336305 15394 main.cpp:354] Iteration 61470, loss = 0.33063
I0526 14:37:28.336341 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.33063 (* 1 = 0.33063 loss)
I0526 14:37:28.336347 15394 sgd_solver.cpp:43] Iteration 61470, lr = 0.0002
I0526 14:37:33.336913 15394 main.cpp:354] Iteration 61480, loss = 0.169105
I0526 14:37:33.336952 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.169104 (* 1 = 0.169104 loss)
I0526 14:37:33.336958 15394 sgd_solver.cpp:43] Iteration 61480, lr = 0.0002
I0526 14:37:38.163545 15394 main.cpp:354] Iteration 61490, loss = 0.478468
I0526 14:37:38.163583 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.478467 (* 1 = 0.478467 loss)
I0526 14:37:38.163589 15394 sgd_solver.cpp:43] Iteration 61490, lr = 0.0002
I0526 14:37:42.866092 15394 main.cpp:465] Iteration 61500, Testing net (#0)
I0526 14:37:55.965723 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8945
I0526 14:37:55.965761 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.333396 (* 1 = 0.333396 loss)
I0526 14:37:56.436770 15394 main.cpp:354] Iteration 61500, loss = 0.221766
I0526 14:37:56.436803 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.221765 (* 1 = 0.221765 loss)
I0526 14:37:56.436810 15394 sgd_solver.cpp:43] Iteration 61500, lr = 0.0002
I0526 14:38:01.318437 15394 main.cpp:354] Iteration 61510, loss = 0.204373
I0526 14:38:01.318472 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204372 (* 1 = 0.204372 loss)
I0526 14:38:01.318490 15394 sgd_solver.cpp:43] Iteration 61510, lr = 0.0002
I0526 14:38:06.415536 15394 main.cpp:354] Iteration 61520, loss = 0.283289
I0526 14:38:06.415578 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.283288 (* 1 = 0.283288 loss)
I0526 14:38:06.415585 15394 sgd_solver.cpp:43] Iteration 61520, lr = 0.0002
I0526 14:38:11.542414 15394 main.cpp:354] Iteration 61530, loss = 0.128923
I0526 14:38:11.542450 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.128922 (* 1 = 0.128922 loss)
I0526 14:38:11.542456 15394 sgd_solver.cpp:43] Iteration 61530, lr = 0.0002
I0526 14:38:16.290213 15394 main.cpp:354] Iteration 61540, loss = 0.236365
I0526 14:38:16.290249 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.236365 (* 1 = 0.236365 loss)
I0526 14:38:16.290256 15394 sgd_solver.cpp:43] Iteration 61540, lr = 0.0002
I0526 14:38:21.102418 15394 main.cpp:354] Iteration 61550, loss = 0.482985
I0526 14:38:21.102459 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.482984 (* 1 = 0.482984 loss)
I0526 14:38:21.102465 15394 sgd_solver.cpp:43] Iteration 61550, lr = 0.0002
I0526 14:38:26.199710 15394 main.cpp:354] Iteration 61560, loss = 0.221697
I0526 14:38:26.199746 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.221696 (* 1 = 0.221696 loss)
I0526 14:38:26.199753 15394 sgd_solver.cpp:43] Iteration 61560, lr = 0.0002
I0526 14:38:31.543490 15394 main.cpp:354] Iteration 61570, loss = 0.217339
I0526 14:38:31.543526 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.217338 (* 1 = 0.217338 loss)
I0526 14:38:31.543532 15394 sgd_solver.cpp:43] Iteration 61570, lr = 0.0002
I0526 14:38:36.557296 15394 main.cpp:354] Iteration 61580, loss = 0.153019
I0526 14:38:36.557335 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.153018 (* 1 = 0.153018 loss)
I0526 14:38:36.557343 15394 sgd_solver.cpp:43] Iteration 61580, lr = 0.0002
I0526 14:38:41.244465 15394 main.cpp:354] Iteration 61590, loss = 0.222931
I0526 14:38:41.244499 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.222931 (* 1 = 0.222931 loss)
I0526 14:38:41.244505 15394 sgd_solver.cpp:43] Iteration 61590, lr = 0.0002
I0526 14:38:45.913177 15394 main.cpp:465] Iteration 61600, Testing net (#0)
I0526 14:38:59.005340 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8971
I0526 14:38:59.005380 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.33065 (* 1 = 0.33065 loss)
I0526 14:38:59.545866 15394 main.cpp:354] Iteration 61600, loss = 0.115473
I0526 14:38:59.545899 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.115473 (* 1 = 0.115473 loss)
I0526 14:38:59.545907 15394 sgd_solver.cpp:43] Iteration 61600, lr = 0.0002
I0526 14:39:04.304915 15394 main.cpp:354] Iteration 61610, loss = 0.263084
I0526 14:39:04.304960 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.263083 (* 1 = 0.263083 loss)
I0526 14:39:04.304967 15394 sgd_solver.cpp:43] Iteration 61610, lr = 0.0002
I0526 14:39:09.556460 15394 main.cpp:354] Iteration 61620, loss = 0.720169
I0526 14:39:09.556502 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.720168 (* 1 = 0.720168 loss)
I0526 14:39:09.556509 15394 sgd_solver.cpp:43] Iteration 61620, lr = 0.0002
I0526 14:39:14.812770 15394 main.cpp:354] Iteration 61630, loss = 0.257126
I0526 14:39:14.812808 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.257125 (* 1 = 0.257125 loss)
I0526 14:39:14.812813 15394 sgd_solver.cpp:43] Iteration 61630, lr = 0.0002
I0526 14:39:19.807725 15394 main.cpp:354] Iteration 61640, loss = 0.110175
I0526 14:39:19.807762 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.110174 (* 1 = 0.110174 loss)
I0526 14:39:19.807768 15394 sgd_solver.cpp:43] Iteration 61640, lr = 0.0002
I0526 14:39:24.797039 15394 main.cpp:354] Iteration 61650, loss = 0.104686
I0526 14:39:24.797073 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.104686 (* 1 = 0.104686 loss)
I0526 14:39:24.797080 15394 sgd_solver.cpp:43] Iteration 61650, lr = 0.0002
I0526 14:39:29.566680 15394 main.cpp:354] Iteration 61660, loss = 0.125156
I0526 14:39:29.566716 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.125155 (* 1 = 0.125155 loss)
I0526 14:39:29.566722 15394 sgd_solver.cpp:43] Iteration 61660, lr = 0.0002
I0526 14:39:34.657058 15394 main.cpp:354] Iteration 61670, loss = 0.173439
I0526 14:39:34.657099 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.173438 (* 1 = 0.173438 loss)
I0526 14:39:34.657106 15394 sgd_solver.cpp:43] Iteration 61670, lr = 0.0002
I0526 14:39:39.677189 15394 main.cpp:354] Iteration 61680, loss = 0.176657
I0526 14:39:39.677227 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.176657 (* 1 = 0.176657 loss)
I0526 14:39:39.677232 15394 sgd_solver.cpp:43] Iteration 61680, lr = 0.0002
I0526 14:39:44.636070 15394 main.cpp:354] Iteration 61690, loss = 0.283675
I0526 14:39:44.636104 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.283674 (* 1 = 0.283674 loss)
I0526 14:39:44.636111 15394 sgd_solver.cpp:43] Iteration 61690, lr = 0.0002
I0526 14:39:49.443863 15394 main.cpp:465] Iteration 61700, Testing net (#0)
I0526 14:40:02.535039 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8984
I0526 14:40:02.535078 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.330216 (* 1 = 0.330216 loss)
I0526 14:40:02.970161 15394 main.cpp:354] Iteration 61700, loss = 0.272608
I0526 14:40:02.970199 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.272608 (* 1 = 0.272608 loss)
I0526 14:40:02.970207 15394 sgd_solver.cpp:43] Iteration 61700, lr = 0.0002
I0526 14:40:08.229780 15394 main.cpp:354] Iteration 61710, loss = 0.0919442
I0526 14:40:08.229820 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0919435 (* 1 = 0.0919435 loss)
I0526 14:40:08.229825 15394 sgd_solver.cpp:43] Iteration 61710, lr = 0.0002
I0526 14:40:13.600343 15394 main.cpp:354] Iteration 61720, loss = 0.125819
I0526 14:40:13.600380 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.125818 (* 1 = 0.125818 loss)
I0526 14:40:13.600388 15394 sgd_solver.cpp:43] Iteration 61720, lr = 0.0002
I0526 14:40:18.180867 15394 main.cpp:354] Iteration 61730, loss = 0.348995
I0526 14:40:18.180903 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.348995 (* 1 = 0.348995 loss)
I0526 14:40:18.180910 15394 sgd_solver.cpp:43] Iteration 61730, lr = 0.0002
I0526 14:40:23.284217 15394 main.cpp:354] Iteration 61740, loss = 0.162989
I0526 14:40:23.284255 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.162989 (* 1 = 0.162989 loss)
I0526 14:40:23.284261 15394 sgd_solver.cpp:43] Iteration 61740, lr = 0.0002
I0526 14:40:28.434478 15394 main.cpp:354] Iteration 61750, loss = 0.233248
I0526 14:40:28.434514 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.233248 (* 1 = 0.233248 loss)
I0526 14:40:28.434520 15394 sgd_solver.cpp:43] Iteration 61750, lr = 0.0002
I0526 14:40:33.327347 15394 main.cpp:354] Iteration 61760, loss = 0.105684
I0526 14:40:33.327389 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.105683 (* 1 = 0.105683 loss)
I0526 14:40:33.327396 15394 sgd_solver.cpp:43] Iteration 61760, lr = 0.0002
I0526 14:40:38.409952 15394 main.cpp:354] Iteration 61770, loss = 0.0703021
I0526 14:40:38.409992 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0703013 (* 1 = 0.0703013 loss)
I0526 14:40:38.409999 15394 sgd_solver.cpp:43] Iteration 61770, lr = 0.0002
I0526 14:40:43.882117 15394 main.cpp:354] Iteration 61780, loss = 0.298574
I0526 14:40:43.882153 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.298573 (* 1 = 0.298573 loss)
I0526 14:40:43.882158 15394 sgd_solver.cpp:43] Iteration 61780, lr = 0.0002
I0526 14:40:49.205894 15394 main.cpp:354] Iteration 61790, loss = 0.187075
I0526 14:40:49.205932 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187075 (* 1 = 0.187075 loss)
I0526 14:40:49.205940 15394 sgd_solver.cpp:43] Iteration 61790, lr = 0.0002
I0526 14:40:53.799135 15394 main.cpp:465] Iteration 61800, Testing net (#0)
I0526 14:41:06.885725 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8957
I0526 14:41:06.885762 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.331226 (* 1 = 0.331226 loss)
I0526 14:41:07.389114 15394 main.cpp:354] Iteration 61800, loss = 0.204293
I0526 14:41:07.389148 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204292 (* 1 = 0.204292 loss)
I0526 14:41:07.389155 15394 sgd_solver.cpp:43] Iteration 61800, lr = 0.0002
I0526 14:41:12.594254 15394 main.cpp:354] Iteration 61810, loss = 0.318002
I0526 14:41:12.594290 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.318002 (* 1 = 0.318002 loss)
I0526 14:41:12.594296 15394 sgd_solver.cpp:43] Iteration 61810, lr = 0.0002
I0526 14:41:17.332502 15394 main.cpp:354] Iteration 61820, loss = 0.208035
I0526 14:41:17.332542 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.208034 (* 1 = 0.208034 loss)
I0526 14:41:17.332551 15394 sgd_solver.cpp:43] Iteration 61820, lr = 0.0002
I0526 14:41:22.748911 15394 main.cpp:354] Iteration 61830, loss = 0.188316
I0526 14:41:22.748952 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.188316 (* 1 = 0.188316 loss)
I0526 14:41:22.748958 15394 sgd_solver.cpp:43] Iteration 61830, lr = 0.0002
I0526 14:41:28.064697 15394 main.cpp:354] Iteration 61840, loss = 0.0973187
I0526 14:41:28.064733 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.097318 (* 1 = 0.097318 loss)
I0526 14:41:28.064739 15394 sgd_solver.cpp:43] Iteration 61840, lr = 0.0002
I0526 14:41:33.256425 15394 main.cpp:354] Iteration 61850, loss = 0.144093
I0526 14:41:33.256461 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.144092 (* 1 = 0.144092 loss)
I0526 14:41:33.256467 15394 sgd_solver.cpp:43] Iteration 61850, lr = 0.0002
I0526 14:41:38.357187 15394 main.cpp:354] Iteration 61860, loss = 0.313602
I0526 14:41:38.357226 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.313602 (* 1 = 0.313602 loss)
I0526 14:41:38.357233 15394 sgd_solver.cpp:43] Iteration 61860, lr = 0.0002
I0526 14:41:43.193055 15394 main.cpp:354] Iteration 61870, loss = 0.198051
I0526 14:41:43.193090 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.19805 (* 1 = 0.19805 loss)
I0526 14:41:43.193097 15394 sgd_solver.cpp:43] Iteration 61870, lr = 0.0002
I0526 14:41:48.080603 15394 main.cpp:354] Iteration 61880, loss = 0.216924
I0526 14:41:48.080642 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.216923 (* 1 = 0.216923 loss)
I0526 14:41:48.080648 15394 sgd_solver.cpp:43] Iteration 61880, lr = 0.0002
I0526 14:41:53.378684 15394 main.cpp:354] Iteration 61890, loss = 0.150355
I0526 14:41:53.378723 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.150354 (* 1 = 0.150354 loss)
I0526 14:41:53.378729 15394 sgd_solver.cpp:43] Iteration 61890, lr = 0.0002
I0526 14:41:57.925146 15394 main.cpp:465] Iteration 61900, Testing net (#0)
I0526 14:42:11.018302 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8958
I0526 14:42:11.018342 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.331209 (* 1 = 0.331209 loss)
I0526 14:42:11.484184 15394 main.cpp:354] Iteration 61900, loss = 0.189636
I0526 14:42:11.484212 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.189635 (* 1 = 0.189635 loss)
I0526 14:42:11.484220 15394 sgd_solver.cpp:43] Iteration 61900, lr = 0.0002
I0526 14:42:16.512632 15394 main.cpp:354] Iteration 61910, loss = 0.203329
I0526 14:42:16.512670 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.203328 (* 1 = 0.203328 loss)
I0526 14:42:16.512676 15394 sgd_solver.cpp:43] Iteration 61910, lr = 0.0002
I0526 14:42:21.168460 15394 main.cpp:354] Iteration 61920, loss = 0.25235
I0526 14:42:21.168504 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.252349 (* 1 = 0.252349 loss)
I0526 14:42:21.168510 15394 sgd_solver.cpp:43] Iteration 61920, lr = 0.0002
I0526 14:42:26.412875 15394 main.cpp:354] Iteration 61930, loss = 0.205046
I0526 14:42:26.412909 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.205045 (* 1 = 0.205045 loss)
I0526 14:42:26.412915 15394 sgd_solver.cpp:43] Iteration 61930, lr = 0.0002
I0526 14:42:31.514248 15394 main.cpp:354] Iteration 61940, loss = 0.138724
I0526 14:42:31.514284 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.138723 (* 1 = 0.138723 loss)
I0526 14:42:31.514291 15394 sgd_solver.cpp:43] Iteration 61940, lr = 0.0002
I0526 14:42:36.652110 15394 main.cpp:354] Iteration 61950, loss = 0.129665
I0526 14:42:36.652151 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.129664 (* 1 = 0.129664 loss)
I0526 14:42:36.652158 15394 sgd_solver.cpp:43] Iteration 61950, lr = 0.0002
I0526 14:42:41.414784 15394 main.cpp:354] Iteration 61960, loss = 0.158774
I0526 14:42:41.414819 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.158773 (* 1 = 0.158773 loss)
I0526 14:42:41.414824 15394 sgd_solver.cpp:43] Iteration 61960, lr = 0.0002
I0526 14:42:46.279160 15394 main.cpp:354] Iteration 61970, loss = 0.441912
I0526 14:42:46.279193 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.441912 (* 1 = 0.441912 loss)
I0526 14:42:46.279199 15394 sgd_solver.cpp:43] Iteration 61970, lr = 0.0002
I0526 14:42:51.374481 15394 main.cpp:354] Iteration 61980, loss = 0.221845
I0526 14:42:51.374521 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.221844 (* 1 = 0.221844 loss)
I0526 14:42:51.374526 15394 sgd_solver.cpp:43] Iteration 61980, lr = 0.0002
I0526 14:42:56.381357 15394 main.cpp:354] Iteration 61990, loss = 0.102805
I0526 14:42:56.381392 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.102805 (* 1 = 0.102805 loss)
I0526 14:42:56.381398 15394 sgd_solver.cpp:43] Iteration 61990, lr = 0.0002
I0526 14:43:00.973517 15394 main.cpp:465] Iteration 62000, Testing net (#0)
I0526 14:43:14.063307 15394 main.cpp:532]     Test net output #0: Accuracy = 0.895
I0526 14:43:14.063344 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.334204 (* 1 = 0.334204 loss)
I0526 14:43:14.542095 15394 main.cpp:354] Iteration 62000, loss = 0.202852
I0526 14:43:14.542126 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.202851 (* 1 = 0.202851 loss)
I0526 14:43:14.542135 15394 sgd_solver.cpp:43] Iteration 62000, lr = 0.0002
I0526 14:43:19.858886 15394 main.cpp:354] Iteration 62010, loss = 0.171994
I0526 14:43:19.858925 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.171993 (* 1 = 0.171993 loss)
I0526 14:43:19.858932 15394 sgd_solver.cpp:43] Iteration 62010, lr = 0.0002
I0526 14:43:24.874857 15394 main.cpp:354] Iteration 62020, loss = 0.485743
I0526 14:43:24.874894 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.485742 (* 1 = 0.485742 loss)
I0526 14:43:24.874902 15394 sgd_solver.cpp:43] Iteration 62020, lr = 0.0002
I0526 14:43:29.929268 15394 main.cpp:354] Iteration 62030, loss = 0.167134
I0526 14:43:29.929302 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.167133 (* 1 = 0.167133 loss)
I0526 14:43:29.929308 15394 sgd_solver.cpp:43] Iteration 62030, lr = 0.0002
I0526 14:43:34.681457 15394 main.cpp:354] Iteration 62040, loss = 0.161344
I0526 14:43:34.681495 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.161343 (* 1 = 0.161343 loss)
I0526 14:43:34.681501 15394 sgd_solver.cpp:43] Iteration 62040, lr = 0.0002
I0526 14:43:39.619704 15394 main.cpp:354] Iteration 62050, loss = 0.283139
I0526 14:43:39.619740 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.283138 (* 1 = 0.283138 loss)
I0526 14:43:39.619746 15394 sgd_solver.cpp:43] Iteration 62050, lr = 0.0002
I0526 14:43:44.997552 15394 main.cpp:354] Iteration 62060, loss = 0.235747
I0526 14:43:44.997586 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.235747 (* 1 = 0.235747 loss)
I0526 14:43:44.997591 15394 sgd_solver.cpp:43] Iteration 62060, lr = 0.0002
I0526 14:43:50.063196 15394 main.cpp:354] Iteration 62070, loss = 0.126993
I0526 14:43:50.063236 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.126993 (* 1 = 0.126993 loss)
I0526 14:43:50.063243 15394 sgd_solver.cpp:43] Iteration 62070, lr = 0.0002
I0526 14:43:55.122185 15394 main.cpp:354] Iteration 62080, loss = 0.258629
I0526 14:43:55.122221 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.258628 (* 1 = 0.258628 loss)
I0526 14:43:55.122227 15394 sgd_solver.cpp:43] Iteration 62080, lr = 0.0002
I0526 14:43:59.253489 15394 main.cpp:354] Iteration 62090, loss = 0.163642
I0526 14:43:59.253525 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.163641 (* 1 = 0.163641 loss)
I0526 14:43:59.253530 15394 sgd_solver.cpp:43] Iteration 62090, lr = 0.0002
I0526 14:44:03.587702 15394 main.cpp:465] Iteration 62100, Testing net (#0)
I0526 14:44:16.682405 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8985
I0526 14:44:16.682443 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.329943 (* 1 = 0.329943 loss)
I0526 14:44:17.184882 15394 main.cpp:354] Iteration 62100, loss = 0.112894
I0526 14:44:17.184917 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.112893 (* 1 = 0.112893 loss)
I0526 14:44:17.184926 15394 sgd_solver.cpp:43] Iteration 62100, lr = 0.0002
I0526 14:44:22.132791 15394 main.cpp:354] Iteration 62110, loss = 0.459808
I0526 14:44:22.132832 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.459807 (* 1 = 0.459807 loss)
I0526 14:44:22.132838 15394 sgd_solver.cpp:43] Iteration 62110, lr = 0.0002
I0526 14:44:27.638779 15394 main.cpp:354] Iteration 62120, loss = 0.153407
I0526 14:44:27.638819 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.153406 (* 1 = 0.153406 loss)
I0526 14:44:27.638826 15394 sgd_solver.cpp:43] Iteration 62120, lr = 0.0002
I0526 14:44:32.886706 15394 main.cpp:354] Iteration 62130, loss = 0.110501
I0526 14:44:32.886742 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.1105 (* 1 = 0.1105 loss)
I0526 14:44:32.886749 15394 sgd_solver.cpp:43] Iteration 62130, lr = 0.0002
I0526 14:44:37.693866 15394 main.cpp:354] Iteration 62140, loss = 0.167576
I0526 14:44:37.693905 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.167575 (* 1 = 0.167575 loss)
I0526 14:44:37.693912 15394 sgd_solver.cpp:43] Iteration 62140, lr = 0.0002
I0526 14:44:42.421406 15394 main.cpp:354] Iteration 62150, loss = 0.244518
I0526 14:44:42.421453 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.244518 (* 1 = 0.244518 loss)
I0526 14:44:42.421459 15394 sgd_solver.cpp:43] Iteration 62150, lr = 0.0002
I0526 14:44:47.400354 15394 main.cpp:354] Iteration 62160, loss = 0.0964453
I0526 14:44:47.400391 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0964445 (* 1 = 0.0964445 loss)
I0526 14:44:47.400398 15394 sgd_solver.cpp:43] Iteration 62160, lr = 0.0002
I0526 14:44:52.280665 15394 main.cpp:354] Iteration 62170, loss = 0.16969
I0526 14:44:52.280709 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.16969 (* 1 = 0.16969 loss)
I0526 14:44:52.280715 15394 sgd_solver.cpp:43] Iteration 62170, lr = 0.0002
I0526 14:44:56.964340 15394 main.cpp:354] Iteration 62180, loss = 0.162464
I0526 14:44:56.964376 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.162463 (* 1 = 0.162463 loss)
I0526 14:44:56.964383 15394 sgd_solver.cpp:43] Iteration 62180, lr = 0.0002
I0526 14:45:02.134251 15394 main.cpp:354] Iteration 62190, loss = 0.21594
I0526 14:45:02.134287 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.215939 (* 1 = 0.215939 loss)
I0526 14:45:02.134294 15394 sgd_solver.cpp:43] Iteration 62190, lr = 0.0002
I0526 14:45:06.835850 15394 main.cpp:465] Iteration 62200, Testing net (#0)
I0526 14:45:19.924955 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8962
I0526 14:45:19.924995 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.332721 (* 1 = 0.332721 loss)
I0526 14:45:20.257401 15394 main.cpp:354] Iteration 62200, loss = 0.414926
I0526 14:45:20.257437 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.414926 (* 1 = 0.414926 loss)
I0526 14:45:20.257447 15394 sgd_solver.cpp:43] Iteration 62200, lr = 0.0002
I0526 14:45:25.415232 15394 main.cpp:354] Iteration 62210, loss = 0.0851143
I0526 14:45:25.415266 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0851136 (* 1 = 0.0851136 loss)
I0526 14:45:25.415272 15394 sgd_solver.cpp:43] Iteration 62210, lr = 0.0002
I0526 14:45:30.293011 15394 main.cpp:354] Iteration 62220, loss = 0.396906
I0526 14:45:30.293048 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.396905 (* 1 = 0.396905 loss)
I0526 14:45:30.293054 15394 sgd_solver.cpp:43] Iteration 62220, lr = 0.0002
I0526 14:45:35.509886 15394 main.cpp:354] Iteration 62230, loss = 0.100557
I0526 14:45:35.509927 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.100556 (* 1 = 0.100556 loss)
I0526 14:45:35.509934 15394 sgd_solver.cpp:43] Iteration 62230, lr = 0.0002
I0526 14:45:40.702849 15394 main.cpp:354] Iteration 62240, loss = 0.212366
I0526 14:45:40.702896 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.212365 (* 1 = 0.212365 loss)
I0526 14:45:40.702903 15394 sgd_solver.cpp:43] Iteration 62240, lr = 0.0002
I0526 14:45:45.923671 15394 main.cpp:354] Iteration 62250, loss = 0.203957
I0526 14:45:45.923708 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.203956 (* 1 = 0.203956 loss)
I0526 14:45:45.923714 15394 sgd_solver.cpp:43] Iteration 62250, lr = 0.0002
I0526 14:45:50.745564 15394 main.cpp:354] Iteration 62260, loss = 0.137286
I0526 14:45:50.745604 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.137285 (* 1 = 0.137285 loss)
I0526 14:45:50.745609 15394 sgd_solver.cpp:43] Iteration 62260, lr = 0.0002
I0526 14:45:55.730511 15394 main.cpp:354] Iteration 62270, loss = 0.208213
I0526 14:45:55.730546 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.208212 (* 1 = 0.208212 loss)
I0526 14:45:55.730553 15394 sgd_solver.cpp:43] Iteration 62270, lr = 0.0002
I0526 14:46:01.395390 15394 main.cpp:354] Iteration 62280, loss = 0.178468
I0526 14:46:01.395424 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.178467 (* 1 = 0.178467 loss)
I0526 14:46:01.395431 15394 sgd_solver.cpp:43] Iteration 62280, lr = 0.0002
I0526 14:46:06.414342 15394 main.cpp:354] Iteration 62290, loss = 0.228259
I0526 14:46:06.414387 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.228259 (* 1 = 0.228259 loss)
I0526 14:46:06.414394 15394 sgd_solver.cpp:43] Iteration 62290, lr = 0.0002
I0526 14:46:11.002384 15394 main.cpp:465] Iteration 62300, Testing net (#0)
I0526 14:46:24.104074 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8963
I0526 14:46:24.104115 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.3356 (* 1 = 0.3356 loss)
I0526 14:46:24.542318 15394 main.cpp:354] Iteration 62300, loss = 0.280957
I0526 14:46:24.542357 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.280956 (* 1 = 0.280956 loss)
I0526 14:46:24.542366 15394 sgd_solver.cpp:43] Iteration 62300, lr = 0.0002
I0526 14:46:29.429947 15394 main.cpp:354] Iteration 62310, loss = 0.155143
I0526 14:46:29.429987 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.155142 (* 1 = 0.155142 loss)
I0526 14:46:29.429994 15394 sgd_solver.cpp:43] Iteration 62310, lr = 0.0002
I0526 14:46:34.386082 15394 main.cpp:354] Iteration 62320, loss = 0.320325
I0526 14:46:34.386121 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.320325 (* 1 = 0.320325 loss)
I0526 14:46:34.386127 15394 sgd_solver.cpp:43] Iteration 62320, lr = 0.0002
I0526 14:46:39.376432 15394 main.cpp:354] Iteration 62330, loss = 0.430329
I0526 14:46:39.376471 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.430328 (* 1 = 0.430328 loss)
I0526 14:46:39.376478 15394 sgd_solver.cpp:43] Iteration 62330, lr = 0.0002
I0526 14:46:44.189400 15394 main.cpp:354] Iteration 62340, loss = 0.176351
I0526 14:46:44.189435 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.176351 (* 1 = 0.176351 loss)
I0526 14:46:44.189440 15394 sgd_solver.cpp:43] Iteration 62340, lr = 0.0002
I0526 14:46:49.086396 15394 main.cpp:354] Iteration 62350, loss = 0.140371
I0526 14:46:49.086434 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.140371 (* 1 = 0.140371 loss)
I0526 14:46:49.086441 15394 sgd_solver.cpp:43] Iteration 62350, lr = 0.0002
I0526 14:46:54.180174 15394 main.cpp:354] Iteration 62360, loss = 0.230471
I0526 14:46:54.180212 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.23047 (* 1 = 0.23047 loss)
I0526 14:46:54.180218 15394 sgd_solver.cpp:43] Iteration 62360, lr = 0.0002
I0526 14:46:59.509364 15394 main.cpp:354] Iteration 62370, loss = 0.136983
I0526 14:46:59.509399 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.136982 (* 1 = 0.136982 loss)
I0526 14:46:59.509405 15394 sgd_solver.cpp:43] Iteration 62370, lr = 0.0002
I0526 14:47:04.408561 15394 main.cpp:354] Iteration 62380, loss = 0.165295
I0526 14:47:04.408602 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.165294 (* 1 = 0.165294 loss)
I0526 14:47:04.408609 15394 sgd_solver.cpp:43] Iteration 62380, lr = 0.0002
I0526 14:47:09.220533 15394 main.cpp:354] Iteration 62390, loss = 0.324077
I0526 14:47:09.220571 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.324077 (* 1 = 0.324077 loss)
I0526 14:47:09.220577 15394 sgd_solver.cpp:43] Iteration 62390, lr = 0.0002
I0526 14:47:13.728391 15394 main.cpp:465] Iteration 62400, Testing net (#0)
I0526 14:47:26.837193 15394 main.cpp:532]     Test net output #0: Accuracy = 0.898
I0526 14:47:26.837230 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.331849 (* 1 = 0.331849 loss)
I0526 14:47:27.303539 15394 main.cpp:354] Iteration 62400, loss = 0.232409
I0526 14:47:27.303570 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.232409 (* 1 = 0.232409 loss)
I0526 14:47:27.303578 15394 sgd_solver.cpp:43] Iteration 62400, lr = 0.0002
I0526 14:47:32.123612 15394 main.cpp:354] Iteration 62410, loss = 0.347089
I0526 14:47:32.123646 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.347089 (* 1 = 0.347089 loss)
I0526 14:47:32.123651 15394 sgd_solver.cpp:43] Iteration 62410, lr = 0.0002
I0526 14:47:37.354080 15394 main.cpp:354] Iteration 62420, loss = 0.133592
I0526 14:47:37.354118 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.133592 (* 1 = 0.133592 loss)
I0526 14:47:37.354125 15394 sgd_solver.cpp:43] Iteration 62420, lr = 0.0002
I0526 14:47:42.079150 15394 main.cpp:354] Iteration 62430, loss = 0.227402
I0526 14:47:42.079185 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.227401 (* 1 = 0.227401 loss)
I0526 14:47:42.079191 15394 sgd_solver.cpp:43] Iteration 62430, lr = 0.0002
I0526 14:47:47.169443 15394 main.cpp:354] Iteration 62440, loss = 0.344449
I0526 14:47:47.169479 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.344448 (* 1 = 0.344448 loss)
I0526 14:47:47.169486 15394 sgd_solver.cpp:43] Iteration 62440, lr = 0.0002
I0526 14:47:52.488173 15394 main.cpp:354] Iteration 62450, loss = 0.188007
I0526 14:47:52.488211 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.188006 (* 1 = 0.188006 loss)
I0526 14:47:52.488225 15394 sgd_solver.cpp:43] Iteration 62450, lr = 0.0002
I0526 14:47:57.697356 15394 main.cpp:354] Iteration 62460, loss = 0.24227
I0526 14:47:57.697392 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.24227 (* 1 = 0.24227 loss)
I0526 14:47:57.697398 15394 sgd_solver.cpp:43] Iteration 62460, lr = 0.0002
I0526 14:48:02.359843 15394 main.cpp:354] Iteration 62470, loss = 0.16539
I0526 14:48:02.359876 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.165389 (* 1 = 0.165389 loss)
I0526 14:48:02.359882 15394 sgd_solver.cpp:43] Iteration 62470, lr = 0.0002
I0526 14:48:07.448176 15394 main.cpp:354] Iteration 62480, loss = 0.209663
I0526 14:48:07.448216 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.209662 (* 1 = 0.209662 loss)
I0526 14:48:07.448222 15394 sgd_solver.cpp:43] Iteration 62480, lr = 0.0002
I0526 14:48:12.318739 15394 main.cpp:354] Iteration 62490, loss = 0.473412
I0526 14:48:12.318774 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.473411 (* 1 = 0.473411 loss)
I0526 14:48:12.318780 15394 sgd_solver.cpp:43] Iteration 62490, lr = 0.0002
I0526 14:48:17.212937 15394 main.cpp:465] Iteration 62500, Testing net (#0)
I0526 14:48:30.327742 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8981
I0526 14:48:30.327783 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.329957 (* 1 = 0.329957 loss)
I0526 14:48:30.872526 15394 main.cpp:354] Iteration 62500, loss = 0.102244
I0526 14:48:30.872556 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.102243 (* 1 = 0.102243 loss)
I0526 14:48:30.872565 15394 sgd_solver.cpp:43] Iteration 62500, lr = 0.0002
I0526 14:48:36.337304 15394 main.cpp:354] Iteration 62510, loss = 0.180378
I0526 14:48:36.337343 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.180378 (* 1 = 0.180378 loss)
I0526 14:48:36.337350 15394 sgd_solver.cpp:43] Iteration 62510, lr = 0.0002
I0526 14:48:41.389915 15394 main.cpp:354] Iteration 62520, loss = 0.451827
I0526 14:48:41.389952 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.451826 (* 1 = 0.451826 loss)
I0526 14:48:41.389958 15394 sgd_solver.cpp:43] Iteration 62520, lr = 0.0002
I0526 14:48:45.746573 15394 main.cpp:354] Iteration 62530, loss = 0.213957
I0526 14:48:45.746613 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.213956 (* 1 = 0.213956 loss)
I0526 14:48:45.746619 15394 sgd_solver.cpp:43] Iteration 62530, lr = 0.0002
I0526 14:48:50.468477 15394 main.cpp:354] Iteration 62540, loss = 0.168015
I0526 14:48:50.468515 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.168015 (* 1 = 0.168015 loss)
I0526 14:48:50.468521 15394 sgd_solver.cpp:43] Iteration 62540, lr = 0.0002
I0526 14:48:55.290066 15394 main.cpp:354] Iteration 62550, loss = 0.204484
I0526 14:48:55.290102 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.204484 (* 1 = 0.204484 loss)
I0526 14:48:55.290107 15394 sgd_solver.cpp:43] Iteration 62550, lr = 0.0002
I0526 14:48:59.656131 15394 main.cpp:354] Iteration 62560, loss = 0.119008
I0526 14:48:59.656168 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.119007 (* 1 = 0.119007 loss)
I0526 14:48:59.656174 15394 sgd_solver.cpp:43] Iteration 62560, lr = 0.0002
I0526 14:49:05.046694 15394 main.cpp:354] Iteration 62570, loss = 0.131825
I0526 14:49:05.046735 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.131824 (* 1 = 0.131824 loss)
I0526 14:49:05.046741 15394 sgd_solver.cpp:43] Iteration 62570, lr = 0.0002
I0526 14:49:10.479478 15394 main.cpp:354] Iteration 62580, loss = 0.107855
I0526 14:49:10.479514 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.107854 (* 1 = 0.107854 loss)
I0526 14:49:10.479521 15394 sgd_solver.cpp:43] Iteration 62580, lr = 0.0002
I0526 14:49:15.404306 15394 main.cpp:354] Iteration 62590, loss = 0.146174
I0526 14:49:15.404343 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.146174 (* 1 = 0.146174 loss)
I0526 14:49:15.404348 15394 sgd_solver.cpp:43] Iteration 62590, lr = 0.0002
I0526 14:49:19.878146 15394 main.cpp:465] Iteration 62600, Testing net (#0)
I0526 14:49:32.969241 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8972
I0526 14:49:32.969276 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.332735 (* 1 = 0.332735 loss)
I0526 14:49:33.483430 15394 main.cpp:354] Iteration 62600, loss = 0.10455
I0526 14:49:33.483463 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.10455 (* 1 = 0.10455 loss)
I0526 14:49:33.483469 15394 sgd_solver.cpp:43] Iteration 62600, lr = 0.0002
I0526 14:49:38.216141 15394 main.cpp:354] Iteration 62610, loss = 0.164415
I0526 14:49:38.216181 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.164414 (* 1 = 0.164414 loss)
I0526 14:49:38.216187 15394 sgd_solver.cpp:43] Iteration 62610, lr = 0.0002
I0526 14:49:42.964448 15394 main.cpp:354] Iteration 62620, loss = 0.269836
I0526 14:49:42.964483 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.269835 (* 1 = 0.269835 loss)
I0526 14:49:42.964488 15394 sgd_solver.cpp:43] Iteration 62620, lr = 0.0002
I0526 14:49:48.006391 15394 main.cpp:354] Iteration 62630, loss = 0.172361
I0526 14:49:48.006425 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.17236 (* 1 = 0.17236 loss)
I0526 14:49:48.006433 15394 sgd_solver.cpp:43] Iteration 62630, lr = 0.0002
I0526 14:49:53.013515 15394 main.cpp:354] Iteration 62640, loss = 0.243682
I0526 14:49:53.013556 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.243681 (* 1 = 0.243681 loss)
I0526 14:49:53.013561 15394 sgd_solver.cpp:43] Iteration 62640, lr = 0.0002
I0526 14:49:57.739929 15394 main.cpp:354] Iteration 62650, loss = 0.215007
I0526 14:49:57.739974 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.215006 (* 1 = 0.215006 loss)
I0526 14:49:57.739979 15394 sgd_solver.cpp:43] Iteration 62650, lr = 0.0002
I0526 14:50:02.650859 15394 main.cpp:354] Iteration 62660, loss = 0.322887
I0526 14:50:02.650894 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.322886 (* 1 = 0.322886 loss)
I0526 14:50:02.650900 15394 sgd_solver.cpp:43] Iteration 62660, lr = 0.0002
I0526 14:50:07.812623 15394 main.cpp:354] Iteration 62670, loss = 0.370684
I0526 14:50:07.812659 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.370683 (* 1 = 0.370683 loss)
I0526 14:50:07.812666 15394 sgd_solver.cpp:43] Iteration 62670, lr = 0.0002
I0526 14:50:12.994252 15394 main.cpp:354] Iteration 62680, loss = 0.170524
I0526 14:50:12.994287 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.170524 (* 1 = 0.170524 loss)
I0526 14:50:12.994293 15394 sgd_solver.cpp:43] Iteration 62680, lr = 0.0002
I0526 14:50:17.847496 15394 main.cpp:354] Iteration 62690, loss = 0.22145
I0526 14:50:17.847532 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.22145 (* 1 = 0.22145 loss)
I0526 14:50:17.847538 15394 sgd_solver.cpp:43] Iteration 62690, lr = 0.0002
I0526 14:50:22.365056 15394 main.cpp:465] Iteration 62700, Testing net (#0)
I0526 14:50:35.462230 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8972
I0526 14:50:35.462270 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.328434 (* 1 = 0.328434 loss)
I0526 14:50:36.002965 15394 main.cpp:354] Iteration 62700, loss = 0.206284
I0526 14:50:36.003001 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.206283 (* 1 = 0.206283 loss)
I0526 14:50:36.003010 15394 sgd_solver.cpp:43] Iteration 62700, lr = 0.0002
I0526 14:50:41.124078 15394 main.cpp:354] Iteration 62710, loss = 0.241458
I0526 14:50:41.124114 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.241457 (* 1 = 0.241457 loss)
I0526 14:50:41.124119 15394 sgd_solver.cpp:43] Iteration 62710, lr = 0.0002
I0526 14:50:45.894166 15394 main.cpp:354] Iteration 62720, loss = 0.132682
I0526 14:50:45.894204 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.132681 (* 1 = 0.132681 loss)
I0526 14:50:45.894212 15394 sgd_solver.cpp:43] Iteration 62720, lr = 0.0002
I0526 14:50:50.918998 15394 main.cpp:354] Iteration 62730, loss = 0.452244
I0526 14:50:50.919042 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.452244 (* 1 = 0.452244 loss)
I0526 14:50:50.919049 15394 sgd_solver.cpp:43] Iteration 62730, lr = 0.0002
I0526 14:50:55.547855 15394 main.cpp:354] Iteration 62740, loss = 0.400302
I0526 14:50:55.547889 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.400301 (* 1 = 0.400301 loss)
I0526 14:50:55.547895 15394 sgd_solver.cpp:43] Iteration 62740, lr = 0.0002
I0526 14:51:00.502812 15394 main.cpp:354] Iteration 62750, loss = 0.215485
I0526 14:51:00.502847 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.215484 (* 1 = 0.215484 loss)
I0526 14:51:00.502854 15394 sgd_solver.cpp:43] Iteration 62750, lr = 0.0002
I0526 14:51:05.625972 15394 main.cpp:354] Iteration 62760, loss = 0.242127
I0526 14:51:05.626011 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.242126 (* 1 = 0.242126 loss)
I0526 14:51:05.626018 15394 sgd_solver.cpp:43] Iteration 62760, lr = 0.0002
I0526 14:51:10.577054 15394 main.cpp:354] Iteration 62770, loss = 0.259479
I0526 14:51:10.577090 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.259478 (* 1 = 0.259478 loss)
I0526 14:51:10.577095 15394 sgd_solver.cpp:43] Iteration 62770, lr = 0.0002
I0526 14:51:15.897754 15394 main.cpp:354] Iteration 62780, loss = 0.311999
I0526 14:51:15.897789 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.311999 (* 1 = 0.311999 loss)
I0526 14:51:15.897795 15394 sgd_solver.cpp:43] Iteration 62780, lr = 0.0002
I0526 14:51:21.218118 15394 main.cpp:354] Iteration 62790, loss = 0.186854
I0526 14:51:21.218158 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.186853 (* 1 = 0.186853 loss)
I0526 14:51:21.218164 15394 sgd_solver.cpp:43] Iteration 62790, lr = 0.0002
I0526 14:51:25.948379 15394 main.cpp:465] Iteration 62800, Testing net (#0)
I0526 14:51:39.046596 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8973
I0526 14:51:39.046633 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.333818 (* 1 = 0.333818 loss)
I0526 14:51:39.586544 15394 main.cpp:354] Iteration 62800, loss = 0.124027
I0526 14:51:39.586575 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.124026 (* 1 = 0.124026 loss)
I0526 14:51:39.586582 15394 sgd_solver.cpp:43] Iteration 62800, lr = 0.0002
I0526 14:51:44.822751 15394 main.cpp:354] Iteration 62810, loss = 0.816959
I0526 14:51:44.822788 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.816958 (* 1 = 0.816958 loss)
I0526 14:51:44.822794 15394 sgd_solver.cpp:43] Iteration 62810, lr = 0.0002
I0526 14:51:49.728912 15394 main.cpp:354] Iteration 62820, loss = 0.306972
I0526 14:51:49.728961 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.306972 (* 1 = 0.306972 loss)
I0526 14:51:49.728967 15394 sgd_solver.cpp:43] Iteration 62820, lr = 0.0002
I0526 14:51:54.535750 15394 main.cpp:354] Iteration 62830, loss = 0.19171
I0526 14:51:54.535786 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.191709 (* 1 = 0.191709 loss)
I0526 14:51:54.535792 15394 sgd_solver.cpp:43] Iteration 62830, lr = 0.0002
I0526 14:51:59.596014 15394 main.cpp:354] Iteration 62840, loss = 0.117928
I0526 14:51:59.596050 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.117927 (* 1 = 0.117927 loss)
I0526 14:51:59.596055 15394 sgd_solver.cpp:43] Iteration 62840, lr = 0.0002
I0526 14:52:04.373045 15394 main.cpp:354] Iteration 62850, loss = 0.124346
I0526 14:52:04.373085 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.124346 (* 1 = 0.124346 loss)
I0526 14:52:04.373093 15394 sgd_solver.cpp:43] Iteration 62850, lr = 0.0002
I0526 14:52:09.581754 15394 main.cpp:354] Iteration 62860, loss = 0.143738
I0526 14:52:09.581791 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.143738 (* 1 = 0.143738 loss)
I0526 14:52:09.581797 15394 sgd_solver.cpp:43] Iteration 62860, lr = 0.0002
I0526 14:52:15.178344 15394 main.cpp:354] Iteration 62870, loss = 0.0871614
I0526 14:52:15.178388 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0871606 (* 1 = 0.0871606 loss)
I0526 14:52:15.178395 15394 sgd_solver.cpp:43] Iteration 62870, lr = 0.0002
I0526 14:52:19.994204 15394 main.cpp:354] Iteration 62880, loss = 0.270665
I0526 14:52:19.994243 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.270665 (* 1 = 0.270665 loss)
I0526 14:52:19.994249 15394 sgd_solver.cpp:43] Iteration 62880, lr = 0.0002
I0526 14:52:25.165024 15394 main.cpp:354] Iteration 62890, loss = 0.426198
I0526 14:52:25.165061 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.426197 (* 1 = 0.426197 loss)
I0526 14:52:25.165067 15394 sgd_solver.cpp:43] Iteration 62890, lr = 0.0002
I0526 14:52:29.961473 15394 main.cpp:465] Iteration 62900, Testing net (#0)
I0526 14:52:43.049093 15394 main.cpp:532]     Test net output #0: Accuracy = 0.898
I0526 14:52:43.049131 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.330564 (* 1 = 0.330564 loss)
I0526 14:52:43.591181 15394 main.cpp:354] Iteration 62900, loss = 0.179501
I0526 14:52:43.591217 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.179501 (* 1 = 0.179501 loss)
I0526 14:52:43.591225 15394 sgd_solver.cpp:43] Iteration 62900, lr = 0.0002
I0526 14:52:48.555963 15394 main.cpp:354] Iteration 62910, loss = 0.0861111
I0526 14:52:48.555997 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0861105 (* 1 = 0.0861105 loss)
I0526 14:52:48.556005 15394 sgd_solver.cpp:43] Iteration 62910, lr = 0.0002
I0526 14:52:53.816906 15394 main.cpp:354] Iteration 62920, loss = 0.289768
I0526 14:52:53.816942 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.289768 (* 1 = 0.289768 loss)
I0526 14:52:53.816948 15394 sgd_solver.cpp:43] Iteration 62920, lr = 0.0002
I0526 14:52:59.055536 15394 main.cpp:354] Iteration 62930, loss = 0.261785
I0526 14:52:59.055573 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.261784 (* 1 = 0.261784 loss)
I0526 14:52:59.055579 15394 sgd_solver.cpp:43] Iteration 62930, lr = 0.0002
I0526 14:53:04.312600 15394 main.cpp:354] Iteration 62940, loss = 0.145412
I0526 14:53:04.312640 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.145411 (* 1 = 0.145411 loss)
I0526 14:53:04.312647 15394 sgd_solver.cpp:43] Iteration 62940, lr = 0.0002
I0526 14:53:09.504580 15394 main.cpp:354] Iteration 62950, loss = 0.232853
I0526 14:53:09.504617 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.232852 (* 1 = 0.232852 loss)
I0526 14:53:09.504623 15394 sgd_solver.cpp:43] Iteration 62950, lr = 0.0002
I0526 14:53:14.759176 15394 main.cpp:354] Iteration 62960, loss = 0.192601
I0526 14:53:14.759208 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.1926 (* 1 = 0.1926 loss)
I0526 14:53:14.759214 15394 sgd_solver.cpp:43] Iteration 62960, lr = 0.0002
I0526 14:53:19.983367 15394 main.cpp:354] Iteration 62970, loss = 0.229661
I0526 14:53:19.983405 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.22966 (* 1 = 0.22966 loss)
I0526 14:53:19.983412 15394 sgd_solver.cpp:43] Iteration 62970, lr = 0.0002
I0526 14:53:25.091102 15394 main.cpp:354] Iteration 62980, loss = 0.298543
I0526 14:53:25.091141 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.298542 (* 1 = 0.298542 loss)
I0526 14:53:25.091147 15394 sgd_solver.cpp:43] Iteration 62980, lr = 0.0002
I0526 14:53:30.235281 15394 main.cpp:354] Iteration 62990, loss = 0.217805
I0526 14:53:30.235319 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.217804 (* 1 = 0.217804 loss)
I0526 14:53:30.235326 15394 sgd_solver.cpp:43] Iteration 62990, lr = 0.0002
I0526 14:53:34.690419 15394 main.cpp:465] Iteration 63000, Testing net (#0)
I0526 14:53:47.784479 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8958
I0526 14:53:47.784513 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.331334 (* 1 = 0.331334 loss)
I0526 14:53:48.255947 15394 main.cpp:354] Iteration 63000, loss = 0.133632
I0526 14:53:48.255983 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.133631 (* 1 = 0.133631 loss)
I0526 14:53:48.255996 15394 sgd_solver.cpp:43] Iteration 63000, lr = 0.0002
I0526 14:53:53.302961 15394 main.cpp:354] Iteration 63010, loss = 0.228446
I0526 14:53:53.303000 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.228445 (* 1 = 0.228445 loss)
I0526 14:53:53.303006 15394 sgd_solver.cpp:43] Iteration 63010, lr = 0.0002
I0526 14:53:58.799590 15394 main.cpp:354] Iteration 63020, loss = 0.225548
I0526 14:53:58.799628 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.225547 (* 1 = 0.225547 loss)
I0526 14:53:58.799633 15394 sgd_solver.cpp:43] Iteration 63020, lr = 0.0002
I0526 14:54:03.755339 15394 main.cpp:354] Iteration 63030, loss = 0.15811
I0526 14:54:03.755375 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.158109 (* 1 = 0.158109 loss)
I0526 14:54:03.755383 15394 sgd_solver.cpp:43] Iteration 63030, lr = 0.0002
I0526 14:54:08.990044 15394 main.cpp:354] Iteration 63040, loss = 0.198994
I0526 14:54:08.990092 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.198993 (* 1 = 0.198993 loss)
I0526 14:54:08.990098 15394 sgd_solver.cpp:43] Iteration 63040, lr = 0.0002
I0526 14:54:14.903565 15394 main.cpp:354] Iteration 63050, loss = 0.322811
I0526 14:54:14.903600 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.32281 (* 1 = 0.32281 loss)
I0526 14:54:14.903616 15394 sgd_solver.cpp:43] Iteration 63050, lr = 0.0002
I0526 14:54:20.020179 15394 main.cpp:354] Iteration 63060, loss = 0.225682
I0526 14:54:20.020218 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.225681 (* 1 = 0.225681 loss)
I0526 14:54:20.020225 15394 sgd_solver.cpp:43] Iteration 63060, lr = 0.0002
I0526 14:54:25.113217 15394 main.cpp:354] Iteration 63070, loss = 0.276836
I0526 14:54:25.113253 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.276836 (* 1 = 0.276836 loss)
I0526 14:54:25.113260 15394 sgd_solver.cpp:43] Iteration 63070, lr = 0.0002
I0526 14:54:30.118929 15394 main.cpp:354] Iteration 63080, loss = 0.300942
I0526 14:54:30.118975 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.300942 (* 1 = 0.300942 loss)
I0526 14:54:30.118981 15394 sgd_solver.cpp:43] Iteration 63080, lr = 0.0002
I0526 14:54:35.117650 15394 main.cpp:354] Iteration 63090, loss = 0.255422
I0526 14:54:35.117691 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.255422 (* 1 = 0.255422 loss)
I0526 14:54:35.117698 15394 sgd_solver.cpp:43] Iteration 63090, lr = 0.0002
I0526 14:54:39.736248 15394 main.cpp:465] Iteration 63100, Testing net (#0)
I0526 14:54:52.829479 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8977
I0526 14:54:52.829522 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.329585 (* 1 = 0.329585 loss)
I0526 14:54:53.302845 15394 main.cpp:354] Iteration 63100, loss = 0.262921
I0526 14:54:53.302881 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.26292 (* 1 = 0.26292 loss)
I0526 14:54:53.302889 15394 sgd_solver.cpp:43] Iteration 63100, lr = 0.0002
I0526 14:54:58.429241 15394 main.cpp:354] Iteration 63110, loss = 0.149621
I0526 14:54:58.429278 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.14962 (* 1 = 0.14962 loss)
I0526 14:54:58.429285 15394 sgd_solver.cpp:43] Iteration 63110, lr = 0.0002
I0526 14:55:03.309078 15394 main.cpp:354] Iteration 63120, loss = 0.112837
I0526 14:55:03.309115 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.112836 (* 1 = 0.112836 loss)
I0526 14:55:03.309120 15394 sgd_solver.cpp:43] Iteration 63120, lr = 0.0002
I0526 14:55:08.329097 15394 main.cpp:354] Iteration 63130, loss = 0.23085
I0526 14:55:08.329138 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.23085 (* 1 = 0.23085 loss)
I0526 14:55:08.329144 15394 sgd_solver.cpp:43] Iteration 63130, lr = 0.0002
I0526 14:55:13.342651 15394 main.cpp:354] Iteration 63140, loss = 0.275738
I0526 14:55:13.342684 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.275738 (* 1 = 0.275738 loss)
I0526 14:55:13.342691 15394 sgd_solver.cpp:43] Iteration 63140, lr = 0.0002
I0526 14:55:18.161681 15394 main.cpp:354] Iteration 63150, loss = 1.03238
I0526 14:55:18.161718 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 1.03238 (* 1 = 1.03238 loss)
I0526 14:55:18.161725 15394 sgd_solver.cpp:43] Iteration 63150, lr = 0.0002
I0526 14:55:23.455941 15394 main.cpp:354] Iteration 63160, loss = 0.124047
I0526 14:55:23.455982 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.124046 (* 1 = 0.124046 loss)
I0526 14:55:23.455988 15394 sgd_solver.cpp:43] Iteration 63160, lr = 0.0002
I0526 14:55:28.571187 15394 main.cpp:354] Iteration 63170, loss = 0.351236
I0526 14:55:28.571218 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.351235 (* 1 = 0.351235 loss)
I0526 14:55:28.571224 15394 sgd_solver.cpp:43] Iteration 63170, lr = 0.0002
I0526 14:55:33.531739 15394 main.cpp:354] Iteration 63180, loss = 0.200134
I0526 14:55:33.531775 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.200133 (* 1 = 0.200133 loss)
I0526 14:55:33.531781 15394 sgd_solver.cpp:43] Iteration 63180, lr = 0.0002
I0526 14:55:38.843008 15394 main.cpp:354] Iteration 63190, loss = 0.134371
I0526 14:55:38.843047 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.13437 (* 1 = 0.13437 loss)
I0526 14:55:38.843053 15394 sgd_solver.cpp:43] Iteration 63190, lr = 0.0002
I0526 14:55:43.233722 15394 main.cpp:465] Iteration 63200, Testing net (#0)
I0526 14:55:56.327689 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8963
I0526 14:55:56.327726 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.333826 (* 1 = 0.333826 loss)
I0526 14:55:56.764163 15394 main.cpp:354] Iteration 63200, loss = 0.218915
I0526 14:55:56.764194 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.218915 (* 1 = 0.218915 loss)
I0526 14:55:56.764202 15394 sgd_solver.cpp:43] Iteration 63200, lr = 0.0002
I0526 14:56:02.029367 15394 main.cpp:354] Iteration 63210, loss = 0.288321
I0526 14:56:02.029402 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.288321 (* 1 = 0.288321 loss)
I0526 14:56:02.029408 15394 sgd_solver.cpp:43] Iteration 63210, lr = 0.0002
I0526 14:56:06.800082 15394 main.cpp:354] Iteration 63220, loss = 0.165557
I0526 14:56:06.800124 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.165557 (* 1 = 0.165557 loss)
I0526 14:56:06.800132 15394 sgd_solver.cpp:43] Iteration 63220, lr = 0.0002
I0526 14:56:11.913600 15394 main.cpp:354] Iteration 63230, loss = 0.168064
I0526 14:56:11.913640 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.168063 (* 1 = 0.168063 loss)
I0526 14:56:11.913646 15394 sgd_solver.cpp:43] Iteration 63230, lr = 0.0002
I0526 14:56:17.008803 15394 main.cpp:354] Iteration 63240, loss = 0.200977
I0526 14:56:17.008836 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.200976 (* 1 = 0.200976 loss)
I0526 14:56:17.008841 15394 sgd_solver.cpp:43] Iteration 63240, lr = 0.0002
I0526 14:56:21.639715 15394 main.cpp:354] Iteration 63250, loss = 0.210585
I0526 14:56:21.639756 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.210584 (* 1 = 0.210584 loss)
I0526 14:56:21.639762 15394 sgd_solver.cpp:43] Iteration 63250, lr = 0.0002
I0526 14:56:26.775713 15394 main.cpp:354] Iteration 63260, loss = 0.138106
I0526 14:56:26.775751 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.138105 (* 1 = 0.138105 loss)
I0526 14:56:26.775758 15394 sgd_solver.cpp:43] Iteration 63260, lr = 0.0002
I0526 14:56:32.435650 15394 main.cpp:354] Iteration 63270, loss = 0.0769862
I0526 14:56:32.435685 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0769856 (* 1 = 0.0769856 loss)
I0526 14:56:32.435693 15394 sgd_solver.cpp:43] Iteration 63270, lr = 0.0002
I0526 14:56:37.829826 15394 main.cpp:354] Iteration 63280, loss = 0.17817
I0526 14:56:37.829864 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.17817 (* 1 = 0.17817 loss)
I0526 14:56:37.829870 15394 sgd_solver.cpp:43] Iteration 63280, lr = 0.0002
I0526 14:56:42.923445 15394 main.cpp:354] Iteration 63290, loss = 0.215409
I0526 14:56:42.923487 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.215409 (* 1 = 0.215409 loss)
I0526 14:56:42.923493 15394 sgd_solver.cpp:43] Iteration 63290, lr = 0.0002
I0526 14:56:47.369789 15394 main.cpp:465] Iteration 63300, Testing net (#0)
I0526 14:57:00.473554 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8963
I0526 14:57:00.473594 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.333437 (* 1 = 0.333437 loss)
I0526 14:57:01.054008 15394 main.cpp:354] Iteration 63300, loss = 0.0988518
I0526 14:57:01.054044 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0988512 (* 1 = 0.0988512 loss)
I0526 14:57:01.054052 15394 sgd_solver.cpp:43] Iteration 63300, lr = 0.0002
I0526 14:57:05.898089 15394 main.cpp:354] Iteration 63310, loss = 0.318482
I0526 14:57:05.898140 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.318482 (* 1 = 0.318482 loss)
I0526 14:57:05.898146 15394 sgd_solver.cpp:43] Iteration 63310, lr = 0.0002
I0526 14:57:11.019980 15394 main.cpp:354] Iteration 63320, loss = 0.310349
I0526 14:57:11.020014 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.310348 (* 1 = 0.310348 loss)
I0526 14:57:11.020020 15394 sgd_solver.cpp:43] Iteration 63320, lr = 0.0002
I0526 14:57:15.928084 15394 main.cpp:354] Iteration 63330, loss = 0.187962
I0526 14:57:15.928123 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.187961 (* 1 = 0.187961 loss)
I0526 14:57:15.928129 15394 sgd_solver.cpp:43] Iteration 63330, lr = 0.0002
I0526 14:57:21.045243 15394 main.cpp:354] Iteration 63340, loss = 0.220083
I0526 14:57:21.045291 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.220082 (* 1 = 0.220082 loss)
I0526 14:57:21.045298 15394 sgd_solver.cpp:43] Iteration 63340, lr = 0.0002
I0526 14:57:26.371071 15394 main.cpp:354] Iteration 63350, loss = 0.111898
I0526 14:57:26.371109 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.111897 (* 1 = 0.111897 loss)
I0526 14:57:26.371114 15394 sgd_solver.cpp:43] Iteration 63350, lr = 0.0002
I0526 14:57:31.414729 15394 main.cpp:354] Iteration 63360, loss = 0.261498
I0526 14:57:31.414767 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.261497 (* 1 = 0.261497 loss)
I0526 14:57:31.414773 15394 sgd_solver.cpp:43] Iteration 63360, lr = 0.0002
I0526 14:57:36.451212 15394 main.cpp:354] Iteration 63370, loss = 0.203377
I0526 14:57:36.451251 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.203376 (* 1 = 0.203376 loss)
I0526 14:57:36.451257 15394 sgd_solver.cpp:43] Iteration 63370, lr = 0.0002
I0526 14:57:41.333413 15394 main.cpp:354] Iteration 63380, loss = 0.445244
I0526 14:57:41.333447 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.445244 (* 1 = 0.445244 loss)
I0526 14:57:41.333453 15394 sgd_solver.cpp:43] Iteration 63380, lr = 0.0002
I0526 14:57:46.490921 15394 main.cpp:354] Iteration 63390, loss = 0.0949287
I0526 14:57:46.490954 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0949281 (* 1 = 0.0949281 loss)
I0526 14:57:46.490962 15394 sgd_solver.cpp:43] Iteration 63390, lr = 0.0002
I0526 14:57:50.960818 15394 main.cpp:465] Iteration 63400, Testing net (#0)
I0526 14:58:04.066045 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8963
I0526 14:58:04.066078 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.325285 (* 1 = 0.325285 loss)
I0526 14:58:04.535809 15394 main.cpp:354] Iteration 63400, loss = 0.254343
I0526 14:58:04.535841 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.254342 (* 1 = 0.254342 loss)
I0526 14:58:04.535848 15394 sgd_solver.cpp:43] Iteration 63400, lr = 0.0002
I0526 14:58:09.857902 15394 main.cpp:354] Iteration 63410, loss = 0.184048
I0526 14:58:09.857950 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.184048 (* 1 = 0.184048 loss)
I0526 14:58:09.857956 15394 sgd_solver.cpp:43] Iteration 63410, lr = 0.0002
I0526 14:58:14.583765 15394 main.cpp:354] Iteration 63420, loss = 0.090395
I0526 14:58:14.583807 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0903944 (* 1 = 0.0903944 loss)
I0526 14:58:14.583814 15394 sgd_solver.cpp:43] Iteration 63420, lr = 0.0002
I0526 14:58:19.973316 15394 main.cpp:354] Iteration 63430, loss = 0.239343
I0526 14:58:19.973356 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.239343 (* 1 = 0.239343 loss)
I0526 14:58:19.973362 15394 sgd_solver.cpp:43] Iteration 63430, lr = 0.0002
I0526 14:58:24.839526 15394 main.cpp:354] Iteration 63440, loss = 0.252167
I0526 14:58:24.839561 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.252166 (* 1 = 0.252166 loss)
I0526 14:58:24.839567 15394 sgd_solver.cpp:43] Iteration 63440, lr = 0.0002
I0526 14:58:29.458802 15394 main.cpp:354] Iteration 63450, loss = 0.224157
I0526 14:58:29.458838 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.224157 (* 1 = 0.224157 loss)
I0526 14:58:29.458844 15394 sgd_solver.cpp:43] Iteration 63450, lr = 0.0002
I0526 14:58:34.652271 15394 main.cpp:354] Iteration 63460, loss = 0.229255
I0526 14:58:34.652309 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.229254 (* 1 = 0.229254 loss)
I0526 14:58:34.652318 15394 sgd_solver.cpp:43] Iteration 63460, lr = 0.0002
I0526 14:58:39.345671 15394 main.cpp:354] Iteration 63470, loss = 0.834595
I0526 14:58:39.345705 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.834594 (* 1 = 0.834594 loss)
I0526 14:58:39.345711 15394 sgd_solver.cpp:43] Iteration 63470, lr = 0.0002
I0526 14:58:44.526082 15394 main.cpp:354] Iteration 63480, loss = 0.210581
I0526 14:58:44.526119 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.21058 (* 1 = 0.21058 loss)
I0526 14:58:44.526125 15394 sgd_solver.cpp:43] Iteration 63480, lr = 0.0002
I0526 14:58:49.456009 15394 main.cpp:354] Iteration 63490, loss = 0.227005
I0526 14:58:49.456051 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.227004 (* 1 = 0.227004 loss)
I0526 14:58:49.456058 15394 sgd_solver.cpp:43] Iteration 63490, lr = 0.0002
I0526 14:58:53.888603 15394 main.cpp:465] Iteration 63500, Testing net (#0)
I0526 14:59:06.985249 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8967
I0526 14:59:06.985288 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.331969 (* 1 = 0.331969 loss)
I0526 14:59:07.487342 15394 main.cpp:354] Iteration 63500, loss = 0.0517677
I0526 14:59:07.487375 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0517671 (* 1 = 0.0517671 loss)
I0526 14:59:07.487383 15394 sgd_solver.cpp:43] Iteration 63500, lr = 0.0002
I0526 14:59:12.681036 15394 main.cpp:354] Iteration 63510, loss = 0.148067
I0526 14:59:12.681071 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.148066 (* 1 = 0.148066 loss)
I0526 14:59:12.681077 15394 sgd_solver.cpp:43] Iteration 63510, lr = 0.0002
I0526 14:59:17.848752 15394 main.cpp:354] Iteration 63520, loss = 0.87979
I0526 14:59:17.848788 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.879789 (* 1 = 0.879789 loss)
I0526 14:59:17.848793 15394 sgd_solver.cpp:43] Iteration 63520, lr = 0.0002
I0526 14:59:22.186820 15394 main.cpp:354] Iteration 63530, loss = 0.210807
I0526 14:59:22.186859 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.210806 (* 1 = 0.210806 loss)
I0526 14:59:22.186866 15394 sgd_solver.cpp:43] Iteration 63530, lr = 0.0002
I0526 14:59:27.066412 15394 main.cpp:354] Iteration 63540, loss = 0.451616
I0526 14:59:27.066449 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.451616 (* 1 = 0.451616 loss)
I0526 14:59:27.066455 15394 sgd_solver.cpp:43] Iteration 63540, lr = 0.0002
I0526 14:59:32.445456 15394 main.cpp:354] Iteration 63550, loss = 0.164762
I0526 14:59:32.445492 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.164761 (* 1 = 0.164761 loss)
I0526 14:59:32.445498 15394 sgd_solver.cpp:43] Iteration 63550, lr = 0.0002
I0526 14:59:37.633574 15394 main.cpp:354] Iteration 63560, loss = 0.177224
I0526 14:59:37.633613 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.177223 (* 1 = 0.177223 loss)
I0526 14:59:37.633625 15394 sgd_solver.cpp:43] Iteration 63560, lr = 0.0002
I0526 14:59:42.654952 15394 main.cpp:354] Iteration 63570, loss = 0.129104
I0526 14:59:42.654985 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.129103 (* 1 = 0.129103 loss)
I0526 14:59:42.654992 15394 sgd_solver.cpp:43] Iteration 63570, lr = 0.0002
I0526 14:59:47.895267 15394 main.cpp:354] Iteration 63580, loss = 0.432891
I0526 14:59:47.895303 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.432891 (* 1 = 0.432891 loss)
I0526 14:59:47.895308 15394 sgd_solver.cpp:43] Iteration 63580, lr = 0.0002
I0526 14:59:53.114959 15394 main.cpp:354] Iteration 63590, loss = 0.168714
I0526 14:59:53.114998 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.168713 (* 1 = 0.168713 loss)
I0526 14:59:53.115005 15394 sgd_solver.cpp:43] Iteration 63590, lr = 0.0002
I0526 14:59:57.387053 15394 main.cpp:465] Iteration 63600, Testing net (#0)
I0526 15:00:10.474632 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8956
I0526 15:00:10.474669 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.334267 (* 1 = 0.334267 loss)
I0526 15:00:11.019665 15394 main.cpp:354] Iteration 63600, loss = 0.198019
I0526 15:00:11.019696 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.198018 (* 1 = 0.198018 loss)
I0526 15:00:11.019704 15394 sgd_solver.cpp:43] Iteration 63600, lr = 0.0002
I0526 15:00:16.191864 15394 main.cpp:354] Iteration 63610, loss = 0.153616
I0526 15:00:16.191900 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.153615 (* 1 = 0.153615 loss)
I0526 15:00:16.191905 15394 sgd_solver.cpp:43] Iteration 63610, lr = 0.0002
I0526 15:00:20.913146 15394 main.cpp:354] Iteration 63620, loss = 0.261849
I0526 15:00:20.913199 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.261849 (* 1 = 0.261849 loss)
I0526 15:00:20.913208 15394 sgd_solver.cpp:43] Iteration 63620, lr = 0.0002
I0526 15:00:25.881181 15394 main.cpp:354] Iteration 63630, loss = 0.270654
I0526 15:00:25.881216 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.270653 (* 1 = 0.270653 loss)
I0526 15:00:25.881222 15394 sgd_solver.cpp:43] Iteration 63630, lr = 0.0002
I0526 15:00:30.354851 15394 main.cpp:354] Iteration 63640, loss = 0.227845
I0526 15:00:30.354887 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.227844 (* 1 = 0.227844 loss)
I0526 15:00:30.354894 15394 sgd_solver.cpp:43] Iteration 63640, lr = 0.0002
I0526 15:00:35.484040 15394 main.cpp:354] Iteration 63650, loss = 0.323104
I0526 15:00:35.484078 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.323104 (* 1 = 0.323104 loss)
I0526 15:00:35.484084 15394 sgd_solver.cpp:43] Iteration 63650, lr = 0.0002
I0526 15:00:40.332470 15394 main.cpp:354] Iteration 63660, loss = 0.451733
I0526 15:00:40.332509 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.451732 (* 1 = 0.451732 loss)
I0526 15:00:40.332517 15394 sgd_solver.cpp:43] Iteration 63660, lr = 0.0002
I0526 15:00:45.279407 15394 main.cpp:354] Iteration 63670, loss = 0.166104
I0526 15:00:45.279444 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.166103 (* 1 = 0.166103 loss)
I0526 15:00:45.279450 15394 sgd_solver.cpp:43] Iteration 63670, lr = 0.0002
I0526 15:00:50.306828 15394 main.cpp:354] Iteration 63680, loss = 0.121623
I0526 15:00:50.306864 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.121623 (* 1 = 0.121623 loss)
I0526 15:00:50.306871 15394 sgd_solver.cpp:43] Iteration 63680, lr = 0.0002
I0526 15:00:55.274796 15394 main.cpp:354] Iteration 63690, loss = 0.286669
I0526 15:00:55.274830 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.286668 (* 1 = 0.286668 loss)
I0526 15:00:55.274837 15394 sgd_solver.cpp:43] Iteration 63690, lr = 0.0002
I0526 15:00:59.676785 15394 main.cpp:465] Iteration 63700, Testing net (#0)
I0526 15:01:12.779642 15394 main.cpp:532]     Test net output #0: Accuracy = 0.897
I0526 15:01:12.779685 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.33457 (* 1 = 0.33457 loss)
I0526 15:01:13.175508 15394 main.cpp:354] Iteration 63700, loss = 0.322287
I0526 15:01:13.175540 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.322287 (* 1 = 0.322287 loss)
I0526 15:01:13.175549 15394 sgd_solver.cpp:43] Iteration 63700, lr = 0.0002
I0526 15:01:18.684926 15394 main.cpp:354] Iteration 63710, loss = 0.270664
I0526 15:01:18.684962 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.270664 (* 1 = 0.270664 loss)
I0526 15:01:18.684969 15394 sgd_solver.cpp:43] Iteration 63710, lr = 0.0002
I0526 15:01:23.391459 15394 main.cpp:354] Iteration 63720, loss = 0.148033
I0526 15:01:23.391499 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.148032 (* 1 = 0.148032 loss)
I0526 15:01:23.391505 15394 sgd_solver.cpp:43] Iteration 63720, lr = 0.0002
I0526 15:01:28.577605 15394 main.cpp:354] Iteration 63730, loss = 0.337495
I0526 15:01:28.577641 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.337495 (* 1 = 0.337495 loss)
I0526 15:01:28.577646 15394 sgd_solver.cpp:43] Iteration 63730, lr = 0.0002
I0526 15:01:33.147415 15394 main.cpp:354] Iteration 63740, loss = 0.446028
I0526 15:01:33.147454 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.446027 (* 1 = 0.446027 loss)
I0526 15:01:33.147459 15394 sgd_solver.cpp:43] Iteration 63740, lr = 0.0002
I0526 15:01:38.435384 15394 main.cpp:354] Iteration 63750, loss = 0.156067
I0526 15:01:38.435423 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.156066 (* 1 = 0.156066 loss)
I0526 15:01:38.435430 15394 sgd_solver.cpp:43] Iteration 63750, lr = 0.0002
I0526 15:01:43.557987 15394 main.cpp:354] Iteration 63760, loss = 0.146004
I0526 15:01:43.558027 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.146003 (* 1 = 0.146003 loss)
I0526 15:01:43.558033 15394 sgd_solver.cpp:43] Iteration 63760, lr = 0.0002
I0526 15:01:48.725574 15394 main.cpp:354] Iteration 63770, loss = 0.162344
I0526 15:01:48.725621 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.162343 (* 1 = 0.162343 loss)
I0526 15:01:48.725628 15394 sgd_solver.cpp:43] Iteration 63770, lr = 0.0002
I0526 15:01:54.200845 15394 main.cpp:354] Iteration 63780, loss = 0.24517
I0526 15:01:54.200886 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.245169 (* 1 = 0.245169 loss)
I0526 15:01:54.200892 15394 sgd_solver.cpp:43] Iteration 63780, lr = 0.0002
I0526 15:01:59.443323 15394 main.cpp:354] Iteration 63790, loss = 0.175293
I0526 15:01:59.443361 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.175292 (* 1 = 0.175292 loss)
I0526 15:01:59.443367 15394 sgd_solver.cpp:43] Iteration 63790, lr = 0.0002
I0526 15:02:03.888958 15394 main.cpp:465] Iteration 63800, Testing net (#0)
I0526 15:02:16.984235 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8971
I0526 15:02:16.984272 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.333043 (* 1 = 0.333043 loss)
I0526 15:02:17.416035 15394 main.cpp:354] Iteration 63800, loss = 0.346805
I0526 15:02:17.416064 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.346805 (* 1 = 0.346805 loss)
I0526 15:02:17.416071 15394 sgd_solver.cpp:43] Iteration 63800, lr = 0.0002
I0526 15:02:22.522019 15394 main.cpp:354] Iteration 63810, loss = 0.207571
I0526 15:02:22.522060 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.207571 (* 1 = 0.207571 loss)
I0526 15:02:22.522066 15394 sgd_solver.cpp:43] Iteration 63810, lr = 0.0002
I0526 15:02:27.943984 15394 main.cpp:354] Iteration 63820, loss = 0.291062
I0526 15:02:27.944021 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.291061 (* 1 = 0.291061 loss)
I0526 15:02:27.944027 15394 sgd_solver.cpp:43] Iteration 63820, lr = 0.0002
I0526 15:02:32.868870 15394 main.cpp:354] Iteration 63830, loss = 0.218897
I0526 15:02:32.868903 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.218897 (* 1 = 0.218897 loss)
I0526 15:02:32.868909 15394 sgd_solver.cpp:43] Iteration 63830, lr = 0.0002
I0526 15:02:37.863124 15394 main.cpp:354] Iteration 63840, loss = 0.354547
I0526 15:02:37.863171 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.354547 (* 1 = 0.354547 loss)
I0526 15:02:37.863178 15394 sgd_solver.cpp:43] Iteration 63840, lr = 0.0002
I0526 15:02:43.226439 15394 main.cpp:354] Iteration 63850, loss = 0.1999
I0526 15:02:43.226476 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.199899 (* 1 = 0.199899 loss)
I0526 15:02:43.226482 15394 sgd_solver.cpp:43] Iteration 63850, lr = 0.0002
I0526 15:02:48.290928 15394 main.cpp:354] Iteration 63860, loss = 0.239304
I0526 15:02:48.290969 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.239303 (* 1 = 0.239303 loss)
I0526 15:02:48.290976 15394 sgd_solver.cpp:43] Iteration 63860, lr = 0.0002
I0526 15:02:53.041183 15394 main.cpp:354] Iteration 63870, loss = 0.267869
I0526 15:02:53.041224 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.267868 (* 1 = 0.267868 loss)
I0526 15:02:53.041229 15394 sgd_solver.cpp:43] Iteration 63870, lr = 0.0002
I0526 15:02:58.310565 15394 main.cpp:354] Iteration 63880, loss = 0.292504
I0526 15:02:58.310600 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.292503 (* 1 = 0.292503 loss)
I0526 15:02:58.310606 15394 sgd_solver.cpp:43] Iteration 63880, lr = 0.0002
I0526 15:03:03.437320 15394 main.cpp:354] Iteration 63890, loss = 0.188709
I0526 15:03:03.437356 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.188709 (* 1 = 0.188709 loss)
I0526 15:03:03.437362 15394 sgd_solver.cpp:43] Iteration 63890, lr = 0.0002
I0526 15:03:08.077255 15394 main.cpp:465] Iteration 63900, Testing net (#0)
I0526 15:03:21.163475 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8973
I0526 15:03:21.163514 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.330517 (* 1 = 0.330517 loss)
I0526 15:03:21.637102 15394 main.cpp:354] Iteration 63900, loss = 0.257305
I0526 15:03:21.637131 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.257304 (* 1 = 0.257304 loss)
I0526 15:03:21.637140 15394 sgd_solver.cpp:43] Iteration 63900, lr = 0.0002
I0526 15:03:26.630241 15394 main.cpp:354] Iteration 63910, loss = 0.171703
I0526 15:03:26.630275 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.171703 (* 1 = 0.171703 loss)
I0526 15:03:26.630282 15394 sgd_solver.cpp:43] Iteration 63910, lr = 0.0002
I0526 15:03:31.675633 15394 main.cpp:354] Iteration 63920, loss = 0.140806
I0526 15:03:31.675671 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.140806 (* 1 = 0.140806 loss)
I0526 15:03:31.675678 15394 sgd_solver.cpp:43] Iteration 63920, lr = 0.0002
I0526 15:03:37.180538 15394 main.cpp:354] Iteration 63930, loss = 0.254586
I0526 15:03:37.180578 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.254586 (* 1 = 0.254586 loss)
I0526 15:03:37.180585 15394 sgd_solver.cpp:43] Iteration 63930, lr = 0.0002
I0526 15:03:42.813853 15394 main.cpp:354] Iteration 63940, loss = 0.301308
I0526 15:03:42.813887 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.301308 (* 1 = 0.301308 loss)
I0526 15:03:42.813894 15394 sgd_solver.cpp:43] Iteration 63940, lr = 0.0002
I0526 15:03:47.845185 15394 main.cpp:354] Iteration 63950, loss = 0.0726782
I0526 15:03:47.845219 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0726776 (* 1 = 0.0726776 loss)
I0526 15:03:47.845227 15394 sgd_solver.cpp:43] Iteration 63950, lr = 0.0002
I0526 15:03:52.904115 15394 main.cpp:354] Iteration 63960, loss = 0.17335
I0526 15:03:52.904158 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.173349 (* 1 = 0.173349 loss)
I0526 15:03:52.904165 15394 sgd_solver.cpp:43] Iteration 63960, lr = 0.0002
I0526 15:03:58.053920 15394 main.cpp:354] Iteration 63970, loss = 0.33251
I0526 15:03:58.053957 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.332509 (* 1 = 0.332509 loss)
I0526 15:03:58.053964 15394 sgd_solver.cpp:43] Iteration 63970, lr = 0.0002
I0526 15:04:02.666826 15394 main.cpp:354] Iteration 63980, loss = 0.0674334
I0526 15:04:02.666872 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.0674329 (* 1 = 0.0674329 loss)
I0526 15:04:02.666879 15394 sgd_solver.cpp:43] Iteration 63980, lr = 0.0002
I0526 15:04:08.063982 15394 main.cpp:354] Iteration 63990, loss = 0.160869
I0526 15:04:08.064034 15394 main.cpp:370]     Train net output #0: SoftmaxWithLoss1 = 0.160868 (* 1 = 0.160868 loss)
I0526 15:04:08.064040 15394 sgd_solver.cpp:43] Iteration 63990, lr = 0.0002
I0526 15:04:12.602198 15394 solver.cpp:459] Snapshotting to binary proto file _iter_64000.caffemodel
I0526 15:04:12.639219 15394 sgd_solver.cpp:458] Snapshotting solver state to binary proto file _iter_64000.solverstate
I0526 15:04:12.829618 15394 main.cpp:445] Iteration 64000, loss = 1.73077
I0526 15:04:12.829646 15394 main.cpp:465] Iteration 64000, Testing net (#0)
I0526 15:04:25.917846 15394 main.cpp:532]     Test net output #0: Accuracy = 0.8947
I0526 15:04:25.917886 15394 main.cpp:532]     Test net output #1: SoftmaxWithLoss1 = 0.334952 (* 1 = 0.334952 loss)
I0526 15:04:25.917892 15394 main.cpp:450] Optimization Done.
