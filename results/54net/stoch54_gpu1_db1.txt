WARNING: Logging before InitGoogleLogging() is written to STDERR
I0612 11:07:31.559465  5211 solver.cpp:53] Initializing solver from parameters: 
train_net: "examples/stochastic_depth/residual_train54.prototxt"
test_net: "examples/stochastic_depth/residual_test54.prototxt"
test_iter: 100
test_interval: 400
base_lr: 0.02
display: 400
max_iter: 200000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
solver_mode: GPU
random_seed: 831486
stepvalue: 100000
stepvalue: 150000
type: "Nesterov"
I0612 11:07:31.559618  5211 solver.cpp:86] Creating training net from train_net file: examples/stochastic_depth/residual_train54.prototxt
I0612 11:07:31.575456  5211 net.cpp:148] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "/scratch/pas282/caffe/examples/cifar10/cifar10_train_leveldb_padding1"
    batch_size: 128
    backend: LEVELDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution21"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution22"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution22"
  top: "Convolution22"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Convolution22"
  top: "Convolution23"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution23"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution24"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution25"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution26"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution27"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution28"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution28"
  top: "Convolution28"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution29"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution30"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "Convolution30"
  top: "Convolution30"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Convolution30"
  top: "Convolution31"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise15"
  type: "Eltwise"
  bottom: "Eltwise14"
  bottom: "Convolution31"
  top: "Eltwise15"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "Eltwise15"
  top: "Eltwise15"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Eltwise15"
  top: "Convolution32"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm32"
  type: "BatchNorm"
  bottom: "Convolution32"
  top: "Convolution32"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale32"
  type: "Scale"
  bottom: "Convolution32"
  top: "Convolution32"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU32"
  type: "ReLU"
  bottom: "Convolution32"
  top: "Convolution32"
}
layer {
  name: "Convolution33"
  type: "Convolution"
  bottom: "Convolution32"
  top: "Convolution33"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm33"
  type: "BatchNorm"
  bottom: "Convolution33"
  top: "Convolution33"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale33"
  type: "Scale"
  bottom: "Convolution33"
  top: "Convolution33"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise16"
  type: "Eltwise"
  bottom: "Eltwise15"
  bottom: "Convolution33"
  top: "Eltwise16"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU33"
  type: "ReLU"
  bottom: "Eltwise16"
  top: "Eltwise16"
}
layer {
  name: "Convolution34"
  type: "Convolution"
  bottom: "Eltwise16"
  top: "Convolution34"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm34"
  type: "BatchNorm"
  bottom: "Convolution34"
  top: "Convolution34"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale34"
  type: "Scale"
  bottom: "Convolution34"
  top: "Convolution34"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU34"
  type: "ReLU"
  bottom: "Convolution34"
  top: "Convolution34"
}
layer {
  name: "Convolution35"
  type: "Convolution"
  bottom: "Convolution34"
  top: "Convolution35"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm35"
  type: "BatchNorm"
  bottom: "Convolution35"
  top: "Convolution35"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale35"
  type: "Scale"
  bottom: "Convolution35"
  top: "Convolution35"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise17"
  type: "Eltwise"
  bottom: "Eltwise16"
  bottom: "Convolution35"
  top: "Eltwise17"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU35"
  type: "ReLU"
  bottom: "Eltwise17"
  top: "Eltwise17"
}
layer {
  name: "Convolution36"
  type: "Convolution"
  bottom: "Eltwise17"
  top: "Convolution36"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
I0612 11:07:31.578055  5211 layer_factory.hpp:77] Creating layer Data1
I0612 11:07:31.579046  5211 net.cpp:190] Creating Layer Data1
I0612 11:07:31.579068  5211 net.cpp:589] Data1 -> Data1
I0612 11:07:31.579113  5211 net.cpp:589] Data1 -> Data2
I0612 11:07:31.624685  5215 db_leveldb.cpp:18] Opened leveldb /scratch/pas282/caffe/examples/cifar10/cifar10_train_leveldb_padding1
I0612 11:07:31.643713  5211 data_layer.cpp:41] output data size: 128,3,32,32
I0612 11:07:31.651753  5211 net.cpp:240] Setting up Data1
I0612 11:07:31.651796  5211 net.cpp:247] Top shape: 128 3 32 32 (393216)
I0612 11:07:31.651809  5211 net.cpp:247] Top shape: 128 (128)
I0612 11:07:31.651818  5211 net.cpp:255] Memory required for data: 1573376
I0612 11:07:31.651836  5211 layer_factory.hpp:77] Creating layer Convolution1
I0612 11:07:31.651876  5211 net.cpp:190] Creating Layer Convolution1
I0612 11:07:31.651890  5211 net.cpp:615] Convolution1 <- Data1
I0612 11:07:31.651916  5211 net.cpp:589] Convolution1 -> Convolution1
I0612 11:07:31.654014  5211 net.cpp:240] Setting up Convolution1
I0612 11:07:31.654042  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.654050  5211 net.cpp:255] Memory required for data: 9961984
I0612 11:07:31.654086  5211 layer_factory.hpp:77] Creating layer BatchNorm1
I0612 11:07:31.654110  5211 net.cpp:190] Creating Layer BatchNorm1
I0612 11:07:31.654119  5211 net.cpp:615] BatchNorm1 <- Convolution1
I0612 11:07:31.654129  5211 net.cpp:576] BatchNorm1 -> Convolution1 (in-place)
I0612 11:07:31.654495  5211 net.cpp:240] Setting up BatchNorm1
I0612 11:07:31.654510  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.654516  5211 net.cpp:255] Memory required for data: 18350592
I0612 11:07:31.654542  5211 layer_factory.hpp:77] Creating layer Scale1
I0612 11:07:31.654564  5211 net.cpp:190] Creating Layer Scale1
I0612 11:07:31.654572  5211 net.cpp:615] Scale1 <- Convolution1
I0612 11:07:31.654582  5211 net.cpp:576] Scale1 -> Convolution1 (in-place)
I0612 11:07:31.654644  5211 layer_factory.hpp:77] Creating layer Scale1
I0612 11:07:31.654832  5211 net.cpp:240] Setting up Scale1
I0612 11:07:31.654856  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.654863  5211 net.cpp:255] Memory required for data: 26739200
I0612 11:07:31.654880  5211 layer_factory.hpp:77] Creating layer ReLU1
I0612 11:07:31.654893  5211 net.cpp:190] Creating Layer ReLU1
I0612 11:07:31.654899  5211 net.cpp:615] ReLU1 <- Convolution1
I0612 11:07:31.654908  5211 net.cpp:576] ReLU1 -> Convolution1 (in-place)
I0612 11:07:31.654927  5211 net.cpp:240] Setting up ReLU1
I0612 11:07:31.654935  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.654942  5211 net.cpp:255] Memory required for data: 35127808
I0612 11:07:31.654947  5211 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0612 11:07:31.654970  5211 net.cpp:190] Creating Layer Convolution1_ReLU1_0_split
I0612 11:07:31.654978  5211 net.cpp:615] Convolution1_ReLU1_0_split <- Convolution1
I0612 11:07:31.654986  5211 net.cpp:589] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0612 11:07:31.654999  5211 net.cpp:589] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0612 11:07:31.655061  5211 net.cpp:240] Setting up Convolution1_ReLU1_0_split
I0612 11:07:31.655071  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.655081  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.655086  5211 net.cpp:255] Memory required for data: 51905024
I0612 11:07:31.655093  5211 layer_factory.hpp:77] Creating layer Convolution2
I0612 11:07:31.655107  5211 net.cpp:190] Creating Layer Convolution2
I0612 11:07:31.655114  5211 net.cpp:615] Convolution2 <- Convolution1_ReLU1_0_split_0
I0612 11:07:31.655125  5211 net.cpp:589] Convolution2 -> Convolution2
I0612 11:07:31.656708  5211 net.cpp:240] Setting up Convolution2
I0612 11:07:31.656730  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.656738  5211 net.cpp:255] Memory required for data: 60293632
I0612 11:07:31.656759  5211 layer_factory.hpp:77] Creating layer BatchNorm2
I0612 11:07:31.656775  5211 net.cpp:190] Creating Layer BatchNorm2
I0612 11:07:31.656783  5211 net.cpp:615] BatchNorm2 <- Convolution2
I0612 11:07:31.656796  5211 net.cpp:576] BatchNorm2 -> Convolution2 (in-place)
I0612 11:07:31.657119  5211 net.cpp:240] Setting up BatchNorm2
I0612 11:07:31.657132  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.657140  5211 net.cpp:255] Memory required for data: 68682240
I0612 11:07:31.657157  5211 layer_factory.hpp:77] Creating layer Scale2
I0612 11:07:31.657178  5211 net.cpp:190] Creating Layer Scale2
I0612 11:07:31.657187  5211 net.cpp:615] Scale2 <- Convolution2
I0612 11:07:31.657197  5211 net.cpp:576] Scale2 -> Convolution2 (in-place)
I0612 11:07:31.657258  5211 layer_factory.hpp:77] Creating layer Scale2
I0612 11:07:31.657438  5211 net.cpp:240] Setting up Scale2
I0612 11:07:31.657449  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.657455  5211 net.cpp:255] Memory required for data: 77070848
I0612 11:07:31.657470  5211 layer_factory.hpp:77] Creating layer ReLU2
I0612 11:07:31.657481  5211 net.cpp:190] Creating Layer ReLU2
I0612 11:07:31.657488  5211 net.cpp:615] ReLU2 <- Convolution2
I0612 11:07:31.657500  5211 net.cpp:576] ReLU2 -> Convolution2 (in-place)
I0612 11:07:31.657512  5211 net.cpp:240] Setting up ReLU2
I0612 11:07:31.657522  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.657531  5211 net.cpp:255] Memory required for data: 85459456
I0612 11:07:31.657536  5211 layer_factory.hpp:77] Creating layer Convolution3
I0612 11:07:31.657557  5211 net.cpp:190] Creating Layer Convolution3
I0612 11:07:31.657564  5211 net.cpp:615] Convolution3 <- Convolution2
I0612 11:07:31.657577  5211 net.cpp:589] Convolution3 -> Convolution3
I0612 11:07:31.658083  5211 net.cpp:240] Setting up Convolution3
I0612 11:07:31.658097  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.658104  5211 net.cpp:255] Memory required for data: 93848064
I0612 11:07:31.658118  5211 layer_factory.hpp:77] Creating layer BatchNorm3
I0612 11:07:31.658133  5211 net.cpp:190] Creating Layer BatchNorm3
I0612 11:07:31.658145  5211 net.cpp:615] BatchNorm3 <- Convolution3
I0612 11:07:31.658164  5211 net.cpp:576] BatchNorm3 -> Convolution3 (in-place)
I0612 11:07:31.658485  5211 net.cpp:240] Setting up BatchNorm3
I0612 11:07:31.658501  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.658507  5211 net.cpp:255] Memory required for data: 102236672
I0612 11:07:31.658535  5211 layer_factory.hpp:77] Creating layer Scale3
I0612 11:07:31.658548  5211 net.cpp:190] Creating Layer Scale3
I0612 11:07:31.658555  5211 net.cpp:615] Scale3 <- Convolution3
I0612 11:07:31.658565  5211 net.cpp:576] Scale3 -> Convolution3 (in-place)
I0612 11:07:31.658623  5211 layer_factory.hpp:77] Creating layer Scale3
I0612 11:07:31.658803  5211 net.cpp:240] Setting up Scale3
I0612 11:07:31.658815  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.658821  5211 net.cpp:255] Memory required for data: 110625280
I0612 11:07:31.658835  5211 layer_factory.hpp:77] Creating layer Eltwise1
I0612 11:07:31.658861  5211 net.cpp:190] Creating Layer Eltwise1
I0612 11:07:31.658869  5211 net.cpp:615] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0612 11:07:31.658879  5211 net.cpp:615] Eltwise1 <- Convolution3
I0612 11:07:31.658888  5211 net.cpp:589] Eltwise1 -> Eltwise1
I0612 11:07:31.658939  5211 net.cpp:240] Setting up Eltwise1
I0612 11:07:31.658951  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.658957  5211 net.cpp:255] Memory required for data: 119013888
I0612 11:07:31.658962  5211 layer_factory.hpp:77] Creating layer ReLU3
I0612 11:07:31.658972  5211 net.cpp:190] Creating Layer ReLU3
I0612 11:07:31.658979  5211 net.cpp:615] ReLU3 <- Eltwise1
I0612 11:07:31.658992  5211 net.cpp:576] ReLU3 -> Eltwise1 (in-place)
I0612 11:07:31.659003  5211 net.cpp:240] Setting up ReLU3
I0612 11:07:31.659010  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.659018  5211 net.cpp:255] Memory required for data: 127402496
I0612 11:07:31.659024  5211 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0612 11:07:31.659034  5211 net.cpp:190] Creating Layer Eltwise1_ReLU3_0_split
I0612 11:07:31.659039  5211 net.cpp:615] Eltwise1_ReLU3_0_split <- Eltwise1
I0612 11:07:31.659047  5211 net.cpp:589] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0612 11:07:31.659061  5211 net.cpp:589] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0612 11:07:31.659216  5211 net.cpp:240] Setting up Eltwise1_ReLU3_0_split
I0612 11:07:31.659231  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.659241  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.659246  5211 net.cpp:255] Memory required for data: 144179712
I0612 11:07:31.659253  5211 layer_factory.hpp:77] Creating layer Convolution4
I0612 11:07:31.659273  5211 net.cpp:190] Creating Layer Convolution4
I0612 11:07:31.659281  5211 net.cpp:615] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0612 11:07:31.659296  5211 net.cpp:589] Convolution4 -> Convolution4
I0612 11:07:31.659809  5211 net.cpp:240] Setting up Convolution4
I0612 11:07:31.659823  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.659832  5211 net.cpp:255] Memory required for data: 152568320
I0612 11:07:31.659847  5211 layer_factory.hpp:77] Creating layer BatchNorm4
I0612 11:07:31.659859  5211 net.cpp:190] Creating Layer BatchNorm4
I0612 11:07:31.659867  5211 net.cpp:615] BatchNorm4 <- Convolution4
I0612 11:07:31.659879  5211 net.cpp:576] BatchNorm4 -> Convolution4 (in-place)
I0612 11:07:31.660188  5211 net.cpp:240] Setting up BatchNorm4
I0612 11:07:31.660200  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.660207  5211 net.cpp:255] Memory required for data: 160956928
I0612 11:07:31.660224  5211 layer_factory.hpp:77] Creating layer Scale4
I0612 11:07:31.660235  5211 net.cpp:190] Creating Layer Scale4
I0612 11:07:31.660243  5211 net.cpp:615] Scale4 <- Convolution4
I0612 11:07:31.660251  5211 net.cpp:576] Scale4 -> Convolution4 (in-place)
I0612 11:07:31.660306  5211 layer_factory.hpp:77] Creating layer Scale4
I0612 11:07:31.660480  5211 net.cpp:240] Setting up Scale4
I0612 11:07:31.660495  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.660502  5211 net.cpp:255] Memory required for data: 169345536
I0612 11:07:31.660516  5211 layer_factory.hpp:77] Creating layer ReLU4
I0612 11:07:31.660529  5211 net.cpp:190] Creating Layer ReLU4
I0612 11:07:31.660537  5211 net.cpp:615] ReLU4 <- Convolution4
I0612 11:07:31.660547  5211 net.cpp:576] ReLU4 -> Convolution4 (in-place)
I0612 11:07:31.660557  5211 net.cpp:240] Setting up ReLU4
I0612 11:07:31.660567  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.660573  5211 net.cpp:255] Memory required for data: 177734144
I0612 11:07:31.660578  5211 layer_factory.hpp:77] Creating layer Convolution5
I0612 11:07:31.660595  5211 net.cpp:190] Creating Layer Convolution5
I0612 11:07:31.660603  5211 net.cpp:615] Convolution5 <- Convolution4
I0612 11:07:31.660614  5211 net.cpp:589] Convolution5 -> Convolution5
I0612 11:07:31.661126  5211 net.cpp:240] Setting up Convolution5
I0612 11:07:31.661140  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.661147  5211 net.cpp:255] Memory required for data: 186122752
I0612 11:07:31.661161  5211 layer_factory.hpp:77] Creating layer BatchNorm5
I0612 11:07:31.661172  5211 net.cpp:190] Creating Layer BatchNorm5
I0612 11:07:31.661180  5211 net.cpp:615] BatchNorm5 <- Convolution5
I0612 11:07:31.661191  5211 net.cpp:576] BatchNorm5 -> Convolution5 (in-place)
I0612 11:07:31.661510  5211 net.cpp:240] Setting up BatchNorm5
I0612 11:07:31.661522  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.661530  5211 net.cpp:255] Memory required for data: 194511360
I0612 11:07:31.661557  5211 layer_factory.hpp:77] Creating layer Scale5
I0612 11:07:31.661568  5211 net.cpp:190] Creating Layer Scale5
I0612 11:07:31.661576  5211 net.cpp:615] Scale5 <- Convolution5
I0612 11:07:31.661586  5211 net.cpp:576] Scale5 -> Convolution5 (in-place)
I0612 11:07:31.661644  5211 layer_factory.hpp:77] Creating layer Scale5
I0612 11:07:31.661842  5211 net.cpp:240] Setting up Scale5
I0612 11:07:31.661854  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.661862  5211 net.cpp:255] Memory required for data: 202899968
I0612 11:07:31.661876  5211 layer_factory.hpp:77] Creating layer Eltwise2
I0612 11:07:31.661895  5211 net.cpp:190] Creating Layer Eltwise2
I0612 11:07:31.661901  5211 net.cpp:615] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0612 11:07:31.661911  5211 net.cpp:615] Eltwise2 <- Convolution5
I0612 11:07:31.661921  5211 net.cpp:589] Eltwise2 -> Eltwise2
I0612 11:07:31.662050  5211 net.cpp:240] Setting up Eltwise2
I0612 11:07:31.662063  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.662070  5211 net.cpp:255] Memory required for data: 211288576
I0612 11:07:31.662076  5211 layer_factory.hpp:77] Creating layer ReLU5
I0612 11:07:31.662086  5211 net.cpp:190] Creating Layer ReLU5
I0612 11:07:31.662092  5211 net.cpp:615] ReLU5 <- Eltwise2
I0612 11:07:31.662104  5211 net.cpp:576] ReLU5 -> Eltwise2 (in-place)
I0612 11:07:31.662117  5211 net.cpp:240] Setting up ReLU5
I0612 11:07:31.662124  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.662132  5211 net.cpp:255] Memory required for data: 219677184
I0612 11:07:31.662137  5211 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0612 11:07:31.662147  5211 net.cpp:190] Creating Layer Eltwise2_ReLU5_0_split
I0612 11:07:31.662153  5211 net.cpp:615] Eltwise2_ReLU5_0_split <- Eltwise2
I0612 11:07:31.662163  5211 net.cpp:589] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0612 11:07:31.662173  5211 net.cpp:589] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0612 11:07:31.662235  5211 net.cpp:240] Setting up Eltwise2_ReLU5_0_split
I0612 11:07:31.662246  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.662255  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.662261  5211 net.cpp:255] Memory required for data: 236454400
I0612 11:07:31.662267  5211 layer_factory.hpp:77] Creating layer Convolution6
I0612 11:07:31.662281  5211 net.cpp:190] Creating Layer Convolution6
I0612 11:07:31.662293  5211 net.cpp:615] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0612 11:07:31.662307  5211 net.cpp:589] Convolution6 -> Convolution6
I0612 11:07:31.662835  5211 net.cpp:240] Setting up Convolution6
I0612 11:07:31.662850  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.662856  5211 net.cpp:255] Memory required for data: 244843008
I0612 11:07:31.662873  5211 layer_factory.hpp:77] Creating layer BatchNorm6
I0612 11:07:31.662883  5211 net.cpp:190] Creating Layer BatchNorm6
I0612 11:07:31.662890  5211 net.cpp:615] BatchNorm6 <- Convolution6
I0612 11:07:31.662899  5211 net.cpp:576] BatchNorm6 -> Convolution6 (in-place)
I0612 11:07:31.662924  5219 blocking_queue.cpp:50] Waiting for data
I0612 11:07:31.663203  5211 net.cpp:240] Setting up BatchNorm6
I0612 11:07:31.663215  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.663223  5211 net.cpp:255] Memory required for data: 253231616
I0612 11:07:31.663240  5211 layer_factory.hpp:77] Creating layer Scale6
I0612 11:07:31.663251  5211 net.cpp:190] Creating Layer Scale6
I0612 11:07:31.663259  5211 net.cpp:615] Scale6 <- Convolution6
I0612 11:07:31.663267  5211 net.cpp:576] Scale6 -> Convolution6 (in-place)
I0612 11:07:31.663326  5211 layer_factory.hpp:77] Creating layer Scale6
I0612 11:07:31.663499  5211 net.cpp:240] Setting up Scale6
I0612 11:07:31.663511  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.663517  5211 net.cpp:255] Memory required for data: 261620224
I0612 11:07:31.663534  5211 layer_factory.hpp:77] Creating layer ReLU6
I0612 11:07:31.663545  5211 net.cpp:190] Creating Layer ReLU6
I0612 11:07:31.663552  5211 net.cpp:615] ReLU6 <- Convolution6
I0612 11:07:31.663563  5211 net.cpp:576] ReLU6 -> Convolution6 (in-place)
I0612 11:07:31.663574  5211 net.cpp:240] Setting up ReLU6
I0612 11:07:31.663583  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.663590  5211 net.cpp:255] Memory required for data: 270008832
I0612 11:07:31.663596  5211 layer_factory.hpp:77] Creating layer Convolution7
I0612 11:07:31.663611  5211 net.cpp:190] Creating Layer Convolution7
I0612 11:07:31.663619  5211 net.cpp:615] Convolution7 <- Convolution6
I0612 11:07:31.663631  5211 net.cpp:589] Convolution7 -> Convolution7
I0612 11:07:31.664139  5211 net.cpp:240] Setting up Convolution7
I0612 11:07:31.664154  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.664162  5211 net.cpp:255] Memory required for data: 278397440
I0612 11:07:31.664176  5211 layer_factory.hpp:77] Creating layer BatchNorm7
I0612 11:07:31.664187  5211 net.cpp:190] Creating Layer BatchNorm7
I0612 11:07:31.664194  5211 net.cpp:615] BatchNorm7 <- Convolution7
I0612 11:07:31.664206  5211 net.cpp:576] BatchNorm7 -> Convolution7 (in-place)
I0612 11:07:31.664510  5211 net.cpp:240] Setting up BatchNorm7
I0612 11:07:31.664523  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.664530  5211 net.cpp:255] Memory required for data: 286786048
I0612 11:07:31.664546  5211 layer_factory.hpp:77] Creating layer Scale7
I0612 11:07:31.664561  5211 net.cpp:190] Creating Layer Scale7
I0612 11:07:31.664568  5211 net.cpp:615] Scale7 <- Convolution7
I0612 11:07:31.664580  5211 net.cpp:576] Scale7 -> Convolution7 (in-place)
I0612 11:07:31.664638  5211 layer_factory.hpp:77] Creating layer Scale7
I0612 11:07:31.664819  5211 net.cpp:240] Setting up Scale7
I0612 11:07:31.664830  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.664836  5211 net.cpp:255] Memory required for data: 295174656
I0612 11:07:31.664850  5211 layer_factory.hpp:77] Creating layer Eltwise3
I0612 11:07:31.664863  5211 net.cpp:190] Creating Layer Eltwise3
I0612 11:07:31.664870  5211 net.cpp:615] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0612 11:07:31.664878  5211 net.cpp:615] Eltwise3 <- Convolution7
I0612 11:07:31.664887  5211 net.cpp:589] Eltwise3 -> Eltwise3
I0612 11:07:31.664929  5211 net.cpp:240] Setting up Eltwise3
I0612 11:07:31.664939  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.664945  5211 net.cpp:255] Memory required for data: 303563264
I0612 11:07:31.664957  5211 layer_factory.hpp:77] Creating layer ReLU7
I0612 11:07:31.664966  5211 net.cpp:190] Creating Layer ReLU7
I0612 11:07:31.664973  5211 net.cpp:615] ReLU7 <- Eltwise3
I0612 11:07:31.664985  5211 net.cpp:576] ReLU7 -> Eltwise3 (in-place)
I0612 11:07:31.664996  5211 net.cpp:240] Setting up ReLU7
I0612 11:07:31.665005  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.665011  5211 net.cpp:255] Memory required for data: 311951872
I0612 11:07:31.665019  5211 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0612 11:07:31.665026  5211 net.cpp:190] Creating Layer Eltwise3_ReLU7_0_split
I0612 11:07:31.665033  5211 net.cpp:615] Eltwise3_ReLU7_0_split <- Eltwise3
I0612 11:07:31.665042  5211 net.cpp:589] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0612 11:07:31.665055  5211 net.cpp:589] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0612 11:07:31.665108  5211 net.cpp:240] Setting up Eltwise3_ReLU7_0_split
I0612 11:07:31.665118  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.665127  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.665132  5211 net.cpp:255] Memory required for data: 328729088
I0612 11:07:31.665138  5211 layer_factory.hpp:77] Creating layer Convolution8
I0612 11:07:31.665154  5211 net.cpp:190] Creating Layer Convolution8
I0612 11:07:31.665161  5211 net.cpp:615] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0612 11:07:31.665172  5211 net.cpp:589] Convolution8 -> Convolution8
I0612 11:07:31.665679  5211 net.cpp:240] Setting up Convolution8
I0612 11:07:31.665693  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.665699  5211 net.cpp:255] Memory required for data: 337117696
I0612 11:07:31.665712  5211 layer_factory.hpp:77] Creating layer BatchNorm8
I0612 11:07:31.665725  5211 net.cpp:190] Creating Layer BatchNorm8
I0612 11:07:31.665734  5211 net.cpp:615] BatchNorm8 <- Convolution8
I0612 11:07:31.665745  5211 net.cpp:576] BatchNorm8 -> Convolution8 (in-place)
I0612 11:07:31.666055  5211 net.cpp:240] Setting up BatchNorm8
I0612 11:07:31.666067  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.666074  5211 net.cpp:255] Memory required for data: 345506304
I0612 11:07:31.666091  5211 layer_factory.hpp:77] Creating layer Scale8
I0612 11:07:31.666105  5211 net.cpp:190] Creating Layer Scale8
I0612 11:07:31.666112  5211 net.cpp:615] Scale8 <- Convolution8
I0612 11:07:31.666122  5211 net.cpp:576] Scale8 -> Convolution8 (in-place)
I0612 11:07:31.666178  5211 layer_factory.hpp:77] Creating layer Scale8
I0612 11:07:31.666366  5211 net.cpp:240] Setting up Scale8
I0612 11:07:31.666379  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.666386  5211 net.cpp:255] Memory required for data: 353894912
I0612 11:07:31.666400  5211 layer_factory.hpp:77] Creating layer ReLU8
I0612 11:07:31.666412  5211 net.cpp:190] Creating Layer ReLU8
I0612 11:07:31.666420  5211 net.cpp:615] ReLU8 <- Convolution8
I0612 11:07:31.666434  5211 net.cpp:576] ReLU8 -> Convolution8 (in-place)
I0612 11:07:31.666445  5211 net.cpp:240] Setting up ReLU8
I0612 11:07:31.666453  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.666461  5211 net.cpp:255] Memory required for data: 362283520
I0612 11:07:31.666467  5211 layer_factory.hpp:77] Creating layer Convolution9
I0612 11:07:31.666484  5211 net.cpp:190] Creating Layer Convolution9
I0612 11:07:31.666491  5211 net.cpp:615] Convolution9 <- Convolution8
I0612 11:07:31.666501  5211 net.cpp:589] Convolution9 -> Convolution9
I0612 11:07:31.666996  5211 net.cpp:240] Setting up Convolution9
I0612 11:07:31.667009  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.667016  5211 net.cpp:255] Memory required for data: 370672128
I0612 11:07:31.667028  5211 layer_factory.hpp:77] Creating layer BatchNorm9
I0612 11:07:31.667040  5211 net.cpp:190] Creating Layer BatchNorm9
I0612 11:07:31.667047  5211 net.cpp:615] BatchNorm9 <- Convolution9
I0612 11:07:31.667055  5211 net.cpp:576] BatchNorm9 -> Convolution9 (in-place)
I0612 11:07:31.667336  5211 net.cpp:240] Setting up BatchNorm9
I0612 11:07:31.667351  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.667357  5211 net.cpp:255] Memory required for data: 379060736
I0612 11:07:31.667377  5211 layer_factory.hpp:77] Creating layer Scale9
I0612 11:07:31.667387  5211 net.cpp:190] Creating Layer Scale9
I0612 11:07:31.667393  5211 net.cpp:615] Scale9 <- Convolution9
I0612 11:07:31.667402  5211 net.cpp:576] Scale9 -> Convolution9 (in-place)
I0612 11:07:31.667456  5211 layer_factory.hpp:77] Creating layer Scale9
I0612 11:07:31.667619  5211 net.cpp:240] Setting up Scale9
I0612 11:07:31.667629  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.667635  5211 net.cpp:255] Memory required for data: 387449344
I0612 11:07:31.667649  5211 layer_factory.hpp:77] Creating layer Eltwise4
I0612 11:07:31.667665  5211 net.cpp:190] Creating Layer Eltwise4
I0612 11:07:31.667671  5211 net.cpp:615] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0612 11:07:31.667680  5211 net.cpp:615] Eltwise4 <- Convolution9
I0612 11:07:31.667690  5211 net.cpp:589] Eltwise4 -> Eltwise4
I0612 11:07:31.667729  5211 net.cpp:240] Setting up Eltwise4
I0612 11:07:31.667739  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.667745  5211 net.cpp:255] Memory required for data: 395837952
I0612 11:07:31.667752  5211 layer_factory.hpp:77] Creating layer ReLU9
I0612 11:07:31.667762  5211 net.cpp:190] Creating Layer ReLU9
I0612 11:07:31.667768  5211 net.cpp:615] ReLU9 <- Eltwise4
I0612 11:07:31.667778  5211 net.cpp:576] ReLU9 -> Eltwise4 (in-place)
I0612 11:07:31.667788  5211 net.cpp:240] Setting up ReLU9
I0612 11:07:31.667796  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.667801  5211 net.cpp:255] Memory required for data: 404226560
I0612 11:07:31.667807  5211 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0612 11:07:31.667816  5211 net.cpp:190] Creating Layer Eltwise4_ReLU9_0_split
I0612 11:07:31.667821  5211 net.cpp:615] Eltwise4_ReLU9_0_split <- Eltwise4
I0612 11:07:31.667829  5211 net.cpp:589] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0612 11:07:31.667840  5211 net.cpp:589] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0612 11:07:31.667892  5211 net.cpp:240] Setting up Eltwise4_ReLU9_0_split
I0612 11:07:31.667902  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.667911  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.667917  5211 net.cpp:255] Memory required for data: 421003776
I0612 11:07:31.667922  5211 layer_factory.hpp:77] Creating layer Convolution10
I0612 11:07:31.667935  5211 net.cpp:190] Creating Layer Convolution10
I0612 11:07:31.667943  5211 net.cpp:615] Convolution10 <- Eltwise4_ReLU9_0_split_0
I0612 11:07:31.667956  5211 net.cpp:589] Convolution10 -> Convolution10
I0612 11:07:31.668427  5211 net.cpp:240] Setting up Convolution10
I0612 11:07:31.668439  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.668447  5211 net.cpp:255] Memory required for data: 429392384
I0612 11:07:31.668473  5211 layer_factory.hpp:77] Creating layer BatchNorm10
I0612 11:07:31.668488  5211 net.cpp:190] Creating Layer BatchNorm10
I0612 11:07:31.668494  5211 net.cpp:615] BatchNorm10 <- Convolution10
I0612 11:07:31.668504  5211 net.cpp:576] BatchNorm10 -> Convolution10 (in-place)
I0612 11:07:31.668788  5211 net.cpp:240] Setting up BatchNorm10
I0612 11:07:31.668800  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.668807  5211 net.cpp:255] Memory required for data: 437780992
I0612 11:07:31.668823  5211 layer_factory.hpp:77] Creating layer Scale10
I0612 11:07:31.668833  5211 net.cpp:190] Creating Layer Scale10
I0612 11:07:31.668838  5211 net.cpp:615] Scale10 <- Convolution10
I0612 11:07:31.668846  5211 net.cpp:576] Scale10 -> Convolution10 (in-place)
I0612 11:07:31.668898  5211 layer_factory.hpp:77] Creating layer Scale10
I0612 11:07:31.669075  5211 net.cpp:240] Setting up Scale10
I0612 11:07:31.669086  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.669092  5211 net.cpp:255] Memory required for data: 446169600
I0612 11:07:31.669113  5211 layer_factory.hpp:77] Creating layer ReLU10
I0612 11:07:31.669124  5211 net.cpp:190] Creating Layer ReLU10
I0612 11:07:31.669131  5211 net.cpp:615] ReLU10 <- Convolution10
I0612 11:07:31.669139  5211 net.cpp:576] ReLU10 -> Convolution10 (in-place)
I0612 11:07:31.669149  5211 net.cpp:240] Setting up ReLU10
I0612 11:07:31.669158  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.669163  5211 net.cpp:255] Memory required for data: 454558208
I0612 11:07:31.669169  5211 layer_factory.hpp:77] Creating layer Convolution11
I0612 11:07:31.669185  5211 net.cpp:190] Creating Layer Convolution11
I0612 11:07:31.669191  5211 net.cpp:615] Convolution11 <- Convolution10
I0612 11:07:31.669203  5211 net.cpp:589] Convolution11 -> Convolution11
I0612 11:07:31.669679  5211 net.cpp:240] Setting up Convolution11
I0612 11:07:31.669692  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.669697  5211 net.cpp:255] Memory required for data: 462946816
I0612 11:07:31.669710  5211 layer_factory.hpp:77] Creating layer BatchNorm11
I0612 11:07:31.669720  5211 net.cpp:190] Creating Layer BatchNorm11
I0612 11:07:31.669726  5211 net.cpp:615] BatchNorm11 <- Convolution11
I0612 11:07:31.669739  5211 net.cpp:576] BatchNorm11 -> Convolution11 (in-place)
I0612 11:07:31.670044  5211 net.cpp:240] Setting up BatchNorm11
I0612 11:07:31.670055  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.670061  5211 net.cpp:255] Memory required for data: 471335424
I0612 11:07:31.670079  5211 layer_factory.hpp:77] Creating layer Scale11
I0612 11:07:31.670089  5211 net.cpp:190] Creating Layer Scale11
I0612 11:07:31.670096  5211 net.cpp:615] Scale11 <- Convolution11
I0612 11:07:31.670104  5211 net.cpp:576] Scale11 -> Convolution11 (in-place)
I0612 11:07:31.670163  5211 layer_factory.hpp:77] Creating layer Scale11
I0612 11:07:31.670326  5211 net.cpp:240] Setting up Scale11
I0612 11:07:31.670337  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.670342  5211 net.cpp:255] Memory required for data: 479724032
I0612 11:07:31.670364  5211 layer_factory.hpp:77] Creating layer Eltwise5
I0612 11:07:31.670377  5211 net.cpp:190] Creating Layer Eltwise5
I0612 11:07:31.670383  5211 net.cpp:615] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0612 11:07:31.670392  5211 net.cpp:615] Eltwise5 <- Convolution11
I0612 11:07:31.670403  5211 net.cpp:589] Eltwise5 -> Eltwise5
I0612 11:07:31.670439  5211 net.cpp:240] Setting up Eltwise5
I0612 11:07:31.670449  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.670455  5211 net.cpp:255] Memory required for data: 488112640
I0612 11:07:31.670461  5211 layer_factory.hpp:77] Creating layer ReLU11
I0612 11:07:31.670474  5211 net.cpp:190] Creating Layer ReLU11
I0612 11:07:31.670480  5211 net.cpp:615] ReLU11 <- Eltwise5
I0612 11:07:31.670487  5211 net.cpp:576] ReLU11 -> Eltwise5 (in-place)
I0612 11:07:31.670497  5211 net.cpp:240] Setting up ReLU11
I0612 11:07:31.670506  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.670511  5211 net.cpp:255] Memory required for data: 496501248
I0612 11:07:31.670516  5211 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0612 11:07:31.670524  5211 net.cpp:190] Creating Layer Eltwise5_ReLU11_0_split
I0612 11:07:31.670531  5211 net.cpp:615] Eltwise5_ReLU11_0_split <- Eltwise5
I0612 11:07:31.670542  5211 net.cpp:589] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0612 11:07:31.670552  5211 net.cpp:589] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0612 11:07:31.670603  5211 net.cpp:240] Setting up Eltwise5_ReLU11_0_split
I0612 11:07:31.670613  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.670620  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.670627  5211 net.cpp:255] Memory required for data: 513278464
I0612 11:07:31.670632  5211 layer_factory.hpp:77] Creating layer Convolution12
I0612 11:07:31.670646  5211 net.cpp:190] Creating Layer Convolution12
I0612 11:07:31.670653  5211 net.cpp:615] Convolution12 <- Eltwise5_ReLU11_0_split_0
I0612 11:07:31.670671  5211 net.cpp:589] Convolution12 -> Convolution12
I0612 11:07:31.671147  5211 net.cpp:240] Setting up Convolution12
I0612 11:07:31.671160  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.671167  5211 net.cpp:255] Memory required for data: 521667072
I0612 11:07:31.671181  5211 layer_factory.hpp:77] Creating layer BatchNorm12
I0612 11:07:31.671192  5211 net.cpp:190] Creating Layer BatchNorm12
I0612 11:07:31.671198  5211 net.cpp:615] BatchNorm12 <- Convolution12
I0612 11:07:31.671211  5211 net.cpp:576] BatchNorm12 -> Convolution12 (in-place)
I0612 11:07:31.671501  5211 net.cpp:240] Setting up BatchNorm12
I0612 11:07:31.671514  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.671519  5211 net.cpp:255] Memory required for data: 530055680
I0612 11:07:31.671535  5211 layer_factory.hpp:77] Creating layer Scale12
I0612 11:07:31.671545  5211 net.cpp:190] Creating Layer Scale12
I0612 11:07:31.671552  5211 net.cpp:615] Scale12 <- Convolution12
I0612 11:07:31.671567  5211 net.cpp:576] Scale12 -> Convolution12 (in-place)
I0612 11:07:31.671618  5211 layer_factory.hpp:77] Creating layer Scale12
I0612 11:07:31.671788  5211 net.cpp:240] Setting up Scale12
I0612 11:07:31.671799  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.671805  5211 net.cpp:255] Memory required for data: 538444288
I0612 11:07:31.671818  5211 layer_factory.hpp:77] Creating layer ReLU12
I0612 11:07:31.671829  5211 net.cpp:190] Creating Layer ReLU12
I0612 11:07:31.671836  5211 net.cpp:615] ReLU12 <- Convolution12
I0612 11:07:31.671844  5211 net.cpp:576] ReLU12 -> Convolution12 (in-place)
I0612 11:07:31.671854  5211 net.cpp:240] Setting up ReLU12
I0612 11:07:31.671864  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.671869  5211 net.cpp:255] Memory required for data: 546832896
I0612 11:07:31.671875  5211 layer_factory.hpp:77] Creating layer Convolution13
I0612 11:07:31.671891  5211 net.cpp:190] Creating Layer Convolution13
I0612 11:07:31.671897  5211 net.cpp:615] Convolution13 <- Convolution12
I0612 11:07:31.671908  5211 net.cpp:589] Convolution13 -> Convolution13
I0612 11:07:31.672384  5211 net.cpp:240] Setting up Convolution13
I0612 11:07:31.672395  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.672402  5211 net.cpp:255] Memory required for data: 555221504
I0612 11:07:31.672415  5211 layer_factory.hpp:77] Creating layer BatchNorm13
I0612 11:07:31.672428  5211 net.cpp:190] Creating Layer BatchNorm13
I0612 11:07:31.672435  5211 net.cpp:615] BatchNorm13 <- Convolution13
I0612 11:07:31.672444  5211 net.cpp:576] BatchNorm13 -> Convolution13 (in-place)
I0612 11:07:31.672737  5211 net.cpp:240] Setting up BatchNorm13
I0612 11:07:31.672749  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.672755  5211 net.cpp:255] Memory required for data: 563610112
I0612 11:07:31.672770  5211 layer_factory.hpp:77] Creating layer Scale13
I0612 11:07:31.672782  5211 net.cpp:190] Creating Layer Scale13
I0612 11:07:31.672788  5211 net.cpp:615] Scale13 <- Convolution13
I0612 11:07:31.672797  5211 net.cpp:576] Scale13 -> Convolution13 (in-place)
I0612 11:07:31.672847  5211 layer_factory.hpp:77] Creating layer Scale13
I0612 11:07:31.673014  5211 net.cpp:240] Setting up Scale13
I0612 11:07:31.673027  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.673033  5211 net.cpp:255] Memory required for data: 571998720
I0612 11:07:31.673046  5211 layer_factory.hpp:77] Creating layer Eltwise6
I0612 11:07:31.673056  5211 net.cpp:190] Creating Layer Eltwise6
I0612 11:07:31.673063  5211 net.cpp:615] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0612 11:07:31.673071  5211 net.cpp:615] Eltwise6 <- Convolution13
I0612 11:07:31.673079  5211 net.cpp:589] Eltwise6 -> Eltwise6
I0612 11:07:31.673123  5211 net.cpp:240] Setting up Eltwise6
I0612 11:07:31.673133  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.673140  5211 net.cpp:255] Memory required for data: 580387328
I0612 11:07:31.673146  5211 layer_factory.hpp:77] Creating layer ReLU13
I0612 11:07:31.673164  5211 net.cpp:190] Creating Layer ReLU13
I0612 11:07:31.673177  5211 net.cpp:615] ReLU13 <- Eltwise6
I0612 11:07:31.673187  5211 net.cpp:576] ReLU13 -> Eltwise6 (in-place)
I0612 11:07:31.673197  5211 net.cpp:240] Setting up ReLU13
I0612 11:07:31.673205  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.673210  5211 net.cpp:255] Memory required for data: 588775936
I0612 11:07:31.673218  5211 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0612 11:07:31.673225  5211 net.cpp:190] Creating Layer Eltwise6_ReLU13_0_split
I0612 11:07:31.673231  5211 net.cpp:615] Eltwise6_ReLU13_0_split <- Eltwise6
I0612 11:07:31.673240  5211 net.cpp:589] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0612 11:07:31.673251  5211 net.cpp:589] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0612 11:07:31.673303  5211 net.cpp:240] Setting up Eltwise6_ReLU13_0_split
I0612 11:07:31.673313  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.673321  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.673326  5211 net.cpp:255] Memory required for data: 605553152
I0612 11:07:31.673332  5211 layer_factory.hpp:77] Creating layer Convolution14
I0612 11:07:31.673352  5211 net.cpp:190] Creating Layer Convolution14
I0612 11:07:31.673358  5211 net.cpp:615] Convolution14 <- Eltwise6_ReLU13_0_split_0
I0612 11:07:31.673368  5211 net.cpp:589] Convolution14 -> Convolution14
I0612 11:07:31.673851  5211 net.cpp:240] Setting up Convolution14
I0612 11:07:31.673864  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.673871  5211 net.cpp:255] Memory required for data: 613941760
I0612 11:07:31.673883  5211 layer_factory.hpp:77] Creating layer BatchNorm14
I0612 11:07:31.673893  5211 net.cpp:190] Creating Layer BatchNorm14
I0612 11:07:31.673900  5211 net.cpp:615] BatchNorm14 <- Convolution14
I0612 11:07:31.673912  5211 net.cpp:576] BatchNorm14 -> Convolution14 (in-place)
I0612 11:07:31.674206  5211 net.cpp:240] Setting up BatchNorm14
I0612 11:07:31.674218  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.674224  5211 net.cpp:255] Memory required for data: 622330368
I0612 11:07:31.674242  5211 layer_factory.hpp:77] Creating layer Scale14
I0612 11:07:31.674252  5211 net.cpp:190] Creating Layer Scale14
I0612 11:07:31.674258  5211 net.cpp:615] Scale14 <- Convolution14
I0612 11:07:31.674273  5211 net.cpp:576] Scale14 -> Convolution14 (in-place)
I0612 11:07:31.674321  5211 layer_factory.hpp:77] Creating layer Scale14
I0612 11:07:31.674499  5211 net.cpp:240] Setting up Scale14
I0612 11:07:31.674510  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.674516  5211 net.cpp:255] Memory required for data: 630718976
I0612 11:07:31.674530  5211 layer_factory.hpp:77] Creating layer ReLU14
I0612 11:07:31.674541  5211 net.cpp:190] Creating Layer ReLU14
I0612 11:07:31.674547  5211 net.cpp:615] ReLU14 <- Convolution14
I0612 11:07:31.674556  5211 net.cpp:576] ReLU14 -> Convolution14 (in-place)
I0612 11:07:31.674566  5211 net.cpp:240] Setting up ReLU14
I0612 11:07:31.674574  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.674581  5211 net.cpp:255] Memory required for data: 639107584
I0612 11:07:31.674585  5211 layer_factory.hpp:77] Creating layer Convolution15
I0612 11:07:31.674602  5211 net.cpp:190] Creating Layer Convolution15
I0612 11:07:31.674607  5211 net.cpp:615] Convolution15 <- Convolution14
I0612 11:07:31.674619  5211 net.cpp:589] Convolution15 -> Convolution15
I0612 11:07:31.675108  5211 net.cpp:240] Setting up Convolution15
I0612 11:07:31.675120  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.675127  5211 net.cpp:255] Memory required for data: 647496192
I0612 11:07:31.675139  5211 layer_factory.hpp:77] Creating layer BatchNorm15
I0612 11:07:31.675153  5211 net.cpp:190] Creating Layer BatchNorm15
I0612 11:07:31.675158  5211 net.cpp:615] BatchNorm15 <- Convolution15
I0612 11:07:31.675168  5211 net.cpp:576] BatchNorm15 -> Convolution15 (in-place)
I0612 11:07:31.675456  5211 net.cpp:240] Setting up BatchNorm15
I0612 11:07:31.675467  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.675477  5211 net.cpp:255] Memory required for data: 655884800
I0612 11:07:31.675495  5211 layer_factory.hpp:77] Creating layer Scale15
I0612 11:07:31.675505  5211 net.cpp:190] Creating Layer Scale15
I0612 11:07:31.675511  5211 net.cpp:615] Scale15 <- Convolution15
I0612 11:07:31.675524  5211 net.cpp:576] Scale15 -> Convolution15 (in-place)
I0612 11:07:31.675573  5211 layer_factory.hpp:77] Creating layer Scale15
I0612 11:07:31.675736  5211 net.cpp:240] Setting up Scale15
I0612 11:07:31.675746  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.675752  5211 net.cpp:255] Memory required for data: 664273408
I0612 11:07:31.675765  5211 layer_factory.hpp:77] Creating layer Eltwise7
I0612 11:07:31.675778  5211 net.cpp:190] Creating Layer Eltwise7
I0612 11:07:31.675786  5211 net.cpp:615] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0612 11:07:31.675793  5211 net.cpp:615] Eltwise7 <- Convolution15
I0612 11:07:31.675804  5211 net.cpp:589] Eltwise7 -> Eltwise7
I0612 11:07:31.675846  5211 net.cpp:240] Setting up Eltwise7
I0612 11:07:31.675856  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.675863  5211 net.cpp:255] Memory required for data: 672662016
I0612 11:07:31.675868  5211 layer_factory.hpp:77] Creating layer ReLU15
I0612 11:07:31.675876  5211 net.cpp:190] Creating Layer ReLU15
I0612 11:07:31.675882  5211 net.cpp:615] ReLU15 <- Eltwise7
I0612 11:07:31.675894  5211 net.cpp:576] ReLU15 -> Eltwise7 (in-place)
I0612 11:07:31.675904  5211 net.cpp:240] Setting up ReLU15
I0612 11:07:31.675912  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.675917  5211 net.cpp:255] Memory required for data: 681050624
I0612 11:07:31.675923  5211 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0612 11:07:31.675932  5211 net.cpp:190] Creating Layer Eltwise7_ReLU15_0_split
I0612 11:07:31.675938  5211 net.cpp:615] Eltwise7_ReLU15_0_split <- Eltwise7
I0612 11:07:31.675946  5211 net.cpp:589] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0612 11:07:31.675957  5211 net.cpp:589] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0612 11:07:31.676012  5211 net.cpp:240] Setting up Eltwise7_ReLU15_0_split
I0612 11:07:31.676023  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.676030  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.676035  5211 net.cpp:255] Memory required for data: 697827840
I0612 11:07:31.676041  5211 layer_factory.hpp:77] Creating layer Convolution16
I0612 11:07:31.676057  5211 net.cpp:190] Creating Layer Convolution16
I0612 11:07:31.676064  5211 net.cpp:615] Convolution16 <- Eltwise7_ReLU15_0_split_0
I0612 11:07:31.676074  5211 net.cpp:589] Convolution16 -> Convolution16
I0612 11:07:31.676555  5211 net.cpp:240] Setting up Convolution16
I0612 11:07:31.676568  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.676573  5211 net.cpp:255] Memory required for data: 706216448
I0612 11:07:31.676586  5211 layer_factory.hpp:77] Creating layer BatchNorm16
I0612 11:07:31.676599  5211 net.cpp:190] Creating Layer BatchNorm16
I0612 11:07:31.676605  5211 net.cpp:615] BatchNorm16 <- Convolution16
I0612 11:07:31.676616  5211 net.cpp:576] BatchNorm16 -> Convolution16 (in-place)
I0612 11:07:31.676908  5211 net.cpp:240] Setting up BatchNorm16
I0612 11:07:31.676920  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.676926  5211 net.cpp:255] Memory required for data: 714605056
I0612 11:07:31.676942  5211 layer_factory.hpp:77] Creating layer Scale16
I0612 11:07:31.676955  5211 net.cpp:190] Creating Layer Scale16
I0612 11:07:31.676961  5211 net.cpp:615] Scale16 <- Convolution16
I0612 11:07:31.676970  5211 net.cpp:576] Scale16 -> Convolution16 (in-place)
I0612 11:07:31.677026  5211 layer_factory.hpp:77] Creating layer Scale16
I0612 11:07:31.677196  5211 net.cpp:240] Setting up Scale16
I0612 11:07:31.677206  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.677212  5211 net.cpp:255] Memory required for data: 722993664
I0612 11:07:31.677227  5211 layer_factory.hpp:77] Creating layer ReLU16
I0612 11:07:31.677239  5211 net.cpp:190] Creating Layer ReLU16
I0612 11:07:31.677245  5211 net.cpp:615] ReLU16 <- Convolution16
I0612 11:07:31.677256  5211 net.cpp:576] ReLU16 -> Convolution16 (in-place)
I0612 11:07:31.677268  5211 net.cpp:240] Setting up ReLU16
I0612 11:07:31.677275  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.677281  5211 net.cpp:255] Memory required for data: 731382272
I0612 11:07:31.677286  5211 layer_factory.hpp:77] Creating layer Convolution17
I0612 11:07:31.677302  5211 net.cpp:190] Creating Layer Convolution17
I0612 11:07:31.677309  5211 net.cpp:615] Convolution17 <- Convolution16
I0612 11:07:31.677319  5211 net.cpp:589] Convolution17 -> Convolution17
I0612 11:07:31.677803  5211 net.cpp:240] Setting up Convolution17
I0612 11:07:31.677814  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.677820  5211 net.cpp:255] Memory required for data: 739770880
I0612 11:07:31.677834  5211 layer_factory.hpp:77] Creating layer BatchNorm17
I0612 11:07:31.677848  5211 net.cpp:190] Creating Layer BatchNorm17
I0612 11:07:31.677855  5211 net.cpp:615] BatchNorm17 <- Convolution17
I0612 11:07:31.677863  5211 net.cpp:576] BatchNorm17 -> Convolution17 (in-place)
I0612 11:07:31.678156  5211 net.cpp:240] Setting up BatchNorm17
I0612 11:07:31.678169  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.678174  5211 net.cpp:255] Memory required for data: 748159488
I0612 11:07:31.678194  5211 layer_factory.hpp:77] Creating layer Scale17
I0612 11:07:31.678205  5211 net.cpp:190] Creating Layer Scale17
I0612 11:07:31.678210  5211 net.cpp:615] Scale17 <- Convolution17
I0612 11:07:31.678220  5211 net.cpp:576] Scale17 -> Convolution17 (in-place)
I0612 11:07:31.678272  5211 layer_factory.hpp:77] Creating layer Scale17
I0612 11:07:31.678453  5211 net.cpp:240] Setting up Scale17
I0612 11:07:31.678465  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.678472  5211 net.cpp:255] Memory required for data: 756548096
I0612 11:07:31.678485  5211 layer_factory.hpp:77] Creating layer Eltwise8
I0612 11:07:31.678498  5211 net.cpp:190] Creating Layer Eltwise8
I0612 11:07:31.678505  5211 net.cpp:615] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0612 11:07:31.678524  5211 net.cpp:615] Eltwise8 <- Convolution17
I0612 11:07:31.678532  5211 net.cpp:589] Eltwise8 -> Eltwise8
I0612 11:07:31.678567  5211 net.cpp:240] Setting up Eltwise8
I0612 11:07:31.678576  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.678581  5211 net.cpp:255] Memory required for data: 764936704
I0612 11:07:31.678586  5211 layer_factory.hpp:77] Creating layer ReLU17
I0612 11:07:31.678596  5211 net.cpp:190] Creating Layer ReLU17
I0612 11:07:31.678601  5211 net.cpp:615] ReLU17 <- Eltwise8
I0612 11:07:31.678611  5211 net.cpp:576] ReLU17 -> Eltwise8 (in-place)
I0612 11:07:31.678620  5211 net.cpp:240] Setting up ReLU17
I0612 11:07:31.678628  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.678633  5211 net.cpp:255] Memory required for data: 773325312
I0612 11:07:31.678638  5211 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0612 11:07:31.678647  5211 net.cpp:190] Creating Layer Eltwise8_ReLU17_0_split
I0612 11:07:31.678653  5211 net.cpp:615] Eltwise8_ReLU17_0_split <- Eltwise8
I0612 11:07:31.678659  5211 net.cpp:589] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0612 11:07:31.678670  5211 net.cpp:589] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0612 11:07:31.678724  5211 net.cpp:240] Setting up Eltwise8_ReLU17_0_split
I0612 11:07:31.678732  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.678740  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.678745  5211 net.cpp:255] Memory required for data: 790102528
I0612 11:07:31.678750  5211 layer_factory.hpp:77] Creating layer Convolution18
I0612 11:07:31.678761  5211 net.cpp:190] Creating Layer Convolution18
I0612 11:07:31.678767  5211 net.cpp:615] Convolution18 <- Eltwise8_ReLU17_0_split_0
I0612 11:07:31.678781  5211 net.cpp:589] Convolution18 -> Convolution18
I0612 11:07:31.679251  5211 net.cpp:240] Setting up Convolution18
I0612 11:07:31.679263  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.679270  5211 net.cpp:255] Memory required for data: 798491136
I0612 11:07:31.679281  5211 layer_factory.hpp:77] Creating layer BatchNorm18
I0612 11:07:31.679291  5211 net.cpp:190] Creating Layer BatchNorm18
I0612 11:07:31.679297  5211 net.cpp:615] BatchNorm18 <- Convolution18
I0612 11:07:31.679306  5211 net.cpp:576] BatchNorm18 -> Convolution18 (in-place)
I0612 11:07:31.679590  5211 net.cpp:240] Setting up BatchNorm18
I0612 11:07:31.679601  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.679606  5211 net.cpp:255] Memory required for data: 806879744
I0612 11:07:31.679621  5211 layer_factory.hpp:77] Creating layer Scale18
I0612 11:07:31.679631  5211 net.cpp:190] Creating Layer Scale18
I0612 11:07:31.679637  5211 net.cpp:615] Scale18 <- Convolution18
I0612 11:07:31.679646  5211 net.cpp:576] Scale18 -> Convolution18 (in-place)
I0612 11:07:31.679703  5211 layer_factory.hpp:77] Creating layer Scale18
I0612 11:07:31.679859  5211 net.cpp:240] Setting up Scale18
I0612 11:07:31.679870  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.679875  5211 net.cpp:255] Memory required for data: 815268352
I0612 11:07:31.679890  5211 layer_factory.hpp:77] Creating layer ReLU18
I0612 11:07:31.679899  5211 net.cpp:190] Creating Layer ReLU18
I0612 11:07:31.679906  5211 net.cpp:615] ReLU18 <- Convolution18
I0612 11:07:31.679916  5211 net.cpp:576] ReLU18 -> Convolution18 (in-place)
I0612 11:07:31.679926  5211 net.cpp:240] Setting up ReLU18
I0612 11:07:31.679934  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.679939  5211 net.cpp:255] Memory required for data: 823656960
I0612 11:07:31.679945  5211 layer_factory.hpp:77] Creating layer Convolution19
I0612 11:07:31.679957  5211 net.cpp:190] Creating Layer Convolution19
I0612 11:07:31.679963  5211 net.cpp:615] Convolution19 <- Convolution18
I0612 11:07:31.679975  5211 net.cpp:589] Convolution19 -> Convolution19
I0612 11:07:31.680443  5211 net.cpp:240] Setting up Convolution19
I0612 11:07:31.680454  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.680459  5211 net.cpp:255] Memory required for data: 832045568
I0612 11:07:31.680472  5211 layer_factory.hpp:77] Creating layer BatchNorm19
I0612 11:07:31.680481  5211 net.cpp:190] Creating Layer BatchNorm19
I0612 11:07:31.680487  5211 net.cpp:615] BatchNorm19 <- Convolution19
I0612 11:07:31.680498  5211 net.cpp:576] BatchNorm19 -> Convolution19 (in-place)
I0612 11:07:31.680783  5211 net.cpp:240] Setting up BatchNorm19
I0612 11:07:31.680794  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.680799  5211 net.cpp:255] Memory required for data: 840434176
I0612 11:07:31.680838  5211 layer_factory.hpp:77] Creating layer Scale19
I0612 11:07:31.680850  5211 net.cpp:190] Creating Layer Scale19
I0612 11:07:31.680855  5211 net.cpp:615] Scale19 <- Convolution19
I0612 11:07:31.680865  5211 net.cpp:576] Scale19 -> Convolution19 (in-place)
I0612 11:07:31.680922  5211 layer_factory.hpp:77] Creating layer Scale19
I0612 11:07:31.681083  5211 net.cpp:240] Setting up Scale19
I0612 11:07:31.681093  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.681099  5211 net.cpp:255] Memory required for data: 848822784
I0612 11:07:31.681112  5211 layer_factory.hpp:77] Creating layer Eltwise9
I0612 11:07:31.681123  5211 net.cpp:190] Creating Layer Eltwise9
I0612 11:07:31.681129  5211 net.cpp:615] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0612 11:07:31.681136  5211 net.cpp:615] Eltwise9 <- Convolution19
I0612 11:07:31.681145  5211 net.cpp:589] Eltwise9 -> Eltwise9
I0612 11:07:31.681182  5211 net.cpp:240] Setting up Eltwise9
I0612 11:07:31.681190  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.681196  5211 net.cpp:255] Memory required for data: 857211392
I0612 11:07:31.681201  5211 layer_factory.hpp:77] Creating layer ReLU19
I0612 11:07:31.681210  5211 net.cpp:190] Creating Layer ReLU19
I0612 11:07:31.681218  5211 net.cpp:615] ReLU19 <- Eltwise9
I0612 11:07:31.681229  5211 net.cpp:576] ReLU19 -> Eltwise9 (in-place)
I0612 11:07:31.681239  5211 net.cpp:240] Setting up ReLU19
I0612 11:07:31.681247  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.681252  5211 net.cpp:255] Memory required for data: 865600000
I0612 11:07:31.681257  5211 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0612 11:07:31.681265  5211 net.cpp:190] Creating Layer Eltwise9_ReLU19_0_split
I0612 11:07:31.681270  5211 net.cpp:615] Eltwise9_ReLU19_0_split <- Eltwise9
I0612 11:07:31.681280  5211 net.cpp:589] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0612 11:07:31.681290  5211 net.cpp:589] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0612 11:07:31.681340  5211 net.cpp:240] Setting up Eltwise9_ReLU19_0_split
I0612 11:07:31.681349  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.681355  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.681361  5211 net.cpp:255] Memory required for data: 882377216
I0612 11:07:31.681366  5211 layer_factory.hpp:77] Creating layer Convolution20
I0612 11:07:31.681380  5211 net.cpp:190] Creating Layer Convolution20
I0612 11:07:31.681385  5211 net.cpp:615] Convolution20 <- Eltwise9_ReLU19_0_split_0
I0612 11:07:31.681397  5211 net.cpp:589] Convolution20 -> Convolution20
I0612 11:07:31.681850  5211 net.cpp:240] Setting up Convolution20
I0612 11:07:31.681861  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.681867  5211 net.cpp:255] Memory required for data: 890765824
I0612 11:07:31.681879  5211 layer_factory.hpp:77] Creating layer BatchNorm20
I0612 11:07:31.681890  5211 net.cpp:190] Creating Layer BatchNorm20
I0612 11:07:31.681895  5211 net.cpp:615] BatchNorm20 <- Convolution20
I0612 11:07:31.681905  5211 net.cpp:576] BatchNorm20 -> Convolution20 (in-place)
I0612 11:07:31.682178  5211 net.cpp:240] Setting up BatchNorm20
I0612 11:07:31.682188  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.682193  5211 net.cpp:255] Memory required for data: 899154432
I0612 11:07:31.682209  5211 layer_factory.hpp:77] Creating layer Scale20
I0612 11:07:31.682217  5211 net.cpp:190] Creating Layer Scale20
I0612 11:07:31.682224  5211 net.cpp:615] Scale20 <- Convolution20
I0612 11:07:31.682231  5211 net.cpp:576] Scale20 -> Convolution20 (in-place)
I0612 11:07:31.682281  5211 layer_factory.hpp:77] Creating layer Scale20
I0612 11:07:31.682452  5211 net.cpp:240] Setting up Scale20
I0612 11:07:31.682464  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.682469  5211 net.cpp:255] Memory required for data: 907543040
I0612 11:07:31.682482  5211 layer_factory.hpp:77] Creating layer ReLU20
I0612 11:07:31.682490  5211 net.cpp:190] Creating Layer ReLU20
I0612 11:07:31.682497  5211 net.cpp:615] ReLU20 <- Convolution20
I0612 11:07:31.682507  5211 net.cpp:576] ReLU20 -> Convolution20 (in-place)
I0612 11:07:31.682517  5211 net.cpp:240] Setting up ReLU20
I0612 11:07:31.682524  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.682529  5211 net.cpp:255] Memory required for data: 915931648
I0612 11:07:31.682535  5211 layer_factory.hpp:77] Creating layer Convolution21
I0612 11:07:31.682550  5211 net.cpp:190] Creating Layer Convolution21
I0612 11:07:31.682556  5211 net.cpp:615] Convolution21 <- Convolution20
I0612 11:07:31.682565  5211 net.cpp:589] Convolution21 -> Convolution21
I0612 11:07:31.683019  5211 net.cpp:240] Setting up Convolution21
I0612 11:07:31.683030  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.683037  5211 net.cpp:255] Memory required for data: 924320256
I0612 11:07:31.683048  5211 layer_factory.hpp:77] Creating layer BatchNorm21
I0612 11:07:31.683058  5211 net.cpp:190] Creating Layer BatchNorm21
I0612 11:07:31.683063  5211 net.cpp:615] BatchNorm21 <- Convolution21
I0612 11:07:31.683074  5211 net.cpp:576] BatchNorm21 -> Convolution21 (in-place)
I0612 11:07:31.683346  5211 net.cpp:240] Setting up BatchNorm21
I0612 11:07:31.683356  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.683364  5211 net.cpp:255] Memory required for data: 932708864
I0612 11:07:31.683379  5211 layer_factory.hpp:77] Creating layer Scale21
I0612 11:07:31.683388  5211 net.cpp:190] Creating Layer Scale21
I0612 11:07:31.683394  5211 net.cpp:615] Scale21 <- Convolution21
I0612 11:07:31.683404  5211 net.cpp:576] Scale21 -> Convolution21 (in-place)
I0612 11:07:31.683452  5211 layer_factory.hpp:77] Creating layer Scale21
I0612 11:07:31.683609  5211 net.cpp:240] Setting up Scale21
I0612 11:07:31.683619  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.683624  5211 net.cpp:255] Memory required for data: 941097472
I0612 11:07:31.683636  5211 layer_factory.hpp:77] Creating layer Eltwise10
I0612 11:07:31.683647  5211 net.cpp:190] Creating Layer Eltwise10
I0612 11:07:31.683655  5211 net.cpp:615] Eltwise10 <- Eltwise9_ReLU19_0_split_1
I0612 11:07:31.683661  5211 net.cpp:615] Eltwise10 <- Convolution21
I0612 11:07:31.683670  5211 net.cpp:589] Eltwise10 -> Eltwise10
I0612 11:07:31.683704  5211 net.cpp:240] Setting up Eltwise10
I0612 11:07:31.683714  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.683719  5211 net.cpp:255] Memory required for data: 949486080
I0612 11:07:31.683724  5211 layer_factory.hpp:77] Creating layer ReLU21
I0612 11:07:31.683733  5211 net.cpp:190] Creating Layer ReLU21
I0612 11:07:31.683738  5211 net.cpp:615] ReLU21 <- Eltwise10
I0612 11:07:31.683748  5211 net.cpp:576] ReLU21 -> Eltwise10 (in-place)
I0612 11:07:31.683758  5211 net.cpp:240] Setting up ReLU21
I0612 11:07:31.683765  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.683771  5211 net.cpp:255] Memory required for data: 957874688
I0612 11:07:31.683776  5211 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0612 11:07:31.683784  5211 net.cpp:190] Creating Layer Eltwise10_ReLU21_0_split
I0612 11:07:31.683790  5211 net.cpp:615] Eltwise10_ReLU21_0_split <- Eltwise10
I0612 11:07:31.683797  5211 net.cpp:589] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0612 11:07:31.683807  5211 net.cpp:589] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0612 11:07:31.683856  5211 net.cpp:240] Setting up Eltwise10_ReLU21_0_split
I0612 11:07:31.683866  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.683873  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.683878  5211 net.cpp:255] Memory required for data: 974651904
I0612 11:07:31.683883  5211 layer_factory.hpp:77] Creating layer Convolution22
I0612 11:07:31.683898  5211 net.cpp:190] Creating Layer Convolution22
I0612 11:07:31.683904  5211 net.cpp:615] Convolution22 <- Eltwise10_ReLU21_0_split_0
I0612 11:07:31.683914  5211 net.cpp:589] Convolution22 -> Convolution22
I0612 11:07:31.684365  5211 net.cpp:240] Setting up Convolution22
I0612 11:07:31.684376  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.684382  5211 net.cpp:255] Memory required for data: 983040512
I0612 11:07:31.684394  5211 layer_factory.hpp:77] Creating layer BatchNorm22
I0612 11:07:31.684406  5211 net.cpp:190] Creating Layer BatchNorm22
I0612 11:07:31.684413  5211 net.cpp:615] BatchNorm22 <- Convolution22
I0612 11:07:31.684422  5211 net.cpp:576] BatchNorm22 -> Convolution22 (in-place)
I0612 11:07:31.684700  5211 net.cpp:240] Setting up BatchNorm22
I0612 11:07:31.684710  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.684715  5211 net.cpp:255] Memory required for data: 991429120
I0612 11:07:31.684731  5211 layer_factory.hpp:77] Creating layer Scale22
I0612 11:07:31.684743  5211 net.cpp:190] Creating Layer Scale22
I0612 11:07:31.684749  5211 net.cpp:615] Scale22 <- Convolution22
I0612 11:07:31.684757  5211 net.cpp:576] Scale22 -> Convolution22 (in-place)
I0612 11:07:31.684804  5211 layer_factory.hpp:77] Creating layer Scale22
I0612 11:07:31.684964  5211 net.cpp:240] Setting up Scale22
I0612 11:07:31.684976  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.684983  5211 net.cpp:255] Memory required for data: 999817728
I0612 11:07:31.684994  5211 layer_factory.hpp:77] Creating layer ReLU22
I0612 11:07:31.685006  5211 net.cpp:190] Creating Layer ReLU22
I0612 11:07:31.685014  5211 net.cpp:615] ReLU22 <- Convolution22
I0612 11:07:31.685020  5211 net.cpp:576] ReLU22 -> Convolution22 (in-place)
I0612 11:07:31.685030  5211 net.cpp:240] Setting up ReLU22
I0612 11:07:31.685037  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.685044  5211 net.cpp:255] Memory required for data: 1008206336
I0612 11:07:31.685048  5211 layer_factory.hpp:77] Creating layer Convolution23
I0612 11:07:31.685063  5211 net.cpp:190] Creating Layer Convolution23
I0612 11:07:31.685070  5211 net.cpp:615] Convolution23 <- Convolution22
I0612 11:07:31.685081  5211 net.cpp:589] Convolution23 -> Convolution23
I0612 11:07:31.685528  5211 net.cpp:240] Setting up Convolution23
I0612 11:07:31.685539  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.685544  5211 net.cpp:255] Memory required for data: 1016594944
I0612 11:07:31.685556  5211 layer_factory.hpp:77] Creating layer BatchNorm23
I0612 11:07:31.685569  5211 net.cpp:190] Creating Layer BatchNorm23
I0612 11:07:31.685575  5211 net.cpp:615] BatchNorm23 <- Convolution23
I0612 11:07:31.685585  5211 net.cpp:576] BatchNorm23 -> Convolution23 (in-place)
I0612 11:07:31.685850  5211 net.cpp:240] Setting up BatchNorm23
I0612 11:07:31.685859  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.685865  5211 net.cpp:255] Memory required for data: 1024983552
I0612 11:07:31.685880  5211 layer_factory.hpp:77] Creating layer Scale23
I0612 11:07:31.685891  5211 net.cpp:190] Creating Layer Scale23
I0612 11:07:31.685897  5211 net.cpp:615] Scale23 <- Convolution23
I0612 11:07:31.685905  5211 net.cpp:576] Scale23 -> Convolution23 (in-place)
I0612 11:07:31.685956  5211 layer_factory.hpp:77] Creating layer Scale23
I0612 11:07:31.686117  5211 net.cpp:240] Setting up Scale23
I0612 11:07:31.686127  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.686132  5211 net.cpp:255] Memory required for data: 1033372160
I0612 11:07:31.686144  5211 layer_factory.hpp:77] Creating layer Eltwise11
I0612 11:07:31.686153  5211 net.cpp:190] Creating Layer Eltwise11
I0612 11:07:31.686161  5211 net.cpp:615] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0612 11:07:31.686167  5211 net.cpp:615] Eltwise11 <- Convolution23
I0612 11:07:31.686178  5211 net.cpp:589] Eltwise11 -> Eltwise11
I0612 11:07:31.686211  5211 net.cpp:240] Setting up Eltwise11
I0612 11:07:31.686223  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.686228  5211 net.cpp:255] Memory required for data: 1041760768
I0612 11:07:31.686233  5211 layer_factory.hpp:77] Creating layer ReLU23
I0612 11:07:31.686241  5211 net.cpp:190] Creating Layer ReLU23
I0612 11:07:31.686247  5211 net.cpp:615] ReLU23 <- Eltwise11
I0612 11:07:31.686254  5211 net.cpp:576] ReLU23 -> Eltwise11 (in-place)
I0612 11:07:31.686264  5211 net.cpp:240] Setting up ReLU23
I0612 11:07:31.686271  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.686277  5211 net.cpp:255] Memory required for data: 1050149376
I0612 11:07:31.686282  5211 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0612 11:07:31.686290  5211 net.cpp:190] Creating Layer Eltwise11_ReLU23_0_split
I0612 11:07:31.686295  5211 net.cpp:615] Eltwise11_ReLU23_0_split <- Eltwise11
I0612 11:07:31.686305  5211 net.cpp:589] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0612 11:07:31.686316  5211 net.cpp:589] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0612 11:07:31.686370  5211 net.cpp:240] Setting up Eltwise11_ReLU23_0_split
I0612 11:07:31.686383  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.686390  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.686395  5211 net.cpp:255] Memory required for data: 1066926592
I0612 11:07:31.686401  5211 layer_factory.hpp:77] Creating layer Convolution24
I0612 11:07:31.686414  5211 net.cpp:190] Creating Layer Convolution24
I0612 11:07:31.686419  5211 net.cpp:615] Convolution24 <- Eltwise11_ReLU23_0_split_0
I0612 11:07:31.686429  5211 net.cpp:589] Convolution24 -> Convolution24
I0612 11:07:31.686898  5211 net.cpp:240] Setting up Convolution24
I0612 11:07:31.686910  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.686916  5211 net.cpp:255] Memory required for data: 1075315200
I0612 11:07:31.686929  5211 layer_factory.hpp:77] Creating layer BatchNorm24
I0612 11:07:31.686941  5211 net.cpp:190] Creating Layer BatchNorm24
I0612 11:07:31.686947  5211 net.cpp:615] BatchNorm24 <- Convolution24
I0612 11:07:31.686955  5211 net.cpp:576] BatchNorm24 -> Convolution24 (in-place)
I0612 11:07:31.687223  5211 net.cpp:240] Setting up BatchNorm24
I0612 11:07:31.687234  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.687239  5211 net.cpp:255] Memory required for data: 1083703808
I0612 11:07:31.687258  5211 layer_factory.hpp:77] Creating layer Scale24
I0612 11:07:31.687268  5211 net.cpp:190] Creating Layer Scale24
I0612 11:07:31.687273  5211 net.cpp:615] Scale24 <- Convolution24
I0612 11:07:31.687281  5211 net.cpp:576] Scale24 -> Convolution24 (in-place)
I0612 11:07:31.687331  5211 layer_factory.hpp:77] Creating layer Scale24
I0612 11:07:31.687489  5211 net.cpp:240] Setting up Scale24
I0612 11:07:31.687500  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.687505  5211 net.cpp:255] Memory required for data: 1092092416
I0612 11:07:31.687517  5211 layer_factory.hpp:77] Creating layer ReLU24
I0612 11:07:31.687530  5211 net.cpp:190] Creating Layer ReLU24
I0612 11:07:31.687536  5211 net.cpp:615] ReLU24 <- Convolution24
I0612 11:07:31.687543  5211 net.cpp:576] ReLU24 -> Convolution24 (in-place)
I0612 11:07:31.687553  5211 net.cpp:240] Setting up ReLU24
I0612 11:07:31.687561  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.687566  5211 net.cpp:255] Memory required for data: 1100481024
I0612 11:07:31.687572  5211 layer_factory.hpp:77] Creating layer Convolution25
I0612 11:07:31.687585  5211 net.cpp:190] Creating Layer Convolution25
I0612 11:07:31.687592  5211 net.cpp:615] Convolution25 <- Convolution24
I0612 11:07:31.687602  5211 net.cpp:589] Convolution25 -> Convolution25
I0612 11:07:31.688052  5211 net.cpp:240] Setting up Convolution25
I0612 11:07:31.688063  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.688069  5211 net.cpp:255] Memory required for data: 1108869632
I0612 11:07:31.688081  5211 layer_factory.hpp:77] Creating layer BatchNorm25
I0612 11:07:31.688091  5211 net.cpp:190] Creating Layer BatchNorm25
I0612 11:07:31.688097  5211 net.cpp:615] BatchNorm25 <- Convolution25
I0612 11:07:31.688105  5211 net.cpp:576] BatchNorm25 -> Convolution25 (in-place)
I0612 11:07:31.688380  5211 net.cpp:240] Setting up BatchNorm25
I0612 11:07:31.688390  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.688395  5211 net.cpp:255] Memory required for data: 1117258240
I0612 11:07:31.688410  5211 layer_factory.hpp:77] Creating layer Scale25
I0612 11:07:31.688419  5211 net.cpp:190] Creating Layer Scale25
I0612 11:07:31.688424  5211 net.cpp:615] Scale25 <- Convolution25
I0612 11:07:31.688432  5211 net.cpp:576] Scale25 -> Convolution25 (in-place)
I0612 11:07:31.688483  5211 layer_factory.hpp:77] Creating layer Scale25
I0612 11:07:31.688637  5211 net.cpp:240] Setting up Scale25
I0612 11:07:31.688647  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.688652  5211 net.cpp:255] Memory required for data: 1125646848
I0612 11:07:31.688668  5211 layer_factory.hpp:77] Creating layer Eltwise12
I0612 11:07:31.688678  5211 net.cpp:190] Creating Layer Eltwise12
I0612 11:07:31.688683  5211 net.cpp:615] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0612 11:07:31.688690  5211 net.cpp:615] Eltwise12 <- Convolution25
I0612 11:07:31.688701  5211 net.cpp:589] Eltwise12 -> Eltwise12
I0612 11:07:31.688735  5211 net.cpp:240] Setting up Eltwise12
I0612 11:07:31.688745  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.688750  5211 net.cpp:255] Memory required for data: 1134035456
I0612 11:07:31.688755  5211 layer_factory.hpp:77] Creating layer ReLU25
I0612 11:07:31.688769  5211 net.cpp:190] Creating Layer ReLU25
I0612 11:07:31.688781  5211 net.cpp:615] ReLU25 <- Eltwise12
I0612 11:07:31.688788  5211 net.cpp:576] ReLU25 -> Eltwise12 (in-place)
I0612 11:07:31.688797  5211 net.cpp:240] Setting up ReLU25
I0612 11:07:31.688805  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.688810  5211 net.cpp:255] Memory required for data: 1142424064
I0612 11:07:31.688817  5211 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I0612 11:07:31.688823  5211 net.cpp:190] Creating Layer Eltwise12_ReLU25_0_split
I0612 11:07:31.688828  5211 net.cpp:615] Eltwise12_ReLU25_0_split <- Eltwise12
I0612 11:07:31.688838  5211 net.cpp:589] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I0612 11:07:31.688849  5211 net.cpp:589] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I0612 11:07:31.688910  5211 net.cpp:240] Setting up Eltwise12_ReLU25_0_split
I0612 11:07:31.688918  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.688926  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.688931  5211 net.cpp:255] Memory required for data: 1159201280
I0612 11:07:31.688937  5211 layer_factory.hpp:77] Creating layer Convolution26
I0612 11:07:31.688952  5211 net.cpp:190] Creating Layer Convolution26
I0612 11:07:31.688958  5211 net.cpp:615] Convolution26 <- Eltwise12_ReLU25_0_split_0
I0612 11:07:31.688968  5211 net.cpp:589] Convolution26 -> Convolution26
I0612 11:07:31.689420  5211 net.cpp:240] Setting up Convolution26
I0612 11:07:31.689431  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.689437  5211 net.cpp:255] Memory required for data: 1167589888
I0612 11:07:31.689450  5211 layer_factory.hpp:77] Creating layer BatchNorm26
I0612 11:07:31.689461  5211 net.cpp:190] Creating Layer BatchNorm26
I0612 11:07:31.689470  5211 net.cpp:615] BatchNorm26 <- Convolution26
I0612 11:07:31.689477  5211 net.cpp:576] BatchNorm26 -> Convolution26 (in-place)
I0612 11:07:31.689759  5211 net.cpp:240] Setting up BatchNorm26
I0612 11:07:31.689770  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.689775  5211 net.cpp:255] Memory required for data: 1175978496
I0612 11:07:31.689797  5211 layer_factory.hpp:77] Creating layer Scale26
I0612 11:07:31.689822  5211 net.cpp:190] Creating Layer Scale26
I0612 11:07:31.689829  5211 net.cpp:615] Scale26 <- Convolution26
I0612 11:07:31.689837  5211 net.cpp:576] Scale26 -> Convolution26 (in-place)
I0612 11:07:31.689889  5211 layer_factory.hpp:77] Creating layer Scale26
I0612 11:07:31.690058  5211 net.cpp:240] Setting up Scale26
I0612 11:07:31.690068  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.690074  5211 net.cpp:255] Memory required for data: 1184367104
I0612 11:07:31.690088  5211 layer_factory.hpp:77] Creating layer ReLU26
I0612 11:07:31.690095  5211 net.cpp:190] Creating Layer ReLU26
I0612 11:07:31.690101  5211 net.cpp:615] ReLU26 <- Convolution26
I0612 11:07:31.690109  5211 net.cpp:576] ReLU26 -> Convolution26 (in-place)
I0612 11:07:31.690119  5211 net.cpp:240] Setting up ReLU26
I0612 11:07:31.690126  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.690132  5211 net.cpp:255] Memory required for data: 1192755712
I0612 11:07:31.690137  5211 layer_factory.hpp:77] Creating layer Convolution27
I0612 11:07:31.690152  5211 net.cpp:190] Creating Layer Convolution27
I0612 11:07:31.690158  5211 net.cpp:615] Convolution27 <- Convolution26
I0612 11:07:31.690168  5211 net.cpp:589] Convolution27 -> Convolution27
I0612 11:07:31.690644  5211 net.cpp:240] Setting up Convolution27
I0612 11:07:31.690655  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.690660  5211 net.cpp:255] Memory required for data: 1201144320
I0612 11:07:31.690672  5211 layer_factory.hpp:77] Creating layer BatchNorm27
I0612 11:07:31.690685  5211 net.cpp:190] Creating Layer BatchNorm27
I0612 11:07:31.690691  5211 net.cpp:615] BatchNorm27 <- Convolution27
I0612 11:07:31.690701  5211 net.cpp:576] BatchNorm27 -> Convolution27 (in-place)
I0612 11:07:31.690963  5211 net.cpp:240] Setting up BatchNorm27
I0612 11:07:31.690973  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.690980  5211 net.cpp:255] Memory required for data: 1209532928
I0612 11:07:31.690995  5211 layer_factory.hpp:77] Creating layer Scale27
I0612 11:07:31.691007  5211 net.cpp:190] Creating Layer Scale27
I0612 11:07:31.691014  5211 net.cpp:615] Scale27 <- Convolution27
I0612 11:07:31.691020  5211 net.cpp:576] Scale27 -> Convolution27 (in-place)
I0612 11:07:31.691069  5211 layer_factory.hpp:77] Creating layer Scale27
I0612 11:07:31.691223  5211 net.cpp:240] Setting up Scale27
I0612 11:07:31.691233  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.691238  5211 net.cpp:255] Memory required for data: 1217921536
I0612 11:07:31.691251  5211 layer_factory.hpp:77] Creating layer Eltwise13
I0612 11:07:31.691258  5211 net.cpp:190] Creating Layer Eltwise13
I0612 11:07:31.691265  5211 net.cpp:615] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I0612 11:07:31.691272  5211 net.cpp:615] Eltwise13 <- Convolution27
I0612 11:07:31.691282  5211 net.cpp:589] Eltwise13 -> Eltwise13
I0612 11:07:31.691316  5211 net.cpp:240] Setting up Eltwise13
I0612 11:07:31.691325  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.691329  5211 net.cpp:255] Memory required for data: 1226310144
I0612 11:07:31.691334  5211 layer_factory.hpp:77] Creating layer ReLU27
I0612 11:07:31.691344  5211 net.cpp:190] Creating Layer ReLU27
I0612 11:07:31.691349  5211 net.cpp:615] ReLU27 <- Eltwise13
I0612 11:07:31.691355  5211 net.cpp:576] ReLU27 -> Eltwise13 (in-place)
I0612 11:07:31.691365  5211 net.cpp:240] Setting up ReLU27
I0612 11:07:31.691371  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.691376  5211 net.cpp:255] Memory required for data: 1234698752
I0612 11:07:31.691382  5211 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I0612 11:07:31.691395  5211 net.cpp:190] Creating Layer Eltwise13_ReLU27_0_split
I0612 11:07:31.691401  5211 net.cpp:615] Eltwise13_ReLU27_0_split <- Eltwise13
I0612 11:07:31.691407  5211 net.cpp:589] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I0612 11:07:31.691417  5211 net.cpp:589] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I0612 11:07:31.691464  5211 net.cpp:240] Setting up Eltwise13_ReLU27_0_split
I0612 11:07:31.691473  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.691479  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.691484  5211 net.cpp:255] Memory required for data: 1251475968
I0612 11:07:31.691489  5211 layer_factory.hpp:77] Creating layer Convolution28
I0612 11:07:31.691501  5211 net.cpp:190] Creating Layer Convolution28
I0612 11:07:31.691507  5211 net.cpp:615] Convolution28 <- Eltwise13_ReLU27_0_split_0
I0612 11:07:31.691516  5211 net.cpp:589] Convolution28 -> Convolution28
I0612 11:07:31.691941  5211 net.cpp:240] Setting up Convolution28
I0612 11:07:31.691951  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.691957  5211 net.cpp:255] Memory required for data: 1259864576
I0612 11:07:31.691969  5211 layer_factory.hpp:77] Creating layer BatchNorm28
I0612 11:07:31.691980  5211 net.cpp:190] Creating Layer BatchNorm28
I0612 11:07:31.691987  5211 net.cpp:615] BatchNorm28 <- Convolution28
I0612 11:07:31.691993  5211 net.cpp:576] BatchNorm28 -> Convolution28 (in-place)
I0612 11:07:31.692255  5211 net.cpp:240] Setting up BatchNorm28
I0612 11:07:31.692265  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.692270  5211 net.cpp:255] Memory required for data: 1268253184
I0612 11:07:31.692284  5211 layer_factory.hpp:77] Creating layer Scale28
I0612 11:07:31.692294  5211 net.cpp:190] Creating Layer Scale28
I0612 11:07:31.692299  5211 net.cpp:615] Scale28 <- Convolution28
I0612 11:07:31.692307  5211 net.cpp:576] Scale28 -> Convolution28 (in-place)
I0612 11:07:31.692353  5211 layer_factory.hpp:77] Creating layer Scale28
I0612 11:07:31.692503  5211 net.cpp:240] Setting up Scale28
I0612 11:07:31.692512  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.692517  5211 net.cpp:255] Memory required for data: 1276641792
I0612 11:07:31.692534  5211 layer_factory.hpp:77] Creating layer ReLU28
I0612 11:07:31.692543  5211 net.cpp:190] Creating Layer ReLU28
I0612 11:07:31.692549  5211 net.cpp:615] ReLU28 <- Convolution28
I0612 11:07:31.692556  5211 net.cpp:576] ReLU28 -> Convolution28 (in-place)
I0612 11:07:31.692565  5211 net.cpp:240] Setting up ReLU28
I0612 11:07:31.692572  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.692579  5211 net.cpp:255] Memory required for data: 1285030400
I0612 11:07:31.692584  5211 layer_factory.hpp:77] Creating layer Convolution29
I0612 11:07:31.692597  5211 net.cpp:190] Creating Layer Convolution29
I0612 11:07:31.692602  5211 net.cpp:615] Convolution29 <- Convolution28
I0612 11:07:31.692613  5211 net.cpp:589] Convolution29 -> Convolution29
I0612 11:07:31.693043  5211 net.cpp:240] Setting up Convolution29
I0612 11:07:31.693054  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.693059  5211 net.cpp:255] Memory required for data: 1293419008
I0612 11:07:31.693070  5211 layer_factory.hpp:77] Creating layer BatchNorm29
I0612 11:07:31.693079  5211 net.cpp:190] Creating Layer BatchNorm29
I0612 11:07:31.693086  5211 net.cpp:615] BatchNorm29 <- Convolution29
I0612 11:07:31.693096  5211 net.cpp:576] BatchNorm29 -> Convolution29 (in-place)
I0612 11:07:31.693356  5211 net.cpp:240] Setting up BatchNorm29
I0612 11:07:31.693366  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.693370  5211 net.cpp:255] Memory required for data: 1301807616
I0612 11:07:31.693384  5211 layer_factory.hpp:77] Creating layer Scale29
I0612 11:07:31.693393  5211 net.cpp:190] Creating Layer Scale29
I0612 11:07:31.693398  5211 net.cpp:615] Scale29 <- Convolution29
I0612 11:07:31.693406  5211 net.cpp:576] Scale29 -> Convolution29 (in-place)
I0612 11:07:31.693452  5211 layer_factory.hpp:77] Creating layer Scale29
I0612 11:07:31.693609  5211 net.cpp:240] Setting up Scale29
I0612 11:07:31.693619  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.693624  5211 net.cpp:255] Memory required for data: 1310196224
I0612 11:07:31.693635  5211 layer_factory.hpp:77] Creating layer Eltwise14
I0612 11:07:31.693645  5211 net.cpp:190] Creating Layer Eltwise14
I0612 11:07:31.693650  5211 net.cpp:615] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I0612 11:07:31.693656  5211 net.cpp:615] Eltwise14 <- Convolution29
I0612 11:07:31.693667  5211 net.cpp:589] Eltwise14 -> Eltwise14
I0612 11:07:31.693699  5211 net.cpp:240] Setting up Eltwise14
I0612 11:07:31.693707  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.693713  5211 net.cpp:255] Memory required for data: 1318584832
I0612 11:07:31.693718  5211 layer_factory.hpp:77] Creating layer ReLU29
I0612 11:07:31.693728  5211 net.cpp:190] Creating Layer ReLU29
I0612 11:07:31.693733  5211 net.cpp:615] ReLU29 <- Eltwise14
I0612 11:07:31.693742  5211 net.cpp:576] ReLU29 -> Eltwise14 (in-place)
I0612 11:07:31.693750  5211 net.cpp:240] Setting up ReLU29
I0612 11:07:31.693758  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.693763  5211 net.cpp:255] Memory required for data: 1326973440
I0612 11:07:31.693768  5211 layer_factory.hpp:77] Creating layer Eltwise14_ReLU29_0_split
I0612 11:07:31.693776  5211 net.cpp:190] Creating Layer Eltwise14_ReLU29_0_split
I0612 11:07:31.693783  5211 net.cpp:615] Eltwise14_ReLU29_0_split <- Eltwise14
I0612 11:07:31.693789  5211 net.cpp:589] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_0
I0612 11:07:31.693799  5211 net.cpp:589] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_1
I0612 11:07:31.693847  5211 net.cpp:240] Setting up Eltwise14_ReLU29_0_split
I0612 11:07:31.693856  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.693862  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.693867  5211 net.cpp:255] Memory required for data: 1343750656
I0612 11:07:31.693872  5211 layer_factory.hpp:77] Creating layer Convolution30
I0612 11:07:31.693886  5211 net.cpp:190] Creating Layer Convolution30
I0612 11:07:31.693892  5211 net.cpp:615] Convolution30 <- Eltwise14_ReLU29_0_split_0
I0612 11:07:31.693912  5211 net.cpp:589] Convolution30 -> Convolution30
I0612 11:07:31.694351  5211 net.cpp:240] Setting up Convolution30
I0612 11:07:31.694370  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.694375  5211 net.cpp:255] Memory required for data: 1352139264
I0612 11:07:31.694386  5211 layer_factory.hpp:77] Creating layer BatchNorm30
I0612 11:07:31.694399  5211 net.cpp:190] Creating Layer BatchNorm30
I0612 11:07:31.694406  5211 net.cpp:615] BatchNorm30 <- Convolution30
I0612 11:07:31.694413  5211 net.cpp:576] BatchNorm30 -> Convolution30 (in-place)
I0612 11:07:31.694679  5211 net.cpp:240] Setting up BatchNorm30
I0612 11:07:31.694689  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.694694  5211 net.cpp:255] Memory required for data: 1360527872
I0612 11:07:31.694708  5211 layer_factory.hpp:77] Creating layer Scale30
I0612 11:07:31.694717  5211 net.cpp:190] Creating Layer Scale30
I0612 11:07:31.694722  5211 net.cpp:615] Scale30 <- Convolution30
I0612 11:07:31.694732  5211 net.cpp:576] Scale30 -> Convolution30 (in-place)
I0612 11:07:31.694778  5211 layer_factory.hpp:77] Creating layer Scale30
I0612 11:07:31.694936  5211 net.cpp:240] Setting up Scale30
I0612 11:07:31.694946  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.694950  5211 net.cpp:255] Memory required for data: 1368916480
I0612 11:07:31.694964  5211 layer_factory.hpp:77] Creating layer ReLU30
I0612 11:07:31.694973  5211 net.cpp:190] Creating Layer ReLU30
I0612 11:07:31.694978  5211 net.cpp:615] ReLU30 <- Convolution30
I0612 11:07:31.694986  5211 net.cpp:576] ReLU30 -> Convolution30 (in-place)
I0612 11:07:31.694995  5211 net.cpp:240] Setting up ReLU30
I0612 11:07:31.695003  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.695008  5211 net.cpp:255] Memory required for data: 1377305088
I0612 11:07:31.695013  5211 layer_factory.hpp:77] Creating layer Convolution31
I0612 11:07:31.695026  5211 net.cpp:190] Creating Layer Convolution31
I0612 11:07:31.695032  5211 net.cpp:615] Convolution31 <- Convolution30
I0612 11:07:31.695044  5211 net.cpp:589] Convolution31 -> Convolution31
I0612 11:07:31.695477  5211 net.cpp:240] Setting up Convolution31
I0612 11:07:31.695487  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.695492  5211 net.cpp:255] Memory required for data: 1385693696
I0612 11:07:31.695505  5211 layer_factory.hpp:77] Creating layer BatchNorm31
I0612 11:07:31.695516  5211 net.cpp:190] Creating Layer BatchNorm31
I0612 11:07:31.695523  5211 net.cpp:615] BatchNorm31 <- Convolution31
I0612 11:07:31.695533  5211 net.cpp:576] BatchNorm31 -> Convolution31 (in-place)
I0612 11:07:31.695796  5211 net.cpp:240] Setting up BatchNorm31
I0612 11:07:31.695806  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.695811  5211 net.cpp:255] Memory required for data: 1394082304
I0612 11:07:31.695825  5211 layer_factory.hpp:77] Creating layer Scale31
I0612 11:07:31.695837  5211 net.cpp:190] Creating Layer Scale31
I0612 11:07:31.695842  5211 net.cpp:615] Scale31 <- Convolution31
I0612 11:07:31.695849  5211 net.cpp:576] Scale31 -> Convolution31 (in-place)
I0612 11:07:31.695894  5211 layer_factory.hpp:77] Creating layer Scale31
I0612 11:07:31.696048  5211 net.cpp:240] Setting up Scale31
I0612 11:07:31.696058  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.696063  5211 net.cpp:255] Memory required for data: 1402470912
I0612 11:07:31.696074  5211 layer_factory.hpp:77] Creating layer Eltwise15
I0612 11:07:31.696084  5211 net.cpp:190] Creating Layer Eltwise15
I0612 11:07:31.696089  5211 net.cpp:615] Eltwise15 <- Eltwise14_ReLU29_0_split_1
I0612 11:07:31.696096  5211 net.cpp:615] Eltwise15 <- Convolution31
I0612 11:07:31.696106  5211 net.cpp:589] Eltwise15 -> Eltwise15
I0612 11:07:31.696138  5211 net.cpp:240] Setting up Eltwise15
I0612 11:07:31.696149  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.696154  5211 net.cpp:255] Memory required for data: 1410859520
I0612 11:07:31.696159  5211 layer_factory.hpp:77] Creating layer ReLU31
I0612 11:07:31.696171  5211 net.cpp:190] Creating Layer ReLU31
I0612 11:07:31.696177  5211 net.cpp:615] ReLU31 <- Eltwise15
I0612 11:07:31.696183  5211 net.cpp:576] ReLU31 -> Eltwise15 (in-place)
I0612 11:07:31.696192  5211 net.cpp:240] Setting up ReLU31
I0612 11:07:31.696200  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.696205  5211 net.cpp:255] Memory required for data: 1419248128
I0612 11:07:31.696210  5211 layer_factory.hpp:77] Creating layer Eltwise15_ReLU31_0_split
I0612 11:07:31.696218  5211 net.cpp:190] Creating Layer Eltwise15_ReLU31_0_split
I0612 11:07:31.696223  5211 net.cpp:615] Eltwise15_ReLU31_0_split <- Eltwise15
I0612 11:07:31.696233  5211 net.cpp:589] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_0
I0612 11:07:31.696241  5211 net.cpp:589] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_1
I0612 11:07:31.696287  5211 net.cpp:240] Setting up Eltwise15_ReLU31_0_split
I0612 11:07:31.696295  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.696302  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.696307  5211 net.cpp:255] Memory required for data: 1436025344
I0612 11:07:31.696312  5211 layer_factory.hpp:77] Creating layer Convolution32
I0612 11:07:31.696326  5211 net.cpp:190] Creating Layer Convolution32
I0612 11:07:31.696332  5211 net.cpp:615] Convolution32 <- Eltwise15_ReLU31_0_split_0
I0612 11:07:31.696341  5211 net.cpp:589] Convolution32 -> Convolution32
I0612 11:07:31.696775  5211 net.cpp:240] Setting up Convolution32
I0612 11:07:31.696786  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.696791  5211 net.cpp:255] Memory required for data: 1444413952
I0612 11:07:31.696804  5211 layer_factory.hpp:77] Creating layer BatchNorm32
I0612 11:07:31.696815  5211 net.cpp:190] Creating Layer BatchNorm32
I0612 11:07:31.696821  5211 net.cpp:615] BatchNorm32 <- Convolution32
I0612 11:07:31.696830  5211 net.cpp:576] BatchNorm32 -> Convolution32 (in-place)
I0612 11:07:31.697091  5211 net.cpp:240] Setting up BatchNorm32
I0612 11:07:31.697101  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.697106  5211 net.cpp:255] Memory required for data: 1452802560
I0612 11:07:31.697124  5211 layer_factory.hpp:77] Creating layer Scale32
I0612 11:07:31.697134  5211 net.cpp:190] Creating Layer Scale32
I0612 11:07:31.697139  5211 net.cpp:615] Scale32 <- Convolution32
I0612 11:07:31.697146  5211 net.cpp:576] Scale32 -> Convolution32 (in-place)
I0612 11:07:31.697194  5211 layer_factory.hpp:77] Creating layer Scale32
I0612 11:07:31.697350  5211 net.cpp:240] Setting up Scale32
I0612 11:07:31.697358  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.697363  5211 net.cpp:255] Memory required for data: 1461191168
I0612 11:07:31.697376  5211 layer_factory.hpp:77] Creating layer ReLU32
I0612 11:07:31.697386  5211 net.cpp:190] Creating Layer ReLU32
I0612 11:07:31.697392  5211 net.cpp:615] ReLU32 <- Convolution32
I0612 11:07:31.697399  5211 net.cpp:576] ReLU32 -> Convolution32 (in-place)
I0612 11:07:31.697408  5211 net.cpp:240] Setting up ReLU32
I0612 11:07:31.697417  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.697420  5211 net.cpp:255] Memory required for data: 1469579776
I0612 11:07:31.697427  5211 layer_factory.hpp:77] Creating layer Convolution33
I0612 11:07:31.697439  5211 net.cpp:190] Creating Layer Convolution33
I0612 11:07:31.697444  5211 net.cpp:615] Convolution33 <- Convolution32
I0612 11:07:31.697453  5211 net.cpp:589] Convolution33 -> Convolution33
I0612 11:07:31.697880  5211 net.cpp:240] Setting up Convolution33
I0612 11:07:31.697890  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.697896  5211 net.cpp:255] Memory required for data: 1477968384
I0612 11:07:31.697907  5211 layer_factory.hpp:77] Creating layer BatchNorm33
I0612 11:07:31.697918  5211 net.cpp:190] Creating Layer BatchNorm33
I0612 11:07:31.697924  5211 net.cpp:615] BatchNorm33 <- Convolution33
I0612 11:07:31.697932  5211 net.cpp:576] BatchNorm33 -> Convolution33 (in-place)
I0612 11:07:31.698191  5211 net.cpp:240] Setting up BatchNorm33
I0612 11:07:31.698205  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.698210  5211 net.cpp:255] Memory required for data: 1486356992
I0612 11:07:31.698225  5211 layer_factory.hpp:77] Creating layer Scale33
I0612 11:07:31.698235  5211 net.cpp:190] Creating Layer Scale33
I0612 11:07:31.698240  5211 net.cpp:615] Scale33 <- Convolution33
I0612 11:07:31.698246  5211 net.cpp:576] Scale33 -> Convolution33 (in-place)
I0612 11:07:31.698299  5211 layer_factory.hpp:77] Creating layer Scale33
I0612 11:07:31.698459  5211 net.cpp:240] Setting up Scale33
I0612 11:07:31.698469  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.698474  5211 net.cpp:255] Memory required for data: 1494745600
I0612 11:07:31.698488  5211 layer_factory.hpp:77] Creating layer Eltwise16
I0612 11:07:31.698498  5211 net.cpp:190] Creating Layer Eltwise16
I0612 11:07:31.698505  5211 net.cpp:615] Eltwise16 <- Eltwise15_ReLU31_0_split_1
I0612 11:07:31.698513  5211 net.cpp:615] Eltwise16 <- Convolution33
I0612 11:07:31.698523  5211 net.cpp:589] Eltwise16 -> Eltwise16
I0612 11:07:31.698554  5211 net.cpp:240] Setting up Eltwise16
I0612 11:07:31.698562  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.698566  5211 net.cpp:255] Memory required for data: 1503134208
I0612 11:07:31.698571  5211 layer_factory.hpp:77] Creating layer ReLU33
I0612 11:07:31.698582  5211 net.cpp:190] Creating Layer ReLU33
I0612 11:07:31.698588  5211 net.cpp:615] ReLU33 <- Eltwise16
I0612 11:07:31.698596  5211 net.cpp:576] ReLU33 -> Eltwise16 (in-place)
I0612 11:07:31.698604  5211 net.cpp:240] Setting up ReLU33
I0612 11:07:31.698611  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.698616  5211 net.cpp:255] Memory required for data: 1511522816
I0612 11:07:31.698621  5211 layer_factory.hpp:77] Creating layer Eltwise16_ReLU33_0_split
I0612 11:07:31.698629  5211 net.cpp:190] Creating Layer Eltwise16_ReLU33_0_split
I0612 11:07:31.698634  5211 net.cpp:615] Eltwise16_ReLU33_0_split <- Eltwise16
I0612 11:07:31.698643  5211 net.cpp:589] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_0
I0612 11:07:31.698653  5211 net.cpp:589] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_1
I0612 11:07:31.698701  5211 net.cpp:240] Setting up Eltwise16_ReLU33_0_split
I0612 11:07:31.698710  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.698716  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.698721  5211 net.cpp:255] Memory required for data: 1528300032
I0612 11:07:31.698726  5211 layer_factory.hpp:77] Creating layer Convolution34
I0612 11:07:31.698737  5211 net.cpp:190] Creating Layer Convolution34
I0612 11:07:31.698743  5211 net.cpp:615] Convolution34 <- Eltwise16_ReLU33_0_split_0
I0612 11:07:31.698755  5211 net.cpp:589] Convolution34 -> Convolution34
I0612 11:07:31.699190  5211 net.cpp:240] Setting up Convolution34
I0612 11:07:31.699201  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.699206  5211 net.cpp:255] Memory required for data: 1536688640
I0612 11:07:31.699218  5211 layer_factory.hpp:77] Creating layer BatchNorm34
I0612 11:07:31.699228  5211 net.cpp:190] Creating Layer BatchNorm34
I0612 11:07:31.699232  5211 net.cpp:615] BatchNorm34 <- Convolution34
I0612 11:07:31.699242  5211 net.cpp:576] BatchNorm34 -> Convolution34 (in-place)
I0612 11:07:31.699506  5211 net.cpp:240] Setting up BatchNorm34
I0612 11:07:31.699515  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.699520  5211 net.cpp:255] Memory required for data: 1545077248
I0612 11:07:31.699534  5211 layer_factory.hpp:77] Creating layer Scale34
I0612 11:07:31.699543  5211 net.cpp:190] Creating Layer Scale34
I0612 11:07:31.699549  5211 net.cpp:615] Scale34 <- Convolution34
I0612 11:07:31.699559  5211 net.cpp:576] Scale34 -> Convolution34 (in-place)
I0612 11:07:31.699605  5211 layer_factory.hpp:77] Creating layer Scale34
I0612 11:07:31.699761  5211 net.cpp:240] Setting up Scale34
I0612 11:07:31.699771  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.699776  5211 net.cpp:255] Memory required for data: 1553465856
I0612 11:07:31.699791  5211 layer_factory.hpp:77] Creating layer ReLU34
I0612 11:07:31.699802  5211 net.cpp:190] Creating Layer ReLU34
I0612 11:07:31.699808  5211 net.cpp:615] ReLU34 <- Convolution34
I0612 11:07:31.699816  5211 net.cpp:576] ReLU34 -> Convolution34 (in-place)
I0612 11:07:31.699826  5211 net.cpp:240] Setting up ReLU34
I0612 11:07:31.699832  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.699837  5211 net.cpp:255] Memory required for data: 1561854464
I0612 11:07:31.699842  5211 layer_factory.hpp:77] Creating layer Convolution35
I0612 11:07:31.699856  5211 net.cpp:190] Creating Layer Convolution35
I0612 11:07:31.699862  5211 net.cpp:615] Convolution35 <- Convolution34
I0612 11:07:31.699870  5211 net.cpp:589] Convolution35 -> Convolution35
I0612 11:07:31.700310  5211 net.cpp:240] Setting up Convolution35
I0612 11:07:31.700321  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.700326  5211 net.cpp:255] Memory required for data: 1570243072
I0612 11:07:31.700337  5211 layer_factory.hpp:77] Creating layer BatchNorm35
I0612 11:07:31.700350  5211 net.cpp:190] Creating Layer BatchNorm35
I0612 11:07:31.700356  5211 net.cpp:615] BatchNorm35 <- Convolution35
I0612 11:07:31.700362  5211 net.cpp:576] BatchNorm35 -> Convolution35 (in-place)
I0612 11:07:31.700621  5211 net.cpp:240] Setting up BatchNorm35
I0612 11:07:31.700631  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.700636  5211 net.cpp:255] Memory required for data: 1578631680
I0612 11:07:31.700651  5211 layer_factory.hpp:77] Creating layer Scale35
I0612 11:07:31.700662  5211 net.cpp:190] Creating Layer Scale35
I0612 11:07:31.700669  5211 net.cpp:615] Scale35 <- Convolution35
I0612 11:07:31.700675  5211 net.cpp:576] Scale35 -> Convolution35 (in-place)
I0612 11:07:31.700719  5211 layer_factory.hpp:77] Creating layer Scale35
I0612 11:07:31.700870  5211 net.cpp:240] Setting up Scale35
I0612 11:07:31.700881  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.700886  5211 net.cpp:255] Memory required for data: 1587020288
I0612 11:07:31.700897  5211 layer_factory.hpp:77] Creating layer Eltwise17
I0612 11:07:31.700906  5211 net.cpp:190] Creating Layer Eltwise17
I0612 11:07:31.700912  5211 net.cpp:615] Eltwise17 <- Eltwise16_ReLU33_0_split_1
I0612 11:07:31.700919  5211 net.cpp:615] Eltwise17 <- Convolution35
I0612 11:07:31.700927  5211 net.cpp:589] Eltwise17 -> Eltwise17
I0612 11:07:31.700964  5211 net.cpp:240] Setting up Eltwise17
I0612 11:07:31.700973  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.700978  5211 net.cpp:255] Memory required for data: 1595408896
I0612 11:07:31.700989  5211 layer_factory.hpp:77] Creating layer ReLU35
I0612 11:07:31.700999  5211 net.cpp:190] Creating Layer ReLU35
I0612 11:07:31.701004  5211 net.cpp:615] ReLU35 <- Eltwise17
I0612 11:07:31.701011  5211 net.cpp:576] ReLU35 -> Eltwise17 (in-place)
I0612 11:07:31.701020  5211 net.cpp:240] Setting up ReLU35
I0612 11:07:31.701027  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.701032  5211 net.cpp:255] Memory required for data: 1603797504
I0612 11:07:31.701037  5211 layer_factory.hpp:77] Creating layer Eltwise17_ReLU35_0_split
I0612 11:07:31.701045  5211 net.cpp:190] Creating Layer Eltwise17_ReLU35_0_split
I0612 11:07:31.701050  5211 net.cpp:615] Eltwise17_ReLU35_0_split <- Eltwise17
I0612 11:07:31.701057  5211 net.cpp:589] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_0
I0612 11:07:31.701068  5211 net.cpp:589] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_1
I0612 11:07:31.701114  5211 net.cpp:240] Setting up Eltwise17_ReLU35_0_split
I0612 11:07:31.701122  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.701129  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.701134  5211 net.cpp:255] Memory required for data: 1620574720
I0612 11:07:31.701139  5211 layer_factory.hpp:77] Creating layer Convolution36
I0612 11:07:31.701153  5211 net.cpp:190] Creating Layer Convolution36
I0612 11:07:31.701164  5211 net.cpp:615] Convolution36 <- Eltwise17_ReLU35_0_split_0
I0612 11:07:31.701174  5211 net.cpp:589] Convolution36 -> Convolution36
I0612 11:07:31.701620  5211 net.cpp:240] Setting up Convolution36
I0612 11:07:31.701632  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.701638  5211 net.cpp:255] Memory required for data: 1628963328
I0612 11:07:31.701650  5211 layer_factory.hpp:77] Creating layer BatchNorm36
I0612 11:07:31.701663  5211 net.cpp:190] Creating Layer BatchNorm36
I0612 11:07:31.701668  5211 net.cpp:615] BatchNorm36 <- Convolution36
I0612 11:07:31.701678  5211 net.cpp:576] BatchNorm36 -> Convolution36 (in-place)
I0612 11:07:31.701944  5211 net.cpp:240] Setting up BatchNorm36
I0612 11:07:31.701954  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.701959  5211 net.cpp:255] Memory required for data: 1637351936
I0612 11:07:31.701974  5211 layer_factory.hpp:77] Creating layer Scale36
I0612 11:07:31.701985  5211 net.cpp:190] Creating Layer Scale36
I0612 11:07:31.701992  5211 net.cpp:615] Scale36 <- Convolution36
I0612 11:07:31.701998  5211 net.cpp:576] Scale36 -> Convolution36 (in-place)
I0612 11:07:31.702049  5211 layer_factory.hpp:77] Creating layer Scale36
I0612 11:07:31.702201  5211 net.cpp:240] Setting up Scale36
I0612 11:07:31.702211  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.702216  5211 net.cpp:255] Memory required for data: 1645740544
I0612 11:07:31.702229  5211 layer_factory.hpp:77] Creating layer ReLU36
I0612 11:07:31.702236  5211 net.cpp:190] Creating Layer ReLU36
I0612 11:07:31.702242  5211 net.cpp:615] ReLU36 <- Convolution36
I0612 11:07:31.702252  5211 net.cpp:576] ReLU36 -> Convolution36 (in-place)
I0612 11:07:31.702261  5211 net.cpp:240] Setting up ReLU36
I0612 11:07:31.702268  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.702273  5211 net.cpp:255] Memory required for data: 1654129152
I0612 11:07:31.702278  5211 layer_factory.hpp:77] Creating layer Convolution37
I0612 11:07:31.702292  5211 net.cpp:190] Creating Layer Convolution37
I0612 11:07:31.702298  5211 net.cpp:615] Convolution37 <- Convolution36
I0612 11:07:31.702306  5211 net.cpp:589] Convolution37 -> Convolution37
I0612 11:07:31.702750  5211 net.cpp:240] Setting up Convolution37
I0612 11:07:31.702762  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.702776  5211 net.cpp:255] Memory required for data: 1662517760
I0612 11:07:31.702788  5211 layer_factory.hpp:77] Creating layer BatchNorm37
I0612 11:07:31.702798  5211 net.cpp:190] Creating Layer BatchNorm37
I0612 11:07:31.702805  5211 net.cpp:615] BatchNorm37 <- Convolution37
I0612 11:07:31.702811  5211 net.cpp:576] BatchNorm37 -> Convolution37 (in-place)
I0612 11:07:31.703059  5211 net.cpp:240] Setting up BatchNorm37
I0612 11:07:31.703068  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.703073  5211 net.cpp:255] Memory required for data: 1670906368
I0612 11:07:31.703120  5211 layer_factory.hpp:77] Creating layer Scale37
I0612 11:07:31.703132  5211 net.cpp:190] Creating Layer Scale37
I0612 11:07:31.703137  5211 net.cpp:615] Scale37 <- Convolution37
I0612 11:07:31.703145  5211 net.cpp:576] Scale37 -> Convolution37 (in-place)
I0612 11:07:31.703192  5211 layer_factory.hpp:77] Creating layer Scale37
I0612 11:07:31.703341  5211 net.cpp:240] Setting up Scale37
I0612 11:07:31.703349  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.703354  5211 net.cpp:255] Memory required for data: 1679294976
I0612 11:07:31.703368  5211 layer_factory.hpp:77] Creating layer Eltwise18
I0612 11:07:31.703377  5211 net.cpp:190] Creating Layer Eltwise18
I0612 11:07:31.703383  5211 net.cpp:615] Eltwise18 <- Eltwise17_ReLU35_0_split_1
I0612 11:07:31.703389  5211 net.cpp:615] Eltwise18 <- Convolution37
I0612 11:07:31.703397  5211 net.cpp:589] Eltwise18 -> Eltwise18
I0612 11:07:31.703431  5211 net.cpp:240] Setting up Eltwise18
I0612 11:07:31.703439  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.703444  5211 net.cpp:255] Memory required for data: 1687683584
I0612 11:07:31.703452  5211 layer_factory.hpp:77] Creating layer ReLU37
I0612 11:07:31.703462  5211 net.cpp:190] Creating Layer ReLU37
I0612 11:07:31.703469  5211 net.cpp:615] ReLU37 <- Eltwise18
I0612 11:07:31.703475  5211 net.cpp:576] ReLU37 -> Eltwise18 (in-place)
I0612 11:07:31.703483  5211 net.cpp:240] Setting up ReLU37
I0612 11:07:31.703490  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.703495  5211 net.cpp:255] Memory required for data: 1696072192
I0612 11:07:31.703500  5211 layer_factory.hpp:77] Creating layer Eltwise18_ReLU37_0_split
I0612 11:07:31.703507  5211 net.cpp:190] Creating Layer Eltwise18_ReLU37_0_split
I0612 11:07:31.703512  5211 net.cpp:615] Eltwise18_ReLU37_0_split <- Eltwise18
I0612 11:07:31.703519  5211 net.cpp:589] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_0
I0612 11:07:31.703531  5211 net.cpp:589] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_1
I0612 11:07:31.703577  5211 net.cpp:240] Setting up Eltwise18_ReLU37_0_split
I0612 11:07:31.703585  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.703591  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.703595  5211 net.cpp:255] Memory required for data: 1712849408
I0612 11:07:31.703600  5211 layer_factory.hpp:77] Creating layer Pooling1
I0612 11:07:31.703611  5211 net.cpp:190] Creating Layer Pooling1
I0612 11:07:31.703618  5211 net.cpp:615] Pooling1 <- Eltwise18_ReLU37_0_split_0
I0612 11:07:31.703624  5211 net.cpp:589] Pooling1 -> Pooling1
I0612 11:07:31.703667  5211 net.cpp:240] Setting up Pooling1
I0612 11:07:31.703675  5211 net.cpp:247] Top shape: 128 16 16 16 (524288)
I0612 11:07:31.703680  5211 net.cpp:255] Memory required for data: 1714946560
I0612 11:07:31.703685  5211 layer_factory.hpp:77] Creating layer Input1
I0612 11:07:31.703694  5211 net.cpp:190] Creating Layer Input1
I0612 11:07:31.703704  5211 net.cpp:589] Input1 -> Input1
I0612 11:07:31.703744  5211 net.cpp:240] Setting up Input1
I0612 11:07:31.703753  5211 net.cpp:247] Top shape: 128 16 16 16 (524288)
I0612 11:07:31.703758  5211 net.cpp:255] Memory required for data: 1717043712
I0612 11:07:31.703763  5211 layer_factory.hpp:77] Creating layer Concat1
I0612 11:07:31.703770  5211 net.cpp:190] Creating Layer Concat1
I0612 11:07:31.703776  5211 net.cpp:615] Concat1 <- Pooling1
I0612 11:07:31.703783  5211 net.cpp:615] Concat1 <- Input1
I0612 11:07:31.703790  5211 net.cpp:589] Concat1 -> Concat1
I0612 11:07:31.703826  5211 net.cpp:240] Setting up Concat1
I0612 11:07:31.703835  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.703841  5211 net.cpp:255] Memory required for data: 1721238016
I0612 11:07:31.703846  5211 layer_factory.hpp:77] Creating layer Convolution38
I0612 11:07:31.703857  5211 net.cpp:190] Creating Layer Convolution38
I0612 11:07:31.703863  5211 net.cpp:615] Convolution38 <- Eltwise18_ReLU37_0_split_1
I0612 11:07:31.703874  5211 net.cpp:589] Convolution38 -> Convolution38
I0612 11:07:31.705101  5211 net.cpp:240] Setting up Convolution38
I0612 11:07:31.705118  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.705124  5211 net.cpp:255] Memory required for data: 1725432320
I0612 11:07:31.705137  5211 layer_factory.hpp:77] Creating layer BatchNorm38
I0612 11:07:31.705149  5211 net.cpp:190] Creating Layer BatchNorm38
I0612 11:07:31.705157  5211 net.cpp:615] BatchNorm38 <- Convolution38
I0612 11:07:31.705164  5211 net.cpp:576] BatchNorm38 -> Convolution38 (in-place)
I0612 11:07:31.705413  5211 net.cpp:240] Setting up BatchNorm38
I0612 11:07:31.705422  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.705427  5211 net.cpp:255] Memory required for data: 1729626624
I0612 11:07:31.705441  5211 layer_factory.hpp:77] Creating layer Scale38
I0612 11:07:31.705453  5211 net.cpp:190] Creating Layer Scale38
I0612 11:07:31.705459  5211 net.cpp:615] Scale38 <- Convolution38
I0612 11:07:31.705466  5211 net.cpp:576] Scale38 -> Convolution38 (in-place)
I0612 11:07:31.705514  5211 layer_factory.hpp:77] Creating layer Scale38
I0612 11:07:31.705665  5211 net.cpp:240] Setting up Scale38
I0612 11:07:31.705680  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.705685  5211 net.cpp:255] Memory required for data: 1733820928
I0612 11:07:31.705698  5211 layer_factory.hpp:77] Creating layer ReLU38
I0612 11:07:31.705708  5211 net.cpp:190] Creating Layer ReLU38
I0612 11:07:31.705714  5211 net.cpp:615] ReLU38 <- Convolution38
I0612 11:07:31.705721  5211 net.cpp:576] ReLU38 -> Convolution38 (in-place)
I0612 11:07:31.705730  5211 net.cpp:240] Setting up ReLU38
I0612 11:07:31.705737  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.705742  5211 net.cpp:255] Memory required for data: 1738015232
I0612 11:07:31.705747  5211 layer_factory.hpp:77] Creating layer Convolution39
I0612 11:07:31.705761  5211 net.cpp:190] Creating Layer Convolution39
I0612 11:07:31.705766  5211 net.cpp:615] Convolution39 <- Convolution38
I0612 11:07:31.705775  5211 net.cpp:589] Convolution39 -> Convolution39
I0612 11:07:31.706734  5211 net.cpp:240] Setting up Convolution39
I0612 11:07:31.706775  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.706784  5211 net.cpp:255] Memory required for data: 1742209536
I0612 11:07:31.706806  5211 layer_factory.hpp:77] Creating layer BatchNorm39
I0612 11:07:31.706827  5211 net.cpp:190] Creating Layer BatchNorm39
I0612 11:07:31.706837  5211 net.cpp:615] BatchNorm39 <- Convolution39
I0612 11:07:31.706851  5211 net.cpp:576] BatchNorm39 -> Convolution39 (in-place)
I0612 11:07:31.707211  5211 net.cpp:240] Setting up BatchNorm39
I0612 11:07:31.707226  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.707232  5211 net.cpp:255] Memory required for data: 1746403840
I0612 11:07:31.707260  5211 layer_factory.hpp:77] Creating layer Scale39
I0612 11:07:31.707274  5211 net.cpp:190] Creating Layer Scale39
I0612 11:07:31.707283  5211 net.cpp:615] Scale39 <- Convolution39
I0612 11:07:31.707293  5211 net.cpp:576] Scale39 -> Convolution39 (in-place)
I0612 11:07:31.707360  5211 layer_factory.hpp:77] Creating layer Scale39
I0612 11:07:31.707569  5211 net.cpp:240] Setting up Scale39
I0612 11:07:31.707581  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.707588  5211 net.cpp:255] Memory required for data: 1750598144
I0612 11:07:31.707604  5211 layer_factory.hpp:77] Creating layer Eltwise19
I0612 11:07:31.707622  5211 net.cpp:190] Creating Layer Eltwise19
I0612 11:07:31.707629  5211 net.cpp:615] Eltwise19 <- Concat1
I0612 11:07:31.707639  5211 net.cpp:615] Eltwise19 <- Convolution39
I0612 11:07:31.707655  5211 net.cpp:589] Eltwise19 -> Eltwise19
I0612 11:07:31.707690  5211 net.cpp:240] Setting up Eltwise19
I0612 11:07:31.707701  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.707708  5211 net.cpp:255] Memory required for data: 1754792448
I0612 11:07:31.707715  5211 layer_factory.hpp:77] Creating layer ReLU39
I0612 11:07:31.707726  5211 net.cpp:190] Creating Layer ReLU39
I0612 11:07:31.707733  5211 net.cpp:615] ReLU39 <- Eltwise19
I0612 11:07:31.707746  5211 net.cpp:576] ReLU39 -> Eltwise19 (in-place)
I0612 11:07:31.707759  5211 net.cpp:240] Setting up ReLU39
I0612 11:07:31.707768  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.707775  5211 net.cpp:255] Memory required for data: 1758986752
I0612 11:07:31.707782  5211 layer_factory.hpp:77] Creating layer Eltwise19_ReLU39_0_split
I0612 11:07:31.707792  5211 net.cpp:190] Creating Layer Eltwise19_ReLU39_0_split
I0612 11:07:31.707799  5211 net.cpp:615] Eltwise19_ReLU39_0_split <- Eltwise19
I0612 11:07:31.707809  5211 net.cpp:589] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_0
I0612 11:07:31.707821  5211 net.cpp:589] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_1
I0612 11:07:31.707886  5211 net.cpp:240] Setting up Eltwise19_ReLU39_0_split
I0612 11:07:31.707897  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.707906  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.707913  5211 net.cpp:255] Memory required for data: 1767375360
I0612 11:07:31.707919  5211 layer_factory.hpp:77] Creating layer Convolution40
I0612 11:07:31.707944  5211 net.cpp:190] Creating Layer Convolution40
I0612 11:07:31.707952  5211 net.cpp:615] Convolution40 <- Eltwise19_ReLU39_0_split_0
I0612 11:07:31.707968  5211 net.cpp:589] Convolution40 -> Convolution40
I0612 11:07:31.709034  5211 net.cpp:240] Setting up Convolution40
I0612 11:07:31.709049  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.709056  5211 net.cpp:255] Memory required for data: 1771569664
I0612 11:07:31.709074  5211 layer_factory.hpp:77] Creating layer BatchNorm40
I0612 11:07:31.709085  5211 net.cpp:190] Creating Layer BatchNorm40
I0612 11:07:31.709094  5211 net.cpp:615] BatchNorm40 <- Convolution40
I0612 11:07:31.709106  5211 net.cpp:576] BatchNorm40 -> Convolution40 (in-place)
I0612 11:07:31.709450  5211 net.cpp:240] Setting up BatchNorm40
I0612 11:07:31.709463  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.709470  5211 net.cpp:255] Memory required for data: 1775763968
I0612 11:07:31.709491  5211 layer_factory.hpp:77] Creating layer Scale40
I0612 11:07:31.709502  5211 net.cpp:190] Creating Layer Scale40
I0612 11:07:31.709509  5211 net.cpp:615] Scale40 <- Convolution40
I0612 11:07:31.709519  5211 net.cpp:576] Scale40 -> Convolution40 (in-place)
I0612 11:07:31.709581  5211 layer_factory.hpp:77] Creating layer Scale40
I0612 11:07:31.709782  5211 net.cpp:240] Setting up Scale40
I0612 11:07:31.709795  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.709801  5211 net.cpp:255] Memory required for data: 1779958272
I0612 11:07:31.709816  5211 layer_factory.hpp:77] Creating layer ReLU40
I0612 11:07:31.709830  5211 net.cpp:190] Creating Layer ReLU40
I0612 11:07:31.709838  5211 net.cpp:615] ReLU40 <- Convolution40
I0612 11:07:31.709848  5211 net.cpp:576] ReLU40 -> Convolution40 (in-place)
I0612 11:07:31.709859  5211 net.cpp:240] Setting up ReLU40
I0612 11:07:31.709869  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.709875  5211 net.cpp:255] Memory required for data: 1784152576
I0612 11:07:31.709882  5211 layer_factory.hpp:77] Creating layer Convolution41
I0612 11:07:31.709902  5211 net.cpp:190] Creating Layer Convolution41
I0612 11:07:31.709909  5211 net.cpp:615] Convolution41 <- Convolution40
I0612 11:07:31.709920  5211 net.cpp:589] Convolution41 -> Convolution41
I0612 11:07:31.711005  5211 net.cpp:240] Setting up Convolution41
I0612 11:07:31.711024  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.711030  5211 net.cpp:255] Memory required for data: 1788346880
I0612 11:07:31.711047  5211 layer_factory.hpp:77] Creating layer BatchNorm41
I0612 11:07:31.711063  5211 net.cpp:190] Creating Layer BatchNorm41
I0612 11:07:31.711072  5211 net.cpp:615] BatchNorm41 <- Convolution41
I0612 11:07:31.711083  5211 net.cpp:576] BatchNorm41 -> Convolution41 (in-place)
I0612 11:07:31.711590  5211 net.cpp:240] Setting up BatchNorm41
I0612 11:07:31.711611  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.711618  5211 net.cpp:255] Memory required for data: 1792541184
I0612 11:07:31.711642  5211 layer_factory.hpp:77] Creating layer Scale41
I0612 11:07:31.711655  5211 net.cpp:190] Creating Layer Scale41
I0612 11:07:31.711663  5211 net.cpp:615] Scale41 <- Convolution41
I0612 11:07:31.711678  5211 net.cpp:576] Scale41 -> Convolution41 (in-place)
I0612 11:07:31.711745  5211 layer_factory.hpp:77] Creating layer Scale41
I0612 11:07:31.711961  5211 net.cpp:240] Setting up Scale41
I0612 11:07:31.711976  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.711982  5211 net.cpp:255] Memory required for data: 1796735488
I0612 11:07:31.711999  5211 layer_factory.hpp:77] Creating layer Eltwise20
I0612 11:07:31.712015  5211 net.cpp:190] Creating Layer Eltwise20
I0612 11:07:31.712024  5211 net.cpp:615] Eltwise20 <- Eltwise19_ReLU39_0_split_1
I0612 11:07:31.712035  5211 net.cpp:615] Eltwise20 <- Convolution41
I0612 11:07:31.712046  5211 net.cpp:589] Eltwise20 -> Eltwise20
I0612 11:07:31.712086  5211 net.cpp:240] Setting up Eltwise20
I0612 11:07:31.712100  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.712112  5211 net.cpp:255] Memory required for data: 1800929792
I0612 11:07:31.712121  5211 layer_factory.hpp:77] Creating layer ReLU41
I0612 11:07:31.712131  5211 net.cpp:190] Creating Layer ReLU41
I0612 11:07:31.712139  5211 net.cpp:615] ReLU41 <- Eltwise20
I0612 11:07:31.712157  5211 net.cpp:576] ReLU41 -> Eltwise20 (in-place)
I0612 11:07:31.712170  5211 net.cpp:240] Setting up ReLU41
I0612 11:07:31.712182  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.712188  5211 net.cpp:255] Memory required for data: 1805124096
I0612 11:07:31.712195  5211 layer_factory.hpp:77] Creating layer Eltwise20_ReLU41_0_split
I0612 11:07:31.712205  5211 net.cpp:190] Creating Layer Eltwise20_ReLU41_0_split
I0612 11:07:31.712213  5211 net.cpp:615] Eltwise20_ReLU41_0_split <- Eltwise20
I0612 11:07:31.712224  5211 net.cpp:589] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_0
I0612 11:07:31.712237  5211 net.cpp:589] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_1
I0612 11:07:31.712308  5211 net.cpp:240] Setting up Eltwise20_ReLU41_0_split
I0612 11:07:31.712321  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.712329  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.712337  5211 net.cpp:255] Memory required for data: 1813512704
I0612 11:07:31.712343  5211 layer_factory.hpp:77] Creating layer Convolution42
I0612 11:07:31.712375  5211 net.cpp:190] Creating Layer Convolution42
I0612 11:07:31.712384  5211 net.cpp:615] Convolution42 <- Eltwise20_ReLU41_0_split_0
I0612 11:07:31.712398  5211 net.cpp:589] Convolution42 -> Convolution42
I0612 11:07:31.713536  5211 net.cpp:240] Setting up Convolution42
I0612 11:07:31.713551  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.713558  5211 net.cpp:255] Memory required for data: 1817707008
I0612 11:07:31.713577  5211 layer_factory.hpp:77] Creating layer BatchNorm42
I0612 11:07:31.713593  5211 net.cpp:190] Creating Layer BatchNorm42
I0612 11:07:31.713601  5211 net.cpp:615] BatchNorm42 <- Convolution42
I0612 11:07:31.713615  5211 net.cpp:576] BatchNorm42 -> Convolution42 (in-place)
I0612 11:07:31.713976  5211 net.cpp:240] Setting up BatchNorm42
I0612 11:07:31.713990  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.713997  5211 net.cpp:255] Memory required for data: 1821901312
I0612 11:07:31.714018  5211 layer_factory.hpp:77] Creating layer Scale42
I0612 11:07:31.714035  5211 net.cpp:190] Creating Layer Scale42
I0612 11:07:31.714043  5211 net.cpp:615] Scale42 <- Convolution42
I0612 11:07:31.714053  5211 net.cpp:576] Scale42 -> Convolution42 (in-place)
I0612 11:07:31.714115  5211 layer_factory.hpp:77] Creating layer Scale42
I0612 11:07:31.714332  5211 net.cpp:240] Setting up Scale42
I0612 11:07:31.714346  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.714364  5211 net.cpp:255] Memory required for data: 1826095616
I0612 11:07:31.714381  5211 layer_factory.hpp:77] Creating layer ReLU42
I0612 11:07:31.714393  5211 net.cpp:190] Creating Layer ReLU42
I0612 11:07:31.714402  5211 net.cpp:615] ReLU42 <- Convolution42
I0612 11:07:31.714416  5211 net.cpp:576] ReLU42 -> Convolution42 (in-place)
I0612 11:07:31.714431  5211 net.cpp:240] Setting up ReLU42
I0612 11:07:31.714440  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.714447  5211 net.cpp:255] Memory required for data: 1830289920
I0612 11:07:31.714454  5211 layer_factory.hpp:77] Creating layer Convolution43
I0612 11:07:31.714475  5211 net.cpp:190] Creating Layer Convolution43
I0612 11:07:31.714483  5211 net.cpp:615] Convolution43 <- Convolution42
I0612 11:07:31.714495  5211 net.cpp:589] Convolution43 -> Convolution43
I0612 11:07:31.715618  5211 net.cpp:240] Setting up Convolution43
I0612 11:07:31.715634  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.715641  5211 net.cpp:255] Memory required for data: 1834484224
I0612 11:07:31.715658  5211 layer_factory.hpp:77] Creating layer BatchNorm43
I0612 11:07:31.715674  5211 net.cpp:190] Creating Layer BatchNorm43
I0612 11:07:31.715683  5211 net.cpp:615] BatchNorm43 <- Convolution43
I0612 11:07:31.715699  5211 net.cpp:576] BatchNorm43 -> Convolution43 (in-place)
I0612 11:07:31.716068  5211 net.cpp:240] Setting up BatchNorm43
I0612 11:07:31.716083  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.716090  5211 net.cpp:255] Memory required for data: 1838678528
I0612 11:07:31.716110  5211 layer_factory.hpp:77] Creating layer Scale43
I0612 11:07:31.716127  5211 net.cpp:190] Creating Layer Scale43
I0612 11:07:31.716135  5211 net.cpp:615] Scale43 <- Convolution43
I0612 11:07:31.716146  5211 net.cpp:576] Scale43 -> Convolution43 (in-place)
I0612 11:07:31.716212  5211 layer_factory.hpp:77] Creating layer Scale43
I0612 11:07:31.716430  5211 net.cpp:240] Setting up Scale43
I0612 11:07:31.716444  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.716450  5211 net.cpp:255] Memory required for data: 1842872832
I0612 11:07:31.716467  5211 layer_factory.hpp:77] Creating layer Eltwise21
I0612 11:07:31.716486  5211 net.cpp:190] Creating Layer Eltwise21
I0612 11:07:31.716496  5211 net.cpp:615] Eltwise21 <- Eltwise20_ReLU41_0_split_1
I0612 11:07:31.716506  5211 net.cpp:615] Eltwise21 <- Convolution43
I0612 11:07:31.716518  5211 net.cpp:589] Eltwise21 -> Eltwise21
I0612 11:07:31.716557  5211 net.cpp:240] Setting up Eltwise21
I0612 11:07:31.716570  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.716576  5211 net.cpp:255] Memory required for data: 1847067136
I0612 11:07:31.716584  5211 layer_factory.hpp:77] Creating layer ReLU43
I0612 11:07:31.716595  5211 net.cpp:190] Creating Layer ReLU43
I0612 11:07:31.716603  5211 net.cpp:615] ReLU43 <- Eltwise21
I0612 11:07:31.716612  5211 net.cpp:576] ReLU43 -> Eltwise21 (in-place)
I0612 11:07:31.716625  5211 net.cpp:240] Setting up ReLU43
I0612 11:07:31.716635  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.716642  5211 net.cpp:255] Memory required for data: 1851261440
I0612 11:07:31.716650  5211 layer_factory.hpp:77] Creating layer Eltwise21_ReLU43_0_split
I0612 11:07:31.716665  5211 net.cpp:190] Creating Layer Eltwise21_ReLU43_0_split
I0612 11:07:31.716673  5211 net.cpp:615] Eltwise21_ReLU43_0_split <- Eltwise21
I0612 11:07:31.716684  5211 net.cpp:589] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_0
I0612 11:07:31.716698  5211 net.cpp:589] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_1
I0612 11:07:31.716768  5211 net.cpp:240] Setting up Eltwise21_ReLU43_0_split
I0612 11:07:31.716778  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.716789  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.716795  5211 net.cpp:255] Memory required for data: 1859650048
I0612 11:07:31.716802  5211 layer_factory.hpp:77] Creating layer Convolution44
I0612 11:07:31.716820  5211 net.cpp:190] Creating Layer Convolution44
I0612 11:07:31.716827  5211 net.cpp:615] Convolution44 <- Eltwise21_ReLU43_0_split_0
I0612 11:07:31.716840  5211 net.cpp:589] Convolution44 -> Convolution44
I0612 11:07:31.717969  5211 net.cpp:240] Setting up Convolution44
I0612 11:07:31.717984  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.717993  5211 net.cpp:255] Memory required for data: 1863844352
I0612 11:07:31.718009  5211 layer_factory.hpp:77] Creating layer BatchNorm44
I0612 11:07:31.718025  5211 net.cpp:190] Creating Layer BatchNorm44
I0612 11:07:31.718034  5211 net.cpp:615] BatchNorm44 <- Convolution44
I0612 11:07:31.718047  5211 net.cpp:576] BatchNorm44 -> Convolution44 (in-place)
I0612 11:07:31.718430  5211 net.cpp:240] Setting up BatchNorm44
I0612 11:07:31.718444  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.718451  5211 net.cpp:255] Memory required for data: 1868038656
I0612 11:07:31.718472  5211 layer_factory.hpp:77] Creating layer Scale44
I0612 11:07:31.718484  5211 net.cpp:190] Creating Layer Scale44
I0612 11:07:31.718492  5211 net.cpp:615] Scale44 <- Convolution44
I0612 11:07:31.718502  5211 net.cpp:576] Scale44 -> Convolution44 (in-place)
I0612 11:07:31.718569  5211 layer_factory.hpp:77] Creating layer Scale44
I0612 11:07:31.718796  5211 net.cpp:240] Setting up Scale44
I0612 11:07:31.718814  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.718822  5211 net.cpp:255] Memory required for data: 1872232960
I0612 11:07:31.718838  5211 layer_factory.hpp:77] Creating layer ReLU44
I0612 11:07:31.718850  5211 net.cpp:190] Creating Layer ReLU44
I0612 11:07:31.718859  5211 net.cpp:615] ReLU44 <- Convolution44
I0612 11:07:31.718873  5211 net.cpp:576] ReLU44 -> Convolution44 (in-place)
I0612 11:07:31.718886  5211 net.cpp:240] Setting up ReLU44
I0612 11:07:31.718896  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.718904  5211 net.cpp:255] Memory required for data: 1876427264
I0612 11:07:31.718910  5211 layer_factory.hpp:77] Creating layer Convolution45
I0612 11:07:31.718929  5211 net.cpp:190] Creating Layer Convolution45
I0612 11:07:31.718935  5211 net.cpp:615] Convolution45 <- Convolution44
I0612 11:07:31.718950  5211 net.cpp:589] Convolution45 -> Convolution45
I0612 11:07:31.720070  5211 net.cpp:240] Setting up Convolution45
I0612 11:07:31.720087  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.720093  5211 net.cpp:255] Memory required for data: 1880621568
I0612 11:07:31.720110  5211 layer_factory.hpp:77] Creating layer BatchNorm45
I0612 11:07:31.720124  5211 net.cpp:190] Creating Layer BatchNorm45
I0612 11:07:31.720130  5211 net.cpp:615] BatchNorm45 <- Convolution45
I0612 11:07:31.720144  5211 net.cpp:576] BatchNorm45 -> Convolution45 (in-place)
I0612 11:07:31.720515  5211 net.cpp:240] Setting up BatchNorm45
I0612 11:07:31.720528  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.720535  5211 net.cpp:255] Memory required for data: 1884815872
I0612 11:07:31.720556  5211 layer_factory.hpp:77] Creating layer Scale45
I0612 11:07:31.720569  5211 net.cpp:190] Creating Layer Scale45
I0612 11:07:31.720577  5211 net.cpp:615] Scale45 <- Convolution45
I0612 11:07:31.720587  5211 net.cpp:576] Scale45 -> Convolution45 (in-place)
I0612 11:07:31.720654  5211 layer_factory.hpp:77] Creating layer Scale45
I0612 11:07:31.720871  5211 net.cpp:240] Setting up Scale45
I0612 11:07:31.720885  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.720891  5211 net.cpp:255] Memory required for data: 1889010176
I0612 11:07:31.720907  5211 layer_factory.hpp:77] Creating layer Eltwise22
I0612 11:07:31.720923  5211 net.cpp:190] Creating Layer Eltwise22
I0612 11:07:31.720932  5211 net.cpp:615] Eltwise22 <- Eltwise21_ReLU43_0_split_1
I0612 11:07:31.720942  5211 net.cpp:615] Eltwise22 <- Convolution45
I0612 11:07:31.720953  5211 net.cpp:589] Eltwise22 -> Eltwise22
I0612 11:07:31.720988  5211 net.cpp:240] Setting up Eltwise22
I0612 11:07:31.721000  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.721007  5211 net.cpp:255] Memory required for data: 1893204480
I0612 11:07:31.721014  5211 layer_factory.hpp:77] Creating layer ReLU45
I0612 11:07:31.721029  5211 net.cpp:190] Creating Layer ReLU45
I0612 11:07:31.721037  5211 net.cpp:615] ReLU45 <- Eltwise22
I0612 11:07:31.721047  5211 net.cpp:576] ReLU45 -> Eltwise22 (in-place)
I0612 11:07:31.721060  5211 net.cpp:240] Setting up ReLU45
I0612 11:07:31.721070  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.721076  5211 net.cpp:255] Memory required for data: 1897398784
I0612 11:07:31.721084  5211 layer_factory.hpp:77] Creating layer Eltwise22_ReLU45_0_split
I0612 11:07:31.721099  5211 net.cpp:190] Creating Layer Eltwise22_ReLU45_0_split
I0612 11:07:31.721107  5211 net.cpp:615] Eltwise22_ReLU45_0_split <- Eltwise22
I0612 11:07:31.721117  5211 net.cpp:589] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_0
I0612 11:07:31.721130  5211 net.cpp:589] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_1
I0612 11:07:31.721199  5211 net.cpp:240] Setting up Eltwise22_ReLU45_0_split
I0612 11:07:31.721210  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.721220  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.721226  5211 net.cpp:255] Memory required for data: 1905787392
I0612 11:07:31.721233  5211 layer_factory.hpp:77] Creating layer Convolution46
I0612 11:07:31.721258  5211 net.cpp:190] Creating Layer Convolution46
I0612 11:07:31.721267  5211 net.cpp:615] Convolution46 <- Eltwise22_ReLU45_0_split_0
I0612 11:07:31.721281  5211 net.cpp:589] Convolution46 -> Convolution46
I0612 11:07:31.722434  5211 net.cpp:240] Setting up Convolution46
I0612 11:07:31.722450  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.722457  5211 net.cpp:255] Memory required for data: 1909981696
I0612 11:07:31.722475  5211 layer_factory.hpp:77] Creating layer BatchNorm46
I0612 11:07:31.722491  5211 net.cpp:190] Creating Layer BatchNorm46
I0612 11:07:31.722499  5211 net.cpp:615] BatchNorm46 <- Convolution46
I0612 11:07:31.722513  5211 net.cpp:576] BatchNorm46 -> Convolution46 (in-place)
I0612 11:07:31.722892  5211 net.cpp:240] Setting up BatchNorm46
I0612 11:07:31.722904  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.722911  5211 net.cpp:255] Memory required for data: 1914176000
I0612 11:07:31.722930  5211 layer_factory.hpp:77] Creating layer Scale46
I0612 11:07:31.722941  5211 net.cpp:190] Creating Layer Scale46
I0612 11:07:31.722949  5211 net.cpp:615] Scale46 <- Convolution46
I0612 11:07:31.722961  5211 net.cpp:576] Scale46 -> Convolution46 (in-place)
I0612 11:07:31.723021  5211 layer_factory.hpp:77] Creating layer Scale46
I0612 11:07:31.723227  5211 net.cpp:240] Setting up Scale46
I0612 11:07:31.723240  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.723248  5211 net.cpp:255] Memory required for data: 1918370304
I0612 11:07:31.723263  5211 layer_factory.hpp:77] Creating layer ReLU46
I0612 11:07:31.723274  5211 net.cpp:190] Creating Layer ReLU46
I0612 11:07:31.723281  5211 net.cpp:615] ReLU46 <- Convolution46
I0612 11:07:31.723291  5211 net.cpp:576] ReLU46 -> Convolution46 (in-place)
I0612 11:07:31.723304  5211 net.cpp:240] Setting up ReLU46
I0612 11:07:31.723312  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.723318  5211 net.cpp:255] Memory required for data: 1922564608
I0612 11:07:31.723325  5211 layer_factory.hpp:77] Creating layer Convolution47
I0612 11:07:31.723345  5211 net.cpp:190] Creating Layer Convolution47
I0612 11:07:31.723351  5211 net.cpp:615] Convolution47 <- Convolution46
I0612 11:07:31.723366  5211 net.cpp:589] Convolution47 -> Convolution47
I0612 11:07:31.724407  5211 net.cpp:240] Setting up Convolution47
I0612 11:07:31.724421  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.724428  5211 net.cpp:255] Memory required for data: 1926758912
I0612 11:07:31.724444  5211 layer_factory.hpp:77] Creating layer BatchNorm47
I0612 11:07:31.724462  5211 net.cpp:190] Creating Layer BatchNorm47
I0612 11:07:31.724469  5211 net.cpp:615] BatchNorm47 <- Convolution47
I0612 11:07:31.724481  5211 net.cpp:576] BatchNorm47 -> Convolution47 (in-place)
I0612 11:07:31.724822  5211 net.cpp:240] Setting up BatchNorm47
I0612 11:07:31.724833  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.724840  5211 net.cpp:255] Memory required for data: 1930953216
I0612 11:07:31.724859  5211 layer_factory.hpp:77] Creating layer Scale47
I0612 11:07:31.724877  5211 net.cpp:190] Creating Layer Scale47
I0612 11:07:31.724885  5211 net.cpp:615] Scale47 <- Convolution47
I0612 11:07:31.724895  5211 net.cpp:576] Scale47 -> Convolution47 (in-place)
I0612 11:07:31.724952  5211 layer_factory.hpp:77] Creating layer Scale47
I0612 11:07:31.725157  5211 net.cpp:240] Setting up Scale47
I0612 11:07:31.725168  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.725174  5211 net.cpp:255] Memory required for data: 1935147520
I0612 11:07:31.725190  5211 layer_factory.hpp:77] Creating layer Eltwise23
I0612 11:07:31.725201  5211 net.cpp:190] Creating Layer Eltwise23
I0612 11:07:31.725209  5211 net.cpp:615] Eltwise23 <- Eltwise22_ReLU45_0_split_1
I0612 11:07:31.725219  5211 net.cpp:615] Eltwise23 <- Convolution47
I0612 11:07:31.725234  5211 net.cpp:589] Eltwise23 -> Eltwise23
I0612 11:07:31.725267  5211 net.cpp:240] Setting up Eltwise23
I0612 11:07:31.725281  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.725292  5211 net.cpp:255] Memory required for data: 1939341824
I0612 11:07:31.725299  5211 layer_factory.hpp:77] Creating layer ReLU47
I0612 11:07:31.725311  5211 net.cpp:190] Creating Layer ReLU47
I0612 11:07:31.725317  5211 net.cpp:615] ReLU47 <- Eltwise23
I0612 11:07:31.725327  5211 net.cpp:576] ReLU47 -> Eltwise23 (in-place)
I0612 11:07:31.725338  5211 net.cpp:240] Setting up ReLU47
I0612 11:07:31.725347  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.725353  5211 net.cpp:255] Memory required for data: 1943536128
I0612 11:07:31.725360  5211 layer_factory.hpp:77] Creating layer Eltwise23_ReLU47_0_split
I0612 11:07:31.725370  5211 net.cpp:190] Creating Layer Eltwise23_ReLU47_0_split
I0612 11:07:31.725376  5211 net.cpp:615] Eltwise23_ReLU47_0_split <- Eltwise23
I0612 11:07:31.725389  5211 net.cpp:589] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_0
I0612 11:07:31.725402  5211 net.cpp:589] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_1
I0612 11:07:31.725463  5211 net.cpp:240] Setting up Eltwise23_ReLU47_0_split
I0612 11:07:31.725473  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.725481  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.725488  5211 net.cpp:255] Memory required for data: 1951924736
I0612 11:07:31.725494  5211 layer_factory.hpp:77] Creating layer Convolution48
I0612 11:07:31.725513  5211 net.cpp:190] Creating Layer Convolution48
I0612 11:07:31.725522  5211 net.cpp:615] Convolution48 <- Eltwise23_ReLU47_0_split_0
I0612 11:07:31.725533  5211 net.cpp:589] Convolution48 -> Convolution48
I0612 11:07:31.726603  5211 net.cpp:240] Setting up Convolution48
I0612 11:07:31.726619  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.726625  5211 net.cpp:255] Memory required for data: 1956119040
I0612 11:07:31.726641  5211 layer_factory.hpp:77] Creating layer BatchNorm48
I0612 11:07:31.726656  5211 net.cpp:190] Creating Layer BatchNorm48
I0612 11:07:31.726665  5211 net.cpp:615] BatchNorm48 <- Convolution48
I0612 11:07:31.726675  5211 net.cpp:576] BatchNorm48 -> Convolution48 (in-place)
I0612 11:07:31.727020  5211 net.cpp:240] Setting up BatchNorm48
I0612 11:07:31.727032  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.727040  5211 net.cpp:255] Memory required for data: 1960313344
I0612 11:07:31.727061  5211 layer_factory.hpp:77] Creating layer Scale48
I0612 11:07:31.727072  5211 net.cpp:190] Creating Layer Scale48
I0612 11:07:31.727080  5211 net.cpp:615] Scale48 <- Convolution48
I0612 11:07:31.727089  5211 net.cpp:576] Scale48 -> Convolution48 (in-place)
I0612 11:07:31.727150  5211 layer_factory.hpp:77] Creating layer Scale48
I0612 11:07:31.727360  5211 net.cpp:240] Setting up Scale48
I0612 11:07:31.727371  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.727377  5211 net.cpp:255] Memory required for data: 1964507648
I0612 11:07:31.727399  5211 layer_factory.hpp:77] Creating layer ReLU48
I0612 11:07:31.727411  5211 net.cpp:190] Creating Layer ReLU48
I0612 11:07:31.727418  5211 net.cpp:615] ReLU48 <- Convolution48
I0612 11:07:31.727428  5211 net.cpp:576] ReLU48 -> Convolution48 (in-place)
I0612 11:07:31.727440  5211 net.cpp:240] Setting up ReLU48
I0612 11:07:31.727449  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.727457  5211 net.cpp:255] Memory required for data: 1968701952
I0612 11:07:31.727463  5211 layer_factory.hpp:77] Creating layer Convolution49
I0612 11:07:31.727481  5211 net.cpp:190] Creating Layer Convolution49
I0612 11:07:31.727488  5211 net.cpp:615] Convolution49 <- Convolution48
I0612 11:07:31.727502  5211 net.cpp:589] Convolution49 -> Convolution49
I0612 11:07:31.728544  5211 net.cpp:240] Setting up Convolution49
I0612 11:07:31.728559  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.728565  5211 net.cpp:255] Memory required for data: 1972896256
I0612 11:07:31.728580  5211 layer_factory.hpp:77] Creating layer BatchNorm49
I0612 11:07:31.728592  5211 net.cpp:190] Creating Layer BatchNorm49
I0612 11:07:31.728605  5211 net.cpp:615] BatchNorm49 <- Convolution49
I0612 11:07:31.728618  5211 net.cpp:576] BatchNorm49 -> Convolution49 (in-place)
I0612 11:07:31.728957  5211 net.cpp:240] Setting up BatchNorm49
I0612 11:07:31.728970  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.728976  5211 net.cpp:255] Memory required for data: 1977090560
I0612 11:07:31.728996  5211 layer_factory.hpp:77] Creating layer Scale49
I0612 11:07:31.729007  5211 net.cpp:190] Creating Layer Scale49
I0612 11:07:31.729013  5211 net.cpp:615] Scale49 <- Convolution49
I0612 11:07:31.729023  5211 net.cpp:576] Scale49 -> Convolution49 (in-place)
I0612 11:07:31.729084  5211 layer_factory.hpp:77] Creating layer Scale49
I0612 11:07:31.729297  5211 net.cpp:240] Setting up Scale49
I0612 11:07:31.729310  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.729316  5211 net.cpp:255] Memory required for data: 1981284864
I0612 11:07:31.729331  5211 layer_factory.hpp:77] Creating layer Eltwise24
I0612 11:07:31.729343  5211 net.cpp:190] Creating Layer Eltwise24
I0612 11:07:31.729351  5211 net.cpp:615] Eltwise24 <- Eltwise23_ReLU47_0_split_1
I0612 11:07:31.729364  5211 net.cpp:615] Eltwise24 <- Convolution49
I0612 11:07:31.729374  5211 net.cpp:589] Eltwise24 -> Eltwise24
I0612 11:07:31.729408  5211 net.cpp:240] Setting up Eltwise24
I0612 11:07:31.729419  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.729425  5211 net.cpp:255] Memory required for data: 1985479168
I0612 11:07:31.729432  5211 layer_factory.hpp:77] Creating layer ReLU49
I0612 11:07:31.729446  5211 net.cpp:190] Creating Layer ReLU49
I0612 11:07:31.729454  5211 net.cpp:615] ReLU49 <- Eltwise24
I0612 11:07:31.729463  5211 net.cpp:576] ReLU49 -> Eltwise24 (in-place)
I0612 11:07:31.729475  5211 net.cpp:240] Setting up ReLU49
I0612 11:07:31.729485  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.729490  5211 net.cpp:255] Memory required for data: 1989673472
I0612 11:07:31.729496  5211 layer_factory.hpp:77] Creating layer Eltwise24_ReLU49_0_split
I0612 11:07:31.729506  5211 net.cpp:190] Creating Layer Eltwise24_ReLU49_0_split
I0612 11:07:31.729513  5211 net.cpp:615] Eltwise24_ReLU49_0_split <- Eltwise24
I0612 11:07:31.729526  5211 net.cpp:589] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_0
I0612 11:07:31.729538  5211 net.cpp:589] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_1
I0612 11:07:31.729605  5211 net.cpp:240] Setting up Eltwise24_ReLU49_0_split
I0612 11:07:31.729615  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.729624  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.729631  5211 net.cpp:255] Memory required for data: 1998062080
I0612 11:07:31.729637  5211 layer_factory.hpp:77] Creating layer Convolution50
I0612 11:07:31.729653  5211 net.cpp:190] Creating Layer Convolution50
I0612 11:07:31.729660  5211 net.cpp:615] Convolution50 <- Eltwise24_ReLU49_0_split_0
I0612 11:07:31.729676  5211 net.cpp:589] Convolution50 -> Convolution50
I0612 11:07:31.731727  5211 net.cpp:240] Setting up Convolution50
I0612 11:07:31.731753  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.731761  5211 net.cpp:255] Memory required for data: 2002256384
I0612 11:07:31.731780  5211 layer_factory.hpp:77] Creating layer BatchNorm50
I0612 11:07:31.731801  5211 net.cpp:190] Creating Layer BatchNorm50
I0612 11:07:31.731812  5211 net.cpp:615] BatchNorm50 <- Convolution50
I0612 11:07:31.731827  5211 net.cpp:576] BatchNorm50 -> Convolution50 (in-place)
I0612 11:07:31.732162  5211 net.cpp:240] Setting up BatchNorm50
I0612 11:07:31.732177  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.732183  5211 net.cpp:255] Memory required for data: 2006450688
I0612 11:07:31.732203  5211 layer_factory.hpp:77] Creating layer Scale50
I0612 11:07:31.732218  5211 net.cpp:190] Creating Layer Scale50
I0612 11:07:31.732228  5211 net.cpp:615] Scale50 <- Convolution50
I0612 11:07:31.732237  5211 net.cpp:576] Scale50 -> Convolution50 (in-place)
I0612 11:07:31.732295  5211 layer_factory.hpp:77] Creating layer Scale50
I0612 11:07:31.732499  5211 net.cpp:240] Setting up Scale50
I0612 11:07:31.732512  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.732519  5211 net.cpp:255] Memory required for data: 2010644992
I0612 11:07:31.732535  5211 layer_factory.hpp:77] Creating layer ReLU50
I0612 11:07:31.732547  5211 net.cpp:190] Creating Layer ReLU50
I0612 11:07:31.732554  5211 net.cpp:615] ReLU50 <- Convolution50
I0612 11:07:31.732568  5211 net.cpp:576] ReLU50 -> Convolution50 (in-place)
I0612 11:07:31.732580  5211 net.cpp:240] Setting up ReLU50
I0612 11:07:31.732589  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.732596  5211 net.cpp:255] Memory required for data: 2014839296
I0612 11:07:31.732602  5211 layer_factory.hpp:77] Creating layer Convolution51
I0612 11:07:31.732621  5211 net.cpp:190] Creating Layer Convolution51
I0612 11:07:31.732630  5211 net.cpp:615] Convolution51 <- Convolution50
I0612 11:07:31.732640  5211 net.cpp:589] Convolution51 -> Convolution51
I0612 11:07:31.733678  5211 net.cpp:240] Setting up Convolution51
I0612 11:07:31.733692  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.733698  5211 net.cpp:255] Memory required for data: 2019033600
I0612 11:07:31.733714  5211 layer_factory.hpp:77] Creating layer BatchNorm51
I0612 11:07:31.733729  5211 net.cpp:190] Creating Layer BatchNorm51
I0612 11:07:31.733737  5211 net.cpp:615] BatchNorm51 <- Convolution51
I0612 11:07:31.733750  5211 net.cpp:576] BatchNorm51 -> Convolution51 (in-place)
I0612 11:07:31.734083  5211 net.cpp:240] Setting up BatchNorm51
I0612 11:07:31.734096  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.734102  5211 net.cpp:255] Memory required for data: 2023227904
I0612 11:07:31.734122  5211 layer_factory.hpp:77] Creating layer Scale51
I0612 11:07:31.734136  5211 net.cpp:190] Creating Layer Scale51
I0612 11:07:31.734143  5211 net.cpp:615] Scale51 <- Convolution51
I0612 11:07:31.734153  5211 net.cpp:576] Scale51 -> Convolution51 (in-place)
I0612 11:07:31.734215  5211 layer_factory.hpp:77] Creating layer Scale51
I0612 11:07:31.734431  5211 net.cpp:240] Setting up Scale51
I0612 11:07:31.734444  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.734452  5211 net.cpp:255] Memory required for data: 2027422208
I0612 11:07:31.734467  5211 layer_factory.hpp:77] Creating layer Eltwise25
I0612 11:07:31.734526  5211 net.cpp:190] Creating Layer Eltwise25
I0612 11:07:31.734537  5211 net.cpp:615] Eltwise25 <- Eltwise24_ReLU49_0_split_1
I0612 11:07:31.734547  5211 net.cpp:615] Eltwise25 <- Convolution51
I0612 11:07:31.734558  5211 net.cpp:589] Eltwise25 -> Eltwise25
I0612 11:07:31.734596  5211 net.cpp:240] Setting up Eltwise25
I0612 11:07:31.734608  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.734614  5211 net.cpp:255] Memory required for data: 2031616512
I0612 11:07:31.734622  5211 layer_factory.hpp:77] Creating layer ReLU51
I0612 11:07:31.734637  5211 net.cpp:190] Creating Layer ReLU51
I0612 11:07:31.734645  5211 net.cpp:615] ReLU51 <- Eltwise25
I0612 11:07:31.734655  5211 net.cpp:576] ReLU51 -> Eltwise25 (in-place)
I0612 11:07:31.734666  5211 net.cpp:240] Setting up ReLU51
I0612 11:07:31.734676  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.734683  5211 net.cpp:255] Memory required for data: 2035810816
I0612 11:07:31.734689  5211 layer_factory.hpp:77] Creating layer Eltwise25_ReLU51_0_split
I0612 11:07:31.734699  5211 net.cpp:190] Creating Layer Eltwise25_ReLU51_0_split
I0612 11:07:31.734706  5211 net.cpp:615] Eltwise25_ReLU51_0_split <- Eltwise25
I0612 11:07:31.734717  5211 net.cpp:589] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_0
I0612 11:07:31.734730  5211 net.cpp:589] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_1
I0612 11:07:31.734793  5211 net.cpp:240] Setting up Eltwise25_ReLU51_0_split
I0612 11:07:31.734804  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.734813  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.734820  5211 net.cpp:255] Memory required for data: 2044199424
I0612 11:07:31.734830  5211 layer_factory.hpp:77] Creating layer Convolution52
I0612 11:07:31.734850  5211 net.cpp:190] Creating Layer Convolution52
I0612 11:07:31.734858  5211 net.cpp:615] Convolution52 <- Eltwise25_ReLU51_0_split_0
I0612 11:07:31.734871  5211 net.cpp:589] Convolution52 -> Convolution52
I0612 11:07:31.735913  5211 net.cpp:240] Setting up Convolution52
I0612 11:07:31.735927  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.735934  5211 net.cpp:255] Memory required for data: 2048393728
I0612 11:07:31.735950  5211 layer_factory.hpp:77] Creating layer BatchNorm52
I0612 11:07:31.735966  5211 net.cpp:190] Creating Layer BatchNorm52
I0612 11:07:31.735975  5211 net.cpp:615] BatchNorm52 <- Convolution52
I0612 11:07:31.735986  5211 net.cpp:576] BatchNorm52 -> Convolution52 (in-place)
I0612 11:07:31.736316  5211 net.cpp:240] Setting up BatchNorm52
I0612 11:07:31.736330  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.736335  5211 net.cpp:255] Memory required for data: 2052588032
I0612 11:07:31.736354  5211 layer_factory.hpp:77] Creating layer Scale52
I0612 11:07:31.736366  5211 net.cpp:190] Creating Layer Scale52
I0612 11:07:31.736373  5211 net.cpp:615] Scale52 <- Convolution52
I0612 11:07:31.736387  5211 net.cpp:576] Scale52 -> Convolution52 (in-place)
I0612 11:07:31.736443  5211 layer_factory.hpp:77] Creating layer Scale52
I0612 11:07:31.736647  5211 net.cpp:240] Setting up Scale52
I0612 11:07:31.736660  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.736666  5211 net.cpp:255] Memory required for data: 2056782336
I0612 11:07:31.736682  5211 layer_factory.hpp:77] Creating layer ReLU52
I0612 11:07:31.736693  5211 net.cpp:190] Creating Layer ReLU52
I0612 11:07:31.736701  5211 net.cpp:615] ReLU52 <- Convolution52
I0612 11:07:31.736711  5211 net.cpp:576] ReLU52 -> Convolution52 (in-place)
I0612 11:07:31.736721  5211 net.cpp:240] Setting up ReLU52
I0612 11:07:31.736732  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.736738  5211 net.cpp:255] Memory required for data: 2060976640
I0612 11:07:31.736744  5211 layer_factory.hpp:77] Creating layer Convolution53
I0612 11:07:31.736763  5211 net.cpp:190] Creating Layer Convolution53
I0612 11:07:31.736771  5211 net.cpp:615] Convolution53 <- Convolution52
I0612 11:07:31.736785  5211 net.cpp:589] Convolution53 -> Convolution53
I0612 11:07:31.737823  5211 net.cpp:240] Setting up Convolution53
I0612 11:07:31.737836  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.737843  5211 net.cpp:255] Memory required for data: 2065170944
I0612 11:07:31.737859  5211 layer_factory.hpp:77] Creating layer BatchNorm53
I0612 11:07:31.737872  5211 net.cpp:190] Creating Layer BatchNorm53
I0612 11:07:31.737880  5211 net.cpp:615] BatchNorm53 <- Convolution53
I0612 11:07:31.737893  5211 net.cpp:576] BatchNorm53 -> Convolution53 (in-place)
I0612 11:07:31.738230  5211 net.cpp:240] Setting up BatchNorm53
I0612 11:07:31.738242  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.738248  5211 net.cpp:255] Memory required for data: 2069365248
I0612 11:07:31.738268  5211 layer_factory.hpp:77] Creating layer Scale53
I0612 11:07:31.738283  5211 net.cpp:190] Creating Layer Scale53
I0612 11:07:31.738291  5211 net.cpp:615] Scale53 <- Convolution53
I0612 11:07:31.738301  5211 net.cpp:576] Scale53 -> Convolution53 (in-place)
I0612 11:07:31.738369  5211 layer_factory.hpp:77] Creating layer Scale53
I0612 11:07:31.738577  5211 net.cpp:240] Setting up Scale53
I0612 11:07:31.738590  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.738596  5211 net.cpp:255] Memory required for data: 2073559552
I0612 11:07:31.738612  5211 layer_factory.hpp:77] Creating layer Eltwise26
I0612 11:07:31.738625  5211 net.cpp:190] Creating Layer Eltwise26
I0612 11:07:31.738632  5211 net.cpp:615] Eltwise26 <- Eltwise25_ReLU51_0_split_1
I0612 11:07:31.738642  5211 net.cpp:615] Eltwise26 <- Convolution53
I0612 11:07:31.738656  5211 net.cpp:589] Eltwise26 -> Eltwise26
I0612 11:07:31.738688  5211 net.cpp:240] Setting up Eltwise26
I0612 11:07:31.738708  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.738714  5211 net.cpp:255] Memory required for data: 2077753856
I0612 11:07:31.738721  5211 layer_factory.hpp:77] Creating layer ReLU53
I0612 11:07:31.738732  5211 net.cpp:190] Creating Layer ReLU53
I0612 11:07:31.738739  5211 net.cpp:615] ReLU53 <- Eltwise26
I0612 11:07:31.738749  5211 net.cpp:576] ReLU53 -> Eltwise26 (in-place)
I0612 11:07:31.738760  5211 net.cpp:240] Setting up ReLU53
I0612 11:07:31.738770  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.738776  5211 net.cpp:255] Memory required for data: 2081948160
I0612 11:07:31.738783  5211 layer_factory.hpp:77] Creating layer Eltwise26_ReLU53_0_split
I0612 11:07:31.738792  5211 net.cpp:190] Creating Layer Eltwise26_ReLU53_0_split
I0612 11:07:31.738800  5211 net.cpp:615] Eltwise26_ReLU53_0_split <- Eltwise26
I0612 11:07:31.738818  5211 net.cpp:589] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_0
I0612 11:07:31.738831  5211 net.cpp:589] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_1
I0612 11:07:31.738891  5211 net.cpp:240] Setting up Eltwise26_ReLU53_0_split
I0612 11:07:31.738903  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.738911  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.738917  5211 net.cpp:255] Memory required for data: 2090336768
I0612 11:07:31.738924  5211 layer_factory.hpp:77] Creating layer Convolution54
I0612 11:07:31.738943  5211 net.cpp:190] Creating Layer Convolution54
I0612 11:07:31.738951  5211 net.cpp:615] Convolution54 <- Eltwise26_ReLU53_0_split_0
I0612 11:07:31.738963  5211 net.cpp:589] Convolution54 -> Convolution54
I0612 11:07:31.740020  5211 net.cpp:240] Setting up Convolution54
I0612 11:07:31.740034  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.740041  5211 net.cpp:255] Memory required for data: 2094531072
I0612 11:07:31.740056  5211 layer_factory.hpp:77] Creating layer BatchNorm54
I0612 11:07:31.740073  5211 net.cpp:190] Creating Layer BatchNorm54
I0612 11:07:31.740082  5211 net.cpp:615] BatchNorm54 <- Convolution54
I0612 11:07:31.740092  5211 net.cpp:576] BatchNorm54 -> Convolution54 (in-place)
I0612 11:07:31.740424  5211 net.cpp:240] Setting up BatchNorm54
I0612 11:07:31.740437  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.740443  5211 net.cpp:255] Memory required for data: 2098725376
I0612 11:07:31.740466  5211 layer_factory.hpp:77] Creating layer Scale54
I0612 11:07:31.740478  5211 net.cpp:190] Creating Layer Scale54
I0612 11:07:31.740485  5211 net.cpp:615] Scale54 <- Convolution54
I0612 11:07:31.740495  5211 net.cpp:576] Scale54 -> Convolution54 (in-place)
I0612 11:07:31.740556  5211 layer_factory.hpp:77] Creating layer Scale54
I0612 11:07:31.740757  5211 net.cpp:240] Setting up Scale54
I0612 11:07:31.740769  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.740775  5211 net.cpp:255] Memory required for data: 2102919680
I0612 11:07:31.740794  5211 layer_factory.hpp:77] Creating layer ReLU54
I0612 11:07:31.740805  5211 net.cpp:190] Creating Layer ReLU54
I0612 11:07:31.740813  5211 net.cpp:615] ReLU54 <- Convolution54
I0612 11:07:31.740823  5211 net.cpp:576] ReLU54 -> Convolution54 (in-place)
I0612 11:07:31.740838  5211 net.cpp:240] Setting up ReLU54
I0612 11:07:31.740847  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.740854  5211 net.cpp:255] Memory required for data: 2107113984
I0612 11:07:31.740860  5211 layer_factory.hpp:77] Creating layer Convolution55
I0612 11:07:31.740875  5211 net.cpp:190] Creating Layer Convolution55
I0612 11:07:31.740883  5211 net.cpp:615] Convolution55 <- Convolution54
I0612 11:07:31.740896  5211 net.cpp:589] Convolution55 -> Convolution55
I0612 11:07:31.741937  5211 net.cpp:240] Setting up Convolution55
I0612 11:07:31.741952  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.741960  5211 net.cpp:255] Memory required for data: 2111308288
I0612 11:07:31.741974  5211 layer_factory.hpp:77] Creating layer BatchNorm55
I0612 11:07:31.741992  5211 net.cpp:190] Creating Layer BatchNorm55
I0612 11:07:31.742000  5211 net.cpp:615] BatchNorm55 <- Convolution55
I0612 11:07:31.742013  5211 net.cpp:576] BatchNorm55 -> Convolution55 (in-place)
I0612 11:07:31.742364  5211 net.cpp:240] Setting up BatchNorm55
I0612 11:07:31.742377  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.742384  5211 net.cpp:255] Memory required for data: 2115502592
I0612 11:07:31.742404  5211 layer_factory.hpp:77] Creating layer Scale55
I0612 11:07:31.742416  5211 net.cpp:190] Creating Layer Scale55
I0612 11:07:31.742424  5211 net.cpp:615] Scale55 <- Convolution55
I0612 11:07:31.742432  5211 net.cpp:576] Scale55 -> Convolution55 (in-place)
I0612 11:07:31.742494  5211 layer_factory.hpp:77] Creating layer Scale55
I0612 11:07:31.742693  5211 net.cpp:240] Setting up Scale55
I0612 11:07:31.742705  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.742712  5211 net.cpp:255] Memory required for data: 2119696896
I0612 11:07:31.742727  5211 layer_factory.hpp:77] Creating layer Eltwise27
I0612 11:07:31.742739  5211 net.cpp:190] Creating Layer Eltwise27
I0612 11:07:31.742748  5211 net.cpp:615] Eltwise27 <- Eltwise26_ReLU53_0_split_1
I0612 11:07:31.742759  5211 net.cpp:615] Eltwise27 <- Convolution55
I0612 11:07:31.742770  5211 net.cpp:589] Eltwise27 -> Eltwise27
I0612 11:07:31.742802  5211 net.cpp:240] Setting up Eltwise27
I0612 11:07:31.742813  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.742820  5211 net.cpp:255] Memory required for data: 2123891200
I0612 11:07:31.742825  5211 layer_factory.hpp:77] Creating layer ReLU55
I0612 11:07:31.742840  5211 net.cpp:190] Creating Layer ReLU55
I0612 11:07:31.742847  5211 net.cpp:615] ReLU55 <- Eltwise27
I0612 11:07:31.742856  5211 net.cpp:576] ReLU55 -> Eltwise27 (in-place)
I0612 11:07:31.742868  5211 net.cpp:240] Setting up ReLU55
I0612 11:07:31.742877  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.742883  5211 net.cpp:255] Memory required for data: 2128085504
I0612 11:07:31.742890  5211 layer_factory.hpp:77] Creating layer Eltwise27_ReLU55_0_split
I0612 11:07:31.742900  5211 net.cpp:190] Creating Layer Eltwise27_ReLU55_0_split
I0612 11:07:31.742908  5211 net.cpp:615] Eltwise27_ReLU55_0_split <- Eltwise27
I0612 11:07:31.742919  5211 net.cpp:589] Eltwise27_ReLU55_0_split -> Eltwise27_ReLU55_0_split_0
I0612 11:07:31.742933  5211 net.cpp:589] Eltwise27_ReLU55_0_split -> Eltwise27_ReLU55_0_split_1
I0612 11:07:31.742995  5211 net.cpp:240] Setting up Eltwise27_ReLU55_0_split
I0612 11:07:31.743005  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.743015  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.743021  5211 net.cpp:255] Memory required for data: 2136474112
I0612 11:07:31.743027  5211 layer_factory.hpp:77] Creating layer Convolution56
I0612 11:07:31.743042  5211 net.cpp:190] Creating Layer Convolution56
I0612 11:07:31.743051  5211 net.cpp:615] Convolution56 <- Eltwise27_ReLU55_0_split_0
I0612 11:07:31.743065  5211 net.cpp:589] Convolution56 -> Convolution56
I0612 11:07:31.744107  5211 net.cpp:240] Setting up Convolution56
I0612 11:07:31.744120  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.744127  5211 net.cpp:255] Memory required for data: 2140668416
I0612 11:07:31.744143  5211 layer_factory.hpp:77] Creating layer BatchNorm56
I0612 11:07:31.744158  5211 net.cpp:190] Creating Layer BatchNorm56
I0612 11:07:31.744165  5211 net.cpp:615] BatchNorm56 <- Convolution56
I0612 11:07:31.744175  5211 net.cpp:576] BatchNorm56 -> Convolution56 (in-place)
I0612 11:07:31.744514  5211 net.cpp:240] Setting up BatchNorm56
I0612 11:07:31.744526  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.744534  5211 net.cpp:255] Memory required for data: 2144862720
I0612 11:07:31.744551  5211 layer_factory.hpp:77] Creating layer Scale56
I0612 11:07:31.744563  5211 net.cpp:190] Creating Layer Scale56
I0612 11:07:31.744570  5211 net.cpp:615] Scale56 <- Convolution56
I0612 11:07:31.744583  5211 net.cpp:576] Scale56 -> Convolution56 (in-place)
I0612 11:07:31.744647  5211 layer_factory.hpp:77] Creating layer Scale56
I0612 11:07:31.744853  5211 net.cpp:240] Setting up Scale56
I0612 11:07:31.744871  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.744879  5211 net.cpp:255] Memory required for data: 2149057024
I0612 11:07:31.744894  5211 layer_factory.hpp:77] Creating layer ReLU56
I0612 11:07:31.744906  5211 net.cpp:190] Creating Layer ReLU56
I0612 11:07:31.744913  5211 net.cpp:615] ReLU56 <- Convolution56
I0612 11:07:31.744923  5211 net.cpp:576] ReLU56 -> Convolution56 (in-place)
I0612 11:07:31.744935  5211 net.cpp:240] Setting up ReLU56
I0612 11:07:31.744946  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.744951  5211 net.cpp:255] Memory required for data: 2153251328
I0612 11:07:31.744958  5211 layer_factory.hpp:77] Creating layer Convolution57
I0612 11:07:31.744977  5211 net.cpp:190] Creating Layer Convolution57
I0612 11:07:31.744984  5211 net.cpp:615] Convolution57 <- Convolution56
I0612 11:07:31.744998  5211 net.cpp:589] Convolution57 -> Convolution57
I0612 11:07:31.746036  5211 net.cpp:240] Setting up Convolution57
I0612 11:07:31.746049  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.746057  5211 net.cpp:255] Memory required for data: 2157445632
I0612 11:07:31.746071  5211 layer_factory.hpp:77] Creating layer BatchNorm57
I0612 11:07:31.746086  5211 net.cpp:190] Creating Layer BatchNorm57
I0612 11:07:31.746094  5211 net.cpp:615] BatchNorm57 <- Convolution57
I0612 11:07:31.746106  5211 net.cpp:576] BatchNorm57 -> Convolution57 (in-place)
I0612 11:07:31.746455  5211 net.cpp:240] Setting up BatchNorm57
I0612 11:07:31.746469  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.746476  5211 net.cpp:255] Memory required for data: 2161639936
I0612 11:07:31.746495  5211 layer_factory.hpp:77] Creating layer Scale57
I0612 11:07:31.746510  5211 net.cpp:190] Creating Layer Scale57
I0612 11:07:31.746518  5211 net.cpp:615] Scale57 <- Convolution57
I0612 11:07:31.746528  5211 net.cpp:576] Scale57 -> Convolution57 (in-place)
I0612 11:07:31.746592  5211 layer_factory.hpp:77] Creating layer Scale57
I0612 11:07:31.746779  5211 net.cpp:240] Setting up Scale57
I0612 11:07:31.746790  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.746796  5211 net.cpp:255] Memory required for data: 2165834240
I0612 11:07:31.746811  5211 layer_factory.hpp:77] Creating layer Eltwise28
I0612 11:07:31.746822  5211 net.cpp:190] Creating Layer Eltwise28
I0612 11:07:31.746830  5211 net.cpp:615] Eltwise28 <- Eltwise27_ReLU55_0_split_1
I0612 11:07:31.746839  5211 net.cpp:615] Eltwise28 <- Convolution57
I0612 11:07:31.746850  5211 net.cpp:589] Eltwise28 -> Eltwise28
I0612 11:07:31.746881  5211 net.cpp:240] Setting up Eltwise28
I0612 11:07:31.746891  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.746897  5211 net.cpp:255] Memory required for data: 2170028544
I0612 11:07:31.746903  5211 layer_factory.hpp:77] Creating layer ReLU57
I0612 11:07:31.746917  5211 net.cpp:190] Creating Layer ReLU57
I0612 11:07:31.746923  5211 net.cpp:615] ReLU57 <- Eltwise28
I0612 11:07:31.746932  5211 net.cpp:576] ReLU57 -> Eltwise28 (in-place)
I0612 11:07:31.746942  5211 net.cpp:240] Setting up ReLU57
I0612 11:07:31.746950  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.746956  5211 net.cpp:255] Memory required for data: 2174222848
I0612 11:07:31.746963  5211 layer_factory.hpp:77] Creating layer Eltwise28_ReLU57_0_split
I0612 11:07:31.746973  5211 net.cpp:190] Creating Layer Eltwise28_ReLU57_0_split
I0612 11:07:31.746978  5211 net.cpp:615] Eltwise28_ReLU57_0_split <- Eltwise28
I0612 11:07:31.746987  5211 net.cpp:589] Eltwise28_ReLU57_0_split -> Eltwise28_ReLU57_0_split_0
I0612 11:07:31.747001  5211 net.cpp:589] Eltwise28_ReLU57_0_split -> Eltwise28_ReLU57_0_split_1
I0612 11:07:31.747057  5211 net.cpp:240] Setting up Eltwise28_ReLU57_0_split
I0612 11:07:31.747067  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.747076  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.747086  5211 net.cpp:255] Memory required for data: 2182611456
I0612 11:07:31.747092  5211 layer_factory.hpp:77] Creating layer Convolution58
I0612 11:07:31.747109  5211 net.cpp:190] Creating Layer Convolution58
I0612 11:07:31.747117  5211 net.cpp:615] Convolution58 <- Eltwise28_ReLU57_0_split_0
I0612 11:07:31.747128  5211 net.cpp:589] Convolution58 -> Convolution58
I0612 11:07:31.748109  5211 net.cpp:240] Setting up Convolution58
I0612 11:07:31.748122  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.748129  5211 net.cpp:255] Memory required for data: 2186805760
I0612 11:07:31.748143  5211 layer_factory.hpp:77] Creating layer BatchNorm58
I0612 11:07:31.748162  5211 net.cpp:190] Creating Layer BatchNorm58
I0612 11:07:31.748169  5211 net.cpp:615] BatchNorm58 <- Convolution58
I0612 11:07:31.748178  5211 net.cpp:576] BatchNorm58 -> Convolution58 (in-place)
I0612 11:07:31.748493  5211 net.cpp:240] Setting up BatchNorm58
I0612 11:07:31.748505  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.748512  5211 net.cpp:255] Memory required for data: 2191000064
I0612 11:07:31.748529  5211 layer_factory.hpp:77] Creating layer Scale58
I0612 11:07:31.748543  5211 net.cpp:190] Creating Layer Scale58
I0612 11:07:31.748549  5211 net.cpp:615] Scale58 <- Convolution58
I0612 11:07:31.748558  5211 net.cpp:576] Scale58 -> Convolution58 (in-place)
I0612 11:07:31.748615  5211 layer_factory.hpp:77] Creating layer Scale58
I0612 11:07:31.748802  5211 net.cpp:240] Setting up Scale58
I0612 11:07:31.748813  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.748819  5211 net.cpp:255] Memory required for data: 2195194368
I0612 11:07:31.748834  5211 layer_factory.hpp:77] Creating layer ReLU58
I0612 11:07:31.748847  5211 net.cpp:190] Creating Layer ReLU58
I0612 11:07:31.748854  5211 net.cpp:615] ReLU58 <- Convolution58
I0612 11:07:31.748863  5211 net.cpp:576] ReLU58 -> Convolution58 (in-place)
I0612 11:07:31.748874  5211 net.cpp:240] Setting up ReLU58
I0612 11:07:31.748883  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.748888  5211 net.cpp:255] Memory required for data: 2199388672
I0612 11:07:31.748894  5211 layer_factory.hpp:77] Creating layer Convolution59
I0612 11:07:31.748911  5211 net.cpp:190] Creating Layer Convolution59
I0612 11:07:31.748919  5211 net.cpp:615] Convolution59 <- Convolution58
I0612 11:07:31.748929  5211 net.cpp:589] Convolution59 -> Convolution59
I0612 11:07:31.749892  5211 net.cpp:240] Setting up Convolution59
I0612 11:07:31.749905  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.749912  5211 net.cpp:255] Memory required for data: 2203582976
I0612 11:07:31.749927  5211 layer_factory.hpp:77] Creating layer BatchNorm59
I0612 11:07:31.749940  5211 net.cpp:190] Creating Layer BatchNorm59
I0612 11:07:31.749948  5211 net.cpp:615] BatchNorm59 <- Convolution59
I0612 11:07:31.749956  5211 net.cpp:576] BatchNorm59 -> Convolution59 (in-place)
I0612 11:07:31.750272  5211 net.cpp:240] Setting up BatchNorm59
I0612 11:07:31.750283  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.750289  5211 net.cpp:255] Memory required for data: 2207777280
I0612 11:07:31.750310  5211 layer_factory.hpp:77] Creating layer Scale59
I0612 11:07:31.750321  5211 net.cpp:190] Creating Layer Scale59
I0612 11:07:31.750329  5211 net.cpp:615] Scale59 <- Convolution59
I0612 11:07:31.750337  5211 net.cpp:576] Scale59 -> Convolution59 (in-place)
I0612 11:07:31.750403  5211 layer_factory.hpp:77] Creating layer Scale59
I0612 11:07:31.750596  5211 net.cpp:240] Setting up Scale59
I0612 11:07:31.750607  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.750613  5211 net.cpp:255] Memory required for data: 2211971584
I0612 11:07:31.750630  5211 layer_factory.hpp:77] Creating layer Eltwise29
I0612 11:07:31.750641  5211 net.cpp:190] Creating Layer Eltwise29
I0612 11:07:31.750649  5211 net.cpp:615] Eltwise29 <- Eltwise28_ReLU57_0_split_1
I0612 11:07:31.750658  5211 net.cpp:615] Eltwise29 <- Convolution59
I0612 11:07:31.750670  5211 net.cpp:589] Eltwise29 -> Eltwise29
I0612 11:07:31.750705  5211 net.cpp:240] Setting up Eltwise29
I0612 11:07:31.750715  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.750721  5211 net.cpp:255] Memory required for data: 2216165888
I0612 11:07:31.750728  5211 layer_factory.hpp:77] Creating layer ReLU59
I0612 11:07:31.750737  5211 net.cpp:190] Creating Layer ReLU59
I0612 11:07:31.750744  5211 net.cpp:615] ReLU59 <- Eltwise29
I0612 11:07:31.750757  5211 net.cpp:576] ReLU59 -> Eltwise29 (in-place)
I0612 11:07:31.750768  5211 net.cpp:240] Setting up ReLU59
I0612 11:07:31.750777  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.750783  5211 net.cpp:255] Memory required for data: 2220360192
I0612 11:07:31.750789  5211 layer_factory.hpp:77] Creating layer Eltwise29_ReLU59_0_split
I0612 11:07:31.750798  5211 net.cpp:190] Creating Layer Eltwise29_ReLU59_0_split
I0612 11:07:31.750804  5211 net.cpp:615] Eltwise29_ReLU59_0_split <- Eltwise29
I0612 11:07:31.750813  5211 net.cpp:589] Eltwise29_ReLU59_0_split -> Eltwise29_ReLU59_0_split_0
I0612 11:07:31.750824  5211 net.cpp:589] Eltwise29_ReLU59_0_split -> Eltwise29_ReLU59_0_split_1
I0612 11:07:31.750890  5211 net.cpp:240] Setting up Eltwise29_ReLU59_0_split
I0612 11:07:31.750901  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.750910  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.750916  5211 net.cpp:255] Memory required for data: 2228748800
I0612 11:07:31.750921  5211 layer_factory.hpp:77] Creating layer Convolution60
I0612 11:07:31.750936  5211 net.cpp:190] Creating Layer Convolution60
I0612 11:07:31.750943  5211 net.cpp:615] Convolution60 <- Eltwise29_ReLU59_0_split_0
I0612 11:07:31.750957  5211 net.cpp:589] Convolution60 -> Convolution60
I0612 11:07:31.751937  5211 net.cpp:240] Setting up Convolution60
I0612 11:07:31.751950  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.751957  5211 net.cpp:255] Memory required for data: 2232943104
I0612 11:07:31.751972  5211 layer_factory.hpp:77] Creating layer BatchNorm60
I0612 11:07:31.751983  5211 net.cpp:190] Creating Layer BatchNorm60
I0612 11:07:31.751991  5211 net.cpp:615] BatchNorm60 <- Convolution60
I0612 11:07:31.752003  5211 net.cpp:576] BatchNorm60 -> Convolution60 (in-place)
I0612 11:07:31.752324  5211 net.cpp:240] Setting up BatchNorm60
I0612 11:07:31.752336  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.752342  5211 net.cpp:255] Memory required for data: 2237137408
I0612 11:07:31.752359  5211 layer_factory.hpp:77] Creating layer Scale60
I0612 11:07:31.752370  5211 net.cpp:190] Creating Layer Scale60
I0612 11:07:31.752377  5211 net.cpp:615] Scale60 <- Convolution60
I0612 11:07:31.752387  5211 net.cpp:576] Scale60 -> Convolution60 (in-place)
I0612 11:07:31.752444  5211 layer_factory.hpp:77] Creating layer Scale60
I0612 11:07:31.752630  5211 net.cpp:240] Setting up Scale60
I0612 11:07:31.752641  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.752647  5211 net.cpp:255] Memory required for data: 2241331712
I0612 11:07:31.752662  5211 layer_factory.hpp:77] Creating layer ReLU60
I0612 11:07:31.752676  5211 net.cpp:190] Creating Layer ReLU60
I0612 11:07:31.752682  5211 net.cpp:615] ReLU60 <- Convolution60
I0612 11:07:31.752691  5211 net.cpp:576] ReLU60 -> Convolution60 (in-place)
I0612 11:07:31.752701  5211 net.cpp:240] Setting up ReLU60
I0612 11:07:31.752710  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.752717  5211 net.cpp:255] Memory required for data: 2245526016
I0612 11:07:31.752722  5211 layer_factory.hpp:77] Creating layer Convolution61
I0612 11:07:31.752740  5211 net.cpp:190] Creating Layer Convolution61
I0612 11:07:31.752746  5211 net.cpp:615] Convolution61 <- Convolution60
I0612 11:07:31.752759  5211 net.cpp:589] Convolution61 -> Convolution61
I0612 11:07:31.753731  5211 net.cpp:240] Setting up Convolution61
I0612 11:07:31.753744  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.753751  5211 net.cpp:255] Memory required for data: 2249720320
I0612 11:07:31.753765  5211 layer_factory.hpp:77] Creating layer BatchNorm61
I0612 11:07:31.753784  5211 net.cpp:190] Creating Layer BatchNorm61
I0612 11:07:31.753793  5211 net.cpp:615] BatchNorm61 <- Convolution61
I0612 11:07:31.753803  5211 net.cpp:576] BatchNorm61 -> Convolution61 (in-place)
I0612 11:07:31.754114  5211 net.cpp:240] Setting up BatchNorm61
I0612 11:07:31.754127  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.754132  5211 net.cpp:255] Memory required for data: 2253914624
I0612 11:07:31.754150  5211 layer_factory.hpp:77] Creating layer Scale61
I0612 11:07:31.754161  5211 net.cpp:190] Creating Layer Scale61
I0612 11:07:31.754168  5211 net.cpp:615] Scale61 <- Convolution61
I0612 11:07:31.754180  5211 net.cpp:576] Scale61 -> Convolution61 (in-place)
I0612 11:07:31.754232  5211 layer_factory.hpp:77] Creating layer Scale61
I0612 11:07:31.754426  5211 net.cpp:240] Setting up Scale61
I0612 11:07:31.754441  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.754448  5211 net.cpp:255] Memory required for data: 2258108928
I0612 11:07:31.754462  5211 layer_factory.hpp:77] Creating layer Eltwise30
I0612 11:07:31.754474  5211 net.cpp:190] Creating Layer Eltwise30
I0612 11:07:31.754482  5211 net.cpp:615] Eltwise30 <- Eltwise29_ReLU59_0_split_1
I0612 11:07:31.754490  5211 net.cpp:615] Eltwise30 <- Convolution61
I0612 11:07:31.754500  5211 net.cpp:589] Eltwise30 -> Eltwise30
I0612 11:07:31.754539  5211 net.cpp:240] Setting up Eltwise30
I0612 11:07:31.754550  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.754556  5211 net.cpp:255] Memory required for data: 2262303232
I0612 11:07:31.754562  5211 layer_factory.hpp:77] Creating layer ReLU61
I0612 11:07:31.754572  5211 net.cpp:190] Creating Layer ReLU61
I0612 11:07:31.754580  5211 net.cpp:615] ReLU61 <- Eltwise30
I0612 11:07:31.754590  5211 net.cpp:576] ReLU61 -> Eltwise30 (in-place)
I0612 11:07:31.754601  5211 net.cpp:240] Setting up ReLU61
I0612 11:07:31.754611  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.754617  5211 net.cpp:255] Memory required for data: 2266497536
I0612 11:07:31.754624  5211 layer_factory.hpp:77] Creating layer Eltwise30_ReLU61_0_split
I0612 11:07:31.754633  5211 net.cpp:190] Creating Layer Eltwise30_ReLU61_0_split
I0612 11:07:31.754639  5211 net.cpp:615] Eltwise30_ReLU61_0_split <- Eltwise30
I0612 11:07:31.754648  5211 net.cpp:589] Eltwise30_ReLU61_0_split -> Eltwise30_ReLU61_0_split_0
I0612 11:07:31.754659  5211 net.cpp:589] Eltwise30_ReLU61_0_split -> Eltwise30_ReLU61_0_split_1
I0612 11:07:31.754717  5211 net.cpp:240] Setting up Eltwise30_ReLU61_0_split
I0612 11:07:31.754727  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.754735  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.754741  5211 net.cpp:255] Memory required for data: 2274886144
I0612 11:07:31.754747  5211 layer_factory.hpp:77] Creating layer Convolution62
I0612 11:07:31.754765  5211 net.cpp:190] Creating Layer Convolution62
I0612 11:07:31.754772  5211 net.cpp:615] Convolution62 <- Eltwise30_ReLU61_0_split_0
I0612 11:07:31.754784  5211 net.cpp:589] Convolution62 -> Convolution62
I0612 11:07:31.755760  5211 net.cpp:240] Setting up Convolution62
I0612 11:07:31.755774  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.755780  5211 net.cpp:255] Memory required for data: 2279080448
I0612 11:07:31.755795  5211 layer_factory.hpp:77] Creating layer BatchNorm62
I0612 11:07:31.755808  5211 net.cpp:190] Creating Layer BatchNorm62
I0612 11:07:31.755816  5211 net.cpp:615] BatchNorm62 <- Convolution62
I0612 11:07:31.755827  5211 net.cpp:576] BatchNorm62 -> Convolution62 (in-place)
I0612 11:07:31.756150  5211 net.cpp:240] Setting up BatchNorm62
I0612 11:07:31.756162  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.756168  5211 net.cpp:255] Memory required for data: 2283274752
I0612 11:07:31.756186  5211 layer_factory.hpp:77] Creating layer Scale62
I0612 11:07:31.756199  5211 net.cpp:190] Creating Layer Scale62
I0612 11:07:31.756206  5211 net.cpp:615] Scale62 <- Convolution62
I0612 11:07:31.756220  5211 net.cpp:576] Scale62 -> Convolution62 (in-place)
I0612 11:07:31.756278  5211 layer_factory.hpp:77] Creating layer Scale62
I0612 11:07:31.756469  5211 net.cpp:240] Setting up Scale62
I0612 11:07:31.756479  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.756486  5211 net.cpp:255] Memory required for data: 2287469056
I0612 11:07:31.756500  5211 layer_factory.hpp:77] Creating layer ReLU62
I0612 11:07:31.756510  5211 net.cpp:190] Creating Layer ReLU62
I0612 11:07:31.756517  5211 net.cpp:615] ReLU62 <- Convolution62
I0612 11:07:31.756530  5211 net.cpp:576] ReLU62 -> Convolution62 (in-place)
I0612 11:07:31.756541  5211 net.cpp:240] Setting up ReLU62
I0612 11:07:31.756549  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.756556  5211 net.cpp:255] Memory required for data: 2291663360
I0612 11:07:31.756561  5211 layer_factory.hpp:77] Creating layer Convolution63
I0612 11:07:31.756578  5211 net.cpp:190] Creating Layer Convolution63
I0612 11:07:31.756587  5211 net.cpp:615] Convolution63 <- Convolution62
I0612 11:07:31.756597  5211 net.cpp:589] Convolution63 -> Convolution63
I0612 11:07:31.757567  5211 net.cpp:240] Setting up Convolution63
I0612 11:07:31.757580  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.757586  5211 net.cpp:255] Memory required for data: 2295857664
I0612 11:07:31.757601  5211 layer_factory.hpp:77] Creating layer BatchNorm63
I0612 11:07:31.757613  5211 net.cpp:190] Creating Layer BatchNorm63
I0612 11:07:31.757622  5211 net.cpp:615] BatchNorm63 <- Convolution63
I0612 11:07:31.757630  5211 net.cpp:576] BatchNorm63 -> Convolution63 (in-place)
I0612 11:07:31.757949  5211 net.cpp:240] Setting up BatchNorm63
I0612 11:07:31.757961  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.757967  5211 net.cpp:255] Memory required for data: 2300051968
I0612 11:07:31.757987  5211 layer_factory.hpp:77] Creating layer Scale63
I0612 11:07:31.757998  5211 net.cpp:190] Creating Layer Scale63
I0612 11:07:31.758005  5211 net.cpp:615] Scale63 <- Convolution63
I0612 11:07:31.758014  5211 net.cpp:576] Scale63 -> Convolution63 (in-place)
I0612 11:07:31.758070  5211 layer_factory.hpp:77] Creating layer Scale63
I0612 11:07:31.758260  5211 net.cpp:240] Setting up Scale63
I0612 11:07:31.758271  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.758278  5211 net.cpp:255] Memory required for data: 2304246272
I0612 11:07:31.758292  5211 layer_factory.hpp:77] Creating layer Eltwise31
I0612 11:07:31.758306  5211 net.cpp:190] Creating Layer Eltwise31
I0612 11:07:31.758314  5211 net.cpp:615] Eltwise31 <- Eltwise30_ReLU61_0_split_1
I0612 11:07:31.758322  5211 net.cpp:615] Eltwise31 <- Convolution63
I0612 11:07:31.758332  5211 net.cpp:589] Eltwise31 -> Eltwise31
I0612 11:07:31.758381  5211 net.cpp:240] Setting up Eltwise31
I0612 11:07:31.758394  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.758399  5211 net.cpp:255] Memory required for data: 2308440576
I0612 11:07:31.758406  5211 layer_factory.hpp:77] Creating layer ReLU63
I0612 11:07:31.758415  5211 net.cpp:190] Creating Layer ReLU63
I0612 11:07:31.758422  5211 net.cpp:615] ReLU63 <- Eltwise31
I0612 11:07:31.758433  5211 net.cpp:576] ReLU63 -> Eltwise31 (in-place)
I0612 11:07:31.758445  5211 net.cpp:240] Setting up ReLU63
I0612 11:07:31.758453  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.758460  5211 net.cpp:255] Memory required for data: 2312634880
I0612 11:07:31.758466  5211 layer_factory.hpp:77] Creating layer Eltwise31_ReLU63_0_split
I0612 11:07:31.758474  5211 net.cpp:190] Creating Layer Eltwise31_ReLU63_0_split
I0612 11:07:31.758481  5211 net.cpp:615] Eltwise31_ReLU63_0_split <- Eltwise31
I0612 11:07:31.758489  5211 net.cpp:589] Eltwise31_ReLU63_0_split -> Eltwise31_ReLU63_0_split_0
I0612 11:07:31.758502  5211 net.cpp:589] Eltwise31_ReLU63_0_split -> Eltwise31_ReLU63_0_split_1
I0612 11:07:31.758561  5211 net.cpp:240] Setting up Eltwise31_ReLU63_0_split
I0612 11:07:31.758570  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.758579  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.758589  5211 net.cpp:255] Memory required for data: 2321023488
I0612 11:07:31.758595  5211 layer_factory.hpp:77] Creating layer Convolution64
I0612 11:07:31.758610  5211 net.cpp:190] Creating Layer Convolution64
I0612 11:07:31.758616  5211 net.cpp:615] Convolution64 <- Eltwise31_ReLU63_0_split_0
I0612 11:07:31.758631  5211 net.cpp:589] Convolution64 -> Convolution64
I0612 11:07:31.759565  5211 net.cpp:240] Setting up Convolution64
I0612 11:07:31.759577  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.759583  5211 net.cpp:255] Memory required for data: 2325217792
I0612 11:07:31.759598  5211 layer_factory.hpp:77] Creating layer BatchNorm64
I0612 11:07:31.759608  5211 net.cpp:190] Creating Layer BatchNorm64
I0612 11:07:31.759614  5211 net.cpp:615] BatchNorm64 <- Convolution64
I0612 11:07:31.759626  5211 net.cpp:576] BatchNorm64 -> Convolution64 (in-place)
I0612 11:07:31.759927  5211 net.cpp:240] Setting up BatchNorm64
I0612 11:07:31.759938  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.759943  5211 net.cpp:255] Memory required for data: 2329412096
I0612 11:07:31.759960  5211 layer_factory.hpp:77] Creating layer Scale64
I0612 11:07:31.759969  5211 net.cpp:190] Creating Layer Scale64
I0612 11:07:31.759976  5211 net.cpp:615] Scale64 <- Convolution64
I0612 11:07:31.759984  5211 net.cpp:576] Scale64 -> Convolution64 (in-place)
I0612 11:07:31.760040  5211 layer_factory.hpp:77] Creating layer Scale64
I0612 11:07:31.760216  5211 net.cpp:240] Setting up Scale64
I0612 11:07:31.760226  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.760232  5211 net.cpp:255] Memory required for data: 2333606400
I0612 11:07:31.760246  5211 layer_factory.hpp:77] Creating layer ReLU64
I0612 11:07:31.760256  5211 net.cpp:190] Creating Layer ReLU64
I0612 11:07:31.760265  5211 net.cpp:615] ReLU64 <- Convolution64
I0612 11:07:31.760273  5211 net.cpp:576] ReLU64 -> Convolution64 (in-place)
I0612 11:07:31.760283  5211 net.cpp:240] Setting up ReLU64
I0612 11:07:31.760291  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.760298  5211 net.cpp:255] Memory required for data: 2337800704
I0612 11:07:31.760303  5211 layer_factory.hpp:77] Creating layer Convolution65
I0612 11:07:31.760319  5211 net.cpp:190] Creating Layer Convolution65
I0612 11:07:31.760326  5211 net.cpp:615] Convolution65 <- Convolution64
I0612 11:07:31.760335  5211 net.cpp:589] Convolution65 -> Convolution65
I0612 11:07:31.761358  5211 net.cpp:240] Setting up Convolution65
I0612 11:07:31.761375  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.761381  5211 net.cpp:255] Memory required for data: 2341995008
I0612 11:07:31.761396  5211 layer_factory.hpp:77] Creating layer BatchNorm65
I0612 11:07:31.761409  5211 net.cpp:190] Creating Layer BatchNorm65
I0612 11:07:31.761415  5211 net.cpp:615] BatchNorm65 <- Convolution65
I0612 11:07:31.761427  5211 net.cpp:576] BatchNorm65 -> Convolution65 (in-place)
I0612 11:07:31.761734  5211 net.cpp:240] Setting up BatchNorm65
I0612 11:07:31.761746  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.761752  5211 net.cpp:255] Memory required for data: 2346189312
I0612 11:07:31.761770  5211 layer_factory.hpp:77] Creating layer Scale65
I0612 11:07:31.761780  5211 net.cpp:190] Creating Layer Scale65
I0612 11:07:31.761786  5211 net.cpp:615] Scale65 <- Convolution65
I0612 11:07:31.761795  5211 net.cpp:576] Scale65 -> Convolution65 (in-place)
I0612 11:07:31.761849  5211 layer_factory.hpp:77] Creating layer Scale65
I0612 11:07:31.762027  5211 net.cpp:240] Setting up Scale65
I0612 11:07:31.762037  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.762043  5211 net.cpp:255] Memory required for data: 2350383616
I0612 11:07:31.762058  5211 layer_factory.hpp:77] Creating layer Eltwise32
I0612 11:07:31.762069  5211 net.cpp:190] Creating Layer Eltwise32
I0612 11:07:31.762078  5211 net.cpp:615] Eltwise32 <- Eltwise31_ReLU63_0_split_1
I0612 11:07:31.762085  5211 net.cpp:615] Eltwise32 <- Convolution65
I0612 11:07:31.762099  5211 net.cpp:589] Eltwise32 -> Eltwise32
I0612 11:07:31.762131  5211 net.cpp:240] Setting up Eltwise32
I0612 11:07:31.762141  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.762147  5211 net.cpp:255] Memory required for data: 2354577920
I0612 11:07:31.762153  5211 layer_factory.hpp:77] Creating layer ReLU65
I0612 11:07:31.762162  5211 net.cpp:190] Creating Layer ReLU65
I0612 11:07:31.762169  5211 net.cpp:615] ReLU65 <- Eltwise32
I0612 11:07:31.762179  5211 net.cpp:576] ReLU65 -> Eltwise32 (in-place)
I0612 11:07:31.762189  5211 net.cpp:240] Setting up ReLU65
I0612 11:07:31.762197  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.762203  5211 net.cpp:255] Memory required for data: 2358772224
I0612 11:07:31.762209  5211 layer_factory.hpp:77] Creating layer Eltwise32_ReLU65_0_split
I0612 11:07:31.762217  5211 net.cpp:190] Creating Layer Eltwise32_ReLU65_0_split
I0612 11:07:31.762223  5211 net.cpp:615] Eltwise32_ReLU65_0_split <- Eltwise32
I0612 11:07:31.762231  5211 net.cpp:589] Eltwise32_ReLU65_0_split -> Eltwise32_ReLU65_0_split_0
I0612 11:07:31.762243  5211 net.cpp:589] Eltwise32_ReLU65_0_split -> Eltwise32_ReLU65_0_split_1
I0612 11:07:31.762298  5211 net.cpp:240] Setting up Eltwise32_ReLU65_0_split
I0612 11:07:31.762308  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.762315  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.762321  5211 net.cpp:255] Memory required for data: 2367160832
I0612 11:07:31.762327  5211 layer_factory.hpp:77] Creating layer Convolution66
I0612 11:07:31.762347  5211 net.cpp:190] Creating Layer Convolution66
I0612 11:07:31.762363  5211 net.cpp:615] Convolution66 <- Eltwise32_ReLU65_0_split_0
I0612 11:07:31.762375  5211 net.cpp:589] Convolution66 -> Convolution66
I0612 11:07:31.764132  5211 net.cpp:240] Setting up Convolution66
I0612 11:07:31.764153  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.764159  5211 net.cpp:255] Memory required for data: 2371355136
I0612 11:07:31.764175  5211 layer_factory.hpp:77] Creating layer BatchNorm66
I0612 11:07:31.764190  5211 net.cpp:190] Creating Layer BatchNorm66
I0612 11:07:31.764199  5211 net.cpp:615] BatchNorm66 <- Convolution66
I0612 11:07:31.764210  5211 net.cpp:576] BatchNorm66 -> Convolution66 (in-place)
I0612 11:07:31.764531  5211 net.cpp:240] Setting up BatchNorm66
I0612 11:07:31.764544  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.764549  5211 net.cpp:255] Memory required for data: 2375549440
I0612 11:07:31.764566  5211 layer_factory.hpp:77] Creating layer Scale66
I0612 11:07:31.764577  5211 net.cpp:190] Creating Layer Scale66
I0612 11:07:31.764585  5211 net.cpp:615] Scale66 <- Convolution66
I0612 11:07:31.764593  5211 net.cpp:576] Scale66 -> Convolution66 (in-place)
I0612 11:07:31.764649  5211 layer_factory.hpp:77] Creating layer Scale66
I0612 11:07:31.764838  5211 net.cpp:240] Setting up Scale66
I0612 11:07:31.764849  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.764855  5211 net.cpp:255] Memory required for data: 2379743744
I0612 11:07:31.764869  5211 layer_factory.hpp:77] Creating layer ReLU66
I0612 11:07:31.764880  5211 net.cpp:190] Creating Layer ReLU66
I0612 11:07:31.764888  5211 net.cpp:615] ReLU66 <- Convolution66
I0612 11:07:31.764899  5211 net.cpp:576] ReLU66 -> Convolution66 (in-place)
I0612 11:07:31.764909  5211 net.cpp:240] Setting up ReLU66
I0612 11:07:31.764919  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.764924  5211 net.cpp:255] Memory required for data: 2383938048
I0612 11:07:31.764930  5211 layer_factory.hpp:77] Creating layer Convolution67
I0612 11:07:31.764943  5211 net.cpp:190] Creating Layer Convolution67
I0612 11:07:31.764950  5211 net.cpp:615] Convolution67 <- Convolution66
I0612 11:07:31.764962  5211 net.cpp:589] Convolution67 -> Convolution67
I0612 11:07:31.765884  5211 net.cpp:240] Setting up Convolution67
I0612 11:07:31.765897  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.765903  5211 net.cpp:255] Memory required for data: 2388132352
I0612 11:07:31.765921  5211 layer_factory.hpp:77] Creating layer BatchNorm67
I0612 11:07:31.765933  5211 net.cpp:190] Creating Layer BatchNorm67
I0612 11:07:31.765939  5211 net.cpp:615] BatchNorm67 <- Convolution67
I0612 11:07:31.765951  5211 net.cpp:576] BatchNorm67 -> Convolution67 (in-place)
I0612 11:07:31.766260  5211 net.cpp:240] Setting up BatchNorm67
I0612 11:07:31.766271  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.766278  5211 net.cpp:255] Memory required for data: 2392326656
I0612 11:07:31.766295  5211 layer_factory.hpp:77] Creating layer Scale67
I0612 11:07:31.766305  5211 net.cpp:190] Creating Layer Scale67
I0612 11:07:31.766311  5211 net.cpp:615] Scale67 <- Convolution67
I0612 11:07:31.766319  5211 net.cpp:576] Scale67 -> Convolution67 (in-place)
I0612 11:07:31.766386  5211 layer_factory.hpp:77] Creating layer Scale67
I0612 11:07:31.766573  5211 net.cpp:240] Setting up Scale67
I0612 11:07:31.766585  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.766590  5211 net.cpp:255] Memory required for data: 2396520960
I0612 11:07:31.766605  5211 layer_factory.hpp:77] Creating layer Eltwise33
I0612 11:07:31.766618  5211 net.cpp:190] Creating Layer Eltwise33
I0612 11:07:31.766626  5211 net.cpp:615] Eltwise33 <- Eltwise32_ReLU65_0_split_1
I0612 11:07:31.766634  5211 net.cpp:615] Eltwise33 <- Convolution67
I0612 11:07:31.766644  5211 net.cpp:589] Eltwise33 -> Eltwise33
I0612 11:07:31.766674  5211 net.cpp:240] Setting up Eltwise33
I0612 11:07:31.766683  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.766688  5211 net.cpp:255] Memory required for data: 2400715264
I0612 11:07:31.766695  5211 layer_factory.hpp:77] Creating layer ReLU67
I0612 11:07:31.766706  5211 net.cpp:190] Creating Layer ReLU67
I0612 11:07:31.766713  5211 net.cpp:615] ReLU67 <- Eltwise33
I0612 11:07:31.766721  5211 net.cpp:576] ReLU67 -> Eltwise33 (in-place)
I0612 11:07:31.766731  5211 net.cpp:240] Setting up ReLU67
I0612 11:07:31.766739  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.766746  5211 net.cpp:255] Memory required for data: 2404909568
I0612 11:07:31.766752  5211 layer_factory.hpp:77] Creating layer Eltwise33_ReLU67_0_split
I0612 11:07:31.766764  5211 net.cpp:190] Creating Layer Eltwise33_ReLU67_0_split
I0612 11:07:31.766770  5211 net.cpp:615] Eltwise33_ReLU67_0_split <- Eltwise33
I0612 11:07:31.766778  5211 net.cpp:589] Eltwise33_ReLU67_0_split -> Eltwise33_ReLU67_0_split_0
I0612 11:07:31.766789  5211 net.cpp:589] Eltwise33_ReLU67_0_split -> Eltwise33_ReLU67_0_split_1
I0612 11:07:31.766846  5211 net.cpp:240] Setting up Eltwise33_ReLU67_0_split
I0612 11:07:31.766855  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.766863  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.766870  5211 net.cpp:255] Memory required for data: 2413298176
I0612 11:07:31.766875  5211 layer_factory.hpp:77] Creating layer Convolution68
I0612 11:07:31.766891  5211 net.cpp:190] Creating Layer Convolution68
I0612 11:07:31.766898  5211 net.cpp:615] Convolution68 <- Eltwise33_ReLU67_0_split_0
I0612 11:07:31.766908  5211 net.cpp:589] Convolution68 -> Convolution68
I0612 11:07:31.767827  5211 net.cpp:240] Setting up Convolution68
I0612 11:07:31.767839  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.767845  5211 net.cpp:255] Memory required for data: 2417492480
I0612 11:07:31.767859  5211 layer_factory.hpp:77] Creating layer BatchNorm68
I0612 11:07:31.767871  5211 net.cpp:190] Creating Layer BatchNorm68
I0612 11:07:31.767879  5211 net.cpp:615] BatchNorm68 <- Convolution68
I0612 11:07:31.767890  5211 net.cpp:576] BatchNorm68 -> Convolution68 (in-place)
I0612 11:07:31.768198  5211 net.cpp:240] Setting up BatchNorm68
I0612 11:07:31.768208  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.768214  5211 net.cpp:255] Memory required for data: 2421686784
I0612 11:07:31.768231  5211 layer_factory.hpp:77] Creating layer Scale68
I0612 11:07:31.768241  5211 net.cpp:190] Creating Layer Scale68
I0612 11:07:31.768249  5211 net.cpp:615] Scale68 <- Convolution68
I0612 11:07:31.768263  5211 net.cpp:576] Scale68 -> Convolution68 (in-place)
I0612 11:07:31.768316  5211 layer_factory.hpp:77] Creating layer Scale68
I0612 11:07:31.768497  5211 net.cpp:240] Setting up Scale68
I0612 11:07:31.768508  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.768514  5211 net.cpp:255] Memory required for data: 2425881088
I0612 11:07:31.768527  5211 layer_factory.hpp:77] Creating layer ReLU68
I0612 11:07:31.768537  5211 net.cpp:190] Creating Layer ReLU68
I0612 11:07:31.768543  5211 net.cpp:615] ReLU68 <- Convolution68
I0612 11:07:31.768553  5211 net.cpp:576] ReLU68 -> Convolution68 (in-place)
I0612 11:07:31.768563  5211 net.cpp:240] Setting up ReLU68
I0612 11:07:31.768570  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.768576  5211 net.cpp:255] Memory required for data: 2430075392
I0612 11:07:31.768581  5211 layer_factory.hpp:77] Creating layer Convolution69
I0612 11:07:31.768599  5211 net.cpp:190] Creating Layer Convolution69
I0612 11:07:31.768605  5211 net.cpp:615] Convolution69 <- Convolution68
I0612 11:07:31.768617  5211 net.cpp:589] Convolution69 -> Convolution69
I0612 11:07:31.769529  5211 net.cpp:240] Setting up Convolution69
I0612 11:07:31.769542  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.769548  5211 net.cpp:255] Memory required for data: 2434269696
I0612 11:07:31.769562  5211 layer_factory.hpp:77] Creating layer BatchNorm69
I0612 11:07:31.769577  5211 net.cpp:190] Creating Layer BatchNorm69
I0612 11:07:31.769583  5211 net.cpp:615] BatchNorm69 <- Convolution69
I0612 11:07:31.769594  5211 net.cpp:576] BatchNorm69 -> Convolution69 (in-place)
I0612 11:07:31.769896  5211 net.cpp:240] Setting up BatchNorm69
I0612 11:07:31.769907  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.769912  5211 net.cpp:255] Memory required for data: 2438464000
I0612 11:07:31.769930  5211 layer_factory.hpp:77] Creating layer Scale69
I0612 11:07:31.769943  5211 net.cpp:190] Creating Layer Scale69
I0612 11:07:31.769949  5211 net.cpp:615] Scale69 <- Convolution69
I0612 11:07:31.769958  5211 net.cpp:576] Scale69 -> Convolution69 (in-place)
I0612 11:07:31.770007  5211 layer_factory.hpp:77] Creating layer Scale69
I0612 11:07:31.770186  5211 net.cpp:240] Setting up Scale69
I0612 11:07:31.770197  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.770203  5211 net.cpp:255] Memory required for data: 2442658304
I0612 11:07:31.770216  5211 layer_factory.hpp:77] Creating layer Eltwise34
I0612 11:07:31.770227  5211 net.cpp:190] Creating Layer Eltwise34
I0612 11:07:31.770234  5211 net.cpp:615] Eltwise34 <- Eltwise33_ReLU67_0_split_1
I0612 11:07:31.770242  5211 net.cpp:615] Eltwise34 <- Convolution69
I0612 11:07:31.770256  5211 net.cpp:589] Eltwise34 -> Eltwise34
I0612 11:07:31.770285  5211 net.cpp:240] Setting up Eltwise34
I0612 11:07:31.770298  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.770303  5211 net.cpp:255] Memory required for data: 2446852608
I0612 11:07:31.770309  5211 layer_factory.hpp:77] Creating layer ReLU69
I0612 11:07:31.770318  5211 net.cpp:190] Creating Layer ReLU69
I0612 11:07:31.770324  5211 net.cpp:615] ReLU69 <- Eltwise34
I0612 11:07:31.770333  5211 net.cpp:576] ReLU69 -> Eltwise34 (in-place)
I0612 11:07:31.770342  5211 net.cpp:240] Setting up ReLU69
I0612 11:07:31.770350  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.770367  5211 net.cpp:255] Memory required for data: 2451046912
I0612 11:07:31.770373  5211 layer_factory.hpp:77] Creating layer Eltwise34_ReLU69_0_split
I0612 11:07:31.770382  5211 net.cpp:190] Creating Layer Eltwise34_ReLU69_0_split
I0612 11:07:31.770388  5211 net.cpp:615] Eltwise34_ReLU69_0_split <- Eltwise34
I0612 11:07:31.770400  5211 net.cpp:589] Eltwise34_ReLU69_0_split -> Eltwise34_ReLU69_0_split_0
I0612 11:07:31.770411  5211 net.cpp:589] Eltwise34_ReLU69_0_split -> Eltwise34_ReLU69_0_split_1
I0612 11:07:31.770467  5211 net.cpp:240] Setting up Eltwise34_ReLU69_0_split
I0612 11:07:31.770475  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.770488  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.770493  5211 net.cpp:255] Memory required for data: 2459435520
I0612 11:07:31.770499  5211 layer_factory.hpp:77] Creating layer Convolution70
I0612 11:07:31.770516  5211 net.cpp:190] Creating Layer Convolution70
I0612 11:07:31.770524  5211 net.cpp:615] Convolution70 <- Eltwise34_ReLU69_0_split_0
I0612 11:07:31.770534  5211 net.cpp:589] Convolution70 -> Convolution70
I0612 11:07:31.771411  5211 net.cpp:240] Setting up Convolution70
I0612 11:07:31.771423  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.771430  5211 net.cpp:255] Memory required for data: 2463629824
I0612 11:07:31.771442  5211 layer_factory.hpp:77] Creating layer BatchNorm70
I0612 11:07:31.771455  5211 net.cpp:190] Creating Layer BatchNorm70
I0612 11:07:31.771461  5211 net.cpp:615] BatchNorm70 <- Convolution70
I0612 11:07:31.771469  5211 net.cpp:576] BatchNorm70 -> Convolution70 (in-place)
I0612 11:07:31.771759  5211 net.cpp:240] Setting up BatchNorm70
I0612 11:07:31.771770  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.771775  5211 net.cpp:255] Memory required for data: 2467824128
I0612 11:07:31.771793  5211 layer_factory.hpp:77] Creating layer Scale70
I0612 11:07:31.771803  5211 net.cpp:190] Creating Layer Scale70
I0612 11:07:31.771809  5211 net.cpp:615] Scale70 <- Convolution70
I0612 11:07:31.771817  5211 net.cpp:576] Scale70 -> Convolution70 (in-place)
I0612 11:07:31.771867  5211 layer_factory.hpp:77] Creating layer Scale70
I0612 11:07:31.772038  5211 net.cpp:240] Setting up Scale70
I0612 11:07:31.772048  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.772053  5211 net.cpp:255] Memory required for data: 2472018432
I0612 11:07:31.772068  5211 layer_factory.hpp:77] Creating layer ReLU70
I0612 11:07:31.772078  5211 net.cpp:190] Creating Layer ReLU70
I0612 11:07:31.772085  5211 net.cpp:615] ReLU70 <- Convolution70
I0612 11:07:31.772094  5211 net.cpp:576] ReLU70 -> Convolution70 (in-place)
I0612 11:07:31.772105  5211 net.cpp:240] Setting up ReLU70
I0612 11:07:31.772114  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.772119  5211 net.cpp:255] Memory required for data: 2476212736
I0612 11:07:31.772125  5211 layer_factory.hpp:77] Creating layer Convolution71
I0612 11:07:31.772137  5211 net.cpp:190] Creating Layer Convolution71
I0612 11:07:31.772143  5211 net.cpp:615] Convolution71 <- Convolution70
I0612 11:07:31.772155  5211 net.cpp:589] Convolution71 -> Convolution71
I0612 11:07:31.773010  5211 net.cpp:240] Setting up Convolution71
I0612 11:07:31.773020  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.773026  5211 net.cpp:255] Memory required for data: 2480407040
I0612 11:07:31.773038  5211 layer_factory.hpp:77] Creating layer BatchNorm71
I0612 11:07:31.773048  5211 net.cpp:190] Creating Layer BatchNorm71
I0612 11:07:31.773056  5211 net.cpp:615] BatchNorm71 <- Convolution71
I0612 11:07:31.773066  5211 net.cpp:576] BatchNorm71 -> Convolution71 (in-place)
I0612 11:07:31.773351  5211 net.cpp:240] Setting up BatchNorm71
I0612 11:07:31.773362  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.773367  5211 net.cpp:255] Memory required for data: 2484601344
I0612 11:07:31.773383  5211 layer_factory.hpp:77] Creating layer Scale71
I0612 11:07:31.773392  5211 net.cpp:190] Creating Layer Scale71
I0612 11:07:31.773399  5211 net.cpp:615] Scale71 <- Convolution71
I0612 11:07:31.773406  5211 net.cpp:576] Scale71 -> Convolution71 (in-place)
I0612 11:07:31.773458  5211 layer_factory.hpp:77] Creating layer Scale71
I0612 11:07:31.773632  5211 net.cpp:240] Setting up Scale71
I0612 11:07:31.773641  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.773646  5211 net.cpp:255] Memory required for data: 2488795648
I0612 11:07:31.773659  5211 layer_factory.hpp:77] Creating layer Eltwise35
I0612 11:07:31.773669  5211 net.cpp:190] Creating Layer Eltwise35
I0612 11:07:31.773675  5211 net.cpp:615] Eltwise35 <- Eltwise34_ReLU69_0_split_1
I0612 11:07:31.773689  5211 net.cpp:615] Eltwise35 <- Convolution71
I0612 11:07:31.773699  5211 net.cpp:589] Eltwise35 -> Eltwise35
I0612 11:07:31.773725  5211 net.cpp:240] Setting up Eltwise35
I0612 11:07:31.773736  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.773741  5211 net.cpp:255] Memory required for data: 2492989952
I0612 11:07:31.773746  5211 layer_factory.hpp:77] Creating layer ReLU71
I0612 11:07:31.773761  5211 net.cpp:190] Creating Layer ReLU71
I0612 11:07:31.773766  5211 net.cpp:615] ReLU71 <- Eltwise35
I0612 11:07:31.773774  5211 net.cpp:576] ReLU71 -> Eltwise35 (in-place)
I0612 11:07:31.773783  5211 net.cpp:240] Setting up ReLU71
I0612 11:07:31.773792  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.773797  5211 net.cpp:255] Memory required for data: 2497184256
I0612 11:07:31.773802  5211 layer_factory.hpp:77] Creating layer Eltwise35_ReLU71_0_split
I0612 11:07:31.773810  5211 net.cpp:190] Creating Layer Eltwise35_ReLU71_0_split
I0612 11:07:31.773815  5211 net.cpp:615] Eltwise35_ReLU71_0_split <- Eltwise35
I0612 11:07:31.773830  5211 net.cpp:589] Eltwise35_ReLU71_0_split -> Eltwise35_ReLU71_0_split_0
I0612 11:07:31.773841  5211 net.cpp:589] Eltwise35_ReLU71_0_split -> Eltwise35_ReLU71_0_split_1
I0612 11:07:31.773895  5211 net.cpp:240] Setting up Eltwise35_ReLU71_0_split
I0612 11:07:31.773903  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.773910  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.773916  5211 net.cpp:255] Memory required for data: 2505572864
I0612 11:07:31.773921  5211 layer_factory.hpp:77] Creating layer Convolution72
I0612 11:07:31.773934  5211 net.cpp:190] Creating Layer Convolution72
I0612 11:07:31.773941  5211 net.cpp:615] Convolution72 <- Eltwise35_ReLU71_0_split_0
I0612 11:07:31.773957  5211 net.cpp:589] Convolution72 -> Convolution72
I0612 11:07:31.774826  5211 net.cpp:240] Setting up Convolution72
I0612 11:07:31.774838  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.774843  5211 net.cpp:255] Memory required for data: 2509767168
I0612 11:07:31.774857  5211 layer_factory.hpp:77] Creating layer BatchNorm72
I0612 11:07:31.774869  5211 net.cpp:190] Creating Layer BatchNorm72
I0612 11:07:31.774875  5211 net.cpp:615] BatchNorm72 <- Convolution72
I0612 11:07:31.774884  5211 net.cpp:576] BatchNorm72 -> Convolution72 (in-place)
I0612 11:07:31.775173  5211 net.cpp:240] Setting up BatchNorm72
I0612 11:07:31.775183  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.775188  5211 net.cpp:255] Memory required for data: 2513961472
I0612 11:07:31.775205  5211 layer_factory.hpp:77] Creating layer Scale72
I0612 11:07:31.775214  5211 net.cpp:190] Creating Layer Scale72
I0612 11:07:31.775221  5211 net.cpp:615] Scale72 <- Convolution72
I0612 11:07:31.775231  5211 net.cpp:576] Scale72 -> Convolution72 (in-place)
I0612 11:07:31.775279  5211 layer_factory.hpp:77] Creating layer Scale72
I0612 11:07:31.775447  5211 net.cpp:240] Setting up Scale72
I0612 11:07:31.775460  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.775465  5211 net.cpp:255] Memory required for data: 2518155776
I0612 11:07:31.775477  5211 layer_factory.hpp:77] Creating layer ReLU72
I0612 11:07:31.775486  5211 net.cpp:190] Creating Layer ReLU72
I0612 11:07:31.775493  5211 net.cpp:615] ReLU72 <- Convolution72
I0612 11:07:31.775501  5211 net.cpp:576] ReLU72 -> Convolution72 (in-place)
I0612 11:07:31.775511  5211 net.cpp:240] Setting up ReLU72
I0612 11:07:31.775518  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.775523  5211 net.cpp:255] Memory required for data: 2522350080
I0612 11:07:31.775528  5211 layer_factory.hpp:77] Creating layer Convolution73
I0612 11:07:31.775544  5211 net.cpp:190] Creating Layer Convolution73
I0612 11:07:31.775550  5211 net.cpp:615] Convolution73 <- Convolution72
I0612 11:07:31.775562  5211 net.cpp:589] Convolution73 -> Convolution73
I0612 11:07:31.776417  5211 net.cpp:240] Setting up Convolution73
I0612 11:07:31.776429  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.776438  5211 net.cpp:255] Memory required for data: 2526544384
I0612 11:07:31.776451  5211 layer_factory.hpp:77] Creating layer BatchNorm73
I0612 11:07:31.776464  5211 net.cpp:190] Creating Layer BatchNorm73
I0612 11:07:31.776470  5211 net.cpp:615] BatchNorm73 <- Convolution73
I0612 11:07:31.776484  5211 net.cpp:576] BatchNorm73 -> Convolution73 (in-place)
I0612 11:07:31.776774  5211 net.cpp:240] Setting up BatchNorm73
I0612 11:07:31.776785  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.776790  5211 net.cpp:255] Memory required for data: 2530738688
I0612 11:07:31.776808  5211 layer_factory.hpp:77] Creating layer Scale73
I0612 11:07:31.776819  5211 net.cpp:190] Creating Layer Scale73
I0612 11:07:31.776825  5211 net.cpp:615] Scale73 <- Convolution73
I0612 11:07:31.776834  5211 net.cpp:576] Scale73 -> Convolution73 (in-place)
I0612 11:07:31.776882  5211 layer_factory.hpp:77] Creating layer Scale73
I0612 11:07:31.777056  5211 net.cpp:240] Setting up Scale73
I0612 11:07:31.777066  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.777072  5211 net.cpp:255] Memory required for data: 2534932992
I0612 11:07:31.777086  5211 layer_factory.hpp:77] Creating layer Eltwise36
I0612 11:07:31.777094  5211 net.cpp:190] Creating Layer Eltwise36
I0612 11:07:31.777101  5211 net.cpp:615] Eltwise36 <- Eltwise35_ReLU71_0_split_1
I0612 11:07:31.777109  5211 net.cpp:615] Eltwise36 <- Convolution73
I0612 11:07:31.777120  5211 net.cpp:589] Eltwise36 -> Eltwise36
I0612 11:07:31.777148  5211 net.cpp:240] Setting up Eltwise36
I0612 11:07:31.777158  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.777163  5211 net.cpp:255] Memory required for data: 2539127296
I0612 11:07:31.777168  5211 layer_factory.hpp:77] Creating layer ReLU73
I0612 11:07:31.777179  5211 net.cpp:190] Creating Layer ReLU73
I0612 11:07:31.777185  5211 net.cpp:615] ReLU73 <- Eltwise36
I0612 11:07:31.777194  5211 net.cpp:576] ReLU73 -> Eltwise36 (in-place)
I0612 11:07:31.777202  5211 net.cpp:240] Setting up ReLU73
I0612 11:07:31.777209  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.777215  5211 net.cpp:255] Memory required for data: 2543321600
I0612 11:07:31.777220  5211 layer_factory.hpp:77] Creating layer Eltwise36_ReLU73_0_split
I0612 11:07:31.777227  5211 net.cpp:190] Creating Layer Eltwise36_ReLU73_0_split
I0612 11:07:31.777233  5211 net.cpp:615] Eltwise36_ReLU73_0_split <- Eltwise36
I0612 11:07:31.777241  5211 net.cpp:589] Eltwise36_ReLU73_0_split -> Eltwise36_ReLU73_0_split_0
I0612 11:07:31.777254  5211 net.cpp:589] Eltwise36_ReLU73_0_split -> Eltwise36_ReLU73_0_split_1
I0612 11:07:31.777304  5211 net.cpp:240] Setting up Eltwise36_ReLU73_0_split
I0612 11:07:31.777313  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.777320  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:31.777325  5211 net.cpp:255] Memory required for data: 2551710208
I0612 11:07:31.777330  5211 layer_factory.hpp:77] Creating layer Pooling2
I0612 11:07:31.777343  5211 net.cpp:190] Creating Layer Pooling2
I0612 11:07:31.777349  5211 net.cpp:615] Pooling2 <- Eltwise36_ReLU73_0_split_0
I0612 11:07:31.777357  5211 net.cpp:589] Pooling2 -> Pooling2
I0612 11:07:31.777391  5211 net.cpp:240] Setting up Pooling2
I0612 11:07:31.777400  5211 net.cpp:247] Top shape: 128 32 8 8 (262144)
I0612 11:07:31.777405  5211 net.cpp:255] Memory required for data: 2552758784
I0612 11:07:31.777410  5211 layer_factory.hpp:77] Creating layer Input2
I0612 11:07:31.777421  5211 net.cpp:190] Creating Layer Input2
I0612 11:07:31.777431  5211 net.cpp:589] Input2 -> Input2
I0612 11:07:31.777468  5211 net.cpp:240] Setting up Input2
I0612 11:07:31.777477  5211 net.cpp:247] Top shape: 128 32 8 8 (262144)
I0612 11:07:31.777482  5211 net.cpp:255] Memory required for data: 2553807360
I0612 11:07:31.777488  5211 layer_factory.hpp:77] Creating layer Concat2
I0612 11:07:31.777498  5211 net.cpp:190] Creating Layer Concat2
I0612 11:07:31.777503  5211 net.cpp:615] Concat2 <- Pooling2
I0612 11:07:31.777510  5211 net.cpp:615] Concat2 <- Input2
I0612 11:07:31.777525  5211 net.cpp:589] Concat2 -> Concat2
I0612 11:07:31.777560  5211 net.cpp:240] Setting up Concat2
I0612 11:07:31.777572  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.777577  5211 net.cpp:255] Memory required for data: 2555904512
I0612 11:07:31.777583  5211 layer_factory.hpp:77] Creating layer Convolution74
I0612 11:07:31.777596  5211 net.cpp:190] Creating Layer Convolution74
I0612 11:07:31.777602  5211 net.cpp:615] Convolution74 <- Eltwise36_ReLU73_0_split_1
I0612 11:07:31.777616  5211 net.cpp:589] Convolution74 -> Convolution74
I0612 11:07:31.779795  5211 net.cpp:240] Setting up Convolution74
I0612 11:07:31.779816  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.779822  5211 net.cpp:255] Memory required for data: 2558001664
I0612 11:07:31.779917  5211 layer_factory.hpp:77] Creating layer BatchNorm74
I0612 11:07:31.779933  5211 net.cpp:190] Creating Layer BatchNorm74
I0612 11:07:31.779942  5211 net.cpp:615] BatchNorm74 <- Convolution74
I0612 11:07:31.779950  5211 net.cpp:576] BatchNorm74 -> Convolution74 (in-place)
I0612 11:07:31.780268  5211 net.cpp:240] Setting up BatchNorm74
I0612 11:07:31.780280  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.780287  5211 net.cpp:255] Memory required for data: 2560098816
I0612 11:07:31.780303  5211 layer_factory.hpp:77] Creating layer Scale74
I0612 11:07:31.780316  5211 net.cpp:190] Creating Layer Scale74
I0612 11:07:31.780323  5211 net.cpp:615] Scale74 <- Convolution74
I0612 11:07:31.780331  5211 net.cpp:576] Scale74 -> Convolution74 (in-place)
I0612 11:07:31.780390  5211 layer_factory.hpp:77] Creating layer Scale74
I0612 11:07:31.780570  5211 net.cpp:240] Setting up Scale74
I0612 11:07:31.780580  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.780586  5211 net.cpp:255] Memory required for data: 2562195968
I0612 11:07:31.780599  5211 layer_factory.hpp:77] Creating layer ReLU74
I0612 11:07:31.780611  5211 net.cpp:190] Creating Layer ReLU74
I0612 11:07:31.780617  5211 net.cpp:615] ReLU74 <- Convolution74
I0612 11:07:31.780627  5211 net.cpp:576] ReLU74 -> Convolution74 (in-place)
I0612 11:07:31.780637  5211 net.cpp:240] Setting up ReLU74
I0612 11:07:31.780643  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.780649  5211 net.cpp:255] Memory required for data: 2564293120
I0612 11:07:31.780654  5211 layer_factory.hpp:77] Creating layer Convolution75
I0612 11:07:31.780670  5211 net.cpp:190] Creating Layer Convolution75
I0612 11:07:31.780678  5211 net.cpp:615] Convolution75 <- Convolution74
I0612 11:07:31.780686  5211 net.cpp:589] Convolution75 -> Convolution75
I0612 11:07:31.783074  5211 net.cpp:240] Setting up Convolution75
I0612 11:07:31.783087  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.783092  5211 net.cpp:255] Memory required for data: 2566390272
I0612 11:07:31.783105  5211 layer_factory.hpp:77] Creating layer BatchNorm75
I0612 11:07:31.783118  5211 net.cpp:190] Creating Layer BatchNorm75
I0612 11:07:31.783124  5211 net.cpp:615] BatchNorm75 <- Convolution75
I0612 11:07:31.783133  5211 net.cpp:576] BatchNorm75 -> Convolution75 (in-place)
I0612 11:07:31.783413  5211 net.cpp:240] Setting up BatchNorm75
I0612 11:07:31.783424  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.783429  5211 net.cpp:255] Memory required for data: 2568487424
I0612 11:07:31.783444  5211 layer_factory.hpp:77] Creating layer Scale75
I0612 11:07:31.783457  5211 net.cpp:190] Creating Layer Scale75
I0612 11:07:31.783463  5211 net.cpp:615] Scale75 <- Convolution75
I0612 11:07:31.783470  5211 net.cpp:576] Scale75 -> Convolution75 (in-place)
I0612 11:07:31.783519  5211 layer_factory.hpp:77] Creating layer Scale75
I0612 11:07:31.783686  5211 net.cpp:240] Setting up Scale75
I0612 11:07:31.783696  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.783701  5211 net.cpp:255] Memory required for data: 2570584576
I0612 11:07:31.783713  5211 layer_factory.hpp:77] Creating layer Eltwise37
I0612 11:07:31.783725  5211 net.cpp:190] Creating Layer Eltwise37
I0612 11:07:31.783732  5211 net.cpp:615] Eltwise37 <- Concat2
I0612 11:07:31.783745  5211 net.cpp:615] Eltwise37 <- Convolution75
I0612 11:07:31.783753  5211 net.cpp:589] Eltwise37 -> Eltwise37
I0612 11:07:31.783783  5211 net.cpp:240] Setting up Eltwise37
I0612 11:07:31.783792  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.783797  5211 net.cpp:255] Memory required for data: 2572681728
I0612 11:07:31.783803  5211 layer_factory.hpp:77] Creating layer ReLU75
I0612 11:07:31.783812  5211 net.cpp:190] Creating Layer ReLU75
I0612 11:07:31.783817  5211 net.cpp:615] ReLU75 <- Eltwise37
I0612 11:07:31.783823  5211 net.cpp:576] ReLU75 -> Eltwise37 (in-place)
I0612 11:07:31.783833  5211 net.cpp:240] Setting up ReLU75
I0612 11:07:31.783839  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.783844  5211 net.cpp:255] Memory required for data: 2574778880
I0612 11:07:31.783849  5211 layer_factory.hpp:77] Creating layer Eltwise37_ReLU75_0_split
I0612 11:07:31.783860  5211 net.cpp:190] Creating Layer Eltwise37_ReLU75_0_split
I0612 11:07:31.783865  5211 net.cpp:615] Eltwise37_ReLU75_0_split <- Eltwise37
I0612 11:07:31.783872  5211 net.cpp:589] Eltwise37_ReLU75_0_split -> Eltwise37_ReLU75_0_split_0
I0612 11:07:31.783882  5211 net.cpp:589] Eltwise37_ReLU75_0_split -> Eltwise37_ReLU75_0_split_1
I0612 11:07:31.783934  5211 net.cpp:240] Setting up Eltwise37_ReLU75_0_split
I0612 11:07:31.783942  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.783949  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.783954  5211 net.cpp:255] Memory required for data: 2578973184
I0612 11:07:31.783959  5211 layer_factory.hpp:77] Creating layer Convolution76
I0612 11:07:31.783972  5211 net.cpp:190] Creating Layer Convolution76
I0612 11:07:31.783977  5211 net.cpp:615] Convolution76 <- Eltwise37_ReLU75_0_split_0
I0612 11:07:31.783987  5211 net.cpp:589] Convolution76 -> Convolution76
I0612 11:07:31.786232  5211 net.cpp:240] Setting up Convolution76
I0612 11:07:31.786247  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.786252  5211 net.cpp:255] Memory required for data: 2581070336
I0612 11:07:31.786264  5211 layer_factory.hpp:77] Creating layer BatchNorm76
I0612 11:07:31.786274  5211 net.cpp:190] Creating Layer BatchNorm76
I0612 11:07:31.786280  5211 net.cpp:615] BatchNorm76 <- Convolution76
I0612 11:07:31.786291  5211 net.cpp:576] BatchNorm76 -> Convolution76 (in-place)
I0612 11:07:31.786578  5211 net.cpp:240] Setting up BatchNorm76
I0612 11:07:31.786589  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.786594  5211 net.cpp:255] Memory required for data: 2583167488
I0612 11:07:31.786610  5211 layer_factory.hpp:77] Creating layer Scale76
I0612 11:07:31.786619  5211 net.cpp:190] Creating Layer Scale76
I0612 11:07:31.786625  5211 net.cpp:615] Scale76 <- Convolution76
I0612 11:07:31.786636  5211 net.cpp:576] Scale76 -> Convolution76 (in-place)
I0612 11:07:31.786684  5211 layer_factory.hpp:77] Creating layer Scale76
I0612 11:07:31.786854  5211 net.cpp:240] Setting up Scale76
I0612 11:07:31.786864  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.786869  5211 net.cpp:255] Memory required for data: 2585264640
I0612 11:07:31.786880  5211 layer_factory.hpp:77] Creating layer ReLU76
I0612 11:07:31.786890  5211 net.cpp:190] Creating Layer ReLU76
I0612 11:07:31.786895  5211 net.cpp:615] ReLU76 <- Convolution76
I0612 11:07:31.786902  5211 net.cpp:576] ReLU76 -> Convolution76 (in-place)
I0612 11:07:31.786911  5211 net.cpp:240] Setting up ReLU76
I0612 11:07:31.786918  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.786923  5211 net.cpp:255] Memory required for data: 2587361792
I0612 11:07:31.786928  5211 layer_factory.hpp:77] Creating layer Convolution77
I0612 11:07:31.786947  5211 net.cpp:190] Creating Layer Convolution77
I0612 11:07:31.786953  5211 net.cpp:615] Convolution77 <- Convolution76
I0612 11:07:31.786962  5211 net.cpp:589] Convolution77 -> Convolution77
I0612 11:07:31.789197  5211 net.cpp:240] Setting up Convolution77
I0612 11:07:31.789208  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.789217  5211 net.cpp:255] Memory required for data: 2589458944
I0612 11:07:31.789230  5211 layer_factory.hpp:77] Creating layer BatchNorm77
I0612 11:07:31.789242  5211 net.cpp:190] Creating Layer BatchNorm77
I0612 11:07:31.789248  5211 net.cpp:615] BatchNorm77 <- Convolution77
I0612 11:07:31.789258  5211 net.cpp:576] BatchNorm77 -> Convolution77 (in-place)
I0612 11:07:31.789537  5211 net.cpp:240] Setting up BatchNorm77
I0612 11:07:31.789548  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.789553  5211 net.cpp:255] Memory required for data: 2591556096
I0612 11:07:31.789571  5211 layer_factory.hpp:77] Creating layer Scale77
I0612 11:07:31.789580  5211 net.cpp:190] Creating Layer Scale77
I0612 11:07:31.789587  5211 net.cpp:615] Scale77 <- Convolution77
I0612 11:07:31.789593  5211 net.cpp:576] Scale77 -> Convolution77 (in-place)
I0612 11:07:31.789645  5211 layer_factory.hpp:77] Creating layer Scale77
I0612 11:07:31.789814  5211 net.cpp:240] Setting up Scale77
I0612 11:07:31.789824  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.789829  5211 net.cpp:255] Memory required for data: 2593653248
I0612 11:07:31.789841  5211 layer_factory.hpp:77] Creating layer Eltwise38
I0612 11:07:31.789851  5211 net.cpp:190] Creating Layer Eltwise38
I0612 11:07:31.789857  5211 net.cpp:615] Eltwise38 <- Eltwise37_ReLU75_0_split_1
I0612 11:07:31.789867  5211 net.cpp:615] Eltwise38 <- Convolution77
I0612 11:07:31.789875  5211 net.cpp:589] Eltwise38 -> Eltwise38
I0612 11:07:31.789901  5211 net.cpp:240] Setting up Eltwise38
I0612 11:07:31.789911  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.789916  5211 net.cpp:255] Memory required for data: 2595750400
I0612 11:07:31.789921  5211 layer_factory.hpp:77] Creating layer ReLU77
I0612 11:07:31.789932  5211 net.cpp:190] Creating Layer ReLU77
I0612 11:07:31.789937  5211 net.cpp:615] ReLU77 <- Eltwise38
I0612 11:07:31.789944  5211 net.cpp:576] ReLU77 -> Eltwise38 (in-place)
I0612 11:07:31.789953  5211 net.cpp:240] Setting up ReLU77
I0612 11:07:31.789960  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.789965  5211 net.cpp:255] Memory required for data: 2597847552
I0612 11:07:31.789970  5211 layer_factory.hpp:77] Creating layer Eltwise38_ReLU77_0_split
I0612 11:07:31.789978  5211 net.cpp:190] Creating Layer Eltwise38_ReLU77_0_split
I0612 11:07:31.789983  5211 net.cpp:615] Eltwise38_ReLU77_0_split <- Eltwise38
I0612 11:07:31.789990  5211 net.cpp:589] Eltwise38_ReLU77_0_split -> Eltwise38_ReLU77_0_split_0
I0612 11:07:31.790000  5211 net.cpp:589] Eltwise38_ReLU77_0_split -> Eltwise38_ReLU77_0_split_1
I0612 11:07:31.790050  5211 net.cpp:240] Setting up Eltwise38_ReLU77_0_split
I0612 11:07:31.790060  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.790066  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.790071  5211 net.cpp:255] Memory required for data: 2602041856
I0612 11:07:31.790076  5211 layer_factory.hpp:77] Creating layer Convolution78
I0612 11:07:31.790087  5211 net.cpp:190] Creating Layer Convolution78
I0612 11:07:31.790093  5211 net.cpp:615] Convolution78 <- Eltwise38_ReLU77_0_split_0
I0612 11:07:31.790105  5211 net.cpp:589] Convolution78 -> Convolution78
I0612 11:07:31.792359  5211 net.cpp:240] Setting up Convolution78
I0612 11:07:31.792371  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.792376  5211 net.cpp:255] Memory required for data: 2604139008
I0612 11:07:31.792389  5211 layer_factory.hpp:77] Creating layer BatchNorm78
I0612 11:07:31.792400  5211 net.cpp:190] Creating Layer BatchNorm78
I0612 11:07:31.792407  5211 net.cpp:615] BatchNorm78 <- Convolution78
I0612 11:07:31.792415  5211 net.cpp:576] BatchNorm78 -> Convolution78 (in-place)
I0612 11:07:31.792695  5211 net.cpp:240] Setting up BatchNorm78
I0612 11:07:31.792704  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.792709  5211 net.cpp:255] Memory required for data: 2606236160
I0612 11:07:31.792724  5211 layer_factory.hpp:77] Creating layer Scale78
I0612 11:07:31.792735  5211 net.cpp:190] Creating Layer Scale78
I0612 11:07:31.792745  5211 net.cpp:615] Scale78 <- Convolution78
I0612 11:07:31.792753  5211 net.cpp:576] Scale78 -> Convolution78 (in-place)
I0612 11:07:31.792801  5211 layer_factory.hpp:77] Creating layer Scale78
I0612 11:07:31.792971  5211 net.cpp:240] Setting up Scale78
I0612 11:07:31.792981  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.792986  5211 net.cpp:255] Memory required for data: 2608333312
I0612 11:07:31.792999  5211 layer_factory.hpp:77] Creating layer ReLU78
I0612 11:07:31.793009  5211 net.cpp:190] Creating Layer ReLU78
I0612 11:07:31.793015  5211 net.cpp:615] ReLU78 <- Convolution78
I0612 11:07:31.793023  5211 net.cpp:576] ReLU78 -> Convolution78 (in-place)
I0612 11:07:31.793032  5211 net.cpp:240] Setting up ReLU78
I0612 11:07:31.793040  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.793045  5211 net.cpp:255] Memory required for data: 2610430464
I0612 11:07:31.793050  5211 layer_factory.hpp:77] Creating layer Convolution79
I0612 11:07:31.793064  5211 net.cpp:190] Creating Layer Convolution79
I0612 11:07:31.793069  5211 net.cpp:615] Convolution79 <- Convolution78
I0612 11:07:31.793078  5211 net.cpp:589] Convolution79 -> Convolution79
I0612 11:07:31.795298  5211 net.cpp:240] Setting up Convolution79
I0612 11:07:31.795310  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.795315  5211 net.cpp:255] Memory required for data: 2612527616
I0612 11:07:31.795327  5211 layer_factory.hpp:77] Creating layer BatchNorm79
I0612 11:07:31.795338  5211 net.cpp:190] Creating Layer BatchNorm79
I0612 11:07:31.795344  5211 net.cpp:615] BatchNorm79 <- Convolution79
I0612 11:07:31.795351  5211 net.cpp:576] BatchNorm79 -> Convolution79 (in-place)
I0612 11:07:31.795621  5211 net.cpp:240] Setting up BatchNorm79
I0612 11:07:31.795631  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.795636  5211 net.cpp:255] Memory required for data: 2614624768
I0612 11:07:31.795650  5211 layer_factory.hpp:77] Creating layer Scale79
I0612 11:07:31.795660  5211 net.cpp:190] Creating Layer Scale79
I0612 11:07:31.795665  5211 net.cpp:615] Scale79 <- Convolution79
I0612 11:07:31.795672  5211 net.cpp:576] Scale79 -> Convolution79 (in-place)
I0612 11:07:31.795723  5211 layer_factory.hpp:77] Creating layer Scale79
I0612 11:07:31.795876  5211 net.cpp:240] Setting up Scale79
I0612 11:07:31.795887  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.795892  5211 net.cpp:255] Memory required for data: 2616721920
I0612 11:07:31.795903  5211 layer_factory.hpp:77] Creating layer Eltwise39
I0612 11:07:31.795913  5211 net.cpp:190] Creating Layer Eltwise39
I0612 11:07:31.795919  5211 net.cpp:615] Eltwise39 <- Eltwise38_ReLU77_0_split_1
I0612 11:07:31.795927  5211 net.cpp:615] Eltwise39 <- Convolution79
I0612 11:07:31.795933  5211 net.cpp:589] Eltwise39 -> Eltwise39
I0612 11:07:31.795960  5211 net.cpp:240] Setting up Eltwise39
I0612 11:07:31.795969  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.795974  5211 net.cpp:255] Memory required for data: 2618819072
I0612 11:07:31.795979  5211 layer_factory.hpp:77] Creating layer ReLU79
I0612 11:07:31.795986  5211 net.cpp:190] Creating Layer ReLU79
I0612 11:07:31.795992  5211 net.cpp:615] ReLU79 <- Eltwise39
I0612 11:07:31.796000  5211 net.cpp:576] ReLU79 -> Eltwise39 (in-place)
I0612 11:07:31.796010  5211 net.cpp:240] Setting up ReLU79
I0612 11:07:31.796016  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.796021  5211 net.cpp:255] Memory required for data: 2620916224
I0612 11:07:31.796026  5211 layer_factory.hpp:77] Creating layer Eltwise39_ReLU79_0_split
I0612 11:07:31.796033  5211 net.cpp:190] Creating Layer Eltwise39_ReLU79_0_split
I0612 11:07:31.796038  5211 net.cpp:615] Eltwise39_ReLU79_0_split <- Eltwise39
I0612 11:07:31.796046  5211 net.cpp:589] Eltwise39_ReLU79_0_split -> Eltwise39_ReLU79_0_split_0
I0612 11:07:31.796054  5211 net.cpp:589] Eltwise39_ReLU79_0_split -> Eltwise39_ReLU79_0_split_1
I0612 11:07:31.796103  5211 net.cpp:240] Setting up Eltwise39_ReLU79_0_split
I0612 11:07:31.796115  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.796121  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.796126  5211 net.cpp:255] Memory required for data: 2625110528
I0612 11:07:31.796131  5211 layer_factory.hpp:77] Creating layer Convolution80
I0612 11:07:31.796144  5211 net.cpp:190] Creating Layer Convolution80
I0612 11:07:31.796150  5211 net.cpp:615] Convolution80 <- Eltwise39_ReLU79_0_split_0
I0612 11:07:31.796159  5211 net.cpp:589] Convolution80 -> Convolution80
I0612 11:07:31.798275  5211 net.cpp:240] Setting up Convolution80
I0612 11:07:31.798286  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.798291  5211 net.cpp:255] Memory required for data: 2627207680
I0612 11:07:31.798303  5211 layer_factory.hpp:77] Creating layer BatchNorm80
I0612 11:07:31.798315  5211 net.cpp:190] Creating Layer BatchNorm80
I0612 11:07:31.798321  5211 net.cpp:615] BatchNorm80 <- Convolution80
I0612 11:07:31.798329  5211 net.cpp:576] BatchNorm80 -> Convolution80 (in-place)
I0612 11:07:31.798598  5211 net.cpp:240] Setting up BatchNorm80
I0612 11:07:31.798607  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.798612  5211 net.cpp:255] Memory required for data: 2629304832
I0612 11:07:31.798630  5211 layer_factory.hpp:77] Creating layer Scale80
I0612 11:07:31.798640  5211 net.cpp:190] Creating Layer Scale80
I0612 11:07:31.798645  5211 net.cpp:615] Scale80 <- Convolution80
I0612 11:07:31.798652  5211 net.cpp:576] Scale80 -> Convolution80 (in-place)
I0612 11:07:31.798701  5211 layer_factory.hpp:77] Creating layer Scale80
I0612 11:07:31.798862  5211 net.cpp:240] Setting up Scale80
I0612 11:07:31.798871  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.798877  5211 net.cpp:255] Memory required for data: 2631401984
I0612 11:07:31.798887  5211 layer_factory.hpp:77] Creating layer ReLU80
I0612 11:07:31.798897  5211 net.cpp:190] Creating Layer ReLU80
I0612 11:07:31.798902  5211 net.cpp:615] ReLU80 <- Convolution80
I0612 11:07:31.798912  5211 net.cpp:576] ReLU80 -> Convolution80 (in-place)
I0612 11:07:31.798920  5211 net.cpp:240] Setting up ReLU80
I0612 11:07:31.798926  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.798931  5211 net.cpp:255] Memory required for data: 2633499136
I0612 11:07:31.798936  5211 layer_factory.hpp:77] Creating layer Convolution81
I0612 11:07:31.798949  5211 net.cpp:190] Creating Layer Convolution81
I0612 11:07:31.798954  5211 net.cpp:615] Convolution81 <- Convolution80
I0612 11:07:31.798964  5211 net.cpp:589] Convolution81 -> Convolution81
I0612 11:07:31.801772  5211 net.cpp:240] Setting up Convolution81
I0612 11:07:31.801789  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.801795  5211 net.cpp:255] Memory required for data: 2635596288
I0612 11:07:31.801808  5211 layer_factory.hpp:77] Creating layer BatchNorm81
I0612 11:07:31.801821  5211 net.cpp:190] Creating Layer BatchNorm81
I0612 11:07:31.801827  5211 net.cpp:615] BatchNorm81 <- Convolution81
I0612 11:07:31.801837  5211 net.cpp:576] BatchNorm81 -> Convolution81 (in-place)
I0612 11:07:31.802109  5211 net.cpp:240] Setting up BatchNorm81
I0612 11:07:31.802119  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.802124  5211 net.cpp:255] Memory required for data: 2637693440
I0612 11:07:31.802139  5211 layer_factory.hpp:77] Creating layer Scale81
I0612 11:07:31.802148  5211 net.cpp:190] Creating Layer Scale81
I0612 11:07:31.802153  5211 net.cpp:615] Scale81 <- Convolution81
I0612 11:07:31.802161  5211 net.cpp:576] Scale81 -> Convolution81 (in-place)
I0612 11:07:31.802211  5211 layer_factory.hpp:77] Creating layer Scale81
I0612 11:07:31.802381  5211 net.cpp:240] Setting up Scale81
I0612 11:07:31.802392  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.802395  5211 net.cpp:255] Memory required for data: 2639790592
I0612 11:07:31.802407  5211 layer_factory.hpp:77] Creating layer Eltwise40
I0612 11:07:31.802422  5211 net.cpp:190] Creating Layer Eltwise40
I0612 11:07:31.802428  5211 net.cpp:615] Eltwise40 <- Eltwise39_ReLU79_0_split_1
I0612 11:07:31.802439  5211 net.cpp:615] Eltwise40 <- Convolution81
I0612 11:07:31.802448  5211 net.cpp:589] Eltwise40 -> Eltwise40
I0612 11:07:31.802474  5211 net.cpp:240] Setting up Eltwise40
I0612 11:07:31.802482  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.802486  5211 net.cpp:255] Memory required for data: 2641887744
I0612 11:07:31.802491  5211 layer_factory.hpp:77] Creating layer ReLU81
I0612 11:07:31.802502  5211 net.cpp:190] Creating Layer ReLU81
I0612 11:07:31.802508  5211 net.cpp:615] ReLU81 <- Eltwise40
I0612 11:07:31.802515  5211 net.cpp:576] ReLU81 -> Eltwise40 (in-place)
I0612 11:07:31.802525  5211 net.cpp:240] Setting up ReLU81
I0612 11:07:31.802531  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.802536  5211 net.cpp:255] Memory required for data: 2643984896
I0612 11:07:31.802541  5211 layer_factory.hpp:77] Creating layer Eltwise40_ReLU81_0_split
I0612 11:07:31.802547  5211 net.cpp:190] Creating Layer Eltwise40_ReLU81_0_split
I0612 11:07:31.802552  5211 net.cpp:615] Eltwise40_ReLU81_0_split <- Eltwise40
I0612 11:07:31.802559  5211 net.cpp:589] Eltwise40_ReLU81_0_split -> Eltwise40_ReLU81_0_split_0
I0612 11:07:31.802569  5211 net.cpp:589] Eltwise40_ReLU81_0_split -> Eltwise40_ReLU81_0_split_1
I0612 11:07:31.802618  5211 net.cpp:240] Setting up Eltwise40_ReLU81_0_split
I0612 11:07:31.802625  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.802631  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.802636  5211 net.cpp:255] Memory required for data: 2648179200
I0612 11:07:31.802641  5211 layer_factory.hpp:77] Creating layer Convolution82
I0612 11:07:31.802655  5211 net.cpp:190] Creating Layer Convolution82
I0612 11:07:31.802661  5211 net.cpp:615] Convolution82 <- Eltwise40_ReLU81_0_split_0
I0612 11:07:31.802670  5211 net.cpp:589] Convolution82 -> Convolution82
I0612 11:07:31.804786  5211 net.cpp:240] Setting up Convolution82
I0612 11:07:31.804797  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.804802  5211 net.cpp:255] Memory required for data: 2650276352
I0612 11:07:31.804814  5211 layer_factory.hpp:77] Creating layer BatchNorm82
I0612 11:07:31.804826  5211 net.cpp:190] Creating Layer BatchNorm82
I0612 11:07:31.804832  5211 net.cpp:615] BatchNorm82 <- Convolution82
I0612 11:07:31.804839  5211 net.cpp:576] BatchNorm82 -> Convolution82 (in-place)
I0612 11:07:31.805106  5211 net.cpp:240] Setting up BatchNorm82
I0612 11:07:31.805116  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.805121  5211 net.cpp:255] Memory required for data: 2652373504
I0612 11:07:31.805135  5211 layer_factory.hpp:77] Creating layer Scale82
I0612 11:07:31.805145  5211 net.cpp:190] Creating Layer Scale82
I0612 11:07:31.805151  5211 net.cpp:615] Scale82 <- Convolution82
I0612 11:07:31.805158  5211 net.cpp:576] Scale82 -> Convolution82 (in-place)
I0612 11:07:31.805207  5211 layer_factory.hpp:77] Creating layer Scale82
I0612 11:07:31.805369  5211 net.cpp:240] Setting up Scale82
I0612 11:07:31.805378  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.805383  5211 net.cpp:255] Memory required for data: 2654470656
I0612 11:07:31.805394  5211 layer_factory.hpp:77] Creating layer ReLU82
I0612 11:07:31.805405  5211 net.cpp:190] Creating Layer ReLU82
I0612 11:07:31.805411  5211 net.cpp:615] ReLU82 <- Convolution82
I0612 11:07:31.805418  5211 net.cpp:576] ReLU82 -> Convolution82 (in-place)
I0612 11:07:31.805428  5211 net.cpp:240] Setting up ReLU82
I0612 11:07:31.805434  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.805438  5211 net.cpp:255] Memory required for data: 2656567808
I0612 11:07:31.805444  5211 layer_factory.hpp:77] Creating layer Convolution83
I0612 11:07:31.805457  5211 net.cpp:190] Creating Layer Convolution83
I0612 11:07:31.805462  5211 net.cpp:615] Convolution83 <- Convolution82
I0612 11:07:31.805472  5211 net.cpp:589] Convolution83 -> Convolution83
I0612 11:07:31.807548  5211 net.cpp:240] Setting up Convolution83
I0612 11:07:31.807559  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.807564  5211 net.cpp:255] Memory required for data: 2658664960
I0612 11:07:31.807577  5211 layer_factory.hpp:77] Creating layer BatchNorm83
I0612 11:07:31.807586  5211 net.cpp:190] Creating Layer BatchNorm83
I0612 11:07:31.807592  5211 net.cpp:615] BatchNorm83 <- Convolution83
I0612 11:07:31.807600  5211 net.cpp:576] BatchNorm83 -> Convolution83 (in-place)
I0612 11:07:31.807864  5211 net.cpp:240] Setting up BatchNorm83
I0612 11:07:31.807874  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.807878  5211 net.cpp:255] Memory required for data: 2660762112
I0612 11:07:31.807893  5211 layer_factory.hpp:77] Creating layer Scale83
I0612 11:07:31.807901  5211 net.cpp:190] Creating Layer Scale83
I0612 11:07:31.807906  5211 net.cpp:615] Scale83 <- Convolution83
I0612 11:07:31.807914  5211 net.cpp:576] Scale83 -> Convolution83 (in-place)
I0612 11:07:31.807963  5211 layer_factory.hpp:77] Creating layer Scale83
I0612 11:07:31.808112  5211 net.cpp:240] Setting up Scale83
I0612 11:07:31.808122  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.808127  5211 net.cpp:255] Memory required for data: 2662859264
I0612 11:07:31.808138  5211 layer_factory.hpp:77] Creating layer Eltwise41
I0612 11:07:31.808146  5211 net.cpp:190] Creating Layer Eltwise41
I0612 11:07:31.808152  5211 net.cpp:615] Eltwise41 <- Eltwise40_ReLU81_0_split_1
I0612 11:07:31.808159  5211 net.cpp:615] Eltwise41 <- Convolution83
I0612 11:07:31.808166  5211 net.cpp:589] Eltwise41 -> Eltwise41
I0612 11:07:31.808192  5211 net.cpp:240] Setting up Eltwise41
I0612 11:07:31.808200  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.808205  5211 net.cpp:255] Memory required for data: 2664956416
I0612 11:07:31.808210  5211 layer_factory.hpp:77] Creating layer ReLU83
I0612 11:07:31.808218  5211 net.cpp:190] Creating Layer ReLU83
I0612 11:07:31.808223  5211 net.cpp:615] ReLU83 <- Eltwise41
I0612 11:07:31.808230  5211 net.cpp:576] ReLU83 -> Eltwise41 (in-place)
I0612 11:07:31.808239  5211 net.cpp:240] Setting up ReLU83
I0612 11:07:31.808245  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.808250  5211 net.cpp:255] Memory required for data: 2667053568
I0612 11:07:31.808254  5211 layer_factory.hpp:77] Creating layer Eltwise41_ReLU83_0_split
I0612 11:07:31.808261  5211 net.cpp:190] Creating Layer Eltwise41_ReLU83_0_split
I0612 11:07:31.808266  5211 net.cpp:615] Eltwise41_ReLU83_0_split <- Eltwise41
I0612 11:07:31.808274  5211 net.cpp:589] Eltwise41_ReLU83_0_split -> Eltwise41_ReLU83_0_split_0
I0612 11:07:31.808282  5211 net.cpp:589] Eltwise41_ReLU83_0_split -> Eltwise41_ReLU83_0_split_1
I0612 11:07:31.808327  5211 net.cpp:240] Setting up Eltwise41_ReLU83_0_split
I0612 11:07:31.808334  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.808341  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.808344  5211 net.cpp:255] Memory required for data: 2671247872
I0612 11:07:31.808349  5211 layer_factory.hpp:77] Creating layer Convolution84
I0612 11:07:31.808363  5211 net.cpp:190] Creating Layer Convolution84
I0612 11:07:31.808369  5211 net.cpp:615] Convolution84 <- Eltwise41_ReLU83_0_split_0
I0612 11:07:31.808378  5211 net.cpp:589] Convolution84 -> Convolution84
I0612 11:07:31.810395  5211 net.cpp:240] Setting up Convolution84
I0612 11:07:31.810405  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.810410  5211 net.cpp:255] Memory required for data: 2673345024
I0612 11:07:31.810421  5211 layer_factory.hpp:77] Creating layer BatchNorm84
I0612 11:07:31.810432  5211 net.cpp:190] Creating Layer BatchNorm84
I0612 11:07:31.810438  5211 net.cpp:615] BatchNorm84 <- Convolution84
I0612 11:07:31.810447  5211 net.cpp:576] BatchNorm84 -> Convolution84 (in-place)
I0612 11:07:31.810699  5211 net.cpp:240] Setting up BatchNorm84
I0612 11:07:31.810708  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.810714  5211 net.cpp:255] Memory required for data: 2675442176
I0612 11:07:31.810727  5211 layer_factory.hpp:77] Creating layer Scale84
I0612 11:07:31.810735  5211 net.cpp:190] Creating Layer Scale84
I0612 11:07:31.810741  5211 net.cpp:615] Scale84 <- Convolution84
I0612 11:07:31.810755  5211 net.cpp:576] Scale84 -> Convolution84 (in-place)
I0612 11:07:31.810804  5211 layer_factory.hpp:77] Creating layer Scale84
I0612 11:07:31.810956  5211 net.cpp:240] Setting up Scale84
I0612 11:07:31.810966  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.810971  5211 net.cpp:255] Memory required for data: 2677539328
I0612 11:07:31.810981  5211 layer_factory.hpp:77] Creating layer ReLU84
I0612 11:07:31.810988  5211 net.cpp:190] Creating Layer ReLU84
I0612 11:07:31.810994  5211 net.cpp:615] ReLU84 <- Convolution84
I0612 11:07:31.811002  5211 net.cpp:576] ReLU84 -> Convolution84 (in-place)
I0612 11:07:31.811010  5211 net.cpp:240] Setting up ReLU84
I0612 11:07:31.811017  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.811022  5211 net.cpp:255] Memory required for data: 2679636480
I0612 11:07:31.811027  5211 layer_factory.hpp:77] Creating layer Convolution85
I0612 11:07:31.811040  5211 net.cpp:190] Creating Layer Convolution85
I0612 11:07:31.811045  5211 net.cpp:615] Convolution85 <- Convolution84
I0612 11:07:31.811053  5211 net.cpp:589] Convolution85 -> Convolution85
I0612 11:07:31.813192  5211 net.cpp:240] Setting up Convolution85
I0612 11:07:31.813207  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.813212  5211 net.cpp:255] Memory required for data: 2681733632
I0612 11:07:31.813226  5211 layer_factory.hpp:77] Creating layer BatchNorm85
I0612 11:07:31.813236  5211 net.cpp:190] Creating Layer BatchNorm85
I0612 11:07:31.813242  5211 net.cpp:615] BatchNorm85 <- Convolution85
I0612 11:07:31.813253  5211 net.cpp:576] BatchNorm85 -> Convolution85 (in-place)
I0612 11:07:31.813513  5211 net.cpp:240] Setting up BatchNorm85
I0612 11:07:31.813522  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.813527  5211 net.cpp:255] Memory required for data: 2683830784
I0612 11:07:31.813541  5211 layer_factory.hpp:77] Creating layer Scale85
I0612 11:07:31.813552  5211 net.cpp:190] Creating Layer Scale85
I0612 11:07:31.813558  5211 net.cpp:615] Scale85 <- Convolution85
I0612 11:07:31.813565  5211 net.cpp:576] Scale85 -> Convolution85 (in-place)
I0612 11:07:31.813609  5211 layer_factory.hpp:77] Creating layer Scale85
I0612 11:07:31.813761  5211 net.cpp:240] Setting up Scale85
I0612 11:07:31.813771  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.813774  5211 net.cpp:255] Memory required for data: 2685927936
I0612 11:07:31.813786  5211 layer_factory.hpp:77] Creating layer Eltwise42
I0612 11:07:31.813794  5211 net.cpp:190] Creating Layer Eltwise42
I0612 11:07:31.813801  5211 net.cpp:615] Eltwise42 <- Eltwise41_ReLU83_0_split_1
I0612 11:07:31.813810  5211 net.cpp:615] Eltwise42 <- Convolution85
I0612 11:07:31.813818  5211 net.cpp:589] Eltwise42 -> Eltwise42
I0612 11:07:31.813843  5211 net.cpp:240] Setting up Eltwise42
I0612 11:07:31.813853  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.813858  5211 net.cpp:255] Memory required for data: 2688025088
I0612 11:07:31.813863  5211 layer_factory.hpp:77] Creating layer ReLU85
I0612 11:07:31.813870  5211 net.cpp:190] Creating Layer ReLU85
I0612 11:07:31.813875  5211 net.cpp:615] ReLU85 <- Eltwise42
I0612 11:07:31.813882  5211 net.cpp:576] ReLU85 -> Eltwise42 (in-place)
I0612 11:07:31.813890  5211 net.cpp:240] Setting up ReLU85
I0612 11:07:31.813896  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.813900  5211 net.cpp:255] Memory required for data: 2690122240
I0612 11:07:31.813905  5211 layer_factory.hpp:77] Creating layer Eltwise42_ReLU85_0_split
I0612 11:07:31.813912  5211 net.cpp:190] Creating Layer Eltwise42_ReLU85_0_split
I0612 11:07:31.813916  5211 net.cpp:615] Eltwise42_ReLU85_0_split <- Eltwise42
I0612 11:07:31.813925  5211 net.cpp:589] Eltwise42_ReLU85_0_split -> Eltwise42_ReLU85_0_split_0
I0612 11:07:31.813935  5211 net.cpp:589] Eltwise42_ReLU85_0_split -> Eltwise42_ReLU85_0_split_1
I0612 11:07:31.813978  5211 net.cpp:240] Setting up Eltwise42_ReLU85_0_split
I0612 11:07:31.813990  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.813999  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.814004  5211 net.cpp:255] Memory required for data: 2694316544
I0612 11:07:31.814009  5211 layer_factory.hpp:77] Creating layer Convolution86
I0612 11:07:31.814021  5211 net.cpp:190] Creating Layer Convolution86
I0612 11:07:31.814026  5211 net.cpp:615] Convolution86 <- Eltwise42_ReLU85_0_split_0
I0612 11:07:31.814035  5211 net.cpp:589] Convolution86 -> Convolution86
I0612 11:07:31.816061  5211 net.cpp:240] Setting up Convolution86
I0612 11:07:31.816072  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.816076  5211 net.cpp:255] Memory required for data: 2696413696
I0612 11:07:31.816088  5211 layer_factory.hpp:77] Creating layer BatchNorm86
I0612 11:07:31.816099  5211 net.cpp:190] Creating Layer BatchNorm86
I0612 11:07:31.816105  5211 net.cpp:615] BatchNorm86 <- Convolution86
I0612 11:07:31.816112  5211 net.cpp:576] BatchNorm86 -> Convolution86 (in-place)
I0612 11:07:31.816368  5211 net.cpp:240] Setting up BatchNorm86
I0612 11:07:31.816377  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.816381  5211 net.cpp:255] Memory required for data: 2698510848
I0612 11:07:31.816395  5211 layer_factory.hpp:77] Creating layer Scale86
I0612 11:07:31.816403  5211 net.cpp:190] Creating Layer Scale86
I0612 11:07:31.816409  5211 net.cpp:615] Scale86 <- Convolution86
I0612 11:07:31.816416  5211 net.cpp:576] Scale86 -> Convolution86 (in-place)
I0612 11:07:31.816464  5211 layer_factory.hpp:77] Creating layer Scale86
I0612 11:07:31.816613  5211 net.cpp:240] Setting up Scale86
I0612 11:07:31.816624  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.816629  5211 net.cpp:255] Memory required for data: 2700608000
I0612 11:07:31.816640  5211 layer_factory.hpp:77] Creating layer ReLU86
I0612 11:07:31.816648  5211 net.cpp:190] Creating Layer ReLU86
I0612 11:07:31.816653  5211 net.cpp:615] ReLU86 <- Convolution86
I0612 11:07:31.816660  5211 net.cpp:576] ReLU86 -> Convolution86 (in-place)
I0612 11:07:31.816668  5211 net.cpp:240] Setting up ReLU86
I0612 11:07:31.816675  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.816679  5211 net.cpp:255] Memory required for data: 2702705152
I0612 11:07:31.816684  5211 layer_factory.hpp:77] Creating layer Convolution87
I0612 11:07:31.816697  5211 net.cpp:190] Creating Layer Convolution87
I0612 11:07:31.816702  5211 net.cpp:615] Convolution87 <- Convolution86
I0612 11:07:31.816714  5211 net.cpp:589] Convolution87 -> Convolution87
I0612 11:07:31.818723  5211 net.cpp:240] Setting up Convolution87
I0612 11:07:31.818733  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.818738  5211 net.cpp:255] Memory required for data: 2704802304
I0612 11:07:31.818748  5211 layer_factory.hpp:77] Creating layer BatchNorm87
I0612 11:07:31.818759  5211 net.cpp:190] Creating Layer BatchNorm87
I0612 11:07:31.818764  5211 net.cpp:615] BatchNorm87 <- Convolution87
I0612 11:07:31.818773  5211 net.cpp:576] BatchNorm87 -> Convolution87 (in-place)
I0612 11:07:31.819013  5211 net.cpp:240] Setting up BatchNorm87
I0612 11:07:31.819022  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.819026  5211 net.cpp:255] Memory required for data: 2706899456
I0612 11:07:31.819041  5211 layer_factory.hpp:77] Creating layer Scale87
I0612 11:07:31.819049  5211 net.cpp:190] Creating Layer Scale87
I0612 11:07:31.819054  5211 net.cpp:615] Scale87 <- Convolution87
I0612 11:07:31.819061  5211 net.cpp:576] Scale87 -> Convolution87 (in-place)
I0612 11:07:31.819104  5211 layer_factory.hpp:77] Creating layer Scale87
I0612 11:07:31.819250  5211 net.cpp:240] Setting up Scale87
I0612 11:07:31.819258  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.819263  5211 net.cpp:255] Memory required for data: 2708996608
I0612 11:07:31.819278  5211 layer_factory.hpp:77] Creating layer Eltwise43
I0612 11:07:31.819286  5211 net.cpp:190] Creating Layer Eltwise43
I0612 11:07:31.819293  5211 net.cpp:615] Eltwise43 <- Eltwise42_ReLU85_0_split_1
I0612 11:07:31.819299  5211 net.cpp:615] Eltwise43 <- Convolution87
I0612 11:07:31.819311  5211 net.cpp:589] Eltwise43 -> Eltwise43
I0612 11:07:31.819335  5211 net.cpp:240] Setting up Eltwise43
I0612 11:07:31.819342  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.819347  5211 net.cpp:255] Memory required for data: 2711093760
I0612 11:07:31.819351  5211 layer_factory.hpp:77] Creating layer ReLU87
I0612 11:07:31.819358  5211 net.cpp:190] Creating Layer ReLU87
I0612 11:07:31.819363  5211 net.cpp:615] ReLU87 <- Eltwise43
I0612 11:07:31.819372  5211 net.cpp:576] ReLU87 -> Eltwise43 (in-place)
I0612 11:07:31.819380  5211 net.cpp:240] Setting up ReLU87
I0612 11:07:31.819386  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.819391  5211 net.cpp:255] Memory required for data: 2713190912
I0612 11:07:31.819394  5211 layer_factory.hpp:77] Creating layer Eltwise43_ReLU87_0_split
I0612 11:07:31.819401  5211 net.cpp:190] Creating Layer Eltwise43_ReLU87_0_split
I0612 11:07:31.819406  5211 net.cpp:615] Eltwise43_ReLU87_0_split <- Eltwise43
I0612 11:07:31.819412  5211 net.cpp:589] Eltwise43_ReLU87_0_split -> Eltwise43_ReLU87_0_split_0
I0612 11:07:31.819420  5211 net.cpp:589] Eltwise43_ReLU87_0_split -> Eltwise43_ReLU87_0_split_1
I0612 11:07:31.819464  5211 net.cpp:240] Setting up Eltwise43_ReLU87_0_split
I0612 11:07:31.819473  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.819478  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.819481  5211 net.cpp:255] Memory required for data: 2717385216
I0612 11:07:31.819486  5211 layer_factory.hpp:77] Creating layer Convolution88
I0612 11:07:31.819496  5211 net.cpp:190] Creating Layer Convolution88
I0612 11:07:31.819502  5211 net.cpp:615] Convolution88 <- Eltwise43_ReLU87_0_split_0
I0612 11:07:31.819512  5211 net.cpp:589] Convolution88 -> Convolution88
I0612 11:07:31.822072  5211 net.cpp:240] Setting up Convolution88
I0612 11:07:31.822088  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.822093  5211 net.cpp:255] Memory required for data: 2719482368
I0612 11:07:31.822105  5211 layer_factory.hpp:77] Creating layer BatchNorm88
I0612 11:07:31.822119  5211 net.cpp:190] Creating Layer BatchNorm88
I0612 11:07:31.822125  5211 net.cpp:615] BatchNorm88 <- Convolution88
I0612 11:07:31.822132  5211 net.cpp:576] BatchNorm88 -> Convolution88 (in-place)
I0612 11:07:31.822386  5211 net.cpp:240] Setting up BatchNorm88
I0612 11:07:31.822397  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.822402  5211 net.cpp:255] Memory required for data: 2721579520
I0612 11:07:31.822415  5211 layer_factory.hpp:77] Creating layer Scale88
I0612 11:07:31.822423  5211 net.cpp:190] Creating Layer Scale88
I0612 11:07:31.822428  5211 net.cpp:615] Scale88 <- Convolution88
I0612 11:07:31.822435  5211 net.cpp:576] Scale88 -> Convolution88 (in-place)
I0612 11:07:31.822482  5211 layer_factory.hpp:77] Creating layer Scale88
I0612 11:07:31.822628  5211 net.cpp:240] Setting up Scale88
I0612 11:07:31.822638  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.822641  5211 net.cpp:255] Memory required for data: 2723676672
I0612 11:07:31.822652  5211 layer_factory.hpp:77] Creating layer ReLU88
I0612 11:07:31.822662  5211 net.cpp:190] Creating Layer ReLU88
I0612 11:07:31.822667  5211 net.cpp:615] ReLU88 <- Convolution88
I0612 11:07:31.822674  5211 net.cpp:576] ReLU88 -> Convolution88 (in-place)
I0612 11:07:31.822681  5211 net.cpp:240] Setting up ReLU88
I0612 11:07:31.822687  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.822691  5211 net.cpp:255] Memory required for data: 2725773824
I0612 11:07:31.822696  5211 layer_factory.hpp:77] Creating layer Convolution89
I0612 11:07:31.822710  5211 net.cpp:190] Creating Layer Convolution89
I0612 11:07:31.822715  5211 net.cpp:615] Convolution89 <- Convolution88
I0612 11:07:31.822721  5211 net.cpp:589] Convolution89 -> Convolution89
I0612 11:07:31.824640  5211 net.cpp:240] Setting up Convolution89
I0612 11:07:31.824651  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.824656  5211 net.cpp:255] Memory required for data: 2727870976
I0612 11:07:31.824669  5211 layer_factory.hpp:77] Creating layer BatchNorm89
I0612 11:07:31.824681  5211 net.cpp:190] Creating Layer BatchNorm89
I0612 11:07:31.824687  5211 net.cpp:615] BatchNorm89 <- Convolution89
I0612 11:07:31.824694  5211 net.cpp:576] BatchNorm89 -> Convolution89 (in-place)
I0612 11:07:31.824944  5211 net.cpp:240] Setting up BatchNorm89
I0612 11:07:31.824954  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.824957  5211 net.cpp:255] Memory required for data: 2729968128
I0612 11:07:31.824970  5211 layer_factory.hpp:77] Creating layer Scale89
I0612 11:07:31.824981  5211 net.cpp:190] Creating Layer Scale89
I0612 11:07:31.824986  5211 net.cpp:615] Scale89 <- Convolution89
I0612 11:07:31.824993  5211 net.cpp:576] Scale89 -> Convolution89 (in-place)
I0612 11:07:31.825037  5211 layer_factory.hpp:77] Creating layer Scale89
I0612 11:07:31.825187  5211 net.cpp:240] Setting up Scale89
I0612 11:07:31.825196  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.825201  5211 net.cpp:255] Memory required for data: 2732065280
I0612 11:07:31.825211  5211 layer_factory.hpp:77] Creating layer Eltwise44
I0612 11:07:31.825222  5211 net.cpp:190] Creating Layer Eltwise44
I0612 11:07:31.825227  5211 net.cpp:615] Eltwise44 <- Eltwise43_ReLU87_0_split_1
I0612 11:07:31.825234  5211 net.cpp:615] Eltwise44 <- Convolution89
I0612 11:07:31.825240  5211 net.cpp:589] Eltwise44 -> Eltwise44
I0612 11:07:31.825266  5211 net.cpp:240] Setting up Eltwise44
I0612 11:07:31.825274  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.825278  5211 net.cpp:255] Memory required for data: 2734162432
I0612 11:07:31.825284  5211 layer_factory.hpp:77] Creating layer ReLU89
I0612 11:07:31.825290  5211 net.cpp:190] Creating Layer ReLU89
I0612 11:07:31.825295  5211 net.cpp:615] ReLU89 <- Eltwise44
I0612 11:07:31.825301  5211 net.cpp:576] ReLU89 -> Eltwise44 (in-place)
I0612 11:07:31.825309  5211 net.cpp:240] Setting up ReLU89
I0612 11:07:31.825314  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.825320  5211 net.cpp:255] Memory required for data: 2736259584
I0612 11:07:31.825323  5211 layer_factory.hpp:77] Creating layer Eltwise44_ReLU89_0_split
I0612 11:07:31.825330  5211 net.cpp:190] Creating Layer Eltwise44_ReLU89_0_split
I0612 11:07:31.825335  5211 net.cpp:615] Eltwise44_ReLU89_0_split <- Eltwise44
I0612 11:07:31.825343  5211 net.cpp:589] Eltwise44_ReLU89_0_split -> Eltwise44_ReLU89_0_split_0
I0612 11:07:31.825351  5211 net.cpp:589] Eltwise44_ReLU89_0_split -> Eltwise44_ReLU89_0_split_1
I0612 11:07:31.825397  5211 net.cpp:240] Setting up Eltwise44_ReLU89_0_split
I0612 11:07:31.825403  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.825409  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.825413  5211 net.cpp:255] Memory required for data: 2740453888
I0612 11:07:31.825418  5211 layer_factory.hpp:77] Creating layer Convolution90
I0612 11:07:31.825428  5211 net.cpp:190] Creating Layer Convolution90
I0612 11:07:31.825433  5211 net.cpp:615] Convolution90 <- Eltwise44_ReLU89_0_split_0
I0612 11:07:31.825441  5211 net.cpp:589] Convolution90 -> Convolution90
I0612 11:07:31.827363  5211 net.cpp:240] Setting up Convolution90
I0612 11:07:31.827375  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.827379  5211 net.cpp:255] Memory required for data: 2742551040
I0612 11:07:31.827390  5211 layer_factory.hpp:77] Creating layer BatchNorm90
I0612 11:07:31.827401  5211 net.cpp:190] Creating Layer BatchNorm90
I0612 11:07:31.827406  5211 net.cpp:615] BatchNorm90 <- Convolution90
I0612 11:07:31.827414  5211 net.cpp:576] BatchNorm90 -> Convolution90 (in-place)
I0612 11:07:31.827659  5211 net.cpp:240] Setting up BatchNorm90
I0612 11:07:31.827667  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.827672  5211 net.cpp:255] Memory required for data: 2744648192
I0612 11:07:31.827685  5211 layer_factory.hpp:77] Creating layer Scale90
I0612 11:07:31.827693  5211 net.cpp:190] Creating Layer Scale90
I0612 11:07:31.827698  5211 net.cpp:615] Scale90 <- Convolution90
I0612 11:07:31.827708  5211 net.cpp:576] Scale90 -> Convolution90 (in-place)
I0612 11:07:31.827756  5211 layer_factory.hpp:77] Creating layer Scale90
I0612 11:07:31.827904  5211 net.cpp:240] Setting up Scale90
I0612 11:07:31.827914  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.827919  5211 net.cpp:255] Memory required for data: 2746745344
I0612 11:07:31.827929  5211 layer_factory.hpp:77] Creating layer ReLU90
I0612 11:07:31.827937  5211 net.cpp:190] Creating Layer ReLU90
I0612 11:07:31.827942  5211 net.cpp:615] ReLU90 <- Convolution90
I0612 11:07:31.827949  5211 net.cpp:576] ReLU90 -> Convolution90 (in-place)
I0612 11:07:31.827956  5211 net.cpp:240] Setting up ReLU90
I0612 11:07:31.827962  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.827966  5211 net.cpp:255] Memory required for data: 2748842496
I0612 11:07:31.827971  5211 layer_factory.hpp:77] Creating layer Convolution91
I0612 11:07:31.827985  5211 net.cpp:190] Creating Layer Convolution91
I0612 11:07:31.827989  5211 net.cpp:615] Convolution91 <- Convolution90
I0612 11:07:31.827998  5211 net.cpp:589] Convolution91 -> Convolution91
I0612 11:07:31.829916  5211 net.cpp:240] Setting up Convolution91
I0612 11:07:31.829926  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.829931  5211 net.cpp:255] Memory required for data: 2750939648
I0612 11:07:31.829942  5211 layer_factory.hpp:77] Creating layer BatchNorm91
I0612 11:07:31.829953  5211 net.cpp:190] Creating Layer BatchNorm91
I0612 11:07:31.829958  5211 net.cpp:615] BatchNorm91 <- Convolution91
I0612 11:07:31.829967  5211 net.cpp:576] BatchNorm91 -> Convolution91 (in-place)
I0612 11:07:31.830210  5211 net.cpp:240] Setting up BatchNorm91
I0612 11:07:31.830219  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.830224  5211 net.cpp:255] Memory required for data: 2753036800
I0612 11:07:31.830238  5211 layer_factory.hpp:77] Creating layer Scale91
I0612 11:07:31.830246  5211 net.cpp:190] Creating Layer Scale91
I0612 11:07:31.830251  5211 net.cpp:615] Scale91 <- Convolution91
I0612 11:07:31.830257  5211 net.cpp:576] Scale91 -> Convolution91 (in-place)
I0612 11:07:31.830302  5211 layer_factory.hpp:77] Creating layer Scale91
I0612 11:07:31.830457  5211 net.cpp:240] Setting up Scale91
I0612 11:07:31.830466  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.830471  5211 net.cpp:255] Memory required for data: 2755133952
I0612 11:07:31.830483  5211 layer_factory.hpp:77] Creating layer Eltwise45
I0612 11:07:31.830492  5211 net.cpp:190] Creating Layer Eltwise45
I0612 11:07:31.830497  5211 net.cpp:615] Eltwise45 <- Eltwise44_ReLU89_0_split_1
I0612 11:07:31.830503  5211 net.cpp:615] Eltwise45 <- Convolution91
I0612 11:07:31.830513  5211 net.cpp:589] Eltwise45 -> Eltwise45
I0612 11:07:31.830536  5211 net.cpp:240] Setting up Eltwise45
I0612 11:07:31.830543  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.830549  5211 net.cpp:255] Memory required for data: 2757231104
I0612 11:07:31.830552  5211 layer_factory.hpp:77] Creating layer ReLU91
I0612 11:07:31.830559  5211 net.cpp:190] Creating Layer ReLU91
I0612 11:07:31.830564  5211 net.cpp:615] ReLU91 <- Eltwise45
I0612 11:07:31.830572  5211 net.cpp:576] ReLU91 -> Eltwise45 (in-place)
I0612 11:07:31.830580  5211 net.cpp:240] Setting up ReLU91
I0612 11:07:31.830586  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.830590  5211 net.cpp:255] Memory required for data: 2759328256
I0612 11:07:31.830595  5211 layer_factory.hpp:77] Creating layer Eltwise45_ReLU91_0_split
I0612 11:07:31.830601  5211 net.cpp:190] Creating Layer Eltwise45_ReLU91_0_split
I0612 11:07:31.830615  5211 net.cpp:615] Eltwise45_ReLU91_0_split <- Eltwise45
I0612 11:07:31.830621  5211 net.cpp:589] Eltwise45_ReLU91_0_split -> Eltwise45_ReLU91_0_split_0
I0612 11:07:31.830629  5211 net.cpp:589] Eltwise45_ReLU91_0_split -> Eltwise45_ReLU91_0_split_1
I0612 11:07:31.830672  5211 net.cpp:240] Setting up Eltwise45_ReLU91_0_split
I0612 11:07:31.830679  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.830684  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.830692  5211 net.cpp:255] Memory required for data: 2763522560
I0612 11:07:31.830695  5211 layer_factory.hpp:77] Creating layer Convolution92
I0612 11:07:31.830706  5211 net.cpp:190] Creating Layer Convolution92
I0612 11:07:31.830711  5211 net.cpp:615] Convolution92 <- Eltwise45_ReLU91_0_split_0
I0612 11:07:31.830721  5211 net.cpp:589] Convolution92 -> Convolution92
I0612 11:07:31.832551  5211 net.cpp:240] Setting up Convolution92
I0612 11:07:31.832561  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.832564  5211 net.cpp:255] Memory required for data: 2765619712
I0612 11:07:31.832574  5211 layer_factory.hpp:77] Creating layer BatchNorm92
I0612 11:07:31.832584  5211 net.cpp:190] Creating Layer BatchNorm92
I0612 11:07:31.832589  5211 net.cpp:615] BatchNorm92 <- Convolution92
I0612 11:07:31.832597  5211 net.cpp:576] BatchNorm92 -> Convolution92 (in-place)
I0612 11:07:31.832834  5211 net.cpp:240] Setting up BatchNorm92
I0612 11:07:31.832842  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.832846  5211 net.cpp:255] Memory required for data: 2767716864
I0612 11:07:31.832859  5211 layer_factory.hpp:77] Creating layer Scale92
I0612 11:07:31.832868  5211 net.cpp:190] Creating Layer Scale92
I0612 11:07:31.832873  5211 net.cpp:615] Scale92 <- Convolution92
I0612 11:07:31.832880  5211 net.cpp:576] Scale92 -> Convolution92 (in-place)
I0612 11:07:31.832921  5211 layer_factory.hpp:77] Creating layer Scale92
I0612 11:07:31.833061  5211 net.cpp:240] Setting up Scale92
I0612 11:07:31.833070  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.833075  5211 net.cpp:255] Memory required for data: 2769814016
I0612 11:07:31.833084  5211 layer_factory.hpp:77] Creating layer ReLU92
I0612 11:07:31.833093  5211 net.cpp:190] Creating Layer ReLU92
I0612 11:07:31.833099  5211 net.cpp:615] ReLU92 <- Convolution92
I0612 11:07:31.833106  5211 net.cpp:576] ReLU92 -> Convolution92 (in-place)
I0612 11:07:31.833112  5211 net.cpp:240] Setting up ReLU92
I0612 11:07:31.833118  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.833122  5211 net.cpp:255] Memory required for data: 2771911168
I0612 11:07:31.833127  5211 layer_factory.hpp:77] Creating layer Convolution93
I0612 11:07:31.833139  5211 net.cpp:190] Creating Layer Convolution93
I0612 11:07:31.833143  5211 net.cpp:615] Convolution93 <- Convolution92
I0612 11:07:31.833150  5211 net.cpp:589] Convolution93 -> Convolution93
I0612 11:07:31.834983  5211 net.cpp:240] Setting up Convolution93
I0612 11:07:31.834993  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.834997  5211 net.cpp:255] Memory required for data: 2774008320
I0612 11:07:31.835007  5211 layer_factory.hpp:77] Creating layer BatchNorm93
I0612 11:07:31.835018  5211 net.cpp:190] Creating Layer BatchNorm93
I0612 11:07:31.835023  5211 net.cpp:615] BatchNorm93 <- Convolution93
I0612 11:07:31.835029  5211 net.cpp:576] BatchNorm93 -> Convolution93 (in-place)
I0612 11:07:31.835268  5211 net.cpp:240] Setting up BatchNorm93
I0612 11:07:31.835275  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.835279  5211 net.cpp:255] Memory required for data: 2776105472
I0612 11:07:31.835292  5211 layer_factory.hpp:77] Creating layer Scale93
I0612 11:07:31.835300  5211 net.cpp:190] Creating Layer Scale93
I0612 11:07:31.835305  5211 net.cpp:615] Scale93 <- Convolution93
I0612 11:07:31.835310  5211 net.cpp:576] Scale93 -> Convolution93 (in-place)
I0612 11:07:31.835356  5211 layer_factory.hpp:77] Creating layer Scale93
I0612 11:07:31.835497  5211 net.cpp:240] Setting up Scale93
I0612 11:07:31.835505  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.835510  5211 net.cpp:255] Memory required for data: 2778202624
I0612 11:07:31.835520  5211 layer_factory.hpp:77] Creating layer Eltwise46
I0612 11:07:31.835530  5211 net.cpp:190] Creating Layer Eltwise46
I0612 11:07:31.835535  5211 net.cpp:615] Eltwise46 <- Eltwise45_ReLU91_0_split_1
I0612 11:07:31.835541  5211 net.cpp:615] Eltwise46 <- Convolution93
I0612 11:07:31.835546  5211 net.cpp:589] Eltwise46 -> Eltwise46
I0612 11:07:31.835577  5211 net.cpp:240] Setting up Eltwise46
I0612 11:07:31.835584  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.835588  5211 net.cpp:255] Memory required for data: 2780299776
I0612 11:07:31.835593  5211 layer_factory.hpp:77] Creating layer ReLU93
I0612 11:07:31.835599  5211 net.cpp:190] Creating Layer ReLU93
I0612 11:07:31.835604  5211 net.cpp:615] ReLU93 <- Eltwise46
I0612 11:07:31.835613  5211 net.cpp:576] ReLU93 -> Eltwise46 (in-place)
I0612 11:07:31.835619  5211 net.cpp:240] Setting up ReLU93
I0612 11:07:31.835625  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.835629  5211 net.cpp:255] Memory required for data: 2782396928
I0612 11:07:31.835633  5211 layer_factory.hpp:77] Creating layer Eltwise46_ReLU93_0_split
I0612 11:07:31.835640  5211 net.cpp:190] Creating Layer Eltwise46_ReLU93_0_split
I0612 11:07:31.835644  5211 net.cpp:615] Eltwise46_ReLU93_0_split <- Eltwise46
I0612 11:07:31.835650  5211 net.cpp:589] Eltwise46_ReLU93_0_split -> Eltwise46_ReLU93_0_split_0
I0612 11:07:31.835659  5211 net.cpp:589] Eltwise46_ReLU93_0_split -> Eltwise46_ReLU93_0_split_1
I0612 11:07:31.835701  5211 net.cpp:240] Setting up Eltwise46_ReLU93_0_split
I0612 11:07:31.835710  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.835714  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.835718  5211 net.cpp:255] Memory required for data: 2786591232
I0612 11:07:31.835722  5211 layer_factory.hpp:77] Creating layer Convolution94
I0612 11:07:31.835734  5211 net.cpp:190] Creating Layer Convolution94
I0612 11:07:31.835739  5211 net.cpp:615] Convolution94 <- Eltwise46_ReLU93_0_split_0
I0612 11:07:31.835747  5211 net.cpp:589] Convolution94 -> Convolution94
I0612 11:07:31.837575  5211 net.cpp:240] Setting up Convolution94
I0612 11:07:31.837585  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.837589  5211 net.cpp:255] Memory required for data: 2788688384
I0612 11:07:31.837599  5211 layer_factory.hpp:77] Creating layer BatchNorm94
I0612 11:07:31.837611  5211 net.cpp:190] Creating Layer BatchNorm94
I0612 11:07:31.837616  5211 net.cpp:615] BatchNorm94 <- Convolution94
I0612 11:07:31.837625  5211 net.cpp:576] BatchNorm94 -> Convolution94 (in-place)
I0612 11:07:31.837867  5211 net.cpp:240] Setting up BatchNorm94
I0612 11:07:31.837877  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.837880  5211 net.cpp:255] Memory required for data: 2790785536
I0612 11:07:31.837895  5211 layer_factory.hpp:77] Creating layer Scale94
I0612 11:07:31.837903  5211 net.cpp:190] Creating Layer Scale94
I0612 11:07:31.837908  5211 net.cpp:615] Scale94 <- Convolution94
I0612 11:07:31.837914  5211 net.cpp:576] Scale94 -> Convolution94 (in-place)
I0612 11:07:31.837960  5211 layer_factory.hpp:77] Creating layer Scale94
I0612 11:07:31.838738  5211 net.cpp:240] Setting up Scale94
I0612 11:07:31.838753  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.838758  5211 net.cpp:255] Memory required for data: 2792882688
I0612 11:07:31.838770  5211 layer_factory.hpp:77] Creating layer ReLU94
I0612 11:07:31.838784  5211 net.cpp:190] Creating Layer ReLU94
I0612 11:07:31.838790  5211 net.cpp:615] ReLU94 <- Convolution94
I0612 11:07:31.838798  5211 net.cpp:576] ReLU94 -> Convolution94 (in-place)
I0612 11:07:31.838805  5211 net.cpp:240] Setting up ReLU94
I0612 11:07:31.838811  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.838815  5211 net.cpp:255] Memory required for data: 2794979840
I0612 11:07:31.838819  5211 layer_factory.hpp:77] Creating layer Convolution95
I0612 11:07:31.838834  5211 net.cpp:190] Creating Layer Convolution95
I0612 11:07:31.838838  5211 net.cpp:615] Convolution95 <- Convolution94
I0612 11:07:31.838845  5211 net.cpp:589] Convolution95 -> Convolution95
I0612 11:07:31.841307  5211 net.cpp:240] Setting up Convolution95
I0612 11:07:31.841323  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.841327  5211 net.cpp:255] Memory required for data: 2797076992
I0612 11:07:31.841339  5211 layer_factory.hpp:77] Creating layer BatchNorm95
I0612 11:07:31.841353  5211 net.cpp:190] Creating Layer BatchNorm95
I0612 11:07:31.841359  5211 net.cpp:615] BatchNorm95 <- Convolution95
I0612 11:07:31.841367  5211 net.cpp:576] BatchNorm95 -> Convolution95 (in-place)
I0612 11:07:31.841614  5211 net.cpp:240] Setting up BatchNorm95
I0612 11:07:31.841624  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.841627  5211 net.cpp:255] Memory required for data: 2799174144
I0612 11:07:31.841640  5211 layer_factory.hpp:77] Creating layer Scale95
I0612 11:07:31.841648  5211 net.cpp:190] Creating Layer Scale95
I0612 11:07:31.841653  5211 net.cpp:615] Scale95 <- Convolution95
I0612 11:07:31.841660  5211 net.cpp:576] Scale95 -> Convolution95 (in-place)
I0612 11:07:31.841706  5211 layer_factory.hpp:77] Creating layer Scale95
I0612 11:07:31.841845  5211 net.cpp:240] Setting up Scale95
I0612 11:07:31.841852  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.841856  5211 net.cpp:255] Memory required for data: 2801271296
I0612 11:07:31.841868  5211 layer_factory.hpp:77] Creating layer Eltwise47
I0612 11:07:31.841877  5211 net.cpp:190] Creating Layer Eltwise47
I0612 11:07:31.841882  5211 net.cpp:615] Eltwise47 <- Eltwise46_ReLU93_0_split_1
I0612 11:07:31.841888  5211 net.cpp:615] Eltwise47 <- Convolution95
I0612 11:07:31.841895  5211 net.cpp:589] Eltwise47 -> Eltwise47
I0612 11:07:31.841922  5211 net.cpp:240] Setting up Eltwise47
I0612 11:07:31.841929  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.841933  5211 net.cpp:255] Memory required for data: 2803368448
I0612 11:07:31.841938  5211 layer_factory.hpp:77] Creating layer ReLU95
I0612 11:07:31.841945  5211 net.cpp:190] Creating Layer ReLU95
I0612 11:07:31.841949  5211 net.cpp:615] ReLU95 <- Eltwise47
I0612 11:07:31.841958  5211 net.cpp:576] ReLU95 -> Eltwise47 (in-place)
I0612 11:07:31.841964  5211 net.cpp:240] Setting up ReLU95
I0612 11:07:31.841970  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.841974  5211 net.cpp:255] Memory required for data: 2805465600
I0612 11:07:31.841979  5211 layer_factory.hpp:77] Creating layer Eltwise47_ReLU95_0_split
I0612 11:07:31.841985  5211 net.cpp:190] Creating Layer Eltwise47_ReLU95_0_split
I0612 11:07:31.841989  5211 net.cpp:615] Eltwise47_ReLU95_0_split <- Eltwise47
I0612 11:07:31.841995  5211 net.cpp:589] Eltwise47_ReLU95_0_split -> Eltwise47_ReLU95_0_split_0
I0612 11:07:31.842003  5211 net.cpp:589] Eltwise47_ReLU95_0_split -> Eltwise47_ReLU95_0_split_1
I0612 11:07:31.842047  5211 net.cpp:240] Setting up Eltwise47_ReLU95_0_split
I0612 11:07:31.842054  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.842059  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.842063  5211 net.cpp:255] Memory required for data: 2809659904
I0612 11:07:31.842068  5211 layer_factory.hpp:77] Creating layer Convolution96
I0612 11:07:31.842080  5211 net.cpp:190] Creating Layer Convolution96
I0612 11:07:31.842085  5211 net.cpp:615] Convolution96 <- Eltwise47_ReLU95_0_split_0
I0612 11:07:31.842093  5211 net.cpp:589] Convolution96 -> Convolution96
I0612 11:07:31.843897  5211 net.cpp:240] Setting up Convolution96
I0612 11:07:31.843909  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.843912  5211 net.cpp:255] Memory required for data: 2811757056
I0612 11:07:31.843922  5211 layer_factory.hpp:77] Creating layer BatchNorm96
I0612 11:07:31.843932  5211 net.cpp:190] Creating Layer BatchNorm96
I0612 11:07:31.843938  5211 net.cpp:615] BatchNorm96 <- Convolution96
I0612 11:07:31.843946  5211 net.cpp:576] BatchNorm96 -> Convolution96 (in-place)
I0612 11:07:31.844168  5211 net.cpp:240] Setting up BatchNorm96
I0612 11:07:31.844177  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.844180  5211 net.cpp:255] Memory required for data: 2813854208
I0612 11:07:31.844194  5211 layer_factory.hpp:77] Creating layer Scale96
I0612 11:07:31.844202  5211 net.cpp:190] Creating Layer Scale96
I0612 11:07:31.844207  5211 net.cpp:615] Scale96 <- Convolution96
I0612 11:07:31.844213  5211 net.cpp:576] Scale96 -> Convolution96 (in-place)
I0612 11:07:31.844259  5211 layer_factory.hpp:77] Creating layer Scale96
I0612 11:07:31.844398  5211 net.cpp:240] Setting up Scale96
I0612 11:07:31.844405  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.844409  5211 net.cpp:255] Memory required for data: 2815951360
I0612 11:07:31.844419  5211 layer_factory.hpp:77] Creating layer ReLU96
I0612 11:07:31.844426  5211 net.cpp:190] Creating Layer ReLU96
I0612 11:07:31.844431  5211 net.cpp:615] ReLU96 <- Convolution96
I0612 11:07:31.844439  5211 net.cpp:576] ReLU96 -> Convolution96 (in-place)
I0612 11:07:31.844446  5211 net.cpp:240] Setting up ReLU96
I0612 11:07:31.844452  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.844455  5211 net.cpp:255] Memory required for data: 2818048512
I0612 11:07:31.844460  5211 layer_factory.hpp:77] Creating layer Convolution97
I0612 11:07:31.844470  5211 net.cpp:190] Creating Layer Convolution97
I0612 11:07:31.844475  5211 net.cpp:615] Convolution97 <- Convolution96
I0612 11:07:31.844483  5211 net.cpp:589] Convolution97 -> Convolution97
I0612 11:07:31.846225  5211 net.cpp:240] Setting up Convolution97
I0612 11:07:31.846233  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.846238  5211 net.cpp:255] Memory required for data: 2820145664
I0612 11:07:31.846247  5211 layer_factory.hpp:77] Creating layer BatchNorm97
I0612 11:07:31.846256  5211 net.cpp:190] Creating Layer BatchNorm97
I0612 11:07:31.846261  5211 net.cpp:615] BatchNorm97 <- Convolution97
I0612 11:07:31.846268  5211 net.cpp:576] BatchNorm97 -> Convolution97 (in-place)
I0612 11:07:31.846503  5211 net.cpp:240] Setting up BatchNorm97
I0612 11:07:31.846510  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.846514  5211 net.cpp:255] Memory required for data: 2822242816
I0612 11:07:31.846526  5211 layer_factory.hpp:77] Creating layer Scale97
I0612 11:07:31.846534  5211 net.cpp:190] Creating Layer Scale97
I0612 11:07:31.846539  5211 net.cpp:615] Scale97 <- Convolution97
I0612 11:07:31.846547  5211 net.cpp:576] Scale97 -> Convolution97 (in-place)
I0612 11:07:31.846586  5211 layer_factory.hpp:77] Creating layer Scale97
I0612 11:07:31.846722  5211 net.cpp:240] Setting up Scale97
I0612 11:07:31.846730  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.846735  5211 net.cpp:255] Memory required for data: 2824339968
I0612 11:07:31.846743  5211 layer_factory.hpp:77] Creating layer Eltwise48
I0612 11:07:31.846751  5211 net.cpp:190] Creating Layer Eltwise48
I0612 11:07:31.846756  5211 net.cpp:615] Eltwise48 <- Eltwise47_ReLU95_0_split_1
I0612 11:07:31.846762  5211 net.cpp:615] Eltwise48 <- Convolution97
I0612 11:07:31.846771  5211 net.cpp:589] Eltwise48 -> Eltwise48
I0612 11:07:31.846791  5211 net.cpp:240] Setting up Eltwise48
I0612 11:07:31.846801  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.846804  5211 net.cpp:255] Memory required for data: 2826437120
I0612 11:07:31.846808  5211 layer_factory.hpp:77] Creating layer ReLU97
I0612 11:07:31.846815  5211 net.cpp:190] Creating Layer ReLU97
I0612 11:07:31.846819  5211 net.cpp:615] ReLU97 <- Eltwise48
I0612 11:07:31.846825  5211 net.cpp:576] ReLU97 -> Eltwise48 (in-place)
I0612 11:07:31.846832  5211 net.cpp:240] Setting up ReLU97
I0612 11:07:31.846837  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.846842  5211 net.cpp:255] Memory required for data: 2828534272
I0612 11:07:31.846845  5211 layer_factory.hpp:77] Creating layer Eltwise48_ReLU97_0_split
I0612 11:07:31.846851  5211 net.cpp:190] Creating Layer Eltwise48_ReLU97_0_split
I0612 11:07:31.846855  5211 net.cpp:615] Eltwise48_ReLU97_0_split <- Eltwise48
I0612 11:07:31.846864  5211 net.cpp:589] Eltwise48_ReLU97_0_split -> Eltwise48_ReLU97_0_split_0
I0612 11:07:31.846873  5211 net.cpp:589] Eltwise48_ReLU97_0_split -> Eltwise48_ReLU97_0_split_1
I0612 11:07:31.846911  5211 net.cpp:240] Setting up Eltwise48_ReLU97_0_split
I0612 11:07:31.846918  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.846923  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.846930  5211 net.cpp:255] Memory required for data: 2832728576
I0612 11:07:31.846935  5211 layer_factory.hpp:77] Creating layer Convolution98
I0612 11:07:31.846946  5211 net.cpp:190] Creating Layer Convolution98
I0612 11:07:31.846951  5211 net.cpp:615] Convolution98 <- Eltwise48_ReLU97_0_split_0
I0612 11:07:31.846959  5211 net.cpp:589] Convolution98 -> Convolution98
I0612 11:07:31.848702  5211 net.cpp:240] Setting up Convolution98
I0612 11:07:31.848711  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.848716  5211 net.cpp:255] Memory required for data: 2834825728
I0612 11:07:31.848726  5211 layer_factory.hpp:77] Creating layer BatchNorm98
I0612 11:07:31.848736  5211 net.cpp:190] Creating Layer BatchNorm98
I0612 11:07:31.848740  5211 net.cpp:615] BatchNorm98 <- Convolution98
I0612 11:07:31.848747  5211 net.cpp:576] BatchNorm98 -> Convolution98 (in-place)
I0612 11:07:31.848964  5211 net.cpp:240] Setting up BatchNorm98
I0612 11:07:31.848973  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.848976  5211 net.cpp:255] Memory required for data: 2836922880
I0612 11:07:31.848989  5211 layer_factory.hpp:77] Creating layer Scale98
I0612 11:07:31.848996  5211 net.cpp:190] Creating Layer Scale98
I0612 11:07:31.849000  5211 net.cpp:615] Scale98 <- Convolution98
I0612 11:07:31.849006  5211 net.cpp:576] Scale98 -> Convolution98 (in-place)
I0612 11:07:31.849051  5211 layer_factory.hpp:77] Creating layer Scale98
I0612 11:07:31.849184  5211 net.cpp:240] Setting up Scale98
I0612 11:07:31.849190  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.849195  5211 net.cpp:255] Memory required for data: 2839020032
I0612 11:07:31.849206  5211 layer_factory.hpp:77] Creating layer ReLU98
I0612 11:07:31.849213  5211 net.cpp:190] Creating Layer ReLU98
I0612 11:07:31.849217  5211 net.cpp:615] ReLU98 <- Convolution98
I0612 11:07:31.849223  5211 net.cpp:576] ReLU98 -> Convolution98 (in-place)
I0612 11:07:31.849231  5211 net.cpp:240] Setting up ReLU98
I0612 11:07:31.849236  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.849241  5211 net.cpp:255] Memory required for data: 2841117184
I0612 11:07:31.849244  5211 layer_factory.hpp:77] Creating layer Convolution99
I0612 11:07:31.849256  5211 net.cpp:190] Creating Layer Convolution99
I0612 11:07:31.849261  5211 net.cpp:615] Convolution99 <- Convolution98
I0612 11:07:31.849269  5211 net.cpp:589] Convolution99 -> Convolution99
I0612 11:07:31.851016  5211 net.cpp:240] Setting up Convolution99
I0612 11:07:31.851025  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.851029  5211 net.cpp:255] Memory required for data: 2843214336
I0612 11:07:31.851039  5211 layer_factory.hpp:77] Creating layer BatchNorm99
I0612 11:07:31.851050  5211 net.cpp:190] Creating Layer BatchNorm99
I0612 11:07:31.851055  5211 net.cpp:615] BatchNorm99 <- Convolution99
I0612 11:07:31.851063  5211 net.cpp:576] BatchNorm99 -> Convolution99 (in-place)
I0612 11:07:31.851287  5211 net.cpp:240] Setting up BatchNorm99
I0612 11:07:31.851295  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.851300  5211 net.cpp:255] Memory required for data: 2845311488
I0612 11:07:31.851311  5211 layer_factory.hpp:77] Creating layer Scale99
I0612 11:07:31.851321  5211 net.cpp:190] Creating Layer Scale99
I0612 11:07:31.851326  5211 net.cpp:615] Scale99 <- Convolution99
I0612 11:07:31.851331  5211 net.cpp:576] Scale99 -> Convolution99 (in-place)
I0612 11:07:31.851372  5211 layer_factory.hpp:77] Creating layer Scale99
I0612 11:07:31.851506  5211 net.cpp:240] Setting up Scale99
I0612 11:07:31.851514  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.851518  5211 net.cpp:255] Memory required for data: 2847408640
I0612 11:07:31.851529  5211 layer_factory.hpp:77] Creating layer Eltwise49
I0612 11:07:31.851537  5211 net.cpp:190] Creating Layer Eltwise49
I0612 11:07:31.851542  5211 net.cpp:615] Eltwise49 <- Eltwise48_ReLU97_0_split_1
I0612 11:07:31.851548  5211 net.cpp:615] Eltwise49 <- Convolution99
I0612 11:07:31.851557  5211 net.cpp:589] Eltwise49 -> Eltwise49
I0612 11:07:31.851582  5211 net.cpp:240] Setting up Eltwise49
I0612 11:07:31.851588  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.851593  5211 net.cpp:255] Memory required for data: 2849505792
I0612 11:07:31.851596  5211 layer_factory.hpp:77] Creating layer ReLU99
I0612 11:07:31.851603  5211 net.cpp:190] Creating Layer ReLU99
I0612 11:07:31.851606  5211 net.cpp:615] ReLU99 <- Eltwise49
I0612 11:07:31.851614  5211 net.cpp:576] ReLU99 -> Eltwise49 (in-place)
I0612 11:07:31.851622  5211 net.cpp:240] Setting up ReLU99
I0612 11:07:31.851627  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.851631  5211 net.cpp:255] Memory required for data: 2851602944
I0612 11:07:31.851635  5211 layer_factory.hpp:77] Creating layer Eltwise49_ReLU99_0_split
I0612 11:07:31.851641  5211 net.cpp:190] Creating Layer Eltwise49_ReLU99_0_split
I0612 11:07:31.851645  5211 net.cpp:615] Eltwise49_ReLU99_0_split <- Eltwise49
I0612 11:07:31.851651  5211 net.cpp:589] Eltwise49_ReLU99_0_split -> Eltwise49_ReLU99_0_split_0
I0612 11:07:31.851658  5211 net.cpp:589] Eltwise49_ReLU99_0_split -> Eltwise49_ReLU99_0_split_1
I0612 11:07:31.851701  5211 net.cpp:240] Setting up Eltwise49_ReLU99_0_split
I0612 11:07:31.851708  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.851713  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.851717  5211 net.cpp:255] Memory required for data: 2855797248
I0612 11:07:31.851722  5211 layer_factory.hpp:77] Creating layer Convolution100
I0612 11:07:31.851732  5211 net.cpp:190] Creating Layer Convolution100
I0612 11:07:31.851737  5211 net.cpp:615] Convolution100 <- Eltwise49_ReLU99_0_split_0
I0612 11:07:31.851745  5211 net.cpp:589] Convolution100 -> Convolution100
I0612 11:07:31.853508  5211 net.cpp:240] Setting up Convolution100
I0612 11:07:31.853523  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.853526  5211 net.cpp:255] Memory required for data: 2857894400
I0612 11:07:31.853538  5211 layer_factory.hpp:77] Creating layer BatchNorm100
I0612 11:07:31.853545  5211 net.cpp:190] Creating Layer BatchNorm100
I0612 11:07:31.853550  5211 net.cpp:615] BatchNorm100 <- Convolution100
I0612 11:07:31.853556  5211 net.cpp:576] BatchNorm100 -> Convolution100 (in-place)
I0612 11:07:31.853777  5211 net.cpp:240] Setting up BatchNorm100
I0612 11:07:31.853785  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.853790  5211 net.cpp:255] Memory required for data: 2859991552
I0612 11:07:31.853801  5211 layer_factory.hpp:77] Creating layer Scale100
I0612 11:07:31.853808  5211 net.cpp:190] Creating Layer Scale100
I0612 11:07:31.853813  5211 net.cpp:615] Scale100 <- Convolution100
I0612 11:07:31.853819  5211 net.cpp:576] Scale100 -> Convolution100 (in-place)
I0612 11:07:31.853862  5211 layer_factory.hpp:77] Creating layer Scale100
I0612 11:07:31.853991  5211 net.cpp:240] Setting up Scale100
I0612 11:07:31.854001  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.854004  5211 net.cpp:255] Memory required for data: 2862088704
I0612 11:07:31.854014  5211 layer_factory.hpp:77] Creating layer ReLU100
I0612 11:07:31.854022  5211 net.cpp:190] Creating Layer ReLU100
I0612 11:07:31.854027  5211 net.cpp:615] ReLU100 <- Convolution100
I0612 11:07:31.854032  5211 net.cpp:576] ReLU100 -> Convolution100 (in-place)
I0612 11:07:31.854039  5211 net.cpp:240] Setting up ReLU100
I0612 11:07:31.854044  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.854048  5211 net.cpp:255] Memory required for data: 2864185856
I0612 11:07:31.854053  5211 layer_factory.hpp:77] Creating layer Convolution101
I0612 11:07:31.854065  5211 net.cpp:190] Creating Layer Convolution101
I0612 11:07:31.854069  5211 net.cpp:615] Convolution101 <- Convolution100
I0612 11:07:31.854077  5211 net.cpp:589] Convolution101 -> Convolution101
I0612 11:07:31.855792  5211 net.cpp:240] Setting up Convolution101
I0612 11:07:31.855803  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.855806  5211 net.cpp:255] Memory required for data: 2866283008
I0612 11:07:31.855815  5211 layer_factory.hpp:77] Creating layer BatchNorm101
I0612 11:07:31.855829  5211 net.cpp:190] Creating Layer BatchNorm101
I0612 11:07:31.855832  5211 net.cpp:615] BatchNorm101 <- Convolution101
I0612 11:07:31.855840  5211 net.cpp:576] BatchNorm101 -> Convolution101 (in-place)
I0612 11:07:31.856058  5211 net.cpp:240] Setting up BatchNorm101
I0612 11:07:31.856066  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.856070  5211 net.cpp:255] Memory required for data: 2868380160
I0612 11:07:31.856081  5211 layer_factory.hpp:77] Creating layer Scale101
I0612 11:07:31.856092  5211 net.cpp:190] Creating Layer Scale101
I0612 11:07:31.856096  5211 net.cpp:615] Scale101 <- Convolution101
I0612 11:07:31.856102  5211 net.cpp:576] Scale101 -> Convolution101 (in-place)
I0612 11:07:31.856142  5211 layer_factory.hpp:77] Creating layer Scale101
I0612 11:07:31.856271  5211 net.cpp:240] Setting up Scale101
I0612 11:07:31.856278  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.856281  5211 net.cpp:255] Memory required for data: 2870477312
I0612 11:07:31.856293  5211 layer_factory.hpp:77] Creating layer Eltwise50
I0612 11:07:31.856300  5211 net.cpp:190] Creating Layer Eltwise50
I0612 11:07:31.856305  5211 net.cpp:615] Eltwise50 <- Eltwise49_ReLU99_0_split_1
I0612 11:07:31.856312  5211 net.cpp:615] Eltwise50 <- Convolution101
I0612 11:07:31.856319  5211 net.cpp:589] Eltwise50 -> Eltwise50
I0612 11:07:31.856339  5211 net.cpp:240] Setting up Eltwise50
I0612 11:07:31.856345  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.856349  5211 net.cpp:255] Memory required for data: 2872574464
I0612 11:07:31.856353  5211 layer_factory.hpp:77] Creating layer ReLU101
I0612 11:07:31.856360  5211 net.cpp:190] Creating Layer ReLU101
I0612 11:07:31.856364  5211 net.cpp:615] ReLU101 <- Eltwise50
I0612 11:07:31.856371  5211 net.cpp:576] ReLU101 -> Eltwise50 (in-place)
I0612 11:07:31.856379  5211 net.cpp:240] Setting up ReLU101
I0612 11:07:31.856384  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.856387  5211 net.cpp:255] Memory required for data: 2874671616
I0612 11:07:31.856391  5211 layer_factory.hpp:77] Creating layer Eltwise50_ReLU101_0_split
I0612 11:07:31.856397  5211 net.cpp:190] Creating Layer Eltwise50_ReLU101_0_split
I0612 11:07:31.856401  5211 net.cpp:615] Eltwise50_ReLU101_0_split <- Eltwise50
I0612 11:07:31.856406  5211 net.cpp:589] Eltwise50_ReLU101_0_split -> Eltwise50_ReLU101_0_split_0
I0612 11:07:31.856413  5211 net.cpp:589] Eltwise50_ReLU101_0_split -> Eltwise50_ReLU101_0_split_1
I0612 11:07:31.856452  5211 net.cpp:240] Setting up Eltwise50_ReLU101_0_split
I0612 11:07:31.856459  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.856464  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.856467  5211 net.cpp:255] Memory required for data: 2878865920
I0612 11:07:31.856472  5211 layer_factory.hpp:77] Creating layer Convolution102
I0612 11:07:31.856523  5211 net.cpp:190] Creating Layer Convolution102
I0612 11:07:31.856530  5211 net.cpp:615] Convolution102 <- Eltwise50_ReLU101_0_split_0
I0612 11:07:31.856539  5211 net.cpp:589] Convolution102 -> Convolution102
I0612 11:07:31.858832  5211 net.cpp:240] Setting up Convolution102
I0612 11:07:31.858847  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.858852  5211 net.cpp:255] Memory required for data: 2880963072
I0612 11:07:31.858867  5211 layer_factory.hpp:77] Creating layer BatchNorm102
I0612 11:07:31.858878  5211 net.cpp:190] Creating Layer BatchNorm102
I0612 11:07:31.858885  5211 net.cpp:615] BatchNorm102 <- Convolution102
I0612 11:07:31.858891  5211 net.cpp:576] BatchNorm102 -> Convolution102 (in-place)
I0612 11:07:31.859112  5211 net.cpp:240] Setting up BatchNorm102
I0612 11:07:31.859120  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.859124  5211 net.cpp:255] Memory required for data: 2883060224
I0612 11:07:31.859136  5211 layer_factory.hpp:77] Creating layer Scale102
I0612 11:07:31.859144  5211 net.cpp:190] Creating Layer Scale102
I0612 11:07:31.859149  5211 net.cpp:615] Scale102 <- Convolution102
I0612 11:07:31.859158  5211 net.cpp:576] Scale102 -> Convolution102 (in-place)
I0612 11:07:31.859201  5211 layer_factory.hpp:77] Creating layer Scale102
I0612 11:07:31.859331  5211 net.cpp:240] Setting up Scale102
I0612 11:07:31.859339  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.859344  5211 net.cpp:255] Memory required for data: 2885157376
I0612 11:07:31.859354  5211 layer_factory.hpp:77] Creating layer ReLU102
I0612 11:07:31.859361  5211 net.cpp:190] Creating Layer ReLU102
I0612 11:07:31.859366  5211 net.cpp:615] ReLU102 <- Convolution102
I0612 11:07:31.859372  5211 net.cpp:576] ReLU102 -> Convolution102 (in-place)
I0612 11:07:31.859380  5211 net.cpp:240] Setting up ReLU102
I0612 11:07:31.859385  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.859388  5211 net.cpp:255] Memory required for data: 2887254528
I0612 11:07:31.859392  5211 layer_factory.hpp:77] Creating layer Convolution103
I0612 11:07:31.859405  5211 net.cpp:190] Creating Layer Convolution103
I0612 11:07:31.859408  5211 net.cpp:615] Convolution103 <- Convolution102
I0612 11:07:31.859416  5211 net.cpp:589] Convolution103 -> Convolution103
I0612 11:07:31.861081  5211 net.cpp:240] Setting up Convolution103
I0612 11:07:31.861091  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.861095  5211 net.cpp:255] Memory required for data: 2889351680
I0612 11:07:31.861104  5211 layer_factory.hpp:77] Creating layer BatchNorm103
I0612 11:07:31.861114  5211 net.cpp:190] Creating Layer BatchNorm103
I0612 11:07:31.861119  5211 net.cpp:615] BatchNorm103 <- Convolution103
I0612 11:07:31.861124  5211 net.cpp:576] BatchNorm103 -> Convolution103 (in-place)
I0612 11:07:31.861340  5211 net.cpp:240] Setting up BatchNorm103
I0612 11:07:31.861347  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.861351  5211 net.cpp:255] Memory required for data: 2891448832
I0612 11:07:31.861362  5211 layer_factory.hpp:77] Creating layer Scale103
I0612 11:07:31.861371  5211 net.cpp:190] Creating Layer Scale103
I0612 11:07:31.861377  5211 net.cpp:615] Scale103 <- Convolution103
I0612 11:07:31.861382  5211 net.cpp:576] Scale103 -> Convolution103 (in-place)
I0612 11:07:31.861419  5211 layer_factory.hpp:77] Creating layer Scale103
I0612 11:07:31.861552  5211 net.cpp:240] Setting up Scale103
I0612 11:07:31.861560  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.861564  5211 net.cpp:255] Memory required for data: 2893545984
I0612 11:07:31.861573  5211 layer_factory.hpp:77] Creating layer Eltwise51
I0612 11:07:31.861583  5211 net.cpp:190] Creating Layer Eltwise51
I0612 11:07:31.861588  5211 net.cpp:615] Eltwise51 <- Eltwise50_ReLU101_0_split_1
I0612 11:07:31.861594  5211 net.cpp:615] Eltwise51 <- Convolution103
I0612 11:07:31.861599  5211 net.cpp:589] Eltwise51 -> Eltwise51
I0612 11:07:31.861623  5211 net.cpp:240] Setting up Eltwise51
I0612 11:07:31.861629  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.861632  5211 net.cpp:255] Memory required for data: 2895643136
I0612 11:07:31.861636  5211 layer_factory.hpp:77] Creating layer ReLU103
I0612 11:07:31.861642  5211 net.cpp:190] Creating Layer ReLU103
I0612 11:07:31.861646  5211 net.cpp:615] ReLU103 <- Eltwise51
I0612 11:07:31.861652  5211 net.cpp:576] ReLU103 -> Eltwise51 (in-place)
I0612 11:07:31.861659  5211 net.cpp:240] Setting up ReLU103
I0612 11:07:31.861665  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.861668  5211 net.cpp:255] Memory required for data: 2897740288
I0612 11:07:31.861671  5211 layer_factory.hpp:77] Creating layer Eltwise51_ReLU103_0_split
I0612 11:07:31.861677  5211 net.cpp:190] Creating Layer Eltwise51_ReLU103_0_split
I0612 11:07:31.861681  5211 net.cpp:615] Eltwise51_ReLU103_0_split <- Eltwise51
I0612 11:07:31.861690  5211 net.cpp:589] Eltwise51_ReLU103_0_split -> Eltwise51_ReLU103_0_split_0
I0612 11:07:31.861696  5211 net.cpp:589] Eltwise51_ReLU103_0_split -> Eltwise51_ReLU103_0_split_1
I0612 11:07:31.861735  5211 net.cpp:240] Setting up Eltwise51_ReLU103_0_split
I0612 11:07:31.861742  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.861750  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.861754  5211 net.cpp:255] Memory required for data: 2901934592
I0612 11:07:31.861758  5211 layer_factory.hpp:77] Creating layer Convolution104
I0612 11:07:31.861768  5211 net.cpp:190] Creating Layer Convolution104
I0612 11:07:31.861773  5211 net.cpp:615] Convolution104 <- Eltwise51_ReLU103_0_split_0
I0612 11:07:31.861779  5211 net.cpp:589] Convolution104 -> Convolution104
I0612 11:07:31.863456  5211 net.cpp:240] Setting up Convolution104
I0612 11:07:31.863466  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.863469  5211 net.cpp:255] Memory required for data: 2904031744
I0612 11:07:31.863479  5211 layer_factory.hpp:77] Creating layer BatchNorm104
I0612 11:07:31.863489  5211 net.cpp:190] Creating Layer BatchNorm104
I0612 11:07:31.863494  5211 net.cpp:615] BatchNorm104 <- Convolution104
I0612 11:07:31.863500  5211 net.cpp:576] BatchNorm104 -> Convolution104 (in-place)
I0612 11:07:31.863715  5211 net.cpp:240] Setting up BatchNorm104
I0612 11:07:31.863723  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.863728  5211 net.cpp:255] Memory required for data: 2906128896
I0612 11:07:31.863739  5211 layer_factory.hpp:77] Creating layer Scale104
I0612 11:07:31.863745  5211 net.cpp:190] Creating Layer Scale104
I0612 11:07:31.863750  5211 net.cpp:615] Scale104 <- Convolution104
I0612 11:07:31.863755  5211 net.cpp:576] Scale104 -> Convolution104 (in-place)
I0612 11:07:31.863797  5211 layer_factory.hpp:77] Creating layer Scale104
I0612 11:07:31.863924  5211 net.cpp:240] Setting up Scale104
I0612 11:07:31.863932  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.863936  5211 net.cpp:255] Memory required for data: 2908226048
I0612 11:07:31.863945  5211 layer_factory.hpp:77] Creating layer ReLU104
I0612 11:07:31.863952  5211 net.cpp:190] Creating Layer ReLU104
I0612 11:07:31.863956  5211 net.cpp:615] ReLU104 <- Convolution104
I0612 11:07:31.863962  5211 net.cpp:576] ReLU104 -> Convolution104 (in-place)
I0612 11:07:31.863970  5211 net.cpp:240] Setting up ReLU104
I0612 11:07:31.863975  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.863978  5211 net.cpp:255] Memory required for data: 2910323200
I0612 11:07:31.863981  5211 layer_factory.hpp:77] Creating layer Convolution105
I0612 11:07:31.863993  5211 net.cpp:190] Creating Layer Convolution105
I0612 11:07:31.863998  5211 net.cpp:615] Convolution105 <- Convolution104
I0612 11:07:31.864006  5211 net.cpp:589] Convolution105 -> Convolution105
I0612 11:07:31.865670  5211 net.cpp:240] Setting up Convolution105
I0612 11:07:31.865680  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.865684  5211 net.cpp:255] Memory required for data: 2912420352
I0612 11:07:31.865694  5211 layer_factory.hpp:77] Creating layer BatchNorm105
I0612 11:07:31.865703  5211 net.cpp:190] Creating Layer BatchNorm105
I0612 11:07:31.865708  5211 net.cpp:615] BatchNorm105 <- Convolution105
I0612 11:07:31.865715  5211 net.cpp:576] BatchNorm105 -> Convolution105 (in-place)
I0612 11:07:31.865927  5211 net.cpp:240] Setting up BatchNorm105
I0612 11:07:31.865934  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.865938  5211 net.cpp:255] Memory required for data: 2914517504
I0612 11:07:31.865952  5211 layer_factory.hpp:77] Creating layer Scale105
I0612 11:07:31.865958  5211 net.cpp:190] Creating Layer Scale105
I0612 11:07:31.865963  5211 net.cpp:615] Scale105 <- Convolution105
I0612 11:07:31.865968  5211 net.cpp:576] Scale105 -> Convolution105 (in-place)
I0612 11:07:31.866008  5211 layer_factory.hpp:77] Creating layer Scale105
I0612 11:07:31.866137  5211 net.cpp:240] Setting up Scale105
I0612 11:07:31.866144  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.866148  5211 net.cpp:255] Memory required for data: 2916614656
I0612 11:07:31.866161  5211 layer_factory.hpp:77] Creating layer Eltwise52
I0612 11:07:31.866169  5211 net.cpp:190] Creating Layer Eltwise52
I0612 11:07:31.866174  5211 net.cpp:615] Eltwise52 <- Eltwise51_ReLU103_0_split_1
I0612 11:07:31.866183  5211 net.cpp:615] Eltwise52 <- Convolution105
I0612 11:07:31.866190  5211 net.cpp:589] Eltwise52 -> Eltwise52
I0612 11:07:31.866211  5211 net.cpp:240] Setting up Eltwise52
I0612 11:07:31.866219  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.866222  5211 net.cpp:255] Memory required for data: 2918711808
I0612 11:07:31.866226  5211 layer_factory.hpp:77] Creating layer ReLU105
I0612 11:07:31.866232  5211 net.cpp:190] Creating Layer ReLU105
I0612 11:07:31.866236  5211 net.cpp:615] ReLU105 <- Eltwise52
I0612 11:07:31.866245  5211 net.cpp:576] ReLU105 -> Eltwise52 (in-place)
I0612 11:07:31.866251  5211 net.cpp:240] Setting up ReLU105
I0612 11:07:31.866256  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.866261  5211 net.cpp:255] Memory required for data: 2920808960
I0612 11:07:31.866264  5211 layer_factory.hpp:77] Creating layer Eltwise52_ReLU105_0_split
I0612 11:07:31.866271  5211 net.cpp:190] Creating Layer Eltwise52_ReLU105_0_split
I0612 11:07:31.866273  5211 net.cpp:615] Eltwise52_ReLU105_0_split <- Eltwise52
I0612 11:07:31.866279  5211 net.cpp:589] Eltwise52_ReLU105_0_split -> Eltwise52_ReLU105_0_split_0
I0612 11:07:31.866286  5211 net.cpp:589] Eltwise52_ReLU105_0_split -> Eltwise52_ReLU105_0_split_1
I0612 11:07:31.866327  5211 net.cpp:240] Setting up Eltwise52_ReLU105_0_split
I0612 11:07:31.866333  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.866338  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.866341  5211 net.cpp:255] Memory required for data: 2925003264
I0612 11:07:31.866345  5211 layer_factory.hpp:77] Creating layer Convolution106
I0612 11:07:31.866364  5211 net.cpp:190] Creating Layer Convolution106
I0612 11:07:31.866369  5211 net.cpp:615] Convolution106 <- Eltwise52_ReLU105_0_split_0
I0612 11:07:31.866377  5211 net.cpp:589] Convolution106 -> Convolution106
I0612 11:07:31.868047  5211 net.cpp:240] Setting up Convolution106
I0612 11:07:31.868057  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.868060  5211 net.cpp:255] Memory required for data: 2927100416
I0612 11:07:31.868069  5211 layer_factory.hpp:77] Creating layer BatchNorm106
I0612 11:07:31.868080  5211 net.cpp:190] Creating Layer BatchNorm106
I0612 11:07:31.868085  5211 net.cpp:615] BatchNorm106 <- Convolution106
I0612 11:07:31.868091  5211 net.cpp:576] BatchNorm106 -> Convolution106 (in-place)
I0612 11:07:31.868309  5211 net.cpp:240] Setting up BatchNorm106
I0612 11:07:31.868315  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.868319  5211 net.cpp:255] Memory required for data: 2929197568
I0612 11:07:31.868330  5211 layer_factory.hpp:77] Creating layer Scale106
I0612 11:07:31.868340  5211 net.cpp:190] Creating Layer Scale106
I0612 11:07:31.868345  5211 net.cpp:615] Scale106 <- Convolution106
I0612 11:07:31.868350  5211 net.cpp:576] Scale106 -> Convolution106 (in-place)
I0612 11:07:31.868387  5211 layer_factory.hpp:77] Creating layer Scale106
I0612 11:07:31.868523  5211 net.cpp:240] Setting up Scale106
I0612 11:07:31.868531  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.868535  5211 net.cpp:255] Memory required for data: 2931294720
I0612 11:07:31.868544  5211 layer_factory.hpp:77] Creating layer ReLU106
I0612 11:07:31.868553  5211 net.cpp:190] Creating Layer ReLU106
I0612 11:07:31.868557  5211 net.cpp:615] ReLU106 <- Convolution106
I0612 11:07:31.868563  5211 net.cpp:576] ReLU106 -> Convolution106 (in-place)
I0612 11:07:31.868571  5211 net.cpp:240] Setting up ReLU106
I0612 11:07:31.868576  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.868579  5211 net.cpp:255] Memory required for data: 2933391872
I0612 11:07:31.868583  5211 layer_factory.hpp:77] Creating layer Convolution107
I0612 11:07:31.868595  5211 net.cpp:190] Creating Layer Convolution107
I0612 11:07:31.868599  5211 net.cpp:615] Convolution107 <- Convolution106
I0612 11:07:31.868605  5211 net.cpp:589] Convolution107 -> Convolution107
I0612 11:07:31.870270  5211 net.cpp:240] Setting up Convolution107
I0612 11:07:31.870280  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.870285  5211 net.cpp:255] Memory required for data: 2935489024
I0612 11:07:31.870296  5211 layer_factory.hpp:77] Creating layer BatchNorm107
I0612 11:07:31.870304  5211 net.cpp:190] Creating Layer BatchNorm107
I0612 11:07:31.870309  5211 net.cpp:615] BatchNorm107 <- Convolution107
I0612 11:07:31.870316  5211 net.cpp:576] BatchNorm107 -> Convolution107 (in-place)
I0612 11:07:31.870538  5211 net.cpp:240] Setting up BatchNorm107
I0612 11:07:31.870546  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.870550  5211 net.cpp:255] Memory required for data: 2937586176
I0612 11:07:31.870563  5211 layer_factory.hpp:77] Creating layer Scale107
I0612 11:07:31.870570  5211 net.cpp:190] Creating Layer Scale107
I0612 11:07:31.870574  5211 net.cpp:615] Scale107 <- Convolution107
I0612 11:07:31.870580  5211 net.cpp:576] Scale107 -> Convolution107 (in-place)
I0612 11:07:31.870623  5211 layer_factory.hpp:77] Creating layer Scale107
I0612 11:07:31.870750  5211 net.cpp:240] Setting up Scale107
I0612 11:07:31.870759  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.870761  5211 net.cpp:255] Memory required for data: 2939683328
I0612 11:07:31.870770  5211 layer_factory.hpp:77] Creating layer Eltwise53
I0612 11:07:31.870779  5211 net.cpp:190] Creating Layer Eltwise53
I0612 11:07:31.870784  5211 net.cpp:615] Eltwise53 <- Eltwise52_ReLU105_0_split_1
I0612 11:07:31.870790  5211 net.cpp:615] Eltwise53 <- Convolution107
I0612 11:07:31.870796  5211 net.cpp:589] Eltwise53 -> Eltwise53
I0612 11:07:31.870818  5211 net.cpp:240] Setting up Eltwise53
I0612 11:07:31.870826  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.870829  5211 net.cpp:255] Memory required for data: 2941780480
I0612 11:07:31.870833  5211 layer_factory.hpp:77] Creating layer ReLU107
I0612 11:07:31.870839  5211 net.cpp:190] Creating Layer ReLU107
I0612 11:07:31.870843  5211 net.cpp:615] ReLU107 <- Eltwise53
I0612 11:07:31.870851  5211 net.cpp:576] ReLU107 -> Eltwise53 (in-place)
I0612 11:07:31.870857  5211 net.cpp:240] Setting up ReLU107
I0612 11:07:31.870862  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.870867  5211 net.cpp:255] Memory required for data: 2943877632
I0612 11:07:31.870870  5211 layer_factory.hpp:77] Creating layer Eltwise53_ReLU107_0_split
I0612 11:07:31.870877  5211 net.cpp:190] Creating Layer Eltwise53_ReLU107_0_split
I0612 11:07:31.870879  5211 net.cpp:615] Eltwise53_ReLU107_0_split <- Eltwise53
I0612 11:07:31.870885  5211 net.cpp:589] Eltwise53_ReLU107_0_split -> Eltwise53_ReLU107_0_split_0
I0612 11:07:31.870893  5211 net.cpp:589] Eltwise53_ReLU107_0_split -> Eltwise53_ReLU107_0_split_1
I0612 11:07:31.870932  5211 net.cpp:240] Setting up Eltwise53_ReLU107_0_split
I0612 11:07:31.870939  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.870944  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.870947  5211 net.cpp:255] Memory required for data: 2948071936
I0612 11:07:31.870951  5211 layer_factory.hpp:77] Creating layer Convolution108
I0612 11:07:31.870962  5211 net.cpp:190] Creating Layer Convolution108
I0612 11:07:31.870967  5211 net.cpp:615] Convolution108 <- Eltwise53_ReLU107_0_split_0
I0612 11:07:31.870975  5211 net.cpp:589] Convolution108 -> Convolution108
I0612 11:07:31.872648  5211 net.cpp:240] Setting up Convolution108
I0612 11:07:31.872658  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.872661  5211 net.cpp:255] Memory required for data: 2950169088
I0612 11:07:31.872670  5211 layer_factory.hpp:77] Creating layer BatchNorm108
I0612 11:07:31.872679  5211 net.cpp:190] Creating Layer BatchNorm108
I0612 11:07:31.872684  5211 net.cpp:615] BatchNorm108 <- Convolution108
I0612 11:07:31.872692  5211 net.cpp:576] BatchNorm108 -> Convolution108 (in-place)
I0612 11:07:31.872906  5211 net.cpp:240] Setting up BatchNorm108
I0612 11:07:31.872915  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.872917  5211 net.cpp:255] Memory required for data: 2952266240
I0612 11:07:31.872931  5211 layer_factory.hpp:77] Creating layer Scale108
I0612 11:07:31.872941  5211 net.cpp:190] Creating Layer Scale108
I0612 11:07:31.872946  5211 net.cpp:615] Scale108 <- Convolution108
I0612 11:07:31.872951  5211 net.cpp:576] Scale108 -> Convolution108 (in-place)
I0612 11:07:31.872992  5211 layer_factory.hpp:77] Creating layer Scale108
I0612 11:07:31.873121  5211 net.cpp:240] Setting up Scale108
I0612 11:07:31.873129  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.873133  5211 net.cpp:255] Memory required for data: 2954363392
I0612 11:07:31.873144  5211 layer_factory.hpp:77] Creating layer ReLU108
I0612 11:07:31.873150  5211 net.cpp:190] Creating Layer ReLU108
I0612 11:07:31.873155  5211 net.cpp:615] ReLU108 <- Convolution108
I0612 11:07:31.873162  5211 net.cpp:576] ReLU108 -> Convolution108 (in-place)
I0612 11:07:31.873169  5211 net.cpp:240] Setting up ReLU108
I0612 11:07:31.873175  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.873179  5211 net.cpp:255] Memory required for data: 2956460544
I0612 11:07:31.873183  5211 layer_factory.hpp:77] Creating layer Convolution109
I0612 11:07:31.873193  5211 net.cpp:190] Creating Layer Convolution109
I0612 11:07:31.873196  5211 net.cpp:615] Convolution109 <- Convolution108
I0612 11:07:31.873204  5211 net.cpp:589] Convolution109 -> Convolution109
I0612 11:07:31.875486  5211 net.cpp:240] Setting up Convolution109
I0612 11:07:31.875500  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.875504  5211 net.cpp:255] Memory required for data: 2958557696
I0612 11:07:31.875515  5211 layer_factory.hpp:77] Creating layer BatchNorm109
I0612 11:07:31.875525  5211 net.cpp:190] Creating Layer BatchNorm109
I0612 11:07:31.875530  5211 net.cpp:615] BatchNorm109 <- Convolution109
I0612 11:07:31.875540  5211 net.cpp:576] BatchNorm109 -> Convolution109 (in-place)
I0612 11:07:31.875761  5211 net.cpp:240] Setting up BatchNorm109
I0612 11:07:31.875769  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.875773  5211 net.cpp:255] Memory required for data: 2960654848
I0612 11:07:31.875788  5211 layer_factory.hpp:77] Creating layer Scale109
I0612 11:07:31.875795  5211 net.cpp:190] Creating Layer Scale109
I0612 11:07:31.875800  5211 net.cpp:615] Scale109 <- Convolution109
I0612 11:07:31.875807  5211 net.cpp:576] Scale109 -> Convolution109 (in-place)
I0612 11:07:31.875849  5211 layer_factory.hpp:77] Creating layer Scale109
I0612 11:07:31.875983  5211 net.cpp:240] Setting up Scale109
I0612 11:07:31.875991  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.875995  5211 net.cpp:255] Memory required for data: 2962752000
I0612 11:07:31.876004  5211 layer_factory.hpp:77] Creating layer Eltwise54
I0612 11:07:31.876013  5211 net.cpp:190] Creating Layer Eltwise54
I0612 11:07:31.876018  5211 net.cpp:615] Eltwise54 <- Eltwise53_ReLU107_0_split_1
I0612 11:07:31.876022  5211 net.cpp:615] Eltwise54 <- Convolution109
I0612 11:07:31.876031  5211 net.cpp:589] Eltwise54 -> Eltwise54
I0612 11:07:31.876052  5211 net.cpp:240] Setting up Eltwise54
I0612 11:07:31.876060  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.876062  5211 net.cpp:255] Memory required for data: 2964849152
I0612 11:07:31.876066  5211 layer_factory.hpp:77] Creating layer ReLU109
I0612 11:07:31.876075  5211 net.cpp:190] Creating Layer ReLU109
I0612 11:07:31.876080  5211 net.cpp:615] ReLU109 <- Eltwise54
I0612 11:07:31.876085  5211 net.cpp:576] ReLU109 -> Eltwise54 (in-place)
I0612 11:07:31.876091  5211 net.cpp:240] Setting up ReLU109
I0612 11:07:31.876096  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:31.876101  5211 net.cpp:255] Memory required for data: 2966946304
I0612 11:07:31.876104  5211 layer_factory.hpp:77] Creating layer Pooling4
I0612 11:07:31.876111  5211 net.cpp:190] Creating Layer Pooling4
I0612 11:07:31.876116  5211 net.cpp:615] Pooling4 <- Eltwise54
I0612 11:07:31.876121  5211 net.cpp:589] Pooling4 -> Pooling4
I0612 11:07:31.876147  5211 net.cpp:240] Setting up Pooling4
I0612 11:07:31.876153  5211 net.cpp:247] Top shape: 128 64 1 1 (8192)
I0612 11:07:31.876157  5211 net.cpp:255] Memory required for data: 2966979072
I0612 11:07:31.876164  5211 layer_factory.hpp:77] Creating layer InnerProduct1
I0612 11:07:31.876175  5211 net.cpp:190] Creating Layer InnerProduct1
I0612 11:07:31.876179  5211 net.cpp:615] InnerProduct1 <- Pooling4
I0612 11:07:31.876186  5211 net.cpp:589] InnerProduct1 -> InnerProduct1
I0612 11:07:31.876343  5211 net.cpp:240] Setting up InnerProduct1
I0612 11:07:31.876351  5211 net.cpp:247] Top shape: 128 10 (1280)
I0612 11:07:31.876355  5211 net.cpp:255] Memory required for data: 2966984192
I0612 11:07:31.876365  5211 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0612 11:07:31.876375  5211 net.cpp:190] Creating Layer SoftmaxWithLoss1
I0612 11:07:31.876380  5211 net.cpp:615] SoftmaxWithLoss1 <- InnerProduct1
I0612 11:07:31.876385  5211 net.cpp:615] SoftmaxWithLoss1 <- Data2
I0612 11:07:31.876395  5211 net.cpp:589] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0612 11:07:31.876408  5211 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0612 11:07:31.876513  5211 net.cpp:240] Setting up SoftmaxWithLoss1
I0612 11:07:31.876520  5211 net.cpp:247] Top shape: (1)
I0612 11:07:31.876524  5211 net.cpp:250]     with loss weight 1
I0612 11:07:31.876545  5211 net.cpp:255] Memory required for data: 2966984196
I0612 11:07:31.876549  5211 net.cpp:316] SoftmaxWithLoss1 needs backward computation.
I0612 11:07:31.876554  5211 net.cpp:316] InnerProduct1 needs backward computation.
I0612 11:07:31.876559  5211 net.cpp:316] Pooling4 needs backward computation.
I0612 11:07:31.876562  5211 net.cpp:316] ReLU109 needs backward computation.
I0612 11:07:31.876565  5211 net.cpp:316] Eltwise54 needs backward computation.
I0612 11:07:31.876570  5211 net.cpp:316] Scale109 needs backward computation.
I0612 11:07:31.876574  5211 net.cpp:316] BatchNorm109 needs backward computation.
I0612 11:07:31.876577  5211 net.cpp:316] Convolution109 needs backward computation.
I0612 11:07:31.876581  5211 net.cpp:316] ReLU108 needs backward computation.
I0612 11:07:31.876585  5211 net.cpp:316] Scale108 needs backward computation.
I0612 11:07:31.876590  5211 net.cpp:316] BatchNorm108 needs backward computation.
I0612 11:07:31.876592  5211 net.cpp:316] Convolution108 needs backward computation.
I0612 11:07:31.876596  5211 net.cpp:316] Eltwise53_ReLU107_0_split needs backward computation.
I0612 11:07:31.876600  5211 net.cpp:316] ReLU107 needs backward computation.
I0612 11:07:31.876605  5211 net.cpp:316] Eltwise53 needs backward computation.
I0612 11:07:31.876610  5211 net.cpp:316] Scale107 needs backward computation.
I0612 11:07:31.876613  5211 net.cpp:316] BatchNorm107 needs backward computation.
I0612 11:07:31.876616  5211 net.cpp:316] Convolution107 needs backward computation.
I0612 11:07:31.876621  5211 net.cpp:316] ReLU106 needs backward computation.
I0612 11:07:31.876624  5211 net.cpp:316] Scale106 needs backward computation.
I0612 11:07:31.876627  5211 net.cpp:316] BatchNorm106 needs backward computation.
I0612 11:07:31.876631  5211 net.cpp:316] Convolution106 needs backward computation.
I0612 11:07:31.876636  5211 net.cpp:316] Eltwise52_ReLU105_0_split needs backward computation.
I0612 11:07:31.876639  5211 net.cpp:316] ReLU105 needs backward computation.
I0612 11:07:31.876642  5211 net.cpp:316] Eltwise52 needs backward computation.
I0612 11:07:31.876647  5211 net.cpp:316] Scale105 needs backward computation.
I0612 11:07:31.876652  5211 net.cpp:316] BatchNorm105 needs backward computation.
I0612 11:07:31.876654  5211 net.cpp:316] Convolution105 needs backward computation.
I0612 11:07:31.876658  5211 net.cpp:316] ReLU104 needs backward computation.
I0612 11:07:31.876662  5211 net.cpp:316] Scale104 needs backward computation.
I0612 11:07:31.876665  5211 net.cpp:316] BatchNorm104 needs backward computation.
I0612 11:07:31.876669  5211 net.cpp:316] Convolution104 needs backward computation.
I0612 11:07:31.876673  5211 net.cpp:316] Eltwise51_ReLU103_0_split needs backward computation.
I0612 11:07:31.876677  5211 net.cpp:316] ReLU103 needs backward computation.
I0612 11:07:31.876680  5211 net.cpp:316] Eltwise51 needs backward computation.
I0612 11:07:31.876688  5211 net.cpp:316] Scale103 needs backward computation.
I0612 11:07:31.876691  5211 net.cpp:316] BatchNorm103 needs backward computation.
I0612 11:07:31.876695  5211 net.cpp:316] Convolution103 needs backward computation.
I0612 11:07:31.876699  5211 net.cpp:316] ReLU102 needs backward computation.
I0612 11:07:31.876703  5211 net.cpp:316] Scale102 needs backward computation.
I0612 11:07:31.876706  5211 net.cpp:316] BatchNorm102 needs backward computation.
I0612 11:07:31.876709  5211 net.cpp:316] Convolution102 needs backward computation.
I0612 11:07:31.876713  5211 net.cpp:316] Eltwise50_ReLU101_0_split needs backward computation.
I0612 11:07:31.876718  5211 net.cpp:316] ReLU101 needs backward computation.
I0612 11:07:31.876721  5211 net.cpp:316] Eltwise50 needs backward computation.
I0612 11:07:31.876726  5211 net.cpp:316] Scale101 needs backward computation.
I0612 11:07:31.876729  5211 net.cpp:316] BatchNorm101 needs backward computation.
I0612 11:07:31.876734  5211 net.cpp:316] Convolution101 needs backward computation.
I0612 11:07:31.876736  5211 net.cpp:316] ReLU100 needs backward computation.
I0612 11:07:31.876740  5211 net.cpp:316] Scale100 needs backward computation.
I0612 11:07:31.876744  5211 net.cpp:316] BatchNorm100 needs backward computation.
I0612 11:07:31.876747  5211 net.cpp:316] Convolution100 needs backward computation.
I0612 11:07:31.876751  5211 net.cpp:316] Eltwise49_ReLU99_0_split needs backward computation.
I0612 11:07:31.876755  5211 net.cpp:316] ReLU99 needs backward computation.
I0612 11:07:31.876760  5211 net.cpp:316] Eltwise49 needs backward computation.
I0612 11:07:31.876765  5211 net.cpp:316] Scale99 needs backward computation.
I0612 11:07:31.876768  5211 net.cpp:316] BatchNorm99 needs backward computation.
I0612 11:07:31.876771  5211 net.cpp:316] Convolution99 needs backward computation.
I0612 11:07:31.876775  5211 net.cpp:316] ReLU98 needs backward computation.
I0612 11:07:31.876780  5211 net.cpp:316] Scale98 needs backward computation.
I0612 11:07:31.876783  5211 net.cpp:316] BatchNorm98 needs backward computation.
I0612 11:07:31.876786  5211 net.cpp:316] Convolution98 needs backward computation.
I0612 11:07:31.876791  5211 net.cpp:316] Eltwise48_ReLU97_0_split needs backward computation.
I0612 11:07:31.876794  5211 net.cpp:316] ReLU97 needs backward computation.
I0612 11:07:31.876798  5211 net.cpp:316] Eltwise48 needs backward computation.
I0612 11:07:31.876803  5211 net.cpp:316] Scale97 needs backward computation.
I0612 11:07:31.876806  5211 net.cpp:316] BatchNorm97 needs backward computation.
I0612 11:07:31.876811  5211 net.cpp:316] Convolution97 needs backward computation.
I0612 11:07:31.876814  5211 net.cpp:316] ReLU96 needs backward computation.
I0612 11:07:31.876817  5211 net.cpp:316] Scale96 needs backward computation.
I0612 11:07:31.876821  5211 net.cpp:316] BatchNorm96 needs backward computation.
I0612 11:07:31.876824  5211 net.cpp:316] Convolution96 needs backward computation.
I0612 11:07:31.876828  5211 net.cpp:316] Eltwise47_ReLU95_0_split needs backward computation.
I0612 11:07:31.876832  5211 net.cpp:316] ReLU95 needs backward computation.
I0612 11:07:31.876837  5211 net.cpp:316] Eltwise47 needs backward computation.
I0612 11:07:31.876840  5211 net.cpp:316] Scale95 needs backward computation.
I0612 11:07:31.876844  5211 net.cpp:316] BatchNorm95 needs backward computation.
I0612 11:07:31.876847  5211 net.cpp:316] Convolution95 needs backward computation.
I0612 11:07:31.876852  5211 net.cpp:316] ReLU94 needs backward computation.
I0612 11:07:31.876855  5211 net.cpp:316] Scale94 needs backward computation.
I0612 11:07:31.876858  5211 net.cpp:316] BatchNorm94 needs backward computation.
I0612 11:07:31.876863  5211 net.cpp:316] Convolution94 needs backward computation.
I0612 11:07:31.876866  5211 net.cpp:316] Eltwise46_ReLU93_0_split needs backward computation.
I0612 11:07:31.876870  5211 net.cpp:316] ReLU93 needs backward computation.
I0612 11:07:31.876874  5211 net.cpp:316] Eltwise46 needs backward computation.
I0612 11:07:31.876878  5211 net.cpp:316] Scale93 needs backward computation.
I0612 11:07:31.876883  5211 net.cpp:316] BatchNorm93 needs backward computation.
I0612 11:07:31.876888  5211 net.cpp:316] Convolution93 needs backward computation.
I0612 11:07:31.876891  5211 net.cpp:316] ReLU92 needs backward computation.
I0612 11:07:31.876894  5211 net.cpp:316] Scale92 needs backward computation.
I0612 11:07:31.876899  5211 net.cpp:316] BatchNorm92 needs backward computation.
I0612 11:07:31.876902  5211 net.cpp:316] Convolution92 needs backward computation.
I0612 11:07:31.876905  5211 net.cpp:316] Eltwise45_ReLU91_0_split needs backward computation.
I0612 11:07:31.876909  5211 net.cpp:316] ReLU91 needs backward computation.
I0612 11:07:31.876914  5211 net.cpp:316] Eltwise45 needs backward computation.
I0612 11:07:31.876917  5211 net.cpp:316] Scale91 needs backward computation.
I0612 11:07:31.876921  5211 net.cpp:316] BatchNorm91 needs backward computation.
I0612 11:07:31.876925  5211 net.cpp:316] Convolution91 needs backward computation.
I0612 11:07:31.876929  5211 net.cpp:316] ReLU90 needs backward computation.
I0612 11:07:31.876932  5211 net.cpp:316] Scale90 needs backward computation.
I0612 11:07:31.876935  5211 net.cpp:316] BatchNorm90 needs backward computation.
I0612 11:07:31.876940  5211 net.cpp:316] Convolution90 needs backward computation.
I0612 11:07:31.876943  5211 net.cpp:316] Eltwise44_ReLU89_0_split needs backward computation.
I0612 11:07:31.876947  5211 net.cpp:316] ReLU89 needs backward computation.
I0612 11:07:31.876950  5211 net.cpp:316] Eltwise44 needs backward computation.
I0612 11:07:31.876957  5211 net.cpp:316] Scale89 needs backward computation.
I0612 11:07:31.876961  5211 net.cpp:316] BatchNorm89 needs backward computation.
I0612 11:07:31.876965  5211 net.cpp:316] Convolution89 needs backward computation.
I0612 11:07:31.876970  5211 net.cpp:316] ReLU88 needs backward computation.
I0612 11:07:31.876973  5211 net.cpp:316] Scale88 needs backward computation.
I0612 11:07:31.876976  5211 net.cpp:316] BatchNorm88 needs backward computation.
I0612 11:07:31.876981  5211 net.cpp:316] Convolution88 needs backward computation.
I0612 11:07:31.876984  5211 net.cpp:316] Eltwise43_ReLU87_0_split needs backward computation.
I0612 11:07:31.876988  5211 net.cpp:316] ReLU87 needs backward computation.
I0612 11:07:31.876991  5211 net.cpp:316] Eltwise43 needs backward computation.
I0612 11:07:31.876996  5211 net.cpp:316] Scale87 needs backward computation.
I0612 11:07:31.876999  5211 net.cpp:316] BatchNorm87 needs backward computation.
I0612 11:07:31.877003  5211 net.cpp:316] Convolution87 needs backward computation.
I0612 11:07:31.877007  5211 net.cpp:316] ReLU86 needs backward computation.
I0612 11:07:31.877010  5211 net.cpp:316] Scale86 needs backward computation.
I0612 11:07:31.877014  5211 net.cpp:316] BatchNorm86 needs backward computation.
I0612 11:07:31.877017  5211 net.cpp:316] Convolution86 needs backward computation.
I0612 11:07:31.877022  5211 net.cpp:316] Eltwise42_ReLU85_0_split needs backward computation.
I0612 11:07:31.877025  5211 net.cpp:316] ReLU85 needs backward computation.
I0612 11:07:31.877029  5211 net.cpp:316] Eltwise42 needs backward computation.
I0612 11:07:31.877033  5211 net.cpp:316] Scale85 needs backward computation.
I0612 11:07:31.877038  5211 net.cpp:316] BatchNorm85 needs backward computation.
I0612 11:07:31.877041  5211 net.cpp:316] Convolution85 needs backward computation.
I0612 11:07:31.877044  5211 net.cpp:316] ReLU84 needs backward computation.
I0612 11:07:31.877048  5211 net.cpp:316] Scale84 needs backward computation.
I0612 11:07:31.877053  5211 net.cpp:316] BatchNorm84 needs backward computation.
I0612 11:07:31.877055  5211 net.cpp:316] Convolution84 needs backward computation.
I0612 11:07:31.877059  5211 net.cpp:316] Eltwise41_ReLU83_0_split needs backward computation.
I0612 11:07:31.877063  5211 net.cpp:316] ReLU83 needs backward computation.
I0612 11:07:31.877068  5211 net.cpp:316] Eltwise41 needs backward computation.
I0612 11:07:31.877071  5211 net.cpp:316] Scale83 needs backward computation.
I0612 11:07:31.877074  5211 net.cpp:316] BatchNorm83 needs backward computation.
I0612 11:07:31.877080  5211 net.cpp:316] Convolution83 needs backward computation.
I0612 11:07:31.877084  5211 net.cpp:316] ReLU82 needs backward computation.
I0612 11:07:31.877089  5211 net.cpp:316] Scale82 needs backward computation.
I0612 11:07:31.877091  5211 net.cpp:316] BatchNorm82 needs backward computation.
I0612 11:07:31.877095  5211 net.cpp:316] Convolution82 needs backward computation.
I0612 11:07:31.877099  5211 net.cpp:316] Eltwise40_ReLU81_0_split needs backward computation.
I0612 11:07:31.877104  5211 net.cpp:316] ReLU81 needs backward computation.
I0612 11:07:31.877106  5211 net.cpp:316] Eltwise40 needs backward computation.
I0612 11:07:31.877111  5211 net.cpp:316] Scale81 needs backward computation.
I0612 11:07:31.877115  5211 net.cpp:316] BatchNorm81 needs backward computation.
I0612 11:07:31.877118  5211 net.cpp:316] Convolution81 needs backward computation.
I0612 11:07:31.877122  5211 net.cpp:316] ReLU80 needs backward computation.
I0612 11:07:31.877125  5211 net.cpp:316] Scale80 needs backward computation.
I0612 11:07:31.877130  5211 net.cpp:316] BatchNorm80 needs backward computation.
I0612 11:07:31.877133  5211 net.cpp:316] Convolution80 needs backward computation.
I0612 11:07:31.877137  5211 net.cpp:316] Eltwise39_ReLU79_0_split needs backward computation.
I0612 11:07:31.877141  5211 net.cpp:316] ReLU79 needs backward computation.
I0612 11:07:31.877145  5211 net.cpp:316] Eltwise39 needs backward computation.
I0612 11:07:31.877149  5211 net.cpp:316] Scale79 needs backward computation.
I0612 11:07:31.877153  5211 net.cpp:316] BatchNorm79 needs backward computation.
I0612 11:07:31.877157  5211 net.cpp:316] Convolution79 needs backward computation.
I0612 11:07:31.877161  5211 net.cpp:316] ReLU78 needs backward computation.
I0612 11:07:31.877164  5211 net.cpp:316] Scale78 needs backward computation.
I0612 11:07:31.877168  5211 net.cpp:316] BatchNorm78 needs backward computation.
I0612 11:07:31.877171  5211 net.cpp:316] Convolution78 needs backward computation.
I0612 11:07:31.877177  5211 net.cpp:316] Eltwise38_ReLU77_0_split needs backward computation.
I0612 11:07:31.877180  5211 net.cpp:316] ReLU77 needs backward computation.
I0612 11:07:31.877184  5211 net.cpp:316] Eltwise38 needs backward computation.
I0612 11:07:31.877188  5211 net.cpp:316] Scale77 needs backward computation.
I0612 11:07:31.877192  5211 net.cpp:316] BatchNorm77 needs backward computation.
I0612 11:07:31.877197  5211 net.cpp:316] Convolution77 needs backward computation.
I0612 11:07:31.877199  5211 net.cpp:316] ReLU76 needs backward computation.
I0612 11:07:31.877203  5211 net.cpp:316] Scale76 needs backward computation.
I0612 11:07:31.877207  5211 net.cpp:316] BatchNorm76 needs backward computation.
I0612 11:07:31.877210  5211 net.cpp:316] Convolution76 needs backward computation.
I0612 11:07:31.877215  5211 net.cpp:316] Eltwise37_ReLU75_0_split needs backward computation.
I0612 11:07:31.877219  5211 net.cpp:316] ReLU75 needs backward computation.
I0612 11:07:31.877223  5211 net.cpp:316] Eltwise37 needs backward computation.
I0612 11:07:31.877228  5211 net.cpp:316] Scale75 needs backward computation.
I0612 11:07:31.877230  5211 net.cpp:316] BatchNorm75 needs backward computation.
I0612 11:07:31.877234  5211 net.cpp:316] Convolution75 needs backward computation.
I0612 11:07:31.877238  5211 net.cpp:316] ReLU74 needs backward computation.
I0612 11:07:31.877243  5211 net.cpp:316] Scale74 needs backward computation.
I0612 11:07:31.877246  5211 net.cpp:316] BatchNorm74 needs backward computation.
I0612 11:07:31.877249  5211 net.cpp:316] Convolution74 needs backward computation.
I0612 11:07:31.877254  5211 net.cpp:316] Concat2 needs backward computation.
I0612 11:07:31.877259  5211 net.cpp:318] Input2 does not need backward computation.
I0612 11:07:31.877264  5211 net.cpp:316] Pooling2 needs backward computation.
I0612 11:07:31.877267  5211 net.cpp:316] Eltwise36_ReLU73_0_split needs backward computation.
I0612 11:07:31.877271  5211 net.cpp:316] ReLU73 needs backward computation.
I0612 11:07:31.877277  5211 net.cpp:316] Eltwise36 needs backward computation.
I0612 11:07:31.877282  5211 net.cpp:316] Scale73 needs backward computation.
I0612 11:07:31.877285  5211 net.cpp:316] BatchNorm73 needs backward computation.
I0612 11:07:31.877290  5211 net.cpp:316] Convolution73 needs backward computation.
I0612 11:07:31.877293  5211 net.cpp:316] ReLU72 needs backward computation.
I0612 11:07:31.877296  5211 net.cpp:316] Scale72 needs backward computation.
I0612 11:07:31.877300  5211 net.cpp:316] BatchNorm72 needs backward computation.
I0612 11:07:31.877305  5211 net.cpp:316] Convolution72 needs backward computation.
I0612 11:07:31.877308  5211 net.cpp:316] Eltwise35_ReLU71_0_split needs backward computation.
I0612 11:07:31.877312  5211 net.cpp:316] ReLU71 needs backward computation.
I0612 11:07:31.877316  5211 net.cpp:316] Eltwise35 needs backward computation.
I0612 11:07:31.877321  5211 net.cpp:316] Scale71 needs backward computation.
I0612 11:07:31.877324  5211 net.cpp:316] BatchNorm71 needs backward computation.
I0612 11:07:31.877327  5211 net.cpp:316] Convolution71 needs backward computation.
I0612 11:07:31.877331  5211 net.cpp:316] ReLU70 needs backward computation.
I0612 11:07:31.877336  5211 net.cpp:316] Scale70 needs backward computation.
I0612 11:07:31.877339  5211 net.cpp:316] BatchNorm70 needs backward computation.
I0612 11:07:31.877342  5211 net.cpp:316] Convolution70 needs backward computation.
I0612 11:07:31.877347  5211 net.cpp:316] Eltwise34_ReLU69_0_split needs backward computation.
I0612 11:07:31.877351  5211 net.cpp:316] ReLU69 needs backward computation.
I0612 11:07:31.877354  5211 net.cpp:316] Eltwise34 needs backward computation.
I0612 11:07:31.877358  5211 net.cpp:316] Scale69 needs backward computation.
I0612 11:07:31.877362  5211 net.cpp:316] BatchNorm69 needs backward computation.
I0612 11:07:31.877367  5211 net.cpp:316] Convolution69 needs backward computation.
I0612 11:07:31.877370  5211 net.cpp:316] ReLU68 needs backward computation.
I0612 11:07:31.877374  5211 net.cpp:316] Scale68 needs backward computation.
I0612 11:07:31.877377  5211 net.cpp:316] BatchNorm68 needs backward computation.
I0612 11:07:31.877382  5211 net.cpp:316] Convolution68 needs backward computation.
I0612 11:07:31.877385  5211 net.cpp:316] Eltwise33_ReLU67_0_split needs backward computation.
I0612 11:07:31.877389  5211 net.cpp:316] ReLU67 needs backward computation.
I0612 11:07:31.877393  5211 net.cpp:316] Eltwise33 needs backward computation.
I0612 11:07:31.877398  5211 net.cpp:316] Scale67 needs backward computation.
I0612 11:07:31.877400  5211 net.cpp:316] BatchNorm67 needs backward computation.
I0612 11:07:31.877404  5211 net.cpp:316] Convolution67 needs backward computation.
I0612 11:07:31.877408  5211 net.cpp:316] ReLU66 needs backward computation.
I0612 11:07:31.877413  5211 net.cpp:316] Scale66 needs backward computation.
I0612 11:07:31.877415  5211 net.cpp:316] BatchNorm66 needs backward computation.
I0612 11:07:31.877419  5211 net.cpp:316] Convolution66 needs backward computation.
I0612 11:07:31.877424  5211 net.cpp:316] Eltwise32_ReLU65_0_split needs backward computation.
I0612 11:07:31.877427  5211 net.cpp:316] ReLU65 needs backward computation.
I0612 11:07:31.877431  5211 net.cpp:316] Eltwise32 needs backward computation.
I0612 11:07:31.877435  5211 net.cpp:316] Scale65 needs backward computation.
I0612 11:07:31.877439  5211 net.cpp:316] BatchNorm65 needs backward computation.
I0612 11:07:31.877444  5211 net.cpp:316] Convolution65 needs backward computation.
I0612 11:07:31.877446  5211 net.cpp:316] ReLU64 needs backward computation.
I0612 11:07:31.877450  5211 net.cpp:316] Scale64 needs backward computation.
I0612 11:07:31.877454  5211 net.cpp:316] BatchNorm64 needs backward computation.
I0612 11:07:31.877459  5211 net.cpp:316] Convolution64 needs backward computation.
I0612 11:07:31.877462  5211 net.cpp:316] Eltwise31_ReLU63_0_split needs backward computation.
I0612 11:07:31.877466  5211 net.cpp:316] ReLU63 needs backward computation.
I0612 11:07:31.877470  5211 net.cpp:316] Eltwise31 needs backward computation.
I0612 11:07:31.877476  5211 net.cpp:316] Scale63 needs backward computation.
I0612 11:07:31.877480  5211 net.cpp:316] BatchNorm63 needs backward computation.
I0612 11:07:31.877485  5211 net.cpp:316] Convolution63 needs backward computation.
I0612 11:07:31.877488  5211 net.cpp:316] ReLU62 needs backward computation.
I0612 11:07:31.877492  5211 net.cpp:316] Scale62 needs backward computation.
I0612 11:07:31.877496  5211 net.cpp:316] BatchNorm62 needs backward computation.
I0612 11:07:31.877501  5211 net.cpp:316] Convolution62 needs backward computation.
I0612 11:07:31.877504  5211 net.cpp:316] Eltwise30_ReLU61_0_split needs backward computation.
I0612 11:07:31.877508  5211 net.cpp:316] ReLU61 needs backward computation.
I0612 11:07:31.877511  5211 net.cpp:316] Eltwise30 needs backward computation.
I0612 11:07:31.877516  5211 net.cpp:316] Scale61 needs backward computation.
I0612 11:07:31.877521  5211 net.cpp:316] BatchNorm61 needs backward computation.
I0612 11:07:31.877523  5211 net.cpp:316] Convolution61 needs backward computation.
I0612 11:07:31.877527  5211 net.cpp:316] ReLU60 needs backward computation.
I0612 11:07:31.877532  5211 net.cpp:316] Scale60 needs backward computation.
I0612 11:07:31.877535  5211 net.cpp:316] BatchNorm60 needs backward computation.
I0612 11:07:31.877538  5211 net.cpp:316] Convolution60 needs backward computation.
I0612 11:07:31.877542  5211 net.cpp:316] Eltwise29_ReLU59_0_split needs backward computation.
I0612 11:07:31.877547  5211 net.cpp:316] ReLU59 needs backward computation.
I0612 11:07:31.877550  5211 net.cpp:316] Eltwise29 needs backward computation.
I0612 11:07:31.877555  5211 net.cpp:316] Scale59 needs backward computation.
I0612 11:07:31.877559  5211 net.cpp:316] BatchNorm59 needs backward computation.
I0612 11:07:31.877562  5211 net.cpp:316] Convolution59 needs backward computation.
I0612 11:07:31.877568  5211 net.cpp:316] ReLU58 needs backward computation.
I0612 11:07:31.877570  5211 net.cpp:316] Scale58 needs backward computation.
I0612 11:07:31.877574  5211 net.cpp:316] BatchNorm58 needs backward computation.
I0612 11:07:31.877578  5211 net.cpp:316] Convolution58 needs backward computation.
I0612 11:07:31.877583  5211 net.cpp:316] Eltwise28_ReLU57_0_split needs backward computation.
I0612 11:07:31.877586  5211 net.cpp:316] ReLU57 needs backward computation.
I0612 11:07:31.877590  5211 net.cpp:316] Eltwise28 needs backward computation.
I0612 11:07:31.877594  5211 net.cpp:316] Scale57 needs backward computation.
I0612 11:07:31.877599  5211 net.cpp:316] BatchNorm57 needs backward computation.
I0612 11:07:31.877602  5211 net.cpp:316] Convolution57 needs backward computation.
I0612 11:07:31.877606  5211 net.cpp:316] ReLU56 needs backward computation.
I0612 11:07:31.877609  5211 net.cpp:316] Scale56 needs backward computation.
I0612 11:07:31.877614  5211 net.cpp:316] BatchNorm56 needs backward computation.
I0612 11:07:31.877617  5211 net.cpp:316] Convolution56 needs backward computation.
I0612 11:07:31.877624  5211 net.cpp:316] Eltwise27_ReLU55_0_split needs backward computation.
I0612 11:07:31.877627  5211 net.cpp:316] ReLU55 needs backward computation.
I0612 11:07:31.877631  5211 net.cpp:316] Eltwise27 needs backward computation.
I0612 11:07:31.877636  5211 net.cpp:316] Scale55 needs backward computation.
I0612 11:07:31.877640  5211 net.cpp:316] BatchNorm55 needs backward computation.
I0612 11:07:31.877643  5211 net.cpp:316] Convolution55 needs backward computation.
I0612 11:07:31.877647  5211 net.cpp:316] ReLU54 needs backward computation.
I0612 11:07:31.877651  5211 net.cpp:316] Scale54 needs backward computation.
I0612 11:07:31.877655  5211 net.cpp:316] BatchNorm54 needs backward computation.
I0612 11:07:31.877660  5211 net.cpp:316] Convolution54 needs backward computation.
I0612 11:07:31.877665  5211 net.cpp:316] Eltwise26_ReLU53_0_split needs backward computation.
I0612 11:07:31.877668  5211 net.cpp:316] ReLU53 needs backward computation.
I0612 11:07:31.877671  5211 net.cpp:316] Eltwise26 needs backward computation.
I0612 11:07:31.877676  5211 net.cpp:316] Scale53 needs backward computation.
I0612 11:07:31.877682  5211 net.cpp:316] BatchNorm53 needs backward computation.
I0612 11:07:31.877686  5211 net.cpp:316] Convolution53 needs backward computation.
I0612 11:07:31.877691  5211 net.cpp:316] ReLU52 needs backward computation.
I0612 11:07:31.877694  5211 net.cpp:316] Scale52 needs backward computation.
I0612 11:07:31.877698  5211 net.cpp:316] BatchNorm52 needs backward computation.
I0612 11:07:31.877701  5211 net.cpp:316] Convolution52 needs backward computation.
I0612 11:07:31.877706  5211 net.cpp:316] Eltwise25_ReLU51_0_split needs backward computation.
I0612 11:07:31.877710  5211 net.cpp:316] ReLU51 needs backward computation.
I0612 11:07:31.877713  5211 net.cpp:316] Eltwise25 needs backward computation.
I0612 11:07:31.877718  5211 net.cpp:316] Scale51 needs backward computation.
I0612 11:07:31.877722  5211 net.cpp:316] BatchNorm51 needs backward computation.
I0612 11:07:31.877725  5211 net.cpp:316] Convolution51 needs backward computation.
I0612 11:07:31.877729  5211 net.cpp:316] ReLU50 needs backward computation.
I0612 11:07:31.877733  5211 net.cpp:316] Scale50 needs backward computation.
I0612 11:07:31.877737  5211 net.cpp:316] BatchNorm50 needs backward computation.
I0612 11:07:31.877742  5211 net.cpp:316] Convolution50 needs backward computation.
I0612 11:07:31.877745  5211 net.cpp:316] Eltwise24_ReLU49_0_split needs backward computation.
I0612 11:07:31.877749  5211 net.cpp:316] ReLU49 needs backward computation.
I0612 11:07:31.877753  5211 net.cpp:316] Eltwise24 needs backward computation.
I0612 11:07:31.877758  5211 net.cpp:316] Scale49 needs backward computation.
I0612 11:07:31.877761  5211 net.cpp:316] BatchNorm49 needs backward computation.
I0612 11:07:31.877765  5211 net.cpp:316] Convolution49 needs backward computation.
I0612 11:07:31.877769  5211 net.cpp:316] ReLU48 needs backward computation.
I0612 11:07:31.877774  5211 net.cpp:316] Scale48 needs backward computation.
I0612 11:07:31.877776  5211 net.cpp:316] BatchNorm48 needs backward computation.
I0612 11:07:31.877780  5211 net.cpp:316] Convolution48 needs backward computation.
I0612 11:07:31.877784  5211 net.cpp:316] Eltwise23_ReLU47_0_split needs backward computation.
I0612 11:07:31.877789  5211 net.cpp:316] ReLU47 needs backward computation.
I0612 11:07:31.877792  5211 net.cpp:316] Eltwise23 needs backward computation.
I0612 11:07:31.877796  5211 net.cpp:316] Scale47 needs backward computation.
I0612 11:07:31.877800  5211 net.cpp:316] BatchNorm47 needs backward computation.
I0612 11:07:31.877804  5211 net.cpp:316] Convolution47 needs backward computation.
I0612 11:07:31.877809  5211 net.cpp:316] ReLU46 needs backward computation.
I0612 11:07:31.877812  5211 net.cpp:316] Scale46 needs backward computation.
I0612 11:07:31.877816  5211 net.cpp:316] BatchNorm46 needs backward computation.
I0612 11:07:31.877820  5211 net.cpp:316] Convolution46 needs backward computation.
I0612 11:07:31.877823  5211 net.cpp:316] Eltwise22_ReLU45_0_split needs backward computation.
I0612 11:07:31.877827  5211 net.cpp:316] ReLU45 needs backward computation.
I0612 11:07:31.877831  5211 net.cpp:316] Eltwise22 needs backward computation.
I0612 11:07:31.877835  5211 net.cpp:316] Scale45 needs backward computation.
I0612 11:07:31.877840  5211 net.cpp:316] BatchNorm45 needs backward computation.
I0612 11:07:31.877843  5211 net.cpp:316] Convolution45 needs backward computation.
I0612 11:07:31.877847  5211 net.cpp:316] ReLU44 needs backward computation.
I0612 11:07:31.877851  5211 net.cpp:316] Scale44 needs backward computation.
I0612 11:07:31.877856  5211 net.cpp:316] BatchNorm44 needs backward computation.
I0612 11:07:31.877859  5211 net.cpp:316] Convolution44 needs backward computation.
I0612 11:07:31.877863  5211 net.cpp:316] Eltwise21_ReLU43_0_split needs backward computation.
I0612 11:07:31.877867  5211 net.cpp:316] ReLU43 needs backward computation.
I0612 11:07:31.877871  5211 net.cpp:316] Eltwise21 needs backward computation.
I0612 11:07:31.877876  5211 net.cpp:316] Scale43 needs backward computation.
I0612 11:07:31.877879  5211 net.cpp:316] BatchNorm43 needs backward computation.
I0612 11:07:31.877889  5211 net.cpp:316] Convolution43 needs backward computation.
I0612 11:07:31.877893  5211 net.cpp:316] ReLU42 needs backward computation.
I0612 11:07:31.877897  5211 net.cpp:316] Scale42 needs backward computation.
I0612 11:07:31.877902  5211 net.cpp:316] BatchNorm42 needs backward computation.
I0612 11:07:31.877904  5211 net.cpp:316] Convolution42 needs backward computation.
I0612 11:07:31.877909  5211 net.cpp:316] Eltwise20_ReLU41_0_split needs backward computation.
I0612 11:07:31.877913  5211 net.cpp:316] ReLU41 needs backward computation.
I0612 11:07:31.877918  5211 net.cpp:316] Eltwise20 needs backward computation.
I0612 11:07:31.877921  5211 net.cpp:316] Scale41 needs backward computation.
I0612 11:07:31.877925  5211 net.cpp:316] BatchNorm41 needs backward computation.
I0612 11:07:31.877929  5211 net.cpp:316] Convolution41 needs backward computation.
I0612 11:07:31.877933  5211 net.cpp:316] ReLU40 needs backward computation.
I0612 11:07:31.877938  5211 net.cpp:316] Scale40 needs backward computation.
I0612 11:07:31.877940  5211 net.cpp:316] BatchNorm40 needs backward computation.
I0612 11:07:31.877944  5211 net.cpp:316] Convolution40 needs backward computation.
I0612 11:07:31.877948  5211 net.cpp:316] Eltwise19_ReLU39_0_split needs backward computation.
I0612 11:07:31.877953  5211 net.cpp:316] ReLU39 needs backward computation.
I0612 11:07:31.877956  5211 net.cpp:316] Eltwise19 needs backward computation.
I0612 11:07:31.877961  5211 net.cpp:316] Scale39 needs backward computation.
I0612 11:07:31.877965  5211 net.cpp:316] BatchNorm39 needs backward computation.
I0612 11:07:31.877969  5211 net.cpp:316] Convolution39 needs backward computation.
I0612 11:07:31.877974  5211 net.cpp:316] ReLU38 needs backward computation.
I0612 11:07:31.877977  5211 net.cpp:316] Scale38 needs backward computation.
I0612 11:07:31.877981  5211 net.cpp:316] BatchNorm38 needs backward computation.
I0612 11:07:31.877985  5211 net.cpp:316] Convolution38 needs backward computation.
I0612 11:07:31.877990  5211 net.cpp:316] Concat1 needs backward computation.
I0612 11:07:31.877995  5211 net.cpp:318] Input1 does not need backward computation.
I0612 11:07:31.877998  5211 net.cpp:316] Pooling1 needs backward computation.
I0612 11:07:31.878002  5211 net.cpp:316] Eltwise18_ReLU37_0_split needs backward computation.
I0612 11:07:31.878006  5211 net.cpp:316] ReLU37 needs backward computation.
I0612 11:07:31.878010  5211 net.cpp:316] Eltwise18 needs backward computation.
I0612 11:07:31.878015  5211 net.cpp:316] Scale37 needs backward computation.
I0612 11:07:31.878020  5211 net.cpp:316] BatchNorm37 needs backward computation.
I0612 11:07:31.878023  5211 net.cpp:316] Convolution37 needs backward computation.
I0612 11:07:31.878027  5211 net.cpp:316] ReLU36 needs backward computation.
I0612 11:07:31.878031  5211 net.cpp:316] Scale36 needs backward computation.
I0612 11:07:31.878034  5211 net.cpp:316] BatchNorm36 needs backward computation.
I0612 11:07:31.878038  5211 net.cpp:316] Convolution36 needs backward computation.
I0612 11:07:31.878042  5211 net.cpp:316] Eltwise17_ReLU35_0_split needs backward computation.
I0612 11:07:31.878047  5211 net.cpp:316] ReLU35 needs backward computation.
I0612 11:07:31.878051  5211 net.cpp:316] Eltwise17 needs backward computation.
I0612 11:07:31.878056  5211 net.cpp:316] Scale35 needs backward computation.
I0612 11:07:31.878059  5211 net.cpp:316] BatchNorm35 needs backward computation.
I0612 11:07:31.878063  5211 net.cpp:316] Convolution35 needs backward computation.
I0612 11:07:31.878067  5211 net.cpp:316] ReLU34 needs backward computation.
I0612 11:07:31.878072  5211 net.cpp:316] Scale34 needs backward computation.
I0612 11:07:31.878074  5211 net.cpp:316] BatchNorm34 needs backward computation.
I0612 11:07:31.878078  5211 net.cpp:316] Convolution34 needs backward computation.
I0612 11:07:31.878082  5211 net.cpp:316] Eltwise16_ReLU33_0_split needs backward computation.
I0612 11:07:31.878087  5211 net.cpp:316] ReLU33 needs backward computation.
I0612 11:07:31.878093  5211 net.cpp:316] Eltwise16 needs backward computation.
I0612 11:07:31.878098  5211 net.cpp:316] Scale33 needs backward computation.
I0612 11:07:31.878101  5211 net.cpp:316] BatchNorm33 needs backward computation.
I0612 11:07:31.878105  5211 net.cpp:316] Convolution33 needs backward computation.
I0612 11:07:31.878109  5211 net.cpp:316] ReLU32 needs backward computation.
I0612 11:07:31.878113  5211 net.cpp:316] Scale32 needs backward computation.
I0612 11:07:31.878116  5211 net.cpp:316] BatchNorm32 needs backward computation.
I0612 11:07:31.878120  5211 net.cpp:316] Convolution32 needs backward computation.
I0612 11:07:31.878124  5211 net.cpp:316] Eltwise15_ReLU31_0_split needs backward computation.
I0612 11:07:31.878129  5211 net.cpp:316] ReLU31 needs backward computation.
I0612 11:07:31.878132  5211 net.cpp:316] Eltwise15 needs backward computation.
I0612 11:07:31.878137  5211 net.cpp:316] Scale31 needs backward computation.
I0612 11:07:31.878141  5211 net.cpp:316] BatchNorm31 needs backward computation.
I0612 11:07:31.878144  5211 net.cpp:316] Convolution31 needs backward computation.
I0612 11:07:31.878149  5211 net.cpp:316] ReLU30 needs backward computation.
I0612 11:07:31.878152  5211 net.cpp:316] Scale30 needs backward computation.
I0612 11:07:31.878156  5211 net.cpp:316] BatchNorm30 needs backward computation.
I0612 11:07:31.878160  5211 net.cpp:316] Convolution30 needs backward computation.
I0612 11:07:31.878165  5211 net.cpp:316] Eltwise14_ReLU29_0_split needs backward computation.
I0612 11:07:31.878168  5211 net.cpp:316] ReLU29 needs backward computation.
I0612 11:07:31.878172  5211 net.cpp:316] Eltwise14 needs backward computation.
I0612 11:07:31.878177  5211 net.cpp:316] Scale29 needs backward computation.
I0612 11:07:31.878181  5211 net.cpp:316] BatchNorm29 needs backward computation.
I0612 11:07:31.878185  5211 net.cpp:316] Convolution29 needs backward computation.
I0612 11:07:31.878190  5211 net.cpp:316] ReLU28 needs backward computation.
I0612 11:07:31.878193  5211 net.cpp:316] Scale28 needs backward computation.
I0612 11:07:31.878197  5211 net.cpp:316] BatchNorm28 needs backward computation.
I0612 11:07:31.878201  5211 net.cpp:316] Convolution28 needs backward computation.
I0612 11:07:31.878204  5211 net.cpp:316] Eltwise13_ReLU27_0_split needs backward computation.
I0612 11:07:31.878209  5211 net.cpp:316] ReLU27 needs backward computation.
I0612 11:07:31.878212  5211 net.cpp:316] Eltwise13 needs backward computation.
I0612 11:07:31.878217  5211 net.cpp:316] Scale27 needs backward computation.
I0612 11:07:31.878221  5211 net.cpp:316] BatchNorm27 needs backward computation.
I0612 11:07:31.878224  5211 net.cpp:316] Convolution27 needs backward computation.
I0612 11:07:31.878228  5211 net.cpp:316] ReLU26 needs backward computation.
I0612 11:07:31.878232  5211 net.cpp:316] Scale26 needs backward computation.
I0612 11:07:31.878237  5211 net.cpp:316] BatchNorm26 needs backward computation.
I0612 11:07:31.878240  5211 net.cpp:316] Convolution26 needs backward computation.
I0612 11:07:31.878244  5211 net.cpp:316] Eltwise12_ReLU25_0_split needs backward computation.
I0612 11:07:31.878248  5211 net.cpp:316] ReLU25 needs backward computation.
I0612 11:07:31.878252  5211 net.cpp:316] Eltwise12 needs backward computation.
I0612 11:07:31.878257  5211 net.cpp:316] Scale25 needs backward computation.
I0612 11:07:31.878260  5211 net.cpp:316] BatchNorm25 needs backward computation.
I0612 11:07:31.878264  5211 net.cpp:316] Convolution25 needs backward computation.
I0612 11:07:31.878268  5211 net.cpp:316] ReLU24 needs backward computation.
I0612 11:07:31.878273  5211 net.cpp:316] Scale24 needs backward computation.
I0612 11:07:31.878276  5211 net.cpp:316] BatchNorm24 needs backward computation.
I0612 11:07:31.878280  5211 net.cpp:316] Convolution24 needs backward computation.
I0612 11:07:31.878284  5211 net.cpp:316] Eltwise11_ReLU23_0_split needs backward computation.
I0612 11:07:31.878290  5211 net.cpp:316] ReLU23 needs backward computation.
I0612 11:07:31.878294  5211 net.cpp:316] Eltwise11 needs backward computation.
I0612 11:07:31.878303  5211 net.cpp:316] Scale23 needs backward computation.
I0612 11:07:31.878306  5211 net.cpp:316] BatchNorm23 needs backward computation.
I0612 11:07:31.878310  5211 net.cpp:316] Convolution23 needs backward computation.
I0612 11:07:31.878314  5211 net.cpp:316] ReLU22 needs backward computation.
I0612 11:07:31.878319  5211 net.cpp:316] Scale22 needs backward computation.
I0612 11:07:31.878322  5211 net.cpp:316] BatchNorm22 needs backward computation.
I0612 11:07:31.878326  5211 net.cpp:316] Convolution22 needs backward computation.
I0612 11:07:31.878330  5211 net.cpp:316] Eltwise10_ReLU21_0_split needs backward computation.
I0612 11:07:31.878334  5211 net.cpp:316] ReLU21 needs backward computation.
I0612 11:07:31.878339  5211 net.cpp:316] Eltwise10 needs backward computation.
I0612 11:07:31.878343  5211 net.cpp:316] Scale21 needs backward computation.
I0612 11:07:31.878347  5211 net.cpp:316] BatchNorm21 needs backward computation.
I0612 11:07:31.878351  5211 net.cpp:316] Convolution21 needs backward computation.
I0612 11:07:31.878365  5211 net.cpp:316] ReLU20 needs backward computation.
I0612 11:07:31.878368  5211 net.cpp:316] Scale20 needs backward computation.
I0612 11:07:31.878372  5211 net.cpp:316] BatchNorm20 needs backward computation.
I0612 11:07:31.878376  5211 net.cpp:316] Convolution20 needs backward computation.
I0612 11:07:31.878381  5211 net.cpp:316] Eltwise9_ReLU19_0_split needs backward computation.
I0612 11:07:31.878386  5211 net.cpp:316] ReLU19 needs backward computation.
I0612 11:07:31.878389  5211 net.cpp:316] Eltwise9 needs backward computation.
I0612 11:07:31.878394  5211 net.cpp:316] Scale19 needs backward computation.
I0612 11:07:31.878398  5211 net.cpp:316] BatchNorm19 needs backward computation.
I0612 11:07:31.878401  5211 net.cpp:316] Convolution19 needs backward computation.
I0612 11:07:31.878407  5211 net.cpp:316] ReLU18 needs backward computation.
I0612 11:07:31.878409  5211 net.cpp:316] Scale18 needs backward computation.
I0612 11:07:31.878413  5211 net.cpp:316] BatchNorm18 needs backward computation.
I0612 11:07:31.878417  5211 net.cpp:316] Convolution18 needs backward computation.
I0612 11:07:31.878422  5211 net.cpp:316] Eltwise8_ReLU17_0_split needs backward computation.
I0612 11:07:31.878427  5211 net.cpp:316] ReLU17 needs backward computation.
I0612 11:07:31.878430  5211 net.cpp:316] Eltwise8 needs backward computation.
I0612 11:07:31.878435  5211 net.cpp:316] Scale17 needs backward computation.
I0612 11:07:31.878439  5211 net.cpp:316] BatchNorm17 needs backward computation.
I0612 11:07:31.878443  5211 net.cpp:316] Convolution17 needs backward computation.
I0612 11:07:31.878448  5211 net.cpp:316] ReLU16 needs backward computation.
I0612 11:07:31.878450  5211 net.cpp:316] Scale16 needs backward computation.
I0612 11:07:31.878454  5211 net.cpp:316] BatchNorm16 needs backward computation.
I0612 11:07:31.878458  5211 net.cpp:316] Convolution16 needs backward computation.
I0612 11:07:31.878463  5211 net.cpp:316] Eltwise7_ReLU15_0_split needs backward computation.
I0612 11:07:31.878468  5211 net.cpp:316] ReLU15 needs backward computation.
I0612 11:07:31.878471  5211 net.cpp:316] Eltwise7 needs backward computation.
I0612 11:07:31.878476  5211 net.cpp:316] Scale15 needs backward computation.
I0612 11:07:31.878479  5211 net.cpp:316] BatchNorm15 needs backward computation.
I0612 11:07:31.878484  5211 net.cpp:316] Convolution15 needs backward computation.
I0612 11:07:31.878487  5211 net.cpp:316] ReLU14 needs backward computation.
I0612 11:07:31.878491  5211 net.cpp:316] Scale14 needs backward computation.
I0612 11:07:31.878495  5211 net.cpp:316] BatchNorm14 needs backward computation.
I0612 11:07:31.878499  5211 net.cpp:316] Convolution14 needs backward computation.
I0612 11:07:31.878504  5211 net.cpp:316] Eltwise6_ReLU13_0_split needs backward computation.
I0612 11:07:31.878507  5211 net.cpp:316] ReLU13 needs backward computation.
I0612 11:07:31.878511  5211 net.cpp:316] Eltwise6 needs backward computation.
I0612 11:07:31.878516  5211 net.cpp:316] Scale13 needs backward computation.
I0612 11:07:31.878522  5211 net.cpp:316] BatchNorm13 needs backward computation.
I0612 11:07:31.878526  5211 net.cpp:316] Convolution13 needs backward computation.
I0612 11:07:31.878530  5211 net.cpp:316] ReLU12 needs backward computation.
I0612 11:07:31.878535  5211 net.cpp:316] Scale12 needs backward computation.
I0612 11:07:31.878538  5211 net.cpp:316] BatchNorm12 needs backward computation.
I0612 11:07:31.878542  5211 net.cpp:316] Convolution12 needs backward computation.
I0612 11:07:31.878546  5211 net.cpp:316] Eltwise5_ReLU11_0_split needs backward computation.
I0612 11:07:31.878551  5211 net.cpp:316] ReLU11 needs backward computation.
I0612 11:07:31.878554  5211 net.cpp:316] Eltwise5 needs backward computation.
I0612 11:07:31.878559  5211 net.cpp:316] Scale11 needs backward computation.
I0612 11:07:31.878562  5211 net.cpp:316] BatchNorm11 needs backward computation.
I0612 11:07:31.878566  5211 net.cpp:316] Convolution11 needs backward computation.
I0612 11:07:31.878571  5211 net.cpp:316] ReLU10 needs backward computation.
I0612 11:07:31.878576  5211 net.cpp:316] Scale10 needs backward computation.
I0612 11:07:31.878579  5211 net.cpp:316] BatchNorm10 needs backward computation.
I0612 11:07:31.878582  5211 net.cpp:316] Convolution10 needs backward computation.
I0612 11:07:31.878587  5211 net.cpp:316] Eltwise4_ReLU9_0_split needs backward computation.
I0612 11:07:31.878593  5211 net.cpp:316] ReLU9 needs backward computation.
I0612 11:07:31.878597  5211 net.cpp:316] Eltwise4 needs backward computation.
I0612 11:07:31.878602  5211 net.cpp:316] Scale9 needs backward computation.
I0612 11:07:31.878607  5211 net.cpp:316] BatchNorm9 needs backward computation.
I0612 11:07:31.878610  5211 net.cpp:316] Convolution9 needs backward computation.
I0612 11:07:31.878614  5211 net.cpp:316] ReLU8 needs backward computation.
I0612 11:07:31.878618  5211 net.cpp:316] Scale8 needs backward computation.
I0612 11:07:31.878623  5211 net.cpp:316] BatchNorm8 needs backward computation.
I0612 11:07:31.878626  5211 net.cpp:316] Convolution8 needs backward computation.
I0612 11:07:31.878630  5211 net.cpp:316] Eltwise3_ReLU7_0_split needs backward computation.
I0612 11:07:31.878634  5211 net.cpp:316] ReLU7 needs backward computation.
I0612 11:07:31.878638  5211 net.cpp:316] Eltwise3 needs backward computation.
I0612 11:07:31.878643  5211 net.cpp:316] Scale7 needs backward computation.
I0612 11:07:31.878648  5211 net.cpp:316] BatchNorm7 needs backward computation.
I0612 11:07:31.878651  5211 net.cpp:316] Convolution7 needs backward computation.
I0612 11:07:31.878655  5211 net.cpp:316] ReLU6 needs backward computation.
I0612 11:07:31.878659  5211 net.cpp:316] Scale6 needs backward computation.
I0612 11:07:31.878664  5211 net.cpp:316] BatchNorm6 needs backward computation.
I0612 11:07:31.878666  5211 net.cpp:316] Convolution6 needs backward computation.
I0612 11:07:31.878671  5211 net.cpp:316] Eltwise2_ReLU5_0_split needs backward computation.
I0612 11:07:31.878675  5211 net.cpp:316] ReLU5 needs backward computation.
I0612 11:07:31.878679  5211 net.cpp:316] Eltwise2 needs backward computation.
I0612 11:07:31.878684  5211 net.cpp:316] Scale5 needs backward computation.
I0612 11:07:31.878687  5211 net.cpp:316] BatchNorm5 needs backward computation.
I0612 11:07:31.878691  5211 net.cpp:316] Convolution5 needs backward computation.
I0612 11:07:31.878695  5211 net.cpp:316] ReLU4 needs backward computation.
I0612 11:07:31.878700  5211 net.cpp:316] Scale4 needs backward computation.
I0612 11:07:31.878703  5211 net.cpp:316] BatchNorm4 needs backward computation.
I0612 11:07:31.878707  5211 net.cpp:316] Convolution4 needs backward computation.
I0612 11:07:31.878711  5211 net.cpp:316] Eltwise1_ReLU3_0_split needs backward computation.
I0612 11:07:31.878715  5211 net.cpp:316] ReLU3 needs backward computation.
I0612 11:07:31.878720  5211 net.cpp:316] Eltwise1 needs backward computation.
I0612 11:07:31.878725  5211 net.cpp:316] Scale3 needs backward computation.
I0612 11:07:31.878728  5211 net.cpp:316] BatchNorm3 needs backward computation.
I0612 11:07:31.878734  5211 net.cpp:316] Convolution3 needs backward computation.
I0612 11:07:31.878738  5211 net.cpp:316] ReLU2 needs backward computation.
I0612 11:07:31.878742  5211 net.cpp:316] Scale2 needs backward computation.
I0612 11:07:31.878746  5211 net.cpp:316] BatchNorm2 needs backward computation.
I0612 11:07:31.878751  5211 net.cpp:316] Convolution2 needs backward computation.
I0612 11:07:31.878754  5211 net.cpp:316] Convolution1_ReLU1_0_split needs backward computation.
I0612 11:07:31.878759  5211 net.cpp:316] ReLU1 needs backward computation.
I0612 11:07:31.878763  5211 net.cpp:316] Scale1 needs backward computation.
I0612 11:07:31.878767  5211 net.cpp:316] BatchNorm1 needs backward computation.
I0612 11:07:31.878770  5211 net.cpp:316] Convolution1 needs backward computation.
I0612 11:07:31.878775  5211 net.cpp:318] Data1 does not need backward computation.
I0612 11:07:31.878779  5211 net.cpp:360] This network produces output SoftmaxWithLoss1
I0612 11:07:31.879118  5211 net.cpp:374] Network initialization done.
I0612 11:07:31.903296  5211 solver.cpp:186] Creating test net (#0) specified by test_net file: examples/stochastic_depth/residual_test54.prototxt
I0612 11:07:31.909150  5211 net.cpp:148] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "/scratch/pas282/caffe/examples/cifar10/cifar10_test_leveldb_padding1"
    batch_size: 128
    backend: LEVELDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution21"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution22"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution22"
  top: "Convolution22"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Convolution22"
  top: "Convolution23"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution23"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution24"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution25"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution26"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution27"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution28"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution28"
  top: "Convolution28"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution29"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution30"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "Convolution30"
  top: "Convolution30"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Convolution30"
  top: "Convolution31"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise15"
  type: "Eltwise"
  bottom: "Eltwise14"
  bottom: "Convolution31"
  top: "Eltwise15"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "Eltwise15"
  top: "Eltwise15"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Eltwise15"
  top: "Convolution32"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm32"
  type: "BatchNorm"
  bottom: "Convolution32"
  top: "Convolution32"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale32"
  type: "Scale"
  bottom: "Convolution32"
  top: "Convolution32"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU32"
  type: "ReLU"
  bottom: "Convolution32"
  top: "Convolution32"
}
layer {
  name: "Convolution33"
  type: "Convolution"
  bottom: "Convolution32"
  top: "Convolution33"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm33"
  type: "BatchNorm"
  bottom: "Convolution33"
  top: "Convolution33"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale33"
  type: "Scale"
  bottom: "Convolution33"
  top: "Convolution33"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise16"
  type: "Eltwise"
  bottom: "Eltwise15"
  bottom: "Convolution33"
  top: "Eltwise16"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU33"
  type: "ReLU"
  bottom: "Eltwise16"
  top: "Eltwise16"
}
layer {
  name: "Convolution34"
  type: "Convolution"
  bottom: "Eltwise16"
  top: "Convolution34"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm34"
  type: "BatchNorm"
  bottom: "Convolution34"
  top: "Convolution34"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale34"
  type: "Scale"
  bottom: "Convolution34"
  top: "Convolution34"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU34"
  type: "ReLU"
  bottom: "Convolution34"
  top: "Convolution34"
}
layer {
  name: "Convolution35"
  type: "Convolution"
  bottom: "Convolution34"
  top: "Convolution35"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm35"
  type: "BatchNorm"
  bottom: "Convolution35"
  top: "Convolution35"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale35"
  type: "Scale"
  bottom: "Convolution35"
  top: "Convolution35"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise17"
  type: "Eltwise"
  bottom: "Eltwise16"
  bottom: "Convolution35"
  top: "Eltwise17"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU35"
  type: "ReLU"
  bottom: "Eltwise17"
  top: "Eltwise17"
}
layer {
  name: "Convolution36"
  type: "Convolution"
  bottom: "Eltwise17"
  top: "Convolution36"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  
I0612 11:07:31.913159  5211 layer_factory.hpp:77] Creating layer Data1
I0612 11:07:31.913425  5211 net.cpp:190] Creating Layer Data1
I0612 11:07:31.913441  5211 net.cpp:589] Data1 -> Data1
I0612 11:07:31.913460  5211 net.cpp:589] Data1 -> Data2
I0612 11:07:31.952543  5220 db_leveldb.cpp:18] Opened leveldb /scratch/pas282/caffe/examples/cifar10/cifar10_test_leveldb_padding1
I0612 11:07:31.953420  5211 data_layer.cpp:41] output data size: 128,3,32,32
I0612 11:07:31.958845  5211 net.cpp:240] Setting up Data1
I0612 11:07:31.958875  5211 net.cpp:247] Top shape: 128 3 32 32 (393216)
I0612 11:07:31.958889  5211 net.cpp:247] Top shape: 128 (128)
I0612 11:07:31.958899  5211 net.cpp:255] Memory required for data: 1573376
I0612 11:07:31.958907  5211 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0612 11:07:31.958923  5211 net.cpp:190] Creating Layer Data2_Data1_1_split
I0612 11:07:31.958932  5211 net.cpp:615] Data2_Data1_1_split <- Data2
I0612 11:07:31.958947  5211 net.cpp:589] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0612 11:07:31.958966  5211 net.cpp:589] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0612 11:07:31.959126  5211 net.cpp:240] Setting up Data2_Data1_1_split
I0612 11:07:31.959146  5211 net.cpp:247] Top shape: 128 (128)
I0612 11:07:31.959156  5211 net.cpp:247] Top shape: 128 (128)
I0612 11:07:31.959163  5211 net.cpp:255] Memory required for data: 1574400
I0612 11:07:31.959170  5211 layer_factory.hpp:77] Creating layer Convolution1
I0612 11:07:31.959194  5211 net.cpp:190] Creating Layer Convolution1
I0612 11:07:31.959203  5211 net.cpp:615] Convolution1 <- Data1
I0612 11:07:31.959223  5211 net.cpp:589] Convolution1 -> Convolution1
I0612 11:07:31.959858  5211 net.cpp:240] Setting up Convolution1
I0612 11:07:31.959883  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.959892  5211 net.cpp:255] Memory required for data: 9963008
I0612 11:07:31.959916  5211 layer_factory.hpp:77] Creating layer BatchNorm1
I0612 11:07:31.959931  5211 net.cpp:190] Creating Layer BatchNorm1
I0612 11:07:31.959939  5211 net.cpp:615] BatchNorm1 <- Convolution1
I0612 11:07:31.959955  5211 net.cpp:576] BatchNorm1 -> Convolution1 (in-place)
I0612 11:07:31.960387  5211 net.cpp:240] Setting up BatchNorm1
I0612 11:07:31.960403  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.960410  5211 net.cpp:255] Memory required for data: 18351616
I0612 11:07:31.960438  5211 layer_factory.hpp:77] Creating layer Scale1
I0612 11:07:31.960453  5211 net.cpp:190] Creating Layer Scale1
I0612 11:07:31.960461  5211 net.cpp:615] Scale1 <- Convolution1
I0612 11:07:31.960475  5211 net.cpp:576] Scale1 -> Convolution1 (in-place)
I0612 11:07:31.960546  5211 layer_factory.hpp:77] Creating layer Scale1
I0612 11:07:31.960929  5211 net.cpp:240] Setting up Scale1
I0612 11:07:31.960948  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.960957  5211 net.cpp:255] Memory required for data: 26740224
I0612 11:07:31.960974  5211 layer_factory.hpp:77] Creating layer ReLU1
I0612 11:07:31.960990  5211 net.cpp:190] Creating Layer ReLU1
I0612 11:07:31.960999  5211 net.cpp:615] ReLU1 <- Convolution1
I0612 11:07:31.961009  5211 net.cpp:576] ReLU1 -> Convolution1 (in-place)
I0612 11:07:31.961024  5211 net.cpp:240] Setting up ReLU1
I0612 11:07:31.961035  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.961041  5211 net.cpp:255] Memory required for data: 35128832
I0612 11:07:31.961048  5211 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0612 11:07:31.961060  5211 net.cpp:190] Creating Layer Convolution1_ReLU1_0_split
I0612 11:07:31.961067  5211 net.cpp:615] Convolution1_ReLU1_0_split <- Convolution1
I0612 11:07:31.961086  5211 net.cpp:589] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0612 11:07:31.961102  5211 net.cpp:589] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0612 11:07:31.961181  5211 net.cpp:240] Setting up Convolution1_ReLU1_0_split
I0612 11:07:31.961194  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.961204  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.961210  5211 net.cpp:255] Memory required for data: 51906048
I0612 11:07:31.961218  5211 layer_factory.hpp:77] Creating layer Convolution2
I0612 11:07:31.961238  5211 net.cpp:190] Creating Layer Convolution2
I0612 11:07:31.961246  5211 net.cpp:615] Convolution2 <- Convolution1_ReLU1_0_split_0
I0612 11:07:31.961261  5211 net.cpp:589] Convolution2 -> Convolution2
I0612 11:07:31.961953  5211 net.cpp:240] Setting up Convolution2
I0612 11:07:31.961971  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.961978  5211 net.cpp:255] Memory required for data: 60294656
I0612 11:07:31.962000  5211 layer_factory.hpp:77] Creating layer BatchNorm2
I0612 11:07:31.962020  5211 net.cpp:190] Creating Layer BatchNorm2
I0612 11:07:31.962029  5211 net.cpp:615] BatchNorm2 <- Convolution2
I0612 11:07:31.962041  5211 net.cpp:576] BatchNorm2 -> Convolution2 (in-place)
I0612 11:07:31.962483  5211 net.cpp:240] Setting up BatchNorm2
I0612 11:07:31.962499  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.962507  5211 net.cpp:255] Memory required for data: 68683264
I0612 11:07:31.962527  5211 layer_factory.hpp:77] Creating layer Scale2
I0612 11:07:31.962541  5211 net.cpp:190] Creating Layer Scale2
I0612 11:07:31.962549  5211 net.cpp:615] Scale2 <- Convolution2
I0612 11:07:31.962559  5211 net.cpp:576] Scale2 -> Convolution2 (in-place)
I0612 11:07:31.962635  5211 layer_factory.hpp:77] Creating layer Scale2
I0612 11:07:31.962879  5211 net.cpp:240] Setting up Scale2
I0612 11:07:31.962893  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.962906  5211 net.cpp:255] Memory required for data: 77071872
I0612 11:07:31.962926  5211 layer_factory.hpp:77] Creating layer ReLU2
I0612 11:07:31.962939  5211 net.cpp:190] Creating Layer ReLU2
I0612 11:07:31.962946  5211 net.cpp:615] ReLU2 <- Convolution2
I0612 11:07:31.962960  5211 net.cpp:576] ReLU2 -> Convolution2 (in-place)
I0612 11:07:31.962973  5211 net.cpp:240] Setting up ReLU2
I0612 11:07:31.962983  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.962990  5211 net.cpp:255] Memory required for data: 85460480
I0612 11:07:31.962997  5211 layer_factory.hpp:77] Creating layer Convolution3
I0612 11:07:31.963019  5211 net.cpp:190] Creating Layer Convolution3
I0612 11:07:31.963027  5211 net.cpp:615] Convolution3 <- Convolution2
I0612 11:07:31.963039  5211 net.cpp:589] Convolution3 -> Convolution3
I0612 11:07:31.963709  5211 net.cpp:240] Setting up Convolution3
I0612 11:07:31.963726  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.963734  5211 net.cpp:255] Memory required for data: 93849088
I0612 11:07:31.963750  5211 layer_factory.hpp:77] Creating layer BatchNorm3
I0612 11:07:31.963769  5211 net.cpp:190] Creating Layer BatchNorm3
I0612 11:07:31.963779  5211 net.cpp:615] BatchNorm3 <- Convolution3
I0612 11:07:31.963789  5211 net.cpp:576] BatchNorm3 -> Convolution3 (in-place)
I0612 11:07:31.964227  5211 net.cpp:240] Setting up BatchNorm3
I0612 11:07:31.964242  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.964251  5211 net.cpp:255] Memory required for data: 102237696
I0612 11:07:31.964277  5211 layer_factory.hpp:77] Creating layer Scale3
I0612 11:07:31.964290  5211 net.cpp:190] Creating Layer Scale3
I0612 11:07:31.964298  5211 net.cpp:615] Scale3 <- Convolution3
I0612 11:07:31.964309  5211 net.cpp:576] Scale3 -> Convolution3 (in-place)
I0612 11:07:31.964387  5211 layer_factory.hpp:77] Creating layer Scale3
I0612 11:07:31.964632  5211 net.cpp:240] Setting up Scale3
I0612 11:07:31.964644  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.964653  5211 net.cpp:255] Memory required for data: 110626304
I0612 11:07:31.964668  5211 layer_factory.hpp:77] Creating layer Eltwise1
I0612 11:07:31.964680  5211 net.cpp:190] Creating Layer Eltwise1
I0612 11:07:31.964689  5211 net.cpp:615] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0612 11:07:31.964702  5211 net.cpp:615] Eltwise1 <- Convolution3
I0612 11:07:31.964715  5211 net.cpp:589] Eltwise1 -> Eltwise1
I0612 11:07:31.964766  5211 net.cpp:240] Setting up Eltwise1
I0612 11:07:31.964779  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.964786  5211 net.cpp:255] Memory required for data: 119014912
I0612 11:07:31.964793  5211 layer_factory.hpp:77] Creating layer ReLU3
I0612 11:07:31.964807  5211 net.cpp:190] Creating Layer ReLU3
I0612 11:07:31.964815  5211 net.cpp:615] ReLU3 <- Eltwise1
I0612 11:07:31.964826  5211 net.cpp:576] ReLU3 -> Eltwise1 (in-place)
I0612 11:07:31.964839  5211 net.cpp:240] Setting up ReLU3
I0612 11:07:31.964849  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.964856  5211 net.cpp:255] Memory required for data: 127403520
I0612 11:07:31.964864  5211 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0612 11:07:31.964876  5211 net.cpp:190] Creating Layer Eltwise1_ReLU3_0_split
I0612 11:07:31.964884  5211 net.cpp:615] Eltwise1_ReLU3_0_split <- Eltwise1
I0612 11:07:31.964895  5211 net.cpp:589] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0612 11:07:31.964907  5211 net.cpp:589] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0612 11:07:31.964980  5211 net.cpp:240] Setting up Eltwise1_ReLU3_0_split
I0612 11:07:31.964993  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.965001  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.965008  5211 net.cpp:255] Memory required for data: 144180736
I0612 11:07:31.965015  5211 layer_factory.hpp:77] Creating layer Convolution4
I0612 11:07:31.965036  5211 net.cpp:190] Creating Layer Convolution4
I0612 11:07:31.965044  5211 net.cpp:615] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0612 11:07:31.965062  5211 net.cpp:589] Convolution4 -> Convolution4
I0612 11:07:31.965726  5211 net.cpp:240] Setting up Convolution4
I0612 11:07:31.965742  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.965752  5211 net.cpp:255] Memory required for data: 152569344
I0612 11:07:31.965767  5211 layer_factory.hpp:77] Creating layer BatchNorm4
I0612 11:07:31.965785  5211 net.cpp:190] Creating Layer BatchNorm4
I0612 11:07:31.965793  5211 net.cpp:615] BatchNorm4 <- Convolution4
I0612 11:07:31.965807  5211 net.cpp:576] BatchNorm4 -> Convolution4 (in-place)
I0612 11:07:31.966228  5211 net.cpp:240] Setting up BatchNorm4
I0612 11:07:31.966243  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.966250  5211 net.cpp:255] Memory required for data: 160957952
I0612 11:07:31.966270  5211 layer_factory.hpp:77] Creating layer Scale4
I0612 11:07:31.966286  5211 net.cpp:190] Creating Layer Scale4
I0612 11:07:31.966295  5211 net.cpp:615] Scale4 <- Convolution4
I0612 11:07:31.966305  5211 net.cpp:576] Scale4 -> Convolution4 (in-place)
I0612 11:07:31.966387  5211 layer_factory.hpp:77] Creating layer Scale4
I0612 11:07:31.966641  5211 net.cpp:240] Setting up Scale4
I0612 11:07:31.966655  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.966662  5211 net.cpp:255] Memory required for data: 169346560
I0612 11:07:31.966678  5211 layer_factory.hpp:77] Creating layer ReLU4
I0612 11:07:31.966691  5211 net.cpp:190] Creating Layer ReLU4
I0612 11:07:31.966698  5211 net.cpp:615] ReLU4 <- Convolution4
I0612 11:07:31.966709  5211 net.cpp:576] ReLU4 -> Convolution4 (in-place)
I0612 11:07:31.966722  5211 net.cpp:240] Setting up ReLU4
I0612 11:07:31.966732  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.966738  5211 net.cpp:255] Memory required for data: 177735168
I0612 11:07:31.966745  5211 layer_factory.hpp:77] Creating layer Convolution5
I0612 11:07:31.966778  5211 net.cpp:190] Creating Layer Convolution5
I0612 11:07:31.966796  5211 net.cpp:615] Convolution5 <- Convolution4
I0612 11:07:31.966812  5211 net.cpp:589] Convolution5 -> Convolution5
I0612 11:07:31.967442  5211 net.cpp:240] Setting up Convolution5
I0612 11:07:31.967456  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.967463  5211 net.cpp:255] Memory required for data: 186123776
I0612 11:07:31.967479  5211 layer_factory.hpp:77] Creating layer BatchNorm5
I0612 11:07:31.967494  5211 net.cpp:190] Creating Layer BatchNorm5
I0612 11:07:31.967502  5211 net.cpp:615] BatchNorm5 <- Convolution5
I0612 11:07:31.967516  5211 net.cpp:576] BatchNorm5 -> Convolution5 (in-place)
I0612 11:07:31.967903  5211 net.cpp:240] Setting up BatchNorm5
I0612 11:07:31.967916  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.967923  5211 net.cpp:255] Memory required for data: 194512384
I0612 11:07:31.967957  5211 layer_factory.hpp:77] Creating layer Scale5
I0612 11:07:31.967969  5211 net.cpp:190] Creating Layer Scale5
I0612 11:07:31.967978  5211 net.cpp:615] Scale5 <- Convolution5
I0612 11:07:31.967988  5211 net.cpp:576] Scale5 -> Convolution5 (in-place)
I0612 11:07:31.968060  5211 layer_factory.hpp:77] Creating layer Scale5
I0612 11:07:31.968286  5211 net.cpp:240] Setting up Scale5
I0612 11:07:31.968299  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.968307  5211 net.cpp:255] Memory required for data: 202900992
I0612 11:07:31.968320  5211 layer_factory.hpp:77] Creating layer Eltwise2
I0612 11:07:31.968332  5211 net.cpp:190] Creating Layer Eltwise2
I0612 11:07:31.968339  5211 net.cpp:615] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0612 11:07:31.968348  5211 net.cpp:615] Eltwise2 <- Convolution5
I0612 11:07:31.968361  5211 net.cpp:589] Eltwise2 -> Eltwise2
I0612 11:07:31.968407  5211 net.cpp:240] Setting up Eltwise2
I0612 11:07:31.968418  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.968425  5211 net.cpp:255] Memory required for data: 211289600
I0612 11:07:31.968431  5211 layer_factory.hpp:77] Creating layer ReLU5
I0612 11:07:31.968446  5211 net.cpp:190] Creating Layer ReLU5
I0612 11:07:31.968461  5211 net.cpp:615] ReLU5 <- Eltwise2
I0612 11:07:31.968471  5211 net.cpp:576] ReLU5 -> Eltwise2 (in-place)
I0612 11:07:31.968482  5211 net.cpp:240] Setting up ReLU5
I0612 11:07:31.968492  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.968498  5211 net.cpp:255] Memory required for data: 219678208
I0612 11:07:31.968505  5211 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0612 11:07:31.968514  5211 net.cpp:190] Creating Layer Eltwise2_ReLU5_0_split
I0612 11:07:31.968521  5211 net.cpp:615] Eltwise2_ReLU5_0_split <- Eltwise2
I0612 11:07:31.968530  5211 net.cpp:589] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0612 11:07:31.968544  5211 net.cpp:589] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0612 11:07:31.968617  5211 net.cpp:240] Setting up Eltwise2_ReLU5_0_split
I0612 11:07:31.968628  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.968638  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.968646  5211 net.cpp:255] Memory required for data: 236455424
I0612 11:07:31.968652  5211 layer_factory.hpp:77] Creating layer Convolution6
I0612 11:07:31.968669  5211 net.cpp:190] Creating Layer Convolution6
I0612 11:07:31.968677  5211 net.cpp:615] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0612 11:07:31.968689  5211 net.cpp:589] Convolution6 -> Convolution6
I0612 11:07:31.969310  5211 net.cpp:240] Setting up Convolution6
I0612 11:07:31.969323  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.969331  5211 net.cpp:255] Memory required for data: 244844032
I0612 11:07:31.969346  5211 layer_factory.hpp:77] Creating layer BatchNorm6
I0612 11:07:31.969360  5211 net.cpp:190] Creating Layer BatchNorm6
I0612 11:07:31.969368  5211 net.cpp:615] BatchNorm6 <- Convolution6
I0612 11:07:31.969380  5211 net.cpp:576] BatchNorm6 -> Convolution6 (in-place)
I0612 11:07:31.969776  5211 net.cpp:240] Setting up BatchNorm6
I0612 11:07:31.969790  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.969796  5211 net.cpp:255] Memory required for data: 253232640
I0612 11:07:31.969815  5211 layer_factory.hpp:77] Creating layer Scale6
I0612 11:07:31.969830  5211 net.cpp:190] Creating Layer Scale6
I0612 11:07:31.969838  5211 net.cpp:615] Scale6 <- Convolution6
I0612 11:07:31.969848  5211 net.cpp:576] Scale6 -> Convolution6 (in-place)
I0612 11:07:31.969913  5211 layer_factory.hpp:77] Creating layer Scale6
I0612 11:07:31.970142  5211 net.cpp:240] Setting up Scale6
I0612 11:07:31.970156  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.970162  5211 net.cpp:255] Memory required for data: 261621248
I0612 11:07:31.970177  5211 layer_factory.hpp:77] Creating layer ReLU6
I0612 11:07:31.970188  5211 net.cpp:190] Creating Layer ReLU6
I0612 11:07:31.970196  5211 net.cpp:615] ReLU6 <- Convolution6
I0612 11:07:31.970206  5211 net.cpp:576] ReLU6 -> Convolution6 (in-place)
I0612 11:07:31.970217  5211 net.cpp:240] Setting up ReLU6
I0612 11:07:31.970227  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.970234  5211 net.cpp:255] Memory required for data: 270009856
I0612 11:07:31.970240  5211 layer_factory.hpp:77] Creating layer Convolution7
I0612 11:07:31.970258  5211 net.cpp:190] Creating Layer Convolution7
I0612 11:07:31.970266  5211 net.cpp:615] Convolution7 <- Convolution6
I0612 11:07:31.970283  5211 net.cpp:589] Convolution7 -> Convolution7
I0612 11:07:31.971137  5211 net.cpp:240] Setting up Convolution7
I0612 11:07:31.971155  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.971163  5211 net.cpp:255] Memory required for data: 278398464
I0612 11:07:31.971179  5211 layer_factory.hpp:77] Creating layer BatchNorm7
I0612 11:07:31.971199  5211 net.cpp:190] Creating Layer BatchNorm7
I0612 11:07:31.971206  5211 net.cpp:615] BatchNorm7 <- Convolution7
I0612 11:07:31.971220  5211 net.cpp:576] BatchNorm7 -> Convolution7 (in-place)
I0612 11:07:31.971616  5211 net.cpp:240] Setting up BatchNorm7
I0612 11:07:31.971629  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.971642  5211 net.cpp:255] Memory required for data: 286787072
I0612 11:07:31.971662  5211 layer_factory.hpp:77] Creating layer Scale7
I0612 11:07:31.971676  5211 net.cpp:190] Creating Layer Scale7
I0612 11:07:31.971684  5211 net.cpp:615] Scale7 <- Convolution7
I0612 11:07:31.971694  5211 net.cpp:576] Scale7 -> Convolution7 (in-place)
I0612 11:07:31.971762  5211 layer_factory.hpp:77] Creating layer Scale7
I0612 11:07:31.971987  5211 net.cpp:240] Setting up Scale7
I0612 11:07:31.971999  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.972007  5211 net.cpp:255] Memory required for data: 295175680
I0612 11:07:31.972021  5211 layer_factory.hpp:77] Creating layer Eltwise3
I0612 11:07:31.972033  5211 net.cpp:190] Creating Layer Eltwise3
I0612 11:07:31.972040  5211 net.cpp:615] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0612 11:07:31.972054  5211 net.cpp:615] Eltwise3 <- Convolution7
I0612 11:07:31.972064  5211 net.cpp:589] Eltwise3 -> Eltwise3
I0612 11:07:31.972113  5211 net.cpp:240] Setting up Eltwise3
I0612 11:07:31.972126  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.972131  5211 net.cpp:255] Memory required for data: 303564288
I0612 11:07:31.972138  5211 layer_factory.hpp:77] Creating layer ReLU7
I0612 11:07:31.972147  5211 net.cpp:190] Creating Layer ReLU7
I0612 11:07:31.972154  5211 net.cpp:615] ReLU7 <- Eltwise3
I0612 11:07:31.972163  5211 net.cpp:576] ReLU7 -> Eltwise3 (in-place)
I0612 11:07:31.972175  5211 net.cpp:240] Setting up ReLU7
I0612 11:07:31.972184  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.972192  5211 net.cpp:255] Memory required for data: 311952896
I0612 11:07:31.972198  5211 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0612 11:07:31.972210  5211 net.cpp:190] Creating Layer Eltwise3_ReLU7_0_split
I0612 11:07:31.972218  5211 net.cpp:615] Eltwise3_ReLU7_0_split <- Eltwise3
I0612 11:07:31.972228  5211 net.cpp:589] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0612 11:07:31.972239  5211 net.cpp:589] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0612 11:07:31.972308  5211 net.cpp:240] Setting up Eltwise3_ReLU7_0_split
I0612 11:07:31.972319  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.972328  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.972334  5211 net.cpp:255] Memory required for data: 328730112
I0612 11:07:31.972342  5211 layer_factory.hpp:77] Creating layer Convolution8
I0612 11:07:31.972357  5211 net.cpp:190] Creating Layer Convolution8
I0612 11:07:31.972363  5211 net.cpp:615] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0612 11:07:31.972375  5211 net.cpp:589] Convolution8 -> Convolution8
I0612 11:07:31.972998  5211 net.cpp:240] Setting up Convolution8
I0612 11:07:31.973012  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.973019  5211 net.cpp:255] Memory required for data: 337118720
I0612 11:07:31.973033  5211 layer_factory.hpp:77] Creating layer BatchNorm8
I0612 11:07:31.973047  5211 net.cpp:190] Creating Layer BatchNorm8
I0612 11:07:31.973055  5211 net.cpp:615] BatchNorm8 <- Convolution8
I0612 11:07:31.973065  5211 net.cpp:576] BatchNorm8 -> Convolution8 (in-place)
I0612 11:07:31.973465  5211 net.cpp:240] Setting up BatchNorm8
I0612 11:07:31.973481  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.973489  5211 net.cpp:255] Memory required for data: 345507328
I0612 11:07:31.973508  5211 layer_factory.hpp:77] Creating layer Scale8
I0612 11:07:31.973520  5211 net.cpp:190] Creating Layer Scale8
I0612 11:07:31.973526  5211 net.cpp:615] Scale8 <- Convolution8
I0612 11:07:31.973537  5211 net.cpp:576] Scale8 -> Convolution8 (in-place)
I0612 11:07:31.973611  5211 layer_factory.hpp:77] Creating layer Scale8
I0612 11:07:31.973834  5211 net.cpp:240] Setting up Scale8
I0612 11:07:31.973848  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.973855  5211 net.cpp:255] Memory required for data: 353895936
I0612 11:07:31.973873  5211 layer_factory.hpp:77] Creating layer ReLU8
I0612 11:07:31.973884  5211 net.cpp:190] Creating Layer ReLU8
I0612 11:07:31.973896  5211 net.cpp:615] ReLU8 <- Convolution8
I0612 11:07:31.973909  5211 net.cpp:576] ReLU8 -> Convolution8 (in-place)
I0612 11:07:31.973923  5211 net.cpp:240] Setting up ReLU8
I0612 11:07:31.973933  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.973940  5211 net.cpp:255] Memory required for data: 362284544
I0612 11:07:31.973947  5211 layer_factory.hpp:77] Creating layer Convolution9
I0612 11:07:31.973961  5211 net.cpp:190] Creating Layer Convolution9
I0612 11:07:31.973968  5211 net.cpp:615] Convolution9 <- Convolution8
I0612 11:07:31.973983  5211 net.cpp:589] Convolution9 -> Convolution9
I0612 11:07:31.974627  5211 net.cpp:240] Setting up Convolution9
I0612 11:07:31.974642  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.974649  5211 net.cpp:255] Memory required for data: 370673152
I0612 11:07:31.974664  5211 layer_factory.hpp:77] Creating layer BatchNorm9
I0612 11:07:31.974676  5211 net.cpp:190] Creating Layer BatchNorm9
I0612 11:07:31.974684  5211 net.cpp:615] BatchNorm9 <- Convolution9
I0612 11:07:31.974696  5211 net.cpp:576] BatchNorm9 -> Convolution9 (in-place)
I0612 11:07:31.975090  5211 net.cpp:240] Setting up BatchNorm9
I0612 11:07:31.975102  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.975109  5211 net.cpp:255] Memory required for data: 379061760
I0612 11:07:31.975128  5211 layer_factory.hpp:77] Creating layer Scale9
I0612 11:07:31.975139  5211 net.cpp:190] Creating Layer Scale9
I0612 11:07:31.975147  5211 net.cpp:615] Scale9 <- Convolution9
I0612 11:07:31.975157  5211 net.cpp:576] Scale9 -> Convolution9 (in-place)
I0612 11:07:31.975224  5211 layer_factory.hpp:77] Creating layer Scale9
I0612 11:07:31.975452  5211 net.cpp:240] Setting up Scale9
I0612 11:07:31.975466  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.975472  5211 net.cpp:255] Memory required for data: 387450368
I0612 11:07:31.975487  5211 layer_factory.hpp:77] Creating layer Eltwise4
I0612 11:07:31.975498  5211 net.cpp:190] Creating Layer Eltwise4
I0612 11:07:31.975509  5211 net.cpp:615] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0612 11:07:31.975519  5211 net.cpp:615] Eltwise4 <- Convolution9
I0612 11:07:31.975530  5211 net.cpp:589] Eltwise4 -> Eltwise4
I0612 11:07:31.975575  5211 net.cpp:240] Setting up Eltwise4
I0612 11:07:31.975586  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.975592  5211 net.cpp:255] Memory required for data: 395838976
I0612 11:07:31.975600  5211 layer_factory.hpp:77] Creating layer ReLU9
I0612 11:07:31.975612  5211 net.cpp:190] Creating Layer ReLU9
I0612 11:07:31.975620  5211 net.cpp:615] ReLU9 <- Eltwise4
I0612 11:07:31.975630  5211 net.cpp:576] ReLU9 -> Eltwise4 (in-place)
I0612 11:07:31.975643  5211 net.cpp:240] Setting up ReLU9
I0612 11:07:31.975652  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.975659  5211 net.cpp:255] Memory required for data: 404227584
I0612 11:07:31.975666  5211 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0612 11:07:31.975675  5211 net.cpp:190] Creating Layer Eltwise4_ReLU9_0_split
I0612 11:07:31.975682  5211 net.cpp:615] Eltwise4_ReLU9_0_split <- Eltwise4
I0612 11:07:31.975690  5211 net.cpp:589] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0612 11:07:31.975703  5211 net.cpp:589] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0612 11:07:31.975771  5211 net.cpp:240] Setting up Eltwise4_ReLU9_0_split
I0612 11:07:31.975782  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.975791  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.975797  5211 net.cpp:255] Memory required for data: 421004800
I0612 11:07:31.975805  5211 layer_factory.hpp:77] Creating layer Convolution10
I0612 11:07:31.975821  5211 net.cpp:190] Creating Layer Convolution10
I0612 11:07:31.975829  5211 net.cpp:615] Convolution10 <- Eltwise4_ReLU9_0_split_0
I0612 11:07:31.975841  5211 net.cpp:589] Convolution10 -> Convolution10
I0612 11:07:31.976474  5211 net.cpp:240] Setting up Convolution10
I0612 11:07:31.976490  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.976500  5211 net.cpp:255] Memory required for data: 429393408
I0612 11:07:31.976537  5211 layer_factory.hpp:77] Creating layer BatchNorm10
I0612 11:07:31.976553  5211 net.cpp:190] Creating Layer BatchNorm10
I0612 11:07:31.976562  5211 net.cpp:615] BatchNorm10 <- Convolution10
I0612 11:07:31.976573  5211 net.cpp:576] BatchNorm10 -> Convolution10 (in-place)
I0612 11:07:31.976961  5211 net.cpp:240] Setting up BatchNorm10
I0612 11:07:31.976975  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.976982  5211 net.cpp:255] Memory required for data: 437782016
I0612 11:07:31.977001  5211 layer_factory.hpp:77] Creating layer Scale10
I0612 11:07:31.977012  5211 net.cpp:190] Creating Layer Scale10
I0612 11:07:31.977020  5211 net.cpp:615] Scale10 <- Convolution10
I0612 11:07:31.977033  5211 net.cpp:576] Scale10 -> Convolution10 (in-place)
I0612 11:07:31.977098  5211 layer_factory.hpp:77] Creating layer Scale10
I0612 11:07:31.977330  5211 net.cpp:240] Setting up Scale10
I0612 11:07:31.977344  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.977351  5211 net.cpp:255] Memory required for data: 446170624
I0612 11:07:31.977366  5211 layer_factory.hpp:77] Creating layer ReLU10
I0612 11:07:31.977380  5211 net.cpp:190] Creating Layer ReLU10
I0612 11:07:31.977388  5211 net.cpp:615] ReLU10 <- Convolution10
I0612 11:07:31.977398  5211 net.cpp:576] ReLU10 -> Convolution10 (in-place)
I0612 11:07:31.977411  5211 net.cpp:240] Setting up ReLU10
I0612 11:07:31.977421  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.977428  5211 net.cpp:255] Memory required for data: 454559232
I0612 11:07:31.977435  5211 layer_factory.hpp:77] Creating layer Convolution11
I0612 11:07:31.977453  5211 net.cpp:190] Creating Layer Convolution11
I0612 11:07:31.977460  5211 net.cpp:615] Convolution11 <- Convolution10
I0612 11:07:31.977471  5211 net.cpp:589] Convolution11 -> Convolution11
I0612 11:07:31.978096  5211 net.cpp:240] Setting up Convolution11
I0612 11:07:31.978111  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.978118  5211 net.cpp:255] Memory required for data: 462947840
I0612 11:07:31.978133  5211 layer_factory.hpp:77] Creating layer BatchNorm11
I0612 11:07:31.978144  5211 net.cpp:190] Creating Layer BatchNorm11
I0612 11:07:31.978152  5211 net.cpp:615] BatchNorm11 <- Convolution11
I0612 11:07:31.978164  5211 net.cpp:576] BatchNorm11 -> Convolution11 (in-place)
I0612 11:07:31.978564  5211 net.cpp:240] Setting up BatchNorm11
I0612 11:07:31.978579  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.978585  5211 net.cpp:255] Memory required for data: 471336448
I0612 11:07:31.978605  5211 layer_factory.hpp:77] Creating layer Scale11
I0612 11:07:31.978616  5211 net.cpp:190] Creating Layer Scale11
I0612 11:07:31.978624  5211 net.cpp:615] Scale11 <- Convolution11
I0612 11:07:31.978637  5211 net.cpp:576] Scale11 -> Convolution11 (in-place)
I0612 11:07:31.978708  5211 layer_factory.hpp:77] Creating layer Scale11
I0612 11:07:31.978935  5211 net.cpp:240] Setting up Scale11
I0612 11:07:31.978947  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.978953  5211 net.cpp:255] Memory required for data: 479725056
I0612 11:07:31.978967  5211 layer_factory.hpp:77] Creating layer Eltwise5
I0612 11:07:31.978981  5211 net.cpp:190] Creating Layer Eltwise5
I0612 11:07:31.978989  5211 net.cpp:615] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0612 11:07:31.978997  5211 net.cpp:615] Eltwise5 <- Convolution11
I0612 11:07:31.979007  5211 net.cpp:589] Eltwise5 -> Eltwise5
I0612 11:07:31.979054  5211 net.cpp:240] Setting up Eltwise5
I0612 11:07:31.979064  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.979070  5211 net.cpp:255] Memory required for data: 488113664
I0612 11:07:31.979076  5211 layer_factory.hpp:77] Creating layer ReLU11
I0612 11:07:31.979085  5211 net.cpp:190] Creating Layer ReLU11
I0612 11:07:31.979092  5211 net.cpp:615] ReLU11 <- Eltwise5
I0612 11:07:31.979104  5211 net.cpp:576] ReLU11 -> Eltwise5 (in-place)
I0612 11:07:31.979115  5211 net.cpp:240] Setting up ReLU11
I0612 11:07:31.979127  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.979133  5211 net.cpp:255] Memory required for data: 496502272
I0612 11:07:31.979140  5211 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0612 11:07:31.979148  5211 net.cpp:190] Creating Layer Eltwise5_ReLU11_0_split
I0612 11:07:31.979154  5211 net.cpp:615] Eltwise5_ReLU11_0_split <- Eltwise5
I0612 11:07:31.979162  5211 net.cpp:589] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0612 11:07:31.979174  5211 net.cpp:589] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0612 11:07:31.979241  5211 net.cpp:240] Setting up Eltwise5_ReLU11_0_split
I0612 11:07:31.979252  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.979261  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.979266  5211 net.cpp:255] Memory required for data: 513279488
I0612 11:07:31.979274  5211 layer_factory.hpp:77] Creating layer Convolution12
I0612 11:07:31.979290  5211 net.cpp:190] Creating Layer Convolution12
I0612 11:07:31.979297  5211 net.cpp:615] Convolution12 <- Eltwise5_ReLU11_0_split_0
I0612 11:07:31.979308  5211 net.cpp:589] Convolution12 -> Convolution12
I0612 11:07:31.979892  5211 net.cpp:240] Setting up Convolution12
I0612 11:07:31.979907  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.979912  5211 net.cpp:255] Memory required for data: 521668096
I0612 11:07:31.979928  5211 layer_factory.hpp:77] Creating layer BatchNorm12
I0612 11:07:31.979943  5211 net.cpp:190] Creating Layer BatchNorm12
I0612 11:07:31.979950  5211 net.cpp:615] BatchNorm12 <- Convolution12
I0612 11:07:31.979959  5211 net.cpp:576] BatchNorm12 -> Convolution12 (in-place)
I0612 11:07:31.980322  5211 net.cpp:240] Setting up BatchNorm12
I0612 11:07:31.980334  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.980340  5211 net.cpp:255] Memory required for data: 530056704
I0612 11:07:31.980360  5211 layer_factory.hpp:77] Creating layer Scale12
I0612 11:07:31.980371  5211 net.cpp:190] Creating Layer Scale12
I0612 11:07:31.980378  5211 net.cpp:615] Scale12 <- Convolution12
I0612 11:07:31.980387  5211 net.cpp:576] Scale12 -> Convolution12 (in-place)
I0612 11:07:31.980449  5211 layer_factory.hpp:77] Creating layer Scale12
I0612 11:07:31.980657  5211 net.cpp:240] Setting up Scale12
I0612 11:07:31.980669  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.980675  5211 net.cpp:255] Memory required for data: 538445312
I0612 11:07:31.980690  5211 layer_factory.hpp:77] Creating layer ReLU12
I0612 11:07:31.980706  5211 net.cpp:190] Creating Layer ReLU12
I0612 11:07:31.980713  5211 net.cpp:615] ReLU12 <- Convolution12
I0612 11:07:31.980722  5211 net.cpp:576] ReLU12 -> Convolution12 (in-place)
I0612 11:07:31.980733  5211 net.cpp:240] Setting up ReLU12
I0612 11:07:31.980742  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.980748  5211 net.cpp:255] Memory required for data: 546833920
I0612 11:07:31.980754  5211 layer_factory.hpp:77] Creating layer Convolution13
I0612 11:07:31.980770  5211 net.cpp:190] Creating Layer Convolution13
I0612 11:07:31.980777  5211 net.cpp:615] Convolution13 <- Convolution12
I0612 11:07:31.980787  5211 net.cpp:589] Convolution13 -> Convolution13
I0612 11:07:31.981369  5211 net.cpp:240] Setting up Convolution13
I0612 11:07:31.981382  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.981389  5211 net.cpp:255] Memory required for data: 555222528
I0612 11:07:31.981402  5211 layer_factory.hpp:77] Creating layer BatchNorm13
I0612 11:07:31.981415  5211 net.cpp:190] Creating Layer BatchNorm13
I0612 11:07:31.981422  5211 net.cpp:615] BatchNorm13 <- Convolution13
I0612 11:07:31.981433  5211 net.cpp:576] BatchNorm13 -> Convolution13 (in-place)
I0612 11:07:31.981806  5211 net.cpp:240] Setting up BatchNorm13
I0612 11:07:31.981819  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.981825  5211 net.cpp:255] Memory required for data: 563611136
I0612 11:07:31.981843  5211 layer_factory.hpp:77] Creating layer Scale13
I0612 11:07:31.981858  5211 net.cpp:190] Creating Layer Scale13
I0612 11:07:31.981866  5211 net.cpp:615] Scale13 <- Convolution13
I0612 11:07:31.981875  5211 net.cpp:576] Scale13 -> Convolution13 (in-place)
I0612 11:07:31.981942  5211 layer_factory.hpp:77] Creating layer Scale13
I0612 11:07:31.982153  5211 net.cpp:240] Setting up Scale13
I0612 11:07:31.982167  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.982172  5211 net.cpp:255] Memory required for data: 571999744
I0612 11:07:31.982189  5211 layer_factory.hpp:77] Creating layer Eltwise6
I0612 11:07:31.982210  5211 net.cpp:190] Creating Layer Eltwise6
I0612 11:07:31.982218  5211 net.cpp:615] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0612 11:07:31.982228  5211 net.cpp:615] Eltwise6 <- Convolution13
I0612 11:07:31.982237  5211 net.cpp:589] Eltwise6 -> Eltwise6
I0612 11:07:31.982285  5211 net.cpp:240] Setting up Eltwise6
I0612 11:07:31.982296  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.982303  5211 net.cpp:255] Memory required for data: 580388352
I0612 11:07:31.982311  5211 layer_factory.hpp:77] Creating layer ReLU13
I0612 11:07:31.982321  5211 net.cpp:190] Creating Layer ReLU13
I0612 11:07:31.982328  5211 net.cpp:615] ReLU13 <- Eltwise6
I0612 11:07:31.982337  5211 net.cpp:576] ReLU13 -> Eltwise6 (in-place)
I0612 11:07:31.982348  5211 net.cpp:240] Setting up ReLU13
I0612 11:07:31.982364  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.982372  5211 net.cpp:255] Memory required for data: 588776960
I0612 11:07:31.982378  5211 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0612 11:07:31.982386  5211 net.cpp:190] Creating Layer Eltwise6_ReLU13_0_split
I0612 11:07:31.982393  5211 net.cpp:615] Eltwise6_ReLU13_0_split <- Eltwise6
I0612 11:07:31.982401  5211 net.cpp:589] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0612 11:07:31.982417  5211 net.cpp:589] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0612 11:07:31.982481  5211 net.cpp:240] Setting up Eltwise6_ReLU13_0_split
I0612 11:07:31.982491  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.982501  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.982506  5211 net.cpp:255] Memory required for data: 605554176
I0612 11:07:31.982512  5211 layer_factory.hpp:77] Creating layer Convolution14
I0612 11:07:31.982533  5211 net.cpp:190] Creating Layer Convolution14
I0612 11:07:31.982540  5211 net.cpp:615] Convolution14 <- Eltwise6_ReLU13_0_split_0
I0612 11:07:31.982552  5211 net.cpp:589] Convolution14 -> Convolution14
I0612 11:07:31.983125  5211 net.cpp:240] Setting up Convolution14
I0612 11:07:31.983141  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.983149  5211 net.cpp:255] Memory required for data: 613942784
I0612 11:07:31.983162  5211 layer_factory.hpp:77] Creating layer BatchNorm14
I0612 11:07:31.983176  5211 net.cpp:190] Creating Layer BatchNorm14
I0612 11:07:31.983183  5211 net.cpp:615] BatchNorm14 <- Convolution14
I0612 11:07:31.983196  5211 net.cpp:576] BatchNorm14 -> Convolution14 (in-place)
I0612 11:07:31.983558  5211 net.cpp:240] Setting up BatchNorm14
I0612 11:07:31.983571  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.983577  5211 net.cpp:255] Memory required for data: 622331392
I0612 11:07:31.983593  5211 layer_factory.hpp:77] Creating layer Scale14
I0612 11:07:31.983606  5211 net.cpp:190] Creating Layer Scale14
I0612 11:07:31.983613  5211 net.cpp:615] Scale14 <- Convolution14
I0612 11:07:31.983623  5211 net.cpp:576] Scale14 -> Convolution14 (in-place)
I0612 11:07:31.983688  5211 layer_factory.hpp:77] Creating layer Scale14
I0612 11:07:31.983899  5211 net.cpp:240] Setting up Scale14
I0612 11:07:31.983911  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.983917  5211 net.cpp:255] Memory required for data: 630720000
I0612 11:07:31.983934  5211 layer_factory.hpp:77] Creating layer ReLU14
I0612 11:07:31.983944  5211 net.cpp:190] Creating Layer ReLU14
I0612 11:07:31.983952  5211 net.cpp:615] ReLU14 <- Convolution14
I0612 11:07:31.983960  5211 net.cpp:576] ReLU14 -> Convolution14 (in-place)
I0612 11:07:31.983976  5211 net.cpp:240] Setting up ReLU14
I0612 11:07:31.983985  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.983991  5211 net.cpp:255] Memory required for data: 639108608
I0612 11:07:31.983999  5211 layer_factory.hpp:77] Creating layer Convolution15
I0612 11:07:31.984015  5211 net.cpp:190] Creating Layer Convolution15
I0612 11:07:31.984022  5211 net.cpp:615] Convolution15 <- Convolution14
I0612 11:07:31.984035  5211 net.cpp:589] Convolution15 -> Convolution15
I0612 11:07:31.984693  5211 net.cpp:240] Setting up Convolution15
I0612 11:07:31.984709  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.984716  5211 net.cpp:255] Memory required for data: 647497216
I0612 11:07:31.984731  5211 layer_factory.hpp:77] Creating layer BatchNorm15
I0612 11:07:31.984745  5211 net.cpp:190] Creating Layer BatchNorm15
I0612 11:07:31.984752  5211 net.cpp:615] BatchNorm15 <- Convolution15
I0612 11:07:31.984765  5211 net.cpp:576] BatchNorm15 -> Convolution15 (in-place)
I0612 11:07:31.985126  5211 net.cpp:240] Setting up BatchNorm15
I0612 11:07:31.985137  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.985144  5211 net.cpp:255] Memory required for data: 655885824
I0612 11:07:31.985162  5211 layer_factory.hpp:77] Creating layer Scale15
I0612 11:07:31.985177  5211 net.cpp:190] Creating Layer Scale15
I0612 11:07:31.985184  5211 net.cpp:615] Scale15 <- Convolution15
I0612 11:07:31.985194  5211 net.cpp:576] Scale15 -> Convolution15 (in-place)
I0612 11:07:31.985255  5211 layer_factory.hpp:77] Creating layer Scale15
I0612 11:07:31.985466  5211 net.cpp:240] Setting up Scale15
I0612 11:07:31.985477  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.985483  5211 net.cpp:255] Memory required for data: 664274432
I0612 11:07:31.985497  5211 layer_factory.hpp:77] Creating layer Eltwise7
I0612 11:07:31.985508  5211 net.cpp:190] Creating Layer Eltwise7
I0612 11:07:31.985515  5211 net.cpp:615] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0612 11:07:31.985525  5211 net.cpp:615] Eltwise7 <- Convolution15
I0612 11:07:31.985538  5211 net.cpp:589] Eltwise7 -> Eltwise7
I0612 11:07:31.985584  5211 net.cpp:240] Setting up Eltwise7
I0612 11:07:31.985594  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.985600  5211 net.cpp:255] Memory required for data: 672663040
I0612 11:07:31.985606  5211 layer_factory.hpp:77] Creating layer ReLU15
I0612 11:07:31.985615  5211 net.cpp:190] Creating Layer ReLU15
I0612 11:07:31.985622  5211 net.cpp:615] ReLU15 <- Eltwise7
I0612 11:07:31.985630  5211 net.cpp:576] ReLU15 -> Eltwise7 (in-place)
I0612 11:07:31.985641  5211 net.cpp:240] Setting up ReLU15
I0612 11:07:31.985649  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.985656  5211 net.cpp:255] Memory required for data: 681051648
I0612 11:07:31.985661  5211 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0612 11:07:31.985673  5211 net.cpp:190] Creating Layer Eltwise7_ReLU15_0_split
I0612 11:07:31.985679  5211 net.cpp:615] Eltwise7_ReLU15_0_split <- Eltwise7
I0612 11:07:31.985688  5211 net.cpp:589] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0612 11:07:31.985699  5211 net.cpp:589] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0612 11:07:31.985764  5211 net.cpp:240] Setting up Eltwise7_ReLU15_0_split
I0612 11:07:31.985774  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.985782  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.985790  5211 net.cpp:255] Memory required for data: 697828864
I0612 11:07:31.985795  5211 layer_factory.hpp:77] Creating layer Convolution16
I0612 11:07:31.985810  5211 net.cpp:190] Creating Layer Convolution16
I0612 11:07:31.985817  5211 net.cpp:615] Convolution16 <- Eltwise7_ReLU15_0_split_0
I0612 11:07:31.985829  5211 net.cpp:589] Convolution16 -> Convolution16
I0612 11:07:31.986418  5211 net.cpp:240] Setting up Convolution16
I0612 11:07:31.986433  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.986438  5211 net.cpp:255] Memory required for data: 706217472
I0612 11:07:31.986457  5211 layer_factory.hpp:77] Creating layer BatchNorm16
I0612 11:07:31.986471  5211 net.cpp:190] Creating Layer BatchNorm16
I0612 11:07:31.986479  5211 net.cpp:615] BatchNorm16 <- Convolution16
I0612 11:07:31.986487  5211 net.cpp:576] BatchNorm16 -> Convolution16 (in-place)
I0612 11:07:31.986848  5211 net.cpp:240] Setting up BatchNorm16
I0612 11:07:31.986862  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.986868  5211 net.cpp:255] Memory required for data: 714606080
I0612 11:07:31.986886  5211 layer_factory.hpp:77] Creating layer Scale16
I0612 11:07:31.986896  5211 net.cpp:190] Creating Layer Scale16
I0612 11:07:31.986903  5211 net.cpp:615] Scale16 <- Convolution16
I0612 11:07:31.986912  5211 net.cpp:576] Scale16 -> Convolution16 (in-place)
I0612 11:07:31.986979  5211 layer_factory.hpp:77] Creating layer Scale16
I0612 11:07:31.987195  5211 net.cpp:240] Setting up Scale16
I0612 11:07:31.987207  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.987215  5211 net.cpp:255] Memory required for data: 722994688
I0612 11:07:31.987244  5211 layer_factory.hpp:77] Creating layer ReLU16
I0612 11:07:31.987257  5211 net.cpp:190] Creating Layer ReLU16
I0612 11:07:31.987264  5211 net.cpp:615] ReLU16 <- Convolution16
I0612 11:07:31.987273  5211 net.cpp:576] ReLU16 -> Convolution16 (in-place)
I0612 11:07:31.987285  5211 net.cpp:240] Setting up ReLU16
I0612 11:07:31.987294  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.987300  5211 net.cpp:255] Memory required for data: 731383296
I0612 11:07:31.987306  5211 layer_factory.hpp:77] Creating layer Convolution17
I0612 11:07:31.987323  5211 net.cpp:190] Creating Layer Convolution17
I0612 11:07:31.987330  5211 net.cpp:615] Convolution17 <- Convolution16
I0612 11:07:31.987344  5211 net.cpp:589] Convolution17 -> Convolution17
I0612 11:07:31.987931  5211 net.cpp:240] Setting up Convolution17
I0612 11:07:31.987944  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.987951  5211 net.cpp:255] Memory required for data: 739771904
I0612 11:07:31.987964  5211 layer_factory.hpp:77] Creating layer BatchNorm17
I0612 11:07:31.987975  5211 net.cpp:190] Creating Layer BatchNorm17
I0612 11:07:31.987982  5211 net.cpp:615] BatchNorm17 <- Convolution17
I0612 11:07:31.987994  5211 net.cpp:576] BatchNorm17 -> Convolution17 (in-place)
I0612 11:07:31.988355  5211 net.cpp:240] Setting up BatchNorm17
I0612 11:07:31.988368  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.988374  5211 net.cpp:255] Memory required for data: 748160512
I0612 11:07:31.988391  5211 layer_factory.hpp:77] Creating layer Scale17
I0612 11:07:31.988404  5211 net.cpp:190] Creating Layer Scale17
I0612 11:07:31.988410  5211 net.cpp:615] Scale17 <- Convolution17
I0612 11:07:31.988420  5211 net.cpp:576] Scale17 -> Convolution17 (in-place)
I0612 11:07:31.988482  5211 layer_factory.hpp:77] Creating layer Scale17
I0612 11:07:31.988689  5211 net.cpp:240] Setting up Scale17
I0612 11:07:31.988701  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.988708  5211 net.cpp:255] Memory required for data: 756549120
I0612 11:07:31.988723  5211 layer_factory.hpp:77] Creating layer Eltwise8
I0612 11:07:31.988732  5211 net.cpp:190] Creating Layer Eltwise8
I0612 11:07:31.988740  5211 net.cpp:615] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0612 11:07:31.988749  5211 net.cpp:615] Eltwise8 <- Convolution17
I0612 11:07:31.988765  5211 net.cpp:589] Eltwise8 -> Eltwise8
I0612 11:07:31.988807  5211 net.cpp:240] Setting up Eltwise8
I0612 11:07:31.988817  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.988823  5211 net.cpp:255] Memory required for data: 764937728
I0612 11:07:31.988829  5211 layer_factory.hpp:77] Creating layer ReLU17
I0612 11:07:31.988842  5211 net.cpp:190] Creating Layer ReLU17
I0612 11:07:31.988849  5211 net.cpp:615] ReLU17 <- Eltwise8
I0612 11:07:31.988857  5211 net.cpp:576] ReLU17 -> Eltwise8 (in-place)
I0612 11:07:31.988868  5211 net.cpp:240] Setting up ReLU17
I0612 11:07:31.988880  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.988888  5211 net.cpp:255] Memory required for data: 773326336
I0612 11:07:31.988893  5211 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0612 11:07:31.988905  5211 net.cpp:190] Creating Layer Eltwise8_ReLU17_0_split
I0612 11:07:31.988912  5211 net.cpp:615] Eltwise8_ReLU17_0_split <- Eltwise8
I0612 11:07:31.988921  5211 net.cpp:589] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0612 11:07:31.988934  5211 net.cpp:589] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0612 11:07:31.989001  5211 net.cpp:240] Setting up Eltwise8_ReLU17_0_split
I0612 11:07:31.989012  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.989019  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.989025  5211 net.cpp:255] Memory required for data: 790103552
I0612 11:07:31.989032  5211 layer_factory.hpp:77] Creating layer Convolution18
I0612 11:07:31.989048  5211 net.cpp:190] Creating Layer Convolution18
I0612 11:07:31.989055  5211 net.cpp:615] Convolution18 <- Eltwise8_ReLU17_0_split_0
I0612 11:07:31.989066  5211 net.cpp:589] Convolution18 -> Convolution18
I0612 11:07:31.989650  5211 net.cpp:240] Setting up Convolution18
I0612 11:07:31.989665  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.989670  5211 net.cpp:255] Memory required for data: 798492160
I0612 11:07:31.989684  5211 layer_factory.hpp:77] Creating layer BatchNorm18
I0612 11:07:31.989697  5211 net.cpp:190] Creating Layer BatchNorm18
I0612 11:07:31.989704  5211 net.cpp:615] BatchNorm18 <- Convolution18
I0612 11:07:31.989714  5211 net.cpp:576] BatchNorm18 -> Convolution18 (in-place)
I0612 11:07:31.990080  5211 net.cpp:240] Setting up BatchNorm18
I0612 11:07:31.990094  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.990100  5211 net.cpp:255] Memory required for data: 806880768
I0612 11:07:31.990121  5211 layer_factory.hpp:77] Creating layer Scale18
I0612 11:07:31.990134  5211 net.cpp:190] Creating Layer Scale18
I0612 11:07:31.990140  5211 net.cpp:615] Scale18 <- Convolution18
I0612 11:07:31.990154  5211 net.cpp:576] Scale18 -> Convolution18 (in-place)
I0612 11:07:31.990221  5211 layer_factory.hpp:77] Creating layer Scale18
I0612 11:07:31.990442  5211 net.cpp:240] Setting up Scale18
I0612 11:07:31.990458  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.990464  5211 net.cpp:255] Memory required for data: 815269376
I0612 11:07:31.990479  5211 layer_factory.hpp:77] Creating layer ReLU18
I0612 11:07:31.990492  5211 net.cpp:190] Creating Layer ReLU18
I0612 11:07:31.990499  5211 net.cpp:615] ReLU18 <- Convolution18
I0612 11:07:31.990509  5211 net.cpp:576] ReLU18 -> Convolution18 (in-place)
I0612 11:07:31.990520  5211 net.cpp:240] Setting up ReLU18
I0612 11:07:31.990527  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.990533  5211 net.cpp:255] Memory required for data: 823657984
I0612 11:07:31.990540  5211 layer_factory.hpp:77] Creating layer Convolution19
I0612 11:07:31.990556  5211 net.cpp:190] Creating Layer Convolution19
I0612 11:07:31.990563  5211 net.cpp:615] Convolution19 <- Convolution18
I0612 11:07:31.990573  5211 net.cpp:589] Convolution19 -> Convolution19
I0612 11:07:31.991125  5211 net.cpp:240] Setting up Convolution19
I0612 11:07:31.991139  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.991144  5211 net.cpp:255] Memory required for data: 832046592
I0612 11:07:31.991158  5211 layer_factory.hpp:77] Creating layer BatchNorm19
I0612 11:07:31.991170  5211 net.cpp:190] Creating Layer BatchNorm19
I0612 11:07:31.991178  5211 net.cpp:615] BatchNorm19 <- Convolution19
I0612 11:07:31.991186  5211 net.cpp:576] BatchNorm19 -> Convolution19 (in-place)
I0612 11:07:31.991528  5211 net.cpp:240] Setting up BatchNorm19
I0612 11:07:31.991539  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.991545  5211 net.cpp:255] Memory required for data: 840435200
I0612 11:07:31.991585  5211 layer_factory.hpp:77] Creating layer Scale19
I0612 11:07:31.991598  5211 net.cpp:190] Creating Layer Scale19
I0612 11:07:31.991610  5211 net.cpp:615] Scale19 <- Convolution19
I0612 11:07:31.991619  5211 net.cpp:576] Scale19 -> Convolution19 (in-place)
I0612 11:07:31.991680  5211 layer_factory.hpp:77] Creating layer Scale19
I0612 11:07:31.991885  5211 net.cpp:240] Setting up Scale19
I0612 11:07:31.991897  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.991904  5211 net.cpp:255] Memory required for data: 848823808
I0612 11:07:31.991916  5211 layer_factory.hpp:77] Creating layer Eltwise9
I0612 11:07:31.991926  5211 net.cpp:190] Creating Layer Eltwise9
I0612 11:07:31.991933  5211 net.cpp:615] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0612 11:07:31.991941  5211 net.cpp:615] Eltwise9 <- Convolution19
I0612 11:07:31.991950  5211 net.cpp:589] Eltwise9 -> Eltwise9
I0612 11:07:31.991991  5211 net.cpp:240] Setting up Eltwise9
I0612 11:07:31.991999  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.992005  5211 net.cpp:255] Memory required for data: 857212416
I0612 11:07:31.992010  5211 layer_factory.hpp:77] Creating layer ReLU19
I0612 11:07:31.992022  5211 net.cpp:190] Creating Layer ReLU19
I0612 11:07:31.992029  5211 net.cpp:615] ReLU19 <- Eltwise9
I0612 11:07:31.992040  5211 net.cpp:576] ReLU19 -> Eltwise9 (in-place)
I0612 11:07:31.992050  5211 net.cpp:240] Setting up ReLU19
I0612 11:07:31.992059  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.992064  5211 net.cpp:255] Memory required for data: 865601024
I0612 11:07:31.992070  5211 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0612 11:07:31.992079  5211 net.cpp:190] Creating Layer Eltwise9_ReLU19_0_split
I0612 11:07:31.992085  5211 net.cpp:615] Eltwise9_ReLU19_0_split <- Eltwise9
I0612 11:07:31.992094  5211 net.cpp:589] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0612 11:07:31.992105  5211 net.cpp:589] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0612 11:07:31.992166  5211 net.cpp:240] Setting up Eltwise9_ReLU19_0_split
I0612 11:07:31.992175  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.992182  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.992188  5211 net.cpp:255] Memory required for data: 882378240
I0612 11:07:31.992194  5211 layer_factory.hpp:77] Creating layer Convolution20
I0612 11:07:31.992208  5211 net.cpp:190] Creating Layer Convolution20
I0612 11:07:31.992215  5211 net.cpp:615] Convolution20 <- Eltwise9_ReLU19_0_split_0
I0612 11:07:31.992226  5211 net.cpp:589] Convolution20 -> Convolution20
I0612 11:07:31.992769  5211 net.cpp:240] Setting up Convolution20
I0612 11:07:31.992782  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.992789  5211 net.cpp:255] Memory required for data: 890766848
I0612 11:07:31.992802  5211 layer_factory.hpp:77] Creating layer BatchNorm20
I0612 11:07:31.992815  5211 net.cpp:190] Creating Layer BatchNorm20
I0612 11:07:31.992821  5211 net.cpp:615] BatchNorm20 <- Convolution20
I0612 11:07:31.992830  5211 net.cpp:576] BatchNorm20 -> Convolution20 (in-place)
I0612 11:07:31.993175  5211 net.cpp:240] Setting up BatchNorm20
I0612 11:07:31.993186  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.993192  5211 net.cpp:255] Memory required for data: 899155456
I0612 11:07:31.993209  5211 layer_factory.hpp:77] Creating layer Scale20
I0612 11:07:31.993227  5211 net.cpp:190] Creating Layer Scale20
I0612 11:07:31.993234  5211 net.cpp:615] Scale20 <- Convolution20
I0612 11:07:31.993243  5211 net.cpp:576] Scale20 -> Convolution20 (in-place)
I0612 11:07:31.993301  5211 layer_factory.hpp:77] Creating layer Scale20
I0612 11:07:31.993494  5211 net.cpp:240] Setting up Scale20
I0612 11:07:31.993507  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.993513  5211 net.cpp:255] Memory required for data: 907544064
I0612 11:07:31.993527  5211 layer_factory.hpp:77] Creating layer ReLU20
I0612 11:07:31.993537  5211 net.cpp:190] Creating Layer ReLU20
I0612 11:07:31.993544  5211 net.cpp:615] ReLU20 <- Convolution20
I0612 11:07:31.993553  5211 net.cpp:576] ReLU20 -> Convolution20 (in-place)
I0612 11:07:31.993568  5211 net.cpp:240] Setting up ReLU20
I0612 11:07:31.993577  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.993582  5211 net.cpp:255] Memory required for data: 915932672
I0612 11:07:31.993588  5211 layer_factory.hpp:77] Creating layer Convolution21
I0612 11:07:31.993603  5211 net.cpp:190] Creating Layer Convolution21
I0612 11:07:31.993610  5211 net.cpp:615] Convolution21 <- Convolution20
I0612 11:07:31.993623  5211 net.cpp:589] Convolution21 -> Convolution21
I0612 11:07:31.994174  5211 net.cpp:240] Setting up Convolution21
I0612 11:07:31.994186  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.994192  5211 net.cpp:255] Memory required for data: 924321280
I0612 11:07:31.994205  5211 layer_factory.hpp:77] Creating layer BatchNorm21
I0612 11:07:31.994218  5211 net.cpp:190] Creating Layer BatchNorm21
I0612 11:07:31.994225  5211 net.cpp:615] BatchNorm21 <- Convolution21
I0612 11:07:31.994235  5211 net.cpp:576] BatchNorm21 -> Convolution21 (in-place)
I0612 11:07:31.994586  5211 net.cpp:240] Setting up BatchNorm21
I0612 11:07:31.994599  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.994606  5211 net.cpp:255] Memory required for data: 932709888
I0612 11:07:31.994621  5211 layer_factory.hpp:77] Creating layer Scale21
I0612 11:07:31.994633  5211 net.cpp:190] Creating Layer Scale21
I0612 11:07:31.994642  5211 net.cpp:615] Scale21 <- Convolution21
I0612 11:07:31.994650  5211 net.cpp:576] Scale21 -> Convolution21 (in-place)
I0612 11:07:31.994710  5211 layer_factory.hpp:77] Creating layer Scale21
I0612 11:07:31.994904  5211 net.cpp:240] Setting up Scale21
I0612 11:07:31.994916  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.994921  5211 net.cpp:255] Memory required for data: 941098496
I0612 11:07:31.994935  5211 layer_factory.hpp:77] Creating layer Eltwise10
I0612 11:07:31.994946  5211 net.cpp:190] Creating Layer Eltwise10
I0612 11:07:31.994952  5211 net.cpp:615] Eltwise10 <- Eltwise9_ReLU19_0_split_1
I0612 11:07:31.994961  5211 net.cpp:615] Eltwise10 <- Convolution21
I0612 11:07:31.994981  5211 net.cpp:589] Eltwise10 -> Eltwise10
I0612 11:07:31.995024  5211 net.cpp:240] Setting up Eltwise10
I0612 11:07:31.995034  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.995040  5211 net.cpp:255] Memory required for data: 949487104
I0612 11:07:31.995046  5211 layer_factory.hpp:77] Creating layer ReLU21
I0612 11:07:31.995055  5211 net.cpp:190] Creating Layer ReLU21
I0612 11:07:31.995061  5211 net.cpp:615] ReLU21 <- Eltwise10
I0612 11:07:31.995069  5211 net.cpp:576] ReLU21 -> Eltwise10 (in-place)
I0612 11:07:31.995080  5211 net.cpp:240] Setting up ReLU21
I0612 11:07:31.995087  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.995093  5211 net.cpp:255] Memory required for data: 957875712
I0612 11:07:31.995100  5211 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0612 11:07:31.995106  5211 net.cpp:190] Creating Layer Eltwise10_ReLU21_0_split
I0612 11:07:31.995112  5211 net.cpp:615] Eltwise10_ReLU21_0_split <- Eltwise10
I0612 11:07:31.995123  5211 net.cpp:589] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0612 11:07:31.995134  5211 net.cpp:589] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0612 11:07:31.995193  5211 net.cpp:240] Setting up Eltwise10_ReLU21_0_split
I0612 11:07:31.995203  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.995209  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.995215  5211 net.cpp:255] Memory required for data: 974652928
I0612 11:07:31.995221  5211 layer_factory.hpp:77] Creating layer Convolution22
I0612 11:07:31.995234  5211 net.cpp:190] Creating Layer Convolution22
I0612 11:07:31.995241  5211 net.cpp:615] Convolution22 <- Eltwise10_ReLU21_0_split_0
I0612 11:07:31.995254  5211 net.cpp:589] Convolution22 -> Convolution22
I0612 11:07:31.995796  5211 net.cpp:240] Setting up Convolution22
I0612 11:07:31.995810  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.995815  5211 net.cpp:255] Memory required for data: 983041536
I0612 11:07:31.995833  5211 layer_factory.hpp:77] Creating layer BatchNorm22
I0612 11:07:31.995846  5211 net.cpp:190] Creating Layer BatchNorm22
I0612 11:07:31.995853  5211 net.cpp:615] BatchNorm22 <- Convolution22
I0612 11:07:31.995862  5211 net.cpp:576] BatchNorm22 -> Convolution22 (in-place)
I0612 11:07:31.996215  5211 net.cpp:240] Setting up BatchNorm22
I0612 11:07:31.996227  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.996233  5211 net.cpp:255] Memory required for data: 991430144
I0612 11:07:31.996259  5211 layer_factory.hpp:77] Creating layer Scale22
I0612 11:07:31.996270  5211 net.cpp:190] Creating Layer Scale22
I0612 11:07:31.996276  5211 net.cpp:615] Scale22 <- Convolution22
I0612 11:07:31.996285  5211 net.cpp:576] Scale22 -> Convolution22 (in-place)
I0612 11:07:31.996345  5211 layer_factory.hpp:77] Creating layer Scale22
I0612 11:07:31.996559  5211 net.cpp:240] Setting up Scale22
I0612 11:07:31.996573  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.996582  5211 net.cpp:255] Memory required for data: 999818752
I0612 11:07:31.996595  5211 layer_factory.hpp:77] Creating layer ReLU22
I0612 11:07:31.996608  5211 net.cpp:190] Creating Layer ReLU22
I0612 11:07:31.996614  5211 net.cpp:615] ReLU22 <- Convolution22
I0612 11:07:31.996623  5211 net.cpp:576] ReLU22 -> Convolution22 (in-place)
I0612 11:07:31.996634  5211 net.cpp:240] Setting up ReLU22
I0612 11:07:31.996641  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.996647  5211 net.cpp:255] Memory required for data: 1008207360
I0612 11:07:31.996654  5211 layer_factory.hpp:77] Creating layer Convolution23
I0612 11:07:31.996670  5211 net.cpp:190] Creating Layer Convolution23
I0612 11:07:31.996675  5211 net.cpp:615] Convolution23 <- Convolution22
I0612 11:07:31.996685  5211 net.cpp:589] Convolution23 -> Convolution23
I0612 11:07:31.997225  5211 net.cpp:240] Setting up Convolution23
I0612 11:07:31.997237  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.997243  5211 net.cpp:255] Memory required for data: 1016595968
I0612 11:07:31.997258  5211 layer_factory.hpp:77] Creating layer BatchNorm23
I0612 11:07:31.997270  5211 net.cpp:190] Creating Layer BatchNorm23
I0612 11:07:31.997278  5211 net.cpp:615] BatchNorm23 <- Convolution23
I0612 11:07:31.997287  5211 net.cpp:576] BatchNorm23 -> Convolution23 (in-place)
I0612 11:07:31.997632  5211 net.cpp:240] Setting up BatchNorm23
I0612 11:07:31.997643  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.997649  5211 net.cpp:255] Memory required for data: 1024984576
I0612 11:07:31.997665  5211 layer_factory.hpp:77] Creating layer Scale23
I0612 11:07:31.997675  5211 net.cpp:190] Creating Layer Scale23
I0612 11:07:31.997681  5211 net.cpp:615] Scale23 <- Convolution23
I0612 11:07:31.997690  5211 net.cpp:576] Scale23 -> Convolution23 (in-place)
I0612 11:07:31.997748  5211 layer_factory.hpp:77] Creating layer Scale23
I0612 11:07:31.997943  5211 net.cpp:240] Setting up Scale23
I0612 11:07:31.997954  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.997961  5211 net.cpp:255] Memory required for data: 1033373184
I0612 11:07:31.997973  5211 layer_factory.hpp:77] Creating layer Eltwise11
I0612 11:07:31.997985  5211 net.cpp:190] Creating Layer Eltwise11
I0612 11:07:31.997992  5211 net.cpp:615] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0612 11:07:31.998000  5211 net.cpp:615] Eltwise11 <- Convolution23
I0612 11:07:31.998011  5211 net.cpp:589] Eltwise11 -> Eltwise11
I0612 11:07:31.998055  5211 net.cpp:240] Setting up Eltwise11
I0612 11:07:31.998065  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.998071  5211 net.cpp:255] Memory required for data: 1041761792
I0612 11:07:31.998076  5211 layer_factory.hpp:77] Creating layer ReLU23
I0612 11:07:31.998085  5211 net.cpp:190] Creating Layer ReLU23
I0612 11:07:31.998091  5211 net.cpp:615] ReLU23 <- Eltwise11
I0612 11:07:31.998102  5211 net.cpp:576] ReLU23 -> Eltwise11 (in-place)
I0612 11:07:31.998112  5211 net.cpp:240] Setting up ReLU23
I0612 11:07:31.998124  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.998131  5211 net.cpp:255] Memory required for data: 1050150400
I0612 11:07:31.998136  5211 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0612 11:07:31.998144  5211 net.cpp:190] Creating Layer Eltwise11_ReLU23_0_split
I0612 11:07:31.998150  5211 net.cpp:615] Eltwise11_ReLU23_0_split <- Eltwise11
I0612 11:07:31.998158  5211 net.cpp:589] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0612 11:07:31.998169  5211 net.cpp:589] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0612 11:07:31.998229  5211 net.cpp:240] Setting up Eltwise11_ReLU23_0_split
I0612 11:07:31.998239  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.998245  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.998251  5211 net.cpp:255] Memory required for data: 1066927616
I0612 11:07:31.998257  5211 layer_factory.hpp:77] Creating layer Convolution24
I0612 11:07:31.998270  5211 net.cpp:190] Creating Layer Convolution24
I0612 11:07:31.998277  5211 net.cpp:615] Convolution24 <- Eltwise11_ReLU23_0_split_0
I0612 11:07:31.998294  5211 net.cpp:589] Convolution24 -> Convolution24
I0612 11:07:31.998842  5211 net.cpp:240] Setting up Convolution24
I0612 11:07:31.998855  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.998863  5211 net.cpp:255] Memory required for data: 1075316224
I0612 11:07:31.998878  5211 layer_factory.hpp:77] Creating layer BatchNorm24
I0612 11:07:31.998888  5211 net.cpp:190] Creating Layer BatchNorm24
I0612 11:07:31.998894  5211 net.cpp:615] BatchNorm24 <- Convolution24
I0612 11:07:31.998908  5211 net.cpp:576] BatchNorm24 -> Convolution24 (in-place)
I0612 11:07:31.999240  5211 net.cpp:240] Setting up BatchNorm24
I0612 11:07:31.999251  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.999258  5211 net.cpp:255] Memory required for data: 1083704832
I0612 11:07:31.999274  5211 layer_factory.hpp:77] Creating layer Scale24
I0612 11:07:31.999284  5211 net.cpp:190] Creating Layer Scale24
I0612 11:07:31.999289  5211 net.cpp:615] Scale24 <- Convolution24
I0612 11:07:31.999300  5211 net.cpp:576] Scale24 -> Convolution24 (in-place)
I0612 11:07:31.999362  5211 layer_factory.hpp:77] Creating layer Scale24
I0612 11:07:31.999552  5211 net.cpp:240] Setting up Scale24
I0612 11:07:31.999563  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.999569  5211 net.cpp:255] Memory required for data: 1092093440
I0612 11:07:31.999584  5211 layer_factory.hpp:77] Creating layer ReLU24
I0612 11:07:31.999596  5211 net.cpp:190] Creating Layer ReLU24
I0612 11:07:31.999603  5211 net.cpp:615] ReLU24 <- Convolution24
I0612 11:07:31.999613  5211 net.cpp:576] ReLU24 -> Convolution24 (in-place)
I0612 11:07:31.999622  5211 net.cpp:240] Setting up ReLU24
I0612 11:07:31.999630  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:31.999636  5211 net.cpp:255] Memory required for data: 1100482048
I0612 11:07:31.999641  5211 layer_factory.hpp:77] Creating layer Convolution25
I0612 11:07:31.999658  5211 net.cpp:190] Creating Layer Convolution25
I0612 11:07:31.999665  5211 net.cpp:615] Convolution25 <- Convolution24
I0612 11:07:31.999675  5211 net.cpp:589] Convolution25 -> Convolution25
I0612 11:07:32.000234  5211 net.cpp:240] Setting up Convolution25
I0612 11:07:32.000249  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.000255  5211 net.cpp:255] Memory required for data: 1108870656
I0612 11:07:32.000269  5211 layer_factory.hpp:77] Creating layer BatchNorm25
I0612 11:07:32.000282  5211 net.cpp:190] Creating Layer BatchNorm25
I0612 11:07:32.000288  5211 net.cpp:615] BatchNorm25 <- Convolution25
I0612 11:07:32.000298  5211 net.cpp:576] BatchNorm25 -> Convolution25 (in-place)
I0612 11:07:32.000644  5211 net.cpp:240] Setting up BatchNorm25
I0612 11:07:32.000655  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.000661  5211 net.cpp:255] Memory required for data: 1117259264
I0612 11:07:32.000679  5211 layer_factory.hpp:77] Creating layer Scale25
I0612 11:07:32.000694  5211 net.cpp:190] Creating Layer Scale25
I0612 11:07:32.000700  5211 net.cpp:615] Scale25 <- Convolution25
I0612 11:07:32.000712  5211 net.cpp:576] Scale25 -> Convolution25 (in-place)
I0612 11:07:32.000768  5211 layer_factory.hpp:77] Creating layer Scale25
I0612 11:07:32.000968  5211 net.cpp:240] Setting up Scale25
I0612 11:07:32.000979  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.000985  5211 net.cpp:255] Memory required for data: 1125647872
I0612 11:07:32.001001  5211 layer_factory.hpp:77] Creating layer Eltwise12
I0612 11:07:32.001011  5211 net.cpp:190] Creating Layer Eltwise12
I0612 11:07:32.001019  5211 net.cpp:615] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0612 11:07:32.001026  5211 net.cpp:615] Eltwise12 <- Convolution25
I0612 11:07:32.001035  5211 net.cpp:589] Eltwise12 -> Eltwise12
I0612 11:07:32.001088  5211 net.cpp:240] Setting up Eltwise12
I0612 11:07:32.001101  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.001106  5211 net.cpp:255] Memory required for data: 1134036480
I0612 11:07:32.001112  5211 layer_factory.hpp:77] Creating layer ReLU25
I0612 11:07:32.001122  5211 net.cpp:190] Creating Layer ReLU25
I0612 11:07:32.001129  5211 net.cpp:615] ReLU25 <- Eltwise12
I0612 11:07:32.001140  5211 net.cpp:576] ReLU25 -> Eltwise12 (in-place)
I0612 11:07:32.001152  5211 net.cpp:240] Setting up ReLU25
I0612 11:07:32.001162  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.001166  5211 net.cpp:255] Memory required for data: 1142425088
I0612 11:07:32.001173  5211 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I0612 11:07:32.001180  5211 net.cpp:190] Creating Layer Eltwise12_ReLU25_0_split
I0612 11:07:32.001186  5211 net.cpp:615] Eltwise12_ReLU25_0_split <- Eltwise12
I0612 11:07:32.001195  5211 net.cpp:589] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I0612 11:07:32.001206  5211 net.cpp:589] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I0612 11:07:32.001272  5211 net.cpp:240] Setting up Eltwise12_ReLU25_0_split
I0612 11:07:32.001281  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.001289  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.001296  5211 net.cpp:255] Memory required for data: 1159202304
I0612 11:07:32.001301  5211 layer_factory.hpp:77] Creating layer Convolution26
I0612 11:07:32.001313  5211 net.cpp:190] Creating Layer Convolution26
I0612 11:07:32.001320  5211 net.cpp:615] Convolution26 <- Eltwise12_ReLU25_0_split_0
I0612 11:07:32.001333  5211 net.cpp:589] Convolution26 -> Convolution26
I0612 11:07:32.001871  5211 net.cpp:240] Setting up Convolution26
I0612 11:07:32.001884  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.001890  5211 net.cpp:255] Memory required for data: 1167590912
I0612 11:07:32.001905  5211 layer_factory.hpp:77] Creating layer BatchNorm26
I0612 11:07:32.001934  5211 net.cpp:190] Creating Layer BatchNorm26
I0612 11:07:32.001941  5211 net.cpp:615] BatchNorm26 <- Convolution26
I0612 11:07:32.001951  5211 net.cpp:576] BatchNorm26 -> Convolution26 (in-place)
I0612 11:07:32.002290  5211 net.cpp:240] Setting up BatchNorm26
I0612 11:07:32.002302  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.002307  5211 net.cpp:255] Memory required for data: 1175979520
I0612 11:07:32.002324  5211 layer_factory.hpp:77] Creating layer Scale26
I0612 11:07:32.002337  5211 net.cpp:190] Creating Layer Scale26
I0612 11:07:32.002344  5211 net.cpp:615] Scale26 <- Convolution26
I0612 11:07:32.002362  5211 net.cpp:576] Scale26 -> Convolution26 (in-place)
I0612 11:07:32.002432  5211 layer_factory.hpp:77] Creating layer Scale26
I0612 11:07:32.002645  5211 net.cpp:240] Setting up Scale26
I0612 11:07:32.002657  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.002663  5211 net.cpp:255] Memory required for data: 1184368128
I0612 11:07:32.002676  5211 layer_factory.hpp:77] Creating layer ReLU26
I0612 11:07:32.002686  5211 net.cpp:190] Creating Layer ReLU26
I0612 11:07:32.002691  5211 net.cpp:615] ReLU26 <- Convolution26
I0612 11:07:32.002707  5211 net.cpp:576] ReLU26 -> Convolution26 (in-place)
I0612 11:07:32.002717  5211 net.cpp:240] Setting up ReLU26
I0612 11:07:32.002724  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.002729  5211 net.cpp:255] Memory required for data: 1192756736
I0612 11:07:32.002735  5211 layer_factory.hpp:77] Creating layer Convolution27
I0612 11:07:32.002749  5211 net.cpp:190] Creating Layer Convolution27
I0612 11:07:32.002755  5211 net.cpp:615] Convolution27 <- Convolution26
I0612 11:07:32.002764  5211 net.cpp:589] Convolution27 -> Convolution27
I0612 11:07:32.003280  5211 net.cpp:240] Setting up Convolution27
I0612 11:07:32.003293  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.003298  5211 net.cpp:255] Memory required for data: 1201145344
I0612 11:07:32.003310  5211 layer_factory.hpp:77] Creating layer BatchNorm27
I0612 11:07:32.003321  5211 net.cpp:190] Creating Layer BatchNorm27
I0612 11:07:32.003329  5211 net.cpp:615] BatchNorm27 <- Convolution27
I0612 11:07:32.003336  5211 net.cpp:576] BatchNorm27 -> Convolution27 (in-place)
I0612 11:07:32.003649  5211 net.cpp:240] Setting up BatchNorm27
I0612 11:07:32.003659  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.003665  5211 net.cpp:255] Memory required for data: 1209533952
I0612 11:07:32.003684  5211 layer_factory.hpp:77] Creating layer Scale27
I0612 11:07:32.003693  5211 net.cpp:190] Creating Layer Scale27
I0612 11:07:32.003700  5211 net.cpp:615] Scale27 <- Convolution27
I0612 11:07:32.003707  5211 net.cpp:576] Scale27 -> Convolution27 (in-place)
I0612 11:07:32.003762  5211 layer_factory.hpp:77] Creating layer Scale27
I0612 11:07:32.004684  5211 net.cpp:240] Setting up Scale27
I0612 11:07:32.004703  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.004709  5211 net.cpp:255] Memory required for data: 1217922560
I0612 11:07:32.004724  5211 layer_factory.hpp:77] Creating layer Eltwise13
I0612 11:07:32.004737  5211 net.cpp:190] Creating Layer Eltwise13
I0612 11:07:32.004745  5211 net.cpp:615] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I0612 11:07:32.004752  5211 net.cpp:615] Eltwise13 <- Convolution27
I0612 11:07:32.004762  5211 net.cpp:589] Eltwise13 -> Eltwise13
I0612 11:07:32.004807  5211 net.cpp:240] Setting up Eltwise13
I0612 11:07:32.004818  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.004823  5211 net.cpp:255] Memory required for data: 1226311168
I0612 11:07:32.004829  5211 layer_factory.hpp:77] Creating layer ReLU27
I0612 11:07:32.004838  5211 net.cpp:190] Creating Layer ReLU27
I0612 11:07:32.004844  5211 net.cpp:615] ReLU27 <- Eltwise13
I0612 11:07:32.004853  5211 net.cpp:576] ReLU27 -> Eltwise13 (in-place)
I0612 11:07:32.004864  5211 net.cpp:240] Setting up ReLU27
I0612 11:07:32.004871  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.004878  5211 net.cpp:255] Memory required for data: 1234699776
I0612 11:07:32.004884  5211 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I0612 11:07:32.004891  5211 net.cpp:190] Creating Layer Eltwise13_ReLU27_0_split
I0612 11:07:32.004897  5211 net.cpp:615] Eltwise13_ReLU27_0_split <- Eltwise13
I0612 11:07:32.004905  5211 net.cpp:589] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I0612 11:07:32.004916  5211 net.cpp:589] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I0612 11:07:32.004974  5211 net.cpp:240] Setting up Eltwise13_ReLU27_0_split
I0612 11:07:32.004984  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.004992  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.004997  5211 net.cpp:255] Memory required for data: 1251476992
I0612 11:07:32.005002  5211 layer_factory.hpp:77] Creating layer Convolution28
I0612 11:07:32.005017  5211 net.cpp:190] Creating Layer Convolution28
I0612 11:07:32.005024  5211 net.cpp:615] Convolution28 <- Eltwise13_ReLU27_0_split_0
I0612 11:07:32.005034  5211 net.cpp:589] Convolution28 -> Convolution28
I0612 11:07:32.005553  5211 net.cpp:240] Setting up Convolution28
I0612 11:07:32.005565  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.005575  5211 net.cpp:255] Memory required for data: 1259865600
I0612 11:07:32.005589  5211 layer_factory.hpp:77] Creating layer BatchNorm28
I0612 11:07:32.005601  5211 net.cpp:190] Creating Layer BatchNorm28
I0612 11:07:32.005609  5211 net.cpp:615] BatchNorm28 <- Convolution28
I0612 11:07:32.005617  5211 net.cpp:576] BatchNorm28 -> Convolution28 (in-place)
I0612 11:07:32.005946  5211 net.cpp:240] Setting up BatchNorm28
I0612 11:07:32.005957  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.005962  5211 net.cpp:255] Memory required for data: 1268254208
I0612 11:07:32.005978  5211 layer_factory.hpp:77] Creating layer Scale28
I0612 11:07:32.005992  5211 net.cpp:190] Creating Layer Scale28
I0612 11:07:32.006000  5211 net.cpp:615] Scale28 <- Convolution28
I0612 11:07:32.006007  5211 net.cpp:576] Scale28 -> Convolution28 (in-place)
I0612 11:07:32.006062  5211 layer_factory.hpp:77] Creating layer Scale28
I0612 11:07:32.006256  5211 net.cpp:240] Setting up Scale28
I0612 11:07:32.006270  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.006276  5211 net.cpp:255] Memory required for data: 1276642816
I0612 11:07:32.006289  5211 layer_factory.hpp:77] Creating layer ReLU28
I0612 11:07:32.006299  5211 net.cpp:190] Creating Layer ReLU28
I0612 11:07:32.006304  5211 net.cpp:615] ReLU28 <- Convolution28
I0612 11:07:32.006312  5211 net.cpp:576] ReLU28 -> Convolution28 (in-place)
I0612 11:07:32.006322  5211 net.cpp:240] Setting up ReLU28
I0612 11:07:32.006330  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.006335  5211 net.cpp:255] Memory required for data: 1285031424
I0612 11:07:32.006340  5211 layer_factory.hpp:77] Creating layer Convolution29
I0612 11:07:32.006362  5211 net.cpp:190] Creating Layer Convolution29
I0612 11:07:32.006369  5211 net.cpp:615] Convolution29 <- Convolution28
I0612 11:07:32.006381  5211 net.cpp:589] Convolution29 -> Convolution29
I0612 11:07:32.006901  5211 net.cpp:240] Setting up Convolution29
I0612 11:07:32.006914  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.006919  5211 net.cpp:255] Memory required for data: 1293420032
I0612 11:07:32.006932  5211 layer_factory.hpp:77] Creating layer BatchNorm29
I0612 11:07:32.006945  5211 net.cpp:190] Creating Layer BatchNorm29
I0612 11:07:32.006953  5211 net.cpp:615] BatchNorm29 <- Convolution29
I0612 11:07:32.006963  5211 net.cpp:576] BatchNorm29 -> Convolution29 (in-place)
I0612 11:07:32.007290  5211 net.cpp:240] Setting up BatchNorm29
I0612 11:07:32.007300  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.007307  5211 net.cpp:255] Memory required for data: 1301808640
I0612 11:07:32.007321  5211 layer_factory.hpp:77] Creating layer Scale29
I0612 11:07:32.007333  5211 net.cpp:190] Creating Layer Scale29
I0612 11:07:32.007340  5211 net.cpp:615] Scale29 <- Convolution29
I0612 11:07:32.007349  5211 net.cpp:576] Scale29 -> Convolution29 (in-place)
I0612 11:07:32.007403  5211 layer_factory.hpp:77] Creating layer Scale29
I0612 11:07:32.007596  5211 net.cpp:240] Setting up Scale29
I0612 11:07:32.007606  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.007611  5211 net.cpp:255] Memory required for data: 1310197248
I0612 11:07:32.007623  5211 layer_factory.hpp:77] Creating layer Eltwise14
I0612 11:07:32.007632  5211 net.cpp:190] Creating Layer Eltwise14
I0612 11:07:32.007639  5211 net.cpp:615] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I0612 11:07:32.007647  5211 net.cpp:615] Eltwise14 <- Convolution29
I0612 11:07:32.007655  5211 net.cpp:589] Eltwise14 -> Eltwise14
I0612 11:07:32.007696  5211 net.cpp:240] Setting up Eltwise14
I0612 11:07:32.007706  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.007711  5211 net.cpp:255] Memory required for data: 1318585856
I0612 11:07:32.007717  5211 layer_factory.hpp:77] Creating layer ReLU29
I0612 11:07:32.007727  5211 net.cpp:190] Creating Layer ReLU29
I0612 11:07:32.007733  5211 net.cpp:615] ReLU29 <- Eltwise14
I0612 11:07:32.007740  5211 net.cpp:576] ReLU29 -> Eltwise14 (in-place)
I0612 11:07:32.007753  5211 net.cpp:240] Setting up ReLU29
I0612 11:07:32.007761  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.007767  5211 net.cpp:255] Memory required for data: 1326974464
I0612 11:07:32.007772  5211 layer_factory.hpp:77] Creating layer Eltwise14_ReLU29_0_split
I0612 11:07:32.007781  5211 net.cpp:190] Creating Layer Eltwise14_ReLU29_0_split
I0612 11:07:32.007786  5211 net.cpp:615] Eltwise14_ReLU29_0_split <- Eltwise14
I0612 11:07:32.007797  5211 net.cpp:589] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_0
I0612 11:07:32.007807  5211 net.cpp:589] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_1
I0612 11:07:32.007861  5211 net.cpp:240] Setting up Eltwise14_ReLU29_0_split
I0612 11:07:32.007870  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.007877  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.007882  5211 net.cpp:255] Memory required for data: 1343751680
I0612 11:07:32.007887  5211 layer_factory.hpp:77] Creating layer Convolution30
I0612 11:07:32.007904  5211 net.cpp:190] Creating Layer Convolution30
I0612 11:07:32.007910  5211 net.cpp:615] Convolution30 <- Eltwise14_ReLU29_0_split_0
I0612 11:07:32.007920  5211 net.cpp:589] Convolution30 -> Convolution30
I0612 11:07:32.008425  5211 net.cpp:240] Setting up Convolution30
I0612 11:07:32.008436  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.008442  5211 net.cpp:255] Memory required for data: 1352140288
I0612 11:07:32.008455  5211 layer_factory.hpp:77] Creating layer BatchNorm30
I0612 11:07:32.008466  5211 net.cpp:190] Creating Layer BatchNorm30
I0612 11:07:32.008473  5211 net.cpp:615] BatchNorm30 <- Convolution30
I0612 11:07:32.008481  5211 net.cpp:576] BatchNorm30 -> Convolution30 (in-place)
I0612 11:07:32.008790  5211 net.cpp:240] Setting up BatchNorm30
I0612 11:07:32.008800  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.008805  5211 net.cpp:255] Memory required for data: 1360528896
I0612 11:07:32.008822  5211 layer_factory.hpp:77] Creating layer Scale30
I0612 11:07:32.008833  5211 net.cpp:190] Creating Layer Scale30
I0612 11:07:32.008839  5211 net.cpp:615] Scale30 <- Convolution30
I0612 11:07:32.008848  5211 net.cpp:576] Scale30 -> Convolution30 (in-place)
I0612 11:07:32.008903  5211 layer_factory.hpp:77] Creating layer Scale30
I0612 11:07:32.009085  5211 net.cpp:240] Setting up Scale30
I0612 11:07:32.009095  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.009100  5211 net.cpp:255] Memory required for data: 1368917504
I0612 11:07:32.009112  5211 layer_factory.hpp:77] Creating layer ReLU30
I0612 11:07:32.009124  5211 net.cpp:190] Creating Layer ReLU30
I0612 11:07:32.009130  5211 net.cpp:615] ReLU30 <- Convolution30
I0612 11:07:32.009138  5211 net.cpp:576] ReLU30 -> Convolution30 (in-place)
I0612 11:07:32.009148  5211 net.cpp:240] Setting up ReLU30
I0612 11:07:32.009155  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.009161  5211 net.cpp:255] Memory required for data: 1377306112
I0612 11:07:32.009166  5211 layer_factory.hpp:77] Creating layer Convolution31
I0612 11:07:32.009181  5211 net.cpp:190] Creating Layer Convolution31
I0612 11:07:32.009186  5211 net.cpp:615] Convolution31 <- Convolution30
I0612 11:07:32.009196  5211 net.cpp:589] Convolution31 -> Convolution31
I0612 11:07:32.009699  5211 net.cpp:240] Setting up Convolution31
I0612 11:07:32.009711  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.009716  5211 net.cpp:255] Memory required for data: 1385694720
I0612 11:07:32.009729  5211 layer_factory.hpp:77] Creating layer BatchNorm31
I0612 11:07:32.009740  5211 net.cpp:190] Creating Layer BatchNorm31
I0612 11:07:32.009747  5211 net.cpp:615] BatchNorm31 <- Convolution31
I0612 11:07:32.009755  5211 net.cpp:576] BatchNorm31 -> Convolution31 (in-place)
I0612 11:07:32.010076  5211 net.cpp:240] Setting up BatchNorm31
I0612 11:07:32.010087  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.010092  5211 net.cpp:255] Memory required for data: 1394083328
I0612 11:07:32.010107  5211 layer_factory.hpp:77] Creating layer Scale31
I0612 11:07:32.010119  5211 net.cpp:190] Creating Layer Scale31
I0612 11:07:32.010126  5211 net.cpp:615] Scale31 <- Convolution31
I0612 11:07:32.010134  5211 net.cpp:576] Scale31 -> Convolution31 (in-place)
I0612 11:07:32.010190  5211 layer_factory.hpp:77] Creating layer Scale31
I0612 11:07:32.010375  5211 net.cpp:240] Setting up Scale31
I0612 11:07:32.010385  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.010391  5211 net.cpp:255] Memory required for data: 1402471936
I0612 11:07:32.010407  5211 layer_factory.hpp:77] Creating layer Eltwise15
I0612 11:07:32.010419  5211 net.cpp:190] Creating Layer Eltwise15
I0612 11:07:32.010426  5211 net.cpp:615] Eltwise15 <- Eltwise14_ReLU29_0_split_1
I0612 11:07:32.010434  5211 net.cpp:615] Eltwise15 <- Convolution31
I0612 11:07:32.010444  5211 net.cpp:589] Eltwise15 -> Eltwise15
I0612 11:07:32.010483  5211 net.cpp:240] Setting up Eltwise15
I0612 11:07:32.010493  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.010498  5211 net.cpp:255] Memory required for data: 1410860544
I0612 11:07:32.010502  5211 layer_factory.hpp:77] Creating layer ReLU31
I0612 11:07:32.010510  5211 net.cpp:190] Creating Layer ReLU31
I0612 11:07:32.010516  5211 net.cpp:615] ReLU31 <- Eltwise15
I0612 11:07:32.010529  5211 net.cpp:576] ReLU31 -> Eltwise15 (in-place)
I0612 11:07:32.010540  5211 net.cpp:240] Setting up ReLU31
I0612 11:07:32.010546  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.010551  5211 net.cpp:255] Memory required for data: 1419249152
I0612 11:07:32.010557  5211 layer_factory.hpp:77] Creating layer Eltwise15_ReLU31_0_split
I0612 11:07:32.010565  5211 net.cpp:190] Creating Layer Eltwise15_ReLU31_0_split
I0612 11:07:32.010571  5211 net.cpp:615] Eltwise15_ReLU31_0_split <- Eltwise15
I0612 11:07:32.010578  5211 net.cpp:589] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_0
I0612 11:07:32.010588  5211 net.cpp:589] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_1
I0612 11:07:32.010645  5211 net.cpp:240] Setting up Eltwise15_ReLU31_0_split
I0612 11:07:32.010654  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.010661  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.010666  5211 net.cpp:255] Memory required for data: 1436026368
I0612 11:07:32.010671  5211 layer_factory.hpp:77] Creating layer Convolution32
I0612 11:07:32.010684  5211 net.cpp:190] Creating Layer Convolution32
I0612 11:07:32.010690  5211 net.cpp:615] Convolution32 <- Eltwise15_ReLU31_0_split_0
I0612 11:07:32.010704  5211 net.cpp:589] Convolution32 -> Convolution32
I0612 11:07:32.011215  5211 net.cpp:240] Setting up Convolution32
I0612 11:07:32.011227  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.011234  5211 net.cpp:255] Memory required for data: 1444414976
I0612 11:07:32.011246  5211 layer_factory.hpp:77] Creating layer BatchNorm32
I0612 11:07:32.011256  5211 net.cpp:190] Creating Layer BatchNorm32
I0612 11:07:32.011262  5211 net.cpp:615] BatchNorm32 <- Convolution32
I0612 11:07:32.011273  5211 net.cpp:576] BatchNorm32 -> Convolution32 (in-place)
I0612 11:07:32.011587  5211 net.cpp:240] Setting up BatchNorm32
I0612 11:07:32.011597  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.011603  5211 net.cpp:255] Memory required for data: 1452803584
I0612 11:07:32.011618  5211 layer_factory.hpp:77] Creating layer Scale32
I0612 11:07:32.011627  5211 net.cpp:190] Creating Layer Scale32
I0612 11:07:32.011633  5211 net.cpp:615] Scale32 <- Convolution32
I0612 11:07:32.011641  5211 net.cpp:576] Scale32 -> Convolution32 (in-place)
I0612 11:07:32.011698  5211 layer_factory.hpp:77] Creating layer Scale32
I0612 11:07:32.011878  5211 net.cpp:240] Setting up Scale32
I0612 11:07:32.011888  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.011893  5211 net.cpp:255] Memory required for data: 1461192192
I0612 11:07:32.011905  5211 layer_factory.hpp:77] Creating layer ReLU32
I0612 11:07:32.011914  5211 net.cpp:190] Creating Layer ReLU32
I0612 11:07:32.011920  5211 net.cpp:615] ReLU32 <- Convolution32
I0612 11:07:32.011935  5211 net.cpp:576] ReLU32 -> Convolution32 (in-place)
I0612 11:07:32.011946  5211 net.cpp:240] Setting up ReLU32
I0612 11:07:32.011955  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.011960  5211 net.cpp:255] Memory required for data: 1469580800
I0612 11:07:32.011965  5211 layer_factory.hpp:77] Creating layer Convolution33
I0612 11:07:32.011976  5211 net.cpp:190] Creating Layer Convolution33
I0612 11:07:32.011982  5211 net.cpp:615] Convolution33 <- Convolution32
I0612 11:07:32.011994  5211 net.cpp:589] Convolution33 -> Convolution33
I0612 11:07:32.012501  5211 net.cpp:240] Setting up Convolution33
I0612 11:07:32.012513  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.012518  5211 net.cpp:255] Memory required for data: 1477969408
I0612 11:07:32.012531  5211 layer_factory.hpp:77] Creating layer BatchNorm33
I0612 11:07:32.012542  5211 net.cpp:190] Creating Layer BatchNorm33
I0612 11:07:32.012547  5211 net.cpp:615] BatchNorm33 <- Convolution33
I0612 11:07:32.012557  5211 net.cpp:576] BatchNorm33 -> Convolution33 (in-place)
I0612 11:07:32.012876  5211 net.cpp:240] Setting up BatchNorm33
I0612 11:07:32.012887  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.012892  5211 net.cpp:255] Memory required for data: 1486358016
I0612 11:07:32.012908  5211 layer_factory.hpp:77] Creating layer Scale33
I0612 11:07:32.012917  5211 net.cpp:190] Creating Layer Scale33
I0612 11:07:32.012923  5211 net.cpp:615] Scale33 <- Convolution33
I0612 11:07:32.012933  5211 net.cpp:576] Scale33 -> Convolution33 (in-place)
I0612 11:07:32.012985  5211 layer_factory.hpp:77] Creating layer Scale33
I0612 11:07:32.013166  5211 net.cpp:240] Setting up Scale33
I0612 11:07:32.013176  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.013181  5211 net.cpp:255] Memory required for data: 1494746624
I0612 11:07:32.013195  5211 layer_factory.hpp:77] Creating layer Eltwise16
I0612 11:07:32.013206  5211 net.cpp:190] Creating Layer Eltwise16
I0612 11:07:32.013212  5211 net.cpp:615] Eltwise16 <- Eltwise15_ReLU31_0_split_1
I0612 11:07:32.013221  5211 net.cpp:615] Eltwise16 <- Convolution33
I0612 11:07:32.013228  5211 net.cpp:589] Eltwise16 -> Eltwise16
I0612 11:07:32.013267  5211 net.cpp:240] Setting up Eltwise16
I0612 11:07:32.013278  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.013283  5211 net.cpp:255] Memory required for data: 1503135232
I0612 11:07:32.013288  5211 layer_factory.hpp:77] Creating layer ReLU33
I0612 11:07:32.013295  5211 net.cpp:190] Creating Layer ReLU33
I0612 11:07:32.013301  5211 net.cpp:615] ReLU33 <- Eltwise16
I0612 11:07:32.013312  5211 net.cpp:576] ReLU33 -> Eltwise16 (in-place)
I0612 11:07:32.013322  5211 net.cpp:240] Setting up ReLU33
I0612 11:07:32.013329  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.013335  5211 net.cpp:255] Memory required for data: 1511523840
I0612 11:07:32.013340  5211 layer_factory.hpp:77] Creating layer Eltwise16_ReLU33_0_split
I0612 11:07:32.013348  5211 net.cpp:190] Creating Layer Eltwise16_ReLU33_0_split
I0612 11:07:32.013353  5211 net.cpp:615] Eltwise16_ReLU33_0_split <- Eltwise16
I0612 11:07:32.013361  5211 net.cpp:589] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_0
I0612 11:07:32.013371  5211 net.cpp:589] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_1
I0612 11:07:32.013427  5211 net.cpp:240] Setting up Eltwise16_ReLU33_0_split
I0612 11:07:32.013437  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.013443  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.013449  5211 net.cpp:255] Memory required for data: 1528301056
I0612 11:07:32.013454  5211 layer_factory.hpp:77] Creating layer Convolution34
I0612 11:07:32.013468  5211 net.cpp:190] Creating Layer Convolution34
I0612 11:07:32.013474  5211 net.cpp:615] Convolution34 <- Eltwise16_ReLU33_0_split_0
I0612 11:07:32.013484  5211 net.cpp:589] Convolution34 -> Convolution34
I0612 11:07:32.013981  5211 net.cpp:240] Setting up Convolution34
I0612 11:07:32.013996  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.014003  5211 net.cpp:255] Memory required for data: 1536689664
I0612 11:07:32.014015  5211 layer_factory.hpp:77] Creating layer BatchNorm34
I0612 11:07:32.014027  5211 net.cpp:190] Creating Layer BatchNorm34
I0612 11:07:32.014034  5211 net.cpp:615] BatchNorm34 <- Convolution34
I0612 11:07:32.014045  5211 net.cpp:576] BatchNorm34 -> Convolution34 (in-place)
I0612 11:07:32.014371  5211 net.cpp:240] Setting up BatchNorm34
I0612 11:07:32.014382  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.014389  5211 net.cpp:255] Memory required for data: 1545078272
I0612 11:07:32.014405  5211 layer_factory.hpp:77] Creating layer Scale34
I0612 11:07:32.014416  5211 net.cpp:190] Creating Layer Scale34
I0612 11:07:32.014422  5211 net.cpp:615] Scale34 <- Convolution34
I0612 11:07:32.014430  5211 net.cpp:576] Scale34 -> Convolution34 (in-place)
I0612 11:07:32.014484  5211 layer_factory.hpp:77] Creating layer Scale34
I0612 11:07:32.014673  5211 net.cpp:240] Setting up Scale34
I0612 11:07:32.014684  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.014689  5211 net.cpp:255] Memory required for data: 1553466880
I0612 11:07:32.014701  5211 layer_factory.hpp:77] Creating layer ReLU34
I0612 11:07:32.014710  5211 net.cpp:190] Creating Layer ReLU34
I0612 11:07:32.014715  5211 net.cpp:615] ReLU34 <- Convolution34
I0612 11:07:32.014724  5211 net.cpp:576] ReLU34 -> Convolution34 (in-place)
I0612 11:07:32.014732  5211 net.cpp:240] Setting up ReLU34
I0612 11:07:32.014739  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.014744  5211 net.cpp:255] Memory required for data: 1561855488
I0612 11:07:32.014750  5211 layer_factory.hpp:77] Creating layer Convolution35
I0612 11:07:32.014766  5211 net.cpp:190] Creating Layer Convolution35
I0612 11:07:32.014772  5211 net.cpp:615] Convolution35 <- Convolution34
I0612 11:07:32.014785  5211 net.cpp:589] Convolution35 -> Convolution35
I0612 11:07:32.015267  5211 net.cpp:240] Setting up Convolution35
I0612 11:07:32.015280  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.015285  5211 net.cpp:255] Memory required for data: 1570244096
I0612 11:07:32.015297  5211 layer_factory.hpp:77] Creating layer BatchNorm35
I0612 11:07:32.015308  5211 net.cpp:190] Creating Layer BatchNorm35
I0612 11:07:32.015314  5211 net.cpp:615] BatchNorm35 <- Convolution35
I0612 11:07:32.015324  5211 net.cpp:576] BatchNorm35 -> Convolution35 (in-place)
I0612 11:07:32.016324  5211 net.cpp:240] Setting up BatchNorm35
I0612 11:07:32.016342  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.016348  5211 net.cpp:255] Memory required for data: 1578632704
I0612 11:07:32.016366  5211 layer_factory.hpp:77] Creating layer Scale35
I0612 11:07:32.016376  5211 net.cpp:190] Creating Layer Scale35
I0612 11:07:32.016382  5211 net.cpp:615] Scale35 <- Convolution35
I0612 11:07:32.016391  5211 net.cpp:576] Scale35 -> Convolution35 (in-place)
I0612 11:07:32.016446  5211 layer_factory.hpp:77] Creating layer Scale35
I0612 11:07:32.016614  5211 net.cpp:240] Setting up Scale35
I0612 11:07:32.016624  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.016629  5211 net.cpp:255] Memory required for data: 1587021312
I0612 11:07:32.016646  5211 layer_factory.hpp:77] Creating layer Eltwise17
I0612 11:07:32.016655  5211 net.cpp:190] Creating Layer Eltwise17
I0612 11:07:32.016662  5211 net.cpp:615] Eltwise17 <- Eltwise16_ReLU33_0_split_1
I0612 11:07:32.016669  5211 net.cpp:615] Eltwise17 <- Convolution35
I0612 11:07:32.016680  5211 net.cpp:589] Eltwise17 -> Eltwise17
I0612 11:07:32.016715  5211 net.cpp:240] Setting up Eltwise17
I0612 11:07:32.016724  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.016728  5211 net.cpp:255] Memory required for data: 1595409920
I0612 11:07:32.016733  5211 layer_factory.hpp:77] Creating layer ReLU35
I0612 11:07:32.016744  5211 net.cpp:190] Creating Layer ReLU35
I0612 11:07:32.016751  5211 net.cpp:615] ReLU35 <- Eltwise17
I0612 11:07:32.016757  5211 net.cpp:576] ReLU35 -> Eltwise17 (in-place)
I0612 11:07:32.016773  5211 net.cpp:240] Setting up ReLU35
I0612 11:07:32.016782  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.016787  5211 net.cpp:255] Memory required for data: 1603798528
I0612 11:07:32.016791  5211 layer_factory.hpp:77] Creating layer Eltwise17_ReLU35_0_split
I0612 11:07:32.016798  5211 net.cpp:190] Creating Layer Eltwise17_ReLU35_0_split
I0612 11:07:32.016804  5211 net.cpp:615] Eltwise17_ReLU35_0_split <- Eltwise17
I0612 11:07:32.016813  5211 net.cpp:589] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_0
I0612 11:07:32.016824  5211 net.cpp:589] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_1
I0612 11:07:32.016876  5211 net.cpp:240] Setting up Eltwise17_ReLU35_0_split
I0612 11:07:32.016885  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.016892  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.016897  5211 net.cpp:255] Memory required for data: 1620575744
I0612 11:07:32.016902  5211 layer_factory.hpp:77] Creating layer Convolution36
I0612 11:07:32.016916  5211 net.cpp:190] Creating Layer Convolution36
I0612 11:07:32.016921  5211 net.cpp:615] Convolution36 <- Eltwise17_ReLU35_0_split_0
I0612 11:07:32.016933  5211 net.cpp:589] Convolution36 -> Convolution36
I0612 11:07:32.017405  5211 net.cpp:240] Setting up Convolution36
I0612 11:07:32.017416  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.017421  5211 net.cpp:255] Memory required for data: 1628964352
I0612 11:07:32.017433  5211 layer_factory.hpp:77] Creating layer BatchNorm36
I0612 11:07:32.017442  5211 net.cpp:190] Creating Layer BatchNorm36
I0612 11:07:32.017448  5211 net.cpp:615] BatchNorm36 <- Convolution36
I0612 11:07:32.017459  5211 net.cpp:576] BatchNorm36 -> Convolution36 (in-place)
I0612 11:07:32.017746  5211 net.cpp:240] Setting up BatchNorm36
I0612 11:07:32.017757  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.017762  5211 net.cpp:255] Memory required for data: 1637352960
I0612 11:07:32.017777  5211 layer_factory.hpp:77] Creating layer Scale36
I0612 11:07:32.017786  5211 net.cpp:190] Creating Layer Scale36
I0612 11:07:32.017792  5211 net.cpp:615] Scale36 <- Convolution36
I0612 11:07:32.017802  5211 net.cpp:576] Scale36 -> Convolution36 (in-place)
I0612 11:07:32.017850  5211 layer_factory.hpp:77] Creating layer Scale36
I0612 11:07:32.018018  5211 net.cpp:240] Setting up Scale36
I0612 11:07:32.018028  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.018033  5211 net.cpp:255] Memory required for data: 1645741568
I0612 11:07:32.018046  5211 layer_factory.hpp:77] Creating layer ReLU36
I0612 11:07:32.018056  5211 net.cpp:190] Creating Layer ReLU36
I0612 11:07:32.018062  5211 net.cpp:615] ReLU36 <- Convolution36
I0612 11:07:32.018070  5211 net.cpp:576] ReLU36 -> Convolution36 (in-place)
I0612 11:07:32.018080  5211 net.cpp:240] Setting up ReLU36
I0612 11:07:32.018087  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.018092  5211 net.cpp:255] Memory required for data: 1654130176
I0612 11:07:32.018097  5211 layer_factory.hpp:77] Creating layer Convolution37
I0612 11:07:32.018111  5211 net.cpp:190] Creating Layer Convolution37
I0612 11:07:32.018116  5211 net.cpp:615] Convolution37 <- Convolution36
I0612 11:07:32.018126  5211 net.cpp:589] Convolution37 -> Convolution37
I0612 11:07:32.018610  5211 net.cpp:240] Setting up Convolution37
I0612 11:07:32.018623  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.018628  5211 net.cpp:255] Memory required for data: 1662518784
I0612 11:07:32.018640  5211 layer_factory.hpp:77] Creating layer BatchNorm37
I0612 11:07:32.018651  5211 net.cpp:190] Creating Layer BatchNorm37
I0612 11:07:32.018658  5211 net.cpp:615] BatchNorm37 <- Convolution37
I0612 11:07:32.018666  5211 net.cpp:576] BatchNorm37 -> Convolution37 (in-place)
I0612 11:07:32.018959  5211 net.cpp:240] Setting up BatchNorm37
I0612 11:07:32.018970  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.018975  5211 net.cpp:255] Memory required for data: 1670907392
I0612 11:07:32.019029  5211 layer_factory.hpp:77] Creating layer Scale37
I0612 11:07:32.019043  5211 net.cpp:190] Creating Layer Scale37
I0612 11:07:32.019050  5211 net.cpp:615] Scale37 <- Convolution37
I0612 11:07:32.019058  5211 net.cpp:576] Scale37 -> Convolution37 (in-place)
I0612 11:07:32.019112  5211 layer_factory.hpp:77] Creating layer Scale37
I0612 11:07:32.019279  5211 net.cpp:240] Setting up Scale37
I0612 11:07:32.019289  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.019294  5211 net.cpp:255] Memory required for data: 1679296000
I0612 11:07:32.019305  5211 layer_factory.hpp:77] Creating layer Eltwise18
I0612 11:07:32.019317  5211 net.cpp:190] Creating Layer Eltwise18
I0612 11:07:32.019323  5211 net.cpp:615] Eltwise18 <- Eltwise17_ReLU35_0_split_1
I0612 11:07:32.019331  5211 net.cpp:615] Eltwise18 <- Convolution37
I0612 11:07:32.019341  5211 net.cpp:589] Eltwise18 -> Eltwise18
I0612 11:07:32.019377  5211 net.cpp:240] Setting up Eltwise18
I0612 11:07:32.019387  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.019392  5211 net.cpp:255] Memory required for data: 1687684608
I0612 11:07:32.019397  5211 layer_factory.hpp:77] Creating layer ReLU37
I0612 11:07:32.019403  5211 net.cpp:190] Creating Layer ReLU37
I0612 11:07:32.019409  5211 net.cpp:615] ReLU37 <- Eltwise18
I0612 11:07:32.019419  5211 net.cpp:576] ReLU37 -> Eltwise18 (in-place)
I0612 11:07:32.019428  5211 net.cpp:240] Setting up ReLU37
I0612 11:07:32.019435  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.019440  5211 net.cpp:255] Memory required for data: 1696073216
I0612 11:07:32.019446  5211 layer_factory.hpp:77] Creating layer Eltwise18_ReLU37_0_split
I0612 11:07:32.019454  5211 net.cpp:190] Creating Layer Eltwise18_ReLU37_0_split
I0612 11:07:32.019459  5211 net.cpp:615] Eltwise18_ReLU37_0_split <- Eltwise18
I0612 11:07:32.019467  5211 net.cpp:589] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_0
I0612 11:07:32.019479  5211 net.cpp:589] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_1
I0612 11:07:32.019532  5211 net.cpp:240] Setting up Eltwise18_ReLU37_0_split
I0612 11:07:32.019541  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.019548  5211 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:07:32.019553  5211 net.cpp:255] Memory required for data: 1712850432
I0612 11:07:32.019558  5211 layer_factory.hpp:77] Creating layer Pooling1
I0612 11:07:32.019567  5211 net.cpp:190] Creating Layer Pooling1
I0612 11:07:32.019572  5211 net.cpp:615] Pooling1 <- Eltwise18_ReLU37_0_split_0
I0612 11:07:32.019579  5211 net.cpp:589] Pooling1 -> Pooling1
I0612 11:07:32.019615  5211 net.cpp:240] Setting up Pooling1
I0612 11:07:32.019623  5211 net.cpp:247] Top shape: 128 16 16 16 (524288)
I0612 11:07:32.019629  5211 net.cpp:255] Memory required for data: 1714947584
I0612 11:07:32.019634  5211 layer_factory.hpp:77] Creating layer Input1
I0612 11:07:32.019642  5211 net.cpp:190] Creating Layer Input1
I0612 11:07:32.019649  5211 net.cpp:589] Input1 -> Input1
I0612 11:07:32.019685  5211 net.cpp:240] Setting up Input1
I0612 11:07:32.019693  5211 net.cpp:247] Top shape: 128 16 16 16 (524288)
I0612 11:07:32.019698  5211 net.cpp:255] Memory required for data: 1717044736
I0612 11:07:32.019703  5211 layer_factory.hpp:77] Creating layer Concat1
I0612 11:07:32.019711  5211 net.cpp:190] Creating Layer Concat1
I0612 11:07:32.019717  5211 net.cpp:615] Concat1 <- Pooling1
I0612 11:07:32.019724  5211 net.cpp:615] Concat1 <- Input1
I0612 11:07:32.019734  5211 net.cpp:589] Concat1 -> Concat1
I0612 11:07:32.019767  5211 net.cpp:240] Setting up Concat1
I0612 11:07:32.019775  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.019780  5211 net.cpp:255] Memory required for data: 1721239040
I0612 11:07:32.019785  5211 layer_factory.hpp:77] Creating layer Convolution38
I0612 11:07:32.019803  5211 net.cpp:190] Creating Layer Convolution38
I0612 11:07:32.019809  5211 net.cpp:615] Convolution38 <- Eltwise18_ReLU37_0_split_1
I0612 11:07:32.019819  5211 net.cpp:589] Convolution38 -> Convolution38
I0612 11:07:32.020437  5211 net.cpp:240] Setting up Convolution38
I0612 11:07:32.020449  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.020454  5211 net.cpp:255] Memory required for data: 1725433344
I0612 11:07:32.020468  5211 layer_factory.hpp:77] Creating layer BatchNorm38
I0612 11:07:32.020479  5211 net.cpp:190] Creating Layer BatchNorm38
I0612 11:07:32.020486  5211 net.cpp:615] BatchNorm38 <- Convolution38
I0612 11:07:32.020494  5211 net.cpp:576] BatchNorm38 -> Convolution38 (in-place)
I0612 11:07:32.020774  5211 net.cpp:240] Setting up BatchNorm38
I0612 11:07:32.020784  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.020789  5211 net.cpp:255] Memory required for data: 1729627648
I0612 11:07:32.020807  5211 layer_factory.hpp:77] Creating layer Scale38
I0612 11:07:32.020815  5211 net.cpp:190] Creating Layer Scale38
I0612 11:07:32.020823  5211 net.cpp:615] Scale38 <- Convolution38
I0612 11:07:32.020829  5211 net.cpp:576] Scale38 -> Convolution38 (in-place)
I0612 11:07:32.020879  5211 layer_factory.hpp:77] Creating layer Scale38
I0612 11:07:32.021047  5211 net.cpp:240] Setting up Scale38
I0612 11:07:32.021057  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.021062  5211 net.cpp:255] Memory required for data: 1733821952
I0612 11:07:32.021075  5211 layer_factory.hpp:77] Creating layer ReLU38
I0612 11:07:32.021085  5211 net.cpp:190] Creating Layer ReLU38
I0612 11:07:32.021091  5211 net.cpp:615] ReLU38 <- Convolution38
I0612 11:07:32.021100  5211 net.cpp:576] ReLU38 -> Convolution38 (in-place)
I0612 11:07:32.021108  5211 net.cpp:240] Setting up ReLU38
I0612 11:07:32.021116  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.021121  5211 net.cpp:255] Memory required for data: 1738016256
I0612 11:07:32.021126  5211 layer_factory.hpp:77] Creating layer Convolution39
I0612 11:07:32.021138  5211 net.cpp:190] Creating Layer Convolution39
I0612 11:07:32.021144  5211 net.cpp:615] Convolution39 <- Convolution38
I0612 11:07:32.021152  5211 net.cpp:589] Convolution39 -> Convolution39
I0612 11:07:32.021975  5211 net.cpp:240] Setting up Convolution39
I0612 11:07:32.021986  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.021991  5211 net.cpp:255] Memory required for data: 1742210560
I0612 11:07:32.022002  5211 layer_factory.hpp:77] Creating layer BatchNorm39
I0612 11:07:32.022013  5211 net.cpp:190] Creating Layer BatchNorm39
I0612 11:07:32.022019  5211 net.cpp:615] BatchNorm39 <- Convolution39
I0612 11:07:32.022027  5211 net.cpp:576] BatchNorm39 -> Convolution39 (in-place)
I0612 11:07:32.022305  5211 net.cpp:240] Setting up BatchNorm39
I0612 11:07:32.022315  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.022320  5211 net.cpp:255] Memory required for data: 1746404864
I0612 11:07:32.022336  5211 layer_factory.hpp:77] Creating layer Scale39
I0612 11:07:32.022344  5211 net.cpp:190] Creating Layer Scale39
I0612 11:07:32.022349  5211 net.cpp:615] Scale39 <- Convolution39
I0612 11:07:32.022364  5211 net.cpp:576] Scale39 -> Convolution39 (in-place)
I0612 11:07:32.022415  5211 layer_factory.hpp:77] Creating layer Scale39
I0612 11:07:32.022580  5211 net.cpp:240] Setting up Scale39
I0612 11:07:32.022589  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.022595  5211 net.cpp:255] Memory required for data: 1750599168
I0612 11:07:32.022613  5211 layer_factory.hpp:77] Creating layer Eltwise19
I0612 11:07:32.022621  5211 net.cpp:190] Creating Layer Eltwise19
I0612 11:07:32.022627  5211 net.cpp:615] Eltwise19 <- Concat1
I0612 11:07:32.022635  5211 net.cpp:615] Eltwise19 <- Convolution39
I0612 11:07:32.022649  5211 net.cpp:589] Eltwise19 -> Eltwise19
I0612 11:07:32.022676  5211 net.cpp:240] Setting up Eltwise19
I0612 11:07:32.022685  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.022689  5211 net.cpp:255] Memory required for data: 1754793472
I0612 11:07:32.022694  5211 layer_factory.hpp:77] Creating layer ReLU39
I0612 11:07:32.022702  5211 net.cpp:190] Creating Layer ReLU39
I0612 11:07:32.022711  5211 net.cpp:615] ReLU39 <- Eltwise19
I0612 11:07:32.022723  5211 net.cpp:576] ReLU39 -> Eltwise19 (in-place)
I0612 11:07:32.022733  5211 net.cpp:240] Setting up ReLU39
I0612 11:07:32.022740  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.022745  5211 net.cpp:255] Memory required for data: 1758987776
I0612 11:07:32.022750  5211 layer_factory.hpp:77] Creating layer Eltwise19_ReLU39_0_split
I0612 11:07:32.022758  5211 net.cpp:190] Creating Layer Eltwise19_ReLU39_0_split
I0612 11:07:32.022763  5211 net.cpp:615] Eltwise19_ReLU39_0_split <- Eltwise19
I0612 11:07:32.022770  5211 net.cpp:589] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_0
I0612 11:07:32.022780  5211 net.cpp:589] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_1
I0612 11:07:32.022833  5211 net.cpp:240] Setting up Eltwise19_ReLU39_0_split
I0612 11:07:32.022841  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.022848  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.022853  5211 net.cpp:255] Memory required for data: 1767376384
I0612 11:07:32.022858  5211 layer_factory.hpp:77] Creating layer Convolution40
I0612 11:07:32.022869  5211 net.cpp:190] Creating Layer Convolution40
I0612 11:07:32.022876  5211 net.cpp:615] Convolution40 <- Eltwise19_ReLU39_0_split_0
I0612 11:07:32.022887  5211 net.cpp:589] Convolution40 -> Convolution40
I0612 11:07:32.023715  5211 net.cpp:240] Setting up Convolution40
I0612 11:07:32.023726  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.023732  5211 net.cpp:255] Memory required for data: 1771570688
I0612 11:07:32.023744  5211 layer_factory.hpp:77] Creating layer BatchNorm40
I0612 11:07:32.023753  5211 net.cpp:190] Creating Layer BatchNorm40
I0612 11:07:32.023759  5211 net.cpp:615] BatchNorm40 <- Convolution40
I0612 11:07:32.023769  5211 net.cpp:576] BatchNorm40 -> Convolution40 (in-place)
I0612 11:07:32.024061  5211 net.cpp:240] Setting up BatchNorm40
I0612 11:07:32.024071  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.024076  5211 net.cpp:255] Memory required for data: 1775764992
I0612 11:07:32.024091  5211 layer_factory.hpp:77] Creating layer Scale40
I0612 11:07:32.024101  5211 net.cpp:190] Creating Layer Scale40
I0612 11:07:32.024106  5211 net.cpp:615] Scale40 <- Convolution40
I0612 11:07:32.024113  5211 net.cpp:576] Scale40 -> Convolution40 (in-place)
I0612 11:07:32.024165  5211 layer_factory.hpp:77] Creating layer Scale40
I0612 11:07:32.024329  5211 net.cpp:240] Setting up Scale40
I0612 11:07:32.024338  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.024343  5211 net.cpp:255] Memory required for data: 1779959296
I0612 11:07:32.024355  5211 layer_factory.hpp:77] Creating layer ReLU40
I0612 11:07:32.024365  5211 net.cpp:190] Creating Layer ReLU40
I0612 11:07:32.024372  5211 net.cpp:615] ReLU40 <- Convolution40
I0612 11:07:32.024379  5211 net.cpp:576] ReLU40 -> Convolution40 (in-place)
I0612 11:07:32.024389  5211 net.cpp:240] Setting up ReLU40
I0612 11:07:32.024395  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.024400  5211 net.cpp:255] Memory required for data: 1784153600
I0612 11:07:32.024405  5211 layer_factory.hpp:77] Creating layer Convolution41
I0612 11:07:32.024420  5211 net.cpp:190] Creating Layer Convolution41
I0612 11:07:32.024425  5211 net.cpp:615] Convolution41 <- Convolution40
I0612 11:07:32.024435  5211 net.cpp:589] Convolution41 -> Convolution41
I0612 11:07:32.025264  5211 net.cpp:240] Setting up Convolution41
I0612 11:07:32.025275  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.025281  5211 net.cpp:255] Memory required for data: 1788347904
I0612 11:07:32.025292  5211 layer_factory.hpp:77] Creating layer BatchNorm41
I0612 11:07:32.025305  5211 net.cpp:190] Creating Layer BatchNorm41
I0612 11:07:32.025310  5211 net.cpp:615] BatchNorm41 <- Convolution41
I0612 11:07:32.025318  5211 net.cpp:576] BatchNorm41 -> Convolution41 (in-place)
I0612 11:07:32.025604  5211 net.cpp:240] Setting up BatchNorm41
I0612 11:07:32.025614  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.025622  5211 net.cpp:255] Memory required for data: 1792542208
I0612 11:07:32.025637  5211 layer_factory.hpp:77] Creating layer Scale41
I0612 11:07:32.025646  5211 net.cpp:190] Creating Layer Scale41
I0612 11:07:32.025652  5211 net.cpp:615] Scale41 <- Convolution41
I0612 11:07:32.025662  5211 net.cpp:576] Scale41 -> Convolution41 (in-place)
I0612 11:07:32.025710  5211 layer_factory.hpp:77] Creating layer Scale41
I0612 11:07:32.025873  5211 net.cpp:240] Setting up Scale41
I0612 11:07:32.025884  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.025889  5211 net.cpp:255] Memory required for data: 1796736512
I0612 11:07:32.025902  5211 layer_factory.hpp:77] Creating layer Eltwise20
I0612 11:07:32.025910  5211 net.cpp:190] Creating Layer Eltwise20
I0612 11:07:32.025916  5211 net.cpp:615] Eltwise20 <- Eltwise19_ReLU39_0_split_1
I0612 11:07:32.025923  5211 net.cpp:615] Eltwise20 <- Convolution41
I0612 11:07:32.025933  5211 net.cpp:589] Eltwise20 -> Eltwise20
I0612 11:07:32.025964  5211 net.cpp:240] Setting up Eltwise20
I0612 11:07:32.025972  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.025977  5211 net.cpp:255] Memory required for data: 1800930816
I0612 11:07:32.025982  5211 layer_factory.hpp:77] Creating layer ReLU41
I0612 11:07:32.025990  5211 net.cpp:190] Creating Layer ReLU41
I0612 11:07:32.025996  5211 net.cpp:615] ReLU41 <- Eltwise20
I0612 11:07:32.026005  5211 net.cpp:576] ReLU41 -> Eltwise20 (in-place)
I0612 11:07:32.026015  5211 net.cpp:240] Setting up ReLU41
I0612 11:07:32.026021  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.026026  5211 net.cpp:255] Memory required for data: 1805125120
I0612 11:07:32.026032  5211 layer_factory.hpp:77] Creating layer Eltwise20_ReLU41_0_split
I0612 11:07:32.026039  5211 net.cpp:190] Creating Layer Eltwise20_ReLU41_0_split
I0612 11:07:32.026044  5211 net.cpp:615] Eltwise20_ReLU41_0_split <- Eltwise20
I0612 11:07:32.026051  5211 net.cpp:589] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_0
I0612 11:07:32.026062  5211 net.cpp:589] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_1
I0612 11:07:32.026113  5211 net.cpp:240] Setting up Eltwise20_ReLU41_0_split
I0612 11:07:32.026123  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.026129  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.026134  5211 net.cpp:255] Memory required for data: 1813513728
I0612 11:07:32.026139  5211 layer_factory.hpp:77] Creating layer Convolution42
I0612 11:07:32.026152  5211 net.cpp:190] Creating Layer Convolution42
I0612 11:07:32.026159  5211 net.cpp:615] Convolution42 <- Eltwise20_ReLU41_0_split_0
I0612 11:07:32.026167  5211 net.cpp:589] Convolution42 -> Convolution42
I0612 11:07:32.026999  5211 net.cpp:240] Setting up Convolution42
I0612 11:07:32.027011  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.027016  5211 net.cpp:255] Memory required for data: 1817708032
I0612 11:07:32.027029  5211 layer_factory.hpp:77] Creating layer BatchNorm42
I0612 11:07:32.027040  5211 net.cpp:190] Creating Layer BatchNorm42
I0612 11:07:32.027047  5211 net.cpp:615] BatchNorm42 <- Convolution42
I0612 11:07:32.027055  5211 net.cpp:576] BatchNorm42 -> Convolution42 (in-place)
I0612 11:07:32.027317  5211 net.cpp:240] Setting up BatchNorm42
I0612 11:07:32.027326  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.027331  5211 net.cpp:255] Memory required for data: 1821902336
I0612 11:07:32.027345  5211 layer_factory.hpp:77] Creating layer Scale42
I0612 11:07:32.027356  5211 net.cpp:190] Creating Layer Scale42
I0612 11:07:32.027361  5211 net.cpp:615] Scale42 <- Convolution42
I0612 11:07:32.027369  5211 net.cpp:576] Scale42 -> Convolution42 (in-place)
I0612 11:07:32.027415  5211 layer_factory.hpp:77] Creating layer Scale42
I0612 11:07:32.027575  5211 net.cpp:240] Setting up Scale42
I0612 11:07:32.027585  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.027590  5211 net.cpp:255] Memory required for data: 1826096640
I0612 11:07:32.027602  5211 layer_factory.hpp:77] Creating layer ReLU42
I0612 11:07:32.027613  5211 net.cpp:190] Creating Layer ReLU42
I0612 11:07:32.027619  5211 net.cpp:615] ReLU42 <- Convolution42
I0612 11:07:32.027629  5211 net.cpp:576] ReLU42 -> Convolution42 (in-place)
I0612 11:07:32.027638  5211 net.cpp:240] Setting up ReLU42
I0612 11:07:32.027645  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.027650  5211 net.cpp:255] Memory required for data: 1830290944
I0612 11:07:32.027655  5211 layer_factory.hpp:77] Creating layer Convolution43
I0612 11:07:32.027667  5211 net.cpp:190] Creating Layer Convolution43
I0612 11:07:32.027673  5211 net.cpp:615] Convolution43 <- Convolution42
I0612 11:07:32.027680  5211 net.cpp:589] Convolution43 -> Convolution43
I0612 11:07:32.028462  5211 net.cpp:240] Setting up Convolution43
I0612 11:07:32.028473  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.028478  5211 net.cpp:255] Memory required for data: 1834485248
I0612 11:07:32.028491  5211 layer_factory.hpp:77] Creating layer BatchNorm43
I0612 11:07:32.028501  5211 net.cpp:190] Creating Layer BatchNorm43
I0612 11:07:32.028506  5211 net.cpp:615] BatchNorm43 <- Convolution43
I0612 11:07:32.028513  5211 net.cpp:576] BatchNorm43 -> Convolution43 (in-place)
I0612 11:07:32.028774  5211 net.cpp:240] Setting up BatchNorm43
I0612 11:07:32.028784  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.028789  5211 net.cpp:255] Memory required for data: 1838679552
I0612 11:07:32.028805  5211 layer_factory.hpp:77] Creating layer Scale43
I0612 11:07:32.028813  5211 net.cpp:190] Creating Layer Scale43
I0612 11:07:32.028818  5211 net.cpp:615] Scale43 <- Convolution43
I0612 11:07:32.028825  5211 net.cpp:576] Scale43 -> Convolution43 (in-place)
I0612 11:07:32.028872  5211 layer_factory.hpp:77] Creating layer Scale43
I0612 11:07:32.029029  5211 net.cpp:240] Setting up Scale43
I0612 11:07:32.029038  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.029043  5211 net.cpp:255] Memory required for data: 1842873856
I0612 11:07:32.029054  5211 layer_factory.hpp:77] Creating layer Eltwise21
I0612 11:07:32.029065  5211 net.cpp:190] Creating Layer Eltwise21
I0612 11:07:32.029072  5211 net.cpp:615] Eltwise21 <- Eltwise20_ReLU41_0_split_1
I0612 11:07:32.029078  5211 net.cpp:615] Eltwise21 <- Convolution43
I0612 11:07:32.029086  5211 net.cpp:589] Eltwise21 -> Eltwise21
I0612 11:07:32.029114  5211 net.cpp:240] Setting up Eltwise21
I0612 11:07:32.029122  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.029126  5211 net.cpp:255] Memory required for data: 1847068160
I0612 11:07:32.029131  5211 layer_factory.hpp:77] Creating layer ReLU43
I0612 11:07:32.029139  5211 net.cpp:190] Creating Layer ReLU43
I0612 11:07:32.029144  5211 net.cpp:615] ReLU43 <- Eltwise21
I0612 11:07:32.029152  5211 net.cpp:576] ReLU43 -> Eltwise21 (in-place)
I0612 11:07:32.029161  5211 net.cpp:240] Setting up ReLU43
I0612 11:07:32.029168  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.029173  5211 net.cpp:255] Memory required for data: 1851262464
I0612 11:07:32.029178  5211 layer_factory.hpp:77] Creating layer Eltwise21_ReLU43_0_split
I0612 11:07:32.029184  5211 net.cpp:190] Creating Layer Eltwise21_ReLU43_0_split
I0612 11:07:32.029189  5211 net.cpp:615] Eltwise21_ReLU43_0_split <- Eltwise21
I0612 11:07:32.029196  5211 net.cpp:589] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_0
I0612 11:07:32.029206  5211 net.cpp:589] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_1
I0612 11:07:32.029254  5211 net.cpp:240] Setting up Eltwise21_ReLU43_0_split
I0612 11:07:32.029263  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.029268  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.029273  5211 net.cpp:255] Memory required for data: 1859651072
I0612 11:07:32.029278  5211 layer_factory.hpp:77] Creating layer Convolution44
I0612 11:07:32.029289  5211 net.cpp:190] Creating Layer Convolution44
I0612 11:07:32.029294  5211 net.cpp:615] Convolution44 <- Eltwise21_ReLU43_0_split_0
I0612 11:07:32.029305  5211 net.cpp:589] Convolution44 -> Convolution44
I0612 11:07:32.030097  5211 net.cpp:240] Setting up Convolution44
I0612 11:07:32.030107  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.030112  5211 net.cpp:255] Memory required for data: 1863845376
I0612 11:07:32.030124  5211 layer_factory.hpp:77] Creating layer BatchNorm44
I0612 11:07:32.030133  5211 net.cpp:190] Creating Layer BatchNorm44
I0612 11:07:32.030138  5211 net.cpp:615] BatchNorm44 <- Convolution44
I0612 11:07:32.030148  5211 net.cpp:576] BatchNorm44 -> Convolution44 (in-place)
I0612 11:07:32.030427  5211 net.cpp:240] Setting up BatchNorm44
I0612 11:07:32.030437  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.030442  5211 net.cpp:255] Memory required for data: 1868039680
I0612 11:07:32.030457  5211 layer_factory.hpp:77] Creating layer Scale44
I0612 11:07:32.030464  5211 net.cpp:190] Creating Layer Scale44
I0612 11:07:32.030470  5211 net.cpp:615] Scale44 <- Convolution44
I0612 11:07:32.030478  5211 net.cpp:576] Scale44 -> Convolution44 (in-place)
I0612 11:07:32.030524  5211 layer_factory.hpp:77] Creating layer Scale44
I0612 11:07:32.030683  5211 net.cpp:240] Setting up Scale44
I0612 11:07:32.030691  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.030696  5211 net.cpp:255] Memory required for data: 1872233984
I0612 11:07:32.030709  5211 layer_factory.hpp:77] Creating layer ReLU44
I0612 11:07:32.030716  5211 net.cpp:190] Creating Layer ReLU44
I0612 11:07:32.030725  5211 net.cpp:615] ReLU44 <- Convolution44
I0612 11:07:32.030731  5211 net.cpp:576] ReLU44 -> Convolution44 (in-place)
I0612 11:07:32.030740  5211 net.cpp:240] Setting up ReLU44
I0612 11:07:32.030747  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.030751  5211 net.cpp:255] Memory required for data: 1876428288
I0612 11:07:32.030756  5211 layer_factory.hpp:77] Creating layer Convolution45
I0612 11:07:32.030769  5211 net.cpp:190] Creating Layer Convolution45
I0612 11:07:32.030776  5211 net.cpp:615] Convolution45 <- Convolution44
I0612 11:07:32.030783  5211 net.cpp:589] Convolution45 -> Convolution45
I0612 11:07:32.031568  5211 net.cpp:240] Setting up Convolution45
I0612 11:07:32.031579  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.031582  5211 net.cpp:255] Memory required for data: 1880622592
I0612 11:07:32.031594  5211 layer_factory.hpp:77] Creating layer BatchNorm45
I0612 11:07:32.031602  5211 net.cpp:190] Creating Layer BatchNorm45
I0612 11:07:32.031608  5211 net.cpp:615] BatchNorm45 <- Convolution45
I0612 11:07:32.031618  5211 net.cpp:576] BatchNorm45 -> Convolution45 (in-place)
I0612 11:07:32.031879  5211 net.cpp:240] Setting up BatchNorm45
I0612 11:07:32.031888  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.031893  5211 net.cpp:255] Memory required for data: 1884816896
I0612 11:07:32.031908  5211 layer_factory.hpp:77] Creating layer Scale45
I0612 11:07:32.031915  5211 net.cpp:190] Creating Layer Scale45
I0612 11:07:32.031921  5211 net.cpp:615] Scale45 <- Convolution45
I0612 11:07:32.031927  5211 net.cpp:576] Scale45 -> Convolution45 (in-place)
I0612 11:07:32.031975  5211 layer_factory.hpp:77] Creating layer Scale45
I0612 11:07:32.032130  5211 net.cpp:240] Setting up Scale45
I0612 11:07:32.032140  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.032145  5211 net.cpp:255] Memory required for data: 1889011200
I0612 11:07:32.032155  5211 layer_factory.hpp:77] Creating layer Eltwise22
I0612 11:07:32.032166  5211 net.cpp:190] Creating Layer Eltwise22
I0612 11:07:32.032171  5211 net.cpp:615] Eltwise22 <- Eltwise21_ReLU43_0_split_1
I0612 11:07:32.032178  5211 net.cpp:615] Eltwise22 <- Convolution45
I0612 11:07:32.032186  5211 net.cpp:589] Eltwise22 -> Eltwise22
I0612 11:07:32.032213  5211 net.cpp:240] Setting up Eltwise22
I0612 11:07:32.032222  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.032227  5211 net.cpp:255] Memory required for data: 1893205504
I0612 11:07:32.032232  5211 layer_factory.hpp:77] Creating layer ReLU45
I0612 11:07:32.032238  5211 net.cpp:190] Creating Layer ReLU45
I0612 11:07:32.032248  5211 net.cpp:615] ReLU45 <- Eltwise22
I0612 11:07:32.032256  5211 net.cpp:576] ReLU45 -> Eltwise22 (in-place)
I0612 11:07:32.032265  5211 net.cpp:240] Setting up ReLU45
I0612 11:07:32.032272  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.032277  5211 net.cpp:255] Memory required for data: 1897399808
I0612 11:07:32.032282  5211 layer_factory.hpp:77] Creating layer Eltwise22_ReLU45_0_split
I0612 11:07:32.032289  5211 net.cpp:190] Creating Layer Eltwise22_ReLU45_0_split
I0612 11:07:32.032294  5211 net.cpp:615] Eltwise22_ReLU45_0_split <- Eltwise22
I0612 11:07:32.032300  5211 net.cpp:589] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_0
I0612 11:07:32.032310  5211 net.cpp:589] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_1
I0612 11:07:32.032358  5211 net.cpp:240] Setting up Eltwise22_ReLU45_0_split
I0612 11:07:32.032366  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.032372  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.032377  5211 net.cpp:255] Memory required for data: 1905788416
I0612 11:07:32.032382  5211 layer_factory.hpp:77] Creating layer Convolution46
I0612 11:07:32.032395  5211 net.cpp:190] Creating Layer Convolution46
I0612 11:07:32.032400  5211 net.cpp:615] Convolution46 <- Eltwise22_ReLU45_0_split_0
I0612 11:07:32.032409  5211 net.cpp:589] Convolution46 -> Convolution46
I0612 11:07:32.033198  5211 net.cpp:240] Setting up Convolution46
I0612 11:07:32.033210  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.033215  5211 net.cpp:255] Memory required for data: 1909982720
I0612 11:07:32.033226  5211 layer_factory.hpp:77] Creating layer BatchNorm46
I0612 11:07:32.033236  5211 net.cpp:190] Creating Layer BatchNorm46
I0612 11:07:32.033242  5211 net.cpp:615] BatchNorm46 <- Convolution46
I0612 11:07:32.033252  5211 net.cpp:576] BatchNorm46 -> Convolution46 (in-place)
I0612 11:07:32.033522  5211 net.cpp:240] Setting up BatchNorm46
I0612 11:07:32.033531  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.033536  5211 net.cpp:255] Memory required for data: 1914177024
I0612 11:07:32.033551  5211 layer_factory.hpp:77] Creating layer Scale46
I0612 11:07:32.033562  5211 net.cpp:190] Creating Layer Scale46
I0612 11:07:32.033567  5211 net.cpp:615] Scale46 <- Convolution46
I0612 11:07:32.033574  5211 net.cpp:576] Scale46 -> Convolution46 (in-place)
I0612 11:07:32.033619  5211 layer_factory.hpp:77] Creating layer Scale46
I0612 11:07:32.033776  5211 net.cpp:240] Setting up Scale46
I0612 11:07:32.033785  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.033790  5211 net.cpp:255] Memory required for data: 1918371328
I0612 11:07:32.033802  5211 layer_factory.hpp:77] Creating layer ReLU46
I0612 11:07:32.033809  5211 net.cpp:190] Creating Layer ReLU46
I0612 11:07:32.033814  5211 net.cpp:615] ReLU46 <- Convolution46
I0612 11:07:32.033826  5211 net.cpp:576] ReLU46 -> Convolution46 (in-place)
I0612 11:07:32.033836  5211 net.cpp:240] Setting up ReLU46
I0612 11:07:32.033843  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.033848  5211 net.cpp:255] Memory required for data: 1922565632
I0612 11:07:32.033852  5211 layer_factory.hpp:77] Creating layer Convolution47
I0612 11:07:32.033866  5211 net.cpp:190] Creating Layer Convolution47
I0612 11:07:32.033871  5211 net.cpp:615] Convolution47 <- Convolution46
I0612 11:07:32.033879  5211 net.cpp:589] Convolution47 -> Convolution47
I0612 11:07:32.034744  5211 net.cpp:240] Setting up Convolution47
I0612 11:07:32.034778  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.034783  5211 net.cpp:255] Memory required for data: 1926759936
I0612 11:07:32.034800  5211 layer_factory.hpp:77] Creating layer BatchNorm47
I0612 11:07:32.034817  5211 net.cpp:190] Creating Layer BatchNorm47
I0612 11:07:32.034824  5211 net.cpp:615] BatchNorm47 <- Convolution47
I0612 11:07:32.034832  5211 net.cpp:576] BatchNorm47 -> Convolution47 (in-place)
I0612 11:07:32.035054  5211 net.cpp:240] Setting up BatchNorm47
I0612 11:07:32.035068  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.035071  5211 net.cpp:255] Memory required for data: 1930954240
I0612 11:07:32.035084  5211 layer_factory.hpp:77] Creating layer Scale47
I0612 11:07:32.035097  5211 net.cpp:190] Creating Layer Scale47
I0612 11:07:32.035102  5211 net.cpp:615] Scale47 <- Convolution47
I0612 11:07:32.035109  5211 net.cpp:576] Scale47 -> Convolution47 (in-place)
I0612 11:07:32.035151  5211 layer_factory.hpp:77] Creating layer Scale47
I0612 11:07:32.035281  5211 net.cpp:240] Setting up Scale47
I0612 11:07:32.035290  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.035293  5211 net.cpp:255] Memory required for data: 1935148544
I0612 11:07:32.035302  5211 layer_factory.hpp:77] Creating layer Eltwise23
I0612 11:07:32.035312  5211 net.cpp:190] Creating Layer Eltwise23
I0612 11:07:32.035320  5211 net.cpp:615] Eltwise23 <- Eltwise22_ReLU45_0_split_1
I0612 11:07:32.035326  5211 net.cpp:615] Eltwise23 <- Convolution47
I0612 11:07:32.035332  5211 net.cpp:589] Eltwise23 -> Eltwise23
I0612 11:07:32.035357  5211 net.cpp:240] Setting up Eltwise23
I0612 11:07:32.035364  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.035367  5211 net.cpp:255] Memory required for data: 1939342848
I0612 11:07:32.035372  5211 layer_factory.hpp:77] Creating layer ReLU47
I0612 11:07:32.035378  5211 net.cpp:190] Creating Layer ReLU47
I0612 11:07:32.035383  5211 net.cpp:615] ReLU47 <- Eltwise23
I0612 11:07:32.035388  5211 net.cpp:576] ReLU47 -> Eltwise23 (in-place)
I0612 11:07:32.035397  5211 net.cpp:240] Setting up ReLU47
I0612 11:07:32.035401  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.035405  5211 net.cpp:255] Memory required for data: 1943537152
I0612 11:07:32.035409  5211 layer_factory.hpp:77] Creating layer Eltwise23_ReLU47_0_split
I0612 11:07:32.035415  5211 net.cpp:190] Creating Layer Eltwise23_ReLU47_0_split
I0612 11:07:32.035419  5211 net.cpp:615] Eltwise23_ReLU47_0_split <- Eltwise23
I0612 11:07:32.035428  5211 net.cpp:589] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_0
I0612 11:07:32.035434  5211 net.cpp:589] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_1
I0612 11:07:32.035475  5211 net.cpp:240] Setting up Eltwise23_ReLU47_0_split
I0612 11:07:32.035482  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.035487  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.035490  5211 net.cpp:255] Memory required for data: 1951925760
I0612 11:07:32.035495  5211 layer_factory.hpp:77] Creating layer Convolution48
I0612 11:07:32.035506  5211 net.cpp:190] Creating Layer Convolution48
I0612 11:07:32.035511  5211 net.cpp:615] Convolution48 <- Eltwise23_ReLU47_0_split_0
I0612 11:07:32.035517  5211 net.cpp:589] Convolution48 -> Convolution48
I0612 11:07:32.036161  5211 net.cpp:240] Setting up Convolution48
I0612 11:07:32.036171  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.036175  5211 net.cpp:255] Memory required for data: 1956120064
I0612 11:07:32.036185  5211 layer_factory.hpp:77] Creating layer BatchNorm48
I0612 11:07:32.036195  5211 net.cpp:190] Creating Layer BatchNorm48
I0612 11:07:32.036201  5211 net.cpp:615] BatchNorm48 <- Convolution48
I0612 11:07:32.036206  5211 net.cpp:576] BatchNorm48 -> Convolution48 (in-place)
I0612 11:07:32.036423  5211 net.cpp:240] Setting up BatchNorm48
I0612 11:07:32.036432  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.036435  5211 net.cpp:255] Memory required for data: 1960314368
I0612 11:07:32.036447  5211 layer_factory.hpp:77] Creating layer Scale48
I0612 11:07:32.036453  5211 net.cpp:190] Creating Layer Scale48
I0612 11:07:32.036458  5211 net.cpp:615] Scale48 <- Convolution48
I0612 11:07:32.036463  5211 net.cpp:576] Scale48 -> Convolution48 (in-place)
I0612 11:07:32.036502  5211 layer_factory.hpp:77] Creating layer Scale48
I0612 11:07:32.036628  5211 net.cpp:240] Setting up Scale48
I0612 11:07:32.036635  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.036639  5211 net.cpp:255] Memory required for data: 1964508672
I0612 11:07:32.036654  5211 layer_factory.hpp:77] Creating layer ReLU48
I0612 11:07:32.036662  5211 net.cpp:190] Creating Layer ReLU48
I0612 11:07:32.036666  5211 net.cpp:615] ReLU48 <- Convolution48
I0612 11:07:32.036674  5211 net.cpp:576] ReLU48 -> Convolution48 (in-place)
I0612 11:07:32.036681  5211 net.cpp:240] Setting up ReLU48
I0612 11:07:32.036687  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.036690  5211 net.cpp:255] Memory required for data: 1968702976
I0612 11:07:32.036695  5211 layer_factory.hpp:77] Creating layer Convolution49
I0612 11:07:32.036703  5211 net.cpp:190] Creating Layer Convolution49
I0612 11:07:32.036707  5211 net.cpp:615] Convolution49 <- Convolution48
I0612 11:07:32.036715  5211 net.cpp:589] Convolution49 -> Convolution49
I0612 11:07:32.037333  5211 net.cpp:240] Setting up Convolution49
I0612 11:07:32.037341  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.037345  5211 net.cpp:255] Memory required for data: 1972897280
I0612 11:07:32.037354  5211 layer_factory.hpp:77] Creating layer BatchNorm49
I0612 11:07:32.037361  5211 net.cpp:190] Creating Layer BatchNorm49
I0612 11:07:32.037366  5211 net.cpp:615] BatchNorm49 <- Convolution49
I0612 11:07:32.037374  5211 net.cpp:576] BatchNorm49 -> Convolution49 (in-place)
I0612 11:07:32.037585  5211 net.cpp:240] Setting up BatchNorm49
I0612 11:07:32.037592  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.037596  5211 net.cpp:255] Memory required for data: 1977091584
I0612 11:07:32.037607  5211 layer_factory.hpp:77] Creating layer Scale49
I0612 11:07:32.037614  5211 net.cpp:190] Creating Layer Scale49
I0612 11:07:32.037618  5211 net.cpp:615] Scale49 <- Convolution49
I0612 11:07:32.037624  5211 net.cpp:576] Scale49 -> Convolution49 (in-place)
I0612 11:07:32.037662  5211 layer_factory.hpp:77] Creating layer Scale49
I0612 11:07:32.037787  5211 net.cpp:240] Setting up Scale49
I0612 11:07:32.037794  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.037798  5211 net.cpp:255] Memory required for data: 1981285888
I0612 11:07:32.037807  5211 layer_factory.hpp:77] Creating layer Eltwise24
I0612 11:07:32.037817  5211 net.cpp:190] Creating Layer Eltwise24
I0612 11:07:32.037822  5211 net.cpp:615] Eltwise24 <- Eltwise23_ReLU47_0_split_1
I0612 11:07:32.037827  5211 net.cpp:615] Eltwise24 <- Convolution49
I0612 11:07:32.037833  5211 net.cpp:589] Eltwise24 -> Eltwise24
I0612 11:07:32.037853  5211 net.cpp:240] Setting up Eltwise24
I0612 11:07:32.037860  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.037863  5211 net.cpp:255] Memory required for data: 1985480192
I0612 11:07:32.037868  5211 layer_factory.hpp:77] Creating layer ReLU49
I0612 11:07:32.037880  5211 net.cpp:190] Creating Layer ReLU49
I0612 11:07:32.037885  5211 net.cpp:615] ReLU49 <- Eltwise24
I0612 11:07:32.037891  5211 net.cpp:576] ReLU49 -> Eltwise24 (in-place)
I0612 11:07:32.037899  5211 net.cpp:240] Setting up ReLU49
I0612 11:07:32.037904  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.037907  5211 net.cpp:255] Memory required for data: 1989674496
I0612 11:07:32.037911  5211 layer_factory.hpp:77] Creating layer Eltwise24_ReLU49_0_split
I0612 11:07:32.037916  5211 net.cpp:190] Creating Layer Eltwise24_ReLU49_0_split
I0612 11:07:32.037922  5211 net.cpp:615] Eltwise24_ReLU49_0_split <- Eltwise24
I0612 11:07:32.037928  5211 net.cpp:589] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_0
I0612 11:07:32.037953  5211 net.cpp:589] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_1
I0612 11:07:32.037997  5211 net.cpp:240] Setting up Eltwise24_ReLU49_0_split
I0612 11:07:32.038004  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.038010  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.038013  5211 net.cpp:255] Memory required for data: 1998063104
I0612 11:07:32.038017  5211 layer_factory.hpp:77] Creating layer Convolution50
I0612 11:07:32.038028  5211 net.cpp:190] Creating Layer Convolution50
I0612 11:07:32.038033  5211 net.cpp:615] Convolution50 <- Eltwise24_ReLU49_0_split_0
I0612 11:07:32.038044  5211 net.cpp:589] Convolution50 -> Convolution50
I0612 11:07:32.038902  5211 net.cpp:240] Setting up Convolution50
I0612 11:07:32.038923  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.038929  5211 net.cpp:255] Memory required for data: 2002257408
I0612 11:07:32.038947  5211 layer_factory.hpp:77] Creating layer BatchNorm50
I0612 11:07:32.038964  5211 net.cpp:190] Creating Layer BatchNorm50
I0612 11:07:32.038975  5211 net.cpp:615] BatchNorm50 <- Convolution50
I0612 11:07:32.038985  5211 net.cpp:576] BatchNorm50 -> Convolution50 (in-place)
I0612 11:07:32.039377  5211 net.cpp:240] Setting up BatchNorm50
I0612 11:07:32.039391  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.039398  5211 net.cpp:255] Memory required for data: 2006451712
I0612 11:07:32.039420  5211 layer_factory.hpp:77] Creating layer Scale50
I0612 11:07:32.039433  5211 net.cpp:190] Creating Layer Scale50
I0612 11:07:32.039440  5211 net.cpp:615] Scale50 <- Convolution50
I0612 11:07:32.039454  5211 net.cpp:576] Scale50 -> Convolution50 (in-place)
I0612 11:07:32.039520  5211 layer_factory.hpp:77] Creating layer Scale50
I0612 11:07:32.039749  5211 net.cpp:240] Setting up Scale50
I0612 11:07:32.039762  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.039769  5211 net.cpp:255] Memory required for data: 2010646016
I0612 11:07:32.039789  5211 layer_factory.hpp:77] Creating layer ReLU50
I0612 11:07:32.039801  5211 net.cpp:190] Creating Layer ReLU50
I0612 11:07:32.039810  5211 net.cpp:615] ReLU50 <- Convolution50
I0612 11:07:32.039820  5211 net.cpp:576] ReLU50 -> Convolution50 (in-place)
I0612 11:07:32.039834  5211 net.cpp:240] Setting up ReLU50
I0612 11:07:32.039844  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.039851  5211 net.cpp:255] Memory required for data: 2014840320
I0612 11:07:32.039858  5211 layer_factory.hpp:77] Creating layer Convolution51
I0612 11:07:32.039877  5211 net.cpp:190] Creating Layer Convolution51
I0612 11:07:32.039885  5211 net.cpp:615] Convolution51 <- Convolution50
I0612 11:07:32.039901  5211 net.cpp:589] Convolution51 -> Convolution51
I0612 11:07:32.041064  5211 net.cpp:240] Setting up Convolution51
I0612 11:07:32.041079  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.041085  5211 net.cpp:255] Memory required for data: 2019034624
I0612 11:07:32.041102  5211 layer_factory.hpp:77] Creating layer BatchNorm51
I0612 11:07:32.041117  5211 net.cpp:190] Creating Layer BatchNorm51
I0612 11:07:32.041126  5211 net.cpp:615] BatchNorm51 <- Convolution51
I0612 11:07:32.041143  5211 net.cpp:576] BatchNorm51 -> Convolution51 (in-place)
I0612 11:07:32.041538  5211 net.cpp:240] Setting up BatchNorm51
I0612 11:07:32.041553  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.041560  5211 net.cpp:255] Memory required for data: 2023228928
I0612 11:07:32.041580  5211 layer_factory.hpp:77] Creating layer Scale51
I0612 11:07:32.041641  5211 net.cpp:190] Creating Layer Scale51
I0612 11:07:32.041651  5211 net.cpp:615] Scale51 <- Convolution51
I0612 11:07:32.041663  5211 net.cpp:576] Scale51 -> Convolution51 (in-place)
I0612 11:07:32.041740  5211 layer_factory.hpp:77] Creating layer Scale51
I0612 11:07:32.041976  5211 net.cpp:240] Setting up Scale51
I0612 11:07:32.041990  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.041996  5211 net.cpp:255] Memory required for data: 2027423232
I0612 11:07:32.042016  5211 layer_factory.hpp:77] Creating layer Eltwise25
I0612 11:07:32.042029  5211 net.cpp:190] Creating Layer Eltwise25
I0612 11:07:32.042038  5211 net.cpp:615] Eltwise25 <- Eltwise24_ReLU49_0_split_1
I0612 11:07:32.042048  5211 net.cpp:615] Eltwise25 <- Convolution51
I0612 11:07:32.042060  5211 net.cpp:589] Eltwise25 -> Eltwise25
I0612 11:07:32.042098  5211 net.cpp:240] Setting up Eltwise25
I0612 11:07:32.042109  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.042116  5211 net.cpp:255] Memory required for data: 2031617536
I0612 11:07:32.042124  5211 layer_factory.hpp:77] Creating layer ReLU51
I0612 11:07:32.042140  5211 net.cpp:190] Creating Layer ReLU51
I0612 11:07:32.042147  5211 net.cpp:615] ReLU51 <- Eltwise25
I0612 11:07:32.042163  5211 net.cpp:576] ReLU51 -> Eltwise25 (in-place)
I0612 11:07:32.042176  5211 net.cpp:240] Setting up ReLU51
I0612 11:07:32.042186  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.042194  5211 net.cpp:255] Memory required for data: 2035811840
I0612 11:07:32.042201  5211 layer_factory.hpp:77] Creating layer Eltwise25_ReLU51_0_split
I0612 11:07:32.042212  5211 net.cpp:190] Creating Layer Eltwise25_ReLU51_0_split
I0612 11:07:32.042219  5211 net.cpp:615] Eltwise25_ReLU51_0_split <- Eltwise25
I0612 11:07:32.042232  5211 net.cpp:589] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_0
I0612 11:07:32.042248  5211 net.cpp:589] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_1
I0612 11:07:32.042320  5211 net.cpp:240] Setting up Eltwise25_ReLU51_0_split
I0612 11:07:32.042332  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.042341  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.042348  5211 net.cpp:255] Memory required for data: 2044200448
I0612 11:07:32.042366  5211 layer_factory.hpp:77] Creating layer Convolution52
I0612 11:07:32.042383  5211 net.cpp:190] Creating Layer Convolution52
I0612 11:07:32.042392  5211 net.cpp:615] Convolution52 <- Eltwise25_ReLU51_0_split_0
I0612 11:07:32.042409  5211 net.cpp:589] Convolution52 -> Convolution52
I0612 11:07:32.043576  5211 net.cpp:240] Setting up Convolution52
I0612 11:07:32.043591  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.043599  5211 net.cpp:255] Memory required for data: 2048394752
I0612 11:07:32.043617  5211 layer_factory.hpp:77] Creating layer BatchNorm52
I0612 11:07:32.043629  5211 net.cpp:190] Creating Layer BatchNorm52
I0612 11:07:32.043637  5211 net.cpp:615] BatchNorm52 <- Convolution52
I0612 11:07:32.043651  5211 net.cpp:576] BatchNorm52 -> Convolution52 (in-place)
I0612 11:07:32.044052  5211 net.cpp:240] Setting up BatchNorm52
I0612 11:07:32.044066  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.044075  5211 net.cpp:255] Memory required for data: 2052589056
I0612 11:07:32.044095  5211 layer_factory.hpp:77] Creating layer Scale52
I0612 11:07:32.044106  5211 net.cpp:190] Creating Layer Scale52
I0612 11:07:32.044116  5211 net.cpp:615] Scale52 <- Convolution52
I0612 11:07:32.044126  5211 net.cpp:576] Scale52 -> Convolution52 (in-place)
I0612 11:07:32.044195  5211 layer_factory.hpp:77] Creating layer Scale52
I0612 11:07:32.044425  5211 net.cpp:240] Setting up Scale52
I0612 11:07:32.044437  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.044445  5211 net.cpp:255] Memory required for data: 2056783360
I0612 11:07:32.044461  5211 layer_factory.hpp:77] Creating layer ReLU52
I0612 11:07:32.044476  5211 net.cpp:190] Creating Layer ReLU52
I0612 11:07:32.044484  5211 net.cpp:615] ReLU52 <- Convolution52
I0612 11:07:32.044494  5211 net.cpp:576] ReLU52 -> Convolution52 (in-place)
I0612 11:07:32.044507  5211 net.cpp:240] Setting up ReLU52
I0612 11:07:32.044517  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.044524  5211 net.cpp:255] Memory required for data: 2060977664
I0612 11:07:32.044531  5211 layer_factory.hpp:77] Creating layer Convolution53
I0612 11:07:32.044551  5211 net.cpp:190] Creating Layer Convolution53
I0612 11:07:32.044559  5211 net.cpp:615] Convolution53 <- Convolution52
I0612 11:07:32.044574  5211 net.cpp:589] Convolution53 -> Convolution53
I0612 11:07:32.045742  5211 net.cpp:240] Setting up Convolution53
I0612 11:07:32.045758  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.045764  5211 net.cpp:255] Memory required for data: 2065171968
I0612 11:07:32.045780  5211 layer_factory.hpp:77] Creating layer BatchNorm53
I0612 11:07:32.045797  5211 net.cpp:190] Creating Layer BatchNorm53
I0612 11:07:32.045806  5211 net.cpp:615] BatchNorm53 <- Convolution53
I0612 11:07:32.045817  5211 net.cpp:576] BatchNorm53 -> Convolution53 (in-place)
I0612 11:07:32.046212  5211 net.cpp:240] Setting up BatchNorm53
I0612 11:07:32.046226  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.046233  5211 net.cpp:255] Memory required for data: 2069366272
I0612 11:07:32.046254  5211 layer_factory.hpp:77] Creating layer Scale53
I0612 11:07:32.046267  5211 net.cpp:190] Creating Layer Scale53
I0612 11:07:32.046274  5211 net.cpp:615] Scale53 <- Convolution53
I0612 11:07:32.046288  5211 net.cpp:576] Scale53 -> Convolution53 (in-place)
I0612 11:07:32.046371  5211 layer_factory.hpp:77] Creating layer Scale53
I0612 11:07:32.046603  5211 net.cpp:240] Setting up Scale53
I0612 11:07:32.046622  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.046628  5211 net.cpp:255] Memory required for data: 2073560576
I0612 11:07:32.046645  5211 layer_factory.hpp:77] Creating layer Eltwise26
I0612 11:07:32.046658  5211 net.cpp:190] Creating Layer Eltwise26
I0612 11:07:32.046666  5211 net.cpp:615] Eltwise26 <- Eltwise25_ReLU51_0_split_1
I0612 11:07:32.046677  5211 net.cpp:615] Eltwise26 <- Convolution53
I0612 11:07:32.046689  5211 net.cpp:589] Eltwise26 -> Eltwise26
I0612 11:07:32.046727  5211 net.cpp:240] Setting up Eltwise26
I0612 11:07:32.046739  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.046747  5211 net.cpp:255] Memory required for data: 2077754880
I0612 11:07:32.046754  5211 layer_factory.hpp:77] Creating layer ReLU53
I0612 11:07:32.046764  5211 net.cpp:190] Creating Layer ReLU53
I0612 11:07:32.046772  5211 net.cpp:615] ReLU53 <- Eltwise26
I0612 11:07:32.046784  5211 net.cpp:576] ReLU53 -> Eltwise26 (in-place)
I0612 11:07:32.046798  5211 net.cpp:240] Setting up ReLU53
I0612 11:07:32.046808  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.046815  5211 net.cpp:255] Memory required for data: 2081949184
I0612 11:07:32.046823  5211 layer_factory.hpp:77] Creating layer Eltwise26_ReLU53_0_split
I0612 11:07:32.046833  5211 net.cpp:190] Creating Layer Eltwise26_ReLU53_0_split
I0612 11:07:32.046840  5211 net.cpp:615] Eltwise26_ReLU53_0_split <- Eltwise26
I0612 11:07:32.046850  5211 net.cpp:589] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_0
I0612 11:07:32.046864  5211 net.cpp:589] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_1
I0612 11:07:32.046939  5211 net.cpp:240] Setting up Eltwise26_ReLU53_0_split
I0612 11:07:32.046952  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.046962  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.046969  5211 net.cpp:255] Memory required for data: 2090337792
I0612 11:07:32.046977  5211 layer_factory.hpp:77] Creating layer Convolution54
I0612 11:07:32.046995  5211 net.cpp:190] Creating Layer Convolution54
I0612 11:07:32.047004  5211 net.cpp:615] Convolution54 <- Eltwise26_ReLU53_0_split_0
I0612 11:07:32.047019  5211 net.cpp:589] Convolution54 -> Convolution54
I0612 11:07:32.048184  5211 net.cpp:240] Setting up Convolution54
I0612 11:07:32.048199  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.048207  5211 net.cpp:255] Memory required for data: 2094532096
I0612 11:07:32.048223  5211 layer_factory.hpp:77] Creating layer BatchNorm54
I0612 11:07:32.048241  5211 net.cpp:190] Creating Layer BatchNorm54
I0612 11:07:32.048250  5211 net.cpp:615] BatchNorm54 <- Convolution54
I0612 11:07:32.048261  5211 net.cpp:576] BatchNorm54 -> Convolution54 (in-place)
I0612 11:07:32.048653  5211 net.cpp:240] Setting up BatchNorm54
I0612 11:07:32.048667  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.048674  5211 net.cpp:255] Memory required for data: 2098726400
I0612 11:07:32.048694  5211 layer_factory.hpp:77] Creating layer Scale54
I0612 11:07:32.048709  5211 net.cpp:190] Creating Layer Scale54
I0612 11:07:32.048718  5211 net.cpp:615] Scale54 <- Convolution54
I0612 11:07:32.048729  5211 net.cpp:576] Scale54 -> Convolution54 (in-place)
I0612 11:07:32.048799  5211 layer_factory.hpp:77] Creating layer Scale54
I0612 11:07:32.049033  5211 net.cpp:240] Setting up Scale54
I0612 11:07:32.049047  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.049059  5211 net.cpp:255] Memory required for data: 2102920704
I0612 11:07:32.049077  5211 layer_factory.hpp:77] Creating layer ReLU54
I0612 11:07:32.049091  5211 net.cpp:190] Creating Layer ReLU54
I0612 11:07:32.049100  5211 net.cpp:615] ReLU54 <- Convolution54
I0612 11:07:32.049111  5211 net.cpp:576] ReLU54 -> Convolution54 (in-place)
I0612 11:07:32.049124  5211 net.cpp:240] Setting up ReLU54
I0612 11:07:32.049134  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.049141  5211 net.cpp:255] Memory required for data: 2107115008
I0612 11:07:32.049149  5211 layer_factory.hpp:77] Creating layer Convolution55
I0612 11:07:32.049167  5211 net.cpp:190] Creating Layer Convolution55
I0612 11:07:32.049175  5211 net.cpp:615] Convolution55 <- Convolution54
I0612 11:07:32.049187  5211 net.cpp:589] Convolution55 -> Convolution55
I0612 11:07:32.050349  5211 net.cpp:240] Setting up Convolution55
I0612 11:07:32.050379  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.050385  5211 net.cpp:255] Memory required for data: 2111309312
I0612 11:07:32.050402  5211 layer_factory.hpp:77] Creating layer BatchNorm55
I0612 11:07:32.050428  5211 net.cpp:190] Creating Layer BatchNorm55
I0612 11:07:32.050436  5211 net.cpp:615] BatchNorm55 <- Convolution55
I0612 11:07:32.050446  5211 net.cpp:576] BatchNorm55 -> Convolution55 (in-place)
I0612 11:07:32.050809  5211 net.cpp:240] Setting up BatchNorm55
I0612 11:07:32.050822  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.050829  5211 net.cpp:255] Memory required for data: 2115503616
I0612 11:07:32.050851  5211 layer_factory.hpp:77] Creating layer Scale55
I0612 11:07:32.050863  5211 net.cpp:190] Creating Layer Scale55
I0612 11:07:32.050870  5211 net.cpp:615] Scale55 <- Convolution55
I0612 11:07:32.050879  5211 net.cpp:576] Scale55 -> Convolution55 (in-place)
I0612 11:07:32.050942  5211 layer_factory.hpp:77] Creating layer Scale55
I0612 11:07:32.051158  5211 net.cpp:240] Setting up Scale55
I0612 11:07:32.051170  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.051177  5211 net.cpp:255] Memory required for data: 2119697920
I0612 11:07:32.051192  5211 layer_factory.hpp:77] Creating layer Eltwise27
I0612 11:07:32.051206  5211 net.cpp:190] Creating Layer Eltwise27
I0612 11:07:32.051215  5211 net.cpp:615] Eltwise27 <- Eltwise26_ReLU53_0_split_1
I0612 11:07:32.051225  5211 net.cpp:615] Eltwise27 <- Convolution55
I0612 11:07:32.051235  5211 net.cpp:589] Eltwise27 -> Eltwise27
I0612 11:07:32.051272  5211 net.cpp:240] Setting up Eltwise27
I0612 11:07:32.051283  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.051290  5211 net.cpp:255] Memory required for data: 2123892224
I0612 11:07:32.051296  5211 layer_factory.hpp:77] Creating layer ReLU55
I0612 11:07:32.051306  5211 net.cpp:190] Creating Layer ReLU55
I0612 11:07:32.051313  5211 net.cpp:615] ReLU55 <- Eltwise27
I0612 11:07:32.051326  5211 net.cpp:576] ReLU55 -> Eltwise27 (in-place)
I0612 11:07:32.051338  5211 net.cpp:240] Setting up ReLU55
I0612 11:07:32.051347  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.051354  5211 net.cpp:255] Memory required for data: 2128086528
I0612 11:07:32.051360  5211 layer_factory.hpp:77] Creating layer Eltwise27_ReLU55_0_split
I0612 11:07:32.051370  5211 net.cpp:190] Creating Layer Eltwise27_ReLU55_0_split
I0612 11:07:32.051378  5211 net.cpp:615] Eltwise27_ReLU55_0_split <- Eltwise27
I0612 11:07:32.051386  5211 net.cpp:589] Eltwise27_ReLU55_0_split -> Eltwise27_ReLU55_0_split_0
I0612 11:07:32.051399  5211 net.cpp:589] Eltwise27_ReLU55_0_split -> Eltwise27_ReLU55_0_split_1
I0612 11:07:32.051465  5211 net.cpp:240] Setting up Eltwise27_ReLU55_0_split
I0612 11:07:32.051476  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.051484  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.051491  5211 net.cpp:255] Memory required for data: 2136475136
I0612 11:07:32.051497  5211 layer_factory.hpp:77] Creating layer Convolution56
I0612 11:07:32.051512  5211 net.cpp:190] Creating Layer Convolution56
I0612 11:07:32.051525  5211 net.cpp:615] Convolution56 <- Eltwise27_ReLU55_0_split_0
I0612 11:07:32.051542  5211 net.cpp:589] Convolution56 -> Convolution56
I0612 11:07:32.052618  5211 net.cpp:240] Setting up Convolution56
I0612 11:07:32.052631  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.052639  5211 net.cpp:255] Memory required for data: 2140669440
I0612 11:07:32.052655  5211 layer_factory.hpp:77] Creating layer BatchNorm56
I0612 11:07:32.052666  5211 net.cpp:190] Creating Layer BatchNorm56
I0612 11:07:32.052675  5211 net.cpp:615] BatchNorm56 <- Convolution56
I0612 11:07:32.052687  5211 net.cpp:576] BatchNorm56 -> Convolution56 (in-place)
I0612 11:07:32.053051  5211 net.cpp:240] Setting up BatchNorm56
I0612 11:07:32.053064  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.053071  5211 net.cpp:255] Memory required for data: 2144863744
I0612 11:07:32.053091  5211 layer_factory.hpp:77] Creating layer Scale56
I0612 11:07:32.053102  5211 net.cpp:190] Creating Layer Scale56
I0612 11:07:32.053109  5211 net.cpp:615] Scale56 <- Convolution56
I0612 11:07:32.053118  5211 net.cpp:576] Scale56 -> Convolution56 (in-place)
I0612 11:07:32.053182  5211 layer_factory.hpp:77] Creating layer Scale56
I0612 11:07:32.053395  5211 net.cpp:240] Setting up Scale56
I0612 11:07:32.053407  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.053414  5211 net.cpp:255] Memory required for data: 2149058048
I0612 11:07:32.053429  5211 layer_factory.hpp:77] Creating layer ReLU56
I0612 11:07:32.053442  5211 net.cpp:190] Creating Layer ReLU56
I0612 11:07:32.053450  5211 net.cpp:615] ReLU56 <- Convolution56
I0612 11:07:32.053460  5211 net.cpp:576] ReLU56 -> Convolution56 (in-place)
I0612 11:07:32.053472  5211 net.cpp:240] Setting up ReLU56
I0612 11:07:32.053481  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.053488  5211 net.cpp:255] Memory required for data: 2153252352
I0612 11:07:32.053494  5211 layer_factory.hpp:77] Creating layer Convolution57
I0612 11:07:32.053513  5211 net.cpp:190] Creating Layer Convolution57
I0612 11:07:32.053519  5211 net.cpp:615] Convolution57 <- Convolution56
I0612 11:07:32.053531  5211 net.cpp:589] Convolution57 -> Convolution57
I0612 11:07:32.054615  5211 net.cpp:240] Setting up Convolution57
I0612 11:07:32.054628  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.054636  5211 net.cpp:255] Memory required for data: 2157446656
I0612 11:07:32.054651  5211 layer_factory.hpp:77] Creating layer BatchNorm57
I0612 11:07:32.054666  5211 net.cpp:190] Creating Layer BatchNorm57
I0612 11:07:32.054674  5211 net.cpp:615] BatchNorm57 <- Convolution57
I0612 11:07:32.054684  5211 net.cpp:576] BatchNorm57 -> Convolution57 (in-place)
I0612 11:07:32.055042  5211 net.cpp:240] Setting up BatchNorm57
I0612 11:07:32.055054  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.055061  5211 net.cpp:255] Memory required for data: 2161640960
I0612 11:07:32.055080  5211 layer_factory.hpp:77] Creating layer Scale57
I0612 11:07:32.055091  5211 net.cpp:190] Creating Layer Scale57
I0612 11:07:32.055099  5211 net.cpp:615] Scale57 <- Convolution57
I0612 11:07:32.055109  5211 net.cpp:576] Scale57 -> Convolution57 (in-place)
I0612 11:07:32.055171  5211 layer_factory.hpp:77] Creating layer Scale57
I0612 11:07:32.055382  5211 net.cpp:240] Setting up Scale57
I0612 11:07:32.055395  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.055402  5211 net.cpp:255] Memory required for data: 2165835264
I0612 11:07:32.055419  5211 layer_factory.hpp:77] Creating layer Eltwise28
I0612 11:07:32.055431  5211 net.cpp:190] Creating Layer Eltwise28
I0612 11:07:32.055440  5211 net.cpp:615] Eltwise28 <- Eltwise27_ReLU55_0_split_1
I0612 11:07:32.055450  5211 net.cpp:615] Eltwise28 <- Convolution57
I0612 11:07:32.055460  5211 net.cpp:589] Eltwise28 -> Eltwise28
I0612 11:07:32.055498  5211 net.cpp:240] Setting up Eltwise28
I0612 11:07:32.055510  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.055516  5211 net.cpp:255] Memory required for data: 2170029568
I0612 11:07:32.055527  5211 layer_factory.hpp:77] Creating layer ReLU57
I0612 11:07:32.055537  5211 net.cpp:190] Creating Layer ReLU57
I0612 11:07:32.055546  5211 net.cpp:615] ReLU57 <- Eltwise28
I0612 11:07:32.055557  5211 net.cpp:576] ReLU57 -> Eltwise28 (in-place)
I0612 11:07:32.055569  5211 net.cpp:240] Setting up ReLU57
I0612 11:07:32.055578  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.055584  5211 net.cpp:255] Memory required for data: 2174223872
I0612 11:07:32.055591  5211 layer_factory.hpp:77] Creating layer Eltwise28_ReLU57_0_split
I0612 11:07:32.055600  5211 net.cpp:190] Creating Layer Eltwise28_ReLU57_0_split
I0612 11:07:32.055608  5211 net.cpp:615] Eltwise28_ReLU57_0_split <- Eltwise28
I0612 11:07:32.055618  5211 net.cpp:589] Eltwise28_ReLU57_0_split -> Eltwise28_ReLU57_0_split_0
I0612 11:07:32.055629  5211 net.cpp:589] Eltwise28_ReLU57_0_split -> Eltwise28_ReLU57_0_split_1
I0612 11:07:32.055696  5211 net.cpp:240] Setting up Eltwise28_ReLU57_0_split
I0612 11:07:32.055707  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.055716  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.055722  5211 net.cpp:255] Memory required for data: 2182612480
I0612 11:07:32.055729  5211 layer_factory.hpp:77] Creating layer Convolution58
I0612 11:07:32.055747  5211 net.cpp:190] Creating Layer Convolution58
I0612 11:07:32.055754  5211 net.cpp:615] Convolution58 <- Eltwise28_ReLU57_0_split_0
I0612 11:07:32.055768  5211 net.cpp:589] Convolution58 -> Convolution58
I0612 11:07:32.057850  5211 net.cpp:240] Setting up Convolution58
I0612 11:07:32.057878  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.057885  5211 net.cpp:255] Memory required for data: 2186806784
I0612 11:07:32.057904  5211 layer_factory.hpp:77] Creating layer BatchNorm58
I0612 11:07:32.057917  5211 net.cpp:190] Creating Layer BatchNorm58
I0612 11:07:32.057926  5211 net.cpp:615] BatchNorm58 <- Convolution58
I0612 11:07:32.057940  5211 net.cpp:576] BatchNorm58 -> Convolution58 (in-place)
I0612 11:07:32.058320  5211 net.cpp:240] Setting up BatchNorm58
I0612 11:07:32.058334  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.058341  5211 net.cpp:255] Memory required for data: 2191001088
I0612 11:07:32.058372  5211 layer_factory.hpp:77] Creating layer Scale58
I0612 11:07:32.058385  5211 net.cpp:190] Creating Layer Scale58
I0612 11:07:32.058393  5211 net.cpp:615] Scale58 <- Convolution58
I0612 11:07:32.058403  5211 net.cpp:576] Scale58 -> Convolution58 (in-place)
I0612 11:07:32.058471  5211 layer_factory.hpp:77] Creating layer Scale58
I0612 11:07:32.058691  5211 net.cpp:240] Setting up Scale58
I0612 11:07:32.058703  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.058711  5211 net.cpp:255] Memory required for data: 2195195392
I0612 11:07:32.058727  5211 layer_factory.hpp:77] Creating layer ReLU58
I0612 11:07:32.058737  5211 net.cpp:190] Creating Layer ReLU58
I0612 11:07:32.058745  5211 net.cpp:615] ReLU58 <- Convolution58
I0612 11:07:32.058758  5211 net.cpp:576] ReLU58 -> Convolution58 (in-place)
I0612 11:07:32.058771  5211 net.cpp:240] Setting up ReLU58
I0612 11:07:32.058781  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.058787  5211 net.cpp:255] Memory required for data: 2199389696
I0612 11:07:32.058794  5211 layer_factory.hpp:77] Creating layer Convolution59
I0612 11:07:32.058809  5211 net.cpp:190] Creating Layer Convolution59
I0612 11:07:32.058816  5211 net.cpp:615] Convolution59 <- Convolution58
I0612 11:07:32.058831  5211 net.cpp:589] Convolution59 -> Convolution59
I0612 11:07:32.059907  5211 net.cpp:240] Setting up Convolution59
I0612 11:07:32.059922  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.059929  5211 net.cpp:255] Memory required for data: 2203584000
I0612 11:07:32.059945  5211 layer_factory.hpp:77] Creating layer BatchNorm59
I0612 11:07:32.059957  5211 net.cpp:190] Creating Layer BatchNorm59
I0612 11:07:32.059965  5211 net.cpp:615] BatchNorm59 <- Convolution59
I0612 11:07:32.059981  5211 net.cpp:576] BatchNorm59 -> Convolution59 (in-place)
I0612 11:07:32.060358  5211 net.cpp:240] Setting up BatchNorm59
I0612 11:07:32.060371  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.060377  5211 net.cpp:255] Memory required for data: 2207778304
I0612 11:07:32.060397  5211 layer_factory.hpp:77] Creating layer Scale59
I0612 11:07:32.060410  5211 net.cpp:190] Creating Layer Scale59
I0612 11:07:32.060416  5211 net.cpp:615] Scale59 <- Convolution59
I0612 11:07:32.060426  5211 net.cpp:576] Scale59 -> Convolution59 (in-place)
I0612 11:07:32.060492  5211 layer_factory.hpp:77] Creating layer Scale59
I0612 11:07:32.060708  5211 net.cpp:240] Setting up Scale59
I0612 11:07:32.060719  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.060726  5211 net.cpp:255] Memory required for data: 2211972608
I0612 11:07:32.060741  5211 layer_factory.hpp:77] Creating layer Eltwise29
I0612 11:07:32.060755  5211 net.cpp:190] Creating Layer Eltwise29
I0612 11:07:32.060765  5211 net.cpp:615] Eltwise29 <- Eltwise28_ReLU57_0_split_1
I0612 11:07:32.060775  5211 net.cpp:615] Eltwise29 <- Convolution59
I0612 11:07:32.060784  5211 net.cpp:589] Eltwise29 -> Eltwise29
I0612 11:07:32.060820  5211 net.cpp:240] Setting up Eltwise29
I0612 11:07:32.060832  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.060837  5211 net.cpp:255] Memory required for data: 2216166912
I0612 11:07:32.060843  5211 layer_factory.hpp:77] Creating layer ReLU59
I0612 11:07:32.060863  5211 net.cpp:190] Creating Layer ReLU59
I0612 11:07:32.060870  5211 net.cpp:615] ReLU59 <- Eltwise29
I0612 11:07:32.060880  5211 net.cpp:576] ReLU59 -> Eltwise29 (in-place)
I0612 11:07:32.060892  5211 net.cpp:240] Setting up ReLU59
I0612 11:07:32.060901  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.060909  5211 net.cpp:255] Memory required for data: 2220361216
I0612 11:07:32.060914  5211 layer_factory.hpp:77] Creating layer Eltwise29_ReLU59_0_split
I0612 11:07:32.060927  5211 net.cpp:190] Creating Layer Eltwise29_ReLU59_0_split
I0612 11:07:32.060935  5211 net.cpp:615] Eltwise29_ReLU59_0_split <- Eltwise29
I0612 11:07:32.060943  5211 net.cpp:589] Eltwise29_ReLU59_0_split -> Eltwise29_ReLU59_0_split_0
I0612 11:07:32.060956  5211 net.cpp:589] Eltwise29_ReLU59_0_split -> Eltwise29_ReLU59_0_split_1
I0612 11:07:32.061025  5211 net.cpp:240] Setting up Eltwise29_ReLU59_0_split
I0612 11:07:32.061036  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.061045  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.061053  5211 net.cpp:255] Memory required for data: 2228749824
I0612 11:07:32.061058  5211 layer_factory.hpp:77] Creating layer Convolution60
I0612 11:07:32.061075  5211 net.cpp:190] Creating Layer Convolution60
I0612 11:07:32.061084  5211 net.cpp:615] Convolution60 <- Eltwise29_ReLU59_0_split_0
I0612 11:07:32.061096  5211 net.cpp:589] Convolution60 -> Convolution60
I0612 11:07:32.062176  5211 net.cpp:240] Setting up Convolution60
I0612 11:07:32.062189  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.062196  5211 net.cpp:255] Memory required for data: 2232944128
I0612 11:07:32.062213  5211 layer_factory.hpp:77] Creating layer BatchNorm60
I0612 11:07:32.062227  5211 net.cpp:190] Creating Layer BatchNorm60
I0612 11:07:32.062237  5211 net.cpp:615] BatchNorm60 <- Convolution60
I0612 11:07:32.062248  5211 net.cpp:576] BatchNorm60 -> Convolution60 (in-place)
I0612 11:07:32.062630  5211 net.cpp:240] Setting up BatchNorm60
I0612 11:07:32.062644  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.062649  5211 net.cpp:255] Memory required for data: 2237138432
I0612 11:07:32.062667  5211 layer_factory.hpp:77] Creating layer Scale60
I0612 11:07:32.062685  5211 net.cpp:190] Creating Layer Scale60
I0612 11:07:32.062692  5211 net.cpp:615] Scale60 <- Convolution60
I0612 11:07:32.062701  5211 net.cpp:576] Scale60 -> Convolution60 (in-place)
I0612 11:07:32.062759  5211 layer_factory.hpp:77] Creating layer Scale60
I0612 11:07:32.062963  5211 net.cpp:240] Setting up Scale60
I0612 11:07:32.062973  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.062983  5211 net.cpp:255] Memory required for data: 2241332736
I0612 11:07:32.062999  5211 layer_factory.hpp:77] Creating layer ReLU60
I0612 11:07:32.063009  5211 net.cpp:190] Creating Layer ReLU60
I0612 11:07:32.063016  5211 net.cpp:615] ReLU60 <- Convolution60
I0612 11:07:32.063025  5211 net.cpp:576] ReLU60 -> Convolution60 (in-place)
I0612 11:07:32.063036  5211 net.cpp:240] Setting up ReLU60
I0612 11:07:32.063045  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.063051  5211 net.cpp:255] Memory required for data: 2245527040
I0612 11:07:32.063057  5211 layer_factory.hpp:77] Creating layer Convolution61
I0612 11:07:32.063077  5211 net.cpp:190] Creating Layer Convolution61
I0612 11:07:32.063084  5211 net.cpp:615] Convolution61 <- Convolution60
I0612 11:07:32.063096  5211 net.cpp:589] Convolution61 -> Convolution61
I0612 11:07:32.064096  5211 net.cpp:240] Setting up Convolution61
I0612 11:07:32.064110  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.064116  5211 net.cpp:255] Memory required for data: 2249721344
I0612 11:07:32.064131  5211 layer_factory.hpp:77] Creating layer BatchNorm61
I0612 11:07:32.064144  5211 net.cpp:190] Creating Layer BatchNorm61
I0612 11:07:32.064152  5211 net.cpp:615] BatchNorm61 <- Convolution61
I0612 11:07:32.064163  5211 net.cpp:576] BatchNorm61 -> Convolution61 (in-place)
I0612 11:07:32.064502  5211 net.cpp:240] Setting up BatchNorm61
I0612 11:07:32.064513  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.064520  5211 net.cpp:255] Memory required for data: 2253915648
I0612 11:07:32.064538  5211 layer_factory.hpp:77] Creating layer Scale61
I0612 11:07:32.064551  5211 net.cpp:190] Creating Layer Scale61
I0612 11:07:32.064559  5211 net.cpp:615] Scale61 <- Convolution61
I0612 11:07:32.064568  5211 net.cpp:576] Scale61 -> Convolution61 (in-place)
I0612 11:07:32.064628  5211 layer_factory.hpp:77] Creating layer Scale61
I0612 11:07:32.064828  5211 net.cpp:240] Setting up Scale61
I0612 11:07:32.064839  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.064846  5211 net.cpp:255] Memory required for data: 2258109952
I0612 11:07:32.064859  5211 layer_factory.hpp:77] Creating layer Eltwise30
I0612 11:07:32.064870  5211 net.cpp:190] Creating Layer Eltwise30
I0612 11:07:32.064878  5211 net.cpp:615] Eltwise30 <- Eltwise29_ReLU59_0_split_1
I0612 11:07:32.064890  5211 net.cpp:615] Eltwise30 <- Convolution61
I0612 11:07:32.064900  5211 net.cpp:589] Eltwise30 -> Eltwise30
I0612 11:07:32.064932  5211 net.cpp:240] Setting up Eltwise30
I0612 11:07:32.064946  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.064952  5211 net.cpp:255] Memory required for data: 2262304256
I0612 11:07:32.064959  5211 layer_factory.hpp:77] Creating layer ReLU61
I0612 11:07:32.064968  5211 net.cpp:190] Creating Layer ReLU61
I0612 11:07:32.064975  5211 net.cpp:615] ReLU61 <- Eltwise30
I0612 11:07:32.064983  5211 net.cpp:576] ReLU61 -> Eltwise30 (in-place)
I0612 11:07:32.064995  5211 net.cpp:240] Setting up ReLU61
I0612 11:07:32.065002  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.065009  5211 net.cpp:255] Memory required for data: 2266498560
I0612 11:07:32.065016  5211 layer_factory.hpp:77] Creating layer Eltwise30_ReLU61_0_split
I0612 11:07:32.065024  5211 net.cpp:190] Creating Layer Eltwise30_ReLU61_0_split
I0612 11:07:32.065031  5211 net.cpp:615] Eltwise30_ReLU61_0_split <- Eltwise30
I0612 11:07:32.065042  5211 net.cpp:589] Eltwise30_ReLU61_0_split -> Eltwise30_ReLU61_0_split_0
I0612 11:07:32.065054  5211 net.cpp:589] Eltwise30_ReLU61_0_split -> Eltwise30_ReLU61_0_split_1
I0612 11:07:32.065114  5211 net.cpp:240] Setting up Eltwise30_ReLU61_0_split
I0612 11:07:32.065124  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.065132  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.065138  5211 net.cpp:255] Memory required for data: 2274887168
I0612 11:07:32.065145  5211 layer_factory.hpp:77] Creating layer Convolution62
I0612 11:07:32.065170  5211 net.cpp:190] Creating Layer Convolution62
I0612 11:07:32.065177  5211 net.cpp:615] Convolution62 <- Eltwise30_ReLU61_0_split_0
I0612 11:07:32.065189  5211 net.cpp:589] Convolution62 -> Convolution62
I0612 11:07:32.066184  5211 net.cpp:240] Setting up Convolution62
I0612 11:07:32.066196  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.066203  5211 net.cpp:255] Memory required for data: 2279081472
I0612 11:07:32.066218  5211 layer_factory.hpp:77] Creating layer BatchNorm62
I0612 11:07:32.066231  5211 net.cpp:190] Creating Layer BatchNorm62
I0612 11:07:32.066239  5211 net.cpp:615] BatchNorm62 <- Convolution62
I0612 11:07:32.066248  5211 net.cpp:576] BatchNorm62 -> Convolution62 (in-place)
I0612 11:07:32.066591  5211 net.cpp:240] Setting up BatchNorm62
I0612 11:07:32.066603  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.066609  5211 net.cpp:255] Memory required for data: 2283275776
I0612 11:07:32.066630  5211 layer_factory.hpp:77] Creating layer Scale62
I0612 11:07:32.066642  5211 net.cpp:190] Creating Layer Scale62
I0612 11:07:32.066648  5211 net.cpp:615] Scale62 <- Convolution62
I0612 11:07:32.066658  5211 net.cpp:576] Scale62 -> Convolution62 (in-place)
I0612 11:07:32.066720  5211 layer_factory.hpp:77] Creating layer Scale62
I0612 11:07:32.066920  5211 net.cpp:240] Setting up Scale62
I0612 11:07:32.066931  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.066938  5211 net.cpp:255] Memory required for data: 2287470080
I0612 11:07:32.066956  5211 layer_factory.hpp:77] Creating layer ReLU62
I0612 11:07:32.066967  5211 net.cpp:190] Creating Layer ReLU62
I0612 11:07:32.066973  5211 net.cpp:615] ReLU62 <- Convolution62
I0612 11:07:32.066984  5211 net.cpp:576] ReLU62 -> Convolution62 (in-place)
I0612 11:07:32.066995  5211 net.cpp:240] Setting up ReLU62
I0612 11:07:32.067004  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.067011  5211 net.cpp:255] Memory required for data: 2291664384
I0612 11:07:32.067018  5211 layer_factory.hpp:77] Creating layer Convolution63
I0612 11:07:32.067031  5211 net.cpp:190] Creating Layer Convolution63
I0612 11:07:32.067039  5211 net.cpp:615] Convolution63 <- Convolution62
I0612 11:07:32.067051  5211 net.cpp:589] Convolution63 -> Convolution63
I0612 11:07:32.068045  5211 net.cpp:240] Setting up Convolution63
I0612 11:07:32.068059  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.068066  5211 net.cpp:255] Memory required for data: 2295858688
I0612 11:07:32.068080  5211 layer_factory.hpp:77] Creating layer BatchNorm63
I0612 11:07:32.068091  5211 net.cpp:190] Creating Layer BatchNorm63
I0612 11:07:32.068099  5211 net.cpp:615] BatchNorm63 <- Convolution63
I0612 11:07:32.068111  5211 net.cpp:576] BatchNorm63 -> Convolution63 (in-place)
I0612 11:07:32.068454  5211 net.cpp:240] Setting up BatchNorm63
I0612 11:07:32.068464  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.068471  5211 net.cpp:255] Memory required for data: 2300052992
I0612 11:07:32.068488  5211 layer_factory.hpp:77] Creating layer Scale63
I0612 11:07:32.068500  5211 net.cpp:190] Creating Layer Scale63
I0612 11:07:32.068506  5211 net.cpp:615] Scale63 <- Convolution63
I0612 11:07:32.068514  5211 net.cpp:576] Scale63 -> Convolution63 (in-place)
I0612 11:07:32.068573  5211 layer_factory.hpp:77] Creating layer Scale63
I0612 11:07:32.068773  5211 net.cpp:240] Setting up Scale63
I0612 11:07:32.068784  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.068791  5211 net.cpp:255] Memory required for data: 2304247296
I0612 11:07:32.068805  5211 layer_factory.hpp:77] Creating layer Eltwise31
I0612 11:07:32.068819  5211 net.cpp:190] Creating Layer Eltwise31
I0612 11:07:32.068826  5211 net.cpp:615] Eltwise31 <- Eltwise30_ReLU61_0_split_1
I0612 11:07:32.068835  5211 net.cpp:615] Eltwise31 <- Convolution63
I0612 11:07:32.068845  5211 net.cpp:589] Eltwise31 -> Eltwise31
I0612 11:07:32.068877  5211 net.cpp:240] Setting up Eltwise31
I0612 11:07:32.068887  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.068897  5211 net.cpp:255] Memory required for data: 2308441600
I0612 11:07:32.068903  5211 layer_factory.hpp:77] Creating layer ReLU63
I0612 11:07:32.068917  5211 net.cpp:190] Creating Layer ReLU63
I0612 11:07:32.068923  5211 net.cpp:615] ReLU63 <- Eltwise31
I0612 11:07:32.068931  5211 net.cpp:576] ReLU63 -> Eltwise31 (in-place)
I0612 11:07:32.068943  5211 net.cpp:240] Setting up ReLU63
I0612 11:07:32.068951  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.068958  5211 net.cpp:255] Memory required for data: 2312635904
I0612 11:07:32.068964  5211 layer_factory.hpp:77] Creating layer Eltwise31_ReLU63_0_split
I0612 11:07:32.068974  5211 net.cpp:190] Creating Layer Eltwise31_ReLU63_0_split
I0612 11:07:32.068979  5211 net.cpp:615] Eltwise31_ReLU63_0_split <- Eltwise31
I0612 11:07:32.068991  5211 net.cpp:589] Eltwise31_ReLU63_0_split -> Eltwise31_ReLU63_0_split_0
I0612 11:07:32.069003  5211 net.cpp:589] Eltwise31_ReLU63_0_split -> Eltwise31_ReLU63_0_split_1
I0612 11:07:32.069067  5211 net.cpp:240] Setting up Eltwise31_ReLU63_0_split
I0612 11:07:32.069077  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.069085  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.069092  5211 net.cpp:255] Memory required for data: 2321024512
I0612 11:07:32.069098  5211 layer_factory.hpp:77] Creating layer Convolution64
I0612 11:07:32.069115  5211 net.cpp:190] Creating Layer Convolution64
I0612 11:07:32.069123  5211 net.cpp:615] Convolution64 <- Eltwise31_ReLU63_0_split_0
I0612 11:07:32.069134  5211 net.cpp:589] Convolution64 -> Convolution64
I0612 11:07:32.070125  5211 net.cpp:240] Setting up Convolution64
I0612 11:07:32.070139  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.070145  5211 net.cpp:255] Memory required for data: 2325218816
I0612 11:07:32.070160  5211 layer_factory.hpp:77] Creating layer BatchNorm64
I0612 11:07:32.070174  5211 net.cpp:190] Creating Layer BatchNorm64
I0612 11:07:32.070181  5211 net.cpp:615] BatchNorm64 <- Convolution64
I0612 11:07:32.070191  5211 net.cpp:576] BatchNorm64 -> Convolution64 (in-place)
I0612 11:07:32.070557  5211 net.cpp:240] Setting up BatchNorm64
I0612 11:07:32.070571  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.070577  5211 net.cpp:255] Memory required for data: 2329413120
I0612 11:07:32.070596  5211 layer_factory.hpp:77] Creating layer Scale64
I0612 11:07:32.070607  5211 net.cpp:190] Creating Layer Scale64
I0612 11:07:32.070616  5211 net.cpp:615] Scale64 <- Convolution64
I0612 11:07:32.070627  5211 net.cpp:576] Scale64 -> Convolution64 (in-place)
I0612 11:07:32.070685  5211 layer_factory.hpp:77] Creating layer Scale64
I0612 11:07:32.070889  5211 net.cpp:240] Setting up Scale64
I0612 11:07:32.070904  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.070910  5211 net.cpp:255] Memory required for data: 2333607424
I0612 11:07:32.070924  5211 layer_factory.hpp:77] Creating layer ReLU64
I0612 11:07:32.070935  5211 net.cpp:190] Creating Layer ReLU64
I0612 11:07:32.070942  5211 net.cpp:615] ReLU64 <- Convolution64
I0612 11:07:32.070951  5211 net.cpp:576] ReLU64 -> Convolution64 (in-place)
I0612 11:07:32.070962  5211 net.cpp:240] Setting up ReLU64
I0612 11:07:32.070971  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.070977  5211 net.cpp:255] Memory required for data: 2337801728
I0612 11:07:32.070983  5211 layer_factory.hpp:77] Creating layer Convolution65
I0612 11:07:32.071001  5211 net.cpp:190] Creating Layer Convolution65
I0612 11:07:32.071007  5211 net.cpp:615] Convolution65 <- Convolution64
I0612 11:07:32.071022  5211 net.cpp:589] Convolution65 -> Convolution65
I0612 11:07:32.072010  5211 net.cpp:240] Setting up Convolution65
I0612 11:07:32.072024  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.072031  5211 net.cpp:255] Memory required for data: 2341996032
I0612 11:07:32.072046  5211 layer_factory.hpp:77] Creating layer BatchNorm65
I0612 11:07:32.072058  5211 net.cpp:190] Creating Layer BatchNorm65
I0612 11:07:32.072067  5211 net.cpp:615] BatchNorm65 <- Convolution65
I0612 11:07:32.072084  5211 net.cpp:576] BatchNorm65 -> Convolution65 (in-place)
I0612 11:07:32.072419  5211 net.cpp:240] Setting up BatchNorm65
I0612 11:07:32.072432  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.072438  5211 net.cpp:255] Memory required for data: 2346190336
I0612 11:07:32.072456  5211 layer_factory.hpp:77] Creating layer Scale65
I0612 11:07:32.072471  5211 net.cpp:190] Creating Layer Scale65
I0612 11:07:32.072479  5211 net.cpp:615] Scale65 <- Convolution65
I0612 11:07:32.072487  5211 net.cpp:576] Scale65 -> Convolution65 (in-place)
I0612 11:07:32.072546  5211 layer_factory.hpp:77] Creating layer Scale65
I0612 11:07:32.072744  5211 net.cpp:240] Setting up Scale65
I0612 11:07:32.072756  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.072762  5211 net.cpp:255] Memory required for data: 2350384640
I0612 11:07:32.072777  5211 layer_factory.hpp:77] Creating layer Eltwise32
I0612 11:07:32.072788  5211 net.cpp:190] Creating Layer Eltwise32
I0612 11:07:32.072795  5211 net.cpp:615] Eltwise32 <- Eltwise31_ReLU63_0_split_1
I0612 11:07:32.072803  5211 net.cpp:615] Eltwise32 <- Convolution65
I0612 11:07:32.072816  5211 net.cpp:589] Eltwise32 -> Eltwise32
I0612 11:07:32.072849  5211 net.cpp:240] Setting up Eltwise32
I0612 11:07:32.072860  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.072865  5211 net.cpp:255] Memory required for data: 2354578944
I0612 11:07:32.072871  5211 layer_factory.hpp:77] Creating layer ReLU65
I0612 11:07:32.072883  5211 net.cpp:190] Creating Layer ReLU65
I0612 11:07:32.072890  5211 net.cpp:615] ReLU65 <- Eltwise32
I0612 11:07:32.072899  5211 net.cpp:576] ReLU65 -> Eltwise32 (in-place)
I0612 11:07:32.072911  5211 net.cpp:240] Setting up ReLU65
I0612 11:07:32.072918  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.072924  5211 net.cpp:255] Memory required for data: 2358773248
I0612 11:07:32.072931  5211 layer_factory.hpp:77] Creating layer Eltwise32_ReLU65_0_split
I0612 11:07:32.072939  5211 net.cpp:190] Creating Layer Eltwise32_ReLU65_0_split
I0612 11:07:32.072945  5211 net.cpp:615] Eltwise32_ReLU65_0_split <- Eltwise32
I0612 11:07:32.072957  5211 net.cpp:589] Eltwise32_ReLU65_0_split -> Eltwise32_ReLU65_0_split_0
I0612 11:07:32.072969  5211 net.cpp:589] Eltwise32_ReLU65_0_split -> Eltwise32_ReLU65_0_split_1
I0612 11:07:32.073029  5211 net.cpp:240] Setting up Eltwise32_ReLU65_0_split
I0612 11:07:32.073040  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.073047  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.073053  5211 net.cpp:255] Memory required for data: 2367161856
I0612 11:07:32.073060  5211 layer_factory.hpp:77] Creating layer Convolution66
I0612 11:07:32.073076  5211 net.cpp:190] Creating Layer Convolution66
I0612 11:07:32.073083  5211 net.cpp:615] Convolution66 <- Eltwise32_ReLU65_0_split_0
I0612 11:07:32.073094  5211 net.cpp:589] Convolution66 -> Convolution66
I0612 11:07:32.074092  5211 net.cpp:240] Setting up Convolution66
I0612 11:07:32.074106  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.074112  5211 net.cpp:255] Memory required for data: 2371356160
I0612 11:07:32.074127  5211 layer_factory.hpp:77] Creating layer BatchNorm66
I0612 11:07:32.074146  5211 net.cpp:190] Creating Layer BatchNorm66
I0612 11:07:32.074153  5211 net.cpp:615] BatchNorm66 <- Convolution66
I0612 11:07:32.074162  5211 net.cpp:576] BatchNorm66 -> Convolution66 (in-place)
I0612 11:07:32.074513  5211 net.cpp:240] Setting up BatchNorm66
I0612 11:07:32.074527  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.074533  5211 net.cpp:255] Memory required for data: 2375550464
I0612 11:07:32.074555  5211 layer_factory.hpp:77] Creating layer Scale66
I0612 11:07:32.074566  5211 net.cpp:190] Creating Layer Scale66
I0612 11:07:32.074573  5211 net.cpp:615] Scale66 <- Convolution66
I0612 11:07:32.074584  5211 net.cpp:576] Scale66 -> Convolution66 (in-place)
I0612 11:07:32.074645  5211 layer_factory.hpp:77] Creating layer Scale66
I0612 11:07:32.074854  5211 net.cpp:240] Setting up Scale66
I0612 11:07:32.074869  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.074875  5211 net.cpp:255] Memory required for data: 2379744768
I0612 11:07:32.074889  5211 layer_factory.hpp:77] Creating layer ReLU66
I0612 11:07:32.074901  5211 net.cpp:190] Creating Layer ReLU66
I0612 11:07:32.074909  5211 net.cpp:615] ReLU66 <- Convolution66
I0612 11:07:32.074918  5211 net.cpp:576] ReLU66 -> Convolution66 (in-place)
I0612 11:07:32.074928  5211 net.cpp:240] Setting up ReLU66
I0612 11:07:32.074936  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.074942  5211 net.cpp:255] Memory required for data: 2383939072
I0612 11:07:32.074947  5211 layer_factory.hpp:77] Creating layer Convolution67
I0612 11:07:32.074964  5211 net.cpp:190] Creating Layer Convolution67
I0612 11:07:32.074970  5211 net.cpp:615] Convolution67 <- Convolution66
I0612 11:07:32.074982  5211 net.cpp:589] Convolution67 -> Convolution67
I0612 11:07:32.075911  5211 net.cpp:240] Setting up Convolution67
I0612 11:07:32.075924  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.075930  5211 net.cpp:255] Memory required for data: 2388133376
I0612 11:07:32.075943  5211 layer_factory.hpp:77] Creating layer BatchNorm67
I0612 11:07:32.075954  5211 net.cpp:190] Creating Layer BatchNorm67
I0612 11:07:32.075961  5211 net.cpp:615] BatchNorm67 <- Convolution67
I0612 11:07:32.075969  5211 net.cpp:576] BatchNorm67 -> Convolution67 (in-place)
I0612 11:07:32.076287  5211 net.cpp:240] Setting up BatchNorm67
I0612 11:07:32.076297  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.076303  5211 net.cpp:255] Memory required for data: 2392327680
I0612 11:07:32.076320  5211 layer_factory.hpp:77] Creating layer Scale67
I0612 11:07:32.076330  5211 net.cpp:190] Creating Layer Scale67
I0612 11:07:32.076336  5211 net.cpp:615] Scale67 <- Convolution67
I0612 11:07:32.076345  5211 net.cpp:576] Scale67 -> Convolution67 (in-place)
I0612 11:07:32.076400  5211 layer_factory.hpp:77] Creating layer Scale67
I0612 11:07:32.076587  5211 net.cpp:240] Setting up Scale67
I0612 11:07:32.076598  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.076604  5211 net.cpp:255] Memory required for data: 2396521984
I0612 11:07:32.076619  5211 layer_factory.hpp:77] Creating layer Eltwise33
I0612 11:07:32.076629  5211 net.cpp:190] Creating Layer Eltwise33
I0612 11:07:32.076637  5211 net.cpp:615] Eltwise33 <- Eltwise32_ReLU65_0_split_1
I0612 11:07:32.076645  5211 net.cpp:615] Eltwise33 <- Convolution67
I0612 11:07:32.076658  5211 net.cpp:589] Eltwise33 -> Eltwise33
I0612 11:07:32.076686  5211 net.cpp:240] Setting up Eltwise33
I0612 11:07:32.076695  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.076701  5211 net.cpp:255] Memory required for data: 2400716288
I0612 11:07:32.076707  5211 layer_factory.hpp:77] Creating layer ReLU67
I0612 11:07:32.076716  5211 net.cpp:190] Creating Layer ReLU67
I0612 11:07:32.076722  5211 net.cpp:615] ReLU67 <- Eltwise33
I0612 11:07:32.076733  5211 net.cpp:576] ReLU67 -> Eltwise33 (in-place)
I0612 11:07:32.076745  5211 net.cpp:240] Setting up ReLU67
I0612 11:07:32.076752  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.076757  5211 net.cpp:255] Memory required for data: 2404910592
I0612 11:07:32.076763  5211 layer_factory.hpp:77] Creating layer Eltwise33_ReLU67_0_split
I0612 11:07:32.076771  5211 net.cpp:190] Creating Layer Eltwise33_ReLU67_0_split
I0612 11:07:32.076777  5211 net.cpp:615] Eltwise33_ReLU67_0_split <- Eltwise33
I0612 11:07:32.076786  5211 net.cpp:589] Eltwise33_ReLU67_0_split -> Eltwise33_ReLU67_0_split_0
I0612 11:07:32.076797  5211 net.cpp:589] Eltwise33_ReLU67_0_split -> Eltwise33_ReLU67_0_split_1
I0612 11:07:32.076854  5211 net.cpp:240] Setting up Eltwise33_ReLU67_0_split
I0612 11:07:32.076864  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.076872  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.076877  5211 net.cpp:255] Memory required for data: 2413299200
I0612 11:07:32.076884  5211 layer_factory.hpp:77] Creating layer Convolution68
I0612 11:07:32.076900  5211 net.cpp:190] Creating Layer Convolution68
I0612 11:07:32.076907  5211 net.cpp:615] Convolution68 <- Eltwise33_ReLU67_0_split_0
I0612 11:07:32.076920  5211 net.cpp:589] Convolution68 -> Convolution68
I0612 11:07:32.077857  5211 net.cpp:240] Setting up Convolution68
I0612 11:07:32.077869  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.077875  5211 net.cpp:255] Memory required for data: 2417493504
I0612 11:07:32.077889  5211 layer_factory.hpp:77] Creating layer BatchNorm68
I0612 11:07:32.077900  5211 net.cpp:190] Creating Layer BatchNorm68
I0612 11:07:32.077908  5211 net.cpp:615] BatchNorm68 <- Convolution68
I0612 11:07:32.077919  5211 net.cpp:576] BatchNorm68 -> Convolution68 (in-place)
I0612 11:07:32.078233  5211 net.cpp:240] Setting up BatchNorm68
I0612 11:07:32.078243  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.078248  5211 net.cpp:255] Memory required for data: 2421687808
I0612 11:07:32.078265  5211 layer_factory.hpp:77] Creating layer Scale68
I0612 11:07:32.078275  5211 net.cpp:190] Creating Layer Scale68
I0612 11:07:32.078282  5211 net.cpp:615] Scale68 <- Convolution68
I0612 11:07:32.078290  5211 net.cpp:576] Scale68 -> Convolution68 (in-place)
I0612 11:07:32.078346  5211 layer_factory.hpp:77] Creating layer Scale68
I0612 11:07:32.078542  5211 net.cpp:240] Setting up Scale68
I0612 11:07:32.078554  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.078560  5211 net.cpp:255] Memory required for data: 2425882112
I0612 11:07:32.078574  5211 layer_factory.hpp:77] Creating layer ReLU68
I0612 11:07:32.078586  5211 net.cpp:190] Creating Layer ReLU68
I0612 11:07:32.078593  5211 net.cpp:615] ReLU68 <- Convolution68
I0612 11:07:32.078603  5211 net.cpp:576] ReLU68 -> Convolution68 (in-place)
I0612 11:07:32.078613  5211 net.cpp:240] Setting up ReLU68
I0612 11:07:32.078620  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.078626  5211 net.cpp:255] Memory required for data: 2430076416
I0612 11:07:32.078631  5211 layer_factory.hpp:77] Creating layer Convolution69
I0612 11:07:32.078647  5211 net.cpp:190] Creating Layer Convolution69
I0612 11:07:32.078655  5211 net.cpp:615] Convolution69 <- Convolution68
I0612 11:07:32.078666  5211 net.cpp:589] Convolution69 -> Convolution69
I0612 11:07:32.079596  5211 net.cpp:240] Setting up Convolution69
I0612 11:07:32.079609  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.079615  5211 net.cpp:255] Memory required for data: 2434270720
I0612 11:07:32.079628  5211 layer_factory.hpp:77] Creating layer BatchNorm69
I0612 11:07:32.079641  5211 net.cpp:190] Creating Layer BatchNorm69
I0612 11:07:32.079648  5211 net.cpp:615] BatchNorm69 <- Convolution69
I0612 11:07:32.079656  5211 net.cpp:576] BatchNorm69 -> Convolution69 (in-place)
I0612 11:07:32.079975  5211 net.cpp:240] Setting up BatchNorm69
I0612 11:07:32.079987  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.079993  5211 net.cpp:255] Memory required for data: 2438465024
I0612 11:07:32.080008  5211 layer_factory.hpp:77] Creating layer Scale69
I0612 11:07:32.080018  5211 net.cpp:190] Creating Layer Scale69
I0612 11:07:32.080024  5211 net.cpp:615] Scale69 <- Convolution69
I0612 11:07:32.080035  5211 net.cpp:576] Scale69 -> Convolution69 (in-place)
I0612 11:07:32.080088  5211 layer_factory.hpp:77] Creating layer Scale69
I0612 11:07:32.080273  5211 net.cpp:240] Setting up Scale69
I0612 11:07:32.080286  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.080292  5211 net.cpp:255] Memory required for data: 2442659328
I0612 11:07:32.080307  5211 layer_factory.hpp:77] Creating layer Eltwise34
I0612 11:07:32.080317  5211 net.cpp:190] Creating Layer Eltwise34
I0612 11:07:32.080323  5211 net.cpp:615] Eltwise34 <- Eltwise33_ReLU67_0_split_1
I0612 11:07:32.080332  5211 net.cpp:615] Eltwise34 <- Convolution69
I0612 11:07:32.080340  5211 net.cpp:589] Eltwise34 -> Eltwise34
I0612 11:07:32.080376  5211 net.cpp:240] Setting up Eltwise34
I0612 11:07:32.080386  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.080396  5211 net.cpp:255] Memory required for data: 2446853632
I0612 11:07:32.080402  5211 layer_factory.hpp:77] Creating layer ReLU69
I0612 11:07:32.080411  5211 net.cpp:190] Creating Layer ReLU69
I0612 11:07:32.080418  5211 net.cpp:615] ReLU69 <- Eltwise34
I0612 11:07:32.080428  5211 net.cpp:576] ReLU69 -> Eltwise34 (in-place)
I0612 11:07:32.080440  5211 net.cpp:240] Setting up ReLU69
I0612 11:07:32.080447  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.080453  5211 net.cpp:255] Memory required for data: 2451047936
I0612 11:07:32.080459  5211 layer_factory.hpp:77] Creating layer Eltwise34_ReLU69_0_split
I0612 11:07:32.080467  5211 net.cpp:190] Creating Layer Eltwise34_ReLU69_0_split
I0612 11:07:32.080473  5211 net.cpp:615] Eltwise34_ReLU69_0_split <- Eltwise34
I0612 11:07:32.080482  5211 net.cpp:589] Eltwise34_ReLU69_0_split -> Eltwise34_ReLU69_0_split_0
I0612 11:07:32.080493  5211 net.cpp:589] Eltwise34_ReLU69_0_split -> Eltwise34_ReLU69_0_split_1
I0612 11:07:32.080552  5211 net.cpp:240] Setting up Eltwise34_ReLU69_0_split
I0612 11:07:32.080562  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.080569  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.080575  5211 net.cpp:255] Memory required for data: 2459436544
I0612 11:07:32.080580  5211 layer_factory.hpp:77] Creating layer Convolution70
I0612 11:07:32.080596  5211 net.cpp:190] Creating Layer Convolution70
I0612 11:07:32.080603  5211 net.cpp:615] Convolution70 <- Eltwise34_ReLU69_0_split_0
I0612 11:07:32.080613  5211 net.cpp:589] Convolution70 -> Convolution70
I0612 11:07:32.081550  5211 net.cpp:240] Setting up Convolution70
I0612 11:07:32.081562  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.081568  5211 net.cpp:255] Memory required for data: 2463630848
I0612 11:07:32.081583  5211 layer_factory.hpp:77] Creating layer BatchNorm70
I0612 11:07:32.081598  5211 net.cpp:190] Creating Layer BatchNorm70
I0612 11:07:32.081604  5211 net.cpp:615] BatchNorm70 <- Convolution70
I0612 11:07:32.081614  5211 net.cpp:576] BatchNorm70 -> Convolution70 (in-place)
I0612 11:07:32.081938  5211 net.cpp:240] Setting up BatchNorm70
I0612 11:07:32.081949  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.081955  5211 net.cpp:255] Memory required for data: 2467825152
I0612 11:07:32.081971  5211 layer_factory.hpp:77] Creating layer Scale70
I0612 11:07:32.081984  5211 net.cpp:190] Creating Layer Scale70
I0612 11:07:32.081991  5211 net.cpp:615] Scale70 <- Convolution70
I0612 11:07:32.082000  5211 net.cpp:576] Scale70 -> Convolution70 (in-place)
I0612 11:07:32.082058  5211 layer_factory.hpp:77] Creating layer Scale70
I0612 11:07:32.082247  5211 net.cpp:240] Setting up Scale70
I0612 11:07:32.082258  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.082264  5211 net.cpp:255] Memory required for data: 2472019456
I0612 11:07:32.082278  5211 layer_factory.hpp:77] Creating layer ReLU70
I0612 11:07:32.082289  5211 net.cpp:190] Creating Layer ReLU70
I0612 11:07:32.082296  5211 net.cpp:615] ReLU70 <- Convolution70
I0612 11:07:32.082305  5211 net.cpp:576] ReLU70 -> Convolution70 (in-place)
I0612 11:07:32.082315  5211 net.cpp:240] Setting up ReLU70
I0612 11:07:32.082324  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.082329  5211 net.cpp:255] Memory required for data: 2476213760
I0612 11:07:32.082335  5211 layer_factory.hpp:77] Creating layer Convolution71
I0612 11:07:32.082350  5211 net.cpp:190] Creating Layer Convolution71
I0612 11:07:32.082365  5211 net.cpp:615] Convolution71 <- Convolution70
I0612 11:07:32.082376  5211 net.cpp:589] Convolution71 -> Convolution71
I0612 11:07:32.083307  5211 net.cpp:240] Setting up Convolution71
I0612 11:07:32.083320  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.083326  5211 net.cpp:255] Memory required for data: 2480408064
I0612 11:07:32.083339  5211 layer_factory.hpp:77] Creating layer BatchNorm71
I0612 11:07:32.083353  5211 net.cpp:190] Creating Layer BatchNorm71
I0612 11:07:32.083364  5211 net.cpp:615] BatchNorm71 <- Convolution71
I0612 11:07:32.083372  5211 net.cpp:576] BatchNorm71 -> Convolution71 (in-place)
I0612 11:07:32.083693  5211 net.cpp:240] Setting up BatchNorm71
I0612 11:07:32.083704  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.083710  5211 net.cpp:255] Memory required for data: 2484602368
I0612 11:07:32.083729  5211 layer_factory.hpp:77] Creating layer Scale71
I0612 11:07:32.083740  5211 net.cpp:190] Creating Layer Scale71
I0612 11:07:32.083746  5211 net.cpp:615] Scale71 <- Convolution71
I0612 11:07:32.083755  5211 net.cpp:576] Scale71 -> Convolution71 (in-place)
I0612 11:07:32.083811  5211 layer_factory.hpp:77] Creating layer Scale71
I0612 11:07:32.084003  5211 net.cpp:240] Setting up Scale71
I0612 11:07:32.084013  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.084019  5211 net.cpp:255] Memory required for data: 2488796672
I0612 11:07:32.084033  5211 layer_factory.hpp:77] Creating layer Eltwise35
I0612 11:07:32.084046  5211 net.cpp:190] Creating Layer Eltwise35
I0612 11:07:32.084053  5211 net.cpp:615] Eltwise35 <- Eltwise34_ReLU69_0_split_1
I0612 11:07:32.084062  5211 net.cpp:615] Eltwise35 <- Convolution71
I0612 11:07:32.084071  5211 net.cpp:589] Eltwise35 -> Eltwise35
I0612 11:07:32.084105  5211 net.cpp:240] Setting up Eltwise35
I0612 11:07:32.084115  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.084120  5211 net.cpp:255] Memory required for data: 2492990976
I0612 11:07:32.084126  5211 layer_factory.hpp:77] Creating layer ReLU71
I0612 11:07:32.084136  5211 net.cpp:190] Creating Layer ReLU71
I0612 11:07:32.084142  5211 net.cpp:615] ReLU71 <- Eltwise35
I0612 11:07:32.084153  5211 net.cpp:576] ReLU71 -> Eltwise35 (in-place)
I0612 11:07:32.084163  5211 net.cpp:240] Setting up ReLU71
I0612 11:07:32.084172  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.084177  5211 net.cpp:255] Memory required for data: 2497185280
I0612 11:07:32.084183  5211 layer_factory.hpp:77] Creating layer Eltwise35_ReLU71_0_split
I0612 11:07:32.084192  5211 net.cpp:190] Creating Layer Eltwise35_ReLU71_0_split
I0612 11:07:32.084197  5211 net.cpp:615] Eltwise35_ReLU71_0_split <- Eltwise35
I0612 11:07:32.084206  5211 net.cpp:589] Eltwise35_ReLU71_0_split -> Eltwise35_ReLU71_0_split_0
I0612 11:07:32.084218  5211 net.cpp:589] Eltwise35_ReLU71_0_split -> Eltwise35_ReLU71_0_split_1
I0612 11:07:32.084276  5211 net.cpp:240] Setting up Eltwise35_ReLU71_0_split
I0612 11:07:32.084286  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.084293  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.084300  5211 net.cpp:255] Memory required for data: 2505573888
I0612 11:07:32.084306  5211 layer_factory.hpp:77] Creating layer Convolution72
I0612 11:07:32.084318  5211 net.cpp:190] Creating Layer Convolution72
I0612 11:07:32.084324  5211 net.cpp:615] Convolution72 <- Eltwise35_ReLU71_0_split_0
I0612 11:07:32.084337  5211 net.cpp:589] Convolution72 -> Convolution72
I0612 11:07:32.085274  5211 net.cpp:240] Setting up Convolution72
I0612 11:07:32.085288  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.085294  5211 net.cpp:255] Memory required for data: 2509768192
I0612 11:07:32.085307  5211 layer_factory.hpp:77] Creating layer BatchNorm72
I0612 11:07:32.085317  5211 net.cpp:190] Creating Layer BatchNorm72
I0612 11:07:32.085325  5211 net.cpp:615] BatchNorm72 <- Convolution72
I0612 11:07:32.085335  5211 net.cpp:576] BatchNorm72 -> Convolution72 (in-place)
I0612 11:07:32.085655  5211 net.cpp:240] Setting up BatchNorm72
I0612 11:07:32.085666  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.085672  5211 net.cpp:255] Memory required for data: 2513962496
I0612 11:07:32.085688  5211 layer_factory.hpp:77] Creating layer Scale72
I0612 11:07:32.085698  5211 net.cpp:190] Creating Layer Scale72
I0612 11:07:32.085705  5211 net.cpp:615] Scale72 <- Convolution72
I0612 11:07:32.085713  5211 net.cpp:576] Scale72 -> Convolution72 (in-place)
I0612 11:07:32.085769  5211 layer_factory.hpp:77] Creating layer Scale72
I0612 11:07:32.085959  5211 net.cpp:240] Setting up Scale72
I0612 11:07:32.085970  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.085976  5211 net.cpp:255] Memory required for data: 2518156800
I0612 11:07:32.085990  5211 layer_factory.hpp:77] Creating layer ReLU72
I0612 11:07:32.086002  5211 net.cpp:190] Creating Layer ReLU72
I0612 11:07:32.086009  5211 net.cpp:615] ReLU72 <- Convolution72
I0612 11:07:32.086017  5211 net.cpp:576] ReLU72 -> Convolution72 (in-place)
I0612 11:07:32.086029  5211 net.cpp:240] Setting up ReLU72
I0612 11:07:32.086036  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.086041  5211 net.cpp:255] Memory required for data: 2522351104
I0612 11:07:32.086047  5211 layer_factory.hpp:77] Creating layer Convolution73
I0612 11:07:32.086062  5211 net.cpp:190] Creating Layer Convolution73
I0612 11:07:32.086069  5211 net.cpp:615] Convolution73 <- Convolution72
I0612 11:07:32.086079  5211 net.cpp:589] Convolution73 -> Convolution73
I0612 11:07:32.087028  5211 net.cpp:240] Setting up Convolution73
I0612 11:07:32.087040  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.087046  5211 net.cpp:255] Memory required for data: 2526545408
I0612 11:07:32.087059  5211 layer_factory.hpp:77] Creating layer BatchNorm73
I0612 11:07:32.087074  5211 net.cpp:190] Creating Layer BatchNorm73
I0612 11:07:32.087080  5211 net.cpp:615] BatchNorm73 <- Convolution73
I0612 11:07:32.087088  5211 net.cpp:576] BatchNorm73 -> Convolution73 (in-place)
I0612 11:07:32.087395  5211 net.cpp:240] Setting up BatchNorm73
I0612 11:07:32.087406  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.087411  5211 net.cpp:255] Memory required for data: 2530739712
I0612 11:07:32.087427  5211 layer_factory.hpp:77] Creating layer Scale73
I0612 11:07:32.087436  5211 net.cpp:190] Creating Layer Scale73
I0612 11:07:32.087442  5211 net.cpp:615] Scale73 <- Convolution73
I0612 11:07:32.087450  5211 net.cpp:576] Scale73 -> Convolution73 (in-place)
I0612 11:07:32.087503  5211 layer_factory.hpp:77] Creating layer Scale73
I0612 11:07:32.087682  5211 net.cpp:240] Setting up Scale73
I0612 11:07:32.087692  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.087698  5211 net.cpp:255] Memory required for data: 2534934016
I0612 11:07:32.087713  5211 layer_factory.hpp:77] Creating layer Eltwise36
I0612 11:07:32.087723  5211 net.cpp:190] Creating Layer Eltwise36
I0612 11:07:32.087730  5211 net.cpp:615] Eltwise36 <- Eltwise35_ReLU71_0_split_1
I0612 11:07:32.087738  5211 net.cpp:615] Eltwise36 <- Convolution73
I0612 11:07:32.087746  5211 net.cpp:589] Eltwise36 -> Eltwise36
I0612 11:07:32.087780  5211 net.cpp:240] Setting up Eltwise36
I0612 11:07:32.087790  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.087795  5211 net.cpp:255] Memory required for data: 2539128320
I0612 11:07:32.087800  5211 layer_factory.hpp:77] Creating layer ReLU73
I0612 11:07:32.087808  5211 net.cpp:190] Creating Layer ReLU73
I0612 11:07:32.087815  5211 net.cpp:615] ReLU73 <- Eltwise36
I0612 11:07:32.087824  5211 net.cpp:576] ReLU73 -> Eltwise36 (in-place)
I0612 11:07:32.087834  5211 net.cpp:240] Setting up ReLU73
I0612 11:07:32.087841  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.087846  5211 net.cpp:255] Memory required for data: 2543322624
I0612 11:07:32.087852  5211 layer_factory.hpp:77] Creating layer Eltwise36_ReLU73_0_split
I0612 11:07:32.087859  5211 net.cpp:190] Creating Layer Eltwise36_ReLU73_0_split
I0612 11:07:32.087865  5211 net.cpp:615] Eltwise36_ReLU73_0_split <- Eltwise36
I0612 11:07:32.087873  5211 net.cpp:589] Eltwise36_ReLU73_0_split -> Eltwise36_ReLU73_0_split_0
I0612 11:07:32.087883  5211 net.cpp:589] Eltwise36_ReLU73_0_split -> Eltwise36_ReLU73_0_split_1
I0612 11:07:32.087940  5211 net.cpp:240] Setting up Eltwise36_ReLU73_0_split
I0612 11:07:32.087949  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.087956  5211 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:07:32.087962  5211 net.cpp:255] Memory required for data: 2551711232
I0612 11:07:32.087971  5211 layer_factory.hpp:77] Creating layer Pooling2
I0612 11:07:32.087981  5211 net.cpp:190] Creating Layer Pooling2
I0612 11:07:32.087987  5211 net.cpp:615] Pooling2 <- Eltwise36_ReLU73_0_split_0
I0612 11:07:32.087998  5211 net.cpp:589] Pooling2 -> Pooling2
I0612 11:07:32.088034  5211 net.cpp:240] Setting up Pooling2
I0612 11:07:32.088043  5211 net.cpp:247] Top shape: 128 32 8 8 (262144)
I0612 11:07:32.088048  5211 net.cpp:255] Memory required for data: 2552759808
I0612 11:07:32.088054  5211 layer_factory.hpp:77] Creating layer Input2
I0612 11:07:32.088065  5211 net.cpp:190] Creating Layer Input2
I0612 11:07:32.088075  5211 net.cpp:589] Input2 -> Input2
I0612 11:07:32.088111  5211 net.cpp:240] Setting up Input2
I0612 11:07:32.088124  5211 net.cpp:247] Top shape: 128 32 8 8 (262144)
I0612 11:07:32.088129  5211 net.cpp:255] Memory required for data: 2553808384
I0612 11:07:32.088134  5211 layer_factory.hpp:77] Creating layer Concat2
I0612 11:07:32.088143  5211 net.cpp:190] Creating Layer Concat2
I0612 11:07:32.088150  5211 net.cpp:615] Concat2 <- Pooling2
I0612 11:07:32.088156  5211 net.cpp:615] Concat2 <- Input2
I0612 11:07:32.088165  5211 net.cpp:589] Concat2 -> Concat2
I0612 11:07:32.088204  5211 net.cpp:240] Setting up Concat2
I0612 11:07:32.088213  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.088218  5211 net.cpp:255] Memory required for data: 2555905536
I0612 11:07:32.088223  5211 layer_factory.hpp:77] Creating layer Convolution74
I0612 11:07:32.088238  5211 net.cpp:190] Creating Layer Convolution74
I0612 11:07:32.088244  5211 net.cpp:615] Convolution74 <- Eltwise36_ReLU73_0_split_1
I0612 11:07:32.088255  5211 net.cpp:589] Convolution74 -> Convolution74
I0612 11:07:32.089664  5211 net.cpp:240] Setting up Convolution74
I0612 11:07:32.089679  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.089685  5211 net.cpp:255] Memory required for data: 2558002688
I0612 11:07:32.089790  5211 layer_factory.hpp:77] Creating layer BatchNorm74
I0612 11:07:32.089804  5211 net.cpp:190] Creating Layer BatchNorm74
I0612 11:07:32.089812  5211 net.cpp:615] BatchNorm74 <- Convolution74
I0612 11:07:32.089821  5211 net.cpp:576] BatchNorm74 -> Convolution74 (in-place)
I0612 11:07:32.090145  5211 net.cpp:240] Setting up BatchNorm74
I0612 11:07:32.090157  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.090162  5211 net.cpp:255] Memory required for data: 2560099840
I0612 11:07:32.090178  5211 layer_factory.hpp:77] Creating layer Scale74
I0612 11:07:32.090188  5211 net.cpp:190] Creating Layer Scale74
I0612 11:07:32.090194  5211 net.cpp:615] Scale74 <- Convolution74
I0612 11:07:32.090204  5211 net.cpp:576] Scale74 -> Convolution74 (in-place)
I0612 11:07:32.090258  5211 layer_factory.hpp:77] Creating layer Scale74
I0612 11:07:32.090456  5211 net.cpp:240] Setting up Scale74
I0612 11:07:32.090467  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.090473  5211 net.cpp:255] Memory required for data: 2562196992
I0612 11:07:32.090487  5211 layer_factory.hpp:77] Creating layer ReLU74
I0612 11:07:32.090495  5211 net.cpp:190] Creating Layer ReLU74
I0612 11:07:32.090502  5211 net.cpp:615] ReLU74 <- Convolution74
I0612 11:07:32.090513  5211 net.cpp:576] ReLU74 -> Convolution74 (in-place)
I0612 11:07:32.090523  5211 net.cpp:240] Setting up ReLU74
I0612 11:07:32.090531  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.090536  5211 net.cpp:255] Memory required for data: 2564294144
I0612 11:07:32.090543  5211 layer_factory.hpp:77] Creating layer Convolution75
I0612 11:07:32.090558  5211 net.cpp:190] Creating Layer Convolution75
I0612 11:07:32.090564  5211 net.cpp:615] Convolution75 <- Convolution74
I0612 11:07:32.090572  5211 net.cpp:589] Convolution75 -> Convolution75
I0612 11:07:32.092980  5211 net.cpp:240] Setting up Convolution75
I0612 11:07:32.092993  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.092998  5211 net.cpp:255] Memory required for data: 2566391296
I0612 11:07:32.093011  5211 layer_factory.hpp:77] Creating layer BatchNorm75
I0612 11:07:32.093029  5211 net.cpp:190] Creating Layer BatchNorm75
I0612 11:07:32.093037  5211 net.cpp:615] BatchNorm75 <- Convolution75
I0612 11:07:32.093045  5211 net.cpp:576] BatchNorm75 -> Convolution75 (in-place)
I0612 11:07:32.093365  5211 net.cpp:240] Setting up BatchNorm75
I0612 11:07:32.093376  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.093381  5211 net.cpp:255] Memory required for data: 2568488448
I0612 11:07:32.093397  5211 layer_factory.hpp:77] Creating layer Scale75
I0612 11:07:32.093406  5211 net.cpp:190] Creating Layer Scale75
I0612 11:07:32.093413  5211 net.cpp:615] Scale75 <- Convolution75
I0612 11:07:32.093420  5211 net.cpp:576] Scale75 -> Convolution75 (in-place)
I0612 11:07:32.093477  5211 layer_factory.hpp:77] Creating layer Scale75
I0612 11:07:32.093668  5211 net.cpp:240] Setting up Scale75
I0612 11:07:32.093678  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.093683  5211 net.cpp:255] Memory required for data: 2570585600
I0612 11:07:32.093696  5211 layer_factory.hpp:77] Creating layer Eltwise37
I0612 11:07:32.093708  5211 net.cpp:190] Creating Layer Eltwise37
I0612 11:07:32.093715  5211 net.cpp:615] Eltwise37 <- Concat2
I0612 11:07:32.093724  5211 net.cpp:615] Eltwise37 <- Convolution75
I0612 11:07:32.093732  5211 net.cpp:589] Eltwise37 -> Eltwise37
I0612 11:07:32.093760  5211 net.cpp:240] Setting up Eltwise37
I0612 11:07:32.093770  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.093775  5211 net.cpp:255] Memory required for data: 2572682752
I0612 11:07:32.093780  5211 layer_factory.hpp:77] Creating layer ReLU75
I0612 11:07:32.093794  5211 net.cpp:190] Creating Layer ReLU75
I0612 11:07:32.093801  5211 net.cpp:615] ReLU75 <- Eltwise37
I0612 11:07:32.093808  5211 net.cpp:576] ReLU75 -> Eltwise37 (in-place)
I0612 11:07:32.093818  5211 net.cpp:240] Setting up ReLU75
I0612 11:07:32.093825  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.093832  5211 net.cpp:255] Memory required for data: 2574779904
I0612 11:07:32.093837  5211 layer_factory.hpp:77] Creating layer Eltwise37_ReLU75_0_split
I0612 11:07:32.093844  5211 net.cpp:190] Creating Layer Eltwise37_ReLU75_0_split
I0612 11:07:32.093849  5211 net.cpp:615] Eltwise37_ReLU75_0_split <- Eltwise37
I0612 11:07:32.093858  5211 net.cpp:589] Eltwise37_ReLU75_0_split -> Eltwise37_ReLU75_0_split_0
I0612 11:07:32.093868  5211 net.cpp:589] Eltwise37_ReLU75_0_split -> Eltwise37_ReLU75_0_split_1
I0612 11:07:32.093927  5211 net.cpp:240] Setting up Eltwise37_ReLU75_0_split
I0612 11:07:32.093936  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.093945  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.093950  5211 net.cpp:255] Memory required for data: 2578974208
I0612 11:07:32.093955  5211 layer_factory.hpp:77] Creating layer Convolution76
I0612 11:07:32.093971  5211 net.cpp:190] Creating Layer Convolution76
I0612 11:07:32.093977  5211 net.cpp:615] Convolution76 <- Eltwise37_ReLU75_0_split_0
I0612 11:07:32.093987  5211 net.cpp:589] Convolution76 -> Convolution76
I0612 11:07:32.096427  5211 net.cpp:240] Setting up Convolution76
I0612 11:07:32.096441  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.096446  5211 net.cpp:255] Memory required for data: 2581071360
I0612 11:07:32.096460  5211 layer_factory.hpp:77] Creating layer BatchNorm76
I0612 11:07:32.096472  5211 net.cpp:190] Creating Layer BatchNorm76
I0612 11:07:32.096479  5211 net.cpp:615] BatchNorm76 <- Convolution76
I0612 11:07:32.096488  5211 net.cpp:576] BatchNorm76 -> Convolution76 (in-place)
I0612 11:07:32.096809  5211 net.cpp:240] Setting up BatchNorm76
I0612 11:07:32.096820  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.096825  5211 net.cpp:255] Memory required for data: 2583168512
I0612 11:07:32.096842  5211 layer_factory.hpp:77] Creating layer Scale76
I0612 11:07:32.096853  5211 net.cpp:190] Creating Layer Scale76
I0612 11:07:32.096860  5211 net.cpp:615] Scale76 <- Convolution76
I0612 11:07:32.096868  5211 net.cpp:576] Scale76 -> Convolution76 (in-place)
I0612 11:07:32.096925  5211 layer_factory.hpp:77] Creating layer Scale76
I0612 11:07:32.097115  5211 net.cpp:240] Setting up Scale76
I0612 11:07:32.097126  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.097131  5211 net.cpp:255] Memory required for data: 2585265664
I0612 11:07:32.097143  5211 layer_factory.hpp:77] Creating layer ReLU76
I0612 11:07:32.097154  5211 net.cpp:190] Creating Layer ReLU76
I0612 11:07:32.097162  5211 net.cpp:615] ReLU76 <- Convolution76
I0612 11:07:32.097168  5211 net.cpp:576] ReLU76 -> Convolution76 (in-place)
I0612 11:07:32.097178  5211 net.cpp:240] Setting up ReLU76
I0612 11:07:32.097187  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.097192  5211 net.cpp:255] Memory required for data: 2587362816
I0612 11:07:32.097196  5211 layer_factory.hpp:77] Creating layer Convolution77
I0612 11:07:32.097213  5211 net.cpp:190] Creating Layer Convolution77
I0612 11:07:32.097220  5211 net.cpp:615] Convolution77 <- Convolution76
I0612 11:07:32.097231  5211 net.cpp:589] Convolution77 -> Convolution77
I0612 11:07:32.099596  5211 net.cpp:240] Setting up Convolution77
I0612 11:07:32.099608  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.099613  5211 net.cpp:255] Memory required for data: 2589459968
I0612 11:07:32.099625  5211 layer_factory.hpp:77] Creating layer BatchNorm77
I0612 11:07:32.099635  5211 net.cpp:190] Creating Layer BatchNorm77
I0612 11:07:32.099642  5211 net.cpp:615] BatchNorm77 <- Convolution77
I0612 11:07:32.099649  5211 net.cpp:576] BatchNorm77 -> Convolution77 (in-place)
I0612 11:07:32.099951  5211 net.cpp:240] Setting up BatchNorm77
I0612 11:07:32.099961  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.099966  5211 net.cpp:255] Memory required for data: 2591557120
I0612 11:07:32.099982  5211 layer_factory.hpp:77] Creating layer Scale77
I0612 11:07:32.099989  5211 net.cpp:190] Creating Layer Scale77
I0612 11:07:32.099995  5211 net.cpp:615] Scale77 <- Convolution77
I0612 11:07:32.100003  5211 net.cpp:576] Scale77 -> Convolution77 (in-place)
I0612 11:07:32.100059  5211 layer_factory.hpp:77] Creating layer Scale77
I0612 11:07:32.100236  5211 net.cpp:240] Setting up Scale77
I0612 11:07:32.100249  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.100255  5211 net.cpp:255] Memory required for data: 2593654272
I0612 11:07:32.100266  5211 layer_factory.hpp:77] Creating layer Eltwise38
I0612 11:07:32.100275  5211 net.cpp:190] Creating Layer Eltwise38
I0612 11:07:32.100282  5211 net.cpp:615] Eltwise38 <- Eltwise37_ReLU75_0_split_1
I0612 11:07:32.100289  5211 net.cpp:615] Eltwise38 <- Convolution77
I0612 11:07:32.100297  5211 net.cpp:589] Eltwise38 -> Eltwise38
I0612 11:07:32.100328  5211 net.cpp:240] Setting up Eltwise38
I0612 11:07:32.100337  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.100342  5211 net.cpp:255] Memory required for data: 2595751424
I0612 11:07:32.100347  5211 layer_factory.hpp:77] Creating layer ReLU77
I0612 11:07:32.100355  5211 net.cpp:190] Creating Layer ReLU77
I0612 11:07:32.100360  5211 net.cpp:615] ReLU77 <- Eltwise38
I0612 11:07:32.100369  5211 net.cpp:576] ReLU77 -> Eltwise38 (in-place)
I0612 11:07:32.100379  5211 net.cpp:240] Setting up ReLU77
I0612 11:07:32.100386  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.100391  5211 net.cpp:255] Memory required for data: 2597848576
I0612 11:07:32.100396  5211 layer_factory.hpp:77] Creating layer Eltwise38_ReLU77_0_split
I0612 11:07:32.100404  5211 net.cpp:190] Creating Layer Eltwise38_ReLU77_0_split
I0612 11:07:32.100409  5211 net.cpp:615] Eltwise38_ReLU77_0_split <- Eltwise38
I0612 11:07:32.100416  5211 net.cpp:589] Eltwise38_ReLU77_0_split -> Eltwise38_ReLU77_0_split_0
I0612 11:07:32.100426  5211 net.cpp:589] Eltwise38_ReLU77_0_split -> Eltwise38_ReLU77_0_split_1
I0612 11:07:32.100481  5211 net.cpp:240] Setting up Eltwise38_ReLU77_0_split
I0612 11:07:32.100489  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.100495  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.100500  5211 net.cpp:255] Memory required for data: 2602042880
I0612 11:07:32.100509  5211 layer_factory.hpp:77] Creating layer Convolution78
I0612 11:07:32.100523  5211 net.cpp:190] Creating Layer Convolution78
I0612 11:07:32.100530  5211 net.cpp:615] Convolution78 <- Eltwise38_ReLU77_0_split_0
I0612 11:07:32.100539  5211 net.cpp:589] Convolution78 -> Convolution78
I0612 11:07:32.102828  5211 net.cpp:240] Setting up Convolution78
I0612 11:07:32.102841  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.102846  5211 net.cpp:255] Memory required for data: 2604140032
I0612 11:07:32.102859  5211 layer_factory.hpp:77] Creating layer BatchNorm78
I0612 11:07:32.102870  5211 net.cpp:190] Creating Layer BatchNorm78
I0612 11:07:32.102880  5211 net.cpp:615] BatchNorm78 <- Convolution78
I0612 11:07:32.102887  5211 net.cpp:576] BatchNorm78 -> Convolution78 (in-place)
I0612 11:07:32.103189  5211 net.cpp:240] Setting up BatchNorm78
I0612 11:07:32.103199  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.103204  5211 net.cpp:255] Memory required for data: 2606237184
I0612 11:07:32.103219  5211 layer_factory.hpp:77] Creating layer Scale78
I0612 11:07:32.103227  5211 net.cpp:190] Creating Layer Scale78
I0612 11:07:32.103234  5211 net.cpp:615] Scale78 <- Convolution78
I0612 11:07:32.103240  5211 net.cpp:576] Scale78 -> Convolution78 (in-place)
I0612 11:07:32.103294  5211 layer_factory.hpp:77] Creating layer Scale78
I0612 11:07:32.103472  5211 net.cpp:240] Setting up Scale78
I0612 11:07:32.103482  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.103487  5211 net.cpp:255] Memory required for data: 2608334336
I0612 11:07:32.103498  5211 layer_factory.hpp:77] Creating layer ReLU78
I0612 11:07:32.103507  5211 net.cpp:190] Creating Layer ReLU78
I0612 11:07:32.103515  5211 net.cpp:615] ReLU78 <- Convolution78
I0612 11:07:32.103523  5211 net.cpp:576] ReLU78 -> Convolution78 (in-place)
I0612 11:07:32.103533  5211 net.cpp:240] Setting up ReLU78
I0612 11:07:32.103539  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.103544  5211 net.cpp:255] Memory required for data: 2610431488
I0612 11:07:32.103549  5211 layer_factory.hpp:77] Creating layer Convolution79
I0612 11:07:32.103564  5211 net.cpp:190] Creating Layer Convolution79
I0612 11:07:32.103569  5211 net.cpp:615] Convolution79 <- Convolution78
I0612 11:07:32.103579  5211 net.cpp:589] Convolution79 -> Convolution79
I0612 11:07:32.105867  5211 net.cpp:240] Setting up Convolution79
I0612 11:07:32.105880  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.105885  5211 net.cpp:255] Memory required for data: 2612528640
I0612 11:07:32.105897  5211 layer_factory.hpp:77] Creating layer BatchNorm79
I0612 11:07:32.105906  5211 net.cpp:190] Creating Layer BatchNorm79
I0612 11:07:32.105912  5211 net.cpp:615] BatchNorm79 <- Convolution79
I0612 11:07:32.105922  5211 net.cpp:576] BatchNorm79 -> Convolution79 (in-place)
I0612 11:07:32.106976  5211 net.cpp:240] Setting up BatchNorm79
I0612 11:07:32.106994  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.106999  5211 net.cpp:255] Memory required for data: 2614625792
I0612 11:07:32.107019  5211 layer_factory.hpp:77] Creating layer Scale79
I0612 11:07:32.107030  5211 net.cpp:190] Creating Layer Scale79
I0612 11:07:32.107038  5211 net.cpp:615] Scale79 <- Convolution79
I0612 11:07:32.107046  5211 net.cpp:576] Scale79 -> Convolution79 (in-place)
I0612 11:07:32.107103  5211 layer_factory.hpp:77] Creating layer Scale79
I0612 11:07:32.107280  5211 net.cpp:240] Setting up Scale79
I0612 11:07:32.107290  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.107295  5211 net.cpp:255] Memory required for data: 2616722944
I0612 11:07:32.107311  5211 layer_factory.hpp:77] Creating layer Eltwise39
I0612 11:07:32.107319  5211 net.cpp:190] Creating Layer Eltwise39
I0612 11:07:32.107326  5211 net.cpp:615] Eltwise39 <- Eltwise38_ReLU77_0_split_1
I0612 11:07:32.107334  5211 net.cpp:615] Eltwise39 <- Convolution79
I0612 11:07:32.107345  5211 net.cpp:589] Eltwise39 -> Eltwise39
I0612 11:07:32.107372  5211 net.cpp:240] Setting up Eltwise39
I0612 11:07:32.107385  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.107391  5211 net.cpp:255] Memory required for data: 2618820096
I0612 11:07:32.107396  5211 layer_factory.hpp:77] Creating layer ReLU79
I0612 11:07:32.107404  5211 net.cpp:190] Creating Layer ReLU79
I0612 11:07:32.107410  5211 net.cpp:615] ReLU79 <- Eltwise39
I0612 11:07:32.107420  5211 net.cpp:576] ReLU79 -> Eltwise39 (in-place)
I0612 11:07:32.107429  5211 net.cpp:240] Setting up ReLU79
I0612 11:07:32.107436  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.107441  5211 net.cpp:255] Memory required for data: 2620917248
I0612 11:07:32.107446  5211 layer_factory.hpp:77] Creating layer Eltwise39_ReLU79_0_split
I0612 11:07:32.107455  5211 net.cpp:190] Creating Layer Eltwise39_ReLU79_0_split
I0612 11:07:32.107460  5211 net.cpp:615] Eltwise39_ReLU79_0_split <- Eltwise39
I0612 11:07:32.107467  5211 net.cpp:589] Eltwise39_ReLU79_0_split -> Eltwise39_ReLU79_0_split_0
I0612 11:07:32.107477  5211 net.cpp:589] Eltwise39_ReLU79_0_split -> Eltwise39_ReLU79_0_split_1
I0612 11:07:32.107530  5211 net.cpp:240] Setting up Eltwise39_ReLU79_0_split
I0612 11:07:32.107539  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.107545  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.107550  5211 net.cpp:255] Memory required for data: 2625111552
I0612 11:07:32.107555  5211 layer_factory.hpp:77] Creating layer Convolution80
I0612 11:07:32.107568  5211 net.cpp:190] Creating Layer Convolution80
I0612 11:07:32.107573  5211 net.cpp:615] Convolution80 <- Eltwise39_ReLU79_0_split_0
I0612 11:07:32.107586  5211 net.cpp:589] Convolution80 -> Convolution80
I0612 11:07:32.110601  5211 net.cpp:240] Setting up Convolution80
I0612 11:07:32.110632  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.110637  5211 net.cpp:255] Memory required for data: 2627208704
I0612 11:07:32.110651  5211 layer_factory.hpp:77] Creating layer BatchNorm80
I0612 11:07:32.110663  5211 net.cpp:190] Creating Layer BatchNorm80
I0612 11:07:32.110671  5211 net.cpp:615] BatchNorm80 <- Convolution80
I0612 11:07:32.110678  5211 net.cpp:576] BatchNorm80 -> Convolution80 (in-place)
I0612 11:07:32.110968  5211 net.cpp:240] Setting up BatchNorm80
I0612 11:07:32.110978  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.110983  5211 net.cpp:255] Memory required for data: 2629305856
I0612 11:07:32.110997  5211 layer_factory.hpp:77] Creating layer Scale80
I0612 11:07:32.111007  5211 net.cpp:190] Creating Layer Scale80
I0612 11:07:32.111012  5211 net.cpp:615] Scale80 <- Convolution80
I0612 11:07:32.111019  5211 net.cpp:576] Scale80 -> Convolution80 (in-place)
I0612 11:07:32.111073  5211 layer_factory.hpp:77] Creating layer Scale80
I0612 11:07:32.111241  5211 net.cpp:240] Setting up Scale80
I0612 11:07:32.111251  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.111255  5211 net.cpp:255] Memory required for data: 2631403008
I0612 11:07:32.111268  5211 layer_factory.hpp:77] Creating layer ReLU80
I0612 11:07:32.111279  5211 net.cpp:190] Creating Layer ReLU80
I0612 11:07:32.111284  5211 net.cpp:615] ReLU80 <- Convolution80
I0612 11:07:32.111291  5211 net.cpp:576] ReLU80 -> Convolution80 (in-place)
I0612 11:07:32.111300  5211 net.cpp:240] Setting up ReLU80
I0612 11:07:32.111307  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.111312  5211 net.cpp:255] Memory required for data: 2633500160
I0612 11:07:32.111316  5211 layer_factory.hpp:77] Creating layer Convolution81
I0612 11:07:32.111331  5211 net.cpp:190] Creating Layer Convolution81
I0612 11:07:32.111337  5211 net.cpp:615] Convolution81 <- Convolution80
I0612 11:07:32.111346  5211 net.cpp:589] Convolution81 -> Convolution81
I0612 11:07:32.113587  5211 net.cpp:240] Setting up Convolution81
I0612 11:07:32.113602  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.113607  5211 net.cpp:255] Memory required for data: 2635597312
I0612 11:07:32.113620  5211 layer_factory.hpp:77] Creating layer BatchNorm81
I0612 11:07:32.113632  5211 net.cpp:190] Creating Layer BatchNorm81
I0612 11:07:32.113642  5211 net.cpp:615] BatchNorm81 <- Convolution81
I0612 11:07:32.113651  5211 net.cpp:576] BatchNorm81 -> Convolution81 (in-place)
I0612 11:07:32.113939  5211 net.cpp:240] Setting up BatchNorm81
I0612 11:07:32.113948  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.113953  5211 net.cpp:255] Memory required for data: 2637694464
I0612 11:07:32.113968  5211 layer_factory.hpp:77] Creating layer Scale81
I0612 11:07:32.113979  5211 net.cpp:190] Creating Layer Scale81
I0612 11:07:32.113986  5211 net.cpp:615] Scale81 <- Convolution81
I0612 11:07:32.113992  5211 net.cpp:576] Scale81 -> Convolution81 (in-place)
I0612 11:07:32.114042  5211 layer_factory.hpp:77] Creating layer Scale81
I0612 11:07:32.114212  5211 net.cpp:240] Setting up Scale81
I0612 11:07:32.114223  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.114226  5211 net.cpp:255] Memory required for data: 2639791616
I0612 11:07:32.114238  5211 layer_factory.hpp:77] Creating layer Eltwise40
I0612 11:07:32.114249  5211 net.cpp:190] Creating Layer Eltwise40
I0612 11:07:32.114255  5211 net.cpp:615] Eltwise40 <- Eltwise39_ReLU79_0_split_1
I0612 11:07:32.114264  5211 net.cpp:615] Eltwise40 <- Convolution81
I0612 11:07:32.114271  5211 net.cpp:589] Eltwise40 -> Eltwise40
I0612 11:07:32.114301  5211 net.cpp:240] Setting up Eltwise40
I0612 11:07:32.114310  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.114315  5211 net.cpp:255] Memory required for data: 2641888768
I0612 11:07:32.114320  5211 layer_factory.hpp:77] Creating layer ReLU81
I0612 11:07:32.114326  5211 net.cpp:190] Creating Layer ReLU81
I0612 11:07:32.114332  5211 net.cpp:615] ReLU81 <- Eltwise40
I0612 11:07:32.114338  5211 net.cpp:576] ReLU81 -> Eltwise40 (in-place)
I0612 11:07:32.114347  5211 net.cpp:240] Setting up ReLU81
I0612 11:07:32.114361  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.114365  5211 net.cpp:255] Memory required for data: 2643985920
I0612 11:07:32.114370  5211 layer_factory.hpp:77] Creating layer Eltwise40_ReLU81_0_split
I0612 11:07:32.114380  5211 net.cpp:190] Creating Layer Eltwise40_ReLU81_0_split
I0612 11:07:32.114385  5211 net.cpp:615] Eltwise40_ReLU81_0_split <- Eltwise40
I0612 11:07:32.114393  5211 net.cpp:589] Eltwise40_ReLU81_0_split -> Eltwise40_ReLU81_0_split_0
I0612 11:07:32.114403  5211 net.cpp:589] Eltwise40_ReLU81_0_split -> Eltwise40_ReLU81_0_split_1
I0612 11:07:32.114455  5211 net.cpp:240] Setting up Eltwise40_ReLU81_0_split
I0612 11:07:32.114464  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.114470  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.114475  5211 net.cpp:255] Memory required for data: 2648180224
I0612 11:07:32.114480  5211 layer_factory.hpp:77] Creating layer Convolution82
I0612 11:07:32.114490  5211 net.cpp:190] Creating Layer Convolution82
I0612 11:07:32.114495  5211 net.cpp:615] Convolution82 <- Eltwise40_ReLU81_0_split_0
I0612 11:07:32.114506  5211 net.cpp:589] Convolution82 -> Convolution82
I0612 11:07:32.116647  5211 net.cpp:240] Setting up Convolution82
I0612 11:07:32.116658  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.116663  5211 net.cpp:255] Memory required for data: 2650277376
I0612 11:07:32.116675  5211 layer_factory.hpp:77] Creating layer BatchNorm82
I0612 11:07:32.116686  5211 net.cpp:190] Creating Layer BatchNorm82
I0612 11:07:32.116693  5211 net.cpp:615] BatchNorm82 <- Convolution82
I0612 11:07:32.116703  5211 net.cpp:576] BatchNorm82 -> Convolution82 (in-place)
I0612 11:07:32.116989  5211 net.cpp:240] Setting up BatchNorm82
I0612 11:07:32.116999  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.117004  5211 net.cpp:255] Memory required for data: 2652374528
I0612 11:07:32.117018  5211 layer_factory.hpp:77] Creating layer Scale82
I0612 11:07:32.117027  5211 net.cpp:190] Creating Layer Scale82
I0612 11:07:32.117033  5211 net.cpp:615] Scale82 <- Convolution82
I0612 11:07:32.117040  5211 net.cpp:576] Scale82 -> Convolution82 (in-place)
I0612 11:07:32.117091  5211 layer_factory.hpp:77] Creating layer Scale82
I0612 11:07:32.117265  5211 net.cpp:240] Setting up Scale82
I0612 11:07:32.117275  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.117280  5211 net.cpp:255] Memory required for data: 2654471680
I0612 11:07:32.117292  5211 layer_factory.hpp:77] Creating layer ReLU82
I0612 11:07:32.117300  5211 net.cpp:190] Creating Layer ReLU82
I0612 11:07:32.117306  5211 net.cpp:615] ReLU82 <- Convolution82
I0612 11:07:32.117313  5211 net.cpp:576] ReLU82 -> Convolution82 (in-place)
I0612 11:07:32.117322  5211 net.cpp:240] Setting up ReLU82
I0612 11:07:32.117328  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.117333  5211 net.cpp:255] Memory required for data: 2656568832
I0612 11:07:32.117338  5211 layer_factory.hpp:77] Creating layer Convolution83
I0612 11:07:32.117352  5211 net.cpp:190] Creating Layer Convolution83
I0612 11:07:32.117357  5211 net.cpp:615] Convolution83 <- Convolution82
I0612 11:07:32.117367  5211 net.cpp:589] Convolution83 -> Convolution83
I0612 11:07:32.119515  5211 net.cpp:240] Setting up Convolution83
I0612 11:07:32.119527  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.119532  5211 net.cpp:255] Memory required for data: 2658665984
I0612 11:07:32.119544  5211 layer_factory.hpp:77] Creating layer BatchNorm83
I0612 11:07:32.119555  5211 net.cpp:190] Creating Layer BatchNorm83
I0612 11:07:32.119561  5211 net.cpp:615] BatchNorm83 <- Convolution83
I0612 11:07:32.119570  5211 net.cpp:576] BatchNorm83 -> Convolution83 (in-place)
I0612 11:07:32.119850  5211 net.cpp:240] Setting up BatchNorm83
I0612 11:07:32.119860  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.119864  5211 net.cpp:255] Memory required for data: 2660763136
I0612 11:07:32.119881  5211 layer_factory.hpp:77] Creating layer Scale83
I0612 11:07:32.119890  5211 net.cpp:190] Creating Layer Scale83
I0612 11:07:32.119895  5211 net.cpp:615] Scale83 <- Convolution83
I0612 11:07:32.119902  5211 net.cpp:576] Scale83 -> Convolution83 (in-place)
I0612 11:07:32.119952  5211 layer_factory.hpp:77] Creating layer Scale83
I0612 11:07:32.120121  5211 net.cpp:240] Setting up Scale83
I0612 11:07:32.120128  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.120133  5211 net.cpp:255] Memory required for data: 2662860288
I0612 11:07:32.120147  5211 layer_factory.hpp:77] Creating layer Eltwise41
I0612 11:07:32.120157  5211 net.cpp:190] Creating Layer Eltwise41
I0612 11:07:32.120162  5211 net.cpp:615] Eltwise41 <- Eltwise40_ReLU81_0_split_1
I0612 11:07:32.120169  5211 net.cpp:615] Eltwise41 <- Convolution83
I0612 11:07:32.120178  5211 net.cpp:589] Eltwise41 -> Eltwise41
I0612 11:07:32.120204  5211 net.cpp:240] Setting up Eltwise41
I0612 11:07:32.120213  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.120218  5211 net.cpp:255] Memory required for data: 2664957440
I0612 11:07:32.120223  5211 layer_factory.hpp:77] Creating layer ReLU83
I0612 11:07:32.120229  5211 net.cpp:190] Creating Layer ReLU83
I0612 11:07:32.120234  5211 net.cpp:615] ReLU83 <- Eltwise41
I0612 11:07:32.120244  5211 net.cpp:576] ReLU83 -> Eltwise41 (in-place)
I0612 11:07:32.120252  5211 net.cpp:240] Setting up ReLU83
I0612 11:07:32.120260  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.120265  5211 net.cpp:255] Memory required for data: 2667054592
I0612 11:07:32.120268  5211 layer_factory.hpp:77] Creating layer Eltwise41_ReLU83_0_split
I0612 11:07:32.120275  5211 net.cpp:190] Creating Layer Eltwise41_ReLU83_0_split
I0612 11:07:32.120280  5211 net.cpp:615] Eltwise41_ReLU83_0_split <- Eltwise41
I0612 11:07:32.120287  5211 net.cpp:589] Eltwise41_ReLU83_0_split -> Eltwise41_ReLU83_0_split_0
I0612 11:07:32.120297  5211 net.cpp:589] Eltwise41_ReLU83_0_split -> Eltwise41_ReLU83_0_split_1
I0612 11:07:32.120347  5211 net.cpp:240] Setting up Eltwise41_ReLU83_0_split
I0612 11:07:32.120354  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.120362  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.120365  5211 net.cpp:255] Memory required for data: 2671248896
I0612 11:07:32.120370  5211 layer_factory.hpp:77] Creating layer Convolution84
I0612 11:07:32.120385  5211 net.cpp:190] Creating Layer Convolution84
I0612 11:07:32.120391  5211 net.cpp:615] Convolution84 <- Eltwise41_ReLU83_0_split_0
I0612 11:07:32.120403  5211 net.cpp:589] Convolution84 -> Convolution84
I0612 11:07:32.122556  5211 net.cpp:240] Setting up Convolution84
I0612 11:07:32.122568  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.122573  5211 net.cpp:255] Memory required for data: 2673346048
I0612 11:07:32.122586  5211 layer_factory.hpp:77] Creating layer BatchNorm84
I0612 11:07:32.122597  5211 net.cpp:190] Creating Layer BatchNorm84
I0612 11:07:32.122603  5211 net.cpp:615] BatchNorm84 <- Convolution84
I0612 11:07:32.122611  5211 net.cpp:576] BatchNorm84 -> Convolution84 (in-place)
I0612 11:07:32.122903  5211 net.cpp:240] Setting up BatchNorm84
I0612 11:07:32.122912  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.122916  5211 net.cpp:255] Memory required for data: 2675443200
I0612 11:07:32.122931  5211 layer_factory.hpp:77] Creating layer Scale84
I0612 11:07:32.122941  5211 net.cpp:190] Creating Layer Scale84
I0612 11:07:32.122946  5211 net.cpp:615] Scale84 <- Convolution84
I0612 11:07:32.122953  5211 net.cpp:576] Scale84 -> Convolution84 (in-place)
I0612 11:07:32.122998  5211 layer_factory.hpp:77] Creating layer Scale84
I0612 11:07:32.123157  5211 net.cpp:240] Setting up Scale84
I0612 11:07:32.123164  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.123168  5211 net.cpp:255] Memory required for data: 2677540352
I0612 11:07:32.123179  5211 layer_factory.hpp:77] Creating layer ReLU84
I0612 11:07:32.123189  5211 net.cpp:190] Creating Layer ReLU84
I0612 11:07:32.123194  5211 net.cpp:615] ReLU84 <- Convolution84
I0612 11:07:32.123201  5211 net.cpp:576] ReLU84 -> Convolution84 (in-place)
I0612 11:07:32.123209  5211 net.cpp:240] Setting up ReLU84
I0612 11:07:32.123216  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.123220  5211 net.cpp:255] Memory required for data: 2679637504
I0612 11:07:32.123225  5211 layer_factory.hpp:77] Creating layer Convolution85
I0612 11:07:32.123239  5211 net.cpp:190] Creating Layer Convolution85
I0612 11:07:32.123244  5211 net.cpp:615] Convolution85 <- Convolution84
I0612 11:07:32.123251  5211 net.cpp:589] Convolution85 -> Convolution85
I0612 11:07:32.125277  5211 net.cpp:240] Setting up Convolution85
I0612 11:07:32.125288  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.125293  5211 net.cpp:255] Memory required for data: 2681734656
I0612 11:07:32.125303  5211 layer_factory.hpp:77] Creating layer BatchNorm85
I0612 11:07:32.125313  5211 net.cpp:190] Creating Layer BatchNorm85
I0612 11:07:32.125319  5211 net.cpp:615] BatchNorm85 <- Convolution85
I0612 11:07:32.125325  5211 net.cpp:576] BatchNorm85 -> Convolution85 (in-place)
I0612 11:07:32.125589  5211 net.cpp:240] Setting up BatchNorm85
I0612 11:07:32.125597  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.125602  5211 net.cpp:255] Memory required for data: 2683831808
I0612 11:07:32.125615  5211 layer_factory.hpp:77] Creating layer Scale85
I0612 11:07:32.125623  5211 net.cpp:190] Creating Layer Scale85
I0612 11:07:32.125628  5211 net.cpp:615] Scale85 <- Convolution85
I0612 11:07:32.125635  5211 net.cpp:576] Scale85 -> Convolution85 (in-place)
I0612 11:07:32.125684  5211 layer_factory.hpp:77] Creating layer Scale85
I0612 11:07:32.125844  5211 net.cpp:240] Setting up Scale85
I0612 11:07:32.125854  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.125859  5211 net.cpp:255] Memory required for data: 2685928960
I0612 11:07:32.125869  5211 layer_factory.hpp:77] Creating layer Eltwise42
I0612 11:07:32.125880  5211 net.cpp:190] Creating Layer Eltwise42
I0612 11:07:32.125885  5211 net.cpp:615] Eltwise42 <- Eltwise41_ReLU83_0_split_1
I0612 11:07:32.125892  5211 net.cpp:615] Eltwise42 <- Convolution85
I0612 11:07:32.125900  5211 net.cpp:589] Eltwise42 -> Eltwise42
I0612 11:07:32.125926  5211 net.cpp:240] Setting up Eltwise42
I0612 11:07:32.125934  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.125942  5211 net.cpp:255] Memory required for data: 2688026112
I0612 11:07:32.125947  5211 layer_factory.hpp:77] Creating layer ReLU85
I0612 11:07:32.125954  5211 net.cpp:190] Creating Layer ReLU85
I0612 11:07:32.125959  5211 net.cpp:615] ReLU85 <- Eltwise42
I0612 11:07:32.125970  5211 net.cpp:576] ReLU85 -> Eltwise42 (in-place)
I0612 11:07:32.125978  5211 net.cpp:240] Setting up ReLU85
I0612 11:07:32.125984  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.125989  5211 net.cpp:255] Memory required for data: 2690123264
I0612 11:07:32.125993  5211 layer_factory.hpp:77] Creating layer Eltwise42_ReLU85_0_split
I0612 11:07:32.126000  5211 net.cpp:190] Creating Layer Eltwise42_ReLU85_0_split
I0612 11:07:32.126005  5211 net.cpp:615] Eltwise42_ReLU85_0_split <- Eltwise42
I0612 11:07:32.126013  5211 net.cpp:589] Eltwise42_ReLU85_0_split -> Eltwise42_ReLU85_0_split_0
I0612 11:07:32.126021  5211 net.cpp:589] Eltwise42_ReLU85_0_split -> Eltwise42_ReLU85_0_split_1
I0612 11:07:32.126070  5211 net.cpp:240] Setting up Eltwise42_ReLU85_0_split
I0612 11:07:32.126077  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.126083  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.126087  5211 net.cpp:255] Memory required for data: 2694317568
I0612 11:07:32.126092  5211 layer_factory.hpp:77] Creating layer Convolution86
I0612 11:07:32.126104  5211 net.cpp:190] Creating Layer Convolution86
I0612 11:07:32.126111  5211 net.cpp:615] Convolution86 <- Eltwise42_ReLU85_0_split_0
I0612 11:07:32.126119  5211 net.cpp:589] Convolution86 -> Convolution86
I0612 11:07:32.128155  5211 net.cpp:240] Setting up Convolution86
I0612 11:07:32.128166  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.128170  5211 net.cpp:255] Memory required for data: 2696414720
I0612 11:07:32.128181  5211 layer_factory.hpp:77] Creating layer BatchNorm86
I0612 11:07:32.128193  5211 net.cpp:190] Creating Layer BatchNorm86
I0612 11:07:32.128199  5211 net.cpp:615] BatchNorm86 <- Convolution86
I0612 11:07:32.128209  5211 net.cpp:576] BatchNorm86 -> Convolution86 (in-place)
I0612 11:07:32.128475  5211 net.cpp:240] Setting up BatchNorm86
I0612 11:07:32.128484  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.128489  5211 net.cpp:255] Memory required for data: 2698511872
I0612 11:07:32.128504  5211 layer_factory.hpp:77] Creating layer Scale86
I0612 11:07:32.128512  5211 net.cpp:190] Creating Layer Scale86
I0612 11:07:32.128517  5211 net.cpp:615] Scale86 <- Convolution86
I0612 11:07:32.128525  5211 net.cpp:576] Scale86 -> Convolution86 (in-place)
I0612 11:07:32.128572  5211 layer_factory.hpp:77] Creating layer Scale86
I0612 11:07:32.128732  5211 net.cpp:240] Setting up Scale86
I0612 11:07:32.128741  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.128746  5211 net.cpp:255] Memory required for data: 2700609024
I0612 11:07:32.128758  5211 layer_factory.hpp:77] Creating layer ReLU86
I0612 11:07:32.128767  5211 net.cpp:190] Creating Layer ReLU86
I0612 11:07:32.128772  5211 net.cpp:615] ReLU86 <- Convolution86
I0612 11:07:32.128780  5211 net.cpp:576] ReLU86 -> Convolution86 (in-place)
I0612 11:07:32.128788  5211 net.cpp:240] Setting up ReLU86
I0612 11:07:32.128795  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.128800  5211 net.cpp:255] Memory required for data: 2702706176
I0612 11:07:32.128804  5211 layer_factory.hpp:77] Creating layer Convolution87
I0612 11:07:32.128815  5211 net.cpp:190] Creating Layer Convolution87
I0612 11:07:32.128819  5211 net.cpp:615] Convolution87 <- Convolution86
I0612 11:07:32.128829  5211 net.cpp:589] Convolution87 -> Convolution87
I0612 11:07:32.131552  5211 net.cpp:240] Setting up Convolution87
I0612 11:07:32.131569  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.131574  5211 net.cpp:255] Memory required for data: 2704803328
I0612 11:07:32.131587  5211 layer_factory.hpp:77] Creating layer BatchNorm87
I0612 11:07:32.131599  5211 net.cpp:190] Creating Layer BatchNorm87
I0612 11:07:32.131606  5211 net.cpp:615] BatchNorm87 <- Convolution87
I0612 11:07:32.131619  5211 net.cpp:576] BatchNorm87 -> Convolution87 (in-place)
I0612 11:07:32.131896  5211 net.cpp:240] Setting up BatchNorm87
I0612 11:07:32.131906  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.131911  5211 net.cpp:255] Memory required for data: 2706900480
I0612 11:07:32.131927  5211 layer_factory.hpp:77] Creating layer Scale87
I0612 11:07:32.131937  5211 net.cpp:190] Creating Layer Scale87
I0612 11:07:32.131942  5211 net.cpp:615] Scale87 <- Convolution87
I0612 11:07:32.131949  5211 net.cpp:576] Scale87 -> Convolution87 (in-place)
I0612 11:07:32.131999  5211 layer_factory.hpp:77] Creating layer Scale87
I0612 11:07:32.132164  5211 net.cpp:240] Setting up Scale87
I0612 11:07:32.132172  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.132177  5211 net.cpp:255] Memory required for data: 2708997632
I0612 11:07:32.132189  5211 layer_factory.hpp:77] Creating layer Eltwise43
I0612 11:07:32.132196  5211 net.cpp:190] Creating Layer Eltwise43
I0612 11:07:32.132202  5211 net.cpp:615] Eltwise43 <- Eltwise42_ReLU85_0_split_1
I0612 11:07:32.132211  5211 net.cpp:615] Eltwise43 <- Convolution87
I0612 11:07:32.132220  5211 net.cpp:589] Eltwise43 -> Eltwise43
I0612 11:07:32.132246  5211 net.cpp:240] Setting up Eltwise43
I0612 11:07:32.132252  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.132257  5211 net.cpp:255] Memory required for data: 2711094784
I0612 11:07:32.132261  5211 layer_factory.hpp:77] Creating layer ReLU87
I0612 11:07:32.132272  5211 net.cpp:190] Creating Layer ReLU87
I0612 11:07:32.132277  5211 net.cpp:615] ReLU87 <- Eltwise43
I0612 11:07:32.132283  5211 net.cpp:576] ReLU87 -> Eltwise43 (in-place)
I0612 11:07:32.132292  5211 net.cpp:240] Setting up ReLU87
I0612 11:07:32.132298  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.132303  5211 net.cpp:255] Memory required for data: 2713191936
I0612 11:07:32.132308  5211 layer_factory.hpp:77] Creating layer Eltwise43_ReLU87_0_split
I0612 11:07:32.132314  5211 net.cpp:190] Creating Layer Eltwise43_ReLU87_0_split
I0612 11:07:32.132318  5211 net.cpp:615] Eltwise43_ReLU87_0_split <- Eltwise43
I0612 11:07:32.132325  5211 net.cpp:589] Eltwise43_ReLU87_0_split -> Eltwise43_ReLU87_0_split_0
I0612 11:07:32.132334  5211 net.cpp:589] Eltwise43_ReLU87_0_split -> Eltwise43_ReLU87_0_split_1
I0612 11:07:32.132388  5211 net.cpp:240] Setting up Eltwise43_ReLU87_0_split
I0612 11:07:32.132397  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.132403  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.132408  5211 net.cpp:255] Memory required for data: 2717386240
I0612 11:07:32.132412  5211 layer_factory.hpp:77] Creating layer Convolution88
I0612 11:07:32.132423  5211 net.cpp:190] Creating Layer Convolution88
I0612 11:07:32.132428  5211 net.cpp:615] Convolution88 <- Eltwise43_ReLU87_0_split_0
I0612 11:07:32.132441  5211 net.cpp:589] Convolution88 -> Convolution88
I0612 11:07:32.134523  5211 net.cpp:240] Setting up Convolution88
I0612 11:07:32.134537  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.134542  5211 net.cpp:255] Memory required for data: 2719483392
I0612 11:07:32.134554  5211 layer_factory.hpp:77] Creating layer BatchNorm88
I0612 11:07:32.134565  5211 net.cpp:190] Creating Layer BatchNorm88
I0612 11:07:32.134572  5211 net.cpp:615] BatchNorm88 <- Convolution88
I0612 11:07:32.134579  5211 net.cpp:576] BatchNorm88 -> Convolution88 (in-place)
I0612 11:07:32.134861  5211 net.cpp:240] Setting up BatchNorm88
I0612 11:07:32.134871  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.134876  5211 net.cpp:255] Memory required for data: 2721580544
I0612 11:07:32.134888  5211 layer_factory.hpp:77] Creating layer Scale88
I0612 11:07:32.134898  5211 net.cpp:190] Creating Layer Scale88
I0612 11:07:32.134904  5211 net.cpp:615] Scale88 <- Convolution88
I0612 11:07:32.134910  5211 net.cpp:576] Scale88 -> Convolution88 (in-place)
I0612 11:07:32.134955  5211 layer_factory.hpp:77] Creating layer Scale88
I0612 11:07:32.135107  5211 net.cpp:240] Setting up Scale88
I0612 11:07:32.135119  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.135123  5211 net.cpp:255] Memory required for data: 2723677696
I0612 11:07:32.135134  5211 layer_factory.hpp:77] Creating layer ReLU88
I0612 11:07:32.135144  5211 net.cpp:190] Creating Layer ReLU88
I0612 11:07:32.135150  5211 net.cpp:615] ReLU88 <- Convolution88
I0612 11:07:32.135156  5211 net.cpp:576] ReLU88 -> Convolution88 (in-place)
I0612 11:07:32.135164  5211 net.cpp:240] Setting up ReLU88
I0612 11:07:32.135170  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.135175  5211 net.cpp:255] Memory required for data: 2725774848
I0612 11:07:32.135179  5211 layer_factory.hpp:77] Creating layer Convolution89
I0612 11:07:32.135191  5211 net.cpp:190] Creating Layer Convolution89
I0612 11:07:32.135195  5211 net.cpp:615] Convolution89 <- Convolution88
I0612 11:07:32.135203  5211 net.cpp:589] Convolution89 -> Convolution89
I0612 11:07:32.137128  5211 net.cpp:240] Setting up Convolution89
I0612 11:07:32.137140  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.137145  5211 net.cpp:255] Memory required for data: 2727872000
I0612 11:07:32.137154  5211 layer_factory.hpp:77] Creating layer BatchNorm89
I0612 11:07:32.137164  5211 net.cpp:190] Creating Layer BatchNorm89
I0612 11:07:32.137171  5211 net.cpp:615] BatchNorm89 <- Convolution89
I0612 11:07:32.137176  5211 net.cpp:576] BatchNorm89 -> Convolution89 (in-place)
I0612 11:07:32.137434  5211 net.cpp:240] Setting up BatchNorm89
I0612 11:07:32.137442  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.137446  5211 net.cpp:255] Memory required for data: 2729969152
I0612 11:07:32.137459  5211 layer_factory.hpp:77] Creating layer Scale89
I0612 11:07:32.137466  5211 net.cpp:190] Creating Layer Scale89
I0612 11:07:32.137472  5211 net.cpp:615] Scale89 <- Convolution89
I0612 11:07:32.137478  5211 net.cpp:576] Scale89 -> Convolution89 (in-place)
I0612 11:07:32.137526  5211 layer_factory.hpp:77] Creating layer Scale89
I0612 11:07:32.137677  5211 net.cpp:240] Setting up Scale89
I0612 11:07:32.137686  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.137691  5211 net.cpp:255] Memory required for data: 2732066304
I0612 11:07:32.137703  5211 layer_factory.hpp:77] Creating layer Eltwise44
I0612 11:07:32.137711  5211 net.cpp:190] Creating Layer Eltwise44
I0612 11:07:32.137717  5211 net.cpp:615] Eltwise44 <- Eltwise43_ReLU87_0_split_1
I0612 11:07:32.137722  5211 net.cpp:615] Eltwise44 <- Convolution89
I0612 11:07:32.137729  5211 net.cpp:589] Eltwise44 -> Eltwise44
I0612 11:07:32.137755  5211 net.cpp:240] Setting up Eltwise44
I0612 11:07:32.137763  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.137768  5211 net.cpp:255] Memory required for data: 2734163456
I0612 11:07:32.137771  5211 layer_factory.hpp:77] Creating layer ReLU89
I0612 11:07:32.137778  5211 net.cpp:190] Creating Layer ReLU89
I0612 11:07:32.137784  5211 net.cpp:615] ReLU89 <- Eltwise44
I0612 11:07:32.137791  5211 net.cpp:576] ReLU89 -> Eltwise44 (in-place)
I0612 11:07:32.137799  5211 net.cpp:240] Setting up ReLU89
I0612 11:07:32.137805  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.137810  5211 net.cpp:255] Memory required for data: 2736260608
I0612 11:07:32.137814  5211 layer_factory.hpp:77] Creating layer Eltwise44_ReLU89_0_split
I0612 11:07:32.137820  5211 net.cpp:190] Creating Layer Eltwise44_ReLU89_0_split
I0612 11:07:32.137825  5211 net.cpp:615] Eltwise44_ReLU89_0_split <- Eltwise44
I0612 11:07:32.137831  5211 net.cpp:589] Eltwise44_ReLU89_0_split -> Eltwise44_ReLU89_0_split_0
I0612 11:07:32.137840  5211 net.cpp:589] Eltwise44_ReLU89_0_split -> Eltwise44_ReLU89_0_split_1
I0612 11:07:32.137886  5211 net.cpp:240] Setting up Eltwise44_ReLU89_0_split
I0612 11:07:32.137892  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.137898  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.137902  5211 net.cpp:255] Memory required for data: 2740454912
I0612 11:07:32.137907  5211 layer_factory.hpp:77] Creating layer Convolution90
I0612 11:07:32.137923  5211 net.cpp:190] Creating Layer Convolution90
I0612 11:07:32.137929  5211 net.cpp:615] Convolution90 <- Eltwise44_ReLU89_0_split_0
I0612 11:07:32.137938  5211 net.cpp:589] Convolution90 -> Convolution90
I0612 11:07:32.139871  5211 net.cpp:240] Setting up Convolution90
I0612 11:07:32.139883  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.139886  5211 net.cpp:255] Memory required for data: 2742552064
I0612 11:07:32.139899  5211 layer_factory.hpp:77] Creating layer BatchNorm90
I0612 11:07:32.139909  5211 net.cpp:190] Creating Layer BatchNorm90
I0612 11:07:32.139914  5211 net.cpp:615] BatchNorm90 <- Convolution90
I0612 11:07:32.139922  5211 net.cpp:576] BatchNorm90 -> Convolution90 (in-place)
I0612 11:07:32.140174  5211 net.cpp:240] Setting up BatchNorm90
I0612 11:07:32.140182  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.140187  5211 net.cpp:255] Memory required for data: 2744649216
I0612 11:07:32.140202  5211 layer_factory.hpp:77] Creating layer Scale90
I0612 11:07:32.140210  5211 net.cpp:190] Creating Layer Scale90
I0612 11:07:32.140216  5211 net.cpp:615] Scale90 <- Convolution90
I0612 11:07:32.140223  5211 net.cpp:576] Scale90 -> Convolution90 (in-place)
I0612 11:07:32.140267  5211 layer_factory.hpp:77] Creating layer Scale90
I0612 11:07:32.140424  5211 net.cpp:240] Setting up Scale90
I0612 11:07:32.140431  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.140435  5211 net.cpp:255] Memory required for data: 2746746368
I0612 11:07:32.140446  5211 layer_factory.hpp:77] Creating layer ReLU90
I0612 11:07:32.140455  5211 net.cpp:190] Creating Layer ReLU90
I0612 11:07:32.140460  5211 net.cpp:615] ReLU90 <- Convolution90
I0612 11:07:32.140467  5211 net.cpp:576] ReLU90 -> Convolution90 (in-place)
I0612 11:07:32.140475  5211 net.cpp:240] Setting up ReLU90
I0612 11:07:32.140481  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.140486  5211 net.cpp:255] Memory required for data: 2748843520
I0612 11:07:32.140491  5211 layer_factory.hpp:77] Creating layer Convolution91
I0612 11:07:32.140501  5211 net.cpp:190] Creating Layer Convolution91
I0612 11:07:32.140504  5211 net.cpp:615] Convolution91 <- Convolution90
I0612 11:07:32.140514  5211 net.cpp:589] Convolution91 -> Convolution91
I0612 11:07:32.142442  5211 net.cpp:240] Setting up Convolution91
I0612 11:07:32.142452  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.142457  5211 net.cpp:255] Memory required for data: 2750940672
I0612 11:07:32.142467  5211 layer_factory.hpp:77] Creating layer BatchNorm91
I0612 11:07:32.142477  5211 net.cpp:190] Creating Layer BatchNorm91
I0612 11:07:32.142482  5211 net.cpp:615] BatchNorm91 <- Convolution91
I0612 11:07:32.142490  5211 net.cpp:576] BatchNorm91 -> Convolution91 (in-place)
I0612 11:07:32.142745  5211 net.cpp:240] Setting up BatchNorm91
I0612 11:07:32.142752  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.142757  5211 net.cpp:255] Memory required for data: 2753037824
I0612 11:07:32.142771  5211 layer_factory.hpp:77] Creating layer Scale91
I0612 11:07:32.142778  5211 net.cpp:190] Creating Layer Scale91
I0612 11:07:32.142782  5211 net.cpp:615] Scale91 <- Convolution91
I0612 11:07:32.142791  5211 net.cpp:576] Scale91 -> Convolution91 (in-place)
I0612 11:07:32.142834  5211 layer_factory.hpp:77] Creating layer Scale91
I0612 11:07:32.142987  5211 net.cpp:240] Setting up Scale91
I0612 11:07:32.142995  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.142999  5211 net.cpp:255] Memory required for data: 2755134976
I0612 11:07:32.143009  5211 layer_factory.hpp:77] Creating layer Eltwise45
I0612 11:07:32.143018  5211 net.cpp:190] Creating Layer Eltwise45
I0612 11:07:32.143023  5211 net.cpp:615] Eltwise45 <- Eltwise44_ReLU89_0_split_1
I0612 11:07:32.143029  5211 net.cpp:615] Eltwise45 <- Convolution91
I0612 11:07:32.143038  5211 net.cpp:589] Eltwise45 -> Eltwise45
I0612 11:07:32.143062  5211 net.cpp:240] Setting up Eltwise45
I0612 11:07:32.143074  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.143077  5211 net.cpp:255] Memory required for data: 2757232128
I0612 11:07:32.143085  5211 layer_factory.hpp:77] Creating layer ReLU91
I0612 11:07:32.143091  5211 net.cpp:190] Creating Layer ReLU91
I0612 11:07:32.143096  5211 net.cpp:615] ReLU91 <- Eltwise45
I0612 11:07:32.143102  5211 net.cpp:576] ReLU91 -> Eltwise45 (in-place)
I0612 11:07:32.143110  5211 net.cpp:240] Setting up ReLU91
I0612 11:07:32.143116  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.143121  5211 net.cpp:255] Memory required for data: 2759329280
I0612 11:07:32.143124  5211 layer_factory.hpp:77] Creating layer Eltwise45_ReLU91_0_split
I0612 11:07:32.143131  5211 net.cpp:190] Creating Layer Eltwise45_ReLU91_0_split
I0612 11:07:32.143136  5211 net.cpp:615] Eltwise45_ReLU91_0_split <- Eltwise45
I0612 11:07:32.143144  5211 net.cpp:589] Eltwise45_ReLU91_0_split -> Eltwise45_ReLU91_0_split_0
I0612 11:07:32.143153  5211 net.cpp:589] Eltwise45_ReLU91_0_split -> Eltwise45_ReLU91_0_split_1
I0612 11:07:32.143198  5211 net.cpp:240] Setting up Eltwise45_ReLU91_0_split
I0612 11:07:32.143204  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.143210  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.143214  5211 net.cpp:255] Memory required for data: 2763523584
I0612 11:07:32.143218  5211 layer_factory.hpp:77] Creating layer Convolution92
I0612 11:07:32.143231  5211 net.cpp:190] Creating Layer Convolution92
I0612 11:07:32.143236  5211 net.cpp:615] Convolution92 <- Eltwise45_ReLU91_0_split_0
I0612 11:07:32.143244  5211 net.cpp:589] Convolution92 -> Convolution92
I0612 11:07:32.145171  5211 net.cpp:240] Setting up Convolution92
I0612 11:07:32.145181  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.145186  5211 net.cpp:255] Memory required for data: 2765620736
I0612 11:07:32.145197  5211 layer_factory.hpp:77] Creating layer BatchNorm92
I0612 11:07:32.145207  5211 net.cpp:190] Creating Layer BatchNorm92
I0612 11:07:32.145212  5211 net.cpp:615] BatchNorm92 <- Convolution92
I0612 11:07:32.145220  5211 net.cpp:576] BatchNorm92 -> Convolution92 (in-place)
I0612 11:07:32.145481  5211 net.cpp:240] Setting up BatchNorm92
I0612 11:07:32.145490  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.145494  5211 net.cpp:255] Memory required for data: 2767717888
I0612 11:07:32.145509  5211 layer_factory.hpp:77] Creating layer Scale92
I0612 11:07:32.145516  5211 net.cpp:190] Creating Layer Scale92
I0612 11:07:32.145521  5211 net.cpp:615] Scale92 <- Convolution92
I0612 11:07:32.145527  5211 net.cpp:576] Scale92 -> Convolution92 (in-place)
I0612 11:07:32.145576  5211 layer_factory.hpp:77] Creating layer Scale92
I0612 11:07:32.145725  5211 net.cpp:240] Setting up Scale92
I0612 11:07:32.145733  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.145737  5211 net.cpp:255] Memory required for data: 2769815040
I0612 11:07:32.145750  5211 layer_factory.hpp:77] Creating layer ReLU92
I0612 11:07:32.145758  5211 net.cpp:190] Creating Layer ReLU92
I0612 11:07:32.145763  5211 net.cpp:615] ReLU92 <- Convolution92
I0612 11:07:32.145769  5211 net.cpp:576] ReLU92 -> Convolution92 (in-place)
I0612 11:07:32.145777  5211 net.cpp:240] Setting up ReLU92
I0612 11:07:32.145783  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.145787  5211 net.cpp:255] Memory required for data: 2771912192
I0612 11:07:32.145792  5211 layer_factory.hpp:77] Creating layer Convolution93
I0612 11:07:32.145804  5211 net.cpp:190] Creating Layer Convolution93
I0612 11:07:32.145809  5211 net.cpp:615] Convolution93 <- Convolution92
I0612 11:07:32.145818  5211 net.cpp:589] Convolution93 -> Convolution93
I0612 11:07:32.147698  5211 net.cpp:240] Setting up Convolution93
I0612 11:07:32.147708  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.147712  5211 net.cpp:255] Memory required for data: 2774009344
I0612 11:07:32.147723  5211 layer_factory.hpp:77] Creating layer BatchNorm93
I0612 11:07:32.147732  5211 net.cpp:190] Creating Layer BatchNorm93
I0612 11:07:32.147738  5211 net.cpp:615] BatchNorm93 <- Convolution93
I0612 11:07:32.147749  5211 net.cpp:576] BatchNorm93 -> Convolution93 (in-place)
I0612 11:07:32.147990  5211 net.cpp:240] Setting up BatchNorm93
I0612 11:07:32.147999  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.148002  5211 net.cpp:255] Memory required for data: 2776106496
I0612 11:07:32.148015  5211 layer_factory.hpp:77] Creating layer Scale93
I0612 11:07:32.148025  5211 net.cpp:190] Creating Layer Scale93
I0612 11:07:32.148030  5211 net.cpp:615] Scale93 <- Convolution93
I0612 11:07:32.148036  5211 net.cpp:576] Scale93 -> Convolution93 (in-place)
I0612 11:07:32.148079  5211 layer_factory.hpp:77] Creating layer Scale93
I0612 11:07:32.148227  5211 net.cpp:240] Setting up Scale93
I0612 11:07:32.148236  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.148239  5211 net.cpp:255] Memory required for data: 2778203648
I0612 11:07:32.148255  5211 layer_factory.hpp:77] Creating layer Eltwise46
I0612 11:07:32.148263  5211 net.cpp:190] Creating Layer Eltwise46
I0612 11:07:32.148269  5211 net.cpp:615] Eltwise46 <- Eltwise45_ReLU91_0_split_1
I0612 11:07:32.148275  5211 net.cpp:615] Eltwise46 <- Convolution93
I0612 11:07:32.148283  5211 net.cpp:589] Eltwise46 -> Eltwise46
I0612 11:07:32.148306  5211 net.cpp:240] Setting up Eltwise46
I0612 11:07:32.148314  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.148319  5211 net.cpp:255] Memory required for data: 2780300800
I0612 11:07:32.148322  5211 layer_factory.hpp:77] Creating layer ReLU93
I0612 11:07:32.148329  5211 net.cpp:190] Creating Layer ReLU93
I0612 11:07:32.148334  5211 net.cpp:615] ReLU93 <- Eltwise46
I0612 11:07:32.148341  5211 net.cpp:576] ReLU93 -> Eltwise46 (in-place)
I0612 11:07:32.148350  5211 net.cpp:240] Setting up ReLU93
I0612 11:07:32.148355  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.148360  5211 net.cpp:255] Memory required for data: 2782397952
I0612 11:07:32.148363  5211 layer_factory.hpp:77] Creating layer Eltwise46_ReLU93_0_split
I0612 11:07:32.148370  5211 net.cpp:190] Creating Layer Eltwise46_ReLU93_0_split
I0612 11:07:32.148373  5211 net.cpp:615] Eltwise46_ReLU93_0_split <- Eltwise46
I0612 11:07:32.148380  5211 net.cpp:589] Eltwise46_ReLU93_0_split -> Eltwise46_ReLU93_0_split_0
I0612 11:07:32.148388  5211 net.cpp:589] Eltwise46_ReLU93_0_split -> Eltwise46_ReLU93_0_split_1
I0612 11:07:32.148432  5211 net.cpp:240] Setting up Eltwise46_ReLU93_0_split
I0612 11:07:32.148438  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.148443  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.148447  5211 net.cpp:255] Memory required for data: 2786592256
I0612 11:07:32.148452  5211 layer_factory.hpp:77] Creating layer Convolution94
I0612 11:07:32.148461  5211 net.cpp:190] Creating Layer Convolution94
I0612 11:07:32.148466  5211 net.cpp:615] Convolution94 <- Eltwise46_ReLU93_0_split_0
I0612 11:07:32.148476  5211 net.cpp:589] Convolution94 -> Convolution94
I0612 11:07:32.153774  5211 net.cpp:240] Setting up Convolution94
I0612 11:07:32.153831  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.153836  5211 net.cpp:255] Memory required for data: 2788689408
I0612 11:07:32.153908  5211 layer_factory.hpp:77] Creating layer BatchNorm94
I0612 11:07:32.153964  5211 net.cpp:190] Creating Layer BatchNorm94
I0612 11:07:32.154044  5211 net.cpp:615] BatchNorm94 <- Convolution94
I0612 11:07:32.154063  5211 net.cpp:576] BatchNorm94 -> Convolution94 (in-place)
I0612 11:07:32.154323  5211 net.cpp:240] Setting up BatchNorm94
I0612 11:07:32.154332  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.154336  5211 net.cpp:255] Memory required for data: 2790786560
I0612 11:07:32.154362  5211 layer_factory.hpp:77] Creating layer Scale94
I0612 11:07:32.154372  5211 net.cpp:190] Creating Layer Scale94
I0612 11:07:32.154377  5211 net.cpp:615] Scale94 <- Convolution94
I0612 11:07:32.154384  5211 net.cpp:576] Scale94 -> Convolution94 (in-place)
I0612 11:07:32.154433  5211 layer_factory.hpp:77] Creating layer Scale94
I0612 11:07:32.154583  5211 net.cpp:240] Setting up Scale94
I0612 11:07:32.154592  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.154599  5211 net.cpp:255] Memory required for data: 2792883712
I0612 11:07:32.154610  5211 layer_factory.hpp:77] Creating layer ReLU94
I0612 11:07:32.154631  5211 net.cpp:190] Creating Layer ReLU94
I0612 11:07:32.154636  5211 net.cpp:615] ReLU94 <- Convolution94
I0612 11:07:32.154645  5211 net.cpp:576] ReLU94 -> Convolution94 (in-place)
I0612 11:07:32.154654  5211 net.cpp:240] Setting up ReLU94
I0612 11:07:32.154660  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.154664  5211 net.cpp:255] Memory required for data: 2794980864
I0612 11:07:32.154669  5211 layer_factory.hpp:77] Creating layer Convolution95
I0612 11:07:32.154690  5211 net.cpp:190] Creating Layer Convolution95
I0612 11:07:32.154695  5211 net.cpp:615] Convolution95 <- Convolution94
I0612 11:07:32.154703  5211 net.cpp:589] Convolution95 -> Convolution95
I0612 11:07:32.156636  5211 net.cpp:240] Setting up Convolution95
I0612 11:07:32.156647  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.156651  5211 net.cpp:255] Memory required for data: 2797078016
I0612 11:07:32.156662  5211 layer_factory.hpp:77] Creating layer BatchNorm95
I0612 11:07:32.156680  5211 net.cpp:190] Creating Layer BatchNorm95
I0612 11:07:32.156687  5211 net.cpp:615] BatchNorm95 <- Convolution95
I0612 11:07:32.156695  5211 net.cpp:576] BatchNorm95 -> Convolution95 (in-place)
I0612 11:07:32.156944  5211 net.cpp:240] Setting up BatchNorm95
I0612 11:07:32.156952  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.156956  5211 net.cpp:255] Memory required for data: 2799175168
I0612 11:07:32.156973  5211 layer_factory.hpp:77] Creating layer Scale95
I0612 11:07:32.156983  5211 net.cpp:190] Creating Layer Scale95
I0612 11:07:32.156990  5211 net.cpp:615] Scale95 <- Convolution95
I0612 11:07:32.156996  5211 net.cpp:576] Scale95 -> Convolution95 (in-place)
I0612 11:07:32.157038  5211 layer_factory.hpp:77] Creating layer Scale95
I0612 11:07:32.157187  5211 net.cpp:240] Setting up Scale95
I0612 11:07:32.157196  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.157199  5211 net.cpp:255] Memory required for data: 2801272320
I0612 11:07:32.157209  5211 layer_factory.hpp:77] Creating layer Eltwise47
I0612 11:07:32.157228  5211 net.cpp:190] Creating Layer Eltwise47
I0612 11:07:32.157271  5211 net.cpp:615] Eltwise47 <- Eltwise46_ReLU93_0_split_1
I0612 11:07:32.157281  5211 net.cpp:615] Eltwise47 <- Convolution95
I0612 11:07:32.157289  5211 net.cpp:589] Eltwise47 -> Eltwise47
I0612 11:07:32.157315  5211 net.cpp:240] Setting up Eltwise47
I0612 11:07:32.157325  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.157328  5211 net.cpp:255] Memory required for data: 2803369472
I0612 11:07:32.157332  5211 layer_factory.hpp:77] Creating layer ReLU95
I0612 11:07:32.157344  5211 net.cpp:190] Creating Layer ReLU95
I0612 11:07:32.157349  5211 net.cpp:615] ReLU95 <- Eltwise47
I0612 11:07:32.157356  5211 net.cpp:576] ReLU95 -> Eltwise47 (in-place)
I0612 11:07:32.157362  5211 net.cpp:240] Setting up ReLU95
I0612 11:07:32.157368  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.157372  5211 net.cpp:255] Memory required for data: 2805466624
I0612 11:07:32.157377  5211 layer_factory.hpp:77] Creating layer Eltwise47_ReLU95_0_split
I0612 11:07:32.157383  5211 net.cpp:190] Creating Layer Eltwise47_ReLU95_0_split
I0612 11:07:32.157387  5211 net.cpp:615] Eltwise47_ReLU95_0_split <- Eltwise47
I0612 11:07:32.157395  5211 net.cpp:589] Eltwise47_ReLU95_0_split -> Eltwise47_ReLU95_0_split_0
I0612 11:07:32.157413  5211 net.cpp:589] Eltwise47_ReLU95_0_split -> Eltwise47_ReLU95_0_split_1
I0612 11:07:32.157459  5211 net.cpp:240] Setting up Eltwise47_ReLU95_0_split
I0612 11:07:32.157469  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.157474  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.157479  5211 net.cpp:255] Memory required for data: 2809660928
I0612 11:07:32.157488  5211 layer_factory.hpp:77] Creating layer Convolution96
I0612 11:07:32.157503  5211 net.cpp:190] Creating Layer Convolution96
I0612 11:07:32.157511  5211 net.cpp:615] Convolution96 <- Eltwise47_ReLU95_0_split_0
I0612 11:07:32.157521  5211 net.cpp:589] Convolution96 -> Convolution96
I0612 11:07:32.159346  5211 net.cpp:240] Setting up Convolution96
I0612 11:07:32.159358  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.159361  5211 net.cpp:255] Memory required for data: 2811758080
I0612 11:07:32.159374  5211 layer_factory.hpp:77] Creating layer BatchNorm96
I0612 11:07:32.159394  5211 net.cpp:190] Creating Layer BatchNorm96
I0612 11:07:32.159400  5211 net.cpp:615] BatchNorm96 <- Convolution96
I0612 11:07:32.159406  5211 net.cpp:576] BatchNorm96 -> Convolution96 (in-place)
I0612 11:07:32.159641  5211 net.cpp:240] Setting up BatchNorm96
I0612 11:07:32.159649  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.159653  5211 net.cpp:255] Memory required for data: 2813855232
I0612 11:07:32.159665  5211 layer_factory.hpp:77] Creating layer Scale96
I0612 11:07:32.159672  5211 net.cpp:190] Creating Layer Scale96
I0612 11:07:32.159677  5211 net.cpp:615] Scale96 <- Convolution96
I0612 11:07:32.159683  5211 net.cpp:576] Scale96 -> Convolution96 (in-place)
I0612 11:07:32.159729  5211 layer_factory.hpp:77] Creating layer Scale96
I0612 11:07:32.159871  5211 net.cpp:240] Setting up Scale96
I0612 11:07:32.159881  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.159885  5211 net.cpp:255] Memory required for data: 2815952384
I0612 11:07:32.159895  5211 layer_factory.hpp:77] Creating layer ReLU96
I0612 11:07:32.159910  5211 net.cpp:190] Creating Layer ReLU96
I0612 11:07:32.159915  5211 net.cpp:615] ReLU96 <- Convolution96
I0612 11:07:32.159921  5211 net.cpp:576] ReLU96 -> Convolution96 (in-place)
I0612 11:07:32.159929  5211 net.cpp:240] Setting up ReLU96
I0612 11:07:32.159934  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.159939  5211 net.cpp:255] Memory required for data: 2818049536
I0612 11:07:32.159942  5211 layer_factory.hpp:77] Creating layer Convolution97
I0612 11:07:32.159967  5211 net.cpp:190] Creating Layer Convolution97
I0612 11:07:32.159972  5211 net.cpp:615] Convolution97 <- Convolution96
I0612 11:07:32.159983  5211 net.cpp:589] Convolution97 -> Convolution97
I0612 11:07:32.161824  5211 net.cpp:240] Setting up Convolution97
I0612 11:07:32.161837  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.161842  5211 net.cpp:255] Memory required for data: 2820146688
I0612 11:07:32.161852  5211 layer_factory.hpp:77] Creating layer BatchNorm97
I0612 11:07:32.161872  5211 net.cpp:190] Creating Layer BatchNorm97
I0612 11:07:32.161878  5211 net.cpp:615] BatchNorm97 <- Convolution97
I0612 11:07:32.161886  5211 net.cpp:576] BatchNorm97 -> Convolution97 (in-place)
I0612 11:07:32.162127  5211 net.cpp:240] Setting up BatchNorm97
I0612 11:07:32.162135  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.162139  5211 net.cpp:255] Memory required for data: 2822243840
I0612 11:07:32.162153  5211 layer_factory.hpp:77] Creating layer Scale97
I0612 11:07:32.162161  5211 net.cpp:190] Creating Layer Scale97
I0612 11:07:32.162166  5211 net.cpp:615] Scale97 <- Convolution97
I0612 11:07:32.162173  5211 net.cpp:576] Scale97 -> Convolution97 (in-place)
I0612 11:07:32.162216  5211 layer_factory.hpp:77] Creating layer Scale97
I0612 11:07:32.162363  5211 net.cpp:240] Setting up Scale97
I0612 11:07:32.162371  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.162375  5211 net.cpp:255] Memory required for data: 2824340992
I0612 11:07:32.162386  5211 layer_factory.hpp:77] Creating layer Eltwise48
I0612 11:07:32.162405  5211 net.cpp:190] Creating Layer Eltwise48
I0612 11:07:32.162410  5211 net.cpp:615] Eltwise48 <- Eltwise47_ReLU95_0_split_1
I0612 11:07:32.162416  5211 net.cpp:615] Eltwise48 <- Convolution97
I0612 11:07:32.162425  5211 net.cpp:589] Eltwise48 -> Eltwise48
I0612 11:07:32.162454  5211 net.cpp:240] Setting up Eltwise48
I0612 11:07:32.162461  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.162466  5211 net.cpp:255] Memory required for data: 2826438144
I0612 11:07:32.162473  5211 layer_factory.hpp:77] Creating layer ReLU97
I0612 11:07:32.162487  5211 net.cpp:190] Creating Layer ReLU97
I0612 11:07:32.162492  5211 net.cpp:615] ReLU97 <- Eltwise48
I0612 11:07:32.162500  5211 net.cpp:576] ReLU97 -> Eltwise48 (in-place)
I0612 11:07:32.162508  5211 net.cpp:240] Setting up ReLU97
I0612 11:07:32.162513  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.162518  5211 net.cpp:255] Memory required for data: 2828535296
I0612 11:07:32.162521  5211 layer_factory.hpp:77] Creating layer Eltwise48_ReLU97_0_split
I0612 11:07:32.162531  5211 net.cpp:190] Creating Layer Eltwise48_ReLU97_0_split
I0612 11:07:32.162536  5211 net.cpp:615] Eltwise48_ReLU97_0_split <- Eltwise48
I0612 11:07:32.162542  5211 net.cpp:589] Eltwise48_ReLU97_0_split -> Eltwise48_ReLU97_0_split_0
I0612 11:07:32.162550  5211 net.cpp:589] Eltwise48_ReLU97_0_split -> Eltwise48_ReLU97_0_split_1
I0612 11:07:32.162595  5211 net.cpp:240] Setting up Eltwise48_ReLU97_0_split
I0612 11:07:32.162602  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.162607  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.162611  5211 net.cpp:255] Memory required for data: 2832729600
I0612 11:07:32.162616  5211 layer_factory.hpp:77] Creating layer Convolution98
I0612 11:07:32.162636  5211 net.cpp:190] Creating Layer Convolution98
I0612 11:07:32.162642  5211 net.cpp:615] Convolution98 <- Eltwise48_ReLU97_0_split_0
I0612 11:07:32.162650  5211 net.cpp:589] Convolution98 -> Convolution98
I0612 11:07:32.164410  5211 net.cpp:240] Setting up Convolution98
I0612 11:07:32.164419  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.164424  5211 net.cpp:255] Memory required for data: 2834826752
I0612 11:07:32.164433  5211 layer_factory.hpp:77] Creating layer BatchNorm98
I0612 11:07:32.164450  5211 net.cpp:190] Creating Layer BatchNorm98
I0612 11:07:32.164455  5211 net.cpp:615] BatchNorm98 <- Convolution98
I0612 11:07:32.164464  5211 net.cpp:576] BatchNorm98 -> Convolution98 (in-place)
I0612 11:07:32.164702  5211 net.cpp:240] Setting up BatchNorm98
I0612 11:07:32.164710  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.164715  5211 net.cpp:255] Memory required for data: 2836923904
I0612 11:07:32.164727  5211 layer_factory.hpp:77] Creating layer Scale98
I0612 11:07:32.164736  5211 net.cpp:190] Creating Layer Scale98
I0612 11:07:32.164741  5211 net.cpp:615] Scale98 <- Convolution98
I0612 11:07:32.164746  5211 net.cpp:576] Scale98 -> Convolution98 (in-place)
I0612 11:07:32.164788  5211 layer_factory.hpp:77] Creating layer Scale98
I0612 11:07:32.164929  5211 net.cpp:240] Setting up Scale98
I0612 11:07:32.164937  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.164940  5211 net.cpp:255] Memory required for data: 2839021056
I0612 11:07:32.164952  5211 layer_factory.hpp:77] Creating layer ReLU98
I0612 11:07:32.164958  5211 net.cpp:190] Creating Layer ReLU98
I0612 11:07:32.164963  5211 net.cpp:615] ReLU98 <- Convolution98
I0612 11:07:32.164970  5211 net.cpp:576] ReLU98 -> Convolution98 (in-place)
I0612 11:07:32.164978  5211 net.cpp:240] Setting up ReLU98
I0612 11:07:32.164984  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.164988  5211 net.cpp:255] Memory required for data: 2841118208
I0612 11:07:32.164993  5211 layer_factory.hpp:77] Creating layer Convolution99
I0612 11:07:32.165024  5211 net.cpp:190] Creating Layer Convolution99
I0612 11:07:32.165029  5211 net.cpp:615] Convolution99 <- Convolution98
I0612 11:07:32.165035  5211 net.cpp:589] Convolution99 -> Convolution99
I0612 11:07:32.166796  5211 net.cpp:240] Setting up Convolution99
I0612 11:07:32.166807  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.166811  5211 net.cpp:255] Memory required for data: 2843215360
I0612 11:07:32.166821  5211 layer_factory.hpp:77] Creating layer BatchNorm99
I0612 11:07:32.166836  5211 net.cpp:190] Creating Layer BatchNorm99
I0612 11:07:32.166841  5211 net.cpp:615] BatchNorm99 <- Convolution99
I0612 11:07:32.166847  5211 net.cpp:576] BatchNorm99 -> Convolution99 (in-place)
I0612 11:07:32.167093  5211 net.cpp:240] Setting up BatchNorm99
I0612 11:07:32.167100  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.167104  5211 net.cpp:255] Memory required for data: 2845312512
I0612 11:07:32.167116  5211 layer_factory.hpp:77] Creating layer Scale99
I0612 11:07:32.167129  5211 net.cpp:190] Creating Layer Scale99
I0612 11:07:32.167135  5211 net.cpp:615] Scale99 <- Convolution99
I0612 11:07:32.167140  5211 net.cpp:576] Scale99 -> Convolution99 (in-place)
I0612 11:07:32.167186  5211 layer_factory.hpp:77] Creating layer Scale99
I0612 11:07:32.167327  5211 net.cpp:240] Setting up Scale99
I0612 11:07:32.167335  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.167340  5211 net.cpp:255] Memory required for data: 2847409664
I0612 11:07:32.167349  5211 layer_factory.hpp:77] Creating layer Eltwise49
I0612 11:07:32.167367  5211 net.cpp:190] Creating Layer Eltwise49
I0612 11:07:32.167373  5211 net.cpp:615] Eltwise49 <- Eltwise48_ReLU97_0_split_1
I0612 11:07:32.167379  5211 net.cpp:615] Eltwise49 <- Convolution99
I0612 11:07:32.167387  5211 net.cpp:589] Eltwise49 -> Eltwise49
I0612 11:07:32.167409  5211 net.cpp:240] Setting up Eltwise49
I0612 11:07:32.167417  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.167420  5211 net.cpp:255] Memory required for data: 2849506816
I0612 11:07:32.167424  5211 layer_factory.hpp:77] Creating layer ReLU99
I0612 11:07:32.167433  5211 net.cpp:190] Creating Layer ReLU99
I0612 11:07:32.167438  5211 net.cpp:615] ReLU99 <- Eltwise49
I0612 11:07:32.167443  5211 net.cpp:576] ReLU99 -> Eltwise49 (in-place)
I0612 11:07:32.167453  5211 net.cpp:240] Setting up ReLU99
I0612 11:07:32.167459  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.167462  5211 net.cpp:255] Memory required for data: 2851603968
I0612 11:07:32.167466  5211 layer_factory.hpp:77] Creating layer Eltwise49_ReLU99_0_split
I0612 11:07:32.167472  5211 net.cpp:190] Creating Layer Eltwise49_ReLU99_0_split
I0612 11:07:32.167476  5211 net.cpp:615] Eltwise49_ReLU99_0_split <- Eltwise49
I0612 11:07:32.167482  5211 net.cpp:589] Eltwise49_ReLU99_0_split -> Eltwise49_ReLU99_0_split_0
I0612 11:07:32.168222  5211 net.cpp:589] Eltwise49_ReLU99_0_split -> Eltwise49_ReLU99_0_split_1
I0612 11:07:32.168278  5211 net.cpp:240] Setting up Eltwise49_ReLU99_0_split
I0612 11:07:32.168288  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.168293  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.168298  5211 net.cpp:255] Memory required for data: 2855798272
I0612 11:07:32.168306  5211 layer_factory.hpp:77] Creating layer Convolution100
I0612 11:07:32.168323  5211 net.cpp:190] Creating Layer Convolution100
I0612 11:07:32.168329  5211 net.cpp:615] Convolution100 <- Eltwise49_ReLU99_0_split_0
I0612 11:07:32.168339  5211 net.cpp:589] Convolution100 -> Convolution100
I0612 11:07:32.170100  5211 net.cpp:240] Setting up Convolution100
I0612 11:07:32.170110  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.170114  5211 net.cpp:255] Memory required for data: 2857895424
I0612 11:07:32.170131  5211 layer_factory.hpp:77] Creating layer BatchNorm100
I0612 11:07:32.170153  5211 net.cpp:190] Creating Layer BatchNorm100
I0612 11:07:32.170159  5211 net.cpp:615] BatchNorm100 <- Convolution100
I0612 11:07:32.170166  5211 net.cpp:576] BatchNorm100 -> Convolution100 (in-place)
I0612 11:07:32.170416  5211 net.cpp:240] Setting up BatchNorm100
I0612 11:07:32.170425  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.170429  5211 net.cpp:255] Memory required for data: 2859992576
I0612 11:07:32.170441  5211 layer_factory.hpp:77] Creating layer Scale100
I0612 11:07:32.170464  5211 net.cpp:190] Creating Layer Scale100
I0612 11:07:32.170469  5211 net.cpp:615] Scale100 <- Convolution100
I0612 11:07:32.170480  5211 net.cpp:576] Scale100 -> Convolution100 (in-place)
I0612 11:07:32.170531  5211 layer_factory.hpp:77] Creating layer Scale100
I0612 11:07:32.170665  5211 net.cpp:240] Setting up Scale100
I0612 11:07:32.170671  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.170682  5211 net.cpp:255] Memory required for data: 2862089728
I0612 11:07:32.170692  5211 layer_factory.hpp:77] Creating layer ReLU100
I0612 11:07:32.170703  5211 net.cpp:190] Creating Layer ReLU100
I0612 11:07:32.170708  5211 net.cpp:615] ReLU100 <- Convolution100
I0612 11:07:32.170713  5211 net.cpp:576] ReLU100 -> Convolution100 (in-place)
I0612 11:07:32.170722  5211 net.cpp:240] Setting up ReLU100
I0612 11:07:32.170727  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.170730  5211 net.cpp:255] Memory required for data: 2864186880
I0612 11:07:32.170739  5211 layer_factory.hpp:77] Creating layer Convolution101
I0612 11:07:32.170759  5211 net.cpp:190] Creating Layer Convolution101
I0612 11:07:32.170763  5211 net.cpp:615] Convolution101 <- Convolution100
I0612 11:07:32.170770  5211 net.cpp:589] Convolution101 -> Convolution101
I0612 11:07:32.173344  5211 net.cpp:240] Setting up Convolution101
I0612 11:07:32.173360  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.173364  5211 net.cpp:255] Memory required for data: 2866284032
I0612 11:07:32.173375  5211 layer_factory.hpp:77] Creating layer BatchNorm101
I0612 11:07:32.173385  5211 net.cpp:190] Creating Layer BatchNorm101
I0612 11:07:32.173390  5211 net.cpp:615] BatchNorm101 <- Convolution101
I0612 11:07:32.173398  5211 net.cpp:576] BatchNorm101 -> Convolution101 (in-place)
I0612 11:07:32.173624  5211 net.cpp:240] Setting up BatchNorm101
I0612 11:07:32.173632  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.173636  5211 net.cpp:255] Memory required for data: 2868381184
I0612 11:07:32.173650  5211 layer_factory.hpp:77] Creating layer Scale101
I0612 11:07:32.173667  5211 net.cpp:190] Creating Layer Scale101
I0612 11:07:32.173673  5211 net.cpp:615] Scale101 <- Convolution101
I0612 11:07:32.173679  5211 net.cpp:576] Scale101 -> Convolution101 (in-place)
I0612 11:07:32.173722  5211 layer_factory.hpp:77] Creating layer Scale101
I0612 11:07:32.173856  5211 net.cpp:240] Setting up Scale101
I0612 11:07:32.173864  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.173868  5211 net.cpp:255] Memory required for data: 2870478336
I0612 11:07:32.173882  5211 layer_factory.hpp:77] Creating layer Eltwise50
I0612 11:07:32.173897  5211 net.cpp:190] Creating Layer Eltwise50
I0612 11:07:32.173902  5211 net.cpp:615] Eltwise50 <- Eltwise49_ReLU99_0_split_1
I0612 11:07:32.173908  5211 net.cpp:615] Eltwise50 <- Convolution101
I0612 11:07:32.173914  5211 net.cpp:589] Eltwise50 -> Eltwise50
I0612 11:07:32.173939  5211 net.cpp:240] Setting up Eltwise50
I0612 11:07:32.173946  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.173950  5211 net.cpp:255] Memory required for data: 2872575488
I0612 11:07:32.173954  5211 layer_factory.hpp:77] Creating layer ReLU101
I0612 11:07:32.173959  5211 net.cpp:190] Creating Layer ReLU101
I0612 11:07:32.173964  5211 net.cpp:615] ReLU101 <- Eltwise50
I0612 11:07:32.173969  5211 net.cpp:576] ReLU101 -> Eltwise50 (in-place)
I0612 11:07:32.173976  5211 net.cpp:240] Setting up ReLU101
I0612 11:07:32.173981  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.173985  5211 net.cpp:255] Memory required for data: 2874672640
I0612 11:07:32.173990  5211 layer_factory.hpp:77] Creating layer Eltwise50_ReLU101_0_split
I0612 11:07:32.174834  5211 net.cpp:190] Creating Layer Eltwise50_ReLU101_0_split
I0612 11:07:32.174844  5211 net.cpp:615] Eltwise50_ReLU101_0_split <- Eltwise50
I0612 11:07:32.174850  5211 net.cpp:589] Eltwise50_ReLU101_0_split -> Eltwise50_ReLU101_0_split_0
I0612 11:07:32.174860  5211 net.cpp:589] Eltwise50_ReLU101_0_split -> Eltwise50_ReLU101_0_split_1
I0612 11:07:32.174909  5211 net.cpp:240] Setting up Eltwise50_ReLU101_0_split
I0612 11:07:32.174917  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.174922  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.174926  5211 net.cpp:255] Memory required for data: 2878866944
I0612 11:07:32.174931  5211 layer_factory.hpp:77] Creating layer Convolution102
I0612 11:07:32.174943  5211 net.cpp:190] Creating Layer Convolution102
I0612 11:07:32.174952  5211 net.cpp:615] Convolution102 <- Eltwise50_ReLU101_0_split_0
I0612 11:07:32.174959  5211 net.cpp:589] Convolution102 -> Convolution102
I0612 11:07:32.176653  5211 net.cpp:240] Setting up Convolution102
I0612 11:07:32.176667  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.176671  5211 net.cpp:255] Memory required for data: 2880964096
I0612 11:07:32.176681  5211 layer_factory.hpp:77] Creating layer BatchNorm102
I0612 11:07:32.176689  5211 net.cpp:190] Creating Layer BatchNorm102
I0612 11:07:32.176694  5211 net.cpp:615] BatchNorm102 <- Convolution102
I0612 11:07:32.176702  5211 net.cpp:576] BatchNorm102 -> Convolution102 (in-place)
I0612 11:07:32.176931  5211 net.cpp:240] Setting up BatchNorm102
I0612 11:07:32.176939  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.176942  5211 net.cpp:255] Memory required for data: 2883061248
I0612 11:07:32.176954  5211 layer_factory.hpp:77] Creating layer Scale102
I0612 11:07:32.176969  5211 net.cpp:190] Creating Layer Scale102
I0612 11:07:32.176973  5211 net.cpp:615] Scale102 <- Convolution102
I0612 11:07:32.176981  5211 net.cpp:576] Scale102 -> Convolution102 (in-place)
I0612 11:07:32.177023  5211 layer_factory.hpp:77] Creating layer Scale102
I0612 11:07:32.177165  5211 net.cpp:240] Setting up Scale102
I0612 11:07:32.177172  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.177176  5211 net.cpp:255] Memory required for data: 2885158400
I0612 11:07:32.177186  5211 layer_factory.hpp:77] Creating layer ReLU102
I0612 11:07:32.177194  5211 net.cpp:190] Creating Layer ReLU102
I0612 11:07:32.177198  5211 net.cpp:615] ReLU102 <- Convolution102
I0612 11:07:32.177204  5211 net.cpp:576] ReLU102 -> Convolution102 (in-place)
I0612 11:07:32.177211  5211 net.cpp:240] Setting up ReLU102
I0612 11:07:32.177217  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.177220  5211 net.cpp:255] Memory required for data: 2887255552
I0612 11:07:32.177229  5211 layer_factory.hpp:77] Creating layer Convolution103
I0612 11:07:32.177248  5211 net.cpp:190] Creating Layer Convolution103
I0612 11:07:32.177253  5211 net.cpp:615] Convolution103 <- Convolution102
I0612 11:07:32.177259  5211 net.cpp:589] Convolution103 -> Convolution103
I0612 11:07:32.178943  5211 net.cpp:240] Setting up Convolution103
I0612 11:07:32.178952  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.178956  5211 net.cpp:255] Memory required for data: 2889352704
I0612 11:07:32.178966  5211 layer_factory.hpp:77] Creating layer BatchNorm103
I0612 11:07:32.178975  5211 net.cpp:190] Creating Layer BatchNorm103
I0612 11:07:32.178980  5211 net.cpp:615] BatchNorm103 <- Convolution103
I0612 11:07:32.178989  5211 net.cpp:576] BatchNorm103 -> Convolution103 (in-place)
I0612 11:07:32.179214  5211 net.cpp:240] Setting up BatchNorm103
I0612 11:07:32.179221  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.179224  5211 net.cpp:255] Memory required for data: 2891449856
I0612 11:07:32.179239  5211 layer_factory.hpp:77] Creating layer Scale103
I0612 11:07:32.179246  5211 net.cpp:190] Creating Layer Scale103
I0612 11:07:32.179251  5211 net.cpp:615] Scale103 <- Convolution103
I0612 11:07:32.179257  5211 net.cpp:576] Scale103 -> Convolution103 (in-place)
I0612 11:07:32.179298  5211 layer_factory.hpp:77] Creating layer Scale103
I0612 11:07:32.179437  5211 net.cpp:240] Setting up Scale103
I0612 11:07:32.179445  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.179448  5211 net.cpp:255] Memory required for data: 2893547008
I0612 11:07:32.179458  5211 layer_factory.hpp:77] Creating layer Eltwise51
I0612 11:07:32.179471  5211 net.cpp:190] Creating Layer Eltwise51
I0612 11:07:32.179476  5211 net.cpp:615] Eltwise51 <- Eltwise50_ReLU101_0_split_1
I0612 11:07:32.179484  5211 net.cpp:615] Eltwise51 <- Convolution103
I0612 11:07:32.179491  5211 net.cpp:589] Eltwise51 -> Eltwise51
I0612 11:07:32.179513  5211 net.cpp:240] Setting up Eltwise51
I0612 11:07:32.179520  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.179529  5211 net.cpp:255] Memory required for data: 2895644160
I0612 11:07:32.179539  5211 layer_factory.hpp:77] Creating layer ReLU103
I0612 11:07:32.179548  5211 net.cpp:190] Creating Layer ReLU103
I0612 11:07:32.179553  5211 net.cpp:615] ReLU103 <- Eltwise51
I0612 11:07:32.179558  5211 net.cpp:576] ReLU103 -> Eltwise51 (in-place)
I0612 11:07:32.179565  5211 net.cpp:240] Setting up ReLU103
I0612 11:07:32.179570  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.179574  5211 net.cpp:255] Memory required for data: 2897741312
I0612 11:07:32.179577  5211 layer_factory.hpp:77] Creating layer Eltwise51_ReLU103_0_split
I0612 11:07:32.179582  5211 net.cpp:190] Creating Layer Eltwise51_ReLU103_0_split
I0612 11:07:32.179586  5211 net.cpp:615] Eltwise51_ReLU103_0_split <- Eltwise51
I0612 11:07:32.179592  5211 net.cpp:589] Eltwise51_ReLU103_0_split -> Eltwise51_ReLU103_0_split_0
I0612 11:07:32.179600  5211 net.cpp:589] Eltwise51_ReLU103_0_split -> Eltwise51_ReLU103_0_split_1
I0612 11:07:32.179642  5211 net.cpp:240] Setting up Eltwise51_ReLU103_0_split
I0612 11:07:32.179649  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.179654  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.179657  5211 net.cpp:255] Memory required for data: 2901935616
I0612 11:07:32.179661  5211 layer_factory.hpp:77] Creating layer Convolution104
I0612 11:07:32.179672  5211 net.cpp:190] Creating Layer Convolution104
I0612 11:07:32.179677  5211 net.cpp:615] Convolution104 <- Eltwise51_ReLU103_0_split_0
I0612 11:07:32.179685  5211 net.cpp:589] Convolution104 -> Convolution104
I0612 11:07:32.181368  5211 net.cpp:240] Setting up Convolution104
I0612 11:07:32.181377  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.181381  5211 net.cpp:255] Memory required for data: 2904032768
I0612 11:07:32.181391  5211 layer_factory.hpp:77] Creating layer BatchNorm104
I0612 11:07:32.181401  5211 net.cpp:190] Creating Layer BatchNorm104
I0612 11:07:32.181406  5211 net.cpp:615] BatchNorm104 <- Convolution104
I0612 11:07:32.181411  5211 net.cpp:576] BatchNorm104 -> Convolution104 (in-place)
I0612 11:07:32.181649  5211 net.cpp:240] Setting up BatchNorm104
I0612 11:07:32.181658  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.181660  5211 net.cpp:255] Memory required for data: 2906129920
I0612 11:07:32.181682  5211 layer_factory.hpp:77] Creating layer Scale104
I0612 11:07:32.181701  5211 net.cpp:190] Creating Layer Scale104
I0612 11:07:32.181706  5211 net.cpp:615] Scale104 <- Convolution104
I0612 11:07:32.181712  5211 net.cpp:576] Scale104 -> Convolution104 (in-place)
I0612 11:07:32.181754  5211 layer_factory.hpp:77] Creating layer Scale104
I0612 11:07:32.181891  5211 net.cpp:240] Setting up Scale104
I0612 11:07:32.181898  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.181902  5211 net.cpp:255] Memory required for data: 2908227072
I0612 11:07:32.181911  5211 layer_factory.hpp:77] Creating layer ReLU104
I0612 11:07:32.181921  5211 net.cpp:190] Creating Layer ReLU104
I0612 11:07:32.181926  5211 net.cpp:615] ReLU104 <- Convolution104
I0612 11:07:32.181932  5211 net.cpp:576] ReLU104 -> Convolution104 (in-place)
I0612 11:07:32.181939  5211 net.cpp:240] Setting up ReLU104
I0612 11:07:32.181944  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.181948  5211 net.cpp:255] Memory required for data: 2910324224
I0612 11:07:32.181951  5211 layer_factory.hpp:77] Creating layer Convolution105
I0612 11:07:32.181975  5211 net.cpp:190] Creating Layer Convolution105
I0612 11:07:32.181980  5211 net.cpp:615] Convolution105 <- Convolution104
I0612 11:07:32.181987  5211 net.cpp:589] Convolution105 -> Convolution105
I0612 11:07:32.183679  5211 net.cpp:240] Setting up Convolution105
I0612 11:07:32.183689  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.183693  5211 net.cpp:255] Memory required for data: 2912421376
I0612 11:07:32.183702  5211 layer_factory.hpp:77] Creating layer BatchNorm105
I0612 11:07:32.183712  5211 net.cpp:190] Creating Layer BatchNorm105
I0612 11:07:32.183719  5211 net.cpp:615] BatchNorm105 <- Convolution105
I0612 11:07:32.183730  5211 net.cpp:576] BatchNorm105 -> Convolution105 (in-place)
I0612 11:07:32.183966  5211 net.cpp:240] Setting up BatchNorm105
I0612 11:07:32.183974  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.183979  5211 net.cpp:255] Memory required for data: 2914518528
I0612 11:07:32.183996  5211 layer_factory.hpp:77] Creating layer Scale105
I0612 11:07:32.184011  5211 net.cpp:190] Creating Layer Scale105
I0612 11:07:32.184016  5211 net.cpp:615] Scale105 <- Convolution105
I0612 11:07:32.184022  5211 net.cpp:576] Scale105 -> Convolution105 (in-place)
I0612 11:07:32.184068  5211 layer_factory.hpp:77] Creating layer Scale105
I0612 11:07:32.184204  5211 net.cpp:240] Setting up Scale105
I0612 11:07:32.184213  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.184217  5211 net.cpp:255] Memory required for data: 2916615680
I0612 11:07:32.184227  5211 layer_factory.hpp:77] Creating layer Eltwise52
I0612 11:07:32.184238  5211 net.cpp:190] Creating Layer Eltwise52
I0612 11:07:32.184244  5211 net.cpp:615] Eltwise52 <- Eltwise51_ReLU103_0_split_1
I0612 11:07:32.184250  5211 net.cpp:615] Eltwise52 <- Convolution105
I0612 11:07:32.184257  5211 net.cpp:589] Eltwise52 -> Eltwise52
I0612 11:07:32.184283  5211 net.cpp:240] Setting up Eltwise52
I0612 11:07:32.184289  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.184293  5211 net.cpp:255] Memory required for data: 2918712832
I0612 11:07:32.184298  5211 layer_factory.hpp:77] Creating layer ReLU105
I0612 11:07:32.184303  5211 net.cpp:190] Creating Layer ReLU105
I0612 11:07:32.184306  5211 net.cpp:615] ReLU105 <- Eltwise52
I0612 11:07:32.184314  5211 net.cpp:576] ReLU105 -> Eltwise52 (in-place)
I0612 11:07:32.184321  5211 net.cpp:240] Setting up ReLU105
I0612 11:07:32.184326  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.184330  5211 net.cpp:255] Memory required for data: 2920809984
I0612 11:07:32.184334  5211 layer_factory.hpp:77] Creating layer Eltwise52_ReLU105_0_split
I0612 11:07:32.184340  5211 net.cpp:190] Creating Layer Eltwise52_ReLU105_0_split
I0612 11:07:32.184342  5211 net.cpp:615] Eltwise52_ReLU105_0_split <- Eltwise52
I0612 11:07:32.184348  5211 net.cpp:589] Eltwise52_ReLU105_0_split -> Eltwise52_ReLU105_0_split_0
I0612 11:07:32.184355  5211 net.cpp:589] Eltwise52_ReLU105_0_split -> Eltwise52_ReLU105_0_split_1
I0612 11:07:32.184397  5211 net.cpp:240] Setting up Eltwise52_ReLU105_0_split
I0612 11:07:32.184403  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.184408  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.184412  5211 net.cpp:255] Memory required for data: 2925004288
I0612 11:07:32.184420  5211 layer_factory.hpp:77] Creating layer Convolution106
I0612 11:07:32.184439  5211 net.cpp:190] Creating Layer Convolution106
I0612 11:07:32.184444  5211 net.cpp:615] Convolution106 <- Eltwise52_ReLU105_0_split_0
I0612 11:07:32.184453  5211 net.cpp:589] Convolution106 -> Convolution106
I0612 11:07:32.186142  5211 net.cpp:240] Setting up Convolution106
I0612 11:07:32.186151  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.186156  5211 net.cpp:255] Memory required for data: 2927101440
I0612 11:07:32.186164  5211 layer_factory.hpp:77] Creating layer BatchNorm106
I0612 11:07:32.186184  5211 net.cpp:190] Creating Layer BatchNorm106
I0612 11:07:32.186190  5211 net.cpp:615] BatchNorm106 <- Convolution106
I0612 11:07:32.186197  5211 net.cpp:576] BatchNorm106 -> Convolution106 (in-place)
I0612 11:07:32.186431  5211 net.cpp:240] Setting up BatchNorm106
I0612 11:07:32.186439  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.186444  5211 net.cpp:255] Memory required for data: 2929198592
I0612 11:07:32.186456  5211 layer_factory.hpp:77] Creating layer Scale106
I0612 11:07:32.186471  5211 net.cpp:190] Creating Layer Scale106
I0612 11:07:32.186476  5211 net.cpp:615] Scale106 <- Convolution106
I0612 11:07:32.186482  5211 net.cpp:576] Scale106 -> Convolution106 (in-place)
I0612 11:07:32.186527  5211 layer_factory.hpp:77] Creating layer Scale106
I0612 11:07:32.186668  5211 net.cpp:240] Setting up Scale106
I0612 11:07:32.186676  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.186679  5211 net.cpp:255] Memory required for data: 2931295744
I0612 11:07:32.186689  5211 layer_factory.hpp:77] Creating layer ReLU106
I0612 11:07:32.186697  5211 net.cpp:190] Creating Layer ReLU106
I0612 11:07:32.186702  5211 net.cpp:615] ReLU106 <- Convolution106
I0612 11:07:32.186709  5211 net.cpp:576] ReLU106 -> Convolution106 (in-place)
I0612 11:07:32.186717  5211 net.cpp:240] Setting up ReLU106
I0612 11:07:32.186722  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.186725  5211 net.cpp:255] Memory required for data: 2933392896
I0612 11:07:32.186734  5211 layer_factory.hpp:77] Creating layer Convolution107
I0612 11:07:32.186748  5211 net.cpp:190] Creating Layer Convolution107
I0612 11:07:32.186753  5211 net.cpp:615] Convolution107 <- Convolution106
I0612 11:07:32.186763  5211 net.cpp:589] Convolution107 -> Convolution107
I0612 11:07:32.188443  5211 net.cpp:240] Setting up Convolution107
I0612 11:07:32.188453  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.188457  5211 net.cpp:255] Memory required for data: 2935490048
I0612 11:07:32.188467  5211 layer_factory.hpp:77] Creating layer BatchNorm107
I0612 11:07:32.188482  5211 net.cpp:190] Creating Layer BatchNorm107
I0612 11:07:32.188486  5211 net.cpp:615] BatchNorm107 <- Convolution107
I0612 11:07:32.188494  5211 net.cpp:576] BatchNorm107 -> Convolution107 (in-place)
I0612 11:07:32.188726  5211 net.cpp:240] Setting up BatchNorm107
I0612 11:07:32.188735  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.188738  5211 net.cpp:255] Memory required for data: 2937587200
I0612 11:07:32.188750  5211 layer_factory.hpp:77] Creating layer Scale107
I0612 11:07:32.188758  5211 net.cpp:190] Creating Layer Scale107
I0612 11:07:32.188762  5211 net.cpp:615] Scale107 <- Convolution107
I0612 11:07:32.188771  5211 net.cpp:576] Scale107 -> Convolution107 (in-place)
I0612 11:07:32.188812  5211 layer_factory.hpp:77] Creating layer Scale107
I0612 11:07:32.188949  5211 net.cpp:240] Setting up Scale107
I0612 11:07:32.188957  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.188961  5211 net.cpp:255] Memory required for data: 2939684352
I0612 11:07:32.188971  5211 layer_factory.hpp:77] Creating layer Eltwise53
I0612 11:07:32.188982  5211 net.cpp:190] Creating Layer Eltwise53
I0612 11:07:32.188987  5211 net.cpp:615] Eltwise53 <- Eltwise52_ReLU105_0_split_1
I0612 11:07:32.188995  5211 net.cpp:615] Eltwise53 <- Convolution107
I0612 11:07:32.189002  5211 net.cpp:589] Eltwise53 -> Eltwise53
I0612 11:07:32.189023  5211 net.cpp:240] Setting up Eltwise53
I0612 11:07:32.189033  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.189036  5211 net.cpp:255] Memory required for data: 2941781504
I0612 11:07:32.189040  5211 layer_factory.hpp:77] Creating layer ReLU107
I0612 11:07:32.189045  5211 net.cpp:190] Creating Layer ReLU107
I0612 11:07:32.189050  5211 net.cpp:615] ReLU107 <- Eltwise53
I0612 11:07:32.189055  5211 net.cpp:576] ReLU107 -> Eltwise53 (in-place)
I0612 11:07:32.189061  5211 net.cpp:240] Setting up ReLU107
I0612 11:07:32.189067  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.189070  5211 net.cpp:255] Memory required for data: 2943878656
I0612 11:07:32.189074  5211 layer_factory.hpp:77] Creating layer Eltwise53_ReLU107_0_split
I0612 11:07:32.189079  5211 net.cpp:190] Creating Layer Eltwise53_ReLU107_0_split
I0612 11:07:32.189083  5211 net.cpp:615] Eltwise53_ReLU107_0_split <- Eltwise53
I0612 11:07:32.189090  5211 net.cpp:589] Eltwise53_ReLU107_0_split -> Eltwise53_ReLU107_0_split_0
I0612 11:07:32.189098  5211 net.cpp:589] Eltwise53_ReLU107_0_split -> Eltwise53_ReLU107_0_split_1
I0612 11:07:32.189137  5211 net.cpp:240] Setting up Eltwise53_ReLU107_0_split
I0612 11:07:32.189143  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.189148  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.189152  5211 net.cpp:255] Memory required for data: 2948072960
I0612 11:07:32.189158  5211 layer_factory.hpp:77] Creating layer Convolution108
I0612 11:07:32.189177  5211 net.cpp:190] Creating Layer Convolution108
I0612 11:07:32.189182  5211 net.cpp:615] Convolution108 <- Eltwise53_ReLU107_0_split_0
I0612 11:07:32.189190  5211 net.cpp:589] Convolution108 -> Convolution108
I0612 11:07:32.191512  5211 net.cpp:240] Setting up Convolution108
I0612 11:07:32.191527  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.191531  5211 net.cpp:255] Memory required for data: 2950170112
I0612 11:07:32.191548  5211 layer_factory.hpp:77] Creating layer BatchNorm108
I0612 11:07:32.191560  5211 net.cpp:190] Creating Layer BatchNorm108
I0612 11:07:32.191565  5211 net.cpp:615] BatchNorm108 <- Convolution108
I0612 11:07:32.191571  5211 net.cpp:576] BatchNorm108 -> Convolution108 (in-place)
I0612 11:07:32.191807  5211 net.cpp:240] Setting up BatchNorm108
I0612 11:07:32.191814  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.191818  5211 net.cpp:255] Memory required for data: 2952267264
I0612 11:07:32.191829  5211 layer_factory.hpp:77] Creating layer Scale108
I0612 11:07:32.191840  5211 net.cpp:190] Creating Layer Scale108
I0612 11:07:32.191845  5211 net.cpp:615] Scale108 <- Convolution108
I0612 11:07:32.191851  5211 net.cpp:576] Scale108 -> Convolution108 (in-place)
I0612 11:07:32.191895  5211 layer_factory.hpp:77] Creating layer Scale108
I0612 11:07:32.192034  5211 net.cpp:240] Setting up Scale108
I0612 11:07:32.192042  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.192046  5211 net.cpp:255] Memory required for data: 2954364416
I0612 11:07:32.192056  5211 layer_factory.hpp:77] Creating layer ReLU108
I0612 11:07:32.192071  5211 net.cpp:190] Creating Layer ReLU108
I0612 11:07:32.192076  5211 net.cpp:615] ReLU108 <- Convolution108
I0612 11:07:32.192082  5211 net.cpp:576] ReLU108 -> Convolution108 (in-place)
I0612 11:07:32.192090  5211 net.cpp:240] Setting up ReLU108
I0612 11:07:32.192095  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.192100  5211 net.cpp:255] Memory required for data: 2956461568
I0612 11:07:32.192102  5211 layer_factory.hpp:77] Creating layer Convolution109
I0612 11:07:32.192116  5211 net.cpp:190] Creating Layer Convolution109
I0612 11:07:32.192121  5211 net.cpp:615] Convolution109 <- Convolution108
I0612 11:07:32.192128  5211 net.cpp:589] Convolution109 -> Convolution109
I0612 11:07:32.193814  5211 net.cpp:240] Setting up Convolution109
I0612 11:07:32.193822  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.193826  5211 net.cpp:255] Memory required for data: 2958558720
I0612 11:07:32.193835  5211 layer_factory.hpp:77] Creating layer BatchNorm109
I0612 11:07:32.193851  5211 net.cpp:190] Creating Layer BatchNorm109
I0612 11:07:32.193856  5211 net.cpp:615] BatchNorm109 <- Convolution109
I0612 11:07:32.193862  5211 net.cpp:576] BatchNorm109 -> Convolution109 (in-place)
I0612 11:07:32.194100  5211 net.cpp:240] Setting up BatchNorm109
I0612 11:07:32.194108  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.194113  5211 net.cpp:255] Memory required for data: 2960655872
I0612 11:07:32.194128  5211 layer_factory.hpp:77] Creating layer Scale109
I0612 11:07:32.194135  5211 net.cpp:190] Creating Layer Scale109
I0612 11:07:32.194139  5211 net.cpp:615] Scale109 <- Convolution109
I0612 11:07:32.194145  5211 net.cpp:576] Scale109 -> Convolution109 (in-place)
I0612 11:07:32.194190  5211 layer_factory.hpp:77] Creating layer Scale109
I0612 11:07:32.194324  5211 net.cpp:240] Setting up Scale109
I0612 11:07:32.194334  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.194337  5211 net.cpp:255] Memory required for data: 2962753024
I0612 11:07:32.194346  5211 layer_factory.hpp:77] Creating layer Eltwise54
I0612 11:07:32.194360  5211 net.cpp:190] Creating Layer Eltwise54
I0612 11:07:32.194365  5211 net.cpp:615] Eltwise54 <- Eltwise53_ReLU107_0_split_1
I0612 11:07:32.194371  5211 net.cpp:615] Eltwise54 <- Convolution109
I0612 11:07:32.194377  5211 net.cpp:589] Eltwise54 -> Eltwise54
I0612 11:07:32.194413  5211 net.cpp:240] Setting up Eltwise54
I0612 11:07:32.194422  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.194425  5211 net.cpp:255] Memory required for data: 2964850176
I0612 11:07:32.194429  5211 layer_factory.hpp:77] Creating layer ReLU109
I0612 11:07:32.194435  5211 net.cpp:190] Creating Layer ReLU109
I0612 11:07:32.194439  5211 net.cpp:615] ReLU109 <- Eltwise54
I0612 11:07:32.194447  5211 net.cpp:576] ReLU109 -> Eltwise54 (in-place)
I0612 11:07:32.194454  5211 net.cpp:240] Setting up ReLU109
I0612 11:07:32.194460  5211 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:07:32.194463  5211 net.cpp:255] Memory required for data: 2966947328
I0612 11:07:32.194468  5211 layer_factory.hpp:77] Creating layer Pooling4
I0612 11:07:32.194473  5211 net.cpp:190] Creating Layer Pooling4
I0612 11:07:32.194478  5211 net.cpp:615] Pooling4 <- Eltwise54
I0612 11:07:32.194484  5211 net.cpp:589] Pooling4 -> Pooling4
I0612 11:07:32.194514  5211 net.cpp:240] Setting up Pooling4
I0612 11:07:32.194521  5211 net.cpp:247] Top shape: 128 64 1 1 (8192)
I0612 11:07:32.194525  5211 net.cpp:255] Memory required for data: 2966980096
I0612 11:07:32.194535  5211 layer_factory.hpp:77] Creating layer InnerProduct1
I0612 11:07:32.194551  5211 net.cpp:190] Creating Layer InnerProduct1
I0612 11:07:32.194555  5211 net.cpp:615] InnerProduct1 <- Pooling4
I0612 11:07:32.194561  5211 net.cpp:589] InnerProduct1 -> InnerProduct1
I0612 11:07:32.195051  5211 net.cpp:240] Setting up InnerProduct1
I0612 11:07:32.195061  5211 net.cpp:247] Top shape: 128 10 (1280)
I0612 11:07:32.195065  5211 net.cpp:255] Memory required for data: 2966985216
I0612 11:07:32.195075  5211 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0612 11:07:32.195082  5211 net.cpp:190] Creating Layer InnerProduct1_InnerProduct1_0_split
I0612 11:07:32.195087  5211 net.cpp:615] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0612 11:07:32.195096  5211 net.cpp:589] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0612 11:07:32.195104  5211 net.cpp:589] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0612 11:07:32.195142  5211 net.cpp:240] Setting up InnerProduct1_InnerProduct1_0_split
I0612 11:07:32.195148  5211 net.cpp:247] Top shape: 128 10 (1280)
I0612 11:07:32.195153  5211 net.cpp:247] Top shape: 128 10 (1280)
I0612 11:07:32.195158  5211 net.cpp:255] Memory required for data: 2966995456
I0612 11:07:32.195160  5211 layer_factory.hpp:77] Creating layer Accuracy
I0612 11:07:32.195170  5211 net.cpp:190] Creating Layer Accuracy
I0612 11:07:32.195174  5211 net.cpp:615] Accuracy <- InnerProduct1_InnerProduct1_0_split_0
I0612 11:07:32.195180  5211 net.cpp:615] Accuracy <- Data2_Data1_1_split_0
I0612 11:07:32.195193  5211 net.cpp:589] Accuracy -> Accuracy
I0612 11:07:32.195214  5211 net.cpp:240] Setting up Accuracy
I0612 11:07:32.195220  5211 net.cpp:247] Top shape: (1)
I0612 11:07:32.195224  5211 net.cpp:255] Memory required for data: 2966995460
I0612 11:07:32.195231  5211 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0612 11:07:32.195237  5211 net.cpp:190] Creating Layer SoftmaxWithLoss1
I0612 11:07:32.195242  5211 net.cpp:615] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_1
I0612 11:07:32.195251  5211 net.cpp:615] SoftmaxWithLoss1 <- Data2_Data1_1_split_1
I0612 11:07:32.195257  5211 net.cpp:589] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0612 11:07:32.195267  5211 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0612 11:07:32.195549  5211 net.cpp:240] Setting up SoftmaxWithLoss1
I0612 11:07:32.195559  5211 net.cpp:247] Top shape: (1)
I0612 11:07:32.195562  5211 net.cpp:250]     with loss weight 1
I0612 11:07:32.195574  5211 net.cpp:255] Memory required for data: 2966995464
I0612 11:07:32.195577  5211 net.cpp:316] SoftmaxWithLoss1 needs backward computation.
I0612 11:07:32.195582  5211 net.cpp:318] Accuracy does not need backward computation.
I0612 11:07:32.195586  5211 net.cpp:316] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0612 11:07:32.195595  5211 net.cpp:316] InnerProduct1 needs backward computation.
I0612 11:07:32.195598  5211 net.cpp:316] Pooling4 needs backward computation.
I0612 11:07:32.195602  5211 net.cpp:316] ReLU109 needs backward computation.
I0612 11:07:32.195606  5211 net.cpp:316] Eltwise54 needs backward computation.
I0612 11:07:32.195611  5211 net.cpp:316] Scale109 needs backward computation.
I0612 11:07:32.195614  5211 net.cpp:316] BatchNorm109 needs backward computation.
I0612 11:07:32.195618  5211 net.cpp:316] Convolution109 needs backward computation.
I0612 11:07:32.195622  5211 net.cpp:316] ReLU108 needs backward computation.
I0612 11:07:32.195626  5211 net.cpp:316] Scale108 needs backward computation.
I0612 11:07:32.195629  5211 net.cpp:316] BatchNorm108 needs backward computation.
I0612 11:07:32.195632  5211 net.cpp:316] Convolution108 needs backward computation.
I0612 11:07:32.195636  5211 net.cpp:316] Eltwise53_ReLU107_0_split needs backward computation.
I0612 11:07:32.195641  5211 net.cpp:316] ReLU107 needs backward computation.
I0612 11:07:32.195644  5211 net.cpp:316] Eltwise53 needs backward computation.
I0612 11:07:32.195649  5211 net.cpp:316] Scale107 needs backward computation.
I0612 11:07:32.195653  5211 net.cpp:316] BatchNorm107 needs backward computation.
I0612 11:07:32.195657  5211 net.cpp:316] Convolution107 needs backward computation.
I0612 11:07:32.195660  5211 net.cpp:316] ReLU106 needs backward computation.
I0612 11:07:32.195663  5211 net.cpp:316] Scale106 needs backward computation.
I0612 11:07:32.195667  5211 net.cpp:316] BatchNorm106 needs backward computation.
I0612 11:07:32.195670  5211 net.cpp:316] Convolution106 needs backward computation.
I0612 11:07:32.195675  5211 net.cpp:316] Eltwise52_ReLU105_0_split needs backward computation.
I0612 11:07:32.195679  5211 net.cpp:316] ReLU105 needs backward computation.
I0612 11:07:32.195683  5211 net.cpp:316] Eltwise52 needs backward computation.
I0612 11:07:32.195688  5211 net.cpp:316] Scale105 needs backward computation.
I0612 11:07:32.195691  5211 net.cpp:316] BatchNorm105 needs backward computation.
I0612 11:07:32.195694  5211 net.cpp:316] Convolution105 needs backward computation.
I0612 11:07:32.195698  5211 net.cpp:316] ReLU104 needs backward computation.
I0612 11:07:32.195703  5211 net.cpp:316] Scale104 needs backward computation.
I0612 11:07:32.195705  5211 net.cpp:316] BatchNorm104 needs backward computation.
I0612 11:07:32.195709  5211 net.cpp:316] Convolution104 needs backward computation.
I0612 11:07:32.195713  5211 net.cpp:316] Eltwise51_ReLU103_0_split needs backward computation.
I0612 11:07:32.195718  5211 net.cpp:316] ReLU103 needs backward computation.
I0612 11:07:32.195721  5211 net.cpp:316] Eltwise51 needs backward computation.
I0612 11:07:32.195725  5211 net.cpp:316] Scale103 needs backward computation.
I0612 11:07:32.195729  5211 net.cpp:316] BatchNorm103 needs backward computation.
I0612 11:07:32.195732  5211 net.cpp:316] Convolution103 needs backward computation.
I0612 11:07:32.195736  5211 net.cpp:316] ReLU102 needs backward computation.
I0612 11:07:32.195739  5211 net.cpp:316] Scale102 needs backward computation.
I0612 11:07:32.195744  5211 net.cpp:316] BatchNorm102 needs backward computation.
I0612 11:07:32.195747  5211 net.cpp:316] Convolution102 needs backward computation.
I0612 11:07:32.195751  5211 net.cpp:316] Eltwise50_ReLU101_0_split needs backward computation.
I0612 11:07:32.195755  5211 net.cpp:316] ReLU101 needs backward computation.
I0612 11:07:32.195758  5211 net.cpp:316] Eltwise50 needs backward computation.
I0612 11:07:32.195763  5211 net.cpp:316] Scale101 needs backward computation.
I0612 11:07:32.195766  5211 net.cpp:316] BatchNorm101 needs backward computation.
I0612 11:07:32.195770  5211 net.cpp:316] Convolution101 needs backward computation.
I0612 11:07:32.195775  5211 net.cpp:316] ReLU100 needs backward computation.
I0612 11:07:32.195777  5211 net.cpp:316] Scale100 needs backward computation.
I0612 11:07:32.195781  5211 net.cpp:316] BatchNorm100 needs backward computation.
I0612 11:07:32.195786  5211 net.cpp:316] Convolution100 needs backward computation.
I0612 11:07:32.195791  5211 net.cpp:316] Eltwise49_ReLU99_0_split needs backward computation.
I0612 11:07:32.195796  5211 net.cpp:316] ReLU99 needs backward computation.
I0612 11:07:32.195799  5211 net.cpp:316] Eltwise49 needs backward computation.
I0612 11:07:32.195804  5211 net.cpp:316] Scale99 needs backward computation.
I0612 11:07:32.195808  5211 net.cpp:316] BatchNorm99 needs backward computation.
I0612 11:07:32.195811  5211 net.cpp:316] Convolution99 needs backward computation.
I0612 11:07:32.195816  5211 net.cpp:316] ReLU98 needs backward computation.
I0612 11:07:32.195819  5211 net.cpp:316] Scale98 needs backward computation.
I0612 11:07:32.195823  5211 net.cpp:316] BatchNorm98 needs backward computation.
I0612 11:07:32.195827  5211 net.cpp:316] Convolution98 needs backward computation.
I0612 11:07:32.195830  5211 net.cpp:316] Eltwise48_ReLU97_0_split needs backward computation.
I0612 11:07:32.195835  5211 net.cpp:316] ReLU97 needs backward computation.
I0612 11:07:32.195838  5211 net.cpp:316] Eltwise48 needs backward computation.
I0612 11:07:32.195843  5211 net.cpp:316] Scale97 needs backward computation.
I0612 11:07:32.195847  5211 net.cpp:316] BatchNorm97 needs backward computation.
I0612 11:07:32.195850  5211 net.cpp:316] Convolution97 needs backward computation.
I0612 11:07:32.195854  5211 net.cpp:316] ReLU96 needs backward computation.
I0612 11:07:32.195858  5211 net.cpp:316] Scale96 needs backward computation.
I0612 11:07:32.195861  5211 net.cpp:316] BatchNorm96 needs backward computation.
I0612 11:07:32.195865  5211 net.cpp:316] Convolution96 needs backward computation.
I0612 11:07:32.195869  5211 net.cpp:316] Eltwise47_ReLU95_0_split needs backward computation.
I0612 11:07:32.195873  5211 net.cpp:316] ReLU95 needs backward computation.
I0612 11:07:32.195876  5211 net.cpp:316] Eltwise47 needs backward computation.
I0612 11:07:32.195880  5211 net.cpp:316] Scale95 needs backward computation.
I0612 11:07:32.195884  5211 net.cpp:316] BatchNorm95 needs backward computation.
I0612 11:07:32.195888  5211 net.cpp:316] Convolution95 needs backward computation.
I0612 11:07:32.195893  5211 net.cpp:316] ReLU94 needs backward computation.
I0612 11:07:32.195895  5211 net.cpp:316] Scale94 needs backward computation.
I0612 11:07:32.195899  5211 net.cpp:316] BatchNorm94 needs backward computation.
I0612 11:07:32.195902  5211 net.cpp:316] Convolution94 needs backward computation.
I0612 11:07:32.195906  5211 net.cpp:316] Eltwise46_ReLU93_0_split needs backward computation.
I0612 11:07:32.195914  5211 net.cpp:316] ReLU93 needs backward computation.
I0612 11:07:32.195917  5211 net.cpp:316] Eltwise46 needs backward computation.
I0612 11:07:32.195922  5211 net.cpp:316] Scale93 needs backward computation.
I0612 11:07:32.195925  5211 net.cpp:316] BatchNorm93 needs backward computation.
I0612 11:07:32.195930  5211 net.cpp:316] Convolution93 needs backward computation.
I0612 11:07:32.195933  5211 net.cpp:316] ReLU92 needs backward computation.
I0612 11:07:32.195937  5211 net.cpp:316] Scale92 needs backward computation.
I0612 11:07:32.195941  5211 net.cpp:316] BatchNorm92 needs backward computation.
I0612 11:07:32.195945  5211 net.cpp:316] Convolution92 needs backward computation.
I0612 11:07:32.195950  5211 net.cpp:316] Eltwise45_ReLU91_0_split needs backward computation.
I0612 11:07:32.195953  5211 net.cpp:316] ReLU91 needs backward computation.
I0612 11:07:32.195956  5211 net.cpp:316] Eltwise45 needs backward computation.
I0612 11:07:32.195961  5211 net.cpp:316] Scale91 needs backward computation.
I0612 11:07:32.195965  5211 net.cpp:316] BatchNorm91 needs backward computation.
I0612 11:07:32.195968  5211 net.cpp:316] Convolution91 needs backward computation.
I0612 11:07:32.195972  5211 net.cpp:316] ReLU90 needs backward computation.
I0612 11:07:32.195976  5211 net.cpp:316] Scale90 needs backward computation.
I0612 11:07:32.195981  5211 net.cpp:316] BatchNorm90 needs backward computation.
I0612 11:07:32.195983  5211 net.cpp:316] Convolution90 needs backward computation.
I0612 11:07:32.195992  5211 net.cpp:316] Eltwise44_ReLU89_0_split needs backward computation.
I0612 11:07:32.195996  5211 net.cpp:316] ReLU89 needs backward computation.
I0612 11:07:32.196001  5211 net.cpp:316] Eltwise44 needs backward computation.
I0612 11:07:32.196005  5211 net.cpp:316] Scale89 needs backward computation.
I0612 11:07:32.196010  5211 net.cpp:316] BatchNorm89 needs backward computation.
I0612 11:07:32.196013  5211 net.cpp:316] Convolution89 needs backward computation.
I0612 11:07:32.196017  5211 net.cpp:316] ReLU88 needs backward computation.
I0612 11:07:32.196022  5211 net.cpp:316] Scale88 needs backward computation.
I0612 11:07:32.196024  5211 net.cpp:316] BatchNorm88 needs backward computation.
I0612 11:07:32.196028  5211 net.cpp:316] Convolution88 needs backward computation.
I0612 11:07:32.196033  5211 net.cpp:316] Eltwise43_ReLU87_0_split needs backward computation.
I0612 11:07:32.196036  5211 net.cpp:316] ReLU87 needs backward computation.
I0612 11:07:32.196040  5211 net.cpp:316] Eltwise43 needs backward computation.
I0612 11:07:32.196045  5211 net.cpp:316] Scale87 needs backward computation.
I0612 11:07:32.196048  5211 net.cpp:316] BatchNorm87 needs backward computation.
I0612 11:07:32.196053  5211 net.cpp:316] Convolution87 needs backward computation.
I0612 11:07:32.196056  5211 net.cpp:316] ReLU86 needs backward computation.
I0612 11:07:32.196060  5211 net.cpp:316] Scale86 needs backward computation.
I0612 11:07:32.196064  5211 net.cpp:316] BatchNorm86 needs backward computation.
I0612 11:07:32.196069  5211 net.cpp:316] Convolution86 needs backward computation.
I0612 11:07:32.196072  5211 net.cpp:316] Eltwise42_ReLU85_0_split needs backward computation.
I0612 11:07:32.196076  5211 net.cpp:316] ReLU85 needs backward computation.
I0612 11:07:32.196079  5211 net.cpp:316] Eltwise42 needs backward computation.
I0612 11:07:32.196084  5211 net.cpp:316] Scale85 needs backward computation.
I0612 11:07:32.196089  5211 net.cpp:316] BatchNorm85 needs backward computation.
I0612 11:07:32.196092  5211 net.cpp:316] Convolution85 needs backward computation.
I0612 11:07:32.196096  5211 net.cpp:316] ReLU84 needs backward computation.
I0612 11:07:32.196105  5211 net.cpp:316] Scale84 needs backward computation.
I0612 11:07:32.196113  5211 net.cpp:316] BatchNorm84 needs backward computation.
I0612 11:07:32.196117  5211 net.cpp:316] Convolution84 needs backward computation.
I0612 11:07:32.196122  5211 net.cpp:316] Eltwise41_ReLU83_0_split needs backward computation.
I0612 11:07:32.196125  5211 net.cpp:316] ReLU83 needs backward computation.
I0612 11:07:32.196130  5211 net.cpp:316] Eltwise41 needs backward computation.
I0612 11:07:32.196135  5211 net.cpp:316] Scale83 needs backward computation.
I0612 11:07:32.196138  5211 net.cpp:316] BatchNorm83 needs backward computation.
I0612 11:07:32.196142  5211 net.cpp:316] Convolution83 needs backward computation.
I0612 11:07:32.196146  5211 net.cpp:316] ReLU82 needs backward computation.
I0612 11:07:32.196149  5211 net.cpp:316] Scale82 needs backward computation.
I0612 11:07:32.196157  5211 net.cpp:316] BatchNorm82 needs backward computation.
I0612 11:07:32.196161  5211 net.cpp:316] Convolution82 needs backward computation.
I0612 11:07:32.196166  5211 net.cpp:316] Eltwise40_ReLU81_0_split needs backward computation.
I0612 11:07:32.196169  5211 net.cpp:316] ReLU81 needs backward computation.
I0612 11:07:32.196173  5211 net.cpp:316] Eltwise40 needs backward computation.
I0612 11:07:32.196177  5211 net.cpp:316] Scale81 needs backward computation.
I0612 11:07:32.196182  5211 net.cpp:316] BatchNorm81 needs backward computation.
I0612 11:07:32.196184  5211 net.cpp:316] Convolution81 needs backward computation.
I0612 11:07:32.196188  5211 net.cpp:316] ReLU80 needs backward computation.
I0612 11:07:32.196193  5211 net.cpp:316] Scale80 needs backward computation.
I0612 11:07:32.196197  5211 net.cpp:316] BatchNorm80 needs backward computation.
I0612 11:07:32.196204  5211 net.cpp:316] Convolution80 needs backward computation.
I0612 11:07:32.196208  5211 net.cpp:316] Eltwise39_ReLU79_0_split needs backward computation.
I0612 11:07:32.196215  5211 net.cpp:316] ReLU79 needs backward computation.
I0612 11:07:32.196219  5211 net.cpp:316] Eltwise39 needs backward computation.
I0612 11:07:32.196225  5211 net.cpp:316] Scale79 needs backward computation.
I0612 11:07:32.196228  5211 net.cpp:316] BatchNorm79 needs backward computation.
I0612 11:07:32.196233  5211 net.cpp:316] Convolution79 needs backward computation.
I0612 11:07:32.196236  5211 net.cpp:316] ReLU78 needs backward computation.
I0612 11:07:32.196240  5211 net.cpp:316] Scale78 needs backward computation.
I0612 11:07:32.196245  5211 net.cpp:316] BatchNorm78 needs backward computation.
I0612 11:07:32.196249  5211 net.cpp:316] Convolution78 needs backward computation.
I0612 11:07:32.196254  5211 net.cpp:316] Eltwise38_ReLU77_0_split needs backward computation.
I0612 11:07:32.196257  5211 net.cpp:316] ReLU77 needs backward computation.
I0612 11:07:32.196261  5211 net.cpp:316] Eltwise38 needs backward computation.
I0612 11:07:32.196266  5211 net.cpp:316] Scale77 needs backward computation.
I0612 11:07:32.196270  5211 net.cpp:316] BatchNorm77 needs backward computation.
I0612 11:07:32.196274  5211 net.cpp:316] Convolution77 needs backward computation.
I0612 11:07:32.196279  5211 net.cpp:316] ReLU76 needs backward computation.
I0612 11:07:32.196281  5211 net.cpp:316] Scale76 needs backward computation.
I0612 11:07:32.196285  5211 net.cpp:316] BatchNorm76 needs backward computation.
I0612 11:07:32.196290  5211 net.cpp:316] Convolution76 needs backward computation.
I0612 11:07:32.196293  5211 net.cpp:316] Eltwise37_ReLU75_0_split needs backward computation.
I0612 11:07:32.196297  5211 net.cpp:316] ReLU75 needs backward computation.
I0612 11:07:32.196300  5211 net.cpp:316] Eltwise37 needs backward computation.
I0612 11:07:32.196310  5211 net.cpp:316] Scale75 needs backward computation.
I0612 11:07:32.196313  5211 net.cpp:316] BatchNorm75 needs backward computation.
I0612 11:07:32.196317  5211 net.cpp:316] Convolution75 needs backward computation.
I0612 11:07:32.196321  5211 net.cpp:316] ReLU74 needs backward computation.
I0612 11:07:32.196326  5211 net.cpp:316] Scale74 needs backward computation.
I0612 11:07:32.196329  5211 net.cpp:316] BatchNorm74 needs backward computation.
I0612 11:07:32.196332  5211 net.cpp:316] Convolution74 needs backward computation.
I0612 11:07:32.196336  5211 net.cpp:316] Concat2 needs backward computation.
I0612 11:07:32.196341  5211 net.cpp:318] Input2 does not need backward computation.
I0612 11:07:32.196346  5211 net.cpp:316] Pooling2 needs backward computation.
I0612 11:07:32.196349  5211 net.cpp:316] Eltwise36_ReLU73_0_split needs backward computation.
I0612 11:07:32.196353  5211 net.cpp:316] ReLU73 needs backward computation.
I0612 11:07:32.196357  5211 net.cpp:316] Eltwise36 needs backward computation.
I0612 11:07:32.196362  5211 net.cpp:316] Scale73 needs backward computation.
I0612 11:07:32.196365  5211 net.cpp:316] BatchNorm73 needs backward computation.
I0612 11:07:32.196368  5211 net.cpp:316] Convolution73 needs backward computation.
I0612 11:07:32.196373  5211 net.cpp:316] ReLU72 needs backward computation.
I0612 11:07:32.196377  5211 net.cpp:316] Scale72 needs backward computation.
I0612 11:07:32.196382  5211 net.cpp:316] BatchNorm72 needs backward computation.
I0612 11:07:32.196385  5211 net.cpp:316] Convolution72 needs backward computation.
I0612 11:07:32.196389  5211 net.cpp:316] Eltwise35_ReLU71_0_split needs backward computation.
I0612 11:07:32.196393  5211 net.cpp:316] ReLU71 needs backward computation.
I0612 11:07:32.196398  5211 net.cpp:316] Eltwise35 needs backward computation.
I0612 11:07:32.196401  5211 net.cpp:316] Scale71 needs backward computation.
I0612 11:07:32.196406  5211 net.cpp:316] BatchNorm71 needs backward computation.
I0612 11:07:32.196410  5211 net.cpp:316] Convolution71 needs backward computation.
I0612 11:07:32.196414  5211 net.cpp:316] ReLU70 needs backward computation.
I0612 11:07:32.196418  5211 net.cpp:316] Scale70 needs backward computation.
I0612 11:07:32.196422  5211 net.cpp:316] BatchNorm70 needs backward computation.
I0612 11:07:32.196429  5211 net.cpp:316] Convolution70 needs backward computation.
I0612 11:07:32.196432  5211 net.cpp:316] Eltwise34_ReLU69_0_split needs backward computation.
I0612 11:07:32.196436  5211 net.cpp:316] ReLU69 needs backward computation.
I0612 11:07:32.196440  5211 net.cpp:316] Eltwise34 needs backward computation.
I0612 11:07:32.196444  5211 net.cpp:316] Scale69 needs backward computation.
I0612 11:07:32.196449  5211 net.cpp:316] BatchNorm69 needs backward computation.
I0612 11:07:32.196451  5211 net.cpp:316] Convolution69 needs backward computation.
I0612 11:07:32.196455  5211 net.cpp:316] ReLU68 needs backward computation.
I0612 11:07:32.196460  5211 net.cpp:316] Scale68 needs backward computation.
I0612 11:07:32.196463  5211 net.cpp:316] BatchNorm68 needs backward computation.
I0612 11:07:32.196467  5211 net.cpp:316] Convolution68 needs backward computation.
I0612 11:07:32.196471  5211 net.cpp:316] Eltwise33_ReLU67_0_split needs backward computation.
I0612 11:07:32.196475  5211 net.cpp:316] ReLU67 needs backward computation.
I0612 11:07:32.196480  5211 net.cpp:316] Eltwise33 needs backward computation.
I0612 11:07:32.196485  5211 net.cpp:316] Scale67 needs backward computation.
I0612 11:07:32.196488  5211 net.cpp:316] BatchNorm67 needs backward computation.
I0612 11:07:32.196492  5211 net.cpp:316] Convolution67 needs backward computation.
I0612 11:07:32.196501  5211 net.cpp:316] ReLU66 needs backward computation.
I0612 11:07:32.196504  5211 net.cpp:316] Scale66 needs backward computation.
I0612 11:07:32.196509  5211 net.cpp:316] BatchNorm66 needs backward computation.
I0612 11:07:32.196513  5211 net.cpp:316] Convolution66 needs backward computation.
I0612 11:07:32.196517  5211 net.cpp:316] Eltwise32_ReLU65_0_split needs backward computation.
I0612 11:07:32.196521  5211 net.cpp:316] ReLU65 needs backward computation.
I0612 11:07:32.196526  5211 net.cpp:316] Eltwise32 needs backward computation.
I0612 11:07:32.196530  5211 net.cpp:316] Scale65 needs backward computation.
I0612 11:07:32.196534  5211 net.cpp:316] BatchNorm65 needs backward computation.
I0612 11:07:32.196538  5211 net.cpp:316] Convolution65 needs backward computation.
I0612 11:07:32.196542  5211 net.cpp:316] ReLU64 needs backward computation.
I0612 11:07:32.196549  5211 net.cpp:316] Scale64 needs backward computation.
I0612 11:07:32.196553  5211 net.cpp:316] BatchNorm64 needs backward computation.
I0612 11:07:32.196557  5211 net.cpp:316] Convolution64 needs backward computation.
I0612 11:07:32.196562  5211 net.cpp:316] Eltwise31_ReLU63_0_split needs backward computation.
I0612 11:07:32.196565  5211 net.cpp:316] ReLU63 needs backward computation.
I0612 11:07:32.196569  5211 net.cpp:316] Eltwise31 needs backward computation.
I0612 11:07:32.196574  5211 net.cpp:316] Scale63 needs backward computation.
I0612 11:07:32.196578  5211 net.cpp:316] BatchNorm63 needs backward computation.
I0612 11:07:32.196581  5211 net.cpp:316] Convolution63 needs backward computation.
I0612 11:07:32.196585  5211 net.cpp:316] ReLU62 needs backward computation.
I0612 11:07:32.196589  5211 net.cpp:316] Scale62 needs backward computation.
I0612 11:07:32.196594  5211 net.cpp:316] BatchNorm62 needs backward computation.
I0612 11:07:32.196599  5211 net.cpp:316] Convolution62 needs backward computation.
I0612 11:07:32.196604  5211 net.cpp:316] Eltwise30_ReLU61_0_split needs backward computation.
I0612 11:07:32.196607  5211 net.cpp:316] ReLU61 needs backward computation.
I0612 11:07:32.196610  5211 net.cpp:316] Eltwise30 needs backward computation.
I0612 11:07:32.196619  5211 net.cpp:316] Scale61 needs backward computation.
I0612 11:07:32.196624  5211 net.cpp:316] BatchNorm61 needs backward computation.
I0612 11:07:32.196629  5211 net.cpp:316] Convolution61 needs backward computation.
I0612 11:07:32.196632  5211 net.cpp:316] ReLU60 needs backward computation.
I0612 11:07:32.196636  5211 net.cpp:316] Scale60 needs backward computation.
I0612 11:07:32.196640  5211 net.cpp:316] BatchNorm60 needs backward computation.
I0612 11:07:32.196643  5211 net.cpp:316] Convolution60 needs backward computation.
I0612 11:07:32.196655  5211 net.cpp:316] Eltwise29_ReLU59_0_split needs backward computation.
I0612 11:07:32.196660  5211 net.cpp:316] ReLU59 needs backward computation.
I0612 11:07:32.196665  5211 net.cpp:316] Eltwise29 needs backward computation.
I0612 11:07:32.196669  5211 net.cpp:316] Scale59 needs backward computation.
I0612 11:07:32.196673  5211 net.cpp:316] BatchNorm59 needs backward computation.
I0612 11:07:32.196677  5211 net.cpp:316] Convolution59 needs backward computation.
I0612 11:07:32.196681  5211 net.cpp:316] ReLU58 needs backward computation.
I0612 11:07:32.196686  5211 net.cpp:316] Scale58 needs backward computation.
I0612 11:07:32.196689  5211 net.cpp:316] BatchNorm58 needs backward computation.
I0612 11:07:32.196693  5211 net.cpp:316] Convolution58 needs backward computation.
I0612 11:07:32.196697  5211 net.cpp:316] Eltwise28_ReLU57_0_split needs backward computation.
I0612 11:07:32.196702  5211 net.cpp:316] ReLU57 needs backward computation.
I0612 11:07:32.196705  5211 net.cpp:316] Eltwise28 needs backward computation.
I0612 11:07:32.196709  5211 net.cpp:316] Scale57 needs backward computation.
I0612 11:07:32.196713  5211 net.cpp:316] BatchNorm57 needs backward computation.
I0612 11:07:32.196717  5211 net.cpp:316] Convolution57 needs backward computation.
I0612 11:07:32.196722  5211 net.cpp:316] ReLU56 needs backward computation.
I0612 11:07:32.196725  5211 net.cpp:316] Scale56 needs backward computation.
I0612 11:07:32.196729  5211 net.cpp:316] BatchNorm56 needs backward computation.
I0612 11:07:32.196734  5211 net.cpp:316] Convolution56 needs backward computation.
I0612 11:07:32.196738  5211 net.cpp:316] Eltwise27_ReLU55_0_split needs backward computation.
I0612 11:07:32.196743  5211 net.cpp:316] ReLU55 needs backward computation.
I0612 11:07:32.196745  5211 net.cpp:316] Eltwise27 needs backward computation.
I0612 11:07:32.196750  5211 net.cpp:316] Scale55 needs backward computation.
I0612 11:07:32.196754  5211 net.cpp:316] BatchNorm55 needs backward computation.
I0612 11:07:32.196758  5211 net.cpp:316] Convolution55 needs backward computation.
I0612 11:07:32.196763  5211 net.cpp:316] ReLU54 needs backward computation.
I0612 11:07:32.196766  5211 net.cpp:316] Scale54 needs backward computation.
I0612 11:07:32.196770  5211 net.cpp:316] BatchNorm54 needs backward computation.
I0612 11:07:32.196774  5211 net.cpp:316] Convolution54 needs backward computation.
I0612 11:07:32.196779  5211 net.cpp:316] Eltwise26_ReLU53_0_split needs backward computation.
I0612 11:07:32.196782  5211 net.cpp:316] ReLU53 needs backward computation.
I0612 11:07:32.196786  5211 net.cpp:316] Eltwise26 needs backward computation.
I0612 11:07:32.196790  5211 net.cpp:316] Scale53 needs backward computation.
I0612 11:07:32.196794  5211 net.cpp:316] BatchNorm53 needs backward computation.
I0612 11:07:32.196799  5211 net.cpp:316] Convolution53 needs backward computation.
I0612 11:07:32.196802  5211 net.cpp:316] ReLU52 needs backward computation.
I0612 11:07:32.196806  5211 net.cpp:316] Scale52 needs backward computation.
I0612 11:07:32.196810  5211 net.cpp:316] BatchNorm52 needs backward computation.
I0612 11:07:32.196815  5211 net.cpp:316] Convolution52 needs backward computation.
I0612 11:07:32.196818  5211 net.cpp:316] Eltwise25_ReLU51_0_split needs backward computation.
I0612 11:07:32.196822  5211 net.cpp:316] ReLU51 needs backward computation.
I0612 11:07:32.196826  5211 net.cpp:316] Eltwise25 needs backward computation.
I0612 11:07:32.196830  5211 net.cpp:316] Scale51 needs backward computation.
I0612 11:07:32.196835  5211 net.cpp:316] BatchNorm51 needs backward computation.
I0612 11:07:32.196838  5211 net.cpp:316] Convolution51 needs backward computation.
I0612 11:07:32.196846  5211 net.cpp:316] ReLU50 needs backward computation.
I0612 11:07:32.196851  5211 net.cpp:316] Scale50 needs backward computation.
I0612 11:07:32.196854  5211 net.cpp:316] BatchNorm50 needs backward computation.
I0612 11:07:32.196857  5211 net.cpp:316] Convolution50 needs backward computation.
I0612 11:07:32.196864  5211 net.cpp:316] Eltwise24_ReLU49_0_split needs backward computation.
I0612 11:07:32.196868  5211 net.cpp:316] ReLU49 needs backward computation.
I0612 11:07:32.196872  5211 net.cpp:316] Eltwise24 needs backward computation.
I0612 11:07:32.196877  5211 net.cpp:316] Scale49 needs backward computation.
I0612 11:07:32.196882  5211 net.cpp:316] BatchNorm49 needs backward computation.
I0612 11:07:32.196884  5211 net.cpp:316] Convolution49 needs backward computation.
I0612 11:07:32.196892  5211 net.cpp:316] ReLU48 needs backward computation.
I0612 11:07:32.196897  5211 net.cpp:316] Scale48 needs backward computation.
I0612 11:07:32.196900  5211 net.cpp:316] BatchNorm48 needs backward computation.
I0612 11:07:32.196905  5211 net.cpp:316] Convolution48 needs backward computation.
I0612 11:07:32.196909  5211 net.cpp:316] Eltwise23_ReLU47_0_split needs backward computation.
I0612 11:07:32.196913  5211 net.cpp:316] ReLU47 needs backward computation.
I0612 11:07:32.196918  5211 net.cpp:316] Eltwise23 needs backward computation.
I0612 11:07:32.196921  5211 net.cpp:316] Scale47 needs backward computation.
I0612 11:07:32.196926  5211 net.cpp:316] BatchNorm47 needs backward computation.
I0612 11:07:32.196929  5211 net.cpp:316] Convolution47 needs backward computation.
I0612 11:07:32.196933  5211 net.cpp:316] ReLU46 needs backward computation.
I0612 11:07:32.196938  5211 net.cpp:316] Scale46 needs backward computation.
I0612 11:07:32.196944  5211 net.cpp:316] BatchNorm46 needs backward computation.
I0612 11:07:32.196949  5211 net.cpp:316] Convolution46 needs backward computation.
I0612 11:07:32.196952  5211 net.cpp:316] Eltwise22_ReLU45_0_split needs backward computation.
I0612 11:07:32.196956  5211 net.cpp:316] ReLU45 needs backward computation.
I0612 11:07:32.196960  5211 net.cpp:316] Eltwise22 needs backward computation.
I0612 11:07:32.196969  5211 net.cpp:316] Scale45 needs backward computation.
I0612 11:07:32.196972  5211 net.cpp:316] BatchNorm45 needs backward computation.
I0612 11:07:32.196976  5211 net.cpp:316] Convolution45 needs backward computation.
I0612 11:07:32.196980  5211 net.cpp:316] ReLU44 needs backward computation.
I0612 11:07:32.196987  5211 net.cpp:316] Scale44 needs backward computation.
I0612 11:07:32.196991  5211 net.cpp:316] BatchNorm44 needs backward computation.
I0612 11:07:32.197003  5211 net.cpp:316] Convolution44 needs backward computation.
I0612 11:07:32.197007  5211 net.cpp:316] Eltwise21_ReLU43_0_split needs backward computation.
I0612 11:07:32.197011  5211 net.cpp:316] ReLU43 needs backward computation.
I0612 11:07:32.197016  5211 net.cpp:316] Eltwise21 needs backward computation.
I0612 11:07:32.197023  5211 net.cpp:316] Scale43 needs backward computation.
I0612 11:07:32.197031  5211 net.cpp:316] BatchNorm43 needs backward computation.
I0612 11:07:32.197034  5211 net.cpp:316] Convolution43 needs backward computation.
I0612 11:07:32.197038  5211 net.cpp:316] ReLU42 needs backward computation.
I0612 11:07:32.197042  5211 net.cpp:316] Scale42 needs backward computation.
I0612 11:07:32.197049  5211 net.cpp:316] BatchNorm42 needs backward computation.
I0612 11:07:32.197053  5211 net.cpp:316] Convolution42 needs backward computation.
I0612 11:07:32.197060  5211 net.cpp:316] Eltwise20_ReLU41_0_split needs backward computation.
I0612 11:07:32.197064  5211 net.cpp:316] ReLU41 needs backward computation.
I0612 11:07:32.197068  5211 net.cpp:316] Eltwise20 needs backward computation.
I0612 11:07:32.197072  5211 net.cpp:316] Scale41 needs backward computation.
I0612 11:07:32.197077  5211 net.cpp:316] BatchNorm41 needs backward computation.
I0612 11:07:32.197080  5211 net.cpp:316] Convolution41 needs backward computation.
I0612 11:07:32.197083  5211 net.cpp:316] ReLU40 needs backward computation.
I0612 11:07:32.197091  5211 net.cpp:316] Scale40 needs backward computation.
I0612 11:07:32.197094  5211 net.cpp:316] BatchNorm40 needs backward computation.
I0612 11:07:32.197098  5211 net.cpp:316] Convolution40 needs backward computation.
I0612 11:07:32.197103  5211 net.cpp:316] Eltwise19_ReLU39_0_split needs backward computation.
I0612 11:07:32.197108  5211 net.cpp:316] ReLU39 needs backward computation.
I0612 11:07:32.197113  5211 net.cpp:316] Eltwise19 needs backward computation.
I0612 11:07:32.197123  5211 net.cpp:316] Scale39 needs backward computation.
I0612 11:07:32.197130  5211 net.cpp:316] BatchNorm39 needs backward computation.
I0612 11:07:32.197134  5211 net.cpp:316] Convolution39 needs backward computation.
I0612 11:07:32.197139  5211 net.cpp:316] ReLU38 needs backward computation.
I0612 11:07:32.197145  5211 net.cpp:316] Scale38 needs backward computation.
I0612 11:07:32.197152  5211 net.cpp:316] BatchNorm38 needs backward computation.
I0612 11:07:32.197156  5211 net.cpp:316] Convolution38 needs backward computation.
I0612 11:07:32.197161  5211 net.cpp:316] Concat1 needs backward computation.
I0612 11:07:32.197166  5211 net.cpp:318] Input1 does not need backward computation.
I0612 11:07:32.197170  5211 net.cpp:316] Pooling1 needs backward computation.
I0612 11:07:32.197175  5211 net.cpp:316] Eltwise18_ReLU37_0_split needs backward computation.
I0612 11:07:32.197178  5211 net.cpp:316] ReLU37 needs backward computation.
I0612 11:07:32.197182  5211 net.cpp:316] Eltwise18 needs backward computation.
I0612 11:07:32.197190  5211 net.cpp:316] Scale37 needs backward computation.
I0612 11:07:32.197194  5211 net.cpp:316] BatchNorm37 needs backward computation.
I0612 11:07:32.197198  5211 net.cpp:316] Convolution37 needs backward computation.
I0612 11:07:32.197201  5211 net.cpp:316] ReLU36 needs backward computation.
I0612 11:07:32.197206  5211 net.cpp:316] Scale36 needs backward computation.
I0612 11:07:32.197209  5211 net.cpp:316] BatchNorm36 needs backward computation.
I0612 11:07:32.197212  5211 net.cpp:316] Convolution36 needs backward computation.
I0612 11:07:32.197217  5211 net.cpp:316] Eltwise17_ReLU35_0_split needs backward computation.
I0612 11:07:32.197221  5211 net.cpp:316] ReLU35 needs backward computation.
I0612 11:07:32.197224  5211 net.cpp:316] Eltwise17 needs backward computation.
I0612 11:07:32.197228  5211 net.cpp:316] Scale35 needs backward computation.
I0612 11:07:32.197238  5211 net.cpp:316] BatchNorm35 needs backward computation.
I0612 11:07:32.197242  5211 net.cpp:316] Convolution35 needs backward computation.
I0612 11:07:32.197247  5211 net.cpp:316] ReLU34 needs backward computation.
I0612 11:07:32.197250  5211 net.cpp:316] Scale34 needs backward computation.
I0612 11:07:32.197257  5211 net.cpp:316] BatchNorm34 needs backward computation.
I0612 11:07:32.197262  5211 net.cpp:316] Convolution34 needs backward computation.
I0612 11:07:32.197265  5211 net.cpp:316] Eltwise16_ReLU33_0_split needs backward computation.
I0612 11:07:32.197269  5211 net.cpp:316] ReLU33 needs backward computation.
I0612 11:07:32.197273  5211 net.cpp:316] Eltwise16 needs backward computation.
I0612 11:07:32.197278  5211 net.cpp:316] Scale33 needs backward computation.
I0612 11:07:32.197281  5211 net.cpp:316] BatchNorm33 needs backward computation.
I0612 11:07:32.197284  5211 net.cpp:316] Convolution33 needs backward computation.
I0612 11:07:32.197288  5211 net.cpp:316] ReLU32 needs backward computation.
I0612 11:07:32.197298  5211 net.cpp:316] Scale32 needs backward computation.
I0612 11:07:32.197301  5211 net.cpp:316] BatchNorm32 needs backward computation.
I0612 11:07:32.197305  5211 net.cpp:316] Convolution32 needs backward computation.
I0612 11:07:32.197309  5211 net.cpp:316] Eltwise15_ReLU31_0_split needs backward computation.
I0612 11:07:32.197314  5211 net.cpp:316] ReLU31 needs backward computation.
I0612 11:07:32.197316  5211 net.cpp:316] Eltwise15 needs backward computation.
I0612 11:07:32.197324  5211 net.cpp:316] Scale31 needs backward computation.
I0612 11:07:32.197331  5211 net.cpp:316] BatchNorm31 needs backward computation.
I0612 11:07:32.197335  5211 net.cpp:316] Convolution31 needs backward computation.
I0612 11:07:32.197340  5211 net.cpp:316] ReLU30 needs backward computation.
I0612 11:07:32.197346  5211 net.cpp:316] Scale30 needs backward computation.
I0612 11:07:32.197355  5211 net.cpp:316] BatchNorm30 needs backward computation.
I0612 11:07:32.197363  5211 net.cpp:316] Convolution30 needs backward computation.
I0612 11:07:32.197368  5211 net.cpp:316] Eltwise14_ReLU29_0_split needs backward computation.
I0612 11:07:32.197372  5211 net.cpp:316] ReLU29 needs backward computation.
I0612 11:07:32.197376  5211 net.cpp:316] Eltwise14 needs backward computation.
I0612 11:07:32.197382  5211 net.cpp:316] Scale29 needs backward computation.
I0612 11:07:32.197386  5211 net.cpp:316] BatchNorm29 needs backward computation.
I0612 11:07:32.197391  5211 net.cpp:316] Convolution29 needs backward computation.
I0612 11:07:32.197396  5211 net.cpp:316] ReLU28 needs backward computation.
I0612 11:07:32.197399  5211 net.cpp:316] Scale28 needs backward computation.
I0612 11:07:32.197402  5211 net.cpp:316] BatchNorm28 needs backward computation.
I0612 11:07:32.197407  5211 net.cpp:316] Convolution28 needs backward computation.
I0612 11:07:32.197410  5211 net.cpp:316] Eltwise13_ReLU27_0_split needs backward computation.
I0612 11:07:32.197414  5211 net.cpp:316] ReLU27 needs backward computation.
I0612 11:07:32.197418  5211 net.cpp:316] Eltwise13 needs backward computation.
I0612 11:07:32.197427  5211 net.cpp:316] Scale27 needs backward computation.
I0612 11:07:32.197435  5211 net.cpp:316] BatchNorm27 needs backward computation.
I0612 11:07:32.197439  5211 net.cpp:316] Convolution27 needs backward computation.
I0612 11:07:32.197443  5211 net.cpp:316] ReLU26 needs backward computation.
I0612 11:07:32.197450  5211 net.cpp:316] Scale26 needs backward computation.
I0612 11:07:32.197458  5211 net.cpp:316] BatchNorm26 needs backward computation.
I0612 11:07:32.197461  5211 net.cpp:316] Convolution26 needs backward computation.
I0612 11:07:32.197465  5211 net.cpp:316] Eltwise12_ReLU25_0_split needs backward computation.
I0612 11:07:32.197469  5211 net.cpp:316] ReLU25 needs backward computation.
I0612 11:07:32.197474  5211 net.cpp:316] Eltwise12 needs backward computation.
I0612 11:07:32.197479  5211 net.cpp:316] Scale25 needs backward computation.
I0612 11:07:32.197481  5211 net.cpp:316] BatchNorm25 needs backward computation.
I0612 11:07:32.197485  5211 net.cpp:316] Convolution25 needs backward computation.
I0612 11:07:32.197489  5211 net.cpp:316] ReLU24 needs backward computation.
I0612 11:07:32.197492  5211 net.cpp:316] Scale24 needs backward computation.
I0612 11:07:32.197500  5211 net.cpp:316] BatchNorm24 needs backward computation.
I0612 11:07:32.197504  5211 net.cpp:316] Convolution24 needs backward computation.
I0612 11:07:32.197509  5211 net.cpp:316] Eltwise11_ReLU23_0_split needs backward computation.
I0612 11:07:32.197511  5211 net.cpp:316] ReLU23 needs backward computation.
I0612 11:07:32.197515  5211 net.cpp:316] Eltwise11 needs backward computation.
I0612 11:07:32.197520  5211 net.cpp:316] Scale23 needs backward computation.
I0612 11:07:32.197527  5211 net.cpp:316] BatchNorm23 needs backward computation.
I0612 11:07:32.197530  5211 net.cpp:316] Convolution23 needs backward computation.
I0612 11:07:32.197535  5211 net.cpp:316] ReLU22 needs backward computation.
I0612 11:07:32.197541  5211 net.cpp:316] Scale22 needs backward computation.
I0612 11:07:32.197553  5211 net.cpp:316] BatchNorm22 needs backward computation.
I0612 11:07:32.197561  5211 net.cpp:316] Convolution22 needs backward computation.
I0612 11:07:32.197566  5211 net.cpp:316] Eltwise10_ReLU21_0_split needs backward computation.
I0612 11:07:32.197569  5211 net.cpp:316] ReLU21 needs backward computation.
I0612 11:07:32.197573  5211 net.cpp:316] Eltwise10 needs backward computation.
I0612 11:07:32.197578  5211 net.cpp:316] Scale21 needs backward computation.
I0612 11:07:32.197585  5211 net.cpp:316] BatchNorm21 needs backward computation.
I0612 11:07:32.197588  5211 net.cpp:316] Convolution21 needs backward computation.
I0612 11:07:32.197592  5211 net.cpp:316] ReLU20 needs backward computation.
I0612 11:07:32.197597  5211 net.cpp:316] Scale20 needs backward computation.
I0612 11:07:32.197600  5211 net.cpp:316] BatchNorm20 needs backward computation.
I0612 11:07:32.197607  5211 net.cpp:316] Convolution20 needs backward computation.
I0612 11:07:32.197614  5211 net.cpp:316] Eltwise9_ReLU19_0_split needs backward computation.
I0612 11:07:32.197618  5211 net.cpp:316] ReLU19 needs backward computation.
I0612 11:07:32.197623  5211 net.cpp:316] Eltwise9 needs backward computation.
I0612 11:07:32.197628  5211 net.cpp:316] Scale19 needs backward computation.
I0612 11:07:32.197631  5211 net.cpp:316] BatchNorm19 needs backward computation.
I0612 11:07:32.197634  5211 net.cpp:316] Convolution19 needs backward computation.
I0612 11:07:32.197638  5211 net.cpp:316] ReLU18 needs backward computation.
I0612 11:07:32.197643  5211 net.cpp:316] Scale18 needs backward computation.
I0612 11:07:32.197646  5211 net.cpp:316] BatchNorm18 needs backward computation.
I0612 11:07:32.197649  5211 net.cpp:316] Convolution18 needs backward computation.
I0612 11:07:32.197654  5211 net.cpp:316] Eltwise8_ReLU17_0_split needs backward computation.
I0612 11:07:32.197659  5211 net.cpp:316] ReLU17 needs backward computation.
I0612 11:07:32.197662  5211 net.cpp:316] Eltwise8 needs backward computation.
I0612 11:07:32.197670  5211 net.cpp:316] Scale17 needs backward computation.
I0612 11:07:32.197674  5211 net.cpp:316] BatchNorm17 needs backward computation.
I0612 11:07:32.197677  5211 net.cpp:316] Convolution17 needs backward computation.
I0612 11:07:32.197681  5211 net.cpp:316] ReLU16 needs backward computation.
I0612 11:07:32.197688  5211 net.cpp:316] Scale16 needs backward computation.
I0612 11:07:32.197696  5211 net.cpp:316] BatchNorm16 needs backward computation.
I0612 11:07:32.197705  5211 net.cpp:316] Convolution16 needs backward computation.
I0612 11:07:32.197710  5211 net.cpp:316] Eltwise7_ReLU15_0_split needs backward computation.
I0612 11:07:32.197715  5211 net.cpp:316] ReLU15 needs backward computation.
I0612 11:07:32.197718  5211 net.cpp:316] Eltwise7 needs backward computation.
I0612 11:07:32.197722  5211 net.cpp:316] Scale15 needs backward computation.
I0612 11:07:32.197729  5211 net.cpp:316] BatchNorm15 needs backward computation.
I0612 11:07:32.197733  5211 net.cpp:316] Convolution15 needs backward computation.
I0612 11:07:32.197737  5211 net.cpp:316] ReLU14 needs backward computation.
I0612 11:07:32.197741  5211 net.cpp:316] Scale14 needs backward computation.
I0612 11:07:32.197748  5211 net.cpp:316] BatchNorm14 needs backward computation.
I0612 11:07:32.197752  5211 net.cpp:316] Convolution14 needs backward computation.
I0612 11:07:32.197757  5211 net.cpp:316] Eltwise6_ReLU13_0_split needs backward computation.
I0612 11:07:32.197762  5211 net.cpp:316] ReLU13 needs backward computation.
I0612 11:07:32.197765  5211 net.cpp:316] Eltwise6 needs backward computation.
I0612 11:07:32.197773  5211 net.cpp:316] Scale13 needs backward computation.
I0612 11:07:32.197777  5211 net.cpp:316] BatchNorm13 needs backward computation.
I0612 11:07:32.197782  5211 net.cpp:316] Convolution13 needs backward computation.
I0612 11:07:32.197784  5211 net.cpp:316] ReLU12 needs backward computation.
I0612 11:07:32.197793  5211 net.cpp:316] Scale12 needs backward computation.
I0612 11:07:32.197796  5211 net.cpp:316] BatchNorm12 needs backward computation.
I0612 11:07:32.197799  5211 net.cpp:316] Convolution12 needs backward computation.
I0612 11:07:32.197804  5211 net.cpp:316] Eltwise5_ReLU11_0_split needs backward computation.
I0612 11:07:32.197808  5211 net.cpp:316] ReLU11 needs backward computation.
I0612 11:07:32.197813  5211 net.cpp:316] Eltwise5 needs backward computation.
I0612 11:07:32.197816  5211 net.cpp:316] Scale11 needs backward computation.
I0612 11:07:32.197820  5211 net.cpp:316] BatchNorm11 needs backward computation.
I0612 11:07:32.197824  5211 net.cpp:316] Convolution11 needs backward computation.
I0612 11:07:32.197829  5211 net.cpp:316] ReLU10 needs backward computation.
I0612 11:07:32.197832  5211 net.cpp:316] Scale10 needs backward computation.
I0612 11:07:32.197844  5211 net.cpp:316] BatchNorm10 needs backward computation.
I0612 11:07:32.197849  5211 net.cpp:316] Convolution10 needs backward computation.
I0612 11:07:32.197857  5211 net.cpp:316] Eltwise4_ReLU9_0_split needs backward computation.
I0612 11:07:32.197861  5211 net.cpp:316] ReLU9 needs backward computation.
I0612 11:07:32.197865  5211 net.cpp:316] Eltwise4 needs backward computation.
I0612 11:07:32.197873  5211 net.cpp:316] Scale9 needs backward computation.
I0612 11:07:32.197878  5211 net.cpp:316] BatchNorm9 needs backward computation.
I0612 11:07:32.197881  5211 net.cpp:316] Convolution9 needs backward computation.
I0612 11:07:32.197885  5211 net.cpp:316] ReLU8 needs backward computation.
I0612 11:07:32.197892  5211 net.cpp:316] Scale8 needs backward computation.
I0612 11:07:32.197901  5211 net.cpp:316] BatchNorm8 needs backward computation.
I0612 11:07:32.197907  5211 net.cpp:316] Convolution8 needs backward computation.
I0612 11:07:32.197911  5211 net.cpp:316] Eltwise3_ReLU7_0_split needs backward computation.
I0612 11:07:32.197916  5211 net.cpp:316] ReLU7 needs backward computation.
I0612 11:07:32.197919  5211 net.cpp:316] Eltwise3 needs backward computation.
I0612 11:07:32.197927  5211 net.cpp:316] Scale7 needs backward computation.
I0612 11:07:32.197935  5211 net.cpp:316] BatchNorm7 needs backward computation.
I0612 11:07:32.197939  5211 net.cpp:316] Convolution7 needs backward computation.
I0612 11:07:32.197943  5211 net.cpp:316] ReLU6 needs backward computation.
I0612 11:07:32.197947  5211 net.cpp:316] Scale6 needs backward computation.
I0612 11:07:32.197950  5211 net.cpp:316] BatchNorm6 needs backward computation.
I0612 11:07:32.197953  5211 net.cpp:316] Convolution6 needs backward computation.
I0612 11:07:32.197958  5211 net.cpp:316] Eltwise2_ReLU5_0_split needs backward computation.
I0612 11:07:32.197962  5211 net.cpp:316] ReLU5 needs backward computation.
I0612 11:07:32.197967  5211 net.cpp:316] Eltwise2 needs backward computation.
I0612 11:07:32.197975  5211 net.cpp:316] Scale5 needs backward computation.
I0612 11:07:32.197983  5211 net.cpp:316] BatchNorm5 needs backward computation.
I0612 11:07:32.197988  5211 net.cpp:316] Convolution5 needs backward computation.
I0612 11:07:32.197991  5211 net.cpp:316] ReLU4 needs backward computation.
I0612 11:07:32.197994  5211 net.cpp:316] Scale4 needs backward computation.
I0612 11:07:32.197999  5211 net.cpp:316] BatchNorm4 needs backward computation.
I0612 11:07:32.198002  5211 net.cpp:316] Convolution4 needs backward computation.
I0612 11:07:32.198006  5211 net.cpp:316] Eltwise1_ReLU3_0_split needs backward computation.
I0612 11:07:32.198010  5211 net.cpp:316] ReLU3 needs backward computation.
I0612 11:07:32.198014  5211 net.cpp:316] Eltwise1 needs backward computation.
I0612 11:07:32.198022  5211 net.cpp:316] Scale3 needs backward computation.
I0612 11:07:32.198029  5211 net.cpp:316] BatchNorm3 needs backward computation.
I0612 11:07:32.198034  5211 net.cpp:316] Convolution3 needs backward computation.
I0612 11:07:32.198037  5211 net.cpp:316] ReLU2 needs backward computation.
I0612 11:07:32.198045  5211 net.cpp:316] Scale2 needs backward computation.
I0612 11:07:32.198048  5211 net.cpp:316] BatchNorm2 needs backward computation.
I0612 11:07:32.198055  5211 net.cpp:316] Convolution2 needs backward computation.
I0612 11:07:32.198060  5211 net.cpp:316] Convolution1_ReLU1_0_split needs backward computation.
I0612 11:07:32.198065  5211 net.cpp:316] ReLU1 needs backward computation.
I0612 11:07:32.198068  5211 net.cpp:316] Scale1 needs backward computation.
I0612 11:07:32.198072  5211 net.cpp:316] BatchNorm1 needs backward computation.
I0612 11:07:32.198076  5211 net.cpp:316] Convolution1 needs backward computation.
I0612 11:07:32.198081  5211 net.cpp:318] Data2_Data1_1_split does not need backward computation.
I0612 11:07:32.198086  5211 net.cpp:318] Data1 does not need backward computation.
I0612 11:07:32.198089  5211 net.cpp:360] This network produces output Accuracy
I0612 11:07:32.198094  5211 net.cpp:360] This network produces output SoftmaxWithLoss1
I0612 11:07:32.198437  5211 net.cpp:374] Network initialization done.
I0612 11:07:32.201486  5211 solver.cpp:65] Solver scaffolding done.
params_lr: 765	has_params_lr: 765	params_weight_decay: 765	has_params_decay: 765
layers; 554
params: 765
I0612 11:07:32.242826  5211 main54.cpp:440] Solving 
I0612 11:07:32.242852  5211 main54.cpp:441] Learning Rate Policy: multistep
I0612 11:07:32.265038  5211 main54.cpp:499] Iteration 0, Testing net (#0)
I0612 11:08:35.354831  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.100078
I0612 11:08:35.354876  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0612 11:08:37.240170  5211 main54.cpp:387] Iteration 0, loss = 4.45378
I0612 11:08:37.240209  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 4.45378 (* 1 = 4.45378 loss)
I0612 11:08:37.240221  5211 sgd_solver.cpp:43] Iteration 0, lr = 0.02
I0612 11:21:38.846045  5211 main54.cpp:499] Iteration 400, Testing net (#0)
I0612 11:22:42.077404  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.363984
I0612 11:22:42.077447  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.84206 (* 1 = 1.84206 loss)
I0612 11:22:44.161016  5211 main54.cpp:387] Iteration 400, loss = 1.62698
I0612 11:22:44.161046  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 1.62698 (* 1 = 1.62698 loss)
I0612 11:22:44.161056  5211 sgd_solver.cpp:43] Iteration 400, lr = 0.02
I0612 11:35:44.715363  5211 main54.cpp:499] Iteration 800, Testing net (#0)
I0612 11:36:47.970990  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.463672
I0612 11:36:47.971035  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.6159 (* 1 = 1.6159 loss)
I0612 11:36:49.916702  5211 main54.cpp:387] Iteration 800, loss = 1.19141
I0612 11:36:49.916731  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 1.19141 (* 1 = 1.19141 loss)
I0612 11:36:49.916740  5211 sgd_solver.cpp:43] Iteration 800, lr = 0.02
I0612 11:49:48.491547  5211 main54.cpp:499] Iteration 1200, Testing net (#0)
I0612 11:50:51.740631  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.422969
I0612 11:50:51.740674  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 2.26037 (* 1 = 2.26037 loss)
I0612 11:50:53.663425  5211 main54.cpp:387] Iteration 1200, loss = 0.86458
I0612 11:50:53.663458  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.86458 (* 1 = 0.86458 loss)
I0612 11:50:53.663467  5211 sgd_solver.cpp:43] Iteration 1200, lr = 0.02
I0612 12:03:53.591913  5211 main54.cpp:499] Iteration 1600, Testing net (#0)
I0612 12:04:56.851809  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.512187
I0612 12:04:56.851855  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.92517 (* 1 = 1.92517 loss)
I0612 12:04:58.737651  5211 main54.cpp:387] Iteration 1600, loss = 1.22318
I0612 12:04:58.737686  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 1.22318 (* 1 = 1.22318 loss)
I0612 12:04:58.737695  5211 sgd_solver.cpp:43] Iteration 1600, lr = 0.02
I0612 12:17:57.265594  5211 main54.cpp:499] Iteration 2000, Testing net (#0)
I0612 12:19:00.479270  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.528125
I0612 12:19:00.479315  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.6053 (* 1 = 1.6053 loss)
I0612 12:19:02.390637  5211 main54.cpp:387] Iteration 2000, loss = 0.917038
I0612 12:19:02.390682  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.917038 (* 1 = 0.917038 loss)
I0612 12:19:02.390692  5211 sgd_solver.cpp:43] Iteration 2000, lr = 0.02
I0612 12:31:56.820561  5211 main54.cpp:499] Iteration 2400, Testing net (#0)
I0612 12:33:00.108741  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.453203
I0612 12:33:00.108785  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 2.3785 (* 1 = 2.3785 loss)
I0612 12:33:01.955287  5211 main54.cpp:387] Iteration 2400, loss = 0.753198
I0612 12:33:01.955324  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.753198 (* 1 = 0.753198 loss)
I0612 12:33:01.955334  5211 sgd_solver.cpp:43] Iteration 2400, lr = 0.02
I0612 12:46:00.182802  5211 main54.cpp:499] Iteration 2800, Testing net (#0)
I0612 12:47:03.423029  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.457188
I0612 12:47:03.423071  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 2.16353 (* 1 = 2.16353 loss)
I0612 12:47:05.398732  5211 main54.cpp:387] Iteration 2800, loss = 0.922823
I0612 12:47:05.398774  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.922823 (* 1 = 0.922823 loss)
I0612 12:47:05.398783  5211 sgd_solver.cpp:43] Iteration 2800, lr = 0.02
I0612 13:00:05.315493  5211 main54.cpp:499] Iteration 3200, Testing net (#0)
I0612 13:01:08.613893  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.557891
I0612 13:01:08.613936  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.54507 (* 1 = 1.54507 loss)
I0612 13:01:10.531086  5211 main54.cpp:387] Iteration 3200, loss = 0.856115
I0612 13:01:10.531121  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.856115 (* 1 = 0.856115 loss)
I0612 13:01:10.531131  5211 sgd_solver.cpp:43] Iteration 3200, lr = 0.02
I0612 13:14:11.189896  5211 main54.cpp:499] Iteration 3600, Testing net (#0)
I0612 13:15:14.445623  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.570312
I0612 13:15:14.445667  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.376 (* 1 = 1.376 loss)
I0612 13:15:16.325204  5211 main54.cpp:387] Iteration 3600, loss = 0.714875
I0612 13:15:16.325234  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.714875 (* 1 = 0.714875 loss)
I0612 13:15:16.325243  5211 sgd_solver.cpp:43] Iteration 3600, lr = 0.02
I0612 13:28:17.860304  5211 main54.cpp:499] Iteration 4000, Testing net (#0)
I0612 13:29:21.140836  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.752344
I0612 13:29:21.140877  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.753144 (* 1 = 0.753144 loss)
I0612 13:29:22.747236  5211 main54.cpp:387] Iteration 4000, loss = 0.731562
I0612 13:29:22.747272  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.731562 (* 1 = 0.731562 loss)
I0612 13:29:22.747280  5211 sgd_solver.cpp:43] Iteration 4000, lr = 0.02
I0612 13:42:27.244850  5211 main54.cpp:499] Iteration 4400, Testing net (#0)
I0612 13:43:30.488121  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.706328
I0612 13:43:30.488165  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.914276 (* 1 = 0.914276 loss)
I0612 13:43:32.603412  5211 main54.cpp:387] Iteration 4400, loss = 0.676244
I0612 13:43:32.603447  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.676244 (* 1 = 0.676244 loss)
I0612 13:43:32.603457  5211 sgd_solver.cpp:43] Iteration 4400, lr = 0.02
I0612 13:56:36.169054  5211 main54.cpp:499] Iteration 4800, Testing net (#0)
I0612 13:57:39.377104  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.63875
I0612 13:57:39.377147  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.10505 (* 1 = 1.10505 loss)
I0612 13:57:41.360574  5211 main54.cpp:387] Iteration 4800, loss = 0.719403
I0612 13:57:41.360611  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.719403 (* 1 = 0.719403 loss)
I0612 13:57:41.360620  5211 sgd_solver.cpp:43] Iteration 4800, lr = 0.02
I0612 14:10:41.405308  5211 main54.cpp:499] Iteration 5200, Testing net (#0)
I0612 14:11:44.655771  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.623125
I0612 14:11:44.655813  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.32286 (* 1 = 1.32286 loss)
I0612 14:11:46.436748  5211 main54.cpp:387] Iteration 5200, loss = 0.829517
I0612 14:11:46.436784  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.829517 (* 1 = 0.829517 loss)
I0612 14:11:46.436794  5211 sgd_solver.cpp:43] Iteration 5200, lr = 0.02
I0612 14:24:46.022936  5211 main54.cpp:499] Iteration 5600, Testing net (#0)
I0612 14:25:49.212646  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.607656
I0612 14:25:49.212688  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.28675 (* 1 = 1.28675 loss)
I0612 14:25:50.990126  5211 main54.cpp:387] Iteration 5600, loss = 0.621429
I0612 14:25:50.990169  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.621429 (* 1 = 0.621429 loss)
I0612 14:25:50.990181  5211 sgd_solver.cpp:43] Iteration 5600, lr = 0.02
I0612 14:38:56.288630  5211 main54.cpp:499] Iteration 6000, Testing net (#0)
I0612 14:39:59.558125  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.669453
I0612 14:39:59.558167  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.0088 (* 1 = 1.0088 loss)
I0612 14:40:01.401029  5211 main54.cpp:387] Iteration 6000, loss = 0.661533
I0612 14:40:01.401067  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.661533 (* 1 = 0.661533 loss)
I0612 14:40:01.401077  5211 sgd_solver.cpp:43] Iteration 6000, lr = 0.02
I0612 14:52:57.920168  5211 main54.cpp:499] Iteration 6400, Testing net (#0)
I0612 14:54:01.201215  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.630469
I0612 14:54:01.201257  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.16317 (* 1 = 1.16317 loss)
I0612 14:54:03.251925  5211 main54.cpp:387] Iteration 6400, loss = 0.57676
I0612 14:54:03.251965  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.57676 (* 1 = 0.57676 loss)
I0612 14:54:03.251976  5211 sgd_solver.cpp:43] Iteration 6400, lr = 0.02
I0612 15:07:04.910086  5211 main54.cpp:499] Iteration 6800, Testing net (#0)
I0612 15:08:08.189947  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.630781
I0612 15:08:08.189992  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.19123 (* 1 = 1.19123 loss)
I0612 15:08:09.936677  5211 main54.cpp:387] Iteration 6800, loss = 0.764797
I0612 15:08:09.936708  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.764797 (* 1 = 0.764797 loss)
I0612 15:08:09.936717  5211 sgd_solver.cpp:43] Iteration 6800, lr = 0.02
I0612 15:21:07.571391  5211 main54.cpp:499] Iteration 7200, Testing net (#0)
I0612 15:22:11.199105  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.732344
I0612 15:22:11.199158  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.804543 (* 1 = 0.804543 loss)
I0612 15:22:12.879753  5211 main54.cpp:387] Iteration 7200, loss = 0.529526
I0612 15:22:12.879788  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.529526 (* 1 = 0.529526 loss)
I0612 15:22:12.879796  5211 sgd_solver.cpp:43] Iteration 7200, lr = 0.02
I0612 15:35:17.991639  5211 main54.cpp:499] Iteration 7600, Testing net (#0)
I0612 15:36:21.713364  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.595547
I0612 15:36:21.713412  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.25245 (* 1 = 1.25245 loss)
I0612 15:36:23.396564  5211 main54.cpp:387] Iteration 7600, loss = 0.591225
I0612 15:36:23.396595  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.591225 (* 1 = 0.591225 loss)
I0612 15:36:23.396601  5211 sgd_solver.cpp:43] Iteration 7600, lr = 0.02
I0612 15:49:33.351114  5211 main54.cpp:499] Iteration 8000, Testing net (#0)
I0612 15:50:37.181272  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.589063
I0612 15:50:37.181318  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.55007 (* 1 = 1.55007 loss)
I0612 15:50:39.204907  5211 main54.cpp:387] Iteration 8000, loss = 0.349334
I0612 15:50:39.204951  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.349334 (* 1 = 0.349334 loss)
I0612 15:50:39.204958  5211 sgd_solver.cpp:43] Iteration 8000, lr = 0.02
I0612 16:03:46.250697  5211 main54.cpp:499] Iteration 8400, Testing net (#0)
I0612 16:04:49.837539  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.597734
I0612 16:04:49.837577  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.4578 (* 1 = 1.4578 loss)
I0612 16:04:51.691880  5211 main54.cpp:387] Iteration 8400, loss = 0.565215
I0612 16:04:51.691911  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.565215 (* 1 = 0.565215 loss)
I0612 16:04:51.691918  5211 sgd_solver.cpp:43] Iteration 8400, lr = 0.02
I0612 16:17:53.112733  5211 main54.cpp:499] Iteration 8800, Testing net (#0)
I0612 16:18:56.757974  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.614453
I0612 16:18:56.758013  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.30425 (* 1 = 1.30425 loss)
I0612 16:18:58.712949  5211 main54.cpp:387] Iteration 8800, loss = 0.48182
I0612 16:18:58.712976  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.48182 (* 1 = 0.48182 loss)
I0612 16:18:58.712985  5211 sgd_solver.cpp:43] Iteration 8800, lr = 0.02
I0612 16:32:02.531991  5211 main54.cpp:499] Iteration 9200, Testing net (#0)
I0612 16:33:05.871721  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.657188
I0612 16:33:05.871765  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.10328 (* 1 = 1.10328 loss)
I0612 16:33:07.615139  5211 main54.cpp:387] Iteration 9200, loss = 0.472636
I0612 16:33:07.615177  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.472636 (* 1 = 0.472636 loss)
I0612 16:33:07.615187  5211 sgd_solver.cpp:43] Iteration 9200, lr = 0.02
I0612 16:46:15.338491  5211 main54.cpp:499] Iteration 9600, Testing net (#0)
I0612 16:47:19.185600  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.782969
I0612 16:47:19.185639  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.653143 (* 1 = 0.653143 loss)
I0612 16:47:20.996140  5211 main54.cpp:387] Iteration 9600, loss = 0.425656
I0612 16:47:20.996182  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.425655 (* 1 = 0.425655 loss)
I0612 16:47:20.996191  5211 sgd_solver.cpp:43] Iteration 9600, lr = 0.02
I0612 17:00:28.487848  5211 main54.cpp:499] Iteration 10000, Testing net (#0)
I0612 17:01:32.290411  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.761875
I0612 17:01:32.290453  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.768041 (* 1 = 0.768041 loss)
I0612 17:01:34.213186  5211 main54.cpp:387] Iteration 10000, loss = 0.422904
I0612 17:01:34.213224  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.422904 (* 1 = 0.422904 loss)
I0612 17:01:34.213232  5211 sgd_solver.cpp:43] Iteration 10000, lr = 0.02
I0612 17:14:41.175786  5211 main54.cpp:499] Iteration 10400, Testing net (#0)
I0612 17:15:44.976373  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.638984
I0612 17:15:44.976418  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.24364 (* 1 = 1.24364 loss)
I0612 17:15:46.850448  5211 main54.cpp:387] Iteration 10400, loss = 0.26134
I0612 17:15:46.850486  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.26134 (* 1 = 0.26134 loss)
I0612 17:15:46.850494  5211 sgd_solver.cpp:43] Iteration 10400, lr = 0.02
I0612 17:28:56.750767  5211 main54.cpp:499] Iteration 10800, Testing net (#0)
I0612 17:30:00.561679  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.694453
I0612 17:30:00.561728  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.03596 (* 1 = 1.03596 loss)
I0612 17:30:02.565670  5211 main54.cpp:387] Iteration 10800, loss = 0.39233
I0612 17:30:02.565708  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.39233 (* 1 = 0.39233 loss)
I0612 17:30:02.565716  5211 sgd_solver.cpp:43] Iteration 10800, lr = 0.02
I0612 17:43:08.663761  5211 main54.cpp:499] Iteration 11200, Testing net (#0)
I0612 17:44:12.463542  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.672109
I0612 17:44:12.463601  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.99554 (* 1 = 0.99554 loss)
I0612 17:44:14.433333  5211 main54.cpp:387] Iteration 11200, loss = 0.45393
I0612 17:44:14.433404  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.45393 (* 1 = 0.45393 loss)
I0612 17:44:14.433415  5211 sgd_solver.cpp:43] Iteration 11200, lr = 0.02
I0612 17:57:18.334398  5211 main54.cpp:499] Iteration 11600, Testing net (#0)
I0612 17:58:22.144862  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.734766
I0612 17:58:22.144904  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.831644 (* 1 = 0.831644 loss)
I0612 17:58:24.223484  5211 main54.cpp:387] Iteration 11600, loss = 0.371763
I0612 17:58:24.223521  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.371763 (* 1 = 0.371763 loss)
I0612 17:58:24.223527  5211 sgd_solver.cpp:43] Iteration 11600, lr = 0.02
I0612 18:11:34.254988  5211 main54.cpp:499] Iteration 12000, Testing net (#0)
I0612 18:12:38.069949  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.741406
I0612 18:12:38.069993  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.79378 (* 1 = 0.79378 loss)
I0612 18:12:39.996295  5211 main54.cpp:387] Iteration 12000, loss = 0.382776
I0612 18:12:39.996332  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.382776 (* 1 = 0.382776 loss)
I0612 18:12:39.996340  5211 sgd_solver.cpp:43] Iteration 12000, lr = 0.02
I0612 18:25:48.600164  5211 main54.cpp:499] Iteration 12400, Testing net (#0)
I0612 18:26:52.423955  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.652422
I0612 18:26:52.424002  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.20973 (* 1 = 1.20973 loss)
I0612 18:26:54.501575  5211 main54.cpp:387] Iteration 12400, loss = 0.344043
I0612 18:26:54.501601  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.344043 (* 1 = 0.344043 loss)
I0612 18:26:54.501608  5211 sgd_solver.cpp:43] Iteration 12400, lr = 0.02
I0612 18:40:03.593575  5211 main54.cpp:499] Iteration 12800, Testing net (#0)
I0612 18:41:07.384888  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.757812
I0612 18:41:07.384932  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.732537 (* 1 = 0.732537 loss)
I0612 18:41:09.346560  5211 main54.cpp:387] Iteration 12800, loss = 0.322802
I0612 18:41:09.346603  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.322802 (* 1 = 0.322802 loss)
I0612 18:41:09.346611  5211 sgd_solver.cpp:43] Iteration 12800, lr = 0.02
I0612 18:54:14.296838  5211 main54.cpp:499] Iteration 13200, Testing net (#0)
I0612 18:55:18.143615  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.744687
I0612 18:55:18.143663  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.818044 (* 1 = 0.818044 loss)
I0612 18:55:20.085376  5211 main54.cpp:387] Iteration 13200, loss = 0.43866
I0612 18:55:20.085417  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.43866 (* 1 = 0.43866 loss)
I0612 18:55:20.085425  5211 sgd_solver.cpp:43] Iteration 13200, lr = 0.02
I0612 19:08:29.639947  5211 main54.cpp:499] Iteration 13600, Testing net (#0)
I0612 19:09:33.760957  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.753125
I0612 19:09:33.761001  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.822858 (* 1 = 0.822858 loss)
I0612 19:09:35.867754  5211 main54.cpp:387] Iteration 13600, loss = 0.308691
I0612 19:09:35.867792  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.308691 (* 1 = 0.308691 loss)
I0612 19:09:35.867799  5211 sgd_solver.cpp:43] Iteration 13600, lr = 0.02
I0612 19:22:46.379614  5211 main54.cpp:499] Iteration 14000, Testing net (#0)
I0612 19:23:50.512949  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.776953
I0612 19:23:50.512989  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.715604 (* 1 = 0.715604 loss)
I0612 19:23:52.592461  5211 main54.cpp:387] Iteration 14000, loss = 0.347102
I0612 19:23:52.592494  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.347102 (* 1 = 0.347102 loss)
I0612 19:23:52.592500  5211 sgd_solver.cpp:43] Iteration 14000, lr = 0.02
I0612 19:37:06.015897  5211 main54.cpp:499] Iteration 14400, Testing net (#0)
I0612 19:38:10.349304  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.821172
I0612 19:38:10.349351  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.539707 (* 1 = 0.539707 loss)
I0612 19:38:12.287802  5211 main54.cpp:387] Iteration 14400, loss = 0.34079
I0612 19:38:12.287863  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.34079 (* 1 = 0.34079 loss)
I0612 19:38:12.287876  5211 sgd_solver.cpp:43] Iteration 14400, lr = 0.02
I0612 19:51:28.177000  5211 main54.cpp:499] Iteration 14800, Testing net (#0)
I0612 19:52:32.470958  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.786406
I0612 19:52:32.471020  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.661988 (* 1 = 0.661988 loss)
I0612 19:52:34.207650  5211 main54.cpp:387] Iteration 14800, loss = 0.438716
I0612 19:52:34.207670  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.438716 (* 1 = 0.438716 loss)
I0612 19:52:34.207677  5211 sgd_solver.cpp:43] Iteration 14800, lr = 0.02
I0612 20:05:47.928445  5211 main54.cpp:499] Iteration 15200, Testing net (#0)
I0612 20:06:52.017891  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.745703
I0612 20:06:52.017937  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.796899 (* 1 = 0.796899 loss)
I0612 20:06:53.958240  5211 main54.cpp:387] Iteration 15200, loss = 0.290417
I0612 20:06:53.958272  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.290417 (* 1 = 0.290417 loss)
I0612 20:06:53.958279  5211 sgd_solver.cpp:43] Iteration 15200, lr = 0.02
I0612 20:20:05.386857  5211 main54.cpp:499] Iteration 15600, Testing net (#0)
I0612 20:21:09.047379  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.818125
I0612 20:21:09.047421  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.562473 (* 1 = 0.562473 loss)
I0612 20:21:11.110688  5211 main54.cpp:387] Iteration 15600, loss = 0.289102
I0612 20:21:11.110718  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.289101 (* 1 = 0.289101 loss)
I0612 20:21:11.110725  5211 sgd_solver.cpp:43] Iteration 15600, lr = 0.02
I0612 20:34:14.401973  5211 main54.cpp:499] Iteration 16000, Testing net (#0)
I0612 20:35:18.063302  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.817266
I0612 20:35:18.063344  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.551417 (* 1 = 0.551417 loss)
I0612 20:35:20.131422  5211 main54.cpp:387] Iteration 16000, loss = 0.295222
I0612 20:35:20.131461  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.295222 (* 1 = 0.295222 loss)
I0612 20:35:20.131469  5211 sgd_solver.cpp:43] Iteration 16000, lr = 0.02
I0612 20:48:27.897172  5211 main54.cpp:499] Iteration 16400, Testing net (#0)
I0612 20:49:32.061811  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.809766
I0612 20:49:32.061867  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.544871 (* 1 = 0.544871 loss)
I0612 20:49:33.983703  5211 main54.cpp:387] Iteration 16400, loss = 0.321162
I0612 20:49:33.983731  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.321162 (* 1 = 0.321162 loss)
I0612 20:49:33.983738  5211 sgd_solver.cpp:43] Iteration 16400, lr = 0.02
I0612 21:02:44.205202  5211 main54.cpp:499] Iteration 16800, Testing net (#0)
I0612 21:03:47.959728  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.787734
I0612 21:03:47.959770  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.674372 (* 1 = 0.674372 loss)
I0612 21:03:49.756819  5211 main54.cpp:387] Iteration 16800, loss = 0.225893
I0612 21:03:49.756868  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.225893 (* 1 = 0.225893 loss)
I0612 21:03:49.756881  5211 sgd_solver.cpp:43] Iteration 16800, lr = 0.02
I0612 21:16:59.126469  5211 main54.cpp:499] Iteration 17200, Testing net (#0)
I0612 21:18:02.827602  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.824844
I0612 21:18:02.827651  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.54467 (* 1 = 0.54467 loss)
I0612 21:18:04.583887  5211 main54.cpp:387] Iteration 17200, loss = 0.333574
I0612 21:18:04.583909  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.333573 (* 1 = 0.333573 loss)
I0612 21:18:04.583916  5211 sgd_solver.cpp:43] Iteration 17200, lr = 0.02
I0612 21:31:07.591737  5211 main54.cpp:499] Iteration 17600, Testing net (#0)
I0612 21:32:11.326200  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.818594
I0612 21:32:11.326242  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.579981 (* 1 = 0.579981 loss)
I0612 21:32:13.243861  5211 main54.cpp:387] Iteration 17600, loss = 0.27629
I0612 21:32:13.243896  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.276289 (* 1 = 0.276289 loss)
I0612 21:32:13.243904  5211 sgd_solver.cpp:43] Iteration 17600, lr = 0.02
I0612 21:45:16.740941  5211 main54.cpp:499] Iteration 18000, Testing net (#0)
I0612 21:46:20.591534  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.755234
I0612 21:46:20.591583  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.799934 (* 1 = 0.799934 loss)
I0612 21:46:22.550272  5211 main54.cpp:387] Iteration 18000, loss = 0.283486
I0612 21:46:22.550304  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.283486 (* 1 = 0.283486 loss)
I0612 21:46:22.550310  5211 sgd_solver.cpp:43] Iteration 18000, lr = 0.02
I0612 21:59:32.998627  5211 main54.cpp:499] Iteration 18400, Testing net (#0)
I0612 22:00:36.582849  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.796484
I0612 22:00:36.582895  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.610201 (* 1 = 0.610201 loss)
I0612 22:00:38.651365  5211 main54.cpp:387] Iteration 18400, loss = 0.209168
I0612 22:00:38.651399  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.209168 (* 1 = 0.209168 loss)
I0612 22:00:38.651407  5211 sgd_solver.cpp:43] Iteration 18400, lr = 0.02
I0612 22:13:49.925248  5211 main54.cpp:499] Iteration 18800, Testing net (#0)
I0612 22:14:53.546492  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.825078
I0612 22:14:53.546535  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.525472 (* 1 = 0.525472 loss)
I0612 22:14:55.509479  5211 main54.cpp:387] Iteration 18800, loss = 0.173081
I0612 22:14:55.509510  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.173081 (* 1 = 0.173081 loss)
I0612 22:14:55.509516  5211 sgd_solver.cpp:43] Iteration 18800, lr = 0.02
I0612 22:28:03.418489  5211 main54.cpp:499] Iteration 19200, Testing net (#0)
I0612 22:29:07.174846  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.767344
I0612 22:29:07.174888  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.747064 (* 1 = 0.747064 loss)
I0612 22:29:09.190183  5211 main54.cpp:387] Iteration 19200, loss = 0.244868
I0612 22:29:09.190206  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.244868 (* 1 = 0.244868 loss)
I0612 22:29:09.190212  5211 sgd_solver.cpp:43] Iteration 19200, lr = 0.02
I0612 22:42:19.845296  5211 main54.cpp:499] Iteration 19600, Testing net (#0)
I0612 22:43:23.328672  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.684219
I0612 22:43:23.328716  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.14199 (* 1 = 1.14199 loss)
I0612 22:43:25.470021  5211 main54.cpp:387] Iteration 19600, loss = 0.226616
I0612 22:43:25.470047  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.226615 (* 1 = 0.226615 loss)
I0612 22:43:25.470054  5211 sgd_solver.cpp:43] Iteration 19600, lr = 0.02
I0612 22:56:36.809906  5211 main54.cpp:499] Iteration 20000, Testing net (#0)
I0612 22:57:40.579756  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.681953
I0612 22:57:40.579798  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.22776 (* 1 = 1.22776 loss)
I0612 22:57:42.626008  5211 main54.cpp:387] Iteration 20000, loss = 0.163932
I0612 22:57:42.626040  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.163932 (* 1 = 0.163932 loss)
I0612 22:57:42.626049  5211 sgd_solver.cpp:43] Iteration 20000, lr = 0.02
I0612 23:10:48.398641  5211 main54.cpp:499] Iteration 20400, Testing net (#0)
I0612 23:11:52.798362  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.827109
I0612 23:11:52.798406  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.545803 (* 1 = 0.545803 loss)
I0612 23:11:54.652969  5211 main54.cpp:387] Iteration 20400, loss = 0.133545
I0612 23:11:54.653014  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.133544 (* 1 = 0.133544 loss)
I0612 23:11:54.653028  5211 sgd_solver.cpp:43] Iteration 20400, lr = 0.02
I0612 23:24:59.198325  5211 main54.cpp:499] Iteration 20800, Testing net (#0)
I0612 23:26:03.563082  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.824219
I0612 23:26:03.563133  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.528013 (* 1 = 0.528013 loss)
I0612 23:26:05.519037  5211 main54.cpp:387] Iteration 20800, loss = 0.291429
I0612 23:26:05.519076  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.291429 (* 1 = 0.291429 loss)
I0612 23:26:05.519083  5211 sgd_solver.cpp:43] Iteration 20800, lr = 0.02
I0612 23:39:17.845857  5211 main54.cpp:499] Iteration 21200, Testing net (#0)
I0612 23:40:21.772781  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.751328
I0612 23:40:21.772822  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.811748 (* 1 = 0.811748 loss)
I0612 23:40:23.685938  5211 main54.cpp:387] Iteration 21200, loss = 0.287774
I0612 23:40:23.685984  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.287773 (* 1 = 0.287773 loss)
I0612 23:40:23.685992  5211 sgd_solver.cpp:43] Iteration 21200, lr = 0.02
I0612 23:53:29.670801  5211 main54.cpp:499] Iteration 21600, Testing net (#0)
I0612 23:54:33.819643  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.733594
I0612 23:54:33.819710  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.912289 (* 1 = 0.912289 loss)
I0612 23:54:35.661911  5211 main54.cpp:387] Iteration 21600, loss = 0.273619
I0612 23:54:35.661947  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.273618 (* 1 = 0.273618 loss)
I0612 23:54:35.661953  5211 sgd_solver.cpp:43] Iteration 21600, lr = 0.02
I0613 00:07:34.230561  5211 main54.cpp:499] Iteration 22000, Testing net (#0)
I0613 00:08:37.835093  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.729219
I0613 00:08:37.835134  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.93845 (* 1 = 0.93845 loss)
I0613 00:08:39.752290  5211 main54.cpp:387] Iteration 22000, loss = 0.334317
I0613 00:08:39.752327  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.334316 (* 1 = 0.334316 loss)
I0613 00:08:39.752336  5211 sgd_solver.cpp:43] Iteration 22000, lr = 0.02
I0613 00:21:42.037287  5211 main54.cpp:499] Iteration 22400, Testing net (#0)
I0613 00:22:45.368077  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.749609
I0613 00:22:45.368124  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.957857 (* 1 = 0.957857 loss)
I0613 00:22:47.249774  5211 main54.cpp:387] Iteration 22400, loss = 0.349908
I0613 00:22:47.249812  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.349907 (* 1 = 0.349907 loss)
I0613 00:22:47.249819  5211 sgd_solver.cpp:43] Iteration 22400, lr = 0.02
I0613 00:35:53.132730  5211 main54.cpp:499] Iteration 22800, Testing net (#0)
I0613 00:36:56.716332  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.771797
I0613 00:36:56.716375  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.792783 (* 1 = 0.792783 loss)
I0613 00:36:58.586726  5211 main54.cpp:387] Iteration 22800, loss = 0.355683
I0613 00:36:58.586769  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.355682 (* 1 = 0.355682 loss)
I0613 00:36:58.586776  5211 sgd_solver.cpp:43] Iteration 22800, lr = 0.02
I0613 00:50:04.539281  5211 main54.cpp:499] Iteration 23200, Testing net (#0)
I0613 00:51:08.449586  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.801016
I0613 00:51:08.449632  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.67703 (* 1 = 0.67703 loss)
I0613 00:51:10.557277  5211 main54.cpp:387] Iteration 23200, loss = 0.114631
I0613 00:51:10.557323  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.114631 (* 1 = 0.114631 loss)
I0613 00:51:10.557329  5211 sgd_solver.cpp:43] Iteration 23200, lr = 0.02
I0613 01:04:17.286053  5211 main54.cpp:499] Iteration 23600, Testing net (#0)
I0613 01:05:20.878756  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.838906
I0613 01:05:20.878803  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.478648 (* 1 = 0.478648 loss)
I0613 01:05:22.809273  5211 main54.cpp:387] Iteration 23600, loss = 0.147597
I0613 01:05:22.809324  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.147596 (* 1 = 0.147596 loss)
I0613 01:05:22.809331  5211 sgd_solver.cpp:43] Iteration 23600, lr = 0.02
I0613 01:18:30.710163  5211 main54.cpp:499] Iteration 24000, Testing net (#0)
I0613 01:19:34.735280  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.803828
I0613 01:19:34.735334  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.646955 (* 1 = 0.646955 loss)
I0613 01:19:36.755265  5211 main54.cpp:387] Iteration 24000, loss = 0.168011
I0613 01:19:36.755298  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.168011 (* 1 = 0.168011 loss)
I0613 01:19:36.755306  5211 sgd_solver.cpp:43] Iteration 24000, lr = 0.02
I0613 01:32:45.329329  5211 main54.cpp:499] Iteration 24400, Testing net (#0)
I0613 01:33:49.109386  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.81
I0613 01:33:49.109431  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.637158 (* 1 = 0.637158 loss)
I0613 01:33:50.831634  5211 main54.cpp:387] Iteration 24400, loss = 0.256159
I0613 01:33:50.831665  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.256158 (* 1 = 0.256158 loss)
I0613 01:33:50.831673  5211 sgd_solver.cpp:43] Iteration 24400, lr = 0.02
I0613 01:46:59.041862  5211 main54.cpp:499] Iteration 24800, Testing net (#0)
I0613 01:48:02.916947  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.706953
I0613 01:48:02.916986  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.10049 (* 1 = 1.10049 loss)
I0613 01:48:05.008539  5211 main54.cpp:387] Iteration 24800, loss = 0.26228
I0613 01:48:05.008575  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.262279 (* 1 = 0.262279 loss)
I0613 01:48:05.008584  5211 sgd_solver.cpp:43] Iteration 24800, lr = 0.02
I0613 02:01:11.440616  5211 main54.cpp:499] Iteration 25200, Testing net (#0)
I0613 02:02:15.643573  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.809141
I0613 02:02:15.643620  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.693102 (* 1 = 0.693102 loss)
I0613 02:02:17.525557  5211 main54.cpp:387] Iteration 25200, loss = 0.339977
I0613 02:02:17.525607  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.339977 (* 1 = 0.339977 loss)
I0613 02:02:17.525619  5211 sgd_solver.cpp:43] Iteration 25200, lr = 0.02
I0613 02:15:21.551702  5211 main54.cpp:499] Iteration 25600, Testing net (#0)
I0613 02:16:25.798002  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.819609
I0613 02:16:25.798053  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.571696 (* 1 = 0.571696 loss)
I0613 02:16:27.729346  5211 main54.cpp:387] Iteration 25600, loss = 0.344994
I0613 02:16:27.729388  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.344993 (* 1 = 0.344993 loss)
I0613 02:16:27.729396  5211 sgd_solver.cpp:43] Iteration 25600, lr = 0.02
I0613 02:29:39.213932  5211 main54.cpp:499] Iteration 26000, Testing net (#0)
I0613 02:30:43.777580  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.8475
I0613 02:30:43.777624  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.485416 (* 1 = 0.485416 loss)
I0613 02:30:45.753584  5211 main54.cpp:387] Iteration 26000, loss = 0.164746
I0613 02:30:45.753626  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.164746 (* 1 = 0.164746 loss)
I0613 02:30:45.753635  5211 sgd_solver.cpp:43] Iteration 26000, lr = 0.02
I0613 02:43:55.442917  5211 main54.cpp:499] Iteration 26400, Testing net (#0)
I0613 02:44:59.554934  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.790313
I0613 02:44:59.554993  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.778087 (* 1 = 0.778087 loss)
I0613 02:45:01.482303  5211 main54.cpp:387] Iteration 26400, loss = 0.280221
I0613 02:45:01.482350  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.280221 (* 1 = 0.280221 loss)
I0613 02:45:01.482369  5211 sgd_solver.cpp:43] Iteration 26400, lr = 0.02
I0613 02:58:08.488366  5211 main54.cpp:499] Iteration 26800, Testing net (#0)
I0613 02:59:12.065717  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.821406
I0613 02:59:12.065781  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.550471 (* 1 = 0.550471 loss)
I0613 02:59:14.091748  5211 main54.cpp:387] Iteration 26800, loss = 0.206024
I0613 02:59:14.091794  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.206024 (* 1 = 0.206024 loss)
I0613 02:59:14.091804  5211 sgd_solver.cpp:43] Iteration 26800, lr = 0.02
I0613 03:12:19.819020  5211 main54.cpp:499] Iteration 27200, Testing net (#0)
I0613 03:13:24.044679  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.833984
I0613 03:13:24.044718  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.56244 (* 1 = 0.56244 loss)
I0613 03:13:25.963407  5211 main54.cpp:387] Iteration 27200, loss = 0.232488
I0613 03:13:25.963441  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.232488 (* 1 = 0.232488 loss)
I0613 03:13:25.963449  5211 sgd_solver.cpp:43] Iteration 27200, lr = 0.02
I0613 03:26:34.521168  5211 main54.cpp:499] Iteration 27600, Testing net (#0)
I0613 03:27:38.274117  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.813906
I0613 03:27:38.274158  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.610969 (* 1 = 0.610969 loss)
I0613 03:27:40.401906  5211 main54.cpp:387] Iteration 27600, loss = 0.384179
I0613 03:27:40.401942  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.384178 (* 1 = 0.384178 loss)
I0613 03:27:40.401958  5211 sgd_solver.cpp:43] Iteration 27600, lr = 0.02
I0613 03:40:39.618971  5211 main54.cpp:499] Iteration 28000, Testing net (#0)
I0613 03:41:43.251130  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.788984
I0613 03:41:43.251180  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.762626 (* 1 = 0.762626 loss)
I0613 03:41:45.262181  5211 main54.cpp:387] Iteration 28000, loss = 0.141482
I0613 03:41:45.262220  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.141482 (* 1 = 0.141482 loss)
I0613 03:41:45.262230  5211 sgd_solver.cpp:43] Iteration 28000, lr = 0.02
I0613 03:54:55.192525  5211 main54.cpp:499] Iteration 28400, Testing net (#0)
I0613 03:55:59.290482  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.847891
I0613 03:55:59.290524  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.480728 (* 1 = 0.480728 loss)
I0613 03:56:01.280002  5211 main54.cpp:387] Iteration 28400, loss = 0.106958
I0613 03:56:01.280036  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.106958 (* 1 = 0.106958 loss)
I0613 03:56:01.280045  5211 sgd_solver.cpp:43] Iteration 28400, lr = 0.02
I0613 04:09:05.829740  5211 main54.cpp:499] Iteration 28800, Testing net (#0)
I0613 04:10:09.794497  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.842578
I0613 04:10:09.794541  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.472267 (* 1 = 0.472267 loss)
I0613 04:10:11.612673  5211 main54.cpp:387] Iteration 28800, loss = 0.348692
I0613 04:10:11.612731  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.348691 (* 1 = 0.348691 loss)
I0613 04:10:11.612743  5211 sgd_solver.cpp:43] Iteration 28800, lr = 0.02
I0613 04:23:20.190323  5211 main54.cpp:499] Iteration 29200, Testing net (#0)
I0613 04:24:24.352278  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.814219
I0613 04:24:24.352329  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.566562 (* 1 = 0.566562 loss)
I0613 04:24:26.401463  5211 main54.cpp:387] Iteration 29200, loss = 0.154929
I0613 04:24:26.401522  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.154929 (* 1 = 0.154929 loss)
I0613 04:24:26.401530  5211 sgd_solver.cpp:43] Iteration 29200, lr = 0.02
I0613 04:37:31.462851  5211 main54.cpp:499] Iteration 29600, Testing net (#0)
I0613 04:38:35.250555  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.86
I0613 04:38:35.250602  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.448872 (* 1 = 0.448872 loss)
I0613 04:38:37.167958  5211 main54.cpp:387] Iteration 29600, loss = 0.194326
I0613 04:38:37.167989  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.194325 (* 1 = 0.194325 loss)
I0613 04:38:37.167995  5211 sgd_solver.cpp:43] Iteration 29600, lr = 0.02
I0613 04:51:44.660624  5211 main54.cpp:499] Iteration 30000, Testing net (#0)
I0613 04:52:48.407311  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.804219
I0613 04:52:48.407359  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.685203 (* 1 = 0.685203 loss)
I0613 04:52:50.522054  5211 main54.cpp:387] Iteration 30000, loss = 0.111126
I0613 04:52:50.522094  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.111125 (* 1 = 0.111125 loss)
I0613 04:52:50.522101  5211 sgd_solver.cpp:43] Iteration 30000, lr = 0.02
I0613 05:06:00.175618  5211 main54.cpp:499] Iteration 30400, Testing net (#0)
I0613 05:07:03.817677  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.829766
I0613 05:07:03.817716  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.55887 (* 1 = 0.55887 loss)
I0613 05:07:05.966852  5211 main54.cpp:387] Iteration 30400, loss = 0.14208
I0613 05:07:05.966888  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.14208 (* 1 = 0.14208 loss)
I0613 05:07:05.966895  5211 sgd_solver.cpp:43] Iteration 30400, lr = 0.02
I0613 05:20:13.201084  5211 main54.cpp:499] Iteration 30800, Testing net (#0)
I0613 05:21:16.816069  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.857422
I0613 05:21:16.816113  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.45041 (* 1 = 0.45041 loss)
I0613 05:21:18.732733  5211 main54.cpp:387] Iteration 30800, loss = 0.119455
I0613 05:21:18.732774  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.119454 (* 1 = 0.119454 loss)
I0613 05:21:18.732781  5211 sgd_solver.cpp:43] Iteration 30800, lr = 0.02
I0613 05:34:25.967629  5211 main54.cpp:499] Iteration 31200, Testing net (#0)
I0613 05:35:29.899706  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.802344
I0613 05:35:29.899747  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.724036 (* 1 = 0.724036 loss)
I0613 05:35:31.863144  5211 main54.cpp:387] Iteration 31200, loss = 0.198968
I0613 05:35:31.863185  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.198967 (* 1 = 0.198967 loss)
I0613 05:35:31.863191  5211 sgd_solver.cpp:43] Iteration 31200, lr = 0.02
I0613 05:48:36.136631  5211 main54.cpp:499] Iteration 31600, Testing net (#0)
I0613 05:49:40.439038  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.861562
I0613 05:49:40.439087  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.444182 (* 1 = 0.444182 loss)
I0613 05:49:42.498029  5211 main54.cpp:387] Iteration 31600, loss = 0.182522
I0613 05:49:42.498076  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.182522 (* 1 = 0.182522 loss)
I0613 05:49:42.498086  5211 sgd_solver.cpp:43] Iteration 31600, lr = 0.02
I0613 06:02:51.916442  5211 main54.cpp:499] Iteration 32000, Testing net (#0)
I0613 06:03:56.607986  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.85125
I0613 06:03:56.608019  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.501134 (* 1 = 0.501134 loss)
I0613 06:03:58.540505  5211 main54.cpp:387] Iteration 32000, loss = 0.237233
I0613 06:03:58.540529  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.237233 (* 1 = 0.237233 loss)
I0613 06:03:58.540534  5211 sgd_solver.cpp:43] Iteration 32000, lr = 0.02
I0613 06:17:10.848790  5211 main54.cpp:499] Iteration 32400, Testing net (#0)
I0613 06:18:14.590937  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.819297
I0613 06:18:14.590994  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.652346 (* 1 = 0.652346 loss)
I0613 06:18:16.523187  5211 main54.cpp:387] Iteration 32400, loss = 0.18766
I0613 06:18:16.523239  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.187659 (* 1 = 0.187659 loss)
I0613 06:18:16.523252  5211 sgd_solver.cpp:43] Iteration 32400, lr = 0.02
I0613 06:31:24.889660  5211 main54.cpp:499] Iteration 32800, Testing net (#0)
I0613 06:32:28.551618  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.856641
I0613 06:32:28.551661  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.478087 (* 1 = 0.478087 loss)
I0613 06:32:30.640547  5211 main54.cpp:387] Iteration 32800, loss = 0.139383
I0613 06:32:30.640580  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.139383 (* 1 = 0.139383 loss)
I0613 06:32:30.640589  5211 sgd_solver.cpp:43] Iteration 32800, lr = 0.02
I0613 06:45:36.435690  5211 main54.cpp:499] Iteration 33200, Testing net (#0)
I0613 06:46:40.198557  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.849766
I0613 06:46:40.198603  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.525009 (* 1 = 0.525009 loss)
I0613 06:46:42.191926  5211 main54.cpp:387] Iteration 33200, loss = 0.139769
I0613 06:46:42.191954  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.139769 (* 1 = 0.139769 loss)
I0613 06:46:42.191962  5211 sgd_solver.cpp:43] Iteration 33200, lr = 0.02
I0613 06:59:49.768981  5211 main54.cpp:499] Iteration 33600, Testing net (#0)
I0613 07:00:54.043148  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.858516
I0613 07:00:54.043212  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.476876 (* 1 = 0.476876 loss)
I0613 07:00:56.077023  5211 main54.cpp:387] Iteration 33600, loss = 0.227445
I0613 07:00:56.077051  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.227445 (* 1 = 0.227445 loss)
I0613 07:00:56.077059  5211 sgd_solver.cpp:43] Iteration 33600, lr = 0.02
I0613 07:14:16.157192  5211 main54.cpp:499] Iteration 34000, Testing net (#0)
I0613 07:15:19.917659  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.853984
I0613 07:15:19.917702  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.505379 (* 1 = 0.505379 loss)
I0613 07:15:21.766953  5211 main54.cpp:387] Iteration 34000, loss = 0.285017
I0613 07:15:21.766989  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.285016 (* 1 = 0.285016 loss)
I0613 07:15:21.766996  5211 sgd_solver.cpp:43] Iteration 34000, lr = 0.02
I0613 07:28:28.477272  5211 main54.cpp:499] Iteration 34400, Testing net (#0)
I0613 07:29:32.053807  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.791328
I0613 07:29:32.053848  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.78443 (* 1 = 0.78443 loss)
I0613 07:29:33.942116  5211 main54.cpp:387] Iteration 34400, loss = 0.183288
I0613 07:29:33.942159  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.183288 (* 1 = 0.183288 loss)
I0613 07:29:33.942168  5211 sgd_solver.cpp:43] Iteration 34400, lr = 0.02
I0613 07:42:43.944531  5211 main54.cpp:499] Iteration 34800, Testing net (#0)
I0613 07:43:48.220652  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.820234
I0613 07:43:48.220700  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.615416 (* 1 = 0.615416 loss)
I0613 07:43:50.216284  5211 main54.cpp:387] Iteration 34800, loss = 0.11347
I0613 07:43:50.216330  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.113469 (* 1 = 0.113469 loss)
I0613 07:43:50.216344  5211 sgd_solver.cpp:43] Iteration 34800, lr = 0.02
I0613 07:57:05.953466  5211 main54.cpp:499] Iteration 35200, Testing net (#0)
I0613 07:58:10.031519  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.806016
I0613 07:58:10.031563  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.715611 (* 1 = 0.715611 loss)
I0613 07:58:11.957324  5211 main54.cpp:387] Iteration 35200, loss = 0.147137
I0613 07:58:11.957366  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.147136 (* 1 = 0.147136 loss)
I0613 07:58:11.957377  5211 sgd_solver.cpp:43] Iteration 35200, lr = 0.02
I0613 08:11:27.094252  5211 main54.cpp:499] Iteration 35600, Testing net (#0)
I0613 08:12:30.870628  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.883281
I0613 08:12:30.870667  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.400093 (* 1 = 0.400093 loss)
I0613 08:12:32.540199  5211 main54.cpp:387] Iteration 35600, loss = 0.332152
I0613 08:12:32.540241  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.332151 (* 1 = 0.332151 loss)
I0613 08:12:32.540251  5211 sgd_solver.cpp:43] Iteration 35600, lr = 0.02
I0613 08:25:43.190408  5211 main54.cpp:499] Iteration 36000, Testing net (#0)
I0613 08:26:48.127893  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.786016
I0613 08:26:48.127941  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.794817 (* 1 = 0.794817 loss)
I0613 08:26:49.980449  5211 main54.cpp:387] Iteration 36000, loss = 0.184833
I0613 08:26:49.980471  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.184832 (* 1 = 0.184832 loss)
I0613 08:26:49.980479  5211 sgd_solver.cpp:43] Iteration 36000, lr = 0.02
I0613 08:40:02.232974  5211 main54.cpp:499] Iteration 36400, Testing net (#0)
I0613 08:41:06.455840  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.827266
I0613 08:41:06.455885  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.590843 (* 1 = 0.590843 loss)
I0613 08:41:08.277149  5211 main54.cpp:387] Iteration 36400, loss = 0.199602
I0613 08:41:08.277185  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.199601 (* 1 = 0.199601 loss)
I0613 08:41:08.277192  5211 sgd_solver.cpp:43] Iteration 36400, lr = 0.02
I0613 08:54:13.093152  5211 main54.cpp:499] Iteration 36800, Testing net (#0)
I0613 08:55:17.219884  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.797422
I0613 08:55:17.219930  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.792609 (* 1 = 0.792609 loss)
I0613 08:55:19.145028  5211 main54.cpp:387] Iteration 36800, loss = 0.185217
I0613 08:55:19.145057  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.185216 (* 1 = 0.185216 loss)
I0613 08:55:19.145066  5211 sgd_solver.cpp:43] Iteration 36800, lr = 0.02
I0613 09:08:26.995062  5211 main54.cpp:499] Iteration 37200, Testing net (#0)
I0613 09:09:31.472151  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.876094
I0613 09:09:31.472208  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.408409 (* 1 = 0.408409 loss)
I0613 09:09:33.348938  5211 main54.cpp:387] Iteration 37200, loss = 0.284574
I0613 09:09:33.348978  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.284573 (* 1 = 0.284573 loss)
I0613 09:09:33.348986  5211 sgd_solver.cpp:43] Iteration 37200, lr = 0.02
I0613 09:22:48.918612  5211 main54.cpp:499] Iteration 37600, Testing net (#0)
I0613 09:23:52.946976  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.841406
I0613 09:23:52.947032  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.543672 (* 1 = 0.543672 loss)
I0613 09:23:54.919003  5211 main54.cpp:387] Iteration 37600, loss = 0.0581033
I0613 09:23:54.919034  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0581029 (* 1 = 0.0581029 loss)
I0613 09:23:54.919039  5211 sgd_solver.cpp:43] Iteration 37600, lr = 0.02
I0613 09:37:03.738889  5211 main54.cpp:499] Iteration 38000, Testing net (#0)
I0613 09:38:08.084043  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.806641
I0613 09:38:08.084094  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.696048 (* 1 = 0.696048 loss)
I0613 09:38:10.230234  5211 main54.cpp:387] Iteration 38000, loss = 0.157448
I0613 09:38:10.230273  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.157447 (* 1 = 0.157447 loss)
I0613 09:38:10.230280  5211 sgd_solver.cpp:43] Iteration 38000, lr = 0.02
I0613 09:51:18.645743  5211 main54.cpp:499] Iteration 38400, Testing net (#0)
I0613 09:52:22.706372  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.862188
I0613 09:52:22.706420  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.443461 (* 1 = 0.443461 loss)
I0613 09:52:24.721849  5211 main54.cpp:387] Iteration 38400, loss = 0.13142
I0613 09:52:24.721873  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.13142 (* 1 = 0.13142 loss)
I0613 09:52:24.721879  5211 sgd_solver.cpp:43] Iteration 38400, lr = 0.02
I0613 10:05:38.094897  5211 main54.cpp:499] Iteration 38800, Testing net (#0)
I0613 10:06:42.300120  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.825312
I0613 10:06:42.300163  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.581636 (* 1 = 0.581636 loss)
I0613 10:06:44.199837  5211 main54.cpp:387] Iteration 38800, loss = 0.119842
I0613 10:06:44.199878  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.119842 (* 1 = 0.119842 loss)
I0613 10:06:44.199887  5211 sgd_solver.cpp:43] Iteration 38800, lr = 0.02
I0613 10:19:53.646787  5211 main54.cpp:499] Iteration 39200, Testing net (#0)
I0613 10:20:57.689900  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.850312
I0613 10:20:57.689945  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.474787 (* 1 = 0.474787 loss)
I0613 10:20:59.806154  5211 main54.cpp:387] Iteration 39200, loss = 0.110425
I0613 10:20:59.806185  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.110425 (* 1 = 0.110425 loss)
I0613 10:20:59.806193  5211 sgd_solver.cpp:43] Iteration 39200, lr = 0.02
I0613 10:34:08.531522  5211 main54.cpp:499] Iteration 39600, Testing net (#0)
I0613 10:35:12.005923  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.844375
I0613 10:35:12.005972  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.509325 (* 1 = 0.509325 loss)
I0613 10:35:13.986235  5211 main54.cpp:387] Iteration 39600, loss = 0.0571919
I0613 10:35:13.986281  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0571916 (* 1 = 0.0571916 loss)
I0613 10:35:13.986289  5211 sgd_solver.cpp:43] Iteration 39600, lr = 0.02
I0613 10:48:14.659226  5211 main54.cpp:499] Iteration 40000, Testing net (#0)
I0613 10:49:17.959966  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.798437
I0613 10:49:17.960008  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.740074 (* 1 = 0.740074 loss)
I0613 10:49:19.980379  5211 main54.cpp:387] Iteration 40000, loss = 0.128702
I0613 10:49:19.980414  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.128701 (* 1 = 0.128701 loss)
I0613 10:49:19.980422  5211 sgd_solver.cpp:43] Iteration 40000, lr = 0.02
I0613 11:02:18.540565  5211 main54.cpp:499] Iteration 40400, Testing net (#0)
I0613 11:03:21.866814  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.842969
I0613 11:03:21.866860  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.521754 (* 1 = 0.521754 loss)
I0613 11:03:23.676306  5211 main54.cpp:387] Iteration 40400, loss = 0.174827
I0613 11:03:23.676343  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.174826 (* 1 = 0.174826 loss)
I0613 11:03:23.676350  5211 sgd_solver.cpp:43] Iteration 40400, lr = 0.02
I0613 11:16:27.486003  5211 main54.cpp:499] Iteration 40800, Testing net (#0)
I0613 11:17:31.302526  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.875313
I0613 11:17:31.302570  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.444113 (* 1 = 0.444113 loss)
I0613 11:17:33.235611  5211 main54.cpp:387] Iteration 40800, loss = 0.104584
I0613 11:17:33.235651  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.104583 (* 1 = 0.104583 loss)
I0613 11:17:33.235658  5211 sgd_solver.cpp:43] Iteration 40800, lr = 0.02
I0613 11:30:43.906430  5211 main54.cpp:499] Iteration 41200, Testing net (#0)
I0613 11:31:47.691628  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.860547
I0613 11:31:47.691668  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.481512 (* 1 = 0.481512 loss)
I0613 11:31:49.585302  5211 main54.cpp:387] Iteration 41200, loss = 0.184911
I0613 11:31:49.585343  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.18491 (* 1 = 0.18491 loss)
I0613 11:31:49.585350  5211 sgd_solver.cpp:43] Iteration 41200, lr = 0.02
I0613 11:44:56.325290  5211 main54.cpp:499] Iteration 41600, Testing net (#0)
I0613 11:46:00.179558  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.852344
I0613 11:46:00.179602  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.500418 (* 1 = 0.500418 loss)
I0613 11:46:02.046510  5211 main54.cpp:387] Iteration 41600, loss = 0.209857
I0613 11:46:02.046546  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.209856 (* 1 = 0.209856 loss)
I0613 11:46:02.046555  5211 sgd_solver.cpp:43] Iteration 41600, lr = 0.02
I0613 11:59:13.415552  5211 main54.cpp:499] Iteration 42000, Testing net (#0)
I0613 12:00:17.274606  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.874687
I0613 12:00:17.274646  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.425409 (* 1 = 0.425409 loss)
I0613 12:00:19.033987  5211 main54.cpp:387] Iteration 42000, loss = 0.124572
I0613 12:00:19.034029  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.124572 (* 1 = 0.124572 loss)
I0613 12:00:19.034039  5211 sgd_solver.cpp:43] Iteration 42000, lr = 0.02
I0613 12:13:28.023772  5211 main54.cpp:499] Iteration 42400, Testing net (#0)
I0613 12:14:31.840723  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.871406
I0613 12:14:31.840769  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.445755 (* 1 = 0.445755 loss)
I0613 12:14:33.563287  5211 main54.cpp:387] Iteration 42400, loss = 0.14634
I0613 12:14:33.563321  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.146339 (* 1 = 0.146339 loss)
I0613 12:14:33.563329  5211 sgd_solver.cpp:43] Iteration 42400, lr = 0.02
I0613 12:27:39.900024  5211 main54.cpp:499] Iteration 42800, Testing net (#0)
I0613 12:28:43.626785  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.831875
I0613 12:28:43.626828  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.641798 (* 1 = 0.641798 loss)
I0613 12:28:45.455725  5211 main54.cpp:387] Iteration 42800, loss = 0.208555
I0613 12:28:45.455770  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.208555 (* 1 = 0.208555 loss)
I0613 12:28:45.455777  5211 sgd_solver.cpp:43] Iteration 42800, lr = 0.02
I0613 12:41:51.989869  5211 main54.cpp:499] Iteration 43200, Testing net (#0)
I0613 12:42:55.771136  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.880781
I0613 12:42:55.771181  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.39377 (* 1 = 0.39377 loss)
I0613 12:42:57.799096  5211 main54.cpp:387] Iteration 43200, loss = 0.164116
I0613 12:42:57.799127  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.164116 (* 1 = 0.164116 loss)
I0613 12:42:57.799134  5211 sgd_solver.cpp:43] Iteration 43200, lr = 0.02
I0613 12:56:03.944126  5211 main54.cpp:499] Iteration 43600, Testing net (#0)
I0613 12:57:07.848335  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.872891
I0613 12:57:07.848386  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.435325 (* 1 = 0.435325 loss)
I0613 12:57:09.920204  5211 main54.cpp:387] Iteration 43600, loss = 0.113639
I0613 12:57:09.920250  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.113638 (* 1 = 0.113638 loss)
I0613 12:57:09.920260  5211 sgd_solver.cpp:43] Iteration 43600, lr = 0.02
I0613 13:10:16.046027  5211 main54.cpp:499] Iteration 44000, Testing net (#0)
I0613 13:11:19.396792  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.8425
I0613 13:11:19.396837  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.546264 (* 1 = 0.546264 loss)
I0613 13:11:21.314107  5211 main54.cpp:387] Iteration 44000, loss = 0.0948213
I0613 13:11:21.314146  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0948208 (* 1 = 0.0948208 loss)
I0613 13:11:21.314154  5211 sgd_solver.cpp:43] Iteration 44000, lr = 0.02
I0613 13:24:22.382683  5211 main54.cpp:499] Iteration 44400, Testing net (#0)
I0613 13:25:25.760964  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.844141
I0613 13:25:25.761008  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.593085 (* 1 = 0.593085 loss)
I0613 13:25:27.599458  5211 main54.cpp:387] Iteration 44400, loss = 0.297108
I0613 13:25:27.599503  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.297108 (* 1 = 0.297108 loss)
I0613 13:25:27.599510  5211 sgd_solver.cpp:43] Iteration 44400, lr = 0.02
I0613 13:38:39.268776  5211 main54.cpp:499] Iteration 44800, Testing net (#0)
I0613 13:39:43.112715  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.875703
I0613 13:39:43.112759  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.427631 (* 1 = 0.427631 loss)
I0613 13:39:44.882459  5211 main54.cpp:387] Iteration 44800, loss = 0.133973
I0613 13:39:44.882501  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.133973 (* 1 = 0.133973 loss)
I0613 13:39:44.882509  5211 sgd_solver.cpp:43] Iteration 44800, lr = 0.02
I0613 13:52:52.350371  5211 main54.cpp:499] Iteration 45200, Testing net (#0)
I0613 13:53:56.236212  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.889609
I0613 13:53:56.236253  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.383178 (* 1 = 0.383178 loss)
I0613 13:53:57.806818  5211 main54.cpp:387] Iteration 45200, loss = 0.274199
I0613 13:53:57.806867  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.274198 (* 1 = 0.274198 loss)
I0613 13:53:57.806877  5211 sgd_solver.cpp:43] Iteration 45200, lr = 0.02
I0613 14:07:08.189790  5211 main54.cpp:499] Iteration 45600, Testing net (#0)
I0613 14:08:12.034039  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.863984
I0613 14:08:12.034080  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.466636 (* 1 = 0.466636 loss)
I0613 14:08:14.108470  5211 main54.cpp:387] Iteration 45600, loss = 0.111951
I0613 14:08:14.108517  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.11195 (* 1 = 0.11195 loss)
I0613 14:08:14.108525  5211 sgd_solver.cpp:43] Iteration 45600, lr = 0.02
I0613 14:21:22.923187  5211 main54.cpp:499] Iteration 46000, Testing net (#0)
I0613 14:22:26.819182  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.862656
I0613 14:22:26.819229  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.535681 (* 1 = 0.535681 loss)
I0613 14:22:28.870151  5211 main54.cpp:387] Iteration 46000, loss = 0.0792208
I0613 14:22:28.870198  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0792203 (* 1 = 0.0792203 loss)
I0613 14:22:28.870208  5211 sgd_solver.cpp:43] Iteration 46000, lr = 0.02
I0613 14:35:37.671082  5211 main54.cpp:499] Iteration 46400, Testing net (#0)
I0613 14:36:41.497474  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.850625
I0613 14:36:41.497522  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.518462 (* 1 = 0.518462 loss)
I0613 14:36:43.366130  5211 main54.cpp:387] Iteration 46400, loss = 0.135981
I0613 14:36:43.366153  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.13598 (* 1 = 0.13598 loss)
I0613 14:36:43.366159  5211 sgd_solver.cpp:43] Iteration 46400, lr = 0.02
I0613 14:49:50.600966  5211 main54.cpp:499] Iteration 46800, Testing net (#0)
I0613 14:50:54.493800  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.874531
I0613 14:50:54.493842  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.455139 (* 1 = 0.455139 loss)
I0613 14:50:56.392230  5211 main54.cpp:387] Iteration 46800, loss = 0.147233
I0613 14:50:56.392274  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.147232 (* 1 = 0.147232 loss)
I0613 14:50:56.392282  5211 sgd_solver.cpp:43] Iteration 46800, lr = 0.02
I0613 15:04:09.259002  5211 main54.cpp:499] Iteration 47200, Testing net (#0)
I0613 15:05:13.158021  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.873203
I0613 15:05:13.158058  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.430333 (* 1 = 0.430333 loss)
I0613 15:05:15.093812  5211 main54.cpp:387] Iteration 47200, loss = 0.180902
I0613 15:05:15.093843  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.180901 (* 1 = 0.180901 loss)
I0613 15:05:15.093852  5211 sgd_solver.cpp:43] Iteration 47200, lr = 0.02
I0613 15:18:27.208520  5211 main54.cpp:499] Iteration 47600, Testing net (#0)
I0613 15:19:31.092638  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.877734
I0613 15:19:31.092689  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.426628 (* 1 = 0.426628 loss)
I0613 15:19:33.096369  5211 main54.cpp:387] Iteration 47600, loss = 0.117611
I0613 15:19:33.096420  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.117611 (* 1 = 0.117611 loss)
I0613 15:19:33.096428  5211 sgd_solver.cpp:43] Iteration 47600, lr = 0.02
I0613 15:32:40.461593  5211 main54.cpp:499] Iteration 48000, Testing net (#0)
I0613 15:33:44.345929  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.843516
I0613 15:33:44.345983  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.58994 (* 1 = 0.58994 loss)
I0613 15:33:46.078450  5211 main54.cpp:387] Iteration 48000, loss = 0.132067
I0613 15:33:46.078502  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.132066 (* 1 = 0.132066 loss)
I0613 15:33:46.078512  5211 sgd_solver.cpp:43] Iteration 48000, lr = 0.02
I0613 15:46:58.393529  5211 main54.cpp:499] Iteration 48400, Testing net (#0)
I0613 15:48:02.216733  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.884297
I0613 15:48:02.216776  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.402905 (* 1 = 0.402905 loss)
I0613 15:48:04.382138  5211 main54.cpp:387] Iteration 48400, loss = 0.0988254
I0613 15:48:04.382164  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0988249 (* 1 = 0.0988249 loss)
I0613 15:48:04.382170  5211 sgd_solver.cpp:43] Iteration 48400, lr = 0.02
I0613 16:01:07.669396  5211 main54.cpp:499] Iteration 48800, Testing net (#0)
I0613 16:02:11.658438  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.875234
I0613 16:02:11.658475  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.468306 (* 1 = 0.468306 loss)
I0613 16:02:13.586776  5211 main54.cpp:387] Iteration 48800, loss = 0.20787
I0613 16:02:13.586807  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.207869 (* 1 = 0.207869 loss)
I0613 16:02:13.586815  5211 sgd_solver.cpp:43] Iteration 48800, lr = 0.02
I0613 16:15:24.179075  5211 main54.cpp:499] Iteration 49200, Testing net (#0)
I0613 16:16:27.805634  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.862969
I0613 16:16:27.805682  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.482859 (* 1 = 0.482859 loss)
I0613 16:16:29.907851  5211 main54.cpp:387] Iteration 49200, loss = 0.0897413
I0613 16:16:29.907897  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0897408 (* 1 = 0.0897408 loss)
I0613 16:16:29.907905  5211 sgd_solver.cpp:43] Iteration 49200, lr = 0.02
I0613 16:29:31.340553  5211 main54.cpp:499] Iteration 49600, Testing net (#0)
I0613 16:30:35.526244  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.882891
I0613 16:30:35.526299  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.433204 (* 1 = 0.433204 loss)
I0613 16:30:37.499176  5211 main54.cpp:387] Iteration 49600, loss = 0.0771197
I0613 16:30:37.499214  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0771192 (* 1 = 0.0771192 loss)
I0613 16:30:37.499225  5211 sgd_solver.cpp:43] Iteration 49600, lr = 0.02
I0613 16:43:44.340899  5211 main54.cpp:499] Iteration 50000, Testing net (#0)
I0613 16:44:48.222306  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.880391
I0613 16:44:48.222347  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.430043 (* 1 = 0.430043 loss)
I0613 16:44:50.177888  5211 main54.cpp:387] Iteration 50000, loss = 0.0822134
I0613 16:44:50.177934  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.082213 (* 1 = 0.082213 loss)
I0613 16:44:50.177947  5211 sgd_solver.cpp:43] Iteration 50000, lr = 0.02
I0613 16:58:00.060967  5211 main54.cpp:499] Iteration 50400, Testing net (#0)
I0613 16:59:03.824283  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.856172
I0613 16:59:03.824347  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.545924 (* 1 = 0.545924 loss)
I0613 16:59:05.883935  5211 main54.cpp:387] Iteration 50400, loss = 0.104588
I0613 16:59:05.883973  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.104588 (* 1 = 0.104588 loss)
I0613 16:59:05.883982  5211 sgd_solver.cpp:43] Iteration 50400, lr = 0.02
I0613 17:12:16.446743  5211 main54.cpp:499] Iteration 50800, Testing net (#0)
I0613 17:13:20.256278  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.880703
I0613 17:13:20.256331  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.44059 (* 1 = 0.44059 loss)
I0613 17:13:22.268177  5211 main54.cpp:387] Iteration 50800, loss = 0.107165
I0613 17:13:22.268223  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.107164 (* 1 = 0.107164 loss)
I0613 17:13:22.268229  5211 sgd_solver.cpp:43] Iteration 50800, lr = 0.02
I0613 17:26:25.341933  5211 main54.cpp:499] Iteration 51200, Testing net (#0)
I0613 17:27:29.393983  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.884609
I0613 17:27:29.394039  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.437642 (* 1 = 0.437642 loss)
I0613 17:27:31.251624  5211 main54.cpp:387] Iteration 51200, loss = 0.155137
I0613 17:27:31.251665  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.155137 (* 1 = 0.155137 loss)
I0613 17:27:31.251673  5211 sgd_solver.cpp:43] Iteration 51200, lr = 0.02
I0613 17:40:31.598691  5211 main54.cpp:499] Iteration 51600, Testing net (#0)
I0613 17:41:35.153940  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.867578
I0613 17:41:35.153985  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.507481 (* 1 = 0.507481 loss)
I0613 17:41:37.081920  5211 main54.cpp:387] Iteration 51600, loss = 0.0785014
I0613 17:41:37.081964  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0785009 (* 1 = 0.0785009 loss)
I0613 17:41:37.081974  5211 sgd_solver.cpp:43] Iteration 51600, lr = 0.02
I0613 17:54:41.045747  5211 main54.cpp:499] Iteration 52000, Testing net (#0)
I0613 17:55:44.780624  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.852031
I0613 17:55:44.780673  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.533525 (* 1 = 0.533525 loss)
I0613 17:55:46.814683  5211 main54.cpp:387] Iteration 52000, loss = 0.176655
I0613 17:55:46.814723  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.176654 (* 1 = 0.176654 loss)
I0613 17:55:46.814731  5211 sgd_solver.cpp:43] Iteration 52000, lr = 0.02
I0613 18:08:51.893595  5211 main54.cpp:499] Iteration 52400, Testing net (#0)
I0613 18:09:55.189970  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.845312
I0613 18:09:55.190007  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.571085 (* 1 = 0.571085 loss)
I0613 18:09:57.277559  5211 main54.cpp:387] Iteration 52400, loss = 0.142458
I0613 18:09:57.277596  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.142458 (* 1 = 0.142458 loss)
I0613 18:09:57.277603  5211 sgd_solver.cpp:43] Iteration 52400, lr = 0.02
I0613 18:22:59.453367  5211 main54.cpp:499] Iteration 52800, Testing net (#0)
I0613 18:24:03.057688  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.859688
I0613 18:24:03.057730  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.500669 (* 1 = 0.500669 loss)
I0613 18:24:05.020344  5211 main54.cpp:387] Iteration 52800, loss = 0.119853
I0613 18:24:05.020385  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.119852 (* 1 = 0.119852 loss)
I0613 18:24:05.020392  5211 sgd_solver.cpp:43] Iteration 52800, lr = 0.02
I0613 18:37:11.126502  5211 main54.cpp:499] Iteration 53200, Testing net (#0)
I0613 18:38:14.842689  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.88125
I0613 18:38:14.842731  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.436671 (* 1 = 0.436671 loss)
I0613 18:38:16.806555  5211 main54.cpp:387] Iteration 53200, loss = 0.101183
I0613 18:38:16.806586  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.101183 (* 1 = 0.101183 loss)
I0613 18:38:16.806594  5211 sgd_solver.cpp:43] Iteration 53200, lr = 0.02
I0613 18:51:28.738651  5211 main54.cpp:499] Iteration 53600, Testing net (#0)
I0613 18:52:32.511093  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.881484
I0613 18:52:32.511137  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.408072 (* 1 = 0.408072 loss)
I0613 18:52:34.322046  5211 main54.cpp:387] Iteration 53600, loss = 0.140722
I0613 18:52:34.322085  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.140722 (* 1 = 0.140722 loss)
I0613 18:52:34.322094  5211 sgd_solver.cpp:43] Iteration 53600, lr = 0.02
I0613 19:05:39.887289  5211 main54.cpp:499] Iteration 54000, Testing net (#0)
I0613 19:06:43.941429  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.879453
I0613 19:06:43.941480  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.445025 (* 1 = 0.445025 loss)
I0613 19:06:45.830075  5211 main54.cpp:387] Iteration 54000, loss = 0.105513
I0613 19:06:45.830121  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.105513 (* 1 = 0.105513 loss)
I0613 19:06:45.830132  5211 sgd_solver.cpp:43] Iteration 54000, lr = 0.02
I0613 19:19:46.098253  5211 main54.cpp:499] Iteration 54400, Testing net (#0)
I0613 19:20:49.429224  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.884141
I0613 19:20:49.429265  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.41012 (* 1 = 0.41012 loss)
I0613 19:20:51.378111  5211 main54.cpp:387] Iteration 54400, loss = 0.0739075
I0613 19:20:51.378146  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0739072 (* 1 = 0.0739072 loss)
I0613 19:20:51.378152  5211 sgd_solver.cpp:43] Iteration 54400, lr = 0.02
I0613 19:33:55.045779  5211 main54.cpp:499] Iteration 54800, Testing net (#0)
I0613 19:34:58.355139  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.837109
I0613 19:34:58.355180  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.668411 (* 1 = 0.668411 loss)
I0613 19:35:00.146421  5211 main54.cpp:387] Iteration 54800, loss = 0.133359
I0613 19:35:00.146458  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.133359 (* 1 = 0.133359 loss)
I0613 19:35:00.146466  5211 sgd_solver.cpp:43] Iteration 54800, lr = 0.02
I0613 19:48:03.868266  5211 main54.cpp:499] Iteration 55200, Testing net (#0)
I0613 19:49:07.228518  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.85125
I0613 19:49:07.228564  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.5656 (* 1 = 0.5656 loss)
I0613 19:49:09.157271  5211 main54.cpp:387] Iteration 55200, loss = 0.131054
I0613 19:49:09.157308  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.131054 (* 1 = 0.131054 loss)
I0613 19:49:09.157315  5211 sgd_solver.cpp:43] Iteration 55200, lr = 0.02
I0613 20:02:12.186386  5211 main54.cpp:499] Iteration 55600, Testing net (#0)
I0613 20:03:15.483001  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.879141
I0613 20:03:15.483048  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.441726 (* 1 = 0.441726 loss)
I0613 20:03:17.330157  5211 main54.cpp:387] Iteration 55600, loss = 0.114006
I0613 20:03:17.330211  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.114006 (* 1 = 0.114006 loss)
I0613 20:03:17.330221  5211 sgd_solver.cpp:43] Iteration 55600, lr = 0.02
I0613 20:16:24.221899  5211 main54.cpp:499] Iteration 56000, Testing net (#0)
I0613 20:17:28.103230  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.876406
I0613 20:17:28.103278  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.456964 (* 1 = 0.456964 loss)
I0613 20:17:30.001128  5211 main54.cpp:387] Iteration 56000, loss = 0.1385
I0613 20:17:30.001171  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.138499 (* 1 = 0.138499 loss)
I0613 20:17:30.001180  5211 sgd_solver.cpp:43] Iteration 56000, lr = 0.02
I0613 20:30:36.569586  5211 main54.cpp:499] Iteration 56400, Testing net (#0)
I0613 20:31:40.382297  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.837578
I0613 20:31:40.382346  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.667293 (* 1 = 0.667293 loss)
I0613 20:31:42.352732  5211 main54.cpp:387] Iteration 56400, loss = 0.175485
I0613 20:31:42.352776  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.175485 (* 1 = 0.175485 loss)
I0613 20:31:42.352784  5211 sgd_solver.cpp:43] Iteration 56400, lr = 0.02
I0613 20:44:51.639926  5211 main54.cpp:499] Iteration 56800, Testing net (#0)
I0613 20:45:55.439543  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.873438
I0613 20:45:55.439587  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.456374 (* 1 = 0.456374 loss)
I0613 20:45:57.374837  5211 main54.cpp:387] Iteration 56800, loss = 0.0949418
I0613 20:45:57.374871  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0949414 (* 1 = 0.0949414 loss)
I0613 20:45:57.374878  5211 sgd_solver.cpp:43] Iteration 56800, lr = 0.02
I0613 20:59:02.273252  5211 main54.cpp:499] Iteration 57200, Testing net (#0)
I0613 21:00:06.103818  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.810156
I0613 21:00:06.103858  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.832268 (* 1 = 0.832268 loss)
I0613 21:00:08.101845  5211 main54.cpp:387] Iteration 57200, loss = 0.282236
I0613 21:00:08.101884  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.282236 (* 1 = 0.282236 loss)
I0613 21:00:08.101892  5211 sgd_solver.cpp:43] Iteration 57200, lr = 0.02
I0613 21:13:15.696252  5211 main54.cpp:499] Iteration 57600, Testing net (#0)
I0613 21:14:19.500604  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.801328
I0613 21:14:19.500658  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.876135 (* 1 = 0.876135 loss)
I0613 21:14:21.432262  5211 main54.cpp:387] Iteration 57600, loss = 0.130944
I0613 21:14:21.432310  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.130943 (* 1 = 0.130943 loss)
I0613 21:14:21.432320  5211 sgd_solver.cpp:43] Iteration 57600, lr = 0.02
I0613 21:27:30.462926  5211 main54.cpp:499] Iteration 58000, Testing net (#0)
I0613 21:28:34.266044  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.849922
I0613 21:28:34.266086  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.596034 (* 1 = 0.596034 loss)
I0613 21:28:36.141015  5211 main54.cpp:387] Iteration 58000, loss = 0.105291
I0613 21:28:36.141058  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.10529 (* 1 = 0.10529 loss)
I0613 21:28:36.141067  5211 sgd_solver.cpp:43] Iteration 58000, lr = 0.02
I0613 21:41:38.871876  5211 main54.cpp:499] Iteration 58400, Testing net (#0)
I0613 21:42:42.710418  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.813125
I0613 21:42:42.710465  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.804954 (* 1 = 0.804954 loss)
I0613 21:42:44.653373  5211 main54.cpp:387] Iteration 58400, loss = 0.140132
I0613 21:42:44.653409  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.140132 (* 1 = 0.140132 loss)
I0613 21:42:44.653416  5211 sgd_solver.cpp:43] Iteration 58400, lr = 0.02
I0613 21:55:52.057029  5211 main54.cpp:499] Iteration 58800, Testing net (#0)
I0613 21:56:55.858048  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.871641
I0613 21:56:55.858091  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.470359 (* 1 = 0.470359 loss)
I0613 21:56:57.790547  5211 main54.cpp:387] Iteration 58800, loss = 0.0879842
I0613 21:56:57.790585  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0879838 (* 1 = 0.0879838 loss)
I0613 21:56:57.790591  5211 sgd_solver.cpp:43] Iteration 58800, lr = 0.02
I0613 22:10:00.967531  5211 main54.cpp:499] Iteration 59200, Testing net (#0)
I0613 22:11:04.788053  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.787031
I0613 22:11:04.788097  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 1.00889 (* 1 = 1.00889 loss)
I0613 22:11:06.555315  5211 main54.cpp:387] Iteration 59200, loss = 0.0906531
I0613 22:11:06.555353  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0906527 (* 1 = 0.0906527 loss)
I0613 22:11:06.555361  5211 sgd_solver.cpp:43] Iteration 59200, lr = 0.02
I0613 22:24:16.170969  5211 main54.cpp:499] Iteration 59600, Testing net (#0)
I0613 22:25:19.995355  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.840703
I0613 22:25:19.995401  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.632077 (* 1 = 0.632077 loss)
I0613 22:25:21.892669  5211 main54.cpp:387] Iteration 59600, loss = 0.113537
I0613 22:25:21.892709  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.113537 (* 1 = 0.113537 loss)
I0613 22:25:21.892715  5211 sgd_solver.cpp:43] Iteration 59600, lr = 0.02
I0613 22:38:28.726409  5211 main54.cpp:499] Iteration 60000, Testing net (#0)
I0613 22:39:32.526609  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.887891
I0613 22:39:32.526648  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.414287 (* 1 = 0.414287 loss)
I0613 22:39:34.568704  5211 main54.cpp:387] Iteration 60000, loss = 0.136647
I0613 22:39:34.568739  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.136646 (* 1 = 0.136646 loss)
I0613 22:39:34.568747  5211 sgd_solver.cpp:43] Iteration 60000, lr = 0.02
I0613 22:52:43.509901  5211 main54.cpp:499] Iteration 60400, Testing net (#0)
I0613 22:53:47.364446  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.875391
I0613 22:53:47.364483  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.444741 (* 1 = 0.444741 loss)
I0613 22:53:49.471777  5211 main54.cpp:387] Iteration 60400, loss = 0.071155
I0613 22:53:49.471814  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0711547 (* 1 = 0.0711547 loss)
I0613 22:53:49.471822  5211 sgd_solver.cpp:43] Iteration 60400, lr = 0.02
I0613 23:06:56.734397  5211 main54.cpp:499] Iteration 60800, Testing net (#0)
I0613 23:08:00.457931  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.847266
I0613 23:08:00.457972  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.565274 (* 1 = 0.565274 loss)
I0613 23:08:02.420235  5211 main54.cpp:387] Iteration 60800, loss = 0.0907744
I0613 23:08:02.420275  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0907741 (* 1 = 0.0907741 loss)
I0613 23:08:02.420282  5211 sgd_solver.cpp:43] Iteration 60800, lr = 0.02
I0613 23:21:05.220134  5211 main54.cpp:499] Iteration 61200, Testing net (#0)
I0613 23:22:09.015697  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.881562
I0613 23:22:09.015743  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.401523 (* 1 = 0.401523 loss)
I0613 23:22:11.118136  5211 main54.cpp:387] Iteration 61200, loss = 0.162476
I0613 23:22:11.118173  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.162476 (* 1 = 0.162476 loss)
I0613 23:22:11.118180  5211 sgd_solver.cpp:43] Iteration 61200, lr = 0.02
I0613 23:35:16.071810  5211 main54.cpp:499] Iteration 61600, Testing net (#0)
I0613 23:36:19.858394  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.859062
I0613 23:36:19.858446  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.499771 (* 1 = 0.499771 loss)
I0613 23:36:22.002852  5211 main54.cpp:387] Iteration 61600, loss = 0.0642731
I0613 23:36:22.002892  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0642727 (* 1 = 0.0642727 loss)
I0613 23:36:22.002897  5211 sgd_solver.cpp:43] Iteration 61600, lr = 0.02
I0613 23:49:28.325338  5211 main54.cpp:499] Iteration 62000, Testing net (#0)
I0613 23:50:32.146360  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.872266
I0613 23:50:32.146416  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.473931 (* 1 = 0.473931 loss)
I0613 23:50:34.248874  5211 main54.cpp:387] Iteration 62000, loss = 0.0842692
I0613 23:50:34.248909  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0842689 (* 1 = 0.0842689 loss)
I0613 23:50:34.248916  5211 sgd_solver.cpp:43] Iteration 62000, lr = 0.02
I0614 00:03:45.057415  5211 main54.cpp:499] Iteration 62400, Testing net (#0)
I0614 00:04:48.888499  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.890625
I0614 00:04:48.888547  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.354474 (* 1 = 0.354474 loss)
I0614 00:04:50.932193  5211 main54.cpp:387] Iteration 62400, loss = 0.0623968
I0614 00:04:50.932240  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0623964 (* 1 = 0.0623964 loss)
I0614 00:04:50.932247  5211 sgd_solver.cpp:43] Iteration 62400, lr = 0.02
I0614 00:17:53.846236  5211 main54.cpp:499] Iteration 62800, Testing net (#0)
I0614 00:18:57.688074  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.886563
I0614 00:18:57.688117  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.437476 (* 1 = 0.437476 loss)
I0614 00:18:59.589838  5211 main54.cpp:387] Iteration 62800, loss = 0.0982676
I0614 00:18:59.589884  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0982671 (* 1 = 0.0982671 loss)
I0614 00:18:59.589892  5211 sgd_solver.cpp:43] Iteration 62800, lr = 0.02
I0614 00:32:05.302044  5211 main54.cpp:499] Iteration 63200, Testing net (#0)
I0614 00:33:09.120479  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.853516
I0614 00:33:09.120518  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.59676 (* 1 = 0.59676 loss)
I0614 00:33:11.020531  5211 main54.cpp:387] Iteration 63200, loss = 0.152888
I0614 00:33:11.020582  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.152887 (* 1 = 0.152887 loss)
I0614 00:33:11.020592  5211 sgd_solver.cpp:43] Iteration 63200, lr = 0.02
I0614 00:46:20.937554  5211 main54.cpp:499] Iteration 63600, Testing net (#0)
I0614 00:47:24.816668  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.866953
I0614 00:47:24.816711  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.487505 (* 1 = 0.487505 loss)
I0614 00:47:26.888221  5211 main54.cpp:387] Iteration 63600, loss = 0.157876
I0614 00:47:26.888260  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.157876 (* 1 = 0.157876 loss)
I0614 00:47:26.888267  5211 sgd_solver.cpp:43] Iteration 63600, lr = 0.02
I0614 01:00:34.171195  5211 main54.cpp:499] Iteration 64000, Testing net (#0)
I0614 01:01:38.006706  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.872656
I0614 01:01:38.006754  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.500789 (* 1 = 0.500789 loss)
I0614 01:01:39.730783  5211 main54.cpp:387] Iteration 64000, loss = 0.173729
I0614 01:01:39.730825  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.173728 (* 1 = 0.173728 loss)
I0614 01:01:39.730834  5211 sgd_solver.cpp:43] Iteration 64000, lr = 0.02
I0614 01:14:48.152494  5211 main54.cpp:499] Iteration 64400, Testing net (#0)
I0614 01:15:51.876523  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.859531
I0614 01:15:51.876565  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.578148 (* 1 = 0.578148 loss)
I0614 01:15:53.883076  5211 main54.cpp:387] Iteration 64400, loss = 0.125506
I0614 01:15:53.883117  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.125506 (* 1 = 0.125506 loss)
I0614 01:15:53.883124  5211 sgd_solver.cpp:43] Iteration 64400, lr = 0.02
I0614 01:29:01.998080  5211 main54.cpp:499] Iteration 64800, Testing net (#0)
I0614 01:30:05.840286  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.892031
I0614 01:30:05.840327  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.37939 (* 1 = 0.37939 loss)
I0614 01:30:07.778288  5211 main54.cpp:387] Iteration 64800, loss = 0.070529
I0614 01:30:07.778331  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0705285 (* 1 = 0.0705285 loss)
I0614 01:30:07.778337  5211 sgd_solver.cpp:43] Iteration 64800, lr = 0.02
I0614 01:43:13.532919  5211 main54.cpp:499] Iteration 65200, Testing net (#0)
I0614 01:44:17.361048  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.856172
I0614 01:44:17.361091  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.542129 (* 1 = 0.542129 loss)
I0614 01:44:19.426388  5211 main54.cpp:387] Iteration 65200, loss = 0.0656552
I0614 01:44:19.426426  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0656548 (* 1 = 0.0656548 loss)
I0614 01:44:19.426432  5211 sgd_solver.cpp:43] Iteration 65200, lr = 0.02
I0614 01:57:30.644767  5211 main54.cpp:499] Iteration 65600, Testing net (#0)
I0614 01:58:34.452690  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.878984
I0614 01:58:34.452735  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.447311 (* 1 = 0.447311 loss)
I0614 01:58:36.420732  5211 main54.cpp:387] Iteration 65600, loss = 0.0839714
I0614 01:58:36.420771  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0839708 (* 1 = 0.0839708 loss)
I0614 01:58:36.420778  5211 sgd_solver.cpp:43] Iteration 65600, lr = 0.02
I0614 02:11:41.482116  5211 main54.cpp:499] Iteration 66000, Testing net (#0)
I0614 02:12:45.357272  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.866094
I0614 02:12:45.357316  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.502882 (* 1 = 0.502882 loss)
I0614 02:12:47.285346  5211 main54.cpp:387] Iteration 66000, loss = 0.12865
I0614 02:12:47.285378  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.128649 (* 1 = 0.128649 loss)
I0614 02:12:47.285387  5211 sgd_solver.cpp:43] Iteration 66000, lr = 0.02
I0614 02:25:54.557909  5211 main54.cpp:499] Iteration 66400, Testing net (#0)
I0614 02:26:58.352130  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.880938
I0614 02:26:58.352179  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.418397 (* 1 = 0.418397 loss)
I0614 02:27:00.315284  5211 main54.cpp:387] Iteration 66400, loss = 0.0707719
I0614 02:27:00.315317  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0707712 (* 1 = 0.0707712 loss)
I0614 02:27:00.315323  5211 sgd_solver.cpp:43] Iteration 66400, lr = 0.02
I0614 02:40:09.273221  5211 main54.cpp:499] Iteration 66800, Testing net (#0)
I0614 02:41:13.133095  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.84375
I0614 02:41:13.133139  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.601833 (* 1 = 0.601833 loss)
I0614 02:41:15.168987  5211 main54.cpp:387] Iteration 66800, loss = 0.0845621
I0614 02:41:15.169025  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0845615 (* 1 = 0.0845615 loss)
I0614 02:41:15.169034  5211 sgd_solver.cpp:43] Iteration 66800, lr = 0.02
I0614 02:54:26.058503  5211 main54.cpp:499] Iteration 67200, Testing net (#0)
I0614 02:55:29.908793  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.875391
I0614 02:55:29.908846  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.460966 (* 1 = 0.460966 loss)
I0614 02:55:31.867877  5211 main54.cpp:387] Iteration 67200, loss = 0.0904902
I0614 02:55:31.867919  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0904896 (* 1 = 0.0904896 loss)
I0614 02:55:31.867928  5211 sgd_solver.cpp:43] Iteration 67200, lr = 0.02
I0614 03:08:40.062804  5211 main54.cpp:499] Iteration 67600, Testing net (#0)
I0614 03:09:43.919607  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.864219
I0614 03:09:43.919652  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.51787 (* 1 = 0.51787 loss)
I0614 03:09:45.618288  5211 main54.cpp:387] Iteration 67600, loss = 0.15151
I0614 03:09:45.618330  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.15151 (* 1 = 0.15151 loss)
I0614 03:09:45.618336  5211 sgd_solver.cpp:43] Iteration 67600, lr = 0.02
I0614 03:22:56.146862  5211 main54.cpp:499] Iteration 68000, Testing net (#0)
I0614 03:23:59.978498  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.878672
I0614 03:23:59.978554  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.472018 (* 1 = 0.472018 loss)
I0614 03:24:01.700525  5211 main54.cpp:387] Iteration 68000, loss = 0.109036
I0614 03:24:01.700567  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.109035 (* 1 = 0.109035 loss)
I0614 03:24:01.700577  5211 sgd_solver.cpp:43] Iteration 68000, lr = 0.02
I0614 03:37:11.456356  5211 main54.cpp:499] Iteration 68400, Testing net (#0)
I0614 03:38:16.379551  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.864688
I0614 03:38:16.379596  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.566078 (* 1 = 0.566078 loss)
I0614 03:38:18.248124  5211 main54.cpp:387] Iteration 68400, loss = 0.0772553
I0614 03:38:18.248165  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0772546 (* 1 = 0.0772546 loss)
I0614 03:38:18.248173  5211 sgd_solver.cpp:43] Iteration 68400, lr = 0.02
I0614 03:51:30.522671  5211 main54.cpp:499] Iteration 68800, Testing net (#0)
I0614 03:52:35.142954  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.889375
I0614 03:52:35.143007  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.404245 (* 1 = 0.404245 loss)
I0614 03:52:37.213982  5211 main54.cpp:387] Iteration 68800, loss = 0.0853042
I0614 03:52:37.214018  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0853035 (* 1 = 0.0853035 loss)
I0614 03:52:37.214026  5211 sgd_solver.cpp:43] Iteration 68800, lr = 0.02
I0614 04:05:53.417614  5211 main54.cpp:499] Iteration 69200, Testing net (#0)
I0614 04:06:57.522668  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.844688
I0614 04:06:57.522718  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.667799 (* 1 = 0.667799 loss)
I0614 04:06:59.407039  5211 main54.cpp:387] Iteration 69200, loss = 0.183584
I0614 04:06:59.407078  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.183583 (* 1 = 0.183583 loss)
I0614 04:06:59.407084  5211 sgd_solver.cpp:43] Iteration 69200, lr = 0.02
I0614 04:20:06.902338  5211 main54.cpp:499] Iteration 69600, Testing net (#0)
I0614 04:21:10.590962  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.887266
I0614 04:21:10.591004  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.404375 (* 1 = 0.404375 loss)
I0614 04:21:12.519703  5211 main54.cpp:387] Iteration 69600, loss = 0.0391643
I0614 04:21:12.519731  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0391635 (* 1 = 0.0391635 loss)
I0614 04:21:12.519740  5211 sgd_solver.cpp:43] Iteration 69600, lr = 0.02
I0614 04:34:16.568395  5211 main54.cpp:499] Iteration 70000, Testing net (#0)
I0614 04:35:20.329458  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.865625
I0614 04:35:20.329498  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.505999 (* 1 = 0.505999 loss)
I0614 04:35:22.335074  5211 main54.cpp:387] Iteration 70000, loss = 0.0432383
I0614 04:35:22.335109  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0432375 (* 1 = 0.0432375 loss)
I0614 04:35:22.335117  5211 sgd_solver.cpp:43] Iteration 70000, lr = 0.02
I0614 04:48:31.475198  5211 main54.cpp:499] Iteration 70400, Testing net (#0)
I0614 04:49:35.128517  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.822891
I0614 04:49:35.128559  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.758765 (* 1 = 0.758765 loss)
I0614 04:49:37.298599  5211 main54.cpp:387] Iteration 70400, loss = 0.0626411
I0614 04:49:37.298635  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0626403 (* 1 = 0.0626403 loss)
I0614 04:49:37.298641  5211 sgd_solver.cpp:43] Iteration 70400, lr = 0.02
I0614 05:02:43.357311  5211 main54.cpp:499] Iteration 70800, Testing net (#0)
I0614 05:03:47.014538  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.855313
I0614 05:03:47.014580  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.589267 (* 1 = 0.589267 loss)
I0614 05:03:48.931794  5211 main54.cpp:387] Iteration 70800, loss = 0.116107
I0614 05:03:48.931828  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.116106 (* 1 = 0.116106 loss)
I0614 05:03:48.931833  5211 sgd_solver.cpp:43] Iteration 70800, lr = 0.02
I0614 05:16:59.577337  5211 main54.cpp:499] Iteration 71200, Testing net (#0)
I0614 05:18:03.868369  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.896953
I0614 05:18:03.868413  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.382873 (* 1 = 0.382873 loss)
I0614 05:18:05.718112  5211 main54.cpp:387] Iteration 71200, loss = 0.222026
I0614 05:18:05.718158  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.222025 (* 1 = 0.222025 loss)
I0614 05:18:05.718168  5211 sgd_solver.cpp:43] Iteration 71200, lr = 0.02
I0614 05:31:15.959606  5211 main54.cpp:499] Iteration 71600, Testing net (#0)
I0614 05:32:19.753614  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.877813
I0614 05:32:19.753659  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.438155 (* 1 = 0.438155 loss)
I0614 05:32:21.599750  5211 main54.cpp:387] Iteration 71600, loss = 0.116441
I0614 05:32:21.599773  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.11644 (* 1 = 0.11644 loss)
I0614 05:32:21.599781  5211 sgd_solver.cpp:43] Iteration 71600, lr = 0.02
I0614 05:45:27.108824  5211 main54.cpp:499] Iteration 72000, Testing net (#0)
I0614 05:46:30.799290  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.885469
I0614 05:46:30.799335  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.429565 (* 1 = 0.429565 loss)
I0614 05:46:32.834115  5211 main54.cpp:387] Iteration 72000, loss = 0.125027
I0614 05:46:32.834163  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.125026 (* 1 = 0.125026 loss)
I0614 05:46:32.834169  5211 sgd_solver.cpp:43] Iteration 72000, lr = 0.02
I0614 05:59:43.392194  5211 main54.cpp:499] Iteration 72400, Testing net (#0)
I0614 06:00:47.680183  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.888906
I0614 06:00:47.680222  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.392808 (* 1 = 0.392808 loss)
I0614 06:00:49.720281  5211 main54.cpp:387] Iteration 72400, loss = 0.0919841
I0614 06:00:49.720319  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0919833 (* 1 = 0.0919833 loss)
I0614 06:00:49.720327  5211 sgd_solver.cpp:43] Iteration 72400, lr = 0.02
I0614 06:14:01.553467  5211 main54.cpp:499] Iteration 72800, Testing net (#0)
I0614 06:15:05.399312  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.886563
I0614 06:15:05.399356  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.37285 (* 1 = 0.37285 loss)
I0614 06:15:07.542295  5211 main54.cpp:387] Iteration 72800, loss = 0.120702
I0614 06:15:07.542333  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.120701 (* 1 = 0.120701 loss)
I0614 06:15:07.542341  5211 sgd_solver.cpp:43] Iteration 72800, lr = 0.02
I0614 06:28:19.731565  5211 main54.cpp:499] Iteration 73200, Testing net (#0)
I0614 06:29:24.034548  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.858984
I0614 06:29:24.034587  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.601093 (* 1 = 0.601093 loss)
I0614 06:29:25.931864  5211 main54.cpp:387] Iteration 73200, loss = 0.0725605
I0614 06:29:25.931907  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0725597 (* 1 = 0.0725597 loss)
I0614 06:29:25.931916  5211 sgd_solver.cpp:43] Iteration 73200, lr = 0.02
I0614 06:42:38.647405  5211 main54.cpp:499] Iteration 73600, Testing net (#0)
I0614 06:43:43.367872  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.868438
I0614 06:43:43.367921  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.480836 (* 1 = 0.480836 loss)
I0614 06:43:45.527618  5211 main54.cpp:387] Iteration 73600, loss = 0.0594634
I0614 06:43:45.527655  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0594626 (* 1 = 0.0594626 loss)
I0614 06:43:45.527667  5211 sgd_solver.cpp:43] Iteration 73600, lr = 0.02
I0614 06:56:59.661173  5211 main54.cpp:499] Iteration 74000, Testing net (#0)
I0614 06:58:03.093065  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.877734
I0614 06:58:03.093109  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.453453 (* 1 = 0.453453 loss)
I0614 06:58:05.087111  5211 main54.cpp:387] Iteration 74000, loss = 0.0918056
I0614 06:58:05.087146  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0918047 (* 1 = 0.0918047 loss)
I0614 06:58:05.087152  5211 sgd_solver.cpp:43] Iteration 74000, lr = 0.02
I0614 07:11:16.217866  5211 main54.cpp:499] Iteration 74400, Testing net (#0)
I0614 07:12:21.185915  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.888594
I0614 07:12:21.185967  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.428707 (* 1 = 0.428707 loss)
I0614 07:12:23.096505  5211 main54.cpp:387] Iteration 74400, loss = 0.0479597
I0614 07:12:23.096539  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0479588 (* 1 = 0.0479588 loss)
I0614 07:12:23.096545  5211 sgd_solver.cpp:43] Iteration 74400, lr = 0.02
I0614 07:25:36.343228  5211 main54.cpp:499] Iteration 74800, Testing net (#0)
I0614 07:26:40.272763  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.840156
I0614 07:26:40.272814  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.703313 (* 1 = 0.703313 loss)
I0614 07:26:42.267719  5211 main54.cpp:387] Iteration 74800, loss = 0.0766975
I0614 07:26:42.267757  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0766966 (* 1 = 0.0766966 loss)
I0614 07:26:42.267765  5211 sgd_solver.cpp:43] Iteration 74800, lr = 0.02
I0614 07:39:55.936401  5211 main54.cpp:499] Iteration 75200, Testing net (#0)
I0614 07:40:59.840257  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.883125
I0614 07:40:59.840306  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.429839 (* 1 = 0.429839 loss)
I0614 07:41:01.831590  5211 main54.cpp:387] Iteration 75200, loss = 0.224285
I0614 07:41:01.831629  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.224284 (* 1 = 0.224284 loss)
I0614 07:41:01.831646  5211 sgd_solver.cpp:43] Iteration 75200, lr = 0.02
I0614 07:54:13.198945  5211 main54.cpp:499] Iteration 75600, Testing net (#0)
I0614 07:55:17.441637  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.869844
I0614 07:55:17.441695  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.533946 (* 1 = 0.533946 loss)
I0614 07:55:19.507920  5211 main54.cpp:387] Iteration 75600, loss = 0.0712996
I0614 07:55:19.507953  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0712989 (* 1 = 0.0712989 loss)
I0614 07:55:19.507959  5211 sgd_solver.cpp:43] Iteration 75600, lr = 0.02
I0614 08:08:29.110740  5211 main54.cpp:499] Iteration 76000, Testing net (#0)
I0614 08:09:33.399485  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.858906
I0614 08:09:33.399525  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.605903 (* 1 = 0.605903 loss)
I0614 08:09:35.401583  5211 main54.cpp:387] Iteration 76000, loss = 0.0561994
I0614 08:09:35.401617  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0561986 (* 1 = 0.0561986 loss)
I0614 08:09:35.401623  5211 sgd_solver.cpp:43] Iteration 76000, lr = 0.02
I0614 08:22:48.568790  5211 main54.cpp:499] Iteration 76400, Testing net (#0)
I0614 08:23:52.673462  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.877813
I0614 08:23:52.673502  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.474979 (* 1 = 0.474979 loss)
I0614 08:23:54.585263  5211 main54.cpp:387] Iteration 76400, loss = 0.149464
I0614 08:23:54.585296  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.149463 (* 1 = 0.149463 loss)
I0614 08:23:54.585304  5211 sgd_solver.cpp:43] Iteration 76400, lr = 0.02
I0614 08:37:08.044734  5211 main54.cpp:499] Iteration 76800, Testing net (#0)
I0614 08:38:12.185211  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.876797
I0614 08:38:12.185258  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.482977 (* 1 = 0.482977 loss)
I0614 08:38:13.943435  5211 main54.cpp:387] Iteration 76800, loss = 0.192636
I0614 08:38:13.943492  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.192636 (* 1 = 0.192636 loss)
I0614 08:38:13.943501  5211 sgd_solver.cpp:43] Iteration 76800, lr = 0.02
I0614 08:51:20.387943  5211 main54.cpp:499] Iteration 77200, Testing net (#0)
I0614 08:52:24.316784  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.881797
I0614 08:52:24.316828  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.451792 (* 1 = 0.451792 loss)
I0614 08:52:26.344578  5211 main54.cpp:387] Iteration 77200, loss = 0.114051
I0614 08:52:26.344610  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.11405 (* 1 = 0.11405 loss)
I0614 08:52:26.344619  5211 sgd_solver.cpp:43] Iteration 77200, lr = 0.02
I0614 09:05:41.481362  5211 main54.cpp:499] Iteration 77600, Testing net (#0)
I0614 09:06:45.649896  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.829687
I0614 09:06:45.649948  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.66005 (* 1 = 0.66005 loss)
I0614 09:06:47.620690  5211 main54.cpp:387] Iteration 77600, loss = 0.0353166
I0614 09:06:47.620721  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0353159 (* 1 = 0.0353159 loss)
I0614 09:06:47.620729  5211 sgd_solver.cpp:43] Iteration 77600, lr = 0.02
I0614 09:20:02.778470  5211 main54.cpp:499] Iteration 78000, Testing net (#0)
I0614 09:21:06.858649  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.886016
I0614 09:21:06.858690  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.438547 (* 1 = 0.438547 loss)
I0614 09:21:08.897629  5211 main54.cpp:387] Iteration 78000, loss = 0.086126
I0614 09:21:08.897661  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0861253 (* 1 = 0.0861253 loss)
I0614 09:21:08.897670  5211 sgd_solver.cpp:43] Iteration 78000, lr = 0.02
I0614 09:34:25.295871  5211 main54.cpp:499] Iteration 78400, Testing net (#0)
I0614 09:35:29.702714  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.890234
I0614 09:35:29.702759  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.397689 (* 1 = 0.397689 loss)
I0614 09:35:31.737992  5211 main54.cpp:387] Iteration 78400, loss = 0.0439103
I0614 09:35:31.738034  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0439096 (* 1 = 0.0439096 loss)
I0614 09:35:31.738044  5211 sgd_solver.cpp:43] Iteration 78400, lr = 0.02
I0614 09:48:48.118063  5211 main54.cpp:499] Iteration 78800, Testing net (#0)
I0614 09:49:52.239274  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.872891
I0614 09:49:52.239315  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.491828 (* 1 = 0.491828 loss)
I0614 09:49:54.078173  5211 main54.cpp:387] Iteration 78800, loss = 0.191721
I0614 09:49:54.078212  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.19172 (* 1 = 0.19172 loss)
I0614 09:49:54.078222  5211 sgd_solver.cpp:43] Iteration 78800, lr = 0.02
I0614 10:03:02.558522  5211 main54.cpp:499] Iteration 79200, Testing net (#0)
I0614 10:04:06.908000  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.857188
I0614 10:04:06.908063  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.585719 (* 1 = 0.585719 loss)
I0614 10:04:08.855609  5211 main54.cpp:387] Iteration 79200, loss = 0.029576
I0614 10:04:08.855648  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0295752 (* 1 = 0.0295752 loss)
I0614 10:04:08.855655  5211 sgd_solver.cpp:43] Iteration 79200, lr = 0.02
I0614 10:17:20.264724  5211 main54.cpp:499] Iteration 79600, Testing net (#0)
I0614 10:18:24.641263  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.852031
I0614 10:18:24.641304  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.623836 (* 1 = 0.623836 loss)
I0614 10:18:26.459126  5211 main54.cpp:387] Iteration 79600, loss = 0.0963772
I0614 10:18:26.459167  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0963764 (* 1 = 0.0963764 loss)
I0614 10:18:26.459177  5211 sgd_solver.cpp:43] Iteration 79600, lr = 0.02
I0614 10:31:43.099156  5211 main54.cpp:499] Iteration 80000, Testing net (#0)
I0614 10:32:47.250599  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.855937
I0614 10:32:47.250648  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.643345 (* 1 = 0.643345 loss)
I0614 10:32:49.147550  5211 main54.cpp:387] Iteration 80000, loss = 0.0944441
I0614 10:32:49.147588  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0944433 (* 1 = 0.0944433 loss)
I0614 10:32:49.147596  5211 sgd_solver.cpp:43] Iteration 80000, lr = 0.02
I0614 10:46:08.426229  5211 main54.cpp:499] Iteration 80400, Testing net (#0)
I0614 10:47:12.596119  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.840391
I0614 10:47:12.596164  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.692518 (* 1 = 0.692518 loss)
I0614 10:47:14.514987  5211 main54.cpp:387] Iteration 80400, loss = 0.0747139
I0614 10:47:14.515012  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0747131 (* 1 = 0.0747131 loss)
I0614 10:47:14.515018  5211 sgd_solver.cpp:43] Iteration 80400, lr = 0.02
I0614 11:00:36.310639  5211 main54.cpp:499] Iteration 80800, Testing net (#0)
I0614 11:01:40.697940  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.858516
I0614 11:01:40.697985  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.58428 (* 1 = 0.58428 loss)
I0614 11:01:42.438941  5211 main54.cpp:387] Iteration 80800, loss = 0.0958959
I0614 11:01:42.438985  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.095895 (* 1 = 0.095895 loss)
I0614 11:01:42.438993  5211 sgd_solver.cpp:43] Iteration 80800, lr = 0.02
I0614 11:14:56.776309  5211 main54.cpp:499] Iteration 81200, Testing net (#0)
I0614 11:16:01.346112  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.881953
I0614 11:16:01.346163  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.454464 (* 1 = 0.454464 loss)
I0614 11:16:03.322698  5211 main54.cpp:387] Iteration 81200, loss = 0.0463538
I0614 11:16:03.322760  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0463529 (* 1 = 0.0463529 loss)
I0614 11:16:03.322777  5211 sgd_solver.cpp:43] Iteration 81200, lr = 0.02
I0614 11:29:17.777097  5211 main54.cpp:499] Iteration 81600, Testing net (#0)
I0614 11:30:22.053843  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.87125
I0614 11:30:22.053890  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.51139 (* 1 = 0.51139 loss)
I0614 11:30:24.071118  5211 main54.cpp:387] Iteration 81600, loss = 0.0718139
I0614 11:30:24.071154  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.071813 (* 1 = 0.071813 loss)
I0614 11:30:24.071163  5211 sgd_solver.cpp:43] Iteration 81600, lr = 0.02
I0614 11:43:42.028167  5211 main54.cpp:499] Iteration 82000, Testing net (#0)
I0614 11:44:46.351207  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.857656
I0614 11:44:46.351246  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.526628 (* 1 = 0.526628 loss)
I0614 11:44:48.251819  5211 main54.cpp:387] Iteration 82000, loss = 0.214327
I0614 11:44:48.251845  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.214326 (* 1 = 0.214326 loss)
I0614 11:44:48.251853  5211 sgd_solver.cpp:43] Iteration 82000, lr = 0.02
I0614 11:58:00.639462  5211 main54.cpp:499] Iteration 82400, Testing net (#0)
I0614 11:59:05.102798  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.873594
I0614 11:59:05.102865  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.561154 (* 1 = 0.561154 loss)
I0614 11:59:07.031515  5211 main54.cpp:387] Iteration 82400, loss = 0.0849727
I0614 11:59:07.031548  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0849718 (* 1 = 0.0849718 loss)
I0614 11:59:07.031556  5211 sgd_solver.cpp:43] Iteration 82400, lr = 0.02
I0614 12:12:19.269944  5211 main54.cpp:499] Iteration 82800, Testing net (#0)
I0614 12:13:23.759412  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.868281
I0614 12:13:23.759454  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.585321 (* 1 = 0.585321 loss)
I0614 12:13:25.534787  5211 main54.cpp:387] Iteration 82800, loss = 0.136553
I0614 12:13:25.534819  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.136552 (* 1 = 0.136552 loss)
I0614 12:13:25.534829  5211 sgd_solver.cpp:43] Iteration 82800, lr = 0.02
I0614 12:26:38.497058  5211 main54.cpp:499] Iteration 83200, Testing net (#0)
I0614 12:27:42.752037  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.868359
I0614 12:27:42.752082  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.58245 (* 1 = 0.58245 loss)
I0614 12:27:44.728900  5211 main54.cpp:387] Iteration 83200, loss = 0.118661
I0614 12:27:44.728932  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.11866 (* 1 = 0.11866 loss)
I0614 12:27:44.728940  5211 sgd_solver.cpp:43] Iteration 83200, lr = 0.02
I0614 12:40:55.067885  5211 main54.cpp:499] Iteration 83600, Testing net (#0)
I0614 12:41:59.884824  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.866875
I0614 12:41:59.884871  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.581476 (* 1 = 0.581476 loss)
I0614 12:42:02.020153  5211 main54.cpp:387] Iteration 83600, loss = 0.0848082
I0614 12:42:02.020193  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0848074 (* 1 = 0.0848074 loss)
I0614 12:42:02.020203  5211 sgd_solver.cpp:43] Iteration 83600, lr = 0.02
I0614 12:55:14.253799  5211 main54.cpp:499] Iteration 84000, Testing net (#0)
I0614 12:56:18.292528  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.864062
I0614 12:56:18.292569  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.609677 (* 1 = 0.609677 loss)
I0614 12:56:20.204439  5211 main54.cpp:387] Iteration 84000, loss = 0.0622668
I0614 12:56:20.204483  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0622661 (* 1 = 0.0622661 loss)
I0614 12:56:20.204490  5211 sgd_solver.cpp:43] Iteration 84000, lr = 0.02
I0614 13:09:31.657702  5211 main54.cpp:499] Iteration 84400, Testing net (#0)
I0614 13:10:36.014516  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.861719
I0614 13:10:36.014560  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.614096 (* 1 = 0.614096 loss)
I0614 13:10:38.139448  5211 main54.cpp:387] Iteration 84400, loss = 0.0434364
I0614 13:10:38.139513  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0434357 (* 1 = 0.0434357 loss)
I0614 13:10:38.139530  5211 sgd_solver.cpp:43] Iteration 84400, lr = 0.02
I0614 13:23:45.869433  5211 main54.cpp:499] Iteration 84800, Testing net (#0)
I0614 13:24:49.984289  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.890781
I0614 13:24:49.984333  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.45091 (* 1 = 0.45091 loss)
I0614 13:24:51.967109  5211 main54.cpp:387] Iteration 84800, loss = 0.103927
I0614 13:24:51.967149  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.103926 (* 1 = 0.103926 loss)
I0614 13:24:51.967155  5211 sgd_solver.cpp:43] Iteration 84800, lr = 0.02
I0614 13:38:08.183781  5211 main54.cpp:499] Iteration 85200, Testing net (#0)
I0614 13:39:12.775739  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.886797
I0614 13:39:12.775792  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.475772 (* 1 = 0.475772 loss)
I0614 13:39:14.614555  5211 main54.cpp:387] Iteration 85200, loss = 0.0690729
I0614 13:39:14.614588  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0690722 (* 1 = 0.0690722 loss)
I0614 13:39:14.614595  5211 sgd_solver.cpp:43] Iteration 85200, lr = 0.02
I0614 13:52:29.227048  5211 main54.cpp:499] Iteration 85600, Testing net (#0)
I0614 13:53:33.375907  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.889219
I0614 13:53:33.375957  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.424177 (* 1 = 0.424177 loss)
I0614 13:53:35.560209  5211 main54.cpp:387] Iteration 85600, loss = 0.0568437
I0614 13:53:35.560252  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.056843 (* 1 = 0.056843 loss)
I0614 13:53:35.560264  5211 sgd_solver.cpp:43] Iteration 85600, lr = 0.02
I0614 14:06:51.946837  5211 main54.cpp:499] Iteration 86000, Testing net (#0)
I0614 14:07:55.814322  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.886719
I0614 14:07:55.814371  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.429013 (* 1 = 0.429013 loss)
I0614 14:07:57.706639  5211 main54.cpp:387] Iteration 86000, loss = 0.187961
I0614 14:07:57.706682  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.187961 (* 1 = 0.187961 loss)
I0614 14:07:57.706691  5211 sgd_solver.cpp:43] Iteration 86000, lr = 0.02
I0614 14:21:13.406580  5211 main54.cpp:499] Iteration 86400, Testing net (#0)
I0614 14:22:17.704969  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.893438
I0614 14:22:17.705010  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.417943 (* 1 = 0.417943 loss)
I0614 14:22:19.687795  5211 main54.cpp:387] Iteration 86400, loss = 0.0339138
I0614 14:22:19.687837  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0339131 (* 1 = 0.0339131 loss)
I0614 14:22:19.687844  5211 sgd_solver.cpp:43] Iteration 86400, lr = 0.02
I0614 14:35:34.431821  5211 main54.cpp:499] Iteration 86800, Testing net (#0)
I0614 14:36:38.907304  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.897422
I0614 14:36:38.907351  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.386509 (* 1 = 0.386509 loss)
I0614 14:36:40.785980  5211 main54.cpp:387] Iteration 86800, loss = 0.0591491
I0614 14:36:40.786013  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0591484 (* 1 = 0.0591484 loss)
I0614 14:36:40.786020  5211 sgd_solver.cpp:43] Iteration 86800, lr = 0.02
I0614 14:49:58.281033  5211 main54.cpp:499] Iteration 87200, Testing net (#0)
I0614 14:51:02.679759  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.868828
I0614 14:51:02.679801  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.485228 (* 1 = 0.485228 loss)
I0614 14:51:04.825080  5211 main54.cpp:387] Iteration 87200, loss = 0.0470175
I0614 14:51:04.825114  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0470169 (* 1 = 0.0470169 loss)
I0614 14:51:04.825121  5211 sgd_solver.cpp:43] Iteration 87200, lr = 0.02
I0614 15:04:14.906572  5211 main54.cpp:499] Iteration 87600, Testing net (#0)
I0614 15:05:19.650465  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.877969
I0614 15:05:19.650509  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.504348 (* 1 = 0.504348 loss)
I0614 15:05:21.576839  5211 main54.cpp:387] Iteration 87600, loss = 0.0262262
I0614 15:05:21.576877  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0262255 (* 1 = 0.0262255 loss)
I0614 15:05:21.576885  5211 sgd_solver.cpp:43] Iteration 87600, lr = 0.02
I0614 15:18:39.507431  5211 main54.cpp:499] Iteration 88000, Testing net (#0)
I0614 15:19:44.194871  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.875781
I0614 15:19:44.194916  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.459484 (* 1 = 0.459484 loss)
I0614 15:19:46.271227  5211 main54.cpp:387] Iteration 88000, loss = 0.0694136
I0614 15:19:46.271262  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.069413 (* 1 = 0.069413 loss)
I0614 15:19:46.271270  5211 sgd_solver.cpp:43] Iteration 88000, lr = 0.02
I0614 15:32:57.692392  5211 main54.cpp:499] Iteration 88400, Testing net (#0)
I0614 15:34:02.080109  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.805703
I0614 15:34:02.080150  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.828689 (* 1 = 0.828689 loss)
I0614 15:34:03.983064  5211 main54.cpp:387] Iteration 88400, loss = 0.0753227
I0614 15:34:03.983094  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0753221 (* 1 = 0.0753221 loss)
I0614 15:34:03.983111  5211 sgd_solver.cpp:43] Iteration 88400, lr = 0.02
I0614 15:47:20.972522  5211 main54.cpp:499] Iteration 88800, Testing net (#0)
I0614 15:48:25.329931  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.865469
I0614 15:48:25.329965  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.555408 (* 1 = 0.555408 loss)
I0614 15:48:27.407632  5211 main54.cpp:387] Iteration 88800, loss = 0.10028
I0614 15:48:27.407678  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.10028 (* 1 = 0.10028 loss)
I0614 15:48:27.407690  5211 sgd_solver.cpp:43] Iteration 88800, lr = 0.02
I0614 16:01:42.505276  5211 main54.cpp:499] Iteration 89200, Testing net (#0)
I0614 16:02:46.959096  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.871641
I0614 16:02:46.959146  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.488441 (* 1 = 0.488441 loss)
I0614 16:02:48.895788  5211 main54.cpp:387] Iteration 89200, loss = 0.0469708
I0614 16:02:48.895813  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0469701 (* 1 = 0.0469701 loss)
I0614 16:02:48.895823  5211 sgd_solver.cpp:43] Iteration 89200, lr = 0.02
I0614 16:16:01.102876  5211 main54.cpp:499] Iteration 89600, Testing net (#0)
I0614 16:17:05.509927  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.877187
I0614 16:17:05.509964  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.44942 (* 1 = 0.44942 loss)
I0614 16:17:07.452775  5211 main54.cpp:387] Iteration 89600, loss = 0.105742
I0614 16:17:07.452805  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.105741 (* 1 = 0.105741 loss)
I0614 16:17:07.452811  5211 sgd_solver.cpp:43] Iteration 89600, lr = 0.02
I0614 16:30:23.409600  5211 main54.cpp:499] Iteration 90000, Testing net (#0)
I0614 16:31:27.596267  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.888203
I0614 16:31:27.596315  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.416567 (* 1 = 0.416567 loss)
I0614 16:31:29.613381  5211 main54.cpp:387] Iteration 90000, loss = 0.133961
I0614 16:31:29.613426  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.13396 (* 1 = 0.13396 loss)
I0614 16:31:29.613438  5211 sgd_solver.cpp:43] Iteration 90000, lr = 0.02
I0614 16:44:39.653746  5211 main54.cpp:499] Iteration 90400, Testing net (#0)
I0614 16:45:43.618787  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.863984
I0614 16:45:43.618835  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.553053 (* 1 = 0.553053 loss)
I0614 16:45:45.456778  5211 main54.cpp:387] Iteration 90400, loss = 0.0991272
I0614 16:45:45.456828  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0991265 (* 1 = 0.0991265 loss)
I0614 16:45:45.456835  5211 sgd_solver.cpp:43] Iteration 90400, lr = 0.02
I0614 16:58:51.980942  5211 main54.cpp:499] Iteration 90800, Testing net (#0)
I0614 16:59:55.904485  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.878047
I0614 16:59:55.904541  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.4641 (* 1 = 0.4641 loss)
I0614 16:59:57.594465  5211 main54.cpp:387] Iteration 90800, loss = 0.199847
I0614 16:59:57.594512  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.199846 (* 1 = 0.199846 loss)
I0614 16:59:57.594521  5211 sgd_solver.cpp:43] Iteration 90800, lr = 0.02
I0614 17:13:07.908792  5211 main54.cpp:499] Iteration 91200, Testing net (#0)
I0614 17:14:11.875413  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.875391
I0614 17:14:11.875449  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.48176 (* 1 = 0.48176 loss)
I0614 17:14:13.818361  5211 main54.cpp:387] Iteration 91200, loss = 0.0433156
I0614 17:14:13.818403  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0433148 (* 1 = 0.0433148 loss)
I0614 17:14:13.818409  5211 sgd_solver.cpp:43] Iteration 91200, lr = 0.02
I0614 17:27:24.509358  5211 main54.cpp:499] Iteration 91600, Testing net (#0)
I0614 17:28:28.410315  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.883281
I0614 17:28:28.410362  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.421828 (* 1 = 0.421828 loss)
I0614 17:28:30.484072  5211 main54.cpp:387] Iteration 91600, loss = 0.0506384
I0614 17:28:30.484105  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0506377 (* 1 = 0.0506377 loss)
I0614 17:28:30.484112  5211 sgd_solver.cpp:43] Iteration 91600, lr = 0.02
I0614 17:41:39.569816  5211 main54.cpp:499] Iteration 92000, Testing net (#0)
I0614 17:42:43.440819  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.889687
I0614 17:42:43.440863  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.38215 (* 1 = 0.38215 loss)
I0614 17:42:45.482550  5211 main54.cpp:387] Iteration 92000, loss = 0.0266025
I0614 17:42:45.482594  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0266018 (* 1 = 0.0266018 loss)
I0614 17:42:45.482601  5211 sgd_solver.cpp:43] Iteration 92000, lr = 0.02
I0614 17:55:58.846071  5211 main54.cpp:499] Iteration 92400, Testing net (#0)
I0614 17:57:02.764757  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.877031
I0614 17:57:02.764804  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.524243 (* 1 = 0.524243 loss)
I0614 17:57:04.636111  5211 main54.cpp:387] Iteration 92400, loss = 0.0683406
I0614 17:57:04.636144  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0683399 (* 1 = 0.0683399 loss)
I0614 17:57:04.636150  5211 sgd_solver.cpp:43] Iteration 92400, lr = 0.02
I0614 18:10:15.918925  5211 main54.cpp:499] Iteration 92800, Testing net (#0)
I0614 18:11:19.765666  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.892344
I0614 18:11:19.765703  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.416338 (* 1 = 0.416338 loss)
I0614 18:11:21.736743  5211 main54.cpp:387] Iteration 92800, loss = 0.0251268
I0614 18:11:21.736773  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0251262 (* 1 = 0.0251262 loss)
I0614 18:11:21.736780  5211 sgd_solver.cpp:43] Iteration 92800, lr = 0.02
I0614 18:24:30.397717  5211 main54.cpp:499] Iteration 93200, Testing net (#0)
I0614 18:25:34.327718  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.872266
I0614 18:25:34.327759  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.521023 (* 1 = 0.521023 loss)
I0614 18:25:36.233948  5211 main54.cpp:387] Iteration 93200, loss = 0.0393353
I0614 18:25:36.233989  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0393347 (* 1 = 0.0393347 loss)
I0614 18:25:36.233994  5211 sgd_solver.cpp:43] Iteration 93200, lr = 0.02
I0614 18:38:49.328693  5211 main54.cpp:499] Iteration 93600, Testing net (#0)
I0614 18:39:53.228163  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.895938
I0614 18:39:53.228216  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.410542 (* 1 = 0.410542 loss)
I0614 18:39:55.338057  5211 main54.cpp:387] Iteration 93600, loss = 0.0455247
I0614 18:39:55.338093  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.045524 (* 1 = 0.045524 loss)
I0614 18:39:55.338099  5211 sgd_solver.cpp:43] Iteration 93600, lr = 0.02
I0614 18:53:08.205332  5211 main54.cpp:499] Iteration 94000, Testing net (#0)
I0614 18:54:12.107235  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.894687
I0614 18:54:12.107282  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.407657 (* 1 = 0.407657 loss)
I0614 18:54:14.070483  5211 main54.cpp:387] Iteration 94000, loss = 0.0858765
I0614 18:54:14.070520  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0858758 (* 1 = 0.0858758 loss)
I0614 18:54:14.070526  5211 sgd_solver.cpp:43] Iteration 94000, lr = 0.02
I0614 19:07:24.301802  5211 main54.cpp:499] Iteration 94400, Testing net (#0)
I0614 19:08:28.149067  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.858203
I0614 19:08:28.149109  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.618659 (* 1 = 0.618659 loss)
I0614 19:08:30.117058  5211 main54.cpp:387] Iteration 94400, loss = 0.0879726
I0614 19:08:30.117095  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0879719 (* 1 = 0.0879719 loss)
I0614 19:08:30.117101  5211 sgd_solver.cpp:43] Iteration 94400, lr = 0.02
I0614 19:21:36.879328  5211 main54.cpp:499] Iteration 94800, Testing net (#0)
I0614 19:22:40.782536  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.8525
I0614 19:22:40.782580  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.60004 (* 1 = 0.60004 loss)
I0614 19:22:42.890853  5211 main54.cpp:387] Iteration 94800, loss = 0.0665994
I0614 19:22:42.890894  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0665988 (* 1 = 0.0665988 loss)
I0614 19:22:42.890902  5211 sgd_solver.cpp:43] Iteration 94800, lr = 0.02
I0614 19:35:52.435014  5211 main54.cpp:499] Iteration 95200, Testing net (#0)
I0614 19:36:56.371911  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.868125
I0614 19:36:56.371954  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.573365 (* 1 = 0.573365 loss)
I0614 19:36:58.286147  5211 main54.cpp:387] Iteration 95200, loss = 0.0516514
I0614 19:36:58.286187  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0516507 (* 1 = 0.0516507 loss)
I0614 19:36:58.286195  5211 sgd_solver.cpp:43] Iteration 95200, lr = 0.02
I0614 19:50:09.291889  5211 main54.cpp:499] Iteration 95600, Testing net (#0)
I0614 19:51:13.172667  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.893828
I0614 19:51:13.172713  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.393074 (* 1 = 0.393074 loss)
I0614 19:51:15.008005  5211 main54.cpp:387] Iteration 95600, loss = 0.0863329
I0614 19:51:15.008033  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0863322 (* 1 = 0.0863322 loss)
I0614 19:51:15.008040  5211 sgd_solver.cpp:43] Iteration 95600, lr = 0.02
I0614 20:04:21.484833  5211 main54.cpp:499] Iteration 96000, Testing net (#0)
I0614 20:05:25.469553  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.879531
I0614 20:05:25.469601  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.48771 (* 1 = 0.48771 loss)
I0614 20:05:27.493675  5211 main54.cpp:387] Iteration 96000, loss = 0.0589919
I0614 20:05:27.493710  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0589913 (* 1 = 0.0589913 loss)
I0614 20:05:27.493717  5211 sgd_solver.cpp:43] Iteration 96000, lr = 0.02
I0614 20:18:38.323213  5211 main54.cpp:499] Iteration 96400, Testing net (#0)
I0614 20:19:42.313357  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.855703
I0614 20:19:42.313421  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.588095 (* 1 = 0.588095 loss)
I0614 20:19:44.365480  5211 main54.cpp:387] Iteration 96400, loss = 0.105214
I0614 20:19:44.365519  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.105214 (* 1 = 0.105214 loss)
I0614 20:19:44.365525  5211 sgd_solver.cpp:43] Iteration 96400, lr = 0.02
I0614 20:32:58.793771  5211 main54.cpp:499] Iteration 96800, Testing net (#0)
I0614 20:34:02.887163  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.887031
I0614 20:34:02.887209  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.451993 (* 1 = 0.451993 loss)
I0614 20:34:04.976311  5211 main54.cpp:387] Iteration 96800, loss = 0.0479899
I0614 20:34:04.976346  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0479893 (* 1 = 0.0479893 loss)
I0614 20:34:04.976353  5211 sgd_solver.cpp:43] Iteration 96800, lr = 0.02
I0614 20:47:14.794389  5211 main54.cpp:499] Iteration 97200, Testing net (#0)
I0614 20:48:18.826948  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.837578
I0614 20:48:18.827015  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.783117 (* 1 = 0.783117 loss)
I0614 20:48:20.774266  5211 main54.cpp:387] Iteration 97200, loss = 0.153767
I0614 20:48:20.774322  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.153766 (* 1 = 0.153766 loss)
I0614 20:48:20.774341  5211 sgd_solver.cpp:43] Iteration 97200, lr = 0.02
I0614 21:01:32.120690  5211 main54.cpp:499] Iteration 97600, Testing net (#0)
I0614 21:02:35.925374  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.902578
I0614 21:02:35.925416  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.394804 (* 1 = 0.394804 loss)
I0614 21:02:37.867240  5211 main54.cpp:387] Iteration 97600, loss = 0.0359138
I0614 21:02:37.867275  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0359131 (* 1 = 0.0359131 loss)
I0614 21:02:37.867281  5211 sgd_solver.cpp:43] Iteration 97600, lr = 0.02
I0614 21:15:44.752899  5211 main54.cpp:499] Iteration 98000, Testing net (#0)
I0614 21:16:48.660074  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.871562
I0614 21:16:48.660120  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.550644 (* 1 = 0.550644 loss)
I0614 21:16:50.554574  5211 main54.cpp:387] Iteration 98000, loss = 0.0788042
I0614 21:16:50.554608  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0788034 (* 1 = 0.0788034 loss)
I0614 21:16:50.554616  5211 sgd_solver.cpp:43] Iteration 98000, lr = 0.02
I0614 21:29:58.450240  5211 main54.cpp:499] Iteration 98400, Testing net (#0)
I0614 21:31:02.350064  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.891328
I0614 21:31:02.350109  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.389932 (* 1 = 0.389932 loss)
I0614 21:31:04.312600  5211 main54.cpp:387] Iteration 98400, loss = 0.0607372
I0614 21:31:04.312639  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0607365 (* 1 = 0.0607365 loss)
I0614 21:31:04.312646  5211 sgd_solver.cpp:43] Iteration 98400, lr = 0.02
I0614 21:44:16.266055  5211 main54.cpp:499] Iteration 98800, Testing net (#0)
I0614 21:45:20.145813  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.833516
I0614 21:45:20.145860  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.74162 (* 1 = 0.74162 loss)
I0614 21:45:22.147323  5211 main54.cpp:387] Iteration 98800, loss = 0.0811068
I0614 21:45:22.147361  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.081106 (* 1 = 0.081106 loss)
I0614 21:45:22.147368  5211 sgd_solver.cpp:43] Iteration 98800, lr = 0.02
I0614 21:58:29.071171  5211 main54.cpp:499] Iteration 99200, Testing net (#0)
I0614 21:59:33.045166  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.879609
I0614 21:59:33.045203  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.490878 (* 1 = 0.490878 loss)
I0614 21:59:35.009382  5211 main54.cpp:387] Iteration 99200, loss = 0.102338
I0614 21:59:35.009420  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.102338 (* 1 = 0.102338 loss)
I0614 21:59:35.009428  5211 sgd_solver.cpp:43] Iteration 99200, lr = 0.02
I0614 22:12:46.105278  5211 main54.cpp:499] Iteration 99600, Testing net (#0)
I0614 22:13:50.085664  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.880938
I0614 22:13:50.085712  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.511 (* 1 = 0.511 loss)
I0614 22:13:51.927109  5211 main54.cpp:387] Iteration 99600, loss = 0.0418974
I0614 22:13:51.927144  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0418967 (* 1 = 0.0418967 loss)
I0614 22:13:51.927150  5211 sgd_solver.cpp:43] Iteration 99600, lr = 0.02
I0614 22:27:03.593577  5211 main54.cpp:499] Iteration 100000, Testing net (#0)
I0614 22:28:07.430061  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.876328
I0614 22:28:07.430107  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.481699 (* 1 = 0.481699 loss)
I0614 22:28:09.436203  5211 main54.cpp:387] Iteration 100000, loss = 0.0373651
I0614 22:28:09.436244  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0373644 (* 1 = 0.0373644 loss)
I0614 22:28:09.436251  5211 sgd_solver.cpp:234] MultiStep Status: Iteration 100000, step = 1
I0614 22:28:09.436255  5211 sgd_solver.cpp:43] Iteration 100000, lr = 0.002
I0614 22:41:21.499287  5211 main54.cpp:499] Iteration 100400, Testing net (#0)
I0614 22:42:25.457602  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.917188
I0614 22:42:25.457646  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.309365 (* 1 = 0.309365 loss)
I0614 22:42:27.365761  5211 main54.cpp:387] Iteration 100400, loss = 0.0557964
I0614 22:42:27.365797  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0557957 (* 1 = 0.0557957 loss)
I0614 22:42:27.365803  5211 sgd_solver.cpp:43] Iteration 100400, lr = 0.002
I0614 22:55:35.880631  5211 main54.cpp:499] Iteration 100800, Testing net (#0)
I0614 22:56:39.828095  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.921172
I0614 22:56:39.828140  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.298783 (* 1 = 0.298783 loss)
I0614 22:56:41.732843  5211 main54.cpp:387] Iteration 100800, loss = 0.016027
I0614 22:56:41.732879  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0160263 (* 1 = 0.0160263 loss)
I0614 22:56:41.732887  5211 sgd_solver.cpp:43] Iteration 100800, lr = 0.002
I0614 23:09:55.522788  5211 main54.cpp:499] Iteration 101200, Testing net (#0)
I0614 23:10:59.451695  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.924531
I0614 23:10:59.451733  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.287483 (* 1 = 0.287483 loss)
I0614 23:11:01.373051  5211 main54.cpp:387] Iteration 101200, loss = 0.0435231
I0614 23:11:01.373087  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0435224 (* 1 = 0.0435224 loss)
I0614 23:11:01.373095  5211 sgd_solver.cpp:43] Iteration 101200, lr = 0.002
I0614 23:24:11.039852  5211 main54.cpp:499] Iteration 101600, Testing net (#0)
I0614 23:25:14.943555  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926016
I0614 23:25:14.943609  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.287658 (* 1 = 0.287658 loss)
I0614 23:25:16.882134  5211 main54.cpp:387] Iteration 101600, loss = 0.0111695
I0614 23:25:16.882172  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0111688 (* 1 = 0.0111688 loss)
I0614 23:25:16.882179  5211 sgd_solver.cpp:43] Iteration 101600, lr = 0.002
I0614 23:38:29.546805  5211 main54.cpp:499] Iteration 102000, Testing net (#0)
I0614 23:39:33.413877  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.925156
I0614 23:39:33.413920  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.288745 (* 1 = 0.288745 loss)
I0614 23:39:35.490414  5211 main54.cpp:387] Iteration 102000, loss = 0.0292111
I0614 23:39:35.490447  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0292103 (* 1 = 0.0292103 loss)
I0614 23:39:35.490454  5211 sgd_solver.cpp:43] Iteration 102000, lr = 0.002
I0614 23:52:46.366502  5211 main54.cpp:499] Iteration 102400, Testing net (#0)
I0614 23:53:50.280419  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.924141
I0614 23:53:50.280462  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.305539 (* 1 = 0.305539 loss)
I0614 23:53:52.285997  5211 main54.cpp:387] Iteration 102400, loss = 0.0374207
I0614 23:53:52.286036  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.03742 (* 1 = 0.03742 loss)
I0614 23:53:52.286043  5211 sgd_solver.cpp:43] Iteration 102400, lr = 0.002
I0615 00:07:04.318105  5211 main54.cpp:499] Iteration 102800, Testing net (#0)
I0615 00:08:08.217589  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926328
I0615 00:08:08.217633  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.298872 (* 1 = 0.298872 loss)
I0615 00:08:10.123268  5211 main54.cpp:387] Iteration 102800, loss = 0.0312118
I0615 00:08:10.123320  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0312111 (* 1 = 0.0312111 loss)
I0615 00:08:10.123327  5211 sgd_solver.cpp:43] Iteration 102800, lr = 0.002
I0615 00:21:25.114828  5211 main54.cpp:499] Iteration 103200, Testing net (#0)
I0615 00:22:29.076364  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926094
I0615 00:22:29.076414  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.311225 (* 1 = 0.311225 loss)
I0615 00:22:31.010649  5211 main54.cpp:387] Iteration 103200, loss = 0.0491557
I0615 00:22:31.010681  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.049155 (* 1 = 0.049155 loss)
I0615 00:22:31.010689  5211 sgd_solver.cpp:43] Iteration 103200, lr = 0.002
I0615 00:35:40.109750  5211 main54.cpp:499] Iteration 103600, Testing net (#0)
I0615 00:36:43.989215  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927344
I0615 00:36:43.989260  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.303335 (* 1 = 0.303335 loss)
I0615 00:36:45.954022  5211 main54.cpp:387] Iteration 103600, loss = 0.051768
I0615 00:36:45.954057  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0517673 (* 1 = 0.0517673 loss)
I0615 00:36:45.954064  5211 sgd_solver.cpp:43] Iteration 103600, lr = 0.002
I0615 00:49:55.623431  5211 main54.cpp:499] Iteration 104000, Testing net (#0)
I0615 00:50:59.511358  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929844
I0615 00:50:59.511399  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.291079 (* 1 = 0.291079 loss)
I0615 00:51:01.315038  5211 main54.cpp:387] Iteration 104000, loss = 0.00762205
I0615 00:51:01.315073  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00762132 (* 1 = 0.00762132 loss)
I0615 00:51:01.315079  5211 sgd_solver.cpp:43] Iteration 104000, lr = 0.002
I0615 01:04:12.686595  5211 main54.cpp:499] Iteration 104400, Testing net (#0)
I0615 01:05:16.609210  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.924922
I0615 01:05:16.609252  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.331844 (* 1 = 0.331844 loss)
I0615 01:05:18.683537  5211 main54.cpp:387] Iteration 104400, loss = 0.0145883
I0615 01:05:18.683563  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0145876 (* 1 = 0.0145876 loss)
I0615 01:05:18.683570  5211 sgd_solver.cpp:43] Iteration 104400, lr = 0.002
I0615 01:18:28.556224  5211 main54.cpp:499] Iteration 104800, Testing net (#0)
I0615 01:19:32.479411  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926172
I0615 01:19:32.479455  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.312088 (* 1 = 0.312088 loss)
I0615 01:19:34.445879  5211 main54.cpp:387] Iteration 104800, loss = 0.0539114
I0615 01:19:34.445916  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0539106 (* 1 = 0.0539106 loss)
I0615 01:19:34.445924  5211 sgd_solver.cpp:43] Iteration 104800, lr = 0.002
I0615 01:32:46.502791  5211 main54.cpp:499] Iteration 105200, Testing net (#0)
I0615 01:33:50.354115  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926484
I0615 01:33:50.354161  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.319458 (* 1 = 0.319458 loss)
I0615 01:33:52.222740  5211 main54.cpp:387] Iteration 105200, loss = 0.0436939
I0615 01:33:52.222771  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0436931 (* 1 = 0.0436931 loss)
I0615 01:33:52.222781  5211 sgd_solver.cpp:43] Iteration 105200, lr = 0.002
I0615 01:47:00.833387  5211 main54.cpp:499] Iteration 105600, Testing net (#0)
I0615 01:48:04.845811  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927266
I0615 01:48:04.845856  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.318493 (* 1 = 0.318493 loss)
I0615 01:48:06.745430  5211 main54.cpp:387] Iteration 105600, loss = 0.0141082
I0615 01:48:06.745468  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0141074 (* 1 = 0.0141074 loss)
I0615 01:48:06.745476  5211 sgd_solver.cpp:43] Iteration 105600, lr = 0.002
I0615 02:01:15.585083  5211 main54.cpp:499] Iteration 106000, Testing net (#0)
I0615 02:02:20.294752  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.925937
I0615 02:02:20.294795  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.321812 (* 1 = 0.321812 loss)
I0615 02:02:22.089339  5211 main54.cpp:387] Iteration 106000, loss = 0.00984186
I0615 02:02:22.089377  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00984108 (* 1 = 0.00984108 loss)
I0615 02:02:22.089385  5211 sgd_solver.cpp:43] Iteration 106000, lr = 0.002
I0615 02:15:34.747658  5211 main54.cpp:499] Iteration 106400, Testing net (#0)
I0615 02:16:39.215250  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927969
I0615 02:16:39.215291  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.31537 (* 1 = 0.31537 loss)
I0615 02:16:41.036772  5211 main54.cpp:387] Iteration 106400, loss = 0.0378792
I0615 02:16:41.036801  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0378784 (* 1 = 0.0378784 loss)
I0615 02:16:41.036808  5211 sgd_solver.cpp:43] Iteration 106400, lr = 0.002
I0615 02:29:53.525475  5211 main54.cpp:499] Iteration 106800, Testing net (#0)
I0615 02:30:57.861860  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.92875
I0615 02:30:57.861896  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.310092 (* 1 = 0.310092 loss)
I0615 02:30:59.742388  5211 main54.cpp:387] Iteration 106800, loss = 0.0940884
I0615 02:30:59.742413  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0940876 (* 1 = 0.0940876 loss)
I0615 02:30:59.742421  5211 sgd_solver.cpp:43] Iteration 106800, lr = 0.002
I0615 02:44:10.674463  5211 main54.cpp:499] Iteration 107200, Testing net (#0)
I0615 02:45:15.321300  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927969
I0615 02:45:15.321352  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.323689 (* 1 = 0.323689 loss)
I0615 02:45:17.246422  5211 main54.cpp:387] Iteration 107200, loss = 0.0258395
I0615 02:45:17.246457  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0258387 (* 1 = 0.0258387 loss)
I0615 02:45:17.246465  5211 sgd_solver.cpp:43] Iteration 107200, lr = 0.002
I0615 02:58:33.010756  5211 main54.cpp:499] Iteration 107600, Testing net (#0)
I0615 02:59:37.366816  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927734
I0615 02:59:37.366866  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.334312 (* 1 = 0.334312 loss)
I0615 02:59:39.381136  5211 main54.cpp:387] Iteration 107600, loss = 0.0115855
I0615 02:59:39.381181  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0115847 (* 1 = 0.0115847 loss)
I0615 02:59:39.381188  5211 sgd_solver.cpp:43] Iteration 107600, lr = 0.002
I0615 03:12:55.987085  5211 main54.cpp:499] Iteration 108000, Testing net (#0)
I0615 03:14:00.546571  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926406
I0615 03:14:00.546617  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.333331 (* 1 = 0.333331 loss)
I0615 03:14:02.519387  5211 main54.cpp:387] Iteration 108000, loss = 0.0260435
I0615 03:14:02.519420  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0260428 (* 1 = 0.0260428 loss)
I0615 03:14:02.519428  5211 sgd_solver.cpp:43] Iteration 108000, lr = 0.002
I0615 03:27:13.049217  5211 main54.cpp:499] Iteration 108400, Testing net (#0)
I0615 03:28:17.463119  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928594
I0615 03:28:17.463158  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.320249 (* 1 = 0.320249 loss)
I0615 03:28:19.264490  5211 main54.cpp:387] Iteration 108400, loss = 0.0710932
I0615 03:28:19.264525  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0710924 (* 1 = 0.0710924 loss)
I0615 03:28:19.264533  5211 sgd_solver.cpp:43] Iteration 108400, lr = 0.002
I0615 03:41:33.752770  5211 main54.cpp:499] Iteration 108800, Testing net (#0)
I0615 03:42:38.099778  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.925547
I0615 03:42:38.099822  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.344778 (* 1 = 0.344778 loss)
I0615 03:42:39.855594  5211 main54.cpp:387] Iteration 108800, loss = 0.0280827
I0615 03:42:39.855628  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0280819 (* 1 = 0.0280819 loss)
I0615 03:42:39.855636  5211 sgd_solver.cpp:43] Iteration 108800, lr = 0.002
I0615 03:55:55.671421  5211 main54.cpp:499] Iteration 109200, Testing net (#0)
I0615 03:57:00.059365  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927969
I0615 03:57:00.059412  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.329366 (* 1 = 0.329366 loss)
I0615 03:57:01.613294  5211 main54.cpp:387] Iteration 109200, loss = 0.0443604
I0615 03:57:01.613318  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0443596 (* 1 = 0.0443596 loss)
I0615 03:57:01.613324  5211 sgd_solver.cpp:43] Iteration 109200, lr = 0.002
I0615 04:10:18.890697  5211 main54.cpp:499] Iteration 109600, Testing net (#0)
I0615 04:11:23.032138  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929766
I0615 04:11:23.032181  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.326855 (* 1 = 0.326855 loss)
I0615 04:11:25.106531  5211 main54.cpp:387] Iteration 109600, loss = 0.0227948
I0615 04:11:25.106575  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0227941 (* 1 = 0.0227941 loss)
I0615 04:11:25.106585  5211 sgd_solver.cpp:43] Iteration 109600, lr = 0.002
I0615 04:24:43.748385  5211 main54.cpp:499] Iteration 110000, Testing net (#0)
I0615 04:25:47.841229  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927813
I0615 04:25:47.841275  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.342772 (* 1 = 0.342772 loss)
I0615 04:25:49.844792  5211 main54.cpp:387] Iteration 110000, loss = 0.0266576
I0615 04:25:49.844841  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0266569 (* 1 = 0.0266569 loss)
I0615 04:25:49.844848  5211 sgd_solver.cpp:43] Iteration 110000, lr = 0.002
I0615 04:39:01.879123  5211 main54.cpp:499] Iteration 110400, Testing net (#0)
I0615 04:40:06.202404  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.925469
I0615 04:40:06.202445  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.346173 (* 1 = 0.346173 loss)
I0615 04:40:08.211040  5211 main54.cpp:387] Iteration 110400, loss = 0.0241744
I0615 04:40:08.211086  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0241737 (* 1 = 0.0241737 loss)
I0615 04:40:08.211097  5211 sgd_solver.cpp:43] Iteration 110400, lr = 0.002
I0615 04:53:26.461062  5211 main54.cpp:499] Iteration 110800, Testing net (#0)
I0615 04:54:30.862934  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.923359
I0615 04:54:30.862984  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.366769 (* 1 = 0.366769 loss)
I0615 04:54:32.913296  5211 main54.cpp:387] Iteration 110800, loss = 0.0119388
I0615 04:54:32.913336  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.011938 (* 1 = 0.011938 loss)
I0615 04:54:32.913344  5211 sgd_solver.cpp:43] Iteration 110800, lr = 0.002
I0615 05:07:51.066519  5211 main54.cpp:499] Iteration 111200, Testing net (#0)
I0615 05:08:55.482970  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.9275
I0615 05:08:55.483021  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.347754 (* 1 = 0.347754 loss)
I0615 05:08:57.560356  5211 main54.cpp:387] Iteration 111200, loss = 0.019858
I0615 05:08:57.560416  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0198573 (* 1 = 0.0198573 loss)
I0615 05:08:57.560423  5211 sgd_solver.cpp:43] Iteration 111200, lr = 0.002
I0615 05:22:10.653642  5211 main54.cpp:499] Iteration 111600, Testing net (#0)
I0615 05:23:14.991385  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927813
I0615 05:23:14.991430  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.34857 (* 1 = 0.34857 loss)
I0615 05:23:17.178519  5211 main54.cpp:387] Iteration 111600, loss = 0.00895017
I0615 05:23:17.178566  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00894945 (* 1 = 0.00894945 loss)
I0615 05:23:17.178573  5211 sgd_solver.cpp:43] Iteration 111600, lr = 0.002
I0615 05:36:29.955705  5211 main54.cpp:499] Iteration 112000, Testing net (#0)
I0615 05:37:34.297885  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926797
I0615 05:37:34.297940  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.367847 (* 1 = 0.367847 loss)
I0615 05:37:36.172329  5211 main54.cpp:387] Iteration 112000, loss = 0.00748709
I0615 05:37:36.172363  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00748639 (* 1 = 0.00748639 loss)
I0615 05:37:36.172370  5211 sgd_solver.cpp:43] Iteration 112000, lr = 0.002
I0615 05:50:53.282512  5211 main54.cpp:499] Iteration 112400, Testing net (#0)
I0615 05:51:57.777719  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.9275
I0615 05:51:57.777767  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.35171 (* 1 = 0.35171 loss)
I0615 05:51:59.746043  5211 main54.cpp:387] Iteration 112400, loss = 0.0223908
I0615 05:51:59.746068  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0223901 (* 1 = 0.0223901 loss)
I0615 05:51:59.746075  5211 sgd_solver.cpp:43] Iteration 112400, lr = 0.002
I0615 06:05:12.744062  5211 main54.cpp:499] Iteration 112800, Testing net (#0)
I0615 06:06:17.293895  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928047
I0615 06:06:17.293936  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.358512 (* 1 = 0.358512 loss)
I0615 06:06:19.197558  5211 main54.cpp:387] Iteration 112800, loss = 0.0137644
I0615 06:06:19.197595  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0137637 (* 1 = 0.0137637 loss)
I0615 06:06:19.197602  5211 sgd_solver.cpp:43] Iteration 112800, lr = 0.002
I0615 06:19:35.793983  5211 main54.cpp:499] Iteration 113200, Testing net (#0)
I0615 06:20:40.440165  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927734
I0615 06:20:40.440210  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.350974 (* 1 = 0.350974 loss)
I0615 06:20:42.625143  5211 main54.cpp:387] Iteration 113200, loss = 0.0012814
I0615 06:20:42.625193  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00128073 (* 1 = 0.00128073 loss)
I0615 06:20:42.625205  5211 sgd_solver.cpp:43] Iteration 113200, lr = 0.002
I0615 06:33:51.331714  5211 main54.cpp:499] Iteration 113600, Testing net (#0)
I0615 06:34:55.567262  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926641
I0615 06:34:55.567306  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.361046 (* 1 = 0.361046 loss)
I0615 06:34:57.706241  5211 main54.cpp:387] Iteration 113600, loss = 0.00405209
I0615 06:34:57.706287  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00405141 (* 1 = 0.00405141 loss)
I0615 06:34:57.706296  5211 sgd_solver.cpp:43] Iteration 113600, lr = 0.002
I0615 06:48:11.937762  5211 main54.cpp:499] Iteration 114000, Testing net (#0)
I0615 06:49:16.307023  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929609
I0615 06:49:16.307077  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.342842 (* 1 = 0.342842 loss)
I0615 06:49:17.846665  5211 main54.cpp:387] Iteration 114000, loss = 0.0648345
I0615 06:49:17.846698  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0648338 (* 1 = 0.0648338 loss)
I0615 06:49:17.846705  5211 sgd_solver.cpp:43] Iteration 114000, lr = 0.002
I0615 07:02:37.477741  5211 main54.cpp:499] Iteration 114400, Testing net (#0)
I0615 07:03:41.677803  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.925703
I0615 07:03:41.677847  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.365421 (* 1 = 0.365421 loss)
I0615 07:03:43.659353  5211 main54.cpp:387] Iteration 114400, loss = 0.0147322
I0615 07:03:43.659384  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0147315 (* 1 = 0.0147315 loss)
I0615 07:03:43.659391  5211 sgd_solver.cpp:43] Iteration 114400, lr = 0.002
I0615 07:16:59.326896  5211 main54.cpp:499] Iteration 114800, Testing net (#0)
I0615 07:18:03.877378  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926094
I0615 07:18:03.877420  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.368163 (* 1 = 0.368163 loss)
I0615 07:18:05.942539  5211 main54.cpp:387] Iteration 114800, loss = 0.00880633
I0615 07:18:05.942587  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00880569 (* 1 = 0.00880569 loss)
I0615 07:18:05.942596  5211 sgd_solver.cpp:43] Iteration 114800, lr = 0.002
I0615 07:31:27.079092  5211 main54.cpp:499] Iteration 115200, Testing net (#0)
I0615 07:32:31.409299  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926562
I0615 07:32:31.409344  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.361583 (* 1 = 0.361583 loss)
I0615 07:32:33.325199  5211 main54.cpp:387] Iteration 115200, loss = 0.00488598
I0615 07:32:33.325245  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00488535 (* 1 = 0.00488535 loss)
I0615 07:32:33.325254  5211 sgd_solver.cpp:43] Iteration 115200, lr = 0.002
I0615 07:45:49.745993  5211 main54.cpp:499] Iteration 115600, Testing net (#0)
I0615 07:46:53.845504  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.93
I0615 07:46:53.845546  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.355492 (* 1 = 0.355492 loss)
I0615 07:46:55.677119  5211 main54.cpp:387] Iteration 115600, loss = 0.00449944
I0615 07:46:55.677146  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00449878 (* 1 = 0.00449878 loss)
I0615 07:46:55.677152  5211 sgd_solver.cpp:43] Iteration 115600, lr = 0.002
I0615 08:00:13.872992  5211 main54.cpp:499] Iteration 116000, Testing net (#0)
I0615 08:01:17.995817  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926016
I0615 08:01:17.995859  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.370491 (* 1 = 0.370491 loss)
I0615 08:01:19.830963  5211 main54.cpp:387] Iteration 116000, loss = 0.0694828
I0615 08:01:19.830997  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0694821 (* 1 = 0.0694821 loss)
I0615 08:01:19.831006  5211 sgd_solver.cpp:43] Iteration 116000, lr = 0.002
I0615 08:14:34.370090  5211 main54.cpp:499] Iteration 116400, Testing net (#0)
I0615 08:15:38.929538  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927188
I0615 08:15:38.929592  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.356862 (* 1 = 0.356862 loss)
I0615 08:15:40.647764  5211 main54.cpp:387] Iteration 116400, loss = 0.179832
I0615 08:15:40.647796  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.179831 (* 1 = 0.179831 loss)
I0615 08:15:40.647804  5211 sgd_solver.cpp:43] Iteration 116400, lr = 0.002
I0615 08:29:01.439780  5211 main54.cpp:499] Iteration 116800, Testing net (#0)
I0615 08:30:05.908318  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927422
I0615 08:30:05.908356  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.361559 (* 1 = 0.361559 loss)
I0615 08:30:07.881078  5211 main54.cpp:387] Iteration 116800, loss = 0.0175146
I0615 08:30:07.881120  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.017514 (* 1 = 0.017514 loss)
I0615 08:30:07.881127  5211 sgd_solver.cpp:43] Iteration 116800, lr = 0.002
I0615 08:43:21.142277  5211 main54.cpp:499] Iteration 117200, Testing net (#0)
I0615 08:44:25.505306  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.925313
I0615 08:44:25.505355  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.385588 (* 1 = 0.385588 loss)
I0615 08:44:27.373364  5211 main54.cpp:387] Iteration 117200, loss = 0.00490487
I0615 08:44:27.373390  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00490427 (* 1 = 0.00490427 loss)
I0615 08:44:27.373397  5211 sgd_solver.cpp:43] Iteration 117200, lr = 0.002
I0615 08:57:42.167959  5211 main54.cpp:499] Iteration 117600, Testing net (#0)
I0615 08:58:46.291471  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928828
I0615 08:58:46.291512  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.359168 (* 1 = 0.359168 loss)
I0615 08:58:48.251164  5211 main54.cpp:387] Iteration 117600, loss = 0.0105006
I0615 08:58:48.251188  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0105 (* 1 = 0.0105 loss)
I0615 08:58:48.251200  5211 sgd_solver.cpp:43] Iteration 117600, lr = 0.002
I0615 09:12:05.869549  5211 main54.cpp:499] Iteration 118000, Testing net (#0)
I0615 09:13:09.978031  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928047
I0615 09:13:09.978075  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.371745 (* 1 = 0.371745 loss)
I0615 09:13:12.022933  5211 main54.cpp:387] Iteration 118000, loss = 0.00116872
I0615 09:13:12.022975  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00116813 (* 1 = 0.00116813 loss)
I0615 09:13:12.022984  5211 sgd_solver.cpp:43] Iteration 118000, lr = 0.002
I0615 09:26:22.147526  5211 main54.cpp:499] Iteration 118400, Testing net (#0)
I0615 09:27:27.068192  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.925781
I0615 09:27:27.068248  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.371471 (* 1 = 0.371471 loss)
I0615 09:27:28.941778  5211 main54.cpp:387] Iteration 118400, loss = 0.00749948
I0615 09:27:28.941802  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00749886 (* 1 = 0.00749886 loss)
I0615 09:27:28.941809  5211 sgd_solver.cpp:43] Iteration 118400, lr = 0.002
I0615 09:40:42.065675  5211 main54.cpp:499] Iteration 118800, Testing net (#0)
I0615 09:41:45.857592  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927891
I0615 09:41:45.857635  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.368615 (* 1 = 0.368615 loss)
I0615 09:41:47.716584  5211 main54.cpp:387] Iteration 118800, loss = 0.00750547
I0615 09:41:47.716639  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00750482 (* 1 = 0.00750482 loss)
I0615 09:41:47.716647  5211 sgd_solver.cpp:43] Iteration 118800, lr = 0.002
I0615 09:55:00.445122  5211 main54.cpp:499] Iteration 119200, Testing net (#0)
I0615 09:56:04.773146  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928516
I0615 09:56:04.773191  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.359225 (* 1 = 0.359225 loss)
I0615 09:56:06.759387  5211 main54.cpp:387] Iteration 119200, loss = 0.00495723
I0615 09:56:06.759434  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0049566 (* 1 = 0.0049566 loss)
I0615 09:56:06.759443  5211 sgd_solver.cpp:43] Iteration 119200, lr = 0.002
I0615 10:09:24.952888  5211 main54.cpp:499] Iteration 119600, Testing net (#0)
I0615 10:10:29.696605  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929219
I0615 10:10:29.696661  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.347817 (* 1 = 0.347817 loss)
I0615 10:10:31.733212  5211 main54.cpp:387] Iteration 119600, loss = 0.00419541
I0615 10:10:31.733235  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00419477 (* 1 = 0.00419477 loss)
I0615 10:10:31.733242  5211 sgd_solver.cpp:43] Iteration 119600, lr = 0.002
I0615 10:23:42.966296  5211 main54.cpp:499] Iteration 120000, Testing net (#0)
I0615 10:24:46.833086  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926016
I0615 10:24:46.833132  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.380394 (* 1 = 0.380394 loss)
I0615 10:24:48.936277  5211 main54.cpp:387] Iteration 120000, loss = 0.000530258
I0615 10:24:48.936313  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000529607 (* 1 = 0.000529607 loss)
I0615 10:24:48.936321  5211 sgd_solver.cpp:43] Iteration 120000, lr = 0.002
I0615 10:37:58.040751  5211 main54.cpp:499] Iteration 120400, Testing net (#0)
I0615 10:39:01.694988  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927188
I0615 10:39:01.695032  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.365327 (* 1 = 0.365327 loss)
I0615 10:39:03.823668  5211 main54.cpp:387] Iteration 120400, loss = 0.00740471
I0615 10:39:03.823701  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00740404 (* 1 = 0.00740404 loss)
I0615 10:39:03.823709  5211 sgd_solver.cpp:43] Iteration 120400, lr = 0.002
I0615 10:52:17.011456  5211 main54.cpp:499] Iteration 120800, Testing net (#0)
I0615 10:53:21.522260  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.924531
I0615 10:53:21.522318  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.367582 (* 1 = 0.367582 loss)
I0615 10:53:23.570618  5211 main54.cpp:387] Iteration 120800, loss = 0.0033419
I0615 10:53:23.570655  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00334124 (* 1 = 0.00334124 loss)
I0615 10:53:23.570662  5211 sgd_solver.cpp:43] Iteration 120800, lr = 0.002
I0615 11:06:33.862890  5211 main54.cpp:499] Iteration 121200, Testing net (#0)
I0615 11:07:37.981112  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929297
I0615 11:07:37.981161  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.361483 (* 1 = 0.361483 loss)
I0615 11:07:39.789875  5211 main54.cpp:387] Iteration 121200, loss = 0.0167535
I0615 11:07:39.789916  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0167528 (* 1 = 0.0167528 loss)
I0615 11:07:39.789926  5211 sgd_solver.cpp:43] Iteration 121200, lr = 0.002
I0615 11:20:53.490109  5211 main54.cpp:499] Iteration 121600, Testing net (#0)
I0615 11:21:58.421607  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.923516
I0615 11:21:58.421668  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.383309 (* 1 = 0.383309 loss)
I0615 11:22:00.361001  5211 main54.cpp:387] Iteration 121600, loss = 0.0261103
I0615 11:22:00.361027  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0261096 (* 1 = 0.0261096 loss)
I0615 11:22:00.361034  5211 sgd_solver.cpp:43] Iteration 121600, lr = 0.002
I0615 11:35:17.736516  5211 main54.cpp:499] Iteration 122000, Testing net (#0)
I0615 11:36:21.947870  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927266
I0615 11:36:21.947932  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.355883 (* 1 = 0.355883 loss)
I0615 11:36:23.767868  5211 main54.cpp:387] Iteration 122000, loss = 0.0183191
I0615 11:36:23.767913  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0183184 (* 1 = 0.0183184 loss)
I0615 11:36:23.767923  5211 sgd_solver.cpp:43] Iteration 122000, lr = 0.002
I0615 11:49:31.877770  5211 main54.cpp:499] Iteration 122400, Testing net (#0)
I0615 11:50:35.359092  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927891
I0615 11:50:35.359139  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.364476 (* 1 = 0.364476 loss)
I0615 11:50:37.314334  5211 main54.cpp:387] Iteration 122400, loss = 0.0236483
I0615 11:50:37.314376  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0236476 (* 1 = 0.0236476 loss)
I0615 11:50:37.314383  5211 sgd_solver.cpp:43] Iteration 122400, lr = 0.002
I0615 12:03:47.146102  5211 main54.cpp:499] Iteration 122800, Testing net (#0)
I0615 12:04:51.887033  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927188
I0615 12:04:51.887082  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.370694 (* 1 = 0.370694 loss)
I0615 12:04:53.654458  5211 main54.cpp:387] Iteration 122800, loss = 0.0116389
I0615 12:04:53.654489  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0116383 (* 1 = 0.0116383 loss)
I0615 12:04:53.654496  5211 sgd_solver.cpp:43] Iteration 122800, lr = 0.002
I0615 12:18:06.696234  5211 main54.cpp:499] Iteration 123200, Testing net (#0)
I0615 12:19:10.893051  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928281
I0615 12:19:10.893101  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.362135 (* 1 = 0.362135 loss)
I0615 12:19:12.925845  5211 main54.cpp:387] Iteration 123200, loss = 0.0065267
I0615 12:19:12.925874  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00652607 (* 1 = 0.00652607 loss)
I0615 12:19:12.925882  5211 sgd_solver.cpp:43] Iteration 123200, lr = 0.002
I0615 12:32:15.141346  5211 main54.cpp:499] Iteration 123600, Testing net (#0)
I0615 12:33:18.953560  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.92625
I0615 12:33:18.953619  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.376825 (* 1 = 0.376825 loss)
I0615 12:33:20.767803  5211 main54.cpp:387] Iteration 123600, loss = 0.0146032
I0615 12:33:20.767834  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0146026 (* 1 = 0.0146026 loss)
I0615 12:33:20.767841  5211 sgd_solver.cpp:43] Iteration 123600, lr = 0.002
I0615 12:46:33.412288  5211 main54.cpp:499] Iteration 124000, Testing net (#0)
I0615 12:47:37.759572  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928594
I0615 12:47:37.759611  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.358738 (* 1 = 0.358738 loss)
I0615 12:47:39.541059  5211 main54.cpp:387] Iteration 124000, loss = 0.0849121
I0615 12:47:39.541084  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0849115 (* 1 = 0.0849115 loss)
I0615 12:47:39.541095  5211 sgd_solver.cpp:43] Iteration 124000, lr = 0.002
I0615 13:00:50.142993  5211 main54.cpp:499] Iteration 124400, Testing net (#0)
I0615 13:01:53.926764  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928047
I0615 13:01:53.926803  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.374478 (* 1 = 0.374478 loss)
I0615 13:01:55.868815  5211 main54.cpp:387] Iteration 124400, loss = 0.00573219
I0615 13:01:55.868846  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00573155 (* 1 = 0.00573155 loss)
I0615 13:01:55.868862  5211 sgd_solver.cpp:43] Iteration 124400, lr = 0.002
I0615 13:15:05.230090  5211 main54.cpp:499] Iteration 124800, Testing net (#0)
I0615 13:16:08.870522  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.925078
I0615 13:16:08.870563  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.378504 (* 1 = 0.378504 loss)
I0615 13:16:10.705271  5211 main54.cpp:387] Iteration 124800, loss = 0.0953183
I0615 13:16:10.705296  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0953176 (* 1 = 0.0953176 loss)
I0615 13:16:10.705302  5211 sgd_solver.cpp:43] Iteration 124800, lr = 0.002
I0615 13:29:17.377835  5211 main54.cpp:499] Iteration 125200, Testing net (#0)
I0615 13:30:21.210170  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929922
I0615 13:30:21.210253  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.368473 (* 1 = 0.368473 loss)
I0615 13:30:23.380630  5211 main54.cpp:387] Iteration 125200, loss = 0.00757762
I0615 13:30:23.380669  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00757692 (* 1 = 0.00757692 loss)
I0615 13:30:23.380678  5211 sgd_solver.cpp:43] Iteration 125200, lr = 0.002
I0615 13:43:31.701125  5211 main54.cpp:499] Iteration 125600, Testing net (#0)
I0615 13:44:35.563129  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929297
I0615 13:44:35.563166  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.367544 (* 1 = 0.367544 loss)
I0615 13:44:37.704865  5211 main54.cpp:387] Iteration 125600, loss = 0.00807303
I0615 13:44:37.704915  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00807232 (* 1 = 0.00807232 loss)
I0615 13:44:37.704921  5211 sgd_solver.cpp:43] Iteration 125600, lr = 0.002
I0615 13:57:46.581089  5211 main54.cpp:499] Iteration 126000, Testing net (#0)
I0615 13:58:50.845537  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928047
I0615 13:58:50.845582  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.381757 (* 1 = 0.381757 loss)
I0615 13:58:52.684473  5211 main54.cpp:387] Iteration 126000, loss = 0.00070886
I0615 13:58:52.684515  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000708145 (* 1 = 0.000708145 loss)
I0615 13:58:52.684523  5211 sgd_solver.cpp:43] Iteration 126000, lr = 0.002
I0615 14:12:03.119981  5211 main54.cpp:499] Iteration 126400, Testing net (#0)
I0615 14:13:06.978312  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929141
I0615 14:13:06.978368  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.37837 (* 1 = 0.37837 loss)
I0615 14:13:08.901391  5211 main54.cpp:387] Iteration 126400, loss = 0.00170069
I0615 14:13:08.901420  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00170002 (* 1 = 0.00170002 loss)
I0615 14:13:08.901428  5211 sgd_solver.cpp:43] Iteration 126400, lr = 0.002
I0615 14:26:16.755998  5211 main54.cpp:499] Iteration 126800, Testing net (#0)
I0615 14:27:20.873462  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926719
I0615 14:27:20.873505  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.376252 (* 1 = 0.376252 loss)
I0615 14:27:22.776314  5211 main54.cpp:387] Iteration 126800, loss = 0.0160983
I0615 14:27:22.776348  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0160976 (* 1 = 0.0160976 loss)
I0615 14:27:22.776355  5211 sgd_solver.cpp:43] Iteration 126800, lr = 0.002
I0615 14:40:33.762923  5211 main54.cpp:499] Iteration 127200, Testing net (#0)
I0615 14:41:37.970820  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.924922
I0615 14:41:37.970859  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.395214 (* 1 = 0.395214 loss)
I0615 14:41:39.926205  5211 main54.cpp:387] Iteration 127200, loss = 0.00180805
I0615 14:41:39.926246  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0018074 (* 1 = 0.0018074 loss)
I0615 14:41:39.926254  5211 sgd_solver.cpp:43] Iteration 127200, lr = 0.002
I0615 14:54:47.637655  5211 main54.cpp:499] Iteration 127600, Testing net (#0)
I0615 14:55:51.223402  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928594
I0615 14:55:51.223444  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.378232 (* 1 = 0.378232 loss)
I0615 14:55:53.123410  5211 main54.cpp:387] Iteration 127600, loss = 0.0210287
I0615 14:55:53.123457  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.021028 (* 1 = 0.021028 loss)
I0615 14:55:53.123466  5211 sgd_solver.cpp:43] Iteration 127600, lr = 0.002
I0615 15:08:59.436390  5211 main54.cpp:499] Iteration 128000, Testing net (#0)
I0615 15:10:02.851476  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929453
I0615 15:10:02.851522  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.381953 (* 1 = 0.381953 loss)
I0615 15:10:04.668598  5211 main54.cpp:387] Iteration 128000, loss = 0.00961657
I0615 15:10:04.668629  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00961591 (* 1 = 0.00961591 loss)
I0615 15:10:04.668635  5211 sgd_solver.cpp:43] Iteration 128000, lr = 0.002
I0615 15:23:09.628692  5211 main54.cpp:499] Iteration 128400, Testing net (#0)
I0615 15:24:12.973685  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927109
I0615 15:24:12.973728  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.394705 (* 1 = 0.394705 loss)
I0615 15:24:14.928244  5211 main54.cpp:387] Iteration 128400, loss = 0.00148143
I0615 15:24:14.928290  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00148078 (* 1 = 0.00148078 loss)
I0615 15:24:14.928298  5211 sgd_solver.cpp:43] Iteration 128400, lr = 0.002
I0615 15:37:18.335256  5211 main54.cpp:499] Iteration 128800, Testing net (#0)
I0615 15:38:21.706207  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927578
I0615 15:38:21.706248  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.388337 (* 1 = 0.388337 loss)
I0615 15:38:23.648401  5211 main54.cpp:387] Iteration 128800, loss = 0.0103102
I0615 15:38:23.648428  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0103096 (* 1 = 0.0103096 loss)
I0615 15:38:23.648435  5211 sgd_solver.cpp:43] Iteration 128800, lr = 0.002
I0615 15:51:24.525038  5211 main54.cpp:499] Iteration 129200, Testing net (#0)
I0615 15:52:27.967608  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927109
I0615 15:52:27.967653  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.38189 (* 1 = 0.38189 loss)
I0615 15:52:29.795138  5211 main54.cpp:387] Iteration 129200, loss = 0.0081689
I0615 15:52:29.795176  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00816826 (* 1 = 0.00816826 loss)
I0615 15:52:29.795183  5211 sgd_solver.cpp:43] Iteration 129200, lr = 0.002
I0615 16:05:32.318610  5211 main54.cpp:499] Iteration 129600, Testing net (#0)
I0615 16:06:35.763177  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926797
I0615 16:06:35.763223  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.372392 (* 1 = 0.372392 loss)
I0615 16:06:37.823768  5211 main54.cpp:387] Iteration 129600, loss = 0.00114653
I0615 16:06:37.823807  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00114592 (* 1 = 0.00114592 loss)
I0615 16:06:37.823813  5211 sgd_solver.cpp:43] Iteration 129600, lr = 0.002
I0615 16:19:43.934243  5211 main54.cpp:499] Iteration 130000, Testing net (#0)
I0615 16:20:47.315013  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928281
I0615 16:20:47.315058  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.382523 (* 1 = 0.382523 loss)
I0615 16:20:49.297471  5211 main54.cpp:387] Iteration 130000, loss = 0.00158662
I0615 16:20:49.297502  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00158601 (* 1 = 0.00158601 loss)
I0615 16:20:49.297509  5211 sgd_solver.cpp:43] Iteration 130000, lr = 0.002
I0615 16:33:55.048816  5211 main54.cpp:499] Iteration 130400, Testing net (#0)
I0615 16:34:58.384277  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927109
I0615 16:34:58.384321  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.374494 (* 1 = 0.374494 loss)
I0615 16:35:00.512678  5211 main54.cpp:387] Iteration 130400, loss = 0.00107579
I0615 16:35:00.512712  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00107518 (* 1 = 0.00107518 loss)
I0615 16:35:00.512719  5211 sgd_solver.cpp:43] Iteration 130400, lr = 0.002
I0615 16:48:01.945780  5211 main54.cpp:499] Iteration 130800, Testing net (#0)
I0615 16:49:05.371788  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928594
I0615 16:49:05.371834  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.387818 (* 1 = 0.387818 loss)
I0615 16:49:07.495669  5211 main54.cpp:387] Iteration 130800, loss = 0.00464602
I0615 16:49:07.495724  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00464544 (* 1 = 0.00464544 loss)
I0615 16:49:07.495731  5211 sgd_solver.cpp:43] Iteration 130800, lr = 0.002
I0615 17:02:08.567927  5211 main54.cpp:499] Iteration 131200, Testing net (#0)
I0615 17:03:12.003801  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927578
I0615 17:03:12.003842  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.393392 (* 1 = 0.393392 loss)
I0615 17:03:13.996953  5211 main54.cpp:387] Iteration 131200, loss = 0.0033456
I0615 17:03:13.996986  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00334502 (* 1 = 0.00334502 loss)
I0615 17:03:13.996992  5211 sgd_solver.cpp:43] Iteration 131200, lr = 0.002
I0615 17:16:16.908565  5211 main54.cpp:499] Iteration 131600, Testing net (#0)
I0615 17:17:20.353595  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928281
I0615 17:17:20.353634  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.384396 (* 1 = 0.384396 loss)
I0615 17:17:22.415319  5211 main54.cpp:387] Iteration 131600, loss = 0.0338458
I0615 17:17:22.415354  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0338452 (* 1 = 0.0338452 loss)
I0615 17:17:22.415360  5211 sgd_solver.cpp:43] Iteration 131600, lr = 0.002
I0615 17:30:23.251989  5211 main54.cpp:499] Iteration 132000, Testing net (#0)
I0615 17:31:26.690646  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927422
I0615 17:31:26.690707  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.37616 (* 1 = 0.37616 loss)
I0615 17:31:28.615207  5211 main54.cpp:387] Iteration 132000, loss = 0.00687058
I0615 17:31:28.615247  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00686998 (* 1 = 0.00686998 loss)
I0615 17:31:28.615257  5211 sgd_solver.cpp:43] Iteration 132000, lr = 0.002
I0615 17:44:28.463644  5211 main54.cpp:499] Iteration 132400, Testing net (#0)
I0615 17:45:31.897462  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.925234
I0615 17:45:31.897511  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.39728 (* 1 = 0.39728 loss)
I0615 17:45:33.815487  5211 main54.cpp:387] Iteration 132400, loss = 0.00284424
I0615 17:45:33.815522  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00284366 (* 1 = 0.00284366 loss)
I0615 17:45:33.815528  5211 sgd_solver.cpp:43] Iteration 132400, lr = 0.002
I0615 17:58:36.521174  5211 main54.cpp:499] Iteration 132800, Testing net (#0)
I0615 17:59:39.861501  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927969
I0615 17:59:39.861546  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.375659 (* 1 = 0.375659 loss)
I0615 17:59:42.063175  5211 main54.cpp:387] Iteration 132800, loss = 0.00400846
I0615 17:59:42.063210  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00400788 (* 1 = 0.00400788 loss)
I0615 17:59:42.063217  5211 sgd_solver.cpp:43] Iteration 132800, lr = 0.002
I0615 18:12:45.385545  5211 main54.cpp:499] Iteration 133200, Testing net (#0)
I0615 18:13:48.810606  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926797
I0615 18:13:48.810653  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.394649 (* 1 = 0.394649 loss)
I0615 18:13:50.895373  5211 main54.cpp:387] Iteration 133200, loss = 0.00094169
I0615 18:13:50.895421  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000941116 (* 1 = 0.000941116 loss)
I0615 18:13:50.895429  5211 sgd_solver.cpp:43] Iteration 133200, lr = 0.002
I0615 18:26:53.998778  5211 main54.cpp:499] Iteration 133600, Testing net (#0)
I0615 18:27:57.367138  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926016
I0615 18:27:57.367178  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.395612 (* 1 = 0.395612 loss)
I0615 18:27:59.349555  5211 main54.cpp:387] Iteration 133600, loss = 0.00912134
I0615 18:27:59.349581  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00912078 (* 1 = 0.00912078 loss)
I0615 18:27:59.349588  5211 sgd_solver.cpp:43] Iteration 133600, lr = 0.002
I0615 18:40:56.064018  5211 main54.cpp:499] Iteration 134000, Testing net (#0)
I0615 18:41:59.490867  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927109
I0615 18:41:59.490911  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.372926 (* 1 = 0.372926 loss)
I0615 18:42:01.453021  5211 main54.cpp:387] Iteration 134000, loss = 0.00142523
I0615 18:42:01.453058  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00142466 (* 1 = 0.00142466 loss)
I0615 18:42:01.453063  5211 sgd_solver.cpp:43] Iteration 134000, lr = 0.002
I0615 18:55:06.969108  5211 main54.cpp:499] Iteration 134400, Testing net (#0)
I0615 18:56:10.395527  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929297
I0615 18:56:10.395570  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.375053 (* 1 = 0.375053 loss)
I0615 18:56:12.431046  5211 main54.cpp:387] Iteration 134400, loss = 0.00191207
I0615 18:56:12.431082  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00191152 (* 1 = 0.00191152 loss)
I0615 18:56:12.431090  5211 sgd_solver.cpp:43] Iteration 134400, lr = 0.002
I0615 19:09:14.874244  5211 main54.cpp:499] Iteration 134800, Testing net (#0)
I0615 19:10:18.186981  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926406
I0615 19:10:18.187026  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.373945 (* 1 = 0.373945 loss)
I0615 19:10:20.007697  5211 main54.cpp:387] Iteration 134800, loss = 0.0142292
I0615 19:10:20.007731  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0142287 (* 1 = 0.0142287 loss)
I0615 19:10:20.007740  5211 sgd_solver.cpp:43] Iteration 134800, lr = 0.002
I0615 19:23:21.716775  5211 main54.cpp:499] Iteration 135200, Testing net (#0)
I0615 19:24:25.025835  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928047
I0615 19:24:25.025877  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.386442 (* 1 = 0.386442 loss)
I0615 19:24:26.978999  5211 main54.cpp:387] Iteration 135200, loss = 0.00429732
I0615 19:24:26.979037  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00429674 (* 1 = 0.00429674 loss)
I0615 19:24:26.979043  5211 sgd_solver.cpp:43] Iteration 135200, lr = 0.002
I0615 19:37:31.641898  5211 main54.cpp:499] Iteration 135600, Testing net (#0)
I0615 19:38:35.076359  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927031
I0615 19:38:35.076400  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.377303 (* 1 = 0.377303 loss)
I0615 19:38:37.131461  5211 main54.cpp:387] Iteration 135600, loss = 0.00264087
I0615 19:38:37.131494  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00264028 (* 1 = 0.00264028 loss)
I0615 19:38:37.131500  5211 sgd_solver.cpp:43] Iteration 135600, lr = 0.002
I0615 19:51:41.773684  5211 main54.cpp:499] Iteration 136000, Testing net (#0)
I0615 19:52:45.136736  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.923594
I0615 19:52:45.136780  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.414056 (* 1 = 0.414056 loss)
I0615 19:52:47.295169  5211 main54.cpp:387] Iteration 136000, loss = 0.00543918
I0615 19:52:47.295204  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00543861 (* 1 = 0.00543861 loss)
I0615 19:52:47.295212  5211 sgd_solver.cpp:43] Iteration 136000, lr = 0.002
I0615 20:05:52.120959  5211 main54.cpp:499] Iteration 136400, Testing net (#0)
I0615 20:06:55.555153  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928047
I0615 20:06:55.555197  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.383084 (* 1 = 0.383084 loss)
I0615 20:06:57.469877  5211 main54.cpp:387] Iteration 136400, loss = 0.00323568
I0615 20:06:57.469915  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00323511 (* 1 = 0.00323511 loss)
I0615 20:06:57.469923  5211 sgd_solver.cpp:43] Iteration 136400, lr = 0.002
I0615 20:20:03.398915  5211 main54.cpp:499] Iteration 136800, Testing net (#0)
I0615 20:21:07.353329  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926953
I0615 20:21:07.353376  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.394478 (* 1 = 0.394478 loss)
I0615 20:21:09.142926  5211 main54.cpp:387] Iteration 136800, loss = 0.0369154
I0615 20:21:09.142971  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0369148 (* 1 = 0.0369148 loss)
I0615 20:21:09.142978  5211 sgd_solver.cpp:43] Iteration 136800, lr = 0.002
I0615 20:34:22.599436  5211 main54.cpp:499] Iteration 137200, Testing net (#0)
I0615 20:35:26.503820  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926172
I0615 20:35:26.503865  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.404162 (* 1 = 0.404162 loss)
I0615 20:35:28.472852  5211 main54.cpp:387] Iteration 137200, loss = 0.0117021
I0615 20:35:28.472890  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0117015 (* 1 = 0.0117015 loss)
I0615 20:35:28.472900  5211 sgd_solver.cpp:43] Iteration 137200, lr = 0.002
I0615 20:48:37.326637  5211 main54.cpp:499] Iteration 137600, Testing net (#0)
I0615 20:49:41.235282  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926562
I0615 20:49:41.235327  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.385839 (* 1 = 0.385839 loss)
I0615 20:49:43.278409  5211 main54.cpp:387] Iteration 137600, loss = 0.0183874
I0615 20:49:43.278447  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0183869 (* 1 = 0.0183869 loss)
I0615 20:49:43.278455  5211 sgd_solver.cpp:43] Iteration 137600, lr = 0.002
I0615 21:02:48.520375  5211 main54.cpp:499] Iteration 138000, Testing net (#0)
I0615 21:03:52.337761  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926719
I0615 21:03:52.337800  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.409249 (* 1 = 0.409249 loss)
I0615 21:03:54.355700  5211 main54.cpp:387] Iteration 138000, loss = 0.00119905
I0615 21:03:54.355732  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0011985 (* 1 = 0.0011985 loss)
I0615 21:03:54.355744  5211 sgd_solver.cpp:43] Iteration 138000, lr = 0.002
I0615 21:17:03.054306  5211 main54.cpp:499] Iteration 138400, Testing net (#0)
I0615 21:18:06.910783  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926484
I0615 21:18:06.910826  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.388689 (* 1 = 0.388689 loss)
I0615 21:18:08.946760  5211 main54.cpp:387] Iteration 138400, loss = 0.00640418
I0615 21:18:08.946822  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00640363 (* 1 = 0.00640363 loss)
I0615 21:18:08.946841  5211 sgd_solver.cpp:43] Iteration 138400, lr = 0.002
I0615 21:31:14.160197  5211 main54.cpp:499] Iteration 138800, Testing net (#0)
I0615 21:32:17.911689  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926406
I0615 21:32:17.911733  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.407685 (* 1 = 0.407685 loss)
I0615 21:32:19.775853  5211 main54.cpp:387] Iteration 138800, loss = 0.0125989
I0615 21:32:19.775879  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0125984 (* 1 = 0.0125984 loss)
I0615 21:32:19.775885  5211 sgd_solver.cpp:43] Iteration 138800, lr = 0.002
I0615 21:45:27.949195  5211 main54.cpp:499] Iteration 139200, Testing net (#0)
I0615 21:46:31.824383  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.925547
I0615 21:46:31.824435  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.396885 (* 1 = 0.396885 loss)
I0615 21:46:33.699929  5211 main54.cpp:387] Iteration 139200, loss = 0.0185493
I0615 21:46:33.699968  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0185488 (* 1 = 0.0185488 loss)
I0615 21:46:33.699975  5211 sgd_solver.cpp:43] Iteration 139200, lr = 0.002
I0615 21:59:45.203402  5211 main54.cpp:499] Iteration 139600, Testing net (#0)
I0615 22:00:49.021481  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.924453
I0615 22:00:49.021522  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.39344 (* 1 = 0.39344 loss)
I0615 22:00:50.959970  5211 main54.cpp:387] Iteration 139600, loss = 0.00344159
I0615 22:00:50.960001  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00344107 (* 1 = 0.00344107 loss)
I0615 22:00:50.960008  5211 sgd_solver.cpp:43] Iteration 139600, lr = 0.002
I0615 22:13:59.959713  5211 main54.cpp:499] Iteration 140000, Testing net (#0)
I0615 22:15:03.860241  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926484
I0615 22:15:03.860286  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.403006 (* 1 = 0.403006 loss)
I0615 22:15:05.584991  5211 main54.cpp:387] Iteration 140000, loss = 0.0638468
I0615 22:15:05.585024  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0638463 (* 1 = 0.0638463 loss)
I0615 22:15:05.585031  5211 sgd_solver.cpp:43] Iteration 140000, lr = 0.002
I0615 22:28:19.212889  5211 main54.cpp:499] Iteration 140400, Testing net (#0)
I0615 22:29:23.090788  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.923984
I0615 22:29:23.090839  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.399868 (* 1 = 0.399868 loss)
I0615 22:29:25.172524  5211 main54.cpp:387] Iteration 140400, loss = 0.00198813
I0615 22:29:25.172562  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00198761 (* 1 = 0.00198761 loss)
I0615 22:29:25.172571  5211 sgd_solver.cpp:43] Iteration 140400, lr = 0.002
I0615 22:42:29.944756  5211 main54.cpp:499] Iteration 140800, Testing net (#0)
I0615 22:43:33.830521  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928203
I0615 22:43:33.830565  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.394407 (* 1 = 0.394407 loss)
I0615 22:43:35.839001  5211 main54.cpp:387] Iteration 140800, loss = 0.0081069
I0615 22:43:35.839042  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00810636 (* 1 = 0.00810636 loss)
I0615 22:43:35.839051  5211 sgd_solver.cpp:43] Iteration 140800, lr = 0.002
I0615 22:56:44.998693  5211 main54.cpp:499] Iteration 141200, Testing net (#0)
I0615 22:57:48.922153  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927969
I0615 22:57:48.922209  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.384522 (* 1 = 0.384522 loss)
I0615 22:57:50.618664  5211 main54.cpp:387] Iteration 141200, loss = 0.0148666
I0615 22:57:50.618695  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.014866 (* 1 = 0.014866 loss)
I0615 22:57:50.618702  5211 sgd_solver.cpp:43] Iteration 141200, lr = 0.002
I0615 23:11:02.403386  5211 main54.cpp:499] Iteration 141600, Testing net (#0)
I0615 23:12:06.294288  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926406
I0615 23:12:06.294332  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.400607 (* 1 = 0.400607 loss)
I0615 23:12:07.999847  5211 main54.cpp:387] Iteration 141600, loss = 0.0358208
I0615 23:12:07.999882  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0358203 (* 1 = 0.0358203 loss)
I0615 23:12:07.999889  5211 sgd_solver.cpp:43] Iteration 141600, lr = 0.002
I0615 23:25:21.831377  5211 main54.cpp:499] Iteration 142000, Testing net (#0)
I0615 23:26:25.751875  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926406
I0615 23:26:25.751917  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.391128 (* 1 = 0.391128 loss)
I0615 23:26:27.693794  5211 main54.cpp:387] Iteration 142000, loss = 0.00121042
I0615 23:26:27.693824  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00120988 (* 1 = 0.00120988 loss)
I0615 23:26:27.693830  5211 sgd_solver.cpp:43] Iteration 142000, lr = 0.002
I0615 23:39:34.521633  5211 main54.cpp:499] Iteration 142400, Testing net (#0)
I0615 23:40:38.425812  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926094
I0615 23:40:38.425853  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.40023 (* 1 = 0.40023 loss)
I0615 23:40:40.156154  5211 main54.cpp:387] Iteration 142400, loss = 0.011959
I0615 23:40:40.156186  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0119585 (* 1 = 0.0119585 loss)
I0615 23:40:40.156193  5211 sgd_solver.cpp:43] Iteration 142400, lr = 0.002
I0615 23:53:51.691747  5211 main54.cpp:499] Iteration 142800, Testing net (#0)
I0615 23:54:55.672942  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929844
I0615 23:54:55.672981  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.368525 (* 1 = 0.368525 loss)
I0615 23:54:57.624825  5211 main54.cpp:387] Iteration 142800, loss = 0.00206601
I0615 23:54:57.624867  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00206551 (* 1 = 0.00206551 loss)
I0615 23:54:57.624873  5211 sgd_solver.cpp:43] Iteration 142800, lr = 0.002
I0616 00:08:07.051486  5211 main54.cpp:499] Iteration 143200, Testing net (#0)
I0616 00:09:10.406635  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.925859
I0616 00:09:10.406680  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.401121 (* 1 = 0.401121 loss)
I0616 00:09:12.247614  5211 main54.cpp:387] Iteration 143200, loss = 0.00243242
I0616 00:09:12.247653  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00243189 (* 1 = 0.00243189 loss)
I0616 00:09:12.247661  5211 sgd_solver.cpp:43] Iteration 143200, lr = 0.002
I0616 00:22:24.132021  5211 main54.cpp:499] Iteration 143600, Testing net (#0)
I0616 00:23:28.314244  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.925391
I0616 00:23:28.314292  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.404826 (* 1 = 0.404826 loss)
I0616 00:23:30.524104  5211 main54.cpp:387] Iteration 143600, loss = 0.00176358
I0616 00:23:30.524150  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00176305 (* 1 = 0.00176305 loss)
I0616 00:23:30.524159  5211 sgd_solver.cpp:43] Iteration 143600, lr = 0.002
I0616 00:36:46.092473  5211 main54.cpp:499] Iteration 144000, Testing net (#0)
I0616 00:37:50.732653  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.925703
I0616 00:37:50.732705  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.389061 (* 1 = 0.389061 loss)
I0616 00:37:52.608494  5211 main54.cpp:387] Iteration 144000, loss = 0.00620364
I0616 00:37:52.608531  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0062031 (* 1 = 0.0062031 loss)
I0616 00:37:52.608538  5211 sgd_solver.cpp:43] Iteration 144000, lr = 0.002
I0616 00:51:06.449093  5211 main54.cpp:499] Iteration 144400, Testing net (#0)
I0616 00:52:10.655196  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.92625
I0616 00:52:10.655241  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.403454 (* 1 = 0.403454 loss)
I0616 00:52:12.589313  5211 main54.cpp:387] Iteration 144400, loss = 0.00384533
I0616 00:52:12.589355  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00384478 (* 1 = 0.00384478 loss)
I0616 00:52:12.589364  5211 sgd_solver.cpp:43] Iteration 144400, lr = 0.002
I0616 01:05:23.545626  5211 main54.cpp:499] Iteration 144800, Testing net (#0)
I0616 01:06:27.856686  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927891
I0616 01:06:27.856732  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.382577 (* 1 = 0.382577 loss)
I0616 01:06:29.785368  5211 main54.cpp:387] Iteration 144800, loss = 0.000953579
I0616 01:06:29.785405  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000953045 (* 1 = 0.000953045 loss)
I0616 01:06:29.785416  5211 sgd_solver.cpp:43] Iteration 144800, lr = 0.002
I0616 01:19:39.109562  5211 main54.cpp:499] Iteration 145200, Testing net (#0)
I0616 01:20:43.598642  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928516
I0616 01:20:43.598692  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.402137 (* 1 = 0.402137 loss)
I0616 01:20:45.626183  5211 main54.cpp:387] Iteration 145200, loss = 0.000808863
I0616 01:20:45.626222  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000808314 (* 1 = 0.000808314 loss)
I0616 01:20:45.626230  5211 sgd_solver.cpp:43] Iteration 145200, lr = 0.002
I0616 01:33:58.995966  5211 main54.cpp:499] Iteration 145600, Testing net (#0)
I0616 01:35:03.267735  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.926719
I0616 01:35:03.267781  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.41367 (* 1 = 0.41367 loss)
I0616 01:35:05.162132  5211 main54.cpp:387] Iteration 145600, loss = 0.00796987
I0616 01:35:05.162168  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00796934 (* 1 = 0.00796934 loss)
I0616 01:35:05.162178  5211 sgd_solver.cpp:43] Iteration 145600, lr = 0.002
I0616 01:48:12.778623  5211 main54.cpp:499] Iteration 146000, Testing net (#0)
I0616 01:49:17.092895  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.924844
I0616 01:49:17.092952  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.4124 (* 1 = 0.4124 loss)
I0616 01:49:19.019285  5211 main54.cpp:387] Iteration 146000, loss = 0.00683283
I0616 01:49:19.019320  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00683235 (* 1 = 0.00683235 loss)
I0616 01:49:19.019326  5211 sgd_solver.cpp:43] Iteration 146000, lr = 0.002
I0616 02:02:26.700539  5211 main54.cpp:499] Iteration 146400, Testing net (#0)
I0616 02:03:31.103423  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927891
I0616 02:03:31.103478  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.393668 (* 1 = 0.393668 loss)
I0616 02:03:33.188282  5211 main54.cpp:387] Iteration 146400, loss = 0.000342219
I0616 02:03:33.188319  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000341733 (* 1 = 0.000341733 loss)
I0616 02:03:33.188326  5211 sgd_solver.cpp:43] Iteration 146400, lr = 0.002
I0616 02:16:44.999670  5211 main54.cpp:499] Iteration 146800, Testing net (#0)
I0616 02:17:48.974815  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928281
I0616 02:17:48.974861  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.385618 (* 1 = 0.385618 loss)
I0616 02:17:50.885890  5211 main54.cpp:387] Iteration 146800, loss = 0.0158262
I0616 02:17:50.885941  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0158257 (* 1 = 0.0158257 loss)
I0616 02:17:50.885948  5211 sgd_solver.cpp:43] Iteration 146800, lr = 0.002
I0616 02:30:57.353039  5211 main54.cpp:499] Iteration 147200, Testing net (#0)
I0616 02:32:01.291371  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928047
I0616 02:32:01.291414  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.405898 (* 1 = 0.405898 loss)
I0616 02:32:03.108132  5211 main54.cpp:387] Iteration 147200, loss = 0.0264803
I0616 02:32:03.108165  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0264797 (* 1 = 0.0264797 loss)
I0616 02:32:03.108176  5211 sgd_solver.cpp:43] Iteration 147200, lr = 0.002
I0616 02:45:10.927094  5211 main54.cpp:499] Iteration 147600, Testing net (#0)
I0616 02:46:15.005024  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928594
I0616 02:46:15.005069  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.38843 (* 1 = 0.38843 loss)
I0616 02:46:16.997882  5211 main54.cpp:387] Iteration 147600, loss = 0.0026597
I0616 02:46:16.997928  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00265919 (* 1 = 0.00265919 loss)
I0616 02:46:16.997937  5211 sgd_solver.cpp:43] Iteration 147600, lr = 0.002
I0616 02:59:25.683523  5211 main54.cpp:499] Iteration 148000, Testing net (#0)
I0616 03:00:29.412755  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928125
I0616 03:00:29.412796  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.391755 (* 1 = 0.391755 loss)
I0616 03:00:31.287988  5211 main54.cpp:387] Iteration 148000, loss = 0.00106577
I0616 03:00:31.288024  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00106527 (* 1 = 0.00106527 loss)
I0616 03:00:31.288031  5211 sgd_solver.cpp:43] Iteration 148000, lr = 0.002
I0616 03:13:33.639041  5211 main54.cpp:499] Iteration 148400, Testing net (#0)
I0616 03:14:37.270928  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930625
I0616 03:14:37.270968  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.389011 (* 1 = 0.389011 loss)
I0616 03:14:39.228561  5211 main54.cpp:387] Iteration 148400, loss = 0.0105246
I0616 03:14:39.228592  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0105241 (* 1 = 0.0105241 loss)
I0616 03:14:39.228600  5211 sgd_solver.cpp:43] Iteration 148400, lr = 0.002
I0616 03:27:46.188222  5211 main54.cpp:499] Iteration 148800, Testing net (#0)
I0616 03:28:49.965308  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928125
I0616 03:28:49.965360  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.403607 (* 1 = 0.403607 loss)
I0616 03:28:52.164531  5211 main54.cpp:387] Iteration 148800, loss = 0.00297465
I0616 03:28:52.164566  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00297418 (* 1 = 0.00297418 loss)
I0616 03:28:52.164582  5211 sgd_solver.cpp:43] Iteration 148800, lr = 0.002
I0616 03:41:56.092542  5211 main54.cpp:499] Iteration 149200, Testing net (#0)
I0616 03:42:59.667511  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.92625
I0616 03:42:59.667554  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.409886 (* 1 = 0.409886 loss)
I0616 03:43:01.580252  5211 main54.cpp:387] Iteration 149200, loss = 0.0121213
I0616 03:43:01.580282  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0121208 (* 1 = 0.0121208 loss)
I0616 03:43:01.580289  5211 sgd_solver.cpp:43] Iteration 149200, lr = 0.002
I0616 03:56:08.177247  5211 main54.cpp:499] Iteration 149600, Testing net (#0)
I0616 03:57:11.958608  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929297
I0616 03:57:11.958657  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.396985 (* 1 = 0.396985 loss)
I0616 03:57:13.865659  5211 main54.cpp:387] Iteration 149600, loss = 0.00109445
I0616 03:57:13.865696  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00109397 (* 1 = 0.00109397 loss)
I0616 03:57:13.865705  5211 sgd_solver.cpp:43] Iteration 149600, lr = 0.002
I0616 04:10:23.299238  5211 main54.cpp:499] Iteration 150000, Testing net (#0)
I0616 04:11:27.032313  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928672
I0616 04:11:27.032361  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.405504 (* 1 = 0.405504 loss)
I0616 04:11:28.750388  5211 main54.cpp:387] Iteration 150000, loss = 0.0249981
I0616 04:11:28.750411  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0249976 (* 1 = 0.0249976 loss)
I0616 04:11:28.750419  5211 sgd_solver.cpp:234] MultiStep Status: Iteration 150000, step = 2
I0616 04:11:28.750422  5211 sgd_solver.cpp:43] Iteration 150000, lr = 0.0002
I0616 04:24:36.456748  5211 main54.cpp:499] Iteration 150400, Testing net (#0)
I0616 04:25:40.079130  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928906
I0616 04:25:40.079176  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.389537 (* 1 = 0.389537 loss)
I0616 04:25:42.083372  5211 main54.cpp:387] Iteration 150400, loss = 0.00276296
I0616 04:25:42.083410  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00276249 (* 1 = 0.00276249 loss)
I0616 04:25:42.083420  5211 sgd_solver.cpp:43] Iteration 150400, lr = 0.0002
I0616 04:38:50.132251  5211 main54.cpp:499] Iteration 150800, Testing net (#0)
I0616 04:39:54.043498  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929375
I0616 04:39:54.043572  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.401164 (* 1 = 0.401164 loss)
I0616 04:39:56.003150  5211 main54.cpp:387] Iteration 150800, loss = 0.0149007
I0616 04:39:56.003190  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0149002 (* 1 = 0.0149002 loss)
I0616 04:39:56.003197  5211 sgd_solver.cpp:43] Iteration 150800, lr = 0.0002
I0616 04:53:01.684453  5211 main54.cpp:499] Iteration 151200, Testing net (#0)
I0616 04:54:05.804203  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929141
I0616 04:54:05.804246  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.401506 (* 1 = 0.401506 loss)
I0616 04:54:07.660763  5211 main54.cpp:387] Iteration 151200, loss = 0.0139721
I0616 04:54:07.660800  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0139716 (* 1 = 0.0139716 loss)
I0616 04:54:07.660809  5211 sgd_solver.cpp:43] Iteration 151200, lr = 0.0002
I0616 05:07:12.459652  5211 main54.cpp:499] Iteration 151600, Testing net (#0)
I0616 05:08:16.199900  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928047
I0616 05:08:16.199951  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.403922 (* 1 = 0.403922 loss)
I0616 05:08:18.170362  5211 main54.cpp:387] Iteration 151600, loss = 0.00112863
I0616 05:08:18.170395  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00112813 (* 1 = 0.00112813 loss)
I0616 05:08:18.170408  5211 sgd_solver.cpp:43] Iteration 151600, lr = 0.0002
I0616 05:21:24.636869  5211 main54.cpp:499] Iteration 152000, Testing net (#0)
I0616 05:22:28.259668  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930938
I0616 05:22:28.259706  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.391209 (* 1 = 0.391209 loss)
I0616 05:22:30.276682  5211 main54.cpp:387] Iteration 152000, loss = 0.00607411
I0616 05:22:30.276718  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0060736 (* 1 = 0.0060736 loss)
I0616 05:22:30.276726  5211 sgd_solver.cpp:43] Iteration 152000, lr = 0.0002
I0616 05:35:36.784914  5211 main54.cpp:499] Iteration 152400, Testing net (#0)
I0616 05:36:40.534142  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928281
I0616 05:36:40.534188  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.403464 (* 1 = 0.403464 loss)
I0616 05:36:42.424953  5211 main54.cpp:387] Iteration 152400, loss = 0.00403384
I0616 05:36:42.424993  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00403333 (* 1 = 0.00403333 loss)
I0616 05:36:42.425001  5211 sgd_solver.cpp:43] Iteration 152400, lr = 0.0002
I0616 05:49:51.301576  5211 main54.cpp:499] Iteration 152800, Testing net (#0)
I0616 05:50:55.400194  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930625
I0616 05:50:55.400249  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.377504 (* 1 = 0.377504 loss)
I0616 05:50:57.231851  5211 main54.cpp:387] Iteration 152800, loss = 0.0102648
I0616 05:50:57.231884  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0102643 (* 1 = 0.0102643 loss)
I0616 05:50:57.231895  5211 sgd_solver.cpp:43] Iteration 152800, lr = 0.0002
I0616 06:03:58.774493  5211 main54.cpp:499] Iteration 153200, Testing net (#0)
I0616 06:05:02.770159  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929844
I0616 06:05:02.770213  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.396388 (* 1 = 0.396388 loss)
I0616 06:05:04.768221  5211 main54.cpp:387] Iteration 153200, loss = 0.0114114
I0616 06:05:04.768255  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0114109 (* 1 = 0.0114109 loss)
I0616 06:05:04.768262  5211 sgd_solver.cpp:43] Iteration 153200, lr = 0.0002
I0616 06:18:12.417253  5211 main54.cpp:499] Iteration 153600, Testing net (#0)
I0616 06:19:16.064730  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929062
I0616 06:19:16.064771  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.390172 (* 1 = 0.390172 loss)
I0616 06:19:18.274878  5211 main54.cpp:387] Iteration 153600, loss = 0.000820468
I0616 06:19:18.274909  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000819988 (* 1 = 0.000819988 loss)
I0616 06:19:18.274916  5211 sgd_solver.cpp:43] Iteration 153600, lr = 0.0002
I0616 06:32:25.195590  5211 main54.cpp:499] Iteration 154000, Testing net (#0)
I0616 06:33:29.042500  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928672
I0616 06:33:29.042546  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.388865 (* 1 = 0.388865 loss)
I0616 06:33:31.095124  5211 main54.cpp:387] Iteration 154000, loss = 0.00670491
I0616 06:33:31.095165  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00670443 (* 1 = 0.00670443 loss)
I0616 06:33:31.095173  5211 sgd_solver.cpp:43] Iteration 154000, lr = 0.0002
I0616 06:46:41.344564  5211 main54.cpp:499] Iteration 154400, Testing net (#0)
I0616 06:47:45.492594  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929922
I0616 06:47:45.492650  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.38543 (* 1 = 0.38543 loss)
I0616 06:47:47.742679  5211 main54.cpp:387] Iteration 154400, loss = 0.000366997
I0616 06:47:47.742714  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000366529 (* 1 = 0.000366529 loss)
I0616 06:47:47.742722  5211 sgd_solver.cpp:43] Iteration 154400, lr = 0.0002
I0616 07:00:57.395541  5211 main54.cpp:499] Iteration 154800, Testing net (#0)
I0616 07:02:01.177140  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927188
I0616 07:02:01.177184  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.391993 (* 1 = 0.391993 loss)
I0616 07:02:02.990325  5211 main54.cpp:387] Iteration 154800, loss = 0.0161926
I0616 07:02:02.990358  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.016192 (* 1 = 0.016192 loss)
I0616 07:02:02.990366  5211 sgd_solver.cpp:43] Iteration 154800, lr = 0.0002
I0616 07:15:11.078773  5211 main54.cpp:499] Iteration 155200, Testing net (#0)
I0616 07:16:14.892679  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929219
I0616 07:16:14.892729  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.388164 (* 1 = 0.388164 loss)
I0616 07:16:16.613154  5211 main54.cpp:387] Iteration 155200, loss = 0.0943467
I0616 07:16:16.613203  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0943461 (* 1 = 0.0943461 loss)
I0616 07:16:16.613212  5211 sgd_solver.cpp:43] Iteration 155200, lr = 0.0002
I0616 07:29:24.879065  5211 main54.cpp:499] Iteration 155600, Testing net (#0)
I0616 07:30:28.726177  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.93125
I0616 07:30:28.726223  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.378749 (* 1 = 0.378749 loss)
I0616 07:30:30.641217  5211 main54.cpp:387] Iteration 155600, loss = 0.000903494
I0616 07:30:30.641250  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000902957 (* 1 = 0.000902957 loss)
I0616 07:30:30.641258  5211 sgd_solver.cpp:43] Iteration 155600, lr = 0.0002
I0616 07:43:38.868957  5211 main54.cpp:499] Iteration 156000, Testing net (#0)
I0616 07:44:42.680972  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928359
I0616 07:44:42.681011  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.392797 (* 1 = 0.392797 loss)
I0616 07:44:44.487396  5211 main54.cpp:387] Iteration 156000, loss = 0.0172636
I0616 07:44:44.487437  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0172631 (* 1 = 0.0172631 loss)
I0616 07:44:44.487444  5211 sgd_solver.cpp:43] Iteration 156000, lr = 0.0002
I0616 07:57:53.965667  5211 main54.cpp:499] Iteration 156400, Testing net (#0)
I0616 07:58:57.775802  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930156
I0616 07:58:57.775848  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.387752 (* 1 = 0.387752 loss)
I0616 07:58:59.790202  5211 main54.cpp:387] Iteration 156400, loss = 0.0128837
I0616 07:58:59.790241  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0128831 (* 1 = 0.0128831 loss)
I0616 07:58:59.790247  5211 sgd_solver.cpp:43] Iteration 156400, lr = 0.0002
I0616 08:12:10.078043  5211 main54.cpp:499] Iteration 156800, Testing net (#0)
I0616 08:13:14.229543  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927188
I0616 08:13:14.229593  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.391499 (* 1 = 0.391499 loss)
I0616 08:13:16.331560  5211 main54.cpp:387] Iteration 156800, loss = 0.00469463
I0616 08:13:16.331591  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0046941 (* 1 = 0.0046941 loss)
I0616 08:13:16.331598  5211 sgd_solver.cpp:43] Iteration 156800, lr = 0.0002
I0616 08:26:28.123615  5211 main54.cpp:499] Iteration 157200, Testing net (#0)
I0616 08:27:31.963037  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930391
I0616 08:27:31.963080  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.397961 (* 1 = 0.397961 loss)
I0616 08:27:33.912245  5211 main54.cpp:387] Iteration 157200, loss = 0.00352895
I0616 08:27:33.912281  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00352841 (* 1 = 0.00352841 loss)
I0616 08:27:33.912291  5211 sgd_solver.cpp:43] Iteration 157200, lr = 0.0002
I0616 08:40:43.299397  5211 main54.cpp:499] Iteration 157600, Testing net (#0)
I0616 08:41:47.628437  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928125
I0616 08:41:47.628492  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.387076 (* 1 = 0.387076 loss)
I0616 08:41:49.615417  5211 main54.cpp:387] Iteration 157600, loss = 0.00648873
I0616 08:41:49.615454  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00648821 (* 1 = 0.00648821 loss)
I0616 08:41:49.615463  5211 sgd_solver.cpp:43] Iteration 157600, lr = 0.0002
I0616 08:54:58.927338  5211 main54.cpp:499] Iteration 158000, Testing net (#0)
I0616 08:56:02.738100  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929609
I0616 08:56:02.738145  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.38695 (* 1 = 0.38695 loss)
I0616 08:56:04.484145  5211 main54.cpp:387] Iteration 158000, loss = 0.0355288
I0616 08:56:04.484186  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0355282 (* 1 = 0.0355282 loss)
I0616 08:56:04.484194  5211 sgd_solver.cpp:43] Iteration 158000, lr = 0.0002
I0616 09:09:13.915971  5211 main54.cpp:499] Iteration 158400, Testing net (#0)
I0616 09:10:18.050600  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930234
I0616 09:10:18.050647  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.386954 (* 1 = 0.386954 loss)
I0616 09:10:20.094755  5211 main54.cpp:387] Iteration 158400, loss = 0.00148246
I0616 09:10:20.094805  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00148193 (* 1 = 0.00148193 loss)
I0616 09:10:20.094812  5211 sgd_solver.cpp:43] Iteration 158400, lr = 0.0002
I0616 09:23:27.285537  5211 main54.cpp:499] Iteration 158800, Testing net (#0)
I0616 09:24:31.208235  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.92875
I0616 09:24:31.208276  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.390791 (* 1 = 0.390791 loss)
I0616 09:24:33.044715  5211 main54.cpp:387] Iteration 158800, loss = 0.0154986
I0616 09:24:33.044747  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0154981 (* 1 = 0.0154981 loss)
I0616 09:24:33.044754  5211 sgd_solver.cpp:43] Iteration 158800, lr = 0.0002
I0616 09:37:40.239465  5211 main54.cpp:499] Iteration 159200, Testing net (#0)
I0616 09:38:44.193734  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.9275
I0616 09:38:44.193776  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.40235 (* 1 = 0.40235 loss)
I0616 09:38:46.127151  5211 main54.cpp:387] Iteration 159200, loss = 0.00496459
I0616 09:38:46.127184  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00496406 (* 1 = 0.00496406 loss)
I0616 09:38:46.127193  5211 sgd_solver.cpp:43] Iteration 159200, lr = 0.0002
I0616 09:51:54.691138  5211 main54.cpp:499] Iteration 159600, Testing net (#0)
I0616 09:52:58.820408  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929922
I0616 09:52:58.820457  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.402238 (* 1 = 0.402238 loss)
I0616 09:53:00.731925  5211 main54.cpp:387] Iteration 159600, loss = 0.000565534
I0616 09:53:00.731962  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000564991 (* 1 = 0.000564991 loss)
I0616 09:53:00.731971  5211 sgd_solver.cpp:43] Iteration 159600, lr = 0.0002
I0616 10:06:09.201190  5211 main54.cpp:499] Iteration 160000, Testing net (#0)
I0616 10:07:13.255772  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929766
I0616 10:07:13.255820  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.390005 (* 1 = 0.390005 loss)
I0616 10:07:15.311261  5211 main54.cpp:387] Iteration 160000, loss = 0.00067958
I0616 10:07:15.311303  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00067902 (* 1 = 0.00067902 loss)
I0616 10:07:15.311311  5211 sgd_solver.cpp:43] Iteration 160000, lr = 0.0002
I0616 10:20:26.250453  5211 main54.cpp:499] Iteration 160400, Testing net (#0)
I0616 10:21:30.254829  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929297
I0616 10:21:30.254886  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.389096 (* 1 = 0.389096 loss)
I0616 10:21:31.980365  5211 main54.cpp:387] Iteration 160400, loss = 0.0107461
I0616 10:21:31.980401  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0107455 (* 1 = 0.0107455 loss)
I0616 10:21:31.980408  5211 sgd_solver.cpp:43] Iteration 160400, lr = 0.0002
I0616 10:34:39.438546  5211 main54.cpp:499] Iteration 160800, Testing net (#0)
I0616 10:35:43.232767  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930313
I0616 10:35:43.232815  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.390707 (* 1 = 0.390707 loss)
I0616 10:35:45.201478  5211 main54.cpp:387] Iteration 160800, loss = 0.00490561
I0616 10:35:45.201509  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00490501 (* 1 = 0.00490501 loss)
I0616 10:35:45.201515  5211 sgd_solver.cpp:43] Iteration 160800, lr = 0.0002
I0616 10:48:50.074614  5211 main54.cpp:499] Iteration 161200, Testing net (#0)
I0616 10:49:53.573146  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930781
I0616 10:49:53.573200  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.380768 (* 1 = 0.380768 loss)
I0616 10:49:55.433542  5211 main54.cpp:387] Iteration 161200, loss = 0.00916296
I0616 10:49:55.433569  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00916234 (* 1 = 0.00916234 loss)
I0616 10:49:55.433581  5211 sgd_solver.cpp:43] Iteration 161200, lr = 0.0002
I0616 11:02:58.616206  5211 main54.cpp:499] Iteration 161600, Testing net (#0)
I0616 11:04:02.218806  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930078
I0616 11:04:02.218850  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.394484 (* 1 = 0.394484 loss)
I0616 11:04:03.799963  5211 main54.cpp:387] Iteration 161600, loss = 0.0172305
I0616 11:04:03.799999  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0172299 (* 1 = 0.0172299 loss)
I0616 11:04:03.800006  5211 sgd_solver.cpp:43] Iteration 161600, lr = 0.0002
I0616 11:17:11.224864  5211 main54.cpp:499] Iteration 162000, Testing net (#0)
I0616 11:18:15.367730  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930156
I0616 11:18:15.367775  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.390276 (* 1 = 0.390276 loss)
I0616 11:18:16.947077  5211 main54.cpp:387] Iteration 162000, loss = 0.0210121
I0616 11:18:16.947123  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0210115 (* 1 = 0.0210115 loss)
I0616 11:18:16.947134  5211 sgd_solver.cpp:43] Iteration 162000, lr = 0.0002
I0616 11:31:25.109624  5211 main54.cpp:499] Iteration 162400, Testing net (#0)
I0616 11:32:29.292016  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927969
I0616 11:32:29.292059  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.399861 (* 1 = 0.399861 loss)
I0616 11:32:31.482272  5211 main54.cpp:387] Iteration 162400, loss = 0.000325077
I0616 11:32:31.482307  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000324451 (* 1 = 0.000324451 loss)
I0616 11:32:31.482316  5211 sgd_solver.cpp:43] Iteration 162400, lr = 0.0002
I0616 11:45:41.488831  5211 main54.cpp:499] Iteration 162800, Testing net (#0)
I0616 11:46:45.358295  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.931094
I0616 11:46:45.358342  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.384155 (* 1 = 0.384155 loss)
I0616 11:46:47.048246  5211 main54.cpp:387] Iteration 162800, loss = 0.0189608
I0616 11:46:47.048287  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0189602 (* 1 = 0.0189602 loss)
I0616 11:46:47.048296  5211 sgd_solver.cpp:43] Iteration 162800, lr = 0.0002
I0616 11:59:55.304232  5211 main54.cpp:499] Iteration 163200, Testing net (#0)
I0616 12:00:59.357377  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.931016
I0616 12:00:59.357419  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.388896 (* 1 = 0.388896 loss)
I0616 12:01:01.262655  5211 main54.cpp:387] Iteration 163200, loss = 0.019835
I0616 12:01:01.262683  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0198344 (* 1 = 0.0198344 loss)
I0616 12:01:01.262691  5211 sgd_solver.cpp:43] Iteration 163200, lr = 0.0002
I0616 12:14:12.794435  5211 main54.cpp:499] Iteration 163600, Testing net (#0)
I0616 12:15:16.413625  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929375
I0616 12:15:16.413668  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.388868 (* 1 = 0.388868 loss)
I0616 12:15:18.196198  5211 main54.cpp:387] Iteration 163600, loss = 0.0123452
I0616 12:15:18.196231  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0123447 (* 1 = 0.0123447 loss)
I0616 12:15:18.196239  5211 sgd_solver.cpp:43] Iteration 163600, lr = 0.0002
I0616 12:28:23.270097  5211 main54.cpp:499] Iteration 164000, Testing net (#0)
I0616 12:29:27.001000  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930859
I0616 12:29:27.001047  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.391279 (* 1 = 0.391279 loss)
I0616 12:29:29.149324  5211 main54.cpp:387] Iteration 164000, loss = 0.00763653
I0616 12:29:29.149363  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00763596 (* 1 = 0.00763596 loss)
I0616 12:29:29.149369  5211 sgd_solver.cpp:43] Iteration 164000, lr = 0.0002
I0616 12:42:35.979023  5211 main54.cpp:499] Iteration 164400, Testing net (#0)
I0616 12:43:39.673446  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929688
I0616 12:43:39.673501  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.397055 (* 1 = 0.397055 loss)
I0616 12:43:41.607555  5211 main54.cpp:387] Iteration 164400, loss = 0.00790851
I0616 12:43:41.607581  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00790794 (* 1 = 0.00790794 loss)
I0616 12:43:41.607589  5211 sgd_solver.cpp:43] Iteration 164400, lr = 0.0002
I0616 12:56:49.177564  5211 main54.cpp:499] Iteration 164800, Testing net (#0)
I0616 12:57:52.972630  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929219
I0616 12:57:52.972678  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.387171 (* 1 = 0.387171 loss)
I0616 12:57:54.695869  5211 main54.cpp:387] Iteration 164800, loss = 0.00399686
I0616 12:57:54.695907  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00399629 (* 1 = 0.00399629 loss)
I0616 12:57:54.695914  5211 sgd_solver.cpp:43] Iteration 164800, lr = 0.0002
I0616 13:11:01.331497  5211 main54.cpp:499] Iteration 165200, Testing net (#0)
I0616 13:12:05.195943  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930703
I0616 13:12:05.195986  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.396055 (* 1 = 0.396055 loss)
I0616 13:12:07.019929  5211 main54.cpp:387] Iteration 165200, loss = 0.0108137
I0616 13:12:07.019961  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0108132 (* 1 = 0.0108132 loss)
I0616 13:12:07.019969  5211 sgd_solver.cpp:43] Iteration 165200, lr = 0.0002
I0616 13:25:18.431641  5211 main54.cpp:499] Iteration 165600, Testing net (#0)
I0616 13:26:22.109729  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.931172
I0616 13:26:22.109772  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.385925 (* 1 = 0.385925 loss)
I0616 13:26:23.856133  5211 main54.cpp:387] Iteration 165600, loss = 0.0259764
I0616 13:26:23.856164  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0259758 (* 1 = 0.0259758 loss)
I0616 13:26:23.856173  5211 sgd_solver.cpp:43] Iteration 165600, lr = 0.0002
I0616 13:39:31.729400  5211 main54.cpp:499] Iteration 166000, Testing net (#0)
I0616 13:40:35.706295  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929062
I0616 13:40:35.706338  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.395863 (* 1 = 0.395863 loss)
I0616 13:40:37.705672  5211 main54.cpp:387] Iteration 166000, loss = 0.00130884
I0616 13:40:37.705709  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00130825 (* 1 = 0.00130825 loss)
I0616 13:40:37.705719  5211 sgd_solver.cpp:43] Iteration 166000, lr = 0.0002
I0616 13:53:41.912487  5211 main54.cpp:499] Iteration 166400, Testing net (#0)
I0616 13:54:45.958809  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930859
I0616 13:54:45.958854  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.388834 (* 1 = 0.388834 loss)
I0616 13:54:48.155182  5211 main54.cpp:387] Iteration 166400, loss = 0.00223426
I0616 13:54:48.155232  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00223363 (* 1 = 0.00223363 loss)
I0616 13:54:48.155243  5211 sgd_solver.cpp:43] Iteration 166400, lr = 0.0002
I0616 14:08:00.716864  5211 main54.cpp:499] Iteration 166800, Testing net (#0)
I0616 14:09:04.422241  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929844
I0616 14:09:04.422283  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.403082 (* 1 = 0.403082 loss)
I0616 14:09:06.416836  5211 main54.cpp:387] Iteration 166800, loss = 0.00185515
I0616 14:09:06.416872  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00185453 (* 1 = 0.00185453 loss)
I0616 14:09:06.416879  5211 sgd_solver.cpp:43] Iteration 166800, lr = 0.0002
I0616 14:22:13.978260  5211 main54.cpp:499] Iteration 167200, Testing net (#0)
I0616 14:23:17.765945  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928984
I0616 14:23:17.765993  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.396784 (* 1 = 0.396784 loss)
I0616 14:23:19.830394  5211 main54.cpp:387] Iteration 167200, loss = 0.0128922
I0616 14:23:19.830425  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0128916 (* 1 = 0.0128916 loss)
I0616 14:23:19.830432  5211 sgd_solver.cpp:43] Iteration 167200, lr = 0.0002
I0616 14:36:28.838430  5211 main54.cpp:499] Iteration 167600, Testing net (#0)
I0616 14:37:32.605164  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929688
I0616 14:37:32.605201  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.38553 (* 1 = 0.38553 loss)
I0616 14:37:34.629329  5211 main54.cpp:387] Iteration 167600, loss = 0.000609653
I0616 14:37:34.629364  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000609033 (* 1 = 0.000609033 loss)
I0616 14:37:34.629372  5211 sgd_solver.cpp:43] Iteration 167600, lr = 0.0002
I0616 14:50:43.459508  5211 main54.cpp:499] Iteration 168000, Testing net (#0)
I0616 14:51:47.699152  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929531
I0616 14:51:47.699205  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.396181 (* 1 = 0.396181 loss)
I0616 14:51:49.705929  5211 main54.cpp:387] Iteration 168000, loss = 0.000431992
I0616 14:51:49.705978  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000431374 (* 1 = 0.000431374 loss)
I0616 14:51:49.705996  5211 sgd_solver.cpp:43] Iteration 168000, lr = 0.0002
I0616 15:04:57.555388  5211 main54.cpp:499] Iteration 168400, Testing net (#0)
I0616 15:06:01.443895  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930703
I0616 15:06:01.443938  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.383277 (* 1 = 0.383277 loss)
I0616 15:06:03.561136  5211 main54.cpp:387] Iteration 168400, loss = 0.00016806
I0616 15:06:03.561183  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000167456 (* 1 = 0.000167456 loss)
I0616 15:06:03.561195  5211 sgd_solver.cpp:43] Iteration 168400, lr = 0.0002
I0616 15:19:09.689193  5211 main54.cpp:499] Iteration 168800, Testing net (#0)
I0616 15:20:13.585302  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929531
I0616 15:20:13.585361  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.397521 (* 1 = 0.397521 loss)
I0616 15:20:15.620077  5211 main54.cpp:387] Iteration 168800, loss = 0.00151788
I0616 15:20:15.620118  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00151727 (* 1 = 0.00151727 loss)
I0616 15:20:15.620126  5211 sgd_solver.cpp:43] Iteration 168800, lr = 0.0002
I0616 15:33:26.658711  5211 main54.cpp:499] Iteration 169200, Testing net (#0)
I0616 15:34:30.547430  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929297
I0616 15:34:30.547468  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.399157 (* 1 = 0.399157 loss)
I0616 15:34:32.379241  5211 main54.cpp:387] Iteration 169200, loss = 0.000898017
I0616 15:34:32.379281  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000897478 (* 1 = 0.000897478 loss)
I0616 15:34:32.379287  5211 sgd_solver.cpp:43] Iteration 169200, lr = 0.0002
I0616 15:47:38.483536  5211 main54.cpp:499] Iteration 169600, Testing net (#0)
I0616 15:48:42.752791  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930313
I0616 15:48:42.752847  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.394589 (* 1 = 0.394589 loss)
I0616 15:48:44.878221  5211 main54.cpp:387] Iteration 169600, loss = 0.00380527
I0616 15:48:44.878255  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00380474 (* 1 = 0.00380474 loss)
I0616 15:48:44.878263  5211 sgd_solver.cpp:43] Iteration 169600, lr = 0.0002
I0616 16:01:48.963093  5211 main54.cpp:499] Iteration 170000, Testing net (#0)
I0616 16:02:52.754523  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.93
I0616 16:02:52.754570  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.388762 (* 1 = 0.388762 loss)
I0616 16:02:54.778223  5211 main54.cpp:387] Iteration 170000, loss = 0.00206744
I0616 16:02:54.778270  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0020669 (* 1 = 0.0020669 loss)
I0616 16:02:54.778277  5211 sgd_solver.cpp:43] Iteration 170000, lr = 0.0002
I0616 16:16:01.693194  5211 main54.cpp:499] Iteration 170400, Testing net (#0)
I0616 16:17:05.828662  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.931406
I0616 16:17:05.828711  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.384033 (* 1 = 0.384033 loss)
I0616 16:17:07.727799  5211 main54.cpp:387] Iteration 170400, loss = 0.00425257
I0616 16:17:07.727836  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00425202 (* 1 = 0.00425202 loss)
I0616 16:17:07.727844  5211 sgd_solver.cpp:43] Iteration 170400, lr = 0.0002
I0616 16:30:12.261953  5211 main54.cpp:499] Iteration 170800, Testing net (#0)
I0616 16:31:16.397017  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.931953
I0616 16:31:16.397060  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.395082 (* 1 = 0.395082 loss)
I0616 16:31:18.204558  5211 main54.cpp:387] Iteration 170800, loss = 0.00971225
I0616 16:31:18.204597  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00971171 (* 1 = 0.00971171 loss)
I0616 16:31:18.204612  5211 sgd_solver.cpp:43] Iteration 170800, lr = 0.0002
I0616 16:44:25.314645  5211 main54.cpp:499] Iteration 171200, Testing net (#0)
I0616 16:45:29.277197  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929453
I0616 16:45:29.277243  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.395903 (* 1 = 0.395903 loss)
I0616 16:45:31.069164  5211 main54.cpp:387] Iteration 171200, loss = 0.0518551
I0616 16:45:31.069206  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0518546 (* 1 = 0.0518546 loss)
I0616 16:45:31.069216  5211 sgd_solver.cpp:43] Iteration 171200, lr = 0.0002
I0616 16:58:41.115068  5211 main54.cpp:499] Iteration 171600, Testing net (#0)
I0616 16:59:45.255076  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.932031
I0616 16:59:45.255125  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.392746 (* 1 = 0.392746 loss)
I0616 16:59:47.246749  5211 main54.cpp:387] Iteration 171600, loss = 0.00134433
I0616 16:59:47.246786  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0013438 (* 1 = 0.0013438 loss)
I0616 16:59:47.246794  5211 sgd_solver.cpp:43] Iteration 171600, lr = 0.0002
I0616 17:12:56.151444  5211 main54.cpp:499] Iteration 172000, Testing net (#0)
I0616 17:13:59.978910  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930781
I0616 17:13:59.978961  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.393863 (* 1 = 0.393863 loss)
I0616 17:14:01.844153  5211 main54.cpp:387] Iteration 172000, loss = 0.0151664
I0616 17:14:01.844213  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0151659 (* 1 = 0.0151659 loss)
I0616 17:14:01.844224  5211 sgd_solver.cpp:43] Iteration 172000, lr = 0.0002
I0616 17:27:08.461711  5211 main54.cpp:499] Iteration 172400, Testing net (#0)
I0616 17:28:12.163503  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.93125
I0616 17:28:12.163547  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.385953 (* 1 = 0.385953 loss)
I0616 17:28:13.992164  5211 main54.cpp:387] Iteration 172400, loss = 0.00963474
I0616 17:28:13.992197  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0096342 (* 1 = 0.0096342 loss)
I0616 17:28:13.992203  5211 sgd_solver.cpp:43] Iteration 172400, lr = 0.0002
I0616 17:41:22.187314  5211 main54.cpp:499] Iteration 172800, Testing net (#0)
I0616 17:42:26.019256  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930781
I0616 17:42:26.019299  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.395625 (* 1 = 0.395625 loss)
I0616 17:42:28.019321  5211 main54.cpp:387] Iteration 172800, loss = 0.000216095
I0616 17:42:28.019358  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000215559 (* 1 = 0.000215559 loss)
I0616 17:42:28.019378  5211 sgd_solver.cpp:43] Iteration 172800, lr = 0.0002
I0616 17:55:34.291427  5211 main54.cpp:499] Iteration 173200, Testing net (#0)
I0616 17:56:38.014933  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.93125
I0616 17:56:38.014979  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.394018 (* 1 = 0.394018 loss)
I0616 17:56:39.878104  5211 main54.cpp:387] Iteration 173200, loss = 0.00901939
I0616 17:56:39.878141  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00901887 (* 1 = 0.00901887 loss)
I0616 17:56:39.878149  5211 sgd_solver.cpp:43] Iteration 173200, lr = 0.0002
I0616 18:09:48.506342  5211 main54.cpp:499] Iteration 173600, Testing net (#0)
I0616 18:10:52.115350  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930469
I0616 18:10:52.115396  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.404567 (* 1 = 0.404567 loss)
I0616 18:10:54.092968  5211 main54.cpp:387] Iteration 173600, loss = 0.0157175
I0616 18:10:54.093014  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.015717 (* 1 = 0.015717 loss)
I0616 18:10:54.093024  5211 sgd_solver.cpp:43] Iteration 173600, lr = 0.0002
I0616 18:23:58.669564  5211 main54.cpp:499] Iteration 174000, Testing net (#0)
I0616 18:25:02.393941  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.932344
I0616 18:25:02.393981  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.382742 (* 1 = 0.382742 loss)
I0616 18:25:04.449663  5211 main54.cpp:387] Iteration 174000, loss = 0.00100022
I0616 18:25:04.449688  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000999721 (* 1 = 0.000999721 loss)
I0616 18:25:04.449697  5211 sgd_solver.cpp:43] Iteration 174000, lr = 0.0002
I0616 18:38:16.558270  5211 main54.cpp:499] Iteration 174400, Testing net (#0)
I0616 18:39:20.682551  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929531
I0616 18:39:20.682600  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.394553 (* 1 = 0.394553 loss)
I0616 18:39:22.566519  5211 main54.cpp:387] Iteration 174400, loss = 0.00472541
I0616 18:39:22.566556  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00472488 (* 1 = 0.00472488 loss)
I0616 18:39:22.566565  5211 sgd_solver.cpp:43] Iteration 174400, lr = 0.0002
I0616 18:52:34.875699  5211 main54.cpp:499] Iteration 174800, Testing net (#0)
I0616 18:53:38.641381  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.93125
I0616 18:53:38.641423  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.378782 (* 1 = 0.378782 loss)
I0616 18:53:40.740509  5211 main54.cpp:387] Iteration 174800, loss = 0.0181032
I0616 18:53:40.740542  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0181026 (* 1 = 0.0181026 loss)
I0616 18:53:40.740550  5211 sgd_solver.cpp:43] Iteration 174800, lr = 0.0002
I0616 19:06:49.721498  5211 main54.cpp:499] Iteration 175200, Testing net (#0)
I0616 19:07:53.843915  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930625
I0616 19:07:53.843963  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.391529 (* 1 = 0.391529 loss)
I0616 19:07:56.045720  5211 main54.cpp:387] Iteration 175200, loss = 0.00291192
I0616 19:07:56.045758  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00291138 (* 1 = 0.00291138 loss)
I0616 19:07:56.045768  5211 sgd_solver.cpp:43] Iteration 175200, lr = 0.0002
I0616 19:21:06.014417  5211 main54.cpp:499] Iteration 175600, Testing net (#0)
I0616 19:22:10.125917  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.931797
I0616 19:22:10.125958  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.377892 (* 1 = 0.377892 loss)
I0616 19:22:12.117475  5211 main54.cpp:387] Iteration 175600, loss = 0.0149471
I0616 19:22:12.117517  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0149466 (* 1 = 0.0149466 loss)
I0616 19:22:12.117527  5211 sgd_solver.cpp:43] Iteration 175600, lr = 0.0002
I0616 19:35:19.413219  5211 main54.cpp:499] Iteration 176000, Testing net (#0)
I0616 19:36:23.125290  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927266
I0616 19:36:23.125344  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.402705 (* 1 = 0.402705 loss)
I0616 19:36:25.094558  5211 main54.cpp:387] Iteration 176000, loss = 0.0244956
I0616 19:36:25.094616  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0244951 (* 1 = 0.0244951 loss)
I0616 19:36:25.094624  5211 sgd_solver.cpp:43] Iteration 176000, lr = 0.0002
I0616 19:49:33.941798  5211 main54.cpp:499] Iteration 176400, Testing net (#0)
I0616 19:50:37.715526  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.932734
I0616 19:50:37.715569  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.399923 (* 1 = 0.399923 loss)
I0616 19:50:39.523237  5211 main54.cpp:387] Iteration 176400, loss = 0.0188811
I0616 19:50:39.523274  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0188806 (* 1 = 0.0188806 loss)
I0616 19:50:39.523284  5211 sgd_solver.cpp:43] Iteration 176400, lr = 0.0002
I0616 20:03:46.474812  5211 main54.cpp:499] Iteration 176800, Testing net (#0)
I0616 20:04:50.570541  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.931016
I0616 20:04:50.570586  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.383965 (* 1 = 0.383965 loss)
I0616 20:04:52.483042  5211 main54.cpp:387] Iteration 176800, loss = 0.0136569
I0616 20:04:52.483068  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0136564 (* 1 = 0.0136564 loss)
I0616 20:04:52.483080  5211 sgd_solver.cpp:43] Iteration 176800, lr = 0.0002
I0616 20:17:56.824419  5211 main54.cpp:499] Iteration 177200, Testing net (#0)
I0616 20:19:00.526608  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930547
I0616 20:19:00.526655  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.395453 (* 1 = 0.395453 loss)
I0616 20:19:02.365051  5211 main54.cpp:387] Iteration 177200, loss = 0.00110056
I0616 20:19:02.365092  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00110001 (* 1 = 0.00110001 loss)
I0616 20:19:02.365098  5211 sgd_solver.cpp:43] Iteration 177200, lr = 0.0002
I0616 20:32:09.949023  5211 main54.cpp:499] Iteration 177600, Testing net (#0)
I0616 20:33:13.693547  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927734
I0616 20:33:13.693589  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.394156 (* 1 = 0.394156 loss)
I0616 20:33:15.556943  5211 main54.cpp:387] Iteration 177600, loss = 0.00414537
I0616 20:33:15.556990  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00414482 (* 1 = 0.00414482 loss)
I0616 20:33:15.557000  5211 sgd_solver.cpp:43] Iteration 177600, lr = 0.0002
I0616 20:46:21.972893  5211 main54.cpp:499] Iteration 178000, Testing net (#0)
I0616 20:47:25.769245  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.932266
I0616 20:47:25.769289  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.388473 (* 1 = 0.388473 loss)
I0616 20:47:27.446074  5211 main54.cpp:387] Iteration 178000, loss = 0.0101449
I0616 20:47:27.446130  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0101443 (* 1 = 0.0101443 loss)
I0616 20:47:27.446141  5211 sgd_solver.cpp:43] Iteration 178000, lr = 0.0002
I0616 21:00:38.043884  5211 main54.cpp:499] Iteration 178400, Testing net (#0)
I0616 21:01:41.799149  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.931094
I0616 21:01:41.799191  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.381482 (* 1 = 0.381482 loss)
I0616 21:01:43.757330  5211 main54.cpp:387] Iteration 178400, loss = 0.00874386
I0616 21:01:43.757369  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00874333 (* 1 = 0.00874333 loss)
I0616 21:01:43.757377  5211 sgd_solver.cpp:43] Iteration 178400, lr = 0.0002
I0616 21:14:55.753311  5211 main54.cpp:499] Iteration 178800, Testing net (#0)
I0616 21:15:59.724504  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.931094
I0616 21:15:59.724548  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.399569 (* 1 = 0.399569 loss)
I0616 21:16:01.546814  5211 main54.cpp:387] Iteration 178800, loss = 0.00681023
I0616 21:16:01.546857  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00680971 (* 1 = 0.00680971 loss)
I0616 21:16:01.546867  5211 sgd_solver.cpp:43] Iteration 178800, lr = 0.0002
I0616 21:29:13.670591  5211 main54.cpp:499] Iteration 179200, Testing net (#0)
I0616 21:30:17.453212  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928906
I0616 21:30:17.453260  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.39041 (* 1 = 0.39041 loss)
I0616 21:30:19.200984  5211 main54.cpp:387] Iteration 179200, loss = 0.013189
I0616 21:30:19.201035  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0131885 (* 1 = 0.0131885 loss)
I0616 21:30:19.201052  5211 sgd_solver.cpp:43] Iteration 179200, lr = 0.0002
I0616 21:43:29.775760  5211 main54.cpp:499] Iteration 179600, Testing net (#0)
I0616 21:44:33.982555  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930781
I0616 21:44:33.982604  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.395342 (* 1 = 0.395342 loss)
I0616 21:44:36.011646  5211 main54.cpp:387] Iteration 179600, loss = 0.00151459
I0616 21:44:36.011688  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00151407 (* 1 = 0.00151407 loss)
I0616 21:44:36.011698  5211 sgd_solver.cpp:43] Iteration 179600, lr = 0.0002
I0616 21:57:44.698802  5211 main54.cpp:499] Iteration 180000, Testing net (#0)
I0616 21:58:49.014348  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930703
I0616 21:58:49.014400  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.38984 (* 1 = 0.38984 loss)
I0616 21:58:50.721985  5211 main54.cpp:387] Iteration 180000, loss = 0.0222056
I0616 21:58:50.722019  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0222051 (* 1 = 0.0222051 loss)
I0616 21:58:50.722026  5211 sgd_solver.cpp:43] Iteration 180000, lr = 0.0002
I0616 22:11:56.792671  5211 main54.cpp:499] Iteration 180400, Testing net (#0)
I0616 22:13:00.783938  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.93
I0616 22:13:00.783984  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.387183 (* 1 = 0.387183 loss)
I0616 22:13:02.733539  5211 main54.cpp:387] Iteration 180400, loss = 0.00707533
I0616 22:13:02.733579  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00707485 (* 1 = 0.00707485 loss)
I0616 22:13:02.733587  5211 sgd_solver.cpp:43] Iteration 180400, lr = 0.0002
I0616 22:26:11.457425  5211 main54.cpp:499] Iteration 180800, Testing net (#0)
I0616 22:27:15.613101  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930313
I0616 22:27:15.613147  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.387253 (* 1 = 0.387253 loss)
I0616 22:27:17.672937  5211 main54.cpp:387] Iteration 180800, loss = 0.00347089
I0616 22:27:17.672971  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0034704 (* 1 = 0.0034704 loss)
I0616 22:27:17.672979  5211 sgd_solver.cpp:43] Iteration 180800, lr = 0.0002
I0616 22:40:24.903426  5211 main54.cpp:499] Iteration 181200, Testing net (#0)
I0616 22:41:28.911298  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.931562
I0616 22:41:28.911345  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.376972 (* 1 = 0.376972 loss)
I0616 22:41:30.660812  5211 main54.cpp:387] Iteration 181200, loss = 0.0258971
I0616 22:41:30.660861  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0258966 (* 1 = 0.0258966 loss)
I0616 22:41:30.660872  5211 sgd_solver.cpp:43] Iteration 181200, lr = 0.0002
I0616 22:54:40.894851  5211 main54.cpp:499] Iteration 181600, Testing net (#0)
I0616 22:55:44.997143  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930781
I0616 22:55:44.997189  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.396722 (* 1 = 0.396722 loss)
I0616 22:55:46.959198  5211 main54.cpp:387] Iteration 181600, loss = 0.012468
I0616 22:55:46.959230  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0124675 (* 1 = 0.0124675 loss)
I0616 22:55:46.959242  5211 sgd_solver.cpp:43] Iteration 181600, lr = 0.0002
I0616 23:08:54.556596  5211 main54.cpp:499] Iteration 182000, Testing net (#0)
I0616 23:09:58.137796  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930703
I0616 23:09:58.137853  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.383677 (* 1 = 0.383677 loss)
I0616 23:10:00.159950  5211 main54.cpp:387] Iteration 182000, loss = 0.00175867
I0616 23:10:00.159986  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00175819 (* 1 = 0.00175819 loss)
I0616 23:10:00.159993  5211 sgd_solver.cpp:43] Iteration 182000, lr = 0.0002
I0616 23:23:09.177088  5211 main54.cpp:499] Iteration 182400, Testing net (#0)
I0616 23:24:13.206195  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.931172
I0616 23:24:13.206234  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.390915 (* 1 = 0.390915 loss)
I0616 23:24:14.997985  5211 main54.cpp:387] Iteration 182400, loss = 0.00194803
I0616 23:24:14.998014  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00194756 (* 1 = 0.00194756 loss)
I0616 23:24:14.998020  5211 sgd_solver.cpp:43] Iteration 182400, lr = 0.0002
I0616 23:37:23.015616  5211 main54.cpp:499] Iteration 182800, Testing net (#0)
I0616 23:38:27.153604  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930391
I0616 23:38:27.153659  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.390028 (* 1 = 0.390028 loss)
I0616 23:38:29.177738  5211 main54.cpp:387] Iteration 182800, loss = 0.000349729
I0616 23:38:29.177780  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000349252 (* 1 = 0.000349252 loss)
I0616 23:38:29.177789  5211 sgd_solver.cpp:43] Iteration 182800, lr = 0.0002
I0616 23:51:36.006434  5211 main54.cpp:499] Iteration 183200, Testing net (#0)
I0616 23:52:40.201220  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.933672
I0616 23:52:40.201273  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.383017 (* 1 = 0.383017 loss)
I0616 23:52:42.213281  5211 main54.cpp:387] Iteration 183200, loss = 0.00736149
I0616 23:52:42.213326  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00736102 (* 1 = 0.00736102 loss)
I0616 23:52:42.213333  5211 sgd_solver.cpp:43] Iteration 183200, lr = 0.0002
I0617 00:05:48.650094  5211 main54.cpp:499] Iteration 183600, Testing net (#0)
I0617 00:06:52.958267  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929609
I0617 00:06:52.958317  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.389574 (* 1 = 0.389574 loss)
I0617 00:06:54.883157  5211 main54.cpp:387] Iteration 183600, loss = 0.00284362
I0617 00:06:54.883188  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00284315 (* 1 = 0.00284315 loss)
I0617 00:06:54.883194  5211 sgd_solver.cpp:43] Iteration 183600, lr = 0.0002
I0617 00:20:01.424074  5211 main54.cpp:499] Iteration 184000, Testing net (#0)
I0617 00:21:05.719676  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930703
I0617 00:21:05.719723  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.393168 (* 1 = 0.393168 loss)
I0617 00:21:07.809602  5211 main54.cpp:387] Iteration 184000, loss = 0.000811532
I0617 00:21:07.809641  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000811081 (* 1 = 0.000811081 loss)
I0617 00:21:07.809649  5211 sgd_solver.cpp:43] Iteration 184000, lr = 0.0002
I0617 00:34:16.673549  5211 main54.cpp:499] Iteration 184400, Testing net (#0)
I0617 00:35:20.425428  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929844
I0617 00:35:20.425485  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.39321 (* 1 = 0.39321 loss)
I0617 00:35:22.556635  5211 main54.cpp:387] Iteration 184400, loss = 0.000209294
I0617 00:35:22.556669  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000208837 (* 1 = 0.000208837 loss)
I0617 00:35:22.556676  5211 sgd_solver.cpp:43] Iteration 184400, lr = 0.0002
I0617 00:48:30.515938  5211 main54.cpp:499] Iteration 184800, Testing net (#0)
I0617 00:49:34.661111  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929141
I0617 00:49:34.661155  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.387221 (* 1 = 0.387221 loss)
I0617 00:49:36.504678  5211 main54.cpp:387] Iteration 184800, loss = 0.00717672
I0617 00:49:36.504716  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00717628 (* 1 = 0.00717628 loss)
I0617 00:49:36.504724  5211 sgd_solver.cpp:43] Iteration 184800, lr = 0.0002
I0617 01:02:49.486481  5211 main54.cpp:499] Iteration 185200, Testing net (#0)
I0617 01:03:53.264554  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929297
I0617 01:03:53.264597  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.40212 (* 1 = 0.40212 loss)
I0617 01:03:55.232645  5211 main54.cpp:387] Iteration 185200, loss = 0.000579135
I0617 01:03:55.232679  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000578691 (* 1 = 0.000578691 loss)
I0617 01:03:55.232686  5211 sgd_solver.cpp:43] Iteration 185200, lr = 0.0002
I0617 01:17:02.846740  5211 main54.cpp:499] Iteration 185600, Testing net (#0)
I0617 01:18:06.894011  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.932031
I0617 01:18:06.894069  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.38384 (* 1 = 0.38384 loss)
I0617 01:18:08.799170  5211 main54.cpp:387] Iteration 185600, loss = 0.00187485
I0617 01:18:08.799216  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00187441 (* 1 = 0.00187441 loss)
I0617 01:18:08.799226  5211 sgd_solver.cpp:43] Iteration 185600, lr = 0.0002
I0617 01:31:16.598477  5211 main54.cpp:499] Iteration 186000, Testing net (#0)
I0617 01:32:20.243549  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928594
I0617 01:32:20.243598  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.401656 (* 1 = 0.401656 loss)
I0617 01:32:22.235911  5211 main54.cpp:387] Iteration 186000, loss = 0.00629978
I0617 01:32:22.235942  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00629934 (* 1 = 0.00629934 loss)
I0617 01:32:22.235950  5211 sgd_solver.cpp:43] Iteration 186000, lr = 0.0002
I0617 01:45:28.751711  5211 main54.cpp:499] Iteration 186400, Testing net (#0)
I0617 01:46:32.523607  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929688
I0617 01:46:32.523653  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.394985 (* 1 = 0.394985 loss)
I0617 01:46:34.246704  5211 main54.cpp:387] Iteration 186400, loss = 0.0174695
I0617 01:46:34.246760  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0174691 (* 1 = 0.0174691 loss)
I0617 01:46:34.246776  5211 sgd_solver.cpp:43] Iteration 186400, lr = 0.0002
I0617 01:59:44.445420  5211 main54.cpp:499] Iteration 186800, Testing net (#0)
I0617 02:00:48.660315  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.931719
I0617 02:00:48.660359  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.388367 (* 1 = 0.388367 loss)
I0617 02:00:50.835450  5211 main54.cpp:387] Iteration 186800, loss = 0.000669857
I0617 02:00:50.835489  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000669425 (* 1 = 0.000669425 loss)
I0617 02:00:50.835497  5211 sgd_solver.cpp:43] Iteration 186800, lr = 0.0002
I0617 02:14:00.956099  5211 main54.cpp:499] Iteration 187200, Testing net (#0)
I0617 02:15:04.534261  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.931562
I0617 02:15:04.534314  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.395488 (* 1 = 0.395488 loss)
I0617 02:15:06.249526  5211 main54.cpp:387] Iteration 187200, loss = 0.0442065
I0617 02:15:06.249558  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0442061 (* 1 = 0.0442061 loss)
I0617 02:15:06.249565  5211 sgd_solver.cpp:43] Iteration 187200, lr = 0.0002
I0617 02:28:10.877588  5211 main54.cpp:499] Iteration 187600, Testing net (#0)
I0617 02:29:14.519772  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928281
I0617 02:29:14.519811  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.386778 (* 1 = 0.386778 loss)
I0617 02:29:16.646294  5211 main54.cpp:387] Iteration 187600, loss = 0.000304154
I0617 02:29:16.646325  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.000303734 (* 1 = 0.000303734 loss)
I0617 02:29:16.646332  5211 sgd_solver.cpp:43] Iteration 187600, lr = 0.0002
I0617 02:42:27.780618  5211 main54.cpp:499] Iteration 188000, Testing net (#0)
I0617 02:43:31.773222  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.931797
I0617 02:43:31.773275  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.384948 (* 1 = 0.384948 loss)
I0617 02:43:33.652278  5211 main54.cpp:387] Iteration 188000, loss = 0.00726039
I0617 02:43:33.652312  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00725995 (* 1 = 0.00725995 loss)
I0617 02:43:33.652318  5211 sgd_solver.cpp:43] Iteration 188000, lr = 0.0002
I0617 02:56:42.476600  5211 main54.cpp:499] Iteration 188400, Testing net (#0)
I0617 02:57:46.355242  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930469
I0617 02:57:46.355290  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.386845 (* 1 = 0.386845 loss)
I0617 02:57:48.103809  5211 main54.cpp:387] Iteration 188400, loss = 0.0668668
I0617 02:57:48.103845  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0668664 (* 1 = 0.0668664 loss)
I0617 02:57:48.103857  5211 sgd_solver.cpp:43] Iteration 188400, lr = 0.0002
I0617 03:11:03.053360  5211 main54.cpp:499] Iteration 188800, Testing net (#0)
I0617 03:12:07.000082  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928672
I0617 03:12:07.000133  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.410469 (* 1 = 0.410469 loss)
I0617 03:12:08.836208  5211 main54.cpp:387] Iteration 188800, loss = 0.00400949
I0617 03:12:08.836251  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00400909 (* 1 = 0.00400909 loss)
I0617 03:12:08.836258  5211 sgd_solver.cpp:43] Iteration 188800, lr = 0.0002
I0617 03:25:13.879731  5211 main54.cpp:499] Iteration 189200, Testing net (#0)
I0617 03:26:17.670166  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929375
I0617 03:26:17.670209  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.398308 (* 1 = 0.398308 loss)
I0617 03:26:19.653553  5211 main54.cpp:387] Iteration 189200, loss = 0.00125718
I0617 03:26:19.653589  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00125677 (* 1 = 0.00125677 loss)
I0617 03:26:19.653596  5211 sgd_solver.cpp:43] Iteration 189200, lr = 0.0002
I0617 03:39:26.089993  5211 main54.cpp:499] Iteration 189600, Testing net (#0)
I0617 03:40:29.992743  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.93125
I0617 03:40:29.992779  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.387434 (* 1 = 0.387434 loss)
I0617 03:40:31.872110  5211 main54.cpp:387] Iteration 189600, loss = 0.0042945
I0617 03:40:31.872146  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00429407 (* 1 = 0.00429407 loss)
I0617 03:40:31.872153  5211 sgd_solver.cpp:43] Iteration 189600, lr = 0.0002
I0617 03:53:36.614713  5211 main54.cpp:499] Iteration 190000, Testing net (#0)
I0617 03:54:40.440469  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930547
I0617 03:54:40.440515  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.390278 (* 1 = 0.390278 loss)
I0617 03:54:42.473028  5211 main54.cpp:387] Iteration 190000, loss = 0.00639124
I0617 03:54:42.473057  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00639079 (* 1 = 0.00639079 loss)
I0617 03:54:42.473065  5211 sgd_solver.cpp:43] Iteration 190000, lr = 0.0002
I0617 04:07:48.022992  5211 main54.cpp:499] Iteration 190400, Testing net (#0)
I0617 04:08:51.805832  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929375
I0617 04:08:51.805877  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.39207 (* 1 = 0.39207 loss)
I0617 04:08:53.764444  5211 main54.cpp:387] Iteration 190400, loss = 0.00295144
I0617 04:08:53.764473  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00295098 (* 1 = 0.00295098 loss)
I0617 04:08:53.764479  5211 sgd_solver.cpp:43] Iteration 190400, lr = 0.0002
I0617 04:22:00.666791  5211 main54.cpp:499] Iteration 190800, Testing net (#0)
I0617 04:23:04.320736  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930703
I0617 04:23:04.320780  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.38887 (* 1 = 0.38887 loss)
I0617 04:23:06.308694  5211 main54.cpp:387] Iteration 190800, loss = 0.0169832
I0617 04:23:06.308728  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0169827 (* 1 = 0.0169827 loss)
I0617 04:23:06.308735  5211 sgd_solver.cpp:43] Iteration 190800, lr = 0.0002
I0617 04:36:13.808338  5211 main54.cpp:499] Iteration 191200, Testing net (#0)
I0617 04:37:17.925196  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.932031
I0617 04:37:17.925240  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.385265 (* 1 = 0.385265 loss)
I0617 04:37:19.878934  5211 main54.cpp:387] Iteration 191200, loss = 0.0045168
I0617 04:37:19.878975  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00451636 (* 1 = 0.00451636 loss)
I0617 04:37:19.878983  5211 sgd_solver.cpp:43] Iteration 191200, lr = 0.0002
I0617 04:50:29.021277  5211 main54.cpp:499] Iteration 191600, Testing net (#0)
I0617 04:51:32.841495  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.927969
I0617 04:51:32.841542  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.393736 (* 1 = 0.393736 loss)
I0617 04:51:34.719849  5211 main54.cpp:387] Iteration 191600, loss = 0.00203881
I0617 04:51:34.719878  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00203835 (* 1 = 0.00203835 loss)
I0617 04:51:34.719894  5211 sgd_solver.cpp:43] Iteration 191600, lr = 0.0002
I0617 05:04:41.694499  5211 main54.cpp:499] Iteration 192000, Testing net (#0)
I0617 05:05:45.500918  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930391
I0617 05:05:45.500960  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.39643 (* 1 = 0.39643 loss)
I0617 05:05:47.490146  5211 main54.cpp:387] Iteration 192000, loss = 0.001302
I0617 05:05:47.490185  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00130151 (* 1 = 0.00130151 loss)
I0617 05:05:47.490193  5211 sgd_solver.cpp:43] Iteration 192000, lr = 0.0002
I0617 05:18:55.100340  5211 main54.cpp:499] Iteration 192400, Testing net (#0)
I0617 05:19:58.889922  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930078
I0617 05:19:58.889966  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.385077 (* 1 = 0.385077 loss)
I0617 05:20:00.793033  5211 main54.cpp:387] Iteration 192400, loss = 0.00987546
I0617 05:20:00.793064  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00987498 (* 1 = 0.00987498 loss)
I0617 05:20:00.793071  5211 sgd_solver.cpp:43] Iteration 192400, lr = 0.0002
I0617 05:33:08.010592  5211 main54.cpp:499] Iteration 192800, Testing net (#0)
I0617 05:34:11.625514  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930938
I0617 05:34:11.625560  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.389333 (* 1 = 0.389333 loss)
I0617 05:34:13.539386  5211 main54.cpp:387] Iteration 192800, loss = 0.00102897
I0617 05:34:13.539420  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00102849 (* 1 = 0.00102849 loss)
I0617 05:34:13.539427  5211 sgd_solver.cpp:43] Iteration 192800, lr = 0.0002
I0617 05:47:19.982956  5211 main54.cpp:499] Iteration 193200, Testing net (#0)
I0617 05:48:23.908449  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928828
I0617 05:48:23.908489  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.404763 (* 1 = 0.404763 loss)
I0617 05:48:25.844738  5211 main54.cpp:387] Iteration 193200, loss = 0.00193044
I0617 05:48:25.844781  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00192996 (* 1 = 0.00192996 loss)
I0617 05:48:25.844795  5211 sgd_solver.cpp:43] Iteration 193200, lr = 0.0002
I0617 06:01:32.370134  5211 main54.cpp:499] Iteration 193600, Testing net (#0)
I0617 06:02:36.058192  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929844
I0617 06:02:36.058244  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.396046 (* 1 = 0.396046 loss)
I0617 06:02:37.999132  5211 main54.cpp:387] Iteration 193600, loss = 0.00505148
I0617 06:02:37.999163  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00505099 (* 1 = 0.00505099 loss)
I0617 06:02:37.999171  5211 sgd_solver.cpp:43] Iteration 193600, lr = 0.0002
I0617 06:15:46.916841  5211 main54.cpp:499] Iteration 194000, Testing net (#0)
I0617 06:16:50.551695  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929844
I0617 06:16:50.551738  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.392406 (* 1 = 0.392406 loss)
I0617 06:16:52.331188  5211 main54.cpp:387] Iteration 194000, loss = 0.00553676
I0617 06:16:52.331212  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00553627 (* 1 = 0.00553627 loss)
I0617 06:16:52.331219  5211 sgd_solver.cpp:43] Iteration 194000, lr = 0.0002
I0617 06:30:00.639941  5211 main54.cpp:499] Iteration 194400, Testing net (#0)
I0617 06:31:04.444780  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928594
I0617 06:31:04.444823  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.406637 (* 1 = 0.406637 loss)
I0617 06:31:06.312042  5211 main54.cpp:387] Iteration 194400, loss = 0.00494985
I0617 06:31:06.312065  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00494936 (* 1 = 0.00494936 loss)
I0617 06:31:06.312072  5211 sgd_solver.cpp:43] Iteration 194400, lr = 0.0002
I0617 06:44:09.897056  5211 main54.cpp:499] Iteration 194800, Testing net (#0)
I0617 06:45:13.745054  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928516
I0617 06:45:13.745098  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.399598 (* 1 = 0.399598 loss)
I0617 06:45:15.707056  5211 main54.cpp:387] Iteration 194800, loss = 0.0121062
I0617 06:45:15.707093  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0121057 (* 1 = 0.0121057 loss)
I0617 06:45:15.707108  5211 sgd_solver.cpp:43] Iteration 194800, lr = 0.0002
I0617 06:58:23.524488  5211 main54.cpp:499] Iteration 195200, Testing net (#0)
I0617 06:59:27.144753  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930703
I0617 06:59:27.144793  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.392904 (* 1 = 0.392904 loss)
I0617 06:59:29.002148  5211 main54.cpp:387] Iteration 195200, loss = 0.0264985
I0617 06:59:29.002180  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.026498 (* 1 = 0.026498 loss)
I0617 06:59:29.002188  5211 sgd_solver.cpp:43] Iteration 195200, lr = 0.0002
I0617 07:12:35.193323  5211 main54.cpp:499] Iteration 195600, Testing net (#0)
I0617 07:13:38.876368  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.931094
I0617 07:13:38.876412  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.390863 (* 1 = 0.390863 loss)
I0617 07:13:40.823369  5211 main54.cpp:387] Iteration 195600, loss = 0.0133092
I0617 07:13:40.823410  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0133087 (* 1 = 0.0133087 loss)
I0617 07:13:40.823416  5211 sgd_solver.cpp:43] Iteration 195600, lr = 0.0002
I0617 07:26:50.282006  5211 main54.cpp:499] Iteration 196000, Testing net (#0)
I0617 07:27:54.265113  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.928203
I0617 07:27:54.265162  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.411311 (* 1 = 0.411311 loss)
I0617 07:27:56.031918  5211 main54.cpp:387] Iteration 196000, loss = 0.0714865
I0617 07:27:56.031949  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.071486 (* 1 = 0.071486 loss)
I0617 07:27:56.031955  5211 sgd_solver.cpp:43] Iteration 196000, lr = 0.0002
I0617 07:41:06.980368  5211 main54.cpp:499] Iteration 196400, Testing net (#0)
I0617 07:42:11.004886  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930703
I0617 07:42:11.004935  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.394396 (* 1 = 0.394396 loss)
I0617 07:42:12.854866  5211 main54.cpp:387] Iteration 196400, loss = 0.033332
I0617 07:42:12.854905  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0333315 (* 1 = 0.0333315 loss)
I0617 07:42:12.854912  5211 sgd_solver.cpp:43] Iteration 196400, lr = 0.0002
I0617 07:55:19.372262  5211 main54.cpp:499] Iteration 196800, Testing net (#0)
I0617 07:56:23.068866  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930469
I0617 07:56:23.068910  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.395579 (* 1 = 0.395579 loss)
I0617 07:56:24.884680  5211 main54.cpp:387] Iteration 196800, loss = 0.00875361
I0617 07:56:24.884726  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00875311 (* 1 = 0.00875311 loss)
I0617 07:56:24.884734  5211 sgd_solver.cpp:43] Iteration 196800, lr = 0.0002
I0617 08:09:35.847494  5211 main54.cpp:499] Iteration 197200, Testing net (#0)
I0617 08:10:39.538064  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930547
I0617 08:10:39.538101  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.397571 (* 1 = 0.397571 loss)
I0617 08:10:41.251950  5211 main54.cpp:387] Iteration 197200, loss = 0.00356032
I0617 08:10:41.251979  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00355983 (* 1 = 0.00355983 loss)
I0617 08:10:41.251986  5211 sgd_solver.cpp:43] Iteration 197200, lr = 0.0002
I0617 08:23:45.363131  5211 main54.cpp:499] Iteration 197600, Testing net (#0)
I0617 08:24:49.101358  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930938
I0617 08:24:49.101409  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.395296 (* 1 = 0.395296 loss)
I0617 08:24:51.097739  5211 main54.cpp:387] Iteration 197600, loss = 0.00353477
I0617 08:24:51.097774  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00353428 (* 1 = 0.00353428 loss)
I0617 08:24:51.097782  5211 sgd_solver.cpp:43] Iteration 197600, lr = 0.0002
I0617 08:37:59.825073  5211 main54.cpp:499] Iteration 198000, Testing net (#0)
I0617 08:39:03.369772  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.929531
I0617 08:39:03.369817  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.397938 (* 1 = 0.397938 loss)
I0617 08:39:05.296197  5211 main54.cpp:387] Iteration 198000, loss = 0.00346977
I0617 08:39:05.296228  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00346928 (* 1 = 0.00346928 loss)
I0617 08:39:05.296236  5211 sgd_solver.cpp:43] Iteration 198000, lr = 0.0002
I0617 08:52:12.740942  5211 main54.cpp:499] Iteration 198400, Testing net (#0)
I0617 08:53:16.667560  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.931719
I0617 08:53:16.667606  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.389086 (* 1 = 0.389086 loss)
I0617 08:53:18.359139  5211 main54.cpp:387] Iteration 198400, loss = 0.0216826
I0617 08:53:18.359174  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.0216821 (* 1 = 0.0216821 loss)
I0617 08:53:18.359181  5211 sgd_solver.cpp:43] Iteration 198400, lr = 0.0002
I0617 09:06:24.122185  5211 main54.cpp:499] Iteration 198800, Testing net (#0)
I0617 09:07:27.597537  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.93
I0617 09:07:27.597578  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.39902 (* 1 = 0.39902 loss)
I0617 09:07:29.515218  5211 main54.cpp:387] Iteration 198800, loss = 0.00559165
I0617 09:07:29.515250  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00559118 (* 1 = 0.00559118 loss)
I0617 09:07:29.515259  5211 sgd_solver.cpp:43] Iteration 198800, lr = 0.0002
I0617 09:20:33.927852  5211 main54.cpp:499] Iteration 199200, Testing net (#0)
I0617 09:21:37.494886  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930469
I0617 09:21:37.494931  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.405532 (* 1 = 0.405532 loss)
I0617 09:21:39.388200  5211 main54.cpp:387] Iteration 199200, loss = 0.0060499
I0617 09:21:39.388236  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00604942 (* 1 = 0.00604942 loss)
I0617 09:21:39.388244  5211 sgd_solver.cpp:43] Iteration 199200, lr = 0.0002
I0617 09:34:47.135260  5211 main54.cpp:499] Iteration 199600, Testing net (#0)
I0617 09:35:51.021726  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.93125
I0617 09:35:51.021767  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.389254 (* 1 = 0.389254 loss)
I0617 09:35:52.876428  5211 main54.cpp:387] Iteration 199600, loss = 0.00422044
I0617 09:35:52.876482  5211 main54.cpp:403]     Train net output #0: SoftmaxWithLoss1 = 0.00421997 (* 1 = 0.00421997 loss)
I0617 09:35:52.876498  5211 sgd_solver.cpp:43] Iteration 199600, lr = 0.0002
I0617 09:49:01.552459  5211 solver.cpp:459] Snapshotting to binary proto file _iter_200000.caffemodel
I0617 09:49:01.777278  5211 sgd_solver.cpp:458] Snapshotting solver state to binary proto file _iter_200000.solverstate
I0617 09:49:02.517279  5211 main54.cpp:479] Iteration 200000, loss = 2.42145
I0617 09:49:02.517323  5211 main54.cpp:499] Iteration 200000, Testing net (#0)
I0617 09:50:06.262204  5211 main54.cpp:566]     Test net output #0: Accuracy = 0.930859
I0617 09:50:06.262254  5211 main54.cpp:566]     Test net output #1: SoftmaxWithLoss1 = 0.390577 (* 1 = 0.390577 loss)
I0617 09:50:06.262264  5211 main54.cpp:484] Optimization Done.
