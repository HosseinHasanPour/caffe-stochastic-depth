WARNING: Logging before InitGoogleLogging() is written to STDERR
I0612 11:05:13.873836  4990 solver.cpp:53] Initializing solver from parameters:
train_net: "examples/stochastic_depth/residual_train54.prototxt"
test_net: "examples/stochastic_depth/residual_test54.prototxt"
test_iter: 100
test_interval: 400
base_lr: 0.02
display: 400
max_iter: 200000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
solver_mode: GPU
random_seed: 831486
stepvalue: 100000
stepvalue: 150000
type: "Nesterov"
I0612 11:05:13.874054  4990 solver.cpp:86] Creating training net from train_net file: examples/stochastic_depth/residual_train54.prototxt
I0612 11:05:13.891945  4990 net.cpp:148] Initializing net from parameters:
state {
  phase: TRAIN
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "/scratch/pas282/caffe/examples/cifar10/cifar10_train_leveldb_padding0"
    batch_size: 128
    backend: LEVELDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution21"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution22"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution22"
  top: "Convolution22"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Convolution22"
  top: "Convolution23"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution23"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution24"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution25"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution26"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution27"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution28"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution28"
  top: "Convolution28"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution29"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution30"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "Convolution30"
  top: "Convolution30"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Convolution30"
  top: "Convolution31"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise15"
  type: "Eltwise"
  bottom: "Eltwise14"
  bottom: "Convolution31"
  top: "Eltwise15"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "Eltwise15"
  top: "Eltwise15"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Eltwise15"
  top: "Convolution32"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm32"
  type: "BatchNorm"
  bottom: "Convolution32"
  top: "Convolution32"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale32"
  type: "Scale"
  bottom: "Convolution32"
  top: "Convolution32"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU32"
  type: "ReLU"
  bottom: "Convolution32"
  top: "Convolution32"
}
layer {
  name: "Convolution33"
  type: "Convolution"
  bottom: "Convolution32"
  top: "Convolution33"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm33"
  type: "BatchNorm"
  bottom: "Convolution33"
  top: "Convolution33"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale33"
  type: "Scale"
  bottom: "Convolution33"
  top: "Convolution33"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise16"
  type: "Eltwise"
  bottom: "Eltwise15"
  bottom: "Convolution33"
  top: "Eltwise16"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU33"
  type: "ReLU"
  bottom: "Eltwise16"
  top: "Eltwise16"
}
layer {
  name: "Convolution34"
  type: "Convolution"
  bottom: "Eltwise16"
  top: "Convolution34"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm34"
  type: "BatchNorm"
  bottom: "Convolution34"
  top: "Convolution34"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale34"
  type: "Scale"
  bottom: "Convolution34"
  top: "Convolution34"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU34"
  type: "ReLU"
  bottom: "Convolution34"
  top: "Convolution34"
}
layer {
  name: "Convolution35"
  type: "Convolution"
  bottom: "Convolution34"
  top: "Convolution35"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm35"
  type: "BatchNorm"
  bottom: "Convolution35"
  top: "Convolution35"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale35"
  type: "Scale"
  bottom: "Convolution35"
  top: "Convolution35"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise17"
  type: "Eltwise"
  bottom: "Eltwise16"
  bottom: "Convolution35"
  top: "Eltwise17"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU35"
  type: "ReLU"
  bottom: "Eltwise17"
  top: "Eltwise17"
}
layer {
  name: "Convolution36"
  type: "Convolution"
  bottom: "Eltwise17"
  top: "Convolution36"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
I0612 11:05:13.895017  4990 layer_factory.hpp:77] Creating layer Data1
I0612 11:05:13.896220  4990 net.cpp:190] Creating Layer Data1
I0612 11:05:13.896245  4990 net.cpp:589] Data1 -> Data1
I0612 11:05:13.896308  4990 net.cpp:589] Data1 -> Data2
I0612 11:05:13.936085  4994 db_leveldb.cpp:18] Opened leveldb /scratch/pas282/caffe/examples/cifar10/cifar10_train_leveldb_padding0
I0612 11:05:13.972379  4990 data_layer.cpp:41] output data size: 128,3,32,32
I0612 11:05:13.978691  4990 net.cpp:240] Setting up Data1
I0612 11:05:13.978737  4990 net.cpp:247] Top shape: 128 3 32 32 (393216)
I0612 11:05:13.978750  4990 net.cpp:247] Top shape: 128 (128)
I0612 11:05:13.978757  4990 net.cpp:255] Memory required for data: 1573376
I0612 11:05:13.978776  4990 layer_factory.hpp:77] Creating layer Convolution1
I0612 11:05:13.978814  4990 net.cpp:190] Creating Layer Convolution1
I0612 11:05:13.978828  4990 net.cpp:615] Convolution1 <- Data1
I0612 11:05:13.978858  4990 net.cpp:589] Convolution1 -> Convolution1
I0612 11:05:13.980504  4990 net.cpp:240] Setting up Convolution1
I0612 11:05:13.980538  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.980546  4990 net.cpp:255] Memory required for data: 9961984
I0612 11:05:13.980586  4990 layer_factory.hpp:77] Creating layer BatchNorm1
I0612 11:05:13.980618  4990 net.cpp:190] Creating Layer BatchNorm1
I0612 11:05:13.980625  4990 net.cpp:615] BatchNorm1 <- Convolution1
I0612 11:05:13.980643  4990 net.cpp:576] BatchNorm1 -> Convolution1 (in-place)
I0612 11:05:13.980981  4990 net.cpp:240] Setting up BatchNorm1
I0612 11:05:13.980998  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.981003  4990 net.cpp:255] Memory required for data: 18350592
I0612 11:05:13.981030  4990 layer_factory.hpp:77] Creating layer Scale1
I0612 11:05:13.981045  4990 net.cpp:190] Creating Layer Scale1
I0612 11:05:13.981051  4990 net.cpp:615] Scale1 <- Convolution1
I0612 11:05:13.981065  4990 net.cpp:576] Scale1 -> Convolution1 (in-place)
I0612 11:05:13.981130  4990 layer_factory.hpp:77] Creating layer Scale1
I0612 11:05:13.981339  4990 net.cpp:240] Setting up Scale1
I0612 11:05:13.981360  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.981367  4990 net.cpp:255] Memory required for data: 26739200
I0612 11:05:13.981386  4990 layer_factory.hpp:77] Creating layer ReLU1
I0612 11:05:13.981402  4990 net.cpp:190] Creating Layer ReLU1
I0612 11:05:13.981408  4990 net.cpp:615] ReLU1 <- Convolution1
I0612 11:05:13.981418  4990 net.cpp:576] ReLU1 -> Convolution1 (in-place)
I0612 11:05:13.981439  4990 net.cpp:240] Setting up ReLU1
I0612 11:05:13.981449  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.981456  4990 net.cpp:255] Memory required for data: 35127808
I0612 11:05:13.981462  4990 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0612 11:05:13.981482  4990 net.cpp:190] Creating Layer Convolution1_ReLU1_0_split
I0612 11:05:13.981488  4990 net.cpp:615] Convolution1_ReLU1_0_split <- Convolution1
I0612 11:05:13.981503  4990 net.cpp:589] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0612 11:05:13.981514  4990 net.cpp:589] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0612 11:05:13.981583  4990 net.cpp:240] Setting up Convolution1_ReLU1_0_split
I0612 11:05:13.981600  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.981611  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.981616  4990 net.cpp:255] Memory required for data: 51905024
I0612 11:05:13.981622  4990 layer_factory.hpp:77] Creating layer Convolution2
I0612 11:05:13.981639  4990 net.cpp:190] Creating Layer Convolution2
I0612 11:05:13.981647  4990 net.cpp:615] Convolution2 <- Convolution1_ReLU1_0_split_0
I0612 11:05:13.981659  4990 net.cpp:589] Convolution2 -> Convolution2
I0612 11:05:13.983454  4990 net.cpp:240] Setting up Convolution2
I0612 11:05:13.983481  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.983489  4990 net.cpp:255] Memory required for data: 60293632
I0612 11:05:13.983510  4990 layer_factory.hpp:77] Creating layer BatchNorm2
I0612 11:05:13.983530  4990 net.cpp:190] Creating Layer BatchNorm2
I0612 11:05:13.983537  4990 net.cpp:615] BatchNorm2 <- Convolution2
I0612 11:05:13.983548  4990 net.cpp:576] BatchNorm2 -> Convolution2 (in-place)
I0612 11:05:13.983865  4990 net.cpp:240] Setting up BatchNorm2
I0612 11:05:13.983880  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.983886  4990 net.cpp:255] Memory required for data: 68682240
I0612 11:05:13.983904  4990 layer_factory.hpp:77] Creating layer Scale2
I0612 11:05:13.983924  4990 net.cpp:190] Creating Layer Scale2
I0612 11:05:13.983932  4990 net.cpp:615] Scale2 <- Convolution2
I0612 11:05:13.983944  4990 net.cpp:576] Scale2 -> Convolution2 (in-place)
I0612 11:05:13.984004  4990 layer_factory.hpp:77] Creating layer Scale2
I0612 11:05:13.984186  4990 net.cpp:240] Setting up Scale2
I0612 11:05:13.984201  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.984207  4990 net.cpp:255] Memory required for data: 77070848
I0612 11:05:13.984222  4990 layer_factory.hpp:77] Creating layer ReLU2
I0612 11:05:13.984235  4990 net.cpp:190] Creating Layer ReLU2
I0612 11:05:13.984242  4990 net.cpp:615] ReLU2 <- Convolution2
I0612 11:05:13.984251  4990 net.cpp:576] ReLU2 -> Convolution2 (in-place)
I0612 11:05:13.984262  4990 net.cpp:240] Setting up ReLU2
I0612 11:05:13.984272  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.984278  4990 net.cpp:255] Memory required for data: 85459456
I0612 11:05:13.984285  4990 layer_factory.hpp:77] Creating layer Convolution3
I0612 11:05:13.984305  4990 net.cpp:190] Creating Layer Convolution3
I0612 11:05:13.984313  4990 net.cpp:615] Convolution3 <- Convolution2
I0612 11:05:13.984328  4990 net.cpp:589] Convolution3 -> Convolution3
I0612 11:05:13.984812  4990 net.cpp:240] Setting up Convolution3
I0612 11:05:13.984829  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.984836  4990 net.cpp:255] Memory required for data: 93848064
I0612 11:05:13.984851  4990 layer_factory.hpp:77] Creating layer BatchNorm3
I0612 11:05:13.984868  4990 net.cpp:190] Creating Layer BatchNorm3
I0612 11:05:13.984881  4990 net.cpp:615] BatchNorm3 <- Convolution3
I0612 11:05:13.984896  4990 net.cpp:576] BatchNorm3 -> Convolution3 (in-place)
I0612 11:05:13.985198  4990 net.cpp:240] Setting up BatchNorm3
I0612 11:05:13.985213  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.985219  4990 net.cpp:255] Memory required for data: 102236672
I0612 11:05:13.985247  4990 layer_factory.hpp:77] Creating layer Scale3
I0612 11:05:13.985260  4990 net.cpp:190] Creating Layer Scale3
I0612 11:05:13.985266  4990 net.cpp:615] Scale3 <- Convolution3
I0612 11:05:13.985276  4990 net.cpp:576] Scale3 -> Convolution3 (in-place)
I0612 11:05:13.985342  4990 layer_factory.hpp:77] Creating layer Scale3
I0612 11:05:13.985534  4990 net.cpp:240] Setting up Scale3
I0612 11:05:13.985546  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.985553  4990 net.cpp:255] Memory required for data: 110625280
I0612 11:05:13.985566  4990 layer_factory.hpp:77] Creating layer Eltwise1
I0612 11:05:13.985585  4990 net.cpp:190] Creating Layer Eltwise1
I0612 11:05:13.985594  4990 net.cpp:615] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0612 11:05:13.985601  4990 net.cpp:615] Eltwise1 <- Convolution3
I0612 11:05:13.985611  4990 net.cpp:589] Eltwise1 -> Eltwise1
I0612 11:05:13.985800  4990 net.cpp:240] Setting up Eltwise1
I0612 11:05:13.985816  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.985823  4990 net.cpp:255] Memory required for data: 119013888
I0612 11:05:13.985831  4990 layer_factory.hpp:77] Creating layer ReLU3
I0612 11:05:13.985841  4990 net.cpp:190] Creating Layer ReLU3
I0612 11:05:13.985847  4990 net.cpp:615] ReLU3 <- Eltwise1
I0612 11:05:13.985865  4990 net.cpp:576] ReLU3 -> Eltwise1 (in-place)
I0612 11:05:13.985877  4990 net.cpp:240] Setting up ReLU3
I0612 11:05:13.985885  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.985893  4990 net.cpp:255] Memory required for data: 127402496
I0612 11:05:13.985898  4990 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0612 11:05:13.985908  4990 net.cpp:190] Creating Layer Eltwise1_ReLU3_0_split
I0612 11:05:13.985914  4990 net.cpp:615] Eltwise1_ReLU3_0_split <- Eltwise1
I0612 11:05:13.985923  4990 net.cpp:589] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0612 11:05:13.985934  4990 net.cpp:589] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0612 11:05:13.985993  4990 net.cpp:240] Setting up Eltwise1_ReLU3_0_split
I0612 11:05:13.986006  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.986013  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.986019  4990 net.cpp:255] Memory required for data: 144179712
I0612 11:05:13.986027  4990 layer_factory.hpp:77] Creating layer Convolution4
I0612 11:05:13.986045  4990 net.cpp:190] Creating Layer Convolution4
I0612 11:05:13.986052  4990 net.cpp:615] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0612 11:05:13.986068  4990 net.cpp:589] Convolution4 -> Convolution4
I0612 11:05:13.986567  4990 net.cpp:240] Setting up Convolution4
I0612 11:05:13.986584  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.986591  4990 net.cpp:255] Memory required for data: 152568320
I0612 11:05:13.986605  4990 layer_factory.hpp:77] Creating layer BatchNorm4
I0612 11:05:13.986618  4990 net.cpp:190] Creating Layer BatchNorm4
I0612 11:05:13.986625  4990 net.cpp:615] BatchNorm4 <- Convolution4
I0612 11:05:13.986636  4990 net.cpp:576] BatchNorm4 -> Convolution4 (in-place)
I0612 11:05:13.986951  4990 net.cpp:240] Setting up BatchNorm4
I0612 11:05:13.986966  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.986973  4990 net.cpp:255] Memory required for data: 160956928
I0612 11:05:13.986991  4990 layer_factory.hpp:77] Creating layer Scale4
I0612 11:05:13.987004  4990 net.cpp:190] Creating Layer Scale4
I0612 11:05:13.987011  4990 net.cpp:615] Scale4 <- Convolution4
I0612 11:05:13.987021  4990 net.cpp:576] Scale4 -> Convolution4 (in-place)
I0612 11:05:13.987087  4990 layer_factory.hpp:77] Creating layer Scale4
I0612 11:05:13.987278  4990 net.cpp:240] Setting up Scale4
I0612 11:05:13.987299  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.987306  4990 net.cpp:255] Memory required for data: 169345536
I0612 11:05:13.987329  4990 layer_factory.hpp:77] Creating layer ReLU4
I0612 11:05:13.987341  4990 net.cpp:190] Creating Layer ReLU4
I0612 11:05:13.987350  4990 net.cpp:615] ReLU4 <- Convolution4
I0612 11:05:13.987363  4990 net.cpp:576] ReLU4 -> Convolution4 (in-place)
I0612 11:05:13.987375  4990 net.cpp:240] Setting up ReLU4
I0612 11:05:13.987385  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.987390  4990 net.cpp:255] Memory required for data: 177734144
I0612 11:05:13.987396  4990 layer_factory.hpp:77] Creating layer Convolution5
I0612 11:05:13.987412  4990 net.cpp:190] Creating Layer Convolution5
I0612 11:05:13.987419  4990 net.cpp:615] Convolution5 <- Convolution4
I0612 11:05:13.987433  4990 net.cpp:589] Convolution5 -> Convolution5
I0612 11:05:13.987936  4990 net.cpp:240] Setting up Convolution5
I0612 11:05:13.987952  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.987959  4990 net.cpp:255] Memory required for data: 186122752
I0612 11:05:13.987973  4990 layer_factory.hpp:77] Creating layer BatchNorm5
I0612 11:05:13.987985  4990 net.cpp:190] Creating Layer BatchNorm5
I0612 11:05:13.987992  4990 net.cpp:615] BatchNorm5 <- Convolution5
I0612 11:05:13.988004  4990 net.cpp:576] BatchNorm5 -> Convolution5 (in-place)
I0612 11:05:13.988350  4990 net.cpp:240] Setting up BatchNorm5
I0612 11:05:13.988366  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.988373  4990 net.cpp:255] Memory required for data: 194511360
I0612 11:05:13.988401  4990 layer_factory.hpp:77] Creating layer Scale5
I0612 11:05:13.988415  4990 net.cpp:190] Creating Layer Scale5
I0612 11:05:13.988422  4990 net.cpp:615] Scale5 <- Convolution5
I0612 11:05:13.988432  4990 net.cpp:576] Scale5 -> Convolution5 (in-place)
I0612 11:05:13.988625  4990 layer_factory.hpp:77] Creating layer Scale5
I0612 11:05:13.988826  4990 net.cpp:240] Setting up Scale5
I0612 11:05:13.988840  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.988847  4990 net.cpp:255] Memory required for data: 202899968
I0612 11:05:13.988862  4990 layer_factory.hpp:77] Creating layer Eltwise2
I0612 11:05:13.988873  4990 net.cpp:190] Creating Layer Eltwise2
I0612 11:05:13.988879  4990 net.cpp:615] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0612 11:05:13.988888  4990 net.cpp:615] Eltwise2 <- Convolution5
I0612 11:05:13.988901  4990 net.cpp:589] Eltwise2 -> Eltwise2
I0612 11:05:13.988945  4990 net.cpp:240] Setting up Eltwise2
I0612 11:05:13.988955  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.988961  4990 net.cpp:255] Memory required for data: 211288576
I0612 11:05:13.988967  4990 layer_factory.hpp:77] Creating layer ReLU5
I0612 11:05:13.988978  4990 net.cpp:190] Creating Layer ReLU5
I0612 11:05:13.988986  4990 net.cpp:615] ReLU5 <- Eltwise2
I0612 11:05:13.988993  4990 net.cpp:576] ReLU5 -> Eltwise2 (in-place)
I0612 11:05:13.989004  4990 net.cpp:240] Setting up ReLU5
I0612 11:05:13.989013  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.989019  4990 net.cpp:255] Memory required for data: 219677184
I0612 11:05:13.989025  4990 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0612 11:05:13.989039  4990 net.cpp:190] Creating Layer Eltwise2_ReLU5_0_split
I0612 11:05:13.989047  4990 net.cpp:615] Eltwise2_ReLU5_0_split <- Eltwise2
I0612 11:05:13.989055  4990 net.cpp:589] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0612 11:05:13.989066  4990 net.cpp:589] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0612 11:05:13.989127  4990 net.cpp:240] Setting up Eltwise2_ReLU5_0_split
I0612 11:05:13.989137  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.989145  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.989151  4990 net.cpp:255] Memory required for data: 236454400
I0612 11:05:13.989157  4990 layer_factory.hpp:77] Creating layer Convolution6
I0612 11:05:13.989172  4990 net.cpp:190] Creating Layer Convolution6
I0612 11:05:13.989186  4990 net.cpp:615] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0612 11:05:13.989197  4990 net.cpp:589] Convolution6 -> Convolution6
I0612 11:05:13.989707  4990 net.cpp:240] Setting up Convolution6
I0612 11:05:13.989724  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.989730  4990 net.cpp:255] Memory required for data: 244843008
I0612 11:05:13.989744  4990 layer_factory.hpp:77] Creating layer BatchNorm6
I0612 11:05:13.989759  4990 net.cpp:190] Creating Layer BatchNorm6
I0612 11:05:13.989766  4990 net.cpp:615] BatchNorm6 <- Convolution6
I0612 11:05:13.989775  4990 net.cpp:576] BatchNorm6 -> Convolution6 (in-place)
I0612 11:05:13.990082  4990 net.cpp:240] Setting up BatchNorm6
I0612 11:05:13.990094  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.990100  4990 net.cpp:255] Memory required for data: 253231616
I0612 11:05:13.990118  4990 layer_factory.hpp:77] Creating layer Scale6
I0612 11:05:13.990130  4990 net.cpp:190] Creating Layer Scale6
I0612 11:05:13.990136  4990 net.cpp:615] Scale6 <- Convolution6
I0612 11:05:13.990146  4990 net.cpp:576] Scale6 -> Convolution6 (in-place)
I0612 11:05:13.990213  4990 layer_factory.hpp:77] Creating layer Scale6
I0612 11:05:13.990406  4990 net.cpp:240] Setting up Scale6
I0612 11:05:13.990420  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.990427  4990 net.cpp:255] Memory required for data: 261620224
I0612 11:05:13.990447  4990 layer_factory.hpp:77] Creating layer ReLU6
I0612 11:05:13.990463  4990 net.cpp:190] Creating Layer ReLU6
I0612 11:05:13.990469  4990 net.cpp:615] ReLU6 <- Convolution6
I0612 11:05:13.990478  4990 net.cpp:576] ReLU6 -> Convolution6 (in-place)
I0612 11:05:13.990490  4990 net.cpp:240] Setting up ReLU6
I0612 11:05:13.990499  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.990505  4990 net.cpp:255] Memory required for data: 270008832
I0612 11:05:13.990511  4990 layer_factory.hpp:77] Creating layer Convolution7
I0612 11:05:13.990532  4990 net.cpp:190] Creating Layer Convolution7
I0612 11:05:13.990540  4990 net.cpp:615] Convolution7 <- Convolution6
I0612 11:05:13.990556  4990 net.cpp:589] Convolution7 -> Convolution7
I0612 11:05:13.991066  4990 net.cpp:240] Setting up Convolution7
I0612 11:05:13.991086  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.991093  4990 net.cpp:255] Memory required for data: 278397440
I0612 11:05:13.991107  4990 layer_factory.hpp:77] Creating layer BatchNorm7
I0612 11:05:13.991119  4990 net.cpp:190] Creating Layer BatchNorm7
I0612 11:05:13.991125  4990 net.cpp:615] BatchNorm7 <- Convolution7
I0612 11:05:13.991139  4990 net.cpp:576] BatchNorm7 -> Convolution7 (in-place)
I0612 11:05:13.991441  4990 net.cpp:240] Setting up BatchNorm7
I0612 11:05:13.991453  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.991459  4990 net.cpp:255] Memory required for data: 286786048
I0612 11:05:13.991477  4990 layer_factory.hpp:77] Creating layer Scale7
I0612 11:05:13.991499  4990 net.cpp:190] Creating Layer Scale7
I0612 11:05:13.991508  4990 net.cpp:615] Scale7 <- Convolution7
I0612 11:05:13.991516  4990 net.cpp:576] Scale7 -> Convolution7 (in-place)
I0612 11:05:13.991570  4990 layer_factory.hpp:77] Creating layer Scale7
I0612 11:05:13.991756  4990 net.cpp:240] Setting up Scale7
I0612 11:05:13.991770  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.991775  4990 net.cpp:255] Memory required for data: 295174656
I0612 11:05:13.991792  4990 layer_factory.hpp:77] Creating layer Eltwise3
I0612 11:05:13.991803  4990 net.cpp:190] Creating Layer Eltwise3
I0612 11:05:13.991811  4990 net.cpp:615] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0612 11:05:13.991818  4990 net.cpp:615] Eltwise3 <- Convolution7
I0612 11:05:13.991827  4990 net.cpp:589] Eltwise3 -> Eltwise3
I0612 11:05:13.991883  4990 net.cpp:240] Setting up Eltwise3
I0612 11:05:13.991894  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.991900  4990 net.cpp:255] Memory required for data: 303563264
I0612 11:05:13.991906  4990 layer_factory.hpp:77] Creating layer ReLU7
I0612 11:05:13.991925  4990 net.cpp:190] Creating Layer ReLU7
I0612 11:05:13.991932  4990 net.cpp:615] ReLU7 <- Eltwise3
I0612 11:05:13.991941  4990 net.cpp:576] ReLU7 -> Eltwise3 (in-place)
I0612 11:05:13.991955  4990 net.cpp:240] Setting up ReLU7
I0612 11:05:13.991963  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.991969  4990 net.cpp:255] Memory required for data: 311951872
I0612 11:05:13.991974  4990 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0612 11:05:13.991983  4990 net.cpp:190] Creating Layer Eltwise3_ReLU7_0_split
I0612 11:05:13.991989  4990 net.cpp:615] Eltwise3_ReLU7_0_split <- Eltwise3
I0612 11:05:13.991999  4990 net.cpp:589] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0612 11:05:13.992014  4990 net.cpp:589] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0612 11:05:13.992069  4990 net.cpp:240] Setting up Eltwise3_ReLU7_0_split
I0612 11:05:13.992079  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.992087  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.992094  4990 net.cpp:255] Memory required for data: 328729088
I0612 11:05:13.992099  4990 layer_factory.hpp:77] Creating layer Convolution8
I0612 11:05:13.992117  4990 net.cpp:190] Creating Layer Convolution8
I0612 11:05:13.992125  4990 net.cpp:615] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0612 11:05:13.992136  4990 net.cpp:589] Convolution8 -> Convolution8
I0612 11:05:13.992633  4990 net.cpp:240] Setting up Convolution8
I0612 11:05:13.992648  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.992655  4990 net.cpp:255] Memory required for data: 337117696
I0612 11:05:13.992669  4990 layer_factory.hpp:77] Creating layer BatchNorm8
I0612 11:05:13.992683  4990 net.cpp:190] Creating Layer BatchNorm8
I0612 11:05:13.992691  4990 net.cpp:615] BatchNorm8 <- Convolution8
I0612 11:05:13.992704  4990 net.cpp:576] BatchNorm8 -> Convolution8 (in-place)
I0612 11:05:13.993008  4990 net.cpp:240] Setting up BatchNorm8
I0612 11:05:13.993021  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.993026  4990 net.cpp:255] Memory required for data: 345506304
I0612 11:05:13.993043  4990 layer_factory.hpp:77] Creating layer Scale8
I0612 11:05:13.993060  4990 net.cpp:190] Creating Layer Scale8
I0612 11:05:13.993067  4990 net.cpp:615] Scale8 <- Convolution8
I0612 11:05:13.993077  4990 net.cpp:576] Scale8 -> Convolution8 (in-place)
I0612 11:05:13.993136  4990 layer_factory.hpp:77] Creating layer Scale8
I0612 11:05:13.993314  4990 net.cpp:240] Setting up Scale8
I0612 11:05:13.993327  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.993333  4990 net.cpp:255] Memory required for data: 353894912
I0612 11:05:13.993348  4990 layer_factory.hpp:77] Creating layer ReLU8
I0612 11:05:13.993360  4990 net.cpp:190] Creating Layer ReLU8
I0612 11:05:13.993366  4990 net.cpp:615] ReLU8 <- Convolution8
I0612 11:05:13.993376  4990 net.cpp:576] ReLU8 -> Convolution8 (in-place)
I0612 11:05:13.993387  4990 net.cpp:240] Setting up ReLU8
I0612 11:05:13.993396  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.993402  4990 net.cpp:255] Memory required for data: 362283520
I0612 11:05:13.993408  4990 layer_factory.hpp:77] Creating layer Convolution9
I0612 11:05:13.993440  4990 net.cpp:190] Creating Layer Convolution9
I0612 11:05:13.993448  4990 net.cpp:615] Convolution9 <- Convolution8
I0612 11:05:13.993458  4990 net.cpp:589] Convolution9 -> Convolution9
I0612 11:05:13.993943  4990 net.cpp:240] Setting up Convolution9
I0612 11:05:13.993959  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.993965  4990 net.cpp:255] Memory required for data: 370672128
I0612 11:05:13.993981  4990 layer_factory.hpp:77] Creating layer BatchNorm9
I0612 11:05:13.993996  4990 net.cpp:190] Creating Layer BatchNorm9
I0612 11:05:13.994004  4990 net.cpp:615] BatchNorm9 <- Convolution9
I0612 11:05:13.994015  4990 net.cpp:576] BatchNorm9 -> Convolution9 (in-place)
I0612 11:05:13.994316  4990 net.cpp:240] Setting up BatchNorm9
I0612 11:05:13.994329  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.994340  4990 net.cpp:255] Memory required for data: 379060736
I0612 11:05:13.994371  4990 layer_factory.hpp:77] Creating layer Scale9
I0612 11:05:13.994390  4990 net.cpp:190] Creating Layer Scale9
I0612 11:05:13.994397  4990 net.cpp:615] Scale9 <- Convolution9
I0612 11:05:13.994406  4990 net.cpp:576] Scale9 -> Convolution9 (in-place)
I0612 11:05:13.994467  4990 layer_factory.hpp:77] Creating layer Scale9
I0612 11:05:13.994663  4990 net.cpp:240] Setting up Scale9
I0612 11:05:13.994674  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.994680  4990 net.cpp:255] Memory required for data: 387449344
I0612 11:05:13.994693  4990 layer_factory.hpp:77] Creating layer Eltwise4
I0612 11:05:13.994704  4990 net.cpp:190] Creating Layer Eltwise4
I0612 11:05:13.994710  4990 net.cpp:615] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0612 11:05:13.994721  4990 net.cpp:615] Eltwise4 <- Convolution9
I0612 11:05:13.994730  4990 net.cpp:589] Eltwise4 -> Eltwise4
I0612 11:05:13.994770  4990 net.cpp:240] Setting up Eltwise4
I0612 11:05:13.994781  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.994786  4990 net.cpp:255] Memory required for data: 395837952
I0612 11:05:13.994792  4990 layer_factory.hpp:77] Creating layer ReLU9
I0612 11:05:13.994803  4990 net.cpp:190] Creating Layer ReLU9
I0612 11:05:13.994809  4990 net.cpp:615] ReLU9 <- Eltwise4
I0612 11:05:13.994817  4990 net.cpp:576] ReLU9 -> Eltwise4 (in-place)
I0612 11:05:13.994828  4990 net.cpp:240] Setting up ReLU9
I0612 11:05:13.994837  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.994843  4990 net.cpp:255] Memory required for data: 404226560
I0612 11:05:13.994848  4990 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0612 11:05:13.994860  4990 net.cpp:190] Creating Layer Eltwise4_ReLU9_0_split
I0612 11:05:13.994866  4990 net.cpp:615] Eltwise4_ReLU9_0_split <- Eltwise4
I0612 11:05:13.994874  4990 net.cpp:589] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0612 11:05:13.994884  4990 net.cpp:589] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0612 11:05:13.994937  4990 net.cpp:240] Setting up Eltwise4_ReLU9_0_split
I0612 11:05:13.994947  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.994954  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.994961  4990 net.cpp:255] Memory required for data: 421003776
I0612 11:05:13.994966  4990 layer_factory.hpp:77] Creating layer Convolution10
I0612 11:05:13.994979  4990 net.cpp:190] Creating Layer Convolution10
I0612 11:05:13.994985  4990 net.cpp:615] Convolution10 <- Eltwise4_ReLU9_0_split_0
I0612 11:05:13.994995  4990 net.cpp:589] Convolution10 -> Convolution10
I0612 11:05:13.995462  4990 net.cpp:240] Setting up Convolution10
I0612 11:05:13.995476  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.995482  4990 net.cpp:255] Memory required for data: 429392384
I0612 11:05:13.995514  4990 layer_factory.hpp:77] Creating layer BatchNorm10
I0612 11:05:13.995530  4990 net.cpp:190] Creating Layer BatchNorm10
I0612 11:05:13.995537  4990 net.cpp:615] BatchNorm10 <- Convolution10
I0612 11:05:13.995546  4990 net.cpp:576] BatchNorm10 -> Convolution10 (in-place)
I0612 11:05:13.995841  4990 net.cpp:240] Setting up BatchNorm10
I0612 11:05:13.995853  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.995858  4990 net.cpp:255] Memory required for data: 437780992
I0612 11:05:13.995874  4990 layer_factory.hpp:77] Creating layer Scale10
I0612 11:05:13.995885  4990 net.cpp:190] Creating Layer Scale10
I0612 11:05:13.995892  4990 net.cpp:615] Scale10 <- Convolution10
I0612 11:05:13.995901  4990 net.cpp:576] Scale10 -> Convolution10 (in-place)
I0612 11:05:13.995970  4990 layer_factory.hpp:77] Creating layer Scale10
I0612 11:05:13.996142  4990 net.cpp:240] Setting up Scale10
I0612 11:05:13.996155  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.996160  4990 net.cpp:255] Memory required for data: 446169600
I0612 11:05:13.996173  4990 layer_factory.hpp:77] Creating layer ReLU10
I0612 11:05:13.996191  4990 net.cpp:190] Creating Layer ReLU10
I0612 11:05:13.996199  4990 net.cpp:615] ReLU10 <- Convolution10
I0612 11:05:13.996208  4990 net.cpp:576] ReLU10 -> Convolution10 (in-place)
I0612 11:05:13.996219  4990 net.cpp:240] Setting up ReLU10
I0612 11:05:13.996228  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.996234  4990 net.cpp:255] Memory required for data: 454558208
I0612 11:05:13.996240  4990 layer_factory.hpp:77] Creating layer Convolution11
I0612 11:05:13.996259  4990 net.cpp:190] Creating Layer Convolution11
I0612 11:05:13.996266  4990 net.cpp:615] Convolution11 <- Convolution10
I0612 11:05:13.996279  4990 net.cpp:589] Convolution11 -> Convolution11
I0612 11:05:13.996737  4990 net.cpp:240] Setting up Convolution11
I0612 11:05:13.996753  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.996760  4990 net.cpp:255] Memory required for data: 462946816
I0612 11:05:13.996774  4990 layer_factory.hpp:77] Creating layer BatchNorm11
I0612 11:05:13.996788  4990 net.cpp:190] Creating Layer BatchNorm11
I0612 11:05:13.996793  4990 net.cpp:615] BatchNorm11 <- Convolution11
I0612 11:05:13.996803  4990 net.cpp:576] BatchNorm11 -> Convolution11 (in-place)
I0612 11:05:13.997095  4990 net.cpp:240] Setting up BatchNorm11
I0612 11:05:13.997108  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.997114  4990 net.cpp:255] Memory required for data: 471335424
I0612 11:05:13.997130  4990 layer_factory.hpp:77] Creating layer Scale11
I0612 11:05:13.997141  4990 net.cpp:190] Creating Layer Scale11
I0612 11:05:13.997148  4990 net.cpp:615] Scale11 <- Convolution11
I0612 11:05:13.997155  4990 net.cpp:576] Scale11 -> Convolution11 (in-place)
I0612 11:05:13.997212  4990 layer_factory.hpp:77] Creating layer Scale11
I0612 11:05:13.997387  4990 net.cpp:240] Setting up Scale11
I0612 11:05:13.997400  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.997405  4990 net.cpp:255] Memory required for data: 479724032
I0612 11:05:13.997421  4990 layer_factory.hpp:77] Creating layer Eltwise5
I0612 11:05:13.997431  4990 net.cpp:190] Creating Layer Eltwise5
I0612 11:05:13.997455  4990 net.cpp:615] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0612 11:05:13.997462  4990 net.cpp:615] Eltwise5 <- Convolution11
I0612 11:05:13.997474  4990 net.cpp:589] Eltwise5 -> Eltwise5
I0612 11:05:13.997509  4990 net.cpp:240] Setting up Eltwise5
I0612 11:05:13.997519  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.997524  4990 net.cpp:255] Memory required for data: 488112640
I0612 11:05:13.997529  4990 layer_factory.hpp:77] Creating layer ReLU11
I0612 11:05:13.997542  4990 net.cpp:190] Creating Layer ReLU11
I0612 11:05:13.997548  4990 net.cpp:615] ReLU11 <- Eltwise5
I0612 11:05:13.997557  4990 net.cpp:576] ReLU11 -> Eltwise5 (in-place)
I0612 11:05:13.997570  4990 net.cpp:240] Setting up ReLU11
I0612 11:05:13.997576  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.997582  4990 net.cpp:255] Memory required for data: 496501248
I0612 11:05:13.997588  4990 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0612 11:05:13.997597  4990 net.cpp:190] Creating Layer Eltwise5_ReLU11_0_split
I0612 11:05:13.997602  4990 net.cpp:615] Eltwise5_ReLU11_0_split <- Eltwise5
I0612 11:05:13.997614  4990 net.cpp:589] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0612 11:05:13.997625  4990 net.cpp:589] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0612 11:05:13.997678  4990 net.cpp:240] Setting up Eltwise5_ReLU11_0_split
I0612 11:05:13.997687  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.997694  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.997700  4990 net.cpp:255] Memory required for data: 513278464
I0612 11:05:13.997705  4990 layer_factory.hpp:77] Creating layer Convolution12
I0612 11:05:13.997725  4990 net.cpp:190] Creating Layer Convolution12
I0612 11:05:13.997731  4990 net.cpp:615] Convolution12 <- Eltwise5_ReLU11_0_split_0
I0612 11:05:13.997741  4990 net.cpp:589] Convolution12 -> Convolution12
I0612 11:05:13.998214  4990 net.cpp:240] Setting up Convolution12
I0612 11:05:13.998229  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.998234  4990 net.cpp:255] Memory required for data: 521667072
I0612 11:05:13.998247  4990 layer_factory.hpp:77] Creating layer BatchNorm12
I0612 11:05:13.998257  4990 net.cpp:190] Creating Layer BatchNorm12
I0612 11:05:13.998263  4990 net.cpp:615] BatchNorm12 <- Convolution12
I0612 11:05:13.998275  4990 net.cpp:576] BatchNorm12 -> Convolution12 (in-place)
I0612 11:05:13.998574  4990 net.cpp:240] Setting up BatchNorm12
I0612 11:05:13.998586  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.998592  4990 net.cpp:255] Memory required for data: 530055680
I0612 11:05:13.998607  4990 layer_factory.hpp:77] Creating layer Scale12
I0612 11:05:13.998618  4990 net.cpp:190] Creating Layer Scale12
I0612 11:05:13.998625  4990 net.cpp:615] Scale12 <- Convolution12
I0612 11:05:13.998636  4990 net.cpp:576] Scale12 -> Convolution12 (in-place)
I0612 11:05:13.998689  4990 layer_factory.hpp:77] Creating layer Scale12
I0612 11:05:13.998868  4990 net.cpp:240] Setting up Scale12
I0612 11:05:13.998881  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.998886  4990 net.cpp:255] Memory required for data: 538444288
I0612 11:05:13.998899  4990 layer_factory.hpp:77] Creating layer ReLU12
I0612 11:05:13.998913  4990 net.cpp:190] Creating Layer ReLU12
I0612 11:05:13.998919  4990 net.cpp:615] ReLU12 <- Convolution12
I0612 11:05:13.998929  4990 net.cpp:576] ReLU12 -> Convolution12 (in-place)
I0612 11:05:13.998937  4990 net.cpp:240] Setting up ReLU12
I0612 11:05:13.998945  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.998950  4990 net.cpp:255] Memory required for data: 546832896
I0612 11:05:13.998956  4990 layer_factory.hpp:77] Creating layer Convolution13
I0612 11:05:13.998975  4990 net.cpp:190] Creating Layer Convolution13
I0612 11:05:13.998980  4990 net.cpp:615] Convolution13 <- Convolution12
I0612 11:05:13.998991  4990 net.cpp:589] Convolution13 -> Convolution13
I0612 11:05:13.999454  4990 net.cpp:240] Setting up Convolution13
I0612 11:05:13.999469  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.999475  4990 net.cpp:255] Memory required for data: 555221504
I0612 11:05:13.999487  4990 layer_factory.hpp:77] Creating layer BatchNorm13
I0612 11:05:13.999497  4990 net.cpp:190] Creating Layer BatchNorm13
I0612 11:05:13.999503  4990 net.cpp:615] BatchNorm13 <- Convolution13
I0612 11:05:13.999516  4990 net.cpp:576] BatchNorm13 -> Convolution13 (in-place)
I0612 11:05:13.999802  4990 net.cpp:240] Setting up BatchNorm13
I0612 11:05:13.999814  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:13.999819  4990 net.cpp:255] Memory required for data: 563610112
I0612 11:05:13.999835  4990 layer_factory.hpp:77] Creating layer Scale13
I0612 11:05:13.999845  4990 net.cpp:190] Creating Layer Scale13
I0612 11:05:13.999850  4990 net.cpp:615] Scale13 <- Convolution13
I0612 11:05:13.999862  4990 net.cpp:576] Scale13 -> Convolution13 (in-place)
I0612 11:05:13.999912  4990 layer_factory.hpp:77] Creating layer Scale13
I0612 11:05:14.000078  4990 net.cpp:240] Setting up Scale13
I0612 11:05:14.000092  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.000097  4990 net.cpp:255] Memory required for data: 571998720
I0612 11:05:14.000110  4990 layer_factory.hpp:77] Creating layer Eltwise6
I0612 11:05:14.000123  4990 net.cpp:190] Creating Layer Eltwise6
I0612 11:05:14.000130  4990 net.cpp:615] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0612 11:05:14.000138  4990 net.cpp:615] Eltwise6 <- Convolution13
I0612 11:05:14.000146  4990 net.cpp:589] Eltwise6 -> Eltwise6
I0612 11:05:14.000190  4990 net.cpp:240] Setting up Eltwise6
I0612 11:05:14.000203  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.000210  4990 net.cpp:255] Memory required for data: 580387328
I0612 11:05:14.000216  4990 layer_factory.hpp:77] Creating layer ReLU13
I0612 11:05:14.000236  4990 net.cpp:190] Creating Layer ReLU13
I0612 11:05:14.000242  4990 net.cpp:615] ReLU13 <- Eltwise6
I0612 11:05:14.000258  4990 net.cpp:576] ReLU13 -> Eltwise6 (in-place)
I0612 11:05:14.000269  4990 net.cpp:240] Setting up ReLU13
I0612 11:05:14.000277  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.000283  4990 net.cpp:255] Memory required for data: 588775936
I0612 11:05:14.000288  4990 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0612 11:05:14.000296  4990 net.cpp:190] Creating Layer Eltwise6_ReLU13_0_split
I0612 11:05:14.000301  4990 net.cpp:615] Eltwise6_ReLU13_0_split <- Eltwise6
I0612 11:05:14.000309  4990 net.cpp:589] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0612 11:05:14.000319  4990 net.cpp:589] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0612 11:05:14.000372  4990 net.cpp:240] Setting up Eltwise6_ReLU13_0_split
I0612 11:05:14.000383  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.000391  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.000396  4990 net.cpp:255] Memory required for data: 605553152
I0612 11:05:14.000401  4990 layer_factory.hpp:77] Creating layer Convolution14
I0612 11:05:14.000416  4990 net.cpp:190] Creating Layer Convolution14
I0612 11:05:14.000422  4990 net.cpp:615] Convolution14 <- Eltwise6_ReLU13_0_split_0
I0612 11:05:14.000435  4990 net.cpp:589] Convolution14 -> Convolution14
I0612 11:05:14.000890  4990 net.cpp:240] Setting up Convolution14
I0612 11:05:14.000905  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.000910  4990 net.cpp:255] Memory required for data: 613941760
I0612 11:05:14.000923  4990 layer_factory.hpp:77] Creating layer BatchNorm14
I0612 11:05:14.000933  4990 net.cpp:190] Creating Layer BatchNorm14
I0612 11:05:14.000939  4990 net.cpp:615] BatchNorm14 <- Convolution14
I0612 11:05:14.000952  4990 net.cpp:576] BatchNorm14 -> Convolution14 (in-place)
I0612 11:05:14.001242  4990 net.cpp:240] Setting up BatchNorm14
I0612 11:05:14.001255  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.001261  4990 net.cpp:255] Memory required for data: 622330368
I0612 11:05:14.001277  4990 layer_factory.hpp:77] Creating layer Scale14
I0612 11:05:14.001287  4990 net.cpp:190] Creating Layer Scale14
I0612 11:05:14.001293  4990 net.cpp:615] Scale14 <- Convolution14
I0612 11:05:14.001307  4990 net.cpp:576] Scale14 -> Convolution14 (in-place)
I0612 11:05:14.001356  4990 layer_factory.hpp:77] Creating layer Scale14
I0612 11:05:14.001519  4990 net.cpp:240] Setting up Scale14
I0612 11:05:14.001531  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.001538  4990 net.cpp:255] Memory required for data: 630718976
I0612 11:05:14.001550  4990 layer_factory.hpp:77] Creating layer ReLU14
I0612 11:05:14.001564  4990 net.cpp:190] Creating Layer ReLU14
I0612 11:05:14.001569  4990 net.cpp:615] ReLU14 <- Convolution14
I0612 11:05:14.001579  4990 net.cpp:576] ReLU14 -> Convolution14 (in-place)
I0612 11:05:14.001587  4990 net.cpp:240] Setting up ReLU14
I0612 11:05:14.001595  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.001601  4990 net.cpp:255] Memory required for data: 639107584
I0612 11:05:14.001606  4990 layer_factory.hpp:77] Creating layer Convolution15
I0612 11:05:14.001623  4990 net.cpp:190] Creating Layer Convolution15
I0612 11:05:14.001631  4990 net.cpp:615] Convolution15 <- Convolution14
I0612 11:05:14.001639  4990 net.cpp:589] Convolution15 -> Convolution15
I0612 11:05:14.002100  4990 net.cpp:240] Setting up Convolution15
I0612 11:05:14.002115  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.002120  4990 net.cpp:255] Memory required for data: 647496192
I0612 11:05:14.002133  4990 layer_factory.hpp:77] Creating layer BatchNorm15
I0612 11:05:14.002147  4990 net.cpp:190] Creating Layer BatchNorm15
I0612 11:05:14.002154  4990 net.cpp:615] BatchNorm15 <- Convolution15
I0612 11:05:14.002162  4990 net.cpp:576] BatchNorm15 -> Convolution15 (in-place)
I0612 11:05:14.002454  4990 net.cpp:240] Setting up BatchNorm15
I0612 11:05:14.002467  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.002473  4990 net.cpp:255] Memory required for data: 655884800
I0612 11:05:14.002495  4990 layer_factory.hpp:77] Creating layer Scale15
I0612 11:05:14.002506  4990 net.cpp:190] Creating Layer Scale15
I0612 11:05:14.002511  4990 net.cpp:615] Scale15 <- Convolution15
I0612 11:05:14.002524  4990 net.cpp:576] Scale15 -> Convolution15 (in-place)
I0612 11:05:14.002575  4990 layer_factory.hpp:77] Creating layer Scale15
I0612 11:05:14.002739  4990 net.cpp:240] Setting up Scale15
I0612 11:05:14.002754  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.002760  4990 net.cpp:255] Memory required for data: 664273408
I0612 11:05:14.002774  4990 layer_factory.hpp:77] Creating layer Eltwise7
I0612 11:05:14.002787  4990 net.cpp:190] Creating Layer Eltwise7
I0612 11:05:14.002795  4990 net.cpp:615] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0612 11:05:14.002802  4990 net.cpp:615] Eltwise7 <- Convolution15
I0612 11:05:14.002811  4990 net.cpp:589] Eltwise7 -> Eltwise7
I0612 11:05:14.002852  4990 net.cpp:240] Setting up Eltwise7
I0612 11:05:14.002864  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.002869  4990 net.cpp:255] Memory required for data: 672662016
I0612 11:05:14.002876  4990 layer_factory.hpp:77] Creating layer ReLU15
I0612 11:05:14.002883  4990 net.cpp:190] Creating Layer ReLU15
I0612 11:05:14.002889  4990 net.cpp:615] ReLU15 <- Eltwise7
I0612 11:05:14.002900  4990 net.cpp:576] ReLU15 -> Eltwise7 (in-place)
I0612 11:05:14.002910  4990 net.cpp:240] Setting up ReLU15
I0612 11:05:14.002918  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.002923  4990 net.cpp:255] Memory required for data: 681050624
I0612 11:05:14.002928  4990 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0612 11:05:14.002938  4990 net.cpp:190] Creating Layer Eltwise7_ReLU15_0_split
I0612 11:05:14.002943  4990 net.cpp:615] Eltwise7_ReLU15_0_split <- Eltwise7
I0612 11:05:14.002951  4990 net.cpp:589] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0612 11:05:14.002961  4990 net.cpp:589] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0612 11:05:14.003018  4990 net.cpp:240] Setting up Eltwise7_ReLU15_0_split
I0612 11:05:14.003029  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.003036  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.003041  4990 net.cpp:255] Memory required for data: 697827840
I0612 11:05:14.003047  4990 layer_factory.hpp:77] Creating layer Convolution16
I0612 11:05:14.003064  4990 net.cpp:190] Creating Layer Convolution16
I0612 11:05:14.003070  4990 net.cpp:615] Convolution16 <- Eltwise7_ReLU15_0_split_0
I0612 11:05:14.003082  4990 net.cpp:589] Convolution16 -> Convolution16
I0612 11:05:14.003551  4990 net.cpp:240] Setting up Convolution16
I0612 11:05:14.003566  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.003571  4990 net.cpp:255] Memory required for data: 706216448
I0612 11:05:14.003584  4990 layer_factory.hpp:77] Creating layer BatchNorm16
I0612 11:05:14.003598  4990 net.cpp:190] Creating Layer BatchNorm16
I0612 11:05:14.003605  4990 net.cpp:615] BatchNorm16 <- Convolution16
I0612 11:05:14.003617  4990 net.cpp:576] BatchNorm16 -> Convolution16 (in-place)
I0612 11:05:14.003904  4990 net.cpp:240] Setting up BatchNorm16
I0612 11:05:14.003916  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.003921  4990 net.cpp:255] Memory required for data: 714605056
I0612 11:05:14.003937  4990 layer_factory.hpp:77] Creating layer Scale16
I0612 11:05:14.003952  4990 net.cpp:190] Creating Layer Scale16
I0612 11:05:14.003958  4990 net.cpp:615] Scale16 <- Convolution16
I0612 11:05:14.003967  4990 net.cpp:576] Scale16 -> Convolution16 (in-place)
I0612 11:05:14.004017  4990 layer_factory.hpp:77] Creating layer Scale16
I0612 11:05:14.004202  4990 net.cpp:240] Setting up Scale16
I0612 11:05:14.004215  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.004221  4990 net.cpp:255] Memory required for data: 722993664
I0612 11:05:14.004235  4990 layer_factory.hpp:77] Creating layer ReLU16
I0612 11:05:14.004245  4990 net.cpp:190] Creating Layer ReLU16
I0612 11:05:14.004257  4990 net.cpp:615] ReLU16 <- Convolution16
I0612 11:05:14.004266  4990 net.cpp:576] ReLU16 -> Convolution16 (in-place)
I0612 11:05:14.004276  4990 net.cpp:240] Setting up ReLU16
I0612 11:05:14.004284  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.004289  4990 net.cpp:255] Memory required for data: 731382272
I0612 11:05:14.004295  4990 layer_factory.hpp:77] Creating layer Convolution17
I0612 11:05:14.004313  4990 net.cpp:190] Creating Layer Convolution17
I0612 11:05:14.004323  4990 net.cpp:615] Convolution17 <- Convolution16
I0612 11:05:14.004331  4990 net.cpp:589] Convolution17 -> Convolution17
I0612 11:05:14.004801  4990 net.cpp:240] Setting up Convolution17
I0612 11:05:14.004814  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.004820  4990 net.cpp:255] Memory required for data: 739770880
I0612 11:05:14.004833  4990 layer_factory.hpp:77] Creating layer BatchNorm17
I0612 11:05:14.004848  4990 net.cpp:190] Creating Layer BatchNorm17
I0612 11:05:14.004853  4990 net.cpp:615] BatchNorm17 <- Convolution17
I0612 11:05:14.004864  4990 net.cpp:576] BatchNorm17 -> Convolution17 (in-place)
I0612 11:05:14.005152  4990 net.cpp:240] Setting up BatchNorm17
I0612 11:05:14.005164  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.005170  4990 net.cpp:255] Memory required for data: 748159488
I0612 11:05:14.005185  4990 layer_factory.hpp:77] Creating layer Scale17
I0612 11:05:14.005199  4990 net.cpp:190] Creating Layer Scale17
I0612 11:05:14.005206  4990 net.cpp:615] Scale17 <- Convolution17
I0612 11:05:14.005214  4990 net.cpp:576] Scale17 -> Convolution17 (in-place)
I0612 11:05:14.005270  4990 layer_factory.hpp:77] Creating layer Scale17
I0612 11:05:14.005441  4990 net.cpp:240] Setting up Scale17
I0612 11:05:14.005453  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.005460  4990 net.cpp:255] Memory required for data: 756548096
I0612 11:05:14.005472  4990 layer_factory.hpp:77] Creating layer Eltwise8
I0612 11:05:14.005483  4990 net.cpp:190] Creating Layer Eltwise8
I0612 11:05:14.005491  4990 net.cpp:615] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0612 11:05:14.005506  4990 net.cpp:615] Eltwise8 <- Convolution17
I0612 11:05:14.005516  4990 net.cpp:589] Eltwise8 -> Eltwise8
I0612 11:05:14.005556  4990 net.cpp:240] Setting up Eltwise8
I0612 11:05:14.005568  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.005573  4990 net.cpp:255] Memory required for data: 764936704
I0612 11:05:14.005578  4990 layer_factory.hpp:77] Creating layer ReLU17
I0612 11:05:14.005589  4990 net.cpp:190] Creating Layer ReLU17
I0612 11:05:14.005594  4990 net.cpp:615] ReLU17 <- Eltwise8
I0612 11:05:14.005601  4990 net.cpp:576] ReLU17 -> Eltwise8 (in-place)
I0612 11:05:14.005611  4990 net.cpp:240] Setting up ReLU17
I0612 11:05:14.005620  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.005625  4990 net.cpp:255] Memory required for data: 773325312
I0612 11:05:14.005630  4990 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0612 11:05:14.005642  4990 net.cpp:190] Creating Layer Eltwise8_ReLU17_0_split
I0612 11:05:14.005648  4990 net.cpp:615] Eltwise8_ReLU17_0_split <- Eltwise8
I0612 11:05:14.005656  4990 net.cpp:589] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0612 11:05:14.005666  4990 net.cpp:589] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0612 11:05:14.005720  4990 net.cpp:240] Setting up Eltwise8_ReLU17_0_split
I0612 11:05:14.005731  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.005738  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.005744  4990 net.cpp:255] Memory required for data: 790102528
I0612 11:05:14.005749  4990 layer_factory.hpp:77] Creating layer Convolution18
I0612 11:05:14.005764  4990 net.cpp:190] Creating Layer Convolution18
I0612 11:05:14.005770  4990 net.cpp:615] Convolution18 <- Eltwise8_ReLU17_0_split_0
I0612 11:05:14.005780  4990 net.cpp:589] Convolution18 -> Convolution18
I0612 11:05:14.006244  4990 net.cpp:240] Setting up Convolution18
I0612 11:05:14.006263  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.006269  4990 net.cpp:255] Memory required for data: 798491136
I0612 11:05:14.006283  4990 layer_factory.hpp:77] Creating layer BatchNorm18
I0612 11:05:14.006296  4990 net.cpp:190] Creating Layer BatchNorm18
I0612 11:05:14.006304  4990 net.cpp:615] BatchNorm18 <- Convolution18
I0612 11:05:14.006312  4990 net.cpp:576] BatchNorm18 -> Convolution18 (in-place)
I0612 11:05:14.006615  4990 net.cpp:240] Setting up BatchNorm18
I0612 11:05:14.006628  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.006634  4990 net.cpp:255] Memory required for data: 806879744
I0612 11:05:14.006649  4990 layer_factory.hpp:77] Creating layer Scale18
I0612 11:05:14.006660  4990 net.cpp:190] Creating Layer Scale18
I0612 11:05:14.006666  4990 net.cpp:615] Scale18 <- Convolution18
I0612 11:05:14.006675  4990 net.cpp:576] Scale18 -> Convolution18 (in-place)
I0612 11:05:14.006729  4990 layer_factory.hpp:77] Creating layer Scale18
I0612 11:05:14.006894  4990 net.cpp:240] Setting up Scale18
I0612 11:05:14.006906  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.006911  4990 net.cpp:255] Memory required for data: 815268352
I0612 11:05:14.006925  4990 layer_factory.hpp:77] Creating layer ReLU18
I0612 11:05:14.006935  4990 net.cpp:190] Creating Layer ReLU18
I0612 11:05:14.006942  4990 net.cpp:615] ReLU18 <- Convolution18
I0612 11:05:14.006949  4990 net.cpp:576] ReLU18 -> Convolution18 (in-place)
I0612 11:05:14.006961  4990 net.cpp:240] Setting up ReLU18
I0612 11:05:14.006968  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.006973  4990 net.cpp:255] Memory required for data: 823656960
I0612 11:05:14.006978  4990 layer_factory.hpp:77] Creating layer Convolution19
I0612 11:05:14.006992  4990 net.cpp:190] Creating Layer Convolution19
I0612 11:05:14.006997  4990 net.cpp:615] Convolution19 <- Convolution18
I0612 11:05:14.007009  4990 net.cpp:589] Convolution19 -> Convolution19
I0612 11:05:14.007467  4990 net.cpp:240] Setting up Convolution19
I0612 11:05:14.007479  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.007485  4990 net.cpp:255] Memory required for data: 832045568
I0612 11:05:14.007498  4990 layer_factory.hpp:77] Creating layer BatchNorm19
I0612 11:05:14.007508  4990 net.cpp:190] Creating Layer BatchNorm19
I0612 11:05:14.007513  4990 net.cpp:615] BatchNorm19 <- Convolution19
I0612 11:05:14.007524  4990 net.cpp:576] BatchNorm19 -> Convolution19 (in-place)
I0612 11:05:14.007796  4990 net.cpp:240] Setting up BatchNorm19
I0612 11:05:14.007807  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.007812  4990 net.cpp:255] Memory required for data: 840434176
I0612 11:05:14.007851  4990 layer_factory.hpp:77] Creating layer Scale19
I0612 11:05:14.007863  4990 net.cpp:190] Creating Layer Scale19
I0612 11:05:14.007869  4990 net.cpp:615] Scale19 <- Convolution19
I0612 11:05:14.007877  4990 net.cpp:576] Scale19 -> Convolution19 (in-place)
I0612 11:05:14.007935  4990 layer_factory.hpp:77] Creating layer Scale19
I0612 11:05:14.008095  4990 net.cpp:240] Setting up Scale19
I0612 11:05:14.008106  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.008111  4990 net.cpp:255] Memory required for data: 848822784
I0612 11:05:14.008123  4990 layer_factory.hpp:77] Creating layer Eltwise9
I0612 11:05:14.008137  4990 net.cpp:190] Creating Layer Eltwise9
I0612 11:05:14.008144  4990 net.cpp:615] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0612 11:05:14.008152  4990 net.cpp:615] Eltwise9 <- Convolution19
I0612 11:05:14.008159  4990 net.cpp:589] Eltwise9 -> Eltwise9
I0612 11:05:14.008193  4990 net.cpp:240] Setting up Eltwise9
I0612 11:05:14.008203  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.008208  4990 net.cpp:255] Memory required for data: 857211392
I0612 11:05:14.008213  4990 layer_factory.hpp:77] Creating layer ReLU19
I0612 11:05:14.008221  4990 net.cpp:190] Creating Layer ReLU19
I0612 11:05:14.008227  4990 net.cpp:615] ReLU19 <- Eltwise9
I0612 11:05:14.008244  4990 net.cpp:576] ReLU19 -> Eltwise9 (in-place)
I0612 11:05:14.008255  4990 net.cpp:240] Setting up ReLU19
I0612 11:05:14.008261  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.008267  4990 net.cpp:255] Memory required for data: 865600000
I0612 11:05:14.008272  4990 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0612 11:05:14.008280  4990 net.cpp:190] Creating Layer Eltwise9_ReLU19_0_split
I0612 11:05:14.008285  4990 net.cpp:615] Eltwise9_ReLU19_0_split <- Eltwise9
I0612 11:05:14.008296  4990 net.cpp:589] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0612 11:05:14.008306  4990 net.cpp:589] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0612 11:05:14.008357  4990 net.cpp:240] Setting up Eltwise9_ReLU19_0_split
I0612 11:05:14.008366  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.008373  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.008378  4990 net.cpp:255] Memory required for data: 882377216
I0612 11:05:14.008384  4990 layer_factory.hpp:77] Creating layer Convolution20
I0612 11:05:14.008399  4990 net.cpp:190] Creating Layer Convolution20
I0612 11:05:14.008404  4990 net.cpp:615] Convolution20 <- Eltwise9_ReLU19_0_split_0
I0612 11:05:14.008421  4990 net.cpp:589] Convolution20 -> Convolution20
I0612 11:05:14.008857  4990 net.cpp:240] Setting up Convolution20
I0612 11:05:14.008872  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.008877  4990 net.cpp:255] Memory required for data: 890765824
I0612 11:05:14.008889  4990 layer_factory.hpp:77] Creating layer BatchNorm20
I0612 11:05:14.008898  4990 net.cpp:190] Creating Layer BatchNorm20
I0612 11:05:14.008904  4990 net.cpp:615] BatchNorm20 <- Convolution20
I0612 11:05:14.008915  4990 net.cpp:576] BatchNorm20 -> Convolution20 (in-place)
I0612 11:05:14.009186  4990 net.cpp:240] Setting up BatchNorm20
I0612 11:05:14.009196  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.009202  4990 net.cpp:255] Memory required for data: 899154432
I0612 11:05:14.009215  4990 layer_factory.hpp:77] Creating layer Scale20
I0612 11:05:14.009225  4990 net.cpp:190] Creating Layer Scale20
I0612 11:05:14.009230  4990 net.cpp:615] Scale20 <- Convolution20
I0612 11:05:14.009238  4990 net.cpp:576] Scale20 -> Convolution20 (in-place)
I0612 11:05:14.009289  4990 layer_factory.hpp:77] Creating layer Scale20
I0612 11:05:14.009445  4990 net.cpp:240] Setting up Scale20
I0612 11:05:14.009456  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.009461  4990 net.cpp:255] Memory required for data: 907543040
I0612 11:05:14.009474  4990 layer_factory.hpp:77] Creating layer ReLU20
I0612 11:05:14.009484  4990 net.cpp:190] Creating Layer ReLU20
I0612 11:05:14.009493  4990 net.cpp:615] ReLU20 <- Convolution20
I0612 11:05:14.009501  4990 net.cpp:576] ReLU20 -> Convolution20 (in-place)
I0612 11:05:14.009510  4990 net.cpp:240] Setting up ReLU20
I0612 11:05:14.009518  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.009523  4990 net.cpp:255] Memory required for data: 915931648
I0612 11:05:14.009528  4990 layer_factory.hpp:77] Creating layer Convolution21
I0612 11:05:14.009544  4990 net.cpp:190] Creating Layer Convolution21
I0612 11:05:14.009551  4990 net.cpp:615] Convolution21 <- Convolution20
I0612 11:05:14.009559  4990 net.cpp:589] Convolution21 -> Convolution21
I0612 11:05:14.010004  4990 net.cpp:240] Setting up Convolution21
I0612 11:05:14.010017  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.010022  4990 net.cpp:255] Memory required for data: 924320256
I0612 11:05:14.010035  4990 layer_factory.hpp:77] Creating layer BatchNorm21
I0612 11:05:14.010046  4990 net.cpp:190] Creating Layer BatchNorm21
I0612 11:05:14.010051  4990 net.cpp:615] BatchNorm21 <- Convolution21
I0612 11:05:14.010061  4990 net.cpp:576] BatchNorm21 -> Convolution21 (in-place)
I0612 11:05:14.010337  4990 net.cpp:240] Setting up BatchNorm21
I0612 11:05:14.010349  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.010362  4990 net.cpp:255] Memory required for data: 932708864
I0612 11:05:14.010382  4990 layer_factory.hpp:77] Creating layer Scale21
I0612 11:05:14.010393  4990 net.cpp:190] Creating Layer Scale21
I0612 11:05:14.010399  4990 net.cpp:615] Scale21 <- Convolution21
I0612 11:05:14.010411  4990 net.cpp:576] Scale21 -> Convolution21 (in-place)
I0612 11:05:14.010462  4990 layer_factory.hpp:77] Creating layer Scale21
I0612 11:05:14.010622  4990 net.cpp:240] Setting up Scale21
I0612 11:05:14.010633  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.010638  4990 net.cpp:255] Memory required for data: 941097472
I0612 11:05:14.010651  4990 layer_factory.hpp:77] Creating layer Eltwise10
I0612 11:05:14.010664  4990 net.cpp:190] Creating Layer Eltwise10
I0612 11:05:14.010670  4990 net.cpp:615] Eltwise10 <- Eltwise9_ReLU19_0_split_1
I0612 11:05:14.010677  4990 net.cpp:615] Eltwise10 <- Convolution21
I0612 11:05:14.010685  4990 net.cpp:589] Eltwise10 -> Eltwise10
I0612 11:05:14.010723  4990 net.cpp:240] Setting up Eltwise10
I0612 11:05:14.010733  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.010738  4990 net.cpp:255] Memory required for data: 949486080
I0612 11:05:14.010743  4990 layer_factory.hpp:77] Creating layer ReLU21
I0612 11:05:14.010751  4990 net.cpp:190] Creating Layer ReLU21
I0612 11:05:14.010757  4990 net.cpp:615] ReLU21 <- Eltwise10
I0612 11:05:14.010767  4990 net.cpp:576] ReLU21 -> Eltwise10 (in-place)
I0612 11:05:14.010776  4990 net.cpp:240] Setting up ReLU21
I0612 11:05:14.010783  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.010789  4990 net.cpp:255] Memory required for data: 957874688
I0612 11:05:14.010794  4990 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0612 11:05:14.010802  4990 net.cpp:190] Creating Layer Eltwise10_ReLU21_0_split
I0612 11:05:14.010807  4990 net.cpp:615] Eltwise10_ReLU21_0_split <- Eltwise10
I0612 11:05:14.010814  4990 net.cpp:589] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0612 11:05:14.010825  4990 net.cpp:589] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0612 11:05:14.010876  4990 net.cpp:240] Setting up Eltwise10_ReLU21_0_split
I0612 11:05:14.010886  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.010893  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.010898  4990 net.cpp:255] Memory required for data: 974651904
I0612 11:05:14.010903  4990 layer_factory.hpp:77] Creating layer Convolution22
I0612 11:05:14.010920  4990 net.cpp:190] Creating Layer Convolution22
I0612 11:05:14.010926  4990 net.cpp:615] Convolution22 <- Eltwise10_ReLU21_0_split_0
I0612 11:05:14.010936  4990 net.cpp:589] Convolution22 -> Convolution22
I0612 11:05:14.011373  4990 net.cpp:240] Setting up Convolution22
I0612 11:05:14.011386  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.011392  4990 net.cpp:255] Memory required for data: 983040512
I0612 11:05:14.011405  4990 layer_factory.hpp:77] Creating layer BatchNorm22
I0612 11:05:14.011418  4990 net.cpp:190] Creating Layer BatchNorm22
I0612 11:05:14.011425  4990 net.cpp:615] BatchNorm22 <- Convolution22
I0612 11:05:14.011435  4990 net.cpp:576] BatchNorm22 -> Convolution22 (in-place)
I0612 11:05:14.011706  4990 net.cpp:240] Setting up BatchNorm22
I0612 11:05:14.011718  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.011723  4990 net.cpp:255] Memory required for data: 991429120
I0612 11:05:14.011737  4990 layer_factory.hpp:77] Creating layer Scale22
I0612 11:05:14.011761  4990 net.cpp:190] Creating Layer Scale22
I0612 11:05:14.011768  4990 net.cpp:615] Scale22 <- Convolution22
I0612 11:05:14.011776  4990 net.cpp:576] Scale22 -> Convolution22 (in-place)
I0612 11:05:14.011828  4990 layer_factory.hpp:77] Creating layer Scale22
I0612 11:05:14.011998  4990 net.cpp:240] Setting up Scale22
I0612 11:05:14.012011  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.012017  4990 net.cpp:255] Memory required for data: 999817728
I0612 11:05:14.012030  4990 layer_factory.hpp:77] Creating layer ReLU22
I0612 11:05:14.012039  4990 net.cpp:190] Creating Layer ReLU22
I0612 11:05:14.012051  4990 net.cpp:615] ReLU22 <- Convolution22
I0612 11:05:14.012063  4990 net.cpp:576] ReLU22 -> Convolution22 (in-place)
I0612 11:05:14.012073  4990 net.cpp:240] Setting up ReLU22
I0612 11:05:14.012080  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.012085  4990 net.cpp:255] Memory required for data: 1008206336
I0612 11:05:14.012090  4990 layer_factory.hpp:77] Creating layer Convolution23
I0612 11:05:14.012107  4990 net.cpp:190] Creating Layer Convolution23
I0612 11:05:14.012114  4990 net.cpp:615] Convolution23 <- Convolution22
I0612 11:05:14.012122  4990 net.cpp:589] Convolution23 -> Convolution23
I0612 11:05:14.012558  4990 net.cpp:240] Setting up Convolution23
I0612 11:05:14.012572  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.012576  4990 net.cpp:255] Memory required for data: 1016594944
I0612 11:05:14.012589  4990 layer_factory.hpp:77] Creating layer BatchNorm23
I0612 11:05:14.012605  4990 net.cpp:190] Creating Layer BatchNorm23
I0612 11:05:14.012611  4990 net.cpp:615] BatchNorm23 <- Convolution23
I0612 11:05:14.012619  4990 net.cpp:576] BatchNorm23 -> Convolution23 (in-place)
I0612 11:05:14.012887  4990 net.cpp:240] Setting up BatchNorm23
I0612 11:05:14.012897  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.012902  4990 net.cpp:255] Memory required for data: 1024983552
I0612 11:05:14.012922  4990 layer_factory.hpp:77] Creating layer Scale23
I0612 11:05:14.012931  4990 net.cpp:190] Creating Layer Scale23
I0612 11:05:14.012938  4990 net.cpp:615] Scale23 <- Convolution23
I0612 11:05:14.012945  4990 net.cpp:576] Scale23 -> Convolution23 (in-place)
I0612 11:05:14.012995  4990 layer_factory.hpp:77] Creating layer Scale23
I0612 11:05:14.013157  4990 net.cpp:240] Setting up Scale23
I0612 11:05:14.013169  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.013173  4990 net.cpp:255] Memory required for data: 1033372160
I0612 11:05:14.013186  4990 layer_factory.hpp:77] Creating layer Eltwise11
I0612 11:05:14.013198  4990 net.cpp:190] Creating Layer Eltwise11
I0612 11:05:14.013206  4990 net.cpp:615] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0612 11:05:14.013212  4990 net.cpp:615] Eltwise11 <- Convolution23
I0612 11:05:14.013221  4990 net.cpp:589] Eltwise11 -> Eltwise11
I0612 11:05:14.013257  4990 net.cpp:240] Setting up Eltwise11
I0612 11:05:14.013267  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.013273  4990 net.cpp:255] Memory required for data: 1041760768
I0612 11:05:14.013278  4990 layer_factory.hpp:77] Creating layer ReLU23
I0612 11:05:14.013286  4990 net.cpp:190] Creating Layer ReLU23
I0612 11:05:14.013293  4990 net.cpp:615] ReLU23 <- Eltwise11
I0612 11:05:14.013303  4990 net.cpp:576] ReLU23 -> Eltwise11 (in-place)
I0612 11:05:14.013312  4990 net.cpp:240] Setting up ReLU23
I0612 11:05:14.013319  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.013324  4990 net.cpp:255] Memory required for data: 1050149376
I0612 11:05:14.013330  4990 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0612 11:05:14.013337  4990 net.cpp:190] Creating Layer Eltwise11_ReLU23_0_split
I0612 11:05:14.013344  4990 net.cpp:615] Eltwise11_ReLU23_0_split <- Eltwise11
I0612 11:05:14.013350  4990 net.cpp:589] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0612 11:05:14.013360  4990 net.cpp:589] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0612 11:05:14.013411  4990 net.cpp:240] Setting up Eltwise11_ReLU23_0_split
I0612 11:05:14.013422  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.013429  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.013434  4990 net.cpp:255] Memory required for data: 1066926592
I0612 11:05:14.013439  4990 layer_factory.hpp:77] Creating layer Convolution24
I0612 11:05:14.013453  4990 net.cpp:190] Creating Layer Convolution24
I0612 11:05:14.013458  4990 net.cpp:615] Convolution24 <- Eltwise11_ReLU23_0_split_0
I0612 11:05:14.013470  4990 net.cpp:589] Convolution24 -> Convolution24
I0612 11:05:14.013906  4990 net.cpp:240] Setting up Convolution24
I0612 11:05:14.013923  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.013929  4990 net.cpp:255] Memory required for data: 1075315200
I0612 11:05:14.013942  4990 layer_factory.hpp:77] Creating layer BatchNorm24
I0612 11:05:14.013952  4990 net.cpp:190] Creating Layer BatchNorm24
I0612 11:05:14.013958  4990 net.cpp:615] BatchNorm24 <- Convolution24
I0612 11:05:14.013967  4990 net.cpp:576] BatchNorm24 -> Convolution24 (in-place)
I0612 11:05:14.014245  4990 net.cpp:240] Setting up BatchNorm24
I0612 11:05:14.014257  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.014262  4990 net.cpp:255] Memory required for data: 1083703808
I0612 11:05:14.014277  4990 layer_factory.hpp:77] Creating layer Scale24
I0612 11:05:14.014288  4990 net.cpp:190] Creating Layer Scale24
I0612 11:05:14.014293  4990 net.cpp:615] Scale24 <- Convolution24
I0612 11:05:14.014302  4990 net.cpp:576] Scale24 -> Convolution24 (in-place)
I0612 11:05:14.014367  4990 layer_factory.hpp:77] Creating layer Scale24
I0612 11:05:14.014528  4990 net.cpp:240] Setting up Scale24
I0612 11:05:14.014539  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.014545  4990 net.cpp:255] Memory required for data: 1092092416
I0612 11:05:14.014560  4990 layer_factory.hpp:77] Creating layer ReLU24
I0612 11:05:14.014570  4990 net.cpp:190] Creating Layer ReLU24
I0612 11:05:14.014576  4990 net.cpp:615] ReLU24 <- Convolution24
I0612 11:05:14.014587  4990 net.cpp:576] ReLU24 -> Convolution24 (in-place)
I0612 11:05:14.014596  4990 net.cpp:240] Setting up ReLU24
I0612 11:05:14.014605  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.014610  4990 net.cpp:255] Memory required for data: 1100481024
I0612 11:05:14.014614  4990 layer_factory.hpp:77] Creating layer Convolution25
I0612 11:05:14.014627  4990 net.cpp:190] Creating Layer Convolution25
I0612 11:05:14.014632  4990 net.cpp:615] Convolution25 <- Convolution24
I0612 11:05:14.014644  4990 net.cpp:589] Convolution25 -> Convolution25
I0612 11:05:14.015085  4990 net.cpp:240] Setting up Convolution25
I0612 11:05:14.015099  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.015105  4990 net.cpp:255] Memory required for data: 1108869632
I0612 11:05:14.015117  4990 layer_factory.hpp:77] Creating layer BatchNorm25
I0612 11:05:14.015127  4990 net.cpp:190] Creating Layer BatchNorm25
I0612 11:05:14.015132  4990 net.cpp:615] BatchNorm25 <- Convolution25
I0612 11:05:14.015143  4990 net.cpp:576] BatchNorm25 -> Convolution25 (in-place)
I0612 11:05:14.015414  4990 net.cpp:240] Setting up BatchNorm25
I0612 11:05:14.015425  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.015430  4990 net.cpp:255] Memory required for data: 1117258240
I0612 11:05:14.015446  4990 layer_factory.hpp:77] Creating layer Scale25
I0612 11:05:14.015456  4990 net.cpp:190] Creating Layer Scale25
I0612 11:05:14.015462  4990 net.cpp:615] Scale25 <- Convolution25
I0612 11:05:14.015470  4990 net.cpp:576] Scale25 -> Convolution25 (in-place)
I0612 11:05:14.015522  4990 layer_factory.hpp:77] Creating layer Scale25
I0612 11:05:14.015683  4990 net.cpp:240] Setting up Scale25
I0612 11:05:14.015694  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.015699  4990 net.cpp:255] Memory required for data: 1125646848
I0612 11:05:14.015712  4990 layer_factory.hpp:77] Creating layer Eltwise12
I0612 11:05:14.015724  4990 net.cpp:190] Creating Layer Eltwise12
I0612 11:05:14.015732  4990 net.cpp:615] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0612 11:05:14.015738  4990 net.cpp:615] Eltwise12 <- Convolution25
I0612 11:05:14.015746  4990 net.cpp:589] Eltwise12 -> Eltwise12
I0612 11:05:14.015784  4990 net.cpp:240] Setting up Eltwise12
I0612 11:05:14.015794  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.015799  4990 net.cpp:255] Memory required for data: 1134035456
I0612 11:05:14.015804  4990 layer_factory.hpp:77] Creating layer ReLU25
I0612 11:05:14.015812  4990 net.cpp:190] Creating Layer ReLU25
I0612 11:05:14.015818  4990 net.cpp:615] ReLU25 <- Eltwise12
I0612 11:05:14.015836  4990 net.cpp:576] ReLU25 -> Eltwise12 (in-place)
I0612 11:05:14.015844  4990 net.cpp:240] Setting up ReLU25
I0612 11:05:14.015852  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.015857  4990 net.cpp:255] Memory required for data: 1142424064
I0612 11:05:14.015862  4990 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I0612 11:05:14.015872  4990 net.cpp:190] Creating Layer Eltwise12_ReLU25_0_split
I0612 11:05:14.015877  4990 net.cpp:615] Eltwise12_ReLU25_0_split <- Eltwise12
I0612 11:05:14.015883  4990 net.cpp:589] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I0612 11:05:14.015893  4990 net.cpp:589] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I0612 11:05:14.015954  4990 net.cpp:240] Setting up Eltwise12_ReLU25_0_split
I0612 11:05:14.015967  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.015976  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.015981  4990 net.cpp:255] Memory required for data: 1159201280
I0612 11:05:14.015986  4990 layer_factory.hpp:77] Creating layer Convolution26
I0612 11:05:14.016000  4990 net.cpp:190] Creating Layer Convolution26
I0612 11:05:14.016005  4990 net.cpp:615] Convolution26 <- Eltwise12_ReLU25_0_split_0
I0612 11:05:14.016016  4990 net.cpp:589] Convolution26 -> Convolution26
I0612 11:05:14.016463  4990 net.cpp:240] Setting up Convolution26
I0612 11:05:14.016475  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.016481  4990 net.cpp:255] Memory required for data: 1167589888
I0612 11:05:14.016494  4990 layer_factory.hpp:77] Creating layer BatchNorm26
I0612 11:05:14.016507  4990 net.cpp:190] Creating Layer BatchNorm26
I0612 11:05:14.016513  4990 net.cpp:615] BatchNorm26 <- Convolution26
I0612 11:05:14.016521  4990 net.cpp:576] BatchNorm26 -> Convolution26 (in-place)
I0612 11:05:14.016803  4990 net.cpp:240] Setting up BatchNorm26
I0612 11:05:14.016814  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.016819  4990 net.cpp:255] Memory required for data: 1175978496
I0612 11:05:14.016837  4990 layer_factory.hpp:77] Creating layer Scale26
I0612 11:05:14.016866  4990 net.cpp:190] Creating Layer Scale26
I0612 11:05:14.016873  4990 net.cpp:615] Scale26 <- Convolution26
I0612 11:05:14.016882  4990 net.cpp:576] Scale26 -> Convolution26 (in-place)
I0612 11:05:14.016938  4990 layer_factory.hpp:77] Creating layer Scale26
I0612 11:05:14.017102  4990 net.cpp:240] Setting up Scale26
I0612 11:05:14.017113  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.017118  4990 net.cpp:255] Memory required for data: 1184367104
I0612 11:05:14.017132  4990 layer_factory.hpp:77] Creating layer ReLU26
I0612 11:05:14.017140  4990 net.cpp:190] Creating Layer ReLU26
I0612 11:05:14.017146  4990 net.cpp:615] ReLU26 <- Convolution26
I0612 11:05:14.017158  4990 net.cpp:576] ReLU26 -> Convolution26 (in-place)
I0612 11:05:14.017168  4990 net.cpp:240] Setting up ReLU26
I0612 11:05:14.017175  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.017180  4990 net.cpp:255] Memory required for data: 1192755712
I0612 11:05:14.017186  4990 layer_factory.hpp:77] Creating layer Convolution27
I0612 11:05:14.017199  4990 net.cpp:190] Creating Layer Convolution27
I0612 11:05:14.017204  4990 net.cpp:615] Convolution27 <- Convolution26
I0612 11:05:14.017213  4990 net.cpp:589] Convolution27 -> Convolution27
I0612 11:05:14.017657  4990 net.cpp:240] Setting up Convolution27
I0612 11:05:14.017670  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.017675  4990 net.cpp:255] Memory required for data: 1201144320
I0612 11:05:14.017688  4990 layer_factory.hpp:77] Creating layer BatchNorm27
I0612 11:05:14.017701  4990 net.cpp:190] Creating Layer BatchNorm27
I0612 11:05:14.017707  4990 net.cpp:615] BatchNorm27 <- Convolution27
I0612 11:05:14.017715  4990 net.cpp:576] BatchNorm27 -> Convolution27 (in-place)
I0612 11:05:14.018002  4990 net.cpp:240] Setting up BatchNorm27
I0612 11:05:14.018013  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.018023  4990 net.cpp:255] Memory required for data: 1209532928
I0612 11:05:14.018043  4990 layer_factory.hpp:77] Creating layer Scale27
I0612 11:05:14.018052  4990 net.cpp:190] Creating Layer Scale27
I0612 11:05:14.018059  4990 net.cpp:615] Scale27 <- Convolution27
I0612 11:05:14.018066  4990 net.cpp:576] Scale27 -> Convolution27 (in-place)
I0612 11:05:14.018117  4990 layer_factory.hpp:77] Creating layer Scale27
I0612 11:05:14.018281  4990 net.cpp:240] Setting up Scale27
I0612 11:05:14.018292  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.018297  4990 net.cpp:255] Memory required for data: 1217921536
I0612 11:05:14.018311  4990 layer_factory.hpp:77] Creating layer Eltwise13
I0612 11:05:14.018326  4990 net.cpp:190] Creating Layer Eltwise13
I0612 11:05:14.018333  4990 net.cpp:615] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I0612 11:05:14.018342  4990 net.cpp:615] Eltwise13 <- Convolution27
I0612 11:05:14.018350  4990 net.cpp:589] Eltwise13 -> Eltwise13
I0612 11:05:14.018402  4990 net.cpp:240] Setting up Eltwise13
I0612 11:05:14.018424  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.018429  4990 net.cpp:255] Memory required for data: 1226310144
I0612 11:05:14.018434  4990 layer_factory.hpp:77] Creating layer ReLU27
I0612 11:05:14.018441  4990 net.cpp:190] Creating Layer ReLU27
I0612 11:05:14.018446  4990 net.cpp:615] ReLU27 <- Eltwise13
I0612 11:05:14.018457  4990 net.cpp:576] ReLU27 -> Eltwise13 (in-place)
I0612 11:05:14.018465  4990 net.cpp:240] Setting up ReLU27
I0612 11:05:14.018472  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.018477  4990 net.cpp:255] Memory required for data: 1234698752
I0612 11:05:14.018482  4990 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I0612 11:05:14.018491  4990 net.cpp:190] Creating Layer Eltwise13_ReLU27_0_split
I0612 11:05:14.018494  4990 net.cpp:615] Eltwise13_ReLU27_0_split <- Eltwise13
I0612 11:05:14.018501  4990 net.cpp:589] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I0612 11:05:14.018510  4990 net.cpp:589] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I0612 11:05:14.018560  4990 net.cpp:240] Setting up Eltwise13_ReLU27_0_split
I0612 11:05:14.018569  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.018576  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.018581  4990 net.cpp:255] Memory required for data: 1251475968
I0612 11:05:14.018586  4990 layer_factory.hpp:77] Creating layer Convolution28
I0612 11:05:14.018599  4990 net.cpp:190] Creating Layer Convolution28
I0612 11:05:14.018604  4990 net.cpp:615] Convolution28 <- Eltwise13_ReLU27_0_split_0
I0612 11:05:14.018616  4990 net.cpp:589] Convolution28 -> Convolution28
I0612 11:05:14.019032  4990 net.cpp:240] Setting up Convolution28
I0612 11:05:14.019044  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.019049  4990 net.cpp:255] Memory required for data: 1259864576
I0612 11:05:14.019062  4990 layer_factory.hpp:77] Creating layer BatchNorm28
I0612 11:05:14.019070  4990 net.cpp:190] Creating Layer BatchNorm28
I0612 11:05:14.019076  4990 net.cpp:615] BatchNorm28 <- Convolution28
I0612 11:05:14.019088  4990 net.cpp:576] BatchNorm28 -> Convolution28 (in-place)
I0612 11:05:14.019362  4990 net.cpp:240] Setting up BatchNorm28
I0612 11:05:14.019373  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.019378  4990 net.cpp:255] Memory required for data: 1268253184
I0612 11:05:14.019393  4990 layer_factory.hpp:77] Creating layer Scale28
I0612 11:05:14.019403  4990 net.cpp:190] Creating Layer Scale28
I0612 11:05:14.019409  4990 net.cpp:615] Scale28 <- Convolution28
I0612 11:05:14.019417  4990 net.cpp:576] Scale28 -> Convolution28 (in-place)
I0612 11:05:14.019466  4990 layer_factory.hpp:77] Creating layer Scale28
I0612 11:05:14.019623  4990 net.cpp:240] Setting up Scale28
I0612 11:05:14.019634  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.019639  4990 net.cpp:255] Memory required for data: 1276641792
I0612 11:05:14.019651  4990 layer_factory.hpp:77] Creating layer ReLU28
I0612 11:05:14.019665  4990 net.cpp:190] Creating Layer ReLU28
I0612 11:05:14.019670  4990 net.cpp:615] ReLU28 <- Convolution28
I0612 11:05:14.019681  4990 net.cpp:576] ReLU28 -> Convolution28 (in-place)
I0612 11:05:14.019691  4990 net.cpp:240] Setting up ReLU28
I0612 11:05:14.019698  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.019703  4990 net.cpp:255] Memory required for data: 1285030400
I0612 11:05:14.019708  4990 layer_factory.hpp:77] Creating layer Convolution29
I0612 11:05:14.019723  4990 net.cpp:190] Creating Layer Convolution29
I0612 11:05:14.019729  4990 net.cpp:615] Convolution29 <- Convolution28
I0612 11:05:14.019738  4990 net.cpp:589] Convolution29 -> Convolution29
I0612 11:05:14.020161  4990 net.cpp:240] Setting up Convolution29
I0612 11:05:14.020174  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.020179  4990 net.cpp:255] Memory required for data: 1293419008
I0612 11:05:14.020191  4990 layer_factory.hpp:77] Creating layer BatchNorm29
I0612 11:05:14.020200  4990 net.cpp:190] Creating Layer BatchNorm29
I0612 11:05:14.020205  4990 net.cpp:615] BatchNorm29 <- Convolution29
I0612 11:05:14.020216  4990 net.cpp:576] BatchNorm29 -> Convolution29 (in-place)
I0612 11:05:14.020478  4990 net.cpp:240] Setting up BatchNorm29
I0612 11:05:14.020488  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.020493  4990 net.cpp:255] Memory required for data: 1301807616
I0612 11:05:14.020508  4990 layer_factory.hpp:77] Creating layer Scale29
I0612 11:05:14.020516  4990 net.cpp:190] Creating Layer Scale29
I0612 11:05:14.020521  4990 net.cpp:615] Scale29 <- Convolution29
I0612 11:05:14.020532  4990 net.cpp:576] Scale29 -> Convolution29 (in-place)
I0612 11:05:14.020578  4990 layer_factory.hpp:77] Creating layer Scale29
I0612 11:05:14.020732  4990 net.cpp:240] Setting up Scale29
I0612 11:05:14.020743  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.020748  4990 net.cpp:255] Memory required for data: 1310196224
I0612 11:05:14.020761  4990 layer_factory.hpp:77] Creating layer Eltwise14
I0612 11:05:14.020771  4990 net.cpp:190] Creating Layer Eltwise14
I0612 11:05:14.020778  4990 net.cpp:615] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I0612 11:05:14.020786  4990 net.cpp:615] Eltwise14 <- Convolution29
I0612 11:05:14.020792  4990 net.cpp:589] Eltwise14 -> Eltwise14
I0612 11:05:14.020831  4990 net.cpp:240] Setting up Eltwise14
I0612 11:05:14.020841  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.020846  4990 net.cpp:255] Memory required for data: 1318584832
I0612 11:05:14.020851  4990 layer_factory.hpp:77] Creating layer ReLU29
I0612 11:05:14.020859  4990 net.cpp:190] Creating Layer ReLU29
I0612 11:05:14.020864  4990 net.cpp:615] ReLU29 <- Eltwise14
I0612 11:05:14.020874  4990 net.cpp:576] ReLU29 -> Eltwise14 (in-place)
I0612 11:05:14.020882  4990 net.cpp:240] Setting up ReLU29
I0612 11:05:14.020889  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.020895  4990 net.cpp:255] Memory required for data: 1326973440
I0612 11:05:14.020900  4990 layer_factory.hpp:77] Creating layer Eltwise14_ReLU29_0_split
I0612 11:05:14.020907  4990 net.cpp:190] Creating Layer Eltwise14_ReLU29_0_split
I0612 11:05:14.020912  4990 net.cpp:615] Eltwise14_ReLU29_0_split <- Eltwise14
I0612 11:05:14.020920  4990 net.cpp:589] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_0
I0612 11:05:14.020927  4990 net.cpp:589] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_1
I0612 11:05:14.020978  4990 net.cpp:240] Setting up Eltwise14_ReLU29_0_split
I0612 11:05:14.020987  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.020993  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.020998  4990 net.cpp:255] Memory required for data: 1343750656
I0612 11:05:14.021003  4990 layer_factory.hpp:77] Creating layer Convolution30
I0612 11:05:14.021018  4990 net.cpp:190] Creating Layer Convolution30
I0612 11:05:14.021023  4990 net.cpp:615] Convolution30 <- Eltwise14_ReLU29_0_split_0
I0612 11:05:14.021033  4990 net.cpp:589] Convolution30 -> Convolution30
I0612 11:05:14.021457  4990 net.cpp:240] Setting up Convolution30
I0612 11:05:14.021471  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.021476  4990 net.cpp:255] Memory required for data: 1352139264
I0612 11:05:14.021487  4990 layer_factory.hpp:77] Creating layer BatchNorm30
I0612 11:05:14.021502  4990 net.cpp:190] Creating Layer BatchNorm30
I0612 11:05:14.021507  4990 net.cpp:615] BatchNorm30 <- Convolution30
I0612 11:05:14.021519  4990 net.cpp:576] BatchNorm30 -> Convolution30 (in-place)
I0612 11:05:14.021776  4990 net.cpp:240] Setting up BatchNorm30
I0612 11:05:14.021787  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.021792  4990 net.cpp:255] Memory required for data: 1360527872
I0612 11:05:14.021806  4990 layer_factory.hpp:77] Creating layer Scale30
I0612 11:05:14.021818  4990 net.cpp:190] Creating Layer Scale30
I0612 11:05:14.021824  4990 net.cpp:615] Scale30 <- Convolution30
I0612 11:05:14.021831  4990 net.cpp:576] Scale30 -> Convolution30 (in-place)
I0612 11:05:14.021879  4990 layer_factory.hpp:77] Creating layer Scale30
I0612 11:05:14.022032  4990 net.cpp:240] Setting up Scale30
I0612 11:05:14.022043  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.022048  4990 net.cpp:255] Memory required for data: 1368916480
I0612 11:05:14.022059  4990 layer_factory.hpp:77] Creating layer ReLU30
I0612 11:05:14.022068  4990 net.cpp:190] Creating Layer ReLU30
I0612 11:05:14.022073  4990 net.cpp:615] ReLU30 <- Convolution30
I0612 11:05:14.022085  4990 net.cpp:576] ReLU30 -> Convolution30 (in-place)
I0612 11:05:14.022095  4990 net.cpp:240] Setting up ReLU30
I0612 11:05:14.022101  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.022106  4990 net.cpp:255] Memory required for data: 1377305088
I0612 11:05:14.022111  4990 layer_factory.hpp:77] Creating layer Convolution31
I0612 11:05:14.022126  4990 net.cpp:190] Creating Layer Convolution31
I0612 11:05:14.022131  4990 net.cpp:615] Convolution31 <- Convolution30
I0612 11:05:14.022140  4990 net.cpp:589] Convolution31 -> Convolution31
I0612 11:05:14.022573  4990 net.cpp:240] Setting up Convolution31
I0612 11:05:14.022588  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.022593  4990 net.cpp:255] Memory required for data: 1385693696
I0612 11:05:14.022604  4990 layer_factory.hpp:77] Creating layer BatchNorm31
I0612 11:05:14.022616  4990 net.cpp:190] Creating Layer BatchNorm31
I0612 11:05:14.022622  4990 net.cpp:615] BatchNorm31 <- Convolution31
I0612 11:05:14.022632  4990 net.cpp:576] BatchNorm31 -> Convolution31 (in-place)
I0612 11:05:14.022894  4990 net.cpp:240] Setting up BatchNorm31
I0612 11:05:14.022905  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.022910  4990 net.cpp:255] Memory required for data: 1394082304
I0612 11:05:14.022927  4990 layer_factory.hpp:77] Creating layer Scale31
I0612 11:05:14.022936  4990 net.cpp:190] Creating Layer Scale31
I0612 11:05:14.022941  4990 net.cpp:615] Scale31 <- Convolution31
I0612 11:05:14.022949  4990 net.cpp:576] Scale31 -> Convolution31 (in-place)
I0612 11:05:14.023000  4990 layer_factory.hpp:77] Creating layer Scale31
I0612 11:05:14.023155  4990 net.cpp:240] Setting up Scale31
I0612 11:05:14.023165  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.023170  4990 net.cpp:255] Memory required for data: 1402470912
I0612 11:05:14.023182  4990 layer_factory.hpp:77] Creating layer Eltwise15
I0612 11:05:14.023191  4990 net.cpp:190] Creating Layer Eltwise15
I0612 11:05:14.023197  4990 net.cpp:615] Eltwise15 <- Eltwise14_ReLU29_0_split_1
I0612 11:05:14.023208  4990 net.cpp:615] Eltwise15 <- Convolution31
I0612 11:05:14.023216  4990 net.cpp:589] Eltwise15 -> Eltwise15
I0612 11:05:14.023252  4990 net.cpp:240] Setting up Eltwise15
I0612 11:05:14.023262  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.023267  4990 net.cpp:255] Memory required for data: 1410859520
I0612 11:05:14.023272  4990 layer_factory.hpp:77] Creating layer ReLU31
I0612 11:05:14.023279  4990 net.cpp:190] Creating Layer ReLU31
I0612 11:05:14.023289  4990 net.cpp:615] ReLU31 <- Eltwise15
I0612 11:05:14.023296  4990 net.cpp:576] ReLU31 -> Eltwise15 (in-place)
I0612 11:05:14.023305  4990 net.cpp:240] Setting up ReLU31
I0612 11:05:14.023313  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.023316  4990 net.cpp:255] Memory required for data: 1419248128
I0612 11:05:14.023321  4990 layer_factory.hpp:77] Creating layer Eltwise15_ReLU31_0_split
I0612 11:05:14.023332  4990 net.cpp:190] Creating Layer Eltwise15_ReLU31_0_split
I0612 11:05:14.023337  4990 net.cpp:615] Eltwise15_ReLU31_0_split <- Eltwise15
I0612 11:05:14.023344  4990 net.cpp:589] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_0
I0612 11:05:14.023353  4990 net.cpp:589] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_1
I0612 11:05:14.023402  4990 net.cpp:240] Setting up Eltwise15_ReLU31_0_split
I0612 11:05:14.023411  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.023418  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.023423  4990 net.cpp:255] Memory required for data: 1436025344
I0612 11:05:14.023428  4990 layer_factory.hpp:77] Creating layer Convolution32
I0612 11:05:14.023440  4990 net.cpp:190] Creating Layer Convolution32
I0612 11:05:14.023447  4990 net.cpp:615] Convolution32 <- Eltwise15_ReLU31_0_split_0
I0612 11:05:14.023455  4990 net.cpp:589] Convolution32 -> Convolution32
I0612 11:05:14.023869  4990 net.cpp:240] Setting up Convolution32
I0612 11:05:14.023881  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.023886  4990 net.cpp:255] Memory required for data: 1444413952
I0612 11:05:14.023898  4990 layer_factory.hpp:77] Creating layer BatchNorm32
I0612 11:05:14.023912  4990 net.cpp:190] Creating Layer BatchNorm32
I0612 11:05:14.023918  4990 net.cpp:615] BatchNorm32 <- Convolution32
I0612 11:05:14.023926  4990 net.cpp:576] BatchNorm32 -> Convolution32 (in-place)
I0612 11:05:14.024181  4990 net.cpp:240] Setting up BatchNorm32
I0612 11:05:14.024193  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.024197  4990 net.cpp:255] Memory required for data: 1452802560
I0612 11:05:14.024211  4990 layer_factory.hpp:77] Creating layer Scale32
I0612 11:05:14.024220  4990 net.cpp:190] Creating Layer Scale32
I0612 11:05:14.024225  4990 net.cpp:615] Scale32 <- Convolution32
I0612 11:05:14.024233  4990 net.cpp:576] Scale32 -> Convolution32 (in-place)
I0612 11:05:14.024283  4990 layer_factory.hpp:77] Creating layer Scale32
I0612 11:05:14.024440  4990 net.cpp:240] Setting up Scale32
I0612 11:05:14.024449  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.024454  4990 net.cpp:255] Memory required for data: 1461191168
I0612 11:05:14.024471  4990 layer_factory.hpp:77] Creating layer ReLU32
I0612 11:05:14.024480  4990 net.cpp:190] Creating Layer ReLU32
I0612 11:05:14.024487  4990 net.cpp:615] ReLU32 <- Convolution32
I0612 11:05:14.024497  4990 net.cpp:576] ReLU32 -> Convolution32 (in-place)
I0612 11:05:14.024505  4990 net.cpp:240] Setting up ReLU32
I0612 11:05:14.024513  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.024516  4990 net.cpp:255] Memory required for data: 1469579776
I0612 11:05:14.024521  4990 layer_factory.hpp:77] Creating layer Convolution33
I0612 11:05:14.024534  4990 net.cpp:190] Creating Layer Convolution33
I0612 11:05:14.024539  4990 net.cpp:615] Convolution33 <- Convolution32
I0612 11:05:14.024550  4990 net.cpp:589] Convolution33 -> Convolution33
I0612 11:05:14.024966  4990 net.cpp:240] Setting up Convolution33
I0612 11:05:14.024977  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.024982  4990 net.cpp:255] Memory required for data: 1477968384
I0612 11:05:14.024994  4990 layer_factory.hpp:77] Creating layer BatchNorm33
I0612 11:05:14.025003  4990 net.cpp:190] Creating Layer BatchNorm33
I0612 11:05:14.025009  4990 net.cpp:615] BatchNorm33 <- Convolution33
I0612 11:05:14.025019  4990 net.cpp:576] BatchNorm33 -> Convolution33 (in-place)
I0612 11:05:14.025279  4990 net.cpp:240] Setting up BatchNorm33
I0612 11:05:14.025288  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.025297  4990 net.cpp:255] Memory required for data: 1486356992
I0612 11:05:14.025312  4990 layer_factory.hpp:77] Creating layer Scale33
I0612 11:05:14.025321  4990 net.cpp:190] Creating Layer Scale33
I0612 11:05:14.025326  4990 net.cpp:615] Scale33 <- Convolution33
I0612 11:05:14.025334  4990 net.cpp:576] Scale33 -> Convolution33 (in-place)
I0612 11:05:14.025384  4990 layer_factory.hpp:77] Creating layer Scale33
I0612 11:05:14.025537  4990 net.cpp:240] Setting up Scale33
I0612 11:05:14.025547  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.025552  4990 net.cpp:255] Memory required for data: 1494745600
I0612 11:05:14.025564  4990 layer_factory.hpp:77] Creating layer Eltwise16
I0612 11:05:14.025576  4990 net.cpp:190] Creating Layer Eltwise16
I0612 11:05:14.025583  4990 net.cpp:615] Eltwise16 <- Eltwise15_ReLU31_0_split_1
I0612 11:05:14.025590  4990 net.cpp:615] Eltwise16 <- Convolution33
I0612 11:05:14.025598  4990 net.cpp:589] Eltwise16 -> Eltwise16
I0612 11:05:14.025629  4990 net.cpp:240] Setting up Eltwise16
I0612 11:05:14.025638  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.025642  4990 net.cpp:255] Memory required for data: 1503134208
I0612 11:05:14.025648  4990 layer_factory.hpp:77] Creating layer ReLU33
I0612 11:05:14.025660  4990 net.cpp:190] Creating Layer ReLU33
I0612 11:05:14.025665  4990 net.cpp:615] ReLU33 <- Eltwise16
I0612 11:05:14.025674  4990 net.cpp:576] ReLU33 -> Eltwise16 (in-place)
I0612 11:05:14.025683  4990 net.cpp:240] Setting up ReLU33
I0612 11:05:14.025691  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.025696  4990 net.cpp:255] Memory required for data: 1511522816
I0612 11:05:14.025701  4990 layer_factory.hpp:77] Creating layer Eltwise16_ReLU33_0_split
I0612 11:05:14.025708  4990 net.cpp:190] Creating Layer Eltwise16_ReLU33_0_split
I0612 11:05:14.025712  4990 net.cpp:615] Eltwise16_ReLU33_0_split <- Eltwise16
I0612 11:05:14.025719  4990 net.cpp:589] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_0
I0612 11:05:14.025728  4990 net.cpp:589] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_1
I0612 11:05:14.025776  4990 net.cpp:240] Setting up Eltwise16_ReLU33_0_split
I0612 11:05:14.025785  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.025791  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.025796  4990 net.cpp:255] Memory required for data: 1528300032
I0612 11:05:14.025801  4990 layer_factory.hpp:77] Creating layer Convolution34
I0612 11:05:14.025815  4990 net.cpp:190] Creating Layer Convolution34
I0612 11:05:14.025821  4990 net.cpp:615] Convolution34 <- Eltwise16_ReLU33_0_split_0
I0612 11:05:14.025830  4990 net.cpp:589] Convolution34 -> Convolution34
I0612 11:05:14.026253  4990 net.cpp:240] Setting up Convolution34
I0612 11:05:14.026265  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.026270  4990 net.cpp:255] Memory required for data: 1536688640
I0612 11:05:14.026283  4990 layer_factory.hpp:77] Creating layer BatchNorm34
I0612 11:05:14.026295  4990 net.cpp:190] Creating Layer BatchNorm34
I0612 11:05:14.026301  4990 net.cpp:615] BatchNorm34 <- Convolution34
I0612 11:05:14.026309  4990 net.cpp:576] BatchNorm34 -> Convolution34 (in-place)
I0612 11:05:14.026581  4990 net.cpp:240] Setting up BatchNorm34
I0612 11:05:14.026592  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.026597  4990 net.cpp:255] Memory required for data: 1545077248
I0612 11:05:14.026612  4990 layer_factory.hpp:77] Creating layer Scale34
I0612 11:05:14.026629  4990 net.cpp:190] Creating Layer Scale34
I0612 11:05:14.026636  4990 net.cpp:615] Scale34 <- Convolution34
I0612 11:05:14.026643  4990 net.cpp:576] Scale34 -> Convolution34 (in-place)
I0612 11:05:14.026690  4990 layer_factory.hpp:77] Creating layer Scale34
I0612 11:05:14.026845  4990 net.cpp:240] Setting up Scale34
I0612 11:05:14.026859  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.026865  4990 net.cpp:255] Memory required for data: 1553465856
I0612 11:05:14.026880  4990 layer_factory.hpp:77] Creating layer ReLU34
I0612 11:05:14.026890  4990 net.cpp:190] Creating Layer ReLU34
I0612 11:05:14.026895  4990 net.cpp:615] ReLU34 <- Convolution34
I0612 11:05:14.026903  4990 net.cpp:576] ReLU34 -> Convolution34 (in-place)
I0612 11:05:14.026912  4990 net.cpp:240] Setting up ReLU34
I0612 11:05:14.026919  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.026924  4990 net.cpp:255] Memory required for data: 1561854464
I0612 11:05:14.026928  4990 layer_factory.hpp:77] Creating layer Convolution35
I0612 11:05:14.026945  4990 net.cpp:190] Creating Layer Convolution35
I0612 11:05:14.026952  4990 net.cpp:615] Convolution35 <- Convolution34
I0612 11:05:14.026962  4990 net.cpp:589] Convolution35 -> Convolution35
I0612 11:05:14.027384  4990 net.cpp:240] Setting up Convolution35
I0612 11:05:14.027395  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.027400  4990 net.cpp:255] Memory required for data: 1570243072
I0612 11:05:14.027412  4990 layer_factory.hpp:77] Creating layer BatchNorm35
I0612 11:05:14.027426  4990 net.cpp:190] Creating Layer BatchNorm35
I0612 11:05:14.027431  4990 net.cpp:615] BatchNorm35 <- Convolution35
I0612 11:05:14.027441  4990 net.cpp:576] BatchNorm35 -> Convolution35 (in-place)
I0612 11:05:14.027696  4990 net.cpp:240] Setting up BatchNorm35
I0612 11:05:14.027707  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.027711  4990 net.cpp:255] Memory required for data: 1578631680
I0612 11:05:14.027726  4990 layer_factory.hpp:77] Creating layer Scale35
I0612 11:05:14.027739  4990 net.cpp:190] Creating Layer Scale35
I0612 11:05:14.027745  4990 net.cpp:615] Scale35 <- Convolution35
I0612 11:05:14.027751  4990 net.cpp:576] Scale35 -> Convolution35 (in-place)
I0612 11:05:14.027801  4990 layer_factory.hpp:77] Creating layer Scale35
I0612 11:05:14.027956  4990 net.cpp:240] Setting up Scale35
I0612 11:05:14.027966  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.027971  4990 net.cpp:255] Memory required for data: 1587020288
I0612 11:05:14.027982  4990 layer_factory.hpp:77] Creating layer Eltwise17
I0612 11:05:14.027992  4990 net.cpp:190] Creating Layer Eltwise17
I0612 11:05:14.027997  4990 net.cpp:615] Eltwise17 <- Eltwise16_ReLU33_0_split_1
I0612 11:05:14.028004  4990 net.cpp:615] Eltwise17 <- Convolution35
I0612 11:05:14.028015  4990 net.cpp:589] Eltwise17 -> Eltwise17
I0612 11:05:14.028053  4990 net.cpp:240] Setting up Eltwise17
I0612 11:05:14.028061  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.028066  4990 net.cpp:255] Memory required for data: 1595408896
I0612 11:05:14.028071  4990 layer_factory.hpp:77] Creating layer ReLU35
I0612 11:05:14.028079  4990 net.cpp:190] Creating Layer ReLU35
I0612 11:05:14.028084  4990 net.cpp:615] ReLU35 <- Eltwise17
I0612 11:05:14.028091  4990 net.cpp:576] ReLU35 -> Eltwise17 (in-place)
I0612 11:05:14.028100  4990 net.cpp:240] Setting up ReLU35
I0612 11:05:14.028106  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.028111  4990 net.cpp:255] Memory required for data: 1603797504
I0612 11:05:14.028115  4990 layer_factory.hpp:77] Creating layer Eltwise17_ReLU35_0_split
I0612 11:05:14.028123  4990 net.cpp:190] Creating Layer Eltwise17_ReLU35_0_split
I0612 11:05:14.028128  4990 net.cpp:615] Eltwise17_ReLU35_0_split <- Eltwise17
I0612 11:05:14.028137  4990 net.cpp:589] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_0
I0612 11:05:14.028147  4990 net.cpp:589] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_1
I0612 11:05:14.028197  4990 net.cpp:240] Setting up Eltwise17_ReLU35_0_split
I0612 11:05:14.028206  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.028213  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.028218  4990 net.cpp:255] Memory required for data: 1620574720
I0612 11:05:14.028223  4990 layer_factory.hpp:77] Creating layer Convolution36
I0612 11:05:14.028234  4990 net.cpp:190] Creating Layer Convolution36
I0612 11:05:14.028240  4990 net.cpp:615] Convolution36 <- Eltwise17_ReLU35_0_split_0
I0612 11:05:14.028256  4990 net.cpp:589] Convolution36 -> Convolution36
I0612 11:05:14.028692  4990 net.cpp:240] Setting up Convolution36
I0612 11:05:14.028704  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.028709  4990 net.cpp:255] Memory required for data: 1628963328
I0612 11:05:14.028722  4990 layer_factory.hpp:77] Creating layer BatchNorm36
I0612 11:05:14.028733  4990 net.cpp:190] Creating Layer BatchNorm36
I0612 11:05:14.028739  4990 net.cpp:615] BatchNorm36 <- Convolution36
I0612 11:05:14.028748  4990 net.cpp:576] BatchNorm36 -> Convolution36 (in-place)
I0612 11:05:14.029011  4990 net.cpp:240] Setting up BatchNorm36
I0612 11:05:14.029022  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.029027  4990 net.cpp:255] Memory required for data: 1637351936
I0612 11:05:14.029042  4990 layer_factory.hpp:77] Creating layer Scale36
I0612 11:05:14.029052  4990 net.cpp:190] Creating Layer Scale36
I0612 11:05:14.029057  4990 net.cpp:615] Scale36 <- Convolution36
I0612 11:05:14.029064  4990 net.cpp:576] Scale36 -> Convolution36 (in-place)
I0612 11:05:14.029114  4990 layer_factory.hpp:77] Creating layer Scale36
I0612 11:05:14.029271  4990 net.cpp:240] Setting up Scale36
I0612 11:05:14.029281  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.029286  4990 net.cpp:255] Memory required for data: 1645740544
I0612 11:05:14.029297  4990 layer_factory.hpp:77] Creating layer ReLU36
I0612 11:05:14.029309  4990 net.cpp:190] Creating Layer ReLU36
I0612 11:05:14.029315  4990 net.cpp:615] ReLU36 <- Convolution36
I0612 11:05:14.029323  4990 net.cpp:576] ReLU36 -> Convolution36 (in-place)
I0612 11:05:14.029331  4990 net.cpp:240] Setting up ReLU36
I0612 11:05:14.029338  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.029343  4990 net.cpp:255] Memory required for data: 1654129152
I0612 11:05:14.029348  4990 layer_factory.hpp:77] Creating layer Convolution37
I0612 11:05:14.029362  4990 net.cpp:190] Creating Layer Convolution37
I0612 11:05:14.029367  4990 net.cpp:615] Convolution37 <- Convolution36
I0612 11:05:14.029379  4990 net.cpp:589] Convolution37 -> Convolution37
I0612 11:05:14.029793  4990 net.cpp:240] Setting up Convolution37
I0612 11:05:14.029805  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.029810  4990 net.cpp:255] Memory required for data: 1662517760
I0612 11:05:14.029822  4990 layer_factory.hpp:77] Creating layer BatchNorm37
I0612 11:05:14.029839  4990 net.cpp:190] Creating Layer BatchNorm37
I0612 11:05:14.029844  4990 net.cpp:615] BatchNorm37 <- Convolution37
I0612 11:05:14.029851  4990 net.cpp:576] BatchNorm37 -> Convolution37 (in-place)
I0612 11:05:14.030108  4990 net.cpp:240] Setting up BatchNorm37
I0612 11:05:14.030119  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.030124  4990 net.cpp:255] Memory required for data: 1670906368
I0612 11:05:14.030177  4990 layer_factory.hpp:77] Creating layer Scale37
I0612 11:05:14.030189  4990 net.cpp:190] Creating Layer Scale37
I0612 11:05:14.030195  4990 net.cpp:615] Scale37 <- Convolution37
I0612 11:05:14.030203  4990 net.cpp:576] Scale37 -> Convolution37 (in-place)
I0612 11:05:14.030256  4990 layer_factory.hpp:77] Creating layer Scale37
I0612 11:05:14.030427  4990 net.cpp:240] Setting up Scale37
I0612 11:05:14.030441  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.030446  4990 net.cpp:255] Memory required for data: 1679294976
I0612 11:05:14.030457  4990 layer_factory.hpp:77] Creating layer Eltwise18
I0612 11:05:14.030467  4990 net.cpp:190] Creating Layer Eltwise18
I0612 11:05:14.030473  4990 net.cpp:615] Eltwise18 <- Eltwise17_ReLU35_0_split_1
I0612 11:05:14.030479  4990 net.cpp:615] Eltwise18 <- Convolution37
I0612 11:05:14.030490  4990 net.cpp:589] Eltwise18 -> Eltwise18
I0612 11:05:14.030524  4990 net.cpp:240] Setting up Eltwise18
I0612 11:05:14.030536  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.030541  4990 net.cpp:255] Memory required for data: 1687683584
I0612 11:05:14.030546  4990 layer_factory.hpp:77] Creating layer ReLU37
I0612 11:05:14.030560  4990 net.cpp:190] Creating Layer ReLU37
I0612 11:05:14.030565  4990 net.cpp:615] ReLU37 <- Eltwise18
I0612 11:05:14.030571  4990 net.cpp:576] ReLU37 -> Eltwise18 (in-place)
I0612 11:05:14.030580  4990 net.cpp:240] Setting up ReLU37
I0612 11:05:14.030586  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.030591  4990 net.cpp:255] Memory required for data: 1696072192
I0612 11:05:14.030596  4990 layer_factory.hpp:77] Creating layer Eltwise18_ReLU37_0_split
I0612 11:05:14.030604  4990 net.cpp:190] Creating Layer Eltwise18_ReLU37_0_split
I0612 11:05:14.030608  4990 net.cpp:615] Eltwise18_ReLU37_0_split <- Eltwise18
I0612 11:05:14.030619  4990 net.cpp:589] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_0
I0612 11:05:14.030628  4990 net.cpp:589] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_1
I0612 11:05:14.030689  4990 net.cpp:240] Setting up Eltwise18_ReLU37_0_split
I0612 11:05:14.030696  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.030702  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.030707  4990 net.cpp:255] Memory required for data: 1712849408
I0612 11:05:14.030711  4990 layer_factory.hpp:77] Creating layer Pooling1
I0612 11:05:14.030725  4990 net.cpp:190] Creating Layer Pooling1
I0612 11:05:14.030730  4990 net.cpp:615] Pooling1 <- Eltwise18_ReLU37_0_split_0
I0612 11:05:14.030737  4990 net.cpp:589] Pooling1 -> Pooling1
I0612 11:05:14.030786  4990 net.cpp:240] Setting up Pooling1
I0612 11:05:14.030794  4990 net.cpp:247] Top shape: 128 16 16 16 (524288)
I0612 11:05:14.030799  4990 net.cpp:255] Memory required for data: 1714946560
I0612 11:05:14.030804  4990 layer_factory.hpp:77] Creating layer Input1
I0612 11:05:14.030818  4990 net.cpp:190] Creating Layer Input1
I0612 11:05:14.030825  4990 net.cpp:589] Input1 -> Input1
I0612 11:05:14.030864  4990 net.cpp:240] Setting up Input1
I0612 11:05:14.030874  4990 net.cpp:247] Top shape: 128 16 16 16 (524288)
I0612 11:05:14.030879  4990 net.cpp:255] Memory required for data: 1717043712
I0612 11:05:14.030882  4990 layer_factory.hpp:77] Creating layer Concat1
I0612 11:05:14.030891  4990 net.cpp:190] Creating Layer Concat1
I0612 11:05:14.030897  4990 net.cpp:615] Concat1 <- Pooling1
I0612 11:05:14.030903  4990 net.cpp:615] Concat1 <- Input1
I0612 11:05:14.030917  4990 net.cpp:589] Concat1 -> Concat1
I0612 11:05:14.030956  4990 net.cpp:240] Setting up Concat1
I0612 11:05:14.030964  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.030969  4990 net.cpp:255] Memory required for data: 1721238016
I0612 11:05:14.030974  4990 layer_factory.hpp:77] Creating layer Convolution38
I0612 11:05:14.030988  4990 net.cpp:190] Creating Layer Convolution38
I0612 11:05:14.030995  4990 net.cpp:615] Convolution38 <- Eltwise18_ReLU37_0_split_1
I0612 11:05:14.031004  4990 net.cpp:589] Convolution38 -> Convolution38
I0612 11:05:14.032331  4990 net.cpp:240] Setting up Convolution38
I0612 11:05:14.032351  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.032356  4990 net.cpp:255] Memory required for data: 1725432320
I0612 11:05:14.032371  4990 layer_factory.hpp:77] Creating layer BatchNorm38
I0612 11:05:14.032382  4990 net.cpp:190] Creating Layer BatchNorm38
I0612 11:05:14.032389  4990 net.cpp:615] BatchNorm38 <- Convolution38
I0612 11:05:14.032397  4990 net.cpp:576] BatchNorm38 -> Convolution38 (in-place)
I0612 11:05:14.032649  4990 net.cpp:240] Setting up BatchNorm38
I0612 11:05:14.032660  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.032665  4990 net.cpp:255] Memory required for data: 1729626624
I0612 11:05:14.032681  4990 layer_factory.hpp:77] Creating layer Scale38
I0612 11:05:14.032691  4990 net.cpp:190] Creating Layer Scale38
I0612 11:05:14.032696  4990 net.cpp:615] Scale38 <- Convolution38
I0612 11:05:14.032703  4990 net.cpp:576] Scale38 -> Convolution38 (in-place)
I0612 11:05:14.032752  4990 layer_factory.hpp:77] Creating layer Scale38
I0612 11:05:14.032902  4990 net.cpp:240] Setting up Scale38
I0612 11:05:14.032912  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.032920  4990 net.cpp:255] Memory required for data: 1733820928
I0612 11:05:14.032935  4990 layer_factory.hpp:77] Creating layer ReLU38
I0612 11:05:14.032944  4990 net.cpp:190] Creating Layer ReLU38
I0612 11:05:14.032950  4990 net.cpp:615] ReLU38 <- Convolution38
I0612 11:05:14.032958  4990 net.cpp:576] ReLU38 -> Convolution38 (in-place)
I0612 11:05:14.032968  4990 net.cpp:240] Setting up ReLU38
I0612 11:05:14.032975  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.032980  4990 net.cpp:255] Memory required for data: 1738015232
I0612 11:05:14.032984  4990 layer_factory.hpp:77] Creating layer Convolution39
I0612 11:05:14.032997  4990 net.cpp:190] Creating Layer Convolution39
I0612 11:05:14.033002  4990 net.cpp:615] Convolution39 <- Convolution38
I0612 11:05:14.033016  4990 net.cpp:589] Convolution39 -> Convolution39
I0612 11:05:14.033730  4990 net.cpp:240] Setting up Convolution39
I0612 11:05:14.033741  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.033746  4990 net.cpp:255] Memory required for data: 1742209536
I0612 11:05:14.033758  4990 layer_factory.hpp:77] Creating layer BatchNorm39
I0612 11:05:14.033767  4990 net.cpp:190] Creating Layer BatchNorm39
I0612 11:05:14.033772  4990 net.cpp:615] BatchNorm39 <- Convolution39
I0612 11:05:14.033782  4990 net.cpp:576] BatchNorm39 -> Convolution39 (in-place)
I0612 11:05:14.034029  4990 net.cpp:240] Setting up BatchNorm39
I0612 11:05:14.034039  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.034044  4990 net.cpp:255] Memory required for data: 1746403840
I0612 11:05:14.034059  4990 layer_factory.hpp:77] Creating layer Scale39
I0612 11:05:14.034067  4990 net.cpp:190] Creating Layer Scale39
I0612 11:05:14.034072  4990 net.cpp:615] Scale39 <- Convolution39
I0612 11:05:14.034080  4990 net.cpp:576] Scale39 -> Convolution39 (in-place)
I0612 11:05:14.034126  4990 layer_factory.hpp:77] Creating layer Scale39
I0612 11:05:14.034276  4990 net.cpp:240] Setting up Scale39
I0612 11:05:14.034286  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.034291  4990 net.cpp:255] Memory required for data: 1750598144
I0612 11:05:14.034301  4990 layer_factory.hpp:77] Creating layer Eltwise19
I0612 11:05:14.034310  4990 net.cpp:190] Creating Layer Eltwise19
I0612 11:05:14.034317  4990 net.cpp:615] Eltwise19 <- Concat1
I0612 11:05:14.034327  4990 net.cpp:615] Eltwise19 <- Convolution39
I0612 11:05:14.034334  4990 net.cpp:589] Eltwise19 -> Eltwise19
I0612 11:05:14.034370  4990 net.cpp:240] Setting up Eltwise19
I0612 11:05:14.034380  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.034384  4990 net.cpp:255] Memory required for data: 1754792448
I0612 11:05:14.034389  4990 layer_factory.hpp:77] Creating layer ReLU39
I0612 11:05:14.034402  4990 net.cpp:190] Creating Layer ReLU39
I0612 11:05:14.034409  4990 net.cpp:615] ReLU39 <- Eltwise19
I0612 11:05:14.034415  4990 net.cpp:576] ReLU39 -> Eltwise19 (in-place)
I0612 11:05:14.034423  4990 net.cpp:240] Setting up ReLU39
I0612 11:05:14.034430  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.034435  4990 net.cpp:255] Memory required for data: 1758986752
I0612 11:05:14.034440  4990 layer_factory.hpp:77] Creating layer Eltwise19_ReLU39_0_split
I0612 11:05:14.034446  4990 net.cpp:190] Creating Layer Eltwise19_ReLU39_0_split
I0612 11:05:14.034451  4990 net.cpp:615] Eltwise19_ReLU39_0_split <- Eltwise19
I0612 11:05:14.034461  4990 net.cpp:589] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_0
I0612 11:05:14.034469  4990 net.cpp:589] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_1
I0612 11:05:14.034518  4990 net.cpp:240] Setting up Eltwise19_ReLU39_0_split
I0612 11:05:14.034528  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.034533  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.034538  4990 net.cpp:255] Memory required for data: 1767375360
I0612 11:05:14.034543  4990 layer_factory.hpp:77] Creating layer Convolution40
I0612 11:05:14.034556  4990 net.cpp:190] Creating Layer Convolution40
I0612 11:05:14.034566  4990 net.cpp:615] Convolution40 <- Eltwise19_ReLU39_0_split_0
I0612 11:05:14.034575  4990 net.cpp:589] Convolution40 -> Convolution40
I0612 11:05:14.035291  4990 net.cpp:240] Setting up Convolution40
I0612 11:05:14.035303  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.035308  4990 net.cpp:255] Memory required for data: 1771569664
I0612 11:05:14.035320  4990 layer_factory.hpp:77] Creating layer BatchNorm40
I0612 11:05:14.035332  4990 net.cpp:190] Creating Layer BatchNorm40
I0612 11:05:14.035338  4990 net.cpp:615] BatchNorm40 <- Convolution40
I0612 11:05:14.035346  4990 net.cpp:576] BatchNorm40 -> Convolution40 (in-place)
I0612 11:05:14.035601  4990 net.cpp:240] Setting up BatchNorm40
I0612 11:05:14.035612  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.035617  4990 net.cpp:255] Memory required for data: 1775763968
I0612 11:05:14.035631  4990 layer_factory.hpp:77] Creating layer Scale40
I0612 11:05:14.035640  4990 net.cpp:190] Creating Layer Scale40
I0612 11:05:14.035646  4990 net.cpp:615] Scale40 <- Convolution40
I0612 11:05:14.035656  4990 net.cpp:576] Scale40 -> Convolution40 (in-place)
I0612 11:05:14.035701  4990 layer_factory.hpp:77] Creating layer Scale40
I0612 11:05:14.035850  4990 net.cpp:240] Setting up Scale40
I0612 11:05:14.035862  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.035867  4990 net.cpp:255] Memory required for data: 1779958272
I0612 11:05:14.035879  4990 layer_factory.hpp:77] Creating layer ReLU40
I0612 11:05:14.035887  4990 net.cpp:190] Creating Layer ReLU40
I0612 11:05:14.035893  4990 net.cpp:615] ReLU40 <- Convolution40
I0612 11:05:14.035900  4990 net.cpp:576] ReLU40 -> Convolution40 (in-place)
I0612 11:05:14.035908  4990 net.cpp:240] Setting up ReLU40
I0612 11:05:14.035915  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.035919  4990 net.cpp:255] Memory required for data: 1784152576
I0612 11:05:14.035924  4990 layer_factory.hpp:77] Creating layer Convolution41
I0612 11:05:14.035939  4990 net.cpp:190] Creating Layer Convolution41
I0612 11:05:14.035944  4990 net.cpp:615] Convolution41 <- Convolution40
I0612 11:05:14.035955  4990 net.cpp:589] Convolution41 -> Convolution41
I0612 11:05:14.036669  4990 net.cpp:240] Setting up Convolution41
I0612 11:05:14.036682  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.036687  4990 net.cpp:255] Memory required for data: 1788346880
I0612 11:05:14.036698  4990 layer_factory.hpp:77] Creating layer BatchNorm41
I0612 11:05:14.036710  4990 net.cpp:190] Creating Layer BatchNorm41
I0612 11:05:14.036716  4990 net.cpp:615] BatchNorm41 <- Convolution41
I0612 11:05:14.036725  4990 net.cpp:576] BatchNorm41 -> Convolution41 (in-place)
I0612 11:05:14.036967  4990 net.cpp:240] Setting up BatchNorm41
I0612 11:05:14.036978  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.036983  4990 net.cpp:255] Memory required for data: 1792541184
I0612 11:05:14.036995  4990 layer_factory.hpp:77] Creating layer Scale41
I0612 11:05:14.037006  4990 net.cpp:190] Creating Layer Scale41
I0612 11:05:14.037012  4990 net.cpp:615] Scale41 <- Convolution41
I0612 11:05:14.037019  4990 net.cpp:576] Scale41 -> Convolution41 (in-place)
I0612 11:05:14.037062  4990 layer_factory.hpp:77] Creating layer Scale41
I0612 11:05:14.037212  4990 net.cpp:240] Setting up Scale41
I0612 11:05:14.037222  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.037226  4990 net.cpp:255] Memory required for data: 1796735488
I0612 11:05:14.037237  4990 layer_factory.hpp:77] Creating layer Eltwise20
I0612 11:05:14.037246  4990 net.cpp:190] Creating Layer Eltwise20
I0612 11:05:14.037252  4990 net.cpp:615] Eltwise20 <- Eltwise19_ReLU39_0_split_1
I0612 11:05:14.037259  4990 net.cpp:615] Eltwise20 <- Convolution41
I0612 11:05:14.037272  4990 net.cpp:589] Eltwise20 -> Eltwise20
I0612 11:05:14.037298  4990 net.cpp:240] Setting up Eltwise20
I0612 11:05:14.037307  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.037312  4990 net.cpp:255] Memory required for data: 1800929792
I0612 11:05:14.037320  4990 layer_factory.hpp:77] Creating layer ReLU41
I0612 11:05:14.037331  4990 net.cpp:190] Creating Layer ReLU41
I0612 11:05:14.037336  4990 net.cpp:615] ReLU41 <- Eltwise20
I0612 11:05:14.037343  4990 net.cpp:576] ReLU41 -> Eltwise20 (in-place)
I0612 11:05:14.037351  4990 net.cpp:240] Setting up ReLU41
I0612 11:05:14.037358  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.037363  4990 net.cpp:255] Memory required for data: 1805124096
I0612 11:05:14.037367  4990 layer_factory.hpp:77] Creating layer Eltwise20_ReLU41_0_split
I0612 11:05:14.037374  4990 net.cpp:190] Creating Layer Eltwise20_ReLU41_0_split
I0612 11:05:14.037379  4990 net.cpp:615] Eltwise20_ReLU41_0_split <- Eltwise20
I0612 11:05:14.037385  4990 net.cpp:589] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_0
I0612 11:05:14.037397  4990 net.cpp:589] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_1
I0612 11:05:14.037442  4990 net.cpp:240] Setting up Eltwise20_ReLU41_0_split
I0612 11:05:14.037449  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.037456  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.037461  4990 net.cpp:255] Memory required for data: 1813512704
I0612 11:05:14.037466  4990 layer_factory.hpp:77] Creating layer Convolution42
I0612 11:05:14.037479  4990 net.cpp:190] Creating Layer Convolution42
I0612 11:05:14.037485  4990 net.cpp:615] Convolution42 <- Eltwise20_ReLU41_0_split_0
I0612 11:05:14.037494  4990 net.cpp:589] Convolution42 -> Convolution42
I0612 11:05:14.038214  4990 net.cpp:240] Setting up Convolution42
I0612 11:05:14.038225  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.038230  4990 net.cpp:255] Memory required for data: 1817707008
I0612 11:05:14.038242  4990 layer_factory.hpp:77] Creating layer BatchNorm42
I0612 11:05:14.038254  4990 net.cpp:190] Creating Layer BatchNorm42
I0612 11:05:14.038259  4990 net.cpp:615] BatchNorm42 <- Convolution42
I0612 11:05:14.038267  4990 net.cpp:576] BatchNorm42 -> Convolution42 (in-place)
I0612 11:05:14.038518  4990 net.cpp:240] Setting up BatchNorm42
I0612 11:05:14.038530  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.038534  4990 net.cpp:255] Memory required for data: 1821901312
I0612 11:05:14.038549  4990 layer_factory.hpp:77] Creating layer Scale42
I0612 11:05:14.038561  4990 net.cpp:190] Creating Layer Scale42
I0612 11:05:14.038568  4990 net.cpp:615] Scale42 <- Convolution42
I0612 11:05:14.038574  4990 net.cpp:576] Scale42 -> Convolution42 (in-place)
I0612 11:05:14.038620  4990 layer_factory.hpp:77] Creating layer Scale42
I0612 11:05:14.038766  4990 net.cpp:240] Setting up Scale42
I0612 11:05:14.038775  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.038780  4990 net.cpp:255] Memory required for data: 1826095616
I0612 11:05:14.038791  4990 layer_factory.hpp:77] Creating layer ReLU42
I0612 11:05:14.038802  4990 net.cpp:190] Creating Layer ReLU42
I0612 11:05:14.038808  4990 net.cpp:615] ReLU42 <- Convolution42
I0612 11:05:14.038815  4990 net.cpp:576] ReLU42 -> Convolution42 (in-place)
I0612 11:05:14.038823  4990 net.cpp:240] Setting up ReLU42
I0612 11:05:14.038830  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.038836  4990 net.cpp:255] Memory required for data: 1830289920
I0612 11:05:14.038839  4990 layer_factory.hpp:77] Creating layer Convolution43
I0612 11:05:14.038854  4990 net.cpp:190] Creating Layer Convolution43
I0612 11:05:14.038859  4990 net.cpp:615] Convolution43 <- Convolution42
I0612 11:05:14.038867  4990 net.cpp:589] Convolution43 -> Convolution43
I0612 11:05:14.039585  4990 net.cpp:240] Setting up Convolution43
I0612 11:05:14.039598  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.039603  4990 net.cpp:255] Memory required for data: 1834484224
I0612 11:05:14.039615  4990 layer_factory.hpp:77] Creating layer BatchNorm43
I0612 11:05:14.039628  4990 net.cpp:190] Creating Layer BatchNorm43
I0612 11:05:14.039633  4990 net.cpp:615] BatchNorm43 <- Convolution43
I0612 11:05:14.039640  4990 net.cpp:576] BatchNorm43 -> Convolution43 (in-place)
I0612 11:05:14.039893  4990 net.cpp:240] Setting up BatchNorm43
I0612 11:05:14.039903  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.039908  4990 net.cpp:255] Memory required for data: 1838678528
I0612 11:05:14.039926  4990 layer_factory.hpp:77] Creating layer Scale43
I0612 11:05:14.039934  4990 net.cpp:190] Creating Layer Scale43
I0612 11:05:14.039939  4990 net.cpp:615] Scale43 <- Convolution43
I0612 11:05:14.039947  4990 net.cpp:576] Scale43 -> Convolution43 (in-place)
I0612 11:05:14.039993  4990 layer_factory.hpp:77] Creating layer Scale43
I0612 11:05:14.040140  4990 net.cpp:240] Setting up Scale43
I0612 11:05:14.040149  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.040154  4990 net.cpp:255] Memory required for data: 1842872832
I0612 11:05:14.040169  4990 layer_factory.hpp:77] Creating layer Eltwise21
I0612 11:05:14.040179  4990 net.cpp:190] Creating Layer Eltwise21
I0612 11:05:14.040184  4990 net.cpp:615] Eltwise21 <- Eltwise20_ReLU41_0_split_1
I0612 11:05:14.040191  4990 net.cpp:615] Eltwise21 <- Convolution43
I0612 11:05:14.040201  4990 net.cpp:589] Eltwise21 -> Eltwise21
I0612 11:05:14.040226  4990 net.cpp:240] Setting up Eltwise21
I0612 11:05:14.040235  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.040238  4990 net.cpp:255] Memory required for data: 1847067136
I0612 11:05:14.040243  4990 layer_factory.hpp:77] Creating layer ReLU43
I0612 11:05:14.040251  4990 net.cpp:190] Creating Layer ReLU43
I0612 11:05:14.040256  4990 net.cpp:615] ReLU43 <- Eltwise21
I0612 11:05:14.040266  4990 net.cpp:576] ReLU43 -> Eltwise21 (in-place)
I0612 11:05:14.040274  4990 net.cpp:240] Setting up ReLU43
I0612 11:05:14.040280  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.040285  4990 net.cpp:255] Memory required for data: 1851261440
I0612 11:05:14.040289  4990 layer_factory.hpp:77] Creating layer Eltwise21_ReLU43_0_split
I0612 11:05:14.040297  4990 net.cpp:190] Creating Layer Eltwise21_ReLU43_0_split
I0612 11:05:14.040302  4990 net.cpp:615] Eltwise21_ReLU43_0_split <- Eltwise21
I0612 11:05:14.040308  4990 net.cpp:589] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_0
I0612 11:05:14.040316  4990 net.cpp:589] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_1
I0612 11:05:14.040364  4990 net.cpp:240] Setting up Eltwise21_ReLU43_0_split
I0612 11:05:14.040372  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.040379  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.040382  4990 net.cpp:255] Memory required for data: 1859650048
I0612 11:05:14.040387  4990 layer_factory.hpp:77] Creating layer Convolution44
I0612 11:05:14.040398  4990 net.cpp:190] Creating Layer Convolution44
I0612 11:05:14.040405  4990 net.cpp:615] Convolution44 <- Eltwise21_ReLU43_0_split_0
I0612 11:05:14.040416  4990 net.cpp:589] Convolution44 -> Convolution44
I0612 11:05:14.041149  4990 net.cpp:240] Setting up Convolution44
I0612 11:05:14.041162  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.041167  4990 net.cpp:255] Memory required for data: 1863844352
I0612 11:05:14.041178  4990 layer_factory.hpp:77] Creating layer BatchNorm44
I0612 11:05:14.041188  4990 net.cpp:190] Creating Layer BatchNorm44
I0612 11:05:14.041193  4990 net.cpp:615] BatchNorm44 <- Convolution44
I0612 11:05:14.041203  4990 net.cpp:576] BatchNorm44 -> Convolution44 (in-place)
I0612 11:05:14.041448  4990 net.cpp:240] Setting up BatchNorm44
I0612 11:05:14.041458  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.041463  4990 net.cpp:255] Memory required for data: 1868038656
I0612 11:05:14.041477  4990 layer_factory.hpp:77] Creating layer Scale44
I0612 11:05:14.041486  4990 net.cpp:190] Creating Layer Scale44
I0612 11:05:14.041491  4990 net.cpp:615] Scale44 <- Convolution44
I0612 11:05:14.041497  4990 net.cpp:576] Scale44 -> Convolution44 (in-place)
I0612 11:05:14.041544  4990 layer_factory.hpp:77] Creating layer Scale44
I0612 11:05:14.041694  4990 net.cpp:240] Setting up Scale44
I0612 11:05:14.041704  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.041712  4990 net.cpp:255] Memory required for data: 1872232960
I0612 11:05:14.041724  4990 layer_factory.hpp:77] Creating layer ReLU44
I0612 11:05:14.041736  4990 net.cpp:190] Creating Layer ReLU44
I0612 11:05:14.041741  4990 net.cpp:615] ReLU44 <- Convolution44
I0612 11:05:14.041749  4990 net.cpp:576] ReLU44 -> Convolution44 (in-place)
I0612 11:05:14.041756  4990 net.cpp:240] Setting up ReLU44
I0612 11:05:14.041764  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.041769  4990 net.cpp:255] Memory required for data: 1876427264
I0612 11:05:14.041772  4990 layer_factory.hpp:77] Creating layer Convolution45
I0612 11:05:14.041787  4990 net.cpp:190] Creating Layer Convolution45
I0612 11:05:14.041792  4990 net.cpp:615] Convolution45 <- Convolution44
I0612 11:05:14.041800  4990 net.cpp:589] Convolution45 -> Convolution45
I0612 11:05:14.042549  4990 net.cpp:240] Setting up Convolution45
I0612 11:05:14.042563  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.042568  4990 net.cpp:255] Memory required for data: 1880621568
I0612 11:05:14.042579  4990 layer_factory.hpp:77] Creating layer BatchNorm45
I0612 11:05:14.042592  4990 net.cpp:190] Creating Layer BatchNorm45
I0612 11:05:14.042598  4990 net.cpp:615] BatchNorm45 <- Convolution45
I0612 11:05:14.042604  4990 net.cpp:576] BatchNorm45 -> Convolution45 (in-place)
I0612 11:05:14.042845  4990 net.cpp:240] Setting up BatchNorm45
I0612 11:05:14.042855  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.042860  4990 net.cpp:255] Memory required for data: 1884815872
I0612 11:05:14.042883  4990 layer_factory.hpp:77] Creating layer Scale45
I0612 11:05:14.042891  4990 net.cpp:190] Creating Layer Scale45
I0612 11:05:14.042896  4990 net.cpp:615] Scale45 <- Convolution45
I0612 11:05:14.042906  4990 net.cpp:576] Scale45 -> Convolution45 (in-place)
I0612 11:05:14.042946  4990 layer_factory.hpp:77] Creating layer Scale45
I0612 11:05:14.043087  4990 net.cpp:240] Setting up Scale45
I0612 11:05:14.043097  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.043102  4990 net.cpp:255] Memory required for data: 1889010176
I0612 11:05:14.043113  4990 layer_factory.hpp:77] Creating layer Eltwise22
I0612 11:05:14.043123  4990 net.cpp:190] Creating Layer Eltwise22
I0612 11:05:14.043128  4990 net.cpp:615] Eltwise22 <- Eltwise21_ReLU43_0_split_1
I0612 11:05:14.043134  4990 net.cpp:615] Eltwise22 <- Convolution45
I0612 11:05:14.043141  4990 net.cpp:589] Eltwise22 -> Eltwise22
I0612 11:05:14.043171  4990 net.cpp:240] Setting up Eltwise22
I0612 11:05:14.043180  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.043184  4990 net.cpp:255] Memory required for data: 1893204480
I0612 11:05:14.043190  4990 layer_factory.hpp:77] Creating layer ReLU45
I0612 11:05:14.043196  4990 net.cpp:190] Creating Layer ReLU45
I0612 11:05:14.043201  4990 net.cpp:615] ReLU45 <- Eltwise22
I0612 11:05:14.043210  4990 net.cpp:576] ReLU45 -> Eltwise22 (in-place)
I0612 11:05:14.043217  4990 net.cpp:240] Setting up ReLU45
I0612 11:05:14.043225  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.043228  4990 net.cpp:255] Memory required for data: 1897398784
I0612 11:05:14.043233  4990 layer_factory.hpp:77] Creating layer Eltwise22_ReLU45_0_split
I0612 11:05:14.043239  4990 net.cpp:190] Creating Layer Eltwise22_ReLU45_0_split
I0612 11:05:14.043244  4990 net.cpp:615] Eltwise22_ReLU45_0_split <- Eltwise22
I0612 11:05:14.043251  4990 net.cpp:589] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_0
I0612 11:05:14.043258  4990 net.cpp:589] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_1
I0612 11:05:14.043303  4990 net.cpp:240] Setting up Eltwise22_ReLU45_0_split
I0612 11:05:14.043310  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.043316  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.043321  4990 net.cpp:255] Memory required for data: 1905787392
I0612 11:05:14.043325  4990 layer_factory.hpp:77] Creating layer Convolution46
I0612 11:05:14.043339  4990 net.cpp:190] Creating Layer Convolution46
I0612 11:05:14.043349  4990 net.cpp:615] Convolution46 <- Eltwise22_ReLU45_0_split_0
I0612 11:05:14.043357  4990 net.cpp:589] Convolution46 -> Convolution46
I0612 11:05:14.044046  4990 net.cpp:240] Setting up Convolution46
I0612 11:05:14.044057  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.044062  4990 net.cpp:255] Memory required for data: 1909981696
I0612 11:05:14.044073  4990 layer_factory.hpp:77] Creating layer BatchNorm46
I0612 11:05:14.044085  4990 net.cpp:190] Creating Layer BatchNorm46
I0612 11:05:14.044091  4990 net.cpp:615] BatchNorm46 <- Convolution46
I0612 11:05:14.044100  4990 net.cpp:576] BatchNorm46 -> Convolution46 (in-place)
I0612 11:05:14.044335  4990 net.cpp:240] Setting up BatchNorm46
I0612 11:05:14.044344  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.044349  4990 net.cpp:255] Memory required for data: 1914176000
I0612 11:05:14.044363  4990 layer_factory.hpp:77] Creating layer Scale46
I0612 11:05:14.044374  4990 net.cpp:190] Creating Layer Scale46
I0612 11:05:14.044379  4990 net.cpp:615] Scale46 <- Convolution46
I0612 11:05:14.044386  4990 net.cpp:576] Scale46 -> Convolution46 (in-place)
I0612 11:05:14.044430  4990 layer_factory.hpp:77] Creating layer Scale46
I0612 11:05:14.044575  4990 net.cpp:240] Setting up Scale46
I0612 11:05:14.044585  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.044589  4990 net.cpp:255] Memory required for data: 1918370304
I0612 11:05:14.044600  4990 layer_factory.hpp:77] Creating layer ReLU46
I0612 11:05:14.044608  4990 net.cpp:190] Creating Layer ReLU46
I0612 11:05:14.044613  4990 net.cpp:615] ReLU46 <- Convolution46
I0612 11:05:14.044623  4990 net.cpp:576] ReLU46 -> Convolution46 (in-place)
I0612 11:05:14.044631  4990 net.cpp:240] Setting up ReLU46
I0612 11:05:14.044637  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.044642  4990 net.cpp:255] Memory required for data: 1922564608
I0612 11:05:14.044646  4990 layer_factory.hpp:77] Creating layer Convolution47
I0612 11:05:14.044661  4990 net.cpp:190] Creating Layer Convolution47
I0612 11:05:14.044666  4990 net.cpp:615] Convolution47 <- Convolution46
I0612 11:05:14.044672  4990 net.cpp:589] Convolution47 -> Convolution47
I0612 11:05:14.045351  4990 net.cpp:240] Setting up Convolution47
I0612 11:05:14.045361  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.045367  4990 net.cpp:255] Memory required for data: 1926758912
I0612 11:05:14.045377  4990 layer_factory.hpp:77] Creating layer BatchNorm47
I0612 11:05:14.045387  4990 net.cpp:190] Creating Layer BatchNorm47
I0612 11:05:14.045393  4990 net.cpp:615] BatchNorm47 <- Convolution47
I0612 11:05:14.045399  4990 net.cpp:576] BatchNorm47 -> Convolution47 (in-place)
I0612 11:05:14.045639  4990 net.cpp:240] Setting up BatchNorm47
I0612 11:05:14.045650  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.045653  4990 net.cpp:255] Memory required for data: 1930953216
I0612 11:05:14.045667  4990 layer_factory.hpp:77] Creating layer Scale47
I0612 11:05:14.045678  4990 net.cpp:190] Creating Layer Scale47
I0612 11:05:14.045683  4990 net.cpp:615] Scale47 <- Convolution47
I0612 11:05:14.045689  4990 net.cpp:576] Scale47 -> Convolution47 (in-place)
I0612 11:05:14.045735  4990 layer_factory.hpp:77] Creating layer Scale47
I0612 11:05:14.045876  4990 net.cpp:240] Setting up Scale47
I0612 11:05:14.045886  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.045889  4990 net.cpp:255] Memory required for data: 1935147520
I0612 11:05:14.045900  4990 layer_factory.hpp:77] Creating layer Eltwise23
I0612 11:05:14.045912  4990 net.cpp:190] Creating Layer Eltwise23
I0612 11:05:14.045917  4990 net.cpp:615] Eltwise23 <- Eltwise22_ReLU45_0_split_1
I0612 11:05:14.045923  4990 net.cpp:615] Eltwise23 <- Convolution47
I0612 11:05:14.045930  4990 net.cpp:589] Eltwise23 -> Eltwise23
I0612 11:05:14.045958  4990 net.cpp:240] Setting up Eltwise23
I0612 11:05:14.045965  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.045969  4990 net.cpp:255] Memory required for data: 1939341824
I0612 11:05:14.045977  4990 layer_factory.hpp:77] Creating layer ReLU47
I0612 11:05:14.045985  4990 net.cpp:190] Creating Layer ReLU47
I0612 11:05:14.045989  4990 net.cpp:615] ReLU47 <- Eltwise23
I0612 11:05:14.045996  4990 net.cpp:576] ReLU47 -> Eltwise23 (in-place)
I0612 11:05:14.046003  4990 net.cpp:240] Setting up ReLU47
I0612 11:05:14.046010  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.046015  4990 net.cpp:255] Memory required for data: 1943536128
I0612 11:05:14.046018  4990 layer_factory.hpp:77] Creating layer Eltwise23_ReLU47_0_split
I0612 11:05:14.046028  4990 net.cpp:190] Creating Layer Eltwise23_ReLU47_0_split
I0612 11:05:14.046033  4990 net.cpp:615] Eltwise23_ReLU47_0_split <- Eltwise23
I0612 11:05:14.046041  4990 net.cpp:589] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_0
I0612 11:05:14.046048  4990 net.cpp:589] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_1
I0612 11:05:14.046094  4990 net.cpp:240] Setting up Eltwise23_ReLU47_0_split
I0612 11:05:14.046103  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.046108  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.046113  4990 net.cpp:255] Memory required for data: 1951924736
I0612 11:05:14.046118  4990 layer_factory.hpp:77] Creating layer Convolution48
I0612 11:05:14.046128  4990 net.cpp:190] Creating Layer Convolution48
I0612 11:05:14.046133  4990 net.cpp:615] Convolution48 <- Eltwise23_ReLU47_0_split_0
I0612 11:05:14.046141  4990 net.cpp:589] Convolution48 -> Convolution48
I0612 11:05:14.046850  4990 net.cpp:240] Setting up Convolution48
I0612 11:05:14.046866  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.046871  4990 net.cpp:255] Memory required for data: 1956119040
I0612 11:05:14.046883  4990 layer_factory.hpp:77] Creating layer BatchNorm48
I0612 11:05:14.046891  4990 net.cpp:190] Creating Layer BatchNorm48
I0612 11:05:14.046897  4990 net.cpp:615] BatchNorm48 <- Convolution48
I0612 11:05:14.046906  4990 net.cpp:576] BatchNorm48 -> Convolution48 (in-place)
I0612 11:05:14.047142  4990 net.cpp:240] Setting up BatchNorm48
I0612 11:05:14.047152  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.047157  4990 net.cpp:255] Memory required for data: 1960313344
I0612 11:05:14.047169  4990 layer_factory.hpp:77] Creating layer Scale48
I0612 11:05:14.047178  4990 net.cpp:190] Creating Layer Scale48
I0612 11:05:14.047183  4990 net.cpp:615] Scale48 <- Convolution48
I0612 11:05:14.047189  4990 net.cpp:576] Scale48 -> Convolution48 (in-place)
I0612 11:05:14.047233  4990 layer_factory.hpp:77] Creating layer Scale48
I0612 11:05:14.047379  4990 net.cpp:240] Setting up Scale48
I0612 11:05:14.047389  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.047394  4990 net.cpp:255] Memory required for data: 1964507648
I0612 11:05:14.047405  4990 layer_factory.hpp:77] Creating layer ReLU48
I0612 11:05:14.047412  4990 net.cpp:190] Creating Layer ReLU48
I0612 11:05:14.047417  4990 net.cpp:615] ReLU48 <- Convolution48
I0612 11:05:14.047427  4990 net.cpp:576] ReLU48 -> Convolution48 (in-place)
I0612 11:05:14.047435  4990 net.cpp:240] Setting up ReLU48
I0612 11:05:14.047441  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.047446  4990 net.cpp:255] Memory required for data: 1968701952
I0612 11:05:14.047451  4990 layer_factory.hpp:77] Creating layer Convolution49
I0612 11:05:14.047464  4990 net.cpp:190] Creating Layer Convolution49
I0612 11:05:14.047471  4990 net.cpp:615] Convolution49 <- Convolution48
I0612 11:05:14.047477  4990 net.cpp:589] Convolution49 -> Convolution49
I0612 11:05:14.048161  4990 net.cpp:240] Setting up Convolution49
I0612 11:05:14.048172  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.048177  4990 net.cpp:255] Memory required for data: 1972896256
I0612 11:05:14.048188  4990 layer_factory.hpp:77] Creating layer BatchNorm49
I0612 11:05:14.048197  4990 net.cpp:190] Creating Layer BatchNorm49
I0612 11:05:14.048202  4990 net.cpp:615] BatchNorm49 <- Convolution49
I0612 11:05:14.048216  4990 net.cpp:576] BatchNorm49 -> Convolution49 (in-place)
I0612 11:05:14.048450  4990 net.cpp:240] Setting up BatchNorm49
I0612 11:05:14.048460  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.048463  4990 net.cpp:255] Memory required for data: 1977090560
I0612 11:05:14.048477  4990 layer_factory.hpp:77] Creating layer Scale49
I0612 11:05:14.048485  4990 net.cpp:190] Creating Layer Scale49
I0612 11:05:14.048491  4990 net.cpp:615] Scale49 <- Convolution49
I0612 11:05:14.048496  4990 net.cpp:576] Scale49 -> Convolution49 (in-place)
I0612 11:05:14.048539  4990 layer_factory.hpp:77] Creating layer Scale49
I0612 11:05:14.048679  4990 net.cpp:240] Setting up Scale49
I0612 11:05:14.048688  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.048692  4990 net.cpp:255] Memory required for data: 1981284864
I0612 11:05:14.048703  4990 layer_factory.hpp:77] Creating layer Eltwise24
I0612 11:05:14.048714  4990 net.cpp:190] Creating Layer Eltwise24
I0612 11:05:14.048720  4990 net.cpp:615] Eltwise24 <- Eltwise23_ReLU47_0_split_1
I0612 11:05:14.048727  4990 net.cpp:615] Eltwise24 <- Convolution49
I0612 11:05:14.048733  4990 net.cpp:589] Eltwise24 -> Eltwise24
I0612 11:05:14.048758  4990 net.cpp:240] Setting up Eltwise24
I0612 11:05:14.048764  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.048769  4990 net.cpp:255] Memory required for data: 1985479168
I0612 11:05:14.048774  4990 layer_factory.hpp:77] Creating layer ReLU49
I0612 11:05:14.048784  4990 net.cpp:190] Creating Layer ReLU49
I0612 11:05:14.048789  4990 net.cpp:615] ReLU49 <- Eltwise24
I0612 11:05:14.048797  4990 net.cpp:576] ReLU49 -> Eltwise24 (in-place)
I0612 11:05:14.048805  4990 net.cpp:240] Setting up ReLU49
I0612 11:05:14.048812  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.048816  4990 net.cpp:255] Memory required for data: 1989673472
I0612 11:05:14.048820  4990 layer_factory.hpp:77] Creating layer Eltwise24_ReLU49_0_split
I0612 11:05:14.048827  4990 net.cpp:190] Creating Layer Eltwise24_ReLU49_0_split
I0612 11:05:14.048832  4990 net.cpp:615] Eltwise24_ReLU49_0_split <- Eltwise24
I0612 11:05:14.048838  4990 net.cpp:589] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_0
I0612 11:05:14.048846  4990 net.cpp:589] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_1
I0612 11:05:14.048893  4990 net.cpp:240] Setting up Eltwise24_ReLU49_0_split
I0612 11:05:14.048902  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.048907  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.048912  4990 net.cpp:255] Memory required for data: 1998062080
I0612 11:05:14.048916  4990 layer_factory.hpp:77] Creating layer Convolution50
I0612 11:05:14.048929  4990 net.cpp:190] Creating Layer Convolution50
I0612 11:05:14.048935  4990 net.cpp:615] Convolution50 <- Eltwise24_ReLU49_0_split_0
I0612 11:05:14.048943  4990 net.cpp:589] Convolution50 -> Convolution50
I0612 11:05:14.050437  4990 net.cpp:240] Setting up Convolution50
I0612 11:05:14.050462  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.050467  4990 net.cpp:255] Memory required for data: 2002256384
I0612 11:05:14.050480  4990 layer_factory.hpp:77] Creating layer BatchNorm50
I0612 11:05:14.050493  4990 net.cpp:190] Creating Layer BatchNorm50
I0612 11:05:14.050499  4990 net.cpp:615] BatchNorm50 <- Convolution50
I0612 11:05:14.050508  4990 net.cpp:576] BatchNorm50 -> Convolution50 (in-place)
I0612 11:05:14.050737  4990 net.cpp:240] Setting up BatchNorm50
I0612 11:05:14.050747  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.050752  4990 net.cpp:255] Memory required for data: 2006450688
I0612 11:05:14.050765  4990 layer_factory.hpp:77] Creating layer Scale50
I0612 11:05:14.050777  4990 net.cpp:190] Creating Layer Scale50
I0612 11:05:14.050783  4990 net.cpp:615] Scale50 <- Convolution50
I0612 11:05:14.050789  4990 net.cpp:576] Scale50 -> Convolution50 (in-place)
I0612 11:05:14.050833  4990 layer_factory.hpp:77] Creating layer Scale50
I0612 11:05:14.050972  4990 net.cpp:240] Setting up Scale50
I0612 11:05:14.050987  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.050992  4990 net.cpp:255] Memory required for data: 2010644992
I0612 11:05:14.051003  4990 layer_factory.hpp:77] Creating layer ReLU50
I0612 11:05:14.051014  4990 net.cpp:190] Creating Layer ReLU50
I0612 11:05:14.051020  4990 net.cpp:615] ReLU50 <- Convolution50
I0612 11:05:14.051026  4990 net.cpp:576] ReLU50 -> Convolution50 (in-place)
I0612 11:05:14.051034  4990 net.cpp:240] Setting up ReLU50
I0612 11:05:14.051041  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.051045  4990 net.cpp:255] Memory required for data: 2014839296
I0612 11:05:14.051050  4990 layer_factory.hpp:77] Creating layer Convolution51
I0612 11:05:14.051064  4990 net.cpp:190] Creating Layer Convolution51
I0612 11:05:14.051069  4990 net.cpp:615] Convolution51 <- Convolution50
I0612 11:05:14.051077  4990 net.cpp:589] Convolution51 -> Convolution51
I0612 11:05:14.051746  4990 net.cpp:240] Setting up Convolution51
I0612 11:05:14.051758  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.051762  4990 net.cpp:255] Memory required for data: 2019033600
I0612 11:05:14.051772  4990 layer_factory.hpp:77] Creating layer BatchNorm51
I0612 11:05:14.051784  4990 net.cpp:190] Creating Layer BatchNorm51
I0612 11:05:14.051789  4990 net.cpp:615] BatchNorm51 <- Convolution51
I0612 11:05:14.051796  4990 net.cpp:576] BatchNorm51 -> Convolution51 (in-place)
I0612 11:05:14.052024  4990 net.cpp:240] Setting up BatchNorm51
I0612 11:05:14.052033  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.052038  4990 net.cpp:255] Memory required for data: 2023227904
I0612 11:05:14.052055  4990 layer_factory.hpp:77] Creating layer Scale51
I0612 11:05:14.052064  4990 net.cpp:190] Creating Layer Scale51
I0612 11:05:14.052068  4990 net.cpp:615] Scale51 <- Convolution51
I0612 11:05:14.052075  4990 net.cpp:576] Scale51 -> Convolution51 (in-place)
I0612 11:05:14.052117  4990 layer_factory.hpp:77] Creating layer Scale51
I0612 11:05:14.052256  4990 net.cpp:240] Setting up Scale51
I0612 11:05:14.052265  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.052269  4990 net.cpp:255] Memory required for data: 2027422208
I0612 11:05:14.052280  4990 layer_factory.hpp:77] Creating layer Eltwise25
I0612 11:05:14.052315  4990 net.cpp:190] Creating Layer Eltwise25
I0612 11:05:14.052322  4990 net.cpp:615] Eltwise25 <- Eltwise24_ReLU49_0_split_1
I0612 11:05:14.052330  4990 net.cpp:615] Eltwise25 <- Convolution51
I0612 11:05:14.052336  4990 net.cpp:589] Eltwise25 -> Eltwise25
I0612 11:05:14.052363  4990 net.cpp:240] Setting up Eltwise25
I0612 11:05:14.052371  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.052376  4990 net.cpp:255] Memory required for data: 2031616512
I0612 11:05:14.052381  4990 layer_factory.hpp:77] Creating layer ReLU51
I0612 11:05:14.052389  4990 net.cpp:190] Creating Layer ReLU51
I0612 11:05:14.052394  4990 net.cpp:615] ReLU51 <- Eltwise25
I0612 11:05:14.052400  4990 net.cpp:576] ReLU51 -> Eltwise25 (in-place)
I0612 11:05:14.052408  4990 net.cpp:240] Setting up ReLU51
I0612 11:05:14.052414  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.052418  4990 net.cpp:255] Memory required for data: 2035810816
I0612 11:05:14.052423  4990 layer_factory.hpp:77] Creating layer Eltwise25_ReLU51_0_split
I0612 11:05:14.052430  4990 net.cpp:190] Creating Layer Eltwise25_ReLU51_0_split
I0612 11:05:14.052434  4990 net.cpp:615] Eltwise25_ReLU51_0_split <- Eltwise25
I0612 11:05:14.052441  4990 net.cpp:589] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_0
I0612 11:05:14.052449  4990 net.cpp:589] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_1
I0612 11:05:14.052494  4990 net.cpp:240] Setting up Eltwise25_ReLU51_0_split
I0612 11:05:14.052501  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.052507  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.052511  4990 net.cpp:255] Memory required for data: 2044199424
I0612 11:05:14.052516  4990 layer_factory.hpp:77] Creating layer Convolution52
I0612 11:05:14.052533  4990 net.cpp:190] Creating Layer Convolution52
I0612 11:05:14.052539  4990 net.cpp:615] Convolution52 <- Eltwise25_ReLU51_0_split_0
I0612 11:05:14.052551  4990 net.cpp:589] Convolution52 -> Convolution52
I0612 11:05:14.053231  4990 net.cpp:240] Setting up Convolution52
I0612 11:05:14.053241  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.053246  4990 net.cpp:255] Memory required for data: 2048393728
I0612 11:05:14.053258  4990 layer_factory.hpp:77] Creating layer BatchNorm52
I0612 11:05:14.053277  4990 net.cpp:190] Creating Layer BatchNorm52
I0612 11:05:14.053283  4990 net.cpp:615] BatchNorm52 <- Convolution52
I0612 11:05:14.053294  4990 net.cpp:576] BatchNorm52 -> Convolution52 (in-place)
I0612 11:05:14.053524  4990 net.cpp:240] Setting up BatchNorm52
I0612 11:05:14.053534  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.053537  4990 net.cpp:255] Memory required for data: 2052588032
I0612 11:05:14.053550  4990 layer_factory.hpp:77] Creating layer Scale52
I0612 11:05:14.053561  4990 net.cpp:190] Creating Layer Scale52
I0612 11:05:14.053567  4990 net.cpp:615] Scale52 <- Convolution52
I0612 11:05:14.053575  4990 net.cpp:576] Scale52 -> Convolution52 (in-place)
I0612 11:05:14.053617  4990 layer_factory.hpp:77] Creating layer Scale52
I0612 11:05:14.053752  4990 net.cpp:240] Setting up Scale52
I0612 11:05:14.053761  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.053766  4990 net.cpp:255] Memory required for data: 2056782336
I0612 11:05:14.053776  4990 layer_factory.hpp:77] Creating layer ReLU52
I0612 11:05:14.053784  4990 net.cpp:190] Creating Layer ReLU52
I0612 11:05:14.053789  4990 net.cpp:615] ReLU52 <- Convolution52
I0612 11:05:14.053800  4990 net.cpp:576] ReLU52 -> Convolution52 (in-place)
I0612 11:05:14.053808  4990 net.cpp:240] Setting up ReLU52
I0612 11:05:14.053814  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.053819  4990 net.cpp:255] Memory required for data: 2060976640
I0612 11:05:14.053823  4990 layer_factory.hpp:77] Creating layer Convolution53
I0612 11:05:14.053838  4990 net.cpp:190] Creating Layer Convolution53
I0612 11:05:14.053843  4990 net.cpp:615] Convolution53 <- Convolution52
I0612 11:05:14.053850  4990 net.cpp:589] Convolution53 -> Convolution53
I0612 11:05:14.054554  4990 net.cpp:240] Setting up Convolution53
I0612 11:05:14.054566  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.054571  4990 net.cpp:255] Memory required for data: 2065170944
I0612 11:05:14.054581  4990 layer_factory.hpp:77] Creating layer BatchNorm53
I0612 11:05:14.054592  4990 net.cpp:190] Creating Layer BatchNorm53
I0612 11:05:14.054597  4990 net.cpp:615] BatchNorm53 <- Convolution53
I0612 11:05:14.054603  4990 net.cpp:576] BatchNorm53 -> Convolution53 (in-place)
I0612 11:05:14.054826  4990 net.cpp:240] Setting up BatchNorm53
I0612 11:05:14.054834  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.054839  4990 net.cpp:255] Memory required for data: 2069365248
I0612 11:05:14.054854  4990 layer_factory.hpp:77] Creating layer Scale53
I0612 11:05:14.054862  4990 net.cpp:190] Creating Layer Scale53
I0612 11:05:14.054867  4990 net.cpp:615] Scale53 <- Convolution53
I0612 11:05:14.054873  4990 net.cpp:576] Scale53 -> Convolution53 (in-place)
I0612 11:05:14.054915  4990 layer_factory.hpp:77] Creating layer Scale53
I0612 11:05:14.055049  4990 net.cpp:240] Setting up Scale53
I0612 11:05:14.055058  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.055061  4990 net.cpp:255] Memory required for data: 2073559552
I0612 11:05:14.055071  4990 layer_factory.hpp:77] Creating layer Eltwise26
I0612 11:05:14.055083  4990 net.cpp:190] Creating Layer Eltwise26
I0612 11:05:14.055088  4990 net.cpp:615] Eltwise26 <- Eltwise25_ReLU51_0_split_1
I0612 11:05:14.055094  4990 net.cpp:615] Eltwise26 <- Convolution53
I0612 11:05:14.055101  4990 net.cpp:589] Eltwise26 -> Eltwise26
I0612 11:05:14.055126  4990 net.cpp:240] Setting up Eltwise26
I0612 11:05:14.055133  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.055141  4990 net.cpp:255] Memory required for data: 2077753856
I0612 11:05:14.055145  4990 layer_factory.hpp:77] Creating layer ReLU53
I0612 11:05:14.055152  4990 net.cpp:190] Creating Layer ReLU53
I0612 11:05:14.055157  4990 net.cpp:615] ReLU53 <- Eltwise26
I0612 11:05:14.055162  4990 net.cpp:576] ReLU53 -> Eltwise26 (in-place)
I0612 11:05:14.055171  4990 net.cpp:240] Setting up ReLU53
I0612 11:05:14.055176  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.055181  4990 net.cpp:255] Memory required for data: 2081948160
I0612 11:05:14.055184  4990 layer_factory.hpp:77] Creating layer Eltwise26_ReLU53_0_split
I0612 11:05:14.055200  4990 net.cpp:190] Creating Layer Eltwise26_ReLU53_0_split
I0612 11:05:14.055205  4990 net.cpp:615] Eltwise26_ReLU53_0_split <- Eltwise26
I0612 11:05:14.055212  4990 net.cpp:589] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_0
I0612 11:05:14.055219  4990 net.cpp:589] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_1
I0612 11:05:14.055263  4990 net.cpp:240] Setting up Eltwise26_ReLU53_0_split
I0612 11:05:14.055271  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.055276  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.055280  4990 net.cpp:255] Memory required for data: 2090336768
I0612 11:05:14.055285  4990 layer_factory.hpp:77] Creating layer Convolution54
I0612 11:05:14.055295  4990 net.cpp:190] Creating Layer Convolution54
I0612 11:05:14.055300  4990 net.cpp:615] Convolution54 <- Eltwise26_ReLU53_0_split_0
I0612 11:05:14.055308  4990 net.cpp:589] Convolution54 -> Convolution54
I0612 11:05:14.055954  4990 net.cpp:240] Setting up Convolution54
I0612 11:05:14.055968  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.055974  4990 net.cpp:255] Memory required for data: 2094531072
I0612 11:05:14.055984  4990 layer_factory.hpp:77] Creating layer BatchNorm54
I0612 11:05:14.055992  4990 net.cpp:190] Creating Layer BatchNorm54
I0612 11:05:14.055997  4990 net.cpp:615] BatchNorm54 <- Convolution54
I0612 11:05:14.056006  4990 net.cpp:576] BatchNorm54 -> Convolution54 (in-place)
I0612 11:05:14.056221  4990 net.cpp:240] Setting up BatchNorm54
I0612 11:05:14.056231  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.056234  4990 net.cpp:255] Memory required for data: 2098725376
I0612 11:05:14.056247  4990 layer_factory.hpp:77] Creating layer Scale54
I0612 11:05:14.056255  4990 net.cpp:190] Creating Layer Scale54
I0612 11:05:14.056259  4990 net.cpp:615] Scale54 <- Convolution54
I0612 11:05:14.056267  4990 net.cpp:576] Scale54 -> Convolution54 (in-place)
I0612 11:05:14.056306  4990 layer_factory.hpp:77] Creating layer Scale54
I0612 11:05:14.056438  4990 net.cpp:240] Setting up Scale54
I0612 11:05:14.056447  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.056452  4990 net.cpp:255] Memory required for data: 2102919680
I0612 11:05:14.056463  4990 layer_factory.hpp:77] Creating layer ReLU54
I0612 11:05:14.056469  4990 net.cpp:190] Creating Layer ReLU54
I0612 11:05:14.056474  4990 net.cpp:615] ReLU54 <- Convolution54
I0612 11:05:14.056483  4990 net.cpp:576] ReLU54 -> Convolution54 (in-place)
I0612 11:05:14.056490  4990 net.cpp:240] Setting up ReLU54
I0612 11:05:14.056496  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.056501  4990 net.cpp:255] Memory required for data: 2107113984
I0612 11:05:14.056505  4990 layer_factory.hpp:77] Creating layer Convolution55
I0612 11:05:14.056519  4990 net.cpp:190] Creating Layer Convolution55
I0612 11:05:14.056522  4990 net.cpp:615] Convolution55 <- Convolution54
I0612 11:05:14.056530  4990 net.cpp:589] Convolution55 -> Convolution55
I0612 11:05:14.057173  4990 net.cpp:240] Setting up Convolution55
I0612 11:05:14.057183  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.057188  4990 net.cpp:255] Memory required for data: 2111308288
I0612 11:05:14.057199  4990 layer_factory.hpp:77] Creating layer BatchNorm55
I0612 11:05:14.057206  4990 net.cpp:190] Creating Layer BatchNorm55
I0612 11:05:14.057214  4990 net.cpp:615] BatchNorm55 <- Convolution55
I0612 11:05:14.057224  4990 net.cpp:576] BatchNorm55 -> Convolution55 (in-place)
I0612 11:05:14.057448  4990 net.cpp:240] Setting up BatchNorm55
I0612 11:05:14.057458  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.057462  4990 net.cpp:255] Memory required for data: 2115502592
I0612 11:05:14.057476  4990 layer_factory.hpp:77] Creating layer Scale55
I0612 11:05:14.057483  4990 net.cpp:190] Creating Layer Scale55
I0612 11:05:14.057487  4990 net.cpp:615] Scale55 <- Convolution55
I0612 11:05:14.057494  4990 net.cpp:576] Scale55 -> Convolution55 (in-place)
I0612 11:05:14.057535  4990 layer_factory.hpp:77] Creating layer Scale55
I0612 11:05:14.057663  4990 net.cpp:240] Setting up Scale55
I0612 11:05:14.057672  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.057677  4990 net.cpp:255] Memory required for data: 2119696896
I0612 11:05:14.057687  4990 layer_factory.hpp:77] Creating layer Eltwise27
I0612 11:05:14.057696  4990 net.cpp:190] Creating Layer Eltwise27
I0612 11:05:14.057703  4990 net.cpp:615] Eltwise27 <- Eltwise26_ReLU53_0_split_1
I0612 11:05:14.057708  4990 net.cpp:615] Eltwise27 <- Convolution55
I0612 11:05:14.057714  4990 net.cpp:589] Eltwise27 -> Eltwise27
I0612 11:05:14.057735  4990 net.cpp:240] Setting up Eltwise27
I0612 11:05:14.057744  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.057747  4990 net.cpp:255] Memory required for data: 2123891200
I0612 11:05:14.057751  4990 layer_factory.hpp:77] Creating layer ReLU55
I0612 11:05:14.057761  4990 net.cpp:190] Creating Layer ReLU55
I0612 11:05:14.057766  4990 net.cpp:615] ReLU55 <- Eltwise27
I0612 11:05:14.057775  4990 net.cpp:576] ReLU55 -> Eltwise27 (in-place)
I0612 11:05:14.057782  4990 net.cpp:240] Setting up ReLU55
I0612 11:05:14.057788  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.057792  4990 net.cpp:255] Memory required for data: 2128085504
I0612 11:05:14.057796  4990 layer_factory.hpp:77] Creating layer Eltwise27_ReLU55_0_split
I0612 11:05:14.057802  4990 net.cpp:190] Creating Layer Eltwise27_ReLU55_0_split
I0612 11:05:14.057807  4990 net.cpp:615] Eltwise27_ReLU55_0_split <- Eltwise27
I0612 11:05:14.057813  4990 net.cpp:589] Eltwise27_ReLU55_0_split -> Eltwise27_ReLU55_0_split_0
I0612 11:05:14.057821  4990 net.cpp:589] Eltwise27_ReLU55_0_split -> Eltwise27_ReLU55_0_split_1
I0612 11:05:14.057862  4990 net.cpp:240] Setting up Eltwise27_ReLU55_0_split
I0612 11:05:14.057869  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.057875  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.057879  4990 net.cpp:255] Memory required for data: 2136474112
I0612 11:05:14.057883  4990 layer_factory.hpp:77] Creating layer Convolution56
I0612 11:05:14.057896  4990 net.cpp:190] Creating Layer Convolution56
I0612 11:05:14.057901  4990 net.cpp:615] Convolution56 <- Eltwise27_ReLU55_0_split_0
I0612 11:05:14.057909  4990 net.cpp:589] Convolution56 -> Convolution56
I0612 11:05:14.058568  4990 net.cpp:240] Setting up Convolution56
I0612 11:05:14.058580  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.058585  4990 net.cpp:255] Memory required for data: 2140668416
I0612 11:05:14.058595  4990 layer_factory.hpp:77] Creating layer BatchNorm56
I0612 11:05:14.058606  4990 net.cpp:190] Creating Layer BatchNorm56
I0612 11:05:14.058612  4990 net.cpp:615] BatchNorm56 <- Convolution56
I0612 11:05:14.058620  4990 net.cpp:576] BatchNorm56 -> Convolution56 (in-place)
I0612 11:05:14.058840  4990 net.cpp:240] Setting up BatchNorm56
I0612 11:05:14.058848  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.058852  4990 net.cpp:255] Memory required for data: 2144862720
I0612 11:05:14.058866  4990 layer_factory.hpp:77] Creating layer Scale56
I0612 11:05:14.058876  4990 net.cpp:190] Creating Layer Scale56
I0612 11:05:14.058881  4990 net.cpp:615] Scale56 <- Convolution56
I0612 11:05:14.058887  4990 net.cpp:576] Scale56 -> Convolution56 (in-place)
I0612 11:05:14.058925  4990 layer_factory.hpp:77] Creating layer Scale56
I0612 11:05:14.059067  4990 net.cpp:240] Setting up Scale56
I0612 11:05:14.059077  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.059082  4990 net.cpp:255] Memory required for data: 2149057024
I0612 11:05:14.059092  4990 layer_factory.hpp:77] Creating layer ReLU56
I0612 11:05:14.059099  4990 net.cpp:190] Creating Layer ReLU56
I0612 11:05:14.059104  4990 net.cpp:615] ReLU56 <- Convolution56
I0612 11:05:14.059113  4990 net.cpp:576] ReLU56 -> Convolution56 (in-place)
I0612 11:05:14.059121  4990 net.cpp:240] Setting up ReLU56
I0612 11:05:14.059128  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.059131  4990 net.cpp:255] Memory required for data: 2153251328
I0612 11:05:14.059135  4990 layer_factory.hpp:77] Creating layer Convolution57
I0612 11:05:14.059149  4990 net.cpp:190] Creating Layer Convolution57
I0612 11:05:14.059154  4990 net.cpp:615] Convolution57 <- Convolution56
I0612 11:05:14.059160  4990 net.cpp:589] Convolution57 -> Convolution57
I0612 11:05:14.059809  4990 net.cpp:240] Setting up Convolution57
I0612 11:05:14.059820  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.059825  4990 net.cpp:255] Memory required for data: 2157445632
I0612 11:05:14.059835  4990 layer_factory.hpp:77] Creating layer BatchNorm57
I0612 11:05:14.059846  4990 net.cpp:190] Creating Layer BatchNorm57
I0612 11:05:14.059854  4990 net.cpp:615] BatchNorm57 <- Convolution57
I0612 11:05:14.059860  4990 net.cpp:576] BatchNorm57 -> Convolution57 (in-place)
I0612 11:05:14.060076  4990 net.cpp:240] Setting up BatchNorm57
I0612 11:05:14.060086  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.060089  4990 net.cpp:255] Memory required for data: 2161639936
I0612 11:05:14.060102  4990 layer_factory.hpp:77] Creating layer Scale57
I0612 11:05:14.060112  4990 net.cpp:190] Creating Layer Scale57
I0612 11:05:14.060118  4990 net.cpp:615] Scale57 <- Convolution57
I0612 11:05:14.060125  4990 net.cpp:576] Scale57 -> Convolution57 (in-place)
I0612 11:05:14.060165  4990 layer_factory.hpp:77] Creating layer Scale57
I0612 11:05:14.060298  4990 net.cpp:240] Setting up Scale57
I0612 11:05:14.060307  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.060312  4990 net.cpp:255] Memory required for data: 2165834240
I0612 11:05:14.060322  4990 layer_factory.hpp:77] Creating layer Eltwise28
I0612 11:05:14.060331  4990 net.cpp:190] Creating Layer Eltwise28
I0612 11:05:14.060338  4990 net.cpp:615] Eltwise28 <- Eltwise27_ReLU55_0_split_1
I0612 11:05:14.060344  4990 net.cpp:615] Eltwise28 <- Convolution57
I0612 11:05:14.060350  4990 net.cpp:589] Eltwise28 -> Eltwise28
I0612 11:05:14.060375  4990 net.cpp:240] Setting up Eltwise28
I0612 11:05:14.060382  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.060387  4990 net.cpp:255] Memory required for data: 2170028544
I0612 11:05:14.060391  4990 layer_factory.hpp:77] Creating layer ReLU57
I0612 11:05:14.060398  4990 net.cpp:190] Creating Layer ReLU57
I0612 11:05:14.060403  4990 net.cpp:615] ReLU57 <- Eltwise28
I0612 11:05:14.060410  4990 net.cpp:576] ReLU57 -> Eltwise28 (in-place)
I0612 11:05:14.060416  4990 net.cpp:240] Setting up ReLU57
I0612 11:05:14.060422  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.060426  4990 net.cpp:255] Memory required for data: 2174222848
I0612 11:05:14.060431  4990 layer_factory.hpp:77] Creating layer Eltwise28_ReLU57_0_split
I0612 11:05:14.060437  4990 net.cpp:190] Creating Layer Eltwise28_ReLU57_0_split
I0612 11:05:14.060441  4990 net.cpp:615] Eltwise28_ReLU57_0_split <- Eltwise28
I0612 11:05:14.060449  4990 net.cpp:589] Eltwise28_ReLU57_0_split -> Eltwise28_ReLU57_0_split_0
I0612 11:05:14.060457  4990 net.cpp:589] Eltwise28_ReLU57_0_split -> Eltwise28_ReLU57_0_split_1
I0612 11:05:14.060498  4990 net.cpp:240] Setting up Eltwise28_ReLU57_0_split
I0612 11:05:14.060506  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.060513  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.060516  4990 net.cpp:255] Memory required for data: 2182611456
I0612 11:05:14.060525  4990 layer_factory.hpp:77] Creating layer Convolution58
I0612 11:05:14.060536  4990 net.cpp:190] Creating Layer Convolution58
I0612 11:05:14.060541  4990 net.cpp:615] Convolution58 <- Eltwise28_ReLU57_0_split_0
I0612 11:05:14.060549  4990 net.cpp:589] Convolution58 -> Convolution58
I0612 11:05:14.061194  4990 net.cpp:240] Setting up Convolution58
I0612 11:05:14.061204  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.061209  4990 net.cpp:255] Memory required for data: 2186805760
I0612 11:05:14.061219  4990 layer_factory.hpp:77] Creating layer BatchNorm58
I0612 11:05:14.061233  4990 net.cpp:190] Creating Layer BatchNorm58
I0612 11:05:14.061239  4990 net.cpp:615] BatchNorm58 <- Convolution58
I0612 11:05:14.061244  4990 net.cpp:576] BatchNorm58 -> Convolution58 (in-place)
I0612 11:05:14.061470  4990 net.cpp:240] Setting up BatchNorm58
I0612 11:05:14.061478  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.061482  4990 net.cpp:255] Memory required for data: 2191000064
I0612 11:05:14.061496  4990 layer_factory.hpp:77] Creating layer Scale58
I0612 11:05:14.061502  4990 net.cpp:190] Creating Layer Scale58
I0612 11:05:14.061507  4990 net.cpp:615] Scale58 <- Convolution58
I0612 11:05:14.061514  4990 net.cpp:576] Scale58 -> Convolution58 (in-place)
I0612 11:05:14.061556  4990 layer_factory.hpp:77] Creating layer Scale58
I0612 11:05:14.061691  4990 net.cpp:240] Setting up Scale58
I0612 11:05:14.061699  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.061703  4990 net.cpp:255] Memory required for data: 2195194368
I0612 11:05:14.061717  4990 layer_factory.hpp:77] Creating layer ReLU58
I0612 11:05:14.061724  4990 net.cpp:190] Creating Layer ReLU58
I0612 11:05:14.061729  4990 net.cpp:615] ReLU58 <- Convolution58
I0612 11:05:14.061738  4990 net.cpp:576] ReLU58 -> Convolution58 (in-place)
I0612 11:05:14.061746  4990 net.cpp:240] Setting up ReLU58
I0612 11:05:14.061753  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.061756  4990 net.cpp:255] Memory required for data: 2199388672
I0612 11:05:14.061760  4990 layer_factory.hpp:77] Creating layer Convolution59
I0612 11:05:14.061771  4990 net.cpp:190] Creating Layer Convolution59
I0612 11:05:14.061775  4990 net.cpp:615] Convolution59 <- Convolution58
I0612 11:05:14.061785  4990 net.cpp:589] Convolution59 -> Convolution59
I0612 11:05:14.062438  4990 net.cpp:240] Setting up Convolution59
I0612 11:05:14.062448  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.062453  4990 net.cpp:255] Memory required for data: 2203582976
I0612 11:05:14.062464  4990 layer_factory.hpp:77] Creating layer BatchNorm59
I0612 11:05:14.062472  4990 net.cpp:190] Creating Layer BatchNorm59
I0612 11:05:14.062477  4990 net.cpp:615] BatchNorm59 <- Convolution59
I0612 11:05:14.062486  4990 net.cpp:576] BatchNorm59 -> Convolution59 (in-place)
I0612 11:05:14.062706  4990 net.cpp:240] Setting up BatchNorm59
I0612 11:05:14.062716  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.062719  4990 net.cpp:255] Memory required for data: 2207777280
I0612 11:05:14.062731  4990 layer_factory.hpp:77] Creating layer Scale59
I0612 11:05:14.062739  4990 net.cpp:190] Creating Layer Scale59
I0612 11:05:14.062744  4990 net.cpp:615] Scale59 <- Convolution59
I0612 11:05:14.062750  4990 net.cpp:576] Scale59 -> Convolution59 (in-place)
I0612 11:05:14.062790  4990 layer_factory.hpp:77] Creating layer Scale59
I0612 11:05:14.062924  4990 net.cpp:240] Setting up Scale59
I0612 11:05:14.062933  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.062937  4990 net.cpp:255] Memory required for data: 2211971584
I0612 11:05:14.062948  4990 layer_factory.hpp:77] Creating layer Eltwise29
I0612 11:05:14.062958  4990 net.cpp:190] Creating Layer Eltwise29
I0612 11:05:14.062964  4990 net.cpp:615] Eltwise29 <- Eltwise28_ReLU57_0_split_1
I0612 11:05:14.062970  4990 net.cpp:615] Eltwise29 <- Convolution59
I0612 11:05:14.062976  4990 net.cpp:589] Eltwise29 -> Eltwise29
I0612 11:05:14.062999  4990 net.cpp:240] Setting up Eltwise29
I0612 11:05:14.063009  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.063014  4990 net.cpp:255] Memory required for data: 2216165888
I0612 11:05:14.063017  4990 layer_factory.hpp:77] Creating layer ReLU59
I0612 11:05:14.063027  4990 net.cpp:190] Creating Layer ReLU59
I0612 11:05:14.063033  4990 net.cpp:615] ReLU59 <- Eltwise29
I0612 11:05:14.063040  4990 net.cpp:576] ReLU59 -> Eltwise29 (in-place)
I0612 11:05:14.063046  4990 net.cpp:240] Setting up ReLU59
I0612 11:05:14.063051  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.063055  4990 net.cpp:255] Memory required for data: 2220360192
I0612 11:05:14.063060  4990 layer_factory.hpp:77] Creating layer Eltwise29_ReLU59_0_split
I0612 11:05:14.063066  4990 net.cpp:190] Creating Layer Eltwise29_ReLU59_0_split
I0612 11:05:14.063074  4990 net.cpp:615] Eltwise29_ReLU59_0_split <- Eltwise29
I0612 11:05:14.063081  4990 net.cpp:589] Eltwise29_ReLU59_0_split -> Eltwise29_ReLU59_0_split_0
I0612 11:05:14.063088  4990 net.cpp:589] Eltwise29_ReLU59_0_split -> Eltwise29_ReLU59_0_split_1
I0612 11:05:14.063130  4990 net.cpp:240] Setting up Eltwise29_ReLU59_0_split
I0612 11:05:14.063138  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.063143  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.063148  4990 net.cpp:255] Memory required for data: 2228748800
I0612 11:05:14.063151  4990 layer_factory.hpp:77] Creating layer Convolution60
I0612 11:05:14.063164  4990 net.cpp:190] Creating Layer Convolution60
I0612 11:05:14.063169  4990 net.cpp:615] Convolution60 <- Eltwise29_ReLU59_0_split_0
I0612 11:05:14.063177  4990 net.cpp:589] Convolution60 -> Convolution60
I0612 11:05:14.063822  4990 net.cpp:240] Setting up Convolution60
I0612 11:05:14.063833  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.063838  4990 net.cpp:255] Memory required for data: 2232943104
I0612 11:05:14.063848  4990 layer_factory.hpp:77] Creating layer BatchNorm60
I0612 11:05:14.063858  4990 net.cpp:190] Creating Layer BatchNorm60
I0612 11:05:14.063864  4990 net.cpp:615] BatchNorm60 <- Convolution60
I0612 11:05:14.063870  4990 net.cpp:576] BatchNorm60 -> Convolution60 (in-place)
I0612 11:05:14.064091  4990 net.cpp:240] Setting up BatchNorm60
I0612 11:05:14.064100  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.064105  4990 net.cpp:255] Memory required for data: 2237137408
I0612 11:05:14.064117  4990 layer_factory.hpp:77] Creating layer Scale60
I0612 11:05:14.064126  4990 net.cpp:190] Creating Layer Scale60
I0612 11:05:14.064131  4990 net.cpp:615] Scale60 <- Convolution60
I0612 11:05:14.064139  4990 net.cpp:576] Scale60 -> Convolution60 (in-place)
I0612 11:05:14.064177  4990 layer_factory.hpp:77] Creating layer Scale60
I0612 11:05:14.064307  4990 net.cpp:240] Setting up Scale60
I0612 11:05:14.064318  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.064322  4990 net.cpp:255] Memory required for data: 2241331712
I0612 11:05:14.064332  4990 layer_factory.hpp:77] Creating layer ReLU60
I0612 11:05:14.064340  4990 net.cpp:190] Creating Layer ReLU60
I0612 11:05:14.064344  4990 net.cpp:615] ReLU60 <- Convolution60
I0612 11:05:14.064352  4990 net.cpp:576] ReLU60 -> Convolution60 (in-place)
I0612 11:05:14.064358  4990 net.cpp:240] Setting up ReLU60
I0612 11:05:14.064364  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.064368  4990 net.cpp:255] Memory required for data: 2245526016
I0612 11:05:14.064373  4990 layer_factory.hpp:77] Creating layer Convolution61
I0612 11:05:14.064386  4990 net.cpp:190] Creating Layer Convolution61
I0612 11:05:14.064390  4990 net.cpp:615] Convolution61 <- Convolution60
I0612 11:05:14.064400  4990 net.cpp:589] Convolution61 -> Convolution61
I0612 11:05:14.065059  4990 net.cpp:240] Setting up Convolution61
I0612 11:05:14.065070  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.065074  4990 net.cpp:255] Memory required for data: 2249720320
I0612 11:05:14.065085  4990 layer_factory.hpp:77] Creating layer BatchNorm61
I0612 11:05:14.065096  4990 net.cpp:190] Creating Layer BatchNorm61
I0612 11:05:14.065106  4990 net.cpp:615] BatchNorm61 <- Convolution61
I0612 11:05:14.065115  4990 net.cpp:576] BatchNorm61 -> Convolution61 (in-place)
I0612 11:05:14.065331  4990 net.cpp:240] Setting up BatchNorm61
I0612 11:05:14.065340  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.065345  4990 net.cpp:255] Memory required for data: 2253914624
I0612 11:05:14.065356  4990 layer_factory.hpp:77] Creating layer Scale61
I0612 11:05:14.065367  4990 net.cpp:190] Creating Layer Scale61
I0612 11:05:14.065372  4990 net.cpp:615] Scale61 <- Convolution61
I0612 11:05:14.065378  4990 net.cpp:576] Scale61 -> Convolution61 (in-place)
I0612 11:05:14.065414  4990 layer_factory.hpp:77] Creating layer Scale61
I0612 11:05:14.065546  4990 net.cpp:240] Setting up Scale61
I0612 11:05:14.065554  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.065559  4990 net.cpp:255] Memory required for data: 2258108928
I0612 11:05:14.065569  4990 layer_factory.hpp:77] Creating layer Eltwise30
I0612 11:05:14.065577  4990 net.cpp:190] Creating Layer Eltwise30
I0612 11:05:14.065582  4990 net.cpp:615] Eltwise30 <- Eltwise29_ReLU59_0_split_1
I0612 11:05:14.065588  4990 net.cpp:615] Eltwise30 <- Convolution61
I0612 11:05:14.065598  4990 net.cpp:589] Eltwise30 -> Eltwise30
I0612 11:05:14.065621  4990 net.cpp:240] Setting up Eltwise30
I0612 11:05:14.065629  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.065632  4990 net.cpp:255] Memory required for data: 2262303232
I0612 11:05:14.065636  4990 layer_factory.hpp:77] Creating layer ReLU61
I0612 11:05:14.065645  4990 net.cpp:190] Creating Layer ReLU61
I0612 11:05:14.065650  4990 net.cpp:615] ReLU61 <- Eltwise30
I0612 11:05:14.065656  4990 net.cpp:576] ReLU61 -> Eltwise30 (in-place)
I0612 11:05:14.065663  4990 net.cpp:240] Setting up ReLU61
I0612 11:05:14.065670  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.065673  4990 net.cpp:255] Memory required for data: 2266497536
I0612 11:05:14.065677  4990 layer_factory.hpp:77] Creating layer Eltwise30_ReLU61_0_split
I0612 11:05:14.065683  4990 net.cpp:190] Creating Layer Eltwise30_ReLU61_0_split
I0612 11:05:14.065687  4990 net.cpp:615] Eltwise30_ReLU61_0_split <- Eltwise30
I0612 11:05:14.065696  4990 net.cpp:589] Eltwise30_ReLU61_0_split -> Eltwise30_ReLU61_0_split_0
I0612 11:05:14.065704  4990 net.cpp:589] Eltwise30_ReLU61_0_split -> Eltwise30_ReLU61_0_split_1
I0612 11:05:14.065742  4990 net.cpp:240] Setting up Eltwise30_ReLU61_0_split
I0612 11:05:14.065749  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.065754  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.065759  4990 net.cpp:255] Memory required for data: 2274886144
I0612 11:05:14.065763  4990 layer_factory.hpp:77] Creating layer Convolution62
I0612 11:05:14.065776  4990 net.cpp:190] Creating Layer Convolution62
I0612 11:05:14.065781  4990 net.cpp:615] Convolution62 <- Eltwise30_ReLU61_0_split_0
I0612 11:05:14.065789  4990 net.cpp:589] Convolution62 -> Convolution62
I0612 11:05:14.066450  4990 net.cpp:240] Setting up Convolution62
I0612 11:05:14.066462  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.066468  4990 net.cpp:255] Memory required for data: 2279080448
I0612 11:05:14.066488  4990 layer_factory.hpp:77] Creating layer BatchNorm62
I0612 11:05:14.066498  4990 net.cpp:190] Creating Layer BatchNorm62
I0612 11:05:14.066503  4990 net.cpp:615] BatchNorm62 <- Convolution62
I0612 11:05:14.066509  4990 net.cpp:576] BatchNorm62 -> Convolution62 (in-place)
I0612 11:05:14.066725  4990 net.cpp:240] Setting up BatchNorm62
I0612 11:05:14.066732  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.066736  4990 net.cpp:255] Memory required for data: 2283274752
I0612 11:05:14.066751  4990 layer_factory.hpp:77] Creating layer Scale62
I0612 11:05:14.066758  4990 net.cpp:190] Creating Layer Scale62
I0612 11:05:14.066763  4990 net.cpp:615] Scale62 <- Convolution62
I0612 11:05:14.066769  4990 net.cpp:576] Scale62 -> Convolution62 (in-place)
I0612 11:05:14.066812  4990 layer_factory.hpp:77] Creating layer Scale62
I0612 11:05:14.066939  4990 net.cpp:240] Setting up Scale62
I0612 11:05:14.066947  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.066951  4990 net.cpp:255] Memory required for data: 2287469056
I0612 11:05:14.066962  4990 layer_factory.hpp:77] Creating layer ReLU62
I0612 11:05:14.066972  4990 net.cpp:190] Creating Layer ReLU62
I0612 11:05:14.066977  4990 net.cpp:615] ReLU62 <- Convolution62
I0612 11:05:14.066982  4990 net.cpp:576] ReLU62 -> Convolution62 (in-place)
I0612 11:05:14.066989  4990 net.cpp:240] Setting up ReLU62
I0612 11:05:14.066995  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.066999  4990 net.cpp:255] Memory required for data: 2291663360
I0612 11:05:14.067003  4990 layer_factory.hpp:77] Creating layer Convolution63
I0612 11:05:14.067015  4990 net.cpp:190] Creating Layer Convolution63
I0612 11:05:14.067020  4990 net.cpp:615] Convolution63 <- Convolution62
I0612 11:05:14.067029  4990 net.cpp:589] Convolution63 -> Convolution63
I0612 11:05:14.067643  4990 net.cpp:240] Setting up Convolution63
I0612 11:05:14.067654  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.067658  4990 net.cpp:255] Memory required for data: 2295857664
I0612 11:05:14.067668  4990 layer_factory.hpp:77] Creating layer BatchNorm63
I0612 11:05:14.067675  4990 net.cpp:190] Creating Layer BatchNorm63
I0612 11:05:14.067680  4990 net.cpp:615] BatchNorm63 <- Convolution63
I0612 11:05:14.067687  4990 net.cpp:576] BatchNorm63 -> Convolution63 (in-place)
I0612 11:05:14.067896  4990 net.cpp:240] Setting up BatchNorm63
I0612 11:05:14.067904  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.067909  4990 net.cpp:255] Memory required for data: 2300051968
I0612 11:05:14.067920  4990 layer_factory.hpp:77] Creating layer Scale63
I0612 11:05:14.067929  4990 net.cpp:190] Creating Layer Scale63
I0612 11:05:14.067932  4990 net.cpp:615] Scale63 <- Convolution63
I0612 11:05:14.067939  4990 net.cpp:576] Scale63 -> Convolution63 (in-place)
I0612 11:05:14.067978  4990 layer_factory.hpp:77] Creating layer Scale63
I0612 11:05:14.068106  4990 net.cpp:240] Setting up Scale63
I0612 11:05:14.068114  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.068119  4990 net.cpp:255] Memory required for data: 2304246272
I0612 11:05:14.068133  4990 layer_factory.hpp:77] Creating layer Eltwise31
I0612 11:05:14.068141  4990 net.cpp:190] Creating Layer Eltwise31
I0612 11:05:14.068146  4990 net.cpp:615] Eltwise31 <- Eltwise30_ReLU61_0_split_1
I0612 11:05:14.068152  4990 net.cpp:615] Eltwise31 <- Convolution63
I0612 11:05:14.068161  4990 net.cpp:589] Eltwise31 -> Eltwise31
I0612 11:05:14.068182  4990 net.cpp:240] Setting up Eltwise31
I0612 11:05:14.068189  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.068193  4990 net.cpp:255] Memory required for data: 2308440576
I0612 11:05:14.068197  4990 layer_factory.hpp:77] Creating layer ReLU63
I0612 11:05:14.068204  4990 net.cpp:190] Creating Layer ReLU63
I0612 11:05:14.068208  4990 net.cpp:615] ReLU63 <- Eltwise31
I0612 11:05:14.068219  4990 net.cpp:576] ReLU63 -> Eltwise31 (in-place)
I0612 11:05:14.068227  4990 net.cpp:240] Setting up ReLU63
I0612 11:05:14.068233  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.068236  4990 net.cpp:255] Memory required for data: 2312634880
I0612 11:05:14.068240  4990 layer_factory.hpp:77] Creating layer Eltwise31_ReLU63_0_split
I0612 11:05:14.068246  4990 net.cpp:190] Creating Layer Eltwise31_ReLU63_0_split
I0612 11:05:14.068250  4990 net.cpp:615] Eltwise31_ReLU63_0_split <- Eltwise31
I0612 11:05:14.068256  4990 net.cpp:589] Eltwise31_ReLU63_0_split -> Eltwise31_ReLU63_0_split_0
I0612 11:05:14.068264  4990 net.cpp:589] Eltwise31_ReLU63_0_split -> Eltwise31_ReLU63_0_split_1
I0612 11:05:14.068305  4990 net.cpp:240] Setting up Eltwise31_ReLU63_0_split
I0612 11:05:14.068311  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.068317  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.068321  4990 net.cpp:255] Memory required for data: 2321023488
I0612 11:05:14.068328  4990 layer_factory.hpp:77] Creating layer Convolution64
I0612 11:05:14.068339  4990 net.cpp:190] Creating Layer Convolution64
I0612 11:05:14.068343  4990 net.cpp:615] Convolution64 <- Eltwise31_ReLU63_0_split_0
I0612 11:05:14.068353  4990 net.cpp:589] Convolution64 -> Convolution64
I0612 11:05:14.068974  4990 net.cpp:240] Setting up Convolution64
I0612 11:05:14.068984  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.068987  4990 net.cpp:255] Memory required for data: 2325217792
I0612 11:05:14.068997  4990 layer_factory.hpp:77] Creating layer BatchNorm64
I0612 11:05:14.069008  4990 net.cpp:190] Creating Layer BatchNorm64
I0612 11:05:14.069013  4990 net.cpp:615] BatchNorm64 <- Convolution64
I0612 11:05:14.069020  4990 net.cpp:576] BatchNorm64 -> Convolution64 (in-place)
I0612 11:05:14.069242  4990 net.cpp:240] Setting up BatchNorm64
I0612 11:05:14.069250  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.069254  4990 net.cpp:255] Memory required for data: 2329412096
I0612 11:05:14.069267  4990 layer_factory.hpp:77] Creating layer Scale64
I0612 11:05:14.069275  4990 net.cpp:190] Creating Layer Scale64
I0612 11:05:14.069280  4990 net.cpp:615] Scale64 <- Convolution64
I0612 11:05:14.069286  4990 net.cpp:576] Scale64 -> Convolution64 (in-place)
I0612 11:05:14.069329  4990 layer_factory.hpp:77] Creating layer Scale64
I0612 11:05:14.069456  4990 net.cpp:240] Setting up Scale64
I0612 11:05:14.069465  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.069469  4990 net.cpp:255] Memory required for data: 2333606400
I0612 11:05:14.069481  4990 layer_factory.hpp:77] Creating layer ReLU64
I0612 11:05:14.069489  4990 net.cpp:190] Creating Layer ReLU64
I0612 11:05:14.069494  4990 net.cpp:615] ReLU64 <- Convolution64
I0612 11:05:14.069500  4990 net.cpp:576] ReLU64 -> Convolution64 (in-place)
I0612 11:05:14.069507  4990 net.cpp:240] Setting up ReLU64
I0612 11:05:14.069512  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.069516  4990 net.cpp:255] Memory required for data: 2337800704
I0612 11:05:14.069520  4990 layer_factory.hpp:77] Creating layer Convolution65
I0612 11:05:14.069533  4990 net.cpp:190] Creating Layer Convolution65
I0612 11:05:14.069537  4990 net.cpp:615] Convolution65 <- Convolution64
I0612 11:05:14.069547  4990 net.cpp:589] Convolution65 -> Convolution65
I0612 11:05:14.070166  4990 net.cpp:240] Setting up Convolution65
I0612 11:05:14.070176  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.070180  4990 net.cpp:255] Memory required for data: 2341995008
I0612 11:05:14.070190  4990 layer_factory.hpp:77] Creating layer BatchNorm65
I0612 11:05:14.070200  4990 net.cpp:190] Creating Layer BatchNorm65
I0612 11:05:14.070206  4990 net.cpp:615] BatchNorm65 <- Convolution65
I0612 11:05:14.070217  4990 net.cpp:576] BatchNorm65 -> Convolution65 (in-place)
I0612 11:05:14.070436  4990 net.cpp:240] Setting up BatchNorm65
I0612 11:05:14.070446  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.070449  4990 net.cpp:255] Memory required for data: 2346189312
I0612 11:05:14.070462  4990 layer_factory.hpp:77] Creating layer Scale65
I0612 11:05:14.070469  4990 net.cpp:190] Creating Layer Scale65
I0612 11:05:14.070474  4990 net.cpp:615] Scale65 <- Convolution65
I0612 11:05:14.070483  4990 net.cpp:576] Scale65 -> Convolution65 (in-place)
I0612 11:05:14.070520  4990 layer_factory.hpp:77] Creating layer Scale65
I0612 11:05:14.070649  4990 net.cpp:240] Setting up Scale65
I0612 11:05:14.070658  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.070662  4990 net.cpp:255] Memory required for data: 2350383616
I0612 11:05:14.070672  4990 layer_factory.hpp:77] Creating layer Eltwise32
I0612 11:05:14.070679  4990 net.cpp:190] Creating Layer Eltwise32
I0612 11:05:14.070684  4990 net.cpp:615] Eltwise32 <- Eltwise31_ReLU63_0_split_1
I0612 11:05:14.070690  4990 net.cpp:615] Eltwise32 <- Convolution65
I0612 11:05:14.070698  4990 net.cpp:589] Eltwise32 -> Eltwise32
I0612 11:05:14.070724  4990 net.cpp:240] Setting up Eltwise32
I0612 11:05:14.070732  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.070736  4990 net.cpp:255] Memory required for data: 2354577920
I0612 11:05:14.070740  4990 layer_factory.hpp:77] Creating layer ReLU65
I0612 11:05:14.070749  4990 net.cpp:190] Creating Layer ReLU65
I0612 11:05:14.070754  4990 net.cpp:615] ReLU65 <- Eltwise32
I0612 11:05:14.070760  4990 net.cpp:576] ReLU65 -> Eltwise32 (in-place)
I0612 11:05:14.070766  4990 net.cpp:240] Setting up ReLU65
I0612 11:05:14.070771  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.070775  4990 net.cpp:255] Memory required for data: 2358772224
I0612 11:05:14.070780  4990 layer_factory.hpp:77] Creating layer Eltwise32_ReLU65_0_split
I0612 11:05:14.070786  4990 net.cpp:190] Creating Layer Eltwise32_ReLU65_0_split
I0612 11:05:14.070790  4990 net.cpp:615] Eltwise32_ReLU65_0_split <- Eltwise32
I0612 11:05:14.070796  4990 net.cpp:589] Eltwise32_ReLU65_0_split -> Eltwise32_ReLU65_0_split_0
I0612 11:05:14.070806  4990 net.cpp:589] Eltwise32_ReLU65_0_split -> Eltwise32_ReLU65_0_split_1
I0612 11:05:14.070843  4990 net.cpp:240] Setting up Eltwise32_ReLU65_0_split
I0612 11:05:14.070850  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.070855  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.070859  4990 net.cpp:255] Memory required for data: 2367160832
I0612 11:05:14.070863  4990 layer_factory.hpp:77] Creating layer Convolution66
I0612 11:05:14.070876  4990 net.cpp:190] Creating Layer Convolution66
I0612 11:05:14.070881  4990 net.cpp:615] Convolution66 <- Eltwise32_ReLU65_0_split_0
I0612 11:05:14.070888  4990 net.cpp:589] Convolution66 -> Convolution66
I0612 11:05:14.072232  4990 net.cpp:240] Setting up Convolution66
I0612 11:05:14.072250  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.072254  4990 net.cpp:255] Memory required for data: 2371355136
I0612 11:05:14.072266  4990 layer_factory.hpp:77] Creating layer BatchNorm66
I0612 11:05:14.072275  4990 net.cpp:190] Creating Layer BatchNorm66
I0612 11:05:14.072280  4990 net.cpp:615] BatchNorm66 <- Convolution66
I0612 11:05:14.072293  4990 net.cpp:576] BatchNorm66 -> Convolution66 (in-place)
I0612 11:05:14.072515  4990 net.cpp:240] Setting up BatchNorm66
I0612 11:05:14.072523  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.072527  4990 net.cpp:255] Memory required for data: 2375549440
I0612 11:05:14.072540  4990 layer_factory.hpp:77] Creating layer Scale66
I0612 11:05:14.072548  4990 net.cpp:190] Creating Layer Scale66
I0612 11:05:14.072553  4990 net.cpp:615] Scale66 <- Convolution66
I0612 11:05:14.072559  4990 net.cpp:576] Scale66 -> Convolution66 (in-place)
I0612 11:05:14.072602  4990 layer_factory.hpp:77] Creating layer Scale66
I0612 11:05:14.072732  4990 net.cpp:240] Setting up Scale66
I0612 11:05:14.072741  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.072746  4990 net.cpp:255] Memory required for data: 2379743744
I0612 11:05:14.072756  4990 layer_factory.hpp:77] Creating layer ReLU66
I0612 11:05:14.072765  4990 net.cpp:190] Creating Layer ReLU66
I0612 11:05:14.072770  4990 net.cpp:615] ReLU66 <- Convolution66
I0612 11:05:14.072777  4990 net.cpp:576] ReLU66 -> Convolution66 (in-place)
I0612 11:05:14.072783  4990 net.cpp:240] Setting up ReLU66
I0612 11:05:14.072789  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.072793  4990 net.cpp:255] Memory required for data: 2383938048
I0612 11:05:14.072798  4990 layer_factory.hpp:77] Creating layer Convolution67
I0612 11:05:14.072810  4990 net.cpp:190] Creating Layer Convolution67
I0612 11:05:14.072815  4990 net.cpp:615] Convolution67 <- Convolution66
I0612 11:05:14.072823  4990 net.cpp:589] Convolution67 -> Convolution67
I0612 11:05:14.073454  4990 net.cpp:240] Setting up Convolution67
I0612 11:05:14.073464  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.073469  4990 net.cpp:255] Memory required for data: 2388132352
I0612 11:05:14.073479  4990 layer_factory.hpp:77] Creating layer BatchNorm67
I0612 11:05:14.073493  4990 net.cpp:190] Creating Layer BatchNorm67
I0612 11:05:14.073499  4990 net.cpp:615] BatchNorm67 <- Convolution67
I0612 11:05:14.073505  4990 net.cpp:576] BatchNorm67 -> Convolution67 (in-place)
I0612 11:05:14.073726  4990 net.cpp:240] Setting up BatchNorm67
I0612 11:05:14.073735  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.073740  4990 net.cpp:255] Memory required for data: 2392326656
I0612 11:05:14.073751  4990 layer_factory.hpp:77] Creating layer Scale67
I0612 11:05:14.073760  4990 net.cpp:190] Creating Layer Scale67
I0612 11:05:14.073765  4990 net.cpp:615] Scale67 <- Convolution67
I0612 11:05:14.073772  4990 net.cpp:576] Scale67 -> Convolution67 (in-place)
I0612 11:05:14.073810  4990 layer_factory.hpp:77] Creating layer Scale67
I0612 11:05:14.073942  4990 net.cpp:240] Setting up Scale67
I0612 11:05:14.073952  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.073956  4990 net.cpp:255] Memory required for data: 2396520960
I0612 11:05:14.073966  4990 layer_factory.hpp:77] Creating layer Eltwise33
I0612 11:05:14.073974  4990 net.cpp:190] Creating Layer Eltwise33
I0612 11:05:14.073981  4990 net.cpp:615] Eltwise33 <- Eltwise32_ReLU65_0_split_1
I0612 11:05:14.073985  4990 net.cpp:615] Eltwise33 <- Convolution67
I0612 11:05:14.073992  4990 net.cpp:589] Eltwise33 -> Eltwise33
I0612 11:05:14.074017  4990 net.cpp:240] Setting up Eltwise33
I0612 11:05:14.074024  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.074028  4990 net.cpp:255] Memory required for data: 2400715264
I0612 11:05:14.074033  4990 layer_factory.hpp:77] Creating layer ReLU67
I0612 11:05:14.074038  4990 net.cpp:190] Creating Layer ReLU67
I0612 11:05:14.074043  4990 net.cpp:615] ReLU67 <- Eltwise33
I0612 11:05:14.074053  4990 net.cpp:576] ReLU67 -> Eltwise33 (in-place)
I0612 11:05:14.074059  4990 net.cpp:240] Setting up ReLU67
I0612 11:05:14.074065  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.074069  4990 net.cpp:255] Memory required for data: 2404909568
I0612 11:05:14.074074  4990 layer_factory.hpp:77] Creating layer Eltwise33_ReLU67_0_split
I0612 11:05:14.074080  4990 net.cpp:190] Creating Layer Eltwise33_ReLU67_0_split
I0612 11:05:14.074084  4990 net.cpp:615] Eltwise33_ReLU67_0_split <- Eltwise33
I0612 11:05:14.074090  4990 net.cpp:589] Eltwise33_ReLU67_0_split -> Eltwise33_ReLU67_0_split_0
I0612 11:05:14.074097  4990 net.cpp:589] Eltwise33_ReLU67_0_split -> Eltwise33_ReLU67_0_split_1
I0612 11:05:14.074138  4990 net.cpp:240] Setting up Eltwise33_ReLU67_0_split
I0612 11:05:14.074146  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.074151  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.074154  4990 net.cpp:255] Memory required for data: 2413298176
I0612 11:05:14.074158  4990 layer_factory.hpp:77] Creating layer Convolution68
I0612 11:05:14.074170  4990 net.cpp:190] Creating Layer Convolution68
I0612 11:05:14.074175  4990 net.cpp:615] Convolution68 <- Eltwise33_ReLU67_0_split_0
I0612 11:05:14.074183  4990 net.cpp:589] Convolution68 -> Convolution68
I0612 11:05:14.074821  4990 net.cpp:240] Setting up Convolution68
I0612 11:05:14.074832  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.074836  4990 net.cpp:255] Memory required for data: 2417492480
I0612 11:05:14.074847  4990 layer_factory.hpp:77] Creating layer BatchNorm68
I0612 11:05:14.074857  4990 net.cpp:190] Creating Layer BatchNorm68
I0612 11:05:14.074862  4990 net.cpp:615] BatchNorm68 <- Convolution68
I0612 11:05:14.074870  4990 net.cpp:576] BatchNorm68 -> Convolution68 (in-place)
I0612 11:05:14.075083  4990 net.cpp:240] Setting up BatchNorm68
I0612 11:05:14.075091  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.075095  4990 net.cpp:255] Memory required for data: 2421686784
I0612 11:05:14.075108  4990 layer_factory.hpp:77] Creating layer Scale68
I0612 11:05:14.075119  4990 net.cpp:190] Creating Layer Scale68
I0612 11:05:14.075124  4990 net.cpp:615] Scale68 <- Convolution68
I0612 11:05:14.075129  4990 net.cpp:576] Scale68 -> Convolution68 (in-place)
I0612 11:05:14.075173  4990 layer_factory.hpp:77] Creating layer Scale68
I0612 11:05:14.075307  4990 net.cpp:240] Setting up Scale68
I0612 11:05:14.075316  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.075320  4990 net.cpp:255] Memory required for data: 2425881088
I0612 11:05:14.075330  4990 layer_factory.hpp:77] Creating layer ReLU68
I0612 11:05:14.075337  4990 net.cpp:190] Creating Layer ReLU68
I0612 11:05:14.075342  4990 net.cpp:615] ReLU68 <- Convolution68
I0612 11:05:14.075351  4990 net.cpp:576] ReLU68 -> Convolution68 (in-place)
I0612 11:05:14.075359  4990 net.cpp:240] Setting up ReLU68
I0612 11:05:14.075364  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.075368  4990 net.cpp:255] Memory required for data: 2430075392
I0612 11:05:14.075372  4990 layer_factory.hpp:77] Creating layer Convolution69
I0612 11:05:14.075384  4990 net.cpp:190] Creating Layer Convolution69
I0612 11:05:14.075389  4990 net.cpp:615] Convolution69 <- Convolution68
I0612 11:05:14.075397  4990 net.cpp:589] Convolution69 -> Convolution69
I0612 11:05:14.076022  4990 net.cpp:240] Setting up Convolution69
I0612 11:05:14.076032  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.076037  4990 net.cpp:255] Memory required for data: 2434269696
I0612 11:05:14.076047  4990 layer_factory.hpp:77] Creating layer BatchNorm69
I0612 11:05:14.076057  4990 net.cpp:190] Creating Layer BatchNorm69
I0612 11:05:14.076063  4990 net.cpp:615] BatchNorm69 <- Convolution69
I0612 11:05:14.076069  4990 net.cpp:576] BatchNorm69 -> Convolution69 (in-place)
I0612 11:05:14.076283  4990 net.cpp:240] Setting up BatchNorm69
I0612 11:05:14.076292  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.076295  4990 net.cpp:255] Memory required for data: 2438464000
I0612 11:05:14.076310  4990 layer_factory.hpp:77] Creating layer Scale69
I0612 11:05:14.076318  4990 net.cpp:190] Creating Layer Scale69
I0612 11:05:14.076323  4990 net.cpp:615] Scale69 <- Convolution69
I0612 11:05:14.076329  4990 net.cpp:576] Scale69 -> Convolution69 (in-place)
I0612 11:05:14.076369  4990 layer_factory.hpp:77] Creating layer Scale69
I0612 11:05:14.076514  4990 net.cpp:240] Setting up Scale69
I0612 11:05:14.076524  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.076527  4990 net.cpp:255] Memory required for data: 2442658304
I0612 11:05:14.076537  4990 layer_factory.hpp:77] Creating layer Eltwise34
I0612 11:05:14.076547  4990 net.cpp:190] Creating Layer Eltwise34
I0612 11:05:14.076553  4990 net.cpp:615] Eltwise34 <- Eltwise33_ReLU67_0_split_1
I0612 11:05:14.076560  4990 net.cpp:615] Eltwise34 <- Convolution69
I0612 11:05:14.076565  4990 net.cpp:589] Eltwise34 -> Eltwise34
I0612 11:05:14.076589  4990 net.cpp:240] Setting up Eltwise34
I0612 11:05:14.076596  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.076601  4990 net.cpp:255] Memory required for data: 2446852608
I0612 11:05:14.076604  4990 layer_factory.hpp:77] Creating layer ReLU69
I0612 11:05:14.076611  4990 net.cpp:190] Creating Layer ReLU69
I0612 11:05:14.076614  4990 net.cpp:615] ReLU69 <- Eltwise34
I0612 11:05:14.076620  4990 net.cpp:576] ReLU69 -> Eltwise34 (in-place)
I0612 11:05:14.076627  4990 net.cpp:240] Setting up ReLU69
I0612 11:05:14.076632  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.076637  4990 net.cpp:255] Memory required for data: 2451046912
I0612 11:05:14.076640  4990 layer_factory.hpp:77] Creating layer Eltwise34_ReLU69_0_split
I0612 11:05:14.076649  4990 net.cpp:190] Creating Layer Eltwise34_ReLU69_0_split
I0612 11:05:14.076654  4990 net.cpp:615] Eltwise34_ReLU69_0_split <- Eltwise34
I0612 11:05:14.076659  4990 net.cpp:589] Eltwise34_ReLU69_0_split -> Eltwise34_ReLU69_0_split_0
I0612 11:05:14.076668  4990 net.cpp:589] Eltwise34_ReLU69_0_split -> Eltwise34_ReLU69_0_split_1
I0612 11:05:14.076707  4990 net.cpp:240] Setting up Eltwise34_ReLU69_0_split
I0612 11:05:14.076714  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.076719  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.076727  4990 net.cpp:255] Memory required for data: 2459435520
I0612 11:05:14.076731  4990 layer_factory.hpp:77] Creating layer Convolution70
I0612 11:05:14.076741  4990 net.cpp:190] Creating Layer Convolution70
I0612 11:05:14.076746  4990 net.cpp:615] Convolution70 <- Eltwise34_ReLU69_0_split_0
I0612 11:05:14.076755  4990 net.cpp:589] Convolution70 -> Convolution70
I0612 11:05:14.077376  4990 net.cpp:240] Setting up Convolution70
I0612 11:05:14.077389  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.077392  4990 net.cpp:255] Memory required for data: 2463629824
I0612 11:05:14.077404  4990 layer_factory.hpp:77] Creating layer BatchNorm70
I0612 11:05:14.077410  4990 net.cpp:190] Creating Layer BatchNorm70
I0612 11:05:14.077415  4990 net.cpp:615] BatchNorm70 <- Convolution70
I0612 11:05:14.077425  4990 net.cpp:576] BatchNorm70 -> Convolution70 (in-place)
I0612 11:05:14.077648  4990 net.cpp:240] Setting up BatchNorm70
I0612 11:05:14.077658  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.077662  4990 net.cpp:255] Memory required for data: 2467824128
I0612 11:05:14.077675  4990 layer_factory.hpp:77] Creating layer Scale70
I0612 11:05:14.077683  4990 net.cpp:190] Creating Layer Scale70
I0612 11:05:14.077687  4990 net.cpp:615] Scale70 <- Convolution70
I0612 11:05:14.077694  4990 net.cpp:576] Scale70 -> Convolution70 (in-place)
I0612 11:05:14.077735  4990 layer_factory.hpp:77] Creating layer Scale70
I0612 11:05:14.077865  4990 net.cpp:240] Setting up Scale70
I0612 11:05:14.077874  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.077878  4990 net.cpp:255] Memory required for data: 2472018432
I0612 11:05:14.077888  4990 layer_factory.hpp:77] Creating layer ReLU70
I0612 11:05:14.077895  4990 net.cpp:190] Creating Layer ReLU70
I0612 11:05:14.077900  4990 net.cpp:615] ReLU70 <- Convolution70
I0612 11:05:14.077908  4990 net.cpp:576] ReLU70 -> Convolution70 (in-place)
I0612 11:05:14.077916  4990 net.cpp:240] Setting up ReLU70
I0612 11:05:14.077921  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.077925  4990 net.cpp:255] Memory required for data: 2476212736
I0612 11:05:14.077929  4990 layer_factory.hpp:77] Creating layer Convolution71
I0612 11:05:14.077942  4990 net.cpp:190] Creating Layer Convolution71
I0612 11:05:14.077946  4990 net.cpp:615] Convolution71 <- Convolution70
I0612 11:05:14.077953  4990 net.cpp:589] Convolution71 -> Convolution71
I0612 11:05:14.078596  4990 net.cpp:240] Setting up Convolution71
I0612 11:05:14.078608  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.078611  4990 net.cpp:255] Memory required for data: 2480407040
I0612 11:05:14.078621  4990 layer_factory.hpp:77] Creating layer BatchNorm71
I0612 11:05:14.078629  4990 net.cpp:190] Creating Layer BatchNorm71
I0612 11:05:14.078634  4990 net.cpp:615] BatchNorm71 <- Convolution71
I0612 11:05:14.078641  4990 net.cpp:576] BatchNorm71 -> Convolution71 (in-place)
I0612 11:05:14.078847  4990 net.cpp:240] Setting up BatchNorm71
I0612 11:05:14.078855  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.078860  4990 net.cpp:255] Memory required for data: 2484601344
I0612 11:05:14.078871  4990 layer_factory.hpp:77] Creating layer Scale71
I0612 11:05:14.078878  4990 net.cpp:190] Creating Layer Scale71
I0612 11:05:14.078882  4990 net.cpp:615] Scale71 <- Convolution71
I0612 11:05:14.078888  4990 net.cpp:576] Scale71 -> Convolution71 (in-place)
I0612 11:05:14.078927  4990 layer_factory.hpp:77] Creating layer Scale71
I0612 11:05:14.079053  4990 net.cpp:240] Setting up Scale71
I0612 11:05:14.079061  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.079066  4990 net.cpp:255] Memory required for data: 2488795648
I0612 11:05:14.079074  4990 layer_factory.hpp:77] Creating layer Eltwise35
I0612 11:05:14.079083  4990 net.cpp:190] Creating Layer Eltwise35
I0612 11:05:14.079089  4990 net.cpp:615] Eltwise35 <- Eltwise34_ReLU69_0_split_1
I0612 11:05:14.079094  4990 net.cpp:615] Eltwise35 <- Convolution71
I0612 11:05:14.079104  4990 net.cpp:589] Eltwise35 -> Eltwise35
I0612 11:05:14.079125  4990 net.cpp:240] Setting up Eltwise35
I0612 11:05:14.079133  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.079136  4990 net.cpp:255] Memory required for data: 2492989952
I0612 11:05:14.079140  4990 layer_factory.hpp:77] Creating layer ReLU71
I0612 11:05:14.079152  4990 net.cpp:190] Creating Layer ReLU71
I0612 11:05:14.079156  4990 net.cpp:615] ReLU71 <- Eltwise35
I0612 11:05:14.079164  4990 net.cpp:576] ReLU71 -> Eltwise35 (in-place)
I0612 11:05:14.079171  4990 net.cpp:240] Setting up ReLU71
I0612 11:05:14.079176  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.079180  4990 net.cpp:255] Memory required for data: 2497184256
I0612 11:05:14.079185  4990 layer_factory.hpp:77] Creating layer Eltwise35_ReLU71_0_split
I0612 11:05:14.079190  4990 net.cpp:190] Creating Layer Eltwise35_ReLU71_0_split
I0612 11:05:14.079195  4990 net.cpp:615] Eltwise35_ReLU71_0_split <- Eltwise35
I0612 11:05:14.079200  4990 net.cpp:589] Eltwise35_ReLU71_0_split -> Eltwise35_ReLU71_0_split_0
I0612 11:05:14.079207  4990 net.cpp:589] Eltwise35_ReLU71_0_split -> Eltwise35_ReLU71_0_split_1
I0612 11:05:14.079247  4990 net.cpp:240] Setting up Eltwise35_ReLU71_0_split
I0612 11:05:14.079254  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.079259  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.079262  4990 net.cpp:255] Memory required for data: 2505572864
I0612 11:05:14.079267  4990 layer_factory.hpp:77] Creating layer Convolution72
I0612 11:05:14.079278  4990 net.cpp:190] Creating Layer Convolution72
I0612 11:05:14.079283  4990 net.cpp:615] Convolution72 <- Eltwise35_ReLU71_0_split_0
I0612 11:05:14.079291  4990 net.cpp:589] Convolution72 -> Convolution72
I0612 11:05:14.079895  4990 net.cpp:240] Setting up Convolution72
I0612 11:05:14.079903  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.079908  4990 net.cpp:255] Memory required for data: 2509767168
I0612 11:05:14.079918  4990 layer_factory.hpp:77] Creating layer BatchNorm72
I0612 11:05:14.079927  4990 net.cpp:190] Creating Layer BatchNorm72
I0612 11:05:14.079932  4990 net.cpp:615] BatchNorm72 <- Convolution72
I0612 11:05:14.079941  4990 net.cpp:576] BatchNorm72 -> Convolution72 (in-place)
I0612 11:05:14.080148  4990 net.cpp:240] Setting up BatchNorm72
I0612 11:05:14.080157  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.080160  4990 net.cpp:255] Memory required for data: 2513961472
I0612 11:05:14.080173  4990 layer_factory.hpp:77] Creating layer Scale72
I0612 11:05:14.080183  4990 net.cpp:190] Creating Layer Scale72
I0612 11:05:14.080188  4990 net.cpp:615] Scale72 <- Convolution72
I0612 11:05:14.080193  4990 net.cpp:576] Scale72 -> Convolution72 (in-place)
I0612 11:05:14.080229  4990 layer_factory.hpp:77] Creating layer Scale72
I0612 11:05:14.080355  4990 net.cpp:240] Setting up Scale72
I0612 11:05:14.080363  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.080368  4990 net.cpp:255] Memory required for data: 2518155776
I0612 11:05:14.080377  4990 layer_factory.hpp:77] Creating layer ReLU72
I0612 11:05:14.080384  4990 net.cpp:190] Creating Layer ReLU72
I0612 11:05:14.080389  4990 net.cpp:615] ReLU72 <- Convolution72
I0612 11:05:14.080396  4990 net.cpp:576] ReLU72 -> Convolution72 (in-place)
I0612 11:05:14.080404  4990 net.cpp:240] Setting up ReLU72
I0612 11:05:14.080409  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.080412  4990 net.cpp:255] Memory required for data: 2522350080
I0612 11:05:14.080416  4990 layer_factory.hpp:77] Creating layer Convolution73
I0612 11:05:14.080428  4990 net.cpp:190] Creating Layer Convolution73
I0612 11:05:14.080432  4990 net.cpp:615] Convolution73 <- Convolution72
I0612 11:05:14.080440  4990 net.cpp:589] Convolution73 -> Convolution73
I0612 11:05:14.081037  4990 net.cpp:240] Setting up Convolution73
I0612 11:05:14.081046  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.081050  4990 net.cpp:255] Memory required for data: 2526544384
I0612 11:05:14.081064  4990 layer_factory.hpp:77] Creating layer BatchNorm73
I0612 11:05:14.081075  4990 net.cpp:190] Creating Layer BatchNorm73
I0612 11:05:14.081082  4990 net.cpp:615] BatchNorm73 <- Convolution73
I0612 11:05:14.081089  4990 net.cpp:576] BatchNorm73 -> Convolution73 (in-place)
I0612 11:05:14.081297  4990 net.cpp:240] Setting up BatchNorm73
I0612 11:05:14.081305  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.081310  4990 net.cpp:255] Memory required for data: 2530738688
I0612 11:05:14.081321  4990 layer_factory.hpp:77] Creating layer Scale73
I0612 11:05:14.081331  4990 net.cpp:190] Creating Layer Scale73
I0612 11:05:14.081336  4990 net.cpp:615] Scale73 <- Convolution73
I0612 11:05:14.081341  4990 net.cpp:576] Scale73 -> Convolution73 (in-place)
I0612 11:05:14.081379  4990 layer_factory.hpp:77] Creating layer Scale73
I0612 11:05:14.081506  4990 net.cpp:240] Setting up Scale73
I0612 11:05:14.081513  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.081517  4990 net.cpp:255] Memory required for data: 2534932992
I0612 11:05:14.081526  4990 layer_factory.hpp:77] Creating layer Eltwise36
I0612 11:05:14.081538  4990 net.cpp:190] Creating Layer Eltwise36
I0612 11:05:14.081544  4990 net.cpp:615] Eltwise36 <- Eltwise35_ReLU71_0_split_1
I0612 11:05:14.081549  4990 net.cpp:615] Eltwise36 <- Convolution73
I0612 11:05:14.081555  4990 net.cpp:589] Eltwise36 -> Eltwise36
I0612 11:05:14.081579  4990 net.cpp:240] Setting up Eltwise36
I0612 11:05:14.081588  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.081590  4990 net.cpp:255] Memory required for data: 2539127296
I0612 11:05:14.081594  4990 layer_factory.hpp:77] Creating layer ReLU73
I0612 11:05:14.081601  4990 net.cpp:190] Creating Layer ReLU73
I0612 11:05:14.081605  4990 net.cpp:615] ReLU73 <- Eltwise36
I0612 11:05:14.081610  4990 net.cpp:576] ReLU73 -> Eltwise36 (in-place)
I0612 11:05:14.081617  4990 net.cpp:240] Setting up ReLU73
I0612 11:05:14.081622  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.081626  4990 net.cpp:255] Memory required for data: 2543321600
I0612 11:05:14.081629  4990 layer_factory.hpp:77] Creating layer Eltwise36_ReLU73_0_split
I0612 11:05:14.081635  4990 net.cpp:190] Creating Layer Eltwise36_ReLU73_0_split
I0612 11:05:14.081640  4990 net.cpp:615] Eltwise36_ReLU73_0_split <- Eltwise36
I0612 11:05:14.081647  4990 net.cpp:589] Eltwise36_ReLU73_0_split -> Eltwise36_ReLU73_0_split_0
I0612 11:05:14.081655  4990 net.cpp:589] Eltwise36_ReLU73_0_split -> Eltwise36_ReLU73_0_split_1
I0612 11:05:14.081694  4990 net.cpp:240] Setting up Eltwise36_ReLU73_0_split
I0612 11:05:14.081701  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.081707  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.081710  4990 net.cpp:255] Memory required for data: 2551710208
I0612 11:05:14.081714  4990 layer_factory.hpp:77] Creating layer Pooling2
I0612 11:05:14.081722  4990 net.cpp:190] Creating Layer Pooling2
I0612 11:05:14.081725  4990 net.cpp:615] Pooling2 <- Eltwise36_ReLU73_0_split_0
I0612 11:05:14.081732  4990 net.cpp:589] Pooling2 -> Pooling2
I0612 11:05:14.081756  4990 net.cpp:240] Setting up Pooling2
I0612 11:05:14.081763  4990 net.cpp:247] Top shape: 128 32 8 8 (262144)
I0612 11:05:14.081766  4990 net.cpp:255] Memory required for data: 2552758784
I0612 11:05:14.081770  4990 layer_factory.hpp:77] Creating layer Input2
I0612 11:05:14.081780  4990 net.cpp:190] Creating Layer Input2
I0612 11:05:14.081786  4990 net.cpp:589] Input2 -> Input2
I0612 11:05:14.081811  4990 net.cpp:240] Setting up Input2
I0612 11:05:14.081818  4990 net.cpp:247] Top shape: 128 32 8 8 (262144)
I0612 11:05:14.081821  4990 net.cpp:255] Memory required for data: 2553807360
I0612 11:05:14.081825  4990 layer_factory.hpp:77] Creating layer Concat2
I0612 11:05:14.081832  4990 net.cpp:190] Creating Layer Concat2
I0612 11:05:14.081836  4990 net.cpp:615] Concat2 <- Pooling2
I0612 11:05:14.081841  4990 net.cpp:615] Concat2 <- Input2
I0612 11:05:14.081851  4990 net.cpp:589] Concat2 -> Concat2
I0612 11:05:14.081881  4990 net.cpp:240] Setting up Concat2
I0612 11:05:14.081889  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.081893  4990 net.cpp:255] Memory required for data: 2555904512
I0612 11:05:14.081897  4990 layer_factory.hpp:77] Creating layer Convolution74
I0612 11:05:14.081912  4990 net.cpp:190] Creating Layer Convolution74
I0612 11:05:14.081917  4990 net.cpp:615] Convolution74 <- Eltwise36_ReLU73_0_split_1
I0612 11:05:14.081923  4990 net.cpp:589] Convolution74 -> Convolution74
I0612 11:05:14.083559  4990 net.cpp:240] Setting up Convolution74
I0612 11:05:14.083576  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.083580  4990 net.cpp:255] Memory required for data: 2558001664
I0612 11:05:14.083648  4990 layer_factory.hpp:77] Creating layer BatchNorm74
I0612 11:05:14.083660  4990 net.cpp:190] Creating Layer BatchNorm74
I0612 11:05:14.083667  4990 net.cpp:615] BatchNorm74 <- Convolution74
I0612 11:05:14.083673  4990 net.cpp:576] BatchNorm74 -> Convolution74 (in-place)
I0612 11:05:14.083900  4990 net.cpp:240] Setting up BatchNorm74
I0612 11:05:14.083909  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.083914  4990 net.cpp:255] Memory required for data: 2560098816
I0612 11:05:14.083928  4990 layer_factory.hpp:77] Creating layer Scale74
I0612 11:05:14.083936  4990 net.cpp:190] Creating Layer Scale74
I0612 11:05:14.083941  4990 net.cpp:615] Scale74 <- Convolution74
I0612 11:05:14.083947  4990 net.cpp:576] Scale74 -> Convolution74 (in-place)
I0612 11:05:14.083989  4990 layer_factory.hpp:77] Creating layer Scale74
I0612 11:05:14.084117  4990 net.cpp:240] Setting up Scale74
I0612 11:05:14.084128  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.084132  4990 net.cpp:255] Memory required for data: 2562195968
I0612 11:05:14.084142  4990 layer_factory.hpp:77] Creating layer ReLU74
I0612 11:05:14.084151  4990 net.cpp:190] Creating Layer ReLU74
I0612 11:05:14.084154  4990 net.cpp:615] ReLU74 <- Convolution74
I0612 11:05:14.084161  4990 net.cpp:576] ReLU74 -> Convolution74 (in-place)
I0612 11:05:14.084167  4990 net.cpp:240] Setting up ReLU74
I0612 11:05:14.084173  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.084177  4990 net.cpp:255] Memory required for data: 2564293120
I0612 11:05:14.084180  4990 layer_factory.hpp:77] Creating layer Convolution75
I0612 11:05:14.084197  4990 net.cpp:190] Creating Layer Convolution75
I0612 11:05:14.084202  4990 net.cpp:615] Convolution75 <- Convolution74
I0612 11:05:14.084210  4990 net.cpp:589] Convolution75 -> Convolution75
I0612 11:05:14.085834  4990 net.cpp:240] Setting up Convolution75
I0612 11:05:14.085845  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.085850  4990 net.cpp:255] Memory required for data: 2566390272
I0612 11:05:14.085860  4990 layer_factory.hpp:77] Creating layer BatchNorm75
I0612 11:05:14.085870  4990 net.cpp:190] Creating Layer BatchNorm75
I0612 11:05:14.085875  4990 net.cpp:615] BatchNorm75 <- Convolution75
I0612 11:05:14.085882  4990 net.cpp:576] BatchNorm75 -> Convolution75 (in-place)
I0612 11:05:14.086097  4990 net.cpp:240] Setting up BatchNorm75
I0612 11:05:14.086104  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.086108  4990 net.cpp:255] Memory required for data: 2568487424
I0612 11:05:14.086122  4990 layer_factory.hpp:77] Creating layer Scale75
I0612 11:05:14.086130  4990 net.cpp:190] Creating Layer Scale75
I0612 11:05:14.086134  4990 net.cpp:615] Scale75 <- Convolution75
I0612 11:05:14.086140  4990 net.cpp:576] Scale75 -> Convolution75 (in-place)
I0612 11:05:14.086182  4990 layer_factory.hpp:77] Creating layer Scale75
I0612 11:05:14.086311  4990 net.cpp:240] Setting up Scale75
I0612 11:05:14.086319  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.086323  4990 net.cpp:255] Memory required for data: 2570584576
I0612 11:05:14.086335  4990 layer_factory.hpp:77] Creating layer Eltwise37
I0612 11:05:14.086344  4990 net.cpp:190] Creating Layer Eltwise37
I0612 11:05:14.086349  4990 net.cpp:615] Eltwise37 <- Concat2
I0612 11:05:14.086360  4990 net.cpp:615] Eltwise37 <- Convolution75
I0612 11:05:14.086374  4990 net.cpp:589] Eltwise37 -> Eltwise37
I0612 11:05:14.086397  4990 net.cpp:240] Setting up Eltwise37
I0612 11:05:14.086405  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.086408  4990 net.cpp:255] Memory required for data: 2572681728
I0612 11:05:14.086412  4990 layer_factory.hpp:77] Creating layer ReLU75
I0612 11:05:14.086419  4990 net.cpp:190] Creating Layer ReLU75
I0612 11:05:14.086423  4990 net.cpp:615] ReLU75 <- Eltwise37
I0612 11:05:14.086431  4990 net.cpp:576] ReLU75 -> Eltwise37 (in-place)
I0612 11:05:14.086438  4990 net.cpp:240] Setting up ReLU75
I0612 11:05:14.086443  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.086447  4990 net.cpp:255] Memory required for data: 2574778880
I0612 11:05:14.086452  4990 layer_factory.hpp:77] Creating layer Eltwise37_ReLU75_0_split
I0612 11:05:14.086457  4990 net.cpp:190] Creating Layer Eltwise37_ReLU75_0_split
I0612 11:05:14.086462  4990 net.cpp:615] Eltwise37_ReLU75_0_split <- Eltwise37
I0612 11:05:14.086467  4990 net.cpp:589] Eltwise37_ReLU75_0_split -> Eltwise37_ReLU75_0_split_0
I0612 11:05:14.086474  4990 net.cpp:589] Eltwise37_ReLU75_0_split -> Eltwise37_ReLU75_0_split_1
I0612 11:05:14.086519  4990 net.cpp:240] Setting up Eltwise37_ReLU75_0_split
I0612 11:05:14.086526  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.086531  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.086535  4990 net.cpp:255] Memory required for data: 2578973184
I0612 11:05:14.086539  4990 layer_factory.hpp:77] Creating layer Convolution76
I0612 11:05:14.086549  4990 net.cpp:190] Creating Layer Convolution76
I0612 11:05:14.086554  4990 net.cpp:615] Convolution76 <- Eltwise37_ReLU75_0_split_0
I0612 11:05:14.086563  4990 net.cpp:589] Convolution76 -> Convolution76
I0612 11:05:14.088187  4990 net.cpp:240] Setting up Convolution76
I0612 11:05:14.088198  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.088202  4990 net.cpp:255] Memory required for data: 2581070336
I0612 11:05:14.088212  4990 layer_factory.hpp:77] Creating layer BatchNorm76
I0612 11:05:14.088219  4990 net.cpp:190] Creating Layer BatchNorm76
I0612 11:05:14.088224  4990 net.cpp:615] BatchNorm76 <- Convolution76
I0612 11:05:14.088232  4990 net.cpp:576] BatchNorm76 -> Convolution76 (in-place)
I0612 11:05:14.088449  4990 net.cpp:240] Setting up BatchNorm76
I0612 11:05:14.088459  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.088462  4990 net.cpp:255] Memory required for data: 2583167488
I0612 11:05:14.088474  4990 layer_factory.hpp:77] Creating layer Scale76
I0612 11:05:14.088485  4990 net.cpp:190] Creating Layer Scale76
I0612 11:05:14.088490  4990 net.cpp:615] Scale76 <- Convolution76
I0612 11:05:14.088496  4990 net.cpp:576] Scale76 -> Convolution76 (in-place)
I0612 11:05:14.088534  4990 layer_factory.hpp:77] Creating layer Scale76
I0612 11:05:14.088667  4990 net.cpp:240] Setting up Scale76
I0612 11:05:14.088675  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.088678  4990 net.cpp:255] Memory required for data: 2585264640
I0612 11:05:14.088688  4990 layer_factory.hpp:77] Creating layer ReLU76
I0612 11:05:14.088696  4990 net.cpp:190] Creating Layer ReLU76
I0612 11:05:14.088699  4990 net.cpp:615] ReLU76 <- Convolution76
I0612 11:05:14.088708  4990 net.cpp:576] ReLU76 -> Convolution76 (in-place)
I0612 11:05:14.088716  4990 net.cpp:240] Setting up ReLU76
I0612 11:05:14.088721  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.088724  4990 net.cpp:255] Memory required for data: 2587361792
I0612 11:05:14.088728  4990 layer_factory.hpp:77] Creating layer Convolution77
I0612 11:05:14.088740  4990 net.cpp:190] Creating Layer Convolution77
I0612 11:05:14.088745  4990 net.cpp:615] Convolution77 <- Convolution76
I0612 11:05:14.088752  4990 net.cpp:589] Convolution77 -> Convolution77
I0612 11:05:14.090397  4990 net.cpp:240] Setting up Convolution77
I0612 11:05:14.090407  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.090411  4990 net.cpp:255] Memory required for data: 2589458944
I0612 11:05:14.090425  4990 layer_factory.hpp:77] Creating layer BatchNorm77
I0612 11:05:14.090435  4990 net.cpp:190] Creating Layer BatchNorm77
I0612 11:05:14.090440  4990 net.cpp:615] BatchNorm77 <- Convolution77
I0612 11:05:14.090446  4990 net.cpp:576] BatchNorm77 -> Convolution77 (in-place)
I0612 11:05:14.090662  4990 net.cpp:240] Setting up BatchNorm77
I0612 11:05:14.090670  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.090674  4990 net.cpp:255] Memory required for data: 2591556096
I0612 11:05:14.090687  4990 layer_factory.hpp:77] Creating layer Scale77
I0612 11:05:14.090693  4990 net.cpp:190] Creating Layer Scale77
I0612 11:05:14.090698  4990 net.cpp:615] Scale77 <- Convolution77
I0612 11:05:14.090703  4990 net.cpp:576] Scale77 -> Convolution77 (in-place)
I0612 11:05:14.090745  4990 layer_factory.hpp:77] Creating layer Scale77
I0612 11:05:14.090873  4990 net.cpp:240] Setting up Scale77
I0612 11:05:14.090881  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.090885  4990 net.cpp:255] Memory required for data: 2593653248
I0612 11:05:14.090894  4990 layer_factory.hpp:77] Creating layer Eltwise38
I0612 11:05:14.090904  4990 net.cpp:190] Creating Layer Eltwise38
I0612 11:05:14.090909  4990 net.cpp:615] Eltwise38 <- Eltwise37_ReLU75_0_split_1
I0612 11:05:14.090915  4990 net.cpp:615] Eltwise38 <- Convolution77
I0612 11:05:14.090921  4990 net.cpp:589] Eltwise38 -> Eltwise38
I0612 11:05:14.090942  4990 net.cpp:240] Setting up Eltwise38
I0612 11:05:14.090948  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.090952  4990 net.cpp:255] Memory required for data: 2595750400
I0612 11:05:14.090956  4990 layer_factory.hpp:77] Creating layer ReLU77
I0612 11:05:14.090965  4990 net.cpp:190] Creating Layer ReLU77
I0612 11:05:14.090970  4990 net.cpp:615] ReLU77 <- Eltwise38
I0612 11:05:14.090977  4990 net.cpp:576] ReLU77 -> Eltwise38 (in-place)
I0612 11:05:14.090984  4990 net.cpp:240] Setting up ReLU77
I0612 11:05:14.090989  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.090993  4990 net.cpp:255] Memory required for data: 2597847552
I0612 11:05:14.090997  4990 layer_factory.hpp:77] Creating layer Eltwise38_ReLU77_0_split
I0612 11:05:14.091003  4990 net.cpp:190] Creating Layer Eltwise38_ReLU77_0_split
I0612 11:05:14.091007  4990 net.cpp:615] Eltwise38_ReLU77_0_split <- Eltwise38
I0612 11:05:14.091012  4990 net.cpp:589] Eltwise38_ReLU77_0_split -> Eltwise38_ReLU77_0_split_0
I0612 11:05:14.091019  4990 net.cpp:589] Eltwise38_ReLU77_0_split -> Eltwise38_ReLU77_0_split_1
I0612 11:05:14.091059  4990 net.cpp:240] Setting up Eltwise38_ReLU77_0_split
I0612 11:05:14.091066  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.091071  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.091075  4990 net.cpp:255] Memory required for data: 2602041856
I0612 11:05:14.091079  4990 layer_factory.hpp:77] Creating layer Convolution78
I0612 11:05:14.091090  4990 net.cpp:190] Creating Layer Convolution78
I0612 11:05:14.091095  4990 net.cpp:615] Convolution78 <- Eltwise38_ReLU77_0_split_0
I0612 11:05:14.091104  4990 net.cpp:589] Convolution78 -> Convolution78
I0612 11:05:14.092730  4990 net.cpp:240] Setting up Convolution78
I0612 11:05:14.092741  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.092746  4990 net.cpp:255] Memory required for data: 2604139008
I0612 11:05:14.092757  4990 layer_factory.hpp:77] Creating layer BatchNorm78
I0612 11:05:14.092767  4990 net.cpp:190] Creating Layer BatchNorm78
I0612 11:05:14.092772  4990 net.cpp:615] BatchNorm78 <- Convolution78
I0612 11:05:14.092780  4990 net.cpp:576] BatchNorm78 -> Convolution78 (in-place)
I0612 11:05:14.092993  4990 net.cpp:240] Setting up BatchNorm78
I0612 11:05:14.093000  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.093004  4990 net.cpp:255] Memory required for data: 2606236160
I0612 11:05:14.093017  4990 layer_factory.hpp:77] Creating layer Scale78
I0612 11:05:14.093025  4990 net.cpp:190] Creating Layer Scale78
I0612 11:05:14.093030  4990 net.cpp:615] Scale78 <- Convolution78
I0612 11:05:14.093039  4990 net.cpp:576] Scale78 -> Convolution78 (in-place)
I0612 11:05:14.093080  4990 layer_factory.hpp:77] Creating layer Scale78
I0612 11:05:14.093209  4990 net.cpp:240] Setting up Scale78
I0612 11:05:14.093217  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.093221  4990 net.cpp:255] Memory required for data: 2608333312
I0612 11:05:14.093232  4990 layer_factory.hpp:77] Creating layer ReLU78
I0612 11:05:14.093240  4990 net.cpp:190] Creating Layer ReLU78
I0612 11:05:14.093245  4990 net.cpp:615] ReLU78 <- Convolution78
I0612 11:05:14.093252  4990 net.cpp:576] ReLU78 -> Convolution78 (in-place)
I0612 11:05:14.093260  4990 net.cpp:240] Setting up ReLU78
I0612 11:05:14.093264  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.093268  4990 net.cpp:255] Memory required for data: 2610430464
I0612 11:05:14.093272  4990 layer_factory.hpp:77] Creating layer Convolution79
I0612 11:05:14.093282  4990 net.cpp:190] Creating Layer Convolution79
I0612 11:05:14.093286  4990 net.cpp:615] Convolution79 <- Convolution78
I0612 11:05:14.093296  4990 net.cpp:589] Convolution79 -> Convolution79
I0612 11:05:14.094914  4990 net.cpp:240] Setting up Convolution79
I0612 11:05:14.094925  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.094929  4990 net.cpp:255] Memory required for data: 2612527616
I0612 11:05:14.094938  4990 layer_factory.hpp:77] Creating layer BatchNorm79
I0612 11:05:14.094946  4990 net.cpp:190] Creating Layer BatchNorm79
I0612 11:05:14.094950  4990 net.cpp:615] BatchNorm79 <- Convolution79
I0612 11:05:14.094959  4990 net.cpp:576] BatchNorm79 -> Convolution79 (in-place)
I0612 11:05:14.095175  4990 net.cpp:240] Setting up BatchNorm79
I0612 11:05:14.095185  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.095187  4990 net.cpp:255] Memory required for data: 2614624768
I0612 11:05:14.095199  4990 layer_factory.hpp:77] Creating layer Scale79
I0612 11:05:14.095206  4990 net.cpp:190] Creating Layer Scale79
I0612 11:05:14.095211  4990 net.cpp:615] Scale79 <- Convolution79
I0612 11:05:14.095218  4990 net.cpp:576] Scale79 -> Convolution79 (in-place)
I0612 11:05:14.095257  4990 layer_factory.hpp:77] Creating layer Scale79
I0612 11:05:14.095386  4990 net.cpp:240] Setting up Scale79
I0612 11:05:14.095396  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.095398  4990 net.cpp:255] Memory required for data: 2616721920
I0612 11:05:14.095408  4990 layer_factory.hpp:77] Creating layer Eltwise39
I0612 11:05:14.095415  4990 net.cpp:190] Creating Layer Eltwise39
I0612 11:05:14.095420  4990 net.cpp:615] Eltwise39 <- Eltwise38_ReLU77_0_split_1
I0612 11:05:14.095427  4990 net.cpp:615] Eltwise39 <- Convolution79
I0612 11:05:14.095434  4990 net.cpp:589] Eltwise39 -> Eltwise39
I0612 11:05:14.095456  4990 net.cpp:240] Setting up Eltwise39
I0612 11:05:14.095463  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.095466  4990 net.cpp:255] Memory required for data: 2618819072
I0612 11:05:14.095470  4990 layer_factory.hpp:77] Creating layer ReLU79
I0612 11:05:14.095479  4990 net.cpp:190] Creating Layer ReLU79
I0612 11:05:14.095484  4990 net.cpp:615] ReLU79 <- Eltwise39
I0612 11:05:14.095489  4990 net.cpp:576] ReLU79 -> Eltwise39 (in-place)
I0612 11:05:14.095495  4990 net.cpp:240] Setting up ReLU79
I0612 11:05:14.095500  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.095504  4990 net.cpp:255] Memory required for data: 2620916224
I0612 11:05:14.095509  4990 layer_factory.hpp:77] Creating layer Eltwise39_ReLU79_0_split
I0612 11:05:14.095515  4990 net.cpp:190] Creating Layer Eltwise39_ReLU79_0_split
I0612 11:05:14.095518  4990 net.cpp:615] Eltwise39_ReLU79_0_split <- Eltwise39
I0612 11:05:14.095527  4990 net.cpp:589] Eltwise39_ReLU79_0_split -> Eltwise39_ReLU79_0_split_0
I0612 11:05:14.095535  4990 net.cpp:589] Eltwise39_ReLU79_0_split -> Eltwise39_ReLU79_0_split_1
I0612 11:05:14.095571  4990 net.cpp:240] Setting up Eltwise39_ReLU79_0_split
I0612 11:05:14.095578  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.095587  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.095590  4990 net.cpp:255] Memory required for data: 2625110528
I0612 11:05:14.095594  4990 layer_factory.hpp:77] Creating layer Convolution80
I0612 11:05:14.095607  4990 net.cpp:190] Creating Layer Convolution80
I0612 11:05:14.095612  4990 net.cpp:615] Convolution80 <- Eltwise39_ReLU79_0_split_0
I0612 11:05:14.095619  4990 net.cpp:589] Convolution80 -> Convolution80
I0612 11:05:14.097236  4990 net.cpp:240] Setting up Convolution80
I0612 11:05:14.097246  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.097250  4990 net.cpp:255] Memory required for data: 2627207680
I0612 11:05:14.097260  4990 layer_factory.hpp:77] Creating layer BatchNorm80
I0612 11:05:14.097270  4990 net.cpp:190] Creating Layer BatchNorm80
I0612 11:05:14.097275  4990 net.cpp:615] BatchNorm80 <- Convolution80
I0612 11:05:14.097281  4990 net.cpp:576] BatchNorm80 -> Convolution80 (in-place)
I0612 11:05:14.097496  4990 net.cpp:240] Setting up BatchNorm80
I0612 11:05:14.097503  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.097507  4990 net.cpp:255] Memory required for data: 2629304832
I0612 11:05:14.097519  4990 layer_factory.hpp:77] Creating layer Scale80
I0612 11:05:14.097527  4990 net.cpp:190] Creating Layer Scale80
I0612 11:05:14.097532  4990 net.cpp:615] Scale80 <- Convolution80
I0612 11:05:14.097537  4990 net.cpp:576] Scale80 -> Convolution80 (in-place)
I0612 11:05:14.097579  4990 layer_factory.hpp:77] Creating layer Scale80
I0612 11:05:14.097709  4990 net.cpp:240] Setting up Scale80
I0612 11:05:14.097718  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.097720  4990 net.cpp:255] Memory required for data: 2631401984
I0612 11:05:14.097730  4990 layer_factory.hpp:77] Creating layer ReLU80
I0612 11:05:14.097739  4990 net.cpp:190] Creating Layer ReLU80
I0612 11:05:14.097744  4990 net.cpp:615] ReLU80 <- Convolution80
I0612 11:05:14.097749  4990 net.cpp:576] ReLU80 -> Convolution80 (in-place)
I0612 11:05:14.097756  4990 net.cpp:240] Setting up ReLU80
I0612 11:05:14.097761  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.097765  4990 net.cpp:255] Memory required for data: 2633499136
I0612 11:05:14.097769  4990 layer_factory.hpp:77] Creating layer Convolution81
I0612 11:05:14.097781  4990 net.cpp:190] Creating Layer Convolution81
I0612 11:05:14.097785  4990 net.cpp:615] Convolution81 <- Convolution80
I0612 11:05:14.097795  4990 net.cpp:589] Convolution81 -> Convolution81
I0612 11:05:14.100096  4990 net.cpp:240] Setting up Convolution81
I0612 11:05:14.100113  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.100117  4990 net.cpp:255] Memory required for data: 2635596288
I0612 11:05:14.100128  4990 layer_factory.hpp:77] Creating layer BatchNorm81
I0612 11:05:14.100139  4990 net.cpp:190] Creating Layer BatchNorm81
I0612 11:05:14.100144  4990 net.cpp:615] BatchNorm81 <- Convolution81
I0612 11:05:14.100152  4990 net.cpp:576] BatchNorm81 -> Convolution81 (in-place)
I0612 11:05:14.100373  4990 net.cpp:240] Setting up BatchNorm81
I0612 11:05:14.100383  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.100386  4990 net.cpp:255] Memory required for data: 2637693440
I0612 11:05:14.100399  4990 layer_factory.hpp:77] Creating layer Scale81
I0612 11:05:14.100406  4990 net.cpp:190] Creating Layer Scale81
I0612 11:05:14.100411  4990 net.cpp:615] Scale81 <- Convolution81
I0612 11:05:14.100417  4990 net.cpp:576] Scale81 -> Convolution81 (in-place)
I0612 11:05:14.100462  4990 layer_factory.hpp:77] Creating layer Scale81
I0612 11:05:14.100596  4990 net.cpp:240] Setting up Scale81
I0612 11:05:14.100605  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.100608  4990 net.cpp:255] Memory required for data: 2639790592
I0612 11:05:14.100618  4990 layer_factory.hpp:77] Creating layer Eltwise40
I0612 11:05:14.100628  4990 net.cpp:190] Creating Layer Eltwise40
I0612 11:05:14.100635  4990 net.cpp:615] Eltwise40 <- Eltwise39_ReLU79_0_split_1
I0612 11:05:14.100639  4990 net.cpp:615] Eltwise40 <- Convolution81
I0612 11:05:14.100649  4990 net.cpp:589] Eltwise40 -> Eltwise40
I0612 11:05:14.100675  4990 net.cpp:240] Setting up Eltwise40
I0612 11:05:14.100682  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.100687  4990 net.cpp:255] Memory required for data: 2641887744
I0612 11:05:14.100690  4990 layer_factory.hpp:77] Creating layer ReLU81
I0612 11:05:14.100697  4990 net.cpp:190] Creating Layer ReLU81
I0612 11:05:14.100702  4990 net.cpp:615] ReLU81 <- Eltwise40
I0612 11:05:14.100709  4990 net.cpp:576] ReLU81 -> Eltwise40 (in-place)
I0612 11:05:14.100716  4990 net.cpp:240] Setting up ReLU81
I0612 11:05:14.100721  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.100725  4990 net.cpp:255] Memory required for data: 2643984896
I0612 11:05:14.100729  4990 layer_factory.hpp:77] Creating layer Eltwise40_ReLU81_0_split
I0612 11:05:14.100735  4990 net.cpp:190] Creating Layer Eltwise40_ReLU81_0_split
I0612 11:05:14.100739  4990 net.cpp:615] Eltwise40_ReLU81_0_split <- Eltwise40
I0612 11:05:14.100744  4990 net.cpp:589] Eltwise40_ReLU81_0_split -> Eltwise40_ReLU81_0_split_0
I0612 11:05:14.100751  4990 net.cpp:589] Eltwise40_ReLU81_0_split -> Eltwise40_ReLU81_0_split_1
I0612 11:05:14.100792  4990 net.cpp:240] Setting up Eltwise40_ReLU81_0_split
I0612 11:05:14.100800  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.100805  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.100808  4990 net.cpp:255] Memory required for data: 2648179200
I0612 11:05:14.100812  4990 layer_factory.hpp:77] Creating layer Convolution82
I0612 11:05:14.100824  4990 net.cpp:190] Creating Layer Convolution82
I0612 11:05:14.100829  4990 net.cpp:615] Convolution82 <- Eltwise40_ReLU81_0_split_0
I0612 11:05:14.100836  4990 net.cpp:589] Convolution82 -> Convolution82
I0612 11:05:14.102470  4990 net.cpp:240] Setting up Convolution82
I0612 11:05:14.102481  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.102485  4990 net.cpp:255] Memory required for data: 2650276352
I0612 11:05:14.102495  4990 layer_factory.hpp:77] Creating layer BatchNorm82
I0612 11:05:14.102505  4990 net.cpp:190] Creating Layer BatchNorm82
I0612 11:05:14.102510  4990 net.cpp:615] BatchNorm82 <- Convolution82
I0612 11:05:14.102519  4990 net.cpp:576] BatchNorm82 -> Convolution82 (in-place)
I0612 11:05:14.102730  4990 net.cpp:240] Setting up BatchNorm82
I0612 11:05:14.102738  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.102742  4990 net.cpp:255] Memory required for data: 2652373504
I0612 11:05:14.102757  4990 layer_factory.hpp:77] Creating layer Scale82
I0612 11:05:14.102764  4990 net.cpp:190] Creating Layer Scale82
I0612 11:05:14.102769  4990 net.cpp:615] Scale82 <- Convolution82
I0612 11:05:14.102776  4990 net.cpp:576] Scale82 -> Convolution82 (in-place)
I0612 11:05:14.102815  4990 layer_factory.hpp:77] Creating layer Scale82
I0612 11:05:14.102946  4990 net.cpp:240] Setting up Scale82
I0612 11:05:14.102953  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.102957  4990 net.cpp:255] Memory required for data: 2654470656
I0612 11:05:14.102968  4990 layer_factory.hpp:77] Creating layer ReLU82
I0612 11:05:14.102975  4990 net.cpp:190] Creating Layer ReLU82
I0612 11:05:14.102980  4990 net.cpp:615] ReLU82 <- Convolution82
I0612 11:05:14.102988  4990 net.cpp:576] ReLU82 -> Convolution82 (in-place)
I0612 11:05:14.102995  4990 net.cpp:240] Setting up ReLU82
I0612 11:05:14.103001  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.103004  4990 net.cpp:255] Memory required for data: 2656567808
I0612 11:05:14.103008  4990 layer_factory.hpp:77] Creating layer Convolution83
I0612 11:05:14.103018  4990 net.cpp:190] Creating Layer Convolution83
I0612 11:05:14.103023  4990 net.cpp:615] Convolution83 <- Convolution82
I0612 11:05:14.103030  4990 net.cpp:589] Convolution83 -> Convolution83
I0612 11:05:14.104655  4990 net.cpp:240] Setting up Convolution83
I0612 11:05:14.104666  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.104671  4990 net.cpp:255] Memory required for data: 2658664960
I0612 11:05:14.104681  4990 layer_factory.hpp:77] Creating layer BatchNorm83
I0612 11:05:14.104691  4990 net.cpp:190] Creating Layer BatchNorm83
I0612 11:05:14.104696  4990 net.cpp:615] BatchNorm83 <- Convolution83
I0612 11:05:14.104706  4990 net.cpp:576] BatchNorm83 -> Convolution83 (in-place)
I0612 11:05:14.104921  4990 net.cpp:240] Setting up BatchNorm83
I0612 11:05:14.104929  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.104933  4990 net.cpp:255] Memory required for data: 2660762112
I0612 11:05:14.104945  4990 layer_factory.hpp:77] Creating layer Scale83
I0612 11:05:14.104953  4990 net.cpp:190] Creating Layer Scale83
I0612 11:05:14.104957  4990 net.cpp:615] Scale83 <- Convolution83
I0612 11:05:14.104965  4990 net.cpp:576] Scale83 -> Convolution83 (in-place)
I0612 11:05:14.105003  4990 layer_factory.hpp:77] Creating layer Scale83
I0612 11:05:14.105130  4990 net.cpp:240] Setting up Scale83
I0612 11:05:14.105139  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.105142  4990 net.cpp:255] Memory required for data: 2662859264
I0612 11:05:14.105151  4990 layer_factory.hpp:77] Creating layer Eltwise41
I0612 11:05:14.105159  4990 net.cpp:190] Creating Layer Eltwise41
I0612 11:05:14.105165  4990 net.cpp:615] Eltwise41 <- Eltwise40_ReLU81_0_split_1
I0612 11:05:14.105170  4990 net.cpp:615] Eltwise41 <- Convolution83
I0612 11:05:14.105178  4990 net.cpp:589] Eltwise41 -> Eltwise41
I0612 11:05:14.105200  4990 net.cpp:240] Setting up Eltwise41
I0612 11:05:14.105206  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.105209  4990 net.cpp:255] Memory required for data: 2664956416
I0612 11:05:14.105213  4990 layer_factory.hpp:77] Creating layer ReLU83
I0612 11:05:14.105222  4990 net.cpp:190] Creating Layer ReLU83
I0612 11:05:14.105227  4990 net.cpp:615] ReLU83 <- Eltwise41
I0612 11:05:14.105232  4990 net.cpp:576] ReLU83 -> Eltwise41 (in-place)
I0612 11:05:14.105239  4990 net.cpp:240] Setting up ReLU83
I0612 11:05:14.105244  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.105248  4990 net.cpp:255] Memory required for data: 2667053568
I0612 11:05:14.105252  4990 layer_factory.hpp:77] Creating layer Eltwise41_ReLU83_0_split
I0612 11:05:14.105258  4990 net.cpp:190] Creating Layer Eltwise41_ReLU83_0_split
I0612 11:05:14.105262  4990 net.cpp:615] Eltwise41_ReLU83_0_split <- Eltwise41
I0612 11:05:14.105271  4990 net.cpp:589] Eltwise41_ReLU83_0_split -> Eltwise41_ReLU83_0_split_0
I0612 11:05:14.105279  4990 net.cpp:589] Eltwise41_ReLU83_0_split -> Eltwise41_ReLU83_0_split_1
I0612 11:05:14.105315  4990 net.cpp:240] Setting up Eltwise41_ReLU83_0_split
I0612 11:05:14.105322  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.105327  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.105331  4990 net.cpp:255] Memory required for data: 2671247872
I0612 11:05:14.105334  4990 layer_factory.hpp:77] Creating layer Convolution84
I0612 11:05:14.105347  4990 net.cpp:190] Creating Layer Convolution84
I0612 11:05:14.105352  4990 net.cpp:615] Convolution84 <- Eltwise41_ReLU83_0_split_0
I0612 11:05:14.105360  4990 net.cpp:589] Convolution84 -> Convolution84
I0612 11:05:14.106988  4990 net.cpp:240] Setting up Convolution84
I0612 11:05:14.106999  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.107003  4990 net.cpp:255] Memory required for data: 2673345024
I0612 11:05:14.107013  4990 layer_factory.hpp:77] Creating layer BatchNorm84
I0612 11:05:14.107023  4990 net.cpp:190] Creating Layer BatchNorm84
I0612 11:05:14.107028  4990 net.cpp:615] BatchNorm84 <- Convolution84
I0612 11:05:14.107033  4990 net.cpp:576] BatchNorm84 -> Convolution84 (in-place)
I0612 11:05:14.107250  4990 net.cpp:240] Setting up BatchNorm84
I0612 11:05:14.107259  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.107262  4990 net.cpp:255] Memory required for data: 2675442176
I0612 11:05:14.107275  4990 layer_factory.hpp:77] Creating layer Scale84
I0612 11:05:14.107281  4990 net.cpp:190] Creating Layer Scale84
I0612 11:05:14.107286  4990 net.cpp:615] Scale84 <- Convolution84
I0612 11:05:14.107291  4990 net.cpp:576] Scale84 -> Convolution84 (in-place)
I0612 11:05:14.107342  4990 layer_factory.hpp:77] Creating layer Scale84
I0612 11:05:14.107472  4990 net.cpp:240] Setting up Scale84
I0612 11:05:14.107481  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.107484  4990 net.cpp:255] Memory required for data: 2677539328
I0612 11:05:14.107494  4990 layer_factory.hpp:77] Creating layer ReLU84
I0612 11:05:14.107503  4990 net.cpp:190] Creating Layer ReLU84
I0612 11:05:14.107508  4990 net.cpp:615] ReLU84 <- Convolution84
I0612 11:05:14.107514  4990 net.cpp:576] ReLU84 -> Convolution84 (in-place)
I0612 11:05:14.107520  4990 net.cpp:240] Setting up ReLU84
I0612 11:05:14.107527  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.107529  4990 net.cpp:255] Memory required for data: 2679636480
I0612 11:05:14.107533  4990 layer_factory.hpp:77] Creating layer Convolution85
I0612 11:05:14.107545  4990 net.cpp:190] Creating Layer Convolution85
I0612 11:05:14.107550  4990 net.cpp:615] Convolution85 <- Convolution84
I0612 11:05:14.107558  4990 net.cpp:589] Convolution85 -> Convolution85
I0612 11:05:14.109179  4990 net.cpp:240] Setting up Convolution85
I0612 11:05:14.109189  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.109194  4990 net.cpp:255] Memory required for data: 2681733632
I0612 11:05:14.109202  4990 layer_factory.hpp:77] Creating layer BatchNorm85
I0612 11:05:14.109213  4990 net.cpp:190] Creating Layer BatchNorm85
I0612 11:05:14.109220  4990 net.cpp:615] BatchNorm85 <- Convolution85
I0612 11:05:14.109226  4990 net.cpp:576] BatchNorm85 -> Convolution85 (in-place)
I0612 11:05:14.109443  4990 net.cpp:240] Setting up BatchNorm85
I0612 11:05:14.109452  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.109455  4990 net.cpp:255] Memory required for data: 2683830784
I0612 11:05:14.109467  4990 layer_factory.hpp:77] Creating layer Scale85
I0612 11:05:14.109477  4990 net.cpp:190] Creating Layer Scale85
I0612 11:05:14.109482  4990 net.cpp:615] Scale85 <- Convolution85
I0612 11:05:14.109488  4990 net.cpp:576] Scale85 -> Convolution85 (in-place)
I0612 11:05:14.109527  4990 layer_factory.hpp:77] Creating layer Scale85
I0612 11:05:14.109658  4990 net.cpp:240] Setting up Scale85
I0612 11:05:14.109666  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.109669  4990 net.cpp:255] Memory required for data: 2685927936
I0612 11:05:14.109679  4990 layer_factory.hpp:77] Creating layer Eltwise42
I0612 11:05:14.109689  4990 net.cpp:190] Creating Layer Eltwise42
I0612 11:05:14.109694  4990 net.cpp:615] Eltwise42 <- Eltwise41_ReLU83_0_split_1
I0612 11:05:14.109700  4990 net.cpp:615] Eltwise42 <- Convolution85
I0612 11:05:14.109706  4990 net.cpp:589] Eltwise42 -> Eltwise42
I0612 11:05:14.109733  4990 net.cpp:240] Setting up Eltwise42
I0612 11:05:14.109740  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.109745  4990 net.cpp:255] Memory required for data: 2688025088
I0612 11:05:14.109748  4990 layer_factory.hpp:77] Creating layer ReLU85
I0612 11:05:14.109755  4990 net.cpp:190] Creating Layer ReLU85
I0612 11:05:14.109758  4990 net.cpp:615] ReLU85 <- Eltwise42
I0612 11:05:14.109766  4990 net.cpp:576] ReLU85 -> Eltwise42 (in-place)
I0612 11:05:14.109773  4990 net.cpp:240] Setting up ReLU85
I0612 11:05:14.109779  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.109782  4990 net.cpp:255] Memory required for data: 2690122240
I0612 11:05:14.109786  4990 layer_factory.hpp:77] Creating layer Eltwise42_ReLU85_0_split
I0612 11:05:14.109792  4990 net.cpp:190] Creating Layer Eltwise42_ReLU85_0_split
I0612 11:05:14.109797  4990 net.cpp:615] Eltwise42_ReLU85_0_split <- Eltwise42
I0612 11:05:14.109802  4990 net.cpp:589] Eltwise42_ReLU85_0_split -> Eltwise42_ReLU85_0_split_0
I0612 11:05:14.109809  4990 net.cpp:589] Eltwise42_ReLU85_0_split -> Eltwise42_ReLU85_0_split_1
I0612 11:05:14.109849  4990 net.cpp:240] Setting up Eltwise42_ReLU85_0_split
I0612 11:05:14.109855  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.109860  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.109869  4990 net.cpp:255] Memory required for data: 2694316544
I0612 11:05:14.109872  4990 layer_factory.hpp:77] Creating layer Convolution86
I0612 11:05:14.109882  4990 net.cpp:190] Creating Layer Convolution86
I0612 11:05:14.109887  4990 net.cpp:615] Convolution86 <- Eltwise42_ReLU85_0_split_0
I0612 11:05:14.109897  4990 net.cpp:589] Convolution86 -> Convolution86
I0612 11:05:14.111531  4990 net.cpp:240] Setting up Convolution86
I0612 11:05:14.111541  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.111546  4990 net.cpp:255] Memory required for data: 2696413696
I0612 11:05:14.111555  4990 layer_factory.hpp:77] Creating layer BatchNorm86
I0612 11:05:14.111562  4990 net.cpp:190] Creating Layer BatchNorm86
I0612 11:05:14.111567  4990 net.cpp:615] BatchNorm86 <- Convolution86
I0612 11:05:14.111575  4990 net.cpp:576] BatchNorm86 -> Convolution86 (in-place)
I0612 11:05:14.111796  4990 net.cpp:240] Setting up BatchNorm86
I0612 11:05:14.111804  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.111809  4990 net.cpp:255] Memory required for data: 2698510848
I0612 11:05:14.111820  4990 layer_factory.hpp:77] Creating layer Scale86
I0612 11:05:14.111829  4990 net.cpp:190] Creating Layer Scale86
I0612 11:05:14.111832  4990 net.cpp:615] Scale86 <- Convolution86
I0612 11:05:14.111840  4990 net.cpp:576] Scale86 -> Convolution86 (in-place)
I0612 11:05:14.111879  4990 layer_factory.hpp:77] Creating layer Scale86
I0612 11:05:14.112006  4990 net.cpp:240] Setting up Scale86
I0612 11:05:14.112015  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.112018  4990 net.cpp:255] Memory required for data: 2700608000
I0612 11:05:14.112027  4990 layer_factory.hpp:77] Creating layer ReLU86
I0612 11:05:14.112035  4990 net.cpp:190] Creating Layer ReLU86
I0612 11:05:14.112038  4990 net.cpp:615] ReLU86 <- Convolution86
I0612 11:05:14.112047  4990 net.cpp:576] ReLU86 -> Convolution86 (in-place)
I0612 11:05:14.112054  4990 net.cpp:240] Setting up ReLU86
I0612 11:05:14.112061  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.112063  4990 net.cpp:255] Memory required for data: 2702705152
I0612 11:05:14.112067  4990 layer_factory.hpp:77] Creating layer Convolution87
I0612 11:05:14.112079  4990 net.cpp:190] Creating Layer Convolution87
I0612 11:05:14.112083  4990 net.cpp:615] Convolution87 <- Convolution86
I0612 11:05:14.112090  4990 net.cpp:589] Convolution87 -> Convolution87
I0612 11:05:14.113709  4990 net.cpp:240] Setting up Convolution87
I0612 11:05:14.113719  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.113723  4990 net.cpp:255] Memory required for data: 2704802304
I0612 11:05:14.113734  4990 layer_factory.hpp:77] Creating layer BatchNorm87
I0612 11:05:14.113744  4990 net.cpp:190] Creating Layer BatchNorm87
I0612 11:05:14.113749  4990 net.cpp:615] BatchNorm87 <- Convolution87
I0612 11:05:14.113755  4990 net.cpp:576] BatchNorm87 -> Convolution87 (in-place)
I0612 11:05:14.113973  4990 net.cpp:240] Setting up BatchNorm87
I0612 11:05:14.113981  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.113984  4990 net.cpp:255] Memory required for data: 2706899456
I0612 11:05:14.113996  4990 layer_factory.hpp:77] Creating layer Scale87
I0612 11:05:14.114003  4990 net.cpp:190] Creating Layer Scale87
I0612 11:05:14.114008  4990 net.cpp:615] Scale87 <- Convolution87
I0612 11:05:14.114014  4990 net.cpp:576] Scale87 -> Convolution87 (in-place)
I0612 11:05:14.114054  4990 layer_factory.hpp:77] Creating layer Scale87
I0612 11:05:14.114192  4990 net.cpp:240] Setting up Scale87
I0612 11:05:14.114200  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.114204  4990 net.cpp:255] Memory required for data: 2708996608
I0612 11:05:14.114213  4990 layer_factory.hpp:77] Creating layer Eltwise43
I0612 11:05:14.114223  4990 net.cpp:190] Creating Layer Eltwise43
I0612 11:05:14.114229  4990 net.cpp:615] Eltwise43 <- Eltwise42_ReLU85_0_split_1
I0612 11:05:14.114234  4990 net.cpp:615] Eltwise43 <- Convolution87
I0612 11:05:14.114240  4990 net.cpp:589] Eltwise43 -> Eltwise43
I0612 11:05:14.114265  4990 net.cpp:240] Setting up Eltwise43
I0612 11:05:14.114272  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.114275  4990 net.cpp:255] Memory required for data: 2711093760
I0612 11:05:14.114279  4990 layer_factory.hpp:77] Creating layer ReLU87
I0612 11:05:14.114289  4990 net.cpp:190] Creating Layer ReLU87
I0612 11:05:14.114295  4990 net.cpp:615] ReLU87 <- Eltwise43
I0612 11:05:14.114300  4990 net.cpp:576] ReLU87 -> Eltwise43 (in-place)
I0612 11:05:14.114306  4990 net.cpp:240] Setting up ReLU87
I0612 11:05:14.114312  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.114316  4990 net.cpp:255] Memory required for data: 2713190912
I0612 11:05:14.114320  4990 layer_factory.hpp:77] Creating layer Eltwise43_ReLU87_0_split
I0612 11:05:14.114326  4990 net.cpp:190] Creating Layer Eltwise43_ReLU87_0_split
I0612 11:05:14.114329  4990 net.cpp:615] Eltwise43_ReLU87_0_split <- Eltwise43
I0612 11:05:14.114334  4990 net.cpp:589] Eltwise43_ReLU87_0_split -> Eltwise43_ReLU87_0_split_0
I0612 11:05:14.114342  4990 net.cpp:589] Eltwise43_ReLU87_0_split -> Eltwise43_ReLU87_0_split_1
I0612 11:05:14.114392  4990 net.cpp:240] Setting up Eltwise43_ReLU87_0_split
I0612 11:05:14.114399  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.114404  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.114408  4990 net.cpp:255] Memory required for data: 2717385216
I0612 11:05:14.114413  4990 layer_factory.hpp:77] Creating layer Convolution88
I0612 11:05:14.114424  4990 net.cpp:190] Creating Layer Convolution88
I0612 11:05:14.114429  4990 net.cpp:615] Convolution88 <- Eltwise43_ReLU87_0_split_0
I0612 11:05:14.114437  4990 net.cpp:589] Convolution88 -> Convolution88
I0612 11:05:14.116744  4990 net.cpp:240] Setting up Convolution88
I0612 11:05:14.116761  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.116765  4990 net.cpp:255] Memory required for data: 2719482368
I0612 11:05:14.116776  4990 layer_factory.hpp:77] Creating layer BatchNorm88
I0612 11:05:14.116787  4990 net.cpp:190] Creating Layer BatchNorm88
I0612 11:05:14.116793  4990 net.cpp:615] BatchNorm88 <- Convolution88
I0612 11:05:14.116799  4990 net.cpp:576] BatchNorm88 -> Convolution88 (in-place)
I0612 11:05:14.117025  4990 net.cpp:240] Setting up BatchNorm88
I0612 11:05:14.117034  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.117038  4990 net.cpp:255] Memory required for data: 2721579520
I0612 11:05:14.117050  4990 layer_factory.hpp:77] Creating layer Scale88
I0612 11:05:14.117058  4990 net.cpp:190] Creating Layer Scale88
I0612 11:05:14.117063  4990 net.cpp:615] Scale88 <- Convolution88
I0612 11:05:14.117069  4990 net.cpp:576] Scale88 -> Convolution88 (in-place)
I0612 11:05:14.117113  4990 layer_factory.hpp:77] Creating layer Scale88
I0612 11:05:14.117244  4990 net.cpp:240] Setting up Scale88
I0612 11:05:14.117251  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.117255  4990 net.cpp:255] Memory required for data: 2723676672
I0612 11:05:14.117267  4990 layer_factory.hpp:77] Creating layer ReLU88
I0612 11:05:14.117274  4990 net.cpp:190] Creating Layer ReLU88
I0612 11:05:14.117280  4990 net.cpp:615] ReLU88 <- Convolution88
I0612 11:05:14.117285  4990 net.cpp:576] ReLU88 -> Convolution88 (in-place)
I0612 11:05:14.117292  4990 net.cpp:240] Setting up ReLU88
I0612 11:05:14.117298  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.117301  4990 net.cpp:255] Memory required for data: 2725773824
I0612 11:05:14.117305  4990 layer_factory.hpp:77] Creating layer Convolution89
I0612 11:05:14.117318  4990 net.cpp:190] Creating Layer Convolution89
I0612 11:05:14.117322  4990 net.cpp:615] Convolution89 <- Convolution88
I0612 11:05:14.117331  4990 net.cpp:589] Convolution89 -> Convolution89
I0612 11:05:14.118970  4990 net.cpp:240] Setting up Convolution89
I0612 11:05:14.118981  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.118985  4990 net.cpp:255] Memory required for data: 2727870976
I0612 11:05:14.118995  4990 layer_factory.hpp:77] Creating layer BatchNorm89
I0612 11:05:14.119009  4990 net.cpp:190] Creating Layer BatchNorm89
I0612 11:05:14.119015  4990 net.cpp:615] BatchNorm89 <- Convolution89
I0612 11:05:14.119024  4990 net.cpp:576] BatchNorm89 -> Convolution89 (in-place)
I0612 11:05:14.119241  4990 net.cpp:240] Setting up BatchNorm89
I0612 11:05:14.119249  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.119253  4990 net.cpp:255] Memory required for data: 2729968128
I0612 11:05:14.119266  4990 layer_factory.hpp:77] Creating layer Scale89
I0612 11:05:14.119274  4990 net.cpp:190] Creating Layer Scale89
I0612 11:05:14.119279  4990 net.cpp:615] Scale89 <- Convolution89
I0612 11:05:14.119285  4990 net.cpp:576] Scale89 -> Convolution89 (in-place)
I0612 11:05:14.119328  4990 layer_factory.hpp:77] Creating layer Scale89
I0612 11:05:14.119462  4990 net.cpp:240] Setting up Scale89
I0612 11:05:14.119469  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.119473  4990 net.cpp:255] Memory required for data: 2732065280
I0612 11:05:14.119489  4990 layer_factory.hpp:77] Creating layer Eltwise44
I0612 11:05:14.119498  4990 net.cpp:190] Creating Layer Eltwise44
I0612 11:05:14.119503  4990 net.cpp:615] Eltwise44 <- Eltwise43_ReLU87_0_split_1
I0612 11:05:14.119508  4990 net.cpp:615] Eltwise44 <- Convolution89
I0612 11:05:14.119516  4990 net.cpp:589] Eltwise44 -> Eltwise44
I0612 11:05:14.119539  4990 net.cpp:240] Setting up Eltwise44
I0612 11:05:14.119546  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.119549  4990 net.cpp:255] Memory required for data: 2734162432
I0612 11:05:14.119554  4990 layer_factory.hpp:77] Creating layer ReLU89
I0612 11:05:14.119560  4990 net.cpp:190] Creating Layer ReLU89
I0612 11:05:14.119565  4990 net.cpp:615] ReLU89 <- Eltwise44
I0612 11:05:14.119572  4990 net.cpp:576] ReLU89 -> Eltwise44 (in-place)
I0612 11:05:14.119580  4990 net.cpp:240] Setting up ReLU89
I0612 11:05:14.119585  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.119588  4990 net.cpp:255] Memory required for data: 2736259584
I0612 11:05:14.119592  4990 layer_factory.hpp:77] Creating layer Eltwise44_ReLU89_0_split
I0612 11:05:14.119598  4990 net.cpp:190] Creating Layer Eltwise44_ReLU89_0_split
I0612 11:05:14.119602  4990 net.cpp:615] Eltwise44_ReLU89_0_split <- Eltwise44
I0612 11:05:14.119607  4990 net.cpp:589] Eltwise44_ReLU89_0_split -> Eltwise44_ReLU89_0_split_0
I0612 11:05:14.119614  4990 net.cpp:589] Eltwise44_ReLU89_0_split -> Eltwise44_ReLU89_0_split_1
I0612 11:05:14.119655  4990 net.cpp:240] Setting up Eltwise44_ReLU89_0_split
I0612 11:05:14.119663  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.119668  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.119671  4990 net.cpp:255] Memory required for data: 2740453888
I0612 11:05:14.119675  4990 layer_factory.hpp:77] Creating layer Convolution90
I0612 11:05:14.119684  4990 net.cpp:190] Creating Layer Convolution90
I0612 11:05:14.119688  4990 net.cpp:615] Convolution90 <- Eltwise44_ReLU89_0_split_0
I0612 11:05:14.119699  4990 net.cpp:589] Convolution90 -> Convolution90
I0612 11:05:14.121321  4990 net.cpp:240] Setting up Convolution90
I0612 11:05:14.121331  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.121335  4990 net.cpp:255] Memory required for data: 2742551040
I0612 11:05:14.121345  4990 layer_factory.hpp:77] Creating layer BatchNorm90
I0612 11:05:14.121352  4990 net.cpp:190] Creating Layer BatchNorm90
I0612 11:05:14.121357  4990 net.cpp:615] BatchNorm90 <- Convolution90
I0612 11:05:14.121366  4990 net.cpp:576] BatchNorm90 -> Convolution90 (in-place)
I0612 11:05:14.121587  4990 net.cpp:240] Setting up BatchNorm90
I0612 11:05:14.121594  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.121598  4990 net.cpp:255] Memory required for data: 2744648192
I0612 11:05:14.121610  4990 layer_factory.hpp:77] Creating layer Scale90
I0612 11:05:14.121618  4990 net.cpp:190] Creating Layer Scale90
I0612 11:05:14.121623  4990 net.cpp:615] Scale90 <- Convolution90
I0612 11:05:14.121630  4990 net.cpp:576] Scale90 -> Convolution90 (in-place)
I0612 11:05:14.121675  4990 layer_factory.hpp:77] Creating layer Scale90
I0612 11:05:14.121810  4990 net.cpp:240] Setting up Scale90
I0612 11:05:14.121819  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.121822  4990 net.cpp:255] Memory required for data: 2746745344
I0612 11:05:14.121832  4990 layer_factory.hpp:77] Creating layer ReLU90
I0612 11:05:14.121840  4990 net.cpp:190] Creating Layer ReLU90
I0612 11:05:14.121843  4990 net.cpp:615] ReLU90 <- Convolution90
I0612 11:05:14.121852  4990 net.cpp:576] ReLU90 -> Convolution90 (in-place)
I0612 11:05:14.121860  4990 net.cpp:240] Setting up ReLU90
I0612 11:05:14.121865  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.121868  4990 net.cpp:255] Memory required for data: 2748842496
I0612 11:05:14.121872  4990 layer_factory.hpp:77] Creating layer Convolution91
I0612 11:05:14.121884  4990 net.cpp:190] Creating Layer Convolution91
I0612 11:05:14.121889  4990 net.cpp:615] Convolution91 <- Convolution90
I0612 11:05:14.121896  4990 net.cpp:589] Convolution91 -> Convolution91
I0612 11:05:14.123538  4990 net.cpp:240] Setting up Convolution91
I0612 11:05:14.123548  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.123553  4990 net.cpp:255] Memory required for data: 2750939648
I0612 11:05:14.123564  4990 layer_factory.hpp:77] Creating layer BatchNorm91
I0612 11:05:14.123574  4990 net.cpp:190] Creating Layer BatchNorm91
I0612 11:05:14.123579  4990 net.cpp:615] BatchNorm91 <- Convolution91
I0612 11:05:14.123584  4990 net.cpp:576] BatchNorm91 -> Convolution91 (in-place)
I0612 11:05:14.123807  4990 net.cpp:240] Setting up BatchNorm91
I0612 11:05:14.123816  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.123819  4990 net.cpp:255] Memory required for data: 2753036800
I0612 11:05:14.123831  4990 layer_factory.hpp:77] Creating layer Scale91
I0612 11:05:14.123839  4990 net.cpp:190] Creating Layer Scale91
I0612 11:05:14.123843  4990 net.cpp:615] Scale91 <- Convolution91
I0612 11:05:14.123849  4990 net.cpp:576] Scale91 -> Convolution91 (in-place)
I0612 11:05:14.123890  4990 layer_factory.hpp:77] Creating layer Scale91
I0612 11:05:14.124022  4990 net.cpp:240] Setting up Scale91
I0612 11:05:14.124030  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.124034  4990 net.cpp:255] Memory required for data: 2755133952
I0612 11:05:14.124043  4990 layer_factory.hpp:77] Creating layer Eltwise45
I0612 11:05:14.124053  4990 net.cpp:190] Creating Layer Eltwise45
I0612 11:05:14.124058  4990 net.cpp:615] Eltwise45 <- Eltwise44_ReLU89_0_split_1
I0612 11:05:14.124064  4990 net.cpp:615] Eltwise45 <- Convolution91
I0612 11:05:14.124070  4990 net.cpp:589] Eltwise45 -> Eltwise45
I0612 11:05:14.124090  4990 net.cpp:240] Setting up Eltwise45
I0612 11:05:14.124097  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.124101  4990 net.cpp:255] Memory required for data: 2757231104
I0612 11:05:14.124104  4990 layer_factory.hpp:77] Creating layer ReLU91
I0612 11:05:14.124114  4990 net.cpp:190] Creating Layer ReLU91
I0612 11:05:14.124119  4990 net.cpp:615] ReLU91 <- Eltwise45
I0612 11:05:14.124124  4990 net.cpp:576] ReLU91 -> Eltwise45 (in-place)
I0612 11:05:14.124130  4990 net.cpp:240] Setting up ReLU91
I0612 11:05:14.124135  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.124140  4990 net.cpp:255] Memory required for data: 2759328256
I0612 11:05:14.124142  4990 layer_factory.hpp:77] Creating layer Eltwise45_ReLU91_0_split
I0612 11:05:14.124150  4990 net.cpp:190] Creating Layer Eltwise45_ReLU91_0_split
I0612 11:05:14.124152  4990 net.cpp:615] Eltwise45_ReLU91_0_split <- Eltwise45
I0612 11:05:14.124158  4990 net.cpp:589] Eltwise45_ReLU91_0_split -> Eltwise45_ReLU91_0_split_0
I0612 11:05:14.124166  4990 net.cpp:589] Eltwise45_ReLU91_0_split -> Eltwise45_ReLU91_0_split_1
I0612 11:05:14.124205  4990 net.cpp:240] Setting up Eltwise45_ReLU91_0_split
I0612 11:05:14.124212  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.124217  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.124220  4990 net.cpp:255] Memory required for data: 2763522560
I0612 11:05:14.124228  4990 layer_factory.hpp:77] Creating layer Convolution92
I0612 11:05:14.124240  4990 net.cpp:190] Creating Layer Convolution92
I0612 11:05:14.124245  4990 net.cpp:615] Convolution92 <- Eltwise45_ReLU91_0_split_0
I0612 11:05:14.124253  4990 net.cpp:589] Convolution92 -> Convolution92
I0612 11:05:14.125883  4990 net.cpp:240] Setting up Convolution92
I0612 11:05:14.125893  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.125897  4990 net.cpp:255] Memory required for data: 2765619712
I0612 11:05:14.125907  4990 layer_factory.hpp:77] Creating layer BatchNorm92
I0612 11:05:14.125916  4990 net.cpp:190] Creating Layer BatchNorm92
I0612 11:05:14.125921  4990 net.cpp:615] BatchNorm92 <- Convolution92
I0612 11:05:14.125929  4990 net.cpp:576] BatchNorm92 -> Convolution92 (in-place)
I0612 11:05:14.126149  4990 net.cpp:240] Setting up BatchNorm92
I0612 11:05:14.126157  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.126162  4990 net.cpp:255] Memory required for data: 2767716864
I0612 11:05:14.126173  4990 layer_factory.hpp:77] Creating layer Scale92
I0612 11:05:14.126183  4990 net.cpp:190] Creating Layer Scale92
I0612 11:05:14.126188  4990 net.cpp:615] Scale92 <- Convolution92
I0612 11:05:14.126194  4990 net.cpp:576] Scale92 -> Convolution92 (in-place)
I0612 11:05:14.126233  4990 layer_factory.hpp:77] Creating layer Scale92
I0612 11:05:14.126374  4990 net.cpp:240] Setting up Scale92
I0612 11:05:14.126382  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.126386  4990 net.cpp:255] Memory required for data: 2769814016
I0612 11:05:14.126399  4990 layer_factory.hpp:77] Creating layer ReLU92
I0612 11:05:14.126405  4990 net.cpp:190] Creating Layer ReLU92
I0612 11:05:14.126410  4990 net.cpp:615] ReLU92 <- Convolution92
I0612 11:05:14.126415  4990 net.cpp:576] ReLU92 -> Convolution92 (in-place)
I0612 11:05:14.126423  4990 net.cpp:240] Setting up ReLU92
I0612 11:05:14.126428  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.126432  4990 net.cpp:255] Memory required for data: 2771911168
I0612 11:05:14.126435  4990 layer_factory.hpp:77] Creating layer Convolution93
I0612 11:05:14.126448  4990 net.cpp:190] Creating Layer Convolution93
I0612 11:05:14.126452  4990 net.cpp:615] Convolution93 <- Convolution92
I0612 11:05:14.126462  4990 net.cpp:589] Convolution93 -> Convolution93
I0612 11:05:14.128088  4990 net.cpp:240] Setting up Convolution93
I0612 11:05:14.128098  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.128103  4990 net.cpp:255] Memory required for data: 2774008320
I0612 11:05:14.128113  4990 layer_factory.hpp:77] Creating layer BatchNorm93
I0612 11:05:14.128120  4990 net.cpp:190] Creating Layer BatchNorm93
I0612 11:05:14.128124  4990 net.cpp:615] BatchNorm93 <- Convolution93
I0612 11:05:14.128134  4990 net.cpp:576] BatchNorm93 -> Convolution93 (in-place)
I0612 11:05:14.128353  4990 net.cpp:240] Setting up BatchNorm93
I0612 11:05:14.128361  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.128365  4990 net.cpp:255] Memory required for data: 2776105472
I0612 11:05:14.128377  4990 layer_factory.hpp:77] Creating layer Scale93
I0612 11:05:14.128384  4990 net.cpp:190] Creating Layer Scale93
I0612 11:05:14.128388  4990 net.cpp:615] Scale93 <- Convolution93
I0612 11:05:14.128401  4990 net.cpp:576] Scale93 -> Convolution93 (in-place)
I0612 11:05:14.128442  4990 layer_factory.hpp:77] Creating layer Scale93
I0612 11:05:14.128579  4990 net.cpp:240] Setting up Scale93
I0612 11:05:14.128587  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.128592  4990 net.cpp:255] Memory required for data: 2778202624
I0612 11:05:14.128602  4990 layer_factory.hpp:77] Creating layer Eltwise46
I0612 11:05:14.128608  4990 net.cpp:190] Creating Layer Eltwise46
I0612 11:05:14.128613  4990 net.cpp:615] Eltwise46 <- Eltwise45_ReLU91_0_split_1
I0612 11:05:14.128618  4990 net.cpp:615] Eltwise46 <- Convolution93
I0612 11:05:14.128628  4990 net.cpp:589] Eltwise46 -> Eltwise46
I0612 11:05:14.128648  4990 net.cpp:240] Setting up Eltwise46
I0612 11:05:14.128659  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.128662  4990 net.cpp:255] Memory required for data: 2780299776
I0612 11:05:14.128666  4990 layer_factory.hpp:77] Creating layer ReLU93
I0612 11:05:14.128675  4990 net.cpp:190] Creating Layer ReLU93
I0612 11:05:14.128679  4990 net.cpp:615] ReLU93 <- Eltwise46
I0612 11:05:14.128685  4990 net.cpp:576] ReLU93 -> Eltwise46 (in-place)
I0612 11:05:14.128692  4990 net.cpp:240] Setting up ReLU93
I0612 11:05:14.128697  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.128701  4990 net.cpp:255] Memory required for data: 2782396928
I0612 11:05:14.128705  4990 layer_factory.hpp:77] Creating layer Eltwise46_ReLU93_0_split
I0612 11:05:14.128711  4990 net.cpp:190] Creating Layer Eltwise46_ReLU93_0_split
I0612 11:05:14.128715  4990 net.cpp:615] Eltwise46_ReLU93_0_split <- Eltwise46
I0612 11:05:14.128720  4990 net.cpp:589] Eltwise46_ReLU93_0_split -> Eltwise46_ReLU93_0_split_0
I0612 11:05:14.128731  4990 net.cpp:589] Eltwise46_ReLU93_0_split -> Eltwise46_ReLU93_0_split_1
I0612 11:05:14.128769  4990 net.cpp:240] Setting up Eltwise46_ReLU93_0_split
I0612 11:05:14.128777  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.128782  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.128785  4990 net.cpp:255] Memory required for data: 2786591232
I0612 11:05:14.128788  4990 layer_factory.hpp:77] Creating layer Convolution94
I0612 11:05:14.128800  4990 net.cpp:190] Creating Layer Convolution94
I0612 11:05:14.128805  4990 net.cpp:615] Convolution94 <- Eltwise46_ReLU93_0_split_0
I0612 11:05:14.128813  4990 net.cpp:589] Convolution94 -> Convolution94
I0612 11:05:14.130460  4990 net.cpp:240] Setting up Convolution94
I0612 11:05:14.130471  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.130475  4990 net.cpp:255] Memory required for data: 2788688384
I0612 11:05:14.130486  4990 layer_factory.hpp:77] Creating layer BatchNorm94
I0612 11:05:14.130494  4990 net.cpp:190] Creating Layer BatchNorm94
I0612 11:05:14.130499  4990 net.cpp:615] BatchNorm94 <- Convolution94
I0612 11:05:14.130506  4990 net.cpp:576] BatchNorm94 -> Convolution94 (in-place)
I0612 11:05:14.130734  4990 net.cpp:240] Setting up BatchNorm94
I0612 11:05:14.130743  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.130746  4990 net.cpp:255] Memory required for data: 2790785536
I0612 11:05:14.130759  4990 layer_factory.hpp:77] Creating layer Scale94
I0612 11:05:14.130765  4990 net.cpp:190] Creating Layer Scale94
I0612 11:05:14.130769  4990 net.cpp:615] Scale94 <- Convolution94
I0612 11:05:14.130775  4990 net.cpp:576] Scale94 -> Convolution94 (in-place)
I0612 11:05:14.130817  4990 layer_factory.hpp:77] Creating layer Scale94
I0612 11:05:14.131645  4990 net.cpp:240] Setting up Scale94
I0612 11:05:14.131661  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.131665  4990 net.cpp:255] Memory required for data: 2792882688
I0612 11:05:14.131677  4990 layer_factory.hpp:77] Creating layer ReLU94
I0612 11:05:14.131685  4990 net.cpp:190] Creating Layer ReLU94
I0612 11:05:14.131690  4990 net.cpp:615] ReLU94 <- Convolution94
I0612 11:05:14.131697  4990 net.cpp:576] ReLU94 -> Convolution94 (in-place)
I0612 11:05:14.131705  4990 net.cpp:240] Setting up ReLU94
I0612 11:05:14.131711  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.131714  4990 net.cpp:255] Memory required for data: 2794979840
I0612 11:05:14.131718  4990 layer_factory.hpp:77] Creating layer Convolution95
I0612 11:05:14.131731  4990 net.cpp:190] Creating Layer Convolution95
I0612 11:05:14.131736  4990 net.cpp:615] Convolution95 <- Convolution94
I0612 11:05:14.131743  4990 net.cpp:589] Convolution95 -> Convolution95
I0612 11:05:14.134043  4990 net.cpp:240] Setting up Convolution95
I0612 11:05:14.134063  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.134066  4990 net.cpp:255] Memory required for data: 2797076992
I0612 11:05:14.134078  4990 layer_factory.hpp:77] Creating layer BatchNorm95
I0612 11:05:14.134086  4990 net.cpp:190] Creating Layer BatchNorm95
I0612 11:05:14.134094  4990 net.cpp:615] BatchNorm95 <- Convolution95
I0612 11:05:14.134104  4990 net.cpp:576] BatchNorm95 -> Convolution95 (in-place)
I0612 11:05:14.134335  4990 net.cpp:240] Setting up BatchNorm95
I0612 11:05:14.134343  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.134347  4990 net.cpp:255] Memory required for data: 2799174144
I0612 11:05:14.134368  4990 layer_factory.hpp:77] Creating layer Scale95
I0612 11:05:14.134377  4990 net.cpp:190] Creating Layer Scale95
I0612 11:05:14.134382  4990 net.cpp:615] Scale95 <- Convolution95
I0612 11:05:14.134390  4990 net.cpp:576] Scale95 -> Convolution95 (in-place)
I0612 11:05:14.134431  4990 layer_factory.hpp:77] Creating layer Scale95
I0612 11:05:14.134567  4990 net.cpp:240] Setting up Scale95
I0612 11:05:14.134575  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.134579  4990 net.cpp:255] Memory required for data: 2801271296
I0612 11:05:14.134589  4990 layer_factory.hpp:77] Creating layer Eltwise47
I0612 11:05:14.134596  4990 net.cpp:190] Creating Layer Eltwise47
I0612 11:05:14.134603  4990 net.cpp:615] Eltwise47 <- Eltwise46_ReLU93_0_split_1
I0612 11:05:14.134608  4990 net.cpp:615] Eltwise47 <- Convolution95
I0612 11:05:14.134616  4990 net.cpp:589] Eltwise47 -> Eltwise47
I0612 11:05:14.134637  4990 net.cpp:240] Setting up Eltwise47
I0612 11:05:14.134644  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.134647  4990 net.cpp:255] Memory required for data: 2803368448
I0612 11:05:14.134651  4990 layer_factory.hpp:77] Creating layer ReLU95
I0612 11:05:14.134660  4990 net.cpp:190] Creating Layer ReLU95
I0612 11:05:14.134665  4990 net.cpp:615] ReLU95 <- Eltwise47
I0612 11:05:14.134670  4990 net.cpp:576] ReLU95 -> Eltwise47 (in-place)
I0612 11:05:14.134676  4990 net.cpp:240] Setting up ReLU95
I0612 11:05:14.134682  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.134685  4990 net.cpp:255] Memory required for data: 2805465600
I0612 11:05:14.134690  4990 layer_factory.hpp:77] Creating layer Eltwise47_ReLU95_0_split
I0612 11:05:14.134696  4990 net.cpp:190] Creating Layer Eltwise47_ReLU95_0_split
I0612 11:05:14.134699  4990 net.cpp:615] Eltwise47_ReLU95_0_split <- Eltwise47
I0612 11:05:14.134707  4990 net.cpp:589] Eltwise47_ReLU95_0_split -> Eltwise47_ReLU95_0_split_0
I0612 11:05:14.134716  4990 net.cpp:589] Eltwise47_ReLU95_0_split -> Eltwise47_ReLU95_0_split_1
I0612 11:05:14.134753  4990 net.cpp:240] Setting up Eltwise47_ReLU95_0_split
I0612 11:05:14.134759  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.134764  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.134768  4990 net.cpp:255] Memory required for data: 2809659904
I0612 11:05:14.134771  4990 layer_factory.hpp:77] Creating layer Convolution96
I0612 11:05:14.134785  4990 net.cpp:190] Creating Layer Convolution96
I0612 11:05:14.134790  4990 net.cpp:615] Convolution96 <- Eltwise47_ReLU95_0_split_0
I0612 11:05:14.134798  4990 net.cpp:589] Convolution96 -> Convolution96
I0612 11:05:14.136432  4990 net.cpp:240] Setting up Convolution96
I0612 11:05:14.136442  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.136446  4990 net.cpp:255] Memory required for data: 2811757056
I0612 11:05:14.136457  4990 layer_factory.hpp:77] Creating layer BatchNorm96
I0612 11:05:14.136467  4990 net.cpp:190] Creating Layer BatchNorm96
I0612 11:05:14.136472  4990 net.cpp:615] BatchNorm96 <- Convolution96
I0612 11:05:14.136478  4990 net.cpp:576] BatchNorm96 -> Convolution96 (in-place)
I0612 11:05:14.136701  4990 net.cpp:240] Setting up BatchNorm96
I0612 11:05:14.136709  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.136713  4990 net.cpp:255] Memory required for data: 2813854208
I0612 11:05:14.136725  4990 layer_factory.hpp:77] Creating layer Scale96
I0612 11:05:14.136732  4990 net.cpp:190] Creating Layer Scale96
I0612 11:05:14.136737  4990 net.cpp:615] Scale96 <- Convolution96
I0612 11:05:14.136744  4990 net.cpp:576] Scale96 -> Convolution96 (in-place)
I0612 11:05:14.136786  4990 layer_factory.hpp:77] Creating layer Scale96
I0612 11:05:14.136924  4990 net.cpp:240] Setting up Scale96
I0612 11:05:14.136934  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.136937  4990 net.cpp:255] Memory required for data: 2815951360
I0612 11:05:14.136946  4990 layer_factory.hpp:77] Creating layer ReLU96
I0612 11:05:14.136956  4990 net.cpp:190] Creating Layer ReLU96
I0612 11:05:14.136961  4990 net.cpp:615] ReLU96 <- Convolution96
I0612 11:05:14.136967  4990 net.cpp:576] ReLU96 -> Convolution96 (in-place)
I0612 11:05:14.136975  4990 net.cpp:240] Setting up ReLU96
I0612 11:05:14.136979  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.136983  4990 net.cpp:255] Memory required for data: 2818048512
I0612 11:05:14.136987  4990 layer_factory.hpp:77] Creating layer Convolution97
I0612 11:05:14.136999  4990 net.cpp:190] Creating Layer Convolution97
I0612 11:05:14.137003  4990 net.cpp:615] Convolution97 <- Convolution96
I0612 11:05:14.137009  4990 net.cpp:589] Convolution97 -> Convolution97
I0612 11:05:14.138648  4990 net.cpp:240] Setting up Convolution97
I0612 11:05:14.138659  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.138664  4990 net.cpp:255] Memory required for data: 2820145664
I0612 11:05:14.138674  4990 layer_factory.hpp:77] Creating layer BatchNorm97
I0612 11:05:14.138686  4990 net.cpp:190] Creating Layer BatchNorm97
I0612 11:05:14.138691  4990 net.cpp:615] BatchNorm97 <- Convolution97
I0612 11:05:14.138697  4990 net.cpp:576] BatchNorm97 -> Convolution97 (in-place)
I0612 11:05:14.138918  4990 net.cpp:240] Setting up BatchNorm97
I0612 11:05:14.138927  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.138931  4990 net.cpp:255] Memory required for data: 2822242816
I0612 11:05:14.138943  4990 layer_factory.hpp:77] Creating layer Scale97
I0612 11:05:14.138952  4990 net.cpp:190] Creating Layer Scale97
I0612 11:05:14.138957  4990 net.cpp:615] Scale97 <- Convolution97
I0612 11:05:14.138964  4990 net.cpp:576] Scale97 -> Convolution97 (in-place)
I0612 11:05:14.139005  4990 layer_factory.hpp:77] Creating layer Scale97
I0612 11:05:14.139140  4990 net.cpp:240] Setting up Scale97
I0612 11:05:14.139148  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.139153  4990 net.cpp:255] Memory required for data: 2824339968
I0612 11:05:14.139161  4990 layer_factory.hpp:77] Creating layer Eltwise48
I0612 11:05:14.139171  4990 net.cpp:190] Creating Layer Eltwise48
I0612 11:05:14.139178  4990 net.cpp:615] Eltwise48 <- Eltwise47_ReLU95_0_split_1
I0612 11:05:14.139183  4990 net.cpp:615] Eltwise48 <- Convolution97
I0612 11:05:14.139189  4990 net.cpp:589] Eltwise48 -> Eltwise48
I0612 11:05:14.139211  4990 net.cpp:240] Setting up Eltwise48
I0612 11:05:14.139219  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.139222  4990 net.cpp:255] Memory required for data: 2826437120
I0612 11:05:14.139225  4990 layer_factory.hpp:77] Creating layer ReLU97
I0612 11:05:14.139232  4990 net.cpp:190] Creating Layer ReLU97
I0612 11:05:14.139236  4990 net.cpp:615] ReLU97 <- Eltwise48
I0612 11:05:14.139241  4990 net.cpp:576] ReLU97 -> Eltwise48 (in-place)
I0612 11:05:14.139248  4990 net.cpp:240] Setting up ReLU97
I0612 11:05:14.139253  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.139257  4990 net.cpp:255] Memory required for data: 2828534272
I0612 11:05:14.139261  4990 layer_factory.hpp:77] Creating layer Eltwise48_ReLU97_0_split
I0612 11:05:14.139271  4990 net.cpp:190] Creating Layer Eltwise48_ReLU97_0_split
I0612 11:05:14.139274  4990 net.cpp:615] Eltwise48_ReLU97_0_split <- Eltwise48
I0612 11:05:14.139281  4990 net.cpp:589] Eltwise48_ReLU97_0_split -> Eltwise48_ReLU97_0_split_0
I0612 11:05:14.139287  4990 net.cpp:589] Eltwise48_ReLU97_0_split -> Eltwise48_ReLU97_0_split_1
I0612 11:05:14.139328  4990 net.cpp:240] Setting up Eltwise48_ReLU97_0_split
I0612 11:05:14.139335  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.139340  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.139344  4990 net.cpp:255] Memory required for data: 2832728576
I0612 11:05:14.139351  4990 layer_factory.hpp:77] Creating layer Convolution98
I0612 11:05:14.139361  4990 net.cpp:190] Creating Layer Convolution98
I0612 11:05:14.139366  4990 net.cpp:615] Convolution98 <- Eltwise48_ReLU97_0_split_0
I0612 11:05:14.139374  4990 net.cpp:589] Convolution98 -> Convolution98
I0612 11:05:14.141005  4990 net.cpp:240] Setting up Convolution98
I0612 11:05:14.141016  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.141021  4990 net.cpp:255] Memory required for data: 2834825728
I0612 11:05:14.141031  4990 layer_factory.hpp:77] Creating layer BatchNorm98
I0612 11:05:14.141037  4990 net.cpp:190] Creating Layer BatchNorm98
I0612 11:05:14.141042  4990 net.cpp:615] BatchNorm98 <- Convolution98
I0612 11:05:14.141050  4990 net.cpp:576] BatchNorm98 -> Convolution98 (in-place)
I0612 11:05:14.141276  4990 net.cpp:240] Setting up BatchNorm98
I0612 11:05:14.141284  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.141288  4990 net.cpp:255] Memory required for data: 2836922880
I0612 11:05:14.141300  4990 layer_factory.hpp:77] Creating layer Scale98
I0612 11:05:14.141307  4990 net.cpp:190] Creating Layer Scale98
I0612 11:05:14.141312  4990 net.cpp:615] Scale98 <- Convolution98
I0612 11:05:14.141320  4990 net.cpp:576] Scale98 -> Convolution98 (in-place)
I0612 11:05:14.141360  4990 layer_factory.hpp:77] Creating layer Scale98
I0612 11:05:14.141492  4990 net.cpp:240] Setting up Scale98
I0612 11:05:14.141500  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.141504  4990 net.cpp:255] Memory required for data: 2839020032
I0612 11:05:14.141513  4990 layer_factory.hpp:77] Creating layer ReLU98
I0612 11:05:14.141520  4990 net.cpp:190] Creating Layer ReLU98
I0612 11:05:14.141525  4990 net.cpp:615] ReLU98 <- Convolution98
I0612 11:05:14.141532  4990 net.cpp:576] ReLU98 -> Convolution98 (in-place)
I0612 11:05:14.141541  4990 net.cpp:240] Setting up ReLU98
I0612 11:05:14.141546  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.141549  4990 net.cpp:255] Memory required for data: 2841117184
I0612 11:05:14.141553  4990 layer_factory.hpp:77] Creating layer Convolution99
I0612 11:05:14.141566  4990 net.cpp:190] Creating Layer Convolution99
I0612 11:05:14.141569  4990 net.cpp:615] Convolution99 <- Convolution98
I0612 11:05:14.141576  4990 net.cpp:589] Convolution99 -> Convolution99
I0612 11:05:14.143218  4990 net.cpp:240] Setting up Convolution99
I0612 11:05:14.143227  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.143231  4990 net.cpp:255] Memory required for data: 2843214336
I0612 11:05:14.143241  4990 layer_factory.hpp:77] Creating layer BatchNorm99
I0612 11:05:14.143251  4990 net.cpp:190] Creating Layer BatchNorm99
I0612 11:05:14.143256  4990 net.cpp:615] BatchNorm99 <- Convolution99
I0612 11:05:14.143265  4990 net.cpp:576] BatchNorm99 -> Convolution99 (in-place)
I0612 11:05:14.143491  4990 net.cpp:240] Setting up BatchNorm99
I0612 11:05:14.143501  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.143504  4990 net.cpp:255] Memory required for data: 2845311488
I0612 11:05:14.143518  4990 layer_factory.hpp:77] Creating layer Scale99
I0612 11:05:14.143527  4990 net.cpp:190] Creating Layer Scale99
I0612 11:05:14.143530  4990 net.cpp:615] Scale99 <- Convolution99
I0612 11:05:14.143537  4990 net.cpp:576] Scale99 -> Convolution99 (in-place)
I0612 11:05:14.143579  4990 layer_factory.hpp:77] Creating layer Scale99
I0612 11:05:14.143717  4990 net.cpp:240] Setting up Scale99
I0612 11:05:14.143724  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.143728  4990 net.cpp:255] Memory required for data: 2847408640
I0612 11:05:14.143738  4990 layer_factory.hpp:77] Creating layer Eltwise49
I0612 11:05:14.143745  4990 net.cpp:190] Creating Layer Eltwise49
I0612 11:05:14.143754  4990 net.cpp:615] Eltwise49 <- Eltwise48_ReLU97_0_split_1
I0612 11:05:14.143759  4990 net.cpp:615] Eltwise49 <- Convolution99
I0612 11:05:14.143765  4990 net.cpp:589] Eltwise49 -> Eltwise49
I0612 11:05:14.143787  4990 net.cpp:240] Setting up Eltwise49
I0612 11:05:14.143795  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.143803  4990 net.cpp:255] Memory required for data: 2849505792
I0612 11:05:14.143807  4990 layer_factory.hpp:77] Creating layer ReLU99
I0612 11:05:14.143817  4990 net.cpp:190] Creating Layer ReLU99
I0612 11:05:14.143821  4990 net.cpp:615] ReLU99 <- Eltwise49
I0612 11:05:14.143827  4990 net.cpp:576] ReLU99 -> Eltwise49 (in-place)
I0612 11:05:14.143834  4990 net.cpp:240] Setting up ReLU99
I0612 11:05:14.143839  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.143843  4990 net.cpp:255] Memory required for data: 2851602944
I0612 11:05:14.143847  4990 layer_factory.hpp:77] Creating layer Eltwise49_ReLU99_0_split
I0612 11:05:14.143853  4990 net.cpp:190] Creating Layer Eltwise49_ReLU99_0_split
I0612 11:05:14.143857  4990 net.cpp:615] Eltwise49_ReLU99_0_split <- Eltwise49
I0612 11:05:14.143862  4990 net.cpp:589] Eltwise49_ReLU99_0_split -> Eltwise49_ReLU99_0_split_0
I0612 11:05:14.143870  4990 net.cpp:589] Eltwise49_ReLU99_0_split -> Eltwise49_ReLU99_0_split_1
I0612 11:05:14.143910  4990 net.cpp:240] Setting up Eltwise49_ReLU99_0_split
I0612 11:05:14.143918  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.143923  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.143926  4990 net.cpp:255] Memory required for data: 2855797248
I0612 11:05:14.143930  4990 layer_factory.hpp:77] Creating layer Convolution100
I0612 11:05:14.143942  4990 net.cpp:190] Creating Layer Convolution100
I0612 11:05:14.143947  4990 net.cpp:615] Convolution100 <- Eltwise49_ReLU99_0_split_0
I0612 11:05:14.143954  4990 net.cpp:589] Convolution100 -> Convolution100
I0612 11:05:14.145609  4990 net.cpp:240] Setting up Convolution100
I0612 11:05:14.145622  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.145627  4990 net.cpp:255] Memory required for data: 2857894400
I0612 11:05:14.145638  4990 layer_factory.hpp:77] Creating layer BatchNorm100
I0612 11:05:14.145645  4990 net.cpp:190] Creating Layer BatchNorm100
I0612 11:05:14.145650  4990 net.cpp:615] BatchNorm100 <- Convolution100
I0612 11:05:14.145659  4990 net.cpp:576] BatchNorm100 -> Convolution100 (in-place)
I0612 11:05:14.145880  4990 net.cpp:240] Setting up BatchNorm100
I0612 11:05:14.145889  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.145894  4990 net.cpp:255] Memory required for data: 2859991552
I0612 11:05:14.145905  4990 layer_factory.hpp:77] Creating layer Scale100
I0612 11:05:14.145912  4990 net.cpp:190] Creating Layer Scale100
I0612 11:05:14.145916  4990 net.cpp:615] Scale100 <- Convolution100
I0612 11:05:14.145925  4990 net.cpp:576] Scale100 -> Convolution100 (in-place)
I0612 11:05:14.145962  4990 layer_factory.hpp:77] Creating layer Scale100
I0612 11:05:14.146095  4990 net.cpp:240] Setting up Scale100
I0612 11:05:14.146103  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.146107  4990 net.cpp:255] Memory required for data: 2862088704
I0612 11:05:14.146116  4990 layer_factory.hpp:77] Creating layer ReLU100
I0612 11:05:14.146123  4990 net.cpp:190] Creating Layer ReLU100
I0612 11:05:14.146127  4990 net.cpp:615] ReLU100 <- Convolution100
I0612 11:05:14.146136  4990 net.cpp:576] ReLU100 -> Convolution100 (in-place)
I0612 11:05:14.146142  4990 net.cpp:240] Setting up ReLU100
I0612 11:05:14.146148  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.146152  4990 net.cpp:255] Memory required for data: 2864185856
I0612 11:05:14.146155  4990 layer_factory.hpp:77] Creating layer Convolution101
I0612 11:05:14.146167  4990 net.cpp:190] Creating Layer Convolution101
I0612 11:05:14.146172  4990 net.cpp:615] Convolution101 <- Convolution100
I0612 11:05:14.146178  4990 net.cpp:589] Convolution101 -> Convolution101
I0612 11:05:14.147821  4990 net.cpp:240] Setting up Convolution101
I0612 11:05:14.147832  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.147836  4990 net.cpp:255] Memory required for data: 2866283008
I0612 11:05:14.147846  4990 layer_factory.hpp:77] Creating layer BatchNorm101
I0612 11:05:14.147861  4990 net.cpp:190] Creating Layer BatchNorm101
I0612 11:05:14.147871  4990 net.cpp:615] BatchNorm101 <- Convolution101
I0612 11:05:14.147878  4990 net.cpp:576] BatchNorm101 -> Convolution101 (in-place)
I0612 11:05:14.148102  4990 net.cpp:240] Setting up BatchNorm101
I0612 11:05:14.148110  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.148113  4990 net.cpp:255] Memory required for data: 2868380160
I0612 11:05:14.148126  4990 layer_factory.hpp:77] Creating layer Scale101
I0612 11:05:14.148133  4990 net.cpp:190] Creating Layer Scale101
I0612 11:05:14.148138  4990 net.cpp:615] Scale101 <- Convolution101
I0612 11:05:14.148144  4990 net.cpp:576] Scale101 -> Convolution101 (in-place)
I0612 11:05:14.148185  4990 layer_factory.hpp:77] Creating layer Scale101
I0612 11:05:14.148319  4990 net.cpp:240] Setting up Scale101
I0612 11:05:14.148326  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.148330  4990 net.cpp:255] Memory required for data: 2870477312
I0612 11:05:14.148339  4990 layer_factory.hpp:77] Creating layer Eltwise50
I0612 11:05:14.148349  4990 net.cpp:190] Creating Layer Eltwise50
I0612 11:05:14.148355  4990 net.cpp:615] Eltwise50 <- Eltwise49_ReLU99_0_split_1
I0612 11:05:14.148360  4990 net.cpp:615] Eltwise50 <- Convolution101
I0612 11:05:14.148365  4990 net.cpp:589] Eltwise50 -> Eltwise50
I0612 11:05:14.148386  4990 net.cpp:240] Setting up Eltwise50
I0612 11:05:14.148392  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.148396  4990 net.cpp:255] Memory required for data: 2872574464
I0612 11:05:14.148401  4990 layer_factory.hpp:77] Creating layer ReLU101
I0612 11:05:14.148409  4990 net.cpp:190] Creating Layer ReLU101
I0612 11:05:14.148413  4990 net.cpp:615] ReLU101 <- Eltwise50
I0612 11:05:14.148419  4990 net.cpp:576] ReLU101 -> Eltwise50 (in-place)
I0612 11:05:14.148425  4990 net.cpp:240] Setting up ReLU101
I0612 11:05:14.148430  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.148434  4990 net.cpp:255] Memory required for data: 2874671616
I0612 11:05:14.148438  4990 layer_factory.hpp:77] Creating layer Eltwise50_ReLU101_0_split
I0612 11:05:14.148444  4990 net.cpp:190] Creating Layer Eltwise50_ReLU101_0_split
I0612 11:05:14.148448  4990 net.cpp:615] Eltwise50_ReLU101_0_split <- Eltwise50
I0612 11:05:14.148453  4990 net.cpp:589] Eltwise50_ReLU101_0_split -> Eltwise50_ReLU101_0_split_0
I0612 11:05:14.148460  4990 net.cpp:589] Eltwise50_ReLU101_0_split -> Eltwise50_ReLU101_0_split_1
I0612 11:05:14.148500  4990 net.cpp:240] Setting up Eltwise50_ReLU101_0_split
I0612 11:05:14.148509  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.148514  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.148517  4990 net.cpp:255] Memory required for data: 2878865920
I0612 11:05:14.148521  4990 layer_factory.hpp:77] Creating layer Convolution102
I0612 11:05:14.148579  4990 net.cpp:190] Creating Layer Convolution102
I0612 11:05:14.148587  4990 net.cpp:615] Convolution102 <- Eltwise50_ReLU101_0_split_0
I0612 11:05:14.148594  4990 net.cpp:589] Convolution102 -> Convolution102
I0612 11:05:14.150916  4990 net.cpp:240] Setting up Convolution102
I0612 11:05:14.150933  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.150938  4990 net.cpp:255] Memory required for data: 2880963072
I0612 11:05:14.150949  4990 layer_factory.hpp:77] Creating layer BatchNorm102
I0612 11:05:14.150960  4990 net.cpp:190] Creating Layer BatchNorm102
I0612 11:05:14.150965  4990 net.cpp:615] BatchNorm102 <- Convolution102
I0612 11:05:14.150972  4990 net.cpp:576] BatchNorm102 -> Convolution102 (in-place)
I0612 11:05:14.151204  4990 net.cpp:240] Setting up BatchNorm102
I0612 11:05:14.151213  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.151217  4990 net.cpp:255] Memory required for data: 2883060224
I0612 11:05:14.151229  4990 layer_factory.hpp:77] Creating layer Scale102
I0612 11:05:14.151237  4990 net.cpp:190] Creating Layer Scale102
I0612 11:05:14.151242  4990 net.cpp:615] Scale102 <- Convolution102
I0612 11:05:14.151247  4990 net.cpp:576] Scale102 -> Convolution102 (in-place)
I0612 11:05:14.151296  4990 layer_factory.hpp:77] Creating layer Scale102
I0612 11:05:14.151428  4990 net.cpp:240] Setting up Scale102
I0612 11:05:14.151437  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.151440  4990 net.cpp:255] Memory required for data: 2885157376
I0612 11:05:14.151453  4990 layer_factory.hpp:77] Creating layer ReLU102
I0612 11:05:14.151459  4990 net.cpp:190] Creating Layer ReLU102
I0612 11:05:14.151464  4990 net.cpp:615] ReLU102 <- Convolution102
I0612 11:05:14.151470  4990 net.cpp:576] ReLU102 -> Convolution102 (in-place)
I0612 11:05:14.151478  4990 net.cpp:240] Setting up ReLU102
I0612 11:05:14.151482  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.151486  4990 net.cpp:255] Memory required for data: 2887254528
I0612 11:05:14.151490  4990 layer_factory.hpp:77] Creating layer Convolution103
I0612 11:05:14.151502  4990 net.cpp:190] Creating Layer Convolution103
I0612 11:05:14.151507  4990 net.cpp:615] Convolution103 <- Convolution102
I0612 11:05:14.151516  4990 net.cpp:589] Convolution103 -> Convolution103
I0612 11:05:14.153144  4990 net.cpp:240] Setting up Convolution103
I0612 11:05:14.153156  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.153159  4990 net.cpp:255] Memory required for data: 2889351680
I0612 11:05:14.153168  4990 layer_factory.hpp:77] Creating layer BatchNorm103
I0612 11:05:14.153178  4990 net.cpp:190] Creating Layer BatchNorm103
I0612 11:05:14.153183  4990 net.cpp:615] BatchNorm103 <- Convolution103
I0612 11:05:14.153192  4990 net.cpp:576] BatchNorm103 -> Convolution103 (in-place)
I0612 11:05:14.153406  4990 net.cpp:240] Setting up BatchNorm103
I0612 11:05:14.153414  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.153419  4990 net.cpp:255] Memory required for data: 2891448832
I0612 11:05:14.153430  4990 layer_factory.hpp:77] Creating layer Scale103
I0612 11:05:14.153442  4990 net.cpp:190] Creating Layer Scale103
I0612 11:05:14.153447  4990 net.cpp:615] Scale103 <- Convolution103
I0612 11:05:14.153453  4990 net.cpp:576] Scale103 -> Convolution103 (in-place)
I0612 11:05:14.153493  4990 layer_factory.hpp:77] Creating layer Scale103
I0612 11:05:14.153625  4990 net.cpp:240] Setting up Scale103
I0612 11:05:14.153633  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.153637  4990 net.cpp:255] Memory required for data: 2893545984
I0612 11:05:14.153648  4990 layer_factory.hpp:77] Creating layer Eltwise51
I0612 11:05:14.153656  4990 net.cpp:190] Creating Layer Eltwise51
I0612 11:05:14.153662  4990 net.cpp:615] Eltwise51 <- Eltwise50_ReLU101_0_split_1
I0612 11:05:14.153667  4990 net.cpp:615] Eltwise51 <- Convolution103
I0612 11:05:14.153676  4990 net.cpp:589] Eltwise51 -> Eltwise51
I0612 11:05:14.153697  4990 net.cpp:240] Setting up Eltwise51
I0612 11:05:14.153703  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.153707  4990 net.cpp:255] Memory required for data: 2895643136
I0612 11:05:14.153712  4990 layer_factory.hpp:77] Creating layer ReLU103
I0612 11:05:14.153717  4990 net.cpp:190] Creating Layer ReLU103
I0612 11:05:14.153722  4990 net.cpp:615] ReLU103 <- Eltwise51
I0612 11:05:14.153729  4990 net.cpp:576] ReLU103 -> Eltwise51 (in-place)
I0612 11:05:14.153736  4990 net.cpp:240] Setting up ReLU103
I0612 11:05:14.153741  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.153745  4990 net.cpp:255] Memory required for data: 2897740288
I0612 11:05:14.153749  4990 layer_factory.hpp:77] Creating layer Eltwise51_ReLU103_0_split
I0612 11:05:14.153755  4990 net.cpp:190] Creating Layer Eltwise51_ReLU103_0_split
I0612 11:05:14.153759  4990 net.cpp:615] Eltwise51_ReLU103_0_split <- Eltwise51
I0612 11:05:14.153764  4990 net.cpp:589] Eltwise51_ReLU103_0_split -> Eltwise51_ReLU103_0_split_0
I0612 11:05:14.153772  4990 net.cpp:589] Eltwise51_ReLU103_0_split -> Eltwise51_ReLU103_0_split_1
I0612 11:05:14.153812  4990 net.cpp:240] Setting up Eltwise51_ReLU103_0_split
I0612 11:05:14.153820  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.153825  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.153831  4990 net.cpp:255] Memory required for data: 2901934592
I0612 11:05:14.153836  4990 layer_factory.hpp:77] Creating layer Convolution104
I0612 11:05:14.153846  4990 net.cpp:190] Creating Layer Convolution104
I0612 11:05:14.153849  4990 net.cpp:615] Convolution104 <- Eltwise51_ReLU103_0_split_0
I0612 11:05:14.153859  4990 net.cpp:589] Convolution104 -> Convolution104
I0612 11:05:14.155498  4990 net.cpp:240] Setting up Convolution104
I0612 11:05:14.155508  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.155513  4990 net.cpp:255] Memory required for data: 2904031744
I0612 11:05:14.155522  4990 layer_factory.hpp:77] Creating layer BatchNorm104
I0612 11:05:14.155530  4990 net.cpp:190] Creating Layer BatchNorm104
I0612 11:05:14.155534  4990 net.cpp:615] BatchNorm104 <- Convolution104
I0612 11:05:14.155544  4990 net.cpp:576] BatchNorm104 -> Convolution104 (in-place)
I0612 11:05:14.155762  4990 net.cpp:240] Setting up BatchNorm104
I0612 11:05:14.155771  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.155774  4990 net.cpp:255] Memory required for data: 2906128896
I0612 11:05:14.155786  4990 layer_factory.hpp:77] Creating layer Scale104
I0612 11:05:14.155793  4990 net.cpp:190] Creating Layer Scale104
I0612 11:05:14.155798  4990 net.cpp:615] Scale104 <- Convolution104
I0612 11:05:14.155807  4990 net.cpp:576] Scale104 -> Convolution104 (in-place)
I0612 11:05:14.155844  4990 layer_factory.hpp:77] Creating layer Scale104
I0612 11:05:14.155977  4990 net.cpp:240] Setting up Scale104
I0612 11:05:14.155984  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.155988  4990 net.cpp:255] Memory required for data: 2908226048
I0612 11:05:14.155997  4990 layer_factory.hpp:77] Creating layer ReLU104
I0612 11:05:14.156004  4990 net.cpp:190] Creating Layer ReLU104
I0612 11:05:14.156009  4990 net.cpp:615] ReLU104 <- Convolution104
I0612 11:05:14.156018  4990 net.cpp:576] ReLU104 -> Convolution104 (in-place)
I0612 11:05:14.156024  4990 net.cpp:240] Setting up ReLU104
I0612 11:05:14.156030  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.156033  4990 net.cpp:255] Memory required for data: 2910323200
I0612 11:05:14.156038  4990 layer_factory.hpp:77] Creating layer Convolution105
I0612 11:05:14.156052  4990 net.cpp:190] Creating Layer Convolution105
I0612 11:05:14.156056  4990 net.cpp:615] Convolution105 <- Convolution104
I0612 11:05:14.156064  4990 net.cpp:589] Convolution105 -> Convolution105
I0612 11:05:14.157694  4990 net.cpp:240] Setting up Convolution105
I0612 11:05:14.157704  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.157708  4990 net.cpp:255] Memory required for data: 2912420352
I0612 11:05:14.157718  4990 layer_factory.hpp:77] Creating layer BatchNorm105
I0612 11:05:14.157728  4990 net.cpp:190] Creating Layer BatchNorm105
I0612 11:05:14.157733  4990 net.cpp:615] BatchNorm105 <- Convolution105
I0612 11:05:14.157739  4990 net.cpp:576] BatchNorm105 -> Convolution105 (in-place)
I0612 11:05:14.157956  4990 net.cpp:240] Setting up BatchNorm105
I0612 11:05:14.157964  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.157968  4990 net.cpp:255] Memory required for data: 2914517504
I0612 11:05:14.157979  4990 layer_factory.hpp:77] Creating layer Scale105
I0612 11:05:14.157987  4990 net.cpp:190] Creating Layer Scale105
I0612 11:05:14.157991  4990 net.cpp:615] Scale105 <- Convolution105
I0612 11:05:14.157996  4990 net.cpp:576] Scale105 -> Convolution105 (in-place)
I0612 11:05:14.158040  4990 layer_factory.hpp:77] Creating layer Scale105
I0612 11:05:14.158174  4990 net.cpp:240] Setting up Scale105
I0612 11:05:14.158182  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.158186  4990 net.cpp:255] Memory required for data: 2916614656
I0612 11:05:14.158195  4990 layer_factory.hpp:77] Creating layer Eltwise52
I0612 11:05:14.158205  4990 net.cpp:190] Creating Layer Eltwise52
I0612 11:05:14.158210  4990 net.cpp:615] Eltwise52 <- Eltwise51_ReLU103_0_split_1
I0612 11:05:14.158216  4990 net.cpp:615] Eltwise52 <- Convolution105
I0612 11:05:14.158226  4990 net.cpp:589] Eltwise52 -> Eltwise52
I0612 11:05:14.158247  4990 net.cpp:240] Setting up Eltwise52
I0612 11:05:14.158254  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.158258  4990 net.cpp:255] Memory required for data: 2918711808
I0612 11:05:14.158262  4990 layer_factory.hpp:77] Creating layer ReLU105
I0612 11:05:14.158272  4990 net.cpp:190] Creating Layer ReLU105
I0612 11:05:14.158275  4990 net.cpp:615] ReLU105 <- Eltwise52
I0612 11:05:14.158282  4990 net.cpp:576] ReLU105 -> Eltwise52 (in-place)
I0612 11:05:14.158288  4990 net.cpp:240] Setting up ReLU105
I0612 11:05:14.158293  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.158298  4990 net.cpp:255] Memory required for data: 2920808960
I0612 11:05:14.158300  4990 layer_factory.hpp:77] Creating layer Eltwise52_ReLU105_0_split
I0612 11:05:14.158308  4990 net.cpp:190] Creating Layer Eltwise52_ReLU105_0_split
I0612 11:05:14.158311  4990 net.cpp:615] Eltwise52_ReLU105_0_split <- Eltwise52
I0612 11:05:14.158316  4990 net.cpp:589] Eltwise52_ReLU105_0_split -> Eltwise52_ReLU105_0_split_0
I0612 11:05:14.158324  4990 net.cpp:589] Eltwise52_ReLU105_0_split -> Eltwise52_ReLU105_0_split_1
I0612 11:05:14.158372  4990 net.cpp:240] Setting up Eltwise52_ReLU105_0_split
I0612 11:05:14.158380  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.158385  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.158390  4990 net.cpp:255] Memory required for data: 2925003264
I0612 11:05:14.158393  4990 layer_factory.hpp:77] Creating layer Convolution106
I0612 11:05:14.158406  4990 net.cpp:190] Creating Layer Convolution106
I0612 11:05:14.158411  4990 net.cpp:615] Convolution106 <- Eltwise52_ReLU105_0_split_0
I0612 11:05:14.158417  4990 net.cpp:589] Convolution106 -> Convolution106
I0612 11:05:14.160048  4990 net.cpp:240] Setting up Convolution106
I0612 11:05:14.160056  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.160061  4990 net.cpp:255] Memory required for data: 2927100416
I0612 11:05:14.160071  4990 layer_factory.hpp:77] Creating layer BatchNorm106
I0612 11:05:14.160080  4990 net.cpp:190] Creating Layer BatchNorm106
I0612 11:05:14.160085  4990 net.cpp:615] BatchNorm106 <- Convolution106
I0612 11:05:14.160096  4990 net.cpp:576] BatchNorm106 -> Convolution106 (in-place)
I0612 11:05:14.160313  4990 net.cpp:240] Setting up BatchNorm106
I0612 11:05:14.160321  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.160325  4990 net.cpp:255] Memory required for data: 2929197568
I0612 11:05:14.160336  4990 layer_factory.hpp:77] Creating layer Scale106
I0612 11:05:14.160346  4990 net.cpp:190] Creating Layer Scale106
I0612 11:05:14.160351  4990 net.cpp:615] Scale106 <- Convolution106
I0612 11:05:14.160357  4990 net.cpp:576] Scale106 -> Convolution106 (in-place)
I0612 11:05:14.160398  4990 layer_factory.hpp:77] Creating layer Scale106
I0612 11:05:14.160532  4990 net.cpp:240] Setting up Scale106
I0612 11:05:14.160540  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.160544  4990 net.cpp:255] Memory required for data: 2931294720
I0612 11:05:14.160557  4990 layer_factory.hpp:77] Creating layer ReLU106
I0612 11:05:14.160563  4990 net.cpp:190] Creating Layer ReLU106
I0612 11:05:14.160567  4990 net.cpp:615] ReLU106 <- Convolution106
I0612 11:05:14.160573  4990 net.cpp:576] ReLU106 -> Convolution106 (in-place)
I0612 11:05:14.160580  4990 net.cpp:240] Setting up ReLU106
I0612 11:05:14.160585  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.160589  4990 net.cpp:255] Memory required for data: 2933391872
I0612 11:05:14.160593  4990 layer_factory.hpp:77] Creating layer Convolution107
I0612 11:05:14.160605  4990 net.cpp:190] Creating Layer Convolution107
I0612 11:05:14.160609  4990 net.cpp:615] Convolution107 <- Convolution106
I0612 11:05:14.160619  4990 net.cpp:589] Convolution107 -> Convolution107
I0612 11:05:14.162242  4990 net.cpp:240] Setting up Convolution107
I0612 11:05:14.162252  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.162256  4990 net.cpp:255] Memory required for data: 2935489024
I0612 11:05:14.162269  4990 layer_factory.hpp:77] Creating layer BatchNorm107
I0612 11:05:14.162277  4990 net.cpp:190] Creating Layer BatchNorm107
I0612 11:05:14.162281  4990 net.cpp:615] BatchNorm107 <- Convolution107
I0612 11:05:14.162289  4990 net.cpp:576] BatchNorm107 -> Convolution107 (in-place)
I0612 11:05:14.162526  4990 net.cpp:240] Setting up BatchNorm107
I0612 11:05:14.162536  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.162540  4990 net.cpp:255] Memory required for data: 2937586176
I0612 11:05:14.162552  4990 layer_factory.hpp:77] Creating layer Scale107
I0612 11:05:14.162559  4990 net.cpp:190] Creating Layer Scale107
I0612 11:05:14.162564  4990 net.cpp:615] Scale107 <- Convolution107
I0612 11:05:14.162572  4990 net.cpp:576] Scale107 -> Convolution107 (in-place)
I0612 11:05:14.162611  4990 layer_factory.hpp:77] Creating layer Scale107
I0612 11:05:14.162747  4990 net.cpp:240] Setting up Scale107
I0612 11:05:14.162755  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.162760  4990 net.cpp:255] Memory required for data: 2939683328
I0612 11:05:14.162768  4990 layer_factory.hpp:77] Creating layer Eltwise53
I0612 11:05:14.162776  4990 net.cpp:190] Creating Layer Eltwise53
I0612 11:05:14.162781  4990 net.cpp:615] Eltwise53 <- Eltwise52_ReLU105_0_split_1
I0612 11:05:14.162786  4990 net.cpp:615] Eltwise53 <- Convolution107
I0612 11:05:14.162794  4990 net.cpp:589] Eltwise53 -> Eltwise53
I0612 11:05:14.162817  4990 net.cpp:240] Setting up Eltwise53
I0612 11:05:14.162822  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.162827  4990 net.cpp:255] Memory required for data: 2941780480
I0612 11:05:14.162830  4990 layer_factory.hpp:77] Creating layer ReLU107
I0612 11:05:14.162838  4990 net.cpp:190] Creating Layer ReLU107
I0612 11:05:14.162843  4990 net.cpp:615] ReLU107 <- Eltwise53
I0612 11:05:14.162848  4990 net.cpp:576] ReLU107 -> Eltwise53 (in-place)
I0612 11:05:14.162855  4990 net.cpp:240] Setting up ReLU107
I0612 11:05:14.162861  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.162864  4990 net.cpp:255] Memory required for data: 2943877632
I0612 11:05:14.162868  4990 layer_factory.hpp:77] Creating layer Eltwise53_ReLU107_0_split
I0612 11:05:14.162874  4990 net.cpp:190] Creating Layer Eltwise53_ReLU107_0_split
I0612 11:05:14.162878  4990 net.cpp:615] Eltwise53_ReLU107_0_split <- Eltwise53
I0612 11:05:14.162884  4990 net.cpp:589] Eltwise53_ReLU107_0_split -> Eltwise53_ReLU107_0_split_0
I0612 11:05:14.162894  4990 net.cpp:589] Eltwise53_ReLU107_0_split -> Eltwise53_ReLU107_0_split_1
I0612 11:05:14.162932  4990 net.cpp:240] Setting up Eltwise53_ReLU107_0_split
I0612 11:05:14.162938  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.162943  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.162947  4990 net.cpp:255] Memory required for data: 2948071936
I0612 11:05:14.162950  4990 layer_factory.hpp:77] Creating layer Convolution108
I0612 11:05:14.162962  4990 net.cpp:190] Creating Layer Convolution108
I0612 11:05:14.162967  4990 net.cpp:615] Convolution108 <- Eltwise53_ReLU107_0_split_0
I0612 11:05:14.162976  4990 net.cpp:589] Convolution108 -> Convolution108
I0612 11:05:14.164607  4990 net.cpp:240] Setting up Convolution108
I0612 11:05:14.164616  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.164620  4990 net.cpp:255] Memory required for data: 2950169088
I0612 11:05:14.164630  4990 layer_factory.hpp:77] Creating layer BatchNorm108
I0612 11:05:14.164639  4990 net.cpp:190] Creating Layer BatchNorm108
I0612 11:05:14.164644  4990 net.cpp:615] BatchNorm108 <- Convolution108
I0612 11:05:14.164650  4990 net.cpp:576] BatchNorm108 -> Convolution108 (in-place)
I0612 11:05:14.164868  4990 net.cpp:240] Setting up BatchNorm108
I0612 11:05:14.164876  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.164880  4990 net.cpp:255] Memory required for data: 2952266240
I0612 11:05:14.164891  4990 layer_factory.hpp:77] Creating layer Scale108
I0612 11:05:14.164898  4990 net.cpp:190] Creating Layer Scale108
I0612 11:05:14.164906  4990 net.cpp:615] Scale108 <- Convolution108
I0612 11:05:14.164912  4990 net.cpp:576] Scale108 -> Convolution108 (in-place)
I0612 11:05:14.164953  4990 layer_factory.hpp:77] Creating layer Scale108
I0612 11:05:14.165087  4990 net.cpp:240] Setting up Scale108
I0612 11:05:14.165096  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.165099  4990 net.cpp:255] Memory required for data: 2954363392
I0612 11:05:14.165108  4990 layer_factory.hpp:77] Creating layer ReLU108
I0612 11:05:14.165117  4990 net.cpp:190] Creating Layer ReLU108
I0612 11:05:14.165122  4990 net.cpp:615] ReLU108 <- Convolution108
I0612 11:05:14.165128  4990 net.cpp:576] ReLU108 -> Convolution108 (in-place)
I0612 11:05:14.165135  4990 net.cpp:240] Setting up ReLU108
I0612 11:05:14.165140  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.165144  4990 net.cpp:255] Memory required for data: 2956460544
I0612 11:05:14.165148  4990 layer_factory.hpp:77] Creating layer Convolution109
I0612 11:05:14.165159  4990 net.cpp:190] Creating Layer Convolution109
I0612 11:05:14.165164  4990 net.cpp:615] Convolution109 <- Convolution108
I0612 11:05:14.165170  4990 net.cpp:589] Convolution109 -> Convolution109
I0612 11:05:14.167489  4990 net.cpp:240] Setting up Convolution109
I0612 11:05:14.167505  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.167510  4990 net.cpp:255] Memory required for data: 2958557696
I0612 11:05:14.167520  4990 layer_factory.hpp:77] Creating layer BatchNorm109
I0612 11:05:14.167531  4990 net.cpp:190] Creating Layer BatchNorm109
I0612 11:05:14.167536  4990 net.cpp:615] BatchNorm109 <- Convolution109
I0612 11:05:14.167542  4990 net.cpp:576] BatchNorm109 -> Convolution109 (in-place)
I0612 11:05:14.167765  4990 net.cpp:240] Setting up BatchNorm109
I0612 11:05:14.167774  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.167778  4990 net.cpp:255] Memory required for data: 2960654848
I0612 11:05:14.167790  4990 layer_factory.hpp:77] Creating layer Scale109
I0612 11:05:14.167798  4990 net.cpp:190] Creating Layer Scale109
I0612 11:05:14.167803  4990 net.cpp:615] Scale109 <- Convolution109
I0612 11:05:14.167809  4990 net.cpp:576] Scale109 -> Convolution109 (in-place)
I0612 11:05:14.167853  4990 layer_factory.hpp:77] Creating layer Scale109
I0612 11:05:14.167989  4990 net.cpp:240] Setting up Scale109
I0612 11:05:14.167996  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.167999  4990 net.cpp:255] Memory required for data: 2962752000
I0612 11:05:14.168009  4990 layer_factory.hpp:77] Creating layer Eltwise54
I0612 11:05:14.168020  4990 net.cpp:190] Creating Layer Eltwise54
I0612 11:05:14.168025  4990 net.cpp:615] Eltwise54 <- Eltwise53_ReLU107_0_split_1
I0612 11:05:14.168030  4990 net.cpp:615] Eltwise54 <- Convolution109
I0612 11:05:14.168036  4990 net.cpp:589] Eltwise54 -> Eltwise54
I0612 11:05:14.168057  4990 net.cpp:240] Setting up Eltwise54
I0612 11:05:14.168064  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.168068  4990 net.cpp:255] Memory required for data: 2964849152
I0612 11:05:14.168072  4990 layer_factory.hpp:77] Creating layer ReLU109
I0612 11:05:14.168081  4990 net.cpp:190] Creating Layer ReLU109
I0612 11:05:14.168087  4990 net.cpp:615] ReLU109 <- Eltwise54
I0612 11:05:14.168092  4990 net.cpp:576] ReLU109 -> Eltwise54 (in-place)
I0612 11:05:14.168100  4990 net.cpp:240] Setting up ReLU109
I0612 11:05:14.168105  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.168109  4990 net.cpp:255] Memory required for data: 2966946304
I0612 11:05:14.168113  4990 layer_factory.hpp:77] Creating layer Pooling4
I0612 11:05:14.168120  4990 net.cpp:190] Creating Layer Pooling4
I0612 11:05:14.168124  4990 net.cpp:615] Pooling4 <- Eltwise54
I0612 11:05:14.168131  4990 net.cpp:589] Pooling4 -> Pooling4
I0612 11:05:14.168161  4990 net.cpp:240] Setting up Pooling4
I0612 11:05:14.168169  4990 net.cpp:247] Top shape: 128 64 1 1 (8192)
I0612 11:05:14.168172  4990 net.cpp:255] Memory required for data: 2966979072
I0612 11:05:14.168176  4990 layer_factory.hpp:77] Creating layer InnerProduct1
I0612 11:05:14.168187  4990 net.cpp:190] Creating Layer InnerProduct1
I0612 11:05:14.168192  4990 net.cpp:615] InnerProduct1 <- Pooling4
I0612 11:05:14.168198  4990 net.cpp:589] InnerProduct1 -> InnerProduct1
I0612 11:05:14.168359  4990 net.cpp:240] Setting up InnerProduct1
I0612 11:05:14.168368  4990 net.cpp:247] Top shape: 128 10 (1280)
I0612 11:05:14.168372  4990 net.cpp:255] Memory required for data: 2966984192
I0612 11:05:14.168382  4990 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0612 11:05:14.168390  4990 net.cpp:190] Creating Layer SoftmaxWithLoss1
I0612 11:05:14.168395  4990 net.cpp:615] SoftmaxWithLoss1 <- InnerProduct1
I0612 11:05:14.168401  4990 net.cpp:615] SoftmaxWithLoss1 <- Data2
I0612 11:05:14.168411  4990 net.cpp:589] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0612 11:05:14.168432  4990 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0612 11:05:14.168545  4990 net.cpp:240] Setting up SoftmaxWithLoss1
I0612 11:05:14.168553  4990 net.cpp:247] Top shape: (1)
I0612 11:05:14.168557  4990 net.cpp:250]     with loss weight 1
I0612 11:05:14.168581  4990 net.cpp:255] Memory required for data: 2966984196
I0612 11:05:14.168586  4990 net.cpp:316] SoftmaxWithLoss1 needs backward computation.
I0612 11:05:14.168591  4990 net.cpp:316] InnerProduct1 needs backward computation.
I0612 11:05:14.168593  4990 net.cpp:316] Pooling4 needs backward computation.
I0612 11:05:14.168597  4990 net.cpp:316] ReLU109 needs backward computation.
I0612 11:05:14.168601  4990 net.cpp:316] Eltwise54 needs backward computation.
I0612 11:05:14.168606  4990 net.cpp:316] Scale109 needs backward computation.
I0612 11:05:14.168611  4990 net.cpp:316] BatchNorm109 needs backward computation.
I0612 11:05:14.168613  4990 net.cpp:316] Convolution109 needs backward computation.
I0612 11:05:14.168617  4990 net.cpp:316] ReLU108 needs backward computation.
I0612 11:05:14.168622  4990 net.cpp:316] Scale108 needs backward computation.
I0612 11:05:14.168624  4990 net.cpp:316] BatchNorm108 needs backward computation.
I0612 11:05:14.168628  4990 net.cpp:316] Convolution108 needs backward computation.
I0612 11:05:14.168632  4990 net.cpp:316] Eltwise53_ReLU107_0_split needs backward computation.
I0612 11:05:14.168637  4990 net.cpp:316] ReLU107 needs backward computation.
I0612 11:05:14.168639  4990 net.cpp:316] Eltwise53 needs backward computation.
I0612 11:05:14.168644  4990 net.cpp:316] Scale107 needs backward computation.
I0612 11:05:14.168648  4990 net.cpp:316] BatchNorm107 needs backward computation.
I0612 11:05:14.168651  4990 net.cpp:316] Convolution107 needs backward computation.
I0612 11:05:14.168655  4990 net.cpp:316] ReLU106 needs backward computation.
I0612 11:05:14.168658  4990 net.cpp:316] Scale106 needs backward computation.
I0612 11:05:14.168663  4990 net.cpp:316] BatchNorm106 needs backward computation.
I0612 11:05:14.168665  4990 net.cpp:316] Convolution106 needs backward computation.
I0612 11:05:14.168670  4990 net.cpp:316] Eltwise52_ReLU105_0_split needs backward computation.
I0612 11:05:14.168674  4990 net.cpp:316] ReLU105 needs backward computation.
I0612 11:05:14.168678  4990 net.cpp:316] Eltwise52 needs backward computation.
I0612 11:05:14.168681  4990 net.cpp:316] Scale105 needs backward computation.
I0612 11:05:14.168685  4990 net.cpp:316] BatchNorm105 needs backward computation.
I0612 11:05:14.168689  4990 net.cpp:316] Convolution105 needs backward computation.
I0612 11:05:14.168694  4990 net.cpp:316] ReLU104 needs backward computation.
I0612 11:05:14.168696  4990 net.cpp:316] Scale104 needs backward computation.
I0612 11:05:14.168700  4990 net.cpp:316] BatchNorm104 needs backward computation.
I0612 11:05:14.168704  4990 net.cpp:316] Convolution104 needs backward computation.
I0612 11:05:14.168707  4990 net.cpp:316] Eltwise51_ReLU103_0_split needs backward computation.
I0612 11:05:14.168711  4990 net.cpp:316] ReLU103 needs backward computation.
I0612 11:05:14.168715  4990 net.cpp:316] Eltwise51 needs backward computation.
I0612 11:05:14.168720  4990 net.cpp:316] Scale103 needs backward computation.
I0612 11:05:14.168727  4990 net.cpp:316] BatchNorm103 needs backward computation.
I0612 11:05:14.168730  4990 net.cpp:316] Convolution103 needs backward computation.
I0612 11:05:14.168735  4990 net.cpp:316] ReLU102 needs backward computation.
I0612 11:05:14.168738  4990 net.cpp:316] Scale102 needs backward computation.
I0612 11:05:14.168741  4990 net.cpp:316] BatchNorm102 needs backward computation.
I0612 11:05:14.168745  4990 net.cpp:316] Convolution102 needs backward computation.
I0612 11:05:14.168750  4990 net.cpp:316] Eltwise50_ReLU101_0_split needs backward computation.
I0612 11:05:14.168753  4990 net.cpp:316] ReLU101 needs backward computation.
I0612 11:05:14.168757  4990 net.cpp:316] Eltwise50 needs backward computation.
I0612 11:05:14.168761  4990 net.cpp:316] Scale101 needs backward computation.
I0612 11:05:14.168766  4990 net.cpp:316] BatchNorm101 needs backward computation.
I0612 11:05:14.168768  4990 net.cpp:316] Convolution101 needs backward computation.
I0612 11:05:14.168772  4990 net.cpp:316] ReLU100 needs backward computation.
I0612 11:05:14.168776  4990 net.cpp:316] Scale100 needs backward computation.
I0612 11:05:14.168779  4990 net.cpp:316] BatchNorm100 needs backward computation.
I0612 11:05:14.168782  4990 net.cpp:316] Convolution100 needs backward computation.
I0612 11:05:14.168787  4990 net.cpp:316] Eltwise49_ReLU99_0_split needs backward computation.
I0612 11:05:14.168792  4990 net.cpp:316] ReLU99 needs backward computation.
I0612 11:05:14.168795  4990 net.cpp:316] Eltwise49 needs backward computation.
I0612 11:05:14.168799  4990 net.cpp:316] Scale99 needs backward computation.
I0612 11:05:14.168803  4990 net.cpp:316] BatchNorm99 needs backward computation.
I0612 11:05:14.168807  4990 net.cpp:316] Convolution99 needs backward computation.
I0612 11:05:14.168812  4990 net.cpp:316] ReLU98 needs backward computation.
I0612 11:05:14.168815  4990 net.cpp:316] Scale98 needs backward computation.
I0612 11:05:14.168818  4990 net.cpp:316] BatchNorm98 needs backward computation.
I0612 11:05:14.168823  4990 net.cpp:316] Convolution98 needs backward computation.
I0612 11:05:14.168826  4990 net.cpp:316] Eltwise48_ReLU97_0_split needs backward computation.
I0612 11:05:14.168830  4990 net.cpp:316] ReLU97 needs backward computation.
I0612 11:05:14.168834  4990 net.cpp:316] Eltwise48 needs backward computation.
I0612 11:05:14.168839  4990 net.cpp:316] Scale97 needs backward computation.
I0612 11:05:14.168843  4990 net.cpp:316] BatchNorm97 needs backward computation.
I0612 11:05:14.168846  4990 net.cpp:316] Convolution97 needs backward computation.
I0612 11:05:14.168850  4990 net.cpp:316] ReLU96 needs backward computation.
I0612 11:05:14.168854  4990 net.cpp:316] Scale96 needs backward computation.
I0612 11:05:14.168858  4990 net.cpp:316] BatchNorm96 needs backward computation.
I0612 11:05:14.168861  4990 net.cpp:316] Convolution96 needs backward computation.
I0612 11:05:14.168865  4990 net.cpp:316] Eltwise47_ReLU95_0_split needs backward computation.
I0612 11:05:14.168869  4990 net.cpp:316] ReLU95 needs backward computation.
I0612 11:05:14.168874  4990 net.cpp:316] Eltwise47 needs backward computation.
I0612 11:05:14.168880  4990 net.cpp:316] Scale95 needs backward computation.
I0612 11:05:14.168884  4990 net.cpp:316] BatchNorm95 needs backward computation.
I0612 11:05:14.168887  4990 net.cpp:316] Convolution95 needs backward computation.
I0612 11:05:14.168891  4990 net.cpp:316] ReLU94 needs backward computation.
I0612 11:05:14.168895  4990 net.cpp:316] Scale94 needs backward computation.
I0612 11:05:14.168900  4990 net.cpp:316] BatchNorm94 needs backward computation.
I0612 11:05:14.168902  4990 net.cpp:316] Convolution94 needs backward computation.
I0612 11:05:14.168906  4990 net.cpp:316] Eltwise46_ReLU93_0_split needs backward computation.
I0612 11:05:14.168911  4990 net.cpp:316] ReLU93 needs backward computation.
I0612 11:05:14.168915  4990 net.cpp:316] Eltwise46 needs backward computation.
I0612 11:05:14.168920  4990 net.cpp:316] Scale93 needs backward computation.
I0612 11:05:14.168922  4990 net.cpp:316] BatchNorm93 needs backward computation.
I0612 11:05:14.168929  4990 net.cpp:316] Convolution93 needs backward computation.
I0612 11:05:14.168933  4990 net.cpp:316] ReLU92 needs backward computation.
I0612 11:05:14.168937  4990 net.cpp:316] Scale92 needs backward computation.
I0612 11:05:14.168941  4990 net.cpp:316] BatchNorm92 needs backward computation.
I0612 11:05:14.168944  4990 net.cpp:316] Convolution92 needs backward computation.
I0612 11:05:14.168948  4990 net.cpp:316] Eltwise45_ReLU91_0_split needs backward computation.
I0612 11:05:14.168952  4990 net.cpp:316] ReLU91 needs backward computation.
I0612 11:05:14.168956  4990 net.cpp:316] Eltwise45 needs backward computation.
I0612 11:05:14.168961  4990 net.cpp:316] Scale91 needs backward computation.
I0612 11:05:14.168964  4990 net.cpp:316] BatchNorm91 needs backward computation.
I0612 11:05:14.168967  4990 net.cpp:316] Convolution91 needs backward computation.
I0612 11:05:14.168972  4990 net.cpp:316] ReLU90 needs backward computation.
I0612 11:05:14.168975  4990 net.cpp:316] Scale90 needs backward computation.
I0612 11:05:14.168978  4990 net.cpp:316] BatchNorm90 needs backward computation.
I0612 11:05:14.168982  4990 net.cpp:316] Convolution90 needs backward computation.
I0612 11:05:14.168987  4990 net.cpp:316] Eltwise44_ReLU89_0_split needs backward computation.
I0612 11:05:14.168990  4990 net.cpp:316] ReLU89 needs backward computation.
I0612 11:05:14.168993  4990 net.cpp:316] Eltwise44 needs backward computation.
I0612 11:05:14.168998  4990 net.cpp:316] Scale89 needs backward computation.
I0612 11:05:14.169003  4990 net.cpp:316] BatchNorm89 needs backward computation.
I0612 11:05:14.169005  4990 net.cpp:316] Convolution89 needs backward computation.
I0612 11:05:14.169009  4990 net.cpp:316] ReLU88 needs backward computation.
I0612 11:05:14.169013  4990 net.cpp:316] Scale88 needs backward computation.
I0612 11:05:14.169016  4990 net.cpp:316] BatchNorm88 needs backward computation.
I0612 11:05:14.169020  4990 net.cpp:316] Convolution88 needs backward computation.
I0612 11:05:14.169024  4990 net.cpp:316] Eltwise43_ReLU87_0_split needs backward computation.
I0612 11:05:14.169028  4990 net.cpp:316] ReLU87 needs backward computation.
I0612 11:05:14.169033  4990 net.cpp:316] Eltwise43 needs backward computation.
I0612 11:05:14.169036  4990 net.cpp:316] Scale87 needs backward computation.
I0612 11:05:14.169040  4990 net.cpp:316] BatchNorm87 needs backward computation.
I0612 11:05:14.169044  4990 net.cpp:316] Convolution87 needs backward computation.
I0612 11:05:14.169047  4990 net.cpp:316] ReLU86 needs backward computation.
I0612 11:05:14.169051  4990 net.cpp:316] Scale86 needs backward computation.
I0612 11:05:14.169054  4990 net.cpp:316] BatchNorm86 needs backward computation.
I0612 11:05:14.169059  4990 net.cpp:316] Convolution86 needs backward computation.
I0612 11:05:14.169062  4990 net.cpp:316] Eltwise42_ReLU85_0_split needs backward computation.
I0612 11:05:14.169066  4990 net.cpp:316] ReLU85 needs backward computation.
I0612 11:05:14.169070  4990 net.cpp:316] Eltwise42 needs backward computation.
I0612 11:05:14.169075  4990 net.cpp:316] Scale85 needs backward computation.
I0612 11:05:14.169077  4990 net.cpp:316] BatchNorm85 needs backward computation.
I0612 11:05:14.169081  4990 net.cpp:316] Convolution85 needs backward computation.
I0612 11:05:14.169085  4990 net.cpp:316] ReLU84 needs backward computation.
I0612 11:05:14.169088  4990 net.cpp:316] Scale84 needs backward computation.
I0612 11:05:14.169092  4990 net.cpp:316] BatchNorm84 needs backward computation.
I0612 11:05:14.169095  4990 net.cpp:316] Convolution84 needs backward computation.
I0612 11:05:14.169100  4990 net.cpp:316] Eltwise41_ReLU83_0_split needs backward computation.
I0612 11:05:14.169103  4990 net.cpp:316] ReLU83 needs backward computation.
I0612 11:05:14.169107  4990 net.cpp:316] Eltwise41 needs backward computation.
I0612 11:05:14.169111  4990 net.cpp:316] Scale83 needs backward computation.
I0612 11:05:14.169116  4990 net.cpp:316] BatchNorm83 needs backward computation.
I0612 11:05:14.169121  4990 net.cpp:316] Convolution83 needs backward computation.
I0612 11:05:14.169126  4990 net.cpp:316] ReLU82 needs backward computation.
I0612 11:05:14.169128  4990 net.cpp:316] Scale82 needs backward computation.
I0612 11:05:14.169132  4990 net.cpp:316] BatchNorm82 needs backward computation.
I0612 11:05:14.169137  4990 net.cpp:316] Convolution82 needs backward computation.
I0612 11:05:14.169139  4990 net.cpp:316] Eltwise40_ReLU81_0_split needs backward computation.
I0612 11:05:14.169143  4990 net.cpp:316] ReLU81 needs backward computation.
I0612 11:05:14.169147  4990 net.cpp:316] Eltwise40 needs backward computation.
I0612 11:05:14.169152  4990 net.cpp:316] Scale81 needs backward computation.
I0612 11:05:14.169155  4990 net.cpp:316] BatchNorm81 needs backward computation.
I0612 11:05:14.169159  4990 net.cpp:316] Convolution81 needs backward computation.
I0612 11:05:14.169163  4990 net.cpp:316] ReLU80 needs backward computation.
I0612 11:05:14.169167  4990 net.cpp:316] Scale80 needs backward computation.
I0612 11:05:14.169170  4990 net.cpp:316] BatchNorm80 needs backward computation.
I0612 11:05:14.169174  4990 net.cpp:316] Convolution80 needs backward computation.
I0612 11:05:14.169178  4990 net.cpp:316] Eltwise39_ReLU79_0_split needs backward computation.
I0612 11:05:14.169183  4990 net.cpp:316] ReLU79 needs backward computation.
I0612 11:05:14.169186  4990 net.cpp:316] Eltwise39 needs backward computation.
I0612 11:05:14.169190  4990 net.cpp:316] Scale79 needs backward computation.
I0612 11:05:14.169194  4990 net.cpp:316] BatchNorm79 needs backward computation.
I0612 11:05:14.169198  4990 net.cpp:316] Convolution79 needs backward computation.
I0612 11:05:14.169203  4990 net.cpp:316] ReLU78 needs backward computation.
I0612 11:05:14.169206  4990 net.cpp:316] Scale78 needs backward computation.
I0612 11:05:14.169209  4990 net.cpp:316] BatchNorm78 needs backward computation.
I0612 11:05:14.169214  4990 net.cpp:316] Convolution78 needs backward computation.
I0612 11:05:14.169217  4990 net.cpp:316] Eltwise38_ReLU77_0_split needs backward computation.
I0612 11:05:14.169221  4990 net.cpp:316] ReLU77 needs backward computation.
I0612 11:05:14.169225  4990 net.cpp:316] Eltwise38 needs backward computation.
I0612 11:05:14.169229  4990 net.cpp:316] Scale77 needs backward computation.
I0612 11:05:14.169234  4990 net.cpp:316] BatchNorm77 needs backward computation.
I0612 11:05:14.169236  4990 net.cpp:316] Convolution77 needs backward computation.
I0612 11:05:14.169240  4990 net.cpp:316] ReLU76 needs backward computation.
I0612 11:05:14.169245  4990 net.cpp:316] Scale76 needs backward computation.
I0612 11:05:14.169247  4990 net.cpp:316] BatchNorm76 needs backward computation.
I0612 11:05:14.169251  4990 net.cpp:316] Convolution76 needs backward computation.
I0612 11:05:14.169255  4990 net.cpp:316] Eltwise37_ReLU75_0_split needs backward computation.
I0612 11:05:14.169260  4990 net.cpp:316] ReLU75 needs backward computation.
I0612 11:05:14.169263  4990 net.cpp:316] Eltwise37 needs backward computation.
I0612 11:05:14.169267  4990 net.cpp:316] Scale75 needs backward computation.
I0612 11:05:14.169271  4990 net.cpp:316] BatchNorm75 needs backward computation.
I0612 11:05:14.169275  4990 net.cpp:316] Convolution75 needs backward computation.
I0612 11:05:14.169278  4990 net.cpp:316] ReLU74 needs backward computation.
I0612 11:05:14.169282  4990 net.cpp:316] Scale74 needs backward computation.
I0612 11:05:14.169286  4990 net.cpp:316] BatchNorm74 needs backward computation.
I0612 11:05:14.169289  4990 net.cpp:316] Convolution74 needs backward computation.
I0612 11:05:14.169293  4990 net.cpp:316] Concat2 needs backward computation.
I0612 11:05:14.169298  4990 net.cpp:318] Input2 does not need backward computation.
I0612 11:05:14.169302  4990 net.cpp:316] Pooling2 needs backward computation.
I0612 11:05:14.169306  4990 net.cpp:316] Eltwise36_ReLU73_0_split needs backward computation.
I0612 11:05:14.169311  4990 net.cpp:316] ReLU73 needs backward computation.
I0612 11:05:14.169314  4990 net.cpp:316] Eltwise36 needs backward computation.
I0612 11:05:14.169322  4990 net.cpp:316] Scale73 needs backward computation.
I0612 11:05:14.169325  4990 net.cpp:316] BatchNorm73 needs backward computation.
I0612 11:05:14.169328  4990 net.cpp:316] Convolution73 needs backward computation.
I0612 11:05:14.169332  4990 net.cpp:316] ReLU72 needs backward computation.
I0612 11:05:14.169337  4990 net.cpp:316] Scale72 needs backward computation.
I0612 11:05:14.169339  4990 net.cpp:316] BatchNorm72 needs backward computation.
I0612 11:05:14.169343  4990 net.cpp:316] Convolution72 needs backward computation.
I0612 11:05:14.169348  4990 net.cpp:316] Eltwise35_ReLU71_0_split needs backward computation.
I0612 11:05:14.169351  4990 net.cpp:316] ReLU71 needs backward computation.
I0612 11:05:14.169355  4990 net.cpp:316] Eltwise35 needs backward computation.
I0612 11:05:14.169359  4990 net.cpp:316] Scale71 needs backward computation.
I0612 11:05:14.169363  4990 net.cpp:316] BatchNorm71 needs backward computation.
I0612 11:05:14.169368  4990 net.cpp:316] Convolution71 needs backward computation.
I0612 11:05:14.169371  4990 net.cpp:316] ReLU70 needs backward computation.
I0612 11:05:14.169374  4990 net.cpp:316] Scale70 needs backward computation.
I0612 11:05:14.169378  4990 net.cpp:316] BatchNorm70 needs backward computation.
I0612 11:05:14.169383  4990 net.cpp:316] Convolution70 needs backward computation.
I0612 11:05:14.169386  4990 net.cpp:316] Eltwise34_ReLU69_0_split needs backward computation.
I0612 11:05:14.169390  4990 net.cpp:316] ReLU69 needs backward computation.
I0612 11:05:14.169394  4990 net.cpp:316] Eltwise34 needs backward computation.
I0612 11:05:14.169399  4990 net.cpp:316] Scale69 needs backward computation.
I0612 11:05:14.169402  4990 net.cpp:316] BatchNorm69 needs backward computation.
I0612 11:05:14.169405  4990 net.cpp:316] Convolution69 needs backward computation.
I0612 11:05:14.169409  4990 net.cpp:316] ReLU68 needs backward computation.
I0612 11:05:14.169414  4990 net.cpp:316] Scale68 needs backward computation.
I0612 11:05:14.169416  4990 net.cpp:316] BatchNorm68 needs backward computation.
I0612 11:05:14.169420  4990 net.cpp:316] Convolution68 needs backward computation.
I0612 11:05:14.169425  4990 net.cpp:316] Eltwise33_ReLU67_0_split needs backward computation.
I0612 11:05:14.169428  4990 net.cpp:316] ReLU67 needs backward computation.
I0612 11:05:14.169432  4990 net.cpp:316] Eltwise33 needs backward computation.
I0612 11:05:14.169436  4990 net.cpp:316] Scale67 needs backward computation.
I0612 11:05:14.169440  4990 net.cpp:316] BatchNorm67 needs backward computation.
I0612 11:05:14.169443  4990 net.cpp:316] Convolution67 needs backward computation.
I0612 11:05:14.169447  4990 net.cpp:316] ReLU66 needs backward computation.
I0612 11:05:14.169451  4990 net.cpp:316] Scale66 needs backward computation.
I0612 11:05:14.169455  4990 net.cpp:316] BatchNorm66 needs backward computation.
I0612 11:05:14.169458  4990 net.cpp:316] Convolution66 needs backward computation.
I0612 11:05:14.169462  4990 net.cpp:316] Eltwise32_ReLU65_0_split needs backward computation.
I0612 11:05:14.169466  4990 net.cpp:316] ReLU65 needs backward computation.
I0612 11:05:14.169471  4990 net.cpp:316] Eltwise32 needs backward computation.
I0612 11:05:14.169474  4990 net.cpp:316] Scale65 needs backward computation.
I0612 11:05:14.169477  4990 net.cpp:316] BatchNorm65 needs backward computation.
I0612 11:05:14.169481  4990 net.cpp:316] Convolution65 needs backward computation.
I0612 11:05:14.169486  4990 net.cpp:316] ReLU64 needs backward computation.
I0612 11:05:14.169489  4990 net.cpp:316] Scale64 needs backward computation.
I0612 11:05:14.169492  4990 net.cpp:316] BatchNorm64 needs backward computation.
I0612 11:05:14.169497  4990 net.cpp:316] Convolution64 needs backward computation.
I0612 11:05:14.169500  4990 net.cpp:316] Eltwise31_ReLU63_0_split needs backward computation.
I0612 11:05:14.169504  4990 net.cpp:316] ReLU63 needs backward computation.
I0612 11:05:14.169508  4990 net.cpp:316] Eltwise31 needs backward computation.
I0612 11:05:14.169512  4990 net.cpp:316] Scale63 needs backward computation.
I0612 11:05:14.169518  4990 net.cpp:316] BatchNorm63 needs backward computation.
I0612 11:05:14.169523  4990 net.cpp:316] Convolution63 needs backward computation.
I0612 11:05:14.169529  4990 net.cpp:316] ReLU62 needs backward computation.
I0612 11:05:14.169533  4990 net.cpp:316] Scale62 needs backward computation.
I0612 11:05:14.169538  4990 net.cpp:316] BatchNorm62 needs backward computation.
I0612 11:05:14.169540  4990 net.cpp:316] Convolution62 needs backward computation.
I0612 11:05:14.169545  4990 net.cpp:316] Eltwise30_ReLU61_0_split needs backward computation.
I0612 11:05:14.169548  4990 net.cpp:316] ReLU61 needs backward computation.
I0612 11:05:14.169553  4990 net.cpp:316] Eltwise30 needs backward computation.
I0612 11:05:14.169558  4990 net.cpp:316] Scale61 needs backward computation.
I0612 11:05:14.169560  4990 net.cpp:316] BatchNorm61 needs backward computation.
I0612 11:05:14.169564  4990 net.cpp:316] Convolution61 needs backward computation.
I0612 11:05:14.169569  4990 net.cpp:316] ReLU60 needs backward computation.
I0612 11:05:14.169571  4990 net.cpp:316] Scale60 needs backward computation.
I0612 11:05:14.169575  4990 net.cpp:316] BatchNorm60 needs backward computation.
I0612 11:05:14.169579  4990 net.cpp:316] Convolution60 needs backward computation.
I0612 11:05:14.169584  4990 net.cpp:316] Eltwise29_ReLU59_0_split needs backward computation.
I0612 11:05:14.169587  4990 net.cpp:316] ReLU59 needs backward computation.
I0612 11:05:14.169591  4990 net.cpp:316] Eltwise29 needs backward computation.
I0612 11:05:14.169595  4990 net.cpp:316] Scale59 needs backward computation.
I0612 11:05:14.169600  4990 net.cpp:316] BatchNorm59 needs backward computation.
I0612 11:05:14.169603  4990 net.cpp:316] Convolution59 needs backward computation.
I0612 11:05:14.169607  4990 net.cpp:316] ReLU58 needs backward computation.
I0612 11:05:14.169611  4990 net.cpp:316] Scale58 needs backward computation.
I0612 11:05:14.169615  4990 net.cpp:316] BatchNorm58 needs backward computation.
I0612 11:05:14.169618  4990 net.cpp:316] Convolution58 needs backward computation.
I0612 11:05:14.169622  4990 net.cpp:316] Eltwise28_ReLU57_0_split needs backward computation.
I0612 11:05:14.169626  4990 net.cpp:316] ReLU57 needs backward computation.
I0612 11:05:14.169631  4990 net.cpp:316] Eltwise28 needs backward computation.
I0612 11:05:14.169634  4990 net.cpp:316] Scale57 needs backward computation.
I0612 11:05:14.169638  4990 net.cpp:316] BatchNorm57 needs backward computation.
I0612 11:05:14.169642  4990 net.cpp:316] Convolution57 needs backward computation.
I0612 11:05:14.169646  4990 net.cpp:316] ReLU56 needs backward computation.
I0612 11:05:14.169651  4990 net.cpp:316] Scale56 needs backward computation.
I0612 11:05:14.169653  4990 net.cpp:316] BatchNorm56 needs backward computation.
I0612 11:05:14.169657  4990 net.cpp:316] Convolution56 needs backward computation.
I0612 11:05:14.169661  4990 net.cpp:316] Eltwise27_ReLU55_0_split needs backward computation.
I0612 11:05:14.169666  4990 net.cpp:316] ReLU55 needs backward computation.
I0612 11:05:14.169669  4990 net.cpp:316] Eltwise27 needs backward computation.
I0612 11:05:14.169673  4990 net.cpp:316] Scale55 needs backward computation.
I0612 11:05:14.169677  4990 net.cpp:316] BatchNorm55 needs backward computation.
I0612 11:05:14.169682  4990 net.cpp:316] Convolution55 needs backward computation.
I0612 11:05:14.169684  4990 net.cpp:316] ReLU54 needs backward computation.
I0612 11:05:14.169688  4990 net.cpp:316] Scale54 needs backward computation.
I0612 11:05:14.169692  4990 net.cpp:316] BatchNorm54 needs backward computation.
I0612 11:05:14.169697  4990 net.cpp:316] Convolution54 needs backward computation.
I0612 11:05:14.169700  4990 net.cpp:316] Eltwise26_ReLU53_0_split needs backward computation.
I0612 11:05:14.169704  4990 net.cpp:316] ReLU53 needs backward computation.
I0612 11:05:14.169708  4990 net.cpp:316] Eltwise26 needs backward computation.
I0612 11:05:14.169713  4990 net.cpp:316] Scale53 needs backward computation.
I0612 11:05:14.169716  4990 net.cpp:316] BatchNorm53 needs backward computation.
I0612 11:05:14.169723  4990 net.cpp:316] Convolution53 needs backward computation.
I0612 11:05:14.169726  4990 net.cpp:316] ReLU52 needs backward computation.
I0612 11:05:14.169730  4990 net.cpp:316] Scale52 needs backward computation.
I0612 11:05:14.169734  4990 net.cpp:316] BatchNorm52 needs backward computation.
I0612 11:05:14.169737  4990 net.cpp:316] Convolution52 needs backward computation.
I0612 11:05:14.169741  4990 net.cpp:316] Eltwise25_ReLU51_0_split needs backward computation.
I0612 11:05:14.169745  4990 net.cpp:316] ReLU51 needs backward computation.
I0612 11:05:14.169749  4990 net.cpp:316] Eltwise25 needs backward computation.
I0612 11:05:14.169754  4990 net.cpp:316] Scale51 needs backward computation.
I0612 11:05:14.169757  4990 net.cpp:316] BatchNorm51 needs backward computation.
I0612 11:05:14.169760  4990 net.cpp:316] Convolution51 needs backward computation.
I0612 11:05:14.169764  4990 net.cpp:316] ReLU50 needs backward computation.
I0612 11:05:14.169769  4990 net.cpp:316] Scale50 needs backward computation.
I0612 11:05:14.169772  4990 net.cpp:316] BatchNorm50 needs backward computation.
I0612 11:05:14.169776  4990 net.cpp:316] Convolution50 needs backward computation.
I0612 11:05:14.169780  4990 net.cpp:316] Eltwise24_ReLU49_0_split needs backward computation.
I0612 11:05:14.169785  4990 net.cpp:316] ReLU49 needs backward computation.
I0612 11:05:14.169787  4990 net.cpp:316] Eltwise24 needs backward computation.
I0612 11:05:14.169792  4990 net.cpp:316] Scale49 needs backward computation.
I0612 11:05:14.169798  4990 net.cpp:316] BatchNorm49 needs backward computation.
I0612 11:05:14.169802  4990 net.cpp:316] Convolution49 needs backward computation.
I0612 11:05:14.169806  4990 net.cpp:316] ReLU48 needs backward computation.
I0612 11:05:14.169811  4990 net.cpp:316] Scale48 needs backward computation.
I0612 11:05:14.169814  4990 net.cpp:316] BatchNorm48 needs backward computation.
I0612 11:05:14.169817  4990 net.cpp:316] Convolution48 needs backward computation.
I0612 11:05:14.169822  4990 net.cpp:316] Eltwise23_ReLU47_0_split needs backward computation.
I0612 11:05:14.169826  4990 net.cpp:316] ReLU47 needs backward computation.
I0612 11:05:14.169831  4990 net.cpp:316] Eltwise23 needs backward computation.
I0612 11:05:14.169834  4990 net.cpp:316] Scale47 needs backward computation.
I0612 11:05:14.169838  4990 net.cpp:316] BatchNorm47 needs backward computation.
I0612 11:05:14.169842  4990 net.cpp:316] Convolution47 needs backward computation.
I0612 11:05:14.169847  4990 net.cpp:316] ReLU46 needs backward computation.
I0612 11:05:14.169850  4990 net.cpp:316] Scale46 needs backward computation.
I0612 11:05:14.169854  4990 net.cpp:316] BatchNorm46 needs backward computation.
I0612 11:05:14.169857  4990 net.cpp:316] Convolution46 needs backward computation.
I0612 11:05:14.169862  4990 net.cpp:316] Eltwise22_ReLU45_0_split needs backward computation.
I0612 11:05:14.169865  4990 net.cpp:316] ReLU45 needs backward computation.
I0612 11:05:14.169869  4990 net.cpp:316] Eltwise22 needs backward computation.
I0612 11:05:14.169874  4990 net.cpp:316] Scale45 needs backward computation.
I0612 11:05:14.169878  4990 net.cpp:316] BatchNorm45 needs backward computation.
I0612 11:05:14.169881  4990 net.cpp:316] Convolution45 needs backward computation.
I0612 11:05:14.169885  4990 net.cpp:316] ReLU44 needs backward computation.
I0612 11:05:14.169889  4990 net.cpp:316] Scale44 needs backward computation.
I0612 11:05:14.169893  4990 net.cpp:316] BatchNorm44 needs backward computation.
I0612 11:05:14.169896  4990 net.cpp:316] Convolution44 needs backward computation.
I0612 11:05:14.169900  4990 net.cpp:316] Eltwise21_ReLU43_0_split needs backward computation.
I0612 11:05:14.169904  4990 net.cpp:316] ReLU43 needs backward computation.
I0612 11:05:14.169909  4990 net.cpp:316] Eltwise21 needs backward computation.
I0612 11:05:14.169912  4990 net.cpp:316] Scale43 needs backward computation.
I0612 11:05:14.169916  4990 net.cpp:316] BatchNorm43 needs backward computation.
I0612 11:05:14.169922  4990 net.cpp:316] Convolution43 needs backward computation.
I0612 11:05:14.169926  4990 net.cpp:316] ReLU42 needs backward computation.
I0612 11:05:14.169930  4990 net.cpp:316] Scale42 needs backward computation.
I0612 11:05:14.169934  4990 net.cpp:316] BatchNorm42 needs backward computation.
I0612 11:05:14.169939  4990 net.cpp:316] Convolution42 needs backward computation.
I0612 11:05:14.169942  4990 net.cpp:316] Eltwise20_ReLU41_0_split needs backward computation.
I0612 11:05:14.169946  4990 net.cpp:316] ReLU41 needs backward computation.
I0612 11:05:14.169950  4990 net.cpp:316] Eltwise20 needs backward computation.
I0612 11:05:14.169955  4990 net.cpp:316] Scale41 needs backward computation.
I0612 11:05:14.169958  4990 net.cpp:316] BatchNorm41 needs backward computation.
I0612 11:05:14.169962  4990 net.cpp:316] Convolution41 needs backward computation.
I0612 11:05:14.169966  4990 net.cpp:316] ReLU40 needs backward computation.
I0612 11:05:14.169970  4990 net.cpp:316] Scale40 needs backward computation.
I0612 11:05:14.169973  4990 net.cpp:316] BatchNorm40 needs backward computation.
I0612 11:05:14.169977  4990 net.cpp:316] Convolution40 needs backward computation.
I0612 11:05:14.169981  4990 net.cpp:316] Eltwise19_ReLU39_0_split needs backward computation.
I0612 11:05:14.169986  4990 net.cpp:316] ReLU39 needs backward computation.
I0612 11:05:14.169989  4990 net.cpp:316] Eltwise19 needs backward computation.
I0612 11:05:14.169994  4990 net.cpp:316] Scale39 needs backward computation.
I0612 11:05:14.169997  4990 net.cpp:316] BatchNorm39 needs backward computation.
I0612 11:05:14.170001  4990 net.cpp:316] Convolution39 needs backward computation.
I0612 11:05:14.170006  4990 net.cpp:316] ReLU38 needs backward computation.
I0612 11:05:14.170009  4990 net.cpp:316] Scale38 needs backward computation.
I0612 11:05:14.170013  4990 net.cpp:316] BatchNorm38 needs backward computation.
I0612 11:05:14.170017  4990 net.cpp:316] Convolution38 needs backward computation.
I0612 11:05:14.170022  4990 net.cpp:316] Concat1 needs backward computation.
I0612 11:05:14.170027  4990 net.cpp:318] Input1 does not need backward computation.
I0612 11:05:14.170030  4990 net.cpp:316] Pooling1 needs backward computation.
I0612 11:05:14.170034  4990 net.cpp:316] Eltwise18_ReLU37_0_split needs backward computation.
I0612 11:05:14.170039  4990 net.cpp:316] ReLU37 needs backward computation.
I0612 11:05:14.170043  4990 net.cpp:316] Eltwise18 needs backward computation.
I0612 11:05:14.170047  4990 net.cpp:316] Scale37 needs backward computation.
I0612 11:05:14.170052  4990 net.cpp:316] BatchNorm37 needs backward computation.
I0612 11:05:14.170055  4990 net.cpp:316] Convolution37 needs backward computation.
I0612 11:05:14.170059  4990 net.cpp:316] ReLU36 needs backward computation.
I0612 11:05:14.170063  4990 net.cpp:316] Scale36 needs backward computation.
I0612 11:05:14.170066  4990 net.cpp:316] BatchNorm36 needs backward computation.
I0612 11:05:14.170070  4990 net.cpp:316] Convolution36 needs backward computation.
I0612 11:05:14.170074  4990 net.cpp:316] Eltwise17_ReLU35_0_split needs backward computation.
I0612 11:05:14.170079  4990 net.cpp:316] ReLU35 needs backward computation.
I0612 11:05:14.170083  4990 net.cpp:316] Eltwise17 needs backward computation.
I0612 11:05:14.170088  4990 net.cpp:316] Scale35 needs backward computation.
I0612 11:05:14.170090  4990 net.cpp:316] BatchNorm35 needs backward computation.
I0612 11:05:14.170094  4990 net.cpp:316] Convolution35 needs backward computation.
I0612 11:05:14.170099  4990 net.cpp:316] ReLU34 needs backward computation.
I0612 11:05:14.170102  4990 net.cpp:316] Scale34 needs backward computation.
I0612 11:05:14.170106  4990 net.cpp:316] BatchNorm34 needs backward computation.
I0612 11:05:14.170110  4990 net.cpp:316] Convolution34 needs backward computation.
I0612 11:05:14.170114  4990 net.cpp:316] Eltwise16_ReLU33_0_split needs backward computation.
I0612 11:05:14.170119  4990 net.cpp:316] ReLU33 needs backward computation.
I0612 11:05:14.170122  4990 net.cpp:316] Eltwise16 needs backward computation.
I0612 11:05:14.170131  4990 net.cpp:316] Scale33 needs backward computation.
I0612 11:05:14.170135  4990 net.cpp:316] BatchNorm33 needs backward computation.
I0612 11:05:14.170140  4990 net.cpp:316] Convolution33 needs backward computation.
I0612 11:05:14.170143  4990 net.cpp:316] ReLU32 needs backward computation.
I0612 11:05:14.170147  4990 net.cpp:316] Scale32 needs backward computation.
I0612 11:05:14.170151  4990 net.cpp:316] BatchNorm32 needs backward computation.
I0612 11:05:14.170155  4990 net.cpp:316] Convolution32 needs backward computation.
I0612 11:05:14.170159  4990 net.cpp:316] Eltwise15_ReLU31_0_split needs backward computation.
I0612 11:05:14.170163  4990 net.cpp:316] ReLU31 needs backward computation.
I0612 11:05:14.170167  4990 net.cpp:316] Eltwise15 needs backward computation.
I0612 11:05:14.170171  4990 net.cpp:316] Scale31 needs backward computation.
I0612 11:05:14.170176  4990 net.cpp:316] BatchNorm31 needs backward computation.
I0612 11:05:14.170178  4990 net.cpp:316] Convolution31 needs backward computation.
I0612 11:05:14.170182  4990 net.cpp:316] ReLU30 needs backward computation.
I0612 11:05:14.170186  4990 net.cpp:316] Scale30 needs backward computation.
I0612 11:05:14.170191  4990 net.cpp:316] BatchNorm30 needs backward computation.
I0612 11:05:14.170194  4990 net.cpp:316] Convolution30 needs backward computation.
I0612 11:05:14.170200  4990 net.cpp:316] Eltwise14_ReLU29_0_split needs backward computation.
I0612 11:05:14.170205  4990 net.cpp:316] ReLU29 needs backward computation.
I0612 11:05:14.170209  4990 net.cpp:316] Eltwise14 needs backward computation.
I0612 11:05:14.170214  4990 net.cpp:316] Scale29 needs backward computation.
I0612 11:05:14.170218  4990 net.cpp:316] BatchNorm29 needs backward computation.
I0612 11:05:14.170222  4990 net.cpp:316] Convolution29 needs backward computation.
I0612 11:05:14.170225  4990 net.cpp:316] ReLU28 needs backward computation.
I0612 11:05:14.170229  4990 net.cpp:316] Scale28 needs backward computation.
I0612 11:05:14.170233  4990 net.cpp:316] BatchNorm28 needs backward computation.
I0612 11:05:14.170238  4990 net.cpp:316] Convolution28 needs backward computation.
I0612 11:05:14.170241  4990 net.cpp:316] Eltwise13_ReLU27_0_split needs backward computation.
I0612 11:05:14.170245  4990 net.cpp:316] ReLU27 needs backward computation.
I0612 11:05:14.170249  4990 net.cpp:316] Eltwise13 needs backward computation.
I0612 11:05:14.170254  4990 net.cpp:316] Scale27 needs backward computation.
I0612 11:05:14.170258  4990 net.cpp:316] BatchNorm27 needs backward computation.
I0612 11:05:14.170261  4990 net.cpp:316] Convolution27 needs backward computation.
I0612 11:05:14.170265  4990 net.cpp:316] ReLU26 needs backward computation.
I0612 11:05:14.170269  4990 net.cpp:316] Scale26 needs backward computation.
I0612 11:05:14.170274  4990 net.cpp:316] BatchNorm26 needs backward computation.
I0612 11:05:14.170277  4990 net.cpp:316] Convolution26 needs backward computation.
I0612 11:05:14.170281  4990 net.cpp:316] Eltwise12_ReLU25_0_split needs backward computation.
I0612 11:05:14.170285  4990 net.cpp:316] ReLU25 needs backward computation.
I0612 11:05:14.170289  4990 net.cpp:316] Eltwise12 needs backward computation.
I0612 11:05:14.170295  4990 net.cpp:316] Scale25 needs backward computation.
I0612 11:05:14.170297  4990 net.cpp:316] BatchNorm25 needs backward computation.
I0612 11:05:14.170301  4990 net.cpp:316] Convolution25 needs backward computation.
I0612 11:05:14.170305  4990 net.cpp:316] ReLU24 needs backward computation.
I0612 11:05:14.170310  4990 net.cpp:316] Scale24 needs backward computation.
I0612 11:05:14.170313  4990 net.cpp:316] BatchNorm24 needs backward computation.
I0612 11:05:14.170317  4990 net.cpp:316] Convolution24 needs backward computation.
I0612 11:05:14.170321  4990 net.cpp:316] Eltwise11_ReLU23_0_split needs backward computation.
I0612 11:05:14.170325  4990 net.cpp:316] ReLU23 needs backward computation.
I0612 11:05:14.170330  4990 net.cpp:316] Eltwise11 needs backward computation.
I0612 11:05:14.170333  4990 net.cpp:316] Scale23 needs backward computation.
I0612 11:05:14.170341  4990 net.cpp:316] BatchNorm23 needs backward computation.
I0612 11:05:14.170344  4990 net.cpp:316] Convolution23 needs backward computation.
I0612 11:05:14.170348  4990 net.cpp:316] ReLU22 needs backward computation.
I0612 11:05:14.170359  4990 net.cpp:316] Scale22 needs backward computation.
I0612 11:05:14.170363  4990 net.cpp:316] BatchNorm22 needs backward computation.
I0612 11:05:14.170367  4990 net.cpp:316] Convolution22 needs backward computation.
I0612 11:05:14.170372  4990 net.cpp:316] Eltwise10_ReLU21_0_split needs backward computation.
I0612 11:05:14.170375  4990 net.cpp:316] ReLU21 needs backward computation.
I0612 11:05:14.170379  4990 net.cpp:316] Eltwise10 needs backward computation.
I0612 11:05:14.170384  4990 net.cpp:316] Scale21 needs backward computation.
I0612 11:05:14.170388  4990 net.cpp:316] BatchNorm21 needs backward computation.
I0612 11:05:14.170392  4990 net.cpp:316] Convolution21 needs backward computation.
I0612 11:05:14.170397  4990 net.cpp:316] ReLU20 needs backward computation.
I0612 11:05:14.170400  4990 net.cpp:316] Scale20 needs backward computation.
I0612 11:05:14.170403  4990 net.cpp:316] BatchNorm20 needs backward computation.
I0612 11:05:14.170408  4990 net.cpp:316] Convolution20 needs backward computation.
I0612 11:05:14.170413  4990 net.cpp:316] Eltwise9_ReLU19_0_split needs backward computation.
I0612 11:05:14.170416  4990 net.cpp:316] ReLU19 needs backward computation.
I0612 11:05:14.170420  4990 net.cpp:316] Eltwise9 needs backward computation.
I0612 11:05:14.170425  4990 net.cpp:316] Scale19 needs backward computation.
I0612 11:05:14.170429  4990 net.cpp:316] BatchNorm19 needs backward computation.
I0612 11:05:14.170433  4990 net.cpp:316] Convolution19 needs backward computation.
I0612 11:05:14.170438  4990 net.cpp:316] ReLU18 needs backward computation.
I0612 11:05:14.170441  4990 net.cpp:316] Scale18 needs backward computation.
I0612 11:05:14.170445  4990 net.cpp:316] BatchNorm18 needs backward computation.
I0612 11:05:14.170449  4990 net.cpp:316] Convolution18 needs backward computation.
I0612 11:05:14.170454  4990 net.cpp:316] Eltwise8_ReLU17_0_split needs backward computation.
I0612 11:05:14.170457  4990 net.cpp:316] ReLU17 needs backward computation.
I0612 11:05:14.170461  4990 net.cpp:316] Eltwise8 needs backward computation.
I0612 11:05:14.170465  4990 net.cpp:316] Scale17 needs backward computation.
I0612 11:05:14.170469  4990 net.cpp:316] BatchNorm17 needs backward computation.
I0612 11:05:14.170474  4990 net.cpp:316] Convolution17 needs backward computation.
I0612 11:05:14.170477  4990 net.cpp:316] ReLU16 needs backward computation.
I0612 11:05:14.170485  4990 net.cpp:316] Scale16 needs backward computation.
I0612 11:05:14.170487  4990 net.cpp:316] BatchNorm16 needs backward computation.
I0612 11:05:14.170491  4990 net.cpp:316] Convolution16 needs backward computation.
I0612 11:05:14.170496  4990 net.cpp:316] Eltwise7_ReLU15_0_split needs backward computation.
I0612 11:05:14.170500  4990 net.cpp:316] ReLU15 needs backward computation.
I0612 11:05:14.170505  4990 net.cpp:316] Eltwise7 needs backward computation.
I0612 11:05:14.170509  4990 net.cpp:316] Scale15 needs backward computation.
I0612 11:05:14.170512  4990 net.cpp:316] BatchNorm15 needs backward computation.
I0612 11:05:14.170516  4990 net.cpp:316] Convolution15 needs backward computation.
I0612 11:05:14.170521  4990 net.cpp:316] ReLU14 needs backward computation.
I0612 11:05:14.170524  4990 net.cpp:316] Scale14 needs backward computation.
I0612 11:05:14.170528  4990 net.cpp:316] BatchNorm14 needs backward computation.
I0612 11:05:14.170532  4990 net.cpp:316] Convolution14 needs backward computation.
I0612 11:05:14.170536  4990 net.cpp:316] Eltwise6_ReLU13_0_split needs backward computation.
I0612 11:05:14.170542  4990 net.cpp:316] ReLU13 needs backward computation.
I0612 11:05:14.170545  4990 net.cpp:316] Eltwise6 needs backward computation.
I0612 11:05:14.170549  4990 net.cpp:316] Scale13 needs backward computation.
I0612 11:05:14.170553  4990 net.cpp:316] BatchNorm13 needs backward computation.
I0612 11:05:14.170560  4990 net.cpp:316] Convolution13 needs backward computation.
I0612 11:05:14.170564  4990 net.cpp:316] ReLU12 needs backward computation.
I0612 11:05:14.170568  4990 net.cpp:316] Scale12 needs backward computation.
I0612 11:05:14.170572  4990 net.cpp:316] BatchNorm12 needs backward computation.
I0612 11:05:14.170577  4990 net.cpp:316] Convolution12 needs backward computation.
I0612 11:05:14.170580  4990 net.cpp:316] Eltwise5_ReLU11_0_split needs backward computation.
I0612 11:05:14.170584  4990 net.cpp:316] ReLU11 needs backward computation.
I0612 11:05:14.170588  4990 net.cpp:316] Eltwise5 needs backward computation.
I0612 11:05:14.170593  4990 net.cpp:316] Scale11 needs backward computation.
I0612 11:05:14.170598  4990 net.cpp:316] BatchNorm11 needs backward computation.
I0612 11:05:14.170600  4990 net.cpp:316] Convolution11 needs backward computation.
I0612 11:05:14.170605  4990 net.cpp:316] ReLU10 needs backward computation.
I0612 11:05:14.170609  4990 net.cpp:316] Scale10 needs backward computation.
I0612 11:05:14.170614  4990 net.cpp:316] BatchNorm10 needs backward computation.
I0612 11:05:14.170616  4990 net.cpp:316] Convolution10 needs backward computation.
I0612 11:05:14.170621  4990 net.cpp:316] Eltwise4_ReLU9_0_split needs backward computation.
I0612 11:05:14.170626  4990 net.cpp:316] ReLU9 needs backward computation.
I0612 11:05:14.170630  4990 net.cpp:316] Eltwise4 needs backward computation.
I0612 11:05:14.170635  4990 net.cpp:316] Scale9 needs backward computation.
I0612 11:05:14.170639  4990 net.cpp:316] BatchNorm9 needs backward computation.
I0612 11:05:14.170642  4990 net.cpp:316] Convolution9 needs backward computation.
I0612 11:05:14.170647  4990 net.cpp:316] ReLU8 needs backward computation.
I0612 11:05:14.170651  4990 net.cpp:316] Scale8 needs backward computation.
I0612 11:05:14.170655  4990 net.cpp:316] BatchNorm8 needs backward computation.
I0612 11:05:14.170658  4990 net.cpp:316] Convolution8 needs backward computation.
I0612 11:05:14.170662  4990 net.cpp:316] Eltwise3_ReLU7_0_split needs backward computation.
I0612 11:05:14.170667  4990 net.cpp:316] ReLU7 needs backward computation.
I0612 11:05:14.170671  4990 net.cpp:316] Eltwise3 needs backward computation.
I0612 11:05:14.170675  4990 net.cpp:316] Scale7 needs backward computation.
I0612 11:05:14.170680  4990 net.cpp:316] BatchNorm7 needs backward computation.
I0612 11:05:14.170683  4990 net.cpp:316] Convolution7 needs backward computation.
I0612 11:05:14.170687  4990 net.cpp:316] ReLU6 needs backward computation.
I0612 11:05:14.170691  4990 net.cpp:316] Scale6 needs backward computation.
I0612 11:05:14.170696  4990 net.cpp:316] BatchNorm6 needs backward computation.
I0612 11:05:14.170698  4990 net.cpp:316] Convolution6 needs backward computation.
I0612 11:05:14.170702  4990 net.cpp:316] Eltwise2_ReLU5_0_split needs backward computation.
I0612 11:05:14.170707  4990 net.cpp:316] ReLU5 needs backward computation.
I0612 11:05:14.170711  4990 net.cpp:316] Eltwise2 needs backward computation.
I0612 11:05:14.170716  4990 net.cpp:316] Scale5 needs backward computation.
I0612 11:05:14.170719  4990 net.cpp:316] BatchNorm5 needs backward computation.
I0612 11:05:14.170723  4990 net.cpp:316] Convolution5 needs backward computation.
I0612 11:05:14.170728  4990 net.cpp:316] ReLU4 needs backward computation.
I0612 11:05:14.170732  4990 net.cpp:316] Scale4 needs backward computation.
I0612 11:05:14.170735  4990 net.cpp:316] BatchNorm4 needs backward computation.
I0612 11:05:14.170739  4990 net.cpp:316] Convolution4 needs backward computation.
I0612 11:05:14.170743  4990 net.cpp:316] Eltwise1_ReLU3_0_split needs backward computation.
I0612 11:05:14.170748  4990 net.cpp:316] ReLU3 needs backward computation.
I0612 11:05:14.170753  4990 net.cpp:316] Eltwise1 needs backward computation.
I0612 11:05:14.170756  4990 net.cpp:316] Scale3 needs backward computation.
I0612 11:05:14.170760  4990 net.cpp:316] BatchNorm3 needs backward computation.
I0612 11:05:14.170764  4990 net.cpp:316] Convolution3 needs backward computation.
I0612 11:05:14.170771  4990 net.cpp:316] ReLU2 needs backward computation.
I0612 11:05:14.170775  4990 net.cpp:316] Scale2 needs backward computation.
I0612 11:05:14.170779  4990 net.cpp:316] BatchNorm2 needs backward computation.
I0612 11:05:14.170783  4990 net.cpp:316] Convolution2 needs backward computation.
I0612 11:05:14.170789  4990 net.cpp:316] Convolution1_ReLU1_0_split needs backward computation.
I0612 11:05:14.170794  4990 net.cpp:316] ReLU1 needs backward computation.
I0612 11:05:14.170797  4990 net.cpp:316] Scale1 needs backward computation.
I0612 11:05:14.170801  4990 net.cpp:316] BatchNorm1 needs backward computation.
I0612 11:05:14.170804  4990 net.cpp:316] Convolution1 needs backward computation.
I0612 11:05:14.170809  4990 net.cpp:318] Data1 does not need backward computation.
I0612 11:05:14.170814  4990 net.cpp:360] This network produces output SoftmaxWithLoss1
I0612 11:05:14.171167  4990 net.cpp:374] Network initialization done.
I0612 11:05:14.185655  4990 solver.cpp:186] Creating test net (#0) specified by test_net file: examples/stochastic_depth/residual_test54.prototxt
I0612 11:05:14.189138  4990 net.cpp:148] Initializing net from parameters:
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "/scratch/pas282/caffe/examples/cifar10/cifar10_test_leveldb_padding0"
    batch_size: 128
    backend: LEVELDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution21"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution22"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution22"
  top: "Convolution22"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Convolution22"
  top: "Convolution23"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution23"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution24"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution25"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution26"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution27"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution28"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution28"
  top: "Convolution28"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution29"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution30"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "Convolution30"
  top: "Convolution30"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Convolution30"
  top: "Convolution31"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise15"
  type: "Eltwise"
  bottom: "Eltwise14"
  bottom: "Convolution31"
  top: "Eltwise15"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "Eltwise15"
  top: "Eltwise15"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Eltwise15"
  top: "Convolution32"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm32"
  type: "BatchNorm"
  bottom: "Convolution32"
  top: "Convolution32"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale32"
  type: "Scale"
  bottom: "Convolution32"
  top: "Convolution32"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU32"
  type: "ReLU"
  bottom: "Convolution32"
  top: "Convolution32"
}
layer {
  name: "Convolution33"
  type: "Convolution"
  bottom: "Convolution32"
  top: "Convolution33"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm33"
  type: "BatchNorm"
  bottom: "Convolution33"
  top: "Convolution33"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale33"
  type: "Scale"
  bottom: "Convolution33"
  top: "Convolution33"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise16"
  type: "Eltwise"
  bottom: "Eltwise15"
  bottom: "Convolution33"
  top: "Eltwise16"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU33"
  type: "ReLU"
  bottom: "Eltwise16"
  top: "Eltwise16"
}
layer {
  name: "Convolution34"
  type: "Convolution"
  bottom: "Eltwise16"
  top: "Convolution34"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm34"
  type: "BatchNorm"
  bottom: "Convolution34"
  top: "Convolution34"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale34"
  type: "Scale"
  bottom: "Convolution34"
  top: "Convolution34"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU34"
  type: "ReLU"
  bottom: "Convolution34"
  top: "Convolution34"
}
layer {
  name: "Convolution35"
  type: "Convolution"
  bottom: "Convolution34"
  top: "Convolution35"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm35"
  type: "BatchNorm"
  bottom: "Convolution35"
  top: "Convolution35"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale35"
  type: "Scale"
  bottom: "Convolution35"
  top: "Convolution35"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise17"
  type: "Eltwise"
  bottom: "Eltwise16"
  bottom: "Convolution35"
  top: "Eltwise17"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU35"
  type: "ReLU"
  bottom: "Eltwise17"
  top: "Eltwise17"
}
layer {
  name: "Convolution36"
  type: "Convolution"
  bottom: "Eltwise17"
  top: "Convolution36"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {

I0612 11:05:14.191669  4990 layer_factory.hpp:77] Creating layer Data1
I0612 11:05:14.191841  4990 net.cpp:190] Creating Layer Data1
I0612 11:05:14.191854  4990 net.cpp:589] Data1 -> Data1
I0612 11:05:14.191866  4990 net.cpp:589] Data1 -> Data2
I0612 11:05:14.230985  4996 db_leveldb.cpp:18] Opened leveldb /scratch/pas282/caffe/examples/cifar10/cifar10_test_leveldb_padding0
I0612 11:05:14.231778  4990 data_layer.cpp:41] output data size: 128,3,32,32
I0612 11:05:14.237267  4990 net.cpp:240] Setting up Data1
I0612 11:05:14.237294  4990 net.cpp:247] Top shape: 128 3 32 32 (393216)
I0612 11:05:14.237304  4990 net.cpp:247] Top shape: 128 (128)
I0612 11:05:14.237310  4990 net.cpp:255] Memory required for data: 1573376
I0612 11:05:14.237318  4990 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0612 11:05:14.237332  4990 net.cpp:190] Creating Layer Data2_Data1_1_split
I0612 11:05:14.237339  4990 net.cpp:615] Data2_Data1_1_split <- Data2
I0612 11:05:14.237350  4990 net.cpp:589] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0612 11:05:14.237365  4990 net.cpp:589] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0612 11:05:14.237516  4990 net.cpp:240] Setting up Data2_Data1_1_split
I0612 11:05:14.237536  4990 net.cpp:247] Top shape: 128 (128)
I0612 11:05:14.237545  4990 net.cpp:247] Top shape: 128 (128)
I0612 11:05:14.237550  4990 net.cpp:255] Memory required for data: 1574400
I0612 11:05:14.237557  4990 layer_factory.hpp:77] Creating layer Convolution1
I0612 11:05:14.237576  4990 net.cpp:190] Creating Layer Convolution1
I0612 11:05:14.237581  4990 net.cpp:615] Convolution1 <- Data1
I0612 11:05:14.237597  4990 net.cpp:589] Convolution1 -> Convolution1
I0612 11:05:14.238090  4990 net.cpp:240] Setting up Convolution1
I0612 11:05:14.238108  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.238114  4990 net.cpp:255] Memory required for data: 9963008
I0612 11:05:14.238134  4990 layer_factory.hpp:77] Creating layer BatchNorm1
I0612 11:05:14.238149  4990 net.cpp:190] Creating Layer BatchNorm1
I0612 11:05:14.238157  4990 net.cpp:615] BatchNorm1 <- Convolution1
I0612 11:05:14.238167  4990 net.cpp:576] BatchNorm1 -> Convolution1 (in-place)
I0612 11:05:14.238564  4990 net.cpp:240] Setting up BatchNorm1
I0612 11:05:14.238580  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.238586  4990 net.cpp:255] Memory required for data: 18351616
I0612 11:05:14.238612  4990 layer_factory.hpp:77] Creating layer Scale1
I0612 11:05:14.238629  4990 net.cpp:190] Creating Layer Scale1
I0612 11:05:14.238636  4990 net.cpp:615] Scale1 <- Convolution1
I0612 11:05:14.238646  4990 net.cpp:576] Scale1 -> Convolution1 (in-place)
I0612 11:05:14.238720  4990 layer_factory.hpp:77] Creating layer Scale1
I0612 11:05:14.238930  4990 net.cpp:240] Setting up Scale1
I0612 11:05:14.238943  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.238950  4990 net.cpp:255] Memory required for data: 26740224
I0612 11:05:14.238965  4990 layer_factory.hpp:77] Creating layer ReLU1
I0612 11:05:14.238976  4990 net.cpp:190] Creating Layer ReLU1
I0612 11:05:14.238982  4990 net.cpp:615] ReLU1 <- Convolution1
I0612 11:05:14.238991  4990 net.cpp:576] ReLU1 -> Convolution1 (in-place)
I0612 11:05:14.239002  4990 net.cpp:240] Setting up ReLU1
I0612 11:05:14.239011  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.239017  4990 net.cpp:255] Memory required for data: 35128832
I0612 11:05:14.239022  4990 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0612 11:05:14.239034  4990 net.cpp:190] Creating Layer Convolution1_ReLU1_0_split
I0612 11:05:14.239040  4990 net.cpp:615] Convolution1_ReLU1_0_split <- Convolution1
I0612 11:05:14.239051  4990 net.cpp:589] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0612 11:05:14.239063  4990 net.cpp:589] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0612 11:05:14.239151  4990 net.cpp:240] Setting up Convolution1_ReLU1_0_split
I0612 11:05:14.239163  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.239171  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.239176  4990 net.cpp:255] Memory required for data: 51906048
I0612 11:05:14.239182  4990 layer_factory.hpp:77] Creating layer Convolution2
I0612 11:05:14.239197  4990 net.cpp:190] Creating Layer Convolution2
I0612 11:05:14.239203  4990 net.cpp:615] Convolution2 <- Convolution1_ReLU1_0_split_0
I0612 11:05:14.239214  4990 net.cpp:589] Convolution2 -> Convolution2
I0612 11:05:14.239926  4990 net.cpp:240] Setting up Convolution2
I0612 11:05:14.239944  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.239950  4990 net.cpp:255] Memory required for data: 60294656
I0612 11:05:14.239970  4990 layer_factory.hpp:77] Creating layer BatchNorm2
I0612 11:05:14.239992  4990 net.cpp:190] Creating Layer BatchNorm2
I0612 11:05:14.240000  4990 net.cpp:615] BatchNorm2 <- Convolution2
I0612 11:05:14.240013  4990 net.cpp:576] BatchNorm2 -> Convolution2 (in-place)
I0612 11:05:14.240386  4990 net.cpp:240] Setting up BatchNorm2
I0612 11:05:14.240401  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.240406  4990 net.cpp:255] Memory required for data: 68683264
I0612 11:05:14.240427  4990 layer_factory.hpp:77] Creating layer Scale2
I0612 11:05:14.240439  4990 net.cpp:190] Creating Layer Scale2
I0612 11:05:14.240445  4990 net.cpp:615] Scale2 <- Convolution2
I0612 11:05:14.240454  4990 net.cpp:576] Scale2 -> Convolution2 (in-place)
I0612 11:05:14.240520  4990 layer_factory.hpp:77] Creating layer Scale2
I0612 11:05:14.240725  4990 net.cpp:240] Setting up Scale2
I0612 11:05:14.240737  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.240742  4990 net.cpp:255] Memory required for data: 77071872
I0612 11:05:14.240767  4990 layer_factory.hpp:77] Creating layer ReLU2
I0612 11:05:14.240780  4990 net.cpp:190] Creating Layer ReLU2
I0612 11:05:14.240789  4990 net.cpp:615] ReLU2 <- Convolution2
I0612 11:05:14.240798  4990 net.cpp:576] ReLU2 -> Convolution2 (in-place)
I0612 11:05:14.240810  4990 net.cpp:240] Setting up ReLU2
I0612 11:05:14.240819  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.240824  4990 net.cpp:255] Memory required for data: 85460480
I0612 11:05:14.240819  4997 blocking_queue.cpp:50] Waiting for data
I0612 11:05:14.240831  4990 layer_factory.hpp:77] Creating layer Convolution3
I0612 11:05:14.240874  4990 net.cpp:190] Creating Layer Convolution3
I0612 11:05:14.240882  4990 net.cpp:615] Convolution3 <- Convolution2
I0612 11:05:14.240893  4990 net.cpp:589] Convolution3 -> Convolution3
I0612 11:05:14.241466  4990 net.cpp:240] Setting up Convolution3
I0612 11:05:14.241482  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.241488  4990 net.cpp:255] Memory required for data: 93849088
I0612 11:05:14.241503  4990 layer_factory.hpp:77] Creating layer BatchNorm3
I0612 11:05:14.241516  4990 net.cpp:190] Creating Layer BatchNorm3
I0612 11:05:14.241523  4990 net.cpp:615] BatchNorm3 <- Convolution3
I0612 11:05:14.241533  4990 net.cpp:576] BatchNorm3 -> Convolution3 (in-place)
I0612 11:05:14.241906  4990 net.cpp:240] Setting up BatchNorm3
I0612 11:05:14.241920  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.241926  4990 net.cpp:255] Memory required for data: 102237696
I0612 11:05:14.241951  4990 layer_factory.hpp:77] Creating layer Scale3
I0612 11:05:14.241962  4990 net.cpp:190] Creating Layer Scale3
I0612 11:05:14.241969  4990 net.cpp:615] Scale3 <- Convolution3
I0612 11:05:14.241986  4990 net.cpp:576] Scale3 -> Convolution3 (in-place)
I0612 11:05:14.242049  4990 layer_factory.hpp:77] Creating layer Scale3
I0612 11:05:14.242249  4990 net.cpp:240] Setting up Scale3
I0612 11:05:14.242260  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.242266  4990 net.cpp:255] Memory required for data: 110626304
I0612 11:05:14.242280  4990 layer_factory.hpp:77] Creating layer Eltwise1
I0612 11:05:14.242295  4990 net.cpp:190] Creating Layer Eltwise1
I0612 11:05:14.242301  4990 net.cpp:615] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0612 11:05:14.242311  4990 net.cpp:615] Eltwise1 <- Convolution3
I0612 11:05:14.242321  4990 net.cpp:589] Eltwise1 -> Eltwise1
I0612 11:05:14.242379  4990 net.cpp:240] Setting up Eltwise1
I0612 11:05:14.242393  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.242398  4990 net.cpp:255] Memory required for data: 119014912
I0612 11:05:14.242404  4990 layer_factory.hpp:77] Creating layer ReLU3
I0612 11:05:14.242413  4990 net.cpp:190] Creating Layer ReLU3
I0612 11:05:14.242424  4990 net.cpp:615] ReLU3 <- Eltwise1
I0612 11:05:14.242432  4990 net.cpp:576] ReLU3 -> Eltwise1 (in-place)
I0612 11:05:14.242444  4990 net.cpp:240] Setting up ReLU3
I0612 11:05:14.242452  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.242458  4990 net.cpp:255] Memory required for data: 127403520
I0612 11:05:14.242463  4990 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0612 11:05:14.242475  4990 net.cpp:190] Creating Layer Eltwise1_ReLU3_0_split
I0612 11:05:14.242481  4990 net.cpp:615] Eltwise1_ReLU3_0_split <- Eltwise1
I0612 11:05:14.242493  4990 net.cpp:589] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0612 11:05:14.242504  4990 net.cpp:589] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0612 11:05:14.242563  4990 net.cpp:240] Setting up Eltwise1_ReLU3_0_split
I0612 11:05:14.242573  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.242580  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.242586  4990 net.cpp:255] Memory required for data: 144180736
I0612 11:05:14.242593  4990 layer_factory.hpp:77] Creating layer Convolution4
I0612 11:05:14.242609  4990 net.cpp:190] Creating Layer Convolution4
I0612 11:05:14.242616  4990 net.cpp:615] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0612 11:05:14.242632  4990 net.cpp:589] Convolution4 -> Convolution4
I0612 11:05:14.243191  4990 net.cpp:240] Setting up Convolution4
I0612 11:05:14.243206  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.243212  4990 net.cpp:255] Memory required for data: 152569344
I0612 11:05:14.243227  4990 layer_factory.hpp:77] Creating layer BatchNorm4
I0612 11:05:14.243239  4990 net.cpp:190] Creating Layer BatchNorm4
I0612 11:05:14.243247  4990 net.cpp:615] BatchNorm4 <- Convolution4
I0612 11:05:14.243258  4990 net.cpp:576] BatchNorm4 -> Convolution4 (in-place)
I0612 11:05:14.243607  4990 net.cpp:240] Setting up BatchNorm4
I0612 11:05:14.243620  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.243626  4990 net.cpp:255] Memory required for data: 160957952
I0612 11:05:14.243646  4990 layer_factory.hpp:77] Creating layer Scale4
I0612 11:05:14.243657  4990 net.cpp:190] Creating Layer Scale4
I0612 11:05:14.243664  4990 net.cpp:615] Scale4 <- Convolution4
I0612 11:05:14.243672  4990 net.cpp:576] Scale4 -> Convolution4 (in-place)
I0612 11:05:14.243732  4990 layer_factory.hpp:77] Creating layer Scale4
I0612 11:05:14.243942  4990 net.cpp:240] Setting up Scale4
I0612 11:05:14.243953  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.243959  4990 net.cpp:255] Memory required for data: 169346560
I0612 11:05:14.243973  4990 layer_factory.hpp:77] Creating layer ReLU4
I0612 11:05:14.243983  4990 net.cpp:190] Creating Layer ReLU4
I0612 11:05:14.243989  4990 net.cpp:615] ReLU4 <- Convolution4
I0612 11:05:14.244001  4990 net.cpp:576] ReLU4 -> Convolution4 (in-place)
I0612 11:05:14.244012  4990 net.cpp:240] Setting up ReLU4
I0612 11:05:14.244020  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.244026  4990 net.cpp:255] Memory required for data: 177735168
I0612 11:05:14.244031  4990 layer_factory.hpp:77] Creating layer Convolution5
I0612 11:05:14.244051  4990 net.cpp:190] Creating Layer Convolution5
I0612 11:05:14.244058  4990 net.cpp:615] Convolution5 <- Convolution4
I0612 11:05:14.244068  4990 net.cpp:589] Convolution5 -> Convolution5
I0612 11:05:14.244624  4990 net.cpp:240] Setting up Convolution5
I0612 11:05:14.244639  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.244647  4990 net.cpp:255] Memory required for data: 186123776
I0612 11:05:14.244659  4990 layer_factory.hpp:77] Creating layer BatchNorm5
I0612 11:05:14.244673  4990 net.cpp:190] Creating Layer BatchNorm5
I0612 11:05:14.244680  4990 net.cpp:615] BatchNorm5 <- Convolution5
I0612 11:05:14.244689  4990 net.cpp:576] BatchNorm5 -> Convolution5 (in-place)
I0612 11:05:14.245041  4990 net.cpp:240] Setting up BatchNorm5
I0612 11:05:14.245054  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.245059  4990 net.cpp:255] Memory required for data: 194512384
I0612 11:05:14.245084  4990 layer_factory.hpp:77] Creating layer Scale5
I0612 11:05:14.245095  4990 net.cpp:190] Creating Layer Scale5
I0612 11:05:14.245101  4990 net.cpp:615] Scale5 <- Convolution5
I0612 11:05:14.245113  4990 net.cpp:576] Scale5 -> Convolution5 (in-place)
I0612 11:05:14.245175  4990 layer_factory.hpp:77] Creating layer Scale5
I0612 11:05:14.245381  4990 net.cpp:240] Setting up Scale5
I0612 11:05:14.245393  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.245398  4990 net.cpp:255] Memory required for data: 202900992
I0612 11:05:14.245412  4990 layer_factory.hpp:77] Creating layer Eltwise2
I0612 11:05:14.245425  4990 net.cpp:190] Creating Layer Eltwise2
I0612 11:05:14.245432  4990 net.cpp:615] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0612 11:05:14.245440  4990 net.cpp:615] Eltwise2 <- Convolution5
I0612 11:05:14.245450  4990 net.cpp:589] Eltwise2 -> Eltwise2
I0612 11:05:14.245493  4990 net.cpp:240] Setting up Eltwise2
I0612 11:05:14.245504  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.245509  4990 net.cpp:255] Memory required for data: 211289600
I0612 11:05:14.245515  4990 layer_factory.hpp:77] Creating layer ReLU5
I0612 11:05:14.245524  4990 net.cpp:190] Creating Layer ReLU5
I0612 11:05:14.245535  4990 net.cpp:615] ReLU5 <- Eltwise2
I0612 11:05:14.245544  4990 net.cpp:576] ReLU5 -> Eltwise2 (in-place)
I0612 11:05:14.245554  4990 net.cpp:240] Setting up ReLU5
I0612 11:05:14.245563  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.245568  4990 net.cpp:255] Memory required for data: 219678208
I0612 11:05:14.245574  4990 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0612 11:05:14.245582  4990 net.cpp:190] Creating Layer Eltwise2_ReLU5_0_split
I0612 11:05:14.245589  4990 net.cpp:615] Eltwise2_ReLU5_0_split <- Eltwise2
I0612 11:05:14.245596  4990 net.cpp:589] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0612 11:05:14.245609  4990 net.cpp:589] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0612 11:05:14.245679  4990 net.cpp:240] Setting up Eltwise2_ReLU5_0_split
I0612 11:05:14.245692  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.245700  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.245707  4990 net.cpp:255] Memory required for data: 236455424
I0612 11:05:14.245712  4990 layer_factory.hpp:77] Creating layer Convolution6
I0612 11:05:14.245729  4990 net.cpp:190] Creating Layer Convolution6
I0612 11:05:14.245736  4990 net.cpp:615] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0612 11:05:14.245748  4990 net.cpp:589] Convolution6 -> Convolution6
I0612 11:05:14.246291  4990 net.cpp:240] Setting up Convolution6
I0612 11:05:14.246305  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.246311  4990 net.cpp:255] Memory required for data: 244844032
I0612 11:05:14.246325  4990 layer_factory.hpp:77] Creating layer BatchNorm6
I0612 11:05:14.246340  4990 net.cpp:190] Creating Layer BatchNorm6
I0612 11:05:14.246346  4990 net.cpp:615] BatchNorm6 <- Convolution6
I0612 11:05:14.246371  4990 net.cpp:576] BatchNorm6 -> Convolution6 (in-place)
I0612 11:05:14.246717  4990 net.cpp:240] Setting up BatchNorm6
I0612 11:05:14.246731  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.246737  4990 net.cpp:255] Memory required for data: 253232640
I0612 11:05:14.246759  4990 layer_factory.hpp:77] Creating layer Scale6
I0612 11:05:14.246770  4990 net.cpp:190] Creating Layer Scale6
I0612 11:05:14.246776  4990 net.cpp:615] Scale6 <- Convolution6
I0612 11:05:14.246786  4990 net.cpp:576] Scale6 -> Convolution6 (in-place)
I0612 11:05:14.246850  4990 layer_factory.hpp:77] Creating layer Scale6
I0612 11:05:14.247056  4990 net.cpp:240] Setting up Scale6
I0612 11:05:14.247067  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.247073  4990 net.cpp:255] Memory required for data: 261621248
I0612 11:05:14.247086  4990 layer_factory.hpp:77] Creating layer ReLU6
I0612 11:05:14.247094  4990 net.cpp:190] Creating Layer ReLU6
I0612 11:05:14.247102  4990 net.cpp:615] ReLU6 <- Convolution6
I0612 11:05:14.247113  4990 net.cpp:576] ReLU6 -> Convolution6 (in-place)
I0612 11:05:14.247124  4990 net.cpp:240] Setting up ReLU6
I0612 11:05:14.247133  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.247138  4990 net.cpp:255] Memory required for data: 270009856
I0612 11:05:14.247143  4990 layer_factory.hpp:77] Creating layer Convolution7
I0612 11:05:14.247159  4990 net.cpp:190] Creating Layer Convolution7
I0612 11:05:14.247164  4990 net.cpp:615] Convolution7 <- Convolution6
I0612 11:05:14.247174  4990 net.cpp:589] Convolution7 -> Convolution7
I0612 11:05:14.247687  4990 net.cpp:240] Setting up Convolution7
I0612 11:05:14.247701  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.247707  4990 net.cpp:255] Memory required for data: 278398464
I0612 11:05:14.247720  4990 layer_factory.hpp:77] Creating layer BatchNorm7
I0612 11:05:14.247736  4990 net.cpp:190] Creating Layer BatchNorm7
I0612 11:05:14.247743  4990 net.cpp:615] BatchNorm7 <- Convolution7
I0612 11:05:14.247752  4990 net.cpp:576] BatchNorm7 -> Convolution7 (in-place)
I0612 11:05:14.248082  4990 net.cpp:240] Setting up BatchNorm7
I0612 11:05:14.248095  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.248105  4990 net.cpp:255] Memory required for data: 286787072
I0612 11:05:14.248121  4990 layer_factory.hpp:77] Creating layer Scale7
I0612 11:05:14.248131  4990 net.cpp:190] Creating Layer Scale7
I0612 11:05:14.248138  4990 net.cpp:615] Scale7 <- Convolution7
I0612 11:05:14.248147  4990 net.cpp:576] Scale7 -> Convolution7 (in-place)
I0612 11:05:14.248209  4990 layer_factory.hpp:77] Creating layer Scale7
I0612 11:05:14.248399  4990 net.cpp:240] Setting up Scale7
I0612 11:05:14.248411  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.248416  4990 net.cpp:255] Memory required for data: 295175680
I0612 11:05:14.248431  4990 layer_factory.hpp:77] Creating layer Eltwise3
I0612 11:05:14.248441  4990 net.cpp:190] Creating Layer Eltwise3
I0612 11:05:14.248448  4990 net.cpp:615] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0612 11:05:14.248456  4990 net.cpp:615] Eltwise3 <- Convolution7
I0612 11:05:14.248469  4990 net.cpp:589] Eltwise3 -> Eltwise3
I0612 11:05:14.248509  4990 net.cpp:240] Setting up Eltwise3
I0612 11:05:14.248519  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.248525  4990 net.cpp:255] Memory required for data: 303564288
I0612 11:05:14.248530  4990 layer_factory.hpp:77] Creating layer ReLU7
I0612 11:05:14.248543  4990 net.cpp:190] Creating Layer ReLU7
I0612 11:05:14.248549  4990 net.cpp:615] ReLU7 <- Eltwise3
I0612 11:05:14.248558  4990 net.cpp:576] ReLU7 -> Eltwise3 (in-place)
I0612 11:05:14.248567  4990 net.cpp:240] Setting up ReLU7
I0612 11:05:14.248575  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.248581  4990 net.cpp:255] Memory required for data: 311952896
I0612 11:05:14.248586  4990 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0612 11:05:14.248594  4990 net.cpp:190] Creating Layer Eltwise3_ReLU7_0_split
I0612 11:05:14.248603  4990 net.cpp:615] Eltwise3_ReLU7_0_split <- Eltwise3
I0612 11:05:14.248611  4990 net.cpp:589] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0612 11:05:14.248621  4990 net.cpp:589] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0612 11:05:14.248677  4990 net.cpp:240] Setting up Eltwise3_ReLU7_0_split
I0612 11:05:14.248687  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.248694  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.248700  4990 net.cpp:255] Memory required for data: 328730112
I0612 11:05:14.248705  4990 layer_factory.hpp:77] Creating layer Convolution8
I0612 11:05:14.248720  4990 net.cpp:190] Creating Layer Convolution8
I0612 11:05:14.248728  4990 net.cpp:615] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0612 11:05:14.248738  4990 net.cpp:589] Convolution8 -> Convolution8
I0612 11:05:14.249255  4990 net.cpp:240] Setting up Convolution8
I0612 11:05:14.249271  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.249277  4990 net.cpp:255] Memory required for data: 337118720
I0612 11:05:14.249290  4990 layer_factory.hpp:77] Creating layer BatchNorm8
I0612 11:05:14.249300  4990 net.cpp:190] Creating Layer BatchNorm8
I0612 11:05:14.249306  4990 net.cpp:615] BatchNorm8 <- Convolution8
I0612 11:05:14.249317  4990 net.cpp:576] BatchNorm8 -> Convolution8 (in-place)
I0612 11:05:14.249698  4990 net.cpp:240] Setting up BatchNorm8
I0612 11:05:14.249713  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.249719  4990 net.cpp:255] Memory required for data: 345507328
I0612 11:05:14.249735  4990 layer_factory.hpp:77] Creating layer Scale8
I0612 11:05:14.249747  4990 net.cpp:190] Creating Layer Scale8
I0612 11:05:14.249752  4990 net.cpp:615] Scale8 <- Convolution8
I0612 11:05:14.249764  4990 net.cpp:576] Scale8 -> Convolution8 (in-place)
I0612 11:05:14.249923  4990 layer_factory.hpp:77] Creating layer Scale8
I0612 11:05:14.250126  4990 net.cpp:240] Setting up Scale8
I0612 11:05:14.250139  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.250145  4990 net.cpp:255] Memory required for data: 353895936
I0612 11:05:14.250159  4990 layer_factory.hpp:77] Creating layer ReLU8
I0612 11:05:14.250187  4990 net.cpp:190] Creating Layer ReLU8
I0612 11:05:14.250200  4990 net.cpp:615] ReLU8 <- Convolution8
I0612 11:05:14.250210  4990 net.cpp:576] ReLU8 -> Convolution8 (in-place)
I0612 11:05:14.250222  4990 net.cpp:240] Setting up ReLU8
I0612 11:05:14.250231  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.250236  4990 net.cpp:255] Memory required for data: 362284544
I0612 11:05:14.250241  4990 layer_factory.hpp:77] Creating layer Convolution9
I0612 11:05:14.250257  4990 net.cpp:190] Creating Layer Convolution9
I0612 11:05:14.250264  4990 net.cpp:615] Convolution9 <- Convolution8
I0612 11:05:14.250274  4990 net.cpp:589] Convolution9 -> Convolution9
I0612 11:05:14.250807  4990 net.cpp:240] Setting up Convolution9
I0612 11:05:14.250823  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.250828  4990 net.cpp:255] Memory required for data: 370673152
I0612 11:05:14.250841  4990 layer_factory.hpp:77] Creating layer BatchNorm9
I0612 11:05:14.250859  4990 net.cpp:190] Creating Layer BatchNorm9
I0612 11:05:14.250865  4990 net.cpp:615] BatchNorm9 <- Convolution9
I0612 11:05:14.250874  4990 net.cpp:576] BatchNorm9 -> Convolution9 (in-place)
I0612 11:05:14.251219  4990 net.cpp:240] Setting up BatchNorm9
I0612 11:05:14.251231  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.251236  4990 net.cpp:255] Memory required for data: 379061760
I0612 11:05:14.251252  4990 layer_factory.hpp:77] Creating layer Scale9
I0612 11:05:14.251263  4990 net.cpp:190] Creating Layer Scale9
I0612 11:05:14.251271  4990 net.cpp:615] Scale9 <- Convolution9
I0612 11:05:14.251282  4990 net.cpp:576] Scale9 -> Convolution9 (in-place)
I0612 11:05:14.251339  4990 layer_factory.hpp:77] Creating layer Scale9
I0612 11:05:14.251534  4990 net.cpp:240] Setting up Scale9
I0612 11:05:14.251546  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.251552  4990 net.cpp:255] Memory required for data: 387450368
I0612 11:05:14.251567  4990 layer_factory.hpp:77] Creating layer Eltwise4
I0612 11:05:14.251579  4990 net.cpp:190] Creating Layer Eltwise4
I0612 11:05:14.251585  4990 net.cpp:615] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0612 11:05:14.251592  4990 net.cpp:615] Eltwise4 <- Convolution9
I0612 11:05:14.251601  4990 net.cpp:589] Eltwise4 -> Eltwise4
I0612 11:05:14.251647  4990 net.cpp:240] Setting up Eltwise4
I0612 11:05:14.251657  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.251663  4990 net.cpp:255] Memory required for data: 395838976
I0612 11:05:14.251669  4990 layer_factory.hpp:77] Creating layer ReLU9
I0612 11:05:14.251680  4990 net.cpp:190] Creating Layer ReLU9
I0612 11:05:14.251688  4990 net.cpp:615] ReLU9 <- Eltwise4
I0612 11:05:14.251695  4990 net.cpp:576] ReLU9 -> Eltwise4 (in-place)
I0612 11:05:14.251704  4990 net.cpp:240] Setting up ReLU9
I0612 11:05:14.251713  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.251718  4990 net.cpp:255] Memory required for data: 404227584
I0612 11:05:14.251724  4990 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0612 11:05:14.251732  4990 net.cpp:190] Creating Layer Eltwise4_ReLU9_0_split
I0612 11:05:14.251737  4990 net.cpp:615] Eltwise4_ReLU9_0_split <- Eltwise4
I0612 11:05:14.251745  4990 net.cpp:589] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0612 11:05:14.251762  4990 net.cpp:589] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0612 11:05:14.251821  4990 net.cpp:240] Setting up Eltwise4_ReLU9_0_split
I0612 11:05:14.251829  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.251837  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.251842  4990 net.cpp:255] Memory required for data: 421004800
I0612 11:05:14.251847  4990 layer_factory.hpp:77] Creating layer Convolution10
I0612 11:05:14.251863  4990 net.cpp:190] Creating Layer Convolution10
I0612 11:05:14.251870  4990 net.cpp:615] Convolution10 <- Eltwise4_ReLU9_0_split_0
I0612 11:05:14.251880  4990 net.cpp:589] Convolution10 -> Convolution10
I0612 11:05:14.252411  4990 net.cpp:240] Setting up Convolution10
I0612 11:05:14.252426  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.252436  4990 net.cpp:255] Memory required for data: 429393408
I0612 11:05:14.252470  4990 layer_factory.hpp:77] Creating layer BatchNorm10
I0612 11:05:14.252483  4990 net.cpp:190] Creating Layer BatchNorm10
I0612 11:05:14.252490  4990 net.cpp:615] BatchNorm10 <- Convolution10
I0612 11:05:14.252504  4990 net.cpp:576] BatchNorm10 -> Convolution10 (in-place)
I0612 11:05:14.252836  4990 net.cpp:240] Setting up BatchNorm10
I0612 11:05:14.252848  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.252854  4990 net.cpp:255] Memory required for data: 437782016
I0612 11:05:14.252869  4990 layer_factory.hpp:77] Creating layer Scale10
I0612 11:05:14.252883  4990 net.cpp:190] Creating Layer Scale10
I0612 11:05:14.252889  4990 net.cpp:615] Scale10 <- Convolution10
I0612 11:05:14.252897  4990 net.cpp:576] Scale10 -> Convolution10 (in-place)
I0612 11:05:14.252950  4990 layer_factory.hpp:77] Creating layer Scale10
I0612 11:05:14.253145  4990 net.cpp:240] Setting up Scale10
I0612 11:05:14.253157  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.253163  4990 net.cpp:255] Memory required for data: 446170624
I0612 11:05:14.253176  4990 layer_factory.hpp:77] Creating layer ReLU10
I0612 11:05:14.253185  4990 net.cpp:190] Creating Layer ReLU10
I0612 11:05:14.253191  4990 net.cpp:615] ReLU10 <- Convolution10
I0612 11:05:14.253199  4990 net.cpp:576] ReLU10 -> Convolution10 (in-place)
I0612 11:05:14.253209  4990 net.cpp:240] Setting up ReLU10
I0612 11:05:14.253216  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.253222  4990 net.cpp:255] Memory required for data: 454559232
I0612 11:05:14.253227  4990 layer_factory.hpp:77] Creating layer Convolution11
I0612 11:05:14.253247  4990 net.cpp:190] Creating Layer Convolution11
I0612 11:05:14.253252  4990 net.cpp:615] Convolution11 <- Convolution10
I0612 11:05:14.253262  4990 net.cpp:589] Convolution11 -> Convolution11
I0612 11:05:14.253801  4990 net.cpp:240] Setting up Convolution11
I0612 11:05:14.253816  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.253823  4990 net.cpp:255] Memory required for data: 462947840
I0612 11:05:14.253836  4990 layer_factory.hpp:77] Creating layer BatchNorm11
I0612 11:05:14.253849  4990 net.cpp:190] Creating Layer BatchNorm11
I0612 11:05:14.253856  4990 net.cpp:615] BatchNorm11 <- Convolution11
I0612 11:05:14.253868  4990 net.cpp:576] BatchNorm11 -> Convolution11 (in-place)
I0612 11:05:14.254186  4990 net.cpp:240] Setting up BatchNorm11
I0612 11:05:14.254199  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.254204  4990 net.cpp:255] Memory required for data: 471336448
I0612 11:05:14.254221  4990 layer_factory.hpp:77] Creating layer Scale11
I0612 11:05:14.254235  4990 net.cpp:190] Creating Layer Scale11
I0612 11:05:14.254241  4990 net.cpp:615] Scale11 <- Convolution11
I0612 11:05:14.254251  4990 net.cpp:576] Scale11 -> Convolution11 (in-place)
I0612 11:05:14.254304  4990 layer_factory.hpp:77] Creating layer Scale11
I0612 11:05:14.254520  4990 net.cpp:240] Setting up Scale11
I0612 11:05:14.254535  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.254540  4990 net.cpp:255] Memory required for data: 479725056
I0612 11:05:14.254554  4990 layer_factory.hpp:77] Creating layer Eltwise5
I0612 11:05:14.254565  4990 net.cpp:190] Creating Layer Eltwise5
I0612 11:05:14.254571  4990 net.cpp:615] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0612 11:05:14.254582  4990 net.cpp:615] Eltwise5 <- Convolution11
I0612 11:05:14.254592  4990 net.cpp:589] Eltwise5 -> Eltwise5
I0612 11:05:14.254637  4990 net.cpp:240] Setting up Eltwise5
I0612 11:05:14.254647  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.254652  4990 net.cpp:255] Memory required for data: 488113664
I0612 11:05:14.254658  4990 layer_factory.hpp:77] Creating layer ReLU11
I0612 11:05:14.254667  4990 net.cpp:190] Creating Layer ReLU11
I0612 11:05:14.254673  4990 net.cpp:615] ReLU11 <- Eltwise5
I0612 11:05:14.254680  4990 net.cpp:576] ReLU11 -> Eltwise5 (in-place)
I0612 11:05:14.254689  4990 net.cpp:240] Setting up ReLU11
I0612 11:05:14.254705  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.254711  4990 net.cpp:255] Memory required for data: 496502272
I0612 11:05:14.254716  4990 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0612 11:05:14.254729  4990 net.cpp:190] Creating Layer Eltwise5_ReLU11_0_split
I0612 11:05:14.254734  4990 net.cpp:615] Eltwise5_ReLU11_0_split <- Eltwise5
I0612 11:05:14.254742  4990 net.cpp:589] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0612 11:05:14.254752  4990 net.cpp:589] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0612 11:05:14.254814  4990 net.cpp:240] Setting up Eltwise5_ReLU11_0_split
I0612 11:05:14.254824  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.254832  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.254838  4990 net.cpp:255] Memory required for data: 513279488
I0612 11:05:14.254843  4990 layer_factory.hpp:77] Creating layer Convolution12
I0612 11:05:14.254858  4990 net.cpp:190] Creating Layer Convolution12
I0612 11:05:14.254863  4990 net.cpp:615] Convolution12 <- Eltwise5_ReLU11_0_split_0
I0612 11:05:14.254873  4990 net.cpp:589] Convolution12 -> Convolution12
I0612 11:05:14.255389  4990 net.cpp:240] Setting up Convolution12
I0612 11:05:14.255409  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.255414  4990 net.cpp:255] Memory required for data: 521668096
I0612 11:05:14.255426  4990 layer_factory.hpp:77] Creating layer BatchNorm12
I0612 11:05:14.255436  4990 net.cpp:190] Creating Layer BatchNorm12
I0612 11:05:14.255442  4990 net.cpp:615] BatchNorm12 <- Convolution12
I0612 11:05:14.255456  4990 net.cpp:576] BatchNorm12 -> Convolution12 (in-place)
I0612 11:05:14.255790  4990 net.cpp:240] Setting up BatchNorm12
I0612 11:05:14.255802  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.255808  4990 net.cpp:255] Memory required for data: 530056704
I0612 11:05:14.255825  4990 layer_factory.hpp:77] Creating layer Scale12
I0612 11:05:14.255834  4990 net.cpp:190] Creating Layer Scale12
I0612 11:05:14.255841  4990 net.cpp:615] Scale12 <- Convolution12
I0612 11:05:14.255849  4990 net.cpp:576] Scale12 -> Convolution12 (in-place)
I0612 11:05:14.255908  4990 layer_factory.hpp:77] Creating layer Scale12
I0612 11:05:14.256096  4990 net.cpp:240] Setting up Scale12
I0612 11:05:14.256108  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.256114  4990 net.cpp:255] Memory required for data: 538445312
I0612 11:05:14.256126  4990 layer_factory.hpp:77] Creating layer ReLU12
I0612 11:05:14.256139  4990 net.cpp:190] Creating Layer ReLU12
I0612 11:05:14.256145  4990 net.cpp:615] ReLU12 <- Convolution12
I0612 11:05:14.256153  4990 net.cpp:576] ReLU12 -> Convolution12 (in-place)
I0612 11:05:14.256163  4990 net.cpp:240] Setting up ReLU12
I0612 11:05:14.256171  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.256177  4990 net.cpp:255] Memory required for data: 546833920
I0612 11:05:14.256183  4990 layer_factory.hpp:77] Creating layer Convolution13
I0612 11:05:14.256202  4990 net.cpp:190] Creating Layer Convolution13
I0612 11:05:14.256208  4990 net.cpp:615] Convolution13 <- Convolution12
I0612 11:05:14.256219  4990 net.cpp:589] Convolution13 -> Convolution13
I0612 11:05:14.256747  4990 net.cpp:240] Setting up Convolution13
I0612 11:05:14.256760  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.256767  4990 net.cpp:255] Memory required for data: 555222528
I0612 11:05:14.256779  4990 layer_factory.hpp:77] Creating layer BatchNorm13
I0612 11:05:14.256789  4990 net.cpp:190] Creating Layer BatchNorm13
I0612 11:05:14.256795  4990 net.cpp:615] BatchNorm13 <- Convolution13
I0612 11:05:14.256806  4990 net.cpp:576] BatchNorm13 -> Convolution13 (in-place)
I0612 11:05:14.257161  4990 net.cpp:240] Setting up BatchNorm13
I0612 11:05:14.257175  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.257181  4990 net.cpp:255] Memory required for data: 563611136
I0612 11:05:14.257199  4990 layer_factory.hpp:77] Creating layer Scale13
I0612 11:05:14.257216  4990 net.cpp:190] Creating Layer Scale13
I0612 11:05:14.257223  4990 net.cpp:615] Scale13 <- Convolution13
I0612 11:05:14.257236  4990 net.cpp:576] Scale13 -> Convolution13 (in-place)
I0612 11:05:14.257295  4990 layer_factory.hpp:77] Creating layer Scale13
I0612 11:05:14.257483  4990 net.cpp:240] Setting up Scale13
I0612 11:05:14.257494  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.257500  4990 net.cpp:255] Memory required for data: 571999744
I0612 11:05:14.257513  4990 layer_factory.hpp:77] Creating layer Eltwise6
I0612 11:05:14.257534  4990 net.cpp:190] Creating Layer Eltwise6
I0612 11:05:14.257541  4990 net.cpp:615] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0612 11:05:14.257552  4990 net.cpp:615] Eltwise6 <- Convolution13
I0612 11:05:14.257561  4990 net.cpp:589] Eltwise6 -> Eltwise6
I0612 11:05:14.257608  4990 net.cpp:240] Setting up Eltwise6
I0612 11:05:14.257622  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.257628  4990 net.cpp:255] Memory required for data: 580388352
I0612 11:05:14.257634  4990 layer_factory.hpp:77] Creating layer ReLU13
I0612 11:05:14.257643  4990 net.cpp:190] Creating Layer ReLU13
I0612 11:05:14.257649  4990 net.cpp:615] ReLU13 <- Eltwise6
I0612 11:05:14.257658  4990 net.cpp:576] ReLU13 -> Eltwise6 (in-place)
I0612 11:05:14.257668  4990 net.cpp:240] Setting up ReLU13
I0612 11:05:14.257675  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.257681  4990 net.cpp:255] Memory required for data: 588776960
I0612 11:05:14.257686  4990 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0612 11:05:14.257694  4990 net.cpp:190] Creating Layer Eltwise6_ReLU13_0_split
I0612 11:05:14.257699  4990 net.cpp:615] Eltwise6_ReLU13_0_split <- Eltwise6
I0612 11:05:14.257712  4990 net.cpp:589] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0612 11:05:14.257724  4990 net.cpp:589] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0612 11:05:14.257783  4990 net.cpp:240] Setting up Eltwise6_ReLU13_0_split
I0612 11:05:14.257793  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.257800  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.257805  4990 net.cpp:255] Memory required for data: 605554176
I0612 11:05:14.257812  4990 layer_factory.hpp:77] Creating layer Convolution14
I0612 11:05:14.257824  4990 net.cpp:190] Creating Layer Convolution14
I0612 11:05:14.257830  4990 net.cpp:615] Convolution14 <- Eltwise6_ReLU13_0_split_0
I0612 11:05:14.257840  4990 net.cpp:589] Convolution14 -> Convolution14
I0612 11:05:14.258375  4990 net.cpp:240] Setting up Convolution14
I0612 11:05:14.258390  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.258396  4990 net.cpp:255] Memory required for data: 613942784
I0612 11:05:14.258410  4990 layer_factory.hpp:77] Creating layer BatchNorm14
I0612 11:05:14.258424  4990 net.cpp:190] Creating Layer BatchNorm14
I0612 11:05:14.258430  4990 net.cpp:615] BatchNorm14 <- Convolution14
I0612 11:05:14.258438  4990 net.cpp:576] BatchNorm14 -> Convolution14 (in-place)
I0612 11:05:14.258774  4990 net.cpp:240] Setting up BatchNorm14
I0612 11:05:14.258786  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.258791  4990 net.cpp:255] Memory required for data: 622331392
I0612 11:05:14.258806  4990 layer_factory.hpp:77] Creating layer Scale14
I0612 11:05:14.258816  4990 net.cpp:190] Creating Layer Scale14
I0612 11:05:14.258821  4990 net.cpp:615] Scale14 <- Convolution14
I0612 11:05:14.258828  4990 net.cpp:576] Scale14 -> Convolution14 (in-place)
I0612 11:05:14.258883  4990 layer_factory.hpp:77] Creating layer Scale14
I0612 11:05:14.259083  4990 net.cpp:240] Setting up Scale14
I0612 11:05:14.259093  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.259099  4990 net.cpp:255] Memory required for data: 630720000
I0612 11:05:14.259110  4990 layer_factory.hpp:77] Creating layer ReLU14
I0612 11:05:14.259122  4990 net.cpp:190] Creating Layer ReLU14
I0612 11:05:14.259130  4990 net.cpp:615] ReLU14 <- Convolution14
I0612 11:05:14.259136  4990 net.cpp:576] ReLU14 -> Convolution14 (in-place)
I0612 11:05:14.259150  4990 net.cpp:240] Setting up ReLU14
I0612 11:05:14.259158  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.259163  4990 net.cpp:255] Memory required for data: 639108608
I0612 11:05:14.259168  4990 layer_factory.hpp:77] Creating layer Convolution15
I0612 11:05:14.259184  4990 net.cpp:190] Creating Layer Convolution15
I0612 11:05:14.259189  4990 net.cpp:615] Convolution15 <- Convolution14
I0612 11:05:14.259202  4990 net.cpp:589] Convolution15 -> Convolution15
I0612 11:05:14.259706  4990 net.cpp:240] Setting up Convolution15
I0612 11:05:14.259719  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.259724  4990 net.cpp:255] Memory required for data: 647497216
I0612 11:05:14.259737  4990 layer_factory.hpp:77] Creating layer BatchNorm15
I0612 11:05:14.259747  4990 net.cpp:190] Creating Layer BatchNorm15
I0612 11:05:14.259752  4990 net.cpp:615] BatchNorm15 <- Convolution15
I0612 11:05:14.259760  4990 net.cpp:576] BatchNorm15 -> Convolution15 (in-place)
I0612 11:05:14.260088  4990 net.cpp:240] Setting up BatchNorm15
I0612 11:05:14.260102  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.260107  4990 net.cpp:255] Memory required for data: 655885824
I0612 11:05:14.260121  4990 layer_factory.hpp:77] Creating layer Scale15
I0612 11:05:14.260133  4990 net.cpp:190] Creating Layer Scale15
I0612 11:05:14.260138  4990 net.cpp:615] Scale15 <- Convolution15
I0612 11:05:14.260146  4990 net.cpp:576] Scale15 -> Convolution15 (in-place)
I0612 11:05:14.260205  4990 layer_factory.hpp:77] Creating layer Scale15
I0612 11:05:14.260387  4990 net.cpp:240] Setting up Scale15
I0612 11:05:14.260399  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.260406  4990 net.cpp:255] Memory required for data: 664274432
I0612 11:05:14.260422  4990 layer_factory.hpp:77] Creating layer Eltwise7
I0612 11:05:14.260432  4990 net.cpp:190] Creating Layer Eltwise7
I0612 11:05:14.260437  4990 net.cpp:615] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0612 11:05:14.260445  4990 net.cpp:615] Eltwise7 <- Convolution15
I0612 11:05:14.260457  4990 net.cpp:589] Eltwise7 -> Eltwise7
I0612 11:05:14.260494  4990 net.cpp:240] Setting up Eltwise7
I0612 11:05:14.260504  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.260509  4990 net.cpp:255] Memory required for data: 672663040
I0612 11:05:14.260514  4990 layer_factory.hpp:77] Creating layer ReLU15
I0612 11:05:14.260525  4990 net.cpp:190] Creating Layer ReLU15
I0612 11:05:14.260531  4990 net.cpp:615] ReLU15 <- Eltwise7
I0612 11:05:14.260538  4990 net.cpp:576] ReLU15 -> Eltwise7 (in-place)
I0612 11:05:14.260547  4990 net.cpp:240] Setting up ReLU15
I0612 11:05:14.260555  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.260560  4990 net.cpp:255] Memory required for data: 681051648
I0612 11:05:14.260565  4990 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0612 11:05:14.260574  4990 net.cpp:190] Creating Layer Eltwise7_ReLU15_0_split
I0612 11:05:14.260581  4990 net.cpp:615] Eltwise7_ReLU15_0_split <- Eltwise7
I0612 11:05:14.260587  4990 net.cpp:589] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0612 11:05:14.260597  4990 net.cpp:589] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0612 11:05:14.260653  4990 net.cpp:240] Setting up Eltwise7_ReLU15_0_split
I0612 11:05:14.260663  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.260669  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.260674  4990 net.cpp:255] Memory required for data: 697828864
I0612 11:05:14.260679  4990 layer_factory.hpp:77] Creating layer Convolution16
I0612 11:05:14.260696  4990 net.cpp:190] Creating Layer Convolution16
I0612 11:05:14.260704  4990 net.cpp:615] Convolution16 <- Eltwise7_ReLU15_0_split_0
I0612 11:05:14.260713  4990 net.cpp:589] Convolution16 -> Convolution16
I0612 11:05:14.261203  4990 net.cpp:240] Setting up Convolution16
I0612 11:05:14.261215  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.261220  4990 net.cpp:255] Memory required for data: 706217472
I0612 11:05:14.261237  4990 layer_factory.hpp:77] Creating layer BatchNorm16
I0612 11:05:14.261250  4990 net.cpp:190] Creating Layer BatchNorm16
I0612 11:05:14.261257  4990 net.cpp:615] BatchNorm16 <- Convolution16
I0612 11:05:14.261265  4990 net.cpp:576] BatchNorm16 -> Convolution16 (in-place)
I0612 11:05:14.261576  4990 net.cpp:240] Setting up BatchNorm16
I0612 11:05:14.261587  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.261593  4990 net.cpp:255] Memory required for data: 714606080
I0612 11:05:14.261607  4990 layer_factory.hpp:77] Creating layer Scale16
I0612 11:05:14.261616  4990 net.cpp:190] Creating Layer Scale16
I0612 11:05:14.261622  4990 net.cpp:615] Scale16 <- Convolution16
I0612 11:05:14.261632  4990 net.cpp:576] Scale16 -> Convolution16 (in-place)
I0612 11:05:14.261685  4990 layer_factory.hpp:77] Creating layer Scale16
I0612 11:05:14.261895  4990 net.cpp:240] Setting up Scale16
I0612 11:05:14.261910  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.261915  4990 net.cpp:255] Memory required for data: 722994688
I0612 11:05:14.261929  4990 layer_factory.hpp:77] Creating layer ReLU16
I0612 11:05:14.261941  4990 net.cpp:190] Creating Layer ReLU16
I0612 11:05:14.261947  4990 net.cpp:615] ReLU16 <- Convolution16
I0612 11:05:14.261955  4990 net.cpp:576] ReLU16 -> Convolution16 (in-place)
I0612 11:05:14.261965  4990 net.cpp:240] Setting up ReLU16
I0612 11:05:14.261972  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.261978  4990 net.cpp:255] Memory required for data: 731383296
I0612 11:05:14.261982  4990 layer_factory.hpp:77] Creating layer Convolution17
I0612 11:05:14.261998  4990 net.cpp:190] Creating Layer Convolution17
I0612 11:05:14.262004  4990 net.cpp:615] Convolution17 <- Convolution16
I0612 11:05:14.262017  4990 net.cpp:589] Convolution17 -> Convolution17
I0612 11:05:14.262531  4990 net.cpp:240] Setting up Convolution17
I0612 11:05:14.262544  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.262550  4990 net.cpp:255] Memory required for data: 739771904
I0612 11:05:14.262562  4990 layer_factory.hpp:77] Creating layer BatchNorm17
I0612 11:05:14.262575  4990 net.cpp:190] Creating Layer BatchNorm17
I0612 11:05:14.262581  4990 net.cpp:615] BatchNorm17 <- Convolution17
I0612 11:05:14.262593  4990 net.cpp:576] BatchNorm17 -> Convolution17 (in-place)
I0612 11:05:14.262905  4990 net.cpp:240] Setting up BatchNorm17
I0612 11:05:14.262917  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.262923  4990 net.cpp:255] Memory required for data: 748160512
I0612 11:05:14.262938  4990 layer_factory.hpp:77] Creating layer Scale17
I0612 11:05:14.262953  4990 net.cpp:190] Creating Layer Scale17
I0612 11:05:14.262960  4990 net.cpp:615] Scale17 <- Convolution17
I0612 11:05:14.262969  4990 net.cpp:576] Scale17 -> Convolution17 (in-place)
I0612 11:05:14.263018  4990 layer_factory.hpp:77] Creating layer Scale17
I0612 11:05:14.263201  4990 net.cpp:240] Setting up Scale17
I0612 11:05:14.263213  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.263219  4990 net.cpp:255] Memory required for data: 756549120
I0612 11:05:14.263231  4990 layer_factory.hpp:77] Creating layer Eltwise8
I0612 11:05:14.263243  4990 net.cpp:190] Creating Layer Eltwise8
I0612 11:05:14.263249  4990 net.cpp:615] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0612 11:05:14.263257  4990 net.cpp:615] Eltwise8 <- Convolution17
I0612 11:05:14.263265  4990 net.cpp:589] Eltwise8 -> Eltwise8
I0612 11:05:14.263305  4990 net.cpp:240] Setting up Eltwise8
I0612 11:05:14.263315  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.263320  4990 net.cpp:255] Memory required for data: 764937728
I0612 11:05:14.263325  4990 layer_factory.hpp:77] Creating layer ReLU17
I0612 11:05:14.263336  4990 net.cpp:190] Creating Layer ReLU17
I0612 11:05:14.263342  4990 net.cpp:615] ReLU17 <- Eltwise8
I0612 11:05:14.263350  4990 net.cpp:576] ReLU17 -> Eltwise8 (in-place)
I0612 11:05:14.263358  4990 net.cpp:240] Setting up ReLU17
I0612 11:05:14.263370  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.263375  4990 net.cpp:255] Memory required for data: 773326336
I0612 11:05:14.263381  4990 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0612 11:05:14.263387  4990 net.cpp:190] Creating Layer Eltwise8_ReLU17_0_split
I0612 11:05:14.263393  4990 net.cpp:615] Eltwise8_ReLU17_0_split <- Eltwise8
I0612 11:05:14.263406  4990 net.cpp:589] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0612 11:05:14.263416  4990 net.cpp:589] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0612 11:05:14.263470  4990 net.cpp:240] Setting up Eltwise8_ReLU17_0_split
I0612 11:05:14.263479  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.263486  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.263491  4990 net.cpp:255] Memory required for data: 790103552
I0612 11:05:14.263496  4990 layer_factory.hpp:77] Creating layer Convolution18
I0612 11:05:14.263512  4990 net.cpp:190] Creating Layer Convolution18
I0612 11:05:14.263519  4990 net.cpp:615] Convolution18 <- Eltwise8_ReLU17_0_split_0
I0612 11:05:14.263530  4990 net.cpp:589] Convolution18 -> Convolution18
I0612 11:05:14.264019  4990 net.cpp:240] Setting up Convolution18
I0612 11:05:14.264034  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.264039  4990 net.cpp:255] Memory required for data: 798492160
I0612 11:05:14.264051  4990 layer_factory.hpp:77] Creating layer BatchNorm18
I0612 11:05:14.264063  4990 net.cpp:190] Creating Layer BatchNorm18
I0612 11:05:14.264070  4990 net.cpp:615] BatchNorm18 <- Convolution18
I0612 11:05:14.264078  4990 net.cpp:576] BatchNorm18 -> Convolution18 (in-place)
I0612 11:05:14.264436  4990 net.cpp:240] Setting up BatchNorm18
I0612 11:05:14.264449  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.264456  4990 net.cpp:255] Memory required for data: 806880768
I0612 11:05:14.264470  4990 layer_factory.hpp:77] Creating layer Scale18
I0612 11:05:14.264485  4990 net.cpp:190] Creating Layer Scale18
I0612 11:05:14.264492  4990 net.cpp:615] Scale18 <- Convolution18
I0612 11:05:14.264502  4990 net.cpp:576] Scale18 -> Convolution18 (in-place)
I0612 11:05:14.264560  4990 layer_factory.hpp:77] Creating layer Scale18
I0612 11:05:14.264766  4990 net.cpp:240] Setting up Scale18
I0612 11:05:14.264778  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.264783  4990 net.cpp:255] Memory required for data: 815269376
I0612 11:05:14.264796  4990 layer_factory.hpp:77] Creating layer ReLU18
I0612 11:05:14.264806  4990 net.cpp:190] Creating Layer ReLU18
I0612 11:05:14.264811  4990 net.cpp:615] ReLU18 <- Convolution18
I0612 11:05:14.264822  4990 net.cpp:576] ReLU18 -> Convolution18 (in-place)
I0612 11:05:14.264832  4990 net.cpp:240] Setting up ReLU18
I0612 11:05:14.264838  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.264843  4990 net.cpp:255] Memory required for data: 823657984
I0612 11:05:14.264849  4990 layer_factory.hpp:77] Creating layer Convolution19
I0612 11:05:14.264875  4990 net.cpp:190] Creating Layer Convolution19
I0612 11:05:14.264883  4990 net.cpp:615] Convolution19 <- Convolution18
I0612 11:05:14.264891  4990 net.cpp:589] Convolution19 -> Convolution19
I0612 11:05:14.265455  4990 net.cpp:240] Setting up Convolution19
I0612 11:05:14.265470  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.265475  4990 net.cpp:255] Memory required for data: 832046592
I0612 11:05:14.265488  4990 layer_factory.hpp:77] Creating layer BatchNorm19
I0612 11:05:14.265501  4990 net.cpp:190] Creating Layer BatchNorm19
I0612 11:05:14.265507  4990 net.cpp:615] BatchNorm19 <- Convolution19
I0612 11:05:14.265516  4990 net.cpp:576] BatchNorm19 -> Convolution19 (in-place)
I0612 11:05:14.265827  4990 net.cpp:240] Setting up BatchNorm19
I0612 11:05:14.265838  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.265843  4990 net.cpp:255] Memory required for data: 840435200
I0612 11:05:14.265885  4990 layer_factory.hpp:77] Creating layer Scale19
I0612 11:05:14.265899  4990 net.cpp:190] Creating Layer Scale19
I0612 11:05:14.265911  4990 net.cpp:615] Scale19 <- Convolution19
I0612 11:05:14.265920  4990 net.cpp:576] Scale19 -> Convolution19 (in-place)
I0612 11:05:14.265979  4990 layer_factory.hpp:77] Creating layer Scale19
I0612 11:05:14.266176  4990 net.cpp:240] Setting up Scale19
I0612 11:05:14.266191  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.266196  4990 net.cpp:255] Memory required for data: 848823808
I0612 11:05:14.266211  4990 layer_factory.hpp:77] Creating layer Eltwise9
I0612 11:05:14.266222  4990 net.cpp:190] Creating Layer Eltwise9
I0612 11:05:14.266228  4990 net.cpp:615] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0612 11:05:14.266237  4990 net.cpp:615] Eltwise9 <- Convolution19
I0612 11:05:14.266250  4990 net.cpp:589] Eltwise9 -> Eltwise9
I0612 11:05:14.266291  4990 net.cpp:240] Setting up Eltwise9
I0612 11:05:14.266305  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.266310  4990 net.cpp:255] Memory required for data: 857212416
I0612 11:05:14.266315  4990 layer_factory.hpp:77] Creating layer ReLU19
I0612 11:05:14.266324  4990 net.cpp:190] Creating Layer ReLU19
I0612 11:05:14.266330  4990 net.cpp:615] ReLU19 <- Eltwise9
I0612 11:05:14.266337  4990 net.cpp:576] ReLU19 -> Eltwise9 (in-place)
I0612 11:05:14.266347  4990 net.cpp:240] Setting up ReLU19
I0612 11:05:14.266365  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.266371  4990 net.cpp:255] Memory required for data: 865601024
I0612 11:05:14.266376  4990 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0612 11:05:14.266383  4990 net.cpp:190] Creating Layer Eltwise9_ReLU19_0_split
I0612 11:05:14.266389  4990 net.cpp:615] Eltwise9_ReLU19_0_split <- Eltwise9
I0612 11:05:14.266401  4990 net.cpp:589] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0612 11:05:14.266410  4990 net.cpp:589] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0612 11:05:14.266468  4990 net.cpp:240] Setting up Eltwise9_ReLU19_0_split
I0612 11:05:14.266477  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.266484  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.266489  4990 net.cpp:255] Memory required for data: 882378240
I0612 11:05:14.266494  4990 layer_factory.hpp:77] Creating layer Convolution20
I0612 11:05:14.266510  4990 net.cpp:190] Creating Layer Convolution20
I0612 11:05:14.266516  4990 net.cpp:615] Convolution20 <- Eltwise9_ReLU19_0_split_0
I0612 11:05:14.266526  4990 net.cpp:589] Convolution20 -> Convolution20
I0612 11:05:14.267033  4990 net.cpp:240] Setting up Convolution20
I0612 11:05:14.267047  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.267053  4990 net.cpp:255] Memory required for data: 890766848
I0612 11:05:14.267066  4990 layer_factory.hpp:77] Creating layer BatchNorm20
I0612 11:05:14.267078  4990 net.cpp:190] Creating Layer BatchNorm20
I0612 11:05:14.267086  4990 net.cpp:615] BatchNorm20 <- Convolution20
I0612 11:05:14.267093  4990 net.cpp:576] BatchNorm20 -> Convolution20 (in-place)
I0612 11:05:14.267410  4990 net.cpp:240] Setting up BatchNorm20
I0612 11:05:14.267422  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.267428  4990 net.cpp:255] Memory required for data: 899155456
I0612 11:05:14.267446  4990 layer_factory.hpp:77] Creating layer Scale20
I0612 11:05:14.267455  4990 net.cpp:190] Creating Layer Scale20
I0612 11:05:14.267462  4990 net.cpp:615] Scale20 <- Convolution20
I0612 11:05:14.267469  4990 net.cpp:576] Scale20 -> Convolution20 (in-place)
I0612 11:05:14.267527  4990 layer_factory.hpp:77] Creating layer Scale20
I0612 11:05:14.267714  4990 net.cpp:240] Setting up Scale20
I0612 11:05:14.267725  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.267730  4990 net.cpp:255] Memory required for data: 907544064
I0612 11:05:14.267743  4990 layer_factory.hpp:77] Creating layer ReLU20
I0612 11:05:14.267755  4990 net.cpp:190] Creating Layer ReLU20
I0612 11:05:14.267761  4990 net.cpp:615] ReLU20 <- Convolution20
I0612 11:05:14.267770  4990 net.cpp:576] ReLU20 -> Convolution20 (in-place)
I0612 11:05:14.267783  4990 net.cpp:240] Setting up ReLU20
I0612 11:05:14.267791  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.267796  4990 net.cpp:255] Memory required for data: 915932672
I0612 11:05:14.267802  4990 layer_factory.hpp:77] Creating layer Convolution21
I0612 11:05:14.267817  4990 net.cpp:190] Creating Layer Convolution21
I0612 11:05:14.267822  4990 net.cpp:615] Convolution21 <- Convolution20
I0612 11:05:14.267832  4990 net.cpp:589] Convolution21 -> Convolution21
I0612 11:05:14.268350  4990 net.cpp:240] Setting up Convolution21
I0612 11:05:14.268364  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.268370  4990 net.cpp:255] Memory required for data: 924321280
I0612 11:05:14.268383  4990 layer_factory.hpp:77] Creating layer BatchNorm21
I0612 11:05:14.268395  4990 net.cpp:190] Creating Layer BatchNorm21
I0612 11:05:14.268402  4990 net.cpp:615] BatchNorm21 <- Convolution21
I0612 11:05:14.268409  4990 net.cpp:576] BatchNorm21 -> Convolution21 (in-place)
I0612 11:05:14.268724  4990 net.cpp:240] Setting up BatchNorm21
I0612 11:05:14.268736  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.268741  4990 net.cpp:255] Memory required for data: 932709888
I0612 11:05:14.268756  4990 layer_factory.hpp:77] Creating layer Scale21
I0612 11:05:14.268765  4990 net.cpp:190] Creating Layer Scale21
I0612 11:05:14.268771  4990 net.cpp:615] Scale21 <- Convolution21
I0612 11:05:14.268779  4990 net.cpp:576] Scale21 -> Convolution21 (in-place)
I0612 11:05:14.268836  4990 layer_factory.hpp:77] Creating layer Scale21
I0612 11:05:14.269031  4990 net.cpp:240] Setting up Scale21
I0612 11:05:14.269042  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.269047  4990 net.cpp:255] Memory required for data: 941098496
I0612 11:05:14.269081  4990 layer_factory.hpp:77] Creating layer Eltwise10
I0612 11:05:14.269094  4990 net.cpp:190] Creating Layer Eltwise10
I0612 11:05:14.269100  4990 net.cpp:615] Eltwise10 <- Eltwise9_ReLU19_0_split_1
I0612 11:05:14.269109  4990 net.cpp:615] Eltwise10 <- Convolution21
I0612 11:05:14.269119  4990 net.cpp:589] Eltwise10 -> Eltwise10
I0612 11:05:14.269162  4990 net.cpp:240] Setting up Eltwise10
I0612 11:05:14.269172  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.269177  4990 net.cpp:255] Memory required for data: 949487104
I0612 11:05:14.269182  4990 layer_factory.hpp:77] Creating layer ReLU21
I0612 11:05:14.269194  4990 net.cpp:190] Creating Layer ReLU21
I0612 11:05:14.269201  4990 net.cpp:615] ReLU21 <- Eltwise10
I0612 11:05:14.269208  4990 net.cpp:576] ReLU21 -> Eltwise10 (in-place)
I0612 11:05:14.269217  4990 net.cpp:240] Setting up ReLU21
I0612 11:05:14.269224  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.269229  4990 net.cpp:255] Memory required for data: 957875712
I0612 11:05:14.269235  4990 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0612 11:05:14.269243  4990 net.cpp:190] Creating Layer Eltwise10_ReLU21_0_split
I0612 11:05:14.269248  4990 net.cpp:615] Eltwise10_ReLU21_0_split <- Eltwise10
I0612 11:05:14.269263  4990 net.cpp:589] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0612 11:05:14.269273  4990 net.cpp:589] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0612 11:05:14.269331  4990 net.cpp:240] Setting up Eltwise10_ReLU21_0_split
I0612 11:05:14.269341  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.269348  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.269353  4990 net.cpp:255] Memory required for data: 974652928
I0612 11:05:14.269358  4990 layer_factory.hpp:77] Creating layer Convolution22
I0612 11:05:14.269371  4990 net.cpp:190] Creating Layer Convolution22
I0612 11:05:14.269376  4990 net.cpp:615] Convolution22 <- Eltwise10_ReLU21_0_split_0
I0612 11:05:14.269389  4990 net.cpp:589] Convolution22 -> Convolution22
I0612 11:05:14.269872  4990 net.cpp:240] Setting up Convolution22
I0612 11:05:14.269886  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.269891  4990 net.cpp:255] Memory required for data: 983041536
I0612 11:05:14.269911  4990 layer_factory.hpp:77] Creating layer BatchNorm22
I0612 11:05:14.269922  4990 net.cpp:190] Creating Layer BatchNorm22
I0612 11:05:14.269927  4990 net.cpp:615] BatchNorm22 <- Convolution22
I0612 11:05:14.269938  4990 net.cpp:576] BatchNorm22 -> Convolution22 (in-place)
I0612 11:05:14.270251  4990 net.cpp:240] Setting up BatchNorm22
I0612 11:05:14.270263  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.270269  4990 net.cpp:255] Memory required for data: 991430144
I0612 11:05:14.270287  4990 layer_factory.hpp:77] Creating layer Scale22
I0612 11:05:14.270298  4990 net.cpp:190] Creating Layer Scale22
I0612 11:05:14.270303  4990 net.cpp:615] Scale22 <- Convolution22
I0612 11:05:14.270316  4990 net.cpp:576] Scale22 -> Convolution22 (in-place)
I0612 11:05:14.270381  4990 layer_factory.hpp:77] Creating layer Scale22
I0612 11:05:14.270573  4990 net.cpp:240] Setting up Scale22
I0612 11:05:14.270586  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.270591  4990 net.cpp:255] Memory required for data: 999818752
I0612 11:05:14.270603  4990 layer_factory.hpp:77] Creating layer ReLU22
I0612 11:05:14.270617  4990 net.cpp:190] Creating Layer ReLU22
I0612 11:05:14.270622  4990 net.cpp:615] ReLU22 <- Convolution22
I0612 11:05:14.270629  4990 net.cpp:576] ReLU22 -> Convolution22 (in-place)
I0612 11:05:14.270638  4990 net.cpp:240] Setting up ReLU22
I0612 11:05:14.270647  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.270651  4990 net.cpp:255] Memory required for data: 1008207360
I0612 11:05:14.270656  4990 layer_factory.hpp:77] Creating layer Convolution23
I0612 11:05:14.270671  4990 net.cpp:190] Creating Layer Convolution23
I0612 11:05:14.270676  4990 net.cpp:615] Convolution23 <- Convolution22
I0612 11:05:14.270685  4990 net.cpp:589] Convolution23 -> Convolution23
I0612 11:05:14.271158  4990 net.cpp:240] Setting up Convolution23
I0612 11:05:14.271172  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.271176  4990 net.cpp:255] Memory required for data: 1016595968
I0612 11:05:14.271188  4990 layer_factory.hpp:77] Creating layer BatchNorm23
I0612 11:05:14.271200  4990 net.cpp:190] Creating Layer BatchNorm23
I0612 11:05:14.271208  4990 net.cpp:615] BatchNorm23 <- Convolution23
I0612 11:05:14.271215  4990 net.cpp:576] BatchNorm23 -> Convolution23 (in-place)
I0612 11:05:14.271520  4990 net.cpp:240] Setting up BatchNorm23
I0612 11:05:14.271533  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.271538  4990 net.cpp:255] Memory required for data: 1024984576
I0612 11:05:14.271553  4990 layer_factory.hpp:77] Creating layer Scale23
I0612 11:05:14.271562  4990 net.cpp:190] Creating Layer Scale23
I0612 11:05:14.271569  4990 net.cpp:615] Scale23 <- Convolution23
I0612 11:05:14.271579  4990 net.cpp:576] Scale23 -> Convolution23 (in-place)
I0612 11:05:14.271631  4990 layer_factory.hpp:77] Creating layer Scale23
I0612 11:05:14.271800  4990 net.cpp:240] Setting up Scale23
I0612 11:05:14.271812  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.271817  4990 net.cpp:255] Memory required for data: 1033373184
I0612 11:05:14.271829  4990 layer_factory.hpp:77] Creating layer Eltwise11
I0612 11:05:14.271842  4990 net.cpp:190] Creating Layer Eltwise11
I0612 11:05:14.271852  4990 net.cpp:615] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0612 11:05:14.271859  4990 net.cpp:615] Eltwise11 <- Convolution23
I0612 11:05:14.271867  4990 net.cpp:589] Eltwise11 -> Eltwise11
I0612 11:05:14.271908  4990 net.cpp:240] Setting up Eltwise11
I0612 11:05:14.271917  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.271922  4990 net.cpp:255] Memory required for data: 1041761792
I0612 11:05:14.271927  4990 layer_factory.hpp:77] Creating layer ReLU23
I0612 11:05:14.271935  4990 net.cpp:190] Creating Layer ReLU23
I0612 11:05:14.271940  4990 net.cpp:615] ReLU23 <- Eltwise11
I0612 11:05:14.271950  4990 net.cpp:576] ReLU23 -> Eltwise11 (in-place)
I0612 11:05:14.271960  4990 net.cpp:240] Setting up ReLU23
I0612 11:05:14.271970  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.271975  4990 net.cpp:255] Memory required for data: 1050150400
I0612 11:05:14.271981  4990 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0612 11:05:14.271988  4990 net.cpp:190] Creating Layer Eltwise11_ReLU23_0_split
I0612 11:05:14.271993  4990 net.cpp:615] Eltwise11_ReLU23_0_split <- Eltwise11
I0612 11:05:14.272001  4990 net.cpp:589] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0612 11:05:14.272009  4990 net.cpp:589] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0612 11:05:14.272063  4990 net.cpp:240] Setting up Eltwise11_ReLU23_0_split
I0612 11:05:14.272071  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.272078  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.272084  4990 net.cpp:255] Memory required for data: 1066927616
I0612 11:05:14.272089  4990 layer_factory.hpp:77] Creating layer Convolution24
I0612 11:05:14.272104  4990 net.cpp:190] Creating Layer Convolution24
I0612 11:05:14.272110  4990 net.cpp:615] Convolution24 <- Eltwise11_ReLU23_0_split_0
I0612 11:05:14.272119  4990 net.cpp:589] Convolution24 -> Convolution24
I0612 11:05:14.272598  4990 net.cpp:240] Setting up Convolution24
I0612 11:05:14.272610  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.272615  4990 net.cpp:255] Memory required for data: 1075316224
I0612 11:05:14.272629  4990 layer_factory.hpp:77] Creating layer BatchNorm24
I0612 11:05:14.272642  4990 net.cpp:190] Creating Layer BatchNorm24
I0612 11:05:14.272649  4990 net.cpp:615] BatchNorm24 <- Convolution24
I0612 11:05:14.272658  4990 net.cpp:576] BatchNorm24 -> Convolution24 (in-place)
I0612 11:05:14.272956  4990 net.cpp:240] Setting up BatchNorm24
I0612 11:05:14.272969  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.272972  4990 net.cpp:255] Memory required for data: 1083704832
I0612 11:05:14.272987  4990 layer_factory.hpp:77] Creating layer Scale24
I0612 11:05:14.273000  4990 net.cpp:190] Creating Layer Scale24
I0612 11:05:14.273005  4990 net.cpp:615] Scale24 <- Convolution24
I0612 11:05:14.273012  4990 net.cpp:576] Scale24 -> Convolution24 (in-place)
I0612 11:05:14.273068  4990 layer_factory.hpp:77] Creating layer Scale24
I0612 11:05:14.273247  4990 net.cpp:240] Setting up Scale24
I0612 11:05:14.273258  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.273262  4990 net.cpp:255] Memory required for data: 1092093440
I0612 11:05:14.273274  4990 layer_factory.hpp:77] Creating layer ReLU24
I0612 11:05:14.273283  4990 net.cpp:190] Creating Layer ReLU24
I0612 11:05:14.273288  4990 net.cpp:615] ReLU24 <- Convolution24
I0612 11:05:14.273298  4990 net.cpp:576] ReLU24 -> Convolution24 (in-place)
I0612 11:05:14.273308  4990 net.cpp:240] Setting up ReLU24
I0612 11:05:14.273315  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.273319  4990 net.cpp:255] Memory required for data: 1100482048
I0612 11:05:14.273324  4990 layer_factory.hpp:77] Creating layer Convolution25
I0612 11:05:14.273339  4990 net.cpp:190] Creating Layer Convolution25
I0612 11:05:14.273344  4990 net.cpp:615] Convolution25 <- Convolution24
I0612 11:05:14.273355  4990 net.cpp:589] Convolution25 -> Convolution25
I0612 11:05:14.273828  4990 net.cpp:240] Setting up Convolution25
I0612 11:05:14.273841  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.273846  4990 net.cpp:255] Memory required for data: 1108870656
I0612 11:05:14.273859  4990 layer_factory.hpp:77] Creating layer BatchNorm25
I0612 11:05:14.273870  4990 net.cpp:190] Creating Layer BatchNorm25
I0612 11:05:14.273877  4990 net.cpp:615] BatchNorm25 <- Convolution25
I0612 11:05:14.273886  4990 net.cpp:576] BatchNorm25 -> Convolution25 (in-place)
I0612 11:05:14.274183  4990 net.cpp:240] Setting up BatchNorm25
I0612 11:05:14.274194  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.274199  4990 net.cpp:255] Memory required for data: 1117259264
I0612 11:05:14.274219  4990 layer_factory.hpp:77] Creating layer Scale25
I0612 11:05:14.274233  4990 net.cpp:190] Creating Layer Scale25
I0612 11:05:14.274240  4990 net.cpp:615] Scale25 <- Convolution25
I0612 11:05:14.274247  4990 net.cpp:576] Scale25 -> Convolution25 (in-place)
I0612 11:05:14.274304  4990 layer_factory.hpp:77] Creating layer Scale25
I0612 11:05:14.274488  4990 net.cpp:240] Setting up Scale25
I0612 11:05:14.274502  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.274507  4990 net.cpp:255] Memory required for data: 1125647872
I0612 11:05:14.274518  4990 layer_factory.hpp:77] Creating layer Eltwise12
I0612 11:05:14.274530  4990 net.cpp:190] Creating Layer Eltwise12
I0612 11:05:14.274538  4990 net.cpp:615] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0612 11:05:14.274544  4990 net.cpp:615] Eltwise12 <- Convolution25
I0612 11:05:14.274552  4990 net.cpp:589] Eltwise12 -> Eltwise12
I0612 11:05:14.274606  4990 net.cpp:240] Setting up Eltwise12
I0612 11:05:14.274621  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.274626  4990 net.cpp:255] Memory required for data: 1134036480
I0612 11:05:14.274631  4990 layer_factory.hpp:77] Creating layer ReLU25
I0612 11:05:14.274641  4990 net.cpp:190] Creating Layer ReLU25
I0612 11:05:14.274646  4990 net.cpp:615] ReLU25 <- Eltwise12
I0612 11:05:14.274652  4990 net.cpp:576] ReLU25 -> Eltwise12 (in-place)
I0612 11:05:14.274662  4990 net.cpp:240] Setting up ReLU25
I0612 11:05:14.274669  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.274677  4990 net.cpp:255] Memory required for data: 1142425088
I0612 11:05:14.274682  4990 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I0612 11:05:14.274688  4990 net.cpp:190] Creating Layer Eltwise12_ReLU25_0_split
I0612 11:05:14.274693  4990 net.cpp:615] Eltwise12_ReLU25_0_split <- Eltwise12
I0612 11:05:14.274701  4990 net.cpp:589] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I0612 11:05:14.274710  4990 net.cpp:589] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I0612 11:05:14.274763  4990 net.cpp:240] Setting up Eltwise12_ReLU25_0_split
I0612 11:05:14.274772  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.274780  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.274785  4990 net.cpp:255] Memory required for data: 1159202304
I0612 11:05:14.274790  4990 layer_factory.hpp:77] Creating layer Convolution26
I0612 11:05:14.274804  4990 net.cpp:190] Creating Layer Convolution26
I0612 11:05:14.274809  4990 net.cpp:615] Convolution26 <- Eltwise12_ReLU25_0_split_0
I0612 11:05:14.274819  4990 net.cpp:589] Convolution26 -> Convolution26
I0612 11:05:14.275287  4990 net.cpp:240] Setting up Convolution26
I0612 11:05:14.275300  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.275305  4990 net.cpp:255] Memory required for data: 1167590912
I0612 11:05:14.275317  4990 layer_factory.hpp:77] Creating layer BatchNorm26
I0612 11:05:14.275344  4990 net.cpp:190] Creating Layer BatchNorm26
I0612 11:05:14.275352  4990 net.cpp:615] BatchNorm26 <- Convolution26
I0612 11:05:14.275362  4990 net.cpp:576] BatchNorm26 -> Convolution26 (in-place)
I0612 11:05:14.275658  4990 net.cpp:240] Setting up BatchNorm26
I0612 11:05:14.275670  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.275674  4990 net.cpp:255] Memory required for data: 1175979520
I0612 11:05:14.275689  4990 layer_factory.hpp:77] Creating layer Scale26
I0612 11:05:14.275698  4990 net.cpp:190] Creating Layer Scale26
I0612 11:05:14.275704  4990 net.cpp:615] Scale26 <- Convolution26
I0612 11:05:14.275712  4990 net.cpp:576] Scale26 -> Convolution26 (in-place)
I0612 11:05:14.275763  4990 layer_factory.hpp:77] Creating layer Scale26
I0612 11:05:14.275949  4990 net.cpp:240] Setting up Scale26
I0612 11:05:14.275960  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.275965  4990 net.cpp:255] Memory required for data: 1184368128
I0612 11:05:14.275977  4990 layer_factory.hpp:77] Creating layer ReLU26
I0612 11:05:14.275990  4990 net.cpp:190] Creating Layer ReLU26
I0612 11:05:14.275995  4990 net.cpp:615] ReLU26 <- Convolution26
I0612 11:05:14.276007  4990 net.cpp:576] ReLU26 -> Convolution26 (in-place)
I0612 11:05:14.276017  4990 net.cpp:240] Setting up ReLU26
I0612 11:05:14.276024  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.276028  4990 net.cpp:255] Memory required for data: 1192756736
I0612 11:05:14.276034  4990 layer_factory.hpp:77] Creating layer Convolution27
I0612 11:05:14.276048  4990 net.cpp:190] Creating Layer Convolution27
I0612 11:05:14.276054  4990 net.cpp:615] Convolution27 <- Convolution26
I0612 11:05:14.276063  4990 net.cpp:589] Convolution27 -> Convolution27
I0612 11:05:14.276552  4990 net.cpp:240] Setting up Convolution27
I0612 11:05:14.276566  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.276571  4990 net.cpp:255] Memory required for data: 1201145344
I0612 11:05:14.276584  4990 layer_factory.hpp:77] Creating layer BatchNorm27
I0612 11:05:14.276597  4990 net.cpp:190] Creating Layer BatchNorm27
I0612 11:05:14.276603  4990 net.cpp:615] BatchNorm27 <- Convolution27
I0612 11:05:14.276612  4990 net.cpp:576] BatchNorm27 -> Convolution27 (in-place)
I0612 11:05:14.276922  4990 net.cpp:240] Setting up BatchNorm27
I0612 11:05:14.276933  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.276938  4990 net.cpp:255] Memory required for data: 1209533952
I0612 11:05:14.276953  4990 layer_factory.hpp:77] Creating layer Scale27
I0612 11:05:14.276962  4990 net.cpp:190] Creating Layer Scale27
I0612 11:05:14.276968  4990 net.cpp:615] Scale27 <- Convolution27
I0612 11:05:14.276978  4990 net.cpp:576] Scale27 -> Convolution27 (in-place)
I0612 11:05:14.277027  4990 layer_factory.hpp:77] Creating layer Scale27
I0612 11:05:14.278055  4990 net.cpp:240] Setting up Scale27
I0612 11:05:14.278076  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.278082  4990 net.cpp:255] Memory required for data: 1217922560
I0612 11:05:14.278097  4990 layer_factory.hpp:77] Creating layer Eltwise13
I0612 11:05:14.278108  4990 net.cpp:190] Creating Layer Eltwise13
I0612 11:05:14.278115  4990 net.cpp:615] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I0612 11:05:14.278123  4990 net.cpp:615] Eltwise13 <- Convolution27
I0612 11:05:14.278136  4990 net.cpp:589] Eltwise13 -> Eltwise13
I0612 11:05:14.278182  4990 net.cpp:240] Setting up Eltwise13
I0612 11:05:14.278192  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.278197  4990 net.cpp:255] Memory required for data: 1226311168
I0612 11:05:14.278201  4990 layer_factory.hpp:77] Creating layer ReLU27
I0612 11:05:14.278209  4990 net.cpp:190] Creating Layer ReLU27
I0612 11:05:14.278215  4990 net.cpp:615] ReLU27 <- Eltwise13
I0612 11:05:14.278223  4990 net.cpp:576] ReLU27 -> Eltwise13 (in-place)
I0612 11:05:14.278230  4990 net.cpp:240] Setting up ReLU27
I0612 11:05:14.278237  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.278242  4990 net.cpp:255] Memory required for data: 1234699776
I0612 11:05:14.278247  4990 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I0612 11:05:14.278257  4990 net.cpp:190] Creating Layer Eltwise13_ReLU27_0_split
I0612 11:05:14.278262  4990 net.cpp:615] Eltwise13_ReLU27_0_split <- Eltwise13
I0612 11:05:14.278270  4990 net.cpp:589] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I0612 11:05:14.278280  4990 net.cpp:589] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I0612 11:05:14.278333  4990 net.cpp:240] Setting up Eltwise13_ReLU27_0_split
I0612 11:05:14.278343  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.278352  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.278367  4990 net.cpp:255] Memory required for data: 1251476992
I0612 11:05:14.278373  4990 layer_factory.hpp:77] Creating layer Convolution28
I0612 11:05:14.278385  4990 net.cpp:190] Creating Layer Convolution28
I0612 11:05:14.278393  4990 net.cpp:615] Convolution28 <- Eltwise13_ReLU27_0_split_0
I0612 11:05:14.278401  4990 net.cpp:589] Convolution28 -> Convolution28
I0612 11:05:14.278934  4990 net.cpp:240] Setting up Convolution28
I0612 11:05:14.278949  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.278960  4990 net.cpp:255] Memory required for data: 1259865600
I0612 11:05:14.278975  4990 layer_factory.hpp:77] Creating layer BatchNorm28
I0612 11:05:14.278991  4990 net.cpp:190] Creating Layer BatchNorm28
I0612 11:05:14.278998  4990 net.cpp:615] BatchNorm28 <- Convolution28
I0612 11:05:14.279006  4990 net.cpp:576] BatchNorm28 -> Convolution28 (in-place)
I0612 11:05:14.279325  4990 net.cpp:240] Setting up BatchNorm28
I0612 11:05:14.279338  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.279343  4990 net.cpp:255] Memory required for data: 1268254208
I0612 11:05:14.279362  4990 layer_factory.hpp:77] Creating layer Scale28
I0612 11:05:14.279372  4990 net.cpp:190] Creating Layer Scale28
I0612 11:05:14.279379  4990 net.cpp:615] Scale28 <- Convolution28
I0612 11:05:14.279387  4990 net.cpp:576] Scale28 -> Convolution28 (in-place)
I0612 11:05:14.279444  4990 layer_factory.hpp:77] Creating layer Scale28
I0612 11:05:14.279623  4990 net.cpp:240] Setting up Scale28
I0612 11:05:14.279634  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.279639  4990 net.cpp:255] Memory required for data: 1276642816
I0612 11:05:14.279651  4990 layer_factory.hpp:77] Creating layer ReLU28
I0612 11:05:14.279664  4990 net.cpp:190] Creating Layer ReLU28
I0612 11:05:14.279670  4990 net.cpp:615] ReLU28 <- Convolution28
I0612 11:05:14.279677  4990 net.cpp:576] ReLU28 -> Convolution28 (in-place)
I0612 11:05:14.279686  4990 net.cpp:240] Setting up ReLU28
I0612 11:05:14.279693  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.279698  4990 net.cpp:255] Memory required for data: 1285031424
I0612 11:05:14.279703  4990 layer_factory.hpp:77] Creating layer Convolution29
I0612 11:05:14.279718  4990 net.cpp:190] Creating Layer Convolution29
I0612 11:05:14.279724  4990 net.cpp:615] Convolution29 <- Convolution28
I0612 11:05:14.279732  4990 net.cpp:589] Convolution29 -> Convolution29
I0612 11:05:14.280210  4990 net.cpp:240] Setting up Convolution29
I0612 11:05:14.280222  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.280228  4990 net.cpp:255] Memory required for data: 1293420032
I0612 11:05:14.280241  4990 layer_factory.hpp:77] Creating layer BatchNorm29
I0612 11:05:14.280266  4990 net.cpp:190] Creating Layer BatchNorm29
I0612 11:05:14.280273  4990 net.cpp:615] BatchNorm29 <- Convolution29
I0612 11:05:14.280282  4990 net.cpp:576] BatchNorm29 -> Convolution29 (in-place)
I0612 11:05:14.280583  4990 net.cpp:240] Setting up BatchNorm29
I0612 11:05:14.280596  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.280601  4990 net.cpp:255] Memory required for data: 1301808640
I0612 11:05:14.280616  4990 layer_factory.hpp:77] Creating layer Scale29
I0612 11:05:14.280624  4990 net.cpp:190] Creating Layer Scale29
I0612 11:05:14.280629  4990 net.cpp:615] Scale29 <- Convolution29
I0612 11:05:14.280637  4990 net.cpp:576] Scale29 -> Convolution29 (in-place)
I0612 11:05:14.280691  4990 layer_factory.hpp:77] Creating layer Scale29
I0612 11:05:14.280875  4990 net.cpp:240] Setting up Scale29
I0612 11:05:14.280886  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.280891  4990 net.cpp:255] Memory required for data: 1310197248
I0612 11:05:14.280905  4990 layer_factory.hpp:77] Creating layer Eltwise14
I0612 11:05:14.280915  4990 net.cpp:190] Creating Layer Eltwise14
I0612 11:05:14.280921  4990 net.cpp:615] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I0612 11:05:14.280930  4990 net.cpp:615] Eltwise14 <- Convolution29
I0612 11:05:14.280939  4990 net.cpp:589] Eltwise14 -> Eltwise14
I0612 11:05:14.280975  4990 net.cpp:240] Setting up Eltwise14
I0612 11:05:14.280984  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.280989  4990 net.cpp:255] Memory required for data: 1318585856
I0612 11:05:14.280994  4990 layer_factory.hpp:77] Creating layer ReLU29
I0612 11:05:14.281005  4990 net.cpp:190] Creating Layer ReLU29
I0612 11:05:14.281011  4990 net.cpp:615] ReLU29 <- Eltwise14
I0612 11:05:14.281018  4990 net.cpp:576] ReLU29 -> Eltwise14 (in-place)
I0612 11:05:14.281033  4990 net.cpp:240] Setting up ReLU29
I0612 11:05:14.281040  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.281045  4990 net.cpp:255] Memory required for data: 1326974464
I0612 11:05:14.281050  4990 layer_factory.hpp:77] Creating layer Eltwise14_ReLU29_0_split
I0612 11:05:14.281059  4990 net.cpp:190] Creating Layer Eltwise14_ReLU29_0_split
I0612 11:05:14.281064  4990 net.cpp:615] Eltwise14_ReLU29_0_split <- Eltwise14
I0612 11:05:14.281075  4990 net.cpp:589] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_0
I0612 11:05:14.281085  4990 net.cpp:589] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_1
I0612 11:05:14.281154  4990 net.cpp:240] Setting up Eltwise14_ReLU29_0_split
I0612 11:05:14.281164  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.281172  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.281175  4990 net.cpp:255] Memory required for data: 1343751680
I0612 11:05:14.281180  4990 layer_factory.hpp:77] Creating layer Convolution30
I0612 11:05:14.281198  4990 net.cpp:190] Creating Layer Convolution30
I0612 11:05:14.281203  4990 net.cpp:615] Convolution30 <- Eltwise14_ReLU29_0_split_0
I0612 11:05:14.281213  4990 net.cpp:589] Convolution30 -> Convolution30
I0612 11:05:14.281684  4990 net.cpp:240] Setting up Convolution30
I0612 11:05:14.281698  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.281704  4990 net.cpp:255] Memory required for data: 1352140288
I0612 11:05:14.281718  4990 layer_factory.hpp:77] Creating layer BatchNorm30
I0612 11:05:14.281728  4990 net.cpp:190] Creating Layer BatchNorm30
I0612 11:05:14.281734  4990 net.cpp:615] BatchNorm30 <- Convolution30
I0612 11:05:14.281746  4990 net.cpp:576] BatchNorm30 -> Convolution30 (in-place)
I0612 11:05:14.282047  4990 net.cpp:240] Setting up BatchNorm30
I0612 11:05:14.282058  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.282063  4990 net.cpp:255] Memory required for data: 1360528896
I0612 11:05:14.282078  4990 layer_factory.hpp:77] Creating layer Scale30
I0612 11:05:14.282086  4990 net.cpp:190] Creating Layer Scale30
I0612 11:05:14.282091  4990 net.cpp:615] Scale30 <- Convolution30
I0612 11:05:14.282102  4990 net.cpp:576] Scale30 -> Convolution30 (in-place)
I0612 11:05:14.282151  4990 layer_factory.hpp:77] Creating layer Scale30
I0612 11:05:14.282321  4990 net.cpp:240] Setting up Scale30
I0612 11:05:14.282332  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.282337  4990 net.cpp:255] Memory required for data: 1368917504
I0612 11:05:14.282349  4990 layer_factory.hpp:77] Creating layer ReLU30
I0612 11:05:14.282373  4990 net.cpp:190] Creating Layer ReLU30
I0612 11:05:14.282380  4990 net.cpp:615] ReLU30 <- Convolution30
I0612 11:05:14.282388  4990 net.cpp:576] ReLU30 -> Convolution30 (in-place)
I0612 11:05:14.282397  4990 net.cpp:240] Setting up ReLU30
I0612 11:05:14.282404  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.282408  4990 net.cpp:255] Memory required for data: 1377306112
I0612 11:05:14.282413  4990 layer_factory.hpp:77] Creating layer Convolution31
I0612 11:05:14.282428  4990 net.cpp:190] Creating Layer Convolution31
I0612 11:05:14.282433  4990 net.cpp:615] Convolution31 <- Convolution30
I0612 11:05:14.282444  4990 net.cpp:589] Convolution31 -> Convolution31
I0612 11:05:14.282927  4990 net.cpp:240] Setting up Convolution31
I0612 11:05:14.282941  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.282946  4990 net.cpp:255] Memory required for data: 1385694720
I0612 11:05:14.282958  4990 layer_factory.hpp:77] Creating layer BatchNorm31
I0612 11:05:14.282970  4990 net.cpp:190] Creating Layer BatchNorm31
I0612 11:05:14.282976  4990 net.cpp:615] BatchNorm31 <- Convolution31
I0612 11:05:14.282984  4990 net.cpp:576] BatchNorm31 -> Convolution31 (in-place)
I0612 11:05:14.283267  4990 net.cpp:240] Setting up BatchNorm31
I0612 11:05:14.283277  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.283282  4990 net.cpp:255] Memory required for data: 1394083328
I0612 11:05:14.283295  4990 layer_factory.hpp:77] Creating layer Scale31
I0612 11:05:14.283311  4990 net.cpp:190] Creating Layer Scale31
I0612 11:05:14.283318  4990 net.cpp:615] Scale31 <- Convolution31
I0612 11:05:14.283324  4990 net.cpp:576] Scale31 -> Convolution31 (in-place)
I0612 11:05:14.283370  4990 layer_factory.hpp:77] Creating layer Scale31
I0612 11:05:14.283530  4990 net.cpp:240] Setting up Scale31
I0612 11:05:14.283543  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.283548  4990 net.cpp:255] Memory required for data: 1402471936
I0612 11:05:14.283560  4990 layer_factory.hpp:77] Creating layer Eltwise15
I0612 11:05:14.283568  4990 net.cpp:190] Creating Layer Eltwise15
I0612 11:05:14.283574  4990 net.cpp:615] Eltwise15 <- Eltwise14_ReLU29_0_split_1
I0612 11:05:14.283581  4990 net.cpp:615] Eltwise15 <- Convolution31
I0612 11:05:14.283588  4990 net.cpp:589] Eltwise15 -> Eltwise15
I0612 11:05:14.283628  4990 net.cpp:240] Setting up Eltwise15
I0612 11:05:14.283638  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.283643  4990 net.cpp:255] Memory required for data: 1410860544
I0612 11:05:14.283648  4990 layer_factory.hpp:77] Creating layer ReLU31
I0612 11:05:14.283658  4990 net.cpp:190] Creating Layer ReLU31
I0612 11:05:14.283663  4990 net.cpp:615] ReLU31 <- Eltwise15
I0612 11:05:14.283670  4990 net.cpp:576] ReLU31 -> Eltwise15 (in-place)
I0612 11:05:14.283679  4990 net.cpp:240] Setting up ReLU31
I0612 11:05:14.283684  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.283689  4990 net.cpp:255] Memory required for data: 1419249152
I0612 11:05:14.283694  4990 layer_factory.hpp:77] Creating layer Eltwise15_ReLU31_0_split
I0612 11:05:14.283701  4990 net.cpp:190] Creating Layer Eltwise15_ReLU31_0_split
I0612 11:05:14.283705  4990 net.cpp:615] Eltwise15_ReLU31_0_split <- Eltwise15
I0612 11:05:14.283715  4990 net.cpp:589] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_0
I0612 11:05:14.283726  4990 net.cpp:589] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_1
I0612 11:05:14.283777  4990 net.cpp:240] Setting up Eltwise15_ReLU31_0_split
I0612 11:05:14.283785  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.283792  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.283797  4990 net.cpp:255] Memory required for data: 1436026368
I0612 11:05:14.283802  4990 layer_factory.hpp:77] Creating layer Convolution32
I0612 11:05:14.283818  4990 net.cpp:190] Creating Layer Convolution32
I0612 11:05:14.283823  4990 net.cpp:615] Convolution32 <- Eltwise15_ReLU31_0_split_0
I0612 11:05:14.283831  4990 net.cpp:589] Convolution32 -> Convolution32
I0612 11:05:14.284271  4990 net.cpp:240] Setting up Convolution32
I0612 11:05:14.284283  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.284288  4990 net.cpp:255] Memory required for data: 1444414976
I0612 11:05:14.284301  4990 layer_factory.hpp:77] Creating layer BatchNorm32
I0612 11:05:14.284313  4990 net.cpp:190] Creating Layer BatchNorm32
I0612 11:05:14.284319  4990 net.cpp:615] BatchNorm32 <- Convolution32
I0612 11:05:14.284329  4990 net.cpp:576] BatchNorm32 -> Convolution32 (in-place)
I0612 11:05:14.284611  4990 net.cpp:240] Setting up BatchNorm32
I0612 11:05:14.284622  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.284626  4990 net.cpp:255] Memory required for data: 1452803584
I0612 11:05:14.284649  4990 layer_factory.hpp:77] Creating layer Scale32
I0612 11:05:14.284658  4990 net.cpp:190] Creating Layer Scale32
I0612 11:05:14.284663  4990 net.cpp:615] Scale32 <- Convolution32
I0612 11:05:14.284672  4990 net.cpp:576] Scale32 -> Convolution32 (in-place)
I0612 11:05:14.284723  4990 layer_factory.hpp:77] Creating layer Scale32
I0612 11:05:14.284885  4990 net.cpp:240] Setting up Scale32
I0612 11:05:14.284896  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.284900  4990 net.cpp:255] Memory required for data: 1461192192
I0612 11:05:14.284912  4990 layer_factory.hpp:77] Creating layer ReLU32
I0612 11:05:14.284921  4990 net.cpp:190] Creating Layer ReLU32
I0612 11:05:14.284926  4990 net.cpp:615] ReLU32 <- Convolution32
I0612 11:05:14.284941  4990 net.cpp:576] ReLU32 -> Convolution32 (in-place)
I0612 11:05:14.284950  4990 net.cpp:240] Setting up ReLU32
I0612 11:05:14.284957  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.284962  4990 net.cpp:255] Memory required for data: 1469580800
I0612 11:05:14.284967  4990 layer_factory.hpp:77] Creating layer Convolution33
I0612 11:05:14.284981  4990 net.cpp:190] Creating Layer Convolution33
I0612 11:05:14.284986  4990 net.cpp:615] Convolution33 <- Convolution32
I0612 11:05:14.284994  4990 net.cpp:589] Convolution33 -> Convolution33
I0612 11:05:14.285429  4990 net.cpp:240] Setting up Convolution33
I0612 11:05:14.285440  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.285446  4990 net.cpp:255] Memory required for data: 1477969408
I0612 11:05:14.285459  4990 layer_factory.hpp:77] Creating layer BatchNorm33
I0612 11:05:14.285480  4990 net.cpp:190] Creating Layer BatchNorm33
I0612 11:05:14.285491  4990 net.cpp:615] BatchNorm33 <- Convolution33
I0612 11:05:14.285500  4990 net.cpp:576] BatchNorm33 -> Convolution33 (in-place)
I0612 11:05:14.285789  4990 net.cpp:240] Setting up BatchNorm33
I0612 11:05:14.285801  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.285806  4990 net.cpp:255] Memory required for data: 1486358016
I0612 11:05:14.285823  4990 layer_factory.hpp:77] Creating layer Scale33
I0612 11:05:14.285832  4990 net.cpp:190] Creating Layer Scale33
I0612 11:05:14.285838  4990 net.cpp:615] Scale33 <- Convolution33
I0612 11:05:14.285845  4990 net.cpp:576] Scale33 -> Convolution33 (in-place)
I0612 11:05:14.285897  4990 layer_factory.hpp:77] Creating layer Scale33
I0612 11:05:14.286064  4990 net.cpp:240] Setting up Scale33
I0612 11:05:14.286074  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.286079  4990 net.cpp:255] Memory required for data: 1494746624
I0612 11:05:14.286090  4990 layer_factory.hpp:77] Creating layer Eltwise16
I0612 11:05:14.286103  4990 net.cpp:190] Creating Layer Eltwise16
I0612 11:05:14.286110  4990 net.cpp:615] Eltwise16 <- Eltwise15_ReLU31_0_split_1
I0612 11:05:14.286118  4990 net.cpp:615] Eltwise16 <- Convolution33
I0612 11:05:14.286124  4990 net.cpp:589] Eltwise16 -> Eltwise16
I0612 11:05:14.286164  4990 net.cpp:240] Setting up Eltwise16
I0612 11:05:14.286172  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.286177  4990 net.cpp:255] Memory required for data: 1503135232
I0612 11:05:14.286182  4990 layer_factory.hpp:77] Creating layer ReLU33
I0612 11:05:14.286190  4990 net.cpp:190] Creating Layer ReLU33
I0612 11:05:14.286195  4990 net.cpp:615] ReLU33 <- Eltwise16
I0612 11:05:14.286204  4990 net.cpp:576] ReLU33 -> Eltwise16 (in-place)
I0612 11:05:14.286212  4990 net.cpp:240] Setting up ReLU33
I0612 11:05:14.286219  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.286223  4990 net.cpp:255] Memory required for data: 1511523840
I0612 11:05:14.286228  4990 layer_factory.hpp:77] Creating layer Eltwise16_ReLU33_0_split
I0612 11:05:14.286236  4990 net.cpp:190] Creating Layer Eltwise16_ReLU33_0_split
I0612 11:05:14.286239  4990 net.cpp:615] Eltwise16_ReLU33_0_split <- Eltwise16
I0612 11:05:14.286247  4990 net.cpp:589] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_0
I0612 11:05:14.286254  4990 net.cpp:589] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_1
I0612 11:05:14.286308  4990 net.cpp:240] Setting up Eltwise16_ReLU33_0_split
I0612 11:05:14.286316  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.286324  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.286329  4990 net.cpp:255] Memory required for data: 1528301056
I0612 11:05:14.286334  4990 layer_factory.hpp:77] Creating layer Convolution34
I0612 11:05:14.286345  4990 net.cpp:190] Creating Layer Convolution34
I0612 11:05:14.286350  4990 net.cpp:615] Convolution34 <- Eltwise16_ReLU33_0_split_0
I0612 11:05:14.286370  4990 net.cpp:589] Convolution34 -> Convolution34
I0612 11:05:14.286808  4990 net.cpp:240] Setting up Convolution34
I0612 11:05:14.286824  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.286829  4990 net.cpp:255] Memory required for data: 1536689664
I0612 11:05:14.286841  4990 layer_factory.hpp:77] Creating layer BatchNorm34
I0612 11:05:14.286850  4990 net.cpp:190] Creating Layer BatchNorm34
I0612 11:05:14.286855  4990 net.cpp:615] BatchNorm34 <- Convolution34
I0612 11:05:14.286862  4990 net.cpp:576] BatchNorm34 -> Convolution34 (in-place)
I0612 11:05:14.287147  4990 net.cpp:240] Setting up BatchNorm34
I0612 11:05:14.287158  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.287163  4990 net.cpp:255] Memory required for data: 1545078272
I0612 11:05:14.287179  4990 layer_factory.hpp:77] Creating layer Scale34
I0612 11:05:14.287189  4990 net.cpp:190] Creating Layer Scale34
I0612 11:05:14.287194  4990 net.cpp:615] Scale34 <- Convolution34
I0612 11:05:14.287200  4990 net.cpp:576] Scale34 -> Convolution34 (in-place)
I0612 11:05:14.287255  4990 layer_factory.hpp:77] Creating layer Scale34
I0612 11:05:14.287415  4990 net.cpp:240] Setting up Scale34
I0612 11:05:14.287425  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.287431  4990 net.cpp:255] Memory required for data: 1553466880
I0612 11:05:14.287444  4990 layer_factory.hpp:77] Creating layer ReLU34
I0612 11:05:14.287452  4990 net.cpp:190] Creating Layer ReLU34
I0612 11:05:14.287458  4990 net.cpp:615] ReLU34 <- Convolution34
I0612 11:05:14.287467  4990 net.cpp:576] ReLU34 -> Convolution34 (in-place)
I0612 11:05:14.287477  4990 net.cpp:240] Setting up ReLU34
I0612 11:05:14.287483  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.287489  4990 net.cpp:255] Memory required for data: 1561855488
I0612 11:05:14.287494  4990 layer_factory.hpp:77] Creating layer Convolution35
I0612 11:05:14.287505  4990 net.cpp:190] Creating Layer Convolution35
I0612 11:05:14.287510  4990 net.cpp:615] Convolution35 <- Convolution34
I0612 11:05:14.287523  4990 net.cpp:589] Convolution35 -> Convolution35
I0612 11:05:14.287994  4990 net.cpp:240] Setting up Convolution35
I0612 11:05:14.288009  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.288014  4990 net.cpp:255] Memory required for data: 1570244096
I0612 11:05:14.288027  4990 layer_factory.hpp:77] Creating layer BatchNorm35
I0612 11:05:14.288035  4990 net.cpp:190] Creating Layer BatchNorm35
I0612 11:05:14.288040  4990 net.cpp:615] BatchNorm35 <- Convolution35
I0612 11:05:14.288051  4990 net.cpp:576] BatchNorm35 -> Convolution35 (in-place)
I0612 11:05:14.289178  4990 net.cpp:240] Setting up BatchNorm35
I0612 11:05:14.289199  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.289204  4990 net.cpp:255] Memory required for data: 1578632704
I0612 11:05:14.289222  4990 layer_factory.hpp:77] Creating layer Scale35
I0612 11:05:14.289235  4990 net.cpp:190] Creating Layer Scale35
I0612 11:05:14.289242  4990 net.cpp:615] Scale35 <- Convolution35
I0612 11:05:14.289249  4990 net.cpp:576] Scale35 -> Convolution35 (in-place)
I0612 11:05:14.289304  4990 layer_factory.hpp:77] Creating layer Scale35
I0612 11:05:14.289469  4990 net.cpp:240] Setting up Scale35
I0612 11:05:14.289479  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.289484  4990 net.cpp:255] Memory required for data: 1587021312
I0612 11:05:14.289495  4990 layer_factory.hpp:77] Creating layer Eltwise17
I0612 11:05:14.289505  4990 net.cpp:190] Creating Layer Eltwise17
I0612 11:05:14.289510  4990 net.cpp:615] Eltwise17 <- Eltwise16_ReLU33_0_split_1
I0612 11:05:14.289517  4990 net.cpp:615] Eltwise17 <- Convolution35
I0612 11:05:14.289525  4990 net.cpp:589] Eltwise17 -> Eltwise17
I0612 11:05:14.289564  4990 net.cpp:240] Setting up Eltwise17
I0612 11:05:14.289574  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.289580  4990 net.cpp:255] Memory required for data: 1595409920
I0612 11:05:14.289585  4990 layer_factory.hpp:77] Creating layer ReLU35
I0612 11:05:14.289594  4990 net.cpp:190] Creating Layer ReLU35
I0612 11:05:14.289600  4990 net.cpp:615] ReLU35 <- Eltwise17
I0612 11:05:14.289608  4990 net.cpp:576] ReLU35 -> Eltwise17 (in-place)
I0612 11:05:14.289623  4990 net.cpp:240] Setting up ReLU35
I0612 11:05:14.289630  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.289635  4990 net.cpp:255] Memory required for data: 1603798528
I0612 11:05:14.289640  4990 layer_factory.hpp:77] Creating layer Eltwise17_ReLU35_0_split
I0612 11:05:14.289647  4990 net.cpp:190] Creating Layer Eltwise17_ReLU35_0_split
I0612 11:05:14.289651  4990 net.cpp:615] Eltwise17_ReLU35_0_split <- Eltwise17
I0612 11:05:14.289661  4990 net.cpp:589] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_0
I0612 11:05:14.289671  4990 net.cpp:589] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_1
I0612 11:05:14.289721  4990 net.cpp:240] Setting up Eltwise17_ReLU35_0_split
I0612 11:05:14.289728  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.289734  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.289739  4990 net.cpp:255] Memory required for data: 1620575744
I0612 11:05:14.289743  4990 layer_factory.hpp:77] Creating layer Convolution36
I0612 11:05:14.289758  4990 net.cpp:190] Creating Layer Convolution36
I0612 11:05:14.289764  4990 net.cpp:615] Convolution36 <- Eltwise17_ReLU35_0_split_0
I0612 11:05:14.289773  4990 net.cpp:589] Convolution36 -> Convolution36
I0612 11:05:14.290216  4990 net.cpp:240] Setting up Convolution36
I0612 11:05:14.290230  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.290235  4990 net.cpp:255] Memory required for data: 1628964352
I0612 11:05:14.290248  4990 layer_factory.hpp:77] Creating layer BatchNorm36
I0612 11:05:14.290261  4990 net.cpp:190] Creating Layer BatchNorm36
I0612 11:05:14.290266  4990 net.cpp:615] BatchNorm36 <- Convolution36
I0612 11:05:14.290273  4990 net.cpp:576] BatchNorm36 -> Convolution36 (in-place)
I0612 11:05:14.290561  4990 net.cpp:240] Setting up BatchNorm36
I0612 11:05:14.290575  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.290580  4990 net.cpp:255] Memory required for data: 1637352960
I0612 11:05:14.290596  4990 layer_factory.hpp:77] Creating layer Scale36
I0612 11:05:14.290606  4990 net.cpp:190] Creating Layer Scale36
I0612 11:05:14.290611  4990 net.cpp:615] Scale36 <- Convolution36
I0612 11:05:14.290619  4990 net.cpp:576] Scale36 -> Convolution36 (in-place)
I0612 11:05:14.290668  4990 layer_factory.hpp:77] Creating layer Scale36
I0612 11:05:14.290843  4990 net.cpp:240] Setting up Scale36
I0612 11:05:14.290853  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.290858  4990 net.cpp:255] Memory required for data: 1645741568
I0612 11:05:14.290870  4990 layer_factory.hpp:77] Creating layer ReLU36
I0612 11:05:14.290881  4990 net.cpp:190] Creating Layer ReLU36
I0612 11:05:14.290889  4990 net.cpp:615] ReLU36 <- Convolution36
I0612 11:05:14.290895  4990 net.cpp:576] ReLU36 -> Convolution36 (in-place)
I0612 11:05:14.290904  4990 net.cpp:240] Setting up ReLU36
I0612 11:05:14.290910  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.290915  4990 net.cpp:255] Memory required for data: 1654130176
I0612 11:05:14.290920  4990 layer_factory.hpp:77] Creating layer Convolution37
I0612 11:05:14.290932  4990 net.cpp:190] Creating Layer Convolution37
I0612 11:05:14.290938  4990 net.cpp:615] Convolution37 <- Convolution36
I0612 11:05:14.290946  4990 net.cpp:589] Convolution37 -> Convolution37
I0612 11:05:14.291396  4990 net.cpp:240] Setting up Convolution37
I0612 11:05:14.291409  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.291414  4990 net.cpp:255] Memory required for data: 1662518784
I0612 11:05:14.291425  4990 layer_factory.hpp:77] Creating layer BatchNorm37
I0612 11:05:14.291436  4990 net.cpp:190] Creating Layer BatchNorm37
I0612 11:05:14.291442  4990 net.cpp:615] BatchNorm37 <- Convolution37
I0612 11:05:14.291450  4990 net.cpp:576] BatchNorm37 -> Convolution37 (in-place)
I0612 11:05:14.291717  4990 net.cpp:240] Setting up BatchNorm37
I0612 11:05:14.291726  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.291730  4990 net.cpp:255] Memory required for data: 1670907392
I0612 11:05:14.291786  4990 layer_factory.hpp:77] Creating layer Scale37
I0612 11:05:14.291802  4990 net.cpp:190] Creating Layer Scale37
I0612 11:05:14.291808  4990 net.cpp:615] Scale37 <- Convolution37
I0612 11:05:14.291816  4990 net.cpp:576] Scale37 -> Convolution37 (in-place)
I0612 11:05:14.291867  4990 layer_factory.hpp:77] Creating layer Scale37
I0612 11:05:14.292021  4990 net.cpp:240] Setting up Scale37
I0612 11:05:14.292032  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.292037  4990 net.cpp:255] Memory required for data: 1679296000
I0612 11:05:14.292048  4990 layer_factory.hpp:77] Creating layer Eltwise18
I0612 11:05:14.292059  4990 net.cpp:190] Creating Layer Eltwise18
I0612 11:05:14.292067  4990 net.cpp:615] Eltwise18 <- Eltwise17_ReLU35_0_split_1
I0612 11:05:14.292073  4990 net.cpp:615] Eltwise18 <- Convolution37
I0612 11:05:14.292080  4990 net.cpp:589] Eltwise18 -> Eltwise18
I0612 11:05:14.292116  4990 net.cpp:240] Setting up Eltwise18
I0612 11:05:14.292125  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.292130  4990 net.cpp:255] Memory required for data: 1687684608
I0612 11:05:14.292135  4990 layer_factory.hpp:77] Creating layer ReLU37
I0612 11:05:14.292142  4990 net.cpp:190] Creating Layer ReLU37
I0612 11:05:14.292147  4990 net.cpp:615] ReLU37 <- Eltwise18
I0612 11:05:14.292156  4990 net.cpp:576] ReLU37 -> Eltwise18 (in-place)
I0612 11:05:14.292165  4990 net.cpp:240] Setting up ReLU37
I0612 11:05:14.292171  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.292176  4990 net.cpp:255] Memory required for data: 1696073216
I0612 11:05:14.292181  4990 layer_factory.hpp:77] Creating layer Eltwise18_ReLU37_0_split
I0612 11:05:14.292187  4990 net.cpp:190] Creating Layer Eltwise18_ReLU37_0_split
I0612 11:05:14.292191  4990 net.cpp:615] Eltwise18_ReLU37_0_split <- Eltwise18
I0612 11:05:14.292198  4990 net.cpp:589] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_0
I0612 11:05:14.292207  4990 net.cpp:589] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_1
I0612 11:05:14.292258  4990 net.cpp:240] Setting up Eltwise18_ReLU37_0_split
I0612 11:05:14.292268  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.292273  4990 net.cpp:247] Top shape: 128 16 32 32 (2097152)
I0612 11:05:14.292278  4990 net.cpp:255] Memory required for data: 1712850432
I0612 11:05:14.292282  4990 layer_factory.hpp:77] Creating layer Pooling1
I0612 11:05:14.292294  4990 net.cpp:190] Creating Layer Pooling1
I0612 11:05:14.292299  4990 net.cpp:615] Pooling1 <- Eltwise18_ReLU37_0_split_0
I0612 11:05:14.292306  4990 net.cpp:589] Pooling1 -> Pooling1
I0612 11:05:14.292337  4990 net.cpp:240] Setting up Pooling1
I0612 11:05:14.292346  4990 net.cpp:247] Top shape: 128 16 16 16 (524288)
I0612 11:05:14.292351  4990 net.cpp:255] Memory required for data: 1714947584
I0612 11:05:14.292354  4990 layer_factory.hpp:77] Creating layer Input1
I0612 11:05:14.292363  4990 net.cpp:190] Creating Layer Input1
I0612 11:05:14.292373  4990 net.cpp:589] Input1 -> Input1
I0612 11:05:14.292408  4990 net.cpp:240] Setting up Input1
I0612 11:05:14.292417  4990 net.cpp:247] Top shape: 128 16 16 16 (524288)
I0612 11:05:14.292421  4990 net.cpp:255] Memory required for data: 1717044736
I0612 11:05:14.292426  4990 layer_factory.hpp:77] Creating layer Concat1
I0612 11:05:14.292434  4990 net.cpp:190] Creating Layer Concat1
I0612 11:05:14.292439  4990 net.cpp:615] Concat1 <- Pooling1
I0612 11:05:14.292445  4990 net.cpp:615] Concat1 <- Input1
I0612 11:05:14.292454  4990 net.cpp:589] Concat1 -> Concat1
I0612 11:05:14.292487  4990 net.cpp:240] Setting up Concat1
I0612 11:05:14.292495  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.292500  4990 net.cpp:255] Memory required for data: 1721239040
I0612 11:05:14.292505  4990 layer_factory.hpp:77] Creating layer Convolution38
I0612 11:05:14.292518  4990 net.cpp:190] Creating Layer Convolution38
I0612 11:05:14.292524  4990 net.cpp:615] Convolution38 <- Eltwise18_ReLU37_0_split_1
I0612 11:05:14.292537  4990 net.cpp:589] Convolution38 -> Convolution38
I0612 11:05:14.293112  4990 net.cpp:240] Setting up Convolution38
I0612 11:05:14.293125  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.293130  4990 net.cpp:255] Memory required for data: 1725433344
I0612 11:05:14.293143  4990 layer_factory.hpp:77] Creating layer BatchNorm38
I0612 11:05:14.293151  4990 net.cpp:190] Creating Layer BatchNorm38
I0612 11:05:14.293157  4990 net.cpp:615] BatchNorm38 <- Convolution38
I0612 11:05:14.293167  4990 net.cpp:576] BatchNorm38 -> Convolution38 (in-place)
I0612 11:05:14.293427  4990 net.cpp:240] Setting up BatchNorm38
I0612 11:05:14.293438  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.293443  4990 net.cpp:255] Memory required for data: 1729627648
I0612 11:05:14.293457  4990 layer_factory.hpp:77] Creating layer Scale38
I0612 11:05:14.293467  4990 net.cpp:190] Creating Layer Scale38
I0612 11:05:14.293472  4990 net.cpp:615] Scale38 <- Convolution38
I0612 11:05:14.293478  4990 net.cpp:576] Scale38 -> Convolution38 (in-place)
I0612 11:05:14.293526  4990 layer_factory.hpp:77] Creating layer Scale38
I0612 11:05:14.293690  4990 net.cpp:240] Setting up Scale38
I0612 11:05:14.293701  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.293705  4990 net.cpp:255] Memory required for data: 1733821952
I0612 11:05:14.293717  4990 layer_factory.hpp:77] Creating layer ReLU38
I0612 11:05:14.293728  4990 net.cpp:190] Creating Layer ReLU38
I0612 11:05:14.293735  4990 net.cpp:615] ReLU38 <- Convolution38
I0612 11:05:14.293741  4990 net.cpp:576] ReLU38 -> Convolution38 (in-place)
I0612 11:05:14.293751  4990 net.cpp:240] Setting up ReLU38
I0612 11:05:14.293757  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.293761  4990 net.cpp:255] Memory required for data: 1738016256
I0612 11:05:14.293766  4990 layer_factory.hpp:77] Creating layer Convolution39
I0612 11:05:14.293783  4990 net.cpp:190] Creating Layer Convolution39
I0612 11:05:14.293789  4990 net.cpp:615] Convolution39 <- Convolution38
I0612 11:05:14.293797  4990 net.cpp:589] Convolution39 -> Convolution39
I0612 11:05:14.294561  4990 net.cpp:240] Setting up Convolution39
I0612 11:05:14.294574  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.294579  4990 net.cpp:255] Memory required for data: 1742210560
I0612 11:05:14.294591  4990 layer_factory.hpp:77] Creating layer BatchNorm39
I0612 11:05:14.294603  4990 net.cpp:190] Creating Layer BatchNorm39
I0612 11:05:14.294610  4990 net.cpp:615] BatchNorm39 <- Convolution39
I0612 11:05:14.294616  4990 net.cpp:576] BatchNorm39 -> Convolution39 (in-place)
I0612 11:05:14.294878  4990 net.cpp:240] Setting up BatchNorm39
I0612 11:05:14.294888  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.294891  4990 net.cpp:255] Memory required for data: 1746404864
I0612 11:05:14.294904  4990 layer_factory.hpp:77] Creating layer Scale39
I0612 11:05:14.294914  4990 net.cpp:190] Creating Layer Scale39
I0612 11:05:14.294919  4990 net.cpp:615] Scale39 <- Convolution39
I0612 11:05:14.294929  4990 net.cpp:576] Scale39 -> Convolution39 (in-place)
I0612 11:05:14.294970  4990 layer_factory.hpp:77] Creating layer Scale39
I0612 11:05:14.295114  4990 net.cpp:240] Setting up Scale39
I0612 11:05:14.295125  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.295130  4990 net.cpp:255] Memory required for data: 1750599168
I0612 11:05:14.295141  4990 layer_factory.hpp:77] Creating layer Eltwise19
I0612 11:05:14.295150  4990 net.cpp:190] Creating Layer Eltwise19
I0612 11:05:14.295155  4990 net.cpp:615] Eltwise19 <- Concat1
I0612 11:05:14.295161  4990 net.cpp:615] Eltwise19 <- Convolution39
I0612 11:05:14.295168  4990 net.cpp:589] Eltwise19 -> Eltwise19
I0612 11:05:14.295198  4990 net.cpp:240] Setting up Eltwise19
I0612 11:05:14.295207  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.295212  4990 net.cpp:255] Memory required for data: 1754793472
I0612 11:05:14.295217  4990 layer_factory.hpp:77] Creating layer ReLU39
I0612 11:05:14.295223  4990 net.cpp:190] Creating Layer ReLU39
I0612 11:05:14.295233  4990 net.cpp:615] ReLU39 <- Eltwise19
I0612 11:05:14.295241  4990 net.cpp:576] ReLU39 -> Eltwise19 (in-place)
I0612 11:05:14.295250  4990 net.cpp:240] Setting up ReLU39
I0612 11:05:14.295258  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.295261  4990 net.cpp:255] Memory required for data: 1758987776
I0612 11:05:14.295266  4990 layer_factory.hpp:77] Creating layer Eltwise19_ReLU39_0_split
I0612 11:05:14.295272  4990 net.cpp:190] Creating Layer Eltwise19_ReLU39_0_split
I0612 11:05:14.295276  4990 net.cpp:615] Eltwise19_ReLU39_0_split <- Eltwise19
I0612 11:05:14.295284  4990 net.cpp:589] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_0
I0612 11:05:14.295291  4990 net.cpp:589] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_1
I0612 11:05:14.295339  4990 net.cpp:240] Setting up Eltwise19_ReLU39_0_split
I0612 11:05:14.295348  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.295354  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.295358  4990 net.cpp:255] Memory required for data: 1767376384
I0612 11:05:14.295362  4990 layer_factory.hpp:77] Creating layer Convolution40
I0612 11:05:14.295377  4990 net.cpp:190] Creating Layer Convolution40
I0612 11:05:14.295382  4990 net.cpp:615] Convolution40 <- Eltwise19_ReLU39_0_split_0
I0612 11:05:14.295389  4990 net.cpp:589] Convolution40 -> Convolution40
I0612 11:05:14.296099  4990 net.cpp:240] Setting up Convolution40
I0612 11:05:14.296111  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.296116  4990 net.cpp:255] Memory required for data: 1771570688
I0612 11:05:14.296128  4990 layer_factory.hpp:77] Creating layer BatchNorm40
I0612 11:05:14.296138  4990 net.cpp:190] Creating Layer BatchNorm40
I0612 11:05:14.296144  4990 net.cpp:615] BatchNorm40 <- Convolution40
I0612 11:05:14.296156  4990 net.cpp:576] BatchNorm40 -> Convolution40 (in-place)
I0612 11:05:14.296403  4990 net.cpp:240] Setting up BatchNorm40
I0612 11:05:14.296412  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.296417  4990 net.cpp:255] Memory required for data: 1775764992
I0612 11:05:14.296430  4990 layer_factory.hpp:77] Creating layer Scale40
I0612 11:05:14.296442  4990 net.cpp:190] Creating Layer Scale40
I0612 11:05:14.296448  4990 net.cpp:615] Scale40 <- Convolution40
I0612 11:05:14.296455  4990 net.cpp:576] Scale40 -> Convolution40 (in-place)
I0612 11:05:14.296496  4990 layer_factory.hpp:77] Creating layer Scale40
I0612 11:05:14.296641  4990 net.cpp:240] Setting up Scale40
I0612 11:05:14.296650  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.296655  4990 net.cpp:255] Memory required for data: 1779959296
I0612 11:05:14.296665  4990 layer_factory.hpp:77] Creating layer ReLU40
I0612 11:05:14.296674  4990 net.cpp:190] Creating Layer ReLU40
I0612 11:05:14.296679  4990 net.cpp:615] ReLU40 <- Convolution40
I0612 11:05:14.296685  4990 net.cpp:576] ReLU40 -> Convolution40 (in-place)
I0612 11:05:14.296692  4990 net.cpp:240] Setting up ReLU40
I0612 11:05:14.296700  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.296703  4990 net.cpp:255] Memory required for data: 1784153600
I0612 11:05:14.296708  4990 layer_factory.hpp:77] Creating layer Convolution41
I0612 11:05:14.296723  4990 net.cpp:190] Creating Layer Convolution41
I0612 11:05:14.296728  4990 net.cpp:615] Convolution41 <- Convolution40
I0612 11:05:14.296736  4990 net.cpp:589] Convolution41 -> Convolution41
I0612 11:05:14.297438  4990 net.cpp:240] Setting up Convolution41
I0612 11:05:14.297449  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.297454  4990 net.cpp:255] Memory required for data: 1788347904
I0612 11:05:14.297466  4990 layer_factory.hpp:77] Creating layer BatchNorm41
I0612 11:05:14.297477  4990 net.cpp:190] Creating Layer BatchNorm41
I0612 11:05:14.297483  4990 net.cpp:615] BatchNorm41 <- Convolution41
I0612 11:05:14.297492  4990 net.cpp:576] BatchNorm41 -> Convolution41 (in-place)
I0612 11:05:14.297736  4990 net.cpp:240] Setting up BatchNorm41
I0612 11:05:14.297746  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.297755  4990 net.cpp:255] Memory required for data: 1792542208
I0612 11:05:14.297770  4990 layer_factory.hpp:77] Creating layer Scale41
I0612 11:05:14.297780  4990 net.cpp:190] Creating Layer Scale41
I0612 11:05:14.297785  4990 net.cpp:615] Scale41 <- Convolution41
I0612 11:05:14.297792  4990 net.cpp:576] Scale41 -> Convolution41 (in-place)
I0612 11:05:14.297838  4990 layer_factory.hpp:77] Creating layer Scale41
I0612 11:05:14.297991  4990 net.cpp:240] Setting up Scale41
I0612 11:05:14.298002  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.298005  4990 net.cpp:255] Memory required for data: 1796736512
I0612 11:05:14.298017  4990 layer_factory.hpp:77] Creating layer Eltwise20
I0612 11:05:14.298024  4990 net.cpp:190] Creating Layer Eltwise20
I0612 11:05:14.298030  4990 net.cpp:615] Eltwise20 <- Eltwise19_ReLU39_0_split_1
I0612 11:05:14.298040  4990 net.cpp:615] Eltwise20 <- Convolution41
I0612 11:05:14.298048  4990 net.cpp:589] Eltwise20 -> Eltwise20
I0612 11:05:14.298072  4990 net.cpp:240] Setting up Eltwise20
I0612 11:05:14.298084  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.298089  4990 net.cpp:255] Memory required for data: 1800930816
I0612 11:05:14.298092  4990 layer_factory.hpp:77] Creating layer ReLU41
I0612 11:05:14.298099  4990 net.cpp:190] Creating Layer ReLU41
I0612 11:05:14.298105  4990 net.cpp:615] ReLU41 <- Eltwise20
I0612 11:05:14.298110  4990 net.cpp:576] ReLU41 -> Eltwise20 (in-place)
I0612 11:05:14.298118  4990 net.cpp:240] Setting up ReLU41
I0612 11:05:14.298125  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.298128  4990 net.cpp:255] Memory required for data: 1805125120
I0612 11:05:14.298133  4990 layer_factory.hpp:77] Creating layer Eltwise20_ReLU41_0_split
I0612 11:05:14.298140  4990 net.cpp:190] Creating Layer Eltwise20_ReLU41_0_split
I0612 11:05:14.298144  4990 net.cpp:615] Eltwise20_ReLU41_0_split <- Eltwise20
I0612 11:05:14.298153  4990 net.cpp:589] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_0
I0612 11:05:14.298162  4990 net.cpp:589] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_1
I0612 11:05:14.298205  4990 net.cpp:240] Setting up Eltwise20_ReLU41_0_split
I0612 11:05:14.298213  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.298219  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.298223  4990 net.cpp:255] Memory required for data: 1813513728
I0612 11:05:14.298228  4990 layer_factory.hpp:77] Creating layer Convolution42
I0612 11:05:14.298243  4990 net.cpp:190] Creating Layer Convolution42
I0612 11:05:14.298248  4990 net.cpp:615] Convolution42 <- Eltwise20_ReLU41_0_split_0
I0612 11:05:14.298256  4990 net.cpp:589] Convolution42 -> Convolution42
I0612 11:05:14.298971  4990 net.cpp:240] Setting up Convolution42
I0612 11:05:14.298985  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.298988  4990 net.cpp:255] Memory required for data: 1817708032
I0612 11:05:14.299000  4990 layer_factory.hpp:77] Creating layer BatchNorm42
I0612 11:05:14.299011  4990 net.cpp:190] Creating Layer BatchNorm42
I0612 11:05:14.299016  4990 net.cpp:615] BatchNorm42 <- Convolution42
I0612 11:05:14.299023  4990 net.cpp:576] BatchNorm42 -> Convolution42 (in-place)
I0612 11:05:14.299268  4990 net.cpp:240] Setting up BatchNorm42
I0612 11:05:14.299278  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.299283  4990 net.cpp:255] Memory required for data: 1821902336
I0612 11:05:14.299299  4990 layer_factory.hpp:77] Creating layer Scale42
I0612 11:05:14.299306  4990 net.cpp:190] Creating Layer Scale42
I0612 11:05:14.299311  4990 net.cpp:615] Scale42 <- Convolution42
I0612 11:05:14.299319  4990 net.cpp:576] Scale42 -> Convolution42 (in-place)
I0612 11:05:14.299363  4990 layer_factory.hpp:77] Creating layer Scale42
I0612 11:05:14.299511  4990 net.cpp:240] Setting up Scale42
I0612 11:05:14.299520  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.299525  4990 net.cpp:255] Memory required for data: 1826096640
I0612 11:05:14.299538  4990 layer_factory.hpp:77] Creating layer ReLU42
I0612 11:05:14.299551  4990 net.cpp:190] Creating Layer ReLU42
I0612 11:05:14.299556  4990 net.cpp:615] ReLU42 <- Convolution42
I0612 11:05:14.299564  4990 net.cpp:576] ReLU42 -> Convolution42 (in-place)
I0612 11:05:14.299572  4990 net.cpp:240] Setting up ReLU42
I0612 11:05:14.299579  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.299583  4990 net.cpp:255] Memory required for data: 1830290944
I0612 11:05:14.299587  4990 layer_factory.hpp:77] Creating layer Convolution43
I0612 11:05:14.299598  4990 net.cpp:190] Creating Layer Convolution43
I0612 11:05:14.299603  4990 net.cpp:615] Convolution43 <- Convolution42
I0612 11:05:14.299613  4990 net.cpp:589] Convolution43 -> Convolution43
I0612 11:05:14.300318  4990 net.cpp:240] Setting up Convolution43
I0612 11:05:14.300330  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.300335  4990 net.cpp:255] Memory required for data: 1834485248
I0612 11:05:14.300346  4990 layer_factory.hpp:77] Creating layer BatchNorm43
I0612 11:05:14.300354  4990 net.cpp:190] Creating Layer BatchNorm43
I0612 11:05:14.300360  4990 net.cpp:615] BatchNorm43 <- Convolution43
I0612 11:05:14.300370  4990 net.cpp:576] BatchNorm43 -> Convolution43 (in-place)
I0612 11:05:14.300616  4990 net.cpp:240] Setting up BatchNorm43
I0612 11:05:14.300624  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.300629  4990 net.cpp:255] Memory required for data: 1838679552
I0612 11:05:14.300642  4990 layer_factory.hpp:77] Creating layer Scale43
I0612 11:05:14.300650  4990 net.cpp:190] Creating Layer Scale43
I0612 11:05:14.300654  4990 net.cpp:615] Scale43 <- Convolution43
I0612 11:05:14.300662  4990 net.cpp:576] Scale43 -> Convolution43 (in-place)
I0612 11:05:14.300707  4990 layer_factory.hpp:77] Creating layer Scale43
I0612 11:05:14.300856  4990 net.cpp:240] Setting up Scale43
I0612 11:05:14.300866  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.300870  4990 net.cpp:255] Memory required for data: 1842873856
I0612 11:05:14.300881  4990 layer_factory.hpp:77] Creating layer Eltwise21
I0612 11:05:14.300889  4990 net.cpp:190] Creating Layer Eltwise21
I0612 11:05:14.300894  4990 net.cpp:615] Eltwise21 <- Eltwise20_ReLU41_0_split_1
I0612 11:05:14.300904  4990 net.cpp:615] Eltwise21 <- Convolution43
I0612 11:05:14.300911  4990 net.cpp:589] Eltwise21 -> Eltwise21
I0612 11:05:14.300935  4990 net.cpp:240] Setting up Eltwise21
I0612 11:05:14.300943  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.300947  4990 net.cpp:255] Memory required for data: 1847068160
I0612 11:05:14.300952  4990 layer_factory.hpp:77] Creating layer ReLU43
I0612 11:05:14.300962  4990 net.cpp:190] Creating Layer ReLU43
I0612 11:05:14.300967  4990 net.cpp:615] ReLU43 <- Eltwise21
I0612 11:05:14.300973  4990 net.cpp:576] ReLU43 -> Eltwise21 (in-place)
I0612 11:05:14.300981  4990 net.cpp:240] Setting up ReLU43
I0612 11:05:14.300987  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.300992  4990 net.cpp:255] Memory required for data: 1851262464
I0612 11:05:14.300997  4990 layer_factory.hpp:77] Creating layer Eltwise21_ReLU43_0_split
I0612 11:05:14.301002  4990 net.cpp:190] Creating Layer Eltwise21_ReLU43_0_split
I0612 11:05:14.301007  4990 net.cpp:615] Eltwise21_ReLU43_0_split <- Eltwise21
I0612 11:05:14.301015  4990 net.cpp:589] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_0
I0612 11:05:14.301024  4990 net.cpp:589] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_1
I0612 11:05:14.301070  4990 net.cpp:240] Setting up Eltwise21_ReLU43_0_split
I0612 11:05:14.301079  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.301084  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.301090  4990 net.cpp:255] Memory required for data: 1859651072
I0612 11:05:14.301093  4990 layer_factory.hpp:77] Creating layer Convolution44
I0612 11:05:14.301105  4990 net.cpp:190] Creating Layer Convolution44
I0612 11:05:14.301110  4990 net.cpp:615] Convolution44 <- Eltwise21_ReLU43_0_split_0
I0612 11:05:14.301120  4990 net.cpp:589] Convolution44 -> Convolution44
I0612 11:05:14.301831  4990 net.cpp:240] Setting up Convolution44
I0612 11:05:14.301843  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.301847  4990 net.cpp:255] Memory required for data: 1863845376
I0612 11:05:14.301859  4990 layer_factory.hpp:77] Creating layer BatchNorm44
I0612 11:05:14.301870  4990 net.cpp:190] Creating Layer BatchNorm44
I0612 11:05:14.301875  4990 net.cpp:615] BatchNorm44 <- Convolution44
I0612 11:05:14.301882  4990 net.cpp:576] BatchNorm44 -> Convolution44 (in-place)
I0612 11:05:14.302134  4990 net.cpp:240] Setting up BatchNorm44
I0612 11:05:14.302145  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.302148  4990 net.cpp:255] Memory required for data: 1868039680
I0612 11:05:14.302162  4990 layer_factory.hpp:77] Creating layer Scale44
I0612 11:05:14.302170  4990 net.cpp:190] Creating Layer Scale44
I0612 11:05:14.302175  4990 net.cpp:615] Scale44 <- Convolution44
I0612 11:05:14.302186  4990 net.cpp:576] Scale44 -> Convolution44 (in-place)
I0612 11:05:14.302227  4990 layer_factory.hpp:77] Creating layer Scale44
I0612 11:05:14.302386  4990 net.cpp:240] Setting up Scale44
I0612 11:05:14.302398  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.302403  4990 net.cpp:255] Memory required for data: 1872233984
I0612 11:05:14.302414  4990 layer_factory.hpp:77] Creating layer ReLU44
I0612 11:05:14.302423  4990 net.cpp:190] Creating Layer ReLU44
I0612 11:05:14.302428  4990 net.cpp:615] ReLU44 <- Convolution44
I0612 11:05:14.302435  4990 net.cpp:576] ReLU44 -> Convolution44 (in-place)
I0612 11:05:14.302443  4990 net.cpp:240] Setting up ReLU44
I0612 11:05:14.302449  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.302453  4990 net.cpp:255] Memory required for data: 1876428288
I0612 11:05:14.302458  4990 layer_factory.hpp:77] Creating layer Convolution45
I0612 11:05:14.302472  4990 net.cpp:190] Creating Layer Convolution45
I0612 11:05:14.302477  4990 net.cpp:615] Convolution45 <- Convolution44
I0612 11:05:14.302487  4990 net.cpp:589] Convolution45 -> Convolution45
I0612 11:05:14.303205  4990 net.cpp:240] Setting up Convolution45
I0612 11:05:14.303216  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.303221  4990 net.cpp:255] Memory required for data: 1880622592
I0612 11:05:14.303232  4990 layer_factory.hpp:77] Creating layer BatchNorm45
I0612 11:05:14.303244  4990 net.cpp:190] Creating Layer BatchNorm45
I0612 11:05:14.303251  4990 net.cpp:615] BatchNorm45 <- Convolution45
I0612 11:05:14.303259  4990 net.cpp:576] BatchNorm45 -> Convolution45 (in-place)
I0612 11:05:14.303499  4990 net.cpp:240] Setting up BatchNorm45
I0612 11:05:14.303508  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.303514  4990 net.cpp:255] Memory required for data: 1884816896
I0612 11:05:14.303526  4990 layer_factory.hpp:77] Creating layer Scale45
I0612 11:05:14.303539  4990 net.cpp:190] Creating Layer Scale45
I0612 11:05:14.303544  4990 net.cpp:615] Scale45 <- Convolution45
I0612 11:05:14.303551  4990 net.cpp:576] Scale45 -> Convolution45 (in-place)
I0612 11:05:14.303592  4990 layer_factory.hpp:77] Creating layer Scale45
I0612 11:05:14.303743  4990 net.cpp:240] Setting up Scale45
I0612 11:05:14.303752  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.303757  4990 net.cpp:255] Memory required for data: 1889011200
I0612 11:05:14.303767  4990 layer_factory.hpp:77] Creating layer Eltwise22
I0612 11:05:14.303776  4990 net.cpp:190] Creating Layer Eltwise22
I0612 11:05:14.303781  4990 net.cpp:615] Eltwise22 <- Eltwise21_ReLU43_0_split_1
I0612 11:05:14.303787  4990 net.cpp:615] Eltwise22 <- Convolution45
I0612 11:05:14.303797  4990 net.cpp:589] Eltwise22 -> Eltwise22
I0612 11:05:14.303822  4990 net.cpp:240] Setting up Eltwise22
I0612 11:05:14.303830  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.303834  4990 net.cpp:255] Memory required for data: 1893205504
I0612 11:05:14.303839  4990 layer_factory.hpp:77] Creating layer ReLU45
I0612 11:05:14.303848  4990 net.cpp:190] Creating Layer ReLU45
I0612 11:05:14.303861  4990 net.cpp:615] ReLU45 <- Eltwise22
I0612 11:05:14.303867  4990 net.cpp:576] ReLU45 -> Eltwise22 (in-place)
I0612 11:05:14.303875  4990 net.cpp:240] Setting up ReLU45
I0612 11:05:14.303881  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.303886  4990 net.cpp:255] Memory required for data: 1897399808
I0612 11:05:14.303890  4990 layer_factory.hpp:77] Creating layer Eltwise22_ReLU45_0_split
I0612 11:05:14.303897  4990 net.cpp:190] Creating Layer Eltwise22_ReLU45_0_split
I0612 11:05:14.303901  4990 net.cpp:615] Eltwise22_ReLU45_0_split <- Eltwise22
I0612 11:05:14.303907  4990 net.cpp:589] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_0
I0612 11:05:14.303920  4990 net.cpp:589] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_1
I0612 11:05:14.303963  4990 net.cpp:240] Setting up Eltwise22_ReLU45_0_split
I0612 11:05:14.303972  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.303977  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.303982  4990 net.cpp:255] Memory required for data: 1905788416
I0612 11:05:14.303985  4990 layer_factory.hpp:77] Creating layer Convolution46
I0612 11:05:14.303999  4990 net.cpp:190] Creating Layer Convolution46
I0612 11:05:14.304005  4990 net.cpp:615] Convolution46 <- Eltwise22_ReLU45_0_split_0
I0612 11:05:14.304013  4990 net.cpp:589] Convolution46 -> Convolution46
I0612 11:05:14.304723  4990 net.cpp:240] Setting up Convolution46
I0612 11:05:14.304734  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.304739  4990 net.cpp:255] Memory required for data: 1909982720
I0612 11:05:14.304750  4990 layer_factory.hpp:77] Creating layer BatchNorm46
I0612 11:05:14.304761  4990 net.cpp:190] Creating Layer BatchNorm46
I0612 11:05:14.304767  4990 net.cpp:615] BatchNorm46 <- Convolution46
I0612 11:05:14.304774  4990 net.cpp:576] BatchNorm46 -> Convolution46 (in-place)
I0612 11:05:14.305038  4990 net.cpp:240] Setting up BatchNorm46
I0612 11:05:14.305047  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.305052  4990 net.cpp:255] Memory required for data: 1914177024
I0612 11:05:14.305065  4990 layer_factory.hpp:77] Creating layer Scale46
I0612 11:05:14.305076  4990 net.cpp:190] Creating Layer Scale46
I0612 11:05:14.305081  4990 net.cpp:615] Scale46 <- Convolution46
I0612 11:05:14.305088  4990 net.cpp:576] Scale46 -> Convolution46 (in-place)
I0612 11:05:14.305133  4990 layer_factory.hpp:77] Creating layer Scale46
I0612 11:05:14.305279  4990 net.cpp:240] Setting up Scale46
I0612 11:05:14.305289  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.305294  4990 net.cpp:255] Memory required for data: 1918371328
I0612 11:05:14.305304  4990 layer_factory.hpp:77] Creating layer ReLU46
I0612 11:05:14.305313  4990 net.cpp:190] Creating Layer ReLU46
I0612 11:05:14.305320  4990 net.cpp:615] ReLU46 <- Convolution46
I0612 11:05:14.305326  4990 net.cpp:576] ReLU46 -> Convolution46 (in-place)
I0612 11:05:14.305335  4990 net.cpp:240] Setting up ReLU46
I0612 11:05:14.305341  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.305344  4990 net.cpp:255] Memory required for data: 1922565632
I0612 11:05:14.305348  4990 layer_factory.hpp:77] Creating layer Convolution47
I0612 11:05:14.305363  4990 net.cpp:190] Creating Layer Convolution47
I0612 11:05:14.305369  4990 net.cpp:615] Convolution47 <- Convolution46
I0612 11:05:14.305377  4990 net.cpp:589] Convolution47 -> Convolution47
I0612 11:05:14.306077  4990 net.cpp:240] Setting up Convolution47
I0612 11:05:14.306088  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.306093  4990 net.cpp:255] Memory required for data: 1926759936
I0612 11:05:14.306104  4990 layer_factory.hpp:77] Creating layer BatchNorm47
I0612 11:05:14.306115  4990 net.cpp:190] Creating Layer BatchNorm47
I0612 11:05:14.306120  4990 net.cpp:615] BatchNorm47 <- Convolution47
I0612 11:05:14.306128  4990 net.cpp:576] BatchNorm47 -> Convolution47 (in-place)
I0612 11:05:14.306386  4990 net.cpp:240] Setting up BatchNorm47
I0612 11:05:14.306401  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.306404  4990 net.cpp:255] Memory required for data: 1930954240
I0612 11:05:14.306421  4990 layer_factory.hpp:77] Creating layer Scale47
I0612 11:05:14.306429  4990 net.cpp:190] Creating Layer Scale47
I0612 11:05:14.306434  4990 net.cpp:615] Scale47 <- Convolution47
I0612 11:05:14.306442  4990 net.cpp:576] Scale47 -> Convolution47 (in-place)
I0612 11:05:14.306488  4990 layer_factory.hpp:77] Creating layer Scale47
I0612 11:05:14.306645  4990 net.cpp:240] Setting up Scale47
I0612 11:05:14.306654  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.306658  4990 net.cpp:255] Memory required for data: 1935148544
I0612 11:05:14.306671  4990 layer_factory.hpp:77] Creating layer Eltwise23
I0612 11:05:14.306679  4990 net.cpp:190] Creating Layer Eltwise23
I0612 11:05:14.306684  4990 net.cpp:615] Eltwise23 <- Eltwise22_ReLU45_0_split_1
I0612 11:05:14.306691  4990 net.cpp:615] Eltwise23 <- Convolution47
I0612 11:05:14.306700  4990 net.cpp:589] Eltwise23 -> Eltwise23
I0612 11:05:14.306723  4990 net.cpp:240] Setting up Eltwise23
I0612 11:05:14.306731  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.306735  4990 net.cpp:255] Memory required for data: 1939342848
I0612 11:05:14.306740  4990 layer_factory.hpp:77] Creating layer ReLU47
I0612 11:05:14.306746  4990 net.cpp:190] Creating Layer ReLU47
I0612 11:05:14.306751  4990 net.cpp:615] ReLU47 <- Eltwise23
I0612 11:05:14.306759  4990 net.cpp:576] ReLU47 -> Eltwise23 (in-place)
I0612 11:05:14.306766  4990 net.cpp:240] Setting up ReLU47
I0612 11:05:14.306772  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.306777  4990 net.cpp:255] Memory required for data: 1943537152
I0612 11:05:14.306780  4990 layer_factory.hpp:77] Creating layer Eltwise23_ReLU47_0_split
I0612 11:05:14.306787  4990 net.cpp:190] Creating Layer Eltwise23_ReLU47_0_split
I0612 11:05:14.306792  4990 net.cpp:615] Eltwise23_ReLU47_0_split <- Eltwise23
I0612 11:05:14.306797  4990 net.cpp:589] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_0
I0612 11:05:14.306804  4990 net.cpp:589] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_1
I0612 11:05:14.306849  4990 net.cpp:240] Setting up Eltwise23_ReLU47_0_split
I0612 11:05:14.306857  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.306862  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.306866  4990 net.cpp:255] Memory required for data: 1951925760
I0612 11:05:14.306870  4990 layer_factory.hpp:77] Creating layer Convolution48
I0612 11:05:14.306881  4990 net.cpp:190] Creating Layer Convolution48
I0612 11:05:14.306885  4990 net.cpp:615] Convolution48 <- Eltwise23_ReLU47_0_split_0
I0612 11:05:14.306896  4990 net.cpp:589] Convolution48 -> Convolution48
I0612 11:05:14.307574  4990 net.cpp:240] Setting up Convolution48
I0612 11:05:14.307585  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.307590  4990 net.cpp:255] Memory required for data: 1956120064
I0612 11:05:14.307600  4990 layer_factory.hpp:77] Creating layer BatchNorm48
I0612 11:05:14.307608  4990 net.cpp:190] Creating Layer BatchNorm48
I0612 11:05:14.307613  4990 net.cpp:615] BatchNorm48 <- Convolution48
I0612 11:05:14.307624  4990 net.cpp:576] BatchNorm48 -> Convolution48 (in-place)
I0612 11:05:14.307860  4990 net.cpp:240] Setting up BatchNorm48
I0612 11:05:14.307868  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.307873  4990 net.cpp:255] Memory required for data: 1960314368
I0612 11:05:14.307886  4990 layer_factory.hpp:77] Creating layer Scale48
I0612 11:05:14.307894  4990 net.cpp:190] Creating Layer Scale48
I0612 11:05:14.307898  4990 net.cpp:615] Scale48 <- Convolution48
I0612 11:05:14.307905  4990 net.cpp:576] Scale48 -> Convolution48 (in-place)
I0612 11:05:14.307948  4990 layer_factory.hpp:77] Creating layer Scale48
I0612 11:05:14.308090  4990 net.cpp:240] Setting up Scale48
I0612 11:05:14.308099  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.308104  4990 net.cpp:255] Memory required for data: 1964508672
I0612 11:05:14.308117  4990 layer_factory.hpp:77] Creating layer ReLU48
I0612 11:05:14.308128  4990 net.cpp:190] Creating Layer ReLU48
I0612 11:05:14.308135  4990 net.cpp:615] ReLU48 <- Convolution48
I0612 11:05:14.308140  4990 net.cpp:576] ReLU48 -> Convolution48 (in-place)
I0612 11:05:14.308147  4990 net.cpp:240] Setting up ReLU48
I0612 11:05:14.308154  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.308158  4990 net.cpp:255] Memory required for data: 1968702976
I0612 11:05:14.308162  4990 layer_factory.hpp:77] Creating layer Convolution49
I0612 11:05:14.308174  4990 net.cpp:190] Creating Layer Convolution49
I0612 11:05:14.308179  4990 net.cpp:615] Convolution49 <- Convolution48
I0612 11:05:14.308187  4990 net.cpp:589] Convolution49 -> Convolution49
I0612 11:05:14.308862  4990 net.cpp:240] Setting up Convolution49
I0612 11:05:14.308873  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.308877  4990 net.cpp:255] Memory required for data: 1972897280
I0612 11:05:14.308888  4990 layer_factory.hpp:77] Creating layer BatchNorm49
I0612 11:05:14.308899  4990 net.cpp:190] Creating Layer BatchNorm49
I0612 11:05:14.308904  4990 net.cpp:615] BatchNorm49 <- Convolution49
I0612 11:05:14.308910  4990 net.cpp:576] BatchNorm49 -> Convolution49 (in-place)
I0612 11:05:14.309144  4990 net.cpp:240] Setting up BatchNorm49
I0612 11:05:14.309152  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.309157  4990 net.cpp:255] Memory required for data: 1977091584
I0612 11:05:14.309170  4990 layer_factory.hpp:77] Creating layer Scale49
I0612 11:05:14.309176  4990 net.cpp:190] Creating Layer Scale49
I0612 11:05:14.309181  4990 net.cpp:615] Scale49 <- Convolution49
I0612 11:05:14.309190  4990 net.cpp:576] Scale49 -> Convolution49 (in-place)
I0612 11:05:14.309231  4990 layer_factory.hpp:77] Creating layer Scale49
I0612 11:05:14.309371  4990 net.cpp:240] Setting up Scale49
I0612 11:05:14.309382  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.309386  4990 net.cpp:255] Memory required for data: 1981285888
I0612 11:05:14.309397  4990 layer_factory.hpp:77] Creating layer Eltwise24
I0612 11:05:14.309404  4990 net.cpp:190] Creating Layer Eltwise24
I0612 11:05:14.309411  4990 net.cpp:615] Eltwise24 <- Eltwise23_ReLU47_0_split_1
I0612 11:05:14.309417  4990 net.cpp:615] Eltwise24 <- Convolution49
I0612 11:05:14.309423  4990 net.cpp:589] Eltwise24 -> Eltwise24
I0612 11:05:14.309453  4990 net.cpp:240] Setting up Eltwise24
I0612 11:05:14.309460  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.309464  4990 net.cpp:255] Memory required for data: 1985480192
I0612 11:05:14.309468  4990 layer_factory.hpp:77] Creating layer ReLU49
I0612 11:05:14.309475  4990 net.cpp:190] Creating Layer ReLU49
I0612 11:05:14.309480  4990 net.cpp:615] ReLU49 <- Eltwise24
I0612 11:05:14.309489  4990 net.cpp:576] ReLU49 -> Eltwise24 (in-place)
I0612 11:05:14.309496  4990 net.cpp:240] Setting up ReLU49
I0612 11:05:14.309502  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.309506  4990 net.cpp:255] Memory required for data: 1989674496
I0612 11:05:14.309510  4990 layer_factory.hpp:77] Creating layer Eltwise24_ReLU49_0_split
I0612 11:05:14.309516  4990 net.cpp:190] Creating Layer Eltwise24_ReLU49_0_split
I0612 11:05:14.309520  4990 net.cpp:615] Eltwise24_ReLU49_0_split <- Eltwise24
I0612 11:05:14.309526  4990 net.cpp:589] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_0
I0612 11:05:14.309547  4990 net.cpp:589] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_1
I0612 11:05:14.309597  4990 net.cpp:240] Setting up Eltwise24_ReLU49_0_split
I0612 11:05:14.309605  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.309612  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.309615  4990 net.cpp:255] Memory required for data: 1998063104
I0612 11:05:14.309619  4990 layer_factory.hpp:77] Creating layer Convolution50
I0612 11:05:14.309633  4990 net.cpp:190] Creating Layer Convolution50
I0612 11:05:14.309638  4990 net.cpp:615] Convolution50 <- Eltwise24_ReLU49_0_split_0
I0612 11:05:14.309651  4990 net.cpp:589] Convolution50 -> Convolution50
I0612 11:05:14.310333  4990 net.cpp:240] Setting up Convolution50
I0612 11:05:14.310343  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.310348  4990 net.cpp:255] Memory required for data: 2002257408
I0612 11:05:14.310365  4990 layer_factory.hpp:77] Creating layer BatchNorm50
I0612 11:05:14.310377  4990 net.cpp:190] Creating Layer BatchNorm50
I0612 11:05:14.310384  4990 net.cpp:615] BatchNorm50 <- Convolution50
I0612 11:05:14.310391  4990 net.cpp:576] BatchNorm50 -> Convolution50 (in-place)
I0612 11:05:14.310631  4990 net.cpp:240] Setting up BatchNorm50
I0612 11:05:14.310641  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.310645  4990 net.cpp:255] Memory required for data: 2006451712
I0612 11:05:14.310657  4990 layer_factory.hpp:77] Creating layer Scale50
I0612 11:05:14.310668  4990 net.cpp:190] Creating Layer Scale50
I0612 11:05:14.310673  4990 net.cpp:615] Scale50 <- Convolution50
I0612 11:05:14.310680  4990 net.cpp:576] Scale50 -> Convolution50 (in-place)
I0612 11:05:14.310719  4990 layer_factory.hpp:77] Creating layer Scale50
I0612 11:05:14.310864  4990 net.cpp:240] Setting up Scale50
I0612 11:05:14.310873  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.310878  4990 net.cpp:255] Memory required for data: 2010646016
I0612 11:05:14.310888  4990 layer_factory.hpp:77] Creating layer ReLU50
I0612 11:05:14.310894  4990 net.cpp:190] Creating Layer ReLU50
I0612 11:05:14.310899  4990 net.cpp:615] ReLU50 <- Convolution50
I0612 11:05:14.310909  4990 net.cpp:576] ReLU50 -> Convolution50 (in-place)
I0612 11:05:14.310916  4990 net.cpp:240] Setting up ReLU50
I0612 11:05:14.310922  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.310926  4990 net.cpp:255] Memory required for data: 2014840320
I0612 11:05:14.310930  4990 layer_factory.hpp:77] Creating layer Convolution51
I0612 11:05:14.310942  4990 net.cpp:190] Creating Layer Convolution51
I0612 11:05:14.310947  4990 net.cpp:615] Convolution51 <- Convolution50
I0612 11:05:14.310956  4990 net.cpp:589] Convolution51 -> Convolution51
I0612 11:05:14.311637  4990 net.cpp:240] Setting up Convolution51
I0612 11:05:14.311650  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.311655  4990 net.cpp:255] Memory required for data: 2019034624
I0612 11:05:14.311664  4990 layer_factory.hpp:77] Creating layer BatchNorm51
I0612 11:05:14.311676  4990 net.cpp:190] Creating Layer BatchNorm51
I0612 11:05:14.311682  4990 net.cpp:615] BatchNorm51 <- Convolution51
I0612 11:05:14.311689  4990 net.cpp:576] BatchNorm51 -> Convolution51 (in-place)
I0612 11:05:14.311933  4990 net.cpp:240] Setting up BatchNorm51
I0612 11:05:14.311942  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.311946  4990 net.cpp:255] Memory required for data: 2023228928
I0612 11:05:14.311959  4990 layer_factory.hpp:77] Creating layer Scale51
I0612 11:05:14.311992  4990 net.cpp:190] Creating Layer Scale51
I0612 11:05:14.311998  4990 net.cpp:615] Scale51 <- Convolution51
I0612 11:05:14.312006  4990 net.cpp:576] Scale51 -> Convolution51 (in-place)
I0612 11:05:14.312054  4990 layer_factory.hpp:77] Creating layer Scale51
I0612 11:05:14.312197  4990 net.cpp:240] Setting up Scale51
I0612 11:05:14.312206  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.312211  4990 net.cpp:255] Memory required for data: 2027423232
I0612 11:05:14.312222  4990 layer_factory.hpp:77] Creating layer Eltwise25
I0612 11:05:14.312229  4990 net.cpp:190] Creating Layer Eltwise25
I0612 11:05:14.312234  4990 net.cpp:615] Eltwise25 <- Eltwise24_ReLU49_0_split_1
I0612 11:05:14.312240  4990 net.cpp:615] Eltwise25 <- Convolution51
I0612 11:05:14.312247  4990 net.cpp:589] Eltwise25 -> Eltwise25
I0612 11:05:14.312269  4990 net.cpp:240] Setting up Eltwise25
I0612 11:05:14.312278  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.312281  4990 net.cpp:255] Memory required for data: 2031617536
I0612 11:05:14.312285  4990 layer_factory.hpp:77] Creating layer ReLU51
I0612 11:05:14.312300  4990 net.cpp:190] Creating Layer ReLU51
I0612 11:05:14.312305  4990 net.cpp:615] ReLU51 <- Eltwise25
I0612 11:05:14.312312  4990 net.cpp:576] ReLU51 -> Eltwise25 (in-place)
I0612 11:05:14.312319  4990 net.cpp:240] Setting up ReLU51
I0612 11:05:14.312325  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.312330  4990 net.cpp:255] Memory required for data: 2035811840
I0612 11:05:14.312335  4990 layer_factory.hpp:77] Creating layer Eltwise25_ReLU51_0_split
I0612 11:05:14.312342  4990 net.cpp:190] Creating Layer Eltwise25_ReLU51_0_split
I0612 11:05:14.312347  4990 net.cpp:615] Eltwise25_ReLU51_0_split <- Eltwise25
I0612 11:05:14.312353  4990 net.cpp:589] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_0
I0612 11:05:14.312361  4990 net.cpp:589] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_1
I0612 11:05:14.312409  4990 net.cpp:240] Setting up Eltwise25_ReLU51_0_split
I0612 11:05:14.312417  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.312423  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.312427  4990 net.cpp:255] Memory required for data: 2044200448
I0612 11:05:14.312432  4990 layer_factory.hpp:77] Creating layer Convolution52
I0612 11:05:14.312444  4990 net.cpp:190] Creating Layer Convolution52
I0612 11:05:14.312449  4990 net.cpp:615] Convolution52 <- Eltwise25_ReLU51_0_split_0
I0612 11:05:14.312458  4990 net.cpp:589] Convolution52 -> Convolution52
I0612 11:05:14.313129  4990 net.cpp:240] Setting up Convolution52
I0612 11:05:14.313140  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.313145  4990 net.cpp:255] Memory required for data: 2048394752
I0612 11:05:14.313156  4990 layer_factory.hpp:77] Creating layer BatchNorm52
I0612 11:05:14.313166  4990 net.cpp:190] Creating Layer BatchNorm52
I0612 11:05:14.313172  4990 net.cpp:615] BatchNorm52 <- Convolution52
I0612 11:05:14.313180  4990 net.cpp:576] BatchNorm52 -> Convolution52 (in-place)
I0612 11:05:14.313416  4990 net.cpp:240] Setting up BatchNorm52
I0612 11:05:14.313424  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.313429  4990 net.cpp:255] Memory required for data: 2052589056
I0612 11:05:14.313441  4990 layer_factory.hpp:77] Creating layer Scale52
I0612 11:05:14.313452  4990 net.cpp:190] Creating Layer Scale52
I0612 11:05:14.313458  4990 net.cpp:615] Scale52 <- Convolution52
I0612 11:05:14.313464  4990 net.cpp:576] Scale52 -> Convolution52 (in-place)
I0612 11:05:14.313504  4990 layer_factory.hpp:77] Creating layer Scale52
I0612 11:05:14.313648  4990 net.cpp:240] Setting up Scale52
I0612 11:05:14.313657  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.313662  4990 net.cpp:255] Memory required for data: 2056783360
I0612 11:05:14.313671  4990 layer_factory.hpp:77] Creating layer ReLU52
I0612 11:05:14.313678  4990 net.cpp:190] Creating Layer ReLU52
I0612 11:05:14.313684  4990 net.cpp:615] ReLU52 <- Convolution52
I0612 11:05:14.313690  4990 net.cpp:576] ReLU52 -> Convolution52 (in-place)
I0612 11:05:14.313697  4990 net.cpp:240] Setting up ReLU52
I0612 11:05:14.313704  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.313707  4990 net.cpp:255] Memory required for data: 2060977664
I0612 11:05:14.313711  4990 layer_factory.hpp:77] Creating layer Convolution53
I0612 11:05:14.313726  4990 net.cpp:190] Creating Layer Convolution53
I0612 11:05:14.313731  4990 net.cpp:615] Convolution53 <- Convolution52
I0612 11:05:14.313740  4990 net.cpp:589] Convolution53 -> Convolution53
I0612 11:05:14.314420  4990 net.cpp:240] Setting up Convolution53
I0612 11:05:14.314431  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.314435  4990 net.cpp:255] Memory required for data: 2065171968
I0612 11:05:14.314446  4990 layer_factory.hpp:77] Creating layer BatchNorm53
I0612 11:05:14.314457  4990 net.cpp:190] Creating Layer BatchNorm53
I0612 11:05:14.314462  4990 net.cpp:615] BatchNorm53 <- Convolution53
I0612 11:05:14.314472  4990 net.cpp:576] BatchNorm53 -> Convolution53 (in-place)
I0612 11:05:14.314707  4990 net.cpp:240] Setting up BatchNorm53
I0612 11:05:14.314715  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.314720  4990 net.cpp:255] Memory required for data: 2069366272
I0612 11:05:14.314733  4990 layer_factory.hpp:77] Creating layer Scale53
I0612 11:05:14.314743  4990 net.cpp:190] Creating Layer Scale53
I0612 11:05:14.314748  4990 net.cpp:615] Scale53 <- Convolution53
I0612 11:05:14.314754  4990 net.cpp:576] Scale53 -> Convolution53 (in-place)
I0612 11:05:14.314796  4990 layer_factory.hpp:77] Creating layer Scale53
I0612 11:05:14.314939  4990 net.cpp:240] Setting up Scale53
I0612 11:05:14.314947  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.314951  4990 net.cpp:255] Memory required for data: 2073560576
I0612 11:05:14.314961  4990 layer_factory.hpp:77] Creating layer Eltwise26
I0612 11:05:14.314970  4990 net.cpp:190] Creating Layer Eltwise26
I0612 11:05:14.314975  4990 net.cpp:615] Eltwise26 <- Eltwise25_ReLU51_0_split_1
I0612 11:05:14.314983  4990 net.cpp:615] Eltwise26 <- Convolution53
I0612 11:05:14.314990  4990 net.cpp:589] Eltwise26 -> Eltwise26
I0612 11:05:14.315013  4990 net.cpp:240] Setting up Eltwise26
I0612 11:05:14.315023  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.315028  4990 net.cpp:255] Memory required for data: 2077754880
I0612 11:05:14.315032  4990 layer_factory.hpp:77] Creating layer ReLU53
I0612 11:05:14.315038  4990 net.cpp:190] Creating Layer ReLU53
I0612 11:05:14.315043  4990 net.cpp:615] ReLU53 <- Eltwise26
I0612 11:05:14.315049  4990 net.cpp:576] ReLU53 -> Eltwise26 (in-place)
I0612 11:05:14.315057  4990 net.cpp:240] Setting up ReLU53
I0612 11:05:14.315062  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.315067  4990 net.cpp:255] Memory required for data: 2081949184
I0612 11:05:14.315070  4990 layer_factory.hpp:77] Creating layer Eltwise26_ReLU53_0_split
I0612 11:05:14.315076  4990 net.cpp:190] Creating Layer Eltwise26_ReLU53_0_split
I0612 11:05:14.315080  4990 net.cpp:615] Eltwise26_ReLU53_0_split <- Eltwise26
I0612 11:05:14.315089  4990 net.cpp:589] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_0
I0612 11:05:14.315098  4990 net.cpp:589] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_1
I0612 11:05:14.315138  4990 net.cpp:240] Setting up Eltwise26_ReLU53_0_split
I0612 11:05:14.315146  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.315151  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.315155  4990 net.cpp:255] Memory required for data: 2090337792
I0612 11:05:14.315160  4990 layer_factory.hpp:77] Creating layer Convolution54
I0612 11:05:14.315172  4990 net.cpp:190] Creating Layer Convolution54
I0612 11:05:14.315177  4990 net.cpp:615] Convolution54 <- Eltwise26_ReLU53_0_split_0
I0612 11:05:14.315186  4990 net.cpp:589] Convolution54 -> Convolution54
I0612 11:05:14.315856  4990 net.cpp:240] Setting up Convolution54
I0612 11:05:14.315867  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.315871  4990 net.cpp:255] Memory required for data: 2094532096
I0612 11:05:14.315882  4990 layer_factory.hpp:77] Creating layer BatchNorm54
I0612 11:05:14.315891  4990 net.cpp:190] Creating Layer BatchNorm54
I0612 11:05:14.315896  4990 net.cpp:615] BatchNorm54 <- Convolution54
I0612 11:05:14.315903  4990 net.cpp:576] BatchNorm54 -> Convolution54 (in-place)
I0612 11:05:14.316141  4990 net.cpp:240] Setting up BatchNorm54
I0612 11:05:14.316150  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.316154  4990 net.cpp:255] Memory required for data: 2098726400
I0612 11:05:14.316169  4990 layer_factory.hpp:77] Creating layer Scale54
I0612 11:05:14.316176  4990 net.cpp:190] Creating Layer Scale54
I0612 11:05:14.316181  4990 net.cpp:615] Scale54 <- Convolution54
I0612 11:05:14.316187  4990 net.cpp:576] Scale54 -> Convolution54 (in-place)
I0612 11:05:14.316231  4990 layer_factory.hpp:77] Creating layer Scale54
I0612 11:05:14.316371  4990 net.cpp:240] Setting up Scale54
I0612 11:05:14.316380  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.316388  4990 net.cpp:255] Memory required for data: 2102920704
I0612 11:05:14.316401  4990 layer_factory.hpp:77] Creating layer ReLU54
I0612 11:05:14.316409  4990 net.cpp:190] Creating Layer ReLU54
I0612 11:05:14.316414  4990 net.cpp:615] ReLU54 <- Convolution54
I0612 11:05:14.316423  4990 net.cpp:576] ReLU54 -> Convolution54 (in-place)
I0612 11:05:14.316431  4990 net.cpp:240] Setting up ReLU54
I0612 11:05:14.316437  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.316442  4990 net.cpp:255] Memory required for data: 2107115008
I0612 11:05:14.316445  4990 layer_factory.hpp:77] Creating layer Convolution55
I0612 11:05:14.316455  4990 net.cpp:190] Creating Layer Convolution55
I0612 11:05:14.316459  4990 net.cpp:615] Convolution55 <- Convolution54
I0612 11:05:14.316469  4990 net.cpp:589] Convolution55 -> Convolution55
I0612 11:05:14.317155  4990 net.cpp:240] Setting up Convolution55
I0612 11:05:14.317167  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.317172  4990 net.cpp:255] Memory required for data: 2111309312
I0612 11:05:14.317181  4990 layer_factory.hpp:77] Creating layer BatchNorm55
I0612 11:05:14.317188  4990 net.cpp:190] Creating Layer BatchNorm55
I0612 11:05:14.317193  4990 net.cpp:615] BatchNorm55 <- Convolution55
I0612 11:05:14.317203  4990 net.cpp:576] BatchNorm55 -> Convolution55 (in-place)
I0612 11:05:14.317433  4990 net.cpp:240] Setting up BatchNorm55
I0612 11:05:14.317442  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.317447  4990 net.cpp:255] Memory required for data: 2115503616
I0612 11:05:14.317459  4990 layer_factory.hpp:77] Creating layer Scale55
I0612 11:05:14.317466  4990 net.cpp:190] Creating Layer Scale55
I0612 11:05:14.317471  4990 net.cpp:615] Scale55 <- Convolution55
I0612 11:05:14.317478  4990 net.cpp:576] Scale55 -> Convolution55 (in-place)
I0612 11:05:14.317519  4990 layer_factory.hpp:77] Creating layer Scale55
I0612 11:05:14.317664  4990 net.cpp:240] Setting up Scale55
I0612 11:05:14.317673  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.317677  4990 net.cpp:255] Memory required for data: 2119697920
I0612 11:05:14.317687  4990 layer_factory.hpp:77] Creating layer Eltwise27
I0612 11:05:14.317694  4990 net.cpp:190] Creating Layer Eltwise27
I0612 11:05:14.317703  4990 net.cpp:615] Eltwise27 <- Eltwise26_ReLU53_0_split_1
I0612 11:05:14.317709  4990 net.cpp:615] Eltwise27 <- Convolution55
I0612 11:05:14.317715  4990 net.cpp:589] Eltwise27 -> Eltwise27
I0612 11:05:14.317737  4990 net.cpp:240] Setting up Eltwise27
I0612 11:05:14.317744  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.317749  4990 net.cpp:255] Memory required for data: 2123892224
I0612 11:05:14.317752  4990 layer_factory.hpp:77] Creating layer ReLU55
I0612 11:05:14.317762  4990 net.cpp:190] Creating Layer ReLU55
I0612 11:05:14.317767  4990 net.cpp:615] ReLU55 <- Eltwise27
I0612 11:05:14.317773  4990 net.cpp:576] ReLU55 -> Eltwise27 (in-place)
I0612 11:05:14.317780  4990 net.cpp:240] Setting up ReLU55
I0612 11:05:14.317786  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.317790  4990 net.cpp:255] Memory required for data: 2128086528
I0612 11:05:14.317795  4990 layer_factory.hpp:77] Creating layer Eltwise27_ReLU55_0_split
I0612 11:05:14.317800  4990 net.cpp:190] Creating Layer Eltwise27_ReLU55_0_split
I0612 11:05:14.317805  4990 net.cpp:615] Eltwise27_ReLU55_0_split <- Eltwise27
I0612 11:05:14.317812  4990 net.cpp:589] Eltwise27_ReLU55_0_split -> Eltwise27_ReLU55_0_split_0
I0612 11:05:14.317821  4990 net.cpp:589] Eltwise27_ReLU55_0_split -> Eltwise27_ReLU55_0_split_1
I0612 11:05:14.317864  4990 net.cpp:240] Setting up Eltwise27_ReLU55_0_split
I0612 11:05:14.317873  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.317878  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.317883  4990 net.cpp:255] Memory required for data: 2136475136
I0612 11:05:14.317886  4990 layer_factory.hpp:77] Creating layer Convolution56
I0612 11:05:14.317898  4990 net.cpp:190] Creating Layer Convolution56
I0612 11:05:14.317908  4990 net.cpp:615] Convolution56 <- Eltwise27_ReLU55_0_split_0
I0612 11:05:14.317915  4990 net.cpp:589] Convolution56 -> Convolution56
I0612 11:05:14.318601  4990 net.cpp:240] Setting up Convolution56
I0612 11:05:14.318613  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.318617  4990 net.cpp:255] Memory required for data: 2140669440
I0612 11:05:14.318627  4990 layer_factory.hpp:77] Creating layer BatchNorm56
I0612 11:05:14.318637  4990 net.cpp:190] Creating Layer BatchNorm56
I0612 11:05:14.318644  4990 net.cpp:615] BatchNorm56 <- Convolution56
I0612 11:05:14.318650  4990 net.cpp:576] BatchNorm56 -> Convolution56 (in-place)
I0612 11:05:14.318873  4990 net.cpp:240] Setting up BatchNorm56
I0612 11:05:14.318881  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.318886  4990 net.cpp:255] Memory required for data: 2144863744
I0612 11:05:14.318898  4990 layer_factory.hpp:77] Creating layer Scale56
I0612 11:05:14.318905  4990 net.cpp:190] Creating Layer Scale56
I0612 11:05:14.318910  4990 net.cpp:615] Scale56 <- Convolution56
I0612 11:05:14.318919  4990 net.cpp:576] Scale56 -> Convolution56 (in-place)
I0612 11:05:14.318958  4990 layer_factory.hpp:77] Creating layer Scale56
I0612 11:05:14.319088  4990 net.cpp:240] Setting up Scale56
I0612 11:05:14.319099  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.319103  4990 net.cpp:255] Memory required for data: 2149058048
I0612 11:05:14.319113  4990 layer_factory.hpp:77] Creating layer ReLU56
I0612 11:05:14.319120  4990 net.cpp:190] Creating Layer ReLU56
I0612 11:05:14.319124  4990 net.cpp:615] ReLU56 <- Convolution56
I0612 11:05:14.319130  4990 net.cpp:576] ReLU56 -> Convolution56 (in-place)
I0612 11:05:14.319138  4990 net.cpp:240] Setting up ReLU56
I0612 11:05:14.319142  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.319146  4990 net.cpp:255] Memory required for data: 2153252352
I0612 11:05:14.319150  4990 layer_factory.hpp:77] Creating layer Convolution57
I0612 11:05:14.319162  4990 net.cpp:190] Creating Layer Convolution57
I0612 11:05:14.319167  4990 net.cpp:615] Convolution57 <- Convolution56
I0612 11:05:14.319176  4990 net.cpp:589] Convolution57 -> Convolution57
I0612 11:05:14.319825  4990 net.cpp:240] Setting up Convolution57
I0612 11:05:14.319836  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.319840  4990 net.cpp:255] Memory required for data: 2157446656
I0612 11:05:14.319850  4990 layer_factory.hpp:77] Creating layer BatchNorm57
I0612 11:05:14.319860  4990 net.cpp:190] Creating Layer BatchNorm57
I0612 11:05:14.319865  4990 net.cpp:615] BatchNorm57 <- Convolution57
I0612 11:05:14.319875  4990 net.cpp:576] BatchNorm57 -> Convolution57 (in-place)
I0612 11:05:14.320093  4990 net.cpp:240] Setting up BatchNorm57
I0612 11:05:14.320102  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.320106  4990 net.cpp:255] Memory required for data: 2161640960
I0612 11:05:14.320118  4990 layer_factory.hpp:77] Creating layer Scale57
I0612 11:05:14.320128  4990 net.cpp:190] Creating Layer Scale57
I0612 11:05:14.320133  4990 net.cpp:615] Scale57 <- Convolution57
I0612 11:05:14.320138  4990 net.cpp:576] Scale57 -> Convolution57 (in-place)
I0612 11:05:14.320176  4990 layer_factory.hpp:77] Creating layer Scale57
I0612 11:05:14.320312  4990 net.cpp:240] Setting up Scale57
I0612 11:05:14.320319  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.320324  4990 net.cpp:255] Memory required for data: 2165835264
I0612 11:05:14.320333  4990 layer_factory.hpp:77] Creating layer Eltwise28
I0612 11:05:14.320341  4990 net.cpp:190] Creating Layer Eltwise28
I0612 11:05:14.320346  4990 net.cpp:615] Eltwise28 <- Eltwise27_ReLU55_0_split_1
I0612 11:05:14.320353  4990 net.cpp:615] Eltwise28 <- Convolution57
I0612 11:05:14.320361  4990 net.cpp:589] Eltwise28 -> Eltwise28
I0612 11:05:14.320384  4990 net.cpp:240] Setting up Eltwise28
I0612 11:05:14.320390  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.320394  4990 net.cpp:255] Memory required for data: 2170029568
I0612 11:05:14.320401  4990 layer_factory.hpp:77] Creating layer ReLU57
I0612 11:05:14.320410  4990 net.cpp:190] Creating Layer ReLU57
I0612 11:05:14.320415  4990 net.cpp:615] ReLU57 <- Eltwise28
I0612 11:05:14.320421  4990 net.cpp:576] ReLU57 -> Eltwise28 (in-place)
I0612 11:05:14.320428  4990 net.cpp:240] Setting up ReLU57
I0612 11:05:14.320435  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.320438  4990 net.cpp:255] Memory required for data: 2174223872
I0612 11:05:14.320442  4990 layer_factory.hpp:77] Creating layer Eltwise28_ReLU57_0_split
I0612 11:05:14.320448  4990 net.cpp:190] Creating Layer Eltwise28_ReLU57_0_split
I0612 11:05:14.320451  4990 net.cpp:615] Eltwise28_ReLU57_0_split <- Eltwise28
I0612 11:05:14.320461  4990 net.cpp:589] Eltwise28_ReLU57_0_split -> Eltwise28_ReLU57_0_split_0
I0612 11:05:14.320468  4990 net.cpp:589] Eltwise28_ReLU57_0_split -> Eltwise28_ReLU57_0_split_1
I0612 11:05:14.320508  4990 net.cpp:240] Setting up Eltwise28_ReLU57_0_split
I0612 11:05:14.320515  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.320520  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.320524  4990 net.cpp:255] Memory required for data: 2182612480
I0612 11:05:14.320528  4990 layer_factory.hpp:77] Creating layer Convolution58
I0612 11:05:14.320540  4990 net.cpp:190] Creating Layer Convolution58
I0612 11:05:14.320545  4990 net.cpp:615] Convolution58 <- Eltwise28_ReLU57_0_split_0
I0612 11:05:14.320552  4990 net.cpp:589] Convolution58 -> Convolution58
I0612 11:05:14.321912  4990 net.cpp:240] Setting up Convolution58
I0612 11:05:14.321928  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.321933  4990 net.cpp:255] Memory required for data: 2186806784
I0612 11:05:14.321943  4990 layer_factory.hpp:77] Creating layer BatchNorm58
I0612 11:05:14.321954  4990 net.cpp:190] Creating Layer BatchNorm58
I0612 11:05:14.321960  4990 net.cpp:615] BatchNorm58 <- Convolution58
I0612 11:05:14.321967  4990 net.cpp:576] BatchNorm58 -> Convolution58 (in-place)
I0612 11:05:14.322199  4990 net.cpp:240] Setting up BatchNorm58
I0612 11:05:14.322207  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.322211  4990 net.cpp:255] Memory required for data: 2191001088
I0612 11:05:14.322224  4990 layer_factory.hpp:77] Creating layer Scale58
I0612 11:05:14.322232  4990 net.cpp:190] Creating Layer Scale58
I0612 11:05:14.322237  4990 net.cpp:615] Scale58 <- Convolution58
I0612 11:05:14.322243  4990 net.cpp:576] Scale58 -> Convolution58 (in-place)
I0612 11:05:14.322285  4990 layer_factory.hpp:77] Creating layer Scale58
I0612 11:05:14.322432  4990 net.cpp:240] Setting up Scale58
I0612 11:05:14.322443  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.322446  4990 net.cpp:255] Memory required for data: 2195195392
I0612 11:05:14.322456  4990 layer_factory.hpp:77] Creating layer ReLU58
I0612 11:05:14.322466  4990 net.cpp:190] Creating Layer ReLU58
I0612 11:05:14.322471  4990 net.cpp:615] ReLU58 <- Convolution58
I0612 11:05:14.322477  4990 net.cpp:576] ReLU58 -> Convolution58 (in-place)
I0612 11:05:14.322485  4990 net.cpp:240] Setting up ReLU58
I0612 11:05:14.322491  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.322494  4990 net.cpp:255] Memory required for data: 2199389696
I0612 11:05:14.322499  4990 layer_factory.hpp:77] Creating layer Convolution59
I0612 11:05:14.322511  4990 net.cpp:190] Creating Layer Convolution59
I0612 11:05:14.322516  4990 net.cpp:615] Convolution59 <- Convolution58
I0612 11:05:14.322526  4990 net.cpp:589] Convolution59 -> Convolution59
I0612 11:05:14.323165  4990 net.cpp:240] Setting up Convolution59
I0612 11:05:14.323176  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.323180  4990 net.cpp:255] Memory required for data: 2203584000
I0612 11:05:14.323190  4990 layer_factory.hpp:77] Creating layer BatchNorm59
I0612 11:05:14.323201  4990 net.cpp:190] Creating Layer BatchNorm59
I0612 11:05:14.323206  4990 net.cpp:615] BatchNorm59 <- Convolution59
I0612 11:05:14.323215  4990 net.cpp:576] BatchNorm59 -> Convolution59 (in-place)
I0612 11:05:14.323447  4990 net.cpp:240] Setting up BatchNorm59
I0612 11:05:14.323457  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.323460  4990 net.cpp:255] Memory required for data: 2207778304
I0612 11:05:14.323472  4990 layer_factory.hpp:77] Creating layer Scale59
I0612 11:05:14.323479  4990 net.cpp:190] Creating Layer Scale59
I0612 11:05:14.323484  4990 net.cpp:615] Scale59 <- Convolution59
I0612 11:05:14.323493  4990 net.cpp:576] Scale59 -> Convolution59 (in-place)
I0612 11:05:14.323531  4990 layer_factory.hpp:77] Creating layer Scale59
I0612 11:05:14.323667  4990 net.cpp:240] Setting up Scale59
I0612 11:05:14.323675  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.323679  4990 net.cpp:255] Memory required for data: 2211972608
I0612 11:05:14.323689  4990 layer_factory.hpp:77] Creating layer Eltwise29
I0612 11:05:14.323696  4990 net.cpp:190] Creating Layer Eltwise29
I0612 11:05:14.323701  4990 net.cpp:615] Eltwise29 <- Eltwise28_ReLU57_0_split_1
I0612 11:05:14.323707  4990 net.cpp:615] Eltwise29 <- Convolution59
I0612 11:05:14.323714  4990 net.cpp:589] Eltwise29 -> Eltwise29
I0612 11:05:14.323742  4990 net.cpp:240] Setting up Eltwise29
I0612 11:05:14.323750  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.323755  4990 net.cpp:255] Memory required for data: 2216166912
I0612 11:05:14.323757  4990 layer_factory.hpp:77] Creating layer ReLU59
I0612 11:05:14.323765  4990 net.cpp:190] Creating Layer ReLU59
I0612 11:05:14.323772  4990 net.cpp:615] ReLU59 <- Eltwise29
I0612 11:05:14.323778  4990 net.cpp:576] ReLU59 -> Eltwise29 (in-place)
I0612 11:05:14.323786  4990 net.cpp:240] Setting up ReLU59
I0612 11:05:14.323791  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.323796  4990 net.cpp:255] Memory required for data: 2220361216
I0612 11:05:14.323798  4990 layer_factory.hpp:77] Creating layer Eltwise29_ReLU59_0_split
I0612 11:05:14.323804  4990 net.cpp:190] Creating Layer Eltwise29_ReLU59_0_split
I0612 11:05:14.323808  4990 net.cpp:615] Eltwise29_ReLU59_0_split <- Eltwise29
I0612 11:05:14.323814  4990 net.cpp:589] Eltwise29_ReLU59_0_split -> Eltwise29_ReLU59_0_split_0
I0612 11:05:14.323824  4990 net.cpp:589] Eltwise29_ReLU59_0_split -> Eltwise29_ReLU59_0_split_1
I0612 11:05:14.323875  4990 net.cpp:240] Setting up Eltwise29_ReLU59_0_split
I0612 11:05:14.323884  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.323889  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.323892  4990 net.cpp:255] Memory required for data: 2228749824
I0612 11:05:14.323896  4990 layer_factory.hpp:77] Creating layer Convolution60
I0612 11:05:14.323909  4990 net.cpp:190] Creating Layer Convolution60
I0612 11:05:14.323915  4990 net.cpp:615] Convolution60 <- Eltwise29_ReLU59_0_split_0
I0612 11:05:14.323922  4990 net.cpp:589] Convolution60 -> Convolution60
I0612 11:05:14.324561  4990 net.cpp:240] Setting up Convolution60
I0612 11:05:14.324571  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.324576  4990 net.cpp:255] Memory required for data: 2232944128
I0612 11:05:14.324586  4990 layer_factory.hpp:77] Creating layer BatchNorm60
I0612 11:05:14.324595  4990 net.cpp:190] Creating Layer BatchNorm60
I0612 11:05:14.324600  4990 net.cpp:615] BatchNorm60 <- Convolution60
I0612 11:05:14.324607  4990 net.cpp:576] BatchNorm60 -> Convolution60 (in-place)
I0612 11:05:14.324831  4990 net.cpp:240] Setting up BatchNorm60
I0612 11:05:14.324839  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.324843  4990 net.cpp:255] Memory required for data: 2237138432
I0612 11:05:14.324856  4990 layer_factory.hpp:77] Creating layer Scale60
I0612 11:05:14.324865  4990 net.cpp:190] Creating Layer Scale60
I0612 11:05:14.324870  4990 net.cpp:615] Scale60 <- Convolution60
I0612 11:05:14.324877  4990 net.cpp:576] Scale60 -> Convolution60 (in-place)
I0612 11:05:14.324918  4990 layer_factory.hpp:77] Creating layer Scale60
I0612 11:05:14.325053  4990 net.cpp:240] Setting up Scale60
I0612 11:05:14.325062  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.325072  4990 net.cpp:255] Memory required for data: 2241332736
I0612 11:05:14.325083  4990 layer_factory.hpp:77] Creating layer ReLU60
I0612 11:05:14.325091  4990 net.cpp:190] Creating Layer ReLU60
I0612 11:05:14.325096  4990 net.cpp:615] ReLU60 <- Convolution60
I0612 11:05:14.325103  4990 net.cpp:576] ReLU60 -> Convolution60 (in-place)
I0612 11:05:14.325110  4990 net.cpp:240] Setting up ReLU60
I0612 11:05:14.325115  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.325119  4990 net.cpp:255] Memory required for data: 2245527040
I0612 11:05:14.325124  4990 layer_factory.hpp:77] Creating layer Convolution61
I0612 11:05:14.325135  4990 net.cpp:190] Creating Layer Convolution61
I0612 11:05:14.325140  4990 net.cpp:615] Convolution61 <- Convolution60
I0612 11:05:14.325147  4990 net.cpp:589] Convolution61 -> Convolution61
I0612 11:05:14.325783  4990 net.cpp:240] Setting up Convolution61
I0612 11:05:14.325793  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.325796  4990 net.cpp:255] Memory required for data: 2249721344
I0612 11:05:14.325806  4990 layer_factory.hpp:77] Creating layer BatchNorm61
I0612 11:05:14.325816  4990 net.cpp:190] Creating Layer BatchNorm61
I0612 11:05:14.325822  4990 net.cpp:615] BatchNorm61 <- Convolution61
I0612 11:05:14.325829  4990 net.cpp:576] BatchNorm61 -> Convolution61 (in-place)
I0612 11:05:14.326056  4990 net.cpp:240] Setting up BatchNorm61
I0612 11:05:14.326064  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.326068  4990 net.cpp:255] Memory required for data: 2253915648
I0612 11:05:14.326082  4990 layer_factory.hpp:77] Creating layer Scale61
I0612 11:05:14.326091  4990 net.cpp:190] Creating Layer Scale61
I0612 11:05:14.326095  4990 net.cpp:615] Scale61 <- Convolution61
I0612 11:05:14.326102  4990 net.cpp:576] Scale61 -> Convolution61 (in-place)
I0612 11:05:14.326141  4990 layer_factory.hpp:77] Creating layer Scale61
I0612 11:05:14.326275  4990 net.cpp:240] Setting up Scale61
I0612 11:05:14.326284  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.326287  4990 net.cpp:255] Memory required for data: 2258109952
I0612 11:05:14.326299  4990 layer_factory.hpp:77] Creating layer Eltwise30
I0612 11:05:14.326308  4990 net.cpp:190] Creating Layer Eltwise30
I0612 11:05:14.326313  4990 net.cpp:615] Eltwise30 <- Eltwise29_ReLU59_0_split_1
I0612 11:05:14.326318  4990 net.cpp:615] Eltwise30 <- Convolution61
I0612 11:05:14.326328  4990 net.cpp:589] Eltwise30 -> Eltwise30
I0612 11:05:14.326349  4990 net.cpp:240] Setting up Eltwise30
I0612 11:05:14.326380  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.326385  4990 net.cpp:255] Memory required for data: 2262304256
I0612 11:05:14.326388  4990 layer_factory.hpp:77] Creating layer ReLU61
I0612 11:05:14.326395  4990 net.cpp:190] Creating Layer ReLU61
I0612 11:05:14.326400  4990 net.cpp:615] ReLU61 <- Eltwise30
I0612 11:05:14.326413  4990 net.cpp:576] ReLU61 -> Eltwise30 (in-place)
I0612 11:05:14.326422  4990 net.cpp:240] Setting up ReLU61
I0612 11:05:14.326428  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.326432  4990 net.cpp:255] Memory required for data: 2266498560
I0612 11:05:14.326436  4990 layer_factory.hpp:77] Creating layer Eltwise30_ReLU61_0_split
I0612 11:05:14.326442  4990 net.cpp:190] Creating Layer Eltwise30_ReLU61_0_split
I0612 11:05:14.326447  4990 net.cpp:615] Eltwise30_ReLU61_0_split <- Eltwise30
I0612 11:05:14.326452  4990 net.cpp:589] Eltwise30_ReLU61_0_split -> Eltwise30_ReLU61_0_split_0
I0612 11:05:14.326459  4990 net.cpp:589] Eltwise30_ReLU61_0_split -> Eltwise30_ReLU61_0_split_1
I0612 11:05:14.326506  4990 net.cpp:240] Setting up Eltwise30_ReLU61_0_split
I0612 11:05:14.326514  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.326519  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.326524  4990 net.cpp:255] Memory required for data: 2274887168
I0612 11:05:14.326527  4990 layer_factory.hpp:77] Creating layer Convolution62
I0612 11:05:14.326540  4990 net.cpp:190] Creating Layer Convolution62
I0612 11:05:14.326545  4990 net.cpp:615] Convolution62 <- Eltwise30_ReLU61_0_split_0
I0612 11:05:14.326556  4990 net.cpp:589] Convolution62 -> Convolution62
I0612 11:05:14.327193  4990 net.cpp:240] Setting up Convolution62
I0612 11:05:14.327203  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.327206  4990 net.cpp:255] Memory required for data: 2279081472
I0612 11:05:14.327217  4990 layer_factory.hpp:77] Creating layer BatchNorm62
I0612 11:05:14.327224  4990 net.cpp:190] Creating Layer BatchNorm62
I0612 11:05:14.327229  4990 net.cpp:615] BatchNorm62 <- Convolution62
I0612 11:05:14.327239  4990 net.cpp:576] BatchNorm62 -> Convolution62 (in-place)
I0612 11:05:14.327467  4990 net.cpp:240] Setting up BatchNorm62
I0612 11:05:14.327476  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.327481  4990 net.cpp:255] Memory required for data: 2283275776
I0612 11:05:14.327492  4990 layer_factory.hpp:77] Creating layer Scale62
I0612 11:05:14.327500  4990 net.cpp:190] Creating Layer Scale62
I0612 11:05:14.327504  4990 net.cpp:615] Scale62 <- Convolution62
I0612 11:05:14.327512  4990 net.cpp:576] Scale62 -> Convolution62 (in-place)
I0612 11:05:14.327553  4990 layer_factory.hpp:77] Creating layer Scale62
I0612 11:05:14.327690  4990 net.cpp:240] Setting up Scale62
I0612 11:05:14.327698  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.327702  4990 net.cpp:255] Memory required for data: 2287470080
I0612 11:05:14.327713  4990 layer_factory.hpp:77] Creating layer ReLU62
I0612 11:05:14.327723  4990 net.cpp:190] Creating Layer ReLU62
I0612 11:05:14.327728  4990 net.cpp:615] ReLU62 <- Convolution62
I0612 11:05:14.327733  4990 net.cpp:576] ReLU62 -> Convolution62 (in-place)
I0612 11:05:14.327740  4990 net.cpp:240] Setting up ReLU62
I0612 11:05:14.327746  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.327750  4990 net.cpp:255] Memory required for data: 2291664384
I0612 11:05:14.327754  4990 layer_factory.hpp:77] Creating layer Convolution63
I0612 11:05:14.327766  4990 net.cpp:190] Creating Layer Convolution63
I0612 11:05:14.327770  4990 net.cpp:615] Convolution63 <- Convolution62
I0612 11:05:14.327777  4990 net.cpp:589] Convolution63 -> Convolution63
I0612 11:05:14.328423  4990 net.cpp:240] Setting up Convolution63
I0612 11:05:14.328433  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.328438  4990 net.cpp:255] Memory required for data: 2295858688
I0612 11:05:14.328449  4990 layer_factory.hpp:77] Creating layer BatchNorm63
I0612 11:05:14.328459  4990 net.cpp:190] Creating Layer BatchNorm63
I0612 11:05:14.328464  4990 net.cpp:615] BatchNorm63 <- Convolution63
I0612 11:05:14.328469  4990 net.cpp:576] BatchNorm63 -> Convolution63 (in-place)
I0612 11:05:14.328701  4990 net.cpp:240] Setting up BatchNorm63
I0612 11:05:14.328709  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.328713  4990 net.cpp:255] Memory required for data: 2300052992
I0612 11:05:14.328725  4990 layer_factory.hpp:77] Creating layer Scale63
I0612 11:05:14.328732  4990 net.cpp:190] Creating Layer Scale63
I0612 11:05:14.328737  4990 net.cpp:615] Scale63 <- Convolution63
I0612 11:05:14.328745  4990 net.cpp:576] Scale63 -> Convolution63 (in-place)
I0612 11:05:14.328785  4990 layer_factory.hpp:77] Creating layer Scale63
I0612 11:05:14.328922  4990 net.cpp:240] Setting up Scale63
I0612 11:05:14.328930  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.328935  4990 net.cpp:255] Memory required for data: 2304247296
I0612 11:05:14.328948  4990 layer_factory.hpp:77] Creating layer Eltwise31
I0612 11:05:14.328954  4990 net.cpp:190] Creating Layer Eltwise31
I0612 11:05:14.328960  4990 net.cpp:615] Eltwise31 <- Eltwise30_ReLU61_0_split_1
I0612 11:05:14.328966  4990 net.cpp:615] Eltwise31 <- Convolution63
I0612 11:05:14.328972  4990 net.cpp:589] Eltwise31 -> Eltwise31
I0612 11:05:14.328996  4990 net.cpp:240] Setting up Eltwise31
I0612 11:05:14.329004  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.329011  4990 net.cpp:255] Memory required for data: 2308441600
I0612 11:05:14.329015  4990 layer_factory.hpp:77] Creating layer ReLU63
I0612 11:05:14.329022  4990 net.cpp:190] Creating Layer ReLU63
I0612 11:05:14.329026  4990 net.cpp:615] ReLU63 <- Eltwise31
I0612 11:05:14.329035  4990 net.cpp:576] ReLU63 -> Eltwise31 (in-place)
I0612 11:05:14.329042  4990 net.cpp:240] Setting up ReLU63
I0612 11:05:14.329047  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.329051  4990 net.cpp:255] Memory required for data: 2312635904
I0612 11:05:14.329056  4990 layer_factory.hpp:77] Creating layer Eltwise31_ReLU63_0_split
I0612 11:05:14.329077  4990 net.cpp:190] Creating Layer Eltwise31_ReLU63_0_split
I0612 11:05:14.329080  4990 net.cpp:615] Eltwise31_ReLU63_0_split <- Eltwise31
I0612 11:05:14.329087  4990 net.cpp:589] Eltwise31_ReLU63_0_split -> Eltwise31_ReLU63_0_split_0
I0612 11:05:14.329094  4990 net.cpp:589] Eltwise31_ReLU63_0_split -> Eltwise31_ReLU63_0_split_1
I0612 11:05:14.329138  4990 net.cpp:240] Setting up Eltwise31_ReLU63_0_split
I0612 11:05:14.329144  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.329150  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.329154  4990 net.cpp:255] Memory required for data: 2321024512
I0612 11:05:14.329159  4990 layer_factory.hpp:77] Creating layer Convolution64
I0612 11:05:14.329171  4990 net.cpp:190] Creating Layer Convolution64
I0612 11:05:14.329176  4990 net.cpp:615] Convolution64 <- Eltwise31_ReLU63_0_split_0
I0612 11:05:14.329185  4990 net.cpp:589] Convolution64 -> Convolution64
I0612 11:05:14.329825  4990 net.cpp:240] Setting up Convolution64
I0612 11:05:14.329835  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.329839  4990 net.cpp:255] Memory required for data: 2325218816
I0612 11:05:14.329849  4990 layer_factory.hpp:77] Creating layer BatchNorm64
I0612 11:05:14.329859  4990 net.cpp:190] Creating Layer BatchNorm64
I0612 11:05:14.329864  4990 net.cpp:615] BatchNorm64 <- Convolution64
I0612 11:05:14.329872  4990 net.cpp:576] BatchNorm64 -> Convolution64 (in-place)
I0612 11:05:14.330101  4990 net.cpp:240] Setting up BatchNorm64
I0612 11:05:14.330108  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.330112  4990 net.cpp:255] Memory required for data: 2329413120
I0612 11:05:14.330124  4990 layer_factory.hpp:77] Creating layer Scale64
I0612 11:05:14.330134  4990 net.cpp:190] Creating Layer Scale64
I0612 11:05:14.330139  4990 net.cpp:615] Scale64 <- Convolution64
I0612 11:05:14.330145  4990 net.cpp:576] Scale64 -> Convolution64 (in-place)
I0612 11:05:14.330183  4990 layer_factory.hpp:77] Creating layer Scale64
I0612 11:05:14.330322  4990 net.cpp:240] Setting up Scale64
I0612 11:05:14.330330  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.330334  4990 net.cpp:255] Memory required for data: 2333607424
I0612 11:05:14.330344  4990 layer_factory.hpp:77] Creating layer ReLU64
I0612 11:05:14.330351  4990 net.cpp:190] Creating Layer ReLU64
I0612 11:05:14.330379  4990 net.cpp:615] ReLU64 <- Convolution64
I0612 11:05:14.330389  4990 net.cpp:576] ReLU64 -> Convolution64 (in-place)
I0612 11:05:14.330396  4990 net.cpp:240] Setting up ReLU64
I0612 11:05:14.330402  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.330406  4990 net.cpp:255] Memory required for data: 2337801728
I0612 11:05:14.330410  4990 layer_factory.hpp:77] Creating layer Convolution65
I0612 11:05:14.330422  4990 net.cpp:190] Creating Layer Convolution65
I0612 11:05:14.330427  4990 net.cpp:615] Convolution65 <- Convolution64
I0612 11:05:14.330435  4990 net.cpp:589] Convolution65 -> Convolution65
I0612 11:05:14.331076  4990 net.cpp:240] Setting up Convolution65
I0612 11:05:14.331085  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.331090  4990 net.cpp:255] Memory required for data: 2341996032
I0612 11:05:14.331099  4990 layer_factory.hpp:77] Creating layer BatchNorm65
I0612 11:05:14.331110  4990 net.cpp:190] Creating Layer BatchNorm65
I0612 11:05:14.331113  4990 net.cpp:615] BatchNorm65 <- Convolution65
I0612 11:05:14.331123  4990 net.cpp:576] BatchNorm65 -> Convolution65 (in-place)
I0612 11:05:14.331336  4990 net.cpp:240] Setting up BatchNorm65
I0612 11:05:14.331346  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.331349  4990 net.cpp:255] Memory required for data: 2346190336
I0612 11:05:14.331360  4990 layer_factory.hpp:77] Creating layer Scale65
I0612 11:05:14.331370  4990 net.cpp:190] Creating Layer Scale65
I0612 11:05:14.331375  4990 net.cpp:615] Scale65 <- Convolution65
I0612 11:05:14.331382  4990 net.cpp:576] Scale65 -> Convolution65 (in-place)
I0612 11:05:14.331421  4990 layer_factory.hpp:77] Creating layer Scale65
I0612 11:05:14.331550  4990 net.cpp:240] Setting up Scale65
I0612 11:05:14.331558  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.331562  4990 net.cpp:255] Memory required for data: 2350384640
I0612 11:05:14.331573  4990 layer_factory.hpp:77] Creating layer Eltwise32
I0612 11:05:14.331581  4990 net.cpp:190] Creating Layer Eltwise32
I0612 11:05:14.331586  4990 net.cpp:615] Eltwise32 <- Eltwise31_ReLU63_0_split_1
I0612 11:05:14.331593  4990 net.cpp:615] Eltwise32 <- Convolution65
I0612 11:05:14.331598  4990 net.cpp:589] Eltwise32 -> Eltwise32
I0612 11:05:14.331622  4990 net.cpp:240] Setting up Eltwise32
I0612 11:05:14.331629  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.331632  4990 net.cpp:255] Memory required for data: 2354578944
I0612 11:05:14.331636  4990 layer_factory.hpp:77] Creating layer ReLU65
I0612 11:05:14.331643  4990 net.cpp:190] Creating Layer ReLU65
I0612 11:05:14.331647  4990 net.cpp:615] ReLU65 <- Eltwise32
I0612 11:05:14.331652  4990 net.cpp:576] ReLU65 -> Eltwise32 (in-place)
I0612 11:05:14.331660  4990 net.cpp:240] Setting up ReLU65
I0612 11:05:14.331665  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.331668  4990 net.cpp:255] Memory required for data: 2358773248
I0612 11:05:14.331672  4990 layer_factory.hpp:77] Creating layer Eltwise32_ReLU65_0_split
I0612 11:05:14.331681  4990 net.cpp:190] Creating Layer Eltwise32_ReLU65_0_split
I0612 11:05:14.331684  4990 net.cpp:615] Eltwise32_ReLU65_0_split <- Eltwise32
I0612 11:05:14.331691  4990 net.cpp:589] Eltwise32_ReLU65_0_split -> Eltwise32_ReLU65_0_split_0
I0612 11:05:14.331697  4990 net.cpp:589] Eltwise32_ReLU65_0_split -> Eltwise32_ReLU65_0_split_1
I0612 11:05:14.331738  4990 net.cpp:240] Setting up Eltwise32_ReLU65_0_split
I0612 11:05:14.331745  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.331750  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.331753  4990 net.cpp:255] Memory required for data: 2367161856
I0612 11:05:14.331758  4990 layer_factory.hpp:77] Creating layer Convolution66
I0612 11:05:14.331766  4990 net.cpp:190] Creating Layer Convolution66
I0612 11:05:14.331771  4990 net.cpp:615] Convolution66 <- Eltwise32_ReLU65_0_split_0
I0612 11:05:14.331779  4990 net.cpp:589] Convolution66 -> Convolution66
I0612 11:05:14.332384  4990 net.cpp:240] Setting up Convolution66
I0612 11:05:14.332396  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.332401  4990 net.cpp:255] Memory required for data: 2371356160
I0612 11:05:14.332409  4990 layer_factory.hpp:77] Creating layer BatchNorm66
I0612 11:05:14.332417  4990 net.cpp:190] Creating Layer BatchNorm66
I0612 11:05:14.332422  4990 net.cpp:615] BatchNorm66 <- Convolution66
I0612 11:05:14.332430  4990 net.cpp:576] BatchNorm66 -> Convolution66 (in-place)
I0612 11:05:14.332653  4990 net.cpp:240] Setting up BatchNorm66
I0612 11:05:14.332661  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.332665  4990 net.cpp:255] Memory required for data: 2375550464
I0612 11:05:14.332677  4990 layer_factory.hpp:77] Creating layer Scale66
I0612 11:05:14.332684  4990 net.cpp:190] Creating Layer Scale66
I0612 11:05:14.332690  4990 net.cpp:615] Scale66 <- Convolution66
I0612 11:05:14.332695  4990 net.cpp:576] Scale66 -> Convolution66 (in-place)
I0612 11:05:14.332736  4990 layer_factory.hpp:77] Creating layer Scale66
I0612 11:05:14.332867  4990 net.cpp:240] Setting up Scale66
I0612 11:05:14.332880  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.332885  4990 net.cpp:255] Memory required for data: 2379744768
I0612 11:05:14.332895  4990 layer_factory.hpp:77] Creating layer ReLU66
I0612 11:05:14.332901  4990 net.cpp:190] Creating Layer ReLU66
I0612 11:05:14.332906  4990 net.cpp:615] ReLU66 <- Convolution66
I0612 11:05:14.332913  4990 net.cpp:576] ReLU66 -> Convolution66 (in-place)
I0612 11:05:14.332921  4990 net.cpp:240] Setting up ReLU66
I0612 11:05:14.332926  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.332931  4990 net.cpp:255] Memory required for data: 2383939072
I0612 11:05:14.332934  4990 layer_factory.hpp:77] Creating layer Convolution67
I0612 11:05:14.332943  4990 net.cpp:190] Creating Layer Convolution67
I0612 11:05:14.332947  4990 net.cpp:615] Convolution67 <- Convolution66
I0612 11:05:14.332957  4990 net.cpp:589] Convolution67 -> Convolution67
I0612 11:05:14.333569  4990 net.cpp:240] Setting up Convolution67
I0612 11:05:14.333577  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.333581  4990 net.cpp:255] Memory required for data: 2388133376
I0612 11:05:14.333591  4990 layer_factory.hpp:77] Creating layer BatchNorm67
I0612 11:05:14.333598  4990 net.cpp:190] Creating Layer BatchNorm67
I0612 11:05:14.333602  4990 net.cpp:615] BatchNorm67 <- Convolution67
I0612 11:05:14.333611  4990 net.cpp:576] BatchNorm67 -> Convolution67 (in-place)
I0612 11:05:14.333824  4990 net.cpp:240] Setting up BatchNorm67
I0612 11:05:14.333832  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.333837  4990 net.cpp:255] Memory required for data: 2392327680
I0612 11:05:14.333848  4990 layer_factory.hpp:77] Creating layer Scale67
I0612 11:05:14.333854  4990 net.cpp:190] Creating Layer Scale67
I0612 11:05:14.333859  4990 net.cpp:615] Scale67 <- Convolution67
I0612 11:05:14.333865  4990 net.cpp:576] Scale67 -> Convolution67 (in-place)
I0612 11:05:14.333905  4990 layer_factory.hpp:77] Creating layer Scale67
I0612 11:05:14.334031  4990 net.cpp:240] Setting up Scale67
I0612 11:05:14.334039  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.334043  4990 net.cpp:255] Memory required for data: 2396521984
I0612 11:05:14.334053  4990 layer_factory.hpp:77] Creating layer Eltwise33
I0612 11:05:14.334061  4990 net.cpp:190] Creating Layer Eltwise33
I0612 11:05:14.334066  4990 net.cpp:615] Eltwise33 <- Eltwise32_ReLU65_0_split_1
I0612 11:05:14.334072  4990 net.cpp:615] Eltwise33 <- Convolution67
I0612 11:05:14.334079  4990 net.cpp:589] Eltwise33 -> Eltwise33
I0612 11:05:14.334098  4990 net.cpp:240] Setting up Eltwise33
I0612 11:05:14.334105  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.334110  4990 net.cpp:255] Memory required for data: 2400716288
I0612 11:05:14.334112  4990 layer_factory.hpp:77] Creating layer ReLU67
I0612 11:05:14.334121  4990 net.cpp:190] Creating Layer ReLU67
I0612 11:05:14.334126  4990 net.cpp:615] ReLU67 <- Eltwise33
I0612 11:05:14.334131  4990 net.cpp:576] ReLU67 -> Eltwise33 (in-place)
I0612 11:05:14.334138  4990 net.cpp:240] Setting up ReLU67
I0612 11:05:14.334143  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.334147  4990 net.cpp:255] Memory required for data: 2404910592
I0612 11:05:14.334151  4990 layer_factory.hpp:77] Creating layer Eltwise33_ReLU67_0_split
I0612 11:05:14.334159  4990 net.cpp:190] Creating Layer Eltwise33_ReLU67_0_split
I0612 11:05:14.334163  4990 net.cpp:615] Eltwise33_ReLU67_0_split <- Eltwise33
I0612 11:05:14.334168  4990 net.cpp:589] Eltwise33_ReLU67_0_split -> Eltwise33_ReLU67_0_split_0
I0612 11:05:14.334175  4990 net.cpp:589] Eltwise33_ReLU67_0_split -> Eltwise33_ReLU67_0_split_1
I0612 11:05:14.334218  4990 net.cpp:240] Setting up Eltwise33_ReLU67_0_split
I0612 11:05:14.334225  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.334230  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.334234  4990 net.cpp:255] Memory required for data: 2413299200
I0612 11:05:14.334239  4990 layer_factory.hpp:77] Creating layer Convolution68
I0612 11:05:14.334252  4990 net.cpp:190] Creating Layer Convolution68
I0612 11:05:14.334257  4990 net.cpp:615] Convolution68 <- Eltwise33_ReLU67_0_split_0
I0612 11:05:14.334265  4990 net.cpp:589] Convolution68 -> Convolution68
I0612 11:05:14.334889  4990 net.cpp:240] Setting up Convolution68
I0612 11:05:14.334899  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.334903  4990 net.cpp:255] Memory required for data: 2417493504
I0612 11:05:14.334913  4990 layer_factory.hpp:77] Creating layer BatchNorm68
I0612 11:05:14.334923  4990 net.cpp:190] Creating Layer BatchNorm68
I0612 11:05:14.334928  4990 net.cpp:615] BatchNorm68 <- Convolution68
I0612 11:05:14.334936  4990 net.cpp:576] BatchNorm68 -> Convolution68 (in-place)
I0612 11:05:14.335146  4990 net.cpp:240] Setting up BatchNorm68
I0612 11:05:14.335155  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.335158  4990 net.cpp:255] Memory required for data: 2421687808
I0612 11:05:14.335170  4990 layer_factory.hpp:77] Creating layer Scale68
I0612 11:05:14.335180  4990 net.cpp:190] Creating Layer Scale68
I0612 11:05:14.335185  4990 net.cpp:615] Scale68 <- Convolution68
I0612 11:05:14.335191  4990 net.cpp:576] Scale68 -> Convolution68 (in-place)
I0612 11:05:14.335227  4990 layer_factory.hpp:77] Creating layer Scale68
I0612 11:05:14.335356  4990 net.cpp:240] Setting up Scale68
I0612 11:05:14.335364  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.335368  4990 net.cpp:255] Memory required for data: 2425882112
I0612 11:05:14.335377  4990 layer_factory.hpp:77] Creating layer ReLU68
I0612 11:05:14.335383  4990 net.cpp:190] Creating Layer ReLU68
I0612 11:05:14.335388  4990 net.cpp:615] ReLU68 <- Convolution68
I0612 11:05:14.335394  4990 net.cpp:576] ReLU68 -> Convolution68 (in-place)
I0612 11:05:14.335400  4990 net.cpp:240] Setting up ReLU68
I0612 11:05:14.335407  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.335409  4990 net.cpp:255] Memory required for data: 2430076416
I0612 11:05:14.335413  4990 layer_factory.hpp:77] Creating layer Convolution69
I0612 11:05:14.335427  4990 net.cpp:190] Creating Layer Convolution69
I0612 11:05:14.335432  4990 net.cpp:615] Convolution69 <- Convolution68
I0612 11:05:14.335438  4990 net.cpp:589] Convolution69 -> Convolution69
I0612 11:05:14.336047  4990 net.cpp:240] Setting up Convolution69
I0612 11:05:14.336057  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.336061  4990 net.cpp:255] Memory required for data: 2434270720
I0612 11:05:14.336071  4990 layer_factory.hpp:77] Creating layer BatchNorm69
I0612 11:05:14.336081  4990 net.cpp:190] Creating Layer BatchNorm69
I0612 11:05:14.336086  4990 net.cpp:615] BatchNorm69 <- Convolution69
I0612 11:05:14.336093  4990 net.cpp:576] BatchNorm69 -> Convolution69 (in-place)
I0612 11:05:14.336310  4990 net.cpp:240] Setting up BatchNorm69
I0612 11:05:14.336318  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.336323  4990 net.cpp:255] Memory required for data: 2438465024
I0612 11:05:14.336333  4990 layer_factory.hpp:77] Creating layer Scale69
I0612 11:05:14.336344  4990 net.cpp:190] Creating Layer Scale69
I0612 11:05:14.336349  4990 net.cpp:615] Scale69 <- Convolution69
I0612 11:05:14.336354  4990 net.cpp:576] Scale69 -> Convolution69 (in-place)
I0612 11:05:14.336392  4990 layer_factory.hpp:77] Creating layer Scale69
I0612 11:05:14.336520  4990 net.cpp:240] Setting up Scale69
I0612 11:05:14.336529  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.336532  4990 net.cpp:255] Memory required for data: 2442659328
I0612 11:05:14.336541  4990 layer_factory.hpp:77] Creating layer Eltwise34
I0612 11:05:14.336549  4990 net.cpp:190] Creating Layer Eltwise34
I0612 11:05:14.336554  4990 net.cpp:615] Eltwise34 <- Eltwise33_ReLU67_0_split_1
I0612 11:05:14.336563  4990 net.cpp:615] Eltwise34 <- Convolution69
I0612 11:05:14.336570  4990 net.cpp:589] Eltwise34 -> Eltwise34
I0612 11:05:14.336592  4990 net.cpp:240] Setting up Eltwise34
I0612 11:05:14.336601  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.336608  4990 net.cpp:255] Memory required for data: 2446853632
I0612 11:05:14.336612  4990 layer_factory.hpp:77] Creating layer ReLU69
I0612 11:05:14.336619  4990 net.cpp:190] Creating Layer ReLU69
I0612 11:05:14.336623  4990 net.cpp:615] ReLU69 <- Eltwise34
I0612 11:05:14.336628  4990 net.cpp:576] ReLU69 -> Eltwise34 (in-place)
I0612 11:05:14.336635  4990 net.cpp:240] Setting up ReLU69
I0612 11:05:14.336640  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.336644  4990 net.cpp:255] Memory required for data: 2451047936
I0612 11:05:14.336647  4990 layer_factory.hpp:77] Creating layer Eltwise34_ReLU69_0_split
I0612 11:05:14.336653  4990 net.cpp:190] Creating Layer Eltwise34_ReLU69_0_split
I0612 11:05:14.336658  4990 net.cpp:615] Eltwise34_ReLU69_0_split <- Eltwise34
I0612 11:05:14.336665  4990 net.cpp:589] Eltwise34_ReLU69_0_split -> Eltwise34_ReLU69_0_split_0
I0612 11:05:14.336673  4990 net.cpp:589] Eltwise34_ReLU69_0_split -> Eltwise34_ReLU69_0_split_1
I0612 11:05:14.336711  4990 net.cpp:240] Setting up Eltwise34_ReLU69_0_split
I0612 11:05:14.336717  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.336722  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.336726  4990 net.cpp:255] Memory required for data: 2459436544
I0612 11:05:14.336730  4990 layer_factory.hpp:77] Creating layer Convolution70
I0612 11:05:14.336742  4990 net.cpp:190] Creating Layer Convolution70
I0612 11:05:14.336747  4990 net.cpp:615] Convolution70 <- Eltwise34_ReLU69_0_split_0
I0612 11:05:14.336755  4990 net.cpp:589] Convolution70 -> Convolution70
I0612 11:05:14.337360  4990 net.cpp:240] Setting up Convolution70
I0612 11:05:14.337369  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.337373  4990 net.cpp:255] Memory required for data: 2463630848
I0612 11:05:14.337383  4990 layer_factory.hpp:77] Creating layer BatchNorm70
I0612 11:05:14.337393  4990 net.cpp:190] Creating Layer BatchNorm70
I0612 11:05:14.337398  4990 net.cpp:615] BatchNorm70 <- Convolution70
I0612 11:05:14.337404  4990 net.cpp:576] BatchNorm70 -> Convolution70 (in-place)
I0612 11:05:14.337620  4990 net.cpp:240] Setting up BatchNorm70
I0612 11:05:14.337627  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.337631  4990 net.cpp:255] Memory required for data: 2467825152
I0612 11:05:14.337644  4990 layer_factory.hpp:77] Creating layer Scale70
I0612 11:05:14.337651  4990 net.cpp:190] Creating Layer Scale70
I0612 11:05:14.337656  4990 net.cpp:615] Scale70 <- Convolution70
I0612 11:05:14.337662  4990 net.cpp:576] Scale70 -> Convolution70 (in-place)
I0612 11:05:14.337700  4990 layer_factory.hpp:77] Creating layer Scale70
I0612 11:05:14.337836  4990 net.cpp:240] Setting up Scale70
I0612 11:05:14.337843  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.337847  4990 net.cpp:255] Memory required for data: 2472019456
I0612 11:05:14.337859  4990 layer_factory.hpp:77] Creating layer ReLU70
I0612 11:05:14.337867  4990 net.cpp:190] Creating Layer ReLU70
I0612 11:05:14.337870  4990 net.cpp:615] ReLU70 <- Convolution70
I0612 11:05:14.337878  4990 net.cpp:576] ReLU70 -> Convolution70 (in-place)
I0612 11:05:14.337887  4990 net.cpp:240] Setting up ReLU70
I0612 11:05:14.337891  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.337895  4990 net.cpp:255] Memory required for data: 2476213760
I0612 11:05:14.337899  4990 layer_factory.hpp:77] Creating layer Convolution71
I0612 11:05:14.337908  4990 net.cpp:190] Creating Layer Convolution71
I0612 11:05:14.337913  4990 net.cpp:615] Convolution71 <- Convolution70
I0612 11:05:14.337921  4990 net.cpp:589] Convolution71 -> Convolution71
I0612 11:05:14.338538  4990 net.cpp:240] Setting up Convolution71
I0612 11:05:14.338548  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.338552  4990 net.cpp:255] Memory required for data: 2480408064
I0612 11:05:14.338562  4990 layer_factory.hpp:77] Creating layer BatchNorm71
I0612 11:05:14.338569  4990 net.cpp:190] Creating Layer BatchNorm71
I0612 11:05:14.338577  4990 net.cpp:615] BatchNorm71 <- Convolution71
I0612 11:05:14.338587  4990 net.cpp:576] BatchNorm71 -> Convolution71 (in-place)
I0612 11:05:14.338806  4990 net.cpp:240] Setting up BatchNorm71
I0612 11:05:14.338814  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.338819  4990 net.cpp:255] Memory required for data: 2484602368
I0612 11:05:14.338830  4990 layer_factory.hpp:77] Creating layer Scale71
I0612 11:05:14.338837  4990 net.cpp:190] Creating Layer Scale71
I0612 11:05:14.338842  4990 net.cpp:615] Scale71 <- Convolution71
I0612 11:05:14.338848  4990 net.cpp:576] Scale71 -> Convolution71 (in-place)
I0612 11:05:14.338888  4990 layer_factory.hpp:77] Creating layer Scale71
I0612 11:05:14.339020  4990 net.cpp:240] Setting up Scale71
I0612 11:05:14.339027  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.339030  4990 net.cpp:255] Memory required for data: 2488796672
I0612 11:05:14.339040  4990 layer_factory.hpp:77] Creating layer Eltwise35
I0612 11:05:14.339047  4990 net.cpp:190] Creating Layer Eltwise35
I0612 11:05:14.339054  4990 net.cpp:615] Eltwise35 <- Eltwise34_ReLU69_0_split_1
I0612 11:05:14.339061  4990 net.cpp:615] Eltwise35 <- Convolution71
I0612 11:05:14.339066  4990 net.cpp:589] Eltwise35 -> Eltwise35
I0612 11:05:14.339087  4990 net.cpp:240] Setting up Eltwise35
I0612 11:05:14.339093  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.339097  4990 net.cpp:255] Memory required for data: 2492990976
I0612 11:05:14.339102  4990 layer_factory.hpp:77] Creating layer ReLU71
I0612 11:05:14.339110  4990 net.cpp:190] Creating Layer ReLU71
I0612 11:05:14.339114  4990 net.cpp:615] ReLU71 <- Eltwise35
I0612 11:05:14.339120  4990 net.cpp:576] ReLU71 -> Eltwise35 (in-place)
I0612 11:05:14.339126  4990 net.cpp:240] Setting up ReLU71
I0612 11:05:14.339131  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.339135  4990 net.cpp:255] Memory required for data: 2497185280
I0612 11:05:14.339139  4990 layer_factory.hpp:77] Creating layer Eltwise35_ReLU71_0_split
I0612 11:05:14.339145  4990 net.cpp:190] Creating Layer Eltwise35_ReLU71_0_split
I0612 11:05:14.339149  4990 net.cpp:615] Eltwise35_ReLU71_0_split <- Eltwise35
I0612 11:05:14.339157  4990 net.cpp:589] Eltwise35_ReLU71_0_split -> Eltwise35_ReLU71_0_split_0
I0612 11:05:14.339165  4990 net.cpp:589] Eltwise35_ReLU71_0_split -> Eltwise35_ReLU71_0_split_1
I0612 11:05:14.339207  4990 net.cpp:240] Setting up Eltwise35_ReLU71_0_split
I0612 11:05:14.339215  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.339220  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.339223  4990 net.cpp:255] Memory required for data: 2505573888
I0612 11:05:14.339227  4990 layer_factory.hpp:77] Creating layer Convolution72
I0612 11:05:14.339239  4990 net.cpp:190] Creating Layer Convolution72
I0612 11:05:14.339244  4990 net.cpp:615] Convolution72 <- Eltwise35_ReLU71_0_split_0
I0612 11:05:14.339251  4990 net.cpp:589] Convolution72 -> Convolution72
I0612 11:05:14.339866  4990 net.cpp:240] Setting up Convolution72
I0612 11:05:14.339876  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.339879  4990 net.cpp:255] Memory required for data: 2509768192
I0612 11:05:14.339890  4990 layer_factory.hpp:77] Creating layer BatchNorm72
I0612 11:05:14.339898  4990 net.cpp:190] Creating Layer BatchNorm72
I0612 11:05:14.339903  4990 net.cpp:615] BatchNorm72 <- Convolution72
I0612 11:05:14.339908  4990 net.cpp:576] BatchNorm72 -> Convolution72 (in-place)
I0612 11:05:14.340122  4990 net.cpp:240] Setting up BatchNorm72
I0612 11:05:14.340131  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.340134  4990 net.cpp:255] Memory required for data: 2513962496
I0612 11:05:14.340145  4990 layer_factory.hpp:77] Creating layer Scale72
I0612 11:05:14.340152  4990 net.cpp:190] Creating Layer Scale72
I0612 11:05:14.340157  4990 net.cpp:615] Scale72 <- Convolution72
I0612 11:05:14.340167  4990 net.cpp:576] Scale72 -> Convolution72 (in-place)
I0612 11:05:14.340203  4990 layer_factory.hpp:77] Creating layer Scale72
I0612 11:05:14.340333  4990 net.cpp:240] Setting up Scale72
I0612 11:05:14.340343  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.340348  4990 net.cpp:255] Memory required for data: 2518156800
I0612 11:05:14.340356  4990 layer_factory.hpp:77] Creating layer ReLU72
I0612 11:05:14.340363  4990 net.cpp:190] Creating Layer ReLU72
I0612 11:05:14.340368  4990 net.cpp:615] ReLU72 <- Convolution72
I0612 11:05:14.340373  4990 net.cpp:576] ReLU72 -> Convolution72 (in-place)
I0612 11:05:14.340380  4990 net.cpp:240] Setting up ReLU72
I0612 11:05:14.340385  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.340389  4990 net.cpp:255] Memory required for data: 2522351104
I0612 11:05:14.340394  4990 layer_factory.hpp:77] Creating layer Convolution73
I0612 11:05:14.340404  4990 net.cpp:190] Creating Layer Convolution73
I0612 11:05:14.340409  4990 net.cpp:615] Convolution73 <- Convolution72
I0612 11:05:14.340418  4990 net.cpp:589] Convolution73 -> Convolution73
I0612 11:05:14.341025  4990 net.cpp:240] Setting up Convolution73
I0612 11:05:14.341035  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.341039  4990 net.cpp:255] Memory required for data: 2526545408
I0612 11:05:14.341049  4990 layer_factory.hpp:77] Creating layer BatchNorm73
I0612 11:05:14.341059  4990 net.cpp:190] Creating Layer BatchNorm73
I0612 11:05:14.341063  4990 net.cpp:615] BatchNorm73 <- Convolution73
I0612 11:05:14.341073  4990 net.cpp:576] BatchNorm73 -> Convolution73 (in-place)
I0612 11:05:14.341287  4990 net.cpp:240] Setting up BatchNorm73
I0612 11:05:14.341295  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.341300  4990 net.cpp:255] Memory required for data: 2530739712
I0612 11:05:14.341311  4990 layer_factory.hpp:77] Creating layer Scale73
I0612 11:05:14.341323  4990 net.cpp:190] Creating Layer Scale73
I0612 11:05:14.341328  4990 net.cpp:615] Scale73 <- Convolution73
I0612 11:05:14.341334  4990 net.cpp:576] Scale73 -> Convolution73 (in-place)
I0612 11:05:14.341370  4990 layer_factory.hpp:77] Creating layer Scale73
I0612 11:05:14.341502  4990 net.cpp:240] Setting up Scale73
I0612 11:05:14.341511  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.341514  4990 net.cpp:255] Memory required for data: 2534934016
I0612 11:05:14.341523  4990 layer_factory.hpp:77] Creating layer Eltwise36
I0612 11:05:14.341531  4990 net.cpp:190] Creating Layer Eltwise36
I0612 11:05:14.341536  4990 net.cpp:615] Eltwise36 <- Eltwise35_ReLU71_0_split_1
I0612 11:05:14.341542  4990 net.cpp:615] Eltwise36 <- Convolution73
I0612 11:05:14.341550  4990 net.cpp:589] Eltwise36 -> Eltwise36
I0612 11:05:14.341572  4990 net.cpp:240] Setting up Eltwise36
I0612 11:05:14.341578  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.341583  4990 net.cpp:255] Memory required for data: 2539128320
I0612 11:05:14.341586  4990 layer_factory.hpp:77] Creating layer ReLU73
I0612 11:05:14.341596  4990 net.cpp:190] Creating Layer ReLU73
I0612 11:05:14.341600  4990 net.cpp:615] ReLU73 <- Eltwise36
I0612 11:05:14.341606  4990 net.cpp:576] ReLU73 -> Eltwise36 (in-place)
I0612 11:05:14.341612  4990 net.cpp:240] Setting up ReLU73
I0612 11:05:14.341619  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.341621  4990 net.cpp:255] Memory required for data: 2543322624
I0612 11:05:14.341625  4990 layer_factory.hpp:77] Creating layer Eltwise36_ReLU73_0_split
I0612 11:05:14.341631  4990 net.cpp:190] Creating Layer Eltwise36_ReLU73_0_split
I0612 11:05:14.341634  4990 net.cpp:615] Eltwise36_ReLU73_0_split <- Eltwise36
I0612 11:05:14.341644  4990 net.cpp:589] Eltwise36_ReLU73_0_split -> Eltwise36_ReLU73_0_split_0
I0612 11:05:14.341650  4990 net.cpp:589] Eltwise36_ReLU73_0_split -> Eltwise36_ReLU73_0_split_1
I0612 11:05:14.341691  4990 net.cpp:240] Setting up Eltwise36_ReLU73_0_split
I0612 11:05:14.341696  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.341701  4990 net.cpp:247] Top shape: 128 32 16 16 (1048576)
I0612 11:05:14.341706  4990 net.cpp:255] Memory required for data: 2551711232
I0612 11:05:14.341712  4990 layer_factory.hpp:77] Creating layer Pooling2
I0612 11:05:14.341722  4990 net.cpp:190] Creating Layer Pooling2
I0612 11:05:14.341727  4990 net.cpp:615] Pooling2 <- Eltwise36_ReLU73_0_split_0
I0612 11:05:14.341733  4990 net.cpp:589] Pooling2 -> Pooling2
I0612 11:05:14.341759  4990 net.cpp:240] Setting up Pooling2
I0612 11:05:14.341766  4990 net.cpp:247] Top shape: 128 32 8 8 (262144)
I0612 11:05:14.341769  4990 net.cpp:255] Memory required for data: 2552759808
I0612 11:05:14.341773  4990 layer_factory.hpp:77] Creating layer Input2
I0612 11:05:14.341781  4990 net.cpp:190] Creating Layer Input2
I0612 11:05:14.341790  4990 net.cpp:589] Input2 -> Input2
I0612 11:05:14.341820  4990 net.cpp:240] Setting up Input2
I0612 11:05:14.341826  4990 net.cpp:247] Top shape: 128 32 8 8 (262144)
I0612 11:05:14.341830  4990 net.cpp:255] Memory required for data: 2553808384
I0612 11:05:14.341833  4990 layer_factory.hpp:77] Creating layer Concat2
I0612 11:05:14.341840  4990 net.cpp:190] Creating Layer Concat2
I0612 11:05:14.341845  4990 net.cpp:615] Concat2 <- Pooling2
I0612 11:05:14.341850  4990 net.cpp:615] Concat2 <- Input2
I0612 11:05:14.341858  4990 net.cpp:589] Concat2 -> Concat2
I0612 11:05:14.341884  4990 net.cpp:240] Setting up Concat2
I0612 11:05:14.341893  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.341897  4990 net.cpp:255] Memory required for data: 2555905536
I0612 11:05:14.341902  4990 layer_factory.hpp:77] Creating layer Convolution74
I0612 11:05:14.341910  4990 net.cpp:190] Creating Layer Convolution74
I0612 11:05:14.341914  4990 net.cpp:615] Convolution74 <- Eltwise36_ReLU73_0_split_1
I0612 11:05:14.341924  4990 net.cpp:589] Convolution74 -> Convolution74
I0612 11:05:14.342917  4990 net.cpp:240] Setting up Convolution74
I0612 11:05:14.342928  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.342932  4990 net.cpp:255] Memory required for data: 2558002688
I0612 11:05:14.342999  4990 layer_factory.hpp:77] Creating layer BatchNorm74
I0612 11:05:14.343017  4990 net.cpp:190] Creating Layer BatchNorm74
I0612 11:05:14.343024  4990 net.cpp:615] BatchNorm74 <- Convolution74
I0612 11:05:14.343029  4990 net.cpp:576] BatchNorm74 -> Convolution74 (in-place)
I0612 11:05:14.343268  4990 net.cpp:240] Setting up BatchNorm74
I0612 11:05:14.343277  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.343281  4990 net.cpp:255] Memory required for data: 2560099840
I0612 11:05:14.343293  4990 layer_factory.hpp:77] Creating layer Scale74
I0612 11:05:14.343302  4990 net.cpp:190] Creating Layer Scale74
I0612 11:05:14.343308  4990 net.cpp:615] Scale74 <- Convolution74
I0612 11:05:14.343314  4990 net.cpp:576] Scale74 -> Convolution74 (in-place)
I0612 11:05:14.343353  4990 layer_factory.hpp:77] Creating layer Scale74
I0612 11:05:14.343488  4990 net.cpp:240] Setting up Scale74
I0612 11:05:14.343497  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.343500  4990 net.cpp:255] Memory required for data: 2562196992
I0612 11:05:14.343510  4990 layer_factory.hpp:77] Creating layer ReLU74
I0612 11:05:14.343519  4990 net.cpp:190] Creating Layer ReLU74
I0612 11:05:14.343525  4990 net.cpp:615] ReLU74 <- Convolution74
I0612 11:05:14.343530  4990 net.cpp:576] ReLU74 -> Convolution74 (in-place)
I0612 11:05:14.343538  4990 net.cpp:240] Setting up ReLU74
I0612 11:05:14.343544  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.343546  4990 net.cpp:255] Memory required for data: 2564294144
I0612 11:05:14.343550  4990 layer_factory.hpp:77] Creating layer Convolution75
I0612 11:05:14.343562  4990 net.cpp:190] Creating Layer Convolution75
I0612 11:05:14.343567  4990 net.cpp:615] Convolution75 <- Convolution74
I0612 11:05:14.343574  4990 net.cpp:589] Convolution75 -> Convolution75
I0612 11:05:14.345214  4990 net.cpp:240] Setting up Convolution75
I0612 11:05:14.345224  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.345228  4990 net.cpp:255] Memory required for data: 2566391296
I0612 11:05:14.345238  4990 layer_factory.hpp:77] Creating layer BatchNorm75
I0612 11:05:14.345252  4990 net.cpp:190] Creating Layer BatchNorm75
I0612 11:05:14.345257  4990 net.cpp:615] BatchNorm75 <- Convolution75
I0612 11:05:14.345263  4990 net.cpp:576] BatchNorm75 -> Convolution75 (in-place)
I0612 11:05:14.345487  4990 net.cpp:240] Setting up BatchNorm75
I0612 11:05:14.345496  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.345500  4990 net.cpp:255] Memory required for data: 2568488448
I0612 11:05:14.345511  4990 layer_factory.hpp:77] Creating layer Scale75
I0612 11:05:14.345518  4990 net.cpp:190] Creating Layer Scale75
I0612 11:05:14.345523  4990 net.cpp:615] Scale75 <- Convolution75
I0612 11:05:14.345528  4990 net.cpp:576] Scale75 -> Convolution75 (in-place)
I0612 11:05:14.345572  4990 layer_factory.hpp:77] Creating layer Scale75
I0612 11:05:14.345705  4990 net.cpp:240] Setting up Scale75
I0612 11:05:14.345712  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.345716  4990 net.cpp:255] Memory required for data: 2570585600
I0612 11:05:14.345727  4990 layer_factory.hpp:77] Creating layer Eltwise37
I0612 11:05:14.345734  4990 net.cpp:190] Creating Layer Eltwise37
I0612 11:05:14.345739  4990 net.cpp:615] Eltwise37 <- Concat2
I0612 11:05:14.345746  4990 net.cpp:615] Eltwise37 <- Convolution75
I0612 11:05:14.345752  4990 net.cpp:589] Eltwise37 -> Eltwise37
I0612 11:05:14.345777  4990 net.cpp:240] Setting up Eltwise37
I0612 11:05:14.345784  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.345788  4990 net.cpp:255] Memory required for data: 2572682752
I0612 11:05:14.345793  4990 layer_factory.hpp:77] Creating layer ReLU75
I0612 11:05:14.345798  4990 net.cpp:190] Creating Layer ReLU75
I0612 11:05:14.345803  4990 net.cpp:615] ReLU75 <- Eltwise37
I0612 11:05:14.345813  4990 net.cpp:576] ReLU75 -> Eltwise37 (in-place)
I0612 11:05:14.345820  4990 net.cpp:240] Setting up ReLU75
I0612 11:05:14.345825  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.345829  4990 net.cpp:255] Memory required for data: 2574779904
I0612 11:05:14.345834  4990 layer_factory.hpp:77] Creating layer Eltwise37_ReLU75_0_split
I0612 11:05:14.345839  4990 net.cpp:190] Creating Layer Eltwise37_ReLU75_0_split
I0612 11:05:14.345844  4990 net.cpp:615] Eltwise37_ReLU75_0_split <- Eltwise37
I0612 11:05:14.345849  4990 net.cpp:589] Eltwise37_ReLU75_0_split -> Eltwise37_ReLU75_0_split_0
I0612 11:05:14.345855  4990 net.cpp:589] Eltwise37_ReLU75_0_split -> Eltwise37_ReLU75_0_split_1
I0612 11:05:14.345899  4990 net.cpp:240] Setting up Eltwise37_ReLU75_0_split
I0612 11:05:14.345906  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.345911  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.345916  4990 net.cpp:255] Memory required for data: 2578974208
I0612 11:05:14.345919  4990 layer_factory.hpp:77] Creating layer Convolution76
I0612 11:05:14.345930  4990 net.cpp:190] Creating Layer Convolution76
I0612 11:05:14.345935  4990 net.cpp:615] Convolution76 <- Eltwise37_ReLU75_0_split_0
I0612 11:05:14.345942  4990 net.cpp:589] Convolution76 -> Convolution76
I0612 11:05:14.347604  4990 net.cpp:240] Setting up Convolution76
I0612 11:05:14.347615  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.347618  4990 net.cpp:255] Memory required for data: 2581071360
I0612 11:05:14.347628  4990 layer_factory.hpp:77] Creating layer BatchNorm76
I0612 11:05:14.347638  4990 net.cpp:190] Creating Layer BatchNorm76
I0612 11:05:14.347643  4990 net.cpp:615] BatchNorm76 <- Convolution76
I0612 11:05:14.347651  4990 net.cpp:576] BatchNorm76 -> Convolution76 (in-place)
I0612 11:05:14.347872  4990 net.cpp:240] Setting up BatchNorm76
I0612 11:05:14.347880  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.347883  4990 net.cpp:255] Memory required for data: 2583168512
I0612 11:05:14.347898  4990 layer_factory.hpp:77] Creating layer Scale76
I0612 11:05:14.347905  4990 net.cpp:190] Creating Layer Scale76
I0612 11:05:14.347910  4990 net.cpp:615] Scale76 <- Convolution76
I0612 11:05:14.347916  4990 net.cpp:576] Scale76 -> Convolution76 (in-place)
I0612 11:05:14.347956  4990 layer_factory.hpp:77] Creating layer Scale76
I0612 11:05:14.348096  4990 net.cpp:240] Setting up Scale76
I0612 11:05:14.348104  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.348109  4990 net.cpp:255] Memory required for data: 2585265664
I0612 11:05:14.348119  4990 layer_factory.hpp:77] Creating layer ReLU76
I0612 11:05:14.348124  4990 net.cpp:190] Creating Layer ReLU76
I0612 11:05:14.348129  4990 net.cpp:615] ReLU76 <- Convolution76
I0612 11:05:14.348137  4990 net.cpp:576] ReLU76 -> Convolution76 (in-place)
I0612 11:05:14.348145  4990 net.cpp:240] Setting up ReLU76
I0612 11:05:14.348150  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.348153  4990 net.cpp:255] Memory required for data: 2587362816
I0612 11:05:14.348157  4990 layer_factory.hpp:77] Creating layer Convolution77
I0612 11:05:14.348166  4990 net.cpp:190] Creating Layer Convolution77
I0612 11:05:14.348170  4990 net.cpp:615] Convolution77 <- Convolution76
I0612 11:05:14.348179  4990 net.cpp:589] Convolution77 -> Convolution77
I0612 11:05:14.349818  4990 net.cpp:240] Setting up Convolution77
I0612 11:05:14.349829  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.349833  4990 net.cpp:255] Memory required for data: 2589459968
I0612 11:05:14.349843  4990 layer_factory.hpp:77] Creating layer BatchNorm77
I0612 11:05:14.349849  4990 net.cpp:190] Creating Layer BatchNorm77
I0612 11:05:14.349854  4990 net.cpp:615] BatchNorm77 <- Convolution77
I0612 11:05:14.349864  4990 net.cpp:576] BatchNorm77 -> Convolution77 (in-place)
I0612 11:05:14.350093  4990 net.cpp:240] Setting up BatchNorm77
I0612 11:05:14.350102  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.350106  4990 net.cpp:255] Memory required for data: 2591557120
I0612 11:05:14.350117  4990 layer_factory.hpp:77] Creating layer Scale77
I0612 11:05:14.350126  4990 net.cpp:190] Creating Layer Scale77
I0612 11:05:14.350129  4990 net.cpp:615] Scale77 <- Convolution77
I0612 11:05:14.350137  4990 net.cpp:576] Scale77 -> Convolution77 (in-place)
I0612 11:05:14.350177  4990 layer_factory.hpp:77] Creating layer Scale77
I0612 11:05:14.350312  4990 net.cpp:240] Setting up Scale77
I0612 11:05:14.350319  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.350323  4990 net.cpp:255] Memory required for data: 2593654272
I0612 11:05:14.350332  4990 layer_factory.hpp:77] Creating layer Eltwise38
I0612 11:05:14.350339  4990 net.cpp:190] Creating Layer Eltwise38
I0612 11:05:14.350344  4990 net.cpp:615] Eltwise38 <- Eltwise37_ReLU75_0_split_1
I0612 11:05:14.350350  4990 net.cpp:615] Eltwise38 <- Convolution77
I0612 11:05:14.350368  4990 net.cpp:589] Eltwise38 -> Eltwise38
I0612 11:05:14.350391  4990 net.cpp:240] Setting up Eltwise38
I0612 11:05:14.350400  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.350404  4990 net.cpp:255] Memory required for data: 2595751424
I0612 11:05:14.350409  4990 layer_factory.hpp:77] Creating layer ReLU77
I0612 11:05:14.350414  4990 net.cpp:190] Creating Layer ReLU77
I0612 11:05:14.350419  4990 net.cpp:615] ReLU77 <- Eltwise38
I0612 11:05:14.350424  4990 net.cpp:576] ReLU77 -> Eltwise38 (in-place)
I0612 11:05:14.350430  4990 net.cpp:240] Setting up ReLU77
I0612 11:05:14.350435  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.350440  4990 net.cpp:255] Memory required for data: 2597848576
I0612 11:05:14.350442  4990 layer_factory.hpp:77] Creating layer Eltwise38_ReLU77_0_split
I0612 11:05:14.350448  4990 net.cpp:190] Creating Layer Eltwise38_ReLU77_0_split
I0612 11:05:14.350452  4990 net.cpp:615] Eltwise38_ReLU77_0_split <- Eltwise38
I0612 11:05:14.350460  4990 net.cpp:589] Eltwise38_ReLU77_0_split -> Eltwise38_ReLU77_0_split_0
I0612 11:05:14.350467  4990 net.cpp:589] Eltwise38_ReLU77_0_split -> Eltwise38_ReLU77_0_split_1
I0612 11:05:14.350507  4990 net.cpp:240] Setting up Eltwise38_ReLU77_0_split
I0612 11:05:14.350514  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.350519  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.350522  4990 net.cpp:255] Memory required for data: 2602042880
I0612 11:05:14.350530  4990 layer_factory.hpp:77] Creating layer Convolution78
I0612 11:05:14.350543  4990 net.cpp:190] Creating Layer Convolution78
I0612 11:05:14.350546  4990 net.cpp:615] Convolution78 <- Eltwise38_ReLU77_0_split_0
I0612 11:05:14.350554  4990 net.cpp:589] Convolution78 -> Convolution78
I0612 11:05:14.352201  4990 net.cpp:240] Setting up Convolution78
I0612 11:05:14.352211  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.352215  4990 net.cpp:255] Memory required for data: 2604140032
I0612 11:05:14.352224  4990 layer_factory.hpp:77] Creating layer BatchNorm78
I0612 11:05:14.352233  4990 net.cpp:190] Creating Layer BatchNorm78
I0612 11:05:14.352238  4990 net.cpp:615] BatchNorm78 <- Convolution78
I0612 11:05:14.352244  4990 net.cpp:576] BatchNorm78 -> Convolution78 (in-place)
I0612 11:05:14.352473  4990 net.cpp:240] Setting up BatchNorm78
I0612 11:05:14.352480  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.352484  4990 net.cpp:255] Memory required for data: 2606237184
I0612 11:05:14.352496  4990 layer_factory.hpp:77] Creating layer Scale78
I0612 11:05:14.352504  4990 net.cpp:190] Creating Layer Scale78
I0612 11:05:14.352509  4990 net.cpp:615] Scale78 <- Convolution78
I0612 11:05:14.352514  4990 net.cpp:576] Scale78 -> Convolution78 (in-place)
I0612 11:05:14.352557  4990 layer_factory.hpp:77] Creating layer Scale78
I0612 11:05:14.352695  4990 net.cpp:240] Setting up Scale78
I0612 11:05:14.352704  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.352707  4990 net.cpp:255] Memory required for data: 2608334336
I0612 11:05:14.352718  4990 layer_factory.hpp:77] Creating layer ReLU78
I0612 11:05:14.352725  4990 net.cpp:190] Creating Layer ReLU78
I0612 11:05:14.352730  4990 net.cpp:615] ReLU78 <- Convolution78
I0612 11:05:14.352735  4990 net.cpp:576] ReLU78 -> Convolution78 (in-place)
I0612 11:05:14.352742  4990 net.cpp:240] Setting up ReLU78
I0612 11:05:14.352747  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.352751  4990 net.cpp:255] Memory required for data: 2610431488
I0612 11:05:14.352754  4990 layer_factory.hpp:77] Creating layer Convolution79
I0612 11:05:14.352766  4990 net.cpp:190] Creating Layer Convolution79
I0612 11:05:14.352771  4990 net.cpp:615] Convolution79 <- Convolution78
I0612 11:05:14.352779  4990 net.cpp:589] Convolution79 -> Convolution79
I0612 11:05:14.354446  4990 net.cpp:240] Setting up Convolution79
I0612 11:05:14.354457  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.354461  4990 net.cpp:255] Memory required for data: 2612528640
I0612 11:05:14.354471  4990 layer_factory.hpp:77] Creating layer BatchNorm79
I0612 11:05:14.354480  4990 net.cpp:190] Creating Layer BatchNorm79
I0612 11:05:14.354485  4990 net.cpp:615] BatchNorm79 <- Convolution79
I0612 11:05:14.354493  4990 net.cpp:576] BatchNorm79 -> Convolution79 (in-place)
I0612 11:05:14.355388  4990 net.cpp:240] Setting up BatchNorm79
I0612 11:05:14.355404  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.355408  4990 net.cpp:255] Memory required for data: 2614625792
I0612 11:05:14.355422  4990 layer_factory.hpp:77] Creating layer Scale79
I0612 11:05:14.355430  4990 net.cpp:190] Creating Layer Scale79
I0612 11:05:14.355437  4990 net.cpp:615] Scale79 <- Convolution79
I0612 11:05:14.355443  4990 net.cpp:576] Scale79 -> Convolution79 (in-place)
I0612 11:05:14.355489  4990 layer_factory.hpp:77] Creating layer Scale79
I0612 11:05:14.355628  4990 net.cpp:240] Setting up Scale79
I0612 11:05:14.355635  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.355639  4990 net.cpp:255] Memory required for data: 2616722944
I0612 11:05:14.355649  4990 layer_factory.hpp:77] Creating layer Eltwise39
I0612 11:05:14.355659  4990 net.cpp:190] Creating Layer Eltwise39
I0612 11:05:14.355664  4990 net.cpp:615] Eltwise39 <- Eltwise38_ReLU77_0_split_1
I0612 11:05:14.355670  4990 net.cpp:615] Eltwise39 <- Convolution79
I0612 11:05:14.355677  4990 net.cpp:589] Eltwise39 -> Eltwise39
I0612 11:05:14.355698  4990 net.cpp:240] Setting up Eltwise39
I0612 11:05:14.355710  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.355713  4990 net.cpp:255] Memory required for data: 2618820096
I0612 11:05:14.355717  4990 layer_factory.hpp:77] Creating layer ReLU79
I0612 11:05:14.355726  4990 net.cpp:190] Creating Layer ReLU79
I0612 11:05:14.355731  4990 net.cpp:615] ReLU79 <- Eltwise39
I0612 11:05:14.355736  4990 net.cpp:576] ReLU79 -> Eltwise39 (in-place)
I0612 11:05:14.355743  4990 net.cpp:240] Setting up ReLU79
I0612 11:05:14.355749  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.355753  4990 net.cpp:255] Memory required for data: 2620917248
I0612 11:05:14.355756  4990 layer_factory.hpp:77] Creating layer Eltwise39_ReLU79_0_split
I0612 11:05:14.355764  4990 net.cpp:190] Creating Layer Eltwise39_ReLU79_0_split
I0612 11:05:14.355768  4990 net.cpp:615] Eltwise39_ReLU79_0_split <- Eltwise39
I0612 11:05:14.355774  4990 net.cpp:589] Eltwise39_ReLU79_0_split -> Eltwise39_ReLU79_0_split_0
I0612 11:05:14.355782  4990 net.cpp:589] Eltwise39_ReLU79_0_split -> Eltwise39_ReLU79_0_split_1
I0612 11:05:14.355823  4990 net.cpp:240] Setting up Eltwise39_ReLU79_0_split
I0612 11:05:14.355830  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.355835  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.355839  4990 net.cpp:255] Memory required for data: 2625111552
I0612 11:05:14.355842  4990 layer_factory.hpp:77] Creating layer Convolution80
I0612 11:05:14.355854  4990 net.cpp:190] Creating Layer Convolution80
I0612 11:05:14.355859  4990 net.cpp:615] Convolution80 <- Eltwise39_ReLU79_0_split_0
I0612 11:05:14.355867  4990 net.cpp:589] Convolution80 -> Convolution80
I0612 11:05:14.358176  4990 net.cpp:240] Setting up Convolution80
I0612 11:05:14.358192  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.358196  4990 net.cpp:255] Memory required for data: 2627208704
I0612 11:05:14.358208  4990 layer_factory.hpp:77] Creating layer BatchNorm80
I0612 11:05:14.358218  4990 net.cpp:190] Creating Layer BatchNorm80
I0612 11:05:14.358224  4990 net.cpp:615] BatchNorm80 <- Convolution80
I0612 11:05:14.358232  4990 net.cpp:576] BatchNorm80 -> Convolution80 (in-place)
I0612 11:05:14.358477  4990 net.cpp:240] Setting up BatchNorm80
I0612 11:05:14.358487  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.358491  4990 net.cpp:255] Memory required for data: 2629305856
I0612 11:05:14.358503  4990 layer_factory.hpp:77] Creating layer Scale80
I0612 11:05:14.358511  4990 net.cpp:190] Creating Layer Scale80
I0612 11:05:14.358515  4990 net.cpp:615] Scale80 <- Convolution80
I0612 11:05:14.358521  4990 net.cpp:576] Scale80 -> Convolution80 (in-place)
I0612 11:05:14.358568  4990 layer_factory.hpp:77] Creating layer Scale80
I0612 11:05:14.358710  4990 net.cpp:240] Setting up Scale80
I0612 11:05:14.358721  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.358724  4990 net.cpp:255] Memory required for data: 2631403008
I0612 11:05:14.358734  4990 layer_factory.hpp:77] Creating layer ReLU80
I0612 11:05:14.358741  4990 net.cpp:190] Creating Layer ReLU80
I0612 11:05:14.358747  4990 net.cpp:615] ReLU80 <- Convolution80
I0612 11:05:14.358752  4990 net.cpp:576] ReLU80 -> Convolution80 (in-place)
I0612 11:05:14.358759  4990 net.cpp:240] Setting up ReLU80
I0612 11:05:14.358764  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.358768  4990 net.cpp:255] Memory required for data: 2633500160
I0612 11:05:14.358772  4990 layer_factory.hpp:77] Creating layer Convolution81
I0612 11:05:14.358784  4990 net.cpp:190] Creating Layer Convolution81
I0612 11:05:14.358788  4990 net.cpp:615] Convolution81 <- Convolution80
I0612 11:05:14.358798  4990 net.cpp:589] Convolution81 -> Convolution81
I0612 11:05:14.360437  4990 net.cpp:240] Setting up Convolution81
I0612 11:05:14.360447  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.360451  4990 net.cpp:255] Memory required for data: 2635597312
I0612 11:05:14.360461  4990 layer_factory.hpp:77] Creating layer BatchNorm81
I0612 11:05:14.360471  4990 net.cpp:190] Creating Layer BatchNorm81
I0612 11:05:14.360481  4990 net.cpp:615] BatchNorm81 <- Convolution81
I0612 11:05:14.360489  4990 net.cpp:576] BatchNorm81 -> Convolution81 (in-place)
I0612 11:05:14.360718  4990 net.cpp:240] Setting up BatchNorm81
I0612 11:05:14.360726  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.360730  4990 net.cpp:255] Memory required for data: 2637694464
I0612 11:05:14.360744  4990 layer_factory.hpp:77] Creating layer Scale81
I0612 11:05:14.360752  4990 net.cpp:190] Creating Layer Scale81
I0612 11:05:14.360756  4990 net.cpp:615] Scale81 <- Convolution81
I0612 11:05:14.360762  4990 net.cpp:576] Scale81 -> Convolution81 (in-place)
I0612 11:05:14.360803  4990 layer_factory.hpp:77] Creating layer Scale81
I0612 11:05:14.360940  4990 net.cpp:240] Setting up Scale81
I0612 11:05:14.360949  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.360951  4990 net.cpp:255] Memory required for data: 2639791616
I0612 11:05:14.360963  4990 layer_factory.hpp:77] Creating layer Eltwise40
I0612 11:05:14.360971  4990 net.cpp:190] Creating Layer Eltwise40
I0612 11:05:14.360976  4990 net.cpp:615] Eltwise40 <- Eltwise39_ReLU79_0_split_1
I0612 11:05:14.360982  4990 net.cpp:615] Eltwise40 <- Convolution81
I0612 11:05:14.360991  4990 net.cpp:589] Eltwise40 -> Eltwise40
I0612 11:05:14.361012  4990 net.cpp:240] Setting up Eltwise40
I0612 11:05:14.361019  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.361023  4990 net.cpp:255] Memory required for data: 2641888768
I0612 11:05:14.361027  4990 layer_factory.hpp:77] Creating layer ReLU81
I0612 11:05:14.361033  4990 net.cpp:190] Creating Layer ReLU81
I0612 11:05:14.361037  4990 net.cpp:615] ReLU81 <- Eltwise40
I0612 11:05:14.361045  4990 net.cpp:576] ReLU81 -> Eltwise40 (in-place)
I0612 11:05:14.361052  4990 net.cpp:240] Setting up ReLU81
I0612 11:05:14.361057  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.361062  4990 net.cpp:255] Memory required for data: 2643985920
I0612 11:05:14.361064  4990 layer_factory.hpp:77] Creating layer Eltwise40_ReLU81_0_split
I0612 11:05:14.361070  4990 net.cpp:190] Creating Layer Eltwise40_ReLU81_0_split
I0612 11:05:14.361074  4990 net.cpp:615] Eltwise40_ReLU81_0_split <- Eltwise40
I0612 11:05:14.361079  4990 net.cpp:589] Eltwise40_ReLU81_0_split -> Eltwise40_ReLU81_0_split_0
I0612 11:05:14.361088  4990 net.cpp:589] Eltwise40_ReLU81_0_split -> Eltwise40_ReLU81_0_split_1
I0612 11:05:14.361129  4990 net.cpp:240] Setting up Eltwise40_ReLU81_0_split
I0612 11:05:14.361136  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.361141  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.361145  4990 net.cpp:255] Memory required for data: 2648180224
I0612 11:05:14.361148  4990 layer_factory.hpp:77] Creating layer Convolution82
I0612 11:05:14.361158  4990 net.cpp:190] Creating Layer Convolution82
I0612 11:05:14.361162  4990 net.cpp:615] Convolution82 <- Eltwise40_ReLU81_0_split_0
I0612 11:05:14.361174  4990 net.cpp:589] Convolution82 -> Convolution82
I0612 11:05:14.362823  4990 net.cpp:240] Setting up Convolution82
I0612 11:05:14.362833  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.362838  4990 net.cpp:255] Memory required for data: 2650277376
I0612 11:05:14.362848  4990 layer_factory.hpp:77] Creating layer BatchNorm82
I0612 11:05:14.362854  4990 net.cpp:190] Creating Layer BatchNorm82
I0612 11:05:14.362859  4990 net.cpp:615] BatchNorm82 <- Convolution82
I0612 11:05:14.362867  4990 net.cpp:576] BatchNorm82 -> Convolution82 (in-place)
I0612 11:05:14.363100  4990 net.cpp:240] Setting up BatchNorm82
I0612 11:05:14.363108  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.363111  4990 net.cpp:255] Memory required for data: 2652374528
I0612 11:05:14.363123  4990 layer_factory.hpp:77] Creating layer Scale82
I0612 11:05:14.363133  4990 net.cpp:190] Creating Layer Scale82
I0612 11:05:14.363138  4990 net.cpp:615] Scale82 <- Convolution82
I0612 11:05:14.363144  4990 net.cpp:576] Scale82 -> Convolution82 (in-place)
I0612 11:05:14.363183  4990 layer_factory.hpp:77] Creating layer Scale82
I0612 11:05:14.363325  4990 net.cpp:240] Setting up Scale82
I0612 11:05:14.363333  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.363337  4990 net.cpp:255] Memory required for data: 2654471680
I0612 11:05:14.363348  4990 layer_factory.hpp:77] Creating layer ReLU82
I0612 11:05:14.363353  4990 net.cpp:190] Creating Layer ReLU82
I0612 11:05:14.363358  4990 net.cpp:615] ReLU82 <- Convolution82
I0612 11:05:14.363366  4990 net.cpp:576] ReLU82 -> Convolution82 (in-place)
I0612 11:05:14.363374  4990 net.cpp:240] Setting up ReLU82
I0612 11:05:14.363379  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.363384  4990 net.cpp:255] Memory required for data: 2656568832
I0612 11:05:14.363386  4990 layer_factory.hpp:77] Creating layer Convolution83
I0612 11:05:14.363399  4990 net.cpp:190] Creating Layer Convolution83
I0612 11:05:14.363402  4990 net.cpp:615] Convolution83 <- Convolution82
I0612 11:05:14.363409  4990 net.cpp:589] Convolution83 -> Convolution83
I0612 11:05:14.365048  4990 net.cpp:240] Setting up Convolution83
I0612 11:05:14.365058  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.365062  4990 net.cpp:255] Memory required for data: 2658665984
I0612 11:05:14.365072  4990 layer_factory.hpp:77] Creating layer BatchNorm83
I0612 11:05:14.365082  4990 net.cpp:190] Creating Layer BatchNorm83
I0612 11:05:14.365087  4990 net.cpp:615] BatchNorm83 <- Convolution83
I0612 11:05:14.365092  4990 net.cpp:576] BatchNorm83 -> Convolution83 (in-place)
I0612 11:05:14.365322  4990 net.cpp:240] Setting up BatchNorm83
I0612 11:05:14.365330  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.365334  4990 net.cpp:255] Memory required for data: 2660763136
I0612 11:05:14.365346  4990 layer_factory.hpp:77] Creating layer Scale83
I0612 11:05:14.365353  4990 net.cpp:190] Creating Layer Scale83
I0612 11:05:14.365357  4990 net.cpp:615] Scale83 <- Convolution83
I0612 11:05:14.365363  4990 net.cpp:576] Scale83 -> Convolution83 (in-place)
I0612 11:05:14.365406  4990 layer_factory.hpp:77] Creating layer Scale83
I0612 11:05:14.365541  4990 net.cpp:240] Setting up Scale83
I0612 11:05:14.365550  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.365552  4990 net.cpp:255] Memory required for data: 2662860288
I0612 11:05:14.365562  4990 layer_factory.hpp:77] Creating layer Eltwise41
I0612 11:05:14.365571  4990 net.cpp:190] Creating Layer Eltwise41
I0612 11:05:14.365577  4990 net.cpp:615] Eltwise41 <- Eltwise40_ReLU81_0_split_1
I0612 11:05:14.365582  4990 net.cpp:615] Eltwise41 <- Convolution83
I0612 11:05:14.365588  4990 net.cpp:589] Eltwise41 -> Eltwise41
I0612 11:05:14.365609  4990 net.cpp:240] Setting up Eltwise41
I0612 11:05:14.365617  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.365620  4990 net.cpp:255] Memory required for data: 2664957440
I0612 11:05:14.365623  4990 layer_factory.hpp:77] Creating layer ReLU83
I0612 11:05:14.365633  4990 net.cpp:190] Creating Layer ReLU83
I0612 11:05:14.365638  4990 net.cpp:615] ReLU83 <- Eltwise41
I0612 11:05:14.365644  4990 net.cpp:576] ReLU83 -> Eltwise41 (in-place)
I0612 11:05:14.365651  4990 net.cpp:240] Setting up ReLU83
I0612 11:05:14.365656  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.365660  4990 net.cpp:255] Memory required for data: 2667054592
I0612 11:05:14.365664  4990 layer_factory.hpp:77] Creating layer Eltwise41_ReLU83_0_split
I0612 11:05:14.365669  4990 net.cpp:190] Creating Layer Eltwise41_ReLU83_0_split
I0612 11:05:14.365674  4990 net.cpp:615] Eltwise41_ReLU83_0_split <- Eltwise41
I0612 11:05:14.365679  4990 net.cpp:589] Eltwise41_ReLU83_0_split -> Eltwise41_ReLU83_0_split_0
I0612 11:05:14.365686  4990 net.cpp:589] Eltwise41_ReLU83_0_split -> Eltwise41_ReLU83_0_split_1
I0612 11:05:14.365727  4990 net.cpp:240] Setting up Eltwise41_ReLU83_0_split
I0612 11:05:14.365734  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.365739  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.365742  4990 net.cpp:255] Memory required for data: 2671248896
I0612 11:05:14.365746  4990 layer_factory.hpp:77] Creating layer Convolution84
I0612 11:05:14.365761  4990 net.cpp:190] Creating Layer Convolution84
I0612 11:05:14.365767  4990 net.cpp:615] Convolution84 <- Eltwise41_ReLU83_0_split_0
I0612 11:05:14.365773  4990 net.cpp:589] Convolution84 -> Convolution84
I0612 11:05:14.369786  4990 net.cpp:240] Setting up Convolution84
I0612 11:05:14.369827  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.369832  4990 net.cpp:255] Memory required for data: 2673346048
I0612 11:05:14.369860  4990 layer_factory.hpp:77] Creating layer BatchNorm84
I0612 11:05:14.369889  4990 net.cpp:190] Creating Layer BatchNorm84
I0612 11:05:14.369907  4990 net.cpp:615] BatchNorm84 <- Convolution84
I0612 11:05:14.369918  4990 net.cpp:576] BatchNorm84 -> Convolution84 (in-place)
I0612 11:05:14.370151  4990 net.cpp:240] Setting up BatchNorm84
I0612 11:05:14.370160  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.370164  4990 net.cpp:255] Memory required for data: 2675443200
I0612 11:05:14.370182  4990 layer_factory.hpp:77] Creating layer Scale84
I0612 11:05:14.370192  4990 net.cpp:190] Creating Layer Scale84
I0612 11:05:14.370196  4990 net.cpp:615] Scale84 <- Convolution84
I0612 11:05:14.370203  4990 net.cpp:576] Scale84 -> Convolution84 (in-place)
I0612 11:05:14.370245  4990 layer_factory.hpp:77] Creating layer Scale84
I0612 11:05:14.370393  4990 net.cpp:240] Setting up Scale84
I0612 11:05:14.370401  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.370405  4990 net.cpp:255] Memory required for data: 2677540352
I0612 11:05:14.370419  4990 layer_factory.hpp:77] Creating layer ReLU84
I0612 11:05:14.370425  4990 net.cpp:190] Creating Layer ReLU84
I0612 11:05:14.370431  4990 net.cpp:615] ReLU84 <- Convolution84
I0612 11:05:14.370440  4990 net.cpp:576] ReLU84 -> Convolution84 (in-place)
I0612 11:05:14.370446  4990 net.cpp:240] Setting up ReLU84
I0612 11:05:14.370452  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.370455  4990 net.cpp:255] Memory required for data: 2679637504
I0612 11:05:14.370460  4990 layer_factory.hpp:77] Creating layer Convolution85
I0612 11:05:14.370472  4990 net.cpp:190] Creating Layer Convolution85
I0612 11:05:14.370476  4990 net.cpp:615] Convolution85 <- Convolution84
I0612 11:05:14.370486  4990 net.cpp:589] Convolution85 -> Convolution85
I0612 11:05:14.372165  4990 net.cpp:240] Setting up Convolution85
I0612 11:05:14.372177  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.372181  4990 net.cpp:255] Memory required for data: 2681734656
I0612 11:05:14.372191  4990 layer_factory.hpp:77] Creating layer BatchNorm85
I0612 11:05:14.372200  4990 net.cpp:190] Creating Layer BatchNorm85
I0612 11:05:14.372205  4990 net.cpp:615] BatchNorm85 <- Convolution85
I0612 11:05:14.372215  4990 net.cpp:576] BatchNorm85 -> Convolution85 (in-place)
I0612 11:05:14.372447  4990 net.cpp:240] Setting up BatchNorm85
I0612 11:05:14.372454  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.372458  4990 net.cpp:255] Memory required for data: 2683831808
I0612 11:05:14.372473  4990 layer_factory.hpp:77] Creating layer Scale85
I0612 11:05:14.372481  4990 net.cpp:190] Creating Layer Scale85
I0612 11:05:14.372486  4990 net.cpp:615] Scale85 <- Convolution85
I0612 11:05:14.372494  4990 net.cpp:576] Scale85 -> Convolution85 (in-place)
I0612 11:05:14.372534  4990 layer_factory.hpp:77] Creating layer Scale85
I0612 11:05:14.372673  4990 net.cpp:240] Setting up Scale85
I0612 11:05:14.372683  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.372686  4990 net.cpp:255] Memory required for data: 2685928960
I0612 11:05:14.372695  4990 layer_factory.hpp:77] Creating layer Eltwise42
I0612 11:05:14.372704  4990 net.cpp:190] Creating Layer Eltwise42
I0612 11:05:14.372717  4990 net.cpp:615] Eltwise42 <- Eltwise41_ReLU83_0_split_1
I0612 11:05:14.372723  4990 net.cpp:615] Eltwise42 <- Convolution85
I0612 11:05:14.372732  4990 net.cpp:589] Eltwise42 -> Eltwise42
I0612 11:05:14.372756  4990 net.cpp:240] Setting up Eltwise42
I0612 11:05:14.372762  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.372771  4990 net.cpp:255] Memory required for data: 2688026112
I0612 11:05:14.372774  4990 layer_factory.hpp:77] Creating layer ReLU85
I0612 11:05:14.372784  4990 net.cpp:190] Creating Layer ReLU85
I0612 11:05:14.372789  4990 net.cpp:615] ReLU85 <- Eltwise42
I0612 11:05:14.372794  4990 net.cpp:576] ReLU85 -> Eltwise42 (in-place)
I0612 11:05:14.372802  4990 net.cpp:240] Setting up ReLU85
I0612 11:05:14.372807  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.372810  4990 net.cpp:255] Memory required for data: 2690123264
I0612 11:05:14.372814  4990 layer_factory.hpp:77] Creating layer Eltwise42_ReLU85_0_split
I0612 11:05:14.372820  4990 net.cpp:190] Creating Layer Eltwise42_ReLU85_0_split
I0612 11:05:14.372823  4990 net.cpp:615] Eltwise42_ReLU85_0_split <- Eltwise42
I0612 11:05:14.372831  4990 net.cpp:589] Eltwise42_ReLU85_0_split -> Eltwise42_ReLU85_0_split_0
I0612 11:05:14.372839  4990 net.cpp:589] Eltwise42_ReLU85_0_split -> Eltwise42_ReLU85_0_split_1
I0612 11:05:14.372881  4990 net.cpp:240] Setting up Eltwise42_ReLU85_0_split
I0612 11:05:14.372889  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.372894  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.372896  4990 net.cpp:255] Memory required for data: 2694317568
I0612 11:05:14.372901  4990 layer_factory.hpp:77] Creating layer Convolution86
I0612 11:05:14.372915  4990 net.cpp:190] Creating Layer Convolution86
I0612 11:05:14.372920  4990 net.cpp:615] Convolution86 <- Eltwise42_ReLU85_0_split_0
I0612 11:05:14.372927  4990 net.cpp:589] Convolution86 -> Convolution86
I0612 11:05:14.374582  4990 net.cpp:240] Setting up Convolution86
I0612 11:05:14.374593  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.374596  4990 net.cpp:255] Memory required for data: 2696414720
I0612 11:05:14.374606  4990 layer_factory.hpp:77] Creating layer BatchNorm86
I0612 11:05:14.374616  4990 net.cpp:190] Creating Layer BatchNorm86
I0612 11:05:14.374622  4990 net.cpp:615] BatchNorm86 <- Convolution86
I0612 11:05:14.374627  4990 net.cpp:576] BatchNorm86 -> Convolution86 (in-place)
I0612 11:05:14.374866  4990 net.cpp:240] Setting up BatchNorm86
I0612 11:05:14.374874  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.374878  4990 net.cpp:255] Memory required for data: 2698511872
I0612 11:05:14.374891  4990 layer_factory.hpp:77] Creating layer Scale86
I0612 11:05:14.374897  4990 net.cpp:190] Creating Layer Scale86
I0612 11:05:14.374902  4990 net.cpp:615] Scale86 <- Convolution86
I0612 11:05:14.374907  4990 net.cpp:576] Scale86 -> Convolution86 (in-place)
I0612 11:05:14.374953  4990 layer_factory.hpp:77] Creating layer Scale86
I0612 11:05:14.375090  4990 net.cpp:240] Setting up Scale86
I0612 11:05:14.375098  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.375102  4990 net.cpp:255] Memory required for data: 2700609024
I0612 11:05:14.375113  4990 layer_factory.hpp:77] Creating layer ReLU86
I0612 11:05:14.375123  4990 net.cpp:190] Creating Layer ReLU86
I0612 11:05:14.375128  4990 net.cpp:615] ReLU86 <- Convolution86
I0612 11:05:14.375133  4990 net.cpp:576] ReLU86 -> Convolution86 (in-place)
I0612 11:05:14.375139  4990 net.cpp:240] Setting up ReLU86
I0612 11:05:14.375145  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.375149  4990 net.cpp:255] Memory required for data: 2702706176
I0612 11:05:14.375154  4990 layer_factory.hpp:77] Creating layer Convolution87
I0612 11:05:14.375167  4990 net.cpp:190] Creating Layer Convolution87
I0612 11:05:14.375172  4990 net.cpp:615] Convolution87 <- Convolution86
I0612 11:05:14.375181  4990 net.cpp:589] Convolution87 -> Convolution87
I0612 11:05:14.377547  4990 net.cpp:240] Setting up Convolution87
I0612 11:05:14.377564  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.377569  4990 net.cpp:255] Memory required for data: 2704803328
I0612 11:05:14.377580  4990 layer_factory.hpp:77] Creating layer BatchNorm87
I0612 11:05:14.377593  4990 net.cpp:190] Creating Layer BatchNorm87
I0612 11:05:14.377599  4990 net.cpp:615] BatchNorm87 <- Convolution87
I0612 11:05:14.377609  4990 net.cpp:576] BatchNorm87 -> Convolution87 (in-place)
I0612 11:05:14.377846  4990 net.cpp:240] Setting up BatchNorm87
I0612 11:05:14.377856  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.377859  4990 net.cpp:255] Memory required for data: 2706900480
I0612 11:05:14.377872  4990 layer_factory.hpp:77] Creating layer Scale87
I0612 11:05:14.377882  4990 net.cpp:190] Creating Layer Scale87
I0612 11:05:14.377887  4990 net.cpp:615] Scale87 <- Convolution87
I0612 11:05:14.377892  4990 net.cpp:576] Scale87 -> Convolution87 (in-place)
I0612 11:05:14.377938  4990 layer_factory.hpp:77] Creating layer Scale87
I0612 11:05:14.378077  4990 net.cpp:240] Setting up Scale87
I0612 11:05:14.378084  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.378088  4990 net.cpp:255] Memory required for data: 2708997632
I0612 11:05:14.378099  4990 layer_factory.hpp:77] Creating layer Eltwise43
I0612 11:05:14.378110  4990 net.cpp:190] Creating Layer Eltwise43
I0612 11:05:14.378115  4990 net.cpp:615] Eltwise43 <- Eltwise42_ReLU85_0_split_1
I0612 11:05:14.378121  4990 net.cpp:615] Eltwise43 <- Convolution87
I0612 11:05:14.378128  4990 net.cpp:589] Eltwise43 -> Eltwise43
I0612 11:05:14.378152  4990 net.cpp:240] Setting up Eltwise43
I0612 11:05:14.378159  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.378163  4990 net.cpp:255] Memory required for data: 2711094784
I0612 11:05:14.378167  4990 layer_factory.hpp:77] Creating layer ReLU87
I0612 11:05:14.378175  4990 net.cpp:190] Creating Layer ReLU87
I0612 11:05:14.378180  4990 net.cpp:615] ReLU87 <- Eltwise43
I0612 11:05:14.378187  4990 net.cpp:576] ReLU87 -> Eltwise43 (in-place)
I0612 11:05:14.378195  4990 net.cpp:240] Setting up ReLU87
I0612 11:05:14.378199  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.378203  4990 net.cpp:255] Memory required for data: 2713191936
I0612 11:05:14.378207  4990 layer_factory.hpp:77] Creating layer Eltwise43_ReLU87_0_split
I0612 11:05:14.378213  4990 net.cpp:190] Creating Layer Eltwise43_ReLU87_0_split
I0612 11:05:14.378217  4990 net.cpp:615] Eltwise43_ReLU87_0_split <- Eltwise43
I0612 11:05:14.378222  4990 net.cpp:589] Eltwise43_ReLU87_0_split -> Eltwise43_ReLU87_0_split_0
I0612 11:05:14.378231  4990 net.cpp:589] Eltwise43_ReLU87_0_split -> Eltwise43_ReLU87_0_split_1
I0612 11:05:14.378271  4990 net.cpp:240] Setting up Eltwise43_ReLU87_0_split
I0612 11:05:14.378278  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.378283  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.378288  4990 net.cpp:255] Memory required for data: 2717386240
I0612 11:05:14.378291  4990 layer_factory.hpp:77] Creating layer Convolution88
I0612 11:05:14.378304  4990 net.cpp:190] Creating Layer Convolution88
I0612 11:05:14.378310  4990 net.cpp:615] Convolution88 <- Eltwise43_ReLU87_0_split_0
I0612 11:05:14.378317  4990 net.cpp:589] Convolution88 -> Convolution88
I0612 11:05:14.379995  4990 net.cpp:240] Setting up Convolution88
I0612 11:05:14.380007  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.380012  4990 net.cpp:255] Memory required for data: 2719483392
I0612 11:05:14.380023  4990 layer_factory.hpp:77] Creating layer BatchNorm88
I0612 11:05:14.380033  4990 net.cpp:190] Creating Layer BatchNorm88
I0612 11:05:14.380038  4990 net.cpp:615] BatchNorm88 <- Convolution88
I0612 11:05:14.380046  4990 net.cpp:576] BatchNorm88 -> Convolution88 (in-place)
I0612 11:05:14.380271  4990 net.cpp:240] Setting up BatchNorm88
I0612 11:05:14.380280  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.380283  4990 net.cpp:255] Memory required for data: 2721580544
I0612 11:05:14.380297  4990 layer_factory.hpp:77] Creating layer Scale88
I0612 11:05:14.380306  4990 net.cpp:190] Creating Layer Scale88
I0612 11:05:14.380311  4990 net.cpp:615] Scale88 <- Convolution88
I0612 11:05:14.380316  4990 net.cpp:576] Scale88 -> Convolution88 (in-place)
I0612 11:05:14.380358  4990 layer_factory.hpp:77] Creating layer Scale88
I0612 11:05:14.380496  4990 net.cpp:240] Setting up Scale88
I0612 11:05:14.380507  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.380511  4990 net.cpp:255] Memory required for data: 2723677696
I0612 11:05:14.380522  4990 layer_factory.hpp:77] Creating layer ReLU88
I0612 11:05:14.380532  4990 net.cpp:190] Creating Layer ReLU88
I0612 11:05:14.380535  4990 net.cpp:615] ReLU88 <- Convolution88
I0612 11:05:14.380543  4990 net.cpp:576] ReLU88 -> Convolution88 (in-place)
I0612 11:05:14.380550  4990 net.cpp:240] Setting up ReLU88
I0612 11:05:14.380556  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.380560  4990 net.cpp:255] Memory required for data: 2725774848
I0612 11:05:14.380563  4990 layer_factory.hpp:77] Creating layer Convolution89
I0612 11:05:14.380574  4990 net.cpp:190] Creating Layer Convolution89
I0612 11:05:14.380579  4990 net.cpp:615] Convolution89 <- Convolution88
I0612 11:05:14.380591  4990 net.cpp:589] Convolution89 -> Convolution89
I0612 11:05:14.382222  4990 net.cpp:240] Setting up Convolution89
I0612 11:05:14.382232  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.382237  4990 net.cpp:255] Memory required for data: 2727872000
I0612 11:05:14.382246  4990 layer_factory.hpp:77] Creating layer BatchNorm89
I0612 11:05:14.382257  4990 net.cpp:190] Creating Layer BatchNorm89
I0612 11:05:14.382262  4990 net.cpp:615] BatchNorm89 <- Convolution89
I0612 11:05:14.382271  4990 net.cpp:576] BatchNorm89 -> Convolution89 (in-place)
I0612 11:05:14.382503  4990 net.cpp:240] Setting up BatchNorm89
I0612 11:05:14.382513  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.382516  4990 net.cpp:255] Memory required for data: 2729969152
I0612 11:05:14.382529  4990 layer_factory.hpp:77] Creating layer Scale89
I0612 11:05:14.382536  4990 net.cpp:190] Creating Layer Scale89
I0612 11:05:14.382541  4990 net.cpp:615] Scale89 <- Convolution89
I0612 11:05:14.382550  4990 net.cpp:576] Scale89 -> Convolution89 (in-place)
I0612 11:05:14.382588  4990 layer_factory.hpp:77] Creating layer Scale89
I0612 11:05:14.382725  4990 net.cpp:240] Setting up Scale89
I0612 11:05:14.382732  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.382736  4990 net.cpp:255] Memory required for data: 2732066304
I0612 11:05:14.382745  4990 layer_factory.hpp:77] Creating layer Eltwise44
I0612 11:05:14.382755  4990 net.cpp:190] Creating Layer Eltwise44
I0612 11:05:14.382760  4990 net.cpp:615] Eltwise44 <- Eltwise43_ReLU87_0_split_1
I0612 11:05:14.382766  4990 net.cpp:615] Eltwise44 <- Convolution89
I0612 11:05:14.382773  4990 net.cpp:589] Eltwise44 -> Eltwise44
I0612 11:05:14.382796  4990 net.cpp:240] Setting up Eltwise44
I0612 11:05:14.382802  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.382805  4990 net.cpp:255] Memory required for data: 2734163456
I0612 11:05:14.382809  4990 layer_factory.hpp:77] Creating layer ReLU89
I0612 11:05:14.382817  4990 net.cpp:190] Creating Layer ReLU89
I0612 11:05:14.382822  4990 net.cpp:615] ReLU89 <- Eltwise44
I0612 11:05:14.382827  4990 net.cpp:576] ReLU89 -> Eltwise44 (in-place)
I0612 11:05:14.382834  4990 net.cpp:240] Setting up ReLU89
I0612 11:05:14.382839  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.382843  4990 net.cpp:255] Memory required for data: 2736260608
I0612 11:05:14.382846  4990 layer_factory.hpp:77] Creating layer Eltwise44_ReLU89_0_split
I0612 11:05:14.382853  4990 net.cpp:190] Creating Layer Eltwise44_ReLU89_0_split
I0612 11:05:14.382858  4990 net.cpp:615] Eltwise44_ReLU89_0_split <- Eltwise44
I0612 11:05:14.382865  4990 net.cpp:589] Eltwise44_ReLU89_0_split -> Eltwise44_ReLU89_0_split_0
I0612 11:05:14.382874  4990 net.cpp:589] Eltwise44_ReLU89_0_split -> Eltwise44_ReLU89_0_split_1
I0612 11:05:14.382912  4990 net.cpp:240] Setting up Eltwise44_ReLU89_0_split
I0612 11:05:14.382920  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.382925  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.382927  4990 net.cpp:255] Memory required for data: 2740454912
I0612 11:05:14.382932  4990 layer_factory.hpp:77] Creating layer Convolution90
I0612 11:05:14.382949  4990 net.cpp:190] Creating Layer Convolution90
I0612 11:05:14.382954  4990 net.cpp:615] Convolution90 <- Eltwise44_ReLU89_0_split_0
I0612 11:05:14.382962  4990 net.cpp:589] Convolution90 -> Convolution90
I0612 11:05:14.384596  4990 net.cpp:240] Setting up Convolution90
I0612 11:05:14.384606  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.384610  4990 net.cpp:255] Memory required for data: 2742552064
I0612 11:05:14.384620  4990 layer_factory.hpp:77] Creating layer BatchNorm90
I0612 11:05:14.384631  4990 net.cpp:190] Creating Layer BatchNorm90
I0612 11:05:14.384636  4990 net.cpp:615] BatchNorm90 <- Convolution90
I0612 11:05:14.384642  4990 net.cpp:576] BatchNorm90 -> Convolution90 (in-place)
I0612 11:05:14.384870  4990 net.cpp:240] Setting up BatchNorm90
I0612 11:05:14.384877  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.384881  4990 net.cpp:255] Memory required for data: 2744649216
I0612 11:05:14.384893  4990 layer_factory.hpp:77] Creating layer Scale90
I0612 11:05:14.384902  4990 net.cpp:190] Creating Layer Scale90
I0612 11:05:14.384907  4990 net.cpp:615] Scale90 <- Convolution90
I0612 11:05:14.384912  4990 net.cpp:576] Scale90 -> Convolution90 (in-place)
I0612 11:05:14.384956  4990 layer_factory.hpp:77] Creating layer Scale90
I0612 11:05:14.385092  4990 net.cpp:240] Setting up Scale90
I0612 11:05:14.385100  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.385103  4990 net.cpp:255] Memory required for data: 2746746368
I0612 11:05:14.385114  4990 layer_factory.hpp:77] Creating layer ReLU90
I0612 11:05:14.385124  4990 net.cpp:190] Creating Layer ReLU90
I0612 11:05:14.385129  4990 net.cpp:615] ReLU90 <- Convolution90
I0612 11:05:14.385135  4990 net.cpp:576] ReLU90 -> Convolution90 (in-place)
I0612 11:05:14.385141  4990 net.cpp:240] Setting up ReLU90
I0612 11:05:14.385148  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.385150  4990 net.cpp:255] Memory required for data: 2748843520
I0612 11:05:14.385155  4990 layer_factory.hpp:77] Creating layer Convolution91
I0612 11:05:14.385167  4990 net.cpp:190] Creating Layer Convolution91
I0612 11:05:14.385172  4990 net.cpp:615] Convolution91 <- Convolution90
I0612 11:05:14.385180  4990 net.cpp:589] Convolution91 -> Convolution91
I0612 11:05:14.386821  4990 net.cpp:240] Setting up Convolution91
I0612 11:05:14.386832  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.386837  4990 net.cpp:255] Memory required for data: 2750940672
I0612 11:05:14.386847  4990 layer_factory.hpp:77] Creating layer BatchNorm91
I0612 11:05:14.386857  4990 net.cpp:190] Creating Layer BatchNorm91
I0612 11:05:14.386863  4990 net.cpp:615] BatchNorm91 <- Convolution91
I0612 11:05:14.386873  4990 net.cpp:576] BatchNorm91 -> Convolution91 (in-place)
I0612 11:05:14.387097  4990 net.cpp:240] Setting up BatchNorm91
I0612 11:05:14.387105  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.387109  4990 net.cpp:255] Memory required for data: 2753037824
I0612 11:05:14.387120  4990 layer_factory.hpp:77] Creating layer Scale91
I0612 11:05:14.387130  4990 net.cpp:190] Creating Layer Scale91
I0612 11:05:14.387135  4990 net.cpp:615] Scale91 <- Convolution91
I0612 11:05:14.387140  4990 net.cpp:576] Scale91 -> Convolution91 (in-place)
I0612 11:05:14.387181  4990 layer_factory.hpp:77] Creating layer Scale91
I0612 11:05:14.387320  4990 net.cpp:240] Setting up Scale91
I0612 11:05:14.387327  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.387331  4990 net.cpp:255] Memory required for data: 2755134976
I0612 11:05:14.387341  4990 layer_factory.hpp:77] Creating layer Eltwise45
I0612 11:05:14.387352  4990 net.cpp:190] Creating Layer Eltwise45
I0612 11:05:14.387357  4990 net.cpp:615] Eltwise45 <- Eltwise44_ReLU89_0_split_1
I0612 11:05:14.387363  4990 net.cpp:615] Eltwise45 <- Convolution91
I0612 11:05:14.387369  4990 net.cpp:589] Eltwise45 -> Eltwise45
I0612 11:05:14.387393  4990 net.cpp:240] Setting up Eltwise45
I0612 11:05:14.387399  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.387403  4990 net.cpp:255] Memory required for data: 2757232128
I0612 11:05:14.387411  4990 layer_factory.hpp:77] Creating layer ReLU91
I0612 11:05:14.387419  4990 net.cpp:190] Creating Layer ReLU91
I0612 11:05:14.387424  4990 net.cpp:615] ReLU91 <- Eltwise45
I0612 11:05:14.387431  4990 net.cpp:576] ReLU91 -> Eltwise45 (in-place)
I0612 11:05:14.387439  4990 net.cpp:240] Setting up ReLU91
I0612 11:05:14.387444  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.387449  4990 net.cpp:255] Memory required for data: 2759329280
I0612 11:05:14.387452  4990 layer_factory.hpp:77] Creating layer Eltwise45_ReLU91_0_split
I0612 11:05:14.387457  4990 net.cpp:190] Creating Layer Eltwise45_ReLU91_0_split
I0612 11:05:14.387461  4990 net.cpp:615] Eltwise45_ReLU91_0_split <- Eltwise45
I0612 11:05:14.387467  4990 net.cpp:589] Eltwise45_ReLU91_0_split -> Eltwise45_ReLU91_0_split_0
I0612 11:05:14.387475  4990 net.cpp:589] Eltwise45_ReLU91_0_split -> Eltwise45_ReLU91_0_split_1
I0612 11:05:14.387516  4990 net.cpp:240] Setting up Eltwise45_ReLU91_0_split
I0612 11:05:14.387523  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.387528  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.387532  4990 net.cpp:255] Memory required for data: 2763523584
I0612 11:05:14.387537  4990 layer_factory.hpp:77] Creating layer Convolution92
I0612 11:05:14.387547  4990 net.cpp:190] Creating Layer Convolution92
I0612 11:05:14.387552  4990 net.cpp:615] Convolution92 <- Eltwise45_ReLU91_0_split_0
I0612 11:05:14.387562  4990 net.cpp:589] Convolution92 -> Convolution92
I0612 11:05:14.389207  4990 net.cpp:240] Setting up Convolution92
I0612 11:05:14.389219  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.389222  4990 net.cpp:255] Memory required for data: 2765620736
I0612 11:05:14.389232  4990 layer_factory.hpp:77] Creating layer BatchNorm92
I0612 11:05:14.389241  4990 net.cpp:190] Creating Layer BatchNorm92
I0612 11:05:14.389246  4990 net.cpp:615] BatchNorm92 <- Convolution92
I0612 11:05:14.389255  4990 net.cpp:576] BatchNorm92 -> Convolution92 (in-place)
I0612 11:05:14.389484  4990 net.cpp:240] Setting up BatchNorm92
I0612 11:05:14.389493  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.389497  4990 net.cpp:255] Memory required for data: 2767717888
I0612 11:05:14.389510  4990 layer_factory.hpp:77] Creating layer Scale92
I0612 11:05:14.389518  4990 net.cpp:190] Creating Layer Scale92
I0612 11:05:14.389523  4990 net.cpp:615] Scale92 <- Convolution92
I0612 11:05:14.389530  4990 net.cpp:576] Scale92 -> Convolution92 (in-place)
I0612 11:05:14.389570  4990 layer_factory.hpp:77] Creating layer Scale92
I0612 11:05:14.389706  4990 net.cpp:240] Setting up Scale92
I0612 11:05:14.389714  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.389717  4990 net.cpp:255] Memory required for data: 2769815040
I0612 11:05:14.389727  4990 layer_factory.hpp:77] Creating layer ReLU92
I0612 11:05:14.389735  4990 net.cpp:190] Creating Layer ReLU92
I0612 11:05:14.389739  4990 net.cpp:615] ReLU92 <- Convolution92
I0612 11:05:14.389747  4990 net.cpp:576] ReLU92 -> Convolution92 (in-place)
I0612 11:05:14.389755  4990 net.cpp:240] Setting up ReLU92
I0612 11:05:14.389760  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.389763  4990 net.cpp:255] Memory required for data: 2771912192
I0612 11:05:14.389767  4990 layer_factory.hpp:77] Creating layer Convolution93
I0612 11:05:14.389780  4990 net.cpp:190] Creating Layer Convolution93
I0612 11:05:14.389786  4990 net.cpp:615] Convolution93 <- Convolution92
I0612 11:05:14.389791  4990 net.cpp:589] Convolution93 -> Convolution93
I0612 11:05:14.391432  4990 net.cpp:240] Setting up Convolution93
I0612 11:05:14.391443  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.391448  4990 net.cpp:255] Memory required for data: 2774009344
I0612 11:05:14.391456  4990 layer_factory.hpp:77] Creating layer BatchNorm93
I0612 11:05:14.391474  4990 net.cpp:190] Creating Layer BatchNorm93
I0612 11:05:14.391479  4990 net.cpp:615] BatchNorm93 <- Convolution93
I0612 11:05:14.391487  4990 net.cpp:576] BatchNorm93 -> Convolution93 (in-place)
I0612 11:05:14.391715  4990 net.cpp:240] Setting up BatchNorm93
I0612 11:05:14.391722  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.391726  4990 net.cpp:255] Memory required for data: 2776106496
I0612 11:05:14.391739  4990 layer_factory.hpp:77] Creating layer Scale93
I0612 11:05:14.391746  4990 net.cpp:190] Creating Layer Scale93
I0612 11:05:14.391752  4990 net.cpp:615] Scale93 <- Convolution93
I0612 11:05:14.391757  4990 net.cpp:576] Scale93 -> Convolution93 (in-place)
I0612 11:05:14.391799  4990 layer_factory.hpp:77] Creating layer Scale93
I0612 11:05:14.391935  4990 net.cpp:240] Setting up Scale93
I0612 11:05:14.391943  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.391947  4990 net.cpp:255] Memory required for data: 2778203648
I0612 11:05:14.391957  4990 layer_factory.hpp:77] Creating layer Eltwise46
I0612 11:05:14.391965  4990 net.cpp:190] Creating Layer Eltwise46
I0612 11:05:14.391971  4990 net.cpp:615] Eltwise46 <- Eltwise45_ReLU91_0_split_1
I0612 11:05:14.391976  4990 net.cpp:615] Eltwise46 <- Convolution93
I0612 11:05:14.391983  4990 net.cpp:589] Eltwise46 -> Eltwise46
I0612 11:05:14.392004  4990 net.cpp:240] Setting up Eltwise46
I0612 11:05:14.392010  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.392014  4990 net.cpp:255] Memory required for data: 2780300800
I0612 11:05:14.392017  4990 layer_factory.hpp:77] Creating layer ReLU93
I0612 11:05:14.392029  4990 net.cpp:190] Creating Layer ReLU93
I0612 11:05:14.392033  4990 net.cpp:615] ReLU93 <- Eltwise46
I0612 11:05:14.392038  4990 net.cpp:576] ReLU93 -> Eltwise46 (in-place)
I0612 11:05:14.392045  4990 net.cpp:240] Setting up ReLU93
I0612 11:05:14.392050  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.392055  4990 net.cpp:255] Memory required for data: 2782397952
I0612 11:05:14.392058  4990 layer_factory.hpp:77] Creating layer Eltwise46_ReLU93_0_split
I0612 11:05:14.392063  4990 net.cpp:190] Creating Layer Eltwise46_ReLU93_0_split
I0612 11:05:14.392067  4990 net.cpp:615] Eltwise46_ReLU93_0_split <- Eltwise46
I0612 11:05:14.392073  4990 net.cpp:589] Eltwise46_ReLU93_0_split -> Eltwise46_ReLU93_0_split_0
I0612 11:05:14.392081  4990 net.cpp:589] Eltwise46_ReLU93_0_split -> Eltwise46_ReLU93_0_split_1
I0612 11:05:14.392122  4990 net.cpp:240] Setting up Eltwise46_ReLU93_0_split
I0612 11:05:14.392128  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.392133  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.392137  4990 net.cpp:255] Memory required for data: 2786592256
I0612 11:05:14.392141  4990 layer_factory.hpp:77] Creating layer Convolution94
I0612 11:05:14.392154  4990 net.cpp:190] Creating Layer Convolution94
I0612 11:05:14.392159  4990 net.cpp:615] Convolution94 <- Eltwise46_ReLU93_0_split_0
I0612 11:05:14.392168  4990 net.cpp:589] Convolution94 -> Convolution94
I0612 11:05:14.394482  4990 net.cpp:240] Setting up Convolution94
I0612 11:05:14.394500  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.394503  4990 net.cpp:255] Memory required for data: 2788689408
I0612 11:05:14.394515  4990 layer_factory.hpp:77] Creating layer BatchNorm94
I0612 11:05:14.394527  4990 net.cpp:190] Creating Layer BatchNorm94
I0612 11:05:14.394533  4990 net.cpp:615] BatchNorm94 <- Convolution94
I0612 11:05:14.394539  4990 net.cpp:576] BatchNorm94 -> Convolution94 (in-place)
I0612 11:05:14.394772  4990 net.cpp:240] Setting up BatchNorm94
I0612 11:05:14.394779  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.394783  4990 net.cpp:255] Memory required for data: 2790786560
I0612 11:05:14.394795  4990 layer_factory.hpp:77] Creating layer Scale94
I0612 11:05:14.394803  4990 net.cpp:190] Creating Layer Scale94
I0612 11:05:14.394807  4990 net.cpp:615] Scale94 <- Convolution94
I0612 11:05:14.394812  4990 net.cpp:576] Scale94 -> Convolution94 (in-place)
I0612 11:05:14.394858  4990 layer_factory.hpp:77] Creating layer Scale94
I0612 11:05:14.394994  4990 net.cpp:240] Setting up Scale94
I0612 11:05:14.395000  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.395009  4990 net.cpp:255] Memory required for data: 2792883712
I0612 11:05:14.395020  4990 layer_factory.hpp:77] Creating layer ReLU94
I0612 11:05:14.395027  4990 net.cpp:190] Creating Layer ReLU94
I0612 11:05:14.395032  4990 net.cpp:615] ReLU94 <- Convolution94
I0612 11:05:14.395038  4990 net.cpp:576] ReLU94 -> Convolution94 (in-place)
I0612 11:05:14.395045  4990 net.cpp:240] Setting up ReLU94
I0612 11:05:14.395051  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.395054  4990 net.cpp:255] Memory required for data: 2794980864
I0612 11:05:14.395059  4990 layer_factory.hpp:77] Creating layer Convolution95
I0612 11:05:14.395073  4990 net.cpp:190] Creating Layer Convolution95
I0612 11:05:14.395078  4990 net.cpp:615] Convolution95 <- Convolution94
I0612 11:05:14.395087  4990 net.cpp:589] Convolution95 -> Convolution95
I0612 11:05:14.396718  4990 net.cpp:240] Setting up Convolution95
I0612 11:05:14.396728  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.396733  4990 net.cpp:255] Memory required for data: 2797078016
I0612 11:05:14.396741  4990 layer_factory.hpp:77] Creating layer BatchNorm95
I0612 11:05:14.396752  4990 net.cpp:190] Creating Layer BatchNorm95
I0612 11:05:14.396757  4990 net.cpp:615] BatchNorm95 <- Convolution95
I0612 11:05:14.396766  4990 net.cpp:576] BatchNorm95 -> Convolution95 (in-place)
I0612 11:05:14.396992  4990 net.cpp:240] Setting up BatchNorm95
I0612 11:05:14.397001  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.397004  4990 net.cpp:255] Memory required for data: 2799175168
I0612 11:05:14.397017  4990 layer_factory.hpp:77] Creating layer Scale95
I0612 11:05:14.397030  4990 net.cpp:190] Creating Layer Scale95
I0612 11:05:14.397035  4990 net.cpp:615] Scale95 <- Convolution95
I0612 11:05:14.397042  4990 net.cpp:576] Scale95 -> Convolution95 (in-place)
I0612 11:05:14.397083  4990 layer_factory.hpp:77] Creating layer Scale95
I0612 11:05:14.397217  4990 net.cpp:240] Setting up Scale95
I0612 11:05:14.397224  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.397228  4990 net.cpp:255] Memory required for data: 2801272320
I0612 11:05:14.397243  4990 layer_factory.hpp:77] Creating layer Eltwise47
I0612 11:05:14.397253  4990 net.cpp:190] Creating Layer Eltwise47
I0612 11:05:14.397258  4990 net.cpp:615] Eltwise47 <- Eltwise46_ReLU93_0_split_1
I0612 11:05:14.397264  4990 net.cpp:615] Eltwise47 <- Convolution95
I0612 11:05:14.397272  4990 net.cpp:589] Eltwise47 -> Eltwise47
I0612 11:05:14.397295  4990 net.cpp:240] Setting up Eltwise47
I0612 11:05:14.397302  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.397305  4990 net.cpp:255] Memory required for data: 2803369472
I0612 11:05:14.397310  4990 layer_factory.hpp:77] Creating layer ReLU95
I0612 11:05:14.397317  4990 net.cpp:190] Creating Layer ReLU95
I0612 11:05:14.397321  4990 net.cpp:615] ReLU95 <- Eltwise47
I0612 11:05:14.397330  4990 net.cpp:576] ReLU95 -> Eltwise47 (in-place)
I0612 11:05:14.397336  4990 net.cpp:240] Setting up ReLU95
I0612 11:05:14.397341  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.397344  4990 net.cpp:255] Memory required for data: 2805466624
I0612 11:05:14.397348  4990 layer_factory.hpp:77] Creating layer Eltwise47_ReLU95_0_split
I0612 11:05:14.397354  4990 net.cpp:190] Creating Layer Eltwise47_ReLU95_0_split
I0612 11:05:14.397358  4990 net.cpp:615] Eltwise47_ReLU95_0_split <- Eltwise47
I0612 11:05:14.397363  4990 net.cpp:589] Eltwise47_ReLU95_0_split -> Eltwise47_ReLU95_0_split_0
I0612 11:05:14.397372  4990 net.cpp:589] Eltwise47_ReLU95_0_split -> Eltwise47_ReLU95_0_split_1
I0612 11:05:14.397414  4990 net.cpp:240] Setting up Eltwise47_ReLU95_0_split
I0612 11:05:14.397421  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.397426  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.397430  4990 net.cpp:255] Memory required for data: 2809660928
I0612 11:05:14.397434  4990 layer_factory.hpp:77] Creating layer Convolution96
I0612 11:05:14.397444  4990 net.cpp:190] Creating Layer Convolution96
I0612 11:05:14.397454  4990 net.cpp:615] Convolution96 <- Eltwise47_ReLU95_0_split_0
I0612 11:05:14.397464  4990 net.cpp:589] Convolution96 -> Convolution96
I0612 11:05:14.399111  4990 net.cpp:240] Setting up Convolution96
I0612 11:05:14.399121  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.399126  4990 net.cpp:255] Memory required for data: 2811758080
I0612 11:05:14.399137  4990 layer_factory.hpp:77] Creating layer BatchNorm96
I0612 11:05:14.399144  4990 net.cpp:190] Creating Layer BatchNorm96
I0612 11:05:14.399149  4990 net.cpp:615] BatchNorm96 <- Convolution96
I0612 11:05:14.399158  4990 net.cpp:576] BatchNorm96 -> Convolution96 (in-place)
I0612 11:05:14.399386  4990 net.cpp:240] Setting up BatchNorm96
I0612 11:05:14.399394  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.399399  4990 net.cpp:255] Memory required for data: 2813855232
I0612 11:05:14.399411  4990 layer_factory.hpp:77] Creating layer Scale96
I0612 11:05:14.399420  4990 net.cpp:190] Creating Layer Scale96
I0612 11:05:14.399423  4990 net.cpp:615] Scale96 <- Convolution96
I0612 11:05:14.399431  4990 net.cpp:576] Scale96 -> Convolution96 (in-place)
I0612 11:05:14.399472  4990 layer_factory.hpp:77] Creating layer Scale96
I0612 11:05:14.399606  4990 net.cpp:240] Setting up Scale96
I0612 11:05:14.399615  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.399618  4990 net.cpp:255] Memory required for data: 2815952384
I0612 11:05:14.399627  4990 layer_factory.hpp:77] Creating layer ReLU96
I0612 11:05:14.399636  4990 net.cpp:190] Creating Layer ReLU96
I0612 11:05:14.399641  4990 net.cpp:615] ReLU96 <- Convolution96
I0612 11:05:14.399648  4990 net.cpp:576] ReLU96 -> Convolution96 (in-place)
I0612 11:05:14.399655  4990 net.cpp:240] Setting up ReLU96
I0612 11:05:14.399662  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.399664  4990 net.cpp:255] Memory required for data: 2818049536
I0612 11:05:14.399668  4990 layer_factory.hpp:77] Creating layer Convolution97
I0612 11:05:14.399700  4990 net.cpp:190] Creating Layer Convolution97
I0612 11:05:14.399705  4990 net.cpp:615] Convolution97 <- Convolution96
I0612 11:05:14.399713  4990 net.cpp:589] Convolution97 -> Convolution97
I0612 11:05:14.401347  4990 net.cpp:240] Setting up Convolution97
I0612 11:05:14.401358  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.401362  4990 net.cpp:255] Memory required for data: 2820146688
I0612 11:05:14.401372  4990 layer_factory.hpp:77] Creating layer BatchNorm97
I0612 11:05:14.401382  4990 net.cpp:190] Creating Layer BatchNorm97
I0612 11:05:14.401387  4990 net.cpp:615] BatchNorm97 <- Convolution97
I0612 11:05:14.401393  4990 net.cpp:576] BatchNorm97 -> Convolution97 (in-place)
I0612 11:05:14.401623  4990 net.cpp:240] Setting up BatchNorm97
I0612 11:05:14.401633  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.401636  4990 net.cpp:255] Memory required for data: 2822243840
I0612 11:05:14.401649  4990 layer_factory.hpp:77] Creating layer Scale97
I0612 11:05:14.401656  4990 net.cpp:190] Creating Layer Scale97
I0612 11:05:14.401661  4990 net.cpp:615] Scale97 <- Convolution97
I0612 11:05:14.401666  4990 net.cpp:576] Scale97 -> Convolution97 (in-place)
I0612 11:05:14.401710  4990 layer_factory.hpp:77] Creating layer Scale97
I0612 11:05:14.401849  4990 net.cpp:240] Setting up Scale97
I0612 11:05:14.401857  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.401861  4990 net.cpp:255] Memory required for data: 2824340992
I0612 11:05:14.401870  4990 layer_factory.hpp:77] Creating layer Eltwise48
I0612 11:05:14.401890  4990 net.cpp:190] Creating Layer Eltwise48
I0612 11:05:14.401896  4990 net.cpp:615] Eltwise48 <- Eltwise47_ReLU95_0_split_1
I0612 11:05:14.401902  4990 net.cpp:615] Eltwise48 <- Convolution97
I0612 11:05:14.401908  4990 net.cpp:589] Eltwise48 -> Eltwise48
I0612 11:05:14.401932  4990 net.cpp:240] Setting up Eltwise48
I0612 11:05:14.401938  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.401942  4990 net.cpp:255] Memory required for data: 2826438144
I0612 11:05:14.401949  4990 layer_factory.hpp:77] Creating layer ReLU97
I0612 11:05:14.401965  4990 net.cpp:190] Creating Layer ReLU97
I0612 11:05:14.401970  4990 net.cpp:615] ReLU97 <- Eltwise48
I0612 11:05:14.401976  4990 net.cpp:576] ReLU97 -> Eltwise48 (in-place)
I0612 11:05:14.401983  4990 net.cpp:240] Setting up ReLU97
I0612 11:05:14.401988  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.401993  4990 net.cpp:255] Memory required for data: 2828535296
I0612 11:05:14.401996  4990 layer_factory.hpp:77] Creating layer Eltwise48_ReLU97_0_split
I0612 11:05:14.402003  4990 net.cpp:190] Creating Layer Eltwise48_ReLU97_0_split
I0612 11:05:14.402006  4990 net.cpp:615] Eltwise48_ReLU97_0_split <- Eltwise48
I0612 11:05:14.402012  4990 net.cpp:589] Eltwise48_ReLU97_0_split -> Eltwise48_ReLU97_0_split_0
I0612 11:05:14.402019  4990 net.cpp:589] Eltwise48_ReLU97_0_split -> Eltwise48_ReLU97_0_split_1
I0612 11:05:14.402063  4990 net.cpp:240] Setting up Eltwise48_ReLU97_0_split
I0612 11:05:14.402070  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.402076  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.402079  4990 net.cpp:255] Memory required for data: 2832729600
I0612 11:05:14.402083  4990 layer_factory.hpp:77] Creating layer Convolution98
I0612 11:05:14.402098  4990 net.cpp:190] Creating Layer Convolution98
I0612 11:05:14.402103  4990 net.cpp:615] Convolution98 <- Eltwise48_ReLU97_0_split_0
I0612 11:05:14.402112  4990 net.cpp:589] Convolution98 -> Convolution98
I0612 11:05:14.403774  4990 net.cpp:240] Setting up Convolution98
I0612 11:05:14.403785  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.403789  4990 net.cpp:255] Memory required for data: 2834826752
I0612 11:05:14.403800  4990 layer_factory.hpp:77] Creating layer BatchNorm98
I0612 11:05:14.403810  4990 net.cpp:190] Creating Layer BatchNorm98
I0612 11:05:14.403815  4990 net.cpp:615] BatchNorm98 <- Convolution98
I0612 11:05:14.403823  4990 net.cpp:576] BatchNorm98 -> Convolution98 (in-place)
I0612 11:05:14.404050  4990 net.cpp:240] Setting up BatchNorm98
I0612 11:05:14.404058  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.404062  4990 net.cpp:255] Memory required for data: 2836923904
I0612 11:05:14.404074  4990 layer_factory.hpp:77] Creating layer Scale98
I0612 11:05:14.404085  4990 net.cpp:190] Creating Layer Scale98
I0612 11:05:14.404090  4990 net.cpp:615] Scale98 <- Convolution98
I0612 11:05:14.404096  4990 net.cpp:576] Scale98 -> Convolution98 (in-place)
I0612 11:05:14.404139  4990 layer_factory.hpp:77] Creating layer Scale98
I0612 11:05:14.404278  4990 net.cpp:240] Setting up Scale98
I0612 11:05:14.404285  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.404289  4990 net.cpp:255] Memory required for data: 2839021056
I0612 11:05:14.404300  4990 layer_factory.hpp:77] Creating layer ReLU98
I0612 11:05:14.404309  4990 net.cpp:190] Creating Layer ReLU98
I0612 11:05:14.404314  4990 net.cpp:615] ReLU98 <- Convolution98
I0612 11:05:14.404320  4990 net.cpp:576] ReLU98 -> Convolution98 (in-place)
I0612 11:05:14.404326  4990 net.cpp:240] Setting up ReLU98
I0612 11:05:14.404332  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.404336  4990 net.cpp:255] Memory required for data: 2841118208
I0612 11:05:14.404340  4990 layer_factory.hpp:77] Creating layer Convolution99
I0612 11:05:14.404353  4990 net.cpp:190] Creating Layer Convolution99
I0612 11:05:14.404357  4990 net.cpp:615] Convolution99 <- Convolution98
I0612 11:05:14.404366  4990 net.cpp:589] Convolution99 -> Convolution99
I0612 11:05:14.406002  4990 net.cpp:240] Setting up Convolution99
I0612 11:05:14.406013  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.406016  4990 net.cpp:255] Memory required for data: 2843215360
I0612 11:05:14.406025  4990 layer_factory.hpp:77] Creating layer BatchNorm99
I0612 11:05:14.406034  4990 net.cpp:190] Creating Layer BatchNorm99
I0612 11:05:14.406038  4990 net.cpp:615] BatchNorm99 <- Convolution99
I0612 11:05:14.406047  4990 net.cpp:576] BatchNorm99 -> Convolution99 (in-place)
I0612 11:05:14.406283  4990 net.cpp:240] Setting up BatchNorm99
I0612 11:05:14.406292  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.406296  4990 net.cpp:255] Memory required for data: 2845312512
I0612 11:05:14.406307  4990 layer_factory.hpp:77] Creating layer Scale99
I0612 11:05:14.406316  4990 net.cpp:190] Creating Layer Scale99
I0612 11:05:14.406319  4990 net.cpp:615] Scale99 <- Convolution99
I0612 11:05:14.406327  4990 net.cpp:576] Scale99 -> Convolution99 (in-place)
I0612 11:05:14.406376  4990 layer_factory.hpp:77] Creating layer Scale99
I0612 11:05:14.406512  4990 net.cpp:240] Setting up Scale99
I0612 11:05:14.406520  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.406524  4990 net.cpp:255] Memory required for data: 2847409664
I0612 11:05:14.406534  4990 layer_factory.hpp:77] Creating layer Eltwise49
I0612 11:05:14.406543  4990 net.cpp:190] Creating Layer Eltwise49
I0612 11:05:14.406548  4990 net.cpp:615] Eltwise49 <- Eltwise48_ReLU97_0_split_1
I0612 11:05:14.406553  4990 net.cpp:615] Eltwise49 <- Convolution99
I0612 11:05:14.406563  4990 net.cpp:589] Eltwise49 -> Eltwise49
I0612 11:05:14.406585  4990 net.cpp:240] Setting up Eltwise49
I0612 11:05:14.406592  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.406596  4990 net.cpp:255] Memory required for data: 2849506816
I0612 11:05:14.406600  4990 layer_factory.hpp:77] Creating layer ReLU99
I0612 11:05:14.406610  4990 net.cpp:190] Creating Layer ReLU99
I0612 11:05:14.406615  4990 net.cpp:615] ReLU99 <- Eltwise49
I0612 11:05:14.406620  4990 net.cpp:576] ReLU99 -> Eltwise49 (in-place)
I0612 11:05:14.406626  4990 net.cpp:240] Setting up ReLU99
I0612 11:05:14.406631  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.406635  4990 net.cpp:255] Memory required for data: 2851603968
I0612 11:05:14.406640  4990 layer_factory.hpp:77] Creating layer Eltwise49_ReLU99_0_split
I0612 11:05:14.406646  4990 net.cpp:190] Creating Layer Eltwise49_ReLU99_0_split
I0612 11:05:14.406648  4990 net.cpp:615] Eltwise49_ReLU99_0_split <- Eltwise49
I0612 11:05:14.406654  4990 net.cpp:589] Eltwise49_ReLU99_0_split -> Eltwise49_ReLU99_0_split_0
I0612 11:05:14.406841  4990 net.cpp:589] Eltwise49_ReLU99_0_split -> Eltwise49_ReLU99_0_split_1
I0612 11:05:14.406894  4990 net.cpp:240] Setting up Eltwise49_ReLU99_0_split
I0612 11:05:14.406905  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.406911  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.406914  4990 net.cpp:255] Memory required for data: 2855798272
I0612 11:05:14.406919  4990 layer_factory.hpp:77] Creating layer Convolution100
I0612 11:05:14.406932  4990 net.cpp:190] Creating Layer Convolution100
I0612 11:05:14.406937  4990 net.cpp:615] Convolution100 <- Eltwise49_ReLU99_0_split_0
I0612 11:05:14.406947  4990 net.cpp:589] Convolution100 -> Convolution100
I0612 11:05:14.408586  4990 net.cpp:240] Setting up Convolution100
I0612 11:05:14.408596  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.408601  4990 net.cpp:255] Memory required for data: 2857895424
I0612 11:05:14.408610  4990 layer_factory.hpp:77] Creating layer BatchNorm100
I0612 11:05:14.408622  4990 net.cpp:190] Creating Layer BatchNorm100
I0612 11:05:14.408627  4990 net.cpp:615] BatchNorm100 <- Convolution100
I0612 11:05:14.408635  4990 net.cpp:576] BatchNorm100 -> Convolution100 (in-place)
I0612 11:05:14.408864  4990 net.cpp:240] Setting up BatchNorm100
I0612 11:05:14.408872  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.408876  4990 net.cpp:255] Memory required for data: 2859992576
I0612 11:05:14.408890  4990 layer_factory.hpp:77] Creating layer Scale100
I0612 11:05:14.408900  4990 net.cpp:190] Creating Layer Scale100
I0612 11:05:14.408905  4990 net.cpp:615] Scale100 <- Convolution100
I0612 11:05:14.408911  4990 net.cpp:576] Scale100 -> Convolution100 (in-place)
I0612 11:05:14.408957  4990 layer_factory.hpp:77] Creating layer Scale100
I0612 11:05:14.409090  4990 net.cpp:240] Setting up Scale100
I0612 11:05:14.409098  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.409106  4990 net.cpp:255] Memory required for data: 2862089728
I0612 11:05:14.409121  4990 layer_factory.hpp:77] Creating layer ReLU100
I0612 11:05:14.409129  4990 net.cpp:190] Creating Layer ReLU100
I0612 11:05:14.409134  4990 net.cpp:615] ReLU100 <- Convolution100
I0612 11:05:14.409142  4990 net.cpp:576] ReLU100 -> Convolution100 (in-place)
I0612 11:05:14.409149  4990 net.cpp:240] Setting up ReLU100
I0612 11:05:14.409154  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.409158  4990 net.cpp:255] Memory required for data: 2864186880
I0612 11:05:14.409164  4990 layer_factory.hpp:77] Creating layer Convolution101
I0612 11:05:14.409178  4990 net.cpp:190] Creating Layer Convolution101
I0612 11:05:14.409181  4990 net.cpp:615] Convolution101 <- Convolution100
I0612 11:05:14.409191  4990 net.cpp:589] Convolution101 -> Convolution101
I0612 11:05:14.411500  4990 net.cpp:240] Setting up Convolution101
I0612 11:05:14.411517  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.411521  4990 net.cpp:255] Memory required for data: 2866284032
I0612 11:05:14.411533  4990 layer_factory.hpp:77] Creating layer BatchNorm101
I0612 11:05:14.411545  4990 net.cpp:190] Creating Layer BatchNorm101
I0612 11:05:14.411550  4990 net.cpp:615] BatchNorm101 <- Convolution101
I0612 11:05:14.411558  4990 net.cpp:576] BatchNorm101 -> Convolution101 (in-place)
I0612 11:05:14.411789  4990 net.cpp:240] Setting up BatchNorm101
I0612 11:05:14.411798  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.411801  4990 net.cpp:255] Memory required for data: 2868381184
I0612 11:05:14.411818  4990 layer_factory.hpp:77] Creating layer Scale101
I0612 11:05:14.411829  4990 net.cpp:190] Creating Layer Scale101
I0612 11:05:14.411834  4990 net.cpp:615] Scale101 <- Convolution101
I0612 11:05:14.411840  4990 net.cpp:576] Scale101 -> Convolution101 (in-place)
I0612 11:05:14.411885  4990 layer_factory.hpp:77] Creating layer Scale101
I0612 11:05:14.412022  4990 net.cpp:240] Setting up Scale101
I0612 11:05:14.412030  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.412034  4990 net.cpp:255] Memory required for data: 2870478336
I0612 11:05:14.412045  4990 layer_factory.hpp:77] Creating layer Eltwise50
I0612 11:05:14.412055  4990 net.cpp:190] Creating Layer Eltwise50
I0612 11:05:14.412060  4990 net.cpp:615] Eltwise50 <- Eltwise49_ReLU99_0_split_1
I0612 11:05:14.412065  4990 net.cpp:615] Eltwise50 <- Convolution101
I0612 11:05:14.412075  4990 net.cpp:589] Eltwise50 -> Eltwise50
I0612 11:05:14.412096  4990 net.cpp:240] Setting up Eltwise50
I0612 11:05:14.412102  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.412106  4990 net.cpp:255] Memory required for data: 2872575488
I0612 11:05:14.412111  4990 layer_factory.hpp:77] Creating layer ReLU101
I0612 11:05:14.412118  4990 net.cpp:190] Creating Layer ReLU101
I0612 11:05:14.412123  4990 net.cpp:615] ReLU101 <- Eltwise50
I0612 11:05:14.412132  4990 net.cpp:576] ReLU101 -> Eltwise50 (in-place)
I0612 11:05:14.412139  4990 net.cpp:240] Setting up ReLU101
I0612 11:05:14.412144  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.412148  4990 net.cpp:255] Memory required for data: 2874672640
I0612 11:05:14.412153  4990 layer_factory.hpp:77] Creating layer Eltwise50_ReLU101_0_split
I0612 11:05:14.412375  4990 net.cpp:190] Creating Layer Eltwise50_ReLU101_0_split
I0612 11:05:14.412384  4990 net.cpp:615] Eltwise50_ReLU101_0_split <- Eltwise50
I0612 11:05:14.412391  4990 net.cpp:589] Eltwise50_ReLU101_0_split -> Eltwise50_ReLU101_0_split_0
I0612 11:05:14.412400  4990 net.cpp:589] Eltwise50_ReLU101_0_split -> Eltwise50_ReLU101_0_split_1
I0612 11:05:14.412448  4990 net.cpp:240] Setting up Eltwise50_ReLU101_0_split
I0612 11:05:14.412461  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.412466  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.412469  4990 net.cpp:255] Memory required for data: 2878866944
I0612 11:05:14.412474  4990 layer_factory.hpp:77] Creating layer Convolution102
I0612 11:05:14.412487  4990 net.cpp:190] Creating Layer Convolution102
I0612 11:05:14.412495  4990 net.cpp:615] Convolution102 <- Eltwise50_ReLU101_0_split_0
I0612 11:05:14.412505  4990 net.cpp:589] Convolution102 -> Convolution102
I0612 11:05:14.414155  4990 net.cpp:240] Setting up Convolution102
I0612 11:05:14.414166  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.414170  4990 net.cpp:255] Memory required for data: 2880964096
I0612 11:05:14.414180  4990 layer_factory.hpp:77] Creating layer BatchNorm102
I0612 11:05:14.414191  4990 net.cpp:190] Creating Layer BatchNorm102
I0612 11:05:14.414197  4990 net.cpp:615] BatchNorm102 <- Convolution102
I0612 11:05:14.414203  4990 net.cpp:576] BatchNorm102 -> Convolution102 (in-place)
I0612 11:05:14.414445  4990 net.cpp:240] Setting up BatchNorm102
I0612 11:05:14.414454  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.414458  4990 net.cpp:255] Memory required for data: 2883061248
I0612 11:05:14.414471  4990 layer_factory.hpp:77] Creating layer Scale102
I0612 11:05:14.414484  4990 net.cpp:190] Creating Layer Scale102
I0612 11:05:14.414489  4990 net.cpp:615] Scale102 <- Convolution102
I0612 11:05:14.414494  4990 net.cpp:576] Scale102 -> Convolution102 (in-place)
I0612 11:05:14.414535  4990 layer_factory.hpp:77] Creating layer Scale102
I0612 11:05:14.414677  4990 net.cpp:240] Setting up Scale102
I0612 11:05:14.414685  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.414690  4990 net.cpp:255] Memory required for data: 2885158400
I0612 11:05:14.414698  4990 layer_factory.hpp:77] Creating layer ReLU102
I0612 11:05:14.414710  4990 net.cpp:190] Creating Layer ReLU102
I0612 11:05:14.414715  4990 net.cpp:615] ReLU102 <- Convolution102
I0612 11:05:14.414721  4990 net.cpp:576] ReLU102 -> Convolution102 (in-place)
I0612 11:05:14.414727  4990 net.cpp:240] Setting up ReLU102
I0612 11:05:14.414733  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.414737  4990 net.cpp:255] Memory required for data: 2887255552
I0612 11:05:14.414741  4990 layer_factory.hpp:77] Creating layer Convolution103
I0612 11:05:14.414754  4990 net.cpp:190] Creating Layer Convolution103
I0612 11:05:14.414759  4990 net.cpp:615] Convolution103 <- Convolution102
I0612 11:05:14.414767  4990 net.cpp:589] Convolution103 -> Convolution103
I0612 11:05:14.416402  4990 net.cpp:240] Setting up Convolution103
I0612 11:05:14.416412  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.416416  4990 net.cpp:255] Memory required for data: 2889352704
I0612 11:05:14.416426  4990 layer_factory.hpp:77] Creating layer BatchNorm103
I0612 11:05:14.416436  4990 net.cpp:190] Creating Layer BatchNorm103
I0612 11:05:14.416441  4990 net.cpp:615] BatchNorm103 <- Convolution103
I0612 11:05:14.416447  4990 net.cpp:576] BatchNorm103 -> Convolution103 (in-place)
I0612 11:05:14.416677  4990 net.cpp:240] Setting up BatchNorm103
I0612 11:05:14.416685  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.416689  4990 net.cpp:255] Memory required for data: 2891449856
I0612 11:05:14.416700  4990 layer_factory.hpp:77] Creating layer Scale103
I0612 11:05:14.416709  4990 net.cpp:190] Creating Layer Scale103
I0612 11:05:14.416714  4990 net.cpp:615] Scale103 <- Convolution103
I0612 11:05:14.416719  4990 net.cpp:576] Scale103 -> Convolution103 (in-place)
I0612 11:05:14.416764  4990 layer_factory.hpp:77] Creating layer Scale103
I0612 11:05:14.416901  4990 net.cpp:240] Setting up Scale103
I0612 11:05:14.416909  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.416913  4990 net.cpp:255] Memory required for data: 2893547008
I0612 11:05:14.416923  4990 layer_factory.hpp:77] Creating layer Eltwise51
I0612 11:05:14.416934  4990 net.cpp:190] Creating Layer Eltwise51
I0612 11:05:14.416940  4990 net.cpp:615] Eltwise51 <- Eltwise50_ReLU101_0_split_1
I0612 11:05:14.416945  4990 net.cpp:615] Eltwise51 <- Convolution103
I0612 11:05:14.416951  4990 net.cpp:589] Eltwise51 -> Eltwise51
I0612 11:05:14.416980  4990 net.cpp:240] Setting up Eltwise51
I0612 11:05:14.416988  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.416996  4990 net.cpp:255] Memory required for data: 2895644160
I0612 11:05:14.416999  4990 layer_factory.hpp:77] Creating layer ReLU103
I0612 11:05:14.417006  4990 net.cpp:190] Creating Layer ReLU103
I0612 11:05:14.417011  4990 net.cpp:615] ReLU103 <- Eltwise51
I0612 11:05:14.417019  4990 net.cpp:576] ReLU103 -> Eltwise51 (in-place)
I0612 11:05:14.417026  4990 net.cpp:240] Setting up ReLU103
I0612 11:05:14.417032  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.417035  4990 net.cpp:255] Memory required for data: 2897741312
I0612 11:05:14.417039  4990 layer_factory.hpp:77] Creating layer Eltwise51_ReLU103_0_split
I0612 11:05:14.417045  4990 net.cpp:190] Creating Layer Eltwise51_ReLU103_0_split
I0612 11:05:14.417049  4990 net.cpp:615] Eltwise51_ReLU103_0_split <- Eltwise51
I0612 11:05:14.417054  4990 net.cpp:589] Eltwise51_ReLU103_0_split -> Eltwise51_ReLU103_0_split_0
I0612 11:05:14.417062  4990 net.cpp:589] Eltwise51_ReLU103_0_split -> Eltwise51_ReLU103_0_split_1
I0612 11:05:14.417105  4990 net.cpp:240] Setting up Eltwise51_ReLU103_0_split
I0612 11:05:14.417112  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.417117  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.417121  4990 net.cpp:255] Memory required for data: 2901935616
I0612 11:05:14.417125  4990 layer_factory.hpp:77] Creating layer Convolution104
I0612 11:05:14.417140  4990 net.cpp:190] Creating Layer Convolution104
I0612 11:05:14.417145  4990 net.cpp:615] Convolution104 <- Eltwise51_ReLU103_0_split_0
I0612 11:05:14.417151  4990 net.cpp:589] Convolution104 -> Convolution104
I0612 11:05:14.418808  4990 net.cpp:240] Setting up Convolution104
I0612 11:05:14.418819  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.418823  4990 net.cpp:255] Memory required for data: 2904032768
I0612 11:05:14.418833  4990 layer_factory.hpp:77] Creating layer BatchNorm104
I0612 11:05:14.418843  4990 net.cpp:190] Creating Layer BatchNorm104
I0612 11:05:14.418848  4990 net.cpp:615] BatchNorm104 <- Convolution104
I0612 11:05:14.418856  4990 net.cpp:576] BatchNorm104 -> Convolution104 (in-place)
I0612 11:05:14.419087  4990 net.cpp:240] Setting up BatchNorm104
I0612 11:05:14.419095  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.419098  4990 net.cpp:255] Memory required for data: 2906129920
I0612 11:05:14.419112  4990 layer_factory.hpp:77] Creating layer Scale104
I0612 11:05:14.419121  4990 net.cpp:190] Creating Layer Scale104
I0612 11:05:14.419126  4990 net.cpp:615] Scale104 <- Convolution104
I0612 11:05:14.419132  4990 net.cpp:576] Scale104 -> Convolution104 (in-place)
I0612 11:05:14.419174  4990 layer_factory.hpp:77] Creating layer Scale104
I0612 11:05:14.419312  4990 net.cpp:240] Setting up Scale104
I0612 11:05:14.419319  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.419322  4990 net.cpp:255] Memory required for data: 2908227072
I0612 11:05:14.419334  4990 layer_factory.hpp:77] Creating layer ReLU104
I0612 11:05:14.419342  4990 net.cpp:190] Creating Layer ReLU104
I0612 11:05:14.419347  4990 net.cpp:615] ReLU104 <- Convolution104
I0612 11:05:14.419354  4990 net.cpp:576] ReLU104 -> Convolution104 (in-place)
I0612 11:05:14.419361  4990 net.cpp:240] Setting up ReLU104
I0612 11:05:14.419368  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.419371  4990 net.cpp:255] Memory required for data: 2910324224
I0612 11:05:14.419374  4990 layer_factory.hpp:77] Creating layer Convolution105
I0612 11:05:14.419386  4990 net.cpp:190] Creating Layer Convolution105
I0612 11:05:14.419390  4990 net.cpp:615] Convolution105 <- Convolution104
I0612 11:05:14.419399  4990 net.cpp:589] Convolution105 -> Convolution105
I0612 11:05:14.421033  4990 net.cpp:240] Setting up Convolution105
I0612 11:05:14.421043  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.421047  4990 net.cpp:255] Memory required for data: 2912421376
I0612 11:05:14.421058  4990 layer_factory.hpp:77] Creating layer BatchNorm105
I0612 11:05:14.421066  4990 net.cpp:190] Creating Layer BatchNorm105
I0612 11:05:14.421074  4990 net.cpp:615] BatchNorm105 <- Convolution105
I0612 11:05:14.421082  4990 net.cpp:576] BatchNorm105 -> Convolution105 (in-place)
I0612 11:05:14.421320  4990 net.cpp:240] Setting up BatchNorm105
I0612 11:05:14.421329  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.421332  4990 net.cpp:255] Memory required for data: 2914518528
I0612 11:05:14.421344  4990 layer_factory.hpp:77] Creating layer Scale105
I0612 11:05:14.421353  4990 net.cpp:190] Creating Layer Scale105
I0612 11:05:14.421358  4990 net.cpp:615] Scale105 <- Convolution105
I0612 11:05:14.421366  4990 net.cpp:576] Scale105 -> Convolution105 (in-place)
I0612 11:05:14.421407  4990 layer_factory.hpp:77] Creating layer Scale105
I0612 11:05:14.421548  4990 net.cpp:240] Setting up Scale105
I0612 11:05:14.421556  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.421561  4990 net.cpp:255] Memory required for data: 2916615680
I0612 11:05:14.421569  4990 layer_factory.hpp:77] Creating layer Eltwise52
I0612 11:05:14.421578  4990 net.cpp:190] Creating Layer Eltwise52
I0612 11:05:14.421583  4990 net.cpp:615] Eltwise52 <- Eltwise51_ReLU103_0_split_1
I0612 11:05:14.421588  4990 net.cpp:615] Eltwise52 <- Convolution105
I0612 11:05:14.421597  4990 net.cpp:589] Eltwise52 -> Eltwise52
I0612 11:05:14.421619  4990 net.cpp:240] Setting up Eltwise52
I0612 11:05:14.421625  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.421629  4990 net.cpp:255] Memory required for data: 2918712832
I0612 11:05:14.421633  4990 layer_factory.hpp:77] Creating layer ReLU105
I0612 11:05:14.421643  4990 net.cpp:190] Creating Layer ReLU105
I0612 11:05:14.421646  4990 net.cpp:615] ReLU105 <- Eltwise52
I0612 11:05:14.421651  4990 net.cpp:576] ReLU105 -> Eltwise52 (in-place)
I0612 11:05:14.421658  4990 net.cpp:240] Setting up ReLU105
I0612 11:05:14.421663  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.421668  4990 net.cpp:255] Memory required for data: 2920809984
I0612 11:05:14.421672  4990 layer_factory.hpp:77] Creating layer Eltwise52_ReLU105_0_split
I0612 11:05:14.421679  4990 net.cpp:190] Creating Layer Eltwise52_ReLU105_0_split
I0612 11:05:14.421681  4990 net.cpp:615] Eltwise52_ReLU105_0_split <- Eltwise52
I0612 11:05:14.421689  4990 net.cpp:589] Eltwise52_ReLU105_0_split -> Eltwise52_ReLU105_0_split_0
I0612 11:05:14.421697  4990 net.cpp:589] Eltwise52_ReLU105_0_split -> Eltwise52_ReLU105_0_split_1
I0612 11:05:14.421737  4990 net.cpp:240] Setting up Eltwise52_ReLU105_0_split
I0612 11:05:14.421744  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.421749  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.421752  4990 net.cpp:255] Memory required for data: 2925004288
I0612 11:05:14.421756  4990 layer_factory.hpp:77] Creating layer Convolution106
I0612 11:05:14.421771  4990 net.cpp:190] Creating Layer Convolution106
I0612 11:05:14.421774  4990 net.cpp:615] Convolution106 <- Eltwise52_ReLU105_0_split_0
I0612 11:05:14.421782  4990 net.cpp:589] Convolution106 -> Convolution106
I0612 11:05:14.423432  4990 net.cpp:240] Setting up Convolution106
I0612 11:05:14.423444  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.423447  4990 net.cpp:255] Memory required for data: 2927101440
I0612 11:05:14.423457  4990 layer_factory.hpp:77] Creating layer BatchNorm106
I0612 11:05:14.423468  4990 net.cpp:190] Creating Layer BatchNorm106
I0612 11:05:14.423473  4990 net.cpp:615] BatchNorm106 <- Convolution106
I0612 11:05:14.423480  4990 net.cpp:576] BatchNorm106 -> Convolution106 (in-place)
I0612 11:05:14.423712  4990 net.cpp:240] Setting up BatchNorm106
I0612 11:05:14.423720  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.423724  4990 net.cpp:255] Memory required for data: 2929198592
I0612 11:05:14.423735  4990 layer_factory.hpp:77] Creating layer Scale106
I0612 11:05:14.423744  4990 net.cpp:190] Creating Layer Scale106
I0612 11:05:14.423749  4990 net.cpp:615] Scale106 <- Convolution106
I0612 11:05:14.423755  4990 net.cpp:576] Scale106 -> Convolution106 (in-place)
I0612 11:05:14.423800  4990 layer_factory.hpp:77] Creating layer Scale106
I0612 11:05:14.423944  4990 net.cpp:240] Setting up Scale106
I0612 11:05:14.423952  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.423956  4990 net.cpp:255] Memory required for data: 2931295744
I0612 11:05:14.423966  4990 layer_factory.hpp:77] Creating layer ReLU106
I0612 11:05:14.423976  4990 net.cpp:190] Creating Layer ReLU106
I0612 11:05:14.423981  4990 net.cpp:615] ReLU106 <- Convolution106
I0612 11:05:14.423987  4990 net.cpp:576] ReLU106 -> Convolution106 (in-place)
I0612 11:05:14.423995  4990 net.cpp:240] Setting up ReLU106
I0612 11:05:14.424000  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.424003  4990 net.cpp:255] Memory required for data: 2933392896
I0612 11:05:14.424007  4990 layer_factory.hpp:77] Creating layer Convolution107
I0612 11:05:14.424022  4990 net.cpp:190] Creating Layer Convolution107
I0612 11:05:14.424027  4990 net.cpp:615] Convolution107 <- Convolution106
I0612 11:05:14.424036  4990 net.cpp:589] Convolution107 -> Convolution107
I0612 11:05:14.425676  4990 net.cpp:240] Setting up Convolution107
I0612 11:05:14.425688  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.425691  4990 net.cpp:255] Memory required for data: 2935490048
I0612 11:05:14.425700  4990 layer_factory.hpp:77] Creating layer BatchNorm107
I0612 11:05:14.425711  4990 net.cpp:190] Creating Layer BatchNorm107
I0612 11:05:14.425716  4990 net.cpp:615] BatchNorm107 <- Convolution107
I0612 11:05:14.425724  4990 net.cpp:576] BatchNorm107 -> Convolution107 (in-place)
I0612 11:05:14.425953  4990 net.cpp:240] Setting up BatchNorm107
I0612 11:05:14.425961  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.425966  4990 net.cpp:255] Memory required for data: 2937587200
I0612 11:05:14.425976  4990 layer_factory.hpp:77] Creating layer Scale107
I0612 11:05:14.425988  4990 net.cpp:190] Creating Layer Scale107
I0612 11:05:14.425993  4990 net.cpp:615] Scale107 <- Convolution107
I0612 11:05:14.425999  4990 net.cpp:576] Scale107 -> Convolution107 (in-place)
I0612 11:05:14.426043  4990 layer_factory.hpp:77] Creating layer Scale107
I0612 11:05:14.426179  4990 net.cpp:240] Setting up Scale107
I0612 11:05:14.426187  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.426192  4990 net.cpp:255] Memory required for data: 2939684352
I0612 11:05:14.426201  4990 layer_factory.hpp:77] Creating layer Eltwise53
I0612 11:05:14.426211  4990 net.cpp:190] Creating Layer Eltwise53
I0612 11:05:14.426218  4990 net.cpp:615] Eltwise53 <- Eltwise52_ReLU105_0_split_1
I0612 11:05:14.426223  4990 net.cpp:615] Eltwise53 <- Convolution107
I0612 11:05:14.426229  4990 net.cpp:589] Eltwise53 -> Eltwise53
I0612 11:05:14.426252  4990 net.cpp:240] Setting up Eltwise53
I0612 11:05:14.426259  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.426262  4990 net.cpp:255] Memory required for data: 2941781504
I0612 11:05:14.426266  4990 layer_factory.hpp:77] Creating layer ReLU107
I0612 11:05:14.426272  4990 net.cpp:190] Creating Layer ReLU107
I0612 11:05:14.426277  4990 net.cpp:615] ReLU107 <- Eltwise53
I0612 11:05:14.426285  4990 net.cpp:576] ReLU107 -> Eltwise53 (in-place)
I0612 11:05:14.426292  4990 net.cpp:240] Setting up ReLU107
I0612 11:05:14.426297  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.426301  4990 net.cpp:255] Memory required for data: 2943878656
I0612 11:05:14.426306  4990 layer_factory.hpp:77] Creating layer Eltwise53_ReLU107_0_split
I0612 11:05:14.426311  4990 net.cpp:190] Creating Layer Eltwise53_ReLU107_0_split
I0612 11:05:14.426316  4990 net.cpp:615] Eltwise53_ReLU107_0_split <- Eltwise53
I0612 11:05:14.426321  4990 net.cpp:589] Eltwise53_ReLU107_0_split -> Eltwise53_ReLU107_0_split_0
I0612 11:05:14.426327  4990 net.cpp:589] Eltwise53_ReLU107_0_split -> Eltwise53_ReLU107_0_split_1
I0612 11:05:14.426378  4990 net.cpp:240] Setting up Eltwise53_ReLU107_0_split
I0612 11:05:14.426388  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.426393  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.426395  4990 net.cpp:255] Memory required for data: 2948072960
I0612 11:05:14.426403  4990 layer_factory.hpp:77] Creating layer Convolution108
I0612 11:05:14.426414  4990 net.cpp:190] Creating Layer Convolution108
I0612 11:05:14.426419  4990 net.cpp:615] Convolution108 <- Eltwise53_ReLU107_0_split_0
I0612 11:05:14.426429  4990 net.cpp:589] Convolution108 -> Convolution108
I0612 11:05:14.428733  4990 net.cpp:240] Setting up Convolution108
I0612 11:05:14.428750  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.428755  4990 net.cpp:255] Memory required for data: 2950170112
I0612 11:05:14.428766  4990 layer_factory.hpp:77] Creating layer BatchNorm108
I0612 11:05:14.428778  4990 net.cpp:190] Creating Layer BatchNorm108
I0612 11:05:14.428784  4990 net.cpp:615] BatchNorm108 <- Convolution108
I0612 11:05:14.428792  4990 net.cpp:576] BatchNorm108 -> Convolution108 (in-place)
I0612 11:05:14.429026  4990 net.cpp:240] Setting up BatchNorm108
I0612 11:05:14.429034  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.429039  4990 net.cpp:255] Memory required for data: 2952267264
I0612 11:05:14.429052  4990 layer_factory.hpp:77] Creating layer Scale108
I0612 11:05:14.429062  4990 net.cpp:190] Creating Layer Scale108
I0612 11:05:14.429066  4990 net.cpp:615] Scale108 <- Convolution108
I0612 11:05:14.429072  4990 net.cpp:576] Scale108 -> Convolution108 (in-place)
I0612 11:05:14.429117  4990 layer_factory.hpp:77] Creating layer Scale108
I0612 11:05:14.429262  4990 net.cpp:240] Setting up Scale108
I0612 11:05:14.429270  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.429275  4990 net.cpp:255] Memory required for data: 2954364416
I0612 11:05:14.429283  4990 layer_factory.hpp:77] Creating layer ReLU108
I0612 11:05:14.429291  4990 net.cpp:190] Creating Layer ReLU108
I0612 11:05:14.429296  4990 net.cpp:615] ReLU108 <- Convolution108
I0612 11:05:14.429304  4990 net.cpp:576] ReLU108 -> Convolution108 (in-place)
I0612 11:05:14.429312  4990 net.cpp:240] Setting up ReLU108
I0612 11:05:14.429317  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.429322  4990 net.cpp:255] Memory required for data: 2956461568
I0612 11:05:14.429325  4990 layer_factory.hpp:77] Creating layer Convolution109
I0612 11:05:14.429339  4990 net.cpp:190] Creating Layer Convolution109
I0612 11:05:14.429343  4990 net.cpp:615] Convolution109 <- Convolution108
I0612 11:05:14.429352  4990 net.cpp:589] Convolution109 -> Convolution109
I0612 11:05:14.431006  4990 net.cpp:240] Setting up Convolution109
I0612 11:05:14.431017  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.431021  4990 net.cpp:255] Memory required for data: 2958558720
I0612 11:05:14.431031  4990 layer_factory.hpp:77] Creating layer BatchNorm109
I0612 11:05:14.431041  4990 net.cpp:190] Creating Layer BatchNorm109
I0612 11:05:14.431046  4990 net.cpp:615] BatchNorm109 <- Convolution109
I0612 11:05:14.431053  4990 net.cpp:576] BatchNorm109 -> Convolution109 (in-place)
I0612 11:05:14.431293  4990 net.cpp:240] Setting up BatchNorm109
I0612 11:05:14.431303  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.431305  4990 net.cpp:255] Memory required for data: 2960655872
I0612 11:05:14.431318  4990 layer_factory.hpp:77] Creating layer Scale109
I0612 11:05:14.431324  4990 net.cpp:190] Creating Layer Scale109
I0612 11:05:14.431329  4990 net.cpp:615] Scale109 <- Convolution109
I0612 11:05:14.431337  4990 net.cpp:576] Scale109 -> Convolution109 (in-place)
I0612 11:05:14.431380  4990 layer_factory.hpp:77] Creating layer Scale109
I0612 11:05:14.431522  4990 net.cpp:240] Setting up Scale109
I0612 11:05:14.431531  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.431535  4990 net.cpp:255] Memory required for data: 2962753024
I0612 11:05:14.431545  4990 layer_factory.hpp:77] Creating layer Eltwise54
I0612 11:05:14.431552  4990 net.cpp:190] Creating Layer Eltwise54
I0612 11:05:14.431557  4990 net.cpp:615] Eltwise54 <- Eltwise53_ReLU107_0_split_1
I0612 11:05:14.431563  4990 net.cpp:615] Eltwise54 <- Convolution109
I0612 11:05:14.431571  4990 net.cpp:589] Eltwise54 -> Eltwise54
I0612 11:05:14.431599  4990 net.cpp:240] Setting up Eltwise54
I0612 11:05:14.431609  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.431613  4990 net.cpp:255] Memory required for data: 2964850176
I0612 11:05:14.431618  4990 layer_factory.hpp:77] Creating layer ReLU109
I0612 11:05:14.431625  4990 net.cpp:190] Creating Layer ReLU109
I0612 11:05:14.431629  4990 net.cpp:615] ReLU109 <- Eltwise54
I0612 11:05:14.431635  4990 net.cpp:576] ReLU109 -> Eltwise54 (in-place)
I0612 11:05:14.431643  4990 net.cpp:240] Setting up ReLU109
I0612 11:05:14.431648  4990 net.cpp:247] Top shape: 128 64 8 8 (524288)
I0612 11:05:14.431651  4990 net.cpp:255] Memory required for data: 2966947328
I0612 11:05:14.431654  4990 layer_factory.hpp:77] Creating layer Pooling4
I0612 11:05:14.431664  4990 net.cpp:190] Creating Layer Pooling4
I0612 11:05:14.431669  4990 net.cpp:615] Pooling4 <- Eltwise54
I0612 11:05:14.431675  4990 net.cpp:589] Pooling4 -> Pooling4
I0612 11:05:14.431704  4990 net.cpp:240] Setting up Pooling4
I0612 11:05:14.431711  4990 net.cpp:247] Top shape: 128 64 1 1 (8192)
I0612 11:05:14.431715  4990 net.cpp:255] Memory required for data: 2966980096
I0612 11:05:14.431718  4990 layer_factory.hpp:77] Creating layer InnerProduct1
I0612 11:05:14.431728  4990 net.cpp:190] Creating Layer InnerProduct1
I0612 11:05:14.431733  4990 net.cpp:615] InnerProduct1 <- Pooling4
I0612 11:05:14.431742  4990 net.cpp:589] InnerProduct1 -> InnerProduct1
I0612 11:05:14.431980  4990 net.cpp:240] Setting up InnerProduct1
I0612 11:05:14.431991  4990 net.cpp:247] Top shape: 128 10 (1280)
I0612 11:05:14.431994  4990 net.cpp:255] Memory required for data: 2966985216
I0612 11:05:14.432005  4990 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0612 11:05:14.432014  4990 net.cpp:190] Creating Layer InnerProduct1_InnerProduct1_0_split
I0612 11:05:14.432019  4990 net.cpp:615] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0612 11:05:14.432026  4990 net.cpp:589] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0612 11:05:14.432036  4990 net.cpp:589] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0612 11:05:14.432075  4990 net.cpp:240] Setting up InnerProduct1_InnerProduct1_0_split
I0612 11:05:14.432082  4990 net.cpp:247] Top shape: 128 10 (1280)
I0612 11:05:14.432087  4990 net.cpp:247] Top shape: 128 10 (1280)
I0612 11:05:14.432091  4990 net.cpp:255] Memory required for data: 2966995456
I0612 11:05:14.432096  4990 layer_factory.hpp:77] Creating layer Accuracy
I0612 11:05:14.432104  4990 net.cpp:190] Creating Layer Accuracy
I0612 11:05:14.432109  4990 net.cpp:615] Accuracy <- InnerProduct1_InnerProduct1_0_split_0
I0612 11:05:14.432114  4990 net.cpp:615] Accuracy <- Data2_Data1_1_split_0
I0612 11:05:14.432121  4990 net.cpp:589] Accuracy -> Accuracy
I0612 11:05:14.432140  4990 net.cpp:240] Setting up Accuracy
I0612 11:05:14.432147  4990 net.cpp:247] Top shape: (1)
I0612 11:05:14.432149  4990 net.cpp:255] Memory required for data: 2966995460
I0612 11:05:14.432153  4990 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0612 11:05:14.432160  4990 net.cpp:190] Creating Layer SoftmaxWithLoss1
I0612 11:05:14.432164  4990 net.cpp:615] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_1
I0612 11:05:14.432170  4990 net.cpp:615] SoftmaxWithLoss1 <- Data2_Data1_1_split_1
I0612 11:05:14.432179  4990 net.cpp:589] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0612 11:05:14.432189  4990 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0612 11:05:14.432343  4990 net.cpp:240] Setting up SoftmaxWithLoss1
I0612 11:05:14.432353  4990 net.cpp:247] Top shape: (1)
I0612 11:05:14.432356  4990 net.cpp:250]     with loss weight 1
I0612 11:05:14.432369  4990 net.cpp:255] Memory required for data: 2966995464
I0612 11:05:14.432374  4990 net.cpp:316] SoftmaxWithLoss1 needs backward computation.
I0612 11:05:14.432379  4990 net.cpp:318] Accuracy does not need backward computation.
I0612 11:05:14.432384  4990 net.cpp:316] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0612 11:05:14.432394  4990 net.cpp:316] InnerProduct1 needs backward computation.
I0612 11:05:14.432397  4990 net.cpp:316] Pooling4 needs backward computation.
I0612 11:05:14.432401  4990 net.cpp:316] ReLU109 needs backward computation.
I0612 11:05:14.432405  4990 net.cpp:316] Eltwise54 needs backward computation.
I0612 11:05:14.432410  4990 net.cpp:316] Scale109 needs backward computation.
I0612 11:05:14.432415  4990 net.cpp:316] BatchNorm109 needs backward computation.
I0612 11:05:14.432417  4990 net.cpp:316] Convolution109 needs backward computation.
I0612 11:05:14.432421  4990 net.cpp:316] ReLU108 needs backward computation.
I0612 11:05:14.432425  4990 net.cpp:316] Scale108 needs backward computation.
I0612 11:05:14.432428  4990 net.cpp:316] BatchNorm108 needs backward computation.
I0612 11:05:14.432432  4990 net.cpp:316] Convolution108 needs backward computation.
I0612 11:05:14.432436  4990 net.cpp:316] Eltwise53_ReLU107_0_split needs backward computation.
I0612 11:05:14.432440  4990 net.cpp:316] ReLU107 needs backward computation.
I0612 11:05:14.432445  4990 net.cpp:316] Eltwise53 needs backward computation.
I0612 11:05:14.432449  4990 net.cpp:316] Scale107 needs backward computation.
I0612 11:05:14.432452  4990 net.cpp:316] BatchNorm107 needs backward computation.
I0612 11:05:14.432456  4990 net.cpp:316] Convolution107 needs backward computation.
I0612 11:05:14.432461  4990 net.cpp:316] ReLU106 needs backward computation.
I0612 11:05:14.432463  4990 net.cpp:316] Scale106 needs backward computation.
I0612 11:05:14.432467  4990 net.cpp:316] BatchNorm106 needs backward computation.
I0612 11:05:14.432471  4990 net.cpp:316] Convolution106 needs backward computation.
I0612 11:05:14.432474  4990 net.cpp:316] Eltwise52_ReLU105_0_split needs backward computation.
I0612 11:05:14.432478  4990 net.cpp:316] ReLU105 needs backward computation.
I0612 11:05:14.432482  4990 net.cpp:316] Eltwise52 needs backward computation.
I0612 11:05:14.432487  4990 net.cpp:316] Scale105 needs backward computation.
I0612 11:05:14.432490  4990 net.cpp:316] BatchNorm105 needs backward computation.
I0612 11:05:14.432494  4990 net.cpp:316] Convolution105 needs backward computation.
I0612 11:05:14.432498  4990 net.cpp:316] ReLU104 needs backward computation.
I0612 11:05:14.432502  4990 net.cpp:316] Scale104 needs backward computation.
I0612 11:05:14.432505  4990 net.cpp:316] BatchNorm104 needs backward computation.
I0612 11:05:14.432508  4990 net.cpp:316] Convolution104 needs backward computation.
I0612 11:05:14.432513  4990 net.cpp:316] Eltwise51_ReLU103_0_split needs backward computation.
I0612 11:05:14.432518  4990 net.cpp:316] ReLU103 needs backward computation.
I0612 11:05:14.432520  4990 net.cpp:316] Eltwise51 needs backward computation.
I0612 11:05:14.432525  4990 net.cpp:316] Scale103 needs backward computation.
I0612 11:05:14.432528  4990 net.cpp:316] BatchNorm103 needs backward computation.
I0612 11:05:14.432533  4990 net.cpp:316] Convolution103 needs backward computation.
I0612 11:05:14.432536  4990 net.cpp:316] ReLU102 needs backward computation.
I0612 11:05:14.432539  4990 net.cpp:316] Scale102 needs backward computation.
I0612 11:05:14.432543  4990 net.cpp:316] BatchNorm102 needs backward computation.
I0612 11:05:14.432548  4990 net.cpp:316] Convolution102 needs backward computation.
I0612 11:05:14.432551  4990 net.cpp:316] Eltwise50_ReLU101_0_split needs backward computation.
I0612 11:05:14.432557  4990 net.cpp:316] ReLU101 needs backward computation.
I0612 11:05:14.432561  4990 net.cpp:316] Eltwise50 needs backward computation.
I0612 11:05:14.432566  4990 net.cpp:316] Scale101 needs backward computation.
I0612 11:05:14.432570  4990 net.cpp:316] BatchNorm101 needs backward computation.
I0612 11:05:14.432574  4990 net.cpp:316] Convolution101 needs backward computation.
I0612 11:05:14.432577  4990 net.cpp:316] ReLU100 needs backward computation.
I0612 11:05:14.432581  4990 net.cpp:316] Scale100 needs backward computation.
I0612 11:05:14.432585  4990 net.cpp:316] BatchNorm100 needs backward computation.
I0612 11:05:14.432590  4990 net.cpp:316] Convolution100 needs backward computation.
I0612 11:05:14.432595  4990 net.cpp:316] Eltwise49_ReLU99_0_split needs backward computation.
I0612 11:05:14.432600  4990 net.cpp:316] ReLU99 needs backward computation.
I0612 11:05:14.432603  4990 net.cpp:316] Eltwise49 needs backward computation.
I0612 11:05:14.432608  4990 net.cpp:316] Scale99 needs backward computation.
I0612 11:05:14.432612  4990 net.cpp:316] BatchNorm99 needs backward computation.
I0612 11:05:14.432616  4990 net.cpp:316] Convolution99 needs backward computation.
I0612 11:05:14.432621  4990 net.cpp:316] ReLU98 needs backward computation.
I0612 11:05:14.432624  4990 net.cpp:316] Scale98 needs backward computation.
I0612 11:05:14.432627  4990 net.cpp:316] BatchNorm98 needs backward computation.
I0612 11:05:14.432631  4990 net.cpp:316] Convolution98 needs backward computation.
I0612 11:05:14.432636  4990 net.cpp:316] Eltwise48_ReLU97_0_split needs backward computation.
I0612 11:05:14.432639  4990 net.cpp:316] ReLU97 needs backward computation.
I0612 11:05:14.432643  4990 net.cpp:316] Eltwise48 needs backward computation.
I0612 11:05:14.432648  4990 net.cpp:316] Scale97 needs backward computation.
I0612 11:05:14.432652  4990 net.cpp:316] BatchNorm97 needs backward computation.
I0612 11:05:14.432656  4990 net.cpp:316] Convolution97 needs backward computation.
I0612 11:05:14.432659  4990 net.cpp:316] ReLU96 needs backward computation.
I0612 11:05:14.432663  4990 net.cpp:316] Scale96 needs backward computation.
I0612 11:05:14.432667  4990 net.cpp:316] BatchNorm96 needs backward computation.
I0612 11:05:14.432670  4990 net.cpp:316] Convolution96 needs backward computation.
I0612 11:05:14.432674  4990 net.cpp:316] Eltwise47_ReLU95_0_split needs backward computation.
I0612 11:05:14.432678  4990 net.cpp:316] ReLU95 needs backward computation.
I0612 11:05:14.432682  4990 net.cpp:316] Eltwise47 needs backward computation.
I0612 11:05:14.432687  4990 net.cpp:316] Scale95 needs backward computation.
I0612 11:05:14.432690  4990 net.cpp:316] BatchNorm95 needs backward computation.
I0612 11:05:14.432693  4990 net.cpp:316] Convolution95 needs backward computation.
I0612 11:05:14.432698  4990 net.cpp:316] ReLU94 needs backward computation.
I0612 11:05:14.432701  4990 net.cpp:316] Scale94 needs backward computation.
I0612 11:05:14.432705  4990 net.cpp:316] BatchNorm94 needs backward computation.
I0612 11:05:14.432708  4990 net.cpp:316] Convolution94 needs backward computation.
I0612 11:05:14.432713  4990 net.cpp:316] Eltwise46_ReLU93_0_split needs backward computation.
I0612 11:05:14.432718  4990 net.cpp:316] ReLU93 needs backward computation.
I0612 11:05:14.432720  4990 net.cpp:316] Eltwise46 needs backward computation.
I0612 11:05:14.432725  4990 net.cpp:316] Scale93 needs backward computation.
I0612 11:05:14.432729  4990 net.cpp:316] BatchNorm93 needs backward computation.
I0612 11:05:14.432732  4990 net.cpp:316] Convolution93 needs backward computation.
I0612 11:05:14.432736  4990 net.cpp:316] ReLU92 needs backward computation.
I0612 11:05:14.432740  4990 net.cpp:316] Scale92 needs backward computation.
I0612 11:05:14.432744  4990 net.cpp:316] BatchNorm92 needs backward computation.
I0612 11:05:14.432747  4990 net.cpp:316] Convolution92 needs backward computation.
I0612 11:05:14.432751  4990 net.cpp:316] Eltwise45_ReLU91_0_split needs backward computation.
I0612 11:05:14.432755  4990 net.cpp:316] ReLU91 needs backward computation.
I0612 11:05:14.432760  4990 net.cpp:316] Eltwise45 needs backward computation.
I0612 11:05:14.432763  4990 net.cpp:316] Scale91 needs backward computation.
I0612 11:05:14.432766  4990 net.cpp:316] BatchNorm91 needs backward computation.
I0612 11:05:14.432770  4990 net.cpp:316] Convolution91 needs backward computation.
I0612 11:05:14.432775  4990 net.cpp:316] ReLU90 needs backward computation.
I0612 11:05:14.432778  4990 net.cpp:316] Scale90 needs backward computation.
I0612 11:05:14.432781  4990 net.cpp:316] BatchNorm90 needs backward computation.
I0612 11:05:14.432785  4990 net.cpp:316] Convolution90 needs backward computation.
I0612 11:05:14.432791  4990 net.cpp:316] Eltwise44_ReLU89_0_split needs backward computation.
I0612 11:05:14.432796  4990 net.cpp:316] ReLU89 needs backward computation.
I0612 11:05:14.432799  4990 net.cpp:316] Eltwise44 needs backward computation.
I0612 11:05:14.432804  4990 net.cpp:316] Scale89 needs backward computation.
I0612 11:05:14.432807  4990 net.cpp:316] BatchNorm89 needs backward computation.
I0612 11:05:14.432811  4990 net.cpp:316] Convolution89 needs backward computation.
I0612 11:05:14.432816  4990 net.cpp:316] ReLU88 needs backward computation.
I0612 11:05:14.432819  4990 net.cpp:316] Scale88 needs backward computation.
I0612 11:05:14.432822  4990 net.cpp:316] BatchNorm88 needs backward computation.
I0612 11:05:14.432826  4990 net.cpp:316] Convolution88 needs backward computation.
I0612 11:05:14.432831  4990 net.cpp:316] Eltwise43_ReLU87_0_split needs backward computation.
I0612 11:05:14.432837  4990 net.cpp:316] ReLU87 needs backward computation.
I0612 11:05:14.432840  4990 net.cpp:316] Eltwise43 needs backward computation.
I0612 11:05:14.432844  4990 net.cpp:316] Scale87 needs backward computation.
I0612 11:05:14.432848  4990 net.cpp:316] BatchNorm87 needs backward computation.
I0612 11:05:14.432852  4990 net.cpp:316] Convolution87 needs backward computation.
I0612 11:05:14.432857  4990 net.cpp:316] ReLU86 needs backward computation.
I0612 11:05:14.432860  4990 net.cpp:316] Scale86 needs backward computation.
I0612 11:05:14.432863  4990 net.cpp:316] BatchNorm86 needs backward computation.
I0612 11:05:14.432868  4990 net.cpp:316] Convolution86 needs backward computation.
I0612 11:05:14.432871  4990 net.cpp:316] Eltwise42_ReLU85_0_split needs backward computation.
I0612 11:05:14.432875  4990 net.cpp:316] ReLU85 needs backward computation.
I0612 11:05:14.432879  4990 net.cpp:316] Eltwise42 needs backward computation.
I0612 11:05:14.432883  4990 net.cpp:316] Scale85 needs backward computation.
I0612 11:05:14.432888  4990 net.cpp:316] BatchNorm85 needs backward computation.
I0612 11:05:14.432890  4990 net.cpp:316] Convolution85 needs backward computation.
I0612 11:05:14.432894  4990 net.cpp:316] ReLU84 needs backward computation.
I0612 11:05:14.432898  4990 net.cpp:316] Scale84 needs backward computation.
I0612 11:05:14.432901  4990 net.cpp:316] BatchNorm84 needs backward computation.
I0612 11:05:14.432905  4990 net.cpp:316] Convolution84 needs backward computation.
I0612 11:05:14.432909  4990 net.cpp:316] Eltwise41_ReLU83_0_split needs backward computation.
I0612 11:05:14.432914  4990 net.cpp:316] ReLU83 needs backward computation.
I0612 11:05:14.432917  4990 net.cpp:316] Eltwise41 needs backward computation.
I0612 11:05:14.432921  4990 net.cpp:316] Scale83 needs backward computation.
I0612 11:05:14.432925  4990 net.cpp:316] BatchNorm83 needs backward computation.
I0612 11:05:14.432929  4990 net.cpp:316] Convolution83 needs backward computation.
I0612 11:05:14.432932  4990 net.cpp:316] ReLU82 needs backward computation.
I0612 11:05:14.432936  4990 net.cpp:316] Scale82 needs backward computation.
I0612 11:05:14.432940  4990 net.cpp:316] BatchNorm82 needs backward computation.
I0612 11:05:14.432943  4990 net.cpp:316] Convolution82 needs backward computation.
I0612 11:05:14.432947  4990 net.cpp:316] Eltwise40_ReLU81_0_split needs backward computation.
I0612 11:05:14.432951  4990 net.cpp:316] ReLU81 needs backward computation.
I0612 11:05:14.432955  4990 net.cpp:316] Eltwise40 needs backward computation.
I0612 11:05:14.432960  4990 net.cpp:316] Scale81 needs backward computation.
I0612 11:05:14.432965  4990 net.cpp:316] BatchNorm81 needs backward computation.
I0612 11:05:14.432968  4990 net.cpp:316] Convolution81 needs backward computation.
I0612 11:05:14.432972  4990 net.cpp:316] ReLU80 needs backward computation.
I0612 11:05:14.432976  4990 net.cpp:316] Scale80 needs backward computation.
I0612 11:05:14.432981  4990 net.cpp:316] BatchNorm80 needs backward computation.
I0612 11:05:14.432986  4990 net.cpp:316] Convolution80 needs backward computation.
I0612 11:05:14.432991  4990 net.cpp:316] Eltwise39_ReLU79_0_split needs backward computation.
I0612 11:05:14.432997  4990 net.cpp:316] ReLU79 needs backward computation.
I0612 11:05:14.433002  4990 net.cpp:316] Eltwise39 needs backward computation.
I0612 11:05:14.433007  4990 net.cpp:316] Scale79 needs backward computation.
I0612 11:05:14.433012  4990 net.cpp:316] BatchNorm79 needs backward computation.
I0612 11:05:14.433015  4990 net.cpp:316] Convolution79 needs backward computation.
I0612 11:05:14.433019  4990 net.cpp:316] ReLU78 needs backward computation.
I0612 11:05:14.433023  4990 net.cpp:316] Scale78 needs backward computation.
I0612 11:05:14.433028  4990 net.cpp:316] BatchNorm78 needs backward computation.
I0612 11:05:14.433032  4990 net.cpp:316] Convolution78 needs backward computation.
I0612 11:05:14.433037  4990 net.cpp:316] Eltwise38_ReLU77_0_split needs backward computation.
I0612 11:05:14.433040  4990 net.cpp:316] ReLU77 needs backward computation.
I0612 11:05:14.433044  4990 net.cpp:316] Eltwise38 needs backward computation.
I0612 11:05:14.433048  4990 net.cpp:316] Scale77 needs backward computation.
I0612 11:05:14.433053  4990 net.cpp:316] BatchNorm77 needs backward computation.
I0612 11:05:14.433058  4990 net.cpp:316] Convolution77 needs backward computation.
I0612 11:05:14.433060  4990 net.cpp:316] ReLU76 needs backward computation.
I0612 11:05:14.433065  4990 net.cpp:316] Scale76 needs backward computation.
I0612 11:05:14.433070  4990 net.cpp:316] BatchNorm76 needs backward computation.
I0612 11:05:14.433073  4990 net.cpp:316] Convolution76 needs backward computation.
I0612 11:05:14.433078  4990 net.cpp:316] Eltwise37_ReLU75_0_split needs backward computation.
I0612 11:05:14.433081  4990 net.cpp:316] ReLU75 needs backward computation.
I0612 11:05:14.433085  4990 net.cpp:316] Eltwise37 needs backward computation.
I0612 11:05:14.433090  4990 net.cpp:316] Scale75 needs backward computation.
I0612 11:05:14.433095  4990 net.cpp:316] BatchNorm75 needs backward computation.
I0612 11:05:14.433099  4990 net.cpp:316] Convolution75 needs backward computation.
I0612 11:05:14.433104  4990 net.cpp:316] ReLU74 needs backward computation.
I0612 11:05:14.433107  4990 net.cpp:316] Scale74 needs backward computation.
I0612 11:05:14.433111  4990 net.cpp:316] BatchNorm74 needs backward computation.
I0612 11:05:14.433115  4990 net.cpp:316] Convolution74 needs backward computation.
I0612 11:05:14.433120  4990 net.cpp:316] Concat2 needs backward computation.
I0612 11:05:14.433125  4990 net.cpp:318] Input2 does not need backward computation.
I0612 11:05:14.433128  4990 net.cpp:316] Pooling2 needs backward computation.
I0612 11:05:14.433133  4990 net.cpp:316] Eltwise36_ReLU73_0_split needs backward computation.
I0612 11:05:14.433137  4990 net.cpp:316] ReLU73 needs backward computation.
I0612 11:05:14.433140  4990 net.cpp:316] Eltwise36 needs backward computation.
I0612 11:05:14.433145  4990 net.cpp:316] Scale73 needs backward computation.
I0612 11:05:14.433149  4990 net.cpp:316] BatchNorm73 needs backward computation.
I0612 11:05:14.433153  4990 net.cpp:316] Convolution73 needs backward computation.
I0612 11:05:14.433157  4990 net.cpp:316] ReLU72 needs backward computation.
I0612 11:05:14.433161  4990 net.cpp:316] Scale72 needs backward computation.
I0612 11:05:14.433164  4990 net.cpp:316] BatchNorm72 needs backward computation.
I0612 11:05:14.433168  4990 net.cpp:316] Convolution72 needs backward computation.
I0612 11:05:14.433172  4990 net.cpp:316] Eltwise35_ReLU71_0_split needs backward computation.
I0612 11:05:14.433176  4990 net.cpp:316] ReLU71 needs backward computation.
I0612 11:05:14.433181  4990 net.cpp:316] Eltwise35 needs backward computation.
I0612 11:05:14.433184  4990 net.cpp:316] Scale71 needs backward computation.
I0612 11:05:14.433188  4990 net.cpp:316] BatchNorm71 needs backward computation.
I0612 11:05:14.433192  4990 net.cpp:316] Convolution71 needs backward computation.
I0612 11:05:14.433195  4990 net.cpp:316] ReLU70 needs backward computation.
I0612 11:05:14.433200  4990 net.cpp:316] Scale70 needs backward computation.
I0612 11:05:14.433205  4990 net.cpp:316] BatchNorm70 needs backward computation.
I0612 11:05:14.433212  4990 net.cpp:316] Convolution70 needs backward computation.
I0612 11:05:14.433218  4990 net.cpp:316] Eltwise34_ReLU69_0_split needs backward computation.
I0612 11:05:14.433221  4990 net.cpp:316] ReLU69 needs backward computation.
I0612 11:05:14.433224  4990 net.cpp:316] Eltwise34 needs backward computation.
I0612 11:05:14.433234  4990 net.cpp:316] Scale69 needs backward computation.
I0612 11:05:14.433240  4990 net.cpp:316] BatchNorm69 needs backward computation.
I0612 11:05:14.433244  4990 net.cpp:316] Convolution69 needs backward computation.
I0612 11:05:14.433249  4990 net.cpp:316] ReLU68 needs backward computation.
I0612 11:05:14.433254  4990 net.cpp:316] Scale68 needs backward computation.
I0612 11:05:14.433257  4990 net.cpp:316] BatchNorm68 needs backward computation.
I0612 11:05:14.433261  4990 net.cpp:316] Convolution68 needs backward computation.
I0612 11:05:14.433265  4990 net.cpp:316] Eltwise33_ReLU67_0_split needs backward computation.
I0612 11:05:14.433269  4990 net.cpp:316] ReLU67 needs backward computation.
I0612 11:05:14.433274  4990 net.cpp:316] Eltwise33 needs backward computation.
I0612 11:05:14.433279  4990 net.cpp:316] Scale67 needs backward computation.
I0612 11:05:14.433282  4990 net.cpp:316] BatchNorm67 needs backward computation.
I0612 11:05:14.433285  4990 net.cpp:316] Convolution67 needs backward computation.
I0612 11:05:14.433290  4990 net.cpp:316] ReLU66 needs backward computation.
I0612 11:05:14.433295  4990 net.cpp:316] Scale66 needs backward computation.
I0612 11:05:14.433298  4990 net.cpp:316] BatchNorm66 needs backward computation.
I0612 11:05:14.433302  4990 net.cpp:316] Convolution66 needs backward computation.
I0612 11:05:14.433306  4990 net.cpp:316] Eltwise32_ReLU65_0_split needs backward computation.
I0612 11:05:14.433310  4990 net.cpp:316] ReLU65 needs backward computation.
I0612 11:05:14.433315  4990 net.cpp:316] Eltwise32 needs backward computation.
I0612 11:05:14.433320  4990 net.cpp:316] Scale65 needs backward computation.
I0612 11:05:14.433325  4990 net.cpp:316] BatchNorm65 needs backward computation.
I0612 11:05:14.433328  4990 net.cpp:316] Convolution65 needs backward computation.
I0612 11:05:14.433332  4990 net.cpp:316] ReLU64 needs backward computation.
I0612 11:05:14.433336  4990 net.cpp:316] Scale64 needs backward computation.
I0612 11:05:14.433341  4990 net.cpp:316] BatchNorm64 needs backward computation.
I0612 11:05:14.433344  4990 net.cpp:316] Convolution64 needs backward computation.
I0612 11:05:14.433348  4990 net.cpp:316] Eltwise31_ReLU63_0_split needs backward computation.
I0612 11:05:14.433352  4990 net.cpp:316] ReLU63 needs backward computation.
I0612 11:05:14.433357  4990 net.cpp:316] Eltwise31 needs backward computation.
I0612 11:05:14.433360  4990 net.cpp:316] Scale63 needs backward computation.
I0612 11:05:14.433364  4990 net.cpp:316] BatchNorm63 needs backward computation.
I0612 11:05:14.433367  4990 net.cpp:316] Convolution63 needs backward computation.
I0612 11:05:14.433372  4990 net.cpp:316] ReLU62 needs backward computation.
I0612 11:05:14.433377  4990 net.cpp:316] Scale62 needs backward computation.
I0612 11:05:14.433380  4990 net.cpp:316] BatchNorm62 needs backward computation.
I0612 11:05:14.433384  4990 net.cpp:316] Convolution62 needs backward computation.
I0612 11:05:14.433388  4990 net.cpp:316] Eltwise30_ReLU61_0_split needs backward computation.
I0612 11:05:14.433393  4990 net.cpp:316] ReLU61 needs backward computation.
I0612 11:05:14.433395  4990 net.cpp:316] Eltwise30 needs backward computation.
I0612 11:05:14.433400  4990 net.cpp:316] Scale61 needs backward computation.
I0612 11:05:14.433405  4990 net.cpp:316] BatchNorm61 needs backward computation.
I0612 11:05:14.433409  4990 net.cpp:316] Convolution61 needs backward computation.
I0612 11:05:14.433413  4990 net.cpp:316] ReLU60 needs backward computation.
I0612 11:05:14.433418  4990 net.cpp:316] Scale60 needs backward computation.
I0612 11:05:14.433421  4990 net.cpp:316] BatchNorm60 needs backward computation.
I0612 11:05:14.433425  4990 net.cpp:316] Convolution60 needs backward computation.
I0612 11:05:14.433434  4990 net.cpp:316] Eltwise29_ReLU59_0_split needs backward computation.
I0612 11:05:14.433439  4990 net.cpp:316] ReLU59 needs backward computation.
I0612 11:05:14.433442  4990 net.cpp:316] Eltwise29 needs backward computation.
I0612 11:05:14.433447  4990 net.cpp:316] Scale59 needs backward computation.
I0612 11:05:14.433451  4990 net.cpp:316] BatchNorm59 needs backward computation.
I0612 11:05:14.433455  4990 net.cpp:316] Convolution59 needs backward computation.
I0612 11:05:14.433459  4990 net.cpp:316] ReLU58 needs backward computation.
I0612 11:05:14.433464  4990 net.cpp:316] Scale58 needs backward computation.
I0612 11:05:14.433467  4990 net.cpp:316] BatchNorm58 needs backward computation.
I0612 11:05:14.433470  4990 net.cpp:316] Convolution58 needs backward computation.
I0612 11:05:14.433475  4990 net.cpp:316] Eltwise28_ReLU57_0_split needs backward computation.
I0612 11:05:14.433480  4990 net.cpp:316] ReLU57 needs backward computation.
I0612 11:05:14.433482  4990 net.cpp:316] Eltwise28 needs backward computation.
I0612 11:05:14.433487  4990 net.cpp:316] Scale57 needs backward computation.
I0612 11:05:14.433491  4990 net.cpp:316] BatchNorm57 needs backward computation.
I0612 11:05:14.433495  4990 net.cpp:316] Convolution57 needs backward computation.
I0612 11:05:14.433500  4990 net.cpp:316] ReLU56 needs backward computation.
I0612 11:05:14.433503  4990 net.cpp:316] Scale56 needs backward computation.
I0612 11:05:14.433507  4990 net.cpp:316] BatchNorm56 needs backward computation.
I0612 11:05:14.433511  4990 net.cpp:316] Convolution56 needs backward computation.
I0612 11:05:14.433516  4990 net.cpp:316] Eltwise27_ReLU55_0_split needs backward computation.
I0612 11:05:14.433519  4990 net.cpp:316] ReLU55 needs backward computation.
I0612 11:05:14.433523  4990 net.cpp:316] Eltwise27 needs backward computation.
I0612 11:05:14.433528  4990 net.cpp:316] Scale55 needs backward computation.
I0612 11:05:14.433532  4990 net.cpp:316] BatchNorm55 needs backward computation.
I0612 11:05:14.433537  4990 net.cpp:316] Convolution55 needs backward computation.
I0612 11:05:14.433540  4990 net.cpp:316] ReLU54 needs backward computation.
I0612 11:05:14.433544  4990 net.cpp:316] Scale54 needs backward computation.
I0612 11:05:14.433549  4990 net.cpp:316] BatchNorm54 needs backward computation.
I0612 11:05:14.433553  4990 net.cpp:316] Convolution54 needs backward computation.
I0612 11:05:14.433557  4990 net.cpp:316] Eltwise26_ReLU53_0_split needs backward computation.
I0612 11:05:14.433562  4990 net.cpp:316] ReLU53 needs backward computation.
I0612 11:05:14.433565  4990 net.cpp:316] Eltwise26 needs backward computation.
I0612 11:05:14.433570  4990 net.cpp:316] Scale53 needs backward computation.
I0612 11:05:14.433574  4990 net.cpp:316] BatchNorm53 needs backward computation.
I0612 11:05:14.433578  4990 net.cpp:316] Convolution53 needs backward computation.
I0612 11:05:14.433583  4990 net.cpp:316] ReLU52 needs backward computation.
I0612 11:05:14.433588  4990 net.cpp:316] Scale52 needs backward computation.
I0612 11:05:14.433591  4990 net.cpp:316] BatchNorm52 needs backward computation.
I0612 11:05:14.433595  4990 net.cpp:316] Convolution52 needs backward computation.
I0612 11:05:14.433599  4990 net.cpp:316] Eltwise25_ReLU51_0_split needs backward computation.
I0612 11:05:14.433604  4990 net.cpp:316] ReLU51 needs backward computation.
I0612 11:05:14.433607  4990 net.cpp:316] Eltwise25 needs backward computation.
I0612 11:05:14.433611  4990 net.cpp:316] Scale51 needs backward computation.
I0612 11:05:14.433616  4990 net.cpp:316] BatchNorm51 needs backward computation.
I0612 11:05:14.433620  4990 net.cpp:316] Convolution51 needs backward computation.
I0612 11:05:14.433624  4990 net.cpp:316] ReLU50 needs backward computation.
I0612 11:05:14.433629  4990 net.cpp:316] Scale50 needs backward computation.
I0612 11:05:14.433634  4990 net.cpp:316] BatchNorm50 needs backward computation.
I0612 11:05:14.433637  4990 net.cpp:316] Convolution50 needs backward computation.
I0612 11:05:14.433645  4990 net.cpp:316] Eltwise24_ReLU49_0_split needs backward computation.
I0612 11:05:14.433648  4990 net.cpp:316] ReLU49 needs backward computation.
I0612 11:05:14.433652  4990 net.cpp:316] Eltwise24 needs backward computation.
I0612 11:05:14.433656  4990 net.cpp:316] Scale49 needs backward computation.
I0612 11:05:14.433660  4990 net.cpp:316] BatchNorm49 needs backward computation.
I0612 11:05:14.433665  4990 net.cpp:316] Convolution49 needs backward computation.
I0612 11:05:14.433668  4990 net.cpp:316] ReLU48 needs backward computation.
I0612 11:05:14.433673  4990 net.cpp:316] Scale48 needs backward computation.
I0612 11:05:14.433677  4990 net.cpp:316] BatchNorm48 needs backward computation.
I0612 11:05:14.433681  4990 net.cpp:316] Convolution48 needs backward computation.
I0612 11:05:14.433686  4990 net.cpp:316] Eltwise23_ReLU47_0_split needs backward computation.
I0612 11:05:14.433689  4990 net.cpp:316] ReLU47 needs backward computation.
I0612 11:05:14.433693  4990 net.cpp:316] Eltwise23 needs backward computation.
I0612 11:05:14.433698  4990 net.cpp:316] Scale47 needs backward computation.
I0612 11:05:14.433703  4990 net.cpp:316] BatchNorm47 needs backward computation.
I0612 11:05:14.433707  4990 net.cpp:316] Convolution47 needs backward computation.
I0612 11:05:14.433712  4990 net.cpp:316] ReLU46 needs backward computation.
I0612 11:05:14.433715  4990 net.cpp:316] Scale46 needs backward computation.
I0612 11:05:14.433720  4990 net.cpp:316] BatchNorm46 needs backward computation.
I0612 11:05:14.433724  4990 net.cpp:316] Convolution46 needs backward computation.
I0612 11:05:14.433728  4990 net.cpp:316] Eltwise22_ReLU45_0_split needs backward computation.
I0612 11:05:14.433732  4990 net.cpp:316] ReLU45 needs backward computation.
I0612 11:05:14.433737  4990 net.cpp:316] Eltwise22 needs backward computation.
I0612 11:05:14.433740  4990 net.cpp:316] Scale45 needs backward computation.
I0612 11:05:14.433744  4990 net.cpp:316] BatchNorm45 needs backward computation.
I0612 11:05:14.433748  4990 net.cpp:316] Convolution45 needs backward computation.
I0612 11:05:14.433753  4990 net.cpp:316] ReLU44 needs backward computation.
I0612 11:05:14.433756  4990 net.cpp:316] Scale44 needs backward computation.
I0612 11:05:14.433759  4990 net.cpp:316] BatchNorm44 needs backward computation.
I0612 11:05:14.433763  4990 net.cpp:316] Convolution44 needs backward computation.
I0612 11:05:14.433768  4990 net.cpp:316] Eltwise21_ReLU43_0_split needs backward computation.
I0612 11:05:14.433771  4990 net.cpp:316] ReLU43 needs backward computation.
I0612 11:05:14.433776  4990 net.cpp:316] Eltwise21 needs backward computation.
I0612 11:05:14.433782  4990 net.cpp:316] Scale43 needs backward computation.
I0612 11:05:14.433786  4990 net.cpp:316] BatchNorm43 needs backward computation.
I0612 11:05:14.433790  4990 net.cpp:316] Convolution43 needs backward computation.
I0612 11:05:14.433794  4990 net.cpp:316] ReLU42 needs backward computation.
I0612 11:05:14.433799  4990 net.cpp:316] Scale42 needs backward computation.
I0612 11:05:14.433804  4990 net.cpp:316] BatchNorm42 needs backward computation.
I0612 11:05:14.433809  4990 net.cpp:316] Convolution42 needs backward computation.
I0612 11:05:14.433812  4990 net.cpp:316] Eltwise20_ReLU41_0_split needs backward computation.
I0612 11:05:14.433816  4990 net.cpp:316] ReLU41 needs backward computation.
I0612 11:05:14.433821  4990 net.cpp:316] Eltwise20 needs backward computation.
I0612 11:05:14.433826  4990 net.cpp:316] Scale41 needs backward computation.
I0612 11:05:14.433830  4990 net.cpp:316] BatchNorm41 needs backward computation.
I0612 11:05:14.433835  4990 net.cpp:316] Convolution41 needs backward computation.
I0612 11:05:14.433838  4990 net.cpp:316] ReLU40 needs backward computation.
I0612 11:05:14.433842  4990 net.cpp:316] Scale40 needs backward computation.
I0612 11:05:14.433846  4990 net.cpp:316] BatchNorm40 needs backward computation.
I0612 11:05:14.433851  4990 net.cpp:316] Convolution40 needs backward computation.
I0612 11:05:14.433856  4990 net.cpp:316] Eltwise19_ReLU39_0_split needs backward computation.
I0612 11:05:14.433862  4990 net.cpp:316] ReLU39 needs backward computation.
I0612 11:05:14.433867  4990 net.cpp:316] Eltwise19 needs backward computation.
I0612 11:05:14.433871  4990 net.cpp:316] Scale39 needs backward computation.
I0612 11:05:14.433876  4990 net.cpp:316] BatchNorm39 needs backward computation.
I0612 11:05:14.433879  4990 net.cpp:316] Convolution39 needs backward computation.
I0612 11:05:14.433883  4990 net.cpp:316] ReLU38 needs backward computation.
I0612 11:05:14.433888  4990 net.cpp:316] Scale38 needs backward computation.
I0612 11:05:14.433892  4990 net.cpp:316] BatchNorm38 needs backward computation.
I0612 11:05:14.433897  4990 net.cpp:316] Convolution38 needs backward computation.
I0612 11:05:14.433900  4990 net.cpp:316] Concat1 needs backward computation.
I0612 11:05:14.433905  4990 net.cpp:318] Input1 does not need backward computation.
I0612 11:05:14.433909  4990 net.cpp:316] Pooling1 needs backward computation.
I0612 11:05:14.433914  4990 net.cpp:316] Eltwise18_ReLU37_0_split needs backward computation.
I0612 11:05:14.433918  4990 net.cpp:316] ReLU37 needs backward computation.
I0612 11:05:14.433923  4990 net.cpp:316] Eltwise18 needs backward computation.
I0612 11:05:14.433926  4990 net.cpp:316] Scale37 needs backward computation.
I0612 11:05:14.433931  4990 net.cpp:316] BatchNorm37 needs backward computation.
I0612 11:05:14.433935  4990 net.cpp:316] Convolution37 needs backward computation.
I0612 11:05:14.433941  4990 net.cpp:316] ReLU36 needs backward computation.
I0612 11:05:14.433946  4990 net.cpp:316] Scale36 needs backward computation.
I0612 11:05:14.433951  4990 net.cpp:316] BatchNorm36 needs backward computation.
I0612 11:05:14.433955  4990 net.cpp:316] Convolution36 needs backward computation.
I0612 11:05:14.433959  4990 net.cpp:316] Eltwise17_ReLU35_0_split needs backward computation.
I0612 11:05:14.433964  4990 net.cpp:316] ReLU35 needs backward computation.
I0612 11:05:14.433967  4990 net.cpp:316] Eltwise17 needs backward computation.
I0612 11:05:14.433972  4990 net.cpp:316] Scale35 needs backward computation.
I0612 11:05:14.433977  4990 net.cpp:316] BatchNorm35 needs backward computation.
I0612 11:05:14.433980  4990 net.cpp:316] Convolution35 needs backward computation.
I0612 11:05:14.433984  4990 net.cpp:316] ReLU34 needs backward computation.
I0612 11:05:14.433990  4990 net.cpp:316] Scale34 needs backward computation.
I0612 11:05:14.433995  4990 net.cpp:316] BatchNorm34 needs backward computation.
I0612 11:05:14.433998  4990 net.cpp:316] Convolution34 needs backward computation.
I0612 11:05:14.434002  4990 net.cpp:316] Eltwise16_ReLU33_0_split needs backward computation.
I0612 11:05:14.434006  4990 net.cpp:316] ReLU33 needs backward computation.
I0612 11:05:14.434010  4990 net.cpp:316] Eltwise16 needs backward computation.
I0612 11:05:14.434015  4990 net.cpp:316] Scale33 needs backward computation.
I0612 11:05:14.434020  4990 net.cpp:316] BatchNorm33 needs backward computation.
I0612 11:05:14.434025  4990 net.cpp:316] Convolution33 needs backward computation.
I0612 11:05:14.434028  4990 net.cpp:316] ReLU32 needs backward computation.
I0612 11:05:14.434032  4990 net.cpp:316] Scale32 needs backward computation.
I0612 11:05:14.434037  4990 net.cpp:316] BatchNorm32 needs backward computation.
I0612 11:05:14.434041  4990 net.cpp:316] Convolution32 needs backward computation.
I0612 11:05:14.434046  4990 net.cpp:316] Eltwise15_ReLU31_0_split needs backward computation.
I0612 11:05:14.434049  4990 net.cpp:316] ReLU31 needs backward computation.
I0612 11:05:14.434053  4990 net.cpp:316] Eltwise15 needs backward computation.
I0612 11:05:14.434057  4990 net.cpp:316] Scale31 needs backward computation.
I0612 11:05:14.434062  4990 net.cpp:316] BatchNorm31 needs backward computation.
I0612 11:05:14.434067  4990 net.cpp:316] Convolution31 needs backward computation.
I0612 11:05:14.434070  4990 net.cpp:316] ReLU30 needs backward computation.
I0612 11:05:14.434074  4990 net.cpp:316] Scale30 needs backward computation.
I0612 11:05:14.434078  4990 net.cpp:316] BatchNorm30 needs backward computation.
I0612 11:05:14.434084  4990 net.cpp:316] Convolution30 needs backward computation.
I0612 11:05:14.434089  4990 net.cpp:316] Eltwise14_ReLU29_0_split needs backward computation.
I0612 11:05:14.434093  4990 net.cpp:316] ReLU29 needs backward computation.
I0612 11:05:14.434098  4990 net.cpp:316] Eltwise14 needs backward computation.
I0612 11:05:14.434103  4990 net.cpp:316] Scale29 needs backward computation.
I0612 11:05:14.434108  4990 net.cpp:316] BatchNorm29 needs backward computation.
I0612 11:05:14.434111  4990 net.cpp:316] Convolution29 needs backward computation.
I0612 11:05:14.434115  4990 net.cpp:316] ReLU28 needs backward computation.
I0612 11:05:14.434120  4990 net.cpp:316] Scale28 needs backward computation.
I0612 11:05:14.434125  4990 net.cpp:316] BatchNorm28 needs backward computation.
I0612 11:05:14.434129  4990 net.cpp:316] Convolution28 needs backward computation.
I0612 11:05:14.434134  4990 net.cpp:316] Eltwise13_ReLU27_0_split needs backward computation.
I0612 11:05:14.434139  4990 net.cpp:316] ReLU27 needs backward computation.
I0612 11:05:14.434142  4990 net.cpp:316] Eltwise13 needs backward computation.
I0612 11:05:14.434146  4990 net.cpp:316] Scale27 needs backward computation.
I0612 11:05:14.434150  4990 net.cpp:316] BatchNorm27 needs backward computation.
I0612 11:05:14.434154  4990 net.cpp:316] Convolution27 needs backward computation.
I0612 11:05:14.434159  4990 net.cpp:316] ReLU26 needs backward computation.
I0612 11:05:14.434162  4990 net.cpp:316] Scale26 needs backward computation.
I0612 11:05:14.434166  4990 net.cpp:316] BatchNorm26 needs backward computation.
I0612 11:05:14.434171  4990 net.cpp:316] Convolution26 needs backward computation.
I0612 11:05:14.434175  4990 net.cpp:316] Eltwise12_ReLU25_0_split needs backward computation.
I0612 11:05:14.434180  4990 net.cpp:316] ReLU25 needs backward computation.
I0612 11:05:14.434183  4990 net.cpp:316] Eltwise12 needs backward computation.
I0612 11:05:14.434188  4990 net.cpp:316] Scale25 needs backward computation.
I0612 11:05:14.434193  4990 net.cpp:316] BatchNorm25 needs backward computation.
I0612 11:05:14.434197  4990 net.cpp:316] Convolution25 needs backward computation.
I0612 11:05:14.434201  4990 net.cpp:316] ReLU24 needs backward computation.
I0612 11:05:14.434206  4990 net.cpp:316] Scale24 needs backward computation.
I0612 11:05:14.434211  4990 net.cpp:316] BatchNorm24 needs backward computation.
I0612 11:05:14.434214  4990 net.cpp:316] Convolution24 needs backward computation.
I0612 11:05:14.434218  4990 net.cpp:316] Eltwise11_ReLU23_0_split needs backward computation.
I0612 11:05:14.434223  4990 net.cpp:316] ReLU23 needs backward computation.
I0612 11:05:14.434226  4990 net.cpp:316] Eltwise11 needs backward computation.
I0612 11:05:14.434231  4990 net.cpp:316] Scale23 needs backward computation.
I0612 11:05:14.434236  4990 net.cpp:316] BatchNorm23 needs backward computation.
I0612 11:05:14.434238  4990 net.cpp:316] Convolution23 needs backward computation.
I0612 11:05:14.434243  4990 net.cpp:316] ReLU22 needs backward computation.
I0612 11:05:14.434247  4990 net.cpp:316] Scale22 needs backward computation.
I0612 11:05:14.434252  4990 net.cpp:316] BatchNorm22 needs backward computation.
I0612 11:05:14.434254  4990 net.cpp:316] Convolution22 needs backward computation.
I0612 11:05:14.434259  4990 net.cpp:316] Eltwise10_ReLU21_0_split needs backward computation.
I0612 11:05:14.434263  4990 net.cpp:316] ReLU21 needs backward computation.
I0612 11:05:14.434267  4990 net.cpp:316] Eltwise10 needs backward computation.
I0612 11:05:14.434273  4990 net.cpp:316] Scale21 needs backward computation.
I0612 11:05:14.434278  4990 net.cpp:316] BatchNorm21 needs backward computation.
I0612 11:05:14.434281  4990 net.cpp:316] Convolution21 needs backward computation.
I0612 11:05:14.434286  4990 net.cpp:316] ReLU20 needs backward computation.
I0612 11:05:14.434291  4990 net.cpp:316] Scale20 needs backward computation.
I0612 11:05:14.434295  4990 net.cpp:316] BatchNorm20 needs backward computation.
I0612 11:05:14.434300  4990 net.cpp:316] Convolution20 needs backward computation.
I0612 11:05:14.434308  4990 net.cpp:316] Eltwise9_ReLU19_0_split needs backward computation.
I0612 11:05:14.434312  4990 net.cpp:316] ReLU19 needs backward computation.
I0612 11:05:14.434316  4990 net.cpp:316] Eltwise9 needs backward computation.
I0612 11:05:14.434324  4990 net.cpp:316] Scale19 needs backward computation.
I0612 11:05:14.434329  4990 net.cpp:316] BatchNorm19 needs backward computation.
I0612 11:05:14.434332  4990 net.cpp:316] Convolution19 needs backward computation.
I0612 11:05:14.434336  4990 net.cpp:316] ReLU18 needs backward computation.
I0612 11:05:14.434340  4990 net.cpp:316] Scale18 needs backward computation.
I0612 11:05:14.434345  4990 net.cpp:316] BatchNorm18 needs backward computation.
I0612 11:05:14.434350  4990 net.cpp:316] Convolution18 needs backward computation.
I0612 11:05:14.434362  4990 net.cpp:316] Eltwise8_ReLU17_0_split needs backward computation.
I0612 11:05:14.434367  4990 net.cpp:316] ReLU17 needs backward computation.
I0612 11:05:14.434371  4990 net.cpp:316] Eltwise8 needs backward computation.
I0612 11:05:14.434376  4990 net.cpp:316] Scale17 needs backward computation.
I0612 11:05:14.434381  4990 net.cpp:316] BatchNorm17 needs backward computation.
I0612 11:05:14.434384  4990 net.cpp:316] Convolution17 needs backward computation.
I0612 11:05:14.434388  4990 net.cpp:316] ReLU16 needs backward computation.
I0612 11:05:14.434392  4990 net.cpp:316] Scale16 needs backward computation.
I0612 11:05:14.434396  4990 net.cpp:316] BatchNorm16 needs backward computation.
I0612 11:05:14.434399  4990 net.cpp:316] Convolution16 needs backward computation.
I0612 11:05:14.434404  4990 net.cpp:316] Eltwise7_ReLU15_0_split needs backward computation.
I0612 11:05:14.434408  4990 net.cpp:316] ReLU15 needs backward computation.
I0612 11:05:14.434412  4990 net.cpp:316] Eltwise7 needs backward computation.
I0612 11:05:14.434417  4990 net.cpp:316] Scale15 needs backward computation.
I0612 11:05:14.434422  4990 net.cpp:316] BatchNorm15 needs backward computation.
I0612 11:05:14.434427  4990 net.cpp:316] Convolution15 needs backward computation.
I0612 11:05:14.434432  4990 net.cpp:316] ReLU14 needs backward computation.
I0612 11:05:14.434435  4990 net.cpp:316] Scale14 needs backward computation.
I0612 11:05:14.434440  4990 net.cpp:316] BatchNorm14 needs backward computation.
I0612 11:05:14.434445  4990 net.cpp:316] Convolution14 needs backward computation.
I0612 11:05:14.434449  4990 net.cpp:316] Eltwise6_ReLU13_0_split needs backward computation.
I0612 11:05:14.434453  4990 net.cpp:316] ReLU13 needs backward computation.
I0612 11:05:14.434458  4990 net.cpp:316] Eltwise6 needs backward computation.
I0612 11:05:14.434463  4990 net.cpp:316] Scale13 needs backward computation.
I0612 11:05:14.434468  4990 net.cpp:316] BatchNorm13 needs backward computation.
I0612 11:05:14.434471  4990 net.cpp:316] Convolution13 needs backward computation.
I0612 11:05:14.434475  4990 net.cpp:316] ReLU12 needs backward computation.
I0612 11:05:14.434479  4990 net.cpp:316] Scale12 needs backward computation.
I0612 11:05:14.434484  4990 net.cpp:316] BatchNorm12 needs backward computation.
I0612 11:05:14.434489  4990 net.cpp:316] Convolution12 needs backward computation.
I0612 11:05:14.434492  4990 net.cpp:316] Eltwise5_ReLU11_0_split needs backward computation.
I0612 11:05:14.434497  4990 net.cpp:316] ReLU11 needs backward computation.
I0612 11:05:14.434501  4990 net.cpp:316] Eltwise5 needs backward computation.
I0612 11:05:14.434506  4990 net.cpp:316] Scale11 needs backward computation.
I0612 11:05:14.434511  4990 net.cpp:316] BatchNorm11 needs backward computation.
I0612 11:05:14.434515  4990 net.cpp:316] Convolution11 needs backward computation.
I0612 11:05:14.434520  4990 net.cpp:316] ReLU10 needs backward computation.
I0612 11:05:14.434523  4990 net.cpp:316] Scale10 needs backward computation.
I0612 11:05:14.434528  4990 net.cpp:316] BatchNorm10 needs backward computation.
I0612 11:05:14.434533  4990 net.cpp:316] Convolution10 needs backward computation.
I0612 11:05:14.434541  4990 net.cpp:316] Eltwise4_ReLU9_0_split needs backward computation.
I0612 11:05:14.434545  4990 net.cpp:316] ReLU9 needs backward computation.
I0612 11:05:14.434550  4990 net.cpp:316] Eltwise4 needs backward computation.
I0612 11:05:14.434556  4990 net.cpp:316] Scale9 needs backward computation.
I0612 11:05:14.434559  4990 net.cpp:316] BatchNorm9 needs backward computation.
I0612 11:05:14.434562  4990 net.cpp:316] Convolution9 needs backward computation.
I0612 11:05:14.434567  4990 net.cpp:316] ReLU8 needs backward computation.
I0612 11:05:14.434571  4990 net.cpp:316] Scale8 needs backward computation.
I0612 11:05:14.434574  4990 net.cpp:316] BatchNorm8 needs backward computation.
I0612 11:05:14.434578  4990 net.cpp:316] Convolution8 needs backward computation.
I0612 11:05:14.434583  4990 net.cpp:316] Eltwise3_ReLU7_0_split needs backward computation.
I0612 11:05:14.434587  4990 net.cpp:316] ReLU7 needs backward computation.
I0612 11:05:14.434592  4990 net.cpp:316] Eltwise3 needs backward computation.
I0612 11:05:14.434597  4990 net.cpp:316] Scale7 needs backward computation.
I0612 11:05:14.434602  4990 net.cpp:316] BatchNorm7 needs backward computation.
I0612 11:05:14.434605  4990 net.cpp:316] Convolution7 needs backward computation.
I0612 11:05:14.434609  4990 net.cpp:316] ReLU6 needs backward computation.
I0612 11:05:14.434614  4990 net.cpp:316] Scale6 needs backward computation.
I0612 11:05:14.434619  4990 net.cpp:316] BatchNorm6 needs backward computation.
I0612 11:05:14.434623  4990 net.cpp:316] Convolution6 needs backward computation.
I0612 11:05:14.434628  4990 net.cpp:316] Eltwise2_ReLU5_0_split needs backward computation.
I0612 11:05:14.434633  4990 net.cpp:316] ReLU5 needs backward computation.
I0612 11:05:14.434636  4990 net.cpp:316] Eltwise2 needs backward computation.
I0612 11:05:14.434640  4990 net.cpp:316] Scale5 needs backward computation.
I0612 11:05:14.434645  4990 net.cpp:316] BatchNorm5 needs backward computation.
I0612 11:05:14.434649  4990 net.cpp:316] Convolution5 needs backward computation.
I0612 11:05:14.434654  4990 net.cpp:316] ReLU4 needs backward computation.
I0612 11:05:14.434659  4990 net.cpp:316] Scale4 needs backward computation.
I0612 11:05:14.434664  4990 net.cpp:316] BatchNorm4 needs backward computation.
I0612 11:05:14.434667  4990 net.cpp:316] Convolution4 needs backward computation.
I0612 11:05:14.434672  4990 net.cpp:316] Eltwise1_ReLU3_0_split needs backward computation.
I0612 11:05:14.434676  4990 net.cpp:316] ReLU3 needs backward computation.
I0612 11:05:14.434680  4990 net.cpp:316] Eltwise1 needs backward computation.
I0612 11:05:14.434686  4990 net.cpp:316] Scale3 needs backward computation.
I0612 11:05:14.434690  4990 net.cpp:316] BatchNorm3 needs backward computation.
I0612 11:05:14.434695  4990 net.cpp:316] Convolution3 needs backward computation.
I0612 11:05:14.434700  4990 net.cpp:316] ReLU2 needs backward computation.
I0612 11:05:14.434705  4990 net.cpp:316] Scale2 needs backward computation.
I0612 11:05:14.434710  4990 net.cpp:316] BatchNorm2 needs backward computation.
I0612 11:05:14.434715  4990 net.cpp:316] Convolution2 needs backward computation.
I0612 11:05:14.434720  4990 net.cpp:316] Convolution1_ReLU1_0_split needs backward computation.
I0612 11:05:14.434725  4990 net.cpp:316] ReLU1 needs backward computation.
I0612 11:05:14.434728  4990 net.cpp:316] Scale1 needs backward computation.
I0612 11:05:14.434732  4990 net.cpp:316] BatchNorm1 needs backward computation.
I0612 11:05:14.434736  4990 net.cpp:316] Convolution1 needs backward computation.
I0612 11:05:14.434741  4990 net.cpp:318] Data2_Data1_1_split does not need backward computation.
I0612 11:05:14.434746  4990 net.cpp:318] Data1 does not need backward computation.
I0612 11:05:14.434749  4990 net.cpp:360] This network produces output Accuracy
I0612 11:05:14.434754  4990 net.cpp:360] This network produces output SoftmaxWithLoss1
I0612 11:05:14.435086  4990 net.cpp:374] Network initialization done.
I0612 11:05:14.437587  4990 solver.cpp:65] Solver scaffolding done.
I0612 11:05:14.470217  4990 solver.cpp:284] Solving
I0612 11:05:14.470234  4990 solver.cpp:285] Learning Rate Policy: multistep
I0612 11:05:14.487886  4990 solver.cpp:342] Iteration 0, Testing net (#0)
I0612 11:06:20.038424  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.100078
I0612 11:06:20.038467  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0612 11:06:22.620312  4990 solver.cpp:233] Iteration 0, loss = 5.81584
I0612 11:06:22.620365  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 5.81584 (* 1 = 5.81584 loss)
I0612 11:06:22.620384  4990 sgd_solver.cpp:294] Iteration 0, lr = 0.02
I0612 11:23:23.709270  4990 solver.cpp:342] Iteration 400, Testing net (#0)
I0612 11:24:28.523684  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.233047
I0612 11:24:28.523723  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 2.4794 (* 1 = 2.4794 loss)
I0612 11:24:31.043740  4990 solver.cpp:233] Iteration 400, loss = 1.39138
I0612 11:24:31.043762  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.39138 (* 1 = 1.39138 loss)
I0612 11:24:31.043771  4990 sgd_solver.cpp:294] Iteration 400, lr = 0.02
I0612 11:41:34.857079  4990 solver.cpp:342] Iteration 800, Testing net (#0)
I0612 11:42:39.533432  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.371406
I0612 11:42:39.533468  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 2.04866 (* 1 = 2.04866 loss)
I0612 11:42:42.056385  4990 solver.cpp:233] Iteration 800, loss = 1.04106
I0612 11:42:42.056407  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 1.04106 (* 1 = 1.04106 loss)
I0612 11:42:42.056417  4990 sgd_solver.cpp:294] Iteration 800, lr = 0.02
I0612 11:59:45.856969  4990 solver.cpp:342] Iteration 1200, Testing net (#0)
I0612 12:00:50.468176  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.392891
I0612 12:00:50.468214  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 2.45204 (* 1 = 2.45204 loss)
I0612 12:00:52.988138  4990 solver.cpp:233] Iteration 1200, loss = 0.743563
I0612 12:00:52.988165  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.743563 (* 1 = 0.743563 loss)
I0612 12:00:52.988174  4990 sgd_solver.cpp:294] Iteration 1200, lr = 0.02
I0612 12:17:56.578910  4990 solver.cpp:342] Iteration 1600, Testing net (#0)
I0612 12:19:01.188171  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.581328
I0612 12:19:01.188205  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.39465 (* 1 = 1.39465 loss)
I0612 12:19:03.711207  4990 solver.cpp:233] Iteration 1600, loss = 0.785952
I0612 12:19:03.711233  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.785952 (* 1 = 0.785952 loss)
I0612 12:19:03.711242  4990 sgd_solver.cpp:294] Iteration 1600, lr = 0.02
I0612 12:36:07.882947  4990 solver.cpp:342] Iteration 2000, Testing net (#0)
I0612 12:37:12.559010  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.640781
I0612 12:37:12.559052  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.18836 (* 1 = 1.18836 loss)
I0612 12:37:15.079988  4990 solver.cpp:233] Iteration 2000, loss = 0.714557
I0612 12:37:15.080018  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.714557 (* 1 = 0.714557 loss)
I0612 12:37:15.080027  4990 sgd_solver.cpp:294] Iteration 2000, lr = 0.02
I0612 12:54:19.069880  4990 solver.cpp:342] Iteration 2400, Testing net (#0)
I0612 12:55:23.750125  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.659453
I0612 12:55:23.750162  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.09706 (* 1 = 1.09706 loss)
I0612 12:55:26.309017  4990 solver.cpp:233] Iteration 2400, loss = 0.514778
I0612 12:55:26.309044  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.514778 (* 1 = 0.514778 loss)
I0612 12:55:26.309052  4990 sgd_solver.cpp:294] Iteration 2400, lr = 0.02
I0612 13:12:30.504659  4990 solver.cpp:342] Iteration 2800, Testing net (#0)
I0612 13:13:35.227231  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.737969
I0612 13:13:35.227275  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.800655 (* 1 = 0.800655 loss)
I0612 13:13:37.751766  4990 solver.cpp:233] Iteration 2800, loss = 0.582524
I0612 13:13:37.751792  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.582524 (* 1 = 0.582524 loss)
I0612 13:13:37.751801  4990 sgd_solver.cpp:294] Iteration 2800, lr = 0.02
I0612 13:30:41.694551  4990 solver.cpp:342] Iteration 3200, Testing net (#0)
I0612 13:31:46.360497  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.684453
I0612 13:31:46.360537  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.00614 (* 1 = 1.00614 loss)
I0612 13:31:48.882006  4990 solver.cpp:233] Iteration 3200, loss = 0.450488
I0612 13:31:48.882033  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.450488 (* 1 = 0.450488 loss)
I0612 13:31:48.882043  4990 sgd_solver.cpp:294] Iteration 3200, lr = 0.02
I0612 13:48:53.247442  4990 solver.cpp:342] Iteration 3600, Testing net (#0)
I0612 13:49:57.969092  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.697266
I0612 13:49:57.969132  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.08362 (* 1 = 1.08362 loss)
I0612 13:50:00.491302  4990 solver.cpp:233] Iteration 3600, loss = 0.417173
I0612 13:50:00.491328  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.417173 (* 1 = 0.417173 loss)
I0612 13:50:00.491338  4990 sgd_solver.cpp:294] Iteration 3600, lr = 0.02
I0612 14:07:04.473657  4990 solver.cpp:342] Iteration 4000, Testing net (#0)
I0612 14:08:09.114337  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.773359
I0612 14:08:09.114382  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.736293 (* 1 = 0.736293 loss)
I0612 14:08:11.636464  4990 solver.cpp:233] Iteration 4000, loss = 0.414126
I0612 14:08:11.636490  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.414126 (* 1 = 0.414126 loss)
I0612 14:08:11.636499  4990 sgd_solver.cpp:294] Iteration 4000, lr = 0.02
I0612 14:25:15.159221  4990 solver.cpp:342] Iteration 4400, Testing net (#0)
I0612 14:26:19.782799  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.665937
I0612 14:26:19.782841  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.25525 (* 1 = 1.25525 loss)
I0612 14:26:22.304139  4990 solver.cpp:233] Iteration 4400, loss = 0.466536
I0612 14:26:22.304167  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.466536 (* 1 = 0.466536 loss)
I0612 14:26:22.304177  4990 sgd_solver.cpp:294] Iteration 4400, lr = 0.02
I0612 14:43:25.820096  4990 solver.cpp:342] Iteration 4800, Testing net (#0)
I0612 14:44:30.461251  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.776016
I0612 14:44:30.461293  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.722398 (* 1 = 0.722398 loss)
I0612 14:44:32.981868  4990 solver.cpp:233] Iteration 4800, loss = 0.354957
I0612 14:44:32.981896  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.354957 (* 1 = 0.354957 loss)
I0612 14:44:32.981907  4990 sgd_solver.cpp:294] Iteration 4800, lr = 0.02
I0612 15:01:36.769330  4990 solver.cpp:342] Iteration 5200, Testing net (#0)
I0612 15:02:41.450291  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.767578
I0612 15:02:41.450330  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.771101 (* 1 = 0.771101 loss)
I0612 15:02:43.970090  4990 solver.cpp:233] Iteration 5200, loss = 0.417141
I0612 15:02:43.970123  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.417141 (* 1 = 0.417141 loss)
I0612 15:02:43.970132  4990 sgd_solver.cpp:294] Iteration 5200, lr = 0.02
I0612 15:19:48.479149  4990 solver.cpp:342] Iteration 5600, Testing net (#0)
I0612 15:20:53.158501  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.746328
I0612 15:20:53.158540  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.828048 (* 1 = 0.828048 loss)
I0612 15:20:55.683204  4990 solver.cpp:233] Iteration 5600, loss = 0.312771
I0612 15:20:55.683229  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.312771 (* 1 = 0.312771 loss)
I0612 15:20:55.683240  4990 sgd_solver.cpp:294] Iteration 5600, lr = 0.02
I0612 15:38:09.160071  4990 solver.cpp:342] Iteration 6000, Testing net (#0)
I0612 15:39:14.733070  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.776016
I0612 15:39:14.733119  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.72347 (* 1 = 0.72347 loss)
I0612 15:39:17.338337  4990 solver.cpp:233] Iteration 6000, loss = 0.325866
I0612 15:39:17.338388  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.325866 (* 1 = 0.325866 loss)
I0612 15:39:17.338403  4990 sgd_solver.cpp:294] Iteration 6000, lr = 0.02
I0612 15:56:31.560490  4990 solver.cpp:342] Iteration 6400, Testing net (#0)
I0612 15:57:37.170197  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.772656
I0612 15:57:37.170240  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.76005 (* 1 = 0.76005 loss)
I0612 15:57:39.721674  4990 solver.cpp:233] Iteration 6400, loss = 0.383403
I0612 15:57:39.721715  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.383403 (* 1 = 0.383403 loss)
I0612 15:57:39.721722  4990 sgd_solver.cpp:294] Iteration 6400, lr = 0.02
I0612 16:14:54.611559  4990 solver.cpp:342] Iteration 6800, Testing net (#0)
I0612 16:16:00.347451  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.739141
I0612 16:16:00.347510  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.936955 (* 1 = 0.936955 loss)
I0612 16:16:02.936275  4990 solver.cpp:233] Iteration 6800, loss = 0.411496
I0612 16:16:02.936312  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.411496 (* 1 = 0.411496 loss)
I0612 16:16:02.936319  4990 sgd_solver.cpp:294] Iteration 6800, lr = 0.02
I0612 16:33:16.695698  4990 solver.cpp:342] Iteration 7200, Testing net (#0)
I0612 16:34:21.468771  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.780312
I0612 16:34:21.468816  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.736788 (* 1 = 0.736788 loss)
I0612 16:34:23.995965  4990 solver.cpp:233] Iteration 7200, loss = 0.348492
I0612 16:34:23.996003  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.348492 (* 1 = 0.348492 loss)
I0612 16:34:23.996011  4990 sgd_solver.cpp:294] Iteration 7200, lr = 0.02
I0612 16:51:30.639912  4990 solver.cpp:342] Iteration 7600, Testing net (#0)
I0612 16:52:35.383579  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.796172
I0612 16:52:35.383623  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.740626 (* 1 = 0.740626 loss)
I0612 16:52:37.911118  4990 solver.cpp:233] Iteration 7600, loss = 0.287464
I0612 16:52:37.911167  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.287464 (* 1 = 0.287464 loss)
I0612 16:52:37.911177  4990 sgd_solver.cpp:294] Iteration 7600, lr = 0.02
I0612 17:09:44.576675  4990 solver.cpp:342] Iteration 8000, Testing net (#0)
I0612 17:10:49.322141  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.779922
I0612 17:10:49.322186  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.759745 (* 1 = 0.759745 loss)
I0612 17:10:51.860232  4990 solver.cpp:233] Iteration 8000, loss = 0.205468
I0612 17:10:51.860270  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.205468 (* 1 = 0.205468 loss)
I0612 17:10:51.860276  4990 sgd_solver.cpp:294] Iteration 8000, lr = 0.02
I0612 17:27:58.325817  4990 solver.cpp:342] Iteration 8400, Testing net (#0)
I0612 17:29:03.117609  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.793906
I0612 17:29:03.117650  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.715116 (* 1 = 0.715116 loss)
I0612 17:29:05.640841  4990 solver.cpp:233] Iteration 8400, loss = 0.379255
I0612 17:29:05.640880  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.379255 (* 1 = 0.379255 loss)
I0612 17:29:05.640887  4990 sgd_solver.cpp:294] Iteration 8400, lr = 0.02
I0612 17:46:11.995110  4990 solver.cpp:342] Iteration 8800, Testing net (#0)
I0612 17:47:16.769135  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.703203
I0612 17:47:16.769209  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.12098 (* 1 = 1.12098 loss)
I0612 17:47:19.303346  4990 solver.cpp:233] Iteration 8800, loss = 0.247005
I0612 17:47:19.303390  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.247005 (* 1 = 0.247005 loss)
I0612 17:47:19.303396  4990 sgd_solver.cpp:294] Iteration 8800, lr = 0.02
I0612 18:04:25.958492  4990 solver.cpp:342] Iteration 9200, Testing net (#0)
I0612 18:05:30.820610  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.837891
I0612 18:05:30.820654  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.530288 (* 1 = 0.530288 loss)
I0612 18:05:33.350761  4990 solver.cpp:233] Iteration 9200, loss = 0.228384
I0612 18:05:33.350801  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.228384 (* 1 = 0.228384 loss)
I0612 18:05:33.350810  4990 sgd_solver.cpp:294] Iteration 9200, lr = 0.02
I0612 18:22:39.845038  4990 solver.cpp:342] Iteration 9600, Testing net (#0)
I0612 18:23:44.608278  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.816172
I0612 18:23:44.608325  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.607259 (* 1 = 0.607259 loss)
I0612 18:23:47.144775  4990 solver.cpp:233] Iteration 9600, loss = 0.195936
I0612 18:23:47.144820  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.195936 (* 1 = 0.195936 loss)
I0612 18:23:47.144829  4990 sgd_solver.cpp:294] Iteration 9600, lr = 0.02
I0612 18:40:53.863816  4990 solver.cpp:342] Iteration 10000, Testing net (#0)
I0612 18:41:58.615658  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.820547
I0612 18:41:58.615703  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.627053 (* 1 = 0.627053 loss)
I0612 18:42:01.148746  4990 solver.cpp:233] Iteration 10000, loss = 0.286067
I0612 18:42:01.148794  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.286067 (* 1 = 0.286067 loss)
I0612 18:42:01.148802  4990 sgd_solver.cpp:294] Iteration 10000, lr = 0.02
I0612 18:59:08.183070  4990 solver.cpp:342] Iteration 10400, Testing net (#0)
I0612 19:00:12.944955  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.779375
I0612 19:00:12.945013  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.807479 (* 1 = 0.807479 loss)
I0612 19:00:15.476621  4990 solver.cpp:233] Iteration 10400, loss = 0.186586
I0612 19:00:15.476668  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.186586 (* 1 = 0.186586 loss)
I0612 19:00:15.476676  4990 sgd_solver.cpp:294] Iteration 10400, lr = 0.02
I0612 19:17:26.672430  4990 solver.cpp:342] Iteration 10800, Testing net (#0)
I0612 19:18:31.900210  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.748047
I0612 19:18:31.900251  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.0914 (* 1 = 1.0914 loss)
I0612 19:18:34.432055  4990 solver.cpp:233] Iteration 10800, loss = 0.148977
I0612 19:18:34.432106  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.148977 (* 1 = 0.148977 loss)
I0612 19:18:34.432113  4990 sgd_solver.cpp:294] Iteration 10800, lr = 0.02
I0612 19:35:48.733671  4990 solver.cpp:342] Iteration 11200, Testing net (#0)
I0612 19:36:53.808553  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.725312
I0612 19:36:53.808593  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.10608 (* 1 = 1.10608 loss)
I0612 19:36:56.355487  4990 solver.cpp:233] Iteration 11200, loss = 0.234255
I0612 19:36:56.355536  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.234255 (* 1 = 0.234255 loss)
I0612 19:36:56.355547  4990 sgd_solver.cpp:294] Iteration 11200, lr = 0.02
I0612 19:54:10.899040  4990 solver.cpp:342] Iteration 11600, Testing net (#0)
I0612 19:55:16.088338  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.817187
I0612 19:55:16.088378  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.653335 (* 1 = 0.653335 loss)
I0612 19:55:18.634897  4990 solver.cpp:233] Iteration 11600, loss = 0.0929637
I0612 19:55:18.634938  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0929636 (* 1 = 0.0929636 loss)
I0612 19:55:18.634946  4990 sgd_solver.cpp:294] Iteration 11600, lr = 0.02
I0612 20:12:32.054404  4990 solver.cpp:342] Iteration 12000, Testing net (#0)
I0612 20:13:37.298461  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.811797
I0612 20:13:37.298503  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.685988 (* 1 = 0.685988 loss)
I0612 20:13:39.877674  4990 solver.cpp:233] Iteration 12000, loss = 0.264445
I0612 20:13:39.877713  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.264445 (* 1 = 0.264445 loss)
I0612 20:13:39.877720  4990 sgd_solver.cpp:294] Iteration 12000, lr = 0.02
I0612 20:30:53.507930  4990 solver.cpp:342] Iteration 12400, Testing net (#0)
I0612 20:31:58.468014  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.837969
I0612 20:31:58.468056  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.572684 (* 1 = 0.572684 loss)
I0612 20:32:01.016294  4990 solver.cpp:233] Iteration 12400, loss = 0.198588
I0612 20:32:01.016330  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.198588 (* 1 = 0.198588 loss)
I0612 20:32:01.016337  4990 sgd_solver.cpp:294] Iteration 12400, lr = 0.02
I0612 20:49:15.857269  4990 solver.cpp:342] Iteration 12800, Testing net (#0)
I0612 20:50:21.175549  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.797813
I0612 20:50:21.175613  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.789894 (* 1 = 0.789894 loss)
I0612 20:50:23.717627  4990 solver.cpp:233] Iteration 12800, loss = 0.155238
I0612 20:50:23.717661  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.155238 (* 1 = 0.155238 loss)
I0612 20:50:23.717669  4990 sgd_solver.cpp:294] Iteration 12800, lr = 0.02
I0612 21:07:39.342444  4990 solver.cpp:342] Iteration 13200, Testing net (#0)
I0612 21:08:44.490460  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.825859
I0612 21:08:44.490505  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.656488 (* 1 = 0.656488 loss)
I0612 21:08:47.037478  4990 solver.cpp:233] Iteration 13200, loss = 0.161757
I0612 21:08:47.037515  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.161757 (* 1 = 0.161757 loss)
I0612 21:08:47.037524  4990 sgd_solver.cpp:294] Iteration 13200, lr = 0.02
I0612 21:26:02.429029  4990 solver.cpp:342] Iteration 13600, Testing net (#0)
I0612 21:27:07.631525  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.844063
I0612 21:27:07.631573  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.604335 (* 1 = 0.604335 loss)
I0612 21:27:10.166066  4990 solver.cpp:233] Iteration 13600, loss = 0.179814
I0612 21:27:10.166120  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.179814 (* 1 = 0.179814 loss)
I0612 21:27:10.166128  4990 sgd_solver.cpp:294] Iteration 13600, lr = 0.02
I0612 21:44:24.691485  4990 solver.cpp:342] Iteration 14000, Testing net (#0)
I0612 21:45:29.815910  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.815703
I0612 21:45:29.815953  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.725154 (* 1 = 0.725154 loss)
I0612 21:45:32.381083  4990 solver.cpp:233] Iteration 14000, loss = 0.173843
I0612 21:45:32.381140  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.173843 (* 1 = 0.173843 loss)
I0612 21:45:32.381148  4990 sgd_solver.cpp:294] Iteration 14000, lr = 0.02
I0612 22:02:46.146124  4990 solver.cpp:342] Iteration 14400, Testing net (#0)
I0612 22:03:51.521209  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.821875
I0612 22:03:51.521251  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.834598 (* 1 = 0.834598 loss)
I0612 22:03:54.052788  4990 solver.cpp:233] Iteration 14400, loss = 0.178447
I0612 22:03:54.052839  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.178447 (* 1 = 0.178447 loss)
I0612 22:03:54.052850  4990 sgd_solver.cpp:294] Iteration 14400, lr = 0.02
I0612 22:21:09.012387  4990 solver.cpp:342] Iteration 14800, Testing net (#0)
I0612 22:22:14.435220  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.763438
I0612 22:22:14.435268  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.991566 (* 1 = 0.991566 loss)
I0612 22:22:16.965535  4990 solver.cpp:233] Iteration 14800, loss = 0.129132
I0612 22:22:16.965570  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.129132 (* 1 = 0.129132 loss)
I0612 22:22:16.965577  4990 sgd_solver.cpp:294] Iteration 14800, lr = 0.02
I0612 22:39:32.428954  4990 solver.cpp:342] Iteration 15200, Testing net (#0)
I0612 22:40:37.590834  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.852656
I0612 22:40:37.590880  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.544118 (* 1 = 0.544118 loss)
I0612 22:40:40.156864  4990 solver.cpp:233] Iteration 15200, loss = 0.125614
I0612 22:40:40.156898  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.125614 (* 1 = 0.125614 loss)
I0612 22:40:40.156904  4990 sgd_solver.cpp:294] Iteration 15200, lr = 0.02
I0612 22:57:53.874181  4990 solver.cpp:342] Iteration 15600, Testing net (#0)
I0612 22:58:58.914615  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.823281
I0612 22:58:58.914657  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.72001 (* 1 = 0.72001 loss)
I0612 22:59:01.456090  4990 solver.cpp:233] Iteration 15600, loss = 0.0993201
I0612 22:59:01.456131  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0993202 (* 1 = 0.0993202 loss)
I0612 22:59:01.456140  4990 sgd_solver.cpp:294] Iteration 15600, lr = 0.02
I0612 23:16:16.124516  4990 solver.cpp:342] Iteration 16000, Testing net (#0)
I0612 23:17:21.303444  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.831797
I0612 23:17:21.303489  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.645767 (* 1 = 0.645767 loss)
I0612 23:17:23.847446  4990 solver.cpp:233] Iteration 16000, loss = 0.112892
I0612 23:17:23.847482  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.112892 (* 1 = 0.112892 loss)
I0612 23:17:23.847491  4990 sgd_solver.cpp:294] Iteration 16000, lr = 0.02
I0612 23:34:37.820469  4990 solver.cpp:342] Iteration 16400, Testing net (#0)
I0612 23:35:43.012142  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.809219
I0612 23:35:43.012183  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.770834 (* 1 = 0.770834 loss)
I0612 23:35:45.561172  4990 solver.cpp:233] Iteration 16400, loss = 0.0980901
I0612 23:35:45.561213  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0980903 (* 1 = 0.0980903 loss)
I0612 23:35:45.561223  4990 sgd_solver.cpp:294] Iteration 16400, lr = 0.02
I0612 23:52:59.214962  4990 solver.cpp:342] Iteration 16800, Testing net (#0)
I0612 23:54:04.485376  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.782344
I0612 23:54:04.485430  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.02625 (* 1 = 1.02625 loss)
I0612 23:54:07.026779  4990 solver.cpp:233] Iteration 16800, loss = 0.0996163
I0612 23:54:07.026823  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0996164 (* 1 = 0.0996164 loss)
I0612 23:54:07.026831  4990 sgd_solver.cpp:294] Iteration 16800, lr = 0.02
I0613 00:13:50.540957  4990 solver.cpp:342] Iteration 17200, Testing net (#0)
I0613 00:14:55.316045  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.841016
I0613 00:14:55.316089  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.606831 (* 1 = 0.606831 loss)
I0613 00:14:57.840999  4990 solver.cpp:233] Iteration 17200, loss = 0.0937241
I0613 00:14:57.841038  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0937242 (* 1 = 0.0937242 loss)
I0613 00:14:57.841045  4990 sgd_solver.cpp:294] Iteration 17200, lr = 0.02
I0613 00:32:06.930443  4990 solver.cpp:342] Iteration 17600, Testing net (#0)
I0613 00:33:12.422590  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.84625
I0613 00:33:12.422637  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.656589 (* 1 = 0.656589 loss)
I0613 00:33:14.971549  4990 solver.cpp:233] Iteration 17600, loss = 0.0958696
I0613 00:33:14.971616  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0958696 (* 1 = 0.0958696 loss)
I0613 00:33:14.971628  4990 sgd_solver.cpp:294] Iteration 17600, lr = 0.02
I0613 00:50:28.839079  4990 solver.cpp:342] Iteration 18000, Testing net (#0)
I0613 00:51:34.181154  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.8025
I0613 00:51:34.181193  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.816216 (* 1 = 0.816216 loss)
I0613 00:51:36.724741  4990 solver.cpp:233] Iteration 18000, loss = 0.0939274
I0613 00:51:36.724797  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0939275 (* 1 = 0.0939275 loss)
I0613 00:51:36.724808  4990 sgd_solver.cpp:294] Iteration 18000, lr = 0.02
I0613 01:08:50.873203  4990 solver.cpp:342] Iteration 18400, Testing net (#0)
I0613 01:09:56.376426  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.79125
I0613 01:09:56.376476  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.97089 (* 1 = 0.97089 loss)
I0613 01:09:58.912667  4990 solver.cpp:233] Iteration 18400, loss = 0.0803177
I0613 01:09:58.912703  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0803178 (* 1 = 0.0803178 loss)
I0613 01:09:58.912709  4990 sgd_solver.cpp:294] Iteration 18400, lr = 0.02
I0613 01:27:12.387140  4990 solver.cpp:342] Iteration 18800, Testing net (#0)
I0613 01:28:17.485625  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.840937
I0613 01:28:17.485667  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.7062 (* 1 = 0.7062 loss)
I0613 01:28:20.062347  4990 solver.cpp:233] Iteration 18800, loss = 0.0819319
I0613 01:28:20.062399  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0819319 (* 1 = 0.0819319 loss)
I0613 01:28:20.062408  4990 sgd_solver.cpp:294] Iteration 18800, lr = 0.02
I0613 01:45:34.817519  4990 solver.cpp:342] Iteration 19200, Testing net (#0)
I0613 01:46:40.162066  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.832031
I0613 01:46:40.162109  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.688995 (* 1 = 0.688995 loss)
I0613 01:46:42.697300  4990 solver.cpp:233] Iteration 19200, loss = 0.0586124
I0613 01:46:42.697345  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0586124 (* 1 = 0.0586124 loss)
I0613 01:46:42.697352  4990 sgd_solver.cpp:294] Iteration 19200, lr = 0.02
I0613 02:03:57.271708  4990 solver.cpp:342] Iteration 19600, Testing net (#0)
I0613 02:05:02.301213  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.846719
I0613 02:05:02.301256  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.547581 (* 1 = 0.547581 loss)
I0613 02:05:04.894608  4990 solver.cpp:233] Iteration 19600, loss = 0.0661543
I0613 02:05:04.894649  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0661544 (* 1 = 0.0661544 loss)
I0613 02:05:04.894657  4990 sgd_solver.cpp:294] Iteration 19600, lr = 0.02
I0613 02:22:20.224998  4990 solver.cpp:342] Iteration 20000, Testing net (#0)
I0613 02:23:25.199348  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.852188
I0613 02:23:25.199405  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.582359 (* 1 = 0.582359 loss)
I0613 02:23:27.735534  4990 solver.cpp:233] Iteration 20000, loss = 0.130723
I0613 02:23:27.735565  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.130723 (* 1 = 0.130723 loss)
I0613 02:23:27.735571  4990 sgd_solver.cpp:294] Iteration 20000, lr = 0.02
I0613 02:40:42.775111  4990 solver.cpp:342] Iteration 20400, Testing net (#0)
I0613 02:41:47.826670  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.768828
I0613 02:41:47.826714  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.3182 (* 1 = 1.3182 loss)
I0613 02:41:50.367380  4990 solver.cpp:233] Iteration 20400, loss = 0.0809347
I0613 02:41:50.367419  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0809347 (* 1 = 0.0809347 loss)
I0613 02:41:50.367430  4990 sgd_solver.cpp:294] Iteration 20400, lr = 0.02
I0613 02:59:04.519173  4990 solver.cpp:342] Iteration 20800, Testing net (#0)
I0613 03:00:09.787044  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.839688
I0613 03:00:09.787086  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.649685 (* 1 = 0.649685 loss)
I0613 03:00:12.311986  4990 solver.cpp:233] Iteration 20800, loss = 0.0822567
I0613 03:00:12.312034  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0822568 (* 1 = 0.0822568 loss)
I0613 03:00:12.312044  4990 sgd_solver.cpp:294] Iteration 20800, lr = 0.02
I0613 03:17:26.358731  4990 solver.cpp:342] Iteration 21200, Testing net (#0)
I0613 03:18:31.625149  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.746953
I0613 03:18:31.625200  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.22207 (* 1 = 1.22207 loss)
I0613 03:18:34.175621  4990 solver.cpp:233] Iteration 21200, loss = 0.119728
I0613 03:18:34.175664  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.119728 (* 1 = 0.119728 loss)
I0613 03:18:34.175673  4990 sgd_solver.cpp:294] Iteration 21200, lr = 0.02
I0613 03:35:49.067309  4990 solver.cpp:342] Iteration 21600, Testing net (#0)
I0613 03:36:54.766314  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.812656
I0613 03:36:54.766371  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.794016 (* 1 = 0.794016 loss)
I0613 03:36:57.355490  4990 solver.cpp:233] Iteration 21600, loss = 0.0511793
I0613 03:36:57.355541  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0511793 (* 1 = 0.0511793 loss)
I0613 03:36:57.355551  4990 sgd_solver.cpp:294] Iteration 21600, lr = 0.02
I0613 03:54:11.488308  4990 solver.cpp:342] Iteration 22000, Testing net (#0)
I0613 03:55:16.680362  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.828516
I0613 03:55:16.680405  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.719246 (* 1 = 0.719246 loss)
I0613 03:55:19.226873  4990 solver.cpp:233] Iteration 22000, loss = 0.156045
I0613 03:55:19.226917  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.156045 (* 1 = 0.156045 loss)
I0613 03:55:19.226925  4990 sgd_solver.cpp:294] Iteration 22000, lr = 0.02
I0613 04:12:33.687870  4990 solver.cpp:342] Iteration 22400, Testing net (#0)
I0613 04:13:38.714798  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.836563
I0613 04:13:38.714843  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.653533 (* 1 = 0.653533 loss)
I0613 04:13:41.249227  4990 solver.cpp:233] Iteration 22400, loss = 0.0770963
I0613 04:13:41.249264  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0770963 (* 1 = 0.0770963 loss)
I0613 04:13:41.249271  4990 sgd_solver.cpp:294] Iteration 22400, lr = 0.02
I0613 04:30:57.614814  4990 solver.cpp:342] Iteration 22800, Testing net (#0)
I0613 04:32:02.792501  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.863359
I0613 04:32:02.792553  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.555954 (* 1 = 0.555954 loss)
I0613 04:32:05.353140  4990 solver.cpp:233] Iteration 22800, loss = 0.075169
I0613 04:32:05.353179  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.075169 (* 1 = 0.075169 loss)
I0613 04:32:05.353186  4990 sgd_solver.cpp:294] Iteration 22800, lr = 0.02
I0613 04:49:20.044689  4990 solver.cpp:342] Iteration 23200, Testing net (#0)
I0613 04:50:25.366801  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.824609
I0613 04:50:25.366852  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.709616 (* 1 = 0.709616 loss)
I0613 04:50:27.902732  4990 solver.cpp:233] Iteration 23200, loss = 0.0488192
I0613 04:50:27.902770  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0488192 (* 1 = 0.0488192 loss)
I0613 04:50:27.902778  4990 sgd_solver.cpp:294] Iteration 23200, lr = 0.02
I0613 05:07:42.967077  4990 solver.cpp:342] Iteration 23600, Testing net (#0)
I0613 05:08:48.576539  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.73875
I0613 05:08:48.576586  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.27654 (* 1 = 1.27654 loss)
I0613 05:08:51.113697  4990 solver.cpp:233] Iteration 23600, loss = 0.0599642
I0613 05:08:51.113747  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0599642 (* 1 = 0.0599642 loss)
I0613 05:08:51.113759  4990 sgd_solver.cpp:294] Iteration 23600, lr = 0.02
I0613 05:26:06.044387  4990 solver.cpp:342] Iteration 24000, Testing net (#0)
I0613 05:27:11.385462  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.823516
I0613 05:27:11.385501  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.724169 (* 1 = 0.724169 loss)
I0613 05:27:13.937953  4990 solver.cpp:233] Iteration 24000, loss = 0.0660887
I0613 05:27:13.938000  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0660888 (* 1 = 0.0660888 loss)
I0613 05:27:13.938007  4990 sgd_solver.cpp:294] Iteration 24000, lr = 0.02
I0613 05:44:27.042898  4990 solver.cpp:342] Iteration 24400, Testing net (#0)
I0613 05:45:32.274773  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.825234
I0613 05:45:32.274816  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.782163 (* 1 = 0.782163 loss)
I0613 05:45:34.804355  4990 solver.cpp:233] Iteration 24400, loss = 0.0284111
I0613 05:45:34.804392  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0284112 (* 1 = 0.0284112 loss)
I0613 05:45:34.804400  4990 sgd_solver.cpp:294] Iteration 24400, lr = 0.02
I0613 06:02:49.828606  4990 solver.cpp:342] Iteration 24800, Testing net (#0)
I0613 06:03:55.382412  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.822031
I0613 06:03:55.382458  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.880854 (* 1 = 0.880854 loss)
I0613 06:03:57.910492  4990 solver.cpp:233] Iteration 24800, loss = 0.08505
I0613 06:03:57.910526  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.08505 (* 1 = 0.08505 loss)
I0613 06:03:57.910534  4990 sgd_solver.cpp:294] Iteration 24800, lr = 0.02
I0613 06:21:12.188657  4990 solver.cpp:342] Iteration 25200, Testing net (#0)
I0613 06:22:17.731874  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.842891
I0613 06:22:17.731923  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.651571 (* 1 = 0.651571 loss)
I0613 06:22:20.268082  4990 solver.cpp:233] Iteration 25200, loss = 0.056248
I0613 06:22:20.268115  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0562481 (* 1 = 0.0562481 loss)
I0613 06:22:20.268122  4990 sgd_solver.cpp:294] Iteration 25200, lr = 0.02
I0613 06:39:33.937505  4990 solver.cpp:342] Iteration 25600, Testing net (#0)
I0613 06:40:39.609547  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.845547
I0613 06:40:39.609593  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.645342 (* 1 = 0.645342 loss)
I0613 06:40:42.140616  4990 solver.cpp:233] Iteration 25600, loss = 0.0659391
I0613 06:40:42.140642  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0659391 (* 1 = 0.0659391 loss)
I0613 06:40:42.140650  4990 sgd_solver.cpp:294] Iteration 25600, lr = 0.02
I0613 06:57:56.294275  4990 solver.cpp:342] Iteration 26000, Testing net (#0)
I0613 06:59:01.321171  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.848594
I0613 06:59:01.321216  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.596921 (* 1 = 0.596921 loss)
I0613 06:59:03.862610  4990 solver.cpp:233] Iteration 26000, loss = 0.0395161
I0613 06:59:03.862655  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0395161 (* 1 = 0.0395161 loss)
I0613 06:59:03.862666  4990 sgd_solver.cpp:294] Iteration 26000, lr = 0.02
I0613 07:16:19.475165  4990 solver.cpp:342] Iteration 26400, Testing net (#0)
I0613 07:17:24.882573  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.825938
I0613 07:17:24.882618  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.682938 (* 1 = 0.682938 loss)
I0613 07:17:27.405117  4990 solver.cpp:233] Iteration 26400, loss = 0.100015
I0613 07:17:27.405151  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.100015 (* 1 = 0.100015 loss)
I0613 07:17:27.405169  4990 sgd_solver.cpp:294] Iteration 26400, lr = 0.02
I0613 07:34:41.001809  4990 solver.cpp:342] Iteration 26800, Testing net (#0)
I0613 07:35:46.287717  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.851797
I0613 07:35:46.287761  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.654967 (* 1 = 0.654967 loss)
I0613 07:35:48.815950  4990 solver.cpp:233] Iteration 26800, loss = 0.058064
I0613 07:35:48.816004  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.058064 (* 1 = 0.058064 loss)
I0613 07:35:48.816015  4990 sgd_solver.cpp:294] Iteration 26800, lr = 0.02
I0613 07:53:04.835182  4990 solver.cpp:342] Iteration 27200, Testing net (#0)
I0613 07:54:09.926439  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.850937
I0613 07:54:09.926481  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.634954 (* 1 = 0.634954 loss)
I0613 07:54:12.464277  4990 solver.cpp:233] Iteration 27200, loss = 0.081716
I0613 07:54:12.464313  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0817161 (* 1 = 0.0817161 loss)
I0613 07:54:12.464321  4990 sgd_solver.cpp:294] Iteration 27200, lr = 0.02
I0613 08:11:26.440948  4990 solver.cpp:342] Iteration 27600, Testing net (#0)
I0613 08:12:31.599705  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.828828
I0613 08:12:31.599742  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.825141 (* 1 = 0.825141 loss)
I0613 08:12:34.130333  4990 solver.cpp:233] Iteration 27600, loss = 0.0803585
I0613 08:12:34.130390  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0803586 (* 1 = 0.0803586 loss)
I0613 08:12:34.130400  4990 sgd_solver.cpp:294] Iteration 27600, lr = 0.02
I0613 08:29:48.623774  4990 solver.cpp:342] Iteration 28000, Testing net (#0)
I0613 08:30:53.753275  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.825938
I0613 08:30:53.753327  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.863268 (* 1 = 0.863268 loss)
I0613 08:30:56.312523  4990 solver.cpp:233] Iteration 28000, loss = 0.0670213
I0613 08:30:56.312573  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0670214 (* 1 = 0.0670214 loss)
I0613 08:30:56.312584  4990 sgd_solver.cpp:294] Iteration 28000, lr = 0.02
I0613 08:48:12.085671  4990 solver.cpp:342] Iteration 28400, Testing net (#0)
I0613 08:49:17.085801  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.784063
I0613 08:49:17.085850  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.16806 (* 1 = 1.16806 loss)
I0613 08:49:19.660418  4990 solver.cpp:233] Iteration 28400, loss = 0.0489366
I0613 08:49:19.660454  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0489367 (* 1 = 0.0489367 loss)
I0613 08:49:19.660460  4990 sgd_solver.cpp:294] Iteration 28400, lr = 0.02
I0613 09:06:34.427780  4990 solver.cpp:342] Iteration 28800, Testing net (#0)
I0613 09:07:39.722503  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.834453
I0613 09:07:39.722550  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.806578 (* 1 = 0.806578 loss)
I0613 09:07:42.290243  4990 solver.cpp:233] Iteration 28800, loss = 0.0817863
I0613 09:07:42.290287  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0817864 (* 1 = 0.0817864 loss)
I0613 09:07:42.290295  4990 sgd_solver.cpp:294] Iteration 28800, lr = 0.02
I0613 09:24:57.349925  4990 solver.cpp:342] Iteration 29200, Testing net (#0)
I0613 09:26:02.285200  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.843828
I0613 09:26:02.285255  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.72663 (* 1 = 0.72663 loss)
I0613 09:26:04.858227  4990 solver.cpp:233] Iteration 29200, loss = 0.0812442
I0613 09:26:04.858268  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0812443 (* 1 = 0.0812443 loss)
I0613 09:26:04.858283  4990 sgd_solver.cpp:294] Iteration 29200, lr = 0.02
I0613 09:43:19.720782  4990 solver.cpp:342] Iteration 29600, Testing net (#0)
I0613 09:44:24.759018  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.839141
I0613 09:44:24.759062  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.733118 (* 1 = 0.733118 loss)
I0613 09:44:27.327124  4990 solver.cpp:233] Iteration 29600, loss = 0.0734558
I0613 09:44:27.327159  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0734559 (* 1 = 0.0734559 loss)
I0613 09:44:27.327167  4990 sgd_solver.cpp:294] Iteration 29600, lr = 0.02
I0613 10:01:42.476876  4990 solver.cpp:342] Iteration 30000, Testing net (#0)
I0613 10:02:47.777688  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.857344
I0613 10:02:47.777726  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.638623 (* 1 = 0.638623 loss)
I0613 10:02:50.371855  4990 solver.cpp:233] Iteration 30000, loss = 0.0669908
I0613 10:02:50.371898  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0669909 (* 1 = 0.0669909 loss)
I0613 10:02:50.371906  4990 sgd_solver.cpp:294] Iteration 30000, lr = 0.02
I0613 10:20:04.562600  4990 solver.cpp:342] Iteration 30400, Testing net (#0)
I0613 10:21:09.880046  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.779922
I0613 10:21:09.880091  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.23727 (* 1 = 1.23727 loss)
I0613 10:21:12.404006  4990 solver.cpp:233] Iteration 30400, loss = 0.0889846
I0613 10:21:12.404038  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0889846 (* 1 = 0.0889846 loss)
I0613 10:21:12.404045  4990 sgd_solver.cpp:294] Iteration 30400, lr = 0.02
I0613 10:38:23.845854  4990 solver.cpp:342] Iteration 30800, Testing net (#0)
I0613 10:39:28.603189  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.840547
I0613 10:39:28.603232  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.687371 (* 1 = 0.687371 loss)
I0613 10:39:31.136813  4990 solver.cpp:233] Iteration 30800, loss = 0.0378168
I0613 10:39:31.136862  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0378168 (* 1 = 0.0378168 loss)
I0613 10:39:31.136871  4990 sgd_solver.cpp:294] Iteration 30800, lr = 0.02
I0613 10:56:36.883257  4990 solver.cpp:342] Iteration 31200, Testing net (#0)
I0613 10:57:41.634567  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.859297
I0613 10:57:41.634615  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.604071 (* 1 = 0.604071 loss)
I0613 10:57:44.168928  4990 solver.cpp:233] Iteration 31200, loss = 0.0363192
I0613 10:57:44.168982  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0363192 (* 1 = 0.0363192 loss)
I0613 10:57:44.168994  4990 sgd_solver.cpp:294] Iteration 31200, lr = 0.02
I0613 11:14:50.193161  4990 solver.cpp:342] Iteration 31600, Testing net (#0)
I0613 11:15:54.974047  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.865859
I0613 11:15:54.974093  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.563014 (* 1 = 0.563014 loss)
I0613 11:15:57.509050  4990 solver.cpp:233] Iteration 31600, loss = 0.0723775
I0613 11:15:57.509095  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0723775 (* 1 = 0.0723775 loss)
I0613 11:15:57.509104  4990 sgd_solver.cpp:294] Iteration 31600, lr = 0.02
I0613 11:33:03.644508  4990 solver.cpp:342] Iteration 32000, Testing net (#0)
I0613 11:34:08.426662  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.82375
I0613 11:34:08.426707  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.835635 (* 1 = 0.835635 loss)
I0613 11:34:10.952133  4990 solver.cpp:233] Iteration 32000, loss = 0.0564255
I0613 11:34:10.952169  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0564255 (* 1 = 0.0564255 loss)
I0613 11:34:10.952177  4990 sgd_solver.cpp:294] Iteration 32000, lr = 0.02
I0613 11:51:17.148551  4990 solver.cpp:342] Iteration 32400, Testing net (#0)
I0613 11:52:21.926827  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.852656
I0613 11:52:21.926872  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.650847 (* 1 = 0.650847 loss)
I0613 11:52:24.454330  4990 solver.cpp:233] Iteration 32400, loss = 0.011497
I0613 11:52:24.454367  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.011497 (* 1 = 0.011497 loss)
I0613 11:52:24.454375  4990 sgd_solver.cpp:294] Iteration 32400, lr = 0.02
I0613 12:09:30.429510  4990 solver.cpp:342] Iteration 32800, Testing net (#0)
I0613 12:10:35.152310  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.817109
I0613 12:10:35.152353  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.848897 (* 1 = 0.848897 loss)
I0613 12:10:37.682211  4990 solver.cpp:233] Iteration 32800, loss = 0.011259
I0613 12:10:37.682258  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.011259 (* 1 = 0.011259 loss)
I0613 12:10:37.682267  4990 sgd_solver.cpp:294] Iteration 32800, lr = 0.02
I0613 12:27:43.449535  4990 solver.cpp:342] Iteration 33200, Testing net (#0)
I0613 12:28:48.205270  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.819219
I0613 12:28:48.205314  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.865095 (* 1 = 0.865095 loss)
I0613 12:28:50.731263  4990 solver.cpp:233] Iteration 33200, loss = 0.0637934
I0613 12:28:50.731302  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0637934 (* 1 = 0.0637934 loss)
I0613 12:28:50.731309  4990 sgd_solver.cpp:294] Iteration 33200, lr = 0.02
I0613 12:45:56.827448  4990 solver.cpp:342] Iteration 33600, Testing net (#0)
I0613 12:47:01.641962  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.836484
I0613 12:47:01.642006  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.818583 (* 1 = 0.818583 loss)
I0613 12:47:04.171495  4990 solver.cpp:233] Iteration 33600, loss = 0.0754053
I0613 12:47:04.171567  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0754053 (* 1 = 0.0754053 loss)
I0613 12:47:04.171576  4990 sgd_solver.cpp:294] Iteration 33600, lr = 0.02
I0613 13:04:10.476460  4990 solver.cpp:342] Iteration 34000, Testing net (#0)
I0613 13:05:15.208284  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.808672
I0613 13:05:15.208323  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.994645 (* 1 = 0.994645 loss)
I0613 13:05:17.738989  4990 solver.cpp:233] Iteration 34000, loss = 0.0545453
I0613 13:05:17.739030  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0545453 (* 1 = 0.0545453 loss)
I0613 13:05:17.739038  4990 sgd_solver.cpp:294] Iteration 34000, lr = 0.02
I0613 13:22:24.262581  4990 solver.cpp:342] Iteration 34400, Testing net (#0)
I0613 13:23:29.119074  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.850391
I0613 13:23:29.119127  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.756319 (* 1 = 0.756319 loss)
I0613 13:23:31.648895  4990 solver.cpp:233] Iteration 34400, loss = 0.0601124
I0613 13:23:31.648954  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0601124 (* 1 = 0.0601124 loss)
I0613 13:23:31.648968  4990 sgd_solver.cpp:294] Iteration 34400, lr = 0.02
I0613 13:40:39.461940  4990 solver.cpp:342] Iteration 34800, Testing net (#0)
I0613 13:41:44.254086  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.797656
I0613 13:41:44.254134  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.0502 (* 1 = 1.0502 loss)
I0613 13:41:46.787952  4990 solver.cpp:233] Iteration 34800, loss = 0.0676825
I0613 13:41:46.788002  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0676825 (* 1 = 0.0676825 loss)
I0613 13:41:46.788012  4990 sgd_solver.cpp:294] Iteration 34800, lr = 0.02
I0613 13:58:54.729193  4990 solver.cpp:342] Iteration 35200, Testing net (#0)
I0613 13:59:59.528383  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.855391
I0613 13:59:59.528424  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.612148 (* 1 = 0.612148 loss)
I0613 14:00:02.057777  4990 solver.cpp:233] Iteration 35200, loss = 0.0314442
I0613 14:00:02.057823  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0314443 (* 1 = 0.0314443 loss)
I0613 14:00:02.057832  4990 sgd_solver.cpp:294] Iteration 35200, lr = 0.02
I0613 14:17:10.143260  4990 solver.cpp:342] Iteration 35600, Testing net (#0)
I0613 14:18:14.923135  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.85625
I0613 14:18:14.923180  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.626058 (* 1 = 0.626058 loss)
I0613 14:18:17.455497  4990 solver.cpp:233] Iteration 35600, loss = 0.080504
I0613 14:18:17.455544  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.080504 (* 1 = 0.080504 loss)
I0613 14:18:17.455554  4990 sgd_solver.cpp:294] Iteration 35600, lr = 0.02
I0613 14:35:25.770804  4990 solver.cpp:342] Iteration 36000, Testing net (#0)
I0613 14:36:30.554148  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.853281
I0613 14:36:30.554193  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.684945 (* 1 = 0.684945 loss)
I0613 14:36:33.086575  4990 solver.cpp:233] Iteration 36000, loss = 0.0277909
I0613 14:36:33.086618  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0277909 (* 1 = 0.0277909 loss)
I0613 14:36:33.086626  4990 sgd_solver.cpp:294] Iteration 36000, lr = 0.02
I0613 14:53:41.249027  4990 solver.cpp:342] Iteration 36400, Testing net (#0)
I0613 14:54:46.063135  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.818984
I0613 14:54:46.063192  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.811507 (* 1 = 0.811507 loss)
I0613 14:54:48.594202  4990 solver.cpp:233] Iteration 36400, loss = 0.0587229
I0613 14:54:48.594259  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0587229 (* 1 = 0.0587229 loss)
I0613 14:54:48.594269  4990 sgd_solver.cpp:294] Iteration 36400, lr = 0.02
I0613 15:11:56.714500  4990 solver.cpp:342] Iteration 36800, Testing net (#0)
I0613 15:13:01.498363  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.841875
I0613 15:13:01.498409  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.764097 (* 1 = 0.764097 loss)
I0613 15:13:04.032213  4990 solver.cpp:233] Iteration 36800, loss = 0.0710676
I0613 15:13:04.032263  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0710676 (* 1 = 0.0710676 loss)
I0613 15:13:04.032271  4990 sgd_solver.cpp:294] Iteration 36800, lr = 0.02
I0613 15:30:11.985492  4990 solver.cpp:342] Iteration 37200, Testing net (#0)
I0613 15:31:16.801791  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.830312
I0613 15:31:16.801836  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.860614 (* 1 = 0.860614 loss)
I0613 15:31:19.337743  4990 solver.cpp:233] Iteration 37200, loss = 0.0548663
I0613 15:31:19.337790  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0548663 (* 1 = 0.0548663 loss)
I0613 15:31:19.337800  4990 sgd_solver.cpp:294] Iteration 37200, lr = 0.02
I0613 15:48:30.491739  4990 solver.cpp:342] Iteration 37600, Testing net (#0)
I0613 15:49:35.472877  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.863047
I0613 15:49:35.472931  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.599471 (* 1 = 0.599471 loss)
I0613 15:49:38.030266  4990 solver.cpp:233] Iteration 37600, loss = 0.0306134
I0613 15:49:38.030309  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0306134 (* 1 = 0.0306134 loss)
I0613 15:49:38.030318  4990 sgd_solver.cpp:294] Iteration 37600, lr = 0.02
I0613 16:06:53.063680  4990 solver.cpp:342] Iteration 38000, Testing net (#0)
I0613 16:07:58.410017  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.845781
I0613 16:07:58.410063  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.765369 (* 1 = 0.765369 loss)
I0613 16:08:00.945987  4990 solver.cpp:233] Iteration 38000, loss = 0.0908397
I0613 16:08:00.946033  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0908397 (* 1 = 0.0908397 loss)
I0613 16:08:00.946048  4990 sgd_solver.cpp:294] Iteration 38000, lr = 0.02
I0613 16:25:14.519212  4990 solver.cpp:342] Iteration 38400, Testing net (#0)
I0613 16:26:19.641582  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.864766
I0613 16:26:19.641625  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.653411 (* 1 = 0.653411 loss)
I0613 16:26:22.190806  4990 solver.cpp:233] Iteration 38400, loss = 0.0486558
I0613 16:26:22.190840  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0486559 (* 1 = 0.0486559 loss)
I0613 16:26:22.190848  4990 sgd_solver.cpp:294] Iteration 38400, lr = 0.02
I0613 16:43:36.667424  4990 solver.cpp:342] Iteration 38800, Testing net (#0)
I0613 16:44:42.052537  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.843359
I0613 16:44:42.052600  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.705654 (* 1 = 0.705654 loss)
I0613 16:44:44.581981  4990 solver.cpp:233] Iteration 38800, loss = 0.0132954
I0613 16:44:44.582032  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0132954 (* 1 = 0.0132954 loss)
I0613 16:44:44.582039  4990 sgd_solver.cpp:294] Iteration 38800, lr = 0.02
I0613 17:01:59.716653  4990 solver.cpp:342] Iteration 39200, Testing net (#0)
I0613 17:03:05.235656  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.844375
I0613 17:03:05.235697  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.718502 (* 1 = 0.718502 loss)
I0613 17:03:07.820809  4990 solver.cpp:233] Iteration 39200, loss = 0.0528997
I0613 17:03:07.820849  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0528997 (* 1 = 0.0528997 loss)
I0613 17:03:07.820858  4990 sgd_solver.cpp:294] Iteration 39200, lr = 0.02
I0613 17:20:22.393200  4990 solver.cpp:342] Iteration 39600, Testing net (#0)
I0613 17:21:27.361704  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.845781
I0613 17:21:27.361747  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.71305 (* 1 = 0.71305 loss)
I0613 17:21:29.957126  4990 solver.cpp:233] Iteration 39600, loss = 0.0420833
I0613 17:21:29.957166  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0420834 (* 1 = 0.0420834 loss)
I0613 17:21:29.957175  4990 sgd_solver.cpp:294] Iteration 39600, lr = 0.02
I0613 17:38:40.509925  4990 solver.cpp:342] Iteration 40000, Testing net (#0)
I0613 17:39:45.308697  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.824453
I0613 17:39:45.308743  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.908414 (* 1 = 0.908414 loss)
I0613 17:39:47.842008  4990 solver.cpp:233] Iteration 40000, loss = 0.115266
I0613 17:39:47.842056  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.115266 (* 1 = 0.115266 loss)
I0613 17:39:47.842066  4990 sgd_solver.cpp:294] Iteration 40000, lr = 0.02
I0613 17:57:01.139958  4990 solver.cpp:342] Iteration 40400, Testing net (#0)
I0613 17:58:06.214310  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.857266
I0613 17:58:06.214364  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.668978 (* 1 = 0.668978 loss)
I0613 17:58:08.743825  4990 solver.cpp:233] Iteration 40400, loss = 0.0498349
I0613 17:58:08.743862  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0498349 (* 1 = 0.0498349 loss)
I0613 17:58:08.743870  4990 sgd_solver.cpp:294] Iteration 40400, lr = 0.02
I0613 18:15:16.461531  4990 solver.cpp:342] Iteration 40800, Testing net (#0)
I0613 18:16:21.230733  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.858516
I0613 18:16:21.230775  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.645103 (* 1 = 0.645103 loss)
I0613 18:16:23.758020  4990 solver.cpp:233] Iteration 40800, loss = 0.164523
I0613 18:16:23.758064  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.164523 (* 1 = 0.164523 loss)
I0613 18:16:23.758071  4990 sgd_solver.cpp:294] Iteration 40800, lr = 0.02
I0613 18:33:34.091739  4990 solver.cpp:342] Iteration 41200, Testing net (#0)
I0613 18:34:39.084808  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.849844
I0613 18:34:39.084851  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.69373 (* 1 = 0.69373 loss)
I0613 18:34:41.613373  4990 solver.cpp:233] Iteration 41200, loss = 0.0315883
I0613 18:34:41.613420  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0315882 (* 1 = 0.0315882 loss)
I0613 18:34:41.613426  4990 sgd_solver.cpp:294] Iteration 41200, lr = 0.02
I0613 18:51:55.434288  4990 solver.cpp:342] Iteration 41600, Testing net (#0)
I0613 18:53:00.742314  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.859844
I0613 18:53:00.742367  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.629291 (* 1 = 0.629291 loss)
I0613 18:53:03.267849  4990 solver.cpp:233] Iteration 41600, loss = 0.0262111
I0613 18:53:03.267886  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0262111 (* 1 = 0.0262111 loss)
I0613 18:53:03.267894  4990 sgd_solver.cpp:294] Iteration 41600, lr = 0.02
I0613 19:10:17.627190  4990 solver.cpp:342] Iteration 42000, Testing net (#0)
I0613 19:11:22.691208  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.865547
I0613 19:11:22.691267  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.578247 (* 1 = 0.578247 loss)
I0613 19:11:25.267455  4990 solver.cpp:233] Iteration 42000, loss = 0.0574118
I0613 19:11:25.267499  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0574117 (* 1 = 0.0574117 loss)
I0613 19:11:25.267508  4990 sgd_solver.cpp:294] Iteration 42000, lr = 0.02
I0613 19:28:30.950050  4990 solver.cpp:342] Iteration 42400, Testing net (#0)
I0613 19:29:35.681037  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.85375
I0613 19:29:35.681083  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.656142 (* 1 = 0.656142 loss)
I0613 19:29:38.217782  4990 solver.cpp:233] Iteration 42400, loss = 0.100695
I0613 19:29:38.217821  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.100694 (* 1 = 0.100694 loss)
I0613 19:29:38.217830  4990 sgd_solver.cpp:294] Iteration 42400, lr = 0.02
I0613 19:46:43.765838  4990 solver.cpp:342] Iteration 42800, Testing net (#0)
I0613 19:47:48.479913  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.856562
I0613 19:47:48.479966  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.591443 (* 1 = 0.591443 loss)
I0613 19:47:51.018949  4990 solver.cpp:233] Iteration 42800, loss = 0.0793684
I0613 19:47:51.019021  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0793684 (* 1 = 0.0793684 loss)
I0613 19:47:51.019038  4990 sgd_solver.cpp:294] Iteration 42800, lr = 0.02
I0613 20:04:56.501410  4990 solver.cpp:342] Iteration 43200, Testing net (#0)
I0613 20:06:01.291445  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.864766
I0613 20:06:01.291491  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.583531 (* 1 = 0.583531 loss)
I0613 20:06:03.816494  4990 solver.cpp:233] Iteration 43200, loss = 0.0259941
I0613 20:06:03.816534  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0259941 (* 1 = 0.0259941 loss)
I0613 20:06:03.816540  4990 sgd_solver.cpp:294] Iteration 43200, lr = 0.02
I0613 20:23:09.461194  4990 solver.cpp:342] Iteration 43600, Testing net (#0)
I0613 20:24:14.218222  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.871875
I0613 20:24:14.218267  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.562437 (* 1 = 0.562437 loss)
I0613 20:24:16.752887  4990 solver.cpp:233] Iteration 43600, loss = 0.0598909
I0613 20:24:16.752933  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0598908 (* 1 = 0.0598908 loss)
I0613 20:24:16.752941  4990 sgd_solver.cpp:294] Iteration 43600, lr = 0.02
I0613 20:41:22.642838  4990 solver.cpp:342] Iteration 44000, Testing net (#0)
I0613 20:42:27.458678  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.833359
I0613 20:42:27.458717  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.728809 (* 1 = 0.728809 loss)
I0613 20:42:29.986605  4990 solver.cpp:233] Iteration 44000, loss = 0.0487163
I0613 20:42:29.986644  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0487163 (* 1 = 0.0487163 loss)
I0613 20:42:29.986652  4990 sgd_solver.cpp:294] Iteration 44000, lr = 0.02
I0613 20:59:35.778790  4990 solver.cpp:342] Iteration 44400, Testing net (#0)
I0613 21:00:40.570569  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.872891
I0613 21:00:40.570611  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.540238 (* 1 = 0.540238 loss)
I0613 21:00:43.092584  4990 solver.cpp:233] Iteration 44400, loss = 0.0877874
I0613 21:00:43.092624  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0877873 (* 1 = 0.0877873 loss)
I0613 21:00:43.092643  4990 sgd_solver.cpp:294] Iteration 44400, lr = 0.02
I0613 21:17:48.891615  4990 solver.cpp:342] Iteration 44800, Testing net (#0)
I0613 21:18:53.662226  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.862891
I0613 21:18:53.662271  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.608717 (* 1 = 0.608717 loss)
I0613 21:18:56.188812  4990 solver.cpp:233] Iteration 44800, loss = 0.0157263
I0613 21:18:56.188843  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0157262 (* 1 = 0.0157262 loss)
I0613 21:18:56.188849  4990 sgd_solver.cpp:294] Iteration 44800, lr = 0.02
I0613 21:36:02.425566  4990 solver.cpp:342] Iteration 45200, Testing net (#0)
I0613 21:37:07.215008  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.828438
I0613 21:37:07.215051  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.867204 (* 1 = 0.867204 loss)
I0613 21:37:09.742422  4990 solver.cpp:233] Iteration 45200, loss = 0.0348526
I0613 21:37:09.742465  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0348525 (* 1 = 0.0348525 loss)
I0613 21:37:09.742473  4990 sgd_solver.cpp:294] Iteration 45200, lr = 0.02
I0613 21:54:15.455859  4990 solver.cpp:342] Iteration 45600, Testing net (#0)
I0613 21:55:20.195370  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.866875
I0613 21:55:20.195416  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.613204 (* 1 = 0.613204 loss)
I0613 21:55:22.721047  4990 solver.cpp:233] Iteration 45600, loss = 0.0188617
I0613 21:55:22.721096  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0188616 (* 1 = 0.0188616 loss)
I0613 21:55:22.721108  4990 sgd_solver.cpp:294] Iteration 45600, lr = 0.02
I0613 22:12:28.373982  4990 solver.cpp:342] Iteration 46000, Testing net (#0)
I0613 22:13:33.170902  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.826953
I0613 22:13:33.170943  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.762497 (* 1 = 0.762497 loss)
I0613 22:13:35.694275  4990 solver.cpp:233] Iteration 46000, loss = 0.0409057
I0613 22:13:35.694308  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0409057 (* 1 = 0.0409057 loss)
I0613 22:13:35.694315  4990 sgd_solver.cpp:294] Iteration 46000, lr = 0.02
I0613 22:30:41.430259  4990 solver.cpp:342] Iteration 46400, Testing net (#0)
I0613 22:31:46.189438  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.839766
I0613 22:31:46.189481  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.788138 (* 1 = 0.788138 loss)
I0613 22:31:48.717259  4990 solver.cpp:233] Iteration 46400, loss = 0.0417668
I0613 22:31:48.717298  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0417668 (* 1 = 0.0417668 loss)
I0613 22:31:48.717305  4990 sgd_solver.cpp:294] Iteration 46400, lr = 0.02
I0613 22:48:54.520371  4990 solver.cpp:342] Iteration 46800, Testing net (#0)
I0613 22:49:59.301167  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.867031
I0613 22:49:59.301205  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.597895 (* 1 = 0.597895 loss)
I0613 22:50:01.829025  4990 solver.cpp:233] Iteration 46800, loss = 0.0197309
I0613 22:50:01.829069  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0197309 (* 1 = 0.0197309 loss)
I0613 22:50:01.829082  4990 sgd_solver.cpp:294] Iteration 46800, lr = 0.02
I0613 23:07:07.431314  4990 solver.cpp:342] Iteration 47200, Testing net (#0)
I0613 23:08:12.183393  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.848594
I0613 23:08:12.183434  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.804602 (* 1 = 0.804602 loss)
I0613 23:08:14.707532  4990 solver.cpp:233] Iteration 47200, loss = 0.0423132
I0613 23:08:14.707571  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0423132 (* 1 = 0.0423132 loss)
I0613 23:08:14.707577  4990 sgd_solver.cpp:294] Iteration 47200, lr = 0.02
I0613 23:25:20.467921  4990 solver.cpp:342] Iteration 47600, Testing net (#0)
I0613 23:26:25.247386  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.838203
I0613 23:26:25.247432  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.883181 (* 1 = 0.883181 loss)
I0613 23:26:27.779407  4990 solver.cpp:233] Iteration 47600, loss = 0.0208481
I0613 23:26:27.779450  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0208481 (* 1 = 0.0208481 loss)
I0613 23:26:27.779459  4990 sgd_solver.cpp:294] Iteration 47600, lr = 0.02
I0613 23:43:33.336920  4990 solver.cpp:342] Iteration 48000, Testing net (#0)
I0613 23:44:38.118201  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.857344
I0613 23:44:38.118247  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.632299 (* 1 = 0.632299 loss)
I0613 23:44:40.645882  4990 solver.cpp:233] Iteration 48000, loss = 0.0110123
I0613 23:44:40.645926  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0110123 (* 1 = 0.0110123 loss)
I0613 23:44:40.645934  4990 sgd_solver.cpp:294] Iteration 48000, lr = 0.02
I0614 00:01:46.335517  4990 solver.cpp:342] Iteration 48400, Testing net (#0)
I0614 00:02:51.089906  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.873125
I0614 00:02:51.089951  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.514127 (* 1 = 0.514127 loss)
I0614 00:02:53.619844  4990 solver.cpp:233] Iteration 48400, loss = 0.0203985
I0614 00:02:53.619894  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0203985 (* 1 = 0.0203985 loss)
I0614 00:02:53.619902  4990 sgd_solver.cpp:294] Iteration 48400, lr = 0.02
I0614 00:19:59.239580  4990 solver.cpp:342] Iteration 48800, Testing net (#0)
I0614 00:21:04.045819  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.867266
I0614 00:21:04.045877  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.600586 (* 1 = 0.600586 loss)
I0614 00:21:06.576331  4990 solver.cpp:233] Iteration 48800, loss = 0.0726009
I0614 00:21:06.576386  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0726009 (* 1 = 0.0726009 loss)
I0614 00:21:06.576397  4990 sgd_solver.cpp:294] Iteration 48800, lr = 0.02
I0614 00:38:12.638607  4990 solver.cpp:342] Iteration 49200, Testing net (#0)
I0614 00:39:17.407743  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.869922
I0614 00:39:17.407790  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.628869 (* 1 = 0.628869 loss)
I0614 00:39:19.956223  4990 solver.cpp:233] Iteration 49200, loss = 0.104235
I0614 00:39:19.956264  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.104235 (* 1 = 0.104235 loss)
I0614 00:39:19.956271  4990 sgd_solver.cpp:294] Iteration 49200, lr = 0.02
I0614 00:56:25.985749  4990 solver.cpp:342] Iteration 49600, Testing net (#0)
I0614 00:57:30.773830  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.859766
I0614 00:57:30.773874  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.623212 (* 1 = 0.623212 loss)
I0614 00:57:33.301473  4990 solver.cpp:233] Iteration 49600, loss = 0.0327043
I0614 00:57:33.301513  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0327043 (* 1 = 0.0327043 loss)
I0614 00:57:33.301522  4990 sgd_solver.cpp:294] Iteration 49600, lr = 0.02
I0614 01:14:38.980145  4990 solver.cpp:342] Iteration 50000, Testing net (#0)
I0614 01:15:43.736172  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.853828
I0614 01:15:43.736224  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.69137 (* 1 = 0.69137 loss)
I0614 01:15:46.262300  4990 solver.cpp:233] Iteration 50000, loss = 0.0420371
I0614 01:15:46.262341  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.042037 (* 1 = 0.042037 loss)
I0614 01:15:46.262349  4990 sgd_solver.cpp:294] Iteration 50000, lr = 0.02
I0614 01:32:52.127260  4990 solver.cpp:342] Iteration 50400, Testing net (#0)
I0614 01:33:56.879432  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.865078
I0614 01:33:56.879474  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.618143 (* 1 = 0.618143 loss)
I0614 01:33:59.414305  4990 solver.cpp:233] Iteration 50400, loss = 0.0459444
I0614 01:33:59.414345  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0459444 (* 1 = 0.0459444 loss)
I0614 01:33:59.414356  4990 sgd_solver.cpp:294] Iteration 50400, lr = 0.02
I0614 01:51:05.172263  4990 solver.cpp:342] Iteration 50800, Testing net (#0)
I0614 01:52:09.946223  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.858125
I0614 01:52:09.946269  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.674631 (* 1 = 0.674631 loss)
I0614 01:52:12.477401  4990 solver.cpp:233] Iteration 50800, loss = 0.0174116
I0614 01:52:12.477442  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0174116 (* 1 = 0.0174116 loss)
I0614 01:52:12.477449  4990 sgd_solver.cpp:294] Iteration 50800, lr = 0.02
I0614 02:09:18.073734  4990 solver.cpp:342] Iteration 51200, Testing net (#0)
I0614 02:10:22.803660  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.838125
I0614 02:10:22.803717  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.804107 (* 1 = 0.804107 loss)
I0614 02:10:25.327399  4990 solver.cpp:233] Iteration 51200, loss = 0.0255365
I0614 02:10:25.327438  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0255364 (* 1 = 0.0255364 loss)
I0614 02:10:25.327446  4990 sgd_solver.cpp:294] Iteration 51200, lr = 0.02
I0614 02:27:31.014441  4990 solver.cpp:342] Iteration 51600, Testing net (#0)
I0614 02:28:35.768199  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.862266
I0614 02:28:35.768244  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.665513 (* 1 = 0.665513 loss)
I0614 02:28:38.307229  4990 solver.cpp:233] Iteration 51600, loss = 0.0167921
I0614 02:28:38.307286  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0167921 (* 1 = 0.0167921 loss)
I0614 02:28:38.307297  4990 sgd_solver.cpp:294] Iteration 51600, lr = 0.02
I0614 02:45:44.157301  4990 solver.cpp:342] Iteration 52000, Testing net (#0)
I0614 02:46:48.877264  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.847969
I0614 02:46:48.877306  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.695339 (* 1 = 0.695339 loss)
I0614 02:46:51.407866  4990 solver.cpp:233] Iteration 52000, loss = 0.0419461
I0614 02:46:51.407910  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0419462 (* 1 = 0.0419462 loss)
I0614 02:46:51.407918  4990 sgd_solver.cpp:294] Iteration 52000, lr = 0.02
I0614 03:03:57.224002  4990 solver.cpp:342] Iteration 52400, Testing net (#0)
I0614 03:05:01.929040  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.836953
I0614 03:05:01.929082  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.788016 (* 1 = 0.788016 loss)
I0614 03:05:04.452399  4990 solver.cpp:233] Iteration 52400, loss = 0.0246346
I0614 03:05:04.452438  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0246346 (* 1 = 0.0246346 loss)
I0614 03:05:04.452445  4990 sgd_solver.cpp:294] Iteration 52400, lr = 0.02
I0614 03:22:10.321960  4990 solver.cpp:342] Iteration 52800, Testing net (#0)
I0614 03:23:15.081270  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.839219
I0614 03:23:15.081315  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.78641 (* 1 = 0.78641 loss)
I0614 03:23:17.617830  4990 solver.cpp:233] Iteration 52800, loss = 0.0957454
I0614 03:23:17.617882  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0957454 (* 1 = 0.0957454 loss)
I0614 03:23:17.617892  4990 sgd_solver.cpp:294] Iteration 52800, lr = 0.02
I0614 03:40:28.469964  4990 solver.cpp:342] Iteration 53200, Testing net (#0)
I0614 03:41:33.626459  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.84625
I0614 03:41:33.626502  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.758958 (* 1 = 0.758958 loss)
I0614 03:41:36.159586  4990 solver.cpp:233] Iteration 53200, loss = 0.0365597
I0614 03:41:36.159621  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0365598 (* 1 = 0.0365598 loss)
I0614 03:41:36.159628  4990 sgd_solver.cpp:294] Iteration 53200, lr = 0.02
I0614 03:58:51.350587  4990 solver.cpp:342] Iteration 53600, Testing net (#0)
I0614 03:59:56.628526  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.864453
I0614 03:59:56.628571  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.663147 (* 1 = 0.663147 loss)
I0614 03:59:59.152854  4990 solver.cpp:233] Iteration 53600, loss = 0.0180977
I0614 03:59:59.152887  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0180978 (* 1 = 0.0180978 loss)
I0614 03:59:59.152894  4990 sgd_solver.cpp:294] Iteration 53600, lr = 0.02
I0614 04:17:13.547029  4990 solver.cpp:342] Iteration 54000, Testing net (#0)
I0614 04:18:19.382407  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.838437
I0614 04:18:19.382452  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.808178 (* 1 = 0.808178 loss)
I0614 04:18:21.935032  4990 solver.cpp:233] Iteration 54000, loss = 0.0624115
I0614 04:18:21.935082  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0624116 (* 1 = 0.0624116 loss)
I0614 04:18:21.935093  4990 sgd_solver.cpp:294] Iteration 54000, lr = 0.02
I0614 04:35:36.845242  4990 solver.cpp:342] Iteration 54400, Testing net (#0)
I0614 04:36:42.701306  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.865547
I0614 04:36:42.701378  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.615565 (* 1 = 0.615565 loss)
I0614 04:36:45.234436  4990 solver.cpp:233] Iteration 54400, loss = 0.055614
I0614 04:36:45.234498  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0556141 (* 1 = 0.0556141 loss)
I0614 04:36:45.234508  4990 sgd_solver.cpp:294] Iteration 54400, lr = 0.02
I0614 04:53:59.728428  4990 solver.cpp:342] Iteration 54800, Testing net (#0)
I0614 04:55:05.074828  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.849375
I0614 04:55:05.074911  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.789504 (* 1 = 0.789504 loss)
I0614 04:55:07.654831  4990 solver.cpp:233] Iteration 54800, loss = 0.0488259
I0614 04:55:07.654868  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0488259 (* 1 = 0.0488259 loss)
I0614 04:55:07.654876  4990 sgd_solver.cpp:294] Iteration 54800, lr = 0.02
I0614 05:12:21.542825  4990 solver.cpp:342] Iteration 55200, Testing net (#0)
I0614 05:13:26.459462  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.817266
I0614 05:13:26.459506  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.877997 (* 1 = 0.877997 loss)
I0614 05:13:29.030369  4990 solver.cpp:233] Iteration 55200, loss = 0.0239713
I0614 05:13:29.030405  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0239713 (* 1 = 0.0239713 loss)
I0614 05:13:29.030413  4990 sgd_solver.cpp:294] Iteration 55200, lr = 0.02
I0614 05:30:42.987129  4990 solver.cpp:342] Iteration 55600, Testing net (#0)
I0614 05:31:48.210235  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.863828
I0614 05:31:48.210283  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.591762 (* 1 = 0.591762 loss)
I0614 05:31:50.779508  4990 solver.cpp:233] Iteration 55600, loss = 0.0277102
I0614 05:31:50.779554  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0277102 (* 1 = 0.0277102 loss)
I0614 05:31:50.779563  4990 sgd_solver.cpp:294] Iteration 55600, lr = 0.02
I0614 05:49:05.087970  4990 solver.cpp:342] Iteration 56000, Testing net (#0)
I0614 05:50:10.308425  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.855547
I0614 05:50:10.308471  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.663807 (* 1 = 0.663807 loss)
I0614 05:50:12.885274  4990 solver.cpp:233] Iteration 56000, loss = 0.0283163
I0614 05:50:12.885308  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0283164 (* 1 = 0.0283164 loss)
I0614 05:50:12.885316  4990 sgd_solver.cpp:294] Iteration 56000, lr = 0.02
I0614 06:07:27.397557  4990 solver.cpp:342] Iteration 56400, Testing net (#0)
I0614 06:08:32.755137  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.871641
I0614 06:08:32.755183  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.542948 (* 1 = 0.542948 loss)
I0614 06:08:35.326401  4990 solver.cpp:233] Iteration 56400, loss = 0.047411
I0614 06:08:35.326438  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0474111 (* 1 = 0.0474111 loss)
I0614 06:08:35.326447  4990 sgd_solver.cpp:294] Iteration 56400, lr = 0.02
I0614 06:25:49.637184  4990 solver.cpp:342] Iteration 56800, Testing net (#0)
I0614 06:26:55.136075  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.825234
I0614 06:26:55.136116  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.875882 (* 1 = 0.875882 loss)
I0614 06:26:57.665313  4990 solver.cpp:233] Iteration 56800, loss = 0.0101749
I0614 06:26:57.665349  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.010175 (* 1 = 0.010175 loss)
I0614 06:26:57.665355  4990 sgd_solver.cpp:294] Iteration 56800, lr = 0.02
I0614 06:44:12.626994  4990 solver.cpp:342] Iteration 57200, Testing net (#0)
I0614 06:45:17.916975  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.840547
I0614 06:45:17.917012  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.719247 (* 1 = 0.719247 loss)
I0614 06:45:20.486942  4990 solver.cpp:233] Iteration 57200, loss = 0.0228218
I0614 06:45:20.486977  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0228219 (* 1 = 0.0228219 loss)
I0614 06:45:20.486985  4990 sgd_solver.cpp:294] Iteration 57200, lr = 0.02
I0614 07:02:31.659085  4990 solver.cpp:342] Iteration 57600, Testing net (#0)
I0614 07:03:36.701642  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.849219
I0614 07:03:36.701686  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.679855 (* 1 = 0.679855 loss)
I0614 07:03:39.249927  4990 solver.cpp:233] Iteration 57600, loss = 0.0196921
I0614 07:03:39.249963  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0196921 (* 1 = 0.0196921 loss)
I0614 07:03:39.249969  4990 sgd_solver.cpp:294] Iteration 57600, lr = 0.02
I0614 07:20:54.731628  4990 solver.cpp:342] Iteration 58000, Testing net (#0)
I0614 07:21:59.876960  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.831016
I0614 07:21:59.877002  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.885903 (* 1 = 0.885903 loss)
I0614 07:22:02.427561  4990 solver.cpp:233] Iteration 58000, loss = 0.0549602
I0614 07:22:02.427597  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0549602 (* 1 = 0.0549602 loss)
I0614 07:22:02.427604  4990 sgd_solver.cpp:294] Iteration 58000, lr = 0.02
I0614 07:39:16.711294  4990 solver.cpp:342] Iteration 58400, Testing net (#0)
I0614 07:40:21.929874  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.887344
I0614 07:40:21.929916  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.491656 (* 1 = 0.491656 loss)
I0614 07:40:24.480890  4990 solver.cpp:233] Iteration 58400, loss = 0.0566746
I0614 07:40:24.480928  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0566747 (* 1 = 0.0566747 loss)
I0614 07:40:24.480936  4990 sgd_solver.cpp:294] Iteration 58400, lr = 0.02
I0614 07:57:38.640614  4990 solver.cpp:342] Iteration 58800, Testing net (#0)
I0614 07:58:43.807833  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.850234
I0614 07:58:43.807878  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.777824 (* 1 = 0.777824 loss)
I0614 07:58:46.347529  4990 solver.cpp:233] Iteration 58800, loss = 0.0732833
I0614 07:58:46.347580  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0732833 (* 1 = 0.0732833 loss)
I0614 07:58:46.347592  4990 sgd_solver.cpp:294] Iteration 58800, lr = 0.02
I0614 08:16:00.856709  4990 solver.cpp:342] Iteration 59200, Testing net (#0)
I0614 08:17:05.960906  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.855078
I0614 08:17:05.960943  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.69961 (* 1 = 0.69961 loss)
I0614 08:17:08.504979  4990 solver.cpp:233] Iteration 59200, loss = 0.0278038
I0614 08:17:08.505007  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0278039 (* 1 = 0.0278039 loss)
I0614 08:17:08.505014  4990 sgd_solver.cpp:294] Iteration 59200, lr = 0.02
I0614 08:34:23.250372  4990 solver.cpp:342] Iteration 59600, Testing net (#0)
I0614 08:35:28.339457  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.867422
I0614 08:35:28.339496  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.602196 (* 1 = 0.602196 loss)
I0614 08:35:30.925398  4990 solver.cpp:233] Iteration 59600, loss = 0.0342288
I0614 08:35:30.925442  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0342289 (* 1 = 0.0342289 loss)
I0614 08:35:30.925451  4990 sgd_solver.cpp:294] Iteration 59600, lr = 0.02
I0614 08:52:46.457361  4990 solver.cpp:342] Iteration 60000, Testing net (#0)
I0614 08:53:51.747243  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.85
I0614 08:53:51.747283  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.64366 (* 1 = 0.64366 loss)
I0614 08:53:54.278882  4990 solver.cpp:233] Iteration 60000, loss = 0.0157164
I0614 08:53:54.278918  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0157165 (* 1 = 0.0157165 loss)
I0614 08:53:54.278924  4990 sgd_solver.cpp:294] Iteration 60000, lr = 0.02
I0614 09:11:08.212436  4990 solver.cpp:342] Iteration 60400, Testing net (#0)
I0614 09:12:13.399932  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.869141
I0614 09:12:13.399984  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.607747 (* 1 = 0.607747 loss)
I0614 09:12:15.946091  4990 solver.cpp:233] Iteration 60400, loss = 0.00965102
I0614 09:12:15.946138  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00965114 (* 1 = 0.00965114 loss)
I0614 09:12:15.946156  4990 sgd_solver.cpp:294] Iteration 60400, lr = 0.02
I0614 09:29:30.780484  4990 solver.cpp:342] Iteration 60800, Testing net (#0)
I0614 09:30:36.069293  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.83625
I0614 09:30:36.069339  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.754376 (* 1 = 0.754376 loss)
I0614 09:30:38.598953  4990 solver.cpp:233] Iteration 60800, loss = 0.0422515
I0614 09:30:38.598987  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0422517 (* 1 = 0.0422517 loss)
I0614 09:30:38.598994  4990 sgd_solver.cpp:294] Iteration 60800, lr = 0.02
I0614 09:47:54.656965  4990 solver.cpp:342] Iteration 61200, Testing net (#0)
I0614 09:48:59.850534  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.802891
I0614 09:48:59.850591  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.15352 (* 1 = 1.15352 loss)
I0614 09:49:02.436002  4990 solver.cpp:233] Iteration 61200, loss = 0.0299758
I0614 09:49:02.436061  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0299759 (* 1 = 0.0299759 loss)
I0614 09:49:02.436074  4990 sgd_solver.cpp:294] Iteration 61200, lr = 0.02
I0614 10:06:17.107002  4990 solver.cpp:342] Iteration 61600, Testing net (#0)
I0614 10:07:22.309247  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.833594
I0614 10:07:22.309288  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.802718 (* 1 = 0.802718 loss)
I0614 10:07:24.873301  4990 solver.cpp:233] Iteration 61600, loss = 0.0281258
I0614 10:07:24.873347  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0281259 (* 1 = 0.0281259 loss)
I0614 10:07:24.873355  4990 sgd_solver.cpp:294] Iteration 61600, lr = 0.02
I0614 10:24:39.471177  4990 solver.cpp:342] Iteration 62000, Testing net (#0)
I0614 10:25:44.764605  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.862031
I0614 10:25:44.764645  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.637949 (* 1 = 0.637949 loss)
I0614 10:25:47.324868  4990 solver.cpp:233] Iteration 62000, loss = 0.0528009
I0614 10:25:47.324901  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.052801 (* 1 = 0.052801 loss)
I0614 10:25:47.324918  4990 sgd_solver.cpp:294] Iteration 62000, lr = 0.02
I0614 10:43:03.299746  4990 solver.cpp:342] Iteration 62400, Testing net (#0)
I0614 10:44:08.506394  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.841953
I0614 10:44:08.506435  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.728926 (* 1 = 0.728926 loss)
I0614 10:44:11.028411  4990 solver.cpp:233] Iteration 62400, loss = 0.019718
I0614 10:44:11.028442  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0197181 (* 1 = 0.0197181 loss)
I0614 10:44:11.028450  4990 sgd_solver.cpp:294] Iteration 62400, lr = 0.02
I0614 11:01:26.311013  4990 solver.cpp:342] Iteration 62800, Testing net (#0)
I0614 11:02:31.793282  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.872891
I0614 11:02:31.793336  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.611782 (* 1 = 0.611782 loss)
I0614 11:02:34.324467  4990 solver.cpp:233] Iteration 62800, loss = 0.0134039
I0614 11:02:34.324513  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0134041 (* 1 = 0.0134041 loss)
I0614 11:02:34.324523  4990 sgd_solver.cpp:294] Iteration 62800, lr = 0.02
I0614 11:19:48.502768  4990 solver.cpp:342] Iteration 63200, Testing net (#0)
I0614 11:20:53.734586  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.827812
I0614 11:20:53.734632  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.818735 (* 1 = 0.818735 loss)
I0614 11:20:56.265578  4990 solver.cpp:233] Iteration 63200, loss = 0.0524859
I0614 11:20:56.265640  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0524861 (* 1 = 0.0524861 loss)
I0614 11:20:56.265650  4990 sgd_solver.cpp:294] Iteration 63200, lr = 0.02
I0614 11:38:11.454717  4990 solver.cpp:342] Iteration 63600, Testing net (#0)
I0614 11:39:16.674089  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.835
I0614 11:39:16.674131  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.906015 (* 1 = 0.906015 loss)
I0614 11:39:19.195276  4990 solver.cpp:233] Iteration 63600, loss = 0.113576
I0614 11:39:19.195304  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.113576 (* 1 = 0.113576 loss)
I0614 11:39:19.195312  4990 sgd_solver.cpp:294] Iteration 63600, lr = 0.02
I0614 11:56:33.963060  4990 solver.cpp:342] Iteration 64000, Testing net (#0)
I0614 11:57:39.077361  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.850781
I0614 11:57:39.077400  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.742211 (* 1 = 0.742211 loss)
I0614 11:57:41.640852  4990 solver.cpp:233] Iteration 64000, loss = 0.0212208
I0614 11:57:41.640887  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.021221 (* 1 = 0.021221 loss)
I0614 11:57:41.640893  4990 sgd_solver.cpp:294] Iteration 64000, lr = 0.02
I0614 12:14:56.034555  4990 solver.cpp:342] Iteration 64400, Testing net (#0)
I0614 12:16:01.230654  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.858828
I0614 12:16:01.230696  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.660779 (* 1 = 0.660779 loss)
I0614 12:16:03.757139  4990 solver.cpp:233] Iteration 64400, loss = 0.0751498
I0614 12:16:03.757179  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.07515 (* 1 = 0.07515 loss)
I0614 12:16:03.757185  4990 sgd_solver.cpp:294] Iteration 64400, lr = 0.02
I0614 12:33:19.139740  4990 solver.cpp:342] Iteration 64800, Testing net (#0)
I0614 12:34:24.280230  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.809687
I0614 12:34:24.280270  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.840732 (* 1 = 0.840732 loss)
I0614 12:34:26.819725  4990 solver.cpp:233] Iteration 64800, loss = 0.0179294
I0614 12:34:26.819772  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0179296 (* 1 = 0.0179296 loss)
I0614 12:34:26.819780  4990 sgd_solver.cpp:294] Iteration 64800, lr = 0.02
I0614 12:53:23.310820  4990 solver.cpp:342] Iteration 65200, Testing net (#0)
I0614 12:54:28.548483  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.834063
I0614 12:54:28.548521  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.810459 (* 1 = 0.810459 loss)
I0614 12:54:31.085774  4990 solver.cpp:233] Iteration 65200, loss = 0.0648212
I0614 12:54:31.085813  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0648214 (* 1 = 0.0648214 loss)
I0614 12:54:31.085826  4990 sgd_solver.cpp:294] Iteration 65200, lr = 0.02
I0614 13:15:21.411551  4990 solver.cpp:342] Iteration 65600, Testing net (#0)
I0614 13:16:26.923712  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.863516
I0614 13:16:26.923749  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.719354 (* 1 = 0.719354 loss)
I0614 13:16:29.510323  4990 solver.cpp:233] Iteration 65600, loss = 0.0647848
I0614 13:16:29.510432  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.064785 (* 1 = 0.064785 loss)
I0614 13:16:29.510453  4990 sgd_solver.cpp:294] Iteration 65600, lr = 0.02
I0614 13:33:42.355865  4990 solver.cpp:342] Iteration 66000, Testing net (#0)
I0614 13:34:47.439927  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.882578
I0614 13:34:47.439981  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.597625 (* 1 = 0.597625 loss)
I0614 13:34:49.994526  4990 solver.cpp:233] Iteration 66000, loss = 0.0494133
I0614 13:34:49.994563  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0494136 (* 1 = 0.0494136 loss)
I0614 13:34:49.994571  4990 sgd_solver.cpp:294] Iteration 66000, lr = 0.02
I0614 13:52:06.200671  4990 solver.cpp:342] Iteration 66400, Testing net (#0)
I0614 13:53:11.620926  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.815859
I0614 13:53:11.620973  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.999407 (* 1 = 0.999407 loss)
I0614 13:53:14.144668  4990 solver.cpp:233] Iteration 66400, loss = 0.0159041
I0614 13:53:14.144709  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0159043 (* 1 = 0.0159043 loss)
I0614 13:53:14.144717  4990 sgd_solver.cpp:294] Iteration 66400, lr = 0.02
I0614 14:10:29.234383  4990 solver.cpp:342] Iteration 66800, Testing net (#0)
I0614 14:11:34.607452  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.867578
I0614 14:11:34.607496  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.668287 (* 1 = 0.668287 loss)
I0614 14:11:37.137349  4990 solver.cpp:233] Iteration 66800, loss = 0.0477442
I0614 14:11:37.137388  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0477444 (* 1 = 0.0477444 loss)
I0614 14:11:37.137397  4990 sgd_solver.cpp:294] Iteration 66800, lr = 0.02
I0614 14:28:53.958261  4990 solver.cpp:342] Iteration 67200, Testing net (#0)
I0614 14:29:58.858541  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.869141
I0614 14:29:58.858589  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.605282 (* 1 = 0.605282 loss)
I0614 14:30:01.391705  4990 solver.cpp:233] Iteration 67200, loss = 0.0389654
I0614 14:30:01.391751  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0389656 (* 1 = 0.0389656 loss)
I0614 14:30:01.391759  4990 sgd_solver.cpp:294] Iteration 67200, lr = 0.02
I0614 14:47:22.483166  4990 solver.cpp:342] Iteration 67600, Testing net (#0)
I0614 14:48:28.190721  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.853359
I0614 14:48:28.190771  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.710581 (* 1 = 0.710581 loss)
I0614 14:48:30.744669  4990 solver.cpp:233] Iteration 67600, loss = 0.00792627
I0614 14:48:30.744709  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00792648 (* 1 = 0.00792648 loss)
I0614 14:48:30.744717  4990 sgd_solver.cpp:294] Iteration 67600, lr = 0.02
I0614 15:05:47.531538  4990 solver.cpp:342] Iteration 68000, Testing net (#0)
I0614 15:06:52.912973  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.838437
I0614 15:06:52.913013  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.861861 (* 1 = 0.861861 loss)
I0614 15:06:55.470895  4990 solver.cpp:233] Iteration 68000, loss = 0.0314902
I0614 15:06:55.470932  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0314904 (* 1 = 0.0314904 loss)
I0614 15:06:55.470950  4990 sgd_solver.cpp:294] Iteration 68000, lr = 0.02
I0614 15:24:12.658978  4990 solver.cpp:342] Iteration 68400, Testing net (#0)
I0614 15:25:17.938423  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.847891
I0614 15:25:17.938493  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.766169 (* 1 = 0.766169 loss)
I0614 15:25:20.517640  4990 solver.cpp:233] Iteration 68400, loss = 0.0256373
I0614 15:25:20.517673  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0256375 (* 1 = 0.0256375 loss)
I0614 15:25:20.517680  4990 sgd_solver.cpp:294] Iteration 68400, lr = 0.02
I0614 15:42:35.465255  4990 solver.cpp:342] Iteration 68800, Testing net (#0)
I0614 15:43:40.713461  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.839141
I0614 15:43:40.713510  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.805607 (* 1 = 0.805607 loss)
I0614 15:43:43.245887  4990 solver.cpp:233] Iteration 68800, loss = 0.0558907
I0614 15:43:43.245921  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0558909 (* 1 = 0.0558909 loss)
I0614 15:43:43.245928  4990 sgd_solver.cpp:294] Iteration 68800, lr = 0.02
I0614 16:00:57.165295  4990 solver.cpp:342] Iteration 69200, Testing net (#0)
I0614 16:02:02.333376  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.867969
I0614 16:02:02.333416  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.662567 (* 1 = 0.662567 loss)
I0614 16:02:04.889698  4990 solver.cpp:233] Iteration 69200, loss = 0.0600934
I0614 16:02:04.889741  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0600936 (* 1 = 0.0600936 loss)
I0614 16:02:04.889750  4990 sgd_solver.cpp:294] Iteration 69200, lr = 0.02
I0614 16:19:20.750497  4990 solver.cpp:342] Iteration 69600, Testing net (#0)
I0614 16:20:26.611991  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.860313
I0614 16:20:26.612047  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.647681 (* 1 = 0.647681 loss)
I0614 16:20:29.146448  4990 solver.cpp:233] Iteration 69600, loss = 0.0315527
I0614 16:20:29.146486  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0315528 (* 1 = 0.0315528 loss)
I0614 16:20:29.146494  4990 sgd_solver.cpp:294] Iteration 69600, lr = 0.02
I0614 16:37:44.110312  4990 solver.cpp:342] Iteration 70000, Testing net (#0)
I0614 16:38:48.952342  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.863281
I0614 16:38:48.952390  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.641263 (* 1 = 0.641263 loss)
I0614 16:38:51.489959  4990 solver.cpp:233] Iteration 70000, loss = 0.0375252
I0614 16:38:51.489989  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0375253 (* 1 = 0.0375253 loss)
I0614 16:38:51.489995  4990 sgd_solver.cpp:294] Iteration 70000, lr = 0.02
I0614 16:55:59.813879  4990 solver.cpp:342] Iteration 70400, Testing net (#0)
I0614 16:57:04.558877  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.869062
I0614 16:57:04.558920  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.641973 (* 1 = 0.641973 loss)
I0614 16:57:07.087882  4990 solver.cpp:233] Iteration 70400, loss = 0.0143594
I0614 16:57:07.087924  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0143596 (* 1 = 0.0143596 loss)
I0614 16:57:07.087930  4990 sgd_solver.cpp:294] Iteration 70400, lr = 0.02
I0614 17:14:15.295325  4990 solver.cpp:342] Iteration 70800, Testing net (#0)
I0614 17:15:20.058724  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.855625
I0614 17:15:20.058764  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.701615 (* 1 = 0.701615 loss)
I0614 17:15:22.585494  4990 solver.cpp:233] Iteration 70800, loss = 0.0170085
I0614 17:15:22.585530  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0170087 (* 1 = 0.0170087 loss)
I0614 17:15:22.585537  4990 sgd_solver.cpp:294] Iteration 70800, lr = 0.02
I0614 17:32:30.735376  4990 solver.cpp:342] Iteration 71200, Testing net (#0)
I0614 17:33:35.563963  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.863672
I0614 17:33:35.564010  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.643905 (* 1 = 0.643905 loss)
I0614 17:33:38.102721  4990 solver.cpp:233] Iteration 71200, loss = 0.0401839
I0614 17:33:38.102758  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0401841 (* 1 = 0.0401841 loss)
I0614 17:33:38.102766  4990 sgd_solver.cpp:294] Iteration 71200, lr = 0.02
I0614 17:50:46.116240  4990 solver.cpp:342] Iteration 71600, Testing net (#0)
I0614 17:51:50.903751  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.805859
I0614 17:51:50.903795  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.14849 (* 1 = 1.14849 loss)
I0614 17:51:53.433015  4990 solver.cpp:233] Iteration 71600, loss = 0.0213236
I0614 17:51:53.433051  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0213237 (* 1 = 0.0213237 loss)
I0614 17:51:53.433058  4990 sgd_solver.cpp:294] Iteration 71600, lr = 0.02
I0614 18:09:02.369806  4990 solver.cpp:342] Iteration 72000, Testing net (#0)
I0614 18:10:07.174849  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.829219
I0614 18:10:07.174888  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.830121 (* 1 = 0.830121 loss)
I0614 18:10:09.711279  4990 solver.cpp:233] Iteration 72000, loss = 0.0414042
I0614 18:10:09.711318  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0414043 (* 1 = 0.0414043 loss)
I0614 18:10:09.711324  4990 sgd_solver.cpp:294] Iteration 72000, lr = 0.02
I0614 18:27:18.452368  4990 solver.cpp:342] Iteration 72400, Testing net (#0)
I0614 18:28:23.276176  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.838906
I0614 18:28:23.276213  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.763908 (* 1 = 0.763908 loss)
I0614 18:28:25.800573  4990 solver.cpp:233] Iteration 72400, loss = 0.0694671
I0614 18:28:25.800616  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0694673 (* 1 = 0.0694673 loss)
I0614 18:28:25.800624  4990 sgd_solver.cpp:294] Iteration 72400, lr = 0.02
I0614 18:45:34.372825  4990 solver.cpp:342] Iteration 72800, Testing net (#0)
I0614 18:46:39.291467  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.874922
I0614 18:46:39.291513  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.597693 (* 1 = 0.597693 loss)
I0614 18:46:41.820518  4990 solver.cpp:233] Iteration 72800, loss = 0.0520651
I0614 18:46:41.820557  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0520653 (* 1 = 0.0520653 loss)
I0614 18:46:41.820566  4990 sgd_solver.cpp:294] Iteration 72800, lr = 0.02
I0614 19:03:50.391774  4990 solver.cpp:342] Iteration 73200, Testing net (#0)
I0614 19:04:55.250310  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.857734
I0614 19:04:55.250358  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.653106 (* 1 = 0.653106 loss)
I0614 19:04:57.788224  4990 solver.cpp:233] Iteration 73200, loss = 0.0745736
I0614 19:04:57.788262  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0745738 (* 1 = 0.0745738 loss)
I0614 19:04:57.788271  4990 sgd_solver.cpp:294] Iteration 73200, lr = 0.02
I0614 19:22:06.426887  4990 solver.cpp:342] Iteration 73600, Testing net (#0)
I0614 19:23:11.154007  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.851719
I0614 19:23:11.154050  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.760005 (* 1 = 0.760005 loss)
I0614 19:23:13.685927  4990 solver.cpp:233] Iteration 73600, loss = 0.0292256
I0614 19:23:13.685966  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0292258 (* 1 = 0.0292258 loss)
I0614 19:23:13.685972  4990 sgd_solver.cpp:294] Iteration 73600, lr = 0.02
I0614 19:40:21.844396  4990 solver.cpp:342] Iteration 74000, Testing net (#0)
I0614 19:41:26.668788  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.844531
I0614 19:41:26.668843  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.658824 (* 1 = 0.658824 loss)
I0614 19:41:29.205112  4990 solver.cpp:233] Iteration 74000, loss = 0.0794668
I0614 19:41:29.205148  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0794669 (* 1 = 0.0794669 loss)
I0614 19:41:29.205155  4990 sgd_solver.cpp:294] Iteration 74000, lr = 0.02
I0614 19:58:37.521078  4990 solver.cpp:342] Iteration 74400, Testing net (#0)
I0614 19:59:42.409287  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.852969
I0614 19:59:42.409333  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.749178 (* 1 = 0.749178 loss)
I0614 19:59:44.943369  4990 solver.cpp:233] Iteration 74400, loss = 0.0250089
I0614 19:59:44.943410  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0250091 (* 1 = 0.0250091 loss)
I0614 19:59:44.943418  4990 sgd_solver.cpp:294] Iteration 74400, lr = 0.02
I0614 20:16:53.473042  4990 solver.cpp:342] Iteration 74800, Testing net (#0)
I0614 20:17:58.276409  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.844844
I0614 20:17:58.276453  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.789578 (* 1 = 0.789578 loss)
I0614 20:18:00.813859  4990 solver.cpp:233] Iteration 74800, loss = 0.0436748
I0614 20:18:00.813899  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.043675 (* 1 = 0.043675 loss)
I0614 20:18:00.813908  4990 sgd_solver.cpp:294] Iteration 74800, lr = 0.02
I0614 20:35:16.917667  4990 solver.cpp:342] Iteration 75200, Testing net (#0)
I0614 20:36:21.759670  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.865469
I0614 20:36:21.759713  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.581842 (* 1 = 0.581842 loss)
I0614 20:36:24.297061  4990 solver.cpp:233] Iteration 75200, loss = 0.0917914
I0614 20:36:24.297098  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0917916 (* 1 = 0.0917916 loss)
I0614 20:36:24.297106  4990 sgd_solver.cpp:294] Iteration 75200, lr = 0.02
I0614 20:53:39.959954  4990 solver.cpp:342] Iteration 75600, Testing net (#0)
I0614 20:54:44.815384  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.855781
I0614 20:54:44.815426  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.678957 (* 1 = 0.678957 loss)
I0614 20:54:47.350536  4990 solver.cpp:233] Iteration 75600, loss = 0.0665877
I0614 20:54:47.350577  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0665879 (* 1 = 0.0665879 loss)
I0614 20:54:47.350586  4990 sgd_solver.cpp:294] Iteration 75600, lr = 0.02
I0614 21:11:56.833891  4990 solver.cpp:342] Iteration 76000, Testing net (#0)
I0614 21:13:01.631153  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.843672
I0614 21:13:01.631196  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.83062 (* 1 = 0.83062 loss)
I0614 21:13:04.159286  4990 solver.cpp:233] Iteration 76000, loss = 0.0219628
I0614 21:13:04.159320  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.021963 (* 1 = 0.021963 loss)
I0614 21:13:04.159327  4990 sgd_solver.cpp:294] Iteration 76000, lr = 0.02
I0614 21:30:12.383052  4990 solver.cpp:342] Iteration 76400, Testing net (#0)
I0614 21:31:17.200335  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.848203
I0614 21:31:17.200381  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.735887 (* 1 = 0.735887 loss)
I0614 21:31:19.739445  4990 solver.cpp:233] Iteration 76400, loss = 0.0434205
I0614 21:31:19.739485  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0434207 (* 1 = 0.0434207 loss)
I0614 21:31:19.739492  4990 sgd_solver.cpp:294] Iteration 76400, lr = 0.02
I0614 21:48:28.174526  4990 solver.cpp:342] Iteration 76800, Testing net (#0)
I0614 21:49:33.009984  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.861641
I0614 21:49:33.010025  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.696621 (* 1 = 0.696621 loss)
I0614 21:49:35.556926  4990 solver.cpp:233] Iteration 76800, loss = 0.0365349
I0614 21:49:35.556963  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0365351 (* 1 = 0.0365351 loss)
I0614 21:49:35.556970  4990 sgd_solver.cpp:294] Iteration 76800, lr = 0.02
I0614 22:06:43.696492  4990 solver.cpp:342] Iteration 77200, Testing net (#0)
I0614 22:07:48.598513  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.877891
I0614 22:07:48.598569  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.533571 (* 1 = 0.533571 loss)
I0614 22:07:51.139065  4990 solver.cpp:233] Iteration 77200, loss = 0.0239321
I0614 22:07:51.139117  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0239323 (* 1 = 0.0239323 loss)
I0614 22:07:51.139127  4990 sgd_solver.cpp:294] Iteration 77200, lr = 0.02
I0614 22:24:59.617794  4990 solver.cpp:342] Iteration 77600, Testing net (#0)
I0614 22:26:04.461397  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.855234
I0614 22:26:04.461441  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.71008 (* 1 = 0.71008 loss)
I0614 22:26:06.986448  4990 solver.cpp:233] Iteration 77600, loss = 0.0454383
I0614 22:26:06.986485  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0454385 (* 1 = 0.0454385 loss)
I0614 22:26:06.986491  4990 sgd_solver.cpp:294] Iteration 77600, lr = 0.02
I0614 22:43:15.399243  4990 solver.cpp:342] Iteration 78000, Testing net (#0)
I0614 22:44:20.284255  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.872031
I0614 22:44:20.284310  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.565011 (* 1 = 0.565011 loss)
I0614 22:44:22.818938  4990 solver.cpp:233] Iteration 78000, loss = 0.0257611
I0614 22:44:22.818974  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0257613 (* 1 = 0.0257613 loss)
I0614 22:44:22.818981  4990 sgd_solver.cpp:294] Iteration 78000, lr = 0.02
I0614 23:01:32.347143  4990 solver.cpp:342] Iteration 78400, Testing net (#0)
I0614 23:02:37.088526  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.871875
I0614 23:02:37.088569  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.6421 (* 1 = 0.6421 loss)
I0614 23:02:39.626988  4990 solver.cpp:233] Iteration 78400, loss = 0.0375446
I0614 23:02:39.627023  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0375448 (* 1 = 0.0375448 loss)
I0614 23:02:39.627030  4990 sgd_solver.cpp:294] Iteration 78400, lr = 0.02
I0614 23:19:48.225560  4990 solver.cpp:342] Iteration 78800, Testing net (#0)
I0614 23:20:53.073240  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.832422
I0614 23:20:53.073309  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.03331 (* 1 = 1.03331 loss)
I0614 23:20:55.610692  4990 solver.cpp:233] Iteration 78800, loss = 0.0522807
I0614 23:20:55.610734  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.052281 (* 1 = 0.052281 loss)
I0614 23:20:55.610743  4990 sgd_solver.cpp:294] Iteration 78800, lr = 0.02
I0614 23:38:04.349568  4990 solver.cpp:342] Iteration 79200, Testing net (#0)
I0614 23:39:09.136243  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.794062
I0614 23:39:09.136288  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.24187 (* 1 = 1.24187 loss)
I0614 23:39:11.667182  4990 solver.cpp:233] Iteration 79200, loss = 0.0398773
I0614 23:39:11.667223  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0398775 (* 1 = 0.0398775 loss)
I0614 23:39:11.667235  4990 sgd_solver.cpp:294] Iteration 79200, lr = 0.02
I0614 23:56:20.104068  4990 solver.cpp:342] Iteration 79600, Testing net (#0)
I0614 23:57:24.996527  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.853906
I0614 23:57:24.996577  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.721699 (* 1 = 0.721699 loss)
I0614 23:57:27.533052  4990 solver.cpp:233] Iteration 79600, loss = 0.00853314
I0614 23:57:27.533094  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00853334 (* 1 = 0.00853334 loss)
I0614 23:57:27.533102  4990 sgd_solver.cpp:294] Iteration 79600, lr = 0.02
I0615 00:14:36.484849  4990 solver.cpp:342] Iteration 80000, Testing net (#0)
I0615 00:15:41.351357  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.852266
I0615 00:15:41.351402  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.769084 (* 1 = 0.769084 loss)
I0615 00:15:43.877799  4990 solver.cpp:233] Iteration 80000, loss = 0.0451533
I0615 00:15:43.877837  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0451534 (* 1 = 0.0451534 loss)
I0615 00:15:43.877846  4990 sgd_solver.cpp:294] Iteration 80000, lr = 0.02
I0615 00:32:52.466652  4990 solver.cpp:342] Iteration 80400, Testing net (#0)
I0615 00:33:57.363886  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.827891
I0615 00:33:57.363929  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.878713 (* 1 = 0.878713 loss)
I0615 00:33:59.900468  4990 solver.cpp:233] Iteration 80400, loss = 0.0429174
I0615 00:33:59.900501  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0429175 (* 1 = 0.0429175 loss)
I0615 00:33:59.900508  4990 sgd_solver.cpp:294] Iteration 80400, lr = 0.02
I0615 00:51:08.003166  4990 solver.cpp:342] Iteration 80800, Testing net (#0)
I0615 00:52:12.813387  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.886328
I0615 00:52:12.813423  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.498965 (* 1 = 0.498965 loss)
I0615 00:52:15.340766  4990 solver.cpp:233] Iteration 80800, loss = 0.0400889
I0615 00:52:15.340801  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0400891 (* 1 = 0.0400891 loss)
I0615 00:52:15.340808  4990 sgd_solver.cpp:294] Iteration 80800, lr = 0.02
I0615 01:09:23.871217  4990 solver.cpp:342] Iteration 81200, Testing net (#0)
I0615 01:10:28.597662  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.857109
I0615 01:10:28.597707  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.693223 (* 1 = 0.693223 loss)
I0615 01:10:31.125551  4990 solver.cpp:233] Iteration 81200, loss = 0.0362351
I0615 01:10:31.125587  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0362353 (* 1 = 0.0362353 loss)
I0615 01:10:31.125596  4990 sgd_solver.cpp:294] Iteration 81200, lr = 0.02
I0615 01:27:40.080854  4990 solver.cpp:342] Iteration 81600, Testing net (#0)
I0615 01:28:44.992372  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.875
I0615 01:28:44.992421  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.597762 (* 1 = 0.597762 loss)
I0615 01:28:47.530280  4990 solver.cpp:233] Iteration 81600, loss = 0.0232396
I0615 01:28:47.530323  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0232398 (* 1 = 0.0232398 loss)
I0615 01:28:47.530330  4990 sgd_solver.cpp:294] Iteration 81600, lr = 0.02
I0615 01:45:56.013916  4990 solver.cpp:342] Iteration 82000, Testing net (#0)
I0615 01:47:00.845177  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.878438
I0615 01:47:00.845216  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.574394 (* 1 = 0.574394 loss)
I0615 01:47:03.376091  4990 solver.cpp:233] Iteration 82000, loss = 0.0207191
I0615 01:47:03.376127  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0207193 (* 1 = 0.0207193 loss)
I0615 01:47:03.376135  4990 sgd_solver.cpp:294] Iteration 82000, lr = 0.02
I0615 02:04:18.326375  4990 solver.cpp:342] Iteration 82400, Testing net (#0)
I0615 02:05:23.356782  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.842656
I0615 02:05:23.356827  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.762456 (* 1 = 0.762456 loss)
I0615 02:05:25.887100  4990 solver.cpp:233] Iteration 82400, loss = 0.0507242
I0615 02:05:25.887137  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0507245 (* 1 = 0.0507245 loss)
I0615 02:05:25.887146  4990 sgd_solver.cpp:294] Iteration 82400, lr = 0.02
I0615 02:22:42.931314  4990 solver.cpp:342] Iteration 82800, Testing net (#0)
I0615 02:23:48.511343  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.854922
I0615 02:23:48.511384  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.656433 (* 1 = 0.656433 loss)
I0615 02:23:51.092875  4990 solver.cpp:233] Iteration 82800, loss = 0.0342774
I0615 02:23:51.092911  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0342776 (* 1 = 0.0342776 loss)
I0615 02:23:51.092918  4990 sgd_solver.cpp:294] Iteration 82800, lr = 0.02
I0615 02:41:06.880128  4990 solver.cpp:342] Iteration 83200, Testing net (#0)
I0615 02:42:11.973836  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.827969
I0615 02:42:11.973891  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.984936 (* 1 = 0.984936 loss)
I0615 02:42:14.548743  4990 solver.cpp:233] Iteration 83200, loss = 0.0139264
I0615 02:42:14.548791  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0139266 (* 1 = 0.0139266 loss)
I0615 02:42:14.548802  4990 sgd_solver.cpp:294] Iteration 83200, lr = 0.02
I0615 02:59:32.606901  4990 solver.cpp:342] Iteration 83600, Testing net (#0)
I0615 03:00:38.223469  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.833125
I0615 03:00:38.223512  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.840924 (* 1 = 0.840924 loss)
I0615 03:00:40.754567  4990 solver.cpp:233] Iteration 83600, loss = 0.0240017
I0615 03:00:40.754608  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.024002 (* 1 = 0.024002 loss)
I0615 03:00:40.754616  4990 sgd_solver.cpp:294] Iteration 83600, lr = 0.02
I0615 03:17:55.874300  4990 solver.cpp:342] Iteration 84000, Testing net (#0)
I0615 03:19:01.165491  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.825859
I0615 03:19:01.165540  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.961201 (* 1 = 0.961201 loss)
I0615 03:19:03.760869  4990 solver.cpp:233] Iteration 84000, loss = 0.00318155
I0615 03:19:03.760913  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00318176 (* 1 = 0.00318176 loss)
I0615 03:19:03.760922  4990 sgd_solver.cpp:294] Iteration 84000, lr = 0.02
I0615 03:36:19.001373  4990 solver.cpp:342] Iteration 84400, Testing net (#0)
I0615 03:37:24.314170  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.837031
I0615 03:37:24.314210  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.777661 (* 1 = 0.777661 loss)
I0615 03:37:26.854972  4990 solver.cpp:233] Iteration 84400, loss = 0.0227501
I0615 03:37:26.855013  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0227503 (* 1 = 0.0227503 loss)
I0615 03:37:26.855022  4990 sgd_solver.cpp:294] Iteration 84400, lr = 0.02
I0615 03:54:42.143793  4990 solver.cpp:342] Iteration 84800, Testing net (#0)
I0615 03:55:47.212136  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.874766
I0615 03:55:47.212175  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.578984 (* 1 = 0.578984 loss)
I0615 03:55:49.808876  4990 solver.cpp:233] Iteration 84800, loss = 0.0697461
I0615 03:55:49.808928  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0697463 (* 1 = 0.0697463 loss)
I0615 03:55:49.808934  4990 sgd_solver.cpp:294] Iteration 84800, lr = 0.02
I0615 04:13:05.782469  4990 solver.cpp:342] Iteration 85200, Testing net (#0)
I0615 04:14:11.240612  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.854453
I0615 04:14:11.240656  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.721949 (* 1 = 0.721949 loss)
I0615 04:14:13.805255  4990 solver.cpp:233] Iteration 85200, loss = 0.0240941
I0615 04:14:13.805294  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0240943 (* 1 = 0.0240943 loss)
I0615 04:14:13.805302  4990 sgd_solver.cpp:294] Iteration 85200, lr = 0.02
I0615 04:31:30.212074  4990 solver.cpp:342] Iteration 85600, Testing net (#0)
I0615 04:32:35.499126  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.855
I0615 04:32:35.499169  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.741701 (* 1 = 0.741701 loss)
I0615 04:32:38.021642  4990 solver.cpp:233] Iteration 85600, loss = 0.0223963
I0615 04:32:38.021682  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0223965 (* 1 = 0.0223965 loss)
I0615 04:32:38.021692  4990 sgd_solver.cpp:294] Iteration 85600, lr = 0.02
I0615 04:49:54.916206  4990 solver.cpp:342] Iteration 86000, Testing net (#0)
I0615 04:51:00.332494  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.823203
I0615 04:51:00.332545  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.850577 (* 1 = 0.850577 loss)
I0615 04:51:02.894130  4990 solver.cpp:233] Iteration 86000, loss = 0.00828453
I0615 04:51:02.894170  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00828476 (* 1 = 0.00828476 loss)
I0615 04:51:02.894179  4990 sgd_solver.cpp:294] Iteration 86000, lr = 0.02
I0615 05:08:20.130887  4990 solver.cpp:342] Iteration 86400, Testing net (#0)
I0615 05:09:25.700664  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.819531
I0615 05:09:25.700703  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.0576 (* 1 = 1.0576 loss)
I0615 05:09:28.247169  4990 solver.cpp:233] Iteration 86400, loss = 0.0590762
I0615 05:09:28.247205  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0590765 (* 1 = 0.0590765 loss)
I0615 05:09:28.247212  4990 sgd_solver.cpp:294] Iteration 86400, lr = 0.02
I0615 05:26:44.532905  4990 solver.cpp:342] Iteration 86800, Testing net (#0)
I0615 05:27:50.232683  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.820234
I0615 05:27:50.232736  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.03319 (* 1 = 1.03319 loss)
I0615 05:27:52.766257  4990 solver.cpp:233] Iteration 86800, loss = 0.0804541
I0615 05:27:52.766295  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0804543 (* 1 = 0.0804543 loss)
I0615 05:27:52.766302  4990 sgd_solver.cpp:294] Iteration 86800, lr = 0.02
I0615 05:45:09.070648  4990 solver.cpp:342] Iteration 87200, Testing net (#0)
I0615 05:46:14.635228  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.821875
I0615 05:46:14.635291  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.929194 (* 1 = 0.929194 loss)
I0615 05:46:17.173168  4990 solver.cpp:233] Iteration 87200, loss = 0.0708947
I0615 05:46:17.173204  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.070895 (* 1 = 0.070895 loss)
I0615 05:46:17.173213  4990 sgd_solver.cpp:294] Iteration 87200, lr = 0.02
I0615 06:03:33.560011  4990 solver.cpp:342] Iteration 87600, Testing net (#0)
I0615 06:04:38.884052  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.8625
I0615 06:04:38.884101  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.661288 (* 1 = 0.661288 loss)
I0615 06:04:41.426072  4990 solver.cpp:233] Iteration 87600, loss = 0.00495249
I0615 06:04:41.426115  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0049527 (* 1 = 0.0049527 loss)
I0615 06:04:41.426125  4990 sgd_solver.cpp:294] Iteration 87600, lr = 0.02
I0615 06:21:58.678470  4990 solver.cpp:342] Iteration 88000, Testing net (#0)
I0615 06:23:04.031298  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.863672
I0615 06:23:04.031339  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.663957 (* 1 = 0.663957 loss)
I0615 06:23:06.590289  4990 solver.cpp:233] Iteration 88000, loss = 0.0573304
I0615 06:23:06.590328  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0573306 (* 1 = 0.0573306 loss)
I0615 06:23:06.590342  4990 sgd_solver.cpp:294] Iteration 88000, lr = 0.02
I0615 06:40:23.678233  4990 solver.cpp:342] Iteration 88400, Testing net (#0)
I0615 06:41:29.042701  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.861797
I0615 06:41:29.042753  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.619769 (* 1 = 0.619769 loss)
I0615 06:41:31.588765  4990 solver.cpp:233] Iteration 88400, loss = 0.0480501
I0615 06:41:31.588798  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0480503 (* 1 = 0.0480503 loss)
I0615 06:41:31.588804  4990 sgd_solver.cpp:294] Iteration 88400, lr = 0.02
I0615 06:58:47.677090  4990 solver.cpp:342] Iteration 88800, Testing net (#0)
I0615 06:59:53.067059  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.864062
I0615 06:59:53.067101  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.64923 (* 1 = 0.64923 loss)
I0615 06:59:55.665266  4990 solver.cpp:233] Iteration 88800, loss = 0.0189439
I0615 06:59:55.665308  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0189441 (* 1 = 0.0189441 loss)
I0615 06:59:55.665326  4990 sgd_solver.cpp:294] Iteration 88800, lr = 0.02
I0615 07:17:11.885993  4990 solver.cpp:342] Iteration 89200, Testing net (#0)
I0615 07:18:17.639803  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.862109
I0615 07:18:17.639852  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.648717 (* 1 = 0.648717 loss)
I0615 07:18:20.186763  4990 solver.cpp:233] Iteration 89200, loss = 0.0338521
I0615 07:18:20.186792  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0338524 (* 1 = 0.0338524 loss)
I0615 07:18:20.186800  4990 sgd_solver.cpp:294] Iteration 89200, lr = 0.02
I0615 07:35:36.852514  4990 solver.cpp:342] Iteration 89600, Testing net (#0)
I0615 07:36:42.793573  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.881641
I0615 07:36:42.793620  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.553232 (* 1 = 0.553232 loss)
I0615 07:36:45.358947  4990 solver.cpp:233] Iteration 89600, loss = 0.0195623
I0615 07:36:45.359002  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0195625 (* 1 = 0.0195625 loss)
I0615 07:36:45.359015  4990 sgd_solver.cpp:294] Iteration 89600, lr = 0.02
I0615 07:54:02.356968  4990 solver.cpp:342] Iteration 90000, Testing net (#0)
I0615 07:55:07.859434  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.862344
I0615 07:55:07.859478  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.725358 (* 1 = 0.725358 loss)
I0615 07:55:10.403612  4990 solver.cpp:233] Iteration 90000, loss = 0.0172835
I0615 07:55:10.403666  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0172838 (* 1 = 0.0172838 loss)
I0615 07:55:10.403672  4990 sgd_solver.cpp:294] Iteration 90000, lr = 0.02
I0615 08:12:26.651240  4990 solver.cpp:342] Iteration 90400, Testing net (#0)
I0615 08:13:31.938210  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.868125
I0615 08:13:31.938249  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.693459 (* 1 = 0.693459 loss)
I0615 08:13:34.523083  4990 solver.cpp:233] Iteration 90400, loss = 0.08415
I0615 08:13:34.523119  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0841503 (* 1 = 0.0841503 loss)
I0615 08:13:34.523126  4990 sgd_solver.cpp:294] Iteration 90400, lr = 0.02
I0615 08:30:51.751935  4990 solver.cpp:342] Iteration 90800, Testing net (#0)
I0615 08:31:57.000566  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.803437
I0615 08:31:57.000607  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.1767 (* 1 = 1.1767 loss)
I0615 08:31:59.543978  4990 solver.cpp:233] Iteration 90800, loss = 0.0416622
I0615 08:31:59.544016  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0416624 (* 1 = 0.0416624 loss)
I0615 08:31:59.544024  4990 sgd_solver.cpp:294] Iteration 90800, lr = 0.02
I0615 08:49:15.980180  4990 solver.cpp:342] Iteration 91200, Testing net (#0)
I0615 08:50:21.816579  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.878516
I0615 08:50:21.816634  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.580767 (* 1 = 0.580767 loss)
I0615 08:50:24.370035  4990 solver.cpp:233] Iteration 91200, loss = 0.0185435
I0615 08:50:24.370085  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0185437 (* 1 = 0.0185437 loss)
I0615 08:50:24.370093  4990 sgd_solver.cpp:294] Iteration 91200, lr = 0.02
I0615 09:07:41.236832  4990 solver.cpp:342] Iteration 91600, Testing net (#0)
I0615 09:08:46.688907  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.820703
I0615 09:08:46.688951  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.00819 (* 1 = 1.00819 loss)
I0615 09:08:49.242357  4990 solver.cpp:233] Iteration 91600, loss = 0.0318201
I0615 09:08:49.242486  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0318203 (* 1 = 0.0318203 loss)
I0615 09:08:49.242544  4990 sgd_solver.cpp:294] Iteration 91600, lr = 0.02
I0615 09:26:06.057194  4990 solver.cpp:342] Iteration 92000, Testing net (#0)
I0615 09:27:11.618363  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.859219
I0615 09:27:11.618408  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.660591 (* 1 = 0.660591 loss)
I0615 09:27:14.204126  4990 solver.cpp:233] Iteration 92000, loss = 0.0225437
I0615 09:27:14.204176  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.022544 (* 1 = 0.022544 loss)
I0615 09:27:14.204186  4990 sgd_solver.cpp:294] Iteration 92000, lr = 0.02
I0615 09:44:31.059861  4990 solver.cpp:342] Iteration 92400, Testing net (#0)
I0615 09:45:36.080654  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.879062
I0615 09:45:36.080698  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.553726 (* 1 = 0.553726 loss)
I0615 09:45:38.622963  4990 solver.cpp:233] Iteration 92400, loss = 0.0756201
I0615 09:45:38.622999  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0756204 (* 1 = 0.0756204 loss)
I0615 09:45:38.623008  4990 sgd_solver.cpp:294] Iteration 92400, lr = 0.02
I0615 10:02:55.150897  4990 solver.cpp:342] Iteration 92800, Testing net (#0)
I0615 10:04:00.447299  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.868672
I0615 10:04:00.447340  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.642689 (* 1 = 0.642689 loss)
I0615 10:04:02.990371  4990 solver.cpp:233] Iteration 92800, loss = 0.0252769
I0615 10:04:02.990414  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0252772 (* 1 = 0.0252772 loss)
I0615 10:04:02.990424  4990 sgd_solver.cpp:294] Iteration 92800, lr = 0.02
I0615 10:21:20.675182  4990 solver.cpp:342] Iteration 93200, Testing net (#0)
I0615 10:22:26.093689  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.853203
I0615 10:22:26.093731  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.792672 (* 1 = 0.792672 loss)
I0615 10:22:28.648020  4990 solver.cpp:233] Iteration 93200, loss = 0.0280277
I0615 10:22:28.648056  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0280279 (* 1 = 0.0280279 loss)
I0615 10:22:28.648066  4990 sgd_solver.cpp:294] Iteration 93200, lr = 0.02
I0615 10:39:44.941983  4990 solver.cpp:342] Iteration 93600, Testing net (#0)
I0615 10:40:50.372606  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.849844
I0615 10:40:50.372644  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.773563 (* 1 = 0.773563 loss)
I0615 10:40:52.921188  4990 solver.cpp:233] Iteration 93600, loss = 0.0373022
I0615 10:40:52.921227  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0373024 (* 1 = 0.0373024 loss)
I0615 10:40:52.921234  4990 sgd_solver.cpp:294] Iteration 93600, lr = 0.02
I0615 10:58:09.707118  4990 solver.cpp:342] Iteration 94000, Testing net (#0)
I0615 10:59:14.789779  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.877891
I0615 10:59:14.789834  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.593045 (* 1 = 0.593045 loss)
I0615 10:59:17.317716  4990 solver.cpp:233] Iteration 94000, loss = 0.0385766
I0615 10:59:17.317761  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0385769 (* 1 = 0.0385769 loss)
I0615 10:59:17.317770  4990 sgd_solver.cpp:294] Iteration 94000, lr = 0.02
I0615 11:16:34.826913  4990 solver.cpp:342] Iteration 94400, Testing net (#0)
I0615 11:17:40.003079  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.883438
I0615 11:17:40.003123  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.565725 (* 1 = 0.565725 loss)
I0615 11:17:42.533804  4990 solver.cpp:233] Iteration 94400, loss = 0.0383932
I0615 11:17:42.533844  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0383934 (* 1 = 0.0383934 loss)
I0615 11:17:42.533852  4990 sgd_solver.cpp:294] Iteration 94400, lr = 0.02
I0615 11:34:59.727782  4990 solver.cpp:342] Iteration 94800, Testing net (#0)
I0615 11:36:05.180493  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.838125
I0615 11:36:05.180541  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.872374 (* 1 = 0.872374 loss)
I0615 11:36:07.773267  4990 solver.cpp:233] Iteration 94800, loss = 0.0665974
I0615 11:36:07.773311  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0665977 (* 1 = 0.0665977 loss)
I0615 11:36:07.773321  4990 sgd_solver.cpp:294] Iteration 94800, lr = 0.02
I0615 11:53:22.969379  4990 solver.cpp:342] Iteration 95200, Testing net (#0)
I0615 11:54:28.212720  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.866406
I0615 11:54:28.212776  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.597815 (* 1 = 0.597815 loss)
I0615 11:54:30.760280  4990 solver.cpp:233] Iteration 95200, loss = 0.0140441
I0615 11:54:30.760321  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0140444 (* 1 = 0.0140444 loss)
I0615 11:54:30.760329  4990 sgd_solver.cpp:294] Iteration 95200, lr = 0.02
I0615 12:11:47.464591  4990 solver.cpp:342] Iteration 95600, Testing net (#0)
I0615 12:12:53.003945  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.840937
I0615 12:12:53.003989  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.817996 (* 1 = 0.817996 loss)
I0615 12:12:55.534358  4990 solver.cpp:233] Iteration 95600, loss = 0.0823226
I0615 12:12:55.534402  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0823229 (* 1 = 0.0823229 loss)
I0615 12:12:55.534411  4990 sgd_solver.cpp:294] Iteration 95600, lr = 0.02
I0615 12:30:12.689746  4990 solver.cpp:342] Iteration 96000, Testing net (#0)
I0615 12:31:18.012154  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.796094
I0615 12:31:18.012200  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 1.12962 (* 1 = 1.12962 loss)
I0615 12:31:20.556839  4990 solver.cpp:233] Iteration 96000, loss = 0.0197635
I0615 12:31:20.556876  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0197638 (* 1 = 0.0197638 loss)
I0615 12:31:20.556885  4990 sgd_solver.cpp:294] Iteration 96000, lr = 0.02
I0615 12:48:36.292846  4990 solver.cpp:342] Iteration 96400, Testing net (#0)
I0615 12:49:41.521524  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.864219
I0615 12:49:41.521564  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.649528 (* 1 = 0.649528 loss)
I0615 12:49:44.117811  4990 solver.cpp:233] Iteration 96400, loss = 0.0119036
I0615 12:49:44.117864  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0119039 (* 1 = 0.0119039 loss)
I0615 12:49:44.117872  4990 sgd_solver.cpp:294] Iteration 96400, lr = 0.02
I0615 13:06:59.391775  4990 solver.cpp:342] Iteration 96800, Testing net (#0)
I0615 13:08:04.332144  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.820156
I0615 13:08:04.332188  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.973917 (* 1 = 0.973917 loss)
I0615 13:08:06.857271  4990 solver.cpp:233] Iteration 96800, loss = 0.0213538
I0615 13:08:06.857316  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0213541 (* 1 = 0.0213541 loss)
I0615 13:08:06.857336  4990 sgd_solver.cpp:294] Iteration 96800, lr = 0.02
I0615 13:25:21.693219  4990 solver.cpp:342] Iteration 97200, Testing net (#0)
I0615 13:26:26.854753  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.865469
I0615 13:26:26.854794  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.640413 (* 1 = 0.640413 loss)
I0615 13:26:29.449898  4990 solver.cpp:233] Iteration 97200, loss = 0.0141569
I0615 13:26:29.449934  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0141572 (* 1 = 0.0141572 loss)
I0615 13:26:29.449941  4990 sgd_solver.cpp:294] Iteration 97200, lr = 0.02
I0615 13:43:45.166237  4990 solver.cpp:342] Iteration 97600, Testing net (#0)
I0615 13:44:50.342721  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.879531
I0615 13:44:50.342763  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.593145 (* 1 = 0.593145 loss)
I0615 13:44:52.916257  4990 solver.cpp:233] Iteration 97600, loss = 0.0784027
I0615 13:44:52.916296  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.078403 (* 1 = 0.078403 loss)
I0615 13:44:52.916303  4990 sgd_solver.cpp:294] Iteration 97600, lr = 0.02
I0615 14:02:08.542708  4990 solver.cpp:342] Iteration 98000, Testing net (#0)
I0615 14:03:13.905555  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.87375
I0615 14:03:13.905594  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.645605 (* 1 = 0.645605 loss)
I0615 14:03:16.441397  4990 solver.cpp:233] Iteration 98000, loss = 0.00534566
I0615 14:03:16.441434  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.005346 (* 1 = 0.005346 loss)
I0615 14:03:16.441442  4990 sgd_solver.cpp:294] Iteration 98000, lr = 0.02
I0615 14:20:33.636773  4990 solver.cpp:342] Iteration 98400, Testing net (#0)
I0615 14:21:38.765262  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.864844
I0615 14:21:38.765298  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.589456 (* 1 = 0.589456 loss)
I0615 14:21:41.291234  4990 solver.cpp:233] Iteration 98400, loss = 0.101032
I0615 14:21:41.291265  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.101032 (* 1 = 0.101032 loss)
I0615 14:21:41.291272  4990 sgd_solver.cpp:294] Iteration 98400, lr = 0.02
I0615 14:38:58.053661  4990 solver.cpp:342] Iteration 98800, Testing net (#0)
I0615 14:40:03.049758  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.867813
I0615 14:40:03.049801  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.671052 (* 1 = 0.671052 loss)
I0615 14:40:05.580199  4990 solver.cpp:233] Iteration 98800, loss = 0.0444005
I0615 14:40:05.580235  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0444008 (* 1 = 0.0444008 loss)
I0615 14:40:05.580242  4990 sgd_solver.cpp:294] Iteration 98800, lr = 0.02
I0615 14:57:20.617858  4990 solver.cpp:342] Iteration 99200, Testing net (#0)
I0615 14:58:25.875844  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.868438
I0615 14:58:25.875890  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.581523 (* 1 = 0.581523 loss)
I0615 14:58:28.408504  4990 solver.cpp:233] Iteration 99200, loss = 0.0659606
I0615 14:58:28.408550  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.065961 (* 1 = 0.065961 loss)
I0615 14:58:28.408558  4990 sgd_solver.cpp:294] Iteration 99200, lr = 0.02
I0615 15:15:37.173257  4990 solver.cpp:342] Iteration 99600, Testing net (#0)
I0615 15:16:42.024258  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.864922
I0615 15:16:42.024302  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.690752 (* 1 = 0.690752 loss)
I0615 15:16:44.561085  4990 solver.cpp:233] Iteration 99600, loss = 0.0320174
I0615 15:16:44.561121  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0320177 (* 1 = 0.0320177 loss)
I0615 15:16:44.561127  4990 sgd_solver.cpp:294] Iteration 99600, lr = 0.02
I0615 15:33:53.205116  4990 solver.cpp:342] Iteration 100000, Testing net (#0)
I0615 15:34:57.929791  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.865937
I0615 15:34:57.929836  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.609974 (* 1 = 0.609974 loss)
I0615 15:35:00.458994  4990 solver.cpp:233] Iteration 100000, loss = 0.0307538
I0615 15:35:00.459031  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0307541 (* 1 = 0.0307541 loss)
I0615 15:35:00.459038  4990 sgd_solver.cpp:234] MultiStep Status: Iteration 100000, step = 1
I0615 15:35:00.459041  4990 sgd_solver.cpp:294] Iteration 100000, lr = 0.002
I0615 15:52:08.965824  4990 solver.cpp:342] Iteration 100400, Testing net (#0)
I0615 15:53:13.795297  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.911094
I0615 15:53:13.795343  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.383903 (* 1 = 0.383903 loss)
I0615 15:53:16.330298  4990 solver.cpp:233] Iteration 100400, loss = 0.00319496
I0615 15:53:16.330333  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00319529 (* 1 = 0.00319529 loss)
I0615 15:53:16.330341  4990 sgd_solver.cpp:294] Iteration 100400, lr = 0.002
I0615 16:10:24.360433  4990 solver.cpp:342] Iteration 100800, Testing net (#0)
I0615 16:11:29.165161  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.919844
I0615 16:11:29.165202  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.350961 (* 1 = 0.350961 loss)
I0615 16:11:31.690764  4990 solver.cpp:233] Iteration 100800, loss = 0.00602875
I0615 16:11:31.690804  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00602907 (* 1 = 0.00602907 loss)
I0615 16:11:31.690811  4990 sgd_solver.cpp:294] Iteration 100800, lr = 0.002
I0615 16:28:39.780269  4990 solver.cpp:342] Iteration 101200, Testing net (#0)
I0615 16:29:44.636661  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.923516
I0615 16:29:44.636701  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.334084 (* 1 = 0.334084 loss)
I0615 16:29:47.162606  4990 solver.cpp:233] Iteration 101200, loss = 0.000861368
I0615 16:29:47.162643  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000861692 (* 1 = 0.000861692 loss)
I0615 16:29:47.162652  4990 sgd_solver.cpp:294] Iteration 101200, lr = 0.002
I0615 16:46:54.591187  4990 solver.cpp:342] Iteration 101600, Testing net (#0)
I0615 16:47:59.438168  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.922813
I0615 16:47:59.438212  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.352437 (* 1 = 0.352437 loss)
I0615 16:48:01.975056  4990 solver.cpp:233] Iteration 101600, loss = 0.0141253
I0615 16:48:01.975091  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0141256 (* 1 = 0.0141256 loss)
I0615 16:48:01.975098  4990 sgd_solver.cpp:294] Iteration 101600, lr = 0.002
I0615 17:05:09.930644  4990 solver.cpp:342] Iteration 102000, Testing net (#0)
I0615 17:06:14.646819  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.922344
I0615 17:06:14.646863  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.351938 (* 1 = 0.351938 loss)
I0615 17:06:17.183598  4990 solver.cpp:233] Iteration 102000, loss = 0.00644949
I0615 17:06:17.183632  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00644982 (* 1 = 0.00644982 loss)
I0615 17:06:17.183640  4990 sgd_solver.cpp:294] Iteration 102000, lr = 0.002
I0615 17:23:25.572991  4990 solver.cpp:342] Iteration 102400, Testing net (#0)
I0615 17:24:30.274765  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.923594
I0615 17:24:30.274807  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.348029 (* 1 = 0.348029 loss)
I0615 17:24:32.799067  4990 solver.cpp:233] Iteration 102400, loss = 0.00152882
I0615 17:24:32.799104  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00152915 (* 1 = 0.00152915 loss)
I0615 17:24:32.799111  4990 sgd_solver.cpp:294] Iteration 102400, lr = 0.002
I0615 17:41:40.227138  4990 solver.cpp:342] Iteration 102800, Testing net (#0)
I0615 17:42:44.940848  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.923281
I0615 17:42:44.940899  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.341945 (* 1 = 0.341945 loss)
I0615 17:42:47.467583  4990 solver.cpp:233] Iteration 102800, loss = 0.00209015
I0615 17:42:47.467622  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00209048 (* 1 = 0.00209048 loss)
I0615 17:42:47.467628  4990 sgd_solver.cpp:294] Iteration 102800, lr = 0.002
I0615 17:59:55.678555  4990 solver.cpp:342] Iteration 103200, Testing net (#0)
I0615 18:01:00.504746  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.924219
I0615 18:01:00.504791  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.36146 (* 1 = 0.36146 loss)
I0615 18:01:03.043416  4990 solver.cpp:233] Iteration 103200, loss = 0.00162129
I0615 18:01:03.043458  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00162161 (* 1 = 0.00162161 loss)
I0615 18:01:03.043467  4990 sgd_solver.cpp:294] Iteration 103200, lr = 0.002
I0615 18:18:12.084666  4990 solver.cpp:342] Iteration 103600, Testing net (#0)
I0615 18:19:16.943431  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.924766
I0615 18:19:16.943475  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.353717 (* 1 = 0.353717 loss)
I0615 18:19:19.480032  4990 solver.cpp:233] Iteration 103600, loss = 0.00241014
I0615 18:19:19.480069  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00241046 (* 1 = 0.00241046 loss)
I0615 18:19:19.480077  4990 sgd_solver.cpp:294] Iteration 103600, lr = 0.002
I0615 18:36:27.216424  4990 solver.cpp:342] Iteration 104000, Testing net (#0)
I0615 18:37:32.012871  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.924531
I0615 18:37:32.012912  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.355922 (* 1 = 0.355922 loss)
I0615 18:37:34.546411  4990 solver.cpp:233] Iteration 104000, loss = 0.00101987
I0615 18:37:34.546447  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0010202 (* 1 = 0.0010202 loss)
I0615 18:37:34.546453  4990 sgd_solver.cpp:294] Iteration 104000, lr = 0.002
I0615 18:54:42.358165  4990 solver.cpp:342] Iteration 104400, Testing net (#0)
I0615 18:55:47.103888  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.926719
I0615 18:55:47.103930  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.361711 (* 1 = 0.361711 loss)
I0615 18:55:49.635551  4990 solver.cpp:233] Iteration 104400, loss = 0.00668027
I0615 18:55:49.635594  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00668059 (* 1 = 0.00668059 loss)
I0615 18:55:49.635602  4990 sgd_solver.cpp:294] Iteration 104400, lr = 0.002
I0615 19:12:57.266057  4990 solver.cpp:342] Iteration 104800, Testing net (#0)
I0615 19:14:02.090781  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.925781
I0615 19:14:02.090821  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.362623 (* 1 = 0.362623 loss)
I0615 19:14:04.626603  4990 solver.cpp:233] Iteration 104800, loss = 0.000911646
I0615 19:14:04.626642  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00091197 (* 1 = 0.00091197 loss)
I0615 19:14:04.626651  4990 sgd_solver.cpp:294] Iteration 104800, lr = 0.002
I0615 19:31:12.235118  4990 solver.cpp:342] Iteration 105200, Testing net (#0)
I0615 19:32:17.079354  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.926797
I0615 19:32:17.079396  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.36199 (* 1 = 0.36199 loss)
I0615 19:32:19.605113  4990 solver.cpp:233] Iteration 105200, loss = 0.00181542
I0615 19:32:19.605150  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00181574 (* 1 = 0.00181574 loss)
I0615 19:32:19.605157  4990 sgd_solver.cpp:294] Iteration 105200, lr = 0.002
I0615 19:49:27.643873  4990 solver.cpp:342] Iteration 105600, Testing net (#0)
I0615 19:50:32.472779  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.926406
I0615 19:50:32.472821  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.358595 (* 1 = 0.358595 loss)
I0615 19:50:35.010545  4990 solver.cpp:233] Iteration 105600, loss = 0.00378811
I0615 19:50:35.010582  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00378844 (* 1 = 0.00378844 loss)
I0615 19:50:35.010591  4990 sgd_solver.cpp:294] Iteration 105600, lr = 0.002
I0615 20:07:43.044489  4990 solver.cpp:342] Iteration 106000, Testing net (#0)
I0615 20:08:47.905637  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927031
I0615 20:08:47.905676  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.374253 (* 1 = 0.374253 loss)
I0615 20:08:50.444674  4990 solver.cpp:233] Iteration 106000, loss = 0.00538158
I0615 20:08:50.444710  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00538191 (* 1 = 0.00538191 loss)
I0615 20:08:50.444717  4990 sgd_solver.cpp:294] Iteration 106000, lr = 0.002
I0615 20:25:58.705358  4990 solver.cpp:342] Iteration 106400, Testing net (#0)
I0615 20:27:03.599555  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.926719
I0615 20:27:03.599611  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.34944 (* 1 = 0.34944 loss)
I0615 20:27:06.142140  4990 solver.cpp:233] Iteration 106400, loss = 0.00178138
I0615 20:27:06.142184  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0017817 (* 1 = 0.0017817 loss)
I0615 20:27:06.142192  4990 sgd_solver.cpp:294] Iteration 106400, lr = 0.002
I0615 20:44:14.361608  4990 solver.cpp:342] Iteration 106800, Testing net (#0)
I0615 20:45:19.094794  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929531
I0615 20:45:19.094840  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.345826 (* 1 = 0.345826 loss)
I0615 20:45:21.622023  4990 solver.cpp:233] Iteration 106800, loss = 0.0123056
I0615 20:45:21.622061  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0123059 (* 1 = 0.0123059 loss)
I0615 20:45:21.622067  4990 sgd_solver.cpp:294] Iteration 106800, lr = 0.002
I0615 21:02:29.476590  4990 solver.cpp:342] Iteration 107200, Testing net (#0)
I0615 21:03:34.184841  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.926094
I0615 21:03:34.184888  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.366982 (* 1 = 0.366982 loss)
I0615 21:03:36.716886  4990 solver.cpp:233] Iteration 107200, loss = 0.000804265
I0615 21:03:36.716928  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000804588 (* 1 = 0.000804588 loss)
I0615 21:03:36.716935  4990 sgd_solver.cpp:294] Iteration 107200, lr = 0.002
I0615 21:20:43.812484  4990 solver.cpp:342] Iteration 107600, Testing net (#0)
I0615 21:21:48.623759  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.926172
I0615 21:21:48.623803  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.362934 (* 1 = 0.362934 loss)
I0615 21:21:51.159026  4990 solver.cpp:233] Iteration 107600, loss = 0.00194046
I0615 21:21:51.159065  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00194078 (* 1 = 0.00194078 loss)
I0615 21:21:51.159072  4990 sgd_solver.cpp:294] Iteration 107600, lr = 0.002
I0615 21:38:58.910114  4990 solver.cpp:342] Iteration 108000, Testing net (#0)
I0615 21:40:03.861225  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.924766
I0615 21:40:03.861268  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.36303 (* 1 = 0.36303 loss)
I0615 21:40:06.394980  4990 solver.cpp:233] Iteration 108000, loss = 0.00074407
I0615 21:40:06.395020  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000744391 (* 1 = 0.000744391 loss)
I0615 21:40:06.395027  4990 sgd_solver.cpp:294] Iteration 108000, lr = 0.002
I0615 21:57:14.622948  4990 solver.cpp:342] Iteration 108400, Testing net (#0)
I0615 21:58:19.323348  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927813
I0615 21:58:19.323390  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.351771 (* 1 = 0.351771 loss)
I0615 21:58:21.848673  4990 solver.cpp:233] Iteration 108400, loss = 0.00218821
I0615 21:58:21.848709  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00218853 (* 1 = 0.00218853 loss)
I0615 21:58:21.848722  4990 sgd_solver.cpp:294] Iteration 108400, lr = 0.002
I0615 22:15:29.581382  4990 solver.cpp:342] Iteration 108800, Testing net (#0)
I0615 22:16:34.429436  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928359
I0615 22:16:34.429478  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.378967 (* 1 = 0.378967 loss)
I0615 22:16:36.966379  4990 solver.cpp:233] Iteration 108800, loss = 0.000340531
I0615 22:16:36.966416  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000340852 (* 1 = 0.000340852 loss)
I0615 22:16:36.966426  4990 sgd_solver.cpp:294] Iteration 108800, lr = 0.002
I0615 22:33:44.989253  4990 solver.cpp:342] Iteration 109200, Testing net (#0)
I0615 22:34:49.853952  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.924688
I0615 22:34:49.853991  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.378694 (* 1 = 0.378694 loss)
I0615 22:34:52.388556  4990 solver.cpp:233] Iteration 109200, loss = 0.000552827
I0615 22:34:52.388592  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000553151 (* 1 = 0.000553151 loss)
I0615 22:34:52.388598  4990 sgd_solver.cpp:294] Iteration 109200, lr = 0.002
I0615 22:52:00.105985  4990 solver.cpp:342] Iteration 109600, Testing net (#0)
I0615 22:53:04.997105  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928984
I0615 22:53:04.997148  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.36034 (* 1 = 0.36034 loss)
I0615 22:53:07.534869  4990 solver.cpp:233] Iteration 109600, loss = 0.000220808
I0615 22:53:07.534919  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000221131 (* 1 = 0.000221131 loss)
I0615 22:53:07.534926  4990 sgd_solver.cpp:294] Iteration 109600, lr = 0.002
I0615 23:10:15.533253  4990 solver.cpp:342] Iteration 110000, Testing net (#0)
I0615 23:11:20.382232  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.926797
I0615 23:11:20.382278  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.371405 (* 1 = 0.371405 loss)
I0615 23:11:22.911566  4990 solver.cpp:233] Iteration 110000, loss = 0.000770366
I0615 23:11:22.911608  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000770689 (* 1 = 0.000770689 loss)
I0615 23:11:22.911615  4990 sgd_solver.cpp:294] Iteration 110000, lr = 0.002
I0615 23:28:31.140553  4990 solver.cpp:342] Iteration 110400, Testing net (#0)
I0615 23:29:36.015739  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928125
I0615 23:29:36.015785  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.37177 (* 1 = 0.37177 loss)
I0615 23:29:38.551846  4990 solver.cpp:233] Iteration 110400, loss = 0.00121061
I0615 23:29:38.551883  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00121093 (* 1 = 0.00121093 loss)
I0615 23:29:38.551890  4990 sgd_solver.cpp:294] Iteration 110400, lr = 0.002
I0615 23:46:46.347335  4990 solver.cpp:342] Iteration 110800, Testing net (#0)
I0615 23:47:51.250593  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.9275
I0615 23:47:51.250636  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.372189 (* 1 = 0.372189 loss)
I0615 23:47:53.784790  4990 solver.cpp:233] Iteration 110800, loss = 0.000232985
I0615 23:47:53.784839  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000233309 (* 1 = 0.000233309 loss)
I0615 23:47:53.784848  4990 sgd_solver.cpp:294] Iteration 110800, lr = 0.002
I0616 00:05:08.409221  4990 solver.cpp:342] Iteration 111200, Testing net (#0)
I0616 00:06:13.301390  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.92875
I0616 00:06:13.301435  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.366911 (* 1 = 0.366911 loss)
I0616 00:06:15.837611  4990 solver.cpp:233] Iteration 111200, loss = 0.000920434
I0616 00:06:15.837649  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000920757 (* 1 = 0.000920757 loss)
I0616 00:06:15.837657  4990 sgd_solver.cpp:294] Iteration 111200, lr = 0.002
I0616 00:23:26.348824  4990 solver.cpp:342] Iteration 111600, Testing net (#0)
I0616 00:24:31.869777  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928203
I0616 00:24:31.869819  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.368366 (* 1 = 0.368366 loss)
I0616 00:24:34.426300  4990 solver.cpp:233] Iteration 111600, loss = 0.000741751
I0616 00:24:34.426342  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000742073 (* 1 = 0.000742073 loss)
I0616 00:24:34.426349  4990 sgd_solver.cpp:294] Iteration 111600, lr = 0.002
I0616 00:41:50.483708  4990 solver.cpp:342] Iteration 112000, Testing net (#0)
I0616 00:42:55.654484  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927969
I0616 00:42:55.654531  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.368263 (* 1 = 0.368263 loss)
I0616 00:42:58.227471  4990 solver.cpp:233] Iteration 112000, loss = 0.000504558
I0616 00:42:58.227515  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00050488 (* 1 = 0.00050488 loss)
I0616 00:42:58.227524  4990 sgd_solver.cpp:294] Iteration 112000, lr = 0.002
I0616 01:00:14.258929  4990 solver.cpp:342] Iteration 112400, Testing net (#0)
I0616 01:01:19.365672  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928125
I0616 01:01:19.365716  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.369981 (* 1 = 0.369981 loss)
I0616 01:01:21.919575  4990 solver.cpp:233] Iteration 112400, loss = 0.000539979
I0616 01:01:21.919610  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000540302 (* 1 = 0.000540302 loss)
I0616 01:01:21.919617  4990 sgd_solver.cpp:294] Iteration 112400, lr = 0.002
I0616 01:18:40.242316  4990 solver.cpp:342] Iteration 112800, Testing net (#0)
I0616 01:19:45.428174  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.926094
I0616 01:19:45.428220  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.371499 (* 1 = 0.371499 loss)
I0616 01:19:48.028301  4990 solver.cpp:233] Iteration 112800, loss = 0.000829879
I0616 01:19:48.028352  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000830202 (* 1 = 0.000830202 loss)
I0616 01:19:48.028362  4990 sgd_solver.cpp:294] Iteration 112800, lr = 0.002
I0616 01:37:03.919064  4990 solver.cpp:342] Iteration 113200, Testing net (#0)
I0616 01:38:09.156688  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927344
I0616 01:38:09.156726  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.379741 (* 1 = 0.379741 loss)
I0616 01:38:11.748910  4990 solver.cpp:233] Iteration 113200, loss = 0.000266535
I0616 01:38:11.748952  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000266856 (* 1 = 0.000266856 loss)
I0616 01:38:11.748960  4990 sgd_solver.cpp:294] Iteration 113200, lr = 0.002
I0616 01:55:27.970582  4990 solver.cpp:342] Iteration 113600, Testing net (#0)
I0616 01:56:33.202548  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.926328
I0616 01:56:33.202589  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.375046 (* 1 = 0.375046 loss)
I0616 01:56:35.758244  4990 solver.cpp:233] Iteration 113600, loss = 0.00127149
I0616 01:56:35.758282  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00127181 (* 1 = 0.00127181 loss)
I0616 01:56:35.758291  4990 sgd_solver.cpp:294] Iteration 113600, lr = 0.002
I0616 02:13:53.043936  4990 solver.cpp:342] Iteration 114000, Testing net (#0)
I0616 02:14:58.202821  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927109
I0616 02:14:58.202860  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.365102 (* 1 = 0.365102 loss)
I0616 02:15:00.746589  4990 solver.cpp:233] Iteration 114000, loss = 0.000226749
I0616 02:15:00.746629  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00022707 (* 1 = 0.00022707 loss)
I0616 02:15:00.746636  4990 sgd_solver.cpp:294] Iteration 114000, lr = 0.002
I0616 02:32:15.772045  4990 solver.cpp:342] Iteration 114400, Testing net (#0)
I0616 02:33:20.937724  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.925937
I0616 02:33:20.937775  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.382124 (* 1 = 0.382124 loss)
I0616 02:33:23.505954  4990 solver.cpp:233] Iteration 114400, loss = 0.000484009
I0616 02:33:23.505993  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000484329 (* 1 = 0.000484329 loss)
I0616 02:33:23.506003  4990 sgd_solver.cpp:294] Iteration 114400, lr = 0.002
I0616 02:50:38.633110  4990 solver.cpp:342] Iteration 114800, Testing net (#0)
I0616 02:51:44.154435  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.924688
I0616 02:51:44.154481  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.386277 (* 1 = 0.386277 loss)
I0616 02:51:46.756363  4990 solver.cpp:233] Iteration 114800, loss = 0.000635802
I0616 02:51:46.756415  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000636121 (* 1 = 0.000636121 loss)
I0616 02:51:46.756433  4990 sgd_solver.cpp:294] Iteration 114800, lr = 0.002
I0616 03:09:01.464493  4990 solver.cpp:342] Iteration 115200, Testing net (#0)
I0616 03:10:06.813627  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928125
I0616 03:10:06.813669  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.372671 (* 1 = 0.372671 loss)
I0616 03:10:09.347748  4990 solver.cpp:233] Iteration 115200, loss = 0.00102405
I0616 03:10:09.347779  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00102437 (* 1 = 0.00102437 loss)
I0616 03:10:09.347785  4990 sgd_solver.cpp:294] Iteration 115200, lr = 0.002
I0616 03:27:23.488430  4990 solver.cpp:342] Iteration 115600, Testing net (#0)
I0616 03:28:28.730973  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.92625
I0616 03:28:28.731014  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.378584 (* 1 = 0.378584 loss)
I0616 03:28:31.324796  4990 solver.cpp:233] Iteration 115600, loss = 0.00038269
I0616 03:28:31.324847  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000383007 (* 1 = 0.000383007 loss)
I0616 03:28:31.324856  4990 sgd_solver.cpp:294] Iteration 115600, lr = 0.002
I0616 03:45:45.945595  4990 solver.cpp:342] Iteration 116000, Testing net (#0)
I0616 03:46:51.350347  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.926172
I0616 03:46:51.350399  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.389802 (* 1 = 0.389802 loss)
I0616 03:46:53.889367  4990 solver.cpp:233] Iteration 116000, loss = 0.000483615
I0616 03:46:53.889420  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00048393 (* 1 = 0.00048393 loss)
I0616 03:46:53.889432  4990 sgd_solver.cpp:294] Iteration 116000, lr = 0.002
I0616 04:04:08.169489  4990 solver.cpp:342] Iteration 116400, Testing net (#0)
I0616 04:05:13.338752  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.926797
I0616 04:05:13.338796  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.365555 (* 1 = 0.365555 loss)
I0616 04:05:15.918004  4990 solver.cpp:233] Iteration 116400, loss = 0.000215084
I0616 04:05:15.918053  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000215399 (* 1 = 0.000215399 loss)
I0616 04:05:15.918063  4990 sgd_solver.cpp:294] Iteration 116400, lr = 0.002
I0616 04:22:31.162261  4990 solver.cpp:342] Iteration 116800, Testing net (#0)
I0616 04:23:36.801190  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929922
I0616 04:23:36.801235  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.362706 (* 1 = 0.362706 loss)
I0616 04:23:39.338845  4990 solver.cpp:233] Iteration 116800, loss = 0.000608658
I0616 04:23:39.338894  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000608977 (* 1 = 0.000608977 loss)
I0616 04:23:39.338904  4990 sgd_solver.cpp:294] Iteration 116800, lr = 0.002
I0616 04:40:54.752967  4990 solver.cpp:342] Iteration 117200, Testing net (#0)
I0616 04:42:00.011500  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.926953
I0616 04:42:00.011555  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.382928 (* 1 = 0.382928 loss)
I0616 04:42:02.547596  4990 solver.cpp:233] Iteration 117200, loss = 0.000156462
I0616 04:42:02.547644  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000156781 (* 1 = 0.000156781 loss)
I0616 04:42:02.547653  4990 sgd_solver.cpp:294] Iteration 117200, lr = 0.002
I0616 04:59:18.190186  4990 solver.cpp:342] Iteration 117600, Testing net (#0)
I0616 05:00:23.408992  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.926797
I0616 05:00:23.409049  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.385771 (* 1 = 0.385771 loss)
I0616 05:00:25.953662  4990 solver.cpp:233] Iteration 117600, loss = 0.000396248
I0616 05:00:25.953701  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000396567 (* 1 = 0.000396567 loss)
I0616 05:00:25.953709  4990 sgd_solver.cpp:294] Iteration 117600, lr = 0.002
I0616 05:17:40.799121  4990 solver.cpp:342] Iteration 118000, Testing net (#0)
I0616 05:18:46.381690  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928672
I0616 05:18:46.381733  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.372448 (* 1 = 0.372448 loss)
I0616 05:18:48.908335  4990 solver.cpp:233] Iteration 118000, loss = 0.00045987
I0616 05:18:48.908370  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000460189 (* 1 = 0.000460189 loss)
I0616 05:18:48.908377  4990 sgd_solver.cpp:294] Iteration 118000, lr = 0.002
I0616 05:36:03.601768  4990 solver.cpp:342] Iteration 118400, Testing net (#0)
I0616 05:37:09.150879  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.9275
I0616 05:37:09.150943  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.368142 (* 1 = 0.368142 loss)
I0616 05:37:11.696148  4990 solver.cpp:233] Iteration 118400, loss = 0.000576122
I0616 05:37:11.696183  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000576442 (* 1 = 0.000576442 loss)
I0616 05:37:11.696192  4990 sgd_solver.cpp:294] Iteration 118400, lr = 0.002
I0616 05:54:26.769217  4990 solver.cpp:342] Iteration 118800, Testing net (#0)
I0616 05:55:31.948402  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928125
I0616 05:55:31.948451  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.386476 (* 1 = 0.386476 loss)
I0616 05:55:34.481187  4990 solver.cpp:233] Iteration 118800, loss = 0.00041986
I0616 05:55:34.481220  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000420179 (* 1 = 0.000420179 loss)
I0616 05:55:34.481227  4990 sgd_solver.cpp:294] Iteration 118800, lr = 0.002
I0616 06:12:49.040379  4990 solver.cpp:342] Iteration 119200, Testing net (#0)
I0616 06:13:54.776868  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.926094
I0616 06:13:54.776916  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.379167 (* 1 = 0.379167 loss)
I0616 06:13:57.326297  4990 solver.cpp:233] Iteration 119200, loss = 0.000346296
I0616 06:13:57.326330  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000346614 (* 1 = 0.000346614 loss)
I0616 06:13:57.326338  4990 sgd_solver.cpp:294] Iteration 119200, lr = 0.002
I0616 06:31:12.064450  4990 solver.cpp:342] Iteration 119600, Testing net (#0)
I0616 06:32:17.214047  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928437
I0616 06:32:17.214088  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.362565 (* 1 = 0.362565 loss)
I0616 06:32:19.754544  4990 solver.cpp:233] Iteration 119600, loss = 0.000136676
I0616 06:32:19.754595  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000136993 (* 1 = 0.000136993 loss)
I0616 06:32:19.754603  4990 sgd_solver.cpp:294] Iteration 119600, lr = 0.002
I0616 06:49:34.742771  4990 solver.cpp:342] Iteration 120000, Testing net (#0)
I0616 06:50:39.724555  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928047
I0616 06:50:39.724596  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.3776 (* 1 = 0.3776 loss)
I0616 06:50:42.256629  4990 solver.cpp:233] Iteration 120000, loss = 0.00134891
I0616 06:50:42.256667  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00134922 (* 1 = 0.00134922 loss)
I0616 06:50:42.256675  4990 sgd_solver.cpp:294] Iteration 120000, lr = 0.002
I0616 07:07:56.586418  4990 solver.cpp:342] Iteration 120400, Testing net (#0)
I0616 07:09:01.468227  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927109
I0616 07:09:01.468266  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.390012 (* 1 = 0.390012 loss)
I0616 07:09:03.992683  4990 solver.cpp:233] Iteration 120400, loss = 0.000336178
I0616 07:09:03.992715  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000336494 (* 1 = 0.000336494 loss)
I0616 07:09:03.992722  4990 sgd_solver.cpp:294] Iteration 120400, lr = 0.002
I0616 07:26:18.188328  4990 solver.cpp:342] Iteration 120800, Testing net (#0)
I0616 07:27:23.350091  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928828
I0616 07:27:23.350134  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.377095 (* 1 = 0.377095 loss)
I0616 07:27:25.895728  4990 solver.cpp:233] Iteration 120800, loss = 0.00233267
I0616 07:27:25.895769  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00233299 (* 1 = 0.00233299 loss)
I0616 07:27:25.895777  4990 sgd_solver.cpp:294] Iteration 120800, lr = 0.002
I0616 07:44:40.751794  4990 solver.cpp:342] Iteration 121200, Testing net (#0)
I0616 07:45:46.293105  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927734
I0616 07:45:46.293145  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.381147 (* 1 = 0.381147 loss)
I0616 07:45:48.830950  4990 solver.cpp:233] Iteration 121200, loss = 0.000884222
I0616 07:45:48.830986  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000884537 (* 1 = 0.000884537 loss)
I0616 07:45:48.830993  4990 sgd_solver.cpp:294] Iteration 121200, lr = 0.002
I0616 08:03:04.043190  4990 solver.cpp:342] Iteration 121600, Testing net (#0)
I0616 08:04:09.214093  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929219
I0616 08:04:09.214134  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.379298 (* 1 = 0.379298 loss)
I0616 08:04:11.767424  4990 solver.cpp:233] Iteration 121600, loss = 0.000608882
I0616 08:04:11.767457  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000609199 (* 1 = 0.000609199 loss)
I0616 08:04:11.767464  4990 sgd_solver.cpp:294] Iteration 121600, lr = 0.002
I0616 08:21:27.652474  4990 solver.cpp:342] Iteration 122000, Testing net (#0)
I0616 08:22:32.877885  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.925547
I0616 08:22:32.877928  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.379837 (* 1 = 0.379837 loss)
I0616 08:22:35.439818  4990 solver.cpp:233] Iteration 122000, loss = 0.000249168
I0616 08:22:35.439857  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000249484 (* 1 = 0.000249484 loss)
I0616 08:22:35.439865  4990 sgd_solver.cpp:294] Iteration 122000, lr = 0.002
I0616 08:39:49.332973  4990 solver.cpp:342] Iteration 122400, Testing net (#0)
I0616 08:40:54.432359  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927813
I0616 08:40:54.432401  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.374882 (* 1 = 0.374882 loss)
I0616 08:40:56.990877  4990 solver.cpp:233] Iteration 122400, loss = 0.000250762
I0616 08:40:56.990926  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000251077 (* 1 = 0.000251077 loss)
I0616 08:40:56.990936  4990 sgd_solver.cpp:294] Iteration 122400, lr = 0.002
I0616 08:58:12.296726  4990 solver.cpp:342] Iteration 122800, Testing net (#0)
I0616 08:59:17.473544  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927031
I0616 08:59:17.473593  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.377273 (* 1 = 0.377273 loss)
I0616 08:59:20.000629  4990 solver.cpp:233] Iteration 122800, loss = 0.000434095
I0616 08:59:20.000661  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00043441 (* 1 = 0.00043441 loss)
I0616 08:59:20.000674  4990 sgd_solver.cpp:294] Iteration 122800, lr = 0.002
I0616 09:16:34.957157  4990 solver.cpp:342] Iteration 123200, Testing net (#0)
I0616 09:17:39.963366  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929531
I0616 09:17:39.963407  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.381336 (* 1 = 0.381336 loss)
I0616 09:17:42.507707  4990 solver.cpp:233] Iteration 123200, loss = 0.000238802
I0616 09:17:42.507750  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000239116 (* 1 = 0.000239116 loss)
I0616 09:17:42.507756  4990 sgd_solver.cpp:294] Iteration 123200, lr = 0.002
I0616 09:34:57.690726  4990 solver.cpp:342] Iteration 123600, Testing net (#0)
I0616 09:36:02.843333  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.925937
I0616 09:36:02.843374  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.381773 (* 1 = 0.381773 loss)
I0616 09:36:05.432958  4990 solver.cpp:233] Iteration 123600, loss = 0.000447629
I0616 09:36:05.432997  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000447944 (* 1 = 0.000447944 loss)
I0616 09:36:05.433004  4990 sgd_solver.cpp:294] Iteration 123600, lr = 0.002
I0616 09:53:20.242424  4990 solver.cpp:342] Iteration 124000, Testing net (#0)
I0616 09:54:25.290568  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930547
I0616 09:54:25.290609  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.36746 (* 1 = 0.36746 loss)
I0616 09:54:27.885191  4990 solver.cpp:233] Iteration 124000, loss = 0.00196828
I0616 09:54:27.885228  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0019686 (* 1 = 0.0019686 loss)
I0616 09:54:27.885236  4990 sgd_solver.cpp:294] Iteration 124000, lr = 0.002
I0616 10:11:43.576565  4990 solver.cpp:342] Iteration 124400, Testing net (#0)
I0616 10:12:48.674593  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928437
I0616 10:12:48.674643  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.390371 (* 1 = 0.390371 loss)
I0616 10:12:51.230958  4990 solver.cpp:233] Iteration 124400, loss = 0.00028437
I0616 10:12:51.230995  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000284683 (* 1 = 0.000284683 loss)
I0616 10:12:51.231003  4990 sgd_solver.cpp:294] Iteration 124400, lr = 0.002
I0616 10:30:07.151182  4990 solver.cpp:342] Iteration 124800, Testing net (#0)
I0616 10:31:12.393088  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928672
I0616 10:31:12.393129  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.390324 (* 1 = 0.390324 loss)
I0616 10:31:14.943651  4990 solver.cpp:233] Iteration 124800, loss = 0.000999464
I0616 10:31:14.943691  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000999776 (* 1 = 0.000999776 loss)
I0616 10:31:14.943697  4990 sgd_solver.cpp:294] Iteration 124800, lr = 0.002
I0616 10:48:29.797333  4990 solver.cpp:342] Iteration 125200, Testing net (#0)
I0616 10:49:34.850147  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927969
I0616 10:49:34.850190  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.379197 (* 1 = 0.379197 loss)
I0616 10:49:37.386776  4990 solver.cpp:233] Iteration 125200, loss = 0.00052415
I0616 10:49:37.386818  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000524462 (* 1 = 0.000524462 loss)
I0616 10:49:37.386827  4990 sgd_solver.cpp:294] Iteration 125200, lr = 0.002
I0616 11:06:50.994534  4990 solver.cpp:342] Iteration 125600, Testing net (#0)
I0616 11:07:56.097342  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928906
I0616 11:07:56.097388  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.376508 (* 1 = 0.376508 loss)
I0616 11:07:58.656692  4990 solver.cpp:233] Iteration 125600, loss = 0.000866787
I0616 11:07:58.656731  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000867098 (* 1 = 0.000867098 loss)
I0616 11:07:58.656739  4990 sgd_solver.cpp:294] Iteration 125600, lr = 0.002
I0616 11:25:14.085222  4990 solver.cpp:342] Iteration 126000, Testing net (#0)
I0616 11:26:19.218699  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928047
I0616 11:26:19.218740  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.399374 (* 1 = 0.399374 loss)
I0616 11:26:21.760711  4990 solver.cpp:233] Iteration 126000, loss = 0.000227455
I0616 11:26:21.760743  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000227765 (* 1 = 0.000227765 loss)
I0616 11:26:21.760751  4990 sgd_solver.cpp:294] Iteration 126000, lr = 0.002
I0616 11:43:37.673606  4990 solver.cpp:342] Iteration 126400, Testing net (#0)
I0616 11:44:42.740591  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928281
I0616 11:44:42.740634  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.380206 (* 1 = 0.380206 loss)
I0616 11:44:45.273835  4990 solver.cpp:233] Iteration 126400, loss = 0.000404505
I0616 11:44:45.273869  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000404814 (* 1 = 0.000404814 loss)
I0616 11:44:45.273875  4990 sgd_solver.cpp:294] Iteration 126400, lr = 0.002
I0616 12:02:01.169575  4990 solver.cpp:342] Iteration 126800, Testing net (#0)
I0616 12:03:06.200331  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929375
I0616 12:03:06.200377  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.365276 (* 1 = 0.365276 loss)
I0616 12:03:08.729698  4990 solver.cpp:233] Iteration 126800, loss = 0.000151391
I0616 12:03:08.729732  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0001517 (* 1 = 0.0001517 loss)
I0616 12:03:08.729738  4990 sgd_solver.cpp:294] Iteration 126800, lr = 0.002
I0616 12:20:23.605439  4990 solver.cpp:342] Iteration 127200, Testing net (#0)
I0616 12:21:29.010537  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929062
I0616 12:21:29.010588  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.383738 (* 1 = 0.383738 loss)
I0616 12:21:31.601523  4990 solver.cpp:233] Iteration 127200, loss = 0.000349787
I0616 12:21:31.601575  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000350096 (* 1 = 0.000350096 loss)
I0616 12:21:31.601585  4990 sgd_solver.cpp:294] Iteration 127200, lr = 0.002
I0616 12:38:45.886411  4990 solver.cpp:342] Iteration 127600, Testing net (#0)
I0616 12:39:51.248293  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929219
I0616 12:39:51.248343  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.382279 (* 1 = 0.382279 loss)
I0616 12:39:53.788967  4990 solver.cpp:233] Iteration 127600, loss = 0.00100837
I0616 12:39:53.789003  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00100868 (* 1 = 0.00100868 loss)
I0616 12:39:53.789011  4990 sgd_solver.cpp:294] Iteration 127600, lr = 0.002
I0616 12:57:07.471494  4990 solver.cpp:342] Iteration 128000, Testing net (#0)
I0616 12:58:12.774730  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928047
I0616 12:58:12.774775  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.38107 (* 1 = 0.38107 loss)
I0616 12:58:15.311375  4990 solver.cpp:233] Iteration 128000, loss = 0.000129944
I0616 12:58:15.311409  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000130254 (* 1 = 0.000130254 loss)
I0616 12:58:15.311416  4990 sgd_solver.cpp:294] Iteration 128000, lr = 0.002
I0616 13:15:30.085527  4990 solver.cpp:342] Iteration 128400, Testing net (#0)
I0616 13:16:35.358335  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929141
I0616 13:16:35.358382  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.380166 (* 1 = 0.380166 loss)
I0616 13:16:37.886593  4990 solver.cpp:233] Iteration 128400, loss = 0.000170195
I0616 13:16:37.886634  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000170506 (* 1 = 0.000170506 loss)
I0616 13:16:37.886643  4990 sgd_solver.cpp:294] Iteration 128400, lr = 0.002
I0616 13:33:51.284867  4990 solver.cpp:342] Iteration 128800, Testing net (#0)
I0616 13:34:56.398218  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929609
I0616 13:34:56.398260  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.387462 (* 1 = 0.387462 loss)
I0616 13:34:58.922982  4990 solver.cpp:233] Iteration 128800, loss = 0.00141692
I0616 13:34:58.923022  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00141723 (* 1 = 0.00141723 loss)
I0616 13:34:58.923030  4990 sgd_solver.cpp:294] Iteration 128800, lr = 0.002
I0616 13:52:14.282316  4990 solver.cpp:342] Iteration 129200, Testing net (#0)
I0616 13:53:19.403754  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929609
I0616 13:53:19.403797  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.377153 (* 1 = 0.377153 loss)
I0616 13:53:21.959906  4990 solver.cpp:233] Iteration 129200, loss = 0.000361199
I0616 13:53:21.959944  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00036151 (* 1 = 0.00036151 loss)
I0616 13:53:21.959951  4990 sgd_solver.cpp:294] Iteration 129200, lr = 0.002
I0616 14:10:36.527020  4990 solver.cpp:342] Iteration 129600, Testing net (#0)
I0616 14:11:41.909440  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928984
I0616 14:11:41.909483  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.370792 (* 1 = 0.370792 loss)
I0616 14:11:44.444185  4990 solver.cpp:233] Iteration 129600, loss = 0.000869303
I0616 14:11:44.444222  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000869613 (* 1 = 0.000869613 loss)
I0616 14:11:44.444231  4990 sgd_solver.cpp:294] Iteration 129600, lr = 0.002
I0616 14:28:59.332659  4990 solver.cpp:342] Iteration 130000, Testing net (#0)
I0616 14:30:04.516960  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927344
I0616 14:30:04.517000  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.381588 (* 1 = 0.381588 loss)
I0616 14:30:07.050762  4990 solver.cpp:233] Iteration 130000, loss = 0.000241784
I0616 14:30:07.050798  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000242095 (* 1 = 0.000242095 loss)
I0616 14:30:07.050806  4990 sgd_solver.cpp:294] Iteration 130000, lr = 0.002
I0616 14:47:22.763770  4990 solver.cpp:342] Iteration 130400, Testing net (#0)
I0616 14:48:27.856889  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928203
I0616 14:48:27.856932  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.378195 (* 1 = 0.378195 loss)
I0616 14:48:30.431089  4990 solver.cpp:233] Iteration 130400, loss = 0.000229298
I0616 14:48:30.431139  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000229608 (* 1 = 0.000229608 loss)
I0616 14:48:30.431148  4990 sgd_solver.cpp:294] Iteration 130400, lr = 0.002
I0616 15:05:46.241854  4990 solver.cpp:342] Iteration 130800, Testing net (#0)
I0616 15:06:51.397964  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930625
I0616 15:06:51.398008  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.376854 (* 1 = 0.376854 loss)
I0616 15:06:53.986425  4990 solver.cpp:233] Iteration 130800, loss = 0.000171817
I0616 15:06:53.986466  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000172128 (* 1 = 0.000172128 loss)
I0616 15:06:53.986474  4990 sgd_solver.cpp:294] Iteration 130800, lr = 0.002
I0616 15:24:09.919051  4990 solver.cpp:342] Iteration 131200, Testing net (#0)
I0616 15:25:15.071599  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929297
I0616 15:25:15.071642  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.371927 (* 1 = 0.371927 loss)
I0616 15:25:17.634006  4990 solver.cpp:233] Iteration 131200, loss = 0.000337652
I0616 15:25:17.634052  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000337962 (* 1 = 0.000337962 loss)
I0616 15:25:17.634059  4990 sgd_solver.cpp:294] Iteration 131200, lr = 0.002
I0616 15:42:32.805181  4990 solver.cpp:342] Iteration 131600, Testing net (#0)
I0616 15:43:37.965931  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928516
I0616 15:43:37.965975  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.387106 (* 1 = 0.387106 loss)
I0616 15:43:40.502526  4990 solver.cpp:233] Iteration 131600, loss = 0.000536733
I0616 15:43:40.502567  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000537044 (* 1 = 0.000537044 loss)
I0616 15:43:40.502574  4990 sgd_solver.cpp:294] Iteration 131600, lr = 0.002
I0616 16:00:55.581038  4990 solver.cpp:342] Iteration 132000, Testing net (#0)
I0616 16:02:00.782691  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929922
I0616 16:02:00.782734  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.373125 (* 1 = 0.373125 loss)
I0616 16:02:03.323338  4990 solver.cpp:233] Iteration 132000, loss = 0.000379245
I0616 16:02:03.323387  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000379555 (* 1 = 0.000379555 loss)
I0616 16:02:03.323395  4990 sgd_solver.cpp:294] Iteration 132000, lr = 0.002
I0616 16:19:18.449996  4990 solver.cpp:342] Iteration 132400, Testing net (#0)
I0616 16:20:23.492046  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.92875
I0616 16:20:23.492089  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.385448 (* 1 = 0.385448 loss)
I0616 16:20:26.019840  4990 solver.cpp:233] Iteration 132400, loss = 0.000116822
I0616 16:20:26.019876  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000117131 (* 1 = 0.000117131 loss)
I0616 16:20:26.019882  4990 sgd_solver.cpp:294] Iteration 132400, lr = 0.002
I0616 16:37:40.062273  4990 solver.cpp:342] Iteration 132800, Testing net (#0)
I0616 16:38:45.154667  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929219
I0616 16:38:45.154708  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.381974 (* 1 = 0.381974 loss)
I0616 16:38:47.743603  4990 solver.cpp:233] Iteration 132800, loss = 0.000350361
I0616 16:38:47.743640  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000350671 (* 1 = 0.000350671 loss)
I0616 16:38:47.743649  4990 sgd_solver.cpp:294] Iteration 132800, lr = 0.002
I0616 16:56:03.008834  4990 solver.cpp:342] Iteration 133200, Testing net (#0)
I0616 16:57:08.100350  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929688
I0616 16:57:08.100392  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.383375 (* 1 = 0.383375 loss)
I0616 16:57:10.671841  4990 solver.cpp:233] Iteration 133200, loss = 0.000128821
I0616 16:57:10.671886  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000129131 (* 1 = 0.000129131 loss)
I0616 16:57:10.671900  4990 sgd_solver.cpp:294] Iteration 133200, lr = 0.002
I0616 17:14:24.846053  4990 solver.cpp:342] Iteration 133600, Testing net (#0)
I0616 17:15:30.110059  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930547
I0616 17:15:30.110098  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.370636 (* 1 = 0.370636 loss)
I0616 17:15:32.685111  4990 solver.cpp:233] Iteration 133600, loss = 0.000235125
I0616 17:15:32.685148  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000235435 (* 1 = 0.000235435 loss)
I0616 17:15:32.685154  4990 sgd_solver.cpp:294] Iteration 133600, lr = 0.002
I0616 17:32:48.449535  4990 solver.cpp:342] Iteration 134000, Testing net (#0)
I0616 17:33:53.748991  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928203
I0616 17:33:53.749032  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.369251 (* 1 = 0.369251 loss)
I0616 17:33:56.277216  4990 solver.cpp:233] Iteration 134000, loss = 9.61952e-05
I0616 17:33:56.277251  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 9.65073e-05 (* 1 = 9.65073e-05 loss)
I0616 17:33:56.277257  4990 sgd_solver.cpp:294] Iteration 134000, lr = 0.002
I0616 17:51:11.393057  4990 solver.cpp:342] Iteration 134400, Testing net (#0)
I0616 17:52:16.944491  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.926484
I0616 17:52:16.944537  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.39981 (* 1 = 0.39981 loss)
I0616 17:52:19.501646  4990 solver.cpp:233] Iteration 134400, loss = 0.000156565
I0616 17:52:19.501688  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000156877 (* 1 = 0.000156877 loss)
I0616 17:52:19.501710  4990 sgd_solver.cpp:294] Iteration 134400, lr = 0.002
I0616 18:09:34.476397  4990 solver.cpp:342] Iteration 134800, Testing net (#0)
I0616 18:10:39.439587  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928672
I0616 18:10:39.439631  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.385094 (* 1 = 0.385094 loss)
I0616 18:10:41.995894  4990 solver.cpp:233] Iteration 134800, loss = 0.000174023
I0616 18:10:41.995949  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000174335 (* 1 = 0.000174335 loss)
I0616 18:10:41.995957  4990 sgd_solver.cpp:294] Iteration 134800, lr = 0.002
I0616 18:27:55.926337  4990 solver.cpp:342] Iteration 135200, Testing net (#0)
I0616 18:29:01.065651  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929141
I0616 18:29:01.065696  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.38749 (* 1 = 0.38749 loss)
I0616 18:29:03.609871  4990 solver.cpp:233] Iteration 135200, loss = 0.000225147
I0616 18:29:03.609910  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000225458 (* 1 = 0.000225458 loss)
I0616 18:29:03.609917  4990 sgd_solver.cpp:294] Iteration 135200, lr = 0.002
I0616 18:46:19.833786  4990 solver.cpp:342] Iteration 135600, Testing net (#0)
I0616 18:47:25.035815  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929922
I0616 18:47:25.035854  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.377253 (* 1 = 0.377253 loss)
I0616 18:47:27.572716  4990 solver.cpp:233] Iteration 135600, loss = 0.000444862
I0616 18:47:27.572757  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000445173 (* 1 = 0.000445173 loss)
I0616 18:47:27.572764  4990 sgd_solver.cpp:294] Iteration 135600, lr = 0.002
I0616 19:04:42.434283  4990 solver.cpp:342] Iteration 136000, Testing net (#0)
I0616 19:05:47.632169  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928203
I0616 19:05:47.632206  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.40349 (* 1 = 0.40349 loss)
I0616 19:05:50.221019  4990 solver.cpp:233] Iteration 136000, loss = 0.000156706
I0616 19:05:50.221057  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000157016 (* 1 = 0.000157016 loss)
I0616 19:05:50.221065  4990 sgd_solver.cpp:294] Iteration 136000, lr = 0.002
I0616 19:23:05.512159  4990 solver.cpp:342] Iteration 136400, Testing net (#0)
I0616 19:24:10.965410  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929297
I0616 19:24:10.965467  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.380585 (* 1 = 0.380585 loss)
I0616 19:24:13.495158  4990 solver.cpp:233] Iteration 136400, loss = 0.00012857
I0616 19:24:13.495198  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000128881 (* 1 = 0.000128881 loss)
I0616 19:24:13.495205  4990 sgd_solver.cpp:294] Iteration 136400, lr = 0.002
I0616 19:41:28.583945  4990 solver.cpp:342] Iteration 136800, Testing net (#0)
I0616 19:42:34.019917  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930391
I0616 19:42:34.019973  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.361795 (* 1 = 0.361795 loss)
I0616 19:42:36.558053  4990 solver.cpp:233] Iteration 136800, loss = 0.000327538
I0616 19:42:36.558086  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000327848 (* 1 = 0.000327848 loss)
I0616 19:42:36.558094  4990 sgd_solver.cpp:294] Iteration 136800, lr = 0.002
I0616 19:59:51.940495  4990 solver.cpp:342] Iteration 137200, Testing net (#0)
I0616 20:00:56.966888  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928828
I0616 20:00:56.966934  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.386264 (* 1 = 0.386264 loss)
I0616 20:00:59.519208  4990 solver.cpp:233] Iteration 137200, loss = 0.000358575
I0616 20:00:59.519246  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000358884 (* 1 = 0.000358884 loss)
I0616 20:00:59.519253  4990 sgd_solver.cpp:294] Iteration 137200, lr = 0.002
I0616 20:18:14.068945  4990 solver.cpp:342] Iteration 137600, Testing net (#0)
I0616 20:19:19.581652  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927188
I0616 20:19:19.581708  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.395589 (* 1 = 0.395589 loss)
I0616 20:19:22.191728  4990 solver.cpp:233] Iteration 137600, loss = 0.000239718
I0616 20:19:22.191768  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000240026 (* 1 = 0.000240026 loss)
I0616 20:19:22.191776  4990 sgd_solver.cpp:294] Iteration 137600, lr = 0.002
I0616 20:36:37.151479  4990 solver.cpp:342] Iteration 138000, Testing net (#0)
I0616 20:37:42.423382  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929141
I0616 20:37:42.423430  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.377508 (* 1 = 0.377508 loss)
I0616 20:37:44.989158  4990 solver.cpp:233] Iteration 138000, loss = 0.000214198
I0616 20:37:44.989212  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000214507 (* 1 = 0.000214507 loss)
I0616 20:37:44.989223  4990 sgd_solver.cpp:294] Iteration 138000, lr = 0.002
I0616 20:54:58.824558  4990 solver.cpp:342] Iteration 138400, Testing net (#0)
I0616 20:56:04.054415  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930781
I0616 20:56:04.054458  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.379219 (* 1 = 0.379219 loss)
I0616 20:56:06.636644  4990 solver.cpp:233] Iteration 138400, loss = 0.000342753
I0616 20:56:06.636685  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000343062 (* 1 = 0.000343062 loss)
I0616 20:56:06.636693  4990 sgd_solver.cpp:294] Iteration 138400, lr = 0.002
I0616 21:13:21.535687  4990 solver.cpp:342] Iteration 138800, Testing net (#0)
I0616 21:14:26.965811  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927266
I0616 21:14:26.965864  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.401219 (* 1 = 0.401219 loss)
I0616 21:14:29.511523  4990 solver.cpp:233] Iteration 138800, loss = 0.000173282
I0616 21:14:29.511559  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000173591 (* 1 = 0.000173591 loss)
I0616 21:14:29.511567  4990 sgd_solver.cpp:294] Iteration 138800, lr = 0.002
I0616 21:31:44.308337  4990 solver.cpp:342] Iteration 139200, Testing net (#0)
I0616 21:32:49.480008  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.926797
I0616 21:32:49.480051  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.384104 (* 1 = 0.384104 loss)
I0616 21:32:52.018373  4990 solver.cpp:233] Iteration 139200, loss = 0.000226315
I0616 21:32:52.018410  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000226625 (* 1 = 0.000226625 loss)
I0616 21:32:52.018419  4990 sgd_solver.cpp:294] Iteration 139200, lr = 0.002
I0616 21:50:07.146145  4990 solver.cpp:342] Iteration 139600, Testing net (#0)
I0616 21:51:12.147097  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930391
I0616 21:51:12.147135  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.380169 (* 1 = 0.380169 loss)
I0616 21:51:14.680268  4990 solver.cpp:233] Iteration 139600, loss = 0.000139449
I0616 21:51:14.680305  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00013976 (* 1 = 0.00013976 loss)
I0616 21:51:14.680311  4990 sgd_solver.cpp:294] Iteration 139600, lr = 0.002
I0616 22:08:29.648845  4990 solver.cpp:342] Iteration 140000, Testing net (#0)
I0616 22:09:34.864893  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930703
I0616 22:09:34.864935  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.380432 (* 1 = 0.380432 loss)
I0616 22:09:37.419364  4990 solver.cpp:233] Iteration 140000, loss = 0.00010593
I0616 22:09:37.419404  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000106242 (* 1 = 0.000106242 loss)
I0616 22:09:37.419412  4990 sgd_solver.cpp:294] Iteration 140000, lr = 0.002
I0616 22:26:52.556831  4990 solver.cpp:342] Iteration 140400, Testing net (#0)
I0616 22:27:57.801787  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928516
I0616 22:27:57.801837  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.392169 (* 1 = 0.392169 loss)
I0616 22:28:00.394680  4990 solver.cpp:233] Iteration 140400, loss = 0.000329028
I0616 22:28:00.394717  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000329339 (* 1 = 0.000329339 loss)
I0616 22:28:00.394734  4990 sgd_solver.cpp:294] Iteration 140400, lr = 0.002
I0616 22:45:14.510188  4990 solver.cpp:342] Iteration 140800, Testing net (#0)
I0616 22:46:19.695252  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927891
I0616 22:46:19.695294  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.38434 (* 1 = 0.38434 loss)
I0616 22:46:22.286229  4990 solver.cpp:233] Iteration 140800, loss = 0.000260505
I0616 22:46:22.286267  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000260817 (* 1 = 0.000260817 loss)
I0616 22:46:22.286276  4990 sgd_solver.cpp:294] Iteration 140800, lr = 0.002
I0616 23:03:36.552805  4990 solver.cpp:342] Iteration 141200, Testing net (#0)
I0616 23:04:41.741641  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929453
I0616 23:04:41.741677  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.373317 (* 1 = 0.373317 loss)
I0616 23:04:44.336575  4990 solver.cpp:233] Iteration 141200, loss = 0.000448941
I0616 23:04:44.336613  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000449253 (* 1 = 0.000449253 loss)
I0616 23:04:44.336621  4990 sgd_solver.cpp:294] Iteration 141200, lr = 0.002
I0616 23:21:59.622211  4990 solver.cpp:342] Iteration 141600, Testing net (#0)
I0616 23:23:04.764384  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.93
I0616 23:23:04.764425  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.389022 (* 1 = 0.389022 loss)
I0616 23:23:07.290011  4990 solver.cpp:233] Iteration 141600, loss = 0.000315418
I0616 23:23:07.290048  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000315729 (* 1 = 0.000315729 loss)
I0616 23:23:07.290055  4990 sgd_solver.cpp:294] Iteration 141600, lr = 0.002
I0616 23:40:21.564380  4990 solver.cpp:342] Iteration 142000, Testing net (#0)
I0616 23:41:26.662289  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928672
I0616 23:41:26.662329  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.382369 (* 1 = 0.382369 loss)
I0616 23:41:29.193516  4990 solver.cpp:233] Iteration 142000, loss = 6.09787e-05
I0616 23:41:29.193565  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 6.12897e-05 (* 1 = 6.12897e-05 loss)
I0616 23:41:29.193575  4990 sgd_solver.cpp:294] Iteration 142000, lr = 0.002
I0616 23:58:44.663036  4990 solver.cpp:342] Iteration 142400, Testing net (#0)
I0616 23:59:49.805579  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.931641
I0616 23:59:49.805626  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.381268 (* 1 = 0.381268 loss)
I0616 23:59:52.343559  4990 solver.cpp:233] Iteration 142400, loss = 0.000274542
I0616 23:59:52.343591  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000274852 (* 1 = 0.000274852 loss)
I0616 23:59:52.343600  4990 sgd_solver.cpp:294] Iteration 142400, lr = 0.002
I0617 00:17:07.348291  4990 solver.cpp:342] Iteration 142800, Testing net (#0)
I0617 00:18:12.440706  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929766
I0617 00:18:12.440752  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.383045 (* 1 = 0.383045 loss)
I0617 00:18:15.012233  4990 solver.cpp:233] Iteration 142800, loss = 0.00030995
I0617 00:18:15.012280  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000310259 (* 1 = 0.000310259 loss)
I0617 00:18:15.012291  4990 sgd_solver.cpp:294] Iteration 142800, lr = 0.002
I0617 00:35:29.727327  4990 solver.cpp:342] Iteration 143200, Testing net (#0)
I0617 00:36:34.996598  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930313
I0617 00:36:34.996644  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.386288 (* 1 = 0.386288 loss)
I0617 00:36:37.550582  4990 solver.cpp:233] Iteration 143200, loss = 0.000279554
I0617 00:36:37.550613  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000279862 (* 1 = 0.000279862 loss)
I0617 00:36:37.550621  4990 sgd_solver.cpp:294] Iteration 143200, lr = 0.002
I0617 00:53:52.163250  4990 solver.cpp:342] Iteration 143600, Testing net (#0)
I0617 00:54:57.346765  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.93
I0617 00:54:57.346809  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.383539 (* 1 = 0.383539 loss)
I0617 00:54:59.892974  4990 solver.cpp:233] Iteration 143600, loss = 0.000276834
I0617 00:54:59.893016  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000277143 (* 1 = 0.000277143 loss)
I0617 00:54:59.893024  4990 sgd_solver.cpp:294] Iteration 143600, lr = 0.002
I0617 01:12:15.089553  4990 solver.cpp:342] Iteration 144000, Testing net (#0)
I0617 01:13:20.247071  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930469
I0617 01:13:20.247109  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.374545 (* 1 = 0.374545 loss)
I0617 01:13:22.785923  4990 solver.cpp:233] Iteration 144000, loss = 0.000115658
I0617 01:13:22.785964  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000115968 (* 1 = 0.000115968 loss)
I0617 01:13:22.785972  4990 sgd_solver.cpp:294] Iteration 144000, lr = 0.002
I0617 01:30:37.679085  4990 solver.cpp:342] Iteration 144400, Testing net (#0)
I0617 01:31:43.213603  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927891
I0617 01:31:43.213663  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.395605 (* 1 = 0.395605 loss)
I0617 01:31:45.764492  4990 solver.cpp:233] Iteration 144400, loss = 0.000596446
I0617 01:31:45.764523  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000596756 (* 1 = 0.000596756 loss)
I0617 01:31:45.764530  4990 sgd_solver.cpp:294] Iteration 144400, lr = 0.002
I0617 01:49:00.000264  4990 solver.cpp:342] Iteration 144800, Testing net (#0)
I0617 01:50:05.191885  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.926719
I0617 01:50:05.191929  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.38676 (* 1 = 0.38676 loss)
I0617 01:50:07.778133  4990 solver.cpp:233] Iteration 144800, loss = 0.000512939
I0617 01:50:07.778169  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00051325 (* 1 = 0.00051325 loss)
I0617 01:50:07.778177  4990 sgd_solver.cpp:294] Iteration 144800, lr = 0.002
I0617 02:07:23.162317  4990 solver.cpp:342] Iteration 145200, Testing net (#0)
I0617 02:08:28.304417  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.92875
I0617 02:08:28.304461  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.379221 (* 1 = 0.379221 loss)
I0617 02:08:30.856034  4990 solver.cpp:233] Iteration 145200, loss = 0.000278671
I0617 02:08:30.856075  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000278981 (* 1 = 0.000278981 loss)
I0617 02:08:30.856083  4990 sgd_solver.cpp:294] Iteration 145200, lr = 0.002
I0617 02:25:45.893085  4990 solver.cpp:342] Iteration 145600, Testing net (#0)
I0617 02:26:51.088968  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929688
I0617 02:26:51.089020  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.369132 (* 1 = 0.369132 loss)
I0617 02:26:53.613517  4990 solver.cpp:233] Iteration 145600, loss = 0.000293805
I0617 02:26:53.613550  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000294115 (* 1 = 0.000294115 loss)
I0617 02:26:53.613557  4990 sgd_solver.cpp:294] Iteration 145600, lr = 0.002
I0617 02:44:07.885570  4990 solver.cpp:342] Iteration 146000, Testing net (#0)
I0617 02:45:13.278544  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.92875
I0617 02:45:13.278600  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.39402 (* 1 = 0.39402 loss)
I0617 02:45:15.810094  4990 solver.cpp:233] Iteration 146000, loss = 0.000172884
I0617 02:45:15.810134  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000173194 (* 1 = 0.000173194 loss)
I0617 02:45:15.810142  4990 sgd_solver.cpp:294] Iteration 146000, lr = 0.002
I0617 03:02:29.287909  4990 solver.cpp:342] Iteration 146400, Testing net (#0)
I0617 03:03:34.390965  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927734
I0617 03:03:34.391006  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.392573 (* 1 = 0.392573 loss)
I0617 03:03:36.924167  4990 solver.cpp:233] Iteration 146400, loss = 0.000149439
I0617 03:03:36.924221  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00014975 (* 1 = 0.00014975 loss)
I0617 03:03:36.924227  4990 sgd_solver.cpp:294] Iteration 146400, lr = 0.002
I0617 03:20:51.985034  4990 solver.cpp:342] Iteration 146800, Testing net (#0)
I0617 03:21:57.579306  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927656
I0617 03:21:57.579347  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.378316 (* 1 = 0.378316 loss)
I0617 03:22:00.109863  4990 solver.cpp:233] Iteration 146800, loss = 0.000171182
I0617 03:22:00.109904  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000171494 (* 1 = 0.000171494 loss)
I0617 03:22:00.109912  4990 sgd_solver.cpp:294] Iteration 146800, lr = 0.002
I0617 03:39:15.967996  4990 solver.cpp:342] Iteration 147200, Testing net (#0)
I0617 03:40:21.358705  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928906
I0617 03:40:21.358770  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.389305 (* 1 = 0.389305 loss)
I0617 03:40:23.927155  4990 solver.cpp:233] Iteration 147200, loss = 0.000914729
I0617 03:40:23.927191  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000915041 (* 1 = 0.000915041 loss)
I0617 03:40:23.927201  4990 sgd_solver.cpp:294] Iteration 147200, lr = 0.002
I0617 03:57:39.052633  4990 solver.cpp:342] Iteration 147600, Testing net (#0)
I0617 03:58:44.427971  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928203
I0617 03:58:44.428014  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.388693 (* 1 = 0.388693 loss)
I0617 03:58:46.972512  4990 solver.cpp:233] Iteration 147600, loss = 0.000144168
I0617 03:58:46.972568  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000144481 (* 1 = 0.000144481 loss)
I0617 03:58:46.972576  4990 sgd_solver.cpp:294] Iteration 147600, lr = 0.002
I0617 04:16:01.882899  4990 solver.cpp:342] Iteration 148000, Testing net (#0)
I0617 04:17:07.499105  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.931719
I0617 04:17:07.499176  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.37188 (* 1 = 0.37188 loss)
I0617 04:17:10.035341  4990 solver.cpp:233] Iteration 148000, loss = 7.77118e-05
I0617 04:17:10.035379  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 7.80245e-05 (* 1 = 7.80245e-05 loss)
I0617 04:17:10.035387  4990 sgd_solver.cpp:294] Iteration 148000, lr = 0.002
I0617 04:34:24.431957  4990 solver.cpp:342] Iteration 148400, Testing net (#0)
I0617 04:35:29.792608  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930938
I0617 04:35:29.792651  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.369459 (* 1 = 0.369459 loss)
I0617 04:35:32.340795  4990 solver.cpp:233] Iteration 148400, loss = 0.00201697
I0617 04:35:32.340839  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00201729 (* 1 = 0.00201729 loss)
I0617 04:35:32.340847  4990 sgd_solver.cpp:294] Iteration 148400, lr = 0.002
I0617 04:52:47.925134  4990 solver.cpp:342] Iteration 148800, Testing net (#0)
I0617 04:53:53.223100  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928828
I0617 04:53:53.223155  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.390824 (* 1 = 0.390824 loss)
I0617 04:53:55.750784  4990 solver.cpp:233] Iteration 148800, loss = 0.00248729
I0617 04:53:55.750823  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0024876 (* 1 = 0.0024876 loss)
I0617 04:53:55.750831  4990 sgd_solver.cpp:294] Iteration 148800, lr = 0.002
I0617 05:11:12.049713  4990 solver.cpp:342] Iteration 149200, Testing net (#0)
I0617 05:12:17.189493  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927422
I0617 05:12:17.189537  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.386532 (* 1 = 0.386532 loss)
I0617 05:12:19.756840  4990 solver.cpp:233] Iteration 149200, loss = 0.000755504
I0617 05:12:19.756897  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000755815 (* 1 = 0.000755815 loss)
I0617 05:12:19.756906  4990 sgd_solver.cpp:294] Iteration 149200, lr = 0.002
I0617 05:29:35.547863  4990 solver.cpp:342] Iteration 149600, Testing net (#0)
I0617 05:30:41.223870  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929766
I0617 05:30:41.223929  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.388405 (* 1 = 0.388405 loss)
I0617 05:30:43.775265  4990 solver.cpp:233] Iteration 149600, loss = 0.000580917
I0617 05:30:43.775290  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000581229 (* 1 = 0.000581229 loss)
I0617 05:30:43.775297  4990 sgd_solver.cpp:294] Iteration 149600, lr = 0.002
I0617 05:47:58.887152  4990 solver.cpp:342] Iteration 150000, Testing net (#0)
I0617 05:49:04.054157  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928359
I0617 05:49:04.054211  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.395794 (* 1 = 0.395794 loss)
I0617 05:49:06.642990  4990 solver.cpp:233] Iteration 150000, loss = 0.000197163
I0617 05:49:06.643028  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000197475 (* 1 = 0.000197475 loss)
I0617 05:49:06.643034  4990 sgd_solver.cpp:234] MultiStep Status: Iteration 150000, step = 2
I0617 05:49:06.643038  4990 sgd_solver.cpp:294] Iteration 150000, lr = 0.0002
I0617 06:06:22.211254  4990 solver.cpp:342] Iteration 150400, Testing net (#0)
I0617 06:07:27.774333  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929219
I0617 06:07:27.774389  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.389358 (* 1 = 0.389358 loss)
I0617 06:07:30.320792  4990 solver.cpp:233] Iteration 150400, loss = 0.000640779
I0617 06:07:30.320832  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000641091 (* 1 = 0.000641091 loss)
I0617 06:07:30.320839  4990 sgd_solver.cpp:294] Iteration 150400, lr = 0.0002
I0617 06:24:44.436405  4990 solver.cpp:342] Iteration 150800, Testing net (#0)
I0617 06:25:49.746803  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928359
I0617 06:25:49.746848  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.390911 (* 1 = 0.390911 loss)
I0617 06:25:52.284337  4990 solver.cpp:233] Iteration 150800, loss = 0.00218458
I0617 06:25:52.284402  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00218489 (* 1 = 0.00218489 loss)
I0617 06:25:52.284417  4990 sgd_solver.cpp:294] Iteration 150800, lr = 0.0002
I0617 06:43:07.859154  4990 solver.cpp:342] Iteration 151200, Testing net (#0)
I0617 06:44:13.022414  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929766
I0617 06:44:13.022454  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.380359 (* 1 = 0.380359 loss)
I0617 06:44:15.601817  4990 solver.cpp:233] Iteration 151200, loss = 0.000659778
I0617 06:44:15.601860  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00066009 (* 1 = 0.00066009 loss)
I0617 06:44:15.601868  4990 sgd_solver.cpp:294] Iteration 151200, lr = 0.0002
I0617 07:01:30.383177  4990 solver.cpp:342] Iteration 151600, Testing net (#0)
I0617 07:02:35.629340  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929297
I0617 07:02:35.629400  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.390614 (* 1 = 0.390614 loss)
I0617 07:02:38.179625  4990 solver.cpp:233] Iteration 151600, loss = 0.000154944
I0617 07:02:38.179666  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000155257 (* 1 = 0.000155257 loss)
I0617 07:02:38.179673  4990 sgd_solver.cpp:294] Iteration 151600, lr = 0.0002
I0617 07:19:53.529438  4990 solver.cpp:342] Iteration 152000, Testing net (#0)
I0617 07:20:59.280089  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930078
I0617 07:20:59.280146  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.384438 (* 1 = 0.384438 loss)
I0617 07:21:01.821663  4990 solver.cpp:233] Iteration 152000, loss = 0.000347904
I0617 07:21:01.821713  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000348217 (* 1 = 0.000348217 loss)
I0617 07:21:01.821720  4990 sgd_solver.cpp:294] Iteration 152000, lr = 0.0002
I0617 07:38:17.436007  4990 solver.cpp:342] Iteration 152400, Testing net (#0)
I0617 07:39:22.761407  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929297
I0617 07:39:22.761456  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.383158 (* 1 = 0.383158 loss)
I0617 07:39:25.310991  4990 solver.cpp:233] Iteration 152400, loss = 0.000202372
I0617 07:39:25.311028  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000202685 (* 1 = 0.000202685 loss)
I0617 07:39:25.311038  4990 sgd_solver.cpp:294] Iteration 152400, lr = 0.0002
I0617 07:56:39.315942  4990 solver.cpp:342] Iteration 152800, Testing net (#0)
I0617 07:57:44.530974  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930078
I0617 07:57:44.531026  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.377232 (* 1 = 0.377232 loss)
I0617 07:57:47.119336  4990 solver.cpp:233] Iteration 152800, loss = 0.000673057
I0617 07:57:47.119385  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00067337 (* 1 = 0.00067337 loss)
I0617 07:57:47.119395  4990 sgd_solver.cpp:294] Iteration 152800, lr = 0.0002
I0617 08:15:01.726160  4990 solver.cpp:342] Iteration 153200, Testing net (#0)
I0617 08:16:06.915828  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930625
I0617 08:16:06.915876  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.380038 (* 1 = 0.380038 loss)
I0617 08:16:09.443558  4990 solver.cpp:233] Iteration 153200, loss = 0.000119686
I0617 08:16:09.443617  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000119999 (* 1 = 0.000119999 loss)
I0617 08:16:09.443624  4990 sgd_solver.cpp:294] Iteration 153200, lr = 0.0002
I0617 08:33:25.170703  4990 solver.cpp:342] Iteration 153600, Testing net (#0)
I0617 08:34:30.702486  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930625
I0617 08:34:30.702539  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.373334 (* 1 = 0.373334 loss)
I0617 08:34:33.259659  4990 solver.cpp:233] Iteration 153600, loss = 0.00227598
I0617 08:34:33.259694  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0022763 (* 1 = 0.0022763 loss)
I0617 08:34:33.259712  4990 sgd_solver.cpp:294] Iteration 153600, lr = 0.0002
I0617 08:51:48.657205  4990 solver.cpp:342] Iteration 154000, Testing net (#0)
I0617 08:52:54.054337  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.92875
I0617 08:52:54.054379  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.383915 (* 1 = 0.383915 loss)
I0617 08:52:56.624824  4990 solver.cpp:233] Iteration 154000, loss = 0.000994953
I0617 08:52:56.624878  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000995266 (* 1 = 0.000995266 loss)
I0617 08:52:56.624889  4990 sgd_solver.cpp:294] Iteration 154000, lr = 0.0002
I0617 09:10:11.295089  4990 solver.cpp:342] Iteration 154400, Testing net (#0)
I0617 09:11:16.773737  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929297
I0617 09:11:16.773777  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.387346 (* 1 = 0.387346 loss)
I0617 09:11:19.299672  4990 solver.cpp:233] Iteration 154400, loss = 0.000481596
I0617 09:11:19.299712  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000481907 (* 1 = 0.000481907 loss)
I0617 09:11:19.299721  4990 sgd_solver.cpp:294] Iteration 154400, lr = 0.0002
I0617 09:28:34.376909  4990 solver.cpp:342] Iteration 154800, Testing net (#0)
I0617 09:29:39.836931  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927109
I0617 09:29:39.836983  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.398099 (* 1 = 0.398099 loss)
I0617 09:29:42.379099  4990 solver.cpp:233] Iteration 154800, loss = 0.000160603
I0617 09:29:42.379137  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000160914 (* 1 = 0.000160914 loss)
I0617 09:29:42.379144  4990 sgd_solver.cpp:294] Iteration 154800, lr = 0.0002
I0617 09:46:57.952531  4990 solver.cpp:342] Iteration 155200, Testing net (#0)
I0617 09:48:03.018751  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930078
I0617 09:48:03.018793  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.379753 (* 1 = 0.379753 loss)
I0617 09:48:05.615048  4990 solver.cpp:233] Iteration 155200, loss = 0.000220299
I0617 09:48:05.615088  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00022061 (* 1 = 0.00022061 loss)
I0617 09:48:05.615097  4990 sgd_solver.cpp:294] Iteration 155200, lr = 0.0002
I0617 10:05:16.040529  4990 solver.cpp:342] Iteration 155600, Testing net (#0)
I0617 10:06:22.002645  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929844
I0617 10:06:22.002687  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.364535 (* 1 = 0.364535 loss)
I0617 10:06:24.519170  4990 solver.cpp:233] Iteration 155600, loss = 7.3351e-05
I0617 10:06:24.519191  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 7.36619e-05 (* 1 = 7.36619e-05 loss)
I0617 10:06:24.519199  4990 sgd_solver.cpp:294] Iteration 155600, lr = 0.0002
I0617 10:23:25.392648  4990 solver.cpp:342] Iteration 156000, Testing net (#0)
I0617 10:24:31.083854  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928594
I0617 10:24:31.083899  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.394996 (* 1 = 0.394996 loss)
I0617 10:24:33.602324  4990 solver.cpp:233] Iteration 156000, loss = 0.000104615
I0617 10:24:33.602356  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000104926 (* 1 = 0.000104926 loss)
I0617 10:24:33.602363  4990 sgd_solver.cpp:294] Iteration 156000, lr = 0.0002
I0617 10:41:34.451997  4990 solver.cpp:342] Iteration 156400, Testing net (#0)
I0617 10:42:40.114351  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928203
I0617 10:42:40.114400  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.380499 (* 1 = 0.380499 loss)
I0617 10:42:42.627048  4990 solver.cpp:233] Iteration 156400, loss = 0.000242795
I0617 10:42:42.627073  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000243106 (* 1 = 0.000243106 loss)
I0617 10:42:42.627079  4990 sgd_solver.cpp:294] Iteration 156400, lr = 0.0002
I0617 10:59:43.588037  4990 solver.cpp:342] Iteration 156800, Testing net (#0)
I0617 11:00:49.296998  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930156
I0617 11:00:49.297041  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.379275 (* 1 = 0.379275 loss)
I0617 11:00:51.813509  4990 solver.cpp:233] Iteration 156800, loss = 0.000797239
I0617 11:00:51.813532  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00079755 (* 1 = 0.00079755 loss)
I0617 11:00:51.813539  4990 sgd_solver.cpp:294] Iteration 156800, lr = 0.0002
I0617 11:17:52.739086  4990 solver.cpp:342] Iteration 157200, Testing net (#0)
I0617 11:18:58.448140  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930313
I0617 11:18:58.448184  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.383769 (* 1 = 0.383769 loss)
I0617 11:19:00.963387  4990 solver.cpp:233] Iteration 157200, loss = 0.000115834
I0617 11:19:00.963416  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000116144 (* 1 = 0.000116144 loss)
I0617 11:19:00.963423  4990 sgd_solver.cpp:294] Iteration 157200, lr = 0.0002
I0617 11:36:01.805013  4990 solver.cpp:342] Iteration 157600, Testing net (#0)
I0617 11:37:07.568472  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927969
I0617 11:37:07.568517  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.393849 (* 1 = 0.393849 loss)
I0617 11:37:10.084470  4990 solver.cpp:233] Iteration 157600, loss = 0.000234466
I0617 11:37:10.084497  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000234776 (* 1 = 0.000234776 loss)
I0617 11:37:10.084506  4990 sgd_solver.cpp:294] Iteration 157600, lr = 0.0002
I0617 11:54:11.012372  4990 solver.cpp:342] Iteration 158000, Testing net (#0)
I0617 11:55:16.739982  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.9275
I0617 11:55:16.740026  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.387844 (* 1 = 0.387844 loss)
I0617 11:55:19.255687  4990 solver.cpp:233] Iteration 158000, loss = 0.000221725
I0617 11:55:19.255713  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000222034 (* 1 = 0.000222034 loss)
I0617 11:55:19.255722  4990 sgd_solver.cpp:294] Iteration 158000, lr = 0.0002
I0617 12:12:20.295375  4990 solver.cpp:342] Iteration 158400, Testing net (#0)
I0617 12:13:26.028909  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930781
I0617 12:13:26.028947  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.362401 (* 1 = 0.362401 loss)
I0617 12:13:28.545156  4990 solver.cpp:233] Iteration 158400, loss = 0.000369072
I0617 12:13:28.545181  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000369381 (* 1 = 0.000369381 loss)
I0617 12:13:28.545187  4990 sgd_solver.cpp:294] Iteration 158400, lr = 0.0002
I0617 12:30:29.633328  4990 solver.cpp:342] Iteration 158800, Testing net (#0)
I0617 12:31:35.379757  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929766
I0617 12:31:35.379801  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.398865 (* 1 = 0.398865 loss)
I0617 12:31:37.897635  4990 solver.cpp:233] Iteration 158800, loss = 0.000411142
I0617 12:31:37.897661  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000411451 (* 1 = 0.000411451 loss)
I0617 12:31:37.897668  4990 sgd_solver.cpp:294] Iteration 158800, lr = 0.0002
I0617 12:48:38.878470  4990 solver.cpp:342] Iteration 159200, Testing net (#0)
I0617 12:49:44.581193  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930703
I0617 12:49:44.581238  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.376017 (* 1 = 0.376017 loss)
I0617 12:49:47.099901  4990 solver.cpp:233] Iteration 159200, loss = 0.000533626
I0617 12:49:47.099923  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000533937 (* 1 = 0.000533937 loss)
I0617 12:49:47.099931  4990 sgd_solver.cpp:294] Iteration 159200, lr = 0.0002
I0617 13:06:48.023005  4990 solver.cpp:342] Iteration 159600, Testing net (#0)
I0617 13:07:53.716128  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.931484
I0617 13:07:53.716168  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.378926 (* 1 = 0.378926 loss)
I0617 13:07:56.232661  4990 solver.cpp:233] Iteration 159600, loss = 0.000373732
I0617 13:07:56.232684  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000374043 (* 1 = 0.000374043 loss)
I0617 13:07:56.232692  4990 sgd_solver.cpp:294] Iteration 159600, lr = 0.0002
I0617 13:24:57.033511  4990 solver.cpp:342] Iteration 160000, Testing net (#0)
I0617 13:26:02.708380  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928672
I0617 13:26:02.708423  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.384195 (* 1 = 0.384195 loss)
I0617 13:26:05.223669  4990 solver.cpp:233] Iteration 160000, loss = 0.000229462
I0617 13:26:05.223692  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000229772 (* 1 = 0.000229772 loss)
I0617 13:26:05.223700  4990 sgd_solver.cpp:294] Iteration 160000, lr = 0.0002
I0617 13:43:06.108156  4990 solver.cpp:342] Iteration 160400, Testing net (#0)
I0617 13:44:11.781965  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928984
I0617 13:44:11.782009  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.392944 (* 1 = 0.392944 loss)
I0617 13:44:14.298975  4990 solver.cpp:233] Iteration 160400, loss = 0.00126916
I0617 13:44:14.299003  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00126947 (* 1 = 0.00126947 loss)
I0617 13:44:14.299010  4990 sgd_solver.cpp:294] Iteration 160400, lr = 0.0002
I0617 14:01:15.212071  4990 solver.cpp:342] Iteration 160800, Testing net (#0)
I0617 14:02:20.887796  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930078
I0617 14:02:20.887841  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.380845 (* 1 = 0.380845 loss)
I0617 14:02:23.404022  4990 solver.cpp:233] Iteration 160800, loss = 0.000111729
I0617 14:02:23.404048  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000112039 (* 1 = 0.000112039 loss)
I0617 14:02:23.404055  4990 sgd_solver.cpp:294] Iteration 160800, lr = 0.0002
I0617 14:19:24.262594  4990 solver.cpp:342] Iteration 161200, Testing net (#0)
I0617 14:20:29.943497  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930234
I0617 14:20:29.943538  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.376196 (* 1 = 0.376196 loss)
I0617 14:20:32.458536  4990 solver.cpp:233] Iteration 161200, loss = 0.000328344
I0617 14:20:32.458559  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000328655 (* 1 = 0.000328655 loss)
I0617 14:20:32.458567  4990 sgd_solver.cpp:294] Iteration 161200, lr = 0.0002
I0617 14:37:33.344118  4990 solver.cpp:342] Iteration 161600, Testing net (#0)
I0617 14:38:39.021165  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927578
I0617 14:38:39.021209  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.396342 (* 1 = 0.396342 loss)
I0617 14:38:41.535207  4990 solver.cpp:233] Iteration 161600, loss = 0.000181789
I0617 14:38:41.535233  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000182099 (* 1 = 0.000182099 loss)
I0617 14:38:41.535240  4990 sgd_solver.cpp:294] Iteration 161600, lr = 0.0002
I0617 14:55:42.450412  4990 solver.cpp:342] Iteration 162000, Testing net (#0)
I0617 14:56:48.149219  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928125
I0617 14:56:48.149263  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.390501 (* 1 = 0.390501 loss)
I0617 14:56:50.667161  4990 solver.cpp:233] Iteration 162000, loss = 0.000382377
I0617 14:56:50.667186  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000382687 (* 1 = 0.000382687 loss)
I0617 14:56:50.667192  4990 sgd_solver.cpp:294] Iteration 162000, lr = 0.0002
I0617 15:13:51.367724  4990 solver.cpp:342] Iteration 162400, Testing net (#0)
I0617 15:14:57.094059  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928125
I0617 15:14:57.094104  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.390791 (* 1 = 0.390791 loss)
I0617 15:14:59.608767  4990 solver.cpp:233] Iteration 162400, loss = 0.000401746
I0617 15:14:59.608793  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000402056 (* 1 = 0.000402056 loss)
I0617 15:14:59.608800  4990 sgd_solver.cpp:294] Iteration 162400, lr = 0.0002
I0617 15:32:00.378717  4990 solver.cpp:342] Iteration 162800, Testing net (#0)
I0617 15:33:06.096153  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.931406
I0617 15:33:06.096194  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.370233 (* 1 = 0.370233 loss)
I0617 15:33:08.612392  4990 solver.cpp:233] Iteration 162800, loss = 0.000155142
I0617 15:33:08.612416  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000155451 (* 1 = 0.000155451 loss)
I0617 15:33:08.612424  4990 sgd_solver.cpp:294] Iteration 162800, lr = 0.0002
I0617 15:50:09.503397  4990 solver.cpp:342] Iteration 163200, Testing net (#0)
I0617 15:51:15.212860  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.931562
I0617 15:51:15.212908  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.381964 (* 1 = 0.381964 loss)
I0617 15:51:17.727196  4990 solver.cpp:233] Iteration 163200, loss = 0.00023864
I0617 15:51:17.727223  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000238949 (* 1 = 0.000238949 loss)
I0617 15:51:17.727236  4990 sgd_solver.cpp:294] Iteration 163200, lr = 0.0002
I0617 16:08:18.525075  4990 solver.cpp:342] Iteration 163600, Testing net (#0)
I0617 16:09:24.203671  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929297
I0617 16:09:24.203716  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.376719 (* 1 = 0.376719 loss)
I0617 16:09:26.720968  4990 solver.cpp:233] Iteration 163600, loss = 0.000293289
I0617 16:09:26.720993  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000293598 (* 1 = 0.000293598 loss)
I0617 16:09:26.721000  4990 sgd_solver.cpp:294] Iteration 163600, lr = 0.0002
I0617 16:26:27.588153  4990 solver.cpp:342] Iteration 164000, Testing net (#0)
I0617 16:27:33.266222  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929375
I0617 16:27:33.266265  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.379246 (* 1 = 0.379246 loss)
I0617 16:27:35.782140  4990 solver.cpp:233] Iteration 164000, loss = 0.000213543
I0617 16:27:35.782166  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000213852 (* 1 = 0.000213852 loss)
I0617 16:27:35.782173  4990 sgd_solver.cpp:294] Iteration 164000, lr = 0.0002
I0617 16:44:36.526530  4990 solver.cpp:342] Iteration 164400, Testing net (#0)
I0617 16:45:42.196499  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929688
I0617 16:45:42.196544  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.392384 (* 1 = 0.392384 loss)
I0617 16:45:44.711438  4990 solver.cpp:233] Iteration 164400, loss = 0.000326357
I0617 16:45:44.711462  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000326666 (* 1 = 0.000326666 loss)
I0617 16:45:44.711469  4990 sgd_solver.cpp:294] Iteration 164400, lr = 0.0002
I0617 17:02:45.575309  4990 solver.cpp:342] Iteration 164800, Testing net (#0)
I0617 17:03:51.245097  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.926797
I0617 17:03:51.245141  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.393097 (* 1 = 0.393097 loss)
I0617 17:03:53.760789  4990 solver.cpp:233] Iteration 164800, loss = 0.000733121
I0617 17:03:53.760812  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00073343 (* 1 = 0.00073343 loss)
I0617 17:03:53.760819  4990 sgd_solver.cpp:294] Iteration 164800, lr = 0.0002
I0617 17:20:54.581753  4990 solver.cpp:342] Iteration 165200, Testing net (#0)
I0617 17:22:00.269876  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928203
I0617 17:22:00.269920  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.387818 (* 1 = 0.387818 loss)
I0617 17:22:02.784426  4990 solver.cpp:233] Iteration 165200, loss = 0.000276411
I0617 17:22:02.784458  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00027672 (* 1 = 0.00027672 loss)
I0617 17:22:02.784466  4990 sgd_solver.cpp:294] Iteration 165200, lr = 0.0002
I0617 17:39:03.647933  4990 solver.cpp:342] Iteration 165600, Testing net (#0)
I0617 17:40:09.321388  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928984
I0617 17:40:09.321431  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.385888 (* 1 = 0.385888 loss)
I0617 17:40:11.838737  4990 solver.cpp:233] Iteration 165600, loss = 0.00040696
I0617 17:40:11.838759  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000407269 (* 1 = 0.000407269 loss)
I0617 17:40:11.838767  4990 sgd_solver.cpp:294] Iteration 165600, lr = 0.0002
I0617 17:57:12.709177  4990 solver.cpp:342] Iteration 166000, Testing net (#0)
I0617 17:58:18.400521  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929844
I0617 17:58:18.400568  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.395697 (* 1 = 0.395697 loss)
I0617 17:58:20.915251  4990 solver.cpp:233] Iteration 166000, loss = 0.000134316
I0617 17:58:20.915278  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000134625 (* 1 = 0.000134625 loss)
I0617 17:58:20.915287  4990 sgd_solver.cpp:294] Iteration 166000, lr = 0.0002
I0617 18:15:21.583343  4990 solver.cpp:342] Iteration 166400, Testing net (#0)
I0617 18:16:27.266181  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929375
I0617 18:16:27.266223  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.383086 (* 1 = 0.383086 loss)
I0617 18:16:29.784589  4990 solver.cpp:233] Iteration 166400, loss = 0.000193805
I0617 18:16:29.784615  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000194114 (* 1 = 0.000194114 loss)
I0617 18:16:29.784622  4990 sgd_solver.cpp:294] Iteration 166400, lr = 0.0002
I0617 18:33:30.688235  4990 solver.cpp:342] Iteration 166800, Testing net (#0)
I0617 18:34:36.326448  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930313
I0617 18:34:36.326490  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.371178 (* 1 = 0.371178 loss)
I0617 18:34:38.841603  4990 solver.cpp:233] Iteration 166800, loss = 0.000596007
I0617 18:34:38.841627  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000596316 (* 1 = 0.000596316 loss)
I0617 18:34:38.841634  4990 sgd_solver.cpp:294] Iteration 166800, lr = 0.0002
I0617 18:51:39.597045  4990 solver.cpp:342] Iteration 167200, Testing net (#0)
I0617 18:52:45.307091  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930234
I0617 18:52:45.307149  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.383597 (* 1 = 0.383597 loss)
I0617 18:52:47.822135  4990 solver.cpp:233] Iteration 167200, loss = 0.000439178
I0617 18:52:47.822157  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000439486 (* 1 = 0.000439486 loss)
I0617 18:52:47.822165  4990 sgd_solver.cpp:294] Iteration 167200, lr = 0.0002
I0617 19:09:48.672072  4990 solver.cpp:342] Iteration 167600, Testing net (#0)
I0617 19:10:54.351107  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.925937
I0617 19:10:54.351147  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.39481 (* 1 = 0.39481 loss)
I0617 19:10:56.866590  4990 solver.cpp:233] Iteration 167600, loss = 0.000281298
I0617 19:10:56.866612  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000281607 (* 1 = 0.000281607 loss)
I0617 19:10:56.866619  4990 sgd_solver.cpp:294] Iteration 167600, lr = 0.0002
I0617 19:27:57.697358  4990 solver.cpp:342] Iteration 168000, Testing net (#0)
I0617 19:29:03.380293  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.926797
I0617 19:29:03.380338  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.388085 (* 1 = 0.388085 loss)
I0617 19:29:05.897052  4990 solver.cpp:233] Iteration 168000, loss = 0.000271537
I0617 19:29:05.897078  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000271846 (* 1 = 0.000271846 loss)
I0617 19:29:05.897085  4990 sgd_solver.cpp:294] Iteration 168000, lr = 0.0002
I0617 19:46:06.697973  4990 solver.cpp:342] Iteration 168400, Testing net (#0)
I0617 19:47:12.390367  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930781
I0617 19:47:12.390416  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.374649 (* 1 = 0.374649 loss)
I0617 19:47:14.907073  4990 solver.cpp:233] Iteration 168400, loss = 0.000653899
I0617 19:47:14.907099  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000654207 (* 1 = 0.000654207 loss)
I0617 19:47:14.907106  4990 sgd_solver.cpp:294] Iteration 168400, lr = 0.0002
I0617 20:04:15.803266  4990 solver.cpp:342] Iteration 168800, Testing net (#0)
I0617 20:05:21.473846  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929219
I0617 20:05:21.473891  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.393229 (* 1 = 0.393229 loss)
I0617 20:05:23.988808  4990 solver.cpp:233] Iteration 168800, loss = 0.000228656
I0617 20:05:23.988831  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000228964 (* 1 = 0.000228964 loss)
I0617 20:05:23.988838  4990 sgd_solver.cpp:294] Iteration 168800, lr = 0.0002
I0617 20:22:24.889634  4990 solver.cpp:342] Iteration 169200, Testing net (#0)
I0617 20:23:30.548848  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929453
I0617 20:23:30.548893  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.387476 (* 1 = 0.387476 loss)
I0617 20:23:33.063880  4990 solver.cpp:233] Iteration 169200, loss = 0.000167504
I0617 20:23:33.063905  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000167813 (* 1 = 0.000167813 loss)
I0617 20:23:33.063911  4990 sgd_solver.cpp:294] Iteration 169200, lr = 0.0002
I0617 20:40:33.897387  4990 solver.cpp:342] Iteration 169600, Testing net (#0)
I0617 20:41:39.590831  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930938
I0617 20:41:39.590875  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.362342 (* 1 = 0.362342 loss)
I0617 20:41:42.110337  4990 solver.cpp:233] Iteration 169600, loss = 0.00103521
I0617 20:41:42.110364  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00103552 (* 1 = 0.00103552 loss)
I0617 20:41:42.110371  4990 sgd_solver.cpp:294] Iteration 169600, lr = 0.0002
I0617 20:58:42.907145  4990 solver.cpp:342] Iteration 170000, Testing net (#0)
I0617 20:59:48.592483  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929062
I0617 20:59:48.592520  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.385186 (* 1 = 0.385186 loss)
I0617 20:59:51.107796  4990 solver.cpp:233] Iteration 170000, loss = 0.000503278
I0617 20:59:51.107825  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000503586 (* 1 = 0.000503586 loss)
I0617 20:59:51.107832  4990 sgd_solver.cpp:294] Iteration 170000, lr = 0.0002
I0617 21:16:51.903043  4990 solver.cpp:342] Iteration 170400, Testing net (#0)
I0617 21:17:57.588446  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930234
I0617 21:17:57.588487  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.386047 (* 1 = 0.386047 loss)
I0617 21:18:00.105239  4990 solver.cpp:233] Iteration 170400, loss = 0.000263111
I0617 21:18:00.105267  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000263419 (* 1 = 0.000263419 loss)
I0617 21:18:00.105273  4990 sgd_solver.cpp:294] Iteration 170400, lr = 0.0002
I0617 21:35:00.967600  4990 solver.cpp:342] Iteration 170800, Testing net (#0)
I0617 21:36:06.674299  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927813
I0617 21:36:06.674345  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.381614 (* 1 = 0.381614 loss)
I0617 21:36:09.191748  4990 solver.cpp:233] Iteration 170800, loss = 0.000345492
I0617 21:36:09.191772  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.0003458 (* 1 = 0.0003458 loss)
I0617 21:36:09.191779  4990 sgd_solver.cpp:294] Iteration 170800, lr = 0.0002
I0617 21:53:10.028285  4990 solver.cpp:342] Iteration 171200, Testing net (#0)
I0617 21:54:15.703234  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.926641
I0617 21:54:15.703279  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.394352 (* 1 = 0.394352 loss)
I0617 21:54:18.218380  4990 solver.cpp:233] Iteration 171200, loss = 0.000522422
I0617 21:54:18.218405  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000522731 (* 1 = 0.000522731 loss)
I0617 21:54:18.218412  4990 sgd_solver.cpp:294] Iteration 171200, lr = 0.0002
I0617 22:11:19.054318  4990 solver.cpp:342] Iteration 171600, Testing net (#0)
I0617 22:12:24.734969  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928203
I0617 22:12:24.735013  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.394493 (* 1 = 0.394493 loss)
I0617 22:12:27.251951  4990 solver.cpp:233] Iteration 171600, loss = 0.000400326
I0617 22:12:27.251981  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000400634 (* 1 = 0.000400634 loss)
I0617 22:12:27.251989  4990 sgd_solver.cpp:294] Iteration 171600, lr = 0.0002
I0617 22:29:27.998409  4990 solver.cpp:342] Iteration 172000, Testing net (#0)
I0617 22:30:33.622609  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929141
I0617 22:30:33.622653  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.383017 (* 1 = 0.383017 loss)
I0617 22:30:36.135761  4990 solver.cpp:233] Iteration 172000, loss = 9.37422e-05
I0617 22:30:36.135782  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 9.40503e-05 (* 1 = 9.40503e-05 loss)
I0617 22:30:36.135789  4990 sgd_solver.cpp:294] Iteration 172000, lr = 0.0002
I0617 22:47:36.900279  4990 solver.cpp:342] Iteration 172400, Testing net (#0)
I0617 22:48:42.566730  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927344
I0617 22:48:42.566768  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.378491 (* 1 = 0.378491 loss)
I0617 22:48:45.081943  4990 solver.cpp:233] Iteration 172400, loss = 0.000253462
I0617 22:48:45.081966  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00025377 (* 1 = 0.00025377 loss)
I0617 22:48:45.081972  4990 sgd_solver.cpp:294] Iteration 172400, lr = 0.0002
I0617 23:05:45.812137  4990 solver.cpp:342] Iteration 172800, Testing net (#0)
I0617 23:06:51.504287  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929297
I0617 23:06:51.504344  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.382273 (* 1 = 0.382273 loss)
I0617 23:06:54.020511  4990 solver.cpp:233] Iteration 172800, loss = 0.000302996
I0617 23:06:54.020539  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000303304 (* 1 = 0.000303304 loss)
I0617 23:06:54.020545  4990 sgd_solver.cpp:294] Iteration 172800, lr = 0.0002
I0617 23:23:54.825935  4990 solver.cpp:342] Iteration 173200, Testing net (#0)
I0617 23:25:00.496176  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927969
I0617 23:25:00.496220  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.404341 (* 1 = 0.404341 loss)
I0617 23:25:03.012991  4990 solver.cpp:233] Iteration 173200, loss = 0.000117323
I0617 23:25:03.013015  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000117631 (* 1 = 0.000117631 loss)
I0617 23:25:03.013022  4990 sgd_solver.cpp:294] Iteration 173200, lr = 0.0002
I0617 23:42:03.667826  4990 solver.cpp:342] Iteration 173600, Testing net (#0)
I0617 23:43:09.352031  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929766
I0617 23:43:09.352077  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.384385 (* 1 = 0.384385 loss)
I0617 23:43:11.865828  4990 solver.cpp:233] Iteration 173600, loss = 0.000112005
I0617 23:43:11.865854  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000112314 (* 1 = 0.000112314 loss)
I0617 23:43:11.865861  4990 sgd_solver.cpp:294] Iteration 173600, lr = 0.0002
I0618 00:00:12.405292  4990 solver.cpp:342] Iteration 174000, Testing net (#0)
I0618 00:01:18.086351  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927891
I0618 00:01:18.086419  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.380774 (* 1 = 0.380774 loss)
I0618 00:01:20.603209  4990 solver.cpp:233] Iteration 174000, loss = 0.000175886
I0618 00:01:20.603234  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000176194 (* 1 = 0.000176194 loss)
I0618 00:01:20.603241  4990 sgd_solver.cpp:294] Iteration 174000, lr = 0.0002
I0618 00:18:21.196756  4990 solver.cpp:342] Iteration 174400, Testing net (#0)
I0618 00:19:26.886196  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927969
I0618 00:19:26.886241  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.390239 (* 1 = 0.390239 loss)
I0618 00:19:29.403254  4990 solver.cpp:233] Iteration 174400, loss = 0.000204147
I0618 00:19:29.403278  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000204456 (* 1 = 0.000204456 loss)
I0618 00:19:29.403286  4990 sgd_solver.cpp:294] Iteration 174400, lr = 0.0002
I0618 00:36:30.117058  4990 solver.cpp:342] Iteration 174800, Testing net (#0)
I0618 00:37:35.804335  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928359
I0618 00:37:35.804380  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.388137 (* 1 = 0.388137 loss)
I0618 00:37:38.320628  4990 solver.cpp:233] Iteration 174800, loss = 0.000382137
I0618 00:37:38.320657  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000382445 (* 1 = 0.000382445 loss)
I0618 00:37:38.320664  4990 sgd_solver.cpp:294] Iteration 174800, lr = 0.0002
I0618 00:54:39.209013  4990 solver.cpp:342] Iteration 175200, Testing net (#0)
I0618 00:55:44.933794  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929062
I0618 00:55:44.933832  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.386333 (* 1 = 0.386333 loss)
I0618 00:55:47.449308  4990 solver.cpp:233] Iteration 175200, loss = 0.000529781
I0618 00:55:47.449331  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000530089 (* 1 = 0.000530089 loss)
I0618 00:55:47.449338  4990 sgd_solver.cpp:294] Iteration 175200, lr = 0.0002
I0618 01:12:48.345463  4990 solver.cpp:342] Iteration 175600, Testing net (#0)
I0618 01:13:54.070605  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929922
I0618 01:13:54.070647  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.369406 (* 1 = 0.369406 loss)
I0618 01:13:56.587134  4990 solver.cpp:233] Iteration 175600, loss = 0.000412577
I0618 01:13:56.587158  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000412885 (* 1 = 0.000412885 loss)
I0618 01:13:56.587165  4990 sgd_solver.cpp:294] Iteration 175600, lr = 0.0002
I0618 01:30:57.459306  4990 solver.cpp:342] Iteration 176000, Testing net (#0)
I0618 01:32:03.168735  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928125
I0618 01:32:03.168778  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.396599 (* 1 = 0.396599 loss)
I0618 01:32:05.686043  4990 solver.cpp:233] Iteration 176000, loss = 0.00025466
I0618 01:32:05.686070  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000254969 (* 1 = 0.000254969 loss)
I0618 01:32:05.686077  4990 sgd_solver.cpp:294] Iteration 176000, lr = 0.0002
I0618 01:49:06.454525  4990 solver.cpp:342] Iteration 176400, Testing net (#0)
I0618 01:50:12.159497  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.92875
I0618 01:50:12.159538  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.381984 (* 1 = 0.381984 loss)
I0618 01:50:14.674876  4990 solver.cpp:233] Iteration 176400, loss = 0.000235161
I0618 01:50:14.674903  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000235469 (* 1 = 0.000235469 loss)
I0618 01:50:14.674911  4990 sgd_solver.cpp:294] Iteration 176400, lr = 0.0002
I0618 02:07:15.344635  4990 solver.cpp:342] Iteration 176800, Testing net (#0)
I0618 02:08:21.030416  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.93
I0618 02:08:21.030462  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.360136 (* 1 = 0.360136 loss)
I0618 02:08:23.544142  4990 solver.cpp:233] Iteration 176800, loss = 0.000112781
I0618 02:08:23.544174  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000113088 (* 1 = 0.000113088 loss)
I0618 02:08:23.544183  4990 sgd_solver.cpp:294] Iteration 176800, lr = 0.0002
I0618 02:25:24.377189  4990 solver.cpp:342] Iteration 177200, Testing net (#0)
I0618 02:26:30.008829  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929609
I0618 02:26:30.008874  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.385038 (* 1 = 0.385038 loss)
I0618 02:26:32.528280  4990 solver.cpp:233] Iteration 177200, loss = 0.000181679
I0618 02:26:32.528302  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000181986 (* 1 = 0.000181986 loss)
I0618 02:26:32.528311  4990 sgd_solver.cpp:294] Iteration 177200, lr = 0.0002
I0618 02:43:33.351387  4990 solver.cpp:342] Iteration 177600, Testing net (#0)
I0618 02:44:39.045086  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928359
I0618 02:44:39.045128  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.387051 (* 1 = 0.387051 loss)
I0618 02:44:41.561452  4990 solver.cpp:233] Iteration 177600, loss = 0.000636102
I0618 02:44:41.561483  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00063641 (* 1 = 0.00063641 loss)
I0618 02:44:41.561496  4990 sgd_solver.cpp:294] Iteration 177600, lr = 0.0002
I0618 03:01:42.389875  4990 solver.cpp:342] Iteration 178000, Testing net (#0)
I0618 03:02:48.069680  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928281
I0618 03:02:48.069721  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.375786 (* 1 = 0.375786 loss)
I0618 03:02:50.584203  4990 solver.cpp:233] Iteration 178000, loss = 0.000682942
I0618 03:02:50.584226  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00068325 (* 1 = 0.00068325 loss)
I0618 03:02:50.584233  4990 sgd_solver.cpp:294] Iteration 178000, lr = 0.0002
I0618 03:19:51.463214  4990 solver.cpp:342] Iteration 178400, Testing net (#0)
I0618 03:20:57.146405  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930391
I0618 03:20:57.146450  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.39007 (* 1 = 0.39007 loss)
I0618 03:20:59.665380  4990 solver.cpp:233] Iteration 178400, loss = 0.000285186
I0618 03:20:59.665410  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000285495 (* 1 = 0.000285495 loss)
I0618 03:20:59.665416  4990 sgd_solver.cpp:294] Iteration 178400, lr = 0.0002
I0618 03:38:00.476718  4990 solver.cpp:342] Iteration 178800, Testing net (#0)
I0618 03:39:06.163328  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928359
I0618 03:39:06.163372  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.398572 (* 1 = 0.398572 loss)
I0618 03:39:08.677278  4990 solver.cpp:233] Iteration 178800, loss = 0.000540326
I0618 03:39:08.677306  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000540635 (* 1 = 0.000540635 loss)
I0618 03:39:08.677314  4990 sgd_solver.cpp:294] Iteration 178800, lr = 0.0002
I0618 03:56:09.478122  4990 solver.cpp:342] Iteration 179200, Testing net (#0)
I0618 03:57:15.132639  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927891
I0618 03:57:15.132684  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.384537 (* 1 = 0.384537 loss)
I0618 03:57:17.648764  4990 solver.cpp:233] Iteration 179200, loss = 0.000233029
I0618 03:57:17.648788  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000233338 (* 1 = 0.000233338 loss)
I0618 03:57:17.648795  4990 sgd_solver.cpp:294] Iteration 179200, lr = 0.0002
I0618 04:14:18.445750  4990 solver.cpp:342] Iteration 179600, Testing net (#0)
I0618 04:15:24.136672  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929531
I0618 04:15:24.136713  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.374422 (* 1 = 0.374422 loss)
I0618 04:15:26.653030  4990 solver.cpp:233] Iteration 179600, loss = 0.000113135
I0618 04:15:26.653058  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000113445 (* 1 = 0.000113445 loss)
I0618 04:15:26.653064  4990 sgd_solver.cpp:294] Iteration 179600, lr = 0.0002
I0618 04:32:27.392884  4990 solver.cpp:342] Iteration 180000, Testing net (#0)
I0618 04:33:33.080533  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928281
I0618 04:33:33.080575  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.386464 (* 1 = 0.386464 loss)
I0618 04:33:35.594863  4990 solver.cpp:233] Iteration 180000, loss = 0.000173082
I0618 04:33:35.594889  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000173392 (* 1 = 0.000173392 loss)
I0618 04:33:35.594897  4990 sgd_solver.cpp:294] Iteration 180000, lr = 0.0002
I0618 04:50:36.332972  4990 solver.cpp:342] Iteration 180400, Testing net (#0)
I0618 04:51:41.994529  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929453
I0618 04:51:41.994570  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.383768 (* 1 = 0.383768 loss)
I0618 04:51:44.512629  4990 solver.cpp:233] Iteration 180400, loss = 0.000409388
I0618 04:51:44.512655  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000409699 (* 1 = 0.000409699 loss)
I0618 04:51:44.512661  4990 sgd_solver.cpp:294] Iteration 180400, lr = 0.0002
I0618 05:08:45.261335  4990 solver.cpp:342] Iteration 180800, Testing net (#0)
I0618 05:09:50.933339  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928984
I0618 05:09:50.933382  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.375592 (* 1 = 0.375592 loss)
I0618 05:09:53.450130  4990 solver.cpp:233] Iteration 180800, loss = 0.000161715
I0618 05:09:53.450152  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000162026 (* 1 = 0.000162026 loss)
I0618 05:09:53.450160  4990 sgd_solver.cpp:294] Iteration 180800, lr = 0.0002
I0618 05:26:54.339613  4990 solver.cpp:342] Iteration 181200, Testing net (#0)
I0618 05:28:00.095063  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929375
I0618 05:28:00.095103  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.371624 (* 1 = 0.371624 loss)
I0618 05:28:02.610190  4990 solver.cpp:233] Iteration 181200, loss = 0.000116393
I0618 05:28:02.610215  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000116703 (* 1 = 0.000116703 loss)
I0618 05:28:02.610224  4990 sgd_solver.cpp:294] Iteration 181200, lr = 0.0002
I0618 05:45:03.568672  4990 solver.cpp:342] Iteration 181600, Testing net (#0)
I0618 05:46:09.238122  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927266
I0618 05:46:09.238165  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.396344 (* 1 = 0.396344 loss)
I0618 05:46:11.755935  4990 solver.cpp:233] Iteration 181600, loss = 0.000160689
I0618 05:46:11.755962  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000160998 (* 1 = 0.000160998 loss)
I0618 05:46:11.755970  4990 sgd_solver.cpp:294] Iteration 181600, lr = 0.0002
I0618 06:03:12.705786  4990 solver.cpp:342] Iteration 182000, Testing net (#0)
I0618 06:04:18.422844  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928203
I0618 06:04:18.422884  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.375545 (* 1 = 0.375545 loss)
I0618 06:04:20.941143  4990 solver.cpp:233] Iteration 182000, loss = 9.88384e-05
I0618 06:04:20.941169  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 9.91479e-05 (* 1 = 9.91479e-05 loss)
I0618 06:04:20.941175  4990 sgd_solver.cpp:294] Iteration 182000, lr = 0.0002
I0618 06:21:21.881592  4990 solver.cpp:342] Iteration 182400, Testing net (#0)
I0618 06:22:27.623227  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927891
I0618 06:22:27.623273  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.38215 (* 1 = 0.38215 loss)
I0618 06:22:30.140110  4990 solver.cpp:233] Iteration 182400, loss = 0.000264483
I0618 06:22:30.140141  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000264793 (* 1 = 0.000264793 loss)
I0618 06:22:30.140149  4990 sgd_solver.cpp:294] Iteration 182400, lr = 0.0002
I0618 06:39:30.992720  4990 solver.cpp:342] Iteration 182800, Testing net (#0)
I0618 06:40:36.617494  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930313
I0618 06:40:36.617534  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.373609 (* 1 = 0.373609 loss)
I0618 06:40:39.131714  4990 solver.cpp:233] Iteration 182800, loss = 0.000163169
I0618 06:40:39.131743  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000163479 (* 1 = 0.000163479 loss)
I0618 06:40:39.131752  4990 sgd_solver.cpp:294] Iteration 182800, lr = 0.0002
I0618 06:57:39.457408  4990 solver.cpp:342] Iteration 183200, Testing net (#0)
I0618 06:58:44.363653  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928359
I0618 06:58:44.363697  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.390108 (* 1 = 0.390108 loss)
I0618 06:58:46.863623  4990 solver.cpp:233] Iteration 183200, loss = 0.000220399
I0618 06:58:46.863664  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000220709 (* 1 = 0.000220709 loss)
I0618 06:58:46.863672  4990 sgd_solver.cpp:294] Iteration 183200, lr = 0.0002
I0618 07:15:47.231273  4990 solver.cpp:342] Iteration 183600, Testing net (#0)
I0618 07:16:52.938179  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930469
I0618 07:16:52.938230  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.378372 (* 1 = 0.378372 loss)
I0618 07:16:55.456897  4990 solver.cpp:233] Iteration 183600, loss = 0.000194059
I0618 07:16:55.456921  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000194368 (* 1 = 0.000194368 loss)
I0618 07:16:55.456928  4990 sgd_solver.cpp:294] Iteration 183600, lr = 0.0002
I0618 07:33:55.657789  4990 solver.cpp:342] Iteration 184000, Testing net (#0)
I0618 07:35:01.353858  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927422
I0618 07:35:01.353904  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.373927 (* 1 = 0.373927 loss)
I0618 07:35:03.870162  4990 solver.cpp:233] Iteration 184000, loss = 0.000140829
I0618 07:35:03.870187  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000141138 (* 1 = 0.000141138 loss)
I0618 07:35:03.870194  4990 sgd_solver.cpp:294] Iteration 184000, lr = 0.0002
I0618 07:52:04.183779  4990 solver.cpp:342] Iteration 184400, Testing net (#0)
I0618 07:53:08.542371  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928281
I0618 07:53:08.542421  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.396452 (* 1 = 0.396452 loss)
I0618 07:53:11.050534  4990 solver.cpp:233] Iteration 184400, loss = 0.000118141
I0618 07:53:11.050567  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000118451 (* 1 = 0.000118451 loss)
I0618 07:53:11.050575  4990 sgd_solver.cpp:294] Iteration 184400, lr = 0.0002
I0618 08:10:10.497875  4990 solver.cpp:342] Iteration 184800, Testing net (#0)
I0618 08:11:16.180857  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928828
I0618 08:11:16.180897  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.390021 (* 1 = 0.390021 loss)
I0618 08:11:18.697125  4990 solver.cpp:233] Iteration 184800, loss = 0.000304313
I0618 08:11:18.697149  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000304623 (* 1 = 0.000304623 loss)
I0618 08:11:18.697156  4990 sgd_solver.cpp:294] Iteration 184800, lr = 0.0002
I0618 08:28:19.584393  4990 solver.cpp:342] Iteration 185200, Testing net (#0)
I0618 08:29:25.271841  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930703
I0618 08:29:25.271879  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.37591 (* 1 = 0.37591 loss)
I0618 08:29:27.786808  4990 solver.cpp:233] Iteration 185200, loss = 0.000521601
I0618 08:29:27.786831  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00052191 (* 1 = 0.00052191 loss)
I0618 08:29:27.786839  4990 sgd_solver.cpp:294] Iteration 185200, lr = 0.0002
I0618 08:46:28.237613  4990 solver.cpp:342] Iteration 185600, Testing net (#0)
I0618 08:47:33.893334  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.92875
I0618 08:47:33.893378  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.379304 (* 1 = 0.379304 loss)
I0618 08:47:36.409123  4990 solver.cpp:233] Iteration 185600, loss = 0.000489143
I0618 08:47:36.409152  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000489453 (* 1 = 0.000489453 loss)
I0618 08:47:36.409158  4990 sgd_solver.cpp:294] Iteration 185600, lr = 0.0002
I0618 09:04:32.707718  4990 solver.cpp:342] Iteration 186000, Testing net (#0)
I0618 09:05:37.046748  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.93
I0618 09:05:37.046793  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.386013 (* 1 = 0.386013 loss)
I0618 09:05:39.560184  4990 solver.cpp:233] Iteration 186000, loss = 0.00030546
I0618 09:05:39.560209  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00030577 (* 1 = 0.00030577 loss)
I0618 09:05:39.560216  4990 sgd_solver.cpp:294] Iteration 186000, lr = 0.0002
I0618 09:22:35.875881  4990 solver.cpp:342] Iteration 186400, Testing net (#0)
I0618 09:23:40.120700  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927969
I0618 09:23:40.120738  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.381866 (* 1 = 0.381866 loss)
I0618 09:23:42.619979  4990 solver.cpp:233] Iteration 186400, loss = 0.000300398
I0618 09:23:42.620008  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000300709 (* 1 = 0.000300709 loss)
I0618 09:23:42.620015  4990 sgd_solver.cpp:294] Iteration 186400, lr = 0.0002
I0618 09:40:39.172718  4990 solver.cpp:342] Iteration 186800, Testing net (#0)
I0618 09:41:43.605350  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930156
I0618 09:41:43.605387  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.372114 (* 1 = 0.372114 loss)
I0618 09:41:46.110520  4990 solver.cpp:233] Iteration 186800, loss = 0.000654784
I0618 09:41:46.110548  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000655095 (* 1 = 0.000655095 loss)
I0618 09:41:46.110554  4990 sgd_solver.cpp:294] Iteration 186800, lr = 0.0002
I0618 09:58:43.734035  4990 solver.cpp:342] Iteration 187200, Testing net (#0)
I0618 09:59:48.017982  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930547
I0618 09:59:48.018020  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.380591 (* 1 = 0.380591 loss)
I0618 09:59:50.563009  4990 solver.cpp:233] Iteration 187200, loss = 0.000287738
I0618 09:59:50.563042  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00028805 (* 1 = 0.00028805 loss)
I0618 09:59:50.563050  4990 sgd_solver.cpp:294] Iteration 187200, lr = 0.0002
I0618 10:16:47.621562  4990 solver.cpp:342] Iteration 187600, Testing net (#0)
I0618 10:17:51.825956  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928203
I0618 10:17:51.825999  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.390399 (* 1 = 0.390399 loss)
I0618 10:17:54.333536  4990 solver.cpp:233] Iteration 187600, loss = 0.000154754
I0618 10:17:54.333566  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000155065 (* 1 = 0.000155065 loss)
I0618 10:17:54.333573  4990 sgd_solver.cpp:294] Iteration 187600, lr = 0.0002
I0618 10:34:52.871649  4990 solver.cpp:342] Iteration 188000, Testing net (#0)
I0618 10:35:57.203390  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928047
I0618 10:35:57.203428  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.379911 (* 1 = 0.379911 loss)
I0618 10:35:59.709734  4990 solver.cpp:233] Iteration 188000, loss = 0.000481387
I0618 10:35:59.709758  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000481698 (* 1 = 0.000481698 loss)
I0618 10:35:59.709765  4990 sgd_solver.cpp:294] Iteration 188000, lr = 0.0002
I0618 10:52:57.105813  4990 solver.cpp:342] Iteration 188400, Testing net (#0)
I0618 10:54:01.533684  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928359
I0618 10:54:01.533720  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.381922 (* 1 = 0.381922 loss)
I0618 10:54:04.093185  4990 solver.cpp:233] Iteration 188400, loss = 0.000340318
I0618 10:54:04.093214  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000340628 (* 1 = 0.000340628 loss)
I0618 10:54:04.093220  4990 sgd_solver.cpp:294] Iteration 188400, lr = 0.0002
I0618 11:11:01.858245  4990 solver.cpp:342] Iteration 188800, Testing net (#0)
I0618 11:12:06.080574  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929844
I0618 11:12:06.080612  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.39065 (* 1 = 0.39065 loss)
I0618 11:12:08.581312  4990 solver.cpp:233] Iteration 188800, loss = 0.000154948
I0618 11:12:08.581334  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000155257 (* 1 = 0.000155257 loss)
I0618 11:12:08.581341  4990 sgd_solver.cpp:294] Iteration 188800, lr = 0.0002
I0618 11:29:05.114382  4990 solver.cpp:342] Iteration 189200, Testing net (#0)
I0618 11:30:09.409114  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.926172
I0618 11:30:09.409154  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.392819 (* 1 = 0.392819 loss)
I0618 11:30:11.923718  4990 solver.cpp:233] Iteration 189200, loss = 0.000546825
I0618 11:30:11.923748  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000547134 (* 1 = 0.000547134 loss)
I0618 11:30:11.923755  4990 sgd_solver.cpp:294] Iteration 189200, lr = 0.0002
I0618 11:47:08.482133  4990 solver.cpp:342] Iteration 189600, Testing net (#0)
I0618 11:48:12.616519  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927969
I0618 11:48:12.616569  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.38264 (* 1 = 0.38264 loss)
I0618 11:48:15.146636  4990 solver.cpp:233] Iteration 189600, loss = 0.000281807
I0618 11:48:15.146663  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000282116 (* 1 = 0.000282116 loss)
I0618 11:48:15.146672  4990 sgd_solver.cpp:294] Iteration 189600, lr = 0.0002
I0618 12:05:11.897152  4990 solver.cpp:342] Iteration 190000, Testing net (#0)
I0618 12:06:16.228757  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930859
I0618 12:06:16.228802  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.379634 (* 1 = 0.379634 loss)
I0618 12:06:18.736027  4990 solver.cpp:233] Iteration 190000, loss = 0.000124695
I0618 12:06:18.736075  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000125004 (* 1 = 0.000125004 loss)
I0618 12:06:18.736085  4990 sgd_solver.cpp:294] Iteration 190000, lr = 0.0002
I0618 12:23:17.249310  4990 solver.cpp:342] Iteration 190400, Testing net (#0)
I0618 12:24:21.800302  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930313
I0618 12:24:21.800348  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.394565 (* 1 = 0.394565 loss)
I0618 12:24:24.305420  4990 solver.cpp:233] Iteration 190400, loss = 0.000230642
I0618 12:24:24.305466  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00023095 (* 1 = 0.00023095 loss)
I0618 12:24:24.305475  4990 sgd_solver.cpp:294] Iteration 190400, lr = 0.0002
I0618 12:41:34.723987  4990 solver.cpp:342] Iteration 190800, Testing net (#0)
I0618 12:42:39.092608  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928906
I0618 12:42:39.092653  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.385093 (* 1 = 0.385093 loss)
I0618 12:42:41.671741  4990 solver.cpp:233] Iteration 190800, loss = 0.00027069
I0618 12:42:41.671787  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000270998 (* 1 = 0.000270998 loss)
I0618 12:42:41.671795  4990 sgd_solver.cpp:294] Iteration 190800, lr = 0.0002
I0618 13:00:04.101898  4990 solver.cpp:342] Iteration 191200, Testing net (#0)
I0618 13:01:08.334018  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929609
I0618 13:01:08.334059  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.380392 (* 1 = 0.380392 loss)
I0618 13:01:10.841552  4990 solver.cpp:233] Iteration 191200, loss = 0.000508477
I0618 13:01:10.841588  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000508785 (* 1 = 0.000508785 loss)
I0618 13:01:10.841594  4990 sgd_solver.cpp:294] Iteration 191200, lr = 0.0002
I0618 13:18:36.516252  4990 solver.cpp:342] Iteration 191600, Testing net (#0)
I0618 13:19:40.955267  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928906
I0618 13:19:40.955314  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.394667 (* 1 = 0.394667 loss)
I0618 13:19:43.538249  4990 solver.cpp:233] Iteration 191600, loss = 0.000183215
I0618 13:19:43.538290  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000183524 (* 1 = 0.000183524 loss)
I0618 13:19:43.538297  4990 sgd_solver.cpp:294] Iteration 191600, lr = 0.0002
I0618 13:37:09.701591  4990 solver.cpp:342] Iteration 192000, Testing net (#0)
I0618 13:38:14.158035  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928516
I0618 13:38:14.158077  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.390838 (* 1 = 0.390838 loss)
I0618 13:38:16.761705  4990 solver.cpp:233] Iteration 192000, loss = 6.425e-05
I0618 13:38:16.761746  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 6.45587e-05 (* 1 = 6.45587e-05 loss)
I0618 13:38:16.761760  4990 sgd_solver.cpp:294] Iteration 192000, lr = 0.0002
I0618 13:55:26.203694  4990 solver.cpp:342] Iteration 192400, Testing net (#0)
I0618 13:56:30.728691  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927188
I0618 13:56:30.728742  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.393574 (* 1 = 0.393574 loss)
I0618 13:56:33.231612  4990 solver.cpp:233] Iteration 192400, loss = 0.000254202
I0618 13:56:33.231647  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000254511 (* 1 = 0.000254511 loss)
I0618 13:56:33.231654  4990 sgd_solver.cpp:294] Iteration 192400, lr = 0.0002
I0618 14:13:30.988867  4990 solver.cpp:342] Iteration 192800, Testing net (#0)
I0618 14:14:35.317288  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930625
I0618 14:14:35.317332  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.373244 (* 1 = 0.373244 loss)
I0618 14:14:37.824085  4990 solver.cpp:233] Iteration 192800, loss = 0.000216483
I0618 14:14:37.824126  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000216791 (* 1 = 0.000216791 loss)
I0618 14:14:37.824136  4990 sgd_solver.cpp:294] Iteration 192800, lr = 0.0002
I0618 14:31:36.189147  4990 solver.cpp:342] Iteration 193200, Testing net (#0)
I0618 14:32:40.749320  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.927891
I0618 14:32:40.749367  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.400325 (* 1 = 0.400325 loss)
I0618 14:32:43.252049  4990 solver.cpp:233] Iteration 193200, loss = 0.000178766
I0618 14:32:43.252099  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000179075 (* 1 = 0.000179075 loss)
I0618 14:32:43.252110  4990 sgd_solver.cpp:294] Iteration 193200, lr = 0.0002
I0618 14:49:41.275872  4990 solver.cpp:342] Iteration 193600, Testing net (#0)
I0618 14:50:45.823657  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928828
I0618 14:50:45.823694  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.385898 (* 1 = 0.385898 loss)
I0618 14:50:48.327806  4990 solver.cpp:233] Iteration 193600, loss = 0.000586176
I0618 14:50:48.327844  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000586485 (* 1 = 0.000586485 loss)
I0618 14:50:48.327852  4990 sgd_solver.cpp:294] Iteration 193600, lr = 0.0002
I0618 15:07:46.519291  4990 solver.cpp:342] Iteration 194000, Testing net (#0)
I0618 15:08:51.039700  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930938
I0618 15:08:51.039746  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.373431 (* 1 = 0.373431 loss)
I0618 15:08:53.541344  4990 solver.cpp:233] Iteration 194000, loss = 0.000330436
I0618 15:08:53.541381  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000330744 (* 1 = 0.000330744 loss)
I0618 15:08:53.541389  4990 sgd_solver.cpp:294] Iteration 194000, lr = 0.0002
I0618 15:25:51.937489  4990 solver.cpp:342] Iteration 194400, Testing net (#0)
I0618 15:26:56.229079  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930078
I0618 15:26:56.229122  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.38892 (* 1 = 0.38892 loss)
I0618 15:26:58.732012  4990 solver.cpp:233] Iteration 194400, loss = 0.000229072
I0618 15:26:58.732046  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00022938 (* 1 = 0.00022938 loss)
I0618 15:26:58.732055  4990 sgd_solver.cpp:294] Iteration 194400, lr = 0.0002
I0618 15:43:56.790545  4990 solver.cpp:342] Iteration 194800, Testing net (#0)
I0618 15:45:01.276798  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930234
I0618 15:45:01.276847  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.37815 (* 1 = 0.37815 loss)
I0618 15:45:03.783953  4990 solver.cpp:233] Iteration 194800, loss = 0.000788743
I0618 15:45:03.783989  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000789051 (* 1 = 0.000789051 loss)
I0618 15:45:03.783998  4990 sgd_solver.cpp:294] Iteration 194800, lr = 0.0002
I0618 16:02:01.926600  4990 solver.cpp:342] Iteration 195200, Testing net (#0)
I0618 16:03:06.502243  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.93
I0618 16:03:06.502296  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.380555 (* 1 = 0.380555 loss)
I0618 16:03:09.017931  4990 solver.cpp:233] Iteration 195200, loss = 0.000440358
I0618 16:03:09.017973  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000440666 (* 1 = 0.000440666 loss)
I0618 16:03:09.017982  4990 sgd_solver.cpp:294] Iteration 195200, lr = 0.0002
I0618 16:20:07.065573  4990 solver.cpp:342] Iteration 195600, Testing net (#0)
I0618 16:21:11.672304  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929453
I0618 16:21:11.672369  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.370503 (* 1 = 0.370503 loss)
I0618 16:21:14.180829  4990 solver.cpp:233] Iteration 195600, loss = 0.000383731
I0618 16:21:14.180867  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000384039 (* 1 = 0.000384039 loss)
I0618 16:21:14.180876  4990 sgd_solver.cpp:294] Iteration 195600, lr = 0.0002
I0618 16:38:12.537704  4990 solver.cpp:342] Iteration 196000, Testing net (#0)
I0618 16:39:16.932214  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929297
I0618 16:39:16.932258  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.39822 (* 1 = 0.39822 loss)
I0618 16:39:19.434828  4990 solver.cpp:233] Iteration 196000, loss = 0.000180156
I0618 16:39:19.434862  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000180466 (* 1 = 0.000180466 loss)
I0618 16:39:19.434871  4990 sgd_solver.cpp:294] Iteration 196000, lr = 0.0002
I0618 16:56:17.229837  4990 solver.cpp:342] Iteration 196400, Testing net (#0)
I0618 16:57:21.813068  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929609
I0618 16:57:21.813112  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.377277 (* 1 = 0.377277 loss)
I0618 16:57:24.334585  4990 solver.cpp:233] Iteration 196400, loss = 7.28154e-05
I0618 16:57:24.334625  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 7.31252e-05 (* 1 = 7.31252e-05 loss)
I0618 16:57:24.334632  4990 sgd_solver.cpp:294] Iteration 196400, lr = 0.0002
I0618 17:14:23.316252  4990 solver.cpp:342] Iteration 196800, Testing net (#0)
I0618 17:15:27.878260  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929922
I0618 17:15:27.878303  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.375298 (* 1 = 0.375298 loss)
I0618 17:15:30.381101  4990 solver.cpp:233] Iteration 196800, loss = 0.000148278
I0618 17:15:30.381160  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000148587 (* 1 = 0.000148587 loss)
I0618 17:15:30.381176  4990 sgd_solver.cpp:294] Iteration 196800, lr = 0.0002
I0618 17:32:28.780323  4990 solver.cpp:342] Iteration 197200, Testing net (#0)
I0618 17:33:33.278069  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929453
I0618 17:33:33.278117  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.39052 (* 1 = 0.39052 loss)
I0618 17:33:35.783126  4990 solver.cpp:233] Iteration 197200, loss = 0.000515318
I0618 17:33:35.783157  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000515627 (* 1 = 0.000515627 loss)
I0618 17:33:35.783164  4990 sgd_solver.cpp:294] Iteration 197200, lr = 0.0002
I0618 17:50:33.939559  4990 solver.cpp:342] Iteration 197600, Testing net (#0)
I0618 17:51:38.287777  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.9275
I0618 17:51:38.287816  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.390029 (* 1 = 0.390029 loss)
I0618 17:51:40.796401  4990 solver.cpp:233] Iteration 197600, loss = 0.000106888
I0618 17:51:40.796437  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000107196 (* 1 = 0.000107196 loss)
I0618 17:51:40.796445  4990 sgd_solver.cpp:294] Iteration 197600, lr = 0.0002
I0618 18:08:38.875867  4990 solver.cpp:342] Iteration 198000, Testing net (#0)
I0618 18:09:43.361356  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930625
I0618 18:09:43.361398  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.375707 (* 1 = 0.375707 loss)
I0618 18:09:45.864984  4990 solver.cpp:233] Iteration 198000, loss = 0.000180522
I0618 18:09:45.865017  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.00018083 (* 1 = 0.00018083 loss)
I0618 18:09:45.865025  4990 sgd_solver.cpp:294] Iteration 198000, lr = 0.0002
I0618 18:26:44.042346  4990 solver.cpp:342] Iteration 198400, Testing net (#0)
I0618 18:27:48.909159  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.930156
I0618 18:27:48.909206  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.388186 (* 1 = 0.388186 loss)
I0618 18:27:51.413723  4990 solver.cpp:233] Iteration 198400, loss = 0.000360453
I0618 18:27:51.413763  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000360761 (* 1 = 0.000360761 loss)
I0618 18:27:51.413772  4990 sgd_solver.cpp:294] Iteration 198400, lr = 0.0002
I0618 18:44:49.334293  4990 solver.cpp:342] Iteration 198800, Testing net (#0)
I0618 18:45:53.840909  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929609
I0618 18:45:53.840952  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.398518 (* 1 = 0.398518 loss)
I0618 18:45:56.342928  4990 solver.cpp:233] Iteration 198800, loss = 0.000330293
I0618 18:45:56.342968  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000330602 (* 1 = 0.000330602 loss)
I0618 18:45:56.342978  4990 sgd_solver.cpp:294] Iteration 198800, lr = 0.0002
I0618 19:02:54.487946  4990 solver.cpp:342] Iteration 199200, Testing net (#0)
I0618 19:03:59.137712  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929297
I0618 19:03:59.137754  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.383181 (* 1 = 0.383181 loss)
I0618 19:04:01.647187  4990 solver.cpp:233] Iteration 199200, loss = 0.000445759
I0618 19:04:01.647233  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000446068 (* 1 = 0.000446068 loss)
I0618 19:04:01.647241  4990 sgd_solver.cpp:294] Iteration 199200, lr = 0.0002
I0618 19:21:00.108394  4990 solver.cpp:342] Iteration 199600, Testing net (#0)
I0618 19:22:04.582168  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.928984
I0618 19:22:04.582214  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.382419 (* 1 = 0.382419 loss)
I0618 19:22:07.087784  4990 solver.cpp:233] Iteration 199600, loss = 0.00012402
I0618 19:22:07.087819  4990 solver.cpp:249]     Train net output #0: SoftmaxWithLoss1 = 0.000124329 (* 1 = 0.000124329 loss)
I0618 19:22:07.087826  4990 sgd_solver.cpp:294] Iteration 199600, lr = 0.0002
I0618 19:39:05.068451  4990 solver.cpp:459] Snapshotting to binary proto file _iter_200000.caffemodel
I0618 19:39:05.277593  4990 sgd_solver.cpp:458] Snapshotting solver state to binary proto file _iter_200000.solverstate
I0618 19:39:06.023056  4990 solver.cpp:322] Iteration 200000, loss = 0.000498833
I0618 19:39:06.023087  4990 solver.cpp:342] Iteration 200000, Testing net (#0)
I0618 19:40:10.390678  4990 solver.cpp:409]     Test net output #0: Accuracy = 0.929922
I0618 19:40:10.390733  4990 solver.cpp:409]     Test net output #1: SoftmaxWithLoss1 = 0.383526 (* 1 = 0.383526 loss)
I0618 19:40:10.390743  4990 solver.cpp:327] Optimization Done.
