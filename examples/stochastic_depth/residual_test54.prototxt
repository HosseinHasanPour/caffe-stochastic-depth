layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_test_leveldb_padding1"
    batch_size: 2
    backend: LEVELDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution21"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution22"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution22"
  top: "Convolution22"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Convolution22"
  top: "Convolution23"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution23"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution24"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution25"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution26"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution27"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution28"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution28"
  top: "Convolution28"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution29"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution30"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "Convolution30"
  top: "Convolution30"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Convolution30"
  top: "Convolution31"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise15"
  type: "Eltwise"
  bottom: "Eltwise14"
  bottom: "Convolution31"
  top: "Eltwise15"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "Eltwise15"
  top: "Eltwise15"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Eltwise15"
  top: "Convolution32"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm32"
  type: "BatchNorm"
  bottom: "Convolution32"
  top: "Convolution32"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale32"
  type: "Scale"
  bottom: "Convolution32"
  top: "Convolution32"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU32"
  type: "ReLU"
  bottom: "Convolution32"
  top: "Convolution32"
}
layer {
  name: "Convolution33"
  type: "Convolution"
  bottom: "Convolution32"
  top: "Convolution33"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm33"
  type: "BatchNorm"
  bottom: "Convolution33"
  top: "Convolution33"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale33"
  type: "Scale"
  bottom: "Convolution33"
  top: "Convolution33"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise16"
  type: "Eltwise"
  bottom: "Eltwise15"
  bottom: "Convolution33"
  top: "Eltwise16"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU33"
  type: "ReLU"
  bottom: "Eltwise16"
  top: "Eltwise16"
}
layer {
  name: "Convolution34"
  type: "Convolution"
  bottom: "Eltwise16"
  top: "Convolution34"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm34"
  type: "BatchNorm"
  bottom: "Convolution34"
  top: "Convolution34"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale34"
  type: "Scale"
  bottom: "Convolution34"
  top: "Convolution34"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU34"
  type: "ReLU"
  bottom: "Convolution34"
  top: "Convolution34"
}
layer {
  name: "Convolution35"
  type: "Convolution"
  bottom: "Convolution34"
  top: "Convolution35"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm35"
  type: "BatchNorm"
  bottom: "Convolution35"
  top: "Convolution35"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale35"
  type: "Scale"
  bottom: "Convolution35"
  top: "Convolution35"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise17"
  type: "Eltwise"
  bottom: "Eltwise16"
  bottom: "Convolution35"
  top: "Eltwise17"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU35"
  type: "ReLU"
  bottom: "Eltwise17"
  top: "Eltwise17"
}
layer {
  name: "Convolution36"
  type: "Convolution"
  bottom: "Eltwise17"
  top: "Convolution36"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm36"
  type: "BatchNorm"
  bottom: "Convolution36"
  top: "Convolution36"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale36"
  type: "Scale"
  bottom: "Convolution36"
  top: "Convolution36"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU36"
  type: "ReLU"
  bottom: "Convolution36"
  top: "Convolution36"
}
layer {
  name: "Convolution37"
  type: "Convolution"
  bottom: "Convolution36"
  top: "Convolution37"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm37"
  type: "BatchNorm"
  bottom: "Convolution37"
  top: "Convolution37"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale37"
  type: "Scale"
  bottom: "Convolution37"
  top: "Convolution37"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise18"
  type: "Eltwise"
  bottom: "Eltwise17"
  bottom: "Convolution37"
  top: "Eltwise18"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU37"
  type: "ReLU"
  bottom: "Eltwise18"
  top: "Eltwise18"
}
layer {
  name: "Convolution38"
  type: "Convolution"
  bottom: "Eltwise18"
  top: "Convolution38"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm38"
  type: "BatchNorm"
  bottom: "Convolution38"
  top: "Convolution38"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale38"
  type: "Scale"
  bottom: "Convolution38"
  top: "Convolution38"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU38"
  type: "ReLU"
  bottom: "Convolution38"
  top: "Convolution38"
}
layer {
  name: "Convolution39"
  type: "Convolution"
  bottom: "Convolution38"
  top: "Convolution39"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm39"
  type: "BatchNorm"
  bottom: "Convolution39"
  top: "Convolution39"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale39"
  type: "Scale"
  bottom: "Convolution39"
  top: "Convolution39"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise19"
  type: "Eltwise"
  bottom: "Eltwise18"
  bottom: "Convolution39"
  top: "Eltwise19"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU39"
  type: "ReLU"
  bottom: "Eltwise19"
  top: "Eltwise19"
}
layer {
  name: "Convolution40"
  type: "Convolution"
  bottom: "Eltwise19"
  top: "Convolution40"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm40"
  type: "BatchNorm"
  bottom: "Convolution40"
  top: "Convolution40"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale40"
  type: "Scale"
  bottom: "Convolution40"
  top: "Convolution40"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU40"
  type: "ReLU"
  bottom: "Convolution40"
  top: "Convolution40"
}
layer {
  name: "Convolution41"
  type: "Convolution"
  bottom: "Convolution40"
  top: "Convolution41"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm41"
  type: "BatchNorm"
  bottom: "Convolution41"
  top: "Convolution41"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale41"
  type: "Scale"
  bottom: "Convolution41"
  top: "Convolution41"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise20"
  type: "Eltwise"
  bottom: "Eltwise19"
  bottom: "Convolution41"
  top: "Eltwise20"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU41"
  type: "ReLU"
  bottom: "Eltwise20"
  top: "Eltwise20"
}
layer {
  name: "Convolution42"
  type: "Convolution"
  bottom: "Eltwise20"
  top: "Convolution42"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm42"
  type: "BatchNorm"
  bottom: "Convolution42"
  top: "Convolution42"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale42"
  type: "Scale"
  bottom: "Convolution42"
  top: "Convolution42"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU42"
  type: "ReLU"
  bottom: "Convolution42"
  top: "Convolution42"
}
layer {
  name: "Convolution43"
  type: "Convolution"
  bottom: "Convolution42"
  top: "Convolution43"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm43"
  type: "BatchNorm"
  bottom: "Convolution43"
  top: "Convolution43"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale43"
  type: "Scale"
  bottom: "Convolution43"
  top: "Convolution43"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise21"
  type: "Eltwise"
  bottom: "Eltwise20"
  bottom: "Convolution43"
  top: "Eltwise21"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU43"
  type: "ReLU"
  bottom: "Eltwise21"
  top: "Eltwise21"
}
layer {
  name: "Convolution44"
  type: "Convolution"
  bottom: "Eltwise21"
  top: "Convolution44"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm44"
  type: "BatchNorm"
  bottom: "Convolution44"
  top: "Convolution44"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale44"
  type: "Scale"
  bottom: "Convolution44"
  top: "Convolution44"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU44"
  type: "ReLU"
  bottom: "Convolution44"
  top: "Convolution44"
}
layer {
  name: "Convolution45"
  type: "Convolution"
  bottom: "Convolution44"
  top: "Convolution45"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm45"
  type: "BatchNorm"
  bottom: "Convolution45"
  top: "Convolution45"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale45"
  type: "Scale"
  bottom: "Convolution45"
  top: "Convolution45"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise22"
  type: "Eltwise"
  bottom: "Eltwise21"
  bottom: "Convolution45"
  top: "Eltwise22"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU45"
  type: "ReLU"
  bottom: "Eltwise22"
  top: "Eltwise22"
}
layer {
  name: "Convolution46"
  type: "Convolution"
  bottom: "Eltwise22"
  top: "Convolution46"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm46"
  type: "BatchNorm"
  bottom: "Convolution46"
  top: "Convolution46"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale46"
  type: "Scale"
  bottom: "Convolution46"
  top: "Convolution46"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU46"
  type: "ReLU"
  bottom: "Convolution46"
  top: "Convolution46"
}
layer {
  name: "Convolution47"
  type: "Convolution"
  bottom: "Convolution46"
  top: "Convolution47"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm47"
  type: "BatchNorm"
  bottom: "Convolution47"
  top: "Convolution47"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale47"
  type: "Scale"
  bottom: "Convolution47"
  top: "Convolution47"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise23"
  type: "Eltwise"
  bottom: "Eltwise22"
  bottom: "Convolution47"
  top: "Eltwise23"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU47"
  type: "ReLU"
  bottom: "Eltwise23"
  top: "Eltwise23"
}
layer {
  name: "Convolution48"
  type: "Convolution"
  bottom: "Eltwise23"
  top: "Convolution48"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm48"
  type: "BatchNorm"
  bottom: "Convolution48"
  top: "Convolution48"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale48"
  type: "Scale"
  bottom: "Convolution48"
  top: "Convolution48"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU48"
  type: "ReLU"
  bottom: "Convolution48"
  top: "Convolution48"
}
layer {
  name: "Convolution49"
  type: "Convolution"
  bottom: "Convolution48"
  top: "Convolution49"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm49"
  type: "BatchNorm"
  bottom: "Convolution49"
  top: "Convolution49"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale49"
  type: "Scale"
  bottom: "Convolution49"
  top: "Convolution49"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise24"
  type: "Eltwise"
  bottom: "Eltwise23"
  bottom: "Convolution49"
  top: "Eltwise24"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU49"
  type: "ReLU"
  bottom: "Eltwise24"
  top: "Eltwise24"
}
layer {
  name: "Convolution50"
  type: "Convolution"
  bottom: "Eltwise24"
  top: "Convolution50"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm50"
  type: "BatchNorm"
  bottom: "Convolution50"
  top: "Convolution50"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale50"
  type: "Scale"
  bottom: "Convolution50"
  top: "Convolution50"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU50"
  type: "ReLU"
  bottom: "Convolution50"
  top: "Convolution50"
}
layer {
  name: "Convolution51"
  type: "Convolution"
  bottom: "Convolution50"
  top: "Convolution51"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm51"
  type: "BatchNorm"
  bottom: "Convolution51"
  top: "Convolution51"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale51"
  type: "Scale"
  bottom: "Convolution51"
  top: "Convolution51"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise25"
  type: "Eltwise"
  bottom: "Eltwise24"
  bottom: "Convolution51"
  top: "Eltwise25"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU51"
  type: "ReLU"
  bottom: "Eltwise25"
  top: "Eltwise25"
}
layer {
  name: "Convolution52"
  type: "Convolution"
  bottom: "Eltwise25"
  top: "Convolution52"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm52"
  type: "BatchNorm"
  bottom: "Convolution52"
  top: "Convolution52"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale52"
  type: "Scale"
  bottom: "Convolution52"
  top: "Convolution52"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU52"
  type: "ReLU"
  bottom: "Convolution52"
  top: "Convolution52"
}
layer {
  name: "Convolution53"
  type: "Convolution"
  bottom: "Convolution52"
  top: "Convolution53"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm53"
  type: "BatchNorm"
  bottom: "Convolution53"
  top: "Convolution53"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale53"
  type: "Scale"
  bottom: "Convolution53"
  top: "Convolution53"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise26"
  type: "Eltwise"
  bottom: "Eltwise25"
  bottom: "Convolution53"
  top: "Eltwise26"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU53"
  type: "ReLU"
  bottom: "Eltwise26"
  top: "Eltwise26"
}
layer {
  name: "Convolution54"
  type: "Convolution"
  bottom: "Eltwise26"
  top: "Convolution54"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm54"
  type: "BatchNorm"
  bottom: "Convolution54"
  top: "Convolution54"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale54"
  type: "Scale"
  bottom: "Convolution54"
  top: "Convolution54"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU54"
  type: "ReLU"
  bottom: "Convolution54"
  top: "Convolution54"
}
layer {
  name: "Convolution55"
  type: "Convolution"
  bottom: "Convolution54"
  top: "Convolution55"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm55"
  type: "BatchNorm"
  bottom: "Convolution55"
  top: "Convolution55"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale55"
  type: "Scale"
  bottom: "Convolution55"
  top: "Convolution55"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise27"
  type: "Eltwise"
  bottom: "Eltwise26"
  bottom: "Convolution55"
  top: "Eltwise27"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU55"
  type: "ReLU"
  bottom: "Eltwise27"
  top: "Eltwise27"
}
layer {
  name: "Convolution56"
  type: "Convolution"
  bottom: "Eltwise27"
  top: "Convolution56"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm56"
  type: "BatchNorm"
  bottom: "Convolution56"
  top: "Convolution56"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale56"
  type: "Scale"
  bottom: "Convolution56"
  top: "Convolution56"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU56"
  type: "ReLU"
  bottom: "Convolution56"
  top: "Convolution56"
}
layer {
  name: "Convolution57"
  type: "Convolution"
  bottom: "Convolution56"
  top: "Convolution57"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm57"
  type: "BatchNorm"
  bottom: "Convolution57"
  top: "Convolution57"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale57"
  type: "Scale"
  bottom: "Convolution57"
  top: "Convolution57"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise28"
  type: "Eltwise"
  bottom: "Eltwise27"
  bottom: "Convolution57"
  top: "Eltwise28"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU57"
  type: "ReLU"
  bottom: "Eltwise28"
  top: "Eltwise28"
}
layer {
  name: "Convolution58"
  type: "Convolution"
  bottom: "Eltwise28"
  top: "Convolution58"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm58"
  type: "BatchNorm"
  bottom: "Convolution58"
  top: "Convolution58"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale58"
  type: "Scale"
  bottom: "Convolution58"
  top: "Convolution58"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU58"
  type: "ReLU"
  bottom: "Convolution58"
  top: "Convolution58"
}
layer {
  name: "Convolution59"
  type: "Convolution"
  bottom: "Convolution58"
  top: "Convolution59"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm59"
  type: "BatchNorm"
  bottom: "Convolution59"
  top: "Convolution59"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale59"
  type: "Scale"
  bottom: "Convolution59"
  top: "Convolution59"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise29"
  type: "Eltwise"
  bottom: "Eltwise28"
  bottom: "Convolution59"
  top: "Eltwise29"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU59"
  type: "ReLU"
  bottom: "Eltwise29"
  top: "Eltwise29"
}
layer {
  name: "Convolution60"
  type: "Convolution"
  bottom: "Eltwise29"
  top: "Convolution60"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm60"
  type: "BatchNorm"
  bottom: "Convolution60"
  top: "Convolution60"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale60"
  type: "Scale"
  bottom: "Convolution60"
  top: "Convolution60"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU60"
  type: "ReLU"
  bottom: "Convolution60"
  top: "Convolution60"
}
layer {
  name: "Convolution61"
  type: "Convolution"
  bottom: "Convolution60"
  top: "Convolution61"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm61"
  type: "BatchNorm"
  bottom: "Convolution61"
  top: "Convolution61"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale61"
  type: "Scale"
  bottom: "Convolution61"
  top: "Convolution61"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise30"
  type: "Eltwise"
  bottom: "Eltwise29"
  bottom: "Convolution61"
  top: "Eltwise30"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU61"
  type: "ReLU"
  bottom: "Eltwise30"
  top: "Eltwise30"
}
layer {
  name: "Convolution62"
  type: "Convolution"
  bottom: "Eltwise30"
  top: "Convolution62"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm62"
  type: "BatchNorm"
  bottom: "Convolution62"
  top: "Convolution62"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale62"
  type: "Scale"
  bottom: "Convolution62"
  top: "Convolution62"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU62"
  type: "ReLU"
  bottom: "Convolution62"
  top: "Convolution62"
}
layer {
  name: "Convolution63"
  type: "Convolution"
  bottom: "Convolution62"
  top: "Convolution63"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm63"
  type: "BatchNorm"
  bottom: "Convolution63"
  top: "Convolution63"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale63"
  type: "Scale"
  bottom: "Convolution63"
  top: "Convolution63"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise31"
  type: "Eltwise"
  bottom: "Eltwise30"
  bottom: "Convolution63"
  top: "Eltwise31"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU63"
  type: "ReLU"
  bottom: "Eltwise31"
  top: "Eltwise31"
}
layer {
  name: "Convolution64"
  type: "Convolution"
  bottom: "Eltwise31"
  top: "Convolution64"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm64"
  type: "BatchNorm"
  bottom: "Convolution64"
  top: "Convolution64"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale64"
  type: "Scale"
  bottom: "Convolution64"
  top: "Convolution64"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU64"
  type: "ReLU"
  bottom: "Convolution64"
  top: "Convolution64"
}
layer {
  name: "Convolution65"
  type: "Convolution"
  bottom: "Convolution64"
  top: "Convolution65"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm65"
  type: "BatchNorm"
  bottom: "Convolution65"
  top: "Convolution65"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale65"
  type: "Scale"
  bottom: "Convolution65"
  top: "Convolution65"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise32"
  type: "Eltwise"
  bottom: "Eltwise31"
  bottom: "Convolution65"
  top: "Eltwise32"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU65"
  type: "ReLU"
  bottom: "Eltwise32"
  top: "Eltwise32"
}
layer {
  name: "Convolution66"
  type: "Convolution"
  bottom: "Eltwise32"
  top: "Convolution66"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm66"
  type: "BatchNorm"
  bottom: "Convolution66"
  top: "Convolution66"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale66"
  type: "Scale"
  bottom: "Convolution66"
  top: "Convolution66"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU66"
  type: "ReLU"
  bottom: "Convolution66"
  top: "Convolution66"
}
layer {
  name: "Convolution67"
  type: "Convolution"
  bottom: "Convolution66"
  top: "Convolution67"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm67"
  type: "BatchNorm"
  bottom: "Convolution67"
  top: "Convolution67"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale67"
  type: "Scale"
  bottom: "Convolution67"
  top: "Convolution67"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise33"
  type: "Eltwise"
  bottom: "Eltwise32"
  bottom: "Convolution67"
  top: "Eltwise33"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU67"
  type: "ReLU"
  bottom: "Eltwise33"
  top: "Eltwise33"
}
layer {
  name: "Convolution68"
  type: "Convolution"
  bottom: "Eltwise33"
  top: "Convolution68"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm68"
  type: "BatchNorm"
  bottom: "Convolution68"
  top: "Convolution68"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale68"
  type: "Scale"
  bottom: "Convolution68"
  top: "Convolution68"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU68"
  type: "ReLU"
  bottom: "Convolution68"
  top: "Convolution68"
}
layer {
  name: "Convolution69"
  type: "Convolution"
  bottom: "Convolution68"
  top: "Convolution69"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm69"
  type: "BatchNorm"
  bottom: "Convolution69"
  top: "Convolution69"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale69"
  type: "Scale"
  bottom: "Convolution69"
  top: "Convolution69"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise34"
  type: "Eltwise"
  bottom: "Eltwise33"
  bottom: "Convolution69"
  top: "Eltwise34"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU69"
  type: "ReLU"
  bottom: "Eltwise34"
  top: "Eltwise34"
}
layer {
  name: "Convolution70"
  type: "Convolution"
  bottom: "Eltwise34"
  top: "Convolution70"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm70"
  type: "BatchNorm"
  bottom: "Convolution70"
  top: "Convolution70"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale70"
  type: "Scale"
  bottom: "Convolution70"
  top: "Convolution70"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU70"
  type: "ReLU"
  bottom: "Convolution70"
  top: "Convolution70"
}
layer {
  name: "Convolution71"
  type: "Convolution"
  bottom: "Convolution70"
  top: "Convolution71"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm71"
  type: "BatchNorm"
  bottom: "Convolution71"
  top: "Convolution71"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale71"
  type: "Scale"
  bottom: "Convolution71"
  top: "Convolution71"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise35"
  type: "Eltwise"
  bottom: "Eltwise34"
  bottom: "Convolution71"
  top: "Eltwise35"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU71"
  type: "ReLU"
  bottom: "Eltwise35"
  top: "Eltwise35"
}
layer {
  name: "Convolution72"
  type: "Convolution"
  bottom: "Eltwise35"
  top: "Convolution72"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm72"
  type: "BatchNorm"
  bottom: "Convolution72"
  top: "Convolution72"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale72"
  type: "Scale"
  bottom: "Convolution72"
  top: "Convolution72"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU72"
  type: "ReLU"
  bottom: "Convolution72"
  top: "Convolution72"
}
layer {
  name: "Convolution73"
  type: "Convolution"
  bottom: "Convolution72"
  top: "Convolution73"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm73"
  type: "BatchNorm"
  bottom: "Convolution73"
  top: "Convolution73"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale73"
  type: "Scale"
  bottom: "Convolution73"
  top: "Convolution73"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise36"
  type: "Eltwise"
  bottom: "Eltwise35"
  bottom: "Convolution73"
  top: "Eltwise36"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU73"
  type: "ReLU"
  bottom: "Eltwise36"
  top: "Eltwise36"
}
layer {
  name: "Convolution74"
  type: "Convolution"
  bottom: "Eltwise36"
  top: "Convolution74"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm74"
  type: "BatchNorm"
  bottom: "Convolution74"
  top: "Convolution74"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale74"
  type: "Scale"
  bottom: "Convolution74"
  top: "Convolution74"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU74"
  type: "ReLU"
  bottom: "Convolution74"
  top: "Convolution74"
}
layer {
  name: "Convolution75"
  type: "Convolution"
  bottom: "Convolution74"
  top: "Convolution75"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm75"
  type: "BatchNorm"
  bottom: "Convolution75"
  top: "Convolution75"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale75"
  type: "Scale"
  bottom: "Convolution75"
  top: "Convolution75"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise37"
  type: "Eltwise"
  bottom: "Eltwise36"
  bottom: "Convolution75"
  top: "Eltwise37"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU75"
  type: "ReLU"
  bottom: "Eltwise37"
  top: "Eltwise37"
}
layer {
  name: "Convolution76"
  type: "Convolution"
  bottom: "Eltwise37"
  top: "Convolution76"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm76"
  type: "BatchNorm"
  bottom: "Convolution76"
  top: "Convolution76"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale76"
  type: "Scale"
  bottom: "Convolution76"
  top: "Convolution76"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU76"
  type: "ReLU"
  bottom: "Convolution76"
  top: "Convolution76"
}
layer {
  name: "Convolution77"
  type: "Convolution"
  bottom: "Convolution76"
  top: "Convolution77"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm77"
  type: "BatchNorm"
  bottom: "Convolution77"
  top: "Convolution77"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale77"
  type: "Scale"
  bottom: "Convolution77"
  top: "Convolution77"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise38"
  type: "Eltwise"
  bottom: "Eltwise37"
  bottom: "Convolution77"
  top: "Eltwise38"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU77"
  type: "ReLU"
  bottom: "Eltwise38"
  top: "Eltwise38"
}
layer {
  name: "Convolution78"
  type: "Convolution"
  bottom: "Eltwise38"
  top: "Convolution78"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm78"
  type: "BatchNorm"
  bottom: "Convolution78"
  top: "Convolution78"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale78"
  type: "Scale"
  bottom: "Convolution78"
  top: "Convolution78"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU78"
  type: "ReLU"
  bottom: "Convolution78"
  top: "Convolution78"
}
layer {
  name: "Convolution79"
  type: "Convolution"
  bottom: "Convolution78"
  top: "Convolution79"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm79"
  type: "BatchNorm"
  bottom: "Convolution79"
  top: "Convolution79"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale79"
  type: "Scale"
  bottom: "Convolution79"
  top: "Convolution79"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise39"
  type: "Eltwise"
  bottom: "Eltwise38"
  bottom: "Convolution79"
  top: "Eltwise39"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU79"
  type: "ReLU"
  bottom: "Eltwise39"
  top: "Eltwise39"
}
layer {
  name: "Convolution80"
  type: "Convolution"
  bottom: "Eltwise39"
  top: "Convolution80"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm80"
  type: "BatchNorm"
  bottom: "Convolution80"
  top: "Convolution80"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale80"
  type: "Scale"
  bottom: "Convolution80"
  top: "Convolution80"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU80"
  type: "ReLU"
  bottom: "Convolution80"
  top: "Convolution80"
}
layer {
  name: "Convolution81"
  type: "Convolution"
  bottom: "Convolution80"
  top: "Convolution81"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm81"
  type: "BatchNorm"
  bottom: "Convolution81"
  top: "Convolution81"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale81"
  type: "Scale"
  bottom: "Convolution81"
  top: "Convolution81"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise40"
  type: "Eltwise"
  bottom: "Eltwise39"
  bottom: "Convolution81"
  top: "Eltwise40"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU81"
  type: "ReLU"
  bottom: "Eltwise40"
  top: "Eltwise40"
}
layer {
  name: "Convolution82"
  type: "Convolution"
  bottom: "Eltwise40"
  top: "Convolution82"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm82"
  type: "BatchNorm"
  bottom: "Convolution82"
  top: "Convolution82"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale82"
  type: "Scale"
  bottom: "Convolution82"
  top: "Convolution82"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU82"
  type: "ReLU"
  bottom: "Convolution82"
  top: "Convolution82"
}
layer {
  name: "Convolution83"
  type: "Convolution"
  bottom: "Convolution82"
  top: "Convolution83"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm83"
  type: "BatchNorm"
  bottom: "Convolution83"
  top: "Convolution83"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale83"
  type: "Scale"
  bottom: "Convolution83"
  top: "Convolution83"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise41"
  type: "Eltwise"
  bottom: "Eltwise40"
  bottom: "Convolution83"
  top: "Eltwise41"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU83"
  type: "ReLU"
  bottom: "Eltwise41"
  top: "Eltwise41"
}
layer {
  name: "Convolution84"
  type: "Convolution"
  bottom: "Eltwise41"
  top: "Convolution84"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm84"
  type: "BatchNorm"
  bottom: "Convolution84"
  top: "Convolution84"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale84"
  type: "Scale"
  bottom: "Convolution84"
  top: "Convolution84"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU84"
  type: "ReLU"
  bottom: "Convolution84"
  top: "Convolution84"
}
layer {
  name: "Convolution85"
  type: "Convolution"
  bottom: "Convolution84"
  top: "Convolution85"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm85"
  type: "BatchNorm"
  bottom: "Convolution85"
  top: "Convolution85"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale85"
  type: "Scale"
  bottom: "Convolution85"
  top: "Convolution85"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise42"
  type: "Eltwise"
  bottom: "Eltwise41"
  bottom: "Convolution85"
  top: "Eltwise42"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU85"
  type: "ReLU"
  bottom: "Eltwise42"
  top: "Eltwise42"
}
layer {
  name: "Convolution86"
  type: "Convolution"
  bottom: "Eltwise42"
  top: "Convolution86"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm86"
  type: "BatchNorm"
  bottom: "Convolution86"
  top: "Convolution86"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale86"
  type: "Scale"
  bottom: "Convolution86"
  top: "Convolution86"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU86"
  type: "ReLU"
  bottom: "Convolution86"
  top: "Convolution86"
}
layer {
  name: "Convolution87"
  type: "Convolution"
  bottom: "Convolution86"
  top: "Convolution87"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm87"
  type: "BatchNorm"
  bottom: "Convolution87"
  top: "Convolution87"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale87"
  type: "Scale"
  bottom: "Convolution87"
  top: "Convolution87"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise43"
  type: "Eltwise"
  bottom: "Eltwise42"
  bottom: "Convolution87"
  top: "Eltwise43"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU87"
  type: "ReLU"
  bottom: "Eltwise43"
  top: "Eltwise43"
}
layer {
  name: "Convolution88"
  type: "Convolution"
  bottom: "Eltwise43"
  top: "Convolution88"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm88"
  type: "BatchNorm"
  bottom: "Convolution88"
  top: "Convolution88"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale88"
  type: "Scale"
  bottom: "Convolution88"
  top: "Convolution88"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU88"
  type: "ReLU"
  bottom: "Convolution88"
  top: "Convolution88"
}
layer {
  name: "Convolution89"
  type: "Convolution"
  bottom: "Convolution88"
  top: "Convolution89"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm89"
  type: "BatchNorm"
  bottom: "Convolution89"
  top: "Convolution89"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale89"
  type: "Scale"
  bottom: "Convolution89"
  top: "Convolution89"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise44"
  type: "Eltwise"
  bottom: "Eltwise43"
  bottom: "Convolution89"
  top: "Eltwise44"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU89"
  type: "ReLU"
  bottom: "Eltwise44"
  top: "Eltwise44"
}
layer {
  name: "Convolution90"
  type: "Convolution"
  bottom: "Eltwise44"
  top: "Convolution90"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm90"
  type: "BatchNorm"
  bottom: "Convolution90"
  top: "Convolution90"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale90"
  type: "Scale"
  bottom: "Convolution90"
  top: "Convolution90"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU90"
  type: "ReLU"
  bottom: "Convolution90"
  top: "Convolution90"
}
layer {
  name: "Convolution91"
  type: "Convolution"
  bottom: "Convolution90"
  top: "Convolution91"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm91"
  type: "BatchNorm"
  bottom: "Convolution91"
  top: "Convolution91"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale91"
  type: "Scale"
  bottom: "Convolution91"
  top: "Convolution91"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise45"
  type: "Eltwise"
  bottom: "Eltwise44"
  bottom: "Convolution91"
  top: "Eltwise45"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU91"
  type: "ReLU"
  bottom: "Eltwise45"
  top: "Eltwise45"
}
layer {
  name: "Convolution92"
  type: "Convolution"
  bottom: "Eltwise45"
  top: "Convolution92"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm92"
  type: "BatchNorm"
  bottom: "Convolution92"
  top: "Convolution92"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale92"
  type: "Scale"
  bottom: "Convolution92"
  top: "Convolution92"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU92"
  type: "ReLU"
  bottom: "Convolution92"
  top: "Convolution92"
}
layer {
  name: "Convolution93"
  type: "Convolution"
  bottom: "Convolution92"
  top: "Convolution93"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm93"
  type: "BatchNorm"
  bottom: "Convolution93"
  top: "Convolution93"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale93"
  type: "Scale"
  bottom: "Convolution93"
  top: "Convolution93"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise46"
  type: "Eltwise"
  bottom: "Eltwise45"
  bottom: "Convolution93"
  top: "Eltwise46"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU93"
  type: "ReLU"
  bottom: "Eltwise46"
  top: "Eltwise46"
}
layer {
  name: "Convolution94"
  type: "Convolution"
  bottom: "Eltwise46"
  top: "Convolution94"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm94"
  type: "BatchNorm"
  bottom: "Convolution94"
  top: "Convolution94"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale94"
  type: "Scale"
  bottom: "Convolution94"
  top: "Convolution94"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU94"
  type: "ReLU"
  bottom: "Convolution94"
  top: "Convolution94"
}
layer {
  name: "Convolution95"
  type: "Convolution"
  bottom: "Convolution94"
  top: "Convolution95"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm95"
  type: "BatchNorm"
  bottom: "Convolution95"
  top: "Convolution95"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale95"
  type: "Scale"
  bottom: "Convolution95"
  top: "Convolution95"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise47"
  type: "Eltwise"
  bottom: "Eltwise46"
  bottom: "Convolution95"
  top: "Eltwise47"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU95"
  type: "ReLU"
  bottom: "Eltwise47"
  top: "Eltwise47"
}
layer {
  name: "Convolution96"
  type: "Convolution"
  bottom: "Eltwise47"
  top: "Convolution96"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm96"
  type: "BatchNorm"
  bottom: "Convolution96"
  top: "Convolution96"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale96"
  type: "Scale"
  bottom: "Convolution96"
  top: "Convolution96"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU96"
  type: "ReLU"
  bottom: "Convolution96"
  top: "Convolution96"
}
layer {
  name: "Convolution97"
  type: "Convolution"
  bottom: "Convolution96"
  top: "Convolution97"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm97"
  type: "BatchNorm"
  bottom: "Convolution97"
  top: "Convolution97"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale97"
  type: "Scale"
  bottom: "Convolution97"
  top: "Convolution97"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise48"
  type: "Eltwise"
  bottom: "Eltwise47"
  bottom: "Convolution97"
  top: "Eltwise48"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU97"
  type: "ReLU"
  bottom: "Eltwise48"
  top: "Eltwise48"
}
layer {
  name: "Convolution98"
  type: "Convolution"
  bottom: "Eltwise48"
  top: "Convolution98"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm98"
  type: "BatchNorm"
  bottom: "Convolution98"
  top: "Convolution98"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale98"
  type: "Scale"
  bottom: "Convolution98"
  top: "Convolution98"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU98"
  type: "ReLU"
  bottom: "Convolution98"
  top: "Convolution98"
}
layer {
  name: "Convolution99"
  type: "Convolution"
  bottom: "Convolution98"
  top: "Convolution99"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm99"
  type: "BatchNorm"
  bottom: "Convolution99"
  top: "Convolution99"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale99"
  type: "Scale"
  bottom: "Convolution99"
  top: "Convolution99"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise49"
  type: "Eltwise"
  bottom: "Eltwise48"
  bottom: "Convolution99"
  top: "Eltwise49"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU99"
  type: "ReLU"
  bottom: "Eltwise49"
  top: "Eltwise49"
}
layer {
  name: "Convolution100"
  type: "Convolution"
  bottom: "Eltwise49"
  top: "Convolution100"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm100"
  type: "BatchNorm"
  bottom: "Convolution100"
  top: "Convolution100"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale100"
  type: "Scale"
  bottom: "Convolution100"
  top: "Convolution100"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU100"
  type: "ReLU"
  bottom: "Convolution100"
  top: "Convolution100"
}
layer {
  name: "Convolution101"
  type: "Convolution"
  bottom: "Convolution100"
  top: "Convolution101"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm101"
  type: "BatchNorm"
  bottom: "Convolution101"
  top: "Convolution101"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale101"
  type: "Scale"
  bottom: "Convolution101"
  top: "Convolution101"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise50"
  type: "Eltwise"
  bottom: "Eltwise49"
  bottom: "Convolution101"
  top: "Eltwise50"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU101"
  type: "ReLU"
  bottom: "Eltwise50"
  top: "Eltwise50"
}
layer {
  name: "Convolution102"
  type: "Convolution"
  bottom: "Eltwise50"
  top: "Convolution102"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm102"
  type: "BatchNorm"
  bottom: "Convolution102"
  top: "Convolution102"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale102"
  type: "Scale"
  bottom: "Convolution102"
  top: "Convolution102"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU102"
  type: "ReLU"
  bottom: "Convolution102"
  top: "Convolution102"
}
layer {
  name: "Convolution103"
  type: "Convolution"
  bottom: "Convolution102"
  top: "Convolution103"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm103"
  type: "BatchNorm"
  bottom: "Convolution103"
  top: "Convolution103"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale103"
  type: "Scale"
  bottom: "Convolution103"
  top: "Convolution103"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise51"
  type: "Eltwise"
  bottom: "Eltwise50"
  bottom: "Convolution103"
  top: "Eltwise51"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU103"
  type: "ReLU"
  bottom: "Eltwise51"
  top: "Eltwise51"
}
layer {
  name: "Convolution104"
  type: "Convolution"
  bottom: "Eltwise51"
  top: "Convolution104"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm104"
  type: "BatchNorm"
  bottom: "Convolution104"
  top: "Convolution104"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale104"
  type: "Scale"
  bottom: "Convolution104"
  top: "Convolution104"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU104"
  type: "ReLU"
  bottom: "Convolution104"
  top: "Convolution104"
}
layer {
  name: "Convolution105"
  type: "Convolution"
  bottom: "Convolution104"
  top: "Convolution105"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm105"
  type: "BatchNorm"
  bottom: "Convolution105"
  top: "Convolution105"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale105"
  type: "Scale"
  bottom: "Convolution105"
  top: "Convolution105"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise52"
  type: "Eltwise"
  bottom: "Eltwise51"
  bottom: "Convolution105"
  top: "Eltwise52"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU105"
  type: "ReLU"
  bottom: "Eltwise52"
  top: "Eltwise52"
}
layer {
  name: "Convolution106"
  type: "Convolution"
  bottom: "Eltwise52"
  top: "Convolution106"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm106"
  type: "BatchNorm"
  bottom: "Convolution106"
  top: "Convolution106"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale106"
  type: "Scale"
  bottom: "Convolution106"
  top: "Convolution106"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU106"
  type: "ReLU"
  bottom: "Convolution106"
  top: "Convolution106"
}
layer {
  name: "Convolution107"
  type: "Convolution"
  bottom: "Convolution106"
  top: "Convolution107"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm107"
  type: "BatchNorm"
  bottom: "Convolution107"
  top: "Convolution107"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale107"
  type: "Scale"
  bottom: "Convolution107"
  top: "Convolution107"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise53"
  type: "Eltwise"
  bottom: "Eltwise52"
  bottom: "Convolution107"
  top: "Eltwise53"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU107"
  type: "ReLU"
  bottom: "Eltwise53"
  top: "Eltwise53"
}
layer {
  name: "Convolution108"
  type: "Convolution"
  bottom: "Eltwise53"
  top: "Convolution108"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm108"
  type: "BatchNorm"
  bottom: "Convolution108"
  top: "Convolution108"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale108"
  type: "Scale"
  bottom: "Convolution108"
  top: "Convolution108"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU108"
  type: "ReLU"
  bottom: "Convolution108"
  top: "Convolution108"
}
layer {
  name: "Convolution109"
  type: "Convolution"
  bottom: "Convolution108"
  top: "Convolution109"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm109"
  type: "BatchNorm"
  bottom: "Convolution109"
  top: "Convolution109"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale109"
  type: "Scale"
  bottom: "Convolution109"
  top: "Convolution109"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise54"
  type: "Eltwise"
  bottom: "Eltwise53"
  bottom: "Convolution109"
  top: "Eltwise54"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU109"
  type: "ReLU"
  bottom: "Eltwise54"
  top: "Eltwise54"
}
layer {
  name: "Convolution110"
  type: "Convolution"
  bottom: "Eltwise54"
  top: "Convolution110"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm110"
  type: "BatchNorm"
  bottom: "Convolution110"
  top: "Convolution110"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale110"
  type: "Scale"
  bottom: "Convolution110"
  top: "Convolution110"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU110"
  type: "ReLU"
  bottom: "Convolution110"
  top: "Convolution110"
}
layer {
  name: "Convolution111"
  type: "Convolution"
  bottom: "Convolution110"
  top: "Convolution111"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm111"
  type: "BatchNorm"
  bottom: "Convolution111"
  top: "Convolution111"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale111"
  type: "Scale"
  bottom: "Convolution111"
  top: "Convolution111"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise55"
  type: "Eltwise"
  bottom: "Eltwise54"
  bottom: "Convolution111"
  top: "Eltwise55"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU111"
  type: "ReLU"
  bottom: "Eltwise55"
  top: "Eltwise55"
}
layer {
  name: "Convolution112"
  type: "Convolution"
  bottom: "Eltwise55"
  top: "Convolution112"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm112"
  type: "BatchNorm"
  bottom: "Convolution112"
  top: "Convolution112"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale112"
  type: "Scale"
  bottom: "Convolution112"
  top: "Convolution112"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU112"
  type: "ReLU"
  bottom: "Convolution112"
  top: "Convolution112"
}
layer {
  name: "Convolution113"
  type: "Convolution"
  bottom: "Convolution112"
  top: "Convolution113"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm113"
  type: "BatchNorm"
  bottom: "Convolution113"
  top: "Convolution113"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale113"
  type: "Scale"
  bottom: "Convolution113"
  top: "Convolution113"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise56"
  type: "Eltwise"
  bottom: "Eltwise55"
  bottom: "Convolution113"
  top: "Eltwise56"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU113"
  type: "ReLU"
  bottom: "Eltwise56"
  top: "Eltwise56"
}
layer {
  name: "Convolution114"
  type: "Convolution"
  bottom: "Eltwise56"
  top: "Convolution114"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm114"
  type: "BatchNorm"
  bottom: "Convolution114"
  top: "Convolution114"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale114"
  type: "Scale"
  bottom: "Convolution114"
  top: "Convolution114"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU114"
  type: "ReLU"
  bottom: "Convolution114"
  top: "Convolution114"
}
layer {
  name: "Convolution115"
  type: "Convolution"
  bottom: "Convolution114"
  top: "Convolution115"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm115"
  type: "BatchNorm"
  bottom: "Convolution115"
  top: "Convolution115"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale115"
  type: "Scale"
  bottom: "Convolution115"
  top: "Convolution115"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise57"
  type: "Eltwise"
  bottom: "Eltwise56"
  bottom: "Convolution115"
  top: "Eltwise57"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU115"
  type: "ReLU"
  bottom: "Eltwise57"
  top: "Eltwise57"
}
layer {
  name: "Convolution116"
  type: "Convolution"
  bottom: "Eltwise57"
  top: "Convolution116"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm116"
  type: "BatchNorm"
  bottom: "Convolution116"
  top: "Convolution116"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale116"
  type: "Scale"
  bottom: "Convolution116"
  top: "Convolution116"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU116"
  type: "ReLU"
  bottom: "Convolution116"
  top: "Convolution116"
}
layer {
  name: "Convolution117"
  type: "Convolution"
  bottom: "Convolution116"
  top: "Convolution117"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm117"
  type: "BatchNorm"
  bottom: "Convolution117"
  top: "Convolution117"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale117"
  type: "Scale"
  bottom: "Convolution117"
  top: "Convolution117"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise58"
  type: "Eltwise"
  bottom: "Eltwise57"
  bottom: "Convolution117"
  top: "Eltwise58"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU117"
  type: "ReLU"
  bottom: "Eltwise58"
  top: "Eltwise58"
}
layer {
  name: "Convolution118"
  type: "Convolution"
  bottom: "Eltwise58"
  top: "Convolution118"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm118"
  type: "BatchNorm"
  bottom: "Convolution118"
  top: "Convolution118"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale118"
  type: "Scale"
  bottom: "Convolution118"
  top: "Convolution118"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU118"
  type: "ReLU"
  bottom: "Convolution118"
  top: "Convolution118"
}
layer {
  name: "Convolution119"
  type: "Convolution"
  bottom: "Convolution118"
  top: "Convolution119"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm119"
  type: "BatchNorm"
  bottom: "Convolution119"
  top: "Convolution119"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale119"
  type: "Scale"
  bottom: "Convolution119"
  top: "Convolution119"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise59"
  type: "Eltwise"
  bottom: "Eltwise58"
  bottom: "Convolution119"
  top: "Eltwise59"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU119"
  type: "ReLU"
  bottom: "Eltwise59"
  top: "Eltwise59"
}
layer {
  name: "Convolution120"
  type: "Convolution"
  bottom: "Eltwise59"
  top: "Convolution120"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm120"
  type: "BatchNorm"
  bottom: "Convolution120"
  top: "Convolution120"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale120"
  type: "Scale"
  bottom: "Convolution120"
  top: "Convolution120"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU120"
  type: "ReLU"
  bottom: "Convolution120"
  top: "Convolution120"
}
layer {
  name: "Convolution121"
  type: "Convolution"
  bottom: "Convolution120"
  top: "Convolution121"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm121"
  type: "BatchNorm"
  bottom: "Convolution121"
  top: "Convolution121"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale121"
  type: "Scale"
  bottom: "Convolution121"
  top: "Convolution121"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise60"
  type: "Eltwise"
  bottom: "Eltwise59"
  bottom: "Convolution121"
  top: "Eltwise60"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU121"
  type: "ReLU"
  bottom: "Eltwise60"
  top: "Eltwise60"
}
layer {
  name: "Convolution122"
  type: "Convolution"
  bottom: "Eltwise60"
  top: "Convolution122"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm122"
  type: "BatchNorm"
  bottom: "Convolution122"
  top: "Convolution122"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale122"
  type: "Scale"
  bottom: "Convolution122"
  top: "Convolution122"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU122"
  type: "ReLU"
  bottom: "Convolution122"
  top: "Convolution122"
}
layer {
  name: "Convolution123"
  type: "Convolution"
  bottom: "Convolution122"
  top: "Convolution123"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm123"
  type: "BatchNorm"
  bottom: "Convolution123"
  top: "Convolution123"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale123"
  type: "Scale"
  bottom: "Convolution123"
  top: "Convolution123"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise61"
  type: "Eltwise"
  bottom: "Eltwise60"
  bottom: "Convolution123"
  top: "Eltwise61"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU123"
  type: "ReLU"
  bottom: "Eltwise61"
  top: "Eltwise61"
}
layer {
  name: "Convolution124"
  type: "Convolution"
  bottom: "Eltwise61"
  top: "Convolution124"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm124"
  type: "BatchNorm"
  bottom: "Convolution124"
  top: "Convolution124"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale124"
  type: "Scale"
  bottom: "Convolution124"
  top: "Convolution124"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU124"
  type: "ReLU"
  bottom: "Convolution124"
  top: "Convolution124"
}
layer {
  name: "Convolution125"
  type: "Convolution"
  bottom: "Convolution124"
  top: "Convolution125"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm125"
  type: "BatchNorm"
  bottom: "Convolution125"
  top: "Convolution125"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale125"
  type: "Scale"
  bottom: "Convolution125"
  top: "Convolution125"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise62"
  type: "Eltwise"
  bottom: "Eltwise61"
  bottom: "Convolution125"
  top: "Eltwise62"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU125"
  type: "ReLU"
  bottom: "Eltwise62"
  top: "Eltwise62"
}
layer {
  name: "Convolution126"
  type: "Convolution"
  bottom: "Eltwise62"
  top: "Convolution126"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm126"
  type: "BatchNorm"
  bottom: "Convolution126"
  top: "Convolution126"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale126"
  type: "Scale"
  bottom: "Convolution126"
  top: "Convolution126"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU126"
  type: "ReLU"
  bottom: "Convolution126"
  top: "Convolution126"
}
layer {
  name: "Convolution127"
  type: "Convolution"
  bottom: "Convolution126"
  top: "Convolution127"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm127"
  type: "BatchNorm"
  bottom: "Convolution127"
  top: "Convolution127"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale127"
  type: "Scale"
  bottom: "Convolution127"
  top: "Convolution127"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise63"
  type: "Eltwise"
  bottom: "Eltwise62"
  bottom: "Convolution127"
  top: "Eltwise63"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU127"
  type: "ReLU"
  bottom: "Eltwise63"
  top: "Eltwise63"
}
layer {
  name: "Convolution128"
  type: "Convolution"
  bottom: "Eltwise63"
  top: "Convolution128"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm128"
  type: "BatchNorm"
  bottom: "Convolution128"
  top: "Convolution128"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale128"
  type: "Scale"
  bottom: "Convolution128"
  top: "Convolution128"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU128"
  type: "ReLU"
  bottom: "Convolution128"
  top: "Convolution128"
}
layer {
  name: "Convolution129"
  type: "Convolution"
  bottom: "Convolution128"
  top: "Convolution129"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm129"
  type: "BatchNorm"
  bottom: "Convolution129"
  top: "Convolution129"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale129"
  type: "Scale"
  bottom: "Convolution129"
  top: "Convolution129"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise64"
  type: "Eltwise"
  bottom: "Eltwise63"
  bottom: "Convolution129"
  top: "Eltwise64"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU129"
  type: "ReLU"
  bottom: "Eltwise64"
  top: "Eltwise64"
}
layer {
  name: "Convolution130"
  type: "Convolution"
  bottom: "Eltwise64"
  top: "Convolution130"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm130"
  type: "BatchNorm"
  bottom: "Convolution130"
  top: "Convolution130"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale130"
  type: "Scale"
  bottom: "Convolution130"
  top: "Convolution130"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU130"
  type: "ReLU"
  bottom: "Convolution130"
  top: "Convolution130"
}
layer {
  name: "Convolution131"
  type: "Convolution"
  bottom: "Convolution130"
  top: "Convolution131"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm131"
  type: "BatchNorm"
  bottom: "Convolution131"
  top: "Convolution131"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale131"
  type: "Scale"
  bottom: "Convolution131"
  top: "Convolution131"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise65"
  type: "Eltwise"
  bottom: "Eltwise64"
  bottom: "Convolution131"
  top: "Eltwise65"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU131"
  type: "ReLU"
  bottom: "Eltwise65"
  top: "Eltwise65"
}
layer {
  name: "Convolution132"
  type: "Convolution"
  bottom: "Eltwise65"
  top: "Convolution132"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm132"
  type: "BatchNorm"
  bottom: "Convolution132"
  top: "Convolution132"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale132"
  type: "Scale"
  bottom: "Convolution132"
  top: "Convolution132"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU132"
  type: "ReLU"
  bottom: "Convolution132"
  top: "Convolution132"
}
layer {
  name: "Convolution133"
  type: "Convolution"
  bottom: "Convolution132"
  top: "Convolution133"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm133"
  type: "BatchNorm"
  bottom: "Convolution133"
  top: "Convolution133"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale133"
  type: "Scale"
  bottom: "Convolution133"
  top: "Convolution133"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise66"
  type: "Eltwise"
  bottom: "Eltwise65"
  bottom: "Convolution133"
  top: "Eltwise66"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU133"
  type: "ReLU"
  bottom: "Eltwise66"
  top: "Eltwise66"
}
layer {
  name: "Convolution134"
  type: "Convolution"
  bottom: "Eltwise66"
  top: "Convolution134"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm134"
  type: "BatchNorm"
  bottom: "Convolution134"
  top: "Convolution134"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale134"
  type: "Scale"
  bottom: "Convolution134"
  top: "Convolution134"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU134"
  type: "ReLU"
  bottom: "Convolution134"
  top: "Convolution134"
}
layer {
  name: "Convolution135"
  type: "Convolution"
  bottom: "Convolution134"
  top: "Convolution135"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm135"
  type: "BatchNorm"
  bottom: "Convolution135"
  top: "Convolution135"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale135"
  type: "Scale"
  bottom: "Convolution135"
  top: "Convolution135"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise67"
  type: "Eltwise"
  bottom: "Eltwise66"
  bottom: "Convolution135"
  top: "Eltwise67"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU135"
  type: "ReLU"
  bottom: "Eltwise67"
  top: "Eltwise67"
}
layer {
  name: "Convolution136"
  type: "Convolution"
  bottom: "Eltwise67"
  top: "Convolution136"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm136"
  type: "BatchNorm"
  bottom: "Convolution136"
  top: "Convolution136"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale136"
  type: "Scale"
  bottom: "Convolution136"
  top: "Convolution136"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU136"
  type: "ReLU"
  bottom: "Convolution136"
  top: "Convolution136"
}
layer {
  name: "Convolution137"
  type: "Convolution"
  bottom: "Convolution136"
  top: "Convolution137"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm137"
  type: "BatchNorm"
  bottom: "Convolution137"
  top: "Convolution137"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale137"
  type: "Scale"
  bottom: "Convolution137"
  top: "Convolution137"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise68"
  type: "Eltwise"
  bottom: "Eltwise67"
  bottom: "Convolution137"
  top: "Eltwise68"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU137"
  type: "ReLU"
  bottom: "Eltwise68"
  top: "Eltwise68"
}
layer {
  name: "Convolution138"
  type: "Convolution"
  bottom: "Eltwise68"
  top: "Convolution138"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm138"
  type: "BatchNorm"
  bottom: "Convolution138"
  top: "Convolution138"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale138"
  type: "Scale"
  bottom: "Convolution138"
  top: "Convolution138"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU138"
  type: "ReLU"
  bottom: "Convolution138"
  top: "Convolution138"
}
layer {
  name: "Convolution139"
  type: "Convolution"
  bottom: "Convolution138"
  top: "Convolution139"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm139"
  type: "BatchNorm"
  bottom: "Convolution139"
  top: "Convolution139"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale139"
  type: "Scale"
  bottom: "Convolution139"
  top: "Convolution139"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise69"
  type: "Eltwise"
  bottom: "Eltwise68"
  bottom: "Convolution139"
  top: "Eltwise69"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU139"
  type: "ReLU"
  bottom: "Eltwise69"
  top: "Eltwise69"
}
layer {
  name: "Convolution140"
  type: "Convolution"
  bottom: "Eltwise69"
  top: "Convolution140"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm140"
  type: "BatchNorm"
  bottom: "Convolution140"
  top: "Convolution140"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale140"
  type: "Scale"
  bottom: "Convolution140"
  top: "Convolution140"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU140"
  type: "ReLU"
  bottom: "Convolution140"
  top: "Convolution140"
}
layer {
  name: "Convolution141"
  type: "Convolution"
  bottom: "Convolution140"
  top: "Convolution141"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm141"
  type: "BatchNorm"
  bottom: "Convolution141"
  top: "Convolution141"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale141"
  type: "Scale"
  bottom: "Convolution141"
  top: "Convolution141"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise70"
  type: "Eltwise"
  bottom: "Eltwise69"
  bottom: "Convolution141"
  top: "Eltwise70"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU141"
  type: "ReLU"
  bottom: "Eltwise70"
  top: "Eltwise70"
}
layer {
  name: "Convolution142"
  type: "Convolution"
  bottom: "Eltwise70"
  top: "Convolution142"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm142"
  type: "BatchNorm"
  bottom: "Convolution142"
  top: "Convolution142"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale142"
  type: "Scale"
  bottom: "Convolution142"
  top: "Convolution142"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU142"
  type: "ReLU"
  bottom: "Convolution142"
  top: "Convolution142"
}
layer {
  name: "Convolution143"
  type: "Convolution"
  bottom: "Convolution142"
  top: "Convolution143"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm143"
  type: "BatchNorm"
  bottom: "Convolution143"
  top: "Convolution143"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale143"
  type: "Scale"
  bottom: "Convolution143"
  top: "Convolution143"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise71"
  type: "Eltwise"
  bottom: "Eltwise70"
  bottom: "Convolution143"
  top: "Eltwise71"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU143"
  type: "ReLU"
  bottom: "Eltwise71"
  top: "Eltwise71"
}
layer {
  name: "Convolution144"
  type: "Convolution"
  bottom: "Eltwise71"
  top: "Convolution144"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm144"
  type: "BatchNorm"
  bottom: "Convolution144"
  top: "Convolution144"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale144"
  type: "Scale"
  bottom: "Convolution144"
  top: "Convolution144"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU144"
  type: "ReLU"
  bottom: "Convolution144"
  top: "Convolution144"
}
layer {
  name: "Convolution145"
  type: "Convolution"
  bottom: "Convolution144"
  top: "Convolution145"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm145"
  type: "BatchNorm"
  bottom: "Convolution145"
  top: "Convolution145"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale145"
  type: "Scale"
  bottom: "Convolution145"
  top: "Convolution145"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise72"
  type: "Eltwise"
  bottom: "Eltwise71"
  bottom: "Convolution145"
  top: "Eltwise72"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU145"
  type: "ReLU"
  bottom: "Eltwise72"
  top: "Eltwise72"
}
layer {
  name: "Convolution146"
  type: "Convolution"
  bottom: "Eltwise72"
  top: "Convolution146"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm146"
  type: "BatchNorm"
  bottom: "Convolution146"
  top: "Convolution146"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale146"
  type: "Scale"
  bottom: "Convolution146"
  top: "Convolution146"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU146"
  type: "ReLU"
  bottom: "Convolution146"
  top: "Convolution146"
}
layer {
  name: "Convolution147"
  type: "Convolution"
  bottom: "Convolution146"
  top: "Convolution147"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm147"
  type: "BatchNorm"
  bottom: "Convolution147"
  top: "Convolution147"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale147"
  type: "Scale"
  bottom: "Convolution147"
  top: "Convolution147"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise73"
  type: "Eltwise"
  bottom: "Eltwise72"
  bottom: "Convolution147"
  top: "Eltwise73"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU147"
  type: "ReLU"
  bottom: "Eltwise73"
  top: "Eltwise73"
}
layer {
  name: "Convolution148"
  type: "Convolution"
  bottom: "Eltwise73"
  top: "Convolution148"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm148"
  type: "BatchNorm"
  bottom: "Convolution148"
  top: "Convolution148"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale148"
  type: "Scale"
  bottom: "Convolution148"
  top: "Convolution148"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU148"
  type: "ReLU"
  bottom: "Convolution148"
  top: "Convolution148"
}
layer {
  name: "Convolution149"
  type: "Convolution"
  bottom: "Convolution148"
  top: "Convolution149"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm149"
  type: "BatchNorm"
  bottom: "Convolution149"
  top: "Convolution149"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale149"
  type: "Scale"
  bottom: "Convolution149"
  top: "Convolution149"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise74"
  type: "Eltwise"
  bottom: "Eltwise73"
  bottom: "Convolution149"
  top: "Eltwise74"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU149"
  type: "ReLU"
  bottom: "Eltwise74"
  top: "Eltwise74"
}
layer {
  name: "Convolution150"
  type: "Convolution"
  bottom: "Eltwise74"
  top: "Convolution150"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm150"
  type: "BatchNorm"
  bottom: "Convolution150"
  top: "Convolution150"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale150"
  type: "Scale"
  bottom: "Convolution150"
  top: "Convolution150"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU150"
  type: "ReLU"
  bottom: "Convolution150"
  top: "Convolution150"
}
layer {
  name: "Convolution151"
  type: "Convolution"
  bottom: "Convolution150"
  top: "Convolution151"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm151"
  type: "BatchNorm"
  bottom: "Convolution151"
  top: "Convolution151"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale151"
  type: "Scale"
  bottom: "Convolution151"
  top: "Convolution151"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise75"
  type: "Eltwise"
  bottom: "Eltwise74"
  bottom: "Convolution151"
  top: "Eltwise75"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU151"
  type: "ReLU"
  bottom: "Eltwise75"
  top: "Eltwise75"
}
layer {
  name: "Convolution152"
  type: "Convolution"
  bottom: "Eltwise75"
  top: "Convolution152"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm152"
  type: "BatchNorm"
  bottom: "Convolution152"
  top: "Convolution152"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale152"
  type: "Scale"
  bottom: "Convolution152"
  top: "Convolution152"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU152"
  type: "ReLU"
  bottom: "Convolution152"
  top: "Convolution152"
}
layer {
  name: "Convolution153"
  type: "Convolution"
  bottom: "Convolution152"
  top: "Convolution153"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm153"
  type: "BatchNorm"
  bottom: "Convolution153"
  top: "Convolution153"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale153"
  type: "Scale"
  bottom: "Convolution153"
  top: "Convolution153"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise76"
  type: "Eltwise"
  bottom: "Eltwise75"
  bottom: "Convolution153"
  top: "Eltwise76"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU153"
  type: "ReLU"
  bottom: "Eltwise76"
  top: "Eltwise76"
}
layer {
  name: "Convolution154"
  type: "Convolution"
  bottom: "Eltwise76"
  top: "Convolution154"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm154"
  type: "BatchNorm"
  bottom: "Convolution154"
  top: "Convolution154"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale154"
  type: "Scale"
  bottom: "Convolution154"
  top: "Convolution154"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU154"
  type: "ReLU"
  bottom: "Convolution154"
  top: "Convolution154"
}
layer {
  name: "Convolution155"
  type: "Convolution"
  bottom: "Convolution154"
  top: "Convolution155"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm155"
  type: "BatchNorm"
  bottom: "Convolution155"
  top: "Convolution155"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale155"
  type: "Scale"
  bottom: "Convolution155"
  top: "Convolution155"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise77"
  type: "Eltwise"
  bottom: "Eltwise76"
  bottom: "Convolution155"
  top: "Eltwise77"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU155"
  type: "ReLU"
  bottom: "Eltwise77"
  top: "Eltwise77"
}
layer {
  name: "Convolution156"
  type: "Convolution"
  bottom: "Eltwise77"
  top: "Convolution156"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm156"
  type: "BatchNorm"
  bottom: "Convolution156"
  top: "Convolution156"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale156"
  type: "Scale"
  bottom: "Convolution156"
  top: "Convolution156"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU156"
  type: "ReLU"
  bottom: "Convolution156"
  top: "Convolution156"
}
layer {
  name: "Convolution157"
  type: "Convolution"
  bottom: "Convolution156"
  top: "Convolution157"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm157"
  type: "BatchNorm"
  bottom: "Convolution157"
  top: "Convolution157"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale157"
  type: "Scale"
  bottom: "Convolution157"
  top: "Convolution157"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise78"
  type: "Eltwise"
  bottom: "Eltwise77"
  bottom: "Convolution157"
  top: "Eltwise78"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU157"
  type: "ReLU"
  bottom: "Eltwise78"
  top: "Eltwise78"
}
layer {
  name: "Convolution158"
  type: "Convolution"
  bottom: "Eltwise78"
  top: "Convolution158"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm158"
  type: "BatchNorm"
  bottom: "Convolution158"
  top: "Convolution158"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale158"
  type: "Scale"
  bottom: "Convolution158"
  top: "Convolution158"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU158"
  type: "ReLU"
  bottom: "Convolution158"
  top: "Convolution158"
}
layer {
  name: "Convolution159"
  type: "Convolution"
  bottom: "Convolution158"
  top: "Convolution159"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm159"
  type: "BatchNorm"
  bottom: "Convolution159"
  top: "Convolution159"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale159"
  type: "Scale"
  bottom: "Convolution159"
  top: "Convolution159"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise79"
  type: "Eltwise"
  bottom: "Eltwise78"
  bottom: "Convolution159"
  top: "Eltwise79"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU159"
  type: "ReLU"
  bottom: "Eltwise79"
  top: "Eltwise79"
}
layer {
  name: "Convolution160"
  type: "Convolution"
  bottom: "Eltwise79"
  top: "Convolution160"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm160"
  type: "BatchNorm"
  bottom: "Convolution160"
  top: "Convolution160"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale160"
  type: "Scale"
  bottom: "Convolution160"
  top: "Convolution160"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU160"
  type: "ReLU"
  bottom: "Convolution160"
  top: "Convolution160"
}
layer {
  name: "Convolution161"
  type: "Convolution"
  bottom: "Convolution160"
  top: "Convolution161"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm161"
  type: "BatchNorm"
  bottom: "Convolution161"
  top: "Convolution161"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale161"
  type: "Scale"
  bottom: "Convolution161"
  top: "Convolution161"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise80"
  type: "Eltwise"
  bottom: "Eltwise79"
  bottom: "Convolution161"
  top: "Eltwise80"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU161"
  type: "ReLU"
  bottom: "Eltwise80"
  top: "Eltwise80"
}
layer {
  name: "Convolution162"
  type: "Convolution"
  bottom: "Eltwise80"
  top: "Convolution162"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm162"
  type: "BatchNorm"
  bottom: "Convolution162"
  top: "Convolution162"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale162"
  type: "Scale"
  bottom: "Convolution162"
  top: "Convolution162"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU162"
  type: "ReLU"
  bottom: "Convolution162"
  top: "Convolution162"
}
layer {
  name: "Convolution163"
  type: "Convolution"
  bottom: "Convolution162"
  top: "Convolution163"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm163"
  type: "BatchNorm"
  bottom: "Convolution163"
  top: "Convolution163"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale163"
  type: "Scale"
  bottom: "Convolution163"
  top: "Convolution163"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise81"
  type: "Eltwise"
  bottom: "Eltwise80"
  bottom: "Convolution163"
  top: "Eltwise81"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU163"
  type: "ReLU"
  bottom: "Eltwise81"
  top: "Eltwise81"
}
layer {
  name: "Convolution164"
  type: "Convolution"
  bottom: "Eltwise81"
  top: "Convolution164"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm164"
  type: "BatchNorm"
  bottom: "Convolution164"
  top: "Convolution164"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale164"
  type: "Scale"
  bottom: "Convolution164"
  top: "Convolution164"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU164"
  type: "ReLU"
  bottom: "Convolution164"
  top: "Convolution164"
}
layer {
  name: "Convolution165"
  type: "Convolution"
  bottom: "Convolution164"
  top: "Convolution165"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm165"
  type: "BatchNorm"
  bottom: "Convolution165"
  top: "Convolution165"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale165"
  type: "Scale"
  bottom: "Convolution165"
  top: "Convolution165"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise82"
  type: "Eltwise"
  bottom: "Eltwise81"
  bottom: "Convolution165"
  top: "Eltwise82"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU165"
  type: "ReLU"
  bottom: "Eltwise82"
  top: "Eltwise82"
}
layer {
  name: "Convolution166"
  type: "Convolution"
  bottom: "Eltwise82"
  top: "Convolution166"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm166"
  type: "BatchNorm"
  bottom: "Convolution166"
  top: "Convolution166"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale166"
  type: "Scale"
  bottom: "Convolution166"
  top: "Convolution166"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU166"
  type: "ReLU"
  bottom: "Convolution166"
  top: "Convolution166"
}
layer {
  name: "Convolution167"
  type: "Convolution"
  bottom: "Convolution166"
  top: "Convolution167"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm167"
  type: "BatchNorm"
  bottom: "Convolution167"
  top: "Convolution167"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale167"
  type: "Scale"
  bottom: "Convolution167"
  top: "Convolution167"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise83"
  type: "Eltwise"
  bottom: "Eltwise82"
  bottom: "Convolution167"
  top: "Eltwise83"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU167"
  type: "ReLU"
  bottom: "Eltwise83"
  top: "Eltwise83"
}
layer {
  name: "Convolution168"
  type: "Convolution"
  bottom: "Eltwise83"
  top: "Convolution168"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm168"
  type: "BatchNorm"
  bottom: "Convolution168"
  top: "Convolution168"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale168"
  type: "Scale"
  bottom: "Convolution168"
  top: "Convolution168"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU168"
  type: "ReLU"
  bottom: "Convolution168"
  top: "Convolution168"
}
layer {
  name: "Convolution169"
  type: "Convolution"
  bottom: "Convolution168"
  top: "Convolution169"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm169"
  type: "BatchNorm"
  bottom: "Convolution169"
  top: "Convolution169"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale169"
  type: "Scale"
  bottom: "Convolution169"
  top: "Convolution169"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise84"
  type: "Eltwise"
  bottom: "Eltwise83"
  bottom: "Convolution169"
  top: "Eltwise84"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU169"
  type: "ReLU"
  bottom: "Eltwise84"
  top: "Eltwise84"
}
layer {
  name: "Convolution170"
  type: "Convolution"
  bottom: "Eltwise84"
  top: "Convolution170"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm170"
  type: "BatchNorm"
  bottom: "Convolution170"
  top: "Convolution170"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale170"
  type: "Scale"
  bottom: "Convolution170"
  top: "Convolution170"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU170"
  type: "ReLU"
  bottom: "Convolution170"
  top: "Convolution170"
}
layer {
  name: "Convolution171"
  type: "Convolution"
  bottom: "Convolution170"
  top: "Convolution171"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm171"
  type: "BatchNorm"
  bottom: "Convolution171"
  top: "Convolution171"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale171"
  type: "Scale"
  bottom: "Convolution171"
  top: "Convolution171"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise85"
  type: "Eltwise"
  bottom: "Eltwise84"
  bottom: "Convolution171"
  top: "Eltwise85"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU171"
  type: "ReLU"
  bottom: "Eltwise85"
  top: "Eltwise85"
}
layer {
  name: "Convolution172"
  type: "Convolution"
  bottom: "Eltwise85"
  top: "Convolution172"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm172"
  type: "BatchNorm"
  bottom: "Convolution172"
  top: "Convolution172"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale172"
  type: "Scale"
  bottom: "Convolution172"
  top: "Convolution172"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU172"
  type: "ReLU"
  bottom: "Convolution172"
  top: "Convolution172"
}
layer {
  name: "Convolution173"
  type: "Convolution"
  bottom: "Convolution172"
  top: "Convolution173"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm173"
  type: "BatchNorm"
  bottom: "Convolution173"
  top: "Convolution173"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale173"
  type: "Scale"
  bottom: "Convolution173"
  top: "Convolution173"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise86"
  type: "Eltwise"
  bottom: "Eltwise85"
  bottom: "Convolution173"
  top: "Eltwise86"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU173"
  type: "ReLU"
  bottom: "Eltwise86"
  top: "Eltwise86"
}
layer {
  name: "Convolution174"
  type: "Convolution"
  bottom: "Eltwise86"
  top: "Convolution174"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm174"
  type: "BatchNorm"
  bottom: "Convolution174"
  top: "Convolution174"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale174"
  type: "Scale"
  bottom: "Convolution174"
  top: "Convolution174"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU174"
  type: "ReLU"
  bottom: "Convolution174"
  top: "Convolution174"
}
layer {
  name: "Convolution175"
  type: "Convolution"
  bottom: "Convolution174"
  top: "Convolution175"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm175"
  type: "BatchNorm"
  bottom: "Convolution175"
  top: "Convolution175"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale175"
  type: "Scale"
  bottom: "Convolution175"
  top: "Convolution175"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise87"
  type: "Eltwise"
  bottom: "Eltwise86"
  bottom: "Convolution175"
  top: "Eltwise87"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU175"
  type: "ReLU"
  bottom: "Eltwise87"
  top: "Eltwise87"
}
layer {
  name: "Convolution176"
  type: "Convolution"
  bottom: "Eltwise87"
  top: "Convolution176"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm176"
  type: "BatchNorm"
  bottom: "Convolution176"
  top: "Convolution176"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale176"
  type: "Scale"
  bottom: "Convolution176"
  top: "Convolution176"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU176"
  type: "ReLU"
  bottom: "Convolution176"
  top: "Convolution176"
}
layer {
  name: "Convolution177"
  type: "Convolution"
  bottom: "Convolution176"
  top: "Convolution177"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm177"
  type: "BatchNorm"
  bottom: "Convolution177"
  top: "Convolution177"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale177"
  type: "Scale"
  bottom: "Convolution177"
  top: "Convolution177"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise88"
  type: "Eltwise"
  bottom: "Eltwise87"
  bottom: "Convolution177"
  top: "Eltwise88"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU177"
  type: "ReLU"
  bottom: "Eltwise88"
  top: "Eltwise88"
}
layer {
  name: "Convolution178"
  type: "Convolution"
  bottom: "Eltwise88"
  top: "Convolution178"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm178"
  type: "BatchNorm"
  bottom: "Convolution178"
  top: "Convolution178"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale178"
  type: "Scale"
  bottom: "Convolution178"
  top: "Convolution178"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU178"
  type: "ReLU"
  bottom: "Convolution178"
  top: "Convolution178"
}
layer {
  name: "Convolution179"
  type: "Convolution"
  bottom: "Convolution178"
  top: "Convolution179"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm179"
  type: "BatchNorm"
  bottom: "Convolution179"
  top: "Convolution179"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale179"
  type: "Scale"
  bottom: "Convolution179"
  top: "Convolution179"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise89"
  type: "Eltwise"
  bottom: "Eltwise88"
  bottom: "Convolution179"
  top: "Eltwise89"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU179"
  type: "ReLU"
  bottom: "Eltwise89"
  top: "Eltwise89"
}
layer {
  name: "Convolution180"
  type: "Convolution"
  bottom: "Eltwise89"
  top: "Convolution180"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm180"
  type: "BatchNorm"
  bottom: "Convolution180"
  top: "Convolution180"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale180"
  type: "Scale"
  bottom: "Convolution180"
  top: "Convolution180"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU180"
  type: "ReLU"
  bottom: "Convolution180"
  top: "Convolution180"
}
layer {
  name: "Convolution181"
  type: "Convolution"
  bottom: "Convolution180"
  top: "Convolution181"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm181"
  type: "BatchNorm"
  bottom: "Convolution181"
  top: "Convolution181"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale181"
  type: "Scale"
  bottom: "Convolution181"
  top: "Convolution181"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise90"
  type: "Eltwise"
  bottom: "Eltwise89"
  bottom: "Convolution181"
  top: "Eltwise90"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU181"
  type: "ReLU"
  bottom: "Eltwise90"
  top: "Eltwise90"
}
layer {
  name: "Convolution182"
  type: "Convolution"
  bottom: "Eltwise90"
  top: "Convolution182"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm182"
  type: "BatchNorm"
  bottom: "Convolution182"
  top: "Convolution182"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale182"
  type: "Scale"
  bottom: "Convolution182"
  top: "Convolution182"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU182"
  type: "ReLU"
  bottom: "Convolution182"
  top: "Convolution182"
}
layer {
  name: "Convolution183"
  type: "Convolution"
  bottom: "Convolution182"
  top: "Convolution183"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm183"
  type: "BatchNorm"
  bottom: "Convolution183"
  top: "Convolution183"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale183"
  type: "Scale"
  bottom: "Convolution183"
  top: "Convolution183"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise91"
  type: "Eltwise"
  bottom: "Eltwise90"
  bottom: "Convolution183"
  top: "Eltwise91"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU183"
  type: "ReLU"
  bottom: "Eltwise91"
  top: "Eltwise91"
}
layer {
  name: "Convolution184"
  type: "Convolution"
  bottom: "Eltwise91"
  top: "Convolution184"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm184"
  type: "BatchNorm"
  bottom: "Convolution184"
  top: "Convolution184"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale184"
  type: "Scale"
  bottom: "Convolution184"
  top: "Convolution184"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU184"
  type: "ReLU"
  bottom: "Convolution184"
  top: "Convolution184"
}
layer {
  name: "Convolution185"
  type: "Convolution"
  bottom: "Convolution184"
  top: "Convolution185"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm185"
  type: "BatchNorm"
  bottom: "Convolution185"
  top: "Convolution185"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale185"
  type: "Scale"
  bottom: "Convolution185"
  top: "Convolution185"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise92"
  type: "Eltwise"
  bottom: "Eltwise91"
  bottom: "Convolution185"
  top: "Eltwise92"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU185"
  type: "ReLU"
  bottom: "Eltwise92"
  top: "Eltwise92"
}
layer {
  name: "Convolution186"
  type: "Convolution"
  bottom: "Eltwise92"
  top: "Convolution186"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm186"
  type: "BatchNorm"
  bottom: "Convolution186"
  top: "Convolution186"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale186"
  type: "Scale"
  bottom: "Convolution186"
  top: "Convolution186"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU186"
  type: "ReLU"
  bottom: "Convolution186"
  top: "Convolution186"
}
layer {
  name: "Convolution187"
  type: "Convolution"
  bottom: "Convolution186"
  top: "Convolution187"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm187"
  type: "BatchNorm"
  bottom: "Convolution187"
  top: "Convolution187"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale187"
  type: "Scale"
  bottom: "Convolution187"
  top: "Convolution187"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise93"
  type: "Eltwise"
  bottom: "Eltwise92"
  bottom: "Convolution187"
  top: "Eltwise93"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU187"
  type: "ReLU"
  bottom: "Eltwise93"
  top: "Eltwise93"
}
layer {
  name: "Convolution188"
  type: "Convolution"
  bottom: "Eltwise93"
  top: "Convolution188"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm188"
  type: "BatchNorm"
  bottom: "Convolution188"
  top: "Convolution188"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale188"
  type: "Scale"
  bottom: "Convolution188"
  top: "Convolution188"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU188"
  type: "ReLU"
  bottom: "Convolution188"
  top: "Convolution188"
}
layer {
  name: "Convolution189"
  type: "Convolution"
  bottom: "Convolution188"
  top: "Convolution189"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm189"
  type: "BatchNorm"
  bottom: "Convolution189"
  top: "Convolution189"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale189"
  type: "Scale"
  bottom: "Convolution189"
  top: "Convolution189"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise94"
  type: "Eltwise"
  bottom: "Eltwise93"
  bottom: "Convolution189"
  top: "Eltwise94"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU189"
  type: "ReLU"
  bottom: "Eltwise94"
  top: "Eltwise94"
}
layer {
  name: "Convolution190"
  type: "Convolution"
  bottom: "Eltwise94"
  top: "Convolution190"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm190"
  type: "BatchNorm"
  bottom: "Convolution190"
  top: "Convolution190"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale190"
  type: "Scale"
  bottom: "Convolution190"
  top: "Convolution190"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU190"
  type: "ReLU"
  bottom: "Convolution190"
  top: "Convolution190"
}
layer {
  name: "Convolution191"
  type: "Convolution"
  bottom: "Convolution190"
  top: "Convolution191"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm191"
  type: "BatchNorm"
  bottom: "Convolution191"
  top: "Convolution191"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale191"
  type: "Scale"
  bottom: "Convolution191"
  top: "Convolution191"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise95"
  type: "Eltwise"
  bottom: "Eltwise94"
  bottom: "Convolution191"
  top: "Eltwise95"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU191"
  type: "ReLU"
  bottom: "Eltwise95"
  top: "Eltwise95"
}
layer {
  name: "Convolution192"
  type: "Convolution"
  bottom: "Eltwise95"
  top: "Convolution192"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm192"
  type: "BatchNorm"
  bottom: "Convolution192"
  top: "Convolution192"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale192"
  type: "Scale"
  bottom: "Convolution192"
  top: "Convolution192"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU192"
  type: "ReLU"
  bottom: "Convolution192"
  top: "Convolution192"
}
layer {
  name: "Convolution193"
  type: "Convolution"
  bottom: "Convolution192"
  top: "Convolution193"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm193"
  type: "BatchNorm"
  bottom: "Convolution193"
  top: "Convolution193"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale193"
  type: "Scale"
  bottom: "Convolution193"
  top: "Convolution193"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise96"
  type: "Eltwise"
  bottom: "Eltwise95"
  bottom: "Convolution193"
  top: "Eltwise96"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU193"
  type: "ReLU"
  bottom: "Eltwise96"
  top: "Eltwise96"
}
layer {
  name: "Convolution194"
  type: "Convolution"
  bottom: "Eltwise96"
  top: "Convolution194"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm194"
  type: "BatchNorm"
  bottom: "Convolution194"
  top: "Convolution194"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale194"
  type: "Scale"
  bottom: "Convolution194"
  top: "Convolution194"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU194"
  type: "ReLU"
  bottom: "Convolution194"
  top: "Convolution194"
}
layer {
  name: "Convolution195"
  type: "Convolution"
  bottom: "Convolution194"
  top: "Convolution195"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm195"
  type: "BatchNorm"
  bottom: "Convolution195"
  top: "Convolution195"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale195"
  type: "Scale"
  bottom: "Convolution195"
  top: "Convolution195"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise97"
  type: "Eltwise"
  bottom: "Eltwise96"
  bottom: "Convolution195"
  top: "Eltwise97"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU195"
  type: "ReLU"
  bottom: "Eltwise97"
  top: "Eltwise97"
}
layer {
  name: "Convolution196"
  type: "Convolution"
  bottom: "Eltwise97"
  top: "Convolution196"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm196"
  type: "BatchNorm"
  bottom: "Convolution196"
  top: "Convolution196"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale196"
  type: "Scale"
  bottom: "Convolution196"
  top: "Convolution196"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU196"
  type: "ReLU"
  bottom: "Convolution196"
  top: "Convolution196"
}
layer {
  name: "Convolution197"
  type: "Convolution"
  bottom: "Convolution196"
  top: "Convolution197"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm197"
  type: "BatchNorm"
  bottom: "Convolution197"
  top: "Convolution197"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale197"
  type: "Scale"
  bottom: "Convolution197"
  top: "Convolution197"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise98"
  type: "Eltwise"
  bottom: "Eltwise97"
  bottom: "Convolution197"
  top: "Eltwise98"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU197"
  type: "ReLU"
  bottom: "Eltwise98"
  top: "Eltwise98"
}
layer {
  name: "Convolution198"
  type: "Convolution"
  bottom: "Eltwise98"
  top: "Convolution198"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm198"
  type: "BatchNorm"
  bottom: "Convolution198"
  top: "Convolution198"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale198"
  type: "Scale"
  bottom: "Convolution198"
  top: "Convolution198"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU198"
  type: "ReLU"
  bottom: "Convolution198"
  top: "Convolution198"
}
layer {
  name: "Convolution199"
  type: "Convolution"
  bottom: "Convolution198"
  top: "Convolution199"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm199"
  type: "BatchNorm"
  bottom: "Convolution199"
  top: "Convolution199"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale199"
  type: "Scale"
  bottom: "Convolution199"
  top: "Convolution199"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise99"
  type: "Eltwise"
  bottom: "Eltwise98"
  bottom: "Convolution199"
  top: "Eltwise99"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU199"
  type: "ReLU"
  bottom: "Eltwise99"
  top: "Eltwise99"
}
layer {
  name: "Convolution200"
  type: "Convolution"
  bottom: "Eltwise99"
  top: "Convolution200"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm200"
  type: "BatchNorm"
  bottom: "Convolution200"
  top: "Convolution200"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale200"
  type: "Scale"
  bottom: "Convolution200"
  top: "Convolution200"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU200"
  type: "ReLU"
  bottom: "Convolution200"
  top: "Convolution200"
}
layer {
  name: "Convolution201"
  type: "Convolution"
  bottom: "Convolution200"
  top: "Convolution201"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm201"
  type: "BatchNorm"
  bottom: "Convolution201"
  top: "Convolution201"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale201"
  type: "Scale"
  bottom: "Convolution201"
  top: "Convolution201"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise100"
  type: "Eltwise"
  bottom: "Eltwise99"
  bottom: "Convolution201"
  top: "Eltwise100"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU201"
  type: "ReLU"
  bottom: "Eltwise100"
  top: "Eltwise100"
}
layer {
  name: "Convolution202"
  type: "Convolution"
  bottom: "Eltwise100"
  top: "Convolution202"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm202"
  type: "BatchNorm"
  bottom: "Convolution202"
  top: "Convolution202"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale202"
  type: "Scale"
  bottom: "Convolution202"
  top: "Convolution202"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU202"
  type: "ReLU"
  bottom: "Convolution202"
  top: "Convolution202"
}
layer {
  name: "Convolution203"
  type: "Convolution"
  bottom: "Convolution202"
  top: "Convolution203"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm203"
  type: "BatchNorm"
  bottom: "Convolution203"
  top: "Convolution203"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale203"
  type: "Scale"
  bottom: "Convolution203"
  top: "Convolution203"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise101"
  type: "Eltwise"
  bottom: "Eltwise100"
  bottom: "Convolution203"
  top: "Eltwise101"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU203"
  type: "ReLU"
  bottom: "Eltwise101"
  top: "Eltwise101"
}
layer {
  name: "Convolution204"
  type: "Convolution"
  bottom: "Eltwise101"
  top: "Convolution204"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm204"
  type: "BatchNorm"
  bottom: "Convolution204"
  top: "Convolution204"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale204"
  type: "Scale"
  bottom: "Convolution204"
  top: "Convolution204"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU204"
  type: "ReLU"
  bottom: "Convolution204"
  top: "Convolution204"
}
layer {
  name: "Convolution205"
  type: "Convolution"
  bottom: "Convolution204"
  top: "Convolution205"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm205"
  type: "BatchNorm"
  bottom: "Convolution205"
  top: "Convolution205"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale205"
  type: "Scale"
  bottom: "Convolution205"
  top: "Convolution205"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise102"
  type: "Eltwise"
  bottom: "Eltwise101"
  bottom: "Convolution205"
  top: "Eltwise102"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU205"
  type: "ReLU"
  bottom: "Eltwise102"
  top: "Eltwise102"
}
layer {
  name: "Convolution206"
  type: "Convolution"
  bottom: "Eltwise102"
  top: "Convolution206"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm206"
  type: "BatchNorm"
  bottom: "Convolution206"
  top: "Convolution206"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale206"
  type: "Scale"
  bottom: "Convolution206"
  top: "Convolution206"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU206"
  type: "ReLU"
  bottom: "Convolution206"
  top: "Convolution206"
}
layer {
  name: "Convolution207"
  type: "Convolution"
  bottom: "Convolution206"
  top: "Convolution207"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm207"
  type: "BatchNorm"
  bottom: "Convolution207"
  top: "Convolution207"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale207"
  type: "Scale"
  bottom: "Convolution207"
  top: "Convolution207"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise103"
  type: "Eltwise"
  bottom: "Eltwise102"
  bottom: "Convolution207"
  top: "Eltwise103"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU207"
  type: "ReLU"
  bottom: "Eltwise103"
  top: "Eltwise103"
}
layer {
  name: "Convolution208"
  type: "Convolution"
  bottom: "Eltwise103"
  top: "Convolution208"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm208"
  type: "BatchNorm"
  bottom: "Convolution208"
  top: "Convolution208"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale208"
  type: "Scale"
  bottom: "Convolution208"
  top: "Convolution208"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU208"
  type: "ReLU"
  bottom: "Convolution208"
  top: "Convolution208"
}
layer {
  name: "Convolution209"
  type: "Convolution"
  bottom: "Convolution208"
  top: "Convolution209"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm209"
  type: "BatchNorm"
  bottom: "Convolution209"
  top: "Convolution209"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale209"
  type: "Scale"
  bottom: "Convolution209"
  top: "Convolution209"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise104"
  type: "Eltwise"
  bottom: "Eltwise103"
  bottom: "Convolution209"
  top: "Eltwise104"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU209"
  type: "ReLU"
  bottom: "Eltwise104"
  top: "Eltwise104"
}
layer {
  name: "Convolution210"
  type: "Convolution"
  bottom: "Eltwise104"
  top: "Convolution210"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm210"
  type: "BatchNorm"
  bottom: "Convolution210"
  top: "Convolution210"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale210"
  type: "Scale"
  bottom: "Convolution210"
  top: "Convolution210"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU210"
  type: "ReLU"
  bottom: "Convolution210"
  top: "Convolution210"
}
layer {
  name: "Convolution211"
  type: "Convolution"
  bottom: "Convolution210"
  top: "Convolution211"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm211"
  type: "BatchNorm"
  bottom: "Convolution211"
  top: "Convolution211"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale211"
  type: "Scale"
  bottom: "Convolution211"
  top: "Convolution211"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise105"
  type: "Eltwise"
  bottom: "Eltwise104"
  bottom: "Convolution211"
  top: "Eltwise105"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU211"
  type: "ReLU"
  bottom: "Eltwise105"
  top: "Eltwise105"
}
layer {
  name: "Convolution212"
  type: "Convolution"
  bottom: "Eltwise105"
  top: "Convolution212"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm212"
  type: "BatchNorm"
  bottom: "Convolution212"
  top: "Convolution212"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale212"
  type: "Scale"
  bottom: "Convolution212"
  top: "Convolution212"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU212"
  type: "ReLU"
  bottom: "Convolution212"
  top: "Convolution212"
}
layer {
  name: "Convolution213"
  type: "Convolution"
  bottom: "Convolution212"
  top: "Convolution213"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm213"
  type: "BatchNorm"
  bottom: "Convolution213"
  top: "Convolution213"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale213"
  type: "Scale"
  bottom: "Convolution213"
  top: "Convolution213"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise106"
  type: "Eltwise"
  bottom: "Eltwise105"
  bottom: "Convolution213"
  top: "Eltwise106"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU213"
  type: "ReLU"
  bottom: "Eltwise106"
  top: "Eltwise106"
}
layer {
  name: "Convolution214"
  type: "Convolution"
  bottom: "Eltwise106"
  top: "Convolution214"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm214"
  type: "BatchNorm"
  bottom: "Convolution214"
  top: "Convolution214"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale214"
  type: "Scale"
  bottom: "Convolution214"
  top: "Convolution214"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU214"
  type: "ReLU"
  bottom: "Convolution214"
  top: "Convolution214"
}
layer {
  name: "Convolution215"
  type: "Convolution"
  bottom: "Convolution214"
  top: "Convolution215"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm215"
  type: "BatchNorm"
  bottom: "Convolution215"
  top: "Convolution215"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale215"
  type: "Scale"
  bottom: "Convolution215"
  top: "Convolution215"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise107"
  type: "Eltwise"
  bottom: "Eltwise106"
  bottom: "Convolution215"
  top: "Eltwise107"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU215"
  type: "ReLU"
  bottom: "Eltwise107"
  top: "Eltwise107"
}
layer {
  name: "Convolution216"
  type: "Convolution"
  bottom: "Eltwise107"
  top: "Convolution216"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm216"
  type: "BatchNorm"
  bottom: "Convolution216"
  top: "Convolution216"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale216"
  type: "Scale"
  bottom: "Convolution216"
  top: "Convolution216"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU216"
  type: "ReLU"
  bottom: "Convolution216"
  top: "Convolution216"
}
layer {
  name: "Convolution217"
  type: "Convolution"
  bottom: "Convolution216"
  top: "Convolution217"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm217"
  type: "BatchNorm"
  bottom: "Convolution217"
  top: "Convolution217"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale217"
  type: "Scale"
  bottom: "Convolution217"
  top: "Convolution217"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise108"
  type: "Eltwise"
  bottom: "Eltwise107"
  bottom: "Convolution217"
  top: "Eltwise108"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU217"
  type: "ReLU"
  bottom: "Eltwise108"
  top: "Eltwise108"
}
layer {
  name: "Convolution218"
  type: "Convolution"
  bottom: "Eltwise108"
  top: "Convolution218"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm218"
  type: "BatchNorm"
  bottom: "Convolution218"
  top: "Convolution218"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale218"
  type: "Scale"
  bottom: "Convolution218"
  top: "Convolution218"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU218"
  type: "ReLU"
  bottom: "Convolution218"
  top: "Convolution218"
}
layer {
  name: "Convolution219"
  type: "Convolution"
  bottom: "Convolution218"
  top: "Convolution219"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm219"
  type: "BatchNorm"
  bottom: "Convolution219"
  top: "Convolution219"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale219"
  type: "Scale"
  bottom: "Convolution219"
  top: "Convolution219"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise109"
  type: "Eltwise"
  bottom: "Eltwise108"
  bottom: "Convolution219"
  top: "Eltwise109"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU219"
  type: "ReLU"
  bottom: "Eltwise109"
  top: "Eltwise109"
}
layer {
  name: "Convolution220"
  type: "Convolution"
  bottom: "Eltwise109"
  top: "Convolution220"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm220"
  type: "BatchNorm"
  bottom: "Convolution220"
  top: "Convolution220"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale220"
  type: "Scale"
  bottom: "Convolution220"
  top: "Convolution220"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU220"
  type: "ReLU"
  bottom: "Convolution220"
  top: "Convolution220"
}
layer {
  name: "Convolution221"
  type: "Convolution"
  bottom: "Convolution220"
  top: "Convolution221"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm221"
  type: "BatchNorm"
  bottom: "Convolution221"
  top: "Convolution221"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale221"
  type: "Scale"
  bottom: "Convolution221"
  top: "Convolution221"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise110"
  type: "Eltwise"
  bottom: "Eltwise109"
  bottom: "Convolution221"
  top: "Eltwise110"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU221"
  type: "ReLU"
  bottom: "Eltwise110"
  top: "Eltwise110"
}
layer {
  name: "Convolution222"
  type: "Convolution"
  bottom: "Eltwise110"
  top: "Convolution222"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm222"
  type: "BatchNorm"
  bottom: "Convolution222"
  top: "Convolution222"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale222"
  type: "Scale"
  bottom: "Convolution222"
  top: "Convolution222"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU222"
  type: "ReLU"
  bottom: "Convolution222"
  top: "Convolution222"
}
layer {
  name: "Convolution223"
  type: "Convolution"
  bottom: "Convolution222"
  top: "Convolution223"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm223"
  type: "BatchNorm"
  bottom: "Convolution223"
  top: "Convolution223"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale223"
  type: "Scale"
  bottom: "Convolution223"
  top: "Convolution223"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise111"
  type: "Eltwise"
  bottom: "Eltwise110"
  bottom: "Convolution223"
  top: "Eltwise111"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU223"
  type: "ReLU"
  bottom: "Eltwise111"
  top: "Eltwise111"
}
layer {
  name: "Convolution224"
  type: "Convolution"
  bottom: "Eltwise111"
  top: "Convolution224"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm224"
  type: "BatchNorm"
  bottom: "Convolution224"
  top: "Convolution224"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale224"
  type: "Scale"
  bottom: "Convolution224"
  top: "Convolution224"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU224"
  type: "ReLU"
  bottom: "Convolution224"
  top: "Convolution224"
}
layer {
  name: "Convolution225"
  type: "Convolution"
  bottom: "Convolution224"
  top: "Convolution225"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm225"
  type: "BatchNorm"
  bottom: "Convolution225"
  top: "Convolution225"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale225"
  type: "Scale"
  bottom: "Convolution225"
  top: "Convolution225"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise112"
  type: "Eltwise"
  bottom: "Eltwise111"
  bottom: "Convolution225"
  top: "Eltwise112"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU225"
  type: "ReLU"
  bottom: "Eltwise112"
  top: "Eltwise112"
}
layer {
  name: "Convolution226"
  type: "Convolution"
  bottom: "Eltwise112"
  top: "Convolution226"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm226"
  type: "BatchNorm"
  bottom: "Convolution226"
  top: "Convolution226"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale226"
  type: "Scale"
  bottom: "Convolution226"
  top: "Convolution226"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU226"
  type: "ReLU"
  bottom: "Convolution226"
  top: "Convolution226"
}
layer {
  name: "Convolution227"
  type: "Convolution"
  bottom: "Convolution226"
  top: "Convolution227"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm227"
  type: "BatchNorm"
  bottom: "Convolution227"
  top: "Convolution227"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale227"
  type: "Scale"
  bottom: "Convolution227"
  top: "Convolution227"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise113"
  type: "Eltwise"
  bottom: "Eltwise112"
  bottom: "Convolution227"
  top: "Eltwise113"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU227"
  type: "ReLU"
  bottom: "Eltwise113"
  top: "Eltwise113"
}
layer {
  name: "Convolution228"
  type: "Convolution"
  bottom: "Eltwise113"
  top: "Convolution228"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm228"
  type: "BatchNorm"
  bottom: "Convolution228"
  top: "Convolution228"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale228"
  type: "Scale"
  bottom: "Convolution228"
  top: "Convolution228"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU228"
  type: "ReLU"
  bottom: "Convolution228"
  top: "Convolution228"
}
layer {
  name: "Convolution229"
  type: "Convolution"
  bottom: "Convolution228"
  top: "Convolution229"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm229"
  type: "BatchNorm"
  bottom: "Convolution229"
  top: "Convolution229"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale229"
  type: "Scale"
  bottom: "Convolution229"
  top: "Convolution229"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise114"
  type: "Eltwise"
  bottom: "Eltwise113"
  bottom: "Convolution229"
  top: "Eltwise114"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU229"
  type: "ReLU"
  bottom: "Eltwise114"
  top: "Eltwise114"
}
layer {
  name: "Convolution230"
  type: "Convolution"
  bottom: "Eltwise114"
  top: "Convolution230"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm230"
  type: "BatchNorm"
  bottom: "Convolution230"
  top: "Convolution230"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale230"
  type: "Scale"
  bottom: "Convolution230"
  top: "Convolution230"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU230"
  type: "ReLU"
  bottom: "Convolution230"
  top: "Convolution230"
}
layer {
  name: "Convolution231"
  type: "Convolution"
  bottom: "Convolution230"
  top: "Convolution231"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm231"
  type: "BatchNorm"
  bottom: "Convolution231"
  top: "Convolution231"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale231"
  type: "Scale"
  bottom: "Convolution231"
  top: "Convolution231"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise115"
  type: "Eltwise"
  bottom: "Eltwise114"
  bottom: "Convolution231"
  top: "Eltwise115"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU231"
  type: "ReLU"
  bottom: "Eltwise115"
  top: "Eltwise115"
}
layer {
  name: "Convolution232"
  type: "Convolution"
  bottom: "Eltwise115"
  top: "Convolution232"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm232"
  type: "BatchNorm"
  bottom: "Convolution232"
  top: "Convolution232"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale232"
  type: "Scale"
  bottom: "Convolution232"
  top: "Convolution232"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU232"
  type: "ReLU"
  bottom: "Convolution232"
  top: "Convolution232"
}
layer {
  name: "Convolution233"
  type: "Convolution"
  bottom: "Convolution232"
  top: "Convolution233"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm233"
  type: "BatchNorm"
  bottom: "Convolution233"
  top: "Convolution233"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale233"
  type: "Scale"
  bottom: "Convolution233"
  top: "Convolution233"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise116"
  type: "Eltwise"
  bottom: "Eltwise115"
  bottom: "Convolution233"
  top: "Eltwise116"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU233"
  type: "ReLU"
  bottom: "Eltwise116"
  top: "Eltwise116"
}
layer {
  name: "Convolution234"
  type: "Convolution"
  bottom: "Eltwise116"
  top: "Convolution234"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm234"
  type: "BatchNorm"
  bottom: "Convolution234"
  top: "Convolution234"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale234"
  type: "Scale"
  bottom: "Convolution234"
  top: "Convolution234"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU234"
  type: "ReLU"
  bottom: "Convolution234"
  top: "Convolution234"
}
layer {
  name: "Convolution235"
  type: "Convolution"
  bottom: "Convolution234"
  top: "Convolution235"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm235"
  type: "BatchNorm"
  bottom: "Convolution235"
  top: "Convolution235"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale235"
  type: "Scale"
  bottom: "Convolution235"
  top: "Convolution235"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise117"
  type: "Eltwise"
  bottom: "Eltwise116"
  bottom: "Convolution235"
  top: "Eltwise117"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU235"
  type: "ReLU"
  bottom: "Eltwise117"
  top: "Eltwise117"
}
layer {
  name: "Convolution236"
  type: "Convolution"
  bottom: "Eltwise117"
  top: "Convolution236"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm236"
  type: "BatchNorm"
  bottom: "Convolution236"
  top: "Convolution236"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale236"
  type: "Scale"
  bottom: "Convolution236"
  top: "Convolution236"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU236"
  type: "ReLU"
  bottom: "Convolution236"
  top: "Convolution236"
}
layer {
  name: "Convolution237"
  type: "Convolution"
  bottom: "Convolution236"
  top: "Convolution237"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm237"
  type: "BatchNorm"
  bottom: "Convolution237"
  top: "Convolution237"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale237"
  type: "Scale"
  bottom: "Convolution237"
  top: "Convolution237"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise118"
  type: "Eltwise"
  bottom: "Eltwise117"
  bottom: "Convolution237"
  top: "Eltwise118"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU237"
  type: "ReLU"
  bottom: "Eltwise118"
  top: "Eltwise118"
}
layer {
  name: "Convolution238"
  type: "Convolution"
  bottom: "Eltwise118"
  top: "Convolution238"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm238"
  type: "BatchNorm"
  bottom: "Convolution238"
  top: "Convolution238"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale238"
  type: "Scale"
  bottom: "Convolution238"
  top: "Convolution238"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU238"
  type: "ReLU"
  bottom: "Convolution238"
  top: "Convolution238"
}
layer {
  name: "Convolution239"
  type: "Convolution"
  bottom: "Convolution238"
  top: "Convolution239"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm239"
  type: "BatchNorm"
  bottom: "Convolution239"
  top: "Convolution239"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale239"
  type: "Scale"
  bottom: "Convolution239"
  top: "Convolution239"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise119"
  type: "Eltwise"
  bottom: "Eltwise118"
  bottom: "Convolution239"
  top: "Eltwise119"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU239"
  type: "ReLU"
  bottom: "Eltwise119"
  top: "Eltwise119"
}
layer {
  name: "Convolution240"
  type: "Convolution"
  bottom: "Eltwise119"
  top: "Convolution240"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm240"
  type: "BatchNorm"
  bottom: "Convolution240"
  top: "Convolution240"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale240"
  type: "Scale"
  bottom: "Convolution240"
  top: "Convolution240"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU240"
  type: "ReLU"
  bottom: "Convolution240"
  top: "Convolution240"
}
layer {
  name: "Convolution241"
  type: "Convolution"
  bottom: "Convolution240"
  top: "Convolution241"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm241"
  type: "BatchNorm"
  bottom: "Convolution241"
  top: "Convolution241"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale241"
  type: "Scale"
  bottom: "Convolution241"
  top: "Convolution241"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise120"
  type: "Eltwise"
  bottom: "Eltwise119"
  bottom: "Convolution241"
  top: "Eltwise120"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU241"
  type: "ReLU"
  bottom: "Eltwise120"
  top: "Eltwise120"
}
layer {
  name: "Convolution242"
  type: "Convolution"
  bottom: "Eltwise120"
  top: "Convolution242"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm242"
  type: "BatchNorm"
  bottom: "Convolution242"
  top: "Convolution242"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale242"
  type: "Scale"
  bottom: "Convolution242"
  top: "Convolution242"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU242"
  type: "ReLU"
  bottom: "Convolution242"
  top: "Convolution242"
}
layer {
  name: "Convolution243"
  type: "Convolution"
  bottom: "Convolution242"
  top: "Convolution243"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm243"
  type: "BatchNorm"
  bottom: "Convolution243"
  top: "Convolution243"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale243"
  type: "Scale"
  bottom: "Convolution243"
  top: "Convolution243"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise121"
  type: "Eltwise"
  bottom: "Eltwise120"
  bottom: "Convolution243"
  top: "Eltwise121"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU243"
  type: "ReLU"
  bottom: "Eltwise121"
  top: "Eltwise121"
}
layer {
  name: "Convolution244"
  type: "Convolution"
  bottom: "Eltwise121"
  top: "Convolution244"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm244"
  type: "BatchNorm"
  bottom: "Convolution244"
  top: "Convolution244"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale244"
  type: "Scale"
  bottom: "Convolution244"
  top: "Convolution244"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU244"
  type: "ReLU"
  bottom: "Convolution244"
  top: "Convolution244"
}
layer {
  name: "Convolution245"
  type: "Convolution"
  bottom: "Convolution244"
  top: "Convolution245"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm245"
  type: "BatchNorm"
  bottom: "Convolution245"
  top: "Convolution245"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale245"
  type: "Scale"
  bottom: "Convolution245"
  top: "Convolution245"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise122"
  type: "Eltwise"
  bottom: "Eltwise121"
  bottom: "Convolution245"
  top: "Eltwise122"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU245"
  type: "ReLU"
  bottom: "Eltwise122"
  top: "Eltwise122"
}
layer {
  name: "Convolution246"
  type: "Convolution"
  bottom: "Eltwise122"
  top: "Convolution246"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm246"
  type: "BatchNorm"
  bottom: "Convolution246"
  top: "Convolution246"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale246"
  type: "Scale"
  bottom: "Convolution246"
  top: "Convolution246"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU246"
  type: "ReLU"
  bottom: "Convolution246"
  top: "Convolution246"
}
layer {
  name: "Convolution247"
  type: "Convolution"
  bottom: "Convolution246"
  top: "Convolution247"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm247"
  type: "BatchNorm"
  bottom: "Convolution247"
  top: "Convolution247"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale247"
  type: "Scale"
  bottom: "Convolution247"
  top: "Convolution247"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise123"
  type: "Eltwise"
  bottom: "Eltwise122"
  bottom: "Convolution247"
  top: "Eltwise123"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU247"
  type: "ReLU"
  bottom: "Eltwise123"
  top: "Eltwise123"
}
layer {
  name: "Convolution248"
  type: "Convolution"
  bottom: "Eltwise123"
  top: "Convolution248"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm248"
  type: "BatchNorm"
  bottom: "Convolution248"
  top: "Convolution248"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale248"
  type: "Scale"
  bottom: "Convolution248"
  top: "Convolution248"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU248"
  type: "ReLU"
  bottom: "Convolution248"
  top: "Convolution248"
}
layer {
  name: "Convolution249"
  type: "Convolution"
  bottom: "Convolution248"
  top: "Convolution249"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm249"
  type: "BatchNorm"
  bottom: "Convolution249"
  top: "Convolution249"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale249"
  type: "Scale"
  bottom: "Convolution249"
  top: "Convolution249"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise124"
  type: "Eltwise"
  bottom: "Eltwise123"
  bottom: "Convolution249"
  top: "Eltwise124"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU249"
  type: "ReLU"
  bottom: "Eltwise124"
  top: "Eltwise124"
}
layer {
  name: "Convolution250"
  type: "Convolution"
  bottom: "Eltwise124"
  top: "Convolution250"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm250"
  type: "BatchNorm"
  bottom: "Convolution250"
  top: "Convolution250"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale250"
  type: "Scale"
  bottom: "Convolution250"
  top: "Convolution250"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU250"
  type: "ReLU"
  bottom: "Convolution250"
  top: "Convolution250"
}
layer {
  name: "Convolution251"
  type: "Convolution"
  bottom: "Convolution250"
  top: "Convolution251"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm251"
  type: "BatchNorm"
  bottom: "Convolution251"
  top: "Convolution251"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale251"
  type: "Scale"
  bottom: "Convolution251"
  top: "Convolution251"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise125"
  type: "Eltwise"
  bottom: "Eltwise124"
  bottom: "Convolution251"
  top: "Eltwise125"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU251"
  type: "ReLU"
  bottom: "Eltwise125"
  top: "Eltwise125"
}
layer {
  name: "Convolution252"
  type: "Convolution"
  bottom: "Eltwise125"
  top: "Convolution252"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm252"
  type: "BatchNorm"
  bottom: "Convolution252"
  top: "Convolution252"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale252"
  type: "Scale"
  bottom: "Convolution252"
  top: "Convolution252"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU252"
  type: "ReLU"
  bottom: "Convolution252"
  top: "Convolution252"
}
layer {
  name: "Convolution253"
  type: "Convolution"
  bottom: "Convolution252"
  top: "Convolution253"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm253"
  type: "BatchNorm"
  bottom: "Convolution253"
  top: "Convolution253"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale253"
  type: "Scale"
  bottom: "Convolution253"
  top: "Convolution253"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise126"
  type: "Eltwise"
  bottom: "Eltwise125"
  bottom: "Convolution253"
  top: "Eltwise126"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU253"
  type: "ReLU"
  bottom: "Eltwise126"
  top: "Eltwise126"
}
layer {
  name: "Convolution254"
  type: "Convolution"
  bottom: "Eltwise126"
  top: "Convolution254"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm254"
  type: "BatchNorm"
  bottom: "Convolution254"
  top: "Convolution254"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale254"
  type: "Scale"
  bottom: "Convolution254"
  top: "Convolution254"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU254"
  type: "ReLU"
  bottom: "Convolution254"
  top: "Convolution254"
}
layer {
  name: "Convolution255"
  type: "Convolution"
  bottom: "Convolution254"
  top: "Convolution255"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm255"
  type: "BatchNorm"
  bottom: "Convolution255"
  top: "Convolution255"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale255"
  type: "Scale"
  bottom: "Convolution255"
  top: "Convolution255"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise127"
  type: "Eltwise"
  bottom: "Eltwise126"
  bottom: "Convolution255"
  top: "Eltwise127"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU255"
  type: "ReLU"
  bottom: "Eltwise127"
  top: "Eltwise127"
}
layer {
  name: "Convolution256"
  type: "Convolution"
  bottom: "Eltwise127"
  top: "Convolution256"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm256"
  type: "BatchNorm"
  bottom: "Convolution256"
  top: "Convolution256"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale256"
  type: "Scale"
  bottom: "Convolution256"
  top: "Convolution256"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU256"
  type: "ReLU"
  bottom: "Convolution256"
  top: "Convolution256"
}
layer {
  name: "Convolution257"
  type: "Convolution"
  bottom: "Convolution256"
  top: "Convolution257"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm257"
  type: "BatchNorm"
  bottom: "Convolution257"
  top: "Convolution257"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale257"
  type: "Scale"
  bottom: "Convolution257"
  top: "Convolution257"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise128"
  type: "Eltwise"
  bottom: "Eltwise127"
  bottom: "Convolution257"
  top: "Eltwise128"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU257"
  type: "ReLU"
  bottom: "Eltwise128"
  top: "Eltwise128"
}
layer {
  name: "Convolution258"
  type: "Convolution"
  bottom: "Eltwise128"
  top: "Convolution258"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm258"
  type: "BatchNorm"
  bottom: "Convolution258"
  top: "Convolution258"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale258"
  type: "Scale"
  bottom: "Convolution258"
  top: "Convolution258"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU258"
  type: "ReLU"
  bottom: "Convolution258"
  top: "Convolution258"
}
layer {
  name: "Convolution259"
  type: "Convolution"
  bottom: "Convolution258"
  top: "Convolution259"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm259"
  type: "BatchNorm"
  bottom: "Convolution259"
  top: "Convolution259"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale259"
  type: "Scale"
  bottom: "Convolution259"
  top: "Convolution259"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise129"
  type: "Eltwise"
  bottom: "Eltwise128"
  bottom: "Convolution259"
  top: "Eltwise129"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU259"
  type: "ReLU"
  bottom: "Eltwise129"
  top: "Eltwise129"
}
layer {
  name: "Convolution260"
  type: "Convolution"
  bottom: "Eltwise129"
  top: "Convolution260"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm260"
  type: "BatchNorm"
  bottom: "Convolution260"
  top: "Convolution260"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale260"
  type: "Scale"
  bottom: "Convolution260"
  top: "Convolution260"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU260"
  type: "ReLU"
  bottom: "Convolution260"
  top: "Convolution260"
}
layer {
  name: "Convolution261"
  type: "Convolution"
  bottom: "Convolution260"
  top: "Convolution261"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm261"
  type: "BatchNorm"
  bottom: "Convolution261"
  top: "Convolution261"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale261"
  type: "Scale"
  bottom: "Convolution261"
  top: "Convolution261"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise130"
  type: "Eltwise"
  bottom: "Eltwise129"
  bottom: "Convolution261"
  top: "Eltwise130"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU261"
  type: "ReLU"
  bottom: "Eltwise130"
  top: "Eltwise130"
}
layer {
  name: "Convolution262"
  type: "Convolution"
  bottom: "Eltwise130"
  top: "Convolution262"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm262"
  type: "BatchNorm"
  bottom: "Convolution262"
  top: "Convolution262"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale262"
  type: "Scale"
  bottom: "Convolution262"
  top: "Convolution262"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU262"
  type: "ReLU"
  bottom: "Convolution262"
  top: "Convolution262"
}
layer {
  name: "Convolution263"
  type: "Convolution"
  bottom: "Convolution262"
  top: "Convolution263"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm263"
  type: "BatchNorm"
  bottom: "Convolution263"
  top: "Convolution263"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale263"
  type: "Scale"
  bottom: "Convolution263"
  top: "Convolution263"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise131"
  type: "Eltwise"
  bottom: "Eltwise130"
  bottom: "Convolution263"
  top: "Eltwise131"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU263"
  type: "ReLU"
  bottom: "Eltwise131"
  top: "Eltwise131"
}
layer {
  name: "Convolution264"
  type: "Convolution"
  bottom: "Eltwise131"
  top: "Convolution264"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm264"
  type: "BatchNorm"
  bottom: "Convolution264"
  top: "Convolution264"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale264"
  type: "Scale"
  bottom: "Convolution264"
  top: "Convolution264"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU264"
  type: "ReLU"
  bottom: "Convolution264"
  top: "Convolution264"
}
layer {
  name: "Convolution265"
  type: "Convolution"
  bottom: "Convolution264"
  top: "Convolution265"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm265"
  type: "BatchNorm"
  bottom: "Convolution265"
  top: "Convolution265"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale265"
  type: "Scale"
  bottom: "Convolution265"
  top: "Convolution265"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise132"
  type: "Eltwise"
  bottom: "Eltwise131"
  bottom: "Convolution265"
  top: "Eltwise132"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU265"
  type: "ReLU"
  bottom: "Eltwise132"
  top: "Eltwise132"
}
layer {
  name: "Convolution266"
  type: "Convolution"
  bottom: "Eltwise132"
  top: "Convolution266"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm266"
  type: "BatchNorm"
  bottom: "Convolution266"
  top: "Convolution266"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale266"
  type: "Scale"
  bottom: "Convolution266"
  top: "Convolution266"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU266"
  type: "ReLU"
  bottom: "Convolution266"
  top: "Convolution266"
}
layer {
  name: "Convolution267"
  type: "Convolution"
  bottom: "Convolution266"
  top: "Convolution267"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm267"
  type: "BatchNorm"
  bottom: "Convolution267"
  top: "Convolution267"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale267"
  type: "Scale"
  bottom: "Convolution267"
  top: "Convolution267"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise133"
  type: "Eltwise"
  bottom: "Eltwise132"
  bottom: "Convolution267"
  top: "Eltwise133"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU267"
  type: "ReLU"
  bottom: "Eltwise133"
  top: "Eltwise133"
}
layer {
  name: "Convolution268"
  type: "Convolution"
  bottom: "Eltwise133"
  top: "Convolution268"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm268"
  type: "BatchNorm"
  bottom: "Convolution268"
  top: "Convolution268"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale268"
  type: "Scale"
  bottom: "Convolution268"
  top: "Convolution268"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU268"
  type: "ReLU"
  bottom: "Convolution268"
  top: "Convolution268"
}
layer {
  name: "Convolution269"
  type: "Convolution"
  bottom: "Convolution268"
  top: "Convolution269"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm269"
  type: "BatchNorm"
  bottom: "Convolution269"
  top: "Convolution269"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale269"
  type: "Scale"
  bottom: "Convolution269"
  top: "Convolution269"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise134"
  type: "Eltwise"
  bottom: "Eltwise133"
  bottom: "Convolution269"
  top: "Eltwise134"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU269"
  type: "ReLU"
  bottom: "Eltwise134"
  top: "Eltwise134"
}
layer {
  name: "Convolution270"
  type: "Convolution"
  bottom: "Eltwise134"
  top: "Convolution270"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm270"
  type: "BatchNorm"
  bottom: "Convolution270"
  top: "Convolution270"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale270"
  type: "Scale"
  bottom: "Convolution270"
  top: "Convolution270"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU270"
  type: "ReLU"
  bottom: "Convolution270"
  top: "Convolution270"
}
layer {
  name: "Convolution271"
  type: "Convolution"
  bottom: "Convolution270"
  top: "Convolution271"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm271"
  type: "BatchNorm"
  bottom: "Convolution271"
  top: "Convolution271"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale271"
  type: "Scale"
  bottom: "Convolution271"
  top: "Convolution271"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise135"
  type: "Eltwise"
  bottom: "Eltwise134"
  bottom: "Convolution271"
  top: "Eltwise135"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU271"
  type: "ReLU"
  bottom: "Eltwise135"
  top: "Eltwise135"
}
layer {
  name: "Convolution272"
  type: "Convolution"
  bottom: "Eltwise135"
  top: "Convolution272"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm272"
  type: "BatchNorm"
  bottom: "Convolution272"
  top: "Convolution272"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale272"
  type: "Scale"
  bottom: "Convolution272"
  top: "Convolution272"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU272"
  type: "ReLU"
  bottom: "Convolution272"
  top: "Convolution272"
}
layer {
  name: "Convolution273"
  type: "Convolution"
  bottom: "Convolution272"
  top: "Convolution273"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm273"
  type: "BatchNorm"
  bottom: "Convolution273"
  top: "Convolution273"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale273"
  type: "Scale"
  bottom: "Convolution273"
  top: "Convolution273"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise136"
  type: "Eltwise"
  bottom: "Eltwise135"
  bottom: "Convolution273"
  top: "Eltwise136"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU273"
  type: "ReLU"
  bottom: "Eltwise136"
  top: "Eltwise136"
}
layer {
  name: "Convolution274"
  type: "Convolution"
  bottom: "Eltwise136"
  top: "Convolution274"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm274"
  type: "BatchNorm"
  bottom: "Convolution274"
  top: "Convolution274"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale274"
  type: "Scale"
  bottom: "Convolution274"
  top: "Convolution274"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU274"
  type: "ReLU"
  bottom: "Convolution274"
  top: "Convolution274"
}
layer {
  name: "Convolution275"
  type: "Convolution"
  bottom: "Convolution274"
  top: "Convolution275"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm275"
  type: "BatchNorm"
  bottom: "Convolution275"
  top: "Convolution275"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale275"
  type: "Scale"
  bottom: "Convolution275"
  top: "Convolution275"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise137"
  type: "Eltwise"
  bottom: "Eltwise136"
  bottom: "Convolution275"
  top: "Eltwise137"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU275"
  type: "ReLU"
  bottom: "Eltwise137"
  top: "Eltwise137"
}
layer {
  name: "Convolution276"
  type: "Convolution"
  bottom: "Eltwise137"
  top: "Convolution276"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm276"
  type: "BatchNorm"
  bottom: "Convolution276"
  top: "Convolution276"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale276"
  type: "Scale"
  bottom: "Convolution276"
  top: "Convolution276"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU276"
  type: "ReLU"
  bottom: "Convolution276"
  top: "Convolution276"
}
layer {
  name: "Convolution277"
  type: "Convolution"
  bottom: "Convolution276"
  top: "Convolution277"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm277"
  type: "BatchNorm"
  bottom: "Convolution277"
  top: "Convolution277"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale277"
  type: "Scale"
  bottom: "Convolution277"
  top: "Convolution277"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise138"
  type: "Eltwise"
  bottom: "Eltwise137"
  bottom: "Convolution277"
  top: "Eltwise138"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU277"
  type: "ReLU"
  bottom: "Eltwise138"
  top: "Eltwise138"
}
layer {
  name: "Convolution278"
  type: "Convolution"
  bottom: "Eltwise138"
  top: "Convolution278"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm278"
  type: "BatchNorm"
  bottom: "Convolution278"
  top: "Convolution278"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale278"
  type: "Scale"
  bottom: "Convolution278"
  top: "Convolution278"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU278"
  type: "ReLU"
  bottom: "Convolution278"
  top: "Convolution278"
}
layer {
  name: "Convolution279"
  type: "Convolution"
  bottom: "Convolution278"
  top: "Convolution279"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm279"
  type: "BatchNorm"
  bottom: "Convolution279"
  top: "Convolution279"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale279"
  type: "Scale"
  bottom: "Convolution279"
  top: "Convolution279"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise139"
  type: "Eltwise"
  bottom: "Eltwise138"
  bottom: "Convolution279"
  top: "Eltwise139"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU279"
  type: "ReLU"
  bottom: "Eltwise139"
  top: "Eltwise139"
}
layer {
  name: "Convolution280"
  type: "Convolution"
  bottom: "Eltwise139"
  top: "Convolution280"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm280"
  type: "BatchNorm"
  bottom: "Convolution280"
  top: "Convolution280"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale280"
  type: "Scale"
  bottom: "Convolution280"
  top: "Convolution280"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU280"
  type: "ReLU"
  bottom: "Convolution280"
  top: "Convolution280"
}
layer {
  name: "Convolution281"
  type: "Convolution"
  bottom: "Convolution280"
  top: "Convolution281"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm281"
  type: "BatchNorm"
  bottom: "Convolution281"
  top: "Convolution281"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale281"
  type: "Scale"
  bottom: "Convolution281"
  top: "Convolution281"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise140"
  type: "Eltwise"
  bottom: "Eltwise139"
  bottom: "Convolution281"
  top: "Eltwise140"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU281"
  type: "ReLU"
  bottom: "Eltwise140"
  top: "Eltwise140"
}
layer {
  name: "Convolution282"
  type: "Convolution"
  bottom: "Eltwise140"
  top: "Convolution282"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm282"
  type: "BatchNorm"
  bottom: "Convolution282"
  top: "Convolution282"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale282"
  type: "Scale"
  bottom: "Convolution282"
  top: "Convolution282"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU282"
  type: "ReLU"
  bottom: "Convolution282"
  top: "Convolution282"
}
layer {
  name: "Convolution283"
  type: "Convolution"
  bottom: "Convolution282"
  top: "Convolution283"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm283"
  type: "BatchNorm"
  bottom: "Convolution283"
  top: "Convolution283"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale283"
  type: "Scale"
  bottom: "Convolution283"
  top: "Convolution283"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise141"
  type: "Eltwise"
  bottom: "Eltwise140"
  bottom: "Convolution283"
  top: "Eltwise141"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU283"
  type: "ReLU"
  bottom: "Eltwise141"
  top: "Eltwise141"
}
layer {
  name: "Convolution284"
  type: "Convolution"
  bottom: "Eltwise141"
  top: "Convolution284"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm284"
  type: "BatchNorm"
  bottom: "Convolution284"
  top: "Convolution284"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale284"
  type: "Scale"
  bottom: "Convolution284"
  top: "Convolution284"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU284"
  type: "ReLU"
  bottom: "Convolution284"
  top: "Convolution284"
}
layer {
  name: "Convolution285"
  type: "Convolution"
  bottom: "Convolution284"
  top: "Convolution285"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm285"
  type: "BatchNorm"
  bottom: "Convolution285"
  top: "Convolution285"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale285"
  type: "Scale"
  bottom: "Convolution285"
  top: "Convolution285"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise142"
  type: "Eltwise"
  bottom: "Eltwise141"
  bottom: "Convolution285"
  top: "Eltwise142"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU285"
  type: "ReLU"
  bottom: "Eltwise142"
  top: "Eltwise142"
}
layer {
  name: "Convolution286"
  type: "Convolution"
  bottom: "Eltwise142"
  top: "Convolution286"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm286"
  type: "BatchNorm"
  bottom: "Convolution286"
  top: "Convolution286"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale286"
  type: "Scale"
  bottom: "Convolution286"
  top: "Convolution286"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU286"
  type: "ReLU"
  bottom: "Convolution286"
  top: "Convolution286"
}
layer {
  name: "Convolution287"
  type: "Convolution"
  bottom: "Convolution286"
  top: "Convolution287"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm287"
  type: "BatchNorm"
  bottom: "Convolution287"
  top: "Convolution287"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale287"
  type: "Scale"
  bottom: "Convolution287"
  top: "Convolution287"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise143"
  type: "Eltwise"
  bottom: "Eltwise142"
  bottom: "Convolution287"
  top: "Eltwise143"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU287"
  type: "ReLU"
  bottom: "Eltwise143"
  top: "Eltwise143"
}
layer {
  name: "Convolution288"
  type: "Convolution"
  bottom: "Eltwise143"
  top: "Convolution288"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm288"
  type: "BatchNorm"
  bottom: "Convolution288"
  top: "Convolution288"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale288"
  type: "Scale"
  bottom: "Convolution288"
  top: "Convolution288"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU288"
  type: "ReLU"
  bottom: "Convolution288"
  top: "Convolution288"
}
layer {
  name: "Convolution289"
  type: "Convolution"
  bottom: "Convolution288"
  top: "Convolution289"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm289"
  type: "BatchNorm"
  bottom: "Convolution289"
  top: "Convolution289"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale289"
  type: "Scale"
  bottom: "Convolution289"
  top: "Convolution289"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise144"
  type: "Eltwise"
  bottom: "Eltwise143"
  bottom: "Convolution289"
  top: "Eltwise144"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU289"
  type: "ReLU"
  bottom: "Eltwise144"
  top: "Eltwise144"
}
layer {
  name: "Convolution290"
  type: "Convolution"
  bottom: "Eltwise144"
  top: "Convolution290"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm290"
  type: "BatchNorm"
  bottom: "Convolution290"
  top: "Convolution290"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale290"
  type: "Scale"
  bottom: "Convolution290"
  top: "Convolution290"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU290"
  type: "ReLU"
  bottom: "Convolution290"
  top: "Convolution290"
}
layer {
  name: "Convolution291"
  type: "Convolution"
  bottom: "Convolution290"
  top: "Convolution291"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm291"
  type: "BatchNorm"
  bottom: "Convolution291"
  top: "Convolution291"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale291"
  type: "Scale"
  bottom: "Convolution291"
  top: "Convolution291"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise145"
  type: "Eltwise"
  bottom: "Eltwise144"
  bottom: "Convolution291"
  top: "Eltwise145"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU291"
  type: "ReLU"
  bottom: "Eltwise145"
  top: "Eltwise145"
}
layer {
  name: "Convolution292"
  type: "Convolution"
  bottom: "Eltwise145"
  top: "Convolution292"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm292"
  type: "BatchNorm"
  bottom: "Convolution292"
  top: "Convolution292"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale292"
  type: "Scale"
  bottom: "Convolution292"
  top: "Convolution292"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU292"
  type: "ReLU"
  bottom: "Convolution292"
  top: "Convolution292"
}
layer {
  name: "Convolution293"
  type: "Convolution"
  bottom: "Convolution292"
  top: "Convolution293"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm293"
  type: "BatchNorm"
  bottom: "Convolution293"
  top: "Convolution293"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale293"
  type: "Scale"
  bottom: "Convolution293"
  top: "Convolution293"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise146"
  type: "Eltwise"
  bottom: "Eltwise145"
  bottom: "Convolution293"
  top: "Eltwise146"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU293"
  type: "ReLU"
  bottom: "Eltwise146"
  top: "Eltwise146"
}
layer {
  name: "Convolution294"
  type: "Convolution"
  bottom: "Eltwise146"
  top: "Convolution294"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm294"
  type: "BatchNorm"
  bottom: "Convolution294"
  top: "Convolution294"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale294"
  type: "Scale"
  bottom: "Convolution294"
  top: "Convolution294"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU294"
  type: "ReLU"
  bottom: "Convolution294"
  top: "Convolution294"
}
layer {
  name: "Convolution295"
  type: "Convolution"
  bottom: "Convolution294"
  top: "Convolution295"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm295"
  type: "BatchNorm"
  bottom: "Convolution295"
  top: "Convolution295"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale295"
  type: "Scale"
  bottom: "Convolution295"
  top: "Convolution295"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise147"
  type: "Eltwise"
  bottom: "Eltwise146"
  bottom: "Convolution295"
  top: "Eltwise147"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU295"
  type: "ReLU"
  bottom: "Eltwise147"
  top: "Eltwise147"
}
layer {
  name: "Convolution296"
  type: "Convolution"
  bottom: "Eltwise147"
  top: "Convolution296"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm296"
  type: "BatchNorm"
  bottom: "Convolution296"
  top: "Convolution296"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale296"
  type: "Scale"
  bottom: "Convolution296"
  top: "Convolution296"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU296"
  type: "ReLU"
  bottom: "Convolution296"
  top: "Convolution296"
}
layer {
  name: "Convolution297"
  type: "Convolution"
  bottom: "Convolution296"
  top: "Convolution297"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm297"
  type: "BatchNorm"
  bottom: "Convolution297"
  top: "Convolution297"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale297"
  type: "Scale"
  bottom: "Convolution297"
  top: "Convolution297"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise148"
  type: "Eltwise"
  bottom: "Eltwise147"
  bottom: "Convolution297"
  top: "Eltwise148"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU297"
  type: "ReLU"
  bottom: "Eltwise148"
  top: "Eltwise148"
}
layer {
  name: "Convolution298"
  type: "Convolution"
  bottom: "Eltwise148"
  top: "Convolution298"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm298"
  type: "BatchNorm"
  bottom: "Convolution298"
  top: "Convolution298"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale298"
  type: "Scale"
  bottom: "Convolution298"
  top: "Convolution298"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU298"
  type: "ReLU"
  bottom: "Convolution298"
  top: "Convolution298"
}
layer {
  name: "Convolution299"
  type: "Convolution"
  bottom: "Convolution298"
  top: "Convolution299"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm299"
  type: "BatchNorm"
  bottom: "Convolution299"
  top: "Convolution299"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale299"
  type: "Scale"
  bottom: "Convolution299"
  top: "Convolution299"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise149"
  type: "Eltwise"
  bottom: "Eltwise148"
  bottom: "Convolution299"
  top: "Eltwise149"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU299"
  type: "ReLU"
  bottom: "Eltwise149"
  top: "Eltwise149"
}
layer {
  name: "Convolution300"
  type: "Convolution"
  bottom: "Eltwise149"
  top: "Convolution300"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm300"
  type: "BatchNorm"
  bottom: "Convolution300"
  top: "Convolution300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale300"
  type: "Scale"
  bottom: "Convolution300"
  top: "Convolution300"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU300"
  type: "ReLU"
  bottom: "Convolution300"
  top: "Convolution300"
}
layer {
  name: "Convolution301"
  type: "Convolution"
  bottom: "Convolution300"
  top: "Convolution301"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm301"
  type: "BatchNorm"
  bottom: "Convolution301"
  top: "Convolution301"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale301"
  type: "Scale"
  bottom: "Convolution301"
  top: "Convolution301"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise150"
  type: "Eltwise"
  bottom: "Eltwise149"
  bottom: "Convolution301"
  top: "Eltwise150"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU301"
  type: "ReLU"
  bottom: "Eltwise150"
  top: "Eltwise150"
}
layer {
  name: "Convolution302"
  type: "Convolution"
  bottom: "Eltwise150"
  top: "Convolution302"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm302"
  type: "BatchNorm"
  bottom: "Convolution302"
  top: "Convolution302"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale302"
  type: "Scale"
  bottom: "Convolution302"
  top: "Convolution302"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU302"
  type: "ReLU"
  bottom: "Convolution302"
  top: "Convolution302"
}
layer {
  name: "Convolution303"
  type: "Convolution"
  bottom: "Convolution302"
  top: "Convolution303"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm303"
  type: "BatchNorm"
  bottom: "Convolution303"
  top: "Convolution303"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale303"
  type: "Scale"
  bottom: "Convolution303"
  top: "Convolution303"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise151"
  type: "Eltwise"
  bottom: "Eltwise150"
  bottom: "Convolution303"
  top: "Eltwise151"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU303"
  type: "ReLU"
  bottom: "Eltwise151"
  top: "Eltwise151"
}
layer {
  name: "Convolution304"
  type: "Convolution"
  bottom: "Eltwise151"
  top: "Convolution304"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm304"
  type: "BatchNorm"
  bottom: "Convolution304"
  top: "Convolution304"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale304"
  type: "Scale"
  bottom: "Convolution304"
  top: "Convolution304"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU304"
  type: "ReLU"
  bottom: "Convolution304"
  top: "Convolution304"
}
layer {
  name: "Convolution305"
  type: "Convolution"
  bottom: "Convolution304"
  top: "Convolution305"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm305"
  type: "BatchNorm"
  bottom: "Convolution305"
  top: "Convolution305"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale305"
  type: "Scale"
  bottom: "Convolution305"
  top: "Convolution305"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise152"
  type: "Eltwise"
  bottom: "Eltwise151"
  bottom: "Convolution305"
  top: "Eltwise152"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU305"
  type: "ReLU"
  bottom: "Eltwise152"
  top: "Eltwise152"
}
layer {
  name: "Convolution306"
  type: "Convolution"
  bottom: "Eltwise152"
  top: "Convolution306"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm306"
  type: "BatchNorm"
  bottom: "Convolution306"
  top: "Convolution306"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale306"
  type: "Scale"
  bottom: "Convolution306"
  top: "Convolution306"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU306"
  type: "ReLU"
  bottom: "Convolution306"
  top: "Convolution306"
}
layer {
  name: "Convolution307"
  type: "Convolution"
  bottom: "Convolution306"
  top: "Convolution307"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm307"
  type: "BatchNorm"
  bottom: "Convolution307"
  top: "Convolution307"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale307"
  type: "Scale"
  bottom: "Convolution307"
  top: "Convolution307"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise153"
  type: "Eltwise"
  bottom: "Eltwise152"
  bottom: "Convolution307"
  top: "Eltwise153"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU307"
  type: "ReLU"
  bottom: "Eltwise153"
  top: "Eltwise153"
}
layer {
  name: "Convolution308"
  type: "Convolution"
  bottom: "Eltwise153"
  top: "Convolution308"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm308"
  type: "BatchNorm"
  bottom: "Convolution308"
  top: "Convolution308"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale308"
  type: "Scale"
  bottom: "Convolution308"
  top: "Convolution308"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU308"
  type: "ReLU"
  bottom: "Convolution308"
  top: "Convolution308"
}
layer {
  name: "Convolution309"
  type: "Convolution"
  bottom: "Convolution308"
  top: "Convolution309"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm309"
  type: "BatchNorm"
  bottom: "Convolution309"
  top: "Convolution309"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale309"
  type: "Scale"
  bottom: "Convolution309"
  top: "Convolution309"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise154"
  type: "Eltwise"
  bottom: "Eltwise153"
  bottom: "Convolution309"
  top: "Eltwise154"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU309"
  type: "ReLU"
  bottom: "Eltwise154"
  top: "Eltwise154"
}
layer {
  name: "Convolution310"
  type: "Convolution"
  bottom: "Eltwise154"
  top: "Convolution310"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm310"
  type: "BatchNorm"
  bottom: "Convolution310"
  top: "Convolution310"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale310"
  type: "Scale"
  bottom: "Convolution310"
  top: "Convolution310"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU310"
  type: "ReLU"
  bottom: "Convolution310"
  top: "Convolution310"
}
layer {
  name: "Convolution311"
  type: "Convolution"
  bottom: "Convolution310"
  top: "Convolution311"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm311"
  type: "BatchNorm"
  bottom: "Convolution311"
  top: "Convolution311"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale311"
  type: "Scale"
  bottom: "Convolution311"
  top: "Convolution311"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise155"
  type: "Eltwise"
  bottom: "Eltwise154"
  bottom: "Convolution311"
  top: "Eltwise155"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU311"
  type: "ReLU"
  bottom: "Eltwise155"
  top: "Eltwise155"
}
layer {
  name: "Convolution312"
  type: "Convolution"
  bottom: "Eltwise155"
  top: "Convolution312"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm312"
  type: "BatchNorm"
  bottom: "Convolution312"
  top: "Convolution312"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale312"
  type: "Scale"
  bottom: "Convolution312"
  top: "Convolution312"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU312"
  type: "ReLU"
  bottom: "Convolution312"
  top: "Convolution312"
}
layer {
  name: "Convolution313"
  type: "Convolution"
  bottom: "Convolution312"
  top: "Convolution313"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm313"
  type: "BatchNorm"
  bottom: "Convolution313"
  top: "Convolution313"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale313"
  type: "Scale"
  bottom: "Convolution313"
  top: "Convolution313"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise156"
  type: "Eltwise"
  bottom: "Eltwise155"
  bottom: "Convolution313"
  top: "Eltwise156"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU313"
  type: "ReLU"
  bottom: "Eltwise156"
  top: "Eltwise156"
}
layer {
  name: "Convolution314"
  type: "Convolution"
  bottom: "Eltwise156"
  top: "Convolution314"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm314"
  type: "BatchNorm"
  bottom: "Convolution314"
  top: "Convolution314"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale314"
  type: "Scale"
  bottom: "Convolution314"
  top: "Convolution314"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU314"
  type: "ReLU"
  bottom: "Convolution314"
  top: "Convolution314"
}
layer {
  name: "Convolution315"
  type: "Convolution"
  bottom: "Convolution314"
  top: "Convolution315"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm315"
  type: "BatchNorm"
  bottom: "Convolution315"
  top: "Convolution315"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale315"
  type: "Scale"
  bottom: "Convolution315"
  top: "Convolution315"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise157"
  type: "Eltwise"
  bottom: "Eltwise156"
  bottom: "Convolution315"
  top: "Eltwise157"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU315"
  type: "ReLU"
  bottom: "Eltwise157"
  top: "Eltwise157"
}
layer {
  name: "Convolution316"
  type: "Convolution"
  bottom: "Eltwise157"
  top: "Convolution316"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm316"
  type: "BatchNorm"
  bottom: "Convolution316"
  top: "Convolution316"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale316"
  type: "Scale"
  bottom: "Convolution316"
  top: "Convolution316"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU316"
  type: "ReLU"
  bottom: "Convolution316"
  top: "Convolution316"
}
layer {
  name: "Convolution317"
  type: "Convolution"
  bottom: "Convolution316"
  top: "Convolution317"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm317"
  type: "BatchNorm"
  bottom: "Convolution317"
  top: "Convolution317"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale317"
  type: "Scale"
  bottom: "Convolution317"
  top: "Convolution317"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise158"
  type: "Eltwise"
  bottom: "Eltwise157"
  bottom: "Convolution317"
  top: "Eltwise158"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU317"
  type: "ReLU"
  bottom: "Eltwise158"
  top: "Eltwise158"
}
layer {
  name: "Convolution318"
  type: "Convolution"
  bottom: "Eltwise158"
  top: "Convolution318"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm318"
  type: "BatchNorm"
  bottom: "Convolution318"
  top: "Convolution318"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale318"
  type: "Scale"
  bottom: "Convolution318"
  top: "Convolution318"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU318"
  type: "ReLU"
  bottom: "Convolution318"
  top: "Convolution318"
}
layer {
  name: "Convolution319"
  type: "Convolution"
  bottom: "Convolution318"
  top: "Convolution319"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm319"
  type: "BatchNorm"
  bottom: "Convolution319"
  top: "Convolution319"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale319"
  type: "Scale"
  bottom: "Convolution319"
  top: "Convolution319"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise159"
  type: "Eltwise"
  bottom: "Eltwise158"
  bottom: "Convolution319"
  top: "Eltwise159"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU319"
  type: "ReLU"
  bottom: "Eltwise159"
  top: "Eltwise159"
}
layer {
  name: "Convolution320"
  type: "Convolution"
  bottom: "Eltwise159"
  top: "Convolution320"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm320"
  type: "BatchNorm"
  bottom: "Convolution320"
  top: "Convolution320"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale320"
  type: "Scale"
  bottom: "Convolution320"
  top: "Convolution320"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU320"
  type: "ReLU"
  bottom: "Convolution320"
  top: "Convolution320"
}
layer {
  name: "Convolution321"
  type: "Convolution"
  bottom: "Convolution320"
  top: "Convolution321"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm321"
  type: "BatchNorm"
  bottom: "Convolution321"
  top: "Convolution321"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale321"
  type: "Scale"
  bottom: "Convolution321"
  top: "Convolution321"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise160"
  type: "Eltwise"
  bottom: "Eltwise159"
  bottom: "Convolution321"
  top: "Eltwise160"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU321"
  type: "ReLU"
  bottom: "Eltwise160"
  top: "Eltwise160"
}
layer {
  name: "Convolution322"
  type: "Convolution"
  bottom: "Eltwise160"
  top: "Convolution322"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm322"
  type: "BatchNorm"
  bottom: "Convolution322"
  top: "Convolution322"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale322"
  type: "Scale"
  bottom: "Convolution322"
  top: "Convolution322"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU322"
  type: "ReLU"
  bottom: "Convolution322"
  top: "Convolution322"
}
layer {
  name: "Convolution323"
  type: "Convolution"
  bottom: "Convolution322"
  top: "Convolution323"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm323"
  type: "BatchNorm"
  bottom: "Convolution323"
  top: "Convolution323"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale323"
  type: "Scale"
  bottom: "Convolution323"
  top: "Convolution323"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise161"
  type: "Eltwise"
  bottom: "Eltwise160"
  bottom: "Convolution323"
  top: "Eltwise161"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU323"
  type: "ReLU"
  bottom: "Eltwise161"
  top: "Eltwise161"
}
layer {
  name: "Convolution324"
  type: "Convolution"
  bottom: "Eltwise161"
  top: "Convolution324"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm324"
  type: "BatchNorm"
  bottom: "Convolution324"
  top: "Convolution324"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale324"
  type: "Scale"
  bottom: "Convolution324"
  top: "Convolution324"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU324"
  type: "ReLU"
  bottom: "Convolution324"
  top: "Convolution324"
}
layer {
  name: "Convolution325"
  type: "Convolution"
  bottom: "Convolution324"
  top: "Convolution325"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm325"
  type: "BatchNorm"
  bottom: "Convolution325"
  top: "Convolution325"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale325"
  type: "Scale"
  bottom: "Convolution325"
  top: "Convolution325"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise162"
  type: "Eltwise"
  bottom: "Eltwise161"
  bottom: "Convolution325"
  top: "Eltwise162"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU325"
  type: "ReLU"
  bottom: "Eltwise162"
  top: "Eltwise162"
}
layer {
  name: "Convolution326"
  type: "Convolution"
  bottom: "Eltwise162"
  top: "Convolution326"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm326"
  type: "BatchNorm"
  bottom: "Convolution326"
  top: "Convolution326"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale326"
  type: "Scale"
  bottom: "Convolution326"
  top: "Convolution326"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU326"
  type: "ReLU"
  bottom: "Convolution326"
  top: "Convolution326"
}
layer {
  name: "Convolution327"
  type: "Convolution"
  bottom: "Convolution326"
  top: "Convolution327"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm327"
  type: "BatchNorm"
  bottom: "Convolution327"
  top: "Convolution327"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale327"
  type: "Scale"
  bottom: "Convolution327"
  top: "Convolution327"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise163"
  type: "Eltwise"
  bottom: "Eltwise162"
  bottom: "Convolution327"
  top: "Eltwise163"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU327"
  type: "ReLU"
  bottom: "Eltwise163"
  top: "Eltwise163"
}
layer {
  name: "Convolution328"
  type: "Convolution"
  bottom: "Eltwise163"
  top: "Convolution328"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm328"
  type: "BatchNorm"
  bottom: "Convolution328"
  top: "Convolution328"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale328"
  type: "Scale"
  bottom: "Convolution328"
  top: "Convolution328"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU328"
  type: "ReLU"
  bottom: "Convolution328"
  top: "Convolution328"
}
layer {
  name: "Convolution329"
  type: "Convolution"
  bottom: "Convolution328"
  top: "Convolution329"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm329"
  type: "BatchNorm"
  bottom: "Convolution329"
  top: "Convolution329"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale329"
  type: "Scale"
  bottom: "Convolution329"
  top: "Convolution329"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise164"
  type: "Eltwise"
  bottom: "Eltwise163"
  bottom: "Convolution329"
  top: "Eltwise164"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU329"
  type: "ReLU"
  bottom: "Eltwise164"
  top: "Eltwise164"
}
layer {
  name: "Convolution330"
  type: "Convolution"
  bottom: "Eltwise164"
  top: "Convolution330"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm330"
  type: "BatchNorm"
  bottom: "Convolution330"
  top: "Convolution330"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale330"
  type: "Scale"
  bottom: "Convolution330"
  top: "Convolution330"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU330"
  type: "ReLU"
  bottom: "Convolution330"
  top: "Convolution330"
}
layer {
  name: "Convolution331"
  type: "Convolution"
  bottom: "Convolution330"
  top: "Convolution331"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm331"
  type: "BatchNorm"
  bottom: "Convolution331"
  top: "Convolution331"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale331"
  type: "Scale"
  bottom: "Convolution331"
  top: "Convolution331"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise165"
  type: "Eltwise"
  bottom: "Eltwise164"
  bottom: "Convolution331"
  top: "Eltwise165"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU331"
  type: "ReLU"
  bottom: "Eltwise165"
  top: "Eltwise165"
}
layer {
  name: "Convolution332"
  type: "Convolution"
  bottom: "Eltwise165"
  top: "Convolution332"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm332"
  type: "BatchNorm"
  bottom: "Convolution332"
  top: "Convolution332"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale332"
  type: "Scale"
  bottom: "Convolution332"
  top: "Convolution332"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU332"
  type: "ReLU"
  bottom: "Convolution332"
  top: "Convolution332"
}
layer {
  name: "Convolution333"
  type: "Convolution"
  bottom: "Convolution332"
  top: "Convolution333"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm333"
  type: "BatchNorm"
  bottom: "Convolution333"
  top: "Convolution333"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale333"
  type: "Scale"
  bottom: "Convolution333"
  top: "Convolution333"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise166"
  type: "Eltwise"
  bottom: "Eltwise165"
  bottom: "Convolution333"
  top: "Eltwise166"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU333"
  type: "ReLU"
  bottom: "Eltwise166"
  top: "Eltwise166"
}
layer {
  name: "Convolution334"
  type: "Convolution"
  bottom: "Eltwise166"
  top: "Convolution334"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm334"
  type: "BatchNorm"
  bottom: "Convolution334"
  top: "Convolution334"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale334"
  type: "Scale"
  bottom: "Convolution334"
  top: "Convolution334"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU334"
  type: "ReLU"
  bottom: "Convolution334"
  top: "Convolution334"
}
layer {
  name: "Convolution335"
  type: "Convolution"
  bottom: "Convolution334"
  top: "Convolution335"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm335"
  type: "BatchNorm"
  bottom: "Convolution335"
  top: "Convolution335"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale335"
  type: "Scale"
  bottom: "Convolution335"
  top: "Convolution335"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise167"
  type: "Eltwise"
  bottom: "Eltwise166"
  bottom: "Convolution335"
  top: "Eltwise167"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU335"
  type: "ReLU"
  bottom: "Eltwise167"
  top: "Eltwise167"
}
layer {
  name: "Convolution336"
  type: "Convolution"
  bottom: "Eltwise167"
  top: "Convolution336"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm336"
  type: "BatchNorm"
  bottom: "Convolution336"
  top: "Convolution336"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale336"
  type: "Scale"
  bottom: "Convolution336"
  top: "Convolution336"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU336"
  type: "ReLU"
  bottom: "Convolution336"
  top: "Convolution336"
}
layer {
  name: "Convolution337"
  type: "Convolution"
  bottom: "Convolution336"
  top: "Convolution337"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm337"
  type: "BatchNorm"
  bottom: "Convolution337"
  top: "Convolution337"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale337"
  type: "Scale"
  bottom: "Convolution337"
  top: "Convolution337"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise168"
  type: "Eltwise"
  bottom: "Eltwise167"
  bottom: "Convolution337"
  top: "Eltwise168"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU337"
  type: "ReLU"
  bottom: "Eltwise168"
  top: "Eltwise168"
}
layer {
  name: "Convolution338"
  type: "Convolution"
  bottom: "Eltwise168"
  top: "Convolution338"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm338"
  type: "BatchNorm"
  bottom: "Convolution338"
  top: "Convolution338"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale338"
  type: "Scale"
  bottom: "Convolution338"
  top: "Convolution338"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU338"
  type: "ReLU"
  bottom: "Convolution338"
  top: "Convolution338"
}
layer {
  name: "Convolution339"
  type: "Convolution"
  bottom: "Convolution338"
  top: "Convolution339"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm339"
  type: "BatchNorm"
  bottom: "Convolution339"
  top: "Convolution339"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale339"
  type: "Scale"
  bottom: "Convolution339"
  top: "Convolution339"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise169"
  type: "Eltwise"
  bottom: "Eltwise168"
  bottom: "Convolution339"
  top: "Eltwise169"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU339"
  type: "ReLU"
  bottom: "Eltwise169"
  top: "Eltwise169"
}
layer {
  name: "Convolution340"
  type: "Convolution"
  bottom: "Eltwise169"
  top: "Convolution340"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm340"
  type: "BatchNorm"
  bottom: "Convolution340"
  top: "Convolution340"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale340"
  type: "Scale"
  bottom: "Convolution340"
  top: "Convolution340"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU340"
  type: "ReLU"
  bottom: "Convolution340"
  top: "Convolution340"
}
layer {
  name: "Convolution341"
  type: "Convolution"
  bottom: "Convolution340"
  top: "Convolution341"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm341"
  type: "BatchNorm"
  bottom: "Convolution341"
  top: "Convolution341"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale341"
  type: "Scale"
  bottom: "Convolution341"
  top: "Convolution341"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise170"
  type: "Eltwise"
  bottom: "Eltwise169"
  bottom: "Convolution341"
  top: "Eltwise170"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU341"
  type: "ReLU"
  bottom: "Eltwise170"
  top: "Eltwise170"
}
layer {
  name: "Convolution342"
  type: "Convolution"
  bottom: "Eltwise170"
  top: "Convolution342"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm342"
  type: "BatchNorm"
  bottom: "Convolution342"
  top: "Convolution342"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale342"
  type: "Scale"
  bottom: "Convolution342"
  top: "Convolution342"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU342"
  type: "ReLU"
  bottom: "Convolution342"
  top: "Convolution342"
}
layer {
  name: "Convolution343"
  type: "Convolution"
  bottom: "Convolution342"
  top: "Convolution343"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm343"
  type: "BatchNorm"
  bottom: "Convolution343"
  top: "Convolution343"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale343"
  type: "Scale"
  bottom: "Convolution343"
  top: "Convolution343"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise171"
  type: "Eltwise"
  bottom: "Eltwise170"
  bottom: "Convolution343"
  top: "Eltwise171"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU343"
  type: "ReLU"
  bottom: "Eltwise171"
  top: "Eltwise171"
}
layer {
  name: "Convolution344"
  type: "Convolution"
  bottom: "Eltwise171"
  top: "Convolution344"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm344"
  type: "BatchNorm"
  bottom: "Convolution344"
  top: "Convolution344"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale344"
  type: "Scale"
  bottom: "Convolution344"
  top: "Convolution344"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU344"
  type: "ReLU"
  bottom: "Convolution344"
  top: "Convolution344"
}
layer {
  name: "Convolution345"
  type: "Convolution"
  bottom: "Convolution344"
  top: "Convolution345"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm345"
  type: "BatchNorm"
  bottom: "Convolution345"
  top: "Convolution345"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale345"
  type: "Scale"
  bottom: "Convolution345"
  top: "Convolution345"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise172"
  type: "Eltwise"
  bottom: "Eltwise171"
  bottom: "Convolution345"
  top: "Eltwise172"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU345"
  type: "ReLU"
  bottom: "Eltwise172"
  top: "Eltwise172"
}
layer {
  name: "Convolution346"
  type: "Convolution"
  bottom: "Eltwise172"
  top: "Convolution346"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm346"
  type: "BatchNorm"
  bottom: "Convolution346"
  top: "Convolution346"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale346"
  type: "Scale"
  bottom: "Convolution346"
  top: "Convolution346"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU346"
  type: "ReLU"
  bottom: "Convolution346"
  top: "Convolution346"
}
layer {
  name: "Convolution347"
  type: "Convolution"
  bottom: "Convolution346"
  top: "Convolution347"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm347"
  type: "BatchNorm"
  bottom: "Convolution347"
  top: "Convolution347"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale347"
  type: "Scale"
  bottom: "Convolution347"
  top: "Convolution347"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise173"
  type: "Eltwise"
  bottom: "Eltwise172"
  bottom: "Convolution347"
  top: "Eltwise173"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU347"
  type: "ReLU"
  bottom: "Eltwise173"
  top: "Eltwise173"
}
layer {
  name: "Convolution348"
  type: "Convolution"
  bottom: "Eltwise173"
  top: "Convolution348"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm348"
  type: "BatchNorm"
  bottom: "Convolution348"
  top: "Convolution348"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale348"
  type: "Scale"
  bottom: "Convolution348"
  top: "Convolution348"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU348"
  type: "ReLU"
  bottom: "Convolution348"
  top: "Convolution348"
}
layer {
  name: "Convolution349"
  type: "Convolution"
  bottom: "Convolution348"
  top: "Convolution349"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm349"
  type: "BatchNorm"
  bottom: "Convolution349"
  top: "Convolution349"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale349"
  type: "Scale"
  bottom: "Convolution349"
  top: "Convolution349"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise174"
  type: "Eltwise"
  bottom: "Eltwise173"
  bottom: "Convolution349"
  top: "Eltwise174"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU349"
  type: "ReLU"
  bottom: "Eltwise174"
  top: "Eltwise174"
}
layer {
  name: "Convolution350"
  type: "Convolution"
  bottom: "Eltwise174"
  top: "Convolution350"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm350"
  type: "BatchNorm"
  bottom: "Convolution350"
  top: "Convolution350"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale350"
  type: "Scale"
  bottom: "Convolution350"
  top: "Convolution350"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU350"
  type: "ReLU"
  bottom: "Convolution350"
  top: "Convolution350"
}
layer {
  name: "Convolution351"
  type: "Convolution"
  bottom: "Convolution350"
  top: "Convolution351"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm351"
  type: "BatchNorm"
  bottom: "Convolution351"
  top: "Convolution351"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale351"
  type: "Scale"
  bottom: "Convolution351"
  top: "Convolution351"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise175"
  type: "Eltwise"
  bottom: "Eltwise174"
  bottom: "Convolution351"
  top: "Eltwise175"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU351"
  type: "ReLU"
  bottom: "Eltwise175"
  top: "Eltwise175"
}
layer {
  name: "Convolution352"
  type: "Convolution"
  bottom: "Eltwise175"
  top: "Convolution352"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm352"
  type: "BatchNorm"
  bottom: "Convolution352"
  top: "Convolution352"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale352"
  type: "Scale"
  bottom: "Convolution352"
  top: "Convolution352"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU352"
  type: "ReLU"
  bottom: "Convolution352"
  top: "Convolution352"
}
layer {
  name: "Convolution353"
  type: "Convolution"
  bottom: "Convolution352"
  top: "Convolution353"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm353"
  type: "BatchNorm"
  bottom: "Convolution353"
  top: "Convolution353"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale353"
  type: "Scale"
  bottom: "Convolution353"
  top: "Convolution353"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise176"
  type: "Eltwise"
  bottom: "Eltwise175"
  bottom: "Convolution353"
  top: "Eltwise176"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU353"
  type: "ReLU"
  bottom: "Eltwise176"
  top: "Eltwise176"
}
layer {
  name: "Convolution354"
  type: "Convolution"
  bottom: "Eltwise176"
  top: "Convolution354"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm354"
  type: "BatchNorm"
  bottom: "Convolution354"
  top: "Convolution354"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale354"
  type: "Scale"
  bottom: "Convolution354"
  top: "Convolution354"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU354"
  type: "ReLU"
  bottom: "Convolution354"
  top: "Convolution354"
}
layer {
  name: "Convolution355"
  type: "Convolution"
  bottom: "Convolution354"
  top: "Convolution355"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm355"
  type: "BatchNorm"
  bottom: "Convolution355"
  top: "Convolution355"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale355"
  type: "Scale"
  bottom: "Convolution355"
  top: "Convolution355"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise177"
  type: "Eltwise"
  bottom: "Eltwise176"
  bottom: "Convolution355"
  top: "Eltwise177"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU355"
  type: "ReLU"
  bottom: "Eltwise177"
  top: "Eltwise177"
}
layer {
  name: "Convolution356"
  type: "Convolution"
  bottom: "Eltwise177"
  top: "Convolution356"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm356"
  type: "BatchNorm"
  bottom: "Convolution356"
  top: "Convolution356"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale356"
  type: "Scale"
  bottom: "Convolution356"
  top: "Convolution356"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU356"
  type: "ReLU"
  bottom: "Convolution356"
  top: "Convolution356"
}
layer {
  name: "Convolution357"
  type: "Convolution"
  bottom: "Convolution356"
  top: "Convolution357"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm357"
  type: "BatchNorm"
  bottom: "Convolution357"
  top: "Convolution357"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale357"
  type: "Scale"
  bottom: "Convolution357"
  top: "Convolution357"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise178"
  type: "Eltwise"
  bottom: "Eltwise177"
  bottom: "Convolution357"
  top: "Eltwise178"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU357"
  type: "ReLU"
  bottom: "Eltwise178"
  top: "Eltwise178"
}
layer {
  name: "Convolution358"
  type: "Convolution"
  bottom: "Eltwise178"
  top: "Convolution358"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm358"
  type: "BatchNorm"
  bottom: "Convolution358"
  top: "Convolution358"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale358"
  type: "Scale"
  bottom: "Convolution358"
  top: "Convolution358"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU358"
  type: "ReLU"
  bottom: "Convolution358"
  top: "Convolution358"
}
layer {
  name: "Convolution359"
  type: "Convolution"
  bottom: "Convolution358"
  top: "Convolution359"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm359"
  type: "BatchNorm"
  bottom: "Convolution359"
  top: "Convolution359"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale359"
  type: "Scale"
  bottom: "Convolution359"
  top: "Convolution359"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise179"
  type: "Eltwise"
  bottom: "Eltwise178"
  bottom: "Convolution359"
  top: "Eltwise179"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU359"
  type: "ReLU"
  bottom: "Eltwise179"
  top: "Eltwise179"
}
layer {
  name: "Convolution360"
  type: "Convolution"
  bottom: "Eltwise179"
  top: "Convolution360"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm360"
  type: "BatchNorm"
  bottom: "Convolution360"
  top: "Convolution360"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale360"
  type: "Scale"
  bottom: "Convolution360"
  top: "Convolution360"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU360"
  type: "ReLU"
  bottom: "Convolution360"
  top: "Convolution360"
}
layer {
  name: "Convolution361"
  type: "Convolution"
  bottom: "Convolution360"
  top: "Convolution361"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm361"
  type: "BatchNorm"
  bottom: "Convolution361"
  top: "Convolution361"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale361"
  type: "Scale"
  bottom: "Convolution361"
  top: "Convolution361"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise180"
  type: "Eltwise"
  bottom: "Eltwise179"
  bottom: "Convolution361"
  top: "Eltwise180"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU361"
  type: "ReLU"
  bottom: "Eltwise180"
  top: "Eltwise180"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise180"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Input1"
  type: "Input"
  top: "Input1"
  input_param {
    shape {
      dim: 2
      dim: 16
      dim: 16
      dim: 16
    }
  }
}
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "Pooling1"
  bottom: "Input1"
  top: "Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution362"
  type: "Convolution"
  bottom: "Eltwise180"
  top: "Convolution362"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm362"
  type: "BatchNorm"
  bottom: "Convolution362"
  top: "Convolution362"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale362"
  type: "Scale"
  bottom: "Convolution362"
  top: "Convolution362"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU362"
  type: "ReLU"
  bottom: "Convolution362"
  top: "Convolution362"
}
layer {
  name: "Convolution363"
  type: "Convolution"
  bottom: "Convolution362"
  top: "Convolution363"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm363"
  type: "BatchNorm"
  bottom: "Convolution363"
  top: "Convolution363"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale363"
  type: "Scale"
  bottom: "Convolution363"
  top: "Convolution363"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise181"
  type: "Eltwise"
  bottom: "Concat1"
  bottom: "Convolution363"
  top: "Eltwise181"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU363"
  type: "ReLU"
  bottom: "Eltwise181"
  top: "Eltwise181"
}
layer {
  name: "Convolution364"
  type: "Convolution"
  bottom: "Eltwise181"
  top: "Convolution364"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm364"
  type: "BatchNorm"
  bottom: "Convolution364"
  top: "Convolution364"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale364"
  type: "Scale"
  bottom: "Convolution364"
  top: "Convolution364"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU364"
  type: "ReLU"
  bottom: "Convolution364"
  top: "Convolution364"
}
layer {
  name: "Convolution365"
  type: "Convolution"
  bottom: "Convolution364"
  top: "Convolution365"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm365"
  type: "BatchNorm"
  bottom: "Convolution365"
  top: "Convolution365"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale365"
  type: "Scale"
  bottom: "Convolution365"
  top: "Convolution365"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise182"
  type: "Eltwise"
  bottom: "Eltwise181"
  bottom: "Convolution365"
  top: "Eltwise182"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU365"
  type: "ReLU"
  bottom: "Eltwise182"
  top: "Eltwise182"
}
layer {
  name: "Convolution366"
  type: "Convolution"
  bottom: "Eltwise182"
  top: "Convolution366"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm366"
  type: "BatchNorm"
  bottom: "Convolution366"
  top: "Convolution366"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale366"
  type: "Scale"
  bottom: "Convolution366"
  top: "Convolution366"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU366"
  type: "ReLU"
  bottom: "Convolution366"
  top: "Convolution366"
}
layer {
  name: "Convolution367"
  type: "Convolution"
  bottom: "Convolution366"
  top: "Convolution367"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm367"
  type: "BatchNorm"
  bottom: "Convolution367"
  top: "Convolution367"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale367"
  type: "Scale"
  bottom: "Convolution367"
  top: "Convolution367"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise183"
  type: "Eltwise"
  bottom: "Eltwise182"
  bottom: "Convolution367"
  top: "Eltwise183"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU367"
  type: "ReLU"
  bottom: "Eltwise183"
  top: "Eltwise183"
}
layer {
  name: "Convolution368"
  type: "Convolution"
  bottom: "Eltwise183"
  top: "Convolution368"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm368"
  type: "BatchNorm"
  bottom: "Convolution368"
  top: "Convolution368"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale368"
  type: "Scale"
  bottom: "Convolution368"
  top: "Convolution368"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU368"
  type: "ReLU"
  bottom: "Convolution368"
  top: "Convolution368"
}
layer {
  name: "Convolution369"
  type: "Convolution"
  bottom: "Convolution368"
  top: "Convolution369"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm369"
  type: "BatchNorm"
  bottom: "Convolution369"
  top: "Convolution369"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale369"
  type: "Scale"
  bottom: "Convolution369"
  top: "Convolution369"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise184"
  type: "Eltwise"
  bottom: "Eltwise183"
  bottom: "Convolution369"
  top: "Eltwise184"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU369"
  type: "ReLU"
  bottom: "Eltwise184"
  top: "Eltwise184"
}
layer {
  name: "Convolution370"
  type: "Convolution"
  bottom: "Eltwise184"
  top: "Convolution370"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm370"
  type: "BatchNorm"
  bottom: "Convolution370"
  top: "Convolution370"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale370"
  type: "Scale"
  bottom: "Convolution370"
  top: "Convolution370"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU370"
  type: "ReLU"
  bottom: "Convolution370"
  top: "Convolution370"
}
layer {
  name: "Convolution371"
  type: "Convolution"
  bottom: "Convolution370"
  top: "Convolution371"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm371"
  type: "BatchNorm"
  bottom: "Convolution371"
  top: "Convolution371"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale371"
  type: "Scale"
  bottom: "Convolution371"
  top: "Convolution371"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise185"
  type: "Eltwise"
  bottom: "Eltwise184"
  bottom: "Convolution371"
  top: "Eltwise185"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU371"
  type: "ReLU"
  bottom: "Eltwise185"
  top: "Eltwise185"
}
layer {
  name: "Convolution372"
  type: "Convolution"
  bottom: "Eltwise185"
  top: "Convolution372"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm372"
  type: "BatchNorm"
  bottom: "Convolution372"
  top: "Convolution372"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale372"
  type: "Scale"
  bottom: "Convolution372"
  top: "Convolution372"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU372"
  type: "ReLU"
  bottom: "Convolution372"
  top: "Convolution372"
}
layer {
  name: "Convolution373"
  type: "Convolution"
  bottom: "Convolution372"
  top: "Convolution373"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm373"
  type: "BatchNorm"
  bottom: "Convolution373"
  top: "Convolution373"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale373"
  type: "Scale"
  bottom: "Convolution373"
  top: "Convolution373"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise186"
  type: "Eltwise"
  bottom: "Eltwise185"
  bottom: "Convolution373"
  top: "Eltwise186"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU373"
  type: "ReLU"
  bottom: "Eltwise186"
  top: "Eltwise186"
}
layer {
  name: "Convolution374"
  type: "Convolution"
  bottom: "Eltwise186"
  top: "Convolution374"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm374"
  type: "BatchNorm"
  bottom: "Convolution374"
  top: "Convolution374"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale374"
  type: "Scale"
  bottom: "Convolution374"
  top: "Convolution374"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU374"
  type: "ReLU"
  bottom: "Convolution374"
  top: "Convolution374"
}
layer {
  name: "Convolution375"
  type: "Convolution"
  bottom: "Convolution374"
  top: "Convolution375"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm375"
  type: "BatchNorm"
  bottom: "Convolution375"
  top: "Convolution375"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale375"
  type: "Scale"
  bottom: "Convolution375"
  top: "Convolution375"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise187"
  type: "Eltwise"
  bottom: "Eltwise186"
  bottom: "Convolution375"
  top: "Eltwise187"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU375"
  type: "ReLU"
  bottom: "Eltwise187"
  top: "Eltwise187"
}
layer {
  name: "Convolution376"
  type: "Convolution"
  bottom: "Eltwise187"
  top: "Convolution376"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm376"
  type: "BatchNorm"
  bottom: "Convolution376"
  top: "Convolution376"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale376"
  type: "Scale"
  bottom: "Convolution376"
  top: "Convolution376"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU376"
  type: "ReLU"
  bottom: "Convolution376"
  top: "Convolution376"
}
layer {
  name: "Convolution377"
  type: "Convolution"
  bottom: "Convolution376"
  top: "Convolution377"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm377"
  type: "BatchNorm"
  bottom: "Convolution377"
  top: "Convolution377"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale377"
  type: "Scale"
  bottom: "Convolution377"
  top: "Convolution377"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise188"
  type: "Eltwise"
  bottom: "Eltwise187"
  bottom: "Convolution377"
  top: "Eltwise188"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU377"
  type: "ReLU"
  bottom: "Eltwise188"
  top: "Eltwise188"
}
layer {
  name: "Convolution378"
  type: "Convolution"
  bottom: "Eltwise188"
  top: "Convolution378"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm378"
  type: "BatchNorm"
  bottom: "Convolution378"
  top: "Convolution378"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale378"
  type: "Scale"
  bottom: "Convolution378"
  top: "Convolution378"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU378"
  type: "ReLU"
  bottom: "Convolution378"
  top: "Convolution378"
}
layer {
  name: "Convolution379"
  type: "Convolution"
  bottom: "Convolution378"
  top: "Convolution379"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm379"
  type: "BatchNorm"
  bottom: "Convolution379"
  top: "Convolution379"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale379"
  type: "Scale"
  bottom: "Convolution379"
  top: "Convolution379"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise189"
  type: "Eltwise"
  bottom: "Eltwise188"
  bottom: "Convolution379"
  top: "Eltwise189"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU379"
  type: "ReLU"
  bottom: "Eltwise189"
  top: "Eltwise189"
}
layer {
  name: "Convolution380"
  type: "Convolution"
  bottom: "Eltwise189"
  top: "Convolution380"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm380"
  type: "BatchNorm"
  bottom: "Convolution380"
  top: "Convolution380"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale380"
  type: "Scale"
  bottom: "Convolution380"
  top: "Convolution380"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU380"
  type: "ReLU"
  bottom: "Convolution380"
  top: "Convolution380"
}
layer {
  name: "Convolution381"
  type: "Convolution"
  bottom: "Convolution380"
  top: "Convolution381"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm381"
  type: "BatchNorm"
  bottom: "Convolution381"
  top: "Convolution381"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale381"
  type: "Scale"
  bottom: "Convolution381"
  top: "Convolution381"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise190"
  type: "Eltwise"
  bottom: "Eltwise189"
  bottom: "Convolution381"
  top: "Eltwise190"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU381"
  type: "ReLU"
  bottom: "Eltwise190"
  top: "Eltwise190"
}
layer {
  name: "Convolution382"
  type: "Convolution"
  bottom: "Eltwise190"
  top: "Convolution382"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm382"
  type: "BatchNorm"
  bottom: "Convolution382"
  top: "Convolution382"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale382"
  type: "Scale"
  bottom: "Convolution382"
  top: "Convolution382"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU382"
  type: "ReLU"
  bottom: "Convolution382"
  top: "Convolution382"
}
layer {
  name: "Convolution383"
  type: "Convolution"
  bottom: "Convolution382"
  top: "Convolution383"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm383"
  type: "BatchNorm"
  bottom: "Convolution383"
  top: "Convolution383"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale383"
  type: "Scale"
  bottom: "Convolution383"
  top: "Convolution383"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise191"
  type: "Eltwise"
  bottom: "Eltwise190"
  bottom: "Convolution383"
  top: "Eltwise191"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU383"
  type: "ReLU"
  bottom: "Eltwise191"
  top: "Eltwise191"
}
layer {
  name: "Convolution384"
  type: "Convolution"
  bottom: "Eltwise191"
  top: "Convolution384"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm384"
  type: "BatchNorm"
  bottom: "Convolution384"
  top: "Convolution384"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale384"
  type: "Scale"
  bottom: "Convolution384"
  top: "Convolution384"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU384"
  type: "ReLU"
  bottom: "Convolution384"
  top: "Convolution384"
}
layer {
  name: "Convolution385"
  type: "Convolution"
  bottom: "Convolution384"
  top: "Convolution385"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm385"
  type: "BatchNorm"
  bottom: "Convolution385"
  top: "Convolution385"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale385"
  type: "Scale"
  bottom: "Convolution385"
  top: "Convolution385"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise192"
  type: "Eltwise"
  bottom: "Eltwise191"
  bottom: "Convolution385"
  top: "Eltwise192"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU385"
  type: "ReLU"
  bottom: "Eltwise192"
  top: "Eltwise192"
}
layer {
  name: "Convolution386"
  type: "Convolution"
  bottom: "Eltwise192"
  top: "Convolution386"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm386"
  type: "BatchNorm"
  bottom: "Convolution386"
  top: "Convolution386"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale386"
  type: "Scale"
  bottom: "Convolution386"
  top: "Convolution386"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU386"
  type: "ReLU"
  bottom: "Convolution386"
  top: "Convolution386"
}
layer {
  name: "Convolution387"
  type: "Convolution"
  bottom: "Convolution386"
  top: "Convolution387"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm387"
  type: "BatchNorm"
  bottom: "Convolution387"
  top: "Convolution387"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale387"
  type: "Scale"
  bottom: "Convolution387"
  top: "Convolution387"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise193"
  type: "Eltwise"
  bottom: "Eltwise192"
  bottom: "Convolution387"
  top: "Eltwise193"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU387"
  type: "ReLU"
  bottom: "Eltwise193"
  top: "Eltwise193"
}
layer {
  name: "Convolution388"
  type: "Convolution"
  bottom: "Eltwise193"
  top: "Convolution388"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm388"
  type: "BatchNorm"
  bottom: "Convolution388"
  top: "Convolution388"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale388"
  type: "Scale"
  bottom: "Convolution388"
  top: "Convolution388"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU388"
  type: "ReLU"
  bottom: "Convolution388"
  top: "Convolution388"
}
layer {
  name: "Convolution389"
  type: "Convolution"
  bottom: "Convolution388"
  top: "Convolution389"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm389"
  type: "BatchNorm"
  bottom: "Convolution389"
  top: "Convolution389"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale389"
  type: "Scale"
  bottom: "Convolution389"
  top: "Convolution389"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise194"
  type: "Eltwise"
  bottom: "Eltwise193"
  bottom: "Convolution389"
  top: "Eltwise194"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU389"
  type: "ReLU"
  bottom: "Eltwise194"
  top: "Eltwise194"
}
layer {
  name: "Convolution390"
  type: "Convolution"
  bottom: "Eltwise194"
  top: "Convolution390"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm390"
  type: "BatchNorm"
  bottom: "Convolution390"
  top: "Convolution390"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale390"
  type: "Scale"
  bottom: "Convolution390"
  top: "Convolution390"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU390"
  type: "ReLU"
  bottom: "Convolution390"
  top: "Convolution390"
}
layer {
  name: "Convolution391"
  type: "Convolution"
  bottom: "Convolution390"
  top: "Convolution391"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm391"
  type: "BatchNorm"
  bottom: "Convolution391"
  top: "Convolution391"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale391"
  type: "Scale"
  bottom: "Convolution391"
  top: "Convolution391"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise195"
  type: "Eltwise"
  bottom: "Eltwise194"
  bottom: "Convolution391"
  top: "Eltwise195"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU391"
  type: "ReLU"
  bottom: "Eltwise195"
  top: "Eltwise195"
}
layer {
  name: "Convolution392"
  type: "Convolution"
  bottom: "Eltwise195"
  top: "Convolution392"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm392"
  type: "BatchNorm"
  bottom: "Convolution392"
  top: "Convolution392"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale392"
  type: "Scale"
  bottom: "Convolution392"
  top: "Convolution392"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU392"
  type: "ReLU"
  bottom: "Convolution392"
  top: "Convolution392"
}
layer {
  name: "Convolution393"
  type: "Convolution"
  bottom: "Convolution392"
  top: "Convolution393"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm393"
  type: "BatchNorm"
  bottom: "Convolution393"
  top: "Convolution393"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale393"
  type: "Scale"
  bottom: "Convolution393"
  top: "Convolution393"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise196"
  type: "Eltwise"
  bottom: "Eltwise195"
  bottom: "Convolution393"
  top: "Eltwise196"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU393"
  type: "ReLU"
  bottom: "Eltwise196"
  top: "Eltwise196"
}
layer {
  name: "Convolution394"
  type: "Convolution"
  bottom: "Eltwise196"
  top: "Convolution394"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm394"
  type: "BatchNorm"
  bottom: "Convolution394"
  top: "Convolution394"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale394"
  type: "Scale"
  bottom: "Convolution394"
  top: "Convolution394"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU394"
  type: "ReLU"
  bottom: "Convolution394"
  top: "Convolution394"
}
layer {
  name: "Convolution395"
  type: "Convolution"
  bottom: "Convolution394"
  top: "Convolution395"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm395"
  type: "BatchNorm"
  bottom: "Convolution395"
  top: "Convolution395"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale395"
  type: "Scale"
  bottom: "Convolution395"
  top: "Convolution395"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise197"
  type: "Eltwise"
  bottom: "Eltwise196"
  bottom: "Convolution395"
  top: "Eltwise197"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU395"
  type: "ReLU"
  bottom: "Eltwise197"
  top: "Eltwise197"
}
layer {
  name: "Convolution396"
  type: "Convolution"
  bottom: "Eltwise197"
  top: "Convolution396"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm396"
  type: "BatchNorm"
  bottom: "Convolution396"
  top: "Convolution396"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale396"
  type: "Scale"
  bottom: "Convolution396"
  top: "Convolution396"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU396"
  type: "ReLU"
  bottom: "Convolution396"
  top: "Convolution396"
}
layer {
  name: "Convolution397"
  type: "Convolution"
  bottom: "Convolution396"
  top: "Convolution397"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm397"
  type: "BatchNorm"
  bottom: "Convolution397"
  top: "Convolution397"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale397"
  type: "Scale"
  bottom: "Convolution397"
  top: "Convolution397"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise198"
  type: "Eltwise"
  bottom: "Eltwise197"
  bottom: "Convolution397"
  top: "Eltwise198"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU397"
  type: "ReLU"
  bottom: "Eltwise198"
  top: "Eltwise198"
}
layer {
  name: "Convolution398"
  type: "Convolution"
  bottom: "Eltwise198"
  top: "Convolution398"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm398"
  type: "BatchNorm"
  bottom: "Convolution398"
  top: "Convolution398"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale398"
  type: "Scale"
  bottom: "Convolution398"
  top: "Convolution398"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU398"
  type: "ReLU"
  bottom: "Convolution398"
  top: "Convolution398"
}
layer {
  name: "Convolution399"
  type: "Convolution"
  bottom: "Convolution398"
  top: "Convolution399"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm399"
  type: "BatchNorm"
  bottom: "Convolution399"
  top: "Convolution399"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale399"
  type: "Scale"
  bottom: "Convolution399"
  top: "Convolution399"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise199"
  type: "Eltwise"
  bottom: "Eltwise198"
  bottom: "Convolution399"
  top: "Eltwise199"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU399"
  type: "ReLU"
  bottom: "Eltwise199"
  top: "Eltwise199"
}
layer {
  name: "Convolution400"
  type: "Convolution"
  bottom: "Eltwise199"
  top: "Convolution400"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm400"
  type: "BatchNorm"
  bottom: "Convolution400"
  top: "Convolution400"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale400"
  type: "Scale"
  bottom: "Convolution400"
  top: "Convolution400"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU400"
  type: "ReLU"
  bottom: "Convolution400"
  top: "Convolution400"
}
layer {
  name: "Convolution401"
  type: "Convolution"
  bottom: "Convolution400"
  top: "Convolution401"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm401"
  type: "BatchNorm"
  bottom: "Convolution401"
  top: "Convolution401"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale401"
  type: "Scale"
  bottom: "Convolution401"
  top: "Convolution401"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise200"
  type: "Eltwise"
  bottom: "Eltwise199"
  bottom: "Convolution401"
  top: "Eltwise200"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU401"
  type: "ReLU"
  bottom: "Eltwise200"
  top: "Eltwise200"
}
layer {
  name: "Convolution402"
  type: "Convolution"
  bottom: "Eltwise200"
  top: "Convolution402"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm402"
  type: "BatchNorm"
  bottom: "Convolution402"
  top: "Convolution402"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale402"
  type: "Scale"
  bottom: "Convolution402"
  top: "Convolution402"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU402"
  type: "ReLU"
  bottom: "Convolution402"
  top: "Convolution402"
}
layer {
  name: "Convolution403"
  type: "Convolution"
  bottom: "Convolution402"
  top: "Convolution403"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm403"
  type: "BatchNorm"
  bottom: "Convolution403"
  top: "Convolution403"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale403"
  type: "Scale"
  bottom: "Convolution403"
  top: "Convolution403"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise201"
  type: "Eltwise"
  bottom: "Eltwise200"
  bottom: "Convolution403"
  top: "Eltwise201"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU403"
  type: "ReLU"
  bottom: "Eltwise201"
  top: "Eltwise201"
}
layer {
  name: "Convolution404"
  type: "Convolution"
  bottom: "Eltwise201"
  top: "Convolution404"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm404"
  type: "BatchNorm"
  bottom: "Convolution404"
  top: "Convolution404"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale404"
  type: "Scale"
  bottom: "Convolution404"
  top: "Convolution404"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU404"
  type: "ReLU"
  bottom: "Convolution404"
  top: "Convolution404"
}
layer {
  name: "Convolution405"
  type: "Convolution"
  bottom: "Convolution404"
  top: "Convolution405"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm405"
  type: "BatchNorm"
  bottom: "Convolution405"
  top: "Convolution405"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale405"
  type: "Scale"
  bottom: "Convolution405"
  top: "Convolution405"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise202"
  type: "Eltwise"
  bottom: "Eltwise201"
  bottom: "Convolution405"
  top: "Eltwise202"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU405"
  type: "ReLU"
  bottom: "Eltwise202"
  top: "Eltwise202"
}
layer {
  name: "Convolution406"
  type: "Convolution"
  bottom: "Eltwise202"
  top: "Convolution406"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm406"
  type: "BatchNorm"
  bottom: "Convolution406"
  top: "Convolution406"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale406"
  type: "Scale"
  bottom: "Convolution406"
  top: "Convolution406"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU406"
  type: "ReLU"
  bottom: "Convolution406"
  top: "Convolution406"
}
layer {
  name: "Convolution407"
  type: "Convolution"
  bottom: "Convolution406"
  top: "Convolution407"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm407"
  type: "BatchNorm"
  bottom: "Convolution407"
  top: "Convolution407"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale407"
  type: "Scale"
  bottom: "Convolution407"
  top: "Convolution407"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise203"
  type: "Eltwise"
  bottom: "Eltwise202"
  bottom: "Convolution407"
  top: "Eltwise203"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU407"
  type: "ReLU"
  bottom: "Eltwise203"
  top: "Eltwise203"
}
layer {
  name: "Convolution408"
  type: "Convolution"
  bottom: "Eltwise203"
  top: "Convolution408"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm408"
  type: "BatchNorm"
  bottom: "Convolution408"
  top: "Convolution408"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale408"
  type: "Scale"
  bottom: "Convolution408"
  top: "Convolution408"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU408"
  type: "ReLU"
  bottom: "Convolution408"
  top: "Convolution408"
}
layer {
  name: "Convolution409"
  type: "Convolution"
  bottom: "Convolution408"
  top: "Convolution409"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm409"
  type: "BatchNorm"
  bottom: "Convolution409"
  top: "Convolution409"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale409"
  type: "Scale"
  bottom: "Convolution409"
  top: "Convolution409"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise204"
  type: "Eltwise"
  bottom: "Eltwise203"
  bottom: "Convolution409"
  top: "Eltwise204"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU409"
  type: "ReLU"
  bottom: "Eltwise204"
  top: "Eltwise204"
}
layer {
  name: "Convolution410"
  type: "Convolution"
  bottom: "Eltwise204"
  top: "Convolution410"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm410"
  type: "BatchNorm"
  bottom: "Convolution410"
  top: "Convolution410"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale410"
  type: "Scale"
  bottom: "Convolution410"
  top: "Convolution410"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU410"
  type: "ReLU"
  bottom: "Convolution410"
  top: "Convolution410"
}
layer {
  name: "Convolution411"
  type: "Convolution"
  bottom: "Convolution410"
  top: "Convolution411"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm411"
  type: "BatchNorm"
  bottom: "Convolution411"
  top: "Convolution411"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale411"
  type: "Scale"
  bottom: "Convolution411"
  top: "Convolution411"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise205"
  type: "Eltwise"
  bottom: "Eltwise204"
  bottom: "Convolution411"
  top: "Eltwise205"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU411"
  type: "ReLU"
  bottom: "Eltwise205"
  top: "Eltwise205"
}
layer {
  name: "Convolution412"
  type: "Convolution"
  bottom: "Eltwise205"
  top: "Convolution412"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm412"
  type: "BatchNorm"
  bottom: "Convolution412"
  top: "Convolution412"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale412"
  type: "Scale"
  bottom: "Convolution412"
  top: "Convolution412"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU412"
  type: "ReLU"
  bottom: "Convolution412"
  top: "Convolution412"
}
layer {
  name: "Convolution413"
  type: "Convolution"
  bottom: "Convolution412"
  top: "Convolution413"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm413"
  type: "BatchNorm"
  bottom: "Convolution413"
  top: "Convolution413"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale413"
  type: "Scale"
  bottom: "Convolution413"
  top: "Convolution413"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise206"
  type: "Eltwise"
  bottom: "Eltwise205"
  bottom: "Convolution413"
  top: "Eltwise206"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU413"
  type: "ReLU"
  bottom: "Eltwise206"
  top: "Eltwise206"
}
layer {
  name: "Convolution414"
  type: "Convolution"
  bottom: "Eltwise206"
  top: "Convolution414"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm414"
  type: "BatchNorm"
  bottom: "Convolution414"
  top: "Convolution414"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale414"
  type: "Scale"
  bottom: "Convolution414"
  top: "Convolution414"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU414"
  type: "ReLU"
  bottom: "Convolution414"
  top: "Convolution414"
}
layer {
  name: "Convolution415"
  type: "Convolution"
  bottom: "Convolution414"
  top: "Convolution415"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm415"
  type: "BatchNorm"
  bottom: "Convolution415"
  top: "Convolution415"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale415"
  type: "Scale"
  bottom: "Convolution415"
  top: "Convolution415"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise207"
  type: "Eltwise"
  bottom: "Eltwise206"
  bottom: "Convolution415"
  top: "Eltwise207"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU415"
  type: "ReLU"
  bottom: "Eltwise207"
  top: "Eltwise207"
}
layer {
  name: "Convolution416"
  type: "Convolution"
  bottom: "Eltwise207"
  top: "Convolution416"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm416"
  type: "BatchNorm"
  bottom: "Convolution416"
  top: "Convolution416"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale416"
  type: "Scale"
  bottom: "Convolution416"
  top: "Convolution416"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU416"
  type: "ReLU"
  bottom: "Convolution416"
  top: "Convolution416"
}
layer {
  name: "Convolution417"
  type: "Convolution"
  bottom: "Convolution416"
  top: "Convolution417"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm417"
  type: "BatchNorm"
  bottom: "Convolution417"
  top: "Convolution417"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale417"
  type: "Scale"
  bottom: "Convolution417"
  top: "Convolution417"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise208"
  type: "Eltwise"
  bottom: "Eltwise207"
  bottom: "Convolution417"
  top: "Eltwise208"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU417"
  type: "ReLU"
  bottom: "Eltwise208"
  top: "Eltwise208"
}
layer {
  name: "Convolution418"
  type: "Convolution"
  bottom: "Eltwise208"
  top: "Convolution418"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm418"
  type: "BatchNorm"
  bottom: "Convolution418"
  top: "Convolution418"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale418"
  type: "Scale"
  bottom: "Convolution418"
  top: "Convolution418"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU418"
  type: "ReLU"
  bottom: "Convolution418"
  top: "Convolution418"
}
layer {
  name: "Convolution419"
  type: "Convolution"
  bottom: "Convolution418"
  top: "Convolution419"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm419"
  type: "BatchNorm"
  bottom: "Convolution419"
  top: "Convolution419"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale419"
  type: "Scale"
  bottom: "Convolution419"
  top: "Convolution419"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise209"
  type: "Eltwise"
  bottom: "Eltwise208"
  bottom: "Convolution419"
  top: "Eltwise209"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU419"
  type: "ReLU"
  bottom: "Eltwise209"
  top: "Eltwise209"
}
layer {
  name: "Convolution420"
  type: "Convolution"
  bottom: "Eltwise209"
  top: "Convolution420"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm420"
  type: "BatchNorm"
  bottom: "Convolution420"
  top: "Convolution420"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale420"
  type: "Scale"
  bottom: "Convolution420"
  top: "Convolution420"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU420"
  type: "ReLU"
  bottom: "Convolution420"
  top: "Convolution420"
}
layer {
  name: "Convolution421"
  type: "Convolution"
  bottom: "Convolution420"
  top: "Convolution421"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm421"
  type: "BatchNorm"
  bottom: "Convolution421"
  top: "Convolution421"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale421"
  type: "Scale"
  bottom: "Convolution421"
  top: "Convolution421"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise210"
  type: "Eltwise"
  bottom: "Eltwise209"
  bottom: "Convolution421"
  top: "Eltwise210"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU421"
  type: "ReLU"
  bottom: "Eltwise210"
  top: "Eltwise210"
}
layer {
  name: "Convolution422"
  type: "Convolution"
  bottom: "Eltwise210"
  top: "Convolution422"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm422"
  type: "BatchNorm"
  bottom: "Convolution422"
  top: "Convolution422"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale422"
  type: "Scale"
  bottom: "Convolution422"
  top: "Convolution422"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU422"
  type: "ReLU"
  bottom: "Convolution422"
  top: "Convolution422"
}
layer {
  name: "Convolution423"
  type: "Convolution"
  bottom: "Convolution422"
  top: "Convolution423"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm423"
  type: "BatchNorm"
  bottom: "Convolution423"
  top: "Convolution423"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale423"
  type: "Scale"
  bottom: "Convolution423"
  top: "Convolution423"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise211"
  type: "Eltwise"
  bottom: "Eltwise210"
  bottom: "Convolution423"
  top: "Eltwise211"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU423"
  type: "ReLU"
  bottom: "Eltwise211"
  top: "Eltwise211"
}
layer {
  name: "Convolution424"
  type: "Convolution"
  bottom: "Eltwise211"
  top: "Convolution424"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm424"
  type: "BatchNorm"
  bottom: "Convolution424"
  top: "Convolution424"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale424"
  type: "Scale"
  bottom: "Convolution424"
  top: "Convolution424"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU424"
  type: "ReLU"
  bottom: "Convolution424"
  top: "Convolution424"
}
layer {
  name: "Convolution425"
  type: "Convolution"
  bottom: "Convolution424"
  top: "Convolution425"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm425"
  type: "BatchNorm"
  bottom: "Convolution425"
  top: "Convolution425"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale425"
  type: "Scale"
  bottom: "Convolution425"
  top: "Convolution425"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise212"
  type: "Eltwise"
  bottom: "Eltwise211"
  bottom: "Convolution425"
  top: "Eltwise212"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU425"
  type: "ReLU"
  bottom: "Eltwise212"
  top: "Eltwise212"
}
layer {
  name: "Convolution426"
  type: "Convolution"
  bottom: "Eltwise212"
  top: "Convolution426"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm426"
  type: "BatchNorm"
  bottom: "Convolution426"
  top: "Convolution426"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale426"
  type: "Scale"
  bottom: "Convolution426"
  top: "Convolution426"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU426"
  type: "ReLU"
  bottom: "Convolution426"
  top: "Convolution426"
}
layer {
  name: "Convolution427"
  type: "Convolution"
  bottom: "Convolution426"
  top: "Convolution427"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm427"
  type: "BatchNorm"
  bottom: "Convolution427"
  top: "Convolution427"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale427"
  type: "Scale"
  bottom: "Convolution427"
  top: "Convolution427"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise213"
  type: "Eltwise"
  bottom: "Eltwise212"
  bottom: "Convolution427"
  top: "Eltwise213"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU427"
  type: "ReLU"
  bottom: "Eltwise213"
  top: "Eltwise213"
}
layer {
  name: "Convolution428"
  type: "Convolution"
  bottom: "Eltwise213"
  top: "Convolution428"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm428"
  type: "BatchNorm"
  bottom: "Convolution428"
  top: "Convolution428"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale428"
  type: "Scale"
  bottom: "Convolution428"
  top: "Convolution428"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU428"
  type: "ReLU"
  bottom: "Convolution428"
  top: "Convolution428"
}
layer {
  name: "Convolution429"
  type: "Convolution"
  bottom: "Convolution428"
  top: "Convolution429"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm429"
  type: "BatchNorm"
  bottom: "Convolution429"
  top: "Convolution429"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale429"
  type: "Scale"
  bottom: "Convolution429"
  top: "Convolution429"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise214"
  type: "Eltwise"
  bottom: "Eltwise213"
  bottom: "Convolution429"
  top: "Eltwise214"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU429"
  type: "ReLU"
  bottom: "Eltwise214"
  top: "Eltwise214"
}
layer {
  name: "Convolution430"
  type: "Convolution"
  bottom: "Eltwise214"
  top: "Convolution430"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm430"
  type: "BatchNorm"
  bottom: "Convolution430"
  top: "Convolution430"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale430"
  type: "Scale"
  bottom: "Convolution430"
  top: "Convolution430"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU430"
  type: "ReLU"
  bottom: "Convolution430"
  top: "Convolution430"
}
layer {
  name: "Convolution431"
  type: "Convolution"
  bottom: "Convolution430"
  top: "Convolution431"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm431"
  type: "BatchNorm"
  bottom: "Convolution431"
  top: "Convolution431"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale431"
  type: "Scale"
  bottom: "Convolution431"
  top: "Convolution431"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise215"
  type: "Eltwise"
  bottom: "Eltwise214"
  bottom: "Convolution431"
  top: "Eltwise215"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU431"
  type: "ReLU"
  bottom: "Eltwise215"
  top: "Eltwise215"
}
layer {
  name: "Convolution432"
  type: "Convolution"
  bottom: "Eltwise215"
  top: "Convolution432"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm432"
  type: "BatchNorm"
  bottom: "Convolution432"
  top: "Convolution432"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale432"
  type: "Scale"
  bottom: "Convolution432"
  top: "Convolution432"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU432"
  type: "ReLU"
  bottom: "Convolution432"
  top: "Convolution432"
}
layer {
  name: "Convolution433"
  type: "Convolution"
  bottom: "Convolution432"
  top: "Convolution433"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm433"
  type: "BatchNorm"
  bottom: "Convolution433"
  top: "Convolution433"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale433"
  type: "Scale"
  bottom: "Convolution433"
  top: "Convolution433"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise216"
  type: "Eltwise"
  bottom: "Eltwise215"
  bottom: "Convolution433"
  top: "Eltwise216"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU433"
  type: "ReLU"
  bottom: "Eltwise216"
  top: "Eltwise216"
}
layer {
  name: "Convolution434"
  type: "Convolution"
  bottom: "Eltwise216"
  top: "Convolution434"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm434"
  type: "BatchNorm"
  bottom: "Convolution434"
  top: "Convolution434"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale434"
  type: "Scale"
  bottom: "Convolution434"
  top: "Convolution434"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU434"
  type: "ReLU"
  bottom: "Convolution434"
  top: "Convolution434"
}
layer {
  name: "Convolution435"
  type: "Convolution"
  bottom: "Convolution434"
  top: "Convolution435"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm435"
  type: "BatchNorm"
  bottom: "Convolution435"
  top: "Convolution435"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale435"
  type: "Scale"
  bottom: "Convolution435"
  top: "Convolution435"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise217"
  type: "Eltwise"
  bottom: "Eltwise216"
  bottom: "Convolution435"
  top: "Eltwise217"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU435"
  type: "ReLU"
  bottom: "Eltwise217"
  top: "Eltwise217"
}
layer {
  name: "Convolution436"
  type: "Convolution"
  bottom: "Eltwise217"
  top: "Convolution436"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm436"
  type: "BatchNorm"
  bottom: "Convolution436"
  top: "Convolution436"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale436"
  type: "Scale"
  bottom: "Convolution436"
  top: "Convolution436"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU436"
  type: "ReLU"
  bottom: "Convolution436"
  top: "Convolution436"
}
layer {
  name: "Convolution437"
  type: "Convolution"
  bottom: "Convolution436"
  top: "Convolution437"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm437"
  type: "BatchNorm"
  bottom: "Convolution437"
  top: "Convolution437"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale437"
  type: "Scale"
  bottom: "Convolution437"
  top: "Convolution437"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise218"
  type: "Eltwise"
  bottom: "Eltwise217"
  bottom: "Convolution437"
  top: "Eltwise218"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU437"
  type: "ReLU"
  bottom: "Eltwise218"
  top: "Eltwise218"
}
layer {
  name: "Convolution438"
  type: "Convolution"
  bottom: "Eltwise218"
  top: "Convolution438"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm438"
  type: "BatchNorm"
  bottom: "Convolution438"
  top: "Convolution438"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale438"
  type: "Scale"
  bottom: "Convolution438"
  top: "Convolution438"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU438"
  type: "ReLU"
  bottom: "Convolution438"
  top: "Convolution438"
}
layer {
  name: "Convolution439"
  type: "Convolution"
  bottom: "Convolution438"
  top: "Convolution439"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm439"
  type: "BatchNorm"
  bottom: "Convolution439"
  top: "Convolution439"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale439"
  type: "Scale"
  bottom: "Convolution439"
  top: "Convolution439"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise219"
  type: "Eltwise"
  bottom: "Eltwise218"
  bottom: "Convolution439"
  top: "Eltwise219"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU439"
  type: "ReLU"
  bottom: "Eltwise219"
  top: "Eltwise219"
}
layer {
  name: "Convolution440"
  type: "Convolution"
  bottom: "Eltwise219"
  top: "Convolution440"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm440"
  type: "BatchNorm"
  bottom: "Convolution440"
  top: "Convolution440"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale440"
  type: "Scale"
  bottom: "Convolution440"
  top: "Convolution440"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU440"
  type: "ReLU"
  bottom: "Convolution440"
  top: "Convolution440"
}
layer {
  name: "Convolution441"
  type: "Convolution"
  bottom: "Convolution440"
  top: "Convolution441"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm441"
  type: "BatchNorm"
  bottom: "Convolution441"
  top: "Convolution441"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale441"
  type: "Scale"
  bottom: "Convolution441"
  top: "Convolution441"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise220"
  type: "Eltwise"
  bottom: "Eltwise219"
  bottom: "Convolution441"
  top: "Eltwise220"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU441"
  type: "ReLU"
  bottom: "Eltwise220"
  top: "Eltwise220"
}
layer {
  name: "Convolution442"
  type: "Convolution"
  bottom: "Eltwise220"
  top: "Convolution442"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm442"
  type: "BatchNorm"
  bottom: "Convolution442"
  top: "Convolution442"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale442"
  type: "Scale"
  bottom: "Convolution442"
  top: "Convolution442"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU442"
  type: "ReLU"
  bottom: "Convolution442"
  top: "Convolution442"
}
layer {
  name: "Convolution443"
  type: "Convolution"
  bottom: "Convolution442"
  top: "Convolution443"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm443"
  type: "BatchNorm"
  bottom: "Convolution443"
  top: "Convolution443"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale443"
  type: "Scale"
  bottom: "Convolution443"
  top: "Convolution443"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise221"
  type: "Eltwise"
  bottom: "Eltwise220"
  bottom: "Convolution443"
  top: "Eltwise221"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU443"
  type: "ReLU"
  bottom: "Eltwise221"
  top: "Eltwise221"
}
layer {
  name: "Convolution444"
  type: "Convolution"
  bottom: "Eltwise221"
  top: "Convolution444"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm444"
  type: "BatchNorm"
  bottom: "Convolution444"
  top: "Convolution444"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale444"
  type: "Scale"
  bottom: "Convolution444"
  top: "Convolution444"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU444"
  type: "ReLU"
  bottom: "Convolution444"
  top: "Convolution444"
}
layer {
  name: "Convolution445"
  type: "Convolution"
  bottom: "Convolution444"
  top: "Convolution445"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm445"
  type: "BatchNorm"
  bottom: "Convolution445"
  top: "Convolution445"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale445"
  type: "Scale"
  bottom: "Convolution445"
  top: "Convolution445"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise222"
  type: "Eltwise"
  bottom: "Eltwise221"
  bottom: "Convolution445"
  top: "Eltwise222"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU445"
  type: "ReLU"
  bottom: "Eltwise222"
  top: "Eltwise222"
}
layer {
  name: "Convolution446"
  type: "Convolution"
  bottom: "Eltwise222"
  top: "Convolution446"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm446"
  type: "BatchNorm"
  bottom: "Convolution446"
  top: "Convolution446"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale446"
  type: "Scale"
  bottom: "Convolution446"
  top: "Convolution446"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU446"
  type: "ReLU"
  bottom: "Convolution446"
  top: "Convolution446"
}
layer {
  name: "Convolution447"
  type: "Convolution"
  bottom: "Convolution446"
  top: "Convolution447"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm447"
  type: "BatchNorm"
  bottom: "Convolution447"
  top: "Convolution447"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale447"
  type: "Scale"
  bottom: "Convolution447"
  top: "Convolution447"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise223"
  type: "Eltwise"
  bottom: "Eltwise222"
  bottom: "Convolution447"
  top: "Eltwise223"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU447"
  type: "ReLU"
  bottom: "Eltwise223"
  top: "Eltwise223"
}
layer {
  name: "Convolution448"
  type: "Convolution"
  bottom: "Eltwise223"
  top: "Convolution448"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm448"
  type: "BatchNorm"
  bottom: "Convolution448"
  top: "Convolution448"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale448"
  type: "Scale"
  bottom: "Convolution448"
  top: "Convolution448"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU448"
  type: "ReLU"
  bottom: "Convolution448"
  top: "Convolution448"
}
layer {
  name: "Convolution449"
  type: "Convolution"
  bottom: "Convolution448"
  top: "Convolution449"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm449"
  type: "BatchNorm"
  bottom: "Convolution449"
  top: "Convolution449"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale449"
  type: "Scale"
  bottom: "Convolution449"
  top: "Convolution449"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise224"
  type: "Eltwise"
  bottom: "Eltwise223"
  bottom: "Convolution449"
  top: "Eltwise224"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU449"
  type: "ReLU"
  bottom: "Eltwise224"
  top: "Eltwise224"
}
layer {
  name: "Convolution450"
  type: "Convolution"
  bottom: "Eltwise224"
  top: "Convolution450"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm450"
  type: "BatchNorm"
  bottom: "Convolution450"
  top: "Convolution450"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale450"
  type: "Scale"
  bottom: "Convolution450"
  top: "Convolution450"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU450"
  type: "ReLU"
  bottom: "Convolution450"
  top: "Convolution450"
}
layer {
  name: "Convolution451"
  type: "Convolution"
  bottom: "Convolution450"
  top: "Convolution451"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm451"
  type: "BatchNorm"
  bottom: "Convolution451"
  top: "Convolution451"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale451"
  type: "Scale"
  bottom: "Convolution451"
  top: "Convolution451"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise225"
  type: "Eltwise"
  bottom: "Eltwise224"
  bottom: "Convolution451"
  top: "Eltwise225"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU451"
  type: "ReLU"
  bottom: "Eltwise225"
  top: "Eltwise225"
}
layer {
  name: "Convolution452"
  type: "Convolution"
  bottom: "Eltwise225"
  top: "Convolution452"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm452"
  type: "BatchNorm"
  bottom: "Convolution452"
  top: "Convolution452"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale452"
  type: "Scale"
  bottom: "Convolution452"
  top: "Convolution452"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU452"
  type: "ReLU"
  bottom: "Convolution452"
  top: "Convolution452"
}
layer {
  name: "Convolution453"
  type: "Convolution"
  bottom: "Convolution452"
  top: "Convolution453"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm453"
  type: "BatchNorm"
  bottom: "Convolution453"
  top: "Convolution453"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale453"
  type: "Scale"
  bottom: "Convolution453"
  top: "Convolution453"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise226"
  type: "Eltwise"
  bottom: "Eltwise225"
  bottom: "Convolution453"
  top: "Eltwise226"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU453"
  type: "ReLU"
  bottom: "Eltwise226"
  top: "Eltwise226"
}
layer {
  name: "Convolution454"
  type: "Convolution"
  bottom: "Eltwise226"
  top: "Convolution454"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm454"
  type: "BatchNorm"
  bottom: "Convolution454"
  top: "Convolution454"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale454"
  type: "Scale"
  bottom: "Convolution454"
  top: "Convolution454"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU454"
  type: "ReLU"
  bottom: "Convolution454"
  top: "Convolution454"
}
layer {
  name: "Convolution455"
  type: "Convolution"
  bottom: "Convolution454"
  top: "Convolution455"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm455"
  type: "BatchNorm"
  bottom: "Convolution455"
  top: "Convolution455"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale455"
  type: "Scale"
  bottom: "Convolution455"
  top: "Convolution455"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise227"
  type: "Eltwise"
  bottom: "Eltwise226"
  bottom: "Convolution455"
  top: "Eltwise227"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU455"
  type: "ReLU"
  bottom: "Eltwise227"
  top: "Eltwise227"
}
layer {
  name: "Convolution456"
  type: "Convolution"
  bottom: "Eltwise227"
  top: "Convolution456"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm456"
  type: "BatchNorm"
  bottom: "Convolution456"
  top: "Convolution456"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale456"
  type: "Scale"
  bottom: "Convolution456"
  top: "Convolution456"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU456"
  type: "ReLU"
  bottom: "Convolution456"
  top: "Convolution456"
}
layer {
  name: "Convolution457"
  type: "Convolution"
  bottom: "Convolution456"
  top: "Convolution457"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm457"
  type: "BatchNorm"
  bottom: "Convolution457"
  top: "Convolution457"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale457"
  type: "Scale"
  bottom: "Convolution457"
  top: "Convolution457"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise228"
  type: "Eltwise"
  bottom: "Eltwise227"
  bottom: "Convolution457"
  top: "Eltwise228"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU457"
  type: "ReLU"
  bottom: "Eltwise228"
  top: "Eltwise228"
}
layer {
  name: "Convolution458"
  type: "Convolution"
  bottom: "Eltwise228"
  top: "Convolution458"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm458"
  type: "BatchNorm"
  bottom: "Convolution458"
  top: "Convolution458"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale458"
  type: "Scale"
  bottom: "Convolution458"
  top: "Convolution458"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU458"
  type: "ReLU"
  bottom: "Convolution458"
  top: "Convolution458"
}
layer {
  name: "Convolution459"
  type: "Convolution"
  bottom: "Convolution458"
  top: "Convolution459"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm459"
  type: "BatchNorm"
  bottom: "Convolution459"
  top: "Convolution459"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale459"
  type: "Scale"
  bottom: "Convolution459"
  top: "Convolution459"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise229"
  type: "Eltwise"
  bottom: "Eltwise228"
  bottom: "Convolution459"
  top: "Eltwise229"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU459"
  type: "ReLU"
  bottom: "Eltwise229"
  top: "Eltwise229"
}
layer {
  name: "Convolution460"
  type: "Convolution"
  bottom: "Eltwise229"
  top: "Convolution460"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm460"
  type: "BatchNorm"
  bottom: "Convolution460"
  top: "Convolution460"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale460"
  type: "Scale"
  bottom: "Convolution460"
  top: "Convolution460"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU460"
  type: "ReLU"
  bottom: "Convolution460"
  top: "Convolution460"
}
layer {
  name: "Convolution461"
  type: "Convolution"
  bottom: "Convolution460"
  top: "Convolution461"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm461"
  type: "BatchNorm"
  bottom: "Convolution461"
  top: "Convolution461"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale461"
  type: "Scale"
  bottom: "Convolution461"
  top: "Convolution461"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise230"
  type: "Eltwise"
  bottom: "Eltwise229"
  bottom: "Convolution461"
  top: "Eltwise230"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU461"
  type: "ReLU"
  bottom: "Eltwise230"
  top: "Eltwise230"
}
layer {
  name: "Convolution462"
  type: "Convolution"
  bottom: "Eltwise230"
  top: "Convolution462"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm462"
  type: "BatchNorm"
  bottom: "Convolution462"
  top: "Convolution462"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale462"
  type: "Scale"
  bottom: "Convolution462"
  top: "Convolution462"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU462"
  type: "ReLU"
  bottom: "Convolution462"
  top: "Convolution462"
}
layer {
  name: "Convolution463"
  type: "Convolution"
  bottom: "Convolution462"
  top: "Convolution463"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm463"
  type: "BatchNorm"
  bottom: "Convolution463"
  top: "Convolution463"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale463"
  type: "Scale"
  bottom: "Convolution463"
  top: "Convolution463"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise231"
  type: "Eltwise"
  bottom: "Eltwise230"
  bottom: "Convolution463"
  top: "Eltwise231"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU463"
  type: "ReLU"
  bottom: "Eltwise231"
  top: "Eltwise231"
}
layer {
  name: "Convolution464"
  type: "Convolution"
  bottom: "Eltwise231"
  top: "Convolution464"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm464"
  type: "BatchNorm"
  bottom: "Convolution464"
  top: "Convolution464"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale464"
  type: "Scale"
  bottom: "Convolution464"
  top: "Convolution464"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU464"
  type: "ReLU"
  bottom: "Convolution464"
  top: "Convolution464"
}
layer {
  name: "Convolution465"
  type: "Convolution"
  bottom: "Convolution464"
  top: "Convolution465"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm465"
  type: "BatchNorm"
  bottom: "Convolution465"
  top: "Convolution465"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale465"
  type: "Scale"
  bottom: "Convolution465"
  top: "Convolution465"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise232"
  type: "Eltwise"
  bottom: "Eltwise231"
  bottom: "Convolution465"
  top: "Eltwise232"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU465"
  type: "ReLU"
  bottom: "Eltwise232"
  top: "Eltwise232"
}
layer {
  name: "Convolution466"
  type: "Convolution"
  bottom: "Eltwise232"
  top: "Convolution466"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm466"
  type: "BatchNorm"
  bottom: "Convolution466"
  top: "Convolution466"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale466"
  type: "Scale"
  bottom: "Convolution466"
  top: "Convolution466"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU466"
  type: "ReLU"
  bottom: "Convolution466"
  top: "Convolution466"
}
layer {
  name: "Convolution467"
  type: "Convolution"
  bottom: "Convolution466"
  top: "Convolution467"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm467"
  type: "BatchNorm"
  bottom: "Convolution467"
  top: "Convolution467"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale467"
  type: "Scale"
  bottom: "Convolution467"
  top: "Convolution467"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise233"
  type: "Eltwise"
  bottom: "Eltwise232"
  bottom: "Convolution467"
  top: "Eltwise233"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU467"
  type: "ReLU"
  bottom: "Eltwise233"
  top: "Eltwise233"
}
layer {
  name: "Convolution468"
  type: "Convolution"
  bottom: "Eltwise233"
  top: "Convolution468"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm468"
  type: "BatchNorm"
  bottom: "Convolution468"
  top: "Convolution468"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale468"
  type: "Scale"
  bottom: "Convolution468"
  top: "Convolution468"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU468"
  type: "ReLU"
  bottom: "Convolution468"
  top: "Convolution468"
}
layer {
  name: "Convolution469"
  type: "Convolution"
  bottom: "Convolution468"
  top: "Convolution469"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm469"
  type: "BatchNorm"
  bottom: "Convolution469"
  top: "Convolution469"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale469"
  type: "Scale"
  bottom: "Convolution469"
  top: "Convolution469"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise234"
  type: "Eltwise"
  bottom: "Eltwise233"
  bottom: "Convolution469"
  top: "Eltwise234"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU469"
  type: "ReLU"
  bottom: "Eltwise234"
  top: "Eltwise234"
}
layer {
  name: "Convolution470"
  type: "Convolution"
  bottom: "Eltwise234"
  top: "Convolution470"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm470"
  type: "BatchNorm"
  bottom: "Convolution470"
  top: "Convolution470"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale470"
  type: "Scale"
  bottom: "Convolution470"
  top: "Convolution470"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU470"
  type: "ReLU"
  bottom: "Convolution470"
  top: "Convolution470"
}
layer {
  name: "Convolution471"
  type: "Convolution"
  bottom: "Convolution470"
  top: "Convolution471"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm471"
  type: "BatchNorm"
  bottom: "Convolution471"
  top: "Convolution471"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale471"
  type: "Scale"
  bottom: "Convolution471"
  top: "Convolution471"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise235"
  type: "Eltwise"
  bottom: "Eltwise234"
  bottom: "Convolution471"
  top: "Eltwise235"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU471"
  type: "ReLU"
  bottom: "Eltwise235"
  top: "Eltwise235"
}
layer {
  name: "Convolution472"
  type: "Convolution"
  bottom: "Eltwise235"
  top: "Convolution472"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm472"
  type: "BatchNorm"
  bottom: "Convolution472"
  top: "Convolution472"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale472"
  type: "Scale"
  bottom: "Convolution472"
  top: "Convolution472"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU472"
  type: "ReLU"
  bottom: "Convolution472"
  top: "Convolution472"
}
layer {
  name: "Convolution473"
  type: "Convolution"
  bottom: "Convolution472"
  top: "Convolution473"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm473"
  type: "BatchNorm"
  bottom: "Convolution473"
  top: "Convolution473"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale473"
  type: "Scale"
  bottom: "Convolution473"
  top: "Convolution473"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise236"
  type: "Eltwise"
  bottom: "Eltwise235"
  bottom: "Convolution473"
  top: "Eltwise236"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU473"
  type: "ReLU"
  bottom: "Eltwise236"
  top: "Eltwise236"
}
layer {
  name: "Convolution474"
  type: "Convolution"
  bottom: "Eltwise236"
  top: "Convolution474"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm474"
  type: "BatchNorm"
  bottom: "Convolution474"
  top: "Convolution474"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale474"
  type: "Scale"
  bottom: "Convolution474"
  top: "Convolution474"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU474"
  type: "ReLU"
  bottom: "Convolution474"
  top: "Convolution474"
}
layer {
  name: "Convolution475"
  type: "Convolution"
  bottom: "Convolution474"
  top: "Convolution475"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm475"
  type: "BatchNorm"
  bottom: "Convolution475"
  top: "Convolution475"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale475"
  type: "Scale"
  bottom: "Convolution475"
  top: "Convolution475"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise237"
  type: "Eltwise"
  bottom: "Eltwise236"
  bottom: "Convolution475"
  top: "Eltwise237"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU475"
  type: "ReLU"
  bottom: "Eltwise237"
  top: "Eltwise237"
}
layer {
  name: "Convolution476"
  type: "Convolution"
  bottom: "Eltwise237"
  top: "Convolution476"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm476"
  type: "BatchNorm"
  bottom: "Convolution476"
  top: "Convolution476"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale476"
  type: "Scale"
  bottom: "Convolution476"
  top: "Convolution476"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU476"
  type: "ReLU"
  bottom: "Convolution476"
  top: "Convolution476"
}
layer {
  name: "Convolution477"
  type: "Convolution"
  bottom: "Convolution476"
  top: "Convolution477"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm477"
  type: "BatchNorm"
  bottom: "Convolution477"
  top: "Convolution477"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale477"
  type: "Scale"
  bottom: "Convolution477"
  top: "Convolution477"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise238"
  type: "Eltwise"
  bottom: "Eltwise237"
  bottom: "Convolution477"
  top: "Eltwise238"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU477"
  type: "ReLU"
  bottom: "Eltwise238"
  top: "Eltwise238"
}
layer {
  name: "Convolution478"
  type: "Convolution"
  bottom: "Eltwise238"
  top: "Convolution478"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm478"
  type: "BatchNorm"
  bottom: "Convolution478"
  top: "Convolution478"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale478"
  type: "Scale"
  bottom: "Convolution478"
  top: "Convolution478"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU478"
  type: "ReLU"
  bottom: "Convolution478"
  top: "Convolution478"
}
layer {
  name: "Convolution479"
  type: "Convolution"
  bottom: "Convolution478"
  top: "Convolution479"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm479"
  type: "BatchNorm"
  bottom: "Convolution479"
  top: "Convolution479"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale479"
  type: "Scale"
  bottom: "Convolution479"
  top: "Convolution479"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise239"
  type: "Eltwise"
  bottom: "Eltwise238"
  bottom: "Convolution479"
  top: "Eltwise239"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU479"
  type: "ReLU"
  bottom: "Eltwise239"
  top: "Eltwise239"
}
layer {
  name: "Convolution480"
  type: "Convolution"
  bottom: "Eltwise239"
  top: "Convolution480"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm480"
  type: "BatchNorm"
  bottom: "Convolution480"
  top: "Convolution480"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale480"
  type: "Scale"
  bottom: "Convolution480"
  top: "Convolution480"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU480"
  type: "ReLU"
  bottom: "Convolution480"
  top: "Convolution480"
}
layer {
  name: "Convolution481"
  type: "Convolution"
  bottom: "Convolution480"
  top: "Convolution481"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm481"
  type: "BatchNorm"
  bottom: "Convolution481"
  top: "Convolution481"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale481"
  type: "Scale"
  bottom: "Convolution481"
  top: "Convolution481"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise240"
  type: "Eltwise"
  bottom: "Eltwise239"
  bottom: "Convolution481"
  top: "Eltwise240"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU481"
  type: "ReLU"
  bottom: "Eltwise240"
  top: "Eltwise240"
}
layer {
  name: "Convolution482"
  type: "Convolution"
  bottom: "Eltwise240"
  top: "Convolution482"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm482"
  type: "BatchNorm"
  bottom: "Convolution482"
  top: "Convolution482"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale482"
  type: "Scale"
  bottom: "Convolution482"
  top: "Convolution482"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU482"
  type: "ReLU"
  bottom: "Convolution482"
  top: "Convolution482"
}
layer {
  name: "Convolution483"
  type: "Convolution"
  bottom: "Convolution482"
  top: "Convolution483"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm483"
  type: "BatchNorm"
  bottom: "Convolution483"
  top: "Convolution483"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale483"
  type: "Scale"
  bottom: "Convolution483"
  top: "Convolution483"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise241"
  type: "Eltwise"
  bottom: "Eltwise240"
  bottom: "Convolution483"
  top: "Eltwise241"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU483"
  type: "ReLU"
  bottom: "Eltwise241"
  top: "Eltwise241"
}
layer {
  name: "Convolution484"
  type: "Convolution"
  bottom: "Eltwise241"
  top: "Convolution484"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm484"
  type: "BatchNorm"
  bottom: "Convolution484"
  top: "Convolution484"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale484"
  type: "Scale"
  bottom: "Convolution484"
  top: "Convolution484"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU484"
  type: "ReLU"
  bottom: "Convolution484"
  top: "Convolution484"
}
layer {
  name: "Convolution485"
  type: "Convolution"
  bottom: "Convolution484"
  top: "Convolution485"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm485"
  type: "BatchNorm"
  bottom: "Convolution485"
  top: "Convolution485"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale485"
  type: "Scale"
  bottom: "Convolution485"
  top: "Convolution485"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise242"
  type: "Eltwise"
  bottom: "Eltwise241"
  bottom: "Convolution485"
  top: "Eltwise242"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU485"
  type: "ReLU"
  bottom: "Eltwise242"
  top: "Eltwise242"
}
layer {
  name: "Convolution486"
  type: "Convolution"
  bottom: "Eltwise242"
  top: "Convolution486"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm486"
  type: "BatchNorm"
  bottom: "Convolution486"
  top: "Convolution486"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale486"
  type: "Scale"
  bottom: "Convolution486"
  top: "Convolution486"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU486"
  type: "ReLU"
  bottom: "Convolution486"
  top: "Convolution486"
}
layer {
  name: "Convolution487"
  type: "Convolution"
  bottom: "Convolution486"
  top: "Convolution487"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm487"
  type: "BatchNorm"
  bottom: "Convolution487"
  top: "Convolution487"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale487"
  type: "Scale"
  bottom: "Convolution487"
  top: "Convolution487"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise243"
  type: "Eltwise"
  bottom: "Eltwise242"
  bottom: "Convolution487"
  top: "Eltwise243"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU487"
  type: "ReLU"
  bottom: "Eltwise243"
  top: "Eltwise243"
}
layer {
  name: "Convolution488"
  type: "Convolution"
  bottom: "Eltwise243"
  top: "Convolution488"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm488"
  type: "BatchNorm"
  bottom: "Convolution488"
  top: "Convolution488"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale488"
  type: "Scale"
  bottom: "Convolution488"
  top: "Convolution488"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU488"
  type: "ReLU"
  bottom: "Convolution488"
  top: "Convolution488"
}
layer {
  name: "Convolution489"
  type: "Convolution"
  bottom: "Convolution488"
  top: "Convolution489"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm489"
  type: "BatchNorm"
  bottom: "Convolution489"
  top: "Convolution489"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale489"
  type: "Scale"
  bottom: "Convolution489"
  top: "Convolution489"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise244"
  type: "Eltwise"
  bottom: "Eltwise243"
  bottom: "Convolution489"
  top: "Eltwise244"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU489"
  type: "ReLU"
  bottom: "Eltwise244"
  top: "Eltwise244"
}
layer {
  name: "Convolution490"
  type: "Convolution"
  bottom: "Eltwise244"
  top: "Convolution490"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm490"
  type: "BatchNorm"
  bottom: "Convolution490"
  top: "Convolution490"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale490"
  type: "Scale"
  bottom: "Convolution490"
  top: "Convolution490"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU490"
  type: "ReLU"
  bottom: "Convolution490"
  top: "Convolution490"
}
layer {
  name: "Convolution491"
  type: "Convolution"
  bottom: "Convolution490"
  top: "Convolution491"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm491"
  type: "BatchNorm"
  bottom: "Convolution491"
  top: "Convolution491"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale491"
  type: "Scale"
  bottom: "Convolution491"
  top: "Convolution491"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise245"
  type: "Eltwise"
  bottom: "Eltwise244"
  bottom: "Convolution491"
  top: "Eltwise245"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU491"
  type: "ReLU"
  bottom: "Eltwise245"
  top: "Eltwise245"
}
layer {
  name: "Convolution492"
  type: "Convolution"
  bottom: "Eltwise245"
  top: "Convolution492"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm492"
  type: "BatchNorm"
  bottom: "Convolution492"
  top: "Convolution492"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale492"
  type: "Scale"
  bottom: "Convolution492"
  top: "Convolution492"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU492"
  type: "ReLU"
  bottom: "Convolution492"
  top: "Convolution492"
}
layer {
  name: "Convolution493"
  type: "Convolution"
  bottom: "Convolution492"
  top: "Convolution493"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm493"
  type: "BatchNorm"
  bottom: "Convolution493"
  top: "Convolution493"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale493"
  type: "Scale"
  bottom: "Convolution493"
  top: "Convolution493"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise246"
  type: "Eltwise"
  bottom: "Eltwise245"
  bottom: "Convolution493"
  top: "Eltwise246"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU493"
  type: "ReLU"
  bottom: "Eltwise246"
  top: "Eltwise246"
}
layer {
  name: "Convolution494"
  type: "Convolution"
  bottom: "Eltwise246"
  top: "Convolution494"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm494"
  type: "BatchNorm"
  bottom: "Convolution494"
  top: "Convolution494"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale494"
  type: "Scale"
  bottom: "Convolution494"
  top: "Convolution494"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU494"
  type: "ReLU"
  bottom: "Convolution494"
  top: "Convolution494"
}
layer {
  name: "Convolution495"
  type: "Convolution"
  bottom: "Convolution494"
  top: "Convolution495"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm495"
  type: "BatchNorm"
  bottom: "Convolution495"
  top: "Convolution495"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale495"
  type: "Scale"
  bottom: "Convolution495"
  top: "Convolution495"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise247"
  type: "Eltwise"
  bottom: "Eltwise246"
  bottom: "Convolution495"
  top: "Eltwise247"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU495"
  type: "ReLU"
  bottom: "Eltwise247"
  top: "Eltwise247"
}
layer {
  name: "Convolution496"
  type: "Convolution"
  bottom: "Eltwise247"
  top: "Convolution496"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm496"
  type: "BatchNorm"
  bottom: "Convolution496"
  top: "Convolution496"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale496"
  type: "Scale"
  bottom: "Convolution496"
  top: "Convolution496"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU496"
  type: "ReLU"
  bottom: "Convolution496"
  top: "Convolution496"
}
layer {
  name: "Convolution497"
  type: "Convolution"
  bottom: "Convolution496"
  top: "Convolution497"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm497"
  type: "BatchNorm"
  bottom: "Convolution497"
  top: "Convolution497"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale497"
  type: "Scale"
  bottom: "Convolution497"
  top: "Convolution497"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise248"
  type: "Eltwise"
  bottom: "Eltwise247"
  bottom: "Convolution497"
  top: "Eltwise248"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU497"
  type: "ReLU"
  bottom: "Eltwise248"
  top: "Eltwise248"
}
layer {
  name: "Convolution498"
  type: "Convolution"
  bottom: "Eltwise248"
  top: "Convolution498"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm498"
  type: "BatchNorm"
  bottom: "Convolution498"
  top: "Convolution498"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale498"
  type: "Scale"
  bottom: "Convolution498"
  top: "Convolution498"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU498"
  type: "ReLU"
  bottom: "Convolution498"
  top: "Convolution498"
}
layer {
  name: "Convolution499"
  type: "Convolution"
  bottom: "Convolution498"
  top: "Convolution499"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm499"
  type: "BatchNorm"
  bottom: "Convolution499"
  top: "Convolution499"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale499"
  type: "Scale"
  bottom: "Convolution499"
  top: "Convolution499"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise249"
  type: "Eltwise"
  bottom: "Eltwise248"
  bottom: "Convolution499"
  top: "Eltwise249"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU499"
  type: "ReLU"
  bottom: "Eltwise249"
  top: "Eltwise249"
}
layer {
  name: "Convolution500"
  type: "Convolution"
  bottom: "Eltwise249"
  top: "Convolution500"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm500"
  type: "BatchNorm"
  bottom: "Convolution500"
  top: "Convolution500"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale500"
  type: "Scale"
  bottom: "Convolution500"
  top: "Convolution500"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU500"
  type: "ReLU"
  bottom: "Convolution500"
  top: "Convolution500"
}
layer {
  name: "Convolution501"
  type: "Convolution"
  bottom: "Convolution500"
  top: "Convolution501"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm501"
  type: "BatchNorm"
  bottom: "Convolution501"
  top: "Convolution501"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale501"
  type: "Scale"
  bottom: "Convolution501"
  top: "Convolution501"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise250"
  type: "Eltwise"
  bottom: "Eltwise249"
  bottom: "Convolution501"
  top: "Eltwise250"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU501"
  type: "ReLU"
  bottom: "Eltwise250"
  top: "Eltwise250"
}
layer {
  name: "Convolution502"
  type: "Convolution"
  bottom: "Eltwise250"
  top: "Convolution502"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm502"
  type: "BatchNorm"
  bottom: "Convolution502"
  top: "Convolution502"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale502"
  type: "Scale"
  bottom: "Convolution502"
  top: "Convolution502"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU502"
  type: "ReLU"
  bottom: "Convolution502"
  top: "Convolution502"
}
layer {
  name: "Convolution503"
  type: "Convolution"
  bottom: "Convolution502"
  top: "Convolution503"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm503"
  type: "BatchNorm"
  bottom: "Convolution503"
  top: "Convolution503"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale503"
  type: "Scale"
  bottom: "Convolution503"
  top: "Convolution503"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise251"
  type: "Eltwise"
  bottom: "Eltwise250"
  bottom: "Convolution503"
  top: "Eltwise251"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU503"
  type: "ReLU"
  bottom: "Eltwise251"
  top: "Eltwise251"
}
layer {
  name: "Convolution504"
  type: "Convolution"
  bottom: "Eltwise251"
  top: "Convolution504"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm504"
  type: "BatchNorm"
  bottom: "Convolution504"
  top: "Convolution504"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale504"
  type: "Scale"
  bottom: "Convolution504"
  top: "Convolution504"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU504"
  type: "ReLU"
  bottom: "Convolution504"
  top: "Convolution504"
}
layer {
  name: "Convolution505"
  type: "Convolution"
  bottom: "Convolution504"
  top: "Convolution505"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm505"
  type: "BatchNorm"
  bottom: "Convolution505"
  top: "Convolution505"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale505"
  type: "Scale"
  bottom: "Convolution505"
  top: "Convolution505"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise252"
  type: "Eltwise"
  bottom: "Eltwise251"
  bottom: "Convolution505"
  top: "Eltwise252"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU505"
  type: "ReLU"
  bottom: "Eltwise252"
  top: "Eltwise252"
}
layer {
  name: "Convolution506"
  type: "Convolution"
  bottom: "Eltwise252"
  top: "Convolution506"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm506"
  type: "BatchNorm"
  bottom: "Convolution506"
  top: "Convolution506"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale506"
  type: "Scale"
  bottom: "Convolution506"
  top: "Convolution506"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU506"
  type: "ReLU"
  bottom: "Convolution506"
  top: "Convolution506"
}
layer {
  name: "Convolution507"
  type: "Convolution"
  bottom: "Convolution506"
  top: "Convolution507"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm507"
  type: "BatchNorm"
  bottom: "Convolution507"
  top: "Convolution507"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale507"
  type: "Scale"
  bottom: "Convolution507"
  top: "Convolution507"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise253"
  type: "Eltwise"
  bottom: "Eltwise252"
  bottom: "Convolution507"
  top: "Eltwise253"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU507"
  type: "ReLU"
  bottom: "Eltwise253"
  top: "Eltwise253"
}
layer {
  name: "Convolution508"
  type: "Convolution"
  bottom: "Eltwise253"
  top: "Convolution508"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm508"
  type: "BatchNorm"
  bottom: "Convolution508"
  top: "Convolution508"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale508"
  type: "Scale"
  bottom: "Convolution508"
  top: "Convolution508"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU508"
  type: "ReLU"
  bottom: "Convolution508"
  top: "Convolution508"
}
layer {
  name: "Convolution509"
  type: "Convolution"
  bottom: "Convolution508"
  top: "Convolution509"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm509"
  type: "BatchNorm"
  bottom: "Convolution509"
  top: "Convolution509"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale509"
  type: "Scale"
  bottom: "Convolution509"
  top: "Convolution509"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise254"
  type: "Eltwise"
  bottom: "Eltwise253"
  bottom: "Convolution509"
  top: "Eltwise254"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU509"
  type: "ReLU"
  bottom: "Eltwise254"
  top: "Eltwise254"
}
layer {
  name: "Convolution510"
  type: "Convolution"
  bottom: "Eltwise254"
  top: "Convolution510"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm510"
  type: "BatchNorm"
  bottom: "Convolution510"
  top: "Convolution510"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale510"
  type: "Scale"
  bottom: "Convolution510"
  top: "Convolution510"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU510"
  type: "ReLU"
  bottom: "Convolution510"
  top: "Convolution510"
}
layer {
  name: "Convolution511"
  type: "Convolution"
  bottom: "Convolution510"
  top: "Convolution511"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm511"
  type: "BatchNorm"
  bottom: "Convolution511"
  top: "Convolution511"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale511"
  type: "Scale"
  bottom: "Convolution511"
  top: "Convolution511"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise255"
  type: "Eltwise"
  bottom: "Eltwise254"
  bottom: "Convolution511"
  top: "Eltwise255"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU511"
  type: "ReLU"
  bottom: "Eltwise255"
  top: "Eltwise255"
}
layer {
  name: "Convolution512"
  type: "Convolution"
  bottom: "Eltwise255"
  top: "Convolution512"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm512"
  type: "BatchNorm"
  bottom: "Convolution512"
  top: "Convolution512"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale512"
  type: "Scale"
  bottom: "Convolution512"
  top: "Convolution512"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU512"
  type: "ReLU"
  bottom: "Convolution512"
  top: "Convolution512"
}
layer {
  name: "Convolution513"
  type: "Convolution"
  bottom: "Convolution512"
  top: "Convolution513"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm513"
  type: "BatchNorm"
  bottom: "Convolution513"
  top: "Convolution513"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale513"
  type: "Scale"
  bottom: "Convolution513"
  top: "Convolution513"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise256"
  type: "Eltwise"
  bottom: "Eltwise255"
  bottom: "Convolution513"
  top: "Eltwise256"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU513"
  type: "ReLU"
  bottom: "Eltwise256"
  top: "Eltwise256"
}
layer {
  name: "Convolution514"
  type: "Convolution"
  bottom: "Eltwise256"
  top: "Convolution514"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm514"
  type: "BatchNorm"
  bottom: "Convolution514"
  top: "Convolution514"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale514"
  type: "Scale"
  bottom: "Convolution514"
  top: "Convolution514"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU514"
  type: "ReLU"
  bottom: "Convolution514"
  top: "Convolution514"
}
layer {
  name: "Convolution515"
  type: "Convolution"
  bottom: "Convolution514"
  top: "Convolution515"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm515"
  type: "BatchNorm"
  bottom: "Convolution515"
  top: "Convolution515"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale515"
  type: "Scale"
  bottom: "Convolution515"
  top: "Convolution515"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise257"
  type: "Eltwise"
  bottom: "Eltwise256"
  bottom: "Convolution515"
  top: "Eltwise257"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU515"
  type: "ReLU"
  bottom: "Eltwise257"
  top: "Eltwise257"
}
layer {
  name: "Convolution516"
  type: "Convolution"
  bottom: "Eltwise257"
  top: "Convolution516"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm516"
  type: "BatchNorm"
  bottom: "Convolution516"
  top: "Convolution516"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale516"
  type: "Scale"
  bottom: "Convolution516"
  top: "Convolution516"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU516"
  type: "ReLU"
  bottom: "Convolution516"
  top: "Convolution516"
}
layer {
  name: "Convolution517"
  type: "Convolution"
  bottom: "Convolution516"
  top: "Convolution517"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm517"
  type: "BatchNorm"
  bottom: "Convolution517"
  top: "Convolution517"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale517"
  type: "Scale"
  bottom: "Convolution517"
  top: "Convolution517"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise258"
  type: "Eltwise"
  bottom: "Eltwise257"
  bottom: "Convolution517"
  top: "Eltwise258"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU517"
  type: "ReLU"
  bottom: "Eltwise258"
  top: "Eltwise258"
}
layer {
  name: "Convolution518"
  type: "Convolution"
  bottom: "Eltwise258"
  top: "Convolution518"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm518"
  type: "BatchNorm"
  bottom: "Convolution518"
  top: "Convolution518"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale518"
  type: "Scale"
  bottom: "Convolution518"
  top: "Convolution518"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU518"
  type: "ReLU"
  bottom: "Convolution518"
  top: "Convolution518"
}
layer {
  name: "Convolution519"
  type: "Convolution"
  bottom: "Convolution518"
  top: "Convolution519"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm519"
  type: "BatchNorm"
  bottom: "Convolution519"
  top: "Convolution519"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale519"
  type: "Scale"
  bottom: "Convolution519"
  top: "Convolution519"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise259"
  type: "Eltwise"
  bottom: "Eltwise258"
  bottom: "Convolution519"
  top: "Eltwise259"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU519"
  type: "ReLU"
  bottom: "Eltwise259"
  top: "Eltwise259"
}
layer {
  name: "Convolution520"
  type: "Convolution"
  bottom: "Eltwise259"
  top: "Convolution520"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm520"
  type: "BatchNorm"
  bottom: "Convolution520"
  top: "Convolution520"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale520"
  type: "Scale"
  bottom: "Convolution520"
  top: "Convolution520"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU520"
  type: "ReLU"
  bottom: "Convolution520"
  top: "Convolution520"
}
layer {
  name: "Convolution521"
  type: "Convolution"
  bottom: "Convolution520"
  top: "Convolution521"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm521"
  type: "BatchNorm"
  bottom: "Convolution521"
  top: "Convolution521"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale521"
  type: "Scale"
  bottom: "Convolution521"
  top: "Convolution521"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise260"
  type: "Eltwise"
  bottom: "Eltwise259"
  bottom: "Convolution521"
  top: "Eltwise260"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU521"
  type: "ReLU"
  bottom: "Eltwise260"
  top: "Eltwise260"
}
layer {
  name: "Convolution522"
  type: "Convolution"
  bottom: "Eltwise260"
  top: "Convolution522"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm522"
  type: "BatchNorm"
  bottom: "Convolution522"
  top: "Convolution522"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale522"
  type: "Scale"
  bottom: "Convolution522"
  top: "Convolution522"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU522"
  type: "ReLU"
  bottom: "Convolution522"
  top: "Convolution522"
}
layer {
  name: "Convolution523"
  type: "Convolution"
  bottom: "Convolution522"
  top: "Convolution523"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm523"
  type: "BatchNorm"
  bottom: "Convolution523"
  top: "Convolution523"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale523"
  type: "Scale"
  bottom: "Convolution523"
  top: "Convolution523"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise261"
  type: "Eltwise"
  bottom: "Eltwise260"
  bottom: "Convolution523"
  top: "Eltwise261"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU523"
  type: "ReLU"
  bottom: "Eltwise261"
  top: "Eltwise261"
}
layer {
  name: "Convolution524"
  type: "Convolution"
  bottom: "Eltwise261"
  top: "Convolution524"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm524"
  type: "BatchNorm"
  bottom: "Convolution524"
  top: "Convolution524"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale524"
  type: "Scale"
  bottom: "Convolution524"
  top: "Convolution524"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU524"
  type: "ReLU"
  bottom: "Convolution524"
  top: "Convolution524"
}
layer {
  name: "Convolution525"
  type: "Convolution"
  bottom: "Convolution524"
  top: "Convolution525"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm525"
  type: "BatchNorm"
  bottom: "Convolution525"
  top: "Convolution525"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale525"
  type: "Scale"
  bottom: "Convolution525"
  top: "Convolution525"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise262"
  type: "Eltwise"
  bottom: "Eltwise261"
  bottom: "Convolution525"
  top: "Eltwise262"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU525"
  type: "ReLU"
  bottom: "Eltwise262"
  top: "Eltwise262"
}
layer {
  name: "Convolution526"
  type: "Convolution"
  bottom: "Eltwise262"
  top: "Convolution526"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm526"
  type: "BatchNorm"
  bottom: "Convolution526"
  top: "Convolution526"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale526"
  type: "Scale"
  bottom: "Convolution526"
  top: "Convolution526"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU526"
  type: "ReLU"
  bottom: "Convolution526"
  top: "Convolution526"
}
layer {
  name: "Convolution527"
  type: "Convolution"
  bottom: "Convolution526"
  top: "Convolution527"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm527"
  type: "BatchNorm"
  bottom: "Convolution527"
  top: "Convolution527"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale527"
  type: "Scale"
  bottom: "Convolution527"
  top: "Convolution527"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise263"
  type: "Eltwise"
  bottom: "Eltwise262"
  bottom: "Convolution527"
  top: "Eltwise263"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU527"
  type: "ReLU"
  bottom: "Eltwise263"
  top: "Eltwise263"
}
layer {
  name: "Convolution528"
  type: "Convolution"
  bottom: "Eltwise263"
  top: "Convolution528"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm528"
  type: "BatchNorm"
  bottom: "Convolution528"
  top: "Convolution528"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale528"
  type: "Scale"
  bottom: "Convolution528"
  top: "Convolution528"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU528"
  type: "ReLU"
  bottom: "Convolution528"
  top: "Convolution528"
}
layer {
  name: "Convolution529"
  type: "Convolution"
  bottom: "Convolution528"
  top: "Convolution529"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm529"
  type: "BatchNorm"
  bottom: "Convolution529"
  top: "Convolution529"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale529"
  type: "Scale"
  bottom: "Convolution529"
  top: "Convolution529"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise264"
  type: "Eltwise"
  bottom: "Eltwise263"
  bottom: "Convolution529"
  top: "Eltwise264"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU529"
  type: "ReLU"
  bottom: "Eltwise264"
  top: "Eltwise264"
}
layer {
  name: "Convolution530"
  type: "Convolution"
  bottom: "Eltwise264"
  top: "Convolution530"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm530"
  type: "BatchNorm"
  bottom: "Convolution530"
  top: "Convolution530"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale530"
  type: "Scale"
  bottom: "Convolution530"
  top: "Convolution530"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU530"
  type: "ReLU"
  bottom: "Convolution530"
  top: "Convolution530"
}
layer {
  name: "Convolution531"
  type: "Convolution"
  bottom: "Convolution530"
  top: "Convolution531"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm531"
  type: "BatchNorm"
  bottom: "Convolution531"
  top: "Convolution531"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale531"
  type: "Scale"
  bottom: "Convolution531"
  top: "Convolution531"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise265"
  type: "Eltwise"
  bottom: "Eltwise264"
  bottom: "Convolution531"
  top: "Eltwise265"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU531"
  type: "ReLU"
  bottom: "Eltwise265"
  top: "Eltwise265"
}
layer {
  name: "Convolution532"
  type: "Convolution"
  bottom: "Eltwise265"
  top: "Convolution532"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm532"
  type: "BatchNorm"
  bottom: "Convolution532"
  top: "Convolution532"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale532"
  type: "Scale"
  bottom: "Convolution532"
  top: "Convolution532"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU532"
  type: "ReLU"
  bottom: "Convolution532"
  top: "Convolution532"
}
layer {
  name: "Convolution533"
  type: "Convolution"
  bottom: "Convolution532"
  top: "Convolution533"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm533"
  type: "BatchNorm"
  bottom: "Convolution533"
  top: "Convolution533"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale533"
  type: "Scale"
  bottom: "Convolution533"
  top: "Convolution533"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise266"
  type: "Eltwise"
  bottom: "Eltwise265"
  bottom: "Convolution533"
  top: "Eltwise266"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU533"
  type: "ReLU"
  bottom: "Eltwise266"
  top: "Eltwise266"
}
layer {
  name: "Convolution534"
  type: "Convolution"
  bottom: "Eltwise266"
  top: "Convolution534"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm534"
  type: "BatchNorm"
  bottom: "Convolution534"
  top: "Convolution534"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale534"
  type: "Scale"
  bottom: "Convolution534"
  top: "Convolution534"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU534"
  type: "ReLU"
  bottom: "Convolution534"
  top: "Convolution534"
}
layer {
  name: "Convolution535"
  type: "Convolution"
  bottom: "Convolution534"
  top: "Convolution535"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm535"
  type: "BatchNorm"
  bottom: "Convolution535"
  top: "Convolution535"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale535"
  type: "Scale"
  bottom: "Convolution535"
  top: "Convolution535"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise267"
  type: "Eltwise"
  bottom: "Eltwise266"
  bottom: "Convolution535"
  top: "Eltwise267"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU535"
  type: "ReLU"
  bottom: "Eltwise267"
  top: "Eltwise267"
}
layer {
  name: "Convolution536"
  type: "Convolution"
  bottom: "Eltwise267"
  top: "Convolution536"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm536"
  type: "BatchNorm"
  bottom: "Convolution536"
  top: "Convolution536"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale536"
  type: "Scale"
  bottom: "Convolution536"
  top: "Convolution536"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU536"
  type: "ReLU"
  bottom: "Convolution536"
  top: "Convolution536"
}
layer {
  name: "Convolution537"
  type: "Convolution"
  bottom: "Convolution536"
  top: "Convolution537"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm537"
  type: "BatchNorm"
  bottom: "Convolution537"
  top: "Convolution537"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale537"
  type: "Scale"
  bottom: "Convolution537"
  top: "Convolution537"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise268"
  type: "Eltwise"
  bottom: "Eltwise267"
  bottom: "Convolution537"
  top: "Eltwise268"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU537"
  type: "ReLU"
  bottom: "Eltwise268"
  top: "Eltwise268"
}
layer {
  name: "Convolution538"
  type: "Convolution"
  bottom: "Eltwise268"
  top: "Convolution538"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm538"
  type: "BatchNorm"
  bottom: "Convolution538"
  top: "Convolution538"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale538"
  type: "Scale"
  bottom: "Convolution538"
  top: "Convolution538"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU538"
  type: "ReLU"
  bottom: "Convolution538"
  top: "Convolution538"
}
layer {
  name: "Convolution539"
  type: "Convolution"
  bottom: "Convolution538"
  top: "Convolution539"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm539"
  type: "BatchNorm"
  bottom: "Convolution539"
  top: "Convolution539"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale539"
  type: "Scale"
  bottom: "Convolution539"
  top: "Convolution539"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise269"
  type: "Eltwise"
  bottom: "Eltwise268"
  bottom: "Convolution539"
  top: "Eltwise269"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU539"
  type: "ReLU"
  bottom: "Eltwise269"
  top: "Eltwise269"
}
layer {
  name: "Convolution540"
  type: "Convolution"
  bottom: "Eltwise269"
  top: "Convolution540"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm540"
  type: "BatchNorm"
  bottom: "Convolution540"
  top: "Convolution540"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale540"
  type: "Scale"
  bottom: "Convolution540"
  top: "Convolution540"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU540"
  type: "ReLU"
  bottom: "Convolution540"
  top: "Convolution540"
}
layer {
  name: "Convolution541"
  type: "Convolution"
  bottom: "Convolution540"
  top: "Convolution541"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm541"
  type: "BatchNorm"
  bottom: "Convolution541"
  top: "Convolution541"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale541"
  type: "Scale"
  bottom: "Convolution541"
  top: "Convolution541"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise270"
  type: "Eltwise"
  bottom: "Eltwise269"
  bottom: "Convolution541"
  top: "Eltwise270"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU541"
  type: "ReLU"
  bottom: "Eltwise270"
  top: "Eltwise270"
}
layer {
  name: "Convolution542"
  type: "Convolution"
  bottom: "Eltwise270"
  top: "Convolution542"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm542"
  type: "BatchNorm"
  bottom: "Convolution542"
  top: "Convolution542"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale542"
  type: "Scale"
  bottom: "Convolution542"
  top: "Convolution542"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU542"
  type: "ReLU"
  bottom: "Convolution542"
  top: "Convolution542"
}
layer {
  name: "Convolution543"
  type: "Convolution"
  bottom: "Convolution542"
  top: "Convolution543"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm543"
  type: "BatchNorm"
  bottom: "Convolution543"
  top: "Convolution543"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale543"
  type: "Scale"
  bottom: "Convolution543"
  top: "Convolution543"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise271"
  type: "Eltwise"
  bottom: "Eltwise270"
  bottom: "Convolution543"
  top: "Eltwise271"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU543"
  type: "ReLU"
  bottom: "Eltwise271"
  top: "Eltwise271"
}
layer {
  name: "Convolution544"
  type: "Convolution"
  bottom: "Eltwise271"
  top: "Convolution544"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm544"
  type: "BatchNorm"
  bottom: "Convolution544"
  top: "Convolution544"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale544"
  type: "Scale"
  bottom: "Convolution544"
  top: "Convolution544"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU544"
  type: "ReLU"
  bottom: "Convolution544"
  top: "Convolution544"
}
layer {
  name: "Convolution545"
  type: "Convolution"
  bottom: "Convolution544"
  top: "Convolution545"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm545"
  type: "BatchNorm"
  bottom: "Convolution545"
  top: "Convolution545"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale545"
  type: "Scale"
  bottom: "Convolution545"
  top: "Convolution545"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise272"
  type: "Eltwise"
  bottom: "Eltwise271"
  bottom: "Convolution545"
  top: "Eltwise272"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU545"
  type: "ReLU"
  bottom: "Eltwise272"
  top: "Eltwise272"
}
layer {
  name: "Convolution546"
  type: "Convolution"
  bottom: "Eltwise272"
  top: "Convolution546"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm546"
  type: "BatchNorm"
  bottom: "Convolution546"
  top: "Convolution546"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale546"
  type: "Scale"
  bottom: "Convolution546"
  top: "Convolution546"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU546"
  type: "ReLU"
  bottom: "Convolution546"
  top: "Convolution546"
}
layer {
  name: "Convolution547"
  type: "Convolution"
  bottom: "Convolution546"
  top: "Convolution547"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm547"
  type: "BatchNorm"
  bottom: "Convolution547"
  top: "Convolution547"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale547"
  type: "Scale"
  bottom: "Convolution547"
  top: "Convolution547"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise273"
  type: "Eltwise"
  bottom: "Eltwise272"
  bottom: "Convolution547"
  top: "Eltwise273"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU547"
  type: "ReLU"
  bottom: "Eltwise273"
  top: "Eltwise273"
}
layer {
  name: "Convolution548"
  type: "Convolution"
  bottom: "Eltwise273"
  top: "Convolution548"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm548"
  type: "BatchNorm"
  bottom: "Convolution548"
  top: "Convolution548"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale548"
  type: "Scale"
  bottom: "Convolution548"
  top: "Convolution548"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU548"
  type: "ReLU"
  bottom: "Convolution548"
  top: "Convolution548"
}
layer {
  name: "Convolution549"
  type: "Convolution"
  bottom: "Convolution548"
  top: "Convolution549"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm549"
  type: "BatchNorm"
  bottom: "Convolution549"
  top: "Convolution549"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale549"
  type: "Scale"
  bottom: "Convolution549"
  top: "Convolution549"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise274"
  type: "Eltwise"
  bottom: "Eltwise273"
  bottom: "Convolution549"
  top: "Eltwise274"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU549"
  type: "ReLU"
  bottom: "Eltwise274"
  top: "Eltwise274"
}
layer {
  name: "Convolution550"
  type: "Convolution"
  bottom: "Eltwise274"
  top: "Convolution550"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm550"
  type: "BatchNorm"
  bottom: "Convolution550"
  top: "Convolution550"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale550"
  type: "Scale"
  bottom: "Convolution550"
  top: "Convolution550"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU550"
  type: "ReLU"
  bottom: "Convolution550"
  top: "Convolution550"
}
layer {
  name: "Convolution551"
  type: "Convolution"
  bottom: "Convolution550"
  top: "Convolution551"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm551"
  type: "BatchNorm"
  bottom: "Convolution551"
  top: "Convolution551"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale551"
  type: "Scale"
  bottom: "Convolution551"
  top: "Convolution551"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise275"
  type: "Eltwise"
  bottom: "Eltwise274"
  bottom: "Convolution551"
  top: "Eltwise275"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU551"
  type: "ReLU"
  bottom: "Eltwise275"
  top: "Eltwise275"
}
layer {
  name: "Convolution552"
  type: "Convolution"
  bottom: "Eltwise275"
  top: "Convolution552"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm552"
  type: "BatchNorm"
  bottom: "Convolution552"
  top: "Convolution552"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale552"
  type: "Scale"
  bottom: "Convolution552"
  top: "Convolution552"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU552"
  type: "ReLU"
  bottom: "Convolution552"
  top: "Convolution552"
}
layer {
  name: "Convolution553"
  type: "Convolution"
  bottom: "Convolution552"
  top: "Convolution553"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm553"
  type: "BatchNorm"
  bottom: "Convolution553"
  top: "Convolution553"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale553"
  type: "Scale"
  bottom: "Convolution553"
  top: "Convolution553"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise276"
  type: "Eltwise"
  bottom: "Eltwise275"
  bottom: "Convolution553"
  top: "Eltwise276"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU553"
  type: "ReLU"
  bottom: "Eltwise276"
  top: "Eltwise276"
}
layer {
  name: "Convolution554"
  type: "Convolution"
  bottom: "Eltwise276"
  top: "Convolution554"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm554"
  type: "BatchNorm"
  bottom: "Convolution554"
  top: "Convolution554"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale554"
  type: "Scale"
  bottom: "Convolution554"
  top: "Convolution554"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU554"
  type: "ReLU"
  bottom: "Convolution554"
  top: "Convolution554"
}
layer {
  name: "Convolution555"
  type: "Convolution"
  bottom: "Convolution554"
  top: "Convolution555"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm555"
  type: "BatchNorm"
  bottom: "Convolution555"
  top: "Convolution555"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale555"
  type: "Scale"
  bottom: "Convolution555"
  top: "Convolution555"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise277"
  type: "Eltwise"
  bottom: "Eltwise276"
  bottom: "Convolution555"
  top: "Eltwise277"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU555"
  type: "ReLU"
  bottom: "Eltwise277"
  top: "Eltwise277"
}
layer {
  name: "Convolution556"
  type: "Convolution"
  bottom: "Eltwise277"
  top: "Convolution556"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm556"
  type: "BatchNorm"
  bottom: "Convolution556"
  top: "Convolution556"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale556"
  type: "Scale"
  bottom: "Convolution556"
  top: "Convolution556"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU556"
  type: "ReLU"
  bottom: "Convolution556"
  top: "Convolution556"
}
layer {
  name: "Convolution557"
  type: "Convolution"
  bottom: "Convolution556"
  top: "Convolution557"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm557"
  type: "BatchNorm"
  bottom: "Convolution557"
  top: "Convolution557"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale557"
  type: "Scale"
  bottom: "Convolution557"
  top: "Convolution557"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise278"
  type: "Eltwise"
  bottom: "Eltwise277"
  bottom: "Convolution557"
  top: "Eltwise278"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU557"
  type: "ReLU"
  bottom: "Eltwise278"
  top: "Eltwise278"
}
layer {
  name: "Convolution558"
  type: "Convolution"
  bottom: "Eltwise278"
  top: "Convolution558"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm558"
  type: "BatchNorm"
  bottom: "Convolution558"
  top: "Convolution558"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale558"
  type: "Scale"
  bottom: "Convolution558"
  top: "Convolution558"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU558"
  type: "ReLU"
  bottom: "Convolution558"
  top: "Convolution558"
}
layer {
  name: "Convolution559"
  type: "Convolution"
  bottom: "Convolution558"
  top: "Convolution559"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm559"
  type: "BatchNorm"
  bottom: "Convolution559"
  top: "Convolution559"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale559"
  type: "Scale"
  bottom: "Convolution559"
  top: "Convolution559"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise279"
  type: "Eltwise"
  bottom: "Eltwise278"
  bottom: "Convolution559"
  top: "Eltwise279"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU559"
  type: "ReLU"
  bottom: "Eltwise279"
  top: "Eltwise279"
}
layer {
  name: "Convolution560"
  type: "Convolution"
  bottom: "Eltwise279"
  top: "Convolution560"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm560"
  type: "BatchNorm"
  bottom: "Convolution560"
  top: "Convolution560"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale560"
  type: "Scale"
  bottom: "Convolution560"
  top: "Convolution560"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU560"
  type: "ReLU"
  bottom: "Convolution560"
  top: "Convolution560"
}
layer {
  name: "Convolution561"
  type: "Convolution"
  bottom: "Convolution560"
  top: "Convolution561"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm561"
  type: "BatchNorm"
  bottom: "Convolution561"
  top: "Convolution561"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale561"
  type: "Scale"
  bottom: "Convolution561"
  top: "Convolution561"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise280"
  type: "Eltwise"
  bottom: "Eltwise279"
  bottom: "Convolution561"
  top: "Eltwise280"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU561"
  type: "ReLU"
  bottom: "Eltwise280"
  top: "Eltwise280"
}
layer {
  name: "Convolution562"
  type: "Convolution"
  bottom: "Eltwise280"
  top: "Convolution562"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm562"
  type: "BatchNorm"
  bottom: "Convolution562"
  top: "Convolution562"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale562"
  type: "Scale"
  bottom: "Convolution562"
  top: "Convolution562"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU562"
  type: "ReLU"
  bottom: "Convolution562"
  top: "Convolution562"
}
layer {
  name: "Convolution563"
  type: "Convolution"
  bottom: "Convolution562"
  top: "Convolution563"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm563"
  type: "BatchNorm"
  bottom: "Convolution563"
  top: "Convolution563"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale563"
  type: "Scale"
  bottom: "Convolution563"
  top: "Convolution563"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise281"
  type: "Eltwise"
  bottom: "Eltwise280"
  bottom: "Convolution563"
  top: "Eltwise281"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU563"
  type: "ReLU"
  bottom: "Eltwise281"
  top: "Eltwise281"
}
layer {
  name: "Convolution564"
  type: "Convolution"
  bottom: "Eltwise281"
  top: "Convolution564"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm564"
  type: "BatchNorm"
  bottom: "Convolution564"
  top: "Convolution564"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale564"
  type: "Scale"
  bottom: "Convolution564"
  top: "Convolution564"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU564"
  type: "ReLU"
  bottom: "Convolution564"
  top: "Convolution564"
}
layer {
  name: "Convolution565"
  type: "Convolution"
  bottom: "Convolution564"
  top: "Convolution565"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm565"
  type: "BatchNorm"
  bottom: "Convolution565"
  top: "Convolution565"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale565"
  type: "Scale"
  bottom: "Convolution565"
  top: "Convolution565"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise282"
  type: "Eltwise"
  bottom: "Eltwise281"
  bottom: "Convolution565"
  top: "Eltwise282"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU565"
  type: "ReLU"
  bottom: "Eltwise282"
  top: "Eltwise282"
}
layer {
  name: "Convolution566"
  type: "Convolution"
  bottom: "Eltwise282"
  top: "Convolution566"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm566"
  type: "BatchNorm"
  bottom: "Convolution566"
  top: "Convolution566"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale566"
  type: "Scale"
  bottom: "Convolution566"
  top: "Convolution566"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU566"
  type: "ReLU"
  bottom: "Convolution566"
  top: "Convolution566"
}
layer {
  name: "Convolution567"
  type: "Convolution"
  bottom: "Convolution566"
  top: "Convolution567"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm567"
  type: "BatchNorm"
  bottom: "Convolution567"
  top: "Convolution567"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale567"
  type: "Scale"
  bottom: "Convolution567"
  top: "Convolution567"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise283"
  type: "Eltwise"
  bottom: "Eltwise282"
  bottom: "Convolution567"
  top: "Eltwise283"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU567"
  type: "ReLU"
  bottom: "Eltwise283"
  top: "Eltwise283"
}
layer {
  name: "Convolution568"
  type: "Convolution"
  bottom: "Eltwise283"
  top: "Convolution568"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm568"
  type: "BatchNorm"
  bottom: "Convolution568"
  top: "Convolution568"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale568"
  type: "Scale"
  bottom: "Convolution568"
  top: "Convolution568"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU568"
  type: "ReLU"
  bottom: "Convolution568"
  top: "Convolution568"
}
layer {
  name: "Convolution569"
  type: "Convolution"
  bottom: "Convolution568"
  top: "Convolution569"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm569"
  type: "BatchNorm"
  bottom: "Convolution569"
  top: "Convolution569"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale569"
  type: "Scale"
  bottom: "Convolution569"
  top: "Convolution569"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise284"
  type: "Eltwise"
  bottom: "Eltwise283"
  bottom: "Convolution569"
  top: "Eltwise284"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU569"
  type: "ReLU"
  bottom: "Eltwise284"
  top: "Eltwise284"
}
layer {
  name: "Convolution570"
  type: "Convolution"
  bottom: "Eltwise284"
  top: "Convolution570"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm570"
  type: "BatchNorm"
  bottom: "Convolution570"
  top: "Convolution570"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale570"
  type: "Scale"
  bottom: "Convolution570"
  top: "Convolution570"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU570"
  type: "ReLU"
  bottom: "Convolution570"
  top: "Convolution570"
}
layer {
  name: "Convolution571"
  type: "Convolution"
  bottom: "Convolution570"
  top: "Convolution571"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm571"
  type: "BatchNorm"
  bottom: "Convolution571"
  top: "Convolution571"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale571"
  type: "Scale"
  bottom: "Convolution571"
  top: "Convolution571"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise285"
  type: "Eltwise"
  bottom: "Eltwise284"
  bottom: "Convolution571"
  top: "Eltwise285"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU571"
  type: "ReLU"
  bottom: "Eltwise285"
  top: "Eltwise285"
}
layer {
  name: "Convolution572"
  type: "Convolution"
  bottom: "Eltwise285"
  top: "Convolution572"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm572"
  type: "BatchNorm"
  bottom: "Convolution572"
  top: "Convolution572"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale572"
  type: "Scale"
  bottom: "Convolution572"
  top: "Convolution572"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU572"
  type: "ReLU"
  bottom: "Convolution572"
  top: "Convolution572"
}
layer {
  name: "Convolution573"
  type: "Convolution"
  bottom: "Convolution572"
  top: "Convolution573"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm573"
  type: "BatchNorm"
  bottom: "Convolution573"
  top: "Convolution573"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale573"
  type: "Scale"
  bottom: "Convolution573"
  top: "Convolution573"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise286"
  type: "Eltwise"
  bottom: "Eltwise285"
  bottom: "Convolution573"
  top: "Eltwise286"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU573"
  type: "ReLU"
  bottom: "Eltwise286"
  top: "Eltwise286"
}
layer {
  name: "Convolution574"
  type: "Convolution"
  bottom: "Eltwise286"
  top: "Convolution574"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm574"
  type: "BatchNorm"
  bottom: "Convolution574"
  top: "Convolution574"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale574"
  type: "Scale"
  bottom: "Convolution574"
  top: "Convolution574"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU574"
  type: "ReLU"
  bottom: "Convolution574"
  top: "Convolution574"
}
layer {
  name: "Convolution575"
  type: "Convolution"
  bottom: "Convolution574"
  top: "Convolution575"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm575"
  type: "BatchNorm"
  bottom: "Convolution575"
  top: "Convolution575"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale575"
  type: "Scale"
  bottom: "Convolution575"
  top: "Convolution575"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise287"
  type: "Eltwise"
  bottom: "Eltwise286"
  bottom: "Convolution575"
  top: "Eltwise287"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU575"
  type: "ReLU"
  bottom: "Eltwise287"
  top: "Eltwise287"
}
layer {
  name: "Convolution576"
  type: "Convolution"
  bottom: "Eltwise287"
  top: "Convolution576"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm576"
  type: "BatchNorm"
  bottom: "Convolution576"
  top: "Convolution576"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale576"
  type: "Scale"
  bottom: "Convolution576"
  top: "Convolution576"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU576"
  type: "ReLU"
  bottom: "Convolution576"
  top: "Convolution576"
}
layer {
  name: "Convolution577"
  type: "Convolution"
  bottom: "Convolution576"
  top: "Convolution577"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm577"
  type: "BatchNorm"
  bottom: "Convolution577"
  top: "Convolution577"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale577"
  type: "Scale"
  bottom: "Convolution577"
  top: "Convolution577"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise288"
  type: "Eltwise"
  bottom: "Eltwise287"
  bottom: "Convolution577"
  top: "Eltwise288"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU577"
  type: "ReLU"
  bottom: "Eltwise288"
  top: "Eltwise288"
}
layer {
  name: "Convolution578"
  type: "Convolution"
  bottom: "Eltwise288"
  top: "Convolution578"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm578"
  type: "BatchNorm"
  bottom: "Convolution578"
  top: "Convolution578"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale578"
  type: "Scale"
  bottom: "Convolution578"
  top: "Convolution578"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU578"
  type: "ReLU"
  bottom: "Convolution578"
  top: "Convolution578"
}
layer {
  name: "Convolution579"
  type: "Convolution"
  bottom: "Convolution578"
  top: "Convolution579"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm579"
  type: "BatchNorm"
  bottom: "Convolution579"
  top: "Convolution579"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale579"
  type: "Scale"
  bottom: "Convolution579"
  top: "Convolution579"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise289"
  type: "Eltwise"
  bottom: "Eltwise288"
  bottom: "Convolution579"
  top: "Eltwise289"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU579"
  type: "ReLU"
  bottom: "Eltwise289"
  top: "Eltwise289"
}
layer {
  name: "Convolution580"
  type: "Convolution"
  bottom: "Eltwise289"
  top: "Convolution580"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm580"
  type: "BatchNorm"
  bottom: "Convolution580"
  top: "Convolution580"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale580"
  type: "Scale"
  bottom: "Convolution580"
  top: "Convolution580"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU580"
  type: "ReLU"
  bottom: "Convolution580"
  top: "Convolution580"
}
layer {
  name: "Convolution581"
  type: "Convolution"
  bottom: "Convolution580"
  top: "Convolution581"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm581"
  type: "BatchNorm"
  bottom: "Convolution581"
  top: "Convolution581"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale581"
  type: "Scale"
  bottom: "Convolution581"
  top: "Convolution581"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise290"
  type: "Eltwise"
  bottom: "Eltwise289"
  bottom: "Convolution581"
  top: "Eltwise290"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU581"
  type: "ReLU"
  bottom: "Eltwise290"
  top: "Eltwise290"
}
layer {
  name: "Convolution582"
  type: "Convolution"
  bottom: "Eltwise290"
  top: "Convolution582"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm582"
  type: "BatchNorm"
  bottom: "Convolution582"
  top: "Convolution582"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale582"
  type: "Scale"
  bottom: "Convolution582"
  top: "Convolution582"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU582"
  type: "ReLU"
  bottom: "Convolution582"
  top: "Convolution582"
}
layer {
  name: "Convolution583"
  type: "Convolution"
  bottom: "Convolution582"
  top: "Convolution583"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm583"
  type: "BatchNorm"
  bottom: "Convolution583"
  top: "Convolution583"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale583"
  type: "Scale"
  bottom: "Convolution583"
  top: "Convolution583"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise291"
  type: "Eltwise"
  bottom: "Eltwise290"
  bottom: "Convolution583"
  top: "Eltwise291"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU583"
  type: "ReLU"
  bottom: "Eltwise291"
  top: "Eltwise291"
}
layer {
  name: "Convolution584"
  type: "Convolution"
  bottom: "Eltwise291"
  top: "Convolution584"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm584"
  type: "BatchNorm"
  bottom: "Convolution584"
  top: "Convolution584"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale584"
  type: "Scale"
  bottom: "Convolution584"
  top: "Convolution584"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU584"
  type: "ReLU"
  bottom: "Convolution584"
  top: "Convolution584"
}
layer {
  name: "Convolution585"
  type: "Convolution"
  bottom: "Convolution584"
  top: "Convolution585"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm585"
  type: "BatchNorm"
  bottom: "Convolution585"
  top: "Convolution585"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale585"
  type: "Scale"
  bottom: "Convolution585"
  top: "Convolution585"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise292"
  type: "Eltwise"
  bottom: "Eltwise291"
  bottom: "Convolution585"
  top: "Eltwise292"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU585"
  type: "ReLU"
  bottom: "Eltwise292"
  top: "Eltwise292"
}
layer {
  name: "Convolution586"
  type: "Convolution"
  bottom: "Eltwise292"
  top: "Convolution586"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm586"
  type: "BatchNorm"
  bottom: "Convolution586"
  top: "Convolution586"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale586"
  type: "Scale"
  bottom: "Convolution586"
  top: "Convolution586"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU586"
  type: "ReLU"
  bottom: "Convolution586"
  top: "Convolution586"
}
layer {
  name: "Convolution587"
  type: "Convolution"
  bottom: "Convolution586"
  top: "Convolution587"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm587"
  type: "BatchNorm"
  bottom: "Convolution587"
  top: "Convolution587"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale587"
  type: "Scale"
  bottom: "Convolution587"
  top: "Convolution587"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise293"
  type: "Eltwise"
  bottom: "Eltwise292"
  bottom: "Convolution587"
  top: "Eltwise293"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU587"
  type: "ReLU"
  bottom: "Eltwise293"
  top: "Eltwise293"
}
layer {
  name: "Convolution588"
  type: "Convolution"
  bottom: "Eltwise293"
  top: "Convolution588"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm588"
  type: "BatchNorm"
  bottom: "Convolution588"
  top: "Convolution588"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale588"
  type: "Scale"
  bottom: "Convolution588"
  top: "Convolution588"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU588"
  type: "ReLU"
  bottom: "Convolution588"
  top: "Convolution588"
}
layer {
  name: "Convolution589"
  type: "Convolution"
  bottom: "Convolution588"
  top: "Convolution589"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm589"
  type: "BatchNorm"
  bottom: "Convolution589"
  top: "Convolution589"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale589"
  type: "Scale"
  bottom: "Convolution589"
  top: "Convolution589"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise294"
  type: "Eltwise"
  bottom: "Eltwise293"
  bottom: "Convolution589"
  top: "Eltwise294"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU589"
  type: "ReLU"
  bottom: "Eltwise294"
  top: "Eltwise294"
}
layer {
  name: "Convolution590"
  type: "Convolution"
  bottom: "Eltwise294"
  top: "Convolution590"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm590"
  type: "BatchNorm"
  bottom: "Convolution590"
  top: "Convolution590"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale590"
  type: "Scale"
  bottom: "Convolution590"
  top: "Convolution590"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU590"
  type: "ReLU"
  bottom: "Convolution590"
  top: "Convolution590"
}
layer {
  name: "Convolution591"
  type: "Convolution"
  bottom: "Convolution590"
  top: "Convolution591"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm591"
  type: "BatchNorm"
  bottom: "Convolution591"
  top: "Convolution591"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale591"
  type: "Scale"
  bottom: "Convolution591"
  top: "Convolution591"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise295"
  type: "Eltwise"
  bottom: "Eltwise294"
  bottom: "Convolution591"
  top: "Eltwise295"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU591"
  type: "ReLU"
  bottom: "Eltwise295"
  top: "Eltwise295"
}
layer {
  name: "Convolution592"
  type: "Convolution"
  bottom: "Eltwise295"
  top: "Convolution592"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm592"
  type: "BatchNorm"
  bottom: "Convolution592"
  top: "Convolution592"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale592"
  type: "Scale"
  bottom: "Convolution592"
  top: "Convolution592"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU592"
  type: "ReLU"
  bottom: "Convolution592"
  top: "Convolution592"
}
layer {
  name: "Convolution593"
  type: "Convolution"
  bottom: "Convolution592"
  top: "Convolution593"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm593"
  type: "BatchNorm"
  bottom: "Convolution593"
  top: "Convolution593"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale593"
  type: "Scale"
  bottom: "Convolution593"
  top: "Convolution593"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise296"
  type: "Eltwise"
  bottom: "Eltwise295"
  bottom: "Convolution593"
  top: "Eltwise296"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU593"
  type: "ReLU"
  bottom: "Eltwise296"
  top: "Eltwise296"
}
layer {
  name: "Convolution594"
  type: "Convolution"
  bottom: "Eltwise296"
  top: "Convolution594"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm594"
  type: "BatchNorm"
  bottom: "Convolution594"
  top: "Convolution594"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale594"
  type: "Scale"
  bottom: "Convolution594"
  top: "Convolution594"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU594"
  type: "ReLU"
  bottom: "Convolution594"
  top: "Convolution594"
}
layer {
  name: "Convolution595"
  type: "Convolution"
  bottom: "Convolution594"
  top: "Convolution595"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm595"
  type: "BatchNorm"
  bottom: "Convolution595"
  top: "Convolution595"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale595"
  type: "Scale"
  bottom: "Convolution595"
  top: "Convolution595"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise297"
  type: "Eltwise"
  bottom: "Eltwise296"
  bottom: "Convolution595"
  top: "Eltwise297"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU595"
  type: "ReLU"
  bottom: "Eltwise297"
  top: "Eltwise297"
}
layer {
  name: "Convolution596"
  type: "Convolution"
  bottom: "Eltwise297"
  top: "Convolution596"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm596"
  type: "BatchNorm"
  bottom: "Convolution596"
  top: "Convolution596"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale596"
  type: "Scale"
  bottom: "Convolution596"
  top: "Convolution596"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU596"
  type: "ReLU"
  bottom: "Convolution596"
  top: "Convolution596"
}
layer {
  name: "Convolution597"
  type: "Convolution"
  bottom: "Convolution596"
  top: "Convolution597"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm597"
  type: "BatchNorm"
  bottom: "Convolution597"
  top: "Convolution597"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale597"
  type: "Scale"
  bottom: "Convolution597"
  top: "Convolution597"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise298"
  type: "Eltwise"
  bottom: "Eltwise297"
  bottom: "Convolution597"
  top: "Eltwise298"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU597"
  type: "ReLU"
  bottom: "Eltwise298"
  top: "Eltwise298"
}
layer {
  name: "Convolution598"
  type: "Convolution"
  bottom: "Eltwise298"
  top: "Convolution598"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm598"
  type: "BatchNorm"
  bottom: "Convolution598"
  top: "Convolution598"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale598"
  type: "Scale"
  bottom: "Convolution598"
  top: "Convolution598"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU598"
  type: "ReLU"
  bottom: "Convolution598"
  top: "Convolution598"
}
layer {
  name: "Convolution599"
  type: "Convolution"
  bottom: "Convolution598"
  top: "Convolution599"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm599"
  type: "BatchNorm"
  bottom: "Convolution599"
  top: "Convolution599"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale599"
  type: "Scale"
  bottom: "Convolution599"
  top: "Convolution599"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise299"
  type: "Eltwise"
  bottom: "Eltwise298"
  bottom: "Convolution599"
  top: "Eltwise299"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU599"
  type: "ReLU"
  bottom: "Eltwise299"
  top: "Eltwise299"
}
layer {
  name: "Convolution600"
  type: "Convolution"
  bottom: "Eltwise299"
  top: "Convolution600"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm600"
  type: "BatchNorm"
  bottom: "Convolution600"
  top: "Convolution600"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale600"
  type: "Scale"
  bottom: "Convolution600"
  top: "Convolution600"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU600"
  type: "ReLU"
  bottom: "Convolution600"
  top: "Convolution600"
}
layer {
  name: "Convolution601"
  type: "Convolution"
  bottom: "Convolution600"
  top: "Convolution601"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm601"
  type: "BatchNorm"
  bottom: "Convolution601"
  top: "Convolution601"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale601"
  type: "Scale"
  bottom: "Convolution601"
  top: "Convolution601"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise300"
  type: "Eltwise"
  bottom: "Eltwise299"
  bottom: "Convolution601"
  top: "Eltwise300"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU601"
  type: "ReLU"
  bottom: "Eltwise300"
  top: "Eltwise300"
}
layer {
  name: "Convolution602"
  type: "Convolution"
  bottom: "Eltwise300"
  top: "Convolution602"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm602"
  type: "BatchNorm"
  bottom: "Convolution602"
  top: "Convolution602"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale602"
  type: "Scale"
  bottom: "Convolution602"
  top: "Convolution602"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU602"
  type: "ReLU"
  bottom: "Convolution602"
  top: "Convolution602"
}
layer {
  name: "Convolution603"
  type: "Convolution"
  bottom: "Convolution602"
  top: "Convolution603"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm603"
  type: "BatchNorm"
  bottom: "Convolution603"
  top: "Convolution603"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale603"
  type: "Scale"
  bottom: "Convolution603"
  top: "Convolution603"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise301"
  type: "Eltwise"
  bottom: "Eltwise300"
  bottom: "Convolution603"
  top: "Eltwise301"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU603"
  type: "ReLU"
  bottom: "Eltwise301"
  top: "Eltwise301"
}
layer {
  name: "Convolution604"
  type: "Convolution"
  bottom: "Eltwise301"
  top: "Convolution604"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm604"
  type: "BatchNorm"
  bottom: "Convolution604"
  top: "Convolution604"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale604"
  type: "Scale"
  bottom: "Convolution604"
  top: "Convolution604"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU604"
  type: "ReLU"
  bottom: "Convolution604"
  top: "Convolution604"
}
layer {
  name: "Convolution605"
  type: "Convolution"
  bottom: "Convolution604"
  top: "Convolution605"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm605"
  type: "BatchNorm"
  bottom: "Convolution605"
  top: "Convolution605"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale605"
  type: "Scale"
  bottom: "Convolution605"
  top: "Convolution605"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise302"
  type: "Eltwise"
  bottom: "Eltwise301"
  bottom: "Convolution605"
  top: "Eltwise302"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU605"
  type: "ReLU"
  bottom: "Eltwise302"
  top: "Eltwise302"
}
layer {
  name: "Convolution606"
  type: "Convolution"
  bottom: "Eltwise302"
  top: "Convolution606"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm606"
  type: "BatchNorm"
  bottom: "Convolution606"
  top: "Convolution606"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale606"
  type: "Scale"
  bottom: "Convolution606"
  top: "Convolution606"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU606"
  type: "ReLU"
  bottom: "Convolution606"
  top: "Convolution606"
}
layer {
  name: "Convolution607"
  type: "Convolution"
  bottom: "Convolution606"
  top: "Convolution607"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm607"
  type: "BatchNorm"
  bottom: "Convolution607"
  top: "Convolution607"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale607"
  type: "Scale"
  bottom: "Convolution607"
  top: "Convolution607"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise303"
  type: "Eltwise"
  bottom: "Eltwise302"
  bottom: "Convolution607"
  top: "Eltwise303"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU607"
  type: "ReLU"
  bottom: "Eltwise303"
  top: "Eltwise303"
}
layer {
  name: "Convolution608"
  type: "Convolution"
  bottom: "Eltwise303"
  top: "Convolution608"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm608"
  type: "BatchNorm"
  bottom: "Convolution608"
  top: "Convolution608"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale608"
  type: "Scale"
  bottom: "Convolution608"
  top: "Convolution608"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU608"
  type: "ReLU"
  bottom: "Convolution608"
  top: "Convolution608"
}
layer {
  name: "Convolution609"
  type: "Convolution"
  bottom: "Convolution608"
  top: "Convolution609"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm609"
  type: "BatchNorm"
  bottom: "Convolution609"
  top: "Convolution609"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale609"
  type: "Scale"
  bottom: "Convolution609"
  top: "Convolution609"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise304"
  type: "Eltwise"
  bottom: "Eltwise303"
  bottom: "Convolution609"
  top: "Eltwise304"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU609"
  type: "ReLU"
  bottom: "Eltwise304"
  top: "Eltwise304"
}
layer {
  name: "Convolution610"
  type: "Convolution"
  bottom: "Eltwise304"
  top: "Convolution610"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm610"
  type: "BatchNorm"
  bottom: "Convolution610"
  top: "Convolution610"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale610"
  type: "Scale"
  bottom: "Convolution610"
  top: "Convolution610"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU610"
  type: "ReLU"
  bottom: "Convolution610"
  top: "Convolution610"
}
layer {
  name: "Convolution611"
  type: "Convolution"
  bottom: "Convolution610"
  top: "Convolution611"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm611"
  type: "BatchNorm"
  bottom: "Convolution611"
  top: "Convolution611"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale611"
  type: "Scale"
  bottom: "Convolution611"
  top: "Convolution611"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise305"
  type: "Eltwise"
  bottom: "Eltwise304"
  bottom: "Convolution611"
  top: "Eltwise305"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU611"
  type: "ReLU"
  bottom: "Eltwise305"
  top: "Eltwise305"
}
layer {
  name: "Convolution612"
  type: "Convolution"
  bottom: "Eltwise305"
  top: "Convolution612"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm612"
  type: "BatchNorm"
  bottom: "Convolution612"
  top: "Convolution612"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale612"
  type: "Scale"
  bottom: "Convolution612"
  top: "Convolution612"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU612"
  type: "ReLU"
  bottom: "Convolution612"
  top: "Convolution612"
}
layer {
  name: "Convolution613"
  type: "Convolution"
  bottom: "Convolution612"
  top: "Convolution613"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm613"
  type: "BatchNorm"
  bottom: "Convolution613"
  top: "Convolution613"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale613"
  type: "Scale"
  bottom: "Convolution613"
  top: "Convolution613"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise306"
  type: "Eltwise"
  bottom: "Eltwise305"
  bottom: "Convolution613"
  top: "Eltwise306"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU613"
  type: "ReLU"
  bottom: "Eltwise306"
  top: "Eltwise306"
}
layer {
  name: "Convolution614"
  type: "Convolution"
  bottom: "Eltwise306"
  top: "Convolution614"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm614"
  type: "BatchNorm"
  bottom: "Convolution614"
  top: "Convolution614"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale614"
  type: "Scale"
  bottom: "Convolution614"
  top: "Convolution614"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU614"
  type: "ReLU"
  bottom: "Convolution614"
  top: "Convolution614"
}
layer {
  name: "Convolution615"
  type: "Convolution"
  bottom: "Convolution614"
  top: "Convolution615"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm615"
  type: "BatchNorm"
  bottom: "Convolution615"
  top: "Convolution615"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale615"
  type: "Scale"
  bottom: "Convolution615"
  top: "Convolution615"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise307"
  type: "Eltwise"
  bottom: "Eltwise306"
  bottom: "Convolution615"
  top: "Eltwise307"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU615"
  type: "ReLU"
  bottom: "Eltwise307"
  top: "Eltwise307"
}
layer {
  name: "Convolution616"
  type: "Convolution"
  bottom: "Eltwise307"
  top: "Convolution616"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm616"
  type: "BatchNorm"
  bottom: "Convolution616"
  top: "Convolution616"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale616"
  type: "Scale"
  bottom: "Convolution616"
  top: "Convolution616"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU616"
  type: "ReLU"
  bottom: "Convolution616"
  top: "Convolution616"
}
layer {
  name: "Convolution617"
  type: "Convolution"
  bottom: "Convolution616"
  top: "Convolution617"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm617"
  type: "BatchNorm"
  bottom: "Convolution617"
  top: "Convolution617"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale617"
  type: "Scale"
  bottom: "Convolution617"
  top: "Convolution617"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise308"
  type: "Eltwise"
  bottom: "Eltwise307"
  bottom: "Convolution617"
  top: "Eltwise308"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU617"
  type: "ReLU"
  bottom: "Eltwise308"
  top: "Eltwise308"
}
layer {
  name: "Convolution618"
  type: "Convolution"
  bottom: "Eltwise308"
  top: "Convolution618"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm618"
  type: "BatchNorm"
  bottom: "Convolution618"
  top: "Convolution618"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale618"
  type: "Scale"
  bottom: "Convolution618"
  top: "Convolution618"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU618"
  type: "ReLU"
  bottom: "Convolution618"
  top: "Convolution618"
}
layer {
  name: "Convolution619"
  type: "Convolution"
  bottom: "Convolution618"
  top: "Convolution619"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm619"
  type: "BatchNorm"
  bottom: "Convolution619"
  top: "Convolution619"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale619"
  type: "Scale"
  bottom: "Convolution619"
  top: "Convolution619"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise309"
  type: "Eltwise"
  bottom: "Eltwise308"
  bottom: "Convolution619"
  top: "Eltwise309"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU619"
  type: "ReLU"
  bottom: "Eltwise309"
  top: "Eltwise309"
}
layer {
  name: "Convolution620"
  type: "Convolution"
  bottom: "Eltwise309"
  top: "Convolution620"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm620"
  type: "BatchNorm"
  bottom: "Convolution620"
  top: "Convolution620"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale620"
  type: "Scale"
  bottom: "Convolution620"
  top: "Convolution620"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU620"
  type: "ReLU"
  bottom: "Convolution620"
  top: "Convolution620"
}
layer {
  name: "Convolution621"
  type: "Convolution"
  bottom: "Convolution620"
  top: "Convolution621"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm621"
  type: "BatchNorm"
  bottom: "Convolution621"
  top: "Convolution621"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale621"
  type: "Scale"
  bottom: "Convolution621"
  top: "Convolution621"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise310"
  type: "Eltwise"
  bottom: "Eltwise309"
  bottom: "Convolution621"
  top: "Eltwise310"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU621"
  type: "ReLU"
  bottom: "Eltwise310"
  top: "Eltwise310"
}
layer {
  name: "Convolution622"
  type: "Convolution"
  bottom: "Eltwise310"
  top: "Convolution622"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm622"
  type: "BatchNorm"
  bottom: "Convolution622"
  top: "Convolution622"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale622"
  type: "Scale"
  bottom: "Convolution622"
  top: "Convolution622"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU622"
  type: "ReLU"
  bottom: "Convolution622"
  top: "Convolution622"
}
layer {
  name: "Convolution623"
  type: "Convolution"
  bottom: "Convolution622"
  top: "Convolution623"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm623"
  type: "BatchNorm"
  bottom: "Convolution623"
  top: "Convolution623"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale623"
  type: "Scale"
  bottom: "Convolution623"
  top: "Convolution623"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise311"
  type: "Eltwise"
  bottom: "Eltwise310"
  bottom: "Convolution623"
  top: "Eltwise311"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU623"
  type: "ReLU"
  bottom: "Eltwise311"
  top: "Eltwise311"
}
layer {
  name: "Convolution624"
  type: "Convolution"
  bottom: "Eltwise311"
  top: "Convolution624"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm624"
  type: "BatchNorm"
  bottom: "Convolution624"
  top: "Convolution624"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale624"
  type: "Scale"
  bottom: "Convolution624"
  top: "Convolution624"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU624"
  type: "ReLU"
  bottom: "Convolution624"
  top: "Convolution624"
}
layer {
  name: "Convolution625"
  type: "Convolution"
  bottom: "Convolution624"
  top: "Convolution625"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm625"
  type: "BatchNorm"
  bottom: "Convolution625"
  top: "Convolution625"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale625"
  type: "Scale"
  bottom: "Convolution625"
  top: "Convolution625"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise312"
  type: "Eltwise"
  bottom: "Eltwise311"
  bottom: "Convolution625"
  top: "Eltwise312"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU625"
  type: "ReLU"
  bottom: "Eltwise312"
  top: "Eltwise312"
}
layer {
  name: "Convolution626"
  type: "Convolution"
  bottom: "Eltwise312"
  top: "Convolution626"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm626"
  type: "BatchNorm"
  bottom: "Convolution626"
  top: "Convolution626"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale626"
  type: "Scale"
  bottom: "Convolution626"
  top: "Convolution626"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU626"
  type: "ReLU"
  bottom: "Convolution626"
  top: "Convolution626"
}
layer {
  name: "Convolution627"
  type: "Convolution"
  bottom: "Convolution626"
  top: "Convolution627"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm627"
  type: "BatchNorm"
  bottom: "Convolution627"
  top: "Convolution627"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale627"
  type: "Scale"
  bottom: "Convolution627"
  top: "Convolution627"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise313"
  type: "Eltwise"
  bottom: "Eltwise312"
  bottom: "Convolution627"
  top: "Eltwise313"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU627"
  type: "ReLU"
  bottom: "Eltwise313"
  top: "Eltwise313"
}
layer {
  name: "Convolution628"
  type: "Convolution"
  bottom: "Eltwise313"
  top: "Convolution628"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm628"
  type: "BatchNorm"
  bottom: "Convolution628"
  top: "Convolution628"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale628"
  type: "Scale"
  bottom: "Convolution628"
  top: "Convolution628"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU628"
  type: "ReLU"
  bottom: "Convolution628"
  top: "Convolution628"
}
layer {
  name: "Convolution629"
  type: "Convolution"
  bottom: "Convolution628"
  top: "Convolution629"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm629"
  type: "BatchNorm"
  bottom: "Convolution629"
  top: "Convolution629"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale629"
  type: "Scale"
  bottom: "Convolution629"
  top: "Convolution629"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise314"
  type: "Eltwise"
  bottom: "Eltwise313"
  bottom: "Convolution629"
  top: "Eltwise314"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU629"
  type: "ReLU"
  bottom: "Eltwise314"
  top: "Eltwise314"
}
layer {
  name: "Convolution630"
  type: "Convolution"
  bottom: "Eltwise314"
  top: "Convolution630"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm630"
  type: "BatchNorm"
  bottom: "Convolution630"
  top: "Convolution630"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale630"
  type: "Scale"
  bottom: "Convolution630"
  top: "Convolution630"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU630"
  type: "ReLU"
  bottom: "Convolution630"
  top: "Convolution630"
}
layer {
  name: "Convolution631"
  type: "Convolution"
  bottom: "Convolution630"
  top: "Convolution631"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm631"
  type: "BatchNorm"
  bottom: "Convolution631"
  top: "Convolution631"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale631"
  type: "Scale"
  bottom: "Convolution631"
  top: "Convolution631"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise315"
  type: "Eltwise"
  bottom: "Eltwise314"
  bottom: "Convolution631"
  top: "Eltwise315"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU631"
  type: "ReLU"
  bottom: "Eltwise315"
  top: "Eltwise315"
}
layer {
  name: "Convolution632"
  type: "Convolution"
  bottom: "Eltwise315"
  top: "Convolution632"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm632"
  type: "BatchNorm"
  bottom: "Convolution632"
  top: "Convolution632"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale632"
  type: "Scale"
  bottom: "Convolution632"
  top: "Convolution632"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU632"
  type: "ReLU"
  bottom: "Convolution632"
  top: "Convolution632"
}
layer {
  name: "Convolution633"
  type: "Convolution"
  bottom: "Convolution632"
  top: "Convolution633"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm633"
  type: "BatchNorm"
  bottom: "Convolution633"
  top: "Convolution633"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale633"
  type: "Scale"
  bottom: "Convolution633"
  top: "Convolution633"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise316"
  type: "Eltwise"
  bottom: "Eltwise315"
  bottom: "Convolution633"
  top: "Eltwise316"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU633"
  type: "ReLU"
  bottom: "Eltwise316"
  top: "Eltwise316"
}
layer {
  name: "Convolution634"
  type: "Convolution"
  bottom: "Eltwise316"
  top: "Convolution634"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm634"
  type: "BatchNorm"
  bottom: "Convolution634"
  top: "Convolution634"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale634"
  type: "Scale"
  bottom: "Convolution634"
  top: "Convolution634"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU634"
  type: "ReLU"
  bottom: "Convolution634"
  top: "Convolution634"
}
layer {
  name: "Convolution635"
  type: "Convolution"
  bottom: "Convolution634"
  top: "Convolution635"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm635"
  type: "BatchNorm"
  bottom: "Convolution635"
  top: "Convolution635"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale635"
  type: "Scale"
  bottom: "Convolution635"
  top: "Convolution635"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise317"
  type: "Eltwise"
  bottom: "Eltwise316"
  bottom: "Convolution635"
  top: "Eltwise317"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU635"
  type: "ReLU"
  bottom: "Eltwise317"
  top: "Eltwise317"
}
layer {
  name: "Convolution636"
  type: "Convolution"
  bottom: "Eltwise317"
  top: "Convolution636"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm636"
  type: "BatchNorm"
  bottom: "Convolution636"
  top: "Convolution636"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale636"
  type: "Scale"
  bottom: "Convolution636"
  top: "Convolution636"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU636"
  type: "ReLU"
  bottom: "Convolution636"
  top: "Convolution636"
}
layer {
  name: "Convolution637"
  type: "Convolution"
  bottom: "Convolution636"
  top: "Convolution637"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm637"
  type: "BatchNorm"
  bottom: "Convolution637"
  top: "Convolution637"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale637"
  type: "Scale"
  bottom: "Convolution637"
  top: "Convolution637"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise318"
  type: "Eltwise"
  bottom: "Eltwise317"
  bottom: "Convolution637"
  top: "Eltwise318"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU637"
  type: "ReLU"
  bottom: "Eltwise318"
  top: "Eltwise318"
}
layer {
  name: "Convolution638"
  type: "Convolution"
  bottom: "Eltwise318"
  top: "Convolution638"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm638"
  type: "BatchNorm"
  bottom: "Convolution638"
  top: "Convolution638"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale638"
  type: "Scale"
  bottom: "Convolution638"
  top: "Convolution638"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU638"
  type: "ReLU"
  bottom: "Convolution638"
  top: "Convolution638"
}
layer {
  name: "Convolution639"
  type: "Convolution"
  bottom: "Convolution638"
  top: "Convolution639"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm639"
  type: "BatchNorm"
  bottom: "Convolution639"
  top: "Convolution639"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale639"
  type: "Scale"
  bottom: "Convolution639"
  top: "Convolution639"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise319"
  type: "Eltwise"
  bottom: "Eltwise318"
  bottom: "Convolution639"
  top: "Eltwise319"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU639"
  type: "ReLU"
  bottom: "Eltwise319"
  top: "Eltwise319"
}
layer {
  name: "Convolution640"
  type: "Convolution"
  bottom: "Eltwise319"
  top: "Convolution640"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm640"
  type: "BatchNorm"
  bottom: "Convolution640"
  top: "Convolution640"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale640"
  type: "Scale"
  bottom: "Convolution640"
  top: "Convolution640"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU640"
  type: "ReLU"
  bottom: "Convolution640"
  top: "Convolution640"
}
layer {
  name: "Convolution641"
  type: "Convolution"
  bottom: "Convolution640"
  top: "Convolution641"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm641"
  type: "BatchNorm"
  bottom: "Convolution641"
  top: "Convolution641"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale641"
  type: "Scale"
  bottom: "Convolution641"
  top: "Convolution641"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise320"
  type: "Eltwise"
  bottom: "Eltwise319"
  bottom: "Convolution641"
  top: "Eltwise320"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU641"
  type: "ReLU"
  bottom: "Eltwise320"
  top: "Eltwise320"
}
layer {
  name: "Convolution642"
  type: "Convolution"
  bottom: "Eltwise320"
  top: "Convolution642"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm642"
  type: "BatchNorm"
  bottom: "Convolution642"
  top: "Convolution642"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale642"
  type: "Scale"
  bottom: "Convolution642"
  top: "Convolution642"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU642"
  type: "ReLU"
  bottom: "Convolution642"
  top: "Convolution642"
}
layer {
  name: "Convolution643"
  type: "Convolution"
  bottom: "Convolution642"
  top: "Convolution643"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm643"
  type: "BatchNorm"
  bottom: "Convolution643"
  top: "Convolution643"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale643"
  type: "Scale"
  bottom: "Convolution643"
  top: "Convolution643"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise321"
  type: "Eltwise"
  bottom: "Eltwise320"
  bottom: "Convolution643"
  top: "Eltwise321"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU643"
  type: "ReLU"
  bottom: "Eltwise321"
  top: "Eltwise321"
}
layer {
  name: "Convolution644"
  type: "Convolution"
  bottom: "Eltwise321"
  top: "Convolution644"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm644"
  type: "BatchNorm"
  bottom: "Convolution644"
  top: "Convolution644"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale644"
  type: "Scale"
  bottom: "Convolution644"
  top: "Convolution644"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU644"
  type: "ReLU"
  bottom: "Convolution644"
  top: "Convolution644"
}
layer {
  name: "Convolution645"
  type: "Convolution"
  bottom: "Convolution644"
  top: "Convolution645"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm645"
  type: "BatchNorm"
  bottom: "Convolution645"
  top: "Convolution645"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale645"
  type: "Scale"
  bottom: "Convolution645"
  top: "Convolution645"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise322"
  type: "Eltwise"
  bottom: "Eltwise321"
  bottom: "Convolution645"
  top: "Eltwise322"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU645"
  type: "ReLU"
  bottom: "Eltwise322"
  top: "Eltwise322"
}
layer {
  name: "Convolution646"
  type: "Convolution"
  bottom: "Eltwise322"
  top: "Convolution646"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm646"
  type: "BatchNorm"
  bottom: "Convolution646"
  top: "Convolution646"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale646"
  type: "Scale"
  bottom: "Convolution646"
  top: "Convolution646"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU646"
  type: "ReLU"
  bottom: "Convolution646"
  top: "Convolution646"
}
layer {
  name: "Convolution647"
  type: "Convolution"
  bottom: "Convolution646"
  top: "Convolution647"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm647"
  type: "BatchNorm"
  bottom: "Convolution647"
  top: "Convolution647"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale647"
  type: "Scale"
  bottom: "Convolution647"
  top: "Convolution647"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise323"
  type: "Eltwise"
  bottom: "Eltwise322"
  bottom: "Convolution647"
  top: "Eltwise323"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU647"
  type: "ReLU"
  bottom: "Eltwise323"
  top: "Eltwise323"
}
layer {
  name: "Convolution648"
  type: "Convolution"
  bottom: "Eltwise323"
  top: "Convolution648"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm648"
  type: "BatchNorm"
  bottom: "Convolution648"
  top: "Convolution648"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale648"
  type: "Scale"
  bottom: "Convolution648"
  top: "Convolution648"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU648"
  type: "ReLU"
  bottom: "Convolution648"
  top: "Convolution648"
}
layer {
  name: "Convolution649"
  type: "Convolution"
  bottom: "Convolution648"
  top: "Convolution649"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm649"
  type: "BatchNorm"
  bottom: "Convolution649"
  top: "Convolution649"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale649"
  type: "Scale"
  bottom: "Convolution649"
  top: "Convolution649"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise324"
  type: "Eltwise"
  bottom: "Eltwise323"
  bottom: "Convolution649"
  top: "Eltwise324"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU649"
  type: "ReLU"
  bottom: "Eltwise324"
  top: "Eltwise324"
}
layer {
  name: "Convolution650"
  type: "Convolution"
  bottom: "Eltwise324"
  top: "Convolution650"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm650"
  type: "BatchNorm"
  bottom: "Convolution650"
  top: "Convolution650"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale650"
  type: "Scale"
  bottom: "Convolution650"
  top: "Convolution650"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU650"
  type: "ReLU"
  bottom: "Convolution650"
  top: "Convolution650"
}
layer {
  name: "Convolution651"
  type: "Convolution"
  bottom: "Convolution650"
  top: "Convolution651"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm651"
  type: "BatchNorm"
  bottom: "Convolution651"
  top: "Convolution651"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale651"
  type: "Scale"
  bottom: "Convolution651"
  top: "Convolution651"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise325"
  type: "Eltwise"
  bottom: "Eltwise324"
  bottom: "Convolution651"
  top: "Eltwise325"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU651"
  type: "ReLU"
  bottom: "Eltwise325"
  top: "Eltwise325"
}
layer {
  name: "Convolution652"
  type: "Convolution"
  bottom: "Eltwise325"
  top: "Convolution652"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm652"
  type: "BatchNorm"
  bottom: "Convolution652"
  top: "Convolution652"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale652"
  type: "Scale"
  bottom: "Convolution652"
  top: "Convolution652"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU652"
  type: "ReLU"
  bottom: "Convolution652"
  top: "Convolution652"
}
layer {
  name: "Convolution653"
  type: "Convolution"
  bottom: "Convolution652"
  top: "Convolution653"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm653"
  type: "BatchNorm"
  bottom: "Convolution653"
  top: "Convolution653"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale653"
  type: "Scale"
  bottom: "Convolution653"
  top: "Convolution653"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise326"
  type: "Eltwise"
  bottom: "Eltwise325"
  bottom: "Convolution653"
  top: "Eltwise326"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU653"
  type: "ReLU"
  bottom: "Eltwise326"
  top: "Eltwise326"
}
layer {
  name: "Convolution654"
  type: "Convolution"
  bottom: "Eltwise326"
  top: "Convolution654"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm654"
  type: "BatchNorm"
  bottom: "Convolution654"
  top: "Convolution654"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale654"
  type: "Scale"
  bottom: "Convolution654"
  top: "Convolution654"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU654"
  type: "ReLU"
  bottom: "Convolution654"
  top: "Convolution654"
}
layer {
  name: "Convolution655"
  type: "Convolution"
  bottom: "Convolution654"
  top: "Convolution655"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm655"
  type: "BatchNorm"
  bottom: "Convolution655"
  top: "Convolution655"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale655"
  type: "Scale"
  bottom: "Convolution655"
  top: "Convolution655"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise327"
  type: "Eltwise"
  bottom: "Eltwise326"
  bottom: "Convolution655"
  top: "Eltwise327"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU655"
  type: "ReLU"
  bottom: "Eltwise327"
  top: "Eltwise327"
}
layer {
  name: "Convolution656"
  type: "Convolution"
  bottom: "Eltwise327"
  top: "Convolution656"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm656"
  type: "BatchNorm"
  bottom: "Convolution656"
  top: "Convolution656"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale656"
  type: "Scale"
  bottom: "Convolution656"
  top: "Convolution656"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU656"
  type: "ReLU"
  bottom: "Convolution656"
  top: "Convolution656"
}
layer {
  name: "Convolution657"
  type: "Convolution"
  bottom: "Convolution656"
  top: "Convolution657"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm657"
  type: "BatchNorm"
  bottom: "Convolution657"
  top: "Convolution657"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale657"
  type: "Scale"
  bottom: "Convolution657"
  top: "Convolution657"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise328"
  type: "Eltwise"
  bottom: "Eltwise327"
  bottom: "Convolution657"
  top: "Eltwise328"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU657"
  type: "ReLU"
  bottom: "Eltwise328"
  top: "Eltwise328"
}
layer {
  name: "Convolution658"
  type: "Convolution"
  bottom: "Eltwise328"
  top: "Convolution658"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm658"
  type: "BatchNorm"
  bottom: "Convolution658"
  top: "Convolution658"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale658"
  type: "Scale"
  bottom: "Convolution658"
  top: "Convolution658"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU658"
  type: "ReLU"
  bottom: "Convolution658"
  top: "Convolution658"
}
layer {
  name: "Convolution659"
  type: "Convolution"
  bottom: "Convolution658"
  top: "Convolution659"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm659"
  type: "BatchNorm"
  bottom: "Convolution659"
  top: "Convolution659"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale659"
  type: "Scale"
  bottom: "Convolution659"
  top: "Convolution659"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise329"
  type: "Eltwise"
  bottom: "Eltwise328"
  bottom: "Convolution659"
  top: "Eltwise329"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU659"
  type: "ReLU"
  bottom: "Eltwise329"
  top: "Eltwise329"
}
layer {
  name: "Convolution660"
  type: "Convolution"
  bottom: "Eltwise329"
  top: "Convolution660"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm660"
  type: "BatchNorm"
  bottom: "Convolution660"
  top: "Convolution660"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale660"
  type: "Scale"
  bottom: "Convolution660"
  top: "Convolution660"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU660"
  type: "ReLU"
  bottom: "Convolution660"
  top: "Convolution660"
}
layer {
  name: "Convolution661"
  type: "Convolution"
  bottom: "Convolution660"
  top: "Convolution661"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm661"
  type: "BatchNorm"
  bottom: "Convolution661"
  top: "Convolution661"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale661"
  type: "Scale"
  bottom: "Convolution661"
  top: "Convolution661"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise330"
  type: "Eltwise"
  bottom: "Eltwise329"
  bottom: "Convolution661"
  top: "Eltwise330"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU661"
  type: "ReLU"
  bottom: "Eltwise330"
  top: "Eltwise330"
}
layer {
  name: "Convolution662"
  type: "Convolution"
  bottom: "Eltwise330"
  top: "Convolution662"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm662"
  type: "BatchNorm"
  bottom: "Convolution662"
  top: "Convolution662"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale662"
  type: "Scale"
  bottom: "Convolution662"
  top: "Convolution662"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU662"
  type: "ReLU"
  bottom: "Convolution662"
  top: "Convolution662"
}
layer {
  name: "Convolution663"
  type: "Convolution"
  bottom: "Convolution662"
  top: "Convolution663"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm663"
  type: "BatchNorm"
  bottom: "Convolution663"
  top: "Convolution663"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale663"
  type: "Scale"
  bottom: "Convolution663"
  top: "Convolution663"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise331"
  type: "Eltwise"
  bottom: "Eltwise330"
  bottom: "Convolution663"
  top: "Eltwise331"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU663"
  type: "ReLU"
  bottom: "Eltwise331"
  top: "Eltwise331"
}
layer {
  name: "Convolution664"
  type: "Convolution"
  bottom: "Eltwise331"
  top: "Convolution664"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm664"
  type: "BatchNorm"
  bottom: "Convolution664"
  top: "Convolution664"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale664"
  type: "Scale"
  bottom: "Convolution664"
  top: "Convolution664"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU664"
  type: "ReLU"
  bottom: "Convolution664"
  top: "Convolution664"
}
layer {
  name: "Convolution665"
  type: "Convolution"
  bottom: "Convolution664"
  top: "Convolution665"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm665"
  type: "BatchNorm"
  bottom: "Convolution665"
  top: "Convolution665"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale665"
  type: "Scale"
  bottom: "Convolution665"
  top: "Convolution665"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise332"
  type: "Eltwise"
  bottom: "Eltwise331"
  bottom: "Convolution665"
  top: "Eltwise332"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU665"
  type: "ReLU"
  bottom: "Eltwise332"
  top: "Eltwise332"
}
layer {
  name: "Convolution666"
  type: "Convolution"
  bottom: "Eltwise332"
  top: "Convolution666"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm666"
  type: "BatchNorm"
  bottom: "Convolution666"
  top: "Convolution666"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale666"
  type: "Scale"
  bottom: "Convolution666"
  top: "Convolution666"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU666"
  type: "ReLU"
  bottom: "Convolution666"
  top: "Convolution666"
}
layer {
  name: "Convolution667"
  type: "Convolution"
  bottom: "Convolution666"
  top: "Convolution667"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm667"
  type: "BatchNorm"
  bottom: "Convolution667"
  top: "Convolution667"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale667"
  type: "Scale"
  bottom: "Convolution667"
  top: "Convolution667"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise333"
  type: "Eltwise"
  bottom: "Eltwise332"
  bottom: "Convolution667"
  top: "Eltwise333"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU667"
  type: "ReLU"
  bottom: "Eltwise333"
  top: "Eltwise333"
}
layer {
  name: "Convolution668"
  type: "Convolution"
  bottom: "Eltwise333"
  top: "Convolution668"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm668"
  type: "BatchNorm"
  bottom: "Convolution668"
  top: "Convolution668"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale668"
  type: "Scale"
  bottom: "Convolution668"
  top: "Convolution668"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU668"
  type: "ReLU"
  bottom: "Convolution668"
  top: "Convolution668"
}
layer {
  name: "Convolution669"
  type: "Convolution"
  bottom: "Convolution668"
  top: "Convolution669"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm669"
  type: "BatchNorm"
  bottom: "Convolution669"
  top: "Convolution669"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale669"
  type: "Scale"
  bottom: "Convolution669"
  top: "Convolution669"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise334"
  type: "Eltwise"
  bottom: "Eltwise333"
  bottom: "Convolution669"
  top: "Eltwise334"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU669"
  type: "ReLU"
  bottom: "Eltwise334"
  top: "Eltwise334"
}
layer {
  name: "Convolution670"
  type: "Convolution"
  bottom: "Eltwise334"
  top: "Convolution670"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm670"
  type: "BatchNorm"
  bottom: "Convolution670"
  top: "Convolution670"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale670"
  type: "Scale"
  bottom: "Convolution670"
  top: "Convolution670"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU670"
  type: "ReLU"
  bottom: "Convolution670"
  top: "Convolution670"
}
layer {
  name: "Convolution671"
  type: "Convolution"
  bottom: "Convolution670"
  top: "Convolution671"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm671"
  type: "BatchNorm"
  bottom: "Convolution671"
  top: "Convolution671"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale671"
  type: "Scale"
  bottom: "Convolution671"
  top: "Convolution671"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise335"
  type: "Eltwise"
  bottom: "Eltwise334"
  bottom: "Convolution671"
  top: "Eltwise335"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU671"
  type: "ReLU"
  bottom: "Eltwise335"
  top: "Eltwise335"
}
layer {
  name: "Convolution672"
  type: "Convolution"
  bottom: "Eltwise335"
  top: "Convolution672"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm672"
  type: "BatchNorm"
  bottom: "Convolution672"
  top: "Convolution672"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale672"
  type: "Scale"
  bottom: "Convolution672"
  top: "Convolution672"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU672"
  type: "ReLU"
  bottom: "Convolution672"
  top: "Convolution672"
}
layer {
  name: "Convolution673"
  type: "Convolution"
  bottom: "Convolution672"
  top: "Convolution673"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm673"
  type: "BatchNorm"
  bottom: "Convolution673"
  top: "Convolution673"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale673"
  type: "Scale"
  bottom: "Convolution673"
  top: "Convolution673"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise336"
  type: "Eltwise"
  bottom: "Eltwise335"
  bottom: "Convolution673"
  top: "Eltwise336"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU673"
  type: "ReLU"
  bottom: "Eltwise336"
  top: "Eltwise336"
}
layer {
  name: "Convolution674"
  type: "Convolution"
  bottom: "Eltwise336"
  top: "Convolution674"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm674"
  type: "BatchNorm"
  bottom: "Convolution674"
  top: "Convolution674"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale674"
  type: "Scale"
  bottom: "Convolution674"
  top: "Convolution674"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU674"
  type: "ReLU"
  bottom: "Convolution674"
  top: "Convolution674"
}
layer {
  name: "Convolution675"
  type: "Convolution"
  bottom: "Convolution674"
  top: "Convolution675"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm675"
  type: "BatchNorm"
  bottom: "Convolution675"
  top: "Convolution675"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale675"
  type: "Scale"
  bottom: "Convolution675"
  top: "Convolution675"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise337"
  type: "Eltwise"
  bottom: "Eltwise336"
  bottom: "Convolution675"
  top: "Eltwise337"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU675"
  type: "ReLU"
  bottom: "Eltwise337"
  top: "Eltwise337"
}
layer {
  name: "Convolution676"
  type: "Convolution"
  bottom: "Eltwise337"
  top: "Convolution676"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm676"
  type: "BatchNorm"
  bottom: "Convolution676"
  top: "Convolution676"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale676"
  type: "Scale"
  bottom: "Convolution676"
  top: "Convolution676"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU676"
  type: "ReLU"
  bottom: "Convolution676"
  top: "Convolution676"
}
layer {
  name: "Convolution677"
  type: "Convolution"
  bottom: "Convolution676"
  top: "Convolution677"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm677"
  type: "BatchNorm"
  bottom: "Convolution677"
  top: "Convolution677"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale677"
  type: "Scale"
  bottom: "Convolution677"
  top: "Convolution677"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise338"
  type: "Eltwise"
  bottom: "Eltwise337"
  bottom: "Convolution677"
  top: "Eltwise338"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU677"
  type: "ReLU"
  bottom: "Eltwise338"
  top: "Eltwise338"
}
layer {
  name: "Convolution678"
  type: "Convolution"
  bottom: "Eltwise338"
  top: "Convolution678"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm678"
  type: "BatchNorm"
  bottom: "Convolution678"
  top: "Convolution678"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale678"
  type: "Scale"
  bottom: "Convolution678"
  top: "Convolution678"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU678"
  type: "ReLU"
  bottom: "Convolution678"
  top: "Convolution678"
}
layer {
  name: "Convolution679"
  type: "Convolution"
  bottom: "Convolution678"
  top: "Convolution679"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm679"
  type: "BatchNorm"
  bottom: "Convolution679"
  top: "Convolution679"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale679"
  type: "Scale"
  bottom: "Convolution679"
  top: "Convolution679"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise339"
  type: "Eltwise"
  bottom: "Eltwise338"
  bottom: "Convolution679"
  top: "Eltwise339"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU679"
  type: "ReLU"
  bottom: "Eltwise339"
  top: "Eltwise339"
}
layer {
  name: "Convolution680"
  type: "Convolution"
  bottom: "Eltwise339"
  top: "Convolution680"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm680"
  type: "BatchNorm"
  bottom: "Convolution680"
  top: "Convolution680"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale680"
  type: "Scale"
  bottom: "Convolution680"
  top: "Convolution680"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU680"
  type: "ReLU"
  bottom: "Convolution680"
  top: "Convolution680"
}
layer {
  name: "Convolution681"
  type: "Convolution"
  bottom: "Convolution680"
  top: "Convolution681"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm681"
  type: "BatchNorm"
  bottom: "Convolution681"
  top: "Convolution681"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale681"
  type: "Scale"
  bottom: "Convolution681"
  top: "Convolution681"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise340"
  type: "Eltwise"
  bottom: "Eltwise339"
  bottom: "Convolution681"
  top: "Eltwise340"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU681"
  type: "ReLU"
  bottom: "Eltwise340"
  top: "Eltwise340"
}
layer {
  name: "Convolution682"
  type: "Convolution"
  bottom: "Eltwise340"
  top: "Convolution682"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm682"
  type: "BatchNorm"
  bottom: "Convolution682"
  top: "Convolution682"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale682"
  type: "Scale"
  bottom: "Convolution682"
  top: "Convolution682"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU682"
  type: "ReLU"
  bottom: "Convolution682"
  top: "Convolution682"
}
layer {
  name: "Convolution683"
  type: "Convolution"
  bottom: "Convolution682"
  top: "Convolution683"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm683"
  type: "BatchNorm"
  bottom: "Convolution683"
  top: "Convolution683"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale683"
  type: "Scale"
  bottom: "Convolution683"
  top: "Convolution683"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise341"
  type: "Eltwise"
  bottom: "Eltwise340"
  bottom: "Convolution683"
  top: "Eltwise341"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU683"
  type: "ReLU"
  bottom: "Eltwise341"
  top: "Eltwise341"
}
layer {
  name: "Convolution684"
  type: "Convolution"
  bottom: "Eltwise341"
  top: "Convolution684"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm684"
  type: "BatchNorm"
  bottom: "Convolution684"
  top: "Convolution684"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale684"
  type: "Scale"
  bottom: "Convolution684"
  top: "Convolution684"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU684"
  type: "ReLU"
  bottom: "Convolution684"
  top: "Convolution684"
}
layer {
  name: "Convolution685"
  type: "Convolution"
  bottom: "Convolution684"
  top: "Convolution685"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm685"
  type: "BatchNorm"
  bottom: "Convolution685"
  top: "Convolution685"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale685"
  type: "Scale"
  bottom: "Convolution685"
  top: "Convolution685"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise342"
  type: "Eltwise"
  bottom: "Eltwise341"
  bottom: "Convolution685"
  top: "Eltwise342"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU685"
  type: "ReLU"
  bottom: "Eltwise342"
  top: "Eltwise342"
}
layer {
  name: "Convolution686"
  type: "Convolution"
  bottom: "Eltwise342"
  top: "Convolution686"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm686"
  type: "BatchNorm"
  bottom: "Convolution686"
  top: "Convolution686"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale686"
  type: "Scale"
  bottom: "Convolution686"
  top: "Convolution686"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU686"
  type: "ReLU"
  bottom: "Convolution686"
  top: "Convolution686"
}
layer {
  name: "Convolution687"
  type: "Convolution"
  bottom: "Convolution686"
  top: "Convolution687"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm687"
  type: "BatchNorm"
  bottom: "Convolution687"
  top: "Convolution687"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale687"
  type: "Scale"
  bottom: "Convolution687"
  top: "Convolution687"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise343"
  type: "Eltwise"
  bottom: "Eltwise342"
  bottom: "Convolution687"
  top: "Eltwise343"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU687"
  type: "ReLU"
  bottom: "Eltwise343"
  top: "Eltwise343"
}
layer {
  name: "Convolution688"
  type: "Convolution"
  bottom: "Eltwise343"
  top: "Convolution688"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm688"
  type: "BatchNorm"
  bottom: "Convolution688"
  top: "Convolution688"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale688"
  type: "Scale"
  bottom: "Convolution688"
  top: "Convolution688"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU688"
  type: "ReLU"
  bottom: "Convolution688"
  top: "Convolution688"
}
layer {
  name: "Convolution689"
  type: "Convolution"
  bottom: "Convolution688"
  top: "Convolution689"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm689"
  type: "BatchNorm"
  bottom: "Convolution689"
  top: "Convolution689"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale689"
  type: "Scale"
  bottom: "Convolution689"
  top: "Convolution689"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise344"
  type: "Eltwise"
  bottom: "Eltwise343"
  bottom: "Convolution689"
  top: "Eltwise344"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU689"
  type: "ReLU"
  bottom: "Eltwise344"
  top: "Eltwise344"
}
layer {
  name: "Convolution690"
  type: "Convolution"
  bottom: "Eltwise344"
  top: "Convolution690"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm690"
  type: "BatchNorm"
  bottom: "Convolution690"
  top: "Convolution690"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale690"
  type: "Scale"
  bottom: "Convolution690"
  top: "Convolution690"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU690"
  type: "ReLU"
  bottom: "Convolution690"
  top: "Convolution690"
}
layer {
  name: "Convolution691"
  type: "Convolution"
  bottom: "Convolution690"
  top: "Convolution691"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm691"
  type: "BatchNorm"
  bottom: "Convolution691"
  top: "Convolution691"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale691"
  type: "Scale"
  bottom: "Convolution691"
  top: "Convolution691"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise345"
  type: "Eltwise"
  bottom: "Eltwise344"
  bottom: "Convolution691"
  top: "Eltwise345"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU691"
  type: "ReLU"
  bottom: "Eltwise345"
  top: "Eltwise345"
}
layer {
  name: "Convolution692"
  type: "Convolution"
  bottom: "Eltwise345"
  top: "Convolution692"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm692"
  type: "BatchNorm"
  bottom: "Convolution692"
  top: "Convolution692"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale692"
  type: "Scale"
  bottom: "Convolution692"
  top: "Convolution692"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU692"
  type: "ReLU"
  bottom: "Convolution692"
  top: "Convolution692"
}
layer {
  name: "Convolution693"
  type: "Convolution"
  bottom: "Convolution692"
  top: "Convolution693"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm693"
  type: "BatchNorm"
  bottom: "Convolution693"
  top: "Convolution693"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale693"
  type: "Scale"
  bottom: "Convolution693"
  top: "Convolution693"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise346"
  type: "Eltwise"
  bottom: "Eltwise345"
  bottom: "Convolution693"
  top: "Eltwise346"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU693"
  type: "ReLU"
  bottom: "Eltwise346"
  top: "Eltwise346"
}
layer {
  name: "Convolution694"
  type: "Convolution"
  bottom: "Eltwise346"
  top: "Convolution694"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm694"
  type: "BatchNorm"
  bottom: "Convolution694"
  top: "Convolution694"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale694"
  type: "Scale"
  bottom: "Convolution694"
  top: "Convolution694"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU694"
  type: "ReLU"
  bottom: "Convolution694"
  top: "Convolution694"
}
layer {
  name: "Convolution695"
  type: "Convolution"
  bottom: "Convolution694"
  top: "Convolution695"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm695"
  type: "BatchNorm"
  bottom: "Convolution695"
  top: "Convolution695"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale695"
  type: "Scale"
  bottom: "Convolution695"
  top: "Convolution695"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise347"
  type: "Eltwise"
  bottom: "Eltwise346"
  bottom: "Convolution695"
  top: "Eltwise347"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU695"
  type: "ReLU"
  bottom: "Eltwise347"
  top: "Eltwise347"
}
layer {
  name: "Convolution696"
  type: "Convolution"
  bottom: "Eltwise347"
  top: "Convolution696"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm696"
  type: "BatchNorm"
  bottom: "Convolution696"
  top: "Convolution696"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale696"
  type: "Scale"
  bottom: "Convolution696"
  top: "Convolution696"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU696"
  type: "ReLU"
  bottom: "Convolution696"
  top: "Convolution696"
}
layer {
  name: "Convolution697"
  type: "Convolution"
  bottom: "Convolution696"
  top: "Convolution697"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm697"
  type: "BatchNorm"
  bottom: "Convolution697"
  top: "Convolution697"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale697"
  type: "Scale"
  bottom: "Convolution697"
  top: "Convolution697"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise348"
  type: "Eltwise"
  bottom: "Eltwise347"
  bottom: "Convolution697"
  top: "Eltwise348"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU697"
  type: "ReLU"
  bottom: "Eltwise348"
  top: "Eltwise348"
}
layer {
  name: "Convolution698"
  type: "Convolution"
  bottom: "Eltwise348"
  top: "Convolution698"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm698"
  type: "BatchNorm"
  bottom: "Convolution698"
  top: "Convolution698"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale698"
  type: "Scale"
  bottom: "Convolution698"
  top: "Convolution698"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU698"
  type: "ReLU"
  bottom: "Convolution698"
  top: "Convolution698"
}
layer {
  name: "Convolution699"
  type: "Convolution"
  bottom: "Convolution698"
  top: "Convolution699"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm699"
  type: "BatchNorm"
  bottom: "Convolution699"
  top: "Convolution699"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale699"
  type: "Scale"
  bottom: "Convolution699"
  top: "Convolution699"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise349"
  type: "Eltwise"
  bottom: "Eltwise348"
  bottom: "Convolution699"
  top: "Eltwise349"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU699"
  type: "ReLU"
  bottom: "Eltwise349"
  top: "Eltwise349"
}
layer {
  name: "Convolution700"
  type: "Convolution"
  bottom: "Eltwise349"
  top: "Convolution700"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm700"
  type: "BatchNorm"
  bottom: "Convolution700"
  top: "Convolution700"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale700"
  type: "Scale"
  bottom: "Convolution700"
  top: "Convolution700"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU700"
  type: "ReLU"
  bottom: "Convolution700"
  top: "Convolution700"
}
layer {
  name: "Convolution701"
  type: "Convolution"
  bottom: "Convolution700"
  top: "Convolution701"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm701"
  type: "BatchNorm"
  bottom: "Convolution701"
  top: "Convolution701"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale701"
  type: "Scale"
  bottom: "Convolution701"
  top: "Convolution701"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise350"
  type: "Eltwise"
  bottom: "Eltwise349"
  bottom: "Convolution701"
  top: "Eltwise350"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU701"
  type: "ReLU"
  bottom: "Eltwise350"
  top: "Eltwise350"
}
layer {
  name: "Convolution702"
  type: "Convolution"
  bottom: "Eltwise350"
  top: "Convolution702"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm702"
  type: "BatchNorm"
  bottom: "Convolution702"
  top: "Convolution702"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale702"
  type: "Scale"
  bottom: "Convolution702"
  top: "Convolution702"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU702"
  type: "ReLU"
  bottom: "Convolution702"
  top: "Convolution702"
}
layer {
  name: "Convolution703"
  type: "Convolution"
  bottom: "Convolution702"
  top: "Convolution703"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm703"
  type: "BatchNorm"
  bottom: "Convolution703"
  top: "Convolution703"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale703"
  type: "Scale"
  bottom: "Convolution703"
  top: "Convolution703"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise351"
  type: "Eltwise"
  bottom: "Eltwise350"
  bottom: "Convolution703"
  top: "Eltwise351"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU703"
  type: "ReLU"
  bottom: "Eltwise351"
  top: "Eltwise351"
}
layer {
  name: "Convolution704"
  type: "Convolution"
  bottom: "Eltwise351"
  top: "Convolution704"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm704"
  type: "BatchNorm"
  bottom: "Convolution704"
  top: "Convolution704"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale704"
  type: "Scale"
  bottom: "Convolution704"
  top: "Convolution704"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU704"
  type: "ReLU"
  bottom: "Convolution704"
  top: "Convolution704"
}
layer {
  name: "Convolution705"
  type: "Convolution"
  bottom: "Convolution704"
  top: "Convolution705"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm705"
  type: "BatchNorm"
  bottom: "Convolution705"
  top: "Convolution705"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale705"
  type: "Scale"
  bottom: "Convolution705"
  top: "Convolution705"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise352"
  type: "Eltwise"
  bottom: "Eltwise351"
  bottom: "Convolution705"
  top: "Eltwise352"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU705"
  type: "ReLU"
  bottom: "Eltwise352"
  top: "Eltwise352"
}
layer {
  name: "Convolution706"
  type: "Convolution"
  bottom: "Eltwise352"
  top: "Convolution706"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm706"
  type: "BatchNorm"
  bottom: "Convolution706"
  top: "Convolution706"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale706"
  type: "Scale"
  bottom: "Convolution706"
  top: "Convolution706"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU706"
  type: "ReLU"
  bottom: "Convolution706"
  top: "Convolution706"
}
layer {
  name: "Convolution707"
  type: "Convolution"
  bottom: "Convolution706"
  top: "Convolution707"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm707"
  type: "BatchNorm"
  bottom: "Convolution707"
  top: "Convolution707"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale707"
  type: "Scale"
  bottom: "Convolution707"
  top: "Convolution707"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise353"
  type: "Eltwise"
  bottom: "Eltwise352"
  bottom: "Convolution707"
  top: "Eltwise353"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU707"
  type: "ReLU"
  bottom: "Eltwise353"
  top: "Eltwise353"
}
layer {
  name: "Convolution708"
  type: "Convolution"
  bottom: "Eltwise353"
  top: "Convolution708"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm708"
  type: "BatchNorm"
  bottom: "Convolution708"
  top: "Convolution708"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale708"
  type: "Scale"
  bottom: "Convolution708"
  top: "Convolution708"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU708"
  type: "ReLU"
  bottom: "Convolution708"
  top: "Convolution708"
}
layer {
  name: "Convolution709"
  type: "Convolution"
  bottom: "Convolution708"
  top: "Convolution709"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm709"
  type: "BatchNorm"
  bottom: "Convolution709"
  top: "Convolution709"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale709"
  type: "Scale"
  bottom: "Convolution709"
  top: "Convolution709"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise354"
  type: "Eltwise"
  bottom: "Eltwise353"
  bottom: "Convolution709"
  top: "Eltwise354"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU709"
  type: "ReLU"
  bottom: "Eltwise354"
  top: "Eltwise354"
}
layer {
  name: "Convolution710"
  type: "Convolution"
  bottom: "Eltwise354"
  top: "Convolution710"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm710"
  type: "BatchNorm"
  bottom: "Convolution710"
  top: "Convolution710"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale710"
  type: "Scale"
  bottom: "Convolution710"
  top: "Convolution710"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU710"
  type: "ReLU"
  bottom: "Convolution710"
  top: "Convolution710"
}
layer {
  name: "Convolution711"
  type: "Convolution"
  bottom: "Convolution710"
  top: "Convolution711"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm711"
  type: "BatchNorm"
  bottom: "Convolution711"
  top: "Convolution711"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale711"
  type: "Scale"
  bottom: "Convolution711"
  top: "Convolution711"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise355"
  type: "Eltwise"
  bottom: "Eltwise354"
  bottom: "Convolution711"
  top: "Eltwise355"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU711"
  type: "ReLU"
  bottom: "Eltwise355"
  top: "Eltwise355"
}
layer {
  name: "Convolution712"
  type: "Convolution"
  bottom: "Eltwise355"
  top: "Convolution712"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm712"
  type: "BatchNorm"
  bottom: "Convolution712"
  top: "Convolution712"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale712"
  type: "Scale"
  bottom: "Convolution712"
  top: "Convolution712"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU712"
  type: "ReLU"
  bottom: "Convolution712"
  top: "Convolution712"
}
layer {
  name: "Convolution713"
  type: "Convolution"
  bottom: "Convolution712"
  top: "Convolution713"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm713"
  type: "BatchNorm"
  bottom: "Convolution713"
  top: "Convolution713"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale713"
  type: "Scale"
  bottom: "Convolution713"
  top: "Convolution713"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise356"
  type: "Eltwise"
  bottom: "Eltwise355"
  bottom: "Convolution713"
  top: "Eltwise356"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU713"
  type: "ReLU"
  bottom: "Eltwise356"
  top: "Eltwise356"
}
layer {
  name: "Convolution714"
  type: "Convolution"
  bottom: "Eltwise356"
  top: "Convolution714"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm714"
  type: "BatchNorm"
  bottom: "Convolution714"
  top: "Convolution714"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale714"
  type: "Scale"
  bottom: "Convolution714"
  top: "Convolution714"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU714"
  type: "ReLU"
  bottom: "Convolution714"
  top: "Convolution714"
}
layer {
  name: "Convolution715"
  type: "Convolution"
  bottom: "Convolution714"
  top: "Convolution715"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm715"
  type: "BatchNorm"
  bottom: "Convolution715"
  top: "Convolution715"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale715"
  type: "Scale"
  bottom: "Convolution715"
  top: "Convolution715"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise357"
  type: "Eltwise"
  bottom: "Eltwise356"
  bottom: "Convolution715"
  top: "Eltwise357"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU715"
  type: "ReLU"
  bottom: "Eltwise357"
  top: "Eltwise357"
}
layer {
  name: "Convolution716"
  type: "Convolution"
  bottom: "Eltwise357"
  top: "Convolution716"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm716"
  type: "BatchNorm"
  bottom: "Convolution716"
  top: "Convolution716"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale716"
  type: "Scale"
  bottom: "Convolution716"
  top: "Convolution716"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU716"
  type: "ReLU"
  bottom: "Convolution716"
  top: "Convolution716"
}
layer {
  name: "Convolution717"
  type: "Convolution"
  bottom: "Convolution716"
  top: "Convolution717"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm717"
  type: "BatchNorm"
  bottom: "Convolution717"
  top: "Convolution717"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale717"
  type: "Scale"
  bottom: "Convolution717"
  top: "Convolution717"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise358"
  type: "Eltwise"
  bottom: "Eltwise357"
  bottom: "Convolution717"
  top: "Eltwise358"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU717"
  type: "ReLU"
  bottom: "Eltwise358"
  top: "Eltwise358"
}
layer {
  name: "Convolution718"
  type: "Convolution"
  bottom: "Eltwise358"
  top: "Convolution718"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm718"
  type: "BatchNorm"
  bottom: "Convolution718"
  top: "Convolution718"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale718"
  type: "Scale"
  bottom: "Convolution718"
  top: "Convolution718"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU718"
  type: "ReLU"
  bottom: "Convolution718"
  top: "Convolution718"
}
layer {
  name: "Convolution719"
  type: "Convolution"
  bottom: "Convolution718"
  top: "Convolution719"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm719"
  type: "BatchNorm"
  bottom: "Convolution719"
  top: "Convolution719"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale719"
  type: "Scale"
  bottom: "Convolution719"
  top: "Convolution719"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise359"
  type: "Eltwise"
  bottom: "Eltwise358"
  bottom: "Convolution719"
  top: "Eltwise359"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU719"
  type: "ReLU"
  bottom: "Eltwise359"
  top: "Eltwise359"
}
layer {
  name: "Convolution720"
  type: "Convolution"
  bottom: "Eltwise359"
  top: "Convolution720"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm720"
  type: "BatchNorm"
  bottom: "Convolution720"
  top: "Convolution720"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale720"
  type: "Scale"
  bottom: "Convolution720"
  top: "Convolution720"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU720"
  type: "ReLU"
  bottom: "Convolution720"
  top: "Convolution720"
}
layer {
  name: "Convolution721"
  type: "Convolution"
  bottom: "Convolution720"
  top: "Convolution721"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm721"
  type: "BatchNorm"
  bottom: "Convolution721"
  top: "Convolution721"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale721"
  type: "Scale"
  bottom: "Convolution721"
  top: "Convolution721"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise360"
  type: "Eltwise"
  bottom: "Eltwise359"
  bottom: "Convolution721"
  top: "Eltwise360"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU721"
  type: "ReLU"
  bottom: "Eltwise360"
  top: "Eltwise360"
}
layer {
  name: "Pooling2"
  type: "Pooling"
  bottom: "Eltwise360"
  top: "Pooling2"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Input2"
  type: "Input"
  top: "Input2"
  input_param {
    shape {
      dim: 2
      dim: 32
      dim: 8
      dim: 8
    }
  }
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "Pooling2"
  bottom: "Input2"
  top: "Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution722"
  type: "Convolution"
  bottom: "Eltwise360"
  top: "Convolution722"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm722"
  type: "BatchNorm"
  bottom: "Convolution722"
  top: "Convolution722"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale722"
  type: "Scale"
  bottom: "Convolution722"
  top: "Convolution722"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU722"
  type: "ReLU"
  bottom: "Convolution722"
  top: "Convolution722"
}
layer {
  name: "Convolution723"
  type: "Convolution"
  bottom: "Convolution722"
  top: "Convolution723"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm723"
  type: "BatchNorm"
  bottom: "Convolution723"
  top: "Convolution723"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale723"
  type: "Scale"
  bottom: "Convolution723"
  top: "Convolution723"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise361"
  type: "Eltwise"
  bottom: "Concat2"
  bottom: "Convolution723"
  top: "Eltwise361"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU723"
  type: "ReLU"
  bottom: "Eltwise361"
  top: "Eltwise361"
}
layer {
  name: "Convolution724"
  type: "Convolution"
  bottom: "Eltwise361"
  top: "Convolution724"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm724"
  type: "BatchNorm"
  bottom: "Convolution724"
  top: "Convolution724"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale724"
  type: "Scale"
  bottom: "Convolution724"
  top: "Convolution724"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU724"
  type: "ReLU"
  bottom: "Convolution724"
  top: "Convolution724"
}
layer {
  name: "Convolution725"
  type: "Convolution"
  bottom: "Convolution724"
  top: "Convolution725"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm725"
  type: "BatchNorm"
  bottom: "Convolution725"
  top: "Convolution725"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale725"
  type: "Scale"
  bottom: "Convolution725"
  top: "Convolution725"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise362"
  type: "Eltwise"
  bottom: "Eltwise361"
  bottom: "Convolution725"
  top: "Eltwise362"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU725"
  type: "ReLU"
  bottom: "Eltwise362"
  top: "Eltwise362"
}
layer {
  name: "Convolution726"
  type: "Convolution"
  bottom: "Eltwise362"
  top: "Convolution726"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm726"
  type: "BatchNorm"
  bottom: "Convolution726"
  top: "Convolution726"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale726"
  type: "Scale"
  bottom: "Convolution726"
  top: "Convolution726"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU726"
  type: "ReLU"
  bottom: "Convolution726"
  top: "Convolution726"
}
layer {
  name: "Convolution727"
  type: "Convolution"
  bottom: "Convolution726"
  top: "Convolution727"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm727"
  type: "BatchNorm"
  bottom: "Convolution727"
  top: "Convolution727"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale727"
  type: "Scale"
  bottom: "Convolution727"
  top: "Convolution727"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise363"
  type: "Eltwise"
  bottom: "Eltwise362"
  bottom: "Convolution727"
  top: "Eltwise363"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU727"
  type: "ReLU"
  bottom: "Eltwise363"
  top: "Eltwise363"
}
layer {
  name: "Convolution728"
  type: "Convolution"
  bottom: "Eltwise363"
  top: "Convolution728"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm728"
  type: "BatchNorm"
  bottom: "Convolution728"
  top: "Convolution728"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale728"
  type: "Scale"
  bottom: "Convolution728"
  top: "Convolution728"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU728"
  type: "ReLU"
  bottom: "Convolution728"
  top: "Convolution728"
}
layer {
  name: "Convolution729"
  type: "Convolution"
  bottom: "Convolution728"
  top: "Convolution729"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm729"
  type: "BatchNorm"
  bottom: "Convolution729"
  top: "Convolution729"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale729"
  type: "Scale"
  bottom: "Convolution729"
  top: "Convolution729"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise364"
  type: "Eltwise"
  bottom: "Eltwise363"
  bottom: "Convolution729"
  top: "Eltwise364"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU729"
  type: "ReLU"
  bottom: "Eltwise364"
  top: "Eltwise364"
}
layer {
  name: "Convolution730"
  type: "Convolution"
  bottom: "Eltwise364"
  top: "Convolution730"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm730"
  type: "BatchNorm"
  bottom: "Convolution730"
  top: "Convolution730"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale730"
  type: "Scale"
  bottom: "Convolution730"
  top: "Convolution730"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU730"
  type: "ReLU"
  bottom: "Convolution730"
  top: "Convolution730"
}
layer {
  name: "Convolution731"
  type: "Convolution"
  bottom: "Convolution730"
  top: "Convolution731"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm731"
  type: "BatchNorm"
  bottom: "Convolution731"
  top: "Convolution731"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale731"
  type: "Scale"
  bottom: "Convolution731"
  top: "Convolution731"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise365"
  type: "Eltwise"
  bottom: "Eltwise364"
  bottom: "Convolution731"
  top: "Eltwise365"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU731"
  type: "ReLU"
  bottom: "Eltwise365"
  top: "Eltwise365"
}
layer {
  name: "Convolution732"
  type: "Convolution"
  bottom: "Eltwise365"
  top: "Convolution732"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm732"
  type: "BatchNorm"
  bottom: "Convolution732"
  top: "Convolution732"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale732"
  type: "Scale"
  bottom: "Convolution732"
  top: "Convolution732"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU732"
  type: "ReLU"
  bottom: "Convolution732"
  top: "Convolution732"
}
layer {
  name: "Convolution733"
  type: "Convolution"
  bottom: "Convolution732"
  top: "Convolution733"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm733"
  type: "BatchNorm"
  bottom: "Convolution733"
  top: "Convolution733"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale733"
  type: "Scale"
  bottom: "Convolution733"
  top: "Convolution733"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise366"
  type: "Eltwise"
  bottom: "Eltwise365"
  bottom: "Convolution733"
  top: "Eltwise366"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU733"
  type: "ReLU"
  bottom: "Eltwise366"
  top: "Eltwise366"
}
layer {
  name: "Convolution734"
  type: "Convolution"
  bottom: "Eltwise366"
  top: "Convolution734"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm734"
  type: "BatchNorm"
  bottom: "Convolution734"
  top: "Convolution734"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale734"
  type: "Scale"
  bottom: "Convolution734"
  top: "Convolution734"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU734"
  type: "ReLU"
  bottom: "Convolution734"
  top: "Convolution734"
}
layer {
  name: "Convolution735"
  type: "Convolution"
  bottom: "Convolution734"
  top: "Convolution735"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm735"
  type: "BatchNorm"
  bottom: "Convolution735"
  top: "Convolution735"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale735"
  type: "Scale"
  bottom: "Convolution735"
  top: "Convolution735"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise367"
  type: "Eltwise"
  bottom: "Eltwise366"
  bottom: "Convolution735"
  top: "Eltwise367"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU735"
  type: "ReLU"
  bottom: "Eltwise367"
  top: "Eltwise367"
}
layer {
  name: "Convolution736"
  type: "Convolution"
  bottom: "Eltwise367"
  top: "Convolution736"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm736"
  type: "BatchNorm"
  bottom: "Convolution736"
  top: "Convolution736"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale736"
  type: "Scale"
  bottom: "Convolution736"
  top: "Convolution736"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU736"
  type: "ReLU"
  bottom: "Convolution736"
  top: "Convolution736"
}
layer {
  name: "Convolution737"
  type: "Convolution"
  bottom: "Convolution736"
  top: "Convolution737"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm737"
  type: "BatchNorm"
  bottom: "Convolution737"
  top: "Convolution737"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale737"
  type: "Scale"
  bottom: "Convolution737"
  top: "Convolution737"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise368"
  type: "Eltwise"
  bottom: "Eltwise367"
  bottom: "Convolution737"
  top: "Eltwise368"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU737"
  type: "ReLU"
  bottom: "Eltwise368"
  top: "Eltwise368"
}
layer {
  name: "Convolution738"
  type: "Convolution"
  bottom: "Eltwise368"
  top: "Convolution738"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm738"
  type: "BatchNorm"
  bottom: "Convolution738"
  top: "Convolution738"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale738"
  type: "Scale"
  bottom: "Convolution738"
  top: "Convolution738"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU738"
  type: "ReLU"
  bottom: "Convolution738"
  top: "Convolution738"
}
layer {
  name: "Convolution739"
  type: "Convolution"
  bottom: "Convolution738"
  top: "Convolution739"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm739"
  type: "BatchNorm"
  bottom: "Convolution739"
  top: "Convolution739"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale739"
  type: "Scale"
  bottom: "Convolution739"
  top: "Convolution739"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise369"
  type: "Eltwise"
  bottom: "Eltwise368"
  bottom: "Convolution739"
  top: "Eltwise369"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU739"
  type: "ReLU"
  bottom: "Eltwise369"
  top: "Eltwise369"
}
layer {
  name: "Convolution740"
  type: "Convolution"
  bottom: "Eltwise369"
  top: "Convolution740"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm740"
  type: "BatchNorm"
  bottom: "Convolution740"
  top: "Convolution740"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale740"
  type: "Scale"
  bottom: "Convolution740"
  top: "Convolution740"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU740"
  type: "ReLU"
  bottom: "Convolution740"
  top: "Convolution740"
}
layer {
  name: "Convolution741"
  type: "Convolution"
  bottom: "Convolution740"
  top: "Convolution741"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm741"
  type: "BatchNorm"
  bottom: "Convolution741"
  top: "Convolution741"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale741"
  type: "Scale"
  bottom: "Convolution741"
  top: "Convolution741"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise370"
  type: "Eltwise"
  bottom: "Eltwise369"
  bottom: "Convolution741"
  top: "Eltwise370"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU741"
  type: "ReLU"
  bottom: "Eltwise370"
  top: "Eltwise370"
}
layer {
  name: "Convolution742"
  type: "Convolution"
  bottom: "Eltwise370"
  top: "Convolution742"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm742"
  type: "BatchNorm"
  bottom: "Convolution742"
  top: "Convolution742"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale742"
  type: "Scale"
  bottom: "Convolution742"
  top: "Convolution742"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU742"
  type: "ReLU"
  bottom: "Convolution742"
  top: "Convolution742"
}
layer {
  name: "Convolution743"
  type: "Convolution"
  bottom: "Convolution742"
  top: "Convolution743"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm743"
  type: "BatchNorm"
  bottom: "Convolution743"
  top: "Convolution743"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale743"
  type: "Scale"
  bottom: "Convolution743"
  top: "Convolution743"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise371"
  type: "Eltwise"
  bottom: "Eltwise370"
  bottom: "Convolution743"
  top: "Eltwise371"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU743"
  type: "ReLU"
  bottom: "Eltwise371"
  top: "Eltwise371"
}
layer {
  name: "Convolution744"
  type: "Convolution"
  bottom: "Eltwise371"
  top: "Convolution744"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm744"
  type: "BatchNorm"
  bottom: "Convolution744"
  top: "Convolution744"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale744"
  type: "Scale"
  bottom: "Convolution744"
  top: "Convolution744"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU744"
  type: "ReLU"
  bottom: "Convolution744"
  top: "Convolution744"
}
layer {
  name: "Convolution745"
  type: "Convolution"
  bottom: "Convolution744"
  top: "Convolution745"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm745"
  type: "BatchNorm"
  bottom: "Convolution745"
  top: "Convolution745"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale745"
  type: "Scale"
  bottom: "Convolution745"
  top: "Convolution745"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise372"
  type: "Eltwise"
  bottom: "Eltwise371"
  bottom: "Convolution745"
  top: "Eltwise372"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU745"
  type: "ReLU"
  bottom: "Eltwise372"
  top: "Eltwise372"
}
layer {
  name: "Convolution746"
  type: "Convolution"
  bottom: "Eltwise372"
  top: "Convolution746"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm746"
  type: "BatchNorm"
  bottom: "Convolution746"
  top: "Convolution746"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale746"
  type: "Scale"
  bottom: "Convolution746"
  top: "Convolution746"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU746"
  type: "ReLU"
  bottom: "Convolution746"
  top: "Convolution746"
}
layer {
  name: "Convolution747"
  type: "Convolution"
  bottom: "Convolution746"
  top: "Convolution747"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm747"
  type: "BatchNorm"
  bottom: "Convolution747"
  top: "Convolution747"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale747"
  type: "Scale"
  bottom: "Convolution747"
  top: "Convolution747"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise373"
  type: "Eltwise"
  bottom: "Eltwise372"
  bottom: "Convolution747"
  top: "Eltwise373"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU747"
  type: "ReLU"
  bottom: "Eltwise373"
  top: "Eltwise373"
}
layer {
  name: "Convolution748"
  type: "Convolution"
  bottom: "Eltwise373"
  top: "Convolution748"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm748"
  type: "BatchNorm"
  bottom: "Convolution748"
  top: "Convolution748"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale748"
  type: "Scale"
  bottom: "Convolution748"
  top: "Convolution748"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU748"
  type: "ReLU"
  bottom: "Convolution748"
  top: "Convolution748"
}
layer {
  name: "Convolution749"
  type: "Convolution"
  bottom: "Convolution748"
  top: "Convolution749"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm749"
  type: "BatchNorm"
  bottom: "Convolution749"
  top: "Convolution749"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale749"
  type: "Scale"
  bottom: "Convolution749"
  top: "Convolution749"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise374"
  type: "Eltwise"
  bottom: "Eltwise373"
  bottom: "Convolution749"
  top: "Eltwise374"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU749"
  type: "ReLU"
  bottom: "Eltwise374"
  top: "Eltwise374"
}
layer {
  name: "Convolution750"
  type: "Convolution"
  bottom: "Eltwise374"
  top: "Convolution750"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm750"
  type: "BatchNorm"
  bottom: "Convolution750"
  top: "Convolution750"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale750"
  type: "Scale"
  bottom: "Convolution750"
  top: "Convolution750"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU750"
  type: "ReLU"
  bottom: "Convolution750"
  top: "Convolution750"
}
layer {
  name: "Convolution751"
  type: "Convolution"
  bottom: "Convolution750"
  top: "Convolution751"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm751"
  type: "BatchNorm"
  bottom: "Convolution751"
  top: "Convolution751"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale751"
  type: "Scale"
  bottom: "Convolution751"
  top: "Convolution751"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise375"
  type: "Eltwise"
  bottom: "Eltwise374"
  bottom: "Convolution751"
  top: "Eltwise375"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU751"
  type: "ReLU"
  bottom: "Eltwise375"
  top: "Eltwise375"
}
layer {
  name: "Convolution752"
  type: "Convolution"
  bottom: "Eltwise375"
  top: "Convolution752"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm752"
  type: "BatchNorm"
  bottom: "Convolution752"
  top: "Convolution752"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale752"
  type: "Scale"
  bottom: "Convolution752"
  top: "Convolution752"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU752"
  type: "ReLU"
  bottom: "Convolution752"
  top: "Convolution752"
}
layer {
  name: "Convolution753"
  type: "Convolution"
  bottom: "Convolution752"
  top: "Convolution753"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm753"
  type: "BatchNorm"
  bottom: "Convolution753"
  top: "Convolution753"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale753"
  type: "Scale"
  bottom: "Convolution753"
  top: "Convolution753"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise376"
  type: "Eltwise"
  bottom: "Eltwise375"
  bottom: "Convolution753"
  top: "Eltwise376"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU753"
  type: "ReLU"
  bottom: "Eltwise376"
  top: "Eltwise376"
}
layer {
  name: "Convolution754"
  type: "Convolution"
  bottom: "Eltwise376"
  top: "Convolution754"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm754"
  type: "BatchNorm"
  bottom: "Convolution754"
  top: "Convolution754"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale754"
  type: "Scale"
  bottom: "Convolution754"
  top: "Convolution754"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU754"
  type: "ReLU"
  bottom: "Convolution754"
  top: "Convolution754"
}
layer {
  name: "Convolution755"
  type: "Convolution"
  bottom: "Convolution754"
  top: "Convolution755"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm755"
  type: "BatchNorm"
  bottom: "Convolution755"
  top: "Convolution755"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale755"
  type: "Scale"
  bottom: "Convolution755"
  top: "Convolution755"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise377"
  type: "Eltwise"
  bottom: "Eltwise376"
  bottom: "Convolution755"
  top: "Eltwise377"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU755"
  type: "ReLU"
  bottom: "Eltwise377"
  top: "Eltwise377"
}
layer {
  name: "Convolution756"
  type: "Convolution"
  bottom: "Eltwise377"
  top: "Convolution756"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm756"
  type: "BatchNorm"
  bottom: "Convolution756"
  top: "Convolution756"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale756"
  type: "Scale"
  bottom: "Convolution756"
  top: "Convolution756"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU756"
  type: "ReLU"
  bottom: "Convolution756"
  top: "Convolution756"
}
layer {
  name: "Convolution757"
  type: "Convolution"
  bottom: "Convolution756"
  top: "Convolution757"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm757"
  type: "BatchNorm"
  bottom: "Convolution757"
  top: "Convolution757"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale757"
  type: "Scale"
  bottom: "Convolution757"
  top: "Convolution757"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise378"
  type: "Eltwise"
  bottom: "Eltwise377"
  bottom: "Convolution757"
  top: "Eltwise378"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU757"
  type: "ReLU"
  bottom: "Eltwise378"
  top: "Eltwise378"
}
layer {
  name: "Convolution758"
  type: "Convolution"
  bottom: "Eltwise378"
  top: "Convolution758"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm758"
  type: "BatchNorm"
  bottom: "Convolution758"
  top: "Convolution758"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale758"
  type: "Scale"
  bottom: "Convolution758"
  top: "Convolution758"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU758"
  type: "ReLU"
  bottom: "Convolution758"
  top: "Convolution758"
}
layer {
  name: "Convolution759"
  type: "Convolution"
  bottom: "Convolution758"
  top: "Convolution759"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm759"
  type: "BatchNorm"
  bottom: "Convolution759"
  top: "Convolution759"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale759"
  type: "Scale"
  bottom: "Convolution759"
  top: "Convolution759"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise379"
  type: "Eltwise"
  bottom: "Eltwise378"
  bottom: "Convolution759"
  top: "Eltwise379"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU759"
  type: "ReLU"
  bottom: "Eltwise379"
  top: "Eltwise379"
}
layer {
  name: "Convolution760"
  type: "Convolution"
  bottom: "Eltwise379"
  top: "Convolution760"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm760"
  type: "BatchNorm"
  bottom: "Convolution760"
  top: "Convolution760"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale760"
  type: "Scale"
  bottom: "Convolution760"
  top: "Convolution760"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU760"
  type: "ReLU"
  bottom: "Convolution760"
  top: "Convolution760"
}
layer {
  name: "Convolution761"
  type: "Convolution"
  bottom: "Convolution760"
  top: "Convolution761"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm761"
  type: "BatchNorm"
  bottom: "Convolution761"
  top: "Convolution761"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale761"
  type: "Scale"
  bottom: "Convolution761"
  top: "Convolution761"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise380"
  type: "Eltwise"
  bottom: "Eltwise379"
  bottom: "Convolution761"
  top: "Eltwise380"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU761"
  type: "ReLU"
  bottom: "Eltwise380"
  top: "Eltwise380"
}
layer {
  name: "Convolution762"
  type: "Convolution"
  bottom: "Eltwise380"
  top: "Convolution762"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm762"
  type: "BatchNorm"
  bottom: "Convolution762"
  top: "Convolution762"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale762"
  type: "Scale"
  bottom: "Convolution762"
  top: "Convolution762"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU762"
  type: "ReLU"
  bottom: "Convolution762"
  top: "Convolution762"
}
layer {
  name: "Convolution763"
  type: "Convolution"
  bottom: "Convolution762"
  top: "Convolution763"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm763"
  type: "BatchNorm"
  bottom: "Convolution763"
  top: "Convolution763"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale763"
  type: "Scale"
  bottom: "Convolution763"
  top: "Convolution763"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise381"
  type: "Eltwise"
  bottom: "Eltwise380"
  bottom: "Convolution763"
  top: "Eltwise381"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU763"
  type: "ReLU"
  bottom: "Eltwise381"
  top: "Eltwise381"
}
layer {
  name: "Convolution764"
  type: "Convolution"
  bottom: "Eltwise381"
  top: "Convolution764"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm764"
  type: "BatchNorm"
  bottom: "Convolution764"
  top: "Convolution764"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale764"
  type: "Scale"
  bottom: "Convolution764"
  top: "Convolution764"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU764"
  type: "ReLU"
  bottom: "Convolution764"
  top: "Convolution764"
}
layer {
  name: "Convolution765"
  type: "Convolution"
  bottom: "Convolution764"
  top: "Convolution765"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm765"
  type: "BatchNorm"
  bottom: "Convolution765"
  top: "Convolution765"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale765"
  type: "Scale"
  bottom: "Convolution765"
  top: "Convolution765"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise382"
  type: "Eltwise"
  bottom: "Eltwise381"
  bottom: "Convolution765"
  top: "Eltwise382"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU765"
  type: "ReLU"
  bottom: "Eltwise382"
  top: "Eltwise382"
}
layer {
  name: "Convolution766"
  type: "Convolution"
  bottom: "Eltwise382"
  top: "Convolution766"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm766"
  type: "BatchNorm"
  bottom: "Convolution766"
  top: "Convolution766"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale766"
  type: "Scale"
  bottom: "Convolution766"
  top: "Convolution766"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU766"
  type: "ReLU"
  bottom: "Convolution766"
  top: "Convolution766"
}
layer {
  name: "Convolution767"
  type: "Convolution"
  bottom: "Convolution766"
  top: "Convolution767"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm767"
  type: "BatchNorm"
  bottom: "Convolution767"
  top: "Convolution767"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale767"
  type: "Scale"
  bottom: "Convolution767"
  top: "Convolution767"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise383"
  type: "Eltwise"
  bottom: "Eltwise382"
  bottom: "Convolution767"
  top: "Eltwise383"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU767"
  type: "ReLU"
  bottom: "Eltwise383"
  top: "Eltwise383"
}
layer {
  name: "Convolution768"
  type: "Convolution"
  bottom: "Eltwise383"
  top: "Convolution768"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm768"
  type: "BatchNorm"
  bottom: "Convolution768"
  top: "Convolution768"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale768"
  type: "Scale"
  bottom: "Convolution768"
  top: "Convolution768"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU768"
  type: "ReLU"
  bottom: "Convolution768"
  top: "Convolution768"
}
layer {
  name: "Convolution769"
  type: "Convolution"
  bottom: "Convolution768"
  top: "Convolution769"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm769"
  type: "BatchNorm"
  bottom: "Convolution769"
  top: "Convolution769"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale769"
  type: "Scale"
  bottom: "Convolution769"
  top: "Convolution769"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise384"
  type: "Eltwise"
  bottom: "Eltwise383"
  bottom: "Convolution769"
  top: "Eltwise384"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU769"
  type: "ReLU"
  bottom: "Eltwise384"
  top: "Eltwise384"
}
layer {
  name: "Convolution770"
  type: "Convolution"
  bottom: "Eltwise384"
  top: "Convolution770"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm770"
  type: "BatchNorm"
  bottom: "Convolution770"
  top: "Convolution770"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale770"
  type: "Scale"
  bottom: "Convolution770"
  top: "Convolution770"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU770"
  type: "ReLU"
  bottom: "Convolution770"
  top: "Convolution770"
}
layer {
  name: "Convolution771"
  type: "Convolution"
  bottom: "Convolution770"
  top: "Convolution771"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm771"
  type: "BatchNorm"
  bottom: "Convolution771"
  top: "Convolution771"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale771"
  type: "Scale"
  bottom: "Convolution771"
  top: "Convolution771"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise385"
  type: "Eltwise"
  bottom: "Eltwise384"
  bottom: "Convolution771"
  top: "Eltwise385"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU771"
  type: "ReLU"
  bottom: "Eltwise385"
  top: "Eltwise385"
}
layer {
  name: "Convolution772"
  type: "Convolution"
  bottom: "Eltwise385"
  top: "Convolution772"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm772"
  type: "BatchNorm"
  bottom: "Convolution772"
  top: "Convolution772"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale772"
  type: "Scale"
  bottom: "Convolution772"
  top: "Convolution772"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU772"
  type: "ReLU"
  bottom: "Convolution772"
  top: "Convolution772"
}
layer {
  name: "Convolution773"
  type: "Convolution"
  bottom: "Convolution772"
  top: "Convolution773"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm773"
  type: "BatchNorm"
  bottom: "Convolution773"
  top: "Convolution773"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale773"
  type: "Scale"
  bottom: "Convolution773"
  top: "Convolution773"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise386"
  type: "Eltwise"
  bottom: "Eltwise385"
  bottom: "Convolution773"
  top: "Eltwise386"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU773"
  type: "ReLU"
  bottom: "Eltwise386"
  top: "Eltwise386"
}
layer {
  name: "Convolution774"
  type: "Convolution"
  bottom: "Eltwise386"
  top: "Convolution774"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm774"
  type: "BatchNorm"
  bottom: "Convolution774"
  top: "Convolution774"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale774"
  type: "Scale"
  bottom: "Convolution774"
  top: "Convolution774"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU774"
  type: "ReLU"
  bottom: "Convolution774"
  top: "Convolution774"
}
layer {
  name: "Convolution775"
  type: "Convolution"
  bottom: "Convolution774"
  top: "Convolution775"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm775"
  type: "BatchNorm"
  bottom: "Convolution775"
  top: "Convolution775"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale775"
  type: "Scale"
  bottom: "Convolution775"
  top: "Convolution775"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise387"
  type: "Eltwise"
  bottom: "Eltwise386"
  bottom: "Convolution775"
  top: "Eltwise387"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU775"
  type: "ReLU"
  bottom: "Eltwise387"
  top: "Eltwise387"
}
layer {
  name: "Convolution776"
  type: "Convolution"
  bottom: "Eltwise387"
  top: "Convolution776"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm776"
  type: "BatchNorm"
  bottom: "Convolution776"
  top: "Convolution776"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale776"
  type: "Scale"
  bottom: "Convolution776"
  top: "Convolution776"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU776"
  type: "ReLU"
  bottom: "Convolution776"
  top: "Convolution776"
}
layer {
  name: "Convolution777"
  type: "Convolution"
  bottom: "Convolution776"
  top: "Convolution777"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm777"
  type: "BatchNorm"
  bottom: "Convolution777"
  top: "Convolution777"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale777"
  type: "Scale"
  bottom: "Convolution777"
  top: "Convolution777"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise388"
  type: "Eltwise"
  bottom: "Eltwise387"
  bottom: "Convolution777"
  top: "Eltwise388"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU777"
  type: "ReLU"
  bottom: "Eltwise388"
  top: "Eltwise388"
}
layer {
  name: "Convolution778"
  type: "Convolution"
  bottom: "Eltwise388"
  top: "Convolution778"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm778"
  type: "BatchNorm"
  bottom: "Convolution778"
  top: "Convolution778"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale778"
  type: "Scale"
  bottom: "Convolution778"
  top: "Convolution778"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU778"
  type: "ReLU"
  bottom: "Convolution778"
  top: "Convolution778"
}
layer {
  name: "Convolution779"
  type: "Convolution"
  bottom: "Convolution778"
  top: "Convolution779"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm779"
  type: "BatchNorm"
  bottom: "Convolution779"
  top: "Convolution779"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale779"
  type: "Scale"
  bottom: "Convolution779"
  top: "Convolution779"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise389"
  type: "Eltwise"
  bottom: "Eltwise388"
  bottom: "Convolution779"
  top: "Eltwise389"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU779"
  type: "ReLU"
  bottom: "Eltwise389"
  top: "Eltwise389"
}
layer {
  name: "Convolution780"
  type: "Convolution"
  bottom: "Eltwise389"
  top: "Convolution780"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm780"
  type: "BatchNorm"
  bottom: "Convolution780"
  top: "Convolution780"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale780"
  type: "Scale"
  bottom: "Convolution780"
  top: "Convolution780"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU780"
  type: "ReLU"
  bottom: "Convolution780"
  top: "Convolution780"
}
layer {
  name: "Convolution781"
  type: "Convolution"
  bottom: "Convolution780"
  top: "Convolution781"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm781"
  type: "BatchNorm"
  bottom: "Convolution781"
  top: "Convolution781"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale781"
  type: "Scale"
  bottom: "Convolution781"
  top: "Convolution781"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise390"
  type: "Eltwise"
  bottom: "Eltwise389"
  bottom: "Convolution781"
  top: "Eltwise390"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU781"
  type: "ReLU"
  bottom: "Eltwise390"
  top: "Eltwise390"
}
layer {
  name: "Convolution782"
  type: "Convolution"
  bottom: "Eltwise390"
  top: "Convolution782"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm782"
  type: "BatchNorm"
  bottom: "Convolution782"
  top: "Convolution782"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale782"
  type: "Scale"
  bottom: "Convolution782"
  top: "Convolution782"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU782"
  type: "ReLU"
  bottom: "Convolution782"
  top: "Convolution782"
}
layer {
  name: "Convolution783"
  type: "Convolution"
  bottom: "Convolution782"
  top: "Convolution783"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm783"
  type: "BatchNorm"
  bottom: "Convolution783"
  top: "Convolution783"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale783"
  type: "Scale"
  bottom: "Convolution783"
  top: "Convolution783"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise391"
  type: "Eltwise"
  bottom: "Eltwise390"
  bottom: "Convolution783"
  top: "Eltwise391"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU783"
  type: "ReLU"
  bottom: "Eltwise391"
  top: "Eltwise391"
}
layer {
  name: "Convolution784"
  type: "Convolution"
  bottom: "Eltwise391"
  top: "Convolution784"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm784"
  type: "BatchNorm"
  bottom: "Convolution784"
  top: "Convolution784"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale784"
  type: "Scale"
  bottom: "Convolution784"
  top: "Convolution784"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU784"
  type: "ReLU"
  bottom: "Convolution784"
  top: "Convolution784"
}
layer {
  name: "Convolution785"
  type: "Convolution"
  bottom: "Convolution784"
  top: "Convolution785"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm785"
  type: "BatchNorm"
  bottom: "Convolution785"
  top: "Convolution785"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale785"
  type: "Scale"
  bottom: "Convolution785"
  top: "Convolution785"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise392"
  type: "Eltwise"
  bottom: "Eltwise391"
  bottom: "Convolution785"
  top: "Eltwise392"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU785"
  type: "ReLU"
  bottom: "Eltwise392"
  top: "Eltwise392"
}
layer {
  name: "Convolution786"
  type: "Convolution"
  bottom: "Eltwise392"
  top: "Convolution786"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm786"
  type: "BatchNorm"
  bottom: "Convolution786"
  top: "Convolution786"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale786"
  type: "Scale"
  bottom: "Convolution786"
  top: "Convolution786"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU786"
  type: "ReLU"
  bottom: "Convolution786"
  top: "Convolution786"
}
layer {
  name: "Convolution787"
  type: "Convolution"
  bottom: "Convolution786"
  top: "Convolution787"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm787"
  type: "BatchNorm"
  bottom: "Convolution787"
  top: "Convolution787"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale787"
  type: "Scale"
  bottom: "Convolution787"
  top: "Convolution787"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise393"
  type: "Eltwise"
  bottom: "Eltwise392"
  bottom: "Convolution787"
  top: "Eltwise393"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU787"
  type: "ReLU"
  bottom: "Eltwise393"
  top: "Eltwise393"
}
layer {
  name: "Convolution788"
  type: "Convolution"
  bottom: "Eltwise393"
  top: "Convolution788"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm788"
  type: "BatchNorm"
  bottom: "Convolution788"
  top: "Convolution788"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale788"
  type: "Scale"
  bottom: "Convolution788"
  top: "Convolution788"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU788"
  type: "ReLU"
  bottom: "Convolution788"
  top: "Convolution788"
}
layer {
  name: "Convolution789"
  type: "Convolution"
  bottom: "Convolution788"
  top: "Convolution789"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm789"
  type: "BatchNorm"
  bottom: "Convolution789"
  top: "Convolution789"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale789"
  type: "Scale"
  bottom: "Convolution789"
  top: "Convolution789"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise394"
  type: "Eltwise"
  bottom: "Eltwise393"
  bottom: "Convolution789"
  top: "Eltwise394"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU789"
  type: "ReLU"
  bottom: "Eltwise394"
  top: "Eltwise394"
}
layer {
  name: "Convolution790"
  type: "Convolution"
  bottom: "Eltwise394"
  top: "Convolution790"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm790"
  type: "BatchNorm"
  bottom: "Convolution790"
  top: "Convolution790"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale790"
  type: "Scale"
  bottom: "Convolution790"
  top: "Convolution790"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU790"
  type: "ReLU"
  bottom: "Convolution790"
  top: "Convolution790"
}
layer {
  name: "Convolution791"
  type: "Convolution"
  bottom: "Convolution790"
  top: "Convolution791"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm791"
  type: "BatchNorm"
  bottom: "Convolution791"
  top: "Convolution791"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale791"
  type: "Scale"
  bottom: "Convolution791"
  top: "Convolution791"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise395"
  type: "Eltwise"
  bottom: "Eltwise394"
  bottom: "Convolution791"
  top: "Eltwise395"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU791"
  type: "ReLU"
  bottom: "Eltwise395"
  top: "Eltwise395"
}
layer {
  name: "Convolution792"
  type: "Convolution"
  bottom: "Eltwise395"
  top: "Convolution792"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm792"
  type: "BatchNorm"
  bottom: "Convolution792"
  top: "Convolution792"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale792"
  type: "Scale"
  bottom: "Convolution792"
  top: "Convolution792"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU792"
  type: "ReLU"
  bottom: "Convolution792"
  top: "Convolution792"
}
layer {
  name: "Convolution793"
  type: "Convolution"
  bottom: "Convolution792"
  top: "Convolution793"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm793"
  type: "BatchNorm"
  bottom: "Convolution793"
  top: "Convolution793"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale793"
  type: "Scale"
  bottom: "Convolution793"
  top: "Convolution793"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise396"
  type: "Eltwise"
  bottom: "Eltwise395"
  bottom: "Convolution793"
  top: "Eltwise396"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU793"
  type: "ReLU"
  bottom: "Eltwise396"
  top: "Eltwise396"
}
layer {
  name: "Convolution794"
  type: "Convolution"
  bottom: "Eltwise396"
  top: "Convolution794"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm794"
  type: "BatchNorm"
  bottom: "Convolution794"
  top: "Convolution794"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale794"
  type: "Scale"
  bottom: "Convolution794"
  top: "Convolution794"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU794"
  type: "ReLU"
  bottom: "Convolution794"
  top: "Convolution794"
}
layer {
  name: "Convolution795"
  type: "Convolution"
  bottom: "Convolution794"
  top: "Convolution795"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm795"
  type: "BatchNorm"
  bottom: "Convolution795"
  top: "Convolution795"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale795"
  type: "Scale"
  bottom: "Convolution795"
  top: "Convolution795"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise397"
  type: "Eltwise"
  bottom: "Eltwise396"
  bottom: "Convolution795"
  top: "Eltwise397"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU795"
  type: "ReLU"
  bottom: "Eltwise397"
  top: "Eltwise397"
}
layer {
  name: "Convolution796"
  type: "Convolution"
  bottom: "Eltwise397"
  top: "Convolution796"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm796"
  type: "BatchNorm"
  bottom: "Convolution796"
  top: "Convolution796"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale796"
  type: "Scale"
  bottom: "Convolution796"
  top: "Convolution796"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU796"
  type: "ReLU"
  bottom: "Convolution796"
  top: "Convolution796"
}
layer {
  name: "Convolution797"
  type: "Convolution"
  bottom: "Convolution796"
  top: "Convolution797"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm797"
  type: "BatchNorm"
  bottom: "Convolution797"
  top: "Convolution797"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale797"
  type: "Scale"
  bottom: "Convolution797"
  top: "Convolution797"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise398"
  type: "Eltwise"
  bottom: "Eltwise397"
  bottom: "Convolution797"
  top: "Eltwise398"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU797"
  type: "ReLU"
  bottom: "Eltwise398"
  top: "Eltwise398"
}
layer {
  name: "Convolution798"
  type: "Convolution"
  bottom: "Eltwise398"
  top: "Convolution798"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm798"
  type: "BatchNorm"
  bottom: "Convolution798"
  top: "Convolution798"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale798"
  type: "Scale"
  bottom: "Convolution798"
  top: "Convolution798"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU798"
  type: "ReLU"
  bottom: "Convolution798"
  top: "Convolution798"
}
layer {
  name: "Convolution799"
  type: "Convolution"
  bottom: "Convolution798"
  top: "Convolution799"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm799"
  type: "BatchNorm"
  bottom: "Convolution799"
  top: "Convolution799"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale799"
  type: "Scale"
  bottom: "Convolution799"
  top: "Convolution799"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise399"
  type: "Eltwise"
  bottom: "Eltwise398"
  bottom: "Convolution799"
  top: "Eltwise399"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU799"
  type: "ReLU"
  bottom: "Eltwise399"
  top: "Eltwise399"
}
layer {
  name: "Convolution800"
  type: "Convolution"
  bottom: "Eltwise399"
  top: "Convolution800"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm800"
  type: "BatchNorm"
  bottom: "Convolution800"
  top: "Convolution800"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale800"
  type: "Scale"
  bottom: "Convolution800"
  top: "Convolution800"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU800"
  type: "ReLU"
  bottom: "Convolution800"
  top: "Convolution800"
}
layer {
  name: "Convolution801"
  type: "Convolution"
  bottom: "Convolution800"
  top: "Convolution801"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm801"
  type: "BatchNorm"
  bottom: "Convolution801"
  top: "Convolution801"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale801"
  type: "Scale"
  bottom: "Convolution801"
  top: "Convolution801"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise400"
  type: "Eltwise"
  bottom: "Eltwise399"
  bottom: "Convolution801"
  top: "Eltwise400"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU801"
  type: "ReLU"
  bottom: "Eltwise400"
  top: "Eltwise400"
}
layer {
  name: "Convolution802"
  type: "Convolution"
  bottom: "Eltwise400"
  top: "Convolution802"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm802"
  type: "BatchNorm"
  bottom: "Convolution802"
  top: "Convolution802"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale802"
  type: "Scale"
  bottom: "Convolution802"
  top: "Convolution802"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU802"
  type: "ReLU"
  bottom: "Convolution802"
  top: "Convolution802"
}
layer {
  name: "Convolution803"
  type: "Convolution"
  bottom: "Convolution802"
  top: "Convolution803"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm803"
  type: "BatchNorm"
  bottom: "Convolution803"
  top: "Convolution803"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale803"
  type: "Scale"
  bottom: "Convolution803"
  top: "Convolution803"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise401"
  type: "Eltwise"
  bottom: "Eltwise400"
  bottom: "Convolution803"
  top: "Eltwise401"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU803"
  type: "ReLU"
  bottom: "Eltwise401"
  top: "Eltwise401"
}
layer {
  name: "Convolution804"
  type: "Convolution"
  bottom: "Eltwise401"
  top: "Convolution804"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm804"
  type: "BatchNorm"
  bottom: "Convolution804"
  top: "Convolution804"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale804"
  type: "Scale"
  bottom: "Convolution804"
  top: "Convolution804"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU804"
  type: "ReLU"
  bottom: "Convolution804"
  top: "Convolution804"
}
layer {
  name: "Convolution805"
  type: "Convolution"
  bottom: "Convolution804"
  top: "Convolution805"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm805"
  type: "BatchNorm"
  bottom: "Convolution805"
  top: "Convolution805"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale805"
  type: "Scale"
  bottom: "Convolution805"
  top: "Convolution805"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise402"
  type: "Eltwise"
  bottom: "Eltwise401"
  bottom: "Convolution805"
  top: "Eltwise402"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU805"
  type: "ReLU"
  bottom: "Eltwise402"
  top: "Eltwise402"
}
layer {
  name: "Convolution806"
  type: "Convolution"
  bottom: "Eltwise402"
  top: "Convolution806"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm806"
  type: "BatchNorm"
  bottom: "Convolution806"
  top: "Convolution806"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale806"
  type: "Scale"
  bottom: "Convolution806"
  top: "Convolution806"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU806"
  type: "ReLU"
  bottom: "Convolution806"
  top: "Convolution806"
}
layer {
  name: "Convolution807"
  type: "Convolution"
  bottom: "Convolution806"
  top: "Convolution807"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm807"
  type: "BatchNorm"
  bottom: "Convolution807"
  top: "Convolution807"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale807"
  type: "Scale"
  bottom: "Convolution807"
  top: "Convolution807"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise403"
  type: "Eltwise"
  bottom: "Eltwise402"
  bottom: "Convolution807"
  top: "Eltwise403"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU807"
  type: "ReLU"
  bottom: "Eltwise403"
  top: "Eltwise403"
}
layer {
  name: "Convolution808"
  type: "Convolution"
  bottom: "Eltwise403"
  top: "Convolution808"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm808"
  type: "BatchNorm"
  bottom: "Convolution808"
  top: "Convolution808"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale808"
  type: "Scale"
  bottom: "Convolution808"
  top: "Convolution808"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU808"
  type: "ReLU"
  bottom: "Convolution808"
  top: "Convolution808"
}
layer {
  name: "Convolution809"
  type: "Convolution"
  bottom: "Convolution808"
  top: "Convolution809"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm809"
  type: "BatchNorm"
  bottom: "Convolution809"
  top: "Convolution809"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale809"
  type: "Scale"
  bottom: "Convolution809"
  top: "Convolution809"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise404"
  type: "Eltwise"
  bottom: "Eltwise403"
  bottom: "Convolution809"
  top: "Eltwise404"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU809"
  type: "ReLU"
  bottom: "Eltwise404"
  top: "Eltwise404"
}
layer {
  name: "Convolution810"
  type: "Convolution"
  bottom: "Eltwise404"
  top: "Convolution810"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm810"
  type: "BatchNorm"
  bottom: "Convolution810"
  top: "Convolution810"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale810"
  type: "Scale"
  bottom: "Convolution810"
  top: "Convolution810"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU810"
  type: "ReLU"
  bottom: "Convolution810"
  top: "Convolution810"
}
layer {
  name: "Convolution811"
  type: "Convolution"
  bottom: "Convolution810"
  top: "Convolution811"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm811"
  type: "BatchNorm"
  bottom: "Convolution811"
  top: "Convolution811"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale811"
  type: "Scale"
  bottom: "Convolution811"
  top: "Convolution811"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise405"
  type: "Eltwise"
  bottom: "Eltwise404"
  bottom: "Convolution811"
  top: "Eltwise405"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU811"
  type: "ReLU"
  bottom: "Eltwise405"
  top: "Eltwise405"
}
layer {
  name: "Convolution812"
  type: "Convolution"
  bottom: "Eltwise405"
  top: "Convolution812"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm812"
  type: "BatchNorm"
  bottom: "Convolution812"
  top: "Convolution812"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale812"
  type: "Scale"
  bottom: "Convolution812"
  top: "Convolution812"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU812"
  type: "ReLU"
  bottom: "Convolution812"
  top: "Convolution812"
}
layer {
  name: "Convolution813"
  type: "Convolution"
  bottom: "Convolution812"
  top: "Convolution813"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm813"
  type: "BatchNorm"
  bottom: "Convolution813"
  top: "Convolution813"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale813"
  type: "Scale"
  bottom: "Convolution813"
  top: "Convolution813"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise406"
  type: "Eltwise"
  bottom: "Eltwise405"
  bottom: "Convolution813"
  top: "Eltwise406"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU813"
  type: "ReLU"
  bottom: "Eltwise406"
  top: "Eltwise406"
}
layer {
  name: "Convolution814"
  type: "Convolution"
  bottom: "Eltwise406"
  top: "Convolution814"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm814"
  type: "BatchNorm"
  bottom: "Convolution814"
  top: "Convolution814"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale814"
  type: "Scale"
  bottom: "Convolution814"
  top: "Convolution814"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU814"
  type: "ReLU"
  bottom: "Convolution814"
  top: "Convolution814"
}
layer {
  name: "Convolution815"
  type: "Convolution"
  bottom: "Convolution814"
  top: "Convolution815"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm815"
  type: "BatchNorm"
  bottom: "Convolution815"
  top: "Convolution815"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale815"
  type: "Scale"
  bottom: "Convolution815"
  top: "Convolution815"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise407"
  type: "Eltwise"
  bottom: "Eltwise406"
  bottom: "Convolution815"
  top: "Eltwise407"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU815"
  type: "ReLU"
  bottom: "Eltwise407"
  top: "Eltwise407"
}
layer {
  name: "Convolution816"
  type: "Convolution"
  bottom: "Eltwise407"
  top: "Convolution816"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm816"
  type: "BatchNorm"
  bottom: "Convolution816"
  top: "Convolution816"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale816"
  type: "Scale"
  bottom: "Convolution816"
  top: "Convolution816"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU816"
  type: "ReLU"
  bottom: "Convolution816"
  top: "Convolution816"
}
layer {
  name: "Convolution817"
  type: "Convolution"
  bottom: "Convolution816"
  top: "Convolution817"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm817"
  type: "BatchNorm"
  bottom: "Convolution817"
  top: "Convolution817"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale817"
  type: "Scale"
  bottom: "Convolution817"
  top: "Convolution817"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise408"
  type: "Eltwise"
  bottom: "Eltwise407"
  bottom: "Convolution817"
  top: "Eltwise408"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU817"
  type: "ReLU"
  bottom: "Eltwise408"
  top: "Eltwise408"
}
layer {
  name: "Convolution818"
  type: "Convolution"
  bottom: "Eltwise408"
  top: "Convolution818"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm818"
  type: "BatchNorm"
  bottom: "Convolution818"
  top: "Convolution818"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale818"
  type: "Scale"
  bottom: "Convolution818"
  top: "Convolution818"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU818"
  type: "ReLU"
  bottom: "Convolution818"
  top: "Convolution818"
}
layer {
  name: "Convolution819"
  type: "Convolution"
  bottom: "Convolution818"
  top: "Convolution819"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm819"
  type: "BatchNorm"
  bottom: "Convolution819"
  top: "Convolution819"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale819"
  type: "Scale"
  bottom: "Convolution819"
  top: "Convolution819"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise409"
  type: "Eltwise"
  bottom: "Eltwise408"
  bottom: "Convolution819"
  top: "Eltwise409"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU819"
  type: "ReLU"
  bottom: "Eltwise409"
  top: "Eltwise409"
}
layer {
  name: "Convolution820"
  type: "Convolution"
  bottom: "Eltwise409"
  top: "Convolution820"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm820"
  type: "BatchNorm"
  bottom: "Convolution820"
  top: "Convolution820"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale820"
  type: "Scale"
  bottom: "Convolution820"
  top: "Convolution820"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU820"
  type: "ReLU"
  bottom: "Convolution820"
  top: "Convolution820"
}
layer {
  name: "Convolution821"
  type: "Convolution"
  bottom: "Convolution820"
  top: "Convolution821"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm821"
  type: "BatchNorm"
  bottom: "Convolution821"
  top: "Convolution821"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale821"
  type: "Scale"
  bottom: "Convolution821"
  top: "Convolution821"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise410"
  type: "Eltwise"
  bottom: "Eltwise409"
  bottom: "Convolution821"
  top: "Eltwise410"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU821"
  type: "ReLU"
  bottom: "Eltwise410"
  top: "Eltwise410"
}
layer {
  name: "Convolution822"
  type: "Convolution"
  bottom: "Eltwise410"
  top: "Convolution822"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm822"
  type: "BatchNorm"
  bottom: "Convolution822"
  top: "Convolution822"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale822"
  type: "Scale"
  bottom: "Convolution822"
  top: "Convolution822"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU822"
  type: "ReLU"
  bottom: "Convolution822"
  top: "Convolution822"
}
layer {
  name: "Convolution823"
  type: "Convolution"
  bottom: "Convolution822"
  top: "Convolution823"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm823"
  type: "BatchNorm"
  bottom: "Convolution823"
  top: "Convolution823"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale823"
  type: "Scale"
  bottom: "Convolution823"
  top: "Convolution823"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise411"
  type: "Eltwise"
  bottom: "Eltwise410"
  bottom: "Convolution823"
  top: "Eltwise411"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU823"
  type: "ReLU"
  bottom: "Eltwise411"
  top: "Eltwise411"
}
layer {
  name: "Convolution824"
  type: "Convolution"
  bottom: "Eltwise411"
  top: "Convolution824"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm824"
  type: "BatchNorm"
  bottom: "Convolution824"
  top: "Convolution824"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale824"
  type: "Scale"
  bottom: "Convolution824"
  top: "Convolution824"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU824"
  type: "ReLU"
  bottom: "Convolution824"
  top: "Convolution824"
}
layer {
  name: "Convolution825"
  type: "Convolution"
  bottom: "Convolution824"
  top: "Convolution825"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm825"
  type: "BatchNorm"
  bottom: "Convolution825"
  top: "Convolution825"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale825"
  type: "Scale"
  bottom: "Convolution825"
  top: "Convolution825"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise412"
  type: "Eltwise"
  bottom: "Eltwise411"
  bottom: "Convolution825"
  top: "Eltwise412"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU825"
  type: "ReLU"
  bottom: "Eltwise412"
  top: "Eltwise412"
}
layer {
  name: "Convolution826"
  type: "Convolution"
  bottom: "Eltwise412"
  top: "Convolution826"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm826"
  type: "BatchNorm"
  bottom: "Convolution826"
  top: "Convolution826"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale826"
  type: "Scale"
  bottom: "Convolution826"
  top: "Convolution826"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU826"
  type: "ReLU"
  bottom: "Convolution826"
  top: "Convolution826"
}
layer {
  name: "Convolution827"
  type: "Convolution"
  bottom: "Convolution826"
  top: "Convolution827"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm827"
  type: "BatchNorm"
  bottom: "Convolution827"
  top: "Convolution827"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale827"
  type: "Scale"
  bottom: "Convolution827"
  top: "Convolution827"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise413"
  type: "Eltwise"
  bottom: "Eltwise412"
  bottom: "Convolution827"
  top: "Eltwise413"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU827"
  type: "ReLU"
  bottom: "Eltwise413"
  top: "Eltwise413"
}
layer {
  name: "Convolution828"
  type: "Convolution"
  bottom: "Eltwise413"
  top: "Convolution828"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm828"
  type: "BatchNorm"
  bottom: "Convolution828"
  top: "Convolution828"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale828"
  type: "Scale"
  bottom: "Convolution828"
  top: "Convolution828"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU828"
  type: "ReLU"
  bottom: "Convolution828"
  top: "Convolution828"
}
layer {
  name: "Convolution829"
  type: "Convolution"
  bottom: "Convolution828"
  top: "Convolution829"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm829"
  type: "BatchNorm"
  bottom: "Convolution829"
  top: "Convolution829"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale829"
  type: "Scale"
  bottom: "Convolution829"
  top: "Convolution829"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise414"
  type: "Eltwise"
  bottom: "Eltwise413"
  bottom: "Convolution829"
  top: "Eltwise414"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU829"
  type: "ReLU"
  bottom: "Eltwise414"
  top: "Eltwise414"
}
layer {
  name: "Convolution830"
  type: "Convolution"
  bottom: "Eltwise414"
  top: "Convolution830"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm830"
  type: "BatchNorm"
  bottom: "Convolution830"
  top: "Convolution830"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale830"
  type: "Scale"
  bottom: "Convolution830"
  top: "Convolution830"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU830"
  type: "ReLU"
  bottom: "Convolution830"
  top: "Convolution830"
}
layer {
  name: "Convolution831"
  type: "Convolution"
  bottom: "Convolution830"
  top: "Convolution831"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm831"
  type: "BatchNorm"
  bottom: "Convolution831"
  top: "Convolution831"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale831"
  type: "Scale"
  bottom: "Convolution831"
  top: "Convolution831"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise415"
  type: "Eltwise"
  bottom: "Eltwise414"
  bottom: "Convolution831"
  top: "Eltwise415"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU831"
  type: "ReLU"
  bottom: "Eltwise415"
  top: "Eltwise415"
}
layer {
  name: "Convolution832"
  type: "Convolution"
  bottom: "Eltwise415"
  top: "Convolution832"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm832"
  type: "BatchNorm"
  bottom: "Convolution832"
  top: "Convolution832"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale832"
  type: "Scale"
  bottom: "Convolution832"
  top: "Convolution832"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU832"
  type: "ReLU"
  bottom: "Convolution832"
  top: "Convolution832"
}
layer {
  name: "Convolution833"
  type: "Convolution"
  bottom: "Convolution832"
  top: "Convolution833"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm833"
  type: "BatchNorm"
  bottom: "Convolution833"
  top: "Convolution833"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale833"
  type: "Scale"
  bottom: "Convolution833"
  top: "Convolution833"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise416"
  type: "Eltwise"
  bottom: "Eltwise415"
  bottom: "Convolution833"
  top: "Eltwise416"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU833"
  type: "ReLU"
  bottom: "Eltwise416"
  top: "Eltwise416"
}
layer {
  name: "Convolution834"
  type: "Convolution"
  bottom: "Eltwise416"
  top: "Convolution834"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm834"
  type: "BatchNorm"
  bottom: "Convolution834"
  top: "Convolution834"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale834"
  type: "Scale"
  bottom: "Convolution834"
  top: "Convolution834"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU834"
  type: "ReLU"
  bottom: "Convolution834"
  top: "Convolution834"
}
layer {
  name: "Convolution835"
  type: "Convolution"
  bottom: "Convolution834"
  top: "Convolution835"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm835"
  type: "BatchNorm"
  bottom: "Convolution835"
  top: "Convolution835"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale835"
  type: "Scale"
  bottom: "Convolution835"
  top: "Convolution835"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise417"
  type: "Eltwise"
  bottom: "Eltwise416"
  bottom: "Convolution835"
  top: "Eltwise417"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU835"
  type: "ReLU"
  bottom: "Eltwise417"
  top: "Eltwise417"
}
layer {
  name: "Convolution836"
  type: "Convolution"
  bottom: "Eltwise417"
  top: "Convolution836"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm836"
  type: "BatchNorm"
  bottom: "Convolution836"
  top: "Convolution836"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale836"
  type: "Scale"
  bottom: "Convolution836"
  top: "Convolution836"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU836"
  type: "ReLU"
  bottom: "Convolution836"
  top: "Convolution836"
}
layer {
  name: "Convolution837"
  type: "Convolution"
  bottom: "Convolution836"
  top: "Convolution837"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm837"
  type: "BatchNorm"
  bottom: "Convolution837"
  top: "Convolution837"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale837"
  type: "Scale"
  bottom: "Convolution837"
  top: "Convolution837"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise418"
  type: "Eltwise"
  bottom: "Eltwise417"
  bottom: "Convolution837"
  top: "Eltwise418"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU837"
  type: "ReLU"
  bottom: "Eltwise418"
  top: "Eltwise418"
}
layer {
  name: "Convolution838"
  type: "Convolution"
  bottom: "Eltwise418"
  top: "Convolution838"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm838"
  type: "BatchNorm"
  bottom: "Convolution838"
  top: "Convolution838"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale838"
  type: "Scale"
  bottom: "Convolution838"
  top: "Convolution838"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU838"
  type: "ReLU"
  bottom: "Convolution838"
  top: "Convolution838"
}
layer {
  name: "Convolution839"
  type: "Convolution"
  bottom: "Convolution838"
  top: "Convolution839"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm839"
  type: "BatchNorm"
  bottom: "Convolution839"
  top: "Convolution839"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale839"
  type: "Scale"
  bottom: "Convolution839"
  top: "Convolution839"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise419"
  type: "Eltwise"
  bottom: "Eltwise418"
  bottom: "Convolution839"
  top: "Eltwise419"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU839"
  type: "ReLU"
  bottom: "Eltwise419"
  top: "Eltwise419"
}
layer {
  name: "Convolution840"
  type: "Convolution"
  bottom: "Eltwise419"
  top: "Convolution840"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm840"
  type: "BatchNorm"
  bottom: "Convolution840"
  top: "Convolution840"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale840"
  type: "Scale"
  bottom: "Convolution840"
  top: "Convolution840"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU840"
  type: "ReLU"
  bottom: "Convolution840"
  top: "Convolution840"
}
layer {
  name: "Convolution841"
  type: "Convolution"
  bottom: "Convolution840"
  top: "Convolution841"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm841"
  type: "BatchNorm"
  bottom: "Convolution841"
  top: "Convolution841"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale841"
  type: "Scale"
  bottom: "Convolution841"
  top: "Convolution841"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise420"
  type: "Eltwise"
  bottom: "Eltwise419"
  bottom: "Convolution841"
  top: "Eltwise420"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU841"
  type: "ReLU"
  bottom: "Eltwise420"
  top: "Eltwise420"
}
layer {
  name: "Convolution842"
  type: "Convolution"
  bottom: "Eltwise420"
  top: "Convolution842"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm842"
  type: "BatchNorm"
  bottom: "Convolution842"
  top: "Convolution842"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale842"
  type: "Scale"
  bottom: "Convolution842"
  top: "Convolution842"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU842"
  type: "ReLU"
  bottom: "Convolution842"
  top: "Convolution842"
}
layer {
  name: "Convolution843"
  type: "Convolution"
  bottom: "Convolution842"
  top: "Convolution843"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm843"
  type: "BatchNorm"
  bottom: "Convolution843"
  top: "Convolution843"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale843"
  type: "Scale"
  bottom: "Convolution843"
  top: "Convolution843"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise421"
  type: "Eltwise"
  bottom: "Eltwise420"
  bottom: "Convolution843"
  top: "Eltwise421"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU843"
  type: "ReLU"
  bottom: "Eltwise421"
  top: "Eltwise421"
}
layer {
  name: "Convolution844"
  type: "Convolution"
  bottom: "Eltwise421"
  top: "Convolution844"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm844"
  type: "BatchNorm"
  bottom: "Convolution844"
  top: "Convolution844"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale844"
  type: "Scale"
  bottom: "Convolution844"
  top: "Convolution844"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU844"
  type: "ReLU"
  bottom: "Convolution844"
  top: "Convolution844"
}
layer {
  name: "Convolution845"
  type: "Convolution"
  bottom: "Convolution844"
  top: "Convolution845"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm845"
  type: "BatchNorm"
  bottom: "Convolution845"
  top: "Convolution845"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale845"
  type: "Scale"
  bottom: "Convolution845"
  top: "Convolution845"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise422"
  type: "Eltwise"
  bottom: "Eltwise421"
  bottom: "Convolution845"
  top: "Eltwise422"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU845"
  type: "ReLU"
  bottom: "Eltwise422"
  top: "Eltwise422"
}
layer {
  name: "Convolution846"
  type: "Convolution"
  bottom: "Eltwise422"
  top: "Convolution846"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm846"
  type: "BatchNorm"
  bottom: "Convolution846"
  top: "Convolution846"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale846"
  type: "Scale"
  bottom: "Convolution846"
  top: "Convolution846"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU846"
  type: "ReLU"
  bottom: "Convolution846"
  top: "Convolution846"
}
layer {
  name: "Convolution847"
  type: "Convolution"
  bottom: "Convolution846"
  top: "Convolution847"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm847"
  type: "BatchNorm"
  bottom: "Convolution847"
  top: "Convolution847"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale847"
  type: "Scale"
  bottom: "Convolution847"
  top: "Convolution847"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise423"
  type: "Eltwise"
  bottom: "Eltwise422"
  bottom: "Convolution847"
  top: "Eltwise423"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU847"
  type: "ReLU"
  bottom: "Eltwise423"
  top: "Eltwise423"
}
layer {
  name: "Convolution848"
  type: "Convolution"
  bottom: "Eltwise423"
  top: "Convolution848"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm848"
  type: "BatchNorm"
  bottom: "Convolution848"
  top: "Convolution848"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale848"
  type: "Scale"
  bottom: "Convolution848"
  top: "Convolution848"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU848"
  type: "ReLU"
  bottom: "Convolution848"
  top: "Convolution848"
}
layer {
  name: "Convolution849"
  type: "Convolution"
  bottom: "Convolution848"
  top: "Convolution849"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm849"
  type: "BatchNorm"
  bottom: "Convolution849"
  top: "Convolution849"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale849"
  type: "Scale"
  bottom: "Convolution849"
  top: "Convolution849"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise424"
  type: "Eltwise"
  bottom: "Eltwise423"
  bottom: "Convolution849"
  top: "Eltwise424"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU849"
  type: "ReLU"
  bottom: "Eltwise424"
  top: "Eltwise424"
}
layer {
  name: "Convolution850"
  type: "Convolution"
  bottom: "Eltwise424"
  top: "Convolution850"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm850"
  type: "BatchNorm"
  bottom: "Convolution850"
  top: "Convolution850"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale850"
  type: "Scale"
  bottom: "Convolution850"
  top: "Convolution850"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU850"
  type: "ReLU"
  bottom: "Convolution850"
  top: "Convolution850"
}
layer {
  name: "Convolution851"
  type: "Convolution"
  bottom: "Convolution850"
  top: "Convolution851"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm851"
  type: "BatchNorm"
  bottom: "Convolution851"
  top: "Convolution851"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale851"
  type: "Scale"
  bottom: "Convolution851"
  top: "Convolution851"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise425"
  type: "Eltwise"
  bottom: "Eltwise424"
  bottom: "Convolution851"
  top: "Eltwise425"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU851"
  type: "ReLU"
  bottom: "Eltwise425"
  top: "Eltwise425"
}
layer {
  name: "Convolution852"
  type: "Convolution"
  bottom: "Eltwise425"
  top: "Convolution852"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm852"
  type: "BatchNorm"
  bottom: "Convolution852"
  top: "Convolution852"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale852"
  type: "Scale"
  bottom: "Convolution852"
  top: "Convolution852"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU852"
  type: "ReLU"
  bottom: "Convolution852"
  top: "Convolution852"
}
layer {
  name: "Convolution853"
  type: "Convolution"
  bottom: "Convolution852"
  top: "Convolution853"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm853"
  type: "BatchNorm"
  bottom: "Convolution853"
  top: "Convolution853"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale853"
  type: "Scale"
  bottom: "Convolution853"
  top: "Convolution853"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise426"
  type: "Eltwise"
  bottom: "Eltwise425"
  bottom: "Convolution853"
  top: "Eltwise426"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU853"
  type: "ReLU"
  bottom: "Eltwise426"
  top: "Eltwise426"
}
layer {
  name: "Convolution854"
  type: "Convolution"
  bottom: "Eltwise426"
  top: "Convolution854"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm854"
  type: "BatchNorm"
  bottom: "Convolution854"
  top: "Convolution854"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale854"
  type: "Scale"
  bottom: "Convolution854"
  top: "Convolution854"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU854"
  type: "ReLU"
  bottom: "Convolution854"
  top: "Convolution854"
}
layer {
  name: "Convolution855"
  type: "Convolution"
  bottom: "Convolution854"
  top: "Convolution855"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm855"
  type: "BatchNorm"
  bottom: "Convolution855"
  top: "Convolution855"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale855"
  type: "Scale"
  bottom: "Convolution855"
  top: "Convolution855"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise427"
  type: "Eltwise"
  bottom: "Eltwise426"
  bottom: "Convolution855"
  top: "Eltwise427"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU855"
  type: "ReLU"
  bottom: "Eltwise427"
  top: "Eltwise427"
}
layer {
  name: "Convolution856"
  type: "Convolution"
  bottom: "Eltwise427"
  top: "Convolution856"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm856"
  type: "BatchNorm"
  bottom: "Convolution856"
  top: "Convolution856"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale856"
  type: "Scale"
  bottom: "Convolution856"
  top: "Convolution856"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU856"
  type: "ReLU"
  bottom: "Convolution856"
  top: "Convolution856"
}
layer {
  name: "Convolution857"
  type: "Convolution"
  bottom: "Convolution856"
  top: "Convolution857"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm857"
  type: "BatchNorm"
  bottom: "Convolution857"
  top: "Convolution857"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale857"
  type: "Scale"
  bottom: "Convolution857"
  top: "Convolution857"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise428"
  type: "Eltwise"
  bottom: "Eltwise427"
  bottom: "Convolution857"
  top: "Eltwise428"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU857"
  type: "ReLU"
  bottom: "Eltwise428"
  top: "Eltwise428"
}
layer {
  name: "Convolution858"
  type: "Convolution"
  bottom: "Eltwise428"
  top: "Convolution858"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm858"
  type: "BatchNorm"
  bottom: "Convolution858"
  top: "Convolution858"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale858"
  type: "Scale"
  bottom: "Convolution858"
  top: "Convolution858"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU858"
  type: "ReLU"
  bottom: "Convolution858"
  top: "Convolution858"
}
layer {
  name: "Convolution859"
  type: "Convolution"
  bottom: "Convolution858"
  top: "Convolution859"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm859"
  type: "BatchNorm"
  bottom: "Convolution859"
  top: "Convolution859"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale859"
  type: "Scale"
  bottom: "Convolution859"
  top: "Convolution859"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise429"
  type: "Eltwise"
  bottom: "Eltwise428"
  bottom: "Convolution859"
  top: "Eltwise429"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU859"
  type: "ReLU"
  bottom: "Eltwise429"
  top: "Eltwise429"
}
layer {
  name: "Convolution860"
  type: "Convolution"
  bottom: "Eltwise429"
  top: "Convolution860"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm860"
  type: "BatchNorm"
  bottom: "Convolution860"
  top: "Convolution860"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale860"
  type: "Scale"
  bottom: "Convolution860"
  top: "Convolution860"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU860"
  type: "ReLU"
  bottom: "Convolution860"
  top: "Convolution860"
}
layer {
  name: "Convolution861"
  type: "Convolution"
  bottom: "Convolution860"
  top: "Convolution861"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm861"
  type: "BatchNorm"
  bottom: "Convolution861"
  top: "Convolution861"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale861"
  type: "Scale"
  bottom: "Convolution861"
  top: "Convolution861"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise430"
  type: "Eltwise"
  bottom: "Eltwise429"
  bottom: "Convolution861"
  top: "Eltwise430"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU861"
  type: "ReLU"
  bottom: "Eltwise430"
  top: "Eltwise430"
}
layer {
  name: "Convolution862"
  type: "Convolution"
  bottom: "Eltwise430"
  top: "Convolution862"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm862"
  type: "BatchNorm"
  bottom: "Convolution862"
  top: "Convolution862"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale862"
  type: "Scale"
  bottom: "Convolution862"
  top: "Convolution862"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU862"
  type: "ReLU"
  bottom: "Convolution862"
  top: "Convolution862"
}
layer {
  name: "Convolution863"
  type: "Convolution"
  bottom: "Convolution862"
  top: "Convolution863"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm863"
  type: "BatchNorm"
  bottom: "Convolution863"
  top: "Convolution863"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale863"
  type: "Scale"
  bottom: "Convolution863"
  top: "Convolution863"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise431"
  type: "Eltwise"
  bottom: "Eltwise430"
  bottom: "Convolution863"
  top: "Eltwise431"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU863"
  type: "ReLU"
  bottom: "Eltwise431"
  top: "Eltwise431"
}
layer {
  name: "Convolution864"
  type: "Convolution"
  bottom: "Eltwise431"
  top: "Convolution864"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm864"
  type: "BatchNorm"
  bottom: "Convolution864"
  top: "Convolution864"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale864"
  type: "Scale"
  bottom: "Convolution864"
  top: "Convolution864"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU864"
  type: "ReLU"
  bottom: "Convolution864"
  top: "Convolution864"
}
layer {
  name: "Convolution865"
  type: "Convolution"
  bottom: "Convolution864"
  top: "Convolution865"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm865"
  type: "BatchNorm"
  bottom: "Convolution865"
  top: "Convolution865"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale865"
  type: "Scale"
  bottom: "Convolution865"
  top: "Convolution865"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise432"
  type: "Eltwise"
  bottom: "Eltwise431"
  bottom: "Convolution865"
  top: "Eltwise432"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU865"
  type: "ReLU"
  bottom: "Eltwise432"
  top: "Eltwise432"
}
layer {
  name: "Convolution866"
  type: "Convolution"
  bottom: "Eltwise432"
  top: "Convolution866"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm866"
  type: "BatchNorm"
  bottom: "Convolution866"
  top: "Convolution866"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale866"
  type: "Scale"
  bottom: "Convolution866"
  top: "Convolution866"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU866"
  type: "ReLU"
  bottom: "Convolution866"
  top: "Convolution866"
}
layer {
  name: "Convolution867"
  type: "Convolution"
  bottom: "Convolution866"
  top: "Convolution867"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm867"
  type: "BatchNorm"
  bottom: "Convolution867"
  top: "Convolution867"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale867"
  type: "Scale"
  bottom: "Convolution867"
  top: "Convolution867"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise433"
  type: "Eltwise"
  bottom: "Eltwise432"
  bottom: "Convolution867"
  top: "Eltwise433"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU867"
  type: "ReLU"
  bottom: "Eltwise433"
  top: "Eltwise433"
}
layer {
  name: "Convolution868"
  type: "Convolution"
  bottom: "Eltwise433"
  top: "Convolution868"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm868"
  type: "BatchNorm"
  bottom: "Convolution868"
  top: "Convolution868"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale868"
  type: "Scale"
  bottom: "Convolution868"
  top: "Convolution868"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU868"
  type: "ReLU"
  bottom: "Convolution868"
  top: "Convolution868"
}
layer {
  name: "Convolution869"
  type: "Convolution"
  bottom: "Convolution868"
  top: "Convolution869"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm869"
  type: "BatchNorm"
  bottom: "Convolution869"
  top: "Convolution869"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale869"
  type: "Scale"
  bottom: "Convolution869"
  top: "Convolution869"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise434"
  type: "Eltwise"
  bottom: "Eltwise433"
  bottom: "Convolution869"
  top: "Eltwise434"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU869"
  type: "ReLU"
  bottom: "Eltwise434"
  top: "Eltwise434"
}
layer {
  name: "Convolution870"
  type: "Convolution"
  bottom: "Eltwise434"
  top: "Convolution870"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm870"
  type: "BatchNorm"
  bottom: "Convolution870"
  top: "Convolution870"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale870"
  type: "Scale"
  bottom: "Convolution870"
  top: "Convolution870"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU870"
  type: "ReLU"
  bottom: "Convolution870"
  top: "Convolution870"
}
layer {
  name: "Convolution871"
  type: "Convolution"
  bottom: "Convolution870"
  top: "Convolution871"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm871"
  type: "BatchNorm"
  bottom: "Convolution871"
  top: "Convolution871"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale871"
  type: "Scale"
  bottom: "Convolution871"
  top: "Convolution871"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise435"
  type: "Eltwise"
  bottom: "Eltwise434"
  bottom: "Convolution871"
  top: "Eltwise435"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU871"
  type: "ReLU"
  bottom: "Eltwise435"
  top: "Eltwise435"
}
layer {
  name: "Convolution872"
  type: "Convolution"
  bottom: "Eltwise435"
  top: "Convolution872"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm872"
  type: "BatchNorm"
  bottom: "Convolution872"
  top: "Convolution872"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale872"
  type: "Scale"
  bottom: "Convolution872"
  top: "Convolution872"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU872"
  type: "ReLU"
  bottom: "Convolution872"
  top: "Convolution872"
}
layer {
  name: "Convolution873"
  type: "Convolution"
  bottom: "Convolution872"
  top: "Convolution873"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm873"
  type: "BatchNorm"
  bottom: "Convolution873"
  top: "Convolution873"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale873"
  type: "Scale"
  bottom: "Convolution873"
  top: "Convolution873"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise436"
  type: "Eltwise"
  bottom: "Eltwise435"
  bottom: "Convolution873"
  top: "Eltwise436"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU873"
  type: "ReLU"
  bottom: "Eltwise436"
  top: "Eltwise436"
}
layer {
  name: "Convolution874"
  type: "Convolution"
  bottom: "Eltwise436"
  top: "Convolution874"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm874"
  type: "BatchNorm"
  bottom: "Convolution874"
  top: "Convolution874"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale874"
  type: "Scale"
  bottom: "Convolution874"
  top: "Convolution874"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU874"
  type: "ReLU"
  bottom: "Convolution874"
  top: "Convolution874"
}
layer {
  name: "Convolution875"
  type: "Convolution"
  bottom: "Convolution874"
  top: "Convolution875"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm875"
  type: "BatchNorm"
  bottom: "Convolution875"
  top: "Convolution875"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale875"
  type: "Scale"
  bottom: "Convolution875"
  top: "Convolution875"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise437"
  type: "Eltwise"
  bottom: "Eltwise436"
  bottom: "Convolution875"
  top: "Eltwise437"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU875"
  type: "ReLU"
  bottom: "Eltwise437"
  top: "Eltwise437"
}
layer {
  name: "Convolution876"
  type: "Convolution"
  bottom: "Eltwise437"
  top: "Convolution876"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm876"
  type: "BatchNorm"
  bottom: "Convolution876"
  top: "Convolution876"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale876"
  type: "Scale"
  bottom: "Convolution876"
  top: "Convolution876"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU876"
  type: "ReLU"
  bottom: "Convolution876"
  top: "Convolution876"
}
layer {
  name: "Convolution877"
  type: "Convolution"
  bottom: "Convolution876"
  top: "Convolution877"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm877"
  type: "BatchNorm"
  bottom: "Convolution877"
  top: "Convolution877"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale877"
  type: "Scale"
  bottom: "Convolution877"
  top: "Convolution877"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise438"
  type: "Eltwise"
  bottom: "Eltwise437"
  bottom: "Convolution877"
  top: "Eltwise438"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU877"
  type: "ReLU"
  bottom: "Eltwise438"
  top: "Eltwise438"
}
layer {
  name: "Convolution878"
  type: "Convolution"
  bottom: "Eltwise438"
  top: "Convolution878"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm878"
  type: "BatchNorm"
  bottom: "Convolution878"
  top: "Convolution878"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale878"
  type: "Scale"
  bottom: "Convolution878"
  top: "Convolution878"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU878"
  type: "ReLU"
  bottom: "Convolution878"
  top: "Convolution878"
}
layer {
  name: "Convolution879"
  type: "Convolution"
  bottom: "Convolution878"
  top: "Convolution879"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm879"
  type: "BatchNorm"
  bottom: "Convolution879"
  top: "Convolution879"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale879"
  type: "Scale"
  bottom: "Convolution879"
  top: "Convolution879"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise439"
  type: "Eltwise"
  bottom: "Eltwise438"
  bottom: "Convolution879"
  top: "Eltwise439"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU879"
  type: "ReLU"
  bottom: "Eltwise439"
  top: "Eltwise439"
}
layer {
  name: "Convolution880"
  type: "Convolution"
  bottom: "Eltwise439"
  top: "Convolution880"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm880"
  type: "BatchNorm"
  bottom: "Convolution880"
  top: "Convolution880"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale880"
  type: "Scale"
  bottom: "Convolution880"
  top: "Convolution880"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU880"
  type: "ReLU"
  bottom: "Convolution880"
  top: "Convolution880"
}
layer {
  name: "Convolution881"
  type: "Convolution"
  bottom: "Convolution880"
  top: "Convolution881"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm881"
  type: "BatchNorm"
  bottom: "Convolution881"
  top: "Convolution881"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale881"
  type: "Scale"
  bottom: "Convolution881"
  top: "Convolution881"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise440"
  type: "Eltwise"
  bottom: "Eltwise439"
  bottom: "Convolution881"
  top: "Eltwise440"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU881"
  type: "ReLU"
  bottom: "Eltwise440"
  top: "Eltwise440"
}
layer {
  name: "Convolution882"
  type: "Convolution"
  bottom: "Eltwise440"
  top: "Convolution882"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm882"
  type: "BatchNorm"
  bottom: "Convolution882"
  top: "Convolution882"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale882"
  type: "Scale"
  bottom: "Convolution882"
  top: "Convolution882"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU882"
  type: "ReLU"
  bottom: "Convolution882"
  top: "Convolution882"
}
layer {
  name: "Convolution883"
  type: "Convolution"
  bottom: "Convolution882"
  top: "Convolution883"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm883"
  type: "BatchNorm"
  bottom: "Convolution883"
  top: "Convolution883"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale883"
  type: "Scale"
  bottom: "Convolution883"
  top: "Convolution883"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise441"
  type: "Eltwise"
  bottom: "Eltwise440"
  bottom: "Convolution883"
  top: "Eltwise441"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU883"
  type: "ReLU"
  bottom: "Eltwise441"
  top: "Eltwise441"
}
layer {
  name: "Convolution884"
  type: "Convolution"
  bottom: "Eltwise441"
  top: "Convolution884"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm884"
  type: "BatchNorm"
  bottom: "Convolution884"
  top: "Convolution884"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale884"
  type: "Scale"
  bottom: "Convolution884"
  top: "Convolution884"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU884"
  type: "ReLU"
  bottom: "Convolution884"
  top: "Convolution884"
}
layer {
  name: "Convolution885"
  type: "Convolution"
  bottom: "Convolution884"
  top: "Convolution885"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm885"
  type: "BatchNorm"
  bottom: "Convolution885"
  top: "Convolution885"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale885"
  type: "Scale"
  bottom: "Convolution885"
  top: "Convolution885"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise442"
  type: "Eltwise"
  bottom: "Eltwise441"
  bottom: "Convolution885"
  top: "Eltwise442"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU885"
  type: "ReLU"
  bottom: "Eltwise442"
  top: "Eltwise442"
}
layer {
  name: "Convolution886"
  type: "Convolution"
  bottom: "Eltwise442"
  top: "Convolution886"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm886"
  type: "BatchNorm"
  bottom: "Convolution886"
  top: "Convolution886"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale886"
  type: "Scale"
  bottom: "Convolution886"
  top: "Convolution886"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU886"
  type: "ReLU"
  bottom: "Convolution886"
  top: "Convolution886"
}
layer {
  name: "Convolution887"
  type: "Convolution"
  bottom: "Convolution886"
  top: "Convolution887"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm887"
  type: "BatchNorm"
  bottom: "Convolution887"
  top: "Convolution887"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale887"
  type: "Scale"
  bottom: "Convolution887"
  top: "Convolution887"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise443"
  type: "Eltwise"
  bottom: "Eltwise442"
  bottom: "Convolution887"
  top: "Eltwise443"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU887"
  type: "ReLU"
  bottom: "Eltwise443"
  top: "Eltwise443"
}
layer {
  name: "Convolution888"
  type: "Convolution"
  bottom: "Eltwise443"
  top: "Convolution888"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm888"
  type: "BatchNorm"
  bottom: "Convolution888"
  top: "Convolution888"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale888"
  type: "Scale"
  bottom: "Convolution888"
  top: "Convolution888"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU888"
  type: "ReLU"
  bottom: "Convolution888"
  top: "Convolution888"
}
layer {
  name: "Convolution889"
  type: "Convolution"
  bottom: "Convolution888"
  top: "Convolution889"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm889"
  type: "BatchNorm"
  bottom: "Convolution889"
  top: "Convolution889"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale889"
  type: "Scale"
  bottom: "Convolution889"
  top: "Convolution889"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise444"
  type: "Eltwise"
  bottom: "Eltwise443"
  bottom: "Convolution889"
  top: "Eltwise444"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU889"
  type: "ReLU"
  bottom: "Eltwise444"
  top: "Eltwise444"
}
layer {
  name: "Convolution890"
  type: "Convolution"
  bottom: "Eltwise444"
  top: "Convolution890"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm890"
  type: "BatchNorm"
  bottom: "Convolution890"
  top: "Convolution890"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale890"
  type: "Scale"
  bottom: "Convolution890"
  top: "Convolution890"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU890"
  type: "ReLU"
  bottom: "Convolution890"
  top: "Convolution890"
}
layer {
  name: "Convolution891"
  type: "Convolution"
  bottom: "Convolution890"
  top: "Convolution891"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm891"
  type: "BatchNorm"
  bottom: "Convolution891"
  top: "Convolution891"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale891"
  type: "Scale"
  bottom: "Convolution891"
  top: "Convolution891"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise445"
  type: "Eltwise"
  bottom: "Eltwise444"
  bottom: "Convolution891"
  top: "Eltwise445"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU891"
  type: "ReLU"
  bottom: "Eltwise445"
  top: "Eltwise445"
}
layer {
  name: "Convolution892"
  type: "Convolution"
  bottom: "Eltwise445"
  top: "Convolution892"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm892"
  type: "BatchNorm"
  bottom: "Convolution892"
  top: "Convolution892"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale892"
  type: "Scale"
  bottom: "Convolution892"
  top: "Convolution892"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU892"
  type: "ReLU"
  bottom: "Convolution892"
  top: "Convolution892"
}
layer {
  name: "Convolution893"
  type: "Convolution"
  bottom: "Convolution892"
  top: "Convolution893"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm893"
  type: "BatchNorm"
  bottom: "Convolution893"
  top: "Convolution893"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale893"
  type: "Scale"
  bottom: "Convolution893"
  top: "Convolution893"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise446"
  type: "Eltwise"
  bottom: "Eltwise445"
  bottom: "Convolution893"
  top: "Eltwise446"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU893"
  type: "ReLU"
  bottom: "Eltwise446"
  top: "Eltwise446"
}
layer {
  name: "Convolution894"
  type: "Convolution"
  bottom: "Eltwise446"
  top: "Convolution894"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm894"
  type: "BatchNorm"
  bottom: "Convolution894"
  top: "Convolution894"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale894"
  type: "Scale"
  bottom: "Convolution894"
  top: "Convolution894"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU894"
  type: "ReLU"
  bottom: "Convolution894"
  top: "Convolution894"
}
layer {
  name: "Convolution895"
  type: "Convolution"
  bottom: "Convolution894"
  top: "Convolution895"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm895"
  type: "BatchNorm"
  bottom: "Convolution895"
  top: "Convolution895"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale895"
  type: "Scale"
  bottom: "Convolution895"
  top: "Convolution895"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise447"
  type: "Eltwise"
  bottom: "Eltwise446"
  bottom: "Convolution895"
  top: "Eltwise447"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU895"
  type: "ReLU"
  bottom: "Eltwise447"
  top: "Eltwise447"
}
layer {
  name: "Convolution896"
  type: "Convolution"
  bottom: "Eltwise447"
  top: "Convolution896"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm896"
  type: "BatchNorm"
  bottom: "Convolution896"
  top: "Convolution896"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale896"
  type: "Scale"
  bottom: "Convolution896"
  top: "Convolution896"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU896"
  type: "ReLU"
  bottom: "Convolution896"
  top: "Convolution896"
}
layer {
  name: "Convolution897"
  type: "Convolution"
  bottom: "Convolution896"
  top: "Convolution897"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm897"
  type: "BatchNorm"
  bottom: "Convolution897"
  top: "Convolution897"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale897"
  type: "Scale"
  bottom: "Convolution897"
  top: "Convolution897"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise448"
  type: "Eltwise"
  bottom: "Eltwise447"
  bottom: "Convolution897"
  top: "Eltwise448"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU897"
  type: "ReLU"
  bottom: "Eltwise448"
  top: "Eltwise448"
}
layer {
  name: "Convolution898"
  type: "Convolution"
  bottom: "Eltwise448"
  top: "Convolution898"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm898"
  type: "BatchNorm"
  bottom: "Convolution898"
  top: "Convolution898"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale898"
  type: "Scale"
  bottom: "Convolution898"
  top: "Convolution898"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU898"
  type: "ReLU"
  bottom: "Convolution898"
  top: "Convolution898"
}
layer {
  name: "Convolution899"
  type: "Convolution"
  bottom: "Convolution898"
  top: "Convolution899"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm899"
  type: "BatchNorm"
  bottom: "Convolution899"
  top: "Convolution899"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale899"
  type: "Scale"
  bottom: "Convolution899"
  top: "Convolution899"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise449"
  type: "Eltwise"
  bottom: "Eltwise448"
  bottom: "Convolution899"
  top: "Eltwise449"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU899"
  type: "ReLU"
  bottom: "Eltwise449"
  top: "Eltwise449"
}
layer {
  name: "Convolution900"
  type: "Convolution"
  bottom: "Eltwise449"
  top: "Convolution900"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm900"
  type: "BatchNorm"
  bottom: "Convolution900"
  top: "Convolution900"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale900"
  type: "Scale"
  bottom: "Convolution900"
  top: "Convolution900"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU900"
  type: "ReLU"
  bottom: "Convolution900"
  top: "Convolution900"
}
layer {
  name: "Convolution901"
  type: "Convolution"
  bottom: "Convolution900"
  top: "Convolution901"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm901"
  type: "BatchNorm"
  bottom: "Convolution901"
  top: "Convolution901"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale901"
  type: "Scale"
  bottom: "Convolution901"
  top: "Convolution901"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise450"
  type: "Eltwise"
  bottom: "Eltwise449"
  bottom: "Convolution901"
  top: "Eltwise450"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU901"
  type: "ReLU"
  bottom: "Eltwise450"
  top: "Eltwise450"
}
layer {
  name: "Convolution902"
  type: "Convolution"
  bottom: "Eltwise450"
  top: "Convolution902"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm902"
  type: "BatchNorm"
  bottom: "Convolution902"
  top: "Convolution902"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale902"
  type: "Scale"
  bottom: "Convolution902"
  top: "Convolution902"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU902"
  type: "ReLU"
  bottom: "Convolution902"
  top: "Convolution902"
}
layer {
  name: "Convolution903"
  type: "Convolution"
  bottom: "Convolution902"
  top: "Convolution903"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm903"
  type: "BatchNorm"
  bottom: "Convolution903"
  top: "Convolution903"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale903"
  type: "Scale"
  bottom: "Convolution903"
  top: "Convolution903"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise451"
  type: "Eltwise"
  bottom: "Eltwise450"
  bottom: "Convolution903"
  top: "Eltwise451"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU903"
  type: "ReLU"
  bottom: "Eltwise451"
  top: "Eltwise451"
}
layer {
  name: "Convolution904"
  type: "Convolution"
  bottom: "Eltwise451"
  top: "Convolution904"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm904"
  type: "BatchNorm"
  bottom: "Convolution904"
  top: "Convolution904"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale904"
  type: "Scale"
  bottom: "Convolution904"
  top: "Convolution904"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU904"
  type: "ReLU"
  bottom: "Convolution904"
  top: "Convolution904"
}
layer {
  name: "Convolution905"
  type: "Convolution"
  bottom: "Convolution904"
  top: "Convolution905"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm905"
  type: "BatchNorm"
  bottom: "Convolution905"
  top: "Convolution905"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale905"
  type: "Scale"
  bottom: "Convolution905"
  top: "Convolution905"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise452"
  type: "Eltwise"
  bottom: "Eltwise451"
  bottom: "Convolution905"
  top: "Eltwise452"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU905"
  type: "ReLU"
  bottom: "Eltwise452"
  top: "Eltwise452"
}
layer {
  name: "Convolution906"
  type: "Convolution"
  bottom: "Eltwise452"
  top: "Convolution906"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm906"
  type: "BatchNorm"
  bottom: "Convolution906"
  top: "Convolution906"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale906"
  type: "Scale"
  bottom: "Convolution906"
  top: "Convolution906"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU906"
  type: "ReLU"
  bottom: "Convolution906"
  top: "Convolution906"
}
layer {
  name: "Convolution907"
  type: "Convolution"
  bottom: "Convolution906"
  top: "Convolution907"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm907"
  type: "BatchNorm"
  bottom: "Convolution907"
  top: "Convolution907"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale907"
  type: "Scale"
  bottom: "Convolution907"
  top: "Convolution907"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise453"
  type: "Eltwise"
  bottom: "Eltwise452"
  bottom: "Convolution907"
  top: "Eltwise453"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU907"
  type: "ReLU"
  bottom: "Eltwise453"
  top: "Eltwise453"
}
layer {
  name: "Convolution908"
  type: "Convolution"
  bottom: "Eltwise453"
  top: "Convolution908"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm908"
  type: "BatchNorm"
  bottom: "Convolution908"
  top: "Convolution908"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale908"
  type: "Scale"
  bottom: "Convolution908"
  top: "Convolution908"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU908"
  type: "ReLU"
  bottom: "Convolution908"
  top: "Convolution908"
}
layer {
  name: "Convolution909"
  type: "Convolution"
  bottom: "Convolution908"
  top: "Convolution909"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm909"
  type: "BatchNorm"
  bottom: "Convolution909"
  top: "Convolution909"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale909"
  type: "Scale"
  bottom: "Convolution909"
  top: "Convolution909"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise454"
  type: "Eltwise"
  bottom: "Eltwise453"
  bottom: "Convolution909"
  top: "Eltwise454"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU909"
  type: "ReLU"
  bottom: "Eltwise454"
  top: "Eltwise454"
}
layer {
  name: "Convolution910"
  type: "Convolution"
  bottom: "Eltwise454"
  top: "Convolution910"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm910"
  type: "BatchNorm"
  bottom: "Convolution910"
  top: "Convolution910"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale910"
  type: "Scale"
  bottom: "Convolution910"
  top: "Convolution910"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU910"
  type: "ReLU"
  bottom: "Convolution910"
  top: "Convolution910"
}
layer {
  name: "Convolution911"
  type: "Convolution"
  bottom: "Convolution910"
  top: "Convolution911"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm911"
  type: "BatchNorm"
  bottom: "Convolution911"
  top: "Convolution911"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale911"
  type: "Scale"
  bottom: "Convolution911"
  top: "Convolution911"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise455"
  type: "Eltwise"
  bottom: "Eltwise454"
  bottom: "Convolution911"
  top: "Eltwise455"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU911"
  type: "ReLU"
  bottom: "Eltwise455"
  top: "Eltwise455"
}
layer {
  name: "Convolution912"
  type: "Convolution"
  bottom: "Eltwise455"
  top: "Convolution912"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm912"
  type: "BatchNorm"
  bottom: "Convolution912"
  top: "Convolution912"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale912"
  type: "Scale"
  bottom: "Convolution912"
  top: "Convolution912"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU912"
  type: "ReLU"
  bottom: "Convolution912"
  top: "Convolution912"
}
layer {
  name: "Convolution913"
  type: "Convolution"
  bottom: "Convolution912"
  top: "Convolution913"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm913"
  type: "BatchNorm"
  bottom: "Convolution913"
  top: "Convolution913"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale913"
  type: "Scale"
  bottom: "Convolution913"
  top: "Convolution913"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise456"
  type: "Eltwise"
  bottom: "Eltwise455"
  bottom: "Convolution913"
  top: "Eltwise456"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU913"
  type: "ReLU"
  bottom: "Eltwise456"
  top: "Eltwise456"
}
layer {
  name: "Convolution914"
  type: "Convolution"
  bottom: "Eltwise456"
  top: "Convolution914"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm914"
  type: "BatchNorm"
  bottom: "Convolution914"
  top: "Convolution914"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale914"
  type: "Scale"
  bottom: "Convolution914"
  top: "Convolution914"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU914"
  type: "ReLU"
  bottom: "Convolution914"
  top: "Convolution914"
}
layer {
  name: "Convolution915"
  type: "Convolution"
  bottom: "Convolution914"
  top: "Convolution915"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm915"
  type: "BatchNorm"
  bottom: "Convolution915"
  top: "Convolution915"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale915"
  type: "Scale"
  bottom: "Convolution915"
  top: "Convolution915"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise457"
  type: "Eltwise"
  bottom: "Eltwise456"
  bottom: "Convolution915"
  top: "Eltwise457"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU915"
  type: "ReLU"
  bottom: "Eltwise457"
  top: "Eltwise457"
}
layer {
  name: "Convolution916"
  type: "Convolution"
  bottom: "Eltwise457"
  top: "Convolution916"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm916"
  type: "BatchNorm"
  bottom: "Convolution916"
  top: "Convolution916"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale916"
  type: "Scale"
  bottom: "Convolution916"
  top: "Convolution916"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU916"
  type: "ReLU"
  bottom: "Convolution916"
  top: "Convolution916"
}
layer {
  name: "Convolution917"
  type: "Convolution"
  bottom: "Convolution916"
  top: "Convolution917"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm917"
  type: "BatchNorm"
  bottom: "Convolution917"
  top: "Convolution917"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale917"
  type: "Scale"
  bottom: "Convolution917"
  top: "Convolution917"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise458"
  type: "Eltwise"
  bottom: "Eltwise457"
  bottom: "Convolution917"
  top: "Eltwise458"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU917"
  type: "ReLU"
  bottom: "Eltwise458"
  top: "Eltwise458"
}
layer {
  name: "Convolution918"
  type: "Convolution"
  bottom: "Eltwise458"
  top: "Convolution918"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm918"
  type: "BatchNorm"
  bottom: "Convolution918"
  top: "Convolution918"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale918"
  type: "Scale"
  bottom: "Convolution918"
  top: "Convolution918"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU918"
  type: "ReLU"
  bottom: "Convolution918"
  top: "Convolution918"
}
layer {
  name: "Convolution919"
  type: "Convolution"
  bottom: "Convolution918"
  top: "Convolution919"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm919"
  type: "BatchNorm"
  bottom: "Convolution919"
  top: "Convolution919"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale919"
  type: "Scale"
  bottom: "Convolution919"
  top: "Convolution919"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise459"
  type: "Eltwise"
  bottom: "Eltwise458"
  bottom: "Convolution919"
  top: "Eltwise459"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU919"
  type: "ReLU"
  bottom: "Eltwise459"
  top: "Eltwise459"
}
layer {
  name: "Convolution920"
  type: "Convolution"
  bottom: "Eltwise459"
  top: "Convolution920"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm920"
  type: "BatchNorm"
  bottom: "Convolution920"
  top: "Convolution920"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale920"
  type: "Scale"
  bottom: "Convolution920"
  top: "Convolution920"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU920"
  type: "ReLU"
  bottom: "Convolution920"
  top: "Convolution920"
}
layer {
  name: "Convolution921"
  type: "Convolution"
  bottom: "Convolution920"
  top: "Convolution921"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm921"
  type: "BatchNorm"
  bottom: "Convolution921"
  top: "Convolution921"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale921"
  type: "Scale"
  bottom: "Convolution921"
  top: "Convolution921"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise460"
  type: "Eltwise"
  bottom: "Eltwise459"
  bottom: "Convolution921"
  top: "Eltwise460"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU921"
  type: "ReLU"
  bottom: "Eltwise460"
  top: "Eltwise460"
}
layer {
  name: "Convolution922"
  type: "Convolution"
  bottom: "Eltwise460"
  top: "Convolution922"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm922"
  type: "BatchNorm"
  bottom: "Convolution922"
  top: "Convolution922"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale922"
  type: "Scale"
  bottom: "Convolution922"
  top: "Convolution922"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU922"
  type: "ReLU"
  bottom: "Convolution922"
  top: "Convolution922"
}
layer {
  name: "Convolution923"
  type: "Convolution"
  bottom: "Convolution922"
  top: "Convolution923"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm923"
  type: "BatchNorm"
  bottom: "Convolution923"
  top: "Convolution923"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale923"
  type: "Scale"
  bottom: "Convolution923"
  top: "Convolution923"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise461"
  type: "Eltwise"
  bottom: "Eltwise460"
  bottom: "Convolution923"
  top: "Eltwise461"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU923"
  type: "ReLU"
  bottom: "Eltwise461"
  top: "Eltwise461"
}
layer {
  name: "Convolution924"
  type: "Convolution"
  bottom: "Eltwise461"
  top: "Convolution924"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm924"
  type: "BatchNorm"
  bottom: "Convolution924"
  top: "Convolution924"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale924"
  type: "Scale"
  bottom: "Convolution924"
  top: "Convolution924"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU924"
  type: "ReLU"
  bottom: "Convolution924"
  top: "Convolution924"
}
layer {
  name: "Convolution925"
  type: "Convolution"
  bottom: "Convolution924"
  top: "Convolution925"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm925"
  type: "BatchNorm"
  bottom: "Convolution925"
  top: "Convolution925"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale925"
  type: "Scale"
  bottom: "Convolution925"
  top: "Convolution925"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise462"
  type: "Eltwise"
  bottom: "Eltwise461"
  bottom: "Convolution925"
  top: "Eltwise462"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU925"
  type: "ReLU"
  bottom: "Eltwise462"
  top: "Eltwise462"
}
layer {
  name: "Convolution926"
  type: "Convolution"
  bottom: "Eltwise462"
  top: "Convolution926"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm926"
  type: "BatchNorm"
  bottom: "Convolution926"
  top: "Convolution926"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale926"
  type: "Scale"
  bottom: "Convolution926"
  top: "Convolution926"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU926"
  type: "ReLU"
  bottom: "Convolution926"
  top: "Convolution926"
}
layer {
  name: "Convolution927"
  type: "Convolution"
  bottom: "Convolution926"
  top: "Convolution927"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm927"
  type: "BatchNorm"
  bottom: "Convolution927"
  top: "Convolution927"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale927"
  type: "Scale"
  bottom: "Convolution927"
  top: "Convolution927"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise463"
  type: "Eltwise"
  bottom: "Eltwise462"
  bottom: "Convolution927"
  top: "Eltwise463"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU927"
  type: "ReLU"
  bottom: "Eltwise463"
  top: "Eltwise463"
}
layer {
  name: "Convolution928"
  type: "Convolution"
  bottom: "Eltwise463"
  top: "Convolution928"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm928"
  type: "BatchNorm"
  bottom: "Convolution928"
  top: "Convolution928"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale928"
  type: "Scale"
  bottom: "Convolution928"
  top: "Convolution928"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU928"
  type: "ReLU"
  bottom: "Convolution928"
  top: "Convolution928"
}
layer {
  name: "Convolution929"
  type: "Convolution"
  bottom: "Convolution928"
  top: "Convolution929"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm929"
  type: "BatchNorm"
  bottom: "Convolution929"
  top: "Convolution929"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale929"
  type: "Scale"
  bottom: "Convolution929"
  top: "Convolution929"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise464"
  type: "Eltwise"
  bottom: "Eltwise463"
  bottom: "Convolution929"
  top: "Eltwise464"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU929"
  type: "ReLU"
  bottom: "Eltwise464"
  top: "Eltwise464"
}
layer {
  name: "Convolution930"
  type: "Convolution"
  bottom: "Eltwise464"
  top: "Convolution930"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm930"
  type: "BatchNorm"
  bottom: "Convolution930"
  top: "Convolution930"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale930"
  type: "Scale"
  bottom: "Convolution930"
  top: "Convolution930"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU930"
  type: "ReLU"
  bottom: "Convolution930"
  top: "Convolution930"
}
layer {
  name: "Convolution931"
  type: "Convolution"
  bottom: "Convolution930"
  top: "Convolution931"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm931"
  type: "BatchNorm"
  bottom: "Convolution931"
  top: "Convolution931"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale931"
  type: "Scale"
  bottom: "Convolution931"
  top: "Convolution931"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise465"
  type: "Eltwise"
  bottom: "Eltwise464"
  bottom: "Convolution931"
  top: "Eltwise465"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU931"
  type: "ReLU"
  bottom: "Eltwise465"
  top: "Eltwise465"
}
layer {
  name: "Convolution932"
  type: "Convolution"
  bottom: "Eltwise465"
  top: "Convolution932"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm932"
  type: "BatchNorm"
  bottom: "Convolution932"
  top: "Convolution932"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale932"
  type: "Scale"
  bottom: "Convolution932"
  top: "Convolution932"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU932"
  type: "ReLU"
  bottom: "Convolution932"
  top: "Convolution932"
}
layer {
  name: "Convolution933"
  type: "Convolution"
  bottom: "Convolution932"
  top: "Convolution933"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm933"
  type: "BatchNorm"
  bottom: "Convolution933"
  top: "Convolution933"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale933"
  type: "Scale"
  bottom: "Convolution933"
  top: "Convolution933"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise466"
  type: "Eltwise"
  bottom: "Eltwise465"
  bottom: "Convolution933"
  top: "Eltwise466"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU933"
  type: "ReLU"
  bottom: "Eltwise466"
  top: "Eltwise466"
}
layer {
  name: "Convolution934"
  type: "Convolution"
  bottom: "Eltwise466"
  top: "Convolution934"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm934"
  type: "BatchNorm"
  bottom: "Convolution934"
  top: "Convolution934"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale934"
  type: "Scale"
  bottom: "Convolution934"
  top: "Convolution934"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU934"
  type: "ReLU"
  bottom: "Convolution934"
  top: "Convolution934"
}
layer {
  name: "Convolution935"
  type: "Convolution"
  bottom: "Convolution934"
  top: "Convolution935"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm935"
  type: "BatchNorm"
  bottom: "Convolution935"
  top: "Convolution935"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale935"
  type: "Scale"
  bottom: "Convolution935"
  top: "Convolution935"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise467"
  type: "Eltwise"
  bottom: "Eltwise466"
  bottom: "Convolution935"
  top: "Eltwise467"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU935"
  type: "ReLU"
  bottom: "Eltwise467"
  top: "Eltwise467"
}
layer {
  name: "Convolution936"
  type: "Convolution"
  bottom: "Eltwise467"
  top: "Convolution936"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm936"
  type: "BatchNorm"
  bottom: "Convolution936"
  top: "Convolution936"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale936"
  type: "Scale"
  bottom: "Convolution936"
  top: "Convolution936"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU936"
  type: "ReLU"
  bottom: "Convolution936"
  top: "Convolution936"
}
layer {
  name: "Convolution937"
  type: "Convolution"
  bottom: "Convolution936"
  top: "Convolution937"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm937"
  type: "BatchNorm"
  bottom: "Convolution937"
  top: "Convolution937"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale937"
  type: "Scale"
  bottom: "Convolution937"
  top: "Convolution937"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise468"
  type: "Eltwise"
  bottom: "Eltwise467"
  bottom: "Convolution937"
  top: "Eltwise468"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU937"
  type: "ReLU"
  bottom: "Eltwise468"
  top: "Eltwise468"
}
layer {
  name: "Convolution938"
  type: "Convolution"
  bottom: "Eltwise468"
  top: "Convolution938"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm938"
  type: "BatchNorm"
  bottom: "Convolution938"
  top: "Convolution938"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale938"
  type: "Scale"
  bottom: "Convolution938"
  top: "Convolution938"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU938"
  type: "ReLU"
  bottom: "Convolution938"
  top: "Convolution938"
}
layer {
  name: "Convolution939"
  type: "Convolution"
  bottom: "Convolution938"
  top: "Convolution939"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm939"
  type: "BatchNorm"
  bottom: "Convolution939"
  top: "Convolution939"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale939"
  type: "Scale"
  bottom: "Convolution939"
  top: "Convolution939"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise469"
  type: "Eltwise"
  bottom: "Eltwise468"
  bottom: "Convolution939"
  top: "Eltwise469"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU939"
  type: "ReLU"
  bottom: "Eltwise469"
  top: "Eltwise469"
}
layer {
  name: "Convolution940"
  type: "Convolution"
  bottom: "Eltwise469"
  top: "Convolution940"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm940"
  type: "BatchNorm"
  bottom: "Convolution940"
  top: "Convolution940"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale940"
  type: "Scale"
  bottom: "Convolution940"
  top: "Convolution940"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU940"
  type: "ReLU"
  bottom: "Convolution940"
  top: "Convolution940"
}
layer {
  name: "Convolution941"
  type: "Convolution"
  bottom: "Convolution940"
  top: "Convolution941"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm941"
  type: "BatchNorm"
  bottom: "Convolution941"
  top: "Convolution941"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale941"
  type: "Scale"
  bottom: "Convolution941"
  top: "Convolution941"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise470"
  type: "Eltwise"
  bottom: "Eltwise469"
  bottom: "Convolution941"
  top: "Eltwise470"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU941"
  type: "ReLU"
  bottom: "Eltwise470"
  top: "Eltwise470"
}
layer {
  name: "Convolution942"
  type: "Convolution"
  bottom: "Eltwise470"
  top: "Convolution942"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm942"
  type: "BatchNorm"
  bottom: "Convolution942"
  top: "Convolution942"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale942"
  type: "Scale"
  bottom: "Convolution942"
  top: "Convolution942"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU942"
  type: "ReLU"
  bottom: "Convolution942"
  top: "Convolution942"
}
layer {
  name: "Convolution943"
  type: "Convolution"
  bottom: "Convolution942"
  top: "Convolution943"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm943"
  type: "BatchNorm"
  bottom: "Convolution943"
  top: "Convolution943"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale943"
  type: "Scale"
  bottom: "Convolution943"
  top: "Convolution943"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise471"
  type: "Eltwise"
  bottom: "Eltwise470"
  bottom: "Convolution943"
  top: "Eltwise471"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU943"
  type: "ReLU"
  bottom: "Eltwise471"
  top: "Eltwise471"
}
layer {
  name: "Convolution944"
  type: "Convolution"
  bottom: "Eltwise471"
  top: "Convolution944"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm944"
  type: "BatchNorm"
  bottom: "Convolution944"
  top: "Convolution944"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale944"
  type: "Scale"
  bottom: "Convolution944"
  top: "Convolution944"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU944"
  type: "ReLU"
  bottom: "Convolution944"
  top: "Convolution944"
}
layer {
  name: "Convolution945"
  type: "Convolution"
  bottom: "Convolution944"
  top: "Convolution945"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm945"
  type: "BatchNorm"
  bottom: "Convolution945"
  top: "Convolution945"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale945"
  type: "Scale"
  bottom: "Convolution945"
  top: "Convolution945"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise472"
  type: "Eltwise"
  bottom: "Eltwise471"
  bottom: "Convolution945"
  top: "Eltwise472"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU945"
  type: "ReLU"
  bottom: "Eltwise472"
  top: "Eltwise472"
}
layer {
  name: "Convolution946"
  type: "Convolution"
  bottom: "Eltwise472"
  top: "Convolution946"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm946"
  type: "BatchNorm"
  bottom: "Convolution946"
  top: "Convolution946"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale946"
  type: "Scale"
  bottom: "Convolution946"
  top: "Convolution946"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU946"
  type: "ReLU"
  bottom: "Convolution946"
  top: "Convolution946"
}
layer {
  name: "Convolution947"
  type: "Convolution"
  bottom: "Convolution946"
  top: "Convolution947"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm947"
  type: "BatchNorm"
  bottom: "Convolution947"
  top: "Convolution947"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale947"
  type: "Scale"
  bottom: "Convolution947"
  top: "Convolution947"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise473"
  type: "Eltwise"
  bottom: "Eltwise472"
  bottom: "Convolution947"
  top: "Eltwise473"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU947"
  type: "ReLU"
  bottom: "Eltwise473"
  top: "Eltwise473"
}
layer {
  name: "Convolution948"
  type: "Convolution"
  bottom: "Eltwise473"
  top: "Convolution948"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm948"
  type: "BatchNorm"
  bottom: "Convolution948"
  top: "Convolution948"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale948"
  type: "Scale"
  bottom: "Convolution948"
  top: "Convolution948"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU948"
  type: "ReLU"
  bottom: "Convolution948"
  top: "Convolution948"
}
layer {
  name: "Convolution949"
  type: "Convolution"
  bottom: "Convolution948"
  top: "Convolution949"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm949"
  type: "BatchNorm"
  bottom: "Convolution949"
  top: "Convolution949"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale949"
  type: "Scale"
  bottom: "Convolution949"
  top: "Convolution949"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise474"
  type: "Eltwise"
  bottom: "Eltwise473"
  bottom: "Convolution949"
  top: "Eltwise474"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU949"
  type: "ReLU"
  bottom: "Eltwise474"
  top: "Eltwise474"
}
layer {
  name: "Convolution950"
  type: "Convolution"
  bottom: "Eltwise474"
  top: "Convolution950"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm950"
  type: "BatchNorm"
  bottom: "Convolution950"
  top: "Convolution950"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale950"
  type: "Scale"
  bottom: "Convolution950"
  top: "Convolution950"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU950"
  type: "ReLU"
  bottom: "Convolution950"
  top: "Convolution950"
}
layer {
  name: "Convolution951"
  type: "Convolution"
  bottom: "Convolution950"
  top: "Convolution951"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm951"
  type: "BatchNorm"
  bottom: "Convolution951"
  top: "Convolution951"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale951"
  type: "Scale"
  bottom: "Convolution951"
  top: "Convolution951"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise475"
  type: "Eltwise"
  bottom: "Eltwise474"
  bottom: "Convolution951"
  top: "Eltwise475"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU951"
  type: "ReLU"
  bottom: "Eltwise475"
  top: "Eltwise475"
}
layer {
  name: "Convolution952"
  type: "Convolution"
  bottom: "Eltwise475"
  top: "Convolution952"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm952"
  type: "BatchNorm"
  bottom: "Convolution952"
  top: "Convolution952"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale952"
  type: "Scale"
  bottom: "Convolution952"
  top: "Convolution952"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU952"
  type: "ReLU"
  bottom: "Convolution952"
  top: "Convolution952"
}
layer {
  name: "Convolution953"
  type: "Convolution"
  bottom: "Convolution952"
  top: "Convolution953"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm953"
  type: "BatchNorm"
  bottom: "Convolution953"
  top: "Convolution953"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale953"
  type: "Scale"
  bottom: "Convolution953"
  top: "Convolution953"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise476"
  type: "Eltwise"
  bottom: "Eltwise475"
  bottom: "Convolution953"
  top: "Eltwise476"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU953"
  type: "ReLU"
  bottom: "Eltwise476"
  top: "Eltwise476"
}
layer {
  name: "Convolution954"
  type: "Convolution"
  bottom: "Eltwise476"
  top: "Convolution954"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm954"
  type: "BatchNorm"
  bottom: "Convolution954"
  top: "Convolution954"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale954"
  type: "Scale"
  bottom: "Convolution954"
  top: "Convolution954"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU954"
  type: "ReLU"
  bottom: "Convolution954"
  top: "Convolution954"
}
layer {
  name: "Convolution955"
  type: "Convolution"
  bottom: "Convolution954"
  top: "Convolution955"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm955"
  type: "BatchNorm"
  bottom: "Convolution955"
  top: "Convolution955"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale955"
  type: "Scale"
  bottom: "Convolution955"
  top: "Convolution955"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise477"
  type: "Eltwise"
  bottom: "Eltwise476"
  bottom: "Convolution955"
  top: "Eltwise477"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU955"
  type: "ReLU"
  bottom: "Eltwise477"
  top: "Eltwise477"
}
layer {
  name: "Convolution956"
  type: "Convolution"
  bottom: "Eltwise477"
  top: "Convolution956"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm956"
  type: "BatchNorm"
  bottom: "Convolution956"
  top: "Convolution956"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale956"
  type: "Scale"
  bottom: "Convolution956"
  top: "Convolution956"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU956"
  type: "ReLU"
  bottom: "Convolution956"
  top: "Convolution956"
}
layer {
  name: "Convolution957"
  type: "Convolution"
  bottom: "Convolution956"
  top: "Convolution957"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm957"
  type: "BatchNorm"
  bottom: "Convolution957"
  top: "Convolution957"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale957"
  type: "Scale"
  bottom: "Convolution957"
  top: "Convolution957"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise478"
  type: "Eltwise"
  bottom: "Eltwise477"
  bottom: "Convolution957"
  top: "Eltwise478"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU957"
  type: "ReLU"
  bottom: "Eltwise478"
  top: "Eltwise478"
}
layer {
  name: "Convolution958"
  type: "Convolution"
  bottom: "Eltwise478"
  top: "Convolution958"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm958"
  type: "BatchNorm"
  bottom: "Convolution958"
  top: "Convolution958"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale958"
  type: "Scale"
  bottom: "Convolution958"
  top: "Convolution958"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU958"
  type: "ReLU"
  bottom: "Convolution958"
  top: "Convolution958"
}
layer {
  name: "Convolution959"
  type: "Convolution"
  bottom: "Convolution958"
  top: "Convolution959"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm959"
  type: "BatchNorm"
  bottom: "Convolution959"
  top: "Convolution959"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale959"
  type: "Scale"
  bottom: "Convolution959"
  top: "Convolution959"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise479"
  type: "Eltwise"
  bottom: "Eltwise478"
  bottom: "Convolution959"
  top: "Eltwise479"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU959"
  type: "ReLU"
  bottom: "Eltwise479"
  top: "Eltwise479"
}
layer {
  name: "Convolution960"
  type: "Convolution"
  bottom: "Eltwise479"
  top: "Convolution960"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm960"
  type: "BatchNorm"
  bottom: "Convolution960"
  top: "Convolution960"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale960"
  type: "Scale"
  bottom: "Convolution960"
  top: "Convolution960"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU960"
  type: "ReLU"
  bottom: "Convolution960"
  top: "Convolution960"
}
layer {
  name: "Convolution961"
  type: "Convolution"
  bottom: "Convolution960"
  top: "Convolution961"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm961"
  type: "BatchNorm"
  bottom: "Convolution961"
  top: "Convolution961"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale961"
  type: "Scale"
  bottom: "Convolution961"
  top: "Convolution961"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise480"
  type: "Eltwise"
  bottom: "Eltwise479"
  bottom: "Convolution961"
  top: "Eltwise480"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU961"
  type: "ReLU"
  bottom: "Eltwise480"
  top: "Eltwise480"
}
layer {
  name: "Convolution962"
  type: "Convolution"
  bottom: "Eltwise480"
  top: "Convolution962"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm962"
  type: "BatchNorm"
  bottom: "Convolution962"
  top: "Convolution962"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale962"
  type: "Scale"
  bottom: "Convolution962"
  top: "Convolution962"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU962"
  type: "ReLU"
  bottom: "Convolution962"
  top: "Convolution962"
}
layer {
  name: "Convolution963"
  type: "Convolution"
  bottom: "Convolution962"
  top: "Convolution963"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm963"
  type: "BatchNorm"
  bottom: "Convolution963"
  top: "Convolution963"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale963"
  type: "Scale"
  bottom: "Convolution963"
  top: "Convolution963"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise481"
  type: "Eltwise"
  bottom: "Eltwise480"
  bottom: "Convolution963"
  top: "Eltwise481"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU963"
  type: "ReLU"
  bottom: "Eltwise481"
  top: "Eltwise481"
}
layer {
  name: "Convolution964"
  type: "Convolution"
  bottom: "Eltwise481"
  top: "Convolution964"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm964"
  type: "BatchNorm"
  bottom: "Convolution964"
  top: "Convolution964"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale964"
  type: "Scale"
  bottom: "Convolution964"
  top: "Convolution964"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU964"
  type: "ReLU"
  bottom: "Convolution964"
  top: "Convolution964"
}
layer {
  name: "Convolution965"
  type: "Convolution"
  bottom: "Convolution964"
  top: "Convolution965"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm965"
  type: "BatchNorm"
  bottom: "Convolution965"
  top: "Convolution965"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale965"
  type: "Scale"
  bottom: "Convolution965"
  top: "Convolution965"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise482"
  type: "Eltwise"
  bottom: "Eltwise481"
  bottom: "Convolution965"
  top: "Eltwise482"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU965"
  type: "ReLU"
  bottom: "Eltwise482"
  top: "Eltwise482"
}
layer {
  name: "Convolution966"
  type: "Convolution"
  bottom: "Eltwise482"
  top: "Convolution966"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm966"
  type: "BatchNorm"
  bottom: "Convolution966"
  top: "Convolution966"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale966"
  type: "Scale"
  bottom: "Convolution966"
  top: "Convolution966"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU966"
  type: "ReLU"
  bottom: "Convolution966"
  top: "Convolution966"
}
layer {
  name: "Convolution967"
  type: "Convolution"
  bottom: "Convolution966"
  top: "Convolution967"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm967"
  type: "BatchNorm"
  bottom: "Convolution967"
  top: "Convolution967"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale967"
  type: "Scale"
  bottom: "Convolution967"
  top: "Convolution967"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise483"
  type: "Eltwise"
  bottom: "Eltwise482"
  bottom: "Convolution967"
  top: "Eltwise483"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU967"
  type: "ReLU"
  bottom: "Eltwise483"
  top: "Eltwise483"
}
layer {
  name: "Convolution968"
  type: "Convolution"
  bottom: "Eltwise483"
  top: "Convolution968"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm968"
  type: "BatchNorm"
  bottom: "Convolution968"
  top: "Convolution968"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale968"
  type: "Scale"
  bottom: "Convolution968"
  top: "Convolution968"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU968"
  type: "ReLU"
  bottom: "Convolution968"
  top: "Convolution968"
}
layer {
  name: "Convolution969"
  type: "Convolution"
  bottom: "Convolution968"
  top: "Convolution969"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm969"
  type: "BatchNorm"
  bottom: "Convolution969"
  top: "Convolution969"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale969"
  type: "Scale"
  bottom: "Convolution969"
  top: "Convolution969"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise484"
  type: "Eltwise"
  bottom: "Eltwise483"
  bottom: "Convolution969"
  top: "Eltwise484"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU969"
  type: "ReLU"
  bottom: "Eltwise484"
  top: "Eltwise484"
}
layer {
  name: "Convolution970"
  type: "Convolution"
  bottom: "Eltwise484"
  top: "Convolution970"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm970"
  type: "BatchNorm"
  bottom: "Convolution970"
  top: "Convolution970"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale970"
  type: "Scale"
  bottom: "Convolution970"
  top: "Convolution970"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU970"
  type: "ReLU"
  bottom: "Convolution970"
  top: "Convolution970"
}
layer {
  name: "Convolution971"
  type: "Convolution"
  bottom: "Convolution970"
  top: "Convolution971"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm971"
  type: "BatchNorm"
  bottom: "Convolution971"
  top: "Convolution971"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale971"
  type: "Scale"
  bottom: "Convolution971"
  top: "Convolution971"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise485"
  type: "Eltwise"
  bottom: "Eltwise484"
  bottom: "Convolution971"
  top: "Eltwise485"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU971"
  type: "ReLU"
  bottom: "Eltwise485"
  top: "Eltwise485"
}
layer {
  name: "Convolution972"
  type: "Convolution"
  bottom: "Eltwise485"
  top: "Convolution972"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm972"
  type: "BatchNorm"
  bottom: "Convolution972"
  top: "Convolution972"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale972"
  type: "Scale"
  bottom: "Convolution972"
  top: "Convolution972"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU972"
  type: "ReLU"
  bottom: "Convolution972"
  top: "Convolution972"
}
layer {
  name: "Convolution973"
  type: "Convolution"
  bottom: "Convolution972"
  top: "Convolution973"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm973"
  type: "BatchNorm"
  bottom: "Convolution973"
  top: "Convolution973"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale973"
  type: "Scale"
  bottom: "Convolution973"
  top: "Convolution973"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise486"
  type: "Eltwise"
  bottom: "Eltwise485"
  bottom: "Convolution973"
  top: "Eltwise486"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU973"
  type: "ReLU"
  bottom: "Eltwise486"
  top: "Eltwise486"
}
layer {
  name: "Convolution974"
  type: "Convolution"
  bottom: "Eltwise486"
  top: "Convolution974"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm974"
  type: "BatchNorm"
  bottom: "Convolution974"
  top: "Convolution974"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale974"
  type: "Scale"
  bottom: "Convolution974"
  top: "Convolution974"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU974"
  type: "ReLU"
  bottom: "Convolution974"
  top: "Convolution974"
}
layer {
  name: "Convolution975"
  type: "Convolution"
  bottom: "Convolution974"
  top: "Convolution975"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm975"
  type: "BatchNorm"
  bottom: "Convolution975"
  top: "Convolution975"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale975"
  type: "Scale"
  bottom: "Convolution975"
  top: "Convolution975"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise487"
  type: "Eltwise"
  bottom: "Eltwise486"
  bottom: "Convolution975"
  top: "Eltwise487"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU975"
  type: "ReLU"
  bottom: "Eltwise487"
  top: "Eltwise487"
}
layer {
  name: "Convolution976"
  type: "Convolution"
  bottom: "Eltwise487"
  top: "Convolution976"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm976"
  type: "BatchNorm"
  bottom: "Convolution976"
  top: "Convolution976"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale976"
  type: "Scale"
  bottom: "Convolution976"
  top: "Convolution976"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU976"
  type: "ReLU"
  bottom: "Convolution976"
  top: "Convolution976"
}
layer {
  name: "Convolution977"
  type: "Convolution"
  bottom: "Convolution976"
  top: "Convolution977"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm977"
  type: "BatchNorm"
  bottom: "Convolution977"
  top: "Convolution977"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale977"
  type: "Scale"
  bottom: "Convolution977"
  top: "Convolution977"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise488"
  type: "Eltwise"
  bottom: "Eltwise487"
  bottom: "Convolution977"
  top: "Eltwise488"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU977"
  type: "ReLU"
  bottom: "Eltwise488"
  top: "Eltwise488"
}
layer {
  name: "Convolution978"
  type: "Convolution"
  bottom: "Eltwise488"
  top: "Convolution978"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm978"
  type: "BatchNorm"
  bottom: "Convolution978"
  top: "Convolution978"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale978"
  type: "Scale"
  bottom: "Convolution978"
  top: "Convolution978"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU978"
  type: "ReLU"
  bottom: "Convolution978"
  top: "Convolution978"
}
layer {
  name: "Convolution979"
  type: "Convolution"
  bottom: "Convolution978"
  top: "Convolution979"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm979"
  type: "BatchNorm"
  bottom: "Convolution979"
  top: "Convolution979"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale979"
  type: "Scale"
  bottom: "Convolution979"
  top: "Convolution979"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise489"
  type: "Eltwise"
  bottom: "Eltwise488"
  bottom: "Convolution979"
  top: "Eltwise489"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU979"
  type: "ReLU"
  bottom: "Eltwise489"
  top: "Eltwise489"
}
layer {
  name: "Convolution980"
  type: "Convolution"
  bottom: "Eltwise489"
  top: "Convolution980"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm980"
  type: "BatchNorm"
  bottom: "Convolution980"
  top: "Convolution980"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale980"
  type: "Scale"
  bottom: "Convolution980"
  top: "Convolution980"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU980"
  type: "ReLU"
  bottom: "Convolution980"
  top: "Convolution980"
}
layer {
  name: "Convolution981"
  type: "Convolution"
  bottom: "Convolution980"
  top: "Convolution981"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm981"
  type: "BatchNorm"
  bottom: "Convolution981"
  top: "Convolution981"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale981"
  type: "Scale"
  bottom: "Convolution981"
  top: "Convolution981"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise490"
  type: "Eltwise"
  bottom: "Eltwise489"
  bottom: "Convolution981"
  top: "Eltwise490"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU981"
  type: "ReLU"
  bottom: "Eltwise490"
  top: "Eltwise490"
}
layer {
  name: "Convolution982"
  type: "Convolution"
  bottom: "Eltwise490"
  top: "Convolution982"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm982"
  type: "BatchNorm"
  bottom: "Convolution982"
  top: "Convolution982"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale982"
  type: "Scale"
  bottom: "Convolution982"
  top: "Convolution982"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU982"
  type: "ReLU"
  bottom: "Convolution982"
  top: "Convolution982"
}
layer {
  name: "Convolution983"
  type: "Convolution"
  bottom: "Convolution982"
  top: "Convolution983"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm983"
  type: "BatchNorm"
  bottom: "Convolution983"
  top: "Convolution983"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale983"
  type: "Scale"
  bottom: "Convolution983"
  top: "Convolution983"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise491"
  type: "Eltwise"
  bottom: "Eltwise490"
  bottom: "Convolution983"
  top: "Eltwise491"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU983"
  type: "ReLU"
  bottom: "Eltwise491"
  top: "Eltwise491"
}
layer {
  name: "Convolution984"
  type: "Convolution"
  bottom: "Eltwise491"
  top: "Convolution984"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm984"
  type: "BatchNorm"
  bottom: "Convolution984"
  top: "Convolution984"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale984"
  type: "Scale"
  bottom: "Convolution984"
  top: "Convolution984"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU984"
  type: "ReLU"
  bottom: "Convolution984"
  top: "Convolution984"
}
layer {
  name: "Convolution985"
  type: "Convolution"
  bottom: "Convolution984"
  top: "Convolution985"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm985"
  type: "BatchNorm"
  bottom: "Convolution985"
  top: "Convolution985"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale985"
  type: "Scale"
  bottom: "Convolution985"
  top: "Convolution985"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise492"
  type: "Eltwise"
  bottom: "Eltwise491"
  bottom: "Convolution985"
  top: "Eltwise492"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU985"
  type: "ReLU"
  bottom: "Eltwise492"
  top: "Eltwise492"
}
layer {
  name: "Convolution986"
  type: "Convolution"
  bottom: "Eltwise492"
  top: "Convolution986"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm986"
  type: "BatchNorm"
  bottom: "Convolution986"
  top: "Convolution986"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale986"
  type: "Scale"
  bottom: "Convolution986"
  top: "Convolution986"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU986"
  type: "ReLU"
  bottom: "Convolution986"
  top: "Convolution986"
}
layer {
  name: "Convolution987"
  type: "Convolution"
  bottom: "Convolution986"
  top: "Convolution987"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm987"
  type: "BatchNorm"
  bottom: "Convolution987"
  top: "Convolution987"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale987"
  type: "Scale"
  bottom: "Convolution987"
  top: "Convolution987"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise493"
  type: "Eltwise"
  bottom: "Eltwise492"
  bottom: "Convolution987"
  top: "Eltwise493"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU987"
  type: "ReLU"
  bottom: "Eltwise493"
  top: "Eltwise493"
}
layer {
  name: "Convolution988"
  type: "Convolution"
  bottom: "Eltwise493"
  top: "Convolution988"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm988"
  type: "BatchNorm"
  bottom: "Convolution988"
  top: "Convolution988"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale988"
  type: "Scale"
  bottom: "Convolution988"
  top: "Convolution988"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU988"
  type: "ReLU"
  bottom: "Convolution988"
  top: "Convolution988"
}
layer {
  name: "Convolution989"
  type: "Convolution"
  bottom: "Convolution988"
  top: "Convolution989"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm989"
  type: "BatchNorm"
  bottom: "Convolution989"
  top: "Convolution989"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale989"
  type: "Scale"
  bottom: "Convolution989"
  top: "Convolution989"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise494"
  type: "Eltwise"
  bottom: "Eltwise493"
  bottom: "Convolution989"
  top: "Eltwise494"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU989"
  type: "ReLU"
  bottom: "Eltwise494"
  top: "Eltwise494"
}
layer {
  name: "Convolution990"
  type: "Convolution"
  bottom: "Eltwise494"
  top: "Convolution990"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm990"
  type: "BatchNorm"
  bottom: "Convolution990"
  top: "Convolution990"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale990"
  type: "Scale"
  bottom: "Convolution990"
  top: "Convolution990"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU990"
  type: "ReLU"
  bottom: "Convolution990"
  top: "Convolution990"
}
layer {
  name: "Convolution991"
  type: "Convolution"
  bottom: "Convolution990"
  top: "Convolution991"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm991"
  type: "BatchNorm"
  bottom: "Convolution991"
  top: "Convolution991"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale991"
  type: "Scale"
  bottom: "Convolution991"
  top: "Convolution991"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise495"
  type: "Eltwise"
  bottom: "Eltwise494"
  bottom: "Convolution991"
  top: "Eltwise495"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU991"
  type: "ReLU"
  bottom: "Eltwise495"
  top: "Eltwise495"
}
layer {
  name: "Convolution992"
  type: "Convolution"
  bottom: "Eltwise495"
  top: "Convolution992"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm992"
  type: "BatchNorm"
  bottom: "Convolution992"
  top: "Convolution992"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale992"
  type: "Scale"
  bottom: "Convolution992"
  top: "Convolution992"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU992"
  type: "ReLU"
  bottom: "Convolution992"
  top: "Convolution992"
}
layer {
  name: "Convolution993"
  type: "Convolution"
  bottom: "Convolution992"
  top: "Convolution993"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm993"
  type: "BatchNorm"
  bottom: "Convolution993"
  top: "Convolution993"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale993"
  type: "Scale"
  bottom: "Convolution993"
  top: "Convolution993"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise496"
  type: "Eltwise"
  bottom: "Eltwise495"
  bottom: "Convolution993"
  top: "Eltwise496"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU993"
  type: "ReLU"
  bottom: "Eltwise496"
  top: "Eltwise496"
}
layer {
  name: "Convolution994"
  type: "Convolution"
  bottom: "Eltwise496"
  top: "Convolution994"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm994"
  type: "BatchNorm"
  bottom: "Convolution994"
  top: "Convolution994"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale994"
  type: "Scale"
  bottom: "Convolution994"
  top: "Convolution994"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU994"
  type: "ReLU"
  bottom: "Convolution994"
  top: "Convolution994"
}
layer {
  name: "Convolution995"
  type: "Convolution"
  bottom: "Convolution994"
  top: "Convolution995"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm995"
  type: "BatchNorm"
  bottom: "Convolution995"
  top: "Convolution995"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale995"
  type: "Scale"
  bottom: "Convolution995"
  top: "Convolution995"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise497"
  type: "Eltwise"
  bottom: "Eltwise496"
  bottom: "Convolution995"
  top: "Eltwise497"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU995"
  type: "ReLU"
  bottom: "Eltwise497"
  top: "Eltwise497"
}
layer {
  name: "Convolution996"
  type: "Convolution"
  bottom: "Eltwise497"
  top: "Convolution996"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm996"
  type: "BatchNorm"
  bottom: "Convolution996"
  top: "Convolution996"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale996"
  type: "Scale"
  bottom: "Convolution996"
  top: "Convolution996"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU996"
  type: "ReLU"
  bottom: "Convolution996"
  top: "Convolution996"
}
layer {
  name: "Convolution997"
  type: "Convolution"
  bottom: "Convolution996"
  top: "Convolution997"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm997"
  type: "BatchNorm"
  bottom: "Convolution997"
  top: "Convolution997"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale997"
  type: "Scale"
  bottom: "Convolution997"
  top: "Convolution997"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise498"
  type: "Eltwise"
  bottom: "Eltwise497"
  bottom: "Convolution997"
  top: "Eltwise498"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU997"
  type: "ReLU"
  bottom: "Eltwise498"
  top: "Eltwise498"
}
layer {
  name: "Convolution998"
  type: "Convolution"
  bottom: "Eltwise498"
  top: "Convolution998"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm998"
  type: "BatchNorm"
  bottom: "Convolution998"
  top: "Convolution998"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale998"
  type: "Scale"
  bottom: "Convolution998"
  top: "Convolution998"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU998"
  type: "ReLU"
  bottom: "Convolution998"
  top: "Convolution998"
}
layer {
  name: "Convolution999"
  type: "Convolution"
  bottom: "Convolution998"
  top: "Convolution999"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm999"
  type: "BatchNorm"
  bottom: "Convolution999"
  top: "Convolution999"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale999"
  type: "Scale"
  bottom: "Convolution999"
  top: "Convolution999"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise499"
  type: "Eltwise"
  bottom: "Eltwise498"
  bottom: "Convolution999"
  top: "Eltwise499"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU999"
  type: "ReLU"
  bottom: "Eltwise499"
  top: "Eltwise499"
}
layer {
  name: "Convolution1000"
  type: "Convolution"
  bottom: "Eltwise499"
  top: "Convolution1000"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1000"
  type: "BatchNorm"
  bottom: "Convolution1000"
  top: "Convolution1000"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1000"
  type: "Scale"
  bottom: "Convolution1000"
  top: "Convolution1000"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1000"
  type: "ReLU"
  bottom: "Convolution1000"
  top: "Convolution1000"
}
layer {
  name: "Convolution1001"
  type: "Convolution"
  bottom: "Convolution1000"
  top: "Convolution1001"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1001"
  type: "BatchNorm"
  bottom: "Convolution1001"
  top: "Convolution1001"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1001"
  type: "Scale"
  bottom: "Convolution1001"
  top: "Convolution1001"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise500"
  type: "Eltwise"
  bottom: "Eltwise499"
  bottom: "Convolution1001"
  top: "Eltwise500"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1001"
  type: "ReLU"
  bottom: "Eltwise500"
  top: "Eltwise500"
}
layer {
  name: "Convolution1002"
  type: "Convolution"
  bottom: "Eltwise500"
  top: "Convolution1002"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1002"
  type: "BatchNorm"
  bottom: "Convolution1002"
  top: "Convolution1002"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1002"
  type: "Scale"
  bottom: "Convolution1002"
  top: "Convolution1002"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1002"
  type: "ReLU"
  bottom: "Convolution1002"
  top: "Convolution1002"
}
layer {
  name: "Convolution1003"
  type: "Convolution"
  bottom: "Convolution1002"
  top: "Convolution1003"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1003"
  type: "BatchNorm"
  bottom: "Convolution1003"
  top: "Convolution1003"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1003"
  type: "Scale"
  bottom: "Convolution1003"
  top: "Convolution1003"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise501"
  type: "Eltwise"
  bottom: "Eltwise500"
  bottom: "Convolution1003"
  top: "Eltwise501"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1003"
  type: "ReLU"
  bottom: "Eltwise501"
  top: "Eltwise501"
}
layer {
  name: "Convolution1004"
  type: "Convolution"
  bottom: "Eltwise501"
  top: "Convolution1004"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1004"
  type: "BatchNorm"
  bottom: "Convolution1004"
  top: "Convolution1004"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1004"
  type: "Scale"
  bottom: "Convolution1004"
  top: "Convolution1004"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1004"
  type: "ReLU"
  bottom: "Convolution1004"
  top: "Convolution1004"
}
layer {
  name: "Convolution1005"
  type: "Convolution"
  bottom: "Convolution1004"
  top: "Convolution1005"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1005"
  type: "BatchNorm"
  bottom: "Convolution1005"
  top: "Convolution1005"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1005"
  type: "Scale"
  bottom: "Convolution1005"
  top: "Convolution1005"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise502"
  type: "Eltwise"
  bottom: "Eltwise501"
  bottom: "Convolution1005"
  top: "Eltwise502"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1005"
  type: "ReLU"
  bottom: "Eltwise502"
  top: "Eltwise502"
}
layer {
  name: "Convolution1006"
  type: "Convolution"
  bottom: "Eltwise502"
  top: "Convolution1006"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1006"
  type: "BatchNorm"
  bottom: "Convolution1006"
  top: "Convolution1006"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1006"
  type: "Scale"
  bottom: "Convolution1006"
  top: "Convolution1006"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1006"
  type: "ReLU"
  bottom: "Convolution1006"
  top: "Convolution1006"
}
layer {
  name: "Convolution1007"
  type: "Convolution"
  bottom: "Convolution1006"
  top: "Convolution1007"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1007"
  type: "BatchNorm"
  bottom: "Convolution1007"
  top: "Convolution1007"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1007"
  type: "Scale"
  bottom: "Convolution1007"
  top: "Convolution1007"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise503"
  type: "Eltwise"
  bottom: "Eltwise502"
  bottom: "Convolution1007"
  top: "Eltwise503"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1007"
  type: "ReLU"
  bottom: "Eltwise503"
  top: "Eltwise503"
}
layer {
  name: "Convolution1008"
  type: "Convolution"
  bottom: "Eltwise503"
  top: "Convolution1008"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1008"
  type: "BatchNorm"
  bottom: "Convolution1008"
  top: "Convolution1008"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1008"
  type: "Scale"
  bottom: "Convolution1008"
  top: "Convolution1008"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1008"
  type: "ReLU"
  bottom: "Convolution1008"
  top: "Convolution1008"
}
layer {
  name: "Convolution1009"
  type: "Convolution"
  bottom: "Convolution1008"
  top: "Convolution1009"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1009"
  type: "BatchNorm"
  bottom: "Convolution1009"
  top: "Convolution1009"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1009"
  type: "Scale"
  bottom: "Convolution1009"
  top: "Convolution1009"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise504"
  type: "Eltwise"
  bottom: "Eltwise503"
  bottom: "Convolution1009"
  top: "Eltwise504"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1009"
  type: "ReLU"
  bottom: "Eltwise504"
  top: "Eltwise504"
}
layer {
  name: "Convolution1010"
  type: "Convolution"
  bottom: "Eltwise504"
  top: "Convolution1010"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1010"
  type: "BatchNorm"
  bottom: "Convolution1010"
  top: "Convolution1010"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1010"
  type: "Scale"
  bottom: "Convolution1010"
  top: "Convolution1010"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1010"
  type: "ReLU"
  bottom: "Convolution1010"
  top: "Convolution1010"
}
layer {
  name: "Convolution1011"
  type: "Convolution"
  bottom: "Convolution1010"
  top: "Convolution1011"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1011"
  type: "BatchNorm"
  bottom: "Convolution1011"
  top: "Convolution1011"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1011"
  type: "Scale"
  bottom: "Convolution1011"
  top: "Convolution1011"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise505"
  type: "Eltwise"
  bottom: "Eltwise504"
  bottom: "Convolution1011"
  top: "Eltwise505"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1011"
  type: "ReLU"
  bottom: "Eltwise505"
  top: "Eltwise505"
}
layer {
  name: "Convolution1012"
  type: "Convolution"
  bottom: "Eltwise505"
  top: "Convolution1012"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1012"
  type: "BatchNorm"
  bottom: "Convolution1012"
  top: "Convolution1012"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1012"
  type: "Scale"
  bottom: "Convolution1012"
  top: "Convolution1012"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1012"
  type: "ReLU"
  bottom: "Convolution1012"
  top: "Convolution1012"
}
layer {
  name: "Convolution1013"
  type: "Convolution"
  bottom: "Convolution1012"
  top: "Convolution1013"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1013"
  type: "BatchNorm"
  bottom: "Convolution1013"
  top: "Convolution1013"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1013"
  type: "Scale"
  bottom: "Convolution1013"
  top: "Convolution1013"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise506"
  type: "Eltwise"
  bottom: "Eltwise505"
  bottom: "Convolution1013"
  top: "Eltwise506"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1013"
  type: "ReLU"
  bottom: "Eltwise506"
  top: "Eltwise506"
}
layer {
  name: "Convolution1014"
  type: "Convolution"
  bottom: "Eltwise506"
  top: "Convolution1014"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1014"
  type: "BatchNorm"
  bottom: "Convolution1014"
  top: "Convolution1014"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1014"
  type: "Scale"
  bottom: "Convolution1014"
  top: "Convolution1014"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1014"
  type: "ReLU"
  bottom: "Convolution1014"
  top: "Convolution1014"
}
layer {
  name: "Convolution1015"
  type: "Convolution"
  bottom: "Convolution1014"
  top: "Convolution1015"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1015"
  type: "BatchNorm"
  bottom: "Convolution1015"
  top: "Convolution1015"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1015"
  type: "Scale"
  bottom: "Convolution1015"
  top: "Convolution1015"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise507"
  type: "Eltwise"
  bottom: "Eltwise506"
  bottom: "Convolution1015"
  top: "Eltwise507"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1015"
  type: "ReLU"
  bottom: "Eltwise507"
  top: "Eltwise507"
}
layer {
  name: "Convolution1016"
  type: "Convolution"
  bottom: "Eltwise507"
  top: "Convolution1016"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1016"
  type: "BatchNorm"
  bottom: "Convolution1016"
  top: "Convolution1016"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1016"
  type: "Scale"
  bottom: "Convolution1016"
  top: "Convolution1016"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1016"
  type: "ReLU"
  bottom: "Convolution1016"
  top: "Convolution1016"
}
layer {
  name: "Convolution1017"
  type: "Convolution"
  bottom: "Convolution1016"
  top: "Convolution1017"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1017"
  type: "BatchNorm"
  bottom: "Convolution1017"
  top: "Convolution1017"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1017"
  type: "Scale"
  bottom: "Convolution1017"
  top: "Convolution1017"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise508"
  type: "Eltwise"
  bottom: "Eltwise507"
  bottom: "Convolution1017"
  top: "Eltwise508"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1017"
  type: "ReLU"
  bottom: "Eltwise508"
  top: "Eltwise508"
}
layer {
  name: "Convolution1018"
  type: "Convolution"
  bottom: "Eltwise508"
  top: "Convolution1018"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1018"
  type: "BatchNorm"
  bottom: "Convolution1018"
  top: "Convolution1018"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1018"
  type: "Scale"
  bottom: "Convolution1018"
  top: "Convolution1018"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1018"
  type: "ReLU"
  bottom: "Convolution1018"
  top: "Convolution1018"
}
layer {
  name: "Convolution1019"
  type: "Convolution"
  bottom: "Convolution1018"
  top: "Convolution1019"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1019"
  type: "BatchNorm"
  bottom: "Convolution1019"
  top: "Convolution1019"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1019"
  type: "Scale"
  bottom: "Convolution1019"
  top: "Convolution1019"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise509"
  type: "Eltwise"
  bottom: "Eltwise508"
  bottom: "Convolution1019"
  top: "Eltwise509"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1019"
  type: "ReLU"
  bottom: "Eltwise509"
  top: "Eltwise509"
}
layer {
  name: "Convolution1020"
  type: "Convolution"
  bottom: "Eltwise509"
  top: "Convolution1020"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1020"
  type: "BatchNorm"
  bottom: "Convolution1020"
  top: "Convolution1020"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1020"
  type: "Scale"
  bottom: "Convolution1020"
  top: "Convolution1020"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1020"
  type: "ReLU"
  bottom: "Convolution1020"
  top: "Convolution1020"
}
layer {
  name: "Convolution1021"
  type: "Convolution"
  bottom: "Convolution1020"
  top: "Convolution1021"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1021"
  type: "BatchNorm"
  bottom: "Convolution1021"
  top: "Convolution1021"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1021"
  type: "Scale"
  bottom: "Convolution1021"
  top: "Convolution1021"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise510"
  type: "Eltwise"
  bottom: "Eltwise509"
  bottom: "Convolution1021"
  top: "Eltwise510"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1021"
  type: "ReLU"
  bottom: "Eltwise510"
  top: "Eltwise510"
}
layer {
  name: "Convolution1022"
  type: "Convolution"
  bottom: "Eltwise510"
  top: "Convolution1022"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1022"
  type: "BatchNorm"
  bottom: "Convolution1022"
  top: "Convolution1022"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1022"
  type: "Scale"
  bottom: "Convolution1022"
  top: "Convolution1022"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1022"
  type: "ReLU"
  bottom: "Convolution1022"
  top: "Convolution1022"
}
layer {
  name: "Convolution1023"
  type: "Convolution"
  bottom: "Convolution1022"
  top: "Convolution1023"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1023"
  type: "BatchNorm"
  bottom: "Convolution1023"
  top: "Convolution1023"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1023"
  type: "Scale"
  bottom: "Convolution1023"
  top: "Convolution1023"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise511"
  type: "Eltwise"
  bottom: "Eltwise510"
  bottom: "Convolution1023"
  top: "Eltwise511"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1023"
  type: "ReLU"
  bottom: "Eltwise511"
  top: "Eltwise511"
}
layer {
  name: "Convolution1024"
  type: "Convolution"
  bottom: "Eltwise511"
  top: "Convolution1024"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1024"
  type: "BatchNorm"
  bottom: "Convolution1024"
  top: "Convolution1024"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1024"
  type: "Scale"
  bottom: "Convolution1024"
  top: "Convolution1024"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1024"
  type: "ReLU"
  bottom: "Convolution1024"
  top: "Convolution1024"
}
layer {
  name: "Convolution1025"
  type: "Convolution"
  bottom: "Convolution1024"
  top: "Convolution1025"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1025"
  type: "BatchNorm"
  bottom: "Convolution1025"
  top: "Convolution1025"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1025"
  type: "Scale"
  bottom: "Convolution1025"
  top: "Convolution1025"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise512"
  type: "Eltwise"
  bottom: "Eltwise511"
  bottom: "Convolution1025"
  top: "Eltwise512"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1025"
  type: "ReLU"
  bottom: "Eltwise512"
  top: "Eltwise512"
}
layer {
  name: "Convolution1026"
  type: "Convolution"
  bottom: "Eltwise512"
  top: "Convolution1026"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1026"
  type: "BatchNorm"
  bottom: "Convolution1026"
  top: "Convolution1026"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1026"
  type: "Scale"
  bottom: "Convolution1026"
  top: "Convolution1026"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1026"
  type: "ReLU"
  bottom: "Convolution1026"
  top: "Convolution1026"
}
layer {
  name: "Convolution1027"
  type: "Convolution"
  bottom: "Convolution1026"
  top: "Convolution1027"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1027"
  type: "BatchNorm"
  bottom: "Convolution1027"
  top: "Convolution1027"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1027"
  type: "Scale"
  bottom: "Convolution1027"
  top: "Convolution1027"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise513"
  type: "Eltwise"
  bottom: "Eltwise512"
  bottom: "Convolution1027"
  top: "Eltwise513"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1027"
  type: "ReLU"
  bottom: "Eltwise513"
  top: "Eltwise513"
}
layer {
  name: "Convolution1028"
  type: "Convolution"
  bottom: "Eltwise513"
  top: "Convolution1028"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1028"
  type: "BatchNorm"
  bottom: "Convolution1028"
  top: "Convolution1028"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1028"
  type: "Scale"
  bottom: "Convolution1028"
  top: "Convolution1028"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1028"
  type: "ReLU"
  bottom: "Convolution1028"
  top: "Convolution1028"
}
layer {
  name: "Convolution1029"
  type: "Convolution"
  bottom: "Convolution1028"
  top: "Convolution1029"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1029"
  type: "BatchNorm"
  bottom: "Convolution1029"
  top: "Convolution1029"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1029"
  type: "Scale"
  bottom: "Convolution1029"
  top: "Convolution1029"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise514"
  type: "Eltwise"
  bottom: "Eltwise513"
  bottom: "Convolution1029"
  top: "Eltwise514"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1029"
  type: "ReLU"
  bottom: "Eltwise514"
  top: "Eltwise514"
}
layer {
  name: "Convolution1030"
  type: "Convolution"
  bottom: "Eltwise514"
  top: "Convolution1030"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1030"
  type: "BatchNorm"
  bottom: "Convolution1030"
  top: "Convolution1030"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1030"
  type: "Scale"
  bottom: "Convolution1030"
  top: "Convolution1030"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1030"
  type: "ReLU"
  bottom: "Convolution1030"
  top: "Convolution1030"
}
layer {
  name: "Convolution1031"
  type: "Convolution"
  bottom: "Convolution1030"
  top: "Convolution1031"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1031"
  type: "BatchNorm"
  bottom: "Convolution1031"
  top: "Convolution1031"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1031"
  type: "Scale"
  bottom: "Convolution1031"
  top: "Convolution1031"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise515"
  type: "Eltwise"
  bottom: "Eltwise514"
  bottom: "Convolution1031"
  top: "Eltwise515"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1031"
  type: "ReLU"
  bottom: "Eltwise515"
  top: "Eltwise515"
}
layer {
  name: "Convolution1032"
  type: "Convolution"
  bottom: "Eltwise515"
  top: "Convolution1032"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1032"
  type: "BatchNorm"
  bottom: "Convolution1032"
  top: "Convolution1032"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1032"
  type: "Scale"
  bottom: "Convolution1032"
  top: "Convolution1032"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1032"
  type: "ReLU"
  bottom: "Convolution1032"
  top: "Convolution1032"
}
layer {
  name: "Convolution1033"
  type: "Convolution"
  bottom: "Convolution1032"
  top: "Convolution1033"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1033"
  type: "BatchNorm"
  bottom: "Convolution1033"
  top: "Convolution1033"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1033"
  type: "Scale"
  bottom: "Convolution1033"
  top: "Convolution1033"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise516"
  type: "Eltwise"
  bottom: "Eltwise515"
  bottom: "Convolution1033"
  top: "Eltwise516"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1033"
  type: "ReLU"
  bottom: "Eltwise516"
  top: "Eltwise516"
}
layer {
  name: "Convolution1034"
  type: "Convolution"
  bottom: "Eltwise516"
  top: "Convolution1034"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1034"
  type: "BatchNorm"
  bottom: "Convolution1034"
  top: "Convolution1034"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1034"
  type: "Scale"
  bottom: "Convolution1034"
  top: "Convolution1034"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1034"
  type: "ReLU"
  bottom: "Convolution1034"
  top: "Convolution1034"
}
layer {
  name: "Convolution1035"
  type: "Convolution"
  bottom: "Convolution1034"
  top: "Convolution1035"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1035"
  type: "BatchNorm"
  bottom: "Convolution1035"
  top: "Convolution1035"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1035"
  type: "Scale"
  bottom: "Convolution1035"
  top: "Convolution1035"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise517"
  type: "Eltwise"
  bottom: "Eltwise516"
  bottom: "Convolution1035"
  top: "Eltwise517"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1035"
  type: "ReLU"
  bottom: "Eltwise517"
  top: "Eltwise517"
}
layer {
  name: "Convolution1036"
  type: "Convolution"
  bottom: "Eltwise517"
  top: "Convolution1036"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1036"
  type: "BatchNorm"
  bottom: "Convolution1036"
  top: "Convolution1036"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1036"
  type: "Scale"
  bottom: "Convolution1036"
  top: "Convolution1036"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1036"
  type: "ReLU"
  bottom: "Convolution1036"
  top: "Convolution1036"
}
layer {
  name: "Convolution1037"
  type: "Convolution"
  bottom: "Convolution1036"
  top: "Convolution1037"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1037"
  type: "BatchNorm"
  bottom: "Convolution1037"
  top: "Convolution1037"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1037"
  type: "Scale"
  bottom: "Convolution1037"
  top: "Convolution1037"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise518"
  type: "Eltwise"
  bottom: "Eltwise517"
  bottom: "Convolution1037"
  top: "Eltwise518"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1037"
  type: "ReLU"
  bottom: "Eltwise518"
  top: "Eltwise518"
}
layer {
  name: "Convolution1038"
  type: "Convolution"
  bottom: "Eltwise518"
  top: "Convolution1038"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1038"
  type: "BatchNorm"
  bottom: "Convolution1038"
  top: "Convolution1038"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1038"
  type: "Scale"
  bottom: "Convolution1038"
  top: "Convolution1038"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1038"
  type: "ReLU"
  bottom: "Convolution1038"
  top: "Convolution1038"
}
layer {
  name: "Convolution1039"
  type: "Convolution"
  bottom: "Convolution1038"
  top: "Convolution1039"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1039"
  type: "BatchNorm"
  bottom: "Convolution1039"
  top: "Convolution1039"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1039"
  type: "Scale"
  bottom: "Convolution1039"
  top: "Convolution1039"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise519"
  type: "Eltwise"
  bottom: "Eltwise518"
  bottom: "Convolution1039"
  top: "Eltwise519"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1039"
  type: "ReLU"
  bottom: "Eltwise519"
  top: "Eltwise519"
}
layer {
  name: "Convolution1040"
  type: "Convolution"
  bottom: "Eltwise519"
  top: "Convolution1040"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1040"
  type: "BatchNorm"
  bottom: "Convolution1040"
  top: "Convolution1040"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1040"
  type: "Scale"
  bottom: "Convolution1040"
  top: "Convolution1040"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1040"
  type: "ReLU"
  bottom: "Convolution1040"
  top: "Convolution1040"
}
layer {
  name: "Convolution1041"
  type: "Convolution"
  bottom: "Convolution1040"
  top: "Convolution1041"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1041"
  type: "BatchNorm"
  bottom: "Convolution1041"
  top: "Convolution1041"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1041"
  type: "Scale"
  bottom: "Convolution1041"
  top: "Convolution1041"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise520"
  type: "Eltwise"
  bottom: "Eltwise519"
  bottom: "Convolution1041"
  top: "Eltwise520"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1041"
  type: "ReLU"
  bottom: "Eltwise520"
  top: "Eltwise520"
}
layer {
  name: "Convolution1042"
  type: "Convolution"
  bottom: "Eltwise520"
  top: "Convolution1042"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1042"
  type: "BatchNorm"
  bottom: "Convolution1042"
  top: "Convolution1042"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1042"
  type: "Scale"
  bottom: "Convolution1042"
  top: "Convolution1042"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1042"
  type: "ReLU"
  bottom: "Convolution1042"
  top: "Convolution1042"
}
layer {
  name: "Convolution1043"
  type: "Convolution"
  bottom: "Convolution1042"
  top: "Convolution1043"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1043"
  type: "BatchNorm"
  bottom: "Convolution1043"
  top: "Convolution1043"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1043"
  type: "Scale"
  bottom: "Convolution1043"
  top: "Convolution1043"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise521"
  type: "Eltwise"
  bottom: "Eltwise520"
  bottom: "Convolution1043"
  top: "Eltwise521"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1043"
  type: "ReLU"
  bottom: "Eltwise521"
  top: "Eltwise521"
}
layer {
  name: "Convolution1044"
  type: "Convolution"
  bottom: "Eltwise521"
  top: "Convolution1044"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1044"
  type: "BatchNorm"
  bottom: "Convolution1044"
  top: "Convolution1044"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1044"
  type: "Scale"
  bottom: "Convolution1044"
  top: "Convolution1044"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1044"
  type: "ReLU"
  bottom: "Convolution1044"
  top: "Convolution1044"
}
layer {
  name: "Convolution1045"
  type: "Convolution"
  bottom: "Convolution1044"
  top: "Convolution1045"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1045"
  type: "BatchNorm"
  bottom: "Convolution1045"
  top: "Convolution1045"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1045"
  type: "Scale"
  bottom: "Convolution1045"
  top: "Convolution1045"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise522"
  type: "Eltwise"
  bottom: "Eltwise521"
  bottom: "Convolution1045"
  top: "Eltwise522"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1045"
  type: "ReLU"
  bottom: "Eltwise522"
  top: "Eltwise522"
}
layer {
  name: "Convolution1046"
  type: "Convolution"
  bottom: "Eltwise522"
  top: "Convolution1046"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1046"
  type: "BatchNorm"
  bottom: "Convolution1046"
  top: "Convolution1046"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1046"
  type: "Scale"
  bottom: "Convolution1046"
  top: "Convolution1046"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1046"
  type: "ReLU"
  bottom: "Convolution1046"
  top: "Convolution1046"
}
layer {
  name: "Convolution1047"
  type: "Convolution"
  bottom: "Convolution1046"
  top: "Convolution1047"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1047"
  type: "BatchNorm"
  bottom: "Convolution1047"
  top: "Convolution1047"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1047"
  type: "Scale"
  bottom: "Convolution1047"
  top: "Convolution1047"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise523"
  type: "Eltwise"
  bottom: "Eltwise522"
  bottom: "Convolution1047"
  top: "Eltwise523"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1047"
  type: "ReLU"
  bottom: "Eltwise523"
  top: "Eltwise523"
}
layer {
  name: "Convolution1048"
  type: "Convolution"
  bottom: "Eltwise523"
  top: "Convolution1048"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1048"
  type: "BatchNorm"
  bottom: "Convolution1048"
  top: "Convolution1048"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1048"
  type: "Scale"
  bottom: "Convolution1048"
  top: "Convolution1048"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1048"
  type: "ReLU"
  bottom: "Convolution1048"
  top: "Convolution1048"
}
layer {
  name: "Convolution1049"
  type: "Convolution"
  bottom: "Convolution1048"
  top: "Convolution1049"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1049"
  type: "BatchNorm"
  bottom: "Convolution1049"
  top: "Convolution1049"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1049"
  type: "Scale"
  bottom: "Convolution1049"
  top: "Convolution1049"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise524"
  type: "Eltwise"
  bottom: "Eltwise523"
  bottom: "Convolution1049"
  top: "Eltwise524"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1049"
  type: "ReLU"
  bottom: "Eltwise524"
  top: "Eltwise524"
}
layer {
  name: "Convolution1050"
  type: "Convolution"
  bottom: "Eltwise524"
  top: "Convolution1050"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1050"
  type: "BatchNorm"
  bottom: "Convolution1050"
  top: "Convolution1050"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1050"
  type: "Scale"
  bottom: "Convolution1050"
  top: "Convolution1050"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1050"
  type: "ReLU"
  bottom: "Convolution1050"
  top: "Convolution1050"
}
layer {
  name: "Convolution1051"
  type: "Convolution"
  bottom: "Convolution1050"
  top: "Convolution1051"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1051"
  type: "BatchNorm"
  bottom: "Convolution1051"
  top: "Convolution1051"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1051"
  type: "Scale"
  bottom: "Convolution1051"
  top: "Convolution1051"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise525"
  type: "Eltwise"
  bottom: "Eltwise524"
  bottom: "Convolution1051"
  top: "Eltwise525"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1051"
  type: "ReLU"
  bottom: "Eltwise525"
  top: "Eltwise525"
}
layer {
  name: "Convolution1052"
  type: "Convolution"
  bottom: "Eltwise525"
  top: "Convolution1052"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1052"
  type: "BatchNorm"
  bottom: "Convolution1052"
  top: "Convolution1052"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1052"
  type: "Scale"
  bottom: "Convolution1052"
  top: "Convolution1052"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1052"
  type: "ReLU"
  bottom: "Convolution1052"
  top: "Convolution1052"
}
layer {
  name: "Convolution1053"
  type: "Convolution"
  bottom: "Convolution1052"
  top: "Convolution1053"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1053"
  type: "BatchNorm"
  bottom: "Convolution1053"
  top: "Convolution1053"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1053"
  type: "Scale"
  bottom: "Convolution1053"
  top: "Convolution1053"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise526"
  type: "Eltwise"
  bottom: "Eltwise525"
  bottom: "Convolution1053"
  top: "Eltwise526"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1053"
  type: "ReLU"
  bottom: "Eltwise526"
  top: "Eltwise526"
}
layer {
  name: "Convolution1054"
  type: "Convolution"
  bottom: "Eltwise526"
  top: "Convolution1054"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1054"
  type: "BatchNorm"
  bottom: "Convolution1054"
  top: "Convolution1054"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1054"
  type: "Scale"
  bottom: "Convolution1054"
  top: "Convolution1054"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1054"
  type: "ReLU"
  bottom: "Convolution1054"
  top: "Convolution1054"
}
layer {
  name: "Convolution1055"
  type: "Convolution"
  bottom: "Convolution1054"
  top: "Convolution1055"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1055"
  type: "BatchNorm"
  bottom: "Convolution1055"
  top: "Convolution1055"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1055"
  type: "Scale"
  bottom: "Convolution1055"
  top: "Convolution1055"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise527"
  type: "Eltwise"
  bottom: "Eltwise526"
  bottom: "Convolution1055"
  top: "Eltwise527"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1055"
  type: "ReLU"
  bottom: "Eltwise527"
  top: "Eltwise527"
}
layer {
  name: "Convolution1056"
  type: "Convolution"
  bottom: "Eltwise527"
  top: "Convolution1056"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1056"
  type: "BatchNorm"
  bottom: "Convolution1056"
  top: "Convolution1056"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1056"
  type: "Scale"
  bottom: "Convolution1056"
  top: "Convolution1056"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1056"
  type: "ReLU"
  bottom: "Convolution1056"
  top: "Convolution1056"
}
layer {
  name: "Convolution1057"
  type: "Convolution"
  bottom: "Convolution1056"
  top: "Convolution1057"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1057"
  type: "BatchNorm"
  bottom: "Convolution1057"
  top: "Convolution1057"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1057"
  type: "Scale"
  bottom: "Convolution1057"
  top: "Convolution1057"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise528"
  type: "Eltwise"
  bottom: "Eltwise527"
  bottom: "Convolution1057"
  top: "Eltwise528"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1057"
  type: "ReLU"
  bottom: "Eltwise528"
  top: "Eltwise528"
}
layer {
  name: "Convolution1058"
  type: "Convolution"
  bottom: "Eltwise528"
  top: "Convolution1058"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1058"
  type: "BatchNorm"
  bottom: "Convolution1058"
  top: "Convolution1058"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1058"
  type: "Scale"
  bottom: "Convolution1058"
  top: "Convolution1058"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1058"
  type: "ReLU"
  bottom: "Convolution1058"
  top: "Convolution1058"
}
layer {
  name: "Convolution1059"
  type: "Convolution"
  bottom: "Convolution1058"
  top: "Convolution1059"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1059"
  type: "BatchNorm"
  bottom: "Convolution1059"
  top: "Convolution1059"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1059"
  type: "Scale"
  bottom: "Convolution1059"
  top: "Convolution1059"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise529"
  type: "Eltwise"
  bottom: "Eltwise528"
  bottom: "Convolution1059"
  top: "Eltwise529"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1059"
  type: "ReLU"
  bottom: "Eltwise529"
  top: "Eltwise529"
}
layer {
  name: "Convolution1060"
  type: "Convolution"
  bottom: "Eltwise529"
  top: "Convolution1060"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1060"
  type: "BatchNorm"
  bottom: "Convolution1060"
  top: "Convolution1060"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1060"
  type: "Scale"
  bottom: "Convolution1060"
  top: "Convolution1060"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1060"
  type: "ReLU"
  bottom: "Convolution1060"
  top: "Convolution1060"
}
layer {
  name: "Convolution1061"
  type: "Convolution"
  bottom: "Convolution1060"
  top: "Convolution1061"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1061"
  type: "BatchNorm"
  bottom: "Convolution1061"
  top: "Convolution1061"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1061"
  type: "Scale"
  bottom: "Convolution1061"
  top: "Convolution1061"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise530"
  type: "Eltwise"
  bottom: "Eltwise529"
  bottom: "Convolution1061"
  top: "Eltwise530"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1061"
  type: "ReLU"
  bottom: "Eltwise530"
  top: "Eltwise530"
}
layer {
  name: "Convolution1062"
  type: "Convolution"
  bottom: "Eltwise530"
  top: "Convolution1062"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1062"
  type: "BatchNorm"
  bottom: "Convolution1062"
  top: "Convolution1062"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1062"
  type: "Scale"
  bottom: "Convolution1062"
  top: "Convolution1062"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1062"
  type: "ReLU"
  bottom: "Convolution1062"
  top: "Convolution1062"
}
layer {
  name: "Convolution1063"
  type: "Convolution"
  bottom: "Convolution1062"
  top: "Convolution1063"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1063"
  type: "BatchNorm"
  bottom: "Convolution1063"
  top: "Convolution1063"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1063"
  type: "Scale"
  bottom: "Convolution1063"
  top: "Convolution1063"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise531"
  type: "Eltwise"
  bottom: "Eltwise530"
  bottom: "Convolution1063"
  top: "Eltwise531"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1063"
  type: "ReLU"
  bottom: "Eltwise531"
  top: "Eltwise531"
}
layer {
  name: "Convolution1064"
  type: "Convolution"
  bottom: "Eltwise531"
  top: "Convolution1064"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1064"
  type: "BatchNorm"
  bottom: "Convolution1064"
  top: "Convolution1064"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1064"
  type: "Scale"
  bottom: "Convolution1064"
  top: "Convolution1064"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1064"
  type: "ReLU"
  bottom: "Convolution1064"
  top: "Convolution1064"
}
layer {
  name: "Convolution1065"
  type: "Convolution"
  bottom: "Convolution1064"
  top: "Convolution1065"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1065"
  type: "BatchNorm"
  bottom: "Convolution1065"
  top: "Convolution1065"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1065"
  type: "Scale"
  bottom: "Convolution1065"
  top: "Convolution1065"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise532"
  type: "Eltwise"
  bottom: "Eltwise531"
  bottom: "Convolution1065"
  top: "Eltwise532"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1065"
  type: "ReLU"
  bottom: "Eltwise532"
  top: "Eltwise532"
}
layer {
  name: "Convolution1066"
  type: "Convolution"
  bottom: "Eltwise532"
  top: "Convolution1066"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1066"
  type: "BatchNorm"
  bottom: "Convolution1066"
  top: "Convolution1066"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1066"
  type: "Scale"
  bottom: "Convolution1066"
  top: "Convolution1066"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1066"
  type: "ReLU"
  bottom: "Convolution1066"
  top: "Convolution1066"
}
layer {
  name: "Convolution1067"
  type: "Convolution"
  bottom: "Convolution1066"
  top: "Convolution1067"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1067"
  type: "BatchNorm"
  bottom: "Convolution1067"
  top: "Convolution1067"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1067"
  type: "Scale"
  bottom: "Convolution1067"
  top: "Convolution1067"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise533"
  type: "Eltwise"
  bottom: "Eltwise532"
  bottom: "Convolution1067"
  top: "Eltwise533"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1067"
  type: "ReLU"
  bottom: "Eltwise533"
  top: "Eltwise533"
}
layer {
  name: "Convolution1068"
  type: "Convolution"
  bottom: "Eltwise533"
  top: "Convolution1068"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1068"
  type: "BatchNorm"
  bottom: "Convolution1068"
  top: "Convolution1068"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1068"
  type: "Scale"
  bottom: "Convolution1068"
  top: "Convolution1068"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1068"
  type: "ReLU"
  bottom: "Convolution1068"
  top: "Convolution1068"
}
layer {
  name: "Convolution1069"
  type: "Convolution"
  bottom: "Convolution1068"
  top: "Convolution1069"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1069"
  type: "BatchNorm"
  bottom: "Convolution1069"
  top: "Convolution1069"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1069"
  type: "Scale"
  bottom: "Convolution1069"
  top: "Convolution1069"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise534"
  type: "Eltwise"
  bottom: "Eltwise533"
  bottom: "Convolution1069"
  top: "Eltwise534"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1069"
  type: "ReLU"
  bottom: "Eltwise534"
  top: "Eltwise534"
}
layer {
  name: "Convolution1070"
  type: "Convolution"
  bottom: "Eltwise534"
  top: "Convolution1070"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1070"
  type: "BatchNorm"
  bottom: "Convolution1070"
  top: "Convolution1070"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1070"
  type: "Scale"
  bottom: "Convolution1070"
  top: "Convolution1070"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1070"
  type: "ReLU"
  bottom: "Convolution1070"
  top: "Convolution1070"
}
layer {
  name: "Convolution1071"
  type: "Convolution"
  bottom: "Convolution1070"
  top: "Convolution1071"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1071"
  type: "BatchNorm"
  bottom: "Convolution1071"
  top: "Convolution1071"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1071"
  type: "Scale"
  bottom: "Convolution1071"
  top: "Convolution1071"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise535"
  type: "Eltwise"
  bottom: "Eltwise534"
  bottom: "Convolution1071"
  top: "Eltwise535"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1071"
  type: "ReLU"
  bottom: "Eltwise535"
  top: "Eltwise535"
}
layer {
  name: "Convolution1072"
  type: "Convolution"
  bottom: "Eltwise535"
  top: "Convolution1072"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1072"
  type: "BatchNorm"
  bottom: "Convolution1072"
  top: "Convolution1072"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1072"
  type: "Scale"
  bottom: "Convolution1072"
  top: "Convolution1072"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1072"
  type: "ReLU"
  bottom: "Convolution1072"
  top: "Convolution1072"
}
layer {
  name: "Convolution1073"
  type: "Convolution"
  bottom: "Convolution1072"
  top: "Convolution1073"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1073"
  type: "BatchNorm"
  bottom: "Convolution1073"
  top: "Convolution1073"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1073"
  type: "Scale"
  bottom: "Convolution1073"
  top: "Convolution1073"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise536"
  type: "Eltwise"
  bottom: "Eltwise535"
  bottom: "Convolution1073"
  top: "Eltwise536"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1073"
  type: "ReLU"
  bottom: "Eltwise536"
  top: "Eltwise536"
}
layer {
  name: "Convolution1074"
  type: "Convolution"
  bottom: "Eltwise536"
  top: "Convolution1074"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1074"
  type: "BatchNorm"
  bottom: "Convolution1074"
  top: "Convolution1074"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1074"
  type: "Scale"
  bottom: "Convolution1074"
  top: "Convolution1074"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1074"
  type: "ReLU"
  bottom: "Convolution1074"
  top: "Convolution1074"
}
layer {
  name: "Convolution1075"
  type: "Convolution"
  bottom: "Convolution1074"
  top: "Convolution1075"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1075"
  type: "BatchNorm"
  bottom: "Convolution1075"
  top: "Convolution1075"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1075"
  type: "Scale"
  bottom: "Convolution1075"
  top: "Convolution1075"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise537"
  type: "Eltwise"
  bottom: "Eltwise536"
  bottom: "Convolution1075"
  top: "Eltwise537"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1075"
  type: "ReLU"
  bottom: "Eltwise537"
  top: "Eltwise537"
}
layer {
  name: "Convolution1076"
  type: "Convolution"
  bottom: "Eltwise537"
  top: "Convolution1076"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1076"
  type: "BatchNorm"
  bottom: "Convolution1076"
  top: "Convolution1076"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1076"
  type: "Scale"
  bottom: "Convolution1076"
  top: "Convolution1076"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1076"
  type: "ReLU"
  bottom: "Convolution1076"
  top: "Convolution1076"
}
layer {
  name: "Convolution1077"
  type: "Convolution"
  bottom: "Convolution1076"
  top: "Convolution1077"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1077"
  type: "BatchNorm"
  bottom: "Convolution1077"
  top: "Convolution1077"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1077"
  type: "Scale"
  bottom: "Convolution1077"
  top: "Convolution1077"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise538"
  type: "Eltwise"
  bottom: "Eltwise537"
  bottom: "Convolution1077"
  top: "Eltwise538"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1077"
  type: "ReLU"
  bottom: "Eltwise538"
  top: "Eltwise538"
}
layer {
  name: "Convolution1078"
  type: "Convolution"
  bottom: "Eltwise538"
  top: "Convolution1078"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1078"
  type: "BatchNorm"
  bottom: "Convolution1078"
  top: "Convolution1078"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1078"
  type: "Scale"
  bottom: "Convolution1078"
  top: "Convolution1078"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1078"
  type: "ReLU"
  bottom: "Convolution1078"
  top: "Convolution1078"
}
layer {
  name: "Convolution1079"
  type: "Convolution"
  bottom: "Convolution1078"
  top: "Convolution1079"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1079"
  type: "BatchNorm"
  bottom: "Convolution1079"
  top: "Convolution1079"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1079"
  type: "Scale"
  bottom: "Convolution1079"
  top: "Convolution1079"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise539"
  type: "Eltwise"
  bottom: "Eltwise538"
  bottom: "Convolution1079"
  top: "Eltwise539"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU1079"
  type: "ReLU"
  bottom: "Eltwise539"
  top: "Eltwise539"
}
layer {
  name: "Pooling3"
  type: "Pooling"
  bottom: "Eltwise539"
  top: "Pooling3"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling3"
  top: "InnerProduct1"
  inner_product_param {
    num_output: 10
    bias_term: true
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}

